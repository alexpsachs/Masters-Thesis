{
    "kittens": "Not necessary, we can just leave in specific branching.\n. Yeah this looks right, the spec text that's inlined is correct but I must have made a few typos when turning it into code. Thank you @NTillmann!\n. My change is on repl.html not index.html.. This removes flow typing from the entire codebase.. ",
    "NTillmann": "The following test case fails, as symbols on objects are not properly serialized.\njs\n(function() {\n  var myObj = {};\n  var fooSym = Symbol('foo');\n  var otherSym = Symbol('bar');\n  myObj['foo'] = 'bar';\n  myObj[fooSym] = 'baz';\n  myObj[otherSym] = 'bing';\n  inspect = function() { return myObj[fooSym]; }\n})();\nLook for the comment \"#22\" in the code.. This is now implemented.. Closing ancient issue with no concrete work items.. The general issue has been cleaned up by the referenced pull requests, and error messages are emitted for any unsupported object kinds.. However, still not supported, not even with warnings, are ES6 related object types:\nPromises. All kinds of iterators. Generators.\n. Search for \"#26\" in the code base to find related TODOs.. Fixed by referenced commit.. Obsolete. We are setting up internal integration tests.. Prepack (in serialiser.js) already has some knowledge built-in regarding the require-implementation that's typically used in React Native bundles. We need to generalize this and make it configurable for other popular implementations.. Something seems wrong here. You two commits add up to... No change?. Abandoning.. Abandoning early proposal.. We must avoid producing the recursion limit exceeded  error, as it causes Flow to ignore half of our code... It's a bug in Flow. You can try to reach out to Avik Chaudhuri for more information... It might already be fixed in Flow 0.39. Try updating the Flow version in package.json to 0.39 to see if that fixes things. Otherwise, what triggered the bug were disjunctive type checks of the form \"x instanceof A || x instanceof B\". Try replacing those in your code with \"((x: any): instanceof A) || ((x: any): instanceof B)\".. You can increase the maximum heap size on the node command line, e.g. to 8GB instead of the default 4GB (I think):\n  --max_old_space_size=8192. This change doesn't really enhance the functionality yet, but just introduced the new stable identity, right? I don't fully understand the vision yet, in particular around property deletions and re-additions. Is the idea that the PropertyBinding will remain in place for a deleted property, and maybe the descriptor in it becomes optional to indicate that the property was deleted? . Abandoned.. Re. not fixing anything: It might be worthwhile to dig through the test262 test suite to see if such a test actually does exist. Maybe by running the entire test suite without all of the exclusions, and a special notification when that former TODO case is invoked. If we find such a test, we should enable it. Otherwise, as Herman said, it would be nice if we could contribute a test to the test262 suite --- it's open source, after all :-) In any case, Nick, if you feel that this is out of scope for this task, then feel free to skip adding a formal test.. The actual coverage information looks a bit dubious.. The changes make the serialiser tests fail. The serialiser walks the final heap, and generates code to reconstruct all objects and their properties. The serialiser should just ignore those new caller and arguments properties. Look at the function canIgnoreProperty in src/serialiser.js; you probably want to add two new special cases there.. I am with Herman that we shouldn't execute twice, just serialise twice. Execution creates new values by design, and then we'd have to somehow relate them. Dealing with the serialiser internal state should be easier.. By far most of the serialiser state should be reset. (Or better design: Separate serialiser into two classes; one with persistent state, and one that gets created twice and holds all of the state that needs to get reset.). In fact, I don't see any state in the Serialiser class that should be kept around between the two serialisation runs. However, there is a small problem.... The serialiser uses preludeGenerator.generateUid() to generate unique identifiers. It might actually work to just serialise twice and generate a lot of Uids, but we would waste a good chunk of \"address space\", leading to longer ids and bigger code, which we don't want. We cannot just undo the changes to the uidCounter either, as there's an interaction with the memoiseReference function generates a uid but also mutates the PreludeGenerator's prelude array and memoisedRefs map.  . Different approaches possible to deal with that. 1) You could add a \"save\" and \"restore\" function to the prelude generator that saves and restores its relevant state between the two runs. 2) You could introduce two \"address spaces\" with two counters: Reserve the prefix \"_0\" for all uids needed for memoiseReference, and let the regular uids start with \"_1\" (and still using \"_2\", \"_3\", ...). Then you only need to save and restore the regular id count, as the mutations to the prelude array and memoisedRefs map can be kept.. With the wrapper, it's incorrect for the \"var o = \" case.\nNote that certain frameworks, in particular React Native, have an interesting interaction going on between the JavaScript and native side: There are implicit ordering dependencies. That motivated the somewhat braindead looking preservation of all assignments to global properties.. The latest code we generate for @sebmarkbage's original example is now:\njs\nx = 1;\nx = 2;\nAdding something to the code to prepack that triggers the function wrapper will make things right.\njs\nvar x = 1;\nvar y = function() {}\nprepacks to\njs\nvar y, x;\n(function () {\n  var _0 = function () {};\n  x = 1;\n  y = _0;\n})();\nWhich is wrong as the variable declaration has been eliminated.  That should be easy to fix.\nAnd then we can close this issue.\n. The following serializer test currently fails:\njs\n// does contain:var x                                                           \nvar x = 1;\nThis is what needs to be done:\n- Add a file with this test code to test/serializer/basic, and \n- Fix the underlying issue (look in src/serializer/ResidualHeapSerializer.js at what happens with ast_body if not this._shouldBeWrapped(body)).. Remaining issue got addressed by referenced merged pull request.. Fixed by referenced commit.. Fixed by #450.. Fixed by referenced pull request.. Abandoned in favor of a sequence of smaller pull requests.. Taking a.foo and embedding that to a string should be good enough.. Fixed by #457.. Fixed by https://github.com/facebook/prepack/pull/387.. Superseded by https://github.com/facebook/prepack/pull/383.. Known issue, introduced by a recent refactoring. In src/intrinsics/ecma262/ObjectProto_toString.js, it should not do \"in\" checks, as we now introduce properties with getters and getters for internal slots.. Fixed with referenced pull request.. There are really two different things to consider here:\n1) Creation of objects with internal slots. We are tracking that issue #416.\n2) Objects (which might or might not have corresponding internal slots) with an intrinsic prototype.\nHere's a test case that shows how we fail to do 2) properly:\n(function() {\n    var x = {}\n    x.__proto__ = Number.prototype;\n    inspect = function() { return x.__proto__.constructor.name; }\n})();. The general issue has been cleaned up by the referenced pull requests, and error messages are emitted for any unsupported object kinds.. Implemented by #421.. Implemented by referenced pull request.. Implemented by #697.. The general issue has been cleaned up by the referenced pull requests, and error messages are emitted for any unsupported object kinds.. We will want that (general React Native compatibility mode). But that's basically a new feature that we don't have yet.. I am happy, but CircleCI points out two Flow issues. Please fix those (I wrote some more about that in an earlier comment.). I think default parameter values are only ES6. So for the time being, we could just emit an \"not supported error\" instead of generating illegal code.. The following test case exposes the issue with the Prepack test runner (just adding the 'inspect' function):\n(function() {\n  let old = Array.prototype.forEach;\n  Array.prototype.forEach = function() {};\n  Array.prototype.forEach = old;\n  inspect = function() { return Array.prototype.forEach.name; }\n})();. (Summarizing offline discussion with Sebastian.)\nThe right way of modeling this would be through abstract values. However, Prepack's symbolic execution machinery isn't complete enough yet.\nSo in the short term, we could tag a ConcreteValue as not-serializable, and then the serializer could complain if it comes across it. This might work, but is problematic as non-object primitive values only have an incidental identity in Prepack.. Recently, ObjectValue got a new internal slot in Prepack: refuseSerialization. This is quite related to the original idea here...\nIt should be straightforward...\n- to generalize refuseSerialization to potentially apply to all values, and\n- to implement the suggested __poison(concreteValue) API in src/intrinsics/prepack/global.js.\nIn this approach, without involving AbstractValue, what's a bit shaky is when other values are derived from it. For example, if the poisoned value is a number and we add one to it, I feel like the resulting value should also be poisoned. This is similar to taint tracking. Then we also have to worry about branches getting tainted, and soon the entire heap is tainted... Maybe @sebmarkbage has some more thoughts on this? Is only implementing this for ObjectValue in fact a good compromise?. Fixed by referenced merged pull request.. We don't generally rely on function hoisting, but if you hit this there's certainly a bug somewhere in the cycle breaking. I need some help to reproduce it.... Thanks for distilling the repro! That really helped.\nFixed by referenced merged pull request.. You've found the right place to plug in your check. Instead of looking for expression statements, a more specific test would be: Make sure that there is no \"VariableDeclaration\" statement, and also recurse into \"BlockStatement\"s. Please also add the tests we talked about in email.. I see. A FunctionDeclaration is like a VariableDeclaration, or you also need to generate a wrapper if that's present.. Fixed by referenced merged pull request.. Fixed by referenced merged pull request.. Fixed by referenced merged pull request.. Implemented by referenced merged pull request.. That's a great example for Prepack! Just to make sure I understand the intention of opening this \"issue\": I assume this is to track a bunch of great usage examples, which we can 1) try to optimize for, and 2) embed as examples in our documentation and/or interactive website in some selection UI.. Sounds like a particularly great way of dealing with #24.. Eval is a problem in general. Even when catching all identifiers used by eval calls executed while prepacking, future eval calls issued by invocation of residual functions may also reference identifiers that Prepack injects. What can we do that is foolproof and still efficient?. More work will need to be done. I am closing this for now, until someone else picks it up.. #856 logs an error when we run into value scoping limitations. As a result, we'll never silently generate wrong code. That's great. What still needs to be done is to actually support those scenarios.. Fixed by referenced pull request.. Implemented by referenced pull request.. Implemented by referenced pull request.. The referenced pull request implements the basic functionality.\nHowever it does not yet determine the minimal set of live objects.\n. Remaining work is tracked in #680.. Implemented by #643.. Implemented by referenced pull requests.. Fixed by referenced pull request.. Fixed by merged referenced pull request.. Subsumed by the bigger #597 agenda.. All cited issues have been resolved. A good part of the intention behind this issue has been implemented. Therefore, closing issue now.. We had some issues with a particular node.js version > 7.0.0 --- somehow we managed to trigger a JIT crash! So this needs some testing with all our workloads.. Prepack already has a \"timeout\" concept to deal with loops, there also needs to be a max-stack-depth option to deal with that practical limitation.. Prepack cannot just skip a loop (or recursive call), as Prepack then wouldn't know what all possible side effects on the heap would, and what values the code could return or exceptions it could throw. That's a hard problem, and it's on our longer term roadmap. Regarding termination determinism, you are right, the current wall clock approach is not deterministic. A evaluation-call-counter-approach would be a great addition as well to make it deterministic!. Hi @motiz88, do you want to go ahead with a pull request that just makes Prepack fail nicely in case of some-configured-stack-depth-exceeded? Otherwise, someone else might want to pick it up. Thanks!. The basic issue was addressed by the closed pull requests referenced above.\nHowever, due to a bug on the website, the error isn't surfacing there. I opened #985 to track that.. Closing as the discussion seems to have run its course.. Support for model arrays is still TBD.\nFor functions, the type (first __abstract argument) can be \"function\".. I created #610 to track the issue with the meaningless invariant. The opportunity to do constant folding is there indeed, but goes way beyond what Prepack can do today. #597 describes a path to that future. In any case, closing this issue as the original question isn't actionable.. This has been resolved by #509.. Closing due to lack of interest... If anyone would like to work on this, feel free to re-open.. Closing as question got answered.. That looks like a node.js or v8 bug to me. Have you tried using the node.js LTS? Do you want to take this issue to the node.js or v8 maintainers?. Closing due to inactivity and missing CLA.. Closing as questions seem to have been answered.. Closing as the question got answered.. The latest Prepack in master has the fix from the merged pull request. But there hasn't been a new npm release yet, and that's when we'd update the website as well.. Closing as the question got answered.. Closing as the question got answered.. Closing as we are tracking the issue in #543.. Check out the timeout option: https://prepack.io/getting-started.html\nOtherwise, as others said, it's by design that Prepack runs the global code.. The issue is tracked in #558. We'll post a roadmap soon.. At this time, very very few. Please follow #24 for updates on this situation.. The serializer could certainly look for some patterns and emit better code.. Optimization implemented as part of #636.. Indeed, watch out for v1.0.. This should address #539.. The generation of new identifiers inside Serializer#_spliceFunctions() is needed to distinguish different captured activation scopes. That by itself isn't wrong. What was wrong is that for some reason not all occurrences of init got the same treatment --- after all, they should have all resolved to the same scope.\nI looked into it a bit more and figure out that it was due to the ordering in which the functions were explored during the visiting phase, which resulted in the creation of different binding instances, and only the last one won. I fix this in #676 and add a regression test.. Fixed by referenced pull request.. \"$SetData, $MapData, $WeakSetData and $WeakMapData need to get tracked\" So it's known to be broken when we enter partial evaluation mode? I am tagging this as a bug.. Seems like it's all done.. Try to Prepack this, where I threw in some environment modelling so that Prepack knows about x, y, stack.\n```\n(function() {\n  let stack = __abstract({}, \"stack\");\n  __makeSimple(stack);\n  let x = __abstract(\"number\", \"x\");\n  let y = __abstract(\"number\", \"y\");\nlet index = 6, nextIndex = 0;\n  //translate operation\n  nextIndex = index + 6;\n  stack[nextIndex - 6] = stack[index - 6];\n  stack[nextIndex - 5] = stack[index - 5];\n  stack[nextIndex - 4] = stack[index - 4];\n  stack[nextIndex - 3] = stack[index - 3];\n  stack[nextIndex - 2] = stack[index - 2] + stack[index - 6] * x + stack[index - 4] * y; //e\n  stack[nextIndex - 1] = stack[index - 1] + stack[index - 5] * x + stack[index - 3] * y;\n})()\n```\nIf you try this today, you might notice that Prepack generates illegal property accessors, e.g. stack.0 instead of stack[0]. I'll file a bug for that.. We'll track the remaining bug in #581.. I have noticed that as well. It can certainly better. When I looked at it myself, I got a bit confused as to whether all browsers define the same special properties on RegEx, that's something else to look into. In any case, a freshly defined RegExp shouldn't need any such property definitions.. If you change \"c++\" to \"c=c+1\", your example works already! So supporting assignment operators like += abstractly seems to be the feature request here. . I opened an issue regarding the assignment operator: #594.. I filed an issue for the invariant failure (#596). As a workaround, things work if there's a common return statement at the end:\njs\n(function(){\nlet c = 0;\nlet overflow = false;\nfunction check() {\n  return global.__abstract ? __abstract('boolean', 'true') : true;\n}\nfunction call() {\n  let result = 4;\n  if (check()) {\n    c = c + 1;\n    if (c > 2) {\n      overflow = true;\n      result = 3;\n    }\n  }\n  return result;\n}\na = call();\nb = call();\ninspect = function() {\n  return overflow;\n};\n})();. This is a small repro found by looking at the example in #577.. Addressed by #1436.. That sounds like a cool feature --- turning Prepack into a static checker.. I imagine that this would be triggered by a new option, e.g. --doNotSerializeObjectFreeze.. Freezing also has the side effect of making all properties non-writable and non-configurable. That's something else that you don't want Prepack to reflect when generating code.\nWould you want to ignore this for all properties that were explicitly defined to be non-writable and non-configurable? That becomes tricky.. I approved it, but two more thoughts:\n1) Sebastian might be on to something with this request for a cyclic test. You only delay until [obj] available, but there might be other pending assignments that are waiting for additional values. And then those would get serialized later.\n2) Freezing an object seems to make all properties non-configurable. Right now, we generate correct but super ugly code for that which we wouldn't have to do when freezing the object afterwards. You could proceed and create a new issue for that.. This seems to be the issue:\n91% additional asset processingThis operation is not yet supported on abstract value\n__IntrospectionError\nat bundle.js:34992:71\nYou could either look at bundle.js:34992:71 and try to understand what's going on there. In a nutshell, the code is doing something that's not currently supported by Prepack along the global code. Could be a loop over some values that cannot be determined at build time, or could be something else.\nPrepack is not yet ready for use in production, and one of the remaining issues is having better error message.... Also see here: #544.. Do you have steps for us to reproduce the issue?. Closing, as we couldn't make progress on the diagnosis. Feel free to re-open with new information.. Closing empty issue.. That looks interesting, but something seems to have gone wrong with the git additions. Your pull request includes the test/test262 contents which is meant to be a submodule. Can you try to clean that up? Thanks!. Implemented by #945.. Addressed by #679.. As the way Prepack optimizes the code is quite different from normal compilation transformations, I would expect Prepack and the Closure compiler to be quite complementary. It's great to see that you are finding that to be true in your example.\nThe Prepack team didn't study the synergies in detail yet.\nDid you see this tweet? https://twitter.com/roman01la/status/859849179149021184. Related to #22, #26.. Hm, good question. Creation of symbols works, but symbols on objects are not serialized. I'll add a comment to #22 that further tests are needed. But it may not be relevant for this issue.. Argh, we really need to do #472.. Seems to have been fixed, as I cannot repro anymore.. Closing as we now have dedicated issue #736 to address this shortcoming.. It looks like the question got answered.. You need to tell Prepack about this assumption it can have about the initial environment, e.g. like  the following. Note that this is only safe to do if define cannot throw an exception, and doesn't update any observable state.\njs\n(function() {\n  __assumeDataProperty(global, \"define\", __abstract(\"function\", \"define\"));\n  define(\"a\", 1, 2);\n})();. The first example works now. However, switch cases over abstract values don't seem supported yet.. \"Visible side effects\" means side effects that would mutate any objects on the JavaScript heap.. To implement this, start by chasing down what happens in the definition of __residual in src/intrinsics/prepack/global.js, and simply omit the construction of a result value in the case of a void type. Either by supporting void directly in the called functions, or by creating new variations of the called functions specifically for the void case, if that results in cleaner code.\nAdd a test case in test/serializer/abstract that verifies that it works.. > I think \"visible\" means more specifically that something else in the program after this residual will read from those things. It is fine to mutate objects on the JavaScript heap, e.g. if this residual function is last in the program.\nYou are right. My previous statement was too conservative.. Implemented by #709.. Implemented by #711.. Closing due to inactivity.. Here's what's going on: Prepack only optimizes code that gets executed along the global code path - that's what we consider the initialization phase. Residual functions such as f just get carried over into the prepacked code (with some tweaks to properly resolve captured variables). As f doesn't get invoked here, it doesn't get optimized. Small wrinkle: If you would invoke f, I'd expect that you get an internal TODO telling you that setTimeout is not yet supported.. Right. This keeps coming up. I created a dedicated issue for this that describes in some more detail what's going on, and what needs to happen: #632. This is part of the bigger effort to implement DOM shims (#24). But if requestAnimationFrame & cancelAnimationFrame are what you need now, we are happy to take your contribution!\nA few things would have to be done to get it fully working:\n1. Add implementations exactly mirroring what's happening already for setTimeout and setInternal.\n2. We need to implement the TODO: The call needs to be emitted to the code generator so that it appears in the residual program.\nI'll try to create a pull request today for the TODOs, then you can take it from there. Thanks for offering your help!. Looks like @sebmarkbage thought of most of the relevant issues...\nAs Sebastian said, the serializer already issues Object.defineProperty, that's easy. Deleting properties on the home object when needed should also be okay. Cycles in general are a problem, and are handled via the _shouldDelayValue / _delay mechanism in the serializer.\nTo begin with, changes will be needed in two places:\n1) The ResidualHeapVisitor.js will have to announce dependencies on the [[HomeObject]] in visitValueFunction.\n2) The serializer.js will have to... a) emit custom code in _serializeValueFunction for functions that are in fact classes, and b) write up functions part of the home object probably in the default case of _serializeValueObject, possibly deleting them afterwards.\nIf it is known that a function is a class, then I'd prefer to keep the class structure in the serialized code instead of always falling back to defineProperty calls, which is more verbose and likely more expensive. And when there are super references, then we of course have to stick to the original structure.\nThere's a general assumption in the serializer that function definitions get hoisted. If the only way to declare a function properly is by sticking it within in the home object declaration, then this assumption doesn't hold anymore. Fixable, as the serializer can generally deal with arbitrary dependencies, but it will need a careful review.\nThis is a huge undertaking. I suggest to break it up into manageable chunks, where Prepack simply detects unsupported scenarios and issues a this.logger.logError to report the limitation --- there are already a handful of existing unsupported cases that you can find a ResidualHeapVisitor.js. Then you can later lift the limitations one by one.. Hi Kevin, thanks for asking!\nThere's one low-hanging fruit in the short term: Dead-code elimination in residual functions, leveraging knowledge about constants computed along the global code. This would effectively optimize the following code:\njs\n(function () {\n  let f = false;\n  global.residual = function () {\n    if (f) { console.log(\"eliminate me\"); }\n    return 42;\n  }\n})();\nI'll follow up with another comment on how that can be achieved.\nLong term, and more comprehensive, would be to build out the true \"partial-evaluators\", an early prototype of which can be found in the src/partial-evaluators directory, and apply them on the residual function AST nodes, starting from a \"havoced state\" where nothing is known, except for those known constants I mentioned earlier. If done right, this will also achieve deadcode elimination, but also constant-folding, and possibly much more. @hermanventer will later write more about the required work.\nI'd be happy to chat with you some more in person. Feel free to reach out to me: nikolait@fb.com.. How to do basic constant-folding in residual functions:\nWe already rewrite residual functions, replacing all captured local variables. This happens in the ClosureRefReplacer in src/serializer/visitors.js. For each captured local variable, we determine if it's ever modified. If not, we can often replace it with the (effectively constant) value computed along global code execution. For the example code I write in the previous comment, it replaces f with false.\nOn top of that, the existing visitor could be enhanced with simple rules, e.g. for an IfStatement, it could check if the condition (after the substitution I just mentioned) is the literal true or false, and then rewrite the AST node to the consequent or alternative.\nThis should make the following serializer test case pass:\njs\n// does not contain:eliminate\n(function () {\n  let f = false;\n  global.inspect = function () {\n    if (f) { console.log(\"eliminate me\"); }\n    return 42;\n  }\n})();. > What would be the appropriate place to add dead code elimination?\nFor the quick win, the ClosureRefReplacer is the right place. Doesn't look super clean, and it isn't the long-term solution, but it's where we can do something now.\n\nI would love it if it were possible to assert some initial conditions\n\nRight... Ideally, all built-ins would get frozen, at least at the end of the global code, but that's not typically the case. We are currently working on a different feature that does in fact make assumptions on what parts of the global code get mutated (#799). So I would be fine by making this assumption for the partial evaluator if some flag is given (the default should still be to be safe).. While basic dead-code elimination has been implemented by #1061, we are still leaving a lot of optimization potential on the table.\nConsider the following code:\njs\n(function () {\n  let c = false;\n  function f() {\n    let x = 0;\n    function g() {\n      return c ? x++ : 42;\n    }\n    return g;\n  }\n  global.x = f();\n})();\nDead-code elimination removes the need for x, and yet the referentialization logic produces a huge chunk of code to deal with x.... No content.. The gh-pages branch doesn't have a properly set up CI, so you can ignore the failure.. As @wdhorton says, this is by design.. Good catch regarding the multiple scopes issue!. You still need to rebase on the latest serializer.. Is there a Babel PR to monitor for this issue?\nAs far as I understand, the remaining work here is to monitor when Babel supports this, and then update to the latest Babel, and find and remove this comment: $FlowFixMe need to backport static property to BabelNodeClassMethod. We've upgraded to Babel 7.. Implemented by #759 and #787 (building on \u00a0#760). Many thanks to @wdhorton for driving this!. I see such a error/warning messaging system as secondary.\nFirst of all, Prepack, \"--residual\" or not, should simply preserve the program behavior: When the original program (conditionally) throws a particular exception, then the rewritten program should do the same. This makes a lot of sense, also without \"--residual\", for conditionally thrown exceptions that indicate that very unlikely environment misconfiguration where the developer chose to just throw an exception instead of handling it more gracefully.. Implemented by #1710.. Right now, Prepack does not know that the number value associated with a Date is always non-NaN number. Plumbing that through will take some time.\nYou can either work around this by testing for whether you are running under Prepack (e.g. !!global.__abstract, and not calling isNaN then), or testing whether d instanceof Date, and then not calling isNaN.. I assume this is meant to address https://github.com/facebook/prepack/blob/master/src/serializer/modules.js#L90-L100?. Look out for #690 in the code to find the place where this needs to get addressed. #798 might be the key to make this safe, which is what should ultimately happen --- not just issuing a warning.. I am pretty sure I've seen it being used. Look for example at SwitchStatement.js, the export default function.. So it is used, case closed.. The abstract values carry in them the ability to produce ASTs, and those can be pretty printed. This could become part of the error message as well.. That looks awesome! I also left some inline comments.... Now implemented: Use that information in the serializer to move initialization of values only used by single residual function into a separate block that runs once inside of the residual function.\nCurrently, measured on a large internal codebase, this moves around 10% of all initializations out of the main code path into residual functions. This seems good enough to me to try to merge this soon.\nConceptually, two low-hanging fruits remain:\n1. All values needed only by more-than-one residual functions, but no other generator, could also get initialized in a delayed way. We could generate common initialization methods for those, and call those from residual functions as needed. My measurements indicate that this could double the percentage of delayed values to somewhere in the area of 20%.\n2. The inline-initialized-require-calls optimizations currently effectively lifts all exported objects to the main scope level. This causes a large chunk of objects to get initialized earlier than needed, another 15%. However, addressing this will yield little benefits, in fact, could make things worse overall: All those objects will have to be initialized once the first delayed require(...) call happens and the giant module table needs to be initialized.. @cblappert Not sure what you mean. Moving around what we do in the global code might be accidentally beneficial if there are external side effects that benefit from a timing change. But I don't see how we can easily delay work overall.. Addressed all feedback. The code should be easier to understand now. Please feel free to re-review... Thanks!. I added three commits that implement, optimize and regression-test delaying initialization of values used from >=2 residual functions.\nThe new regression test will fail until #741 gets merged and this pull request gets rebased once more.. Good catch Herman, but there was one more thing needed to revive the repl.html page: https://github.com/facebook/prepack/commit/60782797c0a0ce7a382816c62b3efa5fd65641ed I wonder if there might be other downstream users, e.g. the webpack integration, that got broken by the requirement for an \"option\" to be set.. Fixed by above commits.. You could leave behind residual code as follows:\njs\n__residual(\"object\", function(console) {\nfor (let i = 0; i < 99999; i++) {\n  console.log(i)\n}\n}, console);\nNote that you should only do this if the residual code that modify any locations that will get referenced later on.\nAlso note that the \"object\" parameter is a bit dubious. We should support \"void\" here. See https://github.com/facebook/prepack/issues/621.. Looks like the question got answered.. Looks good to me. Do you also want to add this to the master branch? The challenge there would be to figure out which Prettier options will be most consistent with the existing eslint settings.... Closing due to inactivity.. Kind of. It eventually calls testTimeout. That seems like the right place to install a pure counter-based approach. It would be great if you'd take this on!. Fixed by referenced merged pull request.. It looks like it will be tough to land these changes while we keep evolving Prepack...\nHow about breaking this up:\n1. A pull request with just adding the config changes to enable running Prettier, but not actually applying Prettier to all sources. Approving and merging should be quick.\n2. Then I can run Prettier once and change the ES-Lint rules, and merge this quickly.\n3. Then we can figure out how to enforce Prettier in the circle configuration.. The snippet in the original comment is actually a proper Prepack test case. Drop it in test/serializer/basic with a reasonable file name, and run yarn test-serializer to see it fail.\nTo tackle this, go to serializer.js, and look at _serializeValueObject. In the for (let [key, propertyBinding] of val.properties) loop, even when delaying we should still push a mapping to undefined.. Implemented by referenced merged pull request.. Realized by referenced merged pull request.. In ResidualFunctions.js, there are three places right now where the expressions like __captured_scopes[__scope_2] are build up via t.memberExpression(this.capturedScopesArray, t.identifier(scope.name), true). Those are the places where we need to do some tweaking.\nIn _getReferentializedScopeInitialization, before emitting the if statement, we should emit a let statement as outlined above. Instead of hard-coding a local variable name such as __captured_scope, the name of the new local variable could be mangled from the scope.name in case there's more than one relevant scope.\nThen in _referentialize, you would replace the member expression with a reference to the corresponding local variable.. Addressed by merged pull request.. As this change sits on top of, but also includes, previously approved pull requests, it's difficult for me to see what's new. Can you merge the other pull requests and rebase this one on top of them?. Note that eliminating the pass requires that the --delayUnsupportedRequires option is turned on, so that the detourCall logic gets triggered.. Added test case. This uncovered issues around the treatment of the new FatalError concept, and the timing of accelerating require calls. Both issues are addressed by the most recent commits.. So, I ran prettier over the code base (#778), but somehow the new prettier-ci-check check still fails with no useful message. Any idea what's going on, @wdhorton?. Okay, figured it out... Apparently, there are still a few offendingly formatted files, and unfortunately, the prettier-ci-check output just doesn't say what they are. Will fix those files, and then try this again.. Incorporated by referenced pull request.. The TODO: join callables is actually a secondary issue. The primary one is that the global.b = Impossible 2\"; gets hit.. This seems to be resolved, as this is currently by design.. Fixed by referenced commit. Thanks, @echo304!. Superseded by #786.. Updated README. Using npm for using Prepack should be fine. You only need all the scripts for further development work. I added a note describing that. . Okay, you one really needs yarn to develop.. > Also investigate whether prettier automatically fixes all lint errors and if eslint is still necessary.\neslint is doing much more than just checking for formatting rules. For example, it disallows the use of eval, switch-case-fallthroughs, octal literals, with, unused variables, .... So the remaining question is basically if there's a convenient way of running Prettier in Nuclide, or detecting that Prettier needs to get run.. @yinghuitan, So we should add @Format to every single file? Any way to configure that more centrally?. Nice cleanup!. See https://github.com/facebook/metro-bundler/commit/dee58678c627e97024000c9b82e372dbd7ba3bf0 for the relevant Metro changes.. All of the work required to deal with this in Prepack has landed.. Decomposing the overall required work:\n1. Add option to Prepack to identify a set of function on the global object which should get handled, and then exploring them separately for effects after the global code is done.\n2. Build a checker to determine that effects are mutually disjoint (Herman volunteered for that).\n3. Enhance serializer to rewrite those functions for the special case that they are pure, i.e. do not mutate any shared state.\n4. Enhance serializer to rewrite those functions in the general case, taking care of general effects, including mutations of shared state.\n3 by itself seems to be a very useful feature, and should be strictly easier than 4.. 1. Is done by #846.\n2. Is done by #850 and #857.\n3. Is done by #912.\n4. Is still missing, with remaining work outlined in #987, #988, #989, #990.. #988, #989, #990 are done.\nStill open is #987.\nRecently new issues surfaced and are still open: #1250 and #1238 and #1140 and #1093.. #988, #989, #990, #1238  are done.\nBugs still open are:\n- Incorrect sharing of bindings of residual/additional functions (#1250)\n- Rework #1107 to work and be cleaner (#1140)\n- Make additional functions capture precisely the values they need (#1093)\nNew feature requests:\n- Make Additional Functions work with arguments (#987)\n- Support multiple additional functions updating a binding (#1087)\n- Support for nested additional functions (#1398). #988, #989, #990, #1140, #1238, #1093  are done.\nBugs still open are:\n- Incorrect sharing of bindings of residual/additional functions (#1250)\nNew feature requests:\n- Make Additional Functions work with arguments (#987) --- first basic version is working!\n- Support multiple additional functions updating a binding (#1087)\n- Support for nested additional functions (#1398). Cannot reproduce. This serializer test case passes:\n(function() {\n  Object.prototype.f = function() {\n    return typeof this;\n  }\n  let n = 42;\n  let t = n.f();\n  inspect = function f() { return t; }\n})();. To avoid the complications around invariants, I suggest adding an option to derive/deriveAbstract \"skipInvariant: bool\". Because really, checking the invariant for Date.now and Math.random is needed the least. Invariant checking is really meant for less predictable model interactions.. Ideally, the logic wouldn't rely on the two-pass serializer. (I am considering killing that feature if it turns out that it doesn't actually matter in practice.) Instead, I'd hope that you can simply check if residualValues contains the AbstractValue corresponding to the declaresDerivedId of the isPure bodyEntry (maybe store the AbtractValue itself also in the bodyEntry for easy access, or even better, replace the current declaresDerivedId with the corresponding AbstractValue).\nIf not, then you could still run all the code that serializes, but add some logic to context.emit to not actually emit anything. That way, the counts should all line up. . For now, that's probably all that's needed. In general, pure entries could actually take arguments, and then you'd want to do a backwards-pass over the generators to identify transitively dead entries. But for now, a TODO to that extent should be enough.. It's a bug, tracked in #454, and should get fixed indeed.. Closing this issue as it's a duplicate.. @yinghuitan, I think all the pieces point to the need to of an intermediate class in our hierarchy, something from which NativeFunctionValue and ECMAScriptFunctionValue derive, but that excludes BoundFunctionValues.. Increasing cycle length for this well-understood reason is okay.\n@hermanventer, how do you feel about OrdinaryFunctionObject?. It would make the code cleaner, as some properties of ECMAScriptFunctionValue seems to also apply to NativeFunctionValue, and the alternative is additional type checking in the code.. Great request, and already captured here with a more general detailed plan: #597.. We want it too, but it's really hard, because: JavaScript...\nWhat we are working on for now is prepacking code that runs right from the beginning of time, when everything is perfectly known (as opposed to code that sits somewhere in the middle of the program, at which point so many strange things could have been done to the built-in objects; are you sure that nobody has overridden the String.prototype.repeat function? And even if you can convince yourself, will Prepack be able to figure that out?). There's still a lot we want to do around those scenarios.\nWhen that's all done, we'll look further out.. Closing as there is nothing to do here right now, and we acknowledge that this general idea is something we do want to tackle eventually.. Your model is sufficient, it's now really a limitation in Prepack that you are hitting: Prepack does not yet know how to abstractly handle String.prototype.includes.\nThat function is safe to keep abstract in many common cases. We need to do something similar to #736, see #818 for work-in-progress on how it should be done.. Fixed by merged pull request.. Reassigning to @cblappert, happy to look at it with a repro.... Done by referenced pull request.. Fixed by referenced merged pull request.. Awesome! @cblappert, do you think this might break any internal tooling?. Coming back to my earlier desire to consolidate all the spread-around calls to createAbstract in a single place: Before the .kind property in an AbstractValue was a rarely used thing, used in a way that's like creating quick/lightweight subclasses of AbstractValue. But now, with hashing, the kind string becomes very relevant everywhere: Values are going to be considered the same if they have the same kind (and args hash). And yet, the kind strings are not centrally managed. If I am adding yet another call to createAbstract, I'd have to scan the entire codebase, trace the control-flow around each createAbstract call to make sure that I don't create kind string collisions. (Or maybe I should have really reused an existing kind, but didn't, and then values are not considered equivalent...)\nTo avoid all of this, I'd like to see a central way of how all this is managed.. Done by #894.. Reopening, as #894 effectively enabled factorifyObjects again, but only when the --inlineExpressions option is NOT on. If we do want to support inlineExpressions, factorifyObjects should be improved to deal with the changed code patterns. Also, --delayInitializations produces code patterns that factorifyObjects doesn't currently deal with.. Here's a test case that shouldn't fail:\njs\n// does not contain:call\n(function() {\n    var f = function() {\n        return function() {\n            return (function() { return this.x; }).bind({x: 42});\n        }\n    }\n    var g1 = f();\n    var g2 = f();\n    var g3 = f();\n    inspect = function() { return g1() + g2() + g3(); }\n})();. Many visitors have been converted to the fast one, and the rest seems to rely on functionality only provided by the general Babel visitor.. Good question. Most tools I know typically terminate after printing the help text when asked to do some via --help. You might complain if there are any more arguments present, but I don't think it's necessary.. Fixed by merged pull request.. Here's a test case for the simple case that already works. Please just add this test case to test/serializer/basic for completeness.\njs\n(function() {\n    var isStrict = function() {\n        \"use strict\";\n        return !!this;\n    };\n    inspect = function() { return isStrict(); }\n})();\nAnd here's a test case that doesn't work, and that's what need to get fixed:\njs\n(function() {\n    var isStrict = function() {\n        \"use strict\";\n        return function() {\n            // This function is too big to be inlined.\n            return !!this;\n        }\n    };\n    let f1 = isStrict();\n    let f2 = isStrict();\n    let f3 = isStrict();\n    inspect = function() { return f1() && f2() && f3(); }\n})();. This is the commit that introduced the invariant violation: https://github.com/facebook/prepack/commit/69761bf5972e1ed1daecdc2a2f7928d20813b3c8. Abandoning.. Also see https://github.com/ExpoSEJS/Z3 where this is based off of.. Also see https://github.com/Z3Prover/z3/issues/1298.. @cblappert: Yes! At the bytecode level, for a medium size FB internal codebase, the prepacked byte code size used to be 100.14% of the original byte code size (so a slight increase), and with this change, the size of the prepacked byte code is now at 99.91% of the original byte code size, so prepacking actually reduces bundle size! I'll post this milestone internally later today.... @yinghuitan: In phabricator, when you click through to the logs of \"prepack-test\", there a row called \"gen_bytecode_sizes\", and the size info is at the end of the corresponding log file. Not very elegant and can certainly be made nicer, but it was something Kishore added on during the last days of his internship.. Here's a test case that shows the issue:\njs\n// Copies of enumerable:1\n(function() {\n    Object.defineProperty(global, \"a\", { enumerable: false, configurable: false, writable: true, value: 42 });\n    Object.defineProperty(global, \"b\", { enumerable: false, configurable: false, writable: true, value: 23 });\n    inspect = function() { return a + b; }\n})();. Implemented by referenced pull request.. What is .modifiedobjects.js.swp? Delete?. Indeed, we should measure first what relevant JS compilers actually inline.. I looked into it. For what matters most for Facebook, nothing gets inlined here. And calls to simple functions like $_0...$_2 look rather expensive. Prepack should inline $_0.\nAnd when still parameters are involved, consider a scheme like the following best hidden class efficiency.\njs\nfunction $_0(__0, __1) {\n    let __res = {\n      x: undefined,\n      y: undefined\n    };\n    __res.x = __0;\n    __res.y = __1;\n    return __res;\n}. Related: serializeGlobalBinding currently turn all references to undefined into void 0. Does that have any effect on performance and/or bytecode size?. The main request was implemented by #1387. I also verified that void 0 has no negative implications.. Addressed by referenced pull request. Remaining work sketched in #995.. @hermanventer, might this be related to #900 / #916? The invariant violation there has the same error message that's now presented to me on the website when I type in code with a syntax error: \nThere's no running execution context. I see, wasn't clear to me from the description that this issue is meant to only apply to introspection errors...\nSo the canonical example for which we'd like to get a clickable error position is\n(function() {\n  let a = __abstract();\n  a + 5;\n})();\nI'll open another issue just for the syntax error problem.. Before landing this, there should be a plan to...\n- update internal models,\n- test whether relevant internal tests work with new code and updated models,\n- update existing documentation (there isn't much, of course, there's something extremely rudimentary on https://prepack.io/; this is the opportunity to really document what __abstract, __makePartial, __makeSimple, ... mean/do!). Both rest and spread operators could be made to work for such simple cases, basically creating abstract values for which we know how to generate code that does the right thing. \nWhat will require some thought is how to support further property access operations on the resulting objects: how does it relate to partial / simple objects, which properties are known to exist.... The bug is in how src/methods/properties.js/InternalUpdatedProperty and src/utils/generator.js/emitDefineProperty interact.\nThe pull request that fixes the issue should include the above test case as a new file in the test/serializer/basic directory.. Fixed by referenced merged pull request.. Are you working at the JavaScript source code level, modelling things with __abstract(...) values, or are you plugging deeper into the Prepack infrastructure? I am wondering since you refer to internal concepts such as ObjectValue, AbstractValue, AbstractObject(Value?).\nYou mention that Prepack \"throws an invariant\" --- do you mean you get an invariant violation while running Prepack? That should never happen and would be a bug.\nIt looks to me like props should be an ObjectValue that is marked as \"simple\", e.g. via __makeSimple(...) (meaning that properties can be accessed freely on it, without fearing that some property getter screws things up).  That would allow accesses to .foo and .yar. However, this doesn't solve the .bar access problem. So, what can we do?\n- A concept like a \"deep\" or \"recursive\" simple looks attractive, but that is not without problems.\n- One could model .foo to be the disjunctive value of either undefined or a new simple object; Prepack already has a notion of such value domains that it keeps around for abstract values, however it's not straightforward to write this as a JavaScript model, we could add a new primitive like __oneOf(val1, val2, ...). Then Prepack would explore both branches for the if statement. However, what Prepack is still missing is the concept of refinement (#620) that would allow Prepack to deduce in the then branch that .foo must be the object. @hermanventer considered looking at refinement next, this could be the challenge to solve.... I agree that this is inefficient. But I don't see a simple works-for-all fix.\nGood heuristics might help.\nIt used to be the case that there were no such lazy objects, instead, we generated the following code:\n```js\n(function () {\n  var __captured_x = 13;\nvar _1 = function () {\n    return __captured_x += 3;\n  };\nvar _2 = function () {\n    return __captured_x -= 2;\n  };\nvar _0 = function () {\n    return _1() + _2();\n  };\ninspect = _0;\n})();\n```\nIn other words, the mutable captured variable got initialized eagerly, which is quite reasonable in this example. And that's probably best if there are only very few captured variables that are not objects. If there are very many captured variables, or if they are huge objects, used across more than one function, then some kind of factory function might be reasonable.. Right. The challenge is to figure out the right heuristics when this should kick in, as by itself, adding a new function adds a ton of overhead at runtime.. In the long run, the big switch statement is probably the right thing we can do.\nBut in the short run, we are dealing with a JavaScript engine that will load into memory the entire related code (takes time and memory), and never release that memory again (still takes memory) as long as the function instance is alive (likely forever, even if we would have code to release it when all is done).. @sebmarkbage, I don't understand what you mean regarding the relationship of eager code loading and de-duplicating.. Looks like this was addressed by #1472.. This is related to #585.. Hi @echo304, do you think you'll have time to work on this, or can I look for other volunteers? Thanks!. Addressed by #1436.. Addressed by merged pull request #1223.. Implemented by merged pull request.. Some tests in test/serializer/optimizations involve delaying and acceleration, e.g. require_accelerate.js, require_delay.js.. Always collect statistics. Only print to screen when logStatistics is given.. The same issue currently exists with prepack-cli.js.. Update: You no longer get a plain error, as @hermanventer implemented prepacking exception-throwing code! Yay. So the current output is, wait for it...\n```js\n(function () {\n  var $$0 = {\n    enumerable: false,\n    configurable: true,\n    writable: true\n  };\nvar _$0 = this;\nvar $1 = $0.ReferenceError;\n  var $2 = $1.prototype;\n  var $3 = $0.Object;\n  var $4 = $3.defineProperty;\nvar __constructor = function () {};\nvar 1 = $2;\nvar _0 = (__constructor.prototype = _1, new __constructor());\n$$0.value = \"ReferenceError\\n    at dummy:3:16\\n    at dummy:1:1\", $4(_0, \"stack\", $$0);\n  $$0.value = \"Identifier is not defined\", $4(_0, \"message\", $$0);\nif (_0.proto !== _1) {\n    throw new Error(\"unexpected prototype\");\n  }\nthrow _0;\n}).call(this);\n```\nWhich is correct. And conceptually pretty awesome. But maybe not the most useful result.\nInstead, when a SyntaxError or TypeError or ReferenceError is created (or thrown?), a CompilerDiagnostic error should be created and handled.. Cannot reproduce anymore, website produces useful output :-). Counting each node type contains a lot of information.\nTo do what the issue asks for, ...\n- you could compute aggregates for object creations, aggregating counts of ArrayExpression, NewExpression, or you could go into the ObjectValue constructor and increment a counter there.\n- counting property updates via node counting is more tricky. It's probably easier to go into a helper function such as InternalUpdatedProperty and increment a counter there.\n- To do what this comment asks for: When forking and merging control-flow, compute the maximum value for each explored case., you'd probably have to add the counters to something that gets tracked by the Effects, and then the join operation computes maximums. Please discuss this if it turns out to be too much work, or not clear.. At the very least, the resulting error code should get some help text:\nhttps://github.com/facebook/prepack/wiki/PP0001 is not yet populated.. I think the \"leaking\" concept brought in by the \"pure\" mode addresses this issue, however, it is not something that's enabled by default (yet).. The most simple fix here is to \"blow up\" nicely if length of abstract string is accessed. Bonus points for creating an abstract length.. Agreed with Herman: Let's upgrade to the latest, currently 0.55.. This is expected, as Prepack only optimizes the global code, and not residual functions. You found the right master issue (#632), so I am closing this one as a duplicate.. #1466 enables arguments for additional functions! @cblappert, what is your plan to further enhance this?. Duplicate of #690.. As Herman said in the last paragraph, the real issue is that we need to model some kind of union value where the case selection is not done by an external input that could be named.\nI find the fact that we currently have a special treatment to allow something like this for intrinsics dubious: I don't know any real intrinsic that actually is optional. The way we currently model the JavaScript engine is exact. Where the optionality comes in is in places where we \"abuse\" the intrinsic concept for values that are either derived (intrinsicNameGenerated), or modeled in some form. I feel that the need to make values optional is more general, not necessarily limited to intrinsics, and it's really about forming a disjunction of values, not just with null or undefined.. This is related to #21. As Herman said, there's no urgent need for that. React Native doesn't use such built-in events.. Floating point computations are not necessarily associative, so we currently err on the side of correctness and do not attempt to further optimize the result.\nYou can get rid of the intermediate identifiers by supplying the option --inlineExpressions on the command line. If you are using the web UI, then we have an open issue to add the ability to change options there (#958).. Not all target JavaScript environments fully support Unicode yet. Let's wait a bit with this one.... Thanks for pointing this out, @gustavderdrache! I created #1235 to track that issue.. This is done.. This looks awesome! Thanks for doing this. +1 for @cblappert's request.. I like the look!\nI just tried it out, and there's just one small wrinkle: For the mathRandomSeed, it matters whether it's undefined, or something else. Your change always makes it a string. This actually causes Prepack to generate different code for the following simple example program:\njs\nz = Math.random();\nCan you turn the empty string into undefined?\nThanks!. We recently landed a new feature that goes into this direction: #912 - serializing independent functions. @cblappert --- we need some good documentation for this feature, what it does, what problem it solves, and what it doesn't do (yet)...\nWhen you want to prepack a module factory, Prepack needs to know about the environment. One could think of that environment consisting of two parts:\n- other modules that can be accessed by calling require --- I think that's what you were mainly thinking about. Different ways of dealing with that: If we could separately Prepack that module, we could create a shim from the structure of the produced module value --- however, this would only really be safe if we assume that the module value, and everything reachable from it, is frozen. Alternatively, it should be easy to model the module value that comes back as just an abstract value, of which nothing is known. Alternatively, with a bit more work we could leverage any existing type annotations to inform Prepack about further aspects of the model value, assuming we trust that the static type annotations will be honored at runtime.\n- the global object, and all built-ins. The feature that was just added to Prepack allows prepacking additional functions that just depend on that, assuming that the global object and all built-ins have not been mutated after the end of global code execution. Again, ideally all of those objects and built-ins would actually get frozen at the end of global code execution to enforce this.. I hope we answered the question. Feel free to reopen to discuss more.. This was addressed by referenced merged pull request.. I am still confused about the motivation of separate __get_scope_binding functions.\n- is there a technical need for it? I don't see that yet.\n- is it meant as an optimization, to avoid loading initialization code for additional functions? That I would understand, but I am not convinced that this is sufficient because of how JSC works.. As @cblappert said, adding logic to the test runner that looks for a comment like // requires babel:jsx, which would then trigger running babel with those plug-ins. Feel free to design the comment-string in a way that makes most sense to you.. Thanks for making the changes!. I see. Then the work becomes to make the values into Values, and build up AbstractValues instead of doing concrete operations (+, >), and then letting the already existing infrastructure figure out that the outcome of the comparison is always false.. 1. got fixed by closed pull request #1042.\n2. still to be done, possibly already addressed?. Thanks to @artiebits for the merged pull request!. Names are now reasonable.. +1 for what @hermanventer said. What should probably happen first is that the serializer can actually emit classes (#630) instead of erasing them.. There are really two separate cases to consider for each location that's referenced by an additional function --- object properties and captured variables:\n- the location holds a constant value; we can then inline that value, do constant folding with it, etc. Or,\n- the location is freely mutable; in that case, we should not assume much about the initial value (maybe a type?), we can treat it as an abstract value, and emit code that represents the final state of the location after the additional function has run.\nPoint is: We'll need some annotations to tell Prepack what is what. For object properties, we could leverage the built-in JavaScript feature to \"freeze\" objects, but I am not sure if our users are going to be willing to do that. When starting from ES6, we could leverage const variable annotations.. @trueadm, do you need this feature? Can you tell us a bit more about the circumstances in your application?. One related idea I started, but never put out a pull request because of time constraints: Mark generators as frozen once they get embedded somewhere, and have invariants that deny any further mutation.. Bug triage conclusion: Not gonna happen.. You need to give node more memory in your harness.. Fixed by referenced pull request.. Do you have a test case that fails today to show the remaining issue?. See #1115 to get an idea of what kind of careful code inspection is currently needed to determine if functions are indeed pure.. Here's a serializer test case that brings out the issue:\njs\n(function () {\n  let me = this;\n  let s = me.__abstract ? __abstract(\"string\", \"('abc')\") : 'abc';\n  try {\n    // passing a Symbol should throw an exception...\n    me.s = s.slice(Symbol(), 2);\n  } catch(e) {\n    me.s = \"caught\";\n  }\n  inspect = function() { return me.s; }\n})();. To address the issue, the above test case should be added to the test suite (a file under test/serializer/abstract), and variations should be added to test the different issues mentioned in the first comment in this thread. And of course the issue should be fixed.\nI created a separate issue #1125 for what @hermanventer pointed out above.. This new way of running test262 seems to run way fewer tests than we used to. Is the plan to bring that up to parity with what it used to be?. So much cleaner! Very nice.. In particular:\n- $StringIteratorNextIndex (needs to be NumberValue | AbstractValue)\n- $SetNextIndex (needs to be NumberValue | AbstractValue)\n- $Prototype (needs to have | AbstractValue, which may have wide-spread typing implications)\n- $IteratedString (needs to have | Abstractvalue)\n... and more\nTo get started, pick one, e.g. $SetNextIndex, and do the right thing.. Issue addressed by merged pull request.. Addressed by #1116.. \"Errors only matters if there is a try/catch anywhere between the abstract call and the pure function call. That should be solvable but even this case is so rare that it is probably fine to fatal in that case.\" That should be addressed before landing the pull request, or at least a TODO/issue be created.. also see here regarding pure vs. non-pure functions: #705. LGTM. Before formally signing off...\n- Do you want to remove the [RFC] tag?\n- Can you fix the test issue?\n- @cblappert, what do you think is the nature of the abstract functions in our models? Any regression risks?. Sounds interesting. Similarly, conditions like x === Foo should get reduced to false.\nThis could be reasonable easy to implement:\n- In the ResidualHeapVisitor, determine whether symbols created via Symbol(...) are only occurring in residual functions in conditional positions (i.e., switch selectors, comparisons).\n- If so, apply the proposed optimization in ClosureRefReplacer.. This pull request has been around for a while. What is left to do?. @sebmarkbage, anything we can do to help move this forward?. Addressed by #1724.. This pull request has been around for a while, and even been approved... Is there anything in particular that should be done before landing? (Besides dealing with the merge conflicts...). Does not repro anymore.. I defer to @hermanventer regarding a semantic sign-off...\nI am missing some kind of verification. Either by adding some internal invariant that states some relationship between the lifetime of a scope and modified bindings, or maybe even a test case if the changes here have an observable implication?. This pull request has been around for a while. Are we waiting for @hermanventer, or something else?. I don't think we want this file: test/serializer/abstract/.Call3.js.swp. The \"bind\" call in question should be generated here: https://github.com/facebook/prepack/blob/master/src/serializer/ResidualFunctions.js#L517\nNote that this is a kind-of optional optimization. Issuing the \"bind\" call is guarded by an if statement in front of it, which already lists a bunch of reasons which rule out that \"bind\" optimizations. As a quick work-around, you could disable the \"bind\" optimization altogether. But really, the question is how to express the condition.. It might be enough to just check whether the immediate residualBinding.serializedValue itself is a FunctionValue, a binding just operates on that immediate value, and initialization of any nested structured are taken care off separately.. Looks great! \nThis went a little bit further that was I originally thought, by including the compiled assets, most notably js/prepack.min.js, in the Prepack master branch itself. That's a bit redundant. Similar for a bunch of the other files like prism.js or tether.min.js which could be fetched from elsewhere while building gh-pages.\nI've to think a bit about what's best... I am a bit afraid that the churn on prepack.min.js will bloat our repo size. @sebmarkbage, do you have any opinions on this?. Hm, another issue is when one combines --simpleClosures and --delayInitializations. That brings out further assumptions in the serializer that closure bindings should get initialized lazily.. And another issue with simple closures: Prepack may produce wrong code a function spawns multiple closures. The following test case fails:\njs\n(function () {\n    function f(init) {\n        let x = init;\n        return function() { let y = x; x = 0; return y; }\n    }\n    let f1 = f(23);\n    let f2 = f(42);\n    inspect = function() { return f1() + f2(); }\n})();. We have effectively have simple closures for leaked bindings, and otherwise the existing code generation scheme should be reasonable.. @sebmarkbage, we generate similarly wrong code for your additional functions example without --simpleClosures. So that seems somewhat orthogonal, and should be handled separately.. @yinghuitan, I agree. But it would have made the test runner more complicated, so I decided to go with the simpler solution here.. Filed #1238 to keep track of @sebmarkbage's issue.. Let's see if I understand...\nLet's make your example a bit more involved:\njs\n(function() {\n  var x = 0;\n  callThis(function() { x++; });\n  global.x1 = x + 1;\n  callThis(function() { x++; });\n  global.x2 = x + 1;\n})();\nAfter each call to callThis, the value of x is unknown, and we'd have to make up a new temporal abstract value whose generator entry reads the referentialized x, and stores that in the binding.\nDoes that match what you want to achieve?. Another example...\njs\n(function() {\n  var x = 0;\n  callThis(function() { x++; });\n  global.x1 = x + 1;\n  callThat();\n  global.x2 = x + 1;\n})();\nIs callThis allowed to store the function, and can callThat invoke it again? If so, the set of potentially mutated bindings is getting bigger for every call.. To deal with this...\n- We'd need to figure out at interpretation time which bindings a function captures. Shouldn't be too hard to move around when ClosureRefVisitor is called, and caching the result.\n- We need to be able to emit a \"reading from a referentialized binding\" generator entry. As @sebmarkbage observed, this is tricky as the whole referentialization thing happens rather late, after all the generators have been processed. The easiest might be to first emit some kind of placeholder babel node, and later patch it up once the expression to read a referentialized value is known.\n- We'll have to proactively emit all those generator entries, but we can mark them as \"pure\", and then the visitor will remove all those entries whose results are not used.\nRegarding lazy initialization... Yeah, it's probably best to just disable that for exactly those referentialized binding that are referenced by the reading-from-a-referentialized-binding generator entries. There might potentially be a benefit to keep them lazy as callThis call might be in a conditional generator.. Great!\nWhat I mean is, immediately after a call to callThis the interpreter won't know which bindings will be read later on. So we must emit reading-from-referentialized-binding generator entries for all bindings which at that point are known to have been referentialized.. Thinking about it, another little issue: Conditional branching complicates things a bit. Along different branches, different bindings might have leaked. Ideally, that set needs to get tracked as part of the Effects, and participate in joins. We might not do that and instead just keep a static set around that simply grows. However, that could theoretically lead to suboptimal reasoning / code, as we'd turn some perfectly concrete values into abstract ones along some paths.. I think we have everything that's needed now with the concept of leaked bindings.. Fixed by referenced pull request.. Bonus points for eliminating the unnecessary (nested) block statements {}.... A simplified version of the original test case that still shows an ordering issue when closing inspecting generated code.\n```js\n(function () {\n  function call(fn) {\n    var template = {};\n    __makeSimple(template);\n    var res = __residual(template, function() {});\n    if (!res.success) {\n      throw res.exception;\n    }\n  }\ntry {\n    call();\n    call();\n  } catch (err) {\n  }\n})();\n```. @hermanventer, is #1337 addressing this issue entirely, or is there anything left to do?. I like your new error text! And specialized emit-invariant functions seem like a great idea.. The invariant text is now a bit more informative, but it doesn't include the file/line number yet, that still needs to be done. I don't think we need special invariant methods anymore.. Is that more of a cosmetic issue? For the given example, I'd expect a JavaScript->bytecode compiler with register allocation to get rid of any overhead.. Isn't the goal is one of the upcoming iterations to largely delay JSRuntime.createLazyObject() itself? Or do you have a good idea what percentage will remain in the global code for a long time?\nI'd rather see the overall design pushed in the right direction first.\nOther thoughts:\n- The VM could offer a function that takes an integer array of indices and returns an array of objects. Then we at least safe the array overhead. Any thoughts on that, @simonhj?\n- The loop may safe code size, however, counteracted by need to for additional array-member-access functions. So it's not entirely clear to me that this would be an overall code size or speed win.\n. A high-level description of the change would be nice. Not sure what to expect.... Implemented by referenced closed pull request.. Here's a small repro: \njs\nglobal.d = Object.getOwnPropertyDescriptor(Map.prototype, \"size\");. Turns out that, as written, getCollection actually assigns to a global property called collection, and Prepack properly preserves that!\nSo everything is working as it should, and the original code should probably be modified.. I added it to support running multiple times up to a fixpoint, and I am pretty sure it was necessary back then. Maybe later fixes such as finding all existing ids and not reusing them addressed the original need for this unique suffix thing. If everything works without it, I won't veto removing it altogether.. Fixed by referenced commit.. Indeed, Promises are not yet fully supported. There are certainly things missing in the serializer, but possibly more...\nHere are some obvious things that need to be done:\n1. Search for \"TODO #26\" in the code. Cases for \"Promise\" need to be added.\n2. The new \"Promise\" cases will (hopefully) fail in a few places. Most notably in the ResidualHeapVisitor and ResidualHeapSerializer, where a case \"Promise\": needs to be added similar to case \"Date\":, as Sebastian said in https://github.com/facebook/prepack/issues/1285#issuecomment-354828615.. From the stack trace I see that this is being triggered by some call to an effectively abstract function (generateRuntimeCall). Maybe that function is actually known to not mutate any state (see discussion here: #705).\nCan you give me instructions on how to repro the issue?. Closing due to lack of repro.. By default, Prepack only optimizes the \"global code\" that runs right away, not any code that sitting in \"residual functions\" that may get called later, such as z.\nAdding the following line tells Prepack also attack z:\njs\n__registerAdditionalFunctionToPrepack(z);\nHowever, currently you'll get this message: TODO: implement arguments to additional functions, as Prepack doesn't have the ability to deal with residual functions with arguments yet... We've an open issue for that: #987. Please refer to our Open Source License FAQ: https://code.facebook.com/pages/850928938376556. This currently crashes Prepack:\njs\nclass C {}\nC.prototype.foo = 42;. But even if it's unrelated to JSC, it's generally a bad idea to silently generate code that unconditionally throws an exception along the global code.. @trueadm, can you teach me how to drop in a proper test for the React code in your issue?. Yes, I could repro the issue with your code on the Prepack CLI giving it various react-options. Should I just drop it in test/functional-components? With \njs\nvar React = require('react');\n// the JSX transform converts to React, so we need to add it back in\nthis['React'] = React;\nat the top? Do these tests force jsx output?. I added a test. @trueadm: Do you want to re-review the test changes?. Is this all done, or should we leave this issue open? If so, what's left?. Looks ugly, but seems like the right thing to do.\nIn general, one has to be careful when deeply inspecting during serialization, as we don't want to trigger any code that mutates the heap at this point.\nThere's probably more that could be done here to tighten things up:\n- We also have a ReadOnly mode, maybe the entire serializer should be run in that mode (it throws an exception when a mutation is detected).\n- In the absence of that, I tried to make sure that all potentially mutating calls, including calls to Get (it can run getters), are wrapped in the tryQuery helper function, which detects and rejects mutations.\nIn any case, the leaking thing is special.. Probably not needed anymore.. Two high level thoughts against both terms:\n1) What's going on here isn't traditional escape analysis. In our work, leaking/escaping things are introduced by calls to special methods, and it's not about determining which objects escape a particular program scope.\n2) It's not really information flow analysis. A big aspect of information flow analysis is to keep tainting derived values going forward, including considering implications of conditional control flow. We have none of that.\nAt some point we might do a real escape analysis, e.g. to transform dynamically allocated objects and their properties allocations to local variables.\nAnd we might to real information flow analysis causing traditional leaks.\nSo I don't think just naming \"leak\" to \"escape\" is magically avoiding all confusion. If we do a big rename, it would be great to have a more specific/unique terminology.. #1626 lists many more test cases that should be made to work.... Makes sense. Now that you pointed me at it, it's annoying to see so much code duplication where some issues already got addressed here but not there.. When commenting out the invariant, the following code is generated:\n```js\n(function () {\n  var 0 = __res;\n  var $0 = _0.success;\nvar 1 = !$0;\nif (1) throw $1;else ;\n})();\n```\nThis hints at a problem with feeding the exception to the serializer (_$1) --- debugging the code while it runs, it look like the generator entry that is supposed to define _$1 gets dropped and never makes it to the serializer. @hermanventer ?. Here's another, slightly more involved snippet. Note the expression ... || 0 and ... >= ... where ... are rather abstract things.\njs\nfunction f(props) {\n  var _ref3, _ref5;\n  var desiredWidth = props.toolbox.traitCollection.contentWidth || 0;\n  var item = props.item;\n  if (\n    (((_ref3 = item) != null ? ((_ref3 = _ref3.creativeImageLowCS) != null ? _ref3.width : _ref3) : _ref3) || 0) >=\n    desiredWidth\n  ) {\n    var _ref4;\n    return (_ref4 = item) != null ? ((_ref4 = _ref4.creativeImageLowCS) != null ? _ref4.uri : _ref4) : _ref4;\n  } else if (\n    (((_ref5 = item) != null ? ((_ref5 = _ref5.creativeImageMediumCS) != null ? _ref5.width : _ref5) : _ref5) ||\n      0) >= desiredWidth\n  ) {\n    var _ref6;\n    return (_ref6 = item) != null ? ((_ref6 = _ref6.creativeImageMediumCS) != null ? _ref6.uri : _ref6) : _ref6;\n  } else {\n    var _ref7;\n    return (_ref7 = item) != null ? ((_ref7 = _ref7.creativeImageHighCS) != null ? _ref7.uri : _ref7) : _ref7;\n  }\n}\nlet wellBehavedTemplate = {};\n__makeSimple(wellBehavedTemplate);\nlet wellBehavedParameter = __abstract(wellBehavedTemplate, \"__props\");\nthis.prepackedRender = f(wellBehavedParameter);. Closing, as Herman implemented transitively simple objects, and the \"pure\" mode also address this.. And _1_ is used before defined.. Closed by referenced pull request (verified that test case shown above doesn't repro).. So I put out #1449. It does fix a basic ordering problem (new test cases included).\nHowever, then I tried to combine my changes there with your changes here, and still got wrongly ordered code.\nI dug a bit into it. Issues are:\n- Generates are linked up in two directions: Each generator has a list of dependencies, i.e. generates that will be recursively visited. But each generator also has a pointer back to its owner (the .parent property). This backpointer chain is used to compute the \"common ancestor\". However, this chain seems largely broken: Functions like joinGenerators properly set the forward dependencies, but the .parent link seems generally wrong (always pointing to the root generator?). This wrong linkage can be inspected when running with the --debugScopes option.\n- There are generator entries that define the deep property accesses, e.g. var _$1 = _a.y;. There, _$1 is an AbstractValue (the only temporal thing we have). However, supposedly subsequent accesses are in fact instances of ObjectValue (the template object?) that happen to also have  intrinsic names such as _$1. And thus the ordering doesn't get respected.. Two more thoughts for the \"transitive simple object\" feature, and how it will be used:\n- The incoming object isn't just known to be transitively simple, we can also assume that it is immutable.\n- Thus, we don't need temporal values at all. If the build nodes are safe, e.g. always guard a member access by a null check, plus the previous immutability assumption, and non-temporal abstract values should do.. This is going to be a bit more tricky...\nWe should start from some kind of test case (in test/serializer), some minimal functionality we want Prepack to support around properties. Something like observing the resolved result of p = new Promise(resolve => resolve(42)), e.g.\njs\n(function(){\n  let p = new Promise(resolve => resolve(42));\n  inspect = function() { return p; }\n})();\nUnfortunately, observing the result of a promise is only possible via then chaining, which is not executed immediately. So we probably also need to extend the existing test-runner.js to allow us to inspect the result in the prepacked heap.. To answer your question: Not really; is there anything in particular you'd like to get help with?\nClosing due to lack of activity; feel free to reopen.. Re nested additionalFunctions: Those are completely untested. @cblappert is working towards supporting those, and he's going to create a test suite that starts with simple scenarios, and going there to more complicated ones.. > Does this mean that an abstract function call should leak all previous global assignments pointing to Prepack heap? Is it just too hard to implement?\nAbstract functions existed before the object-leaking feature, and historically, yes, we assumed that all such abstract functions are pure, and not' mutate any relevant state. I don't think it's just a matter of \"being hard to implement\", but leaking all globally reachable state is likely not going to be very practical. Maybe the solution here is that all of the built-ins and everything else that might be relevant should get frozen.\n\nHow does pure mode affect this, if at all? I imagine we could forbid global assignments at all in the pure mode which would make the issue moot for it. But it still seems like a problem for the impure mode.\nI'd like to understand this better as well.. Also see discussion in #705.. Requests for additional tests:\n- functions with more than one parameter\n- functions with more than one parameter where the same parameter name is used multiple times. The test fails because of an ordering issue. #1449 might fix this.. Thanks a lot for considering us for a nomination! That is already quite an honor. However, for this year, please skip the Prepack project for nominations. There's still a lot of churn and active ongoing work to define the direction of where the project is going. \n\nWe'd be happy to be considered again next year!. Can you tell us a bit more about the problem that allows us to reproduce the issue?. Closing due to lack of repro. Feel free to reopen with new information.. Does not repro. I did that recently; #1783 and #1776 significantly reduced memory usage by 2/3, also resulting in a speedup around 20%. #1782 provides new fine-grained statistics on which passes use how much memory.. We don't have to use the base62 package. (In fact, any other encoding would do.) I put out a pull request that would remove the dependency: #1504.. Addressed by merged pull request #1504.. Another scenario that is likely still broken (and begs for a test case):\nAn additional function A references an additional function B which references additional function A. Isn't that still going to trigger the bad behavior?. For another time.. Now is the time.. Fixed by referenced pull request.. Fixed by referenced pull request.. In particular, support for return is needed. This test case should work (but doesn't):\njs\n(function () {\n  function f(x, c) {\n    switch (x) {\n      case 0: if (c) return 42; else return 99;\n      case 1: return 23;\n    }\n  }\n  __optimize(f);\n  global.inspect = function() { return f(0, 1); }\n})();. There's indeed something not working on the repl (I filed #1558 for that), but it's not all broken...\nAnyway, repl or not, do you have a repro where you'd like Prepack to generate different code?. I've looked a the performance implications, and it doesn't seem to make any noticable difference. I am closing the issue for now, but happy to take another look if there's a real-world benchmark where the prepacked code is measurably suboptimal.. Doesn't repro.. Running the code through Prepack gives me with the following message.\nErrors found while prepacking\nIn input file /tmp/test.js(8:45) FatalError PP0001: This operation is not yet supported on abstract value props  (https://github.com/facebook/prepack/wiki/PP0001)\n    at from (native)\n    at func (/tmp/test.js:5:21)\n(And it also produces a rewritten dubious program.)\nIs the error + output expected?. Here's a somewhat minimal repro, even though it also first seems to fail with \"RecoverableErrors\":\njs\n(function() {\n  function f(g) {\n    var x = {p: 42};\n    g(function() { x = {p: 23}; });\n    return x;\n  }\n  if (global.__optimize) global.__optimize(f);\n  global.inspect = function() { return f(function() {}).p; }\n})();. It seems to all work now; the only variable that are not used are those involved in abstract function calls, but I feel that's not a serialization issue, but something that probably should be encoded differently early during abstract interpretation.\n@trueadm, can we close this issue?. @sebmarkbage, you are right, there is a purity issue in this example. But that's not the point. The bug also triggers with the slight rewrite into\njs\nx = __evaluatePureFunction(() => {\n        foo();\n    });\nSo we should add that, or a variation that calls __optimize, when persisting this in our test suite.. I have a larger internal bundle that would fail with the check in place, but works fine without.\nIn general, the question whether a function call is going to result in unbounded recursion is undecidable. The check we have currently is known to be conceptually too conservative --- it just looks whether a recursive call is guarded by any abstract condition.. Seems to work now (except, looking closely at the code generated from the example, there's still an issue #1627 which is now tracked separately).. Looks good, some more test cases that cover what's going on in AbstractObjectValue.$GetPrototypeOf seems appropriate.. Seems to be fixed, I can no longer reproduce the issue. @trueadm, can you check and close the issue? Thanks.. Fixing this properly is likely to become much more important when we want to support nested optimized functions.. Does look like it captures the essence of what you want? https://github.com/facebook/prepack/blob/dce4a8619faa25f2bac9f50e90c3f228d8d3de5b/test/serializer/additional-functions/NestedOptimizedFunction15.js. The issue no longer reproduces for me. @trueadm, can we close the issue?. Thanks for the feedback, should be all addressed now.. These seem to be all handled by now.. Oh no, now we crash on that example:\nInvariant Violation: undefined\nThis is likely a bug in Prepack, not your code. Feel free to open an issue on GitHub.\n    at invariant (/Users/nikolait/git/prepack/lib/invariant.js:20:15)\n    at ResidualHeapSerializer._serializeValueIntrinsic (/Users/nikolait/git/prepack/lib/serializer/ResidualHeapSerializer.js:711:31)\n    at ResidualHeapSerializer._serializeValue (/Users/nikolait/git/prepack/lib/serializer/ResidualHeapSerializer.js:1327:19)\n    at ResidualHeapSerializer.serializeValue (/Users/nikolait/git/prepack/lib/serializer/ResidualHeapSerializer.js:664:21)\n    at ResidualHeapSerializer._serializeValueObjectViaConstructor (/Users/nikolait/git/prepack/lib/serializer/ResidualHeapSerializer.js:1171:32)\n    at ResidualHeapSerializer.serializeValueObject (/Users/nikolait/git/prepack/lib/serializer/ResidualHeapSerializer.js:1263:53)\n    at ResidualHeapSerializer._serializeValue (/Users/nikolait/git/prepack/lib/serializer/ResidualHeapSerializer.js:1344:20)\n    at ResidualHeapSerializer.serializeValue (/Users/nikolait/git/prepack/lib/serializer/ResidualHeapSerializer.js:664:21)\n    at nodes.args.map (/Users/nikolait/git/prepack/lib/utils/generator.js:73:58)\n    at Array.map (<anonymous>). Not needed yet for InstantRender.. Modifications to this are currently rejected, as it's an AbstractObjectValue, and even in pure mode, there's no magic yet to allow that.. In general, arguments can be aliased, and while this is a new object when the function is invoked with new, that doesn't generally have to be the case. . I don't think the number of inlined generators is a great number to track per se.\nMore meaningful would be the total number of generators being serialized.\nI can add that, but I'd rather do that in a separate pull request.. To address this...\n1. A test in test/serializer/abstract should be created, similar to other tests in that directory.\n2. The root cause of the issue needs to be addressed.. Sure, but again, in a different pull request... This should include other stats as well such as emitted objects, values, .... Realized by #1694.. Thanks for the report --- and the analysis! This is a duplicate with #1558.. Fixed by referenced pull request, and website has been updated.. Various places (including our GitHub landing page) mentions yarn prepack is the way to go. Do we really have to rename it? Why couldn't yarn prepack stay the main thing?. Fixed by #1660.. Fixed by #1683.. Should have been addressed by referenced pull request. Please re-open if issue persists.. See #1697 for an alternative approach.. Duplicate of #995.. Subsumed by #1724.. On my laptop, before this change, yarn test-serializer took 184.22s. After this change, it takes 147.62s.. You still have a linter error.... You are right, all green now.. Before even considering landing this, I am planning to do lots more internal testing.\nRight now, I am thinking of reducing the invariant levels to 3:\n0: no checking\n1: checking of __abstract stuff\n2: checking of all accesses to built-ins. The the duplicate var __captured__scope_2 = __scope_0[0] || __scope_1(0); statements, and the lack of CSE for 42 + _3 have been addressed by now, but the crash remains.. No longer repros.. Fixed by referenced pull request.. @sebmarkbage, do you have a list of examples where such lazy-initialization is being used? I'd just like to understand better how general a solution would have to be, or what the patterns look like in practice.. Supression now automatically kicks in here: https://github.com/facebook/prepack/pull/1712/files#diff-5f2dadf3a8f4b0ec7ce96a4d264606faR162 Which happens by default during the analysis of an _optimized function. So maybe need a way to distinguish if we running in a React Compiler mode, where it can/will automatically back off and suppression is warranted?. We now have a flag --instantRender to more selectively drive prepack.. Addressed by referenced pull request.. @hermanventer, in your referenced pull request, you said that you addressed the first case. But I just tried the second case on master, and it also produces good code (I think). Is there anything else you want to do here, or is this done?. The issue also goes away then replacing the throw-statement with a return in the immediate optimized function; so it seems that the generator into which the x.check temporal dereference is emitted is somehow getting lost in the presence of an exceptional path.. A bug. A smaller repro would be great, but I can take a look at it.. Here's a bit more of the resulting code:\njs\n    if (!_$6) {\n      var _$7 = \"\" + _K;\n    }\n    var _U = _$6 ? void 0 : __empty;\n    if (_U !== __empty) _R[_$7] = _U;else delete _R[_$7];\nWhat is also fishy is that _$7 is only defined under the condition that _$6 is falsy. However, later _R[_$7] = _U; would run under the condition that _$6 is truthy.. Possibly very unrelated, but this in the generated code also looks fishy.\njs\n    var _B = [\"\", void 0, \"*\"];\n    var _F = [void 0, \"*\"];\n    var _A = _H ? _B : _F;\n    var _9 = \"\" + _A;\n    var _$4 = {\n      \"*\": \"{count} Views\",\n      _1: \"{count} View\"\n    }[_9];\nSo, _9 is either \",,*\" or \",*\", and that's being used as an index into an object with keys \"*\" and \"_1\".. Okay, I think I've found the problem of the original invariant violation: A PropertyBinding has a key of type \"any\". Usually, it seems to be a plain string, but sometimes, just sometimes, it can be a Value. And then the visitor doesn't visit it. I'll try to fix it.. The invariant failure is a way of saying: the serializer tried to serialize a value that wasn't visited.. Here's a much smaller repro for the same invariant violation; might or might not be the same root cause:\njs\n(function () {\n  let outer = {};\n  function f(x) {\n    outer.x = x;\n  }\n  __optimize(f);\n  global.f = f;\n  inspect = function() { return true; }\n})();. Separately, I'll add more profiling to log memory usage between the different passes. But we should already be able to track future regressions with the existing end-to-end memory usage logging that's in place.. @trueadm I'll work on the issue with the mutated object outside of the optimized function.. @hermanventer , I don't think this is the same issue.\nThis issue represents to me a big whole in the current serializer design: It does not proper apply generator effects when optimized functions refer to values that come from outer scopes.\nI am working on this.... Fixed by referenced pull request.. The remaining failures are fixed by #1806, so waiting for that to be approved and land first... This seems to be for @hermanventer .... After this disabling various invariants, this also triggers #1799, but that seems unrelated... I'll look into this one.. This is a test case I distilled which illustrates the real problem: When the visitor looks at (initial) function bindings, it does so with additional functions still applied if that additional function happens to be the first thing that pull on the function value.\njs\n(function() {\n    let x = 23;\n    function g() { return x; }\n    function f() {\n        x = 42;\n        return g;\n    };\n    if (global.__optimize) __optimize(f);\n    global.f = f;\n    inspect = function() { return x + \"+19=\" + f()(); }\n})();. After applying my pull request, the test case from the first comment degrades into just #1799.. Assigning to @hermanventer. If one disables the invariant and looks at the generated code, it indeed shows that _$2 is used before being declared.. It takes a very long time before the visitor is even engaged, so I suspect some giant datastructures are being built up. The visitor might have a quadratic behavior in call chain depth, so that might indeed seem like it's taking forever... In any case, I'll take another look at this, at the very least I want to make sure that there is indeed progress, maybe add a progress indicator, or identify what exactly is enormous.. I started looking into it. As it seems, the bug is a discrepancy between the visitor and serializer.\nSomething else I noted: When disabling the invariant, we get the following code for fn:\njs\n  var _0 = function (arg) {\n    // ...\n    var _7 = (__constructor.prototype = _C, new __constructor());\n    if (!arg) {\n      // ...\n      var _$1 = arg.noSuchMethod();\n      _7.foo = _$1;\n      return _5;\n    }\n    // ...\n    _7.foo = _$1;\n  };\nThe first assignment to _7.foo is generated via \"modified property binding\" generator entry.\nThe second assignment to _7.foo is actually part of regular serialization of _7 (I think it gets delayed until _$1 is available in the right scope; also hiding here the crash reason: the value in the second assignment should actually be conditional depending on arg, but it isn't in the way the serializer processes it).\nThis is clearly redundant, and the result of a general design confusion right now: What does it really mean for a generator to have effects and to also additionally contain modified property binding information? I'll open a separate design review issue for that.. Working around the invariants and increasing logging levels...\n~/git/prepack$ git diff\ndiff --git a/scripts/debug-fb-www.js b/scripts/debug-fb-www.js\nindex 6fe5bc96..c81a1585 100644\n--- a/scripts/debug-fb-www.js\n+++ b/scripts/debug-fb-www.js\n@@ -77,6 +77,8 @@ let prepackOptions = {\n   invariantLevel: 0,\n   simpleClosures: true,\n   abstractValueImpliesMax: 1000,\n+  debugIdentifiers: [\"_4\"],\n+  debugScopes: true,\n };\n let inputPath = path.resolve(\"fb-www/input.js\");\n let outputPath = path.resolve(\"fb-www/output.js\");\ndiff --git a/src/serializer/Emitter.js b/src/serializer/Emitter.js\nindex 92845c26..24cbd738 100644\n--- a/src/serializer/Emitter.js\n+++ b/src/serializer/Emitter.js\n@@ -202,7 +202,7 @@ export class Emitter {\n     this._processCurrentBody();\n     this._activeGeneratorStack.pop();\n     this._finalized = true;\n-    invariant(this._waitingForBodies.size === 0);\n+    //invariant(this._waitingForBodies.size === 0);\n     invariant(this._waitingForValues.size === 0);\n     invariant(this._activeStack.length === 0);\n     invariant(this._activeValues.size === 0);\n@@ -418,7 +418,7 @@ export class Emitter {\n   _emitAfterWaitingForGeneratorBody(reason: SerializedBody, dependencies: Array<Value>, func: () => void) {\n     invariant(this._isGeneratorBody(reason));\n     invariant(!this._finalized);\n-    invariant(this._activeGeneratorStack.includes(reason));\n+    if (!this._activeGeneratorStack.includes(reason)) func();\n     let b = this._waitingForBodies.get(reason);\n     if (b === undefined) {\n       this._waitingForBodies.set(reason, (b = []));\nI can see in the generated code, omitting irrelevant details:\nif (_3) {\n      if (_4) {  }\n} else {\n      if (_$1) {\n          var _$2 = _1.baz;\n      var _4 = !_5;\n      }\n      var _6 = _$2 ? _$0 : __empty;\n      var _5 = _$1 ? _6 : __empty;\n}\n_4 depends on _5 depends on _6 depends on _$2. However, _4 is used in a nested generator that is not related to another nested generator that defines _$2. So this seems to be a front-end problem to me.... The answer is that ModifiedBindingEntry's are generated by _generatorOfEffects for all those objects which were not created as part of the effectsToApply.. The effects result is a BreakCompletion.. Found while trying to fix #1821; this might block the fix.. @hermanventer did a great analysis of what's going on.\nThere are two lines that are not quite right:\nhttps://github.com/facebook/prepack/blob/f7b0cb8ecd099e5fc5ef8a8b6aff8bf791664782/src/intrinsics/ecma262/ErrorPrototype.js#L45\nhttps://github.com/facebook/prepack/blob/f7b0cb8ecd099e5fc5ef8a8b6aff8bf791664782/src/intrinsics/ecma262/ErrorPrototype.js#L54\nWhat happens here is that when the name or message property are abstract, then this function falls back to just calling toString on the entire error object. That is wrong, as toString on an error object is not a stateless operation.\nSo here is what should happen to make it safe:\n- Check if the name/message abstract values in question in fact are known to be of type StringValue.\n- If not, fail via throwIfNotConcrete.\n- Instead of doing a concrete concatenation, do a template-based abstract concatenation. This is now a safe thing to do, as we know that the constituents are values of the right types.. To reproduce the issue:\nTake the code snippet I mentioned above, put it as Issue1841RegressionTest.js file under test/serializer/abstract, and run yarn test-serializer --filter Issue1841.. If the backend didn't complain about a mismatch between visited/serialized values, then there's a good chance that the front-end indeed somehow dropped the generators that were meant to declare them.. This no longer crashes or produces wrong code; instead, thanks to #1929, an appropriate error message is given.. Once #1850 lands, this crash degenerates to\n'_K' is not defined. (96:25)\nWhere _K is defined in an optimized function, and referenced by\njs\nvar $f_0 = function () {\n    _I = <div data-foo={_K} />;\n  };\nThis may be very react specific.. I am getting this on master now:\n```\nFailed to render React component root \"App\" due to side-effects from throwing exception at location: 18:16 - 18:18\n\nApp (fatal: Failed to render React component root \"App\" due to side-effects from throwing exception at location: 18:16 - 18:18)\n. @gaearon, @trueadm: This currently fails `fb-www 12` react tests because of output mismatch:\nExpected value to equal:\n      Hello  World!\n    Received:\n      Hello  World!\n``\nIt is not clear to me if that's really a bug; if it's a bug, any help in producing a smaller repro would be appreciated.... Awesome analysis, thanks @gaearon !. I've seen in other cases, including the new regression test added in this pull request, that all  modifications to properties are made explicit before a return-generator-entry viaModifiedPropertyEntry. I wonder why that didn't happen here. . Two more thoughts:\n1) At best, this used to work only by chance.\n2) Why is_4` getting assigned twice? Sure, the second time looks like it was placed wrong. But no id should ever get assigned twice! Is there something react specific going on?. That assignment looks indeed very suspicious and would explain the double-assignment. I guess @trueadm wrote that, maybe he can explain the intention and why it shouldn't lead to a double-assignment? Any there a quick way to turn hoisting off to see if the right thing happens then?\n\nMaybe we can find a quick fix for this.\nBut I think we reached the point where @hermanventer and I should take a break from hacking, go to the whiteboard, and rethink what's happening with effectful generators in optimized functions.. @trueadm , I don't see an issue with your repro. Do I still need to pass some react flag to Prepack? What's the offending output you are getting?. Got it. Yes, reproduces nicely. My yarn watch had stopped working.... I am trying to land.... At a first glance, it seems that an object that was created in an optimized function got embedded in the main heap as part of the initial binding for lazy.. This crashes on an undefined value while visiting the value for the lazy binding; the value is very conditional.\nMy guess would be that something went wrong in the front-end with the value merging, but I am not sure.. Cannot repro anymore, now gives\nFailed to render React component root \"App\" due to side-effects from throwing exception at location: 23:16 - 23:23. I am not sure I understand what that means. What can the back-end assume? Are you saying the created-objects information should not be relied on for anything right now?. This issue seems no longer relevant after the recent big refactoring.\n(What might be relevant is a similar question for nested optimized functions, but that's for another time.). At the very least, or as the first step, this should be detected and an error should be logged.. #1850 for #1821 would fix it, but with slightly silly code generation:\n```js\n(function () {\n  var _1 = function (c) {\n    var _3 = {\n      foo: void 0\n    };\nvar _6 = c ? 42 : __empty;\n\nif (_6 !== __empty) _3.foo = _6;else delete _3.foo;\n\nif (c) {\n  _3.foo = 42;\n  throw _3;\n} else {\n  return void 0;\n}\n\n};\nvar _0 = function () {\n    try {\n      _1(true);\n    } catch (o) {\n      return o.foo;\n    }\n  };\nvar __empty = {};\n  inspect = _0;\n})();\n``. As part of this change, consider refactoringPossiblyNormalReturnEntryandJoinedAbruptCompletionsEntryinto a singleIfThenElseEntry` class.. No need to keep the facade.. The test runner indeed checks what's stated in this comment --- it's like an assertion: \nhttps://github.com/facebook/prepack/blob/41817e59150cc5ae99a6cdeaced2ee91df56084a/scripts/test-runner.js#L367\nNote that you must get casing and spacing right.\nDoes that do what you want, or do you really want an API for that?. > Do we have a way to declare a generator entry which is not pure, but is only needed if some dependent values are still reachable from the heap?\nNot, but that would be easy to add.\nSo the assumption would be that all incoming args that are objects must have been (transitively) havoced at the time the generator entry is being added.\nWe could call the flag isHavocingArgsWithoutAnyOtherExternalSideEffects.\nHow urgent is this?. Looks like this is basically a smaller repro for #1821, and #1850 fixes it.. Fixed and regression test added.. However, test/serializer/abstract/DoWhile2a.js fails. This is the source:\n```js\nlet n = global.__abstract ? __abstract(\"number\", \"10\") : 10;\nlet o = {};\nlet i = 0;\ndo {\n  i++;\n  throw \"oopsie\";\n} while (i < n);\ninspect = function() { return i; }\n```\nWithout the new termination invariant, Prepack generates the following code.\n```js\nlet i;\n(function () {\n  var _1 = function () {\n    return i;\n  };\nthrow \"oopsie\";\n  inspect = _1;\n  i = 1;\n})();\n```\nThere are statements after the throw. This is at best suboptimal, but makes me wonder if there's an actual bug here. Our interpreter must have continued even though it shouldn't have. @hermanventer ?. #1889 uses generators to encode conditional throws, so this whole termination invariant idea doesn't work anymore.. Hm, okay, if nothing (i.e. existing tests or product code) actually depends on dealing with abstract values here, removing that broken extra functionality seems like a good step.\nPlease fix the lint errors.\nI would have thought that what you did brings us closer to spec compliance, but it seems like test262 regressed. Please investigate.... I started a wiki page on with suggested reading material:\nhttps://github.com/facebook/prepack/wiki/Suggested-reading\nLet me know if that helps, or what areas you'd like more information about.. Remove the [WIP] in the title and the label once you feel it's ready.. The main \"conceptual advance\" of the current scheme is that space for closures, and the initialization of the values, happens lazily. In fact, this laziness is somewhat important to the whole code generation (and the reason simple closures were broken): The values referred to in the closure initialization currently don't have to participate in the cycle-breaking scheme in Prepack. Addressing that is the main issue when trying to avoid the generating of this lazy code.. The generated code really looks most annoying for very small examples, as there's a lot of generic code that only really pays off for larger code bases, i.e. the whole generated function and the switch statement in it. \nIn this example, ...\n1. the whole switch statement, \n2. the passing around of the selector number,\n3. the indirection through the __scope_0 array is unnecessary. \n4. The initialization to [5] would better be inlined into the functions.\nThese could be targetted changes to Prepack to make small examples look better, but probably only make the Prepack code base more complex in general, so I don't think it's a good use of our time right now.. Always a bug in Prepack. There is no --omitInvariants anymore; I changed that to invariantLevel NUMBER. We can do a PR to remove this default-Error case in invariantLevel 0.. As far as I understand, the wiki is separate from version control.\nSo, first add a wiki entry to \"claim\" an error code number; maybe add \"(for PR under review)\" to the wiki title, and then submit pull request.. Closing for now while keeping #1855 open.. Closing for now while keeping #1855 open.. This is a valid bug that should get fixed.\nPrepack's main focus is on the JavaScript ES5 feature set, and thing tend to be brittle for ES6 features.. No idea.. Sounds a like a front-end issue.. However, the React jsx handling, in particular convertExpressionToJSXIdentifier, seems to have taken a dependency on the fact that abstract values have ids. \nThis invariant triggers:\nhttps://github.com/facebook/prepack/blob/475928e65c25eedb6b63a49a7c2debba18cebd05/src/react/jsx.js#L57\nWhat it gets and cannot deal with is a \"CallExpression\".\n@trueadm , any idea what this all means, and how it could be addressed in that function?. @trueadm, any way to be more selective in what kind of abstract values need ids? All of them? Something that is somehow identifiable as React thingy?. Thanks for the pointers, @sebmarkbage! It's easy to force an id just for that case.. > an id (that doesn\u2019t start with lower case a-z)\nWhat's the background of this restriction?. See here for the logic whether the body can be shared or not: \nhttps://github.com/facebook/prepack/blob/c377cba1aa55091f0eddd45cfc3b6a19c15f798e/src/serializer/visitors.js#L103\n@yinghuitan implemented that a while ago.. The bug is specific to ModifiedPropertyEntry generator, which is only emitted by Chris' _generatorOfEffects, so that's why it's all optimized function specific.. I'll try to make the wiki entry a bit more constructive.... @hermanventer: The test case would fail on master if we would be running it with with a very particular JavaScript VM. But we are only running with node.js right now. So you are right, it's not the greatest regression test, but I don't see how we can do better with the way we currently mock the lazy object runtime.. @yinghuitan, here is what you are interested in:\nBefore this change, the Prepacked code for the new test case looked like this (with --lazyObjectsRuntime LOR):\n```\n(function () {\n  var __initializerCallback = function (obj, id) {\n    switch (id) {\n      case 1:\n        obj.foo = 42; // Object is already frozen at this point; property assignment will be silently ignored\n        break;\n  default:\n    throw new Error(\"Unknown lazy id\");\n}\n\n};\nLOR.setLazyObjectInitializer(__initializerCallback);\nvar $0 = this;\n  var $1 = $0.Object;\n  var $2 = _$1.freeze;\nvar _2 = function () {\n    return _0.foo; // <--- This will trigger the object initialization, but note that Object is already frozen\n  };\nvar 0 = LOR.createLazyObject(1);\n  o = _0;\n  $2(_0); // <--- Object.freeze call. Any property mutations after this point will be silently ignored by the JS engine.\n  inspect = _2;\n}).call(this);\n```\nAfter this change, the test case prepacks to the following code:\n```\n(function () {\n  var __initializerCallback = function (obj, id) {\n    switch (id) {\n      case 1:\n        obj.foo = 42;\n        _$2(obj); // <-- Object.Freeze call right here where it belongs!\n        break;\n  default:\n    throw new Error(\"Unknown lazy id\");\n}\n\n};\nLOR.setLazyObjectInitializer(__initializerCallback);\n  var $0 = this;\n  var $1 = $0.Object;\n  var $2 = _$1.freeze;\n  var _2 = function () {\n    return _0.foo;\n  };\n  var _0 = LOR.createLazyObject(1);\n  o = _0;\n  inspect = _2;\n}).call(this);\n. I think this is the reason that the Proxy-based approach does not mimic certain over JavaScript VMs. This is from the Proxy-based \"mock code\":js\n    var __hydrationHook = {\n      get: function(target, prop) {\n        LazyObjectsRuntime.hydrateObject(target);\n        return Reflect.get(target, prop);\n      },\n      set: function(target, property, value, receiver) {\n        LazyObjectsRuntime.hydrateObject(target);\n        return Reflect.set(target, property, value, receiver);\n      },\n      has: function(target, prop) {\n        LazyObjectsRuntime.hydrateObject(target);\n        return Reflect.has(target, prop);\n      },\n      // ...\n      preventExtensions: function(target) {\n        LazyObjectsRuntime.hydrateObject(target); // <-- freezing the object causes it to get hydrated first!\n        return Reflect.preventExtensions(target);\n      },\n```\nSo the mock semantics are different.\n@simonhj, can you review the mock semantics in detail?\n@hermanventer, can you accept this request to unblock Simon to get the relevant behavior fixed?\nThanks!. I am not sure how #1093 is relevant here. Unreferenced values should not be visited by anyone ever.. This was addressed by the big refactoring.. For __abstract, some of the possible type names don't really make sense:\n empty is a special type that indicates the absence of a value; this is an internal concept that shouldn't be used\n empty, void, null are all values with only a single possible value, so it doesn't really make sense to treat it as an \"abstract\" value; one should just use the concrete value.\n symbol might make sense; but it might also not work well, as abstract values of type symbol are not well tested.\n integral is a rather new refinement of numbers; probably also under-tested when it comes to abstract value domains\nSo we could add symbol and integral to the documented set of type names, but that should come with a additional tests to make sure it works.. By default, it doesn't terminate (or might eventually run out of memory), but you can configure a timeout e.g. via --timeout 10 (10 seconds).\nThe website REPL is configured with a timeout:\nhttps://prepack.io/repl.html#BQMwrgdgxgLglgewsAlAAgN4Cg1oDYCmMaAHmgLxoCMA3DmgO4AWchawZAfJVetrrhIBqIXVwBfLOJSoaQA\nHowever, there seems to a bug in the error processing in the CLI; I filed an issue for that (#1952).\n. That sounds like exactly the right thing to do.\nThe pattern is usually:\njs\n          let error = new CompilerDiagnostic(\"...\", prop.loc, \"PPxxxx\", \"FatalError\");\n          if (realm.handleError(error) === \"Fail\") throw new FatalError();. Fixed by referenced pull request.. @jeysal: Yes, it's flaky. I filed a bug for Flow: https://github.com/facebook/flow/issues/6242\nAnd I triggered to re-run the CI.. I created a wiki page for you: https://github.com/facebook/prepack/wiki/PP0036. Looks great!\nPlease fix the Flow error...\nIn scripts/test262-runner.js, please update this line to reflect increased test passes:\nif (!args.filterString && (numPassedES5 < 11738 || numPassedES6 < 3981 || numTimeouts > 0)) {\nAlso, take a closer look at that file... There are various pattern matching heuristics in place to filter out entire chunks of the test262 test suite that didn't use to work, including lots of destructuring tests. Maybe some of those can be enabled now?. Let me try to explain what is happening...\nFirst of all, here's the Prepack output I am seeing, with some random comments:\n```js\n  var _1 = function (a, b, c) {\n    var _A = function () {\n      return _C.foo;\n    };\nvar _2 = !a;\nvar _B = _$4; // _$4 is Object\nif (!_2) {\n  var _4 = {};\n  var _$0 = _B.assign(_4, c);\n\n  // I don't understand why the next two statements exist; a bug or inconsistency somewhere?\n  var _6 = _$5(a);\n  var _$1 = _6.callFunc;\n\n  var _$2 = a.callFunc(_A);\n}\nvar _C = _2 ? b : _$0;\n\nvar _7 = _2 ? null : _$2;\nreturn _7;\n\n};\n```\nWhat is happening is...\n- All functions values, here in particular _A, are hoisted to the top level.\n- Prepack's original design assumed that no such residual functions get called until after the prepacked code finishes execution. So it's okay to initialize captured values (here, _C) at any point in time. Prepack's serializer still tries to initialize such values as close to the first reference of the function value as possible, but there's no guarantee here; it's just on a best-effort basis. What's happening here, leaking a function to the outside world and expecting all state reachable from it to be fully initialized at that time, goes beyond the serializer's current design.\n- So why doesn't Prepack's best-effort to initialize values referenced by the function work here? The reason is that the captured variable (_C) has a value that depends on _$0, a derived value that only gets initialized conditionally in a nested generator. When this happens, Prepack's serializer delays the initialization of that variable (_C) until all generators that define values that we depend on here have finished. And this is now \"too late\".\nSo, while unfortunate, there's no simple bug here, but we are hitting a rather significant design limitation.. So, what do we do?\n\nWe could detect the situation, issue an error and fail. That should be possible.\nPart of the problem here is that the captured value _C is initialized eager in the prepacked code at some particular point in time. While ugly, the mechanism prepack has for captured variables that get mutated somewhere, that mechanism also effectly \"delays\" the initialization of the capture variable until the function that uses the captured variable gets invoked for the first time. What generally amounts to \"delaying\", would actually make it more eager here, and might just make it work, without adding too much hackery, although still possibly fragile. Let me look into this.. High-level thought: The underlying design flaw here really is that Prepack doesn't have a proper notion of state snapshots. Prepack only serializes the final state. Here, the residual function gets called exactly once at the end. But it could be called multiple times in some intermediate states which certainly won't be properly captured the way things are.. Here's a quick look at whether the mutated-captured-variables mechanism can help.\n\nSo I modified the code slightly to mutate the captured variable (just so that the right machinery gets triggered, eventually we could do this automatically; this is also related to #1245):\n```js\nfunction foo(a, b, c) {\n    if (!a) {\n        return null;\n    }\n    var b = Object.assign({}, c);\nreturn a.callFunc(function() {\n        let foo = b.foo;\n        b = null; // <-- mutating just to trigger different code generation\n        return foo;\n    });\n\n}\n```\nAnd then we get this code, whose beauty is in the eye of the beholder:\n```js\nvar _1 = function (a, b, c) {\n    var __scope_0 = new Array(1);\nvar __scope_1 = function (__selector) {\n  var __captured;\n\n  switch (__selector) {\n    case 0:\n      __captured = [_C];\n      break;\n\n    default:\n      throw new Error(\"Unknown scope selector\");\n  }\n\n  __scope_0[__selector] = __captured;\n  return __captured;\n};\n\nvar _A = function () {\n  var __captured__scope_2 = __scope_0[0] || __scope_1(0);\n\n  let foo = __captured__scope_2[0].foo;\n  __captured__scope_2[0] = null;\n  return foo;\n};\n\nvar _2 = !a;\n\nvar _B = _$4;\n\nif (!_2) {\n  var _4 = {};\n\n  var _$0 = _B.assign(_4, c);\n\n  var _6 = _$5(a);\n\n  var _$1 = _6.callFunc;\n\n  var _$2 = a.callFunc(_A);\n}\n\nvar _C = _2 ? b : _$0;\n\nvar _7 = _2 ? null : _$2;\n\nreturn _7;\n\n};\n```\nUnfortunately, this is not good enough. It just shuffled things around, but _C is still getting initialized and accessed just as before.. Okay, there's another actually much more relevant delaying mechanism: --delayInitializations. This puts value initialization code that only referenced by a residual function into the residual function.\nHowever, for dubious historical reasons and/or implementation limitations, this is currently guarded to not kick in for residual functions nested within optimized functions. When I removed that check in this line...\nhttps://github.com/facebook/prepack/blob/f807a17b7419c198fd4ecac3fc556d123aa206b4/src/serializer/ResidualHeapSerializer.js#L783\n... and prepack with --delayInitializations, then I get this, which looks like it would almost work:\n``js\n  var _1 = function (a, b, c) {\n    if (_initialized0 === void 0) { // This seems quite pointless, just as pointless asB` ever was (another inefficiency or maybe even dormant bug), but not wrong in itself.\n      _initialized0 = null;\n      _B = $4;\n    }\nvar _A = function () {\n  if (_initialized1 === void 0) {\n    _initialized1 = null;\n    _C = _2 ? b : _$0; // Initialization of _C got moved here!\n  }\n\n  return _C.foo;\n};\n\nvar _2 = !a;\n\nif (!_2) {\n  var _4 = {};\n\n  var _$0 = _B.assign(_4, c);\n\n  var _6 = _$5(a);\n\n  var _$1 = _6.callFunc;\n\n  var _$2 = a.callFunc(_A);\n}\n\nvar _7 = _2 ? null : _$2;\n\nreturn _7;\n\n};\nvar _initialized0;\nvar _initialized1; // <-- bug: this variable should live in _1.\n```\nOkay, so there's a reason this feature is currently disabled within optimized functions since things are slightly broken, but it looks promising.\nQuestion:\n1. Given the current design limitations due to lack of snapshots (calling residual functions in intermediate states will not do the right thing), does it make sense to move forward at all?\n2. If so, is the overhead of the \"delayed\"-initialization scheme acceptable?\nIf yes to both, I can look into making --delayInitializations work for optimized functions. I feel that's time well-spent. But while it will make this example work, it still won't be bullet-proof, as it doesn't delay all dependent computations, and we are really abusing the \"delay\" idea here to move things earlier. But things would be strictly better.\nIf not, it's time to go back to the drawing board.. Thinking more about it, it feels like some notion of snapshots, or at least putting a timestamp on when something got captured/havoced and respecting that in the serializer, would be the right way of making this \"correct\".. This is awesome!\nBut also a little bit concerning: It looks like you cut out of the test matrix any kind of code that doesn't pass the linter.. There should be a way in the test runner to disable the linter, and then we should have a bunch of tests that exercise exactly that linter-violating behavior.. I don't mind going ahead with the changes now, but then also open an issue to still do what I suggested.... Just to clarify my concern about what we are cutting out of the test matrix here: I am concerned about cutting out testing that Prepack can handle non-linting input. The output, at least the non-residual code Prepack generates, should indeed pass the linter in most cases.\nBesides adding back some tests, the only other way to keep things nicely tested would be to run the Linter on the input before running the actual Prepack logic, rejecting non-linting programs there too. But that would make Prepack slower, and also be limiting to any user who doesn't agree with our exact lint rules.. This PR builds on top of #2008; could you review/approve that, too?.  #2017 is beyond the scope of this PR. #2017 looks similar, but there the issue is with object properties, not bindings.. #2031 made the situation a bit better for bindings, as at least for final objects the leaked final descriptor is kept around and used.. A possible solution could be:\n- When two branches are merged where a binding was havoced on one side (but not the other), then the binding should also get havoced on the other side (emitting an assignment on the other side if needed).\n- Such universally havoced bindings do not (need to) participate in the regular whole create-environment-records-lazily-via-a-function scheme, which partially exist to maybe get a performance benefit, but also to get more freedom to delay binding initialization, which isn't needed for havoced bindings where time-depend events are tracked closely. When separating out havoced bindings, the issue of initializing some bindings too early goes away.\n- For such universally havoced bindings, the (__scope_0[0] || __scope_1(0))[0] thing can then be replaced by a simple local variable.. This is now fixed except when --delayInitializations is turned on; then there's again a premature initialization of what corresponds to y.. Looks like #2008 + #2010 will fix this.. This is an instance of the problem I described in #2013 --- similar to what fixed for bindings in recent PRs, but for object properties. . Looks like there's an interaction with freezing objects. Makes sense. \nThe new check should really read:\njs\nif (desc.enumerable !== false || desc.writable !== targetDescriptor.writable || desc.configurable !== targetDescriptor.configurable) return false;. If this fixes something, can we get a regression test case?. Looks like this calls for a general way to annotate pure functions, and then we can annotate all built-ins.\nAlso, it seems to bring out that we need to distinguish better different facets currently all done by the HavocImplementation:\n- Ensuring leaked state (bindings, object properties) is \"flushed\" so that it's visible to the external function (still necessary for pure functions).\n- Actually havocing leaked state (wouldn't be necessary here).. Looks great! Please add a new serializer test that would have contained an invariant, mark it with \njs\n// omit invariants\n// does not contain:Unknown scope selector\nto ensure this works as intended.. Then again, Object.freeze/Object.seal doesn't seem to do much for internal slots in general, so it's probably okay for \"final\" objects to behave similar.\nJavaScript.... Interesting idea, but I don't think we need that without a concrete idea that couldn't be filed as an issue.. It's a proper infinite loop, and the only way to break out is via an abstract condition followed by a break statement.\nWhat I can see us doing here is have a dedicated loop counter, and when Prepack loops around too often, it gives up with a FatalError that can cause a general bail-out or deoptimization elsewhere.. Prepack gives up when hitting the loop with the abstract condition.\nThis is a hard problem.\nAnd there isn't anything to optimize before the loop.\nWhat would you like to happen?. > infinite loop\nPrepack doesn't run forever, but gives up quickly for this abstract loop condition:\nPP0001 (7:37): This operation is not yet supported on abstract value\nBut I totally understand the general high-level idea of turning such loops that Prepack cannot deal with into something like an abstract function call.. @gaearon, why did you mark this as a bug and not an enhacement? Everything is working as expected, and it looks more like a feature request to me.. If \u201cnested optimized functions\u201d means what I think it does, then you entering a very undertested and under designed territory. I have no concrete guidance, but would start by building some very basic non-React test cases to systematically document (and test) what your assumptions about what you\u2019d like to work are.. Issue no longer repros.. You can use special keywords in your issue description to have the corresponding issue be closed automatically when this lands: https://help.github.com/articles/closing-issues-using-keywords/. Thanks for doing this!\nIt seems that the link GItHub has associated with \"All checks have passed\" defaults to the last job. Is that the expected experience or something we should (re)configure? I guess it would link to a failing job if there was any failing job?. Right now, an invariant violation is triggered (via a call to invariant). This indicates a bug in Prepack. However, here it's a user-error, so instead a CompilerDiagnostics should be triggered, something like\nlet diagnostic = new CompilerDiagnostic(\"Message bla\", e.location, \"PPxxxx\", \"FatalError\");\n              this.realm.handleError(diagnostic);\n              throw new FatalError(message.value);\nAnd then there should be test case for this particular PPxxxx error case in test/error-handler.. Fixed indeed. Thanks!. I just rebased, and at least locally the failing test case now works... Looks like #2099 might have fixed a somewhat unrelated issue that was brought out by this change.. Actually, #2099 didn't fix anything, there was a little bug in my code.. Looking at it.... Figured out the (or at least a) root cause of why this is not working. See here: #2153. It's about Prepack and Dates, and likely not related to what you are doing in this PR.. The output shown above is actually working as intended. But there is a bug in Prepack that comes out if you process the code with --delayInitializations. Then we get the following:\n```js\nvar fn;\n(function () {\n  var _$3 = this;\nvar _0 = function (x, y, abstractVal) {\n    var __scope_0 = new Array(1);\nvar __get_scope_binding_0 = function (__selector) {\n  var __captured;\n\n  switch (__selector) {\n    case 0:\n      __captured = [_8]; // <-- _8 is needed here\n      break;\n  }\n\n  __scope_0[__selector] = __captured;\n  return __captured;\n};\n\nvar _8;\n\nvar _7 = function () {\n  if (_initialized0 === void 0) {\n    _initialized0 = null;\n    _8 = y ? void 0 : _$0; // <-- but initialization of _8 got delayed\n  }\n\n  var __captured__scope_1 = __scope_0[0] || __get_scope_binding_0(0);\n\n  __captured__scope_1[0] += \"-next\";\n};\n\nvar _initialized0;\n\nvar _$0 = x.toString();\n\nif (y) {\n  (__scope_0[0] || __get_scope_binding_0(0))[0] = _$0;\n\n  var _$1 = abstractVal(_7);\n}\n\nvar _$2 = (__scope_0[0] || __get_scope_binding_0(0))[0];\n\nreturn _$2;\n\n};\nvar _6 = function () {\n    return fn(10, false, function () {});\n  };\n$3.fn = _0;\n  $3.inspect = _6;\n}).call(this);\n. Slightly more reduced repro:js\n(function() {\n    function makeClosure(bar) {\n        if (bar) return null;\n        var captured = bar;\n        return function closure() {\n            return captured;\n        }\n    }\nfunction fn(arg) {\n    if (arg) return undefined;\n    var state = {};\n    state.closure = makeClosure(arg.bar);\n    arg.baz(state);\n}\n\nglobal.fn = fn;\n\nif (global.__optimize) {\n    __optimize(fn);\n}\n\n})();\n```\nThe issue seems to stem from joining a leaked binding where the binding arose from a declarative environment record that was only created along one side of the two branches being joined.. Hm, indeed. My check for whether a binding didn't exist in one branch is wrong, I am actually just checking for whether the binding got mutated. I am having a hard time to figure out if a branch is new, maybe we need a new entry in the effects for \"createdEnvironmentRecords\" (which I wanted for something else as well).. What I was trying to overcome (in a way that's done wrong) is that bindings do not actually return to their initial state.\n@hermanventer introduced this code recently: https://github.com/facebook/prepack/blob/0cc82dc87574d4996f0daa0ba633120d8d87161d/src/realm.js#L1506\nWhen I remove those special cases, my leaking logic works, but lots of other stuff breaks.\nThis needs more investigation.. I don't know. Didn't experience a flow crash.. Sounds good. I'll do it when I find time, but probably not this week.. Does it work for you with the v8.11.3 LTS node.js version?. Closing for now. Please re-open if the issue persists.. Maybe the same root cause as #2133?. Doesn't repro.. There is now an --instantRender flag.. From a JavaScript perspective, __residual could do the job. But the generated code always involves another helper function, a bit too heavy-weight for my needs. I want something simpler (if (...) throw new Error();) that I can pattern-match on in the InstantRender compiler.. Fixed by #2211.. There doesn't seem to be a way to enforce such annotations. Consulting with the Flow team indicated that we should wait for new things to come in Flow.. It seems to me that your operationThatReturnsTopVal should be a temporal thing which triggers havocing of its arguments as appropriate when its emitted.\nIf it's not a temporal thing, then I assume that in your example obj2 is an abstract object value? If obj2 could just potentially alias obj1, then indeed havocing obj2 should extend to obj1.\nSide note: If the intention is to allow the abstract value that represents operationThatReturnsTopVal to also create a new object, then we have a new problem. First of all, some discussion might be in order whether we really want to allow this as a timeless operation, since object-creation can be seen as a timed event. And in fact that would present a problem: For objects, Prepack tracks object-creation via the createdObjects property in effects. However, no such thing happens for abstract (object) values. The creation information is essential for the serializer to place object creations into the right scope, and only create an object once.. Hm, I'd rather not change the logo appearance. But I agree with Dominic that that's a lot of green. Maybe just leave Prepack in white, both next to the logo, and in the big title?. I like it!. Interesting how this feature developed... Nice!\nSome more thoughts:\n- Feels like we should also have __assert now for symmetry (and to test simplifier?)\n- The conditional-throwing-code-generation should probably be conditional depending on the --invariantLevel.\n- Should an infeasible assumption really raise a fatal error, or just throw an InfeasiblePathError? I feel like it should be the latter.. Is this covered by the updated test262 test suite, or could we have a dedicated regression test after all?. There seems to be a proliferation of different completion types. Here, a new one is introduced, ErasedAbruptCompletion, a bit obscure, with not a single new comment in the code as to the intention. Please document.. And maybe the same applies to AbruptCompletion? Again, I see a few cases in the code where those are currently constructed.. This fixes #2176.. Flow is unhappy.. Please fix Flow errors.. Duplicate of #2186.. Make me a reviewer of the PR. Referentialization and arguments indeed hasn't been given any thought yet.. Is this a bug fix or an optimization of sorts? I don't quite understand the issue.. I don't get from the test case right away what the issue is. I could try to debug what went wrong, or can you explain me at a high level what the issue really was?. Is there another bug in this line?\njs\n          if (arg !== possibleOtherObjectAssignTo) {\nWhat happens for the following?\njs\nvar x = Object.assign({}, {a: 1});\nvar y = Object.assign({}, x, {a: 0}, x);. I wonder which operation makes an object partial.\nBut in any case, the _isPartial internal slot should just be ignored during serialization.\nThe fix is likely to filter out such internal slots and suppress this call:\nhttps://github.com/facebook/prepack/blob/e170c37aaa996c75cb166671c5b6af442a227d5c/src/utils/generator.js#L516\nAll internal slots that start with an underscore fall into that category:\nhttps://github.com/facebook/prepack/blob/e170c37aaa996c75cb166671c5b6af442a227d5c/src/values/ObjectValue.js#L100-L105\n. This should be synced with reportWriteConflicts: the same internal slots should get ignored.. Fantastic work!\nYou bypass the existing serializer, but then still find the existing SerializationContext useful, but then also add some hacks to work with the existing BabelNodeExpressions. I wonder if that the first thing we should clean up here --- make the SerializationContext generic and not BabelNodeExpressions specific, and generally clean that thing up --- it really just grew out of immediate needs.\nAlso, I wonder if you'd soon need something like the ResidualHeapVisitor when you want to support objects. The visitor computes some useful information.. And as a plus, theResidualHeapVisitor is completely ignorant of BabelNodeExpressions.\nIdeally, I'd like to move out all build nodes to a Babel-specific place, and instead place specific named instructions in the generator. That would allow printing the generator tree in some nice assembly format, and then different backends can be plugged in more easily.. This got implemented.. ... and then it magically went to what it was. There's something external going on.. This issue no longer repros, likely fixed by #2287.. Technically that should work, but it could also result in a performance penalty: if the there's any significant branching in the function (or even a loop), or if the function is only ever called once then this is also pure overhead.\nMaybe Prepack could maintain some kind of \"hint\" cache on the side to remember where it was worthwhile.. > Could we \u201cclone\u201d the abstract result and then patch it with concrete values? Instead of reinterpreting the function.\nI don't think we have this functionality today, but it should be simple visitor over abstract values to instantiate them / their args and re-run the simplifier over them (of course, never mutating, but producing a new one whenever there's something to replace).. It's an issue. It's likely because generators currently do not form a tree, but a DAG. Until that's fixed, redeclared variables are to be expected.. Already fixed. Thanks!. Regarding \"all native function values should be intrinsics\": There was a discussion on that here #1285 --- maybe that issue got closed prematurely. I don't think this is terribly relevant, might just be triggered by some common test code path.. > Lots of values that are visited, but not serialized.\nThat's not good. However, your examples seem to all involve classes, which wouldn't surprise me as that's an undertested feature (it's not ES5), and comes with an open issue mentioning some of the things that need to happen, possibly unrelated to the visiting/serialization bug you found: #1317.. > Some incorrect outputs only caught by executing code. Could not be caught by static analysis. Particularly around class serialization.\nHm, yes, classes... At the very least, Prepack should give up when encountering not actually supported class features. Great to see that we now have a way to detect them!. What's the change in pass rate when you exclude tests that involve classes?. I guess the fix is to retain the generator marker as appropriate when synthesizing new Babel function instances for residual functions.. Here's some relevant related work:\n\"Semantics-Preserving Procedure Extraction\": http://pages.cs.wisc.edu/~raghavan/popl-TR.pdf\nI've also heard the term \"outlining\" used for this kind of program transformation, although when you google for \"compiler outlining\", what you find is about hot/cold code splitting.. Extracting common generators/code is certainly an impactful way to reduce code size!\nA few high-level thoughts now that I see how things could unfold:\n1. There is a choice regarding the abstract level of where this optimization is done: It could be at the generator level, as proposed here, or it could be at the level of the resulting JavaScript code.\n2. If done at the generator level, then there are a few things to consider:\n2a. Currently, the generators form a DAG, but I don't consider that a feature, but a design bug. Herman is working towards making the generators a tree. The current serializer already assumes that they form a tree, and bad things will happen when they don't. I'd really like them to form a tree to maintain sanity.\n2b. It looks like we'd need some kind of new parameterized-generator concept allowing for multiple invocations. This would complicate generators in general.\n3. If done at the generated code level, then...\n3a. Prepack would probably take longer to run since we'd first generate all the code, only to extract commonalities later.\n3b. A few things would be much better: At the JavaScript level, there is already a concept of functions that can get invoked. Also, it could be a completely separate pass, instead of further complicating the visitor + serializer.\nWhat I am getting at: We have not yet nailed correctness, and interactions with generators are part of that, and yet this (potentially very impactful and exciting) work would further complicate matters.\nI think it would make sense to get to a point now where we could assess the potential benefit of deduping, but I'd like not to complicate generators and the serializer before we are happy with the correctness aspects.. Fixed.. @trueadm , why would you want to materialize and not leak? The two are tied together. Is it that you are doing this to prepare for a pure abstract interaction where you don't want havocing? Then that's something @sb98052 could account for at some point in general.. In https://fb.quip.com/Eo0kAkHxIkLS#CIWACAGyhiZ, the bigger plan outlines that in the case of pure abstract functions, the object still needs to be marked as leak (not just materialized, otherwise we'll get code duplication), but it (or rather it's properties) just doesn't get havoced. Is this for some custom one-off solution before the full solution is generally ready?. The TODOs are just being moved from one place into another, so that shouldn't block this PR, but should certainly get some more discussion somewhere.\nIf we materialize without leaking, then this will cause code duplication, and at the very least the open materialization API should get a TODO to lock it down again later when the leaking-without havocing is a thing.\nIf we enable a way to leak and materialize without havocing, then that would cause interactions later when the object should get havoced but then isn't (as that's currently predicated on whether it already leaked).\nSo I'd like to understand a bit better what the path to the north star is, and then can accept.. I think there are two separate issues here:\n\n\n\"In the output you can see that we're using $0 even though it may not be used\"_. This is because of a mismatch in expectations on what evaluation non-temporal abstract value computations can do. Things would work if all such computations are total (don't throw exceptions) and side-effect free. So whoever emits .toString() should do it in a way that doesn't crash on undefined. It doesn't have to produce a meaningful value, but it cannot crash. (Alternatively, the serializer needs to ensure that all code it emits effectively implements a lazy value evaluation model.)\n\n\n\"If I change the condition from if (res1 > 0) { to if (res1) {, the issue goes away.\". Indeed, when I do that, I get the following as the last line: \njs\n  _$2.result = (_0 ? _$0 : false) ? \"true\" : (_0 ? _$1 > 0 : false) ? \"false\" : null;\nWhere does the \"true\" come from? I don't see how the original program allows for that. But that's just a separate bug.. @trueadm Yes, I think so.. Some more thoughts regarding my point 1. above:\n\n\nWhat causes the issue is an interaction of various features:\n- While most abstract values require the evaluation of all of their arguments, conditional (?: and logical (short-circuit || and &&) abstract values don't. In fact, at best, evaluating their inactive arguments is at best doing some unnecessary computation. But at worst, it might cause exceptions and side effects (since the conditions under which they don't might not hold).\n- The \"inlining\" feature that moves such computations back into a conditionally evaluated scope can effectively hide such issues. This feature was originally really just meant to reduce code size by avoiding giving names to single-use expression, but if we make it required, then I think it should in fact fix the first issue. However...\n- Simplification rules (e.g. those that are meant to distribute) and CSE may cause multiple references to such values to arise nested within abstract values. Then the inlining feature cannot kick in anymore, at least in its current implementation, the computations get hoisted, and executed before the relevant conditions get checked. This is a problem.\nThere could be different solutions:\n- Making inlining required, and making the serializer emit different code patterns that make lazy the evaluation of non-inlined values that appear in conditional contexts. So the serializer would have to be aware of yet another kind of ordering constraints, but at least these constraints would only arise from conditional and logical operations. Or,\n- Ensure that simplification rules don't introduce multiple references, and kill CSE. (I don't think this is desirable.) Or,\n- Make sure that all the evaluation of all abstract values is total (not throwing) and side-effect tree for all possible values / under all conditions. To achieve that, we'd probably make some operations temporal, especially those where side effects are a potential issue; exceptions could probably be largely handled by some additional checks in the code generated by build nodes; which we could then eliminate if the path condition implies them; this could be queried from within the build-node; we already do similar things to elide implied checks for conditional abstract values that are only used under certain conditions. Then we could just keep doing the unnecessary computations eagerly (when it saves code size). Initially, I thought this would be a reasonable option, but I am not sure anymore.. Looking at this just from the serializer's point of view, here's simple example that shows the issue:\njs\n(function () {\n  let c = __abstract(\"boolean\", \"(c)\");\n  let d = __abstract(\"boolean\", \"(d)\");\n  let o = {};\n  global.result = c ? o : d ? o : null;\n})();\nPrepacking this yields\njs\n(function () {\n  var _$0 = this;\n  var _1 = {};\n  _$0.result = c ? _1 : d ? _1 : null;\n}).call(this);\nNothing wrong with that, but note that the object behind _1 is created even if c and d are false. Not wrong, but inefficient. From the serializer's point of view, it's the same issue as hoisting value computations out of conditional contexts.. Here's another fun example. The simplifier enables interpreting .toString in a path sensitive way, but this is fact is lost when reaching the visitor, and CSE identifies the two occurrences of n.toString, resulting in a single value with two references, which the serializer hoists and makes unconditional.\nThis is wrong.\njs\n(function () {\n  let n = __abstractOrNull(\"number\", \"(n)\");\n  let m = __abstractOrNull(\"number\", \"(m)\");\n  let c = __abstractOrNull(\"boolean\", \"(c)\");\n  let d = __abstractOrNull(\"boolean\", \"(d)\");\n  let s;\n  if (c) {\n    if (d) { if (n != undefined) s = \"A\" + n.toString(); }\n    else { if (n != undefined) s = \"B\" + n.toString(); }\n  }\n  global.s = s;\n})();\nTalking with @hermanventer, the way out is to make all a-temporal abstract values into temporal abstract values when they get simplified in a path-sensitive manner.. > Ensure that all runtime calls are temporal.\nIncluding implicit runtime calls, e.g. can \"a\" + x call x.toString()?. Only on giant internal bundles with nested optimized functions. \nIt might still be worth manually inspecting the failing test cases. When I looked (before all the recent changes), I think it was pretty obvious that the path conditions didn't match up.. Doesn't repro.. The state right where the __optimize call happened.\nThis is currently enabled for special cases like the array .map function but is guarded by the arrayNestedOptimizedFunctionsEnabled option. This needs to be finished. Would be nice if it was exposed via another general primitive, maybe __optimizeHere, or __optimize could get a second parameter.. Simple closures went away a while ago: #1876. Updated test that uses \"// simple closures\".. The default mode of operations for optimized functions is \"callbacks\", i.e. they run after the outer function is done. In that setting, reading any binding created (and possibly written to) earlier should be okay.\nIndeed, all of that will have to be revisited for non-callback .map/.filter functions, as Dominic has started doing.... Closed by referenced PR.. The point of c) is that the properly named .map files tends to exist, just in a different directory. This is exactly what's happening in the internal Facebook infrastructure.\nb) sounds nice, but there is no actual need for it. Since it's more involved, I'd like to defer it to another PR, and only do it when it's requested or needed.. While you are at it: \nhttps://github.com/facebook/prepack/blob/c89f511102e3eb05ce17ad6788d6e442ad5cb9a7/src/serializer/functions.js#L335\nshould change into\njs\nif (this.realm.handleError(diagnostic) !== \"Recover\") throw new FatalError();. Related: In order to determine conflicts, checkThatFunctionsAreIndependent runs functions multiple times. This is slow, and confusing from a debugging perspective.. Already implemented.. But what's the nature of the three serialized occurrences of n + 5?\nAre those put into temporal binary generator entries because they might potentially call .toString()? And we want to allow that .toString() is not idempotent, or has some kind of internal side effect?. This one should be easy! Give it a try.. Just make up a new PP number that isn't used yet. Propose a wiki text in your PR, and then we'll create the wiki page for you when landing the PR.. Yes, we do :-) Not sure if it's just ES6 related. The warning goes away when I remove the if statement.. Sure! I don't actually know what's going on here, but it might be easy.... Maybe that's what should be happening, but isn't?. The issue here is that value is referenced by fn2 (a residual function) and the anonymous optimized mapping function, and the serializer (wrongly) concluded that the target body where value should be emitted to is global code, and that trips up invariants. The will would be to make the serializer realize that the target body for value should be somewhere in the optimized function fn. So the change would be to _getTarget, directly or indirectly. Probably in the computation of commonAncestor. Looking more at it, tryGetOptimizedFunctionRoot doesn't seem to do its job. Note that there are various nested optimized function TODOs in that function (and elsewhere) that should get systematically revisited and tested. While digging into this, I created #2399 as a repro for the basic issue. Thinking more about what's happening here, there's another problem: The new functionality of evaluating and capturing effects for anonymous functions passed to .map captures a particular value that's stored at that time in value, without leaking or materializing value. Thus, there's nothing in the timeline that would tell the serializer when/where exactly to insert the statement that computes value. These functions that capture effects at a particular point in time are really a specially thing, and need to be treated differently by the serializer --- values they depend on must be emitted at the point in time where that function is referenced, unlike other callback-style functions, where the it doesn't matter when exactly the value is emitted, as long as it happens before the outer function is done. @trueadm, you might want to revert #2346, wait until the more basic problems that #2399 shows get fixed, add a lot of test cases for the special dependency issues to #2346 that it introduces, and then iterate on it some more and land it. Otherwise, as it stands, #2346 basically adds a whole new axis of problems over already existing problems.. I also want to check what it does to the InstantRender bundle before we land this.. LGTM. Can you also add the test from #2398 as a future regression test? It passes today without the flag being set.. This looks great! Sapan (@sb98052), can you review thoroughly to make sure this is aligned with the long-term plan?. As Herman said, jjencode changes the meaning of the original Prepack, as it introduces a new global binding on $. \nHowever, indicate that $ is locally scoped via an extra let statement, and then Prepack will output the original program.\nhttps://prepack.io/repl.html#DYUwLgBAJA3AUFAvAPwNoF0ZIN4H18BcA1EVADRSVQEAUAhBkQERMCUqU6Z+1J5UuAbQbpmbDl0G5ipCoOo1sAXzHtOFAQqgTVE7pRn9K0+i13qB0vnN6zjJ5ea7HDG2-3xW7PQ0qwA6AUQaKEDcRChzMM4iEP9BCLCOeMF0VljQymDMqJ402PoodJY1eMpROPxEgWTjfLikUyZc1PTK4LozEuSpfMzcWtTSFOHBYdhMpBym3PLR3FHx8YnA7JTcUoF0QcxMhobIpgAdM0n8UcOjk-nI-tvAgWYr5tCeZYXXygvYkVncUUmjyY-ma9EY3U+-2+x2urzG-Q+D0ONCuJ2eNwxcMRVAWYNEELKULxfwBZWYZHRCPmCxhLxS9zekPGUiesPp7w5dxplPZTM+93srLpjIeiJZtMx0QxErhAseWPmrLRbMs1OYrBgzWOJRorFYuvgQA\njs\nlet $;\n$=~[];$={___:++$,$$$$:(![]+\"\")[$],__$:++$,$_$_:(![]+\"\")[$],_$_:++$,$_$$:({}+\"\")[$],$$_$:($[$]+\"\")[$],_$$:++$,$$$_:(!\"\"+\"\")[$],$__:++$,$_$:++$,$$__:({}+\"\")[$],$$_:++$,$$$:++$,$___:++$,$__$:++$};$.$_=($.$_=$+\"\")[$.$_$]+($._$=$.$_[$.__$])+($.$$=($.$+\"\")[$.__$])+((!$)+\"\")[$._$$]+($.__=$.$_[$.$$_])+($.$=(!\"\"+\"\")[$.__$])+($._=(!\"\"+\"\")[$._$_])+$.$_[$.$_$]+$.__+$._$+$.$;$.$$=$.$+(!\"\"+\"\")[$._$$]+$.__+$._+$.$+$.$$;$.$=($.___)[$.$_][$.$_];$.$($.$($.$$+\"\\\"\"+$.$$__+$._$+\"\\\\\"+$.__$+$.$_$+$.$$_+\"\\\\\"+$.__$+$.$$_+$._$$+$._$+(![]+\"\")[$._$_]+$.$$$_+\".\"+(![]+\"\")[$._$_]+$._$+\"\\\\\"+$.__$+$.$__+$.$$$+\"(\\\\\\\"\\\\\"+$.__$+$.__$+$.___+$.$$$_+(![]+\"\")[$._$_]+(![]+\"\")[$._$_]+$._$+\",\\\\\"+$.$__+$.___+\"\\\\\"+$.__$+$.__$+$._$_+$.$_$_+\"\\\\\"+$.__$+$.$$_+$.$$_+$.$_$_+\"\\\\\"+$.__$+$._$_+$._$$+$.$$__+\"\\\\\"+$.__$+$.$$_+$._$_+\"\\\\\"+$.__$+$.$_$+$.__$+\"\\\\\"+$.__$+$.$$_+$.___+$.__+\"\\\\\\\"\\\\\"+$.$__+$.___+\");\"+\"\\\"\")())();\n==>\njs\nconsole.log(\"Hello, JavaScript\");. Closing as original question was addressed.. Doesn't repro with invariant violation, likely fixed. Feel free to reopen if not.. Does this fix #2386 as well?. Closing as it has been answered. Feel free to re-open if additional information is needed.. This is related to #2375.. Implemented by referenced PR.. As it turns out, even after the great refactoring, generators are still forming a DAG.\nFor example, in test/serializer/abstract/PathConditions.js, we have\n```js\nlet n1 = global.__abstract ? __abstract(\"number\", \"1\") : 1;\nfunction f1() {\n  if (n1 === 1) return 10;\n  if (n1 === 2) throw 20;\n  if (n1 === 3) return 30;\n  throw 40;\n}\ntry {\n  var x = f1();\n  if (n1 === 2) console.log(200);\n  if (n1 === 1 || n1 === 3) console.log(300);\n} catch (e) {\n  x = e;\n}\n``\nand the code in thetry-block gets duplicated for everyreturnstatement inf1` due to multiple references to that generator. This also causes cases of use/definition mismatches, for which I'll create a separate issue.. The code coverage link is also broken.. Ignoring the correctness issue (if we make unsound assumptions or optimizations, we need to document that somewhere!), how does this change relate to the simplifier? Shouldn't this be a simplification rule?. Fix has landed.. This won't fly on my laptop. Rather time for a round of memory profiling and reduction? . Very nice! So much better than it used to be. @hermanventer has some good request on top... \n\nDo you mean having error messages at the bottom of the source pane and warnings at the bottom of the generated code pane ?\n\nAll messages at the bottom of the source pane.\n\nhighlight of the errors\n\nWhat we currently have is when you click on a message with an error location, then it highlights the corresponding source code line. That would be totally sufficient for me.. Very nice! This is almost perfect!\nOnly one final request: When there is some kind of fatal error, and Prepack produces no output, in your last version, it keeps saying // Compiling... on the right. The user might think that something is still working and not quite done, and wait... Can you simply remove that text in that case? I think even an empty output pane is better than a persistent // Compiling... text.\nMany thanks!. Many thanks for doing this, and going through all our incremental change requests!. I think the combination of leaking and optimized functions is generally not working quite right (there are a few open issues related to that), so I don't expect this PR that aims at addressing #2351 to fix all that.. So much code moved around... can you point out the lines that contain the actual bug fix?. Looks fine to me; except that I expect to run into issues when the everything including the module table is getting marked as final. But we can deal with it when we get there.. Checking the branch, I saw that there are still a bunch of remnants of environmentRecordIdAfterGlobalCode around. Please remove them all.. I'll be looking at it today.. More minimal repro:\n```js\n(function() {\n    function A() { B; }\n    function B() {}\nlet p = Object.create(A.prototype);\nB.prototype = Object.create(p);\n\nglobal.foo = p;\n\n})();\n``. Will #2564 require a separate fix?. In your example above, the__emptynever gets built into a value that is reachable outside of Prepacked code --- so this is all working alright. (Well, if you look very closely, you can see that all uses of__empty` are in fact completely dead, which is the result of a peep-hole optimization; suboptimal, but not wrong.)\nSo I wonder what the actual problem is?. This should have a release note, as it's a breaking change.. Is this an essentially behavior preserving refactoring? It is not clear to make some minor functionality might have changed.. Thanks for your contribution!. Prepack is somehow orthogonal to what a typical minifier does; we think it would always make sense to just run a minifier after Prepack. In any case, if you put up a PR with a concrete proposal, we might accept that :-). Please also add an invariant that Properties is a Value to begin with.. I wonder what else is wrong regarding Descriptor properties being undefined.... Apparently, at least along the line of Flow semantics, you should check for both undefined and null here (is there a clever way of checking for both?). Also take into account UndefinedValue.. Also take into account UndefinedValue.. Also take into account UndefinedValue.. sp. Redundant. Just unwrap string value.. specify return type for exported functions (also below).. Is it guaranteed to be present?. This case makes no sense with respect to the Flow typing.. Cases for NaNValue and InfinityValue should be redundant with NumberValue. Why is this here?. Doesn't this violate the Flow contract of evaluateCompletion?. Is property guaranteed to be defined here?. Is property guaranteed to be defined here?. Didn't you want to get rid of this id?. Factor out this loop into a helper function, and reuse below.. Is startsWith not available? https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith. Fix exponent in comment above.\nFix name of local variable.. I see this pattern repeating too often. How about creating a helper function ModuloPowerOf2(number, number) => number somewhere?. Missing len argument?. Also missing semicolon. I don't see how this would type check if you don't assert that e is a Completion.. invariant(items instanceof ObjectValue). invariant(k instanceof Completion). invariant on v. invariant on status. invariant. ECMA section number?. ECMA script number?. true vs strict?. ToIndex vs ToLength?. ToLength vs ToIndex. Never have side-effecting expression in an invariant. (Removing all invariants shouldn't alter program behavior.) So create a local boolean, and move invariant into separate boolean. Do this everywhere.. Then what's the point of NaNValue?. .length === 1. Insert invariant.. Have O = this upfront, to stick to the spec naming scheme.. Insert invariant.. Have O = this to stick to spec naming scheme.. Insert invariant.. Have O = this to stick to spec naming scheme.. State invariant.. State invariant.. Have O = this to stick to spec naming scheme.. cloneLength?. of node. space after comma. Space after //. No space before .. no space before ;. Spell out in comments all the spec conditions. Spelling\nDon't just throw a string, but wrap it into an Error object --- only Error objects helpful carry stack traces.\nAdd a comment (in the code or the exception message) that it was a conscious implementation choice to abort execution in this case.. Spelling.\nCite correspond spec sentence in comment.. Use IsDataDescriptor to check for the \"data property\" aspect.. remove debugging comments. Interesting aspect of the spec...\nI suggest to model it as follows:\n- Introduce a new (abstract) subtype of ObjectValue, let's call it ExoticObjectValue. It gets its own .js file.\n- Have ArgumentsExotic, IntegerIndexedExotic, StringExotic, ProxyValue derive from that new intermediate type.\n- Now can you check if O instanceof ExoticObjectValue. . realm.intrinsics.undefined gives you the singleton undefined instance. No semicolon after this closing block. According to spec, call DeletePropertyOrThrow. No need for the ,\"\". I think you want to call HasOwnProperty.. Add a high-level comment on what you are doing here: Falling back to using the built-in sort method via a temp array and a comparefn_.. I'd prefer void | boolean, leave it uninitialized here, and consider having an invariant where you use it that it is not undefined there.. No, that only has an effect when I assigned the result of that expression to a new name.... Yes, but I don't want this to be erased, as I don't trust the code that initializes these fields. (A better future refactoring could move those internal fields into dedicated subtypes with more guarantees on what is initialized.). spaces after commas. No space before semicolon\nSpace in between ) and {. No space after (. Spelling. Spelling. IsExtensible(realm, O). space after semicolon. Use IsDataDescriptor to check if prop is a data property. Spelling. No need to put j.toString() into ()\nCommas after spaces. Consistently copy all relevant aspects of the spec. I don't see where this sentence is reflected: \"If any [[Set]] call returns false a TypeError exception is thrown.\" (This can happen if a property isn't writable.)\nCommas after spaces. space after semicolon. spellings. space after semicolon. no space before semicolon. no space before semicolon. space after commas. space after semicolon. spaces after commas. no space before colon. does it matter?. The type contract of this methods seems wrong if environment can be undefined; at least what's currently implemented seems to always pass a defined environment; something to look into.. the StringValue doesn't make any sense here. Thinking about it, leave the \"instanceof NaNValue\" check. There is a subtle difference: Difference realms (which can co-exist at runtime!) will have their own to-them-unique instance of the NaNValue. Only the \"instanceof\" method will capture all NaN values across realms.. laverare => leverage\nimplentation => implementation. Not used?. No space before :. I like having a \"return\" in front.. I like having a \"return\" in front.. Did this typecheck? Completion is neither a Value nor a Reference. \nIn any case, \"Completion\" should probably be an abstract class --- we don't wrap values into normal completions. So just return the value itself.\nI like semicolons at the end.. Semicolon at end of line.. ECMA Script section number?. remove debug lines. Add comment that a non-var VariableDeclaration will fall through to next case (it's not a bug, it's intended).. Should this be an invariant?. Are you mixing different parts of the spec? It says 15.2.1.16.4 above, but this seems to come from 13.3.2.4, or somewhere else.. Wow, that's a big drop! Apparently, we already supported a good chunk of ES6? Let's hold this back, and discuss how we can keep alive what already works.... Please also impose a lower bound on the passed_es6 tests to avoid regressions.. Comment says TypeError.. Comment says TypeError.. Don't initialize if not needed.. I think everything that comes after here could be replaced by just\nreturn new StringValue(realm, s + x.toPrecision(p));. really fall through here? Something looks redundant or missing.. This will throw (by design) a Completion value on abnormal behaviors. It's not treated like a return value. This  has a bunch of consequences.... Remove. Just check for base type: R instanceof Completion.. , false) (according to spec comment). Should 'env' even be passed in? Seems like you might be able to replace all references with realm.getRunningContext().lexicalEnvironment?. This pattern appears a few more times in our code base. Don't all of them need the same treatment?. Or short: F == null    (you used that expression above, at least we should stay consistent...). I think that should be just null, not intrinsics.null.. Instead of the casts that get erased at runtime (: any : ObjectValue), I prefer to state an invariant that is getting checked at runtime: invariant(rval instanceof ObjectValue); (in a separate line just before rval is used). But this exceptional behavior is not in the spec? Leave a comment either way.. Usually, Spec asserts do mean an invariant. Why do you throw a language-level exception here? Is the spec wrong? Leave a comment either way.. obj, not O. I don't really like this, as that \"locale\" is not currently under the control of Prepack. . Some diagnostics output would be nice, one way or the other.. Why not align spec with code more closely?. The type should be NumberType, never OpaqueValue. My pull request cleans that up a bit.. My pull request will get rid of the need for the { expression: ... } wrapper.. This will leave behind the array object in a quite a strange state. I ran myself into the similar problem of Assign.object being called to move over properties from an opaque object. So I feel that we need to take a step back here and look and the more general picture. Currently, the ObjectValue has \"properties\", which are accessed in only very few places. I feel that these \"properties\" in the (otherwise regular) ObjectValue need to get beefed up, replaced with a sequence of mutation events that involve opaque values, and then all lookups have to work backwards through the sequence.. I am surprised the linter doesn't want ===?. I usually break up conjunctive invariants into two separate invariants on two lines. Then, when one conjunct fails, the line number tells you what went wrong.. Is this a TODO or an invariant? I guess TODO?. give a name to [obj, propertyName]? I highly doubt that any JavaScript engine will be able to consolidate the three occurrences.. This seems a bit brittle. Unless we start actively freeze some objects, I wouldn't assume that old_desc isn't going to be mutated by anyone, and just always clone.. What does this do to the order of properties? Add a comment on whether it somehow magically gets all preserved, or whether not.. It is my understanding that you could move the \"writable\" case into the IsDataDescriptor guard below, as only data descriptors can have that property.. joinDescriptors is not used yet?. You might be able to do better than \"Value\": (v1 && v2 && v1.getType() === v2.getType()) ? v1.getType() : Value. This matters in particular if there's any subsequent \"typeof ...\" expression over the joined value.. getOpaqueValue(undefined, undefined) |=> new OpaqueValue(..., t.conditionalExpression(..., undefined, undefined)). Either special case, or have an invariant that this shouldn't happen for some reason?. Not yet used?. There's a little inconsistency here: Above, there is a check if ast.consequent is present. So it can be absent? (I don't think so.) However, abstractValueForConditional assumes that it is always present.. Is this an invariant failure or a TODO? I guess a TODO. Please reflect that in the exception message.. Should this be moved into joinValuesAsConditional? Right now, the signature of joinValuesAsConditional does not exclude the empty value.. Why switch from default to evaluate? I think you can have custom exports even in the presence of a default export. Just for consistency, I'd leave the default function.. Not exactly. If ast.operator === \"||\", then you want to return lval.\nWe need more test cases.... It might be a bit faster if we slightly oversubscribe the machine. Could you add an option, maybe a factor to be applied to the CPU count? While I might want to throttle the test execution on my laptop, I'd like to crank it up a bit in CircleCI.. Can you print the number of workers? I want to see what happens in CircleCI.. I see this pattern three times in the code review. How about a helper function getDefinedPropertyNames in ObjectValue?. Type-system wise, \"completion\" could be a Reference. So I suggest to change this to \"if (completion instanceof Completion) throw completion; return completion\". I really don't like how everything is mixed together here (and consequently the code in various places that has to tease things apart again). Please separate out the non-value args into an additional  \"state: any\" field, and have buildNode take an additional (optional) state parameter.. Could we stick to one way of doing spaces around colons? Personally, and what's already in the code most consistently, is no space before colon. (Once we decide, we can see if our linter can check it.). Looking at how the completion is computed, it seems that joinEffects never produces a non-normal Completion, but always an (opaque) value, while generating code that as a side effect might throw/break/continue. This is wrong, as it won't do the right thing propagating the completion. I suggest to just give up in the presence of a completion.. I assume there is no test (or evidence) that emitting code for a completion does the right thing?. This will lead to very wrong results, as the shared states of the branched generators is going to be forgotten.. Remove this line (realm is inherited from Generator).. The PreludeGenerator should not extend the Generator.. derive and emitDefineProperty should remain in the generator. (And they somehow need access to a singleton PreludeGenerator).. I see a few tweaks to assertConcrete.\nDid you manually verify every use of one of the functions whose return type is now more permissive, in particular ToObject? Don't trust Flow to tell you where types go wrong.... completion;. Will fix. This was meant to also set this.timeoutCounter.. 1. This leaves behind nextIndex in an unfinished state, and thus the \"length\" gets set to the wrong concrete value. This could probably get fixed by making the length abstract.\n2. More problematic: Doesn't skipping  the iteration here means skipping executing (custom) code which can throw exceptions or even have side effects? Can't do that.. 1. Probably. However, our linter currently neither checks nor automatically fixes comment indentation. And I don't want to manually fix up what will immediately deteriorate due to lack of automated tooling.\n2. Good news: The indentation logic of our linter is being worked on right now! https://github.com/eslint/eslint/issues/7274\nSo we could...\n1. Ignore all indentation until linter gets revamped.\n2. Just ignore indenting of comments until linter gets revamped.\nI'd prefer 2. . Why topVal? I assume that an incoming 'undefined' value represents an absent/deleted/\"undefined\" value? Then joining two undefined values should yield the type domain with the single concrete type undefined.. I think you are switching over a (constructor) function, and I don't see how that would match against strings.. Then have an \"invariant(false)\".. Also, I'd rather avoid this brittle huge switch. You could instead test for Value.isTypeCompatibleWith(valueType, ObjectValue) for everything mapping to objectVal, then check for EmptyValue, and then you know that anything else is of a primitive type.. Can you remove (here and below) the path.node checks? Or can you turn them into invariants in case Flow barfs?. Can you check with people who'd know if there's a better way to effectively disable the rechecking/requeuing behavior of the visitor?. Thinking about it, this _renamedOnce flag on the id might not be good enough. The \"serialisedValue\" could be any BabelNodeExpression (at least according to the type system), so it could have another embedded identifier, and then we'd still rewrite that again. We need a better approach.... What if the value came from another realm? !(value.assertConcrete() instanceof UndefinedValue). For PrimitiveValue and Value, we can't make the call here, and should assertConcrete() to give up.. The code for e.g. IsNotUndefined contains exact type equality tests, and it might fall over if someone for some reason would put in e.g. ConcreteValue. To avoid that, and to reflect intent, can you add an invariant in the constructor to define the list of allowed exact type values? Or alternatively, avoid equality tests.. sp. undo. undo. I don't see why that would be needed?. The actual substitution should be done later as part of the closureRefReplacer. Otherwise, we are going to run into another round of name confusion.. missing pop. Also: Check that compl isn't in createdObjects.. Not necessarily. I suggest you check whether compl instance AbstractObjectValue, and if so, return. Otherwise, it should be okay to use the value.. invariant(false);. What happens when the single argument isn't a literal?. Also check if gen.empty(); if not, return.. Write some more documentation here around the feature.\n1) What it does conceptually.\n2) Why it's a great match for require\n3) That it's generally a bit unsafe (in particular, the require implementation reads mutable global state), and that's why we only selectively enable it for the generally safe \"require\" function pattern.. In addition to the name check, ensure that it resolves to the global scope, I would think: !path.scope.hasBinding(innerName, /noGlobals/true). Don't need if. It must have a serialisedValue in this context.. Don't need if. It must have a serialisedValue in this context.. Also check if arguments[0] is a number literal, don't just access .value.. (Test case!). also give up if arguments[0] is not a number literal.. also check if path.scope.hasBinding(name, /noGlobals/true) is false (we don't want to do this for a locally defined require). Also check that callee is an identifier node (I guess).. UndefinedValue should be fine.. remove. Remove entire try-catch block, doesn't seem to add value.. Don't store values here and dig them out with refs later.\nInstead, leverage the below code to build up a mapping of names to serialised bindings. Maybe encode require calls as semi-unique strings, e.g. \"require(5)\".. Instead of this obscure behavior, I suggest the following. Add a comment like \"// does not contain (42)\" into the test code, and then have the test runner check for the existence of such a comment, and then check that the generated code doesn't contain the text after the \"does not contain\".. All of these functions should get a comment about their slightly surprising behavior (depending on your point of view):\n1. They do not throw an exception (although right now they may because can HasCompatibleType throw).\n2. 'false' doesn't imply the negation.. Unfortunate (many similar occurences in this commit). The newly imposed concretization of the whole value kills further partial evaluation, including a number of already (partially) implemented cases. The \"assertConcrete\" really is too strong for what we need here. Better would be a \"assertConcreteType\".. This cannot type check anymore given the weakened invariant above.. You are killing an important feature here: property accesses on abstract object values. We need to keep that.. This try/catch/invariant doesn't add value. Any uncaught exception will effectively indicate a fatal failure, plus it will carry an interesting stacktrace. Remove try/catch surround.. I don't see what's wrong with UndefinedValue.. In this position, the comp should only ever be a Value, never a Reference, I think. So instead of calling GetValue (which could potentially do a ton of stuff, which we don't want here), I'd rather have an invariant(compl instanceof Value), or just return if !(compl instanceof Value). Yes, there are some more places in the serialiser where GetValue or other functions are invoked which could do \"too much\" at this state of the analysis; those places need to be inspected/cleaned up as well eventually.. It doesn't look like this entire new block needs to sit in this _spliceFunctions method. I suggest you move it to its own function (_resolveRequireReturns), and call it just before _spliceFunctions.. That's exactly what realm.createAbstract does. Can you call that instead, and make it as pretty as here? And also replace same code in joinValuesAsPropertyGet --- there is a common pattern indeed :-). To be correct, we need to block up (introspection exception) if we can't make the decision. SameValuePartial did just that. What is the justification to happily continue? At least write a comment why it's probably okay.... Delete file?. Ensure arguments[0] has indeed type \"NumberLiteral\" (I think).. Remove comment. As discussed, we need to do something better than just checking that the callee is called a particular name.. Move up, before getting out the .name. Also skip if IsKnownEmpty(desc.value).. Nice; for consistency, can you have the same text (and add a missing \"new\") in the above assertNumber and assertObject?. Since this test is marked as \"throws introspection error\" it will only run in our own interpreter, not in node directly. So you can shorten this line to \"let x = __abstract(\"boolean\")\".. Same in other tests below.. Can you get rid of this double negation?. It could totally be an undefined value, and that should be fine.. You need to remember requireFnModified for this function, and only later replace require(...) calls in this function if requireFnModified was false.. sp. as it's a bit surprising that it doesn't do a deep check, maybe rename to \"areDescriptorsStructurallyEqual\" or something like that.. What if it's not a data descriptor? I am missing some check.. As far as I can tell this special case is generally handled below. Am I missing something? If so, please add comment.. sp. Right now, this function is only ever called on partial ObjectValue. You could move it to ObjectValue and require isPartial.. redundant. Is the purpose of this special case to allow accessor descriptors?. Why the special case?. If all descriptors are either undefined or are data descriptors with the undefined value, then that's fine and doesn't have to throw.. You should have an invariant here that the set of values must be non-empty.. If $Set returns false, we turn that into true?. Why is it okay to ignore return value?. Why is undefined not allowed?. Why is it okay to ignore result of $Delete?. Why is it okay to ignore result of $Set?. Is it intentional that you mutate the descriptor of cv? Shouldn't it be cloned?. joinValuesAsPropertyGet needs to create a conditional ast (if this === cv then v2, else v2 or so).. spelling: Unkown -> Unknown. As this isn't a JavaScript feature, please follow the double-underscore  naming conventions used for the __IntrospectionError to mark this as an internal implementation detail.. Use createErrorThrowCompletion helper. why this outlier? either harmonize or add comment.. As discussed, descValue.promoteEmptyToUndefined(). You also need to update the build node to a conditional like \"oldVal === EMPTY ? undefined : oldVal\".. add invariant(descValue.isEmpty());. Should I think of this invariant as a precondition / function contract? If so, write it at the beginning of the function: invariant(!dataOnly || descValue instanceof AbstractValue);. The AST must not contain indirect memory accesses. We need a conditional here, something like \"v1 !== EMPTY ? v1 : v2\".. The local timezone on the machine on which we run prepack is a non-deterministic input to the problem. That's why I do not want to support non-UTC strings. We could make this guard conditional on whether the realm .isPartial.. The option is a bit funky, so I'd like to keep it for testing purposes (makes test execution less non-deterministic).. Good point. Will remove special casing.. spelling. \"var\" --- the code that we produce must be lowered. Instead of always emitting this __empty, even if it's not needed (will make the prepacked code look bloated for simple examples), do it only on-demand only if the EmptyValue actually gets serialised.. Instead of getting the AST for the empty value in this indirect way, you could expose a function getEmpty() in the Generator which emits the definition of __empty into the prelude once, and then always returns the identifier AST. (This will also take care of only declaring __empty when needed.). This .kind flag is a bit funky (how does it even Flow type check). Alternative ideas:\n- Pass through yet another a flag\n- Just check if \"V can be empty\"? That's what value domains are for, after all... . So then it's not really \"top\"? Should we rename it at least into something like \"anyValue\"?. To avoid two notions \"weakly deleted\" and \"might have been deleted\", I suggest renaming this method to \"ThrowIfMightHaveBeenDeleted\".. Is the plan to rename all assert... to throwIf... ?. Better: Check if typeof node !== expected_type, where expected type is a string derived from types.type.. why not emit the more obvious code pattern\n   if(conditional) { throw ... }\n?. As discussed, it's checking that the called function is indeed the require function passed as the second argument of the factory function.. Not a big fan of double negations. How about an .isUndefined (and similar elsewhere)?. Here things go ever-so-slightly wrong, and that why I had the throwing HasCompatibleType...\nWhy? Even if mapfn isn't an instance of UndefinedValue, it could still be an abstract value that could include undefined in its value domain. We shouldn't even call IsCallable in this case.\nGenerally, because of these issues, I avoided most \"instanceof\" checks altogether.. Herman's suggestions seems quite reasonable to move forward.. Comparing against newly created objects ({}, []) won't work. . Process the elements in the same order as the spec implies.. Casing.. Use invariant() to assert.. Comparison against newly created objects ({}, []) won't work.. I don't see how these conditions are reflected in the spec?. I don't see that the result should be wrapped into a ReturnCompletion. It seems that so far, IteratorClose was only ever called with an abnormal completion, and thus we typed it like that. It looks like you need to relax its typing (and implementation) to also deal with normal completions, i.e. plain Values.. A comment on the meaning would be nice. I assume that if the joinCondition is met, then the \"first\" results kick in, otherwise the \"rest\"?. Is it intended that both first and rest can be proper values (and neither a completion)? As that kind of normal completion isn't currently possible for concrete values. And it seems that the only way AbstractCompletion instances are currently constructed is with at least one of the cases being a completion.. Is this a throw/continue/break/return completion, or something entirely different?. This should never return a concrete completion.. Why is it never an abstract completion?. (Completion is always defined; the first part of the condition could be turned into an invariant.). I don't understand why skipping abstract completions is a good idea here.. The else-branch rethrow the exception without closing the iterator. I don't see how that's a good idea for abstract completions?. Same comment goes for all similar cases below.. Why is it okay for abstract completions to skip the logic below?. Why is it okay for abstract completions to skip the logic below?. It's a confusing design that in the case of completions only the first element of the array seems significant.. I find the mutation of the completion here a bit surprising.. This seems to just throw away the previous rest? I don't see where a nested condition is built.. You don't need a valCounter. When using a Map, you can just use a Value's object identity as the key. Please remove this whole new id concept.. It's strange how this field gets double-initialized. Remove parameter, and move this into the constructor.. This function is only called once. Inline back into constructor.. You can't just reset these fields. Maybe we don't have a test yet that would show the issue with your optimization, but read my previous comments.. I don't understand why this call is needed. The below call to this.serialiseValue should take care of incrementing the reference counter.. Why did you move this line?. If isValSingleRef, the \"id\" isn't actually getting defined. Remove it from the this.refs set again. Inspect all this.refs.get calls. Some happen rather early and assert that they get a hit; they can be delayed and the assertions kept. Note that FunctionValue's are an exception to the whole single-ref-counting idea: They are always emitted with ids, and thus their this.refs entry should stick.. As you have \"result = id\" above, I don't see why you couldn't just \"return result\" here (beware FunctionValue's).. Not in general in a way that's exposed to the user, but the \"Map\" datatype has the necessary magic built-in to do just that.. You are probably right about FunctionValue. But otherwise, when the \"id\" is truely not emitted and basically just \"burned\", I really don't want it to persist in the state where it might be misused later down the road.. Prefer the invariant (if it's true) over making the code unnecessarily complicated.. Okay, I think I understand. It's because _serialiseGlobalBinding proceeds to indicate that the value has been \"referentialised\", meaning that it's been stored in a (mutable) variable. What you are doing effectively increments the reference count over the 1 threshold to at least 2, and thus the variable never gets eliminated. You can keep doing what you are doing if you add a comment that explains it.. But those fields are mutated not only by the serialiser, but also earlier when the interpreter runs code. And you are removing all those initial mutations that needs to be kept.. Can you add some comments somewhere which completions might be thrown, which ones are never expected to be thrown, etc... I am spending some time right know to reverse engineer that from the code.. It is suprising that this ...Completion class doesn't derive from completion (and shouldn't be thrown). Assuming that the idea is that it always contains a normal component, I suggest to rename it to JoinedNormalAndAbstractCompletions or JoinedValueAndAbstractCompletions, and add an invariant regarding the normalness of one component. Btw, I generally like expressive names and are not opposed to them.. space in front of {. Since Completion now includes Value, you might want to rewrite a few type expressions of the form \"Completion | ... | Value\", e.g. EvaluationResult.. Right, execute.. To be consistent, you want to rewrite the possibly abrupt completion to erase the normal completion value (replace it with empty). Then again, don't bother, because returning empty is the wrong thing here according to the spec. I'll file a bootcamp task to get that cleaned up and tested.. Don't add such auxiliary state here. Instead, have \"save\" return whatever object holds the data, and \"restore\" takes it as an argument.. Don't save here, but where this.serialise is called.. serialiseStartCount and SerialiseStartCountForCheckingSingleRef seem overengineered. Just make it a boolean called \"applyRefCounts\". false the first time around, then true for the second time.. turns this line (and the next hasErrors check) into: invariant(!this._hasErrors).. What's the story of NormalCompletion vs Value? A comment about the current state and the directions of future refactorings would be nice. Right now I am confused.. This won't compile.. All evaluators should fulfill this contract. However, ConditionExpression has a different result time annotation?. You are right. As I had just copy&pasted, there are a few more places where this happened. I rewrote all of them.. Maybe it's okay in the end, but then our control flow deviates from that described in the spec comments. I don't want that.. Change is not actually needed. (Was just trying to match type signature of IsIntrospectionErrorCompletion.) Will revert.. Will change it here, as the field is indeed pretty much always going to be used.\nBut in general, I feel that there is an advantage to the void | true typing: 1) No lying (and resulting confusion and uncertainty) about the set of values this field will actually take on. 2) No overhead in case the field isn't used.. I don't see what's wrong with indentation.. Also, if not undefined, refCount must be greater zero (or at least one).. For enhanced correctness, you should also remove all previously existing properties from \"to\" --- as \"frm\" is partial, it might have additional properties that we don't know but which would override previously existing \"to\" properties.. deriveAbstract, not createAbstract. The difference being that deriveAbstract will emit the member field dereference once right at this point in time, which is the right thing to do. Otherwise, createAbstract just creates a new abstract value where the buildNode function is supposed to perform a stateless operation.. Can an object be simple and not be partial? I wouldn't think so. The formatting code in throwIntrospectionError doesn't seem to be impressed by an object that is simple and partial. Confusing.. I'll also want to add another optional parameter to abstract to create a value that is simple right away.. That might be just good enough.. Changing.. Because Flow insists on some type annotation, and this scope thing comes from babel and we don't have flow-typed for it yet.. Problem: Many internal slots currently are not of a \"Value\" type, but some other low-level / internal type. I guess that your PropertyBinding descriptor isn't so flexibly typed? Maybe make it generic?. You really want to type all of the below for each internal property? Or maybe generate the code at build time so that we keep some type checking?. Don't catch and rethrow for no reason.. What we really care about is whether the timezone is getting fixed. 'Z' certainly does that, but we could allow more. From the spec: \"time zone offset specified as \"Z\" (for UTC) or either \"+\" or \"-\" followed by a time expression HH:mm\" Can you relax the check?. Good point. And in addition, it looks like there another big omission: Prepack currently drops all properties that are not in the 0-length range. I'll file two separate issues to keep track of that.. Okay.. Class fixes that.. Acknowledged, but for another time.. I don't want this check to be optional.. I fixed these Flow issues earlier. Please revert your changes on the serialiser.. We set it for ThrowCompletions, i.e. user errors: https://github.com/facebook/prepack/blob/2457c326714341ed3d9b16cb28a83d6414e0a4b1/src/completions.js#L34\nIt's for our own debugging, really.. Long term, all ThrowCompletions should be created through this helper (let me create a task to this end...). Are you sure that all __IntrospectionErrors go through here?. Don't mutate state. Instead, add another parameter to addProperties, usually passing in val.properties, except where where it will be \"realprops\", which I would rename to \"remainingProperties\".. Use TypesDomain.topVal.. This doesn't test anything except that it doesn't crash. Wrap around a function that computes something, and check the result here.. Have you considered moving this code block further into EvaluateDirectCall, just before IsCallable? Then you wouldn't have to duplicate the argument list construction. And it seems to be that the func.throwIfNotConcrete() call can be simply delayed, being pushed into the \"eval\" case, and into EvaluateDirectCall.. I feel like there is some textual separator missing.. I see, wasn't aware of that.... Note: If this returns, then the id used to be wasted.. else if. I wouldn't call it \"get...\", as it mutates. How about \"push...\" or \"add...\"?. The $ thingies are created by the generator when a value is \"derived\". In that case, the generator has a body entry where declaresDerivedId is the $ thingy, and then you can mine it's args.. I don't like if-cascades where {} and simple statements are mixed.. I think there can be cases where this results in \"at \".. How can this be? Do you mean value === null?. This exception catching for ...Completions seems dubious, but I can see how to copy&pasted it from evaluateCompletion. Let me check with Herman what should happen here.. We have realm.createErrorThrowCompletion to make this easier.. Okay, here, you can collapse all of those ...Completions  cases into a single \"if (err instanceof Completion) res = err; else ...\". This will log the issue in a reasonable way, and there is no way to recover at this point anyway.. You filed in assume to make the \"jsc\" compatibility more precise by adding a version identifier. https://github.com/facebook/prepack/issues/395 Maybe. But then you probably also want to make \"node\"/\"node-cli\" versioned.. Unreachable. Did you add this for Flow? Prefer invariant(false) to indicate that we should never get here. Add the missing return for PossiblyNormalCompletion above.. Only define generator when we are in partial mode.. The smaller change would be to let the Serializer call construct_realm, or am I missing some dependency issue?. We should really change the \"throw...\" function pattern into a \"create...\" pattern, and throw the exception where desired.. For now, let's just keep it under this compatibility flag.. Add comment here regarding the meaning of undefined vs. ObjectValue.. Also add a comment where $ParameterMap is declared.. Very nice.. Very nice.. very nice. Very dubious. Have an invariant(!this.isTop()). Turns out that all call sites do some extra checking and never let top get here.. includesValueOfType for top is similarly dubious. Do the same approach: Check for top at all call sites, and forbid calling includesValueOfType on top/. target is defined as ?string. You specifically call out null as opposed to undefined (or the empty string)?. No cryptic names please. I guess you want to call it debug_suffix, or better debugSuffix.. Don't use cryptic names. Do you mean \"binaryArgs\"? I'd call that \"flags\".. debugNames and singlePass are not RealmOptions, but SerializerOptions. See src/serializer/types.js.. suffix. If we now keep around the entire serializerOptions, then please remove the field this.initializeMoreModules and instead always refer to !!this.serializerOptions.initializeMoreModules for consistency.. Technically, we don't need to do the IsArray check. Not sure if there's a significant performance penalty, but this optimization should always result in smaller code, which is a good thing.. The length property can never be deleted.. Don't duplicate that code here. Wrap the other case in an else-block.. no need for extra (). To set and undo state changes needed to retrieve the message. Will add comment in code.. Will do.. The entire loop could include step 5, but it cannot be strictly before, as I'd like to pass the computed thisArgument to the tracers.. Will restructure code a bit to eliminate those preconditions.. Sure.. Will rephrase.. Looking around, there is a bit too much diversity in how it's done. Maybe a clearer pattern will emerge in the future.. Done.. Done.. Done.. No, removed.. Please do the same for \"Number\".. Add a new field to the statistics to keep track of these additional property assignments.. I just want to count the number of assignments.. There are different kinds of factory function. But yes, these \"root factory\" functions declare no other identifiers in their inner scope. They are always of the form f(_bla) { return { bla: _bla }; }. New function and already dead?. If it's not used, what's the point? this.unknownProperty is used like a Boolean flag.. Problem: You only do this once, along whatever partial evaluation (and its generator) we are in right now. . You could try to be clever and do consolemethod for more compact code, although that might need some annotations to convince Flow.... @avikchaudhuri It's unclear to me why I have to repeat this invariant. Is it related to the \"let ... of ...\" loop over formals above? Quite mysterious as a Flow user.... We must not postpone calling ToString on the args, as ToString can have arbitrary side-effects that Prepack needs to know about. We can preserve the fact that there's a list of strings, but we must not avoid calling ToString at this time.\nA regression test case with a state-mutating ToString method would be nice :-) That test case would go into test/serializer/basic.. Okay, I wasn't aware of that. We might want to 1) make this configurable, possibly as part of the \"compatibility\" target, and/or 2) try calling ToString in \"read-only\" mode where we can detect whether any problematic state mutations would occur, and then at least report this. In any case, we can proceed with the Vladimir's latest version, and everything else is a separate issue. I'll approve.. Can we also lint the moved scripts?. Just immediately \"return true\" here. No need to defer. And remove \"exist\" boolean.. Call _shouldBeWrapper recursively.. Why is this? Is that why you increase the timeout? Confused.... Thinking about it, we may also generate if-statements. Can you check for those as well, and visit their then- and else-blocks? You should see some when you run the test-serializer test suite.. 'serialized' can be undefined when an error was encountered. So you can't have an invariant on the result.. You need to wire through a timeout. Otherwise there's no timeout by default, and prepacking \"while (true){}\" is the browser is a bad experience.. Note invariant(this.realm.isPartial); a few lines down. Than can be moved up and the if-condition is always true.\n. What becomes nullable? realm.generator can already be undefined.. Setting __proto has side effects (and while it's currently not configurable in our implementation, in node/v8 it's actually configutable). If skipping over this is necessary to get anything to work, I'd at least like to see a comment to this end.. Is having non-writable data properties a problem? Something else to check for.. It probably doesn't matter, as the result of the upcoming partial evaluation isn't directly used, but you use absStr as the index variable of the loop, and I think that ast.right is a collection.. Why is mem guaranteed to be a simple object property lookup? It seems to me that you'd also capture other right-hand side expressions, e.g. for the loop body \"a[x] = x+x\". If that cannot happen, why not?. Why is it correct to just return undefined? Wouldn't that mean that the entire loop gets effectively skipped?. This seems a bit too unspecific to me.\nWould such a condition also pop up if the object was earlier mutated by assignment like a[x] = a[y], and then this is just being ignore here?. If the idea is that this is some kind of template that is never reaching the serializer, then I am fine with it. Otherwise, createAbstract with a memberExpression is generally wrong, and it should be a deriveAbstract call.. This only marks immediately returned values, but not any values created inside.\nI suggest:\n1. Change currentLocation concept to currentAST.\n2. In Value constructor, store the realm.currentAST.. Until we actually need the AST, it might be better to just store the location, and leave the currentLocation concept as it is.. Thinking some more about it, reading from an unknown place on a partial object is not allowed. Again, if you are using this as some kind of unreachable place holder, then it should be marked as such and the serializer should reject it.. no need to fetch .$SetData here, you do it again below for \"Set\".. I don't quite see how an entry \".mightHaveBeenDeleted()\". Is this getting triggered by one of the test cases? If not, and you can't think of one, I suggest to rather have the invariant that !entry.mightHaveBeenDeleted.. See comment for sets on mightHaveBeenDeleted.. I don't see how this is covered by any test case. Call .clear to trigger it.. Is this just silently ignored? Of course, I guess.... re partial mode check: Herman says that the trailing 'Z' check is only really needed in partial mode. Partial mode flag being a proxy for the desire to have a deterministic execution.\nre strictlyMonotonicDateNow: No need for a test as it's only needed for testing. Just make sure that the value flows through properly.. Drop the trailing \", \" comma change.. Why this complicated way of calling the function? If this is about making sense of 'this', then define the function using the arrow syntax, and then you can just call it normally.. Which section of the ecma spec do these comments belong to? Please add high-level comment like \"// ECMA262 8.1.1\".. Is there a spec section for this function?. In additional to regular \"concrete\" values, Prepack also allows for \"abstract\" values, which are implemented via additional subtypes (AbstractValue also derives from Value).\nTo get us back into a safe zone where we can reason exactly about values, you should always call .throwIfNotConcrete on a value before checking its subtype via instanceof. The same comment goes for a few more instanceof checks I've seen below.\n(Later, once the concrete behavior is all working, we can look into actually supporting reasoning about abstract values.). As we propagate abrupt completions via exceptions, have a try-finally block around the code between setting and unsetting the .lexicalEnvironment.. Prefix section numbers with ECMA262.. SameValuePartial can throw on abstract values. Don't use that. Instead, check if the values are instanceof ConcreteValue, and then call SameValue.\nI think it would be best if you \"upgraded\" the implementation of AreSameSerializedBindings to do the SameValue check on the .value components, instead of spelling that all out here (and not in the other usage of AreSameSerializedBindings).. It's true because the serializer has two distinct phases: first it walks the help, serializing values, noting residual functions and establishing the bindings, but not actually serializing residual functions yet. At that point, the bindings are all initialized. Only then this code kicks in which actually writes out the residual functions, and that can now rely on all serialized values and bindings being initialized.. I'd like to see a better testing story. Having dedicated unit tests is nice, but... Shouldn't you be able to just run all of the test262 tests through this new partial evaluator?\nWe just didn't do that for the serializer tests, as the test262 just didn't exercise the serializer much, and we didn't have a good oracle.. This can throw an exception. Is that just \"going to work\"? If so, why?. IteratorClose should be generalized to work on Completion, including NormalCompletion. When it was written originally, we didn't have a NormalCompletion type yet. Then you can wrap the result into a NormalCompletion, and throw only when IteratorClose returns a non-NormalCompletion, and otherwise return what's in it.. Why v instanceof ObjectValue? Don't see how that's in the spec. Should it be an invariant? if so, why?. Why rhsValue instanceof ObjectValue?. As far as I understand, you should rather state an invariant here that typeof O.$ListIteratorNextIndex === \"number\". It cannot be undefined, and you shouldn't need the logic to turn that into 0. . Prefer realm.intrinsics.undefined over new UndefinedValue(realm).. This is redundant with global, as global === true iff declarativeEnvironmentRecord === undefined. Remove global.. I'd rather call it _get, not _set.. Remove global. See comment below.. spelling. Is reverse + push known to be faster, or why this change?. Design note: Options used to be a pure datastructure, with the intention that it's configured on a command-line, with no behavior attached to it. I can see how it is convenient to use it for this handler, but it's a bit weird.. is this just to get a pull request out?\nWhat's the bigger vision of throwing exceptions vs recoverable errors?\nHow is it going to be tested?. And quite confusing to the end-user.. So the individual errors are logged here. Is this going to be a good experience? Will the end-user understand what's happening if the errors stem from some particular partial evaluation branch?. Hm, interestingly, \"undefined\" already existed before, and then would have just crash? Can you remove \"undefined\"?. Comment makes no sense.. I am confused regarding the purpose of x and y. Assuming all this test does it making sure that we don't crash, remove x.. This ternary expression seems to be a common pattern. Extract to a shared helper method?. This \"res\" thingy serves no purpose, right?. spelling, space after //. That's a lot of copy&paste. Factor out common code.. The call to resolveInitializedModules is potentially expensive, and should get its own time tracking. . Just execute should be time tracked as \"Interpreting global code\".. initializeMoreModules is the essence of \"speculative initialization\".. You pass in a value from the past, not future. In the future, when Prepack might get smarter about value domains, Prepack might figure this out. Either pass in a large value that's actually guaranteed to be in the future, or change the immediate function to do something with past values to recurse.. Very sad.. Let's see. joinAndRemoveNestedReturnCompletions  is typed to possibly return a PossiblyNormalCompletion. The afterCall function is not typed to receive that. Of course, that new type of result value cannot reach the afterCall call. @schandragit, does that make sense, is Flow getting improved to avoid this issue?\nHerman, did you consider restructuring the code a bit to avoid the :any cast?. Would be nice if you could extract the \"Babel parsing\" part of execute. But that can come in a separate pull request.. Would be nice if you could extract the \"Babel generating\" part of serialize. But that can come in a separate pull request.. Sounds awkward. Please rephrase.. Is there a way to move all these configurations into a separate configuration file? This command-line is starting to get big.. By far most changes are around turning strings to single-quote. This makes it really difficult to code review the actual changes. Is there a way to leave strings as they are? If not, I vote for starting out with double-quotes, and possibly changing that default later.. Checking for correct formatting should become part of validation and what's checked by  circle.yml.. Should this return typeIfPure instead of BooleanValue?. And if so, where could we use an additional invariant, or what test case is missing, to detect that?. Move into if statement below.. Good catch.. This code change allows for _getValIdForReference to return a BabelNodeMemberExpression. I'll add a comment why it's an identifier in this case.. Not sure what the confusion is. functionValue is always a FunctionValue per funcNodes typing. Yes, I'll add a comment.. I'll revert. Non-material change.. I add a comment.. I add a comment.. No. i add a comment and an invariant.. This is a subtle bug fix. I add a comment.. No deep reason. Makes generated code easier to read as check and effect are closer together.. Good point. Will change.. Will add long comment.. Will be explained by long comment.. Are plain function values simple? Are bound function values simple? If so, I think the code below would have to peek into .$BoundTargetFunction to figure out if this operation is safe.. returns. This is a breaking change to Prepack users, including our own website:\nhttps://github.com/facebook/prepack/blob/gh-pages/js/repl-worker.js#L31\nLanding this change needs to get synchronized with updating the prepack version on the website, and the repl-worker.js code.\nPlease write a \"BREAKING CHANGE\" paragraph on how to migrate existing code. We shall document this in the next release notes.. So, when we get here, all effects have been nicely undone?. Mention issue number that this relates to: https://github.com/facebook/prepack/issues/705. Why is this true? Is there no other unary operator but ++ and --?. We are targetting ES5.. I'll add the following comments:\nWe have some initialization code, and it should only get executed once, so we are going to guard it.\nFirst, let's see if one of the initialized values is guaranteed to not be undefined after initialization. In that case, we can use that state-change to figure out if initialization needs to run. \nSecond, if we didn't find a non-undefined value, let's make one up. It will transition from undefined to null.\n. We emit a \"let\" only if the original program used a \"let\". Otherwise, we stick to \"var\" as by default we emit ES5 code.. Will change name.. A piece of good news is that the packager will emit a list of all modules dependencies as part of the __d calls. So we won't have to guess anymore.. Filename has a spelling error.. spelling. Indentation looks fine. Prettier will fix that too.... This any-cast makes me sad. Is it really needed?. Please also remove $ yarn global add prepack here, as it doesn't make sense.. While you are at it, you could fix this too... Should be message = \" threw an error\";. When !serialized, then none of the outputs produced below would make sense. Not sure if it can even happen at this point that !!serialized.. This seems wrong?. get here. Your change certainly improves things into the right direction, and checking for !mightHaveBeenDeleted makes sense.\nEven better, but that could come in a different pull request, would be if you always emit the undefined entry here, but then issue a (conditional) delete statement afterwards if the entry indeed got deleted. Where to do that? In _assignProperty, the assignment currently happens conditionally (an ifStatement is generated), and there an else branch could be generated that issues the deletion, assuming that your new kicks in that adds a dummy value to begin with (_assignProperty is called from a few more places, where issuing a deletion probably won't be needed).. I think this test case brings out the issue:\n```js\n(function() {\n    let x = global.__abstract ? __abstract(\"boolean\", \"false\") : false;\n    let o = { a: undefined, b: {} };\n    o.a = o;\n    if (x) delete o.a;\nglobal.inspect = function() {\n  for (let name in o) { return name; }\n};\n\n})();\n```\nCan you either address it as described above, or create a new issue to track the remaining work?. Instead of checking !this.modules.initializedModules.has(moduleIdValue) I'd rather see an invariant that if there is already a value, then it better be the same.. Let's add some more value to this invariant. Move the above initializedModules.set into an else branch of this if.. I think I had introduced the onError parameter to the serializer just for dealing with Introspection errors here. Can the concept be removed in the serializer code if there's no other user for it?. Very nice.. Remove this line, as we'll output the same message below.. By deleting this code, the messages will appear on the screen as errors, not differentiating to our confused users that this is in case recoverable by delaying the require() call?. Looks like you sneaked in an actual bug fix?. Ignore, I saw you already did it!. That's an important invariant that I don't want to remove easily... Let's see what we can do.. I think it's not needed right now, as a native functions are intrinsics, and we add entries to the generator to mutate their properties.\nTo make sure we catch the case when this is no longer true, you could replace the body of this function with throw new Error(\"TODO\"); as there's really no way to test this right now. Or you do the right implementation, which is probably something like return this.length === this.getLength().. While you are at it, we can make the type of $FunctionKind more restrictive. Looks like it (eventually) must be \"generator\" | \"normal\" | \"classConstructor\". While you are at it, we can make the type of $ThisMode more restrictive. Looks like it (eventually) must be \"lexical\" | \"strict\" | global\". Make the return type of GeneratorFunctionCreate be ECMAScriptFunctionValue, and avoid such invariants. This will require changing some more signatures, e.g. of FunctionAllocate.. Change signature of FunctionCreate, and remove invariant.. Why can it not be a BoundFunctionValue?. Avoid invariant by changing function signature.. Look 20 lines up --- same code. Probably should get same treatment.. Or even better, it sounds like the type of F in the function signature should be NativeFunctionValue | ECMAScriptFunctionValue, excluding BoundFunctionValue.. Good catch, fixing the invariant. I see a few more instances of this kind of Assert in construct.js and function.js. Please change all of them, and push up the type signatures as appropriate.. Note 1. Assert: F is an ECMAScript function. above. You can push this up.. Type check should longer be needed after taking care of comment above.. Reading the code below, it seems that the default should be \"strict\", and then you can remove the branch || F instanceof NativeFunctionValue below, which isn't in the spec anyway.. (Wondering if NativeFunctionValue may also be allowed, not sure how our internal classes relate to the spec.). Maybe we should have an intermediate UnboundFunction type (not a great name choice), from which NativeFunctionValue and ECMAScriptFunction derive.. there's a comment below \"visit properties\", so for consistency, say \"visit symbols\" as a comment here. add comment \"inject symbols\" to be consistent with comment below. Is this invariant really needed? Why?. remove comment. Remove this line. Pointless, and will cause problems with cycles.. Instead of an invariant, throw a FatalError(\"TODO: ...\"). Reading through the spec, I now realize that symbol properties can in fact have property getters and setters. So... The right course of action is in fact to adapt _emitProperty.. Please remove commented-out code.. The generated code should be ES5-compatible. So make the variable declaration be a \"var\" instead of \"let\".. Let's keep it simple. We don't really need a new name generator instance. Remove it. . Instead of calling deriveFrom, just get another name via the already existing scopeNameGenerator.. A big part of this whole refactoring is to separate out the aspects of a function-given-as-source into a separate subclass to avoid numerous defined-ness checks and instead get checked type-safety.. Seems to me that $FunctionKind should go to OrdinaryFunctionValue.. Write conjunctive invariants as consecutive invariants.. When the serializer kicks in, do we generate assignments for this?. Why?. Not sure if this is a good idea. Is there a test case that actually hits this?. +1 for @yinghuitan comment.\nAlso, this will skip the ToString(Partial) call, which is okay only if the AbstractValue is known to be a string. So, also guard this case by  && !description.mightNotBeString().. I am surprised this already works...\nTwo more things:\n1. In ResidualHeapVisitor, you also must visit the $Description.\n2. In Emitter.js/getReasonToWaitForDependencies, you need to add a new case for SymbolValue where you check for $Description.. The code might become simpler if the desc/$Description in SymbolValue is always a Value (for which holds that !{value}.mightNotBeString.. Named effect properties would be great. Very mysterious.... Judging by the function name intersectEffects, I find realm.intrinsics.empty and perhaps also new Generator(realm) surprising. Expected would be to at least check if c1 === c2, and then return c1 else empty, or probably better, generating code that does it dynamically. Similarly, deep equality check for generator.\nI understand that this isn't needed for the concrete scenario at hand, but at least one prominent comment about the current limitation would be good.. Why this special treatment? Am I missing some Flow subtlety?. This seems like a generally useful function. I can see how we can cut a few lines e.g. in modules.js by using this.. Okay, !{value}.mightNotBeString() || !{value}.mightNotBeUndefined().\nmightNotBeUndefined does not yet exist, but should be added at this occasion.. The two more things that need to be done have nothing to do with the remaining work of serializing properties which are keyed by symbols. The two more things are strictly needed to make this pull request self-contained.. Is the different spacing intentional?. This looks wrong. [name] has a different number of elements than [lnode, rnode]. What is + applied to?. The spec says that this field is Either \"base\" or \"derived\". Undefined is not an option.\nCan you figure out the built-in functions should be? Or at least at a TODO that this should be followed-up on, as your refactoring just represents the current state.... Does name.$Description have to be of type string, couldn't it also be undefined?. This doesn't seem right, you are not producing the proper string for the AbstractValue case.. Make this Value.. And, whereever .name appeared in the past, fill in .name.throwIfNotConcreteString().value.. Make this void | Value.. I see. Points to that requireReturns should probably be backed by an object, not a map. This all should get reviewed.... Further investigations on this can happen later. I filed an issue for it: https://github.com/facebook/prepack/issues/852. We must keep this invariant.. ?. Even if you can omit: still buildNode and announce, just don't call .emit(). That way, the invariant I pointed out above should still hold.. Is this else branch actually feasible? Is there a test case that exercises it? I'd expect it to be dead.. Change null to undefined.\nOr just drop that part of the disjunction, as the instanceof check is sufficient.. Move this if in the above then-branch.. Align with other code: Either always do instanceof Value check, or always do val.$Description !== undefined. Avoid doing indiscriminate truthiness-check, which is a bit funky in JavaScript.. Is this invariant needed to make Flow happy? If not, I'd omit it.. Make that void | Value. There's no reason to include null.. Prepend test case with a comment like this (enforced by the test runner):\n// does contain:[11, 22. sequential. I am confused if the array length will always be set correctly. Let's talk in person.... Here's a test case that doesn't work with the new code:\njs\n(function() {\n    let a = [1,2,3,,,,];\n    inspect = function() { return a.length; }\n})();. Remove. sp. This includes values that are not actually valid array indices, e.g. Math.pow(2, 64).\nThere is already a function that checks that: IsArrayIndex.. So we are back to potentially emitting giant literals?. The name is confusing. But I can't think of a really good one either. If you don't do the +1 in here, and return -1 if no entries, then the name maxKnownArrayIndex would make sense.. Remove. I suspect that deletion of symbols fully works. So there should be a statement like if (desc === undefined) continue; //deleted, as well as a test case that exercises deletion of a property.. getSuggestedArrayLiteralLength. It seems that Prepack already supports conditional updates of symbol properties.\nPlease include the following test case:\njs\nfunction() {\n    let x = global.__abstract ? __abstract(\"boolean\", \"(true)\") : true;\n    let obj = {};\n    let symbol = Symbol();\n    if (x) {\n        obj[symbol] = 42;\n    }\n    inspect = function() { return obj[symbol]; }\n})();. You also need to wait on this._getDescriptorValues(desc).. || instead of ? true :. Only visit symbol when don't skip this iteration via continue below.. But the commonly used createErrorThrowCompletion doesn't set any location?. One more issue: This visitEntry call needs to happen within a this._withScope(generator, () => { block.. Looks like you did the todo?. tryQuery is used from a few more places. I think the whole error-handling logic should move into tryQuery.. This ties the implementation of _emitProperty very closely to _serializeArrayIndexProperties. Brittle. I'd prefer if there was a new (optional) set being maintained, like dummyProperties, which entries are added to by _serializeArrayIndexProperties, and _emitProperty gets a new parameter cleanupDummyProperty which is set by _emitObjectProperties as needed.. Bonus points if you can come up with a test case that shows the underlying issue without this change.... This looks fishy.. Why this change?. If the generator present, the code in ResidualHeapVisitor will put the value into the scope of that generator, and then the emitter will in turn put the declaration into the code-block associated with that generator. I can add an invariant to that end here, so that you see the tie-back to the generator.. Good idea.. Don't redefine, import from \"./options\";. Dead, please remove.. simplify to errorHandler,. Another silly naming discrepancy that should be addressed eventually. If that's harmonized, then the Options datatype could be truly the union SerializerOptions | RealmOptions | PartialEvaluatorOptions, right?. You could rename this type to PrepackOptions, or CombinedPrepackOptions, to make it a bit more clear what this type represents.. How did you decide which visitValue calls to replace with visitEquivalentValue calls? Shouldn't it be done systematically?. Please move to realm for reproducibility.. Move to realm for reproducibility.. I thought interfaces are on the way out?. Generally, the ^ is guaranteeing that we stay in 32-bits? Worth a comment.. How about a special hash value or a flag, and assert that this never hits the serializer?. And this discussion is the reason why I'd like to move everything that is relevant to reasoning about abstract values in a separate ValueManager class. It should have a method like createBinary(op, arg1, arg2), which hides the details and consolidates those implementation details.. Or an optional object like { skipInvariant: true }.. Don't just try to get the string out manually. If invariantOptions is defined, call ToStringPartial to get the string. This will throw (and it should!) if a bogus non-string value is passed.. When would it be a good idea to do \"DEFINED\" instead of \"FULL\"? I see what it does, but I don't understand why anyone should ever use it.\nAnd note that the name \"DEFINED\" doesn't quite match the condition build up below. I'd expect it to check against undefined, but you are generated code that tests for whether the value is truthy.. To a reader of the code, it's not clear that \"DEFINED\" influences the invariant generation. If we stick to a simple enum, then the name should be more descriptive.. It took me a moment to convince myself that nothing bad is ever happening, even if a NaN hash from a number value enters the picture.. Separate pull requests make sense. I just would have liked to see that straightforward refactoring as the first pull request, to start with the cleanup, instead of first making a dozen files more complicated, and then later having to touch all those files again.... But I think there's a good chunk remaining visitValue calls where non-object values appear. For example in visitValueMap the keys and values can be any Value.. This remaining TODO is not completely unrelated to the comment about #482 below.. What does the x && do?. This scopeList seems to be unnecessary. Down where you need it, you should be able to just say Array.from(scopes).. The use of the globalDirectives below is conditional on just this._shouldBeWrapped. Should the realm strictness / presence of global directives play in there as well?. A more descriptive flag name would be \"globalDeclaration\".. But this doesn't have to be a global declaration?. That new void case seems unreachable.. Why is it guaranteed that configurable===false and enumerable===true? (And what's up with ignoring writable?). I think the original code was already slightly broken, in that it didn't detect if the property update also changed any flags. But just checking even fewer flags doesn't make it better.... Why this change? Looks like this might be related to a new Flow version (https://github.com/facebook/prepack/issues/905). If so, I'd prefer a separate pull request that bumps the Flow version number as well.. Good catch.. Why weaken the static signature?. Did you delete this because of the static signature? I think there's value in the assertion just because Flow isn't sound. Maybe invariant(!(O.mightNotBeObject));. Same for other places where invariant got removed.. Why additionalFunctionInstances &&?. Seems that whether this condition is true or not depends on user input, so should not be an invariant, but rather be logged as an error if violated and important for stuff to work.. _referentialize deals with bindings that are (potentially) mutated by residual functions.\nHow do we deal with this conceptually when the same bindings are used by prepacked residual functions?. This if statement here decides whether a function should be treated in the naive way.\nInstead of that requirement above that all instances of a function must be either prepacked or not, I think you should be able to just deal with the relevant instances right here, and then always go into the native first case.. Comment doesn't make sense here, and the realmGenerator is no more.. I don't like the name \"global scope\", as this is confusing in JavaScript. It's not really the global scope, even for the realm.generator. We always emit to a scope nested in an anonymous function.\nThe word \"scope\" itself might not be the right word, as JavaScript scopes are weird. Maybe that should be renamed to the more generic word \"Context\", or \"User\".. Can we avoid evaluating the functions again? checkThatFunctionsAreIndependent should have done that already, we should just need to keep the effects around.. Let's avoid manipulating global state (this.realm.generator) when possible. Took me a while to figure out what's happening.. Let's talk about visitRoots.\nI think the way it should work is that it only gets called once, and gets some information about additional functions passed in. Within visitRoots, it would enumerate over the additional functions, apply (and later undo) effects, and visit what's relevant. Note that the fixpoint computation below should happen once, and over everything that's relevant.\n. Don't like FV abbreviation.. The initializeMoreModules code should run before we collect effects on additional functions. So the code above needs to be moved below. Basically, the additional functions must be interpreted last.. What does fstr mean?. I don't understand the need to mutate this.generator and this.realm.generator?. Shouldn't the effects be undone later?. Is this to just undo effects? That should probably happen immediately after each function is processed, in all passes.. By default, it should be okay to ignore the preludeGenerator.. Spelling: Instrinsic => Intrinsic. What's the story of why this is needed?\nI don't like AbstractValues with buildNodes that are potentially non-pure... Or is there a reason to believe that it's operating on a pure datastructure?. Instead of t.memberExpression(this.preludeGenerator.memoizeReference(\"Symbol\"), t.identifier(\"for\"), false), you should be able to say this.preludeGenerator.memoizeReference(\"Symbol.for\").. Rename to _emitAfterWaitingForGeneratorBody.. This Flow-type checks? I am impressed.. I don't understand this case, and why it's okay to just ignore this.. Can you explain this in a comment right by the invariant?. And add a TODO to not just check whether the this._delayInitializations option is on, but pass through more information to check that this._body is a delayed initialization body.. This old TODO comment still have some relevance: In some cases, it's important to associate the intrinsic object with a particular point in time that the serializer should know about. In other words, intrinsicNameGenerated are a strange thing.. I think the point of this test case was to make sure we fail nicely in case of an attempt to delete an unknown property on a partial object.. Let's not do side effects here. Instead, build up a sequence expression and return that.. This new special case shouldn't be needed, and the Flow type of buildNode is just that the implicit else-case is actually infeasible.. This doesn't even Flow type check!\nEntries in this.body must have a buildNode field that are functions with a non-void return type, while context.emitDefinePropertyBody is specified to return void.. Again, buildNodeResult will already be truthy, no need for this if statement.. It's probably okay in this pull request, as InternalJSONClone is only used to construct the template object. But in general, one has to be careful: Calling JSON.parse() is always going to create a new object identity, and two such calls shouldn't be considered equivalent.. This code block is a total copy&paste of the toString handling in NumberPrototype.js. That's of course not a problem introduced by this pull request, but this pull request does make the code duplication more elaborate.... Observation: This block of code builds up a binary condition around !==. This is a particular instantiation of the more general binary expression construction. And the string \"!==\" is mentioned three times here.... Why are you excluding +? Because of string concatenation (but the mightNotBeNumber checks guard for that), or because IEEE floating point additions might not be commutative (I think we can consider that it is)? I would like to really better understand the underlying algebra here.... I thought you prefer === undefined over !?. What's the reasoning behind the > 100? I have no clue, and don't see a comment.. Doesn't this object allocation and field initialization create some entries that are tracked by the realm? Just pointing it out, because the catch-logic in binaryOp seems to assume that computeBinary is pure. I'd prefer to make computeBinary truly pure.. It seems to me that this can run arbitrary (state-mutating) code (ToNumber calls ToPrimitive which can call anything on an object), and there's nothing guarding that here, or even a comment about it.. StrictSimple.js fails? Interesting, but I can see how it can happen if the chain of function calls isn't all strict/non-strict. Can you also add a test case for the other case, where the function isn't strict? Just for completeness.. Emitting naive if-statements seems suboptimal for performance.. This will return an object, and we'll probably compare the toString of that object. That seems a bit brittle, as we'll compare that output from node.js against the output of Prepack.. Hm, this indicates that there are abstract values (the val coming in here) which are not pure. That seems wrong. In the past, the isPure designation was rather associated with the buildNode itself.. Is this for template objects? Otherwise, why do we allow abstract values with a value domain of size 1?. How can the condition not be an abstract value?\nEven if the condition can be of a non-BooleanValue type, (why) does it matter?. (The intention is that) this works on any kind of AbstractValue, not just those which are of type BooleanValue, right?. Can you also wire this up to the command-line?. As this calls computeLogical, this function deserves a similar comment as computeLogical regarding side effects.. Copy&paste code duplication with LogicalExpression.js?. You save and restore isReadOnly, but I don't see where it would get mutated?. Is this a bigger issue that also applied to other existing code, or am I missing something?. Is this a temporary hack? What exactly goes wrong with the regular joining logic?. To reason about this, I now need to understand who constructs abstract values with a \"!\" kind string.  How do I figure that out?. Do you mean value.args[1].mightBeNumber?. I do not see that simplification depends on any other state, e.g. path conditions. Re-doing this deeply is wasteful. Unless we want this kind of simplification to be stateful, we should only ever do it once, ideally at construction time, never constructing un-simplified values to begin with, but at least marking that simplification has been applied.. What is the \"inconvenient expressions\"? Maybe it's all going to work out fine in the end, but I think it would be good to start painting a holistic picture of the algebra involved --- what expressions are being constructed, how does a normal formal look like that we can reliably and automatically compute, why is there going to be confluence in the end.... Can you add a TODO with a comment that calls out the particular inconvenient expression that this is working around?. Referentialization kicks in on modified captured bindings.\nTo make things safe, check if any rewritten additional functions have any modified serialized bindings, and if so, log an error.. So you skip objects marked as refuseSerialization as a root. Just to make should, and to indicate intent, also add an invariant to visitValue that we'll never visit a value that has refuseSerialization set.. Is this needed? Why? I don't think this should happen.. Why is this invariant needed now when it wasn't before?. I am confused that the code above obtains a body, but if instance.declarationBodyOverride that body is ignored here? . I also don't understand the comment.. I think @yinghuitan also wanted to refactor this huge function, and pull out helper functions. Might be worth checking if him if came up with a competing.. for (let propertyBinding of obj.properties.values()) is probably more efficient.. I don't like base or Context for the name here. How about commonScope?. Update comments referring to \"global code\".. Is there a deep reason for the new afterGeneratorVisit complication? Below where this is being used, I would just issue another this._withScope call.. I don't understand why partial objects are skipped here.. I don't understand what's special about global here.. Naming is a completely mystery to me.. for (let [binding, old_value] of ob). Don't understand comment.. Why do we care about visiting the old_value?. Instead of this fixup here, can you set the right generator before the additional functions are interpreted, so that this new generator will have the right parent to begin with?. grammar. What's the relationship between bindings and property bindings?. Why are we not allowed to delay initializations in additional functions? Feature cut? Then add a TODO to reconsider this. Or is there a deeper reason why it would never work?. Herman taught me to prefer the more specific desc === undefined.. You should be able to remove the return; and instead have an } else if.. Why does this happen here now when it didn't happen before this pull request?. Looks like this would also set .declarationBodyOverride for a (nested) residual function that's only reachable from an outer additional function?. The serialization already happened. Why is this holding back the binding?. This function shares code with serializeGenerator in _getContext. Can you factor out a common helper function?. Rename this parameter. It no longer just applies to some \"dummy\" property. A better name now would be deleteIfMightHaveBeenDeleted.. Redefining binding values like this seems wrong to me. If this does what I think it is intended to do, then the right way of doing it must go through the \"referentialization\" phase, the referentialized location needs to get updated. Values and locations where values are stored are not the same thing.. Why include things from additional functions? Nobody can rely on this.. In this case, when we are delaying, we are throwing away any partial effects computed by evaluateForEffects above, and in that case, we should not keep around statistics about abandoned nested delayed modules.\nMeaning: Please save this.statistics.delayedModules before the call to evaluateForEffects, and if we get into this effects === undefined case, restore the value before  incrementing it.. I think that means if the parameter is not passed, the default value is undefined. However, if an argument value is passed, it must be true. Maybe a bit surprising, but correct. (true in the signature is a type, not a default value.). By doing a walk over the AST in this way, you are counting what's statically present in the code. The intention of the referenced issue was to count which actually happens, and how often, while running the code in our the interpreter. Look at src/environment.js, there's a evaluateAbstract function which gets called for each AST node.. \"Rather than look for this pattern everywhere\" - I would phrase that as a TODO: In some future, all such expressions should immediately simplify down to some normal form, and it should be impossible to construct values that are not in normal form.. Another invariant should be invariant(!condition.mightNotBeFalse()).. And both invariants should be checked before the if (condition instanceof ConcreteValue) return; statement.. I don't get why that invariant is guaranteed to hold.\n- Anyone can create abstract values with the \"&&\", as we haven't locked that up. But that maybe secondary...\n- createFromLogicalOp seems to happy construct conditions where one operand is a concrete value.. Similar comments as for pushPathCondition apply.. Why the lack of symmetry? pushInversePathCondition deals with both cases... How about folding both together with a boolean parameter negate?. Spelling of simpliedInverseCondition. It's strange to see this one-off case. Maybe this is to solve a little issue at hand, but I don't want to see our reasoning infrastructure being randomized.. Why are the args guaranteed to be of this shape? Hard to tell anything given that anyone can set the .kind property... But in general, if it's a conditional value, why can't there be more structure to the arguments?. Seems quite redundant with the $GetOwnProperty code.. This logic here seems more general than the place where it sits: createFromLogicalOp could do this kind of normalization to benefit anyone who attempts to build logical operations.\nInterestingly, createFromConditionalOp already does some simplification.. Why special casing for BooleanValue and not just using the more general .mightNotBeTrue kind of machinery?. No funky abbreviations please, especially if they don't even match the actual parameter name!. In seconds or what?. I have no problem with the invariant(condition instanceof AbstractValue); invariant. My comments were about other invariants that are or should go in front.. Totally agreed that the factory should not be path sensitive. I just meant the mightNotBeTrue() kind of checks that result in simplified expressions.. A mistake, yes, but this would be a very late invariant check. Should createFromLogicalOp disallow it as well?. What I meant with the one-off is that only here you also add the simplified path condition in addition to a non-simplified path condition. All the other pieces that get pushed might not be simplified. Overall, I am confused whether pushed path conditions are simplified or not. I don't see enforcement or comments, just this one special treatment.. Hm, can't find the constructor invariant. Can you point me to it?. Not sure what the intention here is. Are you after object values, or just abstract values that might be aliased? In general, this new behavior seems too crude.. I see. Still, allowing for an ObjectValue to be potentially null or undefined is quite surprising. Do you consider this a quick hack to unblock the React Compiler, or does this permanently alter the meaning of ObjectValue? (Will be important for any future simplification rules or even a formal encoding for an SMT solver.)\nCan you leave behind a longer comment in the code about this?. Is the whole code around serializedPropertyBindings to support this check?\nIf so, I believe an equivalent way much more lightweight way would be to check if !object.isIntrinsic(), as that's what's guarding the corresponding code in InternalUpdatedProperty.. Why is the invariant true that the body has one entry? What happens when I run prepack on an additional function that actually does nothing?. Unnecessary check, visitObjectProperty does it as well.. As I said in other comment, I don't think we need the added complexity.. I think this was the only callsite of hasInitializerStatement. Please remove the function declaration as well, or even better, add the invariant invariant(!this.residualFunctionInitializers.hasInitializerStatement(functionValue)) to the else-branch.. Took me a while to verify that this is harmless, but seems correct.. Go code coverage!. For condition.kind === \"==\", this seems wrong, as in that case left is known to be falsy.. Why is this check nested in a trueVal instanceof NullValue || trueVal instanceof UndefinedValue branch? Doesn't it always make sense? Or is it to avoid executing some kind that has side effects?. You could reduce unneeded swapping by testing for !(x instanceof AbstractValue), or x instanceof ConcreteValue.. Is there an unwritten rule now that all calls to GetValue should be followed by a call to simplifyAbstractValue?. Why the change of return type? To make Flow happy? Don't see any other dataflow reason.. Interesting and a bit surprising to see this treatment of the empty value. So our \"conditional\" is really something different than just the ternary JavaScript operator. I didn't realize that.. The increasing asymmetry of pushPathCondition vs pushInversePathCondition worries me.. Change requested: The original equality was guaranteed to yield a Boolean (true or false). This possibly replaces it with just cond. Is cond really guaranteed to be a Boolean? \nPrepacking the following doesn't seem to force a \"Booleanization\" of a numeric condition.\njs\n  let x = __abstract(\"number\", 42);\n  y = x ? 1 : 2;\nSimilarly, I'd hope that negate always yields a Boolean in this setting, but I am not sure. Would be nice to see invariants for all this, especially around simplification rules.. All the checks and this nested invariant seems to imply a general precondition for this function: op.kind in [\"==\", \"!=\", \"===\", \"!==\"]. Arguments to abstract values must always be pure, so in that sense, it's safe.. It's by construction. Difficult to check/enforce, but very fundamental to the nature of abstract values.. Why? Is this a performance optimization?. After refining the operands, the following simplification rules are generally applicable, and have nothing to do with path conditions. We shouldn't have to pick and choose some rules here and there. There should only be one way to create logical abstract values, and it should always apply these rules.. Good point. I don't think there should be a helper function for this. There should be just one way of constructing a logical abstract value, and it should always do the optimization.. Great! Would be nice if we had a better framework to state assumptions/guarantees. Right now, I had to chase through all code paths to verify the intended boolean-ness of the result. This doesn't scale when building more complex simplification rules.. #26 still applies. . spelling of simplier. Prefer a sequence of invariants over logical expressions.. +1. That would fix #1007!. Calling factorifyObjects multiple times is not the most optimal solution:\n1. It may result in the creation of virtually identical factory function (duplicate code)\n2. It's frequency-based heuristics will be distorted.\nDoing it this way might be the easiest, but would it be possible instead to delay it until later and then do it all in one go?. Can you add comments that illustrate the patterns that you are processing here?\nI need some higher-level argument to convince myself that the code transformation is correct.. Seems useless. If you added the default case to indicate that it wasn't just forgotten, then this should come with a lint rule that enforces default cases.. Why is this case needed? To assert that functionInstance is not undefined? Prefer an invariant in that case.. Maybe assert that defaultFn() results in something that is truthy.. Incomplete comment. This seems unreferenced, and just by the name of it it's not clear to me what it does.. Spelling. What exactly is the meaning of this? Couldn't the same function instance be referenced by multiple additional functions, and then what?. Why is it a good thing to have multiple captured scopes arrays?. handling?. Then call it functionExpressions.. Instead of the additional if (functions) { nesting, could you just say for (let fname of (functions || []) {? Smaller change, less control-flow to understand.. Grammar.. I am not a fan of cute abbreviations.. spelling. __registerAdditionalFunction may be called from a partially-evaluate context whose effects are later abandoned. And yet, __registerAdditionalFunction stores the given function value in a global map recordedAdditionalFunctions that doesn't participate in effect tracking / undoing.\nWhat are the implications of this? A comment and/or test case would be appropriate. Reading all the reason, I suspect that the result is just a really bad error message when the indexed global variable does not hold a plain function value in the end, but no horrible crash. In that case, a little bit of work should be done to make the error message / diagnosis tolerable.. A better name would be __registerAdditionalFunctionToPrepack.. We don't usually type out === true for something that's known to be a Boolean.. All errors should fall into one of two categories:\n- user facing errors. In that case, a FatalError should be thrown (or @hermanventer probably has a good suggestion on how to do it).\n- internal errors / bugs. In that case, state an invariant.. Probably not. Test cases would help to determine this, as elsewhere we have the invariant that all visited values must be serialized.. Avoid any whenever possible. Please plug in correct type.\nIt seems that a better name for object would be properties.\nSpelling of serialzeValue.. I don't think object can ever be null.. Omit === true for Booleans.. Don't mutate serializedValues like this. Instead, change the visitor to not visit the value.. A few reasons:\n- By pulling on this value, the visitor will transitively visit everything that this value depends on. Just adding the value to serializedValues doesn't do the transitive serialization, leading to obscure invariant failures eventually.\n- Visiting values in scopes where they are not needed will lead to suboptimal code generation.. I am not a big fan of the very dynamic return type.. Again, avoid adding serializedValues like this. Also, seeing all the : any casts hurts my eyes... . Also, this only captures the case where $$typeof is a data property. When it is an accessor prorperty with getters and setters, your _getPropertyValue returns null, the value gets skipped here, and the invariant connecting the visitor and the serializer will break.\nI suggest you handle this in the visitor:\n- Don't visit values that won't be needed.\n- If $$typeof must be a data properties, and it is not reasonable to support accessor properties, call logError (or issue the error in a different way that @hermanventer approves).. You should log an error for this in the visitor. I think a user can construct a legal JavaScript program this trips this invariant.. I must admit that I am not familiar with this syntax. What does this line do?. Instead of propsValue.properties (why does Flow even allow this?), I think you want to check if propsValue instanceof ObjectValue.. Don't do the unspecific : any cast. Doing the ObjectValue typecheck above should fix it.. Don't throw an error, call logError, preferably in the visitor, but here would be okay too. Make the message a bit more descriptive (prop name for JSX object).. If you want to land your pull request before implementing this, call logError for now.. In fact, it seems like you want to visit less for ReactElements. Consider tweaking visitObjectProperties.. I like your comment.. You could generalize all cases a bit for other kinds of literals that have truthy values.. I see three cases in your handling of the IfStatement above, but only two are getting exercised here.. Not very exciting, but you could also reduce true && x to x, and false || x to x.. Avoid casts that end in : any, which just kills all further type checking. Prefer continuing casting to what it is, e.g. ((expr: any): BabelNodeArrayExpression) here, and similarly everywhere else.. According to the type signature of serializeValue, null is impossible. Either delete case, or change into an invariant.. How can childrenLength.value type check? Shouldn't. The (inferred) return type of _getPropertyValue should be null | Value. Can you add that type annotation, and that insert the necessary checks? Note: An ArrayValue might have a length that is an AbstractValue, which you currently don't support. You should log an error in that case.. I don't think you want to just run over it if it isn't a Value.\nIt can be a null if...\n- It's an accessor property, or\n- if it got deleted.\nTo be safe, I'd call logError with a message that indicates that this is an implementation limitation.. Why is it okay to ignore the remaining case? I'd suggest to log an error.. ?ObjectKind allows for null and undefined, right?\nAlso, there are a number of callsites that omit the argument. I understand that Flow allows for this, but let's make it more explicit, and make the argument kind?: ObjectKind which also only allows undefined but not null.. I suspect that symbols get ignored by the serializer for ReactElement?. What is this about? Link to some background information? Seems fishy and not terribly unique.. This can fail if diverged control-flow gets merged. Make it a nice user-facing error.. Better: funcLength !== undefined.. And maybe factor out some bigger chunks into a separate file.. Now I understand. An example would have helped :-). What's the user experience when this FatalError is hit? As no other error gets reported, I'd expect at least some verbal message indicating what limitation the user hit.. Same comment as for the FatalError above.. No need to hide type info in comment, you can make it a real type annotation :-). To avoid costly object allocations, a simpler scheme of void | false | true would be sufficient.. Another case you could add: If the node is a unary expression with operator void and the argument is a literal, then this node will evaluate to undefined without side effects, and thus results in the known truthiness value of false.. If key is an abstract value, is it okay to be not a string?. Don't have global state like this. Move it to the Realm.. Don't maintain global state. Maybe wrap all of this code in a class, and have the serializer instantiate it for the duration of a serialization.. I feel like the condition must not be negated, this should result in an infinite loop.. Test coverage could be better: https://1648-45147841-gh.circle-artifacts.com/0/tmp/circle-artifacts.0ehMLNX/coverage-report/lib/utils/jsx.js.html. Space after //. Looking at construct_realm.js from where this is called, it constructs a few more internal objects. So this assignment should go there at the end. And then the name intrinsicsInitialized is a bit off. Instead, I suggest to just reset the statistics counter, and make the increment in ObjectValue.js unconditional.. What is this catch trying to put under the carpet? Either a comment or logging an error seems appropriate. No code coverage from tests.. If there's legal code that can trigger this, throw a FatalError with a descriptive message instead.. I don't understand the reasoning behind this. Even if it's okay, a comment in the code seems appropriate.. Not exercised by tests.. What if the descriptor is an accessor property? I suspect you'd want to log an error in those cases (not supported).. The :any cast would hide any spelling error in value. Cast to the actual types.. It must be a value, as desc.value !== undefined.. What if it's not a Value? That indicates that we are dealing with an accessor property. Log an error that it's not supported?. Wrong comment(s)?. This doesn't seem to fit the declared function signature. Please don't have cast that end in :any.. @sebmarkbage:\n1. Truly global variables are just bad design in most cases.\n2. More concretely, I don't like global variables that accumulate stuff as the test runner currently runs all test in one process, just creating and destroying realms. So a truly global registry would be a memory leak, and slow down the test runner.\n3. We currently do not actually support multiple realms at the same time, so storing things in the singleton realm is okay.\n4. You are right that one day we might want to support multiple Realms as the spec allows, and then the realm-based symbol registry won't work. I should further familiarize myself with the details of how multiple realms are allowed to interact. In any case, the right thing to do seems to me to introduce some new kind of realm-container, we could call it the JavaScriptEngine (I guess that's you mean by the \"standalone module\"), and all of the global state that isn't realm-specific should move in there. That would hopefully reduce our ever-growing Realm class to what it's supposed to be according to the spec, and allow for multiple realms in the future. The engine class would maintain a set of realms, and each realm has a reference back to the containing engine. Does that make sense to you, @sebmarkbage? If so, then I'll create an issue to track this.. Mysterious boolean.\nIs this function meant to be path sensitive?. Mysterious true value.. I don't understand the intuition behind isCondition.. Why is this change part of an other behavior preserving pull request?. Don't end with : any cast, add cast to type which is supposed to have .parentPath property. Or maybe the BabelTraversePath is missing a property declaration?. Instead of these unsafe cast that end with :any, consider defining an interface HasUniqueTag with uniqueTag, and add a cast to that interface. (This applies to all other uses of uniqueTag as well.) That way, at least any spelling error of uniqueTag would be caught.. Okay, its about the \"root function\". But I don't understand why we need this special handling. . Just from the name of it, I still don't get what ...Condition does. Is it path sensitive? Is it meant to only be called for particular kinds of conditions? Conditional expressions, or maybe binary conditions?. Sad.. We don't use underscores for names.. additionalValueOverride is only used to check an invariant? A Boolean would do?. What does it mean if !residualBinding?. The condition modifiedBinding.value !== residualBinding.value is a bit dubious, I can see it's validity under the assumption that no other additional function modifies this binding value.. Why is this a valid invariant? Could I easily write a program with two additional functions that will violate this? Log an error instead? Indicating to the user that this is a current limitation. Invariants always indicate Prepack bugs that will get the oncall woken up at night.. Instead of this single override, maybe have a map of functions to new values?. +1 for the invariant. Where does this trigger today?. what about Array.prototype.push.apply(prelude, init)? Guaranteed to be faster.. State it as an invariant.. Conceptually, I don't like mutating \"values\", even if they happen to represented by a initialized variable. They should be a nicer way to get to it. Or at least add a TODO that this should be done in a cleaner way.... Bunch of lines deleted here. Not needed?. Can these emit... functions get moved to the Generator? Seems more consistent to me.. Why the new sad : any casts?. Why the sad : any typing?. Omit === true.. I would appreciate it if you could annotate all return types. When reading the code, it takes me longer to figure out what this function can do, and it's always good to double-check Flow.... I see. Now I understand :-) Can you persist that as a comment?. Yes, you can modify. Just edit ./flow-typed/npm/babel-traverse_vx.x.x.js. If you are wondering where those files came from --- I scooped up some stuff from the web and heavily modified it. It's not authoritative, just good guidance!. uniqueTag?: number. That represents the fact that this value can in fact be missing, and it can never be null.. At runtime, function declarations get hoisted, but declaration initializers are not!\nTry a test case like this:\njs\nf = function() {\n  return nested; // note that declaration comes later --- this is okay!\n  function nested() {\n    var x0 = 1;\n    var x1 = x0 + x0;\n    var x2 = x1 + x1;\n    var x3 = x2 + x2;\n    var x4 = x3 + x3;\n    return x4;\n  }\n}\ng = f();\ninspect = function() {  \n  return g();\n}. I don't think EmitBody is best in terms of english grammar. If Body itself is not available, I'd prefer SerializedBody, or maybe CodeBody.. EmitBodyType instead of string.. Let's avoid \"Other\". I'd suggest ConditionalAssignmentBranch.. I don't understand this comment in connection with the invariant below which seems to enforce that they do already have to be specified.. Dead code. Is this invariant needed for Flow?. additional. We don't know that yet here, as we visit additional functions out-of-order, later? Why not just visit them right here?. ?SerializedBody allows for either undefined or null. We don't generally do that in Prepack. (We also don't use == null comparisons.) I'd prefer void | SerializedBody, or targetBody?: SerializedBody if you want to allow omitting the last argument (that way it still rules out null).. Why is it okay to ignore targetBody starting from here on? Should there be an invariant that if !!delayReason, then it must be that targetBody == null?. I am confused about this variable declaration. Doesn't that compete with another declaration? This deserves a comment (and I'd like to understand it).. This invariant detects if there is a mismatch between...\n- What the visitor things is reachable in the final heap, and\n- What the serializer actually serializes.\nThe serializer should never process values that didn't get visited (because then they didn't get attributed to the right scope), and the visitor should never visit values that don't get serialized (because that indicates that it is visiting \"spurious\" roots, pulling in and processing stuff that doesn't actually matter, but causes the serializer to emit suboptimal code).. Generally, if this invariant fails, it means that there's a mismatch between the visitor and serializer, and that mismatch should be fixed.. The visitor will still visit this value, but here you avoid serializing it.. You didn't teach the visitor to visit this value.. (And various other related new values on desc.). Feel free to embed a comment to this end, as this questions comes up often.. But you are not really making up a new identifier, you just get the identifier assigned to that value anyway. So there should already be a declaration somewhere just like the one you are emitting.. I still don't understand how it can be that we don't have two competing (or redundant) variable declarations here.. Expression normalization would allow cutting potentially error prone code duplications.... Tricky, but seems correct.. Reading through the code in serializeValue, I start to be convinced that this is okay.... Via a boolean flag, could we get an invariant that by the time _serializeAbstractValue returns, the function passed to emitNowOrAfterWaitingForDependencies must have been executed?. specify. Tracked objects must be void or a (subtype of a) Value. After state joins, an AbstractValue may appear (encoding a conditional expression), or possibly other Value kinds due to simplification rules.\nThis is not currently enforced well, and we likely have bugs. I just opened #1124 to track this.\nSo... For you, that means, either...\n- change type of $BailOut to be void | StringValue | AbstractValue.\n- where you consume the $BailOut, it's probably reasonable to just give up on an AbstractValue (since it should never actually arise, as no state joining should be going on in or after the reconciler, I think, not sure).\n(@hermanventer is the expert on this topic.). Is that because Flow-types are turned on when we get here, and even if the user omits it, some Babel transform insert an any type?. Calling Get in this way can execute arbitrary code. Is that okay, or is it established somewhere upstream that all the properties for which Get is called are data properties?. Would new StringValue(realm, uniqueKey) also work?. Why is this invariant true? I think the descriptor can be absent for deleted properties.. This should not be tracked:\n1. Tracking is not needed, as the property is only set once directly after object creation, and is never mutated again, or along different execution paths. Tracking is all about joining modifications of (pre-existing) object properties when such modifications happen along alternatively explored execution paths during symbolic execution.\n2. Tracking is only supported for properties that have type Value, or possible a subtype of Value plus AbstractValue. There's some special support for arrays to support map/set data, but that's a big hack. typeAnnotations are certainly not supported.\n3. Tracking imposes a substantial overhead which is just not needed here.. string is not okay, for a tracked property the full type should be void | StringValue | AbstractValue.. Or, since you don't don't support merging of $BailOut properties anyway...\n\nRevert the type to just void | string, and remove the code that rejects AbstractValue.\nRemove it from the tracked list.\nWhere you set $BailOut message, consider the case where $BailOut has already been set, and then either merge the string messages manually, or produce some other kind of error, or consciously do something else (stick to first message, or always overwrite) with a comment as to what you do and why.. This would catch and cover up all kinds of internal errors, including invariant violations, or SyntaxError/ReferenceError/TypeError in prepack code. Please make this more selective, and rethrow everything else.. See comment above. Let's not just sweep all kinds of internal errors under the carpet here.... And then buildExpressionTemplate turns that into a code snippet unknown? How can that ever be okay?. I'd prefer !== undefined. Why did you remove this invariant?. void | ObjectValue. No need to allow two kinds of undefinedness.. Could you add a comment here that explains what combination of properties may be present? I guess that if joinCondition is present, then none of writable, enumerable, configurable, value, get, set may be present? And descriptor1 and descriptor2 may only be defined if joinCondition is present?\n\nWould be nice if that kind of invariant would actually get enforced somewhere. I am a bit afraid that there's code out there today or tomorrow that ignores joinCondition.. Why adding a comment (\"join point following if\") here? I looks a bit inconsistent.. the => to. in a?. Is removing test-react intentional? If not, keep it!. setFunctions. Maybe add an invariant like invariant(singleton === Path || singleton === undefined), as these functions might get called multiple times, somewhat surprisingly.. Is there really a need for these helper functions setPath, setProperties? They mutate an exported variable, so the caller could just do that directly.. Hm, this shows that the way CSE is currently done in the visitor is risky.\nThere's an invariant that the set (at least at the cardinality level) of \"serialized\" values should be the same as the set of \"visited\" values. I wonder why that didn't fire here, as it seems like there should have been a mismatch?. I don't fully understand the semantics of forceHydrateLazyObjects (I can see how it's all connected, but I don't have a good mental modal for it). Can I consider it a hack in place until we switch to @hermanventer's suggestion?. This is an important TODO that should be addressed before landing.. \"once property access no longer fatal\". Do you have an idea how to handle this? I don't have a clear vision for this problem.. Why is that invariant true? Wouldn't it get violated when I simply pass global as an explicit argument to a abstract function? What's so special about $GlobalObject, what about other built-ins (thingies with an .intrinsicName)?. I think there's a conceptual issue in Prepack around these tracked internal properties (https://github.com/facebook/prepack/issues/1124): The formal type should really be BooleanValue | AbstractValue, as merging diverged control-flow paths where a value became tainted on one side, but not on the other, would result in a conditionally tainted value. Same issue applies to _isPartial if applied later after construction. So, while not a new issue, we shouldn't compound the problem going forward. I think this may add a big new layer of complexity to the implementation and reasoning.... So what is the meaning of impureObjects? Reading through the code... newly created objects within the most enclosing evaluatePure scope which were exposed to abstract function calls?. +1 for \"leaked objects\" terminology. Being returns is not a requirement for \"leaked\".\n\"That is also a bit confusing because there other objects than these passed to the abstract function too.\" Indeed. How about \"createdLeakedObjects\"?. How about hasLeaked to stay with the leaking terminology?. The bindings don't really have to be wired through _addEntry / GeneratorEntry. context is an extra argument passed to buildNode, but yet not consumed here. If you add that parameter you, you can just emit the call to context.serializeBinding(bindingArg) from within this buildNode function, instead of doing it in _addEntry. Also, I suggest to rename serializeBinding to something like getReferentializedBindingNode, as it doesn't actually serialize an actual value.. It's a bit weird that lazyObjectsRuntime is part of RealmOptions. Conceptually, it should really just concern the serializer. I understand that this is currently here to emit a magic comment when generating code (for loops) to enable testing.. Adding an invariant(value instanceof AbstractObjectValue); would be nice.. I wonder if this... is going to be always bound to the right thing in the code generation.. I wonder if this is always going to get bound to the right thing.. Is this expected to ever happen? If not, consider an invariant instead.. Is localeCompare the right choice here? I think it uses the current locale.\nOf course, comparing file names is tricky. On Windows, it's basically impossible to know how exactly what the NTFS case insensitive comparison does. But on case sensitive systems, I'd think the right thing to do is a basic character-by-character comparison. Not sure how to best express this in JavaScript.. Make sense. Except... Introducing this locale-dependency essentially makes Prepack non-deterministic: It may output different files on different machines. I wouldn't promise that Prepack is entirely deterministic otherwise, but we should avoid non-deterministic behavior whenever possible.. I am not convinced that $HasComputedName and $HasEmptyConstructor are set along all paths where an instance of this class is created. Thus, the type should probably be ?: boolean.. Can there be any other reference to the classMethod? If so, then that could cause problems.. We should try to find a test case for that.. it's. In serializeValue, you could log a nice user-facing error if such a classMethod ever gets there.. The Flow-type of $HomeObject doesn't allow for that. It's either undefined, or an ObjectValue. You should assert that here, and simplify the control-flow.. spelling: abtract. This will result in O(n) lookup perf. Use a Set<string> instead.. This function still seems a bit underdeveloped.. Really not a fan of falling back to any just to avoid an import (and more cycles?).... Why is the global scope special?. The arguments a bit weird. Why does pushScope and popScope take a LexicalEnvironment as it's first argument, while destroyScope doesn't? Should it take one, and assert that it's equal to context.lexicalEnvironment?. The order in which defineFunction is called on function is not necessarily the order in which the function declarations will appear in the code. (That's why the outer function is called spliceFunctions...). Instead of reasoning over Babel nodes here, check if any residualBinding.value instanceof FunctionValue. Look at the let flatArgs statement above.. But then you never store it back to b.phiNode?. Not all abstract values have an intrinsic name. Why is this guaranteed?. What's wrong with emitting the condition as part of the while clause? A comment would be nice if there's a reason.. Related, I suspect you were trying hard to avoid using the regular mechanism to turn values into nodes, as this test thingy is something very special and not a regular value. Scary implicit assumptions... I feel like we need to do some more fundamental distinction to avoid chaos down the road.. I feel like we need more test cases for all the new code.... Why do you create cond wrapping around exprValue?. With --inlineExpressions, we create two instances of ResidualHeapSerializer. Before your change, they would create separate name generators, each time starting from 0. After your change, they would the name generators would live on, and the second time around we get larger numbers. Besides resulting in unnecessarily long identifiers, this might also potentially cause some minor other differences in the code generation which would cause the identifier-counting scheme to diverge. So in a nutshell, I don't think you should do this change.. The name used to mean something, but after you change, it doesn't, and yet it's used in debugging output further below.. You do something very special with the valueNameGenerator. Still, my comment applies to all other generators.. I don't see how that's needed. There are no side effects involved here. Is there something concrete that goes wrong when you don't derive?. I can see how you'd like to get a value with an intrinsic name as that's what emitDoWhileStatement assumes, but I don't see a deep reason why we need to give a name to the value.. This seems to be the only remaining place where the value-name-generator is actually referenced? If so, I suggest to encapsulate it entirely in the ResidualHeapValueIdentifiers class, and not expose it via the PreludeGenerator --- it's not necessary to expose it, and by encapsulating it we could prevent later bad uses of it.. Okay. Please leave behind a comment / TODO in the code to this end.. All assignments are emitted in some order. Couldn't the right-hand sides refer to the left-hand sides in some cyclic way, resulting in bad code generation? (I tried playing around for a while, but I couldn't produce a test case that exposes this...). There's a test case now that would expose the issue if someone changes it.... This seems a bit brittle, but should be fine.. Indeed. Babel visitors are crazy expensive.. You mutate rval here. I don't like that. Why is it guaranteed that rval is a fresh temporal abstract value, and is there some implicit invariant that widened abstract values shall never be involved in some kind of CSE?. Is this invariant needed? I would have hoped Flow can figure this out.... Calling Get may execute arbitrary code (a getter), and we haven't established yet that this object is well-behaved. To avoid state mutations or exceptions at this point, wrap the Get into a tryQuery call (accessible from the ResidualHeapVisitor via this.logger.tryQuery). That will prevent such issues.\nAnd note that there's quite an overhead... It's probably beneficial to short-circuit all this somehow.. delete comment?. This will just visit it in the top-level scope. But I guess that's okay in practice, as there is only one react library object, and it should be globally accessible.. What's wrong?. Why?. Not sure what the exact reason for this parentScopeVisitQueue thing is. Instead, could you pull the this.realm.evaluateAndRevertInGlobalEnv( inside of this function, and then run the code you pass to parentScopeVisitQueue at the very end of this function?. Why did you move this?. Invariant shouldn't be needed anymore at all, as Flow type guarantees this.. Invariant shouldn't be needed anymore at all, as Flow type guarantees this.. The comment sounds reasonable. Should the visitGenerator call one line earlier also get the same treatment? If not, why not?. What does \"raw\" mean?. Kept in sync with what exactly?. Confusing, at least the name _isObject is confusing. On one hand, it seems that a simple val instanceof ObjectValue might to the trick. On the other hand, an array and a function value are not objects?. In sync with what exactly?. The giant switch seems unnecessary, as only \"Object\" or not matters.. can't be inlined. _heapGraphRecords. heapGraphRecords. Seems like this entire function should just boil down to s.getName(), or isn't Flow up to it?. The old function names were unique, not any more. Is that okay?. Which generators don't have names? Just wondering if we really need the parallel id-concept that is only surfaced sometimes.. If processAdditionalFunctionValues (indirectly) causes the preludeGenerator to get some new entries, then this is clearly the right thing to do.\nAdding something to prevent any further modifications to the PreludeGenerator after this point would be nice, but can be dome later separately.. What is the isNaN condition about?. Ugh, this will make Prepack noticable slower... I'd like to avoid that for when niceness doesn't matter.. I don't fully understand the reasoning here. It shouldn't matter if a name \"leaks\" or not --- if it's used, then it potentially clashes with any name we might generated and place in any scope.. This is the catch all for all serializer errors. I did create a wiki page.. And yes, the logError thing probably should be refactored at some point. This is a minimal change that fixes error reporting in general (instead of causing an internal invariant).. We should amend our coding conversions if we want to enforce this.. Make it more clear that this is not an option that would help an end-user in any way.. You could add .refuseSerialization = true; to make this thing more obscure.. The false parameter is no longer needed. I removed it in an earlier pull request.. I don't understand the motivation behind the original condition (why excludes passing the func in any argument position from leaking?), or the amended one (should it be !arg.safeFromLeaks? if not, why not?). Also, there are many calls to .leakValue in the code. Why is .safeFromLeaks only respected here?. Because body is an array of elements, and not just an element.. This is not generally the case, and doesn't matter. What you really want at this point is at least one value.. You should undo this later on.. I am impressed that we have a test for this :-). Can you cover all the branches in concretize?. A comment of why this is getting (temporarily) disabled with the existing bug number would be nice.. A comment on the meaning of the reactHint would nice. I am a bit lost.. Indeed, not needed, will remove.. Agreed. I filed an issue #1437 to revisit all uses of logError and harmonize the error handling.. So there used to be a separate Referentializer for each ResidualHeapSerializer instance (they will be two when we run with \"inlineExpressions\"). Could that cause any complications with state that gets shared? Maybe it's okay, but it's hard to tell. Making as many details of the Referentializer private (prefixing with \"_\") would help to tell.\nThe first issue I see is around statistics. Looking at the code, I just realized that many months ago the code got refactored to share a single SerializerStatistics instance --- that doesn't look right.\nEffectively doing referentialization only once instead of twice (with \"inlineExpressions\") would be nice, as it will make things faster.. Throwing a FatalError without logging a CompilerDiagnostics will always result in a bad user experience.. In the end, yes. I used it for something else in an intermediate version, but that didn't turn out to be needed in the end.. Will do.. \"s\" is never undefined, but when walking along the parents, eventually it is. The reason we walk the parents is that some nested generators might already be \"done\", but a less nested one might not be --- and then the declared value would still effectively not be usable from the common ancestor scope.. Oops. Let me work on that.. Right, was meant to be used in invariant that I had commented out.... The point is to have it allocated only once. Otherwise, I'd agree with the readability.... Will rename.. Will do.. Will do.. It's the \"first scope\" element. Will clarify.. Will change.. It's more accurately reflecting reality, as the field itself might be absent after the constructor is done.. All of the \"tracked\" properties should include | AbstractValue in their type, as merging two different states of the flag might result in an AbstractValue. (There's an open issue for that: #1124.)\nIn that sense, the current handling of _isPartial and _isSimple is fragile, but at least so far making objects partial or simple is a meta statement that needs to be explicitly inserted by some framework, but your setting of _isFinal may happen implicitly as part of the regular program execution flow.. [value]. Was there a particular reason to list object twice, maybe for referencing counting reasons? . The approach should be fine, it just needs to handle AbstractValues and bail out when it runs into issues.. Consider renaming the enclosing function to leakOrReportErrorIfNotPure. Consider using or generalizing theGenerator'sgetAsPropertyNameExpression.. sp: supports. maybe call it_templateOf.| AbstractValue--- let's do this new one right.... Note that #882 is already closed --- time to remove the (TODO ...) text?. Avoid: anytype.. Why don't we consider leaking the value?. Looking through the current callsites, it seems to be thattypeIfPureis always correct even if the arguments are non-pure.. A few things I don't like...\n1) a non-? argument following ...? arguments.\n2) I don't like the the default switching to having side effects; I think there was a general design to have all of the create... functions that don't have Temporal in their name being side-effect free.. This seems like a significant semantic issue. Maybe only do this in pure mode?. What's this change about? Doesn't seem related.. Did you really intend to just comment this out?. This config is derived from user code, right? If there's any way the values are not a string/number/boolean, then this should be a user-facing diagnostics thingy and not an invariant.. I don't understand how this new config andserverSideRenderOnlyproperty is being tested?. This invariant fails. It seems to only happen when we start from additional functions that have been announced via --additionalFunctions or via the test runner.. In some cases, not the incomingobject, but some other value is returned. Why is it the right thing to do for previously visited values to return the incoming value?. What is this about? Carryover from debugging?. Remove comment. Actual type seems to beresidualFunctionBinding?: ResidualFunctionBinding;. Is this assignment tothis.residualFunctionBindingmeant to happen only once? Can that be guarded with an invariant?. How can that be? How can there be an attempt to serialize if it wasn't visited? (And visiting seems to guarantee settingthis.residualFunctionBindingto a defined value.. The other function that push single a entry all have the naming schemeemit.... Let's keep it consistent.. The generator name doesn't have to be unique, and there's already a globally unique id created for generators anyone, so I would just skip theadditionalFunctionUIDpart.. What does \"double-counting\" mean here?\nWhat I do understand is that we generally emit modifications to intrinsic objects via generator entries, so there's no need to do anything in addition here (that could be the new comment).. So it's really anewBindingEntry.. So it's really anewDescriptor.. Why keep track of the old value? Doesn't seem to be used.. Then: void | ResidualFunctionBinding, or do you usenull?. Resolved. This was due to the global environment record confusion..addTemporalAlias.addTemporalAlias. Is it okay to call this multiple times? Maybe add precondition thatthis.temporalAlias===undefined.. Because lazyHoistedReactNodes is an array I guess.. What do you mean by \"make these mutable\"?. Already defined byGeneratorEntry.. Not used..effects` not really used.. Let's try to avoid state if we can. I think we had issues in the past when GeneratorEntries were moved across Generators --- we should not do that anymore, but still...\nInstead of maintaining this extra state, could the visit function get the containing generator as an argument?. Cc @avikchaudhuri .. So this is likely a bug? Maybe leave behind a TODO?. I removed the .parent property from FunctionValues a while ago as it wasn't well defined. @trueadm, what's the intention behind the .parent check? Doesn't seem to affect anything.. State invariant that this.temporalAlias === undefined || this.temporalAlias === temporalValue.. The serializer will process the .temporalAlias: this.serializeValue(val.temporalAlias);. However, the .temporalAlias doesn't get visited in the ResidualHeapVisitor. Maybe it does get visited as a side effect of something, but even then, it should get actively visited to get put into the right scope.. Should this be tracked? What happens if snapshots are obtained along different execution paths?. Why is the snapshot added back to the object in such a roundabout way?. (Are there any other cases where we'd want to do a deep getSnapshot traversal?). What exactly is perplexing?. \"Skipping\" it means the repro-command-line that is synthesized is not going to mention that cpuprofile path. My reasoning for not including is that 1) it's really unlikely to affect behavior, and 2) this output path might not be portable across environments.. Will make comments more enlightening.... This seems very wrong, possibly there to hide some other conceptual issue?. This seems wrong in general, as the effects only apply for whatever binding was in place here.. Does this mean that the actual binding is effectively ignored? Surprising.. As a general guideline, I'd like to not introduce additional state in the visitor.. createGeneratorVisitCallbacks.visitGenerator already doing for all nested generators --- nested within the main code, or additional functions.\nI guess the intention of your change is to link up nested additional functions, but also linking additional functions to the main code? This makes strong assumptions on how visitGenerator is called --- I am not sure if they hold. Also, while this might make commonAncestor probing code succeed, it's also likely masking mismatches in expectations in isReferencedOnlyByAdditionalFunction --- this function is used in a few places, and it's all about having a single additional function. If a value is held on to by multiple (nested) additional functions, all those design assumptions get out of whack.... sp of evalaute. sp. Instead of pushing around this additional piece of state (evaluatedFunctions), why is it not possible to leverage the createdObjects in the effects, filtering for FunctionValues?. Can you also undo this change?. Are you planning to use _optimizeFunction in the React code?. That doesn't look right, as it will reset usesArguments to false depending on the order in which it visits.. clever. I will add comment and refactor code after our discussion.. Rename to something like serializeClassProperty ?. Why call serializeNameAndId twice? (See next line.). Why not go through serializeClassPrototypeId?. I know null is creeping in as the norm elsewhere, but I'd prefer if we stick to void for the core of Prepack.. So it doesn't fail anymore?. What about something like the following where the same function is requested to be optimized twice, in two slightly different settings? What do we want it to mean?\njs\n(function() {\n  var x = 23;\n  function f() { return x; }\n  function g() { x = 42; __optimize(f); return f; }\n  function h() { __optimize(f); return f; }\n  __optimize(g);\n  __optimize(h);\n  inspect = function() { return g() + \"-\" + h(); }\n})();. A bit surprising that \"verbose\" produces less output.... What do you mean by that?. The type domain I supply here is ObjectValue, so we are getting an AbstractObjectValue. That should be good enough.. @cblappert: Failing is fine with me to start with.\nAlso, I don't like the idea of somewhat randomly picking one, this will lead to very confusing behavior.\n. Annoying that one has to write so much code for what looks like a common and rather straightforward abstract value transformation... Could that be factored out?. Should we push to the path condition what we now know to be true?. The \"dead code\" comment is obsolete, I assume.. The serializer should take care of cycles, how can this happen?. This comment is no longer necessary.. JSC doesn't support Object.getPrototypeOf, and proto should be used instead. See here: https://github.com/facebook/prepack/blob/5a7c47c41614401eaac71bd2754fd29785df1c68/src/serializer/ResidualHeapSerializer.js#L305 Some general helper function would be appropriate.. This would still serialize [c, x, y], possibly leaving around various artifacts, even if c, x or y are not used in the end.. The realm pathCondition isn't scoped right regarding the serializer. Conditions pushed while processing global could would linger around while the serializer is processing the generators of an optimized functions.. Good point. Will address.. However, the user had to actively supply option --mathRandomSeed, so it's something expected, and this just notifies the user how that option was used.. You shouldn't have to check if key and value are undefined. If this is because of Flow, then write invariant(key !== undefined.. This is queue the check one more time. But that's not sufficient for fixpoint computation. It needs to always rerun this logic.. Even for a set, values might be visited for some other reason later on. So each entry here should be wrapped in withUnrelatedScope calls that keep re-issuing withUnrelatedScope calls when the value hasn't been visited yet.. This outer withUnrelatedScope call should not be needed anymore.. This outer withUnrelatedScope call should not be needed anymore (and if it was needed, it should go after entry !== undefined check).. Let's rename the signature, it's NOT dead.. Indeed, this avoidable quadratic behavior is potentially problematic.\nAt the very minimum, let's leave behind a TODO. \nIn practice, I think it is okay for now, and there are other perf bottleness (cough babel traverse cough).. Converting the expressions to strings for keying should be easy via babel-generator. I think you can do that.. I have another pull request coming up with an \"invariantLevel\" where you can dial up and down how many invariants you want with a numeric value.. All of the properties where I removed void get initialized unconditionally in the constructor to a non-void value.. _isHavoced itself is being set via the constructor. To avoid string concatenation over and over.. Oh, I see. The idea is to have stable hidden classes.. Then that would become a bigger change for some other time.... isHavocedObject must not be called when the object is not initialized. It used to generally allow for being called in an uninitialized state, but the way that was written caused two super expensive binding-property look-ups, that I eliminated by not doing that uninitialized check in isHavocedObject anymore... It has to go somewhere.. The additional invariants brought out the bug with the existing serializer test suite that our cloned JSON values where not right. undefined doesn't get mapped to null. This fixes it to make the test pass. The same code change was already in #1709.. 4 roughly corresponds to the old invariant checking default. More than will ever be needed :-). The error message does not match the wiki: https://github.com/facebook/prepack/wiki/PP1001. This makes the Generator constructor very state-sensitive. I am not sure that the constructor is always invoked in the right state. Did you verify that? How do we ensure that going forward?. It's two. The closure is accessed from the optimized function, and the inspect function. But not more!. It's not, will remove.. Will add comment.. When fixpoint_rerun is pass to _withUnrelatedScope, then the return value is used to determine if there was any progress that should re-start fixpoint computation of visited values.. Will add comments.. Not sure what you mean by \"delaying\". _visitBindingHelper will get called right away by visitBinding through the code you wrote.. Adding comment.. Technically, createElement is also a dependency.. Invariant that !canBeApplied?. I don't understand this. Why this roundabout way via getArgsForDeclaredValue, when I think the answer should be available as value.args? Except that getArgsForDeclaredValue will fail if the value comes from some nested generator.. Is there a mechanism that havocs everything reachable from mapfn?. I don't understand why non-abstract values in the consequent/alternate positions can be ignored. Similarly, in the emitter code a bit later. Is the only allowed non-abstract value the EmptyValue? In that case, should a deletion statement be emitted below? @hermanventer? An an invariant would be appropriate... Also, it should be possible to craft a really small serializer regression test without optimized functions that hits this case.. So this test doesn't reach a fixed point. Looking at the code generated for the different iterations, it looks remarkably similar! Except... The following keeps flip-floping.\njs\nvar _E = _$2 === _$3;\njs\nvar _E = _$3 === _$2;. Not sure exactly how it happens. Does the CSE or simplifier have some such flip-flopping build into the algorithm? @hermanventer?. Is this really true? Either x and y might not be structurally equal to right, but that doesn't have to mean that they are not semantically equal.. The kind of entries that get purged seem quite arbitrary. Can you add some comments that reflect your unhappiness with the situation? By itself, this function looks very authoritative.. I cannot parse the comment. This can invoke arbitrary user code, including a state-mutating getter. Is this intended? Probably not. Maybe express this by checking the compatibility mode?. Maybe a more concrete function, like x.mightBeNaN?. Do you really want to include this change?. This will unlock a whole new set of bugs.. I don't fully understand the intention here, but this looks wrong and dangerous to me. So Havoc changed some bindings, but removing the new entries from realm.modifiedBindings means that these changed bindings won't participate in proper tracking and undoing of effects later on. . what is logstream?. It's optional in the args, but not optional in the GeneratorEntry.. Because it's not assigned in the super constructor. A bit dirty, but results in the least amount of code.... It's not optional in GeneratorEntry.. Factoring out this line into a separate helper function emitThrow would be nice.. Compare with the logic here: https://github.com/facebook/prepack/blob/32d9973c304ec02205683622184a64ba40d809f3/src/serializer/ResidualHeapSerializer.js#L2015\nIt seems brittle to me to check the same thing twice over two different abstract. And it also seems misaligned: The other code only puts a \"use strict\" at the global level when there is no function that is unstrict, while you are looking for some function that is strict?\nThe proper fix should be to centralize this decision making.. Value isn't really needed, is it? So just end here with an invariant that the branch is a Value or a ReturnCompletion.. Not sure what happened here. Is this meant to be the regression test?. In any case, the properties were created before my change, and are still created after my change. If tinkering with the hidden classes here would add more performance benefits, then we can investigate that separately. But I don't want to block this PR on that question.. Will add comment.. If the result is a proper (*) value, or a return completion, then the generator should always end with an explicit ReturnValueEntry, which is terminal.\n(*) You are right, the exception of this is an undefined value (not even a return completion with undefined, for that a return statement is generated). I am inclined to always add a return for a value in _generatorOfEffects, then the terminal invariant should hold, right?\nAnd then the code generator can just omit actually producing return undefined, as there cannot be any other statements following, thanks to the invariants.\nDoes that make sense to you?. Two things:\n1) It sets an alternate body.\n2) It calls .releaseOne() on the semaphone; if the counter reaches zero, the function registered with the semaphore will run and emit the Object.freeze call into the right body.. Now that you also handle abstract values, this realm.createErrorThrowCompletion has potentially become dead code. Can you replace it with an invariant(false); and see if anything break? If not, then please include that change.. But is that a feasible code path? If not, it should be guarded with invariant(false);. If yes, we are back to my original request in the issue: I don't think this should raise a JavaScript-level exception (where would the spec say so?), instead, it should produce a CompilerDiagnostics error and fail with FatalError.. This should probably read !== \"Recover\".. WithIdentifier doesn't really apply here. I propose you introduce a different callback.. Right... So then it shouldn't be a \"RecoverableError\" to begin with, but a \"FatalError\". And then the return value of handleError doesn't matter, and you should always throw.. Done. Right, I forgot about #1910... Yes, please claim PP0037 for #1910, and I can create a wiki page for that as well.. I think the recursing on val.$Prototype in the ObjectValue case should also apply to ArrayValue. Maybe we are missing a test case that redefines an array's prototype?. (and has a widened numeric property). spelling of properties. Spelling of properties. Prefix \"private\" fields with an underscore.. What's the intuition behind the variable name \"na\"?. Either always assign, or change field declaration to priorEffects?: Effects.. It should not just exit the process, but fail the test and participate in regular failure processing.. It really cannot be an AbstractValue?. Array really cannot have holes?. Is it okay to just silently drop elements with getters/setters?. This turns missing and accessor elements into undefined elements. Is that really intended?. Any way to make this text into an invariant?. Is this change really needed? Looks a bit scary to me. I'd rather do less state mutation on the side than more.. > which has some sort of assumption that it won't be re-traversed.\nYes, that's the underlying problem here...\nWhile the introduced assignment makes the invariant violation go away, it changes what happens during the next visiting, which is bad. \nThe right thing to do would be to stop mutating state on the side in these GeneratorEntry's, they should be just values. Instead, build up new data structure in the visitor, a mapping of GeneratorEntry to something --- whatever mutable state there was, and pass that on to the next phase that really needs it, and just throw it away after the ResidualHeapGraphVisitor.. We already know that val instanceof FunctionValue (outer if).\nI don't understand why strictness affects the default value of a function's name.. I don't think desc.writable === true should be added to the conjunction like this.\nAccording to this\nhttps://github.com/facebook/prepack/blob/ea0624b10863f5981c9fb8d5d03e64fa0d798ca1/src/methods/function.js#L738\nThen we cannot ignore the current property descriptor if\nenumerable !== false || writable !== false || configurable !== true, but that should be || to the whole condition, not &&.. Basically, add another statement\njs\nif (desc.enumerable !== false || desc.writable !== false || desc.configurable !== true) return false;. spelling. I'd prefer it if we don't add such special cases to the Emitter. The Emitter is already confusing enough.... If this intends to do what I think it does, then you want to do the following:\n1. Pass the result of this.residualHeapSerializer.isReferencedOnlyByAdditionalFunction(value) (currently evaluated by caller) into this function; let's call it additionalFunction. It should be defined by construction.\n2. Then replace this line with the following:\njs\nthis.residualHeapSerializer._getPrelude(additionalFunction).push(statement);. Why?. You probably don't want to merge this.. That is concerning; maybe hiding something. After landing this, can you file an issue with steps to reproduce?\n(E.g. the old code to plug in, and which test case fails.). I like the idea of having two tests: One that omits invariants and \"does not contain\", and one that doesn't omit invariants and \"does contain\".. Agreed that just disabling it for React is fishy. It would only work by chance then.\nI know that there\u2019s an issue with frozen objects, the ordering with Object.freeze. Is that the problem, and not \u201cfinal\u201d?. spelling of defaultPropsEvauated. With your other change to have format default to the empty string, you don't have to do this manual inlining here. Please remove the changes to the serializer.. Not sure what you mean. This error indicates an internal Prepack error, which is an Invariant Violation.. And if it's not a value, why is it okay to just ignore it?. Not a change request, just a thought: There's a growing set of bail-outs from just regular JavaScript code. It would be good to have some kind of logging or account for when these things happen, maybe combined with some configuration as to what kind of things are allowed. (We don't want to allow bailing out for loops or arbitrary functions in InstantRender, and I guess eventually you don't want that for the React Compiler either.) Also possibly just to give de-optimization hints to users.. If we first visit the scope of the parent and then after a nested function, then this will happy continue (and eventually return the parent).\nIf we first visit the scope of the nested function, and then the parent, then this will return undefined.\nThis non-deterministic behavior is bad.\nThis function used to return the only referencing function, if any. What do you want to happen/allow in the case of nesting?. Right, the scopes would be listed whatever order the visitor discovered them (sets retain insertion order), but there's no guaranteed order here.. Havocing is transitive. So everything reachable gets havoced.. The wrapper references all relevant bindings, which in turn get havoced.. If my interpretation is right, then this function now returns the single root optimized function (even if there are other child optimized functions). So maybe rename function to tryGetOptimizedFunctionRoot.. If not a ConcreteValue or an AbstractValue, what could to be?. These checks could be covered with the existing isPure scheme.. So, this is the essence of this change? Peeking into the args and declaring an Object.assign call to be \"pure\" if the to value \"can be skipped\", which is when the value hasn't been visited yet, i.e. isn't subsequently used?. The || t instanceof EmptyValue should be infeasible given the above isBottom check.. Why would it ever be okay to swallow random errors? What about SyntaxError or RangeError or TypeError? Any error that we don't know if benign for sure is by default a bug.. I don't understand why this function is a a good proxy for why we should inline effects. For example, why is a primitive value like \"true\" not getting inlined?. Right. But your logic would still stay to not inline a conditional abstract value whose leaf values are concrete values, but you would inline an conditional abstract value where the leaf values are some other (obscure?) abstract values.. In the constructor, can you add invariant(s) that ensure that isPure and mutatesOnly are mutually exclusive? Also, an invariant that the values listed in mutatesOnly are a subset of the args.. While the visitor runs multiple times, fishing for additional information, and warranting the \"might\" naming, in the serializer things are clear. So please rename mightBeSkippable to omit.. spelling: evaluatePure. If they are not the same (length / content), then I'd rather emit a logError than fail an invariant.. c and f --- impossible to figure out what's going on unless one studies the code...\nHow about terminationConditionCreator and indexedMutator?. I guess this is the case where we have concrete objects in the value domain, and the second half of visitAbstractValue kicks in.. I guess here the first half of visitAbstractValue, since we don't have an overapproximation of a concrete values domain. As far as I can read, this would also potentially havoc  objects referenced in c. So I think another refinement and test case is needed to avoid and test that.. Pull this definition out, replace call to this.serializeValue(value) in else branch with serializedValue.. This .equals check seems very brittle to me. In the sense that I am not sure if without an SMT solver it will work for much more than the trivial test cases?. There is a mismatch between the letters in the comment, and the letters in the implementation.. The actual implementation only does this for concrete values, while the rule makes a more general statement. A comment would be good if this is intentional or just a practical limitation.. Maybe leave a TODO here that havcoing all args is still overly conservative in general (e.g. for \"conditional\").. let isLeaked = this._isLeaked; // cache property access\ninvariant(isLeaked instanceof BooleanValue); // to make sure that joining always does the right thing\nreturn isLeaked.value;\nAnd something similar for isNotLeakedObject.. Or you could cut isNotLeakedObject altogether, as it's really just !isLeakedObject now.. This checks a static property doing a linear search every time this happens. Do you really want to keep this invariant?. Hm, so in PropertyBinding, the object is defined to be AbstractObjectValue, and thus you need to do the cast here. Okay. But I wonder if that's really the most appropriate type definition.\nFor fun, I removed the | AbstractObjectValue, and ran flow again --- no violation!\nNow, of course that doesn't have to mean much, but I wonder if we can make this new code cleaner by if can simply \"fix\" the type definition, after manually reviewing all assignments?. just bc.value instead of the .equals call. There is no object here, what does this test?. Just returning an object from the inspect function will not cause a deep inspection. You want to create a string which contains .now and .foo.. Make inspect function do a deep inspection.. Same here.. Wait what this used to work and now it doesn't? Or is what's going on that this diagnostics arises internally, but is then put under the carpet because the entire .concat call is made abstract? if so, then this should be reflected in this expected-error assertion.. A big motivation behind Sapan's changes is to make leaking unconditional, so an object either has leaked, or it didn't leak.. Can you make a dedicated test case for this?. This test case is in a directory called \"trivial\". This change makes it very much not trivial. I don't think we should overload existing targeted test cases by sneaking in other complex stuff.. I don't see where this all started, but would AbstractValue | ObjectValue be most appropriate? I don't quite see how e.g. a concrete number would ever have to be brought into life by a generator entry, and I see lots of feature interaction potential with e.g. CSE if we allow non-object concrete values to be declared.. See?. Extremely fragile indeed. Assuming the goal is to get the number of Object.assign calls down, would something like Copies of assign:1 be appropriate?. I don't understand the last sentence.. What you are doing here is somewhat non-deterministic: Whether canOmit returns true or false depends on the order in which the visitor looks at generator entries.\nSimilarly, how often attemptToMergeEquivalentObjectAssigns gets called and does some iterative refinement depends on the order in which the visitor happens to look at things.. What's the actual problem with conditional? getTemporalBuildNodeEntryArgsFromDerivedValue should always return undefined for an abstract value with conditional (or most other) kind.. I think calling $Get this way might run a getter. Not a good idea in the visitor to run code.\nTwo thoughts:\n1) The fact that the Object.assign function is ended in the first argument is a bit silly to begin with. It might cause additional code generation. Don't do that, instead, in the build node, get the Object.assign function via the prelude generator's memoizeReference, which already happens for special handling of abstract value with kind === \"explicit conversion to object\". Btw, that other special abstract value is probably also something you'd want to include in your optimization.\n2. This way of digging for identifying information, and the whole new custom-optimization apparatus, tells me that this might call for a new sub-class of GeneratorEntry, e.g. a ObjectAssignGeneratorEntry.. In my view, all in-place mutations of GeneratorEntry instances are undesirable. Yes, we already have a few such instances, but I'd rather want to make those away than to pile-up more. (The background is that this makes the visitor terribly stateful, and running it twice could yield different results, which is just wrong.) What I'd rather want to do is to maintain some information on the side (possibly managed by the visitor and exposed via the callbacks, but nevertheless separate information).. So an outermost call to attemptToMergeEquivalentObjectAssigns might cause state mutations in some distant generator entries. I really don't like adding this kind of complications to the visitor.\nBackground: Currently, the visitor is doing its fixpoint computation in a very naive way, re-running all possible contributors to value declarations, being ignorant of actual dependencies. This is already a huge performance issue for the React Compiler in some cases. Eventually, I want this to be dependency driven (#2111). But for that to work, we cannot peek into remote dependencies or even rewrite them behind the scenes.. PP0013 is about for loops. There is no for loop in this test. What is going on?. Talking to Chris, it seems to be the case that there's a mismatch between the intention of the test runner and the Prepack cli: The test runner happily declares success for this test case, even though it produces a fatal error, and the Prepack cli will terminate with an error-exit code. Please file an issue for that. And we should address that before marking otherwise passing test cases with producing expected FatalError. . sp of optimizaiton. sp otpimization. I looked at the output, and now I understand... Annoying.. With --debugNames turned on, we are getting one step closer to having repeatedly mentioned \"assign\" in the code. However, another (useless) intermediate variable is declared because the function itself is made an argument to the build node. Don't do that, code gets better, and we can start counting :-). Bad complexity.. How do you know that the object referenced by possibleOtherObjectAssignTo, or one of the objects involved in the earlier argument list, hasn't been mutated by some other generator entries in between?. Seems a bit arbitrary that in this case replaceAndRecordDelayedEntry is called by the optimizationFn, but in the \"POSSIBLE_OPTIMIZATION\" function the recordDelayedEntry call happens here.. true should only be returned when something happened that could cause other entries to get visited, which isn't the case here. So also return false.. Why do any work at all if omit might be true, i.e. it is not clear whether this entire generator entry is going to be needed? I suggest to move the entire optimization down to where recordDeclaration happens.. The the argument rewrite would happen next to the CSE code (with ugly state mutation), and related concepts are closer together.... So you skip possibleOtherObjectAssignTo if it has already been visited.\nHowever, if it hasn't already been visited yet, doesn't mean it won't be visited for other reasons later. It doesn't work this way.. Also, what about the objects that were used to create possibleOtherObjectAssignTo, they could have been mutated in between.. spelling of disjunt. Maybe leave behind a comment that this is basically manual simplification, and the code could be simplified if we would trust the simplifier more.. I am surprised that a PossiblyNormalCompletion can have all of its paths abrupt?. You should be able to check this.constructor !== NormalCompletion. (And same for AbruptCompletion.). This would allow for null. I prefer allowAbstractKeys?: true, or : boolean = false.. Make getting the Logging tracer a helper function in the realm.. Throwing a type error would show up as a Prepack bug. Either issue a FatalError or go through createErrorThrowCompletion.. I'd leave the brackets as part of the unconditional code.. Remove the conditional special case, I don't see how that's needed. If it is needed, let's talk about that.. arg: AbstractValue | ObjectValue. Replacing entries is now problematic, as you now keep around a map from args to entries.\nSo, let's scrap this whole generator entry replacement idea and instead go back to in-place mutation for the moment. Replacing whole generator entries wasn't really what I was after to begin with...\nWhat happens here is that the \"dependencies\" are mutated (and at some point the visitor should take into account such dependencies when iterating for fixpoint). What I'll really need in the future is that all such dependency mutations get tracked somehow. But I am fine to just ignore that for, as long as the mutation is easily discoverable in the visit method.. I maintain that this check if fragile and depends on the visiting order, but concede that it's not a functional problem. Leave behind a comment to this end.. We have to find a better way to test this before the changes can land.. If the arg is an ObjectValue, you must also check if it mightBeHavocedObject, and then you cannot optimize when something that may be an abstract function call happened in between startIndex and endIndex. And this needs a test case. @sebmarkbage knows what this is all about, and @sb98052 is on a quest to refactor all of that, including proper accounting for aliasing.. may have a dependency. Let's hide the index business behind a comparison function on GeneratorEntry, such as happensBefore, which might return undefined when the two entries are unrelated (in the future, the index business could be replaced with a more precise tree path analysis). temporalEntryArgToEntries lives in the Realm, but the derivedIds obscurely lives in the PreludeGenerator (I did that a long time ago). Can we consolidate all that in the realm?. That should never happen. Repro?. Why not ObjectValue?. This will probably trip up the linter once you write some unit tests (and we need some unit tests). To address that, you want to make that \"global.__prop_\".. Is this type weakening really needed?. Is this type weakening really needed?. Yes. This conditional check is still here. This tells me something is wrong somewhere.. Thinking about it, a correct name would be notEqualToAndDoesNotHappenBefore. And similarly for the other function.. Didn't run it, but something like this:\n(function () {\n  function f(o1, o2, g, h) {\n    g(o1, o2);\n    let p = Object.assign({}, o1);\n    h(o2); // can mutate o1 !\n    let q = Object.assign({}, p);\n    return q;\n  }\n  __optimize(f);\n  inspect = function() {\n    return f({}, {}, \n      function(o1, o2) {\n        o2.o1 = o1;\n      },\n      function(o2) {\n        o2.o1.x = 42;\n      }\n    ).x;\n  }\n})();. By its name, it's a bit surprising that this \"just\" updates the args. Just get rid of updateEntryInPlace altogether, and keep doing the update in place for now. . Sure, b becomes a conditional, but it does not become a derived id, and it does not have an intrinsic name. So the !name check should be sufficient.. How about this then?\njs\n(function () {\n  function f(o2, g, h) {\n    let o1 = {};\n    g(o1, o2); // leaks o1\n    let p = Object.assign({}, o1);\n    h(o2); // can mutate o1 !\n    let q = Object.assign({}, p);\n    return q;\n  }\n  __optimize(f);\n  inspect = function() {\n    return f({},\n      function(o1, o2) {\n        o2.o1 = o1;\n      },\n      function(o2) {\n        o2.o1.x = 42;\n      }\n    ).x;\n  }\n})();. And right, in my original example, o1 is an abstract value. In that case, additional aliasing information needs to be tracked. Any thoughts, @sb98052?. Never just throw a FatalError without first issuing a CompilerDiagnostics. Doing so should trigger another invariant.. If this indicates an internal error, stick to an invariant.. Because we only need the type definition for Flow. No need to pull in the actual value.. This should probably be ObjectValue.. This should probably be ObjectValue.. Why doesn't this one get , mutatesOnly: [newState], temporalType: \"OBJECT_ASSIGN\"?. This function call with the Object.assign build node is a lot of copy&paste that appears 5 times in the code. I think this calls for a dedicated AbstractValue.createTemporalObjectAssign function.. Let's talk about the PITFALL warning. You are adding a new kind of TemporalBuildNodeEntry, but there is no purgeEntriesWithGeneratorDepencies. Seems like I added that comment a while ago. I have no idea what this is supposed to mean now. Can you delete the PITFALL warning?. sp: mergin. exists. I think the names are flipped now. This one should be called ....DoesNotHappenBefore, and the other one ...DoesNotHappenAfter.. Not Flow, but possibly runtime.. What does \"deeply cloning\" do to the generators (and generator entries) in it?. Technically, we'd want to materialize the exprValue before throwing it. Cc @sb98052 \nHowever, same applies to the other 2 places where emitThrow is already used. Maybe just leave behind a comment for now.. Why do we need this optional pure disabling feature? Would the tests not work with your changes? Is it just for testing?\nI don't really want to maintain two optimized function modes.. So this config parameter is just dead? Kill it.. This should probably be 1.. It's not functionToOptimize anymore. It's now a functionDescriptor or something like that.. As far as I can tell, this case is dead code now.. I don't think there's a need to keep around the StringValue wrapper. Just store the contained string.. If a malformed string is given by the user, Prepack will crash here.\n\"Preparse\" the string already in __optimize and turn a JSON.parse exception into a user-level error or CompilerDiagnostics. It's okay to parse the string twice.. And later you say that abstract values cannot in fact have void or null type.\nLet's call this ECMAScriptType.. Instead of this mutation afterwards, you should be able to extend to the optionsArgs of createTemporalFromBuildFunction to pass this through right away.. Of course, I see... Oh well. Leave behind a comment?. Can we ensure the design is such that no generators get cloned? If that's not conceivable right now, let's that about it.. This entire file / class should get renamed away from \"havoc\" to \"leaking\". Materialization and havocing are side effects of leaking.. If the result type is undefined or null, there's no point of pushing around shape information, right? Or maybe I didn't understand your question?. This special case for accessor properties here (and the corresponding code in the visitor) only exists because of this comment // TODO: Deal with accessor properties in the materialization code, right? \nIf so, please create an issue, and have comments like TODO #Issue in all the relevant places in the code.. Is this the main place where materialization happens when joining states?\nThis code looks dangerous to me. It would permanently mutate whatever generator was captured in lo, right? Shouldn't rather mutate the current generator? Or is there an invariant that all those generators are identical?\n. @hermanventer ?. cond1 and cond2 are dead?. fn2 and fn3 are just getting executed and could be inlined, or are they needed for the regression test?. Maybe add a comment here in the code that we intentionally ignore the result as we are just trying to produce the error message here.. This looks like some left-over debug stuff. Also the comment below. Please clean up.... I don't know how the double-underscore trend for non-private function function names got started. Please only use single-underscores.. Makes sense. Changed code.. Hm, mutating shared state? Why is that okay?. left over from debugging?. Nice!. If you had to _unwrapAbstract the funcValue above, then you probably also have to unwrap the argModelString here.. should (sp). I now understand why you did what you did. It's okay.. According to its Flow type definition, _isPartial is AbstractValue | BooleanValue, and it's initialized in the constructor.\nThe only reason it could ever be undefined is if the effects corresponding to this object have been undone.. This matches the Prepack-specific meta \"internal slots\" that are tracked but have no (not even conceptual) correspondence in JavaScript: _isPartial, _isHavoced, _isSimple, _isFinal, _simplicityIsTransitive, _temporalAlias.. That is exactly what I wanted here: Make sure there is no Warning. (Because before my change, there was a non-sensical warning mentioning an internal Prepack concept that shouldn't raise a warning.). And I changed the test runner to actually enforce it that way.. This will add generators entries for leaked objects every time applyEffects is called.\nLook for example at withEffectsAppliedInGlobalEnv: It (temporarily) applies effects via applyEffects, only then to undo them (via undoBindings and restoreProperties. This goes together with the mutations of canBeApplied. Generator mutations are not undone --- there's an implicit assumptions that generators become immutable once they get embedded somewhere.\nMaybe semantically not wrong, as it would just keep adding the same assignment statements over and over, but still highly dubious / wasteful.\nIf my interpretation of what goes on is correct, then you should either\n1) materialize elsewhere, i.e. where the actual effect join happens (I'd prefer that as I would then understand what's going on),\n2) or at least put something in place to prevent materializing over and over.. This is the main change, everything follows from this: Make the body of visitModifiedBinding participate in the fixed point computation, and be conditional on whether the binding has been visited for other reasons.. > Doesn't this enqueue fixpoint_rerun to be run after the effects have been reverted?\nYes it does. However, the point of the this.scope argument is to ensure that when it will get re-run, it will be so with the right effects applied.\n\nI'm surprised this doesn't cause any issues.\n\nLike what?. Maybe it exists in JSC? Anyway, sounds like a bug that deserves an issue number and a TODO.... I guess behind some other option(s) that would allow to different levels of fuzzing?. This looks dubious. Add a comment why $(pwd).. --reproOnFatalError. There is no --repro anymore. Lot's of code duplication between \"reproOnFatal\" and \"reproUnconditionally\". Rather have a single \"reproMode\".. This is a breaking change to our public package API. Rather put the new optional argument at the end, also making it optional.. Hm, this message might be easily ignored while leaving behind a corrupt repro zip and terminating with a successful error code. generateDebugRepro should return a Boolean, and overall Prepack should fail when generateDebugRepro fails.. See above.. What are the \"corruption issues\"?. Talking to Sapan, the important thing to consider here is the appendGenerator flag: When true, this applyEffects is in effect destructive.. It would be good to audit all calls to applyEffects to understand the appendGenerator logic, and whether it's safe.. Okay. Did you file a bug report somewhere?. This return; looks wrong. Without it, success would be false, and then we'd process.exit(1);. However, with the return;, the process is likely to return with a positive error code, even in the presence of a fatal error!. The name ResidualBuildNode isn't very meaningful without historical knowledge.\nI suggest something like OperationDescriptor.. Hm, so much random stuff indeed...\nThere must be a better to represent that data (still just as data, leaving the actual Babel build node functionality outside via a switch).\nEither via a base class with subclasses, with a type discriminator field for switching,\nor as a big union of separate record types, again with a type descriminator.\nBut we can do that later as another refactoring.\nEverything should be strictly data (with a unique serialization to a string, while not actually having to be a string).. Without historical knowledge, this sounds weird. How about replacing kind?: ... with hasResult?: boolean?. Can an AbstractValue ever be a Symbol at runtime? I'd think so. But then this still might return PrimitiveValue. Is that okay?. I don't like the idea of having yet another global thing (the lookasideTable in this design) that gets mutated as a side effect of some function.\nIs the goal here to eventually avoid having to apply effects in the serializer at all? That would be a good thing. But then rather just store this information as a map in the generator. Then again, that's what effects are...\nThe way CSE is designed, the visitor would then again have to mutate this global lookasideTable. That's fragile. I'd rather have the visitor produce a brand new table, restricted to only what's actually reachable; it can mutate it locally to do CSE, but it effectively becomes immutable once the visitor is done.. We need a better name. It's very similar to effects, so what distinguishes it from effects? (As a guidance for naming.) Is it an EffectsBuilder? Would be nice to distinguish mutable from immutable data structures.. > What I read from this comment is you would like the visitor to return a table with no set- methods. That seems reasonable and compatible with this approach.\nThat would be nice.\n\nI'm avoiding storing the information in the generator because it's easier for me to debug when everything is in a single table\n\nDoesn't really have to be in the generator. But I really don't think that it should be a global table in the realm that is mutated as a side effect calling a function.\n\nremoves any bindings not visited \nI don't want that the visitor mutates any data structures. It could take one table in, and produce another one. But it should mutate anything given to it. (I know that today it does, but I want to move away from that.). Another option: PartialHeapSnapshotBuilder.. Why does this have two leading underscores? Should be only one.. What happens when I try to optimize the same function twice? Make it a set or map (of function to an optional ArgModel), and/or look for collisions (different argModels).. You no longer have to do the unwrapping at this point. Do it earlier when adding to optimizedFunctions, and make it a map of ECMAScriptSourceFunctionValue to an optional ArgModel.. Why does this test have the word \"conflict\" in its name?\nIs the inner function actually being optimized? I don't see any assertions that optimization actually happens. What is this test testing?. I don't see any assertion that this inner function is actually getting optimized?. rember?. __generateInitialOptimizedFunctionsFromRealm --- it's not really Initial, remove that from the name.. Confusing function name: It starts with get, but it doesn't actually return anything. What does it mutate?. This while loop with shifting... Took me a while to realize that this is now a simple look with no queuing going on, since that's handled by the recursive nature of getEffectsFromAdditionalFunctionAndNestedFunctions? Simplify.. What happens when the same function is being requested to be optimized multiple times and from different nesting levels?. What is \"normal mode\"?. Some comments around mutability would be nice.\n1. I'd assume that an Effects instance is generally meant to be immutable. (With a twist regarding canBeApplied.)\n2. However, this function indicates to me that it's main purposes is to allow for some mutability. Is this meant to be an \"internal\" API? However, it's difficult to tell, as I cannot see any immediate mutation after any call to shallowCloneWithResult.\n\nSimilarly for Completion and its shallowCloneWithoutEffects.. Do you see a away to consolidate these two instances of iterating over properties?\nIf not, it's fine as it is.. @trueadm looks like we have really hard to maintain test case here. . A semantic call is made based on comparing display strings after applying a regex? That seems sketchy. (Also didn't see a test for it.) A safer and easier way out would be to disallow calling __optimize on the same function value twice for now.\nAlso, what if the two function values are different, but both point to the same underlying $ECMAScriptCode?\nNot for this PR, but to revisit in the future: In what initial state should a nested optimized function be evaluated in? The state after the outer optimized function is done (appropriate for event handlers), or in the state right where the __optimize call happened (appropriate for functions passed to .map etc. on arrays), or in a way where the entire environment is made abstract (the default if we don't know better?). Instead of obscure _isPartial check, introduce an isValid() like here: #2278\nIs there a test for this?. Let's keep it simple: If we don't know that it will work, issue an error. Be conservative and correct.. It's calling a function ...Leaked... here. Is anyone checking the invariant that the object is marked as leaked?. And then please rewrite this comment and mention the issue number. As it stands right now, it's an odd comment to have in the code base.. Annoying to have this so many times in our code base. Time to consolidate?. What about FunctionValue? Do you want Value.isTypeCompatibleWith(resultType, ObjectValue) that's already mentioned above?\nIn itself, an object result doesn't mean that the function isn't pure, this is just being conservative. Leave behind a comment that mentions this (future optimization opportunity).. Same as above.. Mention #1233 in comment text re. unmodified global prototypes.. For example, here. Nothing bad seems to happen, but is that guaranteed? https://prepack.io/repl.html#GYVwdgxgLglg9mABMAFASkQbwFCMQJwFMoR8lRJYF0sDjSkAmARkQGpEWBuRAX234A3AIb5krALzJ0XbCLHBGiKajSyA+urgAHWAFsYAL0IpgzNdk079Rk4otA. What still not clear to me: Is this really meant to be a user-facing \"error\", even if recoverable? The message seems to indicate that it is completely safe to just ignore. At best, this would be \"Informational\".. This fancy looking while look with shift is still just a simple iteration, right? Why not write a for(x of ...) loop? Less text to read.. Can we teach the linter that __optimize is okay? @trueadm ?\nOr could define var optimize = global.__optimize ? __optimize : _ => {}; in the global code?. Have some marker indicating that the optimization should really happen with the current effects?. posInfo does not include a pointer to pos which is what we want to mutate.. The definition of RecoverableError that Herman and I arrived at is: \"Prepack might produce code that deviates in behavior from the original code, if the original code is not well behaved.\"\nI think that matches here.. We don't really need this. I think emptyExpression would do just fine.. inspect will always run in node, where global.__optimize doesn't exist. So I think this makes this test useless.. See other test comment.. Maybe return !(\"foo\" in result) || result.foo === __empty. Not sure if the __empty would get rewritten. That case, you add at runtime:var __empty = {empty: true};, and then check if result.foo.empty.. You might find more issues with a higher invariant level (then Prepack emits checks for assumptions it makes about the environment).. Looking at the first descriptor should be strictly more correct than looking none. But to be entirely correct, shouldn't we look at all descriptors and fail if they have different (and significant, i.e. not overriden by Desc)  attributes?. If the loop below would start at env and not env.parent, then you wouldn't need this special case. Or is it important that this check runs before the next check around created objects that can return false? I don't get the full picture of what is being checked here and the significance of ordering.. What's the intuition of why this is checking for whether \"is defined inside pure function\"?. And why exclude destroyed envs?. But if the matching lexical environment has been destroyed, then isDefinedInsidePureFn will return false, then below we would report side effect warnings? I am confused.... Okay, I think I understand. The destroyed-aspect is the key in determining whether this modified binding represents a side effect.\nThis simplified version of the function also passes all the public tests in your PR. Anything wrong with that? If it looks right, can we go with this version?\njs\n    const isDefinedInsidePureFn = root => {\n      let context = this.getRunningContext();\n      let { lexicalEnvironment: env } = context;\n      while (env) {\n        if (env.environmentRecord === root) {\n          // We can look at whether the lexical environment of the binding was destroyed to determine if it was defined outside the current pure running context.\n          return !env.destroyed;\n        }\n        env = env.parent;\n      }\n      return false;\n    };. This I find confusing. A better way would be to have tests that need it and work carry some special annotation like // arrayNestedOptimizedFunctionsEnabled.. And once not on by default in the serializer, can you also add the test from  #2398  as a regression test?. This if statement was already there before your change, but I am not sure it's correct. What if you have an object that gets assigned to in both an optimized function and from a pure scope in global code?. Why would it ever be desirable to keep infeasible paths?. It's hard to tell from the callsite what the , true argument means. Maybe make it named?\nWhy don't you want to keepInfeasiblePaths here?. This comment seems to be missing code.. This (and the next) rule seems wrong, unless I am missing some special JavaScript craziness.. The comment seems wrong, while the implementation may be correct.. I think the comment should be // x && (x && y || x && z) <=> x && (y || z). This still seems wrong to me. !x || x || y should be equivalent to true, not y.. What about materializing the abstractArrayValue?. Why even expose the single-object materialization? Doesn't seem to be needed, and nobody should call that, right?. This return doesn't do anything.. This should be fine (at least the way things are right now), there's simply nothing TODO. Add a comment to this end.. This is not true. There an assumption based on a dynamic analysis that this should not happen, but here we are doing a static traversal where we might indeed find unbound writes.. This thing is expensive. We should globally cache the result.. What if there are any nonLocalReadBindings left at the end? Shouldn't happen in strict mode, but otherwise there might be some global variable access. What does that mean?. Why is it okay to just ignore those abstract value kinds here?. Cannot be. What about arrays and functions which are objects too?. We shouldn't have to add values that have already leaked (and have thus been materialized and all environment interactions go through generator entries).. Have an invariant that abstractArrayValue has already leaked?. We don't generally use getters in our code base.. This seems wrong to me. !x0 || ... || x0 is true, not equivalent to some random value.. Only if isCondition, right?. Thinking about it, the first one is actually only valid if isCondition without reordering: (1 && 2) && 1 vs 1 && 2.. But how does that function-object case work when we don't add function values to the objects to materialize?. This invariant now appears twice in the code.. sp: desriptors. Some more comments on the meaning of descriptor1 or descriptor2 being absent would be enlightening. (Not asking for actual code changes here, just comments describing intention.)\nLooking around at where AbstractJoinedDescriptor is being instantiated it seems that (eventually) at least one of the two descriptors must be defined, and the absent descriptor is somewhat equivalent to PropertyDescriptor where value is EmptyValue.. In a way, the absence of either descriptor indicates that the thing doesn't exists that thus mightHaveBeenDeleted.. Right, name matches onParse, which is called after parsing.... Lots of invariants over this data structure could be enforced somewhere and then assumed here. But that's for another PR... Here, I'll make the entries unique (there should be a parser one day).. There is some asymmetry here, causing equalDescriptors not to be commutative when one value is undefined and the other one isn't. That issue already existed in the original code. I doubt that it's intentional? Maybe it gets rescued by the other invariant that the existance of value and get/set are mutually exclusive. (We could use more such invariants in places.)\nAnyway, for clarity, I'd suggest rewriting this case to\njs\nif ((d1.value === undefined) !== (d2.value === undefined)) return false;. There are a few different severity values:\njs\nexport type Severity = \"FatalError\" | \"RecoverableError\" | \"Warning\" | \"Information\";\n\"Information\" is at least as harmless is warning, so that should also be allowed. . There is really no functional difference between 'success' and 'warning', right? Let's just stick to 'success' then for all non-error results.. How about making these things configurable?. Why this change in an existing test?. The body and everything that the body may depend on. Do you have a better name in mind?. I am not entirely sure, but it's fine for my purposes.... That depends on what one wants. In my scenario, I'll do this replacement before the function in question will be invoked for the first time. (Ideally, I'd just replace the function object itself and be done with it without the need for __replaceFunctionBody; but unfortunately, the function is  stored in a way that I can't update the reference to it.). Why the special handling of infinity/NaN? Reading the spec, FPToSI would result in something undefined otherwise. And why mod 2^32? Is this all to emulate x | 0 in JS?. Let's wrap this in a try-finally.. newPathConditions. pathConditions. @hermanventer says we shouldn't have to clone, is that right?. Maybe not clone, but wrap the realm path conditions in a new path conditions object. In any case, watch this PR: #2538. Since we don't clone anymore, add\njs\ninvariant(realm.pathConditions.isReadOnly());. Scope and ReferentializationScope are different. Why is it a good idea to do this casting here?. Shorter: \njs\nreturn parentOptimizedFunction || \"GLOBAL\";. I really don't like this injection from the distance via state mutation. The challenge is to find a way to refactor the code to pass this information in from the outside...\nAlso, the referentializer is only used by the loop below; not clear whether that should be part of visitRoots to begin with. Move it out.. This is not a good type name:\n1) \"Helper\"?\n2) \"State\": As far as I can tell, it just aggregates three values that are not supposed to be mutated by anyone at this point.. Instead of this pattern where we create helper objects (helper state) all the time to pass it to some static function, create a dedicated class that encapsulates the data and code. Maybe ResidualOptimizedFunctions.. Had to reduce default maximum a bit to ensure that we don't run out of default node.js space before running out of default Prepack stack space.. \"VariantArgs\" here and elsewhere has no descriptive value. . The whole TODO comment around environment ids is still applicable (environmentRecordIdAfterGlobalCode was only ever meant as a hack; do you think it's the right thing to do now?).. This is now like a separate phase. Can you wrap it into something like\njs\nstatistics.referentialization.measure(() =>\nsimilar to statistics.deepTraversal? Shouldn't take much time, but we don't want to ignore it.. This thing is substantial. Put it in its own file, similar to all the other ResidualXXX classes.. I don't understand.. Comparing to what happens below for the concrete case, I don't understand how just using \"length\" once as the key here is supposed to work?. The special \"empty value\" is used as a marker value as part of comparisons. It should never leak through as the actual value of anything that's exposed. For that reason, I don't understand how this can fix anything?\nAlso, the identity if that \"empty value\" matters. Replacing it in some contexts with something else (that isn't even unique), seems highly dubious to me. Why is this correct?. You also need to include objects into mayAliasedObjects which the array may already alias.. So you uncollect it here so that it doesn't get optimized with a captured state.\nBut what if the function gets treated like this for a third time?. Can we get a test case that covers this new functionality?. I am a bit surprised about this check here deeply nested on object. I don't understand why only normal properties of class properties should not be emitted?. Spelling: Dervied => Derived. I would move that check into computeFromObjectPrototype.. This will now silently degrade. Leave behind a TODO: Handle this case instead of giving up.. Spelling: dervied. Maybe add invariant(ObjectValue.isIntrinsicDerivedObject(obj)); to keep the two functions in sync.. Cross check with what happens in resolveInitializedModules to make sure we only eliminate those module factory functions for modules that got unconditionally initialized.. Rename to moduleFactoryFunctionsToRemove.. I don't like strange abbreviations. Let's call it removeModuleFactoryFunctions.. Why this when the ECMAScript spec doesn't say so?. _handleComponentTreeRootFailure expects an Error as its first argument, but e can be anything. I don't understand how can Flow type check. And then _handleComponentTreeRootFailure doesn't seem to be bullet proof in handling random errors in a meaningful way. Anyway, I am suspicious of such catch-all handlers.. Very good.\nreturn undefined; for consistency.\nLeave behind a comment in the code why this is correct:\n// Note: If visiting this value earlier would have yielded a non-undefined value, then visiting would have been effectively stopped at that point, as the first non-undefined value is returned to the top-level. The fact that we got here again for an already visited value implies that we should return undefined.. Can we get a test for this?. ",
    "anilanar": "The community is eager to have shims for DOM, if prepack team invests in documenting what needs to be done, how to do them, and split this into smaller tasks.. I'm currently working on this, fixing native properties (such as Map.prototype.size). I assume promises  are handled by #1306.. Actually, prepack should not (?) replace getOwnPropertyDescriptor call for native accessors because there is no way to access native getter/setter functions without a call to getOwnPropertyDescriptor or to its variants.\nFor the example given above, output could be something like:\n(function () {\n  var _0 = Object.getOwnPropertyDescriptor(Map.prototype, \"size\");\n  d = _0;\n}).call(this);\nAfter making isIntrinsic() return true for Map.prototype#size, current output is as follows which is obviously wrong:\n```\n(function () {\n  var _$0 = this;\nvar $1 = $0.Map;\n  var $2 = $1.prototype;\n  var $3 = $2.size; // Because I've set getter fn's intrinsic name to Map.prototype.size for now.\n  var 4 = $3;\n  var _0 = {\n    get: _4,\n    set: void 0,\n    enumerable: false,\n    configurable: true\n  };\n  d = _0;\n}).call(this);\n`. Setting `intrinsicName` for native accessor functions to the following fixes this bug: Object.getOwnPropertyDescriptor(${this.intrinsicName}, \"${name}\").${accessorType} ` whereaccessorType: \"get\" | \"set\"`.\nThis produces non-optimal code. E.g:\nInput:\n(function() {\n    var desc = Object.getOwnPropertyDescriptor(Object.prototype, '__proto__');\n    global.g = desc.get;\n    global.s = desc.set;\n    global.c = desc.configurable;\n})();\nOutput:\n(function () {\n  var _$0 = Object.getOwnPropertyDescriptor(Object.prototype, \"__proto__\").get;\n  var _$1 = Object.getOwnPropertyDescriptor(Object.prototype, \"__proto__\").set;\n  var _2 = _$0;\n  g = _2;\n  var _1 = _$1;\n  s = _1;\n  c = true;\n})();\nI'm pretty sure there's a better approach but I cannot unearth it.. I was confused about the exact definition of intrinsic. By definition, are native accessor properties intrinsic?. @trueadm If so, wouldn't it be nice if getterFunc.isIntrinsic() returned true? It currently returns false because its intrinsicName is undefined.\nThat's what I partially handled in my commit (I should change the way intrinsicName is generated): https://github.com/anilanar/prepack/commit/bd4f59f71a5c7ce38f7f83499c49de52c69a06a9. I see. \nThanks for your code and input, I'll look into other bugs \ud83d\ude03 . What's the difference between createFromBuildFunction and its temporal variant?. ",
    "mohsen1": "Will something like this work?\nhttps://github.com/mohsen1/prepack-assume-browser-globals/blob/master/index.js\nObviously not every global is a function and I need to fix that. \n. ",
    "deltaidea": "That's a good start, but it probably won't be so easy. For example, this would still fail for nested methods window.history.back() and window.document.createElement().\nAnd then we also need to define types of return values. For example, document.querySelector() returns a DOM Element or undefined. If it's an Element, it also has its own methods and properties, which can also return another Element (e.g. el.parentElement), and so on.\nThis is going to be a lot of work. I'm tempted to look for workarounds and hacks.. @ev1stensberg\nThere're links to the relevant tools and definitions all over the \"How does it work?\" section. I'm not sure what else would help. It's not the job of every library and tool to explain CS concepts in detail.. So what you mean is, rewrite it as a continuous explanation at a high level (\"do this, then this\") and not as a collection of bullet points (\"we're using this, and also this, it should be obvious to you what's between them and how they work together\").. Could you give an example of a tool or concept you'd like the page to expand upon?\nGenuinely trying to help. :)\nI've just re-read the \"How does it work?\" section, and it only mentions Babel:\n\nPrepack operates at the AST level, using Babel to parse and generate JavaScript source code.\n\nAll other tools are implementation details. Even explaining what is AST is not particularly important. The fact that it first parses the code into an abstract model is itself an implementation detail.. The culprit at 541:23 is this: window.navigator.userAgent.toLowerCase()\nPrepack is still in development and doesn't have knowledge about browser objects. It doesn't know what's inside navigator or that it even exists.\nThe only thing I can recommend is subscribe to #24 and wait.. Prepack is still in development and doesn't have knowledge about DOM. It doesn't know what's inside document and therefore doesn't know what to expect from document.createElement(\"div\") which is on line 159 in your file.\nI've tried adding DOM coverage myself using __assumeDataProperty() and __abstract() but no success. The only thing I can recommend is subscribe to #24 and wait.. It's because webpackJsonp literally is not defined in the file. Prepack can't know what to expect from external global variables and if they will even exist at runtime. You must provide their definitions.\nAdd this at the beginning of the file:\nJavaScript\n__assumeDataProperty(global, \"webpackJsonp\", __abstract(\"function\")). Click \"Getting Started\" at the top of the home page or in the header and you'll get to\nprepack.io/getting-started.html where you can find this, and a list of options:\n```JavaScript\nvar Prepack = require(\"prepack\");\nPrepack.prepack(codeString, options) // returns { code: string, map: SourceMap }\nPrepack.prepackFromAst(babelAstNode, code, options) // returns { code: string, map: SourceMap }\nPrepack.prepackFile(filename, options, callback) // callback(error, { code: string, map: SourceMap })\nPrepack.prepackFileSync(filename, options) // returns { code: string, map: SourceMap }\n```. Should probably duplicate the \"Getting Started | Try It Out\" buttons to the bottom of the page or even after each section.. See #542 and #24.. What I mean but that is not implementation details or semantics of DOM. Instead, I mean just the signatures of all relevant methods, types of values, as well as the fact that changing stuff in DOM has implications outside of the JS context.\nJavaScript\nconst foo = getFoo();\nfoo.innerText = \"Hello world\";\nThis code is either useless or not, depending on the implementation of getFoo.\nIt's useless if it's const getFoo = () => ({}) and both lines can be eliminated without changing the outcome (nothing happens).\nThis code might also result in an exception if getFoo is not defined at runtime. Then there's no point in keeping the second line as it is unreachable.\nAnother example is just for (let i = 0; i < 10; i++) { foo; }. Seems unnecessary, so let's remove it, right? Wrong, because you can never be sure that window.foo doesn't have a getter that makes an AJAX request.\nThis is not even an obscure edge case, popular libraries do this. Mocha had been doing this for a long time with its .should interface. A getter would throw an exception depending on other stuff and fail the unit test.\nIf that sounds dumb, then your statement date.innerText = dateim.parsed should also be considered free from side-effects because date.innerText isn't used anywhere else and therefore can be removed.\nThe whole point of Prepack is to analyze source code and pre-execute as much as possible. If it can't make assumptions about types and signatures, it won't optimize anything because each expression might have side effects that are obvious to the user but not to Prepack.\nDOM definitions would allow to compile document.createElement(\"div\").tagName.length to just 3, ideally.\nThis tool is not ready for production. It is still in development. Subscribe to #24 and wait.. Thank you for your interest! \ud83d\udc4d I'm just another user, happy to help. This is an interesting project.. @nifgraup\nIt might be a game where the main logic loop potentially runs forever until the user stops playing.\nOr there might be a loop iterating over third-party data hitting API on each iteration to know if there's more data - could run forever as well.\nOr it might just be a long-running background computation; not everything should finish in 100ms, especially on the server side.. Prepack is still in development and only has definitions for basic objects described in ECMAScript.\nexports is a Node-specific thing which is not specified anywhere in the language spec. Prepack assumes that everything unknown is undefined because reasons, therefore exports.foo is trying to access a property of an undefined global variable.\nI've been trying to come up with a hack until we have CommonJS support, but it seems like there's a bug. I'm typing this into the repl:\nJavaScript\n__assumeDataProperty(global, \"exports\", {})\nexports.foo = 5;\nAnd I'm getting this weird result:\n```JavaScript\n(function () {\n  var _0 = this;\nif (_0.exports !== {\n    foo: 5\n  }) {\n    throw new Error(\"Prepack model invariant violation: \" + _0.exports);\n  }\n}).call(this);\n```\nWhy is it checking if the exports contents match the stuff I'm assigning later in this file? That doesn't seem right.\nIf I use __abstract(\"object\") instead of {} in the __assumeDataProperty() arguments, I get this error:\nThis operation is not yet supported on ::global.exports at foo\n__IntrospectionError\n    at repl:2:15\nWhat are we missing?\nAlso, how do we stop Prepack from wrapping the whole file into an IIFE and translating exports into this.exports?. @leocavalcante\nThat works, but it also outputs way more code than the original module.exports = 'foo'.. See #509.. @jtenner Sure! See Getting Started page.. Related to #565 (merged 4 days ago).\nMake sure you're on the latest 0.2.2-alpha.0 version (pushed 14 hours ago).. Duplicate of #521.. Duplicate of #521.. In repl-worker.js there's an error on line 35:\nUncaught ReferenceError: originalError is not defined\nThis is likely a typo on line 5: var originError = console.error;\nShould be originalError, not originError.. __abstract() isn't powerful enough to recreate browser APIs, nor is it intended to be.\nThe idea is that DOM API will be available as some sort of built-in thing that you don't have to write yourself. See #24.\nI know this doesn't help, but Prepack isn't ready for general use in production.. ",
    "obenjiro": "@deltaidea Can https://github.com/Microsoft/TypeScript/blob/master/lib/lib.dom.d.ts help us in some way? Typescript have quite good type definitions.. @sebmarkbage Tnx a lot. mathRandomSeed helps\nPS: maybe you can help, I have other problem right now (maybe i'm missing something again)\nXMLHttpRequest is not defined. ",
    "cblappert": "The Flow typing of the DOM (https://github.com/facebook/flow/blob/v0.44.1/lib/dom.js) is also of interest for this, as we may want to be able to generate models from Flow typed APIs for React Native. The Flow typing does seem to be a lot shorter and may be less complete. \nI think @sebmarkbage has though the most about the web use case, maybe he had some ideas.. Updated it so that it doesn't remove ES6 tests, it just reports results for them separately. (Also reports results separately for groups in the form [groupname] (es6) es5 e.g. \ntest262/test/built-ins/Array/prototype/splice: (es6:  34/34 100%)  108/110 98%)\nBefore: Passed: 29713/30458 98%\nAfter: Passed es5: 22973/24141 95%  Passed es6: 9809/18494 53%\n. Addressed by #400 #409 #707. I will put up another pr soon to add the script checking for cycles. Want to land this quickly because it touches a lot of files.. Internal test now passes.. If you run npm run test-test262 -- --timeout xxx and look at the failures, you should be able to just pick them out of the output (timeout for CircleCI is 120, at the builds I looked at, 16 failed). Try decreasing the timeout a bit and maybe locally changing printing to expose the list of tests that failed based on timeout.. @sebmarkbage did a rewrite of the APIs before launch and might have an opinion on this. He's been trying to model the structure off of Babel.. Sorry for the late response, the code for this is merged and should be included in the latest npm package.. Try giving the node process more memory. The options I usually run with are node --stack_size=10000 --stack_trace_limit=200 --max_old_space_size=8192. We should probably add this suggestion to the webpage somewhere.. This should be addressed at some point. We should add some detection to make sure unobservable intermediate values of globals aren't serialized out (provided we can guarantee that the intermediate statements have no other side effects).\nImplementation details of issue:\nWhenever we hit a Date.now() or Math.random() call or other environment interaction, we add something to the \"generator\" which conceptually serializes it immediately at that program state.. What you can do for that is create either the abstract value or the actual function conditioned on whether global.__abstract exists. See for-in tests for an example.. Similar issue to #543 where we haven't worked on optimizing the output code much.. Prepack is intended to reduce initialization code by evaluating it. If your initialization code is not intended to terminate, then Prepack will not optimize it and probably shouldn't. Put another way, the situations you describe are not things that you could replace with a statically computed result.\nYou could probably refactor the code such that Prepack doesn't try to optimize that logic by putting it in a callback instead of in the main initialization code. Ideally we would want to add some way in Prepack to deal with that by delaying or abstracting over loops. @hermanventer is working on better Abstract Interpretation for loops.. Prepack does not yet evaluate most functions that are not called on the initialization path (with a special exception for a specific require implementation). We have a plan to do this in the future #558. @NTillmann may have a better idea, but we should have a stable product by the end of the year. It is unclear at this point what exactly it will include, but we would at least want to have complete ES5 conformance and mostly bug-free implementation. At that point we should have a complete model for React Native and the ability to easily drop it in the React Native toolchain, but we're not sure what support we'll have for the web then.. For simple examples with few levels of abstraction, Prepack may generate less efficient or larger code. Prepack provides the biggest advantage when there is a large amount of expensive computation or many layers of abstraction to remove.. Update: misread the screenshot initially, its the example on the about page in Google Chrome. . #799 is a specific case of this.. Could you also make it so that the bar at the top extends all the way to the right while scrolling?\n\n. We would definitely welcome someone to come and fix this bug! If you would like you could also create an empty pull request or comment on the issue with your idea for fixing the problem so that you can get feedback on it before coding up the fix!. Tested this by adding\njavascript\nfunction createViaLiteral(x, y, prev) {\n  var obj = { x: x, y: x, prev: prev, __proto__: f.prototype };\n  return obj;\n}\n results are:\nconstructor call: 630\ncreate via empty constructor: 1775\ncreate via obj literal with __proto__: 19955\ncreate via __proto__: 20924\nNumbers are a bit higher because I'm running on a slower machine.. Solved by #667 . Not sure how the absence of an input sourcemap being an error helps you for piping. Prepack works correctly without an input sourcemap. Maybe make it a console.warn instead? . It would be nice to have the example code pre-recorded in the record dropdown so people can have a few already-done examples to switch through. If you could modify your PR to use the new record UI that would be great!. Since the if doesn't have brackets, its body is implicitly the next statement -- in this case the for loop. We should put curly braces around it so it's clearer.. Feel free to send a PR, I probably wont get around to it for a bit.. Without additional knowledge, Prepack does not necessarily know it is safe to do that relocation. An abstract object represents an arbitrary object which means the properties could have getters/setters that modify the program state arbitrarily. You could use __makeSimple(window) which assumes that all unknown properties are simple data properties, but that only goes one nesting-level deep.. Not sure what you mean by shim in this case. The __abstract or __makeSimple functions are the way you \"tell\" Prepack things about specific objects.\nFor the case you just described, you could add the lines: \njavascript\n// Tells Prepack global has a property leftUserEye that is some object we don't know anything about\nglobal.leftUserEye = __abstract({});\n// Tells Prepack that leftUserEye has just a bunch of data properties (that don't have getters/setters with visible side effects).\n__makeSimple(global.leftUserEye);\nYou have to tell Prepack that these properties exist and won't have visible side effects because otherwise you could contrive a situation where accessing global.leftUserEye could throw or modify arbitrary variables because there is a getter on that property.\nWhat if in the environment, leftUserEye was setup like this.\njavascript\nglobal.leftUserEye = Object.defineProperty(global, 'leftUserEye', \n{ \n  get: function() { global.foo = 5; throw new Error(); } \n}); \nThen it would be incorrect for Prepack to just emit the interactions of global.leftUserEye in the output, because Prepack may then assume the wrong control flow or wrong value for global.foo in the final program.. I made a mistake in one of my previous responses: replace the original __makePartial with __makeSimple (will edit now).\n__makeSimple will allow you to go 1 nesting level deep for properties by telling Prepack that those properties have no getters and setters. If you want to go multiple levels deep, you'll have to explicitly specify the properties that are objects and make them simple. Note that properties of simple objects can't really be operated over because Prepack doesn't know their type (they could be a number, object, function etc). This is also why we cannot easily add an annotation to allow Prepack to access arbitrarily nested properties.\nIf you're trying to use some small enough subset of the DOM, you can try explicitly specifying as little as you need to:\njavascript\nthis.window = __abstract(\n{\n  foo: __abstract({})\n}, \"window\");\n__makeSimple(window);\n__makeSimple(window.foo);\nconsole.log(window.baz);\nconsole.log(window.foo.bar);\n// but you can't to window.baz.xyz. My description was worded poorly. I would like to add a npm run lint command that runs eslint over the js/ directory in the gh-pages branch in the same way that it runs over .js files in the master branch. \nEdit: as per #674 please try to use Prettier here instead of eslint.. Finished by above PR. @sebmarkbage is working on this with #397 . As raised in issue #553 Prepack does not yet evaluate most functions that are not called on the initialization path (with a special exception for a specific require implementation). We have a plan to do this in the future #558. What is this?. Not sure, @dulinriley might have a better answer?. This seems like a perfect way to skip only on circle!. In methods/abstract.js there is a SameValuePartial function that takes two Values and a realm (this.realm in serializer) that will check if two Values are equal. (Not all values will have a .value property and checking if they are === is not sufficient to identify equality in all Value types).\nYou probably want to also check if the SerializedBindings are equal with AreSameSerializedBindings if neither binding has a Value field because it is possible for a SerializedBinding to be modified and not have a .value (although you may need to change that). The two places where SerializedBindings are produced are _serializeGlobalBinding and _serializeDeclarativeEnvironmentRecordBinding if you want to see how they get constructed.\nIf you run into more issues, feel free to ping me and drop by my desk to work through them.. You may want to rebase this on top of #679 as Nikolai changed a lot of the serializer and may have made your job a bit easier.. For your second point, it might be worth it to delay be able to delay not the module table but some unused exports entries to allow speculative initialization to have a lower startup cost.. We agree that the __residual function call syntax is clunky and not ideal. We would like to improve it in the future.\nWe can't disable prepack on arbitrary chunks of code because Prepack works by knowing the whole program and the exact global state. If we pause in the middle of evaluation to skip over some arbitrary code, Prepack doesn't know if it's safe to continue or if that code had some visible side-effects that would make Prepack's output incorrect.. Issue is stale, decreasing cycle count is tracked by a different issue.. Trying it manually, Prepack seems to still work on node v8.1.0, so I'm removing the <8.0.0 restriction in #721. Sorry for the late response, please update the PR to include yarn in all places in the README. . This is a great idea. We should probably also make sure our yarn.lock file is up-to-date.\nWe will probably merge this on Monday as we are currently unable to merge requests to the repo.. I'll look at this later when I'm more awake, but before could you explain to me over messenger/in person what this change is doing and why?. Looks good to me, is there anything you still need to do on this?. Please also change the number of passing test262 tests and make sure that all relevant test262 tests pass (you may have to change filters in test262-runner.js to enable the tests).. In this case we should also change the package.json to replace npm in all the scripts with yarn (e.g. validate, prepublish).. This is definitely an area we would like to improve, so thank you for tackling this! Just a few comments:\nWhile you're reordering things, if you're grouping them in some way, could you comment the groups? Otherwise, alphabetical ordering of properties would be an easily maintainable way to organize properties.. I think the goals specified in this PR are mostly achieved. Additionally, this specific use case is no longer needed, so I'm closing this task.. @NTillmann is this simple enough to land?. If you remove the \"use strict\" emitted at the top of the program output by prepack the first time, prepacking it a second time will succeed. The error is because prepack tries to implicitly define a global in strict mode.\nFor more information, see #454. Looks like it was just something transient in the dashboard, closing.. What about the case where the common ancestor is a generator that gets thrown away by applyEffects? I think this exhibits it (the common ancestor to declare y is the factory function of module 1), that function body should be executed in an evaluateForEffects context that is then applied. Running up the scope chain will find this generator which will not get emitted because its contents were copied into the realm generator and that generator was thrown away. I suspect in this case the declaration for the abstract value y refers to will not be emitted.\njavascript\n// add require boilerplate here\nlet a = global.__abstract ? __abstract(\"boolean\", \"(false)\") : false;\nlet x = global.__abstract ? __abstract(\"number\", \"(42)\") : 42;\ndefine(function(global, require, module, exports) {\n  module.exports = require(1);\n}, 0, null);\ndefine(function(global, require, module, exports) {\n   let y = x * 2;\n   if (a) {\n     global.z = y;\n   } else {\n     global.z = y;\n   }\n  module.exports = global.z;\n}, 1, null);\nrequire(0);\ninspect = function() { return global.z.toString(); }. Make sure to change the internal callsite as well when you import the PR (similar to what happened with the --serialize option).. https://github.com/ExpoSEJS/z3javascript seems to provide an npm package that gives JS bindings for Z3.. Does this result in an improvement to bytecode size as well as source code size?. Pushed some changes to switch to my laptop, don't review for now because I need to do some cleanup. . This should work now for nested functions and all property modifications. It may not work correctly for binding modifications to variables that are then captured by residual functions.\nWill add more test cases to check if everything is working properly.. Completed by #923 . In the future, we probably want a way to model the arguments for optimized functions (e.g. specifying that they'll always be simple objects etc).. Completed by #2215. Issue has been addressed - modified bindings are properly dealt with.. Fairly sure I've completed this.. The point of creating separate captured_scopes() functions for the additional functions is because the initializations inside of the helper functions need to access values that may only be defined within the scope of that additional function (unless we want additional functions to hoist any of that information to the global scope which makes implementation and generalization of the additional functions concept more difficult).\nConcrete example:\njavascript\nadditionalFunction() {\n  let x = 5;\n  global.foo = function() { return x; };\n}\nIf we want code for x to only show up inside of additional functions, then that additional function needs its own __get_scope_binding function because otherwise it wouldn't be able to reference x.. Added more tests, merged master in for another test.\nReferentialization currently is still unsupported on additional functions, as is serialization of effects for modified Bindings. Both of these changes require this refactor and will be done in a subsequent PR. @yinghuitan the point of the PR is to fixup variables captured by residual functions that are also modified by additional functions (even though they may not have been free variables in the additional function):\ne.g.\n```javascript\nlet x = { foo: 5 };\nfunction residual(newval) {\n  x.foo = newval;\n  return x;\n}\nfunction additional() {\n  residual(10);\n}\n```\nIn this case, we need to serialize something like x.foo = 10; for additional (as well as fixing up the reference if x was referentialized.. This was solved by one of my previous pull requests, verified that test case works on master.. @sebmarkbage @hermanventer any ideas?. @trueadm is this feature still needed for the React compiler project or did you come up with a workaround that you're satisfied with?. PR was unlanded. created #1140 to address comments. The PR was reverted, re-work it so that it works for react tests and is cleaner. #1144 is the revert.. I'll put up a fix soon, the issue is that I lump together setting up lazily-initialized captured variables with assignments to update modified bindings for additional functions.. Give me a few minutes to fix the history by rebasing instead of merging. Probably a bug with #1217 not having symmetric add/destroy scopes in one place. I'll fix this sometime soonish.. @sebmarkbage made a yarn prepack-prepack command, although I am not sure it still works and it was pinned to a specific node version.. The logic for creating those __captured__scope references should only kick in when the corresponding ResidualFunctionBinding is modified. Since Component2 is constant, we should be serializing it to a var, so either there is a bug in the Referentializer or something is setting Component2 to be modified.. I think at this point all of those test cases are part of additional-functions/ tests except for a few that deal with mutation we don't intend to support.. Test case works in online repl.. Not sure why this is happening tbh, I would have to debug it. Could be factorify trying to eliminate duplicate functions, could be Additional Functions getting the scope wrong for emitting the onclick.\nI can try to look into it sometime next week.. For style, running yarn prettier && yarn lint should get you most of the way there. \nFor adding a test, we have a bunch of tests in test/serializer/*, you could probably copy one of the Conditional* tests and adapt it for switch statements. You can run them with yarn test-serializer.. I can't seem to make a small repro that exposes the behavior. Self-referencing additional functions worked without this PR, and it is impossible to define cyclical additional functions using the test-runner (cyclical additional function references won't pass the independence check).\nThe issue arose because arguments was in the ModifiedBindings of an additional function which should not happen (because arguments should be removed from ModifiedBindings once we return from the additional function as it is not a modified binding but rather a binding that was created for the function call.. It seems like fixing this to apply abrupt effects only for serializing the throw and apply the normal effects only for serializing the return would require significant changes to additional functions. This is something that should be done to emit more succinct code sometime in the future. . Looks like what's happening is that the initializationStatements of the nested function are not getting emitted to the correct location. Looking into how to fix it now.. So what's happening here is the leak logic is putting into the additional function's generator an emitBindingAssignment for commentsByID when it's accessed from the anonymous function. This makes the additional function think that it is capturing the binding from a parent scope and is causing the initializer to be emitted in the parent scope of the additional function.\nLet me think about this a bit and I'll try to put up a PR later.. Issue already fixed in master. What would you expect to happen here vs what is happening here? I would expect us not to be able to do anything on a fully abstract object, but maybe on a simple/recursively simple object.. #2175 addresses this. > (Also, why is the exception value _4 always created along the main execution path? The if statement should defer to two generators referencing their relevant values so that the code generator can emit them in separate blocks.)\nThis is because I currently don't have a way of serializing the different branch's effects in their respective branches, I'll fix that with my Effects > Generator refactor. Fixed and added as test case in #1602. @NTillmann is this actually needed by Instant Render?. Works on master, closing.. What exactly does optimizing a class mean? Optimizing each of its methods individually?. Resolved by PR #2214 . Yarn and npm reserve \"prepack\" in package.json as a keyword that activates at certain times (specifically when you run yarn pack before it creates the tgz archive). Keeping the prepack command means that the cli will be run every time you run yarn pack.\nEdit: this is also the case for npm pack (and depending on the version npm publish). Looks like the v8-profiler package isn't building correctly on windows (and doesn't have a cached artifact for node 8.10, I wonder if we could conditionally include this dependency or if using a different node version works.. Make sure that when you land this, you add the flag to internal cases. I agree with Herman that if there are multiple levels, there should be some document/comment/help note that gives guidance on what the different levels mean and what should go in each level.\nI wonder if it would be better to have only a few levels of invariant + options to turn on specific checks instead of these indirect verbosity numbers. (e.g. --invariantLevel \"0,undefined,abstract\" or something). I'm pretty sure that will still be too much output for React Compiler. Part of the reason the original logic is so complicated is because they had a lot of cases where optimized functions captured values (and possibly modified them) but those values weren't needed by anything afterwards. The issue there is orthogonal to exceptional code paths.\nSee #1093. My PR shouldn't fix this issue, but we're planning on unifying Completions with Effects as well as unifying PossiblyNormalCompletions with ForkedAbruptCompletions. This should simplify a lot of the join logic regarding abrupt completions and shake out some bugs.\nSomewhere in the process of doing this, we might fix this issue. . I just tried this on master, and if you change the last two lines of inspect to return x; instead of returning Math.random(), the test seems to work fine.. Adding babel-jest worked!\nFor the debugging bullet:\nI seem to be able to run jest in the VSCode debugger now based off this: https://jestjs.io/docs/en/troubleshooting, but I can't filter tests or test-suites there. Adding \"error-handler\" to either runtimeArgs or args doesn't seem to stop jest from running all of the test suites.\nThere's also a filter option that's supposed to let you filter to a specific test programmatically, but I can't seem to get it to work (or find any opensource documentation about it).\n. Updated, and it seems like babel-jest is no longer enough to use import syntax. Keeps failing for me with SyntaxError: Unexpected token import.. Just looked in the debugger, and it seems like we're trying to referentialize str as if it were a binding and not an argument.\nLooks like there weren't any tests before that tried to mutate/leak arguments. I should be able to put up a PR soon.. Actually it's a little worse then I originally thought, it looks like we never visit any bindings local to optimized functions unless they are captured by some nested residual function that is also visited.\nLooks like we probably want to visit bindings that are local to optimized functions but leaked as well, have to think about how that should work a little.. Debugged a bit more, and it seems ilke we do actually do the right thing here in the visitor and for loop code, but the generator containing the dummy function referencing the bindings gets lost on this line where we decide to drop the generator instead of applying it. This seems like another variant of the issue where generators/generator entries go missing that @hermanventer is working on.\nWorking on a fix now, but it'll probably take a few days.. For Failure 2, it seems like the message occurs because we don't know if props is modified by func beause props is passed as the this argument to func. We should probably adjust the conflict-detection logic for nested optimized functions.\nI'll look into the two invariant violations.. Failure 3 is because we don't visit locals of optimized functions, we assume that anything that needs the binding will visit the binding. Leaked bindings need the binding to be visited, but only visit the updated value of the binding and not the binding itself. The easiest way to address this category of issues (because there are a lot of things wrong in this area) would be a fairly large refactor that Nikolai has been wanting to do for a while.. Looked into failure 2, put up #2305 for improving the error message. Looks like the creation of func in fn conflicts with the property access in nested.\nDo we want to stop reporting or stop failing on nested optimized functions that access values created in their parent optimized functions?. Looking into it now.. Fix up for failure 1 here: #2339. Failure 3 fixed by #2344. Closing issue since all 3 cases have been addressed.. Probably what's happening here is that the internal map recording functions to optimize is getting mutated, so we should suppress that warning on mutations to our internal global properties.\nAlso we probably don't need the map recording optimized functions to be a global property because we always unconditionally optimize functions even if the __optimize call is conditional.. @trueadm is refactoring how buildNodes work so that every buildNode will have a different type/kind key. Once he adds that, I can add that to the logging. . I would say that the ResidualHeapVisitor should produce the complete table in the normal visiting phase so that we don't have to deal with applying/reverting effects in the fixpoint computation.\nWe should also be able to throw away all effects this way because fromEffects extracts the parts the visitor/serializer will need to know about.. Unnecessary and outdated now that Herman's changes have landed.. @hermanventer @NTillmann, does any literature around this come to mind?\nDo we have an idea of how frequently we have functions like this called multiple times in React Compiler bundles? Is this intended to replace your current approach of making functions abstract to avoid code bloat?. Copied with some modifications from @NTillmann's comment on #2303:\nTo revisit in the future: In what initial state should a nested optimized function be evaluated in?\n- The state after the outer optimized function is done (appropriate for event handlers), what is currently done\n- or in the state right where the __optimize call happened (appropriate for functions passed to .map etc. on arrays), what this Issue suggests adding\n- or in a way where the entire environment is made abstract (the default if we don't know better?), something for the future for general use of optimized functions. @caiismyname could you re-sign the CLA so that we can land these tests?. put back up as #2409. Is the functionality you want that it isn't an error if an optimized function reads something written by the outer optimized function or it isn't an error if an optimized function reads a binding created (+ initialized, maybe modified) in the outer optimized function?\nAlso is this something you want for optimized functions in general or just the non-callback ones like map and filter?. So far as I can tell, the second repro happens because we don't add leaked bindings to the optimized function's FunctionInstance, so state doesn't get cleaned up properly between passes of the serializer. Oddly enough, fixing that doesn't fix the first repro.\nLooking into the first repro now.. This is awesome, could we add your PR description to the Wiki once this is merged in? I think it's a pretty good overview that should be easily accessible. . In this case, are you thinking of optimizing g as a callback or at the place of the __optimize call like functions nested in map calls? I think in the latter case, it makes sense to do this simplification. In the former case, we would want to distinguish when the function to optimize is declared in that conditional scope or not:\nfunction f(c) {\n    if (c) {\n      var foo = 42;\n      __optimize(g);\n      function g() { return foo; }\n      return g;\n    }\n  }\n  __optimize(f);\n  global.f = f;\nvs\nfunction f(c) {\n    var foo = 42;\n    function g() { return foo; }\n    if (c) {\n      __optimize(g);\n    }\n    return g;\n  }\n  __optimize(f);\n  global.f = f;\nIn this second case, if we're treating g as a callback, we probably don't want to optimize g with the condition c, but I'm not sure how much that case matters in practice. Although, if we're optimizing things in pure mode, we can still optimize g in the context of c safely. \nMaybe we can always optimize with the pathCondition at the time of the __optimize call if the call is pure and only one __optimize call is made to the target function.. Logic has been changed so that issue is no longer relevant, closing.. I think currently leaking is path-insensitive by default, so yes leaking in one path means leaking in all contexts.\nCaptured scope issue doesn't repro in master, closing.. This actually seems related to the bit of code I was confused by in the previous PR: #2383. It looks like what's happening is fn declares a derived ID in some nested generator that isn't in the parent chain of the nested optimized function (even though the body is still active in the emitter). I have to think a bit about how to solve this because all of my quick solutions cause other test cases to fall over.. Right, I didn't read PR #2346 too closely. What we want to do for optimized functions that need to be evaluated at a particular time/environment is to materialize any values that they use before.\nI don't think the change needs to be reverted since it's already guarded by a flag (although we might want to turn that flag off by default if it isn't already).. It seems that the debugger tests are passing on CI and failing internally. I don't really have time to look into it this week before PTO.\n@yinghuitan could you look into it? Maybe you have more context on what David was doing here. . Each of the PRs that fixed these issues came with more simplified repros. I was adding these just in case they test something broader then the repros that came with the PRs.\n@hermanventer if you don't think I should commit these tests, then I can abandon this PR and just close the issues.. closed by #2551. Resolved by #2551 . Resolved by #2551 . If we make the website the source of truth for compiler diagnostics, we should probably either migrate the information from the wiki to the website or figure out if opensource team has a bot that could update the wiki from the repo/website.\nOne possible concern for this is that our website would either have to update whenever we land a change adding a new error (making it out of sync with npm version bumps) or we would not be able to access the website version of the documentation until the next weekly release.. @NTillmann This doesn't change the behavior of Prepack -- it's consistent with how we deal with captured global variables, but I want to make sure that this is the behavior you want for nested functions. \nWith this PR, we would allow:\n(function () {\n    let p = 42;\n    function f() {\n        p += 3;\n        function g() { return p; } // Will optimize to `return 47;`\n        p += 1;\n        __optimize(g);\n        p += 1;\n        return g;\n    }\n    __optimize(f);\n    global.f = f;\n})();\nas well as the example at the top of the page. This could produce incorrect code in the case that p (or obj in the example at the top of the page) is leaked or modified by another residual function (or even if f is called more than once).\nA more conservative assumption would be to say that we emit a Recoverable error if g or p/obj.p is leaked because then our return 47; code could be incorrect. . I ended up fixing it in the PR because Nikolai requested it, the reason it matters now is that parentAdditionalFunction is used in two places:\n1. Generator.fromEffects to determine what ModifiedBindings belong to environments created by this optimized function (or nested functions) so that we can elide these modifications.\n2. In tryGetOutermostOptimizedFunction in ResidualOptimizedFunctions. This is used in the serializer and referentializer to determine what scope to emit things into. Previously in a bunch of places we defaulted to emitting things to global scope if we couldn't find a narrower common scope between the set of scopes associated to a value by the ResidualHeapVisitor. Now we correctly try to emit to an optimized function or global.\nThe only time we would produce incorrect code before was in situations like this: #2430 or #2428 which I guess were pretty rare in react compiler use cases.. Closed by #2551 . Passes on master.. Right, so what's happening here is that when we optimize the function in array.map, we record that we should optimize g, but g doesn't exist when we try to optimize it at the end of global code execution unless we apply the effects from the array.map optimized function.\nWe need to either record that the array.map function is the parent of g and apply it's effects before optimizing g or add a way to optimize g inplace during the call to map #2336 . > Also, to my mind effects track state that is mutable - such as property and binding locations, which AbstractValues are not.\nI think of Effects more as a summary of the function because it also includes the return value and set of objects created. . The other approach I can think of would be to record the changes in the state of the visitor but only apply them once the visitor has finished traversing all nodes. This should avoid any visiting of the created nodes, but I will wait to see if Sebastian has a better way before trying this.. The original code (without the optimization) should have a different result than the code after the optimization. In this case I check the toString of the inspect function to make sure that one of the requires is eliminated. This was the simplest way I could think of to do output checking for when running the original code should produce a different result. . If the single argument isn't a literal, we should be able to inline the require if the value is known, and it should fail if the value is abstract.. I'll add a comment. I'm not sure if we want to dump console output into the generator in all cases, so this allows for deciding between dumping it into an array that gets returned and creating console.log statements in the generator.. I assumed that we wanted the behavior the way it was before, although I could also emit something in the generator.. What is this checking?. This will only contain the proper console output if we haven't needed to merge (because in that case currently consoleOutput gets dumped to the generator and a new one created).. the console.log output is captured by the test harness and compared in this case. The inspect function is intended to be a dummy function in this case.. Why do these happen twice with the same set of bindings and properties?. Please leave this as fib. Please use style of existing if statements -- spaces around parentheses and indentation of blocks.\n. Fix indentation here too. Please flow-type every argument.. Please uppercase constants for clarity.. Adding a comment at the top to illustrate what you're trying to build would be helpful.. Why do you clone pg here? It seems like you build up a new generator that then gets thrown away. That seems fine for exposing statistics, then you can just access it from the serialized object in the test-runner.. re-add the anySerializedBindingModified check here . add else case setting Value. It's not really clear what the requirements on the arguments are from this invariant. It seems that both left and right should be NormalCompletions, but that doesn't seem to be enforced in any way.. Wasn't super obvious to me what this is doing, a comment would be nice.. Maybe make a helper for this since it appears in assignment as well.. I feel like a comment explaining the third argument on one of these functions would be useful, as its not intuitive to me that i/o includes modifications to global state. Or is this the common phrase in the literature?. Why two nested if statements instead of continuing the boolean?. Not sure if Generated is the right name here, maybe SerializedOutput?. It's not clear to me why both the ioAst and nast go into the same array.. Is it possible to make a local function that does the work of creating the effects and ast so that we don't have to copy this code?. This is a bit odd to me, but it seems safe. . Is it necessary to hoist all prototypes? If it's the prototype for an object at non-global scope, does it need to be hoisted?\ne.g.\njavascript\nfunction foo() {\n  var x = {};\n  x.prototype = { bar: 5 };\n}\nor am I misunderstanding the comment?. Update error message + return type now that id can be null?. How does id get initialized in this case?. Possibly for clarity, replace arguments with an object {detectValuesUsedBySingleFunctionValue: boolean, collectValToRefCountOnly: boolean}?. I feel like this will be a common pattern, should it have a helper?. If this is a common pattern, maybe there's a way to factor it out so that you don't have to keep retyping it, but not sure if that's possible while retaining Flow checking.. This typing seems less specific than the old typing, is it possible to leave it templated and have flow enforce that?. Why is this needed as well as the checks in the return statement?. This installs yarn not prepack, npm install -g prepack installs prepack. will remove this instance. We record initialized modules on both paths, this is just the code for the non-delaying path. ill remove this. I haven't figured out an efficient way to calculate this number in the general case because in the case of Date.now if we remove n derivedIds, we remove 2n elements from serializedValues (because Date.now has a dummy StringValue(\"__Date.now()\") argument). In general removing a generator entry removes the need to serialize its arguments which may or may not be needed by something else.. Its the new code that figures out when modules are initialized or not, but it doesn't quite work, I'll uncomment it in the next PR.. String an integer keys seem to be distinct, the keys are strings.. I thought we would too, but I didn't see this happening. I'll look again.. I thought the kind only stored that information for builtins.. The point of this PR is that we should be able skip or reduce the strictness of the invariant generated (because checking === on FunctionValues will always fail as currently written). This is so that we can at least check that a value exists instead of eliding the check entirely.. I can change the names to SKIP_INVARIANT, FULL_INVARIANT, VALUE_DEFINED_INVARIANT to make it more clear from the argument passed.. I assume that all instances of the code for an additional function will map to the FunctionValue specified as an input to Prepack, this is somewhat dubious but I have an invariant for it.. Don't do name fixup if we're serializing an additional function.. This test case currently fails because we don't serialize effects pertaining to existent objects aside from the ones that are needed by the generator from Effects.. It lets us fallback to the specified scope (in our case a FunctionValue) instead of the realm generator. This should be used to tell the serializer to emit these intrinsic modifications/nested functions/prototypes at the function's scope instead of the global scope.. We want the generators being used in the Visitor and the Serializer to be the equal because we pass the generator from the visitor into _getTarget to get the corresponding body to emit into. This seemed like the simplest way to do that.. I'll put these github comments into code when I have a more final version. Here we're also trying to avoid the name rewriting because the body no longer has names that correspond to the original program.. I'll make it into a TODO: error. I can probably support it with a bit of refactoring.. Could you update this comment with the case where we have to wait for a generator to become active?. They do get undone because this call is wrapped in an evaluateForEffects call.. Strictly speaking shouldn't it be safe to not do undo after each function is processed if they're independent, and it shouldn't matter on the last pass. I guess its not expensive enough of an operation to matter that much.. We aren't evaluating functions again, we're taking their effects from writeEffects and applying them in an evaluateForEffects context so that the changes are reversed afterwards. Maybe I should make a helper function in the realm that's more clearly named.. Ok, looks like I don't actually have to change the realm.generator just this.generator. . Not sure, I need to think about that.. is it possible to Flow-type the result?. These parameters seem to be unused?. Uncommenting this line will reveal the issue. The mutation to toCapture isn't serialized.. This is needed because I can now run this function multiple times to see what modules have been initialized at the end of each additional function serialization/execution. Alternatively I could not report those numbers.. binding.object can be an AbstractValue, I added a return type of Effects to evaluateForEffects so flow may not have considered that possibility before.. We shouldn't clone the body of a rewritten function because we might need to add function declarations to that body for functions defined inside of that additional function (see line 258). Additionally we shouldn't be running the closure ref fixup because the additional function's body is post-serialization so the identifiers are all correct (this was the original reason why we cloned the bodies).\nI'll change the wording of the comment.. Here and in the below comment we don't want to serialize things that should've been emitted in the generator. Changes to global or Abstract things are reflected in both modifiedProperties/modifiedBindings and the generator.. I'm following the convention from realm.js where this destructuring is abbreviated everywhere.. Should it still be evaluateForEffects if this function doesn't return Effects?. This is mainly just so that I can count how many modules were initialized by additional functions. If you want I can remove this.. I can't avoid calling applyEffects -- the point is to be able to be able to tag things in Effects that will be serialized for additional functions (they will get applied again in serialization). I also can't apply everything upfront because I need to know what changes belong to what additional function.. This is supposed to mean that the value is either true or undefined because it doesn't make sense to specify it as false when it defaults to false, I guess that's not clear so I can change this to boolean.. Why does this matter?. Why use this syntax? Is it just for the scope?. Why is it realm.intrinsics.true not refinedLeft?. Will be removed in next PR. No visible changes, I probably could've put the tests in a different PR.. Why is the order of the effects important here?. This is to put the overwritten value when an additional function overwrites a binding.. Probably should rename this, it is the additional function that created the FunctionInstance (for when a function declaration was nested in an additional function). Agreed, I think the serializeValue call can be done at the callsite instead of passing the boolean through.. If you want to avoid these any casts you can pull desc.value out into a local variable before the if statement. Flow doesn't track member accesses as well as locals.. serializeValue should always return a BabelNodeExpression . Spelling\nAlso, I would prefer returning args to passing in an array to be mutated as all the callsites seem to pass empty arrays.. Recursing with the same arguments?. Above lines should take care of this.. prefer more specific invariant or cast. Please add a comment on why propsValue can be added to serializedValues here. Could you make this a variable instead of a function that's called once?. variables. I don't understand why this is true in the general case or why it is safe to do this dereference.. Some reason things captured by arrow functions don't seem to typecheck as well as other areas.. I wasn't saying use a function expression. Since the code is only called once, why is it in a function at all? putting lines 123-127 after line 132 and using the shouldInline boolean instead of calling shouldInlineFunction  would be clearer imo.. You should be able to change this to instances.length === 1 && rewrittenAdditionalFunctions.has(instances[0].functionValue) because each additional FunctionValue should correspond to exactly one FunctionInstance and we don't know before spliceFunctions what the full body of an additional function is so I assume they're all different.. The test runner doesn't actually execute tests with a // Copies of comment, it just checks that the code abides by that search. \nRequest Changes: Please add a test case that runs the inspect function (or change the test runner). This setup should be done by the $Call function. The only work that should be necessary is things mirroring Call in src/methods/call.js. Also note that if no second argument was given, _prepackCommand will be undefined.. spawn or spawnSync?. unary + is confusing. Request Changes: Strictly speaking this just means that the buffer has allocated that much storage not necessarily that there are that many characters in the buffer. Please either make a comment or invariant around this if the behavior is intended.. Maybe pose this comment as a TODO. Once we get more commands, a switch statement is probably better.. You could move the sequence num increment and stringify into the packageAndSend to make sure you can't forget to increment the sequence num.. Our prettier seems to run off of directory structure instead of @format annotations, everything matching src/**/*.js or scripts/**/*.js should get formatted.. What would be the cleanest way to reuse those files and keep them in sync between the two repos?. I would prefer to have residualFunctionInitializers return an EmitBody instead of possibly creating multiple EmitBody objects for the same entries array.. Why not consequent and alternate or conditional instead of Other?. Style-wise prefer breaking && checks into multiple invariants (clearer to see which one failed when debugging) and putting comments as invariant messages (2nd arg) if necessary. In this case the comment seems redundant with the invariant.. ObjectTypes[key] can be ObjectTypes | string according to type definition, why will it be aValue here?. Prefer \njavascript\nlet objTypes = objectTypes;\ninvariant(objTypes);\nor something similar to any cast if possible. (Flow is bad at tracking nullability through captures and usually only refines local variables.). If its a user error (Prepack is functioning correctly but the user input is unsupported) prefer throwing CompilerDiagnostic to an invariant failure. This way you can define a new error type and add a wiki page and we can link to that when the error is surfaced on the cli or repl. We use invariant failures to mean something internally has gone wrong in Prepack and there's a bug in Prepack that should be fixed.\nSee https://github.com/facebook/prepack/blob/master/src/serializer/modules.js#L147-L154 for an example.. I don't quite understand what the BranchStatus bits are about.. Maybe we could also append the original error + message to the bail-out message.. Careful of using console.error in testing. We don't want to let error logs escape on tests that succeed.. You can probably use an Array here if you're always mapping int => value, they work efficiently with holes as long as you don't access the holes.. What is expensive actually used for?. prefer separate invariants to conjunctions. Prefer changing the visitor to understand classes to explicitly adding to serializedValues. (make a new visitValueClass method that visitValue or visitValueFunction calls to when it detects a class that decides not to visit the arguments, length, name etc).. @NTillmann, do you think there's a better way to do this/can you think of any problems with not going through serializeValue?. Could you put a comment that describes when things should and shouldn't be hoisted.. This seems like it could be factored out into a helper function.. What does hoisting a function into its parent scope mean? Isn't a function already declared in its parent scope?. whats this for?. this.scope.parent won't always be the main scope, try making some tests with nested scopes that you want to hoist out of. You may want to use commonScope (or maybe commonScope.parent. Prefer more specific cast if possible.. Might put a comment here about how we can't leak the exception so that we don't accidentally re-add it.. Hmm, maybe that's because you're accessing things specific to React elements and there should be a ReactElementValue type in the future that is a subtype of object or something.. It's possible but I'm not sure if its worth it. You might have to do a bit of refactoring there (if you want to create an initialization function for each lazily initialized Object instead of one function with a switch statement). Additionally, the Referentializer is a little more general than you need here (assumes that object identity and mutability are a concern) so you would probably also have to add another case in the code it generates. \nI think the idea of keeping all of that logic in a separate file from the serializer might help for maintainability though.\nAlso, if you marked all the scopes that a value is reachable from, _getTargets should be able to identify the common scope of all of the places its used and give you the proper scope to emit the hoisted function + variable.. It doesn't restore to this. onDestroyScope no longer restores anything. The if is necessary because in exceptional cases, the lexicalEnvironment is the environment that threw I believe.. I could, I just thought it might be a little cleaner to not have a giant anonymous function.. Could you add an invariant that lh is the right type?. I am surprised that this fixes the bug, as _visitAdditionalFunction's FunctionValue comes from visitValueFunction which is only called from visitValue which should ensure that a Function is only visited once. If visitAdditionalFunction is being called multiple times it is likely that other functions are also being visited multiple times.\nThat may be because there are new classes that inherit from ResidualHeapVisitor and have different mark functions which are run in addition to the normal visitor. Try setting options.heapGraphFormat to undefined to disable these extra visitors.. I feel like it's probably not processAdditionalFunctionValues that adds to the generator, its probably this chunk of the visitor . Why any?. Is it important to be able to evaluate things with leak logic after interpretation is over? Otherwise you could just set ignoreLeakLogic true before visiting + serialization.. Prefer some sort of CompilerDiagnostic here to an invariant because this is a user-callable function. . This could possibly also be a compiler diagnostic if this invariant is being used to validate user input to __registerReactComponentRoot. Maybe put a comment here that its safe to do this because we leak all of these objects.. It does cause some complications which are taken care of in cleanInstance in the Referentializer invoked at the end of serialization.. The last argument is sent to the function that prints the string in the throw call, the rest are passed to the condition. \nI suppose it would also make sense to refactor emitInvariant to pass the same arguments to both the condition and throw statement, but that should be a different PR.. Can't seem to get the debugger working properly on either VSCode or Nuclide (Nuclide hangs, VSCode refuses to understand sourcemaps). Is there anything special you did aside from adding --runInBand to jest?. How do you mock out react properly when running from cli?. Move the invariant on line 900 up and this won't be necessary.. I think so, also I believe Nikolai made that change.. I wonder if this could be expressed similarly to reportWriteConflicts in functions.js. That function instruments all property reads/writes to report when two additional functions modify the same properties. I forget if it also does something for bindings as well.. Can you type f more specifically than function (args + return type)?. Try realm.withEffectsApplied (you may have to rebase). I added that for debugging because I had issues with not having effects applied. I can remove it.. I can change the comment to say that AbruptCompletions mean the function unconditionally terminates in an exception in which case we will issue a compiler diagnostic and FatalError earlier on.. That isn't a valid type in Flow. I will make an invariant for that then because these entries cannot be moved to another generator as they require respective effects to be applied which will only happen while serializing that particular generator.. A serialized value can in general be a BabelNodeExpression (e.g. an object literal), but since the value has been referentialized, it must be an LVal.. The reason I did unbound instead of modified bindings originally is because there were some issues with modified bindings including more than they should, but the two should be equivalent now because it looks like some PRs have fixed those issues.. Please add a comment that this might have different behavior than getting generator.effects[2] and that the oldValue in the Set returned should be agnostic to whether or not the generator's effects are applied.. We don't do a fixpoint when evaluating registered functions to optimize, we just take whatever was regestered at the end of global code and evaluate that.. I feel like this validation error could be made into a function. Are all of the normal effects already applied or just the generator (specifically thinking of modified bindings/properties/created objects)?. That's a good question, I think in general if we're doing nested additional functions, then we probably don't want to serialize multiple copies of the same additional function. \nWe should also be able to deal with that case properly by figuring out we have to treat x as an abstract number instead of a concrete one, but this also becomes a question about what we want the behavior of additional functions capturing variables to be.. How about for now if the same function is __optimized twice, I just throw a FatalError saying it's not supported yet.. Well in general, we currently optimize everything in the global scope, so we don't do anything smart there. To support most nested optimized functions, we have to evaluate it in the context that it is defined or the context of one of the callsites. I think the easiest thing to do here would be to evaluate them with the effects of the first __optimize call we encounter. . I think the React Compiler probably needs that as most of these checks will be if (val === null) throw ...;. Is there a task for this? We usually try to put task numbers next to TODOs in the code. The serializer hits an invariant otherwise because in the case:\njavascript\nfunction additional() {\n   return [additional];\n}\nThe emitter emits an empty array and waits for additional to be done before emitting the assignment to the array by which point it is in the wrong body.. Could we get a comment explaining why this is necessary?. Please put a comment here about why you're delaying initializing the value of the residualFunctionBinding until here. I suspect it has to do with making sure effects are applied, but it would be nice to document that somewhere.. Please add a comment why in the global case we visit immediately but in this case, we deliay initializing the residual function binding.. This should never be null. Nor should pp or po. The way this is written, if target and source overwrite the same value, we use the value from source not target, please document this.. Please document here at a high level what you intend to happen in cases where the nested effects modify overlapping sets of properties/bindings with different values.. You may want to change this to sourceFiles as well.. canSkip is probably misnamed, canSkip=false means you definitely can't skip the value, but canSkip=true means you may be able to skip the value (it also means that you may not yet have visited the Value or referencedDeclaredValue).\nI think a better name would be mightBeSkippable. Are they equivalent wrt performance or does the spread create an extra intermediate array?. I changed the errors emitted by optimized functions, so I have to update the test cases for test-error-handler. It's not related, it's just a test case from a recently closed issue, same as below. I can remove them and put them in a separate PR if necessary.. It's nice that this now works, when I tried using getNormalCompletion in place of value in the past, I found they differed in a few cases.. Why not just put this in the __optimizedFunctions entry? (Make value be { value: FunctionValue, config: ObjectValue} instead of just the FunctionValue). That way it goes through the whole apply/revert effects logic same as the optimized function entries.. I would add a comment here that in pure functions, we assume that any throw not surrounded by a try block within that pure scope is assumed to be uncaught and exit the entire program (or possibly add a flag for that aside from the pure flag?). . I'm a little suspicious that this is the only place that needs to be changed, so I would mildly prefer having a new property on ThrowCompletions that gets checked in containsCompletion so that if we run into another case where we need to check it, it's obvious what went wrong when looking in the debugger.. Ah, I misread something. I guess what I'm asking for then is an invariant in serialization or visiting somewhere that ensures that we only ever serialize these ThrowCompletions via the emitThrow generator entry and not by recursively visiting some PossiblyNormalCompletion or ForkedAbruptCompletion. Alternatively, you might be able to put the invariant in join to make sure we never join a createdInPureScope completion.. I'm not sure why all of these checks are necessary -- what are you trying to filter out vs leave in here?. I'm not sure it makes sense to a test writer that if they write // expected <Severity>: without any error codes that it gets silently ignored.\nCould we make it an invariant or user-facing error if the list of expected error codes is empty?. Would it make sense to put this into AbstractObjectValue as a mightNotBeCallable method instead of throwing, or is this the only place where it's relevant?. Are we at the point where we can enforce that a generator is only ever directly held by one Effects now?. I don't see anything that ensures that _isPartial is only true when effects are applied/undone. I thought this was an annotation used in our models/used for snapshotting.. Doesn't this enqueue fixpoint_rerun to be run after the effects have been reverted? I'm surprised this doesn't cause any issues.. What I read from this comment is you would like the visitor to return a table with no set- methods. That seems reasonable and compatible with this approach. \nI'm avoiding storing the information in the generator because it's easier for me to debug when everything is in a single table, but in the last PR once the serializer bit is done, I could move the information into the generators.. I guess this is like a builder that can take projections of multiple Effects and provide an immutable view of them to the Serializer. It's not quite an Effects builder because you can't apply the effects, and it encodes many possible program states. \nFinalEffectsViewBuilder? Not sure what name best represents its functionality.. I could also change this in a later PR so that at the end of the visitor, it incorporates the information about visited bindings/properties and removes any bindings not visited at the very end of the visitor.. What do we want to happen here?\nI assume we either want to assume or verify that calling the function from all the nesting levels are the same.\nAlternatively, we could just throw an error.. You probably want to do some sort of input validation here to make sure that the string parses and won't throw an unhandled error later. You can probably just grab the logic from __optimize. . I was not aware of this, can we document this somewhere in the code or the wiki for pure evaluation mode?. Do we also make the assumption in pure mode that we don't have properties on the abstract value with the same name as global prototype properties?. I forget, when can we get two function values pointing to the same underlying ECMAScriptCode? Is that when we have two functions that incidentally have the same source, or something to do with bind or some other case?. I don't think I can come up with a stable unit test case for this because iirc the only time that we throw away effects is when we end a speculative execution with an InfeasiblePathError which is dependent on the simplifier.. I think this might be too general for a testMatch, maybe **/scripts/*.test.js, or move that script to somewhere under the test/ directory.. Prefer it to test, they're aliases, but everything else uses it iirc.. Usually what we do is have a setupXTest file and a X-test.js file, where the setup file contains everything you've put into your .test file, and returns a runTest function that is parameterized by filename + args, then the .test file contains a list of it(<name>, () => runTest(<args>) calls.\nSee https://github.com/facebook/prepack/blob/master/test/react/setupReactTests.js, https://github.com/facebook/prepack/blob/master/test/react/ReactDOM-test.js . Won't this only be true if we're inside an optimized function? Also not sure if _enqueueWithUnrelatedScope does something reasonable when passed undefined.. So looking back at why I added those bits of code, they're only an issue for optimized functions (it prevents a case where something is only reachable from an optimized function and we didn't end up visiting it). We should be fine if it has to do with global/residual code.\nI guess what I was trying to say is that I'm surprised that we use visitBindingAssignment outside of optimized function cases (I wasn't aware of evaluatePureFunction) and that it wasn't designed for that, and that I wasn't sure that it would do the right thing.. This is where the actual bugfix is. The rest of the PR is refactoring to make tryGetOutermostOptimizedFunction availabe to this file.. why unknown_array_method_call shouldn't we change this to unknown_object_method_call or something?. I wonder if we also want to call realm.callReportObjectGetOwnProperties here?\nOr maybe move the call from here: https://github.com/facebook/prepack/blob/47cb48b438e46d8c353e98618033fef7d9dca560/src/methods/properties.js#L2004 to here https://github.com/facebook/prepack/blob/47cb48b438e46d8c353e98618033fef7d9dca560/src/methods/own.js#L40\n@NTillmann thoughts?. nevermind, misread this part. Do we also want to check for hitting parents of pureScopeEnv?\njavascript\nlet outermost;\nfunction foo() {\n  let inner1;\n  return [() => inner1, () => inner1++];\n}\n(function() {\n  let outer;\n  let [getter, incrementer] = foo();\n  function toOptimize(func) {\n    func();\n  }\n}();\n// where toOptimize(incrementer) is called\nDoes this work for something like this were pureScopeEnv ends up being the env containing outer, but there's a modification to inner1 whose parent is outermost which is a parent of outer? Or is this not an issue because calling a function passed as an argument is not pure by default?. Looking at this pattern, I think it might be a cleaner API to pass in the FunctionValue and have evaluatePure do the functionValue.$Environment dereference.. The function isn't quite finding out if a binding was mutated, it's supposed to determine whether a ModifiedBinding mutates nonlocal state, so maybe isMutationOutsideFunction or mutatesNonLocalState. Conceptually the original approach was: if the binding was created by an environment created by an optimized function (or any of its nested functions), then don't emit this.\nThe new approach is: if the binding was created in a parent scope of the optimized function, emit it.\nThese are equivalent iff it's impossible to have a modified binding that is neither \n1. created by a parent scope of the optimized function \n2. created by an environment nested within an optimized function\nWhich I'm not convinced is true (although it may be for pure functions). \nLooks like this is a test case that fails:\n```javascript\nlet outermost;\n  function foo() {\n    let inner1 = 0;\n    return [() => inner1, () => inner1++];\n  }\n  (function() {\n    let outer;\n    let [getter, incrementer] = foo();\n    function toOptimize() {\n      let inner2;\n      incrementer();\n      return getter();\n    }\n    global.bar = toOptimize;\n    global.getter = getter;\n    global.__optimize && global.__optimize(toOptimize);\n  })();\nglobal.inspect = function() {\n    let x = global.getter();\n    let y = global.bar();\n    let z = global.getter();\n    return x + \" \" + y + \" \" + z;\n  }\n```\nHere the environment nesting/chain is:\nglobal => outermost => inner1\nglobal => outermost => outer => inner2\nOptimized Function's environment is inner2, but inner1 isn't a parent of inner2, but mutations to its bindings are observable and need to be serialized.. This is a significantly less useful location than before. Before, we gave the location where the impure modification occurred, now we give the location for the creation of the object that was modified. That information isn't really useful for fixing the impure code.\nCan we somehow do the reporting based off createdObjects as we evaluate the function? You may have to expose a different aggregated createdObjects to do this. Or can we store the location of the modification in the ModifiedBinding then strip it off after the reporting is done? . Doesn't bindingEntry.value === undefined just mean that some other set of effects isn't applied that needs to be? When is it valid for bindingEntry to be undefined now that leaking has its own indicator?. I wonder if we should make a more efficient way to do this, like modifying envRecord.$VarNames to be a Set or making some internal cache that turns it into a set.. same as above but a Map instead of a Set. Not \"F or its parents\" \"F's parents\", we return false if binding was mutated in F's scope above.. Could you explain more why this is true?. @NTillmann did we ever resolve whether or not a function's CreatedObjects is a superset of the CreatedObjects of any of its nested optimized functions?. Why is \"EXCPETION_THROWN\" no longer possible?. Huh, I can see that being the case, but we should probably drop a TODO issue there to add a way to distinguish those cases because it seems like there's a good chance of a bug being created from that somewhere.. I guess it's fine to land this without a story for location because it only really affects React Compiler stuff, but this will make it very difficult to debug any impurity issues.. ",
    "sebmarkbage": "I think it is interesting to narrow down which cases cause side-effects and which might read from a JS provided object that needs to preserve ordering.\nFor many other things we might get away with making it fully abstract for most use cases.. This is an example of where it is important to know something about the DOM implementation itself rather than just the structure of it:\njs\nlet obj = {x: false};\ndocument.body.addEventListener('foo', function (e) {\n  if (obj.x) {\n    console.log('foo');\n  } else {\n    console.log('bar');\n  }\n}, false);\ndocument.body.dispatchEvent(new Event('foo'));\nobj.x = true;\ndocument.body.dispatchEvent(new Event('foo'));\nPrepack will have to know that there is an intermediate state of obj.x that needs to be represented here.\nI don't know how common it is to have any such scenarios of synchronous events but there might be other similar cases that are synchronous that we'll have to know about.\nUsing the JSDOM library can tell us a lot more about these implementations than Flow/TypeScript types can.. Here are some more examples of patterns that Prepack has trouble encoding right now.\n```js\nlet options = {};\noptions.passive = false;\ndocument.body.addEventListener('click', function() {}, options); \noptions.passive = true;\nwindow.addEventListener('click', function() {}, options);\noptions = {};\noptions.prototype = Object.create(HTMLElement.prototype);\ndocument.registerElement('x-foo', options);\noptions.prototype = Object.create(HTMLElement.prototype);\ndocument.registerElement('x-bar', options);\n```\nNote how the options object is read by native code and at different times during initialization.. cc @kittens Does this look correct to you?\n. Actually it gets wrapped in a function.\njs\n(function () {\n  var x = undefined;\n  var x = 1;\n  var x = 2;\n}).call(this);\nSo I guess it actually turns into a noop which is also not correct.. Even with bytecode generation this is incorrect because of the wrapper though. A top level var declaration (outside a \"module\" environment) is the same (kind of) as setting a property on the global object.. @hermanventer The bootstrap function will get its input from process.argv. Not yet implemented here. That's an array of the arguments passed on the command-line to the node executable.\nThe first argument is normally the JavaScript module that is going to be executed.\nI was thinking that will be set up as a constant string value equal to the file about to be Prepacked. This will cause the Node environment to load that module file into memory via a call to the fs binding. That becomes the input source code.\nThe abstract input is the rest of the argv array, which lets the user pass arguments to their Prepacked node.js CLI.\nSince the Node.js uses dynamic module source code loading as the program executes, it needs this different mechanism to be compatible with the ecosystem. Unlike browser/react native where bundles are created by statically analyzing dependency graphs.. Seeing what bootstrap_node does might be helpful: https://github.com/nodejs/node/blob/master/lib/internal/bootstrap_node.js#L146. @hermanventer That is correct. I still need to implement contextify and fs module. The next follow ups on the contextify stuff will demonstrate that. The contextify built-in will execute further scripts in the Prepack Realm when the bootstrap function calls it.. I added a unit test that is only enabled in CI for now (not yarn test) since it's locked to particular node version. This is now only blocked on #598 to be in a landable state (although far from complete).. I added an additional test case that tests the path where ArrayBuffer #598 is needed. CI should now fail until that's fixed.. After rebasing on top of the ArrayBuffer fix I think that this should now be in a landable state. After land, I'll follow up with Issues for a few ideas for future improvements.. @jdalton I think it'll be expected that many things won't work out of the box until the ecosystem shifts towards supporting \"heap snapshot\". E.g. Any hanging open socket at the end won't work 100%. We'll have to keep chasing the minimal set needed. Ideally Prepack can help minimize the things that can and can't be.\nI'll take a look at why zlib doesn't work. Keep em coming. :). This is not quite done yet. E.g. the example const { x } = { x: 5 }; from the PR doesn't actually work right now.\nhttps://github.com/facebook/prepack/blob/8b5f40bcad73a3359b6388f784487d2c85f867ba/src/evaluators/VariableDeclaration.js#L39\nhttps://github.com/facebook/prepack/blob/8b5f40bcad73a3359b6388f784487d2c85f867ba/src/partial-evaluators/AssignmentExpression.js#L101. Do we need a compatibility mode that works with what would be the default in React Native in open source (which I believe is different than this)?. cc @kittens . Additionally, I believe treating intrinsics as a string that just gets injected as an expression is a bit fragile. I used to model these as paths where there was a back pointer to the previous intrinsic operation that yielded the new value. Such as member expressions, calls or the global object.. I thought of a name for this API: __poison(concreteValue).. I think there are two different use cases for primitives to be tainted like this.\n1) To avoid accidentally serialize temporary values such as file handles or user data. Those things probably could get some help from taint tracking.\n2) To avoid accidentally over serializing bloated code that is meant to be folded away. In this scenario, you explicitly want to derive a new value out of the original, but the original shouldn't be reachable once you've done that. For example, you can preevaluate a template string to generate code, but once you've done that you don't need the original template string anymore.\n. Ok, this isn't repro of the same exact issue. Instead of the function being assigned to this is reading the not-yet-bound function. Seems related.\n```js\n(function() {\nfunction wrap(obj) {\n    function A() {\n      return obj.hello();\n    }\n    function B() {\n      return obj.world();\n    }\n    A.B = B;\n    return A;\n  }\nlet fooObj = {};\n  let barObj = {};\n  let fooFn = wrap(fooObj);\n  let barFn = wrap(barObj);\n// Create a cycle\n  fooObj.bar = barFn;\n  barObj.foo = fooFn;\nglobal.foo = fooFn;\n})();\n->js\n(function () {\n  function _6(obj) {\n    return obj.hello();\n  }\nfunction _7(obj) {\n    return obj.world();\n  }\nvar _3 = {\n    foo: _0\n  };\nvar _2 = _6.bind(null, _3);\nvar _4 = _7.bind(null, _3);\n_2.B = _4;\n  var _1 = {\n    bar: _2\n  };\nvar _0 = _6.bind(null, _1);\nvar _5 = _7.bind(null, _1);\n_0.B = _5;\n  foo = _0;\n}).call(this);\n```. Here's one that sort of repros the original issue:\n```js\n(function() {\nfunction wrap(obj) {\n    function A() {\n      return obj.hello();\n    }\n    function B() {\n      return obj.world();\n    }\n    A.B = B;\n    return A;\n  }\nlet fooObj = {};\n  let fooFn = wrap(fooObj);\n  let barFn = wrap(fooObj);\n  fooObj.bar = barFn;\nglobal.foo = fooFn;\n})();\n->js\n(function () {\n  function _5() {\n    return _1.hello();\n  }\nfunction _6() {\n    return _1.world();\n  }\n_2.B = _3;\n  var _1 = {\n    bar: _2\n  };\nvar _0 = _5.bind(null);\nvar _4 = _6.bind(null);\n_0.B = _4;\nvar _2 = _5.bind(null);\nvar _3 = _6.bind(null);\nfoo = _0;\n}).call(this);\n``\n. Allowingmodule.exportsandexports` to be assigned to in this context would be good too. We just need to define some intrinsics for that.. Another case is:\njs\nfunction Foo() {}\nObject.setPrototypeOf(Foo.prototype, Uint8Array.prototype);\nWhere the prototype is intrinsic.. Oh because I pushed the same commit I guess it shows as passed here too. Cool.. This is a branch but it had a legit CI failure after I rebased. Running again.. Ok, instead of using invariant I am now throwing a custom error when serialization fails due to the heap reaching an aborted state.\nI considered just throwing on the first error we encounter. However, in many event loop driven scenarios and module initialization scenarios (such as in the node-cli option) it should actually be fine to throw at certain top levels. E.g. a module can be expected to throw during initialization which would be logged without aborting initialization.\nTherefore I think it is better that logging is exposed as a separate API.\nHowever, its still valuable to throw an error in the API when this happens so that any following compiler logic aborts by default. It also makes the type signature of the API nicer.\nIn cases (like CLI) where we want to ignore this error by default, we just do an instanceof check.. I also switched internalDebug off by default and added it as a flag. It's really noisy by default as an external adopter of the API.. Yea it came up in conversation. I was using it to explain something. Figured we could add it to docs or the website but then I couldn't figure out where to put it. So I guess this is more of an issue of where to put these if need many. But also which are the most canonical. . Similarly I'd like to automatically model Node.js in the same way without actually including all the code from the model but rather treat them as \"native\" or preexisting.. I think direct eval is a slightly different issue.\nThis occurs with indirect eval and foo = Function('return _0;'); too. These are much more common than direct eval and don't suffer from the same problems.. In terms of fool proofing closures with direct eval. I think they require a deopt mode that is slower than the other cases so we wouldn't want to do that for all evals.\nThey'd need to preserve scopes perfectly while not sharing scopes with the general initialization code and not occupying space in each others' scopes. They also need to retain values that otherwise would be considered dead references.\njs\n(function() {\n  var foo = {};\n  bar = {\n    a(code) {\n      return eval(code + 'a');\n    },\n    b(code) {\n      return eval(code + 'b');\n    },\n    c: (function() {\n      var foo = {};\n      return function(code) {\n        return eval(code + 'c');\n      }\n    })()\n  };\n})();\nOne way to encode that is by passing factory functions to the initializer scope. Functions with shared scopes get grouped into their own factory so that the same name can be reused twice.\n```js\n(function (_a, _b) {\n  var _1 = {};\n  var _2 = {};\nvar [_3, _4] = _a(_1);\n  var _5 = _b(_2);\nbar = {\n    a: _3,\n    b: _4,\n    c: _5\n  };\n}).call(\n  this,\n  function(foo) {\n    return [\n      function(code) {\n        return eval(code + 'a');\n      },\n      function(code) {\n        return eval(code + 'b');\n      }\n    ];\n  },\n  function(foo) {\n    return function(code) {\n      return eval(code + 'c');\n    };\n  }\n);\n```\nI did actually do something like this in Prepack 1 because I wanted to lazily parse functions so I didn't create these factories until that closure had to be revived.. If you make bar a local variable in the original code, it gets more complicated because now all three have to share an outer closure so you need to create nested factory functions.. Interesting. The node environment that I have been building out shims for is 7! So it won't work with 6 atm. :). I can confirm that I'm hitting this bug with v7.9.0.\n\n. The only place I can repro it is in tests though. It seems like a bug in contextify (the \"vm\" module used by the test runner).\njs\nvar vm = require('vm');\nlet script = new vm.Script(`\n  var global = this; var self = this;\n  Object.defineProperty(global, \"p\", {\n    configurable: true,\n    enumerable: true,\n    get: function () { throw new Error(\"42\"); }\n  });\n`, { cachedDataProduced: false });\nscript.runInNewContext({});\nIf that's the only case I think we should expand the allowed engine range so that people can use the npm package outside of contributing to the project itself (i.e. running tests). While we try to fix the test.. So what happens is that contextify tries to copy all the properties over and one of them throws which messes up the native side. I think this is covered by the bug https://github.com/nodejs/node/issues/6283\nhttps://github.com/nodejs/node/blob/v7.10.0/src/node_contextify.cc#L96-L117. I have been getting some additional timeouts in Test262 on this version. Let me know if we'll need to bump any timeout values.. The reason we might not want this is if we want to explicit limit ourselves to Node.js compatible syntax so that we can avoid compiling at all in the future. But we could probably just change the few places where that wouldn't work if that happens.. That's because let doesn't create a property on the global object (unlike var). Therefore, that code is completely dead code and eliminated. The resulting file is empty.. We could maybe add a nicer message explaining this when we get an empty file.. I think the above proposal sounds good. Given that most people will want source maps I don't know how practical it is to just pipe but it does makes it easier to get started.\nFor large files I think we should just print them to stdout too. It's a little scary that it silently writes a file now.\nWhere should warnings go? Like the warning that a source map wasn't found? stderr I guess.. That's an interesting idea to bootstrap the ecosystem. It might at least be useful to determine if everything that is expected matches up with the configuration.. Prepack exposes the same APIs as Babel.\nThe \"node\" module exports everything from the \"standalone\" module.\nhttps://github.com/facebook/prepack/blob/master/src/prepack-node.js#L20\nThis exposes a way to pass it code (or ast): https://github.com/facebook/prepack/blob/master/src/prepack-standalone.js#L31\nThe options object takes a filename.. That looks like it is use Math.random. You will need to provide the option mathRandomSeed to let Prepack know that it is ok to encode random values into the output.\nhttps://github.com/facebook/prepack/blob/master/src/options.js#L20. That's because the full DOM API isn't modeled yet. You'll have to manually stub out all the DOM APIs that you rely on. Prepack doesn't know about those things automatically yet. Follow https://github.com/facebook/prepack/issues/24 to see when that's implemented.. Good call. I'll rename to Getting Started.\n.code won't conflict because the existing ones use a different class name.. \n. Renamed to code-block for now.. This is because Prepack doesn't know about the environment variables like document.offsetParent. It thinks it is undefined. See the section on \"Environment Matters\". https://prepack.io/\nPrepack doesn't yet support a full DOM environment. You need to manually stub it out for now.. Duplicate of #509. Do you think it is worth while building a test runner for the CLI script alone? We already have one for the API. I'd like to leave that discussion for later.. This might be enough coverage for now: https://github.com/facebook/prepack/pull/563. Ah. Using the CLI to generate a source map as described here: https://prepack.io/getting-started.html\nprepack script.js --out script-processed.js --srcmapOut script-processed.map\nYields the string [Object object] in script-processed.map. We had the wrong Flow type information from Babel.\nTherefore using it as an input failed.\nprepack script-processed.js --srcmapIn script-processed.map. Fixed in referenced PR.. #536 only concerns the output in the CLI. This is the input in the API.\n@huanz Could you add the same option to the prepack-node APIs so that if you specify it there it doesn't get ignored? You can conditionally use inputSourceMapFilename or inputSourceMap in that case.. We don't have constant folding of the ast at the end yet. I'd recommend running this through a minifier afterwards that does basic constant folding. Prepack is complimentary to such tools.. What is a \"wrapped property getter\"? Maybe I can fix it.. This passes CI now. It seems to pass more ES6 tests than before?. This case doesn't need a Range domain necessarily. It is already a ValuesDomain of only two values. If it grows it might cause too many branches but for my particular use case it wouldn't.\nSo I just need to run the conditional over each value.\nThe thing that I don't fully understand yet is how things join.\nIf I add a third call then overflow should become abstract but in my case of two calls, it should be able to join and remain concrete.. It doesn't become abstract right now with one call because it never hits the line overflow = true. If the second call's condition c > 2 is concrete, then it wouldn't hit the line overflow = true neither.\nSo what do you mean that it becomes abstract right away?. Oh you mean it the check branch becomes abstract and then it joins because overflow only has one possible value? So from outside the branch it is still concrete.. Interesting. I did try that in the bigger example and it didn't work but it must have been something else then. Will try to create another example.. If I add a return value to the branches I get an invariant violation.\njs\n(function(){\nlet c = 0;\nlet overflow = false;\nfunction check() {\n  return global.__abstract ? __abstract('boolean', 'true') : true;\n}\nfunction call() {\n  if (check()) {\n    c = c + 1;\n    if (c > 2) {\n      overflow = true;\n      return 3;\n    }\n  }\n  return 4;\n}\na = call();\nb = call();\ninspect = function() {\n  return overflow;\n};\n})();\n```\nInvariant Violation\n    at invariant (lib/invariant.js:19:15)\n    at Realm.get_captured_effects (lib/realm.js:374:31)\n    at OrdinaryCallEvaluateBody (lib/methods/call.js:349:19)\n    at InternalCall (lib/methods/function.js:974:49)\n    at $Call (lib/methods/function.js:906:10)\n    at FunctionValue.FunctionAllocate.F.$Call (lib/methods/function.js:1198:12)\n    at Call (lib/methods/call.js:456:12)\n    at EvaluateDirectCall (lib/methods/call.js:416:16)\n    at exports.default (lib/evaluators/CallExpression.js:75:41)\n    at LexicalEnvironment.evaluateAbstract (lib/environment.js:1232:16)\n```\n. Thanks! Working around these two issues seems sufficient to fix my use case.. Ah. Interesting. I fixed the assignment case here: https://github.com/facebook/prepack/pull/564 but not the access.. ~~I'll merge this with the hasOwnProperty bug. Feel free to address my comments in a follow up if you want.~~\nThanks for your help!\nEDIT: This fails CI because of lint. We'll have to fix that first.. @hermanventer The problem is that if I add that to any existing codebase, it won't get stripped out and the bytes gets shipped on the network and parsed/compiled/evaluated at init time. For libraries that hunt individual bytes to strip out for optimal download, that's a big deal.. It can if you explicitly opt in to those particular properties being undefined otherwise it can't assume that it is because it could be a new browser feature. The state of the art doesn't assume anything about what it doesn't know about. The problem is making everyone reconfigure their toolchains to add our names to that list.\nBtw, we're also claiming all our names on the global namespace forever because if people ship with this detection in browsers, then if browsers want to add this name later for some other use case, then they can't because the detection code would pass and they would break the existing web.\nSee __defineGetter__ and __proto__ for examples with similar names that have been added.. Prepack wouldn't see normal Object.freeze calls because React has already filtered them out by the time you see them based on process.env.NODE_ENV. It might work with something like:\njs\nif (__PREPACK__ || process.env.NODE_ENV !== 'production') {\n  Object.freeze(obj);\n}\nBut then anyone using Prepack would get it serialized by default and might be slower than without using Prepack by default. Not good.. Hm. Yea. I think that would probably be ideal. There might be reasons to do it somewhere in the code.\nIt could just be parallel meta data to configurable, writable and [[PreventExtensions]].. Can you add a test for cyclical frozen objects?\njs\n  let x = {}, y = {x};\n  x.y = y;\n  Object.freeze(x);\n  Object.freeze(y);. Or use let instead of var since that doesn't set a global property.. A related bug is that float arrays are not able to faithfully represent the precision of their underlying bits which is observable:\njs\nlet a = new Uint32Array(12);\nlet b = new Float32Array(a.buffer);\na[0] = 4294418165; // b[0] is NaN but a very specific NaN\ninspect = function() {\n  let newA = new Uint32Array(b.buffer);\n  return newA[0];\n}. This seems like a bug in Babel to me. Maybe it is intentional for perf but maybe it's something we can upstream?. @NTillmann, what's left of #22? I haven't found anything lacking there anymore.. Test case:\njs\nlet ArrayIteratorPrototype = [][Symbol.iterator]().__proto__;\ninspect = function() {\n  return ArrayIteratorPrototype;\n};\nReal-world use case:\nhttps://github.com/nodejs/node/blob/master/lib/internal/url.js#L48-L51. We might want to clarify what \"visible\" side effects are. Since in this case it clearly will have some side-effect.. I think \"visible\" means more specifically that something else in the program after this residual will read from those things.\nIt is fine to mutate objects on the JavaScript heap, e.g. if this residual function is last in the program.\nThis example is not quite last in the program, and it will mutate the JS heap, but not the fields that are read immediately after this: https://github.com/facebook/prepack/blob/master/src/prepack-cli.js#L155. The implementation in #397 is only covering entire node CLI environments (whole program). Not a single npm package that is supposed to be used by someone else. That's a slightly different problem space.\nDo you want all your transitive dependencies embedded inside of your output file or do you want them to remain as require() calls?. I think that this is more of a case of lack of constant folding. The constant c is false and so the inner functions don't get eliminated.\nPrepack currently doesn't do constant folding since that's a task that most minifiers will do for you. We recommend that you use a minifier after Prepacking which will take care of that.. @wdhorton Have you made any progress? Is there something blocking you?. It's probably better to work off the https://tc39.github.io/ecma262/ spec which is living spec so you get all the recent considerations. There shouldn't be any additional stuff in there yet anyway.. @wdhorton The TypeError you're seeing in the repl does seems like it's a TypeError thrown inside the Node environment that Prepack is running in. It's not a TypeError inside of Prepack itself. I.e. it's due to a bug in the Prepack repl trying to deal with the error handling.\nSo it would indicate to me that something is throwing a string.\n~~I would expect this line to be the one to trigger an error. https://github.com/facebook/prepack/blob/4b106e3974967c16304e8ff7e46f9e57c2e25289/src/methods/call.js#L361~~\n~~Maybe isCallable returns true?~~\n~~https://github.com/facebook/prepack/blob/1eacf0cbe4a2d5a47ea619766a6d09df4c39fddf/src/methods/is.js#L99~~\n~~I believe the constructor shouldn't have a [[Call]] slot defined.~~. ^ Never mind, I'm wrong. It seems like this check should fire:\nhttps://tc39.github.io/ecma262/#sec-ecmascript-function-objects-call-thisargument-argumentslist\nhttps://github.com/facebook/prepack/blob/57cc59c07d164e4827c24637af9c1002b0c4a3c8/src/methods/function.js#L597. I believe that line is wrong in master. It should do:\njs\nthrow realm.createErrorThrowCompletion(realm.intrinsics.TypeError, \"not callable\");. Yea, I think it might be worth while getting super supported in the interpreter first because that'll set up you well for the next challenging part.\nThe next challenging part will be to implement the serialization of classes back into JS. This will need to preserve things like super. Even if the method has been copied over between different objects and such.. I don't actually know the best strategy but there are a few interesting things that I can think of. I'd start by considering class constructors and methods separately, where methods on classes is just a special case of where methods can go.\nWhen should something get serialized as a class syntax?\nI think the only thing that determines this is the constructor function. If its FunctionKind is \"classConstructor\" but otherwise simple, then it should be a class.\njs\nlet x = class {\n  constructor() { }\n};\nLikewise if it has super() in it, it must be defined as a class constructor with extends.\njs\nlet y = ...;\nlet x = class extends y {\n  constructor() { super(); }\n};\nNote that it is perfectly fine for y to be a different prototype property and [[Prototype]] than when it was first created.\n```js\nclass A { }\nclass B { }\nclass C extends A {\n}\nObject.setPrototypeOf(C, B);\n```\nThis can't get serialized as:\njs\nlet C = class extends B { };\nThis will need to get serialized as a class and then mutation.\nIn terms of serializing the methods and properties of the class, the most primitive solution is using the defineProperty (there are helpers in the serializer for this already).\njs\nclass Foo {\n  bar() {}\n}\njs\nlet bar = function() { };\nlet Foo = class { };\nObject.defineProperty(Foo.prototype, 'bar', {\n  value: bar,\n  enumerable: false,\n  configurable: true,\n  writable: true,\n});\nThis covers all the cases where a property might have been mutated and configured after initialization. It doesn't work for methods with super.method() calls in them though.\nHow to serialize \"methods\"?\nAny function with a super.method() or super[method]() syntax in them will have a [[HomeObject]]. This is the object that was first used to initialize the method. To be able faithfully restore such a method it needs to be serialized on to the object it was originally created on. This may be tricky because that may not always be the case anymore.\nImagine this scenario:\njs\nlet foo = {\n  bar() {\n    super.bar();\n  }\n};\nlet baz = {\n  bar: foo.bar\n};\ndelete foo.bar;\ninspect = function() {\n  return baz;\n};\nYou can't just serialize this as:\njs\nlet baz = {\n  bar() {\n    super.bar();\n  }\n};\ninspect = function() {\n  return baz;\n};\nBecause the [[HomeObject]] of baz.bar would now be the wrong object. So the super call would look in the wrong prototype chain. The foo object is still reachable through the [[HomeObject]]. So it needs to get serialized:\njs\nlet foo = {\n  bar() {\n    super.bar();\n  }\n};\n...\nHowever, now the value of bar is wrong. In fact the property is even deleted, so you have to add some code that deletes it... but only after you've already stored it somewhere.\njs\nlet bar = foo.bar;\ndelete foo.bar;\nNo you can initialize baz:\njs\nlet baz = {\n  bar: bar\n};\nThe same thing goes for classes but it is extra tricky because a class creates two objects that can have methods on them.\n```js\nclass Foo {\n  bar() {\n    super.bar();\n  }\n  static baz() {\n    super.baz();\n  }\n}\nlet foo = {\n  bar: Foo.prototype.bar,\n  baz: Foo.baz,\n};\ndelete Foo.prototype.bar;\ndelete Foo.baz;\ninspect = function() {\n  return foo;\n};\n```\nCycles might be tricky. Since the heap created by Prepack running initialization can yield cycles that are not expressable in a declarative way, you might have to do some trickery to preserve cycles. I can't think of a scenario where this is more tricky than the normal problems Prepack has to deal with.\n@NTillmann Can probably point you in the right direction in the Prepack serializer code.. If the global object has a setter on it, it needs to be invoked twice.\nThere is currently no way to use __makeSimple on the global object. Otherwise that would be a way to \"promise\" that the global object doesn't have any setters.. Note that this is also related to https://github.com/facebook/prepack/issues/584. We want libraries to be able to successfully strip their code out when Prepack is not in use.. @r24y That sounds related to \"poisoned\" values. #444 However, I'm not sure Prepack is suitable for that general use case since it doesn't track any residual code branches outside the optimized path (currently just initialization).. \u2705. Wouldn't you typically want to use both together?\nI don't see the global state serialization mode as the only output for the existing partial evaluator. E.g. I've been talking to @NTillmann about that I'd like to use it to optimize sub-programs like residual React components. These have mostly self-contained local state with some abstract inputs. We can bail out of components if that's not the case. But I'd expect the partial evaluator strategy to be able to do more with regard to optimizing these trees than the constant folding would. In this mode, we're run the existing partial evaluator not just on the global state but on various entry points of sub-programs inside the program.\nI don't see the user specifying whether they want A or B. It's more like it should do both by default and then maybe we allow you to turn off specific optimizations?\nHow about these options, which can be combined in any combination? (The last one is just an example of something we can add later.)\njs\nconstantFolding: boolean = true,\nexecuteInitCode: boolean = true,\nspeculativelyExecuteReactComponents: boolean = false,. It's fine to have the mode but I guess I don't see that mode alone as that interesting as a product though because other compilers, like Closure Compiler, already does a decent job in that space - including its limitations.\nIt's more interesting as a new product when combined with other features that Closure isn't currently modeling.\nI suppose it would be interesting to combine the constant folding with partial evaluation of sub-programs (like the React component optimization) even without executing the global scope though.. Is there a guarantee that calls execute in order? Is it safe to have side effects that doesn't affect the serialized heap? E.g. console.log(...);. FB (www) actually does mutate Object.prototype in some cases to patch up an old faulty Safari (JavaScriptCore) implementation of hasOwnProperty. There might need some way to define that as safe.. I don't think all options should necessarily be required to have a CLI equivalent. E.g. callbacks for piecemeal error handling wouldn't be. Another could be passing AST forms or in-memory representation of source maps. The point of a programmatic API in the same language is that it can share richer data structures than the CLI. However, everything that can be translated should have an equivalent as much as possible.. Ok sent a PR for this one case. #877. If I had a test harness I would add this test:\njs\nrealm.evaluators['JSXElement'] = () => realm.intrinsics.null;\njs\nlet x = <div />;\ninspect = () => x;. One way to avoid that runtime overhead is by encoding it as a giant switch statement (which I think is most often encoded as a simple jump table).\n```js\n(function () {\n  var __scope_0 = Array(1);\nvar __initialize_scope_0 = function(selector) {\n    var __scope = __scope_0[selector];\n    if (!__scope) {\n      switch (selector) {\n        case 0:\n          __scope = {\n            x: 13\n          };\n        // Add more scopes here...\n      }\n      __scope_0[selector] = __scope;\n    }\n    return __scope;\n  };\nvar _1 = function () {\n    var __scope_1 = 0;\n    var __captured__scope_1 = __initialize_scope_0(__scope_1);\n    return __captured__scope_1.x += 3;\n  };\nvar _2 = function () {\n    var __scope_1 = 0;\n    var __captured__scope_1 = __initialize_scope_0(__scope_1);\n    return __captured__scope_1.x -= 2;\n  };\nvar _0 = function () {\n    return _1() + _2();\n  };\ninspect = _0;\n})();\n```\nThat way you only need the one helper function for N number of scopes.. Yea the switch idea is mostly just for avoiding allocating function instances.\nWouldn't eager code loading be even more of an argument against duplicating these code branches though?. @hermanventer Note that @trueadm's example used collection != null (weak comparison), not collection !== null (strong comparison). So it's equivalent to collection !== null && collection !== undefined && collection.items which would make it usable if refined twice.. There are still TODOs in the code that reference this issue.. I'm not sure Prepack is in a position to determine what type a binding will have through its life time of the program if it is mutable. For simple constant objects it could annotate but that will be easily inferred by Flow anyway. For nested objects there can be mutations that Prepack wouldn't know about. For residual objects that doesn't leak we know they won't be mutated but we should just exclude them completely.\nSo therefore I don't think there is much type info that would be valuable to add from what Prepack knows that Flow couldn't already infer.\nFor residual functions we could leave function boundary annotations intact. In fact that's what the \"React mode\" that just landed probably does since it doesn't rewrite them. If they refer to type names in the module scope we'd have to rewrite those identifiers which don't atm. So that's one action item.\nHowever the bigger thing that Prepack could do is preserve the types of annotated objects and bindings (including generics) and reoutput then during serialization. That's tricky though because we may only serialize a part of an object not the root that had the annotation.. The move from test/serializer/react/\u2192 test/serializer/jsx/. That implementation of JSX is still React specific. I've tried to keep the brand name around JSX separate from React. So it would be good if we could call this something with React in it. test/serializer/react/jsx/ maybe?. I see you already landed, but I'd like to request a follow up. :). Can we annotate all this Flow related with some consistent annotation? E.g. check for a flow option in addition to the React option? It's a little scary to me how much Flow things we'll need to add get this work. Basically all the features to track values across modules and stuff if we're strict about it. If we don't, we'll encourage people to only use a subset of Flow supported patterns.\nSo long term, I think we'll need to either make Prepack smarter so we don't need them or shell out to ask Flow about what type it thinks this class has.\nIt's probably fine to add a few hacks like this here and there to get us passed the initial blockers. But it would be good to have a kill switch on all these Flow things that is separate from the react switch so that we can try without it and potentially clean up the code if end up not needing it anymore in the future.\n. I think the model is in a good landable state. My next steps are:\n1) Deal with the try/catch scenario mentioned in the original post. My current thinking is to just issue a recoverable error when that happens.\n2) Add unit tests for the scenarios addressed by each individual commit. I can't actually run them without fixing the serializer though.\n3) Fix the referentializer so that I can properly serialize bindings captured by leaked closures. This one I'll need some help with but it doesn't seem to fundamentally influence anything about the abstract evaluation and interpreter part of this.\n. One big question here is whether we want to enable this for all abstract functions in additional functions, since it can possibly regress if those are considered pure today.\nI'd propose that we introduce a new way to create an abstract pure function. E.g. __abstract('purefunction') or something. Then those will still be considered pure. Normal __abstract('function') or calls to unknown abstract types would be considered side-effectful and can only be called in the context of an additional function or React component, in which case the arguments would leak.\n@cblappert Do we rely on a lot of calls to abstract pure functions in RN models? If so, we could perhaps model them as __abstract('purefunction').. Ok. I'd love to land this PR to avoid merge conflicts but I don't feel confident turning it on in all abstract functions yet, until #1245 is fixed. So maybe I just revert the part that opts into a \"pure tree\" which triggers the leak mechanism?. I'll just add a flag so that we can turn it on/off. That way I can at least add the unit tests that can pass.. I'll try to add test cases for the ones that can be serialized. I'm blocked on #1245 for many of them since a lot of scenarios end up being serialized incorrectly due to bindings.. I'm hitting a pretty annoying issue related to this in #1142. When a binding \"leaks\", it can sometimes be referenced in the initialization path. E.g. if you read from it after it leaked. That means that it must be initialized in the initialization path.\nThere might still be value in initializing it lazily if the read is conditional but the overhead might not be worth it.\nThe simplest solution to this would be to just opt-out of the laziness for these bindings since they'll often be eager anyway.. @NTillmann The fix to simple closures leads to a bug.\njs\n(function() {\n  var obj = {};\n  console.log(function() {\n    obj = {};\n  });\n  result = obj;\n})();\n->\n```js\n(function () {\n  var $0 = _0; // this is not initialized\nvar $f_0 = function () {\n    $0 = {};\n  };\nvar _0 = {};\n  console.log($f_0);\n  result = _0;\n})();\n```\nThe \"binding\" initialization gets serialized at the top of the generated scope. With the lazy closures, this is a bit strange output but doesn't break because it is lazy.\nWith simple closures this is eager so it gets assigned a value that isn't initialized yet.. Doing the same thing in an \"additional function\" still fails.\njs\n// additional functions\nfunction additional1() {\n  var obj = {};\n  console.log(function() {\n    obj = {};\n  });\n  return obj;\n}. Yea. The first point is already done in #1142. I'm pretty happy with the model there now.\nThe referentialization is the unsolved issue.\nI'm not sure what you mean by the last point. \"We'll have to proactively emit all those generator entries\". @NTillmann Both of your comments are addressed in #1142. Looks like it is time for another review. :). Even though they're legacy, why do we need to bailout? Supporting more seems better. Seems like they're mostly just like any other class component once they've been prepacked? Is it because of autobind? If so, how will that work with manual binding?\nI wonder if we can be more specific about what about these components is hard so that we can bailout on the same thing if it is manually defined. Presumably we'd have to bailout if I just write the same code with a different property name for the autobind set.. I updated with a version where we also store the thrown value which is either undefined or the caught value. This effectively automatically turns this call into something that returns three values.\nI'm not sure why this is different from if (condition) throw; which already works fine.\nE.g. we can treat one of these calls effectively as:\njs\nvar {success, exception, value} = callHelper(fn);\nWe can do that automatically.\nIn subsequent code:\njs\nif (!success) {\n  throw exception;\n}\nThis already works because conditional throws in conditional branches are already implemented.. I can actually model this helper in user space already. :)\n```js\n(function () {\n  function call(fn) {\n    var template = {};\n    __makePartial(template);\n    __makeSimple(template);\n    var res = __residual(template, function(fn) {\n      var value;\n      var exception;\n      var success = true;\n      try {\n        value = fn();\n      } catch (e) {\n        exception = e;\n        success = false;\n      }\n      return {value, exception, success};\n    }, fn);\n    if (!res.success) {\n      throw res.exception;\n    }\n    return res.value;\n  }\nvar fn = __abstract('function', 'fn');\nvar x = 1;\n  try {\n    call(fn);\n    x = 2;\n    call(fn);\n    x = 3;\n  } catch (err) {\n  }\n  result = x;\n})();\n```\nIt generates some pretty interesting code though.\nEDIT: Even more interesting is that the serializer yields incorrect code.. Sorry, why is this closed? The original issue is not fixed and we might need it at some point later.. Any updates on this? Is anyone actively working on it?. Evaluating Promises should work but there might be bugs in the serializer, which this looks like it might be.\nIt is likely that Promises needs to be serialized using a special case branch here since they have to use a built-in constructor (similar to Date). https://github.com/facebook/prepack/blob/master/src/serializer/ResidualHeapSerializer.js#L1204-L1268. I believe it is broken on other versions of Node since it provides some shims for node internals that change between version and even then some of it is a bit shaky. Ideally we'd do this in a membrane where we simulate what would've happened if we ran it in Node's runtime but don't actually snapshot the whole of Node's internals too.\nIt definitely works though. Prepacking Prepack itself isn't hard. It's Node's file system handles, module system etc. that gets tricky but also doable.. If you don't want any of the node specific things you can use https://github.com/facebook/prepack/blob/master/src/prepack-standalone.js\nOther than that it is basically just for the module system. You can use rollup or something on that file first, and then Prepack the result. (Compile with Babel first just like the normal build those since we may not support all features that we use.). Don't use the node-cli mode. That compiles the entire node runtime into the file. You don't need that if you webpack. Just leave it at the default compatibility mode.. I don't have high hopes of this working well for your use case though. I assume that what you want is to run Prepack, not just on itself, but on itself combined with your interpreter while leaving abstract paths intact. There are many limitations of Prepack that you are likely to hit in this case.\nThere's a reason that not all compilers are as magical as Prepack and you have to be aware of the current limitations so you can apply it to scopes where the limitations of the scope unlocks some new capabilities.\nE.g. module initialization has the benefit that most input is already known AOT and that the start of the program is known. React components has the benefit that you can assume that render functions are pure as well as that the programming model uses lazy evaluation so that if you need to bail out you have safe places to do that.\nIf you can't make those assumptions then it is not safe.\nPrepack can run its whole initialization phase and export the API without running the API through some input data. Prepack can also run itself and produce the result given static input. It cannot be given arbitrary abstract input and partially compile itself in arbitrary ways.. I think the document check is truthy but then fails because by default the \"compatibility\" mode is set to browser which includes a very limited stub of the document object. We should allow a compatibility mode that excludes the document object so that the check and just provides a very plain JS environment.\nYou can add something like plain here:\nhttps://github.com/facebook/prepack/blob/master/src/options.js#L14-L15\nThat doesn't do anything special.\nThere are two other pieces of work that might be relevant here.\n@hermanventer has been working on supporting loops over abstract values. That is still pretty fresh but seems like it would be critical to your use case. Definitely interesting to see.\nI've also experimented with allowing abstract function calls to accept mutable objects/bindings. I don't think you'll need that but it might come up at some point when all possible functions aren't known. That requires a special flag atm. You'll know if you need it though since you'll get a warning that an abstract operation isn't supported.\n  . Item 2. is not actually valid because of the super() call. But without the super call it should work.\nThere are two items named 3. I'll call them 3a and 3b.\n3b. is incorrect but it's confusing because it has three blocks. Which one is before and after?\nRegarding item 3a. There's a third (3c) scenario that we can add.\njs\nclass Bar {\n  bar() {\n  }\n}\nclass Foo extends Bar {\n  bar() {\n    super();\n  }\n}\nwindow.result = {\n  bar: Foo.prototype.bar\n};\ndelete Foo.prototype.bar;\nThese are variants of the same problem. The problem is that the only way to create a method is by putting it in a class body.\nHowever, it doesn't have to be the same class body. The only thing that matters is that it ends up having the same [[HomeObject]].\nIf a method still exists in the same class prototype with the same name we can serialize it in place.\nIf it is not we can create a temporary shadow class that exists only to create the methods. If there are more than one like this, they can ideally use the same one.\njs\nclass $FooTemp extends Bar {\n  bar() {\n    super();\n  }\n}\nvar bar = $FooTemp.prototype.bar;\nAnother set of cases is when the methods have different enumerability/configurability/writable configuration on the properties. Methods have to be reconfigured using defineProperty.\nScenario:\njs\nclass Foo {\n  bar() {\n  }\n}\nObject.defineProperty(Foo.prototype, 'bar', { enumerable: true, writable: false });\n. Public fields is also going to add some complexity to this potentially.. This fixes one of the tests in #1320.. Add another test where it is expected that the resulting functions will throw.. This fixes the other test in #1320. This is sufficient to unblock that work, but I plan on continuing to add more cases like these.. I thought some more about how this is actually modeled and pushed a new approach.\nRequireObjectCoercible doesn't actually do the coercion and not all callers of it uses the return value. So I had to move the actual coercion to where it actually happens which is in ToObjectPartial. To do that I had to loosen some checks to let the value get that far.\nThe key is that once we have this coerced AbstractObjectValue, that can in theory be passed around and we would have to be able to reference it in multiple places. Since coercion from string to an object would need to yield the same object everywhere.\nInside ToObjectPartial we could do the coercion of the value using a builder that emits a helper that checks null and undefined and then throws. E.g. function ToObject(value) { if (value == null) throw new TypeError(); return Object(value); }. That would be the correct way to model the value returned from ToObjectPartial.\nHowever, that would be really inefficient. Especially since in practice, these objects never leak. They're only used by other operations like $Get. The operation that we emit from $Get will do the ToObject coercion anyway - at the same time.\nSo the way I model this is by emitting a sentinel value that should never get serialized. That way we ensure that we never leak the result of a ToObject operation. Instead, all operations that have an implicit ToObject in them, will unwrap this sentinel value and operate on the original.. I'd expect us to be able to work around it for at least another 2 months or so.\nI think we probably need to iterate on the design a bit too.\nE.g. what does it means for an example like this:\n```js\n  var array = __abstract(\"array\", \"array\");\nvar count = 0;\n  var result = [];\n  var result2 = [];\nfor (var i = 0; i < array.length; i++) {\n    count++;\n    result.push({foo: array[i]});\n    result2.push({bar: array[i]});\n  }\nwindow.result = { result, result2, count };\n})();\n```. @trueadm We should try that. I'm not sure people do as much as they do in other life-cycles. Mainly because there is no way to setState there so there is less incentive to do that.\nEDIT: Turns out @bvaughn is working on enabling this double invoking behavior in \"strict mode\" to start enforcing it.. The issue here is that the function itself isn\u2019t abstract. We know the implementation but the implementation is native Prepack and it doesn\u2019t know what to do yet. My plan for these was to make a join point at every call. If the call results in a fatal error, we instead fall back to treating the whole function as unknown and leak.. In the CallExpression evaluator we need to wrap the nested call in evaluateForEffects. If it throws an instanceof FatalError we need to instead generate the call the same way I do for abstract functions in the same file. . Could you open an internal note about all these downstream hacks, shims or workarounds that you\u2019re doing along the way? That will simplify things in the future when these things change upstream and we don\u2019t realize that we\u2019re out of sync. . Why is this?. So we\u2019d rather fail the build than accept a fallback? Seems like it would be better to log diagnostic information and continue compiling like other recoverable errors.\nWe can downstream fail the build if we choose to but seems good to have the option to bail.\nBy continuing we also collect other possible deopts into the logs so that when compiling you can get a good idea of how many things you have to address to get to a fully evaluated state - rather than getting one by one and then giving up.. Something like this where it conditionally throws and otherwise bails out with a comment.\nhttps://github.com/facebook/prepack/blob/f4c46000e20f46b054b1d04ce5e42c89a02ae46d/src/evaluators/WithStatement.js#L36-L37. Needs a test too. That is an example that will generate the wrong code in some cases if we just ignore leaking it.\nTo avoid leaking it and still be safe we need to know the implementation of createFragmentContainer.\nThere are two ways to achieve that. 1) Something like \u201cmembranes\u201d that can reason about code that isn\u2019t being bundled. Hard. 2) Embed an implementation of createFragmentContainer in the bundle that doesn\u2019t have an residual references so that it gets deadcode eliminated and only the results are serialized.\nHowever for Relay containers specifically we\u2019re going to end up chasing our tails trying to optimize or fix it. We should just special case it using knowledge about the AOT compilations step that Relay already does. Or write a shadow implementation of the whole container that assumes Prepack.\nThe ideal here is that the container is completely compiled out and that all its intermediate objects are compiled out. I suspect that it is easier to get that working than incrementally trying to get the current implementation automatically work.\n. If the output of the compiler is not efficient in doing so, then that's what we can possibly fix in the compiler.. Ok @trueadm convinced me offline that we need this as a stop gap solution.\nWhat do you all think about using the kind field for this? That way we don't need to pollute the evaluator with this temporary special case.. The PR description seem to suggest that this fixes some incorrect behavior, but I'm not sure what that is? Is it just a deopt problem rather than a correctness problem?\nI'd expect this to just leak all the input arguments.\nIs the goal here to avoid leaking the input arguments? If so, then that's not safe due to things like:\njs\nrender() {\n  var p = { get foo() { this.bar = 12; } };\n  Object.assign({}, p);\n  return p.bar;\n}\nSo this fix is not safe.\nI see other possible optimizations such as assuming the abstract argument is \"simple\" which means that it won't have a getter like this scenario. Another thing we can optimize for is leaking frozen objects like the props object, shouldn't treat them as leaked since they can't have been mutated. We don't have a lot of frozen objects outside of props so I didn't bother optimizing for that case yet.\nBut I'm not sure what the intention of this fix.. Would it be possible to make an isolated plain Prepack non-React test that shows this failing?. I think I have a sufficient fix. I'll open another PR.. https://github.com/facebook/prepack/pull/1448\nI haven't tested the React specific parts but if that fix seems ok we can rebase this PR's tests on top of it.. Hm. That is worrying.. I intentionally did that because I figured that things we know will be serialized on the object anyway. However, I guess I missed that the partial could be setting it too and this would end up after.\nI think both our fixes still has an issue though.\nWhat happens in a situation like:\njs\nvar x = {};\nvar y = {};\nObject.assign(x, partial, y);\ny.x = 123;\nI think that the object passed to Object.assign will be the already mutated one since that's what we serialize in the tree.\nThat's what the leaking mechanism is suppose to prevent.. In pure mode, the practical effect of this is the same as throwing a FatalError.\nIn non-pure mode, it will terminate if one of the arguments is not frozen.\nIt would be simpler to just check for frozenness on the arguments and if one is not frozen then we throw a FatalError because we haven't yet implemented that as safe.\nLeaking is the wrong model for several reasons other than the terminology. Another issue is that leaking is deep but this only really affects the shallow ness.. For context, I suggested not going down the snapshot strategy because that's what I originally tried in #1142 and that turned out to be very complicated to get in properly in the current model. It was easy to get it wrong (and it was the wrong strategy for leaking anyway). So I suggested banning further modifications to unblock us for now since this covers our current needs. Even though the long term strategy could be to model snapshots.. @gaearon I think your examples are indicative of other bugs that already existed but not really related to this PR. Created a follow up here: #1476. @hermanventer I updated with the new approach for BinaryExpressions. Much simpler.\nI still need to update the OrdinaryToPrimitiveOrAbstract model. A bit worried about that one since we might rely on the current buggy behavior.. One minor comment though.\nWe don\u2019t just forget the state up until the point of the call. We forget state for ever from any new operations performed on the object too.\nSince we don\u2019t really know when the external environment might mutate it once it has escaped.. I see. Unfortunately I think a lot of values in Object.assign can cause leakage too and not just havoc. A non-simple partial can have unknown getters or setters invoked which would cause a leakage. So if that is accounted for, it might not help much. Let\u2019s chat more tomorrow.. Normally it should Fatal if an unfrozen object is passed. https://github.com/facebook/prepack/pull/1520/files#diff-84bf48590f46dad97eec3ce83367123cR424\nIf that recovers, we assume that the function was pure. I guess because someone looked into the error message and determined it was fine. That's mostly because that's what we used to do and I wasn't sure if would be safe to havoc for existing bundles.. I see. The rationale is that they cannot be mutated in a way that is observable to the pure function.\nTherefore, we don't need to worry about their state when they escape because they're not supposed to be mutated anyway. They're effectively frozen as far as the pure function is concerned.\nSince they can't be mutated, they can't have any references to newly created objects in them. Therefore it is safe to not visit deeper nodes.. The problem with this PR is that a frozen object is not guaranteed to be deeply frozen.\nWe don't have to havoc this state, but currently the flag assumes that havoc means deeply. That's why the visitor can bail out whenever it sees an already havoc:ed object.\nIt is also safe if all the fields are already deeply havoc:ed, if they're defined outside all the pure functions, or if they consist of only primitive values.\nTo avoid deep havoc, on something that is frozen, we need the concept of shallow havoc which we don't have yet.. I just noticed this. We need to havoc the keys if this happen. We don't assume that things are well behaved in pure scopes if they're newly created.. Changing the return value to an abstract does nothing to make it safer because we may not even use the return value. The first arg is mutated.\nSo this should probably be reverted. . It is only safe to do this if the first argument never escapes. E.g. you'd have to check that the source AST has an inline object literal, or if it is literal spread syntax.\nHowever, we should discuss whether the intermediate solution is worth it. I've had a lot of trouble reverting hacks to make the full solution later.. We should create some test cases for this.\nFor the havocing arguments something like this:\njs\nvar bar = { x: 0, get foo() { this.x++ } };\nObject.assign(..., bar);\nresult =  bar.x;\nWe need to forget what we think we know about the sources.\nFor the return value being different from the target something like this:\njs\nvar target = {x: 0};\nvar target2 = Object.assign(target, ...);\ntarget2.x = 2;\nresult = target.x;\nWe need to forget what we think we know about the target object, not just on the return value.. The reason for these existing is that Babel doesn\u2019t let classes extend native built in classes because there is no faithful way of doing that.\nIt probably works because of the recent changes that means that we don\u2019t use Babel.\nLanding these means that we can\u2019t go back to using Babel.\nWe probably should confirm that this ok. For example I suspect that we still use Babel for the website build. Can you confirm that the website build still works?. We need to handle the cases of sibling consumers without a new provider:\njs\n<Provider value=\"a\">\n   <Provider value=\"b\">\n     <Consumer />\n   </Provider>\n   <Consumer />\n</Provider>\njs\n<div>\n   <Provider value=\"b\">\n     <Consumer />\n   </Provider>\n   <Consumer />\n</div>\n. I think this doesn't preserved the \"changed bits\" feature. Which is ok for now.. This example yields a lot of unnecessary calls to assign:\njs\n  var x = __abstract({y:1}, 'x');\n  __makePartial(x);\n  __makeSimple(x);\n  var obj = {a:1};\n  Object.assign(obj, x);\n  obj.foo = 123;\n  result = obj;\n->\n```js\n  var _$5 = this;\nvar $6 = $5.Object;\n  var $7 = $6.assign;\n  var 0 = {\n    a: 1\n  };\n  var $0 = 0;\n  var _2 = $7;\n  var _3 = {};\nvar $1 = _2(_3, $0);\nvar _6 = x;\nvar $2 = _2($1, _6);\nvar 7 = {\n    y: 1\n  };\n  var $3 = _7;\nvar $4 = _2($2, _$3);\n_3.foo = 123;\n  result = _3;\n```. Found another one: #1574. It is slightly different in that isFinalObject only guarantees that it is not mutated in the partial evaluation path. Not in the future. But we can just change that definition.. Just use the isFinalObject mechanism for this. Tag React elements, props, and children arrays created by React (not passed in) as final. Check this flag in havoc.. It\u2019s not obvious to me why the assign tests would fail. It seems to me that the tests are buggy or there is a bug in the fix.\nWhy are they failing?. I suppose this mechanism isn't safe is someone overrides length in the loop to make it holey.. I couldn't find a repro. It's probably something else preventing it.\nI was thinking something like array.length = i + 10 in the loop.. The idea of this strategy was to intentionally break on an invariant if we hit a ToObject path that isn't adding a wrapper operation that actually implicitly forces it. The unwrapping ensures that.\nI'm worried that this strategy would let these placeholder objects escape to be serialized without the implicit conversion around it.. I'll try to come up with an example which incorrectly serializes instead of fails on an invariant with this approach.. ~It looks like most cases where we call ToObjectPartial, it is immediately followed by some kind of property access. So it should be fine. The exception is Object(abstractTopVal) which current fatals because we don't know if it is a null/undefined. We'll just have to be careful if we try to handle that case because it might result in leaking an implicit ToObject value which wouldn't be an object at runtime.~. Actually both Object.prototype.valueOf and Object.assign has this issue. #1588. ~Yea, this is the same work as we've done for binary expressions. I'm happy to take that on since I did the last version. Assuming the version that is in place for binary expressions seems to be working.~ EDIT: nvm. That's not what this issue is about. It has nothing to do with unary expressions.. I removed the unary expression in your example. The unary expression doesn't have anything to do with the core issue which has more to do with unknown property access on a partially known object.. I\u2019ve been working on a solution. It\u2019s a bit involved give in how many cases we need to bail out for partial values and how prototype chains works but we\u2019ll get there.. Your pure function isn't pure.\nWe should add errors if you try to mutate a non-newly created thing if we're isInPureScope.\nCan we please start writing tests and examples in terms functions that return values instead of mutating so that they won't break when we add that? Also, who know how the system behaves if they're not pure.. @hermanventer I'm suggesting some simpler.\njs\nSet(...) {\n  if (realm.createdObjectsTrackedForLeaks && !realm.createdObjectsTrackedForLeaks.has(this)) {\n    throw new FatalError();\n  }\n  ...\n}\nAnd the same for bindings.. Do you have any more context to share here? What kind of scenarios does this break in?. The issue is #1586. @gaearon Has started add PRs with failing tests and then waiting for the issue to be fixed before landing. I kind of like the approach since it is helpful to be able to just checkout a bunch of test cases without copy/pasting from issues where they might not be in a runnable state. I suppose we could check them in but then they get lost so yea an issue would be good.. Added some tests for the new paths.. If the issue is evaluating a || b then we can just leave that binary expression in place as abstract and continue evaluating the body.. So basically we want to add more points where we havoc everything within that scope somehow.\nI wonder if we can be a bit smarter than that in these cases.\nSeems difficult to know where the best bailout point is.. There are a few more general issues related to partial property names that makes this not quite a sufficient fix. Will comment later.. The purpose of a \"Reference\" is to defer the operation until later when we know if it will be used as a read or a write. So it's not safe to assume that it'll be used as a read in this code path. We'll need to wait until we get to a point where we dereference.. I continued on the original approach in #1680\nWhile doing this at the member expression level is more in line with how we do other things, I think we probably want to move more of that into the object model because it allows us to optimize further in the prototype chain.\nE.g.\njs\nvar obj = Object.create(abstractObject);\nobj[foo];\nCan be optimized to:\njs\nabstractObject[foo]\nIn cases where foo is known to be a non-getter.. For this particular issue, wouldn't it be enough to evaluate the condition as part of the body? Right after the main body.\nThis works fine:\njs\nvar n = __abstract('number', '(2)');\nvar i = 0;\ndo {\n  console.log(i);\n  var condition = i++ < n;\n} while (condition);. Another detail is that the object gets inlined in the generator so it gets created every iteration.. I'm pretty happy with this implementation but I'll try to add more tests. It's a bit difficult because of other bugs like #1675 to come up with scenarios.. There's at least one case where it is automatic. https://github.com/facebook/prepack/blob/master/src/intrinsics/ecma262/Object.js#L140\nPerhaps that was a mistake.. It forces the target to be simple if any of the sources are partial/simple. But one of the sources might not be.\njs\n  var source = { valueOf() { throw new Error(); } };\n  var source2 = {};\n  __makePartial(source2);\n  __makeSimple(source2);\n  var target = {};\n  Object.assign(target, source, source2); // target is marked as simple\n  var c = __abstract('boolean', '(true)');\n  var abstractKey = c ? target : {};\n  var n = {x: ''};\n  result = n[abstractKey]; // this should not be allowed because target has a side-effectful valueOf\nI suppose Object.assign can enforce that it is only simple if all the sources are simple.. Btw, I'm not sure if this is the right tradeoff. Maybe it's more important for Object.assign to be smart than ToStringing objects.. If you change the numeric properties to named ones, there's still a problem though.. When we SetPartial outside a loop, then we weakly update the known properties. Is there a reason we can't do that for widened properties?. The interesting thing is that something like this works:\njs\n  var arr = {};\n  var i = 0;\n  do {\n    arr[i] = i === 0 ? 'a' : i === 1 ? 'b' : 'x';\nSo I guess it's just important that the join condition gets evaluated inside the loop. Not after the loop.. Wouldn\u2019t snapshotting be an appropriate solution here?\nIn general we\u2019re ok with losing precision later as long as we can serialize the state of an object as it was before we entered the lost precision (eg havocing or Object.assign).. Why does this happen in first-render though? In first-render we should be able to know everything about the object, including whether it is simple. What's the scenario where this breaks down?. Hm. It seems like bad practice to return a value directly from props but I can see how that could happen.\nFor the Object.assign cases we should be able to detect that they're simple since the target object is simple.. cc @trueadm . For abstract values that leave residual calls or property access this isn\u2019t just an ugly inconvenience. Compilers further down the pipeline can\u2019t reorder and end up with unfortunate output.\nSo I think it\u2019s worth spending some time on this.. @hermanventer Do we have a way to \"derive\" a value that is not abstract? In these three cases we know the identity. It's always a newly created array object. We just don't know its numeric properties.\nSo we should be able to treat this as an object with an intrinsic name.\n@trueadm I suggest forking this:\nhttps://github.com/facebook/prepack/blob/master/src/utils/generator.js#L939\nIt generates an id that can be used as an intrinsic name. However, instead of constructing an AbstractValue, it should construct a concrete ObjectValue with that intrinsic name.\nThen you can change the unknownProperty to be an AbstractValue with some special kind. E.g. \"widened numeric property\" and then you can special case the Get here: https://github.com/facebook/prepack/blob/master/src/values/ObjectValue.js#L761\nThis will be super helpful for my other fixed point loop stuff.. There are so many things that depend on AbstractValue's identity being unknown that it is difficult to do much with the resulting object once it is Abstract. For example, everything that calls throwIfNotConcrete stops working even when the object model otherwise would allow it. If we want to take the approach that abstract values should have identity, I think we'll need to take a pass to clean up those assumptions before switching over.\nHowever, my plan for React loops was to lower map calls into loops since I'll need to do a form of loop fusion anyway. When .map is lowered the resulting array will be concrete with a widened unknown property so it'll end up being similar anyway but it'll need to use a snapshot for the initial state (currently a bug in loops). So it seems like this direction allows us to seamlessly switch between lowering and not without having to think about the consequences of switching between concrete and abstract but known identity.\n. We don't actually have to do any of the assignment/increment logic. That's already dealt with by other parts. We just have to deal with the ToNumber aspect of this. I'll send a follow up. #1847. Added some tests that were previously failing and addressed the comment.. We should take a look if we really need this. I'd prefer that the fix is that we move both the binding/object that we're reading from and the write to be abstract.\nIf not, I think we should have to wrap the binding/object itself in something that makes it unsafe, not the mutation. Reading a mutable value is as bad as writing to it.\nSo in code like this:\njs\nvar x = 0;\nfunction Foo() {\n  x++;\n}\nInstead of turning the mutation into safe, how about instead, we havoc it in the module scope? It's never safe to read from it and mutations needs to be tracked.\njs\nvar x = 0;\n__havoc(() => { x; });\nfunction Foo() {\n  x++;\n}\nCurrently havocing fatals in a non pure scope but this special function could by-pass that.\nThis would turn the x++ into an assignment statement in the generator instead of a modified binding:\nhttps://github.com/facebook/prepack/blob/master/src/environment.js#L295\nWhich will by-pass your check.\nNot all side-effects are covered by modified bindings and properties unfortunately. A lot of them comes from generator entries such as this one. That's another issue to consider.. @gaearon That sounds fine. I think a feature that havocs in module scope before we optimize like my proposal above would actually work fine and isn't too bad of a feature. There might be cases with closures that are currently broken due to serializeBinding issues but those will also be broken with any other havocing of closures.\nBtw, does this check cover things like Map?\njs\nvar x = new Map();\nfunction Foo() {\n  x.set('x', 'y');\n}\nMaybe add a test?. There is already a place where this happens. \nhttps://github.com/facebook/prepack/blob/master/src/realm.js#L1301\nhttps://github.com/facebook/prepack/blob/master/src/realm.js#L1329\nJust have to add one that checks for isInPureScope and if the object/closure is part of the newly created objects in createdObjectsTrackedForLeaks and fatal if they're not in that set. (It's fine to mutate newly created objects.)\nNote: Don't use realm.createdObjects because that's the created objects in the currently executing block/scope. Not the whole pure scope.. It might be because we catch FatalError in a bunch of scenarios which lets us bail out. invariant is not correct either since it's only for bugs in Prepack. Maybe we need a EvenMoreFatalError.\nAlternatively, we can also just log it to diagnostics without fataling.. Just to be clear, this has nothing to do with assign. It's just a convenient alias for ToObject.\nI think the particular issue is that this is not temporal https://github.com/facebook/prepack/blob/838c26d7a0bfb3bba8e941889b756e7050b51184/src/methods/to.js#L445\nI originally didn't want these to leak because it serializes suboptimal code. It should almost always unwrap the ToObject wrapper and just refer to the original. This is one of those cases where this should never be serialized as a call because the ToObject is already implied by the property access.\nThis is extra bad because it somehow reused the same object but this should actually be two objects if it's a primitive. Which it would be if it was unwrapped by the property access as intended. I don't know why this isn't causing two objects. Is it some kind of abstract value equality test?\ncc @hermanventer . js\nObject.defineProperty(String.prototype, 'a', { get() { return this.cache || this.cache = {}; } });\nObject.defineProperty(String.prototype, 'b', { get() { return this.cache || this.cache = {}; } });\nfn('foo');\nNot saying anyone would do that but hard to say what else can be an issue.\nIt's more likely if the object does leak. That's what the call to Object.assign was meant to fix in the first place. The scenarios when it leaks to user space. So it is possible. E.g. Object.assign('foo');. Not all scenarios would involve havocing. E.g. the loop is not havocing the target array. It is storing an unknownProperty which can then be referenced by other reads but we don\u2019t havoc.\nIf you read a value after the loop such as obj[10] then that will be part of an abstract value which is reading from the object. So the object will be visited and part of the residual heap which means that the loop is retained. But if we never use the object then we don\u2019t have to.\nThis is not a correctness issue so this is not very time sensitive. Definitely lower priority than the correctness bugs.\nIt helps debugging since it\u2019ll strip a lot of code and I think this will be critical for perf in prod testing.. I don't think this is going to be sufficient because the temporal part was only part of the issue surfaced by the example. It was only toobjected once. It also generates unnecessary code by not unwrapping. Something deeper is wrong here.. There are only 2-3 cases that leak the object created by ToObject directly so that implicit coercion is impossible.\nhttps://github.com/facebook/prepack/pull/1588/files#diff-881abe5d6b0da3c006b3ab24a5cdbf5eR6\nThere are however many instances of ToObject that doesn't leak it and therefore can unwrap it.\nI don't really think we should adhoc add them one by one without anyway to track them. We'll also forget it in new cases. My original approach was to error when we found a new special case so we could add them one by one. However, it had another bug in it in the serializer.\nHerman's second approach was to always emit the explicit coercion so that it would generate the right code, but that didn't account for the abstract value equality and temporal issue. It also ended up generating bloated code since there are many cases where you could unwrap.\nThis is a deep issue. I think we need to meet and coordinate where the right place to solve it is. It's not clear that either strategy is good.. Abstract values that are emitted as first argument to JSX elements needs an id (that doesn\u2019t start with lower case a-z). Could be marked by the visitor?. Specifically this type value is the thing that needs an ID. https://github.com/facebook/prepack/blob/master/src/serializer/ResidualReactElementVisitor.js#L45\nhttps://github.com/facebook/prepack/blob/master/src/serializer/ResidualReactElementSerializer.js#L252\n. React's form of JSX needs to know if something is a HTML tag or local identifier. Using a special syntax like {} was too much since both are very common and the whole point is to make it more readable.\nThe typical convention for a component, just like classes, is to use a capital.\njs\nvar Foo = require('bar/foo');\n<Foo />;\nThe convention for HTML however is lower case these days.\njs\n<div />;\nWe used to have a whitelist of HTML tags but new ones get added so it became a pain to maintain across the ecosystem.\nWe considered having local scoping but at the time it was difficult for transpilers to know their true scope given that they could be running pre-bundled or post-bundled. There's also a quirk that i is both popular in loops and in JSX.\njs\nvar items = [];\nfor (var i = 0; i < 10; i++) {\n  items.push(<li>Foo <i>Bar</i></li>);\n}\nSo we settled on a convention based on case. It worked out surprisingly well and now it's standard practice and has leaked to other systems like Glimmer.. This is the most authoritative implementation today https://github.com/babel/babel/blob/ce420ba51c68591e057696ef43e028f41c6e04cd/packages/babel-types/src/validators/react/isCompatTag.js#L4. This might not be the serializer. Could be an interpreter bug.. I tested your example and it seems to work fine.\nMaybe @hermanventer knows how to upgrade test262? I'm not sure how we do it and how much will break if we do.. This seems like a mistake. It works with var which would be one environment up. It's just because let is block scoped.\nIt is subtle because we don't want to havoc the environment inside the function. It's tricky to get right. I had a lot of bugs. E.g. you want to make sure that the pure function itself doesn't havoc but things in its scope can havoc.\nTry and it and see what breaks? :) . @hermanventer The CallExpression is pretty aggressive and fundamental to the approach of all the havocing. I don't know any issues with it at this point. Even aliasing isn't an issue because the havocing ensures that it isn't a concern:\nWe have to be careful with things like this:\njs\nvar obj1 = {x:0};\nvar obj2 = Object.assign(obj1);\nobj2.x = 1;\nreturn obj1.x;\nThe return value can't just be an abstract topVal, in this case. It must do something to ensure that obj1 might be obj2 (which it is). Havocing ensures that all of that works.. One thing to consider here is that React elements should not be considered frozen objects. They are a different category of objects that are considered \u201cfrozenish\u201d. They should never emit Object.freeze calls but we still know that they\u2019re immutable.\nI think that\u2019s the source of confusion here.. Nice! This is just what I needed.. Basically this is just a fallback mechanism because we haven\u2019t covered all cases. There are too many things that generate topVal objects right now since values domain can choose to go to topVal almost at any time.\nIt\u2019s not always necessary to havoc them as a result. Eg a condition of a topVal object and a concrete object will yield a topVal but we wouldn\u2019t want to havoc all concrete objects in any such case. Only if it actually ends up escaping which is what havocing the args helps with. It is the dependency tree.\nI agree that this is undermodeled but a safer fallback than not havocing anything.. One possible improvement is that we keep known objects in the ValuesDomain whenever we go to top so that we know that it might at least be one of these but also others. That way we can keep a reference back to them in case we need to havoc.. Should we allow the same thing for do/while to avoid forking them further?\nIt seems to me that the fixed point mechanism should be able to deal with this (although it wouldn't unroll).\nHowever I was surprised to find that the fixpoint computation fails.\njs\n  let c = __abstract(\"boolean\", \"(c)\");\n  let l = c ? 1 : 2;\n  let sum = 0;\n  var i = -1;\n  do {\n    i++;\n    sum++;\n  } while (i < l);\n  console.log(sum);. This PR is just slightly better than what came before it. The additions are the proper way to model it I think.\nHavocing the args (which was already there) is a bit sketchy. The goal is to be as conservative as possible for things we haven\u2019t yet modeled so that we don\u2019t yield incorrect code.\nFor loops I want to add a template object form which doesn\u2019t guarantee which concrete instance it is but guarantees that it is not one of the known ones. I believe that can help us model abstract objects without going to topVal in more cases so that we don\u2019t end up needing to be conservative.. Note that master is more conservative than this. The other new test cases doesn't fail on master but they do test that the havocing that was already in master still works. If I removed the havocing of args, then there wouldn't be other tests that failed. So this ensures that all branches are covered.. I'd like to get @NTillmann to review the temporalAliasArgs approach (perhaps re-review the original PR #2112 that added it). This seems like a possibly fragile approach (and heavy weight) since there is so much relying on temporal-ness of arguments that reordering things isn't safe. E.g. with regard to havocing and other things emitting temporal initialization.. This only works if the template is intrinsic. Does that imply that templates can only be used if they're intrinsic?. There's a lot of overlap with this feature and what I'm doing for object set templates, however, it also doesn't handle a lot of the cases I had to deal with so I suspect you'll find bugs.\nThere are inherent problems in modeling things on the abstract value as opposed to inside the value domain since some operations create a new abstract value without regard to the original abstract value and only transfers the value domain. Those wouldn't transfer the shape information.\nOnce we have object set templates, it might be better to model this as a Proxy object or special ObjectValue that can work as the template for the shape.. Here's a twist... It's not actually enough to check if it's there's a data descriptor since exotic objects can have custom implementations of what happens during a $Set. For example, arrays updates the length property.\njs\n(function () {\n  var c = __abstract('boolean', '(false)');\n  var array = [];\n  var otherObj = {};\n  var abstractObj = c ? array : otherObj;\n  abstractObj[5] = 2;\n  result = array.length;\n})();\nIt seems to me that we have to evaluate for effects to cover this case and any setters.. If someExternalFunc is called in a pure scope, it can only have effects on what is passed to it. So if we recursively pass all those values to the \"onlyMutates\" argument to entry, then it should be able to completely eliminate the function call since you're not using obj2 in any way. Seems like we should fix that.\nCan you come up with a variant of this example that isn't optimizable?\n. Btw, in general this problem is easy when all inputs are primitives and the return value is a primitive. If you can find a way to rewrite it to such a form, it's also easier.\nOnce they become objects, it is a lot more complicated because those tend to bring in a lot of entire branches that might be dead. So forcing materialization can sometimes be much worse.\nThey can mutate. They carry identity along with them which we can't even model right now. . @trueadm The reason I ask is because I don't quite understand the constraints since fn2 is pure right now but we're trying to solve a problem that is only relevant if something is not pure.\nIf you return obj2.a in fn2, does that still make sense to illustrate your point?. What if instead of doing this during evaluation, and per function, we instead used an optimizer step in the serializer. Maybe a pre-visitor that finds similar looking abstract value trees and hoist them out into a helper function. That way we are not locked into the original form of the function and it can find common pattern after constant propagation has already happened.. Basically the idea is that the main function and any residual function are \u201cactors\u201d that process some data. They\u2019ll use arena allocation and are expected to be short lived.\nA runtime outside of these can control the memory management of long lived objects. That allows for parallelism and more efficient memory management outside of these \u201cworklets\u201d. . Yea, this exercise really shows where our abstractions leak and where they don't. The generators are fairly flexible but still a bit leaky. There are some things in there that isn't really necessary from interpreters point of view, but it's a hard dependency from the interpreter.\nE.g. creating intermediate variables happens in the interpreter right now. The generator also inserts temporary variables itself. The rest of the system is essentially SSA so it gets a little awkward to manage both. In this PR I just undo this by storing my own variable map and undoing the temporary assignment. We should try to move that concept out to be completely isolated in the serialization pass instead of interleaved.\nRegarding the BabelNodeExpression hack, while the SerializationContext has an unfortunate dependency on it, the deeper issue is actually with AbstractValue whose build node depends on us materializing nodes before we actually know what operation we're serializing. That's the one we need to think a bit about.\nI originally expected LLVM to help me with much of what the visitor does, but it is lacking in some areas so yea I might need a pre-processing pass like the ResidualHeapVisitor.. Note that even patching it with concrete values will likely reinterpret parts of it. E.g. any operation that havocs currently is left as residual and trigger all kinds of effects when we pass it real values.. Thanks for getting this started! This has been needed for so long.\nIt's weird to me that createResidualBuildNode needs extra fields like kind and data. Most things are described on the AbstractValue itself like args and kind.\nThings on data is just a random grab bag of things. It's just as bad a buildNode. In fact, there's even a few build node equivalents in there. With data there is no guarantee for me as a custom serializer writer that I've covered all cases because we can just keep adding random stuff to data. With the previous model I could at least be sure that I've covered everything if I covered any babel node, but now the things I might have to support is unbounded.\nThis is fine as an intermediate step, as I realize that this refactor has to be multiple steps, but I think the end goal should be that ResidualBuildNode is just a string. Do you think we could reasonably get there?. All built-in methods basically have to be made compatible, one-by-one since they're implemented in \"native Prepack\". All the ones (except the invariant) you posted are that.\nThe pure scope mode is good for any built-in method because it basically allow it to fallback to leaving the call in place (see CallExpression). You could enable only that part of the pure scope mechanism.\nHowever, it would be interesting to see what errors you get if you enable only the call expression fallback for NativeFunctionValue. That will find gaps outside built-in methods.. This surfaces an interesting error.\nIn this case:\nhttps://github.com/facebook/prepack/blob/master/test/serializer/abstract/WaitGenerator0b.js#L11\nThe value can be either undefined or number. So the common type is PrimitiveValue which used to be enough. However, that's incorrect because if PrimitiveValue is a Symbol (which is a \"primitive\" by some definition), then this operation will throw so it's incorrect to leave it as pure.\nThis was fixed for ToNumber already but not for ToString. https://github.com/facebook/prepack/commit/04bfefd8f50aa916e7356ac1f302b8d0c21625ce\nAnother issue I found is that this line is actually wrong: https://github.com/facebook/prepack/blob/master/src/evaluators/BinaryExpression.js#L94\nIf neither is StringValue, the pure values may actually be of type PrimitiveValue. However, one of those might still be StringValue so then the return type would be string, not number. I'll come up with a test case.. This also applies to abstract equality for null and undefined.\njs\n(function () {\n  var n = __abstract(\"number\", \"n\");\n  numberIsNull = n == null;\n  var b = __abstract(\"boolean\", \"b\");\n  booleanIsNull = n == null;\n  var s = __abstract(\"string\", \"s\");\n  stringIsNull = n == null;\n  var o = __abstract(\"object\", \"o\");\n  objectIsNull = o == null; // this works\n  stringIsUndefined = s == undefined;\n})();\n. I'll split this into two diffs since fixing the partial property access seems to uncover a lot of other bugs in the React compiler.. I think this case is especially bad because you don't even need to use getOwnPropertyDescriptor for this one:\njs\n  var c = __abstract('boolean', 'c');\n  var y = __abstract({foo:1}, 'y');\n  __makeSimple(y);\n  if (c) y.bar = 2;\n  result = y.bar ? 'truthy' : 'falsy';\n->\n```js\n  var _$1 = this;\nvar __empty = {};\n  var _0 = c;\nif (_0) {\n    y.bar = 2;\n  }\nvar _$0 = _0 ? 2 : __empty; // This turns into two truthy values. The second one should be undefined.\n$1.result = $0 ? \"truthy\" : \"falsy\";\n```. Now you can remove the flag in $OwnPropertyKeys, right? https://github.com/facebook/prepack/blob/master/src/values/ObjectValue.js#L725. I don't understand. You just added that flag in the previous diff and now you're removing the use case that it was added for.\nAbstractObjectValue only passes it through to ObjectValue.\n. How are you expecting to use this?\nThere's a subtle thing that only works because we havoc. There is a rule in pure scope:\nAny abstract topVal is never allowed to be any object that hasn't havoced unless it is defined outside the pure scope.\nThis means that you can never return an abstract topVal from any of the leaked functions if that might return a known object.\njs\nvar obj = {foo: 1};\nvar obj2 = [1].map(() => obj)[0];\nobj2.foo = 2; // If obj2 is an abstract topVal we only emit an assignment, we don't actually update obj\nreturn obj.foo; // Now if this hasn't havoced, we assume that the value is still 1\nSo this doesn't actually solve that use case.\nEDIT: We have a provision that havocs the receiver. https://github.com/facebook/prepack/blob/master/src/values/AbstractObjectValue.js#L819 That might be enough if we are able to trace back the args of the abstract value to havoc the closure when this happens.\nCan you add this as a test case just to make sure it works?. I don\u2019t understand the criteria decided upon. How are not everything temporal according to this definition?\nI believe that almost every expression in JavaScript can throw if given invalid input. So when should I not mark something as temporal?\n(If we count TDZ, I believe literally everything can throw.). Another approach could be to require all abstract values to be derived using the generator but add a flag like isTemporal to distinguish things that could be reordered vs things that can't. As long as that information is preserved in the source code.. I'm still not satisfied with that definition. If an abstract value is atemporal but depends on a temporal value, and is depended upon by a temporal (everything is eventually depended upon by a generator entry). That only means that it has to be computed between those two temporal points. We can still move it relative to other temporal points. That information is already there in the graph and can be computed by the visitor.\nIf we go with the definition for abstract values needing to be temporal if their dependencies are temporal, then we need to start modeling the dependency graph in the generators instead so that different entries in the generator can be reordered depending on their dependency graph.. nice! Less special cases in React code is always good.. Internal tests are failing. I guess something relies on this. Would be nice to get a reduced test case checked in.. Even if with a test case we should fix that this doesn't return the correct type of object. It's like an accidental descriptor.. A way to think about this is:\njs\nlet obj = __abstract({\n  get x() {\n    return Object.getOwnPropertyDescriptor(this, 'x');\n  },\n  set y(value) {\n    Object.defineProperty(this, 'y', { value });\n  }\n}, 'obj');\nresult = obj.x;\nobj.y = 2;\nIf we want to model this, then the get/set operations needs to be passed a this object. If we don't want to leak the template object itself but only refer to the abstract object, then we need to allow the abstract object to be passed as a receiver and allow side-effects.\nThis also happens to be how OrdinaryGet and OrdinarySet are modeled so by fully modeling getter/setters we automatically support OrdinaryGet and OrdinarySet too.. js\n(function () {\n  var c1 = __abstract('boolean', 'c1');\n  var c2 = __abstract('boolean', 'c2');\n  var obj1 = __abstract({x: 1, y: 2, z: 3}, 'obj1');\n  var obj2 = __abstract({x: 2, y: 3, z: 4}, 'obj2');\n  var obj3 = __abstract({x: 3, y: 4, z: 5}, 'obj3');\n  var obj = c1 ? obj1 : c2 ? obj2 : obj3;\n  obj.x = 9;\n  obj.y = 9;\n  obj.z = 9;\n  result = obj;\n})();\nThis used to generate this code:\n```js\n(function () {\n  var _$0 = this;\nvar _g = obj1;\n  var _3 = c1;\nvar _0 = _3 ? 9 : 1;\n_g.x = _0;\n  var _h = obj2;\n  var _8 = c2;\nvar _5 = _8 ? _3 ? 2 : 9 : 2;\n_h.x = _5;\n  var _i = obj3;\nvar _C = _3 ? 3 : 9;\nvar _A = _8 ? 3 : _C;\n_i.x = _A;\nvar _E = _3 ? 9 : 2;\n_g.y = _E;\nvar _I = _8 ? _C : 3;\n_h.y = _I;\nvar _N = _3 ? 4 : 9;\nvar _L = _8 ? 4 : _N;\n_i.y = _L;\nvar _P = _3 ? 9 : 3;\n_g.z = _P;\nvar _T = _8 ? _N : 4;\n_h.z = _T;\nvar _W = _8 ? 5 : _3 ? 5 : 9;\ni.z = _W;\n  $0.result = _3 ? obj1 : _8 ? obj2 : obj3;\n}).call(this);\n```\nWhich would update each object three times.\nIn the new code it still updates each object three times:\n```js\n(function () {\n  var _$0 = this;\nvar _0 = c1;\n  var _l = obj1;\n  var _m = obj2;\n  var _n = obj3;\n  var _7 = c2;\nif (_0) {\n    _l.x = 9;\n    _m.x = 2;\n    _n.x = 3;\n  } else {\n    if (_7) {\n      _l.x = 1;\n      _m.x = 9;\n      _n.x = 3;\n    } else {\n      _l.x = 1;\n      _m.x = 2;\n      _n.x = 9;\n    }\n  }\nif (_0) {\n    _l.y = 9;\n    _m.y = 3;\n    _n.y = 4;\n  } else {\n    if (_7) {\n      _l.y = 2;\n      _m.y = 9;\n      _n.y = 4;\n    } else {\n      _l.y = 2;\n      _m.y = 3;\n      _n.y = 9;\n    }\n  }\nif (_0) {\n    _l.z = 9;\n    _m.z = 4;\n    _n.z = 5;\n  } else {\n    if (_7) {\n      _l.z = 3;\n      _m.z = 9;\n      _n.z = 5;\n    } else {\n      _l.z = 3;\n      _m.z = 4;\n      _n.z = 9;\n    }\n  }\nvar _g = obj1;\n  var _i = obj2;\n  var _j = obj3;\nvar _h = _7 ? _i : _j;\nvar _f = _0 ? _g : _h;\n_$0.result = _f;\n}).call(this);\n```\nI think that is because the defineProperty operation gets assigned a conditional value so it doesn't know that it is unchanged until later when the simplifier deal with it. I'm going to add a case to unwrap conditional descriptors in a follow up which should fix this. After that fix, this should only go through the object model three times on a single object.. Rebased and confirmed that the special case in #2462 is no longer needed. Still passes the new test.. The inexact thing doesn't give us much. We've already fixed a few of those. The problem is that we have hundreds of places that just doesn't deal with joined descriptors and always does the wrong thing instead of fataling. Which means that I can't rely on that mechanism to work. That's preventing me from doing more with this like in https://github.com/facebook/prepack/pull/2461.\nMost things in here are mostly mechanical. I've split out things that are not just mechanical in separate commits and I'll go through and highlight them.\nIn the interpreter I'm trying to just throw fatals as much as possible instead of trying to fix the callsites and then fix them in follow ups.\nI've tried to support them as much as possible in the serializer to avoid having to error. The relevant serializer commit: https://github.com/facebook/prepack/pull/2473/commits/39817cb9fff3e0db5d49898e6e625366e267e442 cc @NTillmann . Ok this is now ready to review. I've split the commits up by whether they're adding a primary mechanism that is worth reviewing or if they're just mechanical updates to the code.\nPrimary Mechanism\nThese are worth reviewing:\nAdd normal type for descriptors  064e271\nAdd refinement to concrete PropertyDescriptor in IsDataDescriptor 9d48ffc - This is an advanced Flow feature to get the refinement from IsDataDescriptor that we already implicitly rely on.\nSupport nominally typed descriptors in the serializer 39817cb - cc @NTillmann this one is for you. This actually adds some functionality that I don't think we really dealt with before.\nAdd mightHaveBeenDeleted helper on Descriptor 1e8f329 - My thinking is that we might want to start asserting more of this at the descriptor level rather than the value but it's also common enough to warrant a helper that works like the Value level.\nOptimistic optimizations for when the descriptor is not joined 2a910ba\nIncrease timeout 852f580 - There seems to be a perf regression that causes one of the RegExp tests in test262 to become fragile. Increasing the timeout a bit.\nMechanical Work\nThese are most just mechanical and are not worth reviewing in detail.\nThese changes a bunch of callsites to use a slightly different API.\nPass Descriptor to ThrowIfMightHaveBeenDeleted instead of Value 15076d0 \nWrap Descriptor literals in PropertyDescriptor class 12e21e4\nWrap $DefineOwnProperty calls in nominal PropertyDescriptor 36b7b23 - We don't want to support the convenience DescriptorInitializer since that requires us to check it many many places.\nUpdate DefinePropertyOrThrow to wrap in PropertyDescriptor 8b6966f\nMove descriptor helpers out to the definition of descriptors 765c7fd - Unnecessary file that doesn't include standard methods. Avoids a cycle too.\nThese add fatal errors where we don't yet handle joined descriptors, or invariants where we already know there won't be any.\nThrow if not concrete 9cd65f3\nAdd invariants to React reconcilers 259012d - cc @trueadm, the React parts doesn't consider joined descriptors. We'll have to fix as needed or perhaps fatal if it is possible to get into these.\nAdd invariants to intrinsic initialization 89cf142\nAdds invariants because unknown properties never join 1d41aec\nAdd invariants because we checked the other case 7eb51be\nRegression\nI had to disable one test because we don't actually handle it properly. It just happened to work in this particular edge case accidentally.\nExpect to throw introspection error on conditional descriptor 6cd5dbb\n. > When React is the target, path conditions are not re-specialized\nIs there some special logic when the React flag is enabled or is this just a consequence of how the React mode is used in practice?. More precision can cause us to hit new types of fatals that would cause us to bail out. It is rare because most things are covered by the fallback mechanism that havocs and leave things in place.\n@trueadm Mind looking into the bailout causes?. So this is approaching a problem space we don't really talk about much but in ES2015 this assumption is actually not true:\njs\nlet Stringish = {[Symbol.hasInstance](v) { return typeof v === 'string'; }};\n'foo' instanceof Stringish; // true. At the very least we can do this optimization for simple objects as the right hand.\nFor objects that are not topVal as the right hand, we should just continue executing since it'll resolve the real value.\nIf it's not an object on the right hand we can continue too since that'll throw.\nIf it's a topVal object on the right hand, we can issue a recoverable error. Since we can assume continue under the assumption it's false.. I think the one we use internally is actually the spec compliant one unfortunately.. We use abstract values in many different ways that isn't just defining the surrounding host environment. Those have subtle differences that can't be expressed using the __abstract() helper. E.g. arguments passed to optimized functions are abstract values with intrinsic names. Those objects can be intrinsic objects, whose properties refer to objects that are not intrinsic.\nE.g. before this API there's no way to express this:\njs\nlet notIntrinsic = {};\nlet intrinsic = __abstract({ nestedObject: notIntrinsic }, \"x\", { externalTemplate: true });\nintrinsic.nestedObject = 12;\nWhile it is not so useful for modeling the host environment, it is useful to be able to write tests for these cases since there are cases where such abstract values do happen in optimized functions etc.\nIn my next PR, I explicitly want to be able to use the same template in two different abstract values to represent abstract objects with different identity - such as objects created by loops or optimized function. For that, I do need the same template to be able to be shared.\nMore over this will also happen with loops because the object created in the loop does escape, then we need to use an abstract value to refer to particular instances of that object. So the template and the abstract value can co-exist.\nI could wait to write any tests until I have every piece in place and then write a full integration test using loops, but that's very hard to work with compared to an isolated unit test.\nI don't like the name externalTemplate. Better ideas? I think we should just drop this . I opened a PR that shows how I intend to use this mechanism: https://github.com/facebook/prepack/pull/2543. Dropping the externalTemplate option right now means dropping rebuildNestedProperties from the __abstract helper. https://github.com/facebook/prepack/blob/master/src/realm.js#L1620\nThis is a potential breaking change since our internal modeling code may depend on nested objects being assigned intrinsic names automagically. So I'd like to change that code first and then drop the option in a follow up when it's safe.. If I use rebuildNestedProperties then the template is also assigned the same intrinsic name so my test case here wouldn\u2019t have failed before.\nIf I use it with the same template in two abstracts, then it causes an invariant.\nSo the reason I need two abstract values is the case mentioned in #2543.\nIt\u2019s possible to get access to multiple instances from the object value created inside the loop body.\nlet a = obj.x;\nlet b = obj.y;\na.someProperty = 1;\nresult = b.someProperty;\nThese may share the same identity or not. So I don\u2019t know if a === b and consequently I don\u2019t know if b.someProperty will have been updated or not.\nThe simplest way to model this is to have all of them share the same template.. The __abstract helper lets me write unit tests for this without invoking the whole loop logic too. https://github.com/sebmarkbage/prepack/blob/9a7a69f7c8dbd4f704d2a69f0c7da3f809c00ae9/test/serializer/abstract/WidenedIdentity4.js\nHowever these templates I suspect will be helpful for modeling return values too. We need a way to model that a function always returns the same object or different instances every time or different instances but those instances may be the same as the return value from another function.\nIn that case you\u2019d share the template as the return value of two different functions. . If I read out two properties from an array created in a loop body:\nlet a = array[0];\nlet b = array[1];\na.x = 1;\nHow do I represent that I want to mutate whatever is in slot 0?\nThere needs to be a new abstract value derived every time I extract a new value from a widened property. That already happens.\nIf I don\u2019t share the template there needs to be some other thing that is shared since they might also be the same object.. An abstract value with two templates already means something else. It means that it can possibly be one of those two exact identities. Eg a conditional object and the code generated even compares the identities.\nRegardless it needs some differentiator that is different than just two templates because the deep mechanism of the object model (such as the special cases in ArrayValue, deep inside ValuesDomain and many other places doesn\u2019t have knowledge of the set of template). So you need some kind of flag that travels with the object or a different type of class.\nHowever once you have that there is little need to keep two objects around that are always identical. It\u2019s just unnecessary memory.\nAnd regardless we need multiple abstract values as mentioned above. . I have a sequence of other PRs that all build on this strategy so we should do this soon (tomorrow) if so since that is blocking all of the future work.. I've gone very deep into these in various branches the past few months. So I at least know a bunch of things that will not work or result in a lot of duplicated code. :) This strategy seems simple and covers the needs for I've found so far.. An example of where this type of scenario shows up in loops:\n```js\nvar obj = {};\nvar i = 0;\ndo {\n  var foo = {hello:'world'};\n  if (i > 0) {\n    obj.x = foo;\n  } else {\n    obj.x = foo;\n    obj.y = foo;\n  }\n  i++;\n} while(...);\nresult = obj.x === obj.y; // Might or might not be true\nconsole.log('Hello ' + obj.x.foo); // always \"Hello world\"\n```\n. The partial set where each object has a known identity is already accomplished by the AbstractObjectValue with a ValuesDomain of more than one value. One such special case is the \"conditional\" kind. \nThe tests starting with test/serializer/abstract/ConditionalAbstractObject... demonstrate a lot of those cases.. Yea I'll definitely break this up into stages. I just wanted to initially see if it was feasible. Looks like it should be doable.. @NTillmann This is the Call I was referring to. I want to do the equivalent of realm.$GlobalEnv.execute but call a function value that was the completion value of the previous execution. This is a very common way to initialize internals in JS engines/browsers in a way that doesn't leak those internals onto the global object (unlike React Native).. oops. yea.. It seems like call of this belongs in a helper somewhere but I'm not sure where.. I didn't quite understand what \"node\" is. Looks like it is currently just for testing source maps. It probably should have some general \"CommonJS\" mode where you can't assume a particular version and many of the variables are abstract.\n\"node-cli\" is interesting because I think we can make the versioning very automatic based on what node version you're running but then the environment is locked to that version of node. So it doesn't quite make sense to specify it.. Is it safe to hide this for the React Native builds or does it need it for some feature detection thing?. Are factory functions guaranteed to not have any other identifiers in its scope? Such as intrinsic names, nested functions etc?. The arguments should not be collapsed into a string here. Ideally they should serialize as object references. That way when they're printed in an environment with dev tools support those objects can be viewed, inspected, expanded in full.\nE.g. console.log({}); should serialize to that, not console.log(\"[object Object]\").. \n. ToString doesn't actually get called in most console.log environments so this not predictable anyway. I believe React Native's production mode without a debugger is the only one that does. E.g. if you have the debugger attached it'll use Chrome's inspector which doesn't call ToString. Neither will Node. Node will use its own object serialization mechanism in the logs.\nIt would be very unfortunate to force Prepacked code into the ToString path.\nI think it's safe to assume that this can be deferred.. I also needed the startLine option to model contextify's ability to shift source location numbers. @kittens is there a way to do the same for columns in babylon?. I originally had it as an invariant but then I wondered if this could be messed with at runtime. Since this can get called after something has messed with internal constructors and prototypes.\nI don't think there is any mechanism to change the allocation strategy here at the moment (even if you change the prototype), but if there was a reflective mechanism to change the constructor or if this constructor was later specified to invoke a super call of its prototype (like the inheritance mechanism is set up) then it would be possible.\nThat was my defensive rationale at least. What do you think?. The goal of this string of PRs is to break out everything from #397 with changes existing code. To make it easier to review that one. I could just leave it in #397 as one big blob but that makes rebasing and reviewing harder. I could make up some artificial test case here but I'm not quite sure how to do a pure unit test since we don't really have any infra set up for unit tests. I'd have to wire up a lot of things just to test this.. Sure, but we should also use prettier for auto-formatting. It's the hot new thing to do. :) . We used to have an invariant but I guess we assumed we called process.exit(1); before that.\nIt seems like maybe this should throw an error in that case instead of logging. At least it should throw after it has logged.. Ah. I thought it was unused but I see now that it's part of a larger set of options. Will fix.. This is the awkward part. This is where we start tracking mutations to the intrinsics in the realm. Maybe this should move to init? That makes it nullable though which is awkward to have to test for everywhere.. In the node environment I'll also take on a dependency on the node-cli mode which won't work in the prepack-standalone API which can't have Node.js dependencies.\nThat's one thing that this set up unlocks.. serializer.generator cannot be atm.. This link leads to \"relay\". Copypasta. :). Note that this depends on a \"devDependency\" atm as a hack. I didn't want to add it as a hard dependency since this is still experimental and we'll just implement these directly eventually.. Note that in this PR I also use some transforms directly as a hack while we're still working out native support for them: https://github.com/facebook/prepack/pull/397/files#r114634310. This will allow hasOwnProperty as a valid compatibility.. You could just make this into an array, and then we'll hard code the values in places like src/realm.js. No need to take on the runtime dependency on the enum object.\n\"jsc-600-1-4-17\" is annoying to type but it'll likely be renamed to something more stable like \"react-native\".. If CompatibilityValues was an array you could just do CompatibilityValues.includes(str) here.. It's silently ignored in non-strict mode. In strict-mode it throws.. This test is a bit odd since a further optimization could be to not serialize these side-effects at all if the timer is cleared before the end of the tick. Since it will never execute. That optimization would fail this test.\nLeaving one setTimeout that isn't cleared remaining might be a better indicator.. It's checked into the repo already. https://github.com/facebook/prepack/tree/master/bin\nIt's an alias for lib/prepack-cli.js which gets there from the build.. This is an incomplete implementation. To run this in a completely uninitialized environment, we'll have to properly implement this. It wasn't possible when I wrote it so I stopped.\nIt'll have to emit a new kind of side-effect that invokes this during initialization and uses a mutated value afterwards.\nThis is the rest of the missing implementation is here: https://github.com/nodejs/node/blob/d56a7e640f766f15980b28d15bbf02bf60975ab2/src/node_buffer.cc#L1182-L1213\nAll of these have corresponding definitions in C in Node.\nThere are three more of these incomplete setup methods inside process:\n_setupNextTick\n_setupPromises\n_setupDomainUse. This is supposed to return a native Uint8Array in the Node environment. Not the Prepack value. It's what I pass to nativeFS.read etc. If the internal representation of DataBlock changes, I want that to be an error so that we can do a conversion from that format to Uint8Array here.. Hm. This is defined in native C code. This is related to the setupBufferJS thing below. The runtime we're currently running in has already called setupBufferJS, read from a mutated object and that's how it gets a handle on this object.\nhttps://github.com/nodejs/node/blob/v7.9.0/src/node_buffer.cc#L1197-L1230\nWe can't do the same thing at this point. Luckily this same object is reachable another way through another module which I found here.. It's defined here: https://github.com/nodejs/node/blob/v7.9.0/src/node_buffer.cc#L1209. utf8Slice creates a string from a Buffer. No side-effects. The rest of the arguments are all integers if they're defined.\ncopy copies bytes from this Buffer by mutating a target Buffer. The rest of the arguments are integers if defined. The return value is an integer.\nhttps://github.com/nodejs/node/blob/v7.9.0/src/node_buffer.cc#L524-L557. And add the invariant at each callsite instead?. Not at the moment. The strategy is very fragile because I only model the minimal needed. Which is why this whole thing is so hacky. The ideal would be to have more of an automatic pass-through or making more things abstract.. To be clear, I'm modeling private APIs here. They do change between minor versions. The rationale for picking this strategy over modeling public APIs is outlined in the PR comment.. Added some complex tests.\nWhat's the best way to define an abstract object that preserves its identity in a test?. I don't think Options should ever be required in the public API. The default should do something useful so that it is easy to try something out - even if that is just to set up the pipeline from one output to another. As you're getting something set up there are usually many other things to think about so you just want to try out those things before thinking about which configuration to use.\nIdeally we would auto-detect the best approach based on the environment used.\nIf the new mode is safer to get started with, then that can be the default but there should at least be some default.. Why are these options more important than any other option though? I just don't see the scenario where someone would want to learn about the intricate details of these optimizations. If they didn't want the global execution scope, they wouldn't have used Prepack to begin with and they would always want constant folding since its added perf cost is likely small comparatively.\nConfiguration hell has been a huge problem in the JS community recently, even coining phrases like \"JS Fatigue\", so I'm very sensitive to it. With things like Babel having individual plugins leading to presets instead and Webpack configuration being something that nobody really understands anymore. It's better to have good decisions made for you.. You could specify this as residual = false, serialize = !residual and may encode a default in both are explicitly specified as false. E.g. throw an error. That way the options and any defaults are fully resolved inside of this module.. I meant to put these in the argument destructuring position:\njs\nexport function getRealmOptions({\n   compatibility = \"browser\",\n   mathRandomSeed,\n   debugNames = false,\n   uniqueSuffix,\n   timeout,\n   residual = false,\n   serialize = !residual,\n   strictlyMonotonicDateNow\n  }: Options): RealmOptions {\n  ...\n}\nSetting these on defaultOptions isn't enough because that doesn't set the defaults if a custom object is provided. E.g. getRealmOptions({}) would yield { ... serialize: undefined, residual: undefined }.\nThese are destructuring patterns with default values. So they can be overridden if the user specifies something specific.\ngetRealmOptions({residual:true, serialize:true}) would yield { ... serialize: true, residual: true }\ngetRealmOptions({residual:true}) would yield { ... serialize: false, residual: true }. It would be idiomatic to put any optional arguments into the options objects. In fact, it's pretty common to put logging events that can be called more than once such as this one in there. E.g. as onError in the options.\nWe should also not have the fileErrorHandler here. File errors should pass the error to the first argument of the callback. This is idiomatic Node.js style that the callback of an async operation is the last argument. It should only be called once - if it completes or if it terminally fails.\nThis lets this work with this conversion to Promises in modern environments: http://2ality.com/2017/05/util-promisify.html Which is now idiomatic in Node 8.. BabelNodeSourceLocation is not in scope. Needs import.. Is there a reason this needs to be deprecated? It's not fully implemented because it was a bit tricky to wire up. It would be good to accept a Babel AST since many environments will already have a Babel compatible AST. It's pure overhead to serialize it and parse it again.. These could be moved into getRealmOptions.. This is not supported by the spec, is it? Symbols behave like other value types. Meaning they get coerced into an object temporarily but the object is dropped.. Can you add an additional test that tests this but then removes the method before serialization?\njs\nbar.foo = foo;\nx = bar.foo();\ndelete bar.foo;\nand\njs\nbar.foo = foo;\nx = bar.foo();\nbar.foo = function() {};. I suppose this works because it's an abstract object, but what if the object is not abstract but the function is?. Oh never mind my comment. I read this as fooSym[bar]. Carry on.. As long as they only read immutable properties of this, they're still pure. It's a very common pattern to export modules like this:\njs\nvar foo = {\n  bar() {\n    return x + 5;\n  },\n  baz(x) {\n    return this.bar(x);\n  }\n};\nFor this to be pure, it's enough that bar is immutable.\nYou could solve this by always calling it using fn.call(thisArg, arg0, arg1...). At least if the property is mutated/mutable.\n. I accepted this PR but it is a bit worrying that this simply gets the wrong behavior without a warning when this case is hit.\nIn a follow up, would it be worth while having a way to taint a property as assumed immutable? So that if it gets deleted or mutated after this callsite it's an error/warning?. CI is another thing to consider that needs to be automatically instantly upgraded or it'll start failing any PRs that get submitted in the time window where CI gets upgraded (which is not instantly when Flow is deployed but a different time window).. @NTillmann It's not great that this moved to the realm since this breaks the spec's notion of a Realm. We'll likely in the future need to have multiple Realms that can interact with each other and transfer objects between each other. Such as with the VM module in the Node interop or iframes in the DOM. In that world, this Symbol table should be shared.\nI don't see a reason why this has to be Realm specific instead of a global registry.\nCan we revert?. Ideally this should extract the Symbol with the key \"react.element\" from the global symbol table and compare the value of $$typeof to that so that not any object with this property name gets serialized as a ReactElement.\nUnfortunately #915 broke the spec by making the symbol table Realm specific. IMO GlobalSymbolRegistry should just move to a separate global Map so that you can just compare:\njs\nthis.properties.get(\"$$typeof\").descriptor.value === GlobalSymbolRegistry.get(\"react.element\")\nBut for now we can get it from the realm I guess.\nYou don't have to do it in this PR but we should at least create a follow up issue.. Should we only enable these plugins when options.reactEnabled is turned on? So that other code properly errors if misconfigured.. This case is also yield invalid JSX because you can't have an arrow as a \"tag\". If there is one it probably will have been serialized as an identifier by Prepack anyway.\nJust remove this case and let it fall into an error case, maybe?. This is fine if this is the a recursive call from member expression, but if it is the root then this will yield an incorrect JSX expression. <this /> causes this to be the string \"this\" since it's the HTML tag. It's probably better to error in that case than yield the wrong output.. If this identifier doesn't start with upper case then this is invalid. We should probably fall into the error case. I think this is probably quite likely if Prepack serializes a value as an identifier. Maybe Prepack needs to always use upper case identifiers or something?. If this is not a lower-case string, then this will not serialize correctly for the same reason. We should probably fail in that case and force Prepack to serialize the value under an identifier.\nE.g.\njs\nvar Foo = \"Bar\";\nreturn <Foo />;\nWill serialize as just <Bar /> but that's an identifier, not a string.. I kind of wish we had an escape hatch like <{\"Bar\"} /> in JSX.. An alternative would be to just store this in its own standalone module so that it can be reached from any module.. This should probably go through the normal property Get operations and such rather than iterating internal data structures. Since if there are getters etc. they should get invoked.. This will turn the key into null for an abstract value. I don't think that's what we want in that case.\nThe actual code for this is '' + key. That case is already handled by Prepack.\nYou could do the same by calling computeBinary(realm, '+', new StringValue(realm, ''), key). https://github.com/facebook/prepack/blob/336236d85ba90686403c12b4040d23150ac8f953/src/evaluators/BinaryExpression.js#L148-L156\nFor an abstract value it'll yield a new abstract value that is the computation '' + key.. If this is abrupt it should probably just let it pass upwards and be handled as an error executing this. So this catch isn't necessary.\nDid you run into something that needed this?. Do you plan on doing something with this in a follow up? Maybe revert this in the first PR unless it's used?. Why do you need a component by name? Won't it be enough to just keep track of a Set of all FunctionValues that we want to optimize. Should be able to have only nameless components.. Ideally this should do a full Symbol.for('react.element') comparison too.. Yea this can also be instantiated. JS VMs tend to have a concept around this shared thing. The spec doesn't have a name for it since as far as it's concerned it is everything.\nV8 calls this an \"Isolate\". JSC calls it a \"VM\" I believe. These essentially represent a single shared GC heap. Since they can share references.. This branch is kind of unnecessary now since the code in the path in the else branch will do the same thing. You could just do:\njs\nif (key !== realm.intrinsics.null) {\n key = computeBinary(realm, \"+\", realm.intrinsics.emptyString, key);\n}\nAnd not worry if it's concrete or abstract.. This is actually incorrect. The $Description of the symbol is basically the toString but not necessarily the global key.\nE.g. this is false:\njs\nSymbol('react.element') === Symbol.for('react.element') // false\nBut they both have the same description.\nYou want to check e.$Key just like Symbol.for does. https://github.com/facebook/prepack/blob/521d5df69c553b71b266cbd20ab035fd41047d10/src/intrinsics/ecma262/Symbol.js#L47-L52. Why ignore symbols? Ideally there probably shouldn't be any but if there are, they're probably ok visiting.. Why is this special case needed? The $$typeof symbol is an intrinsic and so it should be fine visiting.\nThe _owner probably does need to be serialized if it is set to anything other than null (but ideally it should always be null here).\nI'm not sure why you need any special cases here?. Same thing. Why isn't it ok to visit the prototype? It'll just be Object.prototype which is intrinsic anyway.. ok. I still don't understand but maybe I missed some previous thread.. It might be useful to land a separate PR for the test infra changes and some basic test that you then update in the follow up since the rest of this might need more review and by different people.. This helper relies on a lot of implementation details. Can you find a way to use the public API to express this?\nThe typical way you'd create something like this in the public API is by prepending a set up script like:\njs\nrequire = __abstract('function', 'require');. It's weird that this doesn't return an object for some objects. flowAnnotationToObjectTypeTemplate?. This filename doesn't tell me much about what this is doing. I had to guess. Can we put something in the filename and preferably the folder name about this being specifically about turning Flow types into Abstract Objects?\nNot any other Flow support such as preserving annotation and adding more while cross-compiling.. You can keep the tests in this PR but in the infra PR you can just have a single test that does it('succeeds', () => {}) and just checks in jest and such. If there are controversies about using jest or the yarn file update, we can keep it to that PR. But it'll also help review this one since it'll be fewer files to think about once the infra one lands.. You can still stack this on top of the other.. I don't think we want the public API to expose an entire realm and all internals like ObjectCreate thought, right? We wouldn't want someone else to use it this way since these can break at any point.. @cblappert This is unrelated to this PR. I saw that this pattern was added in the additional functions one, but why do we make these a public object instead of just an internal Map? Seems weird for the compiled script to be able to reason about this and mutate this.. Can we just use the code from the upstream package rather than copy then?. If we can't use the code as is by reference, we should document the exact differences but we also need to include copyright header (which is McKenzie I guess).. typo. Sebastian < I'm pretty sure that's how you spell it. :). Checking isReactComponent is a bit safer.\nhttps://github.com/facebook/react/blob/master/packages/react-reconciler/src/ReactFiber.js#L224. @NTillmann This is not part of the tracked properties list (maybe it was at the time of the comment, didn't see what changed). Does it still matter?. Suggested rename: $BailOutReason\nI wasn't sure if this was an indicator that something should bail or not.. This return type is probably any or Object right? Might want to make that a more specific return type here. I.e. ObjectTypes.  That way you can track it properly through all the other callsites instead of having be any all the way and then later cast it.. Curious. Do we use constants as enums this way anywhere else in the code base? Typically we just use strings everywhere since Flow is a guarantee that you don't have any typos anyway.\njs\ntype BranchStatusEnum = 'NO_BRANCH' | 'NEW_BRANCH' | 'BRANCH';\nAnd then you can just use the string at the callsite.. This is on objects owned by React. Even if someone creates another one it'll be to pretend to be us and have to subscribe to those conventions.\nWhat could potentially happen is that we deprecate it and add a warning message as a getter.. Just to confirm, this will be a StringValue for empty string, right? So empty string still passes through.. This might not be safe in DEV because these objects are frozen (Object.freeze). We should probably go behind the scenes in this case to by-pass that.. What is this for? I see it pass around but not created anywhere. I assume it'll be used for classes somehow. How?. I'm not sure this is safe for all possible abstract values. Maybe add a TODO to investigate which ones are safe and not?\nE.g. in conditionals, isn't the first arg the condition?\nSo we would turn this:\njs\nfunction Foo() { return null; }\n(<Foo /> ? <Bar /> : <Baz />);\nInto this:\njs\n(null ? <Bar /> : <Baz />);\nWhich changes the semantics.. We could probably ideally also support iterables here. E.g. for people mapping over immutable-js stuff. No big deal.. This is effectively a bailout because it is an object that we don't support yet. E.g. iterables as children. I wonder if we should annotate this with a bailout reason?. Should we consider this a bailout reason (with a message) too? Basically we don't know what this is and therefore we had to bailout but it might not be obvious why that is. E.g. if it's abstract for some reason.. How can this be null? Isn't the return type of of result always Value? Might help with an annotation.. If the result of this is a fragment or abstract value, then you don't apply the branch logic? Seems like that could lead to bugs. Be careful about dropping the \"else\" conditions for things like this.. What if we do:\njs\n} else if (error instanceof FatalError) {\n  this._assignBailOutMessage(value, \"Evaluation bail-out\");\n} else {\n  throw error;\n}\nSince most errors that leads to bailout should probably be FatalError according to the new Prepack convention if I understand it correctly. E.g. due to abstract values.\nIf it errors for any other reason, then it is likely a bug?\nIt might error for other reasons like \"completion\" objects being thrown. E.g. if user code throws. We can add them to the whitelist of \"approved\" classes of errors that we expect as we find them.\nThat way arbitrary bugs in Prepack would kill the compiler instead of bailing out the optimization. So that we can fix them.. Why is UndefinedValue special cased but anything else is not?. You could use the return value of this to detect if there are any mutations on objects other than newly created ones. Then log those to the error logger. That'll help us track violations in components. :) . Hm. Actually, this really is only about conditionals, right? Does any other abstract value actually work? Maybe we should bail out on any abstract value that isn't a conditional?. I think this is a bug. If both branches return the same component type, then we shouldn't append a unique key to it. It's only if the two branches have different component types that we should. Maybe add a test for this case:\njs\n<div>{abstractVal ?<Foo arg={1} /> : <Foo arg={2} />}</div>\nIn this case state should be preserved.. This seems to look for render. The original function is checking for isReactComponent.. This is an all or nothing approach but that doesn't cover more than two branches.\njs\n<div>{props.a ? <Foo arg={1} /> : props.b ? <Foo arg={2} /> : <Bar />}</div>;\nIn that case I think you need to add add a key but the same key per component type.. js\n<div>{[<Foo />]}<Sibling /></div>\nDoesn't preserve state when it switches to:\njs\n<div>{<Foo />}<Sibling /></div>\nBecause the nested array is in its own slot. I don't think this takes that into account.. They are not necessarily going to get returned from the pure function so they won't always leak that way. They also won't always leak into the called abstract function.\nThey only have the potential to leak. Maybe \"leakable\". That is also a bit confusing because there other objects than these passed to the abstract function too. They don't \"leak\" because they were already in the outside world.. I'm hesitant to call them \"leaked\" since they won't all have the \"hasLeaked\" flag.\nobjectsTrackedForLeaks?\n. If you pass global as an argument to an abstract function it won't be newly created so the visitor should have bailed out before you get here.\nThere isn't inherently special about global vs other intrinsics necessarily. However, if you do hit the global it'll pretty much reach the whole heap so it's better to bail out before it goes into some infinite loop.\nWe could check other intrinsics but since the intrinsic name is useful for other things (e.g. in the Node CLI there are a lot more intrinsics created than just built-in objects). It seems sketchy to assume something very specific that doesn't really have anything to do with the fact that it has an intrinsic name. E.g. I could call a function and have that object return an intrinsic object that can be recreated by calling it again.\nThe global object is one that is at least inherently to have been created before the additional function. There are more on that list but this is probably enough to help debugging.. This is emitted on a newly created object so it won't be. Basically it serializes its initial state here, but it can have multiple initial states if there are several branches. I'm not very happy with this strategy though.\n(If anything, the property assignment above isn't safe if Object.prototype has properties that are non-writable, but we assume they don't.). It is also flagging them as ~tainted~ leaked.. AbstractValues can end up here too. Used to quickly bailout from traversing through them.. mustVisitOnce?. The idea I had was that invoking an unknown getter/setter is just the same as invoking an unknown function. So if you do that on a leaked object, it would generate an effect just like calling a function on it would. The object would \"leak\" again so any properties that are known at that time would be reset again.\nFor setters, it would also leak the value passed into the setter.. Ok.. Yea, in this case that seems pretty straightforward. Although this suffers from the same problem as the object flag. It really should vary between branches and get joined.. Yea, I'm not really sure about what to do about this one. It is nice to avoid having to taint other branches when only one is unknown. However, if we keep this diverged path, we need to deal with it in the Binding case too.. Yup.. Yea this is surfacing a bug in _mark which I'll fix by only bailing out if it's an ObjectValue and newly created.. Yea. Not sure about this. The description could be abstract, which could have objects as their arguments, but since there is no way for code to access those, I think it is safe to never visit symbols. Will remove this path.. Newly created objects within evaluatePure. They may not have been exposed to abstract function calls yet. These are the objects that have the potential to become leaked.. Wouldn't it be nicer to infer this in the serialization step by reading the function body? That way if it is actually in the code, then it gets automatically stripped?. I think this strategy won't let us support things like static initializers since those values need to be visited.\n```js\nvar cycle = {};\ncycle.cycle = cycle;\nclass Foo {\n  static bar = cycle;\n}\n```\nIt probably will miss properties added to methods, right?\njs\nclass Foo {\n  bar() {\n  }\n}\nvar x = new Foo();\nx.bar.taggedFunction = cycle;\nIs it even possible to serialize a reference to a method?\njs\nclass Foo {\n  bar() {\n  }\n}\nresult = {\n  Foo,\n  bar: new Foo().bar\n};. This can also be inferred in the serialization step just like we do with other computed properties. https://github.com/facebook/prepack/blob/master/src/serializer/ResidualHeapSerializer.js#L418\nI also think that this probably doesn't cover added methods after the fact?\njs\nclass Foo {\n}\nFoo.prototype.bar = function() { };\n. The name suggests to me that it would contain a list of properties. Maybe call it something like methodData or something?. Just because this method was originally defined on this class, doesn't mean it still is the same one.\nE.g.\njs\nclass Foo {\n  bar() {\n  }\n  baz() {\n  }\n}\nFoo.prototype.bar = Foo.prototype.bar.bind({});\nvar baz = Foo.prototype.baz;\ndelete Foo.prototype.baz;\nresult = { Foo, baz };\nWe should test that the property on the class is still the correct one.\nIt's probably fine not supporting this yet, but we should at least fatal and not generate subtly wrong code.. Static class methods also have home objects and will end up here but they will be serialized as an instance method instead which is wrong.. If so, can you add a unit test for it? With and without a super call in the static method.. Basically, I'm saying that it doesn't matter how it was originally created. It matters more what is currently there.\nSo class Foo { ['foo']() { } } should be able to serialize as class Foo { foo() { } }.\nI'm not sure I understand how later mutations to the prototype gets serialized. Like this:\njs\nFoo.prototype.bar = function() { };. Not every instance of a class has a constructor. E.g.\njs\nclass Foo { }\ndelete Foo.prototype.constructor;\nThis could also be a getter which could be problematic.\nThe prototype on the constructor also not be the same anymore. E.g.\njs\nclass Foo {}\nresult = new Foo();\nFoo.prototype = {};\nor\njs\nclass Foo { };\nresult = Object.create({ constructor: Foo });\nThe only reason this needs to be serialized as a class is if any function remains that has this as the HomeObject. Otherwise it can just be a normal object.\nAnother solution might be to just tag the ObjectValue of the prototype at construction time just like the constructor is.. Same concern here as the other one. This is not a \"safe\" property to check.. Super is special because that can't be serialized as:\njs\nclass Foo extends Bar {}\nFoo.bar = function() { super(); };\nSo it surfaces accidental wrong serialization.. You could use a Set or WeakSet for this instead so that we don't have to add another field to ObjectValue that is already so bloated, and has complexities like the merging of values in different values and changes over time. Currently the layering between the interpreter and the serialization step is pretty clean. Ideally the additional functions/reconciliation steps should also be cleanly separated from the serialization. This can start mattering more as we're considering new serialization formats such as byte codes. With bundle splitting you may also need to serialize this same value into multiple serialized outputs and then it's cleaner to have this concern exist once per serializer potentially.\nIs there precedence for other serialization related caching using additional fields?\nThat said, nothing else needs something like this because it is added to the set that tracks which values are already visited. Can this just use that mechanism to bail out early?. Maybe we should be sure that this check is exhaustive since this might miss some things? E.g. check isPrimitive and throw an invariant if it's not a known type? . So this is not strictly safe because these objects are mutable and any mutation would be shared.\nWe probably should document the rationale for why we think that this is safe so that we can compare against that rationale to see if this is the correct implementation.\nThe rationale used in the Babel transform might not apply here because that might use things like object literals as a heuristic where this doesn't.\nWe also have another thing that is not strictly safe where if two JSX elements have referential equality, we always bailout regardless of sCU. The rationale is that most JSX elements are created in render functions and don't live in state with mutations.\nI believe that it probably is safe given the rationale above and the fact that this optimization only applies in the particular optimization we already do. But I'm not 100% sure this is safe yet. . @cblappert Prepack already has lazy initialization of objects that are referenced by multiple additional functions. Can we just reuse that instead of reinventing it? I'm concerned about getting the details right.. I was thinking that we should be able to hoist newly created functions too, assume that the function doesn't close over abstract values, like any other object.\njs\nfunction Foo() {\n  var Bar = () => <div />;\n  return <Bar />;\n}\n->\n```js\nvar Bar = () => ;\nvar _bar = ;\nfunction Foo() {\n  return _bar;\n}\n```\nBut then I realized that this is not equivalent since we use the identity of type to determine if state is preserved and it would be a new one every time.\nThe same quirk applies to other objects too though. So maybe we should just live with that?. I'm not sure about this hoistedScope heuristic. We use additionalFunctions to serialize an entire React app behind a branch (as opposed to a CS app for example). Then we would use the React optimization inside the additionalFunction serialization. So there are really two \"main\" scopes. I'm not sure it is safe to assume that there are only two scopes. I think this can end up screwing us.\nI think we might be able to hoist even more though.\nI think that we can hoist local functions too. It doesn't really have to do anything with the scope itself. It depends on what the function closes over. So what you could do instead is visit the environment bindings in the function and see if all of those can also be hoisted. I.e. they don't have abstract values. That way you don't have to use the hoistedScope heuristic.\nE.g. this <div /> should be hoistable even though it is referencing a local function.\njs\nfunction Foo() {\n  var foo = {hello:'world'};\n  return <div onClick={() => console.log(foo.hello)} />;\n}\nIf you implement this by scanning the function properties and closed over environment you can avoid the hoistedScope check.. This also needs to check symbol properties and the prototype.. This isn't really that nice for pluggability. E.g. other plugins won't be able to have the same flexibility to keep adding flags.\nWhat do you think about using a WeakSet in react/reconciliation instead?\nAny ObjectValue won't be particularly fast anyway since they have so many properties. This will be a map-like expando/lookup regardless. So a small\u00a0WeakSet might actually also be as fast or faster.. So if I understand this correctly, we assume that it is a class component if it passes the first time but if it fails the second time (e.g. if the known props are different for the second usage of the class), then we assume that it is a legit error?\nSeems a little random and fragile since just reordering the order that these two cases get serialized will either fail or pass.\nShould we just always try the simple path if it is possible for every particular render?. This still has the same problem that if we have two components which will pass in one case and not pass in another case, then it will seem pretty random when it does and doesn't switch to the complex mode.\njs\nclass SimpleOrComplex extends Component {\n  render() {\n    if (this.props.data) {\n      this._cache = computeString(this.props.data, this._cache);\n      return <div>{this._cache}</div>;\n    }\n    return <div>Default</div>;\n  }\n}\njs\nfunction Foo() {\n  return <SimpleOrComplex data=\"hello\" />;\n}\nfunction Bar() {\n  return <SimpleOrComplex />;\n}\nfunction App({c}) {\n  return c ? <Foo /> : <Bar />;\n}\nDepending on if we happen to visit Foo or Bar first, or if the user inverts the condition in App, this will either fail or not.\nI'd rather have this be more predictable. E.g. always try the simple mode first and callback to complex. I.e. just remove the classComponentTypes cache.. It matters if it is passed to something that doesn't get inlined though.\njs\nfunction Foo() {\n  var Bar = () => <div />;\n  return <NotInlined><Bar key=\"foo\" /></NotInlined>;\n}. typo. ClassProprtiesToIgnore -> ClassPropertiesToIgnore.. Can this happen? If it can never happen, then this should be an invariant, but if it can, then we should have a test for it.. It is kind of a hint because it is a hint that we should try to serialize this as a class body instead of an object literal. It is possible that this doesn't need to be serialized as a class and that this is unnecessary (e.g. if it has no super calls). It is also possible that some functions that are not defined as classes in source would be better off being serialized as a class. E.g. a lowered Babel class can probably be turned back into a class.\nWe could determine either one based on some other heuristic but for now it is a hint.. It is not always safe to ignore these. E.g. this example:\n```js\nclass Foo {\n}\nObject.defineProperty(\n  Foo,\n  'length',\n  { value: 2}\n);\n```\nIf you look at how this is handled for other functions, you see that they're only conditionally ignored.\nhttps://github.com/facebook/prepack/blob/ed40a493e2dff76e61158458e553ad6e7ce975bf/src/serializer/ResidualHeapInspector.js#L82-L106. This function should be typed using generics and a specific function signature. All these functions passed here are inferred as any right now.. How do we know this? If this is a string but an invalid identifier like class Foo { [\"foo bar\"]() { } } then it still must be computed.\nOr if I rename this:\njs\nclass Foo {\n  bar() {\n  }\n}\nFoo.prototype['foo bar'] = Foo.prototype.bar;\ndelete Foo.prototype.bar;. rm only. Usually it is used with some kind of operation described in source.\nhttps://github.com/facebook/prepack/blob/f7b0cb8ecd099e5fc5ef8a8b6aff8bf791664782/src/intrinsics/ecma262/BooleanPrototype.js#L21-L22\nHowever, this doesn't have an equivalent operation since it'll be implicitly called. I just need this to reference the original value.\nI could just return the original expression but the problem is this invariant:\nhttps://github.com/facebook/prepack/blob/master/src/serializer/ResidualHeapSerializer.js#L1483-L1486\nIt makes too strong assumption about what an identifier as the top node means. It is still useful to have though and I don't really want to refactor that whole thing.\nSo I wrapped it in a sequence expression to workaround that issue. Creating a sequence expression from source seemed very fragile though since the parser can easily remove it when there is only one expression.. The primary goal of this is to set the TypesDomain to one compatible with ObjectValue. That in turn causes this to be an AbstractObjectValue which makes the rest work.\nAs a consequence the ValuesDomain becomes top but it probably doesn't have to be. It could be something more precise.. I think that I'll actually remove this one. I wanted to ensure that we always have a warning but this will be covered in other places anyway such as in $Get in this case so if you recover it'll be issued twice which is unnecessary.\nWe also need any solution to #1264 to be colocated with the op that actually forces this so it doesn't make sense here.\nI'll add a test for the other one though.. Ok I made a new createFromCoercionOp.. Hard to say how useful it is to provide the build function since every other case that needs to do this currently uses createFromTemplate to do it.\nIf this is truly just a \"cast\" without runtime semantics, then it seems that going through the builder mechanism is unnecessary and we should really just make this a straight alias.\nI don't know how to fix this invariant if I don't wrap it in a sequenceExpression.\nhttps://github.com/facebook/prepack/blob/9949c16e45fca7c38a4719867a81c33a20cb6e21/src/serializer/ResidualHeapSerializer.js#L1483-L1486\nI'm pretty sure that this check is too aggressive but I'm not familiar enough with the serializer to know how to fix it.. What does hash 0 mean?. This should be ap = [c.consequentEffects, ...]; I believe.. Why does this matter? I didn't think our runtime depended on .length.. But that should still work, so does the unit test in this PR work before and after this change? If so, then we should add another test that tests this specifically (e.g. by reading the function length).. To be able to do that safely, and also stay performant/small, we would need to be able to determine that this did in fact never leak and that this value is only referenced once. That way we can remove the explicit ToObject operation as an optimization in the serializer. That seems like a lot of work for something that currently can't happen but might be something we need for other reasons and then we can change this back.. I just ran it locally and it doesn't fail even without the fix. What am I missing?. Can you explain why this matters to the serializer? Why does the serializer care what the value of length is?\nI understand that it can avoid setting the property sometimes but sometimes it needs to set the property anyway.\nI'm worried that this won't work if the length is explicitly defined, e.g. by some compiler output. I'm also just worried that I don't understand it. :) . Yea I understand that we'll want this change regardless for perf/size reasons but I wonder why it breaks right now. Might be revealing some other bug.. @trueadm Explained to me that this is actually unrelated to the fix. It is the .kind change that is the fix to the bug and this line is just an optimization.. The ToObjectPartial call already does that check, and if this can safely coerce to an object for any other reason, then I figured it probably should.. Is this why this is only a partial fix?. Why do you need to wrap this? We have other places where we traverse function bodies without \nAlso, this is suuuuper slow. So let's a add a todo about fixing this and unify with other things that traverses and caches.. Is there any time that a ThisExpression doesn't have name === \"this\"?. There are other operators like += that are also assignment. Do they not count?. Technically you don't need to, but I guess it's most likely that you would.. Can we put this inline into the generator function since it is related to serialization? It will only be called once anyway so it shouldn't matter. However, most of the time that path will never taken so unnecessary to eagerly test for this.\nHowever, this test is also not sufficient because it doesn't test for all possible invalid identifiers. It should test for isValidIdentifier. Like this: https://github.com/facebook/prepack/blob/9081d3bf3f70585411d1c9c0bc2e5db07bae532e/src/evaluators/CallExpression.js#L125\nThe last check here P instanceof AbstractValue is never going to be true because there is an invariant below that checks that typeof P is a string so not sure why that is needed.. We should call this function something else. This call itself is not pure but it is in a pure context. The thing that we're doing is attempting to evaluate it but if we can't, we fallback.\ntryToEvaluateCallOrLeaveAsAbstract?. @hermanventer Does this check seem ok to you?\nThe idea here is that we can optimistically evaluate something but that causes a prepack error (as opposed to a throw completion), we can fallback to treating the whole call as abstract.. This will never be undefined because of the early return or throw.. This change still triggers an error to be logged and which needs to be explicitly recovered from.. Hm. Why doesn't this need recover-from-errors? Seems like it would trigger some error?. This is only checking the top value not if it is nested.. Why delete this test?. Yes. Let's find out.. Although I'm actually curious if this is actually used because if it is, it might not be assigning any properties to it so it would be broken anyway.. These won't matter since you're just going to throw before this function can do anything useful with them anyway.. returning from a setter doesn't do anything. What is this suppose to test?. Just do:\njs\nif (to.isSimpleObject()) {\n  to.makeSimple();\n}\nThis seems weird. Like why mark something as simple if it already is? Well, it is because the first read is derived from a bunch of considerations. One of those considerations is whether it is partial.\nLater it becomes partial and that switches the default to false. So if we set it explicitly in the beginning, then it'll remains simple even when we make it partial.\ncc @hermanventer This seems a bit odd in the model that isSimpleObject switches property like this when it becomes partial.. Hm. I guess there is no way to make an object not simple again after it has once been explicitly declared simple. So maybe this is not such a good idea.\nThe unit test is an example of this when a Object.defineProperty happens after the assign.. This makes this object permanently simple even if we do:\njs\nvar x = Object.assign({}, partial);\nvar y = 0;\nObject.defineProperty(x, 'foo', { get() { y++ } });\nObject.assign({}, x);\nresult = y;\nWe need that defineProperty to unmark this as simple.. If that's the case, then it seems to me that we should only set this explicit flag if we end up in the unknown partial case. I.e. we have any properties that are unknown.. Yes, and also evaluateWithPossibleThrowCompletion since it might throw.. Yea, this is just because we don't have a different mechanism for storing intermediate snapshots that doesn't also leak.. We could implement a wrapper function for these cases that just leak as an implementation detail for now. That way we can expand on it later if needed.. It may affect the state of leaked objects so when it is invoked matters.. It also needs to track when it might throw so that we can later wrap the operation in a try/catch.\nThe problem is that we don't always need this to be temporal. Only if the arguments has some unknown valueOf semantic or similar side-effect. We should be able to communicate that from getPureBinaryOperationResultType.. Yea, I wasn't sure about this one so I just did this to communicate what change I wanted which was easier this way than forking the whole function.\nI don't think wrapping is the right way to model this, because it is the op that is temporal, not the value it results in. I can see that leading to serialization bugs.\nThe serializer doesn't know that the value that the temporal depends on is actually temporal so it can serialize it where ever and then just refer to that value.\nE.g. we'll want to wrap some of these temporals in try/catch and if the serializer decides to serialize the inner value separately, then the temporal value just refers to that you end up with:\njs\nvar value = left + right;\ntry {\n  var temporalValue = value;\n} catch (x) {\n  ...\n}. Yea this was not intentional to make the default true. I switched from isPure->isTemporal and forgot to switch the default.. If I just report an error here, we don't solve the problem that we're hitting where we want to be able to leave these calls in place.\nSo I'll have to do the catching in computeBinary. That seems reasonable.\nIn general I want to make sure we don't unnecessarily leak too much by not considering the knowledge that we do have at this point. It's probably unlikely to matter for this case though.. The last two todos are not addressed by this PR. They should remain.. Ok. I'll add a comment.. The .call method is not bound to the hasOwnProperty function so that doesn't work because the call function needs this to be the ObjectPrototypeHasOwnPrototype function.\n. Actually, I'll hoist them out because I don't want to assume ToPropertyKey is pure since it's not.. To say it another way, this is not valid:\njs\nvar hasOwnProperty = Object.prototype.hasOwnProperty.call;\nhasOwnProperty(obj, key);. This seems like a new error message that we need to add to the wiki. Probably shouldn\u2019t take the number one spot for this one.. Should we call it firstRenderOnly? It won\u2019t execute on the server and we\u2019ll probably want different output modes for server rendering and client first render so we\u2019ll need to separate them.. firstRenderOnly -> includeFunctionBodies. Instead of mutating setState directly, we should change the .updater which what React normally does and includes replaceState and that stuff too.\nThis can otherwise lead to weird effects due to this being an own property and overriding inheritance chains when people override setState which is on the base class.. Let's follow up in a separate PR to reuse React.Component logic from the react package which uses the updater in a separate function.. I think the notion of the \"pure\" mode is causing unnecessary confusion since it really shouldn't really need to be a mode at all.\nIt should be safer to always use this logic, whether you're in a pure scope or not. It is just that if you're not, the global object also needs to get havoced as soon as any unknown side-effect happens.\nThe purpose of the pure mode is just to scope the consequence of the havoc, not to change anything about the havoc logic such in this place.\nThis branching only fills two purposes: 1) Possible performance optimization. 2) To allow the normal (non-pure) mode to assume that these are pure and recover when they might not be for deeper optimizations (avoiding havoc). Maybe this should go into an \"unsafe mode\"?. We don't have a way to do this today though? I don't see anywhere this is done for abstract expressions. Seems like that'll have to be a larger issue to go back and provide source map hints for all these residual abstract expressions.. This code gets complicated by trying to retain this resultType. If I can instead assume that this type will always be the same as AbstractValue.createFromBinaryOp(...).getType() below, I can simplify this code. I think that should be correct.. This should just use a function declaration and a lower case name. The upper case one is a FunctionValue, not a function like the one.. Good catch. That's a good point about in. I will need to havoc only the first argument.\nI didn't realize hasInstance was available on non-proxies so I will have to havoc both.. What is the intention of \"Recover\"? It is somewhat saying that we assume it is \"well behaved\" but what does that mean? Must it have a specific meaning or can it be broader in some sense of what we expect will happen?. This is not a very helpful comment. :) Why does it fail if you don't?. What does normal mean?. Why is this for first render only? Can't we always fold context if we know its provider?. Why is this first render only? If we know the value (which might be abstract), it should be fine for updates too. Since it's abstract it'll be able to update.. I don\u2019t know if getting a snapshot should imply losing information about all properties.\nI think of the typical use case for a snapshot as calling a pure function with a mutable object.\njs\nvar obj = {foo: \u201cx\u201d};\nvar x = pure(obj);\nobj.foo = \u201cy\u201d;\nvar y = pure(obj);\nIn these cases we don\u2019t want to forget about the properties. It seems to me that forgetting is a special case.\nIt also seems odd to only forget properties and not any other internal values, prototypes etc. Forgetting properties seems very specific to Object.assign specifically so maybe it should move there?. I don't think this is safe because we don't know anything about this object's identity. It might have the same identity as something else in our heap. Normally we don't allow mutations on an object that doesn't have known values in the domain:\nhttps://github.com/facebook/prepack/blob/master/src/values/AbstractObjectValue.js#L482-L485\njs\nvar obj = {x:'a'}\nvar abstractObj = doSomethingThatYieldsATopValObjectFrom(obj);\nObject.assign(abstractObj, {x:'b'});\nresult = obj.x;\nIn this scenario, Prepack doesn't know that obj could've been mutated.. This doesn't deal with symbols, prototypes, or anything except string properties. Should it be renamed to something more specific like getPropertiesSnapshot?. Btw, Object.assign works on symbols too. So you'd need to do this for the symbols map too.. This should say \"not serialized\", right?. We've talked about, in the future, handling abstract functions that are marked as pure (not in a pure scope but just calling a pure function anytime). Those should not need to havoc.\nTo implement that, we'd need some form of snapshots.. That's an interesting point. Should these intrinsic objects be modeled as a single element (template) which is a partial object, instead of topVal? Why would you want to model an intrinsic object as topVal?. This should at least have a big comment clarifying this then. It's sometimes hard to tell if it is safe to use a method, when adding a new feature, if it is partially implemented.. I may have been wrong about this. This function is used by Object.isFrozen(obj). I'm not sure if we should return true for that since technically it is not runtime frozen. We should probably just move this check into Havoc at the same place as the TestIntegrityLevel call.. IMO, we can just add this field directly to ObjectValue but let's check with @hermanventer and @NTillmann if that's ok.. It's not just bound functions. It's all functions that are not ECMAScriptSourceFunctionValue, right?\nvalue instanceof FunctionValue && !(value instanceof ECMAScriptSourceFunctionValue). This pattern match should probably be exhaustive. A whitelist instead of blacklist. What values are valid here?. You also need to havoc the constructor since it is passed to new.target or the prototype is passed as a newly created object.\nMost of the time that won\u2019t matter since the constructor is defined outside the pure function so it won\u2019t be havoced but if it is defined inside the function it can matter. . Children passed in should not be marked as final. Only children arrays created by React.. A delayed reference might have issues even in pure scope. We might need to keep this warning and prevent this earlier.. Adding a check for isInPureMode is almost always a cheat that will lead to incorrect results because there are no assumptions that shouldn\u2019t be covered by havocing. Anything else is an optimization. So if this isn\u2019t safe in non-pure mode it needs to at least havoc something.\nI really want to remove the pure mode because it leads to incorrect assumptions about how we can cheat in this mode.. The simple object check is to ensure this can\u2019t have side effects. If no such guarantee exists we need to havoc this object, the receiver and the property key value.. The above code is not valid if the receiver is not the same as this. At least not unless we\u2019re sure it\u2019s not going to be a getter.. Currently we can\u2019t really write tests against this code path because abstract object values can\u2019t be the prototype of an object. I have an open wip pr to fix that so that we can properly tests this.\nHowever the reason this fires in your case is because the receiver could be a primitive that was coerced with ToObject and therefore they\u2019re different.\nWe could perhaps make a special case for that scenario which is slightly different than accessing through a prototype chain which is the case I was worried about above.. This is not safe for the case when this member expression will be used as a write instead of a read.\njs\nfoo[bar] = 123;\nThe generated code will try to treat this as a value. Probably generate something like var $1 = foo[bar]; $1 = 123; or something incorrect.. This one is pretty straightforward but the other places where this happens are not as straightforward. So I think we should probably wait and see what other patterns happen before we jump to abstractions.. Originally I kept a path for widened values just like this one:\nhttps://github.com/facebook/prepack/blob/master/src/values/AbstractObjectValue.js#L251-L262\nBut these are actually unused right now because widened values always end up as topVal. I started working on making widened values a bit more specific so that we can use this information but I'm not currently working on that so I just switched to an invariant instead for now.. Yea I'm pretty confused about best practices here. I wonder if we should do a pass over everything. It's hard to change a convention when the old one is still there. In www we typically have the policy that if we want people to use a new API we first codemod all the existing uses.\nCan you point to an example that is doing this correctly that I can follow?. Yea, it seems like this is already the case in many other places. Even in this file it was already the case. Since it is in many place I don't really want to change that definition in this PR but maybe a follow up. I'll change this to a todo with an issue.\nIt seems difficult to guarantee that simple objects don't have valueOf/toString though. E.g. Object.assign can return a simple partial object I think but how does it guarantee that there are no keys with valueOf and toString?. I also added this string coercion which fixes #1676.\nIt is also required when the key is not an object, which allows me to test the havocing behavior of object keys with side-effects.\nI'm not sure where to best put this helper. The normal ToStringPartial is expected to return a string value.. I separated out the \"prototype\" one which is very different.\nThere are 4 property access ones that are very similar. Note sure how important it is to distinguish all. Maybe they should be centralized somewhere. I guess we'll see when they popup if they need something more specific.. IMO, it's a bit better to reference the intrinsic value since we don't know if this context is going to be shadowed or even if the global property has later been renamed.\njs\nfunction foo(Object) {\n  return Object.x;\n}\nChange to realm.intrinsics. Object.. This call is not equivalent to ToObject because ToObject throws for null/undefined.\nWhere as this would return an empty object:\nhttps://github.com/facebook/prepack/blob/master/src/intrinsics/ecma262/Object.js#L53\nYou'd have to check for null/undefined.. All these cases above should never happen because they should never get an explicit conversion because the wrapper doesn't create an explicit conversion to object. It gets serialized as one of the other object constructors.\nhttps://github.com/facebook/prepack/blob/master/src/methods/to.js#L409-L428\nMaybe add an invariant instead to ensure this remains the case?. @NTillmann Should this be lazy in the builder or outside the builder? Seems like you had some thoughts on this.\nIs technique guaranteed to dedupe with other residual references to these?\nSuch as:\njs\n(function() {\n  var getPrototypeOf = Object.getPrototypeOf;\n  residual = function(o) {\n    return getPrototypeOf(o);\n  };\n})();. This ensures that if we throw a fatal if we're not in pure mode already. It is the equivalent for what _dereference does. https://github.com/facebook/prepack/blob/88fbdcc47b15a38ac4369b7eeb893e2d62eedba2/src/methods/environment.js#L137-L141. Not all callsites go through $SetPartial though. I guess ideally they should, right?. Hm. This is an interesting case.\nObjects are free to have getters even in pure functions as long as they only mutate things created by that function.\njs\n({\n  _foo: null;\n  get lazy() {\n     if (!this._foo) { this._foo = compute(); }\n     return this._foo;\n  }\n})\nThat's why we're resilient to these in abstract function calls which might invoke them.\nWhat makes this case particularly interesting is that the getter is not invoked until after it leaves the pure function. So it is React itself that is causing this effect. Not the user code.\nIf this mutates something that was returned from state, then that already existed at the time of the call. So the read call is not pure, which makes that intermediate operation not pure.\nThere exists a pure operation in between getDerivedStateFromProps (pure), and render (pure). I guess we can call it the \"getMergedState\" function. And if there is a getter like this on the partial state object, then that makes that hidden function not pure. That breaks the rules of React.\nSo I think this is technically in line with our rules to assume it doesn't have mutating getters.\nNow whether it can throw is another issue.. It is fine if the getter is invoked inside gDSFP because that's the function that created it.\nThe issue is that it leaks and gets called by the functional getMergedState function. The getter wasn't created by the getMergedState function so in that context it breaks the rules.\nAnother way to break the rules is accessing the getter in render.\n```js\ngetDerivedStateFromProps() {\n  return {\n    obj: {\n      _foo: null;\n      get lazy() {\n         if (!this._foo) { this._foo = compute(); }\n         return this._foo;\n      }\n    }\n  };\n}\nrender() {\n  var x = this.state.obj.lazy; // side-effect in render\n}\n``. Returningfalsehere seems odd. Why not justnull`?. Instead of adding this extra conditional, you could just make all the \"else\" branches where you return false, just return the prevState instead.. It seems pretty leaky to have this in the React utils. I've change the structure of this in the past and probably will again so would be nice to have this centralized... if this is a legit technique.\nIt should also be named something else because for conflicts it'll prefer one effect over another. Effects can't just be arbitrarily joined since they have conflicts.. This can override a binding that already exists.\nI think we should forbid any of these effects to have binding and property modifications unless they're part of a newly created object (so and po respectively). That way there can't be a conflict.. The precedingEffects arguments seems difficult to use from the outside since it is highly dependent upon what is in the c argument. Perhaps, it should be private and the public API shouldn't allow this argument.. Instead of evaluating and applying it, can't this be expressed as a pure join of the effects?. Whenever we generate temporal values like these that might throw, we have to wrap it in realm.evaluateWithPossibleThrowCompletion. We've been sloppy with that but we should be more careful about that.. evaluateWithPossibleThrowCompletion. What's this about?. evaluateWithPossibleThrowCompletion. We have to havoc the items because it can container getters or iterators that gets invoked by the iteration.. This shouldn't need to be abstract and we might actually need it to not be. We know for sure which object this will be when it is created.\nThis can be a concrete object with a prototype of Array.prototype. It just needs an unknown property. E.g. a widened property.. This also doesn't need to be abstract. We know which object this is.. Why does the thisArg matter? We know the implementation that it is going to be passed to.. We should move this into AbstractObjectValue but ideally it wouldn't be an AbstractObjectValue. Instead it should be a concrete ObjectValue and then it can move into the Get check here. https://github.com/facebook/prepack/blob/master/src/values/ObjectValue.js#L730\nThe issue is that this can be inherited, shadowed and mutated after extraction.. Let's not do this yet but if this is not a ValuesDomain.topVal but has known values such a \"condition\" of two objects, then we don't have to make this unknown. We can call it on both and join the result to create a conditional of two known objects.. I don't think that this is type safe because some constructors might require more arguments than just the one.\nYou could make it a build function that you pass in instead.\n(intrinsicName: string) => ConcreteValue\nThat way you can pass it to the constructor instead of mutating it below.. You can pass { isPure: true } here because this is always a pure operation so it can be stripped if the return value is not used.. This logic is correct but should probably move to the callers of specializeJoin, right before calling this function, instead of here so that this method only does what it says it does.. We don't actually have to special case these. Every non-numeric propName is fine since this only contains numeric property names. E.g. if (propName !== '' + (+propName)). I think we might need to check if this is a simple object which it should be.\nThis is safe to do on anything that is a isSimpleObject with unknown properties. Doesn't have to be numeric specifically. One approach could be to just try executing the full path and if it throws a FatalError and is a simple object, then do this.. Don't remove it completely but replace it with the condition I posted.\njs\nif (propName !== '' + (+propName)) {\n  invariant(Receiver instanceof ObjectValue);\n  return OrdinaryGet(this.$Realm, Receiver, P, Receiver);\n}\nWhat breaks then?. This needs to be a wrapped in realm.evaluateWithPossibleThrowCompletion since if this is a member expression, this might be a getter or setter that throws.. This is sketchy. We don't do this anywhere else I think and I don't think the serializer is resilient to this.\nWhat you're doing here is mutating the temporary reference that the abstract value has at this point. This value could have other references and those won't be mutated.\nI think this just accidentally works in your example but won't work in other cases and won't work for member expressions I bet.\nLike obj.x++; return obj.x;\n. The way to think about the expressions being passed in here is that they can be any expression. For example an expression doesn't have to be serialized as a temporary variable.\nCurrently we serialize abstract addition as:\njs\nvar x = 1 + 2;\nx;\nSo your expression updates x but we can also have temporary variables like:\njs\nvar x = 1 + 2;\nvar y = x;\ny;\nIn that case your expression only updates one of them.\nWe could also skip the temporary variables:\njs\n1 + 2;\nIn that case this solution would generate invalid syntax.\nSimilarly if this was an expression like obj.x we might serialize it as:\njs\nobj.x;\nWhich would make your update expression work. But sometimes we serialize it as:\njs\nvar tmp = obj.x;\ntmp;\nWhat you're getting passed into the build function is only really safe to read, not mutate.. It only havocs the value extracted from the expression but not the original object. In many example where we've lost all info, derived expressions also havoc the object they were derived from but in other cases they don't. E.g.\njs\nvar otherObj = {x:obj.x};\notherObj.x++;\nreturn otherObj.x;. So this part is because we want to havoc everything that is captured? That will only effect bindings but not objects that are captured.\nSo __safeSideEffect(() => x++) might work but not __safeSideEffect(() => obj.x++ since only obj will be havoced, not what's inside it. But if you do it deeply, it'll pull in the whole environment with it including the global scope.\nIt's also weird that order matters now. Any optimized functions before this will read this value assuming initial value and any optimized functions that runs after this will assume havoced value.. It is completely broken. Let's remove it and fix the normal stuff instead. E.g. by optimizing it if we need to. We need to do something because it'll definitely generate wrong code in current scenarios.. Yea, this is way too fragile.\nThe indention here is that we want to havoc something outside the pure scope which we never do in any other case, and we want that havoc to be permanent so it shouldn't be reverted.\nI'm not sure this is the best strategy though. Not sure havocing outside the pure function actually works as expected. Will need to think about that.. We have too many configurations and options. I think in a follow up we should just turn on error reporting for all optimized functions. Either they're pure or not, and either non-pure is supported or not. No half-way broken options.. If we're both in pure and read only, which error wins? recordModifiedBinding and recordModifiedProperty does different things. They should do the same thing.. Can this ever be AbstractObjectValue here? If not, this should be an invariant. If we can, then we need to handle it because it can cover up mutations if it is wrapped by an abstract value.. The binding can be other environment records that are not safe. Like with, block scoped variables (let/const).... I don't think the currently running context matters. What matters is where the binding was defined. You need to pass in the environment from the binding here.\nI'll try to think of a test case but pretty sure this is wrong.. I think you can add an invariant here that env instanceof DeclarativeEnvironmentRecord. If it's one of the other environments, like the ones that write to objects (with and global), it should not get recorded here. It'll be recorded as a modified property. That's probably a good comment to add.\nHowever, it might not be a function environment record.\nIf it is a let/const, it should be a DeclarativeEnvironmentRecord. To figure out what function it belongs to you have to traverse its parent until you hit a function or global. That's the function that was used to create the environment record. That function is what you use to look up in the map.. This should be renamed to something like isDefinedInsidePureFn.. js\nvar x = 0;\nfunction foo() {\n  x++; // not safe\n}\nfunction bar() {\n  foo();\n}\n__pure(bar);\njs\nvar x = 0;\nfunction foo() {\n  function foo2() {\n    x++; // not safe\n  }\n  foo2();\n}\nfunction bar() {\n  foo();\n}\n__pure(bar);\njs\nfunction foo() {\n  var x = 0;\n  function foo2() {\n    x++; // safe\n  }\n  foo2();\n}\nfunction bar() {\n  foo();\n}\n__pure(bar);\njs\nfunction foo() {\n  var x = 0;\n  function foo2() {\n    function foo3() {\n      x++; // safe\n    }\n    foo3();\n  }\n  foo2();\n}\nfunction bar() {\n  foo();\n}\n__pure(bar);\n. js\n// ECMA262 7.3.23\nThat's the current value. These are not necessarily consistent across versions but we should fix that separately.\nYou could add the new canonical name sec-copydataproperties if you want.. You can just put this comment in the else clause so you can avoid the eslint-disable issue. Looks pretty noisy.. We should never initialize the top value type. It's just an abstract class. You shouldn't need this though.. Move this curly to the end after the loop. That way you don't have to assign anything to from since Flow will know that keys is empty. You can also avoid assigning anything to keys and just leave a comment there.. I thought we got rid of this whitelist?. We shouldn't ignore things that might be errors just because we're in pure scope. Pure scope doesn't matter here.\nThe cases that you care about is the cases where the list of elementTypes is the default [\"Undefined\", \"Null\", \"Boolean\", \"String\", \"Symbol\", \"Number\", \"Object\"].\nThat list has all types on it so it doesn't matter what type the abstract value is.\nIf the elementTypes list is the default, you can just skip this check. Always.. This swallows other types of errors. Needs to rethrow.. Any error recovery like this needs to evaluate for effects so that they can be reverted. Otherwise we'll end up with the effects up until the fatal and then replaying it again.\n. This is implied by the test isn't it? Same for all the other tests. It is fine to have a branch that conditionally returns this if it is a shortcut for some reason. E.g. if (!abstract) return 1 would be a nice optimization. Generally we only check for things that bloat a lot or is much slower.\nI think we can just remove all these does not contain and rely on the tests to verify correctness.. It's unfortunate that we've lost some of the spec text structure here by reordering it.. does not contain: Object.assign might be a better test since we want to ensure that we don't have to perform the operation. Relies less on the actual serialization form.. This should be an invariant. If we got here, something went wrong since this should never throw.. When we call frm.makeNotPartial() we assume that we will call frm.makePartial() after that but if we throw and then recover later, we assume a lot about that the reversal process keeps working like it does today. I don't see an immediate bug right now but I see a ton of subtle changes we could do that would cause this to be a bug. I wonder if there's a way we can make the guarantees of resetting this to partial be stronger. E.g. a try/finally around the place we need it frm.$OwnPropertyKeys().. So technically, we should havoc only frm because it can have getters on it. @NTillmann and I have an idea for why we might be able to get away with not havocing on getters.\nI actually think that havocing this might not be as bad as it sounds. That will still let you do everything else in your tests here. \nHowever, I don't think havocing will be all that bad. If we knew anything about the properties here, then we wouldn't hit this branch it would just go through the normal application. If don't know anything about the properties, such as when we have a completely abstract object, then havocing doesn't really forget anything useful anyway.\nHavocing might forget a bit more than necessary right now but we can fix that separately.\nI'd prefer adding the havocing here in this first PR, for now and then remove it when we relax the requirements for getters later on. When we've narrowed down exactly what that means.\nThis should also be wrapped in realm.evaluateWithPossibleThrowCompletion since the getters might throw. I think we'll want that even if we end up not havocing the source.. I don't understand what's going on here.\nWhy isn't this just delayedSources.push(frm)?. So there's a case here that's pretty dangerous.\nWe can end up in the error handling scenario for any number of different reasons. There are many things that can cause fatals.\nMostly that's fine because we'll just add to the delayedSources. However, not all branches in handleSnapshot actually does that. Particularly if this is a not a partial object but throws for some other reason (e.g. some unknown getter gets invoked on a known object) then we end up in recovery mode, but handleSnapshot doesn't add it to delayed sources in that case so it ends up just being ignored instead.\nI think this is a subtle bug. Probably need to refactor handleSnapshot a bit to ensure that all branches end up adding delayed sources for the recovery case. Which means that it always ends up with a partial to object if we have to recover.. This doesn't look fixed yet.\nIt is possible to fall into this else branch (not havoced and not partial), in the error recovery scenario and that will cause this object to be completely ignored. One possible solution is to havoc it before calling this.. Would be better for the future to add this next to all the delayedSources.push lines so that if we add another branch, it isn't just implied.. I could add a special case for conditionals like this but there is really a large number of similar operations. I can\u2019t special case them all. I just thought of this one as a test case.. It is the property name that is numeric. Not the value of it.. We don\u2019t refuse to compile programs in pure scope mode. It havocs the object in case it had a getter on it.\nIt would be way too restrictive to completely not allow for these.\nIn practice this almost always works out though. Most operations either havoc eagerly as the operation produces the abstract, or it leaves the possible values on the args.\nI think we need to come up with a less conservative way of modeling the cases that go to topVal.. I think the widened slots will need to change to be modeled on the property binding/environment binding instead of as a value.. Optimized functions get these arguments passed into them. https://github.com/facebook/prepack/blob/3deb5e2885a689e7b8be5bb8ad88e24fe8e4fecf/src/serializer/functions.js#L150\nThese two are the only cases of empty args that occurs in test coverage.\nIt is ok not to havoc them since they're arguments to pure functions, they can't be mutated.. You could make it even more specific. You only need to go down this path if obj.mightBeObject() && ((obj instanceof AbstractValue && obj.values.isTop()) || obj.isPartial()). Primitive values always resolve to empty objects. Abstract objects with known templates have known possible keys. Some of them might be empty but they can become conditional.. @hermanventer I dealt with the abstract case here.. @trueadm I don't know what this is supposed to do but currently it is only dealing with one possible value here. This is broken when it can be more than one possible object. I'm not sure what this is supposed to do in that case.. @trueadm Same thing here.. This used to be an implicit Set<any>.. A logical operator with two concrete inputs is never abstract as its return type.. This is not right. Should be empty, not undefined. I'll add a test.. This is what is different with this diff. The intermediate objects are now eliminated.. Found an existing bug. These don't consider setters on the prototype chain. https://github.com/facebook/prepack/issues/2226. We shouldn't follow that definition. This is not 100% correct definition and we need to fix it. We do need to support lazily initialized things. If those things mutate things we already know about and if that might have consequences.\nThe assumption is more limited than saying that all getters are pure. The exact definition should be more along the lines of exactly what this PR does which is \"it's ok to remove redundant getters if the return value isn't used and it's ok to reuse the same value extracted from a getter multiple times and assume it is idempotent\".\nBut even without that narrower assumption, this is still correct. \nInside a pure function, you can't have side-effects. So true side-effects like logging is already not allowed. You can however mutate anything reachable from the object passed to the getter.\nThere are some slight nuances where we need to havoc the object as a result. However, in practice, if we are seeing an abstract getter it is because we don't know anything about the object anyway. So havocing isn't even a big deopt. However, there are theoretical cases where this can happen. E.g. the object is a subclass of an abstract class. This almost never happens in practice though.\nBut havocing ensures that we don't assume something about the state of the object passed in.\nSince it can't have any effect on objects created outside the function, the only way any mutations in the getter can matter, is if its return value is reachable from the return value of the function.\nThat is really what isPure is saying.\nIt's not actually limited to pure getters but all these constraints add up to making it effectively the same.\nhttps://github.com/facebook/prepack/pull/2257. Here's how you use it to call standard library functions. Didn't need any changes to the API.. Note that this only prints constant strings atm. Making these dynamic surfaces some limitations in Prepack or the LLVM backend.. This getTemplate() function is confusing. It only returns if the template is partial but not if all fields are known? Doesn't seem like what you want here.. It is common to get multiple elements, e.g. conditionally two different functions (templates or not).\nI think instead, you should enumerate all the elements and call isCallable on them. If they all have the same value, you return that. If they don't all have the same value, you throw the introspection error.. It would be useful if typeof could return an abstract boolean instead of throwing one way or another.\nMoving it to AbstractObjectValue could work but there are a lot of internal methods. Some of them have the Partial suffix and allows abstract values to be passed or returned.\nWe could have an IsCallablePartial that returns an abstract boolean in this case.. This can be an invariant. There is always at least one element if it is not Top.. This is a duplicate. Maybe sorting alphabetically might make sense to catch those.. That's exactly what I want to avoid. This causes problems because the error is \"recoverable\" and then the runtime value can be a symbol which immediately throws. Even if you don't have any valueOf/toString/toPrimitive overrides in your code. It also causes trouble running test262 in abstract mode which will error compiling instead of passing.. So I looked at the spec again and it looks like now the ToPrimitive operation doesn't throw. The bug is actually in BinaryExpression, because it tests for ToPrimitive being pure but it should be looking at ToString. ToString will always throw for symbols so it's not pure.. I\u2019ll need to avoid emitting this if the prototype is null. . This is the primary change.. I think the issue with this one is that it can end up generating completely invalid code. Not just wrong assumptions. So ignoring it might make it hard to understand a bug. Maybe worth it though.. This method should move to properties.js and become static.\nThis is not overridden by any other type of object and is not part of the standard object model.\nEverything that directly deals with the properties set is in properties.js and it is important that we colocate these things. Note how I recently moved GetPartial/SetPartial there too.. I'd rather you call getOwnPropertyKeysArray directly here.\nThe indirections can't guarantee the safety of this operation in general. So I think it would be better to just assert that here and go directly to the lower level implementation than going through the general ones with a flag that can't be guaranteed.. Hm. My first comment got lost. I just mentioned that I don't like these special cases because they can't be guaranteed through indirections. E.g. Proxy and other subclasses doesn't implement this one. That's why we're better off by-passing these things if we assume something very specific about this operation that makes it safe.. The second loop already asserts that they're equivalent.. That's not correct if I run delete Object.prototype.__proto__ before this though and will still not be accurate for SetPartial etc. So not sure if it's worth adding more slightly incorrect code.. It might not be defined. I don't think we force descriptors to have their defaults filled in.. Updated the description a bit but I realized that we have joined descriptors which could model this scenario. We might actually need to model this case since it has consequences on other parts of the object model life cycle. Such as invoking a setter on an abstract object.. It's nice to catch any unexpected subsequent errors that shouldn't be there.. This is a simple example. Given that the type of the Receiver is a string, this can never throw, have side-effects nor read mutable state (since it's immutable). It can only error if this is fed with the wrong type of input arg. That needs to be fixed.\nHowever, once we fix that, how will I know that this can be turned atemporal again? Not everything has this property. So I have to go through them all one-by-one and think hard if this can really throw or not.. I don't know. This is copy-paste from the other test-serializer.\nUltimately, I'd like to run all the normal serializer tests through the LLVM path. At that point it might make sense to unify the runners.. I think I ultimately want to use test-serializer to run the same tests. For now I just needed a quick way to get started until I have enough features to actually run those tests.. I'm not sure what you mean. It just means that we  always have to initialize it with a Module in the constructor.. If it's not defined, it'll throw and Flow won't let me call equals on it.\nIf it is not yet defined, that means that there are no strings defined in this context yet. So whatever this type is, it can't be equal to a string since there are no strings.. The reason for this approach is because I don't want to generate unnecessary code in the LLVM output for a bunch of types if this type is never referenced in the output. I still have to test whether something is this type without knowing if it might be though. I suspect there will be a lot more of these cases for other types that I'll need to encode. I wouldn't want to document it for ever type but I can make a global comment about it in this file.\nThe equals call is just how the LLVM node bindings work since the wrapper objects don't guarantee JS object equality since the underlying C++ APIs can return instances that the JS bindings doesn't know about. That pattern will be all over the code base. It's pretty common since JS doesn't have operator overloading (yet).. Ohhh you're referring to the +. Yea that just means that this field is read-only which is helpful to make it covariant. In Flow, the classes have the ability to define their own interface so the documentation for interfaces applies here.\nThis is just a way to say that it is read-only. This is to enforce, that we don't mutate this later on. Mutating it would break the invariant that the lazy initialized functions and types all belong to the same module. If we're generating multiple-modules we need multiple Intrinsics objects.\n. The C++ can't make up a type that I haven't created yet. However, if I have created it, the C++ API can return the C++ version of that object from reflection APIs. The JS binding around the C++ bindings doesn't know that there already is a JS instance associated with this C++ object so it creates a new wrapper JS object around the C++ object.. This models the case when one descriptor is empty and not the other. In a follow up I'd like to model this as joinedDescriptors to support two non-equal descriptors too. There's an unrelated bug in properties.js regarding that.\nThis becomes important after this PR because $Get on each of the conditional objects now calls $GetOwnProperty on the Receiver which is both objects, instead of on the unwrapped object. So the $Get now gets two possible results, instead of one, which the simplifier then cleans up.. This is meant as a performance optimization can shouldn't change the output or semantics at all. I'm not sure if it is worth while keeping around or if I should just remove it.. Because this is a simple object this will always issue these two calls:\njs\nlet desc = OrdinaryGetOwnProperty(realm, Receiver, P);\n// do some processing of the descriptor or create a new one\nOrdinarySetOwnProperty(realm, Receiver, P, desc);\nNote how it doesn't actually ever touch or need the cv object passed to it if it is simple. The OrdinaryGetOwnProperty gets a joined descriptor of all possible values on all the objects. It then updates all the possible objects with that joined value.\nThis is very obscure at best. Which is why I don't like this approach. I could just remove this whole thing and it'll just work. Another thing we could do is make a forked version of OrdinarySet's logic that by-passes checking the prototype chain for setters and such.. I'll take a look. The work in #2473 is meant to prepare us for better supporting joined descriptors. In particular I think that OrdinarySet doesn't properly deal with nested joined descriptors. Those issues prevented me from doing more with joined descriptors in this PR.. Ok. I was able to repro the issue and write a test for it. I used joinDescriptors instead since it has this logic already anyway.. This is already a pattern we have for Value. I think we should stick to one pattern or switch both at once.\nIt is plausible that we could make Flow refine these for us similarly to how I did it with IsDataDescriptor. But for now I stuck with the pattern already in place for Values.. The rval instanceof ObjectValue is unnecessary since one of them needs to be an abstract value.\nYou could expand the lval to include abstract values with Value.isTypeCompatibleWith(lval.getType(), PrimitiveValue). That way you handle the abstract primitive case too.\nhttps://github.com/facebook/prepack/blob/master/src/methods/to.js#L682. There are three types of descriptors at the spec level. Generic, Data and Accessors. Lack of value and get/set means it's generic. So if one has a value but the other doesn't, it means that they're not even in the same category of descriptors.\nUndefined value doesn't mean empty btw. That's an empty value.\nThis helper function, for reasons that preceded me, doesn't compare whether the values themselves are equivalent.\nBasically, this function is only meant to determine if this needs to use joined Descriptor or if it's enough to use a joined Value.\nIn theory, accessors doesn't need to use a joined Descriptor neither. We can just use a joined value of the getter and a joined value of the setter.. Nice catch! I didn't think to search for delete.. This is the internal operation called by x | 0 yes. <<, >> and >>> uses ToUint32 which is slightly different.\nhttps://tc39.github.io/ecma262/#sec-toint32\nI'm not sure what you're asking. The spec requires infinity/nan to have a certain behavior. The FPToSI behavior is somewhat undefined but will in practice simply yield the wrong result so I can't rely on it alone.\nThe mod 2^32 is speced because it basically means taking the first 32 bits of the fraction after the rounding. This is different than the overflow behavior you would get from using any of the other LLVM operations.\nThe reason things are defined this way is so that multiple operations are idempotent which helps when you combine multiple of these operations in sequence and asm.js. I don't fully understand it but seems clever.\nNone of this applies to any single or even few CPU instructions. Interestingly no implementation does the same thing here. Everyone tries their own clever thing. I can't rely on certain platform specific quirks so not all solution would work cross-platform. I have some ideas around 64-bit casting (not currently exposed by the llvm-node bindings). In the end I opted for just the simplest code.\n. Note how because of the spec is written these things become safe for subsequent operations.. The reason I don't read it from the current binding is so that I can in the future represent weak updates on the binding without actually emitting a weak descriptor. So instead I explicitly pass it in. That also lets me only pass in the target rather than the modified object.. I'll add a comment. I tried to add a comment to all \"public\" interfaces like OrdinaryDefineOwnProperty and DefineOwnProperty.. We still have to update the internal property binding so that we know what the new value is when we try to read out of it - which is a complicated set of rules.\nhttps://github.com/facebook/prepack/blob/fbc32cc76deeb0735c9a58cb0ad1e55269bea47d/src/values/ArrayValue.js#L207\nI could maybe add an alternative method name but I didn't want people to try to use it without a target and forget to add the target when there should be one. Maybe if it had a really discouraged name. In the end, I'd probably still want to pass null for this instead of forking the internals of this method.\nIt's subtle since the standard method doesn't have this.\nI considered adding a method just for emitting the effects, but it turned out to be very complicated because we have to read the previous state of the binding to determine if we can use assignment and emit the effect after figuring out the final descriptor etc. It also made it easy to forget to do this in new places, the Target argument forces us to think about it.\nIn the end I couldn't figure out a better structure.. ",
    "Janpot": "here's how those typescript definitions are generated: https://github.com/Microsoft/TSJS-lib-generator. ",
    "bertho-zero": "Hi team, is there anything new on this side?. ",
    "skyne98": "It would be nice to have a place to track progress, or some kind of a workaround for now @hermanventer. @hermanventer, the main problem is that it seems like it's impossible to compile any existing or new web application using prepack right now. Each time there would be some DOM operation, or browser API call that makes the process fail. That is very unfortunate, considering the fact that prepack might be the future of JS optimization. People should be able to test and evaluate it already, I think.\nThe second point is -- why not just make every unsupported API call an abstract unknown value right now? Yeah, it will disallow lots of optimizations, but it won't crush the process. Also, as far as I understand --abstractEffectsInAdditionalFunctions can be used to optimize the bodies of functions, right?\nAnyways, thanks for your time! I see the barrage of issues you have, but I think that prepack is worth some attention, therefore people have to be able to play with it, without it crashing on them. May be I am just missing some stupid option that makes it happen, in that case I am sorry!. @hermanventer, thanks for your descriptive answer! It's nice to hear that people are hard at work writing this wonderful project. . By the way, I think we should add a place where all the implemented APIs are tracked, shouldn't we?. Yeah, you are doing a great job, guys! I am sure that in some time it will become a great and universal tool.\nAs for now, I was wondering wether the combination of both Prepack and Closure Compiler can bring desired results?. Yeah, thanks :) Another question. What if there was some hypothetical programming language, that had compiler-checked pure functions? Would Prepack and Closure together benefit from a language having such a feature? (except memoization, for sure). Yeah, pure annotations is a great idea, I think. However, I am curious about what real optimizations you can apply, having this function purity data? Constant folding is obvious, what else?. ",
    "hermanventer": "We are swamped with non DOM related work right now, so there is nothing specifically happening on this front. If there are specific issues that are blocking you from doing something in this area, please add new issues.\nI hope to write some documentation for Prepack a bit later on this year.. I'm afraid that we are all going to have to be very patient with Prepack. Getting to the point where it can usefully run on real browser based applications is going to take a lot of very hard work and a long time. Taking short cuts will result in something that works only for some ill defined subset of JavaScript and only up to a point.\nRight now, Prepack can deal with initialization code (global code) in environments that we can easily model and about which we can make restrictive assumptions. We are hard at work to go beyond that, but the war will be won in a long series of small, hard won victories.\nSome previous work on analyzing JavaScript has already highlighted just how difficult things become once you try to support all of JavaScript and you have to deal with untyped call backs. The conclusion reached in those efforts was that, in the end, the analyzer knows nothing much. Since this is a good description of a typical browser based web app, it makes sense for us to set our sights on gains that are more attainable in the short term.\nThat said, if Prepack actually crashes for some input (i.e. a false invariant or a runtime exception, we'll be glad to hear about it particularly if you have a way to reproduce it). The expected behavior of Prepack is that it should give you a nice error message telling you that your program is not suitable for the current state of Prepack. We have quite a bit of work to do on that front as well.. The ES5 portion of this now passes. Not all tests are appropriately annotated and some tests seem to require non standard behaviors. These are filtered out in our test runner.. Replaced by another pull request.. Seems like the change is already in.. I'm redoing this.. It turns out that this is not a strict mode thing.. Quite a few tests fall over when this happens. (I have inadvertently tried just that scenario.). Recent changes in the serializer means that this is now untestable, so I'm abandoning it until we are in a better place with residual programs.. Before doing any more work on this, please educate me on why this pull request is a good idea in the first place.. Some sort of support for properties will be coming along shortly.. This leaves things unchanged as far as deletion is concerned. Perhaps this will change as we go forward, but I'm doing baby steps.. Updated as per review.. Waiting for linter.. I'm no longer sure this is the right way to go.. Postponed.. Rewrote the TypesDomain and added some tests. Doing that uncovered an unsafe practice: negating the result of HasCompatibleType. For example, if an abstract value can be both a number and a string, its type will be PrimitiveValue, which is not compatible with NumberValue, but that does not imply that the corresponding concrete value will never be a number.. Introduce assertNumber.. Abandon.. Re \"ponder for a bit\", take that in the English sense, not the American sense. ;-)\nI.e. There ought to be a test for this in the 262 suite. If not, that is interesting and we should contribute such a test.. To run more tests you also need to comment out some filtering done in the runTest function of test262-runner.js.\nAlso run \"npm run validate\" before pushing. That will run the linter (and flow) locally, giving you much quicker feedback than waiting for circleci to finish running.. Please fix the lint errors. You can get them to show up locally for you by running \"npm run validate\".. I am exceedingly dubious about your strategy of executing the code twice. \nA better approach would be to serialize it twice.. Replaced this with a complete rewrite.. Since this is fixing a bug it would be great if you can add a regression test for it.. This is not a big issue when the resulting code is compiled to byte codes with an ahead of time compiler, since it's optimizer will delete the redundant initializations. When producing source code for using on a browser, however, this is undesirable and we should tweak to serializer to not emit dead code.. Yes, it seems that Prepack is currently over specialized for a particular scenario. This certainly needs addressing as well.. With #897 the output now looks like this:\nvar x;\n(function () {\n  var _$0_unique27277 = this;\nfunction 0_unique27277() {\n    return $0_unique27277.x;\n  }\nx = 1;\n  x = 2;\n  inspect = _0_unique27277;\n}).call(this);. This seems like a weakness/bug in the serializer. When serializing an object that has a property that is potentially deleted, the property should not be emitted inline, but should be conditionally added afterwards.. You need to test this. The 262 suite has tests for this, but they have been disabled. Look for and remove this bit of code in /src/scripts/test262-runner.js\n// temporarily disable tests which use eval. (ES5)\n if (testFileContents.includes(\"eval(\")) return false;. I've enabled those tests now. Please rebase this request.. The test framework compares the output from the code without prepack with the output from the code with prepack. For this to actually fail if there is a bug, the output has to be non trivial and the comparison should be deep. So in your test case you should convert the array to a string before returning it.. The most I can figure out quickly from all this is that you might be able to prepack the bootstrap function. I'm wondering just how much value this would unlock. What am I missing?. I've created fixes for the two specific examples above. More fixes are needed to fix the entire class of related issues.. We could do additional passes to collapse these things, or we could just leave that to the next compiler. Perhaps a single additional pass would be a good compromise for now.. I'll add negative test cases in my next request.. @romain-intel Have you abandoned this?. Not tracking anything useful.. Pure is not well defined and \"side effect\" implies state change. What we are really trying to say is that deriveAbstract creates a value that must be computed at a particular point in the evolution of the global state, because it depends upon (or changes) state this is not under the control of Prepack.\nI tend to think of this kind of thing as \"Input/Output\". Not that I'm suggesting that we call this \"createIOMonad\" or something like that. :-). Addresses part of issue #489. Addresses issue #453.. Can you run \"npm run validate\" on your system without any issue? If so, can you tell us which version of Node you are using to run it?. I find the timeouts to be non deterministic on my setup. Perhaps not too surprising. The time-out setting for the CI is a bit more generous. I'm OK with leaving things as is as long as CI does not get to be flaky. . Prepack is quite limited in what it can do with abstract values. The error message is telling you where in your code the construct is that Prepack cannot handle just yet. Feel free to extract a smallish test case from your code and opening a more specific issue.. Abstract values can be passed through. I.e. they can be stored in the heap for use by the residual functions. When the heap is constructed by the prepack produced deserialization code, the real values will get stored in the heap.\nBeyond that, simple expressions involving abstract values work and you can also use abstract values in (non loop) conditions.. How does this relate to #536?. This looks like a new issue. The basic problem is that empty generators are not being removed aggressively enough. The likely site where a fix should go seems to be here: https://github.com/facebook/prepack/blob/b854812433c35590901045f8b15997025b1e3c7d/src/utils/generator.js#L418\nThere should be an additional special case for blocks of length 0.. Please add a test case for this.. test/serializer/abstract seems like a better fit since this is not primarily about the basic serializer.. Please feel free to pepper us with questions.. This doesn't look safe to me if the abstract function is not well behaved. We could require that only well behaved functions be exposed as abstract, but I don't see any way we can enforce this. Still, it would be a pity if we can't let people do this sort of thing.\nNikolai, what do you think?. Resolves issues #490 #491 #492. I think there is some more work to be done before we can do a complete test of the deleted cases (see #573). I'd like to get this in, as is, right now since it is blocking us.. I don't know the provenance of these tests, but I doubt that they are intentionally duplicated. I expect that there was an intention to create a wrapped property getter test along the lines of the unwrapped one.. I have no idea either. For now just delete the redundant test.. Since we are not tracking $WeakSetData, any code that writes to it during forked execution can cause wrong code to be generated and thus we guard against such writes and fail Prepack if they occur. If you comment this out, you should be able to write a test that where prepacked code produce a different result from the unprepacked code. Possibly we already have such a test. If not, now will be a great time to add it.\nLooking at your example, try making x false.. This is not the only design that will work, but it seems doable.. I had a look at the places where this is occurs in the scenario we are currently most interested in and it appears to be something a non issue because only class functions and prototype objects get their proto properties set in the prepacked code. I'm lowering the priority of this for the time being.. You need to first merge #566.. I can only assume that node 7 fixed something that matters to the test suite. We defer to the underlying JS engine when there are no heap effects in play.. I'm not sure what you are asking. Are you concerned about evil regexp strings breaking Prepack, or are you asking if Prepack could find vulnerable uses of regexp in the code it is prepacking?. I'm not sure we are ready to head down this slippery slope of reasoning over abstract arithmetic. This case, however, is not too hard. The standard approach is to add a Range domain to abstract values and use that to check simple relational constraints. I expect it will be one of the first steps down the slope for us.. Overflow will become abstract right away and making the condition \"c > 2\" concrete will not solve that problem.. I fixed all of them as part of a pull request that I've abandoned. I'll extract them from there and put up a separate request.. We already have a number of properties that are only available if running with Prepack, for example abstract. __PREPACK would be no different.\nOur hack to get around tools that do not understand these properties is to do \"if (global.__abstract) {...} else {...}.. Since global.__abstract is undefined, one could hope that a minifier will constant fold it away. Am I being way too optimistic about the state of the art?. We currently do no refinement anywhere and it will be a while before we get to it.. Made issue #1378 for the switch statement part of this.. Go for it.. The main problem with this particular example is that foo is not declared and that we do not assume to know all of the properties of the global object (since that is environment dependent). Hence the possibility that \"global.foo\" is property with a setter.\nNote that we DO assume that the setter, if any, will set set the value of foo to 3 and that it will not have any other side effects visible to the heap that will later be serialized. Adding the assumption that the setter, if any, does not care if it is called does not seem such a great leap, but it does seem to be false for at least one scenario that we care about.. There are still two tests that time out. \nI also think that this should not be confined to Circle builds and that it should now be an error if a test times out.\nIt would also be nice if we had a way to run the problem tests with a really long time-out, perhaps once a day, so that we still get some signal from them.. https://531-45147841-gh.circle-artifacts.com/0/tmp/circle-artifacts.P4Udhaj/test262-status.txt\nPasses: 22825 / 22825 (100%)\nES6 passes: 7455 / 7643 (97%)\nSkipped: 5209\nTimeouts: 2. What I mean is that if we exclude tests that are known to run long (but eventually pass, given enough time), then any remaining test that times out must be regarded as a new failure that should be looked at and resolved before merging a pull request.. Could you rebase this request so that we can have another CI run?. On CircleCI we still see these two time-outs:\n../prepack/test/test262/test/language/comments: Passed: 16 / 16 (100%) (es6): 0 / 0 (100%)\n    \u2717 (strict): S7.4_A5.js\n        Timed out\n\u2717 (nostrict): S7.4_A5.js\n    Timed out\n\nI'd like to see at least two changes:\n1) These timeouts should show up as failures. I.e. CircleCI should not report all checks as passed.\n2) The failing test case should be added to the list of time-outs.. Running on my lap top I also see no time-outs when I reduce the cpu-scale. My guess is that particular tests can proceed faster, probably because of less GC pressure, when fewer tests are running at the same time.\nIt appears that you are running more tests than CircleCI does. Have you updated the test262 directory to a more recent version?. git submodule update --recursive --remote\nshould have been\ngit submodule update --init\n. Yes this is a duplicate of #632.. The CircleCI page has a rebuild button. I've triggered another build. The time-outs might be due to load on the CircleCI servers.. This looks good to me, but I think it would be wise to add more tests involving complicated expressions such as simple properties, getter/setter properties, array elements, and chained expressions (eg. ob.x.f++).. Please fix the lint and flow errors.. Duplicate of #594.. I think it probably makes sense to always run the residual mode following the serialization mode. But it also makes sense to run the residual mode by itself, if only because the serialization mode is necessarily very restrictive when it comes the what kind of global code is allowed. The residual mode has to deal with the entire language (perhaps somewhat restricted to make static analysis more powerful).. Stepping back a bit: The way prepack is now, you (will some day) get global code that is \"optimal\" by construction because the code is generated for you. But we can only do that by severely restricting the kind of global code you can write because we need to understand rather exactly what will end up in the final heap and we have only weak mechanisms for preserving observable side effects during construction. We also have a very inadequate story for optimizing the residual call back functions, not least because we cannot restrict the code in those functions to the same extent as we restrict the global code.\nI'm setting out to fix that by introducing a mode where we optimize the given code by partially evaluating it in the light of the  concrete and abstract state we track as part of the same evaluator we run for the global code scenario, but with more conservative assumptions (and also much more stringent requirements for user provided summaries for code that is not available to the evaluator). This is essentially what every optimizing compiler does, but that does not mean it is exactly the same as every other optimizing compiler and thus not worth doing.\nIf and only if you are willing and able to satisfy both the stringent requirements of the serializer and the different stringent requirements of the partial evaluator, you can run the latter after the former and get better code than either will get you by itself.\nIf not, you may want to run just the serializer or just the partial evaluator.\nRight now, with the partial evaluator being just a figment of my imagination, I need some way to integrate and test it, without impacting the current state of things, so the option is a necessary first step for me.\nMaking options optional is not a big deal. I just don't happen to think it is great API design, but design is necessarily opinionated and controversial.. Accidentally deleted and recreated as #671.. The obvious existing optimizing compiler for JavaScript is Closure. I can't find much of substance about its internal workings, but from what I can find, I surmise that there is room for improvement if one aggressively insists on whole program analysis, abstract interpretation, outer fixed point computation and profile guided optimization. We can also emit annotations for particular JavaScript VMs that are not explicit targets for Closure. There really is not much more one can usefully say about this.. foo has module scope. Only heap values reachable from the global scope are serialized. If you omit the let the above will have an output. You can also write \"global.foo\" to make things more obvious and less brittle.. At the moment, Prepack operates by using an interpreter along with an Abstract Interpreter (AI) to run the global code, resulting in a mostly concrete heap with some abstract values here and there. The heap is then walked to produce a completely new, hopefully more efficient program that will recreate the heap when run against actual data.\nThe abstract values must be well behaved, which is to say that it must be known to the AI that the abstract values will not cause unknown changes to the heap or any abrupt changes in the control flow.\nIt is rather difficult to reduce loops with unknown bounds into a set of heap values that fit the above requirements.\nAn alternative approach, which I hope to start exploring this week, is to partially evaluate the given program, using the concrete and abstract values to simplify the original program by reducing expressions with known values to constant expressions and by rewriting control flow to eliminate dead code. In the process it also becomes possible and desirable to do well known compiler optimizations such as function in-lining, loop unrolling, common sub expression elimination, strength reduction and so on. I expect that these optimizations will achieve what you are looking for.\nIt will be a while before V1 of that is finished and ready for production. I'm hoping for something by the end of the year, depending on how much time I can free up and how much help I get.. This looks good to me but it would be very interesting to see how JSC does with a benchmark test that closely mimics the code produced by this change. . To fix the bogus Flow error, add a // $FlowFixMe to the line preceding the line with the bogus error.\nTo test your code, remove the line(s) in scripts/test262-runner.js that explicitly disable the relevant tests from the 262 test suite.. Small pull requests are preferable to large ones, so its OK for super to be out of scope for this one. To make the test suite more relevant you can filter out test failures that fail because super is not supported. One way to do that would be to add a case for super in the code starting at line 998 in the test runner script.. Tracked this down to a bug in node.. 120 works for me.. As the name suggests, this is a specialized flag for use by Prepack developers. It only prints output when something goes wrong.. Looks like Flow v47 is not yet available via npm.. Rolled up into #692.. It passes on CircleCI, so yes, it should be passing.. Rolled up into #692.. Rolled up into #692.. This is only safe when not using the abstract interpreter, because some date formats require environmental information that is necessarily abstract at compile time. If you throw an introspection error in the case where realm.useAbstractInterpretation is true, then this will be OK and at least more of the test262 suite will pass.. CircleCI does not show any more tests passing for test262. It seems that all relevant date tests are filtered out because they fall under the intl402 directory. It would be great if you can tweak the test runner to actually run some Date.parse tests.. Those are the two lines that matter, but simply removing them will introduce many failures to the test run and I'd rather mask those until failures we care more about are resolved.\nYou can solve things by adding another line, which returns true for the directory with the Date.parse tests.. The catch is that the places where it is used do not match the parameter name used in the signature, so just searching for occurrences \"metadata\" does not find any uses.. Please fix the lint warnings.. Please rebase.. Getting close, but please attend to the test runners.. Looks fine to me.. Wow. Fixed the typo in ff7610435fba1ad0856acfc96d5fa9d93c5378e4. We really should get Flow and Lint to run on these files.. Changed the place where the default is set, as per Sebastien's comment.. It seems like we really want __abstractTemporalPureFunction for something like console.log. Temporal functions have to be emitted in the order they appear in the source. The other kind of abstract functions can be called at any time and must always give the same result for the same arguments.. Please run \"npm run validate\" on your local machine and fix all errors before you update this request.. I assume that we can just require a version of node that has native support for generators and if that is not already the case we can make it so.\nI have not spent much time thinking about how we should implement generators, but I'm wary of replacing all calls to env.evaluate() with yield env.evaluate(). I am particularly concerned that this may impact the abstract interpreter in subtle yet catastrophic ways.\nSomewhat less scary for me would be to create an iterator class for each generator function, much like a compiler would, and to use that class for the execution. A long time ago in a galaxy far away, that transformation (by the C# compiler) caused enough trouble for a static analysis tool I helped out with that we went to considerable trouble to decompile the iterator class into a generator method. At least in Prepack we are starting out with the real generator and don't need to forget it when we create the iterator class, so we might just get the best of both worlds.\nBut rewriting the evaluator itself as a generator? Probably not.. In the C# compiler, generators are compiled away into a class that represents the generator state and that implements the various methods expected of an iterator object. The body of generator mostly ends up in the next function.\nThe main difficulty in copying this design in Prepack would be the absence of goto statements because the latter make it a bit easier to retain the original control structure and still being able to resume after yields.. If one wanted to go down the generator to class path, it may well be possible to just have Babel do it for us.\nEither way, there is much to be unsure about. Among the many concerns I have is how we are to save the global state when we suspend execution because of a Yield and how we are to restore it when resuming the generator. Throw in speculative evaluation (the kind we get when abstractly interpreting an if statement with an unknown condition) and my head start to explode.. \"All of the state is saved in the iter generator closure.\"\nI have a hard time believing that. The realm is not going to be so easy.\nMore importantly, how do you iterate an if statement where the condition is abstract?. I intend to add a wiki page for every error number. At some point the error messages will link to the corresponding wiki page.. My pull requests always involve only the last commit.. Yes, pretty sad. Prepack encountered a case that supposedly should never happen. Which makes it hard for me to fix it without a way to reproduce it. Could you attach base.js, or some reduced version of it that you are OK with sharing?. Would you mind updating the test runner to not ignore case \"Unsupported node type Super\"? And while you are at it, perhaps also update the expected number of passing test cases.. Prepack currently optimizes only the initialization phase. Any loop encountered during initialization will get unrolled (if the loops bounds are not known Prepack will just give up and fail to optimize).\nEventually, Prepack will attempt optimization of non-initialization code and will have to deal with loops that cannot (or should not) be unrolled. When that happens, many local variables will go away and constant expressions will get folded into constants.\nAlso note that in your example, it is not safe to assume that points.length will never change from one iteration to the next.. Please do.. Most of the logic concerning PossiblyNormalCompletion can be found in methods/join.js.. Added a regression test.. I'll take on the bits needed for checking that initMoreStuffA and initMoreStuffB are independent from each other.. You need to run prettier.. Introducing a new base class only makes sense if it reduces code duplication and increases type safety. I don't think it does either in this case. . Why make our own copy of traverseFast?. This would be nice, but a lot of work is needed before we can enable something like that. This is not likely to happen in the next 12 months.. No longer needed.. Looks good to me. I'll let Nikolai have a good look though.. Might be glitch in the dashboard. The values are currently at zero.. The message seems to be correct, given that you are running node v5.12. Can you expand a bit on what you see as the issue?. At the moment we essentially assert that unknown extensions will never come our way. Better would be to generate a compiler diagnostic indicating the source location.\nEventually, it probably makes sense to handle everything that Babylon can give us, but I don't think that is going to happen anytime soon.\nWhen you do add support for a new feature, such as JSX, then change what needs to change.. You can use global.__residual to prevent Prepack from inlining a function. Note, however, that any effects this function has on the heap will not be visible to Prepack and hence should not be used by any code that will be rewritten by Prepack. If the function has effects that Prepack should know about, you can try wrapping the function inside another function that will be inlined (but that has a residual call to the delayed function) and which modifies the heap with the values Prepack should know about. Note that the delayed function should not throw any exceptions, since Prepack will not produce code that can handle them.. I think it will suffice to import the library, wrap all functions with wrappers that call the function via __residual, and then to export the wrapped functions. Prepack will strip off the wrappers.\nThe side effects matter only when a function will be called by Prepack. If a function is simply registered as a call back and called by the host application after the global code has completed then it's side effects will not matter to Prepack.\nAn __abstract function is something that Prepack can deal with only if it is not called by Prepack.\nPerhaps a small example will make it easier to nail down the specifics.. This issue is quite stale now and is unlikely to get addressed any time soon, if ever.. @cblappert: I've added your test case. It turns out that is passes (both in the current form of this request and when stacked on top of the CSE request).\nIf I understand things correctly, the reason is that the association between value and scope is formed in ResidualHeapVisitor, using only generators that will get emitted. That means the the generators that form part of Effects are unreachable from any serializer code, even after the containing Effects have been applied.. @NTillmann: I've added your additional test case and it works too. Perhaps it has to be a bit more subtle, because I'm unsurprised that it works.. The fundamental constraint we have to respect is that the code must stick as closely as possible to the language of the specification. For the rest, emphasize readability over everything else.\nWe run the code through prettier and lint, but are not following any particular standard. Feel free to suggest one. But be prepared to defend its strictures with realistic examples. Authority does not fly very far in these parts.. Realm plays that role for us, but that is probably a bad thing. I'd like Realm to be very close to the specification and would like to have a global context class that references the realm. Unfortunately, the size of the refactor required to clean this up has prevented anything happening on this score.. Doesn't seem to do the trick.. These are for introspection errors.. I need to rethink this.. Yes, this looks like a duplicate of #900. Looks good, but please revert the test case change.. I agree with Nikolai that it would be better to provide a new model function that can construct a abstract value that is the join of undefined and an object. This would be an AbstractValue with a values domain that includes both UndefinedValue and the ObjectValue. We would then rely on refinement to get rid of the UndefinedValue.\nI'm still mulling over the exact mechanism for doing this, but it is pretty much on top of my todo list.. This is problematic because the global object may have a setter which is not modeled, but which has an observable side-effect when invoked.. The Cartesian product computation code is pretty well covered by the existing tests, but I don't think any of them will fail if the value set is actually wrong. Coming up with such tests in the current state of the Abstract Interpreter is non trivial and I'd prefer to hold of a bit until it is easier to do so.. Please provide a summary of what this request does. Also, if there is an issue that this fixes, please reference the issue number.. The type checking has improved and the specific case where undefined is expected is called out in the code. Making this completely type safe will lead to code bloat.. Working on it already. :-). Hmm. The best I can do here is to return the join of the exception that arises if collection === undefined and the value of collection.items if collection is an object. This value will be unusable unless refined in a context where \"collection !== undefined\" is a path condition.\n. Looking at this some more, it seems the real problem is that \"collection != null\" does not refine away the undefined value in the right hand of &&. That is just a limitation of the current (extremely limited) logic for reasoning about abstract values. If you had \"collection !== undefined\" that would already work. I think I can beef up things to expand the path condition in the case of \"!=\" expressions.. Probably not. If collection is modeled (undefined | null | object) then \"!== null\" only refines away the null bit and the remaining value is still unusable. I suspect you want __optional to produce (null | object) not (undefined | object).. @sebmarkbage Yes, if collection != null is used, things will work. My last comment is specific to the observation that there were places in the code where collection !== null is used.. PP0001 is currently used for errors that are generated the old way, via reportIntrospectionError. These errors should instead be generated by calling handleError directly, with specific error codes and relevant source locations.. To make requests like this easier to review please rebase on your local system and then push a single commit using \"git push upstream -f MatchSystemAndYarnFlowMatch\".. Requested changes have been made.. Newly requested changes have been made.. Made changes to address review feedback.. I agree that simplification should happen in one place only. I have some ideas on that and will follow up later.. Made requested changes.. This has recently been fixed by @sebmarkbage.. Unless you are Facebook employee, sadly no. There are some changes we need to make to internal test passes.\nIn general, only look for issues with the help wanted label.. Are you done with this?. Do you still plan on landing this? It has been languishing here for two months now.. test262-runner has a number of filter functions that disable tests. We are not specifically disabling tests for class features.\nAdditionally, we are also ignoring test failures that result from tests that we can't filter because of wrong/missing metadata in the headers. I've looked over them and none come to mind as relevant to this feature.\nPerhaps the thing to do at this stage is to actually update our reference to the test262 repository so that we can pull in the newer tests.. We first get CI to pass on Github and then push the PR to fbsource by clicking on the Land to fbsource button. To see the latter you may have to use Chrome. If all goes smoothly the change first lands in fbsource and then propagates back to Github. There are some tests that can fail after CI passes on Github. Normally we run those locally on our laptops.. One can always test more and I'm sure we will add more tests. There are actually already quite a lot of tests that touch the modified code paths. A few more will come soon.. Is this something you are going to finish?. While it would be awesome to have a range domain, this particular example could just as easily be handled by the current ValuesDomain.. This code still needs work. I don't think there is a clear case for making the queue abstraction be anything other than just that. I.e. why make it send a message?. Why not just use: https://www.npmjs.com/package/queue-fifo?. I agree that a name change will be an improvement. It will be more convenient for me to do it in a later pull request.. I've changed simplifyAbstractValue to simplifyAndRefineAbstractValue and introduced simplifyAndRefineAbstractCondition for expressions that are always converted to booleans. I have also removed simplification code from evaluator methods and made the factory for unary expressions call simplifyAbstractValue before returning its result. This uncovered a latent issue in a test case. I've modified the test case and referenced the relevant issue there.. I can't land this because it breaks the serializer. I'm also not quite sure if keeping generators intact is necessarily a good idea because I'm a bit worried about scoping issues at join points. We need to have an discussion about all this.. Abstract values are immutable and hence whatever Prepack knows about their types would be candidates for type annotations. When expressions are not inlined, every abstract value is assigned to a variable. These could be annotated. With inlining we could still use the Flow syntax (expr: type). I'm not sure what the Closure compiler understands. In the long run, Prepack can probably do everything the Closure compiler can do and then some, so targeting Closure may not be a killer scenario.\nThis seems very do-able to me. Obviously it would need to be controlled by an option.. Your test plan is not reproducible. Ideally, another person should be able to get this pull request and verify that the test plan works on their setup.\nYou should also strive get have automated tests from day 1.. Some careful thinking is needed here. Applying effects multiple times can be a bug farm. It might be better to check that effects are applied exactly once, treating join as a form of apply.. fluffed it. This test passes when run in our CI. Perhaps you need to give node more memory?. Nope, that is why the issue is labeled with test needed.. Another thing to watch out for is changes to String.prototype.split and String.prototype.slice. If these are changed, the str.split(x, y) syntax will not actually end up (directly) calling the split function. When guarding agains this, bear in mind that the value of String.prototype.split (or slice) at the time of the call in the original source might be OK, but it may have been modified by the time the call is emitted in the transformed source.. It would be great if you can fix the lint and flow errors before I look at it in detail. Also, the runner itself complains about the version of node not being supported. There is also an out of memory situation, it seems.. Is there a way to exclude tests for errors that should be caught during parsing? For example all tests that expect syntax errors.. The filtering feature looks great and I would love to see us making use of it. Unfortunately, this test runner in its current form has quite a way to go before it gets to feature parity with the existing test runner.\nPerhaps you can just add this as an additional test runner (running against a different clone of the test262 repository) for the time being. We can then gradually add the missing functionality and make the final switch over only when the development workflow will not be impacted by it.. The most important pain point is the lack of concurrency. It is important that on a beefy laptop the test runner uses all available resources. On my laptop the entire suite runs in 1.30 mins.\nNext, it is important to control console spew. When running the tests for validation purposes I want to see at most a concise summary of what failed. Preferably (and this is not realized in the current runner, but could be) I want to hear only about new failures.\nLastly, it must be easy to run an individual test in a single thread in such a way that VSCode can run it in debug mode without much fuss.. Using the updated version test/test262 causes the existing test runner to skip many more tests, hence the overall test fails because it still expect to run (and pass) many more tests. You can either update the expected number of passing tests, or use a separate directory for the updated test262.. Are you planning to do any more work on this?. Running the full test suite in parallel is an important scenario for us as we often tweak the interpreter to deal with abstract values. We also would like to improve the interpreter to the point where it can truly be a reference implementation for the specification. All this is easier if we can quickly zero in on any test that starts failing because of a change we made.\nProbably the best way to get there is to have a base line file for recording the expected failures and then to have the runner only display differences from the base line. Some care will be needed to make the results deterministic even when running in parallel.. #1116 should already address this.. In the CS world the word \"taint\" is strongly associated with data that could be controlled by an outside agent (attacker) and thus present a security threat if it flows to unsafe sinks.\nIn the compiler world, the word \"dirty\" is more usually associated with objects that may have been modified. It would be less confusing to adopt \"dirty\" in the place of \"taint\" for this work.. I'm not very happy about the the change to the equals function. I'll look some more into the underlying problem.. There isn't. Sounds like a useful addition.. Please rebase and try landing again.. This is a bit too much for me to chew over successfully since I have spent almost no time trying to understand how the specification deals with classes. It seems plausible and it is probably progress to land this and then fix it as needed. I do hope, however, that considerable pains were taken to make this as close to the specification as possible, so that future maintainers can use the specification as a way to understand and debug this.. Re unit testing: We do not have a unit test framework and instead rely on end-to-end testing,. It is not clear to me why _$0 is needed.. I looked into this and there are two issues here:\n1) Following if (!timespan || !timespan.startTime) return; the inverse condition is not pushed to the path.\n2) timespan.startTime || 0 does not use the path to evaluate timespan.startTime as a condition.\nThe second is an easy fix. The first is going to be a bit more work. I've know about it for a while but so far it has not come up. I guess my luck has run out. I was hoping that Simon might perhaps take an interest in this one.. For testing this you want to add a test case to the test/error-handler directory. The first parameter to __abstract is a template object or a just a type name. You can just use something like \"number\". The second parameter is the intrinsic name. So, \"__abstract('number', 'foo')\" will create an abstract value with intrinsic name \"foo\". The task is to give a compile time error (complete with source location) whenever a call to __abstract will result in an abstract value that has the same name as an existing abstract value.. A FatalError is just a way to terminate Prepack when an unrecoverable error has been detected. In this case, you would first report the error and then throw a FatalError (regardless of what the handler told you to do).\ntest-error-handler.js still lacks a way to filter the tests to run. Adding such a parameter should be easy enough (just follow the pattern in test-runner.js).. You'll need to add a new error code and it should be documented in https://github.com/facebook/prepack/wiki/Prepack-diagnostics. Please use PP0019. There are no reserved names for __abstract and it the method is only called in code that is being prepacked.. Yes those tests should be updated.. You can ignore: // additional functions.\n// recover-from-errors is used to indicate that Prepack should not stop when it reports a non fatal error. A non fatal error (warning) is something that might be over conservative and for which it is possible to generate code that could work given some assumptions that are known to the programmer that chooses to ignore the warning message.. Please attend to the test failure.. The changes to effects look OK to me. I have not reviewed the rest of this.. The serializer is optimistically running code that can fail with a runtime error, without first setting up a context. Rather than have InternalConstruct insist on there being a context, just throw a FatalError if there isn't one. You can also assert that in this case, the realm is in abstract interpretation mode.. We should never expect to fail an invariant.. The tests are not about ToString, so their names are confusing.. These tests should eventually all pass, but right now some of them are expected to fail. Checked in tests should pass at all times, so marking tests as expected to fail is the only way to check in a test before checking in the fix.\nHandleImplicitAbstractConversion is quite verbose, but that is not a problem per se. The \"Handle\" prefix, however, does not contribute anything so it can be removed.. For testing I look to code coverage data for inspiration. If a particular branch is not taken, I try to construct a case that will take that branch. The previous path condition needs to be restored when the normal branch of a fork joins up with the abrupt branches. Following such a join point, all we know about the path is what we knew before the fork occurred. Of course, path restoration needs to take into account any information discovered since the fork (I.e. the joined effects).. Please update your initial comment with a release note and issue number. You can also remove the unfortunate paragraph.. __prepackVersion() would allow the code being prepacked to behave differently depending on the version of Prepack. I don't really have a use case for it. Your idea seems just fine and I'd be happy if you went ahead with it.\nYou don't show up in the choice list for assignees, but consider this issue claimed for you anyway.. Chris and I discussed this face to face and agreed that an alternative approach may be better.. Actually, we like to see that description in the pull request. Eventually there is a bot that creates a single squashed commit using the description of the pull request.. Please rebase and resolve the conflicts.. I've addressed the review feedback and added a bunch of new test cases that provide significantly better code coverage. Not surprisingly a number of bugs came to light. Fixing these resulting in significant code changes.. The \"No sourcemap found at .\" message is something we can do without as well.. We do want the user to be able to give the location of the source map as a flag when using stdin. We also want to give an error when the location does not exist. What we don't want to do is to complain about source maps when the flag has not been specified. The stdin unit tests are working as intended.\nSo, to fix the \"No sourcemap found...\" problem, you need to suppress the message if the flag was not specified.\nThe other problem is that the syntax error causes an uncaught FatalError. Instead, we'd like a nice compiler diagnostic that is printed out with a source location (obviously one that does not include a file name).\n. I'm a bit freaked out about this. The fundamental assumption of Prepack is that we know the whole program. The environment is a bit special, but we assume that the model tells us everything we need to know.\nWith this discussion, we are entering a whole new dimension and there be dragons.\nThe only viable tactic that comes to mind right now is that we should treat local variables that leak out to the environment as if they are intrinsic properties of the global object.\n. CSE should not treat two distinct objects as interchangeable, even if they are structurally identical. If it does, that is a bug.\nAlso note that CSE only applies to abstract values.. The first comment on the request should describe the purpose of the request and what has changed. It should also start off with \"Release note: xxxx\" where xxx is something that can be included in the description of the next release.. I'm curious too, but I do have some actual ideas. :-). That sounds like a good idea because it avoids doing ToNumber yet again. Which actually matters a lot because there might be side-effects. Actually, a test case to illustrate that possibility will be a fine addition as well.. Thinking about this some more I now realize that side-effects will not be an issue. Once a value is primitive, converting it to a number will never have a side effect. It is still a nice idea to avoid the second conversion, but it is not a correctness issue after all. Sorry about my fuzzy thinking on this.. This is pretty hard to do, not least because of that little foot note at the end: \"We'd also need to handle the object passed to the catch.\"\nA possible work around that already works, is to wrap the call to fn inside a concrete model function that checks the preconditions of fn and throws an appropriate exception if they fail. Then we can go back to regarding fn as pure and well behaved.\nIf fn uses exceptions to communicate rare conditions rather than precondition failures, then there is very little we can do statically. This is one of those situations where we throw up our hands and say \"please change your code\". In this instance you change your code by introducing a non throwing version of fn that returns status codes (or even exceptions) as return results.. A more direct way to fit in with current exception handling logic might be to provide a model function that defines an abstract function that returns not an AbstractValue, but a PossiblyNormalCompletion. The conditions we need for the PNC could well come from model variables that are set in a try catch that wraps the call.. The referenced pull requests fixes the particular test case referenced in this issue, but does not fix the prominent one (that the variable _6 is read before it is initialized). That issue will resurface if the second try-catch is removed. The underlying issue with that is variable _6 refers to the value of a residual call. That is temporal and cannot be hoisted. However, there is a reference to it from the top level code, which causes the declaration to get hoisted along with its initializer. If the initializer were not a reference to a temporal variable, this would not be a problem, but since the initializer in this case is temporal, it must not get hoisted. . I think it is done.. We never want a stack trace unless there is an actual bug in Prepack.. A FatalError is the Prepack way of saying \"an error has already been reported, now just stop running\".. It would be a programming error if a FatalError reaches the final back stop without there being a diagnostic, so it would be appropriate to assert this with an invariant.. I'm afraid that it is still used in a Facebook only test. This task is really there to remind the Facebook team to get rid of this annotation. Sorry for wasting your time.. Sure.. An invariant violation means that something that we thought is impossible has actually happened. I.e. you've run into a programming bug and the onus is on the Prepack developers to fix the problem.\nAs always, if there is a simple way to reproduce this failure it will be a great help to the developers and speed up the resolution of this problem.. I don't think the value added by a test justifies the additional complexity in the test setup, so we can let this one slip by.. We still need a lot of work before we can handle every loop in Prepack, but in principle this is doable this year. Another big gotcha is recursive calls, which is something I'm thinking about at the moment. The real killer, however, is dynamic dispatch, such as found in Environment.evaluateAbstract. Prepack will have to be pretty much completed end-to-end before we can deal with that.. I don't have a specific reason to expect an infinite loop, although there may be obscure bugs that cause non termination. The long runtime may have more mundane explanation: since Prepack currently unrolls every loop and inlines every call, its behavior is probably exponential for the kind of code found in Prepack itself.\nI'm afraid that it will be several years before Futamura projections become something we can reasonably expect of Prepack.\n  . Looks like spam.. See https://github.com/facebook/prepack/wiki/PP0017 for why this is a problem that cannot be safely ignored (as it was up until 0.2.6).\nIf this is an area where Prepack needs to improve in order to be useful, it will be very helpful if you can provide a test case.\n. The error handler tests should fail, but this is probably unrelated to your changes. The other test failure is in test262 and need attention.. Any intention to come back to this?. It seems that the only places that call AbstractEqualityComparison would be happy to get a Value rather than a boolean.. The PR seems not to have updated.. I chatted to Francesco about this and it seems that the correct thing to do is to use a Bottom value for the recursive call and to make all of the transfer functions aware of Bottom. I'll put up another pull request doing that, at some future time.. I'm being super conservative about it. Nevertheless, it seems to cover all of the cases I've seen in my usage of Prepack.. I would appreciate to see createFromCoercionOp replaced with a fixed up version of createFromBuildFunction. The latter is more general and I expect to have a use for it later on.\nI'm also still incredulous about the need for the sequence expression.. This is still a non trivial work item. When do you need it to be done?. It took me days to finally wrap my head around this. It is as simple as I can currently get it.. Next time I have 5 years with nothing better to do, I'll see if I can conjure up a Coq proof. :-). Prepack mostly supports ES5 only at the moment since the main scenarios at Facebook happen after Babel has lowered the code to ES5. Hence there is currently no support for module and require.. Prepack has no builtin knowledge of the Node object model. That has to be provided via an explicit model that is supplied to Prepack just like any other source file.\nWe use var instead of let because some environments we care about still do not support let. There are also other reasons that may come into play in the future as code gets moved around and issues like #1266 get fixed.. Removing the calls to Date.now() seems perfectly OK since they have no side effect on the global heap and their results are not used. Keeping the block structure, as in the second test case, is not strictly necessary, but removing it does not seem particularly compelling. Keeping nested empty blocks, however, is just annoying.. This looks fine. The CI failure happens because you've added builder.js to the big import cycle that slows down Flow for us. Since this is a very small module it may be OK, this time only, to increase the cycle limit.. To get past the cycle limit issue, perhaps just add IntegralValue to Number.js.. Prepack has the potential to be a general purpose whole program optimizer, provided that certain language constructs, such as eval, are avoided. In this current state, this is not possible, but it falls within the scope of our ambition for the tool.\nPoint 2 is relevant as an illustration why the term \"whole program\" is the key to unlocking the potential of Prepack. I.e. as long as we know for sure which function will be invoked to convert numbers to strings, we can happily optimize the example function. Of course, knowing something like that for sure, is no mean feat.. Running Closure over the output of Prepack should be possible and hopefully will give you better results than running Closure only.. Right now, probably not. In the long run, Prepack may be able to use pure annotations as a way to speed up the analysis.. If a function is pure, it will not change the global state when invoked. Before we can optimize call backs, we need to generalize the heap that resulted from the global code to incorporate any modifications that can result from call backs. This involves a fixed point loop and joining the effects of all functions that may effect the heap.\nKnowing up front that a function is pure, means that it does not have to be analyzed as part of the fixed point loop, which makes that computation a bit cheaper.\nA further win would be when the function is called. Normally we'd have to inline the function body in order to discover any effects it may have on the calling and global state. This has to be repeated for every call site along every possible execution path, which leads to exponential blow-up in analysis time. Knowing that function is pure means that we don't have to do this.\nOf course, it is possible to make Prepack discover pure functions all by itself, so having another tool tell it a function is pure is not necessarily a game changer. Unless, of course, the body of the function is not going to be available to Prepack, in which case such an annotation will make a world of difference.\n. There is no interaction with https://prepack.io/repl.html.. I don't understand any of this. Why does ProxyValue have its own $Realm property? I would think that just using the property in Value would be equivalent. Can anyone educate me on this?. OK, I've poured over the specification and tried to understand what [[Realm]] is all about. I can't say that it is much clearer now, but it does seem to me that Prepack is significantly different from the spec in this regard, since all Prepack values have a $Realm property, whereas only Function values have a [[Realm]] property in the specification.\nIdeally, the Realm class should be renamed into something else and should live in an untracked property. Then a new Realm class should be created as per the spec and it's instances should live in FunctionValue instances, as well as the non-value, specification constructs. \nThis will be a non trivial task, so for now, the best thing would be to abandon the introduction of getRealm and to change the definition of GetFunctionRealm so that step 2 moves to after step 4.. Also delete the assignment to $Realm and replace all references to \"this.realm\" with \"this.$Realm\" and delete the \"realm\" property from ProxyValue.. Test case?. I'm not particularly happy with this change. The AI engine does lots of inlining and unrolling and this may result in the same error message for the same line getting reported more than once. We should output only the first error for a particular line.  See test-internal.js for an alternative approach to dealing with errors that have no source locations.. Agreed, I'm annoyed too. File an issue. :-)\n. This seems to be a special case of a more general problem that has been fixed already.. Overloading kind with structured data does not really help either. Basically, only AbstractValue.createXXX should ever set kind to anything. Essentially, you are introducing a subtype of AbstractValue, but there does not seem a good way to call that out in the type system.\nPerhaps the best way to keep this out of the non React specific code paths is to not declare reactHint in the AbstractValue class, but use the flexibility of the type system to add and access it only in React specific code.. Instead of assuming that is could we just look too see if it is frozen?. Actually, there is no simple way to transitively freeze objects, so the _simplicityIsTransitive flag is a better thing to test. Done.. Hmm. Treating transitive simple objects as readonly breaks a test. Reverting that for now.. Is this a bug repro rather than an actual pull request? If so, wouldn't a branch be a better way to make the repro available?\n. Marking this as [WIP] would be helpful.. Please fix the Flow errors.. We used to give an error in this situation and it seems like this is still the intention. Needs debugging and fixing.. You are right. I misunderstood your original change. The resulting object from Object assign is going to be simple whenever it is partial because of checks done earlier on. Although objects can be any combination of simple and partial, the simple flag is only needed if an object is partial because in that case it is not possible to compute simplicity. That makes the flags not quite orthogonal. It also means that your original formulation is better than your most recent change.\nTo make it easier for future readers to figure this out, would you please assert that the to_must_be_partial necessarily implies that to.isSimpleObject() is true and refine the comment a bit to make it clearer that explicitly setting the flag is necessary because it the to object is being marked as partial.. __makeSimple() is a modeling function for objects obtained from the environment. In general, modeling functions are not expected to ever show up in real code. We also cannot allow getters and setters to leak to native code via objects since it will be all too easy for the native code to inadvertently call them, which could modify the global state in ways that Prepack cannot track.\nConsequently, option 2 seems to be the only way to go from here.. I don't think #1456 is wrong or dangerous. I do, however, think that any attempt to modify an object, which has the __isSimple flag set, in way that will invalidate the flag, should result in a compilation error. If the object is not reachable from the native environment, nothing bad could happen, but if it is, there might be code running at runtime that has effects that Prepack did not take into account.. To write a failing test case, you probably need to use the // add at runtime: feature. That allows the test to run code that Prepack is unaware of.. In this case the object is not reachable from native code, so forbidding the property definition seems a bit onerous. You would, however, have to clear the flag, leaving the object both partial and bereft of any known property other than 'foo'. That would be pretty onerous too. So you get to pick your poison, but you die all the same.. No further action seems indicated at this moment.. Please fix the failures before requesting a review.. This is just a mechanical refactor with some added comments and some TODOs. We can dissect the details at length in follow up PRs.. Time to update the PR title and summary.. The specific scenario I'm asking about is when a non local unfrozen object becomes a property of a local object. In that case we bypass the logic you refer to. The place where that happens is https://github.com/facebook/prepack/blob/aa393905bf6dec29181cad31205313ad66f7dc78/src/utils/havoc.js#L116. I don't really see how plain object improves on simple object.. Still waiting for a response to my last question.. Please always provide a release note, even if it is explicitly \"none\". In this case, new functionality is being added and this should be remarked upon in release notes.. It is also time to update the summary. As for the release note, you are adding a new feature here, so a release note is appropriate.. This looks reasonable enough, but obviously needs a test case or two.. The evaluate for effects bit should only be done if abstract interpretation is enabled.. test case please.. __abstract() will be of type Value.. I've confirmed that it still works for the website. This is not actually a surprise since the website has no need for the call stack. If need be, it will be quite easy to revert this.. It does look a bit risky to me, but since it passes the CI it seems worth looking at. I'll have another look in the morning.. It is pretty usual to have a maximum iteration bail out with a message since getting fixed point loops to converge and terminate is a subtle process that can easily go wrong.. We currently don't have infinite loops that I'm aware of, so you won't be able to add a regression test for this. You could do a local test by changing the widening function to be a no-op.. It is not obvious to me why this has Unicode in the title.. Please add a proper summary, complete with release notes.. It would be nice if there were a way to mark these tests as expecting to fail, so that CI is not broken. Keeping a PR around just because we don't have a sane way to merge it into master is not exactly optimal.. It does seem that both sides should be empty and, clearly, we need a test case for this.. I'll see what I can do about the multiple calls to Object.assign.. You've recently introduced ObjectValue.isFinalObject. How is that different from what you need now?. Removing it and then re-introducing it in another way does not make a whole lot of sense. If this is a useful feature, then implement in the most straight forward and efficient way. Right now, isFinalObject seems like the better implementation.. This seems fine to me.\nI don't quite see what you mean by this not being safe. Perhaps a test case for that too?\n. I much prefer having an invariant here. This is not a limitation of prepack but a failure in its implementation. If you can get me any kind of repro I can try to fix the failure.. Is this still an issue?. A purity checker will be very useful here. It is not a trivial project. Perhaps a suitable project for an intern?. In general the best way to add failing tests is probably just be pasting them into the issue. When that is unattractive for some reason, then add markup to the test to indicate that failure is expected and the runner must ignore the test . Be sure to add the path to the test in the issue.. This PR is no longer needed.. The serializer already has a logging infrastructure.. The Logger API is a bit strange, but passing in a value that is not intrinsic will in effect ignore the value. Mostly, the logger infrastructure separates mechanism from policy (leaving the latter up to the driver program, not the Prepack infrastructure), which is why I'm in favor of using it.\nFeel free to make the Logger API a bit less strange.. In general, there are many different kinds of k limits and we probably need to use a less general name for this limit. I also suspect that this one is not as deterministic as we'd like it to be. Eventually, we'll probably want to take it out again (after adding a variety of more specific k-limits, along with specific recovery for each kind of limit).. We clearly don't want to bail out at the root of the component tree. To keep things simple, why not bail out at the leaf?. There is some loss in precision. It does not seem to matter in practice and subsequent changes might introduce even further losses if it means better performance.. Shouldn't \"// abstract effects\" be removed from the test cases as part of this change?. You also should write a release note. This affects visible behavior.. It looks simple enough, but the test failure probably needs a bit of investigation.. Please provide a description.. The fundamental reason for that is that we generate the loop body from the fixpoint, which is a common approximation of the state at the end of each loop iteration. Since the i++ is part of the loop body, the value of i that ends up in console.log is fixed and becomes insensitive to its position relative to the increment.\nTo fix this, we would need to have a separate abstract state for each temporal point. I.e. every generator entry should carry an abstract state with it.\nFor now, this seems more work than is reasonable to take on in the near future.. Astute observation. It turns out that the problem was that the loop termination test was not emitted into the loop body generator at the correct temporal point.. I've put back the invariants and instead added a check to pushRefinedConditions, so that other uses of pushPathCondition and pushInversePathCondition are still protected from programmer error.. I'm not sure this will work for switch statements where the case labels are runtime expressions. Can you add test cases for that?. Partial objects can only be simple if they are explicitly declared to be so, in which case we just assume rather than determine.. I don't see a problem with this line.. OK, the basic problem here is with the definition of \"simple object\". If is the original \"does not have getter and setters\", then target is indeed simple.\nSince we now want \"simple object\" to mean \"does not do funny stuff when you get/set a property or convert the object to a primitive\", we can only conclude that target is simple if all of the arguments to the Object.assign are simple as well and we need to update the implementation of Object.assign to be more careful before it designates target as simple.\nWe also need to add logic to ObjectValue.isSimpleObject.. @sebmarkbage: I don't understand your point about bloated code. Can you explain a bit more?. See #1697.. That is one of the approaches I have been thinking about. It also seems to me that this might be another place to use snapshots.. Before we can hope to deal with this, we'll need a range domain (#1066).. Yes, with loops you have to widen and once you widen, precision is lost. Range domains let you regain some of this precision. If you range over an unbounded collection of strings and use them as property names, it's pretty much game over.. We can do weak updates only if there is a join condition that is stable. A widened property name does not fit the bill.. If you want to use the object before the loop, a snapshot should do the trick. I'm not sure if we can do this without the aid of an annotation. Could you provide a complete test case that represents the scenario you care about?. There should be clear guidance to future developers about which level is appropriate for a given invariant check. I expect that 7 levels will be a challenge for such guidance, so consider reducing the number of levels. Also consider the burden on people who will specify the level number on the command line: how do they decide what is an appropriate level?. There seems to be a bug in depcheck. It will help if you can attach the output you get when you run flow check --profile on this branch.. There does not seem to be any improvement in Circle CI times.. This is indeed kind of like a loop. In the static analysis world, this is know as computing the outer fixed point. Doing it properly is a bridge too far for us right now, so some hackery will be require in the meanwhile.. This is under the control of a flag that you can toggle in your case. The motivation for the flag was to cater for applications where errors are expected and surfacing them to end users is very expensive noise.. I forgot that the second case is turned into a for loop under the covers.. Here is a reduced test case:\n```\nvar x = global.__abstract ? x = __abstract(undefined, \"({ check: false })\") : { check: false };\nfunction func1() {\n  if (x.check) {\n    throw new Error(\"This should never happen\");\n  }\n  return 1;\n}\nif (global.__optimize)\n  __optimize(func1);\ninspect = function () { return func1(); }\n```. https://github.com/facebook/prepack/pull/1758 is indeed the cause for this. Joining the effects and making a generator from it results in top level generator entries getting lost. I'm looking into it some more.. This appears to be the same issue as #1766.. You can close this now in favor of #1795.. We should probably change things so that generator.derive is an implementation detail and only AbstractValue ever calls it. Not in this PR, of course.. This may be related to https://github.com/facebook/prepack/issues/1766.\nThe reduced test case there does not do any mutation, so mutation may not be relevant to the issue.. This happens because of simplification. You can turn that off with an optional argument to createFromConditionalOp. Since simplification is a \"Good Thing (TM)\", it also bears asking \"Why has value not been simplified before calling _resolveAbstractValue?\".. Since there is no catch or finally handler in the picture, no generator should appear more than once, so this is clearly not what we want.. This seems to be React specific.. Thanks, that helps.. When two effects are joined together, or composed together, the result does have a set of created objects that is the union of the two. This does not apply, however, to the effects that get put into the result of Generator.fromEffects. Those always seem to have empty sets of created objects.. It also turns out that when completions are rewritten as a result of reaching join points (for example, removing all return completions from a joined completion tree), the invariants established by the original join will no longer hold. This is not an accident, but necessary. Re-establishing the invariants will take effort, so we need to think carefully about relying on them.. You have increased the cycle length.. Perhaps rename __sideEffect to __safeSideEffect to emphasize the responsibility of the author to ensure that nothing bad will happen despite the side effect.. This looks good, but it would be awesome if you could add a regression test that fails without this fix.. Please fix the lint problems.. This may be a tough one to take on while still learning the ropes.. Thanks for doing this, it is very helpful for directing the search for a fix. At the moment, I think your fix treats the symptom and not the disease, so I'm not going to say go ahead with this, just yet.. This PR is now seriously stale. Can we go ahead and close it?. I'll have a look at the failure.. We have not updated our test262 link for quite some time now. We really need to do it. Problem is, we can't do it from GitHub.. I'm currently working inside this code with a bug that I still don't fully understand. Please put this on ice until I have made some progress.. I'm done with my task. You can now rebase.. I suspect that the problem lies with Prepack's special handling of require. I doubt that code takes strict mode into consideration.. If we havoced everything that is read by an optimized function, we'll probably find it impossible to do any optimizations at all. Right now, we assume that we can only optimize functions that get called after global code has ended, but BEFORE anything else (that might touch what they read) runs.\nIf we wanted to enforce this automatically, we'd have to analyze every other function under some very pessimistic assumptions. Even then, we'd be very dependent on the assumption that we can analyze ALL of the code that could run. Of course, this means no eval, but it also means that we either have disallow calling a closure that are passed in as parameter, or that we get so pessimistic that we'd have to conclude that EVERY other function can interfere with our optimized function.. If that is the case, things are a bit harder. I suppose if you fork the code base, you can edit the forked wiki and point to it in the PR. Any other suggestions for a good workflow are most welcome.. It probably would make sense to put all of our documentation in a source controlled folder.\nFor now, however, let's stick to the Wiki and let's keep talking about the best way to do this. For example, which GitHub projects are models that we should look to for guidance?. The second call to Array(n) does not seem special in any way and may as well get fixed as well.. These invariants are not expected to hold.. We don't seem to have an existing negative test case for this. The place to add new test would be in test/error-handler.. You would use __abstract. Look at test/error-handler/member2.js for inspiration.. The source maps test requires a run time exception. Perhaps that exception is now gone? Some debugging is required, no doubt.. I need to look at this for a bit longer.. OK, here is what I understand: Currently we require operations that call ToObject to not do it, or to undo it, when they end up emitting code that will do the conversion implicitly at runtime.\nWith this PR, the caller of ToObject now has to tell ToObject that a conversion will be done implicitly at runtime, after which it changes the kind of the wrapper so that the serializer can omit the wrapper.\nI don't really see how this is an improvement. Moreover, there are some tricky issues at play. The call to ToObject may result in code executing and the code may have side effects. Even in a pure scope this may be OK, for example because only local state will be modified. Since Prepack tracks these effects, there should be no problem from that side either, as long as the conversion does not happen again at runtime. This requires careful coding at the sites where ToObject is being called and then unwrapped.\nI think this PR makes it less likely that we'll carefully review all such cases.. It also solves that test case.. I think it is redundant.. The model invariant violation came about because the result from filter was not marked as being partially known.. It seems that an array with a widened numeric property should not be regarded as partial then. I'll see what I can do about the invariant checker.. If I make the result from Array.prototype.filter be a proper array (by using Create.ArrayValue, as we should), then everything seems to pass.\nIf, however, I go one step further and  set the length property of the array to be an abstract number, then the React test suite fails.. I'm on call this week so I'll have a look.. The provided test case passes on master.. It would be awesome if we also had a test case that actually checks that the Prepacked error constructor call did the right thing.. Oh, never mind. I was looking at the output not the input. The test should be fine.. The depcheck test is flaky on Circle. Nikolai reported it the Flow team, but so far no enthusiasm from their part. To be fair, this a hard thing to debug.. Agreed. The more validation we can do of Prepack output the better. BTW. Prepack can easily be enhanced to be the best linter ever, at least for global code.. It looks like the latest build has a real Flow issue.. Please rebase this when PR #2092 has been merged.. These failures could be related to the problem that shows up with this repro:\n```\nfunction fn(arg) {\n  if (arg !== null) {\n    if (arg.foo) {\n      return 42;\n    }\n  }\n}\nif (global.__optimize) {\n  __optimize(fn);\n}\ninspect = function() {\n  return JSON.stringify([\n      fn(null),\n      fn({}),\n      fn({foo: true}),\n  ]);\n};\n```\nIssue: #1867. This is now stale.. I am confused by this, so code comments will be very helpful. The lack of a small example of this effect is deeply troubling.. Examples like these can be handled by using the same technique as PR #2173. It is a very specific and limited hack, but if there is real code out there that would work because of it, I can take this on.. We do use different error ranges to group together related messages, so that future tooling may have an easier time to find particular kinds of errors.\nI've updated the wiki with headings to reflect current conventions. When you want to create a new diagnostic that does not fit into one of these categories, open an issue so that we can review the situation and create the category if needed.\nWithin an existing category, just grab the next available message number.. This is a refactor on the way towards fixing something. Lots of existing test cases touch this code.. It seems to me that the recovery code in CallExpression.js is too optimistic in this case. The concern in the Object.assign code is legitimate and just ignoring it does not seem safe. It seems possible to construct a test case that will do the wrong thing with the current implementation.. Nothing jumps out at me, but I'm pretty unfamiliar with this part of the code, so you should twist Dan's arm a bit to also look at it.. Ideally, we need tests that will fail without this change. One way to do that is to add contains constraints to some of the existing tests.. Updated this to no longer require recordModifiedBinding to update the map entry on every modification. This makes the code simpler and also will be consistent with the (only reasonable) way that property bindings will be tracked.. Sorry for taking so long to respond to this.\nIn essence, Prepack is an optimizing compiler for JavaScript. Your proposal would add optimization rules for functional programming patterns, which is becoming important for JavaScript. As such, it seems very much aligned to Prepack goals.\nWe currently have very little support for looping constructs applied to lists of unknown size. That may be something of an impediment to you. Alternatively, think of it as a juicy challenge. :-)\nPlease feel encouraged to dive into the code base and put up some pull requests. Also feel free to reach out to me if you need some help with understanding the code base.. There is no call here, so the output is actually as expected.. I'm afraid I just forgot about it. It looks like we'll have to resurrect something like this after all. I'll have a look at it.. This sounds like something that I ran into using the serializer test suite for additional functions. Ultimately, the right fix is not never apply effects after serialization has started. For now, I've been able to work around this by means of the capturePrestate flag on the realm. This works by saving the current state of a binding into the Effects object whenever redo is called with this flag set. That is more or less what happened to bindings before PR #2134.. I was hoping to get this PR landed and then go from there.. Thanks, that helps to show what is going on. Sadly, it shows that there is another case where CSE is going on and for this case the capturePrestate flag does not help. Generalizing the update logic leads into a rabbit hole of applying effects that have already been applied and things seem to get pretty hopeless from there.\nI suspect that the only way to get immutable effects working is to stop applying effects while already running in serialization code. For now, I'm unable to make further progress on this and this PR will have to go on ice.. No longer needed.. Some things are best done when fresh in your mind and not when time presses.. Subsumed by another PR.. This is an instance of a known problem with composing two forked completions. I'm currently working on the general problem.. This enumeration just sounds wrong:\nan abstract top object value\nan abstract value \nan abstract value that is a conditional or logical operator that has 1 one or many of the above abstract top values or abstract values (recursively).. How about just using __residual for this?. The output for the first test case now looks like this:\n```\nlet x;\n(function () {\n  var _$0 = this;\nvar _0 = function () {\n    JSON.stringify(x);\n  };\nvar __empty = {};\n  _$0.inspect = _0;\n  var _1 = [43];\n  var _7 = true;\n  if (_7) _1[1] = 44;\n  x = _1;\n}).call(this);\n```\nIt would be better to not have the declaration for empty and to inline variable _7, but those are artifacts of the keeping the serializer invariants in tact.. Yes, this technique is applicable to all loops and it preferable to widening since it does not lose precision. On the other hand, it is very costly and may increase analysis times beyond what we might want to tolerate.. This PR is failing the internal React compiler test.. @trueadm  Rebasing this to see if it help with the internal test failures.. This is not compatible with the full join approach.. The new version of BabelCore does not seem to work with test-react.. Your yarn.lock file has a lot of changes to it. When I do the same thing on my machine I see only a few changes. Perhaps revert those changes and try again?. It seems important to make sure that we have 100% code coverage for the new code.. Except for the last new test case, it is not obvious to me that the new test cases will fail on master.. Looks like this one is all yours. Enjoy. :-). Nice.. If a template  is not intrinsic, it is not a template, but a singleton object. That case can arise because of joining. I expect it to work as is.. Sadly the test262 suite still does not have a test that fails for this issue.. Nice idea. I've wanted this for quite a while now. Doing it is a bit tricky and I'm dubious about this PR. We don't want to print the same output twice, so when a test succeeds, only print the output of the last iteration. Also be sure to test what happens when a test fails. In that case we don't want to print the output again, even if we are in verbose mode.. I'll put up another PR for the todo.. It looks like you need to rebase this so that it picks up the latest test262.. This last change is a step in the right direction, but it does not feel to me like we are quite there yet. In essence, I think, the basic idea here is that throw completions should get joined (and then forgotten) when we leave a pure scope. That way, we do not need a flag or special logic all over the place. The method you want to use is Join.extractAndJoinCompletionsOfType.. When did you try? Things might be more correct now. Also, you should not apply the joined effects. I'd rather fix the right approach than bang in something that we may never actually get around to removing and that can make it ever harder to make any change to Prepack.\n. Here is a simpler repro, distilled from the one above:\n```\nlet c1 = global.__abstract ? __abstract(\"boolean\", \"true\") : true;\nlet c2 = global.__abstract ? __abstract(\"boolean\", \"false\") : false;\nfunction foo(cond) {\n  if (cond) throw new Error(\"I am an error!\");\n}\nif (c2) {\n  foo(c1);\n}\ninspect = function() {\n  return \"success\";\n};\n```\n. There is another problem with the original repro: When the return value from fn is combined with the PNC that contains the unhandled exception, it is not added back to all of the normal paths, but just one of them. Moreover, the return value is simplified with the path condition of the single path and hence the undefined value sneaks in. This is a specific instance of the general class of problems that I'm trying to resolve with a redesign of PNC. I may, however, be able to come up with a short term hack to make this specific kind of problem go away.. I'm a little bit conflicted by this. I've become used to \"yarn flow\" as being a complete check that is not dependent on the usually broken and non responsive state of the flow server. For a quick check from the command line I just use \"flow\", which has the additional nice property of always using the latest version of Flow and alerting me as soon as possible of any new issues uncovered by Flow.. The test case file name ends with \",js\" rather than \".js\".. Nice work, but it seems that we have a race condition here. See PR #2250. If you rebase on top of that, it would be easier to do a detailed review.. The added test case passes for me. No idea why it fails for you. I've added it to suite, let's see what CI thinks of it.. I don't think we are at the point where there is a 1-1 correspondence between generator and effects. Although that seems highly desirable, it will make it difficult and expensive to do joins and I need to do a lot more thinking about this.. https://github.com/facebook/prepack/blob/master/src/realm.js#L1053 occurs when one (but not both) of the forked paths turns out to be infeasible. When that happens there is no fork and hence nothing to compose. Clearly, this explanation should appear in the code.. The links seem stale. Is there a test case that can reproduce the invariant?. I'm looking into the bug.. I've verified that this invariant is valid with #2402.. I suspect that landing this would create merge conflicts for #2402. Once that is landed, I expect the tests to pass and you can land them without having to revert #2274.. We can't merge this unless the test suite passes. That probably means reverting the actual code change and marking the new test cases as expected failures. Add \"// throws introspection error\" as the first line in the test case.. Please ensure that the test suite succeeds. Just change to failing test to expect failure.. I notice a lot of TODOs, so it seems that some design discussion might be in order. Right now, I'm still trying to understand the difference between materializing an object and snapshotting an object. I would love to understand that in some detail. Perhaps we can all get in a meeting room and discuss this in real time?. The fact that you need the composition of two conditionals to reproduce this makes me think that this is related to the problem with partial joins.. Looking at this again, I think the key issue is that a (still to be computed) value x that depends on a (still to be computed) value y should always ensure that y is computed in a path that dominates the location of x.\nKind of compilers 101. Bugs will happen. Let's fix this.. #2330 is too simplistic, so that test cases that fail it are not useful. Is there another test case that fails even without #2330 ?. Generic serializer tests are VERY desirable. A blessing on your house for every one you contribute. :-). There is one test that uses \"// simple closures\". Perhaps update that. When did simple closures go away?. I believe it is related to the problem that I'm already working on. I'll check back when I finally get that problem sorted out.. --srcmapIn should probably become --scrMapInPath and it should be a single string.. Simple is a property that can be checked on concrete objects and something that is declared for partial and abstract objects. It applies to any kind of object.. I've deleted the entire residual feature. It did not have a lot of tests to begin with and nothing there would add to our other tests.\nFor review, the most interesting bits of code to read would be the logic for try-catch, for loops and function calls. Most other things are just infrastructure for those.. Working on it. D9258610.. I peeked at the code coverage information for both this PR and master and it seems identical in both cases. Do we have reason to believe that these test cases will catch regressions that the existing tests will not?. This is somewhat out of scope for Prepack. The main aim of Prepack is to optimize code that was written by cooperative developers who are not doing anything to violate Prepack requirements and assumptions.\nThe seemingly redundant assignments have been retained by Prepack because they \"leak\" into the global scope and Prepack assumes that the program is not done running when global code has returned to its caller. To large extent the very purpose of Prepack is to speed up the initialization of a global scope that will be used after global code has finished running.. The change itself looks good, but your new test case is failing.. I have my doubts about this. The effects of a composed completion have already been applied and should not be undone. That bit of functionality is purely there for effects that are still under construction. Let me look at the issue itself when I get a chance.. @trueadm: The issue in #2361 does not reproduce for me at all. Oh wait, I assumed it was a serializer test case. I'll see what I can do using debug-fb-www.js.. @trueadm Sadly, the internal React test is failing, presumably because of exceeding implies limits (a lot of those appear in the log output). Could you have a look and give a prognosis of how fixable this may be?\nIt might be necessary to make some changes so that simplification has a better worst case complexity. (And that may not be easy at all.). I've tried to scratch this itch a number of times already, but always backed off because the magnitude of the change seemed risky and the benefits are ultimately not entirely clear.\nThe diff is pretty hard to review, so I would ask that it be purely \"mechanical\" with no changes of functionality or bug fixes.. \"These are all typed as arbitrary an inexact object where all the fields are optional. That means that essentially any object with any typo can be assigned to a descriptor.\"\nAs a first step, the existing type can just be made exact, no?\n. It seems that the nice performance win I thought I saw was due to just doing much less necessary work. Running on the latest bundle, the performance win is modest.\n@sebmarkbage If line https://fburl.com/j6s3q3xq is deleted, the runtime for the internal test more than doubles while the results appear to be the same.\nAnother concern: Fewer components get inlined with this PR than with master: 798 vs 868.\nOn the other hand, more components get inlined in the test suite.. I suppose my real question is: Could there be less inlining because of increased precision? If so, less could be better. How does one tell?. The empty value is supposed to be unreachable, so it does not really matter if it is modeled as undefined in this situation. I do plan to get rid of this use of the empty value in the near future, which will make this into a non issue. Meanwhile, I think this change is fine.. Is there another profiler with better support?. Great to hear. If you would like to put a pull request to do the substitution I would be happy to test it locally.. Prepack does not report a single issue with multiple error call backs. It does, however, report the same issue multiple times because the abstract interpreter may execute the same code block several times for various reasons.\nYour UI changes are looking good, but I would prefer to see the error messages in the same pane as the source code since they pertain to the source code, not the generated code. I also wonder if there is a way to highlight the source line (preferably the source extent) to which an error refers.. It would be better, yes. Perhaps \"// Prepack is unable to produce output for this input. Please check the left pane for diagnostic information.\". This seems simple enough, but I am lost trying to figure out why you need it. I'm also not quite sure it is correct. I don't have any particular reason to believe it is incorrect, but it is not OBVIOUSLY correct either.. For the loop case, when would two different intrinsic abstract objects need to share the same template?\nIf the abstract value is not intrinsic, there is already no impediment to sharing the template.\nIt does seem sensible to just drop externalTemplate for now.. I don't understand why dropping the externalTemplate option requires dropping rebuildNestedProperties. I also don't understand why #2543 requires you to have two distinct intrinsic abstract objects that share the same template object.. I am deeply uncomfortable with this. We talked about how to use two templates for one abstract object value as a way to indicate that the identity of the abstract object is not known and possibly not unique.\nGoing from there to having two abstract objects that share the same template object is not obvious to me.. We did indeed discuss the need for a flag. Perhaps there is no need for multiple templates in that case. We'll see.\nI don't recall us discussing the scenarios you allude to above and in #2543. These are not supported by a simple widened object abstraction and we should take some time to hash out what can be done about them and how to do it.\nAt this stage I am deeply skeptical that letting two abstract objects that may have distinct identities share the same template object, can possibly be a safe solution. Let's put this PR on ice and follow up with an depth face to face discussion about the underlying problem.. I'm not comfortable with this. I think it is fine to use the value of an outer scope variable, as it is at the time __optimize is being called, but any attempt to modify the variable after that should produce a warning.. I've looked at this some more and I'm wrong about the JSON.parse(JSON.stringify(ob)) cloning special case being about materialization.. This seems to be some kind of interaction between optimizing nested functions and joining the state of the local variables of module.. There is a such an option, see the --help of prepack_cli. How are you running the tool exactly?\n. We do run that website. I guess we just did not expect anyone to try such large programs with it. You should probably try to use the command line interface. See https://prepack.io/getting-started.html for instructions.. The spec requires RangeError in quite a few places and never specifies a message value. It seems to me that it would be more sensible to deal with this situation inside the RangeError constructor than to just sprinkle TODO strings around the code base.. This makes me so happy. :-). In the Python world reviewers will insist that you say \"let lval = GetValue(realm, lref).assertReadable();\". I suspected you could use Flow type cast syntax here: \"(C : ObjectValue)\".. \"(length : number)\" would be more efficient since it gets erased. I suspect that you could also just say \"let length : number = ...\". I have no idea what this is supposed to mean.. I hope there is a better way of saying whatever this is saying.. Do you really want enumerable to be true?. Agreed.. This bit of the specification seems redundant. Perhaps I'm missing something.. The labelSet is not actually used for anything.. Using a for loop here instead of two assignments seems a bit over the top to me.. ToBoolean might have side-effects. It seems a bit weird for assertXXX functions to have side effects.. An alternative design here would be to make ToBoolean aware of partial values.. I'll come back to this soon.. Whoops. Will fix.. This is the one line fix that makes the two additional tests pass.. HasOwnProperty, GetReferencedName. Many people prefer this formatting convention, but it is not the one that is currently used in this project. It is better to stick to a convention you don't like than to introduce many different conventions.. One cannot just do nothing when the AST does not look the way it should. If this happens throw an exception.. \"ObjectLiteral\" && LeftHandSideExpression.type. Aligning the = is not convention in this project.. Abrupt completions are modeled by throwing exceptions, so yes, not necessary.. Section number comments missing.. section number comments.. The spec seems to have a typo. The context makes it clear enough that it should also return true.. What's with this comment?. Please always remove commented out code.. I have been wondering that myself, but it seems like a big refactoring that is probably not the most important thing we can do right now.. Lint rules object.. Agreed. However, it is somewhat less bad than returning undefined. I'll get back to this when I do a complete pass over the evaluator to track everything that is not compile time constant.\nI'll add a comment.. Reading enigmatic comments can be like looking through a glass darkly.. It is already quite unlike the spec and I wanted this to be a bit more like the cod below.. The !! is not needed.. Do you need this? The type annotation seems to preclude it.. Ditto.. I find this cast surprising.. We probably don't need our own Location type anymore.. Another way to deal with this is to extract ast.id into a local before doing the test in line 19.. Both Flow and the Linter are unhappy. Please fix and update the pull request.. The invariant is here solely for the benefit of Flow.. TODO. Not yet.. Point 1: Agreed, but I'd like to come back to this later with a much better abstraction than OpaqueValue. Right now there is enough here to unblock our particular use case.\nPoint 2: This invariant is not enforced and does not seem necessary either. The likelihood of this arising is pretty low, however, so a special case does not seem worthwhile.\n. Not yet.. I'm not 100% sure you are right and it does not seem easy to get 100% sure about this, the way the spec is written.. This does not preserve the order of properties if there were deletions. I don't think we should try to do that.. The assumption here is that the caller is going to update the property map of obj immediately after the call and that desc will be the new value. Descriptors are internal data structures and updating the property map will drop all other references to old_desc.\nIn principle this is somewhat brittle, but if there is code that holds on to old_desc we are already in deep trouble, regardless of whether or not we clone old_desc. I'm pretty sure there isn't such code now and that anyone introducing such code will find that things stop working pretty dramatically.. Sad, but probably accurate. I'll attend to this in a later pull request.. I'm not sure that the type test is useful. The dynamic value could well be something other than a number and things would be work just fine if you removed the check.\nIn general, a partial evaluator is a different beast from a static analysis too for finding bugs. In the former case we should preserve bad runtime behavior, in the latter case we want to report potentially bad behavior even if it is not guaranteed to happen at runtime. As a consequence many things are different between them, particularly when joining abstract values.. I switched because leaving default in place did not work. I'd love to be consistent, but I have not figured out a way to do this.. It's a TODO, as pointed out in the pull request description.. abstractValueForConditional declares it as a nullable type because IfStatement can have it be missing. The checks above are not necessary and I'll remove them.. joinValuesAsConditional always returns an OpaqueValue. We could generalize it but that does not make the code any easier to read. I expect to do some more work here in coming pull requests and things will probably change.\nLooking at this code again, however, made me aware of a bug: If statements always return empty.. Should I gather from this that the serializer does special magic with the arguments of the buildNode function?. Good catch. Fixed now. Also added some test cases for ||.. Adding an intrinsic for this case would be a tad more consistent to me.. This is not strictly true. There are some tests that only work in strict mode and other are not expected to work in strict mode.. You are not really spinning up a process here, so the message may be confusing.. \"Bailed\" does not say much.... debug is probably not the best name to keep in the code.. Agreed.. \"More work remains to be done, but I'll put up separate requests for those.\". I think this is too general.  It should probably be Array.. To be consistent you should create a typed local for this expression.. At this point we know that locString is always going to be \"unknown\".. Shouldn't the comments be indented as well?. Flow was actually pretty helpful. I looked at every change I made, but don't trust me either.\nStill to come: some of the now rename xxxPartial functions return values that are guaranteed not to be abstract. That is wrong and I'm looking into that.. This seems wrong to me.. Maybe, but why was it \"abstract_boolean\" in the first place?. Is this a special comment, or just excessively ironic?. It would be pretty helpful if the number of ES5 tests that are expected to pass allows for a smaller number when the time out is left at its default value. Specifically, 4 tests are expected to time out.. I hate implicit conversions from numbers/pointers to boolean values.. Or we can require the call sites to not assume that !IsNotNumber(x) == IsNumber(x). It turns out that they already do not assume this. In only one place does the else branch not explicitly assert that x is concrete and even there the first call is to ToNumber(x), which asserts that x is concrete.. Sure, but that intrigues me. When would be possible for values from different realms to intermingle? What else would break?. Perhaps endsWith rather than includes?. OK. This comment seems incomplete.. I don't think that will be less surprising.. oops. In this method the size 1 case is indeed a special case, but I treat it differently because that is the prevailing pattern in the class and deviating from it would be surprising to someone not familiar with the code.. There should  be a check.. sp?. I don't think that moving this function will make anything better. I like things to be broadly applicable and if it comes without runtime cost, what's not to like?. The purpose is to do strong updates, but allowing accessor descriptors is nice too.. To be consistent.. Yes, this is more restrictive than it has to be. Will fix.. Will fix.. Will fix.. Will fix.. Will fix.. AbstractObjectValues are built up incrementally, so the invariant is not true at this point.. Will fix.. Will fix.. It should be cloned.. Do you really want to dump things to the real console when this.consoleOutput === undefined?. Can you explain the motivation for this flag?. Is the // TODO still needed? If so, can you describe what needs to be done?. This should be a NativeMethod or some such thing.. Ouch!. success &= CreateDataProperty(realm, obj, \"value\", Desc.value); seems a bit more readable to me.. Actually, we'd like an __IntrospectionError here, along with with some contextual information on the cause of the failure. \"string.assertConcrete()\" is a handy method that will do just that. (Yes, it does need a better name.). This does not seem to conform to http://www.ecma-international.org/ecma-262/7.0/#sec-date-time-string-format.. It is not clear to me that there is any reason why non UTC formats should not be allowed to flow into Date.parse below. The date value that comes back is entirely dependent on the string, so it is a candidate for doing at build time.\nNote, however, that strings that do not conform to the ECMA format might fail to parse at build time, while parsing just fine at runtime. You should therefore check if Date.parse returns NaN at build time and throw an introspection error if it does.. Your change does not entirely fix the failures uncovered by this (but will if you fix your format string).\nAlso, you should remove the option as part of this fix.. Ah, a (not so useful) Flow error, I presume. And yet it happily allows converting number into boolean ins other contexts.. It is precondition, but a rather complicated one. \"descValue instanceof AbstractValue\" is neither possible, nor sufficient at the start of the function.. Seems accidental. I've undone it.. I've changed things a bit more. It is now the responsibility of the write to remove the emptyness. Otherwise we can't check for emptiness when deciding if we need to run up the prototype chain.. It is not UTC that is the problem. Any time zone will do, as long as it is explicitly specified. So, check for the time zone being there, but do not check if it is UTC. In fact: \"When the time zone offset is absent, date-only forms are interpreted as a UTC time and date-time forms are interpreted as a local time.\", so you only need to worry about date-time formats.. At least remove the TODO and update the comments.. Also, this is only an issue if realm.isPartial is true, so check for that.. I can't convince myself that this is correct.. What should happen when buildNode is not a function?. This seems wrong.. Perhaps rename this to inputMap.. I'll get back to this in a later request.. When we know nothing, we do not know that the values domain includes the empty value, so returning false here is appropriate.. Yes, this is trail balloon. If you like it, I'll do the others too.. My suggestion is that you accept any string as input. You just need to check two things:\n1) The result is not NaN.\n2) The string is not a date-time form that is missing a time zone.\nWith these two provisos, we can assume that the Date value coming back at build time will be exactly the same as the value coming back at runtime.. string.throwIfNotConcrete() is the new name for string.assertConcrete().. The point of this is to make it very clear that the negation is \"mightBeUndefined\" which is very different from the presumed negation of \"IsNotUndefined\" which is \"IsUndefined\" which is actually not true because of the \"don't know\" case.. To shut up the linter consider \"bindings = undefined;\". This is the advantage that it drops the reference to the unused data, possibly freeing it up during the next GC.. Actually, if mapfn is an abstract value it is quite OK to call IsCallable on it and IsCallable will only return true if mapfn is a concrete function (or callable object). Hence the mapfn.throwIfNotConcrete() precisely recreates the behavior of HasCompatibleType.\n. why not !== ?. We are trying to stick as closely to the specification as we can. Obvious correctness trumps performance, since this is mostly a reference implementation and static analysis tool, not something that is expected to run the code very quickly.. Here I expect to see \nfor (let name of BoundNames(realm, ast.declarations)\nYou'll have to add logic to the BoundNames function in methods/environment.js, since we have no overloading in JS (unlike in the spec). Just be sure the reference the relevant portions of the spec.. I don't think you need the first part of the conjunction.. I have gone back to a class hierarchy and I've renamed this to PossibyNormalCompletion.. Our convention seems to be that require should not be used directly.. It this the recommended way to add a new property to an object?. I think you can make this well typed by changing buildMathTemplates into a map from string to [Function, Array].. Updated the logic to explicitly test for the case where mapfn is in an indeterminate state.. I'm not a fan of this formulation of Boolean. My preference would be to type this as boolean and to explicitly initialize it to false.. While you are here can you fix the indentation as well?. I'm a bit surprised by this. The type signature of evaluateCompletion guarantees that blockRes is of type AbruptCompletion | Value | Reference. So why weaken the instanceof check? Could it be that you are working around a bug rather than fixing it at source?. if () x;\nelse {\n}. My approach is to make things general unless there is a compelling reason not to do so. Right now, there is no use case for a simple object that is not partial, but it seems imprudent to assume there never will be.\nThe formatting code assumes mutual exclusion, which is clearly wrong. I'll fix that.. Let's get back to this later. I don't much like __makePartial in the first place, so by extension I don't like the current design of __makeSimple, but it is better to be consistent.. Good point, however, simply removing the previously existing properties is not good enough, so I've changed the code to just throw an introspection error if the target object is not empty.. The comment now seems stale.. Why any?. Not currently used, but added for consistency. Will be used in a future pull request.. a check. in line 262 above you throw if object is not concrete, yet here you assume that it can be an instance of AbstractObjectValue. That seems a tad strange.. Why not make this a class?. This leaves me bemused.. Not introduced by this diff, but while we are here, why explicitly apply splice to body? It seems to me that one could write \"bodyReference.body.splice(bodyReference.index).concat(functionBody)\", which raises the question: why splice at all? It seems that \"bodyReference.body.concat(functionBoy)\" should be equivalent.\nPerhaps I'm missing something, but nevertheless this bit of code is mighty strange to read.. Passing in a body only so that we can check that it is equal to this.body seems a bit strange. If you want to do this check for sanity's sake, it will be much more readable if there were a separate method with a name that makes it clear that it is doing a check.. Types are kind of like interfaces. Normally, I would not define an interface unless there are potentially more than one possible implementation for it. In this instance it is not clear to me why a single object literal + type is better than just writing a class in the first place. Doing the latter is a bit more consistent with the overall approach in the code base.. \"announce\" is perhaps a bit too cute for what this function does. It seems a bit misleading to me.. This gives me pause. In general, serialization should not evaluate computed properties. Perhaps this code should fetch the property and ignore it if it is not a data property?. Perhaps name this assertTopAndPopContext?. Parse errors should always present themselves as ThrowCompletions, so we'd want to know when that is not the case.. The \"true\" argument no doubt makes a lot of sense when you are writing this code, but when it reading with little context, one wonders just what it is about. Can the readability of this be improved?. Couldn't you make this a type rather than a class?. I'm getting cold feet with this terminology. We are always partially evaluating. Perhaps \"abstract evaluation\"?. I want to have the normal completions in a separate group.. I'm none too sure about this comment. It seems to me that you are taking JS value and making a corresponding Prepack value.. Agreed. Will do soon.. This seems reasonable to me. I think you should break it out into a separate function and co-located it with execute. Likewise, you may want to break out lines 176-197 and co-locate it with execute in environment.js.. Probably a merge bug.. Avoid \": any\" if at all possible. In this case just use \"bindingId\", which is already the string value that results from \"declar.id.name\".. While you are at, why not break up this line as well?. Coming up with a meaningful name seems hard, which makes we wonder if introducing a name here is actually of any help at all.. The value 2 needs a comment to explain why it is not 1.. rather use \"void | string\".. EmptyValue is a constructor function, not the empty value. Just leave out the initialization. I.e. \"let stmtCompletion;\" Also, move it inside the if since it is not referenced outside of it.. There is a bit of code duplication here. Rather fix up stmtCompletion first and then throw or return it.. turn this into an assignment, so that stmtCompletion is fully initialized.. Rather than change the signature of a function that comes from the specification, consider introducing a private helper function.. This took me by surprise and it took a while before I figured out what is going on here.. Could this get moved to before step 5?. Not specific to this pull request, but I'm a skeptic when it comes to this design (the buildNode function). It seems to me that we are paying a high price for flexibility that we probably don't need.. In the context I have for this review, I cannot figure out why all of these preconditions have to be met. A comment will be very helpful.. Perhaps add an invariant requiring argumentsList to be non empty?. Do you really mean to say that the require call has not been defined?. Perhaps we should build this into partially_evaluate?. At some point I'd like to figure out if we can get the type system to rule out Reference for us.. This looks like a pattern that needs a helper function.. invariant(!(result instanceof IntrospectionThrowCompletion));. I prefer to check for AbruptCompletion and then throwing it, because it seems a bit more readable to the casual reader.. It the cast to any actually needed?. This is not so simple. All, none, or just some of these assignments may create new properties. At best we are counting assignments, not properties. Perhaps that is what you want, but we probably need to rename and better document things in that case.. This smells a bit.. This seems a bit brittle.. Too clever by half.. Add a new line.. why \"if\"? My expectation is that Construct will always provide a value for it. Consequently, I would prefer to state this in an invariant.. We should try to make sure that everything we add to the code base has test coverage, so it would be better if startLine can be added in a separate pull request that includes a use case and test for it.. My understanding of the code is that there is no way for user code to cause $ErrorData to be missing from an Error object. If a change to the prepack code causes $ErrorData to be absent, it is very likely an unintended and undesirable change, so an invariant is a far better way to deal with the absence than relying on a unit test to fail.. Fair enough. It is usually possible to do an integration test that exercises new code, but in this case we'd need a unit testing story.. This last argument does not correspond to a parameter of _delay.. funciton. DateNow. We actually only need to do this check when the realm is in partial mode. (realm.isPartial).. Perhaps call this originalConstructor. Agreed.. This assumes that Object.prototype is never asked directly if it is simple. This is neither necessary nor enforced. I'll rewrite.. It doesn't matter, but I may as well make that explicit.. Will fix.. This is a problem. I've strengthened the condition, but to really solve this I'll need to have more information about what the expression associated with mem looked like. I've added a TODO for this.. I think you need a test case to cover this statement.. The standard way of doing this is to test with IsArrayIndex and convert with ToUint32.. The constructor fails unless one of the constituent completions is an Abrupt completion and that has not yet been established at this point, hence the subsequent code.. Oops yes, I do need to build a new generator since it gets modified and may get modified more than once, but it certainly makes zero sense to throw it away.. Please restore the indentation.. Instead of checking for the CIRCLECI variable, just exclude these tests on all platforms, but make it conditional on another variable so that nightly runs can include them.. This should move to just before the if above.. This is where the speculative initialization happens.. This is the interpretation of the first initialization phase.. This is speculative initialization of more modules.. This is the first (but optional) pass.. This is the second serialization pass.. How does prepack.js get into ./bin?. Just type value as an ObjectValue.. This invariant is redundant.. You should probably use DataBlock instead of Uint8Array.. I don't understand what this is doing.. Why require a second argument and then ignore it?. This seems like a good place to follow the arrow with an expression rather than a block with a return.. I'm a bit surprised by this. The utf8Slice I can find does not expect a this parameter.. This seems inconsistent with utf8Slice and I can't think of a good reason why it should be.. If you unpacked args with a pattern, you might get away with calling copy directly.. This would be more readable if moved to just after the definition of setupBufferJS.. Yes, that is actually preferable because it makes it easier for the reader to verify that the invariant is true.. Fair enough, but it makes me wonder why we have DataBlock type in the first place.. Perhaps add a TODO comment here to remind your future self.. This seems like a duplicate of the one in buffer.js.. Rather use a pattern with more descriptive names.. This comment can be a bit more descriptive. When your future self comes back it he might appreciate a hint as to what your present self had in mind.. Perhaps move this to Realm.js.. what?. ?. causes. ?. This seems rather specific. Wouldn't later versions work as well?. I think this is it.. Also include S15.10.2.12_A3_T1.js.. No, I meant an environment variable.. I don't think that requiring people to pass in {} explicitly amounts to real hardship. I like the idea of reminding them at every call to think about the options they want to use.. getRealmOptions should allow its caller to specify the values of residual and serialize. I think what you want is for defaultOptions to set serialize to true.. I was unable to convince myself that this invariant is true. I trust that it is, but just from a quick reading of the code it is not obvious to me.. It is a little bit too early to try and run test262 through the partial evaluator, but yes, that would make sense.. It works very similar to the non partial evaluator: The exception terminates this code, then gets caught and turned into a throw completion. The completion bubbles up to the containing AST, which re-throws it and so on. When a relevant catch clause is reached, the exception gets swallowed and execution proceeds. Note that this means that the state that reaches the catch clause is the state that applied when the exception was raised and that the containing catch will do the necessary joins etc.\nThe bulk of this still has to be written so I can't test this right now, but that is my thinking and it seems reasonable to me right now.. Agreed. I'll change the signatures.. Agreed.. We should remove this parameter both from here and from the evaluate functions.. I'm following the precedent established by Nikolai in the corresponding Evaluator class, but I also happen to agree with Nikolai that this is bit easier to read and maintain because it would be far too long otherwise.. If nast is just a residual expression resulting from constant folding then evaluating it alone will not preserve any I/O side effects, hence the additional statements are the \"residual I/O\" of the evaluation of node and need to happen before the evaluation of nast. \nAnother way to think of this is that ioAst and nast together form an expression of the form \"let ioAst in nast\". There is no way to express this as a single Babel AST node, hence the somewhat awkward expression of the idea.. While you are at it, it would be nice if you can sort the names.. Most other places in the code put the void option first.. You never have to apologize for an invariant, but I do find myself bemused by the claim that this invariant helps Flow.. This should probably be an invariant. I.e. something that can only happen because of a bug in the evaluator, as opposed to something that happens because of a bug in the code that is being evaluated.. This will be more obviously correct if you explicitly pass in realm.instrinsics.undefined as the last parameter.. Please sort them.. If error is not an abrupt completion, or it is an introspection error, you should rethrow it.. rather use realm.instrinsic.undefined.. Since this routine appears to return abrupt completions it does not make much sense to throw the TypeError below. I would have expected to see the completion being returned.. Please expand on this. What works unexpectedly? Why is it unexpected?. This blank line seems unnecessary.. Since the spec asks us to return a result here, it is surprising to find that we return undefined. Perhaps that is just fine, but it makes the code less obviously correct.. Why not assign to result?. The spec seems to suggest that you factor this out as a helper function.. why return undefined?. No, I love invariants. I'm just surprised, somewhat dubious and very curious that this one helps Flow.. This name seems a bit lame. a) Do you need a new class of Error, or would Error do just fine? b) Why not choose a name that indicates that prepack failed to complete because of evaluation errors?. You DO have to catch and cache regular AbruptCompletions, but this catch also swallows other kinds of errors that happen because of internal errors in the interpreter (i.e. !(error instanceof AbruptCompletion)) or because the source code contains a construct that Prepack cannot deal with when abstract values are involved (i.e. error instanceof IntrospectionThrowCompletion).. Why does this not extend Error?. Hmm. First you write the entire statement in one line, but in the form of a comment. Then you repeat it verbatim, but you break it up into multiple lines.\nI'm also not thrilled with the helper function. I'd rather see something like \"if (something is bad && reportError(\"Hey, this thing is bad because it's BAD\") === \"recover\") { do some recovery thing };\".. What makes this a \"native\" error?. It is somewhat unusual for a compiler to report \"No object code was generated because there were compilation errors\" and this seems sufficiently analogous that I wonder why this is necessary.. That would be nice. :-). We very likely will want to also handle errors that are not Introspection errors.. The comment seems a bit outdated and not all that helpful.. How about a comment that explains the meaning of the result?. We are already logging something. Logging it (possibly again) to the console seems uncalled for.. When the spec is obviously too complicated and there is a much simpler, obviously correct alternative, then use the second by all means. But in general, stick to the spec when it is at all reasonable to so so. Never deviate from the spec solely out of performance considerations.. I guess the spec language strongly suggests throwing this, but it is still a wee bit strange to me.. An invariant is better because it documents your assertion that v should always be an ObjectValue if the rest of the if is true.. If the comments are wrong, then please delete. :-). It should be. I'll look into this in a future pull request.. Parameter with default values should appear last in the list.. Don't leave commented out code in the source.. This does not follow our formatting conventions.. It would be better to have a way of checking the content of the error.. Rather make this be of type BabelNodeSourceLocation.. Please add \"npm run test-error-handler\" to the \"test\" entry below.. Also add a corresponding entry to circle.yml.. rather call this \"emitVoidExpression\".. Needed to deal with PossiblyNormalCompletion. . In the non partial evaluation case the introspection error now gets created later on.. The additional assignment confuses Flow too much, it seems.. bug fix. The second completion wins when composing.. Some callers can now deal with PossiblyNormalCompletions from calls, so move the error upstream.. Out of scope for this request.. Just some cleaning up in this file. No bug fixes or new functionality.. When functions are partially evaluated, it has to happen after an outer fixed point determines the global state that represents all possible states in which a function can get called.. Now that PossiblyNormalCompletions can propagate out of functions this invariant is no longer true.. This is where you should log the start of speculative initialization.. This is the start of non speculative initialization.. Move this up a line.. Rather call this the reference counts pass.. And call this just the serialize pass.. Do you mean the cast to any? I am unhappy about that, but 1) there is no convenient way to add a suitable invariant (because of the large union involved) and 2) a more principled solution with the aid of generics is far too intrusive for this pull request.. Defaulting this to 0 seems a bit odd to me.. It seemed to me that \"a bit\" would actually be \"a lot\". . type these. The tests never reach this line. Can you do better?. This type annotation does not seem right to me.. We would need a test case that depends on the type of the abstract value being a number rather than a Boolean. Right now that would be quite tricky to set up.. will do.. Actually, I forgot about typeof. Adding a test case.. hoisted. I kind of understood things up to this point. Right here, however, I have no idea why the declaration should now go to the prelude, not the body.. I found the logic below hard to follow. If I understand it correctly, you are basically finding the outermost scope in which this value is referenced, but not quite. The reason for the caveat being that the nesting relationship of scopes are not easy to figure out from the parameters to this function. So, if a value is referenced in a single function only, the value should go in there. If not, it either goes into this.mainBody, which seems to be the outer most scope, or it goes into this.body. The latter case arises when there is more than one generator, none of which is necessarily related to this.body, using only the invariants local to this function.. Could scopes be empty?. Why is this true?. Why is this true?. Figuring out that this a non behavior changing cosmetic change caused me to slow down.. This is a bit surprising since _getValIdForReference specifies BabelNodeIdentifier as its return type.. functionValue is a bit ambiguous. Perhaps use \"functionScopedValue\"?. It is not obvious to me why you are deleting this. Is functionInitializers used again?. Why prepend to the body?. Why not use unshift?. Why is this true?. This is a subtle and important design decision that is not obvious to me. Perhaps some comments somewhere will help future readers understand it.. I find this very surprising.. always. Good point. I'll make the isSimple check safer.. It turns out that it is perfectly safe already. Far too safe, in fact. But making a better alternative to isSimple is best left to a later pull request.. This should be realm.intrinsics.null.. The finally will take care of this, which means that you don't need the catch above and you can eliminate this if.. There should probably be an invariant here.. Yes, evaluateNodeForEffects now rolls back fatal effects in its finally clause. See line 308 in realm.js.. Will do.. There are no update operators other than ++ and --, but good point, the if statement in line 39 is redundant in that case. I was seduced by the old code.. I'm hoping to gradually phase out all methods that end in Partial.. Perhaps use a \"let\" rather than a \"var\"?. Perhaps call this capturedScopes(Map/Array)? Just reading this code I can't figure out what is stored here.. let?. I have no idea why this is needed.. I'm none too sure that a sufficiently general helper will improve code readability.. We should intercept the error handler here. That will help to reduce noise to the end user and allow us to ask for execution to continue (return \"Recover\"). But see below for caveats.. Recovering from errors will help with this, but the loss of precision implied by error recovery makes the side-effects unreliable. I.e. we can both have false positives and false negatives.. The evaluator will not reliably discover all require calls because of a loss of precision. We could alternatively use a specialized visitor that uses pattern matching to find the calls in a flow insensitive way. The downside of that is that we would miss require calls that happen via aliases. \nPerhaps the best way is to always do the simple visitor, and then the evaluator and to produce an error message whenever the evaluator finds a require call that was missed by the simple visitor. I.e. lets require and try to enforce the requirement that require calls are discoverable by the simple visitor.. The reason I changed this is that the template does not exclude the possibility of the result being an instance of NullValue or UndefinedValue. The added precision of the other cases is not actually needed anywhere.. It is not needed, but calling them out explicitly makes it more obvious that the code is checking each case in the type union.. While you are at it, could you also sort this?. I don't think we should have public APIs that promise more than they can deliver. I have no objection to removing the deprecated comment once the function is actually implemented.. I am following an existing pattern here and I even remember previous comments requiring it. But, yes, I agree. Putting this into the options object makes more sense and I'll do it.. A type signature will be nice here.. Will do.. It is, due to a bug/limitation in Flow. I'll change this to a $FlowFixMe comment.. The other help messages start with capitals and end with periods. Also, it seems undesirable to abbreviate words inside the help messages.. This is a new case to allow abstract objects that have not been obtained directly from the environmental model.. The check is not needed because o is known to be simple.. Currently it is impossible to write a loop where the source is not partial and that does not generate an error before getting to this point.. No simple object can have properties with Symbol names.. Let the caller deal with giving an error, since the caller has more context to explain why.. This can happen if the property was added during speculative evaluation.. Oops yes.. I've always wondered about this. It seems to me that this cannot be good for performance.. This name seems a bit too generic. A longer name and a comment would be helpful.. name needs explanation.. I none too sure that alternateProperties is a good name for this. Perhaps just call it namedProperties and use obj.properties as the default initializer. Perhaps also a comment say that a non default value is expected to be a subset of obj.properties.. The last argument should be omitted since it is the default value of an optional parameter and explicitly specifying it is surprising.. It is a little bit surprising to see canIgnoreProperty defined in ResidualHeapInspector. It does not seem to contain any logic that is particular to that class. Perhaps it needs to move to a class that is more specifically about properties.. The name _eagerOrDelay does not seem particularly helpful. Perhaps something like \"_callWhenArgumentsHaveBeenSerialized\".. _getDescriptorValues should probably be more consistent with _getNestedAbstractValues and take [obj] as a second parameter. concat is not great for performance here.. I find myself wondering if this over/under counts the objects that are serialized.. Perhaps increment this every time a property is serialized. This way does not seem accurate.. the comma is not needed. Since you initialize the field here, do you still need to do so in the constructor?. There is no need to catch and then throw.. This looks more like \"If we're not...\" rather than like \"Even if we're not..\".. ah yes, will do.. It got uncovered by throwing FatalError for all failures and therefore needs fixing here.. This is indeed a problem. I'll address it today in a followup pull request.. Since the if branch always returns you don't need an else branch here. I prefer to omit such else branches so that the lines don't get too long because of excessive indentation.. If sym is not a SymbolValue at this point, it can only be an AbstractValue. If so, an invariant is not appropriate.. Why not unbox if this a boxed Boolean? That way the logic below will work even for boxed abstract Boolean values.. Never increase this value without a detailed explanation of why there is no other viable choice.. This sounds like something that should become a comment in the actual code.. In the specification, only ECMAScript Function objects can have [[ConstructorKind]] properties. We should try to stick as closely as possible to the specification.. What's with the commented out code?. The main thing is to explain why. I do wonder, however, if the code will not end up being more readable if FunctionValue and all of its subclasses are kept in the same module.. The spec does not have something that corresponds to NativeFunctionValue. It does talk about builtin function objects (http://www.ecma-international.org/ecma-262/7.0/#sec-built-in-function-objects). By the sounds of it, I suspect that it may be OK to just make NativeFunctionValue a subclass of ECMAScriptFunctionValue. Alternatively, you can just add the necessary fields to its class definition as well. Factoring out the commonality between NativeFunctionValue and ECMAScriptFunctionValue into a separate base class is not necessarily helpful.. It seems like you could move this if inside the next one.. You can also add an invariant requiring sym.getType() !== SymbolValue.. Wouldn't you want to serialize the abstract value and wrap in a Number call?. Yes, but out of scope for this request.. additionalFunctions, like all other option properties, is optional. If present, however, its value must be an array. This is the only way I could find that would satisfy these two conditions at once.. Will put it in Realm.. I've changed the name to strongly suggest that only bindings get intersected.. This creates a rebase conflict, so please rebase by hand before you land.. There is no test case that reaches this line. Can you add one?. I don't think this is correct. Array literals can have holes. When there is no expression for an index, push null onto elems. Babel will generate a corresponding hole.. This is how holes are handled in the existing implementation.. I'd like us to get rid of logError and report all errors using Realm.handleError.. Sounds like we need an extra test case.. This was supposed to take care of deleted elements.. And this takes care of elements that are conditionally deleted.. I pondered this for far too long. It seems that somehow the actual body being processed is kept inside this._waitingForBodies, and that its representation is a list of [dependencies, emitterFunc] tuples. This is far from obvious and even now I'm not sure I understand what is going on here.. It sets the error location to realm.currentSourceLocation. In some cases it it will be valuable to allow callers to createErrorThrowCompletion to override that behavior. I'll add that ability when I next get to a relevant bit of code.. Instead of deleting this, please deprecate it.. It uses a naming convention rather than a runtime option. Not something I want to keep, but fixing the runner to deal with options has not yet made it to the top of my to do list.. This is not an error collecting pass, so it makes no sense to report errors here.. Does JSC in fact throw a runtime type error in this situation? If not, it may be preferable to emit a compile time diagnostic here.. This comment should be moved to before replaceName.. I don't want to count in all of the tests that are not selected by the filterString since that is exclusively used to reduce the number of tests to run while debugging.. It took me a while before I could satisfy myself that template.generator is only assigned to once. Perhaps a comment and an invariant would help with this.. At this point my head explodes. Is val.generator merely a flag? I don't see any other use for it.. I believe you, but verifying this by reading the code still eludes me.. Doing a structural equals between different AbstractValue instances can only be done safely by taking the operator that resulted in the abstract value into account along with the arguments. The operator is usually part of the buildNode, but it is easier and probably safer to get to it via the kind property.. Some abstract values never get serialized. For these there is no need for an actual hash value.. This is where the CSE happens.. These values are randomly selected large values.. CSE might increase our chances of running into this limitation in real life.. Calls to VisitValue where the value can only sensibly be an object are not candidates for CSE. It turns out that most VisitValue calls are in this category.. Kind is a generic name and the use case is not documented as such. Abstract values that result from expressions will never be builtin (or intrinsic) so there should be no clash.. We don't make use of the guarantee and it seems a bit restrictive to insist on it.. It is still all over the Flow documentation, without any hint of deprecation.. will do.. I'm dubious. Perhaps I can be persuaded, but either way, such a change belongs in a separate pull request.. Can we make this an enum?. I had that intention for a while and there is already a flag of sorts, but I try to keep away from the serializer. Maybe in a future pull request.. That's Javascript for you. I'll add a comment to the getHash definition of NumberValue.. will change it.. It convinces Flow that x can never be undefined.. I'm happy to replace this with an invariant if you believe it should never happen.. Done.. I don't think so. If the realm is strict then the directive goes to the start of the global code and there is no need to repeat it inside the wrapper.. Yes, but that would be deceiving. What is missing here is the O === realm.$GlobalObject check. I'll add that back.. No.. Good point. Fixed now.. Good catch. Thanks for checking. I'm now rewriting InternalUpdatedProperty entirely.. Actually, it should be \"mixed\" not \"any\". I'll remove this.. It allowed me to avoid writing the invariant in line 317 just once rather than in 6 different call sites. I'll restore it and write the 6 more invariants.. Writing an invariant that is obviously true, just because we don't trust the type checker deeply offends me.. In general, if you write an invariant, you should be convinced that it is always true and you should document the reasons why you are convinced. That really helps when you later debug the failure of this invariant.. Perhaps put that in a code comment. The gist being that rewritten bodies are assumed to be already optimized.. This comment perplexes me because of the \"if we're\" bit. Did you mean \"We have to do this on the first pass ...\"?. Supplying an array for BabelNodeStatement as the clarifying comment to an invariant seems pretty strange to me.. This is a bit strange for me. If you don't want g to change, why not assign something else (e.g. a new Generator) to this.generator?. I don't understand this.. This follows the pattern established by someone else (you?) in Realm.rebuildObjectProperty. The serializer expects things this way.\nThe basic question is pertinent, however. In setting up intrinsic objects this way, we implicitly require intrinsic objects to have pure properties. I suspect that we can't get by without this requirement, though.\n. This omission is deliberate. The file is test data, not something that will be executed.. Good catch.. Oops. My bad. . Clearly I need better refactoring tools. :-). No, not every string is an identifier.. We can do better here, but things get complicated and right now we don't have a motivating scenario.. That is the job of Delete.js.. I'm trying to figure out ways to make this less bad. The changes will be rather intrusive and should be done in a series of separate pull requests.. I tried to just keep this where it was in BinaryExpression, but that causes the Flow cycle length to increase. Arguably, this is the better place for it anyway.. Will do.. Ah yes, copy pasta. Will remove.. The ugliness of the pretty version of line 77 made me swallow ! for this instance.\nI'll add a comment. The reason for the size restriction is that the larger a value set becomes, the less useful it becomes while at the same time it becomes computationally expensive.. Good catch. This should throw a FatalError.. Good point. I've added some guards and a comment.. The check below is redundant. Thanks for noticing.. This is over conservative. I'll tweak it.. The result of a conditional operation is never intrinsic, so that is expected. The kind is in fact set to \"conditional\".. I don't think I understand your point. This works in Node:\n$ node\n\nlet fooSym = Symbol.for(\"foo\")\nundefined\nfooSym\nSymbol(foo)\nlet bar = {}\nundefined\nbar[fooSym] = function() { return this; }\n[Function]\nbar[fooSym]()\n{ [Symbol(foo)]: [Function] }\nbar[fooSym] = function(x) { return x + this.y; }\n[Function]\nbar.y = 2;\n2\nbar[fooSym](3)\n5\n. Good question. I'll add your test cases and see.. Hmm. I guess the short answer is: \"Only pure functions may be abstract.\" Hence any function that uses its this argument is disqualified. \n\nWe can possibly make an exception for calls where the this argument is an intrinsic, since such calls will get serialized in order, along with any modifications of their properties. Right now, this will take care of the second case. It turns out that the first case will not work because deleting properties of intrinsic objects is not tracked.  That seems like a separate issue to me.. Unfortunately, it is far from simple to establish immutability and it is definitely out of scope for this pull request.. I'm adding an error if an unfrozen concrete object is passed to an abstract function.. JSON.stringify. Actually, the values are pure. The point is that they must be computed at a particular point in time. I'm moving this to AbstractValue and I'm renaming it to makeTemporal.\nIn general, the notion that an abstract value need not be pure is deeply troubling. We should revisit the whole issue, but not in this pull request.. There isn't a factory function that is custom made for this situation and since this function is essentially a private helper function for use by AbstractValue, I did not think it worthwhile to create yet another factory function in AbstractValue.. Since any value can be converted to a Boolean and many path conditions will be \"thruthy\" rather than Boolean valued, yes.. Right now, this should never arise. I'll remove it.. Right. This should be an invariant and the type does not matter.. Please open an issue to remind us to fix the type definition of Effects.. It needs to get mutated here.. This is not supposed to have side-effects.. Only the factory functions set the kind now.. The regular joining logic is not wrong, but constructs inconvenient expressions. You are quite right to wonder why make a special case of only the return value. That should get fixed too, but probably not in this request.. I do.. I don't disagree, but that is somewhat orthogonal to the the simplification logic being recursive. I still want this code to be as it is.. Not quite. The code in LogicalExpression.js avoids evaluating the second expression. At this point both expressions have already been evaluated. (We are joining two value collections via the && and || operators.). This seems redundant.. To fit in with the other functions, rather name this \"evaluateForEffectsInGlobalEnv\".. This name is a bit misleading since it can prepend as well as append.. This looks familiar. Perhaps unify this with the filter statement in line 229.. At this point I'm lost.. Perhaps have two separate versions of naiveProcessInstances. There will be small amount of duplicated code, but the intent should be much more discoverable. The name also needs some work.. Seems to belong to the code in line 83.. I'll amplify the comment, but thinking about this some more, the join expressions for the side effects of the second argument are just fine as they are. So no TODO needed here. This change makes things the way I want to them to be.. This is from the previous pull request. Adding a TODO like that at this point does not strike me as at all as useful.. It is sort of really obvious, but why not? I'll add it.. The invariant in line 45 is there to convince Flow that a Value that is not a ConcreteValue is actually an AbstractValue. It is inconvenient to insist that the condition may not known to be true and there is not much to be gained from checking that it is not, since it naturally arises from refinement of existing path conditions. It should, however, always be the case that a path condition cannot be known to be definitely false, since that would contract the implicit assertion that path conditions are always true in the path they guard. That invariant I can add.. I'll add a comment. The reason is that if the first argument is concrete, the second argument will never be evaluated and hence it is a mistake to make such an abstract value.. I did initially fold both together and I found that the code became so unreadable that I was not confident it was correct.\nThere lack of symmetry, such as it is, is because pushPathCondition gets a ready made condition that can be pushed as is, whereas pushInversePathCondition has to invert the condition before pushing it. . similar answers.. will fix.. I'll remove the check for AbstractValue; that is no longer needed. The equality check is there to avoid duplication in the case where an expression failed to actually simplify.. We know this value in AbstractObjectValue, so both operands must be objects, otherwise invariants would fail in the constructor. The condition should be Abstract, because otherwise there would be no need for the join. The comment in line 134 already speaks to this.. It is, but it is also different in subtle ways that make it easier to read in its redundant form. I may come back to this, but at the moment I would prefer to keep things this way.. I don't want the abstract value factory functions to be path sensitive. There is probably room for an in depth design discussion about all this, but it is a bit premature right now.. This is more specific than it needs to be. I'll generalize it, but I can't really think of a valid use case for the more general form.. Indeed. I'll see to it.. As discussed earlier, we need a representation for intrinsic objects that can be null or undefined. The realization exploited by the request is that if we assume that any intrinsic object may be null or undefined, then the only thing in the code that needs to change is this bit.. Every operation on an abstract object value that retrieves elements from its values collection assert that all of the elements are objects, so this is a maintained invariant of the class. The constructor, however, does not check the invariant. There is no good reason why it shouldn't (and I expected that it does), so I'll add a check.. I'll add a comment. Note that only intrinsic object values are affected by this.. Good catch, will fix.. Another good catch. !== will not have any side effects, so the general check should be safe and allow more refinements to succeed.. Should this be an identifier?. Flow gets updated pretty often. It seems to me that this will either tie us to an old version or require us to update  this file every time flow pushes a new version. Also, what is the role of yarn.lock in all this?. OK, this is coming back to me now. I am not in favor of lagging behind the latest Flow in our editing environment. I rather like to be reminded to update package.json whenever a Flow type error shows up in the editor, but not in yarn flow.. This gets a bit tedious.. Good catch. Will change.. Fair enough. Will change.. The buffer may actually be non empty, so rather append err.message to the buffer and then post the buffer.. The message here should agree with the wiki page for the error.\n. It would be more relevant to point out the location of the throw statement.. PP0016 as currently documented is not appropriate for this situation because it assumes that only exceptions that are not caught by try-catch blocks will cause the error to happen.\nIf this is the only current use of PP0016, you can just update the Wiki.\n. Join calls AbstractValue. createFromConditionalOp which now can return a concrete value as a result of refinement and simplification.. Two abstract values with the same type and intrinsic name will be treated as identical during simplification. Having just one value reach the serializer breaks the test case.. Good point. There is no reason why pushInversePathCondition should not also handle != and ==.. It is so that we can use return inside this block, but then also post process the return value before actually returning it.. Good question. Right now, things happen here because I did not want to add simplifier.js to the long cycle. I'm not happy about this and have some ideas of how to refactor things a bit more nicely. I'll add some relevant todo comments in a future pull request.. createFromConditionalOp can now return concrete values and concrete values do not have the mightBeEmpty property. I introduced mightBeEmpty a long time ago to make it easier to model joins between branches where a property is missing and branches where it is present. We could possibly do the same for undefined and null, but since empty is not really a value, while the others are, the analogy is somewhat strained. I'm still in a muddle about the whole thing and I'm putting it off until later.. It should be refinedLeft.. We still don't want this to specify a particular version of Flow. I.e. leave this file unchanged so that we always use the latest deployed version of Flow.. CI won't fail because package.json fixes the flow version it should use. The setting in .flowconfig affects mainly the editing experience.. Yes, but mostly it makes debugging less painful.. Great catch. Will fix.. It does, but I like having the derived invariant here instead.. Agreed.. sure.. will add. will add.. Agreed. Will attempt it in a future diff.. There aren't any great ways of doing this that I can think of, but I'll get back to this when unifying all of the simplification code.. I would love to see true be the default value here.. You want to import this and you should also update package.json to make this module a runtime dependency.. Do not assume that prepack is being run from a particular directory. Rather parameterize this and supply it from your test runner.. This is pretty much always true, so no need to spell it out.. It is never OK to check in code inside comments. If this pull request is only intended for early feed back, make that clear in the title of the pull request.. This suggests that a debugger can be attached while debugging is disabled. Is this the case? If so, why?. This makes the prepack error go way.. This makes sure that the $MapData property is tracked in the current effects and thus enter the join logic.\nNote that the $MapData property does not show up anywhere but in Map specific code and in the generic join logic.. Things in the src directory should not have hard coded paths. Rather pass these values in as a parameter.. Note that every time this is called, the entire contents of the file is replaced. This implies that the debugger UI and the debugger code in Prepack have to maintain a strict and synchronous request response protocol. Please add some documentation here to inform the future reader of these assumptions.. Why split dbgFileContents? Also, under what circumstances would we supply the realm with a debug channel to which no debugger is attached? . Why not use an array here? Also, why not provide for column breakpoints?  Another thing to consider is that there may be multiple files. We also need to discuss what to do about source maps.. We are unable to guarantee this invariant in our code since we depend on what Bablylon comes up with. Also, the logic below ignores AST nodes that span multiple lines. This seems a bit brittle. A single assignment statement can easily span more than one source line and a block of more than one statement can easily fit into a single line.. Why the split? In general, should we be ignoring any characters?\nAnother issue: Once you've read a command from the file, shouldn't you make the file go away? If not, how do you know it has been updated?. I'm bemused by the lineNum part of this command. It would be helpful to have single file documenting the protocol.. It is still not clear to me why there would be more than one command in a particular interaction.. Because of the join condition.. The todo bit is the near future. For now, there just be a generic message about prepack failing.. The parameter is already a Boolean, this makes the reader perplexed and confused.. This is needed to avoid early termination in the case of node evaluating to joined abrupt completion.. To reproduce the serializer invariant failure, remove the if statement below.. empty line here. Always create an issue and reference the issue id in the TODO comment.. The convention in our code base is to always put void first. I.e. \"void | DebugChannel\".. It is good practice to name functions that return Boolean values with \"is\" in their names. In this case, \"debuggerIsAttached\" would be a better name.. Debugger is not very specific. Perhaps DebugServer?. Perhaps flag the breakpoint as \"singleUse\", not \"virtual\". The latter term is far too overloaded to be useful here.. What about file and column?. You may as well spell out previous in full.. Why is this needed? You may as well keep reading the channel until it returns a non empty string.. Instead of waiting for a run command, process commands until a run command is encountered. Then return to your caller.. This is not so much parsing the command as processing it. The result of calling parse is typically a parse tree. In this case you are both parsing a command and executing it. Also, why not just make the result of executing it tell you whether to wait for another command or to return to the caller.. I have commented on this before: You break on simple statements like assignment, break, return and so on. Simple statements can span more than one line. Complex statements, such as blocks and if statements, can all be on one line. I.e. this test is far too simple. It seems to me that you can simply omit this test.. This is debug spew and should be controlled by an option.. This name is far too general for such a specific action.. Why lineNum?. Not every BabelNode has non null loc property. Rather than terminate Prepack, just ignore such nodes (if logging is desired, log the node type).. check invariant(!isNaN(lineNum)).. Add some comments to each of the properties to document intent. For example, the index is not just a number, it is a line number. Which immediately raises the question: what about the file and the column?. It is not clear to me what you are doing here.. Do we still need this?. It will always be the case that a debugger might not be attached.. \"for now\" needs an explanation and an issue number.. Just spell out \"debug\".. This file name does not suggest that this is a communication \"pipe\" between the prepack debug engine and the adapter.. This will cause the shutdown call below to not happen.. I am mystified by this method.. Shouldn't all communication with Prepack go via the debug channel?. message !== undefined. I don't see a case where you return true.. Please change \"Function\" to \"Realm => void\".. This comment now seems misleading.. parts[4] is a string. It makes no sense to check if it is NaN.. parts[3] is a string. It makes no sense to check if it is NaN.. And then the debugger is always enabled by default? Why?. why the call to toString?. Perhaps rename this to something like \"PerFileBreakpointMap\".. I'll document or remove.. x || true can simplify to just true if we don't care about the actual value of x, only its truthiness.. The pull request is not entirely behavior preserving because a few simplifications done inside the factories are now replaced by full scale simplification. One of the effects of that is that templates now end up being asked for their truthiness and this breaks things. It is basically a bug that has been uncovered and it is convenient to fix it here.. isn't what?. Is it really necessary to resort to any here?. We generally avoid statics.. We also avoid using any whenever possible. In this case, the unique tag is not necessary as the object identity can be used instead.. It is not clear to me what you are doing here. According to the type signature funcBody is never null/undefined, hence !funcBody is equivalent to false.. typo. How does this scale? I'm always suspicious of linear lookups. Could instances grow with the size of the program we are prepacking?. Flow now catches this outrage. Yay. There is an issue for fixing it, but not a priority right now.. Will do when I have more time and look into exception handling for require calls.. I need to get back to this. It may have been a transient issue, or it may have to do with flow types for Babel.\nBTW. Flow is incredibly slow right now and has pathological behaviors requiring it to be shut down frequently. This makes figuring out Flow errors to be quite painful.. Refinement is path sensitive by definition. Condition indicates that only the truthiness matters, not the actual value.. Apparently not. Just deleting them (in the absence of the other changes) does not make for detectable difference, but reading over the code it no longer made sense to me. A bit of red herring here, so feel free to ignore.. Sure.. This comment now seems a little out of place.. I'm curious why this invariant moved out of the if below.. Is it OK to just carry one in this case?. Does this work if you want to specify arguments to prepack itself?. Should the adapter stay alive in this case?. \"frontend\"? I assume that is the UI.. No need for a type annotation here. Flow is very good about inferring the types of local variables.. Dumping the message, or a prefix of it would be helpful.. a comment to explain why the message could be length 0 would be helpful.. Looks like you're not quite done with this.. Is this a value prescribed by the protocol?. Clearly this is not prescribed by the protocol. It does seem a terse. Could there in the future be another adapter that involves Prepack?. It is not clear to me what a Session is and why it is distinct from the adapter. Mostly, I'm bemused by the logic that deals with parsing commands and buffering.. We do have normalization, so the latter check seems like dead code. Well spotted.\nI wonder, however, if it is wise to take dependency on the normalization order at this point.. I'm not clear on the intent of this check. Perhaps expand the comment with the rationale?. We do want to skip tests that check for early SyntaxErrors, because dealing with those is out of scope for Prepack. Ideally, there would be a tag in the tests that we can use to exclude them. Absent such a tag, the old framework resorts to running the test and then ignoring the result if it fails with a SyntaxError. It seems from the output of the test run that many tests are still visibly failing because of late SyntaxError detection, so something needs to get fixed here.. Debugging left over. Will remove.. Let's keep this.. name this test-test262-new. unchange -> unchanged. Perhaps these objects should be termed \"leaked objects\" since they leak into the outside world and then effectively become abstract.. contains:do. You may as well use TypesDomain.topVal in this case.. Issue number needed here.. Sneaking in null where it is not expected is brittle and really not OK. Either fix ResidualHeapInspector to expect null, or pass in an actual logger here.. Making a new inspector object just so that you can call _canIgnoreProperty with a cache that you are going to throw away seems painful. Better would be to make _canIgnoreProperty into a public function.. It this safe to do if the property is not configurable?. A comment explaining the purpose of the class would be nice here. I find \"Visitor\" to be a bit a bit general and somewhat misleading. It seems that the real purpose is to call emitAllProperties on all objects that are reachable from a root. The code would be much more readable if the class name directly suggested that this is what it is doing.. The comment says \"Value\", the code says \"ObjectValue\". Perhaps they should agreed.. The code implies that only ObjectValue instances will ever be added to this set. The code may well be wrong.. I know this fits in with the other visitors, but I really dislike the name \"_mark\". It seems to me that this method should really be named \"mustVisit\".. This is never called.. There seems to be very little point in call this._mark(val) here. . This appears to be a no-op.. Avoid any like the Plague.. _mark will never return true for an abstract value.. That was my first thought too, but Flow does not like it:\n18:   Singletons.Path = new PathImplementation();\n       ^^^^^^^^^^^^^^^ assignment of property Path. Mutation not allowed on\n 18:   Singletons.Path = new PathImplementation();\n       ^^^^^^^^^^ exports of \"./singletons.js\". I'll add the invariants in the in a later pull request.. It was intentional, but it has since been fixed. I'll revert.. It turns out that enforcing such an invariant is way more trouble than it is worth. The gain is at best extremely modest. The aggravation of maintaining the invariant is not.. Good question. I don't know.. The reason just came to me: The invariant would have failed, had not another invariant failed first. This changes makes both invariant checks pass.. This should be \"ast: void | BabelNode\". \"ast?:\" tells Flow not to complain if the ast argument is not supplied.. initialize. You can use \"this.realm.getRunningContext()\" instead.. It would be nice to append the function name here.. Rather use \"With\".. object currently being emitted. the -> that. rather import this in line 14.. Is this because it is impossible to specify an additional function name that identifies a class constructor, or is there another check somewhere that prevents this and generates an appropriate diagnostic?. I'm none too sure that this is a safe assumption.. Instead of making this a precondition, you could just return false. Then you would only need a single test for lines 135 and 136.. It seems that isValidSteppingLocation guarantees ast.loc and ast.loc.source are defined.. You can use a switch statement instead of this long list of ifs.. What's with the (options: any) bit?. I scratched my head about it for a while. A union does not seem quite right to me since it will not converge onto a fixpoint. It is a bit surprising to think of the empty set as Top, but since createdObjects is used only during joins and for a simplistic form of escape analysis, the empty set actually has the right semantics. I'll add a comment.. I am in two minds about this. Giving it a name help readability, but then you need to add an artificial reference to it in order to shut up the \"variable not used\" lint warning. The latter clutters up the code and decreases readability. In OCaml, people often just use \"\" in this situation (although \"_name\" is probably the better option). I actually don't think it is reasonable to look at the pattern and suspect that it is a typo. In general, the type checker will be quick to notice such typos, so human readers can afford to be a bit more relaxed.. I'm not sure that I can do better than \"KeyValueList\", which is about as readable as the actual type expression.. Fair enough. But I think of invariants as comments and the subsequent invariant states exactly this.. Flow is generally able to catch such errors.. Ooh, salivate.. This comment is pretty redundant, given the name of the constant.. You may want to move this line as well.. Instead of looking up filePath twice, just call get and check if the result is undefined.. Probably because it does not assume that the if condition guarantees that breakpoint is not undefined. If you just call get, this problem goes away.. Rather than create a runtime error, we would like to a see a compile time diagnostic. Look for places where CompilerDiagnostic instances are created for a model of how to report diagnostics. Better yet, blame one and look at the pull request that introduced it.. Remove this.. Remove this.. This can just be a set of strings.. in the else case, add nameString to _abstractValuesDefined.. This seems highly suspicious to me.. This is extremely unlikely to work.. Not quite the right place for that comment, but yeah, this code need comments. On the other hand it really needs to get deleted.... Rather call this pathConditions. Ditto for the field.. Try not to have changes that are not directly related to the pull request.. You can move this test into the subsequent if statement.. You can avoid spamming the diff with changes like these by making your editor run prettier for you.. I expected to see that pnc.savedPathConditions is always the conditions that go into the composition.. Have you checked your code coverage information? I.e. is there a test that reaches this line?. I expected pnc to have a merged path condition that is the inverse of c.joinCondition.. merged path should be c.joinCondition.. I expected to see a merged condition that is [!joinCondition]+result2.path.. I expected to see [joinCondition]+result1.path. Since the * operation is inside a residual function, it will not be prepacked and hence the code for dealing with with abstract conversion values will not kick in. Add \"let y = 123 * ob;\" to the global code and then just reference y in the residual function.. All functions that can be reached from the external environment are residual. The global object is treated as externally visible.\nIf inspect were called in the global code itself, the call would be inlined (and thus prepacked), but the function will remain (because it is visible).. It is possible to implement Sets to have O(1) lookup and any decent implementation will do so.. Is this recursion necessary?. Are you sure this is always true? Do you really need it to always be true?. It seems that this returns true if stoppables contains at least one element. It also seems that only the first element is actually used. This seems highly surprising to me.. I can't say that \"shouldDebuggeeStop\" is suggestive of a communication of the channel.. You could just return here. That terminates the search and avoids the add, without the need of an extra local variable.. Try __abstract instead of _abstract. I don't think so. The second completion starts from a fork point inside the normal path of the first completion and presumably has its merged path as its saved path. The result, however, is a single completion with a single normal path, starting at the fork point that led to pnc, so the saved path should be the one that applied to pnc, since that is the only path that all of the threads collected in the result will have in common.. In that case the name of the method is highly confusing and it makes little sense for it to return a value.. I missed the collapsed code in the diff view, so never mind.. The best way to make sure that a future programmer does not break something is to write very simple, easy to understand code and to add comments. Writing something that seems wrong, impedes understanding and does not help the future programmer.. These comments add no value. Try harder. :-). The second iteration of the test will use a different suffix and the \"does not contain\" directive will be inoperative. The \"copies of\" alternative invokes a path in the runner that does not add the suffix and does not iterate to a fixed point.. \"Children\" is confusing here. Rather just stick to \"objects\".. Presumably this is path, so in keeping with the next two fields rather name this \"heapGraphFilePath\".. Perhaps this should be named \"_path\"?. Perhaps this should be named \"predecessor\"?. I can't find a place where this is actually used.. Oh, I now see you talk about this in the summary. I guess this OK then.. Well then, I am persuaded that your test is fine as it is now. :-). Every time you create an abstract value it is simplified in the current path context. This can result in a concrete value.. typo. Casting to any is generally not OK and this case is no exception. First assign the result of createFromUnaryOp to a local and add it to path only if it is in fact an AbstractValue. It does not seem correct for the result to be something other than an AbstractValue, so you may want to add an invariant to that effect.. A set of. Oops.. The intrinsic name requirement is a precondition of emitDoWhileStatement. I would hoist it, but then Flow complains. Repeating it seemed a bit over the top to me. I'll add a comment.. I'll look at this again.. Since cond is the loop exit condition it needs to be temporal.. I'll move it into the while clause.. It is always a good idea to add a comment to document why you are convinced that the invariant will always be true.. pathCondtion -> pathConditions. Rather call this composedPath.. You can shorten this to:\nlet mergedPath = pnc.pathConditions.concat(c.pathConditions);. c.alternate may itself be a PossiblyNormalCompletion and, if so, you should append its pathConditions to get the path that applies to the normal branch.. You need to account for the possibility that c.consequent may be a PossiblyNormalCompletion.. If completion.alternate is a PossiblyNormalCondition, you need to push all of its pathConditions.. Need to handle the case where completion.consequent is a PossiblyNormalCondition.. When I don't force evaluation of the expression inside the loop body, it does not actually get emitted anywhere if I do the seemingly obvious thing of making the test condition an argument of the entry created by emitDoWhileStatement. Perhaps we can came back to this when you are in the office again?. Ah yes, you are quite right. I take that back.. If prepack is unable to interpret a loop because of an unknown loop bound, or because of some other problem in the loop body, it will issue a diagnostic and throw a FatalError. This helper function captures the diagnostic, squashes the exception and undoes any effects from the abortive loop interpretation, leaving the field open for the fixed point computation to have a go.. The effects that summarizes the state changes of an arbitrary iteration of the loop body. That is used to generate code for the loop body. The outsideEffects is used to summary the entire loop for the subsequent code.. I did not think it worthwhile because the functions strongly suggest what they expect their arguments to be and because Flow types make sure that right tuple column is used.. It means that we give up on trying to reach a fix point. That is a temporary restriction. I plan to deal with properties eventually, but that is a bit harder and will make the pull request too large for review.. pathConditions. I'm a bit worried about this too. Let me try and cook up a test case that will clarify things one way or another.. Got a test case that showed up some problems with sequencing. Things have now been refactored so that every rh side is first evaluated into temporary variables before the locals (in the guise of their phi nodes) are updated. Any references to phi nodes inside the loop body will always be to their values at loop iteration start. I.e. everything is done the SSA way until all expressions have been evaluated, then the phi nodes are updated in a batch of assignments that do no expression evaluation.. The point is exactly that the same phi node should be used across all fix point iterations.. rval is freshly constructed via AbstractValue.createFromWidening. The modification here can be regarded as completing the construction. This is very convenient, but yes, you are right that it is a bit of a code smell. I'll add another constructor method to AbstractValue.. I was wondering about this pattern of embedding user facing error messages inside exceptions, so I had a closer look and I noticed that you promote these to PP0019 at some point. That undocumented error code has now been grabbed by someone else, so please change it and document it. While you are at it, also consider making a separate error code (with specialized documentation) for each instance of ExpectedBailOut.\nAlso, if you wan't to fit in with best practice (and why not) then report the diagnostic at the point where you do the check and then bail out using FatalError (unless the error is recoverable, in which case the error handler can tell you to repair and carry on).. It will help to reader if you explain in a code comment why you believe the invariant to be true.. Looking at your documentation for the error code it seems to me that is essentially just saying \"hey something is wrong with code, go figure it out yourself\". If you want the documentation to be a bit more helpful, the error has to be more specific to a particular situation and there has to be a useful hint about how the error may be avoided.. Feel free to change it in one of your upcoming pull requests.. This reformatting seems unnecessary.. Why is this a comment?. comment?. Please use a name that is not so cryptically abbreviated.. This needs some explanation. Destruction and freezing do not necessarily go together.. If realm.getRunningContext().lexicalEnvironment !== loopEnv, you may need to do more cleanup.. Could this be different from environment? If so, are you doing enough cleanup?. Will this always restore context.lexicalEnvironment to this? If so, it would be nice to say so in an invariant.. It is not clear to me why you are deleting here rather than adding.. Seems like you may want to delete the previous line and uncomment this one.. (but we can update existing values if variables are captured by closures). invariant(currentEnv !== undefined);. Might this be different from loopEnv? If so, how did that come about and could those circumstances lead to environments that become inaccessible because of the next line, but that are not destroyed? If not, it would be good to assert that here using an invariant.. In line 65 of prepack-node-environment.js we have a similar code pattern. Should that also be fixed up?. The expected result for this test is exit code 1, as it says in the comment.. It would be better if any diagnostics that were collected were printed out before printing the stack trace and terminating the process. One way to do this it make the catch wrap the finally.. In line 263 below throw a FatalError so that the catch clause (which should now be wrapping the finally), can terminate the process with exit code 1.. This fixes an unrelated bug that gets uncovered by the new test cases.. I'm not inclined to agree with this sentiment. Centralizing all Babel AST generation in the generator does not make the code more readable or maintainable. Moreover, the architecture specifically provides build functions so that this logic can be distributed to places where they can be read in context.. Fixing a typo that only manifested as a bug in the new test cases.. Until widening came in to the picture, no test case caused an abstract value with type === PrimitiveValue.. If we ever introduce an IntegralValue as a subtype of NumberValue, this kind of thing will be necessary, so may as well do it now while touching this code.. Why only a hint?. Is there a test case for this?. Are there checks to ensure that the classPrototype uniquely corresponds to a single class expression AST node?. Why run the test at all?. Please add a comment here to explain the significance of making the buildNode undefined.. Maybe call this \"additonalRoots\"?. This subtly assumes that additional functions can never be nested inside additional functions.. Sadly no. The expected type is a Flow union of so many cases that asserting it dynamically will be unwieldy and fragile. . retrive -> retrieve.\nBut on the whole I would prefer not to see the message. The absence of a call stack is eloquent enough.. unescapleUniqueSuffix -> unescapeUniqueSuffix. test-react writes to console.error, which cases yarn test to exit early. Unrelated to the rest of this pull request, but something that needs a work around until test-react gets fixed.. I specifically wrote it the other way because I thought the other way is more readable. :-). This is a one time initialization of a \"phi node\" and will not be repeated if widenPropertyBindings is called again (as it usually is). Discovering the need for a phi node requires the fixed point computation, thus it cannot be reasonably separated from this code.. Everything is possible, but not everything is an improvement. In this case, F is the name used in the specification and as a rule we stick to the names used in the spec. The f vs F horribleness is due to the interaction between a weakness in Flow and and over eager Lint rule. To put it another way, I do not want to differentiate F and f. They are the same thing and would be the same variable if Flow were smarter.. This error message is going to be very short lived.. I'll add a comment. This is the place where we keep track of the arguments of the most recent active call to the function from a particular location. It serves as an optimization since without it we'd have to traverse the stack upon every call in order to detect recursive calls.. This is the place where an abstract recursive call is replaced with a Top value.. Just calling F here is not safe since it may be referring to outer scope variables and properties that will not be in the right state at the temporal point where this call happens.. Yes, either that or we need some kind of check to make sure that F does not access any state other than its parameters.. Good question. Only one recursive function at a time will be the root of a fix point computation and thus have call sites that gets this special kind of result, so we'd expect all such values to come from the same function. It is probably worthwhile to add an invariant to that effect.. Please add a test where this diagnostic is actually produced.. I am befuddled by this. It seems very different from other places where createFromTemplate is used.. Hmm. AbstractValue.createFromBuildFunction (which does not currently exist) would be less surprising. Just returning the object, as is, seems like the obviously correct thing to do here, however.\nWhat seems to be happening here is that arg is further abstracted by setting its ValuesDomain to top. The rest is just smoke and mirrors. It is probably interesting to find out why this is necessary. At the very least it should be much more obvious that is happening (preferably with a source code comment explaining why it is needed).. Ah yes, you are quite right, this is all about setting the TypeDomain to ObjectValue. Well then, what is needed here is an obvious way to do just that.. There shouldn't be a need for a sequence expression here. Also, it seems more useful to let the caller supply the build function.. The comment above and the help text for the diagnostic does not make it clear whether this is due to a user error (or the incompleteness of Prepack) or because there is a bug in Prepack. Since the latter case should always be checked via an invariant, I assume it is the former. Please make this a bit more obvious by clarifying the comment and adding some more context to the help text.. I have the following in a local commit that I'm not ready to put up in a pull request:\n```\nstatic createFromBuildFunction(\n   realm: Realm,\n   resultType: typeof Value,\n   args: Array,\n   buildFunction: AbstractValueBuildNodeFunction,\n   optionalArgs?: {|\n     kind?: string,\n     returnValueOf?: ECMAScriptSourceFunctionValue,\n   |}\n ): AbstractValue | UndefinedValue {\n   let types = new TypesDomain(resultType);\n   let values = ValuesDomain.topVal;\n   let Constructor = Value.isTypeCompatibleWith(resultType, ObjectValue) ? AbstractObjectValue : AbstractValue;\n   let result = new Constructor(realm, types, values, 0, args, buildFunction);\n   if (optionalArgs !== undefined) {\n     if (optionalArgs.kind !== undefined) result.kind = optionalArgs.kind;\n     if (optionalArgs.returnValueOf !== undefined) result.returnValueOf = optionalArgs.returnValueOf;\n   }\n   return result;\n }\n```. Nothing good. It would be better to incorporate the kind and any arguments into the hash.. Ah yes. Thanks for having my back here. I'll fix it and add some more test cases.. Doing this here and then calling AbstractRelationalComparison below can cause side effects to happen more than once if lval has a side-effecting implicit conversion. This is probably why there are test262 failures.. handlie -> handle. Please update the Wiki with the new error text. Also note that the error text should be a heading inside the actual wiki page for the error.. This change departs from existing usage where \"can\" does not imply might. It is also not quite general, since type might be PrimitiveType, which should also return true. Since the function is only used inside the constructor for Reference and you are generalizing that, it should be sufficient to rename the function to \"mightBecomeAnObject\". (And, of course, the PrimitiveValue case should also be handled.). Given the semantics specified in the specification, this change seems undesirable.. Rather than change the meaning of HasPrimitiveBase and relaxing this invariant, let's keep things as they are in the specification and introduce a separate branch where we handle pure functions.. I still think that this should be createFromBuildFunction and that the serializer should just work without needing another special case. I'm willing to let this go for now and fix it up in a subsequent pull request.. Shouldn't this check that we are in a pure function?. Yes, the second call happens in a forked path. Merging the forked path that results from the call with the forked path doing the call, while keeping the interpreter in a sane state does not work yet.. The second obj.$IsClassPrototype is redundant.. Good question. Historical reasons, it seems. This is a good place to do some cleanup.. Value.isTypeCompatibleWith will work out that an IntegralValue instance is also a NumberValue instance, so there is no need to check for the former. Alternatively, one could use === instead of calling Value.isTypeCompatibleWith. . In the case of - and + you need to know that the operand type is integral before the result type can be declared to be integral. This will require you to change the signature (and the comment) of the method. Unless the constructor for NumberValue is modified to return an instance of IntegralValue when ever a number that happens to be an integer is passed to it, we cannot guarantee that any integral number value will necessarily be an instance of IntegralValue.. The semicolon at the end of this line should not be there.. Instead of doing a bunch of tests to determine which constructor to use, why not create a single factory function that simply checks if its number argument is actually an integer?. For concrete values it is a very reasonable thing to do. The main thing is to make the code easier to read and to make it more difficult to forget to maintain the invariant that an integer value is always wrapped in a IntegralValue.. We are not hugely concerned about the runtime performance of this operation, so it would be reasonable to factor out this logic into a function, such as \"HasSameType\".. You could replace this with \"if (!HasSameType(x, y)) {\". The type annotation of createAbstractObject should already guarantee this.. We have a rule that all abstract values MUST be created in AbstractValue.. Then create an issue for the Flow team and use FlowFixMe to suppress the error and to reference the issue. That said, I'm incredulous.. I think they may be fixed already. We need to update our reference to the tests. This is a bit involved because Facebook internal repositories need to get updated as well. Let me see if I can get someone to take an interest.. This part is a fix we should keep.. Rather keep it as -1.. This works correctly, but the reader gets a surprise and has to consult the bizarre definition of Add (which should probably be renamed to Additive, to be closer to the specification). The flag is important when the second operand is an unknown expression. In this case, however, it is perfectly OK to retain the -1.. It seems possible to reach this line. Returning undefined is OK with the signature, but returning undefined implicitly seems a bit like a code smell. I am also bemused at the significance of returning an empty array, as opposed to undefined, when value is undefined rather than, say, a StringValue.. Rather use \"!t.isValidIdentifier(P)\" instead of \"!isNaN(P)\". New error codes should be documented int the wiki. Also the range is significant. Any errors that arise because of limitations of the abstract interpreter should be in the range 0 - 999. \nSince every wiki page should be specific to the root cause, it does not do to use a single error code for every error that is reported via logError. The quick fix is to pass in the error code as a parameter.\nA better fix might be to just get rid of logError.. There is also a wiki page that lists all known errors: https://github.com/facebook/prepack/wiki/Prepack-diagnostics. This is confusing. Perhaps a comment to explain?. What is the purpose of len?. The in prefix suggests a Boolean value. Perhaps \"currentAdditionalFunction\"?. null does make historical sense, but our current usage in Prepack is to always use type void, regardless of whether the non void value is an object.. Perhaps this case can be added as a test case?. a, b => a and b. This should probably be in a finally block.. Mind blown.. Actually, we DO serialize template objects, hence to assignments to obj.intrinsicName*. The reason being that we get properties from the template objects and these properties become temporal (derived) values because the root object is intrinsic. It is the right behavior, but it does mean that this is not proxy for \"template did not leak\".. It is not obvious to me why this is not jut \"ast_body.push(body)\".. You are adding ConcreteModelConverter.js to the big cycle. You can avoid that by exposing it via Singletons.js.. In general, there should be a 1-1 correspondence between error code and message. Also, this function is so small that it may as well be inlined. You should also pay attention to the return result of handleError.. You probably want to add a special case for abstractConcreteUnion. Any one of the concrete cases will do, but you won't necessarily get them from the values domain, hence the need for a special case.. This is not correct if the template has a different prototype.. Initialize this to the empty list.. parameters, which. In general, if a specific location is not available, we default to realm.currentLocation. This will usually identify an expression that is part of the overall construct. In this particular case, the realm's current location has very little to do with what is going on here. The best we can do is to point the programmer to the function itself. fun1.expressionLocation should contain the relevant location.. This should probably be in a finally block.. Emitting a concrete. This only happens if the program is known to always terminate with an exception. The error text suggests that this might not actually happen. Which is it?. Looks like generally useful code that should be used more often.. This can be obtained by blaming the line and referring back to this pull request.. This assignment creates the property for all abstract values, which is not something we want.. \"or React known abstract value\" -> \"or a known React abstract value\". I am decidedly less than thrilled with this kind of addition, but a better alternative does not readily present itself.. The performance argument cuts both ways. Generally, I'm loathe to add memory pressure. Having two classes, may be less bad than filling up memory with emptiness. Do you have measurements that suggest this is a clear win?. The code has an invariant that asserts that the type is never top.. This is not really something that belongs in the TypesDomain since it is more of a utility kind of thing and it is not used by any of the constructors or transfer functions of the TypesDomain. The inverse of this function is defined in Value, which is not exactly a great place either. It seems like good idea to keep this in the same place as the inverse, wherever that may be.. This doesn't have to be a set.. I'm familiar with hidden classes, monomorphism and optimizing JavaScript. Ultimately, intuition is not enough and one has to measure things.. It seems that caller's will have a hard time ensuring that this invariant is never violated, unless they always pass in op. So, shouldn't op be non optional?. We really want a 1-1 correspondence between error codes and error messages. Ideally, we also want information about where the current value of $Extensible came from to feature in the error message.. The difficultly in properly contextualizing the error at this point is indicative that it may be better to generate it further up in the call chain.. This is a little surprising. The type system should guarantee this.. Yes. The operator use would be \"<\". The call sites should also assert that their return values are BooleanValue instances.. Add a test with an abstract base.. Add a test with <. simple and partial should be orthogonal, so don't make the simplicity of to subject to it being partial.. And the sources are simple.. because we can't iterate over all of their properties.. Partial objects (and to is now partial) can't be calculated to be simple. We already established above that to is simple, so. set the _isSimple flag. Shouldn't this return \"Promise\" rather than this.$Promise?. Seems like a comment will be helpful, just not that comment. ;-)\nMaybe something like \"Make this temporally not partial so that we can call frm.$OwnPropertyKeys below.\". I am still not sure that the target needs to leak. Please explain why in a comment.. \"Leaking\" the value seems a bit bizarre. The real issue here is that nextSource is referenced in temporal expression and there needs to be complete and unchanging at that point in time. I guess the overall mechanism is the right one, but the name is misleading.. PP001 is not an appropriate error code. Make a new one and document it.. It is not obvious to me what scopes.values().next().value is at this point, so a comment seems called for.. Not random but perhaps arbitrary.. What is the reasoning behind moving from \"parentBody: void | SerializedBody\" to \"parentBody?: SerializedBody\"?. This is more than just a generic AbstractValue. It is effectively a call to global.__abstract expressed at the meta level. That probably needs a bit more explanation in the comment.\nIn fact, that is probably wrong, since a given name can only be used once per realm and this is too much to ask for when the name is a parameter name. Either qualify the name, or create a value like I do in checkResidualFunctions in prepack-standalone.js.. Apropos my comments above, add and another function with parameter name \"argument\". . If to is an AbstractObjectValue it should also be made final.. This is no longer a good way to report an error. We'd like a specific error message (and code) and also a source location that is as accurate as we can make it. A better way to do this might be to just throw the FatalError with a specific error message and then to catch that in a context where we have the source location available.. I find this a bit surprising. The invariant below (which ought to have been commented) basically states that since O.$GetOwnProperty (above in line 479) returned a descriptor, there must have been a property binding holding the descriptor and hence map.get(key) should always return that descriptor.. This is a deprecated way of generating diagnostic messages. The modern way is to always do so in a context where we know the source location and to always have a dedicated message and code for every distinct kind of problem.. It seems that $GetOwnProperty nowadays will return a descriptor when there is no binding. That is not necessarily a good thing. I'll look into it some more.. Look for places where CompilerDiagnostic is created in CallExpression.js.. Looking at the overall logic: We only get here for simple partial objects. For such objects, we are happy for you to read and write properties even though we are not sure they exist. It seems inconsistent to fault when you try and delete such a property. So, rather than give an error message here, why not use emitPropertyDelete?. \"Marked as final\" is an implementation detail that is not part of the mental model of someone using Prepack. Consider a message like \"Mutating an object with unknown properties, after some of those properties have already been used, is not supported.\" In the wiki page you can can discuss Object.assign and perhaps give a code snippet illustrating how things can go wrong.. Sure, but in another pull request.. Only AbstractValue should use derive. Any other code should use factories in AbstractValue to create abstract values.. You want to pass FunctionValue here, not types.. This wants a type value, not a type domain.. Why is bindingType as string and not a BabelVariableKind?. Please add punctuation so that it is clear that the next sentence is not part of this one.. This should be in a finally clause.. While you are at it, you may as well fix the cast to any. The type annotation of Effects is enough to guarantee that propertyBinding is of type PropertyBinding. You can get rid of the casts to any.. The type annotation in the pattern is not needed.. Is this because of a precondition? If so, update the function comment to make it clear that effects[0] must be a Value.. The type annotation should not be necessary.. The cast to any is not needed.. Sadly, there is no sane way to assert this. The expected type is a gigantic union and there is no way to assert membership of a union, so you have to assert a big disjunction, which is very tedious to read and write.. Dumping the code is used primarily for debugging purposes. Also, this in not breaking new ground, but follows the precedent set by test-internal.js.. Rather treat this as user error than as an internal Prepack failure:\nAbstractValue.reportIntrospectionError(input);\nthrow new FatalError();. Add this as the first line of the test:\n// throws introspection error. If input is a concrete value we still want to use the interpreter, so rather change this condition to: input instanceof AbstractValue.. Why delete the comment?. Comment?. Yes, better leave that as a failure case for now. Going forward, we'd have to have a way to bail out of the interpreter. See DoWhileStatement.js for an example of how this will work.. Chris, have a look at this in particular. I seem to remember that you recently changed it from generators[0] to scopes.values().next().value. Has the need of that change now gone away?. Not even in pure mode. The correct thing to do here is to report an error if result is an abstract value with the Top type.  Right now that is probably good enough. Eventually, BinaryExpression.computeBinary could catch the error and (in pure mode) return an abstract binary operation instead.\nTo put things another way: Returning an abstract value here that results in an expression that first calls method, then checks if the result is a primitive and alternatively either throws a runtime error or calls the other method, is pretty awkward to express and seems a silly way of doing what will happen naturally if we just emit the source level operator that caused this call to ToPrimitive.. WHOA. From now on every binary op is temporal BY DEFAULT???? Not good. And very likely not intended.\nThe way to go here is for the caller to wrap the atemporal value in a temporal value whose build function just returns the atemporal value.\n. Why do you want a temporal value here? By definition, nothing this operation does may affect the state of Prepack so it really should not matter when this happens.. No! It might be an object at runtime.. If base is an AbstractValue with type Value (Top), we do not know that it will not be an object at runtime.. I missed this during the last review. If you really believe ref should always be a reference, say so in the type of the parameter. That is much fairer on the callers of this function.\nThat said, WHY do you believe this is always a reference?. Leak.leakValue doesn't do much in line of optimizing the (probably common) case where value is known not be an object. You could check this with \"value.mightBeObject() && !value.isSimpleObject()\" or you could add such a check to Leak.leakValue.. Why the invariant? It should be guaranteed by the return type of GetValue.. It is not obvious to me that this needs to be a temporal value. Can you add a comment to explain why it must be?. Why are you sure that this a string? The type system says it could also be SymbolValue.. We can't evaluate this expression at compile time, so we either have to produce a compile time error rejecting this code, or the operation needs to result in an abstract value that will do the right thing (including throwing a type error) at runtime.. Oh, and to be clear: You should never write an invariant unless you firmly believe that it can never be false. You should always document the reasons for your belief. Should the invariant fail, that should be because there is a bug, not because of some bad input.. The delete operator is misclassified as a unary operator. It should really be an update operator. The way it is currently implement for abstract values appear to be broken. Your use of a temporal value masks this problem in your test cases, but does not solve the underlying bug. The best way to proceed would be to do the right thing here, but file an issue to fix delete.. nodes[1] won't be defined unless you pass propertyName as an argument in line 125. See generateRuntime call in CallExpression.js.\nWhich raises the question: why isn't there a test that fall over?. PP0012 seems more to the point here.. typeof seems very specific for a function called generically \"generateRuntimeCall\".. Why do you believe this must be a Reference?. Why do you believe this must be an AbstractValue?. Why do you believe that GetValue will always produce an abstract value. I can easily construct a call to generateRuntimeCall where that will not be the case, so you are asserting a precondition for the expr parameter. You need to make that explicit in a comment and you need to demonstrate that every call site satisfies the precondition.. You seem to believe that func will throw a FatalError if and only if expr is either an abstract value or a reference to an abstract value. That is an intricate and subtle precondition to push to callers of tryToEvaluateOperationOrLeaveAsAbstract. Do you really need to do that?. At this point you can just assert that value is defined.. val.getKind() === \"ReactElement\". don't want to ... what?. they we be ?. arg should be mathRandomSeed.. On my laptop this invokes /usr/local/bin/prepack which is defined as\n!/usr/bin/env node\nrequire(\"../lib/prepack-cli\");\nThat version of prepack behaves differently from the version in \"./lib/prepac-cli.js\". throwIfNotConcreteObject will allow you to dispense with the invariant below.. My first thought about this was that it is still broken because it does not deal with other forms of recursion. Then I remembered that the abstract interpreter cannot deal with it either (and will give a diagnostic), so no problem with that.. Havoc is already a verb and Havoc.value can be read as \"havoc this value\". I don't think it can get any clearer than that.. The comment for computeBinary points out: \"Note that calling this can result in user code running, which can side-effect the heap.\".\nThis is highly problematic in this context because we may get here AFTER the case that is actually executed at runtime has been processed. In fact, only the FIRST case condition can be evaluated unconditionally.\nConsequently, the only safe way to evaluate a list case clauses is in the form of if else if else if ..... This is best expressed in the form of recursive function, not an iteration, since you need a stack of conditions.. You can call mightNotBeTrue on concrete values, which allows you omit this case.. Move this to line 166 below.. Statements never result in References, so you can assert that r is not a Reference.. We don't just make up new exceptions and throw them willy nilly. When we encounter a case where Prepack is currently unable to deal with something, we report a diagnostic message via realm.handleError and either throw a FatalError to terminate execution, or repair the error and carry on, depending on the return result of handleError.. If r is now an AbruptCompletion you should break out of the loop.. If r is an AbruptCompletion, throw r.. result can only be a Value at this point.. Can't happen.. Just use UpdateEmpty instead of GetValue.. It is easy to misread this pattern, which is what happened to me. The other reason you don't want to do this is that you end up with very different looking code when you decide to actually recover from an error.. Missed that. Putting the check in the loop header makes that logic non local and hard to spot when reading the code incrementally.. The last TODO is kind of pointless with the current implementation of havoc, which I did not fully understand when I wrote the TODO. The second to last TODO no longer seems very valuable to me since it only retains knowledge about which properties are not in the havoced object. It does not seem likely that such knowledge will help anything very much, so doing work to make it happen does not seem a good investment.. PossiblyNormalCompletion is an implementation detail that should not appear in a error message that is read by a developer using Prepack.. You want to create a CompilerDiagnostic, for which you'll need a new error code, which implies that you'll update the Wiki with a nice explanation of how such a situation arises and how to avoid it.. Or return, or continue.. Should this be commented out?. !(result instanceof Completion) is always true here.. You may want to move this earlier so that you don't have to duplicate it so much.. The type system says that parent is guaranteed to be an ObjectValue at this point, so why assert that it is non null and not undefined? Also, ObjectValue.$Get is method, so why do you assert that is it not null|undefined?. In effect, this is saying that realm.isInPureScope() implies that To.PropertyKey and To.ObjectPartial will not have observable side effects. This probably bears saying over and over again, lest people pick up on the try-catch pattern without realizing that there a huge and dangerous assumption needed before anything can be done in here.. I suspect that t.callExpression(methodNode, [objectNode, nameNode]) will work if you pass in ObjectPrototypeHasOwnPrototype.$Call in line 45. That would be better code to generate.. Boolean parameters are generally a bad idea. Having one called forceJoin in a method called joinEffects is confusing at best.\nThe current behavior is not exactly obvious either: The reason that the join excludes the effects of the normal completion is that they are not complete at this stage and must be joined in later. This ought to be well documented.\nWhen you are forcing a join, however, I get concerned since you really should do it only when it is guaranteed that there will be no more normal effects, and in cases like that it is best to not have a PossiblyNormalCompletion in the result.. That would be AbruptCompletions and those are interesting/problematic since they can only occur if every call to the function will terminate with an exception.. I don't understand why you are doing the join at this point. It does not seem like a natural join point to me. In particular, exceptions do not get swallowed at this point, so they should not be joining their effects with the normal effects here. Let's discuss this face to face.. You are adding a restriction here. It is not obvious to me that it is needed.. The arg does not leak, so why havoc it?. Since props is a concrete object this should not be necessary.. the beelow introspection error -> the introspection error below. we are in a pure. I don't think we need to be concerned that an object is partial or not. Only that it is simple, because we are emitting runtime code and we need to be sure that fetching the property will not cause havoc.. There is no need to havoc P since it does not leak.. PP001 is used for errors that still need to be converted to proper diagnostics. You should never use it in new code.. Additional function related messages should be in the PP1000 range.. and if -> and since. we but... what?. that the property -> that ToPropertyKey. if its' -> even if it's. the below introspection error -> the introspection error below, since converting P to a string is assumed to be well behaved in a pure scope. While you are at, please sort these. I find the term \"safe\" here a bit misleading. It seems that in \"pure\" mode, we simply assume that unknown functions such as abstract functions with explicit calls, or in this case, implicit calls to unknown valueOf and toString functions, will refrain from side effecting the global state in general, but are permitted to leak and/or side-effect their arguments and hence we havoc those. It probably bears repeating this definition of \"pure\" mode all over the code base so that it is hard to miss.. You may as well pass it in as an optional parameter like we do for the two operands.. Flow should know that __args is an Array and that ought to be enough to type check the callExpression without needing the cast to any.. If the first (to) argument is simple, the result will be simple as well. This might be useful to capture.. Ah yes, co-variance lying in wait. It would be nice to get more accurate Flow types for Babel, but that is beyond the scope of this PR. For now, at least cast to Array instead of Array.. The reader of this message is thinking about JavaScript source language constructs and may not find a reference to \"PutValue\" to be very informative.. PP0012 seems to cover this case adequately.. Insert something like:\nif (!realm.useAbstractInterpretation) return ObjectAssignInner(context, args);. Is this true? The left hand side of in is converted to a string, so that might side-effect. For instanceof we might end up calling a @@hasInstance method.. This may be wrong since result need not be primitive, in which case the second method may have to be called if name is the name of the first method. Since it is hard to tell at this point, and not possible to emit an AbstractValue that will call both values (if need be), the best thing to do here is to give a FatalError and let the caller figure out how to delay things until runtime.. Rather than resorting to logging here, why not report a diagnostic with a warning severity?. The error message is not going to be very informative if this a FatalError since the really interesting stuff will already have been reported as diagnostics.. Rather than throwing an ExpectedBailOut, why not just report a diagnostic and throw a FatalError?. that apart -> apart. The reporter of an error can mark its severity as \"RecoverableError\", which means that it is offering to make an assumption and fix things up so that analysis can continue. If the client is interested in continuing the analysis, it returns \"Recover\" from errorHandler and undertakes to collect, organize and display multiple errors without duplication.\nIn some situations, typically when there is speculative evaluation, all kinds of errors are downgraded to warnings and the result of errorHandler is ignored.. This error does not seem much more informative than PP0002. Perhaps the latter will do nicely in this situation?. Did you mean to leave this in?. Seems like a feature we don't want to get rid off. Perhaps this can become \"// skip this test for now\". . There are scenarios where we want a snapshot without forgetting about the properties. This should be handled by the caller, for the sake of efficiency, but also for flexibility. I don't understand your point about calls to pure functions. Currently, any parameter passed to an abstract function is havoced and that seems appropriate. It seems to me that a havoced object should not need its properties. Let's get back to this in a later PR.\nI think symbols will work just fine the way things are right now, but I'll add some test cases just to make sure.. Good point. It would only be safe if to were also an intrinsic object and then only because of our overall assumption that intrinsic objects are never aliased. I'll tighten this up.. I don't think so, what we are really getting here is a name represents the state of the object at this temporal point. Right now it does not deal with prototypes (and I don't think it is needed for they way Object.assign is currently implemented), but eventually it should. I don't foresee us wanting to have both getPropertiesSnapshot and getSnapshot.. I think that we can handle that scenario without rewriting getSnapshot. I guess we'll see, but for now I'd like to go ahead with the current formulation.. You probably don't want an intrinsic with a values domain of Top. . Not your code, but since you are here, you never want a user visible error message to live inside a FatalError. Always call realm.handleError with a CompilerDiagnostic. In this case, however, I think that you are asserting that Environment.ResolveBinding is never going to return a Reference with a referencedName that is different from the name passed as its second parameter. That is best expressed as an invariant, along with a comment that clarifies the assumption and the reasoning for it.. This is the invariant you want. The above is nothing more than a (misleading) comment.. It is OK to call it multiple times since you want to update it as time goes by.. This might be a good place to assert that binding will always be defined. After poking through the call site code it seems to me that this is a precondition. It would be nice if I did not have to spend so much effort to find it out.. Why apply push rather than calling it directly?. Additional -> Pure. Maybe call this build-prepack?. This seems very large.. You probably want to move this inside the if.. Perhaps reset the counter here?. Normally I'd ask you to delete this from the Wiki, but I see that this error number is already used for something else altogether, so two wrongs make a right here.. Are these casts actually needed?. I am always looking for a motivating comment when I see an invariant. When can a serializedValue be something other than an LVal? Why can that never happen here?. Re: symbols. Prepack has currently very poor support for symbols. We also require partial targets and sources to be simple, which imply no symbols. We do not currently fail if you create a symbol property on an intrinsic or temporal object. I need to get back to this, but it seems inappropriate to fix this in the current pull request.\n. This seems like a bug in Flow.. Seems like a bug in Flow.. No, the temporalValue should be a differently value at each point where a snapshot is taken.. The temporal alias should be visited from the generator that was active at the temporal point where it was created.. This leaves me perplexed rather than enlightened.. The comment. I now notice it is following an existing pattern. Nevertheless, what on earth is being skipped  and how does skipping help with repro purposes?. Coming back to me now. Perhaps \"do not include this in options produced by --repro\".. None comes to mind. This is conservative, so we can afford to find out by running over real code.. The invariant basically states that nothing bad can happen if a reference is delayed. The conditions are too restrictive when you make the additional assumptions of being in pure mode. It seems to me that you could add a disjunction here that succeeds if we are in pure mode.. verbose is probably not the right name for this option.. That is my understanding.. Is it safe to assume that this has been bound to an object?. In general, it is better to issue diagnostics in the evaluator where the AST is close at hand. Realm.currentLocation could be wildly wrong. The purpose of the invariant is to require the caller to have done the necessary checks and to have issued the appropriate diagnostics.. Rather than relying on the constructor of Reference to do the checks and issue the diagnostic, do it here.. If it were to be supported, how would it work? In general, how do we ensure that we optimize a function in the right setting?. It appears from experiments that the this value of a function is always an object, but the specification does not obviously require a boxed object. I guess it is safe enough, but it is hard to be quite sure.. It is perhaps worthwhile to add a test case that supplies a non object to apply.. That results in a runtime error with a somewhat hard to understand error message. A compile time diagnostic would be better. Even better would be code to handle the actual assignment.. in a pure scope. and leave a residual. were -> can be. other -> earlier. Add: \"We have to havoc since the property may be a getter or setter, which can run unknown code that has access to Receiver and (even in pure mode) can modify it in unknown ways.\". No, a simple object does not have getters and setters and does not have symbol properties (and this applies to its prototype chain as well -- excepting the original Object.prototype object). We could expand this definition to mean that valueOf and toString will be well behaved, but that is non trivial. It seems that the expanded definition is so useful that it is already a de facto part of the definition, so this need to be made into an issue. While we are at it, we can also lift the restriction of symbol properties.. We do have diagnostic error codes for this sort of thing. We really really really should not introduce any new uses of reportIntrospectionError.. I think the real problem here is that selection result has not been refined with the current path conditions. Instead of \"!selectionResult.mightNotBeTrue()\" write \"Path.implies(selectionResult)\" (likewise for mightNotBeFalse).. https://fburl.com/aqqtguux. The main problem with a big code mod is that the existing uses of reportIntrospectionError are in places that are convenient for us, but which do not have the right source context at hand and do not facilitate recovery actions.. Every error message should have a unique error code and wiki page discussing it. While these two errors are closely related, they arise in different situations can do with distinct discussion in the Wiki.. This should be move to To. I'm not very partial to the xxxPartial naming pattern. Perhaps call this \"ToAbstractString\".. Perhaps amplify this comment to account for the cycle breaking?. Why not use type AdditionalFunctionEntry?. This is a bogus error code and the message is too vague.. I was mainly concerned about the prototype one. The others in this PR are basically the same error.. Your wiki pages would be more helpful if you can add a code sample that illustrates what can go wrong.. Good catch. Looks like Object.assign will do the right thing.. memoizeReference already takes care of the shadowing problem.. Yes, I have noted this in the initial comment.. I would not be very surprised if this case were the common one. It seems to me that your approach is path insensitive, which limits optimization opportunities.. This invariant seems like a precondition and therefore should appear during function entry and not inside a conditional like this.. You can assert that condition is an abstract value here because value.args[0] is guaranteed to be abstract and _resolveDeeply returns an abstract when called on an abstract. Please mention all this in the comment explaining why the assertion is true.. For what it's worth: value.kind === \"conditional\" guarantees that length === 3.. It is not clear to me why PP0031 needs to exist, given that we already have PP0012.. This seems to be a duplicate of the code in line 632. You can avoid the duplication by moving line 722 below this if.. Why is this a better error message than PP0011?. If it were simple. , is if. Meanwhile you could call $SetPartial from $Set in this particular case.. This will do nothing if realm.omitInvariants is true. We may as well check this at the start of emitFullInvariant and avoid some work.. Do we want to do this if O is partial but not intrinsic? If not, then line 1278 above also needs attention.. You should rather just use:\nthis.initializedModules.set(moduleId,  moduleValue.promoteEmptyToUndefined());. Please allocate a new error number in the range PP8000 - PP8999 and create a wiki page for it.. This message sound more like a warning than a mere bit of information. I.e. it warns that thing might go wrong because of the code that is being pointed out.. I don't understand the need for this.. I suppose this is what you mean by \"cleaning up types\". The reason why they were allowed to be void was to make them sparse. I.e. most objects would not be partial, so avoiding allocating a property entry for this case seemed like a good thing to me. Do you have data that suggests otherwise. Can you share it?. It is not clear to me how an object can be in a havoced state while it is being initialized and even less clear that this is at all desirable.. Perhaps omitting invariants could be a mode rather than a separate switch?. That part I understand. Why you need to create the property, I don't understand.. Perhaps it would make more sense to remove those initializations?. The constructor sets it to false. The invariant allows it to be true. I don't see why you would want that.. Why 4?. There is no discussion about what issue if being resolved by this and this seems a strange PR in which to make such a change.. It is probably better to have separate hidden classes for the non normal case. The fewer properties we require for the 99% case, the better.. Ah, so set may be called from the constructor and for such calls, you don't want to call isHavocedObject because it uses a tracked property. Makes sense now. Perhaps a comment will help the future reader.. I expected to merely removing the initializations would do the trick. Perhaps I'm missing something, but it is really not all that obvious.. The old behavior was actually wrong and this PR fixes this test case to behave as it should.. Next PR.. 0 : 99 ????. Above, you add in a comment to identify the last parameter.. Whoa, where did that formatting come from?. The wiki has now been updated.. I have no idea why this works. You should add some comments to describe the basic idea in some detail.. I can't find the code that looks at this value.. conditionalFeasibility , t and f are not great names. There should also be a comment here explaining what this map represents. . Where is this used?. I expected this to 1 copy.. Generators have to be compositional or things quickly go wrong and there are many test cases that will fail. This guarantees that a generator will not be constructed with a list of path conditions that are not true for some its entries.. I spent a lot of time looking at that option and failing. Join is not as self contained as you may think. In the join that results from \"ob = { foo: 1, bar: 2 }; if (c) { ob.foo = 10; } else { ob. bar = 20; }; ob.foo;\" then the joined value of ob.foo after the if-else is not c ? 10 : undefined, as you might conclude if you did the join in isolation, but rather c ? 10 : 1.\nSo, before we can do the Join.joinNestedEffects, we need apply the prior effects so that the join can find them in the objects.. It is a fair point, but I am none too sure that having two functions rather than one will really make things easier to understand. For now, I'd like to conform to the API of joinEffectsAndPromoteNestedReturnCompletions.. Windows. I'd like to see a comment that explains why you believe this will always be the case.. Moving entries from one generator to another is an anti-pattern for us.. Please sort these while you are at it.. Please explain why this value is the maximum.. Never modify an abstract value after it has been created. You can pass in the kind as an optional argument to createTemporalFromBuildFunction.. What does it mean to be \"safe in this context to create\"?. Please sort these. Make this an argument to createTemporalFromBuildFunction. The simplifier does try to make things canonical and that can involve re-ordering commutative operands.. I don't think we should accept non convergence of the fixed point loop. But I'll need to dig into this a bit more.. For this method, EmptyValue and deletion seem like Red Herrings. The obvious bug here, mea culpa, is that conditional expressions were expected, all too conveniently, to always have abstract consequent and alternate values. If those are concrete, they should still be added to the returned values array, but they should not be visited. It may help to rename the method to \"_getNestedValuesFromAbstract\".. These invariants make me feel uneasy. As always, I strongly recommend adding a comment explaining why this must always be true. I can't say that I understand the changes in this PR well enough to convince myself about this.. Coming back to the question of what to do with EmptyValue: When this value \"leaks\" outside of code that checks/ensures property absence, it must be \"promoted\" to undefined. There is a helper method \"promoteEmptyToUndefined\" on Value. Currently it is only used to guard against EmptyValue being written into a variable or property. It seems that it should also be used to guard against EmptyValue leaking out of an optimized function.\nI can look into this and fix it in a separate PR.. The non convergence is a result of a hash depending on a name that is generated differently (by design) for every fixed point iteration. Fixing the hash to use a simple counter make the failure go away.\nTo fix this, change line 952 in utils/generator.js from\n  let res = new Constructor(this.realm, types, values, hashString(id.name), [], id, options);\nto\n  let res = new Constructor(this.realm, types, values, 1735003607742176 + this.preludeGenerator.derivedIds.size, [], id, options);. Even better would be to also change this method name to getSerializerStatistics.. The EmptyValue problem is fixed in https://github.com/facebook/prepack/pull/1787. Good catch, it is hard to remember to always use three valued logic. In this case it should be sufficient to just check that y is a concrete value.. issue number?. Please sort these.. Please sort these. Rather call this createTemporalWithWidenedNumericProperty. This method does not belong in Widen. Move it to ArrayValue.\nProbably should be called \"isIntrinsicAndHasWidenedNumericProperty\". I'm none too sure about the necessity of the check for the object being intrinsic.. Please explain the need for the cast to any.. Should context be O? At the very least write a comment about it.. Should context be O?. random keystroke detected. array and will like -> array and the call will likely. !(initialValue instanceof UndefinedValue). This error code has already been taken. Update it and create a wiki page for it before someone else takes PP0035.. Please sort these.. Added some scary looking comments.. Doing this while the effects that contains completion have not been applied causes completion to capture the current outer generator, which is why the declaration is out of place later on.. Calling Get here is not safe since it you may end up calling a getter that has side-effects. It is unlikely that the caller of isReactElement is going to always be careful to make sure that only side-effects that are expected by the application programmer survives.\nThere is a helper method: _SafeGetDataPropertyValue that you can use to get the value of a local (i.e. not from the prototype) data (i.e. no getter) property, in such a way that no invariant checking code is generated (i.e. no sneaky side effects).. This seems like something that belongs in Realm.. Good idea, but probably something to do as a separate PR that fixes all overly general uses of mightBeNumber. Also, I can't really test the distinction until we have range domains.. Yes, I want the output from --verbose to be as readable as possible.. we can -> we have to. havoc it -> havoc the argument\nthe mutations -> the possible mutations. This is probably not intentional.. How about \"!(value instanceof ObjectValue && value.isFinalObject)\"?. I'm bemused by this. You havoc but you don't actually want the havoc. Can you add some explanation of what the havoc is doing for you and and clarify why the modified bindings should be restored? Also, is there a cheaper, more direct way of doing all this?. An invariant failure means that we have a programming bug in Prepack that we should fix. I should hope that is NOT equivalent to that. I suspect you mean to say there is a programming bug in the application that is being Prepacked. Which means that this is a special kind of FatalError, which begs the question of why you do not extend FatalError and can also be explained better in the preceding comment.. I have trouble understanding what you mean by \"outside these effects\".. Would the \"expected bail-out\" language reach users of the React compiler? If so, they may not know what to make of it.. Hopefully effects lists everything the render did. It would be weird and brittle if additional effects were still lurking in realm.savedEffects.. // Copies of 42:1. If neither of the two objects has the property, perhaps we could just return undefined?. Since isTerminal is declared to be optional, it is a bit surprising the see the !! here.. Why the assignment?. Only assign if true.. This invariant is not true and I don't see why it should be true. It is perfectly OK and expected for one branch to be a normal completion and the other to be a throw completion.. A PossiblyNormalCompletion entry never terminates a generator.. Yes. The test now fails without this PR.. It will be safer it this entire section of code moved to the front of this function. . The fact that obj is an AbstractObjectValue does not tell us that the implicit conversion did not have side effects. Even if these side effects are benign and private to the current pure scope, repeating them might break things.. A temporal value is something that needs to get created/computed at a particular point in the time line and may have further mutations that occur later on in the time line. An a-temporal value can get computed at any point and does not change.. I see there is a PR that will make PossiblyNormalReturnEntry go away. That should erase this concern.. I am completely lost here. Apart from manipulating the semaphore, what does this actually do?. I don't get this condition. Did you mean:\nif (initialValue && !(initialValue instanceof UndefinedValue)) {. Could/should this happen in a non pure scope?. then should probably be:\nif (!initialValue || initialValue instanceof UndefinedValue) {\nBut since this guards an error message that complains about there being a value in the first place, I still don't get it.. We would like to declare the properties here.. I'm all for consistency, but I do have to wonder if it would be more readable to just use the property directly, i.e.\nlet rval = outsideEffects.result;. Here is an example where we are already inconsistent and it doesn't seem quite so bad.. Why did the formatting change?. It will probably be quite nice to just stick with the property names of Effects.. We do have a helper called evaluateCompletionDeref that does just this.. I think you mean evaluateCompletion here, since evaluate will never return an AbruptCompletion.. Seems like it. Clearly we need more test coverage in this area.. On the other hand, conditional expressions are expressions, so perhaps evaluate is the right thing to do here in both cases and we do not need the check for an AbruptCompletion.. If this used evaluate rather than evaluateCompletionDeref, you could dispense with the check for AbruptCompletion, but you'd need to bring back the check for Reference. It sounds like we need a helper called evaluateDeref. As far as I can tell the else is now an infeasible path and should be guarded by an invariant(false).. Including the hashValue/object id should be helpful.. Please add a type annotation for realm.. The partial evaluator needs to get fixed to work in the new world. This is not critical path and will have to wait a bit.. Yes, but joinValuesAsConditional should also do this optimization, so while this is faster, it is also a teeny bit of code bloat.. It seems to be a forgotten residue of earlier code that has been replaced.. It seems like something we should try to fix in joinValuesAsConditional. Any chance you can come up with a repro?. I have no idea what is going on here. Care to explain?. It is short for \"new alternate\". Without the abbreviation, the code get's so spread out vertically that I find it hard to read.. That is not legal syntax for properties and I (and you) prefer not to make properties be of type ?Effects.. if (left !== undefined && right !== undefined && left.equals(right)) {\n  return left;\n}. This is a good example of an utterly useless comment. Much better (and much harder) is to write a comment that explains to a reader of the code why this invariant is expected to hold. In terms of debug logging, for those who care about such things, it would be better to include information about the two values.. The  closest proxy to it that can be checked cheaply is to require priorCompletion.savedEffects to be defined.. It seems like a bug or short coming in the serializer. I do not quite understand why.. Since outputFilename is an optional parameter we already know that it cannot be null, so outputFilename !== undefined would be sufficient.. The type annotation for heapGraphFilePath already excludes null.. instead of \"typeof outputFilename !== \"undefined\"\" just write \"outputFilename !== undefined\".. Instead of \"typeof outputFilename === \"string\"\" write \"outputFilename !== \"\"\".. outputFilename !== undefined && outputFilename !== \"\". keepOldSteppers === true. !== true. O.$StringData !== undefined. ditto. ditto some more.. name !== undefined. locString !== undefined. name !== undefined. I don't think there is a need to distinguish _view and view.. Is this needed?. It seems nicer to put a type annotation on t and to modify the assignment below to have an else case.. I see. That is a bit sad. Never mind then.. Sorry, typo on my part. Yes, name === undefined.. You are correct.. Play it safe and put an invariant here requiring ref.base.kind === \"conditional\".. Since this function is only called if isIntrinsicAndHasWidenedNumericProperty is true for arr, can this ever be different from realm.intrinsics.ArrayPrototype? Should there be some sort of invariant.. This can run a getter. Since we don't know what P is, can we risk running it here? It might be worthwhile to write a test case that tries to break this.. Can we make assumptions about Array.prototype? It could have been modified in global code. Perhaps there should be a test that property copyWithin is a local data property?. OK, I meant to say \"we don't know what proto[P] is\".. As things stand, the fact that Prepack might know which getter is being run when you evaluate O[\"copyWithin\", does not make it OK to run this getter at runtime. At least not without further checks.\nWhat I mean by local data property, is that \"copyWithin\" is known NOT to be local property of O, and is a also known to BE a local property of Array.prototype and it is furthermore known that Array.prototype.copyWithin is NOT a getter.. Those changes look good, but how do they relate to this code? There is no check here that it is safe to call copyWithin.. If proto !== realm.intrinsics.ArrayPrototype you emit a runtime call. That seems dangerous. I think that it is actually true that proto === realm.intrinsics.ArrayPrototype is true in all cases, so an invariant seems better than a conditional.. If this.values.isTop() we know NOTHING, so we have to return true here.. I'm dubious as well.. Why is this now expected?. It is not clear to me what is being inlined here and why it is OK for Object.assign to go away.. You may want to assert that nextSource is neither NullValue nor UndefinedValue at this point.. Why is it valid? !frm.mightNotBeHavocedObject() tells you for sure that frm is havoced, while !frm.mightBeHavocedObject() tells you for sure that frm is not havoced. Without the negation you don't really know anything.. This seems like change that fixes something. Is there a test case for this?. Crying out for a test case. ;-). If this fixes nothing and you are sure that the current version works, you should put this in its own PR with appropriate comments. Ideally, you would like to see a test case that a) mutates config and then fails and b) recovers and then does the right thing at runtime.. We need this because \"throw __empty\" is used as a signal for \"the normal branch\". See Program.js/274.. Cheating a bit so that extractAndJoinCompletionsOfType can be used to get a single join of the normal code branch and all of the exceptional branches.. I think these may as well be part of RealmOptions.. Instead of silently doing nothing if both these conditions are not met, why not have a check somewhere that complains and then use invariants to make sure that we can assume it everywhere else?. result.message !== \"\"\nBetter yet, provide a default message that is not blank.. Rather use \"Diagnostic\". Rather spell this out.. Do you want to marshall message as undefined if it is not supplied? Consider making the parameter not optional, or provide a more useful default.. If leftValue evaluates with side-effects, these effects will be invisible to the _resolveDeeply call below. Perhaps such code should not be allowed, but in that case a check will be needed. So either way, leftValue should be evaluated before rightValue.. You only want to evaluate leftValue once. This code does not seem quite correct.. Never mind, I was thinking of AST nodes, not a-temporal abstract values.. I do, however, wonder if you want to resolve rightValue deeply. If would not be evaluated at runtime if leftValue is truthy.. I see. What exactly does __resolveDeeply do and why do you use evaluateForEffects on it?. In the light of this, it seems OK to make message optional.. Instead of making this \"\" if not supplied, keep it undefined. JSON.stringify will then omit it from the string. That seems like a better way of handling an optional parameter.. whatsoever.. Prepack might produce code that deviates in behavior from the original code, if the original code is not well behaved.. Prepack will produce code that matches the behavior of the original code, but the original code might have an error.. Prepack is unable to produce code that could possibly match the behavior of the original code.. At this point (at least in master) completion is guaranteed be an instance of Value.. Probably not needed.. completion cannot be an instance of PossiblyNormalCompletion at this point.. I would have expected that evaluateCompletion will never return a Value and that this can be part of its type annotation.. Come to think of it, why not introduce a new subtype of NormalCompletion called \"SimpleNormalCompletion\"?. You probably want to remove \"| Value\" from the type of c.. You should never throw a FatalError unless you have first reported a diagnostic message.. Not for this PR, but we really should encapsulate this in a helper.. This seems a bit like papering over a huge crack in the wall. The loop can modify many other things in a way that is totally opaque to Prepack. Yet, only the this value is havoced. Better than nothing, but not much better.. Can you add a comment to explain why the wrapper needs to get havoced? Preferably, there should be a test that fails if it is not havoced.. Why not throw?. PP? We frown on non standard abbreviations.. infinite. We only use invariants to state conditions that we firmly believe should ALWAYS be true. An invariant that could fail because of environmental factors should instead be a runtime check with an appropriate user friendly diagnostic message.. if (this._adapterChannel !== undefined) {. You need to update the type annotation to \"void | AdaperChannel\". Something that we probably should add support for.. actually start the execution.. The comment is now out of date. Just delete it.. The type annotation already precludes c from being a normal completion. There is no need for it and there is no todo here either.. Given the name of the method, it would be more appropriate to do the wrapping inside the method.. Given the name of the method, do the wrapping inside it rather than at the point of call.. Rather join just join the values.. Delete this comment.. This can now just become Completion.. Amounts to just Completion. You probably want to rename value to completion.. At this stage completion cannot be a PossiblyNormalCompletion.. Moving the code around like this makes blame less effective.. fix what?. The message seem to imply that canBeApplied is true.. If the loop body throws, it terminates early. That seems similar to a loop body with a return in it. I don't see why you check for the latter, but not the former.. What is with the starting \"?. The loop body may access locations that are not reachable from this.. Which answers my previous question. It would be good to point this out in the actual code. It is really not that obvious.. Did you mean to leave this in?. issue number. This did not have to move.. You did not have to reorder these.. What is going on here is that the existing pre-state may be out of date because common subexpression elimination may have changed the values of some properties before a nested set of Effects is applied (via redoProperties). Without updating the pre-state in, we cannot safely undo the nested Effects without breaking the processing of the outer effects.\nThis is an artifact of applying and undoing effects while serializing and probably another reason for getting rid of the Generator.fromEffects logic.. Perhaps call this \"inReactProps\"? Come to think of it, reactProps is not a very helpful name for someone unfamiliar with the code base.. You may want to subclass Error with something specific to this situation.. No, this should be the state before the fork, so joining the descriptor is not appropriate.. Agreed. Going to undefined seems like a bug.. BTW. even if I apply your suggested change, test-react still fails for me.. Yes, master with the PR. I did have some merge conflicts.. No, if this is not bottom and t is EmptyValue then we are joining not bottom with bottom, which is not bottom.. This marking only happens if a closure is actually constructed, so it is not as pessimistic as purely syntactic approach, but it is still pretty pessimistic because it does not analyze the function body to find the set of identifiers that might bind to variables that are not local to the function body.. Rather use an iterator that does not allocate any memory.. I'm none too sure what is going on here. At the very least this annotation should be removed from the test case that has it.. This comment seems wrong.. It is not clear to me how this test case is related to the rest of this PR.. How is this related to the rest of this PR?. How are these files related to the rest of the PR?. This is not needed for this PR, but I noticed it while debugging and it seems worth fixing.. I can see that we should not waste time on non objects nor havoc objects that appear in the val.args, but cannot be seen by the callee. This is all good.. Here I get concerned. By definition ALL objects known to prepack might be denoted by val. Just havocing the arguments does not seem sufficient. As things are today, we refuse to compile any program that accesses a property of an abstract object with a values domain that is Top.. It seems wrong to for a value that calls out \"numeric\" in its kind to not have a types domain of NumberValue. Not the fault of this PR, but now that we've noticed..... It took me a while to convince myself that this is OK. Essentially, anything created this way is \"pre-havoced\", i.e. we don't know the value of a property of such an object and we get a new one every time we access the property. At the very least we should provide and efficient and much more obviously correct way of checking that an abstract value is of this kind.. On second thoughts: We can only access properties of abstract objects with templates and such object will have a values domain that is not top.. Ah, very misleading.. It seems that \"mightBeLeakedObject\" might be more appropriate.. Why do we have an expensive dynamic check of static property inside of a loop?. Every value has already has method mightNotBeTrue, also isTrue(bv) => !bv.mightNotBeTrue() but the other way around, so using the latter is probably better.. f only takes one argument.. f expects its first argument to be a function.. I don't get this. Why?. This mismatch is intentional because the two cases below are specializations of the general idea of the comment.. The prefix \"derive\" in the name of this function seems misleading to me.. I'm no fan of the term \"derive\" in general. It would be nice if we can phase out its use, starting with any method that does not ultimately call Generator.deriveAbstract or Generator.deriveConcrete.. I don't have a better name to suggest, but I do feel a little sad about this. In Spec# we had \"assert\" for compile time invariants that should be proved by the compiler and \"assume\" for runtime invariants that can be exploited by the compiler. That seems SO much nicer than \"invariant\" vs \"__invariant\".. This value is a bit mysterious and makes the test case harder to read than is necessary.. Why use a map to get at the arguments that are already stored in result and that can be obtained with result.args?. Come to think of it, you should push the invariant condition onto the path, because execution cannot continue unless it is true.. OK, looking at the code of generator.deriveAbstract I can't off hand see a compelling reason why the arguments should not also be stored on the abstract value. Perhaps there is some subtle reason arising from the structure of the serializer, so @NTillmann would have to weigh in on this.\nIt also bears noting that realm.preludegenerator.derivedIds already seems to provide a way to map abstract values to their arguments, albeit in a much more obtuse way.. It's intended use case is a = [fixedPrefix]; if (c1) a.push(x1); if (c2) a.push(x2); ... and so on. That will match this test because of existing normalization and simplification code. However limited it may be, it does help the Array.map use case, so it is not entirely pointless.. This is really something that test262 should cover. It may well do that already, but we need to update our version of it. Meanwhile it doesn't hurt to just sneak it into an existing test case. Most of those need basic things to work and break when they don't. This is just one more such thing.. The changes above were needed to fix those issues.. Why \"type\"?. It is correct. The path conditions are restored when evaluateNodeForEffects returns, so the path would be whatever it was when the fork (that is now being joined) has occurred.. It is correct here for the same reason as above.. The path conditions here should probably be empty. Picking up the current path conditions from the Realm might be the reason why composition does not work.. Does that make Flow faster?. This name is very generic, so a comment giving a brief idea of what it is about will be very helpful to a future reader.. In the context of Prepack, that seems a bit unlikely to me. Startup is not our problem.. Please sort these.. a map and a set. shouldn't set be undefined? See lines 723 and 729 above.. Please break up this long line.. I am befuddled by this name. How does this method proffer Advice? Is there a less obtuse way of describing what it does?. Did you mean to say advice?. Given our existing naming scheme, it is really confusing for an (ObjectValue, Generator) pair to be referred to as an IntermediateObjectValue. Every other type that ends with the Value suffix is a subclass of Value. This one is not. That is surprising and a trap for the unwary.. We already have !d1.value.mightNotBeTrue(). Also, the _ prefix is used for private object properties and using it for a local name seems strange. d1ValueIsTrue would be a better name.. leaked objects are. Why not call the type \"LeakedObjects\"?. I'm uncomfortable with this. Havocing an object is not the same as leaking it. This conflates the two concepts.. This seems to do the same kind of thing as ObjectValue.getSnapSnot. That seems like a great pity to me. . A routine that is named \"havoc\" ends up \"leaking\" an object. That smells wrong.. I apologize if I have offended you. If you do not welcome the unguarded impressions of someone reading your code, I'll refrain. No offense was intended. It is just me being my authentic self.. It would have to clone all that. On second thoughts, though, I would like to do something that does not amount to tail duplication.. __optimize. Rather use possibleConfig._SafeGetDataPropertyValue(\"pure\"). While you are at, perhaps fix all of the other unsafe uses of Get in this file?. I'm surprised and somewhat dismayed that this seems to work at all. If I understand the basic idea, this seems to be all about bubbling up the exception right to the top level, but then not emitting any code for throwing it there because the code has already been emitted here. It seems to me, therefore, that it would be safer to throw an actual throw completion here (with a flag set) and then to a) complain loudly if anything ends up catching the throw and b) not emitting any code for it at the top level.. I am busy conceiving it.. Throwing a normal completion smells wrong. It would be awesome if you make this work by using a ThrowCompletion.. We probably don't need to call yarn from yarn.. The previous version of this made sense in as much as that it avoided building a set unless it was actually wanted. Do you now make use of the set for every call of foldMaps?. A comment explaining the role of the generator will be very helpful to a new reader.. Best practice for invariants is to explain why you believe they can never be false. In this instance, I cannot verify this unless I leave the diff view (of this commit) and start reading the overall code. A comment would have saved me a bunch of time.\nAs it is, I can't quite figure out how lo can ever become undefined. So my question is: Why is LeakedObjects defined to allow undefined elements? In particular, what is the use case and which test case exercises that use case?. If we come across a use case where we need to havoc something without leaking it, this approach will bite us. Right now, I'm not convinced that there is such a use case, so this may turn out to be OK. It just smells a bit off to me.. remove \"with target\". I'm a bit perplexed by this. Is there a failure case that this fixes?. There is already a timeout check to guard against loops that are actually infinite. In theory that also works in this case. The reason why we need this is because keeping track of so many forked execution paths is highly non linear and can lead to so much work being done from one timeout check to the next that it seems like things will never terminate. It would be nice to have a comment explaining this in the actual source code.. Great, I was looking for this just yesterday!. Perhaps this calls for two separate methods?. Is this intentional? If so, a comment will help the reader.. Does the test case crash Prepack without this fix?. to a LeakedObject. consisting of a generator and the object, if the object leaked.. the generator timeline -> the timeline. Pairs a leaked object with the generator in which it must be materialized into the timeline.. computeJoinedLeakedPropertyAndLeakedObject. I'm currently working on this code, so there will be merge conflicts for one of us.. It took me a while to figure out that recurse captures and e and sneaks it into nae. I would make it more explicit if it were up to me.. I would prefer a function, rather than a procedure with side effects.. I'm trying to move towards a world where Effects is immutable. This code certainly will not help me get there.\nIt is not clear to me where the materialization should happen, however. It cannot happen at this point in the time line, because the objects need to be materialized before the calls that leak them. Those, presumably, are in the generator that is appended to the current generator in line 1456. \nOn the other hand, they need to happen after any temporal values that they may depend on. Those too, can be tied to the generators that make up the ones appended in line 1456, so the materialization cannot happen before them. Possibly, the serializer is going to just sort all of this out, but that where my brain explodes.\nI do suspect, however, that this is exactly what happens in code above since the materialization will append the definition of the objects to point in the timeline that comes after the calls to that leak them. Or at least, that is my current state of understanding this code.\nIf you can get away with materializing the leaked objects into the current generator at this point, you'll be able to rip out quite a few lines from the PR, which is something I'm always happy to see.. Please always add a return type annotation.. The Flow guide suggests that you use {} rather than Object.. It appears that [1] will display as just 1. Is that what you want?. I think you should include the type prop here.. It is not OK, but right now it is necessary. Long term, I'd like to fix this. That will not be easy and is going to take quite a bit of preparation.. Not your fault, but this statement seems unsafe. A TODO comment and an issue would be great.. This comment now seems wrong.. It is neither clear to me that it is correct to just check for instances of ECMAScriptSourceFunctionValue nor that it is a good idea to name this check \"isFunction\".. There is already a Spec method: IsDataDescriptor. It seems to me that isCertainlyLeaked && IsDataDescriptor(descriptor) would be safer and more in keeping with existing conventions. . You probably want to move this to follow the handleError call. I worried that it might be too strict, but it seems that it will only get here for operations that will always fail on symbols.. This is probably too aggressive. Not every binary operation on symbols will fail at runtime. The error would be better generated at the actual operation, where there is more context.. A symbol is a primitive value, so line 623 seems correct while 622 seems wrong.. buildStack does not yet handle abstract messages. You can add such support by emitting the stack as a string template. Alternatively, you could just comment out the throw with a TODO comment, along with an issue describing what needs to be done.. This looks like a candidate for ToStringValue.. This looks like a candidate for ToStringValue.. The throw should replace the diagnostic in line 99.. The original logic for this seemed more consistent to \"isCertainlyLeaked && IsDataDescriptor(descriptor)\".. Why not put NameGenerator in its own file? Importing it from generator.js seems plausible, but importing it from PreludeGenerator.js just seems weird.. I'm a bit at a loss as to your point. The clone methods do not make exact clones, but modify their results in the way that is spelled out in their names. As for the immutability of Effects, that is the goal but not yet the reality. When it becomes reality, there will still be lazy initialization. The canBeApplied flag is a temporary debugging aid.. The name is already long, no need to abbreviate Prototype. The AbstractValueType bit is probably redundant and not that helpful.. I think the comment should read: \"has not been altered since global code has finished\".. prototypeIfPrimitive. Rather use _SafeGetDataPropertyValue.. This comment creates FUD rather than enlightenment. Can you reference an issue that spells out the issue in detail, along with examples?. This makes no sense to me. We know that target is a primitive boolean (not undefined and not null) and we know that this version of toString has no side effects. Calling it via the time line is just not right.\nThere is a bit of an issue with the existing code: All we really know at this point is that there is an expression that ends up calling this toString method on the original value of String.prototype.toString. We don't actually know that (A).toString() will end up calling this method at runtime. So, to be on the safe side we should guard this case with the additional constraint that the current value of String.prototype.toString is in fact this method.. Are there cases where we do not want createTemporalFromBuildFunction to return a value that is the closest match to its type argument? If not, it seems to me that ArrayValue.createTemporalWithWidenedNumericProperty should be invoked via createTemporalFromBuildFunction and never directly.. None of the String.prototype.methods need to become temporal.. _SafeGetDataPropertyValue returns a Value, not a descriptor.. Rather than use lval.args[1] and lval.args[2] below, we usually deconstruct lval.args at this point. I.e. let \"[condition, ll, lr] = lval.args;\" or some such thing.. I think you may have removed the only references to ABSTRACT_OBJECT_SET_PARTIAL. If so, please remove its definition as well.. I see. Since the operation is known to be an error at compile time, we may as well process it as such. If something handles it, fine, if not it bubbles to the top level and gets a message at that point.\nI do think, however, that is highly confusing to do this in a function called reportError. Perhaps just rename reportError to reportPossibleErrorOrDoThrowCompletion.. __prepack_internal__ seems like a rather generic and non descriptive way to do this check.. We decided back in January to rename additional functions to optimized functions, but even now we are still adding new names that incorporate additional. Sigh.. This name is not any better than \"doSomeRandomStuffToSomethingOrOther\". It would be less bad if this function were nested inside createAbstractArrayValue. Either way, a more descriptive name would help the reader.. The function name suggests that it returns an abstract value. It seems to do no such thing.. Please provide parameter types and a return type.. Please provide a return type annotation.. Since posInfo already includes all of the information in pos, why pass it in?. I would prefer to see something like:\nlet delta = posInfo.newLine - otherInfo.newLine;\npos.line = Max.max(0, otherInfo.originalPosition.line + delta);. may be. If the severity is a FatalError there is no possibility of recovery and returning \"Recover\" should be ignored. Returning it anyway may well be a valid thing for a test runner to do, as long as there are never any tests that depend on actual recovery. In other words, such test should fail not succeed.. If we just carry on from this point, we'll do so with an incorrect state, which may led to weird and misleading errors later on in the compilation.. WHOAAAA! We can never recover from FatalError.. Since this is marked as recoverable (and is recoverable) we have to honor the result of handleError.. Please have a look at other places where CompilerDiagnostic instances are created. There are niceties to be observed and you should not throw diagnostics.. Not your fault, but while you are here, would it be possible to change this to \"env !== null\". We avoid implicit conversions to boolean whenever possible.. Perhaps just check that P !== __proto__?. not actually -> not. P, however, if it has -> P. If, however, it has. The previous line is pretty short, so just combine this line with it.. I'm confused by this. Since current is a descriptor that is obtained from a property, current.enumerable should be defined and be a boolean, so why not just write !(\"enumerable\" in Desc) && current.enumerable?. The wiki description of this is very brief and the example requires a detailed understanding of the behavior of Object.defineProperty. It would be helpful to expand a bit on the description to make it clear that in the absence of an explicit enumerable property in the descriptor it would either leave the existing true value unchanged or set it to false, depending on the value of c.. realm.generator !== undefined. Is recover necessary here? It seems kind of weird if there is just one error.. It would be nice to have a test case that actually does the wrong thing (and thus fails) if the error is not generated (and treated as fatal).. Path conditions are in fact simplified. When you push a new path condition, all the existing path conditions are simplified using the new condition.. Only AbstractValue methods should ever call deriveAbstract directly.. If getPureBinaryOperationResultType does not throw, it should not be the case that the binary operation may throw or have a side effect.. In particular, if val is temporal, then the derived values must be temporal as well. The reason being that val is known to be an object (and thus not null or undefined) at this temporal point, but may be null or undefined at a different temporal point. Since stringify and parse are not total when their arguments are null or undefined, they cannot become a-temporal when their arguments are not also a-temporal.. Are you fixing things or just adding a todo comment? If the former, this is not complete, if the latter then please add TODO to the comment along with an issue number.. You only need to to do this if O is temporal.. Check if O is temporal.. Simple: if Receiver is temporal, the get call must be temporal. Otherwise it is a-temporal.. Since this is a warning, it is recoverable and you should throw the fatal error only if the return result of handleError is \"Fail\".. In that case then yes, \"FatalError\" not \"Warning\". And then don't recover.. Indeed. The invariant just makes this more obvious and also serves as a sanity check. In general, we are open to stating redundant invariants if it makes the code more readable and if it makes it harder to accidently break the code.. It is a fair question, but I don't know the answer. It might be an improvement, but it is not entirely obvious to me that it would be. For now, it is probably not the most important thing we have to worry about.. We need an error message that will help a developer pin point what is wrong and help them understand how to fix it. The error code needs to be unique and there should be a wiki page that documents the error in some detail, preferably along with example code.. Why do we require chalk and not import it?. This will be copy no 6 of this function. It looks like something we should factor out.. Please sort these.. Intrinsics is not an interface or a type, so what is the meaning of the invariant annotation in this context?. Is it a good idea to return false if _stringType is not defined? Why not return this.stringType.equals(type)?. This will break things (and has already). The ECMA spec is clear that the behavior below is correct. I.e. any object that is callable (implements [[Call]]) should report \"function\". I'd need to understand your scenario in more detail before I can help you come up with robust solution.. I see. The current code seems wrong then. It should not give up when it can't tell if a abstract object is callable or not. Worth calling out in an issue.. You seem to be using a feature of Flow that is not documented in https://flow.org/en/docs/. My reading of that document is that + is a way to mark an interface property as covariant, which constrains the code accesses the underlying object via the interface to not write to that property, lest it inadvertently violate the type annotation of the property of the underlying object.\nThere is no documentation that I can find that informs me that + is a way to mark a class property as \"must be initialized inside the constructor\". I'm also much bemused by this interpretation since this should already the be case since _module MUST always have the type Module.\nWhere do I find more information on this use of +?. Hmm, this is extremely subtle. You are essentially saying that the only way a there can be a type T so that this.stringType.equals(T) is if T === this.stringType. I'm none too sure that this is desirable, but if it is, there should be a big comment about it and my follow up to that would be why call equals instead of using ===?. I don't think a blog post from 2016 trumps the current documentation. Even so, I don't see anything there that suggests that + means that we always have to initialize the property.. We probably should never call materializeBinding unless abstract interpretation is enabled, in which case we can assert at this point that realmGenerator !== undefined.. An initialized binding should never have an undefined value. I don't see how we can validly call materializeBinding before initialization is complete. Also a binding that has been initialized to realm.intrinsics.undefined seems to me like it should be materialized.. It seems to me that this value should be set to an abstract value that has an expression that does a runtime read from the binding. The abstract value should behave like Top otherwise.\nI expect that this logic happens elsewhere. It seems to me, however, that this is the right place to put it.. leaks the value -> might like the value via a setter method. The receiver, too, might leak to a setter. behaviour -> behavior. I'm still befuddled. If the C++ API can return a value that wasn't obtained via the getter of stringType, what guarantee is there that isStringType won't be called before stringType is called and therefore have inconsistent behavior?. OK, be that as it may then. A source code comment to this effect would be very helpful to a future reader. Ideally some invariant to enforce it would also be desirable.. Actually no, that is debugging code that got left in. I'll remove.. It is not desirable, but a hack to work around the fact that generator.emitConditionalThrow wants a value for its parameter. Fixing that to take the completion instead would be preferable. For this PR, however, that seems out of scope.. I'll delete the comment.. The comment is correct if you don't equate the meta variable x with the comment variable x. I'll update the comment to make it more difficult to equate them.. The comment tries to communicate the pattern in the most abstract way. The code does not follow the names in the comment when things get complicated.. Duh! I'll remove this.. Since Flow checks this for us, there is not a lot of value in making sure at runtime that Flow did not goof at compile time. I find it detracts from readability when there are runtime checks that repeat what type annotations guarantee.. I don't understand this. Why is it OK to only update the first concrete object in the set of elements? As far as I can tell, we have not established that the set is of size one. Did you mean to include this inside the if below? If this code is indeed wrong, it would be great to add a test case that will trip over it.. Nice!. Since you are no longer tracking doesNotHaveProp, it is wrong to just continue here. The best solution to this seems to be to join the descriptors rather than the values. That is on my radar screen. Meanwhile you need to continue to issue an error when this happens. Since this passes tests, it also be really awesome to get a test case that falls over this.. This suggests that the result returned from throwIfNotConcrete can be different from the old value of existingProp. That makes the code harder to read in my opinion.. I see. Just remove this.. What happens when dependency is not a number or string? What happens if tryInitializeModule does not succeed? Since you throw away the return value of tryInitializeModule and it has no effect on the global state, it is not clear what the point of the call is. Is there a side-effect, such as an error message? Some comments about your intent here would be very helpful.. Since the default value is undefined, this is unnecessary and somewhat confusing.. Perhaps make this an actual getter?. Correct. Moreover, only if isCondition is true.. Correct.. Good catch.. Rather put this condition into a helper function named something like \"operationMustBeTemporal\".. I'm still a little bit disturbed by this. If one of the arguments is temporal, then moving the operation to point where the current path conditions do not apply may be safe, but it seems hardly desirable.\nIn essence, any operation over temporal values should result in a temporal value, as a rule, except for a few specific cases that are well documented.. This logic seems the inverse of what you intend. This seems to call for an additional test case.. Why is this commented out?. I find the \"onExecute\" name a bit surprising. This is called when Abstract Interpretation (execution) is completed, right? . Presumably these are mutually exclusive and this if can be inside an else.. Why || and not &&?. Why are you not checking if leftValue and rightValue are known to be functions? Alternatively, why are you checking if consequentVal and alternateVal are functions?. soureces. evalaute. evalaute. I don't understand this comment.. Thinking about this some more I'm not sure that there is value in checking if consequentVal and/or alternateVal are functions. Since we are calling them, they very likely are functions, whatever we've been able to statically determine so far. Also, using an if statement to create separate call sites should be a good thing for performance since the two call sites might end up being mono-morphic, whether a single call site for an expression resulting in the function to call is extremely likely to be poly-morphic.. use Array<ConcreteValue>. Rather keep the type as Array<ConcreteValue> and fix up the call sites.. Instead of using a slice, use a filter.. Return Array<ConcreteValue>. Rather use a filter to get the concrete values.. Please explain why this is not longer desirable.. I just noticed that the test is actually broken and the intent is very clearly x.entries().. Eventually.. What is the right time? What is the wrong time?. Is it safe in general to just update all of these properties?. You are not just replacing the body but the parameters too and much else beside.. to remain -> remain. This seems a bit odd to me. Care to add a comment?. Why have such a subtle treatment of Target? Wouldn't it be better to just not call the method in the first place?. Do not clone.. Remove this.. Do not clone.. It is not clear to me why this case now need value to not be an abstract object value.. !== undefined. Should be possibleParent instead of fun. Please add a test case that will fail with the code as it is now.. Flow does not understand this test well enough to be know that the assignment in line 307 below is type safe. You can fix that by moving the deleted invariant to just before line 307.. We frown upon type casts like this because they are not checked in any way. Right now it is correct because of the condition in line 303, but in the future things might change. Perhaps not here, but it is better to just uniformly enforce a rule about this.. We need an actual Wiki page for this. I am not thrilled by this, however. It may be more specific than PP0001, but it is still vague and not actionable. Each call to this routine should instead have its own error code along with a wiki page that gives concrete advice about it.. It is far too subtle to change the semantics of the abstract interpreter based on whether or not a warning was upgraded to an error and then subsequently ignored.. Never ignore the result of handleError and then carry on. You may only ignore it if you throw a FatalError immediately afterwards.. You need to update the return type annotation.. It seems to me that this is reduction of current functionality. It might be prudent to first establish that we no longer need it and probably wont need it any time soon.. This is an early version of snapshotting/materialization. It might help to first rewrite this to make use of our current best way to materialize an object before emitting a runtime call.. Not your doing, but I hate it when terms related to internal implementation details of Prepack leak out via error messages. Moreover, the text of this message is very obscure and may mislead a programmer who has to make sense of it. \nEven worse than that, the wiki page for this error gives an outdated example. Prepack already snapshots and does the right thing for the example. I'm none too sure if there are other cases. If there are none, the whole concept of final objects should be deleted. Otherwise, the wiki page should be updated with examples that cover ALL of the other cases.\nIs there an issue for this?. As I've said before, we should not use the same error code for different error messages. At best we can parameterize a single message. Given that, this abstraction is a trap and should be removed.. Materialization is an internal concept and should not leak into error messages. The message is also very obscure. If you can't explain why this is not allowed in clear terms along with a wiki page that has a clarifying example, you are not quite done thinking about this problem.. This error is totally unrelated to the previous call to instantRenderBailout and a perfect example of the trap that I want to remove.. What does this mean? Give an example in a wiki page.. What is an impure array operator? Give a motivating example in a wiki page.. Why is this no longer a fatal error? Is it likely that the code generated in this case will do the right thing? If so, I want to see a regression test that does the right thing in this case.. Helper function letting Prepack developers inspect a value using a debugger.. delete this line.. I would prefer this to be \"EMPTY_STATEMENT\".. Rather do something like \"if (global.__debugValue) { __debugValue(ob); }\". Make this test so that it can fail. For example, assert that \"debugger\" is present in the output.. See line 136 in /ResidualOperationSerializer.js. Why is this an invariant? I.e. do you believe that Prepack's code is incorrect if callback is something else? If so, why? . You never use ca1 and ca2, so why pass them in?. This sounds like a user facing error message, so putting it in an invariant is wildly wrong.. I'd actually prefer it if this entire PR is reverted. I think membership of CreatedAbstracts is too coarse a measure to be useful in a truly effective heuristic for inlining vs outlining decisions. We should spend some more time discussing and designing this feature before making invasive code changes. I don't know if this PR is performance neutral or not, but the heap usage doubled in the period when it went in. It seems worthwhile to revert it, if only to establish that it is not the cause of the regression.. Rather call this \"namesToInvalidate\".. The invariant is still needed to satisfy Flow.. I think you could make this more general by treating two sets of path conditions equivalent if set a implies all of the conditions in set b and vice versa. I.e. a <=> b is as good as a = b.. ",
    "nandor": "I've updated the code.. 2^53 - 1. 2^53. Yes. Maybe type OrdinaryGetOwnProperty as Descriptor | void instead?. Good question.. ",
    "ghost": "I fixed as many lint + flow errors as I could, but there's one error I can't fix, it says recursion limit exceeded . @hermanventer  suggested I ask @NTillmann about how to fix it.. Another OOM from the new cluster method. I believe it's because these tests are particularly long compared to normal tests that it causes this problem. Any suggestions on how to tackle the memory issue?. It seems that max_old_space_size is a limit on how high memory can be for a single process, and according to v8's documentation, on 64-bit machines it can't ever be higher than ~1.7 GB. This is also per-process, and there doesn't seem to be a way to tell it to control the whole cluster. I could make this argument ~200 MB, so that each process on its own doesn't use more than 200 MB. With 16 processes, that equates to 3.2 GB. Also, max_old_space_size does not count all types of memory (It mentioned it doesn't track memory used to hold large files or something like that). I'll give it a try locally with a really low number to see if it has any effect.. Now it has enough memory, but timing out. We'll need to either raise the timeout or make the test faster. The issue was fixed a few commits ago, I changed to the built-in versions of decodeURI/encodeURI. To reduce the load, I'll follow @hermanventer 's suggestion to filter based on the string \"complex tests\" in the description of these long-running tests. I'll also scope it to just \"codeURI\" so that it doesn't filter complex tests from other modules.. Here are some benchmarks I made against the master for comparison:\nBase:\n2881 Passed es5: 22001/22025 99%  Passed es6: 7596/7792 97%\n    real    6m7.003s\n    user    6m7.720s\n    sys     0m3.848s\nMy Diff:\n```\n    === RESULTS ===\n    Total run: 32176\n    Total skipped: 7314\n    ES6 run: 8806\n    ES6 skipped: 5586\n    Total passes: 30399\n    Total failures: 1777\n    ES6 passes: 8045\n    ES6 failures: 761\nreal    2m1.802s\nuser    14m9.901s\nsys     0m11.366s\n\n```\nSome things to keep in mind: Total passes here means ES5 + ES6 passes\nES6 passes means specifically ES6 passes.\n\"Total run\" is the sum of total passed + total failed\n\"Total skipped\" means all the tests that were not run to completion and reported in the results.\nI can't figure out why the total number of tests run is higher (by about 329 tests), unless there was a timing issue between pulls from master onto local in one run, and then the next.\nIs there a filter I forgot to add? Perhaps someone will notice if a test they wrote earlier has started failing.\nAlso, I am open to suggestions on the best way to output the results (I could also just use the current format if that would be best, I was experimenting to see what would be the most informative)\n. Ok added a \"cpuScale\" option to the test runner. Default is \"1\" for \"1 for every logical CPU on my machine\". 2 means twice as many processes as cpu's, 0.5 means half, etc.\nAlso, this test runner finds an error in one of the tests:\nprepack/test/test262/test/built-ins/Object/assign/Override.js\nThere is a yaml parse exception on this file. Maybe someone should take a look at it. The test runner OOM'ed, but each process was only using ~100 MB of memory (they have a link to the memory usage by process). Maybe the total amount of processes could be decreased with cpuScale to be 0.5 on CircleCI to keep memory usage low?. Before this is submitted, could you also remove the if (args.filterString) on line 335? I was going to do that in a separate diff but since it's so small might as well add it into here.. I misread the docs. Using fetch would be something more for consuming the modules prepared after prepacked. Please pardon the noise.. https://github.com/facebook/prepack/commit/43ae646. help me. Getting started.pdf\n. ",
    "idf": "Test case:\n\n. ",
    "nbenton": "Re. not fixing anything, Nikolai gave the following as desired output, which we now get:\n\nlet a = [1,2,3]\nundefined\na.join = undefined\nundefined\na.toString()\n'[object Array]'\n.exit\n\nBut obviously, if I've broken tests that used to pass, that's bad.. So I think this version passes all the 262 toString tests and does the right thing when join = undefined. I've added a test joinuncallable.js under tests/ - can't check it in in the right place under test262 because that's a submodule, but it seems to get run correctly when you put it there and run the tests.. Noticed I'd left that in just after pushing, will remove. ",
    "siegebell": "I keep getting a 404 when I try to look at the results of the CircleCI tests. Is there another way to see them?. Nevermind -- I need to log in and grant CircleCi access to my account. 404 is an unhelpful error message.... @NTillmann is it protocol for a reviewer or me to click \"Merge pull request\"?. ",
    "kathryngray": "I've commented out all of the portions of test262-runner.js that seemed to me directly applicable to pattern destructuring; this included the destructuring-binding filter, and all of the mentions of pattern as possible filter-removed errors. Is there more I should be commenting out? \nAlso I could use advice on determining where binding initialization should be inserted with regards to function calls; the spec is a bit vague and it was difficult to identify from navigating the source files. . I've fixed many places where I wasn't following the spec (notably, I'd missed that BoundNames was defined in the spec and defined it and added appropriate calls).  As of the last push, there are two more running tests for destructuring/binding and two more tests pass. There are still problems between keyedBindingInit (which needs to not just operate on strings and identifiers) and BindingInit that likely have to do with Babel and the spec not having the same AST nodes. \nAs I've graduated from BootCamp and am now in my team and needing to focus on team tasks, I don't know if I can dedicate much more time to this task. I'm quite happy to discuss what I've done in more detail.. ",
    "jackmafb": "Need to fix lint issue + test bugs. otherwise, if there are other high level pointers, please comment. thank you. I've thought about not executing again. But, Serialiser.js has a bunch of internal state variables so I re-execute to return to a clean slate state before serialization. Perhaps you can point to me which state variables need to be reset?   if I understand correctly, execute generates some kind of reference-object graph, and serialise produces some kind of expression tree.. I inspected all places where this.refs.gets are called. Besides serialiseValue(), they happen in _serialiseValueArray, _serialiseValueObject, and _spliceFuntions. We can ignore _spliceFunctions because the code always returns the id.\nFor _serialiseValueArray and _serialiseValueObject, they pretty much could break this.refs.get wise if we miscalculate the number of references per val, because we ONLY remove stuff from this.refs in the 2nd run of serialiseValue call for referenceNum == 1 per val based on what the 1st run informed us regarding the number of references for a value. \nPerhaps you can give me an example of circular/maybe recursive referencing object or array sample that you think might break so I can use it as a starting point if you think are edgy?. without this line. We fail the let binding test. The test below failed. Does this make sense to you?  \ntest/serialiser/basic/LetGlobal.js\nTypeError: Property left of AssignmentExpression expected node to be of a type [\"LVal\"] but instead got \"NumericLiteral\"\n    at Object.validate (/Users/jackma/prepack/prepack/node_modules/babel-types/lib/definitions/index.js:109:13)\n    at Object.validate (/Users/jackma/prepack/prepack/node_modules/babel-types/lib/index.js:505:9)\n    at NodePath._replaceWith (/Users/jackma/prepack/prepack/node_modules/babel-traverse/lib/path/replacement.js:176:7)\n    at NodePath.replaceWith (/Users/jackma/prepack/prepack/node_modules/babel-traverse/lib/path/replacement.js:160:8)\n    at Object.AssignmentExpressionUpdateExpression (/Users/jackma/prepack/prepack/lib/serialiser.js:126:20)\n    at NodePath._call (/Users/jackma/prepack/prepack/node_modules/babel-traverse/lib/path/context.js:76:18)\n    at NodePath.call (/Users/jackma/prepack/prepack/node_modules/babel-traverse/lib/path/context.js:48:17)\n    at NodePath.visit (/Users/jackma/prepack/prepack/node_modules/babel-traverse/lib/path/context.js:105:12)\n    at TraversalContext.visitQueue (/Users/jackma/prepack/prepack/node_modules/babel-traverse/lib/context.js:150:16)\n    at TraversalContext.visitSingle (/Users/jackma/prepack/prepack/node_modules/babel-traverse/lib/context.js:108:19)\n    at TraversalContext.visit (/Users/jackma/prepack/prepack/node_modules/babel-traverse/lib/context.js:192:19)\n    at Function.traverse.node (/Users/jackma/prepack/prepack/node_modules/babel-traverse/lib/index.js:114:17)\noriginal code\nlet x = 0;\nvar y = 1;\nfunction f() {\n  let w = { x : 5 };\n  var z = { z: 6 };\n  x += 1;\n  y += 1;\n  let foo = function() { w.x += z.z + 1; }\n  foo();\n  return x + w.x + y;\n}\ninspect = f;\noutput of inspect() on original code\n15\noutput of inspect() on last generated code iteration\nundefined. I also expect that we can just return result. However, flow throws static check error. Having some sort of check like invariant(result!==undefined) fixes this. Notice the code also has \nif (!referenceOnly && this.shouldInline(val)) {\n      let res = this._serialiseValue(\"\", val, reasons);\n      invariant(res !== undefined);\n      return res;\n    }. if isValSingRef, the \"id\" is defined but simply not returned (instead we return a serialised value). I am not seeing why we need to remove stuff from this.refs.....\nBtw, for the functionValue. It doesn't really matter. My code logic (and same for the original) always returns id for functionValue because _serialiseValue returns undefined for functionValue which means the code returns id instead.. I can move it back. It's moved because of editing. It doesn't change behavior. Sorry for the confusion.. you mean simply use Value object reference?    I don't think there's an equality (like in Java's Object.equal() method) concept in comparing object in javascript.. ok. it was meant for clarity so folks know what these states are for though.... prelude: Array<BabelNodeStatement>;\n  derivedIds: Set<BabelNodeIdentifier>;\n  memoisedRefs: Map<string, BabelNodeIdentifier | BabelNodeMemberExpression>;\n  uidCounter: number;\nAbove are the only states in prelude. execute() method only touches derivedIds. In other words, after execute(), uidCounter, prelude, and memoisedRefs are guaranteed to be the same as the initial values. These 3 values are touched by serialise(). Therefore, I simply reset preludeGenerator's dirty 3 values touched by first serialise() before I run second serialise().  Does the above make sense?  As such, I don't see the need in saving and restoring states.. Sure. This was put here more for correctness. Since we run serialise twice, this variable needs to be correct only once as we don't really use it any more in the second run, but the second run will still populate this variable and basically we will get double ref count for every valId. I will introduce a flag called serializationCount for use in seraliseValue to know when not to increment refcount. Maybe that improves readability and helps understand.. by \"interpreter runs code\", do you mean the execute() method also mutates those fields?\nfor safety, I will save and restore then.. ",
    "romain-intel": "Replacing with another pull request.. I was out last week due to a family emergency. I am doing it now. Sorry for the delay. I'll upload an updated version shortly.. I moved to another team. Sorry I left this one hanging. Would you like me to rebase it?. OK, I had understood you only wanted UTC set dates. I'll fix this and push an update.Thx.. Do you mean the check for whether the string is concrete? Not quite sure what you mean :(. Also, for the spelling check, you mean to add a test that would fail if strictlyMonotonicDateNow is now true (i.e.: it was misspelled)?. ",
    "TheSavior": "\ud83d\udc4d . CI is failing because there is no config file on this branch. It doesn't need to run though since there are no tests. . Heh, I saw this last night. I think I actually fixed this in my last change: https://github.com/facebook/prepack/blob/gh-pages/index-secret.html#L13. Ah, good catch! I missed one then. :P. Should this page be considered the \"getting started\" page?\nAlso, GitHub on my phone isn't letting me do inline comments. Will the .code::before selector conflict with the ones that exist right now that say input and output on the index page?\nA screenshot would be valuable :+1:. Can you add a link to the button group in the hero to this page as well? So it has both the getting started and try it out links there.. Also, .code seems too close to the code tag (which would conflict) for my taste. I'd prefer if it was something else but I wouldn't gate this change on that.. Should be resolved now. Thanks for reporting!. Closing in favor of https://github.com/facebook/prepack/pull/575\nThanks for taking the first stab at this @solodynamo!. Adding a screenshot of this diff:\n\n. Updated the colors and width so it now looks like this:\n\n. Thanks for contributing @JoelMarcey !. Thanks for contributing @ludovicgueth!. This makes window.prepack be the serialiser module.. This change surprised me. I haven't seen nativeStack before but that was the only thing defined on the object. \n\nA search of MDN didn't seem to bring anything up which is even weirder. Have you guys seen this?. Good catch. Fixed here: https://github.com/facebook/prepack/pull/484. Typo at the end of this line. Perhaps \"Your code was all dead code and thus eliminated\" might be more clear wording?\nOr perhaps \"Your code had no effect and thus was dead code eliminated\". Is this change necessary?. Got it. This should be done with css to make all examples on the site the same. We should handle that separately from this PR. Can you undo these blank lines?. Unfortunately, the fixed height is no good for the examples on the front page. Since that is the rule that makes this PR work, it probably isn't the right approach. Hmm :-/. I moved the pseudo selector up so \"input\" and \"output\" would be visible even when the code was scrolled horizontally.. ",
    "jra3": "I feel silly asking if I added the test case correctly... There didn't seem to be any portion of code enforcing any assertions. I take it that these tests just look to see if any output changes rev to rev?. I'm not sure that will do it. When I coerce it to a string, it drops the named property. Is there some other method of serializing I should use? json?\n```> a = [0,1,2]\n[ 0, 1, 2 ]\n\na.foo = 42\n42\na\n[ 0, 1, 2, foo: 42 ]\na + \"\"\n'0,1,2'\n```. I think this is correct now.. \n",
    "jdalton": "I've noticed this may still throw errors when attempting to load built-in modules like \"zlib\".. @sebmarkbage Cool, thanks!. I have a webpack bundle that has its target: \"node\". The bundle includes references to the real, not mocked, module, process, and require (to load fs or path). When I run prepack it errors out with:\nbash\nmodule is not defined\nReferenceError\nThe output.libraryTarget is 'commonjs2' which means it's exporting to module.exports = ..... IE8 is as dead as...\n\n. Related to #451.. ",
    "sahands": "@NTillmann The latest commit should address all your suggestions. Please take another look. Thanks!. ",
    "dkrew0213": "@NTillmann \nI am modifying the code to check the \"VariableDeclaration\" statement to determine whether we need the function wrapper or not and testing it now but hitting some issues. \nIt looks like unit test itself goes through multiple iteration of the serialization and feeds its output into the serializer again and again. (Looks like about 4 times and checks the actual value and the expected value.)\nI have noticed that with our approach on the \"VariableDeclaration\" statement check is breaking many unit tests. \nWhile looking at the values.js unit test in detail, I have notice that we will bypass wrapper function in the second iteration of the serialization. The actual output looks like this and with this iteration the expected value and the actual value matches.\nfunction _1() {\n  return 1 + arguments[0];\n}\nfunction _2() {\n  return 0 + arguments[0];\n}\nfunction _0() {\n  return _1(42) - _2(42);\n}\ninspect = _0;\nFunctionDeclaration \nFunctionDeclaration \nFunctionDeclaration \nExpressionStatement\nHowever after feeding this into the serializer again it gets interpreted as following.\n(function () {\n  function _0() {\n    return 1 + arguments[0];\n  }\nvar _1 = _0;\nfunction _1() {\n    return 0 + arguments[0];\n  }\nvar _2 = _1;\nfunction _2() {\n    return _1(42) - _2(42);\n  }\nvar _0 = _2;\n  inspect = _2;\n}).call(this);\nFunctionDeclaration\nVariableDeclaration\nFunctionDeclaration\nVariableDeclaration\nFunctionDeclaration\nVariableDeclaration\nExpressionStatement\nAs having the variableDeclaration, it gets wrapped into function and generates the following code which output comes out as NaN. \nSo the serialization which does not have any VariableDeclaration in the middle is interfering with the unit test. Should we revisit the detection logic? And figure out a logic via ExpressionStatements?\n. Yes it looks like functionDeclaration and variable declaration should be the driving trigger for the wrapper. I will made changes according to this.. I have removed the exist boolean.. Modified the code to call into the shoudBeWrapper recursively additionally noticed that we are using \"BlockingStatement\" instead of \"BlockStatement\". I will fix that.. It seems like  \"test/serializer/abstract/BranchingConsoleLog.js\" is the only unit test which generates the \"IfStatement\". \nAnd while we looking at the structure of the \"\"IfStatement\" it looks something like this.\nIfStatement -> alternate -> BlockStatement\nIfStatement -> consequent -> BlockStatement\nI looks like we could detect the \"IfStatement\" and run the same function and call it recursively. I will make the change accordingly.\n. ",
    "Wandalen": "As I reported in #823 , second pass for the same file throws \"serializer failed\" error. . Is not that bug? For me strange that second execution causes problems.\nIf prepack map program from language A to language A, it also should be able to take its output as input. Am I wrong? \n. I see. Thanks for explanation. . ",
    "InTheCloudDan": "Where can I see a list of all the long running tests? I don't mind doing some grunt work if it's just excluding them in circleci for now then figure out a better way to handle it.. Does anyone have a suggestion on how they would like this implemented? Pass it in as --pipe, or default the output to not have the surrounding text:\nconsole.log(\"+++++++++++++++++ Prepacked source code\");\n      console.log(code);\n      console.log(\"=================\");\n. @cblappert or @NTillmann any suggestion on how you would like it to be approached? I just don't want to submit something that's way off base.. @cblappert I just wanted to get it out of stdout.\nI've gone ahead and changed to warning. I'm still trying to wrap my head around what all of the pieces are so wasn't sure what it was supposed to be and I saw a lot more use of console.error overall so wasn't sure if that was just default.. @hermanventer can you tell me which tests are passing? I'm trying with rebased to latest master and timeout of 115 and here's my output:\n```\n\u279c  prepack git:(skipTests) \u2717 npm run test-test262 -- --timeout 115\n\nprepack@0.2.3-alpha.0 test-test262 /Users/danielobrien/Projects/prepack\nbabel-node scripts/test262-runner.js \"--timeout\" \"115\"\n\nMaster starting up, forking 8 workers\nRunning... 10%\nRunning... 20%\nRunning... 30%\nRunning... 40%\nRunning... 50%\nRunning... 60%\nRunning... 70%\nRunning... 80%\nRunning... 90%\n=== RESULTS ===\nPasses: 22683 / 22879 (99%)\nES6 passes: 7406 / 7690 (96%)\nSkipped: 6615\nTimeouts: 0\n```\nAlso I'm not sure what you mean by it should be an error? So actually fail the circleci builds?\nFor all tests to run I could also check to make sure the an environment variable NIGHTLY_BUILD isn't present then you could configure a once a day cron job passing in that variable. Some additional reference for using an environmental variable: https://circleci.com/docs/1.0/nightly-builds/. in its current form it should not be skipping any tests in CircleCI since I didn't check for that environment variable. I'll add that in and push the commit momentarily.\n*Edit - nevermind I get it, it is currently skipping them all for everything. Wasn't thinking it through properly\n*Edit2 - I'm rerunning on my local machine with same CpuScale value to see if I can get the timeouts that way.. Tried again on my local machine with same CpuScale and still not getting those timeouts:\n```\n\u279c  prepack git:(skipTests) \u2717 npm run test-test262 -- --timeout 115 --cpuScale 0.25\n\nprepack@0.2.3-alpha.0 test-test262 /Users/danielobrien/Projects/prepack\nbabel-node scripts/test262-runner.js \"--timeout\" \"115\" \"--cpuScale\" \"0.25\"\n\nMaster starting up, forking 2 workers\nRunning... 0%\nRunning... 10%\nRunning... 20%\nRunning... 30%\nRunning... 40%\nRunning... 50%\nRunning... 60%\nRunning... 70%\nRunning... 80%\nRunning... 90%\n=== RESULTS ===\nPasses: 22697 / 22893 (99%)\nES6 passes: 7406 / 7690 (96%)\nSkipped: 6615\nTimeouts: 0\n```\nAny thoughts on what I'm missing?. 1. So we want to exclude the test, so there's no failures then set https://github.com/facebook/prepack/blob/57cc59c07d164e4827c24637af9c1002b0c4a3c8/scripts/test262-runner.js#L620 to\nnumTimeouts > 0 ?\n\nSounds good I can take care of that.\n\nI haven't made any manual changes to test262, I did the git clone of the repo and ran:\ngit submodule init\ngit submodule update --recursive --remote\nSo I don't know why there'd be a difference? This is my first time trying to tackle issues like this so I may have done something wrong, but if so I don't know where.. ok I have another PR open for README I can add this in,\nSo step 1 is still:\ngit submodule init\nThen do:\ngit submodule update --init\nIf that's right I can get this commited with that one.. I'm not sure how to interpret the test. Seems like a whole lot of timeouts, is there a way to force it to retry?. Ok so we don't want to do an environment variable for the nightly build? Just confirming because the env var seems preferred method. I can easily change it to something like \nif !nightly_build. ",
    "dulinriley": "I just added the PR for sharing an ArrayBuffer among TypedArrays, I'll add in the DataView one soon as well.. @sebmarkbage Let me know if there's anything you else you need from ArrayBuffer/TypedArray to get node.js working. You should be able to set tracking up:\n$ git checkout BRANCH_NAME\n$ git push --set-upstream remote/BRANCH_NAME\n$ # After executing that you should be able to do future pushes to your branch by\n$ git push # now sends to remote/BRANCH_NAME, not master\nKeeping up to date with master is just:\n$ git pull origin master # git pull == git fetch && git merge\nActually git pull origin master should work without tracking anyway, but with upstream tracking you don't need to specify git push origin BRANCH_NAME every time you want to push.\n. It was an unused dependency, re-ran locally and the serializer tests (and test262) passes.. He told me to accept this.. ",
    "yinghuitan": "This optimization will require computing a fixed point in the ResidualHeapVisitor.\nConsider the following:\n(function() {\n    function f() {\n        let obj = {\n           g1: function() {},\n           g2: function() {} };\n        return function() { return obj.g2; }\n    }\n    global_g2 = f();\n})();\n. Be careful: Different declarative bindings might point to the same value.\n(function() {\n    function f(obj) {\n        return function() { return obj.g2; }\n    }\n    let obj = {\n       g1: function() {},\n       g2: function() {} };\n    global_g2_1 = f(obj);\n    global_g2_2 = f(obj);\n})();\n. Note that we need to traverse all residual functions to discover if we can apply this transformation at all:\n```\n(function() {\n  function f(obj) { return obj.p; }\n  function g(obj) { Object.assign(obj, { p: 42 }); }\n  let obj = { p: 23 };\n  global.f = f;\n  global.g = g;\n})();. @hermanventer, I am trying prepack against the following test:\n(function() {\n  let x = global.__abstract ? __abstract(\"boolean\", \"true\") : true;\n  let s = new WeakSet();\n  if (x) {\n   s.add(s);\n  } else {\n  }\n  inspect = function() { return s.has(s); }\n})();\nPrepack fails at here:\nhttps://github.com/facebook/prepack/blob/4824b47038131efcfd3e5f3928e2d2833a2aac23/src/intrinsics/ecma262/WeakSetPrototype.js#L56\nCan you help me to understand what is the purpose of \"ThrowIfInternalSlotNotWritable()\" checking here? It is checking if the $WeakSetData internal field is a new created object during forked branch execution. I am not sure why this checking is necessary. For example, if I commented out this check, prepack just succeeds.\n. @hermanventer, thanks. \nMy understanding is that, I need to:\n1. Add $WeakSetData to the \"trackedProperties\" array.\n2. Make $WeakSetData to use ArrayValue reflection type so that any changes to it got tracked.\n3. Modify any code that uses $WeakSetData as raw array to instead use the abstract operations operating on it.\n4. Remove ThrowIfInternalSlotNotWritable().\n5. Do similar steps for other fields, $SetData, $MapData, $WeakSetData and $WeakMapData.\n. @wdhorton, are you still working on it? If not, I would like to take over. Thanks.. Actually, Prettier is already integrated into Nuclide. You will need to add \"@format\" at the top of the file header to opt-in the auto-formatting and linter UI.. @NTillmann, if we want to enable Prettier for all prepack codebase, we can just use ESLint plugin: https://github.com/prettier/prettier#eslint\nTo surface ESLint warnings in Nuclide diagnostics UI, we need to manually install linter-eslint Atom package:\nhttps://github.com/AtomLinter/linter-eslint\nWe can use \"cmd-shift-C\" to format code in editor, see the format warning in Nuclide UI, and select the \"auto-fix\" tooltip button to fix the format issue. \n@cblappert, do you want me to take over this?. #792. You are right. We are correctly here in behavior:\n1. In strict mode, we are passing the unboxed primitive value. \n2. In non-strict mode, we are passing the boxed value wrapping the primitive.\n3. However, if the target function is NativeFunctionValue(like toString()), we are skipping the boxing even under non-strict mode, and pass non-box primitive value.\n. #467 . @NTillmann, sounds good. How about call this shared base class OrdinaryFunctionObject? Per the spec, bound function object is an exotic function object which is different from ordinary function object. \nMy only concern is that, adding this OrdinaryFunctionObject will cause the cycle length to increase to 58 which we wanted to avoid. Any idea how to workaround the cycle length increase issue?\n. @NTillmann, @hermanventer, here is my opinion:\nThere are two benefits of introducing a shared OrdinaryFunctionValue class:\n1. Move $ConstructorKind field out of FunctionValue into OrdinaryFunctionValue.\n2. Make some of the code paths(mostly evaluation code paths) that only apply to ECMAScriptFunctionValue and NativeFunctionValue to use more restricted type OrdinaryFunctionValue.\nAnd one downside: potential increase the cycle length.\n2 above seems to justify the adding new class.. After doing some investigation, I found:\n\nWe already did correct thing for object properties so we just need to improve for array.\nOnce we moved array index property assignment to initialization list, we do not need to move length assignment to the beginning. Because the array constructor should already have enough information(from initialization list) to predicate the storage capacity.. Take this one to get more familiar with residual function serialization.. This issue has been fixed.. @NTillmann, awesome result~! It's amazing that such a small change improved so much.\nBtw: how do you measure the bytecode size? Manually or ct-scan run?. Doing this will increase the code size. Maybe we should leave the inline optimization to the JS compiler?. For reference, the reason superLongName won't be optimized away by minifier/compiler is because it is part of object property which is preserved for reflection purpose.. If we want to keep the delay initialization but still without duplication, one option would be generate a helper function for the delay initialization stub, like the following or similar:\n\n```js\n(function () {\n  var __scope_0 = Array(1);\nvar __get_scope_variable = function(selector) {\n    var __captured = __scope_0[selector];\n    if (!__captured) {\n      if (selector === 0) {\n        __scope_0[selector] = {\n          x: 13\n        };\n      }\n      ...\n      __captured = __scope_0[selector];\n    }\n    return __captured;\n  }\nvar _1 = function () {\n    var __scope_1 = 0;\n    var __captured__scope_1 = __get_scope_variable(__scope_0, __scope_1);\n    return __captured__scope_1.x += 3;\n  };\nvar _2 = function () {\n    var __scope_1 = 0;\n    var __captured__scope_1 = __get_scope_variable(__scope_0, __scope_1);\n    return __captured__scope_1.x -= 2;\n  };\nvar _0 = function () {\n    return _1() + _2();\n  };\ninspect = _0;\n})();\n```. @hermanventer, @NTillmann, I originally did not upgrade to 0.55 flow because I got dozens of flow errors for latest flow. But all the errors I saw are gone today; I think I may get a dirty environment last week. Will use 0.55 flow.. Abandon per Herman's request.. Currently, each option takes three lines in visual space. Can you put all the checkboxes, input field and dropdown list to the same line as the option name? Then two lines will be enough. . #885\n. Abandon for now, may revisit it when we needed.. Will follow-up these review comments in #1069.. @cblappert, there are several benefits of sharing the single __get_scope_binding function:\n1. Not creating more extra function objects(which is expensive per @NTillmann)\n2. If the nested functions modify free variables in global scope, these global scope free variables' initial values will generate one copy in single __get_scope_binding(but will be duplicated multiple times in each __get_scope_binding() in your design).\n. I think I understand what @NTillmann is talking about. Will create a testcase for that scenario.. These two testcases will fail if I remove the cloneDeep() call, but succeeds with it. One covers the single function instance scenario, the other covers the shared function instances scenario.. Btw: in our team meeting, @NTillmann recommended a guideline that every PR should have a \"Release Note:\" field now. See #1068. Furthermore, it seems that AdapterChannel is used by UI, while DebugChannel is used by Prepack to communicate each other. Why do not make the channel symmetric? I mean design a single channel that can be used from both sides. I know Prepack and UI both have some customized/special action to perform, but we should be able to abstract out the common channel part to be symmetric and sharing the same read/write logic.. @trueadm, I am fine with doing it in later PR.. The graph UI looks good, but it looks quite confusing without identifier for each node. I suggest you only land this after identifier is added.. Can we add an option to disable the graph? In case if some user hates it.... Great, some suggestions:\n1. Can we put the legend at the bottom? \n2. Also, make the legend one row instead of three?. For \"lazy initialization\" concern, I do not think it will be an issue if we have a generator entry that can serialize the leaked bindings. Because visitor's scope analysis will report this binding being referenced both from residual function(callThis()) and global code(the leaked binding generator entry), it won't be delay initialized.. Just to confirm: the new UI is not displayed by default right? What is the UI action to trigger the display?. For \"TODO: add a legend to the UI describing what the different shapes and colors mean\", you added it in this diff.. @sebmarkbage, I found the sample code failed on latest master, even though it succeeds on the REPL website. Do you get the same result? \nAlso, are you able to narrow down the reproduce code even further if possible? The output is too much to read/reason about.. For heap graph feature, it needs its own test runner to check the graph output matches expected so I won't include it in this PR. I will file a task for it.. @trueadm, only react tests failed for this. Is there any wiki talking about how to best debug single react test failure? I can try investigate the react test runner, but it would be time saving if there is a documentation for it.. Ok, I will try remove it in later PR if I have time.. @artiebits, @NTillmann, the dot language graph supports duplicate edges between two nodes. It is just the visualization @JWZ2018 did generated same id for the edges which caused vis.js to break. \nI will fix it.. No, currently, if there is a bug in the visualization(Vis.js bug or graph data format not valid), it won't break down the whole website. It's just the \"Show Heap\" button shows no content(not sure if this can be improved with some error message). The serialized code will still show.(At least this is true for this bug).. Sorry for the late response, but I do not think this is correct. \nThe purpose of this function is to check if a body is generator body or not, while additionalFunction body clearly is not a generator body. . @trueadm, yeah, heap visualization is not compatible with additional function or react compiler. I have a not landed diff to detect this and disable visualization. I think we should disable visualization if additional function/react compiler is enabled.. @NTillmann, can you paste out the lazy prepacked code for this testcase in test plan section of summary? Then I can better understand the goal of the change.. @hermanventer. There seems to be a bug in prepack interpreter here. What I observed is that, the \"context\" object passed into \"toString\" method is actually the unboxed primitive value instead of the boxed ObjectValue in prepack. While I observed the node JS behavior, the boxed context is passed in(as you said). \nI will file an issue for this bug(passing unboxed context into toString()).. Assuming the bug is fixed, the boxed context is passed into \"toString()\" function. I am not sure I understand \"unbox the boxed boolean will work even for abstract Boolean values\".\nMy understanding is that, I still need to perform realm.createAbstract(new TypesDomain(StringValue)) logic for it. Because if I pass the context to the else branch, thisBooleanValue() will throw because it expects $BooleanData to be concrete.. Will do.. Makes sense. I will add \"sym.throwIfNotConcreteSymbol()\" before the invariant call.. What is the meaning of hasDefaultLength() function? Maybe we do not need to override it in NativeFunctionValue class?. BoundFunctionValue always uses its internal wrapped $BoundTargetFunction(which eventually is NativeFunction/ECMAScriptFuntionValue) to call/evaluate its body. So when OrdinaryCallEvaluateBody() is called, the F field can never be BoundFunctionValue.. Since the parent class FunctionValue defines hasDefaultLength() as abstract method(throws exception), I will just remove hasDefaultLength() from NativeFunctionValue. Anyone calls hasDefaultLength() on NativeFunctionValue will just throw by default.. Flow reported the new added file ECMAScriptFunctionValue.js as new cycle. Considering both BoundFunctionValue and NativeFunctionValue are also in the list, I thought it is expected ECMAScriptFunctionValue.js identified as new cycle? Do you mind share some alternative choices/solutions to avoid the increase of cycle? . Sure, I can do this.. Makes sense.. That is my initial thought too. Unfortunately, I found NativeFunctionValue actually use it here:\nhttps://github.com/facebook/prepack/blob/4824b47038131efcfd3e5f3928e2d2833a2aac23/src/values/NativeFunctionValue.js#L51\nAnd this NativeFunctionValue.$ConstructorKind is later used in InternalConstruct() in function.js.\nSo we can't move it down to ECMAScriptFunctionValue. . Fyi, even using the OrdinaryFunctionValue as the signature, we still have to use invariant() here. Seems like flow is not smart enough to figure out branch typing.. I think that change is out of scope of this issue. The goal of this pull request is to get toString() working on an abstract value. I will file another issue for your suggestion.\nBtw: even we implemented in serializer, it won't work E2E; because the following code will fail in ToNumber() call in to.js.\nlet x = global.__abstract ? __abstract(\"number\", 42) : 42;\nlet y = Number(x);. Created #838. I will address this in that issue.. @NTillmann, I may not agree with this. Moving $FunctionKind to OrdinaryFunctionValue will force it to become optional by adding \"void\". I do not think this is helpful for flow. I would rather force any places accessing $FunctionKind field to explicitly check for ECMAScriptFunctionValue. This avoids bugs like accidentally use $FunctionKind in NativeFunctionValue code paths.. I think you also need to mark \"$Description\" as \"string | AbstractValue\".. I would change to:\ndescString = description;\nso that you can leverage the single \"return new SymbolValue()\" below.. Thanks. This is a bit tricky: if I use \"delete a[2]\" it won't leave hole in the middle of array, while if I used \"var a = [1, 2,,,5]\" it will. My new commit handles it.. Maybe call this variable \"funcExpression\" instead of \"funcDeclaration\"?. This should be \"t.functionExpression\" as well?. Per our discussion offline, this should check both the global realm.isStrict and current FunctionValue's isStrict.. Maybe add a comment explaining the meaning of this option.. With this change, the serializer will emit much verbose code below:\n```\nvar x;\n(function () {\n  var _1 = this;\nvar _$0 = Object.defineProperty;\n  var _0 = _1;\n_$0(_0, \"x\", {\n    enumerable: true,\n    configurable: false,\n    writable: true,\n    value: 1\n  });\n_$0(_0, \"x\", {\n    enumerable: true,\n    configurable: false,\n    writable: true,\n    value: 2\n  });\n_$0(_0, \"x\", {\n    enumerable: true,\n    configurable: false,\n    writable: true,\n    value: void 0\n  });\n}).call(this);\n```\nThis is because the new logic will change the normal global assignment to use generator.emitDefineProperty() instead of generator.emitGlobalDeclaration(). \nI think we need some kind of logic to distinguish between global binding vs assignment and use generator.emitGlobalDeclaration() vs generator.emitGlobalAssignment() correspondingly.. I think you want to remove \"!== undefined\" since you are checking \"globalReg === undefined\" below. Otherwise, you should use globalReg as boolean.. Seems it does.. My assumption/understanding is that: the only time this._activeBodies does not contain this._body happens during delay initialization scenario, which this._body points to the body of the residual function. In this scenario, since we are emitting into residual function body, we do not need to wait depdendencies as long as it is declared.\nI can not come up a real world case that violates this assumption. Let me know if you can.. What about other non-string property access? Like, array index on simple partial object, or symbol type etc... Seems that we should still be able to support.. Isn't \"!t.isIdentifier(pname)\" always evaluated to be false?. Ah, I incorrectly looked at the code to be \"t.Identifier()\" instead of \"t.isIdentifier()\".. Makes sense. Let's add a TODO comment here for future improvement.. Should this be \"operand: AbstractValue | ConcreteValue\"? Because you are checking \"operand instanceof AbstractValue\" vs \"invariant(operand instanceof ConcreteValue);\" below.. You want to remove the duplicate copyright header. The same for the other one.. I think the testcase should have the following in comment to test out the expectation which will fail. \n// does contain:\"use strict\"\nThen you can investigate and fix it.(Culprit logic is in ResidualFunctions.js). I just realize the code itself already tests the strictness in the generated code so that testcase would fail without \"does contain\" checking. Now you just need to investigate and fix the testcase failure :-). I do not think this is necessary. This function expression is just generating a stub call to the real function body so \"use strict\" is only needed in the real function body and unnecessary here. Let me know if you can find a testcase to cause this assumption to fail.. Now I see. Since it uses \"this\" point, so it goes into this code path so the strictness needs to be preserved from sub call function to the real function body. Thanks.. kind and intrinsicName fields seems are not set in AbstractValue.createFromConditionalOp() method. Is this expected?. It took me a while to understand the purpose of this code. \nCan we add a comment explaining that implied contract for template string expects parameters \"A\", \"B\" etc...?. Add one more invariant:\njs\nlet paramList = \"A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z\";\ninvariant(originalLength * 2 - 1 > 0 && originalLength * 2 - 1 <= paramList.length);. Why not directly via the AbstractValue factory function? I thought we wanted to avoid directly creating AbstractObjectValue/AbstractValue via constructor.. Seems that \"maxStackDepth\" is never undefined? If so, you want to remove \"void\" from the typing.. The same, if this.maxStackDepth is never undefined, you do not need the first null check.. You can use just ES6 syntax: additionalFunctions,. Can we be more consistent with other code by passing \"additionalFunctionValuesAndEffects\" from ResidualHeapVisitor constructor? . Not your code, but since you are modifying around here. Change to:\njs\nfor (let moduleValue of this.modules.initializedModules.values()). This checking is unnecessary. If the map is empty, the for loop below just does nothing.. Why should the default value to be \"true\"? By default all object/properties should refuse serialization?. Can you move this block of code into a helper method called \"visitAdditionalFunctionEffects()\"? It will be at the same abstract level as visitGenerator() and more readable.. High-level, ResidualFuncitonVisitor should be a class doing pure tagging for values in generator/heap tree. It's weird to call applyEffects() here, maybe move this into functions.js in evaluation stage.. Hmm, really confusing code style in my opinion. I would suggest change to:\njs\nrefuseSerialization = false: boolean\nwhich is much more readable.. Thanks, it should be a number literal.. @hermanventer, \"yarn flow\" already ties to an old version here:\nhttps://github.com/facebook/prepack/blob/master/package.json#L81\nThis diff just matches the system flow version with what \"yarn flow\" uses.\nWhen we are ready to update, we should update both places.. add\ninvariant(value.args.length === 2). All the comments use \"yz\" may need to change to \"xy\" to align with the code.. \"(cond ? xx : yy)\" => \"(cond ? xx : xy)\" to align with code.. Can you add this as a comment into the testcase? People read this testcase will ask frequently.. I am a bit vague on this. Is it safe to do this optimization while \"y\" has some side-effect? For example:\njs\nvar y = sideEffect();\nvar result = c ? (c ? x : y) : z;. Missing a comment for \"||\". Similar to my comment below, what if \"x\" has side-effect? I do not think it is safe to optimize it away. Or maybe there is a all-arguments-non-side-effect pre-requirement checking somewhere I missed?. Missing comment for \"||\". This section is the same logic as the block starting from line325. Maybe fold into a helper function to avoid duplication?. Also, any reason, the code here only performs this one kind of refinement, while the code you added in refineWithPathCondition() does several more? . I have different engineering perspective on this:\nI understand you want the system flow to be sync with latest release which can tell us to fix flow errors and upgrade. But this time window is really annoying sometimes confusing -- you do not know if the flow errors in Nuclide is because of your feature code change(which you must fix), or just a new flow release(which you can ignore temporarily and fix later). Mentally, you can't trust flow errors in Nuclide anymore. \nI think fixing newer flow errors and upgrading flow to latest version should be an out-of-band task not conflicting with daily feature development. For example, it can be added to on-call's duty list.. Just to confirm: this PR did not add any visible changes, right? So these two testcases are not related to this PR -- they should pass even without this PR?. What does this comment mean? Can you more elaborate in the comment?. There are two modes for debugger: attach, launch. I would call this \"debuggerInstance\" instead so not to be confused with launch/attach action mode.. You may want to read this file path from config file instead of hard code it. . Prefer \"for (const command of commands)\" style.. What is \"virtual\" breakpoint set by debugger?. Please mark all these fields as private with leading underscore. I know our existing codebase did not follow this pattern well, but new code should stick to private fields as much as possible. . What is the purpose of this method? It does not seem to be used anywhere? Also, mark it with leading underscore if private.. High level, creating Debugger instance should be associated with \"enableDebugger\" flag, while \"Debugger Attached\" should be treated as a normal debugger command and processed in Debugger.js.. \"isDescChanged?: boolean\" introduces three states: not-exist, true, false. \nChange to \"isDescChanged: boolean = false\" to use two states instead.. Use \"generator.emitDefineProperty(O, P, desc, /isDescChanged/true);\" to increase readability.. There are several places in the codebase that check for \"desc.enumerable && desc.configurable && desc.writable\". Can you make into a helper function called \"hasDefaultAttributeValues()\"? Thanks.. Due to a bug in node/test-runner, this testcase incorrectly succeeds even without this change. \nTo workaround this issue, please add following directives to the top of the testcase:\n// Copies of enumerable:2\nThis will make the testcase fail before but succeeds with your change.. Can we make this \"isGlobal: boolean = false\"?\nisGlobal? introduces three states: undefined, true, false, while the \"isGlobal: boolean\" only has two states.. Will this URL automatically turn into a hyperlink while running in prepack.io/repl.html? Do we need to add \"https://\" prefix per discussion below?\nhttps://stackoverflow.com/questions/29681775/how-to-create-hyperlinks-linked-to-javascript-functions-in-chromes-console-log. Can you append \"TODO\" prefix so that we won't forget them?. Since we know the initial values of these four fields and they will be needed together anyway, I would suggest we combine them into one map:\n_funcToScopeInfo: Map<FunctionValue | null, { scopeInstanceIndex: number, CapturedScopeArray: ...};. Require change(or design discussion): instead of creating separate __get_scope_binding() function inside each additional function, I would suggest we share them. Single __get_scope_binding function should be enough.. I do not think this check is necessary. If this condition is true, the following for loops will just do nothing.. High level, currently, we have two ways to get additional functions, and we have two separate chunks of code to parse, interpret and merge them into \"calls\" array.\nI would put them into two private helper functions: _generateAdditionalFunctionCallsFromInput() and _generateAdditionalFunctionCallsFromDirective(). Both are called from checkThatFunctionsAreIndependent().\nThis will make the code self-documented and more readable. . For completeness/code coverage, please also add a testcase for \"do...while\".. Maybe just use \"does not contain: while\" for now.. Try not to use \"any\" in the typing. This disables the flow type checking. Use:\nimport fs from \"fs\";. This API design is a bit weird. I would throw exception for this and provide another API called \"isEmpty()\" to check emptiness.. Do both VSCode and Nuclide adapter expect line number starting at one instead of zero? If so, please add an explicit comment for this.. I do not think UI need to send response to the engine.. Any reason function expression is better? Personally, I like function declaration better than function expression because the code is more readable(you can easily spot if a symbol is a function or normal variable). I copied from existing code. Seems out-dated code, will fix. . Will move into realm.. Will add comment to explain the reason.. Because the code we are traverse is always wrapped into file AST via:\njs\nt.file(t.program([t.expressionStatement(funcNode)\nSo the path.parentPath.parentPath will be safe to dereference. I will add a comment though.. I think we are testing wrong direction here. We should test the nested function inside additional function that modifies free variables instead of additional function itself. For example, can you try if the following testcase pass?\njs\n(function () {\n  let top = 5;\n  function af1() {\n    let mutable = 3;\n    return function() {\n      return (++mutable) + (--top);\n    }\n  };\n  global.residual = function() {\n    return ++top;\n  };\n  global.f = af1;\n  global.__registerAdditionalFunctionToPrepack(af1);\n  inspect = function() {\n    return f()() + residual();\n  }\n})();\n. Do you mean \"additional\" function instead of \"residual\" function? Also, there are several code parts for modified bindings, can you elaborate what exact code it is trying to emit?. Can you comment the meaning of key, value of \"overriddenPreludes\" map? It seems to map from \"preludeOverride\" to some kind of \"prelude\" which makes no sense to me. There are so many words \"prelude\" here.. Yes. BabelTraversePath is missing \"parentPath\" property flow declaration which I do not think I can modify. I will add a comment.. Our goal is traversing the residual function and replace any duplicated \"nested\" function. We do not want to replace residual function itself, right? Otherwise, we may replace the root residual function with bind(null) to itself which is wrong.. Makes sense, will do.. Function can make code more readable because it defines a well documented scope which people can be comfortable look at its name without dig into its implementation.\nI do not think creating a function makes the code unclear here.. Thanks. I will move back in.. Hmm, I do not think that is a problem of this PR: all the tests using \"Copies of\" has \"inspect\" function in it. That test runner bug is a separate issue which I do not think it should hold this PR.\nNote: checking \"Copies of\" is the major purpose of this test.. Wow, good insight, thanks for catching this!\nI will use this PR only for non-factory function case, and use a part3 PR for the function declaration.. I would call it LENGTH_SEPARATOR which is the real purpose of this const. The fact we are using two dash is an implementation details which may change.. Can you comment when will readFileSync() return with empty content?. When will this happen? Isn't this a violation of protocol and should be an invariant or throw?. contents.slice() will make a memory copy. I would check \"contents.length - startIndex >= messageLength\" before \"contents.slice()\" so that we won't pay the copy cost during partial read.. Can you prefix all the private fields(inFilePath, fs, etc...) with leading underscore? . I remember, per original design, we need to send an acknowledge response to UI once successfully read a request so that UI know it is safe to send another request. Is this in future PR or we changed this design?. Prefix private fields with underscore.. Similar, LENGTH_SEPARATOR. Most of the high level logic are dealing with partial reading. Please add a big comment explaining this high level goal here.. There are many duplicate/shared logic between here and DebuggerChannel read. You may consider how to share the code(like introduce another shared class which handles the message format details) so that if we would like to change the message format, one change is needed(instead two places).. It is not the parent process, it is mock UI process itself.. Is this holding all the pending commands from UI? Did not see any code using it. Will be used in later PR? . At the top of this file, can you add comment about the source you copy this from?. Why do we have to use \"any\" here? You should be able to import fs type using:\njs\nimport type fs from \"fs\". How do users know inFilePath and outFilePath are relative paths and which directory do they relative to? This needs to be explicitly documented for these two options.. I suggest you do slice() call after length check below to avoid one slice() call during partial read.. or there is no debug message available.. unpackage() also returns null when UI did not send any debugger command. This will cause this loop using high CPU doing nothing.\nCan you distinguish between the partial read and no-command-at-all two scenarios and add a sleep(50ms) call in the second scenario?. Take out these block of arguments parsing code into its own function as self-commenting.. I would suggest you provide a single output function instead of direct call console.log() here. Because one day we may want to change the mock UI to write to a file or other output source. At that time, modify a single function is much pleasant than searching and replace all the console.log.. I do not think we should special check for breakpoint here. What you want to do here is \"processDebuggerCommand()\" here, not necessary breakpoints, there may be other commands you want to process from UI, like async break.. I do not think you need this. This function should be renamed to \"processDebuggerCommand()\" which process any debugger command form UI. It should be a big switch case which process any individual command instead of special case for breakpoint.. I see. The github collapse code confused me during review. . The github code collapsing confused me. You already call this executeCommand() which is good. But my later comment still applies: process all debugger UI commands as a big flat switch case, do not make hierachy commands here.. Please do not use \"line\" here which leaks the implementation details of we are using a file line, use command or message.. Please divide the messages into two category:\n1. DEBUGGER_COMMAND: should suffix with _COMMAND, from UI => engine\n2. DEBUGGER_RESPONSE: should suffix with _RESPONSE, from engine => UI.. You need another invariant here: invariant(contents.length <= startIndex  + messageLength)\nThis ensures there will not be more than one message in the channel.\n. You do not need two variables. Just change \"blocking\" to be \"resumeFromStop\", then:\njs\nlet resumeFromStop = false;\nwhile (!resumeFromStop) {\n  message = this.channel.readIn().toString();\n  resumeFromStop = this.processDebuggerCommand(message);\n}\n. That's one of the reason I wanted you to change here. Use the same constant for both direction is very confusing: when people see a constant, they do not know if it is a debugger command or response message.\nPlease specify only one purpose for each constant and add comment for them. . The API design is bad. Do not pass runCondition as an external callback. Just treat \"DebugMessage.PREPACK_RUN\" as a debugger command and return true for it.. I did not see the benefit of categorizing all breakpoints together. Just follow other debugger pattern here by flatting all debugger commands into one switch case here. (For example, see https://chromedevtools.github.io/devtools-protocol/tot/Debugger/)\nBasically, you can remove \"DebugMessage.BREAKPOINT\" and inline the content of executeBreakpointCommand() into this switch case.. Why do you pass \"fs\" to FileIOWrapper? Just hide \"fs\" inside FileIOWrapper.. You should throw exception for unknown command here instead of silent allow it. It broke the channel invariant and protocol. . Is it possible this(writeOut() is called while this._requestReceived is false) can happen?\nIf possible, you have to queue this message and retry later. Otherwise, you are dropping prepack response to UI~!\nIf not possible, change it to an invariant.. Is this safe to do?\nWhat if debugger UI wrote more than one commands(happens in Nuclide quite often) in the file? Currently, the code only parsed one command, then erase the whole content. This means if there are multiple commands in it, all the later commands in the files are dropped or even corrupted the file content.. Why is that? Please add a comment at least. Anyone read this code will wonder why fs can't be encapsulated inside FileIOWrapper.. There will be other commands telling Prepack to continue(like step-into, step-over, step-out etc..)\nBut still, process all these commands as a real command inside the big switch instead of using a out-of-band callback. The caller of this API should not need to decide what condition debugger should continue.. I finally found your one message invariant. You added at the end of unpackage() method, please bring it to front. The invariant validation should be as early as possible.. These two fields are public accessed right? so remove leading underscore.. What is the meaning of magic number \"1\" here? Add a comment.. Do you need to distinguish between ack a command vs real complete response of a command? For example, you may execute \"step-over\" command, you need to ack immediately, but can't finish the command until engine really stops. \n. this.channel.writeOut() contains the details of the format of the message which may change. Please take out and hide all the \"this.channel.writeOut\" calls behind one helper function. Then one day we want to change the format, only one place needs to be changed instead of every switch case.. Prefer:\njs\nfor (const breakpoint of args.breakpoints). I still do not understand this. What is the definition of \"prepack-node\" here? Prepack debugger should never be used during web scenario so the code importing \"fs\" should never be executed. Also, currently, there are three files importing \"fs\", why is it better than one file importing \"fs\"? Let's chat in person for this.. Again, please hide \"fs\" inside FileIOWrapper. You do not need to pass \"fs\" from constructor.. Can you add comments for the meaning of these two flags?. I do not feel \"repl\" is a very informative name regarding what it does. How about call it \"outOfProcessRuntime\"?. Are you excluding es6 tests from running under es5 mode? I thought you wanted to babel lower es6 tests to es5 code for running?. Is e.toString() more readable?. Change this function to \"testInOutOfProcessRuntime(runtimePath)\" to align with the option name change.. I see.\nIn this situation, it seems wasteful to babel lower for non-es6 tests under es5 mode.\nOr if you still want to opt-in some es6 tests for es5 mode, you can introduce two flags: es6-can-lower, es6-cannot-lower(you may change the wording).. Sounds like there is no need to lower using babel under es5 mode since we exclude es6 tests from running under es5 mode.. Also, the name is a bit confusing to me. Based on its implementation, prepareReplExternalSepc() indicates its purpose better.. Please prefix all these private fields with leading underscore.. The fact that, 90% of the tests are es5-only tests which do not need to be babel lowered; they are all transformed by additional babel lowering API call, is the thing I feel wasteful. \nWe can avoid this by introducing three categories: default(no babel call), es6-can-lower(call babel on it), es6-cannot-lower(skip for es5 mode).\nBut I am fine if you insist on your design since it only slows down test-runner. . Hmm, I thought you just need to mark es6 tests and decide which can and can't be lowered?\nIf we want to do it, here are the logic steps in my mind:\n1. Directly run the es5 runtime for all the tests. Any failed tests are es6 tests(which I hope are not many). Any succeeded tests are es5 tests do not need babel lowering.\n2. Mark these es6 tests with es6-can-lower flag which tells test-runner to babel lower them and run them. Any failed tests are es6 tests that can't be lowered(mark them with es6-cannot-lower flag).\n3. Done.. Yeah, I am fine with this.. EventEmitter is an implementation details in channel.\nDo not create EventEmitter in DebuggerAdapter and pass to AdapterChannel. Create it inside AdapterChannel. Then AdapterChannel should expose a method called, registerChannelEvent() which internally calls _eventEmitter.addListener().. We are actually designing a small RPC system right now. In RPC terminology, we normally call this \"MessageMarshaller\", \"formatXXX\" => \"marshalXXX\", \"parseXXX\" => \"unmarshalXXX\".. Just call it \"setBreakpoints()\". The fact it is queued is an implementation details.. I think you will need a DebuggerResponse message sometime later. \nWhen that happens, you may want to take out \"requestID\"(or event kind) out and put inside DebuggerRequest/DebuggerResponse. . Good point. Yes, targetBody is only supposed to be used while delayReason is undefined branch. I will add this invariant. . Will do.. This code just serializes the abstract value into \"serializedValue\", then add a var declaration for it:\njs\nvar uid = < serializedValue>;\nFinally it just calls emitter to emit it.\nFor \"Doesn't that compete with another declaration\", what is \"another declaration\"?. I see your question now. \nThere is not another declaration. Before _serializeAbstractValue is called(actually before any _serializeValue call), this.residualHeapValueIdentifiers.setIdentifier() is called to assign a new identifier for a Value.(This is done in serializeValue() method).\nSo residualHeapValueIdentifiers.getIdentifierAndIncrementReferenceCount() can always fetch the previous assigned identifier.\nI will add a comment on \"getIdentifierAndIncrementReferenceCount()\" call with above explanation. But I am not sure if it is necessary because I followed the pattern of other places in this file using emitNowOrAfterWaitingForDependencies(): most of them call getIdentifierAndIncrementReferenceCount() to fetch the previously assigned identifier with the same assumption.. Hmm, this invariant may not be true -- when this abstract value needs to wait for its generator body to be available, the function passed to emitNowOrAfterWaitingForDependencies() will be queued and executed later. \nThis happens for the testcase together with this PR.. I will land this for now and chat you offline tomorrow so that I can start send out other dependent PRs. . Does VSP debug protocol expect the top frame at index 0?. What is the difference between response and acknowledge?. \"prefix\" does not make any sense here, call it \"messageType\" or something similar.. Do not call it \"prefix\", call it \"messageName\". \"prefix\" is an implementation details, \"messageName\" indicates its real meaning.. To be consistent with DebuggerRequest, define it as:\nexport type DebuggerResponse = {\n  id: number,\n  kind: string,\n  arguments: ....\n};. Change to import type.. Why this is needed? What import caused the cycle increase?. Then please change the comment to indicate this fact. Your current comment explains what this does not why this needs to be done.. Add a space to separate these three categories and add comments to explain the meaning of each category.. Then, consider pass the necessary data into debugger instead of the whole realm object if possible. Increase the flow cycle increases the flow checking time, it is already very bad now..... This is a redundant invariant from previous checkin.\nIn \"_serializeAbstractValue()\" function, there is already same invariant.. If you can match the property names, much cleaner to use spread operator \"...args\".. Can you explain why we are supporting two runtimes, instead of just prepack?. Why are we comparing string against numeric 0 here?. How can a container not be LexicalEnvironment? . This is weird. You are building a hash map here. Why not using a real map? Then you do not need to do this \"void | T\" thing.. 1. Add comments for several concepts here: the purpose of this class and how should client use it. And the meaning of \"reference\".\n2. I would call this \"VariableManager\", Factory normally means the factory pattern which creates variable well this class does not create variable only manages its lifetime.\n3. You need to clear the content of the map during \"resume\" otherwise, you are leaking memory.. How do you handle if \"scopes\" command is called multiple times for the stop session?. As we discussed offline, we just need user to specify the location of prepack and use the same consistent way to run it so we do not need separate runtime.. Thank you! That's the word I am looking for.. Yes. It's for using from interpreter to emit that magic comment. I will add a comment.. Yes, it is a hack flag telling derive() method to emit that magic comment or not. If we are able to switch to @hermanventer's suggestion we should be able to remove this usage.. Use explicit check here: cachedRef != null. Because JS will treat number 0 as falseness. (I know you never use 0 as a valid reference here, but this falseness checking a potential bug farm we should avoid).. For non-lexical environment(like object container), are you expecting to return empty list? I assume you want to return the children properties list which you haven't implemented yet. Please add a TODO comment.. The same, either invariant to fail or add a TODO comment instead of silently return empty collection.. We generally call it \"_onDebuggeeResumed()\".. There is a getOrDefault() helper function for this pattern.. I would suggest you change \"BreakpointCollection\" class to \"BreakpointManager\" and move all these breakpoint related handling logic into BreakpointManager.. I can see this is violating the design of marshaller in several aspects:\n1. All the parts related join slice parsing should move inside unmarshalXXX() call. This is true not only for this change, but all the other places you called slice() method.\n2. I did not see why you need to parse parts and reqeustID fields from message at the beginning of \"_processPrepackMessage\". Please refactor this code to move all message parsing code into unmarshalXXX() API.\n3. With above suggestions, unmarshalXXX() API should only take a single message as argument. So you only need a single marshal() public API which dispatchs its call to individual private _unmarshalXXX() APIs.\n. My comments to processPrepackMessage() to AdapterChannel applies here as well. . You used to support the single breakpoint request format. Now you completely switched to multi-breakpoint requests. \nDo you need to support both? \nMy understanding is that, debugger UI will send multi-breakpoint requests during launch, but will use single breakpoint request for later individual breakpoint operations so you need both.. This source loc parsing code is duplicated in at least two places. Consider putting it inside a helper function.. Why is \"ast\" optional? . yeah, it is an invariant originally. \nHowever, I found it failed all the react compiler tests. I do not know why but all the AST node of the react compiler tests do not have location so it has to be check here. @trueadm, do you know why functions in react compiler tests do not location information from babel?. Frankly, I do not think the real ordering of the source path matters for this feature. The purpose is grouping all the functions from the same files together during multi-files scenario so that line/column comparison makes sense.\nAs long as the comparison function is consistent regarding their relative ordering we should be good.. Update comments, it's not a data structure wrapper now.. 1. To be consistent: change addBreakpoint() API to take single BreakpointType.\n2. I think you can set addBreakpoint() as private now. . Above comment applies to here as well.. Mark this field as private leading underscore.. The same.. The same. All the APIs have the same signature, the same parameters, I suggest you consolidate them into a helper function which takes one extra parameter of target function name so you do not need to duplicate the code.. Change this to use unmarshallRequest() as well.. If you follow the same suggestion as _processPrepackMessage() here by not splitting requestID from the request, you can collapse the remaining marshalXXX() call into a single marshal() API too. Feel free to do in later PR though.. Hmm, you are defining \"_pendingRequestCallbacks\" as a ES6 map while using it as a raw object map. Is it correct? . Instead of sendStepInResponse(), I suggest you create a single debuggerStop message and with a field containing the stop reason(breakpoint, or step-into, step-over, step-out etc...). This aligns with VSP StoppedEvent.. You may want to generalize this into \" processStepCommand\" later.. The name does not make sense. The meaning of this method should be \"shouldCompleteStep()\" or something similar.. Each stepping mode will have its own stop condition, so you may want to generalize each step mode into its own Stepper class.. Add comment why IsStatement() is needed here.. As I said in previous comment, this is misleading name. Every location is a valid step-in location. This function checks if step-in request completes. So rename to \"_isStepInComplete\".. Add comment \"// override\" for all these methods so that reviewer can easily see how this method is used/called.. This is ugly. I suggest you take out the message parsing \"JSON.parse()\" into a method, which needs try catch. Then all _unmarshalXXX methods do not need try...catch.. It's fine right now, but you will soon change it to checkStepComplete() general method.. Request change: This kind of sequencial checking has a problem:\nAssume you are at line 10, and you set a breakpoint at line 11. Then you issue a step-into which will land at line11 later. In current design, debugger will stop twice. Once inside checkForBreakpoint(), when user resumes from breakpoint, checkStepIn() will stop it again which is wrong.\n. Add an invariant here: invariant(this. _stepInData === undefined);. It works in this scenario because you are missing one invariant here: checking \"this. _stepInData is undefined\" in _processStepIn() which means there should only be one step-in request on the flight. Currently, you are silently overwriting the this._stepInData for each step-in instead of explicitly cancel the previous stepper. After adding this invariant, you will see the failure. \nAnother way to demonstrate the failure:\n1. Current line is 10, while set breakpoint at line 11\n2. Step-in from line10 => line11\n3. BreakpointManager stops at line11 while step-into stepper is not done yet.\n4. You do a \"step-over\"(note: note step-into) which will not overwrite this._stepInData. \n5. The code comes back and checkStepInto() which will stop again at line11.\nThe root cause of the problem is that it sequentially notify each managers. Instead, you want all the execution control related managers to be notified and then consolidate a final stop disposition decision.\nIn summary, you want:\n1. Separate stepping logic into its own stepper.\n2. At each line, send the current AST to all managers\n3. Collect stop decision from each manager and join them into a single decision.. It's weird to have \"Prepack\" in this. Let's call it, marshallStoppedResponse or marshallStoppedEvent. 1. You can omit \"value\" and direct return the function call.\n2. Add inline comments for the two \"true\" parameters.. Agreed. I will fix it in later PR.. Call it StepIntoStepper.. Do not initialize this way. Use parent class contructor to initialize.. This should be a common API among all steppers. Put this as an abstract method in base class which throws exception and override here.. This name is not true anymore: there may be other stops in the middle. Just call it \"_stepStartData\". Eventually, you want Array to hold all steppers.. You should embed readable exception message into displayValue so that user knows why evaluation failed.. This forces user to specify evalFrameID. Do you have a CLI command to perform global eval(without specify frameId?). Please rename this function \"isValidBreakpoint\". It is not checking if a breakpoint is a valid or not, but check if debugger should stop.. I do not think you need this anymore.. Add a comment for its meaning.. Rename \"StoppedData\" to be SourceData. It does not necessary mean stopped state anymore.. Why do you need to check \"breakpoint.column !== 0\" here? this._lastExecuted.column can never be zero right? Then, this whole code can be collapsed into:\njs\nreturn filePath === this._lastExecuted.filePath && lineNum === this._lastExecuted.line && breakpoint.column === this._lastExecuted.column ? null : breakpoint;\n. If we have multiple steppers on flight, they may finish at the same time, the reason will overwrite each other.. The name seems to indicate it is a pure function, but its implementation has side-effect. Figure out a better name indicating its mutation nature.. I do not like this design of arbitration on stopping logic. It hard-coded the assumption that breakpoint manager is stopped before steppingmanager which may change in future. For example, when we added exception manager to deal with exception, who is responsible for deciding stop? \nThere should be a dedicated StopEventManager that gathers information from all managers and make the central decision.. I have seen this block of code again and again for at least three times. Take them out into a helper function.. It's bad to pass in the whole realm just for a single stack depth check. Just pass in realm.contextStack.length as \"currenStackDepth\". Create a flow type for {source, line, column} tuple. The code will be much cleaner.. You can still write it much more compact as:\njs\nreturn filePath === this._lastExecuted.filePath && lineNum === this._lastExecuted.line && (breakpoint.column === 0 || breakpoint.column === this._lastExecuted.column) ? null : breakpoint;. Call it \"isAstLocationChanged\". This method will return true even column changed. Do you plan to support column stepping?. This is a bad API design. Its name indicates it should return boolean, but its signature and implementation means \"getCompletionType\", I think you want two APIs here.. The fact that you have to explicitly check \"reason === \"Breakpoint\"\" here indicates you have some hard-code assumption in this design.. Add comments for this class.. Make this as comment for this method.. Agreed. shouldDebuggeeStop() indicates it is a pure function which should not have side-effect in it. . This is not ideal to test the change: it relies on the test runner to use \"unique27277\" as suffix which may be changed later.\nYou may want to use \"// Copies of\" or find another stable pattern as test invariant.. Consider changing scopeInstances from \"Set<...>\" to \"Map\". It will improve algorithm perf and much simplify the code.. I suggest you create a new testcase using the simplified testcase from @simonhj. \nThen you can check // Copies of __scope_1: 1. \n(Actually \"__scope_1\" function should be called \"__get_scope_bindings\", but there is another bug that incorrect named it).. I am matching the pattern as other file I/O code here. \nwriteFileSync() will throw exception while failing. The parent function's try...catch will handle this case.. I am modeling the object reference relationship as parent=>child here. Is that not correct mental model for it? I would like to avoid \"predecessor\" because it may be confused with the term \"predecessor\" during graph's traversal which may not be the parent node if BFS is used.. Any reason debugInFilePath is a relative path? I would assume client pass absolute path.. At high level, I was surprised that \"firstUsage.isNotEarlierThan()\" below did not catch this testcase. Because we are essentially use it before the function's insertion point and first usage checking is more accurate.\nIn future PR we may want to check the residualBinding.value is not serialized yet, which will give us more accurate result.. This hard-code the fact that only works on Mac. I suggest you use tmp Node JS API:\nhttps://www.npmjs.com/package/tmp\n. I hate this inlineExpressions design that create name generators and lots of code and completely throw them away...\nAnyway, under this situation, I would still make valueNameGenerator singleton while reverts all other name generators to be local.\nFor debug names, they should get name from ResidualHeapValueIdentifiers class which will be persisted across two passes.. You can use more functional style: \njs\nconst nodesData = nodes.map(...);\nconst edgesData = Array.from(edges).map(...);\n. Since ordering matters now, maybe add a comment documenting this ordering so that future changes will not try to revert it back.. Hmm, it's my fault to design the option badly. The options passing to prepackSources() API should be a boolean flag instead of a path. Only prepack-cli itself should see the path. Feel free to change it in future PR.. Is phiNode's lifetime spanning across widenBindings() invocation session? If not, since phiNode is only used inside widenBindings(), maybe we could create a Map map inside widenBindings to temporal store these values? By doing this, we do not need to expose \"phiNode\" outside of widenBindings() function and these values can be released after widenBindings() call.. Maybe worth documenting these two effects in evaluateForFixpointEffects().. Can you add a comment here for the reason?. This type of regex string hurts my eyes, I would put it inside a helper function with meaningful name so that I won't need to read/see it unless I am interested.. The logic looks good to me. But I do not like the fact that we are stuffing more generator serialization code into realm.js. It would be more centralized if we put all generator related code as member functions of generator class.. This change is intented to make two objects using different property names so that it's much easier to debug.. Is this testing additional function? If so, I was expecting some annotations to specify target additional function.. Any reason for this change?. Seems more readable:\njs\n!refName.mightNotBeString() || !refName.mightNotBeNumber(). This will make widenPropertyBindings() API having side-effect right? Every calling of widenPropertyBindings() will cause some entries being added into realm.generator. That may make the API harder to use(it can't be called multiple times). Not sure how to fix it though.. Maybe not, \"generator\" above represents any time sensitive generator entries captured in the additional function so it should be visited from that generator(or its sub-generators).\nWhile for modified properties and bindings that are not captured in generator, they should be in additional function's scope(the change here).. Makes sense, let me try.. _getFunctionName() is only used for debugging purpose so it's should be fine. \nThis diff is just the first refactoring to improve it not the final/perfect one. 99% of the case it will not have duplicate, and user can always modify the original source to avoid duplicate for important debugging scenario if needed. In future diff, we may want to add the function's serialized identifier name together with original name.\n. There are many temp generators created and throw away, they do not have names yet. Also, there are sub-generators created during fork execution will not have names yet so falling back to id is safer.\n  . That maps to ResidualHeapSerializer's serializeValueObject() method. In it, we only support serializing objects that is not created using constructor and is not objects that we do special handling for, like Map, Date, String, Number etc.... I call this category of objects \"raw objects\" and there is a serializeValueRawObject() method for it. \nNot sure what is a better name for it? Maybe \"literal object\"?\n  . Keep in sync with \"_serializeValue()\" of ResidualHeapSerializer. Will add.. Yes, if you look ResidualHeapSerializer._serializeValue(), we do not call serializeValueObject() for array or functions and many other cases. So _isObject() here really means the value that is serialized via serializeValueObject() method in ResidualHeapSerializer. \nAny better approach/suggestion welcome.. In sync with ResidualHeapSerializer.serializeValueObject() method logic. Will add.. Makes sense. I will delete it.. Do you promote the _mainBody as a field just for the invariant() in finalize() method?. Let's add comment for these fields. It's not intuitive to know each meaning.. Why walking to the parent is needed? Isn't \"s\" never undefined?. Did you accidentally disable this invariant? If not, please add a TODO comment explaining why.. I did not see this method being used. . Since _getReasonToWaitForDependenciesOptions is only used by one dependenciesVisitor() call. Seems more readable to inline it into the callsite instead of saving it as a reusable field.. I feel it should be called \"EmitterDependenciesVisitorCallbacks\" to indicate it is set of callbacks. \"Options\" confuses me to believe it is some config option to the API.. Can you document 1. the meaning of \"done\", 2. how does caller know when it should use true or false?. Can you add comments to all these fields? . It is not a file path, you are using VISJS format here. I would call \"// heap graph\" instead of heapGraphFilePath. I would write the comment like: ModifiedBindingEntry caches the state from declarativeEnvironmentRecordsBindings during visitor so we have to pass the same cache to future visitors.. Yeah, heapGraphFilePath is a command line level option not actually the engine/serializer level option, which is heapGraphFormat. But either way, we are just trying to enable heap graph and do not care about the output in this test.. The indention in the code looks a bit weird. You may want to be consistent with testcase to use 2 spaces indention.. How does the test work? Do we have any test runner to verify this step out behavior from code? Or it is just a JS code for manual testing? If so, I do not think it makes sense to checkin.. Also, please test recursive call cases.. I do not think this is correct, source location may be not changing for recursive function call during step out. For example:\nfunction foo() {\n   if (depth > 10) {\n     return;\n   }\n   foo();     <=== stop here.\n}\nIn the above stop line, you issue a step-out, you may land at the same line in the caller frame.. The code can be simplified as\nreturn currentStackSize < this._startStackSize;\nThe same for step-over code.. I do not think we need this change anymore.. If you look at the indention at line 8, 9, 13, 14 etc..., they all have much bigger indention than 2.. Yes, we should fix for step-over case.. \"must have\" => \"either\". The whole code logic can be merged as:\nreturn currentStackSize < this._stepStartData.startStackSize ||\n  (currentStackSize === this._stepStartData.startStackSize) && this.isAstLocationChanged(ast));. Why leave this commented line?. message += \". \" + result.message;. I would call it \"shouldStopForSeverity()\" to clearly indicate this function decides whether debugger should stop or not.. I thought you showed me yesterday that you have to pass a valid ast ndoe to waitForRun()?. You have at least two places doing the validation for severity. You may want to make this as a helper method called \"isValidSeverity()\", then reuse from both callsites.. This is a pretty weird name. It is not passing any launch arguments, it is passing diagnostic severity. Also, it only has one field why do we need a wrapper type here? We can directly use diagnosticSeverity in all callsites.. Then just DebuggerConfig should be fine. . Why use two if checkings? . Can you add comments explain under what situation this._adapterChannel can be undefined? Also, is it ok to silently do nothing in this situation?. The same, is it ok to silent do nothing if this._adapterChannel is undefined?. Let's use a helper function called ensureAdapterChannelAvailable() for all these runtime checking and throw exception if the checking failed.. Per our discussion offline, once we delay InitializedEvent response to launch, _bufferedBreakpointRequests should not be necessary. We do have runtime check to assert this assumption/protocol at runtime.. This comment should be modified to \"Nuclide\" does not support column debugging.. I do not think this is needed. You already checked it.. The same, no needed.. This is unnecessary. You just created _adapterChannel before this line, it makes no sense to check it.. The same unnecessary.. This comment states the negative side, and assumes some history context which reader may be confused. \nInstead, I would change to:\nImportant: Responding InitializedEvent is the master switch that caused UI to start sending further requests like breakpoints, execution control etc... So InitializedEvent should be sent after  _adapterChannel is ready and prepack is launched so that we are ready to handle these requests.. You can store this._adapterChannel in a local variable so that later use of this local variable does not need invariant().. I do not know what is unintuitive. Make a local copy is a way to explicitly tell type system that my state won't be changed by other external code. That's why invariant is unnecessary because you are helping type system to do the analysis. If your method got bigger and bigger, with 10+ using of this._adapterChannel, adding \"invariant\" 10+ times is not only annoying but also clutters the main logic of the code. . This won't work if there is whitespace in file path. You need to use https://www.npmjs.com/package/shell-quote to correctly handle this.. Add a comment explaining these magic options.. Why it is better to single string instead of array?. Is this line/column pair after source map mapping(from original foo.js instead of current bundle.js)? For bundle.js, after minification, it's possible multiple JS code lines are merged into single line so we do need column based stepping. \nIf this is after source map mapping, please explicitly call this out in comment.. The name \"find\" seems to indicate this function is a pure(no mutation inside it), but it is actually mutating state field. I would call it updateSourcemapPrefixes().. Based on flow type, you want to use undefined here.. These comments are not very useful. You want to explain each field's meaning. Also, you may add a comment pointing to its definition in quip doc.. Why do you need _useRootPrefix flag? Can't you use \"_sourcemapDirectoryRoot === undefined\" to know this fact?. Since it is only called once during initialization, let's call it initializeSourcemapPrefixes().. Please doc comment this method.. This file deals with two source map formats. It's very important to clearly call out and distinguish between them. So I suggest you give a high level document about these two modes in class level doc comment here. So that people know there are two modes involving here.\n. 1. In comment, please explicitly call out _sourcemapCommonPrefix/_sourcemapMapDifference are for babel relative path scenario and _sourcemapDirectoryRoot is used by buck scenario.\n2. change _sourcemapDirectoryRoot to _buckRoot. Also, it's good to call out these two scenarios are one for buck one for babel. And give two short path related examples.. It's very important to give a comment for public APIs. \nLet's call out its intention/scenario not its implementation details. For example: used by adapter to convert relative source path(in engine) to absolute path(used by UI/IDE).. Change to buckRoot. It's better to move this as class level comments.. Do you want to inline all fields of args into launchArgs? If so, these three lines can be simplified using spread operation: ...args. Add a comment for the purpose of this field.. Add doc comment for this class.. These three copying loops seem to should be in a common helper method. Add a comment for what is this code doing.. Why are we generating empty zip? . Why are you changing DebuggerError to Error?. Why typeof DebugReproManager not just DebugReproManager?. More readable to make these two lines into one line:\nlet reproMode: void | \"reproUnconditionally\" | \"reproOnFatalError\";. Per my understanding, debugBuckRoot is only used by SourceMapManager while buck is being used. In repro replay mode, there should never be any buck so this parameter is never needed and should not be added into reproArguments. IIRC, these two parameters are required for debug sessions. Will the replay debug session succeed without them?. Add comments for these two fields. I do not understand your comment. How can buckRoot specified but not sourceMaps? It seems should be an error.. Is this only used by reproOnFatalError or both repro options?. Instead of calling process.exit() coordinated, let's do zipping as the last step of Prepack and call process.exit() there.. Can you call it externalPrepackPath? debugReproPrepackPath is hard to understand its meaning.. Also, please add a comment for this field and when it will be used.. This validation/reporting should be done early other than later if possible.. Change to the new name I suggested above as well.. ",
    "Adriana1999": "Pending. xxx. _assumeDataProperty(global, \"xxx\", __abstract());. In German. ",
    "facebook-github-bot": "Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Kishore-B-Rao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Kishore-B-Rao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Kishore-B-Rao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Kishore-B-Rao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Kishore-B-Rao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Kishore-B-Rao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Kishore-B-Rao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Kishore-B-Rao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sebmarkbage has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @simonhj has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @NTillmann has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @alexgyori has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JWZ2018 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JWZ2018 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JWZ2018 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @tcirstea has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JWZ2018 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JWZ2018 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yinghuitan has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cblappert has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @hermanventer has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. ",
    "1000hz": "D'oh, @spicyj beat me to it with #510. ",
    "hzoo": "Yeah, if you want you can change the value of the node version to compile less. In development you can also do \"node\": \"current\" to run on the currently running version\n```js\n{\n  \"presets\": [\n    [\"env\", {\n      \"targets\": {\n        \"node\": \"7\"\n      }\n    }]\n  ]\n}. FYI, Also I noticed this PR added a yarn.lock file and it wasn't there before so don't know if that was wanted or not.. Using uglify but otherwise this could be\njs\n    [\"env\", {\n      \"targets\": {\n        \"node\": 6.1\n      }\n    }],\nAnd could run babili instead. Ah ok! Well without any targets it acts the same as preset-es2015 other than also providing support for es2016/es2017. env includes the same dependencies in package.json. Yeah env includes all the transforms in e2015 (superset) so it's ok. ",
    "montogeek": "You mean this?\njs\n(function() {\n  let x = 0\n  global.x = x;\n})();. I just tried it in a React bundle, couldn't make it work: https://twitter.com/sebmarkbage/status/859842908194693121. No, I mean, using prepack directly. No, I am talking about prepack, no your plugin.\nWill try it later!. ",
    "sebringj": "let a = 'a';. OK cool thanks for explaining.\n\nI just tried this:\nlet a = 1, b = 2; console.log(a + b)\nthen turned into this:\nconsole.log(3);\nwhich is cool. ",
    "bevacqua": "+1 to not having surrounding text by default. imo, CLI should be:\n```bash\nprepack file.js\nprint prepacked file as stdout\ncat file.js | prepack\nprint prepacked file as stdout\n```\nYou could then implement the currently default behavior in user-land as:\nbash\nprepack file.js > file.js. @sebmarkbage I think an API like this is acceptable if you want to throw in source maps:\ncat file.js | prepack --source-map foo.js.map > foo.js\nYou could go further and add an --output option (which redirects output to a file instead of stdout) for consistency:\ncat file.js | prepack \\\n  --output foo.js \\\n  --source-map foo.js.map. ",
    "gordomium": "This seems done. When should we release it?. ",
    "hulkish": "i think we should expose the ability to configure that very area to the user.... instead of making it an abstraction.\nThis would make it really easy to keep prepack's part in this very lightweight.. ",
    "TheLarkInn": "That would be nice, @gajus you could also just execute this on a resulting bundle I believe. Am I mistaken @sebmarkbage @kittens?. Oh is this all it would take to \"pepper\" the interpreter. I'm going to try and PR this on prepack-webpack-plugin today in the next 20min. . ",
    "gajus": "\nThat would be nice, @gajus you could also just execute this on a resulting bundle I believe.\n\nThats what the plugin does (on the resulting chunk, to be specific).. > I just tried it in a React bundle, couldn't make it work: https://twitter.com/sebmarkbage/status/859842908194693121\nSorry, just published a fix (assuming you are referring to the webpack plugin).. > No, I mean, using prepack directly\nWrong issue thread in that case.. ",
    "motiz88": "I'd like to take a look at this as my first foray into Prepack.. So one early observation I have is that I can't find a \"bail out\" / deopt path in Prepack's evaluators. I've been able to add a maxStackDepth option to Realm, analogous to timeout, but all it does for now is throw an error which terminates evaluation completely - which is pretty much the same as getting a native stack overflow error, although it does improve on that slightly by offering determinism.\n(Oh and timeout isn't deterministic it seems? Counted in \"wall clock\" time rather than some notion of a more abstract program counter. So - a last-ditch safety mechanism rather than a general compilation option)\nWhat I would like Prepack to do in these cases, which presumably is what it's ultimately meant to do, is predictably fall back to just using the unoptimised code as written. It should not fail on potentially infinite loops or unbounded stack growth but rather leave them to be handled at run time.. Yes, I'm picking this back up now. PR coming soon.. ",
    "gre": "I've tried the mathRandomSeed and still get the same error. Would be great if the error message was telling which abstract value it failed on (like saying it's Math.random). ",
    "jpike88": "You're basically dealing with a tool that tries to compete with the likes of what V8 is already capable of doing... but with zero stats to show its worth.\nI also think the example code snippets provided are a weak argument for this tool. A loop, mutating a variable to get a determinate result... how often would a scenario like that occur? I don't think I've ever seen something like that more than a couple of times in my entire coding career. The second you add a more ambiguous variable to the loop, you need that loop to happen. So you might as well throw in the incrementing of x, as the computation required to modify that other variable may very well render the incrementing of x as negligible... unless you're doing something ridiculously intensive to x inside a loop (wtf).\nI want concrete examples using realistic use cases, and I want benchmarks. Until then, I'll be avoiding it.. I understand the difference between JIT and pre-optimisation.\nWhat I'm requesting is proper benchmarking on real examples. 50ms off a 150ms load may translate to 80ms off a 2000ms load. And while V8 has to work harder to do its job, I struggle to find scenarios on modern devices where it's sluggish. It's a valid question to ask, if I'm to consider a tool that may sacrifice my ability to trace errors easily.. In fact, existing minification libraries (like https://github.com/mishoo/UglifyJS2, which I use) already have optimisation techniques somewhat similar to this tool built into them. And they're already fully compatible with scripts that reference the DOM. In fact, many of these techniques are turned off by default as aggressively optimising JS can result in intended consequences.\nPre-optimization/minification/etc should go hand in hand in a single deployment build, otherwise you're having to deal with yet another source map, which would break existing error reporting methods.. ",
    "jaredly": "@ev1stensberg I found the \"how does it work?\" section of the website https://prepack.io/ to be very enlightening, and I think it addresses much of your question!\n@jpike88 here's something more than fibonacci https://twitter.com/roman01la/status/859849691831422976 . Given your comparison to v8, I'm not sure you understand what this is for. v8 has to strike a delicate balance when JITing javascript, because it can't take so long analyzing the code that there's a lag before execution. This is ahead-of-time, and so can take as long as it wants, dramatically reducing the amount of work that v8 then has to do at runtime.. @ev1stensberg Sorry if my answer seemed dismissive! I certainly didn't intend it that way. The readme gives a low-level perspective, I'l try for a mid-level one.\nPrepack implements a JavaScript interpreter in JavaScript (although it cheats in some places). It then runs your initialization code -- all of the code that has to run before anything \"real\" happens like actually rendering your app. This includes the module definitions, instantiating a bunch of objects, etc.\nAt the end of this, it has a virtual \"heap\" with all of the objects that have been created, along with all the attributes/etc that are the result of the initialization. Prepack then writes a new javascript file that contains all of the objects, the way they are after initialization, along with all of the other code it didn't run, hooked up in such a way that the other code doesn't have to care that the initialization work which is normally done at runtime was already done at compile time.\nThis has the potential to cut down the startup time of an app dramatically! Instead of doing a bunch of logic & execution to initialize, the browser has all of the objects ready-made for it.\nLooking back at this, I'm not sure if this is intelligible at all, but I hope it helps!\n@jpike88 I apologize for being condescending -- your initial comment felt hostile, and I was defensive. In response to the question \"are there really substantial benefits that would outweigh the costs involved\", here's my take:\nI see prepack as being most useful on mobile devices, where resources are much more constrained than on a desktop. As I understand it, the JIT tradeoffs are even starker there, and JSCore (on iOS) takes a long time to warm up before you start seeing benefits. In my work tailoring a large web app (khan academy) to mobile browsers, I've seen the js engine take multiple seconds just to evaluate the javascript modules & initialization code. If prepack can cut that in half, I'll be thrilled! On desktop, it might be the difference between 100ms and 50ms, and I'll agree with your point that the obfuscation cost might not be worth it.\nIndeed, this seems to be the focus of the folks behind prepack, as their first target is to get it compatible with React Native javascript bundles.\nCheers!. @phpnode I think that can just be a: 123 -- it doesn't need to be abstract. title should be for unused variable. ",
    "evinism": "I guess I'm curious why this is popping up now-- these aren't new ideas, nor was the JS community not ready for them earlier-- we've had minifiers for JS for over a decade. I kind of assumed if further preoptimization techniques were found to be effective in the real world, we'd have seen them by now. To me, the examples provided aren't particularly compelling for the reasons outlined above, JIT should handle most other runtime things, and the timing is off. If this does turn out to be useful in more than a handful of cases, it'll be pretty strange that a community like JS forgot to do this.\nSolid real world metrics will make me shut up really fast.. ",
    "evenstensberg": "@jaredly That section in specific is hard to connect without getting confused. I think you'retaking into account that you presume what every tool does, everyone also know. True, but I'm not only speaking from the point of view of not understanding CS concepts, it's also about trying to simplify things, so that non-native people can understand what is being expressed. This is quite important and relative.. Not saying to cut it, but it would be nice to include a small snippet of description for these types of tools, their advanced, and helps people to grasp the context better. Based on personal experience, of course, may be only me thinking this way. In general I'd like the About section to be more relatable in terms of readability, it's just that. Example is all the other bullet points that are somewhat hard to grasp at first :) . @jaredly No worries, I don't take it personal or anything. This is just a user story, if people think feedback like this is bad, then I'd ask what they're thinking. Generally, this is excellent to improve and understand what parts the user doesn't understand. It makes room for improvement. \nLikewise! . ",
    "wmertens": "@jpike88 \n\nIn fact, many of these techniques are turned off by default as aggressively optimising JS can result in [un]intended consequences\n\nExactly. Prepack is actually in a position where it can optimize beyond what current minifiers can do.   Even if this optimization results in \"only\" 5% less code and 5% faster startup, that's still 5% that the VM won't have to do every time the app runs.\nEven better, it allows programmers to write code that is easy to understand and maintain but would be inefficient to run. DWIM.. \u2026and if there is, would it be possible to automatically backtrack on some type of errors and mark that function as non-prepackable?. Ok, I think I understand, but I'm having trouble imagining how I would do this for arbitrary third-party modules. What is a good approach?\nE.g. if I'm going to use prepack I can tell webpack to replace my dep with an annotated dep, so that part's easy.\nHowever, making the actual annotated dep, should I import it, add __residual on all the relevant functions, and then re-export? It seems that the actual return value of __residual must be used, so I must monkey-patch the library?\nI'm also not sure about the no-side-effects part. I want to pre-calculate css-in-js objects right up to the point where they get registered on a stylesheet, so that the remaining call is the pre-processed css given directly to the stylesheet injection function. I would be wrapping that stylesheet function with __residual, as I understand, but of course it will have side effects, are those ok?\nOr should I be making that function __abstract in this case?\nI promise to make a wiki page explaining how to wrap third-party modules once we figure out a nice approach :). ",
    "nfroidure": "I have at least one real world use case for prepack, even if I cannot use prepack for it right now, I think that it should be possible in the near future.\nCurrently, there are a lot of API client generators that take your Swagger/OpenAPI definitions and generate an API client.\nGenerating code is a very efficient way (in a performance point of view) to create a REST API client compared to the fact of embedding the whole Swagger definition in your client and use it to dynamically generate the client at script initialization.\nWhile the code generation is efficient, it is hard to debug due to the additional steps introduced by templating (see https://www.youtube.com/watch?v=EmGfdlixQHo).\nWith a partial evaluator, you could write code that dynamically generate the API client but optimize it with prepack in your production builds. That way you won't have to download the whole Swagger file in the client apps but you will still have easily understandable JavaScript code with no syntax overhead introduced by templates. Giving the same result than code generation but in a nicer way.\nTo be honnest, I failed to do so right now (this doesn't work https://gist.github.com/nfroidure/77090688788054033a4744e0d009b5d1) but i think I'll give it another try when prepack will be more smart and handle partial evaluation of JavaScript modules.\n. @sebmarkbage For a single package distribution, do you think it is feasible and has chances to ship in prepack someday?\nI'd like to generate API's clients as a module from swagger definitions with prepack.\nThat said, maybe \"prepacking\" the whole frontend app later is sufficient?\nThe idea is to avoid the AST templating approach I use there https://github.com/nfroidure/asttpl since the templates are somewhat unreadable :D https://github.com/nfroidure/asttpl/blob/master/src/realworld.mocha.js\nEdit: Here is a better explanation of what I'm trying to do ;) https://github.com/facebook/prepack/issues/522#issuecomment-300706099. Thanks!. ",
    "phpnode": "@NTillmann thanks, also is there a way to indicate when we know the exact value of the declaration? e.g. I currently turn a: 123 into a: __abstract('number'). @jaredly awesome, now we just need arrays and unions :). ",
    "vkurchatkin": "Is it me, or prepack doesn't do anything useful with abstract values at the moment?. Assignments to global object are observable.. > Prepack is quite limited in what it can do with abstract values\n@hermanventer is there an example of what prepack can do?  I tried a bunch of things and seems that it mostly either throws or ignores expressions with abstract values.. I'm trying something like this:\n```js\n__assumeDataProperty(global, \"a\", __abstract('number'));\n(function() {\n  if (a === 1) {\n    console.log(a + 23)\n  }\n}())\n```\nWhat I get is:\n```js\n(function () {\n  var _0 = this;\nvar _1 = _0.a;\nif (_0.a !== _1) { // Not sure what this is, but seems like a bug\n    throw new Error(\"Prepack model invariant violation: \" + _0.a);\n  }\nif (_1 === 1) {\n    console.log(_1 + 23); // I would expect this to be folded\n  }\n}).call(this);\n```\n. > This will hang Prepack indefinetely - seems like Prepack is actually running the code\nIt's exactly what it does.. > Is this the same reason why I'm getting this error:\nIt' a different issue. Prepack parses files as scripts, which are not allowed to have import or export statements.. @sebmarkbage fixed everything. OK! I've just notices that jsc-600-1-4-17 is something that you probably don't want to repeat a lot.. Was trying to please Flow, but it's definitely not worth it. ",
    "mlrawlings": "So they are.  Thanks for pointing that out \ud83d\udc4d . ",
    "MichaelBlume": "npm log https://gist.github.com/MichaelBlume/3480cc1dfde5e4f8274a2765774686c5. ",
    "Pr0x1m4": "Any ideas as to why CI is building this PR?. It aligns the scrollbar to the end of the code block, see before and after.\n\n. Not sure how else to accomplish this. ",
    "anmonteiro": "Created #533 with a fix\n. Ooops! sorry for the noise. ",
    "hemantasapkota": "Thanks. Worked.. ",
    "jasonslyvia": "According to the section The Environment matters! of https://prepack.io/,\n\nPrepack has no built-in knowledge of document or window. In fact, when prepacking code which references such properties, they will evaluate to undefined.. \n",
    "chenyong": "Tracking https://github.com/facebook/prepack/issues/24 instead.. ",
    "warent": "Thanks guys! Super excited about this project!. ",
    "huanz": "@sebmarkbage the prepack-node methods prepackFile and prepackFileSync already has sourceMap option\uff0cother methods exports from prepack-standalone i have already changed. ",
    "Frezc": "Found solution in doc.. I add \n__assumeDataProperty(global, \"xxx\", __abstract());\nto top of file, but get\nThis operation is not yet supported on abstract values ::global.xxx and ::global\n__IntrospectionError\n at index.js:2:149\n at call (native)\n at t (index.js:2:102)\n at index.js:2:557\n at call (native)\n at t (index.js:2:102)\n at index.js:2:200. ",
    "SukantGujar": "Replacing with y = Math.random() has the same effect. Something wonky with the Symbolic Execution trying to predict the abstract values :). There seems to be a cut-off on the branching so it doesn't wander long.. ",
    "kamranahmedse": "@cblappert this doesn't seem to be fixed yet\n\n. ",
    "isiahmeadows": "I take it the site still hasn't been updated yet? Using the original example, I'm seeing this:\n\nClick to show\n\n```js\n(function () {\n  var _$2S = this;\n\n  var _$0 = _$2S.Date.now();\n\n  var _1 = _$0 * 2;\n\n  var _0 = _1 > 42;\n\n  {\n    if (_0) {\n      {\n        {\n          {\n            {\n              {\n                {\n                  {\n                    {\n                      {\n                        {}\n                        {}\n                      }\n                      {}\n                    }\n                    {\n                      {}\n                      {}\n                    }\n                  }\n                  {\n                    {\n                      {}\n                      {}\n                    }\n                    {}\n                  }\n                }\n                {\n                  {\n                    {\n                      {}\n                      {}\n                    }\n                    {}\n                  }\n                  {\n                    {}\n                    {}\n                  }\n                }\n              }\n              {\n                {\n                  {\n                    {\n                      {}\n                      {}\n                    }\n                    {}\n                  }\n                  {\n                    {}\n                    {}\n                  }\n                }\n                {\n                  {\n                    {}\n                    {}\n                  }\n                  {}\n                }\n              }\n            }\n            {\n              {\n                {\n                  {\n                    {\n                      {}\n                      {}\n                    }\n                    {}\n                  }\n                  {\n                    {}\n                    {}\n                  }\n                }\n                {\n                  {\n                    {}\n                    {}\n                  }\n                  {}\n                }\n              }\n              {\n                {\n                  {\n                    {}\n                    {}\n                  }\n                  {}\n                }\n                {\n                  {}\n                  {}\n                }\n              }\n            }\n          }\n          {\n            {\n              {\n                {\n                  {\n                    {\n                      {}\n                      {}\n                    }\n                    {}\n                  }\n                  {\n                    {}\n                    {}\n                  }\n                }\n                {\n                  {\n                    {}\n                    {}\n                  }\n                  {}\n                }\n              }\n              {\n                {\n                  {\n                    {}\n                    {}\n                  }\n                  {}\n                }\n                {\n                  {}\n                  {}\n                }\n              }\n            }\n            {\n              {\n                {\n                  {\n                    {}\n                    {}\n                  }\n                  {}\n                }\n                {\n                  {}\n                  {}\n                }\n              }\n              {\n                {\n                  {}\n                  {}\n                }\n                {}\n              }\n            }\n          }\n        }\n        {\n          {\n            {\n              {\n                {\n                  {\n                    {\n                      {}\n                      {}\n                    }\n                    {}\n                  }\n                  {\n                    {}\n                    {}\n                  }\n                }\n                {\n                  {\n                    {}\n                    {}\n                  }\n                  {}\n                }\n              }\n              {\n                {\n                  {\n                    {}\n                    {}\n                  }\n                  {}\n                }\n                {\n                  {}\n                  {}\n                }\n              }\n            }\n            {\n              {\n                {\n                  {\n                    {}\n                    {}\n                  }\n                  {}\n                }\n                {\n                  {}\n                  {}\n                }\n              }\n              {\n                {\n                  {}\n                  {}\n                }\n                {}\n              }\n            }\n          }\n          {\n            {\n              {\n                {\n                  {\n                    {}\n                    {}\n                  }\n                  {}\n                }\n                {\n                  {}\n                  {}\n                }\n              }\n              {\n                {\n                  {}\n                  {}\n                }\n                {}\n              }\n            }\n            {\n              {\n                {\n                  {}\n                  {}\n                }\n                {}\n              }\n              {\n                {}\n                {}\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  var _5 = _0 ? 55 : _$0;\n\n  result = _5;\n}).call(this);\n```\n\n(It might be a separate bug, however - the \"useless\" line isn't even present, and invariants aren't even being checked.). @hermanventer Filed #1333. (I found other issues, too.). Just as a heads up, let could be swapped for var without change. Also, note that module and require are CommonJS-specific, and have nothing to do with ES6+.\nHere's another thing: if I replace require with console.log, it still generates the unnecessary blocks, just without erroneously removing the calls.\nEdit: Here's a smaller test case.. @hermanventer The first sentence of my last comment was mentioning that var/let was out of scope of this bug. I was just stating it was immaterial.. ",
    "almcaffee": "I solved this issue by ensuring all other scripts are loaded before main.bundle.js. Check your loader and console out the load order to ensure its correct.. ",
    "medikoo": "@deltaidea indeed, for some reason I assumed that \"Getting Started\" link at the top just scrolls to other content on main (\"About\") page. My bad.\nPossibly placing link to \"Getting Started\" between \"Examples\" and \"How does it work?\" would help, it's the area where I was expecting some info on that.\nAnyway I'm closing, sorry for noise.. ",
    "aligoren": "@deltaidea Yes, I saw these issue topics. But, I have no idea, why prepack need to knowledge about DOM? I think I will solve this problem myself.\nAlso, it worked dateim.js file except let.\nhttps://github.com/facebook/prepack/issues/515#issuecomment-298996381\nThanks :). @deltaidea Thank you for your explanation.\nNow I understand. I will try contribute this project when i understand fully.\nThanks again.. ",
    "adrianheine": "Sure, in test/serializer/basic/?. Sorry for the delay, but I'm having a really hard time writing that test. I understand what the test runner is doing, but I don't know how I could test for such an issue. Since the test runner executes the code, I cannot just declare an abstract global function, it has to be really there, but how am I supposed to put it there?. Okay, I think I got it. This test should fail in current master, but pass with my patch.. ",
    "nifgraup": "If prepack hangs on your code, you should definitely not put it into production.. ",
    "darrenscerri": "Ok thanks, good to know. Closing the issue then.. ",
    "kabirbaidhya": "Nice. BTW, do we have a roadmap or milestone set about what features are going to be implemented for the first stable release eg: v1.x.x and when that is expected to be?. Great. Anyway, I'm looking forward to using this in our regular dev workflow as soon as this is stable and production-ready. For now, I think a milestone/roadmap with expected features for the next stable version in the website/github would be helpful.. Great. Thanks :+1: . ",
    "solodynamo": "Which browser you are using ? as it seems to be in correct place in mine.. Yeah it is ..got the issue and have solved, submitting a PR for it.. Yeah sure , working towards it.. Have pushed the upgrades so now top bar stays fixed while scrolling .. ",
    "jacktuck": "One metric to follow would be its version, probably worth waiting for v1. Currently at 0.2.1-alpha.0. What about ReDOS? Could that path be optimized?\nhttps://www.owasp.org/index.php/Regular_expression_Denial_of_Service_-_ReDoS. I think this is being tracked already #632 \nThe crux of the issue being that Prepack only optimizes code that gets executed along the global code path. ",
    "matheusml": "Is this the same reason why I'm getting this error:\n'import' and 'export' may appear only with 'sourceType: module' (112:0)\nSyntax Error\nwhen trying to prepack a ES module file?. ",
    "leocavalcante": "\nwhich are not allowed to have import or export statements\n\nI think its just not implemented yet. Hacked into sourceType argument, it is a hard-coded script string, but clearly an open space for module comes in eventually. There is already type declarations its missing an evaluator.. Workaround for now seams to be calling __residual:\ninput\njs\nconst foo = 'foo'\n__residual('object', e => module.exports = e, {foo})\noutput (repl)\n```js\n(function () {\n  function _0(e) {\n    return module.exports = e;\n  }\nvar _1 = {\n    foo: \"foo\"\n  };\nvar _$0 = _0(_1);\nif (typeof $0 !== \"object\" && typeof $0 !== \"function\" || $0 === null) {\n    throw new Error(\"Prepack model invariant violation: \" + $0);\n  }\n})();\n```\ntest\njs\nconst { foo } = require('./foo.js')\nconsole.log(foo) // foo\n\u26a0\ufe0f Just a hacky way to play around, you shouldn't be using Prepack right now.. @deltaidea Yeah, definitely do not worth it for such small code like exporting a string.\nIMHO, Prepack is only specially suited for bundles, because it can't predict what will be called from the public API of a module if it not gets the clients using this module. But, of couse, probably in the near future it would be able to static analyse import/require calls from a entry point (and maybe already generate the bundle? Good bye Webpack?) Let's see.. ",
    "Davidherrmann": "@JoelMarcey . X. A.",
    "wychen": "This self-erasing pattern is used a lot in the JS code generated by GWT. This bug makes prepack unusable to reprocess the output of GWT.. @nicolo-ribaudo I think it's always a step forward to send it out and get some peer feedback.. ",
    "nicolo-ribaudo": "Hi, would a pull request for this bug be accepted?. This is what I think could solve this issue:\nI noticed that inside Serializer#_spliceFunctions() prepack generates a new identifier for every modified value. (Line 1254)\nNon-primitive values (e.g. objects and functions) are serialized by reference (identifier) instead of value, so it gets generated a new identifier whose value is a reference to the old one.\nThis is noticeable when compiling this code:\n```js\n(function() {\n  var obj = {\n    fn() {\n      obj = { fn() {} };\n    }\n  };\ninspect = () => obj.fn();\n})();\njs\n(function () {\n  function _0() {\n    return $0.fn();\n  }\nfunction _2() {\n    $0 = {\n      fn() {}\n};\n\n}\nvar _1 = {\n    fn: _2\n  };\n  var $0 = _1;\n  inspect = _0;\n})();\n```\nDo you see that the object is defined as _1 and then aliased to $0? This is not a problem for objects, but it yelds problems when it happens for a function (because the function call references the function's original name).\nThe solution I propose is to not alias these values (e.g. use _1 instead of $0), so that the issue doesn't happens. What do you think about this approach?. ",
    "samwgoldman": "What about using __proto__ in the object initializer, as described in the ES2015 spec. AIUI, this is non-standard before ES2015, but was standardized because everyone seems to support it.. Sounds like __proto__ in the initializer is a non-solution :). ",
    "jtenner": "Sorry to be selfish and ask, but I would love to start testing out this software with my babel plugin. Is there any way to test out these changes?. Just wanted to clarify if the changes were already made or if I needed to install a specific branch to try them out. Turns out they are already working! Thank you!\nIt's taking my input:\n```javascript\nlet x = \n\n\n\n;\nx({ x: 100, y: 101 });\n```\nTurning it into...\n```javascript\n//the following code helps prepack determine what gets output\n let log = function(type, args) {\n    console.log(type, args);\n  };\n  let ctx = __abstract({ \n    save: function() { log(\"save\", [].slice.call(arguments)) },\n    canvas:{},\n    setTransform: function() { log(\"setTransform\", [].slice.call(arguments)) },\n    fillText: function() { log(\"fillText\", [].slice.call(arguments)) },\n    restore: function() { log(\"restore\", [].slice.call(arguments)) }\n  }, \"_ctx\");\n//start what was output by the babel plugin\n  let x = function _inline(props, _ctx, _state) {\n  _ctx.save();\n  _state = _state || {};\n  _state.initiailTransform = _state.initiailTransform || [1, 0, 0, 1, 0, 0];\n  let _stack = new Float64Array(6000);\n  _stack.set(_state.initiailTransform || [1, 0, 0, 1, 0, 0]);\nlet _cache;\nlet _index = 6;\n  let _nextIndex = 6;\n  _nextIndex = _index + 6;\n  _cache = [props.x, props.y];\n  _stack[_nextIndex - 6] = _stack[_index - 6];\n  _stack[_nextIndex - 5] = _stack[_index - 5];\n  _stack[_nextIndex - 4] = _stack[_index - 4];\n  _stack[_nextIndex - 3] = _stack[_index - 3];\n  _stack[_nextIndex - 2] = _stack[_index - 2] + _stack[_index - 6] * _cache[0] + _stack[_index - 4] * _cache[1];\n  _stack[_nextIndex - 1] = _stack[_index - 1] + _stack[_index - 5] * _cache[0] + _stack[_index - 3] * _cache[1];\n  _index = _nextIndex;\n_ctx.setTransform(_stack[_index - 6], _stack[_index - 5], _stack[_index - 4], _stack[_index - 3], _stack[_index - 2], _stack[_index - 1]);\n_ctx.fillText(\"Hello World!\", 0, 0);\n_index -= 6;\n_ctx.restore();\n};\nx({ x: 100, y: 100 }, ctx);\n```\n...and turning into something incredible.\njavascript\nconsole.log(\"save\", []);\nconsole.log(\"setTransform\", [1, 0, 0, 1, 100, 100]);\nconsole.log(\"fillText\", [\"Hello World!\", 0, 0]);\nconsole.log(\"restore\", []);\nI can't believe what I am seeing.. ",
    "jamesgpearce": "\ud83d\udc53 . ",
    "iHaiduk": "When the prepack plug-in is turned off, the build shows the following code(34992:71) :\n```\n/ 697 /\n/***/ (function(module, exports, webpack_require) {\n// 26.1.6 Reflect.get(target, propertyKey [, receiver])\nvar gOPD           = webpack_require(48)\n  , getPrototypeOf = webpack_require(49)\n  , has            = webpack_require(39)\n  , $export        = webpack_require(3)\n  , isObject       = webpack_require(21)\n  , anObject       = webpack_require(12);\nfunction get(target, propertyKey/, receiver/){\n  var receiver = arguments.length < 3 ? target : arguments[2]\n    , desc, proto;\n  if(anObject(target) === receiver)return target[propertyKey];\n  if(desc = gOPD.f(target, propertyKey))return has(desc, 'value')\n    ? desc.value\n    : desc.get !== undefined\n      ? desc.get.call(receiver)\n      : undefined;\n  if(isObject(proto = getPrototypeOf(target)))return get(proto, propertyKey, receiver);\n}\n$export($export.S, 'Reflect', {get: get});\n/***/ }),\n```\n\nAfter I decided to try to start the prepack of an already compiled but not minifined project:\n$ prepack bundle.js --out bundle-prepack.js\nAnd I have next:\n\nwebpackJsonp is not defined\nReferenceError\n    at bundle.js:11:8\n    at webpackUniversalModuleDefinition (bundle.js:7:11)\n    at bundle.js:1:1\n\nSource:\n\nP.S. I know what prepack is young but will be cool if it will can work with webpack. This really fixes the bug with webpackJsonp is not defined, but this test was performed for the unpacked version.\nAs for further work, I received such an answer:\n$ prepack bundle.js --out bundle-prepack.js --trace\n[calls] >partial evaluation\n[calls] <partial evaluation\n[calls] >partial evaluation\n[calls] <partial evaluation\n[calls] >__abstract(\"function\")\n[calls] <__abstract\n[calls] >partial evaluation\n[calls] <partial evaluation\n[calls] >partial evaluation\n[calls] <partial evaluation\n[calls] >__assumeDataProperty((some object), \"webpackJsonp\", (some abstract value))\n[calls] <__assumeDataProperty\n[calls] >partial evaluation\n[calls] <partial evaluation\n[calls] >partial evaluation\n[calls] <partial evaluation\n[calls] >TypeError(\"not an object\")\n[calls] <TypeError\n[calls] >partial evaluation\n[calls]   >partial evaluation\n[calls]   <partial evaluation\n[calls]   >partial evaluation\n[calls]   <partial evaluation\n[calls]   >[Symbol.hasInstance]((some object))\n[calls]   <[Symbol.hasInstance]\n[calls] <partial evaluation\n[calls] >partial evaluation\n[calls] <partial evaluation\n[calls] >partial evaluation\n[calls] <partial evaluation\nnot an object\nTypeError. ",
    "mehmetkose": "another same InitializationError issue within Gulpjs. ",
    "SalomonSmeke": "edited reason: irrelevant, red herring.. ",
    "7tomir7": "\u0421\u043f\u0430\u0441\u0438\u0431\u043e \u043d\u043e \u0443\u043c\u0435\u043d\u044f \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430 \u0441 \u0432\u043b\u0430\u0434\u0435\u043d\u0438\u0435\u043c \u0438\u043d\u043e\u0441\u0442\u0440\u0430\u043d\u043d\u044b\u0445 \u044f\u0437\u044b\u043a\u043e\u0432.\ud83d\udee1\u270c\ud83d\udee1\n\u041e\u0442\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u043e \u0441\u043e \u0441\u043c\u0430\u0440\u0442\u0444\u043e\u043d\u0430 Samsung Galaxy.\n-------- \u0418\u0441\u0445\u043e\u0434\u043d\u043e\u0435 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0435 --------\n\u041e\u0442: Facebook Community Bot notifications@github.com\n\u0414\u0430\u0442\u0430: 07.05.2017 16:09 (GMT+03:00)\n\u041a\u043e\u043c\u0443: facebook/prepack prepack@noreply.github.com\n\u041a\u043e\u043f\u0438\u044f: Subscribed subscribed@noreply.github.com\n\u0422\u0435\u043c\u0430: Re: [facebook/prepack] I add demo record functionality to the website (#592)\nThank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHubhttps://github.com/facebook/prepack/pull/592#issuecomment-299705395, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AbLCjkADxLvWkUQZJ0zSTQ5hxsgOY9SMks5r3cKjgaJpZM4NTI7O.\n. \ud83d\udee1\ud83d\udee1\ud83d\udee1\ud83d\udee1\ud83d\udee1\ud83d\udee1\ud83d\udee1\ud83d\udee1\ud83d\udee1\n5 \u0418\u044e\u043d 2017 \u0433. 20:51 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c Nikolai Tillmann notifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\nYou still need to rebase on the latest serializer.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHubhttps://github.com/facebook/prepack/pull/643#issuecomment-306256748, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AbLCjmrqmPnJ6PxMatXWhxQe3CTxdtvzks5sBEAqgaJpZM4NbeQR.\n. ",
    "sheweichun": "I removed test/test262 and had merged with prepack/gh-pages branch. I recommit again,but it show no test commands were found,in fact, there isn't package.json. ",
    "JoshuaGross": "@NTillmann And thanks to the core team for making it so easy to get involved!. ",
    "lxzxl": "You need to wrap it in a IIFE.\n```javascript\n(function() {\n  var a = [1,2,3,4,5,6]; for(var i=0;i<a.length;i++){ console.log(a[i]); }\n})();\n// result\nconsole.log(1);\nconsole.log(2);\nconsole.log(3);\nconsole.log(4);\nconsole.log(5);\nconsole.log(6);\n. ",
    "osterbergmarcus": "I would like to take a stab at this one. With the new repl record feature do we still want to show a set of example code?\nIf so I'll have to update the current UI on my PR https://github.com/facebook/prepack/pull/638. Sounds good, I will look into it.. any ideas why CI fails?. ",
    "abhisheksoni27": "Can I work on this? :tada:. Oh, I see. I have read that in the literature, but yes, you are right. It's better to surround it with braces in cases where it might lead to confusion. You can close this if you are gonna send a PR. (Or should I? :confused:). All right. I'll send a PR right away. . @cblappert How will we add eslint to the editor? I don't think it's available as a JS file, is it? . Oh. Now it makes sense. We could do that. Have you heard of standard.js? And Prettier?. Arghh! I don't know why these previous commits are showing here, even though the difference is fine. Should I make a new branch and then a new PR?. @cblappert Great! Also, is there a better way to bring my repository up to terms with the upstream branch other than git fetch upstream && git merge upstream/BRANCH_NAME && git push origin BRANCH_NAME ? :thinking: . @dulinriley Thanks a lot! git pull origin upstream did the trick. :tada:. I changed that for testing. Forgot to change it back. :frowning: . ",
    "thelgevold": "That's very cool. Thanks for sharing.. ",
    "seanpan": "Awesome! It works with 0.2.2-alpha.0 build. Although the output is really large (almost twice). It seems an extra optimization is necessary.\nThanks for your comment.. ",
    "ilyaigpetrov": "I still don't get it.\nLet's imagine there is an object global.leftUserEye = { color, ... } which is known only at runtime.\nLet's take that I run Prepack on a script that accesses global.leftUserEye somewhere in the code, but not everywhere -- so we have space for a compile-time optimization.\nI want Prepack to optimize script, but transfer all interactions with global.leftUserEye to output intact.\nWhy I can't tell Prepack to leave global.leftUserEye intact, why I have to shim it?\n. Ok, side effects from accessing window.* make optimization uneasy:\njs\n'use strict';\nlet foo = `Pi is ${ calculatePi({ precision: 99999 }) }`;\nconsole.log(window.document); // May change the value of `foo` as a side effect!\nconsole.log(foo); // Can we use optimized `foo` here? You never know.\nIt means Prepack is difficult to use with functions without source codes, because Prepack can't know if they have side effects.\n\n\nIdeally I want to be able to tell Prepack: \"Accessing object foo.* may only change vars X and Y and it can't have any other side effects\". But I think I ask too much yet.\n\n\nNow I want to lie to Prepack by telling that window.* has no side effects:\njs\n'use strict';\n__residual('object', function() {\n  console.log(window.document);\n  return {};\n});\nGives:\nconsole\nresidual function at ./p.js:3:33 refers to the following identifiers defined outside of the local scope: console, window\nHow to tell Prepack that window.* is free of side effects with all it props of any depth (even if it isn't)?. \n\n",
    "a1astair": "This has been addressed in #569 but this request is adding on the footer to the getting started page. Re-opening as the previous issue is for the index.html and not the getting-started.html. ",
    "artiebits": "https://github.com/facebook/prepack/pull/710. | Prettier option | ESLint equivalent in the existing eslint settings\n| ------------- | ------------- | \n| --print-width 120  | |\n| `--tab-width 2`  | |\n| --use-tabs false  | \"no-tabs\": 2 |\n| --semi true  | \"semi\": 2 |\n| --single-quote false (Quotes in JSX will always be double) | ` |\n|--trailing-comma none|\"comma-dangle\": 0|\n|--bracket-spacing true(spaces between brackets in object literals) |\"object-curly-spacing\": [2, \"always\"]` |\nAs a result:\n```\noptions = {\n  \"print-width\": 120,\n  \"tab-width\": 2,\n  \"use-tabs\": false,\n  \"semi\": true,\n  \"single-quote\": false,\n  \"trailing-comma\": \"none\",\n  \"bracket-spacing\": true\n};\nIf that looks good I can update Prettier options in this branch.\nAbout the master branch, I used `eslint-config-prettier-check` to find rules that are unnecessary or might conflict with prettier:\n- array-bracket-spacing\n- brace-style\n- comma-spacing\n- comma-style\n- computed-property-spacing\n- eol-last\n- flowtype/generic-spacing\n- flowtype/space-after-type-colon\n- flowtype/space-before-generic-bracket\n- flowtype/space-before-type-colon\n- flowtype/union-intersection-spacing\n- func-call-spacing\n- jsx-quotes\n- key-spacing\n- keyword-spacing\n- new-parens\n- no-extra-semi\n- no-mixed-spaces-and-tabs\n- no-spaced-func\n- no-trailing-spaces\n- object-curly-spacing\n- semi\n- semi-spacing\n- space-in-parens\n- space-infix-ops\n- space-unary-ops\n``\nI am not sure that we can switch off ESLint rules because we will lose rules about headers. React team didn't switch off ESLint rules as well when added Prettier rules. Any ideas? . @wdhorton good to see your PR! It's a luck that most of Prettier options consistent with the Prepack ESLint settings but I decided to keep all options just in case if default value of some Prettier option will change in the future.. Updated Prettier options to consistent with the main branch.. Hi, can you assign it to me, please? \nI\u2019ve added the version as a command line option but confusing about__prepackVersion. Can you explain me your vision of these feature? I have an idea to implementprepackVersioninprepack-standalone.js` that will be reachable from Prepack object:\n{ \n  prepackVersion: [Getter],\n  prepackNodeCLI: [Getter],\n  prepackNodeCLISync: [Getter],\n  InitializationError: [Getter],\n  prepackSources: [Getter],\n  prepackString: [Getter],\n  prepack: [Getter],\n  prepackFromAst: [Getter],\n  prepackStdin: [Function: prepackStdin],\n  prepackFile: [Function: prepackFile],\n  prepackFileSync: [Function: prepackFileSync] \n}\nto use it like this:\nvar Prepack = require(\"prepack\");\nconsole.log(Prepack.prepackVersion)\nIn that way we also can get and display the version on the website.\nBut what is your vision?. @j-nolan nice job! \nRelay and Jest use Docusaurus to generate their websites from website and docs directories, but unfortunately it isn\u2019t officially public yet. And there is a lot of work to do if you want to refactor the current site in that way. And also Relay and Jest don\u2019t have playgrounds like Prepack has.\nI am not so experienced in bash scripting but is it possible to not store prepack.min.js and just generate it for gh-pages? \nAlso maybe it's better to remove tether.min.js and etc. from repo and just import them into html files as external resources.. @j-nolan It's here https://cdnjs.com/libraries/tether-select. \nSo, we can remove tether, select and select-theme-dark from the repo.. You are welcome!. The reason is that the graph which returns from Prepack.prepackSources contains edges array with duplicate ids. Take a look at this example that filter edges http://jsbin.com/ralaxibici/edit?js,output. If so I can use my filterEgdes function for the website.. ",
    "sanex3339": "As require() calls. It's standard behaviour for many npm packages.. ",
    "wdhorton": "I'd like to try tackling this issue!. @sebmarkbage I think I'm most of the way there with #669\u2014I've manually confirmed that the basic behavior is working in the REPL. I just need to dig into the test262 results and potentially adjust for edge cases, planning on doing that today.. So I'm looking through the test262 results, and I've run into some behavior that I can't understand.\nThe code is failing the test default-constructor-2 with this message:\n\u2717 (es6) (strict): default-constructor-2.js\n        Got an error, but was not expecting one:\n        Interpreter: Thrown value was not an object!\n        Native: Error\n            at new ThrowCompletion (/home/ubuntu/prepack/lib/completions.js:74:41)\n            at exports.default (/home/ubuntu/prepack/lib/evaluators/ThrowStatement.js:10:9)\n            at LexicalEnvironment.evaluateAbstract (/home/ubuntu/prepack/lib/environment.js:1309:16)\n            at LexicalEnvironment.evaluateAbstractCompletion (/home/ubuntu/prepack/lib/environment.js:1197:21)\n            at EvaluateStatements (/home/ubuntu/prepack/lib/methods/function.js:1468:28)\n            at exports.default (/home/ubuntu/prepack/lib/evaluators/BlockStatement.js:51:12)\n            at LexicalEnvironment.evaluateAbstract (/home/ubuntu/prepack/lib/environment.js:1309:16)\n            at LexicalEnvironment.evaluateAbstractCompletion (/home/ubuntu/prepack/lib/environment.js:1197:21)\n            at OrdinaryCallEvaluateBody (/home/ubuntu/prepack/lib/methods/call.js:346:58)\n            at InternalCall (/home/ubuntu/prepack/lib/methods/function.js:958:14)\nIf you look at where the message \"Thrown value was not an object!\" comes from in the harness, you find it in the definition of assert.throws:\n```js\nassert.throws = function (expectedErrorConstructor, func, message) {\n    if (typeof func !== \"function\") {\n        $ERROR('assert.throws requires two arguments: the error constructor ' +\n            'and a function to run');\n        return;\n    }\n    if (message === undefined) {\n        message = '';\n    } else {\n        message += ' ';\n    }\ntry {\n    func();\n} catch (thrown) {\n    if (typeof thrown !== 'object' || thrown === null) {\n        message += 'Thrown value was not an object!';\n        $ERROR(message);\n    } else if (thrown.constructor !== expectedErrorConstructor) {\n        message += 'Expected a ' + expectedErrorConstructor.name + ' but got a ' + thrown.constructor.name;\n        $ERROR(message);\n    }\n    return;\n}\n\nmessage += 'Expected a ' + expectedErrorConstructor.name + ' to be thrown but no exception was thrown at all';\n$ERROR(message);\n\n};\n```\nAnd the relevant code from the failing default-constructor-2 test:\njs\nclass Base1 { }\nassert.throws(TypeError, function() { Base1(); });\nBut when I run that same code manually in the REPL I get:\n```\n\nclass Base1 {}\nundefined\nlet func = function () { Base1() }\nundefined\nfunc()\nError: TypeError\n    at serialize (/Users/William/Desktop/prepack/lib/repl-cli.js:46:15)\n    at REPLServer._eval (/Users/William/Desktop/prepack/lib/repl-cli.js:67:13)\n    at bound (domain.js:280:14)\n    at REPLServer.runBound [as eval] (domain.js:293:12)\n    at REPLServer.onLine (repl.js:536:10)\n    at emitOne (events.js:96:13)\n    at REPLServer.emit (events.js:191:7)\n    at REPLServer.Interface._onLine (readline.js:241:10)\n    at REPLServer.Interface._line (readline.js:590:8)\n    at REPLServer.Interface._ttyWrite (readline.js:869:14)\n```\n\nSo it seems like it's throwing a TypeError, which should pass the test.\nAfter some experimenting, I think the issue comes down to this:\n```\n\nclass Base1 {}\nundefined\nlet func = function () { Base1() }\nundefined\ntry { func() } catch (err) { console.log(typeof err) }\nstring\n```\n\nSo my question for someone who knows more about how the error throwing behaves: is the test failing because the code is throwing a string rather than an object? Or does it just appear that way in the repl because it's serializing err?. I looked into another failing test, prepack/test/test262/test/language/statements/class/subclass/class-definition-null-proto-this.js, and found this note:\nThe behavior under test was introduced in the \"ES2017\" revision of the\n  specification and conflicts with prior editions.\nYou can see from the MDN docs that previously you couldn't instantiate a class that extended null:\n```\nclass nullExtends extends null {\n  constructor() {}\n}\nObject.getPrototypeOf(nullExtends); // Function.prototype\nObject.getPrototypeOf(nullExtends.prototype) // null\nnew nullExtends(); //ReferenceError: this is not defined\n```\nThe spec linked in this issue was the 6.0 (2015) version, but should I have been working off a more recent one?. @sebmarkbage thanks for tracking that down!. @sebmarkbage what's next in terms of getting classes working in prepack? would love to keep working on this. I ignored all the failing test262 tests with super when I implemented ClassDeclaration, so maybe I can work on getting super supported?. @sebmarkbage I got super working via #762 and #764. Could you give me some examples of what serialization of classes should look like, so I know the right direction to go? Like, for example, say you have this code:\n```js\n(function() {\n  class Foo {\n    constructor(x) {\n      this.x = x;\n    }\n  }\nglobal.foo = new Foo(5);\n})();\nHow should that be serialized? Does it change if we add a method to the class? And what does it mean to preserve `super`? There's obviously a lot of complexity here, just want to be sure I don't head too far down the wrong track from the outset. I think this behavior is correct, right? Per the spec, you can only use 'import' and 'export' in modules.. Ok! Should I go ahead and submit a PR for that to babel?. There's a known issue with the type-checking: #661. @hermanventer can you advise on how to interpret the test262 results? some of the `class` behavior will fail because `super` isn't working yet, not sure if that's in scope or out of scope for this initial PR.. Happy to help with this one! I just moved over a large codebase at my job to Prettier.. @NTillmann do you have a preference on max line length? Doesn't look like there's one specified for the project.. @archiekh In my PR (#729) I followed what the React team did and didn't turn off ESLint rules unless they directly conflicted with the prettier formatting. I think that's the right way to go.. I also think that in your options, you could leave out most of the values because they correspond to the prettier defaults:\noptions = {\n  \"print-width\": 120,\n  \"tab-width\": 2,\n  \"use-tabs\": false,\n  \"semi\": true,\n  \"single-quote\": false,\n  \"trailing-comma\": \"none\",\n  \"bracket-spacing\": true\n};\ncould just be:\noptions = {\n  \"print-width\": 120\n};\n``. That makes sense to me!. I can tackle this one. Well, this is failing on theprettier-ci-check`, so I guess we know that works too.. Just made the updates. @cblappert I checked the tests and updated the number of expected passing. There's no spec section, I just pulled it out as a convenience method because I was having trouble getting the evaluation of ClassHeritage to return the right thing. Thought I saw a similar pattern elsewhere in the codebase but I can't seem to find it now. Should I move it back inline? . fixed. Added the section number. got it!. fixed!. ",
    "bakkot": "What needs to be done for this to happen? Is this something someone from outside the project but with a good grasp of static analysis and JavaScript semantics could reasonably help progress?. Thanks for the response!\nI'm happy to go add a little dead-code elimination logic. I've already been doing a similar thing in a personal project (actually, that's what made me want to look at Prepack, and this issue is what stopped me from using it). But in practice, in my experience, I think it's not going to do all that much without also doing at least a little constant folding and propagation - at least in my samples I ran into at least as many cases like if (1 === 2) as if (false).\nOf course, it's easy enough to transform 1 === 2 too, but at that point it starts getting into the territory of the partial evaluator, which would be a much better solution anyway.\nWhat would be the appropriate place to add dead code elimination? I could do it in ClosureRefReplacer, looks like, but that doesn't feel like the right place.\n\nRe: the partial evaluator approach, in particular\n\nstarting from a \"havoced state\" where nothing is known, except for those known constants I mentioned earlier\n\nI would love it if it were possible to assert some initial conditions - for example, no new properties on Object.prototype or Array.prototype. For many applications, consumers might be comfortable relying on invariants like those, and transformation could get a lot further. . This is related to #632, I suppose.. Ah, one sec, just realized I overlooked a case.... OK, updated. Should be good to go.\nI forgot (class { [foo()](){} } exists, and might be side-effecting, which makes classes with bodies not safe to treat as literals.\nThere is an absurd number of expression positions in JavaScript.. Sure, done. This is getting further and further into the realm of partial evaluation, though - for example, I'm considering [] to be truthy, but not [0] (because I don't want to eliminate [sideEffect()], and don't have a 'isPossiblySideEffecting' function on hand).. Done.. Added a test. I'm not super happy with these tests, though - there doesn't seem to be a good way of asserting the precise shape of the output. For example, I can assert that [] || 'eliminate' prepacks into something not containing 'eliminate', but not that it actually ends up as [], which is an important property to preserve.\nHave you considered adding snapshot tests? For example, the prettier project uses them almost exclusively, to great effect. It makes it easy to see what the impact of a change is over a large range of code.. I didn't add any tests for this, mind, because I didn't see a good way to fit it into the existing test framework. Same for reducing do { foo } while (false) to { foo }.. This is true. I could also handle !false, +0, [0, true], void void [ +!'a', { foo: 0, get bar(){ return whatever(); } } ], typeof /a/, and so on. But one could go a long, long way down this road, and I think it probably makes sense to do the remainder of that work as part of partial evaluation, rather than in an ad-hoc way here.. I generally figure the cost of this sort of object allocation is worth the additional readability, at least in modern engines. v8 at least is pretty good at optimizing the creation and use of this sort of object.. I'm not sure how. I don't know what assertion I can make about them, given the current test framework.\n(I'd love to have snapshot tests...). Sure, done.. ",
    "BrodaNoel": "\n. ",
    "dekwi123": "Noreply. ",
    "pablo9503": "Cantidad YouTube velo me fixit. El 19/06/2017 21:07, \"Facebook Community Bot\" notifications@github.com\nescribi\u00f3:\n\n@NTillmann https://github.com/ntillmann has imported this pull request.\nIf you are a Facebook employee, you can view this diff on Phabricator\nhttps://phabricator.intern.facebook.com/D5282069.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/prepack/pull/741#issuecomment-309639233, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AbPGV_Ff0F5sgpnkT36fBDbOYR-O_8ktks5sF0V9gaJpZM4N_BKn\n.\n. \n",
    "abullrd": "Thanks for the feedback Chris! I had tried using AreSameSerializedBindings, but its implementation seems to check reference equality, which fails for the serializedBindings of each instance. For example, given the example in #494, \nlet instance0 = functionEntry.instances[0];\nlet instance1 = functionEntry.instances[1];\nAreSameSerializedBindings(instance0.serializedBindings.l, instance1.serializedBindings.l) // => false\nThough they both refer to the same let l = 1; expression in f. Maybe I am on the wrong track, but my understanding is that we can only combine function instances that share modified bindings.. That would be sweet @NTillmann! Chris helped me find a failure w/ the current implementation regarding closures that I'm hoping to fix up soon, I may be able to squeeze that in at the same time.. Haha just ran into this after I got my tests working :) Planning on\nrebasing and updating this PR soon. Sorry for the long delay!\n. Updated w/ fixes for nested scopes calling each other, of particular interest see tests CapturedScope3.js and CapturedScope6.js. New output looks like\n```\n  function $_1(__scope_1, __scope_0) {\n    if (!__captured_scopes[__scope_1]) __captured_scopes[__scope_1] = {\n      valueC: 10\n    };\n    if (!__captured_scopes[__scope_0]) __captured_scopes[__scope_0] = {\n      valueA: 1\n    };\n    __captured_scopes[__scope_1].valueC++;\n    return __captured_scopes[__scope_0].valueA * __captured_scopes[__scope_1].valueC;\n  }\nvar _6 = $_1.bind(null, 3, 1);\n```\nA few thoughts:\n\n\nI determine the scope id to bind to using the DeclarativeEnvironmentRecord of the binding. This changed slightly with the new ResidualHeapVisitor, perhaps there is a better way to be doing this?\n\n\nAlso w/ those changes all nested bindings now seem to be available in names. This seems good in general but means that we don't split scopes around usage and may end up initializing more than necessary. I don't think this is different than the existing solution, but worth noting.\n\n\nI haven't implemented the improvement Nikolai mentioned above to eliminate all clones. I don't think it would be too difficult but wanted to get thoughts on this first.. Updated and rebased. Hey! I was just reading through recent PRs and noticed this. I believe that null should be retained in this case. The node.js callback convention is to use a function (error, result) signature. See here for example. I know its weird to pass an explicit null, but seeing callback calls like that in node is not as unusual as you might think :). Yep! A typical node flow looks something like\n\n\nfoo(function (error, result) {\n  if (error) {\n     console.error(error);\n     return;\n  }\n  // do something\n});. This part doesn't lint yet b/c I expect it to change, see my comments above. Updated, thanks for the hints!  I added this line so I could test against the output of statistics, any ideas about the right way to get access to this from test-runner?. Cool, thats what I was doing, just wanted to make sure no one would get upset about the changed return structure. I updated the code to make the construction a little cleaner here, let me know if there are other things I should improve in this pr!. Yeah, I forgot to remove this from an earlier iteration i was playing around with. Fair enough!. ",
    "ryaninvents": "This is a great idea! I'd suggest perhaps that this not be the only plugin mechanism available; I'm having trouble picturing how one would use this to trace value flow through a program. For instance, imagine marking places where user input is accepted, tracing its flow, and ensuring that it is SQL- and HTML-sanitized before being used in a database call. This information could then be logged or passed to some sort of linter.\nI'm interested in discussing plugins of this nature, so if I should open a new issue for that conversation please let me know.. @sebmarkbage Point taken with regard to Prepack only tracking a single code branch at a time. \nThanks for the link to 444. \"Poisoned\" values seem exactly like what I was describing, but I was using that as a specific example of a general pattern: tagging values with arbitrary metadata and using that metadata as the information flows through the system. The discussion over there describes \"tagging\" values in a way that matches what I had in my head.\nAfter thinking a bit more on what I was trying to say, it seems like the plugin API proposed here would work perfectly. Take for example showing documentation in your IDE on mouseover. Given the following file (pardon the pseudocode):\n```js\nimport uuid from 'uuid';\nconst id = uuid.v4();\n```\nIf the cursor were over the id declaration, it could run a Babel transform and create:\n```js\nimport uuid from 'uuid';\nconst id = uuid.v4();\n__emitDocumentation(id);\n```\nWhich would return an HTML snippet of the uuid.v4 documentation to the IDE.. ",
    "Kishore-B-Rao": "See Profiling #714 for continuation of this pull request. I began my investigation of implementing es6 generators in prepack but unfortunately ran out of time. Attached is a word document capturing my thoughts and notes for how to go about implementing it for the next person. Hope this helps!\nGenerators.docx\n. The profiling summary can be extracted from all the other output by piping output into grep \"\\[Profiling\\]\". The first issue was that when using the string \"void\" for residual functions it would return undefined instead of UndefinedValue for the type. What is the reason for removing \"undefined\" case? It may be used by other portions of the code which would then crash?. Yes this was left over from the original test case that I refactored, I will change this!. The test was essentially to avoid crashing so I will remove x.. Hmm this particular ternary expression is only used in derive and emitVoidExpression in this file...do you still think its work making a helper function for the two instances or am I overlooking some other use cases?. I removed the undefined case and it still passes all the test cases so it must have been extraneous. Good catch. Yes just to illustrate a void function that does something but doesn't impact the heap\n. Yes you are right...I will redo it with __residual_unsafe calling __residual with an added argument.. Hmm that should have should up on my linter...will fix!. Yes I can add that to this pull request as well but I thought the idea was to separate this from serializing the symbols (PR #833). I believe that ToStringPartial expects a concrete value:\nreturn ToString(realm, typeof val === \"string\" ? val : val.throwIfNotConcrete());\n. So do you think that the description can never be undefined? In src/intrinsics/ecma262/Symbol.js lines 29/30 it appears that we are allowing for the case where the description is undefined.. Yes otherwise it complains on the next line. Sounds good\n. good catch i will just change it to be description instanceof Value. ",
    "xtuc": "We can backport that change in Babel 6. . coucou :wave: . ",
    "anywhichway": "Thanks for the prompt reply. Close if you wish. Or leave open for others to see. I would assist, but the type of comp sci analysis of code required is beyond my capabilities.. ",
    "hershi": "Addressed by #698 . For the type signature - the newest revision includes that\nFor the testing aspect, I've created issue #693 to track it, and will tackle it once I'm done with #675. Hi @abullrd - thanks for pointing this out. I'm a JS noob, so not too familiar with node conventions and whether this was the intention here or not.\nIf I understand you correctly, you're saying that the convention of using function (error, result) is so that the same handler can handle both error and success cases by inspecting which of the arguments is valid, right?\n@hermanventer, @cblappert can probably better attest to whether that was the intention of the original code, in which case, this can be reverted.. Thanks for catching this and providing the details @abullrd . I created #706 with a fix - please let me know if that captures your intention or if I missed anything.. After further discussion with Herman, we decided to:\n1. Focus this change on the public-facing API and hone the type definitions there\n2. While we introduce the notion of recovery in the API (specifically, in the handler return value), not implement recovery anywhere in the code yet\n3. Implement calling to the handler in a single location in the code as a sanity check for wiring the API (but, further to no. 2 above, fail in that location, regardless of handler result)\nNext iteration will reflect the above. Added the test runners and validated that it runs in both the local run (npm run test) and in the circleCI report.. @hermanventer, @cblappert , any comments, or shall I just merge the code?. By mistake. But I removed it altogether now based on your other comment. Will stop by to discuss. I thought we wanted to limit it to that for now, no? It's true that we may want to handle other errors in the future, but would be hard to write generic code to convert them to native. We can adjust this handler as needed in the future, since it's not used by the external client (that is abstracted in the NativeError).. The comment was an accidental remnant from when I was trying to model the helper function.\nRegarding the helper function, my goal was to avoid requiring overly verbose code, since the way the code is currently structured relies on exceptions - which means that something is bad from above would translate into a try-catch\nMy original version had that try-catch explicitly in the code, and I introduced the helper function to make it easy to add support for more recoverable errors. I'm open to suggestions regarding other ways to handle this, or if you think writing the verbose version of the code wherever we want to enable handling recovery would be more fitting.. The fact that its data lives in the context of prepack/the caller rather than the context of the program being run.\nI've changed it to ProgramEvaluationError, though I'm not sure if that's much better... let me know if you have suggestions for a better name. Based on discussion with Herman, the plan is to focus this change on introducing the mechanism needed for recovering from errors, while leveraging it in specific places where we want to support recovery will be done separately (and probably gradually).\nUsing the new mechanism in this location is intended to:\n1. Serve as a sanity check + usage example\n2. Allow for testing (I'm working on the tests and they'll be included in the next iteration of the review). \"Known\" might be a strong word, since I'm very new to JS :)\nI'm assuming that arrays behave more or less like Arrays/Vectors in other languages. If that's the case, then calling unshift n times will result in O(n^2), because for every call we are copying all the previously inserted items, where's pushing would be O(n), with reverse taking either O(n) (if it actually creates a new copy) or O(1) (if it works like an iterator adapter, though my guess was that in JS it's the former anyway), with a total complexity of O(n).\nAre my assumptions regarding JS wrong here or anything else I'm missing?. I've also run a minor benchmark and my assumptions seem to hold - considerably faster to push vs. unshift. Ah, I didn't know that bit. I'll look at restructuring it.. Done. Done. Removed. Removed. Will stop by to understand the concern better. Removed. I've changed this to be passed independently of Options in prepack-standalone, which is needed for tests.\nTo make it useful for prepack-cli or any other consumer, this will need to be added to prepack-node.js as well. It's easy to do, but since it's not very useful at the moment, I figured it's better to leave it out for now to not mess up the interface with unnecessary parameters for now. Let me know if you think otherwise and want me to introduce it there as well.. Done. Done. Done. Done. Done. ",
    "chirag04": "@NTillmann is there a better workaround that works with third party modules as well? Can we reopen this till then?. ",
    "ncave": "Thanks, it could be the node version:\n```\n\nnode ./bin/prepack.js ./test/node-cli/Simple.js --out Simple-test.js --compatibility node-cli\nPrepack's node-cli mode currently only works on Node v7.9.0.\nYou are running version v7.10.0 which will likely fail.\nnot an object\nTypeError\n    at internal/url.js:1386:29\n    at bootstrap_node.js:530:7\n    at bootstrap_node.js:471:5\n    at startup (bootstrap_node.js:59:5)\n    at bootstrap_node.js:542:3\n```. Different error on node 8.0.0:\n\n```\n\nnode ./bin/prepack.js ./test/node-cli/Simple.js --out Simple-test.js --compatibility node-cli\nPrepack's node-cli mode currently only works on Node v7.9.0.\nYou are running version v8.0.0 which will likely fail.\nC:\\Projects\\prepack\\lib\\prepack-cli.js:109\n      throw x;\n      ^\n\nTypeError: Cannot read property 'constructor' of null\n    at createDeepIntrinsic (C:\\Projects\\prepack\\lib\\intrinsics\\node\\utils.js:64:97)\n    at exports.default (C:\\Projects\\prepack\\lib\\intrinsics\\node\\process.js:32:50)\n    at prepackNodeCLISync (C:\\Projects\\prepack\\lib\\prepack-node-environment.js:78:42)\n    at prepackFileSync (C:\\Projects\\prepack\\lib\\prepack-node.js:146:59)\n    at run (C:\\Projects\\prepack\\lib\\prepack-cli.js:100:24)\n    at Object. (C:\\Projects\\prepack\\lib\\prepack-cli.js:142:3)\n    at Module._compile (module.js:569:30)\n    at Object.Module._extensions..js (module.js:580:10)\n    at Module.load (module.js:503:32)\n    at tryModuleLoad (module.js:466:12)\n```. @hermanventer Thanks, clearly it's the node version. Closing this.. ",
    "sandersky": "@hermanventer I'm guessing this isn't as simple as removing these two lines.. This brings in some of the intl402 date tests but the tests don't appear to be related to Date.parse as far as I can tell. I noticed some of the additional tests pass and some fail (all failures appear to be related to Date.Date.prototype.toLocaleString() not being  implemented).. ",
    "calebmer": "@hermanventer done. I was using a Flow global type, $ReadOnlyArray which eslint did not yet know about \ud83d\ude0a. @hermanventer At first changing all of the evaluator functions to generators should not cause a feature regression. However, I\u2019m not sure how the partial evaluator will be effected when generators are implemented in the evaluator and evaluation may be paused and resumed at any time. This is an uncertainty for any implementation of pause/suspend infrastructure though.\nWhat do you mean by \u201ccreate an iterator class for each generator function?\u201d Could you give a quick demonstration?. This is roughly how Babel transpiles generators. I\u2019m unsure how implementing a custom data structure that emulates generators would be better for performance, readability, or code path predictability. (Assuming that the only time we suspend execution is at a YieldExpression, otherwise generators only add a layer of indirection.). We don\u2019t need to worry about saving global state. If global state changes when the generator is resumed that modified global state will be used. If you\u2019re worried about managing state in the evaluator that\u2019s why generators are a really good fit. It will capture the closure state and allow us to resume using that state after calling next().\nAs for the partial evaluator/abstract stuff, I also have no idea on what will happen there \ud83d\ude23. I\u2019m confident that the refactor alone to use generators for all of the evaluators will not throw off the current logic for partial evaluation. However, once we actually start pausing/resuming evaluation when we implement generators in the evaluator not sure what side effects that will have.\nI think we may only know by trying \ud83d\ude0a\nProbably should have done this in the OP, but I\u2019m going to include a visualization of what I\u2019m thinking:\n``js\nfunction* evaluateBlockStatement(env, expressions) {\n  let lastValue = undefined;\n  for (const expression of expressions) {\n    //env.evaluate()returns a stub object. To actually evaluate\n    // we callenv.actuallyEvaluate()on the stub object returned\n    // byenv.evaluate()`.\n    lastValue = yield env.evaluate(expression);\n  }\n  return lastValue;\n}\n// Normal execution. This is the default and should not change Prepack\n// behavior. We take the stub that was yielded and actually go and\n// evaluate that.\nconst iter = evaluateBlockStatement(...);\nlet step;\nlet value;\ndo {\n  step = iter.next(value);\n  value = env.actuallyEvaluate(step.value);\n} while (!step.done)\n// Generator execution.\nconst iter = evaluateBlockStatement(...);\nlet step;\nlet value;\ndo {\n  step = iter.next(value);\n  if (step.value.type === 'YieldExpression') {\n    // Stop execution here, but save iter. When the runtime is ready to\n    // resume we can continue iterating by calling iter.next() somewhere\n    // else. All of the state is saved in the iter generator closure.\n    break;\n  } else {\n    value = env.actuallyEvaluate(step.value);\n  }\n} while (!step.done)\n```. I'm confident this approach should work for normal evaluation, but I am not fully clear on implications to abstract evaluation. It's hard for me at the moment to think about the implications without having a spec compatible generator implementation to play with.\nI can't think of a reason why this approach would never work. (Or would be too difficult as to not be valuable.) You're right, there are some complications around state in the realm, but those should be solvable.. I built a simple fuzzer to help me learn the React Compiler and what its limits are. Running my change through that fuzzer caught a bug in this program:\n```js\nconst React = require(\"react\");\n__evaluatePureFunction(() => {\n  function Root(props) {\n    return (\n      \n\n\n\n\n    );\n  }\n__optimizeReactComponentTree(Root);\nmodule.exports = Root;\n});\n```\nI fixed that bug and added a test case.\nReact.Fragment also needs to be visited in the root scope so its reference is accessible in the hoisted element initialization function.. Rebased onto #2250. Here are the two cases this diff fixes before and after.\nThe first is fixed by passing effects to joinNormalCompletions.\nThe second is fixed by refactoring replacePossiblyNormalCompletionWithForkedAbruptCompletion so that consequent/alternate code paths are symmetric. In short, it was caused by composing effects too early in the (AbruptCompletion, PossiblyNormalCompletion) code path.\nInput\n```js\nfunction fn1(arg) {\n  if (arg.foo) {\n    if (arg.bar) {\n      return 42;\n    }\n  }\n}\nfunction fn2(arg) {\n  if (arg.foo) {\n    return 1;\n  } else {\n    if (arg.bar) {\n      return 2;\n    }\n  }\n}\n__optimize(fn1);\n__optimize(fn2);\n```\nBad Ouput\n``js\nvar _1 = function (arg) {\n  return _$1 ? 42 : void 0; // <-------------_$1` is not defined\n};\nvar 6 = function (arg) {\n  var $2 = arg.foo;\nif (!$2) {\n    var $3 = arg.bar;\nif (!_$3) {\n  var _$3 = arg.bar; // <------------- `arg.bar` is defined twice, could also be `arg.bar()`\n}\n\n}\nreturn $2 ? 1 : $3 ? 2 : void 0;\n};\n```\nAfter #2250\n``js\nvar _1 = function (arg) {\n  var _$0 = arg.foo;\n  return _$0 ? _$1 ? 42 : void 0 : void 0; // <-------------_$1` is still not defined\n};\nvar 8 = function (arg) {\n  var $2 = arg.foo;\nif (!$2) {\n    var $3 = arg.bar;\nif (!_$3) {\n  var _$3 = arg.bar; // <------------- `arg.bar` is defined twice, could also be `arg.bar()`\n}\n\n}\nreturn $2 ? 1 : $3 ? 2 : void 0;\n};\n```\nAfter this diff\n```js\nvar 1 = function (arg) {\n  var $0 = arg.foo;\nif ($0) {\n    var $1 = arg.bar;\n  }\nreturn $0 ? $1 ? 42 : void 0 : void 0;\n};\nvar 8 = function (arg) {\n  var $2 = arg.foo;\nif (!$2) {\n    var $3 = arg.bar;\n  }\nreturn $2 ? 1 : $3 ? 2 : void 0;\n};\n``\n. For generators, how useful do you think it would be totoStringtheirbuildNode? So we could see the source of the function. You can kind of get an idea from_entries` but it still requires some thought.. I had assumed before this was roughly how Prepack worked.\nCould we \u201cclone\u201d the abstract result and then patch it with concrete values? Instead of reinterpreting the function.. Reverting #2274 to demonstrate the tests added in this PR pass. (Including the case added in #2274.). Finally rebased past @hermanventer\u2019s changes. These tests are fixed! We can land them as regression tests.. \u201cLots\u201d might be a bit of an exaggeration as you note, @NTillmann. More like \u201clots\u201d relative to 5% of tests that failed. A 95% pass rate is pretty good.. > What's the change in pass rate when you exclude tests that involve classes?\n95% still. I added a basic check to exclude source files that include class. ES6 passes rise from 91% to 93% though.\n=== RESULTS ===\nPasses: 16238 / 16949 (95%)\nES5 passes: 11501 / 11873 (96%)\nES6 passes: 4737 / 5076 (93%)\nSkipped: 14206\nTimeouts: 0\n\nI also opened some issues for problems I thought were actionable and not class related. (Since class serialization is known to have issues.)\n\n\n2292\n\n\n2293\n\n\n2294\n\n\nNone seem super related to React code, but #2293 might be. Haven\u2019t audited all the NativeFunctionValues this effects.. I played around a bit trying to fix some of the high firing Prepack errors to get better coverage. I got to a 31% pass rate just by fixing String(x) where x is an object value.\n=== RESULTS ===\nPasses: 5602 / 17780 (31%)\nES5 passes: 3241 / 12045 (26%)\nES6 passes: 2361 / 5735 (41%)\nSkipped: 13375\nTimeouts: 28\nNew output. Now with error messages!\nOther things I tried:\n\nNot using an abstract string in Object.defineProperty since that\u2019s the second error which fires a lot. However, the static Babel based approach I was using only worked in 1k of cases. I\u2019d rather just add support for abstract properties in Object.defineProperty. (That\u2019s non-trivial though whereas String(x) was.)\nTaking @sebmarkbage\u2019s advice to leave CallExpressions but havoc their arguments. I did this, but it only moved the pass rate by 4%. We still got throwIfNotConcrete errors from evaluator code and we run into a bunch of errors since that particular feature was designed for pure mode, but we run outside of pure mode (my commit for the curious). Decided that it would be more valuable to fix high firing fatal errors.\n\nI\u2019d like to get this merged. It\u2019s not perfect, but I plan to keep iterating. I\u2019m going to move on from trying to understand where failings are in the suite and try to fix as many issues as possible with this rough prioritization scheme:\n\nPrepack build passes, but runtime has an unexpected result. (React relevant stuff.)\nPrepack invariants and other unexpected JS errors.\nFatal errors.\n\nI\u2019m worried that invariants and fatal errors are hiding errors in the 1 category, so I might bounce around between these categories to uncover more issues in 1.. I\u2019d like to see a brief literature review on this topic to help expand/justify the theory. From a quick search it seems like there\u2019s a lot of thought on when compilers should and should not inline, but our case is more interesting as we want to recompose abstractions. I\u2019m not sure what the right search terms are there to find the appropriate research for that. Maybe something involving graph theory? Is there any research on expanding CSE to common expressions with single different variables?. I interpret that there are two parts to this.\n\nWe need to detect similar generators.\nWe need to diff those generators.\n\nIt seems like 2 is a relatively straightforward problem compared to 1. This PR currently implements 1.\nCould I see the result of generatorsByHash on our internal bundle? Based off that we should be able to estimate how much code this PR could deduplicate. Mostly I\u2019m interested in a map of hashes to Set sizes.. It has to do with ReactEquivalenceSet and the visitor delaying actions until after withCleanEquivalenceSet finishes.. Ooh, this can cause some broken output too.\nOutput\n```js\n(function() {\n  var _$6 = this;\nvar _$7 = require(\"react\").Component;\nvar 4 = function(props, context) {\n    _K === void 0 && $f_0();\n    var _R = props;\n    var $0 = R.z;\n    var $1 = _R.h;\nif (!_$1) {\n  var _$2 = _H;\n}\n\nvar _8 = <_D a={_$0} />;\n\nvar _6 = (\n  <div>\n    {_8}\n    {_$1 ? null : _$2}\n  </div>\n);\n\nreturn _6;\n\n};\n_$6.x = void 0;\nvar _H = {_K}; // <-------- <foobar> not in lazy function. Refers to _K.\nvar D = class extends $7 {\n    constructor(props) {\n      super(props);\n      this.state = {};\n    }\nrender() {\n  var _$4 = this.props.a;\n\n  if (!_$4) {\n    var _$5 = _H;\n  }\n\n  return _$4 ? null : _$5;\n}\n\n};\nvar $f_0 = function() {\n    _K = ; // <------------------------ _K initialized after _H already took the value!\n  };\nvar _K;\nmodule.exports = _4;\n}.call(this));\n```\nInput\n```js\nrequire(\"react\");\nglobal.x = undefined;\n__evaluatePureFunction(() => {\n  const React = require(\"react\");\nfunction Tau(props) {\n    return React.createElement(\n      \"div\",\n      null,\n      React.createElement(Epsilon, {\n        a: props.z,\n      }),\n      React.createElement(Zeta, {\n        p: props.h,\n      })\n    );\n  }\nclass Epsilon extends React.Component {\n    constructor(props) {\n      super(props);\n      this.state = {};\n    }\nrender() {\n  return React.createElement(Zeta, { p: this.props.a });\n}\n\n}\nfunction Zeta(props) {\n    const x = React.createElement(\"div\", null);\n    return props.p ? null : React.createElement(\"foobar\", { yolo: true }, x);\n  }\n__optimizeReactComponentTree(Tau);\nmodule.exports = Tau;\n});\n```. Another related output bug I found while fixing this issue. This is a scary one. The build succeeds, eslint passes, but the output is wrong.\nOutput\n```js\n(function () {\n  var _$4 = this;\nvar _$5 = require(\"react\").Component;\nvar 4 = function (props, context) {\n    _9 === void 0 && $f_0();\n    var $1 = props.z;\nvar _B = <_D a={_$1} />;\n\nvar _5 = <div>{_7}{_B}</div>;\n\nreturn _5;\n\n};\n_$4.x = void 0;\nvar D = class extends $5 {\n    constructor(props) {\n      super(props);\n      this.state = {};\n    }\nrender() {\n  return _H; // <------------------------- Uses `_H` but does not call `$f_0`!\n}\n\n};\nvar $f_0 = function () {\n    _9 = ;\n    _7 = {_9}{_9};\n    _J = ;\n    _H = {_J}{_J};\n  };\nvar _9;\nvar _7;\nvar _J;\nvar _H;\nmodule.exports = _4;\n}).call(this);\n```\nInput\n```js\nrequire(\"react\");\nglobal.x = undefined;\n__evaluatePureFunction(() => {\n  const React = require(\"react\");\nfunction Tau(props) {\n    return React.createElement(\n      \"div\",\n      null,\n      React.createElement(Zeta, {\n        p: props.h,\n      }),\n      React.createElement(Epsilon, {\n        a: props.z,\n      })\n    );\n  }\nclass Epsilon extends React.Component {\n    constructor(props) {\n      super(props);\n      this.state = {};\n    }\nrender() {\n  return React.createElement(Zeta, { p: this.props.a });\n}\n\n}\nfunction Zeta(props) {\n    const x = React.createElement(\"div\", null);\n    return React.createElement(\"foobar\", null, x, React.createElement(\"div\", null));\n    // return props.p ? null : React.createElement(\"foobar\", null, x, React.createElement(\"div\", null));\n  }\n__optimizeReactComponentTree(Tau);\nmodule.exports = Tau;\n});\n```. You can also look at some of the stacks I posted in #2297 for more ideas of what\u2019s commonly executed against test262 (although that is less representative of user code). Like this one.\nTwo big ones:\njs\n__abstract().prop;\nObject.defineProperty(o, __abstract(), {});. Also, if we had a a mechanism like the one I described above we might be able to implement the React Compiler first render optimization in user code:\njs\nconst firstRender = (props) => __optimize(\n  (props) => React.renderOnce(React.createElement(MyComponent, props)),\n  __abstract(/* insert model here */, props),\n);\n(React.renderOnce might also be React.renderToString?). > Keys shouldn't matter for first render mode, but matter in normal mode.\n@gaearon could they matter when we hydrate the first-render tree? For instance if we bail out on a class component. Or is my mental model of hydration wrong?. @gaearon disabled this for first render mode \ud83d\udc4d . Shouldn\u2019t these never be left in the source?. > Can we also have a tool to extract errors from sqlite?\nI couldn\u2019t think of a good way to display/deduplicate the errors. As I do more of that I\u2019ll try to find common patterns for displaying errors.. I have a fix for this too. It depends on the fix for #2420 though. So I\u2019ll wait until that is landed to publish the fix for this issue.. This is in code @cblappert was recently editing. I have a fix incoming.. > visitBindingAssignment assumes it's inside of an optimized function.\nWhich is an incorrect assumption as my test shows since we have __evaluatePureFunction. Should we still call this.visitBinding but with a different scope? What\u2019s a test that will fail if we don\u2019t? I can\u2019t come up with one.\nRe-requesting review since I don\u2019t understand the change you\u2019re looking for.. @NTillmann thanks for the test case! It does fix it. Although I had to update the PR to fully fix the issue. I had fixed the invariant, but that case output:\n```js\nlet result;\n(function () {\n  var _$4 = this;\nvar _3 = function () {\n    var __leaked_1; // <------------------ __leaked_1 declared\nvar _$2 = __leaked_1;\n\nvar _$3 = _$2 + 42;\n\n__leaked_1 = _$3;\nreturn void 0;\n\n};\n__leaked_1 = 23; // <------------------- __leaked_1 used outside of function!\nvar _$0 = (() => {})(_3);\nvar _$1 = __leaked_1; // <-------------- __leaked_1 used again outside of function!\nvar _6 = () => {\n    return result;\n  };\n$4.inspect = _6;\n  result = $1;\n}).call(this);\n```\nThis issue was because we weren\u2019t visiting the binding in the global scope we wouldn\u2019t referentialize it there. So I updated visitBinding to take a Scope instead of a FunctionValue so we could visit the binding in pure scope instead of just in an optimized function.\nI updated the PR so now your case in #2386 is fixed.\n@NTillmann and @cblappert, you should probably give this PR another review with the updates.. While I fixed the invariant, there are a couple other obvious issues. While the following input now compiles (it used to throw an invariant) it has two correctness issues.\nInput\n```js\nif (!global.__evaluatePureFunction) global.__evaluatePureFunction = f => f();\nconst getNumber = global.__abstract ? global.__abstract(\"function\", \"(() => 1)\") : () => 1;\nconst b1 = global.__abstract ? global.__abstract(\"boolean\", \"true\") : true;\nconst b2 = global.__abstract ? global.__abstract(\"boolean\", \"!false\") : true;\nconst result = global.__evaluatePureFunction(() => {\n  let x, y;\nfunction f() {\n    x = getNumber();\n    if (!b1) throw new Error(\"abrupt\");\n    y = getNumber();\n    if (!b2) throw new Error(\"abrupt\");\n    if (global.__fatal) global.__fatal();\n    return x + y;\n  }\nf();\nreturn x + y;\n});\nglobal.inspect = () => result;\n```\nOutput\n```js\nlet getNumber, b1, b2, result;\n(function () {\n  var __get_scope_binding_0 = function (__selector) {\n    var __captured;\nswitch (__selector) {\n  case 0:\n    __captured = [void 0, void 0];\n    break;\n}\n\n__scope_0[__selector] = __captured;\nreturn __captured;\n\n};\nvar __scope_0 = new Array(1);\nvar _$3 = this;\nvar _1 = function () {\n    var __captured__scope_1 = __scope_0[0] || __get_scope_binding_0(0);\n__captured__scope_1[0] = getNumber();\nif (!b1) throw new Error(\"abrupt\");\n__captured__scope_1[1] = getNumber();\nif (!b2) throw new Error(\"abrupt\");\nif (global.__fatal) global.__fatal();\nreturn __captured__scope_1[0] + __captured__scope_1[1];\n\n};\nvar _$2 = _1(); // <------------------- Called before getNumber is initialized.\nvar _2 = () => {\n    return result;\n  };\n_$3.inspect = _2;\ngetNumber = () => 1;\nb1 = true;\n  b2 = !false;\n  result = 0 / 0; // <-------------------- result is NaN. Should be 2.\n}).call(this);\n```. I\u2019m continuing to look at this to find a workaround since it is blocking me. Filed another issue related to this one: #2464. This fix only papers over what seems to be a deeper issue documented in #2464.\nI removed the fix from this PR since I observed behavior on my internal React Native bundle which led me to agree that this is not the fix. This PR now only has two new failing test cases and a utility __fatal function.. Closing in favor of #2466 and #2458.. @trueadm I did add a test in test/serializer/basic/FactorifyMixNodeTypes.js \ud83d\ude42\n```js\nconst a = { x: 1, y: 2, z: 3 };\nconst b = { x: 1, y: 4, z: 5 };\nconst c = { x: 1, y: 6, z: 7 };\nconst d = { x: 1, y: 8, z: 9 };\nconst e = { x: 1, y: 2, z: 10 };\n// Hold two references to each object so they are not inlined.\nconst ref1 = { a, b, c, d };\nconst ref2 = { a, b, c, d };\nglobal.inspect = () => JSON.stringify({ ref1, ref2, e });\n```\nPrepack REPL. I\u2019ll reopen after fixing tests.. True. Updated to use ObjectValue | AbstractObjectValue.. I like your changes @trueadm \ud83d\udc4d \nFixed the serializer tests now that __optimize does not log a diagnostic for throws.. Well, then get ready for a lot of apologies \ud83d\ude0a\nWant me to delete them all?. Doing that here results in some failing tests. Here the instruction doesn\u2019t put a ? before Call, and in the next step its specified that if completion is an error it should be thrown instead of innerResult.\nOne of the failing tests is language/expressions/assignment/dstr-array-rest-iter-thrw-close-err.js. Here there are two errors which may be thrown. ReturnError may be thrown by the return method which is called by this line in IteratorClose, and Test262Error which is thrown in the destructure pattern on line 64. Both will be thrown, but the test expects that it will be the Test262Error that \u201cwins.\u201d We call IteratorClose after thrower() throws the Test262Error, as a \u201cfinally\u201d type thing I guess. The Test262Error is represented as the completion argument in IteratorClose. If we do not catch the error thrown by Call (which will be the ReturnError in this case) then the Test262Error will be wrongly ignored instead of the ReturnError. This test confused me when I first saw it, does that explanation make sense?\nPerhaps we should modify the code for step 7 so that it throws? It returns in master and I didn\u2019t change it.. Its that way in master, I didn\u2019t think to change it. Makes no difference in tests pass rate \ud83d\udc4d. result isn\u2019t really used and IteratorBindingInitialization returns void at the moment. I\u2019ll do it for explicitness anyway \ud83d\udc4d. I mentioned this in the OP. The code works, the tests pass, but I am not comfortable with the solution. Now that I\u2019m looking at the code again the completion passed into IteratorClose here really isn\u2019t an AbruptCompletion, it\u2019s a normal completion. I just felt the need to make it an AbruptCompletion because that is what the type says. Let me do a bit of a refactoring now that I think I understand this code path better and you can let me know what you think \ud83d\udc4d. Ok. I did new UndefinedValue(realm) in a couple of places. Want me to replace all of them with realm.instrinsic.undefined?. We\u2019re returning something now, but it is still undefined. Is that better?. The spec has us call BindingInitialization recursively where BindingInitialization handles properties and list of properties etc. There are a lot of rules and a lot of way to handle those rules with a lot of recursion on BindingInitialization for what is fundamentally just this simple logic. This happens a lot in the part of the spec I implemented. I chose to keep the implementation straightforward over sticking to the recursive and complicated language of the spec. Do you agree with this tradeoff?. InitializeBoundName returns undefined anyway? There may have been a reason in development, but there\u2019s no obvious reason now. I\u2019ll put it back the way it was.. Oh, I meant delete the comments. Not invariants \ud83d\ude0a. Ah, makes sense. Changed it to the following. Better?\njs\nlet innerResult;\ntry {\n  innerResult = Call(realm, ret.throwIfNotConcrete(), iterator, []);\n} catch (error) {\n  if (error instanceof AbruptCompletion) {\n    innerResult = error;\n  } else {\n    throw error;\n  }\n}. Yeah, that\u2019s the change I made in response to @hermanventer thanks for confirming. I just initialized a Completion instead of a NormalCompletion. I\u2019ll make that change \ud83d\udc4d. v should always be an ObjectValue if the rest of the if is true, but Flow doesn\u2019t know that so that\u2019s why the v instanceof ObjectValue is there. It could be an invariant if you would rather.. Same as above, I\u2019ll apply your answer everywhere I used this pattern \ud83d\udc4d. \ud83d\udc4d. Why were we using this fixpoint_rerun recursion? I moved the visiting logic into ResidualReactElementVisitor along with the other visiting logic for that class and didn\u2019t observe any test failures.. This error wouldn\u2019t be recoverable since we would get an invariant exception in our serializer. So I updated the code to throw a FatalError instead.. Visiting this value in the global generator is a bit clowny (read comment), but it is the same thing that the previous fixpoint_rerun code did.\nIs this be a valid call to _withScope? Why? There\u2019s a scary comment on _withScope I don\u2019t yet understand which makes me less confident about this.\nhttps://github.com/facebook/prepack/blob/e3f4262c9dafce766835acdaff39af04de231fae/src/serializer/ResidualHeapVisitor.js#L243-L245. Internal bundle compiles \ud83d\udc4d . I had assumed that this error might be thrown when the user did not require('react'). Guess we wouldn\u2019t make it to this point if that were the case.. The getter could also be:\njs\nconst x = {\n  get thisShouldNotAppear() {\n    console.log('side effect!');\n    return 42;\n  },\n};\nWhy is this safe to eliminate?. @hermanventer: is this reuse of your TODO logic ok?. @trueadm I noticed that some property accesses were not emitted in my NestedConditions test and found your discussion in:\nhttps://github.com/facebook/prepack/pull/2097/files/225590fe2e7c4e1dd40a0ea4b3d12d790900e609#r194060187\nGetters could have a \u201cpure\u201d side-effect like console.log, correct? If a function call cannot be removed in pure scope, then a getter probably shouldn\u2019t be as well?\nThis change is only tangentially related. I thought my serializer tests would snapshot the serialized output, but they don\u2019t. Happy to remove if you disagree or move to another PR.\nHere\u2019s a gist with the serialized output without this \u201cfix\u201d:\nhttps://gist.github.com/calebmer/3ba090cda321ce67576c8d3c73ec5670. Instead could we do:\n\"flow\": \"flow\",\nSince flow status is the default behavior. This enables you to run whatever args you want:\nyarn flow check\nyarn flow cycle\nyarn flow version. > Property reads are assumed to be side effect free. If a property is backed by a getter, then the getter must be a pure function.\nI see \ud83d\udc4d. Thanks for the context. I thought this was a bug in my code \ud83d\udc4d. \ud83d\udc4d. I removed the side effects. Since you\u2019ll be working on this code, I\u2019ll let you move it to the appropriate scope \ud83d\udc4d. Could a regular expression make more sense? Like /\\/\\*\\s+eslint-disable\\s+(.*?)\\s+\\*\\//g.. Yep. #2292 \ud83d\udc4d. You can type check this instead of passing a random bag of values like this:\n```js\ntype OperationsMap = {\n  A: number,\n  B: string,\n};\nfunction create>(type: K, data: $ElementType) {\n  return;\n}\ncreate('A', 42); // Ok\ncreate('B', 42); // Error: B expects string data.\ncreate('C', true); // Error: C is not a operation type.\n```\ntry-Flow\nUnless you want to completely get rid of these eventually?\nWe could/should do a similar thing for abstract value args.. What about getKey or getDedupeKey instead of getHash?. :+1:. This would cause an infinite loop unless the branches of ToString were inlined into ToStringValue, so I\u2019ll leave this for now.. \ud83d\udc4d . Is there a reason this isn\u2019t this?\njs\ncomponent: {props: string},. Updated to 3 \ud83d\udc4d . > Won't this only be true if we're inside an optimized function?\nNope.\nIn my example this will be true for non-local references in a havoced function. We havoc functions in pure scope. __evaluatePureFunction creates a pure scope without needing __optimize. Consider:\n```js\n__evaluatePureFunction(() => {\n  const x = {};\nvar havoc = __abstract(\"function\", \"(() => {})\");\n  havoc(() => x);\n});\n```\nNo __optimize, but residualBinding.potentialReferentializationScopes.size === 0 is true.\n\nAlso not sure if _enqueueWithUnrelatedScope does something reasonable when passed undefined.\n\nI think you misunderstood the change? _enqueueWithUnrelatedScope is not passed undefined. I moved this invariant to the if condition. So the invariant must still be true for _enqueueWithUnrelatedScope to run.. On an AbstractObjectValue IsCallable() could be true or false. Depending on whether or not the abstract object is callable. Since IsCallable() returns a boolean, we throw when there is a \u201ctop\u201d AbstractObjectValue instead of emitting typeof x like the branch below does. I added this condition so that AbstractObjectValues went to the AbstractValue.createFromUnaryOp(realm, \"typeof\", val) branch. The test failures appear to be unrelated to the correctness of this change.\nHowever, I backed out of this change anyway. Since IsCallable() already has handling for abstract values which I didn\u2019t realize. That means this change was a regression in what typeof operations Prepack could concretize. Instead I opted to return a simple abstract object type which is clearly not callable so it doesn\u2019t throw.. I don\u2019t know enough about this to know whether or not it is correct. I tried producing a failing test case based on your comment but didn\u2019t have success. I\u2019ll leave to @cblappert who has better context on this code and this condition.\nThe defense for this condition based on my understanding of the code is that we only need to execute the code under this condition once per binding in the \u201clargest\u201d possible scope. Perhaps accidentally if this is in a pure scope it will be visited first since optimized functions are only evaluated at the very end of global scope? Under my understanding, if __optimize evaluated the function in place (instead of at the end of global scope) the following example would referentialize i in f.\n```js\nconst havoc = __abstract(\"function\", \"(() => {})\");\nglobal.result = __evaluatePureFunction(() => {\n  const f = () => i++;\n  __optimize(f);\nlet i = 0;\nhavoc(f);\nreturn f;\n});\n```\nAlthough I might completely misunderstand \ud83d\ude42. Covariant (read-only) properties are allowed to be initialized in class constructors in a recent-ish change to the type system. This preserves the semantics of covariant properties since you can\u2019t assign back some larger type.\n```js\ntype Y = {+p: number | string};\nclass X {\n  +p: number;\nconstructor() {\n    this.p = 42; // Ok\nsetTimeout(() => {\n  this.p = 0; // Error\n  (this: Y).p = 'foo'; // Error\n}, 0);\n\n}\nm() {\n    this.p = 0; // Error\n    (this: Y).p = 'foo'; // Error\n  }\n}\n```\ntry-Flow. return effects.result;?. First bug here.. Second bug here.. ",
    "galenyuan": "Its wired, why not do like ESLint?. ",
    "echo304": "I'm going to dive into this issue. @NTillmann I've tried to figure out how things work under the hood but it's not easy to get my hand dirty. If I could have your advice where I should start to tackle this issue, that must be super helpful.. @cblappert Thanks for the comment!\nIf I could group them somehow, that would be nice. But I agree with your suggestion for long term maintainability. (By simply ordering by alphabetical order). I'm going to work onto it.. I'm gonna tackle this issue \u270b . Let me tackle this issue \u270b . From the perspective of product design,\ndoes it need to terminate process when --help option is passed even if other arguments(ex-filename) are passed too? \nIf so, this issue can be fixed by adding one line of code that terminate process when arg === 'help'.\nAny thought?. Let me tackle this one \u270b . Sorry @NTillmann ! You'd better find other awesome guy who is able to solve this issue!. I've fixed here by adding one more condition to check if !!serialized\nAnd log some msg if serialized.code === '' which means no input.. Is issure a typo? \ud83d\ude0f . oooops... \ud83d\ude0f . You're right. else branch wasn't needed. Thanks for pointing out!. let's pick PrepackOptions . good call \ud83d\udc4d . ",
    "onbjerg": "If you want this, then it would probably make sense to adjust it in the other places of the README as well. ",
    "vemacs": "@hermanventer Here's a ZIP with the compiled script and the source map: https://transfer.sh/ZRytf/dist.zip. ",
    "gavwin": "Closing the pull request now because I found out that the FB coding style is to use braces even if optional.. ",
    "rajapanidepu": "Duplicate of #782 and #786. ",
    "davidaurelio": "The new mode produces code as follows:\njs\n__d(function(global, require, module, exports, dependencyMap) { \n  ... \n  require(dependencyMap[1]);\n  ... \n  require(dependencyMap[0]); \n  ... }, 1, [23 42]);. ",
    "javache": "This looks great. For our use-case specifically, A and B will be independent but may be writing to shared parts of the heap.\nfuncton initStuff() {\n  global.registry = {};\n}\nfunction initMoreStuffA() {\n  global.registry['A'] = 'a';\n}\nfunction initMoreStuffB() {\n  global.registry['B'] = 'b';\n}\nAnother property that would hold true for this is that.\ninitStuff()\ninitMoreStuffB()\ninitMoreStuffA()\nwill result in the same heap layout as the original.. ",
    "jakearchibald": "It might be that I'm the only person in the world that wants this \ud83d\ude00. ",
    "a8m": "Closing in favor of #1621. Closed via #1721 . Closed via #1632. Closed via #1681. Where do you see it? CircleCI looks green.... Oh, you're right!. You were right! Thanks for the help.. Time complexity is pretty bad if all cases are different from each other. The other alternative I thought about is to use Map with the initializationValues as a key, but it needs to be converted to a string. it's possible because all arguments are numbers.\nBut I'm not sure what is preferred. Maybe I can come up with another implementation, run benchmark tests and see how they behave in practice.\nDo you have any other suggestion?. The linter complains about this import. I need to update the babel-types file in the flow-typed directory.. Got it. Thanks!. ",
    "brokenpeace": "I didn\u2019t look close but I would of suggested a simple test case for this.. Changing out libraries even with deep understanding can have some impacts on people using this\n. yikes. well was typing some comments. I feel this logic is very inconsistent ( not at fault of this change but overall ) and could be simplified by A) creating a Class Context? it seems a lot of various value types (0, undefined, false)/length some places? I did not get to look at it that close but I know it is getting a bit over engineered and all of these if !something is from my world a no-no if it can be avoided? It increases the likelihood of misreading intent\u2026\nSorry if I am overstepping new to this library but I do love it and would like to contribute. If this is not the case can someone please point me to the standards we are following?\n@hermanventer @yinghuitan . Yea, as mentioned dig the library and am newer to NodeJS so just wanted clarity. It makes sense to adhere to the existing style. I just assumed NodeJS in general kinda encouraged one because jumping around libraries could get fun\u2026 \nThe larger concern/question is about a Context class? by default initializing as global I think based on what I have gone through. I just think it would make more send to use a Central consistent class/subclasses for Context thats how Ive always used it in Golang and other languages.. this will keep it standard tin checking by knowing what to expect and check for also quickly finding the context out in a single call from the Object?. ok makes sense that clears it up. I am just trying to make sure I am following along logically with how things are being done because of the various values/ways required to determine the Context. Thank you I will dig deeper into this library tonight. I look forward to contributing hopefully \ud83e\udd15 . ",
    "carlsagan21": "Done!. Oh got it. And what about others?. ",
    "trueadm": "@NTillmann I'm using the internals of Prepack, plugging in bits here and there directly, you can see some of the code here:\nhttps://github.com/trueadm/react/blob/compiler/scripts/compiler/src/evaluator.js\nRegarding the invariant, it happens when I calling it via https://github.com/trueadm/react/blob/compiler/scripts/compiler/src/reconciler.js#L97:\nI've been working on this with @sebmarkbage, so he might be able to add more clarity to what our intentions are in terms of what we'd like from Prepack. Your second point sounds like the sort of thing we're looking for though :). @hermanventer Awesome stuff \u2013 that will help the React compilation efforts hugely. Let me know if there's anything I can help with/test with. :). I can see how that affects the output. Why do we need to refine the context \u2013 because we also need to union a NullValue? The issue is that != null seems universally used over our codebases and to bail out here wouldn't be perfect.. @hermanventer That would be great. Thank you :). @hermanventer On a side note, I came across places today where !== null are explicitly used, so I guess a union of UndefinedValue and NullValue would be ideal. :/. @hermanventer The issue is, the value being passed in might be null, undefined or something else \u2013 so you'd expect all those paths to be returned as possibilities. Maybe I'm not understanding something properly or I'm lacking some context. :/. Is it okay if we get this PR merged? I assume we land to fbsource first like other fb project workflows?. @NTillmann You made a really good point about the ReactElement children when they're arrays. They shouldn't be serialized as var a = [1,2,3]; return <div>{a}</div> and return <div>123</div> are handled differently in React world. I'll rethink that bit.. I've made appropriate changes and refined how children are handled \u2013 I still need to revist at some point the applyKeysToNestedArray and how they're handled on a serialzed child. I've added a TODO and will revisit once we get tests up and running.\n@NTillmann I think we need to add a Babel compile stage for JSX flagged tests. I'll add it to this PR once I get some time. What would be the most straight-forward way of doing this with the current test runner?. @NTillmann I've addressed Sebastian's feedback and I feel the PR is in a good place now. In regards to your comment about assumptions being explicitly stated \u2013 can you give some examples? I'm happy to make them, but maybe they can be added in a new PR when other parts of the React support gets integrated and some assumptions may change.. @NTillmann Eventually we will need it I think. The thing is, React's render phase is meant to be close to \"pure\", so this sort of thing shouldn't happen \u2013 in reality it does though. I think @sebmarkbage already had a similar issue or comment somewhere outlining these cases, so he might be able to better go into detail (and it's getting late here).. @cblappert It's still something we'll need as there will be many React component roots (additionFunctions).. I'm closing this PR and breaking it into small PR chunks as per @sebmarkbage's recommendation.. @sebmarkbage That's fine, the renames can happen in that PR \u2013 the PRs are all coupled anyway. :). @yinghuitan They don't break the compiler, they just result in invalid output after which Babel can't parse.. > Maybe we could also append the original error + message to the bail-out message.\n@cblappert It will insert the original message in the comment, which I tried, but ended up adding like 10 lines of comments and making the output unreadable. Not sure what the best approach on this is.\nMaybe we can re-visit at a later stage so we get the functionality in this landed?. I'm landing this now and I've added a follow up issue: https://github.com/facebook/prepack/issues/1131. @sebmarkbage I thought about this long and hard and realistically, we need to enforce this constraint (having Flow annotations) right now until we can unblock that requirement later on in Prepack. Given Prepack will be dealing with bundles, the flow option will be lost too, so short term \u2013 these hacks are needed simply to get us into a place where things fold.\nI'll add a requiresFlow switch though \u2013 that's a good idea. It will be enabled by default.. One constraint to add, if the JSX attribute of key is a StringValue we cannot add these de-dupe optimizations to that React element as this depends on React runtime constraint. Check this issue for prior discussions on this topic: https://github.com/facebook/react/issues/3226\nSo this can be optimized:\njsx\nfunction MyComponent() {\n  return (\n    <div>\n      <span />\n      <span />\n      <span />\n      <span />\n    </div>\n  );\n}\nTo be:\n```jsx\nconst __a = ;\nconst __b = {__a}{__a}{__a}{__a};\nfunction MyComponent() {\n  return __b;\n}\n```\nIf a React element has a key, we will also need to preserve that. For example:\njsx\nfunction MyComponent() {\n  return [<div key=\"a\" />, <div key=\"b\" />, <div key=\"c\" />, <div key=\"d\" />];\n}\nWe can't hoist those nodes reliably, one way we could optimize this could be:\njsx\n__div(key) {\n  return <div key={key} />\n}\nfunction MyComponent() {\n  return [__div(a), __div(b), __div(c), __div(d)];\n}. A bunch of these use-cases should be covered by the PR: https://github.com/facebook/prepack/pull/1196. @sebmarkbage Even better, if you can come up with more good short example tests, please stick them on here and I'll build tests around them and fix them accordingly. :). @yinghuitan Definitely agree that the code should be in its own module. I think we can probably do that as a follow up PR though, if that's okay.. Would be awesome if @sebmarkbage could give this a once over again. :). @NTillmann @sebmarkbage Can we merge this PR if everyone is happy, it's been lying around for some time now and would be useful if instead any issues we found could be added as follow ups instead of blocking this PR?. @hermanventer I've not strictly gone through this PR according to the spec. I instead added functionality and then added instances of what the spec states to match the functionality via manual testing. I feel this PR needs a bit more work in terms of additional tests and a few bits of missing functionality relating to when the class has been constructed, i.e. var a = new ClassThing(); a.doSomething().. This PR has gotten too unwieldy to properly manage now \u2013 it's hard to track what needs to be fixed where because minor changes to a file mark comments as out of date (a terrible auto-GitHub feature in my opinion, it should be manually controlled). So, instead I'll merge this PR and create a new issue with the outstanding issues on them as per comments in this PR. \nThe next PR I setup to fix the issues will also include more extensive tests. This shouldn't block anything as we aren't shipping any code that includes ES2015 classes and the bugs in this are more edge-cases rather than common usage/behaviour.\n  . Follow up issue created: https://github.com/facebook/prepack/issues/1317. @hermanventer I'll think of a better approach rather than introducing transforms into affects. Maybe I can attach them only to additionalFunctions for now.. @gaearon We don't support them as they're deprecated. The bail out is only on the single React Element, not the entire render method of the function.. @sebmarkbage They bail out because they have very different heuristics and right now I don't have the bandwidth to support them. Also by bailing out, it allows us to support <Text /> on RN. :). I managed to get the REPL working in a separate commit so we can close this for now: https://github.com/facebook/prepack/commit/1dbefcbd83d793b53b26afa4bfe36638b4b751cb. @yinghuitan Might be worth pining @cblappert as I helped him yesterday set up a debug environment for the React test cases.\nWhat I do, is setup a local file and run it via the CLI with the Node debugger enabled. You'll need to enable reactEnabled, set the compatibility flag to react-mocks and the reactOutput flag to either jsx or create-element, depending on which one failed for you. I'll write this all up in the wiki after the holiday season :). Thanks for reviewing! I believe the issue you saw was already fixed in this PR: https://github.com/facebook/prepack/pull/1298\nIt probably hasn't been deployed yet.\n  . @sebmarkbage I updated the original message, I made some typos. I think public fields is going to have to be a separate workflow to add later.. @NTillmann Fixed in https://github.com/facebook/prepack/pull/1662. What's left to unblock this PR? Would be good to have it so I can merge #1321 once it passes :). See #1328. Missing test was added.. This has fallen so out of date that I'm going to close for now and have to do a major rebase at some point once I can resume this work.. @sebmarkbage I can evaluate the constructor, but I was concerned about side-effects in the constructor. Until we start to push people away from side-effectful behaviour in the constructor, I'm not sure we can evaluate it with confidence. If we were to call the constructor of a component twice like we did other lifecycle events for async, I'm sure we'd see just as many issues.. If we change the inherits method to be:\njs\n    subClass.prototype = Object.create(superClass && superClass.prototype, {\n      constructor: {\n        value: subClass,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n    if (superClass)\n      Object.setPrototypeOf\n        ? Object.setPrototypeOf(subClass, superClass)\n        : (subClass.__proto__ = superClass);\nYou no longer get broken output. Maybe we should use this version instead?. @gaearon I'm not even sure how it works, maybe it relies on some special internal hacks/logic that I'm not aware of. See my inline comment.. @gaearon The function is missing the arguments props, context from React.Component. So that seems like a bug here (but that should be probably be made a separate issue rather than tagged to this one).\nWhat I was trying to say was that we shouldn't be serializing the mock React.Component at all but the polyfill seems to be making it happen. If we change the polyfill to use React.Component as the prototype, Prepack correctly serializes the output out.\nWe should write some test cases for these bugs too.. @gaearon Almost all of this code is already covered by existing tests. They all use a public API and many of them use multiple component trees. I'll add a few more tests with even larger trees tomorrow.. @gaearon I'll do that react-optimized-trees counter checker as another PR as I really want this one landed as its blocking a bunch of work that needs to happen in regards to bytecode.. @sebmarkbage That makes sense. Is it difficult to implement? This feature is blocking https://github.com/facebook/prepack/pull/1360 so it would be good to get this in soon. I'd be happy to take it on if you can explain how I might go about doing it.. @sebmarkbage Thanks, I'll look into that next.. @sebmarkbage I believe I have this working now, but I'm not 100% sure I've done it the right way. Please could you let me know.. @sebmarkbage @cblappert I've added a new test, but it fails when run with inlineExpressions set to false. When inlineExpressions is enabled, the tests pass. I dug a bit deeper, and it seems that there's an issue with preludeGenerator entries never being serialized properly. Is this a known issue with inlineExpressions? You can see below from the output that _$9_global is never defined:\n```js\n(function () {\n  var 1_additional1 = function () {\n    var _3 = $9_global;\n    {\n      var _2 = {\n        get foo() {\n          return \"bar\";\n        }\n  };\n  var _$1_derived = _2_.foo;\n\n  var _$2_derived = _3_.String(_$1_derived);\n}\nreturn _$2_derived;\n\n};\nvar 6_additional2 = function () {\n    var _3 = $9_global;\n    {\n      var _7 = {\n        foo: {\n          bar: \"baz\"\n        }\n      };\n      var $5_derived = _7.foo;\n      var $6_derived = $5_derived.bar;\n  var _$7_derived = _3_.String(_$6_derived);\n}\nreturn _$7_derived;\n\n};\nvar 0 = function () {\n    let ret1 = _1_additional1();\nlet ret2 = _6_additional2();\n\nreturn ret1 + ret2;\n\n};\ninspect = 0;\n}).call(this);\n```\nIt should be referenced to var _$9_global = global.String or something similar. I've made a possible fix in this commit:  https://github.com/facebook/prepack/pull/1361/commits/1030a15c91192b9484b16b13338fee7b061eda7d. @sebmarkbage This is directly related to the work @gaearon and I are doing internally on the POC so we'll probably note these shims with that project.. @sebmarkbage We need all the render phase to be evaluated and not bail-out with errors so that we can serialize to bytecode properly.. @sebmarkbage The idea was to throw a CompilerDiagnostic error. Is that what you meant?. Actually, I think we should abandon this PR for now. After thinking about this, there's not any real value in changing how the errors are thrown at this time. We can revisit this later.. @NTillmann I believe my example should fail with simpleClosures disabled.. The tests use the options specified in the React test runner rather than from the test source input. We should maybe run all React ltests with and without simpleClosures?. Closing this for now. Might revisit at a later point.. @gaearon I'll add that test and fix the issue it creates.. @gaearon Yep, I've done that locally and found the same too. This is caused by the length of the array being returned as an AbstractValue rather than NumberValue because the array has been marked as leaked. Looking into a solution now.. Follow up PR created: https://github.com/facebook/prepack/pull/1377. @sebmarkbage Unfortunately, I couldn't find a simple test case to use for this. This particular bug came from testing this code on internal FB UFI bundle (via webpack) when run in a pure wrapper (which isn't currently landed yet). Maybe we can revisit this and add a test case once the other functionality lands.. Closed PR as all the comments no longer referenced the code or the title anymore. New PR open: #1382. Can we add another test case if possible for this to cover the points made by Herman?. @gaearon Do you want to apply this PR and change the current logic on master then? I'd be happy for that as it doesn't seem at change anything in terms of the UFI bundle when testing locally.. I wanted to ensure the definitions of those global are known by Prepack and stored in the fbLibraries for future work. Furthermore, this PR does more than just deal with those two cases. It\u2019s a tidy up of all the require logic so we re-use the same abstracts. I\u2019ll update the PR description later when I\u2019m home.. @gaearon I disagree with @sebmarkbage on that. Many of these special cases are intended to be used again for open-source. Styled Components have been experimenting with the fb-www mode to make their bundles work too. Furthermore, the system we have on RN was very confusing and meant many things were not in sync \u2013 so I don't feel we gain anything from that approach.\nIn relation to making the global partial, I tried this before, but it has unwanted side-effects related to serialization. I spoke before to @NTillmann about this when he was in London and he wasn't sure that making the global partial was the best approach either. We can re-visit though, to see if the same problems exist.. @gaearon resolved prevents further creation of further derived references for objects that we know don't need to be referenced again (module.exports for example):\nhttps://github.com/facebook/prepack/blob/661271cc76d4cf67e57525ec745264abff78d792/src/methods/properties.js#L1164-L1190. One of the issues I\u2019ve found is that we mark far too many objects as escaping/leaking. This affects the React reconciliation stage as what was an object value before is now an abstract value. If you remove the leaking logic, the React reconciliation process doesn\u2019t hit any invariants.. I'll revisit this tomorrow and add some tests.. Closing as I think we can embed a createFragmentContainer mock like we have the React mocks. This is the only way we can do bytecode anyway after thinking about this long and hard.. Closing now as we're not implementing this.. @gaearon Added a bail out case for non-root factory components until the TODO is fixed :). This has been discussed internally by the React team already and we've come up with a possible strategy.. I added tests to this. Well modified existing as per feedback. It\u2019s hacks but then so are these non standards magic globals. Otherwise I\u2019d use the standard abstract API, but it would not keep the standard we need internally.. @gaearon Sorry, I added the updated test.. @gaearon We could change the code somewhat to throw, but I manually checked the output in this case.. Ignore my last land, this was done by mistake. I cancelled it on Phabricator.. Closing in favor of a different approach.. @gaearon I tried on a dummy bundle locally. I changed the root module.exports = ... to be return ... and inside this wrapper and all was good.. I've been manually merging in master to try and trigger the bot to recognize this PR. I'm not lost my mind.. @gaearon If you have any tests in mind, feel free to paste them on this PR and I'll add more tests around the same thing. I couldn't think of any obvious tests as the React compiler flattens arrays in most cases so they don't even show anymore.. @gaearon I don't see any mention of Symbol.for in my compiled output? :/. @gaearon Ah that's with output set to create-element (or default) rather than jsx. Looking into it now.. This PR isn't working either. :/. @NTillmann Yep. They are only used for the React reconciler part right now, not for serialization or the visiting phases.. @sebmarkbage I disagree, I've explored all those paths already and it impacts creates far more duplication and code-bloat when we either bundle ReactRelay or if we mock out a streamlined version. This significant impacts initial performance and the ability to properly handle this with bytecode. I was going to add a dedicated bytecode operation for ReactRelay containers as the best performance-to-size win \u2013 something this PR allows without too much work.\nIn terms of downstream effects, this means that we need to keep an eye on API changes but I've already pinged the Relay team and they've told me that they don't expect to change the container APIs anytime soon.. @gaearon Updated snapshots that (correctly) failed as now more component trees get processed! :). @gaearon Ready for you to take a look at when you have a chance.. Fixed in https://github.com/facebook/prepack/pull/1453. @cblappert Any idea as to why this might be happening?. Fixed in https://github.com/facebook/prepack/pull/1452. @sebmarkbage Unfortunately, neither an invariant or FatalError gets thrown. Instead it returns a broken object literal. Check the React test. I\u2019m fine with leaking all the arguments, except we can\u2019t make abstract object values frozen, so leaking props will do more damage. Trying to throws an invariant. I also though getters weren\u2019t copied or even triggered from object assign?. That\u2019s what this PR originally did. But all the Object.assign tests failed :/\n. @sebmarkbage I did that too - it is in my commits.. @sebmarkbage Unfortunately, it doesn't work with the React test because the Abstract value created isn't simple and the test tries to access property x on the abstract value which results in a FatalError.. I'm closing this PR for now and will attempt to fix it in another PR.. @sendilkumarn Do you need any help with this PR?. @gaearon I want to get this landed so I'm going to pull out the work where we pass around reactHints on Object.assign and add a flag instead for reactMode. . @gaearon It's going to be a pre-cursor for the work needed to not break the UFI. Given this PR greatly improves our test coverage too, I think we should get this in and then work towards the last few things to get the UFI working (i.e. Object.assign, rest, try/catch etc in separate PRs). What do you think?. @gaearon Thanks, case fixed in latest commit.. Can you please add some tests around additionalFunctions to this too? When we start handling nested additionalFunctions I envisage serialization problems around dependencies.. @gaearon I've pushed a revision that makes a better explanation. We don't need to check the keys because that's already handled above. I've also added a test where we add getters/setters to the target after it's been assigned to show it working as a simple object.. @gaearon In relation to your example, how could we call doSomethingBad() from within Prepack? It should be marking it as leaking right? I looked into it, and the value never leaks. To make it leak, we'd have to add getters/setters to all the know global values so we trigger the value to leak \u2013 which isn't straightforward. Maybe the best approach is to only apply this logic if we're in a pure wrapper, as no one should be assigning to the window in those cases.. @gaearon That's because you're meant to Prepack all your code and not have code outside that Prepack can't see.. @gaearon Let's look when you're back.. @sebmarkbage It wasn't about the sources being simple, it was to mark the target simple if we knew that the target object had no keys on it and we knew the target wasn't abstract. I think the original description on the PR was old and I forgot to update it.\nMarking something simple seems to be the confusing topic here, I was told that making an object simple means object is safe to read and write unknown properties and that we can add getters/setters to it as long as we know they have no side-effects.\nThe main case we're trying to solve here is:\n```js\nvar a = __makeSimple(__makePartial(__abstract({}, \"a\")));\nvar b = {};\nObject.assign(b, a, { bar: 1 });\nglobal.result = [b.foo, b.bar];\n// output\nvar b = {};\nObject.assign(b, a, { bar: 1 });\nresult = [b.foo, 1]\n``. @gaearon It's all React specific in the fact that these codepaths only exist via pure wrappers becauseAbstractObjectValue` properties would throw FatalErrors without it, thus not getting to the point where they construct member expression.. @gaearon Added another test as per what you mentioned. I missed those tests, sorry.. Can we add the tests in the other PR too please?. Is this PR still live or has it been replaced with a newer one? . Shouldn't we only leak when we have partials or abstract? For example, the below example clearly isn't leaking as we create the objects and track them fully:\n```js\nlet x = { a: 1, b: 2 }\nlet y = { c: 3, d: 4 }\nlet z = Object.assign({}, x, y);\ndelete x.a;\ndelete y.c;\nglobal.results = [x, y, z]\n```\nIf you look at leaking as \"escaping\", then nothing above actually escapes, but would be marked as such by this PR anyway. I feel like we're missing something here \u2013 if simple fixes this, then there's a bug somewhere else.. @gaearon I addressed the PR feedback and hopefully what I changed is what you meant by your points above.. @gaearon I didn't quite understand the point @sebmarkbage made. I appears reportErrorIfNotPure() is only called via certain paths. The following operators get called from those paths:\n<, >, >=, <=, >>>, <<, >>, &, |, ^, **, %, /, *, -\nThese can all leak though as they're all logic/math operators and would called valueOf?. @gaearon I'll add a follow up PR.. @hermanventer Changes made, let me know if this is okay now. Thanks for the help!. @sebmarkbage This looks like the next we need for the UFI.. In case anyone is wondering why I keep importing this PR, it's because it's not picking up the right commit on Phabricator. :/. @hermanventer I removed the logic in the delete operator and kept that code path separate without needing to using a temporal abstract.. Closing as I believe I have a better approach. @sebmarkbage I couldn't recreate the issues in standalone tests, they were only apparent when using the UFI. :(\nIf you're happy for it to merge, I'll work on adding tests on my flight this weekend over to Seattle.. @cblappert That's fine, but in the case of ReactElements, they are meant to be immutable objects.. @sebmarkbage We do, but this is more to meet a milestone so I'm happy with a small patch for the wins it gives.. @gaearon Had to update snapshots, done now!. @NTillmann This PR fails internal FB tests.. @sebmarkbage We discussed this in depth today. Forgetting state isn't actually something we want in all cases. Using real production code in the UFI has flagged up several blockers from this pattern that make it impossible to properly evaluate the app \u2013 especially when we're creating derived abstracts in places like CallExpression when a FatalError was thrown and caught \u2013 on things we know cannot leak \u2013 for example Object.assign can never leak simple sources, it's actually a havoc, but we do want the target object to have properties if the last source is a concrete object. Let's go through this again tomorrow when you're in Seattle.. @yinghuitan I was of the understanding that an additionalFunction was a generator body.. @NTillmann Ideally, we should break down compatibility more so it's based on implementation rather than heuristics. Furthermore, we should aim to reduce the Prepack options so we don't have as much config as we do now. This is larger discussion though \u2013 maybe we can talk about it next week.. CI is failing in the ECMA tests :(. @sebmarkbage let\u2019s talk about this when we\u2019re in the office. @sebmarkbage  Currently, when Object.assign fails, it recovers in CallExpression and re-creates the Object.assign and leaks all the arguments, isn't what the plan was to do as a follow up to this PR? How does that differ from existing logic?. It would seem CallExpression logic right now might be buggy if that is the case.. @sebmarkbage If we havoc the target and make it partial, which I believe was the intention from above comments, then the above should be fine?. @hermanventer Working on it now. Trying to figure our how to create an abstract with __abstract that does not have a set type other than Value.. @hermanventer awesome, thanks for that!. @hermanventer I've come up with a fix, but it might not be right: https://github.com/facebook/prepack/pull/1538. Something is still wrong with it unfortunately, this invariant now triggers later on in the UFI:\nhttps://github.com/facebook/prepack/blob/f3814460e2eff64cb301afb085912bb89b1ba40b/src/methods/join.js#L462\nAlthough both are ReturnCompletions, so maybe we can do an alternative code path there and join the effects if that's the case:\n\n. I pushed a change in relation to my reply above. I'm still not confident this is right, there might be a much safer/more sane fix I'm missing here.. @sebmarkbage How does changed bits work? I don't mind adding it in a follow up PR. Thanks for the review. I plan on following up on the extra stuff on the plane tomorrow.. Added fix.. I've looked into this and here are some findings:\n\nsimple-2.js an invariant on serialization, fixed in #1555 \nclass-root-with-instance-vars.js this isn't a bug and now I think back, the main reason why the tests aren't shared between the firstRender. The global scope is concrete on first render, but the tests don't know this. We'd have to remodel the tests to make them universal for both modes.\nclass-root-with-refs.js an issue with serialization, fixed in #1556. @hermanventer I was under the impression we were going to remove the isFinal logic with your snapshotting changes?. This PR is blocking a bunch of problems from being fixed on the UFI. It would be good if we could decide soon on the best approach going forward.. @sebmarkbage I made the changes but tests still fail because the final checks prevent havocing, meaning the Object.assign tests fail. I'll have to wait for snapshotting to merge before continuing with this PR.. @sebmarkbage The tests are failing because the havoc logic never checked if they were final before, it was marking final objects as havoced. Then, as the objects were havoced and final, the logic for dealing with havoc was the first code path. . Okay I've rebased with master and greatly simplified all the logic to just be a few changes as per requested and all tests now pass! \ud83d\udcaf \n\n@gaearon mind reviewing please?. @NTillmann you are probably misssing a pure wrapper. Optimized functions used to all be pure with the node enabled.. I've removed the two tests related to this. Instead I added them to https://github.com/facebook/prepack/pull/1641 as comments to be added.. Closing in favour of a proper fix to come later.. @cblappert I'd expect it to throw a FatalError and the we'd recover and emit a temporal with the pure code like we do in other cases.. @sebmarkbage Any luck on this? It's common to run into this invariant, related to this issue I believe, and it causes the compilation to completely die:\nhttps://github.com/facebook/prepack/blob/master/src/values/AbstractObjectValue.js#L485\nAt least if we could change it to a FatalError, then we can continue and recover at least.. I believe this is a related fix: https://github.com/facebook/prepack/pull/1651. I believe not.. @hermanventer What logging infrastructure are you referring to specifically. Most of this PR is related to logging React information.. I just wanted to log out some basic information, Logger appears to be only able to log out things with given values. I couldn't see any other way of just outputting simple verbose information.. @hermanventer Gotcha. Let me know if my latest changes make sense then.. @hermanventer I found a few more cases where this issue still occurs with the UFI bundle. I'll ping over a repro to you so you can take a look at some point when you're free.. @gaearon This strategy fixes that, but that change was actually already made in a previous PR. The changes in this PR are more around reducing output so it's hard to test other than that the current coverage is also good coverage for regressions this might have brought with it.. @gaearon We could do, not entirely sure how to best do that, maybe we could introduce the comment system too. I feel that it might be a lot of work, so I can do that as a follow up next week. I'm just trying to get easy bail-out cases resolved right now.. Related: https://github.com/facebook/prepack/issues/1609. Another huge issue with timeout is that it\u2019s not deterministic. On my MacBook Pro I get different errors on React tests using the timeout feature compared to my Mac Pro. Your comments look good, I\u2019ll address them later :). I\u2019ll add a test case one the limit PR I created gets merged, it\u2019s hard to come up with case without it. I'll add tests around this in a follow up PR.. We bail out on leads now and recover, but it\u2019s not very effective. We actually want to recover on the body of a component function body. So we can continue with the leaf component.. @sebmarkbage that was an example, the real cases we're failing in are nested conditions many levels deep.. Addressed in https://github.com/facebook/prepack/pull/1614.. @NTillmann Would it make it easier to pull out my changes to Visitor and Serializer in relation to nested optimized functions? I can then land the PR without the tests that fail being skipped and we can work together on getting them to pass?. I'm going to land this PR now, the core logic I didn't want to break was the serializer changes. The React changes are limited in subset and have been confirmed against both existing tests and manual tests on the UFI. This PR is needed to unblock further work and stacking this PR with the amount of changes it has is messy now. I'm happy to make changes in follow up PRs, but given it's all React related there shouldn't be anything affecting Prepack master.. You also missed: https://github.com/facebook/prepack/blob/master/website/js/repl.js#L79-L83. Awesome stuff. Some tests around usage of \u201cthis\u201d and bind would be good too. I\u2019ll add them tomorrow.. Why did you need to change the content of the tests to make the build pass? Seems a bit hacky?. Please add these tests:\n```js\n(function() {\n  function f(x) {\n    this.x = 5 + x;\n    this.doSomething = function(y) {\n      return this.x + y;\n    }.bind(this);\n  }\nif (global.__optimize) __optimize(f);\nglobal.inspect = function() {\n    var obj = new f(10);\n    return obj.doSomething(20);\n  };\n})();\n```\nAnd:\n```js\n(function() {\n  function f(x) {\n    this.x = 5 + x;\n    var self = this;\n    this.doSomething = function(y) {\n      return self.x + y;\n    };\n  }\nif (global.__optimize) __optimize(f);\nglobal.inspect = function() {\n    var obj = new f(10);\n    return obj.doSomething(20);\n  };\n})();\n```\nI don't feel it's safe to really land this functionality till \"simple\" cases like above are supported.. @NTillmann In that case, we should add the tests but as \"skipped\" like I've done for some of the React tests and come back to them later \u2013 with a related issue.. @gaearon No bugs just and oversight, we just need to keep looping around in case more branches get added in closures and sub branches so we can process them all. I intentionally didn't update the tests so you can see the changes affect.. @gaearon Fixed the issues and added another test plus updates.. Rebased and added some basic tests. @NTillmann would be good to review this now as it's a long standing PR that was actually relatively simple to implement for basic cases.. It would be good if this could be reviewed soon, it's blocking the UFI work @sebmarkbage @NTillmann . @sebmarkbage Can you outline what you think needs to change for this PR to land? It's a big blocker on the current work we're doing. Can you maybe get the failing test in this PR to pass using what thoughts you have?. @hermanventer @sebmarkbage I've taken a different approach in my latest commit to this PR. I've swapped the invariant for a FatalError and now try and recover in MemberExpression if we're in pure mode. This means way less assumptions and the output code is far more safe to my eyes. Let me know if this a better approach. I'll attack the AbstractObjectValue invariant in another PR as this doesn't affect this particular problem it seems.. @hermanventer Made the changes as per your feedback.. @sebmarkbage If you try that, you run into this error: \nhttps://github.com/facebook/prepack/blob/master/src/methods/properties.js#L975\nI'm not sure I follow why this approach is wrong, if we use it for a write it should fail accordingly.. I'll close this in favour of #1680, thanks @sebmarkbage  :). Can we add these to a set of tests somehow? Like we have with Jest snapshots  \u2013 it saves all the values to a file after tests run and then on the next test run, they're compared.. This is all kind of coupled to to UFI for now, let's at least land this and I can work on this later in the week.. I was also confused by this, we should probably show a better error, like \"classes are not supported as optimized functions\". Unless someone actually meant to optimize the constructor \u2013 but that doesn't make any sense either.. @gaearon In case there was ever a case where two ObjectValue has the same names.. This approach isn't right as this should never happen. Closing for a better fix.. Not sure why the depcheck fails? This doesn't happen locally. @hermanventer . @gaearon I've made the changes as per your suggestion. The output now stops us emitting defineProperty for the length of functions that previous had no arguments, but we set them to having a value of 2.. @gaearon Yes, just an abstract value. Returning an abstract value is completely fine for example if you have a condition statement that is not known, you will return an abstract value (that is what is happening here).\njs\n  static getDerivedStateFromProps(nextProps, prevState) {\n    if (nextProps.a !== nextProps.b) {\n      return Object.assign({}, \n        prevState,\n        { title: \"Hello world\" }, \n      );\n    }\n    return null;\n  }\nThere's no way to force a conditional into an object safely that I can think of.. @gaearon I've taken a different approach that doesn't make as many assumptions unless absolutely needed as well as inline comments as to why we need to create a temporal object.assign when the partial abstract state is completely unknown.. Would also appreciate if @sebmarkbage has a look at this too. If we can't assume the partial state when we know an abstract value is totally abstract (comes from prevProps in most cases) and safe to assume doesn't have getters, then what alternatives do we have for getDerivedPropsFromState? We can't bail-out here either :/. Not really as this is for the case when a property from prevProps has been accessed. :/. Only in first render do we process gDSFP, we don\u2019t do this in normal mode. The nextProps argument can contain abstract values, so if you look at the tests on this PR you\u2019ll see. I want to do another pass on the logic in this PR anyway, to reduce the amount of code it emits in the complex cases.. @sebmarkbage So convert them from an abstract to an abstract object value and make them simple?. @hermanventer I'm not sure why, locally the build is quite a bit faster (2mins).. @gaearon No, the V8 team know of a regression but I'll need to bisect it myself and possibly come up with a patch/revert against V8. I'll do that next week.. @cblappert Did you get a chance to look at the failing test on this PR?. If I make a repro of the issue without the React code and make an issue for it instead @cblappert. Would that help more?. I've merge the latest master into this branch and it's still failing. I'll try and make a smaller repro and an issue for it.. @gaearon With all the latest changes, all tests in this PR now pass, so it's ready to be reviewed again.. I added a TODO in the source and we can pick this up in a follow up.. I've addressed all feedback (I think) that was in the scope of this PR and also included a more detailed description plus small refactors and comments in the code so there's more clarity as to why I did it this way.. I found the correct fix after more digging. I was apply the nest closure effects in the wrong order.. @gaearon It's part of the lint process currently on the CI. This change was made on fbsource, not on Github, so it skipped the CI process entirely.. @NTillmann This issue is fixed with the changes I made in my PR: https://github.com/facebook/prepack/pull/1768\nI'm not sure why, but maybe the latest condition to not emit the generator of a PossiblyNormalCompletion effects is part of the cause. Related to https://github.com/facebook/prepack/commit/2b1bf611db50c0c86b0014d3d8b834d56bbf0b17. Looks to be fixed.. @sebmarkbage Thanks, I will do.. Okay, I've now made a large refactor to use the logic explained in @sebmarkbage's comments. Rather than using abstract values, we now use concrete array values and use unknownProperties to make this all work.. Thanks for the feedback, I'll address them tomorrow morning and I'll fix the tests. :). Is everyone happy with this PR now? I've made all the changes as per requested. I'd rather address more feedback and cover other issues in a follow up PR, as to not overburden the size of this PR.. I looked into this and I have a PR (https://github.com/facebook/prepack/pull/1781) that fixes some of the issues but the underlying issue looks to be that we're mutating a variable _cachedFbtResults from within a pure function. This goes against the function being pure in this case and might be the reason for things breaking (they weren't accounted for when creating this functionality in Prepack).. That's not intended \u2013 in this case, we're serializing a value that was not visited. If you remove the invariant, can you see what is not correctly being emitted properly?. var _$7 = \"\" + _K;\nif (_U !== __empty) _R[_$7] = _U;else delete _R[_$7];\nThis definitely looks like a Prepack bug that has come about recently. @NTillmann might have more context as to the source.. This isn't fixed yet. Still fails for me.. My bad I hadn\u2019t rebased. @gaearon I'd rather we were correct and addressed performance when it becomes the primary issue. For now this is not for first render route too, so it shouldn't affect current work.. @gaearon Not at this point, as arrow functions are not supported. I'll make a not on my arrow function PR to include logic for this too. https://github.com/facebook/prepack/pull/1650. @gaearon Added test and made the change you requested.. @sebmarkbage @NTillmann I'm struggling to get the tests in this PR passing, please could you check out this PR and see if you can help if you get a chance?. @NTillmann @hermanventer  For the 2nd test, where the cache is outside of the additional function (shown below):\n```js\nvar cache = {};\nfunction additional1(x, y) {\n  if (!cache[x]) {\n    cache[x] = y;\n  }\n  return cache[x];\n}\nif (global.__optimize)\n  __optimize(additional1);\ninspect = function inspect() {\n  return additional1(\"a\", 5);\n}\n```\nCurrently, with this PR applied, I run into the following invariant with this test:\n\nThe value it's waiting on is for this conditional if (!cache[x]) {. Any ideas?. @NTillmann I've removed/skipped the failing tests to do with mutated the object outside the optimized function. I'll tackle that as another PR so this can land.. If we can get a repro case for this, I think I have a good idea how to fix it.. I believe this should be fixed with #1807 too.. This case still fails for me and seems to be related to the React issue:\n```js\nvar cache = {};\nfunction additional1(x, y) {\n  if (!cache[x]) {\n    cache[x] = y;\n  }\n  return cache[x];\n}\nif (global.__optimize)\n  __optimize(additional1);\ninspect = function inspect() {\n  return additional1(\"a\", 5);\n}\n``. Fixed by https://github.com/facebook/prepack/pull/1805.. This is failing becauseSymbol.for(\"react.element\")has been assigned to the object, making the visitor think it's a ReactElement.. @gaearon We can refine theisReactElementcheck to ensure the object has atypeandprops` too.. It's obscure because we skip looking at the prototype if it's a ReactElement, because we don't want to serialize the prototype in the case of using JSX sugar. In this case, we're creating an object via a function constructor, so it goes a different route via the normal serialization of ReactElement, and instead sees it as a function first then object after.. The getTarget issue from this PR will be resolved from https://github.com/facebook/prepack/pull/1810. We then get an invariant from this above test case: \nInvariant Violation: an abstract value with an identifier \"_$1\" was referenced before being declared. Fixed.. I tracked this down to a possible bug in composeNestedThrowEffectsWithHandler. Specifically, the same effect in priorEffects is being applied twice:\nhttps://github.com/facebook/prepack/blob/124451fd4de31338008cffbd57aceaecc29d1a99/src/evaluators/TryStatement.js#L116-L118\nhttps://github.com/facebook/prepack/blob/124451fd4de31338008cffbd57aceaecc29d1a99/src/evaluators/TryStatement.js#L133-L135\nI believe I have the fix for this here: https://github.com/facebook/prepack/pull/1811. I'll look into this one today.. Fixed.. Closing this. This isn't the right fix. PR with a better fix: https://github.com/facebook/prepack/pull/1811. @NTillmann That was there from before, what do you suggest replacing it with? I can use getProperty that should not have the same side-effects.. @gaearon The reason for not using withEffectsAppliedInGlobalEnv directly was because it does a bunch of logic that would conflict with the logic in TryStatement \u2013 specifically it applies the effects passed in, when we don't want that as the logic in TryStatement is to apply a list of priorEffects.. I've tidied up the solution and added comments.. @NTillmann is this fixed now?. I don't get this invariant on master \u2013 has it been fixed?. @gaearon Never mind, I can see the invariant now.. I did some digging into this issue. It appears the invariant is firing when trying to find the AdditionalFunction target body. This particular target body was pushed into _activeGeneratorStack and then later on was popped off the array at this line at the end of emitting:\nhttps://github.com/facebook/prepack/blob/master/src/serializer/Emitter.js#L158\nI'm not really sure what all this code is 100% doing, I'm sure @NTillmann has a much better idea. It could be that we shouldn't pop an entry in _activeGeneratorStack if it's being awaited by another value maybe?. @NTillmann Do you want me to do some more digging on this issue or do you have a rough idea what the issue is?. I'll look into this next to see if I can see anything obvious.. This no longer triggers an invariant. I'm not sure which PR fixed this, as there might already be a test case for this? If not, we should add it so we don't regress. @gaearon do you know which PR fixed this?. @gaearon The fragments are symbols that we don't visit as we don't serialize out the actual creation of the symbol (rather, it's an implementation detail in React itself.. @gaearon Yep, as we don't visit the \"type\" of ReactElements when outputting to JSX.. @sebmarkbage I'm happy for you to add a follow up, please check my comments too.. It looks good, would you mind adding the test cases you put in the previous PR in here too please?. In the case of _4, it is meant to be assigned twice. This is completely intentional. It happens because ReactElement are immutable nodes, and a mutation on the ReactElement at a later point (because we're waiting on a property) means we have to serialize a complete new object and re-reference it.\nThis isn't to do with hoisting, it's to do with how the ReactElementSerializer \"waits\" for values via _serializeNowOrAfterWaitingForDependencies. I suspect there might be something wrong in this PR too? I'll dig deeper.. So after looking into it, the issue appears to be around the added:\nthis.residualHeapSerializer.emitter.getBody() to ResidualReactElementSerializer. It never used this before. The issue is that it's giving us the AdditionalFunction body, but this isn't the right body. The target body should be of that of the conditional. Currently it emits this:\njs\nif (_1) {\n  var _$1 = _S.className;\n  return _4;\n} else {\n  throw _L;\n}\n_4 = <div className={_$1}>{_9}{_G}!</div>;\nIt should be this:\njs\nif (_1) {\n  var _$1 = _S.className;\n  _4 = <div className={_$1}>{_9}{_G}!</div>;\n  return _4;\n} else {\n  throw _L;\n}\nThe ReactElement serializer isn't doing anything wrong here \u2013 it's designed to emit to the same variable many times \u2013 that's actually a very important feature. It does this because when we inline and fold components, ReactElements naturally get their stucture shared. This can be problematic because of the fact they're immutable. Prepack normally just mutates the existing object at different parts to get around this, but we can't do that. So we have to create new ReactElements. In the above example you can hopefully see that the condition _1 results in the ReactElement gaining className attribute or not, so we have to emit the ReactElement before when it doesn't have className and again in the condition, when it does.. I created a PR that splits the ReactElement visitor logic out and should make these problems easier to find. https://github.com/facebook/prepack/pull/1858.. I've merge master into this branch and fixed merge conflicts.. I've got a repro that isn't React specific, but shows the exact same problem:\n```js\nfunction nullthrows(x) {\n  if (x != null) {\n    return x;\n  }\n  throw new Error('no');\n};\nfunction App(props) {\n  nullthrows(props.className);\n  return {\n    className: props.className,\n  };\n}\n__optimize(App);\n```\n@NTillmann does that help any?. I merged master and all tests are looking good. I want to merge this now as quite a few small bugs depend on the fixes in this PR.. Opps, sorry, we did it exactly at the same time! :D. @gaearon I agree that the traversal logic is somewhat duplicated. Let's try and tackle that in a follow up PR together.. @NTillmann if you check out this PR and try this in fb-www/input.js:\n```js\nrequire(\"react\");\n__evaluatePureFunction(function() {\n  var React = require(\"react\");\nvar lazy = null;\nfunction createLazy() {\n    if (!lazy) {\n      lazy = {};\n    }\n  }\nfunction URI(arg) {\n    if (!arg) {\n      return;\n    }\n    var obj;\n    if (arg === 0) {\n      obj = {};\n    }\n    if (!{}[obj]) {\n      throw new Error(\"no\");\n    }\n    this.foo = obj;\n  }\nfunction Middle(props) {\n    var foo = props.href.foo;\n    URI(foo);\n    var href = URI(foo);\n    createLazy();\n    return href;\n  }\nfunction App(props) {\n    return React.createElement(Middle, {\n      href: new URI(\"http://foo.com/\" + props.x)\n    });\n  }\n__optimizeReactComponentTree(App, {\n    firstRenderOnly: true\n  });\nmodule.exports = App;\n});\n```\nI get an issue where it still tries to visit an AbstractValue that was created in the React component render's effects. The thing is, these effects are never applied and should be reverted because an impure component tree was detected. For some reason, the binding value was not properly restored to null.\nSame as https://github.com/facebook/prepack/issues/1854 I believe.. @hermanventer Fixed the cycle length.. @NTillmann I looked at __residual and it doesn't do what we want. I originally applied the havoc logic to __residual, but then thought it might be risky as these are used on RN in production which might be dangerous right now. We can align what we mean and what to do in a design meeting \u2013 there should be some form on convergence though as I'd imagine you'd want to use safeSideEffect in IR.. The alternative to address @sebmarkbage and @NTillmann concerns for this PR might be to removed __safeSideEffect entirely. We'd need to refactor all the tests though, but maybe that's a good thing. What do you think @gaearon?. Let's do that then. I'm happy removing __safeSideEffect \u2013 I never liked it, I just thought everyone else would want it and I'm somewhat happy that everyone seems to be equally supportive of not having it. Plus it adds additional complexity that we would be best to avoid right now. If anyone else would like to apply the changes to this PR to remove it, feel free!. We might not need to. The tests in this PR needed simpleClosures because of __safeSideEffect but if we're removing it we might not need to change that flag \u2013 as long as we fix up all the failing tests.. @sebmarkbage @gaearon I've removed __safeSideEffect from this PR. I've also updated tests that now fail because of side-effects in the render phase and rather than removing them (I did remove one firstRender test as it was actually a bad test), I added a test assertion called expectReconcilerRenderBailOut that validates the error threw. The error is validated and the message it has is snapshotted so can detect regressions where the error message changes.. Furthermore, we should follow up with @sebmarkbage's proposal in another PR. I'm not sure the best way of automatically doing this \u2013 but maybe we can be explicit like in the examples @sebmarkbage gave. Either way, it's not in the scope of this PR and we should design around that in a follow up.. @sebmarkbage I tried that originally but it didn\u2019t work for me. :( this why I had to check the effects after the entire render. This might be because the FatalError is being caught and a fallback is in place. @sebmarkbage are you happy with this PR now?. The issue here appears to be that the temporal isn't being serialized:\nhttps://github.com/facebook/prepack/blob/master/src/react/elements.js#L92-L99\nIf you remove the throw, you can see this temporal is emitted correctly.. This test now has a different issue.\nOutput:\n```js\n  var 0 = function (props, context) {\n    var $0 = props.a;\nvar _1 = _$0 === true;\n\n_5 === void 0 && $f_0();\nvar _4 = {\n  children: _5\n};\n\nif (_1) {\n  var _7 = props;\n\n  var _$1 = _$7(_4, _7);\n}\n\nif (_8) {\n  if (_1) {\n    var _$2 = _4.b;\n  }\n\n  return _B;\n} else {\n  var _E = (__constructor.prototype = _$9, new __constructor());\n\n  $$0.value = \"Error\\n    at MaybeThrow (/Users/ADM/Projects/prepack/fb-www/input.js:8:9)\", _$A(_E, \"stack\", $$0);\n  $$0.value = \"no\", _$A(_E, \"message\", $$0);\n  throw _E;\n}\n\nvar _8 = _$2 === false; // <--- this should be defined above, not down here\n\n};\n``. I've extracted the failing non React case from this issue into https://github.com/facebook/prepack/issues/1914.. @sebmarkbage will know about this, as he added this specific type ofObject.assign` usage. Maybe there was an unforeseen side-effect from doing it here?. I figured it out, it requires re-writing the React reconciler abstract conditional evaluation logic :)\nFixed in https://github.com/facebook/prepack/pull/1874. I've rebased it with master.. I'm going to merge, assuming that's okay with @hermanventer so I can feed this into some other fixes I have.. @gaearon Fixes as per request. This seems much better.. @gaearon I made a change to pass through args. I like your follow up PR too, looks good. Temporals don't usually have args, instead the entries to the generator contains the args.. I'll hold off landing this PR, it still doesn't feel right.. My PR does appear to fix the problem at hand even if the output is not optimal \u2013 maybe we should add more tests too though. Unless I've mistaken you? The follow up should be to refine the output like your follow up PR does; furthermore, Sebastian may have ideas on that.\nI agree though, I'm also confused somewhat as to what the wider fix should be. It's probably obvious and we're close. Let's wait for @sebmarkbage to clarify his comments on the issue.. Is this PR still an approach we want to look into again? Or should we close it?. If you can put a PR up for the fixes to havoc, do any of the existing tests fail? If not, we can at least fix the invariant and then follow up with a PR to fix the output.. I think should make a wiki homepage and link to it from the website and the README and Contributing.md entry points.. Will be the basis for a hackathon I wanted to do this week to see if we could render a fully evaluated component tree to a template string. :). Thanks for this :). The sourcemaps test is failing, not sure why though. @NTillmann any idea how to get it passing?. @anilanar Many of them are as their contents are not something we want to serialize (as it's all internal implementation details).. @anilanar This function might have been missing an intrinsic value intentionally, thus why it was set as undefined. I tested giving it an intrinsic value but that didn't fix the core issue here (you're not meant to serialize Map.prototype.size as a prototype function, it's strictly an internal getter I believe).. @NTillmann they needs ids for JSX. Specifically, how you reference things with JSX has particular quirks, as things lowecase <div> are not referenced components, but those with uppercase and _ are referenced components, thus why <_$1> works. @sebmarkbage might be able to shine more light on this as he helped me get my head around these issues early on, he might have another fix.. @gaearon I shouldn't expect so, I'll do a scan through the codebase tomorrow to make sure.. It's failing because it can't get Array.prototype.map when partial because it goes down this codepath:\nhttps://github.com/facebook/prepack/blob/master/src/methods/properties.js#L1179. If we make them partial, we'll need to special case a bunch of places for them so that accesses to prototype methods passes through. I'm not sure which is the better approach.. So I looked into this and it took many attempts to get this working. In essense the reason the latest changes seemed to work, was because setting an abstract length value was causing a FatalError which meant that the pure scope recovery was kicking in and passing the newly added tests. This also meant that all the respective React tests were failing as the new special arrays were never being applied.\nI looked at every approach I could think of, including adding an abstract length value. Even if I made the abstract length work, I had to make a build function so at runtime, we could properly derive the O.length, the problem was that this resulted in countless serialization issues. If I created the length as a temporal value, I got the furthest, but then we also emitted the length and I had some tests still failing when dealing with combination of nested conditions an the fact the array is intrinsic.\nI then decided to add more tests around arrays and I saw even more issues with serialization, where things just weren't being emitted at all. The limitations of what our serializer can do is becoming very apparent but I managed to find a work around. \nInstead of creating an array the conventional way and assigning an abstract length, I went back to the old way of not defining a length and instead adding in checks for the special array in places where things would break. This resulted in all the tests (including the new ones) to work properly and also gave the opportunity to tidy up some parts and add better support in other areas. Furthermore, the serialized output actually looks good without bloat.\nI'm going to continue working on the special arrays in a follow up PR, as I feel this PR is now in a good place to land if people are happy with it. The follow up tasks I want to deal with are:\n\nhandling the special arrays in loops\nhandling the special arrays in array spread\nhandling the special arrays in Object.assign. @hermanventer Feel free to add/change anything that I did in my latest commit to get this PR into a state where you're happy for it to be merged.. @gaearon I don't believe this is a bug introduced by this PR, but rather another deeper issue that seems relates to all the other temporal issues (ordering of how they are emitted are wrong). I think we should make a follow up PR to try and fix that rather than add to this already very large PR.. I know @loganfsmyth and @hzoo might be super busy, but if they could take a look at some of the Babel related code here it might be good to see if there are any further optimizations that we might be able to do to improve performance.. This implementation allows mutating it in the constructor, after that it makes it immutable. I intentionally forbid it here. This is a good constraint to have IMO as we state that that outside of the constructor state should only be updated via setState or via getDerivedStateFromProps.. @gaearon Not that I could see, it fixed the same issue coming up that https://github.com/facebook/prepack/pull/1955 fixed. Given that PR already landed, this PR fixes nothing now :). @NTillmann Addressed your comment.. @NTillmann I've spent most the day looking into how we might fix this problem. In the above case, a.callFunc bails-out, resulting in a temporal CallExpression abstract value where its contents (including b are havoced). When visiting the entries, we visit the function and address its bindings (b in this case) in this._enqueueWithUnrelatedScope. Which means, we see a different binding from what we would have done with the effects of the condition applied (which is the entry for the Object.assign(...)). When we get to serializing the conditional generators, the binding serializes out to be an abstract conditional but this gets emitted after the condition generators are serialized.\n\nI thought how we might get around this. This seems related to CallExpression bailing out for now, so I looked into adding in more temporals for each of the bindings in the closure before we emit the bailed out call expression.  So the idea is that we then do this:\n```js\n  var _1 = function (a, b, c) {\n    var _C;  // <-- we emit all variable declarations for inner closures at the top of the parent\n    var _A = function () {\n      return _C.foo;\n    };\nvar _2 = !a;\n\nvar _B = _$5;\n\nif (!_2) {\n  var _4 = {};\n\n  var _$0 = _B.assign(_4, c);\n\n  var _6 = _$6(a);\n\n  _C = $0;  // <-- we know assign the value at this point\n\n  var _$1 = _6.callFunc;\n\n  var _$2 = a.callFunc(_A);\n}\n\n_C = _2 ? b : _$0;  // <-- we leave this as before, except we don't add a var\n\nvar _7 = _2 ? null : _$2;\n\nreturn _7;\n\n};\n```\nit relies on making a single variable declaration for all bindings inside inner closures. Thinking about it though, we should probably be doing this anyway.\nI have a hacky solution that makes this issue work: https://github.com/facebook/prepack/pull/1975. I don't hoist the declarations to the top of the function though, but it follows the same premise I mentioned about in regards to emitting a temporal before the abstract function call occurs.. I think we should go ahead and try it out. @sebmarkbage and @gaearon may have different thoughts, but our aim for this half was always to be correct first. We can always further optimize and redesign things better next half.. The depcheck test was passing in this PR and in recent commits is failing. I'm not sure why, it started failing after I edited the comment.. I think this may be supported already: https://github.com/eslint/eslint/pull/7948. This is great, really improves the output in React components too.. Actually, I don't think we need to do this \u2013 as it won't help the React compiler if we have an abstract instance.. @prometheansacrifice Please can you merge/rebase master on this PR?. This PR now fails CI on ArrayFrom2.js, so I'm closing this PR for a follow up at a later point as this is no longer that important (the fix for this already landed).. For example:\n\n@hermanventer If you use the same repro bundle I sent you last time, you should see the same issues.\n. @gaearon Fixed the lint. Oops.. @hermanventer I'd be happy to send you the repro test case. Maybe you can see something I cannot?. After looking into this more, this is a fix, but it's not the right fix, so I'm closing this for now.. @NTillmann How do you mean? All the tests still run, I've not removed any tests. I've had to add variable declarations or explicit global \u2013 but that's a good thing in the long run, as it means our tests follow best practices for actual JS too. Feel free to add a flag to disable the linter on some tests and/or a follow up issue and I can tackle it some time in the week.. @NTillmann The regression tests are the existing tests in this case \u2013 if they all pass, then this is all good. The internal case on our bundle that fails is far too complex to create a repro of :/\nHowever, I added a bunch of tests for the holely array cases.. This is awesome, thank you!. I have another failing havoc residual case here: https://github.com/facebook/prepack/issues/2017\nI'm not sure if it's related to what this PR should fix too?. @NTillmann That makes sense. Let's get this PR landed then as it fixes a bunch of issues on our FB bundle. :). > if, it doesn't deal with abstract loop conditions: ToBooleanPartial throws on abstract values\nThis is one of the main bail out causes in the React reconciler when running on the internal FB bundle. We should definitely fix this.. I noticed a few bugs with this PR applied when running on our internal bundle. I'll try and make repro cases but one of them looks pretty simple \u2013 we're emitting this line:\njs\n_23U.arguments = void 0;\n_23U.caller = void 0;\nYou can't do this in StrictMode:\n\nWe should check if we're in StrictMode and forbid emitting those properties otherwise we can runtime errors trying to do so.\nSimilarly, we can't assign the length or name to a function as they're read-only properties:\njs\n_23U.length = 1;\n_23U.name = \"bound \";\n\n. Here's a repro, all I did was add use strict to each function:\n```js\nfunction Component(x, result) {\n  \"use strict\";\n  this.val = x;\n  this.result = result;\n  this.do = function(x) {\n    return this.val + result;\n  }.bind(this);\n}\nfunction foo(a, b, c, result) {\n  \"use strict\";\n  if (!a) {\n    return null;\n  }\n  var _ref11;\n  var x =\n    (_ref11 = b) != null\n      ? (_ref11 = _ref11.feedback) != null\n        ? _ref11.display_comments\n        : _ref11\n      : _ref11;\nvar a = new Component(x, result);\n  var func = a.do;\nreturn c(func);\n}\nglobal.__optimize && __optimize(foo);\ninspect = function() {\n  function func(x) {\n    return x();\n  }\n  var val = foo(\n    true,\n    {\n      feedback: {\n        display_comments: 5\n      }\n    },\n    func,\n    10\n  );\n  return JSON.stringify(val);\n};\n``. To get around this locally, I did this, which was a quick hack tohavoc.js` in this PR:\njs\n// TODO: Support havocing objects with non-standard properties\n// We have repros, e.g. test/serializer/optimized-functions/HavocBindings1.js\nif (\n  obj instanceof FunctionValue &&\n  (name === \"name\" ||\n    name === \"arguments\" ||\n    name === \"length\" ||\n    name === \"caller\" ||\n    name === \"callee\")\n) {\n  continue;\n}. @NTillmann These issues seem related to realm.evaluateWithAbstractConditional. It's calling this.applyEffects that changing the descriptor values to an AbstractValue, when they were concrete before. Why is it mutating the descriptor values of final/frozen objects? :O. This case throws an invariant with this PR:\n```js\nfunction Component(props) {\n  var x = props.x ?  : ;\n  props.foo(x);\n  return props.y ? x : ;\n}\n__optimizeReactComponentTree(Component, {\n  firstRenderOnly: true,\n});\n``. Another failing case, throws aninvariant` as per like you reported earlier:\n```js\nfunction Child1() {\n  return null;\n}\nfunction Child2() {\n  return null;\n}\nfunction Child3(props) {\n  return props.x;\n}\nfunction Component(props) {\n  var MixedType = props.x ?  : ;\n  props.y(MixedType);\n  var elem = ;\n  return elem;\n}\n__optimizeReactComponentTree(Component, {\n  firstRenderOnly: true,\n});\n``. @NTillmann I updated the last test case, I made a mistake with it. Sorry about that.. @NTillmann are you happy with the requested changes?. @NTillmann Sorry, I didn't push my latest commit where I removed that.. Turns out this PR was a red herring. So closing.. @NTillmann I'll gradually get around to all the built-ins, but I want to do it gradually and maybe then hand off as a good task for someone new to Prepack. I agree about extending on the havoc implementation, but for now these changes are useful to unblock some inlining possibilities on the internal bundle experiment :). The issues in the summary are in relation to the PR failing on our internal FB bundle test: https://github.com/facebook/prepack/pull/2023. For some reason, with that PR, the properties of a ReactElement become abstract.. @gaearon I added a ton of test cases and handled all the different possible cases.. With final objects, we shouldn't be able to changefoo` to 42, it should throw in that case.. Thanks!. I see an invariant on this issue with master now. Which is a bit worrying, was this from the recent changes @cblappert?\nEdit: I see https://github.com/facebook/prepack/pull/2110 hasn't merged yet, does that PR fix this issue?. @hermanventer I believe this new invariant we're seeing might be related to some of your recent PRs. With the above test case, this is the invariant we're getting on evaluateWithAbstractConditional in realm.js:\n\nAny ideas as to why this might be happening now? This issue above used to result in an infinite loop before.. @NTillmann Ideally, if we could give up somehow or \"bail-out\" and leave the loop constructs as temporals and treat the body of the loop as an optimized function (I believe we already have this code done for loops anyway?). Maybe @sebmarkbage and @hermanventer might know more. At the very least, we should bail out somehow \u2013 an infinite loop in Prepack should never occur.. I can try and take a look at this, maybe @NTillmann can give me some pointers before I begin?. @NTillmann It is indeed that area, we already have React tests working with some subset of nested optimized React functions for a while now. I was wondering why there might be issues in this particular case. The above \"non-React\" test by @gaearon might help more, so you don't need to know the internals of the React reconciler.. @gaearon I'm cool with that. Will be good to get those bugs ironed out this half. Nested optimized functions might be a good starter for next half then.. This appears to be fixed on master now. PR up: https://github.com/facebook/prepack/pull/2124. @gaearon Was this fixed?. @hermanventer Are you happy with this PR now?. @NTillmann just let me know that he'll be looking into a proper general fix for Object.freeze/final objects. So that PR should succeed the changes in this PR, but this is good for now.. @sebmarkbage Sorry, can you re-review. I hadn't pushed all the commits and you read a very outdated version. We don't need to havoc anything, because in cases where the target is abstract and not simple, we rethrow.\nObject.assign({}, {x: 1}, abstract); This works with my latest changes as do all the existing Object.assign tests.. I believe I've now addressed all feedback and added more tests intending to break the new logic \u2013 finding bugs that I've since fixed.. @sebmarkbage We didn't get around to looking into this together this week but if we could maybe review again next week, that would be awesome. If you can think of test cases that might break this, that would be even more awesome.. @sebmarkbage I've made the changes as per your feedback. In regards to correctness, I meant build time correctness. We used to incorrectly bail out before with Object.assign in cases like:\njs\nfunction fn(someAbstract) {\n  var foo = Object.assign({}, someAbstract, {a: 1})\n  return foo.a;\n}\nThis is a big issue at build time, because it means we're incorrectly seeing things as abstract when they're not at all. Although havocing would mean this is correct at runtime, we need to be more correct at build time too or we end up doing unnecessary work at build time. I'm calling this build-time correctness and I've added tests that cover this.\nI've dealt with all the concerns, and made it so we havoc frm and also tidied up the code so it's in the same format as before (actually it's even cleaner now).. @gaearon I needed to move the snapshot function call to with the try so it happens when the object is not partial. I've made that change and the test should now pass.. It would be good if we good re-cut the release version to master because of this PR https://github.com/facebook/prepack/pull/2082. Otherwise there's a missing dependency using Prepack.. Thanks!. You can try using master for now. I\u2019ve got a PR that fixes this.. @sebmarkbage At some point, not sure when that should be though.. @gaearon I just landed. Thanks though! :). @hermanventer Are you happy with this PR now after our discussions?. @gaearon Would you mind giving this PR a look too please?. @gaearon That's a really awesome find with that bug. I feel it's actually a big underlying issue, that might already exists with standard if/conditionals. Can you see if you can also reproduce with them? If so, I'll need to make another PR that tackles that issue. Maybe we can also get ReactElements to wrap correctly in if statements too.. @gaearon Okay, then it's just a bug with this PR, that's good news.. @gaearon Fixed the issue you had above.. We have a fix for this on an internal diff: D8301297. So closing this PR for that.. Added custom Jest mocks for RN so tests correctly work. This PR is now good for review.. @gaearon Regarding splitting up into separate test files, I believe this might not be possible with Jest. @cblappert looked into this and I believe was told that we couldn't use custom config unless we forked the Jest test-runner and made our own version.. @gaearon That mock stuff shouldn't take too long to do, it's the fact we run the same test with multiple iterations and configuration. I'm not saying it's not possible, it just not a simple task that one can do in a few hours (unless you know something I do not). We need to think about how it might work and design it?. @gaearon Making these changes allows the serializer to not emit temporals that never end up getting used, reducing the output and also making it easier to debug the output (less spam of temporals). The current tests and internal snapshot tests should cover all the cases for this change.. @gaearon @hermanventer Added a regression test :). I'm going to have to defer this PR, as it's getting stuck on an internal FB test during serialization. @cblappert thinks it might be due to the fixpoint computation. @NTillmann @hermanventer any ideas? I've sent a repro case on workplace in our group so you can see this occurring for yourselves.. This PR is all good now. https://github.com/facebook/prepack/wiki/Compiler-assumptions. @hermanventer I just checked this out and the failing React test seems to be a failing Jest snapshot. The snapshot looks to have been recording something that should have been failing, so this PR actually fixes a previous regression! If you update the snapshot on your PR, the test will pass (yarn test-react -u).. Thanks!. @gaearon I wondered how to do that. We don't have any infrastructure to currently do that (counting createElement calls sounds flaky) reliably. I'd need to do that in another PR.. @gaearon Added a regression test!. I\u2019m redesigning this implementation around temporal alias values now. So it\u2019s WIP.. @gaearon Sure, here's simple render with jsx spread 10.\nBefore:\n```js\n  var 5 = function (props, context) {\n    var _S = props;\n    var $0 = _S.key;\nvar _$1 = \"\" + _$0;\n\nvar _$2 = _S.ref;\nvar _T = _$E;\nvar _8 = {};\n\nvar _$3 = _T(_8, props);\n\nvar _$4 = _U(_$3, _2);\n\nvar _$5 = _8.item1;\nvar _$6 = _8.item2;\nvar _$7 = _8.key;\nvar _$8 = _8.ref;\nvar _B = {};\n\nvar _$9 = _T(_B, _$4);\n\nvar _E = <_0 text={_$5} />;\n\nvar _G = <_0 text={_$6} />;\n\n_B.children = [_E, _G];\n\nvar _L = <span>{_$5}</span>;\n\nvar _N = <span>{_$6}</span>;\n\nvar _I = <div {..._$9}>{_L}{_N}</div>;\n\nreturn _I;\n\n};\n```\nAfter:\n```js\n  var 5 = function (props, context) {\n    var _S = props;\n    var $0 = _S.key;\nvar _$1 = \"\" + _$0;\n\nvar _$2 = _S.ref;\nvar _T = _$G;\nvar _8 = {};\n\nvar _$3 = _T(_8, props);\n\nvar _$4 = _U(_$3, _2);\n\nvar _$5 = _8.item1;\nvar _$6 = _8.item2;\nvar _$7 = _8.key;\nvar _$8 = _8.ref;\nvar _B = {};\n\nvar _$9 = _T(_B, _$4);\n\nvar _E = <_0 text={_$5} />;\n\nvar _G = <_0 text={_$6} />;\n\n_B.children = [_E, _G];\nvar _I = {};\n\nvar _$A = _T(_I, _$4);\n\nvar _L = <span>{_$5}</span>;\n\nvar _N = <span>{_$6}</span>;\n\nvar _J = <div {..._I}>{_L}{_N}</div>;\n\nreturn _J;\n\n};\n```\nIn the future, we should somehow detect this deadcode block, this was the original Object.assign that we cloned:\n```js\n    var _B = {};\nvar _$9 = _T(_B, _$4);\n\nvar _E = <_0 text={_$5} />;\n\nvar _G = <_0 text={_$6} />;\n\n_B.children = [_E, _G];\n\n```\nBut that's a separate issue. We can actually remove most of it by adding isPure on the Object.assign in question above, but then the visitor takes about 10mins to run on our internal bundle :/. @gaearon This is a better approach because we've run into many issues in the past with immutable objects (such as props and ReactElement). After spending a significant amount of time trying to get temporal entries for ReactElements, the thing that was always breaking was when a temporal ReactElement had a dependency on a props object that had a temporalAlias. Given we didn't clone the temporalAlias, and rather we shared the temporal alias, it meant that a ReactElement in its own effects but was referencing a temporal that was created in another effects, it would leave to variables being declared in one place, but not the other. This doesn't happen on master with non-lazy ReactElements because they're not temporal and always concrete and in the top scope, so having a props with a shared temporal actually works fine as the ReactElements always serialize at the end of execution \u2013 so all the temporals will already have been defined.. Can you add a test has an inspect function with a Promise returning from it? Also, does the test runner wait until each async test has resolved before continuing to the next test?. @prometheansacrifice Why would this work?\n```js\nfunction fn(resolve) {\n  setTimeout(function() {\n    resolve();\n  }, 100);\n}\ninspect = function() {\n  return new Promise(fn);\n}\n```. @sebmarkbage I was just looking into the exact problem. :) Thanks for the example too.. This PR is blocked on https://github.com/facebook/prepack/issues/2122. I'm seeing one last issue with this PR and leaked bindings. Will try and make a repro for it.. @NTillmann Please can you look at this failing test? I've attached the same test to this PR, so you can check it out locally and run the serializer test to see the same failure. It looks like we're close, just this last failing lazy binding case to solve.. I tried out this PR on our internal FB bundle and I get plenty of lint errors now with variables being used before they're defined:\n'_PO' was used before it was defined. (8019:21)\n'_PT' was used before it was defined. (8021:21)\n'_PY' was used before it was defined. (8023:21)\n'_Pd' was used before it was defined. (8025:21)\n'_PO' was used before it was defined. (8684:23)\n'_PT' was used before it was defined. (8686:23)\n'_PY' was used before it was defined. (8688:23)\n'_Pd' was used before it was defined. (8690:23)\n'_PO' was used before it was defined. (18744:27)\n'_PT' was used before it was defined. (18777:27)\n'_PO' was used before it was defined. (19592:27)\n'_PT' was used before it was defined. (19594:27)\n'_PO' was used before it was defined. (19598:25)\n'_PT' was used before it was defined. (19600:25)\n'_PY' was used before it was defined. (29817:27)\n'_Pd' was used before it was defined. (29850:27)\n'_PY' was used before it was defined. (30665:27)\n'_Pd' was used before it was defined. (30667:27)\n'_PY' was used before it was defined. (30671:25)\n'_Pd' was used before it was defined. (30673:25)\nIf you use the same input.js I gave you last time, with debug-fb-www, you should be able to see the same errors. I'll try and reduce.\nIt seems that they are all conditional abstract values with dependencies from quickly glancing at the backing values behind all these bindings.. @gaearon tagging you on this as I\u2019ve tried to come up with a small repro all day but I\u2019ve really struggled. It\u2019s only noticeable when we try and optimize the root component on our internal bundle and this seems to be related to begin with on the pluginsList variable. If you get time next week, would be good if you can take a look and see if you have more luck.. @NTillmann Good points, glad I'm on the right direction with this PR then. I'll likely come back to this PR some time in the future, as I have far too many other things to be working on now. So if either you or @gaearon have any bandwidth to tidy and clean up this PR, feel free!. I've addressed @NTillmann's feedback regarding mutatesOnly and changed this PR to reflect his comments. I've also fixed the Flow issues and took in the note from @cblappert in regards to mightBeSkippable.. I've put up a PR that refactors the React equivalence logic so that it works with this PR and fixes a bunch of subtle bugs found when this PR was merged: https://github.com/facebook/prepack/pull/2138 applied.. I've found other bugs with this PR when running this bundle on our internal bundle test. Specifically:\nhttps://github.com/facebook/prepack/blob/9c11ec9a5e3435a343f3ffed92591b6b758e6c6d/src/values/ObjectValue.js#L145\nbinding.descriptor is undefined when mightNotBeHavocedObject is called.\nI'll try and make a repro and give more information on this.. I'm seeing a new issue with this PR and our internal bundle related to the equivalence system (like I had with the React objects), but this is with normal object bindings, specifically:\nDuring the visitor phase, we hit generator entries that hit an abstract conditional value. We find it's equivalent to another abstract value and replace the arg.value. We then visit an object at a later but this time we're inside some nested effects. We go through an object's properties:\nhttps://github.com/facebook/prepack/blob/master/src/serializer/ResidualHeapVisitor.js#L281-L331\nWe then see one of the properties of that object is that same abstract value we found before, we then get the equivalent value and replace it:\nhttps://github.com/facebook/prepack/blob/master/src/serializer/ResidualHeapVisitor.js#L398\nThe issue is, just like I experienced with React objects, when we visit an equivalent value in the visitor phase and replace the binding value directly (but inside some effects), as soon we undo the effects/bindings, we completely lose the change we did to make it use the equivalent value.\nWe can hack around this, like we do with React and basically force change the object.properties.set(someKey, newBinding) and that works as it means that this object property binding will never exist in the effects and can't ever be undo/reverted \u2013 but that's hacky and we can do that for React objects as they're immutable. The object in question isn't immutable here and this is far too dangerous IMO even if it's at the visitor/serializer phase.\n. @hermanventer What's your plan of action to fix these other issues? Are there cases where capturePrestate should be used but aren't being properly flagged? Is the long term fix to never apply effects in serialization? I feel making that work is probably going to result in far less bugs if we do that now \u2013 unless you think it's going to take too long to do?. This fails with an invariant on this PR:\n```js\nfunction fn(x, y) {\n  var obj1 = {\n    val : x !== null ? y : undefined,\n  };\n  var obj2 = {\n    val : x !== null ? y : undefined,\n  };\n  return [obj1, obj2];\n}\nglobal.__optimize && __optimize(fn);\n```. @NTillmann I'll try and come up with a regression test tomorrow. I wanted to get this in to unblock @hermanventer's PR.. @gaearon Nice case to fix, will look into that now.. @gaearon I've updated the code with that test and also fixed it.. @gaearon I'm breaking this PR down slightly into smaller commits. As it's grown a bit since!. I'm closing this PR, as per my last message, this PR is to be broken into many smaller PRs (some of which have already merged).. @gaearon I've added some more tests with nested arrays.. @gaearon Just saw this, I must have missed your reply. I've merged master and fixed the issue in question. I added support conditionals, it was missing the logic for them so it wouldn't add keys if a conditional existing in the returned branch. I'm not sure we need to go back to the drawing board on this, as I feel the logic holds but it might seem that it's hacky from your perspective. I'll happily talk you through it if that might help. I'll add some comments to the code now.. @hermanventer This PR is POC for that very reason, it's not something I expect to merge immediately but more to invoke discussion as to how it might help.. Closing this POC, will come up with another similar approach in another follow up PR.. @gaearon Was the plan for a follow up PR along with getting nested pure functions sharing nested objects (somehow, it's needed for the other PR). I know this was a blocking PR on other work.. @hermanventer This is something we'll need to fix, it's because the React compiler is picking up on a side-effect on our internal bundle. @gaearon I believe we need to modify the internal bundle test and remove these lazy bindings.. I'm seeing a new invariant with our internal bundle now:\n\nIt appears because this.alternate is SimpleNormalCompletion, which doesn't have an effects field on the object.\nTo get past this invariant, I changed some code in join.js, specifically:\nFrom:\njs\npnc.alternateEffects.result = pnc.alternate;\nTo:\njs\nif (nc.effects === undefined) {\n  nc.effects = construct_empty_effects(realm, nc);\n} else {\n  pnc.alternateEffects.result = nc;\n}\nAnd, from:\njs\npnc.consequentEffects.result = pnc.consequent;\nTo:\njs\nif (nc.effects === undefined) {\n  nc.effects = construct_empty_effects(realm, nc);\n} else {\n  pnc.consequentEffects.result = nc;\n}\nThen I ran into another invariant https://github.com/facebook/prepack/blob/master/src/methods/join.js#L760-L762\nI commented that invariant out and the bundle compiled and passed the tests.\n. It seems the same invariant in my last comment is something we run into with our internal bundle when we add back in the throw statements. I'll try and come up with a small repro tomorrow.. @hermanventer If you can rebase and fix the conflicts, this might land. If not, I'll see why.. @hermanventer Thanks. I'm now seeing the same invariant I mentioned in a message above:\nhttps://github.com/facebook/prepack/blob/master/src/methods/join.js#L775-L777\n\nb2.previousValue is UndefinedValue. @hermanventer Repo case for the last invariant:\n```js\nfunction fn(text, sortedRanges) {\n  var cursor = 0;\n  var shrinkage = 0;\n  var text = text;\n  var numRanges = sortedRanges.length;\n  for (var i = 0; i < numRanges; i++) {\n    var range = sortedRanges[i];\n    if (range.offset < cursor) {\n      continue;\n    }\nshrinkage += 5;\n\ncursor = range.offset + range.length;\n\n}\n  return shrinkage;\n}\n__optimize(fn);\n``. @LaRuaNa I updated Prepack to use Babel 7, so hopefully this issue is fixed. @LaRuaNa can you please check and let me know? Closing this PR now as we're on Babel 7.. @Guru107 What about with the original logo, but the arrow being black rather than white?. @sebmarkbage I'm not sure I understand the concerns aroundtemporalAliasArgs`. It's designed to provide us a way to traverse previous snapshots that come from Object.assign or React. The ordering doesn't matter either. All these objects should be final and havocing shouldn't be affected.. I noticed this and did this in https://github.com/facebook/prepack/pull/2193. Sorry for not realiziing, there were 250 odd file changes, it was hard to see through the noise.. The changes for this are already on master.. @gaearon It ensures that all the temporal entries are cloned too, unlike before when they might not have been. We need deep cloning for a later PR where we can mutated the cloned tree of config/props and remove any refs/keys/function values safely. The object tree that we cloned should then get DCE as it should no longer be referenced anymore, if it is referenced, then there will likely be a valid use-case for being there (or a missing DCE feature).. I'm closing this as I think a better approach to dealing with props we don't want for first render might be to remove the Object.assign calls instead by using better type data. The issue with cloning is that it creates bloat that in some cases can't be dead coded because of havocing a specific property on an object that we clone means we have to keep around both copies :/.. @NTillmann thanks for reviewing. I was also unsure who to make stateful changes, there seems to be no real ideal place in the codebase to make such optimization\u2019s. On a note to ordering, it shouldn\u2019t matter. The entries will continuing to loop around until true is returned. I tried that as my first experiment.\nWhat if instead of mutating existing entries, I create new ones that are the merge of previous ones? Would that help?. @NTillmann I've come up with a largely different approach (using the same logic to merge though), but this time doing it without mutating in place and instead taking much of the feedback and criticisms you had and applying them to this new approach. Hopefully this is more what you were thinking!. @gaearon Nikolai's PR https://github.com/facebook/prepack/pull/2210 addressed the concern you add (I believe). Once it lands I'll rebase this PR with it and update as necessary :). I'm closing this for for now.\nThe better approach seems to be to get all the cases that currently fail around throwing to work with our internal bundle rather than build around it with pure scope.\nAs per comments, using ThrowCompletion involves another set of logic that wasn't part of this PR's ambitions, it was meant to skip all the joining logic and edge case handling, under the assumption that it wasn't necessary in pure scope. I still think this assumption has some values, but let's move ahead in unison. Adding a flag to ThrowCompletion isn't going to work around the internals here.. Opening this again as I believe I have a way forward.. I've updated the PR and it now uses a flag on ThrowCompletions. The 262 tests fail in the CI, so I need to see why that is. Must be some kind of bad submodule update.. @hermanventer I tried doing something like that originally, but when we join the completions, we end up hitting all the current bugs (for example https://github.com/facebook/prepack/issues/2241) around PossibleNormalCompletions \u2013 which is why we removed throws from the React internal bundle to begin with.\nThe strategy your suggesting sounds good, but it sounds like something we should do once the existing bugs around forking/joining/composing completions are resolved. This PR is more of a short term fix, that hopefully we can remove later for a longer term solution.. @hermanventer If you look at the issue referenced in my last message, I created that repro yesterday. If we can fix that, that might be the last case blocking the correctness around this. Either way, I'll take another stab at doing this using Join.extractAndJoinCompletionsOfType, but I feel that bug I just mentioned will need to be fixed first, as it was why I went down this route to begin with.. @hermanventer I was also somewhat confused how to properly use replacePossiblyNormalCompletionWithForkedAbruptCompletion and extractAndJoinCompletionsOfType. I could not get them working as expected without some test failing somewhere. I'd appreciate a chat over VC/workchat when you have time to explain how I might use the different methods in Join/realm to do what we mentioned above.. Making the PR WIP, will get around to finishing it in the future (instead of closing the PR).. This is out of date. The idea might still stand but will require another visit at another time.. Another test case:\n```js\nfunction fn2(sholdError) {\n  if (sholdError) {\n    throw new Error(\"Error\");\n  }\n  return {\n    thisValueShouldExist: true,\n  };\n}\nfunction fn(sholdError) {\n  var a = Object.assign({}, fn2(sholdError))\n  return a.thisValueShouldExist;\n}\n__optimize(fn);\n```. @calebmer Make sure you rebase master, seems Prettier is failing because of something that was fixed on master already.. Did you have a response for failure 1? Maybe I missed it somewhere/somehow?. @sebmarkbage I put a version above that is what we output now.. I'm not sure why the React tests are failing on CI but not locally, very strange.. This new test case I added to the previous doesn't seem to be fixed https://github.com/facebook/prepack/issues/2241#issuecomment-405084791:\n```js\nfunction fn2(sholdError) {\n  if (sholdError) {\n    throw new Error(\"Error\");\n  }\n  return {\n    thisValueShouldExist: true,\n  };\n}\nfunction fn(sholdError) {\n  var a = Object.assign({}, fn2(sholdError))\n  return a.thisValueShouldExist;\n}\n__optimize(fn);\n```. Here's a test case that does fail:\n```js\nfunction fn2(sholdError) {\n  if (sholdError) {\n    throw new Error(\"Error\");\n  }\n  return {\n    thisValueShouldExist: true,\n  };\n}\nfunction fn(sholdError) {\n  var a = Object.assign({}, fn2(sholdError))\n  return a.thisValueShouldExist;\n}\nthis.__optimize && __optimize(fn);\ninspect = function() {\n  return fn(false);\n}\n```. @NTillmann It's a bug fix, the test case added fails without this fix.. @NTillmann I've cleaned up the test, it was like that from another case I was building and just extracted it directly here. What the Object.assign merging does, is try is merge the sources. The issue is when merging the sources, we encounter the same source. We need to bail out because the ordering matters.\nSo take:\njs\nvar a = Object.assign({}, x, { a: 1 });\nvar b = Object.assign({}, x, { b: 1 });\nvar c = Object.assign({}, a, b);\nx has { a: 0 }, so c should actually pick up { a: 0, b: 1 }. When we merged before this fix, we merged to be:\nvar c = Object.assign({}, x, { a: 1 }, { b: 1 })\nThis is not correct though, we should have x between { a: 1 } and { b: 1 } as x has { a: 0 }. With this PR we get:\njs\nvar a = Object.assign({}, x, { b: 1 });\nvar c = Object.assign({}, x, { a: 1 }, a, { b: 1 });. @NTillmann As per our conversation, I've correctly fixed this issue as well as the other issue you came up with. We use a different, far more sensical strategy now that involves putting things into \"suffixes\" and \"prefixes\" around the \"to\" we're attempting to merge.. I'm merging this now, seems super useful for follow up PRs.. So how can we not get this invariant? I'm not sure if you're proposing a solution or something else.. I updated the PR with master and added the check in a bunch of other places. It seems we are hitting more cases now, which is good in some respects. Herman's join PR seems to fix all the failing test cases though.. Fixed conflicts from master. Let's try and get this one in if possible :). @gaearon Yep, the tests pass now.. I looked into this too and feel the right strategy is to probably revert https://github.com/facebook/prepack/pull/2274. What do you think @hermanventer?. @sebmarkbage It's a first pass, the idea is to remove them all in follow ups. To do all that in one PR would be pretty insane, especially with merge conflicts constantly coming in. I believe kind will still be needed though, we had that before too except it was from wrapping functions within functions, which is why we need another approach. I added TODO comments to the PR.. I think this is to be somewhat expected, minus the invariant you're seeing. We need to fix that.\nYou're hitting to many AbstractValue.throwIfNotConcrete errors because this transform is making abstract values, but abstract values are unsafe for many of the operations so it ends up in FatalErrors. The reason we can compile so much as of late is because we apply a \"pure scope\" to optimized functions and React components. Doing so gets us around the majority of AbstractValue.throwIfNotConcrete errors from occurring. You can apply the pure scope manually by wrapping the tests in __evaluatePureFunction(funcContainingTestCode).\nI'd be interested to also know what test failures from the 104 tests are because of bad output  \u2013 which is the worst possible case IMO. Are those tests failing currently on master without the transform too? If they are not, we should focus our efforts on those first, as those will be blockers soon enough.. Please can you pull out your String(x) fix into a separate PR if possible? I'll take another review of this PR again on Monday morning :). @sebmarkbage For LLVM output, can we can just use a goto instead of using these normalized functions everywhere? :P. @calebmer I'm not sure on any literature on the topic - it's actually something I came up with recently in discussion with @sebmarkbage (https://github.com/facebook/prepack/issues/2253). The heuristics when and when not to inline something form a basis of checking the total size of a generator (a bit like V8 and other JS engines check the size of a given function, before determining if they should store the function in the inline cache).\nI searched around for previous research on this topic ages ago (way back when I started on the project) but found nothing of real importance online. It's not an easy thing to search for, as the term \"compiler\" is so overloaded, you end up getting swamped in dead ends.. @calebmer I'd imagine both to be somewhat involved. I've not done any testing on the current hashing idea, it would need some more development and designing around our bundle but totally do-able. It sounds like you're really interested in this, so I'm happy to hack on it with you more if you'd like to explore it more on our internal bundle.. @cblappert The PR can pick up patterns. I didn't get a chance to look into why it wasn't right now, but I will do on Monday. The general idea is that this might be a better general purpose solution rather than leaving functions as abstract, as that means we have to havoc/leave JS in place, which might not be ideal for alternative outputs.. @NTillmann I agree in regards to correctness and complicating matters. I can park this PR and idea until later if that makes more sense. I don't want to close this PR though, as the ideas shouldn't get lost forever.. I'm closing this for now as I no longer believe it's the best approach.. @calebmer That was one of the ideas I had too, but it was more involved and I wanted to try and re-use existing logic where possible for now to see if type data gave much value. We can always re-factor it to that approach later though.. @hotsnr Unfortunately, most things in our case come from GraphQL and are also optional too.. @calebmer I don\u2019t think we ever want to do that. We need to keep the model in Prepack because of all the complex things we need to do. For example we snapshot props and ReactElement objects do they are temporal and have bunch of equivalence optimization\u2019s etc, not to mention cloning of them when we evaluate them. We should speak about it on VC again some time :). This PR is still good to merge, we just can't apply the type data changes to our internal bundle that add types for arrays, because we need to have materialization as a feature added (without havocing/leaking anything in the process). We'll need to look into materialization without havocing, which I believe @sb98052 has been looking at lately. Ideally, we just want to do Materialize.value(realm, someValue) and it should traverse through the value and its bindings like havocing does, but instead of havocing the values, it should materialize them and flag them so it doesn't need to happen again.. @hermanventer I can revert the changes for the values to temporals and keep them as templates and try and come up with a repro case that I was seeing on our internal bundle?. Test case that fails with non-temporal toString and split:\nAlso related to our chat on workplace:\n@NTillmann @hermanventer @sebmarkbage \nIt breaks with inlineExpressions turned, because it takes the abstract template values out of the conditionals.\nInput:\n```js\nfunction fn(cond, cond2, a, b, c) {\n  var x = global.__abstract ? __abstract(\"number\", \"a\") : a;\n  var y;\n  var z;\n  var obj = Object.assign({}, b, {x})\nif (cond) {\n    y = obj.x.toString() + c;\n    z = y.split(\"\");\n  } else {\n    if (cond2) {\n      return null;\n    }\n    y = obj.x.toString() + \" \" + c;\n    z = y.split(\"\");\n  }\n  return z;\n}\ninspect = function() {\n  return fn(false, false, 4, {}, 5);\n};\nthis.__optimize && __optimize(fn);\n``. A better case that fails even withinlineExpressions` enabled, this appears to be a clear bug.\nInput:\n```js\nfunction fn2(cond, items) {\n  if (cond) {\n    return items.length;\n  }\n  return 0;\n}\nfunction fn(cond, x, y) {\n  var items = Array.from(x);\n  var items2 = Array.from(y);\nvar len = fn2(cond, items);\n  var len2 = fn2(cond, items2);\nif (len > 0) {\n    return len.toString();\n  }\n  if (len2 > 0) {\n    return len.toString();\n  }\n  return \"Should hit this!\";\n}\nthis.__optimize && __optimize(fn);\ninspect = function() {\n  return fn(false, [], []);\n}\n```\nOutput:\n```js\n  var 4 = function (cond, x, y) {\n    var _O = $6;\nvar _$0 = _O(x);\n\nvar _$1 = _O(y);\n\nif (cond) {\n  var _$2 = _$0.length;\n}\n\nif (cond) {\n  var _$3 = _$1.length;\n}\n\nvar _7 = _$2.toString();  //  <---$2 might not be declared....\n\nreturn (cond ? _$2 > 0 : false) ? _7 : (cond ? _$3 > 0 : false) ? _7 : \"Should hit this!\";\n\n};\n```. I can\u2019t land this as it fails our internal bundle test with the same problems outlined in work chat.. Some progress, as per our discussion in https://github.com/facebook/prepack/issues/2327. I've made the following changes:\n\nMade String.prototype.toString output ('' + A) as the template, rather than (A).toString() like before. Doing so makes all the tests around these issues pass and actually has the nice effect of being slightly more performant than using toString() in V8 and JSC.\nFound a bug in String.prototype.split where the resultType was incorrectly set to StringValue when it should have been ArrayValue.\nUpdated AbstractValue.createFromTemplate to apply the same hashing logic when the resultType is that of an ObjectValue as createFromType already did.\nFixed a bug where createFromType only checked if the resultType was === to ObjectValue, but this misses cases where the resultType might be === to ArrayValue.\n\nWith these changes our internal bundle now passes as do all internal tests.. This has been on my radar for a while now as it does come up in our internal bundle too. I can take a look today.. @calebmer Hydration isn't affected by keys. Furthermore, we never render any key information or metadata during server-side render, so the hydration process always mounts components when traversing the SSR tree.. This looks good, I was wondering if we could also have an API on the materialize singleton to recursively step through and mark many objects/bindings for materialization? Materialize.value(someFunction) for example, which would use a similar (if not the same) implementation as havocing does for traversing through bindings to materialize many things. That's really what I want, especially for the case below:\njs\nfunction mapFunc(item) {\n  return this.formatTitle(item.title);\n}\nreturn abstractItemsArray.map(\n  mapFunc.bind(this)  //  <-- `this` would be materialized, which is the issue I'm facing on our internal bundle\n);. Yes, this is primarily for abstract array methods, such as map, where we don\u2019t want to havoc values because we need their value when optimizing the nested optimized function. So we need to materialize the bindings of the array method call, mainly for cases where the method has been bound to this. Leaking is fine, I was just after something in the initial stage to unblock progress on the project.. Actually, I don't think we need this right now. It might actually complicate things more with exposing args this way and changing type of an abstract value might bring new bugs.. @NTillmann thanks for taking the time to explain.\nSo I guess all these other cases are likely to fail to?\n| \"(A).length\"\n  | \"(A).toString()\"\n  | \"(A).slice(B,C)\"\n  | \"(A).split(B,C)\"\n  | \"global.JSON.stringify(A)\"\n  | \"global.JSON.parse(A)\"\n  | \"JSON.stringify(...)\"\n  | \"JSON.parse(...)\"\nGiven that the values in their args might be undefined/null, it seems they can also throw at runtime too. Note that none of these template get used in optimized functions or React components, which is why I'm concerned as they can't get used as abstract function calls will always result in temporals in pure scope, so we've likely had correctness issues for some time now but been unaware because it was being covered up by pure scope.. I dug into this more today too. We use a temporal abstract values for toString, split, toLocaleString, slice, length and a bunch of others. They all have side-effects and not safe to be a-temporal without changing how the hashing works (like Herman did for ToObject templates), I managed to make repros for most of them locally. For example, here is split: https://prepack.io/repl.html#G4QwTgBCELwQLgCwJYGcB0B9TIBGr4wQBjeCAfgmzwKNIAoAiW5AOwHNGAaCR+gcgBmAe2H8AlI3EQAXLxHDGAbgBQoSLlhR0qAA4AbZPHrjV6iMS0gdBoydUrkgiPU0x3F6QG8VEC8NZUYX0AU3R9YXYmAGVEYQBXfQATCFYQ4BDIRBBdXRDWKRUAXyA\nIn my opinion, they should be temporal abstract values or have unique hashes (which means that CSE won't work anyway), with the exception of maybe Number.prototype.toString, String.prototype.toString and Boolean.prototype.toString - for these we can use the shorthand + \"\" syntax rather than the prototype method call, which makes it side-effect free. We just need to be careful with integral values because + might bring about unwarranted bugs here.\nFurthmore, on our internal bundle the source of the issues, and the reason why https://github.com/facebook/prepack/pull/2321 can't land in its current state is not because of CSE only. It's because the logic in the simplication phase, where we check if two abstract values are equal via equals and then simplify conditions. This makes sense, but clearly if you are doing this to two side-effectful operations like split, then this is going to break as per my example in this reply.. @hermanventer I was planning on creating a React regression test that was a repro of the same internal bug rather than just a generic serializer test.. @hermanventer Oh, I meant that I was going to create a serializer test too, just I wanted to both that and a nice React test :) maybe I'll create a serializer test just to get this in a follow up with the React repro next week.. I'll fix up this PR and get it landed, as I believe it's blocking other issues and repros I'm working on right now.. Like the other issue, if I use explicit nested optimized functions:\n```js\nfunction fn(x, y, obj, cond) {\n  var arr = x;\n  var arr2 = y;\nvar a = obj.a;\nvar mapper1 = function(item) {\n    if (cond) {\n      return a;\n    }\n  };\n  __optimize(mapper1);\n  var res = arr.map(mapper1);\nvar mapper2 = function(item) {\n    if (cond) {\n      return a;\n    }\n  };\n  __optimize(mapper2);\n  var res2 = arr2.map(mapper2);\nreturn [res, res2];\n}\n__optimize(fn);\n```\nUpdate: this now works with the latest changes on master. Note that the logic in this test case is different from that of above, as the map function and the array are both havoced.. Without using the implicit nested optimized function logic:\n```js\nfunction fn(x, obj, cond, abstractFunc) {\n  var arr = x;\nvar a = {\n    x: 5,\n  };\nif (cond) {\n    abstractFunc(function(y) {\n      a = 1;\n    });\nvar z = a.x;\n\nvar mapper = function(item) {\n  return z;\n};\n__optimize(mapper);\nvar res = arr.map(mapper);\n\n}\nreturn res;\n}\n__optimize(fn);\n```\nUpdate: The error has been fixed on master.. @calebmer They might be left in residual functions that are on the global (i.e. nested optimized functions). They just make linter noise, and we should exclude them.. @calebmer  It would be good if we could fix this one together. I believe it's very closely related to a pushing false invariant blocking our internal bundle from running nested optimized functions.. @hermanventer It would be awesome if you could take some time to look into this at some point. I'm not 100% sure what is going on when I've debugged the test case above.. This is absolutely epic. Thank you for working on this, this is exactly what we need and it's far faster than finding issues without working backwards from bugs to make repros (although that is still valuable). Can we also have a tool to extract errors from sqlite?\nI'll review this PR properly tomorrow as it's a very large PR, but still, awesome work.. In regards to your question, yes, making things simple assumes they are partial too in this given case:\nhttps://github.com/facebook/prepack/blob/master/src/values/AbstractObjectValue.js#L164\nIn my opinion though, I think we should remove the whole makeSimple system from Prepack. It made sense to have it when we didn't have the pure scope system, but with the pure scope system, I think the simple system gets in the way and is somewhat confusing. It's actually somewhat bad naming too, as it's most definitely not \"simple\" to understand. \"Simple\" should never be used in any computer-science terminology in my opinion, but that's a different topic.\nI also looked into the output of your above case. I wasn't sure if you were trying to outline a bug too. The output of this with current master is:\n```js\n(function () {\n  var _$4 = this;\nvar $5 = $4.Object;\n  var $6 = $5.assign;\n  var _5 = {};\nvar $0 = $6(_5, y);\n$4.has = true;\n  var $2 = 5.anything;\n  $4.desc = {\n    value: _$2,\n    writable: true,\n    enumerable: true,\n    configurable: true\n  };\n}).call(this);\n```\nIt's interesting that has is true here and there is even a descriptor.\nAnother interesting Object.assign pattern that doesn't optimize well with simple/partial is:\n```js\nfunction fn(x) {\n  var obj1 = Object.assign({}, x);\n  delete obj1.foo;\n  var obj2 = Object.assign({}, obj1, { a: 0 });\n  return [obj2.foo, obj2.a];\n}\n__optimize(fn);\n``. This is becausexyandzare all temporal entries in the case above, not a-temporal abstract values that go through the CSE system.. @sebmarkbage Nope, I tried that, we reference it viaAbstractObjectValue.$OwnPropertyKeysand changing all those call-sites can be done at another time (I also thought they were only done via ObjectValue only).. @sebmarkbage It's this that's causing the issues https://github.com/facebook/prepack/pull/2381/commits/30a0493fc587115669718047cdde44219397cdfc#diff-5cb5f0c9909e8738d567acfaff9bb980R142. It passes the flag to AbstractObjectValue, that passes to ObjectValue. Unless I'm misunderstanding you.. Looks like an ES6 feature bug. Do we have a tag for ES6 features?. @cblappert I'm not sure that overloading the// expectedcomment to have no error really makes a lot of sense to those unfamiliar with that particular comment.. I thought this was handled withrealm.suppressDiagnostics = true;`?. This currently fails the internal React bundle. I'll look into it more today and try and come up with a repro.. Here's a repo for the failing issue:\n```js\nfunction joinClasses(className) {\n  var newClassName = className || \"\";\n  for (\n    var _len = arguments.length,\n      classes = Array(_len > 1 ? _len - 1 : 0),\n      _key = 1;\n    _key < _len;\n    _key++\n  ) {\n    classes[_key - 1] = arguments[_key];\n  }\n  var argLength = classes.length;\nfor (var index = 0; index < argLength; index++) {\n    var nextClass = classes[index];\n    if (nextClass != null && nextClass !== \"\") {\n      newClassName =\n        (newClassName ? newClassName + \" \" : \"\") + nextClass;\n    }\n  }\n  return newClassName;\n}\nfunction fn(_ref) {\n  var className = _ref.className;\n  var comment = _ref.comment;\n  var author = comment.author;\n  var authorID = author && author.id;\n  var authorName = author && author.name;\n  if (!author || !authorID || authorName == null) {\n    return null;\n  }\n  if (author.url) {\n    return {\n      props: {\n        className: joinClasses(\n          comment.is_author_weak_reference\n            ? \"somestring\"\n            : \"\",\n          className\n        ),\n    uid: authorID\n  },\n  children: authorName\n}\n\n} else {\n    return {\n      props: { className: className },\n      children: authorName\n    };\n  }\n}\nthis.__optimize && __optimize(fn);\n```\nI found this because the createdObjects when evaluating the effects of this internal component was missing all the objects from before calling evaluateForEffects. The above repos nicely and has many missing variables.. A reduced version also breaks:\n```js\nfunction fn(_ref) {\n  var className = _ref.className;\n  var comment = _ref.comment;\n  var author = comment.author;\n  var authorID = author && author.id;\n  var authorName = author && author.name;\n  if (!author || !authorID || authorName == null) {\n    return null;\n  }\n  if (author.url) {\n    return {\n      props: {\n        className: null,\n    uid: authorID\n  },\n  children: authorName\n}\n\n} else {\n    return {\n      props: { className: className },\n      children: authorName\n    };\n  }\n}\nthis.__optimize && __optimize(fn);\n```\nThere are less errors in the output, but still many errors.. @hermanventer it seems you will also need to make some changes on your imported diff for fbsource, as it tries to run test-residual which no longer exists.. @rahilvora Thanks for looking into this. You have a Flow error in your PR, if you can check? Seems that you are using CompilerDiagnostic without the right number of arguments.. @NTillmann That test was already added and fixed as part of another PR.. @sebmarkbage Please can you add the test cases to this PR when you have time?. Is this stale? @yinghuitan did you have a chance to look into this?. I think we should leave the tests in, just because the coverage might not change, the logic in the code might change in the future (very likely with nested optimized functions) and then the coverage might very well change too.. Is this PR still active? Seems you addressed most of these issues in other PRs?. @AleCaste You can attempt to fix this by adding abstract support for documentElement on document. See https://github.com/facebook/prepack/blob/master/src/intrinsics/dom/document.js.. We could use an abstract value with a kind that is used to distinguish them. There'd be quite a few parts of the codebase that would need to be altered to understand this new kind though.. Why do we want to reject the this binding? It's used all over our internal bundle for array methods :/. This looks good. I noticed quite a lot of tests were failing though and after looking into them, it you are materializing intrinsic objects \u2013 in this case the React global is one of those that is failing because we are. We shouldn't materialize intrinsic objects at all as far as I'm aware.\nAnother area I noticed was getLeakedFunctionInfo needs to support BoundFunctionValues:\nhttps://github.com/facebook/prepack/blob/master/src/utils/leak.js#L93. Does the internal bundle still pass? You will need to import if you haven\u2019t got it setup locally.. @sebmarkbage As I suspected. It looks like things accidentally work because the most common case is looking for the property of value. I'll fix in a another PR.. Fixed this in https://github.com/facebook/prepack/pull/2462 and added a test :). Looking into the tests more, I thought that the ordering here mattered but it doesn't seem to matter as this is the order of how the React Reconciler takes conditions \u2013 which seems to have flipper from before so I think this is actually fine. Unfortunately, the same pushing false invariant still occurs in our internal React bundle and also from https://github.com/facebook/prepack/issues/2361 (I wasn't sure if this PR was to also fix or somewhat address those issues too).\nIt appears that test/serializer/optimized-functions/LoopBailout18.js is causing the CI to fail because it takes longer than 10m and thus CircleCI fails the tests.\nhttps://support.circleci.com/hc/en-us/articles/360007188574-Build-has-hit-timeout-limit. @hermanventer Sorry, this only seems to occur with abstractValueImpliesMax set to 1000, as per debug-fb-www's settings.. This PR is currently failing the internal React bundle test with an invariant in _getTarget in the serializer. I'll dig into it today and see if I can see if there's anything obvious.. Maybe we should introduce abstractValueImpliesMax in the test-runner as a separate run like we do for other config settings too?. I'm going to close this PR. Not having a kLimit on the LoopBailout18 test causes it to take forever. I looked at adding a manual override to the test, but it feels like a code smell and we should definitely aim to reduce random test config all over the place rather than add more. Maybe I'll revisit this again in the future.. I\u2019ll look into this and get back to you both :). I'm landing this as this actually fixes another issue that I was tracking for our internal bundle.. This issue is fixed with https://github.com/facebook/prepack/pull/2494, but as a side-effect we now have a case that the React reconciler no longer works with:\n```js\nvar React = require(\"react\");\nfunction Child() {\n  return This should be inlined;\n}\nfunction App(props) {\n  var a = props.x ? null : function () {};\n  return a && ;\n}\nApp.getTrials = function(renderer, Root) {\n  renderer.update();\n  return [[\"simple render\", renderer.toJSON()]];\n};\nif (this.__optimizeReactComponentTree) {\n  __optimizeReactComponentTree(App);\n}\nmodule.exports = App;\n. Fixed in #2494. Shouldn't they return `ObjectValue | AbstractObjectValue` in this case? It doesn't make sense why they might return anything other than that.. @calebmer I pushed some changes that I proposed above and also fixed up the React tests. I added an invariant that we run into on the internal React bundle that we'll need to fix in a follow up PR too. If you could review and let me know if you like the changes?. @hermanventer Should be good to review now, everything looks to pass locally on all our internal bundles too with some great results.. This PR is no longer a WIP. :). @hermanventer Thanks for the comment. I'll address in a follow up next week. I did however notice that the check on the `consequentVal` and `alternateVal` resulted in less output code without less inline nodes. I'll change to separate if statements though, that's a good call :). @sebmarkbage This sucks a bit.js\nfunction fn(x) {\n  var y = undefined;\n  if (y instanceof x) {\n    return y.somethingThatDoesNotExist;\n  }\n}\n```\nPrepack will spit out this:\n```js\n  var 2 = function (x) {\n    var $0 = void 0 instanceof x;\nvar _4 = (__constructor.prototype = _$3, new __constructor());\n\n$$0.value = \"null or undefined\", _$5(_4, \"message\", $$0);\n$$0.value = \"TypeError: null or undefined\\n    at fn (/Users/ADM/Projects/prepack/fb-www/input.js:6:12)\", _$5(_4, \"stack\", $$0);\nif (_$0) throw _4;else {}\nreturn void 0;\n\n};\n```\nWhich is somewhat problematic in the cases of code bloat. Interestingly, Closure Compiler also optimizes the same thing above away even though it supports ES2015.. @NTillmann Nope, as this creates a temporal with  createOperationDescriptor(\"BINARY_EXPRESSION\", { binaryOperator: op }). @sebmarkbage I've refined the code to add the simple check.. I'm not sure the best plan of action here. It seems our internal Babel transform for this is not spec compliant yet the one we use on Github is? If you look at the compiled output in lib/values/ObjectValue.js it looks nothing like what you pasted above.\nAnyway, here's a PR that removes in usage and changes them to explicit undefined checks like you did in your other PR: https://github.com/facebook/prepack/pull/2512. I believe I found the source of the issue. It was to do with the for (let field in Desc) { in properties.js where we check if the descriptors are identical. Beforehand, we only iterated through properties on the descriptor that existed. Now that they all exist, but are set to undefined this matching logic would fail in many cases and emit undefined properties unnecessarily.. I'll take another look at this PR next week. @sebmarkbage would be good if you could see what I'm doing wrong here, it seems defining these properties on the ObjectValue instance causes the 262 tests to fail, so it might be that I've missed a codesite where in is being used on ObjectValue still. I'm going to focus on getting your other PR landed first.. There seems to be an issue with our internal bundle when combined with this PR. This invariant is occurring because it's trying to get the \"render\" method from a React component class that has leaked during the class constructor being called/getDerivedStateFromProps. This should never happen. Out of curiosity, I forced the instance to not leak, thus removing that invariant from possibly occurring and we end up with a broken bundle where only 150 component nodes inline.. @NTillmann Why not? It should work fine, even if you have less than 32gb of RAM \u2013 did for me on my MacBook which only has 16gb.. Agreed, this is a temporary fix.. Looking good so far! The internal React www bundle passes and we actually inline 25% more nodes, which is very impressive (at the cost of 25% more code). However, the internal React Native bundle still seems to hang with this PR.\nAs you probably already see, the serializer tests seem to time out on CI with conditions2.js test. Locally, LoopBailout18.js also takes forever, except Node runs out of system memory before the test completes.. Please can you add some background as to what assigns parentAdditionalFunction and why things work now without it? It would be good for someone on the team other than I to take a stab at this \u2013 purely to get some understand and grasps of the React part of the codebase. However, I'm happy to take it on if not. :). It looks like it's an issue with residual function holding bindings/references to other functions. Here's a minimal repro @NTillmann @cblappert if you have any ideas:\n```js\n(function() {\nfunction createClass(ctor, superClass) {\n    if (superClass) {\n      ctor.prototype = Object.create(superClass.prototype);\n    }\n    ctor.prototype.constructor = ctor;\n  }\nfunction mixin(ctor, methods) {\n    var keyCopier = function(key) {\n      ctor.prototype[key] = methods[key];\n    };\n    Object.keys(methods).forEach(keyCopier);\n    Object.getOwnPropertySymbols && Object.getOwnPropertySymbols(methods).forEach(keyCopier);\n    return ctor;\n  }\nfunction Iterable(value) {}\n  function Iterator(next) {}\ncreateClass(Seq, Iterable);\n  function Seq(value) {}\ncreateClass(IndexedSeq, Seq);\n  function IndexedSeq(value) {}\ncreateClass(SetSeq, Seq);\n  function SetSeq(value) {\n    indexedSeqFromValue;\n  }\nSetSeq.prototype.toSetSeq = function() {\n    return this;\n  };\nSeq.isSeq = isSeq;\n  Seq.Set = SetSeq;\n  Seq.Indexed = IndexedSeq;\ncreateClass(ArraySeq, IndexedSeq);\n  function ArraySeq(array) {}\ncreateClass(IterableSeq, IndexedSeq);\n  function IterableSeq(iterable) {}\ncreateClass(IteratorSeq, IndexedSeq);\n  function IteratorSeq(iterator) {}\ncreateClass(ToIndexedSequence, IndexedSeq);\n  function ToIndexedSequence(iter) {}\nIterable.Iterator = Iterator;\nmixin(Iterable, {\n    foo: function() {\n      ToIndexedSequence;\n    },\n  });\nfunction isSeq(maybeSeq) {}\nfunction indexedSeqFromValue(value) {\n    maybeIndexedSeqFromValue;\n  }\nfunction seqFromValue(value) {\n    ObjectSeq;\n  }\nfunction maybeIndexedSeqFromValue(value) {\n    ArraySeq;\n    IteratorSeq;\n    IterableSeq;\n  }\nglobal.foo = Iterable;\n})();\n``. @NTillmann Oh, I think I misunderstood you then. I thought you said that__emptyshould never be visible in the output code. In terms of my original problem, the React reconciler is passed a conditional that has one side that is anEmptyValue`. Furthermore, the React reconciler in this particular use-case is trying to serialize this conditional, which is an element in array as JSX children. When we do this, it gets output like this:\njs\nvar conditionalElement = x ? 1 : __empty;\nvar reactElement = <div>{conditionalElement}{conditionalElement}{conditionalElement}</div>\nThis is not right though, as the __empty value is now reachable. We can't use Prepack's way of generating arrays because ReactElement children must be explicit, passing in a reference to an array is a correctness issue. Technically, you can get around this by using createElement rather than JSX, where this would work and it would use the existing logic that doesn't expose __empty:\njs\nvar arr = [1];\nif (x) arr[1] = 1;\nvar reactElement = React.createElement(\"div\", null, ...arr);\nUnfortunately, you cannot spread JSX children (it's explicitly forbidden in the spec). So we have to inline each element of the array into the ReactElement, which results in exposing __empty again. I actually have a way of getting around this in my PR (if you look at the latest comments/commits) that this issue is linked to, but this issue is also coverage for why we generate so much bad code anyway (which is never going to give performance wins).. Will close then for your PR :). @sb98052 This additional information is used to known what abstract values are created in certain effects. For example, my other PR aims to wrap a function call in evaluateForEffects. We then take the Value that was returned from the function call's effects and apply some heuristics to determine if we should \"inline\" the function call and its effects, or instead leave the function call in code. When trying to determine if something should optionally be inlined, we have an odd case with abstract values where we do not know where if the abstract was created inside the function call, or if the abstract was created previously.\n```js\nvar someAbstractValueCreatedOutside = __abstract();\nfunction foo(x, y) {\n  return [x + y, someAbstractValueCreatedOutside];\n}\nvar returnValueFromFunctionCall = foo(10, 2);\n```\nIf you look at this example, we can avoid the function call altogether and avoid potential code bloat because we know that the function returns something that we can clone and re-model without the effects of the function (as long as we have effects.createdAbstracts to determine that someAbstractValueCreatedOutside was indeed not created in the function call.. @sb98052 The logic I have traverses through all args on abstract values, only if the abstract value exists in the effects. If all args of an abstract value are also all created in the function then we know it's not safe to re-model. If an abstract value was created in a function, but it's effects were not, we clone the abstract value outside of the function's effects and re-model it's args to be that of what were outside.. @sb98052 Yes, I mean \"any\" sorry.. @sb98052 How can your logic know if an abstract value is a temporal created inside a function's effects vs a temporal created outside? I also use the effects.createdAbstracts to fast-path optimizations, so if I know something was created outside then I don't traverse through it's args and I don't need to clone/remodel it either.. @sb98052 That's a point, maybe createdAbstracts could be createdDerivedAbstracts instead. Food for thought.. Merging this for now, just to unblock my PR. Will revise in a later PR.. Closing this as I feel we should rethink evaluatePure as a separate workflow.. @cblappert Addressed feedback and refined logic + added more tests. It doesn't unfortunately fix https://github.com/facebook/prepack/issues/2599 so I'll keep looking into that one.. This PR has been consumed by https://github.com/facebook/prepack/pull/2600.. Another failing case:\n```js\nfunction fn(items, abstractFunc) {\n  var a = 10;\n  var b = function() {\n    return a;\n  };\n  var arr = Array.from(items);\nfunction fn2() {\n    abstractFunc(function() {\n      return b;\n    });\n  }\nvar mapped = arr.map(function() {\n    return fn2();\n  });\nb = function() {\n    return 20;\n  };\nreturn [b, mapped];\n}\ninspect = function() {\n  var value;\n  function mutateBinding(caller) {\n    value = caller()();\n  }\n  fn([1,2,3], mutateBinding);\n  return value;\n};\nglobal.__optimize && __optimize(fn);\n```. The PR currently fails the Flow depcheck:\nBiggest cycle: 57 (out of 5 cycles reported by Flow)\nError: You increased cycle length from the previous high of 56\nI'm not entirely sure what is doing it, other than maybe the new module I added for outlining.. @sb98052 Sorry I missed that!. I've updated it to an invariant :). I opted for _getSerializedPropertyValue(properties: Map<string, any>, key: string) { instead, is that okay for this?. All the evaluation code was pretty much copy and pasted from the React compiler \u2013 I will go through and add more Flow annotations. Thanks :). Users can still pass in undefined as a value for key or ref.. For desc.value?. I believe it should be okay. @sebmarkbage can confirm.. Nice spot, surprised that Flow/ESLint can't detect these \u2013 it was a typo.. I agree, I'll take this out for now and put it into another PR at a later point as per what you said.. This object is needed, componentsByName isn't needed though.. Made this change, thanks for the help.. All the identifiers Prepack uses start with _ anyway, so it's not even an issue with uppercase characters here.. Actually I checked, <foo.bar> is a valid component still. I don't think the uppercase heuristic is correct unless for JSXMemberExpressions then?. What about <this.props.something />. I guess this should have never been allowed from day 1, but I don't think we can change this now, it's a bit late? I'll instead opt to look for a root flag.. If we visit it, then we need to handle it in serialisation stage by emitting it or adding it to the values (which I previously did, but removed due to prior feedback).. Same as above. Same as above. Thanks, I'll work on a fix for this once I wake up. :). Thanks!. I was hesitant to remove the tests from the code \u2013 that did cross my mind though. I still feel they're relevant here though, I'm not sure how a basic test using the current infrastructure would warrant any real gain.. additionalGlobals is a public API option that I added in a previous PR for this exact purpose.. Agreed, naming things is hard. Will change the name, but leave it in the folder as it's related to Flow.. abstractObjectFactories.js?. So move test-react.js out of this PR? Sorry, I'm confused :/. I thought we did want to expose these objects as additionalGlobals was meant as an escape hatch. I guess we could add an option reactMocksEnabled and then move this logic into core global instrincts?. This is all taken from Babel. I thought this wasn't actual JS error that is occurring, rather it's console.error being fired?. We can't use it from upstream but I'll make make those changes in another PR.. Yep, this should be fine.. Added Value to the union.. We need to resume the reconciliation process here though. Re-throwing here will abort the process entirely.. @sebmarkbage this was based on your original logic, do you see another route? If there's an internal error, should we bail out of the tree entirely \u2013 given that it's very likely at the moment?. This is fine, an empty string will be appended to the new string which is never empty.. I actually saw that same function and replicated here. This is doing the same thing as under the hood as the original logic?. I'll make as a TODO right now, as I don't want to block this landing because of a DEV mode constraint, we can revisit later. Is that okay with you?. There are others from my testing, ||, && etc. I'd rather add a TODO here :). It was taken from the prototype. You're right, it's for class components. I'd rather remove for now.. I'll add a TODO. This was moved from reconciliation.. This was moved from reconciliation.. It seems to work in all the tests.. Do you mean the JSX Babel nodes created by the serializer? I'm not sure how we can best add source to them.. I didn't actually explicitly write this, I think it was VSCode auto importing :/. Ah yes, I forgot about computed class method names. What would be a better way of dealing with them?. Actually, I think we can support constructors too. This PR is still a WIP, so I'll add it to my TODO list.. It's better to use a Map over an Object.. typo, you have \"key\" rather than key.. It's not needed right now as current is never accessed at this point. I'm creating the object to be used later.. Added. :). Removed.. This is only meant to be a mock/stub. The real logic get's handled by the Prepack React reconciliation code. The constructor of any of the components never gets called in fact.. Agreed. Done :). I tried that, it was too messy to read the AST and infer this.. Static methods are supported fine \u2013 they were tested. They are actually properties of the constructor function.. I'm not sure I follow here \u2013 how is this related to computed method names? I've just added support for $HomeObject being set on properties on the prototype, so your example should work now.. @sebmarkbage Sure. Although I'm not sure what is special about the super call. Prepack doesn't touch it as we don't ever evaluate it.. I'll add tests for these cases and try and fix them accordingly.. Both cases are handled as you put above. The computed method gets turned into a string property and the later added bar also gets added. :) There are tests for your first case already, I'll add some for the second case tomorrow.. A function might be declared in the additionalFunction, and be inaccessible in the parent scope.. I tried to, but battled endlessly with Flow issues because the function has a generic used. The generic in this case should be fine as Value though. Unless you can think of a way of making it work? Casting to ObjectValue seems to break the world.. I'll address this and the other concerns you had in a follow up tomorrow along with some tests. Thanks :). I've changed how this works slightly so it's clearer. It now looks for an explicit SimpleClassBailOut error thrown to determine if the class component is indeed simple. If it is not simple, it will always from there on apply the \"complex\" route for that component. The SimpleClassBailOut cannot be thrown from normal bailouts so it's safe.. I switched to a WeakMap because we need to know if the type is \"SIMPLE\" | \"COMPLEX\". Having a set wouldn't give us this data as there are three routes:\n- not yet evaluated to be either simple or complex\n- being simple\n- being complex. Your above example doesn't really matter here. It will be evaluated by the reconciler and inlined before it gets to the hoisting logic. There are already tests that show this. :). @cblappert I'll move the logic out in a separate PR if that's okay?. Got ya.. It handled closures now. So this shouldn't be an issue :). That's strange, I've been using PP0019 for some time now and documented on the wiki page. \nIn regards to your other comments. They only get promoted if the root component in the reconciliation tree bails out; if components further down the tree bail-out, it skips over them and continues (but adds an inline message). I didn't want to overload the details of ExpectedBailOut by having each one give a code, as this shouldn't be the case. Maybe I misunderstand you here, the original code was something suggested by @NTillmann I believe in a previous PR \u2013 sorry if I misunderstand you.. @hermanventer You should see the message in the DiagnosticError, as the errors are all expected ones (other errors get passed through), the message should be clear as to what happened to cause the problem.. add types. make lazy. add to non jsx. This is fixed now.. This is fixed now.. So for your first case: static bar = cycle; is invalid syntax currently, so skipping this.\nSecond case: this seems handled currently. Test for this needs adding.\nThird case: I never got around to this, so this needs to be done and tests need adding.. There should be, this bit was tested quite extensively in manual testing. It lacks some additional automated tests to be added.. Maybe hint was a bad name to use in the comment. It's a boolean flag to let us know that this was a class.. This was done intentionally. Flow just gets confused and outputs about 20 errors if you try and make this something other than any. I spoke to the Flow team and they said that Flow's inference struggles with this sort of dynamic function pattern and its on their roadmap to fix. I'm not sure it's of any value to hack around Flow to make this work right now.\n  . It's due to incompleteness of ES2015 Prepack currently, the wiki explains more on this. Once the edge cases are handled, I'll move this to an invariant (as per the PR that explained this when merged).. Because of val.hasDefaultLength() checks the value against the arguments to validate if it doesn't need to be serialized out.\nhttps://github.com/trueadm/prepack/blob/fixes-class-component-replacement/src/serializer/ResidualHeapInspector.js#L89\nhttps://github.com/trueadm/prepack/blob/fixes-class-component-replacement/src/values/ECMAScriptSourceFunctionValue.js#L40-L52. The new test fails before. The reason is, we change the arguments of the function.. Sorry, I was a n00b and forgot to git add the test that fails. :D Done that now!. It needs to be 2 because I explicitly set the arguments array to be two elements (it's fixed to always be this intentionally):\nhttps://github.com/trueadm/prepack/blob/fixes-class-component-replacement/src/react/utils.js#L224\nIf I do not set it, and the arguments length is different, it means the serialization output of this functional class component will include 3-4 extra lines of AST to use defineProperty to set it.. Flow complains for me :(. I can move this function out. Thanks for letting me know.. You can't traverse any other way, we do the same thing everywhere else.. ThisExpression doesn't have a name. This checks if the Identifier has a name of this (it can happen now and then, so this checks against it).. @sebmarkbage You'd need to create the assignment to a value before incrementing right?. What does __superConstructor__ even do? Every other polyfill does a __proto__ assignment or setPrototypeOf here instead.. If you change that one line to __proto__, everything works as expected. but because we are setting it to be superClass, it tries to emit the function React.Component instead; which isn't right :/. I actually thought it was a good criteria as this is under the mocks tests for fb.. I've added a pure test in addition to the React test. It is meta data for the test runner, I've had to change the line number to 27 because I've added the // recover-from-error which tells is that the behaviour of this test has changed now that we expect to recover from such abstract cases .. Well, the reason this is used is because we need to return Value for effects. React component renders can't ever return undefined though as the reconciler blocks this, so if this occurs we know it's been done as part of a bail out.. I didn't want to do anything special, because in the past this has caused more confusion than necessary.. The createElement/JSX isn't dealt with here. If we return, we are simply not flagging a function as being an additionalFunction at all. \nEvery time we process a component/function, we get back the Effect, which is generated by the reconciler. We then set the effects to be additional for that particular function so later on when we come to serializing the original function, we instead use the additional function effects.. I didn't want to use Set here and instead used an array so that in the future we could process the same function multiple times with different props and context. We'd create a new function context each time this happens from the same original function, we'd just be dealing with different effects.. This breaks FB www rules around certain naming cases, so there\u2019s interval correctness to this PR too. . I couldn\u2019t think of another way of doing this properly. . @sebmarkbage I believe we're not trying to detect errors here and the serializer test runner works differently? I didn't need to add it and it definitely went through the same code path as it fails without this PR.. What do you both suggest we do then? Drop this PR and find another solution? Maybe I could split out the traversal work and the work in the generator (keeping that would make for better naming already).. This was causing a Flow error for me locally saying that too many arguments were passed. I guess this was triggered because I modified Realm.js.. I\u2019m not trying to check against objects, but rather than root visit to the matching abstract function. I think the whole naming of leak is complicating things somewhat here too. We should rename to escape. This bit of logic makes more sense then - \u201cthis abstract function is safe when evaluating its contents for escape analysis\u201d. . Definitely, I ran into an issue regarding this today when an error was thrown in _withScope.. We render the object. In order for us to render the internal render method, we need to apply a nested additionalFunction because we're inside a closure. Currently additionalFunctions only work when they are referenced to global scope. So we'll need to work on that before we can do that.. It's rendering the functional component that returns the factory object and the reconciler returns that value as the render result (the same as it was before). This passes as React handles renders that return factory objects.. I tried that originally but I couldn\u2019t get it to serialize right. There is a way via creating the AbstractValue via the constructor route, but that means more boilerplate code than this route. This is already a somewhat hacky route as what we're doing isn't really \"normal\" \u2013 in that we want to serialize something in a very strict manner.. That was for debugging. Removed :). Fixed. Address in a new commit. I'm assigning it to keep the AbstractValue monomorphic. If we don't define it, the hidden class of it will change (impacting performance).. I thought about storing a WeakMap referencing AbstractValue's to their reactHints. I opted for this approach, but if anyone else can think of a better approach, I'd be happy to change.. Sorry, I meant this is just something that can have a performance win for V8 (via Node). Otherwise, if we don't define properties that are later added we actually pay more cost in terms of memory and overhead that wouldn't occur if the objects were monomorphic. Here's a good article on this: http://mrale.ph/blog/2015/01/11/whats-up-with-monomorphism.html\nI realise I've probably explained this badly, maybe @sebmarkbage can better explain as I'm on my phone right now.. I agree, we should be measuring these things. One might argue that we should be measuring the performance of not ensuring all our classes are monomorphic rather than making everything polymorphic. Especially considering we create enough of them to warrant the hot path of the hidden classes being used, off-setting any memory issues anyway. https://github.com/v8/v8/wiki/Design-Elements\nI'll revert this change for now because you seem to feel strongly about this and I don't have the time to add in extensive and accurate benchmarking for Prepack right now (although I definitely want to). I'll be in Seattle at the end of the month, I'd be happy to sit down with you and explain some of the ideas I have around benchmarking this sort of heuristic though.. @NTillmann @sebmarkbage @cblappert what is your take on this change?. If I change the above comment you made to a CompilerDiagnostic, it should cover the \"user\" side of this problem as this utility function is only internal.. This file is exactly the same code we had before we removed it.. If we can determine this, that will make sense, otherwise tests fail without this.. I just tried. Seems that we can't mark AbstractObjectValue as frozen :( Prepack only supports ObjectValue. Flow complains if we don't. Annoying, I know. I've already told the Flow team a while ago about this and it's on their roadmap.. I'll add more tests for these cases.. This was all changed, the code above was the same code as before.. Fixed. We could add a flag later for UFI testing.. Transpiled source is when the code is run through Babel before being passed to Prepack to be evaluated and compiled.. We're in a pure scope now, so we can make those assertions.. There was some confusion over the scope of this PR as the other PR blurred it all.. @gaearon Good point, change made.. I have no idea why this project does this for VS Code, Sublime and Atom, I'm so confused why it only happens for Prepack.. I can change that, but it doesn't make any difference for these tests as there are no keys to copy over. I'll add another test that does have keys.. I've add some code that follows the assumptions. If they were changed and the FatalError wasn't thrown, then the object wouldn't be made simple.. I tried that, it fails the my second test as not all sources need to be simple too for the target to be simple.. @cblappert This is the point that I'm a bit stuck with. If I try realm.composeWithSavedCompletion(value);, it gives me back a ObjectValue that looks like a ReactElement, so that's good \u2013 but it also makes the realm.generator._entries and empty array and this during visiting/serialization. If I instead skip over checking the value here (just to find what is causing the problems), I get an invariant later on when checking all the bindings for their values.\nIf you check out this branch and use the test provided , you should see the same problem.. \n. I\u2019m not trying to set here. I\u2019m just trying to get the value for the purpose of this test.. We're setting y on copyOfProps.\nThe result is this, so it appears to be working?\n<div>Hello 20 30</div>;. @gaearon @sebmarkbage I see what I think you mean now, I had a lint rule on Atom that said I needed add a setter if I had a getter, so I added a random no-op one. Haha.. It creates the wrong output because of the bugs on master with Object.assign. When we use Babel to convert JSX spread to JS, it uses Object.assign but the arguments are in the wrong order, like currently happens on master. If you apply your fix for Object.assign this test passes.. Typo. It's because the variable disappears from Prepack serialization if we don't, then you get obj1 is undefined when we try and run it with a JS VM for the test.. I don\u2019t bother debugging via Jest anymore, I just setup the same test in its own file and run all the test-react configuration flags on it.. Done, are you happy with this PR apart from that?. I'd prefer to do this in a follow-up PR as there are many places the pattern I used above exists. They should all be change in one PR for consistency.. Can you look more into this, it seems there might be a bug in another part of the code base if this is the case?. Can you link me to an example of the sort of error I should be using here? I noticed @sebmarkbage was using this pattern in CallExpression.js, so I just re-used that.. I run fb-www for compatability using the CLI directly with settings passed on command line.. It's 2 because an empty object that has a deleted key and ref, is two properties in size. It looks confusing, but makes sense if maybe I added a comment? I'll try and address your other point by moving the code around a bit too.. Great point.. What about the implementation I made in the follow commit? That okay?. I didn't delete it, it was still there. I force pushed the previous change. You were too ninja quick and saw before I got a chance to fix the push :D. Was there, I force pushed the previous commit by mistake.. Done :). Please can you explain?. What if we didn't throw a TypeError, but another type of error? It's far better than creating an invariant, which we can't recover from.. @hermanventer Would there be a good PP code that I could use that has already been made? I looked through the list but wasn't sure what was best.. I saw that we use createFromUnaryOp, but I couldn't get it working properly with delete operations on object properties. Rather than over-complicate the logic and create either createFromUnaryOp or createTemporalFromBuildFunction depending on the operation, I just unified them both.. I removed that FatalError altogether. We can follow up the delete logic in another PR.. It was a typo, I've since fixed it.. createFromUnaryOp expects an AbstractValue as its third argument.. I couldn't see that method on realm?. I couldn't see how we could, as the snapshot applies its own formatting.. Is Havoc.value clear? Maybe it could be Havoc.add or something that describes the verb for the action?. Yes, the test now fails. I'll fix it and uncomment it in a follow up PR.. serverSideRenderOnly is more of a TODO right now for my upcoming PR. I added it as ReactComponentTreeConfig can't be an empty object and it seemed somewhat logical to break down the actual implementation of serverSideRenderOnly from defining it in config.. It's the same error though as PP001 that already exists.. Yeah, I don't mind, I'll change it in the PR that actually does this logic.. It's the exactly same code from https://github.com/facebook/prepack/blob/master/src/serializer/functions.js#L135-L139 that was used before? I've not added any code here. The change to the code should be in a separate PR, as this isn't changing the previous logic or code.. Yep, maybe we can add it on at some point.. Normal is just a default case where neither folding or inlining happens \u2013 typically for things like React.Fragment or Context.Provider and Context.Consumer.. If we don't the test that runs eval on the getTrials function doesn't correctly pick up the closed over value. This has been a common pain with how we run tests this way \u2013 nothing else we can do for now.. No, because on update render, we need keep the children closure otherwise updates to it won't work.. I wanted to be on the safe side right now for updates, as we don't know if a parent in an unknown parent tree exists.. Actually I wanted them to pass for this check as they are frozen if react options are enabled \u2013 just like they would be in the real world on DEV.. Opps, that was left in from debugging, I'll remove.. You can do this.mainBody.entries.push(...lazyHoistedReactNodes) instead.. This is the name of the option in options.js. https://github.com/facebook/prepack/blob/master/src/options.js#L52. I agree, build-prepack makes more sense given how many build commands we have already.. This is the expected behaviour as this is how $Delete also works.. The issue is that the bound function's target function is the body I want to replace.. Yep, it's wrong but get's the test case in the issue working correctly. Maybe you could spend some time this week to help me work out how this should be done better?. It should be on bound functions, you can't apply a new context to them as per spec.. Good point, I'll try that tomorrow.. That's not really in the scope of this PR, that's a huge change to the hoisting system :/. Will add more test cases.. Will add more test cases and fix this.. Good point.. Good point.. It's an existing issue.. I removed this invariant because I was finding it was getting triggered all the time when in combination with the pure wrapper, which isn't right as indicates that our assumptions at this stage are not right? Maybe @hermanventer has a better idea what to do with this invariant block.. I moved this below as this was another common invariant that was triggered when in combination with the pure wrapper.. I do the checks twice as the logic in the middle of this function can cause it to never reach the end of this function.. I dig a lot of digging and found TimeSlice needed to be mocked, like React, otherwise it havocs far too much on the init path making it impossible to render the root UFI components.. It will serialize too much out code we don't want because we have class sugar syntax now.. I'm not sure what the fix for this is then @sebmarkbage?. We have checks for that elsewhere in the codebase:\nhttps://github.com/facebook/prepack/blob/master/src/methods/properties.js#L975. @hermanventer I believe @sebmarkbage has a better approach so maybe I should close this PR.. If a value resolves to be the same value (which is likely in many cases) then the original value is returned.. Doesn't this newline make sense?. Made the relevant changes.. I originally tried, but the test-renderer doesn't seem to work with object refs right now so I was going to look into that after this landed.. I'll add a callback ref to show it working though.. Yep, but getElements triggers an invariant if it's undefined, which is why we can't use it here.. - You can forward refs more through several levels\nCan you give me an example of a test like this? Ideally, if you could just add a said test to this PR that would be awesome.. Fixed. :). Found a bug when you pass in key or ref to a ReactElement that is partial but we know the key or ref to be concrete, i.e. <div {...partialObject} key=\"123\" />. Holds a reference to the function or it gets DCE.. Sure, I'm not concerned about how we reference it. I'll change.. One thing that this handles though, is if you only have a completely abstract value, where we use AbstractValue.createFromLogicalOp(realm, \"&&\", c, newState);. Because it's an &&, rather than a conditional (having a conditional return the prevState will invalidate the parent || statement). So having a top level || that returns the prevState catches all these cases as long as all child branches correctly return a valid falsey.. false is better to minify (!1) and I believe it has better runtime costs for boolean casting in non JIT environments.. Don't use arguments, instead be explicit.. These 2 lines were the real fix for this PR.. If you look at the test I added, you'll see the 3 possible cases in there. If you don't pass a value, like createElement(x) the 2nd argument is undefined, if you pass do createElement(x, undefined), the 2nd argument a concrete undefined value.. This is an internal getter, we shouldn't be falling back to the original Get in any case, that was my mistake. If we fallback, we might as well just have done the original Get to begin with.. I originally added this invariant in thinking it would never be possible as part of a normal code path, it turns out that we will run into this with normal code though.. Definitely. I was just trying to demonstrate a work-around that would give hints upon a better fix. I never imagined this PR would be merged.. That would be ideal, but the args are empty as this a temporal abstract :(. Why do we want to havoc it if we're going to process the function later as an optimized function? Not sure what to do here if we have to, I was of the understanding that we didn't for functions such as Array.from where the mapfn was not abstract.. @sebmarkbage I wasn't sure if this was right, but we hit this abstract value in the 2nd test I added.. Why do we need to delete in the case of an EmptyValue? I tried that just now but the output made absolutely no sense \u2013 there is no reason to delete anything here.. Then should we change the tests to not error on the re-ordering of operands?. @hermanventer I've made the changes you suggested here.. Thanks @hermanventer, I've made that change.. We don't support it right now, it was to be dealt with in a follow up PR.. Nice one, will do.. Will do.. I'm not sure what you mean? Remove the checks for these names? If I do that, stuff breaks.. If I do array.push(x) I get a serialization issue, as it passes your above condition, but fails in mine and goes to being a temporal instead.. I'm not sure if we should visit them, maybe @hermanventer can shine some light.. Nice one. Thanks for spotting that!. This isn't new code introduced in this PR, so I'm happy to fix in a follow up PR too.. I was of the understand that this wasn't necessary because Environment.GetValue(realm, expr) would have already dealt with that and wrapped it.. It should deal with these too, as it havocs the original value. I just wrote some tests for the cases above and they pass for me because of havocing.. For example:\nInput:\n```js\nfunction additional1(x) {\n  x.x++\n  return x.x;\n}\nfunction additional2(x) {\n ++x.x\n return x.x;\n}\nif (global.__optimize) {\n  __optimize(additional1);\n  __optimize(additional2);\n}\ninspect = function() {\n  let x = additional1({x: 4});\n  let y = additional2({x: 10});\n  return x + y;\n}\n```\nOutput:\n```js\nvar additional1, additional2;\n(function () {\n  var _$6 = this;\nvar $7 = $6.Object;\n  var $8 = $7.assign;\nvar 1 = function (x) {\n    var _2 = $8(x);\nvar _$3 = _2.x;\n\nvar _$4 = ++_$3;\n\nvar _$5 = _2.x;\nreturn _$5;\n\n};\nvar 6 = function (x) {\n    var _7 = $8(x);\nvar _$0 = _7.x;\n\nvar _$1 = _$0++;\n\nvar _$2 = _7.x;\nreturn _$2;\n\n};\nvar _0 = function () {\n    let x = additional1({\n      x: 4\n    });\n    let y = additional2({\n      x: 10\n    });\n    return x + y;\n  };\n$6.additional1 = _6;\n  $6.additional2 = _1;\n  inspect = _0;\n}).call(this);\n```. This still works:\nInput:\n```js\nfunction additional1(x) {\n  var otherObj = {x:x.x};\n  otherObj.x++;\n  return otherObj.x;\n}\nfunction additional2(x) {\n  var otherObj = {x:x.x};\n  ++otherObj.x;\n  return otherObj.x;\n}\nif (global.__optimize) {\n  __optimize(additional1);\n  __optimize(additional2);\n}\ninspect = function() {\n  let x = additional1({x: 4});\n  let y = additional2({x: 10});\n  return x + y;\n}\n```\nOutput:\n```js\nvar additional1, additional2;\n(function () {\n  var _$4 = this;\nvar $5 = $4.Object;\n  var $6 = $5.assign;\nvar 1 = function (x) {\n    var _2 = $6(x);\nvar _$2 = _2.x;\n\nvar _$3 = ++_$2;\n\nreturn _$2;\n\n};\nvar 5 = function (x) {\n    var _6 = $6(x);\nvar _$0 = _6.x;\n\nvar _$1 = _$0++;\n\nreturn _$0;\n\n};\nvar _0 = function () {\n    let x = additional1({\n      x: 4\n    });\n    let y = additional2({\n      x: 10\n    });\n    return x + y;\n  };\n$4.additional1 = _5;\n  $4.additional2 = _1;\n  inspect = _0;\n}).call(this);\n```\nbash\nPassed: 4/4 100%\ntest/serializer/additional-functions/UpdateExpression.js {\"delayInitializations\":false,\"inlineExpressions\":false,\"simpleClosures\":false,\"residual\":false}\ntest/serializer/additional-functions/UpdateExpression.js {\"delayInitializations\":true,\"inlineExpressions\":true,\"simpleClosures\":false,\"residual\":false}\ntest/serializer/additional-functions/UpdateExpression.js {\"delayInitializations\":false,\"inlineExpressions\":false,\"simpleClosures\":true,\"residual\":false}\ntest/serializer/additional-functions/UpdateExpression.js {\"delayInitializations\":false,\"inlineExpressions\":true,\"simpleClosures\":true,\"residual\":false}. I thought about it, but actually it doesn't need it here as we should never be failing in the visitor or something is very broken.. Now we have a dedicated visitor, we simply don't visit these at all. The above code was all very hacky really. I'm happy to see this hacky code gone now!. Actually, sorry, we do need this logic. I'll rename and add a comment.. If the render was impure, we skip applying it's effects. So the effects are never used and should be restored.. Intentionally left in so you can see it correctly finds an impure binding modification.. This is to help debugging.. Eventually, when we're at that stage these should make it out with a URL to a detailed wiki page.. I updated all the comments around this \u2013 just in case anyone was wondering.. I'd like to know more about this too. If simpleClosures is broken, why don't we remove it and fix the normal operations of closures? If I disable it, loads of tests fail \u2013 see the PR summary for info on why.. We could diff the changes to bindings and then ignore them specifically when checking for side-effects? I originally tried that but ran into some strange errors.. I mentioned this in my summary. In the cases where d1 and d2 are both undefined, it's not really safe to continue to then do Join.joinValuesAsConditional(this.$Realm, cond, d1val, d2val); as one of the React tests broke when we did this (bad output).. Intentionally left as a TODO for now. Intentionally left as a TODO for now. We can't unfortunately, I tried that as my first approach. The issue is that the property might be on the prototype (which is ironically what they are in this case).. That's because I removed this part in this PR: https://github.com/facebook/prepack/pull/1690/files#diff-35328c9e9230682947d04cd307cec77cR1653. We should aim to, which means the original tests for this feature didn't add all the coverage they should have. I also tried renaming it to see if tests broke when I made this PR and thought it was odd.. We only want to use wrapped in the above case, otherwise we should still use this?. Good point, I'll do that for sure.. We can probably work out from the binding, what function it was in. I'm not sure how we can make a call stack again though as this happens after all the evaluation has occured.. Hehe, this PR means we can finally remove this TODO!. Agreed, I'll refactor this fix around that.. We need to create a \"temporal\" entry in the generator here.. I'll handle these in a follow up.. A test case would be awesome :). Will add those checks. Will add other bindings, do you know which ones you were thinking of?. All these tests pass with the current code.. It's for when the value doesn't exist or has been passed in as undefined.. The others will need to be changed to pure scope too.. Sorry, you were right with your first reply. Change applied.. We can return earlier. This should have always been here really.. We don't do that currently for arrays as the kind is Array which skips the check. Otherwise I would have kept that logic in too (check a few lines down for what I mean).. This looked like an obvious optimization here, unless I'm mistaken?. Why was this test skipped?. I actually found a case just now where joinValuesAsConditional's simplify step hits the limit and returns the abstract condition, even though d1val === d2val.. That's using Prettier :P. Not sure, I manually added one in and it seems happy with it. Meh, something strange going on with Prettier here. It passes the lint rules at least.. No, we need them. We need to access the array prototype methods, but only the ones that create new arrays.. Sounds good. I can change this next week.. Nope, it shouldn't be.. Not via JSX/createElement directly. Edit: You can if you pass in a hoely array though.. Yes, these are ReactElement children \u2013 it's created via an internal part of React.. Ah, I understand what Nikolai meant now. Fixed! :). I've made the invariant a TODO incase this ever comes up. It shouldn't though but at least the invariant makes more sense now.. Yep, that's what I intended to do. We're resolving empty slots into undefined.. The only place this can ever get set is the React reconciler with the props going into a function.. When the reconciler enters a component and it's completely abstract it creates completely abstract props and context when calling render (functional component) or assigns them to the instance (class component). It makes them simple and final too.. Formatting is a bit off here.. It's used to determine if something is fully abstract and has no values in its ValuesDomain.. We create a template object that can contain values (in this case, key and ref and make the bindings with undefined descriptors). We then need to attach it to an abstract object value so we need to ensure it has a values domain so we can add it to its Set.. Sorry for the confusion. When an abstract object value has no ValueSet, we can't make it final as there's no underlying object for it. If we try it will fire an invariant.. We need to create a template to store the fact we want to make key and ref. In order to do that we need to create a backing template so we can Set values. You can't Set values on an abstract object value that is \"top\" (one without a template).. You're right, we can also reset key and ref if they're not set already because if we didn't have a a safe key/ref it would have thrown above. Resetting makes the abstract object value have a backing template, thus we can then make it final in all cases. Change committed.. This is not a cache. It's adding it to the Set as it's not partial thus doesn't have partial properties.. It can't ever get them though, we're creating a ReactElement here and making props from the config. The props are immutable and can't change, so it can't get new properties that are partial.. Ignore my last comment, it was incorrect. I replied on my phone and didn't see the context properly (github is terrible on mobile). This is a generic function, so I removed the additions to the Sets.. Like in my latest commit?. That's exactly what I want to do!. Unfortunately not, abstract object values cannot be final \u2013 only their underlying template can be and not all abstract object values have templates (that's why we do the top check).. Oops, I wasn't meant to remove that. Nice spot.. Test added :). This was a whoopsie that has been here for a while it seems.. When we join effects, shouldn't we join this new property on the descriptors too? Otherwise we'll lose this property and have no idea what the original value was on the joined effects?. It means to add keys to ReactElement nodes in this specific branch.. It was something missed off, not sure of any bugs, but this is the right logic to do after speaking with @sebmarkbage.. After speaking to @NTillmann it seems we don't need to when dealing with ObjectValue setting. So I'd rather remove duplicate logic where possible.. This occurs frequently, but I've not seen anything fail in snapshots. Maybe you can think of a test case?. I also added a comment in my commit.. Done :). Out of scope for now. We definitely didn't support this before and this PR was more of a clean up than adding brand new functionality. We might be able to add some form of helper method at runtime that adds in keys \u2013 as the array is completely abstract to us.. Let's handle in a follow up still. Failing hard here may make sense once we have more tests around it. I've updated https://github.com/facebook/prepack/issues/1131 to include a point about them.. Good point. I'll make sure that we check the value matches the prototype.. We know that P is a string, it's in an if condition.. We have a pure scope check, which means that we're stating that the global hasn't been modified outside of Prepack's knowledge.\nAlso, sorry for asking a silly question, but what is a local data property and how do you envisage I might test it? Do you mean as $GetOwnProperty check?. I just pushed some changes to get.js, I believe it now addresses this concern. Let me know if I've missed something.. I've added checks to ensure all the prototype methods are not local methods. We can safely know they were on the prototype as all unknown arrays come from get.js only to the NativeFunction values in ArrayPrototype.js.. That's true, I've made those changes too :). I updated the summary above. At this point in time, ReactElements are the only final objects that have a dedicated serialization codepath that ensures that any of their delayed properties are output together with the entire object.. @NTillmann Yes, it seems like the same issue for Object.freeze and ordering. Any properties that are delayed are emitted way after the function call. I updated the summary to explain why ReactElements are special.. Actually, I just tried this and the effects were reverted fine \u2013 as we're already in a recovery (from CallExpression).. No, this doesn't fix anything. Purely changed whilst I was looking at all Object.assign sites.. I don't really know what either of you expect me to test here? This is purely a cosmetic change.. Done. Sorry, I misread which file this commented related to. I've updated the test comment.. Removed from this PR. Will address in a follow up.. Done. Doh :D. Yep, I was testing to make sure it worked with and without, but then forgot to enable it again :P. I was under the impression that leftValue only evaluated once with this code. Please can you explain what makes it evaluate twice?. How would I evaluate leftValue? I thought by this point it was already evaluated?. It takes the value and tries to unfold it if it\u2019s a valid React value (ReactElement, array, abstract value) that allows us to generate a new value from it. Doing this might create generator entries that need to be wrapped in a condition (otherwise we get runtime errors). We should be wrapping the right value in a conditional so at runtime it won\u2019t happen unless the left value is truthy. It's safe because this only happens in pure scope. Even if there was a getter, the getter should be a pure function because we're in pure scope, and not change state of that around it, so not calling it should not cause side-effects.. Interestingly, Google Closure Compiler also applies the same optimization heuristic here too.. All optimized functions run in pure scope. If something is doing as you mention above, then that breaks our constraint and it shouldn't be used with pure scope.. I'll improve the comment. It's because the getTrials closure doesn't get the right reference unless we put it on the global (because of how we evaluate the getTrials call in react-test).. Ah this isn't needed, only for react-context3.js where it's used. I'll remove and update the comment on that test.. Not really, as we improve inlining, we need to update snapshots. It's a pain but not having the snapshots and regressing is going to be more painful.. It does look up reference counts, unless it's the root, in which case it doesn't need to as there can be no parent components with context in.. Happy to rename if you have  a better name though.. This wasn't a new change, it's been in master for ages.. It further inlines code, if you remove this line, one of the newer tests fail for me (as the contents of the render props doesn't get inlined).. _isContextValueKnown sounds good, if you are fixing this PR, would you mind making this change too please? I'm sorting out the conditional PR :). Ah, no, this is not trying to optimize nested optimized functions (which are caught later by reactOptimizeNestedFunctions flag anyway, so that's handled). This is when we don't need to process the render prop as an optimized nested function and can just inline the contents.. That would be the big fix. Let's do that next week when I'm in London :) putting them in their own files will also speed things up nicely.. No, this is not a function, this is inlining the result from calling the render prop on line 527.. It's testing without a value.. Opps, this test wasn't meant to be added here.. Probably no test touches it.. This doesn't seem related to this PR. It's just that we encounter it when a ReactElement is an arg on a generator entry.. The amount of times createElement is called from both compiled and non-compiled. 4 + 3. Yeah, I will do. Sorry, still trying to get my head around why it fails out internal bundle :/. Intentional. This PR is WIP. This is actually another correctness thing, that wasn't done before but should have been. See the original snapshot logic from Object.assign:\nhttps://github.com/facebook/prepack/blob/master/src/intrinsics/ecma262/Object.js#L122. Sure, happy to explain as it took me a while to understand it too. What I meant by a correctness change, was that I wanted the React logic to 1:1 match the existing logic of Object.assign. When we snapshot an object via getSnapshot we first check if the object already has a temporalAlias value, if so we return that value otherwise we do some work and create a temporal of that object at that point in time. This is important, because _temporalAlias is a tracked value on the object, which means that it's bindings can change between different scopes/effects.\nSo at a later point, if we try to call getSnapshot again and the object has already had it's temporalAlias set, then we use that value. That value may have been created in some effects with a conditional, so the value might be a conditional abstract representing two possible temporal values at different points. If we overwrote the temporal alias and removed the existing conditional, we'd potentially break things.. We can do, but I thought this way was better because we're not introducing another property onto AbstractObjectValue.. @gaearon Do you feel that we should move to using properties? I'm happy to make this change now, but I don't have any strong preference. I actually thought of doing that originally but then thought feedback would be \"can't you move this into a Map, rather than adding another property\". Heh.. It's only for our props. If we have other cases, I'll move it out in a follow up PR. :). You're right, we can't hit this code path. someReactNode || someReactNode and someReactNode && someReactNode are not possible at this point (it would always resolve truthy or falsey because they are known objects). I've removed this code and added an invariant.. I thought I'd rename it on this PR as this PR was quite tiny in size and it is somewhat related.. Removed, it's no longer needed. I had a test case that I thought needed this but I fixed this in another place.. I'll remove those changes. I'll probably do a tidy up PR instead and just do a lot of renaming as a single PR :). It is tied to nested optimized functions, this only occurs if a function is optimized inside another optimized function.. For the React Compiler this okay (for now), long term we do want to support loops fully as I stated in my summary. Maybe if you have some good ideas on how to configure such a thing, you could make an issue for it with some suggestions and we could implement it \u2013 as you're right, we definitely can't do this for IR.\nOn a side note though, we might be able to support parts of this for the React Compiler. When we create this wrapper function, we can also check to see if the for loop is pure or has few side-effects and contain the side-effects in the wrapper function, then create another function for the loop body, then tell Prepack to optimize the inner function for the body. I thought of doing that as part of this PR, but it would really convolute the contents for now. It's best as a follow up PR.. See the test cases, I need those to work :) sorry I\u2019m on mobile atm but can explain better when I\u2019m back to my desk.. Thanks for the detailed explanation that makes sense. I\u2019m happy for you to rename it, I\u2019m at the dentist right now :). It\u2019s a todo. Once everyone is happy I\u2019ll change the todo into a proper fatal. @gaearon\nYou misunderstood my reply to Nikolai. I wasn\u2019t suggesting that the tests were good indicators of the problem. I was saying that they demonstrate the problem in case he wanted to know what this PR was attempting to fix . Throw where and with what? Sorry, not sure I get what you mean here.. I think I addressed your issue Nikolai, I've changed the logic. Just adding a test for it too.. I understand now. Thanks, added that case.. What locations are you referring to? The havoc logic recursively goes through every binding and object in the AST of the loop and its body. If something isn't being reached, we need to fix it in the havoc logic. If you mean the loop body is accessing something Prepack doesn't know about, then this isn't safe for pure scope.. Yes, as the non-compiled code won't strip off the ref and thus the tests won't match. I couldn't think of another way.. Not yet, this test is more for my follow up PR. I left it in a comment for now saying just that.. Good idea.. When they're not created in a component (i.e. in the main body of the app). We need this for the follow up PR to be able to know if it can strip out properties.. Nice one, will do! :). I thought does not contain was added for these reasons? I'm happy to change it to something else. We'd need an assertion for if something is abstract, I'm guessing from your above comment?. I'll look to see if I can clean up the text structure some more.. Done. Done.. It's mutated so that in the serialization phase, we know it's pure. We can't do the same purity check here, as that's only something that occurs in the visitor phase. I guess we could make another flag?. So we know it hasn't incorrectly been removed. I had to change the test as we know reference Object.assign as a variable and then use it as a call, unlike before (because we aren't bailing out).. I did that originally but it looked more complex. Unless you have an example that looks more DRY.. I've removed that condition. I understand what you mean now.. We can't havoc it before going into this, or we can't get a snapshot from it properly. I've changed to code to push it to delayedSources.. What's wrong with inheritance? I find this code cleaner and easier to understand/read now.. I have to disagree here, This isn't the same as UI components, this is business logic. I actually find inheritance is fine in cases like this when there's only a single level of inheritance and the contract is explicit.\nI'll refactor the classes again though as I don't want to block this PR on arguments of the validity of inheritance :D. It's for snapshotting, I've addressed in latest commit :). I've redone it all and removed the classes, it's all functions and argument passing now. Functional FTW. It was to make Flow happy.. How do you mean? We should add this to the existing scheme or it should be handled with another implementation?. If it's undefined, then we need to create the binding. That's why we do it here.. I think this line is the cause for the failure of the repro. Can this not be?\nthis.joinDescriptors(realm, joinCondition, be1.previousDescriptor, be2.previousDescriptor)?. Either way, we should never be setting the descriptor to undefined if both previous descriptors are defined. Otherwise, when we undo the bindings and switch to the previous descriptor, which is undefined, we run into issues like in the failing test case Dan gave above.. That's a valid point. Let me simplify this.. So, I've simplified it in many other cases, but we still need to call it manually in some cases like the one above. I think most cases are now covered though.. I did add a comment to the above point though.. I'll move the ordering.. @hermanventer with master rebased on your PR? Last time I checked it all passed for me.. Fixed in https://github.com/facebook/prepack/pull/2149. Yes, you beat me to this, I changed it in my latest commit.. Without this line, I get an error when importing react-native. This also seems to be the reason why tests fail, as it doesn't allow for inlining of View and Text.. We support ES2015, why not use array spread? \nstatements.push(...switchCase.consequent);. Same as my other comment.. AFAIK they are equivalent if not faster, you should be able to tell with a quick sanity test locally on our bundle?. Simple closures were removed a while back, I couldn't see why we had it in the codebase still, it confused me at first.. BooleanValue is an instance of a ConcreteValue, so it would be inlined unless part of a conditional with an abstract value.. It will inline if a conditionals leaf values are all concrete, if a single leaf is abstract it won\u2019t though. I tried it in the reverse, but we inline and create quite a bit more bloat. Maybe I\u2019ll refine it more.. I'll take another look at this and see why again.. Fixed the test.. We want to make it optional still as we're the only consumers of using the side-effect detection whilst pureScope is also used by the generic optimized function code path.. Can we just use a normal arrow function here rather than bind?. Maybe remove this from the React reconciler now that it's generic.. I've reverted my changes and put the separate logic behind a mergeWithParentEvaluatePures flag to be use in later work, with comments as to why it's needed.. It shows up in Atom and VSCode, so you can decide what to use if you\u2019re not sure. We should do this everywhere tbh . Lol, yeah, I should have removed that . It's loosely based on https://github.com/facebook/react-native/blob/master/jest/setup.js. I've had to change parts though to make it work with this. If this breaks, someone will need to fix it, I don't see any other way. It sucks, but then so does the need to mock everything in RN. I was pointed to use these mock setup files to fork, it's apparently how others have done it in the past too.. This modified from https://github.com/facebook/react-native/blob/master/jest-preset.json. The version on RN master wouldn't work with the version from NPM and the current RN master isn't on NPM.. Like I said in other comment, it sucks, but I asked the RN folks and they pointed me to the Jest mock folder on the RN repo and said to fork and use that.. You can use the react-native preset, which pulls these exact same files in. The only issue is that the preset mocks View and Text, and we don't want them to be mocked, we want the real version so we can compare the \"inlined\" View and Text (RCTView and RCTText/RCTVirtualText). I asked the RN folks and they guided me to these files and said I should fork them to do what I want with Jest.. I'll come up with a test does fail when it's false.. I'll try that out, I never even knew there was an unmock! Likely next week though, unless you wanted to pick this up? Seems you know more about Jest than I do.. Why not get the realm off the value rather than add it to every call site?. We can leave it off, you're right that this doesn't help here. This functionality is mainly for the work in the other PR that adds pure scope checking around all function calls when in pure mode.. Done. They're not on the AbstractValue, rather they are the temporal generator node args. If the abstract value and the generator node both had the same args, this entire thing would be vastly easier to do :). Another way would be to link the generator entry to the abstract value, in fact that might be a general easier approach. In the other PR https://github.com/facebook/prepack/pull/2148, which this is a small part of, we also need to know the additional args when the generator entry was created so we can clone and re-create the generator entries (see https://github.com/facebook/prepack/pull/2148/files#diff-5cb5f0c9909e8738d567acfaff9bb980R278). So having a link from an abstract value, and it's original temporal entry would be highly beneficial. If not, and you feel this is a bad approach, how might we do this? @sebmarkbage @NTillmann . @hermanventer Good point. I've created a PR to change to that approach https://github.com/facebook/prepack/pull/2199. I tried to adds the args (to see what would happen) and it appears to break the serializer output and we run into invariants, so I guess the derived abstract values don't have args on the value for structure reasons like you suggest.. I believe it's to help Flow, as per the usual code. I don't understand how this could ever happen, it doesn't happen when running on our internal bundle and tests at least.. Made it an invariant :). We don't mutate other entries, we only mutate the existing entry, recursively merging in the other entries.. Ignore this I have a better alternative.. Maybe we should do that in another PR, the only reason I did it here was to make Flow work without adding loads of invariants.. There are no usages of Object.assign though, it's declared and referenced as _5 outside the function once in the module.. That is what is happening though, we return true because we've created a new entry that needs to be visited. If I change this to false a bunch of React tests correctly fail.. We check a few lines up:\njs\n    if (!callbacks.canOmit(possibleOtherObjectAssignTo)) {\n      continue;\n    }. I've re-worked this. There is no argument re-writing going on here though. We don't mutate any entries anymore, we create new ones instead.. I guess we're confusing how Object.assign works then? If a tree of Object.assigns, say:\nA -> B -> C -> D\nEven if A, B or C have not been visited, but they may be visited, D won't apply any optimizations until D itself has been visited. I added a test for this too:\nI added a bunch of tests around this. Unless I'm completely missing something, or maybe you can give a test case that fails this?. In principle, the getProperty method is only meant to be used on Objects that can only ever have one value as they're React objects that we control. So this invariant is fine with me.. I'm not familiar with this bit of code. I believe @yinghuitan wrote the original code.. @gaearon Addressed with Nikolai's PR: https://github.com/facebook/prepack/pull/2210. We can tighten up and not need as many invariants now.. Maybe you can better address this in a follow up as it means changing how all the current temporals works for Object.assign. On another note, using a single reference to Object.assign , is far better than doing runtime property accesses to do the same thing, even if it does yield better output. Doing _$0.assign() as worse than doing _$0(...), as it means having to prototype lookup for assign on _$0 everytime.. It's needed as conditional temporal entries get recorded too.. I used to do this check in previous logic, but you said to not do a conditional check there either. The fact is, conditional generator entries do definitely get recorded.. Mind providing a quick test case for me please? I'm not sure I fully understand and seeing code might help :). Do you mean to move derivedIds to Realm too?. Yeah, this only happened recently after updating Flow I think but no one changed the file. Strange one but nextSource might be null or undefined and we have standard logic that deals with that in applyObjectAssignSource. . Same as my reply to your other comment.. Okay I will remove this check and tell you what test fails.. This test fails:\njs\nfunction f(x, foo, bar) {\n  var a = Object.assign({}, foo, bar, {a: 1});\n  foo = {};\n  var b\n  if (x) {\n    b = Object.assign({}, a, {a: 2});\n  } else {\n    b = Object.assign({}, a, {a: 5});\n  }\n  var c = Object.assign({}, b, {a: 2}, {d: 5});\n  return c;\n}\nBecause b is a conditional abstract object value that has a temporal entry.. So I added logic to do what you said above, but the issue is that o1 can never be marked as havoc as it's never an AbstractObjectValue or ObjectValue. It sounds like we're doing something here that we don't currently support in Prepack, so I'm not sure how to model it. Regardless, I'll add that logic you mentioned.. This test works with your change, and works with my previous concerns:\njs\nfunction f(o1, o2, g, h) {\n  let a = Object.assign({}, o1);\n  g(a, o2);\n  let p = Object.assign({}, a);\n  h(o2); // can mutate a !\n  let q = Object.assign({}, p);\n  return q;\n}. Done :). Got you now. Applied change.. @NTillmann Your last test passes with the changes in this PR. :). Let's go back to the invariant here, it's an internal Prepack issue if it fails.. We may have been doing this in the case where React is behind something that is behind a value that is delayed. If you run your PR on our internal bundle that I sent you the other night, do we hit any issues when compiling it?. I added memoizeReference(\"Object.assign\"). We still need to reference variables that change between tests though :/. I'll do in a follow up PR, if that's okay?. They won\u2019t work with my changes as the function isn\u2019t behaving pure and thus doesn\u2019t go down the same code path to emit binding changes to objects that were mutated outside the scope.. @sb98052 I can fill you in on how getSnapshot works if that helps? Feel free to ping me and we can setup a VC or chat over workplace. Otherwise, I'll be sure to put up a PR tomorrow adding some comments around it if that helps.. What if I throw a SimpleNormalCompletion here instead of a new type of completion? We only care for the generator entries of this execution path, not of any value thrown.. Applied changes, now uses SimpleNormalCompletion and seems to work fine without needing to add another completion.. Will try using a flag instead.. Add another property to the existing one I added? I'm a little confused, please can you expand more?. I believe this was just a rename from ioVal which was the same invariant as before. So maybe @NTillmann can explain more why leakedObjects is a union with void. We should probably refine that type so that there is no union with void?. I'll add a test case.. No it was not.. Yes, it does :). Fixed the test, I didn't save the file before committing.. In pure scope, it's assumed that abstract values don't have side-effects that are unknown: https://github.com/facebook/prepack/wiki/Compiler-assumptions#pure-scope-assumptions. console.log is technically a side-effectful thing right? Why were you using getters for in your test? Minifiers like google closure compiler will also strip these too, so we added the same assumptions to our wiki doc. Let's talk about this in a separate issue \u2013 I don't want to side track the work you've done in this PR :). I actually first opted to add a Set and do has lookups, but found that it was actually much slower here because the arrays in Object.assign are almost always small arrays with generally less than 8 items.. I was thinking of moving the data into args rather than creating another logic path. It can be 1 or 3, not a Boolean . I'll rename that as part of this PR.. Yeah the idea is to remove this object and move the data into args. We pass around functions and references to Prepack internals in some cases, so those particular operations will need refactoring quite heavily, but it's all incremental work.. Removing it in follow up, it was a really early comment from the first day on that PR. Thanks for pointing it out.. I'm not bothered on naming really, getKey or getDedupeKey is good with me too. I went with getHash just to get some code out there so others could get their teeth into the proposal.. Rather than doing intrinsicName || __originalName every time, we should create a helper function like have with React, getFunctionName(). Functions might also have a name as a property, and neither of these ways will get it, so it's best if we start making the name getting part generic in the code base.. Eventually I wanted to maybe add context and state, so left it open. But I'll change this.. It should be documented on https://github.com/facebook/prepack/wiki/Compiler-assumptions. They are primitive values, they can't have properties (that I'm aware of) on string, number, boolean and symbol. You can [] access characters at an index, but then that wouldn't be on the prototype.. I was probably a bit eager here and didn't need to change this one.. Maybe we can at a future point, I don't feel this PR should change all those call sites though, there are quite a fair few of them.. I can make a repro as a separate issue.. Can we extract this key adding logic into its own function that has a descriptive name. We might want to apply the same logic in other parts of the reconciler or in branching.js at some point so it would be useful to have as utility function.. Can we call it heapInspector and remove the underscore?. There's only three cases of them and they're backed by the Flow enum. Extracting it out into a single place is a good idea though, but it also makes all the other template strings inconsistent \u2013 they should all then be imported from a central location to be consistent. Something for a follow up I guess.. We can probably add it to the whitelist: https://github.com/facebook/prepack/blob/master/scripts/lint-config.js#L14. How do you mean? This particular line shouldn't worry about the implementation, it just needs to pass the inputs for possible nested optimized functions. They might not be used, it depends on the heuristics in ArrayValue. createTemporalWithWidenedNumericProperty. We need a better way of creating names for variables rather than incrementing a counter really. That's the main problem here.. I changed the name, but maybe I'm missing your point. I opted for the simplest path here without an overly convoluted path. I thought that maybe the best approach might not be to mark properties as checked, but that probably is out-of-scope for this PR.. Will do this in a follow up, same for other comments.. Not sure I agree about not passing explicit flags. I think they are much clearer of intent that having hacky things in place like we had.. That's a good point, I found we can leverage env.destroyed and use that loop and it simplifies the code quite a bit.. It's checking that the environment record of the binding was that of the function we're in.. If they're excluded, it means we already executed that and destroyed the bindings in that scope so we don't check if that env anymore as it's bindings are no longer valid.. How can it be a pure function if the env has been destroyed? It should rightly report that there is a side-effect, as in the case of a pure function the env should never be destroyed.. Updated PR with this code. :). I thought it would be better to have it on by default in tests so we can catch bugs earlier, but I don't feel strongly and can change this.. US vs UK spelling. It's specific to && which only occurs with Herman's PR applied. Where we have the the left-side of a && condition to evaluate to something thruthy, that is not a valid React return value. As it evaluates to true, the right-side will always be used.. Will add this another test. The original tests from taken from my issue, test simple-23 fail with Herman's PR applied and simple-22 doesn't fully inline without Herman's PR.. Both names are confusing. If anything they should get the prefix after or something to show they happen after the action. We might as well get the naming right for both in this PR?. Let's keep this invariant, it's been very useful in finding early evaluation errors. Rather, we should capture the effects of the function call (using evaluateForEffects) and apply them if the createdObjects has been correctly restored. We ran into countless issues in the past that this guarded against, so I don't think we should regress on this if possible.. Actually, to make this PR easier I'm happy to remove the invariant for now. I can revisit with some changes later this week that I had planned.. It's an optimization, if neither values are functions then just proceed with the default code path.. I've added the same checks as for the conditional above. We only check if either of the values are function values, otherwise we don't bother trying to optimize as we'll just end up producing more output without gaining any precision.. That's a good point. We might need to add debugger to the eslint check too.. It's not outputting anything and statements can't be empty. Maybe \"EMPTY_OP\". I commented on this earlier, not sure where my comment went. I mentioned that it's probably best to remove both lines of comments as they don't add any real value.. I know what you mean (you're relating it to Babel's emptyStatement), but I meant as a generic operation rather than as the output JS AST node. I don't mind either way, it's all bikeshedding anyway.. That's what I mean, we need to ensure there is none. We also need to be careful of residual functions that might not be be prepacked (thus the possible eslint rule change) containing the __debugValue.. Yeah, there's some strange things happening to comments in the latest Github update. Sebastian wrote loads of comments to one of my PRs from a few weeks back and I never got them either, he had to remake them all.. Rather than output the empty variable, instead we generate an empty string as the React serialization expects this for cases where the value is a string.. Is filter used anywhere? I wasn't sure why we have this now when it doesn't really appear to be used anywhere?. If you remove the string literal optimization, you will see __empty leaked out to the output. I was under the assumption that this could happen? If not, I can easily make a repro as a separate issue and remove the above optimization.\nhttps://github.com/facebook/prepack/issues/2573. I should also add the length for the concrete case too.. I've removed this form the PR, but now the tests fail as __empty is no longer an empty string but an empty object which gets serialized out and is invalid as a return value for a React render.. I have a different approach that removes holes from the arrays in the reconciler so we shouldn't hit the same issue but the still overall problem with __empty exists, see the issue above.. I can add a realm.callReportObjectGetOwnProperties call here. That's a good shout.. You're importing the lib value here, you most definitely don't want to do this (VSCode auto does it sometimes).. This is also the wrong import, you need to import from src, not lib.. I find it a bit strange to put all of this on one line.. Can you give a test that fails with this PR? I wasn't sure how to factor your above example into what you described.. I did this originally, but then you're dependent on a function, where you might not have one (in which case you might pass in the current context's current lexical env). I'm not too bothered on which approach we use though.. We removed it ages ago and I forgot to change it here. Throwing isn't considered a side-effect in a pure function anymore.. I think this comment in general doesn't make sense. I'll update.. Definitely. Probably out of scope for this PR though.. Definitely. Probably out of scope for this PR though.. That's what I thought, but there seems to be cases where it can be defined due to joining of bindings where the binding never existed in the other set of effects.. This is a tricky one and one of the downsides of the approach in this PR. We'd probably have to store the location at the time of modification. Maybe that can be a follow up, as it seems that we need to take some time to consider the different approaches.. I believe I fixed this in a subsequent PR.. So we could use them at a later point if needed. I'm happy if we remove them though.\nIn terms of performance, this change added no noticeable overhead in my testing and I frequently compare compile times between commits.. @hermanventer Sure, if you feel that's the best course then I'm happy for it to be reverted.. ",
    "alexgyori": "All tests pass now; let me know if you see some other issue or I should add some more tests.. Well, the test case I added fails unless I add strict to those stubs. Frankly, I'm sort of new to JS and I'm still trying to fully understand how strict works and why the test would fail without this code.. StrictComplex.js fails if I remove this, not StrictSimple.js.. I added a non-strict test. LGTM?. ",
    "laughmetal": "Thanks for the review!\nLet me add the other examples to the same commit/PR so people don't get confused.. ",
    "joeymrios": "done. done. I'll make the OPTIONS button show a button border like save/delete, without showing it just on hover over.. done. what do you all think?. done. done. ",
    "tcirstea": "How can I effectively test this? The file I'm prepacking gives me {...\"valuesInlined\":0,\"delayedValues\":0,\"acceleratedModules\":0,\"delayedModules\":0}. Ran the tests. As is stands, the only two tests that accelerate one modules are require_spec_accelerate_delay.js and require_accelerate.js.\nNo modules are delayed, and based on my debugging, the code never goes into the if (effects === undefined) code block.\nAnother question, do we want the statistics to be collected regardless of the logStatistics variable? If it is set to false, the acc/del statistics will always be 0 right now.. ",
    "JWZ2018": "Currently only added object creation count. Will work on the other ones later.. Too far behind master. Closing for now, will open another one for this later.. These changes only add in the options that are missing in the CLI that should be there.\nIf the enforcing equivalence part is still needed, I can restructure the argument parsing logic in the CLI so that the equivalence can be checked even when not running from the CLI.. I can change the error handling.. This PR starts the debugger adapter and a mock UI as a python CLI to test it with.\nyarn flow currently fails because there is no flow-typed for vscode-debugadapter and vscode-debugprotocol. I will get this resolved while the code is being reviewed. . Fixed yarn flow. I will be rewriting the mock-ui in NodeJS. Please hold off review on that.. Something didn't turn out right with git push. Closing this and re-opening in a different PR.. This PR only tracks object creation statistics. I will work on the other two statistics mentioned in the task progressively.. I hope to get back to this sometime. If I do, I would be starting on a new PR. Closing this one.. I originally thought the queue will handle part of the communication sending/receiving. Now I realize the adapter can handle all of it through callbacks. So we can use an existing library for the queue. Closing this.. I will set up testing for the debugger in a separate PR afterwards to avoid making this one too big.. The main difference between DebugChannel and AdapterChannel is the DebugChannel should block when Prepack is waiting for a message from the adapter but AdapterChannel cannot block when it is waiting. Some of the common logic can be extracted out.. I will add a message handling class in a separate PR.. I don't see a way to disable thread queries. The Nuclide node debugger fetches and displays the single thread.. Updated test plan. Automated tests to come soon.. I reproduced the bug with stopping multiple times on the same line. It only occurs when I step to a line with a breakpoint and then try to continue (not step) from there. I will fix it.. I've fixed the buggy behaviour of stopping multiple times at the same location.. Only the step in is cancelled during a stop currently. We can handle other kinds of stepping differently on a stop.. I will do this refactoring in the next PR.. During interpreting, the evaluate function may be called on the same AST node more than once. This will cause the debugger to stop multiple times at the same breakpoint consecutively. I add a check for this case here.. Closing because failed to convert to diff.. \n\n\n. Any UI design suggestions welcome.. Heap graph is hidden by default, shown on button click\n\n\n. \n. \n. Closing because website code has moved to master branch. Will open a new PR with these changes there.. \n. The graph UI is hidden by default. It is triggered by a button click on the \"SHOW HEAP\" blue button on the top right. I have updated the summary to remove the TODO.\nThis is the view when the page is first loaded:\n\n. fixed. Yup I've started on that already. Will put that up in a separate PR.. Will do. Oops! Fixed. Ok I will relook at this and try again.. Verified this is pointing to the throw statement already.. Will update the wiki to have this as one of the possible triggers of this error.. Changed. Removed. Removed. This has been removed for now.. The debugger may want to set a \"breakpoint\" on a certain line as part of executing another feature such as step. I will remove this if it turns out to unnecessary.. Moved the shutdown above.. I think the isNaN check still works for strings. I will move it to after the call to parseInt.. Same as above. Will do.. Will remove.. This flag is hiding the debugger while it is being built. After it is built, whether it is used will be determined by the debuggerIsAttached check in the DebugChannel. This flag will be removed then.. I originally thought readFileSync would return a Buffer but it looks like specifying the encoding will already turn the result into a string so I will remove this.. From what I've seen, both can accept line number starting at one. I will change it if that's not the case when we try to connect to an IDE.. Yes, the entire command is passed in as one argument. See example above. We can eventually make the command to be read from a file like the launch.json in vscode.. Terminated the adapter process in this case.. I moved the parsing and buffering into a separate class.. It should not be, I removed this check.. This and _processEvent will be implemented in the next PR to not make this one too big. For now, they just confirm a message is received and parsed by printing it. . I think we need the asynchronous version here. The sychronous one will not return until the Prepack process has exited. But the adapter may need to run while Prepack is still running (e.g. passing state info to UI or passing new user commands to Prepack).. Changed to compare against actual length in the buffer.. For the CLI, we can keep these two commands as being from user input. This way we can control tests on them using the CLI. In an actual IDE, these will be done without user input.. Changed.. Moved the increment into _packageAndSend. The stringify is harder to move because each request has a different type of arguments, so all the possible types would need to be specified in _packageAndSend.. Yes, this will be used in the next PR when all 3 parts (DebugServer in Prepack, DebugAdapter, UI) are connected.. The response/acknowledgement will be sent next time Prepack is stopped, which may not be immediately or after running for a while, so we may not know the know the response at the time of reading in. The caller (or something else later) is responsible for sending a response. I will add a comment here.. This file was autogenerated using the CLI from https://github.com/flowtype/flow-typed because it's not there already. It is needed to satisfy flow checks.. I will use the npm package to set up automated testing.. This comment just explains why this invariant is here.. Updated invariants and removed comment.. checkForActions is the entry point into the debugger from Prepack. On each AST node that is evaluated, this method is called to check if the debugger needs to perform any actions on this AST node. Currently the only action is breakpoint, but more actions will be added. Reading in commands from the UI is done in waitForRun. This is the synchronous case so Prepack should block until a message is received. The sleep will need to be synchronous so it will still block the CPU.. Many of the messages (e.g. all the breakpoint ones) can be used both ways.. Unpackage already handles that. If there is more than one message, an error is thrown from the invariant. Also, there are flags on both sides checking a message is only sent when the other side is ready to accept one.. Anything called directly or indirectly from prepack-node cannot import fs.. It should not be possible. I will change to invariant.. I originally thought there can be other commands to tell Prepack to continue depending on different reasons that it stopped. So runCondition is meant to capture any logic needed to determine whether the correct \"continue\" command was given in each case. As of now, only PREPACK_RUN is a continue command so I will change to remove the runCondition.. I asked @cblappert about this before. I think it has to do with Prepack being used on the web?. FileIOWrapper cannot directly import fs even when it itself is being passed from prepack-node. It is still a dependency to prepack-standalone. I tried this yesterday.. Changed to import type DebugChannel so fs is hidden inside FileIOWrapper.. Importing the realm in the debugger causes this. Even with import type or import typeof this cycle length increases by 1.. The protocol does not specify, but Nuclide displays the current frame as frame 0. The index is mostly to identify the frame for other requests like scopes and variables so as long as the indices are unique.. Acknowledge is just notifying the adapter that Prepack has gotten the request. Response is when Prepack sends information requested by the adapter. Currently, there aren't any requests that use both, but there will be in the future.. I can change it to be similar to DebuggerRequest, but the kind field needs to go into each argument type to be used for type refinement by flow.. I have tried this before, but most objects needed (ExecutionContext, LexicalEnvironment, etc) have pointers to the realm, so importing any of them will cause this cycle increase. I checked with @cblappert before, there doesn't seem to be a good way to avoid this.. It's specified by the protocol to tell the UI if this collection of variables is big or slow to retrieve and the UI can choose to retrieve them differently.. Prepack can be started in different ways. e.g. the prepack command or node lib/prepack-cli.js.. should be a length check. will fix.. A container can also be an ObjectValue containing it's properties. I will add this as the next step.. waitForRun is called in the constructor where there is no ast yet.. The protocol has breakpoint requests always send a list of breakpoints, so even with one breakpoint, the UI will send a list and this change can handle it.. The frameId passed in from the UI can correspond to any of the contexts in the stack.. It works functionality wise and there are no flow errors. I will change it to use ES6 map to be consistent though.. Flow will complain when I remove this check.. I'm not sure. That was already there, I just fixed the lint issue.. This problem should happen in the current code. But strangely, I'm not able to reproduce it. Will look into it more.. There is a check in _isValidSteppingLocation for whether the current location is the same as the previously stopped location. If so, it will not stop again.. I will do this and the refactoring of marshallXXX in separate PRs to not make this one too big.. Changed.. This is already the case. I will add // Override here.. Should the different kind of steppers be held separately? If so, there can only be one step into stepper at a time.. This is to distinguish between line and column breakpoints. Line breakpoints will have breakpoint.column === 0. . If multiple steppers complete at the same time, we only need one reason in the end. Right now I make it the reason of the last stepper to complete. Should there be some logic to choose which reason to take?. I don't think it makes this assumption. The onDebuggeeStopped in each manager is called from the _onDebuggeeStopped method of DebugServer. This happens immediately before Prepack goes into a waiting state for any reason, so it does not make any assumptions on which order the managers were checked. If we would like to have some aggregation of the stopping, we can have each of the manager's onDebuggeeStopped methods return a result and the _onDebuggeeStopped in the DebugServer can be changed into a StopEventManager that joins these results.. I don't think there is a recursion here. This waitForRun call is inside checkForActions.. Stoppables is list of objects that the debuggee should stop on (breakpoints, completed steppers). Having at least one element means there is at least one reason for the debuggee to stop on this ast node. When the debuggee should stop, a reason is sent to the UI. When there are multiple reasons to stop, only one reason is needed. I currently choose this to be the reason of the first stoppable. I aggregate all the possible stoppables here so we can potentially do some more sophisticated logic to choose which reason to send.. Yes. checkForActions is only run nodes where the location is set. Otherwise it is skipped. See _checkAndUpdateLastExecuted in DebugServer for the check.. I will change this and move the channel call outside.. I have changed the name to getDebuggeeStopReason and have it return the reason or void. I have also moved the channel call outside.. Can you add comment listing out all the information you would like to display on the UI for nodes and edges. I will look into designing the UI so they can be display when they are available here.. I will change to autogenerate a temporary file in the next PR.. I will add this in separate PR.. It does not expect a StoppedEvent on entry of the debug adapter. The engine should be paused on entry but no event should be propagated to the UI. I will add a comment here.. ",
    "jas14": "FYI the stack overflow example provided in #985 shows \"Cannot read property 'forEach' of undefined\" instead of the desired \"Maximum stack depth exceeded\" -- that's coming from within prepack, not the REPL.... ",
    "jeysal": "I'll have a go at this.. @hermanventer By \"did the right thing\" you mean set the Error message to \"42\"?\nIf I understand prepack's test setup correctly, the return value of the inspect function from the original code is diffed with the return value of the inspect function from the prepacked code, right? Shouldn't that make sure that the message is the same?. Is yarn depcheck flaky? Failed on CI for some reason.... @NTillmann can we merge this or is there anything left to do on this one?. We need to keep some sort of default case / sanity check, else str would be possibly uninitialized at the end of the function.. Agreed, changing this.. ",
    "gustavderdrache": "Prepack will crash attempting to evaluate even this reduced case:\njs\nnew Proxy(function () {}, {});\nI found this trying to run this on a React code base that wasn't set to production. In dev mode,\n the SyntheticEvent class is proxied.. ",
    "M-ZubairAhmed": "Can I take this one ?. can I work on this one ?. ",
    "shuliuncsu": "@yinghuitan Updated, thank you.. It seems there are only two occurrences of this in properties.js and one occurrence in generator.js, while the rests have different logic. It may be better keep current way since it is more explicit.. ",
    "atav32": "Or just a link to https://github.com/gajus/prepack-webpack-plugin. ",
    "baptistemanson": "I think this issue is now resolved!. Hi all,\nI'm getting my feet wet on that task ;). \nHere is what I understood:\n- stdin is read by prepack-stdin only when there is no file provided as input\n- prepack-stdin still has logic to check sourcemaps that needs to be removed? Or do we want a user to be able to give sourcemaps as a flag when using stdin?\n- this logic is present only because prepack-stdin was copied and pasted from prepack-file\n- stdin unit tests never passed\nSo I think I have to:\n- remove the logic around reading sourcemaps in prepack-stdin\n- fix the unit tests\nAm I on the right tracks?\n. Thank you!\nI will make a PR.. I will give it a try.. Here is the point I reached.\nWith the input:\njs\n(function () {\n  __assumeDataProperty(global, \"unknownProperty\", 1);\n  })();\nprepack outputs:\n```js\n(function () {\n  var _$0 = this;\nvar 0 = $0;\nif (_0.unknownProperty !== 1) {\n    throw new Error(\"Prepack model invariant violation in ../notepad/test.js at (3:50): global.unknownProperty was expected to be equal to 1, got \" + _0.unknownProperty);\n  }\n}).call(this);\nwhich throws this error when executed:bash\nError: Prepack model invariant violation in ../notepad/test.js at (3:50): global.unknownProperty was expected to be equal to 1, got undefined\nI may have missed test cases: I only understood how to get this error via the __assumeDataProperty function. From what I can infer, we use it when we want to inform prepack that the context has some objects + properties already set (like the window object, require, it, should? not sure). Is there any other way to trigger the \"Model Invariant Violation\"?. Right now we emit Invariant with:js\nemitInvariant(\n    args: Array,\n    violationConditionFn: (Array) => BabelNodeExpression,\n    appendLastToInvariantFn?: BabelNodeExpression => BabelNodeExpression\n  )\n_emitInvariant_ doesn't know what is tested (injected violationConditionFn). It cannot throw helpful messages.\nIt seems there is only 3 different violationConditionFn: (typeof, !==, ===). \nI can either:js\n// specialize each invariant\nemitTypeofInvariant(node, type);\nemitEqualInvariant(node, valueNode);\nemitNotEqualInvariant(node, valueNode);\n// or delegate the help message as well\nemitInvariant(\n    args: Array,\n    violationConditionHelpMessage: string,\n    violationConditionFn: (Array) => BabelNodeExpression,\n    appendLastToInvariantFn?: BabelNodeExpression => BabelNodeExpression\n)\n```\nYour thoughts @cblappert ?. Sorry everybody for not being super responsive! I implemented a first version of it, let me rebase and clean up.. I will correct to remove the stack trace + failing test. Thank you for being patient with me!. - I manually reverted the prettier reformatting.\n- I ran prettier though on the test files\n- I inlined the syntax error file\n- I fixed the unit tests\nI sadly couldn't figure out how to make the difference between:\n- a FatalError due to a user input issue, like a syntax error and \n- a FatalError coming from prepack itself which would require the complete stack trace.\nSo the stack trace is still present, with stdin or with a filename.. Thank you @hermanventer you are very patient with me.\n- I undertand that I can catch at the highest level possible any \"FatalError\" .\n- I need to make sure that we always called handleError with a CompilerDiagnostic before each potential FatalError throw.\nI looked for a DEBUG flag/env var to bypass the catch, but couldn't find any yet.\nSo I thought I could check the status of errors[] array, and only catch if errors has at least one CompilerDiagnostic in it. What do you think?. I think it is ready for review now. Have a nice weekend!. Hi @hermanventer,\n- I split the unit tests in 2 checks: return signal and error message.\n- I decided to create a printDiagnostics function.\n- I deleted on purpose stderror, it was acting as a duplicate of echo \"{}()\" that you guys provided, and it triggers an error in most IDEs.\n\nI didn't double wrap try{}catch{}finally{} as you suggested, not that it was a bad idea ;). I just found the code readable enough when I introduced \"printDiagnostics\".. No time is wasted except yours! I grab those tasks to help me learn the codebase. Thanks for taking the time to answer me.. I just saw I forgot to set up my git username on this new laptop, I'll make a new PR. Sorry!. Prettier added it. I will manually correct it.. Yes.. Sure, I will separate it in two assertions, one for the message and one for the error.. \n",
    "rwaldron": "@hermanventer These tests don't fail when run in Node.js directly: \n$ test262-harness --hostType node --hostPath `which node` test/built-ins/Array/S15.4_A1.1_T10.js\nRan 2 tests\n2 passed\n0 failed. Is there a list of test files that trigger this? We need to fix those in test262!. ",
    "leobalter": "I'm expecting some feedback for this PR.\nIt works, but as said, it can use some further improvements. Any feedback will be really helpful to prioritize anything.\ncc @sebmarkbage . Sure thing. I was using the tests in a small subset of files and now I noticed the there is some uncaught timeout issue, perhaps.\nI'll push a fixed code soon.. it should pass on the lint and the flow check tasks.. @NTillmann I'm actually using only a subset of test files to run while I try to fix an unexpected memory leak if we run the tests against everything.\nYou can find the subset definition here: https://github.com/facebook/prepack/pull/1122/files#diff-4ebecfb92903473e83654d42ad5c892cR299\nThis line can be dropped out to run the tests for every folder.\nThis is a work in progress, I'm working on planned improvements, but due to it's size, I wanted to have it open as a PR here so we can apply any prioritization if necessary.. > Is there a way to exclude tests for errors that should be caught during parsing? For example all tests that expect syntax errors.\nI can add a filter for negative tests. I've been thinking if a separation for runtime or early errors in the negative flags in the yaml config file is fine to start:\nyaml\nnegative:\n  - runtime # filter all the runtime errors specified by the negative metadata flag \n  - early # filter all the tests for early errors\nWhat do you think? I'll push a patch for this today.. Ok, I pushed a custom arguments features with most of the features already present at the old test262-runner file.\nThe new commit bits are also using the negative filter for early errors.\nEverything is passing locally on the flow check and eslint processes. I need to wait a bit more for the CI results.\n. Running the tests locally: https://gist.github.com/leobalter/4ea72144711f597b34c30681fc447c89. I squashed and rebased the commits fixing a conflict in the yarn.lock file.. Please let me know if there is any other feedback for this work. When it's good to land I can fix the yarn.lock conflict, rebase and push it again.. > Unfortunately, this test runner in its current form has quite a way to go before it gets to feature parity with the existing test runner.\nWould you mind listing what is missing for for feature parity from your perspective? \nWhile I'm working to separate both runners, I'd be interested to support fully migrating to the new one only.. > Are you planning to do any more work on this?\nSure thing. We are finally past the TC39 meeting and I'm dedicating some time this week to work on this branch.. I squashed the previous commits and added f5f0a6a to fix the CI run. Tests are running just fine from my end and I believe the CI should be green anytime soon. \n\nUsing the updated version test/test262 causes the existing test runner to skip many more tests, hence the overall test fails because it still expect to run (and pass) many more tests. You can either update the expected number of passing tests, or use a separate directory for the updated test262.\n\nI just reused the same directory for Test262 to avoid any extra noise. Not only because of filters, I expect less es5id and es6id with time, as improved/refactored tests might not reuse them. Test262 could definitely have a better flag system for features added in specific edition or time, but those legacy tags are not the best to maintain on Test262.\n\nMeanwhile, I have some thoughts based on your feedback we can follow up, probably after this PR.\nWhile not faster, the new test262 has an easy way to define specific folders to run the tests. Using workers is definitely interesting for a development PoV. Getting faster results is really a nice to have feature.\nOne thing we could do is also work together to define and design the desired output for the runner. I'm sure some conversations would allow us to find what is humanly desirable for consuming a large set of test results.\nI'm totally game - if time allows me - to have a test runner iterating only over new or modified tests, as the results are already exported and we can reuse them. This should also be something under a flag (or a parameter) as new versions of Prepack would probably require a new run through all the tests.\n. This is not much clear for me as well. I reused most of the logic from the original text execution.\nhttps://github.com/facebook/prepack/blob/master/scripts/test262-runner.js#L994-L995\nMy plan is to first tackle the stream events but I was taking so long to do a better refactoring for the logics to understand the execution result. This is for sure a place for improvement, but as far as I can tell, this is some sort of test skip for early SyntaxErrors, does it sound right?. sure! We have the negative tags in the frontmatter metadata, and I'm using that to capture the filtering.\nWith the filter on I can work to improve this verification process for the execution results.. ",
    "simonhj": "Smaller test that exhibit same problem\n```javascript\nfunction f (x) {\n  var valueA = 0;\n  function c() {\n    x ? valueA++ : valueA += 2;\n    return valueA;\n  }\nreturn c;\n}\nvar s = f(true);\nvar r = f(false);\n``. Yeah on second thought it should be possible to run an inferior process without lazy. . Not sure I follow: How is this better than what happens currently, a generic crash (which might be what we want)?  . Agreed on testing. Any ideas on good corner cases to cover?. @hermanventer do you have a good idea for a testcase testing \"restore previous path condition\" part of this functionality?. Good catch, thanks. . Yes. I am not sure what the right thing to do here is.  I added the babel lowering to deal with test that use ES6 features like let and for-of loops, such they could still run in an es5 context. However some tests explicitly test ES6 features, such as symbols for intstance and testing them in es5 mode is pointless. Futhermore babel won't fix a test using the Symbol API for example. \nSo I ended up having both, but I am open to ideas.  . :+1:. Its a pretty common JS idiom to force string conversion (and actually faster than toString !). Why is it wasteful? Seems simpler to me, if you are dealing with an es5-only runtime and the majority of tests was not written with this mindset, lowering them to get rid of syntactical/semantics features seems the cleanest approach allowing you to still use the test. I only added the flag to deal with tests that can't be lowered properly. Would \"es6-only\" be a better name? . its a fair point. But your design requires me to go through all 700 or so tests and categorize all of them, which I would like to avoid :). . Yes. I am not saying it can't be done. I am just saying I think its a lot of work just to avoid some babel invocations. \nIf you feel strongly about it, I can do it. But it seems like a lot, for what we are trying achieve here. . Name not clear, did you mean \"augment\"?. IscreatedObjectsalways the empty set after widening. Naively I would expect it to be the union. . The typeArray<{ $Key: void | Value, $Value: void | Value }appears all over the place. A descriptive alias would help readability . Tricky control flow. If one is an array, the other must also be orundefined`? Deserves at least a comment. . When pattern matching I like to name all constituents, even if unused. Makes it clear that its not a typo. . Fair enough and while I agree that a SML type checker would catch such a typo, I am less convinced that JavaScript will. . So the empty set implies \"no information\" which in the context of an escape analysis means everything might escape?\n. Because they should always be equal right?. Is there a reason for the switch to the pattern-matching? Seems like overkill in this case . This is overly clever :), simply looping through with something like \njavascript\nfor (const scope of instance.scopeInstances) {\n //....\n}\nis more clear. . At least break out of the for-loop when a match is found. . Ahh, good catch. That fixes it. . -- heapGraphFile => --heapGraphFile. Since we are doing IO shouldn't there be some error checking?. Open to suggestions on this one. I don't understand why AbstractValue.createFromUnaryOp returns a  Value instead of an AbstractValue.. I see. Makes sense. Thanks. How so? JoinedAbruptCompletions has two AbruptCompletions as children, they cannot be PossibleNormal can they?. What does diagnostic mean in this context?. Would be easier to read if parts of the tuple was given names with pattern matching. . What is insideEffects here?. Does undefined mean that we cannot reach a fix point? \n. Matter of test, but I would be prefer callerSavedCompletion. Would it be possible to give F and f better names to differentiate them?. nit: maybe the word recursion should be in the error message. . I am a bit unclear what this represents. The current (possibly abstract) arguments for a given call site? . I see. It seemed F and f were two distinct things, but its just the placate the compiler, well, that is what it is. . Whats the intuition here? Are we guaranteed that only recursive function is currently being computed? . Is the todo still valid?. Why are we passing consequent as an explicit parameter if its contained in consequentEffects ? . It seems to me that it would simplify the diff somewhat if we can avoid this book keeping. . Whats the impetus for this change?. Spurious formatting edit?. A top-level comment indicating the purpose of the file would be nice :). Emit -> Emitting . Given the comment you should probably explain why you are increasing it :). Could be converted to a switch statement.. If possible add in assert for this. . nit: verbose often means debug output, but in this case it seems to mean \"dump code\". . newline. ",
    "prometheansacrifice": "@hermanventer  Is there a data structure somewhere that maintains a list of all Abstract values? I couldn't find (at the first look) one in createFromTemplate\nFull disclosure: this is my first time looking at internals of a Symbolic Evaluation engine :). @hermanventer I'm yet to add a test. Am I on the right path though?\nReason for lack of tests\nI couldn't find an example in the repo that used __abstract() to create abstract values from templates: all of what I saw provided typeName to __abstract().  This one instance where fs is modelled uses .createFromTemplate itself. Should the test be written using .createFromTemplate too?\nI'm not entirely familiar how tests are run. My understanding: put this test under serializer using a name like  createFromTemplate.js? And if so will a simple try/catch be okay? I couldn't find any assertion library. Did I miss it?\ntry {\n// create two abstract values with the same name and expect to catch it?\n} catch() {\n}. Create compile time error as in the following?\nlet loc = ast.object.loc;\n      let error = new CompilerDiagnostic(\"An abtract value with the same name exists\", loc, <errorCode>, \"FatalError\");\n      if (realm.handleError(error) === \"Fail\") throw new FatalError();\nI found the above pattern in a few places? Or just a throw new FatalError() would suffice?\nAlso, is there a way to run just this test file? The whole suite takes time and logs get buried.. > A FatalError is just a way to terminate Prepack when an unrecoverable error has been detected. In this case, you would first report the error and then throw a FatalError (regardless of what the handler told you to do).\nDone. Although I wasn't sure of the error code. Used the default (as seen here)PP0001. Whats the right one?\n\ntest-error-handler.js still lacks a way to filter the tests to run. Adding such a parameter should be easy enough (just follow the pattern in test-runner.js).\n\nMay I keep it for a separate PR? :) I'll use the trick locally until then.. Is PP1005 appropriate for this?\nI came up with the following for the wiki\nAn abtract value with the same name exists. All abstract values defined in the environment must have a unique name. Ensure that you have not used the same name in your `__abstract` or used one that is used internally by Prepack\nThe following part\n\nor used one that is used internally by Prepack\n\nGrepping the source, I couldn't find __abstract() calls. Nevertheless, will prepack ever call __abstract() internally (or use internal methods like how fs does). In case it does then such a list would have to conveniently exposed so that consumers don't use names used internally.\nIf it doesn't I guess I can just omit that part from the wiki. Sure. Is the following okay for the wiki? I'll update the wiki once the PR lands.\nPP0019\nAn abtract value with the same name exists.\nAll abstract values defined in the environment must have a unique name. Make sure that you have not used the same name for more than one abstract values.. What do the following comments, found at the top of the tests, mean?\n// additional functions\n// recover-from-errors\nShould they be present in my tests. A few serialiser tests are failing now. Should tests (like this one) that use same name for two different abstract values, be updated?. I need help figuring out why this test (additional-functions/modifiedobjects.js) fails.\nI noticed that those global mutations are missing in the prepacked code. Mutations to the global variable foo is missing which explains the output mismatch: [object Object]55[object Object]5undefined54243false instead of  [object Object]55[object Object]5undefined54443false\n```\nvar additional1, additional2;\n(function () {\n  var $$0_unique27277 = {\n    enumerable: false,\n    configurable: true,\n    writable: false\n  };\n  var $$1_unique27277 = {\n    enumerable: false,\n    configurable: true\n  };\nvar _$0_unique27277 = this;\nvar $1_unique27277 = $0_unique27277.Object;\n  var $2_unique27277 = $1_unique27277.defineProperty;\nvar $f_0_unique27277 = function () {\n    _0_unique27277 = 5;\n    _1_unique27277 = void 0;\n    x = 10;\n    // _3_unique27277.foo += 1 and foo += 1 not found\n    return void 0;\n  };\nvar $f_1_unique27277 = function () {\n    _2_unique27277 = 5;\n    y = 5;\n    return void 0;\n  };\nvar $f_2_unique27277 = function () {\n    return 43;\n  };\nvar $f_3_unique27277 = function () {\n    let z = _0_unique27277;\n    let x = _1_unique27277;\n    let y = _2_unique27277;\n_$0_unique27277.additional1();\n\nlet z2 = _0_unique27277;\n\n_$0_unique27277.additional2();\n\nreturn '' + z + z2 + x + y + _0_unique27277 + _1_unique27277 + _2_unique27277 + _$0_unique27277.foo + _$0_unique27277.bar + (_$0_unique27277.foo === _$0_unique27277.bar);\n\n};\nlet 0_unique27277 = {};\n  let _1_unique27277 = 5;\n  $0_unique27277.additional1 = $f_0_unique27277;\n  let 2_unique27277 = {};\n  $0_unique27277.additional2 = $f_1_unique27277;\n  var 3_unique27277 = $0_unique27277;\n  $$0_unique27277.value = 42, $2_unique27277(_3_unique27277, \"foo\", $$0_unique27277);\n  $$1_unique27277.get = $f_2_unique27277, $2_unique27277(_3_unique27277, \"bar\", $$1_unique27277);\n  inspect = $f_3_unique27277;\n}).call(this);\n``. Interesting. [modifiedobjects.js](https://github.com/facebook/prepack/blob/master/test/serializer/additional-functions/modifiedobjects.js) didn't fail on the CI.. After Irm -rfednode_modules` and installed things again and the above failing test passed. It can be ignored. All requested changes have been made. Ready for review \ud83d\ude04 . Appended PP0019 the list of diagnostics in the wiki.. > The tests are not about ToString, so their names are confusing.\nRename to HandleImplicitAbstractConversion.js. Too verbose?\n\nTo mark a test as expecting to fail, add \"// throws introspection error\" as the first line of the test.\n\nPR #1109 wants a fix where such abstract conversions are taken into account right? So tests shouldn't fail right? What am I missing?. This patch works. Is this good enough? Should I create and use a ToNumberOrAbstract instead?. But how can there be side effects? Evaluating a binary expression at computeBinary makes sure that operands are pure (not writing/reading to heap or throwing). What am I missing?. Maybe heres where I went wrong..? I thought you meant:\nImplicitAbstractConversionWithSideEffects.js\n```\nlet glob = 1;\nlet x = global.__abstract ? __abstract(\"number\", \"(3)\") : 3;\nlet ob =  { valueOf: () => {\n  glob += 1;\n  return x;\n}};\nlet ob2 =  { valueOf: () => {\n  glob += 1;\n  return 4;\n}};\nlet y = 123 * ob * ob2;\ninspect = function() { return y + ' ' + glob; }\n```. No problem. I'll update the PR soon.. After this commit (the one with custom error handler to handle prepack errors) I guess the only thing left to do is print the call stack.\nDoes this need a test? Can you please help me with it @hermanventer It looks like a test for something like this needs to be written in bash. Prepack currently doesn't support sourceType 'module.' \nRan the above code on master\nErrors found while prepacking\nIn input file src.js(1:1) FatalError PP1004: Syntax error: 'import' and 'export' may appear only with 'sourceType: \"module\"' (1:0) (https://github.com/facebook/prepack/wiki/PP1004)\nSo ES6 modules cannot be directly prepacked. Try transpiling it down to a bundle format for the browser.\nFor example, I bundled it to iife using rollup and got this prepacked code. Removed WIP so that I can get some feedback on this PR.\nWhen running the error handler tests, amidst the logs I saw this,\ntest/error-handler/call2.js                        \ntest/error-handler/class.js                        \nUnexpected error: serialized 7 of 8                \ntest/error-handler/conditional-return.js           \ntest/error-handler/forInStatement.js               \ntest/error-handler/forOfStatement.js\nBut the results of the test said 36/36 100%. Is this why the CI is normal? This doesn't happen on master. I'm not able to figure which test is failing either.. I do. I want to take another shot this weekend. Hope it's okay.\nOn Wed, Feb 7, 2018, 3:09 AM Herman Venter notifications@github.com wrote:\n\nAny intention to come back to this?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/prepack/pull/1314#issuecomment-363573489,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AC9BumLPztCrn2lOGh0ET0ppPgRKzSwdks5tSMaVgaJpZM4RUprz\n.\n. @hermanventer I had trouble with == and !=: AbstractEqualityComparison returns a boolean, but I needed to return an AbstractValue\n\nL245 in ./methods/abstract.js,\nIdea was to change\nif ((x instanceof StringValue || x instanceof NumberValue || x instanceof SymbolValue) && y instanceof ObjectValue) {\n    return AbstractEqualityComparison(realm, x, To.ToPrimitive(realm, y));\n  }\nto\nif ((x instanceof StringValue || x instanceof NumberValue || x instanceof SymbolValue) && y instanceof ObjectValue) {\n    const py = To.ToPrimitiveOrAbstract(realm, y);\n    if (py instanceof AbstractValue) {\n       return AbstractValue.createFromBinaryOp(realm, op, x, py);\n    }\n    return AbstractEqualityComparison(realm, x, py);\n  }. > It seems that the only places that call AbstractEqualityComparison would be happy to get a Value rather than a boolean.\nMaking the change an updating the PR.. @hermanventer It hasn't. I'm sorry I should have marked it WIP. . @hermanventer Added support for != and ==. Removed the invariant and made op param mandatory too.. @hermanventer Can you please take a look at the PR again? Sorry for disappearing for so long. I think the coverage has increased 2% in the ValuesDomain file now.. Thank you so much :) The wiki was exactly what I had in mind. I'll close this issue for now re-open it if I feel the need for more material.. Fair point. Or a section in the ReadMe.md itself pointing to the Wiki?. Now that the Readme points to the wiki, I think we can close this - at least for now. Feel free to reopen this if there is a need.. I'm unsure about certain invariants I had to add. Added Seems necessary. Flow complained too. comment next to them. . Can I get some help on writing tests? I did refer to the ClassDeclaration PR but realised that file has changed a lot.. @sebmarkbage \n\nWe just need to upgrade test262 to include the new tests that covers spread.\n\nHow do I do that? Update the git submodule to a newer commit?\n\nHowever, a good follow up in a future PR would be to add abstract interpreter support. In its current \nstate, it'll throw when the keys are unknown.\nYou can look at how Object.assign is implemented to figure out how.\u00a0https://github.com/facebook/prepack/blob/master/src/intrinsics/ecma262/Object.js#L64-L169\nThat would require tests and you can look in\u00a0test/serializer/abstract\u00a0and look for tests starting with\u00a0ObjectAssign\u00a0or\u00a0object-assign.\n\nThank you. This really helps. I\u2019ll follow it in the immediate next PR.\n\nYou could add the new canonical name\u00a0sec-copydataproperties\u00a0if you want.\n\nI\u2019m not familiar with canonical names. I named it // ECMA262 7.3.23 (sec-copydataproperties) is that okay?\nOne more thing.\nThe following ran fine on Node but failed here.\njs\nvar obj3 = { ...(obj = { a: 1, b: 2 }), x: 1 };\nobj = { a: 1, b: 2 } this should have been covered by \u2026AssignmentExpression? Did I miss something? Or is this not covered in the spec?. Flow keeps crashing with Flow_error.EMergeTimeout(105.016726017) on my mac. There already is an open issue. @hermanventer Can I please get some help with test262 tests? I'm not able to figure out which tests are failing because of this PR. I did spot some destructuring related failures earlier. Fixed them.. @trueadm All tests pass :). @NTillmann Is this close to what you have in mind?\nFor the following\n```js\nconst a = __abstract('number', '(a)');\nconst x = 6;\nconst y = x * 2;\nresult = a + x + y;\n__residual('boolean', function(result, console, __describe) {\n  console.log(__describe(result));\n  return true;\n}, result, console, __describe);\n```\nI saw\n[abstract], kind: +, hash: 1882435125\n12, hash: 120000000\n[abstract], kind: +, hash: 721776267\n6, hash: 60000000\n[abstract], kind: template:abstract:(a), hash: 83680053, intrinsic name: (a)\nSeems a bit too verbose. Does it help?. Reason for disabling eslint: a snippet with class expression was failing the serialiser tests. I had to disable eslint for the block to fix ClassExpression2.js. Serialized output\n```js\n(function () {\n  var _$0 = this;\nvar __constructor = function () {};\nvar _3 = class extends _6 {\n    constructor() {\n      super();\n      this.y = 10;\n    }\nmethod(z) {\n  return this.x + this.y + z;\n}\n\n};\nvar _6 = class {\n    constructor() {\n      this.x = 10;\n    }\nmethod(y) {\n  return this.x + y;\n}\n\n};\nvar _0 = (__constructor.prototype = _3.prototype, new __constructor());\n0.x = 10;\n  _0.y = 10;\n  $0.a = _0;\n}).call(global);\n```\nThe derived class is getting hoisted for some reason.. > Can you add a test has an inspect function with a Promise returning from it?\nBut it wouldn't serialize properly.\n\nAlso, does the test runner wait until each async test has resolved before continuing to the next test?\n\nYes, the next test is run only after the current test's promise is resolved.. @trueadm \nSerialized output for the snippet you posted\n```js\nvar fn;\n(function () {\n  var _$0 = this;\nvar _0 = function (resolve) {\n    setTimeout(function () {\n      resolve(6);\n    }, 100);\n  };\nvar _1 = function () {\n    return new Promise(fn);\n  };\n$0.fn = _0;\n  $0.inspect = _1;\n}).call(this);\n```\nOn the other hand, the following fails due to incomplete implementation of Promises\n```js\nvar promise = Promise.resolve(3).then(val => val + 2);\ninspect = function() {\n  return promise;\n}\n```. @NTillmann Are the two serialisers going to merge sometime in future? Coming from a contributor's perspective, what changes can we expect in the current serialiser?. Hey, thanks.\nJust realised tests would let me push just silly patches. Can you help me there? Refer comment. Then, how would _abstractValuesDefined be updated and maintained?. Did you mean to rewrite it in such a away that it stores only names of abstract values? . I understand now. I just saw your other comment about the else case. . This has been fixed in a later commit\nApologies for the confusion. I guess I should squash such commits together. I tend to keep certain  commits unsquashed so that the reviewer can see how things changed. While I understand keyed collections like Sets are supposed to use sublinear access times, Set still does a linear lookup of entries: spec section. Am I misinterpreting it?\nI had initially used a simple object as a lookup table to do better than O(n).. My bad. Will fix it.. Is this because only global code (or code that runs during initialisation phase) get prepacked, as explained in the note below Module Initialization section on the landing page?\nIf thats right, these test files are nothing but small standalone programs that are getting prepacked themselves with certain comments a like acting like assertions? Is inspect analogous to __residual?. Okay. I'll use the Sets approach immediately once all tests pass. On my TODO.. I was not sure of touching ./intrinsics/ecma262/ArrayPrototype.js\nhttps://github.com/facebook/prepack/blob/master/src/intrinsics/ecma262/ArrayPrototype.js#L1353-L1354\nhttps://github.com/facebook/prepack/blob/master/src/intrinsics/ecma262/ArrayPrototype.js#L1357-L1358\nIs it okay update the call over there?. ",
    "lukas1994": "updated the commit description\nready to merge?. where is the description of the PR? I updated the first 'comment'. Can I merge this?. mhh not sure if that's a good idea\nwhat if someone adds stuff after this if block?. Mhh, but we need to know the name of the scope somehow - regexes are not supported right now I think.\nThe 27277 seems to hard coded in the tester script anyway:\n\n. For copies of I need at least one match though, so copies of __scope_2, __scope_2:0 doesn't work and copies of __scope_2:17 is also kinda confusing.. We would need // Copies of __scope_2:6 but then this test could easily break when someone changes the code generation.\n```javascript\nfunction f (x) {\n  var valueA = 0;\n  function c() {\n    x ? valueA++ : valueA += 2;\n    return valueA;\n  }\nreturn c;\n}\nvar s = f(true);\nvar r = f(false);\n```. ",
    "j-nolan": "Thanks for reviewing!\nTo avoid storing dependencies on the repo, one idea would be to refactor the site as an app with a proper package.json and dev/build scripts. That's how Relay and Jest do it in their website/ directories. And they   store markdown doc files in a separate docs/ directory.\n. Hello,\n\nI am not so experienced in bash scripting but is it possible to not store prepack.min.js and just generate it for gh-pages?\n\nYes, that would be possible and would avoid redundancy. We would just have to add a build step in the \"How to edit the website\" section of the README but I think it's a reasonable tradeoff.\nGood point about loading from CDNs. Tether as a version available on cloudflare. Can't find one for select.js though.. Following suggestions by @artiebits I amended my PR as follows: \n- Don't store prepack.min.js on repo, ask collaborators to build it from sources\n- Load tether and tether-select from CDN instead of storing the bundles in the repo\nI also renamed docs/ to website/ to make it clear that it contains the website rather than the raw documentation.\nAdditional notes:\n- I noticed the CDN served a slightly different version of select-dark-theme.css. In fact, the only difference is that a single rule was added. I don't know what that rule used to fix but I suspect it's not needed anymore. Perhaps @sheweichun could confirm?\n- I checked if we could also load prism.js from CDN. Since it's a custom build, and I didn't find a CDN that provided that same custom build (clike + javascript), I left it in the repo. But I believe 11KB is still reasonable\n@NTillmann what do you think of that new version?. Looks good to me.\nFor some reason I have small UI bugs on the current version of prepack.io:\n\n\nBut when I try this PR locally everything works fine so let's land it and see if it fixes the production website.\nI'll leave someone from the prepack team approve the PR. @hermanventer or @NTillmann?. ",
    "gaearon": "Is there any way to do a feature check instead? It\u2019s not obvious to me that JSC lacks symbols. And that may change in the future. . Do you generally add regression tests for cases like this? As I understand this fixes an infinite loop, would be nice to ensure we don't break again.. We could, but is it worth figuring out why the current version breaks?. Regardless of what the polyfill does or doesn't do, isn't Prepack emitting variable access for undeclared variables always a bug? I don't understand how valid JS code (app code + polyfill code), even if buggy, can result in broken JS output (undeclared variables).. >The function is missing the arguments props, context from React.Component. So that seems like a bug here (but that should be probably be made a separate issue rather than tagged to this one).\nMakes sense, thanks. Yeah I wasn't saying it's related to this issue in particular, I just wanted to point out this seems like a bug in Prepack regardless of this implementation.. Ah okay I didn't realize that. I do wish we had a way to track that in tests though. E.g.\njs\n// react-optimized-trees 3\nOtherwise we don't even know if these optimizations turn on or not.. Sounds good to me. AFAIK this currently breaks my compiled bundle. I'll try to come up with a test case so we can fix that before landing.. Here's a minimal example.\njs\n(function() {\n  function App() {}\n  App.prototype.hi = function() {};\n  global.WrappedApp = require(\"RelayModern\").createFragmentContainer(App);\n})();\nIt compiles (with a \"recoverable error\" about leaking) before this change but doesn't compile anymore.. I'm chatting to @sebmarkbage, he suggested replacing that invariant with a break and then adding Array to the whitelist of \"kind\" switch cases that just return (that's the next error caused by this diff for UFI bundle).. After fixing those two cases I hit an invariant here: https://github.com/facebook/prepack/blob/a39eff31dd5bd179b47122fbaf1f97f09f669e44/src/serializer/ResidualHeapSerializer.js#L1486. Yeah. I haven\u2019t had time to rebase/update yet. If you wanna do it, go for it. I\u2019ll be back in a few hours. . Per out of band conversation we decided that the leak logic probably works as intended. We just need to replace prepack invariant we're hitting with a better fatal error.. Curiously, after pre-processing the Prepack input with that Babel plugin we discussed, everything already works out of the box. Can you explain more about which problems this PR is solving?. Somewhat related comment from @sebmarkbage:\n\nWe should also treat that whole scope and the global object as partial so that we treat any unknown global as abstract by default.\n\nCould you also address as a part of that?. >everything already works out of the box\nTaking this back. I probably did something wrong, because now Prepack complains about unexpected globals on master (which makes sense).. Another request from @sebmarkbage: it would be nice if instead of installing all these special cases manually, we created a file with __abstract calls, and evaluated it in www env. Just like we do in RN to model their stuff.. >To prevent extra serialization bloat, kind = \"resolved\" is used on some objects.\nCan you expand on that? What else uses this property? What kind of bloat does it prevent? When is it safe to do?. I think the main \"problem\" that inspired this PR is that createFragmentContainer(Something) \"leaks\" Something. It's not clear to me if that's by design or not, and whether we'd have to work around this when we get to the render path. It seems like something that would come up with HOCs a lot.\nI still need more time to understand the cases here and in which case something would be \"safe\" or not. Still developing the mental model. This particular PR doesn't unblock any work immediately.. I think a good first step will be to extract tiny scenarios in which a particular escape affects a particular future rendering path. And discuss them on case by case basis.. This doesn't work:\n```js\nvar React = require('react');\n// the JSX transform converts to React, so we need to add it back in\nthis['React'] = React;\nfunction FactoryComponent(props) {\n    return {\n        render() {\n            return {props.title};\n        },\n    }\n}\nfunction App(props) {\n  return Hello, ;\n}\nApp.getTrials = function(renderer, Root) {\n    renderer.update();\n    return [['render simple factory classes', renderer.toJSON()]];\n};\nif (this.__registerReactComponentRoot) {\n  __registerReactComponentRoot(App);\n}\nmodule.exports = App;\n```\nIt works in React, but here it fails because {render} is not a valid React element that can be inlined. Is that what your TODO is referencing? I think we should fix that before merging as it seems pretty essential to considering this pattern working.. We'll probably want some tests too so we don't regress on this.. >I added tests to this. Well modified existing as per feedback\nHmm I don\u2019t see, did you push?. Is there any way we can tweak the test that would ensure the output is actually the same as we expect? For example cx() didn't throw before with multiple arguments, it just silently emitted one argument. It would be nice to verify it works as intended.. I think that if we use a private API then we need a test that will fail when that API no longer works. Just verifying the output once is not enough. In general, this seems to be a crucial part of www-specific mocks so I do think a test that checks the output is necessary. . Can we add tests for state preservation when switching between Fragments and arrays? See tests added as part of merging Fragment export.. Here is a test that still produces Symbol.for in the output. Is that expected?\n```js\nvar Stateful = (function (superclass) {\n  function Stateful () {\n    superclass.apply(this, arguments);\n    this.state = { updated: false };\n  }\nif ( superclass ) {\n    Stateful.proto = superclass;\n  }\n  Stateful.prototype = Object.create( superclass && superclass.prototype );\n  Stateful.prototype.constructor = Stateful;\n  Stateful.prototype.componentWillReceiveProps = function componentWillReceiveProps() {\n    this.setState({ updated: true });\n  }\n  Stateful.prototype.render = function render () {\n    return (\n      \n        {this.props.children}\n        (is update: {String(this.state.updated)})\n      \n    );\n  };\nreturn Stateful;\n}(React.Component));\nfunction Stateless(props) {\n  return {props.children};\n}\nfunction App(props) {\n  if (props.switch) {\n    return (\n      \nHi\n\n    );\n  }\n  return [\n    Bye\n  ];\n}\n```. Here is a full test:\n```js\nvar React = require('react');\n// the JSX transform converts to React, so we need to add it back in\nthis['React'] = React;\nvar Stateful = (function (superclass) {\n  function Stateful () {\n    superclass.apply(this, arguments);\n    this.state = { updated: false };\n  }\nif ( superclass ) {\n    Stateful.proto = superclass;\n  }\n  Stateful.prototype = Object.create( superclass && superclass.prototype );\n  Stateful.prototype.constructor = Stateful;\n  Stateful.prototype.componentWillReceiveProps = function componentWillReceiveProps() {\n    this.setState({ updated: true });\n  }\n  Stateful.prototype.render = function render () {\n    return (\n      \n        {this.props.children}\n        (is update: {String(this.state.updated)})\n      \n    );\n  };\nreturn Stateful;\n}(React.Component));\nfunction Stateless(props) {\n  return {props.children};\n}\nfunction App(props) {\n  if (props.switch) {\n    return (\n      \nHi\n\n    );\n  }\n  return [\n    Bye\n  ];\n}\nApp.getTrials = function(renderer, Root) {\n  let results = [];\n  renderer.update();\n  results.push(['mount', renderer.toJSON()]);\nrenderer.update();\n  results.push(['update with same type', renderer.toJSON()]);\nrenderer.update();\n  results.push(['update with different type', renderer.toJSON()]);\nrenderer.update();\n  results.push(['update with same type (again)', renderer.toJSON()]);\nrenderer.update();\n  results.push(['update with different type (again)', renderer.toJSON()]);\n  return results;\n};\nif (this.__registerReactComponentRoot) {\n  __registerReactComponentRoot(App);\n}\nmodule.exports = App;\n```\nHere is a part of compiledCode that looks odd to me:\n```js\n      var $g = $c.Symbol;\n      var $h = $g.for;\n  // ...\n\n    var _7 = _D(_$h(\"react.fragment\"), null, _c);\n\n``. Please fix the test description before landing: https://github.com/facebook/prepack/pull/1413#discussion_r167058851. Let's rebase this on top of https://github.com/facebook/prepack/pull/1422 when it lands.. My guess is that since it's a named function, Prepack erroneously thinks it's supposed to be in the global scope. Maybe it doesn't understand \"where\" the scope is when inside React JSX attributes?. Tagging as [WIP] since it's just a failing test. We'd still appreciate if you could look into this. :-). I pushed a second commit that shows the same problem withextends(and different test output \u2014 ?!), and a third case withdelete` (which currently fatals). All of these are common patterns and at least should skip to \"find\" the next subtree.. I put it up as a PR mostly so:\n\nBoth me and @trueadm see it as an outstanding TODO (we'd have to explicitly list branches somewhere)\n@trueadm can push commits to start fixing this when he finds time\n\nWe do that (push a failing test as a PR) quite often in React repo.\nIf you prefer those not to clutter the open PR view I understand and can close this.. > Unfortunately, neither an invariant or FatalError gets thrown. Instead it returns a broken object literal.\nIt seems like the right fix would be to figure out where the assumptions start to break down (which causes a bad literal to be emitted). Then throw a FatalError there. And now #1361 would be sufficient.. https://prepack.io/repl.html#G4QwTgBA9gRgVhAvBA5gG1iNA6A+rkGAZwBcwQBjEiAMhtQxiz1wFsQBrAUwAVwSAllggB+CPnbc+YQVgAU+QqXJU5AbwC+AGggAiWHF0BKIxABcETQG4AUKEgUoABwCeAeQBmb+Egje4XFTYIEREAigAdura0PBGtjbomDgAHr6Orp7+VkA\nThis serializes to x = {} but should be x = obj x = Object.assign({}, obj).\nThat's not the case where it fails though. It's the case where it emits bad output.\n@trueadm Can you recall how to re-create the case that threw the invariant?. Can you verify this doesn't break the UFI bundle?. OK, I'll read it again within an hour and then ping you back.\nI'd still feel better if you could run it at least on some tiny app.. This works on master but gives different output on this branch.\n```js\nvar React = require('react');\nthis['React'] = React;\nfunction App(props) {\n  var divProps = {};\n  Object.defineProperty(divProps, 'className', {\n    get() {\n      return 'hi';\n    }\n  })\n  return ;\n}\nApp.getTrials = function(renderer, Root) {\n  renderer.update();\n  return [['simple render with jsx spread 4', renderer.toJSON()]];\n};\nif (this.__registerReactComponentRoot) {\n  __registerReactComponentRoot(App);\n}\nmodule.exports = App;\n```\nSeems like this is because createElement uses for...in which skips non-enumerable properties.\nThis probably means that in all cases other than spread-less JSX like <Foo x={1} y={2} /> we actually need to filter out non-enumerable and non-own properties. Only spread-less JSX is safe because user had no control over the passed objects.. This test throws an invariant with JSX input but works with createElement input.\n```js\nvar React = require('react');\nthis['React'] = React;\nfunction App(props) {\n  return ;\n}\nApp.getTrials = function(renderer, Root) {\n  renderer.update();\n  return [['simple render with jsx spread 6', renderer.toJSON()]];\n};\nif (this.__registerReactComponentRoot) {\n  __registerReactComponentRoot(App);\n}\nmodule.exports = App;\n```. I don't think this is safe.\nConsider this outside (non-Prepacked) code:\n```js\n// This runs outside of Prepack\nwindow.GOOD = {};\nwindow.doSomethingBad = function() {\n  Object.defineProperty(window.supposedlySimple, 'foo', {\n    enumerable: true,\n    get() {\n      window.mutatedOutside.mutatedField = true;\n    }\n  });\n}\n```\nand this Prepackable code:\n```js\n(function() {\n  var mutatedOutside = {};\n  window.mutatedOutside = mutatedOutside;\nvar obj = typeof __makePartial !== 'undefined' ? __makeSimple(__makePartial(__abstract({}, \"window.GOOD\"))) : window.GOOD;\n  var supposedlySimple = Object.assign({}, obj);\n  window.supposedlySimple = supposedlySimple;\nvar doSomethingBad = typeof __abstract !== 'undefined' ? __abstract('function', 'window.doSomethingBad') : window.doSomethingBad;\n  doSomethingBad();\nObject.assign({}, supposedlySimple);\nif (mutatedOutside.mutatedField) {\n    window.answer = 'no way'\n  } else {\n    window.answer = 'okay'\n  }\n})();\n```\nI run it with:\nnode ./lib/prepack-cli.js --simpleClosures --omitInvariants --debugNames --compatibility browser ~/Desktop/input.js\nOn master, this fails at compile time. In this branch, it introduces a deviation in behavior between Prepacked and non-Prepacked versions (Prepack says answer is 'okay' but the original code says it's 'no way').\nMy understanding is this happens because we \"claimed\" the return value of Object.assign (supposedlySimple in this example) is simple. This marks it as such for its whole lifetime. But we don't actually have any guarantee that this will be the case. If some external code puts a getter onto it, we can't assume this anymore. To reproduce, I put a getter onto it from the external code, and then ran another Object.assign to trick Prepack into believing it's safe to ignore that getter.\nI'm not sure I'm right in the conclusion (that it shouldn't be supported), but this is definitely a regression. Maybe there's some stronger set of guarantees we need to put elsewhere.\nI think the above is also the reason Prepack codebase doesn't do .makeSimple() in almost any other places.. Yeah, tbh I'm pretty confused about the guarantees Prepack already assumes.\nThis has the same issue on master:\n```js\n/*\n  // This runs outside of Prepack\nwindow.doSomethingBad = function() {\n    window.mutatedOutside.mutatedField = true;\n  }\n*/\n(function() {\n    var mutatedOutside = {};\n    window.mutatedOutside = mutatedOutside;\nvar doSomethingBad = typeof __abstract !== 'undefined' ? __abstract('function', 'window.doSomethingBad') : window.doSomethingBad;\ndoSomethingBad();\n\nif (mutatedOutside.mutatedField) {\n  window.answer = 'no way'\n} else {\n  window.answer = 'okay'\n}\n\n})();\n```\nI'll file a new issue to ask about this.. I think this contradicts that:\n\nWe already have leaking logic that tracks some of these cases. If call(arg) leaks arg, so should global.arg = arg, no?\nThe fact that you can call an abstract function in the first place.\n\nI'll file a new issue to discuss.. https://github.com/facebook/prepack/issues/1454. This case hits an invariant now. It used to be a recoverable error. Is this expected?\njs\n(function() {\n  __evaluatePureFunction(() => {\n    var obj = typeof __makePartial !== 'undefined' ? __makeSimple(__makePartial(__abstract({}, \"window.GOOD\"))) : window.GOOD;\n    var supposedlySimple = Object.assign({}, obj);\n    var doSomethingBad = typeof __abstract !== 'undefined' ? __abstract('function', 'window.doSomethingBad') : window.doSomethingBad;\n    doSomethingBad(supposedlySimple);\n    Object.assign({}, supposedlySimple);\n  });\n})();. Not necessarily React-specific, just abstractEffectsInAdditionalFunctions-specific? Maybe this would be an appropriate place for a standalone test then? https://github.com/facebook/prepack/tree/master/test/serializer/pure-functions. Yep, I will.. I found a weird case that this PR \"fixes\". I don't understand why.\n```js\nvar React = require('react');\nthis['React'] = React;\nfunction App(props) {\n  var copyOfProps = {};\n  var copyOfProps2 = {};\n  Object.assign(copyOfProps, props, {x: 20});\n  Object.assign(copyOfProps2, copyOfProps);\n  return copyOfProps2.x;\n}\nApp.getTrials = function(renderer, Root) {\n  renderer.update();\n  return [['simple render with object assign', renderer.toJSON()]];\n};\nif (this.__registerReactComponentRoot) {\n  __registerReactComponentRoot(App);\n}\nmodule.exports = App;\n```\nWithout this PR, this gives different output (10 vs 20). This is worrying me.. @hermanventer\nCan you please provide more details? The reason I need this fix is they\u2019re already not quite orthogonal.\nisSimpleObject() returns true for a known object (because it enumerates the properties). But as soon as I make it partial, isSimpleObject() starts returning false (because now it looks at the flag). So changing one already changes the other.\nIn my case I need to make an object partial without un-making it simple (if it was already simple). The crux of the issue is that simplicity is calculated differently for partial and non-partial object. . @hermanventer Is this change sufficient?. Do you think this means https://github.com/facebook/prepack/pull/1456 is the wrong/dangerous fix?\nSomething was calculated-simple, then we called Object.assign with it as a target, then it becomes partial and flagged-simple, then we put a property on it. Now it's wrongly tagged as simple.\nI'm struggling to come up with a scenario where this matters. Can you give me some example where assuming an object is simple (but it's not) actually introduces a bug?. >I do, however, think that any attempt to modify an object, which has the __isSimple flag set, in way that will invalidate the flag, should result in a compilation error.\nDoesn't this mean that, combined with #1456, this should be a compile error?\n```js\nvar obj = global.__abstract && global.__makePartial && global.__makeSimple ? __makeSimple(__makePartial(__abstract({}, \"({foo:1})\"))) : {foo:1};\nvar x = {};\nObject.assign(x, obj); // will mark x as flagged-simple\nObject.defineProperty(x, 'foo', { get() {} });\n```\nI think it's pretty unintuitive that calling Object.assign on something forbids defining properties on it later. Although it might not be that common of a pattern so it's probably not a blocker for us.\nWhat do you think?. Superseded by https://github.com/facebook/prepack/pull/1459. Does it make sense to you that this fixes\njs\nvar copyOfObj = Object.assign({}, obj, {foo: 2});\nbut we hit a fatal if we try\njs\nvar copyOfObj = Object.assign({}, obj, {foo: 2}, {foo: 3});\ninstead?\nDoes this mean in practice we'll get at most one non-partial after the first partial?. This PR is as far as I can get with the current assumptions but I think the next PR shows these assumptions were flawed (and the existing test I was trying to keep passing was showing an unsafe situation that should\u2019ve fataled).. Oops, I thought about a wrong PR.\nHere\u2019s how I\u2019d explain it: this PR, then https://github.com/facebook/prepack/issues/1460, and then https://github.com/facebook/prepack/pull/1468 fix progressively more cases. But the last one also demonstrates that some assumptions weren\u2019t right, and thus fixing them requires breaking an existing test case. . Superseded by https://github.com/facebook/prepack/pull/1468. I think you\u2019re right. If all arguments are known we shouldn\u2019t need to leak.. I pushed a commit that doesn't leak the target. I'm not sure it's necessary to do given the other bailouts we already have. Even if it is necessary, it probably needs a separate discussion because it makes ObjectAssign.js test fatal, and that code is presumably coming from RN.. I pushed another update to this that leaks the target too.\nAt first I thought that we can't do this without causing this test to fatal. And that test seemed important for RN startup sequence since it looks like a copy-paste from there.\nHowever, after a rebase, my change in https://github.com/facebook/prepack/pull/1456 seems sufficient for running that code now, even though both target and sources are marked as leaked now.. @hermanventer \nTo address a comment collapsed by GH:\n\n\"Leaking\" the value seems a bit bizarre. The real issue here is that nextSource is referenced in temporal expression and there needs to be complete and unchanging at that point in time. I guess the overall mechanism is the right one, but the name is misleading.\n\nThis is exactly right. I agree the naming doesn't make much sense here. My mental model is something like \"become abstract\" or \"become unknowable\" from that point in time. Happy to rename it if you're happy with some other term.. >I am still not sure that the target needs to leak. Please explain why in a comment.\nI am not sure myself. My justification is I'd err on the safe side (since this issue already causes bad output on master) and if that's not right, the burden of proof is on whoever changes it back. But I realize this might be asking too much.\nIf it is, I am happy to revert \"leaking\" the target for now.. Pushed a change that doesn't leak the target. Without a test case it's all voodoo anyway.. @hermanventer I think \"blackboxing\" is the most natural analogy I can find.. This fix is definitely insufficient. I have a new test that shows it (and offers another approach) in https://github.com/facebook/prepack/pull/1468.. Superseded by https://github.com/facebook/prepack/pull/1468. The above two cases are outlawed (except for the pure mode) in https://github.com/facebook/prepack/pull/1460 by using the leak infrastructure. It's probably not the best solution but I added enough tests that we should catch this again if we undo my fix in favor of some other fix.\nWhile looking at it, I noticed another case that currently gives output mismatch, even with my leaking PR:\n```js\n// abstract effects\nvar __evaluatePureFunction = this.__evaluatePureFunction || (f => f());\nvar obj = global.__abstract && global.__makePartial && global.__makeSimple ? __makeSimple(__makePartial(__abstract({}, \"({foo:1})\"))) : {foo:1};\nvar x;\n__evaluatePureFunction(() => {\n  x = {};\n  var y = {};\n  Object.assign(x, obj, y, {bar: 2});\n  y.foo = 2;\n});\ninspect = function() {\n  return JSON.stringify(x);\n}\n```\nThe property order ends up being different. My leaking PR outlaws this in impure mode, but in the pure mode I still encounter this issue (which I wouldn't expect to). Means something else is wrong.. Here is yet another case that's broken on master and in all my PRs \ud83d\ude1e \n```js\nvar obj = global.__abstract && global.__makePartial && global.__makeSimple ? __makeSimple(__makePartial(__abstract({}, \"({foo:1})\"))) : {foo:1};\nvar copyOfObj = Object.assign({}, obj);\nvar copyOfCopyOfObj = Object.assign({}, copyOfObj);\ncopyOfObj.x = 10;\ninspect = function() {\n  return JSON.stringify(copyOfCopyOfObj);\n}\n```. Here is a simpler one, also broken both on master and in my PRs:\n```js\nvar obj = global.__abstract && global.__makePartial && global.__makeSimple ? __makeSimple(__makePartial(__abstract({}, \"({foo:1})\"))) : {foo:1};\nvar copyOfObj = {};\nObject.assign(copyOfObj, obj);\ncopyOfObj.x = 10;\ninspect = function() {\n  return JSON.stringify(copyOfObj);\n}\n```. Here's another one, broken everywhere:\n```js\nvar obj = global.__abstract && global.__makePartial && global.__makeSimple ? __makeSimple(__makePartial(__abstract({foo: __abstract('number')}, \"({foo:1})\"))) : {foo:1};\nvar copyOfObj = {};\nObject.assign(copyOfObj, obj);\ncopyOfObj.foo = 2;\ninspect = function() {\n  return JSON.stringify(copyOfObj);\n}\n```\nThis shows that even if we reverted https://github.com/facebook/prepack/commit/de01669c5d71d62e8ad91f8f0a7287519635d14a, we'd still have this problem for known fields.. >In a pure wrapper we can safely proceed with this.\nCan you explain your reasoning behind this?\nI understand both things are called \"pure\" but I'm not sure they refer to the same concept and are necessarily safe.\nThe definition of purity in this file:\nhttps://github.com/trueadm/prepack/blob/e007604a6358b9195c7ea93ef3648916d068921d/src/evaluators/BinaryExpression.js#L51\n\n(terminates, does not throw exception, does not read or write heap)\n\nCan you explain why neither of those cases is relevant in pure scope?. Sebastian suggested we should be more specific than that. It\u2019s not necessary to always leak everything.\nInstead we should look at specific operators (+, -, typeof, etc) and see in which cases they would call into user code. Such as + calling valueOf. Then leak the specific thing we need to leak just before it happens. . This PR doesn't contain a serializer test. I would prefer if future changes like this did because if there is some edge case we need to handle, it's not obvious which React test I should be looking at. It is also likely that we'll replace React tests more often and lose coverage for this.\nI tried to start by adding a very simple serializer test:\n```js\n// additional functions\n// abstract effects\nlet obj1 = global.__abstract ? __abstract('object', '({foo: {valueOf() { return 42; }}})') : {foo: {valueOf() { return 42; }}};\nlet obj2 = global.__abstract ? __abstract('object', '({foo: {bar: {valueOf() { return 42; }}}})') : {foo: {bar: {valueOf() { return 42; }}}};\nif (global.__makeSimple) {\n  __makeSimple(obj2);\n}\nfunction additional1() {\n  return '' + obj1.foo;\n}\nfunction additional2() {\n  return '' + obj2.foo.bar;\n}\ninspect = function() {\n  let ret1 = additional1();\n  let ret2 = additional2();\n  return ret1 + ret2;\n}\n```\nUnfortunately it gives me a Node SIGSEGV on this branch. The master just fatals (as expected).\nDoes this happen to anybody else?. I pushed another change that adds support for the existing case in the impure mode: one simple partial argument. I believe this should be safe (I couldn't get it to break in the impure mode).\nSo this covers the existing special case from RN code now.\nI think this is ready for review.. After chatting more with @sebmarkbage I see this is not sufficient either \ud83d\ude1e \nIn particular, this doesn't help the cases where the target itself is being mutated.\nHere are a few such cases:\n\nhttps://github.com/facebook/prepack/issues/1462#issuecomment-366468792\nhttps://github.com/facebook/prepack/issues/1462#issuecomment-366469382\nhttps://github.com/facebook/prepack/issues/1462#issuecomment-366470124. Superseded by https://github.com/facebook/prepack/pull/1469. @hermanventer @NTillmann \n\nMind another review? I believe I addressed the comments in the last two commits.\n. Pushed up a Flow fix.\nRegarding the error message, realm.currentLocation seems sufficient. Is it not? In all error handler tests I added, the error points to the exact line with the mutation.\nI did add a separate error code though.. Filed https://github.com/facebook/prepack/issues/1480 as a followup.. Here is an example that's broken with this assumption.\n```js\n// additional functions\n// abstract effects\nlet obj1 = global.__abstract ? __abstract('object', '({valueOf() { this.x = 10; return 42; }})') : {valueOf() { this.x = 10; return 42; }};\nfunction additional1() {\n  var y = Object.create(obj1);\n  y + ''; // mutation, but Prepack drops it\n  return y.x;\n}\nfunction additional2() {\n}\ninspect = function() {\n  return additional1();\n}\n```\nHere is another example:\n```js\n// additional functions\n// abstract effects\nfunction additional1() {\n  var x = {\n    valueOf:\n      (global.__abstract\n        ? __abstract('function', '(function() { this.foo++; return 10; })') \n        : function() { this.foo++; return 10; }\n      ),\n    foo: 0\n  };\n  return x + '' + x.foo; // Prepack thinks it's safe to turn into \"[object Object]0\"\n}\nfunction additional2() {\n}\ninspect = function() {\n  return additional1();\n}\n```\nThat's probably fine. I think I agree we should say that primitive methods like toString / valueOf / @@toPrimitive / etc defined on objects created inside the pure mode are expected to be \"purer\" than other abstract external code, and it should probably be safe to assume they're idempotent and don't mutate their inputs.\nThis is a new assumption to me (I haven't seen it mentioned before). If @sebmarkbage is on board with this in pure mode let's continue. . Added a doc page: https://github.com/facebook/prepack/wiki/PP0026. Some snapshots are failing?. Closing as some of these are fixed, and we determined the other test case didn't quite make sense anyway.. If I explicitly optimize the middle component, then it fails with expected invariant (I don't know how to assert on this in test though):\n\n\n```js\nvar React = require('react');\nthis['React'] = React;\n\n// FB www polyfill\nif (!this.babelHelpers) {\n  this.babelHelpers = {\n    inherits(subClass, superClass) {\n      Object.assign(subClass, superClass);\n      subClass.prototype = Object.create(superClass && superClass.prototype);\n      subClass.prototype.constructor = subClass;\n      subClass.__superConstructor__ = superClass;\n      return superClass;\n    },\n  };\n}\n\nvar _React$Component = babelHelpers.inherits(\n  Middle,\n  React.Component\n);\n_superProto = _React$Component && _React$Component.prototype;\n\nfunction Middle(props) {\n  _superProto.constructor.call(this, props);\n  this.$Middle_renderItem = function() {\n    return this.props.item;\n  }.bind(this);\n}\nMiddle.prototype.render = function() {\n  var children = this.props.children;\n  return children({\n    renderItem: this.$Middle_renderItem,\n  });\n};\n\nfunction App(props) {\n  return ;\n}\n\nApp.getTrials = function(renderer, Root) {\n  renderer.update(\n    Hi}>\n      {obj => {obj.renderItem()}}\n    \n  );\n  return [['render with bound child function', renderer.toJSON()]];\n};\n\nif (this.__optimizeReactComponentTree) {\n  __optimizeReactComponentTree(Middle, {\n    firstRenderOnly: true\n  });\n}\n\nmodule.exports = App;\n```\n\n\n\nI tried to optimize the parent component so that it falls back. But it still fails with this test case\u2014this time, with the actual bug:\n\n\n```js\nvar React = require('react');\nthis['React'] = React;\n\n// FB www polyfill\nif (!this.babelHelpers) {\n  this.babelHelpers = {\n    inherits(subClass, superClass) {\n      Object.assign(subClass, superClass);\n      subClass.prototype = Object.create(superClass && superClass.prototype);\n      subClass.prototype.constructor = subClass;\n      subClass.__superConstructor__ = superClass;\n      return superClass;\n    },\n  };\n}\n\nvar _React$Component = babelHelpers.inherits(\n  Middle,\n  React.Component\n);\n_superProto = _React$Component && _React$Component.prototype;\n\nfunction Middle(props) {\n  _superProto.constructor.call(this, props);\n  this.$Middle_renderItem = function() {\n    return this.props.item;\n  }.bind(this);\n}\nMiddle.prototype.render = function() {\n  var children = this.props.children;\n  return children({\n    renderItem: this.$Middle_renderItem,\n  });\n};\n\nfunction App(props) {\n  return ;\n}\n\nApp.getTrials = function(renderer, Root) {\n  renderer.update(\n    Hi}>\n      {obj => {obj.renderItem()}}\n    \n  );\n  return [['render with bound child function', renderer.toJSON()]];\n};\n\nif (this.__optimizeReactComponentTree) {\n  __optimizeReactComponentTree(App, {\n    firstRenderOnly: true\n  });\n}\n\nmodule.exports = App;\n```\n\n\n. Anything blocking landing this?. Main reason I'm starting PRs for them is they usually require changes in multiple files (at least for React tests) and it's convenient to not have to copy paste all of them manually. I can check out PRs with a single command.. You can search the codebase for .logger calls. I think Herman might be asking to reuse the same infra for consistency. . Can you come up with a test case? Does this solve .ref = null issue?. >The changes in this PR are more around reducing output so it's hard to test other than that the current coverage\nI think prepack\u2019s own suite uses \u201cdoes not contain\u201d comments for testing such cases. Maybe we should also support this for React tests?. Yeah not a blocker. . What case is this fixing? . Can you explain how we do this now and why this is a \"better way\"? It's hard to review without this context. :-). It's also not clear whether \"isn't right\" means there are bugs. If there are bugs, can you explain how they happen? Are there test cases for these bugs?. What\u2019s output before and after?. >the partial state wasn't an abstract object value or object value\nSo it was just an abstract, is that right?\nBut we know that the API asks you to return a null or an object. So if you return something else it\u2019s already a bug.\nIs there any way that instead of forking assign logic we could instead force Prepack to treat getDerivedStateFromProps return value as always an object (or null)? Like an unsafe cast. Then maybe we could reuse existing assign?. Why is this safe? We don\u2019t know partialState is simple. (Which is one of the conditions assign checks against.) Or do we? What if it has a getter that mutates something in our heap?. >If we can't assume the partial state when we know an abstract value is totally abstract (comes from prevProps in most cases)\nWe know prevProps must be simple. Does this help anyhow?\nEdit: wait. We don\u2019t have prevProps \ud83d\ude1b . Have we definitely identified the Node regression and when the fix is coming?. Can we add Prettier check as a CI step?. (One way to work around it in this bundle is to remove _cachedFbtResults[pattern] = result; assignment.). The new invariant for this case now looks like this:\nInvariant Violation: serialized 37 of 36\nThis is likely a bug in Prepack, not your code. Feel free to open an issue on GitHub.\n    at invariant (/Users/gaearon/p/prepack/src/invariant.js:16:15)\n    at ResidualHeapSerializer.serialize (/Users/gaearon/p/prepack/src/serializer/ResidualHeapSerializer.js:2093:17)\n    at statistics.referenceCounts.measure (/Users/gaearon/p/prepack/src/serializer/serializer.js:226:15)\n    at PerformanceTracker.measure (/Users/gaearon/p/prepack/src/statistics.js:100:14)\n    at ast (/Users/gaearon/p/prepack/src/serializer/serializer.js:206:38)\n    at statistics.total.measure (/Users/gaearon/p/prepack/src/serializer/serializer.js:138:17)\n    at PerformanceTracker.measure (/Users/gaearon/p/prepack/src/statistics.js:100:14)\n    at Serializer.init (/Users/gaearon/p/prepack/src/serializer/serializer.js:103:35)\n    at prepackSources (/Users/gaearon/p/prepack/src/prepack-standalone.js:66:33)\n    at compileSource (/Users/gaearon/p/prepack/scripts/debug-fb-www.js:91:18)\nIf this is intended behavior then we should find a way to throw a meaningful error early instead of failing like this.. === serialized but not visited values\nResidualHeapSerializer.js:2130\nAbstractValue _$7 (cannot print value)\nOutput:\n\n\n```js\n(function () {\n  var _$8 = this;\n\n  var _$9 = _$8.Object;\n  var _$A = _$9.assign;\n\n  var _0 = function (props, context) {\n    var _a = props;\n    var _$0 = _a.feedback;\n\n    var _2 = _$A(_$0);\n\n    var _$1 = _2.viewCountReduced;\n    var _$2 = _a.feedback;\n\n    var _4 = _$A(_$2);\n\n    var _$3 = _4.viewCount;\n\n    var _H = 1 === _$3;\n\n    var _B = [\"\", void 0, \"*\"];\n    var _F = [void 0, \"*\"];\n\n    var _A = _H ? _B : _F;\n\n    var _9 = \"\" + _A;\n\n    var _$4 = {\n      \"*\": \"{count} Views\",\n      _1: \"{count} View\"\n    }[_9];\n\n    var _P = _9 === \"_1\";\n\n    var _N = _9 === \"*\";\n\n    var _L = _N ? \"{count} Views\" : _$4;\n\n    var _K = _P ? \"{count} View\" : _L;\n\n    var _$5 = \"\" + _K;\n\n    var _$6 = _R[_$5];\n\n    if (!_$6) {\n      var _$7 = \"\" + _K;\n    }\n\n    var _U = _$6 ? void 0 : __empty;\n\n    if (_U !== __empty) _R[_$7] = _U;else delete _R[_$7];\n\n    var _Y = _$6 || void 0;\n\n    var _W = ;\n\n    return _W;\n  };\n\n  var __empty = {};\n  var _R = {};\n  module.exports = _0;\n}).call(this);\n```\n\n\n. I'll try to reduce now.. Here is a smaller case:\n```js\n(function() {\nvar cache = {};\nfunction fn(args) {\n    var maybeTrue = args.unknown === 42;\n    var maybeNull = maybeTrue ? {} : null;\nvar cacheKey = maybeNull.foo;\nvar cachedValue = cache[cacheKey];\nif (cachedValue) {\n  return cachedValue;\n}\n\nvar result;\ncache[cacheKey] = result;\nreturn result;\n\n}\n__optimize(fn);\nmodule.exports = fn;\n})();\n```. The repro case in the post compiles for me.\n\n. Worried this will be slow. Is it not on a large bundle?. Will/can this also find arrows?. Nice. This also unblocks another bug repro which used to take a very long time but now fails fast.. Here's a related issue that might require similar changes to the abstract conditional in another file.\nhttps://github.com/facebook/prepack/issues/1883. Seems like this got fixed. I'll file if this comes up again.. Hmm. This is fun.\nCan we make it only treat objects that have an own props property as elements (in addition to the brand check)?. Sounds good to me. Why is the failure so obscure? The visitor thought it's an element, and what then?. Pasting from the closed PR, here's some logs of effect being applied twice:\n```\n!!! apply effect:  18\n!!! apply effect:  30\n!!! apply effect:  35\n!!! apply effect:  40\n!!! apply effect:  46\n!!! apply effect:  45\n!!! apply effect:  52\n!!! apply effect:  60\n!!! apply effect:  59\n!!! apply effect:  71\n\n\n\n\n\n\n\n\n\n\nenter composeNested <<<<<<<<<\n  pushed consequent to prior effects: [] ->  [48]\n  recalculating consequent effects\n  popped from prior effects: [48] ->  []\n\n\n\n\n\n\n\n\n\n\n\npushed alternate to prior effects: [] ->  [70]\n  recalculating alternate effects\n\n\n\n\n\n\n\n\n\n\nenter composeNested <<<<<<<<<\n    pushed consequent to prior effects: [70] ->  [70, 43]\n    recalculating consequent effects\n    !!! apply effect:  70\n    !!! apply effect:  43\n    popped from prior effects: [70, 43] ->  [70]\n    ------\n    pushed alternate to prior effects: [70] ->  [70, 68]\n    recalculating alternate effects\n    >>>>>>>>>> enter composeNested <<<<<<<<<\n      pushed consequent to prior effects: [70, 68] ->  [70, 68, 57]\n      recalculating consequent effects\n      popped from prior effects: [70, 68, 57] ->  [70, 68]\n      ------\n      pushed alternate to prior effects: [70, 68] ->  [70, 68, 66]\n      recalculating alternate effects\n      !!! apply effect:  70\n``. Now need to update the snapshot.. Can you explain what this fix is doing? It seems shady to drop the last item to an input whenever we enter a function. In that case it would make more sense to drop it *before* calling the function.. I added some logs to the original code that shows how we apply the70` effect twice:\n\n\n\n\n\n\n\n\n\n\n```\n!!! apply effect:  18\n!!! apply effect:  30\n!!! apply effect:  35\n!!! apply effect:  40\n!!! apply effect:  46\n!!! apply effect:  45\n!!! apply effect:  52\n!!! apply effect:  60\n!!! apply effect:  59\n!!! apply effect:  71\n\n\n\n\n\n\n\n\n\n\nenter composeNested <<<<<<<<<\n  pushed consequent to prior effects: [] ->  [48]\n  recalculating consequent effects\n  popped from prior effects: [48] ->  []\n\n\n\n\n\n\n\n\n\n\n\npushed alternate to prior effects: [] ->  [70]\n  recalculating alternate effects\n\n\n\n\n\n\n\n\n\n\nenter composeNested <<<<<<<<<\n    pushed consequent to prior effects: [70] ->  [70, 43]\n    recalculating consequent effects\n    !!! apply effect:  70\n    !!! apply effect:  43\n    popped from prior effects: [70, 43] ->  [70]\n    ------\n    pushed alternate to prior effects: [70] ->  [70, 68]\n    recalculating alternate effects\n    >>>>>>>>>> enter composeNested <<<<<<<<<\n      pushed consequent to prior effects: [70, 68] ->  [70, 68, 57]\n      recalculating consequent effects\n      popped from prior effects: [70, 68, 57] ->  [70, 68]\n      ------\n      pushed alternate to prior effects: [70, 68] ->  [70, 68, 66]\n      recalculating alternate effects\n      !!! apply effect:  70\n```\n\n\n\n\n\n\n\n\n\n\nMaybe this can help finding the problem in the logic?. Why is it safe to reset the flag in this particular case?\nwithEffectsAppliedInGlobalEnv also called restoreBindings and restoreProperties. We're not doing it here. Why?. Also why not use withEffectsAppliedInGlobalEnv directly here?. Does the test pass for you? When I run this as input.js I still get the invariant (but in a new place now).. @NTillmann This is as much as I can reduce, wdyt? https://github.com/facebook/prepack/pull/1811/commits/9abfd06285fd445fd6af3752abfca2ecf3ca778d. If you comment out the serialize() call it turns into this output.\nNote _$1 and _$2 are not defined.\n\n\n```js\n(function () {\n  var $$0 = {\n    enumerable: false,\n    configurable: true,\n    writable: true\n  };\n\n  var _$6 = this;\n\n  var _$7 = _$6.Object;\n  var _$8 = _$7.assign;\n  var _$9 = _$6.Error;\n  var _$A = _$9.prototype;\n  var _$B = _$7.defineProperty;\n  var _$C = _$6.TypeError;\n  var _$D = _$C.prototype;\n\n  var _0 = function (arg) {\n    var _1 = _$8(arg);\n\n    var _$0 = _1.foo;\n\n    var _3 = !_$2;\n\n    var _M = _$A;\n\n    if (_3) {\n      var _5 = (__constructor.prototype = _M, new __constructor());\n\n      $$0.value = \"Error\\n    at setBarFrom (/Users/gaearon/p/prepack/fb-www/input.js:14:13)\\n    at URI (/Users/gaearon/p/prepack/fb-www/input.js:4:7)\\n    at fn (/Users/gaearon/p/prepack/fb-www/input.js:26:17)\", _$B(_5, \"stack\", $$0);\n      $$0.value = \"no\", _$B(_5, \"message\", $$0);\n      throw _5;\n    } else {\n      if (_$0) {\n        if (_9) {\n          var _B = (__constructor.prototype = _M, new __constructor());\n\n          $$0.value = \"Error\\n    at setBarFrom (/Users/gaearon/p/prepack/fb-www/input.js:14:13)\\n    at URI (/Users/gaearon/p/prepack/fb-www/input.js:4:7)\\n    at fn (/Users/gaearon/p/prepack/fb-www/input.js:28:7)\", _$B(_B, \"stack\", $$0);\n          $$0.value = \"no\", _$B(_B, \"message\", $$0);\n          throw _B;\n        } else {\n          if (arg) {\n            if (_$0) {\n              var _E = _$8(_$1);\n\n              var _$5 = _E.something;\n            }\n          }\n\n          return void 0;\n        }\n\n        var _9 = !_$5;\n      } else {\n        var _H = (__constructor.prototype = _$D, new __constructor());\n\n        $$0.value = \"TypeError\\n    at URI (/Users/gaearon/p/prepack/fb-www/input.js:8:16)\\n    at fn (/Users/gaearon/p/prepack/fb-www/input.js:28:7)\", _$B(_H, \"stack\", $$0);\n        $$0.value = \"not an object\", _$B(_H, \"message\", $$0);\n        throw _H;\n      }\n    }\n  };\n\n  var __constructor = function () {};\n\n  module.exports = _0;\n}).call(this);\n```\n\n\n. I get it on master. Are you trying with debug-fb-www?. This got fixed.. I pushed a regression test into https://github.com/facebook/prepack/pull/1860 in case we enable throwing later.. There's actually a few more that are uncovered right after fixing this.\nhttps://github.com/facebook/prepack/blob/065fa2765b8ece0eac0b54b6a5e017f5416d0fc6/src/values/AbstractObjectValue.js#L244-L245\nhttps://github.com/facebook/prepack/blob/065fa2765b8ece0eac0b54b6a5e017f5416d0fc6/src/values/AbstractObjectValue.js#L312-L313\nIt is a bit worrying however that the comment above these lines (including the one you edited) specifically says \"concrete objects\". I'm not sure if that's supposed to be important or not.. This got fixed in https://github.com/facebook/prepack/pull/1933 . It was fixed by https://github.com/facebook/prepack/pull/1863.\nI'll send a PR with a regression test for this specific case.. Serializer test in https://github.com/facebook/prepack/pull/1880.. This is already fixed. Adding a test in https://github.com/facebook/prepack/pull/1916.. Why does this help? What's special about fragments per se (as opposed to e.g. context consumers/providers)?. Right, what I'm saying is that context provider type is an object that has a symbol property (which also doesn't need to be serialized). So is this only a problem when the type itself is a symbol?\n. This is fixed on master.. With latest changes it just produces undefined _$2 in output.\nWhen https://github.com/facebook/prepack/pull/1860 lands, we'll disable throwing so this won't affect us, but it still shows that there's a problem lurking in there.\n```js\n(function () {\n  var __scope_0 = new Array(1);\nvar __scope_1 = function (__selector) {\n    var __captured;\nswitch (__selector) {\n  case 0:\n    __captured = [void 0];\n    break;\n\n  default:\n    throw new Error(\"Unknown scope selector\");\n}\n\n__scope_0[__selector] = __captured;\nreturn __captured;\n\n};\nvar $$0 = {\n    enumerable: false,\n    configurable: true,\n    writable: true\n  };\nvar _$3 = this;\nvar $4 = $3.Object;\n  var $5 = $4.assign;\n  var $6 = $3.Error;\n  var $7 = $6.prototype;\n  var $8 = $4.defineProperty;\nvar _0 = function (props, context) {\n    var __captured__scope_2 = __scope_0[0] || __scope_1(0);\nvar _$0 = props.p;\n\nvar _1 = _$5(_$0);\n\nvar _$1 = _1.hello;\n\nvar _3 = _$2 ? void 0 : {};\n\n__captured__scope_2[0] = _3;\n\nvar _8 = !_$1;\n\nvar _A = !_$2;\n\nvar _7 = _8 && _A;\n\nvar _J = _$7;\n\nif (_7) {} else {\n  var _C = (__constructor.prototype = _J, new __constructor());\n\n  $$0.value = \"Error\\n    at maybeThrow (/Users/gaearon/p/prepack/fb-www/input.js:10:13)\\n    at URI (/Users/gaearon/p/prepack/fb-www/input.js:5:5)\\n    at App (/Users/gaearon/p/prepack/fb-www/input.js:26:15)\", _$8(_C, \"stack\", $$0);\n  $$0.value = \"foo\", _$8(_C, \"message\", $$0);\n\n  var _F = (__constructor.prototype = _J, new __constructor());\n\n  $$0.value = \"Error\\n    at maybeThrow (/Users/gaearon/p/prepack/fb-www/input.js:10:13)\\n    at URI (/Users/gaearon/p/prepack/fb-www/input.js:5:5)\\n    at parseHref (/Users/gaearon/p/prepack/fb-www/input.js:18:5)\\n    at App (unknown)\", _$8(_F, \"stack\", $$0);\n  $$0.value = \"foo\", _$8(_F, \"message\", $$0);\n\n  var _B = _$1 ? _C : _F;\n\n  throw _B;\n}\n\n};\nvar __constructor = function () {};\nmodule.exports = _0;\n}).call(this);\n``. This is fixed on master.. Hmm. I get this even if I comment out [all options](https://github.com/facebook/prepack/blob/41817e59150cc5ae99a6cdeaced2ee91df56084a/scripts/debug-fb-www.js#L53-L79) in the script.. Also if I turn this into a regular serializer test, I do see the same undeclared variable in the output if Iconsole.log(fn)` to reveal source after optimizing.\n\n. Here is a failing serializer test.\n```js\n(function() {\nfunction URI(uri) {\n    this.a = \"\";\n    var b = bar(uri) || {};\n    if (b.foo && b.foo()) {\n      throw new Error(\"foo\");\n    }\n    this.a = b;\n    return this;\n  }\nfunction bar(uri) {\n    var str = \"\";\n    if (uri.a) {\n      str += uri.a;\n    }\n    return str;\n  }\nfunction fn(arg) {\n    new URI(new URI(arg));\n  }\nglobal.__optimize && global.__optimize(fn);\nfunction inspect() {\n    try {\n      fn({ a: \"hello\" });\n      return \"ok\";\n    } catch (err) {\n      return err;\n    }\n  }\nglobal.inspect = inspect;\n})();\n```. Fixed by https://github.com/facebook/prepack/pull/1903. Yeah, we disabled throwing in React to work around the bugs.\nI think you should be able to temporarily re-enable it by commenting out this line:\nhttps://github.com/facebook/prepack/blob/aa700a2667f5c28754ae2dad2a64a3ad4191276a/src/realm.js#L648. This is already fixed on master.. @NTillmann I'll look at the test failure now. @NTillmann \nIt does seem to introduce a React regression.\nHere's a minimal input.js for yarn debug-fb-www:\n```js\nrequire(\"react\");\n__evaluatePureFunction(function() {\n  var React = require(\"react\");\nfunction nullthrows(x) {\n    if (x != null) {\n      return x;\n    }\n    throw new Error('no');\n  };\nfunction App(props) {\n    nullthrows(props.className);\n    return ;\n  }\n__optimizeReactComponentTree(App, {\n    firstRenderOnly: true\n  });\nmodule.exports = App;\n});\n```\nThe output is (with my inline comments that show what's wrong):\n```js\n(function () {\n  var $$0 = {\n    enumerable: false,\n    configurable: true,\n    writable: true\n  };\nvar _$2 = this;\nvar $3 = $2.Error;\n  var $4 = $3.prototype;\n  var $5 = $2.Object;\n  var $6 = $5.defineProperty;\nvar _0 = function (props, context) {\n    var _4 = ;  // <------------ the return value is hoisted up and misses className\nvar _6 = {\n  className: void 0\n};\n\nvar _8 = (__constructor.prototype = _$4, new __constructor());\n\n$$0.value = \"Error\\n    at nullthrows (/Users/gaearon/p/prepack/fb-www/input.js:10:11)\\n    at App (/Users/gaearon/p/prepack/fb-www/input.js:14:5)\", _$6(_8, \"stack\", $$0);\n$$0.value = \"no\", _$6(_8, \"message\", $$0);\nvar _D = props;\nvar _$0 = _D.className;\n\nvar _1 = _$0 != null;\n\nif (_1) {\n  var _$1 = _D.className;\n  return _4;  // <--------------- if we didn't throw, we return _4\n} else {\n  throw _8;\n}\n\n_4 = <div className={_$1} />; // <--------------- but it is set to the right thing too late!\n_6.className = _$1; // <------------- this is suspicious, why did we create this object at all?\n\n};\nvar __constructor = function () {};\nmodule.exports = _0;\n}).call(this);\n```. Maybe React element hoisting logic is buggy? Hoisting is React-specific.. To be clear, it's not getting assigned twice on master.\nThere's also no unused object with className prop on master.\nMaster output for the same input:\n```js\n(function () {\n  var $$0 = {\n    enumerable: false,\n    configurable: true,\n    writable: true\n  };\nvar _$2 = this;\nvar $3 = $2.Error;\n  var $4 = $3.prototype;\n  var $5 = $2.Object;\n  var $6 = $5.defineProperty;\nvar 0 = function (props, context) {\n    var _D = props;\n    var $0 = _D.className;\nvar _1 = _$0 != null;\n\nif (_1) {\n  var _$1 = _D.className;\n\n  var _4 = <div className={_$1} />;  // <----------------- just here\n\n  return _4;\n} else {\n  var _8 = (__constructor.prototype = _$4, new __constructor());\n\n  $$0.value = \"Error\\n    at nullthrows (/Users/gaearon/p/prepack/fb-www/input.js:10:11)\\n    at App (/Users/gaearon/p/prepack/fb-www/input.js:14:5)\", _$6(_8, \"stack\", $$0);\n  $$0.value = \"no\", _$6(_8, \"message\", $$0);\n  throw _8;\n}\n\n};\nvar __constructor = function () {};\nmodule.exports = _0;\n}).call(this);\n```. My guess is maybe this logic is relevant and maybe somehow it's not the best way to do it?\nhttps://github.com/facebook/prepack/pull/1850/files#diff-6537ea22dfd40c79de800bc20037ee16R194. Accept to unblock. Haven\u2019t studied in detail but if the tests as passing (and the new nullthrows case is also fixed) this sounds great! I\u2019ll read more tomorrow. . This turns into https://github.com/facebook/prepack/issues/1854 now.. For future reference, one way to bump into this (although possibly irrelevant to this bug) is to create a temporal with args array containing undefined. . Yeah, we disallowed throwing exceptions in React code because of issues like this.\nI think you can temporarily get around this check by commenting out this line:\nhttps://github.com/facebook/prepack/blob/47f84b405a78657c4bcca6f6ecb7a6a71d5c4368/src/realm.js#L649. This seems to have been fixed.. Follow-up: https://github.com/facebook/prepack/pull/1859. I think that in practice we should be able to exclude (or fix or transform) product code that currently relies on mutations, so we should start by just forbidding them, and fix our tests if we need to. Then if we find a situation in product code where a directive like this really buys us something we can consider adding support for this back. My main concern is that it will increase surface area for bugs and complexity without actually being that much useful.. Should we start working on getting non-simpleClosures mode working with our tests before landing this?. This looks like a mutation in render phase to me.\nWhy does it compile without error?\n```js\nrequire(\"react\");\n__evaluatePureFunction(function() {\n  var React = require(\"react\");\nvar foo = {};\nfunction App(props) {\n    if (foo.hasOwnProperty(props.x)) {\n      foo[props.x] = 0;\n    }\n    const x = foo[props.x]++;\n    return x;\n  }\n__optimizeReactComponentTree(App);\nmodule.exports = App;\n});\n``. As discussed offline, we'll need a more precise callsite reporting forthrow` because it's hard to hunt them down.. I'm going to give it a test now. (We discussed more changes based on some bugs found with internal bundles. Let's land when all of those look good.). This now turned into another case of undefined variable in the output.. I sent https://github.com/facebook/prepack/pull/1879 for the suboptimal code concern. >but this should actually be two objects if it's a primitive\nIs this a correctness problem? I understand the output is suboptimal, but can you give me an example where it matters whether we created one or two. As long as it's not exposed to the user why does it matter (aside from the obviously bad hoisting)?. Here is another test case for this based on product code:\n```js\n(function() {\n  function fn(arg) {\n    return arg != null && arg.x && arg.y;\n  };\nif (global.__optimize) __optimize(fn);\nglobal.inspect = function() {\n    return JSON.stringify([\n      fn(null),\n      fn(undefined),\n      fn({x: false, y: 5}),\n      fn({x: 5, y: 10}),\n    ])\n  }\n})();\n``. This got fixed in https://github.com/facebook/prepack/pull/1925.. Note that this isn't just aboutObject.assignin this issue. The way we read the.nameproperty is also unsafe and runs on anull` value.. This will need a rebase after https://github.com/facebook/prepack/pull/1874 lands since it moved that code . Could you add the test please?. What do you think about this point from @sebmarkbage?\n\nIt should almost always unwrap the ToObject wrapper and just refer to the original. This is one of those cases where this should never be serialized as a call because the ToObject is already implied by the property access.\n\nWith this change, the output is:\n```js\n  var 1 = function (arg) {\n    var _B = $6;\nif (arg) {\n  var _$0 = _B(arg);\n\n  var _$1 = _$0.a;\n}\n\nif (arg) {\n  var _$2 = _B(arg);\n\n  var _$3 = _$2.b;\n}\n\nvar _6 = arg ? _$1 : null;\n\nvar _9 = arg ? _$3 : null;\n\nreturn {\n  a: _6,\n  b: _9\n};\n\n};\n```\nBut I think he's saying that ideally it would be\n```js\n  var 1 = function (arg) {\n    if (arg) {\n      var $1 = arg.a;\n    }\nif (arg) {\n  var _$3 = arg.b;\n}\n\nvar _6 = arg ? _$1 : null;\n\nvar _9 = arg ? _$3 : null;\n\nreturn {\n  a: _6,\n  b: _9\n};\n\n};\n```\nbecause the Object.assign() here doesn't help us with anything. In this case we do ToObject for property access which already enforces that it\u2019s an object (null.something would throw at runtime). So it\u2019s as if we\u2019re adding an unnecessary invariant to ensure something that would happen anyway, with the cost (potentially expensive) of creating these throwaway objects.\nThere are probably other places where this behavior is helpful. Such as if we didn\u2019t access the property immediately afterwards. I\u2019m not sure how we can know which case it is.\nWDYT?. In https://github.com/facebook/prepack/pull/1690, there is a mention of unwrapping:\n\nThe serializer will now serialize the abstract result of calling To.ToObjectPartial on an abstract value as \"Object.assign(abstract_value)\". In the one case where the serialized code is known to implicitly convert the abstract value to an object anyway, the caller of To.ToObjectPartial strips away the wrapper in order to avoid the redundant explicit conversion.\n\nThat sentence seems to refer to this case: https://github.com/facebook/prepack/commit/88fbdcc47b15a38ac4369b7eeb893e2d62eedba2#diff-5cb5f0c9909e8738d567acfaff9bb980R115\nPerhaps @sebmarkbage was hoping this would also happen for property access?. I have a PR coming on top. https://github.com/facebook/prepack/pull/1879. This is not safe without changing some code.\nSpecifically, obj.args is now an empty array. It used to contain a single wrapped value.\n\nWe rely on this here. We don't seem to have a test for this pattern but if we reached this code it would mistakingly push undefined into the delayedSources. I also rely on it in a follow-up PR that tries to make the output better (https://github.com/facebook/prepack/pull/1879).\nSo we need to expose a way to read the wrapped value (or change how it\u2019s being read).. The object argument is second now.\n\nSo we need to fix these callsites to read args[1]:\nhttps://github.com/facebook/prepack/blob/555e18bb62246b2d00f3ab5bedcab3db9e0ea1c8/src/intrinsics/ecma262/Object.js#L116-L118\nhttps://github.com/facebook/prepack/blob/3005452448aa972fda02c7b12eb485b08c921ae6/src/values/AbstractObjectValue.js#L251-L252\n. Note that with this merged, https://github.com/facebook/prepack/pull/1879 will no longer work (even if it's also fixed to read args[1]). This is because now that it's a temporal, we can't just throw it away, so the output always contains it. I'm not sure what the right fix is.. Interestingly, combining this with https://github.com/facebook/prepack/pull/1878 leads to this invariant in my serializer test: https://github.com/facebook/prepack/issues/1854. I don't understand why. See https://github.com/facebook/prepack/pull/1878#issuecomment-386826268.. Actually I'm struggling to come up with a case where we'd want to emit Object.assign. If we're trying to \"emulate\" the behavior of something like Object.keys() by emitting a temporal call to it, then of course it will also do the ToObject conversion we just did. So when do we actually need it?. I'd like to wait for some thoughts from @sebmarkbage to understand the cases where emitting is intentional. Maybe there's a wider fix we could do instead of fixing them one by one. I know I missed a bunch in ArrayPrototype for example.. This seems to happen because the logic in visitObjectPropertiesWithComputedNames hasn't been updated in the same way that its twin in the residual heap visitor has been.\nI tried fixing that by this diff:\n```diff\n--- a/src/utils/havoc.js\n+++ b/src/utils/havoc.js\n@@ -171,26 +171,33 @@ class ObjectValueHavocingVisitor {\n   }\nvisitObjectPropertiesWithComputedNames(absVal: AbstractValue): void {\n-    invariant(absVal.args.length === 3);\n-    let cond = absVal.args[0];\n-    invariant(cond instanceof AbstractValue);\n-    if (cond.kind === \"template for property name condition\") {\n-      let P = cond.args[0];\n-      invariant(P instanceof AbstractValue);\n-      let V = absVal.args[1];\n-      let earlier_props = absVal.args[2];\n-      if (earlier_props instanceof AbstractValue) this.visitObjectPropertiesWithComputedNames(earlier_props);\n-      this.visitValue(P);\n-      this.visitValue(V);\n+    if (absVal.kind === \"widened property\") return;\n+    if (absVal.kind === \"template for prototype member expression\") return;\n+    if (absVal.kind === \"conditional\") {\n+      let cond = absVal.args[0];\n+      invariant(cond instanceof AbstractValue);\n+      if (cond.kind === \"template for property name condition\") {\n+        let P = cond.args[0];\n+        invariant(P instanceof AbstractValue);\n+        let V = absVal.args[1];\n+        let earlier_props = absVal.args[2];\n+        if (earlier_props instanceof AbstractValue) this.visitObjectPropertiesWithComputedNames(earlier_props);\n+        this.visitValue(P);\n+        this.visitValue(V);\n+      } else {\n+        // conditional assignment\n+        this.visitValue(cond);\n+        let consequent = absVal.args[1];\n+        if (consequent instanceof AbstractValue) {\n+          this.visitObjectPropertiesWithComputedNames(consequent);\n+        }\n+        let alternate = absVal.args[2];\n+        if (alternate instanceof AbstractValue) {\n+          this.visitObjectPropertiesWithComputedNames(alternate);\n+        }\n+      }\n     } else {\n-      // conditional assignment\n-      this.visitValue(cond);\n-      let consequent = absVal.args[1];\n-      invariant(consequent instanceof AbstractValue);\n-      let alternate = absVal.args[2];\n-      invariant(alternate instanceof AbstractValue);\n-      this.visitObjectPropertiesWithComputedNames(consequent);\n-      this.visitObjectPropertiesWithComputedNames(alternate);\n+      this.visitValue(absVal);\n     }\n   }\n```\nBut my serializer test still doesn't pass. The invariant is gone, but the output doesn't match.. Wouldn't producing wrong code be worse than an invariant?. We can fix this now.\nhttps://github.com/facebook/prepack/pull/1942. Should we point to Wiki from somewhere? In my experience Wiki pages aren\u2019t always easy to find. It\u2019s not obvious when a project actually uses the Wiki so many don\u2019t look for it.\nI would suggest having a file like CONTRIBUTING.md that points to the relevant resources. . I don't think it matters where it is as long as:\n\nthere's a centralized place with links to all contributing docs\nwe link to that place from other entry points people might consider (README, Contributing.md, website). I think it's fine if Wiki home page plays that role, let's just make sure we link to it everywhere.. To clarify, here's a smaller repro:\n\njs\n(function () {\n  \"use strict\";\n  let moduleTable = {};\n  function require(id) {\n    return {};\n  }\n  global.require = require;\n})();\nthree = require(\"three\");\nThe problem is here:\n```js\n(function () {\n  \"use strict\"; // <--- claims to have strict mode\nvar _$0 = this;\nvar _0 = function (id) {\n    return {};\n  };\n_$0.require = _0;\n  three = {}; // <-------- does an implicit global assignment\n}).call(this);\n```. Also, why is this a limitation at all?\n\nPrepack can use the heap values that resulted from running the global code, as if they were constants.\n\nCould Prepack havoc x so that it is treated as abstract by optimized functions?. Makes sense, thanks for explaining!. Never mind, I misread. There's an array wrapper.. Why?. That doesn\u2019t handle the cases where you need to force conversion, does it?\nI don\u2019t know the spec well enough to point out those cases but my impression is they exist. . Might be the same issue as https://github.com/facebook/prepack/issues/1840. >What's the background of this restriction?\nOn the web, people are used to tags like <div> meaning platform-specific components. We can't have a whitelist because browsers add new tags, and people can also define custom ones for the browser. So we need a way to distinguish React components from intentional usage of browser tags. We went with using \"starts with lowercase\" as a decision mechanism. Lowercase first letter = you meant HTML tag.. Do you expect we might have more of these?. (I filed https://github.com/facebook/prepack/issues/1962 for another similar issue). Does this also solve\n```js\n(function() {\n  function fn(arg) {\n    var a = arg ? arg.a : null;\n    var b = arg ? arg.b : null;\n    return { a, b };\n  }\nif (global.__optimize) global.__optimize(fn);\nglobal.inspect = function() {\n    return JSON.stringify([fn(null), fn({ a: 1, b: 1 })]);\n  };\n})();\n```\n?\nI just left my desk. Do you think it\u2019s redundant? I\u2019d feel safer if we had regression tests for both but I defer to your judgement. . Looks like there's a Prepack model invariant violation.\n```\nvar inner, fn;\n(function () {\n  var _$6 = this;\nvar $7 = $6.Object;\n  var $8 = $7.assign;\n  var $9 = $6.Array;\n  var $A = $9.from;\n  var $B = $6.Error;\n  var $C = $7.prototype;\n  var $D = $C.hasOwnProperty;\n  var $E = $9.prototype;\n  var $F = $E.filter;\n  var $G = $6.Boolean;\nvar 2 = function (arg) {\n    var _3 = $8(arg);\nvar _$0 = _3.condition;\n\nvar _5 = !_$0;\n\nvar _M = _$9;\nvar _N = _$A;\nvar _K = _$E;\nvar _L = _$F;\nvar _P = _$G;\n\nif (!_5) {\n  if (typeof _M.from !== \"function\") throw new _$B(\"Prepack model invariant violation (\" + 0 + \"): \" + _M.from);\n\n  var _7 = _$8(arg);\n\n  var _$1 = _7.foo;\n\n  var _$2 = _N(_$1);\n\n  var _8 = _$2;\n  if (_$D.call(_8, \"filter\")) throw new _$B(\"Prepack model invariant violation (\" + 1 + \"): \" + _8.filter);\n  if (typeof _K.filter !== \"function\") throw new _$B(\"Prepack model invariant violation (\" + 2 + \"): \" + _K.filter);\n\n  var _$3 = _8.filter(_P);\n\n  var _9 = _$3;\n  if (_$D.call(_9, \"0\")) throw new _$B(\"Prepack model invariant violation (\" + 3 + \"): \" + _9[0]);\n  var _$4 = _9[\"0\"];\n  if (_$D.call(_9, \"length\")) throw new _$B(\"Prepack model invariant violation (\" + 4 + \"): \" + _9.length);\n  var _$5 = _9[\"length\"];\n}\n\nvar _G = 0 === _$5;\n\nvar _E = _G ? null : 42;\n\nvar _C = _5 ? null : _E;\n\nreturn _C;\n\n};\nvar _J = function (props) {\n    var foo = Array.from(props.foo);\n    var bar = foo.filter(Boolean);\n    bar[0];\nif (bar.length === 0) {\n  return null;\n}\n\nreturn 42;\n\n};\nvar _0 = function () {\n    return JSON.stringify([fn({\n      condition: false\n    }), fn({\n      condition: true,\n      foo: []\n    }), fn({\n      condition: true,\n      foo: [false]\n    }), fn({\n      condition: true,\n      foo: [true]\n    }), fn({\n      condition: true,\n      foo: [false, 5]\n    }), fn({\n      condition: true,\n      foo: [true, 5]\n    })]);\n  };\n$6.inner = _J;\n  $6.fn = 2;\n  var _1 = $C;\n  if ($D.call(_1, \"0\")) throw new $B(\"Prepack model invariant violation (\" + 5 + \"): \" + 1[0]);\n  if ($D.call(1, \"inspect\")) throw new $B(\"Prepack model invariant violation (\" + 6 + \"): \" + 1.inspect);\n  inspect = _0;\n}).call(this);\noutput of inspect() on last generated code iteration\nError: Prepack model invariant violation (4): 0\nevalmachine.:49\n      if ($D_unique27277.call(9_unique27277, \"length\")) throw new $B_unique27277(\"Prepack model invariant violation (\" + 4 + \"): \" + _9_unique27277.length);\n                                                          ^\nError: Prepack model invariant violation (4): 0\n```. The test failure is because we (unexpectedly?) are able to inline less React components.\nI'd like @trueadm to have a look before we merge.. I guess making it partial causes a bailout in React logic.. Here is another case that this PR is not fixing:\n```js\nfunction fn(arg) {\n  if (!arg.condition) {\n    return null;\n  }\nvar fooArr = Array.from(arg.foo);\n  return arg.calculate(function() {\n    return fooArr;\n  });\n}\nif (global.__optimize) __optimize(fn);\ninspect = function() {\n  return JSON.stringify([\n    fn({condition: false}),\n    fn({\n      condition: true,\n      foo: 10,\n      calculate(f) { return f().length; }\n    }),\n    fn({\n      condition: true,\n      foo: [1, 2, 3],\n      calculate(f) { return f().length; }\n    }),\n  ])\n}\n```\nDoes that indicate a related problem?. That sounds good to me. I'll file a separate issue then.. Here's a longer reproduction case that more closely resembles product code.\nI'm not sure if these two are the same issue, but the first one is probably easier to start with.\nPosting this just in case.\n```js\n(function() {\n  function fn(arg) {\n    var tmp;\n    var prop = (tmp = arg) != null ? tmp.prop : tmp;\n    if (arg == null || prop == null) {\n      return null;\n    }\n    return prop;\n  }\nif (global.__optimize) __optimize(fn);\nglobal.inspect = function() {\n    return JSON.stringify([\n      fn(null),\n      fn(undefined),\n      fn({}),\n      fn({prop: 'foo'})\n    ]);\n  };\n})();\n``. This is a bug in simplifier. I verified returningvaluefromsimplify` immediately fixes it.\nWe already know simplifier has some bugs in handling comparisons: https://github.com/facebook/prepack/issues/1830.. Maybe something is wrong here. Disabling this part produces correct output.. Here's a shorter one.\n```js\n(function() {\n  function fn(arg) {\n    return arg == null ? 'a' : (arg && 'b');\n  }\nif (global.__optimize) __optimize(fn);\nglobal.inspect = function() {\n    return JSON.stringify([\n      fn(null),\n      fn(undefined),\n      fn({})\n    ]);\n  };\n})();\n```. I think I might have a fix for this.. Hmm, never mind, my fix is wrong.\nI tried this\ndiff\n--- a/src/utils/paths.js\n+++ b/src/utils/paths.js\n@@ -161,7 +161,7 @@ function pushInversePathCondition(condition: Value) {\n       let right = condition.args[1];\n       if (left instanceof ConcreteValue && right instanceof AbstractValue) [left, right] = [right, left];\n       if (left instanceof AbstractValue && (right instanceof UndefinedValue || right instanceof NullValue)) {\n-        let op = condition.kind === \"!=\" ? \"===\" : \"!==\";\n+        let op = condition.kind === \"!=\" ? \"!==\" : \"===\";\n         if (op === \"!==\") pushInversePathCondition(left);\n         else pushPathCondition(left);\n         let leftEqNull = AbstractValue.createFromBinaryOp(realm, op, left, realm.intrinsics.null);\nbut it breaks yarn test-serializer --filter SimpleObject4.. https://github.com/facebook/prepack/pull/1933. Adding this test (based on https://github.com/facebook/prepack/issues/1830 which no longer causes an invariant) shows an output mismatch though:\n```js\n(function() {\n  function save(obj, x) {\n    if (!obj[x]) {\n      obj[x] = x;\n    }\n  }\nfunction fn(arg) {\n    var obj = {};\n    if (arg == null) {\n      // nothing\n    } else {\n      save(obj, arg === 1 ? 'a' : 'b')\n    }\n    if (arg != null) {\n      save(obj);\n    } else {\n      save(obj);\n    }\n    return obj;\n  }\nif (global.__optimize) __optimize(fn);\nglobal.inspect = function() {\n    return JSON.stringify([\n      fn(null),\n      fn(undefined),\n      fn(1),\n      fn(2),\n    ]);\n  }\n})();\n```. I tried to add this test (https://github.com/facebook/prepack/pull/1933#issuecomment-388128573) in addition to the one in the PR already.\nWithout this PR, that test produces a Pushing false invariant: https://github.com/facebook/prepack/issues/1830.\nWith this PR, it produces an output mismatch when run via serializer test harness. It looks like this:\nOutput mismatch!\noriginal code\n\n\n```js\n(function() {\n  function save(obj, x) {\n    if (!obj[x]) {\n      obj[x] = x;\n    }\n  }\n\n  function fn(arg) {\n    var obj = {};\n    if (arg == null) {\n      // nothing\n    } else {\n      save(obj, arg === 1 ? 'a' : 'b')\n    }\n    if (arg != null) {\n      save(obj);\n    } else {\n      save(obj);\n    }\n    return obj;\n  }\n\n  if (global.__optimize) __optimize(fn);\n\n  global.inspect = function() {\n    return JSON.stringify([\n      fn(null),\n      fn(undefined),\n      fn(1),\n      fn(2),\n    ]);\n  }\n})();\n```\n\n\noutput of inspect() on original code\n[{},{},{\"a\":\"a\"},{\"b\":\"b\"}]\ngenerated code in iteration 0\n\n\n```js\n(function () {\n  var _$3 = this;\n\n  var _$4 = _$3.Object;\n  var _$5 = _$4.prototype;\n  var _$6 = _$5.hasOwnProperty;\n  var _$7 = _$3.Error;\n\n  var _2 = function (arg) {\n    var _3 = arg == null;\n\n    var _6 = {\n      undefined: void 0\n    };\n\n    var _K = 1 === arg;\n\n    var _H = _K ? \"a\" : \"b\";\n\n    if (!_3) {\n      var _$0 = _6[_H];\n    }\n\n    var _E = !_$0;\n\n    if (_3) {\n      if (_E) {\n        _6[_H] = _H;\n      }\n    }\n\n    var _G = arg != null;\n\n    if (_G) {\n      var _$1 = _6[\"undefined\"];\n      if (_$6.call(_1, \"undefined\")) throw new _$7(\"Prepack model invariant violation (\" + 6 + \"): \" + _1.undefined);\n    } else {\n      var _$2 = _6[\"undefined\"];\n\n      var _C = _E ? _$2 : __empty;\n\n      var _B = !_C;\n\n      if (_B) {\n        if (_$6.call(_1, \"undefined\")) throw new _$7(\"Prepack model invariant violation (\" + 7 + \"): \" + _1.undefined);\n      }\n    }\n\n    var _9 = _B ? void 0 : __empty;\n\n    var _7 = _G ? void 0 : _9;\n\n    if (_7 !== __empty) _6.undefined = _7;else delete _6.undefined;\n    return _6;\n  };\n\n  var _0 = function () {\n    return JSON.stringify([_2(null), _2(undefined), _2(1), _2(2)]);\n  };\n\n  var __empty = {};\n  var _1 = _$5;\n  if (_$6.call(_1, \"0\")) throw new _$7(\"Prepack model invariant violation (\" + 4 + \"): \" + _1[0]);\n  if (_$6.call(_1, \"inspect\")) throw new _$7(\"Prepack model invariant violation (\" + 5 + \"): \" + _1.inspect);\n  inspect = _0;\n}).call(this);\n```\n\n\noutput of inspect() on last generated code iteration\n[{\"b\":\"b\"},{\"b\":\"b\"},{},{}]\nI'm not sure if this PR is just uncovering another existing issue, or causing it.\nBut I learn towards \"uncovering\" because if I completely disable the simplifier on master, I get the same exact output mismatch for that test. Therefore, my fix to simplifier is probably correct, but there is another bug lurking in there (maybe in serializer) that's causing this.\nSo I'll land this fix but keep another issue related to this failing test.. I reduced the new failure (which also happens on master) into https://github.com/facebook/prepack/issues/1935. It's indeed an independent issue.. Seems like\n```js\nvar _5 = arg ? true : __empty;\n\n```\nshould have been the other way around?. Looks like the bug is that this always puts empty value on the right side.\nhttps://github.com/facebook/prepack/blob/00d8a1a82064eb4af36f23aee2b1152e0a681175/src/methods/join.js#L950\nBut its side should actually depend on which is the left and which is the right one:\nhttps://github.com/facebook/prepack/blob/00d8a1a82064eb4af36f23aee2b1152e0a681175/src/methods/join.js#L912. https://github.com/facebook/prepack/pull/1937 has a fix.. Here is a simpler test:\n```js\n(function() {\n  function foo(x) {\n    if (!x) {\n      return null;\n    }\n    return x != null ? x : null;\n  }\nglobal.__optimize && __optimize(foo);\nglobal.inspect = function() {\n    return JSON.stringify([\n      foo(null),\n      foo(undefined),\n      foo(0),\n      foo(1),\n      foo({}),\n    ]);\n  }\n})();\n```. https://github.com/facebook/prepack/pull/1954. https://github.com/facebook/prepack/pull/1956. Unlike props, technically React allows mutating state. Do we intentionally forbid it here?. The Array.from-specific part has been fixed in https://github.com/facebook/prepack/pull/1970.\nThe remaining issue is tracked as https://github.com/facebook/prepack/issues/1973 (and might be \"by design\").. This fix triggers an invariant in one of my bundles here:\nhttps://github.com/facebook/prepack/blob/3b3c4f371cddc087deb77585036478e4871c35cf/src/serializer/ResidualHeapVisitor.js#L1005\nSpecifically, I get there through visitObjectPrototype where obj.$Prototype is literally undefined.. To be clear I'm not entirely sure we have exactly this problem in our bundles. We didn't know about this design limitation when we were reducing the actual case so it's plausible we don't hit this bigger issue in reality, and it's not high priority to us. This needs additional investigation.. Can we have a React test with a runtime error that demonstrates what we're trying to catch?\nSo that this doesn't get removed later when we forget why we added it.. Yep, thank you for spotting. I misread ESLint docs.. Ahh, I misread the docs! I thought turning off variables completely disables variable check.. lint?. lint. We cover these by the bundle now. We can extract smaller ones on a case by case basis if we bump into them.. This serializer test passes on master:\n```js\nfunction fn(arg) {\n  var res = fn2(arg);\n  switch (res) {\n    case \"a\":\n      return 1;\n  }\n}\nfunction fn2(arg) {\n  if (arg > 0) {\n    return \"c\";\n  } else if (arg > 0) {\n    return \"b\";\n  }\n  return \"a\";\n}\nglobal.__optimize && __optimize(fn);\ninspect = function() {\n  return JSON.stringify([\n    fn(0),\n    fn(1),\n  ]);\n};\n```\nBut it breaks with this PR.\nNote it's very similar to https://github.com/facebook/prepack/issues/2058 (which fails on master). However, this one doesn't fail on master.. It's hard for me to tell what is just cleanup and what is fixing bugs. Can you separate the two, and make test cases for changes that affect the output?. >since recently, reads from havoced final objects don't return a fresh abstract values, but instead the last-known internal value\nWhen did we change this?\nI think initially \u201cfinal\u201d meant \u201cwe\u2019re not allowed to mutate it from Prepack side because we that would modify its heap value but we\u2019ve already used its value inside a temporal\u201d.\nAt some point it seems like we started using it to mean \u201csomething that is considered immutable even though we didn\u2019t explicitly freeze it\u201d.\nI think the new usage is fine if snapshots superseded the need for the first usage. But is this still doing what it\u2019s intended to do?\nhttps://github.com/facebook/prepack/blob/21cb2b4da5dc36b25dd4604f3747af549ca9d402/src/values/AbstractObjectValue.js#L203-L204\nI\u2019m not sure.. It's a bug from the React compiler perspective. Normally when some feature is missing we want to \"fall back\" and either emit different equivalent code, or if it's hard, \"step out\" of this component and leave it as it was (without evaluation). I don't know enough about React reconciler to tell what the right fix is.\nBut I consider any valid code that crashes the compiler (instead of just bailing out on a tree) to be a bug.. Here is a non-React serializer test case:\n```js\n(function () {\n  function fn(arg) {\n    var value = arg.x !== null ? arg.x : 0;\nfunction fn2() {\n  return value;\n}\nglobal.__optimize && __optimize(fn2);\n\nreturn Array.from(arg.arr).map(fn2);\n\n}\nglobal.__optimize && __optimize(fn);\nglobal.inspect = function() {\n    return JSON.stringify([\n      fn({arr: [1, 2, 3], x: 1}),\n      fn({arr: [1, 2, 3], x: null}),\n    ])\n  };\n})();\n```. @NTillmann This doesn't use React: https://github.com/facebook/prepack/issues/2056#issuecomment-393625192. I'm removing \"high priority\" because we know that nested optimized functions were never finished, and while this is nice to have and would help us, it's not actively making code wrong (unlike other high pri bugs which do).. No. Unless I made a mistake checking today.\nA similar one was (but it was introduced in the same PR where it later got fixed). But not this one AFAIK. . Looks like ObjectAssign2 is failing?. Could you please also address https://github.com/facebook/prepack/pull/2068#discussion_r196549917 (in that and other tests)? I think they are overly conservative about the output that's allowed.. We don't maintain any plugins ourselves. Prepack exposes a Node API so you can write a FuseBox (or any other tool) plugin for it. That said please also note Prepack is not ready for production use, and in general if you target web (and use, e.g., DOM APIs) you likely won't find it very useful right now.. Nice, thanks. Do you want to land or I'll land it?. This got fixed at some point. I'll add a regression test in a follow up.. React elements are like lazy function calls. It's important to preserve the semantics of short-circuiting. With something && <A /> it's never safe to evaluate anything in A unless we do this all of that under the equivalent something condition.. I'm not seeing this happen with if or ternaries on master.. Another concern is React test already being super slow. We shouldn't add more init time things to it. Let's split them up into two separate test files.. We do this in React repo so it's definitely possible. It would need to be a separate command with its own config.. But to be clear, I'm not proposing to split configuration as much as runtime initialization of mocks etc. Mocks can be local to a test file, right?. It's a bit hard to review changes that don't explain the intention (why is this important? what does this let us do? what behavior/output has changed? is this a stepping stone to something?). >Testing is covered by all existing tests, as this is a performance fix rather than a correctness fix.\nWe could still add tests that assert output doesn't include unconditional elements, or something.. I think having a single test that counts createElement calls is fine and wouldn't be much effort.. The internal bundle also fails with this.. NestedThrowEffects runs into an invariant it seems.\ntest/serializer/additional-functions/NestedThrowEffects.js {\"delayInitializations\":false,\"inlineExpressions\":false,\"residual\":false}\n{ Invariant Violation: undefined\nThis is likely a bug in Prepack, not your code. Feel free to open an issue on GitHub.\n    at invariant (/home/circleci/project/lib/invariant.js:10:136)\n    at JoinImplementation.joinOrForkResults (/home/circleci/project/lib/methods/join.js:9:41726)\n    at JoinImplementation.joinForkOrChoose (/home/circleci/project/lib/methods/join.js:9:30226)\n    at composeNestedThrowEffectsWithHandler (/home/circleci/project/lib/evaluators/TryStatement.js:9:8204)\n    at exports.default (/home/circleci/project/lib/evaluators/TryStatement.js:9:2306)\n    at LexicalEnvironment.evaluateAbstract (/home/circleci/project/lib/environment.js:9:55282)\n    at LexicalEnvironment.evaluate (/home/circleci/project/lib/environment.js:9:54439)\n    at LexicalEnvironment.evaluateCompletion (/home/circleci/project/lib/environment.js:9:39246)\n    at LexicalEnvironment.evaluateCompletionDeref (/home/circleci/project/lib/environment.js:9:38706)\n    at FunctionImplementation.EvaluateStatements (/home/circleci/project/lib/methods/function.js:9:47736) name: 'Invariant Violation' }. What's the difference in the output, briefly? Can you give a few line example of before/after?. >but this is a better approach\nCan you explain in more detail what's better about it? What problems were you running into, and why does this approach solve them?. (needs Flow fix). Here is a reduced repro:\n```js\n(function() {\nglobal._DateFormatConfig = {\n    formats: {\n      'l, F j, Y': 'l, F j, Y',\n    },\n  }\nvar DateFormatConfig = global.__abstract ?  __abstract({}, \"(global._DateFormatConfig)\") : global._DateFormatConfig;\n  global.__makeSimple && __makeSimple(DateFormatConfig);\nvar MONTH_NAMES = void 0;\n  var WEEKDAY_NAMES = void 0;\nvar DateStrings = {\n    getWeekdayName: function getWeekdayName(weekday) {\n      if (!WEEKDAY_NAMES) {\n        WEEKDAY_NAMES = [\n          \"Sunday\",\n          \"Monday\",\n          \"Tuesday\",\n          \"Wednesday\",\n          \"Thursday\",\n          \"Friday\",\n          \"Saturday\"\n        ];\n      }\n  return WEEKDAY_NAMES[weekday];\n},\n_initializeMonthNames: function _initializeMonthNames() {\n  MONTH_NAMES = [\n    \"January\",\n    \"February\",\n    \"March\",\n    \"April\",\n    \"May\",\n    \"June\",\n    \"July\",\n    \"August\",\n    \"September\",\n    \"October\",\n    \"November\",\n    \"December\"\n  ];\n},\n\ngetMonthName: function getMonthName(month) {\n  if (!MONTH_NAMES) {\n    DateStrings._initializeMonthNames();\n  }\n\n  return MONTH_NAMES[month - 1];\n},\n\n};\nfunction formatDate(date, format, options) {\n    options = options || {};\nif (typeof date === \"string\") {\n  date = parseInt(date, 10);\n}\nif (typeof date === \"number\") {\n  date = new Date(date * 1000);\n}\nvar localizedFormat = DateFormatConfig.formats[format];\nvar prefix = \"getUTC\";\nvar dateDay = date[prefix + \"Date\"]();\nvar dateDayOfWeek = date[prefix + \"Day\"]();\nvar dateMonth = date[prefix + \"Month\"]();\nvar dateYear = date[prefix + \"FullYear\"]();\n\nvar output = \"\";\nfor (var i = 0; i < localizedFormat.length; i++) {\n  var character = localizedFormat.charAt(i);\n\n  switch (character) {\n    case \"j\":\n      output += dateDay;\n      break;\n    case \"l\":\n      output += DateStrings.getWeekdayName(dateDayOfWeek);\n      break;\n    case \"F\":\n    case \"f\":\n      output += DateStrings.getMonthName(dateMonth + 1);\n      break;\n    case \"Y\":\n      output += dateYear;\n      break;\n    default:\n      output += character;\n  }\n}\n\nreturn output;\n\n}\nfunction fn(a, b) {\n    return formatDate(a, \"l, F j, Y\");\n  }\nglobal.fn = fn;\nglobal.__optimize && __optimize(fn);\nglobal.inspect = function() {\n    return JSON.stringify(global.fn(\"1529579851072\"));\n  }\n})();\n````. I can't reduce it further than this.\n```js\nrequire(\"react\");\n__evaluatePureFunction(function() {\nvar React = require('react')\nfunction makeClosure(bar) {\n    if (bar.length === 0) {\n      return function(props) {};\n    }\n    var captured = bar;\n    return function closure() {\n      this.captured = captured;\n    }\n  }\nfunction Child(props) {\n    this.state = {};\n  }\n  Child.prototype.isReactComponent = {};\n  Child.getDerivedStateFromProps = function(nextProps) {\n    if (nextProps.bar) {\n      return {\n        closure: makeClosure(nextProps.bar),\n      };\n    }\n  };\nChild.prototype.render = function() {\n    var closure = this.state.closure;\n    return null;\n  };\nfunction App(props) {\n    if (props.foo) {\n      return null\n    }\n    return React.createElement(Child, props);\n  }\nmodule.exports = App;\nif (global.__optimizeReactComponentTree) {\n    __optimizeReactComponentTree(App, {\n      firstRenderOnly: true\n    });\n  }\n});\n```. Okay, here's a small one without React.\n```js\n(function() {\n  function makeClosure(bar) {\n    if (bar.length === 0) {\n      return function(props) {};\n    }\n    var captured = bar;\n    return function closure() {\n      this.captured = captured;\n    }\n  }\nfunction fn(arg) {\n    if (arg.foo) {\n      return null\n    }\n    var state = {};\n    if (arg.bar) {\n      state.closure = makeClosure(arg.bar);\n    }\n    arg.baz(state);\n    return state.closure;\n  }\nglobal.fn = fn;\nif (global.__optimize) {\n    __optimize(fn);\n  }\n})();\n```. Interestingly, this change\ndiff\n-    var captured = bar;\n    return function closure() {\n-      this.captured = captured;\n+      this.captured = bar;\n    }\nturns it from bad output into an invariant:\nan abstract value with an identifier \"_$2\" was referenced before being declared. Looks like Havoc8 failed.. This feels quite hacky. It's as if we take a generic concept (\"intrinsic\") and then say \"in React reconciler they behave differently\". But this seems to me like we should either reuse some existing mechanism, or use a different concept.\nCan we give them different hashValues instead?. Don't know if it was expected, but this commit makes the build 3 times slower for our internal bundle in my testing. That makes it significantly more difficult for me to extract isolated small test cases because it kills my iteration speed.. Remaining failing case here: https://phabricator.internmc.facebook.com/P59738169. Btw I didn't mean to drop classes :-)\nI meant that instead of having ReactPropsSet extend ReactSet, you can delegate to it.\n```js\nclass ReactPropsSet {\n  reactSet = new ReactSet(whatItActuallyNeeds);\nadd() {\n    var something = this.reactSet.doSomething();\n    // ...\n}\n```\nThen interaction between them is explicit and I don't need to guess which methods are private to the base class vs which are meant to be accessible by superclass, and whether base class ever calls the superclass.\nAnyway, no need to rewrite\u2014hope this explains what I meant.. Let's just revert the last commit? The argument count in functions is wild.\nI agree classes are better in this case. I'm sorry if my last comments were confusing. I was strictly speaking about dropping inheritance, not dropping classes.. Anyway. Whatever you think is clearer \ud83d\udc4d Let's not get stuck on this.. Similar case with wrong output:\n```js\nrequire(\"react\");\n__evaluatePureFunction(function() {\n  const React = require('react');\nfunction App(props) {\n    return props.foo ? [] : [];\n  }\nfunction Foo() {\n    return ;\n  }\n  function Bar() {\n    return ;\n  }\n__optimizeReactComponentTree(App);\nmodule.exports = App;\n});\n```\nHere, too, we incorrectly \"forget\" that the node should be keyed.. >This PR moves the logic of stripping first render from serialization to the point at which we create ReactElements.\nWhat about something like\njs\n<MyComponent>\n  <div renderItem={function() { return <p /> }} />\n</MyComponent>\nand then MyComponent being return props.children.props.renderItem();?\nWould that break this case?. Confirmed this fixes the perf regression. Thanks.. Can you also add tests for nesting arrays?. These are helpful. Let\u2019s review tomorrow in person?. Any reason you don\u2019t want to use an array?. What Node version are you using?. You shouldn't need to run yarn upgrade.\nInstead, revert your changes and then run yarn add -D babel-core@6.26.3.. I think this is ready for a review now. I'll check remaining followups either later in this PR, or in the next one.\nThis reduces the time it takes to run yarn test-react from ~45s on my machine to ~21s. It also fixes an annoying issue where a watcher would trigger twice on each change, and clear the screen while you were trying to read it.\nIt gives you an ability to run a subset of tests from command line, e.g. yarn test-react FirstRender. You can do the same with Jest watcher filtering interface in yarn test-react --watch (and then press p).\nWhen there's a bug in one output mode (e.g. createElement => createElement), it now fails immediately for a particular test case, and doesn't attempt it in other modes (since they would likely fail too). So failures should appear faster.\nAdditionally, this PR adds yarn test-react-fast for cases when you don't care about JSX syntax tests. It runs all tests in ~10s (and is even faster in watch mode), but the output is a bit noisy because of a warning about \"obsolete snapshots\" (which aren't really obsolete\u2014just skipped in this mode).\nI also added Prettier to tests so we can stop doing the formatting nits.. Okay, I figured out the last pieces.\nJest tests don't pause properly because of https://github.com/facebook/jest/issues/6598 and https://github.com/facebook/jest/issues/6599.\nOnce that gets fixed, we'll get a fast and responsive test runner.. Hi!\nWe don't use GitHub for legal requests or discussions. It's possible that Prepack would be relicensed in the future (like React and React Native were), but not certain. If this happens, you'll see it on the repo.\nCheers.. I believe you checked the old tests back in.\nPlease don't forget to check the diff by clicking \"Files changed\" after complex merges. :-). https://github.com/facebook/prepack/pull/2196. I usually look at line count after merges, if there\u2019s many thousand lines then something went wrong :P. >This PR ensures that when we clone config or props objects that we deeply clone the object properly, including any temporal properties on derived abstract values.\nWhat does this achieve for us?. Since my comment is lost somewhere above, I'll copy paste it here:\n\nWhy would you need loads of invariants? Presumably there's just some specific callsite you introduced that caused everything downstream to want a more generic type. That's the callsite where you need to put the invariant.\n\n. Let's wait for this to fail. Then in a follow-up I'll submit the changes we previously missed.. Lol this tripped me hard a few days ago. Thanks for fixing.. >Why the files directly required by the -test file have to use let ... require instead of import {} from\nBecause we don't currently run Babel in our Jest setup. We can do this by adding babel-jest as a dependency.. If you add babel-jest, it would also make sense to reference src from React tests (instead of lib), and then replace it here too so Jest would watch changes to src by itself.. Awesome work!\nI'm seeing this output on master:\n```js\n(function () {\n  var _$2 = this;\nvar 1 = function (arg) {\n    var $0 = arg.foo;\nif (_$0) {\n  var _$1 = arg.bar;\n}\n\nif (_$0) {\n  var _$1 = arg.bar;\n}\n\nreturn _$0 ? _$1 ? 42 : void 0 : void 0;\n\n};\nvar _0 = function () {\n    return JSON.stringify([_1(null), _1({}), _1({\n      foo: true\n    })]);\n  };\n_$2.inspect = _0;\n}).call(this);\n```\nNote _$1 is duplicated. Is that normal?\n. Sent https://github.com/facebook/prepack/pull/2282 as a first step towards avoiding such regressions. We still need to fix them before we can merge it though.. Would it be useful to add lint suppression to known cases where it happens and hope to reduce them in the future? Or is it too non deterministic?. >It looks like this fails on a lot more tests then the regressed NestedConditions.js I added. I\u2019m guessing for different reasons. Is this expected?\nNot by me, but yes, seems like it's an unexpected existing flaw. @trueadm You'll get it in? I forgot why we didn't last time.. Keys shouldn't matter for first render mode, but matter in normal mode.. I don't quite understand the discussion about hydration in this thread.\nSSR works in two steps:\n\n\nFirst, HTML is produced. That usually happens on the server although technically you can run it on the client too. When you produce HTML, keys don't matter because there are never any updates. You can produce HTML both with normal bundle and with first-render-only bundle. In fact \"first-render-only\" bundle is exactly \"the subset of the normal bundle that is sufficient to produce the same HTML with less code\".\n\n\nSecondly, DOM is hydrated. This always happens on the client. Hydration happens the same way a normal initial client render works, except that we reuse existing DOM nodes as we traverse them instead of creating new ones. Hydration can only be done with a \"full\" bundle, because \"first-render-only\" bundle would neither have events nor lifecycles nor support for updates. The whole point of hydration is to attach event handlers (which can trigger updates). In a full bundle, keys matter \u2014 if the keys are wrong, the first render (hydration itself) would work but any updates would potentially work differently.\n\n\nAn ideal end state is Prepack being able to produce two bundles. One for the initial render, and the other one being \"just enough to support updates without repeating the initial render logic\". However this would require React to have a way to \"progressively enhance\" components with update logic after they've already rendered or been hydrated. Some future things we talked about can help us with that. I'm not sure how we'd deal with keys in this scenario but they would probably have to be specified in the initial render bundle so that the first update is hooked up correctly. So maybe we're really talking about three bundles: one for SSR (no keys), one for first render (with keys), and one for updates. But that's a far future ideal, and not what we do today.. Doesn't this disable them globally for the whole file? I think you want // eslint-disable-next-line or something like that.. Let's add a comment explaining what the regex is trying to find.. Can we restructure this so that instead of repeating similar logic in both branches, we first wrap resultA and resultB into an array if necessary and then do the assertions unconditionally?. Maybe try { } finally { } so this is isolated from other tests in case it fails?. Would be nice to understand why.. It this only used for testing infra? Or for real implementation? It's not clear.\nShould this be renamed to src/intrinsics/react-mocks/global.js?\n. This utility name sounds very generic but it's not very clear what this does.\nWhat is normalized JSON looking like?\nIs it useful in any other places than this test infra?. Nit: indent. Nit: indent. (and in most places below). Nit: style is odd, can we use the same code style as in code?. Why do we need this.* assignment here but not in other places?. If runTest fails for some reason, global.console.error won't be restored.\nIf you do\njs\nglobal.console.error = ...\ntry {\n  doStuff\n} finally {\n  global.console.error = original\n}\nit is restored no matter what.. Shouldn't it also have isReactComponent = true on the prototype? Or inherit from Component.. Why?. I don't think this object is created unless there's at least one ref?. If we have to set every field then there's also this.updater.. Does React fall back to empty object for props? I'm not sure where this is coming from.. What is this function? (I haven't seen this in React). Same, why do we need this?. (I guess this should've been a field? See below). I think this should be an object: https://github.com/facebook/react/blob/9491dee79586d21c115cd4d5986c81b7d88d2b3f/packages/react/src/ReactBaseClasses.js#L26. Agree if it never should get called it should throw.. That's an FB specific thing, I don't actually remember what it does. Need to check.. Can we use a minimal repro here for clarity? I don't think any of the webpack stuff is necessary.. Yeah, but we don't actually use webpack at FB in practice so IMO this is obscuring what the test is about (our class transform). typo. Should this really be a React test? Seems like a more generic feature that could maybe be in the main test suite.\nI don't mean the existing test to be deleted, but maybe a new one in additional-functions could do?. What does this do?. How does this undefined get used?\nI understand it's a bail out but it's not clear to me what's going to happen with that undefined value. Is it just ignored somewhere?\nCan you make a test for this case?. Oh, I see, it gets used here. It is a bit confusing to me that we use undefined for this (even though technically we ignore its \"meaning\" and just use it as a marker). Could this be something more special?. If it failed, how does the bailout work? Where do we keep the original createElement call?. Does the order matter here? Can you create a test with multiple trees and different depths?. Sounds good, thanks for explaining. OK, that makes sense. Thanks.. Note I don't think this would fix the internal naming problem in all cases. It solves the common case (where they don't actually clash). But if they do, this won't help.\nSo this is not blocking my work. This solution won't be a full fix (even if it worked fully).. For the FB use case I think we should have some preprocessing step that just turns them into globals (and teach Prepack to treat them as globals). Because our transform doesn't actually care if they're imported or not.. I guess the problem with that approach is that we actually need to leave them as cx, not global.cx \ud83e\udd14 . We should probably assert this isn't already true here. Since otherwise you'd get really confusing results if these ever end up nested.. I wonder if it would make more sense to wrap the whole serialization process into evaluateWithoutLeakLogic than to special-case the length access.\nIf my understanding is right by that point we don't really \"run\" user code so we don't have to worry about it \"using\" the leaked values. Maybe I'm wrong though.. That's the part I'm not sure about. My impression was that indeed it's not important: https://github.com/facebook/prepack/pull/1382#discussion_r165111775. But maybe I'm wrong. For now I'd keep this targeted fix, and double check with @sebmarkbage when he's more available.\n. Sent this as a followup https://github.com/facebook/prepack/pull/1384. cx, not Bootloader?. Bootloader isn't called as a function, it's called like Booloader.loadAllModules() or something (see the bundles). Typo . I don\u2019t understand. If we don\u2019t actually render then how can the test pass?. But how does the test pass? I assume it\u2019s supposed to compare what React really renders with what the compiler renders. If compiler doesn\u2019t call the render method how can it pass?. I still don\u2019t understand. I\u2019ll look at this when I\u2019m at home (in an hour). OK. I thought result means \"a React element\" but it just means \"a class or a function that we will serialize back as a type\". Is that right?. Nit: mixing tabs and spaces?. Nit: \";\" at the end of the comment?. Nit: tab/spacing mix here too (sorry, I copy pasted :-). Nit: extra space at the end. This looks like a private API. Would be nice to verify it won't break with someone. : any probably isn't great either.\nMaybe there's a supported way to do this? @NTillmann . My impression is that AbstractValue constructor gives you more control. Maybe if you use that you won\u2019t have to assign a private property. . What invariant does this skip and why?. Nit: this is just an inheritance chain, isn\u2019t it? \u201cMultiple inheritance\u201d typically implies something different. There are more things described as symbols. We shouldn't just assume that if it's a symbol, it must be a fragment. We should throw for unknown ones.. These descriptions don't match what we're testing anymore. They should say \"update with array\" or \"update with fragment\".. Nit: this code would be clearer if we kept the function call unconditional, and only branched for the first argument. Still an issue. We should test the update path too. I don't think we know this is safe. AFAIK there's nothing that tells us to is simple.. Not sure this is right. abstractPropsArgs are only created from spreads.\nBut you may have something like <div {...props1} something=\"something\" {...props2} />.\nI think this code will do Object.assign({}, props1, props2) and lose something=\"something\".. Hmm, I see now you're pushing props up to that point to the array.\nStill I'd like to see more coverage here. A bunch of different cases with one spread, many spreads, spread-before-normal-args, spread-after-normal-args, spread-between-args, etc. Make sure key and ref end up being what we expect in all cases, even with complex overrides.. What is special about default props and children here? I would expect default props to work the same way whether the prop is \u201cchildren\u201d or any other prop. This special case is confusing and I\u2019m not a fan of isDefaultProps argument here. The code below intentionally tries to treat \u201cdefault props\u201d as just props that were assigned early. This special case undermines that. . Can you clarify why invariant is useful to run on every prop assignment? Do you expect this to change? Can we run it just once?. I don\u2019t feel good about being unsafe by default. I think I would prefer a bailout in this case with a clear message telling me what to fix. If it\u2019s not a hard fix in most cases it could be okay to change the source, and we could make it smarter over time. But this is definitely unsafe.\nIf you feel strongly about this maybe we could put it behind a flag. \u2014reactMode unsafe. . While we\u2019re at it could we also mark it as frozen?. What is the difference between \"transpiled JSX\" and \"create-element\"?. I still don't understand this. There's nothing as far as I can see that guarantees target is simple. What gives us the knowledge to claim it is simple now?. Ah I get it now. Maybe it would be clearer if it said something like \"JSX input, JSX output\" or \"non-JSX input, non-JSX output\" etc. Right now it's not clear what \"JSX\" refers to in the test name.. Hmm I think I see. You're saying that if we're in pure scope, we promised not to mutate any objects created before we entered it. So even if we have an object with a getter that has a side effect, presumably we promise not to run it?\nI don't think I understand if this is safe. This will need @sebmarkbage or @hermanventer to take a look.. Can this break some case in RN that doesn't specify this?. I don\u2019t think we know this unless the target had no properties before the call. . Shouldn\u2019t this run before we assigned all the properties? By now it already has keys (we just set them, no?)\nIf this observation is correct then I\u2019m surprised how the tests could pass. Is test stressing this code path at all?. Nit: tabs/spaces . I think this makes sense. But I would feel better if the assumptions we're making (e.g. that FatalError would have been thrown by now) were somehow written in code. The line says we don't \"yet\" support this. What if we later add support? Then the assumption in this code branch would be invalid.. I don't like that we assume this to be true. Seems dangerous.\nHere's my alternative proposal (against master) for how we could express it. Does it make sense?\n```diff\n@@ -60,6 +60,8 @@ export default function(realm: Realm): NativeFunctionValue {\n     // 1. Let to be ? ToObject(target).\n     let to = To.ToObjectPartial(realm, target);\n     let to_must_be_partial = false;\n+    let to_must_be_simple = false;\n+    let simple_sources_count = 0;\n // 2. If only one argument was passed, return to.\n if (!sources.length) return to;\n\n@@ -81,7 +83,9 @@ export default function(realm: Realm): NativeFunctionValue {\n     let frm_was_partial = frm.isPartialObject();\n     if (frm_was_partial) {\n\n\nif (!frm.isSimpleObject()) {\nif (frm.isSimpleObject()) {\nsimple_sources_count++\n} else {\n             // If this is not a simple object, it may have getters on it that can\n             // mutate any state as a result. We don't yet support this.\n             AbstractValue.reportIntrospectionError(nextSource);\n@@ -110,9 +114,15 @@ export default function(realm: Realm): NativeFunctionValue {\n       if (to_must_be_partial) {\n         // Only OK if to is an empty object because nextSource might have\n         // properties at runtime that will overwrite current properties in to.\n// For now, just throw if this happens.\n         let to_keys = to.$OwnPropertyKeys();\nif (to_keys.length !== 0) {\nif (to_keys.length === 0) {\n// If all sources are simple, and target has no keys,\n// we know it is safe to assume target is simple too.\nif (simple_sources_count === sources.length) {\nto_must_be_simple = true;\n}\n} else {\n\n// For now, just throw if this happens.\n           AbstractValue.reportIntrospectionError(nextSource);\n           throw new FatalError();\n         }\n@@ -140,7 +150,13 @@ export default function(realm: Realm): NativeFunctionValue {\n     }\n// 5. Return to.\n-    if (to_must_be_partial) to.makePartial();\n+    if (to_must_be_partial) {\n+      to.makePartial();\n+    }\n+    if (to_must_be_simple) {\n+      to.makeSimple();\n+    }\n+\n return to;\n   });\n```. Aah I see what you mean.. Nit: mixing tabs and spaces (same in other file). I think this would be clearer if you branched before memberExpression call and turned it into two possible calls. . Same . In terms of code clarity, what I suggested is:\n\n\njs\ncallFunc = t.isValidIdentifier(propName) ?\n  t.memberExpression(nodes[0], t.identifier(propName), false) :\n  t.memberExpression(nodes[0], t.stringLiteral(propName), true);\nI think this makes it more obvious why both branches exist.\nI don't feel strongly about this though.. https://github.com/facebook/prepack/pull/1456. That's what I thought but I asked @hermanventer and he said\n\nThe idea of a simple object is simply that it's safe to read and write unknown properties. If there is a getter of setter involved that is OK as long as there is no observable side effects. Of course if the property is known and we have the definition of the getter or setter then that is OK too.\n\nand\n\nDemoting a simple object is not a supported scenario. It is probably not a good idea.\n\nSo I'm confused over this. I'm also not sure what assumptions Prepack codebase makes around \"simple\" (i.e. does it treat it as \"has no getters/setters\" or \"has no unknown getters/setters\") in practice, regardless of the original intention.\nFor example would this be safe if there were known getters/setters:\nhttps://github.com/facebook/prepack/blob/6203b6b125e916815fac848d06ca86ed7f73d4dc/src/evaluators/BinaryExpression.js#L133\n?\nThis\nhttps://github.com/facebook/prepack/blob/6203b6b125e916815fac848d06ca86ed7f73d4dc/src/methods/to.js#L783\n?\nI'm not sure. The fact that it's used in so few places also makes it hard for me to tell what it's supposed to represent in practice, and if it's consistent today or not.. But this code never runs, does it? We're not setting to y anywhere.. This test expects an error. It should error because if it didn't, Prepack would pass the final state of y in the residual Object.assign call.. children = children = seems accidental. This test breaks if I put\njs\nreturn <Button {...props} id={\"5\"} switch={true} />\ninstead. Is this a known issue or a bug?. (On master it just fails, but at least it doesn't create wrong output. I think failing is always preferable. If there's some case we can't handle, could you bail out here?). I think this makes sense but maybe it needs to be:\n```js\nif (leftPure && rightPure) return typeIfPure;\nif (realm.isInPureScope()) {\n  if (!leftPure) Leak.leakValue(lval);\n  if (!rightPure) Leak.leakValue(rval);\n  return typeIfPure;\n}\n```\nSimilar to this: https://github.com/facebook/prepack/blob/4f22fbae831e08804104f1b08bcd8b5ad00c44ee/src/values/AbstractObjectValue.js#L346\n?\nBecause they might leak the object to toString() and valueOf().\nI'm struggling to come up with a case where that would matter though.. Safe to do what exactly? We make sources partial again later.. To be clear, this code already existed, I just moved it around a bit.. Why?. Neither of deleted properties exist.\nFor this reason, even if I replace the createTemporalFromBuildFunction inner callback return value with something like return t.stringLiteral('hi');, this test still passes.\nLet's add another test where we delete an unknown property but also ensure it has been deleted.. This line isn't covered by serializer tests. So it's not clear to me if it works and which case it covers.. I don't see us actually using args in a meaningful way here. This part of CallExpression logic seems unnecessary here.. When is leaking necessary in practice? Seems like the only case delete could trigger outside code is if this is a proxy. Otherwise I don't see a reason to leak.\nHow do you feel about skipping this if thisArg is a simple object?. Not covered by serializer tests. Not covered by serializer tests. Why do we define both globals and regular variables with the same name? This seems a bit confusing to me. . Let's change this to use // add at runtime. This checks for __makePartial but then uses __makeSimple.. Thanks for explaining. I wasn't sure what \"tracking\" means but this makes more sense now.. Does this mean the whole approach is flawed, or just that I should make it accept AbstractValue and also treat this as a bailout reason when I check for it?. We're adding booleans here. This is easy to get wrong. See my suggestion above.. As far as I can tell, them being partial or simple is irrelevant to the code branch we're trying to test.\nHow about this instead?\n```js\n// additional functions\n// abstract effects\nlet obj1 = global.__abstract ? __abstract('object', '({foo: {valueOf() { return 42; }}})') : {foo: {valueOf() { return 42; }}};\nlet obj2 = global.__abstract ? __abstract('object', '({foo: {bar: {valueOf() { return 42; }}}})') : {foo: {bar: {valueOf() { return 42; }}}};\nfunction additional1() {\n  return 42 < obj1.foo;\n}\nfunction additional2() {\n  return 42 > obj2.foo.bar;\n}\ninspect = function() {\n  let ret1 = additional1();\n  let ret2 = additional2();\n  return JSON.stringify({ ret1, ret2 });\n}\n``\n. Same comment as below, I think we can lose it if we change__abstract({}to__abstract('object'. Simple/partial doesn't matter here.. In which cases does this matter? Everywhere I check forisFinalObject, the argument is already justObjectValue`. Am I missing some checks?. It seems like instead of tracking the counts, it would be sufficient to start with \njs\nvar mayContainRefOrKey = false\nand then set it to true whenever we don't know for sure (or if we set an actual ref or key attribute).. 2 is quite magic here. It is not obvious it is referring to the deleted key and ref earlier.\nIt seems a bit strange to me that we only push the config when there's > 2 properties in this branch, but in the branch below we push it when there's > 0 properties. However the condition of the branch itself depends on the spreadValue. I don't understand why the next spreadValue should determine whether the previous config should be pushed.\nIs there any way to restructure this to have less moving pieces? For example maybe we could always push configs (even if empty) but later ignore the empty ones.\nI'm not just nitpicking on style. My concern is that this code is crucial to get right, and it's quite stateful and relies on very subtle details (e.g. if I remove the deleteRefAndKeyFromProps call above which might seem superficial to someone, the logic ends up skipping valid properties, whereas ideally it would've just bailed out more often). If we can make it less brittle that would be great.. I think this needs && binding.descriptor.enumerable to fix https://github.com/facebook/prepack/pull/1447#issuecomment-367359080.. I think this needs && binding.descriptor.enumerable to fix https://github.com/facebook/prepack/pull/1447#issuecomment-367359080.. I'm hitting this invariant with very simple code. Why?\n```js\nvar React = require('react');\nthis['React'] = React;\nfunction App(props) {\n  return ;\n}\nApp.getTrials = function(renderer, Root) {\n  var props = {};\n  renderer.update();\n  return [['simple render with jsx spread 5', renderer.toJSON()]];\n};\nif (this.__registerReactComponentRoot) {\n  __registerReactComponentRoot(App);\n}\nmodule.exports = App;\n```. I think this isn't safe for the same reason as https://github.com/facebook/prepack/pull/1447#issuecomment-367359080.\nThis object could have a prototype and could have non-enumerable properties on it. We should filter those out.. Maybe we can compare property names instead? That would be more explicit.\nIt would also help to extract config creation into a separate function that immediately deletes key and ref. Then we don't need to \"remember\" to delete them in two different places (for first and subsequent configs). I think it would also be clearer if config was renamed to partialConfig or something that better represents the fact that we may create many such configs as we go.\nIn either case, I still don't quite understand why we need to use 2 here but 0 just below.. Oops. Addressed. What is special about this case? I don't see how it differs from the last catch-all.. Should this use AbstractValue.createTemporalFromBuildFunction?\nI don't understand how to choose between that and derive().. In other words, AbstractObjectValue represents that we know it is an object whereas AbstractValue means we're not sure what it is (but it could as well be an object)?. Can we pass this through pretty printer before giving it to jest?. I think checking .toLowerCase() for both letters would match what React does more closely.. Why is this important?. This doesn't mean anything, does it?\nA rethrow catch clause is equivalent to no catch clause.. Thanks, I couldn't come up with a better name!. Why do we delete the descriptor rather than the binding itself from the property map?. Typo. . Same . You seem to create the binding the same way in both branches. Maybe unify that part? . Extra comma at the end?. This looks wrong to me. How do we know these children are created by React, and not passed in?\nI would expect that we'd mark them as final early\u2014when we create an array (here and here). If we don't create children ourselves then we shouldn't be marking them.. Same. Nit: I don't see why add a paren here. It made me think you're negating the whole expression at first.. Remove?. Maybe make createReactElement delegate to this?. Let's add an early invariant for abstract.kind === \"conditional\"? The code in this method relies on that but it's not reflected in type signature so we could forget this in the future.. Is this meant to enable recursive conditionals? I tried that but it doesn't work because it fails earlier.\njs\nlet Type = props.switch ? (props.switch ? Foo : Bar) : Bar;\n```\n  Invariant Violation: undefined\n    This is likely a bug in Prepack, not your code. Feel free to open an issue on GitHub.\n  14 |   const message = `${format}\n  15 | This is likely a bug in Prepack, not your code. Feel free to open an issue on GitHub.`;\n> 16 |   let error = new Error(message);\n  17 |   error.name = \"Invariant Violation\";\n  18 |   throw error;\n  19 | }\n\n  at invariant (src/invariant.js:16:15)\n  at AbstractObjectValue.$Get (src/values/AbstractObjectValue.js:460:19)\n  at Get (lib/methods/get.js:342:12)\n  at Reconciler._getComponentResolutionStrategy (src/react/reconcilation.js:786:3)\n  at Reconciler._resolveReactElement (src/react/reconcilation.js:1050:25)\n  at Reconciler._resolveDeeply (src/react/reconcilation.js:1210:7)\n  at Reconciler._renderComponent (src/react/reconcilation.js:753:5)\n\n```\nWe should either fix this and add a test, or not try to handle this case.. This test should verify updates work too. (Particularly switching the switch.). The output looks like\n```js\n        var _7 = {_B};\n    var _I = <div key=\"mt\">{_B}</div>;\n\n    var _5 = _$0 ? _7 : _I;\n\n```\nIs there any reason why elements can't be created lazily? In practice we always only need one of them, i.e.\njs\n        var _5 = _$0 ? <span key=\"oz\">{_B}</span> : <div key=\"mt\">{_B}</div>;. So does this happen in other cases too before this PR? Then it's fine I guess.. We already have an if (callerFn) condition below, maybe unify them?. It would be nice to call it out explicitly or have a test that reproes it. Or somebody will break it.. Can you explain more about which patterns make this necessary?. What is the original code doing here? Try adding to names, but if they come up empty, just do the same thing again?. When would it be equal?. Nite: Extra newline. I think this logic is wrong and should mirror what React does more closely.\nSpecifically:\n\n\nIf static getDerivedStateFromProps or instance getSnapshotBeforeUpdate exist, we treat component as having a \u201cmodern\u201d lifecycle. In that case neither componentWillMount nor UNSAFE_componentWillMount gets called (ref).\n\n\nIf neither of the modern methods exist, then we first call componentWillMount if it exists, then call UNSAFE_componentWillMount if it exists. Even if componentWillMount exists, it should not prevent UNSAFE_componentWillMount from getting called. (ref). It's not obvious from this test that the ref forwarding actually works. Can you make it do something with that ref? e.g. pass it down a few levels to a class, call a method to read a prop.. Is this a private field?. Can we also verify that:\n\n\nYou can forward refs more through several levels\n\nIt works with class instances too (e.g. test ref.current.getValue() with getValue() { return this.props.value; }). Is there a good reason why it triggers an invariant? I suppose somebody put it there to protect against something. Why should we get around that?. forwardRef that renders another forwardRef. Maybe this doesn't make sense. I'm not sure.. Why is this necessary now but wasn't before?. Same question. What does this do?. Can we do something like App.App2 = App2 in the body instead? . I'd like to have @sebmarkbage weigh on this. Still not sure this is necessarily true although it makes sense.. Seems like you could get rid of includeFunctionBodies now. . I don\u2019t understand why this is safe. It seems to say \u201cif we read from an object that we don\u2019t know about, let\u2019s just say the property is undefined\u201d. Why is that correct?. Why?. I find it a bit confusing we check both for intrinsics and for actual undefined. . Aaah. Okay. . Can this be a strict check?. Looks like it\u2019s missing . it.only. It can also have result.savedEffects, do we need to visit those?. What about other completion types like JoinedAbruptCompletions (which also have consequentEffects and alternateEffects? Why or why not do we need to handle them here?. If this fix is right then the push / pop pair below also needs changing.\n\nI'm not sure the fix is right. \"Pop\" seems intended to match the \"push\" before it. It's strange to push first, and then shift later. Maybe the intention was to remove the specific item we pushed? In that case it would still be symmetrical but it would make sense if it broke when more than one item have been pushed since then. (Edit: I checked, and that's not the case.)\n. There is a very similar structure in composeNestedEffectsWithFinalizer below. If this fix is correct then should it also be applied there?. This result is newly created a few lines above. So it will always have canBeApplied = true.\n. we're -> we've?. Maybe add an invariant here that it was false?. What if f throws? Should restoration happen inside a finally block, and f() be inside of a try block?. (I'm looking at withEffectsAppliedInGlobalEnv which does it this way). Let's fix this to be composeNestedEffectsWithFinalizer/2. Looks like bad original copypasta.. Typo: What is -> what if. Seems like this comment isn't attached to anything now? . Maybe this doesn't matter but should we wrap in try/finally? Can func() ever throw?. Where is this logic now? Was it unnecessary?. It's confusing this looks like a boolean function call but apparently it has a mutation/side effect since return value is not used. I considered putting these methods on the React serializer/visitor itself but it felt way too abstract and indirect, especially because React visitor is already a \"visitor\". So I wanted to make the relationship very direct by making this an argument with a special type.. We do use it for debug-fb-www script though. So this moves us closer to how we currently generate the bundles.\nDoes it mean it's too unstable and we shouldn't?. Nit: Last word on this line breaks grammar. Is this the best place to fix it? Or is there some more appropriate fix higher up the call stack?\nTechnically I\u2019d say they\u2019re still \u201cequal\u201d. Equality is just not sufficient in this case to allow replacing them. As Seb noted maybe they should\u2019ve been temporal? Or maybe something above can say \u201clet\u2019s rely on equality unless the timing aspect matters\u201d. \n. Leftover. If I make a typo in this string on master, then ToObject.js serializer test from #1690 fails.\nBut if I make a typo in this branch, I don't see failing tests. Does this mean this kind is now unused? Why? Can/should it be removed?. Yes but that's not the only place in the codebase checking for that string. It means we don't cover those other places by tests.. Yes, I initialized it to this. Seems like when we have a Prepack bug (not even an invariant, but a JS error like accessing a property on undefined), we get here. This doesn't seem great because we lose the original call stack. For example I got a message like this:\nError: Failed to optimize React component tree for \"FeedStoryUFISummary\" due to evaluation error: Cannot read property '$Get' of undefined\n    at renderComponentTree (/Users/gaearon/p/prepack/src/react/reconcilation.js:225:15)\n    at Realm.evaluateForEffects (/Users/gaearon/p/prepack/src/realm.js:761:15)\nCould we preserve the stack, or better, only \"wrap\" errors that are known to be intentional (FatalError?), and aren't just bugs in Prepack?. When I get this in a bundle I'm testing, there doesn't seem to be no indication of where the error happened.\nThe component name seems to point to the top-level component which isn't very useful. Instead, I want to know where throw is located, and its JS stack.. Is it time to address this? :-). \"from mutating a property\" maybe?\nI'm seeing an error like\n\nFailed to render React component \"Tooltip\" due to side-effects from mutating the object \"(\\d)(\\d{3})($|\\D)\"\n\nwhen it points to code like\njs\nvar _regexCache = {};\nI assume the name is the property name here, not the object name.. Don't forget to revert this. That's the branch I was fixing but I assume others had the same problem. I don't know how to test other branches.. This code is lifted from IfStatement. Is it wrong too?. Re:\n\nOn the other hand, conditional expressions are expressions, so perhaps evaluate is the right thing to do here in both cases and we do not need the check for an AbruptCompletion.\n\nI can add evaluateDeref() that can't return AbruptCompletion if you prefer?. That sounds good.. Why did this return move?. Nit: noopFunction would be a more common casing convention. Reduce is not guaranteed to return an array, and we removed that logic. Let's fix up the comment too.. Nit: Prettier?. Why didn't it linebreak? . Can you explain why in more detail? It\u2019s not obvious to me. . If both are undefined then return value would be undefined too?\nI think maybe you want left || realm.intrinsics.undefined, like below.. description is copy pasta. Why does being simple and final imply it\u2019s safe from having a key or a ref?. What does \u201cwith the props going into a function\u201d mean? Can you give an example?. So how do we know they don't have ref/key?. You probably mean invariant(false, ...). Let's use a more specific tagging mechanism for \"doesn't have key/ref\" because it seems orthogonal to finality.. I know this code existed before but the two lines below are suspicious:\njs\nconfig.makePartial();\nconfig.makeSimple();\nWhy do we think that just because something is used as a spread <Foo {...config} /> the config itself is simple? Nothing prevents us from declaring a config variable with getters, using it in a spread, and then later using it for other purposes. I don't think it's right that we assume config itself becomes simple after being used in JSX.\nCan we remove the two lines below? The tests React seem to pass without them anyway.. Maybe hasNoPartialKeyOrRef? It's kind of ambiguous, and I thought makeSafe is a function based on naming.. Can it be NullValue? I thought you were checking for that on line 499.. I don't think this is right.\nIt will fail if you explicitly pass undefined:\njs\nReact.createElement('div', {children: 'hi'}, undefined)\nIt's the arguments.length that matters.\nCan you please fix this and add a regression test for it?. Can you explain what isTop() check here gives you? Why does it determine final-ness?. Can we just not call it on NullValue and make input type more specific?. I don't understand what this is doing. Can you explain?. If config is an abstract coming from external code why is it safe to assume it has no ref and key? I don't understand this.\nI understand why props wouldn't have ref/key on it. But not why config wouldn't have it. As far as I can tell spreadValue could literally be anything.. I understand what it represents technically. I don\u2019t understand why it makes sense here logically.. You\u2019re describing the mechanics of how to construct Prepack objects. But I\u2019m asking about the higher level picture of what you\u2019re trying to do and why it is the correct thing to do.. So if we created props, we know them and can mark them as final.\nBut if we got them from outside then we don\u2019t know anything about them (and thus can\u2019t mark them as final).\nIs that accurate? If it is, can\u2019t we move makeFinal to where we create them (since we know what they are at that point)? Or is there something else going on here?. What tells us it doesn't have a partial key or ref here?. It's counter-intuitive to me that a function with a \"pure\" name like has* performs this caching side effect.\nHow do we know it's never going to become partial? Some other code could call makePartial().. Same question here\u2014if it doesn't have a partial key/ref now does it mean it will never get them?\nOr should this check be done every time?. Same question. Right but whether it is partial or not can change after it has already been added to the set. That's what I meant by \"caching\". It seems to me like you're using a characteristic of an object at a certain point in time (\"is not a partial\") to make a projection (\"it won't ever be partial\"). Unless you remove it from the set when it becomes partial I don't see why this is sufficient.\nDoes this make sense?. OK, I missed the fact that hasNoPartialKeyOrRef assumes its argument is a React props object and not any arbitrary object. Can you rename this method to make this assumption clear? e.g. hasNoPartialKeyOrRefOnReactPropsObject.. Maybe invariant if the argument is not final would be helpful too.. I also don't see this rule being consistently followed.\nFor example: https://github.com/facebook/prepack/pull/1996/files#diff-f17c375ba23f7377a789f6f90f5ea0cdR248\nAs far as I can tell you're passing spreadValue which is not guaranteed to be a \"React props\" immutable object. It could anything, couldn't it?\n\n. Can/should we assert that the passed object is final? So we don't pass something non-final by mistake.. Why do we think it's safe to remove this? Maybe it is but only for the first render?\nHere's a test case with spread ref that fails on master and still fails on this PR:\n```js\nvar React = require('react');\nthis['React'] = React;\nclass Wat extends React.Component {\n  render() {\n    return ;\n  }\n}\nfunction App(props) {\n  return ;\n}\nApp.getTrials = function(renderer, Root) {\n  var obj;\n  function ref(inst) {\n    obj = inst;\n  }\n  renderer.update();\n  return [\n    ['simple render with jsx spread 6', renderer.toJSON()],\n    ['type', Object.keys(obj).join(',')]\n  ];\n};\nif (this.__optimizeReactComponentTree) {\n  __optimizeReactComponentTree(App);\n}\nmodule.exports = App;\n```. Can we at least check finality for cases where it's not abstract (or when we have all templates)?. Needs an invariant? It's not clear what happens in that case now.. Why this change? I thought we intentionally used \"internal\" methods in these cases. Copypaste?. Is this fixing a bug? Which one?\nI don't see this in the old code. Can you explain this in more detail on an example? I never really understood what \"applying branching logic\" means in practice. Let's be more explicit, e.g. >= 1?. This needs a test case then?. Let's call this sanitizeHostProps(). The assumption is easy to miss.. Should we throw if we couldn't set it?. Per our discussion let's fix the bug here and add a regression test.\nMy sketch:\n```js\nvar React = require('react');\n// the JSX transform converts to React, so we need to add it back in\nthis['React'] = React;\nfunction App(props) {\n  if (props.foo) {\n    return ;\n  }\n  return ;\n}\nfunction Foo() {\n  return ;\n}\nfunction Bar() {\n  return ;\n}\nif (this.__optimizeReactComponentTree) {\n  __optimizeReactComponentTree(App);\n}\nmodule.exports = App;\n``. We need to also ensurenodes[0] !== nodes[2]`.. I think we're getting closer but this will probably still need more work.\nAt least, arrays and fragments have special state-preserving behavior that we should respect.\nI'll try to make a test case.\nhttps://gist.github.com/clemmy/b3ef00f9507909429d8aa0d3ee4f986b. Note it\u2019ll also be important that only one level nesting is special cased. Deeper nesting change loses state. . And is it safe to skip then? Why? Adding keys seems essential for correctness. . ^^ this comment seems completely irrelevant now. Could you please make sure that when the code changes, the comments are still helpful?. Yeah, but it seems like in that case we should fail hard instead of emitting code that works differently.. Oops. Why are React elements special? It seems like we should check for frozen or final objects instead?. Commented out by mistake?. typo. Let's add \njs\n// Create it eagerly so it's created outside effect branches. What if this is a getter? Why is this safe to eliminate?. I don't see the pure scope here.\nI also don't understand why it would be safe even in pure scope. An external function could pass an object with a getter that mutates external state on call. I don't think pure scope means that may never happen?\njs\n// external code\nlet counter = 0;\nMyApplet.something({\n  get x() {\n    counter++;\n  }\n});\n// use counter. It's becoming quite annoying that we get mismatching snapshots in the diffs. Any way to avoid that?. This is not a super descriptive comment. Why does the test fail? Why do we need a global with this special name here? . I'm mostly confused at where this gets used. I don't see getTrials reading something called _Consumer.. Is this copypasta? It's not used. Same in all other tests.. It's confusing to me that a function says it \"has a reference\" just by looking at flag. Technically it doesn't even look at the \"references\" field.\nDoes the function need to be renamed to better reflect its new meaning?. What does it help your code determine (as opposed to what it does)? That should be the name. :-). For example _isContextValueKnown() or something.. What does this fix? It doesn't seem to affect the test result.. I think we should understand what's going on here before landing.. Oh okay. \u00af\\(\u30c4)/\u00af. I can try to send a clearer fix to this.. https://github.com/facebook/prepack/pull/2102. Is this using nested optimized functions under the hood? Shouldn't we also disable this when reactOptimizeNestedFunctions is false? I'm worried those are too buggy to rely on.. That's not what I mean.\nIf you look closely, the title of the snapshot has changed. So there's no way to compare them at all: they have moved.\nI'm not sure what causes it but my guess is we're adding new tests in the middle of the file, and that confuses the differ. Maybe it's time to split test-react into many files?. What's the difference between these two cases? Both are functions inside functions. Can you explain more about how this callback differs from e.g. map callback?. You can remove these changes after https://github.com/facebook/prepack/pull/2102 lands. Maybe let's also test a single update here?. Why no value?. Let's put something more interesting as default value? To ensure we don't accidentally use null for some other reason.. Let's test update too?. Let's test an update. We can remove this and use the approach from https://github.com/facebook/prepack/pull/2102. Let's test updates too. Ahh I see. You don't need to leave function itself in the output. Got it.. In that case React will give you undefined. But default context value is null in this example. Because we render it (and React treats them both as empty), I'm not sure the test would actually catch anything.\nLet's change the default value to something like \"foo\" in this test?. I don't seem to ever get into that branch when I run the tests. How do you get into it?. Can you add some? I couldn't figure out how to get it to follow this code path.\nI can't verify some things around it otherwise.. Same for branch just below.. Can you add a clarifying comment? Like\njs\n        // App + span on first render, App + div on second render. (= 4)\n        // Repeated twice (= 8) because both original and Prepacked code does it.. Please clarify where 7 comes from.. I'm worried about relaxing such a generic invariant because of our special case.\nWhy is this justified?. debug stuff. I don't understand what \"doesn't seem related to this PR\" means in this case.\nThis PR changes this line, so to me it seems related. :-)\nI'm worried that we're relaxing an existing constraint because of some change that only benefits us. It might mean that we should fix it on our side instead (e.g. by not getting into this code path altogether).\nCan you explain what this invariant is checking, and why you think checking it is no longer important in the generic case?. I understand. I'm asking to add it as a comment, similar to what I suggest in https://github.com/facebook/prepack/pull/2107#discussion_r194541733. So that when somebody changes this test, they have an easy reference for how 7 was calculated initially, and thus know whether their new result is correct or not.. Oops. Oops. This looks suspicious to me. We're mutating the source here? What if the same source is used in multiple calls, or even many times in a single call? We'd lose this information for all but the last call. So it seems inconsistent.. Do we know it improves correctness or is it a guess? It could have been a bug in the original code too. Can you explain in more detail what specifically does doing this solve?. Can we just expose them as a property on the temporal so we don't have to remember to set them in a global map?. Do you expect that there will be more places where we want to reconstruct a temporal? Or is this more React-specific?\nI don't care strongly either way. I think I'd like to have a property so we don't have to remember to track them. But if it's only relevant for our props objects then meh.. Can we cut this stuff out of the test? It seems like the essence is just having two equivalent elements.. What does this do? Removing this line doesn't seem to fail any tests.. Nit: the renaming change makes it harder to see what actually changed in the logic vs what was renamed. In the future it might be better to separate the renames from the behavior differences.. I understand\u2014I'm just saying even splitting this up in two commits would make it easier for review to a person unfamiliar with the code (like me). This doesn't seem to be tied to optimized semantics. Can this be renamed to isDefinedInsideFunction(childFunction, maybeParentFunction) or similar?. I mean the function implementation itself is generic and would work with any two functions. It's confusing to me that \"Is nested optimized function\" takes an argument called \"optimized function\". It's like if isNumber argument was called number. This makes it hard to say what you can pass in.\nSimilarly, I assume that if \"Is nested optimized function\" returns true, it means the passed function (or, rather, one of them: the function signature doesn't tell me which one is being tested), is indeed optimized. That's what the function name claims. But in practice you can easily get a true even if you passed a function that wasn't optimized.\nThis is why I think a name like isDefinedInsideFunction(childFunction, maybeParentFunction) or similar would describe what this function does more accurately. But that's not super important, just a nitpick.. @NTillmann \nDo I understand your comment correctly that scopes are not guaranteed to be in any specific order?\nOr is the problem in something else?\n@trueadm \nThat some code makes tests pass doesn't mean there don't exist other potential tests in the universe that it would cause to fail :-) Discovering these as they happen is costly because we always have to reduce the case from product code. So if we can catch more issues proactively at the time we make changes, we should try to.. Got it, thanks for explaining!. Can we make this a shared helper that takes all these things as arguments? So it\u2019s obvious this must be kept in sync with identical logic in the other file. . Why do we expect a difference in behavior and set checkRef? Seems a bit surprising. Generally in tests we try to show the behavior is preserved. . Do we check this anyhow?. When would this be false?. I think this would make the test intention clearer\njs\nif (isOptimizedForFirstRender && val !== undefined) {\n  throw new Error('Expected first render mode to not serialize ref callbacks.');\n}\n:-)\nI initially was a bit puzzled as to what we're testing.. Should this be makePartial?. It's unexpected to me that the first visit mutates this.isPure.. I think @sebmarkbage means that if you tried to assert the optimization doesn't break correctness, just executing the test and comparing inspect results (which happens anyway) would be sufficient. 1 is not 2. So this comment doesn't seem to add anything useful to the check.\nOn the other hand, there are plausible optimizations (such as returning 1 early under a condition) that would break this test but would otherwise be totally valid. So again, seems like this line just adds friction.. This looks duplicated from the above code path, can we unify?\nYou can make makePartial and makeNotPartial calls conditional but leave the try / finally structure shared.. What does this test? Why is it important to have Object.assign; in the output?. This reads simpler to me but maybe I'm missing something\n```js\n  // ii. Let keys be ? from.[OwnPropertyKeys].\n  let frm_was_partial = frm.isPartialObject();\n  if (frm_was_partial) {\n    if (!to.isSimpleObject() || !frm.isSimpleObject()) {\n      // If an object is not a simple object, it may have getters on it that can\n      // mutate any state as a result. We don't yet support this.\n      AbstractValue.reportIntrospectionError(nextSource);\n      throw new FatalError();\n    }\n    to_must_be_partial = true;\n    // Make this temporarily not partial\n    // so that we can call frm.$OwnPropertyKeys below.\n    frm.makeNotPartial();\n  }\ntry {\n    keys = frm.$OwnPropertyKeys();\n    if (to_must_be_partial) {\n      handleObjectAssignSnapshot(to, frm, frm_was_partial, delayedSources);\n    }\n  } finally {\n    if (frm_was_partial) {\n      frm.makePartial();\n    }\n  }\n```. Does inheritance really help here?\nI know we use it for the value taxonomy but I'd prefer to avoid it for the rest of the logic. I imagine you could instantiate ReactSet instead, keep it as a field, and delegate to it when necessary.. Same reason we don't use it in components? :-)\nInheritance makes the dependencies between parts very implicit. It's hard for me to tell what is the contract between ReactSet and its subclasses. Do they call its methods? Does it call their methods? Does both happen? Since all interaction happens through this.something() I have to check every method name to verify where it's defined.\nThis problem usually becomes even more difficult with time, as superclass become coupled to subclasses, and then one of them needs to behave differently but can't \"break out\".\nUsing delegation would make it clearer what ReactSet is doing, and how each of the specific \"sets\" uses this functionality.. It's not blocking, I'm just finding it harder to understand what the code is doing because of the implicitness.. What case does this handle?\nI think this would break if there was a prop called temporalAlias (very unlikely but should be easy to fix).. Can we use a symbol or an object as a key in this case? String clashes with user supplied props (which also use strings).. Maybe isReactPropsObject? A single object is called \"props\", it's not a plural in this sense.\nThe fact that it checks a set is an implementation detail. It's meant to be more of a brand check conceptually. Like isArray rather than inArrays or isArrays.. Yep.. This looks like we're trying to create an object to match the shape below. Can we instead make peace with it being undefined, and remove the invariant below? Object.assign should work either way.. Typo: \"as not\". Maybe markToSafely* because can* looks like it's asking rather than setting. typo. Can we call this propsObj or something to indicate this doesn't actually deeply traverse arbitrary objects? I didn't initially catch that.. Same nit about instanceof. This doesn't look right. Just because it might be final doesn't actually make it final. The result has a stronger assertion that might be false for the original object. Can we preserve the level of knowledge without distorting it?. It's getting pretty hard for me to understand when we need to call transferSafePropertiesToRemoveFromObjectsToProps. How do you know where to put it? What happens if you forget to? Are any tests tracking this?. Oops, GH lost my comment. Well, it said that maybe it's better to check instanceof AbstractObjectValue first (if you're trying to skip it) and then check instanceof ObjectValue. I don't like constructor equality checks because they will break if concrete objects ever become a subclass of ObjectValue.. This name is pretty generic. What does this \"clone\" exactly? What objects does it work on? What is its purpose?\nMy impression is this isn't just producing a simple shallow clone but has a more specific purpose, so might want to reflect this in naming.. How do we make it final and then immediately do an Object.assign to it? Seems inconsistent. I thought finals are treated as immutable.\nShould we do this after it's fully initialized?. I don't think it makes sense to mark this test as expecting a failure.\nThe only reason we mutate instance there is to read it during the test. It's not meant to be a test of \"writing variables\". It's a test of inlining things that use refs.\nSo if we can't use it approach, we just need to change how the test reads it \u2014 for example, by using renderer.getInstance() instead of a variable called instance.\nWe shouldn't expect this test to be broken, we should fix the test.. Why did Flow miss an argument here? Is it because it's marked as optional?\nCan we mark it as explicit union of null | (...) => ... so we don't forget to pass it around in other places?. I'm not sure this makes sense.\nWith this code, every time we enter a \"nested\" pure scope, we're reusing the same set of tracked objects. So we're effectively having them \"share\" the same top-level pure scope.\nIf my understanding is correct, every pure scope should have its own set of tracked objects associated with it. When we enter a nested pure scope, we should create a new set. When we leave it, we should restore the previous set.\nI can\u2019t immediately give you an example of why this matters, but conceptually that approach would make more sense to me. Are there any reasons why you didn\u2019t implement it that way? I can try to come up with a specific example if this explanation doesn\u2019t make sense.. I just realized that what I'm describing is pretty much what the original code was doing.\nWhy did this part need to change? I thought you're fixing the side effect detection part.. What do nested pure scopes even mean?\nNormally, a pure scope means that it's safe to make abstract calls inside it because we know they won't touch anything except what we created in it.\njs\nvar outer = {};\n__evaluatePureFunction(() => {\n  var x = {};\n  // we know `outer` won't change so we don't havoc it:\n  abstract(outer);\n  // this will havoc `x`:\n  abstract(outer, x); \n});\nHere\u2019s the scenario I\u2019m worried about:\n```js\nvar outer = {};\n__evaluatePureFunction(() => {\n  var x = {};\n  __evaluatePureFunction(() => {\n    var y = {};\n// we know `outer` won't change so we don't havoc it:\nabstract(outer);\n\n// should this havoc `x` or not?\n// my intuition is that it *shouldn't* because the inner scope is \"pure\".\n// but I think this PR would change that.\nabstract(x);\n\n// this will havoc `y`:\nabstract(y);\n\n});\n});\n```\n. I meant that the generic path can explicitly pass null. But if it\u2019s not marked as optional argument then Flow should enforce that you either pass function or null, making the decision explicit. . This comment doesn't make sense in a test.. Why does this need a default value if we're passing it explicitly?. Typo. Can we mark argument names at call sites? Like we do with /*state*/ above.\nOr turn this into object options.. I changed this to false and none of the tests failed. I know you have a long comment explaining what this does, but it didn't really help me. Can you show a practical example for why it matters?. Is this file based on some example? What's the source of truth? When this breaks or isn't sufficient with future RN versions, how will the next person fix it?. Do we need all of these options for the subset we're planning to test? It would be nice to trim it down as much as we can.. What is the source of truth for all of this? I'm sure it'll break in future RN versions.. Are you saying that any RN apps that want to use Jest also copy paste this? Or is there another way?. Why can't we use RN preset + jest.unmock to undo the mocks?. There's no argument here now, is there?. What is this about? Can this happen? Or is it just to help Flow?. Let's change it to an invariant then?\nI thought you introduced this code (I didn't see it before), do you mean it's from somewhere else?. This looks much simpler \ud83e\udd17. Please copy this comment to the other file too, it took me a bit to figure out.\nIf we want to be strict about outputting JSX, we could just generate an intermediate variable though.\njs\nvar _0 = 'RCTText';\nreturn <_0 {...props} />. ^^ this approach might be nice (assuming it's not difficult) because then we don't have to complicate logic at all output code paths with a mustVisitReactElement argument.. Wait. This looks confusing.\nWe shouldn't ever be using App in this test directly I think. It always led to bugs in the past. It should be using Root instead.\nWas this intentional?. Why would you need loads of invariants? Presumably there's just some specific callsite you introduced that caused everything downstream to want a more generic type. That's the callsite where you need to put the invariant.. Can we replace two lines above with just '**/test/**/*-test.js? Or would it not include the root /test/*-test files?. Please also change this:\nhttps://github.com/facebook/prepack/blob/afc77da9a0ec97fc1dec171fc2244326a7bfde54/test/react/setupReactTests.js#L14\nand this:\nhttps://github.com/facebook/prepack/blob/afc77da9a0ec97fc1dec171fc2244326a7bfde54/test/react/setupReactTests.js#L24\nto use src.\nPlease verify that changing files in src re-runs the tests in yarn test-react --watch mode even if you don't run yarn watch.. \u00af_(\u30c4)_/\u00af regexes are easy to mess up, I was kind of aiming at a low tech way to do this, similar to how other comment-based checks we have are low tech. What was this about?. https://flow.org/blog/2016/10/04/Property-Variance/. Sorry, I just meant that this is the only place where I know + was documented. Dunno if that changed, and haven't looked into how to use it myself.. Nit: just \"in a condition\" is sufficient. Also double space\nUnless this is really specific to && and doesn't happen with if?. Nit: maybe drop #?. I don't understand what this is supposed to test. What does <Child2 /> && <Child /> mean?\nJudging by the issue description I would assume the test would be something like\n```js\nfunction App(props) {\n  if (props.neverHappens) {\n    return \n  }\n  return null;\n}\nfunction Bad() {\n  return {}; // Invalid\n}\n```\nand then the test should check we still render successfully.. ",
    "jhalley": "Got it. I'll do the modification.. ",
    "DeividasK": "@NTillmann Hey Nikolai,\nI already found a similar function signature to what was discussed in this issue and am not sure of whether this has been implemented or not. I couldn't find any relevant PRs after a short search. Let me know if this is something that still needs to be worked on or whether this should have been closed.\nThanks!. Hey @NTillmann,\nI tried to figure out what this was suppose to be doing. I know it should always be getting an argument (or should it?), so we probably want to give a helpful error message to the user if this is used without an argument? I don't really what's supposed to be happening here.\nI'd be happy to help with this issue if you tell me what needs to be done here in a bit more detail. Thanks!. Sorry for the slow response. This seems to have been fixed now:\n\nProduces Warning PP0023: Program may terminate with exception: Called __optimize on an invalid type.\nI haven't noticed a test case for this, should I add one? If not, is there something else that needs to be done?. ",
    "karel-3d": "Oh OK! I will try to make a minimal case. ",
    "jlongster": "I just ran into this too. It's very difficult to reduce down to a test case given the nature of running prepack on a generated bundle. My bundle isn't too big, it's ~1500 lines, and here it is: https://gist.github.com/jlongster/85c2f8f313bf52af1e7996b285273587\nFWIW here's the screenshot of the error:\n\nAny tips for how to make a reduced test case? If you hit this yourself how would you do it? I suppose I can try to invoke smaller parts of the system and see what happens.. I figured it out - it's promises. How well are promises supported?\nI install a global function in my VM which returns a promise: https://gist.github.com/jlongster/85c2f8f313bf52af1e7996b285273587#file-interpreter-output-js-L257-L263. This function is available to the code my VM is interpreting.\nAt the point where my VM implements the CALL operator which calls functions, it checks the return type to see if it's a promise, and if so, it suspends the VM: https://gist.github.com/jlongster/85c2f8f313bf52af1e7996b285273587#file-interpreter-output-js-L348-L350\nIf I remove these two pieces of code (make foo return a normal value, and don't check the return type) prepack successfully evaluates my VM.\nMaybe this issue is known and promises aren't well-supported yet. . Nice, thanks. I'd like to start contributing and that seems easy enough. Hopefully I'll find time soon (if someone else want to work on it please do).. That's super cool. Even if it ever worked at one point, that's encouraging and means it's achievable. I'll check it out and see if it still works.. Do you happen to know off-hand which version of node is the last one that worked?\nDoes prepack even need to use any of the filesystem if all I want to do is give it a source string to partially evaluate? Basically, I don't want any of the CLI. It's probably not as shaky if I ignore that part of the system, as you said prepacking prepack itself is more straight-forward.. FWIW I tried to compile it tonight. Here's the webpack config to generate a bundle of prepack standalone:\njs\nmodule.exports = {\n  entry: './src/prepack-standalone.js',\n  output: {\n    path: __dirname + '/dist',\n    filename: 'output.js'\n  },\n  module: {\n    rules: [{ test: /\\.js$/, exclude: /node_modules/, loader: 'babel-loader' }]\n  }\n};\nThis generates a dist/output.js folder. Running prepare throws an obscure invariant violation though:\n% prepack ./dist/output.js --out ./dist/processed.js --mathRandomSeed rnd --compatibility node-cli\nInvariant Violation\n    at invariant (/usr/local/lib/node_modules/prepack/lib/invariant.js:19:15)\n    at Realm.onDestroyScope (/usr/local/lib/node_modules/prepack/lib/realm.js:295:31)\n    at evalMachine (/usr/local/lib/node_modules/prepack/lib/intrinsics/node/contextify.js:299:13)\n    at NativeFunctionValue.runInThisContext [as callback] (/usr/local/lib/node_modules/prepack/lib/intrinsics/node/contextify.js:115:12)\n    at NativeFunctionValue.callCallback (/usr/local/lib/node_modules/prepack/lib/values/NativeFunctionValue.js:101:53)\n    at OrdinaryCallEvaluateBody (/usr/local/lib/node_modules/prepack/lib/methods/call.js:314:16)\n    at InternalCall (/usr/local/lib/node_modules/prepack/lib/methods/function.js:136:49)\n    at FunctionImplementation.$Call (/usr/local/lib/node_modules/prepack/lib/methods/function.js:1227:14)\n    at NativeFunctionValue._this.$Call (/usr/local/lib/node_modules/prepack/lib/values/NativeFunctionValue.js:44:36)\n    at Call (/usr/local/lib/node_modules/prepack/lib/methods/call.js:495:12)\nI copied the same flags as the prepack-prepack command in package.json. Not sure what to look for since there's not much info about the invariant violation. Based on the stack it looks like it's this invariant.\n. Ok, that mostly works. Looks like it pulls in the debug module which has this code:\njs\nreturn (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\ninside a useColors function, which prepack fails on:\nIn input file ./dist/output.js(95990:18) FatalError PP0001: This operation is not yet supported on abstract value document  (https://github.com/facebook/prepack/wiki/PP0001)\nIf I just removed all the code within useColors and return false, it prepacks!\nIf I add this code at the bottom of prepack-standalone.js:\njs\nconsole.log(prepack('var x = 0; for(var i=0; i<5; i++) { x += i }; console.log(x)'))\nThen creating the new bundle and prepacking it generates a file that I can run in node (I need to go to the bottom of the file and replace }).call(this) with }).call(global) to run in node, is there a flag to automatically do that?). Running the prepacked JS output what you'd expect!\njs\n% node ./dist/processed.js\n{ code: 'x = 0;\\ni = 0;\\ni = 1;\\nx = 1;\\ni = 2;\\nx = 3;\\ni = 3;\\nx = 6;\\ni = 4;\\nx = 10;\\ni = 5;\\nconsole.log(10);',\n  map: null,\n  reactStatistics: null,\n  statistics:\n   _23 {\n     objects: 0,\n     objectProperties: 0,\n     functions: 0,\n     functionClones: 0,\n     referentialized: 0,\n     valueIds: 0,\n     valuesInlined: 0,\n     delayedValues: 0,\n     acceleratedModules: 0,\n     delayedModules: 0 },\n  timingStats: undefined,\n  heapGraph: undefined }\nBut I think I see what you mean. It will probably fail if I try to give it a program that requires part of prepack to be abstract itself. It looks like it was able to run prepack on the given program entirely in the prepacking phase, so none of prepack needed to be abstract.. Well, I bundled up my compiler+VM with this code in the entry point:\njs\nfunction runSource(src) {\n  vm.runSource(src);\n  console.log(vm.reg1);\n}\nThen pasted that code as a string into the prepack bundle, and it's now prepacking that file... been almost 5 minutes but it's still going! I doubt it will finish without an error but we'll see what happens.. But this does clarify that this isn't suited for what prepack currently is built for: optimizing the startup path, since core value (the source) isn't known AOT. It's fun to think about this though. I'll update with whatever happens and then close the issue.. It ran for a long time and then errored with this: Invariant Violation: FatalError must generate at least one CompilerDiagnostic. That's the end of this experiment. Thanks anyway!. I see in the prepack CLI it will not show any errors thrown if there are no compiler diagnostics. That's what results in seeing \"FatalError must generate at least one CompilerDiagnostic\" without any info. It might be nice to add an option or something to print out the internal error. (related to https://github.com/facebook/prepack/issues/1305)\nTurns out it was just a stack overflow, so I bumped up the stack which should fix it. Still running.. I continually tried bumping the stack size up until it's using a huge number (--stack_size=100000) and I still get \"maximum stack depth exceeded\". Not sure if it's genuinely too complicated or if it's hitting an infinite loop. Either way, this probably isn't going to work and I'll stop spamming this issue!. Oh, I just realized this is not V8 hitting it's stack limit, this is an error thrown by prepack itself: https://github.com/facebook/prepack/blob/master/src/realm.js#L362. I hardcoded a much larger stack limit and we'll see what error comes next!. That's awesome! I don't comprehend abstract values fully yet, or how prepack should work with libraries instead of apps, which is essentially what I'm doing. I'd love to study prepack more and contribute though when I find time. In the next week or so I'll try to make small tweaks.\nPrepack seems to working on prepacking my use case - but it's been running for 2.5 hours now. Not sure if it's hit an infinite loop or not. Last time I let it run for a while and it eventually finished (after an hour maybe?). In that case I forgot to export the main function so prepack just compiled it all away. Now I'm exporting a function \"run(src)\" (which will actually compile, not run) to the global scope. I'll leave it running until something happens.\n. @hermanventer would you expect it to get into an infinite loop while trying to partially evaluate it? I'm surprised it hasn't thrown any errors yet after almost 3 hours of running. But maybe it is just stuck in a loop.\nVery cool to hear that this could even be possible though. I haven't wrapped my head around what kind of code this should output, but being able to generate a compiler from my interpreter would be pretty mind-blowing and open up use cases I thought were impossible for me (as a single dev).. To put a nail in this coffin, it finally did something after 7.5 hours of running: run out of heap memory!\n```\n<--- Last few GCs --->\n[10255:0x102801000] 20261371 ms: Mark-sweep 8096.5 (8589.3) -> 8096.5 (8588.3) MB, 48354.9 / 0.0 ms  (+ 0.0 ms in 0 steps since start of marking, biggest step 0.0 ms, walltime since start of marking 48357 ms) last resort\n[10255:0x102801000] 20306160 ms: Mark-sweep 8096.5 (8588.3) -> 8096.4 (8588.3) MB, 44785.4 / 0.0 ms  last resort\n<--- JS stacktrace --->\n==== JS stack trace =========================================\nSecurity context: 0x1b8ab70266a1 \n    1: getBindingIdentifiers [/usr/local/lib/node_modules/prepack/node_modules/babel-types/lib/retrievers.js:~20] pc=0x268da40a5ce5\n    2: arguments adaptor frame: 2->3\n    3: FunctionDeclarationInstantiation [/usr/l...\nFATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory\n 1: node::Abort() [/usr/local/bin/node]\n 2: node::FatalException(v8::Isolate, v8::Local, v8::Local) [/usr/local/bin/node]\n 3: v8::internal::V8::FatalProcessOutOfMemory(char const, bool) [/usr/local/bin/node]\n 4: v8::internal::Factory::NewTransitionArray(int) [/usr/local/bin/node]\n 5: v8::internal::TransitionArray::Insert(v8::internal::Handle, v8::internal::Handle, v8::internal::Handle, v8::internal::SimpleTransitionFlag) [/usr/local/bin/node]\n\n```\n  . ",
    "GrosSacASac": "it should be written in getting started guide. ",
    "axules": "prepack v.0.2.20\nError was generated in \\node_modules\\prepack\\lib\\utils\\leak.js:513\nfunction ensureFrozenValue(realm, value, loc) {\n  // TODO: This should really check if it is recursively immutability.\n  if (value instanceof _index.ObjectValue && !(0, _index2.TestIntegrityLevel)(realm, value, \"frozen\")) {\n    var diag = new _errors.CompilerDiagnostic(\"Unfrozen object leaked before end of global code\", loc || realm.currentLocation, \"PP0017\", \"RecoverableError\");\n    if (realm.handleError(diag) !== \"Recover\") throw new _errors.FatalError();\n  }\n}\nBecause TestIntegrityLevel (\\node_modules\\prepack\\lib\\methods\\integrity.js:147) returned false in 4\n```\n// 3. Let status be ? IsExtensible(O).\n  var status = (0, _index2.IsExtensible)(realm, O);\n// 4. If status is true, return false.\n  if (status === true) return false;\n``\nNextIsExtensible(realm, O)in \\node_modules\\prepack\\lib\\methods\\is.js:116\nNext$IsExtensiblein \\node_modules\\prepack\\lib\\values\\ObjectValue.js:452\nNextOrdinaryIsExtensiblein \\node_modules\\prepack\\lib\\methods\\is.js:110\nAnd in the endgetExtensible` in \\node_modules\\prepack\\lib\\values\\ObjectValue.js:256\nFunction getExtensible was executed 1315 times on build and only once returned not true value.\nI think, TestIntegrityLevel (\\node_modules\\prepack\\lib\\methods\\integrity.js:147) should be reviewed and tested.. Stack trace\n```\nError: PP0017: Unfrozen object leaked before end of global code at 2:1 to 72834:8\nError\n    at main.ca62a6d893b65b967b8d.js:2:2\nD:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1224\n          throw err;\n          ^\nError: A fatal error occurred while prepacking.\n    at new FatalError (D:\\projects\\just_project\\node_modules\\prepack\\lib\\errors.js:48:14)\n    at ensureFrozenValue (D:\\projects\\just_project\\node_modules\\prepack\\lib\\utils\\leak.js:513:54)\n    at LeakImplementation.leakValue (D:\\projects\\just_project\\node_modules\\prepack\\lib\\utils\\leak.js:533:9)\n    at generateRuntimeCall (D:\\projects\\just_project\\node_modules\\prepack\\lib\\evaluators\\CallExpression.js:134:28)\n    at EvaluateCall (D:\\projects\\just_project\\node_modules\\prepack\\lib\\evaluators\\CallExpression.js:188:12)\n    at exports.default (D:\\projects\\just_project\\node_modules\\prepack\\lib\\evaluators\\CallExpression.js:30:10)\n    at LexicalEnvironment.evaluateAbstract (D:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1539:22)\n    at LexicalEnvironment.evaluate (D:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1527:22)\n    at exports.default (D:\\projects\\just_project\\node_modules\\prepack\\lib\\evaluators\\ExpressionStatement.js:10:21)\n    at LexicalEnvironment.evaluateAbstract (D:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1539:22)\n    at LexicalEnvironment.evaluate (D:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1527:22)\n    at LexicalEnvironment.evaluateCompletion (D:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1215:21)\n    at LexicalEnvironment.evaluateCompletionDeref (D:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1207:25)\n    at exports.default (D:\\projects\\just_project\\node_modules\\prepack\\lib\\evaluators\\Program.js:34:23)\n    at LexicalEnvironment.evaluateAbstract (D:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1539:22)\n    at LexicalEnvironment.evaluate (D:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1527:22)\n    at exports.default (D:\\projects\\just_project\\node_modules\\prepack\\lib\\evaluators\\File.js:8:15)\n    at LexicalEnvironment.evaluateAbstract (D:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1539:22)\n    at LexicalEnvironment.evaluate (D:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1527:22)\n    at LexicalEnvironment.evaluateCompletion (D:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1215:21)\n    at LexicalEnvironment.executeSources (D:\\projects\\just_project\\node_modules\\prepack\\lib\\environment.js:1327:20)\n    at Serializer._execute (D:\\projects\\just_project\\node_modules\\prepack\\lib\\serializer\\serializer.js:101:52)\n    at Serializer.init (D:\\projects\\just_project\\node_modules\\prepack\\lib\\serializer\\serializer.js:141:23)\n    at prepack (D:\\projects\\just_project\\node_modules\\prepack\\lib\\prepack-standalone.js:154:31)\n    at Compilation.compilation.plugin (D:\\projects\\just_project\\node_modules\\prepack-webpack-plugin\\dist\\PrepackPlugin.js:58:56)\n    at Compilation.applyPluginsAsyncSeries (D:\\projects\\just_project\\node_modules\\tapable\\lib\\Tapable.js:206:13)\n    at self.applyPluginsAsync.err (D:\\projects\\just_project\\node_modules\\webpack\\lib\\Compilation.js:666:10)\n    at next (D:\\projects\\just_project\\node_modules\\tapable\\lib\\Tapable.js:202:11)\n    at Compilation. (D:\\projects\\just_project\\node_modules\\purifycss-webpack\\dist\\index.js:102:11)\n    at next (D:\\projects\\just_project\\node_modules\\tapable\\lib\\Tapable.js:204:14)\n```. Hack - for prepack v0.2.7 and next\n\nOpen \\node_modules\\prepack\\lib\\utils\\leak.js\nFind function ensureFrozenValue\nUpdate this function - add false into if\nfunction ensureFrozenValue(realm, value, loc) {\n  // TODO: This should really check if it is recursively immutability.\n  if (false && value instanceof _index.ObjectValue && !(0, _index2.TestIntegrityLevel)(realm, value, \"frozen\")) {\n.... \n",
    "granthusbands": "Ah, thank you. This was a reduced testcase, but #987 is indeed required before I can make further progress. Are there any forums or IRC channels that might good for this sort of issue?. ",
    "Kingwl": "ci build failed \ni have already increase limit in https://github.com/facebook/prepack/pull/1334. I updated the valueDomain and method, then the ecma262 test was broken ...\nThis seems like a big job. i have no idea about how it work with test  built-ins/Function/internals/Construct. i guess because of in GetFunctionRealm \n\n\nAssert: obj is a callable object.\nIf obj has a [[Realm]] internal slot, then\na. Return obj.[[Realm]].\nIf obj is a Bound Function exotic object, then\na. Let target be obj.[[BoundTargetFunction]].\nb. Return ? GetFunctionRealm(target). \nIf obj is a Proxy exotic object, then\na. If obj.[[ProxyHandler]] is null, throw a TypeError exception. b. Let proxyTarget be obj.[[ProxyTarget]].\nc. Return ? GetFunctionRealm(proxyTarget). 5. Return the current Realm Record.. This is not very reasonable. Is there any suggestion?. oh my fault :XD. IMO, using value to judge types is not a good choice  . \n\n",
    "sophiebits": "\n. @trueadm made me write this, please tell me if it's totally wrong!. Forgot to push the test case, now added.. Updated with preservation of simplicity and a more specific cast.. Ah I see, I missed the havocing here. https://github.com/facebook/prepack/blob/905b9370438de15bcd99649e812ed3caa3aff67e/src/evaluators/CallExpression.js#L121\n@sebmarkbage The original motivation was to enable\nfoo = {...bar};\nfoo.baz = 17;\nPreviously it had foo as an AbstractValue but I think it should be safe to make it an AbstractObjectValue? Which Put is happier with.. I will just revert this for now I guess.. CallExpression havocs the arguments. I am not sure if we also need to mark the return value final (and if that means CallExpression is already buggy?).. This is a pretty simplified stub implementation of Component. What consequence does that have? Could it mean Prepack breaks some code it wouldn't otherwise? (I see it's not changed from before though.). This should have current: null. How does this interact with the real ReactCurrentOwner? Does this mean Prepacked createElement calls will always have no owner? Or is there some way that we should connect it to the real one?. Can we make it throw then?. I copied this from src/react/elements.js. callExpression is typed as callExpression(callee: BabelNodeExpression, _arguments: Array<BabelNodeExpression | BabelNodeSpreadElement>): BabelNodeCallExpression but AbstractValueBuildNodeFunction has Array as argument. These aren't compatible.\nIf the flow types for t.callExpression are updated to take a $ReadOnlyArray then it doesn't need the cast. Not sure if we can just change flow-typed? I assume the changes are meant to be pushed upstream to flow-typed/too.. This is missing getChildContext right? Maybe intentionally?. no braces? :|. ",
    "bvaughn": "Related issue facebook/react/issues/12089. ",
    "neilmacintosh": "Basic support is done. But to have solid support for switch statements, what remains (at least) is:\n- handling cases that result in abrupt completion other than \"break\" (return, throw etc).\n- proper handling of i/o operations that might occur inside the cases\nThe tests are also fairly basic currently. I'm sure there's a few corner cases around strange things you can do in switch statements which will need some sort of change made to support them.\n. After chatting with @hermanventer I'm going to rework this so it doesn't disturb the interpreter code so much (among other things) and issue a new PR. Thanks for the help @cblappert! I'll be sure to use those suggestions in the next PR.. Thanks @hermanventer, going to land the corrected PR and move on to the next phase.. I think I've addressed all the comments except the one about throwing AbruptCompletions. That exposed a bug in my handling of them which I'd like to postpone to the next PR.. Ok. Updated title, summary and tag. Added proper emission of a compiler error (at least I think so) and a wiki page for the new error.. Ah, thanks! I was wondering the right way to emit an error like that. invariant(false) felt a little hacky.. Nice. And so I learn how the test framework goes...;-). Makes perfect sense, will do. \nIf input is a ConcreteValue but the case selectors result in AbstractValues (which I'm assuming is a possibility) I would think we would still want to take the abstract interpreter path. But if such a thing is possible then I can deal with that wrinkle in a subsequent revision.. Ok. I'll kill this PR and try again!. Oh nice, I didn't realize!. Yay. That helps shed light on what Reference is. ;-). yep!. Of course. Note that in this case I am not making up exception classes. I am calling functions with those names that return the usual FatalError. I just wanted to wrap them up rather than repeat the code to report the diagnostic and throw the error each time I wanted to do it. So is using a wrapper function like this to do what you described a problem?. Makes sense, but Isn't that what happens? I think GetValue() makes result an AbruptCompletion in that case and then the test in the loop header will break out of the loop.. Makes sense!. Yay! Will remove it.. excellent. I can simplify this then.. ok.. Yep. I was trying to avoid having two if-then-break tests scattered around the loop, but...ugly as it is....it is probably much easier to understand. I'll change it.. Good point! Especially in Javascript where things are much more free flowing than my most recent implementation language (not good or bad...just different ;-)).. Interestingly, this then caused my tests to fail. It looks as though I have a little bit of work to do around handling Abrupt and PossiblyNormalCompletions correctly (beyond completions arising from break statements). So I've left it to error out of abstract evaluation if it sees a case that ends up in AbruptCompletion for now (just without the use of the helper function to do so). That way I can focus on finishing up this PR and addressing the completion issues (and i/o effects, expanding tests etc) in the next one.. Ah! No. Nice catch.. Ah yes...leftover from moving out the breaks. I'll kill it off, thanks.. ok. makes sense. I think your next comment has the punchline here ;-). Aha. I see now. I'll go look into how to do that and update this PR appropriately.\n. Yep.. Ok. Can you confirm that the correct place to describe the (hopefully temporary) limitation is here: https://prepack.io/frequently-asked-questions.html?\n. Ignore that, I found it! OK...do I create a PR for the change to the wiki or just edit it directly? If I edit it directly, do I do that before landing the PR?. Ok. Created the page and uploading another diff to see if I have the error handling right.. thanks!. ",
    "kedromelon": "interested in helping out here. having trouble reproducing though -- is more context needed? i seem to be seeing a compiletime TypeError in the repl when i pack this snippet: \nhttps://prepack.io/repl.html#PrCGGdwVwWwUwCKgC6gAoCcD2AHOHkBPACmQAsBLcAGgAIAiLAIwCs4BjZW5OcZeuiFBM+GUJ2L0A3jgBctAIwAGJQF8BDZm060ANhR5jd9AJQmA3ACggA. ",
    "sendilkumarn": "@NTillmann  I agree that this is tricky. \n\nneed to extend the existing test-runner.js \n\nThinking whether we need this, the test cases seems to run without any issues  (I may be wrong completely). @hermanventer sorry I missed this completely. \n@trueadm I would love to have some help with this. Is there any doc or wiki available for this? . ",
    "VictorHom": "was wondering if the issue with the infinite loop is fixed - I don't think the posted example when run through prepack causes an issue anymore. Trying to see if there's a trace I can follow or if I'm not reading the issue correctly.\nOtherwise, I could use some direction on the max iteration bail if that's something that is doable.. still trying to get around the project, but it might be in realm:325 in testTimeout, the throw might need to be updated from throw new _errors.FatalError(\"Timed out\");  to  something like \nthrow new _errors.CompilerDiagnostic(\n        \"Possible time error\",\n        loc,\n        \"PPXXXX\",\n        \"TimeError\"\n      );\nso we can surface a more descriptive error\nI can help get a pr if that's the general correct issue to fix. The reason I set as === is to make sure to throw since the original code just threw. If I set it as !==, it won't hit the throw. When I run with the timeout flag and !==, I get the following repeat trace. I have to take another look if we shouldn't just throw in the timeout check\nat Realm.testTimeout (/src/devenv/node-v8.11.1-darwin-x64/lib/node_modules/prepack/lib/realm.js:302:23)\n    at LexicalEnvironment.evaluateAbstract (/src/devenv/node-v8.11.1-darwin-x64/lib/node_modules/prepack/lib/environment.js:1285:16)\n    at LexicalEnvironment.evaluate (/src/devenv/node-v8.11.1-darwin-x64/lib/node_modules/prepack/lib/environment.js:1278:20)\n    at ForBodyEvaluation (/src/devenv/node-v8.11.1-darwin-x64/lib/node_modules/prepack/lib/evaluators/ForStatement.js:179:25)\n    at exports.default (/src/devenv/node-v8.11.1-darwin-x64/lib/node_modules/prepack/lib/evaluators/ForStatement.js:99:12)\n    at LexicalEnvironment.evaluateAbstract (/src/devenv/node-v8.11.1-darwin-x64/lib/node_modules/prepack/lib/environment.js:1290:20)\n    at LexicalEnvironment.evaluate (/src/devenv/node-v8.11.1-darwin-x64/lib/node_modules/prepack/lib/environment.js:1278:20)\n    at exports.default (/src/devenv/node-v8.11.1-darwin-x64/lib/node_modules/prepack/lib/evaluators/WhileStatement.js:8:15)\n    at LexicalEnvironment.evaluateAbstract (/src/devenv/node-v8.11.1-darwin-x64/lib/node_modules/prepack/lib/environment.js:1290:20)\n    at LexicalEnvironment.evaluate (/src/devenv/node-v8.11.1-darwin-x64/lib/node_modules/prepack/lib/environment.js:1278:20). If we use the invariant method, https://github.com/VictorHom/prepack/blob/ad9b7d11d08f151a71c958f5eaf4b21088698b12/src/invariant.js#L17\nwill set the name of the error to be \"Invariant Violation\", so that will still be there. Is that alright?. That makes sense. A misunderstanding from me on what invariant meant. I'll fix. ",
    "kurtextrem": "The code where I have observed this, is here: https://github.com/kurtextrem/Twitch5/blob/master/worker.js\nBefore prepacking, replace this line: https://github.com/kurtextrem/Twitch5/blob/master/worker.js#L12 with const \u0412\u0415\u0420\u0421\u0418\u042f_\u0411\u0420\u0410\u0423\u0417\u0415\u0420\u0410 = 60\nWhy I created this issue, see here (it's minified and... the REPL doesn't work as I said so I can't show you the unminified result): https://github.com/kurtextrem/Twitch5/blob/master/worker_pre.js\n```javascript\n\"use strict\";\nvar \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u0442\u044c,\u0411\u0440\u0430\u043a\u043e\u0432\u0430\u0442\u044c,\u0417\u0430\u0432\u0435\u0440\u0448\u0438\u0442\u044c\u0420\u0430\u0431\u043e\u0442\u0443\u0418\u041f\u043e\u043a\u0430\u0437\u0430\u0442\u044c\u0421\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0435,\u0417\u0430\u0432\u0435\u0440\u0448\u0438\u0442\u044c\u0420\u0430\u0431\u043e\u0442\u0443\u0418\u041e\u0442\u043f\u0440\u0430\u0432\u0438\u0442\u044c\u041e\u0442\u0447\u0435\u0442,\u0412\u044b\u0431\u0440\u043e\u0441\u0438\u0442\u044c\u0412\u041f\u043e\u043c\u043e\u0439\u043a\u0443,\u041e\u043a\u0440\u0443\u0433\u043b\u0438\u0442\u044c\u0420\u0430\u0437\u043c\u0435\u0440\u041a\u0443\u0447\u0438AsmJS,AsmJS,\u041f\u043e\u0442\u043e\u043a\u0411\u0438\u0442\u043e\u0432,IsoBaseMedia,ID3,\u0421\u0440\u0435\u0437,\u0421\u0440\u0435\u0437\u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438;\n(function(){var t=Array(2),\n```\nPrepack creates a new variable and initializes it with Array(2) why and what for is unknown to me, but see OP why new Array(2) should be preferred \n(I think [] is even better as this is probably used for array operations, not to optimize initiation - but that's up to you guys as Prepack is for optimization initiation?) . @NTillmann Out of curiosity, what/how did you bench?. ",
    "miyaokamarina": "Similar issue on Linux, node v9.11.1, npm v5.8.0, yarn v1.5.1: console output.\nLooks like it's v8-inspector's issue.. ",
    "giansalex": "Thanks!. ",
    "sb98052": "Updated to cover the provided example, with the example added as a test case.. Updated with rerun-till-fixpoint logic.. Done. The block evaluates to undefined without the fix, and 1 with it.. Thanks! I appreciate your prompt feedback.. This bug is triggered by nested abstract tests in optimized functions that end in possibly normal completions. In the above example, if arg !== null can be replaced by any abstract test, e.g. if arg.bar. There are two issues at the join point at the exit from the optimized function, when the normal and abrupt completion paths are merged (joinEffectsAndPromoteNested -> joinGenerators).\n1) The join condition in the merge contains a conditional captured temporally in the inner of the two tests. The serializer does not see the declaration for this abstract value and bails with the invariant failure reported in this issue.\n2) The join condition is incomplete, and contains only the innermost condition, instead of the entire path condition, leading to the generation of incorrect code.\nA brief exchange with @hermanventer suggested that fixing this might get lumped into some refactoring and design work that he will be doing.. Happy to let you take care of it. But let me sum up my progress.\nThe issue seems to be that while Realm.joinEffects selectively captures Effects for the the Normal side of PossiblyNormalCompletions at branch joins, the converse does not happen at subsequent joins.\nI've made a change that tries to fix the latter higher level joins. This fixes the bug and passes tests. If it's the right idea, I can go ahead and submit a pull request (with a test).\ndiff --git a/src/methods/join.js b/src/methods/join.js\nindex 27741dc..fa6eafd 100644\n--- a/src/methods/join.js\n+++ b/src/methods/join.js\n@@ -434,8 +434,12 @@ export class JoinImplementation {\n     if (precedingEffects) realm.applyEffects(precedingEffects, \"\", false);\n     try {\n       if (c instanceof PossiblyNormalCompletion) {\n-        let e1 = this.joinEffectsAndPromoteNested(CompletionType, realm, c.consequent, e, c.consequentEffects);\n-        let e2 = this.joinEffectsAndPromoteNested(CompletionType, realm, c.alternate, e, c.alternateEffects);\n+        let preceding_for_consequent = (c.consequent instanceof AbruptCompletion)?c.consequentEffects:undefined;\n+        let preceding_for_alternate = (c.alternate instanceof AbruptCompletion)?c.alternateEffects:undefined;\n+\n+        let e1 = this.joinEffectsAndPromoteNested(CompletionType, realm, c.consequent, e, preceding_for_consequent);\n+        let e2 = this.joinEffectsAndPromoteNested(CompletionType, realm, c.alternate, e, preceding_for_alternate);\n+        \n         if (e1.result instanceof AbruptCompletion) {\n           if (e2.result instanceof Value)\n             e2.result = new CompletionType(realm.intrinsics.undefined, realm.currentLocation);. Yes, that does what I was looking for.. Closing. Superseded by #1875.. @trueadm Done. I've updated the release log. This is the set of changes to package.json starting with your fbjs fix.\n```\n--- a/package.json\n+++ b/package.json\n@@ -1,6 +1,6 @@\n {\n   \"name\": \"prepack\",\n-  \"version\": \"0.2.37-alpha.0\",\n+  \"version\": \"0.2.37\",\n@@ -67,6 +67,7 @@\n     \"babel-traverse\": \"^6.9.0\",\n     \"babel-types\": \"^6.9.0\",\n     \"babylon\": \"^6.18.0\",\n+    \"fbjs\": \"^0.8.16\",\n@@ -91,7 +92,6 @@\n     \"eslint-plugin-flowtype\": \"^2.40.0\",\n     \"eslint-plugin-header\": \"^1.0.0\",\n     \"eslint-plugin-prettier\": \"^2.1.2\",\n-    \"fbjs\": \"^0.8.16\",\n@@ -1,6 +1,6 @@\n {\n   \"name\": \"prepack\",\n-  \"version\": \"0.2.37-alpha.0\",\n+  \"version\": \"0.2.38-alpha.0\",\n``\n. Never mind. This test passes fine.. I've addressed the issues brought up in the comments, and also significantly refactored the leak-accounting logic. Instead of dealing with leaks where modified properties are joined (joinModifiedProperties), leaked objects are now collected and passed on for joining at a more opportune point, when the rest of the effects have been applied. This is necessary to carry out materialization correctly and in the right order in the face of other accesses to the same object. Leaked objects have been made an optional field of the Effects structure, and the materialization part of leaking and havocing has been moved to ObjectValue.js.. Take 3. I have addressed the review comments. The main other change is the addition of the materialization path tosingletons.jsto break the flow dependency cycle betweenhavoc.jsandrealm.js. I spent a fair bit of time trying various gymnastics, such as declaring the HeapInspector class, breaking it up, and moving code around betweenObjectValue.js,join.jsandhavoc.js`, but could not find a way short of this approach to break the dependency.\nThis changeset raises a number of future tasks, but I feel that they should be handled separately in the interest of keeping this set of changes focused on the issues it is intended to address. Some of these are:\n\nFactoring out redundant behavior between getSnapshot and materialization\nMaking a deep pass through the code base and changing the terms havoc, leak and materialize to the appropriate term\n\nI would be happy to add issues for these items and assign them to myself.. I've addressed the last batch of review comments.. I've addressed the latest batch of review comments.. Rebased to master to facilitate checkouts of this PR. Please do not review.. Abandoning this pull request. The only part left that has not been merged is \"making leaking unconditoinal.\" It is not clear how the implementation in this request factors into the changes coming up in LVA, or if at all. To rethink.. Thanks for your review. I think I understand why not \"derive.\" It pertains to algebraic expressions, not arbitrary code. So you can derive a value at a given point in the program but you cannot derive a blob of code that should be injected or passed around from that point. \nBesides this I found only two uses of derive other than deriveConcrete and deriveAbstract. These are deriveGetBinding and deriveState, and both of these eventually call deriveAbstract (the latter conditionally).\nI've renamed __invariant to __assume, and added some code to link the static and dynamic cases. That is, __assume asserts if possible, and outputs a compiler diagnostic if the assertion fails. I'm assuming this (renaming) is ok by @NTillmann. \nI think I have addressed all of your comments.. Thanks very much!. Thanks!\nActually, this change no longer passes the React internal bundle. It did a while ago. Looking into the source of the regression.. Kindly ignore changes on this PR. I am coordinating with @trueadm at the moment, who is helping debug the failure with the internal bundle. . I dug into this a bit, and found the issue to manifest itself in joinDescriptors when it gets executed for the join between the exceptional and normal paths. By this time, the effects for the alternate path of the if have already been applied via evaluateWithAbstractConditional -> applyEffects, and joinDescriptors concludes that the value it sees is from before the split.\ncc @hermanventer . @NTillmann and @trueadm helped produce a small repro, then @NTillmann in fixing it. The repro (see below) will be checked in as part of #2302.\n```js\nfunction leaker(g, c) {\n  let o = { foo: {}};\n  o.proto = {};\nif (c) {\n    g(o);\n  } else {\n    o.foo = {bar: 5};\n    g(o);\n  }\n  return o;\n}\n__optimize(leaker);\n```\nThe key is an object with a custom prototype that gets leaked and has its properties accessed in multiple scopes.. To my mind, there are two main parts to the long term plan. The first is to decouple the notions of leaking, havocing and materialization in the code while continuing to preserve the model that relates these things and leads to the generation of correct code, without pathological duplication. The second is to come up with a system to soften the impact of values leaking, such as by better accounting of aliasing, and with some of the tactics @NTillmann has described in his quip doc (leaking for reading, leaking for writing). A third would be to possibly guard assumptions that we make if we do not do all three of these things together.\nI'm going to be working towards the goal incrementally in the weeks to come. If we merge this code, and @trueadm materializes without leaking, then the duplication I optimized out in #2302 will regress, but only for the specific case of abstract array methods (which hopefully shouldn't be too bad). I can deal with eliminating that in a future increment, possibly by basing it on prior materialization, rather than prior leaking.\nI'll go ahead and rename the  method \"materializeLeakedObject\" to \"materializeObject\" - the old name is a remnant of the tuple that paired a generator with an object.\n@trueadm needs recursive materialization - I'll follow up with him to see what we can do without that. I would certainly not want to add it to this PR, in the interest of keeping PRs small and focused.. A few things are happening here. First, the code with which these problems were reported is old. @trueadm's type-based refinement changes, i.e. https://github.com/facebook/prepack/commit/1986d760a53a23196a6439265a3c8e8e006cbb79 make the problem go away, for .toString(). This is because with this change, when the type of x is known, x.toString() turns into '' + x. Before the change, a runtime call was being generated. I suspect that the root of the problem was the a-temporal nature of this runtime call.\nSecond, abstract-concrete unions get simplified based on the path condition. This simplification is correct only if subsequent operations on the union yield a-temporal results. The interesting case here is when path conditions simplify a temporal value into being a-temporal..toString() is an example of this. x.toString() as a runtime call is temporal, but simplified into x + '' is a-temporal and safe.\nThere seem to be three approaches to dealing with this problem in general:\n\nEnsure that all such runtime calls that are temporal.\nDerive AbstractValues when simplifying them in a path-specific way\nMake AbstractValues that may be simplified in a path-specific way temporal to begin with (e.g. the AbstractValue in abstract-concrete unions)\n\nIf we do (2) or (3) the .tostring() example above would stop working, even though the path implies that expressions with x.toString() can be lifted.. I think what this boils down to is: any expression (not only call) that can throw or generate side effects conditionally should be temporal. Is there a way that implicit toStrings can be manipulated to do that?\nEven with toString runtime calls gone, there are still cases that lead to this problem. I'm going to create separate issues for these.\nAn interesting one is the in binary operator, which throws if the right hand side does not have type object, because it is not created via AbstractValue.createFromTemplate. My attempt to trigger the problem however led to a different bug (#2406).\nProbably, more auditing will be needed to temporalize all such cases.. Thanks. I've addressed the comments, and this time confirmed that when // instant render is removed, the tests fail with the appropriate errors. Also some contortions to make node expose Instant Render's __empty embedded in an array, since trailing __empty builtins do not increase the length of the array.. Thanks. Digging in a bit, it seems that Nikolai is right. It guards against the possibility of overridden toString or valueOf calls. The line that causes the entries to turn into temporals is this: https://github.com/facebook/prepack/blame/c89f511102e3eb05ce17ad6788d6e442ad5cb9a7/src/evaluators/BinaryExpression.js#L95\nIt seems right (and nice).. This is fine. The way the object n is declared sets the values domain to a singleton with that object. . Input:\n```js\n(function () {\n  let o = __abstractOrNull(\"object\", \"o\");\n  let s;\nif (o != undefined) s = \"foobar\" in o;\n  if (o != undefined) s = \"foobar\" in o;\nglobal.s = s;\n})();\nOutput:js\n(function () {\n  var _$0 = this;\nvar _3 = o;\n  var _6 = _3;\nvar _5 = _6 != void 0;\nvar _1 = \"foobar\" in _3;\nvar _0 = _5 ? _1 : void 0;\n_$0.s = _0;\n}).call(this);\n})();\n.js\n(function () {\n  let o = __abstractOrNull(\"string\", \"o\");\n  let s;\nif (o != undefined) s = 5 + o.length;\n  if (o != undefined) s = 6 + o.length;\nglobal.s = s;\n})();```. It's fantastic that you were able to get this working.\nThat said a few aspects of this conflict with my long term roadmap that it would be good to get resolved.\n\n\nThe terminology you have used is inconsistent with the one that we have been moving towards. We want to use leaking and havocing as principled terms based on the conditions in which they occur, rather than definitions that are tied to the implementation. It's not clear to me what the purpose of cloning leaking and havocing is (is it to transitively materialize, if so, we should extend MaterializeImplementation). And why do we need to track them with two flags. For havocing, we have topVal. For havocing of bindings we don't have this - but that needs to be fixed (#2446).\n\n\nIt is not clear to me that \"leaked for read\" and \"leaked for write\" should be attributes of a binding. Environment bindings that are transitively captured by a function and written to should get materialized before the call and leaked and havoced after. Ones that are only read should transitively materialize. But I think the binding itself should be represented with leaked and havoced values (#2446).\n\n\nAnother thought is that keeping this state beyond calls only makes sense if the capturing function leaks into the environment, which I think we don't support for nested optimized functions. So we could, at least for now, make it a requirement that the function is not leaked and only used once. That ought to fix this test:\njs\nfunction f(c) {\n  var arr = Array.from(c);\n  let a = 0;\n  function op(x) {\n    let y = 5;\n    let z = 7;\n    let v = y + z;\n    return v + a;\n  }\n  let ret0 = arr.map(op);\n  a = 2;\n  let ret = ret0.map(op);\n  return ret;\n}\n__optimize(f);\ninspect = () => f();\nI propose that we proceed in two steps: \n1) Unblock the current use case by merging in what is necessary - namely, materializing \"bindings that are read\" transitively.\n2) This should buy us time. In the meantime, we coordinate progress on the rest.. I think a more complete statement of the criterion would be \"the value produced by the template can throw under a condition that is not precluded by the assumptions under which the template is used.\" This is the root of the specific bug that this PR tries to knock off, since such dynamic conditions are sensitive to simplifications by the simplifier. \nThe general problem of formalizing the constraints under which something can be atemporal and balancing those constraints with efficiency is still open, and this PR doesn't help with that.. > > \"the value produced by the template can throw under a condition that is not precluded by the assumptions under which the template is used\"\n\nThis seems like circular reasoning to me. This can only be used under the conditions we use it.\n\nMore like \"This can only throw under the conditions in which it is expected to throw\" which is not circular. It's the throwing under certain conditions that is precluded, not the conditions themselves. But my phrasing didn't help in making this clear.\nThat said, the distinction is irrelevant if the precondition for a value to be atemporal is that it never throw at runtime.\nI do see your concern - my approach makes some values atemporal in a conditional setting, but at the cost of making many others temporal, even in an unconditional setting. As a side effect of my change, calls to String.length and such would never get lifted, and that's bad.\nI'll try to come up with an approach that strikes a better balance, given these parameters.\n. Very nice. Herman's insight strikes the balance we want, and also refines the criterion. In general, a value must be temporal if it is dynamic (can throw, side effects). The assumption that something is not dynamic may itself rely on dynamic parameters - and those should be temporal. Conversely, if a parameter is temporal, then a value that relies on such an assumption becomes temporal too.\nI've updated my implementation to do this. Also, I have added inverted tests to make sure that the operations I have touched get lifted in the unconditional case.\nThis is still work in progress because turning on the currently commented out invariant in createAbstractConcreteValue breaks a few things. Also, some tests are breaking and have to be fixed.. I'll allocate a new one for the condition in __assume and add it to the wiki.. Thanks. Some of this code is indeed problematic, in a way that clarifying the terminology exposes. We are effectively mixing checks amounting to isHavoced, isLeaked and isInitialized for bindings. I was planning on fixing that next. I just went ahead and created an issue, #2446. Perhaps we need a new abstract domain for locations.\nIn general, the comments around the uses of these routines are not as helpful as they could be. I have noted your feedback and will incorporate it when I make a pass over the comments.\nI did add the invariant for abstract interpretation when materializing bindings.. That's an option. Another operation is to add a flag alongside hasLeaked. @hermanventer proposed using something compatible with abstract interpretation semantics (set the value to the top of a hypothetical abstract domain). This might make things like joining somewhat more convenient, going forward. To discuss.. Oh, I should have been more precise - we don't have to reject the this binding - just take it into account when rejecting aliasing effects. So if you alias up this to the contents of the array or other non-local objects, then it leads to the same issues.. I squashed because I moved a fair bit of code around while proofreading the code, so not sure if a diff would have been useful. The main changes:\n1) Fixed the issue with intrinsics being materialized:\nhttps://github.com/facebook/prepack/pull/2456/files#diff-7c5d0dd678054fc89e7eb35f66582c28R692\n2) Supported bound functions and fixed a few other issues by not treating the main optimized function specially:\nhttps://github.com/facebook/prepack/pull/2456/files#diff-7c5d0dd678054fc89e7eb35f66582c28R609\n3) Fixed some cases in which certain values would not be get traversed.\n4) Added a reduced version of your repro as a test caes (MaterializeObject0). More of these on their way.\n. Added a few more tests. Verified that they fail without this changeset, and succeed with it. I will add more tests covering other materialization paths in the future. For now, removing the WIP tag.. Thanks. I'll create issues for the points that are not already lumped into future work. Some others, I will resolve before landing.. So the way I see it, \"widened identity\" is a way of representing aliasing. The notion fits in like a glove because in traditional alias analysis, there are two ways of representing aliasing information - keeping track of the set of objects that point to a given memory location, or associating an alias set with every object. Your solution uses the former approach.\nMy thought, for dealing with leaking, had been to use the latter approach - to associate a set of possible aliases with every aliasing location. Nothing special has to be done as long as we don't lose precision. So in let obj3 = c ? obj1 : obj2 it is computable at any point that obj3 may alias obj1 or obj2. One place at which you lose precision is if you call an external function. So when you call obj3 = leak(obj1, obj2) obj3 may alias obj1 or obj2. This is useful to track, because if you assume that leak is pure, as long as you don't mutate obj3 or obj2 accesses to obj1 do not have to be derived (as they currently are).\nI think the difference between the two cases is that in your case, widened identity means an abstract object must alias the objects in the set - but in my case we want to track a partial set that the object may alias. Not sure how to reconcile these two use cases.. > Looks fine to me; except that I expect to run into issues when the everything including the module table is getting marked as final. But we can deal with it when we get there.\n@NTillmann Note that accessing such objects lead to recoverable errors for Instant Render. . Ok, I'm going to abandon most of this - but keep a small nit I fixed in the process. I'll solve the problem this was to address differently.. Updated to address comments:\n- We now leak the array operator on second specialization, and invalidate the function for specialization forever. Previously, pessimistic leaking would be invoked on every subsequent specialization.\n- May alias sets propagate through Array.map chains\n- We leak when an indexed property of a widened numeric array is accessed (previously materialized). It also fixes #2564, which was caused by the same problem. The path condition x == null was being expanded using a conjunction instead of a disjunction, as x === null && x === undefined But x === null => x !== undefined, so the second condition got discarded, effectively creating the assumption x == null => x===null.\nI've added the other repro as a test as well.\n. Can you summarize what exactly you need this additional information for in the effects data structure?. Ok, thanks. So you are saying that you have a heuristic for deciding whether a function should be inlined or outlined, and that heuristic relies on whether abstract values reachable from the return value of the function were created inside or referenced from the outside? Is that the totality of the heuristic? \nI'm drilling in here because I ran into very similar issues when dealing with the effects of array operators, which depend on whether objects were created inside or outside. Also, to my mind effects track state that is mutable - such as property and binding locations, which AbstractValues are not.\nSo bear with me a bit longer :-)\nWhat if an abstract value is created inside, but all of its args refer to pre-existing values? E.g. (outside boolean)?(outside object 1):(outside object 2). Then does the function not fall into the outlinable category? If so, then the test isn't \"if an abstract value was created.\" Rather \"if external locations are reachable from the abstract value.\" And this is what I implemented for the array case.. >  If all args of an abstract value are also all created in the function then we know it's not safe to re-model\nDid you mean \"if any of the args of an abstract value are created in the function?\"\nThere are two types of abstract values that get created - ones that are reachable via the return value, and ones that involve mutations to non-local state. Assuming that the functions you are dealing with are pure, it's not clear to me why the check does not amount to \"are created objects reachable from the return value.\" \n. Right, it is a summary that consists of two things: the functional part, i.e. the return value, and the side effects part. I was referring to the side effects part when I said \"tracks mutable locations.\" It appears to me that for pure functions, abstract values go into the functional part - because they don't reflect a function's behavior, but rather how we model that behavior. It might be that the information needed is computable from the return value, as here:\nhttps://github.com/facebook/prepack/blob/b942cd9635ee36787e1ea878616714ade7380799/src/values/ArrayValue.js#L146-L148\nI should put up a PR shortly that cleans the API up.\n. @trueadm You have a valid point. My logic (even the modified version I'm going to submit) cannot determine whether temporals reachable from the return value were created within the function or passed from the outside. I wonder though if what we need is a \"temporal interactions\" field that tracks temporals, rather than all abstract values. Those certainly fall into the \"side effects\" category since they summarize an aspect of side-effectful behavior. And it pertains to the analyzed code, rather than to our modeling constructs.\nOne thing that will happen if you track all abstract values is that since abstract values are immutable, every time one is transformed, it will show up in createdAbstracts. So if you have something like if (foo == null) and the simplifier expands it, you'll get three new abstract values. These will include values that are not reachable from the return value of the function. Again, if all you want to check is whether something in there is temporal, then it should work - but the field might end up accumulating a lot of clutter.\n . Yep, coming up, as mentioned in the description.. No worries - the test is now in.. The point was to verify that the tag used is a keyword, so that if somebody renames it or tracks it differently, then this code breaks. But I can do something to make sure it's only called once.. I tried a slew of different tests to break your unconditional leak declarative bindings patch. This one I decided to keep (don't quite remember why). If you think it's covered by something else, I can drop it.. Will do.. It is more appropriate if we retain flow sensitivity for the _isLeaked flag, it is not more appropriate if we drop this flow sensitivity. \nThe purpose of this pull request is to deal with competition between materialization of object properties via the generator timeline, and interpretation, which is independent of the timeline. The outcome is duplicated code caused by the creation of object properties both via materialization and object initialization. For the non-branched case, this is easy to fix - if an object is leaked, you suppress the serialization of the second kind of initialization. For the branched case, it is more involved (and may also affect correctness - although I could not come up with a test case equivalent to #2007). Nikolai's idea was to handle it by eliminating flow-sensitive \"materialization.\" If an object is leaked, it is leaked and materialized along all consequent as well as alternate paths.\nThis effectively eliminates flow-sensitive leaking in practice, so if we do this, then there is no point in tracking it via abstract conditionals.. See #2208 . The emphasis on being befuddled and the characterization thereafter detracts from what is a simple question, \"Why the term Advice?\" It was a loose reference to this - https://en.wikipedia.org/wiki/Advice_(programming). What is being proffered is some logic or computation that is to be woven in at a future join point.. This comment provides no information, beyond your being uncomfortable with this. The point of the renames I did was to clarify the difference in the code between these two concepts. Do you disagree with the changed use at this code site? Do you disagree with it in general? Please be more precise.\n. The great pity to me is that ObjectValue.getSnapshot is not documented, as is not the model of which it is a part. Nonetheless, I will see if I can somehow decipher its behavior and reconcile it with my changes.. No offense was taken. The unguardedness of my own impressions is just as amenable to the analysis of code as it is to the code itself. If this is unacceptable, then I shall refrain. I hope that I correctly interpreted your question and was able to clarify my terminology. In the next version (to be put up soon) I have changed the name of this function to computeJoinedLeakPropertyAndLeakedObject.. I see. We have leaking and havocing, which are intertwined, but not a term that is a union of the two things that can put at points dominating such uses. I will try to come up with a proposal (or at least fix this case).. Thanks. Comments would certainly be helpful. Right now, the materializeInGenerator function factorizes out code that was already in the (old-terminology-) havocing implementation. As such, if there is any redundancy between these two things, then it is pre-existing, and out of scope for this pull request. I would be happy to take on the task of reconciling the two things in a separate task.. I teetered between the two options, both of which are unsatisfying. With one you get a redundant Set, with the other you spill the void type outwards, all the way to the LeakedObjects type, get asymmetry in the Set, Map tuple (in the MapAndSet data structure, one can be undefined but the other can't). That invariant was the reason for the redundant Set in the previous version. I dislike both options, and chances are, every time somebody points out the infelicity of one, I will rush towards the other.. I think I have found a good middle ground, and fixed a typing bug that helps eliminate some unnecessary annotations and invariants.. I considered several alternatives, and the motivation for capturing the generator at the leak point, creating a LeakedObject type, and modifying the Effects structure was to pass it here, as this is the point at which all of the information needed for materialization comes together. If you materialize into the current generator at this point, you will see the object being built post-join. If you materialize where bindings and properties are joint, you will see disembodied objects missing property bindings, and unexpected deletes because descriptors that applyEffects eventually populates are not present at that point. This deletion logic is quite involved and I am glad I avoided colliding with it with the approach that I took.\n. Done. Yes, things get complicated with getters and setters, especially if they cross reference other properties in the object.. I have added a comment to that code.. See #2295 . I will look into it, and submit a separate pull request if I come up with something.. This condition should be precluded by the check in 1141.. Precluded by 1187. Precluded by 1192. I have a rather basic question. Now that we are doing full joins, why do we need to retain the tree structure of completions? Why not make completions a set of summaries for each type, e.g. NormalCompletions, ReturnCompletions etc. and join path conditions in addition to values in this method. The summary would need to include the path condition in addition to the value. Doing so should eliminate a great deal of redundant work later on when path conditions are pushed, i.e. in pushPathConditionsLeadingToCompletionOfType and friends, which traverse the tree repetitively.  You could still retain the type of the completion as a predicate on the size of the constituent sets.. Yes, the index properties of widened arrays are not backed by locations, so no materialization is needed. I'll add an invariant that fails if this every changes.. Eventually it should go away. Right now, it is dangling out of the leaking implementation. . Dropped.. True. We ought to use the interpreter to compute the set of non-local bindings: #2478. Using the interpreter should eliminate this #2478.. Done. There was a case I wanted to cover, it's now checked in as a test.. I have added an invariant to ensure that it empties out after rewinding down the scopes, and added an issue #2484 to deal with global environments.. #2 - Lumped into the larger, #2485.\n1 - The function is handled by line 804, which visits the object properties of a function. We now have an invariant that insures that the array value is intrinsic, and so property accesses are at best temporal.\nI have added a test for the function-object case.. My assumption was that these lead to intrinsic values, which do not need materialization, but I have just dropped the exceptions. This call now fails, and will be dealt with as part of #2484.. Could you elaborate what you mean by \"don't add function values to the objects to materialize?\" An example would help. The main outer function (i.e. the array op) is passed to computeFromFunctionValue which in turn explores its properties.. Fixed.. Thanks, I should have emphasized that the implementation is work in progress. I am yet to audit all of the paths that lead to this invariant.. It was inverted. On the other hand, it is not obvious to me that InternalJSONClone can create the particular conditions that this PR is trying to fix. So I have dropped this check for now, and will audit in a follow up request.. I'm going to enforce this protocol in a follow up PR that addresses #2489. Doing so will involve auditing uses of all of the abstract value factory methods.. I've deferred this to the refactoring in #2489.. My changes broke the test by causing the value of f to be derived in the consequent branch of f && f(), which counts as a second occurrence of f; Since the derivation is legit, I considered updating the comparator to two. But upon digging further I found that I could not reproduce the original problem that you fixed with #1158, even after reverting your change, making me doubt if it was still relevant, so I dropped it. But in hindsight, now, perhaps it is not a bad thing to keep it around as a regression test, so I have added it back.. Ok, I'll find another way to do this.. This I've fixed.. There is no debugger in the output (as observed in the exchange about the empty_statement op). . I agree that it is bikeshedding. However, now that you brought it up, I prefer \"NOOP.\" \"EMPTY_STATEMENT\" ties in with other constants used lexically. But try a google search for \"NOOP\" and then one for \"EMPTY_STATEMENT\" and decide which one contains more signal.. @trueadm Oops - Not sure why I didn't see your comments. Perhaps you approved, and added the nits afterwards.. @trueadm I thought about adding does not contain: debugger when I checked in the test, but decided to leave it out because there's no path for it to get there. I added the test as an illustration of how to use this helper, and for test coverage. But I'm happy to add the line - it helps with documentation, as well.. I put it in as a reminder for whoever adds support for filter (in case it's not me) that the leaking semantics of these various operators are different. So for instance, a non-mutating filter cannot alias. I was also planning on adding it soon.. Yikes. Good catch. It was auto-added by VSCode. Perhaps we need a lint rule for this.. Ok. I've set it to:\n    // We currently do not support context-sensitive specialization,\n    // where the calls we specialize depend on the specialization context.\n    // TODO: #2454\n    // TODO: Implement context-sensitive specialization instead of giving up. wfm :-).\n",
    "lxfind": "We probably don't want to do an abstract concatenation here, because according to the spec, if either name or message is abstract value, we have to evaluate that value, check if it's undefined, and if so replace with it with something else. That would make the generated code too long. I propose we just remove those two checks regarding the abstract value, and not handle prepacking Error object with abstract name/message at all.\nbtw it also misses one step (Step 7) according to http://es5.github.io/#x15.11.4.4\nApparently the ECMA website missed this step.. ",
    "olydis": "@NTillmann Also combine emitPossiblyNormalReturn and emitJoinedAbruptCompletions to emit IfThenElse or keep the \"facade\" as is?. closed via https://github.com/facebook/prepack/pull/1889. @NTillmann Will also look into other refactorings you mentioned in the issue, but wanted to get feedback on this part for the time being (I literally guessed certain pieces, e.g. the fact that I just instantiate Generators and give them the same realm... I'm not 100% sure about the implications; might also be missing out on existing helper methods etc). . lol especially since that function already exists \ud83d\udc4d . Fair point, this is actually the spot that confused me before and led me to create that (not anymore) buggy test case; so I didn't wanna touch it before being sure about why value is not required. From further investigation I now assume that all the things I wanted value to be are part of effects (where I also saw stuff happen in recent commits, presumably fixing my test case).. ",
    "infinnie": "@hermanventer But it looks somewhat different from what it is like in non-strict mode.. So\njs\nvar Thing = (function () {\n  \"use strict\";\n  // do something\n  var x = 1;\n  return function () {\n    x++;\n    return x;\n  };\n})();\na = 1; // mixed strict and non-strict modes\nis compiled into\n```js\nvar Thing;\n(function () {\n  \"use strict\";\nvar __scope_0 = Array(1);\nvar __scope_1 = function (__selector) {\n    var __captured;\nswitch (__selector) {\n  case 0:\n    __captured = [1];\n    break;\n\n  default:\n    throw new Error(\"Unknown scope selector\");\n}\n\n__scope_0[__selector] = __captured;\nreturn __captured;\n\n};\nvar _0 = function () {\n    var __captured__scope_2 = __scope_0[0] || __scope_1(0);\n__captured__scope_2[0]++;\nreturn __captured__scope_2[0];\n\n};\nThing = _0;\n  a = 1; // implicit global assignment which is not allowed in strict mode\n})();\n```\nHowever, in the compiled result of the source code\njs\nvar Thing = (function () {\n  \"use strict\";\n  // do something\n  var x = 1;\n  return function () {\n    x++;\n    return x;\n  };\n})(), a = 1;\na is correctly declared ahead of the function execution.. ",
    "chanakyabhardwajj": "\n\nCreate a new wiki page with the PP error number as its name.\n\n\nWhat's the best way to submit wiki edits? Once the (code) PR is approved/merged, do you also merge the wiki changes from the fork?. >>  first add a wiki entry...\nI apologize if I am mistaken, but I can not edit the wiki at all (as I am not part of the organization). That\u2019s why I asked this question. . Would the following workflow be acceptable?\nhttps://gist.github.com/larrybotha/10650410. That would (imho) simplify it for everyone in the future. However, I am happy to contribute whichever way suits you the best.. ",
    "bernard-lin": "We could also host it on the site instead of on the wiki?. Got it, thanks! \nAlso, do you know what I have to do to run the ECMA-262 tests locally since the test262 folder links to another repo? Should I just clone that repo into that folder?. @hermanventer, any tips on writing tests for abstract operations?\nWould I use the __abstract operation? (e.g. __abstract('object', '({toString() { return \"x\"; } : 3})') \nI always seem to run into the invalid syntax error first.\nThanks for the help!. @NTillmann PP0036 already in use by https://github.com/facebook/prepack/pull/1910. Should I rename the other one then?\n. since you already made a wiki page for this one?. ",
    "Andarist": "I've adjusted the second call as well.. ",
    "bomsy": "I would love to work on this!. ",
    "dsgkirkby": "I tried removing the filter for destructuring-binding (results for ES6 tests only):\nAll tests\nMaster: 5427 / 6116 (689 failed - 92.9% pass rate)\nBranch: 5684 / 6116 (432 failed - 91.6% pass rate)\nAdded tests only\nMaster: 1168 / 1468 (300 failed - 79.6% pass rate)\nBranch: 1389 / 1468 (79 failed - 97.1% pass rate)\nI haven't dug into exactly what's failing but I think that's probably good enough to enable these tests?. Update:\n- It seems that circleci runs less tests than locally so I've lowered the expected passes to match how many pass there\n- The added failures are due to lexical environments being leaked, which looks like it might be an issue with generators - those failures are happening on master for some generator-related tests. ",
    "omoabobade": "Currently working on this, i noticed there is no documentation concerning error codes, or do i just use arbitrary error codes for those not existing in the wiki yet? For example i want to throw error for an havoced object.. ",
    "caiismyname": "Screenshot of new behavior on the code snippet that previously caused the REPL to crash\n\n. @cblappert Is this more like it? Also, not sure where the parameters (except name of file containing code being tested) should come from -- read in from some comment block in the test code or hard coded into the foo.test.js runner as params?. Will do. I put it like that originally to avoid confusion with the actual flag (the flag itself is --heapGraphFilePath so I kept it the same). Without it, we run into the following problem:\nIn the provided example\n(function () {\n  let a = __abstract(\"number\", \"a\");\n  let b, c;\n  global.f = function() {\n    b = a + 42;\n    c = a + 42;\n  }\n  __optimize(f);\n})();\nwhen the ModifiedBindingEntry does the .visitModifiedBinding, there is a .visitEquivalentValue(newValue) call on the new value, and the returned newValue may not match the original (it's replaced by the \"equivalent\" value if one is found). This happens to us in this test case because of the \nb = a + 42;\nc = a + 42;\nsince the a + 42 look the same. The assignment realigns the state to what is expected by the invariant assertion. \nThis problem actually seems to be at least somewhat independent of the problem caused by the cache/ResidualFunctionBinding, but it was in the same code area and also causes the code to crash. \nIt seems that the more fundamental issue is that we're re-traversing a the heap, which has some sort of assumption that it won't be re-traversed.. @yinghuitan was saying then that it might be easier to detect and reject calls to __optimize() when the --heapGraphFilePath flag is given, since the two haven't been made to work together yet. Would that be a more relevant solution? . Wasn't sure what to give these fields since they're not really applicable. Suggestions?. Currently it's just manual -- I was going to accumulate them until I had a chance to write a test runner. Will remove from commits until the runner is made. I see. I just tested it and it does affect correctness -- I had assumed it was simply an optimizing heuristic. Question: What benefit does this provide StepOver? It seems like its if (currentStackSize <= this._startStackSize) check would always be sufficient and correct. . What do you mean? This test file is 2-space indented, and so are the existing tests. . Upon further investigation, it seems like this same line causes the same bug in stepOver. . The message should be optional, since it is only used by debugger Diagnostic messages and nothing else. The most appropriate default message for non-diagnostic cases would be nothing (\"\") -- should I go with that? That solution collides with a previous comment of yours:\n\nBetter yet, provide a default message that is not blank.\n\nThis message also can't be combined into the reason field, since StoppedReason is a flow enumeration of strings -- we can't enumerate all possible error messages.. Yes, that is true. This is an artifact of the whole out-of-order commits. That will be addressed in the PR that fixes nuclide integration.. The wrapper is so future features can also use this. For example, row/column indexing support, as well as sourcemaps, will all be passed through this structure. \n\"Launch\" is a bit misleading -- would \"DebuggerConfigArguments\" work better?. The checks happen in two distant locations. The best way to share would be to create a utility in Utils, and everything currently in there seems more involved than a two line check. I think creating/importing such a utility would create more confusion than clarity.. You're right, the _ensure... call is unnecessary but the invariant needs to be there to satisfy flow (I believe because the previous call to this._adapterChannel.registerChannelEvent messes with its \"knowledge\".. Same as above (line 66), flow. . @yinghuitan since I need the invariant for flow, should I just keep the this._ensureAdapterChannelCreated call for readability purposes?. I see that does satisfy flow, but it seems like a very unintuitive way of writing code -- I've never seen a global var. re-assigned to a local for use within a function (unless the goal was some copy+mutate operation). \nWhile two invariants is slightly more verbose and ugly, it would be clearer that flow was the reason, instead of some potentially unseen intention.. I see. I initially thought it was the act of calling a method on an object that triggered flow -- protecting against external code modifying the object makes more sense now.. Removing because the purpose of the IsStatement check is to only step once per line. This is taken care of with the change in checkAndUpdateLastExecuted that ignores columns.. Moved DebuggerConfigArguments here to address cycle issue. Also moved DebugChannel in here to consolidate all debugger related arguments into one wrapper. Had to remove DebuggerConfigArgs from realm to avoid import of ./types.js to avoid flow cycle. I originally decided against calling it \"initialize\" because it's run only when the sourcemaps are a certain format, whereas \"initialize\" implies to me that it would run unconditionally. \nEdit: Nevermind, I found a better way to aggregate everything. Updated. Will hold off putting in a link until documentation goes on the public-facing wiki. Wiki would be more accessible than Quip. Addressed in comment a couple lines down. It's not. Using an array requires some Nuclide changes which I will put into a separate PR. For now, I've refactored the code so that as much as possible is handled as an array.. Will look into this for next PR addressing Nuclide UI issues.. Different files not found can lead to different levels of corruption -- a missing input file vs. a missing source file (which may not even get opened). Perhaps it should error if an input file, prepack, or sourcemap can't be found, but let it go if a source file isn't there?. yarn pack creates a .tgz file. If we use node-fs to read that file, then use node-zip to zip that file (which is how all the other files are zipped), when we unzip the overall zip file created by node-zip, the .tgz is corrupted -- attempts to unzip it from the commandline fail with a \"unrecognized archive format\" error, and attempts to open it using GUI archive utilities produce a .cpgz which indicates a problem in the zipping process.. Inputs without sourcemaps won't have a sourcemap or sourcefiles, but we still can zip in the input files. The input filenames were saved when reading CLI arguments, and thus don't need to be passed in. Will clarify in a comment\n. Whoops, didn't realize that success controlled error code. Thanks. Initially because SourceMap was no longer specific to the debugger. However on further thought, this condition is not an error. It is explained in the comment:\n\nA buckRoot is unnecessary if there are no sourcemaps to translate between.\nIt actually causes paths to become incorrect, preventing proper files from opening.. Just did. Sorry, I don't understand your suggestion:\nRather put the new optional argument at the end\n\nThere is no new argument -- I'm removing debuggerConfigArgs. Are you saying to add a dummy optional argument to the end of the PrepackSources parameters? \n. Would like to note here that this process.exit() has the potential to cause a race condition:\nThe last if (!success && reproMode === \"none\") process.exit(1); must check reproMode because generateDebugRepro involves an async process (directory zipping). If there is an ongoing repro and the process exits, the repro may terminate prematurely, causing no repro to be generated. Instead, this only triggers if there is no repro -- if there is, the generateDebugRepro function will handle process exiting if it needs to. . buckRoot is just an CLI input. It can be disregarded if there are no sourceMaps. \nI'm saying there is a way to proceed if we are given a buckRoot but no sourceMap, and doing that does not necessarily mean an error will occur.\nEDIT: Also it looks like I accidentally reverted to the wrong version of this code. . The \"buck\" part of buckRoot does not refer to an invocation of the buck build system -- it refers to the format of the sourcemaps when they're generated by Buck. \nThe buckRoot is still necessary because the format of the sourcemaps hasn't changed. If we want to open the correct original files, we still need to perform the same relative/absolute translation which requires the buckRoot, which is done by the SourceMapManager. @NTillmann ^^\n. Hmm, I actually believe these fields are unnecessary in general, as the launchRequest handler in the DebugAdapter automatically generates these fields. So the information is required for debugging, but it's not necessary for the user to input them. \nWould you happen to know what situation they're meant for? Otherwise I'd assume they were created to help bootstrap the debugger but are no longer relevant and can be removed.. Oops, changed to DebugReproManagerType. The previous code was to get around the singletons pattern, where DebugReproManager is a value of type DebugReproManagerType. . The list of files is passed in both flags, but the FatalError flag is more pertinent since this is the error object. I will clarify the comment though\n. Ah, does it also circumvent the function test is not found errors?. ",
    "pmrcunha": "I'll try to find out why the test isn't passing as soon as I have some time! \ud83d\ude1e . I removed the utility. Thank you for the explanation!. Thank you! It was a great learning experience.. What would you say is more readable, to keep destructuring:\njs\nlet {\n    result: result1,\n    generator: generator1,\n    modifiedBindings: modifiedBindings1,\n    modifiedProperties: modifiedProperties1,\n    createdObjects: createdObjects1,\n  } = realm.evaluateForEffects(...\nor to name the objects and call their properties directly ?\njs\nconst e1 = realm.evaluateForEffects(...)\n...\nnew Effects(e1.result, e1.generator, e1.modifiedBindings, e1.modifiedProperties, e1.createdObjects),\n.... I had prettier-eslint turned off. I'll fix it.. I went for the second option whenever possible, as it is a bit more terse.. I have now realized that in Flow x === undefined is as safe as typeof x === \"undefined\". Should I convert my changes to the first option, which I believe is more readable?. I do this because flow strict doesn't allow mutation of function parameters, and the linting rules don't allow re-declaration.. name === undefined? Or was the previous implementation incorrect?. Is this not the case when an output filename is not provided? Wouldn't it be outputFilename === undefined || outputFilename === \"\"?. outputFilename !== \"\" would allow for filename to be undefined.\nI'll instead check for outputFilename !== undefined and check for both undefined and empty string in the if statement. ",
    "ahmad2smile": "Ran into this one while trying prepack. I do think its related to a while loop I got in a saga using redux-saga for polling. Oddly enough If I add wait/delay in catch block of saga CRA build show drop in bundle size. Waiting on #2118 \n. ",
    "felicianotech": "Already signed the CLA ^. Maybe there's simply a delay in the system?. I believe that some weirdness due to that the check is from my own CircleCI account and not Facebook's.\nMerging this PR, or pushing your own branch with the code from someone who's a collaborator on the repo should initiate a new build under Facebook's org.. ",
    "rpkoller": "Same situation and error with version 0.2.39 which is live on npm now. :/ Retried with 0.2.41 and Node 10.5 now, but same result. ",
    "LaRuaNa": "Currently v10.5.0. Yea seems like some mocks are failing. I'm checking it but might need some help. I'm not that much familiar with prepack codebase yet :). Since yarn fails checking dependencies i can't use yarn upgrade so i removed yarn.lock and that causes a lot of changes because yarn updates several packages. Moreover seems like there are another packages depending on upath. And the reason why react tests fail seems to be an incompatibility with react-relay which is also updated from 1.4.1 to 1.6.0. Well, since yarn fails while checking packages i can't run yarn add -D. But I'll give it a try in a container with compatible node version\nEdit: There are another dependencies like babe-cli and watchpack which also need to be updated. But they don't contain the fix yet. So I'll come up with a fix when those are updated.. @trueadm Thanks for fix works well :). ",
    "Guru107": "@NTillmann Hi, \ud83d\udc4b Can I work on this? Don't have much OSS contributing experience. Looking forward to it. Let me know. @NTillmann @hermanventer I came up with a color scheme, have a look. \nI tweaked the SVG logo a bit and removed the background. Let me know if that is ok?\n\nUsing original logo\n. @trueadm I had removed the green background and made the arrow green.. With white hero text and logo.\n\nCheck out the code block theme\n. ",
    "Gyran": "This sounds interesting to look at. Any pointers on where to start looking?. Should the output be just nothing?. ",
    "enzoferey": "Hi @NTillmann, I would love to take this issue !\nAs far as I see this would be something like adding another clause here: https://github.com/facebook/prepack/blob/067a378227d0c2034aa963c8981cf243356f349a/website/js/repl.js#L170 with a \"warning\" type branch and modifying: https://github.com/facebook/prepack/blob/067a378227d0c2034aa963c8981cf243356f349a/website/js/repl-worker.js#L40 to dispatch a \"warning\" instead of just success/error, right ?\nI will need to look further on Prepack code to know how warnings are formatted in order to know which kind of result to dispatch.\nDo you we want to display the generated code as well as the warning message underneath ?\nBtw, I come from the React podcast, very interesting episode !\nEDIT:\nfound that severity: \"Warning\" in the buffer can be used to fix these issue. I'm fixing it and opening a PR.. It should be closed, yes. And same than @bencooper222, let me know if there is anything else you need help with !. I would be glad to fix it but can't find that screenshot anywhere on the website. @Aladdin-ADD . Not sure how to fix this because it is CircleCI dependent and I don't even know if non facebook people can do it. \nWhat I saw is that it looks like the \"latest\" build tag is not working properly, because if you try with other builds ids it works.\nThe \"website\" issue label should removed imho, not related. . Fixed an unnoticed issue with heap graph. It doesn't seem to work anyways because the boxNetwork variable created from the data is never used (it never worked it seams). Plus when warnings happen but code is still generated (as it is the case with the snippet from the issue), no graph data is returned from the compiler (that's why I added an extra check against undefined).\nThere is a lot of discrepancy in code style along the repl.js and repl-worker.js as arrow functions are sometimes used, sometimes not; var keyword is used sometimes, others let is used instead...\nI don't know how clean you want this code to be, but I could refactor it at the same time I add the warnings display.\nAlso, I noticed that error messages overflow the code result box and other CSS issues.\nI think having a great playground plays an important part in getting people excited about the project, it should be very smooth imho.\nLet me know what you think \ud83d\udc4d. Hi @NTillmann, thanks for the feedback.\nI think the best is to work first on the logic and displaying messages next to code and later on discuss about formatting in a different PR as you suggested. I agree on the CI check.\nI have updated the branch without any formatting change and I will work on the remaining task in the next days \ud83d\udc4d. So... I had some time before the weekend ! \ud83d\udc4d \n@NTillmann, I have covered the requested changes and added support to display the messages and the code at the same time. Furthermore, every message has it owns node rather than just appending them in a single big one as it was done before. This allows showing multiple messages of different types and have proper styling on each of them !\nI took heavy inspiration from the Google Chrome DevTools console for color palettes. Let's see how each case looks like:\nError\n\nWarning\n\nErrors\n\nWarnings\n\nError and warning\n\n\nMy only concern is in the first error screenshot for example, we have a first line with the error code and basic info and just underneath the stack which might seem like a another error. This is because Prepack sends the errors split. There are several ways to fix it but I would need to know if every time Prepack sends an error without a code field means it's related to the last error (see below line):\nhttps://github.com/facebook/prepack/blob/2457103e19b1de6b4347e2b522b67e63aee2e31a/website/js/repl.js#L132\nI hope this was what you wanted, have a nice weekend ! \ud83d\ude80 . Hi @hermanventer !\nDo you mean having error messages at the bottom of the source pane and warnings at the bottom of the generated code pane ?\nRegarding the highlight of the errors it should be possible as we have code line and position data from the errors. Would having the line with a red background and showing the error code on hover would be okay for you ? Or hovering on a message highlights the line it's refering to ? Both ? Do you have any idea of what would feel natural to you ?. Okay ! \nSo I have moved all messages to the bottom of the source pane. How it looks:\nError:\n\nWarning:\n\nError and warning:\n\nRegarding the source line code highlight, @hermanventer could you please confirm that the current functionality is enough ?\nHave a nice weekend !. Hi ! \nWouldn't it be better to have a valuable feedback message like \"// There was some error. Please check left pane\" instead of a empty output ?\n. Done !\n\n. Thank you guys for working on such a complex and game changer project. Let me know if you want me to help out on any other website related issues/improvements (we talked earlier about code formating and code quality).\n. Great, didn't know about it, thanks.. Okay ! :+1:. ",
    "bencooper222": "Shouldn't this be closed or is there still something I can help with?. ",
    "zjijz": "I think I responded to your comment about the placement of the throw statement, but let me know if I missed something. I also wasn't sure if the diagnostic error for PossiblyNormalCompletion should be removed.. The three tests that are failing were pre-existing tests meant to throw inspection errors, but instead are throwing Infeasible Path errors.\nTest should have caused introspection error, but instead caused a different internal error!\nError: Infeasible path explored\n    at pushRefinedConditions (/home/circleci/project/lib/utils/paths.js:9:16417)\n    at PathImplementation.withInverseCondition (/home/circleci/project/lib/utils/paths.js:9:4192)\n    at JoinImplementation.updatePossiblyNormalCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:15838)\n    at updateNonAbruptCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:15295)\n    at _singletons.Path.withCondition (/home/circleci/project/lib/methods/join.js:9:16575)\n    at PathImplementation.withCondition (/home/circleci/project/lib/utils/paths.js:9:3047)\n    at JoinImplementation.updatePossiblyNormalCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:16286)\n    at updateNonAbruptCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:15295)\n    at _singletons.Path.withInverseCondition (/home/circleci/project/lib/methods/join.js:9:16134)\n    at PathImplementation.withInverseCondition (/home/circleci/project/lib/utils/paths.js:9:4277)\nError: Infeasible path explored\n    at pushRefinedConditions (/home/circleci/project/lib/utils/paths.js:9:16417)\n    at PathImplementation.withInverseCondition (/home/circleci/project/lib/utils/paths.js:9:4192)\n    at JoinImplementation.updatePossiblyNormalCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:15838)\n    at updateNonAbruptCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:15295)\n    at _singletons.Path.withCondition (/home/circleci/project/lib/methods/join.js:9:16575)\n    at PathImplementation.withCondition (/home/circleci/project/lib/utils/paths.js:9:3047)\n    at JoinImplementation.updatePossiblyNormalCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:16286)\n    at updateNonAbruptCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:15295)\n    at _singletons.Path.withInverseCondition (/home/circleci/project/lib/methods/join.js:9:16134)\n    at PathImplementation.withInverseCondition (/home/circleci/project/lib/utils/paths.js:9:4277)\nShould I revert my handling changes and keep the test cases and then move on from the issue? I would be willing to help out on this, but I'm not sure on where to get started on it.. I have been running yarn test-serializer --filter Switch3. The test file is located at test/serializer/optimized-functions/Switch3.js. \nIt has an expected FatalError test that should pass (because we're expecting it), but the test still fails. \nI have some more work to do reverting my changes in this PR, but I need to make even more tests that expect FatalError so I need this part done.. Ready for review. These changes to test-runner were taken from https://github.com/facebook/prepack/pull/2303, which had a similar change on the test runner event handler.\nThe test suite won't pass the new tests if I revert code, even if split up into their own files because FatalErrors were previously not recoverable in the test framework. I also had to manually add the extra returns in SwitchStatement for when the FatalError does need to recover to finish the test.. Summary:\nThe fix for PP0027 that I attempted to fix was replacing:\n(Line 90)\njavascript\n...\n    } else if (result instanceof AbruptCompletion) {\n      // TODO correct handling of PossiblyNormal and AbruptCompletion\n      let diagnostic = new CompilerDiagnostic(\n        \"case block containing a throw, return or continue is not yet supported\",\n        result.location,\n        \"PP0027\",\n        \"FatalError\"\n      );\n      realm.handleError(diagnostic);\n      throw new FatalError();\n    }\n...\nwith\njavascript\n...\n    } else if (result instanceof AbruptCompletion) {\n      throw result;\n    }\n...\nWhen I implemented this, all additional test cases added by this PR were successful (besides Switch5, which is blocked by PP0037). However, test/serializer/abstract/Switch.js was failing with error:\nTest should have caused introspection error, but instead caused a different internal error!\nError: Infeasible path explored\n    at pushRefinedConditions (/home/circleci/project/lib/utils/paths.js:9:16417)\n    at PathImplementation.withInverseCondition (/home/circleci/project/lib/utils/paths.js:9:4192)\n    at JoinImplementation.updatePossiblyNormalCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:15838)\n    at updateNonAbruptCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:15295)\n    at _singletons.Path.withCondition (/home/circleci/project/lib/methods/join.js:9:16575)\n    at PathImplementation.withCondition (/home/circleci/project/lib/utils/paths.js:9:3047)\n    at JoinImplementation.updatePossiblyNormalCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:16286)\n    at updateNonAbruptCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:15295)\n    at _singletons.Path.withInverseCondition (/home/circleci/project/lib/methods/join.js:9:16134)\n    at PathImplementation.withInverseCondition (/home/circleci/project/lib/utils/paths.js:9:4277)\nError: Infeasible path explored\n    at pushRefinedConditions (/home/circleci/project/lib/utils/paths.js:9:16417)\n    at PathImplementation.withInverseCondition (/home/circleci/project/lib/utils/paths.js:9:4192)\n    at JoinImplementation.updatePossiblyNormalCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:15838)\n    at updateNonAbruptCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:15295)\n    at _singletons.Path.withCondition (/home/circleci/project/lib/methods/join.js:9:16575)\n    at PathImplementation.withCondition (/home/circleci/project/lib/utils/paths.js:9:3047)\n    at JoinImplementation.updatePossiblyNormalCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:16286)\n    at updateNonAbruptCompletionWithValue (/home/circleci/project/lib/methods/join.js:9:15295)\n    at _singletons.Path.withInverseCondition (/home/circleci/project/lib/methods/join.js:9:16134)\n    at PathImplementation.withInverseCondition (/home/circleci/project/lib/utils/paths.js:9:4277). The tests won't \"pass\" when run though. CI would say that all of these new tests failed (which was the issue I kept running into before).. It would only carry on in an environment where handling a FatalError returned \"Recover\", which was only happening in tests.. ",
    "hotsnr": "@calebmer @trueadm The main point of creating this modeling was that mechanism under __abstractOrNull is not working properly (see #2158). If your model always has optional: false then there it may not have such a value for you.. This is to be rebased. It was 0 by the time I started.. This means that I need to extend deriveAbstract. Also I should handle case for undefined in createTemporalFromBuildFunction. Are you ok with this? And why there is no handling of null in createTemporalFromBuildFunction?. Hmm, I forgot to actually use my change in this place. My point is that inside createTemporalFromBuildFunction has if (resultType === UndefinedValue) { but doesn't have this trick for NullValue.. This double unwrapping was needed after this change. As a consequence here it is possible to get my ObjectValue wrapped in AbstractValue (union) or/and to get my ObjectValue having an AbstractValue (union) with function value. I haven't unwrapped anything in __optimize implementation because I'm not sure that it is safe there. Is it ok to do this in such a way? Or is it better to unwrap function value directly in __optimize implementation?. It is not possible because a non-string argument to __optimize will produce an error. Should I support it? It is unlikely that models are going to be provided as something dynamically evaluated.. ",
    "rahilvora": "Hey @NTillmann I am very new to open source contribution and I would love to work on this issue. Should I go ahead with it?. Sure. Will try it :). PR for this issue:  https://github.com/facebook/prepack/pull/2403 . @NTillmann Can you please tell which error message I should add for this issues which will help a developer to understand the error  https://github.com/facebook/prepack/wiki/Prepack-diagnostics . Hey @NTillmann  can i work on this issue ?\n. @trueadm Sure.. I believe it should not be a warning but an error as bug says \n'In the implementation, it shouldn't check via an invariant that the argument is a proper value, but instead, it should throw a user-level exception or emit a CompilerDiagnostics error.'\nShould I replace warning with error?. ",
    "aladdin-add": "it was in readme in the repo: https://github.com/facebook/prepack#status. ",
    "kdex": "The v8 profiler in and of itself is fine; it's just the (seemingly unofficial?) node bindings that are causing these issues, i.e. the v8-profiler package.\n\nIs there another profiler with better support?\n\nI would reckon so. I just stumbled upon v8-profiler-node8, which (despite of its name) claims to also support node 10.x.\nI tried to install it on my machine, and it built just fine. Maybe you could experiment with substituting the node bindings and see if it also works with your test matrix?. ",
    "giftkugel": "You're welcome, but I am not happy, that I am not passing some checks ...\nFirst the yarn prettier-all check failed because I didn't know about it.\nNow I am failing the flow version; flow check check. \ud83d\ude1e \nBut the old code was passing arg also directly to debuggerConfigArgs.diagnosticSeverity which is Severity type. Did the old code pass the flow type check?. It was not necessary to insert that call of the invariant method again, as I wanted to omit a method call which does not have any function.\nI have added a flow type cast to the line and that fixed the flow type check.. I restored the invariant method again. \ud83d\ude04. ",
    "matthargett": "@sebmarkbage it looks like some simple lint fixes will make this go green:\n```\n/home/circleci/project/src/intrinsics/dom/document.js\n  16:8  error  'invariant' is defined but never used  no-unused-vars\n/home/circleci/project/src/intrinsics/ecma262/JSON.js\n  28:10  error  'ValuesDomain' is defined but never used  no-unused-vars\n/home/circleci/project/src/intrinsics/prepack/global.js\n  29:10  error  'ValuesDomain' is defined but never used  no-unused-vars\n/home/circleci/project/src/intrinsics/prepack/utils.js\n  23:10  error  'ValuesDomain' is defined but never used  no-unused-vars\n/home/circleci/project/src/values/ObjectValue.js\n  13:10  error  'ValuesDomain' is defined but never used               no-unused-vars\n  52:10  error  'createOperationDescriptor' is defined but never used  no-unused-vars\n```. if it passes on master, is there a missing test that should be added? or is the internal test difficult to reduce?. #2596 was merged, so can this be closed now?. ",
    "Simek": "Part of index.html without Prepack plugin:\n<div id=\"app\"><div class=\"organization-module login\"><div class=\"notif__container \"><span></span></div><div class=\"login-wrapper\"><section class=\"login-box\"><img src=\"/public/logo-small.png\" class=\"login-logo\" alt=\"\"><div id=\"form\"><div class=\"field-wrapper\"><label for=\"username\">User</label><input type=\"text\" class=\"\" autocomplete=\"off\"></div><div class=\"field-wrapper\"><label for=\"password\">Password</label><input type=\"password\" class=\"\" autocomplete=\"off\"></div><button class=\"button green\">Login</button></div></section><div class=\"login-img\"></div><div class=\"login-bg\"></div></div></div></div>\nPart of index.html WITH Prepack plugin:\n<div id=\"app\"></div>. ",
    "dabugen": "Hi Herman,\nthanks for your reply. I was using https://prepack.io/ and I guess this site is not run by you guys then? Sorry if that is the case. Do you know of any other website where I can use Prepack without such a low timeout?\nThank you :-). Yes, I\u00b4d be absolutely eager to see what Prepack would do to such a complex program and how it can optimize it, to see how I can further optimize my code. It\u00b4s a program that is being run 24/7 with a steady 100% CPU load, so every optimization in terms of efficiency is very important to me. OK, I will try this way then. Thank you very much.. ",
    "kkeita": "I think it's possible that an object change from being exotic to ordinary  (or from ordinary to exotic) during it's life time.  Looking at the spec at 4.3.7, it looks like an exotic object is defined in term of having  non regular \"internal slots\", since those slots are writable properties, an object might start as ordinary and become exotic afterward. \n. ",
    "nijiaju": "You are right. '&=' is better.. Here is the issue. CreateDataProperty returns a boolean which is not a legal operand for bitwise operation. So, I guess we have to keep the code as it is.. ",
    "luckyharryji": "When figuring out the test cases, I tried to console.log here to see the result of  \"ToString(realm, string)\", which print the format like \"Mon Mar 13 2017 14:43:02 GMT-0700 (PDT)\". This string format is the result of toUTCString() function of Date object in JavaScript, which can also be used as the parameter of Date.parse(string), but does not being defined in date time format in http://www.ecma-international.org/ecma-262/7.0/#sec-date-time-string-format.  Should we handle this now? @hermanventer  @NTillmann . ",
    "vladima": "good point. ",
    "schandragit": "@NTillmann I am not sure improvements to Flow, which we discussed recently, include reasoning about control-flow infeasibility.. ",
    "marcindobry": "It was supposed to be a joke since the README has two options of installing prepack, both using yarn :/. ",
    "fromcelticpark": "Typo in Memrory. I'm not really sure, that !mightHaveBeenDeleted is the right condition here to check against.\nBut without this check tests were failing with the following error:\n```\ntest/serializer/abstract/PutValue11.js\nOutput mismatch!\noriginal code\nvar c = global.__abstract ? __abstract(\"boolean\", \"false\") : false;\na = {};\nif (c) a.f = a;\ninspect = function() { return 'f' in a; }\noutput of inspect() on original code\nfalse\ngenerated code in iteration 0\nvar c;\n(function () {\n  var __empty = {};\nvar _$0_unique27277 = this;\nfunction 3_unique27277() {\n    return 'f' in $0_unique27277.a;\n  }\nc = void 0;\n  var _0_unique27277 = false;\n  c = _0_unique27277;\n  var _1_unique27277 = {\n    f: void 0\n  };\nvar _2_unique27277 = _0_unique27277 ? _1_unique27277 : __empty;\nif (_2_unique27277 !== __empty) _1_unique27277.f = _2_unique27277;\n  a = _1_unique27277;\n  inspect = _3_unique27277;\n}).call(this);\noutput of inspect() on last generated code iteration\ntrue\n```. Yeah, I will look into it in the current pull request.. ",
    "patxu": "Ah I see, yes I'll add the https prefix.. ",
    "mostafaeweda": "This file doesn't seem very useful (it's mostly all any) & I can't find it in https://github.com/flowtype/flow-typed -- which should be the source of truth for any npm module types.. nit: I see this project is setup with prettier in the devDependencies - but don't see the @format --> did you use prettier to format this file?. this._prepackProcess is never set to null --> so, no need to check for null -- OR (change the flow type to nullable and set to null here). nit space after //. this is duplicating Nuclide's V8Protocol.js & VsDebugSession.js (https://github.com/facebook/nuclide/blob/master/pkg/nuclide-debugger-common/lib/V8Protocol.js)\nAlso, there's the npm package: vscode-debugadapter-testsupport which'd help you setup and send individual events to the adapter in a promise-based fashion.. Again, this is all duplicated work. This should better wrap Nuclide's VsDebugSession or use VSCode's utils instead.. If the file doesn't add any value, you should just add it to the ignore section in .flowconfig.. We discussed offline that it'd be best to switch to using the vscode npm package.. ",
    "phanipattapu": "Thanks for pointing out. Will commit a fix shortly.. ",
    "kwkit": "This doesn't seem to be referenced anywhere or do anything. Just wanted to flag this out and make sure it really can be removed safely. "
}