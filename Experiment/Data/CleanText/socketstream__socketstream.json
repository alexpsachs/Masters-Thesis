{
    "socketstream-owen": "Thanks Marcin!\n. Hi Kryton\nThis is fixed in 0.0.56. Thanks for letting us know.\n. Thanks for the link. We'll take a look.\n. The UA sniffing is turned off by default, though 'Strict' mode can be switched on if desired.\nI have to say, I can't get excited about any browser which makes the end user jump through hoops to be able to use websockets. This goes for IE 9 too.\nAs soon as these browsers support websockets out-of-the-box we'll be pleased to mention them in the Features. Until then, if any one wishes to write a small FAQ mentioning experimental support in Opera and IE 9, I'd be happy to merge that in.\n. That would be good. Just one or two sentences will do.\nThanks,\nOwen\nOn 26 Jun 2011, at 14:51, tronning wrote:\n\nIt's not \"jumping through hoops\" It's one switch that has to be turned on in Operas settings. It's all there just like in Chrome and Safari, just not turned on by default. I'll do the Opera FAQ if you want to?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/9#issuecomment-1440936\n. Perfect. Thank you. Will add it to the docs shortly.\n\nOn 26 Jun 2011, at 15:54, tronningreply@reply.github.com wrote:\n\nok :\nQ: Will SocketStream websockets apps run in the Opera browser?\nA: As of this writing websockets is supported but turned off by default in Opera. In order for Opera 11 to run websockets apps you need to turn it on in the settings. Do \"opera:config#Enable%20WebSockets\" in the address field and hit enter. Check \"Enable websockets\" Save and you are good to go.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/9#issuecomment-1441470\n. browser_check is normally switched off by default so I presume you switched it on here? If not, it's possible you have some client-side code in there showing the message.\n. Hi\n\nAt the moment the exports.authenticate = true flag is only read by the HTTP API (it engages Basic Auth). It has no effect on the websocket request. We will change this in the future.\n. Hi there\nI'm sorry, we've not had chance to test unicode support here yet - though I did presume it would have worked fine as we have used unicode characters in other areas within Node without any problems.\nCan anyone else look at this issue?\n. Awesome. Thanks! Merged already. Will sort a new npm package out shortly. \nOn 28 Jun 2011, at 17:11, eliseereply@reply.github.com wrote:\n\nI dug a little and I fixed it:\n- javascript is served as text/javascript and no charset is set so if the browser requests something else by default (iso-8859-15 in my case), the resource gets interpreted as such. It can either be fixed by changing generated tags to request type=\"text/javascript;charset=utf-8\" or by serving the actual resource with a \"text/javascript;charset=utf-8\" header. I went with the second option and made a pull request\n- Length of response in server.deliver was computed with body.length (which returns the number of characters instead of the number of bytes) so I switched it to Buffer.byteLength(body)\nThe pull request is above :)\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/13#issuecomment-1459064\n. Yup. This is one of the major known issues. We've documented it in the readme. For now you must create your new file, restart the server (so it starts watching it), then touch/save and of the existing files to trigger a rebuild. Sucks I know. \n\nUnfortunately the fix is not simple as watching for new files efficiently on both OS X and Linux platforms is tricky. Someone wrote a library for this recently and mentioned it on the node.js google group, but I haven't had time to play with it yet.\nIf you can help in anyway here it would be awesome. \nThanks\nOwen\nOn 28 Jun 2011, at 20:45, Rodeoclashreply@reply.github.com wrote:\n\nIf I add additional files to:\n/lib/client/\n/lib/css/\nThe docs specify that these changes will be detected upon a server restart and recompiled. This behaviour does not occur until I manually delete the files stored under /public/assets/\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/15\n. Here you go:\n\nhttp://groups.google.com/group/nodejs/browse_thread/thread/57815dc0b6763fb3/9c852dcf633ed8f5?lnk=gst&q=stalker#9c852dcf633ed8f5\nNot tried it myself. Speed and efficiency are key here - as is perfect support for Max OS X and Unix/Linux platforms.\nIf we can crack this nut it would be very exciting.\n. Thanks Elis\u00e9e. That would really help us.\nI will try it on Linux and Mac before merging it in. Typically Linux detects changes instantly whilst OS X polls at intervals. Do you know if stalker solves this polling problem? I know it's something to do with the different file notify libraries within the kernel but I don't know the exact details off hand.\n. Hi Elis\u00e9e\nJust wondering if you made any progress with this? I'm working on v 0.2.0 now and want to make sure it recognises new files correctly.\nOwen\n. Fantastic. Thanks :)\n. Hi Elisee. Any luck? Let me know if you don't have time and I'll take a look this weekend.\n. Hi Elisee\nWith the first 0.2.0 release only days away now I'd like to take one last look at this and see if we can crack it.\nDid you get anywhere? If not, no worries - I'll see if we can solve this via other means.\nThanks,\nOwen\n. No worries. I will have another go later today/tomorrow. Would love to get this into the final 0.2.0 release, due out tomorrow.\nElisee, do you have your latest code on Github?\n. Ah right. Number 2 is more concerning as it would mean we need two different ways to watch a directory.\n@jslatts are there any plans to add a callback when an existing file changes?\nThanks for your collective efforts so far\n. Hey Elisee\nClosing this now as 0.3 cunningly does away with this problem altogether by serving everything live in development mode. Thanks for your efforts here. I hope you'll give 0.3 a whirl in the future.\nOwen\n. Great! I've also started discussions with other hosting providers to figure out which ones we can recommend to SocketStream developers. People want to deploy their apps faster than I thought!\n. Paul's script can be found here:\nhttp://groups.google.com/group/socketstream/browse_thread/thread/faf1336e13dc4006\nGood work!\n. Hi there\nWe are seeing this error occasionally when using HTTPS too. \nI am hoping the latest release of node (out today) may be the solution as it has improved HTTPS support. If not a new release of SS with Socket IO 0.7 will be out within a week. We will begin debugging properly if the problem persists.\nOwen\nOn 29 Jun 2011, at 16:48, jmonsterreply@reply.github.com wrote:\n\nThis could be a problem with a dependency, such as Socket.IO ... I'm new to node :\\\nNote: This only happens with HTTPS\nIf I sit in a browser and hold in Command-R (reload), after a couple refreshes the server dies with the error:\nnode.js:134\n       throw e; // process.nextTick error, or 'error' event on first tick\n       ^\nError: EPIPE, Broken pipe\n   at Socket._writeImpl (net.js:159:14)\n   at Socket._writeOut (net.js:450:25)\n   at Socket.write (net.js:377:17)\n   at EncryptedStream.ondata (stream.js:36:26)\n   at EncryptedStream.emit (events.js:64:17)\n   at EncryptedStream._push (tls.js:299:12)\n   at SecurePair.cycle (tls.js:581:20)\n   at CleartextStream.write (tls.js:96:13)\n   at ServerResponse._writeRaw (http.js:391:28)\n   at ServerResponse._send (http.js:371:15)\nMy guess is that a socket is closed but something (net.js?) is attempting to write to them anyway\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/20\n. No, it's not a simple migration - as I'm finding out ;)\n\nNearly there though. The new Socket.IO 0.7 version will be ready for testing in the dev branch within a few days. Just doing a lot of travelling / meetings at the moment.\n. Good news here: Node 0.4.9 seems to have solved this problem. Yay\n. Hmm interesting you bring this up. I have been considering having an /config/app.coffee file instead of /config/app.json file for a while. It would allow us to add more comments into the file to describe what each option does. Hence you would have:\n```\nSet Primary Server Port\nSS.config.http.port = 80\n```\ninstead of\n{\"http\": {\"port\":80}}\nTo be honest, one of the main reasons I'm leaning towards the CoffeeScript approach is because the 'true' JSON parser is just so damn picky.\nI'm going to leave this issue open a while. If you feel strongly against the move to /config/app.coffee speak now :) Otherwise it will probably happen at some point in the near future.\nThanks for bringing this up. Let us know how you get on with Cloud9IDE.\nOwen\n. Hmm I thought about supporting both methods and then thought against it - let's just pick the best one and go with it. I vote we go for /config/app/coffee  We don't want to be supporting two ways of merging configs and explaining how to set your config in the readme for evermore.\nPaul if you can work on this that would be awesome.\nLet's do something like:\n```\nCONFIG FILE\nexports.config ->\n# HTTP\n# Set host and port to listen on\n  SS.config.http.host = '0.0.0.0'         \n  SS.config.http.port = 80\n```\nThis way we can simply require the file as a normal module. We will then need to load-in any environment-specific config file (like /config/environments/development.coffee) right after, effectively over-writing some settings in /config/app.coffee\nOf course, now we have people working on this SocketStream projects for real, we also need to be able to handle the upgrade nicely.\nTherefore the second piece to this change is to make a beautiful upgrade framework which will read the last_known and current values from SS.internal.state and run scripts if it detects you've just upgraded to a newer version.\nIt should pop up on the terminal with something like:\n```\nWe notice you're upgrading from SocketStream 0.1.2 to 0.1.3.\n\n0.1.3 sets config variables programatically instead of declaring them as JSON. Your JSON-based config files will be left untouched, but you'll need to manually set the same parameters in /config/app.coffee\n\nDo you wish to proceed with the upgrade? Y/N\n```\nSomething like that anyway. If we design the upgrade framework we'll be able to do automatically major changes in the future very easily (and automatically wherever possible).\nAnyone fancy having a go at this? Name your module /lib/upgrade.coffee\nCheers\nOwen\nOn 1 Jul 2011, at 07:23, paulbjensen wrote:\n\nMaybe we could have a dual-compatibility approach, so that you could use /config/app.coffee in place of app.json. We could keep app.json as the default used in new generated apps.\nI will work on this feature.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/21#issuecomment-1482139\n. Ah right! Keep it as a declared object. Yes, that will be much neater - especially as we will still be able to put comments around the settings (something I'm very keen to do). It may make it harder to 'uncomment' things should you wish to enable them - I'm not sure without giving it a go.\n\nWe should definitely try this approach first. Thanks!\nOn 1 Jul 2011, at 10:21, ggoodman wrote:\n\nHi the sort of coffeescript config file I was thinking about would look something like this.  This would mean a very similar syntax to your existing json config.\ncoffeescript\nmodule.exports =\n http:\n   host: '0.0.0.0'\n   port: process.env.C9_PORT\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/21#issuecomment-1483062\n. Paul's changes are now in the master branch, released as 0.1.3. The config files are now much cleaner and we are able to include inline comments - as well as dynamic values, allowing you to use SocketStream with Cloud9IDE. Good work!\n. Hmm thanks for letting us know. We've not tried this yet I have to admit. Would be good to get it working.\n\nIn other news... how does everyone feel about jQuery templating vs other solutions out there?\n. I too favour supporting multiple engines using file extensions. We will work towards that in future releases.\nGoing to back to the start of this thread, Samuel you'll be pleased to know 0.1.4 now allows nested directories in /app/views. It will be released shortly.\n. 0.1.4 is now released. This should fix the original problem. Please let us know if there are any problems.\n. Hi there\nThanks for this. We're going to keep the extensions (now renamed as helpers in the client and server) in JS for now, but we may change that in the future. \nIt would be nice we could come up with an easy way for you to append your own helpers..... I'll have a think about that.\nCheers,\nOwen\n. Thanks Andrey\nI see your point. This is a tricky one as I've been used to calling Array.any? in Ruby/Rails for years and really miss that in JS. Such a shame JS doesn't support question marks in method names :)\nI'm going to leave it in for now, but if there is strong opposition against keeping it in we could change it to Array.hasAny instead. What does everyone else think?\nThanks for pointing it out.\n. Thanks for raising this Andrey.\nThis is a pretty complex issue and I really want to make sure we do the right thing here.\nI will discuss it with Addy and the rest of the team next week when I'm back in London and keep the discussion going here.\n. Hi Andrey\nThe bind method you suggested is now in 0.1.4 by default.\nWe're not going to include Augment.js at this time, but it's nice to know the option is there in the future.\nThanks,\nOwen\n. Not easily at the moment, sorry. Before we send the 'shared' file to the client we do a quick regexp on all the uses of 'exports.' and replace that with the full namespace. It's obviously a hack, but a very high performance one which makes the API tree concept work a treat. Additionally in staging mode this is only ever done once and doesn't require the client to do any complicated processing (or use 'requires').\nIn the future it may be possible to parse the file properly so you could alias exports to something else, but it's not high on our agenda at the moment.\nOf course, if you can think of a different way to make shared code work seamlessly across client and server - please let us know. As always with SocketStream, consistency and performance are our key considerations.\nThanks,\nOwen\nOn 1 Jul 2011, at 16:27, colinsullivan wrote:\n\nSay I have the following in a .coffee file in shared/:\nColin = exports\n   Colin.VERSION = '0.0.1'\nThis will get compiled to:\nvar Colin;\n   if (!SS.shared.Colin) {\n       SS.shared.Colin = {};\n   }\n   Colin = exports;\n   Colin.VERSION = '0.0.1';\nBut if I have this:\nexports.VERSION = '0.0.1'\nIt gets compiled correctly, as\nSS.shared.Colin.VERSION = '0.0.1';\nWould it be possible to include usage of the exports variable as in the first example?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/27\n. Hi Colin\n\nGoing to close this for now. If anyone want's to submit a pull request containing some super-smart regexps I'll be happy to merge it in - but for now, please stick to using the word 'exports'.\nCheers,\nOwen\n. SocketStream does it all automatically for you, front and back end - and everything in between :)\nInvestigate the API trees concept. Basically you can have as many sub-folders and files as you wish.\nDon't put dots in your file names. Instead do this:\nshared/Foo   <- make this a directory\nshared/Foo/Bar.coffee   <- a file\nshared/Foo/Models/Customer.coffee\nNow you can do SS.shared.Foo.Bar.method_name() or SS.shared.Foo.Models.Customer.find() or whatever you like from both the front and back end.\nIf for any reason this doesn't work as I've described, let us know. Thanks.\n. Wow never knew about that - thanks. But the I suppose for us the question is, can github do coffeescript? :)\nOn 3 Jul 2011, at 20:45, chikamichireply@reply.github.com wrote:\n\nHi, just a quick issue that's a suggestion, really: you may want to use\njavascript\n// the code\ninstead of indentation, so as to benefit from syntax highlighting; especially in the README.md file.\nKeep the good work going :)\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/29\n. I agree. Good find!\n. Hi ltackett\n\nThere is no real requirement for wget - you could just as well use curl or simply click and download as I did. I've updated the documentation to reflect this. Thanks for pointing it out.\n. Hmm good point. So you won't be able to do this by putting your methods in exports.actions; however you can write your own server-side modules, put them in /lib/server and 'require' them into your server-side code by name.\nBy doing it this way callbacks are entirely optional (though always recommended if you're doing any IO whatsoever).\n. Totally agree. It's going to happen automatically without the need for a wrapper.\nThis is all linked to child processes, something we're spending a lot of time researching at the moment. Fortunately there are new advances in Node 0.5 which will make this easier for us.\nRealistically I feel this functionality is about a month or so away at the moment, but child processes and scalability in general will be our major focus once Socket.IO 0.7 is integrated and stable.\n. Hi Jonathan\nI've not used node-inspector myself but I've heard really good things about it - so I'm keen to support if it's an easy change.\nI'll add it to the list of things to look at. If anyone wants to take a stab at this and submit a pull request I'd be happy to merge it in.\nOwen\n. Great! Thanks Harlan.\nI've put it on the list for 0.2.0 which makes use of child_processes and auto-restarts when the server code changes.\n. Hi all. Support for debugging is coming in the next 0.2 beta later this week.\n. SocketStream 0.2 beta 2 now supports the Node debugger. Just type debug before the command you wish to run. E.g.:\n`socketstream debug server`\n. Thanks for spotting it!\n. I'm happy to abandon the numbering system for JS and CSS client libs and go with manual declaration in the config file if people prefer this. I always realised this was going to be a contentious decision :) I just like it myself precisely because you don't need to update another file when you add a new file.\nThat said, manually specifing everything does tie in nicely with our plan to deliver different assets to different devices (e.g. serve mobile libs to iPhones). Maybe a /config/assets.coffee file is the best way to declare this all.\nI would certainly want to stay well clear of using 'require' on the client. We tried this at first and it didn't feel right. That said, we do need to find a way to async load in additional libs in the future.\nIf anyone has opinions on this one way or another, please post them below. \n. Cool ok. I have been outvoted :) 0.2.0 will abandon the numbering system and allow you to specify each asset in a config file.\nThis will make it a lot easier to handle multiple types of clients, so it's no bad thing.\nOn 12 Jul 2011, at 18:45, eliseereply@reply.github.com wrote:\n\nI like the simplicity of the file numbering but the truth is, the day you'll need to add a file between number 2 and 3 and you already have 20 other files, it's going to be painful. A list in a config file would be much easier to edit for sure, so I would go with that.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/35#issuecomment-1556208\n. Want to give a quick update on this.\n\nI tried re-working the asset manager for 0.2 and realised it was going to be a huge undertaking to do all the things we've mentioned here plus a bunch of other stuff that needs to be done at the same time to prepare it for future plans we have.\nHence the Asset Manager will get completely re-thought and re-written as part of 0.3.\nThe 0.2 preview will be out in a matter of days now and includes many huge new features. As soon as it's stable I'll start working on 0.3.\n. Paul will submit a revised version in the future\n. Hi there\nWe have seen this issue before. Thankfully I got chance today to properly debug it.\nIt turns out to be a bug caused by the fact document.location.port will happily return you a real port number - unless you're running on port 80 or 443 in which case it's blank. Handy! This was leading to a malformed URL string (which I can see in your example above) and hence the NPObject error and no flashsocket connection.\nThis will be fixed in 0.1.5 which should hopefully be released later today.\nThanks,\nOwen\n. Ah great. Thanks for this.\nYou're spot on about only passing the request to the middleware once it has been fully received.\nWe have plans to use POST requests in the future to handle file uploads and REST. Apart from that, I was thinking the need to read this data is probably pretty limited (as form input should be sent over the websocket). What are you using the POST data for may I ask?\nLet's try to figure out the possible use cases then we can see if the framework should handle this or push the 'end' handler into /config/http.coffee so the developer can choose to intercept incoming request stream data there. This would break existing sites so it may have to be change for 0.2.0.\n. Thanks Derek. We'll definitely come up with a nice way to get hold of the POST params in a future release.\nI'm going to be looking at using Connect middleware in v 0.2.0. That may well be the solution. I should get time to experiment with this over the weekend.\n. Going to close this now. I have re-written the middleware in v 0.2.0 to use Connect and it's working well.\nThis means a new /config/http.coffee file format but it's worth it to plug into the wealth of 3rd party extensions and have full access to the POST headers.\nVersion 0.2.0 will be out within a few weeks.\n. Hi Derek\nHTTP POST data is now accessible in the latest 0.2 beta using the new @request object (available within your /app/server methods).\nLet me know how you get on.\n. This makes me think we should fully support Connect. I have thought about doing this a few times for authentication and other reasons. It would then be easy to route HTTP requests to Express or another framework.\nThe only reason I haven't done this so far was to keep everything as close to the standard Node libs as possible for speed and flexibility - plus of course it's another mandatory library to install.\nI'm going to have a play round with this idea for v 0.2.0. Anyone got any thoughts or comments on this?\nFor now if we make the servers object (containing the primary and secondary server object) a global var (SS.internals.servers) would this help you out in the short term?\n. Great ok. Look out for it in 0.1.6 which is no more than a few days away.\n. Yes, quite correct. The hiredis driver gives extra speed but is not required. We can get rid of the dependency in a future version.\nI'm keen to keep the focus on speed and do everything we can to make apps run as fast as possible. If you don't have it installed we could show a warning upon startup.\nGood compromise?\n. Closing this has the dependency has been removed from 0.1.7\n. We hear you :)\nI will register the #socketstream channel and include this in the github (and tweet it) once it's done.\nThanks to Mark Ach\u00e9e who gave me the details on how to do this (and was the first to request a channel some weeks back).\n. Done! Join us on #socketstream on freenode\n. Thanks!\n. Changed in the forthcoming 0.2.0. Thanks!\n. Hi RJ. Thanks for letting us know. Fixed in 0.1.8.\n. Thanks Blake. I'm afraid my head is full of the features going into 0.2.0 at the moment, but I welcome any discussion around this topic.\nIt's not something every web app would want (e.g. a stock trading site or a real time game), but if your app is content based it would be nice if we could have a solution (or at least a recipe) that pleases the end user and Google at the same time.\nAll suggestions welcome. As always don't be afraid of making big changes to the existing implementation (i.e. jQuery templates) if it means a clear win in other areas.\n. Very interesting. If you can get something up and running it would be great to cover it in the docs. I know at least one other person has asked me about this.\nI could see this becoming a separate Connect module which is optionally loaded into the HTTP Middleware stack (v 0.2.0 uses Connect).\n. Hi Blake\nThanks for your interest here. Going to close this now as 0.3 is fully compatible with Connect, Express and anything else out there so it should be possible to build something like this on top of SocketStream. Doubtless an area I will revisit in the future once 0.3.0 is finished.\nOwen\n. We can definitely do this. Just to check with you, as I've not used this myself, the auth function does not require a callback? \n. Great. This is now in 0.2.0. Please give it a go when it is released and let me know if it all works as planned. Thanks for the suggestion.\n. Ah right, didn't know that. It's a simple one liner so far and it's definitely in 0.2.\nCurrently targeting Sunday for the first preview release of 0.2.\n. Hi there\nPlease see previous discussion on this: http://groups.google.com/group/socketstream/browse_thread/thread/0834dfdc0bc5a3c4\nI'm still tempted to implement it in future versions, but the main problem is the HTTP API. Right now it all works well because multiple vars are handled by providing an object over websockets or a query string which we turn into an object. But once /app/server methods expect more than one arg, what do we do with the HTTP API?\nIf we can solve that issue, I'm happy to make 0.3 support multiple arguments.\n. Hi guys\nYou may be interested in the discussion going on here: http://groups.google.com/group/socketstream/browse_thread/thread/7c832596e4785f2e\n. Hi there\nWas just about to drop back to the 0.1 branch, dust off my svn skills and give this ago but alas NPM is currently down.\nRather than explicitly filtering out .svn files, let's filter out any files beginning with a dot. I know many functions already do this but clearly something has slipped through the net somewhere.\nWill hopefully try again later this evening NPM permitting.\nOwen\n. Hi syrio\nThanks for the pull request. I'll decline it only because this is no longer an issue in 0.2 and all the effort is now going into making this stable in the next week or so.\nOwen\n. Sure - it sounds like a simple change.\nI would say make a pull request and I'll take it from there - but I'm more concerned with how Cloud9 will work with 0.2 given the split process architecture and need (at least for now) to have ZeroMQ compiled.\nIf you could give 0.2 a whirl on Cloud9 I'd be interested to hear how you get on. Hopefully the problems you find can be resolved quickly.\nOwen\nOn 17 Aug 2011, at 15:25, ggoodman wrote:\n\nIn a non-standard run environment (Cloud9IDE). I have a bootstrap file as such:\n``` coffee-script\nrequire(\"coffee-script\");\nss = require(\"socketstream/lib/main\");\nss.init();\nAdjust SS.root to a subdirectory instead of the root dir\nSS.root = SS.root + \"/appname\";\nss.start.server();\n```\nI have had to modify the line in assets/index.coffee where the public_path is set from exports.public_path =  './public/assets' to exports.public_path =   SS.root + '/public/assets' as well as making similar changes to the watch_dirs to make them based on SS.root instead of the current working directory.\nIs this something that you would consider integrating into master?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/54\n. Boo. Thought that may be the case.\n\nI'm hoping we can drop the mandatory requirement to use ZeroMQ once Node 0.6 comes out and everyone is using it. This will allow us to use the new inter-process JSON message API instead when running the 'socketstream server' integrated server in development.\nHowever, the need to launch two processes is essential if we're going to support auto-reloading server-side files upon change. Do you know if Cloud9 is ok with that?\nWhen I get chance I'll play with it a little - I do love the idea of an IDE on the web.\n. Good news. The next version of 0.2 (most likely beta2) will support Cloud9IDE. Should be ready later this week.\n. Beta2 committed to Github now (moved to master branch). Should load fine on Cloud9IDE as ZeroMQ is no longer required.\nPlease submit a pull request for the path changes you described above and I'll merge into master.\n. Great. Is there anything I could put in the Readme to make it easier for others wanting to do the same?\n. Hey @ggoodman \nAny chance of letting us know what you needed to tweak to make SocketStream work with Cloud9?\nI would love to put it in the docs as a few other people would like to know.\nCheers,\nOwen\n. Hey there\nThanks for this - very helpful.\nAs it turns out I'm already modifying the interface exposed in 0.2.4 as I needed to make changes for testing and seeding the DB, so I'll make sure you're able to start the server this way too.\n. I've released 0.2.4 today which should make it much easier to use SocketStream with Cloud9 without modification.\nSee https://github.com/socketstream/socketstream/blob/master/HISTORY.md\n. Hmm looks like you still have SocketStream 0.1 installed in the global path.\nMake sure you run 'npm install -g' from within the SocketStream 0.2 directory.\nLet me know how you get on.\n. Closing this for now. Let me know if you still have an issue here.\n. Thanks! Fixed in the latest 0.2 code I'm pushing later today or tomorrow.\nOnly tested this on /app/client code though.\n. I quite like the idea of app.domready and app.load, as well as app.init but to be honest I've always felt the init method is living in the wrong place as it is.\nI'm tempted to change this in 0.3 so we emit an event to SS.events.on 'init' instead - and maybe also have a separate file for client-side system events, like we have /config/events.coffee for server-side events.\nThis feels cleaner to me than muddying up your own application SS.client code.\nAs always thoughts and suggestions welcome by all.\n. Closing this for now. Will definitely try to integrate these ideas into 0.3.\n. As far as I can tell this is fixed in 0.2 with server-side events, specifically the\nSS.events.on 'client:init'\nevent. Please re-open the issue if this is not the case.\n. Yup. Vendor has gone in 0.2 anyway.\nPrior to the decision to remove require.paths from Node 0.5, the simple solution would have been to put any shared server-side code in /lib/server\nNow it will have to live inside the /node_modules directory of your project - which in fairness isn't so bad.\nIf you can think of any better solutions let me know.\n. Not sure Node allows you to look in two dirs (I think the whole point of abolishing require.paths was to allow developers to know exactly where to find external modules) but I definitely want to get this idea tested and documented. Cheers\n. Thanks. This was fixed in the 0.2 beta i pushed last night\n. Hi there\nNo unfortuntaly not. By design HTTP middleware is called before the request hits any part of the SocketStream stack.\nTherefore two options are possible in the future:\n1. We make possible and document how you can parse the session_id cookie and load a session manually\n2. We look into better ways to do authentication\nI am going to be looking at the latter over this next week. In particular, seeing if we can integrate Conenct Auth or Everyauth.\n. Ok thanks. Will give this some thought\n. Closing this for now. Going to bear it in mind for the future as we need to do this ourselves.\n. Hi Colin\nAs the load order can never be guaranteed, simple call a function once all the code has loaded which extends your code as desired.\n. Indeed. Very true. This is already listed in TODO.md to be done before the final 0.2 release. You'll also see a link to the bug I had when trying to use the 'zmq' package. Hopefully that's being fixed now.\nI will try again in the next few days as I'm doing a fair bit of work around the transport layer at the moment.\n. Got the new zmq npm working well with beta2 which I'll push to Github today or tomorrow. Hopefully it will well for you too\n. Hmm ok. I wonder if we should we even make it a hidden file at all now we have a /tmp dir\nMaybe better move it to /tmp/last_known_state\nAlso, we need a place to record PIDS in use so deployment scripts can kill master and child processes upon pushing out new versions of the app\n. In this context 'state' means the version of SocketStream last used to to run the application with.\nThe 'server' version is used to warn if you try running the app with an earlier version of SocketStream.\nThe 'client' version is used to force a rebuild of all client asset files if the client code has been upgraded.\nI would love to integrate well with common deployment platforms.\n. I'm keen to keep all the related files together in the app directory. Mostly because we want to be easily support hosting providers hosting hundreds of small SocketStream apps on the same server.\nNow each app has a local /tmp how about we do /tmp/socketstream1.pid, /tmp/socketstream2.pid etc (numbers are necessary when running in multi-process mode).\nThe last known state file could live in /tmp/last_known_state.json\nSound reasonable?\n. Closing as there is no concept of .socketstream_state in 0.3. The onus is on the app developer to use the right api syntax with the right version of SocketStream. If I need to reimplement this idea I will reconsider the name.\n. Great! Thanks a lot.\nJust to let you know, I'll be moving a lot of things out of the main README in 0.2.0 and into /doc/guide\nI was thinking of doing /doc/guide/en so we can do a /doc/guide/jp etc in the future.\nEach markdown file will represent a page/section on the forthcoming website (i.e. the website documentation will come from these files).\nAny thoughts?\n. Thanks\n. So there are big plans to re-write the client asset manager in a future release of SocketStream.\nThe new version needs to do the following:\n1. Support multiple pages/clients. I.e an iPhone client, or Admin client to be delivered if you goto /admin\n2. Have a new file containing rules to determine which client to serve a device (using a combination of user-agent and URL)\n3. Support other file formats such as .less and .sass without having to load or install anything we don't need (hard!)\nOn top of this is the need to do what you mention - to be able to load in new CSS and other client assets as the application requires.\nAs you can see there's lots of work to do here, but I'm keen to get some plans in place on how to tackle this - and ideally some help with the coding.\n. Great news. Thanks!\nI will be looking at Connect Auth and Everyauth over the next few weeks. If you are doing the same let's share findings.\nWith the new Plug Sockets feature in 0.2 you should find it very easy to connect to your external servers using zmq. Feel free to develop / improve the wrapper it uses if you need more features (such as timing out should the connection fail).\n. Is this issue still relevant?\n. Ok thank you. Going to close this now.\nFor anyone finding this in the future, supporting different types of CSS files (i.e. for 'handheld' devices) can now be achieved by detecting the useragent and sending a different CSS file (by defining a new client with ss.client.define).\nSupporting a print style sheet could be achieved by adding a 'manual' CSS link in your app view and pointing it at a CSS file in /client/static.\nNot perfect, but it will do for now as there are much bigger fish to fry.\n. CoffeeScript automatically wraps all files within closures in order to prevent polluting the global namespace. If you're not using CS it would be a good idea to wrap everything in the module pattern as you suggest.\nDespite my dislike of the 'require' method, I actually like the elegance of your proposed solution. Thanks!\nIt needs to go hand-in-hand with other features which will come with a re-write of the Client Asset Manager which will also involve big changes to the project directory structure. This is sounding like something for 0.4 as it maybe too big for 0.3 (which really needs to be about getting Models and Authentication right).\n. Closing this now. You will find something very similar to this idea in 0.3, hopefully ready to go onto github tomorrow. Thanks for the inspiration and ideas!\n. Hmm yes this is an issue at the moment. The current approach is fast (performance wise) and consistant with the rest of the API, but it's not ideal. It can be caught ou' as you've found.\nMy biggest gripe with using 'require' is that it feels cumbersome and messy. Ryan Dahl has also stated he doesn't like it and wishes Node.js could do something better.\nReally what I need to do is work out the new features I really want to support in the future (such as multiple clients) and see if the API Tree concept still holds, or whether we need to do things very differently. It may be requiring modules is the best way after all, but I don't want to make a hasty decision.\n. I have been working on a new solution for SocketStream 0.3 which does away with the textual replacement problem altogether. Closing this now, but thanks for raising.\n. The problem here is that the exception is happening inside the callback, not in the scope of the method.\nIf it did, you'd see the stack trace passed up to the browser console, plus a mention in the log.\nThe problem of tracking and handling exceptions within callbacks seems to be commonplace when using Node.js. I'd love to know the proper way to do this as it catches me out a lot!\n. Good catch. Thanks!\n. Hi. Do you get the same error if you delete the .socketstream_state file and restart? This will force the client libs to rebuild.\nIf so it looks like a potential bug in the new Socket.IO library, though not one we've seen with our own apps running 0.2.0.\n. Assuming this is ok now. Let me know if not\n. Thanks for spotting. Will put an 8Mb configurable limit on in 0.2.1\n. Not at the mo, but it should be very easy for you to do that right now following the examples in /config/http.coffee\nI am interested in supporting an optional module which makes file uploads easy, sending progress back to your app via an event emitter. I was looking at formidable and formaline earlier today. Both look very interesting.\nIf you fancy giving them a go and reporting back that would be very helpful.\n. Fixed in 0.2.1 so closing this\n. Hi there\nGlad you've got this working. Going to decline the pull request for now as:\n1. I've already put a max POST limit on the HTTP AP in 0.2.1 (to be released soon). This should be present whether or not you want to use node-formidable else otherwise it would be very easy to bring down any SocketStream server.\n2. Handling file uploads is something we want to support whether or not you wish to use the HTTP API. It should be a separate module, which very likely will use node-formidable but I wouldn't want to rush the decision. A lot of factors need to be considered.\n. Hi Colin\nMake sure you're looking at @session.user_id (not @session.user.user_id as above) and don't set it directly - use the @session.setUserId() method.\n@session.user.user_id woud set a value on a module which would remain the same for every user/browser.\nOh an just FYI as you asked in IRC, @getSession(cb) is now deprecated in 0.2.0. I thought it was going to be necessary to use callbacks but thankfully I found a way round it.\n. Yep setting @session.user.attributes is the same issue. It doesn't exist at the moment, so please use @session.attributes instead.\nHere's a big problem I would love people to use their brain power to help me solve:\nWe need to separate internal user commands (such as @session.user.logout() ) with the need to access an instance of your own custom user model (i.e. @session.user.checkoutCart() ).\nThey both can't exist in the same space so I've deliberately kept @user as reserved variable name for now thinking this is where the 'instance' of your custom user model will reside... but as you can imagine they are very interlinked, sharing the same id attribute as a bare minimum.\nI would welcome some clever thinking here as it affect the way we do Models in v 0.3.\n. Hey Marcin\nGreat to hear from one of the first watchers of the project :)\nI need to think about this a little. So you're wanting to message individual tabs/windows, even though they may be logged in as the same user?\nThe easiest way is to simply subscribe each client to a different channel (channels are linked the the client/socket, not the user_id) then message that channel.\nThis way should the user hit refresh and get a different socket_id (as they would), you can still continue messaging that tab - even if they are connected to a different front-end server.\nAlso there are plans afoot which would be impacted if we added SS.publish.socket(). I will tell you about them in Dublin at the end of the month.\nLet me know if publishing to a channel doesn't work for you.\nOwen\n. Hi Marcin\nYou are spot on. If you really really want to target the individual socket, regardless of session, this is the only way to do it.\nI'll merge the change but won't document it until I'm sure of our current plans around this area.\nI will arrive on the 28th so unfortunately it sounds like I'll miss you. Shame!\n. I'd like to pass through the socket_id as @request.socket_id\nBasically the @request object is full of meta data that most people won't care about, but it's there in case you do.\nSound ok?\n. Just doing it now. \nNeed to change things slightly as backend/publish.coffee has no way to access SS.io.sockets unless it's running in single process mode, hence the event must go via redis and the internal RPC transport. Just looking into it now...\n. If we're going to add it into the core it needs to work the same way whether or not you're running in single/multi process mode, just like everything else.\nGood news is it's a simple fix. Just need to write a test then I'll merge it in.\n. I've merged-in the code and modified it slightly. Also taken the opportunity to do some broader refactoring around publishing events. All this will go into 0.2.2 in the near future, along with documentation for the new SS.publish.socket(socket_id, ...) method.\nThanks :)\n. Don't worry, it's on its way :) The release I'm working on still needs a bit more work.\n. Don't worry, it's on its way :) The release I'm working on still needs a bit more work.\nOn 19 Sep 2011, at 07:50, Marcin Olak wrote:\n\nit seems like this patch didn't make it into 0.2.2? : >\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/pull/78#issuecomment-2134372\n. Hey there\n\nCould you tell me what you're trying to do in Jade?\nAs we are very much a single-page framework all data manipulation is done client-side in the DOM, hence the jQuery templating (though SocketStream should would fine with other templating libs).\n. If I understand correctly, we do this ourselves with the != SocketStream magic variable, but there would be no point in you doing this as all the HTML the client requires (basically the layout structure) is rendered and sent once upon initial connection. After that all the magic needs to happen in the client.\nDo let me know if I've completely got the wrong end of the stick here :)\n. Cool ok. Can you describe what you mean by template inheritance?\n. Great suggestion. Will definitely implement this. Thanks\n. Hey Jerry. For sure. If/when we do this it won't be mandatory.\n. Closing this as this feature is now implemented in 0.3 alpha3 by setting the maxAge option:\nss.session.options.maxAge = <value in milliseconds>\nPlease reopen if this doesn't work as expected.\n. This is true, we're not watching these files - only the /lib/client files\nWe could, but we really need to test out the performance if Node is watching a large number of app files in Dev mode.\nAlso right now it's still possible to save a file, change to your browser and press reload faster than Node can detect the change on OS X - which means this feature isn't as useful as it could be.\nOnce Node can monitor a large number of files efficiently and detect changes (and additions/deletions) on OS X as quickly as Linux it will be an awesome feature.\n. Hi there\nCan you tell me what the use case is here? You may always get the session_id cookie via @session.id, but I'm guessing you're wanting something else here?\n. Hi there.\nSorry for the slow reply - on vacation at the moment.\nStill not convinced we nee the additional RPC overhead of sending cookies (i.e. on every request over ZeroMQ when running in multi-process mode).\nThe easiest way round this problem is to save a 'permanent' cookie on the client as you suggest but send the value of this to the server on the first command you call. You can then write a server-side action to attach the language value to the session via @session.attributes\nNot ruling out it for good, but this seems like the best solution for now.\nOwen\n. Thanks for the suggestion. Quite like the idea of per-request/module settings but it would need to be written for other settings - not just for this one. I'll bear it in mind. Cheers\n. Done!\n. Hey there.\nNot sure of an exact timeframe for this but it's definitely on our short to medium term roadmap, along with server-side models.\n. Hi Andy\nYou're right. Lots of the initial code grew organically from the 'is it possible to do this' experiment I did about this time last year. The session stuff is the oldest and worst of the lot written before the decision to use Connect was made. It has to go before any new features are added.\nTotally agree with you we should off-load more onto Connect where possible. Also the redis_proxy idea needs revisiting as this was brought in to support distributed hosting. Since then my ideas on this have further developed and I really want to make all the ZeroMQ stuff a separate optional npm module (after thoroughly investigating Hook.io first).\nCan't go into all the other points just at the moment but I broadly agree and will come back to this post when looking at re-implementing sessions.\nI'm going to be writing a new Google Group post about the plans and philosophy behind 0.3 in the next few days.\nCheers,\nOwen\n. Connect.session will be used in SocketStream 0.3. Closing this now\n. Thanks!\n. Thanks a lot!\nGoing to take a good look at this shortly. Working on an actual SocketStream app at the moment which is a nice change from framework stuff and travelling.\nRe lib/frontend/client/cached/lib.min.js: Agreed, we should do this in 0.3.\nIdeally SocketStream should custom-build the client-side code with only the features you need. Third-party modules should also be able to expose client code which will be included each time this is generated.\nCheers,\nOwen\n. Hey again\nHad a good think about this. I love the idea, but we have a problem:\nAt the moment everything in /lib/frontend has no knowledge of Redis and shouldn't do because all session data flows over the internal RPC layer. For good or for bad, this is how it works at the moment; so we're unable to require anything Redis-based here.\nSo how about another idea... We make this (plus some minor modifications I've made) the start of 0.3 which I can deploy to a new branch on github next week.\nWe'll make it clear this branch is not ready for use yet, it's a work in progress, thus giving me (and others via pull requests) the ability to go in and completely rip out code and start again in areas (most notably sessions!).\n0.3 will not have this internal RPC layer, at least not in the core. All the ZeroMQ-related code needs to come out and live in an optional npm module - eventually.\nBut the number one priority is a stripped-down ultra-clean core which runs great in single process mode, with the emphasis being on making it easy for others to extend and contribute to via new modules.\nHow does that sound?\n. Hi there\nGoing to close this now. 0.3 is not going to be based on any 0.2 code at all - I've decided against that.\nI'd love to get your thoughts on the code, particularly around sessions, once I put it on github.\nOwen\n. Yup this should work. The only code it takes in the framework is:\nhttps://github.com/socketstream/socketstream/blob/master/lib/backend/session.coffee#L111\nBasically at the moment it's just loading a module. The plan in future was to check the module had a valid interface and was compatible with the current version of SocketStream before allowing it to be used.\nOf course the main limitation with this auth method is you can only perform auth against an internal database - not one where the auth service refuses to allow proxying of credentials (such as facebook connect).\n. I should add we're using this method in a few of ours apps, but it feels a bit clunky. Esp having to call the @session.setUserId() method in your own app code.\nIf you can think of a more elegant implementation please let me know.\n. @paulbjensen Cool. Just remember you'll need to call @session.setUserId() if you ever want to use SS.publish.user() or SS.users.online\n. Interesting idea. Thanks!\nI'm keen to make sure 0.3 is much more flexible when it comes to templating.\n. Multiple template languages are coming in 0.3 so closing this issue now. The first 0.3 alpha will be out by the end of the month, so stay tuned for updates :)\n. Hi Paul\nThis is fixed in 0.2.4. Please reopen if you still have problems.\nOwen\n. Hi Andrew\nWell spotted. This is fixed in 0.2.5 out soon.\nOwen\n. Hi Andrew\nWell spotted. Will be fixed in 0.2.5 out soon.\nOwen\n. Hi there\nDo you still have this problem? Everything is working fine on my machine and I've not had this problem reported before, so I'm not sure what to suggest without more debugging info, sorry.\nOwen\n. Hi there!\nThanks for this! Looks good. Let me have a look into it tomorrow and find the best way to proceed.\nWould love to get this into 0.2.5 if possible.\nOwen\n. Hi there\nThink i misread this and thought it was a bigger change than it is :) Sure I'll merge this in. Please submit another for the other time Jade is called if you wish.\nOwen\n. Thanks!\n. Haha kinda cool\n. Thanks!\n. Hmm interesting. I put this in initially as I had a problem that took me ages to debug. It turned out to be caused by one of the CSS files in my lib dir which wasn't correctly terminated so I put this in to be sure in future.\nI've never come across the problem of an extra semicolon stopping something else from working before. Can you provide any more details (e.g. browser, or a snippet of the css output).\nIf this is indeed a problem, the only proper solution would be to check for a terminating semicolon and add one if not present.\n. Ah my mistake, of course you're right.\nI still feel there once was a problem concatenating multiple CSS files together, but it must have been something unrelated to this. Do let me know if you come across anything.\nI will accept the pull request. Thanks.\n. Hi there\nYup, totally agree. It is likely to happen but right now I'm putting all my time into the first preview of SocketStream 0.3.\nBut I am looking for people who may be interested in making 0.2 support Node 0.6, see here: https://groups.google.com/d/msg/socketstream/AFwFAPMKzjU/k2fsLjwGL94J\nIf you or anyone else reading this is interested in working on this please let me know.\nOwen\n. Now supported in 0.2.6 using connect 1.X\n. Sorry - my bad. I forgot to run all the integration tests. These would have caught the pull request which broke it.\nFixed in 0.2.7.\n. Brian I believe this is the famous Socket.IO + Safari with proxy settings bug. I'm going to close this now as the Socket.IO team is well aware of this. The good news is 0.3 is now websocket transport agnostic so we have the ability to use other transports in the future.\n. Hi there\nAs far as I know no.de still does not support websockets, so I think that's your problem. SocketStream should work fine on NodeJitsu and many other hosting providers. We use EC2 servers ourselves.\nOwen\n. Thanks Ian, you're quite correct.\nI'm working full time on SocketStream 0.3 at the moment which is essentially a brand new piece of software. I will need to re-write the feature list entirely as so much has changed, so I'll bear this in mind.\nStill on track to release the first 0.3 alpha by the end of December, so please look out for it and feel free to share your thoughts.\n. Hi Ian.\nClosing this now as I'm about to release 0.3 (tomorrow hopefully). So far very little has been done around authentication but it provides a much better framework to build solutions on in the future.\n. Hi there.\nCan you let me know, does this error occur with a newly created project or an existing project? Also which OS?\nThanks,\nOwen\n. Hey there.\nYes, I am aware of this with 0.2. I'm pretty sure none of the 0.3 code will be affected by this, but if you or anyone else spots an example of this please let me know and I will fix it.\n. Closing this now 0.3 is out. If you spot this problem with 0.3 let me know, but I think it will be fine.\n. It is up again now, but it keeps going down intermittently. It is running the new 0.3 code and it appears something happens to make it suddenly jump to 100% CPU usage and stay there (hence 'forever' won't help).\nI'm trying to output as much debugging info as I can but as yet I can't see what's causing it. One of the many things that still need to be sorted before the code if ready for to be used by others.\n. Sorry I didn't mean to close this one - I hit the wrong button.\nI have installed monit on the server as per your suggestion and have tested it will restart correctly if the process is killed, but have yet to see it restart due to high cpu usage. I'll be out later today but will keep an eye on it.\nThe site should stay up from now on.\n. That's because it's not ready yet. See https://groups.google.com/d/msg/socketstream/AFwFAPMKzjU/wERmwMoxCIwJ\n. Because I don't like anyone seeing ideas which are only half baked or certain to change, as has been the case with the most of 0.3 code up until the last few days. I feel very strongly about this.\nUnfinished work and ideas not only look sloppy but also generate many unnecessary github issues and emails which need to be answered when often the only answer is \"because I haven't had time to do it yet\".\nThe 0.3 code will go online once I'm happy with the core ideas and I feel most people's first experience with it will be a positive one. There will still be lots of work to do to move from dirty untested code to solid production-ready code and your help would be very much appreciated.\n. So I thought this too but I heard Isaac say this is not a problem for Windows in a recent Node Up podcast. Maybe he's referring to require() calls, not to paths which are used by other modules -e.g fs?\nIn either case whilst the first alpha release of 0.3 is unlikely to run fine on Windows, I will make sure 0.3.0 does before it's released.\n. Closing this now as I believe 0.3 is now cross platform thanks to the pull requests I've merged in. I will do a full test on Windows before 0.3.0 is released.\n. Closing this as the latest 0.3 code should run fine on Windows. Please reopen if not.\n. Hi there\nJust pass the full module path, e.g. '../../lib/server/myauth'. Please let me know if you get it working.\n. Thanks Troy. Good point about relative directories.\n. Hi Dave\nThanks for this. Just want to be sure, are you saying all the assets serve correctly in Windows - even when you enable ss.client.packAssets() just by making this change? If so that would be a massive result!\nSadly my only Windows machine is the VM on the Mac in the office. I was planning to test 0.3 out on there next week.\nOwen\n. Great stuff. Merging this in. I have updated the README and INSTALL files too.\n. Hi there.\nThis functionality is still present in 0.3, nothing has been removed here. Can you describe which .coffee files you're referring to?\n. Hmm how strange. Does this mean the /server/rpc/actions/demo.coffee file installed by default when you create a new project is not working (i.e. the basic chat demo doesn't work)?\nNote the files in /server will not auto reload if you make changes (you'll have to restart the server). You can use 'nodemon' as described in the Questions section in the README if you'd like to have this functionality.\n. Ah right. Glad it's working for you now\n. Thanks for letting me know. Fixed\n. Yes the basic idea is that you must tell socketstream what the home directory is. Normally this is done automatically when you 'cd' into it in the terminal and run 'socketstream start', but when doing startup scripts on the server you need to set the home directory manually.\nThe discussion in #113 may help you.\n. Closing this now\n. Yes very much so. That's one of the key goals of 0.3.\nSo if you have an existing Express JS project you will be able to leverage SocketStream in it, so you could have a normal website at / and use SocketStream to serve /realtime or anything else you like.\nTake a look at the example of using Express JS on the tour at www.socketstream.org/tour\n. Yup that's the solution. By passing 'ss' as the third function we no longer need the global variable.\nThere are hardly any docs at present but it will be fully documented soon within the coming weeks.\n. So calling actions() each time is a benefit as it allows you to do things before the method is called. E.g.:\n``` javascript\nexports.actions = function(req, res, ss) {\nconsole.log(req) // debug or rewrite requests\n// return available functions\n  return {\nmyMethod: function(params){\n     res('my response')\n   }\n  }\n}\n```\nNow if I've missed something critical here which means the performance will degrade over time, please let me know. It could be argued that with the 0.3 middleware feature the need to debug within the actions() function is redundant. Not making this a function (and returning to the 0.2 style) would mean passing the cb param AND the ss param (as it's no longer a global) to every function which seems messy.\nRegarding publishing events outside of the ss.rpc() handler, you can do that now by referencing ss.api\nE.g. in your main app.js file you can call ss.api.publish.all() however this needs to be called after you call ss.start() for this is the command which establishes the connection to the event transport (likely to be Redis).\nss.api is the object which is sent to the third param of the actions() function. It is intended to be the 'internal API' of commands which can be called once everything has loaded and connected.\nThe issue of whether or not to prototype an instance of 'ss', e.g in your ss.getInstance example above is one I've been pondering. If we really need to do it we will.\n. Agreed.\nNot a simple change because of the way we use an EventEmitter to route incoming requests (which itself is up for debate) but I agree we need to do something here. Added it to TODO.md (my local copy).\n. Fixing this in alpha4\n. Just not possible yet. But I want it to be. 'Investigate if it's possible to make SocketStream sessions accessible to regular HTTP requests?' is listed in the TODO.md file.\nThis is why I hate putting stuff on github before it's finished :(\nI'm working on documentation at the moment. If you'd like to have a look at how we can do this (without relying on Socket.IO sessions as the transport is now modular) that would be great.\n. Thank you. Appreciated\n. Closing now as this is all in alpha3\n. Hi Jamie\nWow this is very surprising! I can't think of any reason off the top of my head why this would be the case and I've had no other reports of this.\nPublishing to channels is already implemented in 0.3. If you get chance and are able to please use that instead. I'm almost certain it will not suffer from the same problem, but let me know if it does and I will reopen this issue and fix it immediately.\nAs I'm sure you can imagine, with so much to do to get 0.3 finished, I'm trying to avoid touching 0.2 unless absolutely necessary.\nOwen\n. This looks really good. Thank you.\nGoing to get a whole bunch of stuff I've been working on released today (which shouldn't impact your pull request) then delve into this.\n. Hi there\nI've had a chance to look at this today.\nI really like the approach of using Redis as the medium to share sessions between SocketStream and Connect/Express/etc. Good idea.\nI don't mind having to include the extra dep ('connect-redis') but I do mind the fact this patch forces every user into running Redis, even if they have no desire to share sessions. I definitely want to avoid this as I want SocketStream to remain session-store agnostic (with no need to use any if you're just downloading an experimenting with it for the first time).\nAlso we don't want to hit Redis upon every RPC call as it would dramatically impact performance. Hence we need to keep the cache idea by default (and implement pruning) but provide a way to disable it (forcing a Redis lookup on each request) if you are sharing sessions with HTTP calls.\nThanks for fixing the bug with the router. Well spotted.\nI've got your code in a branch and will work on it to see if we can achieve the best of both worlds here.\nOwen\n. Been working on this today and showing some good results so far. Will work on it more tomorrow and update you soon.\n. Closing this now as this code, and much more, is in alpha3. Thanks again\n. Agreed. We need a lot more debugging and error handling here in general.\nChanging this file at the moment as I'm redesigning the middleware API. Will see if I can improve this while I'm at it.\n. So i've made an additional file in a new project called /server/rpc/app.js and put foo)bar in it.\nWhen I start the app it errors as we would like:\nob:test owen$ node app\nStarting SocketStream 0.3.0alpha4 in development mode...\n/Users/owen/Work/test/server/rpc/app.js:1\nfoo)bar\n   ^\nnode.js:201\n        throw e; // process.nextTick error, or 'error' event on first tick\n              ^\nSyntaxError: Unexpected token )\n    at Module._compile (module.js:427:25)\n    at Object..js (module.js:450:10)\n    at Module.load (module.js:351:31)\nDoes this not happen for you?\n. Are you catching uncaught exceptions somewhere in your app?\n. Tested this again on a brand new project on my home mac (separate from earlier), same result.\nThe only thing I can think of is that one of your included modules is calling\nprocess.on('uncaughtException',cb)\nRecommend running grep -R uncaughtException node_modules\nPlease try with a new app. You should have no problem installing hogan. I've tried that on two separate systems now and no one else has complained of any problems installing it.\n. Thanks for spotting. Fixed now\n. Thanks again. Implemented this in the next release, hopefully out tomorrow.\n. Thank you. Was looking for a solution to this. I've updated the code and will push it along with other changes by the end of the week.\n. Hmm not sure that's the pull request you wanted to submit. Looks like that would just delete the contents of README.md\n. Yup, agree this needs doing. Will keep this open until debugging around RPC calls is improved.\n. What sort of syntax errors are you talking about in 1.? When I create RPC action files with syntax errors they typically throw and error and prevent the server from starting - which is good. I think we really need to identify the cases here and work towards writing test cases to see how each possible error is handled.\nI totally agree we need to improve debugging and error reporting in general. Alpha4 will see internal changes to the way responders process requests (it won't break any apps). Once that's done let's think about the best way to proceed.\n. Hi there. Some of the new error handling in alpha4 should help you here. I'll keep this issue open as I can't say for certain that all possible errors will be caught yet, but please let me know how you get on and how to reproduce any issues you find.\n. Thanks. I've put this in the next release.\n. Ah ok. Interesting. I've tested it with Firefox 10 (latest stable release) and it works fine.\nGuessing it could be a Socket.IO issue but I can't find any previous reports of this.\nIs it working fine for you in another browser/version?\n. Yup this is the session id cookie bug which is now fixed in the latest master. Sorry for the very stupid mistake on my part here.\n. Hi there\nSocketStream can do this already. Instead of \ntemplates: ['chat']\nit is\ntmpl: ['chat']\n(where 'chat' is a folder containing templates).\nI will update the template docs to show this.\n. Hi there\nThanks for the kind offer.\nPlease take look at the things that must be done before 0.3.0 is released and see if any of them interest you:\nhttps://github.com/socketstream/socketstream/blob/master/TODO.md\nAlternatively, help around documentation is very much appreciated. For example, mindeavor recently contributed the Client Side Templates doc.\nBest thing to do if you wish to contribute is hang out in our IRC channel #socketstream on Freenode\nI'm not always in there but I see a log of all chat and normally respond later in the day.\nCheers,\nOwen \n. Hi Gilbert\nThanks, this looks great. Just want to chat with you over IRC before I merge it in. Hopefully catch you later today.\nOwen\n. Fix has been merged into the latest master. Please reopen if you still have a problem here.\n. Hi there\nThanks for letting me know. This was caused by a stupid mistake on my part which only showed up if you had more than one cookie present. Should be fixed now.\nOwen\n. We could have an ignore list for file extensions, in the same way we ignore hidden files?\n. Wouldn't this be a pain for you if mercurial wants to make .orig files all over the place?\n. Hmm in second thoughts, if you don't delete them, they will get packed; so I think you're right. Will change the error message to show the file name.\n. Lesson for me: Check stuff before merging it in!\nThis pull request broke the main chat demo because it didn't recognise .jade templates.\nI have fixed it now. Also removed the echo formatter, as this is basically just the .html one, so we're falling back on that now if it doesn't exist.\nBtw I ran the tests and nothing broke. Thanks again for adding them :)\n. Thanks for spotting this. I've fixed it another way, but it's been a lesson to always check stuff before merging it in!\n. Not yet on the client, sorry. I am hoping someone will contribute a solution here:\nhttps://github.com/socketstream/socketstream/blob/master/src/browser_client/init.coffee#L20-33\nIf not I will get round to it.\n. Hey. Have you restarted the server and ensure you only have one tab open at once?\nHas this just started recently?\n. Hey there. Going to close this now as we've discussed this on IRC. Let me know if you're still having problems.\n. Message efficiency is very important to me, which is how the idea of different responder came about in the first place. Once we support different types of responders you won't always have to use the JSON-encoded RPC responder for simple tasks like passing the X,Y position of a car on the screen.\nHowever being transport-neutral is also important to me, so whilst Socket.IO is using 5:::{\"name\":\"message\",\"args\":[ at the start of each message, another transport layer like Pusher Pipe or Socks JS (which I'm hoping we can integrate with) may choose to do it differently.\nAll that been said, it looks like there is something sub-optimal with the way we're transmitting Event messages so I will take a look. Thanks for letting me know.\n. I've had a look into this today.\nIt appears to be a Socket.IO quirk.\nIf you put console.log(msg) before this line: https://github.com/socketstream/socketstream/blob/master/src/websocket/transports/socketio/index.coffee#L43\nyou will see that msg is a string without any slashes. Socket.IO seems to add these when calling io.sockets.emit('message', msg) but not when calling socket.send(data).\nIf you have any insights here please let me know, otherwise I will close the ticket as it's not a major issue and likely to be fixed in a future version.\n. Yeah, unfortunately we have to pass a message here (not an object) as it looks like:\nevent\u00a7{\"t\":\"all\",\"e\":\"newMessage\"....\nMaybe there is a way to send a 'real' message (as a string) to all sockets, rather than an object? If you find a way please let me know, else I'll take a look sometime.\n. Ok guys, not had this problem myself but I will look into it today. \nI know there is a big issue with onready events at the moment in general. I am sick of having to put $(document).ready(handler) at the top of all my client-side JS files which use templates. It's one of the things I want to sort in the next alpha.\n. Guys can you get the latest code from master, delete your node_modules dir then reinstall (sudo npm link).\nThis problem is proving hard to debug so I want to make sure everyone is on the latest version of socket io\n. Guys I'm going to need some help debugging this one. I use chrome too and although I've observed the session problem #174 (now fixed), I've never had the problem of the 'ready' event not firing.\nPlease ensure you're on the latest master before reporting any problems.\n. So just to be clear here, you're getting this error from a .png file in client/static ?\n. Hmm ok, so jQuery UI must be adding a dialog box or something and requiring the css elements which in turn are looking for image files.\nThis is always a pain in the neck as all the image files should ideally be moved into /client/static/images or something like that and the links to them updated.\nHowever if you were to say this is a pain for developers I would agree with you, especially as jQuery UI usage is so common. What would your ideal behaviour be from SocketStream?\n. It's not an unknown reason :) The GET requests begins with http://fuuuu:3000/_serveDev so it never gets to the static middleware.\nThe solution, sadly, is to go through your jQuery UI CSS code and replace the relative paths to the images with absolute paths. E.g.:\n.ui-widget-content { border: 1px solid #aaaaaa; background: #ffffff url(images/ui-bg_flat_75_ffffff_40x100.png) 50% 50% repeat-x; color: #222222; }\nneeds to become\n.ui-widget-content { border: 1px solid #aaaaaa; background: #ffffff url(/images/ui-bg_flat_75_ffffff_40x100.png) 50% 50% repeat-x; color: #222222; }\nI know this is a pain, but as you can imagine it's not an easy fix. The only two solutions I can see is to rename the links (as above) or to rewrite the incoming URL.\n. You submit this issue at a good time. Now alpha4 is out and I'm pretty happy with the server-side API, I really want to turn my attention back to the client as I'm still unhappy with a few things here and believe they can be better.\nThe idea behind two vars is to have SocketStream for everything to do with the internal workings of the system (including system events), and keep the ss var just for the responders - which may be user-defined in the future, hence we keep the namespace clean for people to implement ss.model and such.\nI agree this needs more thought. I hope to get chance to think about this and other client-side issues this week. It would be useful to list them and share them on the news group so people can suggest ideas. I'll keep you posted.\n. SocketStream.ss.model is too wordy, but I like your idea of allowing the app to define the global var.\nAlso I've long thought we need a single point of entry client-side, almost like an app.js for the client.\nCool about backbone. Can't wait to start working on backbone model sync over websockets!\n. I imagine it's the Redis connection or any other open connections to blame here, no?\nWith any connections open my app terminates instantly with ^C.\n. Don't think it would be the router. Could be the fs.watch() API if you have many files in /client, esp as you only seem to have noticed this after the live reload feature went in and that is the main difference between dev and prod environments.\nNot had anyone else report this problem, and not seen it myself of large apps (with plenty of files in /client).\nCan you comment out this line and try again: https://github.com/socketstream/socketstream/blob/master/src/client_asset_manager/index.coffee#L85\n. This errors correctly now. Also sends the complete stack trace to the browser.\nWe could show stack traces in the console view too, but most of the time this would be messy and unnecessary as we are throwing the error ourselves (e.g. export.actions is not a function) and the error message alone is all you need to fix the problem.\n. Please try these examples again.\nMost of the errors here are now caught, however they will not stop the server - deliberately so. Once it's up and running we don't want any request to kill it; however, what we do definitely need is a pre-flight check (which I believe we had in 0.2).\nThis will check for common errors (such as missing exports.actions) when the responder is initialised for the first time. Of course we also need tests cases writing for all these checks too.\nAlso note I'm deliberately not checking that the export.actions function returns any actions - that's because it doesn't have to if you're using middleware which handles (or redirects) all requests to another server, etc.\nAlso we cannot concern ourselves with what functions return - it doesn't matter. All that matters is if they call res(). Technically they don't have to do that either, but it's a good idea to stop the callback stack growing too large.\n. Thanks. As you know pretty much everything is undocumented right now.\nAs I'm going away for 4 days shortly I will spend some time documenting things we have which are unlikely to change, rather than start anything new. Channels feels like a good place to start as this API is not going to change.\n. Done  https://github.com/socketstream/socketstream/blob/master/doc/guide/en/pub_sub_events.md\n. Can you elaborate, or better still, submit a pull request :)\n. I think connect.compress() will do the same thing here, no?\n. True. The /client dir is excluded as no changes here should cause the server to restart.\nInstead, any changes to this file should cause the browser to refresh.\nPlease reopen if this doesn't happen for you or you mean something else.\n. Ok thanks for updating.\nI will be away until Monday, but I'll reopen this and take a look next week.\n. Hey there\nJust trying to understand what's causing this error. Do you have files without extensions?\nI agree we need to handle this possibility better, but I would definitely encourage the use of file extensions here.\n. Ah I guess you must be calling\nss.client.formatters.add(require('ss-hogan'));\nsomewhere? As ss-hogan is for templates only, it should be called with \nss.client.templateEngine.use(require('ss-hogan'));\nIf not, I'm struggling to see how you're getting this error\n. Closing this as I don't believe this problem will arise if you use 'ss-hogan' with\nss.client.templateEngine.use(require('ss-hogan'));\nRather than\nss.client.formatters.add(require('ss-hogan'));\n. Thanks. I am aware of this. Will be fixed before 0.3.0 is released.\n. Agreed. Should help in debugging #153 too\n. Yup still needs to be done, but the API is not yet stable. Should be after the next (and hopefully final) alpha.\n. No plans to develop anything like this at present, so it would be great if you do. Thanks\n. Done now in ss-jade 0.1.1. Please let me know if this doesn't fix your problem\n. Hi there\n'localhost:5000' is for the console server only. To connect to the console install the client with sudo npm install -g ss-console then type ss-console.\nThe other bug is more interesting. I have observed this from time to time but it occurs very rarely and always go away after a server restart. It is possibly related to the recent Socket.IO upgrade - I will keep an eye on this.\nPlease reopen the ticket if this problem persists even if you restart the server and refresh the client.\n. Ah thanks for the feedback.\nI'm planning to add some contributed code which will only reload the CSS if the CSS changes without reloading everything. It won't completely fix your problem but may help eliminate some cases.\nIf you can think of any other improvements we can make please let me know.\n. Thanks. Will try this out and put it in the next release (beta1 I hope) if there are no problem.\nAlso I'm curious to see where it puts the cache files and if they cause a problem with anything out.\n. Hmm this could be a problem if you have lots of files, esp as a user will have no way of opting out of this if we put it into the core.\nI have long thought we need to cache all assets in RAM when in production, but the developer needs to be able to set limits otherwise RAM usage would get out of control (imagine an e-book site serving hundreds of thousands of PDF books).\n. It's not quite as simple as just updating package.json. I need to see if there is a new client out too - there is:\nhttps://github.com/LearnBoost/socket.io-client/blob/master/dist/socket.io.min.js\nAnd then test that out. In this case I'll need to remove some code I had to put into the previous release (https://github.com/socketstream/socketstream/blob/master/src/websocket/transports/socketio/index.coffee#L19) as Socket.IO was buggy (which has happend a few times now).\n. Hi,\nI haven't had a chance yet, please jump in. Thanks.\nRegards,\nPaul Jensen\nOn Wednesday, November 27, 2013, Morgan Craft wrote:\n\nRan into an issue adding twitter bootstrap and the css files attempt to\nload fonts/ as static content and socketstream has a meltdown. I believe\nthis is of a similar issue? I'm willing to dive in and see if I can't sort\nthis out. @paulbjensen https://github.com/paulbjensen do you have\nexisting work on this that I should look at? Or just jump in?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/286#issuecomment-29388465\n.\n. Hey. That's an old bug fixed long ago. Upgrade to the latest version and you should be fine. \n. Hi luksch,\n\nLet me take a look at this tonight. I've had to do some critical work in\nthe past week which sucked the life out of me, but I should be around to\nsort it out tonight.\nRegards,\nPaul Jensen\nOn Wednesday, January 29, 2014, luksch notifications@github.com wrote:\n\nHello!\nin the docs (\nhttps://github.com/socketstream/socketstream/blob/master/doc/guide/en/pub_sub_events.md#event-transports)\nI read\n\"The SocketStream Pub/Sub system has been designed from the ground up with horizontal scalability and high-throughput in mind. The all and channel commands will be automatically load-balanced across all SocketStream servers when an external event transport is used.\nThis sounds great, but I am experiencing very unexpected results when I\nlet two node instances run on the same server sharing the redis transport.\nI in fact end up with a scenario where each nodejs server sends all channel\nmessages to all connected clients. I thought the idea was that each nodejs\nserver only sends messages to the sessions it is responsible for. Please\npoint me to where I am doing things wrongly...\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/429\n.\n. Thanks Marcin!\n. Hi Kryton\n\nThis is fixed in 0.0.56. Thanks for letting us know.\n. Thanks for the link. We'll take a look.\n. The UA sniffing is turned off by default, though 'Strict' mode can be switched on if desired.\nI have to say, I can't get excited about any browser which makes the end user jump through hoops to be able to use websockets. This goes for IE 9 too.\nAs soon as these browsers support websockets out-of-the-box we'll be pleased to mention them in the Features. Until then, if any one wishes to write a small FAQ mentioning experimental support in Opera and IE 9, I'd be happy to merge that in.\n. That would be good. Just one or two sentences will do.\nThanks,\nOwen\nOn 26 Jun 2011, at 14:51, tronning wrote:\n\nIt's not \"jumping through hoops\" It's one switch that has to be turned on in Operas settings. It's all there just like in Chrome and Safari, just not turned on by default. I'll do the Opera FAQ if you want to?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/9#issuecomment-1440936\n. Perfect. Thank you. Will add it to the docs shortly.\n\nOn 26 Jun 2011, at 15:54, tronningreply@reply.github.com wrote:\n\nok :\nQ: Will SocketStream websockets apps run in the Opera browser?\nA: As of this writing websockets is supported but turned off by default in Opera. In order for Opera 11 to run websockets apps you need to turn it on in the settings. Do \"opera:config#Enable%20WebSockets\" in the address field and hit enter. Check \"Enable websockets\" Save and you are good to go.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/9#issuecomment-1441470\n. browser_check is normally switched off by default so I presume you switched it on here? If not, it's possible you have some client-side code in there showing the message.\n. Hi\n\nAt the moment the exports.authenticate = true flag is only read by the HTTP API (it engages Basic Auth). It has no effect on the websocket request. We will change this in the future.\n. Hi there\nI'm sorry, we've not had chance to test unicode support here yet - though I did presume it would have worked fine as we have used unicode characters in other areas within Node without any problems.\nCan anyone else look at this issue?\n. Awesome. Thanks! Merged already. Will sort a new npm package out shortly. \nOn 28 Jun 2011, at 17:11, eliseereply@reply.github.com wrote:\n\nI dug a little and I fixed it:\n- javascript is served as text/javascript and no charset is set so if the browser requests something else by default (iso-8859-15 in my case), the resource gets interpreted as such. It can either be fixed by changing generated tags to request type=\"text/javascript;charset=utf-8\" or by serving the actual resource with a \"text/javascript;charset=utf-8\" header. I went with the second option and made a pull request\n- Length of response in server.deliver was computed with body.length (which returns the number of characters instead of the number of bytes) so I switched it to Buffer.byteLength(body)\nThe pull request is above :)\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/13#issuecomment-1459064\n. Yup. This is one of the major known issues. We've documented it in the readme. For now you must create your new file, restart the server (so it starts watching it), then touch/save and of the existing files to trigger a rebuild. Sucks I know. \n\nUnfortunately the fix is not simple as watching for new files efficiently on both OS X and Linux platforms is tricky. Someone wrote a library for this recently and mentioned it on the node.js google group, but I haven't had time to play with it yet.\nIf you can help in anyway here it would be awesome. \nThanks\nOwen\nOn 28 Jun 2011, at 20:45, Rodeoclashreply@reply.github.com wrote:\n\nIf I add additional files to:\n/lib/client/\n/lib/css/\nThe docs specify that these changes will be detected upon a server restart and recompiled. This behaviour does not occur until I manually delete the files stored under /public/assets/\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/15\n. Here you go:\n\nhttp://groups.google.com/group/nodejs/browse_thread/thread/57815dc0b6763fb3/9c852dcf633ed8f5?lnk=gst&q=stalker#9c852dcf633ed8f5\nNot tried it myself. Speed and efficiency are key here - as is perfect support for Max OS X and Unix/Linux platforms.\nIf we can crack this nut it would be very exciting.\n. Thanks Elis\u00e9e. That would really help us.\nI will try it on Linux and Mac before merging it in. Typically Linux detects changes instantly whilst OS X polls at intervals. Do you know if stalker solves this polling problem? I know it's something to do with the different file notify libraries within the kernel but I don't know the exact details off hand.\n. Hi Elis\u00e9e\nJust wondering if you made any progress with this? I'm working on v 0.2.0 now and want to make sure it recognises new files correctly.\nOwen\n. Fantastic. Thanks :)\n. Hi Elisee. Any luck? Let me know if you don't have time and I'll take a look this weekend.\n. Hi Elisee\nWith the first 0.2.0 release only days away now I'd like to take one last look at this and see if we can crack it.\nDid you get anywhere? If not, no worries - I'll see if we can solve this via other means.\nThanks,\nOwen\n. No worries. I will have another go later today/tomorrow. Would love to get this into the final 0.2.0 release, due out tomorrow.\nElisee, do you have your latest code on Github?\n. Ah right. Number 2 is more concerning as it would mean we need two different ways to watch a directory.\n@jslatts are there any plans to add a callback when an existing file changes?\nThanks for your collective efforts so far\n. Hey Elisee\nClosing this now as 0.3 cunningly does away with this problem altogether by serving everything live in development mode. Thanks for your efforts here. I hope you'll give 0.3 a whirl in the future.\nOwen\n. Great! I've also started discussions with other hosting providers to figure out which ones we can recommend to SocketStream developers. People want to deploy their apps faster than I thought!\n. Paul's script can be found here:\nhttp://groups.google.com/group/socketstream/browse_thread/thread/faf1336e13dc4006\nGood work!\n. Hi there\nWe are seeing this error occasionally when using HTTPS too. \nI am hoping the latest release of node (out today) may be the solution as it has improved HTTPS support. If not a new release of SS with Socket IO 0.7 will be out within a week. We will begin debugging properly if the problem persists.\nOwen\nOn 29 Jun 2011, at 16:48, jmonsterreply@reply.github.com wrote:\n\nThis could be a problem with a dependency, such as Socket.IO ... I'm new to node :\\\nNote: This only happens with HTTPS\nIf I sit in a browser and hold in Command-R (reload), after a couple refreshes the server dies with the error:\nnode.js:134\n       throw e; // process.nextTick error, or 'error' event on first tick\n       ^\nError: EPIPE, Broken pipe\n   at Socket._writeImpl (net.js:159:14)\n   at Socket._writeOut (net.js:450:25)\n   at Socket.write (net.js:377:17)\n   at EncryptedStream.ondata (stream.js:36:26)\n   at EncryptedStream.emit (events.js:64:17)\n   at EncryptedStream._push (tls.js:299:12)\n   at SecurePair.cycle (tls.js:581:20)\n   at CleartextStream.write (tls.js:96:13)\n   at ServerResponse._writeRaw (http.js:391:28)\n   at ServerResponse._send (http.js:371:15)\nMy guess is that a socket is closed but something (net.js?) is attempting to write to them anyway\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/20\n. No, it's not a simple migration - as I'm finding out ;)\n\nNearly there though. The new Socket.IO 0.7 version will be ready for testing in the dev branch within a few days. Just doing a lot of travelling / meetings at the moment.\n. Good news here: Node 0.4.9 seems to have solved this problem. Yay\n. Hmm interesting you bring this up. I have been considering having an /config/app.coffee file instead of /config/app.json file for a while. It would allow us to add more comments into the file to describe what each option does. Hence you would have:\n```\nSet Primary Server Port\nSS.config.http.port = 80\n```\ninstead of\n{\"http\": {\"port\":80}}\nTo be honest, one of the main reasons I'm leaning towards the CoffeeScript approach is because the 'true' JSON parser is just so damn picky.\nI'm going to leave this issue open a while. If you feel strongly against the move to /config/app.coffee speak now :) Otherwise it will probably happen at some point in the near future.\nThanks for bringing this up. Let us know how you get on with Cloud9IDE.\nOwen\n. Hmm I thought about supporting both methods and then thought against it - let's just pick the best one and go with it. I vote we go for /config/app/coffee  We don't want to be supporting two ways of merging configs and explaining how to set your config in the readme for evermore.\nPaul if you can work on this that would be awesome.\nLet's do something like:\n```\nCONFIG FILE\nexports.config ->\n# HTTP\n# Set host and port to listen on\n  SS.config.http.host = '0.0.0.0'         \n  SS.config.http.port = 80\n```\nThis way we can simply require the file as a normal module. We will then need to load-in any environment-specific config file (like /config/environments/development.coffee) right after, effectively over-writing some settings in /config/app.coffee\nOf course, now we have people working on this SocketStream projects for real, we also need to be able to handle the upgrade nicely.\nTherefore the second piece to this change is to make a beautiful upgrade framework which will read the last_known and current values from SS.internal.state and run scripts if it detects you've just upgraded to a newer version.\nIt should pop up on the terminal with something like:\n```\nWe notice you're upgrading from SocketStream 0.1.2 to 0.1.3.\n\n0.1.3 sets config variables programatically instead of declaring them as JSON. Your JSON-based config files will be left untouched, but you'll need to manually set the same parameters in /config/app.coffee\n\nDo you wish to proceed with the upgrade? Y/N\n```\nSomething like that anyway. If we design the upgrade framework we'll be able to do automatically major changes in the future very easily (and automatically wherever possible).\nAnyone fancy having a go at this? Name your module /lib/upgrade.coffee\nCheers\nOwen\nOn 1 Jul 2011, at 07:23, paulbjensen wrote:\n\nMaybe we could have a dual-compatibility approach, so that you could use /config/app.coffee in place of app.json. We could keep app.json as the default used in new generated apps.\nI will work on this feature.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/21#issuecomment-1482139\n. Ah right! Keep it as a declared object. Yes, that will be much neater - especially as we will still be able to put comments around the settings (something I'm very keen to do). It may make it harder to 'uncomment' things should you wish to enable them - I'm not sure without giving it a go.\n\nWe should definitely try this approach first. Thanks!\nOn 1 Jul 2011, at 10:21, ggoodman wrote:\n\nHi the sort of coffeescript config file I was thinking about would look something like this.  This would mean a very similar syntax to your existing json config.\ncoffeescript\nmodule.exports =\n http:\n   host: '0.0.0.0'\n   port: process.env.C9_PORT\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/21#issuecomment-1483062\n. Paul's changes are now in the master branch, released as 0.1.3. The config files are now much cleaner and we are able to include inline comments - as well as dynamic values, allowing you to use SocketStream with Cloud9IDE. Good work!\n. Hmm thanks for letting us know. We've not tried this yet I have to admit. Would be good to get it working.\n\nIn other news... how does everyone feel about jQuery templating vs other solutions out there?\n. I too favour supporting multiple engines using file extensions. We will work towards that in future releases.\nGoing to back to the start of this thread, Samuel you'll be pleased to know 0.1.4 now allows nested directories in /app/views. It will be released shortly.\n. 0.1.4 is now released. This should fix the original problem. Please let us know if there are any problems.\n. Hi there\nThanks for this. We're going to keep the extensions (now renamed as helpers in the client and server) in JS for now, but we may change that in the future. \nIt would be nice we could come up with an easy way for you to append your own helpers..... I'll have a think about that.\nCheers,\nOwen\n. Thanks Andrey\nI see your point. This is a tricky one as I've been used to calling Array.any? in Ruby/Rails for years and really miss that in JS. Such a shame JS doesn't support question marks in method names :)\nI'm going to leave it in for now, but if there is strong opposition against keeping it in we could change it to Array.hasAny instead. What does everyone else think?\nThanks for pointing it out.\n. Thanks for raising this Andrey.\nThis is a pretty complex issue and I really want to make sure we do the right thing here.\nI will discuss it with Addy and the rest of the team next week when I'm back in London and keep the discussion going here.\n. Hi Andrey\nThe bind method you suggested is now in 0.1.4 by default.\nWe're not going to include Augment.js at this time, but it's nice to know the option is there in the future.\nThanks,\nOwen\n. Not easily at the moment, sorry. Before we send the 'shared' file to the client we do a quick regexp on all the uses of 'exports.' and replace that with the full namespace. It's obviously a hack, but a very high performance one which makes the API tree concept work a treat. Additionally in staging mode this is only ever done once and doesn't require the client to do any complicated processing (or use 'requires').\nIn the future it may be possible to parse the file properly so you could alias exports to something else, but it's not high on our agenda at the moment.\nOf course, if you can think of a different way to make shared code work seamlessly across client and server - please let us know. As always with SocketStream, consistency and performance are our key considerations.\nThanks,\nOwen\nOn 1 Jul 2011, at 16:27, colinsullivan wrote:\n\nSay I have the following in a .coffee file in shared/:\nColin = exports\n   Colin.VERSION = '0.0.1'\nThis will get compiled to:\nvar Colin;\n   if (!SS.shared.Colin) {\n       SS.shared.Colin = {};\n   }\n   Colin = exports;\n   Colin.VERSION = '0.0.1';\nBut if I have this:\nexports.VERSION = '0.0.1'\nIt gets compiled correctly, as\nSS.shared.Colin.VERSION = '0.0.1';\nWould it be possible to include usage of the exports variable as in the first example?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/27\n. Hi Colin\n\nGoing to close this for now. If anyone want's to submit a pull request containing some super-smart regexps I'll be happy to merge it in - but for now, please stick to using the word 'exports'.\nCheers,\nOwen\n. SocketStream does it all automatically for you, front and back end - and everything in between :)\nInvestigate the API trees concept. Basically you can have as many sub-folders and files as you wish.\nDon't put dots in your file names. Instead do this:\nshared/Foo   <- make this a directory\nshared/Foo/Bar.coffee   <- a file\nshared/Foo/Models/Customer.coffee\nNow you can do SS.shared.Foo.Bar.method_name() or SS.shared.Foo.Models.Customer.find() or whatever you like from both the front and back end.\nIf for any reason this doesn't work as I've described, let us know. Thanks.\n. Wow never knew about that - thanks. But the I suppose for us the question is, can github do coffeescript? :)\nOn 3 Jul 2011, at 20:45, chikamichireply@reply.github.com wrote:\n\nHi, just a quick issue that's a suggestion, really: you may want to use\njavascript\n// the code\ninstead of indentation, so as to benefit from syntax highlighting; especially in the README.md file.\nKeep the good work going :)\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/29\n. I agree. Good find!\n. Hi ltackett\n\nThere is no real requirement for wget - you could just as well use curl or simply click and download as I did. I've updated the documentation to reflect this. Thanks for pointing it out.\n. Hmm good point. So you won't be able to do this by putting your methods in exports.actions; however you can write your own server-side modules, put them in /lib/server and 'require' them into your server-side code by name.\nBy doing it this way callbacks are entirely optional (though always recommended if you're doing any IO whatsoever).\n. Totally agree. It's going to happen automatically without the need for a wrapper.\nThis is all linked to child processes, something we're spending a lot of time researching at the moment. Fortunately there are new advances in Node 0.5 which will make this easier for us.\nRealistically I feel this functionality is about a month or so away at the moment, but child processes and scalability in general will be our major focus once Socket.IO 0.7 is integrated and stable.\n. Hi Jonathan\nI've not used node-inspector myself but I've heard really good things about it - so I'm keen to support if it's an easy change.\nI'll add it to the list of things to look at. If anyone wants to take a stab at this and submit a pull request I'd be happy to merge it in.\nOwen\n. Great! Thanks Harlan.\nI've put it on the list for 0.2.0 which makes use of child_processes and auto-restarts when the server code changes.\n. Hi all. Support for debugging is coming in the next 0.2 beta later this week.\n. SocketStream 0.2 beta 2 now supports the Node debugger. Just type debug before the command you wish to run. E.g.:\n`socketstream debug server`\n. Thanks for spotting it!\n. I'm happy to abandon the numbering system for JS and CSS client libs and go with manual declaration in the config file if people prefer this. I always realised this was going to be a contentious decision :) I just like it myself precisely because you don't need to update another file when you add a new file.\nThat said, manually specifing everything does tie in nicely with our plan to deliver different assets to different devices (e.g. serve mobile libs to iPhones). Maybe a /config/assets.coffee file is the best way to declare this all.\nI would certainly want to stay well clear of using 'require' on the client. We tried this at first and it didn't feel right. That said, we do need to find a way to async load in additional libs in the future.\nIf anyone has opinions on this one way or another, please post them below. \n. Cool ok. I have been outvoted :) 0.2.0 will abandon the numbering system and allow you to specify each asset in a config file.\nThis will make it a lot easier to handle multiple types of clients, so it's no bad thing.\nOn 12 Jul 2011, at 18:45, eliseereply@reply.github.com wrote:\n\nI like the simplicity of the file numbering but the truth is, the day you'll need to add a file between number 2 and 3 and you already have 20 other files, it's going to be painful. A list in a config file would be much easier to edit for sure, so I would go with that.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/35#issuecomment-1556208\n. Want to give a quick update on this.\n\nI tried re-working the asset manager for 0.2 and realised it was going to be a huge undertaking to do all the things we've mentioned here plus a bunch of other stuff that needs to be done at the same time to prepare it for future plans we have.\nHence the Asset Manager will get completely re-thought and re-written as part of 0.3.\nThe 0.2 preview will be out in a matter of days now and includes many huge new features. As soon as it's stable I'll start working on 0.3.\n. Paul will submit a revised version in the future\n. Hi there\nWe have seen this issue before. Thankfully I got chance today to properly debug it.\nIt turns out to be a bug caused by the fact document.location.port will happily return you a real port number - unless you're running on port 80 or 443 in which case it's blank. Handy! This was leading to a malformed URL string (which I can see in your example above) and hence the NPObject error and no flashsocket connection.\nThis will be fixed in 0.1.5 which should hopefully be released later today.\nThanks,\nOwen\n. Ah great. Thanks for this.\nYou're spot on about only passing the request to the middleware once it has been fully received.\nWe have plans to use POST requests in the future to handle file uploads and REST. Apart from that, I was thinking the need to read this data is probably pretty limited (as form input should be sent over the websocket). What are you using the POST data for may I ask?\nLet's try to figure out the possible use cases then we can see if the framework should handle this or push the 'end' handler into /config/http.coffee so the developer can choose to intercept incoming request stream data there. This would break existing sites so it may have to be change for 0.2.0.\n. Thanks Derek. We'll definitely come up with a nice way to get hold of the POST params in a future release.\nI'm going to be looking at using Connect middleware in v 0.2.0. That may well be the solution. I should get time to experiment with this over the weekend.\n. Going to close this now. I have re-written the middleware in v 0.2.0 to use Connect and it's working well.\nThis means a new /config/http.coffee file format but it's worth it to plug into the wealth of 3rd party extensions and have full access to the POST headers.\nVersion 0.2.0 will be out within a few weeks.\n. Hi Derek\nHTTP POST data is now accessible in the latest 0.2 beta using the new @request object (available within your /app/server methods).\nLet me know how you get on.\n. This makes me think we should fully support Connect. I have thought about doing this a few times for authentication and other reasons. It would then be easy to route HTTP requests to Express or another framework.\nThe only reason I haven't done this so far was to keep everything as close to the standard Node libs as possible for speed and flexibility - plus of course it's another mandatory library to install.\nI'm going to have a play round with this idea for v 0.2.0. Anyone got any thoughts or comments on this?\nFor now if we make the servers object (containing the primary and secondary server object) a global var (SS.internals.servers) would this help you out in the short term?\n. Great ok. Look out for it in 0.1.6 which is no more than a few days away.\n. Yes, quite correct. The hiredis driver gives extra speed but is not required. We can get rid of the dependency in a future version.\nI'm keen to keep the focus on speed and do everything we can to make apps run as fast as possible. If you don't have it installed we could show a warning upon startup.\nGood compromise?\n. Closing this has the dependency has been removed from 0.1.7\n. We hear you :)\nI will register the #socketstream channel and include this in the github (and tweet it) once it's done.\nThanks to Mark Ach\u00e9e who gave me the details on how to do this (and was the first to request a channel some weeks back).\n. Done! Join us on #socketstream on freenode\n. Thanks!\n. Changed in the forthcoming 0.2.0. Thanks!\n. Hi RJ. Thanks for letting us know. Fixed in 0.1.8.\n. Thanks Blake. I'm afraid my head is full of the features going into 0.2.0 at the moment, but I welcome any discussion around this topic.\nIt's not something every web app would want (e.g. a stock trading site or a real time game), but if your app is content based it would be nice if we could have a solution (or at least a recipe) that pleases the end user and Google at the same time.\nAll suggestions welcome. As always don't be afraid of making big changes to the existing implementation (i.e. jQuery templates) if it means a clear win in other areas.\n. Very interesting. If you can get something up and running it would be great to cover it in the docs. I know at least one other person has asked me about this.\nI could see this becoming a separate Connect module which is optionally loaded into the HTTP Middleware stack (v 0.2.0 uses Connect).\n. Hi Blake\nThanks for your interest here. Going to close this now as 0.3 is fully compatible with Connect, Express and anything else out there so it should be possible to build something like this on top of SocketStream. Doubtless an area I will revisit in the future once 0.3.0 is finished.\nOwen\n. We can definitely do this. Just to check with you, as I've not used this myself, the auth function does not require a callback? \n. Great. This is now in 0.2.0. Please give it a go when it is released and let me know if it all works as planned. Thanks for the suggestion.\n. Ah right, didn't know that. It's a simple one liner so far and it's definitely in 0.2.\nCurrently targeting Sunday for the first preview release of 0.2.\n. Hi there\nPlease see previous discussion on this: http://groups.google.com/group/socketstream/browse_thread/thread/0834dfdc0bc5a3c4\nI'm still tempted to implement it in future versions, but the main problem is the HTTP API. Right now it all works well because multiple vars are handled by providing an object over websockets or a query string which we turn into an object. But once /app/server methods expect more than one arg, what do we do with the HTTP API?\nIf we can solve that issue, I'm happy to make 0.3 support multiple arguments.\n. Hi guys\nYou may be interested in the discussion going on here: http://groups.google.com/group/socketstream/browse_thread/thread/7c832596e4785f2e\n. Hi there\nWas just about to drop back to the 0.1 branch, dust off my svn skills and give this ago but alas NPM is currently down.\nRather than explicitly filtering out .svn files, let's filter out any files beginning with a dot. I know many functions already do this but clearly something has slipped through the net somewhere.\nWill hopefully try again later this evening NPM permitting.\nOwen\n. Hi syrio\nThanks for the pull request. I'll decline it only because this is no longer an issue in 0.2 and all the effort is now going into making this stable in the next week or so.\nOwen\n. Sure - it sounds like a simple change.\nI would say make a pull request and I'll take it from there - but I'm more concerned with how Cloud9 will work with 0.2 given the split process architecture and need (at least for now) to have ZeroMQ compiled.\nIf you could give 0.2 a whirl on Cloud9 I'd be interested to hear how you get on. Hopefully the problems you find can be resolved quickly.\nOwen\nOn 17 Aug 2011, at 15:25, ggoodman wrote:\n\nIn a non-standard run environment (Cloud9IDE). I have a bootstrap file as such:\n``` coffee-script\nrequire(\"coffee-script\");\nss = require(\"socketstream/lib/main\");\nss.init();\nAdjust SS.root to a subdirectory instead of the root dir\nSS.root = SS.root + \"/appname\";\nss.start.server();\n```\nI have had to modify the line in assets/index.coffee where the public_path is set from exports.public_path =  './public/assets' to exports.public_path =   SS.root + '/public/assets' as well as making similar changes to the watch_dirs to make them based on SS.root instead of the current working directory.\nIs this something that you would consider integrating into master?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/54\n. Boo. Thought that may be the case.\n\nI'm hoping we can drop the mandatory requirement to use ZeroMQ once Node 0.6 comes out and everyone is using it. This will allow us to use the new inter-process JSON message API instead when running the 'socketstream server' integrated server in development.\nHowever, the need to launch two processes is essential if we're going to support auto-reloading server-side files upon change. Do you know if Cloud9 is ok with that?\nWhen I get chance I'll play with it a little - I do love the idea of an IDE on the web.\n. Good news. The next version of 0.2 (most likely beta2) will support Cloud9IDE. Should be ready later this week.\n. Beta2 committed to Github now (moved to master branch). Should load fine on Cloud9IDE as ZeroMQ is no longer required.\nPlease submit a pull request for the path changes you described above and I'll merge into master.\n. Great. Is there anything I could put in the Readme to make it easier for others wanting to do the same?\n. Hey @ggoodman \nAny chance of letting us know what you needed to tweak to make SocketStream work with Cloud9?\nI would love to put it in the docs as a few other people would like to know.\nCheers,\nOwen\n. Hey there\nThanks for this - very helpful.\nAs it turns out I'm already modifying the interface exposed in 0.2.4 as I needed to make changes for testing and seeding the DB, so I'll make sure you're able to start the server this way too.\n. I've released 0.2.4 today which should make it much easier to use SocketStream with Cloud9 without modification.\nSee https://github.com/socketstream/socketstream/blob/master/HISTORY.md\n. Hmm looks like you still have SocketStream 0.1 installed in the global path.\nMake sure you run 'npm install -g' from within the SocketStream 0.2 directory.\nLet me know how you get on.\n. Closing this for now. Let me know if you still have an issue here.\n. Thanks! Fixed in the latest 0.2 code I'm pushing later today or tomorrow.\nOnly tested this on /app/client code though.\n. I quite like the idea of app.domready and app.load, as well as app.init but to be honest I've always felt the init method is living in the wrong place as it is.\nI'm tempted to change this in 0.3 so we emit an event to SS.events.on 'init' instead - and maybe also have a separate file for client-side system events, like we have /config/events.coffee for server-side events.\nThis feels cleaner to me than muddying up your own application SS.client code.\nAs always thoughts and suggestions welcome by all.\n. Closing this for now. Will definitely try to integrate these ideas into 0.3.\n. As far as I can tell this is fixed in 0.2 with server-side events, specifically the\nSS.events.on 'client:init'\nevent. Please re-open the issue if this is not the case.\n. Yup. Vendor has gone in 0.2 anyway.\nPrior to the decision to remove require.paths from Node 0.5, the simple solution would have been to put any shared server-side code in /lib/server\nNow it will have to live inside the /node_modules directory of your project - which in fairness isn't so bad.\nIf you can think of any better solutions let me know.\n. Not sure Node allows you to look in two dirs (I think the whole point of abolishing require.paths was to allow developers to know exactly where to find external modules) but I definitely want to get this idea tested and documented. Cheers\n. Thanks. This was fixed in the 0.2 beta i pushed last night\n. Hi there\nNo unfortuntaly not. By design HTTP middleware is called before the request hits any part of the SocketStream stack.\nTherefore two options are possible in the future:\n1. We make possible and document how you can parse the session_id cookie and load a session manually\n2. We look into better ways to do authentication\nI am going to be looking at the latter over this next week. In particular, seeing if we can integrate Conenct Auth or Everyauth.\n. Ok thanks. Will give this some thought\n. Closing this for now. Going to bear it in mind for the future as we need to do this ourselves.\n. Hi Colin\nAs the load order can never be guaranteed, simple call a function once all the code has loaded which extends your code as desired.\n. Indeed. Very true. This is already listed in TODO.md to be done before the final 0.2 release. You'll also see a link to the bug I had when trying to use the 'zmq' package. Hopefully that's being fixed now.\nI will try again in the next few days as I'm doing a fair bit of work around the transport layer at the moment.\n. Got the new zmq npm working well with beta2 which I'll push to Github today or tomorrow. Hopefully it will well for you too\n. Hmm ok. I wonder if we should we even make it a hidden file at all now we have a /tmp dir\nMaybe better move it to /tmp/last_known_state\nAlso, we need a place to record PIDS in use so deployment scripts can kill master and child processes upon pushing out new versions of the app\n. In this context 'state' means the version of SocketStream last used to to run the application with.\nThe 'server' version is used to warn if you try running the app with an earlier version of SocketStream.\nThe 'client' version is used to force a rebuild of all client asset files if the client code has been upgraded.\nI would love to integrate well with common deployment platforms.\n. I'm keen to keep all the related files together in the app directory. Mostly because we want to be easily support hosting providers hosting hundreds of small SocketStream apps on the same server.\nNow each app has a local /tmp how about we do /tmp/socketstream1.pid, /tmp/socketstream2.pid etc (numbers are necessary when running in multi-process mode).\nThe last known state file could live in /tmp/last_known_state.json\nSound reasonable?\n. Closing as there is no concept of .socketstream_state in 0.3. The onus is on the app developer to use the right api syntax with the right version of SocketStream. If I need to reimplement this idea I will reconsider the name.\n. Great! Thanks a lot.\nJust to let you know, I'll be moving a lot of things out of the main README in 0.2.0 and into /doc/guide\nI was thinking of doing /doc/guide/en so we can do a /doc/guide/jp etc in the future.\nEach markdown file will represent a page/section on the forthcoming website (i.e. the website documentation will come from these files).\nAny thoughts?\n. Thanks\n. So there are big plans to re-write the client asset manager in a future release of SocketStream.\nThe new version needs to do the following:\n1. Support multiple pages/clients. I.e an iPhone client, or Admin client to be delivered if you goto /admin\n2. Have a new file containing rules to determine which client to serve a device (using a combination of user-agent and URL)\n3. Support other file formats such as .less and .sass without having to load or install anything we don't need (hard!)\nOn top of this is the need to do what you mention - to be able to load in new CSS and other client assets as the application requires.\nAs you can see there's lots of work to do here, but I'm keen to get some plans in place on how to tackle this - and ideally some help with the coding.\n. Great news. Thanks!\nI will be looking at Connect Auth and Everyauth over the next few weeks. If you are doing the same let's share findings.\nWith the new Plug Sockets feature in 0.2 you should find it very easy to connect to your external servers using zmq. Feel free to develop / improve the wrapper it uses if you need more features (such as timing out should the connection fail).\n. Is this issue still relevant?\n. Ok thank you. Going to close this now.\nFor anyone finding this in the future, supporting different types of CSS files (i.e. for 'handheld' devices) can now be achieved by detecting the useragent and sending a different CSS file (by defining a new client with ss.client.define).\nSupporting a print style sheet could be achieved by adding a 'manual' CSS link in your app view and pointing it at a CSS file in /client/static.\nNot perfect, but it will do for now as there are much bigger fish to fry.\n. CoffeeScript automatically wraps all files within closures in order to prevent polluting the global namespace. If you're not using CS it would be a good idea to wrap everything in the module pattern as you suggest.\nDespite my dislike of the 'require' method, I actually like the elegance of your proposed solution. Thanks!\nIt needs to go hand-in-hand with other features which will come with a re-write of the Client Asset Manager which will also involve big changes to the project directory structure. This is sounding like something for 0.4 as it maybe too big for 0.3 (which really needs to be about getting Models and Authentication right).\n. Closing this now. You will find something very similar to this idea in 0.3, hopefully ready to go onto github tomorrow. Thanks for the inspiration and ideas!\n. Hmm yes this is an issue at the moment. The current approach is fast (performance wise) and consistant with the rest of the API, but it's not ideal. It can be caught ou' as you've found.\nMy biggest gripe with using 'require' is that it feels cumbersome and messy. Ryan Dahl has also stated he doesn't like it and wishes Node.js could do something better.\nReally what I need to do is work out the new features I really want to support in the future (such as multiple clients) and see if the API Tree concept still holds, or whether we need to do things very differently. It may be requiring modules is the best way after all, but I don't want to make a hasty decision.\n. I have been working on a new solution for SocketStream 0.3 which does away with the textual replacement problem altogether. Closing this now, but thanks for raising.\n. The problem here is that the exception is happening inside the callback, not in the scope of the method.\nIf it did, you'd see the stack trace passed up to the browser console, plus a mention in the log.\nThe problem of tracking and handling exceptions within callbacks seems to be commonplace when using Node.js. I'd love to know the proper way to do this as it catches me out a lot!\n. Good catch. Thanks!\n. Hi. Do you get the same error if you delete the .socketstream_state file and restart? This will force the client libs to rebuild.\nIf so it looks like a potential bug in the new Socket.IO library, though not one we've seen with our own apps running 0.2.0.\n. Assuming this is ok now. Let me know if not\n. Thanks for spotting. Will put an 8Mb configurable limit on in 0.2.1\n. Not at the mo, but it should be very easy for you to do that right now following the examples in /config/http.coffee\nI am interested in supporting an optional module which makes file uploads easy, sending progress back to your app via an event emitter. I was looking at formidable and formaline earlier today. Both look very interesting.\nIf you fancy giving them a go and reporting back that would be very helpful.\n. Fixed in 0.2.1 so closing this\n. Hi there\nGlad you've got this working. Going to decline the pull request for now as:\n1. I've already put a max POST limit on the HTTP AP in 0.2.1 (to be released soon). This should be present whether or not you want to use node-formidable else otherwise it would be very easy to bring down any SocketStream server.\n2. Handling file uploads is something we want to support whether or not you wish to use the HTTP API. It should be a separate module, which very likely will use node-formidable but I wouldn't want to rush the decision. A lot of factors need to be considered.\n. Hi Colin\nMake sure you're looking at @session.user_id (not @session.user.user_id as above) and don't set it directly - use the @session.setUserId() method.\n@session.user.user_id woud set a value on a module which would remain the same for every user/browser.\nOh an just FYI as you asked in IRC, @getSession(cb) is now deprecated in 0.2.0. I thought it was going to be necessary to use callbacks but thankfully I found a way round it.\n. Yep setting @session.user.attributes is the same issue. It doesn't exist at the moment, so please use @session.attributes instead.\nHere's a big problem I would love people to use their brain power to help me solve:\nWe need to separate internal user commands (such as @session.user.logout() ) with the need to access an instance of your own custom user model (i.e. @session.user.checkoutCart() ).\nThey both can't exist in the same space so I've deliberately kept @user as reserved variable name for now thinking this is where the 'instance' of your custom user model will reside... but as you can imagine they are very interlinked, sharing the same id attribute as a bare minimum.\nI would welcome some clever thinking here as it affect the way we do Models in v 0.3.\n. Hey Marcin\nGreat to hear from one of the first watchers of the project :)\nI need to think about this a little. So you're wanting to message individual tabs/windows, even though they may be logged in as the same user?\nThe easiest way is to simply subscribe each client to a different channel (channels are linked the the client/socket, not the user_id) then message that channel.\nThis way should the user hit refresh and get a different socket_id (as they would), you can still continue messaging that tab - even if they are connected to a different front-end server.\nAlso there are plans afoot which would be impacted if we added SS.publish.socket(). I will tell you about them in Dublin at the end of the month.\nLet me know if publishing to a channel doesn't work for you.\nOwen\n. Hi Marcin\nYou are spot on. If you really really want to target the individual socket, regardless of session, this is the only way to do it.\nI'll merge the change but won't document it until I'm sure of our current plans around this area.\nI will arrive on the 28th so unfortunately it sounds like I'll miss you. Shame!\n. I'd like to pass through the socket_id as @request.socket_id\nBasically the @request object is full of meta data that most people won't care about, but it's there in case you do.\nSound ok?\n. Just doing it now. \nNeed to change things slightly as backend/publish.coffee has no way to access SS.io.sockets unless it's running in single process mode, hence the event must go via redis and the internal RPC transport. Just looking into it now...\n. If we're going to add it into the core it needs to work the same way whether or not you're running in single/multi process mode, just like everything else.\nGood news is it's a simple fix. Just need to write a test then I'll merge it in.\n. I've merged-in the code and modified it slightly. Also taken the opportunity to do some broader refactoring around publishing events. All this will go into 0.2.2 in the near future, along with documentation for the new SS.publish.socket(socket_id, ...) method.\nThanks :)\n. Don't worry, it's on its way :) The release I'm working on still needs a bit more work.\n. Don't worry, it's on its way :) The release I'm working on still needs a bit more work.\nOn 19 Sep 2011, at 07:50, Marcin Olak wrote:\n\nit seems like this patch didn't make it into 0.2.2? : >\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/pull/78#issuecomment-2134372\n. Hey there\n\nCould you tell me what you're trying to do in Jade?\nAs we are very much a single-page framework all data manipulation is done client-side in the DOM, hence the jQuery templating (though SocketStream should would fine with other templating libs).\n. If I understand correctly, we do this ourselves with the != SocketStream magic variable, but there would be no point in you doing this as all the HTML the client requires (basically the layout structure) is rendered and sent once upon initial connection. After that all the magic needs to happen in the client.\nDo let me know if I've completely got the wrong end of the stick here :)\n. Cool ok. Can you describe what you mean by template inheritance?\n. Great suggestion. Will definitely implement this. Thanks\n. Hey Jerry. For sure. If/when we do this it won't be mandatory.\n. Closing this as this feature is now implemented in 0.3 alpha3 by setting the maxAge option:\nss.session.options.maxAge = <value in milliseconds>\nPlease reopen if this doesn't work as expected.\n. This is true, we're not watching these files - only the /lib/client files\nWe could, but we really need to test out the performance if Node is watching a large number of app files in Dev mode.\nAlso right now it's still possible to save a file, change to your browser and press reload faster than Node can detect the change on OS X - which means this feature isn't as useful as it could be.\nOnce Node can monitor a large number of files efficiently and detect changes (and additions/deletions) on OS X as quickly as Linux it will be an awesome feature.\n. Hi there\nCan you tell me what the use case is here? You may always get the session_id cookie via @session.id, but I'm guessing you're wanting something else here?\n. Hi there.\nSorry for the slow reply - on vacation at the moment.\nStill not convinced we nee the additional RPC overhead of sending cookies (i.e. on every request over ZeroMQ when running in multi-process mode).\nThe easiest way round this problem is to save a 'permanent' cookie on the client as you suggest but send the value of this to the server on the first command you call. You can then write a server-side action to attach the language value to the session via @session.attributes\nNot ruling out it for good, but this seems like the best solution for now.\nOwen\n. Thanks for the suggestion. Quite like the idea of per-request/module settings but it would need to be written for other settings - not just for this one. I'll bear it in mind. Cheers\n. Done!\n. Hey there.\nNot sure of an exact timeframe for this but it's definitely on our short to medium term roadmap, along with server-side models.\n. Hi Andy\nYou're right. Lots of the initial code grew organically from the 'is it possible to do this' experiment I did about this time last year. The session stuff is the oldest and worst of the lot written before the decision to use Connect was made. It has to go before any new features are added.\nTotally agree with you we should off-load more onto Connect where possible. Also the redis_proxy idea needs revisiting as this was brought in to support distributed hosting. Since then my ideas on this have further developed and I really want to make all the ZeroMQ stuff a separate optional npm module (after thoroughly investigating Hook.io first).\nCan't go into all the other points just at the moment but I broadly agree and will come back to this post when looking at re-implementing sessions.\nI'm going to be writing a new Google Group post about the plans and philosophy behind 0.3 in the next few days.\nCheers,\nOwen\n. Connect.session will be used in SocketStream 0.3. Closing this now\n. Thanks!\n. Thanks a lot!\nGoing to take a good look at this shortly. Working on an actual SocketStream app at the moment which is a nice change from framework stuff and travelling.\nRe lib/frontend/client/cached/lib.min.js: Agreed, we should do this in 0.3.\nIdeally SocketStream should custom-build the client-side code with only the features you need. Third-party modules should also be able to expose client code which will be included each time this is generated.\nCheers,\nOwen\n. Hey again\nHad a good think about this. I love the idea, but we have a problem:\nAt the moment everything in /lib/frontend has no knowledge of Redis and shouldn't do because all session data flows over the internal RPC layer. For good or for bad, this is how it works at the moment; so we're unable to require anything Redis-based here.\nSo how about another idea... We make this (plus some minor modifications I've made) the start of 0.3 which I can deploy to a new branch on github next week.\nWe'll make it clear this branch is not ready for use yet, it's a work in progress, thus giving me (and others via pull requests) the ability to go in and completely rip out code and start again in areas (most notably sessions!).\n0.3 will not have this internal RPC layer, at least not in the core. All the ZeroMQ-related code needs to come out and live in an optional npm module - eventually.\nBut the number one priority is a stripped-down ultra-clean core which runs great in single process mode, with the emphasis being on making it easy for others to extend and contribute to via new modules.\nHow does that sound?\n. Hi there\nGoing to close this now. 0.3 is not going to be based on any 0.2 code at all - I've decided against that.\nI'd love to get your thoughts on the code, particularly around sessions, once I put it on github.\nOwen\n. Yup this should work. The only code it takes in the framework is:\nhttps://github.com/socketstream/socketstream/blob/master/lib/backend/session.coffee#L111\nBasically at the moment it's just loading a module. The plan in future was to check the module had a valid interface and was compatible with the current version of SocketStream before allowing it to be used.\nOf course the main limitation with this auth method is you can only perform auth against an internal database - not one where the auth service refuses to allow proxying of credentials (such as facebook connect).\n. I should add we're using this method in a few of ours apps, but it feels a bit clunky. Esp having to call the @session.setUserId() method in your own app code.\nIf you can think of a more elegant implementation please let me know.\n. @paulbjensen Cool. Just remember you'll need to call @session.setUserId() if you ever want to use SS.publish.user() or SS.users.online\n. Interesting idea. Thanks!\nI'm keen to make sure 0.3 is much more flexible when it comes to templating.\n. Multiple template languages are coming in 0.3 so closing this issue now. The first 0.3 alpha will be out by the end of the month, so stay tuned for updates :)\n. Hi Paul\nThis is fixed in 0.2.4. Please reopen if you still have problems.\nOwen\n. Hi Andrew\nWell spotted. This is fixed in 0.2.5 out soon.\nOwen\n. Hi Andrew\nWell spotted. Will be fixed in 0.2.5 out soon.\nOwen\n. Hi there\nDo you still have this problem? Everything is working fine on my machine and I've not had this problem reported before, so I'm not sure what to suggest without more debugging info, sorry.\nOwen\n. Hi there!\nThanks for this! Looks good. Let me have a look into it tomorrow and find the best way to proceed.\nWould love to get this into 0.2.5 if possible.\nOwen\n. Hi there\nThink i misread this and thought it was a bigger change than it is :) Sure I'll merge this in. Please submit another for the other time Jade is called if you wish.\nOwen\n. Thanks!\n. Haha kinda cool\n. Thanks!\n. Hmm interesting. I put this in initially as I had a problem that took me ages to debug. It turned out to be caused by one of the CSS files in my lib dir which wasn't correctly terminated so I put this in to be sure in future.\nI've never come across the problem of an extra semicolon stopping something else from working before. Can you provide any more details (e.g. browser, or a snippet of the css output).\nIf this is indeed a problem, the only proper solution would be to check for a terminating semicolon and add one if not present.\n. Ah my mistake, of course you're right.\nI still feel there once was a problem concatenating multiple CSS files together, but it must have been something unrelated to this. Do let me know if you come across anything.\nI will accept the pull request. Thanks.\n. Hi there\nYup, totally agree. It is likely to happen but right now I'm putting all my time into the first preview of SocketStream 0.3.\nBut I am looking for people who may be interested in making 0.2 support Node 0.6, see here: https://groups.google.com/d/msg/socketstream/AFwFAPMKzjU/k2fsLjwGL94J\nIf you or anyone else reading this is interested in working on this please let me know.\nOwen\n. Now supported in 0.2.6 using connect 1.X\n. Sorry - my bad. I forgot to run all the integration tests. These would have caught the pull request which broke it.\nFixed in 0.2.7.\n. Brian I believe this is the famous Socket.IO + Safari with proxy settings bug. I'm going to close this now as the Socket.IO team is well aware of this. The good news is 0.3 is now websocket transport agnostic so we have the ability to use other transports in the future.\n. Hi there\nAs far as I know no.de still does not support websockets, so I think that's your problem. SocketStream should work fine on NodeJitsu and many other hosting providers. We use EC2 servers ourselves.\nOwen\n. Thanks Ian, you're quite correct.\nI'm working full time on SocketStream 0.3 at the moment which is essentially a brand new piece of software. I will need to re-write the feature list entirely as so much has changed, so I'll bear this in mind.\nStill on track to release the first 0.3 alpha by the end of December, so please look out for it and feel free to share your thoughts.\n. Hi Ian.\nClosing this now as I'm about to release 0.3 (tomorrow hopefully). So far very little has been done around authentication but it provides a much better framework to build solutions on in the future.\n. Hi there.\nCan you let me know, does this error occur with a newly created project or an existing project? Also which OS?\nThanks,\nOwen\n. Hey there.\nYes, I am aware of this with 0.2. I'm pretty sure none of the 0.3 code will be affected by this, but if you or anyone else spots an example of this please let me know and I will fix it.\n. Closing this now 0.3 is out. If you spot this problem with 0.3 let me know, but I think it will be fine.\n. It is up again now, but it keeps going down intermittently. It is running the new 0.3 code and it appears something happens to make it suddenly jump to 100% CPU usage and stay there (hence 'forever' won't help).\nI'm trying to output as much debugging info as I can but as yet I can't see what's causing it. One of the many things that still need to be sorted before the code if ready for to be used by others.\n. Sorry I didn't mean to close this one - I hit the wrong button.\nI have installed monit on the server as per your suggestion and have tested it will restart correctly if the process is killed, but have yet to see it restart due to high cpu usage. I'll be out later today but will keep an eye on it.\nThe site should stay up from now on.\n. That's because it's not ready yet. See https://groups.google.com/d/msg/socketstream/AFwFAPMKzjU/wERmwMoxCIwJ\n. Because I don't like anyone seeing ideas which are only half baked or certain to change, as has been the case with the most of 0.3 code up until the last few days. I feel very strongly about this.\nUnfinished work and ideas not only look sloppy but also generate many unnecessary github issues and emails which need to be answered when often the only answer is \"because I haven't had time to do it yet\".\nThe 0.3 code will go online once I'm happy with the core ideas and I feel most people's first experience with it will be a positive one. There will still be lots of work to do to move from dirty untested code to solid production-ready code and your help would be very much appreciated.\n. So I thought this too but I heard Isaac say this is not a problem for Windows in a recent Node Up podcast. Maybe he's referring to require() calls, not to paths which are used by other modules -e.g fs?\nIn either case whilst the first alpha release of 0.3 is unlikely to run fine on Windows, I will make sure 0.3.0 does before it's released.\n. Closing this now as I believe 0.3 is now cross platform thanks to the pull requests I've merged in. I will do a full test on Windows before 0.3.0 is released.\n. Closing this as the latest 0.3 code should run fine on Windows. Please reopen if not.\n. Hi there\nJust pass the full module path, e.g. '../../lib/server/myauth'. Please let me know if you get it working.\n. Thanks Troy. Good point about relative directories.\n. Hi Dave\nThanks for this. Just want to be sure, are you saying all the assets serve correctly in Windows - even when you enable ss.client.packAssets() just by making this change? If so that would be a massive result!\nSadly my only Windows machine is the VM on the Mac in the office. I was planning to test 0.3 out on there next week.\nOwen\n. Great stuff. Merging this in. I have updated the README and INSTALL files too.\n. Hi there.\nThis functionality is still present in 0.3, nothing has been removed here. Can you describe which .coffee files you're referring to?\n. Hmm how strange. Does this mean the /server/rpc/actions/demo.coffee file installed by default when you create a new project is not working (i.e. the basic chat demo doesn't work)?\nNote the files in /server will not auto reload if you make changes (you'll have to restart the server). You can use 'nodemon' as described in the Questions section in the README if you'd like to have this functionality.\n. Ah right. Glad it's working for you now\n. Thanks for letting me know. Fixed\n. Yes the basic idea is that you must tell socketstream what the home directory is. Normally this is done automatically when you 'cd' into it in the terminal and run 'socketstream start', but when doing startup scripts on the server you need to set the home directory manually.\nThe discussion in #113 may help you.\n. Closing this now\n. Yes very much so. That's one of the key goals of 0.3.\nSo if you have an existing Express JS project you will be able to leverage SocketStream in it, so you could have a normal website at / and use SocketStream to serve /realtime or anything else you like.\nTake a look at the example of using Express JS on the tour at www.socketstream.org/tour\n. Yup that's the solution. By passing 'ss' as the third function we no longer need the global variable.\nThere are hardly any docs at present but it will be fully documented soon within the coming weeks.\n. So calling actions() each time is a benefit as it allows you to do things before the method is called. E.g.:\n``` javascript\nexports.actions = function(req, res, ss) {\nconsole.log(req) // debug or rewrite requests\n// return available functions\n  return {\nmyMethod: function(params){\n     res('my response')\n   }\n  }\n}\n```\nNow if I've missed something critical here which means the performance will degrade over time, please let me know. It could be argued that with the 0.3 middleware feature the need to debug within the actions() function is redundant. Not making this a function (and returning to the 0.2 style) would mean passing the cb param AND the ss param (as it's no longer a global) to every function which seems messy.\nRegarding publishing events outside of the ss.rpc() handler, you can do that now by referencing ss.api\nE.g. in your main app.js file you can call ss.api.publish.all() however this needs to be called after you call ss.start() for this is the command which establishes the connection to the event transport (likely to be Redis).\nss.api is the object which is sent to the third param of the actions() function. It is intended to be the 'internal API' of commands which can be called once everything has loaded and connected.\nThe issue of whether or not to prototype an instance of 'ss', e.g in your ss.getInstance example above is one I've been pondering. If we really need to do it we will.\n. Agreed.\nNot a simple change because of the way we use an EventEmitter to route incoming requests (which itself is up for debate) but I agree we need to do something here. Added it to TODO.md (my local copy).\n. Fixing this in alpha4\n. Just not possible yet. But I want it to be. 'Investigate if it's possible to make SocketStream sessions accessible to regular HTTP requests?' is listed in the TODO.md file.\nThis is why I hate putting stuff on github before it's finished :(\nI'm working on documentation at the moment. If you'd like to have a look at how we can do this (without relying on Socket.IO sessions as the transport is now modular) that would be great.\n. Thank you. Appreciated\n. Closing now as this is all in alpha3\n. Hi Jamie\nWow this is very surprising! I can't think of any reason off the top of my head why this would be the case and I've had no other reports of this.\nPublishing to channels is already implemented in 0.3. If you get chance and are able to please use that instead. I'm almost certain it will not suffer from the same problem, but let me know if it does and I will reopen this issue and fix it immediately.\nAs I'm sure you can imagine, with so much to do to get 0.3 finished, I'm trying to avoid touching 0.2 unless absolutely necessary.\nOwen\n. This looks really good. Thank you.\nGoing to get a whole bunch of stuff I've been working on released today (which shouldn't impact your pull request) then delve into this.\n. Hi there\nI've had a chance to look at this today.\nI really like the approach of using Redis as the medium to share sessions between SocketStream and Connect/Express/etc. Good idea.\nI don't mind having to include the extra dep ('connect-redis') but I do mind the fact this patch forces every user into running Redis, even if they have no desire to share sessions. I definitely want to avoid this as I want SocketStream to remain session-store agnostic (with no need to use any if you're just downloading an experimenting with it for the first time).\nAlso we don't want to hit Redis upon every RPC call as it would dramatically impact performance. Hence we need to keep the cache idea by default (and implement pruning) but provide a way to disable it (forcing a Redis lookup on each request) if you are sharing sessions with HTTP calls.\nThanks for fixing the bug with the router. Well spotted.\nI've got your code in a branch and will work on it to see if we can achieve the best of both worlds here.\nOwen\n. Been working on this today and showing some good results so far. Will work on it more tomorrow and update you soon.\n. Closing this now as this code, and much more, is in alpha3. Thanks again\n. Agreed. We need a lot more debugging and error handling here in general.\nChanging this file at the moment as I'm redesigning the middleware API. Will see if I can improve this while I'm at it.\n. So i've made an additional file in a new project called /server/rpc/app.js and put foo)bar in it.\nWhen I start the app it errors as we would like:\nob:test owen$ node app\nStarting SocketStream 0.3.0alpha4 in development mode...\n/Users/owen/Work/test/server/rpc/app.js:1\nfoo)bar\n   ^\nnode.js:201\n        throw e; // process.nextTick error, or 'error' event on first tick\n              ^\nSyntaxError: Unexpected token )\n    at Module._compile (module.js:427:25)\n    at Object..js (module.js:450:10)\n    at Module.load (module.js:351:31)\nDoes this not happen for you?\n. Are you catching uncaught exceptions somewhere in your app?\n. Tested this again on a brand new project on my home mac (separate from earlier), same result.\nThe only thing I can think of is that one of your included modules is calling\nprocess.on('uncaughtException',cb)\nRecommend running grep -R uncaughtException node_modules\nPlease try with a new app. You should have no problem installing hogan. I've tried that on two separate systems now and no one else has complained of any problems installing it.\n. Thanks for spotting. Fixed now\n. Thanks again. Implemented this in the next release, hopefully out tomorrow.\n. Thank you. Was looking for a solution to this. I've updated the code and will push it along with other changes by the end of the week.\n. Hmm not sure that's the pull request you wanted to submit. Looks like that would just delete the contents of README.md\n. Yup, agree this needs doing. Will keep this open until debugging around RPC calls is improved.\n. What sort of syntax errors are you talking about in 1.? When I create RPC action files with syntax errors they typically throw and error and prevent the server from starting - which is good. I think we really need to identify the cases here and work towards writing test cases to see how each possible error is handled.\nI totally agree we need to improve debugging and error reporting in general. Alpha4 will see internal changes to the way responders process requests (it won't break any apps). Once that's done let's think about the best way to proceed.\n. Hi there. Some of the new error handling in alpha4 should help you here. I'll keep this issue open as I can't say for certain that all possible errors will be caught yet, but please let me know how you get on and how to reproduce any issues you find.\n. Thanks. I've put this in the next release.\n. Ah ok. Interesting. I've tested it with Firefox 10 (latest stable release) and it works fine.\nGuessing it could be a Socket.IO issue but I can't find any previous reports of this.\nIs it working fine for you in another browser/version?\n. Yup this is the session id cookie bug which is now fixed in the latest master. Sorry for the very stupid mistake on my part here.\n. Hi there\nSocketStream can do this already. Instead of \ntemplates: ['chat']\nit is\ntmpl: ['chat']\n(where 'chat' is a folder containing templates).\nI will update the template docs to show this.\n. Hi there\nThanks for the kind offer.\nPlease take look at the things that must be done before 0.3.0 is released and see if any of them interest you:\nhttps://github.com/socketstream/socketstream/blob/master/TODO.md\nAlternatively, help around documentation is very much appreciated. For example, mindeavor recently contributed the Client Side Templates doc.\nBest thing to do if you wish to contribute is hang out in our IRC channel #socketstream on Freenode\nI'm not always in there but I see a log of all chat and normally respond later in the day.\nCheers,\nOwen \n. Hi Gilbert\nThanks, this looks great. Just want to chat with you over IRC before I merge it in. Hopefully catch you later today.\nOwen\n. Fix has been merged into the latest master. Please reopen if you still have a problem here.\n. Hi there\nThanks for letting me know. This was caused by a stupid mistake on my part which only showed up if you had more than one cookie present. Should be fixed now.\nOwen\n. We could have an ignore list for file extensions, in the same way we ignore hidden files?\n. Wouldn't this be a pain for you if mercurial wants to make .orig files all over the place?\n. Hmm in second thoughts, if you don't delete them, they will get packed; so I think you're right. Will change the error message to show the file name.\n. Lesson for me: Check stuff before merging it in!\nThis pull request broke the main chat demo because it didn't recognise .jade templates.\nI have fixed it now. Also removed the echo formatter, as this is basically just the .html one, so we're falling back on that now if it doesn't exist.\nBtw I ran the tests and nothing broke. Thanks again for adding them :)\n. Thanks for spotting this. I've fixed it another way, but it's been a lesson to always check stuff before merging it in!\n. Not yet on the client, sorry. I am hoping someone will contribute a solution here:\nhttps://github.com/socketstream/socketstream/blob/master/src/browser_client/init.coffee#L20-33\nIf not I will get round to it.\n. Hey. Have you restarted the server and ensure you only have one tab open at once?\nHas this just started recently?\n. Hey there. Going to close this now as we've discussed this on IRC. Let me know if you're still having problems.\n. Message efficiency is very important to me, which is how the idea of different responder came about in the first place. Once we support different types of responders you won't always have to use the JSON-encoded RPC responder for simple tasks like passing the X,Y position of a car on the screen.\nHowever being transport-neutral is also important to me, so whilst Socket.IO is using 5:::{\"name\":\"message\",\"args\":[ at the start of each message, another transport layer like Pusher Pipe or Socks JS (which I'm hoping we can integrate with) may choose to do it differently.\nAll that been said, it looks like there is something sub-optimal with the way we're transmitting Event messages so I will take a look. Thanks for letting me know.\n. I've had a look into this today.\nIt appears to be a Socket.IO quirk.\nIf you put console.log(msg) before this line: https://github.com/socketstream/socketstream/blob/master/src/websocket/transports/socketio/index.coffee#L43\nyou will see that msg is a string without any slashes. Socket.IO seems to add these when calling io.sockets.emit('message', msg) but not when calling socket.send(data).\nIf you have any insights here please let me know, otherwise I will close the ticket as it's not a major issue and likely to be fixed in a future version.\n. Yeah, unfortunately we have to pass a message here (not an object) as it looks like:\nevent\u00a7{\"t\":\"all\",\"e\":\"newMessage\"....\nMaybe there is a way to send a 'real' message (as a string) to all sockets, rather than an object? If you find a way please let me know, else I'll take a look sometime.\n. Ok guys, not had this problem myself but I will look into it today. \nI know there is a big issue with onready events at the moment in general. I am sick of having to put $(document).ready(handler) at the top of all my client-side JS files which use templates. It's one of the things I want to sort in the next alpha.\n. Guys can you get the latest code from master, delete your node_modules dir then reinstall (sudo npm link).\nThis problem is proving hard to debug so I want to make sure everyone is on the latest version of socket io\n. Guys I'm going to need some help debugging this one. I use chrome too and although I've observed the session problem #174 (now fixed), I've never had the problem of the 'ready' event not firing.\nPlease ensure you're on the latest master before reporting any problems.\n. So just to be clear here, you're getting this error from a .png file in client/static ?\n. Hmm ok, so jQuery UI must be adding a dialog box or something and requiring the css elements which in turn are looking for image files.\nThis is always a pain in the neck as all the image files should ideally be moved into /client/static/images or something like that and the links to them updated.\nHowever if you were to say this is a pain for developers I would agree with you, especially as jQuery UI usage is so common. What would your ideal behaviour be from SocketStream?\n. It's not an unknown reason :) The GET requests begins with http://fuuuu:3000/_serveDev so it never gets to the static middleware.\nThe solution, sadly, is to go through your jQuery UI CSS code and replace the relative paths to the images with absolute paths. E.g.:\n.ui-widget-content { border: 1px solid #aaaaaa; background: #ffffff url(images/ui-bg_flat_75_ffffff_40x100.png) 50% 50% repeat-x; color: #222222; }\nneeds to become\n.ui-widget-content { border: 1px solid #aaaaaa; background: #ffffff url(/images/ui-bg_flat_75_ffffff_40x100.png) 50% 50% repeat-x; color: #222222; }\nI know this is a pain, but as you can imagine it's not an easy fix. The only two solutions I can see is to rename the links (as above) or to rewrite the incoming URL.\n. You submit this issue at a good time. Now alpha4 is out and I'm pretty happy with the server-side API, I really want to turn my attention back to the client as I'm still unhappy with a few things here and believe they can be better.\nThe idea behind two vars is to have SocketStream for everything to do with the internal workings of the system (including system events), and keep the ss var just for the responders - which may be user-defined in the future, hence we keep the namespace clean for people to implement ss.model and such.\nI agree this needs more thought. I hope to get chance to think about this and other client-side issues this week. It would be useful to list them and share them on the news group so people can suggest ideas. I'll keep you posted.\n. SocketStream.ss.model is too wordy, but I like your idea of allowing the app to define the global var.\nAlso I've long thought we need a single point of entry client-side, almost like an app.js for the client.\nCool about backbone. Can't wait to start working on backbone model sync over websockets!\n. I imagine it's the Redis connection or any other open connections to blame here, no?\nWith any connections open my app terminates instantly with ^C.\n. Don't think it would be the router. Could be the fs.watch() API if you have many files in /client, esp as you only seem to have noticed this after the live reload feature went in and that is the main difference between dev and prod environments.\nNot had anyone else report this problem, and not seen it myself of large apps (with plenty of files in /client).\nCan you comment out this line and try again: https://github.com/socketstream/socketstream/blob/master/src/client_asset_manager/index.coffee#L85\n. This errors correctly now. Also sends the complete stack trace to the browser.\nWe could show stack traces in the console view too, but most of the time this would be messy and unnecessary as we are throwing the error ourselves (e.g. export.actions is not a function) and the error message alone is all you need to fix the problem.\n. Please try these examples again.\nMost of the errors here are now caught, however they will not stop the server - deliberately so. Once it's up and running we don't want any request to kill it; however, what we do definitely need is a pre-flight check (which I believe we had in 0.2).\nThis will check for common errors (such as missing exports.actions) when the responder is initialised for the first time. Of course we also need tests cases writing for all these checks too.\nAlso note I'm deliberately not checking that the export.actions function returns any actions - that's because it doesn't have to if you're using middleware which handles (or redirects) all requests to another server, etc.\nAlso we cannot concern ourselves with what functions return - it doesn't matter. All that matters is if they call res(). Technically they don't have to do that either, but it's a good idea to stop the callback stack growing too large.\n. Thanks. As you know pretty much everything is undocumented right now.\nAs I'm going away for 4 days shortly I will spend some time documenting things we have which are unlikely to change, rather than start anything new. Channels feels like a good place to start as this API is not going to change.\n. Done  https://github.com/socketstream/socketstream/blob/master/doc/guide/en/pub_sub_events.md\n. Can you elaborate, or better still, submit a pull request :)\n. I think connect.compress() will do the same thing here, no?\n. True. The /client dir is excluded as no changes here should cause the server to restart.\nInstead, any changes to this file should cause the browser to refresh.\nPlease reopen if this doesn't happen for you or you mean something else.\n. Ok thanks for updating.\nI will be away until Monday, but I'll reopen this and take a look next week.\n. Hey there\nJust trying to understand what's causing this error. Do you have files without extensions?\nI agree we need to handle this possibility better, but I would definitely encourage the use of file extensions here.\n. Ah I guess you must be calling\nss.client.formatters.add(require('ss-hogan'));\nsomewhere? As ss-hogan is for templates only, it should be called with \nss.client.templateEngine.use(require('ss-hogan'));\nIf not, I'm struggling to see how you're getting this error\n. Closing this as I don't believe this problem will arise if you use 'ss-hogan' with\nss.client.templateEngine.use(require('ss-hogan'));\nRather than\nss.client.formatters.add(require('ss-hogan'));\n. Thanks. I am aware of this. Will be fixed before 0.3.0 is released.\n. Agreed. Should help in debugging #153 too\n. Yup still needs to be done, but the API is not yet stable. Should be after the next (and hopefully final) alpha.\n. No plans to develop anything like this at present, so it would be great if you do. Thanks\n. Done now in ss-jade 0.1.1. Please let me know if this doesn't fix your problem\n. Hi there\n'localhost:5000' is for the console server only. To connect to the console install the client with sudo npm install -g ss-console then type ss-console.\nThe other bug is more interesting. I have observed this from time to time but it occurs very rarely and always go away after a server restart. It is possibly related to the recent Socket.IO upgrade - I will keep an eye on this.\nPlease reopen the ticket if this problem persists even if you restart the server and refresh the client.\n. Ah thanks for the feedback.\nI'm planning to add some contributed code which will only reload the CSS if the CSS changes without reloading everything. It won't completely fix your problem but may help eliminate some cases.\nIf you can think of any other improvements we can make please let me know.\n. Thanks. Will try this out and put it in the next release (beta1 I hope) if there are no problem.\nAlso I'm curious to see where it puts the cache files and if they cause a problem with anything out.\n. Hmm this could be a problem if you have lots of files, esp as a user will have no way of opting out of this if we put it into the core.\nI have long thought we need to cache all assets in RAM when in production, but the developer needs to be able to set limits otherwise RAM usage would get out of control (imagine an e-book site serving hundreds of thousands of PDF books).\n. It's not quite as simple as just updating package.json. I need to see if there is a new client out too - there is:\nhttps://github.com/LearnBoost/socket.io-client/blob/master/dist/socket.io.min.js\nAnd then test that out. In this case I'll need to remove some code I had to put into the previous release (https://github.com/socketstream/socketstream/blob/master/src/websocket/transports/socketio/index.coffee#L19) as Socket.IO was buggy (which has happend a few times now).\n. Hi,\nI haven't had a chance yet, please jump in. Thanks.\nRegards,\nPaul Jensen\nOn Wednesday, November 27, 2013, Morgan Craft wrote:\n\nRan into an issue adding twitter bootstrap and the css files attempt to\nload fonts/ as static content and socketstream has a meltdown. I believe\nthis is of a similar issue? I'm willing to dive in and see if I can't sort\nthis out. @paulbjensen https://github.com/paulbjensen do you have\nexisting work on this that I should look at? Or just jump in?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/286#issuecomment-29388465\n.\n. Hey. That's an old bug fixed long ago. Upgrade to the latest version and you should be fine. \n. Hi luksch,\n\nLet me take a look at this tonight. I've had to do some critical work in\nthe past week which sucked the life out of me, but I should be around to\nsort it out tonight.\nRegards,\nPaul Jensen\nOn Wednesday, January 29, 2014, luksch notifications@github.com wrote:\n\nHello!\nin the docs (\nhttps://github.com/socketstream/socketstream/blob/master/doc/guide/en/pub_sub_events.md#event-transports)\nI read\n\"The SocketStream Pub/Sub system has been designed from the ground up with horizontal scalability and high-throughput in mind. The all and channel commands will be automatically load-balanced across all SocketStream servers when an external event transport is used.\nThis sounds great, but I am experiencing very unexpected results when I\nlet two node instances run on the same server sharing the redis transport.\nI in fact end up with a scenario where each nodejs server sends all channel\nmessages to all connected clients. I thought the idea was that each nodejs\nserver only sends messages to the sessions it is responsible for. Please\npoint me to where I am doing things wrongly...\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/429\n.\n. \n",
    "paulbjensen": "Hi Piotr,\nWe're having difficulty in replicating this error. Could you do me a favour and try this on your computer?\ncoffee\nrequire 'argsparser@0.0.4'\nand let me know if you're able to load the library fine there?\n. Does this work?\nrequire 'argsparser'\nI assume you installed node via the tarball from the homepage. I can recommend the git repo (0.5.0-pre).\n. Hi Kryton,\nIt looks like we need to add support for ignoring backup files. I will have a look at this tomorrow morning, and hope to have a fix for you by tomorrow evening.\n. Thanks elisee.\n. Hi johnny,\nwhat version of iOS did you test this against? (both for the phone and simulator). iOS versions from 4 up are the one that support WebSockets, anthing below that (3.2) didn't.\nIf you're still having issues, let me know, it could be a bad regex used in lib/http_middleware/browser_check.coffee, line 49 which is not catching iOS users.\nLet me know how you get on \n. Hi Johnny,\nAre you still having issues with this?\nIf you are, could you visit either ssdashboard.com or socketracer.com, and let me know if you see the browser incompatible message. Thanks.\n. Thanks Elisee\n. This issue is fixed by this commit: https://github.com/socketstream/socketstream/commit/f520c9f2dc4b099682d528276b2b1a5611d996db\n. Maybe we could have a dual-compatibility approach, so that you could use /config/app.coffee in place of app.json. We could keep app.json as the default used in new generated apps.\nI will work on this feature.\n. Hi,\nI've committed this feature to a new branch (dynamic_config_files). I've also written tests against it, which you can run with 'cake spec'. There is one more test case to handle (error handling from a .js or .coffee config file), but once that is done, I think that this feature will just require a little refactoring, then it is ready for merging into master.\n. In theory, you could easily swap out the client-side templating library with the one of your choice. The question is... should we provide command-line options to do this, in the same way that running 'rails new' and then appending the option flag to use the haml templating engine uses HAML over ERB?\nI think that it's a nice feature, all we would need is a list of popular templating libraries, and then I think we could do this.\n. I say we do it.\n. Done. Thanks.\n. @jonmumm FYI, I've been implementing a feature to provide this, which you can see here: \nhttps://github.com/socketstream/socketstream/pull/36#issuecomment-1548650\n. Hi harlanji,\ndo you have a fork of the code for this? It would be nice to add it as an option for now.\n. Hi Brian,\nI'm going to have a look at replicating the issue. When you say you used a recipe provided by the community, did you mean the instructions listed in the install.md file, or the Linode StackScript?\n. @madgnu - Thanks for the tip.\n@brianconnoly - I'm going to amend the instructions to use Node.js v0.4.9. In the meantime, if you have a look at the Linode StackScript I use, you can find instructions on installing Node.js v0.4.9:\nhttp://www.linode.com/stackscripts/view/?StackScriptID=2863\nLet me know once you've setup fine on your box.\n. It turns out that this issue is an error with the Safari browser, as explained in the comments on the Socket.io 193 ticket. This is a bug that effects all WebSocket connections. Closing as this is something that can only be fixed by Safari.\n. I've got a different form of user authentication working at the moment, one that isn't using the approach advocated in that document. It is available to see here at: https://github.com/paulbjensen/shogunapp\n. Hi Brian,\nI'd like to find out more:\n- Do you know how long you left the app running in the background for?\n- What is your iOS device?\n- What is your firmware version?\n- Have you been able to replicate the crash?\n. Hi Brian,\nSorry, got caught watching \"Dig\" http://www.imdb.com/title/tt0388888/ - really good documentary.\nSo I'm assuming that you don't see an error get raised in the SS app's log, as this is the browser dying and not the application.\nIf you go to Settings > Safari > Advanced and enable the Debug Console, do you see any error messages raised in the browser?\n. Hi Brian,\nprod ;)\n. Interesting, thanks Brian. I'll go and have a look at the issues on Socket.IO to see if there is anything similar happening with them.\n. Hi, do you have a Segfault message you could post? Also what version of Redis you are running on your machine? Thanks.\n. Awesome, looks like Owen did the sensible thing and switched off from the all-hands meeting.\n. Hi aliasone,\nIt's possible. First, because 0.3 requires Node 0.6+, you'll want to use Node version manager, it's similar to Ruby's RVM solution and works very well:\nhttps://github.com/creationix/nvm\nSecondly, you'll want to include socketstream as a dependency of your project in the 0.2.7 app, run npm install, and change the command that you run to YOUR_APP/node_modules/socketstream/bin/socketstream start\nHope that helps. \n. Hi,\nApologies for late reply (housemate interviewing, feel like a cooking judge). You've followed the instructions correctly, so you're not at fault. I'll be on the irc chat room tomorrow from 11:30am GMT to help you out. In the meantime what is the output of the following commands on your machine:\nwhich socketstream\nsocketstream v\nand what is the output from the \"sudo npm link\" command inside the socketstream directory?\n. you could write an alias in your bash config/profile file:\nalias ss3=\"/usr/local/bin/socketstream\"\nThat way you keep the socketstream command for 0.2 projects , and have the ss3 command for the creation of projects for socketstream 0.3.\n. So I figured out the tasty. \n```\nconsole.log app.listen 3000\n=> undefined\n```\nI changed the code so that \nss.start app\napp.listen 3000\n. I'm going to have a look at getting this in before 0.3.11 is released.\n. Hi,\nThere is a feature branch, but it's still a work in progress. I will have a look into it this weekend. Apologies for the delay, if only I could work on SocketStream full time.\n. @kulicuu Thanks, I'll assign to you.\n. Wanted to know whether anything more is happening on this front? it's worth noting recent efforts with https://github.com/observing/thor and https://github.com/observing/balancerbattle.\n. I had a brief look into this. I think that we'll need to upgrade SocketStream's version of engine.io as a first step, and then create a suitable generator file for the expected websocket messages.\n. I will need to look at using GZIP compression for a 0.3 app. It's important.\n. I'm going to close this, and if it crops up again, I'll pick it up.\n. I'll be happy to take a look at it this weekend and see if we can make it happen.\n. I have some good news. I managed to get SocketStream working with Passport, using the Twitter authentication strategy. Here is the repo: https://github.com/paulbjensen/ss-passport-example\nThere are some thorny issues that need attention:\n1 - You cannot use ss.http.route to handle the routes for passport. This is because 1 - ss.http.route does not handle passing (req,res,next), and 2 - there is no ability to pass the HTTP verb (GET, POST, DELETE) to the route. In order to get passport working, I had to use the connect-route npm (version 0.1.3) to chain the routes onto the SocketStream application's connect middleware.\nIt would be ideal if we could find a way to make ss.http.route handle chaining, as well as specifying the http verb.\n2 - To use passport successfully, you have to attach the connect middlewares in a specific order. This has been a stumbling block for a lot of passport users. The middlewares in the SS app are appended in this order:\n``` javascript\n    ss.http.middleware.prepend(ss.http.connect.bodyParser());\n    ss.http.middleware.prepend(ss.http.connect.query());\n    ss.http.middleware.prepend(redirect());  // we append this because connect removed the redirect middleware from the core\nss.http.middleware.append(passport.initialize());\nss.http.middleware.append(passport.session());\nss.http.middleware.append(connectRoute(api));\n\n```\nI'm going to take a quick break before thinking about how we can refactor the code into an npm that will simplify integrating passport with SocketStream.\n@moiseevigor Thanks for your offer of help. If you're interested, I'd welcome any improvements you can make to the ss-passport-example (such as saving the twitter profile to the db, or displaying it directly in the page), or trying another authentication strategy (Facebook, github, etc).\n. I've had a brief look at how to assist passport integration with SocketStream. Passport provides a lot of flexibility in how you setup the app to authenticate with a 3rd-party. This comes at the cost of having to do some gruntwork in setting up routes, connect middleware (in the right order), and storing the user's information in the database.\nThe issue I see here is finding a way to reduce the gruntwork, without compromising the flexibility that Passport offers. I will need to explore this by implementing different authentication strategies, and finding common tasks that can be automated by default, with the option of configuring the module to not do that should you wish.\nI read @leostera's comment about him trying to get the authentication to happen almost within the single page app. I think it's possible. At the moment the example repo I made today will redirect to Twitter's login, then do a bit of OAuth redirection, and then eventually end up back at the application. The issue with this is that say you're in the middle of doing something with your single page app, redirecting to any page will mean losing that current page's state.\nMy idea would be to make the auth work like this:\n1 - You click the 'login' link. It opens in a new window.\n2 - You authenticate with Twitter in the new window.\n3 - The SS app authenticates the OAuth token, and the app now has the user's data. That window closes automatically.\n4 - The SS app pings a 'signedIn' event with the user's data. The user is now logged in, and we can trigger view partial changes like replacing the login link in the nav bar with the user's account.\nThis way, the app's page never has to be reloaded, and we can login to/logout from a 3rd-party service as close to in-the-app as possible.\n. This feels like something to be dealt with in a major update to SocketStream. Thus moving to 0.4 milestone.\n. I'm marking this as closed, as comments have answered the question.\n. Hi,\nI've got Dashku running on HTTPS with no issues. I'll take a look at this by tomorrow (apologies, I'm stretched for time today).\n. Hi,\nThere hasn't been any progress. It's something that is worth addressing in 0.4.\nHaving taken a quick look at BinaryJS, it looks like we'd need to address the following issues:\n1 - BinaryJS uses a custom version of MessagePack for transmitting data. SocketStream uses JSON. We'd need to find a way to configure the message format.\n2 - BinaryJS uses a custom version of the 'ws' node module. SocketStream currently uses engine.io as the default websocket library, with support for sock-js as well. We'd need to ascertain how to support binaryjs' server-side requirements in line with SocketStream.\n3 - BinarySJ would need to ship a client library to handle the streaming of files to the server.\nWe'd need to experiment with this first before we can establish if it's possible to do it. If anyone has attempted this, your experience would be worth mentioning here.\n. Hi,\nI'm going to take a look at this during the week.\n. Hi, I bumped chokidar to 0.6.3, though I see 0.7 is out. I'd like to try and have a go at replicating this. I have a Macbook Air with OS X Mavericks and a Desktop with Ubuntu 13.10 available for testing this issue out.\n. Hi @drosen0, are you still experiencing this issue. If not, can I close the issue?\n. I just ran into this issue. +1 for making RPC response in tests match the RPC response in browser. \n. I will fix this before 0.3.11 is released.\n. I can also recommend loading Bootstrap via a CDN as a way to work around this issue:\n@import url('http://netdna.bootstrapcdn.com/bootstrap/3.0.1/css/bootstrap.min.css')\n@import url('http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css')\nWe'll need to take a look at this file: https://github.com/socketstream/socketstream/blob/master/lib/http/index.js#L96\nI'll be at home in an hour to have a look at this.\n. Thanks @RomanMinkin.\nWe'll need to find a way to allow SocketStream http routing to be configurable so that HTTP requests for files can return a 404 instead of the html for the client, at the moment 200's are returned, and the parser for that file breaks because it's getting back HTML content where it expects something else.\nOn a side note, something to consider for 0.4 will be how to support using client-side modules/components in such a way that we could install them via either npm or bower or component.io, and then load them in our app without need to move files to different locations. It's a tough cookie, but I think that cracking this would be great.\n. This is now fixed by PR #419. It will be part of release 0.3.11\n. I think that this is definitely worth doing, and will therefore suggest it goes into 0.4\n. @kulicuu cool, please do. Thanks.\n. Hi,\nThanks for describing the issue in more detail. In the case of Dashku, I had a similar case of needing to fetch the current user via an RPC call, but what I chose to do is do almost all of the view rendering via Hogan.js, and have the app.jade be a simple html container with little pre-defined markup.\nIn terms of rendering multiple client-side templates, I built a simple library to handle doing this, called StateManager. It's got the same principle that Backbone has in that it applies a light structure to switching between states.\nIf it helps I can put the file in a gist and write a simple example to show how it works. It may be of help.\n. Marking as closed unless anyone objects.\n. Hi Leandro,\nI used to pre-compile the assets by running my app in a custom SS environment which would pack the assets, and then run a Cake task to copy those generated files to fixed paths that would be used in production via the CDN config option. \nThe reason I did this was because I planned to deploy the SS app across multiple instances, and I needed them all to use the same JS/CSS urls no matter which instance was viewed.\nWhat you're trying to do is smarter, and I haven't tried doing it that way. The best thing I can suggest would be to fork SocketStream and add in support to emit events on assets being compiled.\nGood luck.\n. An update - 0.4 is being cancelled, so that we can focus all dev work on one branch, the current branch.\n. I'm putting this into consideration for the 0.4 milestone branch.\n. Sadly I'm not able to do that right now. If I could work on SocketStream as part of my job, that would be great, but sadly I'm doing more of a sysadmin/full-stack dev/qa job at the moment.\n. @thepian is this something that can be done for 0.3.12, or would depend on a major update (i.e. 0.4).\n. Made a pull request to fix this issue: https://github.com/socketstream/socketstream/pull/323\n. Closing as the pull request #323 fixes this issue.\n. If you want to run Express in production mode (so you can utilise view caching), then in order to ensure that both SS and Express are running in the same environment, you have to either a) pass both environment variables in your command line, or b) pass one environment variable in your command line, and have that set the other environment variable in your code, or c) set both environment variables in your code.\nI hadn't considered that there would be a case for running SS in a different environment to Express and other node libraries.\n. done\n. I think it would be very useful, but the challenge is code reloading reliably. On the Node.js google group, there is a lot of discussions about hot code loading:\nhttps://groups.google.com/forum/?fromgroups=#!searchin/nodejs/hot$20code$20load\nThe general gist seems to be that reloading can lead to issues with garbage collection, and you can end up having weird problems that are caused by variables not being cleaned up. Thus, the suggested route is to load your app in a child process, and have file changes kill that child process and start a new one in it's place. In this case, it would mean reloading the application.\n. Adding this into 0.3.12\n. If you wish to reopen the PR and add some tests for it, I'll be happy to consider it for merging. \n. Hi,\nTo my knowledge, there's never been an official way to handle i18n within SocketStream. That said, there are 2 posts from users mentioning i18n in the Google Group:\nhttps://groups.google.com/forum/?fromgroups=#!searchin/socketstream/i18n/socketstream/ObQHROrSvPA/FA65kGOyyIwJ\nhttps://groups.google.com/forum/?fromgroups=#!searchin/socketstream/i18n/socketstream/cTso7tQ4-Zo/24kqaFn7rFcJ\nIt may be worth getting in contact with those post authors to get their take on how they approached it.\n. Closing as this is a discussion and not a feature request.\n. Hi halfblood369,\nCould you try and run this command and post stacktrace here:\nnpm install hiredis\nAlso, what version of Windows are you installing Socketstream on?\n. Hi,\nYou will need to install 'make' for windows, which you can get here: http://gnuwin32.sourceforge.net/packages/make.htm\nOnce you've done that, make sure to reload your command prompt (so that make is a known command), and then run the commands again.\n. You're welcome, I'll make sure (excuse the pun) that this info goes into the FAQ. \n. It looks nice, I have a crazy idea. \nWould it be possible to use this feature to make an rpc file use multiple RPC functions, providing RPC actions you can plug into an rpc file and re-use across rpc files?\n. Suggestions 1 & 2 seem sensible.\nI agree that config options shouldn't be a mandatory requirement in SS, but I think strongly believe that shipping a config file/option in default SS apps will be very helpful to users when they want to put their apps into production.\n. I have discovered how to resolve this issue, and a potential gotcha for anyone else who comes across the same problem.\nIt you attempt to execute your app.js file inside the cakefile, then attempt to load ss.start() inside one of your test files, the ss inside your test file will not load the RPC, for some strange reason.\nBy removing the loading of app.js inside of the cakefile, I have been able to stop this issue. As a result of this discovery, I am now on course to remove all of the global variables inside of Dashku, and re-architect Dashku so that it can use a plugin architecture.\nRemind me at some point to write this up for the documentation on testing SocketStream applications.\n. I think you have to call it via ss.api.rpc\n. Hi,\nSocketStream uses Socket.io for the Websocket transport. If I understand your requirements correctly, then this may be of help:\nhttps://github.com/pkyeck/socket.IO-objc\nSee the YouTube video for a quick explanation:\nhttp://www.youtube.com/watch?v=VCXKMVENW_o\n. Update: Using a forked version of SocketStream, I've been able to make the default SocketStream app deploy to Heroku. It involved removing Socket.io from the dependencies list in the package.json file. \nTo get the SS app working on Heroku, I used ss-engine.io with the following configuration options:\njavascript\n    ss.ws.transport.use(require('ss-engine.io'), {\n      client: {\n        transports: [\"polling\"],\n        upgrade: false\n      },\n      server: {\n        transports: [\"polling\"],\n        allowUpgrades: false,\n        pingInterval: 10000\n      }\n    });\nI now think that there is a case to replace Socket.io as a dependency of SocketStream with either SockJS or Engine.io.\n. So there's an outstanding issue with ss-engine.io that's worth reading. \nIf Socket.IO doesn't reconnect channel subscriptions upon a reconnection, then ss-engine.io can replace it now. However, if it does, then we need to implement this feature into ss-engine.io before it could replace Socket.io.\nI'll check Socket.io's current behaviour now.\n. Hi @jcw,\nI don't see any references to ss-engine.io in your app.js file, and the version of socketstream in your package.json file is \"~0.3.2\". I might be wrong but that version of SocketStream is before ss-engine.io was merged into SocketStream. Can you check whether the socketstream node module is either the 0.3.2 published version, or the master branch version on github?\n. Hi, I've just checked on my mac (uninstalled and unlinked all versions of SocketStream from my mac), and npm install socketstream installs 0.3.2 with socket.io 0.9.8.\nIs it possible that you have a copy of the socketstream repository that has been linked to via npm link?\n. You're welcome. With regards to the RPC issues you were experiencing, I will try and run that app against the master branch version of SS to find out what is going on there.\n. I've tried running the homemon app but I see this and I'm not sure what I do next.\n\nI've had Dashku.com running with the master branch of SocketStream for over a week now \nwithout any connectivity problems. I have not been able to replicate any problems with doing RPC with this. Would greatly appreciate a 3rd check by someone else to see if they encounter any issues with doing RPC against the master branch.\n. Hi.\nI'm using 'npm start' to launch the app, and I checked out the master branch of your app. \nI may have misunderstood what you meant by \"using git master\". If you mean how can you check your against the master branch of SocketStream,the way I do it is I checkout SocketStream into a directory, go to the app's directory, then type 'npm link path/to/socketstream_directory'. I type 'npm unlink socketstream' when I'm done.\n. Hi,\nIt's absolutely fine, I'd like to figure out what the bug is and fix it, regardless of what library it originates in. \n. It's a long shot, but does the number of argurments that you pass to an RPC have any effect on it working? In my app's cases, I've only passed ss.rpc ('x.x', callback) or ss.rpc ('x.x', arg1, callback).\nThanks for the info, I'll give it a look later on today.\n. Hi @jcw,\nI ran the latest version of your app, and the app seems to work fine with both the 0.3.2 and master branch versions of SocketStream (the server time display on the sandbox url worked exactly the same in both cases).\nI followed your readme instructions, then I did the following to test master branch of SS:\n1 - edit the package.json so it reads:\n\"dependencies\": {\n  \"socketstream\": \"git://github.com/socketstream/socketstream.git\",\n...\n2 - Put the following commands in the terminal:\nrm -rf node_modules/socketstream\nnpm install\n3 - Boot the app as the readme instructs.\nCould you tell me what rpc call you were having trouble with?\n. Hi,\nI'm afraid I don't have any listings under \"Briqs\". \nI tried the 'host.api' call from the client with this command:\nss.rpc('host.api','log','this is a message');\nI managed to get the server to print out 'this is a message' in the server terminal output, both for 0.3.2 and for the master version.\nCan you try the same, and see if it works for you?\n. You're welcome @jcw, glad to have helped figure that one that.\n. Yep, ss-engine.io was created from a copy of ss-sockjs' codebase. I'd be happy to accept any PRs to ss-engine.io to clean this up.\n. Hi @davisford,\nOwen is on holiday for a couple of weeks. I'll lend you my eyeballs and see if I can figure out what's happening.\n. Hi plievone, \nThanks for spotting the issue. Would you like to fork the repo and submit a pull request with the fix in, or would you like me to do that?\n. Yep, so there are 2 API methods exposed: 1 inside of rpc files, and another for all other files. You'll need to call ss.api.publish.\nHere is the linked section in that document: https://github.com/socketstream/socketstream/blob/master/doc/guide/en/pub_sub_events.md#publishing-events-via-appjs\n. What file contains the call to ss.api.publish, and how is it being loaded (in a separate Node.js process to the SocketStream app, or as a require(\"./example_file\") in the SocketStream app's codebase)?\n. The folder path needs to be server/rpc, then run node app.js.\n. Hi, just wanted to ask if changing the path of the file from rpc/serial.js to server/rpc/serial.js did the trick?\n. Sorry, I'm in github-issues-driven development mode ;)\nLuckily for you, I ran into this once. I believe it was to do with using npm modules being compiled against a older version of Node.js (0.8.12), then using a updated version of Node.js (0.8.16).\nThe suggestion here is to remove all modules in the app's node_modules folder ('rm -rf node_modules' works for me), then run 'npm install' again, then the app runs again.\n. Hi @thebadger412,\nFiles inside of the server/rpc folder need to be structured with this code:\n```\nexports.actions = (req,res,ss) ->\nexample: ->\n    ss.api.publish.channel('channelName','eventName', {data:'value'});\n\n```\nTake a look at this file in Dashku for reference: https://github.com/Anephenix/dashku/blob/master/server/rpc/dashboard.coffee#L44\nAlso note that ss is being inherited from exports.actions (req,res,ss), not the require at the top of the file.\n. Commented on the gist file.\nAlso, in relation to \"Like I want it so as soon as the server starts it sends this value to bigNumber..\", you'll need to make an RPC call somewhere (either from browser or terminal, or somewhere in the app.js file after the server is started and a port is listened on) - Here is the relevant document about RPC:  https://github.com/socketstream/socketstream/blob/master/doc/guide/en/rpc_responder.md\n. Hi, there's a bit of Javascript you can use to stub out console for IE here:\nhttps://gist.github.com/gerad/1943520\nIs this still an issue with SocketStream 0.3.4? I'm wondering if browserify didn't clean up the calls to console by now. \n. Oh wait, it is. Nevermind. I will make a PR with this patch for IE.\n. Thanks for the info. A StackOverflow thread suggests some other possible options:\nhttp://stackoverflow.com/questions/690251/what-happened-to-console-log-in-ie8\n. Hi Raynos,\nI don't know if you've tried it, but there is an npm module called livereload: https://npmjs.org/package/livereload which reloads CSS files without requiring a page refresh.\n. How about this? http://aboutcode.net/vogue/\n. You're welcome. I remembered seeing other tools that did the same thing. Hopefully one of them does a good enough job.\n. Hi Rednaxus,\nThanks for reporting this. I'll begin a fork of SocketStream to implement the security fix, and a notification on the Google Group now.\n. Hi Rednaxus,\nI've committed the patch. I'm going to let the others know as well. Could you do me a favour and give this patch a try?\n. Hi Rednaxus,\nAt the time I simply wanted to make sure users could patch the security hole ASAP. I didn't give consideration to auto-detecting the server protocol and setting the value that way. I will have a look and see if it's possible.\n. I had a very brief look last night but I couldn't find a way from within http/index or session/index. The next chance I'll get to look at this is this evening.\n. An update. I'm probably not going to get a chance to implement a way of auto-detecting the server protocol and setting the secure flag in the session options. Would anyone else like to have a pop at implementing this? \n. Hi @jcw, \nIf you are using Node V0.8.20, then this is the issue that you are encountering: https://github.com/senchalabs/connect/issues/750\nIt's basically a change in Node v0.8.20 which means that you have to handle socket errors. It's irritating, but the upside is that the change in that version of Node stops a memory leak.\n. The middleware you suggested should (in my opinion) work, and in order to check that you have intercepted that socket hang up error, I would write this line instead:\nres.on 'error', (err) -> console.log err\n. Hi,\nThe engine.io http library would also have to be patched. \nAlternatively, 0.8.21 was released last night. I I recommend upgrading from 0.8.20.\n. # \u270c\n. I'd like to add this feature in, as I spent some time last night trying to get it in to optimise an app's loadtime performance to get under 200ms. I will find a way to add those changes in and update documentation as appropriate.\n. Thanks @essentialjs,\nYeah, this was essentially to gain the page-rendering improvement that occurs when you locate the JS assets before the closing body tag, rather than directly after the link tags for the CSS in the head section.\n. I'll close this PR for now, and added the feature request to the Trello board for now.\n. Hi @polidore,\nThe line you highlighted in the code gets a connect session id from the user's cookie, and is used to bind the websocket connection to that session. \nYou said that your app servers have separate session stores? There is the possibility of sharing sessions between app servers via Redis, which I believe should stop the servers from resetting the cookie every time the load balancer  points the client to another server.\nAlso, are you setting the max age in your session config? See this for info.\nhttps://github.com/socketstream/socketstream/blob/master/doc/guide/en/sessions.md#auto-expiring-sessions\n. Hi @polidore,\nThanks for the issue.\nI don't think that this is an issue with the cookie key, as the connect.sid cookie key has been used within SocketStream since the socket.io implementation, see: https://github.com/socketstream/socketstream/blob/38da2b096b43adbb2a814d94bd0ff6eda060d5c3/src/websocket/transports/socketio/index.coffee#L84. That said, there should probably be a way to specify a custom cookie key.\nI'd like to try and replicate the app setup that you've used for your app, because when I developed ss-engine.io I naturally assumed that you would want to share session data across all running instances of the app, so that client reconnections use the same session, and do not lose channel subscriptions. I recall that you're not sharing sessions between servers in your case, so I'd like to try and fix this issue to cater for that use case.\n. Hi, no worries, I get the frustration when working software breaks. \nI will give it a go tomorrow morning, and checkout your pull request as well.\n. Hi,\nWas this issue resolved by the work on the Websockets (#397)?\n. I don't know if this is related, but has anyone seen this bit about needing a P3P header in IE9 in order for it to work with sessions: http://ruhmesmeile.github.io/socketstream-presentation/#/5/11\n. @mdedetrich Thanks for the tip, I'll make a note to add that to the documentation.\n. The workaround suggested here may help: http://stackoverflow.com/questions/6136101/jquery-ajax-request-in-ie9-not-sending-cookie-header \n. Hi, I'll look into this today. Sorry it's sat on the queue for so long.\n. This is now fixed as part of the 0.3.6 release\n. Hi @dzz0615,\nThis looks like a useful feature. Thank you for contributing it. Fingers crossed this gets merged in, if anything it brings 0.3 a bit closer to how 0.4 will work.\n. Thanks for scoping it to that release, I wonder if they've encountered the same issue in the engine.io repo. I'll have a look into it.\n. I've tried running a default ss app on v0.10.6, and not replicated the issue, but I did discover that the default transport bundled into SS from 0.3.4 isn't using reconnection logic, which is a bug. I'll try out 0.9.4 and try to replicate the issue with that.\n. At this point in time, not likely. SocketStream's client library management was created well before the likes of component.io and bower came into existence. This is an issue I want to address with 0.4 - how to make SocketStream play nicely with client-side tools like bower, grunt, and yeoman.\n. @mattlenz Does Roman's suggestion provide what you need?\n. Hi, \nI provided a response to this query in the Google Group a few weeks back: https://groups.google.com/d/msg/socketstream/c_7KBIDzqwY/C6RavWCskfsJ \nI just wanted to catch up and check if everything is good?\n. Also, if you need to delay the test timeout, you can use this: http://visionmedia.github.io/mocha/#test-specific-timeouts\n. Also, you may want to manually check that ss.rpc('app.square') is working from the browser, because it could be the case that it isn't returning.\n. I ran this test as documented in the guide, and it ran fine. I'm closing this issue as a result.\n. I'll have a look into it. From a quick look I think that the reason why the ss global variable is set like that was so that it was clear where that variable was originating from.\n. Just wanted to check up on this issue and ask:\n1 - If you adjust the line to expose ss as a local variable, do you still encounter a problem?\n2 - For the approach you described, do you have a working example that you could submit in a PR?\n. Hi,\nI'll have a look at it this lunchtime (BST).\n. Thanks Roman,\nI gave this a try on Dashku (running locally, but using minified assets), and using Google Chrome's PageSpeed Insights extension, my score went from 47/100 to 93/100. BAM!\n. Hi Owen,\nI didn't see that, my bad. I'll take a 2nd look later on this weekend.\n. I've replace the connect-gzip npm with connect's compress middleware. The last change left to do is to get the html file gzipped.\n. Sorry, I left some compressed files in the test app before I checked it again, so I didn't spot that it hadn't compressed properly.\n. This thread on Stack Overflow might be of assistance WRT configuring the global path prefix for npm module binaries. http://stackoverflow.com/questions/14803978/npm-global-path-prefix.\n. I would, but I'm currently trying to work out what happened to a comment I left in one of the threads. Would like to know of it was deleted, and if so, why?\n. Ok, rather perplexing but nevermind.\nMy experience of using both is that RequireJS involves more effort to setup, as you have to use shims to support non-AMD modules, so you end up having to maintain links in 2 places instead of 1.\nI've used Grunt and it's a good tool, but I'm wondering how would a developer use Grunt with SocketStream? Is it to copy the minified assets to a CDN? Is it to lint the code as part of a pre-deployment strategy? It would be nice to document the developer workflow to see what gaps exist and how they can be plugged.\nI've toyed with Yeoman sparingly, but I ought to give it some more attention to see how it could be useful.\n. I'm looking into making an SS app generator with Yeoman now.\n. Closing as it's a duplicate of #378 \n. Hi Owen,\nI've looked at implementing this via ss.api.log, but I've realised from looking at the code that the publish and session modules have no knowledge/link to ss.\nI have 2 ideas about how to approach this:\n1 -  add and require a separate log module into the app to replace console.log, and which ss.log will alias to.\n2 - change how the publish and session modules load, so that they have an implicit knowledge of ss, and can then traverse the api tree to call ss.log.\nI think that 1 would be a quicker option for now.\n. I haven't forgotten about this, but when I had a go at it, I realised that I had to untangle some requires further up in SocketStream's stack of internals. I will get to this.\n. Marking as closed, thanks to the work done in #430\n. It's an issue of how to handle source map files. The asset module uses code formatters to transpile files into other formats, and because .map files are not handled, they raise an error. We could add a handle for .map files, but I'll need to look into how we do that.\nThis is an issue of how to support source map files. Ultimately it points towards a broader question of how to handle client-side files, as we now have a range of approaches, from having grunt to concatenating/minifying, to having bower manage our software dependencies. The landscape has changed a bit since 0.3 came into existence.\n. If you see the readme here (https://github.com/anephenix/ss-engine.io), you should be able to pass the contextpath for engine.io. SS-engine.io got integrated into SocketStream from 0.3.4.\nLet me know if that solves your issue.\n. @tomhowe Could you let us know if this issue is still affecting you? I'd like to fix it if it is.\n. Thanks Tom. If you have any feedback about SocketStream, I'm open to hearing it. \n. Thanks for posting that. I'll look at it this lunchtime (GMT), and if all is good, merge it in.\n. Tested, works. Thanks for the Pull Request.\n. Note: Check that you have grunt-cli installed beforehand as suggested here: http://gruntjs.com/getting-started\n. Hi,\nSorry, I should have communicated it better. I attempted to do both comment-porting and linting at the same time, and that introduced bugs. I therefore split out the comment porting and linting, and completed the comment porting part, allowing us to use the lib folder as the single source for the codebase.\nYou're absolutely right, linting the codebase is going to be a huge task.\n. Added a comment about a potential misspelling of 'grunt test' (currently reads 'gunt test').\n. Here's a fix for the issue: http://www.mattgoldspink.co.uk/2013/02/10/using-travis-ci-with-grunt-0-4-x/\n. Thanks Roman.\nTravis CI passes for Node versions 0.8 and 0.10, but 0.6 fails: https://travis-ci.org/socketstream/socketstream\nGrunt works with versions Node 0.8 and greater. Adding this change would mean ditching support for Node 0.6.\nI'd like to get some feedback on whether we do this. There are some implications, such as being able to support OpenShift's Node.js cartridge (which as far as I know only supports 0.6). \n. In that case, I don't see any reason to continue supporting Node 0.6 (after all, it is 2 levels below the current stable branch). If you could remove the need to test 0.6 from the .travis.yml file, then this commit would be good to go.\n. The minimum version of Node is specified in the package.json file, and in the travis config file.\nWe could add a line in the Readme file.\n. Hi Roman,\nThanks for the explanation.\nThe code example you gave for Mocha demonstrates an important lesson about Node.js - callbacks should not be nested at a level outside of a closure that executes an important instruction, as they will be evaluated asynchronously to whatever is going on inside of that closure.\nAlthough I take it upon myself to audit all the code commits that are being made to SocketStream, I can't rule out that I would miss something. I therefore think that there's a case for making this change.\nWhat would be involved with replacing Mocha with NodeUnit?\n. If you make a PR into the 'tests' branch, then I'll merge it in. PS - On topic, have you used Istanbul for code coverage? http://gotwarlost.github.io/istanbul/\nI'm curious to try it out. \n. An update,\nAfter some consideration, I've decided to revert from using NodeUnit for the test suite. After playing with it for some time, I found it made organising the tests for modules, and reading what those tests were, worse. It was a quality I didn't fully appreciate at the time until I delved deep into using it. Thus I've ported the test code back, allowing the tidying-up changes to remain.\nWith regards to assertion counting, I agree that we should have this in place, so I did some initial research, and I've adapted this suggestion (https://github.com/visionmedia/mocha/wiki/Assertion-counting) into a helper library that we're using throughout the test suite.\nSorry about undoing some of the work here.\n. No, I should have explained my comment better.\nThe syntax style offered by NodeUnit is in my opinion not as friendly to read as Mocha's. That is a subjective call, so I'd like to explain my thoughts. \nThe key premise I'm making is that the closer the code is to reading like plain english, then the easier it will be for other people to read and understand, and therefore the easier it will be to contribute.\nMocha's syntax style is very similar to RSpec's, and it's use of the style ' it \"should do something\" ' fits nicely with describing exactly what the test covers, as well as being able to organise those tests by way of the keyword \"describe\". This contributes to a developer-workflow of guiding the developer to speak in plain terms what they're trying to do first, before they begin to write the tests.\nWith NodeUnit, we lose the ability to express the tests in this format, if anything we tried to keep the context, but then the function names were strings, which didn't feel right.\nWith the tests I've made a decision to resort to using a test framework that allows us to continue writing tests that fit this idea. I can give an example of this. \nA couple of months ago a colleague was writing some pseudocode to break down a feature into logical parts. At one point he wrote a line of code that caught my eye. That line of code, reading something like \"do action if condition is true and another condition is true\". \nHis line of pseudocode was valid CoffeeScript. The gap between plain english and programming code was almost 0. I won't evoke Wittgenstein, but this is a wonderful case of language and logic being perfectly in fit.\nOf course, that said, one could argue that dropping the source code being written in CoffeeScript goes against this idea, and to be fair, there's a point in that. I weighed this up, and when I realised how much of a barrier CoffeeScript was to people wanting to work with SocketStream, as well as it adding steps to the code contribution process which people missed, I came to the position that for benefit of SocketStream being a broader effort, it would have to be written in a language that everyone could work with: JavaScript.\nThat's my take on it. Interestingly, this seems somewhat similar to the debate around TestUnit/RSpec in the Ruby world around 2011:\nhttp://www.rubyinside.com/dhh-offended-by-rspec-debate-4610.html\nhttp://www.ultrasaurus.com/sarahblog/2011/04/on-choosing-rspec-as-a-test-framework/\nThoughts?\n. Hi @azat-co,\nThanks for the tip. The reason to consider NodeUnit over Mocha was the support for assertion counting, but there was a way to support that in Mocha, and the syntax style in Mocha was in my opinion a better fit.\nThere was also a 2nd reason, which is that making the tests more human readable will assist with helping to understand SocketStream's inner workings enough that a language-agnostic specification could be created, which would potentially allow for SocketStream to exist in other languages.\n. Hi,\nJust want to check that this was the same issue discussed here: https://groups.google.com/forum/#!topic/socketstream/MohS3GEICgQ. If so, the resolution is to make sure that the server is listening on port 443.\n. Cool, I'll mark this as closed.\n. Thanks, I'll take a look at it by tomorrrow.\n. Thanks Robert,\nThis issue makes me think that asset serving/handling needs to be more flexible, the question is whether to address that in 0.3, or in 0.4. In my opinion, making SocketStream's asset handling wrap access to html headers could be cumbersome, and what might be better is to allow the developer to handle asset loading and compilation separate to SocketStream, but still be able to use SocketStream for pub-sub/rpc and more.\nI will definitely consider it WRT 0.4.\n. Out of curiosity, what is the workaround you found?\n. Thanks Ben, I'll take a look at this in an hour or two.\n. Thanks Ben, that's now merged.\n. I've figured out a way to work around this and get it fixed. I will test first, then publish when done.\n. So it turns out your filename can't contain gitignore or nodemonignore in it, as they will be stripped out on the basis of a match, even if the filename isn't .gitignore or .nodemonignore.\nWe'll have to use other names for those files to prevent them being removed by npm publish.\n. Hi,\nI've encountered your problem, and I will being to fix it tomorrow. Unfortunately I couldn't do anything about beforehand as I had to help my mother move house today.\nThanks for reporting it, and apologies that you had to in the first place.\nRegards,\nPaul Jensen\n. Hi @zvxy, I have a fix for the issue you found which will be pushed shortly.\nI've discovered that when writing to files (with either fs.writeFile or fs.createWriteStream) with a dot at the beginning of the filename, the file never gets written. This could be a bug, but I'll ask before I file anything. The implications are that we can't ship .gitignore/.nodemoningore files with a beginning dot in the name.\n. I've stopped the app generator from breaking, but I've also spotted that the .gitignore and .nodemonignore files are not being generated in a new project, which looks like an issue with them containing dots in their file name.\n. Actually, it turns out that this isn't broken anymore, I was using ls -ll instead of ls -la to list the files, and Max OS X doesn't list those files with ls by default.\n. Hi Roman,\nThanks for the commit. If we correct the spelling of browserifyExcludePath in the code, I'd like to give it a full run and get it merged in.\n. Also, I'm open to looking at your suggestion about minimatch, although I think it ought to come in via a separate pull request.\n. Hi, I tried the branch, but encountered this error: \n/Users/paulbjensen/Work/anephenix/test-402/node_modules/socketstream/lib/client/index.js:93\n          _results1.push(options[k][x] = y);\n                                       ^\nTypeError: Cannot set property '0' of undefined\n    at /Users/paulbjensen/Work/anephenix/test-402/node_modules/socketstream/lib/client/index.js:93:44\n    at Object.set (/Users/paulbjensen/Work/anephenix/test-402/node_modules/socketstream/lib/client/index.js:96:13)\n    at Object.<anonymous> (/Users/paulbjensen/Work/anephenix/test-402/app.js:25:11)\n    at Module._compile (module.js:456:26)\n    at Object.Module._extensions..js (module.js:474:10)\n    at Module.load (module.js:356:32)\n    at Function.Module._load (module.js:312:12)\n    at Function.Module.runMain (module.js:497:10)\n    at startup (node.js:119:16)\n    at node.js:901:3\nI'll dig into what's going on here more tomorrow.\n. ss.client.set({ brosefyExcludePaths: ['app/controllers'] });\nThis is before pulling in the rename changes. I'll check with the rename changes as well.\n. I'll push test-402 up to a new git repo\n. Here, https://github.com/paulbjensen/test-402\n. A dumbass move on my part, forgot to npm link. Sorry.\n. View templates already contain the <meta charset=\"utf-8\"> attribute, so I say nothing more needs to be done here. I'll give it a check now.\n. Thanks Roman, great stuff.\n. Thanks for adding this. I'll look at it tomorrow as I'm battling a cold and\nneed to sleep first.\nOn Wednesday, October 9, 2013, RomanMinkin wrote:\n\nHi everyone,\nI have spent some time to finally come up with the solution for gzip\nsupport for main HTML files. Related issue #376https://github.com/socketstream/socketstream/pull/376\nWorks only for packed files, which does make cense.\nI tested with default SocketStream demo app (http + connect) and with more\nadvanced with Express.js https://github.com/visionmedia/express on the\ntop.\nResults:\nDate                Wed, 09 Oct 2013 19:59:55 GMT\nContent-Encoding    gzip\nTransfer-Encoding   chunked\nConnection          keep-alive\nVary                Accept-Encoding\nContent-Type        text/html\nand with Express\nDate                Wed, 09 Oct 2013 20:00:14 GMT\nContent-Encoding    gzip\nTransfer-Encoding   chunked\nConnection          keep-alive\nX-Powered-By        Express\nVary                Accept-Encoding\nContent-Type        text/html\n\nYou can merge this Pull Request by running\ngit pull https://github.com/RomanMinkin/socketstream feature/gzip-compression-for-main-html-files\nOr view, comment on, or merge it at:\nhttps://github.com/socketstream/socketstream/pull/404\nCommit Summary\n- Added support for GZIP compression for main HTML files\nFile Changes\n- M lib/client/http.jshttps://github.com/socketstream/socketstream/pull/404/files#diff-0(14)\n- M lib/http/index.jshttps://github.com/socketstream/socketstream/pull/404/files#diff-1(5)\nPatch Links:\n- https://github.com/socketstream/socketstream/pull/404.patch\n- https://github.com/socketstream/socketstream/pull/404.diff\n\n\nPaul Jensen\n07914 171 345\n. Thanks Roman, so glad to get that optimisation sorted as well. \nI don't know if you've seen it before but there's a neat extension for Google Chrome called PageSpeed Insights: https://developers.google.com/speed/pagespeed/insights/, it's very handy for spotting ways to improve web app performance.\n. Hi Lukas,\nThanks. At the moment there is no way to run packAssets separate to calling ss.start, and there ought to be (like for example running it as part of your Grunt workflow). \nI've marked this as a feature request.\nI've had a go at trying a workaround to this, in this repo: https://github.com/paulbjensen/test-405 . What I do is have the app.js contain most of the app loading, and then pass ss and server as public objects. Then I have server.js for booting the app on a port and run, and have pack.js boot the app (on a separate port) and pack the assets.\nWe'd need a way to trigger a callback on packAssets finishing. I'll look into adding that, as well as finding a way to run it outside of booting ss.start.\n. Hi @evanlh, Thanks for this, I appreciate your help with it.\nIn my opinion, providing access to internal events via the API isn't a bad idea. I'll play with this patch in a couple of SS apps, and see how well it works.\n. Hi,\nYes. SocketStream's codebase was never developed with linting in mind. It was introduced recently, and I tried to lint the codebase, but in the process of doing so the web framework broke in places, so I decided that it would be better to put unit tests in first before getting the codebase linted.\nAs the length of your log file demonstrates, there is a lot of work to do.\n. Added a note for now. We want JSHint in there to remind us that we have to get the codebase linted, no matter how much or how ugly the work is going to be.\n. Hi, thanks for submitting this. I'll take a look at it later today.\n. Thanks. At some point we'll want to document this in the guide, and give a description of the pros/cons\n. You're welcome, thanks for contributing it, there's always room for\nimprovements like this.\nOn 25 October 2013 16:41, pygy notifications@github.com wrote:\n\nBTW, thanks for accepting this :-)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/407#issuecomment-27102684\n.\n\n\nPaul Jensen\n07914 171 345\n. Good idea, I'll create a milestone and assign this issue to it.\n. No, instead do npm run lint.\n. Yep, agreed. I've been trying to use !condition instead of === undefined or === null in these cases, was there a line I broke? \n. What if we add fixtures and auxiliary files to .jshintignore?\n. Hi,\nI don't believe that we have an ability to switch ports based on the transport protocol. I'll need to take a closer look at working with OpenShift. We originally had the demo app running on it, but we experienced some issues so we moved it to Linode. \nWe'd also need to look at how to work with OpenShift's scaling system. They use HAProxy to handle routing requests to gears. I've seen threads saying that a gear handles a maximum of 10 concurrent connections. I don't know if they use sticky sessions, but we'd need to determine that as it's crucial to how the underlying engine.io transports work (a long-polling/websocket session's state is stored within a process).\n. I should note that SocketStream no longer uses Socket.io, but instead uses\nEngine.io (which is the transport library part of Socket.io, and will be\npart of Socket.io 1.0).\nOn 18 October 2013 10:56, Christian Sterzl notifications@github.com wrote:\n\nThx for looking at it. I've seen following post:\nhttps://github.com/LearnBoost/socket.io/wiki/Socket.IO-and-firewall-software\nThe client js will initially try to connect to port 4000 and fall back to\nports 80 or 843, if that doesn't work. I also tested different orders for\nport 80 and 843, to make sure both work (or not).\nSo the client seems to be able of doing this. On the server are both ports\nopen anyway. Maybe this is helping.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/409#issuecomment-26584117\n.\n\n\nPaul Jensen\n07914 171 345\n. Good question. I think it will involve forking the repo, and editing the client wrapper files in /lib/client to add an error listener.\nI'll have a look for you at lunchtime.\n. So, that was a long lunch. Apologies for the delay in getting back.\nAfter encountering a painful bug in engine.io, I updated chassis.io to the latest version, and I now realise that SocketStream could use the same update. I'm going to be updating the client in the coming days.\nWith regards to dealing with your query, the way that I think it can be achieved is this: \n1 - Fork this repo: https://github.com/socketstream/ss-engine.io\n2 - Add an 'onerror' event on the sock event emitter as defined here:\nhttps://github.com/socketstream/ss-engine.io/blob/master/client/wrapper.js#L17\nInside of that error, set config.port to the port to the openshift websocket port.\nNow, I'm assuming that sock.onerror will call before sock.onclose, so that you can change the config.port value before the reconnect logic kicks in, and attempts to reestablish the connection.\nIf you need a hand, let me know.\n. No worries @Waxolunist, I am in the same position right now ;)\n. Thanks, I'll take a look today.\n. So, @americanyak is responsible for the documentation, and there is a repo where work is being done to port the docs to the main web site.\nWe'll need to do more there.\n. The repo is private, but I'm going to open source it now.\n. Here is the repo: https://github.com/socketstream/ss-documentation\n. Yep, I think that Github anulled team access when I transferred the repo from Anephenix org to SocketStream account. You're both added as collaborators now.\n. To follow up, I see a list of tasks:\n- [ ] Get the docs site functioning\n- [ ] Get the docs site hosted on a server and a domain pointing to it (doc.socketstream.org)\n- [ ] Get the doc linked to it\n- [ ] Add documentation on how plugin writers can contribute to SocketStream\nAny more to add? I'll get onto it.\n. Hi Romain,\nThanks for the suggestion, I think that this could work. What are everyone else's thoughts?\n. @RomanMinkin do it.\n. This is now available via the ss-ejs npm: https://github.com/socketstream/ss-ejs\n. Hi,\n@Waxolunist is right. \nAt the moment, if you are serving plain vanilla html views, then we look for a  tag, and what that out with the html needed to boot the app's javascript and css.\nIf you are using jade templates, then socketstream is accessible as a local variable. I would potentially like to find a way to support the same pattern of a jade html tag that is just socketstream, and again replacing that out. It's something to consider down the line.\nAre the css in the jade templates now working for you? \n. Thanks.\n. Hi, I've tested your change out. It nicely handles supporting Push State Routing, whilst at the same time returning 404s for other files.\nYou'll need to declare the path dependency at the top of the lib/http/router.js file:\nvar path = require('path');\nIf you add that in another commit to the feature branch and push again, the PR will pick it up, and then I will merge the PR. Thanks for your work.\n. No, that was all. Thanks. If you want to check how your local build of SocketStream work against an existing app, npm link will let you do that:\ncd app\nnpm link <path_to_socketstream_copy>\nThen when you've checked out your changes:\ncd app\nnpm unlink <path_to_socketstream_copy>\nnpm install\n. For tracking purposes, fixes #286\n. Thanks Roman, I'll have a look at it tomorrow, if not tonight.\n. Hi Roman,\nI've had a look at the pull request. There is a regression when the app attempts to serve this route:\nhttp://localhost:3000/_serveDev/start?ts=1388920881715\nIt takes a couple of minutes to serve the file:\n\nI tested this by pointing the socketstream/ss-home repo to use this PR of socketstream via npm link.\nI'll have a look at the issue again this evening.\n. No worries,\nI will take a look again tonight. In terms of whether to upgrade connect, I'm open to considering it, but I also expect that it won't be a straightforward swap-in-and-out, so I think that it would be a candidate not for this release, but possibly for 0.3.12.\n. I believe that @kulicuu is looking into this issue, is that right?\n. Hi everyone,\nThanks for your suggestions, I think that there are some good recommendations in there. There's a lot of thoughts relating to this subject, so apologies if this a long and rambling comment.\nMy thoughts\n\n0.3 is what most people use, and still needs a lot of work (test coverage, issues)\n0.4 is beginning to look like vapourware (no development since April 2013).\nSince 2011, SocketStream was effectively rewritten twice, each with breaking changes.\nThose rewrites (though doing good things) caused uncertainty and frustration for developers wanting to build apps using SocketStream, apps that would be used in the long term.\nPeople I spoke to in private said that they abandoned SocketStream because of this.\nThe popularity and momentum behind SocketStream is directly linked to the number of developers working with it multiplied by the time they could give the project.\nIn Summer 2011, there was a team of 3 working almost full time on it at AOL, then it was just Owen from July/August 2011, then Owen left AOL in November 2012. Now, no one works on it full time.\nThe lack of (easy to find) documentation may have limited the adoption of the framework.\nThe lack of tests for the framework has made it difficult to add features without causing regressions.\n\nWith these things in mind, I've realised that 0.3 has to be maintained, that the gaps in tests and docs have to be filled in, and that given current time available, this makes working on 0.4 more unlikely.\nAn article that has influenced my thinking is this: http://www.joelonsoftware.com/articles/fog0000000069.html\nI feel that some of the things Joel Spolsky mentioned in that post have parallels with SocketStream's history: namely the fact that when SocketStream was rewritten with 0.3, the Meteor project came along and gained the lion's share of attention in the real-time web space.\n0.3 is good enough to build amazing apps on; I have proved that by building Dashku and then getting offered the chance to move to California and work for Facebook as a result.\nSo where does that leave 0.4?\nI think if we're brutally honest, unless there are more people and time to work on SocketStream, 0.4 as a rewrite of 0.3 won't see the light of day in June as I promised.\n0.4 was originally inspired by Substack's streams talk at LXJS 2012: http://www.youtube.com/watch?v=lQAV3bPOYHo\nHowever, after some initial testing, Owen found that streams were significantly lower than Connect's middleware (in terms of requests per second). Therefore SocketStream 0.4 would instead be envisioned as a way of decoupling the features of SocketStream so that you could use SocketStream's asset compilation without having to use the WebSocket transport module, and so on.\nAt RealtimeConf EU, Owen presented Prism, SocketStream's WebSocket transport effectively decoupled out of the stack. Soon after, ti was proposed that Prism should be replaced by Arnout Kazemier's Primus module. Then, a couple of months on, not much happened, and Owen was more involved in other projects, and so he looked for a new lead developer. \nNo changes to 0.4 have happened since Owen worked on Prism and handed over the project. \nI'm therefore coming to the view that socketstream-0.4 needs to be declared as abandonware. \nI don't want to do anything to the 0.4-related modules just yet, but I think that we'll want to keep the code available as a sandbox for things we can do in the 0.3 codebase. I will consider Romain's suggestion.\nWe can instead get to 0.4 by way of refactoring the code in 0.3, rather than rewriting it.\nOn a second note, I think that SocketStream is going to require more support than it gets, more than it got from AOL (who actually took developers away from it at the height of it's popularity... big company politics).\nI think that SocketStream requires a corporate sponsor, someone who is interested in Node.js, and is interested in SocketStream's potential, especially in advertising.\nLet me know your thoughts.\n. @arxpoetica You're welcome, it's important to incorporate feedback into the project. \nI think your suggestion WRT 0.5 makes sense, but no work can begin on the new version until the work on 0.3 is done.\n. The announcement has been made. Closing as a result.\n. This may be of interest https://github.com/socketstream/socketstream/issues/405\nIn terms of getting the assets to be packed to a relative reference, I have got them to be packed with a fixed filename before, but not in terms of getting a relative file reference. I take it you're trying to serve the JS/CSS via a CDN?\nAs for the engine.io path, that option exists here: https://github.com/socketstream/ss-engine.io#usage\nI'll look into this at some point. It's difficult to get time at the moment as I'm the only full-stack developer/sysadmin at work, and I've got 3 projects to deliver before I go on holiday to Thailand/Australia in March.\nI will try and see to this before then.\n. Hi,\nCan I ask how you've setup the index.html for serving, as well as how you boot the socketstream app?\nI remember Owen once saying that the html page has to be served at the same location as the socketstream server, you can't serve this from a CDN (sadly). \n. Hi,\nIt sounds similar to what David Zhang experienced when he was making an Android version of an app that was connecting to SocketStream: https://groups.google.com/forum/?pli=1#!topic/socketstream/CfDts_W3cZM\nIt sounds like the client is unable to handshake with the server, due to a lack of session id. Have you tried experimenting with enabled only long-polling, or just websockets when establishing the connection to your phonegap app?\n. If you want to remove the makefile as part of the PR, that would be great.\nOn 28 January 2014 14:54, RomanMinkin notifications@github.com wrote:\n\nHi @ignlg https://github.com/ignlg,\nThanks for dong that!\nFYI Makefile has been deprecated instead we are using grunt test for\nrunning tests. Checkout CONTRIBUTING.md#working-with-source-codehttps://github.com/socketstream/socketstream/blob/master/CONTRIBUTING.md#working-with-source-codefor detailed information.\np.s. Makefile should be removed, i do not know why we are still keeping\nit =)\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/427#issuecomment-33484841\n.\n\n\nPaul Jensen\n07914 171 345\n. :) - Thanks Ignacio.\nOn 28 January 2014 16:03, Ignacio Lago notifications@github.com wrote:\n\nAs it was there I thought that it should be maintained. Otherwise it's\ngarbage. Grabage day =)\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/427#issuecomment-33492409\n.\n\n\nPaul Jensen\n07914 171 345\n. Cool. \nIf we could theme it so it doesn't look like a defacto Bootstrap site, then that would be great. I'd be happy to port the theme from the new ss site to this. Once that's done, I'll switch the DNS.\n. On a side note, core now has admin privileges.\n. Hi Luksch,\nSorry I didn't address this last night. I'm here now. Could you provide some more information?\nWhen you say \"where each nodejs server sends all channel messages to all connected clients\", could you let me know these bits:\n1 - What kind of message you are sending \"ss.publish.all\", or on a specific channel that some clients are subscribed to.\n2 - Could you execute these commands, and then send the output from that command when you see this unexpected behaviour?\n```\nredis-cli\n\nMONITOR\n```\n\n3 - You say that you have 2 node instances on the same server. Are they using clustering, or are they both running independently?\nThanks. We'll figure out what's going on and then resolve it.\n. Hi Luksch,\nSorry for not replying earlier, work was very busy before I took my holiday (which I'm on now). I'm looking at it right now. I've got a repo here:\nhttps://github.com/socketstream/test-429\nWhat I'm going to do is replicate what you're doing, and then debug it.\n. Hi, \nI've pushed some updates to that repo. I would like it to effectively replicate what was going on in your case. It's not yet finished (it's causing on error on the client), but once it's done I will check with you if it replicates the issue that you're encountering.\nI'm sorry about how long it's taken to get back to you on all of this.\n. Hi @luksch,\nI managed to replicate the issue that you described. In the test-429 repo, the node app is setup to use Redis, and the app runs on port 3000, and you can make it run on another port by passing a PORT=3001 env variable before running it on the command line.\nWhat I did was run 2 instances of the app (ports 3000 and 3001), and have the client code subscribe to a channel and publish a message if the client was on port 3001. I then had the client log out any channel messages and data sent.\nWhat I found was that both web pages for 3000 and 3001 received the channel events and data, even though only the client on port 3001 was supposed to receive them.\nThank you for bringing this bug to my attention, and I'm very sorry that I haven't addressed it sooner.  I'm going to ascertain where in the stack the error is occurring, and fix this ASAP.\n. Hi @luksch,\nI've looked closer into this issue, and determined what is going on with it.\nAn important question - did you use the same web browser to view the app on ports 3000 and 3001?\nI did this, and when I used MONITOR in Redis and replicated the test, I realised that the session id across ports 3000 and 3001 were using the same session id. The sequence of events:\n1. Boot the app instances\n2. Load localhost:3000 on Chrome, you see this in Redis's MONITOR output:\n1397668855.297857 [4 127.0.0.1:49617] \"get\" \"sess:QZjauOQjvk+KQJSgajKU35Af\"\n1397668855.315888 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.460099 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.631572 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.651987 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.657819 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.663204 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.664853 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.682862 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.684663 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.752127 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.754217 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.825633 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.825706 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.850876 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.851917 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668856.286425 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1. Load localhost:3001 on Firefox, you see this in Redis's MONITOR output:\n1397668940.799253 [4 127.0.0.1:49620] \"get\" \"sess:hGLo9zc24UVq5SrtPLPWh2Ng\"\n1397668940.819681 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.023671 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.030047 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.032372 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.037014 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.039049 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.039912 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.046075 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.047053 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.047944 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.050092 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.054008 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.056990 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.063100 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.064955 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.405076 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.493249 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.501983 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"channels\\\":[\\\"arbChannel\\\"]}\"\nTake a look at the values around sess:. You'll notice that they're different IDs.\nNow...\n1.  Load localhost:3001 on Chrome, you see this in Redis's MONITOR output:\n1397669085.636825 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.657687 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.775757 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.778843 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.845790 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.868078 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.869567 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.871450 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.873816 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.876063 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.886307 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.888882 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.912369 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.923943 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.940766 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.945730 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669086.567125 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669086.631212 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669086.643265 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"channels\\\":[\\\"arbChannel\\\"]}\"\nNotice that the sess: value for localhost:3001 is the same as the one on localhost:3000. Also notice how the session is now marked as having a channel subscription to 'arbChannel'?\nThis is what is happening. \nIs this a bug? Yes and No.\nNo, because on the one hand, both servers see the same session id, and both read/write to the same data source, hence being able to horizontally scale the web app instances whilst have them writing to the same data source.\nOn the other hand, yes, this is a bug. Do you want to have the same session id for localhost:3000 and localhost:3001? I imagine in your case not. This is what I need to look into further, because it's not straightforward to developers that this is what is happening, or what they wanted.\n. Hi @luksch,\nI'd like to pick this up again. Since we last spoke, I finished working at Axisto and started a company. I'm currently doing some client work as part of the new company.\nTo briefly explain the problem that you ran into, it looks like the trying to access a site on localhost:3000 and localhost:3001 returns the same session, hence both receive the same messages.\nA potential way to work around this issue would be to try and access the site from say 127.0.0.1:3001, so that you don't see the same session.\nI'm sorry that I've been off the radar for a couple of months. I had to serve 3 month's notice at my previous job, and I started work at a client site, taking over a rather large codebase with immediate issues to address and projects to begin. To say the least I've been inactive on matter regarding SocketStream.\n. I will have a look into this issue again.\n. I'll provide one later today, one I get a bit of time.\n. To add some context, my reply that was mentioned on Apr 16, 2014 should be revisited. I worked out what was going on, but I've yet to make the change so that you can configure the behaviour to work differently.\n. The channels are attached to the session id, and when you visit the site on localhost:3000 and localhost:3001 in the same browser, then both will load the same cookie, hence the same session id. \n. @evanlh Thanks you for contributing this PR.\n@RomanMinkin Thank you for taking a look at it.\nI'm sorry I haven't responded to this earlier, work has taken over my life and will continue to do so for the next 3 weeks. \nI'll have a look at the PR code and offer any feedback that hasn't been made already.\n. Thanks @RomanMinkin. I'm starting to think that the 2nd event parameter is a YAGNI, and that we should remove it, plus cleanup the calls from watcher.on to it.\nBasically do what @evanlh did originally (apologies for the circling). \nThoughts?\n. On a side note, with that taken care of, this feature branch looks good to merge.\n. Hi,\nI've tried replicating this error on Dashku's staging server, but it didn't occur.\nHas anyone else encountered this issue?\n. No, Linode.\nDo we have this error occurring on another SocketStream app hosted on\nNodejitsu?\nIt would be good to determine if it is a hosting-specific issue or an\napplication-specific issue.\nOn 13 February 2014 10:20, Wylie Joshua.Cullick notifications@github.comwrote:\n\nDashku is on AWS right?\nOn Thu, Feb 13, 2014 at 11:38 AM, Paul Jensen notifications@github.comwrote:\n\nHi,\nI've tried replicating this error on Dashku's staging server, but it\ndidn't occur.\nHas anyone else encountered this issue?\n\nReply to this email directly or view it on GitHub<\nhttps://github.com/socketstream/socketstream/pull/430#issuecomment-34961990>\n.\n\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-34965186\n.\n\n\nPaul Jensen\n07914 171 345\n. Hi Wylie, thanks for the update. What are the Heroku issues?\n. Hi Wylie, \nAre you using Heroku's websocket support?\nPreviously, we had to use long-polling to handle working with heroku, as Heroku does not support sticky-sessions. See this link: https://coderwall.com/p/h2swda\n. Hi Roman,\nOk. Just for your info, 0.1 and 0.2 are old, deprecated versions of\nSocketStream, as 0.3 was a rewrite of 0.2, and introduced breaking changes.\nOn 5 February 2014 16:02, RomanMinkin notifications@github.com wrote:\n\nHi Paul,\nIf you do not mind I'm going to convert old as mammoths 0.1, 0.2 branches\ninto 0.1.0 and 0.2.0 tags.\nSo the actual branches space would be clear from versions. And all the\nversions will be in their place.\np.s. I actually ready all I need to make a push =)\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/431\n.\n\n\nPaul Jensen\n07914 171 345\n. Cross-linking this comment https://github.com/socketstream/socketstream/pull/430#issuecomment-34961990\n. Hi @kulicuu,\nCould you let me know if you're still experiencing this issue?\nThanks.\n. Cool, I think I'll keep this open to investigate the cause of the Nodejitsu issue at a later time.\n. Hi @kulicuu,\nThanks for your info. Are you using any logging modules in your app, or making any specific calls relating to logging?\nI've tested the master version of SS against Dashku with no issues reported. I will test this against VMUX as well to see if this is happening elsewhere.\n. Ok, I'm going to be judge, jury, and executioner on this one.\n. I can recommend using Nginx to handle HTTPS traffic, and that's how Dashku\nhandles it.\nI've used Forever before in the past, but these days I use upstart scripts\n- they are setup to boot services in case your machine is rebooted.\nOn 17 February 2014 18:38, Wylie Joshua.Cullick notifications@github.comwrote:\n\nOff-topic :: but on subject of SS deploys to Linode :: Thoughts on custom\nNginx front vs something like Forever/-> PM2 or even Phusion Passenger ?\nI'm halfway in between the latter two : PM2 handling pretty raw SS (https\nimplemented in the app file) but also testing out Phusion, which is\ninteresting.\nOn Mon, Feb 17, 2014 at 8:34 PM, Paul Jensen notifications@github.comwrote:\n\nMerged #434 https://github.com/socketstream/socketstream/pull/434.\n\nReply to this email directly or view it on GitHub<\nhttps://github.com/socketstream/socketstream/pull/434>\n.\n\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/434#issuecomment-35311162\n.\n\n\nPaul Jensen\n07914 171 345\n. Hi,\nI've recently had to update engine.io as part of chassis.io (an engine.io wrapper library), but I haven't got round to sorting it out in SocketStream (yet). I welcome any efforts to help out with this.\nWRT the client change, https://github.com/socketstream/socketstream/pull/360 may be of interest.\n. Thanks @kulicuu, I appreciate the help.\n. Hi,\nIt's on my radar. I've been through the list of dependencies that SocketStream has, and upgrading them 1-by-1 (after what was a long time where nothing was updated).\nI'm currently getting the UglifyJS dependency up-to-date, but then engine.io, along with connect and connect-redis are next in line.\nI'm sorry that it's been sidelined for so long, admittedly I had a difficult time trying to manage my work/life balance for the 1st half of the year, and it took it's toll, including on looking after this. \n. Thanks @kulicuu, absolutely fine to document notes in the thread.\n. Hi,\nThanks for your contribution, I'll have a look at 5pm today (sorry for the delay, I'm in a rush to hand off items before I go on holiday next week).\nRegards,\nPaul Jensen\n. Thanks for this.\n. @Waxolunist I know the feeling (minus babies), congratulations.\nI'm currently on holiday in Australia until Friday, I will catchup on this over the weekend.\n. Hi @Waxolunist,\nSorry about the lengthy delay on getting back to this - I had a great holiday, followed by a very busy few weeks following (in fact I had to work towards the end of my holiday).\nThe points you raised are very valid - the client-side pipeline workflow is nice, but it's opinionated approach makes it difficult to work with package managers like bower and component.io.\nI've recently used Gulp at work for a desktop application, and I think that it is a brilliant tool for client-side development - I think that there is potential for it to be a client-side replacement to SocketStream's client-side part.\nIn order to do that though, we need to take a good look at the framework, and begin the work of getting to the vision of 0.4, by way of refactoring 0.3.\nI want to make it possible for SocketStream to be used in a more modular fashion - such as being able to make use of the RPC/PubSub features without requiring the client-side part, as well as being able to build the client-side assets without having to boot the whole app.\nThese are things I'm going to be looking at this week.\n. I agree that SocketStream needs an updated mission statement. I want SocketStream to be the best framework for creating Realtime Web Apps - it's a lofty ambition, but a worthy one.\nThe focus of the past 18 months has been to listen to the community and to stabilise the project. I think that goal isn't yet complete, but is close. There are libraries to upgrade, tests to write, documentation to add, and a general need to grow the community to support those steps. There is no way that 1 person can do this by themselves, as I have found out the hard way this year.\nEventually, I would like to get to the goals of 0.4 by way of refactoring 0.3, once tests and documentation are in place. I don't know how long it will take, but my company (Anephenix) is going to commercially sponsor work on SocketStream to get this done. I'm currently working for a major client in London, so my time is extremely limited.\nI still have a lot of passion for SocketStream, and I want to see it succeed, in fact it's one of the reasons why Anephenix exists.\nWith regards to r.js, I do find that I prefer Browserify's approach - RequireJS' approach at times feels rather weird. That said, the asset pipeline of SocketStream has room for improvement. There is a need to make it handle unknown file formats better (as was the case with .map files), and to make it work better with bower components/ client-side node_modules.\n. Thanks for the PR @mmalecki.\nIn my opinion, it would make sense to put it in test/unit/http/index.test.js, but if you have an alternative file path, I'm open to hearing it.\n. I've used this library in the past to mock apis for a set of tests within a file https://github.com/felixge/node-gently\nUsing this with a combination of before/after hooks in Mocha will allow us to mock the cookie parser middleware, and then set it back to normal after the test has run.\nThat said, we could put the tests in a separate file for now, and at a later time move them into the index.test.js file using Mocha's hooks and Node Gently (if required).\n. Having tried (and failed) to mock it out in index.test.js, I'm going to try and put it in a separate test file. Sorry this has taken longer than intended.\n. I've forked a branch containing tests, they are a work in progress.\nhttps://github.com/socketstream/socketstream/tree/mmalecki-cookie-secret-tests\nTrying to isolate the call to connect's cookieParser middleware with Gently isn't working. I want to get it passing.\n. No worries Maciej, I'll find a way.\nOn a side note, if you have some thoughts regarding the pain points you encountered with working with SocketStream, I'd be happy to take a look into it.\n. I wrestled with getting tests to intercept the cookie parser secret, but didn't crack it. I will do eventually, but in light of things I felt it would be better to get this feature in now than to delay it any further. Thanks for the commit.\n. Yep, it doesn't. I had to use Fedor Indutny's sticky module to be able to\ndo this (with a clustered express app) - https://github.com/indutny/sticky\nOn 2 April 2014 15:46, Wylie Joshua.Cullick notifications@github.comwrote:\n\nMaybe it's because NodeJS cluster module no do sticky sessions.\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/441#issuecomment-39338970\n.\n\n\nPaul Jensen\n07914 171 345\n. Apologies, this is the link to the repo\nhttps://github.com/indutny/sticky-session\nOn 2 April 2014 15:58, Paul Jensen paulbjensen@gmail.com wrote:\n\nYep, it doesn't. I had to use Fedor Indutny's sticky module to be able to\ndo this (with a clustered express app) - https://github.com/indutny/sticky\nOn 2 April 2014 15:46, Wylie Joshua.Cullick notifications@github.comwrote:\n\nMaybe it's because NodeJS cluster module no do sticky sessions.\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/441#issuecomment-39338970\n.\n\n\nPaul Jensen\n07914 171 345\n\n\nPaul Jensen\n07914 171 345\n. You could try it on a staging box, fire up a linode, try it, see if it works. If it does, use that and power down the Linode (they now offer a metered billing option too).\n. I've heard of JSON web tokens before, I'm definitely keen to explore using them as an alternative to sticky sessions for hosting app instances across multiple servers.\n. At the moment, the reason to use sticky-sessions is because of the way that engine.io stores state when handling the handshake for establishing a connection - if there was a way to share that state across multiple Node processes, then sticky-sessions could be ditched.\nI think that cookies will eventually become irrelevant - the DoNotTrack feature that was proposed in IE and Firefox is a signal of what's to come, as well as the fact that Google and Facebook have already started tracking users via other methods.\nI see JSON web tokens as offering a way to authenticate requests, regardless of whether the client is a web browser, or a server-side process. I think that unifying this could offer exciting possibilities:\n- We could write an API for authenticating requests once, and have it used by both the server-side REPL, a REST API for 3rd-party clients, and an RPC API for client-side consumption.\n- We don't have to do any form of sticky-sessions in front of the app instances - scaling is simply a matter of round-robin load balancing in front of multiple servers.\n. This blog post has a brilliant answer to your question regarding the benefits of using tokens compared to cookies for authentication: https://auth0.com/blog/2014/01/07/angularjs-authentication-with-cookies-vs-token/\n. Hi, is this still an issue or has it been solved?\n. Cool. We can add a ss-socket.io transport wrapper library module once 1.0.0-pre2 is released.\n. To add context, the first version of SocketStream used Socket.io as the Websocket transport library. Over time, a drop-in replacement using SockJS was also added, which was a superb library (and was used in Dashku at the time), as there were some problems with using Socket.io as the transport library. There was even an experimental Pusher wrapper, but that didn't go anywhere.\nDue to supporting Dashku's use at Bechtel, I took up the task of trying to ensure that a disconnected WebSocket connection would be re-established from the client (i.e. losing mobile signal results in a severed connection), and my research at the time pointed to Engine.io, which was Socket.io's WebSocket connection library and nothing else. I ended up creating ss-engine.io as a result, and managed to get the library to replace Socket.io in SocketStream as the default WebSocket transport library.\nIn terms of the roadmap for Engine.io and Socket.io, the idea is that Engine.io will eventually find it's way back in Socket.io 1.0. I'm glad that Guillermo is close to achieving that goal.\n. @arxpoetica Is there an action to follow from this issue? I'm tempted to close it for now, and when someone makes a wrapper for 1.0, then we can take of it there.\n. There's a way in Socket.io/Engine.io to detect the Websocket 'close' event, and this is triggered when:\n- a user closes their browser tab/window on the desktop\n- a user closes the web browser application (Safari) on iOS\n- ~ 30 seconds after a user locks their iOS device\nIs there a way to expose this event in SocketStream's websocket transport library? Good question, I'll check now. If it is, great, otherwise if not, then I think it's something that SocketStream should not obscure access to, so it would be added via PR.\nI'll check now.\n. If you have a stacktrace, I'd be happy to take a look, my email is paul@socketstream.com\nI found a line in ss-engine.io which refers to the socket 'close' event:\nhttps://github.com/socketstream/ss-engine.io/blob/master/lib/index.js#L147\nAt the moment, it removes the socket from the list of sockets that are open. If we can expose access to the socket object from SS, then we can bind another function on that event as well.\n. Hi @kulicuu,\nI noticed that you mentioned a controller called globalState. Does this state need to handled at an application instance level, or across all application instances?\n. Hi @kulicuu,\nI'm using the sticky-session with a work app in production, but not Dashku, so it's use with SocketStream is fairly new territory.\nI learned last year that booting a Node HTTP server takes ~50ms, A connect one ~120ms - this compelled me to take a look at ways in which the bootstrapping process of apps could be slowed down, and ways in which to optimise the process. Unfortunately all of that knowledge wasn't written, and I've had so much to take care of in the last 5 months that I can't remember it.\nI'll take a look into running Dashku with sticky-session to see if I can spot any gotchas.\n. Hi @pygy, I've updated the readme here: https://github.com/socketstream/socketstream/commit/713d3d1bff2f1399412b281ae3ca69281307a3f7\n. Please see https://github.com/socketstream/ss-home/pull/1\n. Yep, in fact I ought to overhaul the entire readme - it needs a lot of updating.\n. Hi,\nI managed to do this in Dashku, the code is here: https://github.com/anephenix/dashku\nThe answer lies in using either a) Express with SocketStream or b) Connect-router middleware with SocketStream.\nIf you have a look at this file: https://github.com/anephenix/dashku/blob/master/app.js\nOn Line 7 I require the connect-route npm module,\nOn Line 24 I requre Dashku's REST API\nOn Line 30 I prepend the connect middleware loading the API\nNow let's have a look at the api file, here: https://github.com/anephenix/dashku/blob/master/server/api.js\nLine 164 is of interest, here I provide a route that let's you download files (for sending data to widgets).\nNow let's look at the scriptDownloader file here: https://github.com/anephenix/dashku/blob/master/server/scriptDownloader.js\nLine 52 shows us a function that is used for downloading a file containing custom values.\nLines 56-58 are the ones that you will be interested in, here: https://github.com/anephenix/dashku/blob/master/server/scriptDownloader.js#L56-L58\nThey provides the headers needed to tell the browser to download the file.\nI might be wrong, but I think that when calling ss.http.route, you might be able to just use the lines shown on L56-L58 in scriptDownloader.js within that route, and it would give you what you're after.\nLet me know if that helps, or if you need any other help. Paul\n. @EricCat You're welcome, I'm glad to help.\n. Hi @EricCat,\nHave you tried using this in place of res.download?\nres.get(path, function (req, res) {\n    var data = \"data to download\";\n    res.writeHead(200, { 'Content-disposition': 'attachment', 'Content-Type': 'text/plain' });\nres.end(data);\n};\n. Hi @EricCat,\nWhere does the file containing that bit of code exist?\nIf it's in /server/rpc, then it won't work. It will need to be loaded as a connect middleware from the main app.js file. \n. Thanks @EricCat,\nI think that the reason it's not working is because you can't load connect routes from files inside of the rpc folder.\nCould you try and put the req.get part of the code in the app.js file, so that the app.js file has this bit of code in it:\nss.http.middleware.append(connectRoute(function(router){\n    router.get('/', passport.authenticate('basic', {session: true}));\n    router.get('/myFile, function (req, res) {\n        var data = \"data to download\";\n        res.writeHead(200, { 'Content-disposition': 'attachment', 'Content-Type': 'text/plain' });\n        res.end(data);        \n    });\n}));\n. Hi @kulicuu,\nIdeally it would be good to get them all linted under strict mode, but I think I'll need to revisit that file. Apologies for being inactive of recent.\nI think it would be good to rework the code to get this to pass.\n. Closed. Thanks @kulicuu, I'm sorry that it took as long as it did to merge. I've been busy of recent; changed job and moved house within the last month, and moving again next week. \n. Hi @kulicuu,\nThanks for the work. I'm open to considering using connect-redis by default (though it would require anyone trying SocketStream to have Redis installed and running).\nAs for the other modules, I say we can try them all, and see which ones work the best.\n. I think that's a fair point - the default memory store isn't a scalable option, but it does allow people to get started quickly without having to install and start Redis.\n. I had a longer think about it. In truth there is a case for both; in one case you're optimising for someone new to SocketStream, and in the other case, you're optimising for someone who is going to put a SocketStream app into production.\nIn the former's case, you're giving them 2 less steps to jump through (not having to have Redis installed, and to not have it running before you run an app).\nIn the latter's case, you're taking away those steps, on the basis that they will want to use Redis. It does provide a key requirement to scaling the app to run across multiple instances (as well as to withstand instances being restarted).\nIt ultimately comes down to 2 things: What should be part of SocketStream's core, and what should not? and a 2nd thing: how does that technology choice impact the user? \nThe question of what should be part of SocketStream's core is a pertinent one. We've learnt that having the framework written in CoffeeScript was a choice that alienated some from both using and/or contributing to the project. Personally I loved CoffeeScript, but not everyone feels the same.\nSo Redis being part of SocketStream's core. True, you'll want to use it when you put a SocketStream app into production, as you would if you put an Express app into production. But Express does not mandate that you install Redis in order to run connect. Instead, there is the connect-redis node module for that, along with alternatives that use Mongo or CouchDB instead of Redis for session storage.\nAnd that's the thing; Redis is a personal choice. Again I use it for work and it's been fine in my uses cases, but I can't guarantee that everyone who uses SocketStream will be the same.\nI feel your frustration @kulicuu - I was in a similar position of having to reduce work on Open Source when I was managing multiple projects at my previous job during the peak time of the year. I'll be happy to talk more offline.\nI will close the issue.\n. I think @owenb wrote that comment. I think that the idea was to use events to trigger multiple actions.\n. @owenb would be the best person to ask regarding the intent around the comment, I can only infer its meaning.\n. This feels like something to consider for 0.4\n. Hi @klausb, thanks for filing the issue.\nI've seen an option in SockJS to enable the use of JSESSIONID for load-balancing purposes, and there is a transport wrapper for it with SocketStream: https://github.com/socketstream/ss-sockjs, the only thing is that I think the reconnection logic is not yet in it, but it might be worth trying.\nI'll look into updating the ss-sockjs library with the reconnection logic I put into ss-engine.io and SocketStream last year.\n. Not yet sadly, but I think it should be a consideration for 0.4\n. I'll try and get a look into it tonight. Thanks for your work, I'm sorry I\nhaven't been as active recently.\nRegards,\nPaul Jensen\nOn 3 March 2015 at 17:50, Henrik Vendelbo notifications@github.com wrote:\n\n@paulbjensen https://github.com/paulbjensen Could you have a look at\nthe next branch and see how you like the option to use relative\ndependencies in client defs.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/455#issuecomment-76996748\n.\n\n\nPaul Jensen\n07914 171 345\n. Hi @thepian,\nI'll look into it.\n. Hi @thepian,\nI'd be happy to accept a PR with those changes.\n. Hi @thepian,\nI've been looking at another ticket about separating out JS and CSS tags in the generated html, for the reasons you suggested. The GH issue is here: https://github.com/socketstream/socketstream/pull/355\nI will probably need to close that PR and extract it out into a new PR due to the number of changes since the PR was originally filed.\n. Hi Ian,\nI like the site background, but I take your point on board. I would be open to a pull request - I can describe how to generate the docs and tinker with the CSS if you like.\n. Cool, there's a section on documentation generation here: https://github.com/socketstream/socketstream/blob/master/CONTRIBUTING.md#documentation-generation\nThe docs/css/main.css contains the relevant css to modify. When you're happy, submit a PR and I'll take a look and merge. Thanks.\n. Closing as merged\n. Thanks @polpo, I've merged that in and will update the docs in a minute.\n. I changed the CSS stylesheet to be more readable for those who have red-green color-blindness.\n. Thanks @thepian, I'll take a look at it later on today.\n. Thanks for this.\n. Hi @thepian, that's correct, Owen embedded a portion of the code from Browserify to support how SocketStream handles client-side dependency management.\nIt would definitely be nice to abstract that portion of the code out, making SocketStream more modular and therefore easier to maintain. The plugin option would help work towards some of the goals that Owen had for 0.4, but I'm happy to consider the alternative as well - we're currently using a very old version of Browserify in SocketStream, it's due an upgrade.\n. Henrik is right, the way that SocketStream handles compiling and serving assets is deeply ingrained in the framework, and changing it is a big job.\nHenrik's solution is a good way to achieve it, as it moves closer to the vision of making SocketStream mode modular.\n. I'm not sure if this should be a 0.3.12 or 0.4 concern, any thoughts?\n. I did consider this idea, about a year ago when I was toying with a new framework concept (outside of SocketStream). It turns out that you can close/open HTTP servers in Node quite easily, and this would allow some kind of auto-reloading based on server code updating.\nAt the moment, the closest available solution is to use nodemon with SocketStream.\n. Hi @louh,\nHow are you specifying these routes server-side (with Express)?\nIf I understand correctly, you need the SocketStream app to allow some routes to serve JSON, instead of   the SocketStream app?\n. Hi @louh,\nI embedded a REST API into Dashku by using the connect-route node module, using ss.http.middleware.prepend as demonstrated on this line: https://github.com/Anephenix/dashku/blob/master/app.js#L31\nWhich then loads this: https://github.com/Anephenix/dashku/blob/master/server/api.js#L60\nHere is a link to the node module: https://github.com/baryshev/connect-route\nAs for the ability to get Davis.js to ignore the path, there is a way: https://github.com/olivernn/davis.js/issues/30\n. Hi @louh,\nWere my suggestions what you were after?\n. No worries, glad to hear it worked.\n. Hi @louh, is it ok for me to mark the issue as resolved?\n. Thanks for your input so far, some good suggestions and I'd like to get some of these turned into concrete features for SocketStream.\nI've seen some projects use Trello for this sort of thing, so I've taken @arxpoetica's suggestion and created a Trello board here: https://trello.com/b/3ufvApqM/socketstream. I'll invite all of you to the board tomorrow morning.\nI'll add more tomorrow, but I need to sleep now.\n. I've made invites. Feel free to put features in there, then we can arrange them in order of most desired features first.\nAt work so will provide more thoughts later.\n. Thanks for organising the trello board, and for taking the ideas put forward here and putting them into the board.\nWhen Owen demoed Prism back at RealtimeConf EU last year, he eventually saw Arnout Kazemier's Primus, and concluded that it could be better to switch to using that instead.\nOriginally when I took over the lead developer role, my plan was to advance both 0.4 and maintain 0.3. I eventually gave up on doing that for these reasons:\n- Users did not like the fact that the reset button kept being pushed on the framework, with features that had existed in previous versions of the framework being removed.\n- People were in limbo between waiting for 0.4 to arrive or continuing to work with (earmarked for deprecation) 0.3. Some people with 0.3 apps in production also felt a bit concerned that they were building on top of abandonware.\n- To build 0.4 at the same time as maintaining 0.3 would have required more time than I alone could provide. This has been the most difficult lesson I've learnt in managing the project.\nI therefore chose to focus on working on 0.3, and get to the goals of 0.4 by way of refactoring 0.3.\nBut, playing devil's advocate, if there was a period of 6 months dedicated to a complete rewrite of SocketStream; one where everything was tested properly, where existing features were complete, where the framework was more modular in design, and where updating 0.3 apps to 0.4 involved minimal pain, would that be something that the team would be interested in considering?\n. @arxpoetica yep, that's sorted now.\nThanks for all of the discussion. I think that a team-based approach will work, and hopefully will speed up the project progress by eliminating a dependency on a single person (me) to do things. I'll add you all to the core team, and that will allow you to make commits/changes among other things. Next after that will be making the website available to all to modify.\n. Added the ss-home repo as well (which contains the site). I'll need ssh public keys from you chaps to add to the server which serves socketstream.com.\n. @kulicuu @arxpoetica Thanks, will install them at some point today.\n. WebRTC is very cool for P2P data transfer and transmission. Say you were building a game, I could see a case for building a plugin to support a multiplayer feature for a game, where sending data between the 2 players would be better than sending it through a central server.\nI would resist adding a technology without having a real business need behind it. Find the need first, then that will help shape how to build that plugin.\n. Apologies for the delay in replying. I can do weekends.\n. Ok, I can do January 3rd/4th if that works for others.\n. Would 1100 UTC work for everyone? \n. Seems cool, speak tomorrow.\n. You can add ?video=off to the url in order to disable video (screen sharing will still work).\n. http://appear.in/socketstream\n. Have you chaps been able to join?\n. Try again.\n. Ok, we're going to try a google hangout, will send invites via email\n. @thepian Sorry you didn't get to be on the call, next time. As for your requests, the 1st wish is intended, but not easy to do (SS uses a modified early copy of Browserify, so this is going to be a bit tricky), and as for the 2nd wish, there is a plan to upgrade connect, which should allow using express 4 to happen.\n. Hi @thepian, so I understand it better, is it that you can't access the SocketStream view for /switzerland, because you have a route defined for /switzerland/as-pdf.html?\n. Ok, I'll try and replicate it with a test app, and see what's going on.\n. Thanks, can't believe I mistyped 'synonymous' (though I put it down to a keyboard error ;) )\n. @thepian Sorry I didn't respond earlier, I'm currently in Reykjavik on holiday. Thanks for the PR and doing the merge, it's so much better than waiting on me. \n. I'm going to mark 0.3.11 as finished (as it technically shipped), and put this into the next minor (0.3.12)\n. Hi, Thanks for filing the issue. I'll take a look into it.\n. Hi @greenpdx,\nI had a look at the issue that you mentioned. I haven't been able to replicate the error that you encountered.\nCan I check the following? \n- That you generated a new SocketStream app with default settings\n- What version of Node.js you are using (I am using 0.10.35)\n- That the server/middleware/example.js file exists, and returns a function.\n- That you uncommented line 10 in server/rpc/demo.js\nRegards,\nPaul Jensen\n. Hi, thanks for identifying more info about why it occurred. Does the issue still happen when running node-debug?\n. I checked it with node debug app.js, it's working. Marking as closed.\n. Thanks, done\n. I think this would be worth separating out for 0.4, so that SocketStream's codebase becomes a bit more manageable.\n. Thanks, I'll look into it.\n. Agreed.\n. That looks like a line that is inspecting the version of Node.js to see if it is version 0.6.\nThe line can be simplified to require('fs'), and rename the variable to 'fs'.\n. Cool, will close this, and wait to get it in when the PR is merged. \n. Hi Henrik,\nYep, it was a result of converting the code over from CoffeeScript, hence there is room to optimise the codebase.\n. Done, created.\n. I'd suggest \"next\" in honour of Steve Jobs.\nOn 3 February 2015 at 16:59, Henrik Vendelbo notifications@github.com\nwrote:\n\nThanks. How about the idea of having a separate branch used for the next\nmajor release? I'm not sure what name to suggest\n- future\n- major\n- next\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/483#issuecomment-72688723\n.\n\n\nPaul Jensen\n07914 171 345\n. yep, let's do this.\n. I'll try and take a look into this tonight.\n. I merged a PR from @lafras-h about 1-2 weeks ago, which I tested manually and it works but I don't think it added any automated tests.\nThis can be marked as closed, and as for automated tests, I can take a look into it.\n. If you want routing, it's possible to deliver it as connect middleware, and not require express at all. Originally it was in connect's core, but then pulled out, and then someone turned it into a middleware you loads via npm. That's how I got Dashku to work alongside loading a REST API as well.\nI think maybe some documentation around how to do this would be useful.\nShould we look to support other options? Perhaps. In my experimentation with the core http server about a year ago, I stumbled across a more efficient level of support for routing than using connect. It was a project named 'vorka', I'd be happy to pull it up and have a look at it.\n. I didn't put it on Github, I'll dig it out from my disk backup and post it.\n. Thanks Henrik, I'll try and test them tonight (I know I said that 2 nights ago on another issue, sorry, it's been a busy few days).\n. @thepian hi Henrik, yes, it makes things simpler.\n. I'll have a look tonight.\n. In my experience with git submodules (a commercial project with Vodafone), they're a world of pain, because they complicate how you manage the code. You have to synchronise multiple git repos, and ensure that changes in git submodule folders do not end up getting tracked and pulled in by the local main repo. I would recommend avoiding them.\nIn my experience with e2e testing, I've resorted to using Cucumber and a combination of selenium-launcher and soda to test web apps end to end. As for a web framework, the framework was never originally tested, and so the question of how to do e2e testing on it will need some thinking.\n. Agreed. I think the challenge here is to get the ss variable to be passed and loaded into the various other places where console.log is being called. It will require some internal rewiring in order to achieve that. \n. This sounds like a good change. Please proceed.\n. Hi, Thanks for the PR. If you could make the changes as suggested by Codacy, then I'll take a look and merge it in. Thanks. \n. Hi, \nIs the delayTime attribute meant to delay executing the next reload? I tried this code snippet in my app, but it didn't seem to slow down when reloads were executed:\nss.client.set({\n    onChange: { \n        delayTime:5000,\n        guardTime:8000,\n        validate: function (path, event,action) {\n            console.log('onChangeValidate :', path);\n            return true;\n        },\n        publish:function (path, event,action,pubs) { \n            console.log('onChange.Publish :', action);\n            //modify pubs if needed return null to not send any pubs\n            return pubs;\n        }\n    }\n});\n. My apologies, I forgot to link the test app to the cloned version of SocketStream containing your feature branch. It works, thank you.\nI'm happy to merge it in now, and will add an item to the documentation to describe how to use the feature.\nThanks for your work.\n. @thepian that's fine, please go ahead.\n. It's a Code Coverage service which monitors code coverage % on your repos. If you integrate it with your Github repo then it will check commits and post the results to the comments section in the PR. \n. Cool - please go ahead.\n. At the start of the project and to this day SocketStream followed a pattern of 0. being major updates (i.e. Owen rewriting it and making big changes), which goes against the convention of .0 being major updates.\nIf we want to switch to .0, then we need to look at what would be a major update to SocketStream, as well as when we'd want to classify SocketStream as stable. During the time I've been looking after the project, I chose to focus on making the 0.3 branch stable rather than rewrite the framework as Owen planned to with SocketStream-0.4.\nI think that with some of the new features that have been added, 0.4 should be the next stage of minor updates, and 1.0 should be when the project is considered stable.\nStable in my opinion would be the following:\n- Good code coverage\n- Good documentation\n- 0 bug issues on GH (just feature requests and queries)\nTutorials and example apps would be nice, but are not a deal-breaker.\nWe would also need to communicate this change to the community, as they've been used to the existing pattern of updates.\nOn a side note, I just want to express my thanks to all of you for your recent work with SocketStream, I appreciate it.\n. Try ss.api.db instead of ss.db when trying to access the api from the server/rpc/example.js file, which is basically what @kulicuu recommended (sorry I haven't had coffee yet).\n. The docs are generated by a grunt task, and pushed up to the gh-pages branch on Github.\nThe reason that the docs were put with the code is because they generate documentation from the code comments. Here is an example: http://socketstream.github.io/socketstream/docs/#/api/http.index:index\n. @thepian I'll take a look now\n. Yeah, I think that there was a plan to change that line as Node 0.6 is beyond what we'd look to support today.\nThanks for spotting it. I'll see if we can change it quickly.\n. @thepian yes, absolutely fine with me. WRT publishing to npm, what is your handle on npm - so I can add you as an author to be able to do publishing.\n. Thanks, I've added you to the npm so you can publish updates.\n. Thanks @arxpoetica. Yeah markdown is still a great way to do docs.\nLooking at the thread, I agree with @thepian that getting articles on SocketStream would have a big impact on growing the community. I'd like to assist but time is of short supply for the next 2 months at least (finishing client work and writing book).\nId also like to get the SocketStream Twitter account in more hands - I looked at Buffer to manage this but was wondering if there are any other tools that can do the same thing (teams accessing social media accounts), I also looked at Hootsuite. If anyone sees anything then please let me know.\n. I'm ok with either approach. If we want to use 1 var per line, we'll need to modify the value of \"onevar\" in the .jshintrc file to false.\n. I had an idea this morning of moving the code in the lib/cli folder into its own npm module. This would allow us to reuse the logic in a Yeoman generator, as well as reduce the amount of code that SocketStream contains (new_project could move into the ss-generator npm). The idea would then be to have this ss-generator npm be included in socketstream and support it's cli commands, but the files and logic is within the npm module.\nI extracted the lib/cli folder, new_project and its tests into a separate folder, and it's gone fine so far (it's quite nicely isolated from the rest of the codebase).\nI can push up a copy to github if it seems like a good way to go forward?\n. Here is the repo: https://github.com/socketstream/ss-generator.\nOnce I've resolved all the issues, I'll create a feature branch of SocketStream where ss-generator is used in place of the lib/cli code.\n. They should - there's some code that needs reorganising and the new_project folder is a good case. Since ss-generator has it's own copy we don't need it for that, but there are some tests which depend on it. What we can do is make another commit to revert the accidental file deletion, as well as remove the new_project folder, and change existing tests to use it in the test/fixtures folder. \n. The PR has some fix commits in that are a bit messy. I'll close the PR and make a new one following the suggested branch procedure.\n. It's possible that this could be moved out, in fact SocketStream originally had socket.io as the bundled library, which could be swapped out with engine.io via ss-engine.io or sockjs with ss-sockjs.\nss-engine.io hasn't been updated in a while, but could be updated and thus the code for web sockets is loaded that way, rather than being inside the core of SocketStream.\n. @thepian Any idea why the client.formatters.test file is failing? https://travis-ci.org/socketstream/socketstream/jobs/61007693. I do see this happen intermittently when running the tests on my laptop (1 in every 4/5 test runs).\n. Ah, sorry, was meant to be in next\n. Closed this and opened a new one for merging into \"next\" here #536.\nI managed to replicate the error again on my machine but on test/unit/client/index.test.js#L138. It looks like the client.packAssets and client.load function calls are synchronous, but the files might still be in the process of being generated, and so the attempts to read the packed asset files fail.\nThe quick workaround is to put some fs.exists calls in the code and to wait until all files exist, but I think that the better approach would be to make asset packing support a callback when it has finished generating the files. I'll have a look at the code and see if this is feasible. Let me know your thoughts.\n. This seems to be failing on a test that is unrelated to the CLI:\n1) code formatter loading API #call should support alternate extensions:\n      AssertionError: expected '// couldn\\'t format ./abc/index.a issue=1431377849247' to be 'require.define(\"/abc/index\",function(e,t,n,r,i){window.a=\"formatter index.a\"})'\n      + expected - actual\n      +require.define(\"/abc/index\",function(e,t,n,r,i){window.a=\"formatter index.a\"})\n      -// couldn't format ./abc/index.a issue=1431377849247\nIs this fixed in master? If so, we can pull in those commits and try again.\n. Hi Henrik, it seems to happen when running Travis CI. I can also sometimes get failing tests on the master branch when I run the tests ~ 4/5 times - 1 test run eventually fails.\n. This is a bug, we'll fix it shortly.\nOn 8 May 2015 at 09:36, Ilya Dorman notifications@github.com wrote:\n\nWhen doing socketstream new  I get a 0.3.12 app and the SS in\npackage.json is also 0.3.12. Why not 0.4.2?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/538.\n\n\nPaul Jensen\n07914 171 345\n. It is - https://github.com/socketstream/socketstream/blob/master/lib/cli/generate.js#L183\nWe can change that so it reads it from the package.json file.\n. Hi @arxpoetica, I'm afraid not, but the good news is that I'll be in a very good position to take a look next week; I finish with the client next week, so that leaves only the book plus getting ready to move to Amsterdam on my todo list, meaning plenty of time for other items.\n. When trying this branch with Dashku's integration tests, Dashku is able to boot up, but we've now noticed that the ss.tmpl objects all begin with 'templates-' at the front, was this a deliberate change?\n. Yep, I'll take a look. I'll also provide a few more details relating to the behaviour I saw in Dashku.\n. I think I know what is happening now, some explanation.\nIf you checkout a copy of Dashku from here: https://github.com/dashku/dashku, then after running npm install, you run npm link to get Dashku to load a local copy of the Socketstream repo rather than the version specified in package.json, like so:\nnpm link PATH_TO_SOCKETSTREAM_REPO\nAfter doing that, once you've got mongodb and redis running, run npm start, and visit localhost:3000. You should see something like this:\n\nIf you open your inspector, on the console panel you'll see this:\n\nIf you run ss.tmpl in the inspector console panel, you should see this:\n\nAll of the Hogan.js templates in ss.tmpl begin with 'templates-' at the front of them. All of those Hogan.js template files live in the client/templates folder. I think that this might be linked. \n. Fantastic, thanks @thepian.\n. run npm test on the command line.\n. Once I get my chapter submitted and another book meeting done, this item is next on my todo list.\n. Hi @hulmgulm, thanks for the detailed bug info. What version of SS are you using?\nSocketStream is meant to allow both HTTP and WS to access the same cookie, so this sounds like a bug, possibly linked to the engine.io upgrade but that is more of a hunch than anything. I will take a look when I get the chance; I'm finishing work at my client this week, so I will have plenty of time to sink my teeth into the project.\n. Are there parts of SocketStream's code where this should be used? It would be good to see an example of how using Immutable.js would improve it.\n. @kulicuu ok to close the issue?\n. Pressed wrong button.\n. I've tracked this by running npm run cover-test, and these results vary:\n\nand this\n\nYou can see that the lib/client and lib/client/bundler's coverage stats change between runs, so I will look into the code and tests and see why they're varying.\n. Not always - I've just been running npm run cover-test a couple of times, current coverage results reports 76.77%, but on one case where everything passed, it returned 76.83%. I'll isolate where the variance is occurring.\n. The tests are passing, the errors are to do with getting Coveralls to receive the coverage stats. Some errors are 500 (a server error on their end), and some look to be an invalid repo token being passed automatically by Travis in the background to coveralls.\nGoing to merge this in.\n. I'll ask their support channel.\n. Thanks for spotting the issue and putting it on Github. Give me a couple of minutes and I'll fix it.\n. Hi, I've pushed a fix up (https://github.com/socketstream/ss-console/pull/8), and published it with ss-console 0.1.4 on NPM. I'll close it but if you have any further issues please reopen and let me know.\n. Yes, definitely, but also worth checking them with production apps as well before merging into master and publishing on npm.\n. It's to do with the use of * to select all directories on Windows. Windows does not like * for some reason.\n. Sorry, wrong issue.\n. I've been able to replicate the error on Windows. Will investigate and fix.\n. The way I've managed to fix this is by changing the app.js file on line 11 to this:\ntmpl: 'chat'\nUsing '' as a folder wildcard on Windows does not work. It we swap out '' with the name of the 1st and only folder (chat), then the app works.\nChanging this in the app generator would fix generating new apps with the demo app code, but not apps with a minimal install.\nI'll keep searching for a way to support folder wildcard on Windows.\n. Hi Christian,\nMy workaround for the SS chat app was to simply pass the folder/file name chat in, rather than use the * character to select everything.\nFor Dashku, try changing the tmpl: on line 37 in app.js to this:\ntmpl: ['account','app','dashboard','dashboardView','docs','homepage','widget','alert.jade','changePasswordModal.jade','inputFieldError.jade','loginModal.jade','signupModal.jade']\nIf this works on Windows, please let me know, or better, submit a Pull request to Dashku and I'll review and merge it in.\n. Thanks, merged it in.\n. @thepian Yes, that could work. I have a laptop with Windows on it so I can test it there.\n. A potential fix that could be done now would be to use the async library's 'series' function to chain a series of functions together without ending up in callback hell: https://github.com/caolan/async\n. You can use it today with your app and reduce the callback hell. I think also that adding support for promises is worth discussing.\n. @arxpoetica @thepian SocketStream basically uses connect middleware, and provides append/prepend as ways to insert other connect-middleware before the initial stack. That is how Dashku is able to append a REST API to the dashboard single page app.\nOn the old version of the website, there was an example in the tour that featured a way to load SocketStream and Express together. I can try and dig it out and make it more obvious for users.\nThe HTTP layer in SocketStream does need a closer look. The time when I experimented with alternative approaches to HTTP in https://github.com/anephenix/vorka 2 years ago I found that it was better to use a pure HTTP server over Express (3), and Express 4 has removed all of the connect middleware to be faster. If you do some rough benchmarking requests using a tool like siege, you'll see that Vorka does better than Express, and way much better than Hapi.\n. Hi,\nThe router code is smelly and does cause issues, especially when people want to return 404s for routes that are not matched, hence I think it needs a fresh look.\nThe reason why SocketStream was built on connect as opposed to Express was because it's focus at the time was on supporting Single Page Apps, and Express bundled a bunch of middleware by default that wasn't necessary to that goal.\nThe section I put about performance was more about being how bloated some web frameworks had become in 2013 - Express has recognised this and hence why the middleware stack is much thinner in v4 than in v3.\nHenrik's point is a good one - what is SocketStream's purpose? It does a lot of things, but trying to maintain a framework doing all of those things is a big job, and usually libraries come out which do the job a lot better, so maybe now is the time to re-assess that. It won't be an easy thing to do, as it will require a lot of time and thought.\nAnd that is the other thing - I hardly have the time to work on SocketStream, given the book for Manning publications and moving to another country. I think that if SocketStream is going to progress then it will need someone with more time than I have, therefore I'd like to find someone to take over leading the project.\n. @thepian SockJS has always been available as a plugin - the thing is the engine.io code is in the core repo, which was copy/pasted from the ss-engine.io npm module, and @kulicuu did some changes to it to make it use the latest engine.io release.\nThe reason for this PR was 2 things - firstly, to have 1 place where the engine.io implementation is maintained (rather than inside both socketstream and the ss-engine.io module), as well as to reduce the amount of code that exists inside of socketstream, so we can see how all the libraries connect with each other, and be in a better position to refactor the implementation to make it more modular.\nAt the moment I'm manually testing the implementation, and there is a JS client error in the version of ss-engine.io which I will need to debug, so we'll need to resolve that before we can merge this in.\n. I've dug a little into this so far (FYI I'm running on Mac OS X Mavericks and io.js 3.1.0)\nThe lib/client/index.js file is calling lib/client/http.js with a clients object, which stores the clients. At the time of initialisation, the clients object is empty.\nWhen we call the ss.client.define function in the app, the client is added to the clients object in lib/client/index.js, but http.js has the empty object that was passed into it. Basically we need a way to share the clients object state between both files without message passing. \n. This seems to be happening even on 0.4.3 (not just master branch).\n. Some further testing, it looks like an issue with iojs and not Node.js 0.12. Going to do some more testing to verify.\n. Will do in 2 hours' time (at work atm).\n. Sorry, totally lost track of this. Gimme 10 mins.\n. Latest version of master works, thanks. Will close.\nI realised that if the version of socketstream points to 0.4.3 but the repo is linked to master, it will cause errors, and if the generator points to master but app loads 0.4.3, then another error occurs.\nBasically, always check that the app generator and the module loaded by the app are the same.\n. Hi Robert, segfaults tend to occur if you install an npm module with compiled dependencies using one version of Node, then try to run it after switching to another version of Node. \nI'd like to suggest trying to re-install SocketStream on Node v4.0.0, and then seeing if you still get that error.\n. Hi Robert,\nI can confirm that Socketstream works on v4.0.0. \nI did the following:\nnvm install v4.0.0\nnpm install -g socketstream\nsocketstream new another-app\ncd another-app\nnpm install\nnpm start\nPlease confirm it works for yours well.\n. Interesting, what's your OS and version? (mine was Mac OS X Yosemite 10.10.5)\n. I'd suggest checking where the socketstream binary points to with which socketstream\n. Hi @aaroncalderon, apologies for the issue, it looks like we need to add an integration test that ensures that any app that is newly-generated by SocketStream can be installed and run without issues.\n. I'll take a look.. @yanzixiang can I check what version of SocketStream you were using? Thanks.. This might be the item in question:\nhttps://github.com/socketstream/socketstream-cookie-session\nhttps://www.npmjs.com/package/socketstream-cookie-session\nI will dig a bit further.. Looks good to me\n. I'm going to see if I can fix this first, before changing anything else.. I should add that this was run on an app running 0.3.. I'll note that 0.3 doesn't work on Node 6. As for 0.4.5, chokidar@1.1.0 is not installing on Node 6:\n```\nsocketstream socketstream new test-app\nmodule.js:471\n    throw err;\n    ^\nError: Cannot find module 'chokidar'\n    at Function.Module._resolveFilename (module.js:469:15)\n    at Function.Module._load (module.js:417:25)\n    at Module.require (module.js:497:17)\n    at require (internal/module.js:20:19)\n    at Object. (/Users/pauljensen/.nvm/versions/node/v6.9.1/lib/node_modules/socketstream/lib/tasks/live_reload.js:9:16)\n    at Module._compile (module.js:570:32)\n    at Object.Module._extensions..js (module.js:579:10)\n    at Module.load (module.js:487:32)\n    at tryModuleLoad (module.js:446:12)\n    at Function.Module._load (module.js:438:3)\n``` . Going to close - SocketStream 0.3 won't be supported on Node.js version 6. . Hi,\nI handed over the role of running the project to @thepian last September, as my year was going to be very hectic. In the past year I've just about finished writing a book for Manning publications about Cross Platform Desktop Applications, moved back to London from Amsterdam, helped support my girlfriend as she went through medical treatment this year, and done all of that alongside a full time job in a startup.\nThankfully the treatment is over and she is well, but it has been a really hard year, and I just wasn't prepared to try and squeeze SS in amidst all of that. I am slowly winding my way back into doing some OSS.\nWRT is the project dead? I think it's a fair question to ask based on commit activity - the framework still works (amazingly SocketStream works out of the box on Heroku as they now support WebSockets), but lack of recent activity shows that there is a challenge here - how to keep the project going if no activity happens.\nSimple answer is to generate some activity - make commits, fix bugs, write code, refactor code, write tutorials, answer Qs on Stack Overflow, you get the idea. Problem is how do you that alongside life in general? No one individual can do all of that alone, it's too much. You have to spread the workload, and you have to make it happen regularly. I think that Pieter Hintjen's book on social architecture is a really good read on this.\nIf someone wants to invite me back into the GitHub organisation (I rationalised them a few months ago to the ones I could work on actively at the time), then I will be happy to try and pickup a few items and get the ball rolling.\n. No. I'm back to help.. I'll close the issue.. Thanks for these, I will see if we can get them in.. Hi,\nI've started the process of reissuing the certificate for it, we will see how it goes.. The SSL cert for socketstream.com has been updated. Hi,\nAs suggested in #218, try running this command to resolve the uglify-js issue that you are experiencing:\nnpm install uglify-js -g\n\nThe stack trace indicates that this isn't running a SocketStream app, but instead another app, and therefore not directly-linked to SocketStream. I will therefore close this issue.. I'd like to propose that we simplify the branching strategy.\nAt the moment there are 2 versions of SocketStream being worked on - 0.5 (unstable) in the develop branch and 0.4 (stable) in the master branch. I'd like to propose getting the 0.5 branch stable first, then getting it merged into master and dealing with the merge conflicts that currently exist there.\nThe goal is so that we don't have to duplicate code fixes across multiple versions of SocketStream.. @thepian thoughts?. Very interesting question. If you want to store stream data on the client but not in memory, then there is the possibility of using the browser's localstorage API to do store data, and use a trick around subdomains to store multiple gigabytes of data on the user's comptuer. For an example, Feross' fill disk repo is worth a look: https://github.com/feross/filldisk.com.\nHope that helps.\n . Hi Piotr,\nWe're having difficulty in replicating this error. Could you do me a favour and try this on your computer?\ncoffee\nrequire 'argsparser@0.0.4'\nand let me know if you're able to load the library fine there?\n. Does this work?\nrequire 'argsparser'\nI assume you installed node via the tarball from the homepage. I can recommend the git repo (0.5.0-pre).\n. Hi Kryton,\nIt looks like we need to add support for ignoring backup files. I will have a look at this tomorrow morning, and hope to have a fix for you by tomorrow evening.\n. Thanks elisee.\n. Hi johnny,\nwhat version of iOS did you test this against? (both for the phone and simulator). iOS versions from 4 up are the one that support WebSockets, anthing below that (3.2) didn't.\nIf you're still having issues, let me know, it could be a bad regex used in lib/http_middleware/browser_check.coffee, line 49 which is not catching iOS users.\nLet me know how you get on \n. Hi Johnny,\nAre you still having issues with this?\nIf you are, could you visit either ssdashboard.com or socketracer.com, and let me know if you see the browser incompatible message. Thanks.\n. Thanks Elisee\n. This issue is fixed by this commit: https://github.com/socketstream/socketstream/commit/f520c9f2dc4b099682d528276b2b1a5611d996db\n. Maybe we could have a dual-compatibility approach, so that you could use /config/app.coffee in place of app.json. We could keep app.json as the default used in new generated apps.\nI will work on this feature.\n. Hi,\nI've committed this feature to a new branch (dynamic_config_files). I've also written tests against it, which you can run with 'cake spec'. There is one more test case to handle (error handling from a .js or .coffee config file), but once that is done, I think that this feature will just require a little refactoring, then it is ready for merging into master.\n. In theory, you could easily swap out the client-side templating library with the one of your choice. The question is... should we provide command-line options to do this, in the same way that running 'rails new' and then appending the option flag to use the haml templating engine uses HAML over ERB?\nI think that it's a nice feature, all we would need is a list of popular templating libraries, and then I think we could do this.\n. I say we do it.\n. Done. Thanks.\n. @jonmumm FYI, I've been implementing a feature to provide this, which you can see here: \nhttps://github.com/socketstream/socketstream/pull/36#issuecomment-1548650\n. Hi harlanji,\ndo you have a fork of the code for this? It would be nice to add it as an option for now.\n. Hi Brian,\nI'm going to have a look at replicating the issue. When you say you used a recipe provided by the community, did you mean the instructions listed in the install.md file, or the Linode StackScript?\n. @madgnu - Thanks for the tip.\n@brianconnoly - I'm going to amend the instructions to use Node.js v0.4.9. In the meantime, if you have a look at the Linode StackScript I use, you can find instructions on installing Node.js v0.4.9:\nhttp://www.linode.com/stackscripts/view/?StackScriptID=2863\nLet me know once you've setup fine on your box.\n. It turns out that this issue is an error with the Safari browser, as explained in the comments on the Socket.io 193 ticket. This is a bug that effects all WebSocket connections. Closing as this is something that can only be fixed by Safari.\n. I've got a different form of user authentication working at the moment, one that isn't using the approach advocated in that document. It is available to see here at: https://github.com/paulbjensen/shogunapp\n. Hi Brian,\nI'd like to find out more:\n- Do you know how long you left the app running in the background for?\n- What is your iOS device?\n- What is your firmware version?\n- Have you been able to replicate the crash?\n. Hi Brian,\nSorry, got caught watching \"Dig\" http://www.imdb.com/title/tt0388888/ - really good documentary.\nSo I'm assuming that you don't see an error get raised in the SS app's log, as this is the browser dying and not the application.\nIf you go to Settings > Safari > Advanced and enable the Debug Console, do you see any error messages raised in the browser?\n. Hi Brian,\nprod ;)\n. Interesting, thanks Brian. I'll go and have a look at the issues on Socket.IO to see if there is anything similar happening with them.\n. Hi, do you have a Segfault message you could post? Also what version of Redis you are running on your machine? Thanks.\n. Awesome, looks like Owen did the sensible thing and switched off from the all-hands meeting.\n. Hi aliasone,\nIt's possible. First, because 0.3 requires Node 0.6+, you'll want to use Node version manager, it's similar to Ruby's RVM solution and works very well:\nhttps://github.com/creationix/nvm\nSecondly, you'll want to include socketstream as a dependency of your project in the 0.2.7 app, run npm install, and change the command that you run to YOUR_APP/node_modules/socketstream/bin/socketstream start\nHope that helps. \n. Hi,\nApologies for late reply (housemate interviewing, feel like a cooking judge). You've followed the instructions correctly, so you're not at fault. I'll be on the irc chat room tomorrow from 11:30am GMT to help you out. In the meantime what is the output of the following commands on your machine:\nwhich socketstream\nsocketstream v\nand what is the output from the \"sudo npm link\" command inside the socketstream directory?\n. you could write an alias in your bash config/profile file:\nalias ss3=\"/usr/local/bin/socketstream\"\nThat way you keep the socketstream command for 0.2 projects , and have the ss3 command for the creation of projects for socketstream 0.3.\n. So I figured out the tasty. \n```\nconsole.log app.listen 3000\n=> undefined\n```\nI changed the code so that \nss.start app\napp.listen 3000\n. I'm going to have a look at getting this in before 0.3.11 is released.\n. Hi,\nThere is a feature branch, but it's still a work in progress. I will have a look into it this weekend. Apologies for the delay, if only I could work on SocketStream full time.\n. @kulicuu Thanks, I'll assign to you.\n. Wanted to know whether anything more is happening on this front? it's worth noting recent efforts with https://github.com/observing/thor and https://github.com/observing/balancerbattle.\n. I had a brief look into this. I think that we'll need to upgrade SocketStream's version of engine.io as a first step, and then create a suitable generator file for the expected websocket messages.\n. I will need to look at using GZIP compression for a 0.3 app. It's important.\n. I'm going to close this, and if it crops up again, I'll pick it up.\n. I'll be happy to take a look at it this weekend and see if we can make it happen.\n. I have some good news. I managed to get SocketStream working with Passport, using the Twitter authentication strategy. Here is the repo: https://github.com/paulbjensen/ss-passport-example\nThere are some thorny issues that need attention:\n1 - You cannot use ss.http.route to handle the routes for passport. This is because 1 - ss.http.route does not handle passing (req,res,next), and 2 - there is no ability to pass the HTTP verb (GET, POST, DELETE) to the route. In order to get passport working, I had to use the connect-route npm (version 0.1.3) to chain the routes onto the SocketStream application's connect middleware.\nIt would be ideal if we could find a way to make ss.http.route handle chaining, as well as specifying the http verb.\n2 - To use passport successfully, you have to attach the connect middlewares in a specific order. This has been a stumbling block for a lot of passport users. The middlewares in the SS app are appended in this order:\n``` javascript\n    ss.http.middleware.prepend(ss.http.connect.bodyParser());\n    ss.http.middleware.prepend(ss.http.connect.query());\n    ss.http.middleware.prepend(redirect());  // we append this because connect removed the redirect middleware from the core\nss.http.middleware.append(passport.initialize());\nss.http.middleware.append(passport.session());\nss.http.middleware.append(connectRoute(api));\n\n```\nI'm going to take a quick break before thinking about how we can refactor the code into an npm that will simplify integrating passport with SocketStream.\n@moiseevigor Thanks for your offer of help. If you're interested, I'd welcome any improvements you can make to the ss-passport-example (such as saving the twitter profile to the db, or displaying it directly in the page), or trying another authentication strategy (Facebook, github, etc).\n. I've had a brief look at how to assist passport integration with SocketStream. Passport provides a lot of flexibility in how you setup the app to authenticate with a 3rd-party. This comes at the cost of having to do some gruntwork in setting up routes, connect middleware (in the right order), and storing the user's information in the database.\nThe issue I see here is finding a way to reduce the gruntwork, without compromising the flexibility that Passport offers. I will need to explore this by implementing different authentication strategies, and finding common tasks that can be automated by default, with the option of configuring the module to not do that should you wish.\nI read @leostera's comment about him trying to get the authentication to happen almost within the single page app. I think it's possible. At the moment the example repo I made today will redirect to Twitter's login, then do a bit of OAuth redirection, and then eventually end up back at the application. The issue with this is that say you're in the middle of doing something with your single page app, redirecting to any page will mean losing that current page's state.\nMy idea would be to make the auth work like this:\n1 - You click the 'login' link. It opens in a new window.\n2 - You authenticate with Twitter in the new window.\n3 - The SS app authenticates the OAuth token, and the app now has the user's data. That window closes automatically.\n4 - The SS app pings a 'signedIn' event with the user's data. The user is now logged in, and we can trigger view partial changes like replacing the login link in the nav bar with the user's account.\nThis way, the app's page never has to be reloaded, and we can login to/logout from a 3rd-party service as close to in-the-app as possible.\n. This feels like something to be dealt with in a major update to SocketStream. Thus moving to 0.4 milestone.\n. I'm marking this as closed, as comments have answered the question.\n. Hi,\nI've got Dashku running on HTTPS with no issues. I'll take a look at this by tomorrow (apologies, I'm stretched for time today).\n. Hi,\nThere hasn't been any progress. It's something that is worth addressing in 0.4.\nHaving taken a quick look at BinaryJS, it looks like we'd need to address the following issues:\n1 - BinaryJS uses a custom version of MessagePack for transmitting data. SocketStream uses JSON. We'd need to find a way to configure the message format.\n2 - BinaryJS uses a custom version of the 'ws' node module. SocketStream currently uses engine.io as the default websocket library, with support for sock-js as well. We'd need to ascertain how to support binaryjs' server-side requirements in line with SocketStream.\n3 - BinarySJ would need to ship a client library to handle the streaming of files to the server.\nWe'd need to experiment with this first before we can establish if it's possible to do it. If anyone has attempted this, your experience would be worth mentioning here.\n. Hi,\nI'm going to take a look at this during the week.\n. Hi, I bumped chokidar to 0.6.3, though I see 0.7 is out. I'd like to try and have a go at replicating this. I have a Macbook Air with OS X Mavericks and a Desktop with Ubuntu 13.10 available for testing this issue out.\n. Hi @drosen0, are you still experiencing this issue. If not, can I close the issue?\n. I just ran into this issue. +1 for making RPC response in tests match the RPC response in browser. \n. I will fix this before 0.3.11 is released.\n. I can also recommend loading Bootstrap via a CDN as a way to work around this issue:\n@import url('http://netdna.bootstrapcdn.com/bootstrap/3.0.1/css/bootstrap.min.css')\n@import url('http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css')\nWe'll need to take a look at this file: https://github.com/socketstream/socketstream/blob/master/lib/http/index.js#L96\nI'll be at home in an hour to have a look at this.\n. Thanks @RomanMinkin.\nWe'll need to find a way to allow SocketStream http routing to be configurable so that HTTP requests for files can return a 404 instead of the html for the client, at the moment 200's are returned, and the parser for that file breaks because it's getting back HTML content where it expects something else.\nOn a side note, something to consider for 0.4 will be how to support using client-side modules/components in such a way that we could install them via either npm or bower or component.io, and then load them in our app without need to move files to different locations. It's a tough cookie, but I think that cracking this would be great.\n. This is now fixed by PR #419. It will be part of release 0.3.11\n. I think that this is definitely worth doing, and will therefore suggest it goes into 0.4\n. @kulicuu cool, please do. Thanks.\n. Hi,\nThanks for describing the issue in more detail. In the case of Dashku, I had a similar case of needing to fetch the current user via an RPC call, but what I chose to do is do almost all of the view rendering via Hogan.js, and have the app.jade be a simple html container with little pre-defined markup.\nIn terms of rendering multiple client-side templates, I built a simple library to handle doing this, called StateManager. It's got the same principle that Backbone has in that it applies a light structure to switching between states.\nIf it helps I can put the file in a gist and write a simple example to show how it works. It may be of help.\n. Marking as closed unless anyone objects.\n. Hi Leandro,\nI used to pre-compile the assets by running my app in a custom SS environment which would pack the assets, and then run a Cake task to copy those generated files to fixed paths that would be used in production via the CDN config option. \nThe reason I did this was because I planned to deploy the SS app across multiple instances, and I needed them all to use the same JS/CSS urls no matter which instance was viewed.\nWhat you're trying to do is smarter, and I haven't tried doing it that way. The best thing I can suggest would be to fork SocketStream and add in support to emit events on assets being compiled.\nGood luck.\n. An update - 0.4 is being cancelled, so that we can focus all dev work on one branch, the current branch.\n. I'm putting this into consideration for the 0.4 milestone branch.\n. Sadly I'm not able to do that right now. If I could work on SocketStream as part of my job, that would be great, but sadly I'm doing more of a sysadmin/full-stack dev/qa job at the moment.\n. @thepian is this something that can be done for 0.3.12, or would depend on a major update (i.e. 0.4).\n. Made a pull request to fix this issue: https://github.com/socketstream/socketstream/pull/323\n. Closing as the pull request #323 fixes this issue.\n. If you want to run Express in production mode (so you can utilise view caching), then in order to ensure that both SS and Express are running in the same environment, you have to either a) pass both environment variables in your command line, or b) pass one environment variable in your command line, and have that set the other environment variable in your code, or c) set both environment variables in your code.\nI hadn't considered that there would be a case for running SS in a different environment to Express and other node libraries.\n. done\n. I think it would be very useful, but the challenge is code reloading reliably. On the Node.js google group, there is a lot of discussions about hot code loading:\nhttps://groups.google.com/forum/?fromgroups=#!searchin/nodejs/hot$20code$20load\nThe general gist seems to be that reloading can lead to issues with garbage collection, and you can end up having weird problems that are caused by variables not being cleaned up. Thus, the suggested route is to load your app in a child process, and have file changes kill that child process and start a new one in it's place. In this case, it would mean reloading the application.\n. Adding this into 0.3.12\n. If you wish to reopen the PR and add some tests for it, I'll be happy to consider it for merging. \n. Hi,\nTo my knowledge, there's never been an official way to handle i18n within SocketStream. That said, there are 2 posts from users mentioning i18n in the Google Group:\nhttps://groups.google.com/forum/?fromgroups=#!searchin/socketstream/i18n/socketstream/ObQHROrSvPA/FA65kGOyyIwJ\nhttps://groups.google.com/forum/?fromgroups=#!searchin/socketstream/i18n/socketstream/cTso7tQ4-Zo/24kqaFn7rFcJ\nIt may be worth getting in contact with those post authors to get their take on how they approached it.\n. Closing as this is a discussion and not a feature request.\n. Hi halfblood369,\nCould you try and run this command and post stacktrace here:\nnpm install hiredis\nAlso, what version of Windows are you installing Socketstream on?\n. Hi,\nYou will need to install 'make' for windows, which you can get here: http://gnuwin32.sourceforge.net/packages/make.htm\nOnce you've done that, make sure to reload your command prompt (so that make is a known command), and then run the commands again.\n. You're welcome, I'll make sure (excuse the pun) that this info goes into the FAQ. \n. It looks nice, I have a crazy idea. \nWould it be possible to use this feature to make an rpc file use multiple RPC functions, providing RPC actions you can plug into an rpc file and re-use across rpc files?\n. Suggestions 1 & 2 seem sensible.\nI agree that config options shouldn't be a mandatory requirement in SS, but I think strongly believe that shipping a config file/option in default SS apps will be very helpful to users when they want to put their apps into production.\n. I have discovered how to resolve this issue, and a potential gotcha for anyone else who comes across the same problem.\nIt you attempt to execute your app.js file inside the cakefile, then attempt to load ss.start() inside one of your test files, the ss inside your test file will not load the RPC, for some strange reason.\nBy removing the loading of app.js inside of the cakefile, I have been able to stop this issue. As a result of this discovery, I am now on course to remove all of the global variables inside of Dashku, and re-architect Dashku so that it can use a plugin architecture.\nRemind me at some point to write this up for the documentation on testing SocketStream applications.\n. I think you have to call it via ss.api.rpc\n. Hi,\nSocketStream uses Socket.io for the Websocket transport. If I understand your requirements correctly, then this may be of help:\nhttps://github.com/pkyeck/socket.IO-objc\nSee the YouTube video for a quick explanation:\nhttp://www.youtube.com/watch?v=VCXKMVENW_o\n. Update: Using a forked version of SocketStream, I've been able to make the default SocketStream app deploy to Heroku. It involved removing Socket.io from the dependencies list in the package.json file. \nTo get the SS app working on Heroku, I used ss-engine.io with the following configuration options:\njavascript\n    ss.ws.transport.use(require('ss-engine.io'), {\n      client: {\n        transports: [\"polling\"],\n        upgrade: false\n      },\n      server: {\n        transports: [\"polling\"],\n        allowUpgrades: false,\n        pingInterval: 10000\n      }\n    });\nI now think that there is a case to replace Socket.io as a dependency of SocketStream with either SockJS or Engine.io.\n. So there's an outstanding issue with ss-engine.io that's worth reading. \nIf Socket.IO doesn't reconnect channel subscriptions upon a reconnection, then ss-engine.io can replace it now. However, if it does, then we need to implement this feature into ss-engine.io before it could replace Socket.io.\nI'll check Socket.io's current behaviour now.\n. Hi @jcw,\nI don't see any references to ss-engine.io in your app.js file, and the version of socketstream in your package.json file is \"~0.3.2\". I might be wrong but that version of SocketStream is before ss-engine.io was merged into SocketStream. Can you check whether the socketstream node module is either the 0.3.2 published version, or the master branch version on github?\n. Hi, I've just checked on my mac (uninstalled and unlinked all versions of SocketStream from my mac), and npm install socketstream installs 0.3.2 with socket.io 0.9.8.\nIs it possible that you have a copy of the socketstream repository that has been linked to via npm link?\n. You're welcome. With regards to the RPC issues you were experiencing, I will try and run that app against the master branch version of SS to find out what is going on there.\n. I've tried running the homemon app but I see this and I'm not sure what I do next.\n\nI've had Dashku.com running with the master branch of SocketStream for over a week now \nwithout any connectivity problems. I have not been able to replicate any problems with doing RPC with this. Would greatly appreciate a 3rd check by someone else to see if they encounter any issues with doing RPC against the master branch.\n. Hi.\nI'm using 'npm start' to launch the app, and I checked out the master branch of your app. \nI may have misunderstood what you meant by \"using git master\". If you mean how can you check your against the master branch of SocketStream,the way I do it is I checkout SocketStream into a directory, go to the app's directory, then type 'npm link path/to/socketstream_directory'. I type 'npm unlink socketstream' when I'm done.\n. Hi,\nIt's absolutely fine, I'd like to figure out what the bug is and fix it, regardless of what library it originates in. \n. It's a long shot, but does the number of argurments that you pass to an RPC have any effect on it working? In my app's cases, I've only passed ss.rpc ('x.x', callback) or ss.rpc ('x.x', arg1, callback).\nThanks for the info, I'll give it a look later on today.\n. Hi @jcw,\nI ran the latest version of your app, and the app seems to work fine with both the 0.3.2 and master branch versions of SocketStream (the server time display on the sandbox url worked exactly the same in both cases).\nI followed your readme instructions, then I did the following to test master branch of SS:\n1 - edit the package.json so it reads:\n\"dependencies\": {\n  \"socketstream\": \"git://github.com/socketstream/socketstream.git\",\n...\n2 - Put the following commands in the terminal:\nrm -rf node_modules/socketstream\nnpm install\n3 - Boot the app as the readme instructs.\nCould you tell me what rpc call you were having trouble with?\n. Hi,\nI'm afraid I don't have any listings under \"Briqs\". \nI tried the 'host.api' call from the client with this command:\nss.rpc('host.api','log','this is a message');\nI managed to get the server to print out 'this is a message' in the server terminal output, both for 0.3.2 and for the master version.\nCan you try the same, and see if it works for you?\n. You're welcome @jcw, glad to have helped figure that one that.\n. Yep, ss-engine.io was created from a copy of ss-sockjs' codebase. I'd be happy to accept any PRs to ss-engine.io to clean this up.\n. Hi @davisford,\nOwen is on holiday for a couple of weeks. I'll lend you my eyeballs and see if I can figure out what's happening.\n. Hi plievone, \nThanks for spotting the issue. Would you like to fork the repo and submit a pull request with the fix in, or would you like me to do that?\n. Yep, so there are 2 API methods exposed: 1 inside of rpc files, and another for all other files. You'll need to call ss.api.publish.\nHere is the linked section in that document: https://github.com/socketstream/socketstream/blob/master/doc/guide/en/pub_sub_events.md#publishing-events-via-appjs\n. What file contains the call to ss.api.publish, and how is it being loaded (in a separate Node.js process to the SocketStream app, or as a require(\"./example_file\") in the SocketStream app's codebase)?\n. The folder path needs to be server/rpc, then run node app.js.\n. Hi, just wanted to ask if changing the path of the file from rpc/serial.js to server/rpc/serial.js did the trick?\n. Sorry, I'm in github-issues-driven development mode ;)\nLuckily for you, I ran into this once. I believe it was to do with using npm modules being compiled against a older version of Node.js (0.8.12), then using a updated version of Node.js (0.8.16).\nThe suggestion here is to remove all modules in the app's node_modules folder ('rm -rf node_modules' works for me), then run 'npm install' again, then the app runs again.\n. Hi @thebadger412,\nFiles inside of the server/rpc folder need to be structured with this code:\n```\nexports.actions = (req,res,ss) ->\nexample: ->\n    ss.api.publish.channel('channelName','eventName', {data:'value'});\n\n```\nTake a look at this file in Dashku for reference: https://github.com/Anephenix/dashku/blob/master/server/rpc/dashboard.coffee#L44\nAlso note that ss is being inherited from exports.actions (req,res,ss), not the require at the top of the file.\n. Commented on the gist file.\nAlso, in relation to \"Like I want it so as soon as the server starts it sends this value to bigNumber..\", you'll need to make an RPC call somewhere (either from browser or terminal, or somewhere in the app.js file after the server is started and a port is listened on) - Here is the relevant document about RPC:  https://github.com/socketstream/socketstream/blob/master/doc/guide/en/rpc_responder.md\n. Hi, there's a bit of Javascript you can use to stub out console for IE here:\nhttps://gist.github.com/gerad/1943520\nIs this still an issue with SocketStream 0.3.4? I'm wondering if browserify didn't clean up the calls to console by now. \n. Oh wait, it is. Nevermind. I will make a PR with this patch for IE.\n. Thanks for the info. A StackOverflow thread suggests some other possible options:\nhttp://stackoverflow.com/questions/690251/what-happened-to-console-log-in-ie8\n. Hi Raynos,\nI don't know if you've tried it, but there is an npm module called livereload: https://npmjs.org/package/livereload which reloads CSS files without requiring a page refresh.\n. How about this? http://aboutcode.net/vogue/\n. You're welcome. I remembered seeing other tools that did the same thing. Hopefully one of them does a good enough job.\n. Hi Rednaxus,\nThanks for reporting this. I'll begin a fork of SocketStream to implement the security fix, and a notification on the Google Group now.\n. Hi Rednaxus,\nI've committed the patch. I'm going to let the others know as well. Could you do me a favour and give this patch a try?\n. Hi Rednaxus,\nAt the time I simply wanted to make sure users could patch the security hole ASAP. I didn't give consideration to auto-detecting the server protocol and setting the value that way. I will have a look and see if it's possible.\n. I had a very brief look last night but I couldn't find a way from within http/index or session/index. The next chance I'll get to look at this is this evening.\n. An update. I'm probably not going to get a chance to implement a way of auto-detecting the server protocol and setting the secure flag in the session options. Would anyone else like to have a pop at implementing this? \n. Hi @jcw, \nIf you are using Node V0.8.20, then this is the issue that you are encountering: https://github.com/senchalabs/connect/issues/750\nIt's basically a change in Node v0.8.20 which means that you have to handle socket errors. It's irritating, but the upside is that the change in that version of Node stops a memory leak.\n. The middleware you suggested should (in my opinion) work, and in order to check that you have intercepted that socket hang up error, I would write this line instead:\nres.on 'error', (err) -> console.log err\n. Hi,\nThe engine.io http library would also have to be patched. \nAlternatively, 0.8.21 was released last night. I I recommend upgrading from 0.8.20.\n. # \u270c\n. I'd like to add this feature in, as I spent some time last night trying to get it in to optimise an app's loadtime performance to get under 200ms. I will find a way to add those changes in and update documentation as appropriate.\n. Thanks @essentialjs,\nYeah, this was essentially to gain the page-rendering improvement that occurs when you locate the JS assets before the closing body tag, rather than directly after the link tags for the CSS in the head section.\n. I'll close this PR for now, and added the feature request to the Trello board for now.\n. Hi @polidore,\nThe line you highlighted in the code gets a connect session id from the user's cookie, and is used to bind the websocket connection to that session. \nYou said that your app servers have separate session stores? There is the possibility of sharing sessions between app servers via Redis, which I believe should stop the servers from resetting the cookie every time the load balancer  points the client to another server.\nAlso, are you setting the max age in your session config? See this for info.\nhttps://github.com/socketstream/socketstream/blob/master/doc/guide/en/sessions.md#auto-expiring-sessions\n. Hi @polidore,\nThanks for the issue.\nI don't think that this is an issue with the cookie key, as the connect.sid cookie key has been used within SocketStream since the socket.io implementation, see: https://github.com/socketstream/socketstream/blob/38da2b096b43adbb2a814d94bd0ff6eda060d5c3/src/websocket/transports/socketio/index.coffee#L84. That said, there should probably be a way to specify a custom cookie key.\nI'd like to try and replicate the app setup that you've used for your app, because when I developed ss-engine.io I naturally assumed that you would want to share session data across all running instances of the app, so that client reconnections use the same session, and do not lose channel subscriptions. I recall that you're not sharing sessions between servers in your case, so I'd like to try and fix this issue to cater for that use case.\n. Hi, no worries, I get the frustration when working software breaks. \nI will give it a go tomorrow morning, and checkout your pull request as well.\n. Hi,\nWas this issue resolved by the work on the Websockets (#397)?\n. I don't know if this is related, but has anyone seen this bit about needing a P3P header in IE9 in order for it to work with sessions: http://ruhmesmeile.github.io/socketstream-presentation/#/5/11\n. @mdedetrich Thanks for the tip, I'll make a note to add that to the documentation.\n. The workaround suggested here may help: http://stackoverflow.com/questions/6136101/jquery-ajax-request-in-ie9-not-sending-cookie-header \n. Hi, I'll look into this today. Sorry it's sat on the queue for so long.\n. This is now fixed as part of the 0.3.6 release\n. Hi @dzz0615,\nThis looks like a useful feature. Thank you for contributing it. Fingers crossed this gets merged in, if anything it brings 0.3 a bit closer to how 0.4 will work.\n. Thanks for scoping it to that release, I wonder if they've encountered the same issue in the engine.io repo. I'll have a look into it.\n. I've tried running a default ss app on v0.10.6, and not replicated the issue, but I did discover that the default transport bundled into SS from 0.3.4 isn't using reconnection logic, which is a bug. I'll try out 0.9.4 and try to replicate the issue with that.\n. At this point in time, not likely. SocketStream's client library management was created well before the likes of component.io and bower came into existence. This is an issue I want to address with 0.4 - how to make SocketStream play nicely with client-side tools like bower, grunt, and yeoman.\n. @mattlenz Does Roman's suggestion provide what you need?\n. Hi, \nI provided a response to this query in the Google Group a few weeks back: https://groups.google.com/d/msg/socketstream/c_7KBIDzqwY/C6RavWCskfsJ \nI just wanted to catch up and check if everything is good?\n. Also, if you need to delay the test timeout, you can use this: http://visionmedia.github.io/mocha/#test-specific-timeouts\n. Also, you may want to manually check that ss.rpc('app.square') is working from the browser, because it could be the case that it isn't returning.\n. I ran this test as documented in the guide, and it ran fine. I'm closing this issue as a result.\n. I'll have a look into it. From a quick look I think that the reason why the ss global variable is set like that was so that it was clear where that variable was originating from.\n. Just wanted to check up on this issue and ask:\n1 - If you adjust the line to expose ss as a local variable, do you still encounter a problem?\n2 - For the approach you described, do you have a working example that you could submit in a PR?\n. Hi,\nI'll have a look at it this lunchtime (BST).\n. Thanks Roman,\nI gave this a try on Dashku (running locally, but using minified assets), and using Google Chrome's PageSpeed Insights extension, my score went from 47/100 to 93/100. BAM!\n. Hi Owen,\nI didn't see that, my bad. I'll take a 2nd look later on this weekend.\n. I've replace the connect-gzip npm with connect's compress middleware. The last change left to do is to get the html file gzipped.\n. Sorry, I left some compressed files in the test app before I checked it again, so I didn't spot that it hadn't compressed properly.\n. This thread on Stack Overflow might be of assistance WRT configuring the global path prefix for npm module binaries. http://stackoverflow.com/questions/14803978/npm-global-path-prefix.\n. I would, but I'm currently trying to work out what happened to a comment I left in one of the threads. Would like to know of it was deleted, and if so, why?\n. Ok, rather perplexing but nevermind.\nMy experience of using both is that RequireJS involves more effort to setup, as you have to use shims to support non-AMD modules, so you end up having to maintain links in 2 places instead of 1.\nI've used Grunt and it's a good tool, but I'm wondering how would a developer use Grunt with SocketStream? Is it to copy the minified assets to a CDN? Is it to lint the code as part of a pre-deployment strategy? It would be nice to document the developer workflow to see what gaps exist and how they can be plugged.\nI've toyed with Yeoman sparingly, but I ought to give it some more attention to see how it could be useful.\n. I'm looking into making an SS app generator with Yeoman now.\n. Closing as it's a duplicate of #378 \n. Hi Owen,\nI've looked at implementing this via ss.api.log, but I've realised from looking at the code that the publish and session modules have no knowledge/link to ss.\nI have 2 ideas about how to approach this:\n1 -  add and require a separate log module into the app to replace console.log, and which ss.log will alias to.\n2 - change how the publish and session modules load, so that they have an implicit knowledge of ss, and can then traverse the api tree to call ss.log.\nI think that 1 would be a quicker option for now.\n. I haven't forgotten about this, but when I had a go at it, I realised that I had to untangle some requires further up in SocketStream's stack of internals. I will get to this.\n. Marking as closed, thanks to the work done in #430\n. It's an issue of how to handle source map files. The asset module uses code formatters to transpile files into other formats, and because .map files are not handled, they raise an error. We could add a handle for .map files, but I'll need to look into how we do that.\nThis is an issue of how to support source map files. Ultimately it points towards a broader question of how to handle client-side files, as we now have a range of approaches, from having grunt to concatenating/minifying, to having bower manage our software dependencies. The landscape has changed a bit since 0.3 came into existence.\n. If you see the readme here (https://github.com/anephenix/ss-engine.io), you should be able to pass the contextpath for engine.io. SS-engine.io got integrated into SocketStream from 0.3.4.\nLet me know if that solves your issue.\n. @tomhowe Could you let us know if this issue is still affecting you? I'd like to fix it if it is.\n. Thanks Tom. If you have any feedback about SocketStream, I'm open to hearing it. \n. Thanks for posting that. I'll look at it this lunchtime (GMT), and if all is good, merge it in.\n. Tested, works. Thanks for the Pull Request.\n. Note: Check that you have grunt-cli installed beforehand as suggested here: http://gruntjs.com/getting-started\n. Hi,\nSorry, I should have communicated it better. I attempted to do both comment-porting and linting at the same time, and that introduced bugs. I therefore split out the comment porting and linting, and completed the comment porting part, allowing us to use the lib folder as the single source for the codebase.\nYou're absolutely right, linting the codebase is going to be a huge task.\n. Added a comment about a potential misspelling of 'grunt test' (currently reads 'gunt test').\n. Here's a fix for the issue: http://www.mattgoldspink.co.uk/2013/02/10/using-travis-ci-with-grunt-0-4-x/\n. Thanks Roman.\nTravis CI passes for Node versions 0.8 and 0.10, but 0.6 fails: https://travis-ci.org/socketstream/socketstream\nGrunt works with versions Node 0.8 and greater. Adding this change would mean ditching support for Node 0.6.\nI'd like to get some feedback on whether we do this. There are some implications, such as being able to support OpenShift's Node.js cartridge (which as far as I know only supports 0.6). \n. In that case, I don't see any reason to continue supporting Node 0.6 (after all, it is 2 levels below the current stable branch). If you could remove the need to test 0.6 from the .travis.yml file, then this commit would be good to go.\n. The minimum version of Node is specified in the package.json file, and in the travis config file.\nWe could add a line in the Readme file.\n. Hi Roman,\nThanks for the explanation.\nThe code example you gave for Mocha demonstrates an important lesson about Node.js - callbacks should not be nested at a level outside of a closure that executes an important instruction, as they will be evaluated asynchronously to whatever is going on inside of that closure.\nAlthough I take it upon myself to audit all the code commits that are being made to SocketStream, I can't rule out that I would miss something. I therefore think that there's a case for making this change.\nWhat would be involved with replacing Mocha with NodeUnit?\n. If you make a PR into the 'tests' branch, then I'll merge it in. PS - On topic, have you used Istanbul for code coverage? http://gotwarlost.github.io/istanbul/\nI'm curious to try it out. \n. An update,\nAfter some consideration, I've decided to revert from using NodeUnit for the test suite. After playing with it for some time, I found it made organising the tests for modules, and reading what those tests were, worse. It was a quality I didn't fully appreciate at the time until I delved deep into using it. Thus I've ported the test code back, allowing the tidying-up changes to remain.\nWith regards to assertion counting, I agree that we should have this in place, so I did some initial research, and I've adapted this suggestion (https://github.com/visionmedia/mocha/wiki/Assertion-counting) into a helper library that we're using throughout the test suite.\nSorry about undoing some of the work here.\n. No, I should have explained my comment better.\nThe syntax style offered by NodeUnit is in my opinion not as friendly to read as Mocha's. That is a subjective call, so I'd like to explain my thoughts. \nThe key premise I'm making is that the closer the code is to reading like plain english, then the easier it will be for other people to read and understand, and therefore the easier it will be to contribute.\nMocha's syntax style is very similar to RSpec's, and it's use of the style ' it \"should do something\" ' fits nicely with describing exactly what the test covers, as well as being able to organise those tests by way of the keyword \"describe\". This contributes to a developer-workflow of guiding the developer to speak in plain terms what they're trying to do first, before they begin to write the tests.\nWith NodeUnit, we lose the ability to express the tests in this format, if anything we tried to keep the context, but then the function names were strings, which didn't feel right.\nWith the tests I've made a decision to resort to using a test framework that allows us to continue writing tests that fit this idea. I can give an example of this. \nA couple of months ago a colleague was writing some pseudocode to break down a feature into logical parts. At one point he wrote a line of code that caught my eye. That line of code, reading something like \"do action if condition is true and another condition is true\". \nHis line of pseudocode was valid CoffeeScript. The gap between plain english and programming code was almost 0. I won't evoke Wittgenstein, but this is a wonderful case of language and logic being perfectly in fit.\nOf course, that said, one could argue that dropping the source code being written in CoffeeScript goes against this idea, and to be fair, there's a point in that. I weighed this up, and when I realised how much of a barrier CoffeeScript was to people wanting to work with SocketStream, as well as it adding steps to the code contribution process which people missed, I came to the position that for benefit of SocketStream being a broader effort, it would have to be written in a language that everyone could work with: JavaScript.\nThat's my take on it. Interestingly, this seems somewhat similar to the debate around TestUnit/RSpec in the Ruby world around 2011:\nhttp://www.rubyinside.com/dhh-offended-by-rspec-debate-4610.html\nhttp://www.ultrasaurus.com/sarahblog/2011/04/on-choosing-rspec-as-a-test-framework/\nThoughts?\n. Hi @azat-co,\nThanks for the tip. The reason to consider NodeUnit over Mocha was the support for assertion counting, but there was a way to support that in Mocha, and the syntax style in Mocha was in my opinion a better fit.\nThere was also a 2nd reason, which is that making the tests more human readable will assist with helping to understand SocketStream's inner workings enough that a language-agnostic specification could be created, which would potentially allow for SocketStream to exist in other languages.\n. Hi,\nJust want to check that this was the same issue discussed here: https://groups.google.com/forum/#!topic/socketstream/MohS3GEICgQ. If so, the resolution is to make sure that the server is listening on port 443.\n. Cool, I'll mark this as closed.\n. Thanks, I'll take a look at it by tomorrrow.\n. Thanks Robert,\nThis issue makes me think that asset serving/handling needs to be more flexible, the question is whether to address that in 0.3, or in 0.4. In my opinion, making SocketStream's asset handling wrap access to html headers could be cumbersome, and what might be better is to allow the developer to handle asset loading and compilation separate to SocketStream, but still be able to use SocketStream for pub-sub/rpc and more.\nI will definitely consider it WRT 0.4.\n. Out of curiosity, what is the workaround you found?\n. Thanks Ben, I'll take a look at this in an hour or two.\n. Thanks Ben, that's now merged.\n. I've figured out a way to work around this and get it fixed. I will test first, then publish when done.\n. So it turns out your filename can't contain gitignore or nodemonignore in it, as they will be stripped out on the basis of a match, even if the filename isn't .gitignore or .nodemonignore.\nWe'll have to use other names for those files to prevent them being removed by npm publish.\n. Hi,\nI've encountered your problem, and I will being to fix it tomorrow. Unfortunately I couldn't do anything about beforehand as I had to help my mother move house today.\nThanks for reporting it, and apologies that you had to in the first place.\nRegards,\nPaul Jensen\n. Hi @zvxy, I have a fix for the issue you found which will be pushed shortly.\nI've discovered that when writing to files (with either fs.writeFile or fs.createWriteStream) with a dot at the beginning of the filename, the file never gets written. This could be a bug, but I'll ask before I file anything. The implications are that we can't ship .gitignore/.nodemoningore files with a beginning dot in the name.\n. I've stopped the app generator from breaking, but I've also spotted that the .gitignore and .nodemonignore files are not being generated in a new project, which looks like an issue with them containing dots in their file name.\n. Actually, it turns out that this isn't broken anymore, I was using ls -ll instead of ls -la to list the files, and Max OS X doesn't list those files with ls by default.\n. Hi Roman,\nThanks for the commit. If we correct the spelling of browserifyExcludePath in the code, I'd like to give it a full run and get it merged in.\n. Also, I'm open to looking at your suggestion about minimatch, although I think it ought to come in via a separate pull request.\n. Hi, I tried the branch, but encountered this error: \n/Users/paulbjensen/Work/anephenix/test-402/node_modules/socketstream/lib/client/index.js:93\n          _results1.push(options[k][x] = y);\n                                       ^\nTypeError: Cannot set property '0' of undefined\n    at /Users/paulbjensen/Work/anephenix/test-402/node_modules/socketstream/lib/client/index.js:93:44\n    at Object.set (/Users/paulbjensen/Work/anephenix/test-402/node_modules/socketstream/lib/client/index.js:96:13)\n    at Object.<anonymous> (/Users/paulbjensen/Work/anephenix/test-402/app.js:25:11)\n    at Module._compile (module.js:456:26)\n    at Object.Module._extensions..js (module.js:474:10)\n    at Module.load (module.js:356:32)\n    at Function.Module._load (module.js:312:12)\n    at Function.Module.runMain (module.js:497:10)\n    at startup (node.js:119:16)\n    at node.js:901:3\nI'll dig into what's going on here more tomorrow.\n. ss.client.set({ brosefyExcludePaths: ['app/controllers'] });\nThis is before pulling in the rename changes. I'll check with the rename changes as well.\n. I'll push test-402 up to a new git repo\n. Here, https://github.com/paulbjensen/test-402\n. A dumbass move on my part, forgot to npm link. Sorry.\n. View templates already contain the <meta charset=\"utf-8\"> attribute, so I say nothing more needs to be done here. I'll give it a check now.\n. Thanks Roman, great stuff.\n. Thanks for adding this. I'll look at it tomorrow as I'm battling a cold and\nneed to sleep first.\nOn Wednesday, October 9, 2013, RomanMinkin wrote:\n\nHi everyone,\nI have spent some time to finally come up with the solution for gzip\nsupport for main HTML files. Related issue #376https://github.com/socketstream/socketstream/pull/376\nWorks only for packed files, which does make cense.\nI tested with default SocketStream demo app (http + connect) and with more\nadvanced with Express.js https://github.com/visionmedia/express on the\ntop.\nResults:\nDate                Wed, 09 Oct 2013 19:59:55 GMT\nContent-Encoding    gzip\nTransfer-Encoding   chunked\nConnection          keep-alive\nVary                Accept-Encoding\nContent-Type        text/html\nand with Express\nDate                Wed, 09 Oct 2013 20:00:14 GMT\nContent-Encoding    gzip\nTransfer-Encoding   chunked\nConnection          keep-alive\nX-Powered-By        Express\nVary                Accept-Encoding\nContent-Type        text/html\n\nYou can merge this Pull Request by running\ngit pull https://github.com/RomanMinkin/socketstream feature/gzip-compression-for-main-html-files\nOr view, comment on, or merge it at:\nhttps://github.com/socketstream/socketstream/pull/404\nCommit Summary\n- Added support for GZIP compression for main HTML files\nFile Changes\n- M lib/client/http.jshttps://github.com/socketstream/socketstream/pull/404/files#diff-0(14)\n- M lib/http/index.jshttps://github.com/socketstream/socketstream/pull/404/files#diff-1(5)\nPatch Links:\n- https://github.com/socketstream/socketstream/pull/404.patch\n- https://github.com/socketstream/socketstream/pull/404.diff\n\n\nPaul Jensen\n07914 171 345\n. Thanks Roman, so glad to get that optimisation sorted as well. \nI don't know if you've seen it before but there's a neat extension for Google Chrome called PageSpeed Insights: https://developers.google.com/speed/pagespeed/insights/, it's very handy for spotting ways to improve web app performance.\n. Hi Lukas,\nThanks. At the moment there is no way to run packAssets separate to calling ss.start, and there ought to be (like for example running it as part of your Grunt workflow). \nI've marked this as a feature request.\nI've had a go at trying a workaround to this, in this repo: https://github.com/paulbjensen/test-405 . What I do is have the app.js contain most of the app loading, and then pass ss and server as public objects. Then I have server.js for booting the app on a port and run, and have pack.js boot the app (on a separate port) and pack the assets.\nWe'd need a way to trigger a callback on packAssets finishing. I'll look into adding that, as well as finding a way to run it outside of booting ss.start.\n. Hi @evanlh, Thanks for this, I appreciate your help with it.\nIn my opinion, providing access to internal events via the API isn't a bad idea. I'll play with this patch in a couple of SS apps, and see how well it works.\n. Hi,\nYes. SocketStream's codebase was never developed with linting in mind. It was introduced recently, and I tried to lint the codebase, but in the process of doing so the web framework broke in places, so I decided that it would be better to put unit tests in first before getting the codebase linted.\nAs the length of your log file demonstrates, there is a lot of work to do.\n. Added a note for now. We want JSHint in there to remind us that we have to get the codebase linted, no matter how much or how ugly the work is going to be.\n. Hi, thanks for submitting this. I'll take a look at it later today.\n. Thanks. At some point we'll want to document this in the guide, and give a description of the pros/cons\n. You're welcome, thanks for contributing it, there's always room for\nimprovements like this.\nOn 25 October 2013 16:41, pygy notifications@github.com wrote:\n\nBTW, thanks for accepting this :-)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/407#issuecomment-27102684\n.\n\n\nPaul Jensen\n07914 171 345\n. Good idea, I'll create a milestone and assign this issue to it.\n. No, instead do npm run lint.\n. Yep, agreed. I've been trying to use !condition instead of === undefined or === null in these cases, was there a line I broke? \n. What if we add fixtures and auxiliary files to .jshintignore?\n. Hi,\nI don't believe that we have an ability to switch ports based on the transport protocol. I'll need to take a closer look at working with OpenShift. We originally had the demo app running on it, but we experienced some issues so we moved it to Linode. \nWe'd also need to look at how to work with OpenShift's scaling system. They use HAProxy to handle routing requests to gears. I've seen threads saying that a gear handles a maximum of 10 concurrent connections. I don't know if they use sticky sessions, but we'd need to determine that as it's crucial to how the underlying engine.io transports work (a long-polling/websocket session's state is stored within a process).\n. I should note that SocketStream no longer uses Socket.io, but instead uses\nEngine.io (which is the transport library part of Socket.io, and will be\npart of Socket.io 1.0).\nOn 18 October 2013 10:56, Christian Sterzl notifications@github.com wrote:\n\nThx for looking at it. I've seen following post:\nhttps://github.com/LearnBoost/socket.io/wiki/Socket.IO-and-firewall-software\nThe client js will initially try to connect to port 4000 and fall back to\nports 80 or 843, if that doesn't work. I also tested different orders for\nport 80 and 843, to make sure both work (or not).\nSo the client seems to be able of doing this. On the server are both ports\nopen anyway. Maybe this is helping.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/409#issuecomment-26584117\n.\n\n\nPaul Jensen\n07914 171 345\n. Good question. I think it will involve forking the repo, and editing the client wrapper files in /lib/client to add an error listener.\nI'll have a look for you at lunchtime.\n. So, that was a long lunch. Apologies for the delay in getting back.\nAfter encountering a painful bug in engine.io, I updated chassis.io to the latest version, and I now realise that SocketStream could use the same update. I'm going to be updating the client in the coming days.\nWith regards to dealing with your query, the way that I think it can be achieved is this: \n1 - Fork this repo: https://github.com/socketstream/ss-engine.io\n2 - Add an 'onerror' event on the sock event emitter as defined here:\nhttps://github.com/socketstream/ss-engine.io/blob/master/client/wrapper.js#L17\nInside of that error, set config.port to the port to the openshift websocket port.\nNow, I'm assuming that sock.onerror will call before sock.onclose, so that you can change the config.port value before the reconnect logic kicks in, and attempts to reestablish the connection.\nIf you need a hand, let me know.\n. No worries @Waxolunist, I am in the same position right now ;)\n. Thanks, I'll take a look today.\n. So, @americanyak is responsible for the documentation, and there is a repo where work is being done to port the docs to the main web site.\nWe'll need to do more there.\n. The repo is private, but I'm going to open source it now.\n. Here is the repo: https://github.com/socketstream/ss-documentation\n. Yep, I think that Github anulled team access when I transferred the repo from Anephenix org to SocketStream account. You're both added as collaborators now.\n. To follow up, I see a list of tasks:\n- [ ] Get the docs site functioning\n- [ ] Get the docs site hosted on a server and a domain pointing to it (doc.socketstream.org)\n- [ ] Get the doc linked to it\n- [ ] Add documentation on how plugin writers can contribute to SocketStream\nAny more to add? I'll get onto it.\n. Hi Romain,\nThanks for the suggestion, I think that this could work. What are everyone else's thoughts?\n. @RomanMinkin do it.\n. This is now available via the ss-ejs npm: https://github.com/socketstream/ss-ejs\n. Hi,\n@Waxolunist is right. \nAt the moment, if you are serving plain vanilla html views, then we look for a  tag, and what that out with the html needed to boot the app's javascript and css.\nIf you are using jade templates, then socketstream is accessible as a local variable. I would potentially like to find a way to support the same pattern of a jade html tag that is just socketstream, and again replacing that out. It's something to consider down the line.\nAre the css in the jade templates now working for you? \n. Thanks.\n. Hi, I've tested your change out. It nicely handles supporting Push State Routing, whilst at the same time returning 404s for other files.\nYou'll need to declare the path dependency at the top of the lib/http/router.js file:\nvar path = require('path');\nIf you add that in another commit to the feature branch and push again, the PR will pick it up, and then I will merge the PR. Thanks for your work.\n. No, that was all. Thanks. If you want to check how your local build of SocketStream work against an existing app, npm link will let you do that:\ncd app\nnpm link <path_to_socketstream_copy>\nThen when you've checked out your changes:\ncd app\nnpm unlink <path_to_socketstream_copy>\nnpm install\n. For tracking purposes, fixes #286\n. Thanks Roman, I'll have a look at it tomorrow, if not tonight.\n. Hi Roman,\nI've had a look at the pull request. There is a regression when the app attempts to serve this route:\nhttp://localhost:3000/_serveDev/start?ts=1388920881715\nIt takes a couple of minutes to serve the file:\n\nI tested this by pointing the socketstream/ss-home repo to use this PR of socketstream via npm link.\nI'll have a look at the issue again this evening.\n. No worries,\nI will take a look again tonight. In terms of whether to upgrade connect, I'm open to considering it, but I also expect that it won't be a straightforward swap-in-and-out, so I think that it would be a candidate not for this release, but possibly for 0.3.12.\n. I believe that @kulicuu is looking into this issue, is that right?\n. Hi everyone,\nThanks for your suggestions, I think that there are some good recommendations in there. There's a lot of thoughts relating to this subject, so apologies if this a long and rambling comment.\nMy thoughts\n\n0.3 is what most people use, and still needs a lot of work (test coverage, issues)\n0.4 is beginning to look like vapourware (no development since April 2013).\nSince 2011, SocketStream was effectively rewritten twice, each with breaking changes.\nThose rewrites (though doing good things) caused uncertainty and frustration for developers wanting to build apps using SocketStream, apps that would be used in the long term.\nPeople I spoke to in private said that they abandoned SocketStream because of this.\nThe popularity and momentum behind SocketStream is directly linked to the number of developers working with it multiplied by the time they could give the project.\nIn Summer 2011, there was a team of 3 working almost full time on it at AOL, then it was just Owen from July/August 2011, then Owen left AOL in November 2012. Now, no one works on it full time.\nThe lack of (easy to find) documentation may have limited the adoption of the framework.\nThe lack of tests for the framework has made it difficult to add features without causing regressions.\n\nWith these things in mind, I've realised that 0.3 has to be maintained, that the gaps in tests and docs have to be filled in, and that given current time available, this makes working on 0.4 more unlikely.\nAn article that has influenced my thinking is this: http://www.joelonsoftware.com/articles/fog0000000069.html\nI feel that some of the things Joel Spolsky mentioned in that post have parallels with SocketStream's history: namely the fact that when SocketStream was rewritten with 0.3, the Meteor project came along and gained the lion's share of attention in the real-time web space.\n0.3 is good enough to build amazing apps on; I have proved that by building Dashku and then getting offered the chance to move to California and work for Facebook as a result.\nSo where does that leave 0.4?\nI think if we're brutally honest, unless there are more people and time to work on SocketStream, 0.4 as a rewrite of 0.3 won't see the light of day in June as I promised.\n0.4 was originally inspired by Substack's streams talk at LXJS 2012: http://www.youtube.com/watch?v=lQAV3bPOYHo\nHowever, after some initial testing, Owen found that streams were significantly lower than Connect's middleware (in terms of requests per second). Therefore SocketStream 0.4 would instead be envisioned as a way of decoupling the features of SocketStream so that you could use SocketStream's asset compilation without having to use the WebSocket transport module, and so on.\nAt RealtimeConf EU, Owen presented Prism, SocketStream's WebSocket transport effectively decoupled out of the stack. Soon after, ti was proposed that Prism should be replaced by Arnout Kazemier's Primus module. Then, a couple of months on, not much happened, and Owen was more involved in other projects, and so he looked for a new lead developer. \nNo changes to 0.4 have happened since Owen worked on Prism and handed over the project. \nI'm therefore coming to the view that socketstream-0.4 needs to be declared as abandonware. \nI don't want to do anything to the 0.4-related modules just yet, but I think that we'll want to keep the code available as a sandbox for things we can do in the 0.3 codebase. I will consider Romain's suggestion.\nWe can instead get to 0.4 by way of refactoring the code in 0.3, rather than rewriting it.\nOn a second note, I think that SocketStream is going to require more support than it gets, more than it got from AOL (who actually took developers away from it at the height of it's popularity... big company politics).\nI think that SocketStream requires a corporate sponsor, someone who is interested in Node.js, and is interested in SocketStream's potential, especially in advertising.\nLet me know your thoughts.\n. @arxpoetica You're welcome, it's important to incorporate feedback into the project. \nI think your suggestion WRT 0.5 makes sense, but no work can begin on the new version until the work on 0.3 is done.\n. The announcement has been made. Closing as a result.\n. This may be of interest https://github.com/socketstream/socketstream/issues/405\nIn terms of getting the assets to be packed to a relative reference, I have got them to be packed with a fixed filename before, but not in terms of getting a relative file reference. I take it you're trying to serve the JS/CSS via a CDN?\nAs for the engine.io path, that option exists here: https://github.com/socketstream/ss-engine.io#usage\nI'll look into this at some point. It's difficult to get time at the moment as I'm the only full-stack developer/sysadmin at work, and I've got 3 projects to deliver before I go on holiday to Thailand/Australia in March.\nI will try and see to this before then.\n. Hi,\nCan I ask how you've setup the index.html for serving, as well as how you boot the socketstream app?\nI remember Owen once saying that the html page has to be served at the same location as the socketstream server, you can't serve this from a CDN (sadly). \n. Hi,\nIt sounds similar to what David Zhang experienced when he was making an Android version of an app that was connecting to SocketStream: https://groups.google.com/forum/?pli=1#!topic/socketstream/CfDts_W3cZM\nIt sounds like the client is unable to handshake with the server, due to a lack of session id. Have you tried experimenting with enabled only long-polling, or just websockets when establishing the connection to your phonegap app?\n. If you want to remove the makefile as part of the PR, that would be great.\nOn 28 January 2014 14:54, RomanMinkin notifications@github.com wrote:\n\nHi @ignlg https://github.com/ignlg,\nThanks for dong that!\nFYI Makefile has been deprecated instead we are using grunt test for\nrunning tests. Checkout CONTRIBUTING.md#working-with-source-codehttps://github.com/socketstream/socketstream/blob/master/CONTRIBUTING.md#working-with-source-codefor detailed information.\np.s. Makefile should be removed, i do not know why we are still keeping\nit =)\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/427#issuecomment-33484841\n.\n\n\nPaul Jensen\n07914 171 345\n. :) - Thanks Ignacio.\nOn 28 January 2014 16:03, Ignacio Lago notifications@github.com wrote:\n\nAs it was there I thought that it should be maintained. Otherwise it's\ngarbage. Grabage day =)\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/427#issuecomment-33492409\n.\n\n\nPaul Jensen\n07914 171 345\n. Cool. \nIf we could theme it so it doesn't look like a defacto Bootstrap site, then that would be great. I'd be happy to port the theme from the new ss site to this. Once that's done, I'll switch the DNS.\n. On a side note, core now has admin privileges.\n. Hi Luksch,\nSorry I didn't address this last night. I'm here now. Could you provide some more information?\nWhen you say \"where each nodejs server sends all channel messages to all connected clients\", could you let me know these bits:\n1 - What kind of message you are sending \"ss.publish.all\", or on a specific channel that some clients are subscribed to.\n2 - Could you execute these commands, and then send the output from that command when you see this unexpected behaviour?\n```\nredis-cli\n\nMONITOR\n```\n\n3 - You say that you have 2 node instances on the same server. Are they using clustering, or are they both running independently?\nThanks. We'll figure out what's going on and then resolve it.\n. Hi Luksch,\nSorry for not replying earlier, work was very busy before I took my holiday (which I'm on now). I'm looking at it right now. I've got a repo here:\nhttps://github.com/socketstream/test-429\nWhat I'm going to do is replicate what you're doing, and then debug it.\n. Hi, \nI've pushed some updates to that repo. I would like it to effectively replicate what was going on in your case. It's not yet finished (it's causing on error on the client), but once it's done I will check with you if it replicates the issue that you're encountering.\nI'm sorry about how long it's taken to get back to you on all of this.\n. Hi @luksch,\nI managed to replicate the issue that you described. In the test-429 repo, the node app is setup to use Redis, and the app runs on port 3000, and you can make it run on another port by passing a PORT=3001 env variable before running it on the command line.\nWhat I did was run 2 instances of the app (ports 3000 and 3001), and have the client code subscribe to a channel and publish a message if the client was on port 3001. I then had the client log out any channel messages and data sent.\nWhat I found was that both web pages for 3000 and 3001 received the channel events and data, even though only the client on port 3001 was supposed to receive them.\nThank you for bringing this bug to my attention, and I'm very sorry that I haven't addressed it sooner.  I'm going to ascertain where in the stack the error is occurring, and fix this ASAP.\n. Hi @luksch,\nI've looked closer into this issue, and determined what is going on with it.\nAn important question - did you use the same web browser to view the app on ports 3000 and 3001?\nI did this, and when I used MONITOR in Redis and replicated the test, I realised that the session id across ports 3000 and 3001 were using the same session id. The sequence of events:\n1. Boot the app instances\n2. Load localhost:3000 on Chrome, you see this in Redis's MONITOR output:\n1397668855.297857 [4 127.0.0.1:49617] \"get\" \"sess:QZjauOQjvk+KQJSgajKU35Af\"\n1397668855.315888 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.460099 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.631572 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.651987 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.657819 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.663204 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.664853 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.682862 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.684663 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.752127 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.754217 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.825633 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.825706 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397668855.850876 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668855.851917 [4 127.0.0.1:49617] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668856.286425 [4 127.0.0.1:49617] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1. Load localhost:3001 on Firefox, you see this in Redis's MONITOR output:\n1397668940.799253 [4 127.0.0.1:49620] \"get\" \"sess:hGLo9zc24UVq5SrtPLPWh2Ng\"\n1397668940.819681 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.023671 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.030047 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.032372 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.037014 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.039049 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.039912 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.046075 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.047053 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.047944 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.050092 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.054008 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.056990 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.063100 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.064955 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397668941.405076 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.493249 [4 127.0.0.1:49620] \"get\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\"\n1397668941.501983 [4 127.0.0.1:49620] \"setex\" \"sess:kw+KJ/9V9j/UtKb/z6d9CnRI\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"channels\\\":[\\\"arbChannel\\\"]}\"\nTake a look at the values around sess:. You'll notice that they're different IDs.\nNow...\n1.  Load localhost:3001 on Chrome, you see this in Redis's MONITOR output:\n1397669085.636825 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.657687 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.775757 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.778843 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.845790 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.868078 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.869567 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.871450 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.873816 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.876063 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.886307 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.888882 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.912369 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.923943 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669085.940766 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669085.945730 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"}}\"\n1397669086.567125 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669086.631212 [4 127.0.0.1:49620] \"get\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\"\n1397669086.643265 [4 127.0.0.1:49620] \"setex\" \"sess:UpImTLP5vsBvoEdVSRO8qcCL\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"channels\\\":[\\\"arbChannel\\\"]}\"\nNotice that the sess: value for localhost:3001 is the same as the one on localhost:3000. Also notice how the session is now marked as having a channel subscription to 'arbChannel'?\nThis is what is happening. \nIs this a bug? Yes and No.\nNo, because on the one hand, both servers see the same session id, and both read/write to the same data source, hence being able to horizontally scale the web app instances whilst have them writing to the same data source.\nOn the other hand, yes, this is a bug. Do you want to have the same session id for localhost:3000 and localhost:3001? I imagine in your case not. This is what I need to look into further, because it's not straightforward to developers that this is what is happening, or what they wanted.\n. Hi @luksch,\nI'd like to pick this up again. Since we last spoke, I finished working at Axisto and started a company. I'm currently doing some client work as part of the new company.\nTo briefly explain the problem that you ran into, it looks like the trying to access a site on localhost:3000 and localhost:3001 returns the same session, hence both receive the same messages.\nA potential way to work around this issue would be to try and access the site from say 127.0.0.1:3001, so that you don't see the same session.\nI'm sorry that I've been off the radar for a couple of months. I had to serve 3 month's notice at my previous job, and I started work at a client site, taking over a rather large codebase with immediate issues to address and projects to begin. To say the least I've been inactive on matter regarding SocketStream.\n. I will have a look into this issue again.\n. I'll provide one later today, one I get a bit of time.\n. To add some context, my reply that was mentioned on Apr 16, 2014 should be revisited. I worked out what was going on, but I've yet to make the change so that you can configure the behaviour to work differently.\n. The channels are attached to the session id, and when you visit the site on localhost:3000 and localhost:3001 in the same browser, then both will load the same cookie, hence the same session id. \n. @evanlh Thanks you for contributing this PR.\n@RomanMinkin Thank you for taking a look at it.\nI'm sorry I haven't responded to this earlier, work has taken over my life and will continue to do so for the next 3 weeks. \nI'll have a look at the PR code and offer any feedback that hasn't been made already.\n. Thanks @RomanMinkin. I'm starting to think that the 2nd event parameter is a YAGNI, and that we should remove it, plus cleanup the calls from watcher.on to it.\nBasically do what @evanlh did originally (apologies for the circling). \nThoughts?\n. On a side note, with that taken care of, this feature branch looks good to merge.\n. Hi,\nI've tried replicating this error on Dashku's staging server, but it didn't occur.\nHas anyone else encountered this issue?\n. No, Linode.\nDo we have this error occurring on another SocketStream app hosted on\nNodejitsu?\nIt would be good to determine if it is a hosting-specific issue or an\napplication-specific issue.\nOn 13 February 2014 10:20, Wylie Joshua.Cullick notifications@github.comwrote:\n\nDashku is on AWS right?\nOn Thu, Feb 13, 2014 at 11:38 AM, Paul Jensen notifications@github.comwrote:\n\nHi,\nI've tried replicating this error on Dashku's staging server, but it\ndidn't occur.\nHas anyone else encountered this issue?\n\nReply to this email directly or view it on GitHub<\nhttps://github.com/socketstream/socketstream/pull/430#issuecomment-34961990>\n.\n\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-34965186\n.\n\n\nPaul Jensen\n07914 171 345\n. Hi Wylie, thanks for the update. What are the Heroku issues?\n. Hi Wylie, \nAre you using Heroku's websocket support?\nPreviously, we had to use long-polling to handle working with heroku, as Heroku does not support sticky-sessions. See this link: https://coderwall.com/p/h2swda\n. Hi Roman,\nOk. Just for your info, 0.1 and 0.2 are old, deprecated versions of\nSocketStream, as 0.3 was a rewrite of 0.2, and introduced breaking changes.\nOn 5 February 2014 16:02, RomanMinkin notifications@github.com wrote:\n\nHi Paul,\nIf you do not mind I'm going to convert old as mammoths 0.1, 0.2 branches\ninto 0.1.0 and 0.2.0 tags.\nSo the actual branches space would be clear from versions. And all the\nversions will be in their place.\np.s. I actually ready all I need to make a push =)\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/431\n.\n\n\nPaul Jensen\n07914 171 345\n. Cross-linking this comment https://github.com/socketstream/socketstream/pull/430#issuecomment-34961990\n. Hi @kulicuu,\nCould you let me know if you're still experiencing this issue?\nThanks.\n. Cool, I think I'll keep this open to investigate the cause of the Nodejitsu issue at a later time.\n. Hi @kulicuu,\nThanks for your info. Are you using any logging modules in your app, or making any specific calls relating to logging?\nI've tested the master version of SS against Dashku with no issues reported. I will test this against VMUX as well to see if this is happening elsewhere.\n. Ok, I'm going to be judge, jury, and executioner on this one.\n. I can recommend using Nginx to handle HTTPS traffic, and that's how Dashku\nhandles it.\nI've used Forever before in the past, but these days I use upstart scripts\n- they are setup to boot services in case your machine is rebooted.\nOn 17 February 2014 18:38, Wylie Joshua.Cullick notifications@github.comwrote:\n\nOff-topic :: but on subject of SS deploys to Linode :: Thoughts on custom\nNginx front vs something like Forever/-> PM2 or even Phusion Passenger ?\nI'm halfway in between the latter two : PM2 handling pretty raw SS (https\nimplemented in the app file) but also testing out Phusion, which is\ninteresting.\nOn Mon, Feb 17, 2014 at 8:34 PM, Paul Jensen notifications@github.comwrote:\n\nMerged #434 https://github.com/socketstream/socketstream/pull/434.\n\nReply to this email directly or view it on GitHub<\nhttps://github.com/socketstream/socketstream/pull/434>\n.\n\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/434#issuecomment-35311162\n.\n\n\nPaul Jensen\n07914 171 345\n. Hi,\nI've recently had to update engine.io as part of chassis.io (an engine.io wrapper library), but I haven't got round to sorting it out in SocketStream (yet). I welcome any efforts to help out with this.\nWRT the client change, https://github.com/socketstream/socketstream/pull/360 may be of interest.\n. Thanks @kulicuu, I appreciate the help.\n. Hi,\nIt's on my radar. I've been through the list of dependencies that SocketStream has, and upgrading them 1-by-1 (after what was a long time where nothing was updated).\nI'm currently getting the UglifyJS dependency up-to-date, but then engine.io, along with connect and connect-redis are next in line.\nI'm sorry that it's been sidelined for so long, admittedly I had a difficult time trying to manage my work/life balance for the 1st half of the year, and it took it's toll, including on looking after this. \n. Thanks @kulicuu, absolutely fine to document notes in the thread.\n. Hi,\nThanks for your contribution, I'll have a look at 5pm today (sorry for the delay, I'm in a rush to hand off items before I go on holiday next week).\nRegards,\nPaul Jensen\n. Thanks for this.\n. @Waxolunist I know the feeling (minus babies), congratulations.\nI'm currently on holiday in Australia until Friday, I will catchup on this over the weekend.\n. Hi @Waxolunist,\nSorry about the lengthy delay on getting back to this - I had a great holiday, followed by a very busy few weeks following (in fact I had to work towards the end of my holiday).\nThe points you raised are very valid - the client-side pipeline workflow is nice, but it's opinionated approach makes it difficult to work with package managers like bower and component.io.\nI've recently used Gulp at work for a desktop application, and I think that it is a brilliant tool for client-side development - I think that there is potential for it to be a client-side replacement to SocketStream's client-side part.\nIn order to do that though, we need to take a good look at the framework, and begin the work of getting to the vision of 0.4, by way of refactoring 0.3.\nI want to make it possible for SocketStream to be used in a more modular fashion - such as being able to make use of the RPC/PubSub features without requiring the client-side part, as well as being able to build the client-side assets without having to boot the whole app.\nThese are things I'm going to be looking at this week.\n. I agree that SocketStream needs an updated mission statement. I want SocketStream to be the best framework for creating Realtime Web Apps - it's a lofty ambition, but a worthy one.\nThe focus of the past 18 months has been to listen to the community and to stabilise the project. I think that goal isn't yet complete, but is close. There are libraries to upgrade, tests to write, documentation to add, and a general need to grow the community to support those steps. There is no way that 1 person can do this by themselves, as I have found out the hard way this year.\nEventually, I would like to get to the goals of 0.4 by way of refactoring 0.3, once tests and documentation are in place. I don't know how long it will take, but my company (Anephenix) is going to commercially sponsor work on SocketStream to get this done. I'm currently working for a major client in London, so my time is extremely limited.\nI still have a lot of passion for SocketStream, and I want to see it succeed, in fact it's one of the reasons why Anephenix exists.\nWith regards to r.js, I do find that I prefer Browserify's approach - RequireJS' approach at times feels rather weird. That said, the asset pipeline of SocketStream has room for improvement. There is a need to make it handle unknown file formats better (as was the case with .map files), and to make it work better with bower components/ client-side node_modules.\n. Thanks for the PR @mmalecki.\nIn my opinion, it would make sense to put it in test/unit/http/index.test.js, but if you have an alternative file path, I'm open to hearing it.\n. I've used this library in the past to mock apis for a set of tests within a file https://github.com/felixge/node-gently\nUsing this with a combination of before/after hooks in Mocha will allow us to mock the cookie parser middleware, and then set it back to normal after the test has run.\nThat said, we could put the tests in a separate file for now, and at a later time move them into the index.test.js file using Mocha's hooks and Node Gently (if required).\n. Having tried (and failed) to mock it out in index.test.js, I'm going to try and put it in a separate test file. Sorry this has taken longer than intended.\n. I've forked a branch containing tests, they are a work in progress.\nhttps://github.com/socketstream/socketstream/tree/mmalecki-cookie-secret-tests\nTrying to isolate the call to connect's cookieParser middleware with Gently isn't working. I want to get it passing.\n. No worries Maciej, I'll find a way.\nOn a side note, if you have some thoughts regarding the pain points you encountered with working with SocketStream, I'd be happy to take a look into it.\n. I wrestled with getting tests to intercept the cookie parser secret, but didn't crack it. I will do eventually, but in light of things I felt it would be better to get this feature in now than to delay it any further. Thanks for the commit.\n. Yep, it doesn't. I had to use Fedor Indutny's sticky module to be able to\ndo this (with a clustered express app) - https://github.com/indutny/sticky\nOn 2 April 2014 15:46, Wylie Joshua.Cullick notifications@github.comwrote:\n\nMaybe it's because NodeJS cluster module no do sticky sessions.\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/441#issuecomment-39338970\n.\n\n\nPaul Jensen\n07914 171 345\n. Apologies, this is the link to the repo\nhttps://github.com/indutny/sticky-session\nOn 2 April 2014 15:58, Paul Jensen paulbjensen@gmail.com wrote:\n\nYep, it doesn't. I had to use Fedor Indutny's sticky module to be able to\ndo this (with a clustered express app) - https://github.com/indutny/sticky\nOn 2 April 2014 15:46, Wylie Joshua.Cullick notifications@github.comwrote:\n\nMaybe it's because NodeJS cluster module no do sticky sessions.\n\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/441#issuecomment-39338970\n.\n\n\nPaul Jensen\n07914 171 345\n\n\nPaul Jensen\n07914 171 345\n. You could try it on a staging box, fire up a linode, try it, see if it works. If it does, use that and power down the Linode (they now offer a metered billing option too).\n. I've heard of JSON web tokens before, I'm definitely keen to explore using them as an alternative to sticky sessions for hosting app instances across multiple servers.\n. At the moment, the reason to use sticky-sessions is because of the way that engine.io stores state when handling the handshake for establishing a connection - if there was a way to share that state across multiple Node processes, then sticky-sessions could be ditched.\nI think that cookies will eventually become irrelevant - the DoNotTrack feature that was proposed in IE and Firefox is a signal of what's to come, as well as the fact that Google and Facebook have already started tracking users via other methods.\nI see JSON web tokens as offering a way to authenticate requests, regardless of whether the client is a web browser, or a server-side process. I think that unifying this could offer exciting possibilities:\n- We could write an API for authenticating requests once, and have it used by both the server-side REPL, a REST API for 3rd-party clients, and an RPC API for client-side consumption.\n- We don't have to do any form of sticky-sessions in front of the app instances - scaling is simply a matter of round-robin load balancing in front of multiple servers.\n. This blog post has a brilliant answer to your question regarding the benefits of using tokens compared to cookies for authentication: https://auth0.com/blog/2014/01/07/angularjs-authentication-with-cookies-vs-token/\n. Hi, is this still an issue or has it been solved?\n. Cool. We can add a ss-socket.io transport wrapper library module once 1.0.0-pre2 is released.\n. To add context, the first version of SocketStream used Socket.io as the Websocket transport library. Over time, a drop-in replacement using SockJS was also added, which was a superb library (and was used in Dashku at the time), as there were some problems with using Socket.io as the transport library. There was even an experimental Pusher wrapper, but that didn't go anywhere.\nDue to supporting Dashku's use at Bechtel, I took up the task of trying to ensure that a disconnected WebSocket connection would be re-established from the client (i.e. losing mobile signal results in a severed connection), and my research at the time pointed to Engine.io, which was Socket.io's WebSocket connection library and nothing else. I ended up creating ss-engine.io as a result, and managed to get the library to replace Socket.io in SocketStream as the default WebSocket transport library.\nIn terms of the roadmap for Engine.io and Socket.io, the idea is that Engine.io will eventually find it's way back in Socket.io 1.0. I'm glad that Guillermo is close to achieving that goal.\n. @arxpoetica Is there an action to follow from this issue? I'm tempted to close it for now, and when someone makes a wrapper for 1.0, then we can take of it there.\n. There's a way in Socket.io/Engine.io to detect the Websocket 'close' event, and this is triggered when:\n- a user closes their browser tab/window on the desktop\n- a user closes the web browser application (Safari) on iOS\n- ~ 30 seconds after a user locks their iOS device\nIs there a way to expose this event in SocketStream's websocket transport library? Good question, I'll check now. If it is, great, otherwise if not, then I think it's something that SocketStream should not obscure access to, so it would be added via PR.\nI'll check now.\n. If you have a stacktrace, I'd be happy to take a look, my email is paul@socketstream.com\nI found a line in ss-engine.io which refers to the socket 'close' event:\nhttps://github.com/socketstream/ss-engine.io/blob/master/lib/index.js#L147\nAt the moment, it removes the socket from the list of sockets that are open. If we can expose access to the socket object from SS, then we can bind another function on that event as well.\n. Hi @kulicuu,\nI noticed that you mentioned a controller called globalState. Does this state need to handled at an application instance level, or across all application instances?\n. Hi @kulicuu,\nI'm using the sticky-session with a work app in production, but not Dashku, so it's use with SocketStream is fairly new territory.\nI learned last year that booting a Node HTTP server takes ~50ms, A connect one ~120ms - this compelled me to take a look at ways in which the bootstrapping process of apps could be slowed down, and ways in which to optimise the process. Unfortunately all of that knowledge wasn't written, and I've had so much to take care of in the last 5 months that I can't remember it.\nI'll take a look into running Dashku with sticky-session to see if I can spot any gotchas.\n. Hi @pygy, I've updated the readme here: https://github.com/socketstream/socketstream/commit/713d3d1bff2f1399412b281ae3ca69281307a3f7\n. Please see https://github.com/socketstream/ss-home/pull/1\n. Yep, in fact I ought to overhaul the entire readme - it needs a lot of updating.\n. Hi,\nI managed to do this in Dashku, the code is here: https://github.com/anephenix/dashku\nThe answer lies in using either a) Express with SocketStream or b) Connect-router middleware with SocketStream.\nIf you have a look at this file: https://github.com/anephenix/dashku/blob/master/app.js\nOn Line 7 I require the connect-route npm module,\nOn Line 24 I requre Dashku's REST API\nOn Line 30 I prepend the connect middleware loading the API\nNow let's have a look at the api file, here: https://github.com/anephenix/dashku/blob/master/server/api.js\nLine 164 is of interest, here I provide a route that let's you download files (for sending data to widgets).\nNow let's look at the scriptDownloader file here: https://github.com/anephenix/dashku/blob/master/server/scriptDownloader.js\nLine 52 shows us a function that is used for downloading a file containing custom values.\nLines 56-58 are the ones that you will be interested in, here: https://github.com/anephenix/dashku/blob/master/server/scriptDownloader.js#L56-L58\nThey provides the headers needed to tell the browser to download the file.\nI might be wrong, but I think that when calling ss.http.route, you might be able to just use the lines shown on L56-L58 in scriptDownloader.js within that route, and it would give you what you're after.\nLet me know if that helps, or if you need any other help. Paul\n. @EricCat You're welcome, I'm glad to help.\n. Hi @EricCat,\nHave you tried using this in place of res.download?\nres.get(path, function (req, res) {\n    var data = \"data to download\";\n    res.writeHead(200, { 'Content-disposition': 'attachment', 'Content-Type': 'text/plain' });\nres.end(data);\n};\n. Hi @EricCat,\nWhere does the file containing that bit of code exist?\nIf it's in /server/rpc, then it won't work. It will need to be loaded as a connect middleware from the main app.js file. \n. Thanks @EricCat,\nI think that the reason it's not working is because you can't load connect routes from files inside of the rpc folder.\nCould you try and put the req.get part of the code in the app.js file, so that the app.js file has this bit of code in it:\nss.http.middleware.append(connectRoute(function(router){\n    router.get('/', passport.authenticate('basic', {session: true}));\n    router.get('/myFile, function (req, res) {\n        var data = \"data to download\";\n        res.writeHead(200, { 'Content-disposition': 'attachment', 'Content-Type': 'text/plain' });\n        res.end(data);        \n    });\n}));\n. Hi @kulicuu,\nIdeally it would be good to get them all linted under strict mode, but I think I'll need to revisit that file. Apologies for being inactive of recent.\nI think it would be good to rework the code to get this to pass.\n. Closed. Thanks @kulicuu, I'm sorry that it took as long as it did to merge. I've been busy of recent; changed job and moved house within the last month, and moving again next week. \n. Hi @kulicuu,\nThanks for the work. I'm open to considering using connect-redis by default (though it would require anyone trying SocketStream to have Redis installed and running).\nAs for the other modules, I say we can try them all, and see which ones work the best.\n. I think that's a fair point - the default memory store isn't a scalable option, but it does allow people to get started quickly without having to install and start Redis.\n. I had a longer think about it. In truth there is a case for both; in one case you're optimising for someone new to SocketStream, and in the other case, you're optimising for someone who is going to put a SocketStream app into production.\nIn the former's case, you're giving them 2 less steps to jump through (not having to have Redis installed, and to not have it running before you run an app).\nIn the latter's case, you're taking away those steps, on the basis that they will want to use Redis. It does provide a key requirement to scaling the app to run across multiple instances (as well as to withstand instances being restarted).\nIt ultimately comes down to 2 things: What should be part of SocketStream's core, and what should not? and a 2nd thing: how does that technology choice impact the user? \nThe question of what should be part of SocketStream's core is a pertinent one. We've learnt that having the framework written in CoffeeScript was a choice that alienated some from both using and/or contributing to the project. Personally I loved CoffeeScript, but not everyone feels the same.\nSo Redis being part of SocketStream's core. True, you'll want to use it when you put a SocketStream app into production, as you would if you put an Express app into production. But Express does not mandate that you install Redis in order to run connect. Instead, there is the connect-redis node module for that, along with alternatives that use Mongo or CouchDB instead of Redis for session storage.\nAnd that's the thing; Redis is a personal choice. Again I use it for work and it's been fine in my uses cases, but I can't guarantee that everyone who uses SocketStream will be the same.\nI feel your frustration @kulicuu - I was in a similar position of having to reduce work on Open Source when I was managing multiple projects at my previous job during the peak time of the year. I'll be happy to talk more offline.\nI will close the issue.\n. I think @owenb wrote that comment. I think that the idea was to use events to trigger multiple actions.\n. @owenb would be the best person to ask regarding the intent around the comment, I can only infer its meaning.\n. This feels like something to consider for 0.4\n. Hi @klausb, thanks for filing the issue.\nI've seen an option in SockJS to enable the use of JSESSIONID for load-balancing purposes, and there is a transport wrapper for it with SocketStream: https://github.com/socketstream/ss-sockjs, the only thing is that I think the reconnection logic is not yet in it, but it might be worth trying.\nI'll look into updating the ss-sockjs library with the reconnection logic I put into ss-engine.io and SocketStream last year.\n. Not yet sadly, but I think it should be a consideration for 0.4\n. I'll try and get a look into it tonight. Thanks for your work, I'm sorry I\nhaven't been as active recently.\nRegards,\nPaul Jensen\nOn 3 March 2015 at 17:50, Henrik Vendelbo notifications@github.com wrote:\n\n@paulbjensen https://github.com/paulbjensen Could you have a look at\nthe next branch and see how you like the option to use relative\ndependencies in client defs.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/455#issuecomment-76996748\n.\n\n\nPaul Jensen\n07914 171 345\n. Hi @thepian,\nI'll look into it.\n. Hi @thepian,\nI'd be happy to accept a PR with those changes.\n. Hi @thepian,\nI've been looking at another ticket about separating out JS and CSS tags in the generated html, for the reasons you suggested. The GH issue is here: https://github.com/socketstream/socketstream/pull/355\nI will probably need to close that PR and extract it out into a new PR due to the number of changes since the PR was originally filed.\n. Hi Ian,\nI like the site background, but I take your point on board. I would be open to a pull request - I can describe how to generate the docs and tinker with the CSS if you like.\n. Cool, there's a section on documentation generation here: https://github.com/socketstream/socketstream/blob/master/CONTRIBUTING.md#documentation-generation\nThe docs/css/main.css contains the relevant css to modify. When you're happy, submit a PR and I'll take a look and merge. Thanks.\n. Closing as merged\n. Thanks @polpo, I've merged that in and will update the docs in a minute.\n. I changed the CSS stylesheet to be more readable for those who have red-green color-blindness.\n. Thanks @thepian, I'll take a look at it later on today.\n. Thanks for this.\n. Hi @thepian, that's correct, Owen embedded a portion of the code from Browserify to support how SocketStream handles client-side dependency management.\nIt would definitely be nice to abstract that portion of the code out, making SocketStream more modular and therefore easier to maintain. The plugin option would help work towards some of the goals that Owen had for 0.4, but I'm happy to consider the alternative as well - we're currently using a very old version of Browserify in SocketStream, it's due an upgrade.\n. Henrik is right, the way that SocketStream handles compiling and serving assets is deeply ingrained in the framework, and changing it is a big job.\nHenrik's solution is a good way to achieve it, as it moves closer to the vision of making SocketStream mode modular.\n. I'm not sure if this should be a 0.3.12 or 0.4 concern, any thoughts?\n. I did consider this idea, about a year ago when I was toying with a new framework concept (outside of SocketStream). It turns out that you can close/open HTTP servers in Node quite easily, and this would allow some kind of auto-reloading based on server code updating.\nAt the moment, the closest available solution is to use nodemon with SocketStream.\n. Hi @louh,\nHow are you specifying these routes server-side (with Express)?\nIf I understand correctly, you need the SocketStream app to allow some routes to serve JSON, instead of   the SocketStream app?\n. Hi @louh,\nI embedded a REST API into Dashku by using the connect-route node module, using ss.http.middleware.prepend as demonstrated on this line: https://github.com/Anephenix/dashku/blob/master/app.js#L31\nWhich then loads this: https://github.com/Anephenix/dashku/blob/master/server/api.js#L60\nHere is a link to the node module: https://github.com/baryshev/connect-route\nAs for the ability to get Davis.js to ignore the path, there is a way: https://github.com/olivernn/davis.js/issues/30\n. Hi @louh,\nWere my suggestions what you were after?\n. No worries, glad to hear it worked.\n. Hi @louh, is it ok for me to mark the issue as resolved?\n. Thanks for your input so far, some good suggestions and I'd like to get some of these turned into concrete features for SocketStream.\nI've seen some projects use Trello for this sort of thing, so I've taken @arxpoetica's suggestion and created a Trello board here: https://trello.com/b/3ufvApqM/socketstream. I'll invite all of you to the board tomorrow morning.\nI'll add more tomorrow, but I need to sleep now.\n. I've made invites. Feel free to put features in there, then we can arrange them in order of most desired features first.\nAt work so will provide more thoughts later.\n. Thanks for organising the trello board, and for taking the ideas put forward here and putting them into the board.\nWhen Owen demoed Prism back at RealtimeConf EU last year, he eventually saw Arnout Kazemier's Primus, and concluded that it could be better to switch to using that instead.\nOriginally when I took over the lead developer role, my plan was to advance both 0.4 and maintain 0.3. I eventually gave up on doing that for these reasons:\n- Users did not like the fact that the reset button kept being pushed on the framework, with features that had existed in previous versions of the framework being removed.\n- People were in limbo between waiting for 0.4 to arrive or continuing to work with (earmarked for deprecation) 0.3. Some people with 0.3 apps in production also felt a bit concerned that they were building on top of abandonware.\n- To build 0.4 at the same time as maintaining 0.3 would have required more time than I alone could provide. This has been the most difficult lesson I've learnt in managing the project.\nI therefore chose to focus on working on 0.3, and get to the goals of 0.4 by way of refactoring 0.3.\nBut, playing devil's advocate, if there was a period of 6 months dedicated to a complete rewrite of SocketStream; one where everything was tested properly, where existing features were complete, where the framework was more modular in design, and where updating 0.3 apps to 0.4 involved minimal pain, would that be something that the team would be interested in considering?\n. @arxpoetica yep, that's sorted now.\nThanks for all of the discussion. I think that a team-based approach will work, and hopefully will speed up the project progress by eliminating a dependency on a single person (me) to do things. I'll add you all to the core team, and that will allow you to make commits/changes among other things. Next after that will be making the website available to all to modify.\n. Added the ss-home repo as well (which contains the site). I'll need ssh public keys from you chaps to add to the server which serves socketstream.com.\n. @kulicuu @arxpoetica Thanks, will install them at some point today.\n. WebRTC is very cool for P2P data transfer and transmission. Say you were building a game, I could see a case for building a plugin to support a multiplayer feature for a game, where sending data between the 2 players would be better than sending it through a central server.\nI would resist adding a technology without having a real business need behind it. Find the need first, then that will help shape how to build that plugin.\n. Apologies for the delay in replying. I can do weekends.\n. Ok, I can do January 3rd/4th if that works for others.\n. Would 1100 UTC work for everyone? \n. Seems cool, speak tomorrow.\n. You can add ?video=off to the url in order to disable video (screen sharing will still work).\n. http://appear.in/socketstream\n. Have you chaps been able to join?\n. Try again.\n. Ok, we're going to try a google hangout, will send invites via email\n. @thepian Sorry you didn't get to be on the call, next time. As for your requests, the 1st wish is intended, but not easy to do (SS uses a modified early copy of Browserify, so this is going to be a bit tricky), and as for the 2nd wish, there is a plan to upgrade connect, which should allow using express 4 to happen.\n. Hi @thepian, so I understand it better, is it that you can't access the SocketStream view for /switzerland, because you have a route defined for /switzerland/as-pdf.html?\n. Ok, I'll try and replicate it with a test app, and see what's going on.\n. Thanks, can't believe I mistyped 'synonymous' (though I put it down to a keyboard error ;) )\n. @thepian Sorry I didn't respond earlier, I'm currently in Reykjavik on holiday. Thanks for the PR and doing the merge, it's so much better than waiting on me. \n. I'm going to mark 0.3.11 as finished (as it technically shipped), and put this into the next minor (0.3.12)\n. Hi, Thanks for filing the issue. I'll take a look into it.\n. Hi @greenpdx,\nI had a look at the issue that you mentioned. I haven't been able to replicate the error that you encountered.\nCan I check the following? \n- That you generated a new SocketStream app with default settings\n- What version of Node.js you are using (I am using 0.10.35)\n- That the server/middleware/example.js file exists, and returns a function.\n- That you uncommented line 10 in server/rpc/demo.js\nRegards,\nPaul Jensen\n. Hi, thanks for identifying more info about why it occurred. Does the issue still happen when running node-debug?\n. I checked it with node debug app.js, it's working. Marking as closed.\n. Thanks, done\n. I think this would be worth separating out for 0.4, so that SocketStream's codebase becomes a bit more manageable.\n. Thanks, I'll look into it.\n. Agreed.\n. That looks like a line that is inspecting the version of Node.js to see if it is version 0.6.\nThe line can be simplified to require('fs'), and rename the variable to 'fs'.\n. Cool, will close this, and wait to get it in when the PR is merged. \n. Hi Henrik,\nYep, it was a result of converting the code over from CoffeeScript, hence there is room to optimise the codebase.\n. Done, created.\n. I'd suggest \"next\" in honour of Steve Jobs.\nOn 3 February 2015 at 16:59, Henrik Vendelbo notifications@github.com\nwrote:\n\nThanks. How about the idea of having a separate branch used for the next\nmajor release? I'm not sure what name to suggest\n- future\n- major\n- next\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/483#issuecomment-72688723\n.\n\n\nPaul Jensen\n07914 171 345\n. yep, let's do this.\n. I'll try and take a look into this tonight.\n. I merged a PR from @lafras-h about 1-2 weeks ago, which I tested manually and it works but I don't think it added any automated tests.\nThis can be marked as closed, and as for automated tests, I can take a look into it.\n. If you want routing, it's possible to deliver it as connect middleware, and not require express at all. Originally it was in connect's core, but then pulled out, and then someone turned it into a middleware you loads via npm. That's how I got Dashku to work alongside loading a REST API as well.\nI think maybe some documentation around how to do this would be useful.\nShould we look to support other options? Perhaps. In my experimentation with the core http server about a year ago, I stumbled across a more efficient level of support for routing than using connect. It was a project named 'vorka', I'd be happy to pull it up and have a look at it.\n. I didn't put it on Github, I'll dig it out from my disk backup and post it.\n. Thanks Henrik, I'll try and test them tonight (I know I said that 2 nights ago on another issue, sorry, it's been a busy few days).\n. @thepian hi Henrik, yes, it makes things simpler.\n. I'll have a look tonight.\n. In my experience with git submodules (a commercial project with Vodafone), they're a world of pain, because they complicate how you manage the code. You have to synchronise multiple git repos, and ensure that changes in git submodule folders do not end up getting tracked and pulled in by the local main repo. I would recommend avoiding them.\nIn my experience with e2e testing, I've resorted to using Cucumber and a combination of selenium-launcher and soda to test web apps end to end. As for a web framework, the framework was never originally tested, and so the question of how to do e2e testing on it will need some thinking.\n. Agreed. I think the challenge here is to get the ss variable to be passed and loaded into the various other places where console.log is being called. It will require some internal rewiring in order to achieve that. \n. This sounds like a good change. Please proceed.\n. Hi, Thanks for the PR. If you could make the changes as suggested by Codacy, then I'll take a look and merge it in. Thanks. \n. Hi, \nIs the delayTime attribute meant to delay executing the next reload? I tried this code snippet in my app, but it didn't seem to slow down when reloads were executed:\nss.client.set({\n    onChange: { \n        delayTime:5000,\n        guardTime:8000,\n        validate: function (path, event,action) {\n            console.log('onChangeValidate :', path);\n            return true;\n        },\n        publish:function (path, event,action,pubs) { \n            console.log('onChange.Publish :', action);\n            //modify pubs if needed return null to not send any pubs\n            return pubs;\n        }\n    }\n});\n. My apologies, I forgot to link the test app to the cloned version of SocketStream containing your feature branch. It works, thank you.\nI'm happy to merge it in now, and will add an item to the documentation to describe how to use the feature.\nThanks for your work.\n. @thepian that's fine, please go ahead.\n. It's a Code Coverage service which monitors code coverage % on your repos. If you integrate it with your Github repo then it will check commits and post the results to the comments section in the PR. \n. Cool - please go ahead.\n. At the start of the project and to this day SocketStream followed a pattern of 0. being major updates (i.e. Owen rewriting it and making big changes), which goes against the convention of .0 being major updates.\nIf we want to switch to .0, then we need to look at what would be a major update to SocketStream, as well as when we'd want to classify SocketStream as stable. During the time I've been looking after the project, I chose to focus on making the 0.3 branch stable rather than rewrite the framework as Owen planned to with SocketStream-0.4.\nI think that with some of the new features that have been added, 0.4 should be the next stage of minor updates, and 1.0 should be when the project is considered stable.\nStable in my opinion would be the following:\n- Good code coverage\n- Good documentation\n- 0 bug issues on GH (just feature requests and queries)\nTutorials and example apps would be nice, but are not a deal-breaker.\nWe would also need to communicate this change to the community, as they've been used to the existing pattern of updates.\nOn a side note, I just want to express my thanks to all of you for your recent work with SocketStream, I appreciate it.\n. Try ss.api.db instead of ss.db when trying to access the api from the server/rpc/example.js file, which is basically what @kulicuu recommended (sorry I haven't had coffee yet).\n. The docs are generated by a grunt task, and pushed up to the gh-pages branch on Github.\nThe reason that the docs were put with the code is because they generate documentation from the code comments. Here is an example: http://socketstream.github.io/socketstream/docs/#/api/http.index:index\n. @thepian I'll take a look now\n. Yeah, I think that there was a plan to change that line as Node 0.6 is beyond what we'd look to support today.\nThanks for spotting it. I'll see if we can change it quickly.\n. @thepian yes, absolutely fine with me. WRT publishing to npm, what is your handle on npm - so I can add you as an author to be able to do publishing.\n. Thanks, I've added you to the npm so you can publish updates.\n. Thanks @arxpoetica. Yeah markdown is still a great way to do docs.\nLooking at the thread, I agree with @thepian that getting articles on SocketStream would have a big impact on growing the community. I'd like to assist but time is of short supply for the next 2 months at least (finishing client work and writing book).\nId also like to get the SocketStream Twitter account in more hands - I looked at Buffer to manage this but was wondering if there are any other tools that can do the same thing (teams accessing social media accounts), I also looked at Hootsuite. If anyone sees anything then please let me know.\n. I'm ok with either approach. If we want to use 1 var per line, we'll need to modify the value of \"onevar\" in the .jshintrc file to false.\n. I had an idea this morning of moving the code in the lib/cli folder into its own npm module. This would allow us to reuse the logic in a Yeoman generator, as well as reduce the amount of code that SocketStream contains (new_project could move into the ss-generator npm). The idea would then be to have this ss-generator npm be included in socketstream and support it's cli commands, but the files and logic is within the npm module.\nI extracted the lib/cli folder, new_project and its tests into a separate folder, and it's gone fine so far (it's quite nicely isolated from the rest of the codebase).\nI can push up a copy to github if it seems like a good way to go forward?\n. Here is the repo: https://github.com/socketstream/ss-generator.\nOnce I've resolved all the issues, I'll create a feature branch of SocketStream where ss-generator is used in place of the lib/cli code.\n. They should - there's some code that needs reorganising and the new_project folder is a good case. Since ss-generator has it's own copy we don't need it for that, but there are some tests which depend on it. What we can do is make another commit to revert the accidental file deletion, as well as remove the new_project folder, and change existing tests to use it in the test/fixtures folder. \n. The PR has some fix commits in that are a bit messy. I'll close the PR and make a new one following the suggested branch procedure.\n. It's possible that this could be moved out, in fact SocketStream originally had socket.io as the bundled library, which could be swapped out with engine.io via ss-engine.io or sockjs with ss-sockjs.\nss-engine.io hasn't been updated in a while, but could be updated and thus the code for web sockets is loaded that way, rather than being inside the core of SocketStream.\n. @thepian Any idea why the client.formatters.test file is failing? https://travis-ci.org/socketstream/socketstream/jobs/61007693. I do see this happen intermittently when running the tests on my laptop (1 in every 4/5 test runs).\n. Ah, sorry, was meant to be in next\n. Closed this and opened a new one for merging into \"next\" here #536.\nI managed to replicate the error again on my machine but on test/unit/client/index.test.js#L138. It looks like the client.packAssets and client.load function calls are synchronous, but the files might still be in the process of being generated, and so the attempts to read the packed asset files fail.\nThe quick workaround is to put some fs.exists calls in the code and to wait until all files exist, but I think that the better approach would be to make asset packing support a callback when it has finished generating the files. I'll have a look at the code and see if this is feasible. Let me know your thoughts.\n. This seems to be failing on a test that is unrelated to the CLI:\n1) code formatter loading API #call should support alternate extensions:\n      AssertionError: expected '// couldn\\'t format ./abc/index.a issue=1431377849247' to be 'require.define(\"/abc/index\",function(e,t,n,r,i){window.a=\"formatter index.a\"})'\n      + expected - actual\n      +require.define(\"/abc/index\",function(e,t,n,r,i){window.a=\"formatter index.a\"})\n      -// couldn't format ./abc/index.a issue=1431377849247\nIs this fixed in master? If so, we can pull in those commits and try again.\n. Hi Henrik, it seems to happen when running Travis CI. I can also sometimes get failing tests on the master branch when I run the tests ~ 4/5 times - 1 test run eventually fails.\n. This is a bug, we'll fix it shortly.\nOn 8 May 2015 at 09:36, Ilya Dorman notifications@github.com wrote:\n\nWhen doing socketstream new  I get a 0.3.12 app and the SS in\npackage.json is also 0.3.12. Why not 0.4.2?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/538.\n\n\nPaul Jensen\n07914 171 345\n. It is - https://github.com/socketstream/socketstream/blob/master/lib/cli/generate.js#L183\nWe can change that so it reads it from the package.json file.\n. Hi @arxpoetica, I'm afraid not, but the good news is that I'll be in a very good position to take a look next week; I finish with the client next week, so that leaves only the book plus getting ready to move to Amsterdam on my todo list, meaning plenty of time for other items.\n. When trying this branch with Dashku's integration tests, Dashku is able to boot up, but we've now noticed that the ss.tmpl objects all begin with 'templates-' at the front, was this a deliberate change?\n. Yep, I'll take a look. I'll also provide a few more details relating to the behaviour I saw in Dashku.\n. I think I know what is happening now, some explanation.\nIf you checkout a copy of Dashku from here: https://github.com/dashku/dashku, then after running npm install, you run npm link to get Dashku to load a local copy of the Socketstream repo rather than the version specified in package.json, like so:\nnpm link PATH_TO_SOCKETSTREAM_REPO\nAfter doing that, once you've got mongodb and redis running, run npm start, and visit localhost:3000. You should see something like this:\n\nIf you open your inspector, on the console panel you'll see this:\n\nIf you run ss.tmpl in the inspector console panel, you should see this:\n\nAll of the Hogan.js templates in ss.tmpl begin with 'templates-' at the front of them. All of those Hogan.js template files live in the client/templates folder. I think that this might be linked. \n. Fantastic, thanks @thepian.\n. run npm test on the command line.\n. Once I get my chapter submitted and another book meeting done, this item is next on my todo list.\n. Hi @hulmgulm, thanks for the detailed bug info. What version of SS are you using?\nSocketStream is meant to allow both HTTP and WS to access the same cookie, so this sounds like a bug, possibly linked to the engine.io upgrade but that is more of a hunch than anything. I will take a look when I get the chance; I'm finishing work at my client this week, so I will have plenty of time to sink my teeth into the project.\n. Are there parts of SocketStream's code where this should be used? It would be good to see an example of how using Immutable.js would improve it.\n. @kulicuu ok to close the issue?\n. Pressed wrong button.\n. I've tracked this by running npm run cover-test, and these results vary:\n\nand this\n\nYou can see that the lib/client and lib/client/bundler's coverage stats change between runs, so I will look into the code and tests and see why they're varying.\n. Not always - I've just been running npm run cover-test a couple of times, current coverage results reports 76.77%, but on one case where everything passed, it returned 76.83%. I'll isolate where the variance is occurring.\n. The tests are passing, the errors are to do with getting Coveralls to receive the coverage stats. Some errors are 500 (a server error on their end), and some look to be an invalid repo token being passed automatically by Travis in the background to coveralls.\nGoing to merge this in.\n. I'll ask their support channel.\n. Thanks for spotting the issue and putting it on Github. Give me a couple of minutes and I'll fix it.\n. Hi, I've pushed a fix up (https://github.com/socketstream/ss-console/pull/8), and published it with ss-console 0.1.4 on NPM. I'll close it but if you have any further issues please reopen and let me know.\n. Yes, definitely, but also worth checking them with production apps as well before merging into master and publishing on npm.\n. It's to do with the use of * to select all directories on Windows. Windows does not like * for some reason.\n. Sorry, wrong issue.\n. I've been able to replicate the error on Windows. Will investigate and fix.\n. The way I've managed to fix this is by changing the app.js file on line 11 to this:\ntmpl: 'chat'\nUsing '' as a folder wildcard on Windows does not work. It we swap out '' with the name of the 1st and only folder (chat), then the app works.\nChanging this in the app generator would fix generating new apps with the demo app code, but not apps with a minimal install.\nI'll keep searching for a way to support folder wildcard on Windows.\n. Hi Christian,\nMy workaround for the SS chat app was to simply pass the folder/file name chat in, rather than use the * character to select everything.\nFor Dashku, try changing the tmpl: on line 37 in app.js to this:\ntmpl: ['account','app','dashboard','dashboardView','docs','homepage','widget','alert.jade','changePasswordModal.jade','inputFieldError.jade','loginModal.jade','signupModal.jade']\nIf this works on Windows, please let me know, or better, submit a Pull request to Dashku and I'll review and merge it in.\n. Thanks, merged it in.\n. @thepian Yes, that could work. I have a laptop with Windows on it so I can test it there.\n. A potential fix that could be done now would be to use the async library's 'series' function to chain a series of functions together without ending up in callback hell: https://github.com/caolan/async\n. You can use it today with your app and reduce the callback hell. I think also that adding support for promises is worth discussing.\n. @arxpoetica @thepian SocketStream basically uses connect middleware, and provides append/prepend as ways to insert other connect-middleware before the initial stack. That is how Dashku is able to append a REST API to the dashboard single page app.\nOn the old version of the website, there was an example in the tour that featured a way to load SocketStream and Express together. I can try and dig it out and make it more obvious for users.\nThe HTTP layer in SocketStream does need a closer look. The time when I experimented with alternative approaches to HTTP in https://github.com/anephenix/vorka 2 years ago I found that it was better to use a pure HTTP server over Express (3), and Express 4 has removed all of the connect middleware to be faster. If you do some rough benchmarking requests using a tool like siege, you'll see that Vorka does better than Express, and way much better than Hapi.\n. Hi,\nThe router code is smelly and does cause issues, especially when people want to return 404s for routes that are not matched, hence I think it needs a fresh look.\nThe reason why SocketStream was built on connect as opposed to Express was because it's focus at the time was on supporting Single Page Apps, and Express bundled a bunch of middleware by default that wasn't necessary to that goal.\nThe section I put about performance was more about being how bloated some web frameworks had become in 2013 - Express has recognised this and hence why the middleware stack is much thinner in v4 than in v3.\nHenrik's point is a good one - what is SocketStream's purpose? It does a lot of things, but trying to maintain a framework doing all of those things is a big job, and usually libraries come out which do the job a lot better, so maybe now is the time to re-assess that. It won't be an easy thing to do, as it will require a lot of time and thought.\nAnd that is the other thing - I hardly have the time to work on SocketStream, given the book for Manning publications and moving to another country. I think that if SocketStream is going to progress then it will need someone with more time than I have, therefore I'd like to find someone to take over leading the project.\n. @thepian SockJS has always been available as a plugin - the thing is the engine.io code is in the core repo, which was copy/pasted from the ss-engine.io npm module, and @kulicuu did some changes to it to make it use the latest engine.io release.\nThe reason for this PR was 2 things - firstly, to have 1 place where the engine.io implementation is maintained (rather than inside both socketstream and the ss-engine.io module), as well as to reduce the amount of code that exists inside of socketstream, so we can see how all the libraries connect with each other, and be in a better position to refactor the implementation to make it more modular.\nAt the moment I'm manually testing the implementation, and there is a JS client error in the version of ss-engine.io which I will need to debug, so we'll need to resolve that before we can merge this in.\n. I've dug a little into this so far (FYI I'm running on Mac OS X Mavericks and io.js 3.1.0)\nThe lib/client/index.js file is calling lib/client/http.js with a clients object, which stores the clients. At the time of initialisation, the clients object is empty.\nWhen we call the ss.client.define function in the app, the client is added to the clients object in lib/client/index.js, but http.js has the empty object that was passed into it. Basically we need a way to share the clients object state between both files without message passing. \n. This seems to be happening even on 0.4.3 (not just master branch).\n. Some further testing, it looks like an issue with iojs and not Node.js 0.12. Going to do some more testing to verify.\n. Will do in 2 hours' time (at work atm).\n. Sorry, totally lost track of this. Gimme 10 mins.\n. Latest version of master works, thanks. Will close.\nI realised that if the version of socketstream points to 0.4.3 but the repo is linked to master, it will cause errors, and if the generator points to master but app loads 0.4.3, then another error occurs.\nBasically, always check that the app generator and the module loaded by the app are the same.\n. Hi Robert, segfaults tend to occur if you install an npm module with compiled dependencies using one version of Node, then try to run it after switching to another version of Node. \nI'd like to suggest trying to re-install SocketStream on Node v4.0.0, and then seeing if you still get that error.\n. Hi Robert,\nI can confirm that Socketstream works on v4.0.0. \nI did the following:\nnvm install v4.0.0\nnpm install -g socketstream\nsocketstream new another-app\ncd another-app\nnpm install\nnpm start\nPlease confirm it works for yours well.\n. Interesting, what's your OS and version? (mine was Mac OS X Yosemite 10.10.5)\n. I'd suggest checking where the socketstream binary points to with which socketstream\n. Hi @aaroncalderon, apologies for the issue, it looks like we need to add an integration test that ensures that any app that is newly-generated by SocketStream can be installed and run without issues.\n. I'll take a look.. @yanzixiang can I check what version of SocketStream you were using? Thanks.. This might be the item in question:\nhttps://github.com/socketstream/socketstream-cookie-session\nhttps://www.npmjs.com/package/socketstream-cookie-session\nI will dig a bit further.. Looks good to me\n. I'm going to see if I can fix this first, before changing anything else.. I should add that this was run on an app running 0.3.. I'll note that 0.3 doesn't work on Node 6. As for 0.4.5, chokidar@1.1.0 is not installing on Node 6:\n```\nsocketstream socketstream new test-app\nmodule.js:471\n    throw err;\n    ^\nError: Cannot find module 'chokidar'\n    at Function.Module._resolveFilename (module.js:469:15)\n    at Function.Module._load (module.js:417:25)\n    at Module.require (module.js:497:17)\n    at require (internal/module.js:20:19)\n    at Object. (/Users/pauljensen/.nvm/versions/node/v6.9.1/lib/node_modules/socketstream/lib/tasks/live_reload.js:9:16)\n    at Module._compile (module.js:570:32)\n    at Object.Module._extensions..js (module.js:579:10)\n    at Module.load (module.js:487:32)\n    at tryModuleLoad (module.js:446:12)\n    at Function.Module._load (module.js:438:3)\n``` . Going to close - SocketStream 0.3 won't be supported on Node.js version 6. . Hi,\nI handed over the role of running the project to @thepian last September, as my year was going to be very hectic. In the past year I've just about finished writing a book for Manning publications about Cross Platform Desktop Applications, moved back to London from Amsterdam, helped support my girlfriend as she went through medical treatment this year, and done all of that alongside a full time job in a startup.\nThankfully the treatment is over and she is well, but it has been a really hard year, and I just wasn't prepared to try and squeeze SS in amidst all of that. I am slowly winding my way back into doing some OSS.\nWRT is the project dead? I think it's a fair question to ask based on commit activity - the framework still works (amazingly SocketStream works out of the box on Heroku as they now support WebSockets), but lack of recent activity shows that there is a challenge here - how to keep the project going if no activity happens.\nSimple answer is to generate some activity - make commits, fix bugs, write code, refactor code, write tutorials, answer Qs on Stack Overflow, you get the idea. Problem is how do you that alongside life in general? No one individual can do all of that alone, it's too much. You have to spread the workload, and you have to make it happen regularly. I think that Pieter Hintjen's book on social architecture is a really good read on this.\nIf someone wants to invite me back into the GitHub organisation (I rationalised them a few months ago to the ones I could work on actively at the time), then I will be happy to try and pickup a few items and get the ball rolling.\n. No. I'm back to help.. I'll close the issue.. Thanks for these, I will see if we can get them in.. Hi,\nI've started the process of reissuing the certificate for it, we will see how it goes.. The SSL cert for socketstream.com has been updated. Hi,\nAs suggested in #218, try running this command to resolve the uglify-js issue that you are experiencing:\nnpm install uglify-js -g\n\nThe stack trace indicates that this isn't running a SocketStream app, but instead another app, and therefore not directly-linked to SocketStream. I will therefore close this issue.. I'd like to propose that we simplify the branching strategy.\nAt the moment there are 2 versions of SocketStream being worked on - 0.5 (unstable) in the develop branch and 0.4 (stable) in the master branch. I'd like to propose getting the 0.5 branch stable first, then getting it merged into master and dealing with the merge conflicts that currently exist there.\nThe goal is so that we don't have to duplicate code fixes across multiple versions of SocketStream.. @thepian thoughts?. Very interesting question. If you want to store stream data on the client but not in memory, then there is the possibility of using the browser's localstorage API to do store data, and use a trick around subdomains to store multiple gigabytes of data on the user's comptuer. For an example, Feross' fill disk repo is worth a look: https://github.com/feross/filldisk.com.\nHope that helps.\n . ",
    "pusewicz": "Hmm, it throws the error too. For any version. Let me reinstall node and npm and give it another go.\n[piotr@Vaygr] ~ ruby-1.9.2-p136 $  coffee\ncoffee>  require 'argsparser@0.0.4'\nError: Cannot find module 'argsparser@0.0.4'\n    at Function._resolveFilename (module.js:320:11)\n    at Function._load (module.js:266:25)\n    at require (module.js:348:19)\n    at Object.<anonymous> (eval at <anonymous> (/usr/local/lib/node/.npm/coffee-script/1.0.1/package/lib/coffee-script.js:64:17))\n    at Object.eval (/usr/local/lib/node/.npm/coffee-script/1.0.1/package/lib/coffee-script.js:64:12)\n    at Interface.<anonymous> (/usr/local/lib/node/.npm/coffee-script/1.0.1/package/lib/repl.js:19:26)\n    at Interface.emit (events.js:64:17)\n    at Interface._onLine (readline.js:153:10)\n    at Interface._line (readline.js:408:8)\n    at Interface._ttyWrite (readline.js:585:14)\n. I'm using Homebrew on Mac OS X.\nOn 20 Apr 2011, at 11:27, paulbjensen wrote:\n\nDoes this work?\nrequire 'argsparser'\nI assume you installed node via the tarball from the homepage. I can recommend the git repo (0.5.0-pre).\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/4#comment_1032025\n. I think I know what it is. Just installed node and saw this:\n\n==> Caveats\nPlease add /usr/local/lib/node to your NODE_PATH environment variable to have node libraries picked up.\n. Yup, that was it. All is fine now.\n. Hmm, it throws the error too. For any version. Let me reinstall node and npm and give it another go.\n[piotr@Vaygr] ~ ruby-1.9.2-p136 $  coffee\ncoffee>  require 'argsparser@0.0.4'\nError: Cannot find module 'argsparser@0.0.4'\n    at Function._resolveFilename (module.js:320:11)\n    at Function._load (module.js:266:25)\n    at require (module.js:348:19)\n    at Object.<anonymous> (eval at <anonymous> (/usr/local/lib/node/.npm/coffee-script/1.0.1/package/lib/coffee-script.js:64:17))\n    at Object.eval (/usr/local/lib/node/.npm/coffee-script/1.0.1/package/lib/coffee-script.js:64:12)\n    at Interface.<anonymous> (/usr/local/lib/node/.npm/coffee-script/1.0.1/package/lib/repl.js:19:26)\n    at Interface.emit (events.js:64:17)\n    at Interface._onLine (readline.js:153:10)\n    at Interface._line (readline.js:408:8)\n    at Interface._ttyWrite (readline.js:585:14)\n. I'm using Homebrew on Mac OS X.\nOn 20 Apr 2011, at 11:27, paulbjensen wrote:\n\nDoes this work?\nrequire 'argsparser'\nI assume you installed node via the tarball from the homepage. I can recommend the git repo (0.5.0-pre).\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/4#comment_1032025\n. I think I know what it is. Just installed node and saw this:\n\n==> Caveats\nPlease add /usr/local/lib/node to your NODE_PATH environment variable to have node libraries picked up.\n. Yup, that was it. All is fine now.\n. ",
    "addyosmani": "Thanks for the heads up. I see that some of our demos are currently failing in Opera 11+ with the websocket flag turned on such as SocketRacer.\nI believe we're using UA sniffing to detect whether or not a browser supports WebSockets (Owen or Paul could confirm), however this could probably be easily changed over to feature detection so that we don't have to whitelist them as follows (rough):\nif WebSocket of window\n  window.setTimeout ->\n    useFallback()  if nothingHappened()\n  , 5 * 1000\nelse\n  useFallback()\nOwen/Paul, do you have any concerns about using feature detection here or would you be more comfortable with just clarifying Opera support in the docs?\n. I've tested accessing ssdashboard.com directly from an iPhone, added it to the Homescreen and attempted to launch directly from there but haven't been able to reproduce this issue.\n. Closing ticket as we haven't been able to reproduce nor received any further feedback from the ticket submitter.\n. We've reviewed this ticket and decided to keep the current implementation in it's present form. This may be reviewed again at some point in the future. Thanks!\n. I agree with some of your points. We've actually discussed the idea of dependency loading without the need to state any sort of inclusion order at all previously.\nThat said, I think it would be great to get Owen (the project lead)'s latest insights into how he best thinks this problem should be tackled as I know it's been a pain-point a few developers have already mentioned.\n. The alternatives that I'm aware of are:\n- http://benalman.com/projects/javascript-debug-console-log/\n- http://paulirish.com/2009/log-a-lightweight-wrapper-for-consolelog/\n- https://gist.github.com/1754448\nThe first two don't claim support for IE9 (though were released prior to it), so it may be worth trying them out if the patik.com one isn't working out :)\n. Thanks for the heads up. I see that some of our demos are currently failing in Opera 11+ with the websocket flag turned on such as SocketRacer.\nI believe we're using UA sniffing to detect whether or not a browser supports WebSockets (Owen or Paul could confirm), however this could probably be easily changed over to feature detection so that we don't have to whitelist them as follows (rough):\nif WebSocket of window\n  window.setTimeout ->\n    useFallback()  if nothingHappened()\n  , 5 * 1000\nelse\n  useFallback()\nOwen/Paul, do you have any concerns about using feature detection here or would you be more comfortable with just clarifying Opera support in the docs?\n. I've tested accessing ssdashboard.com directly from an iPhone, added it to the Homescreen and attempted to launch directly from there but haven't been able to reproduce this issue.\n. Closing ticket as we haven't been able to reproduce nor received any further feedback from the ticket submitter.\n. We've reviewed this ticket and decided to keep the current implementation in it's present form. This may be reviewed again at some point in the future. Thanks!\n. I agree with some of your points. We've actually discussed the idea of dependency loading without the need to state any sort of inclusion order at all previously.\nThat said, I think it would be great to get Owen (the project lead)'s latest insights into how he best thinks this problem should be tackled as I know it's been a pain-point a few developers have already mentioned.\n. The alternatives that I'm aware of are:\n- http://benalman.com/projects/javascript-debug-console-log/\n- http://paulirish.com/2009/log-a-lightweight-wrapper-for-consolelog/\n- https://gist.github.com/1754448\nThe first two don't claim support for IE9 (though were released prior to it), so it may be worth trying them out if the patik.com one isn't working out :)\n. ",
    "tronning": "It's not \"jumping through hoops\" It's one switch that has to be turned on in Operas settings. It's all there just like in Chrome and Safari, just not turned on by default. I'll do the Opera FAQ if you want to?\n. ok :\nQ: Will SocketStream websockets apps run in the Opera browser?\nA: As of this writing websockets is supported but turned off by default in Opera. In order for Opera 11 to run websockets apps you need to turn it on in the settings. Do \"opera:config#Enable%20WebSockets\" in the address field and hit enter. Check \"Enable websockets\" Save and you are good to go.\n. It's not \"jumping through hoops\" It's one switch that has to be turned on in Operas settings. It's all there just like in Chrome and Safari, just not turned on by default. I'll do the Opera FAQ if you want to?\n. ok :\nQ: Will SocketStream websockets apps run in the Opera browser?\nA: As of this writing websockets is supported but turned off by default in Opera. In order for Opera 11 to run websockets apps you need to turn it on in the settings. Do \"opera:config#Enable%20WebSockets\" in the address field and hit enter. Check \"Enable websockets\" Save and you are good to go.\n. ",
    "elisee": "I dug a little and I fixed it in two parts:\n- javascript is served as text/javascript and no charset is set so if the browser requests something else by default (iso-8859-15 in my case), the resource gets interpreted as such. It can either be fixed by changing generated tags to request type=\"text/javascript;charset=utf-8\" or by serving the actual resource with a \"text/javascript;charset=utf-8\" header. I went with the second option and made a pull request\n- Length of response in server.deliver was computed with body.length (which returns the number of characters instead of the number of bytes) so I switched it to Buffer.byteLength(body), otherwise a file with UTF-8 chars would have been truncated\nI'll send a pull request\n. (owen: you might want to close this issue)\n. > Someone wrote a library for this recently and mentioned it on the node.js google group, but I haven't had time to play with it yet.\nWhat was the name of this library?\n. I started working on this and it looks pretty straightforward with node-stalker. I think I'll need to add a callback for changed files, since currently it only does callbacks on add and remove, and then it should be all good.\nI'll try to send a pull request for node-stalker tonight (besides the trivial one I already sent) and if it gets accepted I'll send one here too.\n(For those who might care, the socketstream changes should be done in watchForChangedDirs in lib/asset/index.coffee)\n. Hey!\nThere's a bug in the stalker module and @jslatts is on it. You can track progress in the issue there: https://github.com/jslatts/stalker/issues/2\nOnce it's fixed I'll try to send a pull request to stalker with support for checking for file updates and then one here too!\n. Thanks, I'll try to have a go at it tonight.\n. Sorry I moved last week and had a bunch of stuff to do as a result. I'm on it right now, let's see if I can get it to work.\n. Ok so I tried to add the latest stalker to socketstream again and couldn't get stalker to report new / removed files reliably. Thought I'd run some unit tests to check that everything is working as expected:\nnpm install vows@0.5.8 # 0.5.9 was just released and fails with an exception on require('vows/console')\nvows spec/*\n5 dots are displayed and then it stays like that forever, never returning. I'm running node 0.4.8 on Ubuntu 11.04 32-bit. I tried to get a more useful report from vows but I think it won't output anything until all tests have run. @jslatts : any idea what I'm doing wrong?\n. I managed to get some more info by passing --spec to vows. I opened an issue in stalker as you requested: https://github.com/jslatts/stalker/issues/3\n. Hi Owen,\nI haven't dug enough to find the root cause of the failing tests and @jslatts couldn't find an immediate solution though he mentioned it might be OS-dependent since the stalker tests don't fail on its MacOS X installation. If I get it to run I'll let you know, but don't count too much on it.\n. I just pushed a commit there: https://github.com/elisee/socketstream/commit/ed2ba134722ccfa89079557b4a39440cc72fe131\nIt doesn't work since (1) stalker doesn't work properly on my machine (2) there's no support for a \"file changed\" callback in stalker yet. On a Mac, I think it should properly detect new and removed files.\n. Adding the new callback itself isn't too much work, but I can't do if the library doesn't run properly as is on my machine.\n. I like the simplicity of the file numbering but the truth is, the day you'll need to add a file between number 2 and 3 and you already have 20 other files, it's going to be painful. A list in a config file would be much easier to edit for sure, so I would go with that.\n. Just FYI the next version of Subversion (1.7) will finally stop putting .svn folders everywhere and will only create a root .svn folder (\u00e0 la .hg / .git).\n. I dug a little and I fixed it in two parts:\n- javascript is served as text/javascript and no charset is set so if the browser requests something else by default (iso-8859-15 in my case), the resource gets interpreted as such. It can either be fixed by changing generated tags to request type=\"text/javascript;charset=utf-8\" or by serving the actual resource with a \"text/javascript;charset=utf-8\" header. I went with the second option and made a pull request\n- Length of response in server.deliver was computed with body.length (which returns the number of characters instead of the number of bytes) so I switched it to Buffer.byteLength(body), otherwise a file with UTF-8 chars would have been truncated\nI'll send a pull request\n. (owen: you might want to close this issue)\n. > Someone wrote a library for this recently and mentioned it on the node.js google group, but I haven't had time to play with it yet.\nWhat was the name of this library?\n. I started working on this and it looks pretty straightforward with node-stalker. I think I'll need to add a callback for changed files, since currently it only does callbacks on add and remove, and then it should be all good.\nI'll try to send a pull request for node-stalker tonight (besides the trivial one I already sent) and if it gets accepted I'll send one here too.\n(For those who might care, the socketstream changes should be done in watchForChangedDirs in lib/asset/index.coffee)\n. Hey!\nThere's a bug in the stalker module and @jslatts is on it. You can track progress in the issue there: https://github.com/jslatts/stalker/issues/2\nOnce it's fixed I'll try to send a pull request to stalker with support for checking for file updates and then one here too!\n. Thanks, I'll try to have a go at it tonight.\n. Sorry I moved last week and had a bunch of stuff to do as a result. I'm on it right now, let's see if I can get it to work.\n. Ok so I tried to add the latest stalker to socketstream again and couldn't get stalker to report new / removed files reliably. Thought I'd run some unit tests to check that everything is working as expected:\nnpm install vows@0.5.8 # 0.5.9 was just released and fails with an exception on require('vows/console')\nvows spec/*\n5 dots are displayed and then it stays like that forever, never returning. I'm running node 0.4.8 on Ubuntu 11.04 32-bit. I tried to get a more useful report from vows but I think it won't output anything until all tests have run. @jslatts : any idea what I'm doing wrong?\n. I managed to get some more info by passing --spec to vows. I opened an issue in stalker as you requested: https://github.com/jslatts/stalker/issues/3\n. Hi Owen,\nI haven't dug enough to find the root cause of the failing tests and @jslatts couldn't find an immediate solution though he mentioned it might be OS-dependent since the stalker tests don't fail on its MacOS X installation. If I get it to run I'll let you know, but don't count too much on it.\n. I just pushed a commit there: https://github.com/elisee/socketstream/commit/ed2ba134722ccfa89079557b4a39440cc72fe131\nIt doesn't work since (1) stalker doesn't work properly on my machine (2) there's no support for a \"file changed\" callback in stalker yet. On a Mac, I think it should properly detect new and removed files.\n. Adding the new callback itself isn't too much work, but I can't do if the library doesn't run properly as is on my machine.\n. I like the simplicity of the file numbering but the truth is, the day you'll need to add a file between number 2 and 3 and you already have 20 other files, it's going to be painful. A list in a config file would be much easier to edit for sure, so I would go with that.\n. Just FYI the next version of Subversion (1.7) will finally stop putting .svn folders everywhere and will only create a root .svn folder (\u00e0 la .hg / .git).\n. ",
    "linlexing": "Well now, thanks elisee\n. Well now, thanks elisee\n. ",
    "Rodeoclash": "Ok, it appears it picks up changes but fails to detect when new files are added unless the cache has been manually deleted.\n. I'm happy with the jQuery templating but I'm not throwing around massive\namounts of HTML yet. I guess at some point it would be great to make it\nagnostic as to which templating system you want to use, like Rails (i.e. ERB\nbe default, but the option to change it).\nNot really a priority though ;)\nSamuel Richardson\nwww.richardson.co.nz | 0405 472 748\nOn Wed, Jul 6, 2011 at 2:24 AM, blup \nreply@reply.github.comwrote:\n\nIn response to jQuery templating - given SocketStream's emphasis on\nperformance, I would definitely reconsider (\nhttp://jsperf.com/dom-vs-innerhtml-based-templating/174). It seems to\nscore poorly in performance tests.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/22#issuecomment-1504953\n. Ok, it appears it picks up changes but fails to detect when new files are added unless the cache has been manually deleted.\n. I'm happy with the jQuery templating but I'm not throwing around massive\namounts of HTML yet. I guess at some point it would be great to make it\nagnostic as to which templating system you want to use, like Rails (i.e. ERB\nbe default, but the option to change it).\n\nNot really a priority though ;)\nSamuel Richardson\nwww.richardson.co.nz | 0405 472 748\nOn Wed, Jul 6, 2011 at 2:24 AM, blup \nreply@reply.github.comwrote:\n\nIn response to jQuery templating - given SocketStream's emphasis on\nperformance, I would definitely reconsider (\nhttp://jsperf.com/dom-vs-innerhtml-based-templating/174). It seems to\nscore poorly in performance tests.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/22#issuecomment-1504953\n. \n",
    "jslatts": "FYI, it should be fixed. Let me know how it goes.\n. I am getting the same error from vows 0.5.9, but 0.5.8 works for me. \nWhat do you mean you are not getting reliable file reporting? can you file an issue @ the stalker page with the steps to reproduce?\n. Sorry guys, I have been on vacation for several weeks so I have been pretty unhelpful with this. I simply can't reproduce the issue yet.\n. FYI, it should be fixed. Let me know how it goes.\n. I am getting the same error from vows 0.5.9, but 0.5.8 works for me. \nWhat do you mean you are not getting reliable file reporting? can you file an issue @ the stalker page with the steps to reproduce?\n. Sorry guys, I have been on vacation for several weeks so I have been pretty unhelpful with this. I simply can't reproduce the issue yet.\n. ",
    "jmonster": "I was thinking the same thing -- I tried doing a naive port to 0.7 using the Socket.IO migration guide + find/replace but wasn't successful.\n. Very awesome, just tried it out -- thanks for the update!\n. I was thinking the same thing -- I tried doing a naive port to 0.7 using the Socket.IO migration guide + find/replace but wasn't successful.\n. Very awesome, just tried it out -- thanks for the update!\n. ",
    "ggoodman": "Hi the sort of coffeescript config file I was thinking about would look something like this.  This would mean a very similar syntax to your existing json config.\ncoffeescript\nmodule.exports =\n  http:\n    host: '0.0.0.0'\n    port: process.env.C9_PORT\nThis would also mean you could 'just load it' and then do a config.extend() as is currently done.\n. Just tried and it seems like the ZeroMQ requirement will mean that it's dead\nin the water in that environment.\nOn Wed, Aug 17, 2011 at 11:03 AM, socketstream \nreply@reply.github.comwrote:\n\nSure - it sounds like a simple change.\nI would say make a pull request and I'll take it from there - but I'm more\nconcerned with how Cloud9 will work with 0.2 given the split process\narchitecture and need (at least for now) to have ZeroMQ compiled.\nIf you could give 0.2 a whirl on Cloud9 I'd be interested to hear how you\nget on. Hopefully the problems you find can be resolved quickly.\nOwen\nOn 17 Aug 2011, at 15:25, ggoodman wrote:\n\nIn a non-standard run environment (Cloud9IDE). I have a bootstrap file as\nsuch:\n``` coffee-script\nrequire(\"coffee-script\");\nss = require(\"socketstream/lib/main\");\nss.init();\nAdjust SS.root to a subdirectory instead of the root dir\nSS.root = SS.root + \"/appname\";\nss.start.server();\n```\nI have had to modify the line in assets/index.coffee where the\npublic_path is set from exports.public_path =  './public/assets' to\nexports.public_path =   SS.root + '/public/assets' as well as making\nsimilar changes to the watch_dirs to make them based on SS.root instead of\nthe current working directory.\nIs this something that you would consider integrating into master?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/54\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/54#issuecomment-1827106\n. Great news! Look forward to it.\n. Got it working on Cloud9IDE as you suggested without needing to tweak too much code.\n\nI didn't originally know that you could change the working directory using process.chdir()... that was enough to get things up and running.\n. I was able to use a bootstrap file such as the following, to both create (tweak the command) and run (as-is) a sockestream project in Cloud9IDE: https://gist.github.com/1264721. Since I was using an earlier version, I needed to tweak the config to refer to an off-site redis instance.\nIt would be much simpler to do if require('sockestream') exposed a different interface.\nMy suggestions would be:\n- default interface does not automatically call init()\n- default interface exposes init, start, create and other useful commands that are currently only accessible through the CLI\n. Ugh, didn't mean to close this. Clicked comment and close by accident.\n. Hi the sort of coffeescript config file I was thinking about would look something like this.  This would mean a very similar syntax to your existing json config.\ncoffeescript\nmodule.exports =\n  http:\n    host: '0.0.0.0'\n    port: process.env.C9_PORT\nThis would also mean you could 'just load it' and then do a config.extend() as is currently done.\n. Just tried and it seems like the ZeroMQ requirement will mean that it's dead\nin the water in that environment.\nOn Wed, Aug 17, 2011 at 11:03 AM, socketstream \nreply@reply.github.comwrote:\n\nSure - it sounds like a simple change.\nI would say make a pull request and I'll take it from there - but I'm more\nconcerned with how Cloud9 will work with 0.2 given the split process\narchitecture and need (at least for now) to have ZeroMQ compiled.\nIf you could give 0.2 a whirl on Cloud9 I'd be interested to hear how you\nget on. Hopefully the problems you find can be resolved quickly.\nOwen\nOn 17 Aug 2011, at 15:25, ggoodman wrote:\n\nIn a non-standard run environment (Cloud9IDE). I have a bootstrap file as\nsuch:\n``` coffee-script\nrequire(\"coffee-script\");\nss = require(\"socketstream/lib/main\");\nss.init();\nAdjust SS.root to a subdirectory instead of the root dir\nSS.root = SS.root + \"/appname\";\nss.start.server();\n```\nI have had to modify the line in assets/index.coffee where the\npublic_path is set from exports.public_path =  './public/assets' to\nexports.public_path =   SS.root + '/public/assets' as well as making\nsimilar changes to the watch_dirs to make them based on SS.root instead of\nthe current working directory.\nIs this something that you would consider integrating into master?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/54\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/54#issuecomment-1827106\n. Great news! Look forward to it.\n. Got it working on Cloud9IDE as you suggested without needing to tweak too much code.\n\nI didn't originally know that you could change the working directory using process.chdir()... that was enough to get things up and running.\n. I was able to use a bootstrap file such as the following, to both create (tweak the command) and run (as-is) a sockestream project in Cloud9IDE: https://gist.github.com/1264721. Since I was using an earlier version, I needed to tweak the config to refer to an off-site redis instance.\nIt would be much simpler to do if require('sockestream') exposed a different interface.\nMy suggestions would be:\n- default interface does not automatically call init()\n- default interface exposes init, start, create and other useful commands that are currently only accessible through the CLI\n. Ugh, didn't mean to close this. Clicked comment and close by accident.\n. ",
    "Trakkasure": "Keeping everything tight and compact in a fast, well maintained system is a good thing.\n. You could have the server compare the files in the directory with the list(s).\nAnd if a new file is added, by default, add it to the end of the list.\nI think this would give you what you want, and what others want too.\n. There are so many middleware add-ons for connect it's silly. That would be a great addition.\n. Keeping everything tight and compact in a fast, well maintained system is a good thing.\n. You could have the server compare the files in the directory with the list(s).\nAnd if a new file is added, by default, add it to the end of the list.\nI think this would give you what you want, and what others want too.\n. There are so many middleware add-ons for connect it's silly. That would be a great addition.\n. ",
    "blup": "In response to jQuery templating - given SocketStream's emphasis on performance, I would definitely reconsider (http://jsperf.com/dom-vs-innerhtml-based-templating/174). It seems to score poorly in performance tests.\n. +1 to having the server object exposed to the projects (server.coffee), that way we can create/implement our own server logic (connect/express/etc).\n. Thanks for the explanation, I'll close the issue for now.\n. In response to jQuery templating - given SocketStream's emphasis on performance, I would definitely reconsider (http://jsperf.com/dom-vs-innerhtml-based-templating/174). It seems to score poorly in performance tests.\n. +1 to having the server object exposed to the projects (server.coffee), that way we can create/implement our own server logic (connect/express/etc).\n. Thanks for the explanation, I'll close the issue for now.\n. ",
    "dlindahl": "I second the recommendation to allow the user to specify which templating engine to use. I particularly like how Express handles it, by file extension type. If I recall correctly, Express has some adapters to handle the different engines. That allows users to write their own adapter if one does not already exist.\nI dislike the CLI option because it makes upgrading existing apps difficult and would make mixing together different engines an impossibility (if you are in to that sort of thing)\n. I am converting a MySQL backed Rails App to a MongoDB backed Node/SocketStream App. It tracks user events on our main website. The overhead for including WebSocket support for every browser we support on every page is too high for the given functionality (usually only one small request per page, occassionally several larger ones), thus the POST requests. Its simple, quick, easy, and fully supported by everyone natively.\nI totally understand the no POST decision though, and I think for most Apps, its probably the right decision. I just happen to have the edge case!\nI would say that if you end up not supporting this, it should definitely be noted in the MiddleWare documentation. Its not a huge problem, it just wasn't the behavior that I was expecting.\nKeep up the great work!\n. I'm tempted to agree with the Connect path. Let someone else deal with it :)\n. That's pretty exciting news! Thanks!\n. I second the recommendation to allow the user to specify which templating engine to use. I particularly like how Express handles it, by file extension type. If I recall correctly, Express has some adapters to handle the different engines. That allows users to write their own adapter if one does not already exist.\nI dislike the CLI option because it makes upgrading existing apps difficult and would make mixing together different engines an impossibility (if you are in to that sort of thing)\n. I am converting a MySQL backed Rails App to a MongoDB backed Node/SocketStream App. It tracks user events on our main website. The overhead for including WebSocket support for every browser we support on every page is too high for the given functionality (usually only one small request per page, occassionally several larger ones), thus the POST requests. Its simple, quick, easy, and fully supported by everyone natively.\nI totally understand the no POST decision though, and I think for most Apps, its probably the right decision. I just happen to have the edge case!\nI would say that if you end up not supporting this, it should definitely be noted in the MiddleWare documentation. Its not a huge problem, it just wasn't the behavior that I was expecting.\nKeep up the great work!\n. I'm tempted to agree with the Connect path. Let someone else deal with it :)\n. That's pretty exciting news! Thanks!\n. ",
    "andreyvit": "Oh yeah, I feel your pain, missing out on Ruby Enumerable methods just as much. I do think you should gsub '.any()', '.length' in this case.\n. Doing more homework\u2026\nLatest Safari on desktop and iOS is only missing the Function.prototype.bind function. Same for Android.\nLatest Chrome has all of them, same for Firefox 5.\nSo I guess the suggestion is to add the following method into helpers.js:\n```\n// https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Function/bind\nif ( !Function.prototype.bind ) {\nFunction.prototype.bind = function( obj ) {\n    var slice = [].slice,\n        args = slice.call(arguments, 1), \n        self = this, \n        nop = function () {}, \n        bound = function () {\n          return self.apply( this instanceof nop ? this : ( obj || {} ), \n                              args.concat( slice.call(arguments) ) );  \n        };\nnop.prototype = self.prototype;\n\nbound.prototype = new nop();\n\nreturn bound;\n\n};\n}\n```\nHere's a test to see which functions are missing from your browser: http://needed-augment-js-methods-tests.s3.amazonaws.com/index.html (it's Augment.js tests, but without the library included).\nLet me know if you want a pull request.\n. Oh yeah, I feel your pain, missing out on Ruby Enumerable methods just as much. I do think you should gsub '.any()', '.length' in this case.\n. Doing more homework\u2026\nLatest Safari on desktop and iOS is only missing the Function.prototype.bind function. Same for Android.\nLatest Chrome has all of them, same for Firefox 5.\nSo I guess the suggestion is to add the following method into helpers.js:\n```\n// https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Function/bind\nif ( !Function.prototype.bind ) {\nFunction.prototype.bind = function( obj ) {\n    var slice = [].slice,\n        args = slice.call(arguments, 1), \n        self = this, \n        nop = function () {}, \n        bound = function () {\n          return self.apply( this instanceof nop ? this : ( obj || {} ), \n                              args.concat( slice.call(arguments) ) );  \n        };\nnop.prototype = self.prototype;\n\nbound.prototype = new nop();\n\nreturn bound;\n\n};\n}\n```\nHere's a test to see which functions are missing from your browser: http://needed-augment-js-methods-tests.s3.amazonaws.com/index.html (it's Augment.js tests, but without the library included).\nLet me know if you want a pull request.\n. ",
    "colinsullivan": "Makes sense.  My regexp skills are not particularly refined but it seems that there is likely a modification that can be performed on your regexp to handle these cases.  \nIn any case, I understand this may be quite a bit of thinking for a small convenience.\nThanks for a great framework.\n. ## Awesome thanks.\nColin Sullivan\nhttp://colin-sullivan.com\nOn Fri, Jul 1, 2011 at 4:49 PM, socketstream \nreply@reply.github.comwrote:\n\nSocketStream does it all automatically for you, front and back end - and\neverything in between :)\nInvestigate the API trees concept. Basically you can have as many\nsub-folders and files as you wish.\nDon't put dots in your file names. Instead do this:\nshared/Foo   <- make this a directory\nshared/Foo/Bar.coffee   <- a file\nshared/Foo/Models/Customer.coffee\nNow you can do SS.shared.Foo.Bar.method_name() or\nSS.shared.Foo.Models.Customer.find() or whatever you like from both the\nfront and back end.\nIf for any reason this doesn't work as I've described, let us know. Thanks.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/28#issuecomment-1487037\n. I am using @session.setUserId as you described, but I am attempting to set the @session.user.attributes directly.  Is this the issue?  If so, what is this @session.user.attributes object for?  Is there a common way to set it with my user's attributes when needed?  I can store them in Redis of course, and retrieve them every time, I just figured there was a SocketStream construct for handling this common task.\n\nThanks so much for the @getSession clarification.\n. Makes sense.  My regexp skills are not particularly refined but it seems that there is likely a modification that can be performed on your regexp to handle these cases.  \nIn any case, I understand this may be quite a bit of thinking for a small convenience.\nThanks for a great framework.\n. ## Awesome thanks.\nColin Sullivan\nhttp://colin-sullivan.com\nOn Fri, Jul 1, 2011 at 4:49 PM, socketstream \nreply@reply.github.comwrote:\n\nSocketStream does it all automatically for you, front and back end - and\neverything in between :)\nInvestigate the API trees concept. Basically you can have as many\nsub-folders and files as you wish.\nDon't put dots in your file names. Instead do this:\nshared/Foo   <- make this a directory\nshared/Foo/Bar.coffee   <- a file\nshared/Foo/Models/Customer.coffee\nNow you can do SS.shared.Foo.Bar.method_name() or\nSS.shared.Foo.Models.Customer.find() or whatever you like from both the\nfront and back end.\nIf for any reason this doesn't work as I've described, let us know. Thanks.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/28#issuecomment-1487037\n. I am using @session.setUserId as you described, but I am attempting to set the @session.user.attributes directly.  Is this the issue?  If so, what is this @session.user.attributes object for?  Is there a common way to set it with my user's attributes when needed?  I can store them in Redis of course, and retrieve them every time, I just figured there was a SocketStream construct for handling this common task.\n\nThanks so much for the @getSession clarification.\n. ",
    "chikamichi": "Let's try this out:\n``` coffee-script\nexports.actions =\nlookup: (coords_from_browser, cb) ->\n    host = 'maps.googleapis.com'\n    r = coords_from_browser.coords\n    http = require('http')\n    google = http.createClient(80, host)\n    google.on 'error', (e) -> console.error \"Unable to connect to #{host}\"\n    request = google.request 'GET', \"/maps/api/geocode/json?sensor=true&latlng=#{r.latitude},#{r.longitude}\"\n    request.end()\n    request.on 'error', (e) -> console.error \"Unable to parse response from #{host}\"\n    request.on 'response', (response) => parseResponse(response, cb)\nparseResponse = (response, cb) ->  # note: private methods are written outside of exports.actions\n  output = ''\n  response.setEncoding('utf8')\n  response.on 'data', (chunk) -> output += chunk\n  response.on 'end', ->\n    j = JSON.parse(output)\n    result = j.results[0]\n    cb(result)\n```\nSeems to be working pretty fine with ``` coffee-script (or coffeescript).\n. You're welcome.\n. Let's try this out:\n``` coffee-script\nexports.actions =\nlookup: (coords_from_browser, cb) ->\n    host = 'maps.googleapis.com'\n    r = coords_from_browser.coords\n    http = require('http')\n    google = http.createClient(80, host)\n    google.on 'error', (e) -> console.error \"Unable to connect to #{host}\"\n    request = google.request 'GET', \"/maps/api/geocode/json?sensor=true&latlng=#{r.latitude},#{r.longitude}\"\n    request.end()\n    request.on 'error', (e) -> console.error \"Unable to parse response from #{host}\"\n    request.on 'response', (response) => parseResponse(response, cb)\nparseResponse = (response, cb) ->  # note: private methods are written outside of exports.actions\n  output = ''\n  response.setEncoding('utf8')\n  response.on 'data', (chunk) -> output += chunk\n  response.on 'end', ->\n    j = JSON.parse(output)\n    result = j.results[0]\n    cb(result)\n```\nSeems to be working pretty fine with ``` coffee-script (or coffeescript).\n. You're welcome.\n. ",
    "harlanji": "I was able to hack this in pretty easily by adding it to bin/socketstream... obviously not a long term solution, but I can report that node-inspector with '--debug' works fine. For some reason '--debug-brk' behaved the same as '--debug', but I didn't need it enough to press the issue further.\nMy idea for a permanent solution is to use child_process::spawn, and add debug flags if signaled by the cli. This could work well with some kind of auto-restart for modified server source or watchdog process, but I can't commit to doing this right now. \n. I would LOVE to get RequireJS (or similar, it's been a year since I've explored that stuff) into this action, and share module/loading semantics between the client and server. It's been a side interest for the past year or so, but I've never had the time or a playground to actually get it working. My team is pushing ahead with SS right now and I imagine we'll want to really tame the dependencies as we module-up our existing (spaghetti) code base into SS/Backbone. No commitments (sorry), but this is my vision and hopefully we can really get nice automatic dependency management somewhere down the line. I was spoiled by spending years in maven land ;).< /idealistic_rant>\nrealistically, I'm really pleased to see the proposed solution be included in 0.2.0.\n. I agree it's a really non-descriptive error message, and I scratched my head for a while the first time I hit it as well. I think I remember reading that is by design, and that the rationale to that pattern is that it will cause less client breakage if the API changes.\n. I was able to hack this in pretty easily by adding it to bin/socketstream... obviously not a long term solution, but I can report that node-inspector with '--debug' works fine. For some reason '--debug-brk' behaved the same as '--debug', but I didn't need it enough to press the issue further.\nMy idea for a permanent solution is to use child_process::spawn, and add debug flags if signaled by the cli. This could work well with some kind of auto-restart for modified server source or watchdog process, but I can't commit to doing this right now. \n. I would LOVE to get RequireJS (or similar, it's been a year since I've explored that stuff) into this action, and share module/loading semantics between the client and server. It's been a side interest for the past year or so, but I've never had the time or a playground to actually get it working. My team is pushing ahead with SS right now and I imagine we'll want to really tame the dependencies as we module-up our existing (spaghetti) code base into SS/Backbone. No commitments (sorry), but this is my vision and hopefully we can really get nice automatic dependency management somewhere down the line. I was spoiled by spending years in maven land ;).< /idealistic_rant>\nrealistically, I'm really pleased to see the proposed solution be included in 0.2.0.\n. I agree it's a really non-descriptive error message, and I scratched my head for a while the first time I hit it as well. I think I remember reading that is by design, and that the rationale to that pattern is that it will cause less client breakage if the API changes.\n. ",
    "igagen": "Yeah, that would be great if you didn't have to specify the order at all. I guess the ideal solution would be to do a require statement, just like you would on the server, though that might be a bit more work to implement.\n. That's fine, it's not urgent for me, but glad to hear it will be addressed\nin the 0.3 release. I'm excited to see the 0.2 release, sounds like it will\nbe a big one.\nThanks for following up!\n-Alex\nOn Wed, Aug 3, 2011 at 5:08 AM, socketstream \nreply@reply.github.comwrote:\n\nWant to give a quick update on this.\nI tried re-working the asset manager for 0.2 and realised it was going to\nbe a huge undertaking to do all the things we've mentioned here plus a bunch\nof other stuff that needs to be done at the same time to prepare it for\nfuture plans we have.\nHence the Asset Manager will get completely re-thought and re-written as\npart of 0.3.\nThe 0.2 preview will be out in a matter of days now and includes many huge\nnew features. As soon as it's stable I'll start working on 0.3.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/35#issuecomment-1717433\n. Yeah, that would be great if you didn't have to specify the order at all. I guess the ideal solution would be to do a require statement, just like you would on the server, though that might be a bit more work to implement.\n. That's fine, it's not urgent for me, but glad to hear it will be addressed\nin the 0.3 release. I'm excited to see the 0.2 release, sounds like it will\nbe a big one.\n\nThanks for following up!\n-Alex\nOn Wed, Aug 3, 2011 at 5:08 AM, socketstream \nreply@reply.github.comwrote:\n\nWant to give a quick update on this.\nI tried re-working the asset manager for 0.2 and realised it was going to\nbe a huge undertaking to do all the things we've mentioned here plus a bunch\nof other stuff that needs to be done at the same time to prepare it for\nfuture plans we have.\nHence the Asset Manager will get completely re-thought and re-written as\npart of 0.3.\nThe 0.2 preview will be out in a matter of days now and includes many huge\nnew features. As soon as it's stable I'll start working on 0.3.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/35#issuecomment-1717433\n. \n",
    "jonmumm": "Yes exposing the server would work for me for now.\n. Yes exposing the server would work for me for now.\n. ",
    "madgnu": "Caught this problem at unstable version of node.js - v0.5.1.\n. Caught this problem at unstable version of node.js - v0.5.1.\n. ",
    "brianconnoly": "I mean the instructions listed in the install.md file\n. Thank you!\nIt would be nice if you will put link in the README.md file!\nI'll try it later.\n. 1) about 30 seconds\n2) iPad 2 32Gb 3G ( but surfing is via wifi )\n3) last, 5.0.1\n4) Yes, I can\n. Sorry for making wait so long.\nSafari on iOS \"speeps\" tabs that are not in use, and free memory for new ones.\nSo when a tab with SS is being restored, it crash browser.\nApplication works fine on relaunch.\nI think it's problem of Socket.IO. I tried to create a pure-node application with Socket.IO and it also crashes.\n. We created a multiplayer chess-game based on SS2.\nIt would be nice if this issue can be fixed.\n. I mean the instructions listed in the install.md file\n. Thank you!\nIt would be nice if you will put link in the README.md file!\nI'll try it later.\n. 1) about 30 seconds\n2) iPad 2 32Gb 3G ( but surfing is via wifi )\n3) last, 5.0.1\n4) Yes, I can\n. Sorry for making wait so long.\nSafari on iOS \"speeps\" tabs that are not in use, and free memory for new ones.\nSo when a tab with SS is being restored, it crash browser.\nApplication works fine on relaunch.\nI think it's problem of Socket.IO. I tried to create a pure-node application with Socket.IO and it also crashes.\n. We created a multiplayer chess-game based on SS2.\nIt would be nice if this issue can be fixed.\n. ",
    "rjregenold": "Forgot to add versions:\nsocketstream 0.1.6\nnode 0.4.8\nnpm 1.0.13\nLet me know if you need any other version info.\n. Works like a champ. Keep up the great work on socketstream!\n. Forgot to add versions:\nsocketstream 0.1.6\nnode 0.4.8\nnpm 1.0.13\nLet me know if you need any other version info.\n. Works like a champ. Keep up the great work on socketstream!\n. ",
    "tralamazza": "Build issue fixed.\n. Build issue fixed.\n. ",
    "bminer": "Totally understood. This might be a SocketStream 0.4.0 idea. I'm going to hack away at something like this over the next few weeks, and I'll be in touch with you guys (either via IRC or whatever).  It might require some significant changes.\nI've also never used Git, so it would be a good time to learn. I'm really waiting on full documentation of SocketStream and its inter-workings. It's nice to be able to use the console to see all of the config options, but there are still some questions that won't be answered until some more documentation is published (I know you guys are working hard on this)... or until I start digging deeper into the code.  Also, I'm not a CoffeeScript fan, and I don't know if you guys would mind if I contributed code in pure JS???\n. Here's another library that I found:\nhttps://github.com/balupton/history.js\nMuch better than using jQuery BBQ and onhashchange event.\n. It has a callback, but I don't believe that it's required.  The AUTH command will be queued until the 'ready' event is ready to fire.  Just make sure that auth() is called before any other command is issued to Redis.  Also, auth() will automatically cache the password so that reconnections happen nicely. Thanks!\n. I will definitely try it out. Thanks!\n. Totally understood. This might be a SocketStream 0.4.0 idea. I'm going to hack away at something like this over the next few weeks, and I'll be in touch with you guys (either via IRC or whatever).  It might require some significant changes.\nI've also never used Git, so it would be a good time to learn. I'm really waiting on full documentation of SocketStream and its inter-workings. It's nice to be able to use the console to see all of the config options, but there are still some questions that won't be answered until some more documentation is published (I know you guys are working hard on this)... or until I start digging deeper into the code.  Also, I'm not a CoffeeScript fan, and I don't know if you guys would mind if I contributed code in pure JS???\n. Here's another library that I found:\nhttps://github.com/balupton/history.js\nMuch better than using jQuery BBQ and onhashchange event.\n. It has a callback, but I don't believe that it's required.  The AUTH command will be queued until the 'ready' event is ready to fire.  Just make sure that auth() is called before any other command is issued to Redis.  Also, auth() will automatically cache the password so that reconnections happen nicely. Thanks!\n. I will definitely try it out. Thanks!\n. ",
    "life0fun": "This is a such important feature as most hosting platform require redis password.....cant wait to have it.\nThanks,\n. Hi Owen,\n    I changed localhost to 127.0.0.1, and looks like the error is gone....now I can launch SocketStream server in multi-process mode.\n    My other zmq test apps can take localhost.....I will dig deep further later.\nThanks,\n. can we close this one and re-open #379 , as Owen has comments there and discussion still on-going at that thread.\n. Hi Owen,\n    I haven't tried CommonJS. It seems to me that requirejs provides a very nice modular system with AMD that can be used to improve our current solution for client/code/libs.  Looks like commonJS can solve the problem of sharing code.\n   For build and deploy automation, maybe we can open an issue to track for adding  socketstream grunt template, if that's the right direction to go.\nThanks,\n-haijin\n. This is a such important feature as most hosting platform require redis password.....cant wait to have it.\nThanks,\n. Hi Owen,\n    I changed localhost to 127.0.0.1, and looks like the error is gone....now I can launch SocketStream server in multi-process mode.\n    My other zmq test apps can take localhost.....I will dig deep further later.\nThanks,\n. can we close this one and re-open #379 , as Owen has comments there and discussion still on-going at that thread.\n. Hi Owen,\n    I haven't tried CommonJS. It seems to me that requirejs provides a very nice modular system with AMD that can be used to improve our current solution for client/code/libs.  Looks like commonJS can solve the problem of sharing code.\n   For build and deploy automation, maybe we can open an issue to track for adding  socketstream grunt template, if that's the right direction to go.\nThanks,\n-haijin\n. ",
    "sjerrys": "cant wait to see......\n. Hi guys~\nThere are cases: since users are using their own laptop, they dont want \"login\" everytime they come back. \nMay I suggest a permanent cookie for this kind problem, or let the developer make the config.\n. cant wait to see......\n. Hi guys~\nThere are cases: since users are using their own laptop, they dont want \"login\" everytime they come back. \nMay I suggest a permanent cookie for this kind problem, or let the developer make the config.\n. ",
    "franklywatson": "Agree that filtering out . files is probably the sanest thing to do. Let me know if there is anything I can do to help\nCheers\nJ\n. Thanks guys :)\n. Agree that filtering out . files is probably the sanest thing to do. Let me know if there is anything I can do to help\nCheers\nJ\n. Thanks guys :)\n. ",
    "nponeccop": "I agree that domready and load should not be exposed using SS.client\n. I was thinking about node_modules too. Maybe it is better to have 2 node_modules folders - /app/node_modules for your own modules and /node_modules for third-party dependencies.\nI think the recommendation should be documented - so feel free to reopen the bug.\n. JFYI there are other use cases for session access:\n1) captchas\n2) user-private images (think of flickr/picasa, pr0n, charts, a website selling aerial/satellite photographs)\n3) user-private SWFs\n5) user-private static content (e.g. commercial software packages)\n4) third-party components relying on RESTful API (we use amcharts to display stock charts and they want the chart data served in csv format)\nSo the limitation is rather serious and not limited to openid or authentication\n. Should this be reopened now?\n. I submitted a pull request to resolve some issues with latest zmq on Cygwin:\nhttps://github.com/JustinTulloss/zeromq.node/pull/49\nI hope this will help. Tomorrow I'll try to change zeromq to zmq and report the results.\n. I think we should follow common conventions such as Linux Filesystem Hierarchy and Filesystem Hierarchy Standard in cases it doesn't do any harm.\nOf course replacing server and client with usr/share/client just because a standard says so is an overkill. But having pid in var/run and cached concatenated js in var/cache seems reasonable to me.\nRegarding the file - it contains the following both in 0.1 and 0.2 (numbers are different in 0.2 of course):\njavascript\n{\"version\":{\"server\":\"0.1.8\",\"client\":\"0.0.18\"}}\nWhy do you use the word \"state\" to describe this?\nRegarding the deployment - to what extent do you plan to integrate deployment capabilities in SocketStream? Do you plan to support common deployment platforms such as AWS, RackspaceCloud/OpenStack or Heroku?\n. What do you think about var/run and var/cache?\n. Keeping everything in the app directory is a very good idea.\nI was talking about replacing local /tmp inside app folder with local var/run and var/cache. I was not talking about putting something to system-wide /var - that is even not generally possible as only root can write to /var/. \ntmp is just a wrong term. Section 3.17 of Filesystem Hierarchy Standard says:\n\nPrograms must not assume that any \ufb01les or directories in /tmp are preserved between invocations of the\nprogram.\n\nSection 5.5 says about var/cache:\n\n/var/cache is intended for cached data from applications. Such data is locally generated as a result of\ntime-consuming I/O or calculation. The application must be able to regenerate or restore the data. Unlike\n/var/spool, the cached \ufb01les can be deleted without data loss. The data must remain valid between invocations\nof the application and rebooting the system.\n\nSection 5.13.1 says:\n\nProcess identi\ufb01er (PID) \ufb01les, which were originally placed in /etc, must be placed in /var/run. The naming\nconvention for PID \ufb01les is .pid.\n\nSo according to this standard, last_known_state and generated static assets belong to var/cache and PID files belong to var/pid. Since the standard is so widely deployed and so many administrators are familiar with it, shoving to /tmp what belongs to /var would mislead many people and make their life harder.\nIf you are against this, you can rename tmp to cache or temp so no associations with LFH/FHS standards will emerge in people minds. \n. We plan to use your library in production, so I will help you to implement the features we need for our yet unreleased project.\nOpenId support is the highest priority for us for now, so I will work on #61 first. After that we need an ability to connect our backend data collector using zmq, so I will work on that.\nzmq accepted my patch for Cygwin support recently, as Cygwin is our development platform, and I maintain Node.JS Cygwin binaries so I'm already working in this direction.\n. We have an implementation of OpenID authentication using openid NPM libary. Our authenticator works as a connect middleware and relies on connect sessions. If you use normal connect sessions in your current Socket.IO authentication framework then it should be rather straighforward to use the framework provided by 0.2 with our authenticator even if the hook is called before bodyparser and cookieparser connect sessions rely on. I will share my findings of course.\n. The authentication part is not relevant. The CSS part is relevant, but not important for me any more.\n. As a workaround you can use @media (http://www.w3schools.com/css/css_mediatypes.asp) in your style sheet to define separate styles for printing within a single stylesheet.\n. Maybe you should start using milestones feature of github to mark certain issues as 0.2/0.3/0.4\n. Modules and API Tree are different concepts and can coexist. API Tree is a convenient way to expose lots of functions using hierarchical name spaces. Modules are a convenient way to hide certain functions within a single name space.\nHaving everything exposed is a bad idea. There are so many architectural reasons for this that I cannot tell which one is the most important. One consideration is that if I know that certain identifier is module-private I have more confidence that I can change it without breaking something elsewhere. Now any function can be potentially called from anywhere - this is a recipe for disaster once project gets bigger.\nRegarding require I think the main disadvantage is that requires are dynamic. A static module system would help a lot. For example:\n1. A Javascript linker becomes easier to implement. Asset manager can stop sending unused modules to clients, and orphan modules can be much easier detected in large programs.\n2. Programs become easier to comprehend because you know the dependencies of the code you are looking at.\nAs Javascript is a dynamic language, a static module system means that module dependencies are not written in Javascript but either as pragmas (special comments) or completely separate make-type dependency specification language. Exports can remain dynamic just like they are now in CommonJS Modules Spec.\n. Also note that there are 2 separate ways for a session to expire:\n1) browser forgets session cookie because of cookie expiration or manual deletion\n2) server forgets session data because of session store purging (e.g. using Redis SETEX/EXPIRE timeout)\nAlso there are session cookies which expire when you close browser window.\n. Note that SETEX expiration is implemented in #127\n. See #89\n. I also submitted a bug to node.js: https://github.com/joyent/node/issues/1797\n. Then why you are closing the issue despite it's not resolved yet? The issues are there to remind about open problems.\nhttp://mmonit.com/monit/documentation/monit.html can be used to restart node if it is high on resource usage:\nif totalmem > 100.0 MB for 2 cycles then restart\nsame applies for CPU\n. That's why master branch is there. Push your latest dirty untested work at least weekly to master branch. A more common approach is to do many very small commits and pushing often, few times a day - look at https://github.com/joyent/node/commits/master for example.\nGitHub is a social development website, not just a hosting for source tarballs. Other people are there to help you with development, so by releasing work as often as it's comfortable for you you will get much more help and feedback.\n. Node itself can accept both forward and backward slashes. But your code expects only forward slashes and breaks.\n. I found a solution myself: action function has ss argument, and it can be used for my use case:\njavascript\nexports.actions = function (req, res, ss)\n{\n    foo.on('tick', function ()\n    {\n        ss.publish.all('foo', [ ' bar' ])\n    })\n    return {\n       action1 : function (...) { ... }\n       action2 : ...\n       ...\n   }\n}\nI think you should add this to the doc\n. It is not good because actions() is called every time an action arrives. So more and more handlers attach to foo over time. Of course I can use a flag to prevent multiple attachments, but that's inconvenient.\nAnother drawback is that I cannot broadcast before I receive the first RPC from the first client. So in case RPCs are not needed, a programmer is forced to send a fake RPC from a client just to get an instance of ss at the server.\nA possible solution is to have exports.init = function (ss) which is guaranteed to be called once upon server startup if present. Or to export a useful instance from socketstream module, so the following example works:\njavascript\nvar ss = require('socketstream')\nss,publish.all('foo', [ ' bar' ])\nOr we can use an asynchronous interface to wait  if  all() is not always available:\njavascript\nvar ss = require('socketstream')\nss.getInstance(function (ss) { ss.publish.all('foo', [ ' bar' ]) })\n. ss.api.publish.all() is fine\n. Seems fixed in 0.3alpha4 \n. > If you'd like to have a look at how we can do this (without relying on Socket.IO \n\nsessions as the transport is now modular) that would be great.\n\nI'll take a look at it as we have two options now in our project: either patch 0.2 or 0.3 to include such session support. I'll show you my findings regarding 0.3 (for 0.2 my attempt was #89).\n. You can write your own session store for Connect and use it in both SS and Connect parts.\nAlso note that you only set userId and don't provide a full session object for sockets yet. The patch allows web sockets to see userId from connect session object, but not other values.\n. I confirm that this still happens in alpha4.\nTo reproduce, remove existing server/rpc/demo.coffee and put demo.js there instead with nonsense code like foo)bar.\nExpected behaviour: server displays an uncaught exception stacktrace and exits.\nActual behaviour: server displays an exception without a stacktrace and keeps running.\nI couldn't reproduce this with the demo chat application,  that because I cannot install Hogan, see https://github.com/socketstream/ss-hogan/issues/1\nBut I can reproduce with my app. Can you confirm the bug with chat app?\n. Somehow it doesn't. All I get is\n/home/foo/server/rpc/app.js:1\nfoo)bar\n   ^\n. no. We looked specifically for this.\n. Nothing interesting:\n[quux@bar ~]$ grep -R uncaughtException node_modules\nnode_modules/q/README.md:``process`` ``\"uncaughtException\"``.\nnode_modules/q/CHANGES.md:   emit ``uncaughtException`` events, and browsers to\nnode_modules/q/CHANGES.md:   now emitted to Node's `\"uncaughtException\"` `process`\nnode_modules/qq/CHANGES:   now emitted to Node's `\"uncaughtException\"` `process`\nnode_modules/ss-coffee/node_modules/coffee-script/lib/coffee-script/repl.js:  process.on('uncaughtException', error);\nnode_modules/socketstream/lib/socketstream.js://process.on('uncaughtException', function (err) { console.error('Exception caught: ', err)})\nnode_modules/socketstream/node_modules/mocha/_mocha.js:    process.removeListener('uncaughtException', uncaught);\nnode_modules/socketstream/node_modules/mocha/_mocha.js:  process.on('uncaughtException', uncaught);\nnode_modules/socketstream/node_modules/mocha/lib/runner.js:    process.removeListener('uncaughtException', uncaught);\nnode_modules/socketstream/node_modules/mocha/lib/runner.js:  process.on('uncaughtException', uncaught);\nnode_modules/socketstream/node_modules/mocha/History.md:  * Fixed \"test end\" event for uncaughtExceptions. Closes #61\nnode_modules/socketstream/node_modules/mocha/mocha.js:    process.removeListener('uncaughtException', uncaught);\nnode_modules/socketstream/node_modules/mocha/mocha.js:  process.on('uncaughtException', uncaught);\nnode_modules/socketstream/node_modules/mocha/mocha.js:  if ('uncaughtException' == e) {\nnode_modules/socketstream/node_modules/mocha/mocha.js:  if ('uncaughtException' == e) {\nnode_modules/socketstream/node_modules/redis/test.js:process.on('uncaughtException', function (err) {\nnode_modules/socketstream/node_modules/coffee-script/lib/coffee-script/repl.js:  process.on('uncaughtException', error);\nnode_modules/socketstream/node_modules/socket.io/node_modules/redis/test.js:process.on('uncaughtException', function (err) {\nnode_modules/socketstream/node_modules/socket.io/node_modules/socket.io-client/node_modules/ws/test/autobahn.js:process.on('uncaughtException', function(err) {\nnode_modules/socketstream/node_modules/socket.io/node_modules/socket.io-client/node_modules/ws/test/autobahn-server.js:process.on('uncaughtException', function(err) {\nnode_modules/socketstream/src/socketstream.js://process.on('uncaughtException', function (err) { console.error('Exception caught: ', err)})\nI'll keep investigating and let you know. I suspect a try-catch block in connect.\n. I still get the same behavior. The following on stderr and nothing on stdout:\n/home/foo/server/rpc/bar.js:2\n});\n^\n. > To reproduce, remove existing server/rpc/demo.coffee and put demo.js there instead with nonsense code like foo)bar.\n\nExpected behaviour: server displays an uncaught exception stacktrace and exits.\nActual behaviour: server displays an exception without a stacktrace and keeps running.\n\nStill happens in my project with latest SS\nAs now ss-hogan is fixed, I'll try to reproduce with your test chat app and let you know the result\n. Cannot reproduce with test chat app - I see the expected \"tracing and dying\" behavior with it.\nI'm closing the bug then.\n. Tracked down this to a bug in my RPC action file (server/rpc/foo.js). Because of this bug an exception was thrown in socketstream.js from ws.responders.load() call but it was then silently caught. Can you ensure that such exceptions are not silently caught but at least produce a message in the logs?\n. Still happens in 0.3 alpha 3 (I run with SS_DEV=1):\nTypeError: Cannot read property 'html' of null\n    at Client.html (/home/ics/node_modules/socketstream/src/client_asset_manager/client.coffee:88:21)\n    at Client.htmlFromCache (/home/ics/node_modules/socketstream/src/client_asset_manager/client.coffee:61:23)\n    at ServerResponse.serve (/home/ics/node_modules/socketstream/src/client_asset_manager/index.coffee:35:21)\n    at Object.<anonymous> (/home/ics/app.js:35:7)\n    at nextMiddleware (/home/ics/node_modules/connect/lib/middleware/router.js:175:25)\n    at param (/home/ics/node_modules/connect/lib/middleware/router.js:183:16)\n    at pass (/home/ics/node_modules/connect/lib/middleware/router.js:191:10)\n    at Object.router [as handle] (/home/ics/node_modules/connect/lib/middleware/router.js:197:6)\n    at next (/home/ics/node_modules/connect/lib/http.js:203:15)\n    at Object.bodyParser [as handle] (/home/ics/node_modules/connect/lib/middleware/bodyParser.js:88:61)\n. Do you have an idea where exceptions can be silently caught? I use SS_DEV=1 so process.on('unhandledException' is commented out. Where should I look at?\nAt the moment at least two different types of exceptions are silently caught:\n1. Syntax errors in files in server/rpc/\n2. Runtime errors during execution of rpc handlers.\nWe are really tired setting try-catch blocks around our code to debug, so I'm going to work on that. Do you have an idea where it's better to start? How do you see RPC debugging and error reporting in SS in general?\n. We got the error again. Now it looks like this (last sources from git, SS_DEV=1):\nTypeError: Cannot read property 'html' of null\n    at Client.html (/home/ics/node_modules/socketstream/src/client_asset_manager/client.coffee:88:21)\n    at Client.htmlFromCache (/home/ics/node_modules/socketstream/src/client_asset_manager/client.coffee:61:23)\n    at ServerResponse.<anonymous> (/home/ics/node_modules/socketstream/src/client_asset_manager/index.coffee:35:21)\n    at Object.<anonymous> (/home/ics/app.js:35:7)\n    at nextMiddleware (/home/ics/node_modules/connect/lib/middleware/router.js:175:25)\n    at param (/home/ics/node_modules/connect/lib/middleware/router.js:183:16)\n    at pass (/home/ics/node_modules/connect/lib/middleware/router.js:191:10)\n    at Object.router [as handle] (/home/ics/node_modules/connect/lib/middleware/router.js:197:6)\n    at next (/home/ics/node_modules/connect/lib/http.js:203:15)\n    at Object.bodyParser [as handle] (/home/ics/node_modules/connect/lib/middleware/bodyParser.js:88:61)\nI found that the exception is thrown from ss.serve('main'). Note that I use connect for the main web server, so I call res.serve from within a connect router callback:\n``` Javascript\nfunction routes(app)\n{\n    app.get('/', function (req, res) {\n        res.serve('main')}\n    )\n}\nvar app = connect.createServer(\n    connect.logger()\n,   ss.http.middleware\n,   connect.bodyParser()\n,   connect.router(routes)\n)\n```\nThe problem is not catching the exception, but the occurence of the exception in the first place.\nThe exception is thrown because of the following line in src/client_asset_manager/client.coffee:\nCoffeescript\nif ssClient.html?\nssClient itself is null here, so an attempt to check if its property is set crashes.\nThe bug turned out to be because of missing socket.io dependency: I forgot to update socket.io on one of our development PCs. That exception was silently caught somehow so later another exception appeared. \nA quick an dirty workaround is to put try-catch block in socketstream.js in start().\n. Closing for now - we haven't seen this problem for long time.\n. I think it's better to die with an informative diagnostic message, for example: \n/home/foo/bar.orig: Error: Unsupported file extension orig. Please provide a formatter.\n. io.sockets.emit('message', msg) accepts an object, while socket.send(data) accepts a string. So you shouldn't JSON-encode msg but pass a Javascript object instead, and emit will call JSON.stringify for you.\n. I was thinking of converting that to \n{\"x\" : \"event, \"t\":\"all\",\"e\":\"newMessage\"....\nYou already use JSON for serialization, why mix it with something else (the event\u00a7 and rpc\u00a7 prefixes)? Also think of replaceable effective serializers such as MessagePack, Thrift, ProtocolBuffers etc \n. I do that every time you release an update :) I have updated all developer hosts now, but the error persists.\n. The bug is still there. Note that we use Express for HTTP routing and Chrome for testing. \n. Here is what I found:\nhttps://github.com/socketstream/socketstream/blob/master/src/websocket/transports/socketio/index.coffee\nprocessSession returns false in 2 cases. However, diagnostic message is displayed only in one case. Here is JS compilation result, so implicit returns are visible:\n``` Javascript\nprocessSession = function(socket) {\n  var cookie, rawCookie, sessionId;\n  if (socket.sessionId) return true;\n  try {\n    rawCookie = socket.handshake.headers.cookie;\n    cookie = qs.parse(rawCookie);\n    sessionId = cookie['connect.sid'].split('.')[0];\n    return socket.sessionId = sessionId;\n  } catch (e) {\n    console.log('Warning: connect.sid session cookie not detected. User may have cookies disabled or session cookie has expired');\n    return false;\n  }\n};\n```\nI suggest to move console.log outside to the call site, to the else branch of if (processSession(...))\nNote also that this code will throw if socket is somehow undefined, for example, because of a bug in socket.io\n. I'm still experiencing this to the extent I abandoned using SS.ready in my app.\n. You can close it for now. I can't tell you if it's broken because I don't use it in production, and the issue was relatively rare.\n. >  I've not heard of anyone reporting this problem for months\nWe stopped to use ss.ready months ago, that's why. It seems to work without it, and we were too lazy to enable it back to see if it became reliable.\n. The image files are already in /client/static/images and it works most of the time, but sometimes for some unknown reason  SocketStream wants to serve them using _serverDev instead of static middleware.\n. Here is the third solution we actually use: put your CSS to static/ folder :)\nThe bug was on our side: we had 2 copies of one CSS file in different folders because of problems with source control. Closing.\n. Can it be SocketStream.ss.model and such? BTW we use backbone.js client-side models with current socketstream.\n. It doesn't have to be too wordy. I can write\nJavascript\nvar ss = require('socketstream').ss.model\nonce per file. I have to do something like that in Node.JS anyway, so same requirement on client doesn't feel like an inconvenience.\nMoreover, the variable doesn't have to be global - we can reserve globals only for legacy client-side libraries which cannot be run as a CommonJS module. We can wrap our main module in a closure the same way we wrap non-main modules, so any variables defined in the main module are local to the closure. And the main module won't have exports just like in Node.js it doesn't.\n. I think this can be closed for now, as channels seem to do their job.\n. Closing for now then. I'll investigate it closer and re-open if it's because of socketstream\n. Investigation showed the bug is because of SocketStream. We delay ss.start(server) until our other components have started, and that takes up to a minute. Termination before SocketStream has started is always instant. So the tests below are performed when log shows that SS has started. By \"slow\" I mean takes 10+ seconds. Instant is instant - probably less than 0.2 sec.\nCase 1\nBoth SS_ENV and SS_DEV are unset. Termination is slow.\nCase 2\nSS_ENV is unset. SS_DEV=1. Termination is slow.\nCase 3\nSS_ENV=production. SS_DEV=1. Termination is instant\nCase 4\nSS_ENV=production. SS_DEV is unset Termination is instant\nSo I think it has something to do with monitoring for changes and/or the router.\n. I have 91 file in client:\n[foo@bar ~]$ find client -type f | wc -l\n91\nCommenting the line helped!\n. I still get a red string (the arrow and 'quux is not defined' are red):\n\u2192 rpc:1 app.init quux is not defined\nI also noticed a stacktrace in browser console in client. Is this intended behaviour? It exposes server internals to clients in production mode, which is not good. It's fine in development mode though, but in production no stack traces must be visible to clients, as that may help to find exploits.\n. No problems in our app with 0.9.0 so far. Thank you.\n. Basically, replace     .use(connect.static(staticPath)) in http/index.coffee with .use(gzippo.staticGzip(staticPath))\nThis should help to reduce download size for .js, .css and .html in production mode.\n. connect.compress() doesn't cache - it zips it every time which is waste of CPU for static files. \n. It seems they fixed the leak in node 0.7. https://github.com/joyent/node/issues/2504\nSo as soon as 0.8 becomes available (0.7 is an unstable branch) we should retest.\n. Here is early proof of concept code:\nhttps://gist.github.com/2029434\nI had to patch socket.io-client to add the handshakeHeaders option. The code creates 1000 clients in parallel. Each client sends  app.init RPC which subscribes it to a channel depending on account subscription status.\nThen every 15 seconds two events are broadcast using channels, so each of the 1000 clients receives only one.\n1000 parallel RPCs and broadcasts to 1000 clients don't put much load on the server which is a good sign.\n. I disable it as a workaround for #160.\nAlso, it is not a convenient feature for us. It is a pain to see our app reinitializing because you modified a file.\nWe use Chrome debugger and we may have some breakpoints. Page refresh triggers those breakpoints and debugger starts flashing in the task bar. Also our app take long time to initialize because it loads large datasets on startup, and it's a pain to see it reinitializing over and over while you are editing a file. You know that Ctrl-S habit to be safe in case of crashes, it makes too many reloads.\n. Try to put userId in session and let us know the results. My original patch only supported userId in session, as I didn't need anything else there.\n. It caches in memory\n. It only caches zippable assets - that is .js and .css. It seems to perform a match on MIME type using a configurable object with .test method (a RegExp for example):\nhttps://github.com/tomgallacher/gzippo/blob/master/lib/staticGzip.js\nJavascript\ncontentTypeMatch = options.contentTypeMatch || /text|javascript|json/,\n. zlib binding in node.js core turned out to cause memory leak. So we should wait until the leak is fixed. See https://github.com/joyent/node/issues/2933\n. There are many design options here. For example, you can just improve  serveClient implementation to be more friendly to external caches and caching middleware sitting on top of it. Or you can make it configurable.\nAlso note that it is hard to make reverse proxies caching both page versions in your example, so probably a different approach will be used by high-load sites (e.g. redirects or moving the switching logic to the proxy).\n. aaa.html \n. Yeah, you were not supposed to paste it as it wasn't a pull request but a dirty fix (we only needed IE9 as it has native canvas)\nWell, our app relies heavily on console.log so if you remove console.log altogether from SS core, we'll have to add a library anyway. Also grepping for console seems to find few references to it in the libraries we use, so it's really hard for us to avoid the console.\n. No, I still get 'console is undefined' in IE9 with current version from Git\n. I think it's a great decision. I was rather surprised to see you shipping a large console.log wrapping library. The current console.log wrapper has two flaws:\n- doesn't support all modern browsers\n- tries too hard to support ancient browsers.\nFor me 3 solutions are equally good:\n1. No dependency of SS on console.log and no console.log wrapper, so I can use my own if I need one;\n2. A simplistic wrapper only to ensure that calling console.log never causes crashes. No dancing to work around IE and Opera bugs, just a no-op log function for crash protection will suffice;\n3. A cross-platform alternative to console.log which sends logs to server and/or has a configurable client-side presentation layer.\n. I never used Hogan. The only thing I know about this library is that it is named in honour of Hulk Hogan, an actor with mustache :) I'm interested in it because it will allow me to run your chat app. Older Hogan doesn't install at all because of permission problem.\n. The problem was with hogan library, and I was waiting for Twitter people to fix it.\n. I just use config = require('./config') everywhere I need it. No need for SS to include configuration facilities.\n. I use Javascript. But you can write in Coffeescript, with automated translation by coffeescript module, not by Socketstream. \n. @haohello \nFor now you can use a reverse proxy to do the gzip work for you. Zlib bindings for node are leaky now, we can't do anything before that bug is fixed.\n. This approach is fundamentally limited by Rice's theorem - your dependency analyzer can never be both sound and complete. I can always write something like this to hide the dependency on baz module from the analyzer:\nJavascript\nsetTimeout(function { var bar = require; bar('ba' + 'z').foo() }, 8000)\nSo a more bulletproof approach is either to supply dependencies metadata manually (as NPM does) or to enforce some program structure, as AMD does.\nJavascript\ndefine(\"alpha\", [\"require\", \"exports\", \"beta\"], function (require, exports, beta) {\n     exports.verb = function() {\n         return beta.verb();\n         //Or:\n         return require(\"beta\").verb();\n     }\n });\nWith this AMD approach the dependency analyzer can run the define function on the server side to get the dependency info (without running the actual definition function!), which is both fast and doesn't require impossible analyses of turing-complete languages.\n. One rule is not enough. Here I don't pass variables into require, but create an alias for require:\nJavascript\nvar foo = require\nfoo('bar')\nSo now we have 2 rules: 1) pass variables into the require statement 2) don't create aliases for require\nBut now I can circumvent with the following:\nJavascript\nvar require = function () { }\nrequire('djfdkjfkdjf')\nNow we have a false dependency on djfdkjfkdjf. So we should add 3rd rule: don't shadow require identifier. I still can circumvent:\neval(\"req\" + \"uire('foo')\")\nSo we have 4th rule \"don't use eval\". Now I can still use the following without violating previous rules:\nglobal['req' + 'uire'] = function () {   } ; require('fjkdjfkd')\nSo we have 5 rules. Should I continue? :)\n. I just think that AMD is much better structure than current if static detection of dependencies is considered.\nPeople like simple rules. If rules are obscure, people start to treat libraries like magic black boxes which occasionally break. I think this is against the SS philosophy. While my mentioning of Rice's theorem were more of a pun, there are many pretty realistic situations when dependency detection by parsing may fail and lead to obscure errors. Obscure errors are opposite to user friendliness.\nIf a user refactors foo = require('bar'); baz = require('zoo'); quux = aaa ? foo : baz; into seemingly equivalent\nfoo = require(aaa ? 'bar' : 'zoo')\nshe will get a rather unexpected missing dependency error on the client. With AMD approach breaking by mistake or overlook is just  not possible, so it's less error prone and better.\n. @wmulligan That's just a bug which can be fixed without static dependency detection. It is pretty possible to detect the order without resorting to parsing. It is just somehow not done now, so feel free to open a separate issue for order detection. Of course for '/libs/' it's not possible - we are only talking about orderly initialization of commonjs modules.\n@mindeavor the CommonJS approach has an advantage over AMD: it's standard (many people feel good when they see something standards adopted) and it works in node.js out of the box (so sharing code between client and server is possible).\nI think we should proceed as following:\n- implement correct order detection in module initialization code\n- implement AMD module loader in addition to existing commonjs\nIt should be easier to implement efficiently than parsing.\n. I vote for closing. I never wanted AMD instead of CommonJS, just as a separate feature in addition to CommonJS to facilitate more usage scenarios and faster dep tracking. I'm pretty happy with current situation and against the dependency checks just like I opposed the automatic client refreshes.\n. Connect is designed the way so multiple versions can coexist. I'm using SS with Express without problems. Let me find what code I use.\n``` Javacript\nss.client.define('main', {\n    view:   'app.jade',\n    css:    ['libs', 'app.styl'],\n    code:   ['libs', 'main'],\n    tmpl:   ['main']\n})\n// Remove to use only plain .js, .html and .css files if you prefer\nss.client.formatters.add(require('ss-coffee'))\nss.client.formatters.add(require('ss-jade'))\nss.client.formatters.add(require('ss-stylus'))\nfunction routes(app)\n{\n    app.get('/', function (req, res) {\n        res.serve('main')}\n    )\n}\nvar app = express.createServer(\n    express.logger({stream : openForAppend(\"var/log/http.log\")})\n,   ss.http.middleware\n,   express.bodyParser()\n,   express.router(routes)\n)\nvar server = app.listen(3000);\nss.start(server);\n```\nNote that you can remove whatever middleware you don't need (logger, bodyparser). And openForAppend is my own function, so feel free to define it using fs.createWriteStream if you want express to log to file.\n. @trungpham These files are not dynamic. Timestamps are used to force expiration every time socketstream server is restarted, not every time a request is made. So we don't pay a latency penalty.\n. The problem is that socketstream uses connect.session internally, so you cannot have different secret and key than socketstream. Here is the relevant fragment from src/http/index.coffee if you consider patching it to replace secret and key:\nCoffeeScript\n  load: (sessionStore, sessionOptions) ->\n    # Append SocketStream middleware upon server load\n    app\n    .use(connect.cookieParser('SocketStream'))\n    .use(connect.favicon(staticPath + '/favicon.ico'))\n    .use(connect.session(\n      cookie: { path: '/', httpOnly: false, maxAge: sessionOptions.maxAge },\n      store: sessionStore\n    ))\n. I think he only wants an ability to set arbitrary cookie name and secret instead of using the values hardcoded into socketstream.\n. Our fix consists of 3 parts:\n1. insertion of HTTP middleware before socket.io (no patching of anything required)\n2. storing req.sessionID set by connect middleware in socket.io handshake object (1 line in socket.io lib/manager.js)\n3. using handshake.sessionID instead of handshake.headers.cookie in socketstream processSession() (1 line in socketstream websocket/transports/socketio/index.coffee)\nIt is far from being a pull request, but you should understand the idea.\nPutting middleware before socket.io\nThis code we use in app.js to start the server. Dependency on express can be easily removed and the rest can be put inside ss.start and http.middleware.\nSocket.io decorates a passed instance of builtin node HTTP server with its handlers for various events (connect, close, upgrade, request and maybe something else). We are only interested in the request handler installed by socket.io. We remove the handlers (an array of functions with 2 arguments and this) and convert it to a connect middleware (a single function with 3 arguments, 3rd is unused in our case).\nThen we install the middleware function in our HTTP middleware chain so it comes after connect.session middleware and not before.\n``` Javascript\nvar socketIoRequestHandler\nfunction routes(app)\n{\n    app.get('/', function (req, res) {\n        res.serve('main')\n    })\n    // This can be implemented in socketstream just by comparison of req.url\n    // without express router. This redirection of certain requests \n    // should be in ss.http.middleware at any point after connect.session\n    app.all('/socket.io/*', socketIoRequestHandler)\n}\nvar app = express.createServer()\nvar server = app.listen(3000);\nvar defaultListeners = server.listeners('request')\nss.start(server)\nvar ioRequestListener = server.listeners('request')\nsocketIoRequestHandler = function (req, res, next)\n{\n    ioRequestListener.forEach(function(listener)\n    {\n        listener.call(server, req, res)\n    })\n}\nserver.removeAllListeners('request');\ndefaultListeners.forEach(function (l)\n{\n    server.on('request', l)\n})\n// at this stage we removed listeners for request events installed by\n// socket.io and replaced then with default listeners\n// the removal and replacement should be a part of ss.serve()\napp.use(ss.http.middleware)\napp.use(express.router(routes))\n```\n. ## Storing req.sessionID in socket.handshake\nA single line in Manager.prototype.handshakeData function in lib/manager.js of socket.io:\nJavascript\n  return {\n      headers: data.headers\n    , address: connectionAddress\n    , time: date.toString()\n    , query: data.query\n    , url: data.request.url\n    , xdomain: !!data.request.headers.origin\n    , secure: data.request.connection.secure\n    , issued: +date\n    // we just add this line\n    , sessionID : data.request.sessionID\n  };\nNote that connect session object is also accessible here. So we could just use session : data.request.session and remove the need to reimplement an identical session object (and stores!) in socketstream. But we chose just to get sessionID to keep changes in socketstream minimal.\nWe cannot use data.headers.cookie because it only contains request headers. If a socket.io handshake request is the first request  reaching origin servers, then connect.session engages because of the previous fix and sets Set-cookie header before handshakeData() receives control. But it's a response header and not a request header, so it's not in the headers field.\nNode doesn't provide a way to inspect response headers already injected into current response, but fortunately connect.session middleware also monkey patches request object by adding .session and .sessionID fields. The latter is just a session ID without a HMAC signature, so it can be used by socketstream to fetch data from session store without additional parsing.\nBasically, data.headers.cookie is not always present, but data.request.sessionID and .session are always present after our previous fix and contain the session information we need.\nUsing handshake.sessionID instead of handshake.cookie\nThis step is trivial. Here is a dirty fix:\n``` diff\ndiff --git a/src/websocket/transports/socketio/index.coffee b/src/websocket/transports/socketio/index.coffee\nold mode 100644\nnew mode 100644\nindex b07843f..c46875e\n--- a/src/websocket/transports/socketio/index.coffee\n+++ b/src/websocket/transports/socketio/index.coffee\n@@ -66,10 +66,7 @@ processSession = (socket) ->\n# Parse session ID from initial hankshake data\n   try\n-    rawCookie = socket.handshake.headers.cookie\n-    cookie = qs.parse(rawCookie, '; ')\n-    sessionId = cookie['connect.sid'].split('.')[0]\n-    socket.sessionId = sessionId\n+    socket.sessionId = socket.handshake.sessionID\n   catch e\n     console.log('Warning: connect.sid session cookie not detected. User may have cookies disabled or session cookie has expired\n     false\n```\n. Cookies serve only the purpose of linking HTTP sessions to Websocket connections. If you want your users authenticated by openid/oauth, you need this linking. If linking is not needed, cookies should not be used. It is not needed in case of password-based authentication, but password based auth is so 20th century and Web 1.0 :)\n. oh lol, it turned out that ss.event was replaced by ss.server, but ss.event somehow continued to work without throwing an exception.\nClose this issue if API change from ss.event to ss.server was documented.\n. Done\n. I think channel subscription should be per connection and not per session.\n. > I think we should leave the decision to the app developer a  d provide the best tools for both approaches. \nI agree\n. Few thoughts:\n- I use varnish reverse proxy to move all burden away from node.\n- There is a free Coral CDN which is good only to redirect traffic spikes to it so your site doesn't completely die. It requires to issue redirects from foo.com/bar.js to foo.com.nyud.net/bar.js depending on user-agent. So if you want CDN support built into SS I think this scenario should also be implementable with your framework.\n- I'll take a look on Rackspace Cloud way of using Akamai CDN to include it as a separate scenario too\n. > one could gzip the minified files already\nThere is an issue for that: #165\nWe cannot do that before the release of node v0.8.x as there are various bugs in gzipping module. I use varnish reverse proxy with various hacks to compress assets.\n. So I can just call packAssets() and assets will be properly repacked and re-read from disk? I didn't know it was safe to call packAssets() multiple times during app lifespan.\n. req and res are not available in ss rpc responders because there are no HTTP requests or responses. RPC responders can work over web sockets or over flash sockets.\nconnect sessions are available in ss rpc responders, and req/res are available if you process HTTP requests.\n. It will work because socket.io performs an HTTP handshake even in case of Flash sockets\n. In RPC methods connection handshake is over - it's too late.\nDirect access to Socket.io handshake could be beneficial, but what about  transports other than socket.io? \n. You have access to cookies from HTTP requests and on client. If you need a non-httponly cookies use separate AJAX requests or connect middleware for that. \nI don't think the idea to misuse Socket.io handshake to access cookies is good - the access is possible only once per session so it is not worth the effort.\n. I agree that domready and load should not be exposed using SS.client\n. I was thinking about node_modules too. Maybe it is better to have 2 node_modules folders - /app/node_modules for your own modules and /node_modules for third-party dependencies.\nI think the recommendation should be documented - so feel free to reopen the bug.\n. JFYI there are other use cases for session access:\n1) captchas\n2) user-private images (think of flickr/picasa, pr0n, charts, a website selling aerial/satellite photographs)\n3) user-private SWFs\n5) user-private static content (e.g. commercial software packages)\n4) third-party components relying on RESTful API (we use amcharts to display stock charts and they want the chart data served in csv format)\nSo the limitation is rather serious and not limited to openid or authentication\n. Should this be reopened now?\n. I submitted a pull request to resolve some issues with latest zmq on Cygwin:\nhttps://github.com/JustinTulloss/zeromq.node/pull/49\nI hope this will help. Tomorrow I'll try to change zeromq to zmq and report the results.\n. I think we should follow common conventions such as Linux Filesystem Hierarchy and Filesystem Hierarchy Standard in cases it doesn't do any harm.\nOf course replacing server and client with usr/share/client just because a standard says so is an overkill. But having pid in var/run and cached concatenated js in var/cache seems reasonable to me.\nRegarding the file - it contains the following both in 0.1 and 0.2 (numbers are different in 0.2 of course):\njavascript\n{\"version\":{\"server\":\"0.1.8\",\"client\":\"0.0.18\"}}\nWhy do you use the word \"state\" to describe this?\nRegarding the deployment - to what extent do you plan to integrate deployment capabilities in SocketStream? Do you plan to support common deployment platforms such as AWS, RackspaceCloud/OpenStack or Heroku?\n. What do you think about var/run and var/cache?\n. Keeping everything in the app directory is a very good idea.\nI was talking about replacing local /tmp inside app folder with local var/run and var/cache. I was not talking about putting something to system-wide /var - that is even not generally possible as only root can write to /var/. \ntmp is just a wrong term. Section 3.17 of Filesystem Hierarchy Standard says:\n\nPrograms must not assume that any \ufb01les or directories in /tmp are preserved between invocations of the\nprogram.\n\nSection 5.5 says about var/cache:\n\n/var/cache is intended for cached data from applications. Such data is locally generated as a result of\ntime-consuming I/O or calculation. The application must be able to regenerate or restore the data. Unlike\n/var/spool, the cached \ufb01les can be deleted without data loss. The data must remain valid between invocations\nof the application and rebooting the system.\n\nSection 5.13.1 says:\n\nProcess identi\ufb01er (PID) \ufb01les, which were originally placed in /etc, must be placed in /var/run. The naming\nconvention for PID \ufb01les is .pid.\n\nSo according to this standard, last_known_state and generated static assets belong to var/cache and PID files belong to var/pid. Since the standard is so widely deployed and so many administrators are familiar with it, shoving to /tmp what belongs to /var would mislead many people and make their life harder.\nIf you are against this, you can rename tmp to cache or temp so no associations with LFH/FHS standards will emerge in people minds. \n. We plan to use your library in production, so I will help you to implement the features we need for our yet unreleased project.\nOpenId support is the highest priority for us for now, so I will work on #61 first. After that we need an ability to connect our backend data collector using zmq, so I will work on that.\nzmq accepted my patch for Cygwin support recently, as Cygwin is our development platform, and I maintain Node.JS Cygwin binaries so I'm already working in this direction.\n. We have an implementation of OpenID authentication using openid NPM libary. Our authenticator works as a connect middleware and relies on connect sessions. If you use normal connect sessions in your current Socket.IO authentication framework then it should be rather straighforward to use the framework provided by 0.2 with our authenticator even if the hook is called before bodyparser and cookieparser connect sessions rely on. I will share my findings of course.\n. The authentication part is not relevant. The CSS part is relevant, but not important for me any more.\n. As a workaround you can use @media (http://www.w3schools.com/css/css_mediatypes.asp) in your style sheet to define separate styles for printing within a single stylesheet.\n. Maybe you should start using milestones feature of github to mark certain issues as 0.2/0.3/0.4\n. Modules and API Tree are different concepts and can coexist. API Tree is a convenient way to expose lots of functions using hierarchical name spaces. Modules are a convenient way to hide certain functions within a single name space.\nHaving everything exposed is a bad idea. There are so many architectural reasons for this that I cannot tell which one is the most important. One consideration is that if I know that certain identifier is module-private I have more confidence that I can change it without breaking something elsewhere. Now any function can be potentially called from anywhere - this is a recipe for disaster once project gets bigger.\nRegarding require I think the main disadvantage is that requires are dynamic. A static module system would help a lot. For example:\n1. A Javascript linker becomes easier to implement. Asset manager can stop sending unused modules to clients, and orphan modules can be much easier detected in large programs.\n2. Programs become easier to comprehend because you know the dependencies of the code you are looking at.\nAs Javascript is a dynamic language, a static module system means that module dependencies are not written in Javascript but either as pragmas (special comments) or completely separate make-type dependency specification language. Exports can remain dynamic just like they are now in CommonJS Modules Spec.\n. Also note that there are 2 separate ways for a session to expire:\n1) browser forgets session cookie because of cookie expiration or manual deletion\n2) server forgets session data because of session store purging (e.g. using Redis SETEX/EXPIRE timeout)\nAlso there are session cookies which expire when you close browser window.\n. Note that SETEX expiration is implemented in #127\n. See #89\n. I also submitted a bug to node.js: https://github.com/joyent/node/issues/1797\n. Then why you are closing the issue despite it's not resolved yet? The issues are there to remind about open problems.\nhttp://mmonit.com/monit/documentation/monit.html can be used to restart node if it is high on resource usage:\nif totalmem > 100.0 MB for 2 cycles then restart\nsame applies for CPU\n. That's why master branch is there. Push your latest dirty untested work at least weekly to master branch. A more common approach is to do many very small commits and pushing often, few times a day - look at https://github.com/joyent/node/commits/master for example.\nGitHub is a social development website, not just a hosting for source tarballs. Other people are there to help you with development, so by releasing work as often as it's comfortable for you you will get much more help and feedback.\n. Node itself can accept both forward and backward slashes. But your code expects only forward slashes and breaks.\n. I found a solution myself: action function has ss argument, and it can be used for my use case:\njavascript\nexports.actions = function (req, res, ss)\n{\n    foo.on('tick', function ()\n    {\n        ss.publish.all('foo', [ ' bar' ])\n    })\n    return {\n       action1 : function (...) { ... }\n       action2 : ...\n       ...\n   }\n}\nI think you should add this to the doc\n. It is not good because actions() is called every time an action arrives. So more and more handlers attach to foo over time. Of course I can use a flag to prevent multiple attachments, but that's inconvenient.\nAnother drawback is that I cannot broadcast before I receive the first RPC from the first client. So in case RPCs are not needed, a programmer is forced to send a fake RPC from a client just to get an instance of ss at the server.\nA possible solution is to have exports.init = function (ss) which is guaranteed to be called once upon server startup if present. Or to export a useful instance from socketstream module, so the following example works:\njavascript\nvar ss = require('socketstream')\nss,publish.all('foo', [ ' bar' ])\nOr we can use an asynchronous interface to wait  if  all() is not always available:\njavascript\nvar ss = require('socketstream')\nss.getInstance(function (ss) { ss.publish.all('foo', [ ' bar' ]) })\n. ss.api.publish.all() is fine\n. Seems fixed in 0.3alpha4 \n. > If you'd like to have a look at how we can do this (without relying on Socket.IO \n\nsessions as the transport is now modular) that would be great.\n\nI'll take a look at it as we have two options now in our project: either patch 0.2 or 0.3 to include such session support. I'll show you my findings regarding 0.3 (for 0.2 my attempt was #89).\n. You can write your own session store for Connect and use it in both SS and Connect parts.\nAlso note that you only set userId and don't provide a full session object for sockets yet. The patch allows web sockets to see userId from connect session object, but not other values.\n. I confirm that this still happens in alpha4.\nTo reproduce, remove existing server/rpc/demo.coffee and put demo.js there instead with nonsense code like foo)bar.\nExpected behaviour: server displays an uncaught exception stacktrace and exits.\nActual behaviour: server displays an exception without a stacktrace and keeps running.\nI couldn't reproduce this with the demo chat application,  that because I cannot install Hogan, see https://github.com/socketstream/ss-hogan/issues/1\nBut I can reproduce with my app. Can you confirm the bug with chat app?\n. Somehow it doesn't. All I get is\n/home/foo/server/rpc/app.js:1\nfoo)bar\n   ^\n. no. We looked specifically for this.\n. Nothing interesting:\n[quux@bar ~]$ grep -R uncaughtException node_modules\nnode_modules/q/README.md:``process`` ``\"uncaughtException\"``.\nnode_modules/q/CHANGES.md:   emit ``uncaughtException`` events, and browsers to\nnode_modules/q/CHANGES.md:   now emitted to Node's `\"uncaughtException\"` `process`\nnode_modules/qq/CHANGES:   now emitted to Node's `\"uncaughtException\"` `process`\nnode_modules/ss-coffee/node_modules/coffee-script/lib/coffee-script/repl.js:  process.on('uncaughtException', error);\nnode_modules/socketstream/lib/socketstream.js://process.on('uncaughtException', function (err) { console.error('Exception caught: ', err)})\nnode_modules/socketstream/node_modules/mocha/_mocha.js:    process.removeListener('uncaughtException', uncaught);\nnode_modules/socketstream/node_modules/mocha/_mocha.js:  process.on('uncaughtException', uncaught);\nnode_modules/socketstream/node_modules/mocha/lib/runner.js:    process.removeListener('uncaughtException', uncaught);\nnode_modules/socketstream/node_modules/mocha/lib/runner.js:  process.on('uncaughtException', uncaught);\nnode_modules/socketstream/node_modules/mocha/History.md:  * Fixed \"test end\" event for uncaughtExceptions. Closes #61\nnode_modules/socketstream/node_modules/mocha/mocha.js:    process.removeListener('uncaughtException', uncaught);\nnode_modules/socketstream/node_modules/mocha/mocha.js:  process.on('uncaughtException', uncaught);\nnode_modules/socketstream/node_modules/mocha/mocha.js:  if ('uncaughtException' == e) {\nnode_modules/socketstream/node_modules/mocha/mocha.js:  if ('uncaughtException' == e) {\nnode_modules/socketstream/node_modules/redis/test.js:process.on('uncaughtException', function (err) {\nnode_modules/socketstream/node_modules/coffee-script/lib/coffee-script/repl.js:  process.on('uncaughtException', error);\nnode_modules/socketstream/node_modules/socket.io/node_modules/redis/test.js:process.on('uncaughtException', function (err) {\nnode_modules/socketstream/node_modules/socket.io/node_modules/socket.io-client/node_modules/ws/test/autobahn.js:process.on('uncaughtException', function(err) {\nnode_modules/socketstream/node_modules/socket.io/node_modules/socket.io-client/node_modules/ws/test/autobahn-server.js:process.on('uncaughtException', function(err) {\nnode_modules/socketstream/src/socketstream.js://process.on('uncaughtException', function (err) { console.error('Exception caught: ', err)})\nI'll keep investigating and let you know. I suspect a try-catch block in connect.\n. I still get the same behavior. The following on stderr and nothing on stdout:\n/home/foo/server/rpc/bar.js:2\n});\n^\n. > To reproduce, remove existing server/rpc/demo.coffee and put demo.js there instead with nonsense code like foo)bar.\n\nExpected behaviour: server displays an uncaught exception stacktrace and exits.\nActual behaviour: server displays an exception without a stacktrace and keeps running.\n\nStill happens in my project with latest SS\nAs now ss-hogan is fixed, I'll try to reproduce with your test chat app and let you know the result\n. Cannot reproduce with test chat app - I see the expected \"tracing and dying\" behavior with it.\nI'm closing the bug then.\n. Tracked down this to a bug in my RPC action file (server/rpc/foo.js). Because of this bug an exception was thrown in socketstream.js from ws.responders.load() call but it was then silently caught. Can you ensure that such exceptions are not silently caught but at least produce a message in the logs?\n. Still happens in 0.3 alpha 3 (I run with SS_DEV=1):\nTypeError: Cannot read property 'html' of null\n    at Client.html (/home/ics/node_modules/socketstream/src/client_asset_manager/client.coffee:88:21)\n    at Client.htmlFromCache (/home/ics/node_modules/socketstream/src/client_asset_manager/client.coffee:61:23)\n    at ServerResponse.serve (/home/ics/node_modules/socketstream/src/client_asset_manager/index.coffee:35:21)\n    at Object.<anonymous> (/home/ics/app.js:35:7)\n    at nextMiddleware (/home/ics/node_modules/connect/lib/middleware/router.js:175:25)\n    at param (/home/ics/node_modules/connect/lib/middleware/router.js:183:16)\n    at pass (/home/ics/node_modules/connect/lib/middleware/router.js:191:10)\n    at Object.router [as handle] (/home/ics/node_modules/connect/lib/middleware/router.js:197:6)\n    at next (/home/ics/node_modules/connect/lib/http.js:203:15)\n    at Object.bodyParser [as handle] (/home/ics/node_modules/connect/lib/middleware/bodyParser.js:88:61)\n. Do you have an idea where exceptions can be silently caught? I use SS_DEV=1 so process.on('unhandledException' is commented out. Where should I look at?\nAt the moment at least two different types of exceptions are silently caught:\n1. Syntax errors in files in server/rpc/\n2. Runtime errors during execution of rpc handlers.\nWe are really tired setting try-catch blocks around our code to debug, so I'm going to work on that. Do you have an idea where it's better to start? How do you see RPC debugging and error reporting in SS in general?\n. We got the error again. Now it looks like this (last sources from git, SS_DEV=1):\nTypeError: Cannot read property 'html' of null\n    at Client.html (/home/ics/node_modules/socketstream/src/client_asset_manager/client.coffee:88:21)\n    at Client.htmlFromCache (/home/ics/node_modules/socketstream/src/client_asset_manager/client.coffee:61:23)\n    at ServerResponse.<anonymous> (/home/ics/node_modules/socketstream/src/client_asset_manager/index.coffee:35:21)\n    at Object.<anonymous> (/home/ics/app.js:35:7)\n    at nextMiddleware (/home/ics/node_modules/connect/lib/middleware/router.js:175:25)\n    at param (/home/ics/node_modules/connect/lib/middleware/router.js:183:16)\n    at pass (/home/ics/node_modules/connect/lib/middleware/router.js:191:10)\n    at Object.router [as handle] (/home/ics/node_modules/connect/lib/middleware/router.js:197:6)\n    at next (/home/ics/node_modules/connect/lib/http.js:203:15)\n    at Object.bodyParser [as handle] (/home/ics/node_modules/connect/lib/middleware/bodyParser.js:88:61)\nI found that the exception is thrown from ss.serve('main'). Note that I use connect for the main web server, so I call res.serve from within a connect router callback:\n``` Javascript\nfunction routes(app)\n{\n    app.get('/', function (req, res) {\n        res.serve('main')}\n    )\n}\nvar app = connect.createServer(\n    connect.logger()\n,   ss.http.middleware\n,   connect.bodyParser()\n,   connect.router(routes)\n)\n```\nThe problem is not catching the exception, but the occurence of the exception in the first place.\nThe exception is thrown because of the following line in src/client_asset_manager/client.coffee:\nCoffeescript\nif ssClient.html?\nssClient itself is null here, so an attempt to check if its property is set crashes.\nThe bug turned out to be because of missing socket.io dependency: I forgot to update socket.io on one of our development PCs. That exception was silently caught somehow so later another exception appeared. \nA quick an dirty workaround is to put try-catch block in socketstream.js in start().\n. Closing for now - we haven't seen this problem for long time.\n. I think it's better to die with an informative diagnostic message, for example: \n/home/foo/bar.orig: Error: Unsupported file extension orig. Please provide a formatter.\n. io.sockets.emit('message', msg) accepts an object, while socket.send(data) accepts a string. So you shouldn't JSON-encode msg but pass a Javascript object instead, and emit will call JSON.stringify for you.\n. I was thinking of converting that to \n{\"x\" : \"event, \"t\":\"all\",\"e\":\"newMessage\"....\nYou already use JSON for serialization, why mix it with something else (the event\u00a7 and rpc\u00a7 prefixes)? Also think of replaceable effective serializers such as MessagePack, Thrift, ProtocolBuffers etc \n. I do that every time you release an update :) I have updated all developer hosts now, but the error persists.\n. The bug is still there. Note that we use Express for HTTP routing and Chrome for testing. \n. Here is what I found:\nhttps://github.com/socketstream/socketstream/blob/master/src/websocket/transports/socketio/index.coffee\nprocessSession returns false in 2 cases. However, diagnostic message is displayed only in one case. Here is JS compilation result, so implicit returns are visible:\n``` Javascript\nprocessSession = function(socket) {\n  var cookie, rawCookie, sessionId;\n  if (socket.sessionId) return true;\n  try {\n    rawCookie = socket.handshake.headers.cookie;\n    cookie = qs.parse(rawCookie);\n    sessionId = cookie['connect.sid'].split('.')[0];\n    return socket.sessionId = sessionId;\n  } catch (e) {\n    console.log('Warning: connect.sid session cookie not detected. User may have cookies disabled or session cookie has expired');\n    return false;\n  }\n};\n```\nI suggest to move console.log outside to the call site, to the else branch of if (processSession(...))\nNote also that this code will throw if socket is somehow undefined, for example, because of a bug in socket.io\n. I'm still experiencing this to the extent I abandoned using SS.ready in my app.\n. You can close it for now. I can't tell you if it's broken because I don't use it in production, and the issue was relatively rare.\n. >  I've not heard of anyone reporting this problem for months\nWe stopped to use ss.ready months ago, that's why. It seems to work without it, and we were too lazy to enable it back to see if it became reliable.\n. The image files are already in /client/static/images and it works most of the time, but sometimes for some unknown reason  SocketStream wants to serve them using _serverDev instead of static middleware.\n. Here is the third solution we actually use: put your CSS to static/ folder :)\nThe bug was on our side: we had 2 copies of one CSS file in different folders because of problems with source control. Closing.\n. Can it be SocketStream.ss.model and such? BTW we use backbone.js client-side models with current socketstream.\n. It doesn't have to be too wordy. I can write\nJavascript\nvar ss = require('socketstream').ss.model\nonce per file. I have to do something like that in Node.JS anyway, so same requirement on client doesn't feel like an inconvenience.\nMoreover, the variable doesn't have to be global - we can reserve globals only for legacy client-side libraries which cannot be run as a CommonJS module. We can wrap our main module in a closure the same way we wrap non-main modules, so any variables defined in the main module are local to the closure. And the main module won't have exports just like in Node.js it doesn't.\n. I think this can be closed for now, as channels seem to do their job.\n. Closing for now then. I'll investigate it closer and re-open if it's because of socketstream\n. Investigation showed the bug is because of SocketStream. We delay ss.start(server) until our other components have started, and that takes up to a minute. Termination before SocketStream has started is always instant. So the tests below are performed when log shows that SS has started. By \"slow\" I mean takes 10+ seconds. Instant is instant - probably less than 0.2 sec.\nCase 1\nBoth SS_ENV and SS_DEV are unset. Termination is slow.\nCase 2\nSS_ENV is unset. SS_DEV=1. Termination is slow.\nCase 3\nSS_ENV=production. SS_DEV=1. Termination is instant\nCase 4\nSS_ENV=production. SS_DEV is unset Termination is instant\nSo I think it has something to do with monitoring for changes and/or the router.\n. I have 91 file in client:\n[foo@bar ~]$ find client -type f | wc -l\n91\nCommenting the line helped!\n. I still get a red string (the arrow and 'quux is not defined' are red):\n\u2192 rpc:1 app.init quux is not defined\nI also noticed a stacktrace in browser console in client. Is this intended behaviour? It exposes server internals to clients in production mode, which is not good. It's fine in development mode though, but in production no stack traces must be visible to clients, as that may help to find exploits.\n. No problems in our app with 0.9.0 so far. Thank you.\n. Basically, replace     .use(connect.static(staticPath)) in http/index.coffee with .use(gzippo.staticGzip(staticPath))\nThis should help to reduce download size for .js, .css and .html in production mode.\n. connect.compress() doesn't cache - it zips it every time which is waste of CPU for static files. \n. It seems they fixed the leak in node 0.7. https://github.com/joyent/node/issues/2504\nSo as soon as 0.8 becomes available (0.7 is an unstable branch) we should retest.\n. Here is early proof of concept code:\nhttps://gist.github.com/2029434\nI had to patch socket.io-client to add the handshakeHeaders option. The code creates 1000 clients in parallel. Each client sends  app.init RPC which subscribes it to a channel depending on account subscription status.\nThen every 15 seconds two events are broadcast using channels, so each of the 1000 clients receives only one.\n1000 parallel RPCs and broadcasts to 1000 clients don't put much load on the server which is a good sign.\n. I disable it as a workaround for #160.\nAlso, it is not a convenient feature for us. It is a pain to see our app reinitializing because you modified a file.\nWe use Chrome debugger and we may have some breakpoints. Page refresh triggers those breakpoints and debugger starts flashing in the task bar. Also our app take long time to initialize because it loads large datasets on startup, and it's a pain to see it reinitializing over and over while you are editing a file. You know that Ctrl-S habit to be safe in case of crashes, it makes too many reloads.\n. Try to put userId in session and let us know the results. My original patch only supported userId in session, as I didn't need anything else there.\n. It caches in memory\n. It only caches zippable assets - that is .js and .css. It seems to perform a match on MIME type using a configurable object with .test method (a RegExp for example):\nhttps://github.com/tomgallacher/gzippo/blob/master/lib/staticGzip.js\nJavascript\ncontentTypeMatch = options.contentTypeMatch || /text|javascript|json/,\n. zlib binding in node.js core turned out to cause memory leak. So we should wait until the leak is fixed. See https://github.com/joyent/node/issues/2933\n. There are many design options here. For example, you can just improve  serveClient implementation to be more friendly to external caches and caching middleware sitting on top of it. Or you can make it configurable.\nAlso note that it is hard to make reverse proxies caching both page versions in your example, so probably a different approach will be used by high-load sites (e.g. redirects or moving the switching logic to the proxy).\n. aaa.html \n. Yeah, you were not supposed to paste it as it wasn't a pull request but a dirty fix (we only needed IE9 as it has native canvas)\nWell, our app relies heavily on console.log so if you remove console.log altogether from SS core, we'll have to add a library anyway. Also grepping for console seems to find few references to it in the libraries we use, so it's really hard for us to avoid the console.\n. No, I still get 'console is undefined' in IE9 with current version from Git\n. I think it's a great decision. I was rather surprised to see you shipping a large console.log wrapping library. The current console.log wrapper has two flaws:\n- doesn't support all modern browsers\n- tries too hard to support ancient browsers.\nFor me 3 solutions are equally good:\n1. No dependency of SS on console.log and no console.log wrapper, so I can use my own if I need one;\n2. A simplistic wrapper only to ensure that calling console.log never causes crashes. No dancing to work around IE and Opera bugs, just a no-op log function for crash protection will suffice;\n3. A cross-platform alternative to console.log which sends logs to server and/or has a configurable client-side presentation layer.\n. I never used Hogan. The only thing I know about this library is that it is named in honour of Hulk Hogan, an actor with mustache :) I'm interested in it because it will allow me to run your chat app. Older Hogan doesn't install at all because of permission problem.\n. The problem was with hogan library, and I was waiting for Twitter people to fix it.\n. I just use config = require('./config') everywhere I need it. No need for SS to include configuration facilities.\n. I use Javascript. But you can write in Coffeescript, with automated translation by coffeescript module, not by Socketstream. \n. @haohello \nFor now you can use a reverse proxy to do the gzip work for you. Zlib bindings for node are leaky now, we can't do anything before that bug is fixed.\n. This approach is fundamentally limited by Rice's theorem - your dependency analyzer can never be both sound and complete. I can always write something like this to hide the dependency on baz module from the analyzer:\nJavascript\nsetTimeout(function { var bar = require; bar('ba' + 'z').foo() }, 8000)\nSo a more bulletproof approach is either to supply dependencies metadata manually (as NPM does) or to enforce some program structure, as AMD does.\nJavascript\ndefine(\"alpha\", [\"require\", \"exports\", \"beta\"], function (require, exports, beta) {\n     exports.verb = function() {\n         return beta.verb();\n         //Or:\n         return require(\"beta\").verb();\n     }\n });\nWith this AMD approach the dependency analyzer can run the define function on the server side to get the dependency info (without running the actual definition function!), which is both fast and doesn't require impossible analyses of turing-complete languages.\n. One rule is not enough. Here I don't pass variables into require, but create an alias for require:\nJavascript\nvar foo = require\nfoo('bar')\nSo now we have 2 rules: 1) pass variables into the require statement 2) don't create aliases for require\nBut now I can circumvent with the following:\nJavascript\nvar require = function () { }\nrequire('djfdkjfkdjf')\nNow we have a false dependency on djfdkjfkdjf. So we should add 3rd rule: don't shadow require identifier. I still can circumvent:\neval(\"req\" + \"uire('foo')\")\nSo we have 4th rule \"don't use eval\". Now I can still use the following without violating previous rules:\nglobal['req' + 'uire'] = function () {   } ; require('fjkdjfkd')\nSo we have 5 rules. Should I continue? :)\n. I just think that AMD is much better structure than current if static detection of dependencies is considered.\nPeople like simple rules. If rules are obscure, people start to treat libraries like magic black boxes which occasionally break. I think this is against the SS philosophy. While my mentioning of Rice's theorem were more of a pun, there are many pretty realistic situations when dependency detection by parsing may fail and lead to obscure errors. Obscure errors are opposite to user friendliness.\nIf a user refactors foo = require('bar'); baz = require('zoo'); quux = aaa ? foo : baz; into seemingly equivalent\nfoo = require(aaa ? 'bar' : 'zoo')\nshe will get a rather unexpected missing dependency error on the client. With AMD approach breaking by mistake or overlook is just  not possible, so it's less error prone and better.\n. @wmulligan That's just a bug which can be fixed without static dependency detection. It is pretty possible to detect the order without resorting to parsing. It is just somehow not done now, so feel free to open a separate issue for order detection. Of course for '/libs/' it's not possible - we are only talking about orderly initialization of commonjs modules.\n@mindeavor the CommonJS approach has an advantage over AMD: it's standard (many people feel good when they see something standards adopted) and it works in node.js out of the box (so sharing code between client and server is possible).\nI think we should proceed as following:\n- implement correct order detection in module initialization code\n- implement AMD module loader in addition to existing commonjs\nIt should be easier to implement efficiently than parsing.\n. I vote for closing. I never wanted AMD instead of CommonJS, just as a separate feature in addition to CommonJS to facilitate more usage scenarios and faster dep tracking. I'm pretty happy with current situation and against the dependency checks just like I opposed the automatic client refreshes.\n. Connect is designed the way so multiple versions can coexist. I'm using SS with Express without problems. Let me find what code I use.\n``` Javacript\nss.client.define('main', {\n    view:   'app.jade',\n    css:    ['libs', 'app.styl'],\n    code:   ['libs', 'main'],\n    tmpl:   ['main']\n})\n// Remove to use only plain .js, .html and .css files if you prefer\nss.client.formatters.add(require('ss-coffee'))\nss.client.formatters.add(require('ss-jade'))\nss.client.formatters.add(require('ss-stylus'))\nfunction routes(app)\n{\n    app.get('/', function (req, res) {\n        res.serve('main')}\n    )\n}\nvar app = express.createServer(\n    express.logger({stream : openForAppend(\"var/log/http.log\")})\n,   ss.http.middleware\n,   express.bodyParser()\n,   express.router(routes)\n)\nvar server = app.listen(3000);\nss.start(server);\n```\nNote that you can remove whatever middleware you don't need (logger, bodyparser). And openForAppend is my own function, so feel free to define it using fs.createWriteStream if you want express to log to file.\n. @trungpham These files are not dynamic. Timestamps are used to force expiration every time socketstream server is restarted, not every time a request is made. So we don't pay a latency penalty.\n. The problem is that socketstream uses connect.session internally, so you cannot have different secret and key than socketstream. Here is the relevant fragment from src/http/index.coffee if you consider patching it to replace secret and key:\nCoffeeScript\n  load: (sessionStore, sessionOptions) ->\n    # Append SocketStream middleware upon server load\n    app\n    .use(connect.cookieParser('SocketStream'))\n    .use(connect.favicon(staticPath + '/favicon.ico'))\n    .use(connect.session(\n      cookie: { path: '/', httpOnly: false, maxAge: sessionOptions.maxAge },\n      store: sessionStore\n    ))\n. I think he only wants an ability to set arbitrary cookie name and secret instead of using the values hardcoded into socketstream.\n. Our fix consists of 3 parts:\n1. insertion of HTTP middleware before socket.io (no patching of anything required)\n2. storing req.sessionID set by connect middleware in socket.io handshake object (1 line in socket.io lib/manager.js)\n3. using handshake.sessionID instead of handshake.headers.cookie in socketstream processSession() (1 line in socketstream websocket/transports/socketio/index.coffee)\nIt is far from being a pull request, but you should understand the idea.\nPutting middleware before socket.io\nThis code we use in app.js to start the server. Dependency on express can be easily removed and the rest can be put inside ss.start and http.middleware.\nSocket.io decorates a passed instance of builtin node HTTP server with its handlers for various events (connect, close, upgrade, request and maybe something else). We are only interested in the request handler installed by socket.io. We remove the handlers (an array of functions with 2 arguments and this) and convert it to a connect middleware (a single function with 3 arguments, 3rd is unused in our case).\nThen we install the middleware function in our HTTP middleware chain so it comes after connect.session middleware and not before.\n``` Javascript\nvar socketIoRequestHandler\nfunction routes(app)\n{\n    app.get('/', function (req, res) {\n        res.serve('main')\n    })\n    // This can be implemented in socketstream just by comparison of req.url\n    // without express router. This redirection of certain requests \n    // should be in ss.http.middleware at any point after connect.session\n    app.all('/socket.io/*', socketIoRequestHandler)\n}\nvar app = express.createServer()\nvar server = app.listen(3000);\nvar defaultListeners = server.listeners('request')\nss.start(server)\nvar ioRequestListener = server.listeners('request')\nsocketIoRequestHandler = function (req, res, next)\n{\n    ioRequestListener.forEach(function(listener)\n    {\n        listener.call(server, req, res)\n    })\n}\nserver.removeAllListeners('request');\ndefaultListeners.forEach(function (l)\n{\n    server.on('request', l)\n})\n// at this stage we removed listeners for request events installed by\n// socket.io and replaced then with default listeners\n// the removal and replacement should be a part of ss.serve()\napp.use(ss.http.middleware)\napp.use(express.router(routes))\n```\n. ## Storing req.sessionID in socket.handshake\nA single line in Manager.prototype.handshakeData function in lib/manager.js of socket.io:\nJavascript\n  return {\n      headers: data.headers\n    , address: connectionAddress\n    , time: date.toString()\n    , query: data.query\n    , url: data.request.url\n    , xdomain: !!data.request.headers.origin\n    , secure: data.request.connection.secure\n    , issued: +date\n    // we just add this line\n    , sessionID : data.request.sessionID\n  };\nNote that connect session object is also accessible here. So we could just use session : data.request.session and remove the need to reimplement an identical session object (and stores!) in socketstream. But we chose just to get sessionID to keep changes in socketstream minimal.\nWe cannot use data.headers.cookie because it only contains request headers. If a socket.io handshake request is the first request  reaching origin servers, then connect.session engages because of the previous fix and sets Set-cookie header before handshakeData() receives control. But it's a response header and not a request header, so it's not in the headers field.\nNode doesn't provide a way to inspect response headers already injected into current response, but fortunately connect.session middleware also monkey patches request object by adding .session and .sessionID fields. The latter is just a session ID without a HMAC signature, so it can be used by socketstream to fetch data from session store without additional parsing.\nBasically, data.headers.cookie is not always present, but data.request.sessionID and .session are always present after our previous fix and contain the session information we need.\nUsing handshake.sessionID instead of handshake.cookie\nThis step is trivial. Here is a dirty fix:\n``` diff\ndiff --git a/src/websocket/transports/socketio/index.coffee b/src/websocket/transports/socketio/index.coffee\nold mode 100644\nnew mode 100644\nindex b07843f..c46875e\n--- a/src/websocket/transports/socketio/index.coffee\n+++ b/src/websocket/transports/socketio/index.coffee\n@@ -66,10 +66,7 @@ processSession = (socket) ->\n# Parse session ID from initial hankshake data\n   try\n-    rawCookie = socket.handshake.headers.cookie\n-    cookie = qs.parse(rawCookie, '; ')\n-    sessionId = cookie['connect.sid'].split('.')[0]\n-    socket.sessionId = sessionId\n+    socket.sessionId = socket.handshake.sessionID\n   catch e\n     console.log('Warning: connect.sid session cookie not detected. User may have cookies disabled or session cookie has expired\n     false\n```\n. Cookies serve only the purpose of linking HTTP sessions to Websocket connections. If you want your users authenticated by openid/oauth, you need this linking. If linking is not needed, cookies should not be used. It is not needed in case of password-based authentication, but password based auth is so 20th century and Web 1.0 :)\n. oh lol, it turned out that ss.event was replaced by ss.server, but ss.event somehow continued to work without throwing an exception.\nClose this issue if API change from ss.event to ss.server was documented.\n. Done\n. I think channel subscription should be per connection and not per session.\n. > I think we should leave the decision to the app developer a  d provide the best tools for both approaches. \nI agree\n. Few thoughts:\n- I use varnish reverse proxy to move all burden away from node.\n- There is a free Coral CDN which is good only to redirect traffic spikes to it so your site doesn't completely die. It requires to issue redirects from foo.com/bar.js to foo.com.nyud.net/bar.js depending on user-agent. So if you want CDN support built into SS I think this scenario should also be implementable with your framework.\n- I'll take a look on Rackspace Cloud way of using Akamai CDN to include it as a separate scenario too\n. > one could gzip the minified files already\nThere is an issue for that: #165\nWe cannot do that before the release of node v0.8.x as there are various bugs in gzipping module. I use varnish reverse proxy with various hacks to compress assets.\n. So I can just call packAssets() and assets will be properly repacked and re-read from disk? I didn't know it was safe to call packAssets() multiple times during app lifespan.\n. req and res are not available in ss rpc responders because there are no HTTP requests or responses. RPC responders can work over web sockets or over flash sockets.\nconnect sessions are available in ss rpc responders, and req/res are available if you process HTTP requests.\n. It will work because socket.io performs an HTTP handshake even in case of Flash sockets\n. In RPC methods connection handshake is over - it's too late.\nDirect access to Socket.io handshake could be beneficial, but what about  transports other than socket.io? \n. You have access to cookies from HTTP requests and on client. If you need a non-httponly cookies use separate AJAX requests or connect middleware for that. \nI don't think the idea to misuse Socket.io handshake to access cookies is good - the access is possible only once per session so it is not worth the effort.\n. ",
    "arumons": "It is a good idea. \nI'll begin to translate document v0.2. \n. It is a good idea. \nI'll begin to translate document v0.2. \n. ",
    "sberryman": "Well now that you changed the way static assets are served (looks like they are coming from _serveDev in development) how would you go about linking to a print stylesheet?\n. Thanks @owenb, I ended up going that route. @nponeccop I tried doing that at first but it didn't seem to be working in Chrome. Either way, thanks for the feedback. @owenb is this going in to the docs you are preparing for the 0.3 release? \n. Yeah, nothing is really documented on other assets. Like how to link to static images or in this case css. Also the fact that you cant use LESS or Stylus.\nMore of just an FYI than anything else really. There is no way to use files locally and then take advantage of CDN in production either (at least easily.)\nAs a complete side note, does anyone have any suggestions to remove console.log in production? I log a ton while developing, I guess I could write my own log level wrappers though but wasn't sure if there is a standard out there or some compilation flag for coffee-script that would strip out all console.log messages.\n. I figured it out, I was looking at old documentation.\nIt would have been nice with an example for backbone but it really is easy when you include underscore and backbone in the client/code/libs folder.\n. I love the focus on this issue right now. I would actually like to make the build process a little more static? I want to build everything on my dev box and push to CDN (basically disabling build in production) OR use @plievone approach and have CloudFront pull the assets on demand.\nI was thinking that a build server would build everything on git push, upload to S3 and create a tarball of all the project files. Maybe that is the \"old\" way of doing deployments but it is also a very reliable method.\n. You'll hear a much better answer from owenb on this but I asked about this in the past. I think he is saving this for the 0.4 release and probably wants your feedback on how you would like this implemented. I found the best way to do this for now is to use cloudfront and set the origin to my server. I also used gzippo (https://github.com/tomgco/gzippo) to compress the files on the fly.\njavascript\nss.http.middleware.append(gzippo.staticGzip( __dirname + ss.client.options.dirs.static))\nI don't have a huge load on my app so this hasn't been an issue for me yet but the compressing of the assets really helped.\n. while you're at it, upgrade connect and connect-redis (1.4.4) as well. connect-redis (1.4.4) is pegged to redis 0.8.1 now.\n. @americanyak 0.9.10 does not have redis as part of devDependency. It has been updated in the master branch but it hasn't been pushed to npm yet.\nhttps://github.com/LearnBoost/socket.io/issues/1030\nWe'll have to wait until they push a new version\n. Just an FYI. I was working with @bradleymeck from Nodejitsu today to get this working. I used my fork of socketstream where I point socket.io to the master branch. Everything seems to build correctly but we ran into a ENOMEM issue when trying to spawn the app. He is going to look into that this evening and will post updates when I have them. He did confirm there were ZERO build issues which was great to hear.\n. Thanks!\nOn Sep 13, 2012, at 2:00 PM, Owen Barnes notifications@github.com wrote:\nThanks Shaun\nWas going to get this out tonight but you beat me to it :) Working on a new\nReadme into, so I'll push that later on, bump the version number on that,\nand push to npm.\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/socketstream/socketstream/pull/296#issuecomment-8543338.\n. Agree, would love to see this in 0.4\nOn Nov 23, 2012, at 3:49 PM, jbremmer notifications@github.com wrote:\nAny i18n tips/suggestions? Ideally solution supporting server and client\nside at the same time.\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/socketstream/socketstream/issues/324.\n. Well now that you changed the way static assets are served (looks like they are coming from _serveDev in development) how would you go about linking to a print stylesheet?\n. Thanks @owenb, I ended up going that route. @nponeccop I tried doing that at first but it didn't seem to be working in Chrome. Either way, thanks for the feedback. @owenb is this going in to the docs you are preparing for the 0.3 release? \n. Yeah, nothing is really documented on other assets. Like how to link to static images or in this case css. Also the fact that you cant use LESS or Stylus.\nMore of just an FYI than anything else really. There is no way to use files locally and then take advantage of CDN in production either (at least easily.)\nAs a complete side note, does anyone have any suggestions to remove console.log in production? I log a ton while developing, I guess I could write my own log level wrappers though but wasn't sure if there is a standard out there or some compilation flag for coffee-script that would strip out all console.log messages.\n. I figured it out, I was looking at old documentation.\nIt would have been nice with an example for backbone but it really is easy when you include underscore and backbone in the client/code/libs folder.\n. I love the focus on this issue right now. I would actually like to make the build process a little more static? I want to build everything on my dev box and push to CDN (basically disabling build in production) OR use @plievone approach and have CloudFront pull the assets on demand.\nI was thinking that a build server would build everything on git push, upload to S3 and create a tarball of all the project files. Maybe that is the \"old\" way of doing deployments but it is also a very reliable method.\n. You'll hear a much better answer from owenb on this but I asked about this in the past. I think he is saving this for the 0.4 release and probably wants your feedback on how you would like this implemented. I found the best way to do this for now is to use cloudfront and set the origin to my server. I also used gzippo (https://github.com/tomgco/gzippo) to compress the files on the fly.\njavascript\nss.http.middleware.append(gzippo.staticGzip( __dirname + ss.client.options.dirs.static))\nI don't have a huge load on my app so this hasn't been an issue for me yet but the compressing of the assets really helped.\n. while you're at it, upgrade connect and connect-redis (1.4.4) as well. connect-redis (1.4.4) is pegged to redis 0.8.1 now.\n. @americanyak 0.9.10 does not have redis as part of devDependency. It has been updated in the master branch but it hasn't been pushed to npm yet.\nhttps://github.com/LearnBoost/socket.io/issues/1030\nWe'll have to wait until they push a new version\n. Just an FYI. I was working with @bradleymeck from Nodejitsu today to get this working. I used my fork of socketstream where I point socket.io to the master branch. Everything seems to build correctly but we ran into a ENOMEM issue when trying to spawn the app. He is going to look into that this evening and will post updates when I have them. He did confirm there were ZERO build issues which was great to hear.\n. Thanks!\nOn Sep 13, 2012, at 2:00 PM, Owen Barnes notifications@github.com wrote:\nThanks Shaun\nWas going to get this out tonight but you beat me to it :) Working on a new\nReadme into, so I'll push that later on, bump the version number on that,\nand push to npm.\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/socketstream/socketstream/pull/296#issuecomment-8543338.\n. Agree, would love to see this in 0.4\nOn Nov 23, 2012, at 3:49 PM, jbremmer notifications@github.com wrote:\nAny i18n tips/suggestions? Ideally solution supporting server and client\nside at the same time.\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/socketstream/socketstream/issues/324.\n. ",
    "owenb": "Or, if you don't mind writing it in pure CSS (as apposed to Stylus), put it in /client/static/css/myprintsheet.css and put your own manual <link> tag in the headers with the file pointing to /css/myprintsheet.css\n. Glad it's working for you.\nI'd like it to go in the docs. Not quite sure what section it would fit into. We have a page on Client Code already, but this is really other assets.\n. Thanks for the feedback. Will try to get round to writing this up shortly. \nAgreed with the CDN issue. I would like to find a solution to this - not quite so easy as with Rails as we're not making people using the image_tag() helper or anything.\nRegarding logging, short answer is there is no way to silence them at the moment in production but I hope to address this sooner than later.\nThis area still needs a lot of thought. I got quite far into integrating Winston, only to find out it didn't take multiple params and made for a rather messy experience when developing (a lot of datestamps etc could not be edited without hard patching). There are several other logging libs I'd like to try before making a final decision.\n. Can you let me know if you're still having problems here and close the issue if not. Cheers\n. Sorry, what do you do to get:\n/home/foo/server/rpc/bar.js:2\n});\n^\nIf there are any more obvious error cases I've overlooked I want to try and fix them before 0.3.0\n. Can you let me know the status here. There is no ssClient in beta1 so I'm hoping this is no longer a problem.\n. Hi Robert\nWhere does your swf file live? Also, are you running a recent version of SocketStream?\n. Don't worry, this problem is now fully fixed in the lastest alpha (alpha5). I am finishing it up and will release it in the next few days.\n. This is now fixed in alpha5\n. Hi all\nPlease try again with alpha5 as there have been major client-side changes. If you're still having problems I'm determined to get to them bottom of them. Any debugging info you can provide would be very helpful.\n. Guys any update on this? Please make sure you're running the recent release as there's been a change to the way the cookie string is split.\nIf anyone is still having problem running the latest code I'll add more debugging as @nponeccop suggests, otherwise I will close this issue.\n. Hi there\nIf anyone is having problems with this please let me know. Make sure you're running the latest master.\n_Note - very important! _ ss.event became ss.server a while ago.\n. Hi there\nAre you using Express? Have you seen any error messages complaining about missing session cookies?\n. Hmm ok. I asked because I just debugged a similar problem which turned out to be caused by Express extending Node's HTTP request object in a way which was making cookie parsing intermittent. Incidentally if anyone has this issue, reversing the require order so you require('socketstream') before require('express') fixes the issue. I will debug this further next week as the load order should clearly not make a difference!\nBut back to your issue... As I've not heard of anyone reporting this problem for months, it would be helpful if you can insert some debug logging around here:\nhttps://github.com/socketstream/socketstream/blob/master/lib/websocket/transports/socketio/index.js#L44\nLet's see how far we're getting. I assume processSession() is returning correctly otherwise you would see the Warning: connect.sid session cookie error I mentioned in the terminal.\nThanks,\nOwen\n. Ah ok. Definitely a transport issue with Heroku. Engine.io (which we're going to use in SocketStream 0.4) should work well with Heroku, but right now I would recommend against hosting there. That said, you maybe able to get it to work by shuffling the transports around and inserting some debugging code to ensure the session cookie is parse correctly. Good luck!\n. Ah right. Apologies - you are the only person I know of who is using SocketStream on Heroku so the advice I can provide is limited. Very glad to hear things are working out for you, by and large.\nI am not against the idea of exposing the other Socket.IO connection events in principal, but we will need to make it clear that not all events are supported on all transports. I think most users will understand that. Hopefully in the future it will be possible to ensure ss-sockjs can emit these additional event types by coding this into the module.\n. Ha ok, well if you do get chance to re-enable it, please do. It needs to be 100% reliable and if it's we need to fix it.\n. Fixed this in beta1 (as much as possible) by rewriting the error message so it's much clearer, explaining what file is causing the problem and what to do about it.\n. This is now implemented in alpha5. We setup\nwindow.ss = require('socketstream')\nby default so you can call ss() commands via the browser's console, but there's nothing to stop you putting\nvar ss = require('socketstream')\nat the top of every file if you prefer.\n. Closing for now. See reason in #182\n. Hi all\nThanks for this, and apologies for the late reply.\nHaving given this some thought I think it's pretty clear we need a few API calls on the collections of 'users', and 'channels' - and maybe 'sessions' as well.\nE.g:\n``` javascript\n// get a list of socketIds in use by a particular userId (will also tell you how many devices this userId is using)\nss.users.find(userId) -> [array of socketIds]\n// get a list of socketIds in use by a particular sessionId (i.e. how many open tabs)\nss.sessions.find(sessionId) -> [array of socketIds]\n// unsubscribe all sockets (devices) attached to this userId (effectively logging the user out of all devices simultaneously) \nss.users.unsubscribeAll(userId) -> true\n// get a list of sockets subscribed to a particular channel\nss.channels.find(channelName) -> [array of socketIds]\n// unsubscribes all sockets from the named channel\nss.channels.unsubscribeAll(channelName) -> true\n```\nToo late to put them into 0.3 now, but I'll earmark this for 0.4. Of course the actual API may change - I'll have to give it more thought. Suggestions welcome.\n. Hey Robert\nThat would be awesome if you could add these changes to 0.3. In fact, if you could do that and update the dependencies, I'm happy to do another 0.3 release.\nLet me know if you run into any problems.\nOwen\n. Hi there\nI have tried running SS_ENV=production nodemon app.coffee and it all works fine. This could be because lots has changed in beta1.\nClosing this now but please repen if you have the same problem.\n. Fixed in 0.3 beta1\n. Still not had time to write this yet but thankfully these event handlers are now created for you by default in entry.js', plus their names are pretty self explanatory (with the exception ofready` which just means SocketStream has fully loaded, your session has been created and we are now ready to accept incoming requests).\nIdeally we need a doc page called \"Handling disconnections\" or something like that which documents all the events and provides tips on handling reconnections. Contributions gratefully received.\n. Thanks @nponeccop \n@dennismartensson has also been working on this problem and has posted a project here: https://github.com/dennismartensson/load_test\nI have yet to fully dive into it, but I know it uses PhantomJS to spawn new headless browsers to test concurrency.\n. Yes, Thor is great! It came out very recently.\nIf you pass it a generator file you can simulate load on a SS server by sending it the same message an ss.rpc() produces.\nHaven't got around to using it with SocketStream yet, but if you get chance, I'd love to see how it goes.\n. Hey there\nIf I understand right, we need to allow you to pass custom local vars here:\nhttps://github.com/socketstream/ss-jade/blob/master/lib/wrapper.js#L23\nIf this sounds right we can make this a config option for ss-jade\n. Cool ok. I will implement this after the next SocketStream release is out.\n. Yes there is indeed, it's in the HISTORY.md file\nss.client.set({liveReload: false})\n. (oh and more interestingly for me, why do you want to disable it - does it not work as you expect?)\n. Hey there\nAre you calling req.session.save() after updating the req.session object?\n. Hey\nCan you let me know if this is still a problem and close the issue if it's now resolved.\nThanks\n. Closing this issue for now. Once gzipping assets becomes simple and stable we will support it.\n. Hey. It's caused by images in your css directory. See the #155\nWe still need to find a better solution to this\n. I have improved this error message in the forthcoming beta1 release\n. Very true.\nWe used to serve it statically in previous versions, but things became more complicated with multiple clients. For example you can now do:\njavascript\nss.http.router.on('/', function(req, res) {\n  if (req.headers['user-agent'].match(/iPhone/))\n    res.serveClient('iphone');\n  else\n    res.serveClient('main');\n});\nWhich needs to be processed by Node in production mode as well as development.\nStill I am interested in finding a way to serve the root HTML statically if you don't need to interpret the incoming request, as I fully agree everything should be on a CDN if it can be. I'll have a think about it.\n. Indeed, only problem is you need to hit the HTTP server at some point now to get a cookie for use with your Connect Session.\nNow that all clients are now cached in RAM in production mode, things should be far faster than before.\nPlease feel free to add something here, or close the ticket if you're happy with this for now.\n. Hey David\nI like this new proposal of nesting dirs inside 'libs' but making them behave as 'libs'. We shouldn't need to involve any regexp parsing in that. Would certainly prefer to keep it simple but intuitive.\n. Code complexity mainly. A good design should be simple. I'm not sure we have that here yet, but hopefully we're on the right track.\nBut I'm happy to make sub directories of 'libs' act as 'libs' in a future release as this feels more intuitive and won't break anyone's code.\n. Agreed. Good point. This will be in the next release.\n. Yup indeed. Simple beats fuzzy every time. Too many choices are a bad thing and messy to document.\n. Thanks :)\nGoing to merge this into a local branch and see how it feels to use on a real project.\n. It's not impossible to do it this way, but not recommended.\nInstead put all your shared logic into regular node modules and require them at the top of your /server/rpc files. Ideally all your main business logic should live outside of /server/rpc files\n. I agree. It will all happen with time.\nWe're all learning how to do that to some extent.\n. You cannot do this inside SocketStream as such, but you can setup a route in app.js which sends a file.\nAlternatively, use SocketStream with something like Express to do the same thing.\n. I'm refactoring a lot of this code at the moment.\nCan you tell me what type of file you put in the client/code/libs dir to cause the error above?\n. Argh I love IE.\nCan't just paste the code in sadly as some older browsers don't support forEach()\nJust wondering if we could modify the way we use console in the SocketStream client code so we can remove this file and avoid the problem altogether.\n. I'm aware this is still a problem. Will look into it this week.\n. Hey @addyosmani \nJust wondering if you know of a better cross-browser implementation of console than the one we're using here:\nhttp://patik.com/blog/complete-cross-browser-console-log/\nIt's currently causing problems for us in IE9.\n@nponeccop if Addy doesn't know of anything better, I will attempt to fix the one we have using your suggestion.\n. Hi all\nNo change on this so far. I know this is a big issue but I need to find time to investigate the alternatives and get a working Windows VM to test with IE9.\nI'm writing some documentation for SocketStream at the moment. I hope to look at this issue next\n. I've read though the various options (thanks @addyosmani !) and had chance to rethink this.\nI believe the only time we (or you, the developer) should ever be using console.log is when you're developing your app. We should never be calling console.log in production and hence, we really shouldn't be sending a 1.3kb wrapper library to every client (including mobile clients).\nI initially put the console.log wrapper in because people were complaining the ss.rpc() commands weren't working correctly in their browsers. In fact, the RPC commands work fine, but the default callback (if you don't provide one) is console.log, hence older browsers were showing errors instead of the expected response.\nSo my preference is to take it out altogether. Yes, this will cause a few issues along the lines of \"ss.rpc() commands not working in browser X\"; but as most browsers now support console.log() with multiple arguments this shouldn't be as much of a problem as it used to be.\nIf there are no strong objections I'll remove the wrapper in the next release (hopefully out in a few days).\n. Great. Agree with 1 & 2. This may involved tweaking the RPC client code a little over time, but I agree we shouldn't try to support ancient versions of IE etc - just the latest versions of each major browser.\nLove the idea behind 3. Great news is, with the next release of SocketStream, it will be possible to write a Request Responder to do just that.\n. Closing this now as the console.log wrapper was removed in 0.3 RC1\n. Thanks. Still seems to be hogan.js here: https://github.com/twitter/hogan.js/blob/master/package.json\nAre you aware of any breaking changes?\n. Woah you've still got this problem with ss-hogan? I assumed that was long solved.\nSure ok, I'll update it and try some apps out with the new version. If all is well I'll update the module.\n. Ok thanks. Updated\n. Hey\nStill not sure what we're going to do regarding configuration. My feeling is the less configuration the better, as the moment you start adding lots of config it starts to feel like a black box framework again. In particular, if you're using SocketStream with other frameworks in the same app, things could get messy.\nI'm interested in looking at things like nconf but quite honestly I'm in no hurry to make a decision here, especially when it's already so easy to divide your app into different files and just require the one you want (e.g. require('./config/production.js) passing the ss object around by reference.\nAlso I much rather have a Javascript/programmable approach to configuration as we do at the moment than the declarative/JSON/YAML approached of the past.\nAny other opinions on this welcome.\n. SocketStream doesn't and shouldn't touch CoffeeScript code.\nAs nponeccop say's, it's Node which interprets .coffee files. However the initial file you load must be .js UNLESS you start your app with coffee instead of node.\nI.e. right now you run node app.js and then from that point any extra file you require can be a .coffee file, but if you want 100% CS in your project you would convert app.js to app.coffee and start your app with coffee app.coffee\n. No problem. Happy to help. I'll close this issue now\n. I'm aware there are some system libs which are not minified in production but this will be fixed in the next release.\nIf you use stylus your CSS will be compacted in production mode. Nothing is done with regular .css files at the moment but could be in the future.\nCoffeeKup templates are not touched in production mode. It would be possible to add some sort of minifying to them in production mode.\nWe will introduce GZip at some point. See #182\n. All code in the .js file we produce when you call ss.client.packAssets() is now minimised correctly in 0.3 Beta1.\nClosing this now but I will continue to look for ways we can minify other content (such as CoffeeKup templates).\n. Great suggestion - just what I've been looking for!\nI've put it in the next release, out tomorrow.\n. Hi Will\nThanks for your idea. I'll take time to fully digest your idea shortly, but right now I can tell you /index.js is already fully supported when you require a folder with /index.js in it.\n. Hey Will\nSo I've been thinking about your idea... I'm definitely interested in exploring this.\nAs you may know, we're only using part of browserify at the moment. The plan was always to explore the other parts (which resolve module deps server-side) and to see if we can use these in SocketStream.\nIt's not a simple matter, mostly because server-side parsing of client-side files is SLOW, though we would naturally use a filesystem cache to help matter.\nSo if I understand you right, you propose we do something like:\njavascript\nss.client.define({\n   view: 'app.jade',\n   css: ['libs','app.styl']\n   code: {entry: 'app.coffee', libs: ['libs']}\n});\nSocketStream would then use the entry file to resolve all the modules used and send only the required modules to the client. Right?\nCan it be done? For sure. I'm just worried about performance, especially when developing, as this would force the developer to wait anything up to 4 seconds each time a JS file is saved so the dependency tree can be rebuilt.\n. Yup :) I've already got a branch with detective running and it works well, but as I say it can be slow in development (even if you take a md5 checksum of each module and store the dependencies which it what I was doing).\nI'll have a play with this idea some more and see how it feels in reality when working on a large-ish site.\nI agree it would be great if we can pull it off.\n. Because each module takes 1-10 seconds to determine it's dependencies, so we need to cache each file's dependences (between server restarts). Plus we don't know which file changes, only that there is a change, hence the need for a checksum.\nI've already written the code that does all this, but as I say, it's more a question of working out if it's a good idea or not in reality. Hopefully I'll get chance to spend more time on this next week.\n. Good to hear from you all on this!\nSo first up, let me say, I'm in no rush to change the current system. I've had a lot of positive feedback about it and I feel it has three huge advantages which I'm not going to surrender easily:\n1. If you know how to write Node.js apps, you know how to write client-side code in SocketStream. There's nothing new and funky to learn, as there was in previous versions of SocketStream.\n2. It is dead easy to require any client-code module within your server-side code without having to modify anything. Even if the module requires sub-modules it all works fine out of the box. Want to use a system module like Node's url, we can support that too. This is a big deal. As far as I know no other framework has pulled off code sharing in a structured, scalable way.\n3. Minimal overhead and negligible performance impact. Whether it's in development or production, the server does almost no work to deliver the benefits of the current solution (basically it just wraps a small amount of code around each module).\nTo make all of this work the developer only needs to remember one thing: Only require a module if it exists. That's it. You can choose to bundle modules in the initial payload (as 95% of apps will do) or require them on demand with ss.load.code, just don't require a module unless you've sent the code to the browser, one way or another.\nSo if we're going to move away from the current solution to something else, there needs to be a damn good reason to do so.\nAs I say, I've experimented with other components of browserify to offer a more auto-magical solution. It's a very appealing idea, but ultimately it would mean adding additional complexity and dependencies to the framework.\nMore importantly, it would slow developers down during the development process. Even with the best caching, if you're modifying a client module on the fly, the server would hang for at least one second to resolve the dependencies in the module you've changed. That's going to get very annoying very quickly.\nTherefore I've been thinking of alternative idea: To keep things as they are but add a 'Pre-flight Checker' feature at some point in the future, most likely as an optional module. This would scan though all your client code, check all the dependencies resolve correctly and make sure you're not sending anything you don't explicitly require (orphan modules). Granted, it would take a while to run, but typically it's something you'd only run once before you deploy.\nNaturally @nponeccop is right that it would be perfectly possible to fool the dependency checking if you require modules in exotic non-standard ways, but if you choose to use this optional and non-essential feature, we must assume a degree of common sense.\nJust to let you all know, the next release, beta1, will hopefully be ready early next week. I have refactored a lot of the code in the Client Asset Manager but there will be no external changes to the way modules work.\n. Any more thoughts on this guys? If anyone still thinks we should be using AMD instead of this approach please do make an argument for it.\nIf I don't hear anything back in a few days I'll close this issue, as I'm trying to tidy up the list before we launch 0.3.0 properly in April.\n. Thanks guys.\nSo just to restate, I'm very happy with the current system and there are no plans to change it at present.\nBut I would like us to have a Pre-flight Checker. Done right, this would not only detect module problems, but also perform any other checks you'd want to have done on your client and server code before it goes into production.\nShould anyone like to have a crack at building this it would be very appreciated (I'll assist in anyway I can). If not, consider it on my medium-term todo list (after a number of other optional modules I want to build first).\nClosing this now. Thanks again for your input.\n. Hey!\nIn actual fact if you don't explicitly use any templateEngine all templates are rendered like this by default, to retain compatibility with 0.2.\nUp until two days ago this was documented in the tour (on the website) but I removed it thinking most 0.2 users already knew this.\nI will update the template docs soon to make this clear. Thanks for brining it to my attention.\nOwen\n. Thanks. This will be fixed in the next release\n. Fixed in 0.3 beta1\n. Hi there.\nThe Live Reload documentation page covers how to deal with this error: https://github.com/socketstream/socketstream/blob/master/doc/guide/en/live_reload.md\n. Hi there\nI've not used SocketStream and Express together for a while so things may have changed in the recent API. I also recall reading the new 2.0 version of Connect we're using requires Express 3.0 which isn't on NPM yet; therefor please clone this locally and link it to your project.\nIf all that still fails I will checkout the code myself and investigate.\n. Thanks for pointing this out - I lost sight of this when the issue got closed.\nI have repopened it to remind me to change the website asap.\n. Hi there\nI've updated the code on the website and tested it with both Express 2.5.9 and 3.0 beta7.\nIf anyone else has trouble integrating express, please let me know.\n. Hi there.\nYou'll need a client folder containing the various JS, CSS, Views, etc you want to use with SocketStream. Right now these dirs are not user definable.\nAs for PhoneGap, I've never tried it, but if we can support it out-of-the-box, even if it means we need to make a few tweaks here and there, I'd be interested to do that.\n. Hi Jacob\nI agree, there are some disadvantages to the fixed folder structure approach if you want to use SocketStream with other frameworks and toolchains.\nI chose the current system as I see a big benefit to providing some level of structure, esp when developers will often be working on multiple projects within teams.\nWe could certainly make the paths to each asset type configurable in a future release, but I doubt it's quite as simple as that. I think it would be best to look at each integration use case individually and see if any common patterns arise.\n. Thanks Jacob\nIf we made the current asset paths user-configurable (e.g. /client/static could become /public/assets or anything else), would it help you in this instance?\n. Ok we will support user-definable /client directories in the next release. The current defaults will not change.\n. Hi there\nThanks. I've accepted this. I'm just a bit puzzled why this bug hasn't shown up before... What browser are you using?\n. Hi there\nYou can pass the database index number as db to ss.session.store.use('redis'); right now, e.g.  ss.session.store.use('redis', {db: 5}); \nAt the moment you can't do this to ss.publish.transport.use('redis'); but I've put it in the next release, beta1, for consistency.\n. Hi there\nSorry you can't do this in 0.3 as I can't figure out a way to implement it cleanly without global variables.\nJust create a new connection - the overhead is minimal\n. If i understand you right, yes you can.\nYou can all ss.api.publish.all() from your app.js file or pass that object to a file you require\n. That's an interesting point. We don't have support for that yet, but I guess you're thinking along the lines of what Rails provides with config.action_controller.asset_host ?\n. Ok. Well the variable in config.action_controller.asset_host only works when you use things like the image_tag helper. As we have no such think in SocketStream, it's really more down to how you're doing your image links.\nFor example, you could have a client-side variable which gets changed depending upon the domain you're accessing (e.g. mydomain.com vs localhost). This could be use inside your template code.\nFor now I guess you'll have to improvise a little, but if there are specific ways we can make this easier I'm interested in supporting them as I know it's a common issue.\n. Ah cool. I will put basic CDN support in the next release (which will just do what you're doing here without having to remove != SocketStream)\n. Hi there\nThis is now in 0.3 beta2. Put this in your app.js file:\nss.client.packAssets({cdn: {js: \"http://my.cdn.com/my.js\", css: \"http://my.cdn.com/my.css\"}})\nThe CDN links you provide will only be used in production mode.\n. Hi there\nThat's basically the right idea. The first request to the server should be some sort of init command to find out if the session is logged in or not, then you can load/show the correct template.\n. Hey, do you need any more help with this or can I close it?\n. Hey there\nI think this relates to #201\nIt looks like we're going to have to make the dirs user-definable. If we were to do that, would it help in your situation?\n. I'm putting the ability to override the client-side dirs in the next release. This should help you, but let me know if there is more we can do.\n. Unfortunately the files generated are going to be different every time as the filenames include a timestamp to prevent caching.\n. The ability to override the default client-side dir structure is now in 0.3 beta2 (see changelog for details).\n@nponeccop is spot on about the timestamps.\nClosing this issue now.\n. Hi there\nBear in mind all client-side code is packed, minified and sent in one file which the browser will cache in production mode anyway.\nDo you see Local Storage to do something more than this? While I see it as our job to guide users and ensure they can use any storage solution of their choice (AmplifyJs looks interesting @haohello), we must be very careful about mandating/bundling any new libraries - especially client side.\n. Hi there\nMake sure you ss.load.code() the directory the code is in. This should be outside of the app directory as everything in here will get bundled and sent to the client upon connection anyway.\nE.g. create a new folder like: /client/code/async\n. Did this fix it? Please close if it did\n. Something's not right there. We don't do any caching at the RPC level.\nFeel free to paste some code in and I'll investigate. \n. Ok... can't see anything wrong there.\nIf you console.log out numberUpdated before you call res() do you get the same thing each time?\nAssuming you don't, put the following in your app.js file to see what's going through the websocket:\njavascript\nss.ws.transport.use('socketio', {io: function(io){\n  io.set('log level', 4)\n}});\n. Hi there\nThanks for posting the solution. I think this relates to #192 which I'm aware still needs to be be fixed. It's on my list.\n. Thanks!\n. Totally agree. I've fixed it in the next release.\nThanks for pointing it out.\n. I'm afraid I can't see a way to 'get your sessions back' if the secret used to hash the session ID has changed.... but I am wondering if we can improve the way Express works with SocketStream here as we really don't want two lots of Session middleware loading up at once.\n. Ah think you are right. Yes, we need to be able to pass this as an option. I will make this possible in a future release.\n. Closing this now. Note a recent commit means you will no longer see this error:\n! Error: Session ID ... not found. Use Redis to persist sessions between server restarts. Terminating incoming request\nas sessions are now automatically re-created if they don't exist\n. Many thanks @nponeccop. I'm currently working on releasing a few more things in time for recording the Node Up podcast tomorrow, but I'll take a look at this early next week.\n. Hi guys\nI need to make some decisions on this for SocketStream 0.4.\nI'm all for going down the random token route, but one of the great features of 0.3 that I want to carry though to 0.4 is the ability to share sessions between WS & HTTP requests.\nHence, keeping some level of cookie support is likely to be necessary, though we will need to move back to reading this via client-side JS and sending the session ID to the server as the initial WS request, as Engine.io does not have a 'handshake' object (at least not that I can see). This is no bad thing as it will keep things more consistent between transports (as SockJS already uses this method).\nIf anyone has any smart ideas, now is great time to share them :)\nOwen\n. Hey\nYup this changed in alpha5, it was documented in the changelog at the time.\nGlad to know the entire connection handling code isn't broken for you :)\n. (oh and I'd love to see your fix for #219)\n. Thanks. Interesting (and common) use case. I will take a look\n. I agree there is a need for this. The main problem is that socketIds are very transitory.\nShould the connection go down and reconnect for any reason (server reboot, wifi problems, user hits reload by accident), you get another socketId - so the app would have to deal with this and manually resubscribe.\nIdeally I think we should offer both req.session.channel.subscribe() and something like req.socket.channel.subscribe().\nAt the heart of this is a much bigger and broader discussion: Should individual tabs simply act as multiple interfaces to the same app, or function completely independently? Ultimately I think we should leave the decision to the app developer and provide the best tools for both approaches. \n. Going to close this now. Rest assured this is an issue very much on my mind and something I am keen to support in the future.\n. Hi guys\nSorry for the delay getting to this.\nI totally agree. I want to ensure SocketStream has excellent support for CDNs. Right now I have yet to deploy a public SocketStream app using a CDN, so I haven't encountered these issues first hand - so I'm relying on people who have to make specific suggestions in terms of changes we can make to the core to improve compatibility.\nI am also interested in exploring whether or not it's possible to put everything on the CDN, only using SocketStream to generate the initial HTML, CSS, JS etc and, of course, for the websocket connections. There are some issues with this approach if you have multiple clients defined, but it would be nice to have this option.\nI think the best thing for me to do is use CloudFront for www.socketstream.org (as it's already hosted on EC2). This should bring to the surface any problems with the current approach.\nOwen\n. Hi all\nI'm working on this problem right now as I want to improve our CDN support in 0.3.0 and that may mean a few minor API changes.\nI'm going to start by trying to get www.socketstream.org using Amazon CloudFront (as the site is currently hosted on EC2) and see what needs to be done to make this as easy and painless as possible.\nIf anyone has any more CDN related thoughts, please post them here or join me on IRC (#socketstream on Freenode).\nOwen\n. Hi\nGreat to hear that, by in large, things are working well with Cloudfront. I have done some brief testing and had a similar experience, however things can be improved.\nHere are the proposed changes for 0.3.0 (or possibly an interim release... let's see):\n1. ss.client.packAssets() will now check for existing assets already packed in /client/static/assets and use them if they can be found. If any assets are missing they will be automatically be re-packed.\n2. To force re-packing of assets each time you start your app (i.e. the current behaviour) pass SS_PACK=1\n3. The default cache expiration time will be changed to 30 days (bearing in mind your point about each asset having it's own unique URL). Note: This setting can already be overridden manually with ss.client.set({static: {maxAge: newValue}})\n4. CDN paths can now be strings or functions. E.g:\n``` javascript\n// in app.js\n// Note:\n// client.id      = unique id/timestamp for this client\n// client.name    = unique name for this client (e.g. 'main')\n// client.path    = path which would normally appear - e.g. \"/assets/main/1340039525318.js\"\nss.client.packAssets({cdn: {\n  js:  function(client){ return \"http://mycdnhost.cdnprovider.com/mypath/\" + client.name + \"/\" + client.id + \".js\" },\n  css: function(client){ return \"http://mycdnhost.cdnprovider.com\" + client.path }\n}})\n```\nThese changes should make it much easier to deploy a project to a cluster of servers, complete with pre-packed assets. I am also looking to see if the client IDs can be changed by sending an event to the server, without having to restart each process - though this feature may have to wait for a future release.\nAs @nponeccop says, we'll re-look at the issue of gzipping once 0.8 is released and stable.\nComments/suggestions on the proposed changes welcome.\nOwen\n. I've made a commit today which implements the changes I proposed (minus the CDN / function change which I will commit soon).\nThis is important as several users are reporting problems deploying their apps to Nodejitsu as the asset build process was causing the deployment to time out. This will no longer happen if you're running on the latest code.\n@plievone Just to be clear I really want to implement gzipping of assets too - I'm just wanting to wait until this is stable in Node 0.8. The moment we start implementing shell based solutions we will break our existing 100% compatibility with Windows. As for your other points - thanks, I will take them on board. I do know we have an issue with jQuery CSS pointing to image files in the wrong place. This needs to be addressed for jQuery UI too.\n. Hi @drosen0 \nIt's possible, but SocketStream prints a few lines out explaining that it's trying to find assets and even states that assets can be repacked with SS_PACK=1, so hopefully this will avoid any confusion.... but point taken.\n. Thanks. I am keen to add zlib support in the near future.\nIncidentally I can confirm the latest SocketStream code from master works well with Node 0.8 (at least on my Mac).\n. I've decided to put GZip support into SocketStream 0.4, along with other tweaks and enhancements in this area.\nGoing to close this now as many of the CDN changes proposed and discussed are now in 0.3.\nFeel free to open a new issue to discuss/debate further changes.\n. Yes it is. I found it useful when I wanted to test asset packing on my local machine without loading the entire production database stack.\n. Right now I'm changing asset packing in 0.4 so it will be done on a per-client basis. E.g. if you define a client called 'main' and assign this to the 'main' var and you will call main.pack(), passing any options required.\nQuite how this will fit with the idea of SS_PACK I am not sure yet. This is why there's still a lot of thinking to do.\nFeel free to suggest any other ideas (including radically different ones).\n. Hey there\nSorry, my bad. I fixed this a few hours ago in the latest commit. Please reopen if you're still having problems\n. Thanks for taking the time to put together a great pull request.\nI will merge it in now. Assuming no problems are reported it will be part of the 0.3.0 release next month.\n. Hey there\nThanks for this. I'm interested in integrating it, but I need to be sure we don't break any existing functionality. Live Reload is a tricky thing to get right. In particular, I'm keen to ensure the problem @madscoaducom had with VIM renaming files will not resurface if we use chokidar.\nTherefore, @madscoaducom, if you're able to test this and let me know it would be appreciated. I'll also test it on my Mac.\nAs for being able to pass an array of dirs to watch, this functionality is important as we typically don't want to watch the /client/workers directory. However, if you can think of a better syntax/way of expressing which directories to watch, please let me know as I'm open for changing the API.\nThanks,\nOwen\n. Thanks. Keen to look at better ways to specify the client config, but I'd like to avoid using JSON or any other type of config file (see #194).\nI agree some parts of the API feel clunky but I'm convinced we can improve upon it without having to resort to config files - we just need to find a better design. Feel free to 'think outside the box'. I'm happy to make big changes if there is a very good reason to do so.\n. Thanks guys for looking into this.\nDon't worry about the multiple commits - I don't mind merging a few in (though if you do want to submit a new pull request, I'm happy to take that).\nThe race condition has historically been a bit of an issue - though currently I have not noticed this with the current implementation on my Mac, nor have others reported any problems.\nI will test out the new changes and let you know. I'm planning to do an 0.3 RC2 release in the next few days - would be good to get this in it.\nOwen\n. @CyberWalrus I think you may be on to something with this idea... I really do. It has the potential to clean up a lot of things if it's done right. Going to have a think about how it would work in reality.\n. Hey guys\nQuick update on this. @madscoaducom sadly the patch I merged in was causing some problems when I manually renamed files in OSX. So for now I've temporarily disabled the re-watching of the file in 0.3 RC2 as the value of file was the OLD filename, not the new - causing the following error:\nfs.js:671\n    throw errnoException(errno, 'watch');\n          ^\nError: watch ENOENT\n    at errnoException (fs.js:644:11)\n    at FSWatcher.start (fs.js:671:11)\n    at Object.watch (fs.js:699:11)\n    at /Users/owen/Work/socketstream/src/client/live_reload.coffee:57:29\n    at Array.forEach (native)\n    at /Users/owen/Work/socketstream/src/client/live_reload.coffee:53:26\n    at FSWatcher.<anonymous> (/Users/owen/Work/socketstream/src/client/live_reload.coffee:61:20)\n    at FSWatcher.emit (events.js:70:17)\n    at FSEvent.onchange (fs.js:660:12)\nThe complexities of all this make me more even keener to use a library like the one @CyberWalrus suggested, although it's clear now we need to try both manually renaming files and auto renaming (as VIM does) in all major OS platforms, as well as adding and removing files.\nI hope to look into this more when I have some time.\nOwen\n. Hi @CyberWalrus \nSorry for the delay replying. I'm still very interested in this, especially as there have been more issues with the current implementation, as you have spotted.\nI will try out the latest version and encourage others to do the same.\nThanks!\nOwen\n. Hey @CyberWalrus. I'm using your patch on Mac OSX and it's looking good. No problems so far.\nWould really love it if someone can confirm it's working on Linux (I know you're on Windows). If so, I'll put this in 0.3.0\n. Ah great news!\nUnless any other problems are encountered I will put this patch in 0.3.0\n. Thanks for your help @CyberWalrus\nI may review things again when everyone's on Node 0.8 (as I'm hoping file watching maybe a little easier), but for now this is the best solution.\n. Hey Jay\nI was getting that error too on a previous release, but only when renaming a file - not on the startup. I also disabled the code causing it in the latest RC2 code I put out a few hours ago.\nCan you try that and let me know if you still have a problem.\nCheers,\nOwen\n. Hmm how strange.\nI deleted my local repo and cloned it afresh from Github to see if there was a error, but everything worked find - no problems. That's on OS X.\nThe only thing I can think is that you're running it from Dropbox. It could be that the file watchers (which observe changes) are causing problems with the Live Reload code which does the same.\n. Hi there\nSorry for the delay replying. I'm really keen to make sure we have good support (and documentation) for Passport as I love the concept; however I have not had chance to use it as yet.\nCan you let me know if you managed to find a workaround? If not I will try to have a look.\n. Hi all\nGoing to close this for now, but please reopen if you're still having problem. The best long term solution to this is a \"receipe\" on our website showing how to integrate Passport with SocketStream 0.4.\n. Thanks. This does look interesting. I'm afraid I don't have the time to make and maintain a new module at the moment, but feel free to do this yourself and I'll add a link in the Readme.\n. Hi there.\nI have not seen this error before. Please can you tell me more about what you did before it occurred. \nPlease also make sure you're running the latest 0.3 RC2 release.\n. Hey Davis\nCan you let me know where you are with this now and if you still need help?\nBtw I am aware that the Jade/Hogan mix is confusing. I am thinking about making Jade templating (using https://github.com/socketstream/ss-clientjade) the default in the next major release but I want to work with it some more before I confirm that.\n. Closing this now as I believed we resolved it over IRC. Please reopen if this is not the case\n. Hi there\nI've not seen this error before and can't think what it could be off hand. If you're still having problems please let me know what OS you're using as the FS Watcher works very differently on Linux and OS X\n. Cool, thank you.\nJust to let you know, we're likely going to be using a module soon to handle file change detection. See #227\nIt would be great if you could try that patch before I make the final decision to include it in 0.3.0\n. Ah yes, the temporary files created by VIM are causing similar problems.\nTry pulling from https://github.com/CyberWalrus/socketstream.git then run npm link again\n. I've decided to integrate the patch from CyberWalrus. It's now in the latest master.\nI've also updated the Live Reload documentation to deal with the issue of temporary files created by VIM.\nTo help me keep track of problems I'll close this issue now, but please open a new one if you continue to have problems with the latest code.\n. Hi there\nPrinting out the stack trace in the browser and terminal (without crashing the server) is the desired behaviour during development - however we do need to take a thorough look at logging and make it possible to hide/surpress different errors in production. This is still a big item on the todo list.\n. Hey there\nSorry for the delay replying.\nJust trying to see how this would work in practice and, also, if it would break any existing apps out there. Can you provide a few examples and show what this change would achieve?\nThanks\n. Thanks for the example. I see what you mean now.\nNote that ss.client.define() only defines what assets the client should contain - it doesn't influence any routing.\nAll routing at the moment is just done by an EventEmitter. It works (for the most part as you've noticed), but I've never felt totally happy with this approach. It's interesting you mention mapleTree. It came up in the latest Node Up podcast and I thought it sounded interesting.\nI'd like to take a look at it properly and see if we could use this rather than rolling our own. This would not stop people using Express Router or other routering libs if they wish; but hopefully it would provide more power out of the box for the simple HTTP routing needs SocketStream tries to address.\nWould be interesting to hear your thoughts on this.\n. Thanks. Glad you're liking it :)\nRegarding the router, point taken. I'll investigate the possibilities here a little more and let you know.\n. Hey. Just trying this out now...\nI created a new client called 'test' and routed it with:\njavascript\nss.http.route('/test', function(req, res) {\n  res.serve('test');\n})\nWhether I call\nhttp://localhost:3000/test/subpath\nor \nhttp://localhost:3000/test?name=matthias\nor even\nhttp://localhost:3000/test/something/else?name=matthias\nThey are all correctly resolving to 'test' without this patch. Am I missing something?\n. Ah I see the problem now - I was testing this whilst still having a route to '/' defined. The problem only shows up if you don't define a route for '/'.\nThanks for explaining everything in detail. I've tried this and I can reproduce the problem and see how the patch fixes it; hence I will merge the pull request. I will also add another commit after running make build which converts the CS files into JS so the changes take effect.\nJust to let you know, I'm still not feeling happy about using an EventEmitter as the routing mechanism - it just feels wrong, so I hope to play with ultra-lightweight solutions in the future (such as MapleTree) to see if they would be a better fit for SocketStream 1.0.\n. Hey there\nSorry for the delay getting to this.\nThis is an interesting idea. I am certainly wanting SocketStream to be used in really large scale projects, so I can see the value in doing this. That said, the potential bandwidth savings must be balanced with the additional code complexity (and performance implications of calling an event emitter each time something changes in UniqueSet).\nRather than trying to replace what's there (at least for now); I think it would be worth putting this code into a separate module which could be included in your app.js with:\nss.publish.transport.use(require('redis-demultiplexed'))\n(or whatever you decide to call it). You would still need to patch unqiue_set.js for now, but if you fancy making it into a module I'll happily test it on my projects and try to see if I can identify any problems.\nThanks very much for the idea + code.\nOwen\n. Hey @timothyjoelwright \nI have given this a bit more thought. I am pondering taking out Redis pub/sub support in the next release of SocketStream (0.4) altogether to allow people to roll their own solutions.\nReplicating the current behaviour of multiplexing events would be trivial (4-5 lines of code in your app); but I agree with you that larger installations (which SocketStream is really targeted at) will want to ensure only the bare minimum of traffic flows between Redis and each SocketStream server. The exact implementation of this will depend upon the app's design.\nJust a thought at the moment, but I welcome your thoughts.\n. Interesting findings with regards to PubNub and Pusher!\nRight now the pubsub transport in 0.3 is completely modular and the API is frozen, so people could already make a module for RabbitMQ or ZeroMQ or anything else, should they wish.\nWhat I'm really getting at is: is this the best approach?\nMaybe for small/medium scale apps, but for really large scale apps (the ones I want to build), I think it would be best to make the app subscribe to individual Redis channels and then use ss.publish.channel() to push these events to the relevant clients in the most efficient way possible.\nThis would allow you to send messages over Redis (or ActiveMQ, or whatever) in the best message format for your app, which may not even be JSON at all.\nIt's just a thought at the moment. Need to do more real world testing before I make a decision here. Opinions welcome.\n. Exactly. Pretty much decided to remove Redis as a dep now, especially as some folks are having problems deploying their apps to NodeJitsu because of the hiredis dependency.\nHowever, Redis will continue to be a great fit for SocketStream and I will include full instructions on how to use it as a session store or pub/sub transport. The only real difference is that you will add it as a dependency to your app, rather than it being a dependency of SocketStream.\n. Hmm ok. I'm thinking of using the https://github.com/paulmillr/chokidar library as recommended and implemented by @CyberWalrus in pull request #227\nI'd appreciate it if you can give it a go and see if it fixes some of these issues. I will also try and replicate the problems you're having.\n. Hi there\nI've decided to integrate the chokidar lib based upon successful testing by myself and others. The new code is now in master.\nI'll close this issue now, but please open a new one if the new code is giving you problems.\n. Thanks for spotting\nDespite very carefully trying to update and publish things in the right order it seems an earlier version was pushed to NPM - a little confusing though as I downloaded the .tgz file after publishing it a few days ago and it appeared to be correct.\nPlease can you check and confirm for me just so I know I'm not going mad!\n. Thanks. I'm having similar bizarre caching issues too on the Mac. I have looked in all the obvious places but an old version seems to be lurking somewhere....\n. Thanks so much!\nI will merge this in now. I'll go over ii, try it out, and maybe make some slight amendments before adding it to the readme index.\n. Great. Thank you!\n. Hmm interesting. This ties in with another problem. Right now if you want to use Node Cluster in production (as you would) it means ss.client.packAssets() is called multiple times.\nRight now it is scriptable/programable so there are ways around it - but I'm looking at other approaches, possibly using the server side event bus: ss.events.emit('client:assets:rebuild') or something like that.\nThoughts welcome \n. Not yet you can't, but I'm working on this now to see if this can be made possible - and to generally decouple the packing of assets with the use of assets to better enable scaling/clustering/cdn support.\n. Just to let you know, I made some changes in 0.3 to allow for better CDN support.\nIn 0.4 you will call pack() on each individual client, allowing you to create a git hook or make task to pre-pack assets before they are deployed.\nIn addition I am still keen to look at triggering a re-pack by emitting an event.\nClosing this now but expect improvements along these lines in the future.\n. I'm hoping we can have really good support for PhoneGap in SocketStream 0.4, along with a doc page explaining how to set everything up. In many ways PhoneGap is a natural fit for the single-page nature of SocketStream.\nIf anyone else has any hints or tips please share them here. I hope to have a play with PhoneGap myself soon.\n. Hmm I've not come across this before. The last comment is the most surprising as this middleware is doing absolutely nothing! Can you double confirm that you restarted the server and it was still sending two replies?\nIf so I'll try to set something similar up and see if I can replicate it.\n. Thanks, that would be appreciated. If there is anything fundamentally wrong I want to fix it before I release 0.3.0.\n. Ah I see the problem. At the end of your security.js file, on line 13, you have\n}();\nRemove the () and all should work fine.\n. No worries. Glad it's fixed for you :)\n. Hi there\nHaving not heard of any similar problems to this I tried to reproduce the example above as closely as possible, but didn't see any problems. The session saved correctly.\nAre you using the default in-memory session store? If possible try using the Redis session store and then monitor redis on the command line with redis-cli and then type monitor. This will allow you to see exactly what is being stored.\n. Hey\nJade will get installed when you run npm install in the project directory you have just created. You can verify this by looking for ss-jade in the package.json file the installer created.\nss-jade depends on Jade which will be automatically installed.\nRegards,\nOwen\n. Closing this now, reopen if you still have a problem\n. No tutorial yet but checkout Issue #200\n. I have recently tried Express 0.3 with SocketStream and it works well.\nPlease follow the code example on www.socketstream.org/tour which has been updated with code which will work well on 2.5 & 3.0. Any problems let me know.\n. No, sorry. There used to be some cookie get/set methods in SocketStream but I took them out in an attempt to keep the client-side code as lean as possible. There are many jQuery plugins which will help you do this.\n. Ah right. No, that's not possible. Just store anything you need in the session object\n. Hi there\nIf I understand right, this is possible already by accessing ss.http.middleware which is basically the connect app and calling ss.http.middleware.append() or ss.http.middleware.prepend() on it and adding your own middleware.\nYou can access the connect module directly with ss.http.connect.\nLet me know how you get on.\n. Exactly as @nponeccop  says. An ss.rpc request, or any request over the websocket, is not a HTTP request and shouldn't have access to the HTTP request/response object.\n. Technically it would be possible to give you access to Socket.IO meta data when you're using that transport; but I don't want to implement this because:\n1. SocketStream would no longer be 100% websocket transport agnostic as it is now\n2. The websocket transport should be completely independent of the HTTP request and may not even be on the same domain (e.g if you were to use Pusher Pipe or a PubNub backend)\n3. In SocketStream 0.4 we will be moving to Engine.IO which I'm pretty sure will not allow you access to the cookies.\nSo overall you are much better storing session-related info in the user's session (req.session) rather than the cookies. If you really really want to use cookies, read them using JavaScript on the client-side and send the contents over an RPC request to the server.\nOwen\n. Thanks for reminding me. Was going to do this before 0.3.0 was released, but as I'm now trying to do more iterative commits, I've done this now.\nI've already done some testing with Node 0.7 and basically all works well apart from the Live Reload which I will look into. Please pull the latest commit and let me know if you have any problems\n. So far all working well from my initial testing, apart from Live Reload (which is now using chokidar 0.2.6) on my Mac. Not looked into this yet. @CyberWalrus, do you have any ideas?\n. Cheers guys. Looks like this is a know issue in the release I was trying. Will keep an eye on this.\n. I can confirm there are no problems with Live Reload on the Mac using Node 0.8.0.\n. Closing this now as many users are now running 0.8 successfully \n. Hey David\nThanks. I know this was an issue but the last commit I made today should fix this, though I haven't had time to test and confirm (was planning too tomorrow).\nThe problem was first noticed by a poster on the Google Group a few days ago and my reply was as follows:\n``` code\nThanks for letting me know. I can reproduce the bug.\nUpon investigation I see it occurs because more recent versions of Node.js clear require.cache when the REPL is launched. In this case, the cached variable formatters.byExtension has been cleared, so SocketStream is unable to handle incoming '.jade' requests.\nThis appears to be a known issue: https://github.com/joyent/node/issues/3226\nAs for the solution... I'm not sure yet. I'm going to dig into it more. If anyone knows more about this issue, please get in touch.\nFor now, it would be best to stop using ss-console until this is resolved  - hopefully very soon.\n```\nThe change I made today abandoned replying on modules to cache their content - which seems like the safest bet for now.\nCheers,\nOwen\n. Hey David\nYup, we had the same issue with template formatters. Fixed it in the same way. Please give the latest commit a go and let me know how you get on.\nOwen\n. Hi there\nExample code is shown on slide 7 of http://www.socketstream.org/tour\n. Wow great info, thanks!\nIf the match origin protocol is exposed as a config option (either now or on the future) you will be able to change it from your app.js file by configuring SocketIO.\nI'd be interested to see how SockJS performs with SSL too.\nOwen\n. Hi there\nSorry it's a bit confusing at the moment as the latest release on NPM is not compatible with Node 0.8. I hope to fix this shortly by releasing 0.3.0 on both github and npm.\nFor now create the new project as you did before, but instead of typing sudo npm install type sudo npm link socket stream instead, then  sudo npm install to get Jade/Stylus/etc.\nThat will tell npm to use to the latest SocketStream version you checked out, not the one on npm.\nCheers,\nOwen\n. Thanks for this!\nTotally agree upon the idea in principal. I just need to try this out myself and make sure it's the best way to implement it in practice.\nOn a related note, I've been hoping for a while it will be possible to share middleware between SocketStream Request Responders (like RPC) and Connect, as they use the same format. This would be very handy for authentication middleware.\nHowever, getting the load order right is critical as an app must define its HTTP middleware (which maybe written in CoffeeScript etc) before SocketStream starts up (which is when the middleware is currently loaded)...\nI'll give it all more thought and let you know the outcome. Thanks again,\nOwen\n. Thanks for spotting. Fixed\n. Hi there\nSorry for the short delay. I wanted to figure out what had changed before I merged this in. Here's the culprit:\nhttps://github.com/senchalabs/connect/commit/0915c26fb2e08113cb1e9b4dae88a424a758fd6d\nThanks for contributing \n. Cheers. Will check this out and try to reproduce.\n. Can you provide an example?\nMost of the time an exception should kill the server (in development mode) and print a stack trace. If you're not using Redis to store session data, the session will be lost.\n. Hi there. Going to close this now as no one else has reported this. Please re-open if it reappears.\n. Hi Davis\nI'm almost certain this relates to #256 as I can see several references to sess:s in your Redis monitor output.\nI haven't come across either of these problems on my mac, and nobody else has reported anything so I was planning to delve into sometime this week and try to figure out what's going on.\nI'm guessing it has something to do with upping the Connect or Connect Redis dependency version - but that's just a guess at the moment.\n@jcrugzz perhaps you can help? What setup are you using that caused you to have the  sess:s issue? Are you running the latest SocketStream master code?\nDefinitely want to get to the bottom of this before I release 0.3.0.\nTip: Before you upgrade from RC2 to master, sudo rm -fr your node_modules directory to make sure all the deps get fully updated. Npm has had issues in the past where deps are not updated correctly.\nThanks for any help looking into this,\nOwen\n. Yup - very well spotted. I will fix the docs. Thanks for letting me know.\n. Good suggestion. Thanks\n. Hey\nSure, that's the plan. Not sure when I'll get chance to do it, but hopefully soon.\nOwen\n. Hey there\nTried to look on the URL but I can't see anything.\nDoes the chat demo work fine for you locally? \nOwen\n. Hmm sounds like it, but feel free to pop onto IRC and I will help you to debug.\n. Hi there\nYes, SocketStream uses Connect, so you can only extend the HTTP layer with Connect or Connect-compatible middleware (as used in FlatIron). This also enables us to easily support Express.\nSadly integrating BinaryJS (which looks very interesting) would never be as simple as just plugging it in as it also makes use of the websocket. SocketStream has a way to multiplex several different kinds of message over the web socket called Request Responders but I doubt this would work with binary data. Not sure yet - I'd love to find out.\nOwen\n. Hey\nSo as you may know, SocketStream uses Socket.IO as it's default websocket transport. I've had a quick look and can see binary support was apparently added to version 0.8.5, but documentation is pretty much non-existent. If you can find any examples, please let me know.\nSo theoretically it appears to be possible. As for the implementation, I'd have to take a proper look at how best to do this. Perhaps we could create a new binary data Request Responder? I'm not sure yet.\nWhat sort of data are you interested in sending?\n. Yes it can, though Socket.IO is the default and most mature / well tested. It would be worth looking to see if binary support is possible in SockJS - I haven't had chance to do that yet.\n. Hi there\nYou make a good point and hit on something which is currently confusing in SocketStream 0.3, something which I hope to fix in 0.4:\nRight now when you create a new project with Jade (socketstream new -j myproject) you get a .jade file in chat/messages.jade but this is only interpreted by Jade on the server, it has nothing to do with client-side templating. Hence you can use a .jade file to generate the HTML before it is sent to Hogan, or any other templating engine.\nThe ss-clientjade module you refer to was kindly contributed by a user and allows you to use Jade in the browser as a client-side templating language, doing away with the need for Hogan. I forked the module a while back to help the author upgrade to a new module format but have not been keeping it up-to-date, nor do I have the ability to publish it to npm. I have deleted my fork to avoid confusion.\nTo be honest I was a bit skeptical of using Jade in the browser at first, but once I got chance to use it, I found it a joy to use. So much so that I'm thinking of making Jade client-side templating the default in 0.4 when you run socketstream new -j, instead of Hogan. If this happens I will adapt ss-jade to work both on the server and client which will do away with the need for ss-clientjade altogether. Feedback welcome.\nThanks for your other thoughts. I will bear them in mind. Also note I've updated ss-jade and ss-stylus today with the latest deps.\n. Hi there\nThere is no out-of-the-box way to do this, though it's an interesting request and definitely a 'nice to have' for the future.\nThe easiest way to do this is handle it in the client. Send the req.id (which is automatically assigned and is always sequential) back in the response and disregard any out-of-order responses.\nOwen\n. Good to hear you sorted it out. I'll close this now\n. Oh dear - sounds like a file watching / polling issue with chokidar. I recently upgraded SocketStream to the latest version, which maybe the cause of the problem.\nWhen you get a moment, could you try running SocketStream using an older version of chokidar and let me know how you get on? I don't get many opportunities to test SocketStream on Windows.\n. Hi guys\nThanks for looking into this. I'd like to release SocketStream 0.3.1 this week.\nIt would be good if we could reach a consensus on either keeping chokidar 0.4.0 as is, or going back to using 0.3.0 - bearing in mind that almost everyone will now be on Node 0.8.\nOwen\n. Bah file watching in Node still sucks. If anyone could take a look at this and help improve it, it would be greatly appreciated.\nLive Reload will become a 'Websocket Service' module in 0.4. Something that you will explicitly choose to use in your app (just one line of code), however the way it works under-the-hood is essentially the same. One advantage is that it will be easier to pass more options; however I'd much rather fix the underlying issue as many apps are going to contain hundreds of images.\nIf anyone can help improve this in 0.3, I'll ensure the changes get into 0.4.\n. Sounds like a good plan @paulmillr. It will be a lot easier to pass options directly through to chokidar in SocketStream 0.4. Will look something like: https://github.com/socketstream/socketstream-0.4/blob/master/example_app/app.js#L31\n. Thanks @paulmillr \n@drosen0 please let me know if this helps. If so I'll do another release of SocketStream using chokidar 0.5 and document how to deal with large numbers of images.\n. Hi @drosen0\nPlease can you let me know if this helped. If I don't hear anything in a few days, I will presume it did and close the ticket. Cheers\n. Hey\n1. Sure. If you can submit a pull request that turns this line into a regexp that would be great: https://github.com/socketstream/socketstream/blob/master/src/client/formatters/html.coffee#L16\n2. Not just at the moment but I'm hoping 0.4 will be able to inject the tags automatically in the right place (putting the JS at the bottom), doing away with the need for the  tag altogether. Not sure yet - it's just an idea I need to test out.\n. Closing now. Thanks\n. Can you please run make build before submitting.\nThis is exactly why I'm moving to vanilla JS in 0.4 :)\n. Thanks!\n. Done. Thank you\n. Thanks!\n. Hi there\nCommitting node_modules to the repo is seen as a good idea to many: http://www.mikealrogers.com/posts/nodemodules-in-git.html\nHowever, I'm happy to take this pull request as personally I prefer to keep my project repos lightweight and deploy using npm pack.\n. Hmm maybe.. not sure about this as I have plans to link the docs with live comments and more in the future.\nRight now it's really easy to contribute by forking master, adding/changing docs, and submitting a pull request.\n. Oh I see. Thanks!\nThis does look interesting. I'll check it out\n. Thanks.\nWhere exactly do you mean?\n. Agreed this is confusing. I still this there is a lot of work todo around this area to make everything feel cleaner.\nI'll bear it in mind. Thank you\n(btw this is exactly the sort of feedback I like to hear as it's really difficult for me to approach things as a new user)\n. I think client_app.js is too long, maybe init.js instead.... I don't know - it all sounds a bit unclean.\nI think I need to think the whole thing through a bit more, but thanks for offering.\n. Hi there\nRight now this is how it works - you just get one argument and it's an array of all the params.\nBut I agree with you that it should work in exactly the same way as it does when calling a RPC method from /server/rpc or from the browser.\nThere maybe a reason why I didn't do this this, but I can't remember off hand. I'll have a look and see if we can change to this behaviour in 0.3.1. It would mean breaking people's existing unit tests, but I think it would be worth it for the long term.\nCheers,\nOwen\n. Decided to leave this as it is in 0.3, but will fix in 0.4. Need to redesign the entire testing interface for this anyway to enable every Request Responder to be tested, not just RPC.\nThanks for pointing it out.\n. Thanks for letting me know. I believe there maybe an issue here with Safari. I am away this week, but I will test as soon as I get chance.\nIf anyone else is experiencing this, or can post any more info, please let me know.\n. Hey there\nJust done a quick Google and it looks like it maybe related to this: http://stackoverflow.com/questions/9930671/safari-3rd-party-cookie-iframe-trick-no-longer-working\n. Ah good. Looks like this is a known issue with Safari and third-party cookies.\nI'll close this issue now, but if you think of anything I can do with SocketStream to improve matters, let me know.\n. Thanks for this. I am away this week, but will take a look when I return.\n. Hi there\nJust add it to your view file manually, before or after the SocketStream tag.\nOwen\n. Totally agree. Don't worry - this confusion will go away in 0.4 as we will make a distinction between configuring the library and configuring the instance.\n. Thank you!\n. I agree. Good point.\nIf you fancy having a crack at this I'd gladly merge it in; otherwise I'll add it to the TODO list.\nBasically we need to change the logic here:\nhttps://github.com/socketstream/socketstream/blob/master/src/http/index.coffee#L92\nso that we parse the URL request, isolate the extension, and pass every request to the static handler (by calling next()) if it is for a .jpeg, .png, etc. \n. Hi there\nSo my general feeling towards this is that I don't want to complicate the SocketStream code with server-side template support at all. There just isn't a need for it.\nIf you want to show the app's version, just get that data over a standard RPC request and display it on the screen. The only reason to support server-side template rendering is for search engines, but I've already decided not to prioritise SEO as 99% of all SocketStream apps require a user to login to do anything useful.\nOf course you can always use Express to render server-side templates, which can be useful for parts of your app which really need SEO support (like an About page or such like).\nCheers,\nOwen\n. Thanks! :)\n. Hey @leostera \n0.4 will allow you to pack assets offline, and (hopefully) write code which responds to asset packing events. I've not written that bit yet, but that's the plan.\nUntil then, Paul's suggestion is a good one.\n. Hey there\nIt should all work right out of the box.\nThis thread may help: https://groups.google.com/forum/?fromgroups=#!topic/socketstream/GI-7PPTAWyA\nIf not, let me know and I'll investigate further.\nOwen\n. So sadly things have changed in the very latest version of Express within the last few weeks. Consequently the code on the website no longer works.\nThe immediate fix is to swap the stack order around:\napp.stack = ss.http.middleware.stack.concat(app.stack);\nBut this is an ugly fix and I don't like it. The root of the problem is that middleware can be difficult to work with when you need to combine one array with another.\nThere is a discussion going on in our Google Group about a better way to do this. One option, maybe for 0.4, is to put all the middleware your app needs into your app.js file, which although ugly, would make it easier to see where things are going wrong.\nSuggestions (from anyone) welcome. I will return to this after LXJS in a few days time.\n. I've updated http://www.socketstream.org/tour with a new example for Express 3.0 now it's out.\nI'm still really unhappy with the idea of concatting arrays of middleware - it's way too messy and likely to break again in the future. I will try to come up with something better for 0.4\n. Hmm we can do. It would have to be sent before any scripts which use templates, but that is doable.\nAny particular reason you don't like the code in the head tag?\n. Agreed. Spoke about this on the newsgroup too. For 0.4 I'd like any dom elements to output to the HTML view and all other code to go into a seperate JS file, auto loaded before everything else, and then packed into the same main .js file as everything else.\n. Thanks Shaun\nWas going to get this out tonight but you beat me to it :) Working on a new Readme intro, so I'll push that later on, bump the version number on that, and push to npm.\n. So at the moment you either need a cookie already set on the browser, or the ability for the client to set a cookie using JS (which is how the ss-sockjs transport adapter works).\nWhen you say mobile client, do you mean mobile Safari/Chrome, or accessing SocketStream via a native app?\n. Hi there\nThe lack of a session object is going to be the biggest problem here, particularly how it relates to secure authentication.\nAs SocketStream 0.3 is not designed to work with any other than a normal web browser, I'm going to close this ticket. As for future versions, if we can easily provide a client library which uses a documented protocol, we will. This is definitely the best approach to take - but it will mean having to rethink a lot of things around cookies/authentication/sessions.\n. Thanks Paul. Looks like it should be simple to fix. Will take a look after LXJS.\n. So right now put your module in your client code folder as you would normally, and require() it inside your server code.\nThis works, but feels a bit ugly as you need to have crazy paths. A suggestion for 0.4 has been to create a /shared folder in addition to /client and /server; something which I'm actively considering.\n. Thanks :) Going to close this for now but making it easier to share code in 0.4 is a top priority\n. I don't believe so, and certainly not a standard way we'd need to support across multiple transports. You're best getting it from the server.\n. Ah that's in interesting idea to treat each client as a portable component. Hmm... worth some more thought. Thank you!\n. Hi\nTJ changed the connect.sid cookie format between releases. This means any existing session id cookies won't work. If you start a new session in the browser you will be fine.\nOwen\n. Ah ok. So you'll need to upgrade Express to a later version too as the change was made in Connect and both Express and SocketStream need to be looking at the same cookie id for session sharing to work.\n. Hi Paul\nThe idea of keeping it different was to ensure you could control SocketStream independently to Express, or maybe logic in your own app.\nDo you (or anyone else) see any reason to change this that I've missed?\n. Yeah... On balance I think it would be worth going with NODE_ENV in 0.4. I'll make sure SS_ENV works too.\n. Ah yes, sorry. The connect.sid cookie format changed a while back. I updated socket.io but not ss-sockjs. My bad.\nPlease can you pull the latest version of ss-sockjs from github and confirm all works well. If so, I will release this to npm.\n@paulbjensen please can you make the same change to ss-engineio\nNote I'm trying to take this low-level stuff out of the transport adapters in 0.4\n. Exactly what Paul says.\nAt the moment your /server code is running in the same thread. This is good for speed, but means once the module is loaded, it's cached and can't be changed.\nUltimately I'd like to see us support multi process dev environments again, like we did in 0.2, but this mustn't be at the expense of the simplicity we have now. \n. Closing this for now. If I find a really nice way to do this in 0.4 I will.\n. Hi there\nDoes this work correctly when in development? If so this is clearly a bug and I will try to fix.\n. Agreed. We should have 100% the same behaviour between dev and prod modes.\nIf you fancy looking into this and submitting a pull request, that would be fantastic. Otherwise I'll add it to the todo list and look at it after RealtimeConf\n. Hey. Can you tell me why you'd want to do this? Changing the cookie will break all compatibility with Express/Connect so it's not something I want to encourage.\n. Hey there\nSorry for the delay replying - I've been away on vacation.\nGoing to keep things as they are for now in 0.3, but may change the way we integrate with Express in 0.4. Either way, thanks for the pull request :)\n. Thanks for spotting! Reminds me of http://www.mrc-cbu.cam.ac.uk/people/matt.davis/Cmabrigde/ :)\n. Hey. I like where you're going with this. Not had chance to check it out, but will do before I merge it in as it's a big change to a critical function which must work correctly on each branch otherwise users will abandon SocketStream before having chance to try it out.\n. Hi @rngadam \nI'm going to close this now as I only want to make minimal changes to 0.3 from this point on. However, there are a lot of good ideas here, some of which I will carry through to 0.4 (which I'm now able to resume working on full time).\n. Agree. I'm putting the script loading code at the bottom of the page in the new experimental code for 0.4: https://github.com/socketstream/socketstream-0.4\n. Thanks for letting me know. Odd though as the /server/rpc directory has been created, there just isn't any files there.\nI can't think of any quick, clean fix for this (making a dummy data file in /server/rpc feels wrong) so I'll leave this for now as all my attention is on 0.4. If you can think of any easy way round this, please let me know.\n. Hey there!\nSorry for the delay replying.\nHmm this sounds very odd. Never heard of this problem before.\nI would recommend monitoring the traffic over Redis (with redis-cli and then monitor) to see what's going on. Feel free to paste the logs in and I'll take a look.\nOwen\n. Hey!\nThanks for submitting this. I agree the convention is wrong for Angular, however I can't accept your pull request as it would break existing sites in production which use Angular.\nThe place to fix this properly is in 0.4. Thanks for flagging it up.\nOwen\n. Hi there\nI'm happy to take a pull request if you'd like to research this and suggest a fix. But for now I'm going to close this as I don't really see it as a bug to be fixed.\nOwen\n. Hey. This sounds like a good idea. Will investigate further for 0.4\n. Thanks!\n. There is no 'official way' as yet but I did try using http://jamuhl.github.com/ and found that worked well. You can always put your .json files (one for each language) in your static folder and load them via an AJAX call.\nCould you also do this over the WS? I guess so. Would there be any advantage? Not really. Sending large files over the WS is almost never worth it as it will block any other requests.\nMy plan for 0.4 documentation is to include a 'Recipe Area' full of articles like \"How do I use Redis with SocketStream?\" and \"How do I add i18n to my app\" with code examples which point you in the right direction.\n. Thanks Paul\n. Interesting idea. It doesn't look as pretty as a closure, nor is it as easy to type, though I can see why it would be faster and more memory efficient.\nWithout thinking it through too much or testing, from what I can see, this pull request would break existing behaviour? \nI don't want to do that for 0.3, but happy to see if we can come up with a better RPC file format for 0.4.\n. Hey there\nSorry for the delay getting back to you. I have been considering this :)\nI've decided to keep everything as it in in 0.3. However, even though 0.3 RPC code must be compatible with rts-rpc, the module which will provide this functionality in 0.4, I will look into ways to making the code more memory efficient. If it's not possible, I'm already planning to release a much improved RPC solution later this year and will definitely bear this in mind then.\nThanks for taking the time to do this, and apologies again for the delay responding.\nOwen\n. Hi there\nA valid issue for sure. I understand you want a list of the client IDs, but what would you expect that API to look like?\nMaybe something like ss.client.all() would return an array of clients (each an object containing an ID)?\n. Hi there\nI'm going to have to rethink quite a lot around asset packing in 0.4, but I will definitely bear this in mind when I do.\n. Agreed. We need a much better API for this in 0.4. It will come.\nThanks for posting\n. This is what I suggest for 0.4.\n1. We don't do this if you make a 'minimal' project.\n2. We make a 'How to/Recipe' doc article called something like \"How to use different config files for each environment\" and mention the different approaches, as you have done above.\n3. Possibly create a config file for each default env when you create a 'normal' project. I'm not sure about that yet.\nThe key is we shouldn't make it mandatory, but we should make it easy to learn how to implement this if you need it.\nJust to let you know, I'm playing around with Github Wiki at the moment to see if we could use this for the How to/ Recipe articles. We definitely need to find a way for the community to contribute to articles like this.\n. Agreed. SocketStream can't and shouldn't try to be all things to all people.\nMaking it fun and easy to build large-scale realtime web apps needs to be our top priority. If you choose to build your app using the project generator, i'm happy to include a basic env-based config system.\nLet's discuss specifics in the 0.4 repo\n. Agree. Coming in 0.4 for sure\n. Indeed. Please note 0.3.3 will be released shortly which will use Engine.IO instead of Socket.IO (different protocol) but there's no real reason to upgrade if you're happy with 0.3.2.\nI don't know much about websockets on IOS, but I hear Socket Rocket is a good websocket library to use.\n. Initially I was against this idea, but if you can confirm all the connection/reconnection logic still works well; I'm happy to do this and make it 0.3.3 (along with a few other changes that need to go in).\nThanks Paul\n. Thanks Paul\nI've accepted the Pull Request and decided to release 0.3.3 which will replace Socket.IO with Engine.IO as soon as I get chance to verify everything is working correctly.\n. Thanks Paul. Going to merge this now. This should hopefully form the bulk of 0.3.3 but I need to do some final testing, and integrate anything else before pushing it. Soon as I can as I'm on holiday for two weeks.\nEveryone: Please note I've decided to swap out the bundled Socket.IO with Engine.IO as it is much better in a number of ways. If for some reason you really don't want to use Engine.IO, stick with 0.3.2. which works well. However, many sites in production run SockJS. The choice is yours.\n. Hi @pilevone\nThanks for your Engine.io insights - I always appreciate it.\nI know Paul adapted ss-sockjs to make it work with Engine.io, so there may be some leftovers we don't necessarily need.\nAlso I have mixed success trying to parse the cookies from Engine.io. It seemed to work at some point then stop working. For the sake of 0.3 I'd prefer to leave things as they are right now, as I want to focus all my attention on 0.4.\nI'd really like your help around session authentication in 0.4. We have a big decision to make: Should we enable other non-browser clients (other node servers or mobile devices) to talk to a SocketStream server directly? If we do, we can't rely on cookies being present and need to find a better way to handle authentication. Or is this a lot of work for a feature many will never use... SocketStream is a web framework after all. I'd welcome your thoughts.\nOne point to note: If we don't use cookies we must modify the initial HTML sent to the client and inject a unique token into that - which kills any hope of caching the HTML as we do at the moment.\nRegards,\nOwen\n. Thanks Paul. Taking both changes here (the latter commit improves reconnection).\n. Well spotted! I tested this and confirmed it. Will be fixed in 0.3.3, coming soon\n. Agreed, this is a bug. It can only be solved by passing the port through to the framework somehow. I will remember this issue when i work on 0.4. Thanks for letting me know\n. Hi @thebadger412\nPlease follow @paulbjensen's suggestion and let us know how you get on. If this is now working for you, please close the issue.\n. Hi there\nCan you let me know where we are with this? Please close the issue if this is now working for you.\n. Hey there\nSorry for taking an age to get back to you. I was considering this request for some time, then got really busy with other work and, during the last month, 0.4 development.\nAs the first alpha version of 0.4 will be out very soon, I no longer want to make any changes to 0.3 - unless it's a critical bug or something similar.\nHowever, your elegant solution has inspired me to do something similar with 0.4. What it will be exactly, I'm not sure yet (I was working all day yesterday on the new asset builder), but rest assured I see the need to render jade file server-side and I'll make sure it's possible.\nAgain, sorry for taking so long to reply.\nCheers,\nOwen\n. Hi Krasen\nThanks so much for taking the time to make an app and give me this feedback. I have read it all and agree with many of your points.\nAs you can imagine, deciding what should live in the framework, and what in the app, is probably the hardest decision I have to make. However, a lot of clarity has come from my work with 0.3 and really thinking hard about what SocketStream 0.4 should be.\nYou will see some big changes coming in 0.4. I also want the framework to do more (including many of the points you mentioned above), but do so with a lot less magic. Instead everything will be API driven and optional wherever possible.\nFor example, I agree a config system would be useful. But no one in the Node community can agree which is best (a bit like templating!). So my plan is to offer one as part of SocketStream, but it would be an optional API - you won't have to use it.\nThe only downside to the approach is there will be slightly more code in app.js. However one of the main things I've learned over the last 12 months is that more code is not necessarily a bad thing. Sometimes keeping things more verbose makes this easier to understand, debug and interchange at a later date.\nIf you're on IRC sometimes it would be good to chat further. I'd love to have you involved in the development of 0.4 in some way.\nThanks again,\nOwen\n. Thanks\n. Thanks for the offer, but it's not worth it for now as most of my effort is now going into 0.4. There i will be using JSHint throughout.\n. Hey Krasen\nI've not been able to replicate this because the caching is handled on the client. So even though each new request to the server would return new content, if you call\njs\nss.load.code('/test', function() {\n    require('/cached.js');\n});\nmultiple times it should never call the server more than once. Are you seeing something different?\nI'm going to change the syntax for packing assets in 0.4. It feels really messy in 0.3, mostly because I changed the behaviour late in the day to support pre-processing and caching of asset files.\nCheers,\nOwen\n. Thanks Krasen\nI see what you mean now. I'll merge this in and look though it again to make sure I can't see any obvious reason why this won't work out as expected. If all is well, it will be included in 0.3.3 which I'm going to release very soon.\nThanks again,\nOwen\n. Hi there\nPlease paste in the code of the server.remoteFunction\n. Hi there. Closing this for now, but if you're still having problems please paste the entire contents of your /server/rpc code into a Gist so it's more easily readable and I'll happily take a look\n. Cool. Thanks for letting me know. Will try and make this possible in 0.4\n. This is definitely happening in 0.4, so going to close this now.\n. Hi Paul\nLet me know if you can do the HTTP/HTTPS detection. If not I'll merge this in and have a look before releasing it.\nOwen\n. Hi there\nYou can't and shouldn't do this as visitors would just be able to alter the path and read any file from your hard drive. Just setup an explicit route or create a symlink to the file on your external hard drive.\n. Hi there\nAt the moment you will have to put this file in the templates directory. But I can appreciate that's not a great solution for you as your example is so trivial you can do it all in one file. Something to think about fixing in 0.4 for sure.\nCheers,\nOwen\n. Hi there\nThis is a good idea. Let me have a think about the exact API\n. We can't do this dynamically each time we serve the view as we want to be able to cache it in production (or on a CDN), so sending a userID is a no go.\nBut I'm all for pushing 'static' config params to the client somehow. Will bear it in mind when working on 0.4.\n. Thanks Paul for answering so quickly.\nThis sudden change in behaviour is so annoying. Looks like it won't error at all in 0.8.21 so we just need to wait this one out.\n. Hi there\nThanks for doing this, but I've decided against accepting it into the core as:\n1. there will be no more releases of 0.3 unless a major bug is found\n2. this feature is already in 0.4\nCheers,\nOwen\n. Fixed in 0.3.4 and also in 0.4. Thanks for letting me know\n. Ah right. Would you mind tracking down the x-forwarded-for header and apply this if it exists? I'll happily merge in a pull request.\nWe will get tests around all of this stuff once the APIs settle down. They would prevent annoying regressions like this.\n. Thanks Ben. I'll get this released ASAP.\nJust to let you know, I've been working on defining the new Transport and Service (Request Responder) API in 0.4 over the weekend.\nI've been looking through ss-angular to see how it works as I'd love to launch 0.4 with working ss-angular and ss-backbone modules from day one.\nI notice you currently rely on ss.rpc and (I think) ss.events in your code at present. These will be extracted out of the core in 0.4 into separate modules. Instead the new Service API will handle the callbacks, JSON serialising and (maybe, not sure yet, pubsub) for you. I've yet to figure out if we should allow one service module to depend upon another (and, if so, how to solve versioning problems here).\nI've not committed any of this new work at the moment as it's all in flux right now, but when I have something I'm happy with I'll push it to https://github.com/socketstream/socketstream-0.4. I'd be very interested to hear your thoughts.\nI'm very much looking forward to the day when the APIs settle down so we can fully test everything and prevent bugs like this one from happening.\nThanks again for your work on ss-angular. I'm determined to make sure it works even better in 0.4.\nOwen\n. Hey Ben\nApologies, I've been so engrossed in 0.4 development these last few weeks I've not been spending as much time on 0.3 issues as I should.\nYour patch looks good, but I'm always ultra-cautious when it comes to changing things like this as inevitably it will break something none of us have considered.\nAs soon as I get chance I'll try it out myself and think hard about anything which could go wrong. If all looks good I'll merge it in.\nAlso, I'll be in touch shortly regarding Angular integration in 0.4. I think I'm onto something pretty good but want to advance it a bit more before showing you.\nCheers,\nOwen\n. Hi Ben\nI'm working on Sessions support in 0.4 today and I've started thinking about the two approaches here.\n1. The client-side JS reads the session cookie and sends it over the WS (what we have today in 0.3)\n2. We try to obtain the session id server-side by looking at the HTTP headers (what we used to have in socket.io)\nWhile I agree 2 is more reliable if the transport supports it (last time I checked, SockJS doesn't), it has a big problem: it requires the client to be running in a browser.\nThe latest version of 0.4 (which I will push within the next week) has separate modules for the client and server 'realtime' components. Best of all, the client can run anywhere - on the browser, or in another Node process. Thus there is no longer any need for ss-console as you can simple connect to the server using the same client library and use a REPL to invoke RPC commands etc.\nAll this works great already - without sessions support. Figuring out how to add this is the hard part.\nI'm going to do some experimenting with ideas today and let you know. Ideally I'd like to find a secure and reliable way to do method 1 properly, even if cookies expire or don't exist at all.\nOwen\n. Hey Ben\nI've had chance to test this and I can confirm it works well. However, I'm a bit reluctant to merge this in, now that I know 0.4 will not work this way.\nAs we discussed, in 0.4 we're going to continue reading and setting cookies in the JS client. However, I will make it clear in the docs that, if you use SocketStream with Express, you will need to turn off the http only setting on the cookie. I'm hoping this is all that's needed to ensure everything works flawlessly each time.\nWould like to hear your thoughts. If you still think there's a strong case for doing a final 0.3 release which uses this code, I'm prepared to consider it. I'm just worried about significantly changing the underlying behaviour at such a late stage in the game.\nCheers,\nOwen\n. Thanks!\n. Hi there\nCan you describe why you need this? The concept of api.add() will go away in 0.4, but you'll still be able to append properties to a global object which is accesible inside your code.\n. Hi there. As we've discussed I'm not (at least at the moment) trying to make a hot-loading server, so right now there's no need/use for an api.remove() function.\n. Hi there\nI can't really answer your question but I can provide guidance which may help.\nThe future of SocketStream is more modularity, choice and independence. A lot of ideas which used to be buried deep inside 0.3 will be extracted into separate modules with their own tests in 0.4. This process has already begun (see https://github.com/socketstream/socketstream-0.4/blob/master/HISTORY.md).\nThat said, all this choice and freedom are useless if developers are left with a confusing mess. So I'm going to spend a lot more time on documentation, recipes, examples, screencasts, etc showing how everything works beautifully together.\nSocketStream will always focus 100% on single page apps; however the way you will use SocketStream and Express together will change in 0.4 which will make it easier to build a new 'normal' multi-page website and use SocketStream to deliver a numer of 'views' (e.g. add a realtime page at /admin). Also, there is also nothing to stop you generating views server-side before you pass them into SocketStream (as regular .html files).\nHowever, what I'm definitely not doing is going down the whole \"render everything on the sever first then make everything auto-magically update on the client\". Meteor and Derby both do this, but pay a big price is code speed and complexity. I have never seen the appeal of this approach as true web apps (realtime dashboards, trading terminals, flight checkers, etc - all the stuff SocketStream does well) all have signin screens, which are never going to be accessible via Google anyway.\nHope that helps\nOwen\n. Hey @pocesar \nStick with 0.3 for a few more weeks. I'm working hard to get the first 0.4 preview out by the third week in April when I'll be talking at Realtime Conf EU. Until then everything is likely to be massive flux as I'm doing a lot of re-organisation and changing APIs.\nOwen\n. No prob. 0.4 is coming on well. Expect an alpha release shortly. Closing this now.\n. Thanks so much for spotting this, and fixing it!\nIt does kinda make me realise that very few people must be using the minimal mode!\n. Hey. We can do this, but I'm not sure why you're checking for existence of all the files:\nif options.module is false and 'entry.js' not in pathAry and 'system' not in pathAry and 'shared' not in pathAry then output else wrapCode(output, pathAry, opts.pathPrefix)\nCan't we just see if options.module is set?\nCheers\n. Thanks for working out what the problem is @emgeee. There were many buggy 0.9 Node releases on the road to getting 0.10 out. Now 0.10 is out, no one should be using any 0.9 versions for anything so I'm going to close this.\n. Ah thanks for pointing this out. Normally I test pull requests before merging them in, but didn't this time. My bad.\nFixed now.\n. Thanks for the pull request. Looks correct, but sadly you need to change the corresponding coffeescript file in /src too. Sorry - I know it's a real pain. This is exactly why I stopped using CS in 0.4.\n. Thanks!\n. Hi there\nThis is correct behaviour. Like most web frameworks, SocketStream uses process.cwd() to determine the current directory, so you need to cd into that dir before running it.\nCheers,\nOwen\n. Hi Paul\nHave you seen https://github.com/nateps/connect-gzip/pull/20  ? It looks like the current library is not using Node's internal gzip but doing it's own thing, which can lead to race conditions.\nAlso, as it stands at the moment, the main HTML served would not be gzipped, only the assets (JS & CSS). Which is better than nothing, but these should (ideally) always go on a CDN anyway.\nThat said, if we could get a solid gzip implementation which doesn't introduce bugs and covers all output, I would feel happy putting it in the core.\nOwen\n. Hi Paul. It looks like the static middleware is called before the compress middleware here, in which case none of the static assets (JS and CSS files) will get compressed.\nCan you verify (by looking at the headers in the browser) and also google to see if there are any known problems using connect-compress. If all is good I'll merge it in. Thanks\n. Thanks Paul. I'll do another 0.3 release soon with this in it.\n. @paulbjensen Not sure, but I know I've not deleted anything.\n@life0fun SocketStream contains its own basic build tools (i.e. when you start it up in production it will build all the assest for you into minified files). Are you wanting something in addition to this?\n. Hi there\nI'm very certain I don't want to use requirejs for SocketStream. I've tried it before and found the CommonJS system (using Browserify) much better, not only at working with client-side code - but for sharing code between the server and the client.\n. Hey Paul\nFeel free to backport this idea from 0.4 into 0.3 if you like:\nhttps://github.com/socketstream/socketstream-0.4/blob/master/index.js#L38-L43\nYou then use the log object from within the internal code. If nothing has been attached to the 'debug' and 'info' levels then it's a (silent) noop.\nOwen\n. Ah yes. I can see what's happening here. It's looking for a .map file but we have no code formatters registered with this (like we do have with .coffee for example).\nI'll take a look as soon as I get a moment.\n. Great to see this\n. Great to see you contributing @mmalecki   Don't be shy about suggesting bigger changes.\nI don't get chance to check-in often, but every time I do I see many good things happening. Very cool :)\n. Or, if you don't mind writing it in pure CSS (as apposed to Stylus), put it in /client/static/css/myprintsheet.css and put your own manual <link> tag in the headers with the file pointing to /css/myprintsheet.css\n. Glad it's working for you.\nI'd like it to go in the docs. Not quite sure what section it would fit into. We have a page on Client Code already, but this is really other assets.\n. Thanks for the feedback. Will try to get round to writing this up shortly. \nAgreed with the CDN issue. I would like to find a solution to this - not quite so easy as with Rails as we're not making people using the image_tag() helper or anything.\nRegarding logging, short answer is there is no way to silence them at the moment in production but I hope to address this sooner than later.\nThis area still needs a lot of thought. I got quite far into integrating Winston, only to find out it didn't take multiple params and made for a rather messy experience when developing (a lot of datestamps etc could not be edited without hard patching). There are several other logging libs I'd like to try before making a final decision.\n. Can you let me know if you're still having problems here and close the issue if not. Cheers\n. Sorry, what do you do to get:\n/home/foo/server/rpc/bar.js:2\n});\n^\nIf there are any more obvious error cases I've overlooked I want to try and fix them before 0.3.0\n. Can you let me know the status here. There is no ssClient in beta1 so I'm hoping this is no longer a problem.\n. Hi Robert\nWhere does your swf file live? Also, are you running a recent version of SocketStream?\n. Don't worry, this problem is now fully fixed in the lastest alpha (alpha5). I am finishing it up and will release it in the next few days.\n. This is now fixed in alpha5\n. Hi all\nPlease try again with alpha5 as there have been major client-side changes. If you're still having problems I'm determined to get to them bottom of them. Any debugging info you can provide would be very helpful.\n. Guys any update on this? Please make sure you're running the recent release as there's been a change to the way the cookie string is split.\nIf anyone is still having problem running the latest code I'll add more debugging as @nponeccop suggests, otherwise I will close this issue.\n. Hi there\nIf anyone is having problems with this please let me know. Make sure you're running the latest master.\n_Note - very important! _ ss.event became ss.server a while ago.\n. Hi there\nAre you using Express? Have you seen any error messages complaining about missing session cookies?\n. Hmm ok. I asked because I just debugged a similar problem which turned out to be caused by Express extending Node's HTTP request object in a way which was making cookie parsing intermittent. Incidentally if anyone has this issue, reversing the require order so you require('socketstream') before require('express') fixes the issue. I will debug this further next week as the load order should clearly not make a difference!\nBut back to your issue... As I've not heard of anyone reporting this problem for months, it would be helpful if you can insert some debug logging around here:\nhttps://github.com/socketstream/socketstream/blob/master/lib/websocket/transports/socketio/index.js#L44\nLet's see how far we're getting. I assume processSession() is returning correctly otherwise you would see the Warning: connect.sid session cookie error I mentioned in the terminal.\nThanks,\nOwen\n. Ah ok. Definitely a transport issue with Heroku. Engine.io (which we're going to use in SocketStream 0.4) should work well with Heroku, but right now I would recommend against hosting there. That said, you maybe able to get it to work by shuffling the transports around and inserting some debugging code to ensure the session cookie is parse correctly. Good luck!\n. Ah right. Apologies - you are the only person I know of who is using SocketStream on Heroku so the advice I can provide is limited. Very glad to hear things are working out for you, by and large.\nI am not against the idea of exposing the other Socket.IO connection events in principal, but we will need to make it clear that not all events are supported on all transports. I think most users will understand that. Hopefully in the future it will be possible to ensure ss-sockjs can emit these additional event types by coding this into the module.\n. Ha ok, well if you do get chance to re-enable it, please do. It needs to be 100% reliable and if it's we need to fix it.\n. Fixed this in beta1 (as much as possible) by rewriting the error message so it's much clearer, explaining what file is causing the problem and what to do about it.\n. This is now implemented in alpha5. We setup\nwindow.ss = require('socketstream')\nby default so you can call ss() commands via the browser's console, but there's nothing to stop you putting\nvar ss = require('socketstream')\nat the top of every file if you prefer.\n. Closing for now. See reason in #182\n. Hi all\nThanks for this, and apologies for the late reply.\nHaving given this some thought I think it's pretty clear we need a few API calls on the collections of 'users', and 'channels' - and maybe 'sessions' as well.\nE.g:\n``` javascript\n// get a list of socketIds in use by a particular userId (will also tell you how many devices this userId is using)\nss.users.find(userId) -> [array of socketIds]\n// get a list of socketIds in use by a particular sessionId (i.e. how many open tabs)\nss.sessions.find(sessionId) -> [array of socketIds]\n// unsubscribe all sockets (devices) attached to this userId (effectively logging the user out of all devices simultaneously) \nss.users.unsubscribeAll(userId) -> true\n// get a list of sockets subscribed to a particular channel\nss.channels.find(channelName) -> [array of socketIds]\n// unsubscribes all sockets from the named channel\nss.channels.unsubscribeAll(channelName) -> true\n```\nToo late to put them into 0.3 now, but I'll earmark this for 0.4. Of course the actual API may change - I'll have to give it more thought. Suggestions welcome.\n. Hey Robert\nThat would be awesome if you could add these changes to 0.3. In fact, if you could do that and update the dependencies, I'm happy to do another 0.3 release.\nLet me know if you run into any problems.\nOwen\n. Hi there\nI have tried running SS_ENV=production nodemon app.coffee and it all works fine. This could be because lots has changed in beta1.\nClosing this now but please repen if you have the same problem.\n. Fixed in 0.3 beta1\n. Still not had time to write this yet but thankfully these event handlers are now created for you by default in entry.js', plus their names are pretty self explanatory (with the exception ofready` which just means SocketStream has fully loaded, your session has been created and we are now ready to accept incoming requests).\nIdeally we need a doc page called \"Handling disconnections\" or something like that which documents all the events and provides tips on handling reconnections. Contributions gratefully received.\n. Thanks @nponeccop \n@dennismartensson has also been working on this problem and has posted a project here: https://github.com/dennismartensson/load_test\nI have yet to fully dive into it, but I know it uses PhantomJS to spawn new headless browsers to test concurrency.\n. Yes, Thor is great! It came out very recently.\nIf you pass it a generator file you can simulate load on a SS server by sending it the same message an ss.rpc() produces.\nHaven't got around to using it with SocketStream yet, but if you get chance, I'd love to see how it goes.\n. Hey there\nIf I understand right, we need to allow you to pass custom local vars here:\nhttps://github.com/socketstream/ss-jade/blob/master/lib/wrapper.js#L23\nIf this sounds right we can make this a config option for ss-jade\n. Cool ok. I will implement this after the next SocketStream release is out.\n. Yes there is indeed, it's in the HISTORY.md file\nss.client.set({liveReload: false})\n. (oh and more interestingly for me, why do you want to disable it - does it not work as you expect?)\n. Hey there\nAre you calling req.session.save() after updating the req.session object?\n. Hey\nCan you let me know if this is still a problem and close the issue if it's now resolved.\nThanks\n. Closing this issue for now. Once gzipping assets becomes simple and stable we will support it.\n. Hey. It's caused by images in your css directory. See the #155\nWe still need to find a better solution to this\n. I have improved this error message in the forthcoming beta1 release\n. Very true.\nWe used to serve it statically in previous versions, but things became more complicated with multiple clients. For example you can now do:\njavascript\nss.http.router.on('/', function(req, res) {\n  if (req.headers['user-agent'].match(/iPhone/))\n    res.serveClient('iphone');\n  else\n    res.serveClient('main');\n});\nWhich needs to be processed by Node in production mode as well as development.\nStill I am interested in finding a way to serve the root HTML statically if you don't need to interpret the incoming request, as I fully agree everything should be on a CDN if it can be. I'll have a think about it.\n. Indeed, only problem is you need to hit the HTTP server at some point now to get a cookie for use with your Connect Session.\nNow that all clients are now cached in RAM in production mode, things should be far faster than before.\nPlease feel free to add something here, or close the ticket if you're happy with this for now.\n. Hey David\nI like this new proposal of nesting dirs inside 'libs' but making them behave as 'libs'. We shouldn't need to involve any regexp parsing in that. Would certainly prefer to keep it simple but intuitive.\n. Code complexity mainly. A good design should be simple. I'm not sure we have that here yet, but hopefully we're on the right track.\nBut I'm happy to make sub directories of 'libs' act as 'libs' in a future release as this feels more intuitive and won't break anyone's code.\n. Agreed. Good point. This will be in the next release.\n. Yup indeed. Simple beats fuzzy every time. Too many choices are a bad thing and messy to document.\n. Thanks :)\nGoing to merge this into a local branch and see how it feels to use on a real project.\n. It's not impossible to do it this way, but not recommended.\nInstead put all your shared logic into regular node modules and require them at the top of your /server/rpc files. Ideally all your main business logic should live outside of /server/rpc files\n. I agree. It will all happen with time.\nWe're all learning how to do that to some extent.\n. You cannot do this inside SocketStream as such, but you can setup a route in app.js which sends a file.\nAlternatively, use SocketStream with something like Express to do the same thing.\n. I'm refactoring a lot of this code at the moment.\nCan you tell me what type of file you put in the client/code/libs dir to cause the error above?\n. Argh I love IE.\nCan't just paste the code in sadly as some older browsers don't support forEach()\nJust wondering if we could modify the way we use console in the SocketStream client code so we can remove this file and avoid the problem altogether.\n. I'm aware this is still a problem. Will look into it this week.\n. Hey @addyosmani \nJust wondering if you know of a better cross-browser implementation of console than the one we're using here:\nhttp://patik.com/blog/complete-cross-browser-console-log/\nIt's currently causing problems for us in IE9.\n@nponeccop if Addy doesn't know of anything better, I will attempt to fix the one we have using your suggestion.\n. Hi all\nNo change on this so far. I know this is a big issue but I need to find time to investigate the alternatives and get a working Windows VM to test with IE9.\nI'm writing some documentation for SocketStream at the moment. I hope to look at this issue next\n. I've read though the various options (thanks @addyosmani !) and had chance to rethink this.\nI believe the only time we (or you, the developer) should ever be using console.log is when you're developing your app. We should never be calling console.log in production and hence, we really shouldn't be sending a 1.3kb wrapper library to every client (including mobile clients).\nI initially put the console.log wrapper in because people were complaining the ss.rpc() commands weren't working correctly in their browsers. In fact, the RPC commands work fine, but the default callback (if you don't provide one) is console.log, hence older browsers were showing errors instead of the expected response.\nSo my preference is to take it out altogether. Yes, this will cause a few issues along the lines of \"ss.rpc() commands not working in browser X\"; but as most browsers now support console.log() with multiple arguments this shouldn't be as much of a problem as it used to be.\nIf there are no strong objections I'll remove the wrapper in the next release (hopefully out in a few days).\n. Great. Agree with 1 & 2. This may involved tweaking the RPC client code a little over time, but I agree we shouldn't try to support ancient versions of IE etc - just the latest versions of each major browser.\nLove the idea behind 3. Great news is, with the next release of SocketStream, it will be possible to write a Request Responder to do just that.\n. Closing this now as the console.log wrapper was removed in 0.3 RC1\n. Thanks. Still seems to be hogan.js here: https://github.com/twitter/hogan.js/blob/master/package.json\nAre you aware of any breaking changes?\n. Woah you've still got this problem with ss-hogan? I assumed that was long solved.\nSure ok, I'll update it and try some apps out with the new version. If all is well I'll update the module.\n. Ok thanks. Updated\n. Hey\nStill not sure what we're going to do regarding configuration. My feeling is the less configuration the better, as the moment you start adding lots of config it starts to feel like a black box framework again. In particular, if you're using SocketStream with other frameworks in the same app, things could get messy.\nI'm interested in looking at things like nconf but quite honestly I'm in no hurry to make a decision here, especially when it's already so easy to divide your app into different files and just require the one you want (e.g. require('./config/production.js) passing the ss object around by reference.\nAlso I much rather have a Javascript/programmable approach to configuration as we do at the moment than the declarative/JSON/YAML approached of the past.\nAny other opinions on this welcome.\n. SocketStream doesn't and shouldn't touch CoffeeScript code.\nAs nponeccop say's, it's Node which interprets .coffee files. However the initial file you load must be .js UNLESS you start your app with coffee instead of node.\nI.e. right now you run node app.js and then from that point any extra file you require can be a .coffee file, but if you want 100% CS in your project you would convert app.js to app.coffee and start your app with coffee app.coffee\n. No problem. Happy to help. I'll close this issue now\n. I'm aware there are some system libs which are not minified in production but this will be fixed in the next release.\nIf you use stylus your CSS will be compacted in production mode. Nothing is done with regular .css files at the moment but could be in the future.\nCoffeeKup templates are not touched in production mode. It would be possible to add some sort of minifying to them in production mode.\nWe will introduce GZip at some point. See #182\n. All code in the .js file we produce when you call ss.client.packAssets() is now minimised correctly in 0.3 Beta1.\nClosing this now but I will continue to look for ways we can minify other content (such as CoffeeKup templates).\n. Great suggestion - just what I've been looking for!\nI've put it in the next release, out tomorrow.\n. Hi Will\nThanks for your idea. I'll take time to fully digest your idea shortly, but right now I can tell you /index.js is already fully supported when you require a folder with /index.js in it.\n. Hey Will\nSo I've been thinking about your idea... I'm definitely interested in exploring this.\nAs you may know, we're only using part of browserify at the moment. The plan was always to explore the other parts (which resolve module deps server-side) and to see if we can use these in SocketStream.\nIt's not a simple matter, mostly because server-side parsing of client-side files is SLOW, though we would naturally use a filesystem cache to help matter.\nSo if I understand you right, you propose we do something like:\njavascript\nss.client.define({\n   view: 'app.jade',\n   css: ['libs','app.styl']\n   code: {entry: 'app.coffee', libs: ['libs']}\n});\nSocketStream would then use the entry file to resolve all the modules used and send only the required modules to the client. Right?\nCan it be done? For sure. I'm just worried about performance, especially when developing, as this would force the developer to wait anything up to 4 seconds each time a JS file is saved so the dependency tree can be rebuilt.\n. Yup :) I've already got a branch with detective running and it works well, but as I say it can be slow in development (even if you take a md5 checksum of each module and store the dependencies which it what I was doing).\nI'll have a play with this idea some more and see how it feels in reality when working on a large-ish site.\nI agree it would be great if we can pull it off.\n. Because each module takes 1-10 seconds to determine it's dependencies, so we need to cache each file's dependences (between server restarts). Plus we don't know which file changes, only that there is a change, hence the need for a checksum.\nI've already written the code that does all this, but as I say, it's more a question of working out if it's a good idea or not in reality. Hopefully I'll get chance to spend more time on this next week.\n. Good to hear from you all on this!\nSo first up, let me say, I'm in no rush to change the current system. I've had a lot of positive feedback about it and I feel it has three huge advantages which I'm not going to surrender easily:\n1. If you know how to write Node.js apps, you know how to write client-side code in SocketStream. There's nothing new and funky to learn, as there was in previous versions of SocketStream.\n2. It is dead easy to require any client-code module within your server-side code without having to modify anything. Even if the module requires sub-modules it all works fine out of the box. Want to use a system module like Node's url, we can support that too. This is a big deal. As far as I know no other framework has pulled off code sharing in a structured, scalable way.\n3. Minimal overhead and negligible performance impact. Whether it's in development or production, the server does almost no work to deliver the benefits of the current solution (basically it just wraps a small amount of code around each module).\nTo make all of this work the developer only needs to remember one thing: Only require a module if it exists. That's it. You can choose to bundle modules in the initial payload (as 95% of apps will do) or require them on demand with ss.load.code, just don't require a module unless you've sent the code to the browser, one way or another.\nSo if we're going to move away from the current solution to something else, there needs to be a damn good reason to do so.\nAs I say, I've experimented with other components of browserify to offer a more auto-magical solution. It's a very appealing idea, but ultimately it would mean adding additional complexity and dependencies to the framework.\nMore importantly, it would slow developers down during the development process. Even with the best caching, if you're modifying a client module on the fly, the server would hang for at least one second to resolve the dependencies in the module you've changed. That's going to get very annoying very quickly.\nTherefore I've been thinking of alternative idea: To keep things as they are but add a 'Pre-flight Checker' feature at some point in the future, most likely as an optional module. This would scan though all your client code, check all the dependencies resolve correctly and make sure you're not sending anything you don't explicitly require (orphan modules). Granted, it would take a while to run, but typically it's something you'd only run once before you deploy.\nNaturally @nponeccop is right that it would be perfectly possible to fool the dependency checking if you require modules in exotic non-standard ways, but if you choose to use this optional and non-essential feature, we must assume a degree of common sense.\nJust to let you all know, the next release, beta1, will hopefully be ready early next week. I have refactored a lot of the code in the Client Asset Manager but there will be no external changes to the way modules work.\n. Any more thoughts on this guys? If anyone still thinks we should be using AMD instead of this approach please do make an argument for it.\nIf I don't hear anything back in a few days I'll close this issue, as I'm trying to tidy up the list before we launch 0.3.0 properly in April.\n. Thanks guys.\nSo just to restate, I'm very happy with the current system and there are no plans to change it at present.\nBut I would like us to have a Pre-flight Checker. Done right, this would not only detect module problems, but also perform any other checks you'd want to have done on your client and server code before it goes into production.\nShould anyone like to have a crack at building this it would be very appreciated (I'll assist in anyway I can). If not, consider it on my medium-term todo list (after a number of other optional modules I want to build first).\nClosing this now. Thanks again for your input.\n. Hey!\nIn actual fact if you don't explicitly use any templateEngine all templates are rendered like this by default, to retain compatibility with 0.2.\nUp until two days ago this was documented in the tour (on the website) but I removed it thinking most 0.2 users already knew this.\nI will update the template docs soon to make this clear. Thanks for brining it to my attention.\nOwen\n. Thanks. This will be fixed in the next release\n. Fixed in 0.3 beta1\n. Hi there.\nThe Live Reload documentation page covers how to deal with this error: https://github.com/socketstream/socketstream/blob/master/doc/guide/en/live_reload.md\n. Hi there\nI've not used SocketStream and Express together for a while so things may have changed in the recent API. I also recall reading the new 2.0 version of Connect we're using requires Express 3.0 which isn't on NPM yet; therefor please clone this locally and link it to your project.\nIf all that still fails I will checkout the code myself and investigate.\n. Thanks for pointing this out - I lost sight of this when the issue got closed.\nI have repopened it to remind me to change the website asap.\n. Hi there\nI've updated the code on the website and tested it with both Express 2.5.9 and 3.0 beta7.\nIf anyone else has trouble integrating express, please let me know.\n. Hi there.\nYou'll need a client folder containing the various JS, CSS, Views, etc you want to use with SocketStream. Right now these dirs are not user definable.\nAs for PhoneGap, I've never tried it, but if we can support it out-of-the-box, even if it means we need to make a few tweaks here and there, I'd be interested to do that.\n. Hi Jacob\nI agree, there are some disadvantages to the fixed folder structure approach if you want to use SocketStream with other frameworks and toolchains.\nI chose the current system as I see a big benefit to providing some level of structure, esp when developers will often be working on multiple projects within teams.\nWe could certainly make the paths to each asset type configurable in a future release, but I doubt it's quite as simple as that. I think it would be best to look at each integration use case individually and see if any common patterns arise.\n. Thanks Jacob\nIf we made the current asset paths user-configurable (e.g. /client/static could become /public/assets or anything else), would it help you in this instance?\n. Ok we will support user-definable /client directories in the next release. The current defaults will not change.\n. Hi there\nThanks. I've accepted this. I'm just a bit puzzled why this bug hasn't shown up before... What browser are you using?\n. Hi there\nYou can pass the database index number as db to ss.session.store.use('redis'); right now, e.g.  ss.session.store.use('redis', {db: 5}); \nAt the moment you can't do this to ss.publish.transport.use('redis'); but I've put it in the next release, beta1, for consistency.\n. Hi there\nSorry you can't do this in 0.3 as I can't figure out a way to implement it cleanly without global variables.\nJust create a new connection - the overhead is minimal\n. If i understand you right, yes you can.\nYou can all ss.api.publish.all() from your app.js file or pass that object to a file you require\n. That's an interesting point. We don't have support for that yet, but I guess you're thinking along the lines of what Rails provides with config.action_controller.asset_host ?\n. Ok. Well the variable in config.action_controller.asset_host only works when you use things like the image_tag helper. As we have no such think in SocketStream, it's really more down to how you're doing your image links.\nFor example, you could have a client-side variable which gets changed depending upon the domain you're accessing (e.g. mydomain.com vs localhost). This could be use inside your template code.\nFor now I guess you'll have to improvise a little, but if there are specific ways we can make this easier I'm interested in supporting them as I know it's a common issue.\n. Ah cool. I will put basic CDN support in the next release (which will just do what you're doing here without having to remove != SocketStream)\n. Hi there\nThis is now in 0.3 beta2. Put this in your app.js file:\nss.client.packAssets({cdn: {js: \"http://my.cdn.com/my.js\", css: \"http://my.cdn.com/my.css\"}})\nThe CDN links you provide will only be used in production mode.\n. Hi there\nThat's basically the right idea. The first request to the server should be some sort of init command to find out if the session is logged in or not, then you can load/show the correct template.\n. Hey, do you need any more help with this or can I close it?\n. Hey there\nI think this relates to #201\nIt looks like we're going to have to make the dirs user-definable. If we were to do that, would it help in your situation?\n. I'm putting the ability to override the client-side dirs in the next release. This should help you, but let me know if there is more we can do.\n. Unfortunately the files generated are going to be different every time as the filenames include a timestamp to prevent caching.\n. The ability to override the default client-side dir structure is now in 0.3 beta2 (see changelog for details).\n@nponeccop is spot on about the timestamps.\nClosing this issue now.\n. Hi there\nBear in mind all client-side code is packed, minified and sent in one file which the browser will cache in production mode anyway.\nDo you see Local Storage to do something more than this? While I see it as our job to guide users and ensure they can use any storage solution of their choice (AmplifyJs looks interesting @haohello), we must be very careful about mandating/bundling any new libraries - especially client side.\n. Hi there\nMake sure you ss.load.code() the directory the code is in. This should be outside of the app directory as everything in here will get bundled and sent to the client upon connection anyway.\nE.g. create a new folder like: /client/code/async\n. Did this fix it? Please close if it did\n. Something's not right there. We don't do any caching at the RPC level.\nFeel free to paste some code in and I'll investigate. \n. Ok... can't see anything wrong there.\nIf you console.log out numberUpdated before you call res() do you get the same thing each time?\nAssuming you don't, put the following in your app.js file to see what's going through the websocket:\njavascript\nss.ws.transport.use('socketio', {io: function(io){\n  io.set('log level', 4)\n}});\n. Hi there\nThanks for posting the solution. I think this relates to #192 which I'm aware still needs to be be fixed. It's on my list.\n. Thanks!\n. Totally agree. I've fixed it in the next release.\nThanks for pointing it out.\n. I'm afraid I can't see a way to 'get your sessions back' if the secret used to hash the session ID has changed.... but I am wondering if we can improve the way Express works with SocketStream here as we really don't want two lots of Session middleware loading up at once.\n. Ah think you are right. Yes, we need to be able to pass this as an option. I will make this possible in a future release.\n. Closing this now. Note a recent commit means you will no longer see this error:\n! Error: Session ID ... not found. Use Redis to persist sessions between server restarts. Terminating incoming request\nas sessions are now automatically re-created if they don't exist\n. Many thanks @nponeccop. I'm currently working on releasing a few more things in time for recording the Node Up podcast tomorrow, but I'll take a look at this early next week.\n. Hi guys\nI need to make some decisions on this for SocketStream 0.4.\nI'm all for going down the random token route, but one of the great features of 0.3 that I want to carry though to 0.4 is the ability to share sessions between WS & HTTP requests.\nHence, keeping some level of cookie support is likely to be necessary, though we will need to move back to reading this via client-side JS and sending the session ID to the server as the initial WS request, as Engine.io does not have a 'handshake' object (at least not that I can see). This is no bad thing as it will keep things more consistent between transports (as SockJS already uses this method).\nIf anyone has any smart ideas, now is great time to share them :)\nOwen\n. Hey\nYup this changed in alpha5, it was documented in the changelog at the time.\nGlad to know the entire connection handling code isn't broken for you :)\n. (oh and I'd love to see your fix for #219)\n. Thanks. Interesting (and common) use case. I will take a look\n. I agree there is a need for this. The main problem is that socketIds are very transitory.\nShould the connection go down and reconnect for any reason (server reboot, wifi problems, user hits reload by accident), you get another socketId - so the app would have to deal with this and manually resubscribe.\nIdeally I think we should offer both req.session.channel.subscribe() and something like req.socket.channel.subscribe().\nAt the heart of this is a much bigger and broader discussion: Should individual tabs simply act as multiple interfaces to the same app, or function completely independently? Ultimately I think we should leave the decision to the app developer and provide the best tools for both approaches. \n. Going to close this now. Rest assured this is an issue very much on my mind and something I am keen to support in the future.\n. Hi guys\nSorry for the delay getting to this.\nI totally agree. I want to ensure SocketStream has excellent support for CDNs. Right now I have yet to deploy a public SocketStream app using a CDN, so I haven't encountered these issues first hand - so I'm relying on people who have to make specific suggestions in terms of changes we can make to the core to improve compatibility.\nI am also interested in exploring whether or not it's possible to put everything on the CDN, only using SocketStream to generate the initial HTML, CSS, JS etc and, of course, for the websocket connections. There are some issues with this approach if you have multiple clients defined, but it would be nice to have this option.\nI think the best thing for me to do is use CloudFront for www.socketstream.org (as it's already hosted on EC2). This should bring to the surface any problems with the current approach.\nOwen\n. Hi all\nI'm working on this problem right now as I want to improve our CDN support in 0.3.0 and that may mean a few minor API changes.\nI'm going to start by trying to get www.socketstream.org using Amazon CloudFront (as the site is currently hosted on EC2) and see what needs to be done to make this as easy and painless as possible.\nIf anyone has any more CDN related thoughts, please post them here or join me on IRC (#socketstream on Freenode).\nOwen\n. Hi\nGreat to hear that, by in large, things are working well with Cloudfront. I have done some brief testing and had a similar experience, however things can be improved.\nHere are the proposed changes for 0.3.0 (or possibly an interim release... let's see):\n1. ss.client.packAssets() will now check for existing assets already packed in /client/static/assets and use them if they can be found. If any assets are missing they will be automatically be re-packed.\n2. To force re-packing of assets each time you start your app (i.e. the current behaviour) pass SS_PACK=1\n3. The default cache expiration time will be changed to 30 days (bearing in mind your point about each asset having it's own unique URL). Note: This setting can already be overridden manually with ss.client.set({static: {maxAge: newValue}})\n4. CDN paths can now be strings or functions. E.g:\n``` javascript\n// in app.js\n// Note:\n// client.id      = unique id/timestamp for this client\n// client.name    = unique name for this client (e.g. 'main')\n// client.path    = path which would normally appear - e.g. \"/assets/main/1340039525318.js\"\nss.client.packAssets({cdn: {\n  js:  function(client){ return \"http://mycdnhost.cdnprovider.com/mypath/\" + client.name + \"/\" + client.id + \".js\" },\n  css: function(client){ return \"http://mycdnhost.cdnprovider.com\" + client.path }\n}})\n```\nThese changes should make it much easier to deploy a project to a cluster of servers, complete with pre-packed assets. I am also looking to see if the client IDs can be changed by sending an event to the server, without having to restart each process - though this feature may have to wait for a future release.\nAs @nponeccop says, we'll re-look at the issue of gzipping once 0.8 is released and stable.\nComments/suggestions on the proposed changes welcome.\nOwen\n. I've made a commit today which implements the changes I proposed (minus the CDN / function change which I will commit soon).\nThis is important as several users are reporting problems deploying their apps to Nodejitsu as the asset build process was causing the deployment to time out. This will no longer happen if you're running on the latest code.\n@plievone Just to be clear I really want to implement gzipping of assets too - I'm just wanting to wait until this is stable in Node 0.8. The moment we start implementing shell based solutions we will break our existing 100% compatibility with Windows. As for your other points - thanks, I will take them on board. I do know we have an issue with jQuery CSS pointing to image files in the wrong place. This needs to be addressed for jQuery UI too.\n. Hi @drosen0 \nIt's possible, but SocketStream prints a few lines out explaining that it's trying to find assets and even states that assets can be repacked with SS_PACK=1, so hopefully this will avoid any confusion.... but point taken.\n. Thanks. I am keen to add zlib support in the near future.\nIncidentally I can confirm the latest SocketStream code from master works well with Node 0.8 (at least on my Mac).\n. I've decided to put GZip support into SocketStream 0.4, along with other tweaks and enhancements in this area.\nGoing to close this now as many of the CDN changes proposed and discussed are now in 0.3.\nFeel free to open a new issue to discuss/debate further changes.\n. Yes it is. I found it useful when I wanted to test asset packing on my local machine without loading the entire production database stack.\n. Right now I'm changing asset packing in 0.4 so it will be done on a per-client basis. E.g. if you define a client called 'main' and assign this to the 'main' var and you will call main.pack(), passing any options required.\nQuite how this will fit with the idea of SS_PACK I am not sure yet. This is why there's still a lot of thinking to do.\nFeel free to suggest any other ideas (including radically different ones).\n. Hey there\nSorry, my bad. I fixed this a few hours ago in the latest commit. Please reopen if you're still having problems\n. Thanks for taking the time to put together a great pull request.\nI will merge it in now. Assuming no problems are reported it will be part of the 0.3.0 release next month.\n. Hey there\nThanks for this. I'm interested in integrating it, but I need to be sure we don't break any existing functionality. Live Reload is a tricky thing to get right. In particular, I'm keen to ensure the problem @madscoaducom had with VIM renaming files will not resurface if we use chokidar.\nTherefore, @madscoaducom, if you're able to test this and let me know it would be appreciated. I'll also test it on my Mac.\nAs for being able to pass an array of dirs to watch, this functionality is important as we typically don't want to watch the /client/workers directory. However, if you can think of a better syntax/way of expressing which directories to watch, please let me know as I'm open for changing the API.\nThanks,\nOwen\n. Thanks. Keen to look at better ways to specify the client config, but I'd like to avoid using JSON or any other type of config file (see #194).\nI agree some parts of the API feel clunky but I'm convinced we can improve upon it without having to resort to config files - we just need to find a better design. Feel free to 'think outside the box'. I'm happy to make big changes if there is a very good reason to do so.\n. Thanks guys for looking into this.\nDon't worry about the multiple commits - I don't mind merging a few in (though if you do want to submit a new pull request, I'm happy to take that).\nThe race condition has historically been a bit of an issue - though currently I have not noticed this with the current implementation on my Mac, nor have others reported any problems.\nI will test out the new changes and let you know. I'm planning to do an 0.3 RC2 release in the next few days - would be good to get this in it.\nOwen\n. @CyberWalrus I think you may be on to something with this idea... I really do. It has the potential to clean up a lot of things if it's done right. Going to have a think about how it would work in reality.\n. Hey guys\nQuick update on this. @madscoaducom sadly the patch I merged in was causing some problems when I manually renamed files in OSX. So for now I've temporarily disabled the re-watching of the file in 0.3 RC2 as the value of file was the OLD filename, not the new - causing the following error:\nfs.js:671\n    throw errnoException(errno, 'watch');\n          ^\nError: watch ENOENT\n    at errnoException (fs.js:644:11)\n    at FSWatcher.start (fs.js:671:11)\n    at Object.watch (fs.js:699:11)\n    at /Users/owen/Work/socketstream/src/client/live_reload.coffee:57:29\n    at Array.forEach (native)\n    at /Users/owen/Work/socketstream/src/client/live_reload.coffee:53:26\n    at FSWatcher.<anonymous> (/Users/owen/Work/socketstream/src/client/live_reload.coffee:61:20)\n    at FSWatcher.emit (events.js:70:17)\n    at FSEvent.onchange (fs.js:660:12)\nThe complexities of all this make me more even keener to use a library like the one @CyberWalrus suggested, although it's clear now we need to try both manually renaming files and auto renaming (as VIM does) in all major OS platforms, as well as adding and removing files.\nI hope to look into this more when I have some time.\nOwen\n. Hi @CyberWalrus \nSorry for the delay replying. I'm still very interested in this, especially as there have been more issues with the current implementation, as you have spotted.\nI will try out the latest version and encourage others to do the same.\nThanks!\nOwen\n. Hey @CyberWalrus. I'm using your patch on Mac OSX and it's looking good. No problems so far.\nWould really love it if someone can confirm it's working on Linux (I know you're on Windows). If so, I'll put this in 0.3.0\n. Ah great news!\nUnless any other problems are encountered I will put this patch in 0.3.0\n. Thanks for your help @CyberWalrus\nI may review things again when everyone's on Node 0.8 (as I'm hoping file watching maybe a little easier), but for now this is the best solution.\n. Hey Jay\nI was getting that error too on a previous release, but only when renaming a file - not on the startup. I also disabled the code causing it in the latest RC2 code I put out a few hours ago.\nCan you try that and let me know if you still have a problem.\nCheers,\nOwen\n. Hmm how strange.\nI deleted my local repo and cloned it afresh from Github to see if there was a error, but everything worked find - no problems. That's on OS X.\nThe only thing I can think is that you're running it from Dropbox. It could be that the file watchers (which observe changes) are causing problems with the Live Reload code which does the same.\n. Hi there\nSorry for the delay replying. I'm really keen to make sure we have good support (and documentation) for Passport as I love the concept; however I have not had chance to use it as yet.\nCan you let me know if you managed to find a workaround? If not I will try to have a look.\n. Hi all\nGoing to close this for now, but please reopen if you're still having problem. The best long term solution to this is a \"receipe\" on our website showing how to integrate Passport with SocketStream 0.4.\n. Thanks. This does look interesting. I'm afraid I don't have the time to make and maintain a new module at the moment, but feel free to do this yourself and I'll add a link in the Readme.\n. Hi there.\nI have not seen this error before. Please can you tell me more about what you did before it occurred. \nPlease also make sure you're running the latest 0.3 RC2 release.\n. Hey Davis\nCan you let me know where you are with this now and if you still need help?\nBtw I am aware that the Jade/Hogan mix is confusing. I am thinking about making Jade templating (using https://github.com/socketstream/ss-clientjade) the default in the next major release but I want to work with it some more before I confirm that.\n. Closing this now as I believed we resolved it over IRC. Please reopen if this is not the case\n. Hi there\nI've not seen this error before and can't think what it could be off hand. If you're still having problems please let me know what OS you're using as the FS Watcher works very differently on Linux and OS X\n. Cool, thank you.\nJust to let you know, we're likely going to be using a module soon to handle file change detection. See #227\nIt would be great if you could try that patch before I make the final decision to include it in 0.3.0\n. Ah yes, the temporary files created by VIM are causing similar problems.\nTry pulling from https://github.com/CyberWalrus/socketstream.git then run npm link again\n. I've decided to integrate the patch from CyberWalrus. It's now in the latest master.\nI've also updated the Live Reload documentation to deal with the issue of temporary files created by VIM.\nTo help me keep track of problems I'll close this issue now, but please open a new one if you continue to have problems with the latest code.\n. Hi there\nPrinting out the stack trace in the browser and terminal (without crashing the server) is the desired behaviour during development - however we do need to take a thorough look at logging and make it possible to hide/surpress different errors in production. This is still a big item on the todo list.\n. Hey there\nSorry for the delay replying.\nJust trying to see how this would work in practice and, also, if it would break any existing apps out there. Can you provide a few examples and show what this change would achieve?\nThanks\n. Thanks for the example. I see what you mean now.\nNote that ss.client.define() only defines what assets the client should contain - it doesn't influence any routing.\nAll routing at the moment is just done by an EventEmitter. It works (for the most part as you've noticed), but I've never felt totally happy with this approach. It's interesting you mention mapleTree. It came up in the latest Node Up podcast and I thought it sounded interesting.\nI'd like to take a look at it properly and see if we could use this rather than rolling our own. This would not stop people using Express Router or other routering libs if they wish; but hopefully it would provide more power out of the box for the simple HTTP routing needs SocketStream tries to address.\nWould be interesting to hear your thoughts on this.\n. Thanks. Glad you're liking it :)\nRegarding the router, point taken. I'll investigate the possibilities here a little more and let you know.\n. Hey. Just trying this out now...\nI created a new client called 'test' and routed it with:\njavascript\nss.http.route('/test', function(req, res) {\n  res.serve('test');\n})\nWhether I call\nhttp://localhost:3000/test/subpath\nor \nhttp://localhost:3000/test?name=matthias\nor even\nhttp://localhost:3000/test/something/else?name=matthias\nThey are all correctly resolving to 'test' without this patch. Am I missing something?\n. Ah I see the problem now - I was testing this whilst still having a route to '/' defined. The problem only shows up if you don't define a route for '/'.\nThanks for explaining everything in detail. I've tried this and I can reproduce the problem and see how the patch fixes it; hence I will merge the pull request. I will also add another commit after running make build which converts the CS files into JS so the changes take effect.\nJust to let you know, I'm still not feeling happy about using an EventEmitter as the routing mechanism - it just feels wrong, so I hope to play with ultra-lightweight solutions in the future (such as MapleTree) to see if they would be a better fit for SocketStream 1.0.\n. Hey there\nSorry for the delay getting to this.\nThis is an interesting idea. I am certainly wanting SocketStream to be used in really large scale projects, so I can see the value in doing this. That said, the potential bandwidth savings must be balanced with the additional code complexity (and performance implications of calling an event emitter each time something changes in UniqueSet).\nRather than trying to replace what's there (at least for now); I think it would be worth putting this code into a separate module which could be included in your app.js with:\nss.publish.transport.use(require('redis-demultiplexed'))\n(or whatever you decide to call it). You would still need to patch unqiue_set.js for now, but if you fancy making it into a module I'll happily test it on my projects and try to see if I can identify any problems.\nThanks very much for the idea + code.\nOwen\n. Hey @timothyjoelwright \nI have given this a bit more thought. I am pondering taking out Redis pub/sub support in the next release of SocketStream (0.4) altogether to allow people to roll their own solutions.\nReplicating the current behaviour of multiplexing events would be trivial (4-5 lines of code in your app); but I agree with you that larger installations (which SocketStream is really targeted at) will want to ensure only the bare minimum of traffic flows between Redis and each SocketStream server. The exact implementation of this will depend upon the app's design.\nJust a thought at the moment, but I welcome your thoughts.\n. Interesting findings with regards to PubNub and Pusher!\nRight now the pubsub transport in 0.3 is completely modular and the API is frozen, so people could already make a module for RabbitMQ or ZeroMQ or anything else, should they wish.\nWhat I'm really getting at is: is this the best approach?\nMaybe for small/medium scale apps, but for really large scale apps (the ones I want to build), I think it would be best to make the app subscribe to individual Redis channels and then use ss.publish.channel() to push these events to the relevant clients in the most efficient way possible.\nThis would allow you to send messages over Redis (or ActiveMQ, or whatever) in the best message format for your app, which may not even be JSON at all.\nIt's just a thought at the moment. Need to do more real world testing before I make a decision here. Opinions welcome.\n. Exactly. Pretty much decided to remove Redis as a dep now, especially as some folks are having problems deploying their apps to NodeJitsu because of the hiredis dependency.\nHowever, Redis will continue to be a great fit for SocketStream and I will include full instructions on how to use it as a session store or pub/sub transport. The only real difference is that you will add it as a dependency to your app, rather than it being a dependency of SocketStream.\n. Hmm ok. I'm thinking of using the https://github.com/paulmillr/chokidar library as recommended and implemented by @CyberWalrus in pull request #227\nI'd appreciate it if you can give it a go and see if it fixes some of these issues. I will also try and replicate the problems you're having.\n. Hi there\nI've decided to integrate the chokidar lib based upon successful testing by myself and others. The new code is now in master.\nI'll close this issue now, but please open a new one if the new code is giving you problems.\n. Thanks for spotting\nDespite very carefully trying to update and publish things in the right order it seems an earlier version was pushed to NPM - a little confusing though as I downloaded the .tgz file after publishing it a few days ago and it appeared to be correct.\nPlease can you check and confirm for me just so I know I'm not going mad!\n. Thanks. I'm having similar bizarre caching issues too on the Mac. I have looked in all the obvious places but an old version seems to be lurking somewhere....\n. Thanks so much!\nI will merge this in now. I'll go over ii, try it out, and maybe make some slight amendments before adding it to the readme index.\n. Great. Thank you!\n. Hmm interesting. This ties in with another problem. Right now if you want to use Node Cluster in production (as you would) it means ss.client.packAssets() is called multiple times.\nRight now it is scriptable/programable so there are ways around it - but I'm looking at other approaches, possibly using the server side event bus: ss.events.emit('client:assets:rebuild') or something like that.\nThoughts welcome \n. Not yet you can't, but I'm working on this now to see if this can be made possible - and to generally decouple the packing of assets with the use of assets to better enable scaling/clustering/cdn support.\n. Just to let you know, I made some changes in 0.3 to allow for better CDN support.\nIn 0.4 you will call pack() on each individual client, allowing you to create a git hook or make task to pre-pack assets before they are deployed.\nIn addition I am still keen to look at triggering a re-pack by emitting an event.\nClosing this now but expect improvements along these lines in the future.\n. I'm hoping we can have really good support for PhoneGap in SocketStream 0.4, along with a doc page explaining how to set everything up. In many ways PhoneGap is a natural fit for the single-page nature of SocketStream.\nIf anyone else has any hints or tips please share them here. I hope to have a play with PhoneGap myself soon.\n. Hmm I've not come across this before. The last comment is the most surprising as this middleware is doing absolutely nothing! Can you double confirm that you restarted the server and it was still sending two replies?\nIf so I'll try to set something similar up and see if I can replicate it.\n. Thanks, that would be appreciated. If there is anything fundamentally wrong I want to fix it before I release 0.3.0.\n. Ah I see the problem. At the end of your security.js file, on line 13, you have\n}();\nRemove the () and all should work fine.\n. No worries. Glad it's fixed for you :)\n. Hi there\nHaving not heard of any similar problems to this I tried to reproduce the example above as closely as possible, but didn't see any problems. The session saved correctly.\nAre you using the default in-memory session store? If possible try using the Redis session store and then monitor redis on the command line with redis-cli and then type monitor. This will allow you to see exactly what is being stored.\n. Hey\nJade will get installed when you run npm install in the project directory you have just created. You can verify this by looking for ss-jade in the package.json file the installer created.\nss-jade depends on Jade which will be automatically installed.\nRegards,\nOwen\n. Closing this now, reopen if you still have a problem\n. No tutorial yet but checkout Issue #200\n. I have recently tried Express 0.3 with SocketStream and it works well.\nPlease follow the code example on www.socketstream.org/tour which has been updated with code which will work well on 2.5 & 3.0. Any problems let me know.\n. No, sorry. There used to be some cookie get/set methods in SocketStream but I took them out in an attempt to keep the client-side code as lean as possible. There are many jQuery plugins which will help you do this.\n. Ah right. No, that's not possible. Just store anything you need in the session object\n. Hi there\nIf I understand right, this is possible already by accessing ss.http.middleware which is basically the connect app and calling ss.http.middleware.append() or ss.http.middleware.prepend() on it and adding your own middleware.\nYou can access the connect module directly with ss.http.connect.\nLet me know how you get on.\n. Exactly as @nponeccop  says. An ss.rpc request, or any request over the websocket, is not a HTTP request and shouldn't have access to the HTTP request/response object.\n. Technically it would be possible to give you access to Socket.IO meta data when you're using that transport; but I don't want to implement this because:\n1. SocketStream would no longer be 100% websocket transport agnostic as it is now\n2. The websocket transport should be completely independent of the HTTP request and may not even be on the same domain (e.g if you were to use Pusher Pipe or a PubNub backend)\n3. In SocketStream 0.4 we will be moving to Engine.IO which I'm pretty sure will not allow you access to the cookies.\nSo overall you are much better storing session-related info in the user's session (req.session) rather than the cookies. If you really really want to use cookies, read them using JavaScript on the client-side and send the contents over an RPC request to the server.\nOwen\n. Thanks for reminding me. Was going to do this before 0.3.0 was released, but as I'm now trying to do more iterative commits, I've done this now.\nI've already done some testing with Node 0.7 and basically all works well apart from the Live Reload which I will look into. Please pull the latest commit and let me know if you have any problems\n. So far all working well from my initial testing, apart from Live Reload (which is now using chokidar 0.2.6) on my Mac. Not looked into this yet. @CyberWalrus, do you have any ideas?\n. Cheers guys. Looks like this is a know issue in the release I was trying. Will keep an eye on this.\n. I can confirm there are no problems with Live Reload on the Mac using Node 0.8.0.\n. Closing this now as many users are now running 0.8 successfully \n. Hey David\nThanks. I know this was an issue but the last commit I made today should fix this, though I haven't had time to test and confirm (was planning too tomorrow).\nThe problem was first noticed by a poster on the Google Group a few days ago and my reply was as follows:\n``` code\nThanks for letting me know. I can reproduce the bug.\nUpon investigation I see it occurs because more recent versions of Node.js clear require.cache when the REPL is launched. In this case, the cached variable formatters.byExtension has been cleared, so SocketStream is unable to handle incoming '.jade' requests.\nThis appears to be a known issue: https://github.com/joyent/node/issues/3226\nAs for the solution... I'm not sure yet. I'm going to dig into it more. If anyone knows more about this issue, please get in touch.\nFor now, it would be best to stop using ss-console until this is resolved  - hopefully very soon.\n```\nThe change I made today abandoned replying on modules to cache their content - which seems like the safest bet for now.\nCheers,\nOwen\n. Hey David\nYup, we had the same issue with template formatters. Fixed it in the same way. Please give the latest commit a go and let me know how you get on.\nOwen\n. Hi there\nExample code is shown on slide 7 of http://www.socketstream.org/tour\n. Wow great info, thanks!\nIf the match origin protocol is exposed as a config option (either now or on the future) you will be able to change it from your app.js file by configuring SocketIO.\nI'd be interested to see how SockJS performs with SSL too.\nOwen\n. Hi there\nSorry it's a bit confusing at the moment as the latest release on NPM is not compatible with Node 0.8. I hope to fix this shortly by releasing 0.3.0 on both github and npm.\nFor now create the new project as you did before, but instead of typing sudo npm install type sudo npm link socket stream instead, then  sudo npm install to get Jade/Stylus/etc.\nThat will tell npm to use to the latest SocketStream version you checked out, not the one on npm.\nCheers,\nOwen\n. Thanks for this!\nTotally agree upon the idea in principal. I just need to try this out myself and make sure it's the best way to implement it in practice.\nOn a related note, I've been hoping for a while it will be possible to share middleware between SocketStream Request Responders (like RPC) and Connect, as they use the same format. This would be very handy for authentication middleware.\nHowever, getting the load order right is critical as an app must define its HTTP middleware (which maybe written in CoffeeScript etc) before SocketStream starts up (which is when the middleware is currently loaded)...\nI'll give it all more thought and let you know the outcome. Thanks again,\nOwen\n. Thanks for spotting. Fixed\n. Hi there\nSorry for the short delay. I wanted to figure out what had changed before I merged this in. Here's the culprit:\nhttps://github.com/senchalabs/connect/commit/0915c26fb2e08113cb1e9b4dae88a424a758fd6d\nThanks for contributing \n. Cheers. Will check this out and try to reproduce.\n. Can you provide an example?\nMost of the time an exception should kill the server (in development mode) and print a stack trace. If you're not using Redis to store session data, the session will be lost.\n. Hi there. Going to close this now as no one else has reported this. Please re-open if it reappears.\n. Hi Davis\nI'm almost certain this relates to #256 as I can see several references to sess:s in your Redis monitor output.\nI haven't come across either of these problems on my mac, and nobody else has reported anything so I was planning to delve into sometime this week and try to figure out what's going on.\nI'm guessing it has something to do with upping the Connect or Connect Redis dependency version - but that's just a guess at the moment.\n@jcrugzz perhaps you can help? What setup are you using that caused you to have the  sess:s issue? Are you running the latest SocketStream master code?\nDefinitely want to get to the bottom of this before I release 0.3.0.\nTip: Before you upgrade from RC2 to master, sudo rm -fr your node_modules directory to make sure all the deps get fully updated. Npm has had issues in the past where deps are not updated correctly.\nThanks for any help looking into this,\nOwen\n. Yup - very well spotted. I will fix the docs. Thanks for letting me know.\n. Good suggestion. Thanks\n. Hey\nSure, that's the plan. Not sure when I'll get chance to do it, but hopefully soon.\nOwen\n. Hey there\nTried to look on the URL but I can't see anything.\nDoes the chat demo work fine for you locally? \nOwen\n. Hmm sounds like it, but feel free to pop onto IRC and I will help you to debug.\n. Hi there\nYes, SocketStream uses Connect, so you can only extend the HTTP layer with Connect or Connect-compatible middleware (as used in FlatIron). This also enables us to easily support Express.\nSadly integrating BinaryJS (which looks very interesting) would never be as simple as just plugging it in as it also makes use of the websocket. SocketStream has a way to multiplex several different kinds of message over the web socket called Request Responders but I doubt this would work with binary data. Not sure yet - I'd love to find out.\nOwen\n. Hey\nSo as you may know, SocketStream uses Socket.IO as it's default websocket transport. I've had a quick look and can see binary support was apparently added to version 0.8.5, but documentation is pretty much non-existent. If you can find any examples, please let me know.\nSo theoretically it appears to be possible. As for the implementation, I'd have to take a proper look at how best to do this. Perhaps we could create a new binary data Request Responder? I'm not sure yet.\nWhat sort of data are you interested in sending?\n. Yes it can, though Socket.IO is the default and most mature / well tested. It would be worth looking to see if binary support is possible in SockJS - I haven't had chance to do that yet.\n. Hi there\nYou make a good point and hit on something which is currently confusing in SocketStream 0.3, something which I hope to fix in 0.4:\nRight now when you create a new project with Jade (socketstream new -j myproject) you get a .jade file in chat/messages.jade but this is only interpreted by Jade on the server, it has nothing to do with client-side templating. Hence you can use a .jade file to generate the HTML before it is sent to Hogan, or any other templating engine.\nThe ss-clientjade module you refer to was kindly contributed by a user and allows you to use Jade in the browser as a client-side templating language, doing away with the need for Hogan. I forked the module a while back to help the author upgrade to a new module format but have not been keeping it up-to-date, nor do I have the ability to publish it to npm. I have deleted my fork to avoid confusion.\nTo be honest I was a bit skeptical of using Jade in the browser at first, but once I got chance to use it, I found it a joy to use. So much so that I'm thinking of making Jade client-side templating the default in 0.4 when you run socketstream new -j, instead of Hogan. If this happens I will adapt ss-jade to work both on the server and client which will do away with the need for ss-clientjade altogether. Feedback welcome.\nThanks for your other thoughts. I will bear them in mind. Also note I've updated ss-jade and ss-stylus today with the latest deps.\n. Hi there\nThere is no out-of-the-box way to do this, though it's an interesting request and definitely a 'nice to have' for the future.\nThe easiest way to do this is handle it in the client. Send the req.id (which is automatically assigned and is always sequential) back in the response and disregard any out-of-order responses.\nOwen\n. Good to hear you sorted it out. I'll close this now\n. Oh dear - sounds like a file watching / polling issue with chokidar. I recently upgraded SocketStream to the latest version, which maybe the cause of the problem.\nWhen you get a moment, could you try running SocketStream using an older version of chokidar and let me know how you get on? I don't get many opportunities to test SocketStream on Windows.\n. Hi guys\nThanks for looking into this. I'd like to release SocketStream 0.3.1 this week.\nIt would be good if we could reach a consensus on either keeping chokidar 0.4.0 as is, or going back to using 0.3.0 - bearing in mind that almost everyone will now be on Node 0.8.\nOwen\n. Bah file watching in Node still sucks. If anyone could take a look at this and help improve it, it would be greatly appreciated.\nLive Reload will become a 'Websocket Service' module in 0.4. Something that you will explicitly choose to use in your app (just one line of code), however the way it works under-the-hood is essentially the same. One advantage is that it will be easier to pass more options; however I'd much rather fix the underlying issue as many apps are going to contain hundreds of images.\nIf anyone can help improve this in 0.3, I'll ensure the changes get into 0.4.\n. Sounds like a good plan @paulmillr. It will be a lot easier to pass options directly through to chokidar in SocketStream 0.4. Will look something like: https://github.com/socketstream/socketstream-0.4/blob/master/example_app/app.js#L31\n. Thanks @paulmillr \n@drosen0 please let me know if this helps. If so I'll do another release of SocketStream using chokidar 0.5 and document how to deal with large numbers of images.\n. Hi @drosen0\nPlease can you let me know if this helped. If I don't hear anything in a few days, I will presume it did and close the ticket. Cheers\n. Hey\n1. Sure. If you can submit a pull request that turns this line into a regexp that would be great: https://github.com/socketstream/socketstream/blob/master/src/client/formatters/html.coffee#L16\n2. Not just at the moment but I'm hoping 0.4 will be able to inject the tags automatically in the right place (putting the JS at the bottom), doing away with the need for the  tag altogether. Not sure yet - it's just an idea I need to test out.\n. Closing now. Thanks\n. Can you please run make build before submitting.\nThis is exactly why I'm moving to vanilla JS in 0.4 :)\n. Thanks!\n. Done. Thank you\n. Thanks!\n. Hi there\nCommitting node_modules to the repo is seen as a good idea to many: http://www.mikealrogers.com/posts/nodemodules-in-git.html\nHowever, I'm happy to take this pull request as personally I prefer to keep my project repos lightweight and deploy using npm pack.\n. Hmm maybe.. not sure about this as I have plans to link the docs with live comments and more in the future.\nRight now it's really easy to contribute by forking master, adding/changing docs, and submitting a pull request.\n. Oh I see. Thanks!\nThis does look interesting. I'll check it out\n. Thanks.\nWhere exactly do you mean?\n. Agreed this is confusing. I still this there is a lot of work todo around this area to make everything feel cleaner.\nI'll bear it in mind. Thank you\n(btw this is exactly the sort of feedback I like to hear as it's really difficult for me to approach things as a new user)\n. I think client_app.js is too long, maybe init.js instead.... I don't know - it all sounds a bit unclean.\nI think I need to think the whole thing through a bit more, but thanks for offering.\n. Hi there\nRight now this is how it works - you just get one argument and it's an array of all the params.\nBut I agree with you that it should work in exactly the same way as it does when calling a RPC method from /server/rpc or from the browser.\nThere maybe a reason why I didn't do this this, but I can't remember off hand. I'll have a look and see if we can change to this behaviour in 0.3.1. It would mean breaking people's existing unit tests, but I think it would be worth it for the long term.\nCheers,\nOwen\n. Decided to leave this as it is in 0.3, but will fix in 0.4. Need to redesign the entire testing interface for this anyway to enable every Request Responder to be tested, not just RPC.\nThanks for pointing it out.\n. Thanks for letting me know. I believe there maybe an issue here with Safari. I am away this week, but I will test as soon as I get chance.\nIf anyone else is experiencing this, or can post any more info, please let me know.\n. Hey there\nJust done a quick Google and it looks like it maybe related to this: http://stackoverflow.com/questions/9930671/safari-3rd-party-cookie-iframe-trick-no-longer-working\n. Ah good. Looks like this is a known issue with Safari and third-party cookies.\nI'll close this issue now, but if you think of anything I can do with SocketStream to improve matters, let me know.\n. Thanks for this. I am away this week, but will take a look when I return.\n. Hi there\nJust add it to your view file manually, before or after the SocketStream tag.\nOwen\n. Totally agree. Don't worry - this confusion will go away in 0.4 as we will make a distinction between configuring the library and configuring the instance.\n. Thank you!\n. I agree. Good point.\nIf you fancy having a crack at this I'd gladly merge it in; otherwise I'll add it to the TODO list.\nBasically we need to change the logic here:\nhttps://github.com/socketstream/socketstream/blob/master/src/http/index.coffee#L92\nso that we parse the URL request, isolate the extension, and pass every request to the static handler (by calling next()) if it is for a .jpeg, .png, etc. \n. Hi there\nSo my general feeling towards this is that I don't want to complicate the SocketStream code with server-side template support at all. There just isn't a need for it.\nIf you want to show the app's version, just get that data over a standard RPC request and display it on the screen. The only reason to support server-side template rendering is for search engines, but I've already decided not to prioritise SEO as 99% of all SocketStream apps require a user to login to do anything useful.\nOf course you can always use Express to render server-side templates, which can be useful for parts of your app which really need SEO support (like an About page or such like).\nCheers,\nOwen\n. Thanks! :)\n. Hey @leostera \n0.4 will allow you to pack assets offline, and (hopefully) write code which responds to asset packing events. I've not written that bit yet, but that's the plan.\nUntil then, Paul's suggestion is a good one.\n. Hey there\nIt should all work right out of the box.\nThis thread may help: https://groups.google.com/forum/?fromgroups=#!topic/socketstream/GI-7PPTAWyA\nIf not, let me know and I'll investigate further.\nOwen\n. So sadly things have changed in the very latest version of Express within the last few weeks. Consequently the code on the website no longer works.\nThe immediate fix is to swap the stack order around:\napp.stack = ss.http.middleware.stack.concat(app.stack);\nBut this is an ugly fix and I don't like it. The root of the problem is that middleware can be difficult to work with when you need to combine one array with another.\nThere is a discussion going on in our Google Group about a better way to do this. One option, maybe for 0.4, is to put all the middleware your app needs into your app.js file, which although ugly, would make it easier to see where things are going wrong.\nSuggestions (from anyone) welcome. I will return to this after LXJS in a few days time.\n. I've updated http://www.socketstream.org/tour with a new example for Express 3.0 now it's out.\nI'm still really unhappy with the idea of concatting arrays of middleware - it's way too messy and likely to break again in the future. I will try to come up with something better for 0.4\n. Hmm we can do. It would have to be sent before any scripts which use templates, but that is doable.\nAny particular reason you don't like the code in the head tag?\n. Agreed. Spoke about this on the newsgroup too. For 0.4 I'd like any dom elements to output to the HTML view and all other code to go into a seperate JS file, auto loaded before everything else, and then packed into the same main .js file as everything else.\n. Thanks Shaun\nWas going to get this out tonight but you beat me to it :) Working on a new Readme intro, so I'll push that later on, bump the version number on that, and push to npm.\n. So at the moment you either need a cookie already set on the browser, or the ability for the client to set a cookie using JS (which is how the ss-sockjs transport adapter works).\nWhen you say mobile client, do you mean mobile Safari/Chrome, or accessing SocketStream via a native app?\n. Hi there\nThe lack of a session object is going to be the biggest problem here, particularly how it relates to secure authentication.\nAs SocketStream 0.3 is not designed to work with any other than a normal web browser, I'm going to close this ticket. As for future versions, if we can easily provide a client library which uses a documented protocol, we will. This is definitely the best approach to take - but it will mean having to rethink a lot of things around cookies/authentication/sessions.\n. Thanks Paul. Looks like it should be simple to fix. Will take a look after LXJS.\n. So right now put your module in your client code folder as you would normally, and require() it inside your server code.\nThis works, but feels a bit ugly as you need to have crazy paths. A suggestion for 0.4 has been to create a /shared folder in addition to /client and /server; something which I'm actively considering.\n. Thanks :) Going to close this for now but making it easier to share code in 0.4 is a top priority\n. I don't believe so, and certainly not a standard way we'd need to support across multiple transports. You're best getting it from the server.\n. Ah that's in interesting idea to treat each client as a portable component. Hmm... worth some more thought. Thank you!\n. Hi\nTJ changed the connect.sid cookie format between releases. This means any existing session id cookies won't work. If you start a new session in the browser you will be fine.\nOwen\n. Ah ok. So you'll need to upgrade Express to a later version too as the change was made in Connect and both Express and SocketStream need to be looking at the same cookie id for session sharing to work.\n. Hi Paul\nThe idea of keeping it different was to ensure you could control SocketStream independently to Express, or maybe logic in your own app.\nDo you (or anyone else) see any reason to change this that I've missed?\n. Yeah... On balance I think it would be worth going with NODE_ENV in 0.4. I'll make sure SS_ENV works too.\n. Ah yes, sorry. The connect.sid cookie format changed a while back. I updated socket.io but not ss-sockjs. My bad.\nPlease can you pull the latest version of ss-sockjs from github and confirm all works well. If so, I will release this to npm.\n@paulbjensen please can you make the same change to ss-engineio\nNote I'm trying to take this low-level stuff out of the transport adapters in 0.4\n. Exactly what Paul says.\nAt the moment your /server code is running in the same thread. This is good for speed, but means once the module is loaded, it's cached and can't be changed.\nUltimately I'd like to see us support multi process dev environments again, like we did in 0.2, but this mustn't be at the expense of the simplicity we have now. \n. Closing this for now. If I find a really nice way to do this in 0.4 I will.\n. Hi there\nDoes this work correctly when in development? If so this is clearly a bug and I will try to fix.\n. Agreed. We should have 100% the same behaviour between dev and prod modes.\nIf you fancy looking into this and submitting a pull request, that would be fantastic. Otherwise I'll add it to the todo list and look at it after RealtimeConf\n. Hey. Can you tell me why you'd want to do this? Changing the cookie will break all compatibility with Express/Connect so it's not something I want to encourage.\n. Hey there\nSorry for the delay replying - I've been away on vacation.\nGoing to keep things as they are for now in 0.3, but may change the way we integrate with Express in 0.4. Either way, thanks for the pull request :)\n. Thanks for spotting! Reminds me of http://www.mrc-cbu.cam.ac.uk/people/matt.davis/Cmabrigde/ :)\n. Hey. I like where you're going with this. Not had chance to check it out, but will do before I merge it in as it's a big change to a critical function which must work correctly on each branch otherwise users will abandon SocketStream before having chance to try it out.\n. Hi @rngadam \nI'm going to close this now as I only want to make minimal changes to 0.3 from this point on. However, there are a lot of good ideas here, some of which I will carry through to 0.4 (which I'm now able to resume working on full time).\n. Agree. I'm putting the script loading code at the bottom of the page in the new experimental code for 0.4: https://github.com/socketstream/socketstream-0.4\n. Thanks for letting me know. Odd though as the /server/rpc directory has been created, there just isn't any files there.\nI can't think of any quick, clean fix for this (making a dummy data file in /server/rpc feels wrong) so I'll leave this for now as all my attention is on 0.4. If you can think of any easy way round this, please let me know.\n. Hey there!\nSorry for the delay replying.\nHmm this sounds very odd. Never heard of this problem before.\nI would recommend monitoring the traffic over Redis (with redis-cli and then monitor) to see what's going on. Feel free to paste the logs in and I'll take a look.\nOwen\n. Hey!\nThanks for submitting this. I agree the convention is wrong for Angular, however I can't accept your pull request as it would break existing sites in production which use Angular.\nThe place to fix this properly is in 0.4. Thanks for flagging it up.\nOwen\n. Hi there\nI'm happy to take a pull request if you'd like to research this and suggest a fix. But for now I'm going to close this as I don't really see it as a bug to be fixed.\nOwen\n. Hey. This sounds like a good idea. Will investigate further for 0.4\n. Thanks!\n. There is no 'official way' as yet but I did try using http://jamuhl.github.com/ and found that worked well. You can always put your .json files (one for each language) in your static folder and load them via an AJAX call.\nCould you also do this over the WS? I guess so. Would there be any advantage? Not really. Sending large files over the WS is almost never worth it as it will block any other requests.\nMy plan for 0.4 documentation is to include a 'Recipe Area' full of articles like \"How do I use Redis with SocketStream?\" and \"How do I add i18n to my app\" with code examples which point you in the right direction.\n. Thanks Paul\n. Interesting idea. It doesn't look as pretty as a closure, nor is it as easy to type, though I can see why it would be faster and more memory efficient.\nWithout thinking it through too much or testing, from what I can see, this pull request would break existing behaviour? \nI don't want to do that for 0.3, but happy to see if we can come up with a better RPC file format for 0.4.\n. Hey there\nSorry for the delay getting back to you. I have been considering this :)\nI've decided to keep everything as it in in 0.3. However, even though 0.3 RPC code must be compatible with rts-rpc, the module which will provide this functionality in 0.4, I will look into ways to making the code more memory efficient. If it's not possible, I'm already planning to release a much improved RPC solution later this year and will definitely bear this in mind then.\nThanks for taking the time to do this, and apologies again for the delay responding.\nOwen\n. Hi there\nA valid issue for sure. I understand you want a list of the client IDs, but what would you expect that API to look like?\nMaybe something like ss.client.all() would return an array of clients (each an object containing an ID)?\n. Hi there\nI'm going to have to rethink quite a lot around asset packing in 0.4, but I will definitely bear this in mind when I do.\n. Agreed. We need a much better API for this in 0.4. It will come.\nThanks for posting\n. This is what I suggest for 0.4.\n1. We don't do this if you make a 'minimal' project.\n2. We make a 'How to/Recipe' doc article called something like \"How to use different config files for each environment\" and mention the different approaches, as you have done above.\n3. Possibly create a config file for each default env when you create a 'normal' project. I'm not sure about that yet.\nThe key is we shouldn't make it mandatory, but we should make it easy to learn how to implement this if you need it.\nJust to let you know, I'm playing around with Github Wiki at the moment to see if we could use this for the How to/ Recipe articles. We definitely need to find a way for the community to contribute to articles like this.\n. Agreed. SocketStream can't and shouldn't try to be all things to all people.\nMaking it fun and easy to build large-scale realtime web apps needs to be our top priority. If you choose to build your app using the project generator, i'm happy to include a basic env-based config system.\nLet's discuss specifics in the 0.4 repo\n. Agree. Coming in 0.4 for sure\n. Indeed. Please note 0.3.3 will be released shortly which will use Engine.IO instead of Socket.IO (different protocol) but there's no real reason to upgrade if you're happy with 0.3.2.\nI don't know much about websockets on IOS, but I hear Socket Rocket is a good websocket library to use.\n. Initially I was against this idea, but if you can confirm all the connection/reconnection logic still works well; I'm happy to do this and make it 0.3.3 (along with a few other changes that need to go in).\nThanks Paul\n. Thanks Paul\nI've accepted the Pull Request and decided to release 0.3.3 which will replace Socket.IO with Engine.IO as soon as I get chance to verify everything is working correctly.\n. Thanks Paul. Going to merge this now. This should hopefully form the bulk of 0.3.3 but I need to do some final testing, and integrate anything else before pushing it. Soon as I can as I'm on holiday for two weeks.\nEveryone: Please note I've decided to swap out the bundled Socket.IO with Engine.IO as it is much better in a number of ways. If for some reason you really don't want to use Engine.IO, stick with 0.3.2. which works well. However, many sites in production run SockJS. The choice is yours.\n. Hi @pilevone\nThanks for your Engine.io insights - I always appreciate it.\nI know Paul adapted ss-sockjs to make it work with Engine.io, so there may be some leftovers we don't necessarily need.\nAlso I have mixed success trying to parse the cookies from Engine.io. It seemed to work at some point then stop working. For the sake of 0.3 I'd prefer to leave things as they are right now, as I want to focus all my attention on 0.4.\nI'd really like your help around session authentication in 0.4. We have a big decision to make: Should we enable other non-browser clients (other node servers or mobile devices) to talk to a SocketStream server directly? If we do, we can't rely on cookies being present and need to find a better way to handle authentication. Or is this a lot of work for a feature many will never use... SocketStream is a web framework after all. I'd welcome your thoughts.\nOne point to note: If we don't use cookies we must modify the initial HTML sent to the client and inject a unique token into that - which kills any hope of caching the HTML as we do at the moment.\nRegards,\nOwen\n. Thanks Paul. Taking both changes here (the latter commit improves reconnection).\n. Well spotted! I tested this and confirmed it. Will be fixed in 0.3.3, coming soon\n. Agreed, this is a bug. It can only be solved by passing the port through to the framework somehow. I will remember this issue when i work on 0.4. Thanks for letting me know\n. Hi @thebadger412\nPlease follow @paulbjensen's suggestion and let us know how you get on. If this is now working for you, please close the issue.\n. Hi there\nCan you let me know where we are with this? Please close the issue if this is now working for you.\n. Hey there\nSorry for taking an age to get back to you. I was considering this request for some time, then got really busy with other work and, during the last month, 0.4 development.\nAs the first alpha version of 0.4 will be out very soon, I no longer want to make any changes to 0.3 - unless it's a critical bug or something similar.\nHowever, your elegant solution has inspired me to do something similar with 0.4. What it will be exactly, I'm not sure yet (I was working all day yesterday on the new asset builder), but rest assured I see the need to render jade file server-side and I'll make sure it's possible.\nAgain, sorry for taking so long to reply.\nCheers,\nOwen\n. Hi Krasen\nThanks so much for taking the time to make an app and give me this feedback. I have read it all and agree with many of your points.\nAs you can imagine, deciding what should live in the framework, and what in the app, is probably the hardest decision I have to make. However, a lot of clarity has come from my work with 0.3 and really thinking hard about what SocketStream 0.4 should be.\nYou will see some big changes coming in 0.4. I also want the framework to do more (including many of the points you mentioned above), but do so with a lot less magic. Instead everything will be API driven and optional wherever possible.\nFor example, I agree a config system would be useful. But no one in the Node community can agree which is best (a bit like templating!). So my plan is to offer one as part of SocketStream, but it would be an optional API - you won't have to use it.\nThe only downside to the approach is there will be slightly more code in app.js. However one of the main things I've learned over the last 12 months is that more code is not necessarily a bad thing. Sometimes keeping things more verbose makes this easier to understand, debug and interchange at a later date.\nIf you're on IRC sometimes it would be good to chat further. I'd love to have you involved in the development of 0.4 in some way.\nThanks again,\nOwen\n. Thanks\n. Thanks for the offer, but it's not worth it for now as most of my effort is now going into 0.4. There i will be using JSHint throughout.\n. Hey Krasen\nI've not been able to replicate this because the caching is handled on the client. So even though each new request to the server would return new content, if you call\njs\nss.load.code('/test', function() {\n    require('/cached.js');\n});\nmultiple times it should never call the server more than once. Are you seeing something different?\nI'm going to change the syntax for packing assets in 0.4. It feels really messy in 0.3, mostly because I changed the behaviour late in the day to support pre-processing and caching of asset files.\nCheers,\nOwen\n. Thanks Krasen\nI see what you mean now. I'll merge this in and look though it again to make sure I can't see any obvious reason why this won't work out as expected. If all is well, it will be included in 0.3.3 which I'm going to release very soon.\nThanks again,\nOwen\n. Hi there\nPlease paste in the code of the server.remoteFunction\n. Hi there. Closing this for now, but if you're still having problems please paste the entire contents of your /server/rpc code into a Gist so it's more easily readable and I'll happily take a look\n. Cool. Thanks for letting me know. Will try and make this possible in 0.4\n. This is definitely happening in 0.4, so going to close this now.\n. Hi Paul\nLet me know if you can do the HTTP/HTTPS detection. If not I'll merge this in and have a look before releasing it.\nOwen\n. Hi there\nYou can't and shouldn't do this as visitors would just be able to alter the path and read any file from your hard drive. Just setup an explicit route or create a symlink to the file on your external hard drive.\n. Hi there\nAt the moment you will have to put this file in the templates directory. But I can appreciate that's not a great solution for you as your example is so trivial you can do it all in one file. Something to think about fixing in 0.4 for sure.\nCheers,\nOwen\n. Hi there\nThis is a good idea. Let me have a think about the exact API\n. We can't do this dynamically each time we serve the view as we want to be able to cache it in production (or on a CDN), so sending a userID is a no go.\nBut I'm all for pushing 'static' config params to the client somehow. Will bear it in mind when working on 0.4.\n. Thanks Paul for answering so quickly.\nThis sudden change in behaviour is so annoying. Looks like it won't error at all in 0.8.21 so we just need to wait this one out.\n. Hi there\nThanks for doing this, but I've decided against accepting it into the core as:\n1. there will be no more releases of 0.3 unless a major bug is found\n2. this feature is already in 0.4\nCheers,\nOwen\n. Fixed in 0.3.4 and also in 0.4. Thanks for letting me know\n. Ah right. Would you mind tracking down the x-forwarded-for header and apply this if it exists? I'll happily merge in a pull request.\nWe will get tests around all of this stuff once the APIs settle down. They would prevent annoying regressions like this.\n. Thanks Ben. I'll get this released ASAP.\nJust to let you know, I've been working on defining the new Transport and Service (Request Responder) API in 0.4 over the weekend.\nI've been looking through ss-angular to see how it works as I'd love to launch 0.4 with working ss-angular and ss-backbone modules from day one.\nI notice you currently rely on ss.rpc and (I think) ss.events in your code at present. These will be extracted out of the core in 0.4 into separate modules. Instead the new Service API will handle the callbacks, JSON serialising and (maybe, not sure yet, pubsub) for you. I've yet to figure out if we should allow one service module to depend upon another (and, if so, how to solve versioning problems here).\nI've not committed any of this new work at the moment as it's all in flux right now, but when I have something I'm happy with I'll push it to https://github.com/socketstream/socketstream-0.4. I'd be very interested to hear your thoughts.\nI'm very much looking forward to the day when the APIs settle down so we can fully test everything and prevent bugs like this one from happening.\nThanks again for your work on ss-angular. I'm determined to make sure it works even better in 0.4.\nOwen\n. Hey Ben\nApologies, I've been so engrossed in 0.4 development these last few weeks I've not been spending as much time on 0.3 issues as I should.\nYour patch looks good, but I'm always ultra-cautious when it comes to changing things like this as inevitably it will break something none of us have considered.\nAs soon as I get chance I'll try it out myself and think hard about anything which could go wrong. If all looks good I'll merge it in.\nAlso, I'll be in touch shortly regarding Angular integration in 0.4. I think I'm onto something pretty good but want to advance it a bit more before showing you.\nCheers,\nOwen\n. Hi Ben\nI'm working on Sessions support in 0.4 today and I've started thinking about the two approaches here.\n1. The client-side JS reads the session cookie and sends it over the WS (what we have today in 0.3)\n2. We try to obtain the session id server-side by looking at the HTTP headers (what we used to have in socket.io)\nWhile I agree 2 is more reliable if the transport supports it (last time I checked, SockJS doesn't), it has a big problem: it requires the client to be running in a browser.\nThe latest version of 0.4 (which I will push within the next week) has separate modules for the client and server 'realtime' components. Best of all, the client can run anywhere - on the browser, or in another Node process. Thus there is no longer any need for ss-console as you can simple connect to the server using the same client library and use a REPL to invoke RPC commands etc.\nAll this works great already - without sessions support. Figuring out how to add this is the hard part.\nI'm going to do some experimenting with ideas today and let you know. Ideally I'd like to find a secure and reliable way to do method 1 properly, even if cookies expire or don't exist at all.\nOwen\n. Hey Ben\nI've had chance to test this and I can confirm it works well. However, I'm a bit reluctant to merge this in, now that I know 0.4 will not work this way.\nAs we discussed, in 0.4 we're going to continue reading and setting cookies in the JS client. However, I will make it clear in the docs that, if you use SocketStream with Express, you will need to turn off the http only setting on the cookie. I'm hoping this is all that's needed to ensure everything works flawlessly each time.\nWould like to hear your thoughts. If you still think there's a strong case for doing a final 0.3 release which uses this code, I'm prepared to consider it. I'm just worried about significantly changing the underlying behaviour at such a late stage in the game.\nCheers,\nOwen\n. Thanks!\n. Hi there\nCan you describe why you need this? The concept of api.add() will go away in 0.4, but you'll still be able to append properties to a global object which is accesible inside your code.\n. Hi there. As we've discussed I'm not (at least at the moment) trying to make a hot-loading server, so right now there's no need/use for an api.remove() function.\n. Hi there\nI can't really answer your question but I can provide guidance which may help.\nThe future of SocketStream is more modularity, choice and independence. A lot of ideas which used to be buried deep inside 0.3 will be extracted into separate modules with their own tests in 0.4. This process has already begun (see https://github.com/socketstream/socketstream-0.4/blob/master/HISTORY.md).\nThat said, all this choice and freedom are useless if developers are left with a confusing mess. So I'm going to spend a lot more time on documentation, recipes, examples, screencasts, etc showing how everything works beautifully together.\nSocketStream will always focus 100% on single page apps; however the way you will use SocketStream and Express together will change in 0.4 which will make it easier to build a new 'normal' multi-page website and use SocketStream to deliver a numer of 'views' (e.g. add a realtime page at /admin). Also, there is also nothing to stop you generating views server-side before you pass them into SocketStream (as regular .html files).\nHowever, what I'm definitely not doing is going down the whole \"render everything on the sever first then make everything auto-magically update on the client\". Meteor and Derby both do this, but pay a big price is code speed and complexity. I have never seen the appeal of this approach as true web apps (realtime dashboards, trading terminals, flight checkers, etc - all the stuff SocketStream does well) all have signin screens, which are never going to be accessible via Google anyway.\nHope that helps\nOwen\n. Hey @pocesar \nStick with 0.3 for a few more weeks. I'm working hard to get the first 0.4 preview out by the third week in April when I'll be talking at Realtime Conf EU. Until then everything is likely to be massive flux as I'm doing a lot of re-organisation and changing APIs.\nOwen\n. No prob. 0.4 is coming on well. Expect an alpha release shortly. Closing this now.\n. Thanks so much for spotting this, and fixing it!\nIt does kinda make me realise that very few people must be using the minimal mode!\n. Hey. We can do this, but I'm not sure why you're checking for existence of all the files:\nif options.module is false and 'entry.js' not in pathAry and 'system' not in pathAry and 'shared' not in pathAry then output else wrapCode(output, pathAry, opts.pathPrefix)\nCan't we just see if options.module is set?\nCheers\n. Thanks for working out what the problem is @emgeee. There were many buggy 0.9 Node releases on the road to getting 0.10 out. Now 0.10 is out, no one should be using any 0.9 versions for anything so I'm going to close this.\n. Ah thanks for pointing this out. Normally I test pull requests before merging them in, but didn't this time. My bad.\nFixed now.\n. Thanks for the pull request. Looks correct, but sadly you need to change the corresponding coffeescript file in /src too. Sorry - I know it's a real pain. This is exactly why I stopped using CS in 0.4.\n. Thanks!\n. Hi there\nThis is correct behaviour. Like most web frameworks, SocketStream uses process.cwd() to determine the current directory, so you need to cd into that dir before running it.\nCheers,\nOwen\n. Hi Paul\nHave you seen https://github.com/nateps/connect-gzip/pull/20  ? It looks like the current library is not using Node's internal gzip but doing it's own thing, which can lead to race conditions.\nAlso, as it stands at the moment, the main HTML served would not be gzipped, only the assets (JS & CSS). Which is better than nothing, but these should (ideally) always go on a CDN anyway.\nThat said, if we could get a solid gzip implementation which doesn't introduce bugs and covers all output, I would feel happy putting it in the core.\nOwen\n. Hi Paul. It looks like the static middleware is called before the compress middleware here, in which case none of the static assets (JS and CSS files) will get compressed.\nCan you verify (by looking at the headers in the browser) and also google to see if there are any known problems using connect-compress. If all is good I'll merge it in. Thanks\n. Thanks Paul. I'll do another 0.3 release soon with this in it.\n. @paulbjensen Not sure, but I know I've not deleted anything.\n@life0fun SocketStream contains its own basic build tools (i.e. when you start it up in production it will build all the assest for you into minified files). Are you wanting something in addition to this?\n. Hi there\nI'm very certain I don't want to use requirejs for SocketStream. I've tried it before and found the CommonJS system (using Browserify) much better, not only at working with client-side code - but for sharing code between the server and the client.\n. Hey Paul\nFeel free to backport this idea from 0.4 into 0.3 if you like:\nhttps://github.com/socketstream/socketstream-0.4/blob/master/index.js#L38-L43\nYou then use the log object from within the internal code. If nothing has been attached to the 'debug' and 'info' levels then it's a (silent) noop.\nOwen\n. Ah yes. I can see what's happening here. It's looking for a .map file but we have no code formatters registered with this (like we do have with .coffee for example).\nI'll take a look as soon as I get a moment.\n. Great to see this\n. Great to see you contributing @mmalecki   Don't be shy about suggesting bigger changes.\nI don't get chance to check-in often, but every time I do I see many good things happening. Very cool :)\n. ",
    "index0h": "sorry accidentally created two issues\n. Have you any plans to integrate something like connect-form to parse post?\n. Hi,\nIn cookies could be saved config's between sessions for any pages of site\nexample: user's native language russian, but default on site is english. If user close browser (according to Session auto remove) -> language = english\nwhith cookies language still russian for any pages of the site\n. Hi there.\nYou are right, custom cookies are not needed. Maybe it's just my habit, as php programmer))\n. sorry accidentally created two issues\n. Have you any plans to integrate something like connect-form to parse post?\n. Hi,\nIn cookies could be saved config's between sessions for any pages of site\nexample: user's native language russian, but default on site is english. If user close browser (according to Session auto remove) -> language = english\nwhith cookies language still russian for any pages of the site\n. Hi there.\nYou are right, custom cookies are not needed. Maybe it's just my habit, as php programmer))\n. ",
    "kyokpae": "Hi Owen,\nI'm almost certain that subscribing to private channel won't do the work since it will bind my session (not socket) to the channel. After reading lib/backend/session and lib/frontent/subscribe I understand that subscribing to a private channel is done with @session.channel.subscribe and that links a session to that channel. Since session may span across multiple tabs any event published to that channel will reach all the tabs. This is the behavior that I see when using socketstream.\nYou understand me corerctly. What I'm aiming at is targeting individual tabs, even though they may be logged as same user. Main reason is that the same user may want to have couple of tabs open within the same session with several different UI components - each of them subscribing to a different set of events. With current code - we'd need to have a event demultiplexer on the client side - so that tabs themselves filter out events they're not really interested in. What my change allows to achieve is to have a demultiplexer on the server side.\nI'm also fine with user hitting the refresh button and getting assigned different socket for that new tab. That's fine. If I want to target session I'll use current functionality which works great for this purpose.\nI am using this in my personal project where in each tab I can setup different UI and it works great, plus it reduces amount of outgoing server traffic. Parts of the code I stripped out but are needed to utilize this functionality are of course server side demultiplexer and custom server method so that tabs can subscribe to events of their choice. I wanted to keep the change as small so that it doesn't affect any of your plans for ss development.\nSo what do you think about all this? Commit is quite small and I believe that interesting things can be built on top of it.\nTell me what your thoughts are.\nPS When do you come to Dublin. Any chance that before 23th? I'm on holiday afterwards and it would be great to meet again.\n. Thanks :)\n. perfect!\n. I'll update the pull request in the evening.\n. I'm not sure that routing via Redis is needed at this layer. Other socket stream processes don't need to know about sockets owned by some other individual process. Maybe what this patch lacks is this server-side demultiplexer (that subscribes to redis events on behalf of browser tabs) and some method on client-side to make tab observing some event e.g. SS.events.on({event:'NAME', thisTabOnly: true}, ....)\n. can't wait to see the next release then : ) cheers!\n. it seems like this patch didn't make it into 0.2.2? : >\n. worrying no more. thanks\n. Hi Owen,\nI'm almost certain that subscribing to private channel won't do the work since it will bind my session (not socket) to the channel. After reading lib/backend/session and lib/frontent/subscribe I understand that subscribing to a private channel is done with @session.channel.subscribe and that links a session to that channel. Since session may span across multiple tabs any event published to that channel will reach all the tabs. This is the behavior that I see when using socketstream.\nYou understand me corerctly. What I'm aiming at is targeting individual tabs, even though they may be logged as same user. Main reason is that the same user may want to have couple of tabs open within the same session with several different UI components - each of them subscribing to a different set of events. With current code - we'd need to have a event demultiplexer on the client side - so that tabs themselves filter out events they're not really interested in. What my change allows to achieve is to have a demultiplexer on the server side.\nI'm also fine with user hitting the refresh button and getting assigned different socket for that new tab. That's fine. If I want to target session I'll use current functionality which works great for this purpose.\nI am using this in my personal project where in each tab I can setup different UI and it works great, plus it reduces amount of outgoing server traffic. Parts of the code I stripped out but are needed to utilize this functionality are of course server side demultiplexer and custom server method so that tabs can subscribe to events of their choice. I wanted to keep the change as small so that it doesn't affect any of your plans for ss development.\nSo what do you think about all this? Commit is quite small and I believe that interesting things can be built on top of it.\nTell me what your thoughts are.\nPS When do you come to Dublin. Any chance that before 23th? I'm on holiday afterwards and it would be great to meet again.\n. Thanks :)\n. perfect!\n. I'll update the pull request in the evening.\n. I'm not sure that routing via Redis is needed at this layer. Other socket stream processes don't need to know about sockets owned by some other individual process. Maybe what this patch lacks is this server-side demultiplexer (that subscribes to redis events on behalf of browser tabs) and some method on client-side to make tab observing some event e.g. SS.events.on({event:'NAME', thisTabOnly: true}, ....)\n. can't wait to see the next release then : ) cheers!\n. it seems like this patch didn't make it into 0.2.2? : >\n. worrying no more. thanks\n. ",
    "NoizeMe": "Ah, I see what you did there :D.\nWhat I tried to do is registering variables to a Jade template, similar to what I'm used to with Express.\nSo I can't register variables from the server-side code with a Jade template?\n. No, you are completely right.\nI guess it's because I'm coming from a really traditional programming background and need to get used to this new concept :).\nBut it would still be useful to get things like template inheritance.\n. Ah, I see what you did there :D.\nWhat I tried to do is registering variables to a Jade template, similar to what I'm used to with Express.\nSo I can't register variables from the server-side code with a Jade template?\n. No, you are completely right.\nI guess it's because I'm coming from a really traditional programming background and need to get used to this new concept :).\nBut it would still be useful to get things like template inheritance.\n. ",
    "MichaelWalsh": "Related to https://github.com/LearnBoost/socket.io/issues/193\n. Related to https://github.com/LearnBoost/socket.io/issues/193\n. ",
    "arboleya": "That sounds just perfect!\nAnyway, according my needs I endup using CooffeeKup for client-side templating (over jade and all the other thousands), it's just powerful and you keep coding in CoffeeScript, as you do. Feels confortable, and transparent.\nI have also made a patch of it (not committed to the author yet), aiming to separate the tempalte code from the renderer logic:\nhttps://github.com/serpentem/coffeekup/commit/f790ef6bd9218d30ccfd230d8cfbc847d9a069c7\nJade have a cleaner syntax (it's just unarguable) and some other great features, but I would definitely consider Coffeekup as an option too.\nIn the end I found Coffeekup to be more powerful, fast and tiny for focusing on the client-side.\nMy 2\u00a2\n. That sounds just perfect!\nAnyway, according my needs I endup using CooffeeKup for client-side templating (over jade and all the other thousands), it's just powerful and you keep coding in CoffeeScript, as you do. Feels confortable, and transparent.\nI have also made a patch of it (not committed to the author yet), aiming to separate the tempalte code from the renderer logic:\nhttps://github.com/serpentem/coffeekup/commit/f790ef6bd9218d30ccfd230d8cfbc847d9a069c7\nJade have a cleaner syntax (it's just unarguable) and some other great features, but I would definitely consider Coffeekup as an option too.\nIn the end I found Coffeekup to be more powerful, fast and tiny for focusing on the client-side.\nMy 2\u00a2\n. ",
    "jp-a": "Actually, the same problem occurs for Asset Templates compilation in lib/frontend/asset/templates.coffee and I would suggest making a similar addition as:\n\n30    -      jade.compile(source)()\n   30 +      jade.compile(source, {filename: \"#{SS.root}/#{path}\"})()\n\nCan you please let me know how to proceed from there:\n- Create an additional pull request?\n- Close current pull request and create another with both modifications?\n- Forget about it ;-)\nThanks.\n. Actually, the same problem occurs for Asset Templates compilation in lib/frontend/asset/templates.coffee and I would suggest making a similar addition as:\n\n30    -      jade.compile(source)()\n   30 +      jade.compile(source, {filename: \"#{SS.root}/#{path}\"})()\n\nCan you please let me know how to proceed from there:\n- Create an additional pull request?\n- Close current pull request and create another with both modifications?\n- Forget about it ;-)\nThanks.\n. ",
    "6": "Oh! I assumed the semicolon insertion was for JavaScript. Here's a simple example of where the semicolon breaks CSS for me. Say you have two files in lib/css:\na.css contains the following:\nbody { \n  border: 20px solid red;\n}\nb.css contains the following:\nbody {\n    border: 20px solid blue;\n}\nThe concatFiles function will produce the following output:\nbody { \n  border: 20px solid red;\n};\nbody {\n  border: 20px solid blue;\n};\nWhen I open this page up in Chrome 15, Firefox 6.0.2, and Safari 5.1.1, I get a red border.\n. Oh! I assumed the semicolon insertion was for JavaScript. Here's a simple example of where the semicolon breaks CSS for me. Say you have two files in lib/css:\na.css contains the following:\nbody { \n  border: 20px solid red;\n}\nb.css contains the following:\nbody {\n    border: 20px solid blue;\n}\nThe concatFiles function will produce the following output:\nbody { \n  border: 20px solid red;\n};\nbody {\n  border: 20px solid blue;\n};\nWhen I open this page up in Chrome 15, Firefox 6.0.2, and Safari 5.1.1, I get a red border.\n. ",
    "rednaxus": "yup, works now, great stuff!\n. Hi, definitely an issue for me, i have lots of images in our app, so when they're all in, the development mode goes into 150% cpu utilization (unusable)!  (MacOS, latest SS 0.3.2, chokidar 0.4.0, nodejs 0.8.12)\nEven with moderate numbers of images, the CPU utilization keeps going up pretty dramatically, in the 25% range, which is still usable, once it gets to the 100% range can't use it, so i disable liveReload\nChanging the chokidar setting options.interval to 1000 puts it back in the 33% range, which is a little slow on startup, but sort of usable, at 500ms it's running 66%\n. @drosen0, ok, done... tested 0.3.0 chokidar on MacOS, same result 160% CPU.... too bad\nNote.. I have lots of image files (>1000), so you may not see the same results\n. hi Owen, testing chokidar 0.5.0 on mac, not a significant improvement, sorry (160% cpu)... SS 0.3.2, is there something else i should be setting to check this?\n. hi Paul, giving a look at this, I'm not sure I see where you detect the kind of server it is... if http it should be secure:false, if https, should be secure:true\n. i just hacked something, like whenever it's https it has a key/certificate, that kind of stuff, if you look closer at the http and https objects they'll have something a little more obvious\n. yup, works now, great stuff!\n. Hi, definitely an issue for me, i have lots of images in our app, so when they're all in, the development mode goes into 150% cpu utilization (unusable)!  (MacOS, latest SS 0.3.2, chokidar 0.4.0, nodejs 0.8.12)\nEven with moderate numbers of images, the CPU utilization keeps going up pretty dramatically, in the 25% range, which is still usable, once it gets to the 100% range can't use it, so i disable liveReload\nChanging the chokidar setting options.interval to 1000 puts it back in the 33% range, which is a little slow on startup, but sort of usable, at 500ms it's running 66%\n. @drosen0, ok, done... tested 0.3.0 chokidar on MacOS, same result 160% CPU.... too bad\nNote.. I have lots of image files (>1000), so you may not see the same results\n. hi Owen, testing chokidar 0.5.0 on mac, not a significant improvement, sorry (160% cpu)... SS 0.3.2, is there something else i should be setting to check this?\n. hi Paul, giving a look at this, I'm not sure I see where you detect the kind of server it is... if http it should be secure:false, if https, should be secure:true\n. i just hacked something, like whenever it's https it has a key/certificate, that kind of stuff, if you look closer at the http and https objects they'll have something a little more obvious\n. ",
    "aliasone": "I believe this is a socket.io issue related to something in here\nhttps://github.com/LearnBoost/socket.io/issues/193\nhttps://github.com/LearnBoost/socket.io/issues/493\nhttp://groups.google.com/group/socket_io/browse_thread/thread/8d6419c7edd9def8\nI've also encountered it regularly though, hoping for something that helps the problem soon.\n. hi, sure, it's an existing project on osx.\n. Hrrm, yea this is what I did initially but for some reason I get  Error: Error: Cannot find module '../../lib/server/auth'\n. Yes, thanks Troy, this worked!\n. path = require 'path'\nHere is some more info: http://nodejs.org/docs/v0.3.1/api/path.html\n. I am using Node 0.6+, also I do not need it to run inside a current socketstream project. Following the directions...\ngit clone https://github.com/socketstream/socketstream.git\ncd socketstream\nsudo npm link\nTo generate a new empty SocketStream project type:\nsocketstream new -name_of_your_project-\nThis creates a 0.2.7 socketstream project and the rest of the directions don't work. What am I doing wrong?\n. So I think what is happening is socket stream 0.3 is being installed in /usr/local/bin/socketstream and 0.2.7 is in /usr/bin/socketstream I don't want to get rid of 0.2.7 yet though so I dont want to delete that pointer. \nHow should I proceed so I can use both? \n. I believe this is a socket.io issue related to something in here\nhttps://github.com/LearnBoost/socket.io/issues/193\nhttps://github.com/LearnBoost/socket.io/issues/493\nhttp://groups.google.com/group/socket_io/browse_thread/thread/8d6419c7edd9def8\nI've also encountered it regularly though, hoping for something that helps the problem soon.\n. hi, sure, it's an existing project on osx.\n. Hrrm, yea this is what I did initially but for some reason I get  Error: Error: Cannot find module '../../lib/server/auth'\n. Yes, thanks Troy, this worked!\n. path = require 'path'\nHere is some more info: http://nodejs.org/docs/v0.3.1/api/path.html\n. I am using Node 0.6+, also I do not need it to run inside a current socketstream project. Following the directions...\ngit clone https://github.com/socketstream/socketstream.git\ncd socketstream\nsudo npm link\nTo generate a new empty SocketStream project type:\nsocketstream new -name_of_your_project-\nThis creates a 0.2.7 socketstream project and the rest of the directions don't work. What am I doing wrong?\n. So I think what is happening is socket stream 0.3 is being installed in /usr/local/bin/socketstream and 0.2.7 is in /usr/bin/socketstream I don't want to get rid of 0.2.7 yet though so I dont want to delete that pointer. \nHow should I proceed so I can use both? \n. ",
    "ianjennings": "Great to hear from you. I'm going to use socket stream on a project over winter break, and started infrastructure research this week. Really looking forward to the release and glad to hear it's on time.\n. Great to hear from you. I'm going to use socket stream on a project over winter break, and started infrastructure research this week. Really looking forward to the release and glad to hear it's on time.\n. ",
    "codemasta92": "This is Issue #111\n. This is Issue #111\n. ",
    "ghost": "I ran into this also.  The work-around is to pass in an absolute path, or better, use something like \"modname = path.resolve 'lib/server/myauth\".  Note the lack of relative directories, and note that this might depend on how the server is started.\n. What was the solution?\n. Thanks Owen, that's a good solution.\nI ended up solving this issue by saving the parameters for the request to an instance variable, then currying the original parameters i sent with the request to the callback. When the client side callback is fired from the rpc request, i check those curried paramters against the instance variable version and if they don't match, then this response is from an older request and I discard it.  This prevents old requests that return after more recent ones from affecting my results and also solves everything client side without need to pass the id from the server to the client.\n. Thanks Owen, it is a pretty large blocker for me to be able to release something when it doesn't work in Safari unfortunately.\n. On https://github.com/socketstream/socketstream/blob/master/lib/websocket/transports/socketio/index.js#L86\nsocket.handshake.headers.cookie returns undefined\nI printed just the headers and cookies is definitely not present.  Again my scenario is that my app is running in an iframe on a facebook canvas app page.\nThanks!\n. I wonder if the connect session.js middleware is failing to set the cookie, I see when its doing: \nres.setHeader('Set-Cookie', val);\nIt prints back:\nset-cookie connect.sid=s%COOKIEVALUEHERE; Path=/; Expires=Thu, 09 Aug 2012 20:13:45 GMT\nsaving\nno SID sent, generating session\nIf I inspect in the javascript console in Safari and look at cookies for my iframe'd app, no cookies exist.\n. I discovered in Safari, there is a privacy tab set to block all third party cookies which you can switch to 'Never (block)'\nThat allows my app to write cookies and work.\n. Something to do with this bug? https://github.com/LearnBoost/socket.io-client/pull/125 \n. I fixed my issue, see here: https://github.com/LearnBoost/socket.io-client/pull/125#issuecomment-7835113.\nQuick Summary:  Make sure your meta tags in your < head > come before your script tags.:\n<head>\n      <meta charset=\"utf-8\"/>\n     <SocketStream>\n     <title>Demo</title>\n  </head>\nI originally had Socketstream at the beginning and the meta tags afterwards and it caused this issue. So strange.\n. You're probably aware of this but I'm getting problems starting new projects with 0.3.6+. Tested with and without coffee/jade/etc. Apps run fine but still throw exceptions.\nTypeError: Cannot read property 'compress' of undefined\n    at /home/eric/node/test/node_modules/socketstream/lib/client/system/index.js:95:21\nand when ran with SS_ENV=production:\n! Error compiling /home/eric/node/test/client/code/app/entry.coffee into CoffeeScript\n! Error compiling /home/eric/node/test/client/code/app/app.coffee into CoffeeScript\nUncaught Exception!\n. Excellent, thank you!\n. Thank you Paul :)\n. I do verify that it is working now without error after an npm update ss-console, thanks again!\n. I ran into this also.  The work-around is to pass in an absolute path, or better, use something like \"modname = path.resolve 'lib/server/myauth\".  Note the lack of relative directories, and note that this might depend on how the server is started.\n. What was the solution?\n. Thanks Owen, that's a good solution.\nI ended up solving this issue by saving the parameters for the request to an instance variable, then currying the original parameters i sent with the request to the callback. When the client side callback is fired from the rpc request, i check those curried paramters against the instance variable version and if they don't match, then this response is from an older request and I discard it.  This prevents old requests that return after more recent ones from affecting my results and also solves everything client side without need to pass the id from the server to the client.\n. Thanks Owen, it is a pretty large blocker for me to be able to release something when it doesn't work in Safari unfortunately.\n. On https://github.com/socketstream/socketstream/blob/master/lib/websocket/transports/socketio/index.js#L86\nsocket.handshake.headers.cookie returns undefined\nI printed just the headers and cookies is definitely not present.  Again my scenario is that my app is running in an iframe on a facebook canvas app page.\nThanks!\n. I wonder if the connect session.js middleware is failing to set the cookie, I see when its doing: \nres.setHeader('Set-Cookie', val);\nIt prints back:\nset-cookie connect.sid=s%COOKIEVALUEHERE; Path=/; Expires=Thu, 09 Aug 2012 20:13:45 GMT\nsaving\nno SID sent, generating session\nIf I inspect in the javascript console in Safari and look at cookies for my iframe'd app, no cookies exist.\n. I discovered in Safari, there is a privacy tab set to block all third party cookies which you can switch to 'Never (block)'\nThat allows my app to write cookies and work.\n. Something to do with this bug? https://github.com/LearnBoost/socket.io-client/pull/125 \n. I fixed my issue, see here: https://github.com/LearnBoost/socket.io-client/pull/125#issuecomment-7835113.\nQuick Summary:  Make sure your meta tags in your < head > come before your script tags.:\n<head>\n      <meta charset=\"utf-8\"/>\n     <SocketStream>\n     <title>Demo</title>\n  </head>\nI originally had Socketstream at the beginning and the meta tags afterwards and it caused this issue. So strange.\n. You're probably aware of this but I'm getting problems starting new projects with 0.3.6+. Tested with and without coffee/jade/etc. Apps run fine but still throw exceptions.\nTypeError: Cannot read property 'compress' of undefined\n    at /home/eric/node/test/node_modules/socketstream/lib/client/system/index.js:95:21\nand when ran with SS_ENV=production:\n! Error compiling /home/eric/node/test/client/code/app/entry.coffee into CoffeeScript\n! Error compiling /home/eric/node/test/client/code/app/app.coffee into CoffeeScript\nUncaught Exception!\n. Excellent, thank you!\n. Thank you Paul :)\n. I do verify that it is working now without error after an npm update ss-console, thanks again!\n. ",
    "cberkhoff": "How did you get path? (Error: ReferenceError: path is not defined)\n. thanks\n. How did you get path? (Error: ReferenceError: path is not defined)\n. thanks\n. ",
    "drosen0": "Hi Owen,\nYes, I can confirm. Setting SS_ENV=production, the css and js are minified and packed, and the chat demo still works:\n```\nD:\\Projects\\TempSocket>set SS_ENV=production\nD:\\Projects\\TempSocket>node app\nStarting SocketStream 0.3.0alpha1-pre in production mode...\n   info  - socket.io started\nPre-packing and minifying the 'main' client...\n\u2713 Packed 2 files into /client/static/assets/main/1326661027334.css\n  Minified message.coffee from 0.315 KB to 0.237 KB\n  Minified demo.coffee from 0.581 KB to 0.442 KB\n\u2713 Packed 3 files into /client/static/assets/main/1326661027334.js\n\u2713 Created and cached HTML file /client/static/assets/main/1326661027334.html\n\u2192 rpc:1 demo.sendMessage\n\u2799 all newMessage\n\u2190 rpc:1 demo.sendMessage\n\u2192 rpc:1 demo.sendMessage\n\u2799 all newMessage\n\u2190 rpc:1 demo.sendMessage\n```\nInstallation is slightly different in Windows, since npm link is not yet supported and the shell comment (#!/usr/bin/env node) is ignored:\n```\ngit clone https://github.com/socketstream/socketstream.git\ncd socketstream\nnpm install\ncd ..\nnode socketstream\\bin\\socketstream new \ncd \nnpm install\nnpm install ..\\socketstream\n```\nCheers,\nDave\nP.S. Thank you for creating this awesome framework!\n. Never mind, it's working now with no changes. The only difference since yesterday was I restarted node app. I think the issue was unrelated to Firefox. Here's what I did:\n1. Another socketstream 0.3a2 app I have been playing with was already loaded in the browser at localhost:3000.\n2. Quit the running 0.3a2 node app.\n3. Created a new 0.3a3 chat example.\n4. Start node app on the new 0.3a3 chat example.\n5. Hit refresh in Firefox.\n6. Typing something + Enter logged only:\nrpc: x demo.sendMessage\n(but not all newMessage).\n7. Open Chrome to localhost:3000.\n8. Typing something + Enter correctly logged:\nrpc: x demo.sendMessage\n   all newMessage\n9. Subsequent refreshing and restarting Firefox did not fix the issue.\n10. Restart node app.\n11. Refresh in Firefox.\n12. Now it works correctly.\nPerhaps a cached version of the client script registered itself incorrectly with the server? Interesting that the server didn't recover from it in this case.\n. I just read your response to Dirk Dressel's question in the group, and realize this might be the cookie expiration issue.\n. Are you more concerned about the performance implication or code complexity? If performance, consider that it only happens at startup (and when client files reload).\n. I hadn't thought of regexes as complex, but I understand your concern.\n. Here's a simplified version:\ncoffee-script\nif 'libs' in pathAry\n  code\nelse if 'system' in pathAry\n  ...\nelse\n  ...\n. This code snippet doesn't support the example I had mentioned at the top ('libs0', 'libs1', ...) but thinking about it, I don't like that fuzziness anyway. This way it's clear because it simply means that 'libs' and 'system' can have subfolders.\n. Now that it's implemented in 0.3beta1, I can confirm that it works well for me.\n. This is great. The style update happens so fast, it's like editing Stylus files within Firebug or the WebKit developer tool.\n. The default behavior of an absent SS_PACK could be confusing to users, when changing files in production mode has zero effect across restarts of node. (For my use, I just check for command line options -p/--production and -c/--compile in app.js, so the default works fine for me.)\n. Oh that'll probably be fine and should avoid confusion. (Come to think of it, the default behavior will probably break my command line option check, but it's not important.)\n. In development mode, SS_PACK=1 still causes the assets to be packed. Is this intentional?\n. It's slightly less convenient to switch between modes for testing an app, as it requires toggling two environment variables. (I've needed to do this occasionally to locate an error, such as invalid syntax in an included Jade view. Sometimes the production compilation gives a better hint as to which file to look in.) I appreciate that 0.4 will have a better way to manage when assets are compiled.\n. @leostera Have you had any luck integrating with Passport yet?\nEdit: I should add that I haven't tried this yet.\n. It seems that the npm-cache folder is caching the prior version of \"socketstream 0.3.0rc2\" that I had previously npm installed from the folder of the git project. Yet I still cannot get the updated version via npm, so there must be another cache somewhere else.\n1. npm uninstall socketstream -g\n2. delete the contents of npm-cache\n3. npm install socketstream -g\n4. The package that gets installed has the old version of generate.coffee and generate.js.\nI confirmed with a diff that the file contents within http://registry.npmjs.org/socketstream/-/socketstream-0.3.0RC2.tgz and https://nodeload.github.com/socketstream/socketstream/tarball/master are identical (with the exception of .gitignore and .npmignore), and they both contain the new version of generate.coffee and generate.js.\nAssuming this is working correctly for everyone else, this might just be an issue that is unique to my installation of npm.\n(By the way, the variable name in generate.coffee is misspelled as pacakgejs.)\n. I also tried deleting the temp files in both the user profile and windows folders (between steps 2 and 3), but no change. I should mention that this is on Windows 7.\nI'd guess it's getting the correct version of the package for new users. I can test this later tonight on my wife's Mac.\n. Well, though the outcome is obvious, I confirmed that it works on a fresh install (on a Mac).\n. Looks like it's still broken after today's commit. joyent/node#3226 is two months old and hasn't had any comments, so it must not affect too many users.\n. Today's commit works for me.\n. Yes, that's it:\n- chokidar@0.2.6 - ok\n- chokidar@0.3.0 - ok\n- chokidar@0.4.0 - high CPU\n. How can I get more information about what's happening? Using Process Hacker, I can see threads within node.exe getting created every few seconds when using chokidar 0.4.0, but with 0.3.0 the number of threads remains constant. Would a nodetime profile help?\n. Just tested using node 0.8.5 (just released) with chokidar 0.4.0, and it seems that node's fs.watchFile has been optimized a bit. Now I'm seeing CPU load of 12-18%. With chokidar 0.3.0 the load sits at 0.00-0.01%.\nPart of the difference is I have a project built using SocketStream with many files being watched. If I start a new project, the CPU idles at 1.1-1.2%. Now go into the client/css folder and make a lot of copies of app.styl. With 512 copies of app.styl, the CPU hovers at 35-50%.\n. At least from my limited experience with chokidar 0.2.6 as used by SocketStream on Windows, it has been stable and reliable. I haven't tried on other platforms, but if there are no major issues, might I suggest that SocketStream use chokidar 0.3.0 until the fs.watch bugs are ironed out?\n. I'm using 0.3.0 on Windows and it seems flawless, though I can only vouch for chokidar as it is used within SocketStream. The CPU utilization of 0.4.0 is a blocker for me. But then, I could be the only one doing development on a 4 year old laptop.\n. @paulmillr I apologize that I haven't gotten to this. My free time has been limited, but also I admit that I'm not too excited to try this change.\nQuintupling the interval to 500ms, I'd expect my CPU to reduce from 15% down to 3%. That's low, but it still bothers me, since the prior version (a) uses virtually no CPU, (b) notices the changes instantly rather than at intervals, and (c) works flawlessly (for me).\nWhile it's true that no one has +1'd this issue, I'm also not aware of any chokidar-related socketstream issues reported while it was on 0.2.6.\n. @polidore I'd be interested to know whether the difference is due to the 64-bit vs 32-bit versions. Just to be sure, have you tried with a large number of watched files? I tested using a new SS project, making 512 copies of app.styl, and @paulmillr tested using 4280 files.\nWhen I get a chance, I'll test this on my wife's iMac which has nearly identical hardware specs to my 4-year-old laptop. I'll also give the options.interval change a test when I get a chance.\n. > When I get a chance, I'll test this on my wife's iMac\nOops I guess I never got around to this, but sounds like it's an issue on MacOS as well. On Windows, file watching works flawlessly (and with virtually zero CPU utilization) as long as I specify chokidar version 0.3.0 in package.json. @rednaxus can you please try chokidar 0.3.0 on MacOS?\n. Hi @paulbjensen, thank you for following up on this issue. I haven't used SocketStream in quite a long time (and also I switched development platforms), so I can't comment on whether it's fixed. I do use grunt-contrib-watch, which uses gaze. I've noticed that on Mac, some of the projects I work on do use considerable CPU while watching (it seems to be those using an older version of grunt-contrib-watch, and therefore older version of gaze; or it could be that the older projects have more files) and some do not.\n. Hi Owen,\nYes, I can confirm. Setting SS_ENV=production, the css and js are minified and packed, and the chat demo still works:\n```\nD:\\Projects\\TempSocket>set SS_ENV=production\nD:\\Projects\\TempSocket>node app\nStarting SocketStream 0.3.0alpha1-pre in production mode...\n   info  - socket.io started\nPre-packing and minifying the 'main' client...\n\u2713 Packed 2 files into /client/static/assets/main/1326661027334.css\n  Minified message.coffee from 0.315 KB to 0.237 KB\n  Minified demo.coffee from 0.581 KB to 0.442 KB\n\u2713 Packed 3 files into /client/static/assets/main/1326661027334.js\n\u2713 Created and cached HTML file /client/static/assets/main/1326661027334.html\n\u2192 rpc:1 demo.sendMessage\n\u2799 all newMessage\n\u2190 rpc:1 demo.sendMessage\n\u2192 rpc:1 demo.sendMessage\n\u2799 all newMessage\n\u2190 rpc:1 demo.sendMessage\n```\nInstallation is slightly different in Windows, since npm link is not yet supported and the shell comment (#!/usr/bin/env node) is ignored:\n```\ngit clone https://github.com/socketstream/socketstream.git\ncd socketstream\nnpm install\ncd ..\nnode socketstream\\bin\\socketstream new \ncd \nnpm install\nnpm install ..\\socketstream\n```\nCheers,\nDave\nP.S. Thank you for creating this awesome framework!\n. Never mind, it's working now with no changes. The only difference since yesterday was I restarted node app. I think the issue was unrelated to Firefox. Here's what I did:\n1. Another socketstream 0.3a2 app I have been playing with was already loaded in the browser at localhost:3000.\n2. Quit the running 0.3a2 node app.\n3. Created a new 0.3a3 chat example.\n4. Start node app on the new 0.3a3 chat example.\n5. Hit refresh in Firefox.\n6. Typing something + Enter logged only:\nrpc: x demo.sendMessage\n(but not all newMessage).\n7. Open Chrome to localhost:3000.\n8. Typing something + Enter correctly logged:\nrpc: x demo.sendMessage\n   all newMessage\n9. Subsequent refreshing and restarting Firefox did not fix the issue.\n10. Restart node app.\n11. Refresh in Firefox.\n12. Now it works correctly.\nPerhaps a cached version of the client script registered itself incorrectly with the server? Interesting that the server didn't recover from it in this case.\n. I just read your response to Dirk Dressel's question in the group, and realize this might be the cookie expiration issue.\n. Are you more concerned about the performance implication or code complexity? If performance, consider that it only happens at startup (and when client files reload).\n. I hadn't thought of regexes as complex, but I understand your concern.\n. Here's a simplified version:\ncoffee-script\nif 'libs' in pathAry\n  code\nelse if 'system' in pathAry\n  ...\nelse\n  ...\n. This code snippet doesn't support the example I had mentioned at the top ('libs0', 'libs1', ...) but thinking about it, I don't like that fuzziness anyway. This way it's clear because it simply means that 'libs' and 'system' can have subfolders.\n. Now that it's implemented in 0.3beta1, I can confirm that it works well for me.\n. This is great. The style update happens so fast, it's like editing Stylus files within Firebug or the WebKit developer tool.\n. The default behavior of an absent SS_PACK could be confusing to users, when changing files in production mode has zero effect across restarts of node. (For my use, I just check for command line options -p/--production and -c/--compile in app.js, so the default works fine for me.)\n. Oh that'll probably be fine and should avoid confusion. (Come to think of it, the default behavior will probably break my command line option check, but it's not important.)\n. In development mode, SS_PACK=1 still causes the assets to be packed. Is this intentional?\n. It's slightly less convenient to switch between modes for testing an app, as it requires toggling two environment variables. (I've needed to do this occasionally to locate an error, such as invalid syntax in an included Jade view. Sometimes the production compilation gives a better hint as to which file to look in.) I appreciate that 0.4 will have a better way to manage when assets are compiled.\n. @leostera Have you had any luck integrating with Passport yet?\nEdit: I should add that I haven't tried this yet.\n. It seems that the npm-cache folder is caching the prior version of \"socketstream 0.3.0rc2\" that I had previously npm installed from the folder of the git project. Yet I still cannot get the updated version via npm, so there must be another cache somewhere else.\n1. npm uninstall socketstream -g\n2. delete the contents of npm-cache\n3. npm install socketstream -g\n4. The package that gets installed has the old version of generate.coffee and generate.js.\nI confirmed with a diff that the file contents within http://registry.npmjs.org/socketstream/-/socketstream-0.3.0RC2.tgz and https://nodeload.github.com/socketstream/socketstream/tarball/master are identical (with the exception of .gitignore and .npmignore), and they both contain the new version of generate.coffee and generate.js.\nAssuming this is working correctly for everyone else, this might just be an issue that is unique to my installation of npm.\n(By the way, the variable name in generate.coffee is misspelled as pacakgejs.)\n. I also tried deleting the temp files in both the user profile and windows folders (between steps 2 and 3), but no change. I should mention that this is on Windows 7.\nI'd guess it's getting the correct version of the package for new users. I can test this later tonight on my wife's Mac.\n. Well, though the outcome is obvious, I confirmed that it works on a fresh install (on a Mac).\n. Looks like it's still broken after today's commit. joyent/node#3226 is two months old and hasn't had any comments, so it must not affect too many users.\n. Today's commit works for me.\n. Yes, that's it:\n- chokidar@0.2.6 - ok\n- chokidar@0.3.0 - ok\n- chokidar@0.4.0 - high CPU\n. How can I get more information about what's happening? Using Process Hacker, I can see threads within node.exe getting created every few seconds when using chokidar 0.4.0, but with 0.3.0 the number of threads remains constant. Would a nodetime profile help?\n. Just tested using node 0.8.5 (just released) with chokidar 0.4.0, and it seems that node's fs.watchFile has been optimized a bit. Now I'm seeing CPU load of 12-18%. With chokidar 0.3.0 the load sits at 0.00-0.01%.\nPart of the difference is I have a project built using SocketStream with many files being watched. If I start a new project, the CPU idles at 1.1-1.2%. Now go into the client/css folder and make a lot of copies of app.styl. With 512 copies of app.styl, the CPU hovers at 35-50%.\n. At least from my limited experience with chokidar 0.2.6 as used by SocketStream on Windows, it has been stable and reliable. I haven't tried on other platforms, but if there are no major issues, might I suggest that SocketStream use chokidar 0.3.0 until the fs.watch bugs are ironed out?\n. I'm using 0.3.0 on Windows and it seems flawless, though I can only vouch for chokidar as it is used within SocketStream. The CPU utilization of 0.4.0 is a blocker for me. But then, I could be the only one doing development on a 4 year old laptop.\n. @paulmillr I apologize that I haven't gotten to this. My free time has been limited, but also I admit that I'm not too excited to try this change.\nQuintupling the interval to 500ms, I'd expect my CPU to reduce from 15% down to 3%. That's low, but it still bothers me, since the prior version (a) uses virtually no CPU, (b) notices the changes instantly rather than at intervals, and (c) works flawlessly (for me).\nWhile it's true that no one has +1'd this issue, I'm also not aware of any chokidar-related socketstream issues reported while it was on 0.2.6.\n. @polidore I'd be interested to know whether the difference is due to the 64-bit vs 32-bit versions. Just to be sure, have you tried with a large number of watched files? I tested using a new SS project, making 512 copies of app.styl, and @paulmillr tested using 4280 files.\nWhen I get a chance, I'll test this on my wife's iMac which has nearly identical hardware specs to my 4-year-old laptop. I'll also give the options.interval change a test when I get a chance.\n. > When I get a chance, I'll test this on my wife's iMac\nOops I guess I never got around to this, but sounds like it's an issue on MacOS as well. On Windows, file watching works flawlessly (and with virtually zero CPU utilization) as long as I specify chokidar version 0.3.0 in package.json. @rednaxus can you please try chokidar 0.3.0 on MacOS?\n. Hi @paulbjensen, thank you for following up on this issue. I haven't used SocketStream in quite a long time (and also I switched development platforms), so I can't comment on whether it's fixed. I do use grunt-contrib-watch, which uses gaze. I've noticed that on Mac, some of the projects I work on do use considerable CPU while watching (it seems to be those using an older version of grunt-contrib-watch, and therefore older version of gaze; or it could be that the older projects have more files) and some do not.\n. ",
    "a0n": "Hi, with lots of help of owenb, i found what was the problem in my case.\nthe problem probably lies in node-redis and had something to do with this ticket: https://github.com/mranney/node_redis/issues/150\nthe problem was was solved but can still encounter for various reasons.\nnode-redis has a build in javascript parser and no dependencies, but in case that hiredis can be required it will use hiredis.\nyou have to manualy make sure that you either remove hiredis completely or update hiredis to the proper version for the node-redis version you're using. (in my case the HEAD)\nIt took me so long to solve this because i had a leftover node_modules folder in my home path, so updating or deleting hiredis had no effect, since an old version of hiredis was always required from ~/node_modules/hiredis.\n. Hi, with lots of help of owenb, i found what was the problem in my case.\nthe problem probably lies in node-redis and had something to do with this ticket: https://github.com/mranney/node_redis/issues/150\nthe problem was was solved but can still encounter for various reasons.\nnode-redis has a build in javascript parser and no dependencies, but in case that hiredis can be required it will use hiredis.\nyou have to manualy make sure that you either remove hiredis completely or update hiredis to the proper version for the node-redis version you're using. (in my case the HEAD)\nIt took me so long to solve this because i had a leftover node_modules folder in my home path, so updating or deleting hiredis had no effect, since an old version of hiredis was always required from ~/node_modules/hiredis.\n. ",
    "davej": "For example, the .coffee files in server/rpc/actions/, but really it's the same for any CoffeeScript file in my app. I've checked and ss-coffee is installed in the node_modules for my app and I've added it to client.formatters in app.js: ss.client.formatters.add(require('ss-coffee'));.\nAm I missing a step?\n. > Hmm how strange. Does this mean the /server/rpc/actions/demo.coffee file installed by default when you create a new project is not working (i.e. the basic chat demo doesn't work)?\nNo, the demo worked fine by default. But any changes I made to the demo.coffee didn't have any effect, so I manually compiled the .coffee files to .js files in the same directory (i.e. demo.coffee -> demo.js) and that worked fine.\n\nNote the files in /server will not auto reload if you make changes (you'll have to restart the server).\n\nYes, I realise this. I currently use nodemon and it restarts the server for me when I change a .js file but has no effect when I change a .coffee file.\n. I deleted the compiled .js files in server/rpc/actions/ and everything seems to work now.\nI have no idea why it didn't work before but I'm going to close this ticket because if nobody else is experiencing this problem then it was probably my fault.\nBy the way, my confusion was compounded by a bug in the latest version of nodemon: https://github.com/remy/nodemon/issues/56#issuecomment-3544737\n. For example, the .coffee files in server/rpc/actions/, but really it's the same for any CoffeeScript file in my app. I've checked and ss-coffee is installed in the node_modules for my app and I've added it to client.formatters in app.js: ss.client.formatters.add(require('ss-coffee'));.\nAm I missing a step?\n. > Hmm how strange. Does this mean the /server/rpc/actions/demo.coffee file installed by default when you create a new project is not working (i.e. the basic chat demo doesn't work)?\nNo, the demo worked fine by default. But any changes I made to the demo.coffee didn't have any effect, so I manually compiled the .coffee files to .js files in the same directory (i.e. demo.coffee -> demo.js) and that worked fine.\n\nNote the files in /server will not auto reload if you make changes (you'll have to restart the server).\n\nYes, I realise this. I currently use nodemon and it restarts the server for me when I change a .js file but has no effect when I change a .coffee file.\n. I deleted the compiled .js files in server/rpc/actions/ and everything seems to work now.\nI have no idea why it didn't work before but I'm going to close this ticket because if nobody else is experiencing this problem then it was probably my fault.\nBy the way, my confusion was compounded by a bug in the latest version of nodemon: https://github.com/remy/nodemon/issues/56#issuecomment-3544737\n. ",
    "bellecp": "I managed to solve it (but it looks really hackish)\nBut launching socketstream with\n\nNODE_PATH=/home/nick/socketstream-project/lib/server/ socketstream start\nthe module is found\n\n(the module file is exactly located at /home/nick/socketstream-project/lib/server/custom_auth.coffee)\n. I managed to solve it (but it looks really hackish)\nBut launching socketstream with\n\nNODE_PATH=/home/nick/socketstream-project/lib/server/ socketstream start\nthe module is found\n\n(the module file is exactly located at /home/nick/socketstream-project/lib/server/custom_auth.coffee)\n. ",
    "jcurtis": "Very understandable; I'll give 0.3 a whirl. \n. Very understandable; I'll give 0.3 a whirl. \n. ",
    "lorensr": "I'm sorry, don't know how that happened. Opened new request.\n. I'm sorry, don't know how that happened. Opened new request.\n. ",
    "raila": "I had to delete old cookies first to get\u00a0it to work.\n. Ah, good to know. I started to rename the files. I was used to the rails convention to name form files  _form.\n. I had to delete old cookies first to get\u00a0it to work.\n. Ah, good to know. I started to rename the files. I was used to the rails convention to name form files  _form.\n. ",
    "haohello": "ok, thank you. by the way, how can I contribute to this project?\n. can we use the same approach as we're dealing with the template files in a sub folder with a dash to indicate a sub folder? \n. I restarted the server and put this new app into production mode and those warnings are gone, however the code is loading pretty slow in the browser and the socket event seems not firing properly..\nI'm using a ubuntu server and this server is behind a NAT and with the port forwarding setup, well, the url for it is, http://www.yunlilai.com:8088/new\nyou have to reload twice to load this site in the chrome, in firefox it'ok to only load once to display,  i have no idea why it is pretty slow to load in the browser...\nThank you very much.\n. hi shoe, this wasn't resolved for my environment setup, as I've got the socketstream app deployed to a ubuntu vm within a windows host, basically this ubuntu vm is behind the NAT and it's too frustrating to get the socket.io working properly for this  kind of setup, for a workaround, I'm migrating the vm to a linux host and also assign a public ip address for one of the linux vms so that this public facing vm will act as a gateway (reverse proxy) for the other linux instances...\nreverse proxy in the linux world looks promising, and there are already several useful tools that we can choose from in the open source world.\n. Well, as per what we've observed,  the other bug might be caused by the newly added feature of Live Reload which seems to periodically keep the client and the server in sync, and that being said, anything you used to prepend or append to the dom element would be prepended or appended accumulatively.  \nThe following is just a code snippet of ours:\ncloud603 = require('cloud603View')\ntopBar = require('topBarView')\nmain = require('mainView')\nfootBar = require('footBarView')\nSocketStream.event.on 'ready', ->\n$(document).ready ->\n    new topBar.view\n    new main.view\n    new footBar.view\nWhile in mainView, we have the following code:\nmainSearchVw: =>\n    @closeSubViews()\n    mainSearchView = new mainSearch.view\n    @$el.append mainSearchView.$el     # here is what is causing problems when you are just sitting and watching the screen\n    @subViews.push mainSearchView\nAnd when we changed the line '@$el.append mainSearchView.$el'  to '@$el.html mainSearchView.$el', the bug is gone, and that's why we think the root cause of this bug is newly added feature of 'Live Reload'. \nHope this helps!\n. and also every two or three minutes or so, it keeps reloading everything, and all the client side event started over...\n. is there a way for us to optionally disable the live reloading?\n. I've already had such code in the server side code which handles the users' login\nreq.session.userId = ruser.userName\n           req.session.user = ruser\n           res ruser\n. I tried with the following code, but still in vain, not sure what it is really going on behind the scene\nreq.session.save (err) =>\n     console.log('Session data has been saved:', req.session)\n. hi owen, thanks for your help, the code now works pretty well.\n. Thank you owen, well I think it would be much better if we could have a socketstream best practice on how to structure the code.\n. Thanks for your prompt update.\n. has this issue been resolved in the latest release?  since I was tweaking the source code to have the socketstream work in IE 6 as described in an issue created by me\n. yeah, I really love your idea of dealing with the configurations this way, however i'm wondering in which code format are you writing such kind of module code for the server side? javascript or coffeescript?\nis there a way that I can write this code in coffeescript and be translated by socketstream automatically?\n. I think it would be great idea to have socketstream handle all coffee related code in a socketstream project,  and it'll be easier  to keep everybody on the team to keep the coding style consistent...\n. Owen, thank you for helping me clarifying this issue.  I'm trying to learn more about node.js and also about socketstream, and I hope that I can contribute to this project in some way.\n. the coffescript files are packed together and aren't minified..\ncss file isn't minified...\nthe inline coffeekup template script isn't minified..\nAlso, is there a way that I can tweak to gzip these cient side files?\n. @nponeccop \n Your code works, thank you very much, maybe you can update the relevant doc on the site www.socketstream.org\n. Thank you for your reply, I'll have a try on this, also I would like to outsource all my javascript lib files, css files and image files to a cdn network,  what is the best way to add those assets' links in socketstream?\n. yeah, that's exactly what I'm looking for,  since if I host everything myself it'll be pretty slow for the site' s visitors.\n. I replaced everything that will be in this interpolation,\n!= SocketStream\nwith a static address that was bind specifically for cdn purpose, as below\nlink(href=\"http://static.cloud603.com/styles/cloud603min.css\", media=\"screen\", rel=\"stylesheet\", type=\"text/css\")\nscript(src='http://static.cloud603.com/scripts/cloud603min.js', type='text/javascript')\ncloud603min.css contains all the css styles generated and minified by several stylus files by socketstream.\ncloud603min.js contains the js and coffee code in the app folder, libs folder as well as the code injected by socketstream.\n. Thank you Owen.\n. I'm using amplify.js to cache some key/value pairs on the client, which by now works pretty well for me,  you can check it out at their website http://www.amplifyjs.com\n. found it in the readme and socket.io wiki,  wrap it up as follows\n```\nss.ws.transport.use('socketio', {io: function(io){\n  if (ss.env == 'production') {\n      io.enable('browser client etag');\n      io.set('log level', 1);\n  io.set('transports', [\n    'websocket'\n  , 'flashsocket'\n  , 'htmlfile'\n  , 'xhr-polling'\n  , 'jsonp-polling'\n  ]);\n }\nelse{\n    io.set('log level', 4);\n    io.set('transports', ['websocket']);\n}\n\n}});\n```\n. The information that you provided is quite useful, thank you very much.\n.    var console = window.console;\n     if (!console || !console.log || !console.error) {\n        console = {log: function(){ }, error: function(){ }};\n        window.console = console;  // add this line in socket.io client js, since the console implementation included in socketstream doesn't work properly in IE 6\n      }\n. switch to the latest version of socket.io which is v0.9.3 and in the line 1617 of the client socket.io.js file,\nadd a conditional statement for IE6, and this will fix the problem I mentioned above.\n   if (typeof document.addEventListener == 'function') // test if the current browser isn't IE6\n        xhr.withCredentials = true;\n. Also, I think it would be better to include the non-minified development version of JavaScript lib files for development and pack and minify them once the production environment variable is set\n. that's an error happened when I upgraded to the latest socketstream and the generated html code was still using the old version script files cached in my cdn host.\nIt has already been resolved.\n. ok, thank you. by the way, how can I contribute to this project?\n. can we use the same approach as we're dealing with the template files in a sub folder with a dash to indicate a sub folder? \n. I restarted the server and put this new app into production mode and those warnings are gone, however the code is loading pretty slow in the browser and the socket event seems not firing properly..\nI'm using a ubuntu server and this server is behind a NAT and with the port forwarding setup, well, the url for it is, http://www.yunlilai.com:8088/new\nyou have to reload twice to load this site in the chrome, in firefox it'ok to only load once to display,  i have no idea why it is pretty slow to load in the browser...\nThank you very much.\n. hi shoe, this wasn't resolved for my environment setup, as I've got the socketstream app deployed to a ubuntu vm within a windows host, basically this ubuntu vm is behind the NAT and it's too frustrating to get the socket.io working properly for this  kind of setup, for a workaround, I'm migrating the vm to a linux host and also assign a public ip address for one of the linux vms so that this public facing vm will act as a gateway (reverse proxy) for the other linux instances...\nreverse proxy in the linux world looks promising, and there are already several useful tools that we can choose from in the open source world.\n. Well, as per what we've observed,  the other bug might be caused by the newly added feature of Live Reload which seems to periodically keep the client and the server in sync, and that being said, anything you used to prepend or append to the dom element would be prepended or appended accumulatively.  \nThe following is just a code snippet of ours:\ncloud603 = require('cloud603View')\ntopBar = require('topBarView')\nmain = require('mainView')\nfootBar = require('footBarView')\nSocketStream.event.on 'ready', ->\n$(document).ready ->\n    new topBar.view\n    new main.view\n    new footBar.view\nWhile in mainView, we have the following code:\nmainSearchVw: =>\n    @closeSubViews()\n    mainSearchView = new mainSearch.view\n    @$el.append mainSearchView.$el     # here is what is causing problems when you are just sitting and watching the screen\n    @subViews.push mainSearchView\nAnd when we changed the line '@$el.append mainSearchView.$el'  to '@$el.html mainSearchView.$el', the bug is gone, and that's why we think the root cause of this bug is newly added feature of 'Live Reload'. \nHope this helps!\n. and also every two or three minutes or so, it keeps reloading everything, and all the client side event started over...\n. is there a way for us to optionally disable the live reloading?\n. I've already had such code in the server side code which handles the users' login\nreq.session.userId = ruser.userName\n           req.session.user = ruser\n           res ruser\n. I tried with the following code, but still in vain, not sure what it is really going on behind the scene\nreq.session.save (err) =>\n     console.log('Session data has been saved:', req.session)\n. hi owen, thanks for your help, the code now works pretty well.\n. Thank you owen, well I think it would be much better if we could have a socketstream best practice on how to structure the code.\n. Thanks for your prompt update.\n. has this issue been resolved in the latest release?  since I was tweaking the source code to have the socketstream work in IE 6 as described in an issue created by me\n. yeah, I really love your idea of dealing with the configurations this way, however i'm wondering in which code format are you writing such kind of module code for the server side? javascript or coffeescript?\nis there a way that I can write this code in coffeescript and be translated by socketstream automatically?\n. I think it would be great idea to have socketstream handle all coffee related code in a socketstream project,  and it'll be easier  to keep everybody on the team to keep the coding style consistent...\n. Owen, thank you for helping me clarifying this issue.  I'm trying to learn more about node.js and also about socketstream, and I hope that I can contribute to this project in some way.\n. the coffescript files are packed together and aren't minified..\ncss file isn't minified...\nthe inline coffeekup template script isn't minified..\nAlso, is there a way that I can tweak to gzip these cient side files?\n. @nponeccop \n Your code works, thank you very much, maybe you can update the relevant doc on the site www.socketstream.org\n. Thank you for your reply, I'll have a try on this, also I would like to outsource all my javascript lib files, css files and image files to a cdn network,  what is the best way to add those assets' links in socketstream?\n. yeah, that's exactly what I'm looking for,  since if I host everything myself it'll be pretty slow for the site' s visitors.\n. I replaced everything that will be in this interpolation,\n!= SocketStream\nwith a static address that was bind specifically for cdn purpose, as below\nlink(href=\"http://static.cloud603.com/styles/cloud603min.css\", media=\"screen\", rel=\"stylesheet\", type=\"text/css\")\nscript(src='http://static.cloud603.com/scripts/cloud603min.js', type='text/javascript')\ncloud603min.css contains all the css styles generated and minified by several stylus files by socketstream.\ncloud603min.js contains the js and coffee code in the app folder, libs folder as well as the code injected by socketstream.\n. Thank you Owen.\n. I'm using amplify.js to cache some key/value pairs on the client, which by now works pretty well for me,  you can check it out at their website http://www.amplifyjs.com\n. found it in the readme and socket.io wiki,  wrap it up as follows\n```\nss.ws.transport.use('socketio', {io: function(io){\n  if (ss.env == 'production') {\n      io.enable('browser client etag');\n      io.set('log level', 1);\n  io.set('transports', [\n    'websocket'\n  , 'flashsocket'\n  , 'htmlfile'\n  , 'xhr-polling'\n  , 'jsonp-polling'\n  ]);\n }\nelse{\n    io.set('log level', 4);\n    io.set('transports', ['websocket']);\n}\n\n}});\n```\n. The information that you provided is quite useful, thank you very much.\n.    var console = window.console;\n     if (!console || !console.log || !console.error) {\n        console = {log: function(){ }, error: function(){ }};\n        window.console = console;  // add this line in socket.io client js, since the console implementation included in socketstream doesn't work properly in IE 6\n      }\n. switch to the latest version of socket.io which is v0.9.3 and in the line 1617 of the client socket.io.js file,\nadd a conditional statement for IE6, and this will fix the problem I mentioned above.\n   if (typeof document.addEventListener == 'function') // test if the current browser isn't IE6\n        xhr.withCredentials = true;\n. Also, I think it would be better to include the non-minified development version of JavaScript lib files for development and pack and minify them once the production environment variable is set\n. that's an error happened when I upgraded to the latest socketstream and the generated html code was still using the old version script files cached in my cdn host.\nIt has already been resolved.\n. ",
    "gilbert": "Fix for this is here: https://github.com/mindeavor/socketstream/tree/templates\nSummary of changes:\n1. A formatter is no longer required. If the template file extension is unrecognized, it just echos the file's contents.\n2. The template_engine file is only given html formatters. Since templates are html, there's no reason to give it other formats, such as coffeescript.\n. How about a command that detects the dependencies:\n$ socketstream deps\nThis command would do a dependency detection, then write the results to a cache file. When SocketStream sees this file, it will know what order to load the client libs.\nThe developer would only run this command when he needs to.\nRegarding the require \"rules\": I don't see this as a big deal. If you want to take advantage of SocketStream, you fit your code into a compatible structure. Require is no different.\n. Personally I think AMD is the best solution. I'm just trying to make things work out using what SocketStream already has.\n. I think some sort of dependency checking is necessary, but as others have said, it shouldn't be on each page load. The pre-flight checker seems like a good way of doing it.\nOne last question though. What's the current state of async loading in SocketStream?\n. Fix for this is here: https://github.com/mindeavor/socketstream/tree/templates\nSummary of changes:\n1. A formatter is no longer required. If the template file extension is unrecognized, it just echos the file's contents.\n2. The template_engine file is only given html formatters. Since templates are html, there's no reason to give it other formats, such as coffeescript.\n. How about a command that detects the dependencies:\n$ socketstream deps\nThis command would do a dependency detection, then write the results to a cache file. When SocketStream sees this file, it will know what order to load the client libs.\nThe developer would only run this command when he needs to.\nRegarding the require \"rules\": I don't see this as a big deal. If you want to take advantage of SocketStream, you fit your code into a compatible structure. Require is no different.\n. Personally I think AMD is the best solution. I'm just trying to make things work out using what SocketStream already has.\n. I think some sort of dependency checking is necessary, but as others have said, it shouldn't be on each page load. The pre-flight checker seems like a good way of doing it.\nOne last question though. What's the current state of async loading in SocketStream?\n. ",
    "mercuryt": "seems good, thanks\n. seems good, thanks\n. ",
    "arxpoetica": "Owen -- I've been getting this error repeatedly on an .swf file (for playing YouTube audio/video). I don't understand the message and don't know what to do with it. Halp?\n. I'm giving this a bump to remind myself of the value of some of these items\u2014I think they may actually need to happen in SS 3, and I'll be willing to work on them.\n. Yes, we have an immediate need. Right now the approach is to go to the connect/middelware layer and figure it out. So, getting into the grit of it helps, and then I could abstract it out a level.\n. That would be epic. Sorry I never got to it. :)\n. How to auth on socket.io. http://howtonode.org/socket-io-auth fwiw\n. Update on this? What was the IRC solution? I think I'm running into the same problem.\n. Might be related or not, but I figured out that ss-clientjade and ss-hogan are incompatible. But I think that might be a separate issue, and strictly a bug with the ss-clientjade wrapper...\n. Just my two cents. Removing Redis seems like a big step, so I'd like to hear what you plan on doing.\n. How so?\n. Nice.\n. Completely agree.\nAs a side note, I've been looking a lot at Sails lately. They've borrowed heavily from Rails, so they get a lot of things right in that they've already had the background to help them get started faster.\nI think we're coming from a different paradigm (different needs, different services), but there are a few things that Sails does right (even over Rails) that I think we could look at. One of them is the sort of interoperability/plug-play they give to different db/services.\nI'm in favor of decoupling Redis PubSub as a starting point, but simultaneously making official support via a plugin. It's what we were already talking about w/ 0.4, but it seems worth restating. :+1: \n. @thepian ^ just bookmarking?\n. Cool.\n. Referencing ticket #465 as there are overlapping considerations.\n. I'm noting that socket.io still depends on Redis 0.7.2 --> https://github.com/LearnBoost/socket.io/blob/master/package.json\nNot sure there's anything we can do about that or if this bug should be reopened until that dependency is updated? Should we be bugging Guillermo Rauch (or one of the other socket.io devs), for example?\n_UPDATE:_\nI just realized the latest version of socket.io (0.9.10) only includes Redis as a devdependency, so maybe just update socketstream to point to the latest socket.io version?\n. Correct.\n. mdedetrich and I were talking about something related. See this documentation for primer: https://github.com/socketstream/socketstream/blob/master/doc/guide/en/sessions.md#auto-expiring-sessions All the documentation says is how to set an expiry. We need a way to deal with expired cookies instead of SS just throwing an error while its running, a way to regenerate the session (which goes through a cookie) should the cookie expire. On Nodejitsu, for example, the standard practise is to extend the cookie (i.e. create a new one). The problem here is ss just throws the error, and there is no way to catch it and do something like (if cookie doesn't exist -> create new one).\n. keepitsimple -- why did you close this? did you figure out the prob?\n. I've been testing via Mocha and can't get .rpc to load either (it's just undefined).\nI'm not 100% sure what you did here from your description. What do you mean by \"use a plugin architecture\"? How did you get the .rpc to show up?\n. so...require('socketstream').api is defined, but not require('socketstream').api.rpc...?\nWhat were you referring to above about plugin architecture?\n. Just a little more info, I'm looking at what you did here: https://github.com/dashku/dashku/blob/master/test/server/rpc/widgetTemplate.test.js#L40\nThis test is passing?\nUpdate: I'm realizing that .rpc is a client side call (duh), and I'm trying to call them from server-side tests. Still, I'd like to do just that, so the question still stands, albeit, I'm now realizing it just might not be available. Is rpc available somehow server side? Further, how are you running the Dashku test I noted above?\n. Thanks Owen.\n. For the record, Engine.io doesn't log to the console the same as Socket.io. Haven't been able to figure out the difference, but that's just 2 cents.\n. Owen, I'll break this out into its own issue, but we might take a page from Derby, which does page caching in partials, which is a smart compromise that allows flexibility but still maintains caching for most of the HTML.\n. This is an older thread, but there's a related forum thread that's tied to this issues, so I though I'd just cross link the two: https://groups.google.com/forum/#!topic/socketstream/Uxb6vvGaBZs\n. Note related forum post: https://groups.google.com/forum/?fromgroups#!topic/socketstream/BlgJQOhvcQA\n. - 0.8 is fine, but I think we should specify this in the documentation. Help me remember?\n. Nice.\n. I think it's fine for 0.4. I found a workaround in 0.3, so I think we're good. :)\n. Hard coded.\n<link rel=\"stylesheet\" type=\"text/css\" media=\"print\" href=\"/uncompiled-css/print.css\">\n. Hi @pygy \u2014 there's definitely an effort underway to get the documentation in order. I've been extremely busy, but I plan on still working on helping out in this area. Let me know if there's any way you'd like to be involved in that effort.\n. Yes and no. It's nice to have documentation coming from a single source. The ss-documentation repo is more than just documentation, however. It's the website hosting the documentation; so maybe it's misnamed. I've gone back and forth on pulling documentation from the actual ss repo. It wouldn't be hard to do. Pros include not repeating one's self (as you pointed out) as well as conversion to static files (also you pointed out) from markdown. Disadvantages: markdown is not a complete HTML templating language, so if we decide to do something more advanced\u2014which I think we will be down the road\u2014markdown probably won't float.\nOverall, I think it's really a matter of just getting something out the door that works for now and going from there. So I think the current approach will be to just scrape the docs and convert to static from markdown.\nRE: the approach to 0.4\u2014that's a much bigger topic. If you want to open a separate ticket, we can chat about that elsewhere. :)\n. YES! I don't think I have permissions, though, ha. @paulbjensen can you add @kulicuu ?? :)\n. TOTALLY digging it. I'm feeling sheepish that I haven't been as true to my word on the documentation, so I'm totally game in shifting gears like this and using it. Thanks for doing this.\n. I 99% agree with these thoughts. Very, very good thoughts. My only minor quibble is that the next major SocketStream release ought to be 0.5, just to help us avoid confusion. But everything else is an epic YES. I'm already feeling motivated by the idea that we could just start working on 0.3 again, with the idea in mind of an eventual (epic!) 0.5 release.\nOn a personal note, this new trajectory does 2 things immediately for me:\n1. It immediately allows me to feel free to contribute back to the project on what will feel like the main course going forward (no more split, yay!).\n2. Any efforts toward documentation will be far easier to parse.\nSo, amen, and thanks for being so supportive of this direction, @paulbjensen. Also kudos to @RomanMinkin for keeping some momentum on the project with major work while things seemed to languish among the rest of us for a while. I truly believe this new direction could resurrect the project.\nIn my humble opinion, there's still not quite anything on the market like SocketStream, and if we are more deliberate and (yes!) plodding, we'll actually turn the corner faster with a better framework and (yes!) see a 0.5 release that resembles something better than imagined in a shorter time.\nUnify the project, and everyone wins.\n. (Btw, for anyone wondering, YES, I did change my username from americanyak to arxpoetica\u2014tangent, yes\u2014but I'm trying to unify my various screennames, ha.)\n. Totes McGoats!\n. Awesome work!\n. Epic.\n. Feel free to close.\n. Agreed.\n. Not to derail this ticket, but if you're going to introduce web pack into the mix, we should also seriously consider jspm.io. (Here's some reference on that: http://glenmaddern.com/articles/javascript-in-2015) I've been meaning to bring it up, regardless.\n. In theory it does all of the above, but brings ES6 into the mix...I haven't used it enough though to vouch.\n. jspm is a build tool AND a front end module handler (like browserify). More exactly, it models the behavior of NPM.\n. Sort of, yes. But it uses the NPM pattern for require.\n. My thinking is 0.4. I'm not convinced these ideas are fully vetted. There are a lot of pros and cons to the different approaches, and opinions seem to be strong on which direction to go. My sense is there's more to be said (not just by me).\n. Referencing ticket #287 as there are overlapping considerations.\n. Awesome work.\n. Very good news.\n. :+1: What are you thinking?\n. I am in favor of simplicity with extensibility versus a more robust feature. That said, there are some things a framework of this type should JUST DO. For me, a roadmap needs to start there, analyzing top priorities and features. Whittle out the nice to haves from the need to haves.\n. (Personally, I think this could most easily be done w/ Trello. I've never found GitHub to be easy to use in this regard, but if it can be done, I'd like to see it!)\n. Trello username: @roberthall\n. I did a little grooming of the Trello board. Five columns:\n| Ideas | Features | Priorities | Known Issues | In Progress |\n| ...   | ...        | ...      | ...          | ...         |\n1. Ideas: brainstorm, anything goes.\n2. Features: agreed-upon (voted?) roadmap ideas we actually intend to implement.\n3. Priorities: top features to do first.\n4. Known Issues: things that either have to happen for priorities OR things that are already in motion with socketstream.\n5. Roadmap items in progress.\nThe last two columns will be the biggest crossover with GitHub. I also added all the items from this thread that have been brought up under \"ideas.\"\nI propose we pick up where we left off with Prism, with an eye to version 0.4. The current version of SocketStream will be deprecated upon 0.4 release, but supported for a set period of time, with only major bug fixes after that period of time. Something along those lines.\nThoughts?\n. I think I was one of the voices against a rebuild in the past. Having worked a bit more on projects that advance and don't break with maintenance fixes, I'm actually more pro now with regards to building anew and maintaining an older source code.\nA caveat: I don't think we need to completely rewrite SocketStream. It's a really good library. @owenb did an excellent job at that. I think we can take existing functionality, make it more modular where necessary (don't constrain ourselves, but be reasonable), and build something better while maintaining an older code base.\nThe thing about SocketStream, there's not really another library out there right now that does what it does. It's already loosely coupled enough to allow developers to build things up the way they like, which is one of it's main strengths, imho.\nIf I could choose our direction on a roadmap, I would make a few priorities.\n- Don't go overboard on adding new features, at least for starters. Pick the most important aspects of the library that need emphasis and focus there.\n- With those priorities lets be very careful if we decouple the app. I'm all for doing that, but only if we simultaneously add documentation and demos that actually show how things go together. That can go a long way toward satisfying the requirement on \"where do I start\" for users who may come new to SocketStream\n- Lastly, lets make SocketStream an easier, more fun place to contribute. We've tried to do this in the past, and some people have made heroic efforts, but I don't think there's enough community still. It needs to be made easier and fun. Having been a long time observer, with minimal contribution (other than comments), I'm willing to make a substantive effort in this regard. On a personal note, it's never been easy for me to figure out how to fork the project, so this is the main kind of contribution effort I'm talking about.\nIt would be fantastic, @paulbjensen if you didn't feel like you were shouldering this whole thing, and it became a bit more of something with vitality that a community was lifting because it felt awesome to contribute. I'm not sure what all the secret recipe for that is, but I remain committed to this project. Maybe a bit off topic (maybe not?), but it would probably be good to try and figure out how to make that work so no one's feeling overwhelmed.\nI actually had some other thoughts kicking around in my head on this, but they've drifted off. Hopefully as we continue, I can re-up them to my conscience. :)\n. I just threw \"Better contribution documentation\" under priorities on Trello. If anyone disagrees, let me know. :stuck_out_tongue_winking_eye: \n. @paulbjensen can you turn voting on in the trello board (it's under menu > power ups). Might be valuable to see how people vote on different cards, and could help us prioritize. (I don't think voting is the ultimate say, just to be clear, but helpful, yes?)\n. @paulbjensen emailed .pub file.\n. @kulicuu I'm interested in what your saying, but it seems a bit off topic.\n. Hi people. I've been thinking about how to kick the SS dev cycle up a notch, and wondering if anyone is interested in doing some actual google hangouts/skype calls, whatever. (There's also this: https://appear.in/) If we had enough (but not too many) interested people, it might help us to coordinate efforts better.\nThoughts?\n. Cool. Lets set something official up in the New Year.\n. What time on the 4th? Might be hard for me to do...\n. The reason this is tricky is that I'm EST and I'm gone in the morning (which is prime time for you UKers). :+1: I can probably squeeze in an early AM Boston time (between 11:00 and 13:00 UTC), but after morning, I'm really only available from 18:30 UTC on.\n(This should help in conversions http://www.worldtimebuddy.com/est-to-utc-converter.)\nSorry for my limited schedule. If this proves to be too difficult to go back and forth in this thread on times, we can always put together a doodle http://doodle.com/ and try and plan ahead based on that.\n. That works great for me. :+1: \n. we can use https://appear.in/socketstream ... just \"knock\" or DM me your email (for those of you who have my email or twitter handle already) and I'll give you a room key (I locked it down). (Open to alternatives if people have preferences.)\n. @kulicuu  also go here: https://gitter.im/socketstream/socketstream\n. Hi Everyone, I'm closing this issue since we've created a more proactive process for meeting and going over roadmap. If you'd like to be on the roadmap contact list (for meeting times, notes, etc.) go ahead and leave a note here, and we'll figure out how to get contact info, etc.\n. @kulicuu @thepian @paulbjensen you guys want to try hitting another conversation any time soon? I'm on vacation next week\u2014I might be able to find some time. (If anyone thinks its useful.)\n. Just a quick note that there's been a version bump in the last day: https://github.com/Automattic/engine.io/commit/ba530a47624b1a71f05cc172d9b89e49d375d9b5\n. This is going off topic, but since you all have already, I think we need to build in something to SocketStream that allows for Express-like pages\u2014maybe this should be a feature request. But I've been thinking more and more that many applications that are single page end up needing routing that doesn't end up utilizing the web socket. Again, conversation for another thread. I'll open up a ticket and we can brain dump there.\nUpdate: see https://github.com/socketstream/socketstream/issues/488\n. :+1: \n. Sorry, @thepian somehow I missed this. Koa is probably not the right solution\u2014yet\u2014it uses generators which solves a whole host of middleware/connect issues. The problem is that Koa currently requires node 0.11.x for the --harmony flag which exposes generators to your script. And only in 0.11.x and up. So it's iffy in the present\u2014but maybe still something to look at.\nSails is a full on framework, so not applicable here. I was only referencing it as they have a very well-thought-out routing system (fully REST-ful, MVC, fleshed out routing policies, etc.) which borrows heavily from Rails. I've been tinkering with it the last few days, quite impressed with the way it handles routes and exposes sockets, which was what set off this thread in the first place.\n@paulbjensen url for vorka?\n. gotcha.\n. FYI, I'm currently digging into Koa over here: https://github.com/socketstream/ss-examples/tree/feature/ractive-example/ractive-jade-koa. I haven't pushed much up yet, but I'll continue to plug on it. I may ask for a hand and opinions soon.\n. I think that's a good idea\u2014granted that we still allow for defining clients.\n. Point me to the changes and I'll give you some opinions. :)\n. LIKE.\n. Dude. You are rocking it. :dragon:\n. Awesome. I'm going to do a Ractive.js example at some point.\n. Can someone please \u2018splain the @coveralls account?\n. Word. Thx!\n. http://semver.org/ FYI\n. So just really quick, I think we can press forward, like Paul is saying to reach 0.4. BUT.\nThe value of semver is that it gives an outward community something really predictable and reliable to look to.\n- Users will know that any 0.0.x release is just bug fixes (non-breaking),\n- Users will know that any 0.x.x release may include both bug fixes and or improvements or changes to the platform (that are non-breaking and 100% backwards compatible), and,\n- Users will know that any x.x.x release will include backwards incompatible changes or/and be a major milestone change with big enough feature changes to warrant a major release upgrade.\n(This site says it a little better: http://semver.org/)\nBut I think, since we've been talking about 0.4 forever, it makes sense to continue on that path, and after that release start using semver from there on out. (so, 0.4.x for bug fixes, 0.5.x for larger features and improvements, and 1.x.x for breaking changes, for example).\nNot to beat a dead horse, but I think there's massive value in using something people are familiar with.\n. @thepian interesting. If it's truly non breaking then 0.4 would sort of fall in step, with semver. Even so, I would keep it 0.4 for clarity.\nAs to a module, there might be one, but the change I'm proposing is only just something to agree on (or not).\n. Okay, cool. I'm gonna go ahead and call this sufficiently vetted, and close it. We can discuss further (if needed) once the next/0.4 release lands.\n. Ah, okay that's quite a trick. Makes sense to leave them as is then. I'll close.\n. @thepian I have more to say. I'm going to open a new ticket w/ a more general \"improve docs\" question.\n. @luksch tangent\u2014but out of curiosity, what are you using SocketStream for?\n. Cool.\n. I created a pull request for this. @paulbjensen (or someone) pls. review: #517 (and merge at will).\n. @thepian two things; I'm not fluent enough in the testing environment of SS to add one (sorry!), but also, #517 is not a feature for the next branch, but a hotfix on master. The idea is to help out @luksch in the short term on 0.3.\nI do plan to get up to speed on the testing environment. If you feel a test is requisite for this hotfix, feel free. Sorry I can't be of more immediate help.\n. I'll cherry pick it in. (And we can build tests around it in the next branch. win win.)\n. Just to give everyone a quick \"for example,\" I can't find anywhere that gives an installation guide for setting up SocketStream to do development work on the app itself. Fortunately, with a little trial and error I was able to figure it out on my own (npm link!). But there should be a 101 on this. I started writing it. Anyone want to modify it? Did I do it right?\n```\nDeveloping on SocketStream\nFork SocketStream on Github.\nThen install and link the forked SocketStream\ngit clone git@github.com:[your-fork]/socketstream.git\ncd socketstream/\nnpm link\n\nGenerate your app:\nsocketstream new -m [app-name]\n\n(Additional app generate options include -c if you prefer CoffeeScript, -j if you prefer Jade, and -s for Stylus or -l for Less if you prefer a CSS precompiler.)\nNext, run the following commands:\ncd [app-name]\nnpm install\n\nAnd start your app:\nnode app.js\n\n[...more to come, details on pull requests, build process, etc., etc...]\n```\nI know @kulicuu said once he was going to get me running out the gate, but I finally got around to doing it on my own...all these years... ;)\n. @thepian I'll delete the working docs branch and rebranch off of next\u2014I haven't done anything significant yet\u2014but I do plan on working with markdown.\nThis may be a useful tool for us: https://fiddle.md\nWe can take up considerations about JSDocs vs ngdocs vs something else at a later date; it's not the most important aspect of documentation, I agree.\n. updated docs branch: https://github.com/socketstream/socketstream/tree/feature/doc-updates-0.4\n. Hey\u2014so I set up a workspace on Hackpad for a collaborative place to edit docs-in-the-works.\nNaturally, the best place to have the docs is still in .md files under the /docs folder committed in this github repo. But I wanted somewhere where it would be easy to edit stuff a little more on the fly and in a collaborative way. Hackpad is pretty awesome for this kind of stuff (it's better than Google Docs, but that's another topic).\nIt's private, so if you want an invite, just let me know your email (see mine over here: https://github.com/arxpoetica) and I can add you: https://socketstream.hackpad.com/\n. @thepian good question. (I assume by joshing you're referring to linting/hinting?) To my knowledge there's absolutely nothing wrong w/ separate var declarations. I prefer them as it's more readable, less prone to mistake\u2014but I'll follow whichever convention the majority wants. :wink: @paulbjensen opinions?\n. Huh. Interesting. What do you like about it?\n. I was just thinking about this. What's your reason @thepian? I was definitely noticing that all these bots were creating a lot of noise with all the inline comments on pull requests. I suppose that's a good thing\u2014it forces us to go back and clean up unlinted code. But it also makes it hard to look for non-bot comments in pull requests. Thoughts?\n. Let me clarify. I care enormously about linting\u2014it's AS GOOD as tests for catching bugs/errors. It also gives code consistency and sanity. I was only questioning the utility of the bots. There are other techniques for linting.\nI'm fine with or without bots, just wanted to clarify what I see as the value of linting (absolutely) vs. the value of bots (maybe).\n. sounds good.\n. I appreciate moving it into its own repo.\n. that sounds fine\n. /off-topic, but the whole point of semver is not worrying about minor releases like 0.4.x\u2014do as many as needed to keep things working!\n. This appears to be the breaking change: https://github.com/socketstream/socketstream/commit/9bfdad5a84df1e3fdd74e6f2c9de697af4e06968#diff-e0f3678f754a6146e6e9109a7830a48fL96\nEssentially, init was passed ss in the past, but is now conditionally passed ss.root in the case where typeof mod is not a function.\nMost of the current template wrappers (ss-jade, ss-hogan, ss-ractive, ss-coffekup) have init set to a function, but leave the main module alone (which translates to typeof mod === 'object'), so either:\na) most of the template wrappers will need to rewrite their wrappers to access ss OR\nb) we change this back to what it was\nI admit I'm on the fence about this since the current implementation is more inline w/ the formatters API, bringing them inline. Thoughts?\nFor the time being, I'm just going to change my local ss-ractive version (since that's what I'm working off of at the moment), and wait for input.\n. (\nfor reference:\nhttps://github.com/socketstream/ss-jade/blob/master/wrapper.js#L6\nhttps://github.com/socketstream/ss-hogan/blob/master/engine.js#L7\nhttps://github.com/socketstream/ss-ractive/blob/master/engine.js#L7\nhttps://github.com/socketstream/ss-coffeekup/blob/master/engine.js#L5\n)\n. @thepian right, they're technically different. I think they should be the same/similar, though. Thoughts? I think I'd rather have a breaking change and make them the same.\n. Cool & thx. Can you add a ref. to the fix?\n. @thepian there's enough you commented here, I wonder if it should go in a separate issue?\n. Ha. Isn't that a good thing. ;)\n. @paulbjensen any clues where I should start hunting on this one?\n. Amsterdam! Off topic, but I'll be curious of your travels. (For another thread.)\n. Okay. The good news. I dug pretty deep into the SocketStream code base. I now understand way more than I did before. ;)\nThe bad news, I think Koa may be pretty incompatible w/ SocketStream. That's because SocketStream makes pretty heavy assumptions about middleware. It operates using connect() (as the default strategy) (See https://github.com/socketstream/socketstream/blob/master/lib/http/default.strategy.js#L32 and https://github.com/socketstream/socketstream/blob/master/lib/http/index.js#L171). This means SS relies heavily on app.use(function() { ... }), where Koa relies on app.use(function *() { ... }). Note the asterisk. Generators!\nI may still be wrong on this. It may actually be possible to concatenate functions with generators using Koa, but that's a bit beyond me. Still, I'm going to post a code sample (it's the ss-example I've been working on), and show you where I am, and what I think needs to happen, and see if anyone else sees any glaring \"ah-ha\" as to how to get the middleware conjoined.\nAs for this rabbit hole I've gone down, even if I don't end up completing the Koa task, it's been a huge win in terms of understanding the workings of SS. But I will definitely be sad if I can't get this working, even just as a POC.\n. Holy...nix that...I think I just got it working!\nStand by...!...\nUpdate: yes, it's working! I'll post what I've learned when I get a moment.\nHappy, happy!\n. All right, so in essence, here's how you concatenate middleware w/ Koa:\nvar app = koa();\nvar ssMiddleware = ss.http.middleware; // assignment important, since this is a getter\napp.use(function*(next) {\n    yield ssMiddleware.bind(null, this.req, this.res);\n    yield next;\n});\nThis middleware binds req and res onto the Koa this object. It's a bit of a hack, and inefficient (probably), because what's really happening isn't truly concatenated. It's more like two sets of middleware, made available to Koa. Notice also, this doesn't bind Koa back onto SocketStream. Essentially, Koa this.request and this.response are still available, but the SS this.req and this.res are also available to each Koa generator, up the line, since the middleware binds it pre-routes or pre-whatever comes after.\nAlso, it's important to note that the session is only available (in Koa routes) as the store\u2014it doesn't have the added functionality, such as _.bindToSocket, etc., because we haven't loaded it yet. That's still okay, but we just have to handle setting session.userId and delete session.userId on our own, without the SocketStream helpers. This tiny detail took me forever to figure out, which was half my trouble.\nNot perfect, but I'm satisfied. It works. It could be better. Ideally, SocketStream middleware would be made compatible w/ generators, either via a plugin, or some other methodology. I'm a little worn out on dealing w/ this problem, and since it's working, I'm going to let it stand as is for now, and start building out the rest of this app. At some point I might circle back around on this issue and see if I can create my own set of middleware that runs generators. It might take changing some of SocketStreams internals to do such, and that would mean we'd have to loosen the coupling to connect and make either a possibility. Generators or callbacks. ;)\n. @thepian any thoughts on this? ^\n. @kulicuu you might want to also see issue #539 which I opened. Different scenario, but same \u201cshared session\u201d problem. There's additional background cited in that ticket.\nI'll be watching both of these tickets closely.\n. Okay. Not sure I know the distinction. As for well-engineered, I agree. I was thinking this morning that the ss api ought to expose the session in a more meaningful way.\n. Thanks for looking at things. I've been looking at those very files too, logging and digging, etc. I feel like I'm closer to getting the mechanics. Something that I never knew before\u2014by default we're using express-session (part of the connect universe) to handle sessions. That's not necessarily a bad thing, but it's a pretty big \"oh\" and should be documented. Good news is, this situation has made me dig quite a bit to understand the guts of the machine (as you call it).\n. Can you describe the changes you made? I've had a look over. Seems like your passing options and adding a secret in various places. What additionally is going on?\n. Let me see if I'm understanding correctly. In other words, alternatively, the following is now possible:\nss.session.options = {\n    secret: 'some session secret',\n    cookie: {\n        [...settings...]\n    },\n    [...additional session settings...]\n}\nIs this correct? You've provided an API basically to alter/set the session store?\n. I see, I see.\nSO. I think the other issue I've opened is going to actually require a more robust session API. (I think.) I won't elaborate any further here, but I'll open that convo up elsewhere so we can bounce it back and forth.\nIn essence\u2014it's possible (I might be wrong) that it's currently not possible to share sessions w/ some kinds of middleware in our current set up (for example, Koa). Like I said, I'll elaborate elsewhere, so I don't take this particular ticket too far tangent.\n. I think this actually fixed my issue. It started working after I updated. See: https://github.com/socketstream/socketstream/issues/539#issuecomment-106666039\n. Looks good.\n. Note, there's just a little spring cleaning going on in this PR as well as the API secret option.\n. Interesting...\n. For the record, you can maintain immutable code without an added library: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/freeze\n. @thepian I don't disagree\u2014however\u2014currently it's not possible to hook into the middleware for the MIME type in dev mode\u2014unless I'm missing something. _Update_ I'm realizing my comment might be flippant. :P I think you might be right. So, really, this issue might be moot. I'll investigate, and offer a solution to on that google thread. And add documentation. :)\n. :+1: \n. Good idea.\n. Agreed.\n. This is great. Just to be clear, you're suggesting I use this now until or if we bake in actually async/promise functionality?\n. I'm open to other suggestions. Basically\u2014anything to avoid callback hell makes life happy. ;)\n. SocketStream uses Connect under the surface in various places. It might make sense to be more explicit about that relationship, but I'm also not sure I understand what your proposing.\n. Interesting...\n. Can you explain what you mean by \"retired\"\u2014I'm wary of this approach, since I use ss-jade (and maybe ss-engineio) regularly ... ?\n. ah gotcha. thx\n. :+1: :+1: :+1: \n. Excellent, I'll give it a try.\n. Hmm...not working. With the following definition:\ncode: [..., '../node_modules/Template/code', ...]\nI get the following error:\n! Error: /Users/[user]/Documents/workspace/[project]/client/node_modules/Template/code directory not found\nSeeing that /client/ directory still in that path...so if I try adding an extra ../ I get the following:\nCouldn't serve client main, issue=1441074633914 \nENOENT, no such file or directory '/Users/[user]/Documents/workspace/[project]/client/Template/code/template.js'\nclient=N131alA3\n    at Error (native)\n    at Object.fs.openSync (fs.js:500:18)\n    at Object.fs.readFileSync (fs.js:352:15)\n[...etc...]\nmore:\n{\"bundle\":\"js\",\"file\":\"/Template/code/template.js\",\"ext\":\"js\"}\nClues? I have a local (up to date) copy of SocketStream. If you can point me in the right direction, I can try and debug myself.\n. Okay. I'll look into it and possibly do a PR. :snowman: \n. So I'm still following the papertrail, but I was surprised to figure out that the path for finding assets is parsed from request.url at socketstream/lib/client/serve/dev.js:42-46 (as part of serveJS). In other words, it's getting parsed off the query from this string: /assets/main/VJeVNUJp.js?_=[MyTemplate]/code/template.js\nWhat's the reason for doing this? Seems a bit backward.\n. So if no. 3 is true, then it appears to be broken...but I'm still digging into that... ;)\nNot sure what you mean in no. 5. Are you saying that the query parsing is done in another way, but should really be handled by the bundler?\n. Okay, a little further down the rabbit hole. It doesn't look like the final source of the problem, but line 631 in the bundler index file is trying to do a path.join with an incomplete path part. Specifically it looks like the rel variable is not a relative path.\nSo let's say I feed the client definition a path like ../../node_modules/Template/code/template.js, the rel variable somehow comes through as just `/Tribe-Kupuna/code/template.js'. In other words:\npath.join(ss.root,options.dirs.client,rel)\ntransliterated looks like:\npath.join('/Users/[user]/Documents/workspace/[project]','/client','/Template/code/template.js')\nSo...what happened to '../../node_modules'? A little confusing. But it looks like the rel variable is coming from request.url at socketstream/lib/client/serve/dev.js:42-46 as I mentioned above. So maybe that's just a bad way of parsing the variable? Hope this is helping and not just confusing. :P\n. If I'm understanding you correctly, that would be a breaking change? I'm okay with that, but it should be documented.\n. :+1: \n. Yow. It makes sense though. When I tried to debug a few weeks ago, like I said, the path variable was all over the place. It made me wonder if there was a cleaner way of keeping track of and using paths.\n. Hmm. Maybe I've done something bad on my installation w/ nvm. I've done the first two commands above. After running the third, however (socketstream new another-app), I get:\nbash\n[1]    8163 segmentation fault  socketstream new another-app\nI'll keep digging and see what's going on.\n. Same, but 10.10.4.\n. For what it's worth, when I do nvm use 0.12.7, it starts working again. I'm thinking this must (somehow) be a system thing, and not have anything to do w/ SocketStream. But where to begin... :wink: \n. Okay. So I got my app running. Turned out I needed to update my npm dependencies, oops: http://stackoverflow.com/a/32289269/209803 Makes perfect sense.\nHowever, still not clear on why a global build of socketstream would segfault. Here's the which:\nbash\n$ which socketstream\n/Users/[user]/.nvm/versions/node/v4.0.0/bin/socketstream\nI'll keep working on that, and close the issue when I figure it out. I'm sure it's similar to the problem I had in my actual app.\n. Oh weird. Now my global socketstream is working. Strange. Maybe updating my local build tricked the system. I'm not sure what I did, but we're good. Closing.\n. agree. will solve a lot of problems not supporting backward compatibility.\n. FYI, Node 4 is the merger of io.js back into the main Node branch (io is no longer a thing). And yes, it includes lots of new goodies as well as more frequent updates (on Semver). We should definitely add Node 4 to the test suite. Actually, it's going to be a more rapid moving target. We're already on 4.2.1.\n. :+1: :+1: :+1: \n. @thepian thoughts?\n@aaroncalderon just to be clear, what version of SocketStream are you running?\n. :+1: \n. I have not seen a lot of movement on it lately, and I used to be much more active as a participant. @paulbjensen? @thepian?\nI believe @thepian is the current project lead.\n. Currently, @thepian is the only one who can invite you back in (I'm only a member, not an owner).\n. Agreed. Full steam ahead.. Owen -- I've been getting this error repeatedly on an .swf file (for playing YouTube audio/video). I don't understand the message and don't know what to do with it. Halp?\n. I'm giving this a bump to remind myself of the value of some of these items\u2014I think they may actually need to happen in SS 3, and I'll be willing to work on them.\n. Yes, we have an immediate need. Right now the approach is to go to the connect/middelware layer and figure it out. So, getting into the grit of it helps, and then I could abstract it out a level.\n. That would be epic. Sorry I never got to it. :)\n. How to auth on socket.io. http://howtonode.org/socket-io-auth fwiw\n. Update on this? What was the IRC solution? I think I'm running into the same problem.\n. Might be related or not, but I figured out that ss-clientjade and ss-hogan are incompatible. But I think that might be a separate issue, and strictly a bug with the ss-clientjade wrapper...\n. Just my two cents. Removing Redis seems like a big step, so I'd like to hear what you plan on doing.\n. How so?\n. Nice.\n. Completely agree.\nAs a side note, I've been looking a lot at Sails lately. They've borrowed heavily from Rails, so they get a lot of things right in that they've already had the background to help them get started faster.\nI think we're coming from a different paradigm (different needs, different services), but there are a few things that Sails does right (even over Rails) that I think we could look at. One of them is the sort of interoperability/plug-play they give to different db/services.\nI'm in favor of decoupling Redis PubSub as a starting point, but simultaneously making official support via a plugin. It's what we were already talking about w/ 0.4, but it seems worth restating. :+1: \n. @thepian ^ just bookmarking?\n. Cool.\n. Referencing ticket #465 as there are overlapping considerations.\n. I'm noting that socket.io still depends on Redis 0.7.2 --> https://github.com/LearnBoost/socket.io/blob/master/package.json\nNot sure there's anything we can do about that or if this bug should be reopened until that dependency is updated? Should we be bugging Guillermo Rauch (or one of the other socket.io devs), for example?\n_UPDATE:_\nI just realized the latest version of socket.io (0.9.10) only includes Redis as a devdependency, so maybe just update socketstream to point to the latest socket.io version?\n. Correct.\n. mdedetrich and I were talking about something related. See this documentation for primer: https://github.com/socketstream/socketstream/blob/master/doc/guide/en/sessions.md#auto-expiring-sessions All the documentation says is how to set an expiry. We need a way to deal with expired cookies instead of SS just throwing an error while its running, a way to regenerate the session (which goes through a cookie) should the cookie expire. On Nodejitsu, for example, the standard practise is to extend the cookie (i.e. create a new one). The problem here is ss just throws the error, and there is no way to catch it and do something like (if cookie doesn't exist -> create new one).\n. keepitsimple -- why did you close this? did you figure out the prob?\n. I've been testing via Mocha and can't get .rpc to load either (it's just undefined).\nI'm not 100% sure what you did here from your description. What do you mean by \"use a plugin architecture\"? How did you get the .rpc to show up?\n. so...require('socketstream').api is defined, but not require('socketstream').api.rpc...?\nWhat were you referring to above about plugin architecture?\n. Just a little more info, I'm looking at what you did here: https://github.com/dashku/dashku/blob/master/test/server/rpc/widgetTemplate.test.js#L40\nThis test is passing?\nUpdate: I'm realizing that .rpc is a client side call (duh), and I'm trying to call them from server-side tests. Still, I'd like to do just that, so the question still stands, albeit, I'm now realizing it just might not be available. Is rpc available somehow server side? Further, how are you running the Dashku test I noted above?\n. Thanks Owen.\n. For the record, Engine.io doesn't log to the console the same as Socket.io. Haven't been able to figure out the difference, but that's just 2 cents.\n. Owen, I'll break this out into its own issue, but we might take a page from Derby, which does page caching in partials, which is a smart compromise that allows flexibility but still maintains caching for most of the HTML.\n. This is an older thread, but there's a related forum thread that's tied to this issues, so I though I'd just cross link the two: https://groups.google.com/forum/#!topic/socketstream/Uxb6vvGaBZs\n. Note related forum post: https://groups.google.com/forum/?fromgroups#!topic/socketstream/BlgJQOhvcQA\n. - 0.8 is fine, but I think we should specify this in the documentation. Help me remember?\n. Nice.\n. I think it's fine for 0.4. I found a workaround in 0.3, so I think we're good. :)\n. Hard coded.\n<link rel=\"stylesheet\" type=\"text/css\" media=\"print\" href=\"/uncompiled-css/print.css\">\n. Hi @pygy \u2014 there's definitely an effort underway to get the documentation in order. I've been extremely busy, but I plan on still working on helping out in this area. Let me know if there's any way you'd like to be involved in that effort.\n. Yes and no. It's nice to have documentation coming from a single source. The ss-documentation repo is more than just documentation, however. It's the website hosting the documentation; so maybe it's misnamed. I've gone back and forth on pulling documentation from the actual ss repo. It wouldn't be hard to do. Pros include not repeating one's self (as you pointed out) as well as conversion to static files (also you pointed out) from markdown. Disadvantages: markdown is not a complete HTML templating language, so if we decide to do something more advanced\u2014which I think we will be down the road\u2014markdown probably won't float.\nOverall, I think it's really a matter of just getting something out the door that works for now and going from there. So I think the current approach will be to just scrape the docs and convert to static from markdown.\nRE: the approach to 0.4\u2014that's a much bigger topic. If you want to open a separate ticket, we can chat about that elsewhere. :)\n. YES! I don't think I have permissions, though, ha. @paulbjensen can you add @kulicuu ?? :)\n. TOTALLY digging it. I'm feeling sheepish that I haven't been as true to my word on the documentation, so I'm totally game in shifting gears like this and using it. Thanks for doing this.\n. I 99% agree with these thoughts. Very, very good thoughts. My only minor quibble is that the next major SocketStream release ought to be 0.5, just to help us avoid confusion. But everything else is an epic YES. I'm already feeling motivated by the idea that we could just start working on 0.3 again, with the idea in mind of an eventual (epic!) 0.5 release.\nOn a personal note, this new trajectory does 2 things immediately for me:\n1. It immediately allows me to feel free to contribute back to the project on what will feel like the main course going forward (no more split, yay!).\n2. Any efforts toward documentation will be far easier to parse.\nSo, amen, and thanks for being so supportive of this direction, @paulbjensen. Also kudos to @RomanMinkin for keeping some momentum on the project with major work while things seemed to languish among the rest of us for a while. I truly believe this new direction could resurrect the project.\nIn my humble opinion, there's still not quite anything on the market like SocketStream, and if we are more deliberate and (yes!) plodding, we'll actually turn the corner faster with a better framework and (yes!) see a 0.5 release that resembles something better than imagined in a shorter time.\nUnify the project, and everyone wins.\n. (Btw, for anyone wondering, YES, I did change my username from americanyak to arxpoetica\u2014tangent, yes\u2014but I'm trying to unify my various screennames, ha.)\n. Totes McGoats!\n. Awesome work!\n. Epic.\n. Feel free to close.\n. Agreed.\n. Not to derail this ticket, but if you're going to introduce web pack into the mix, we should also seriously consider jspm.io. (Here's some reference on that: http://glenmaddern.com/articles/javascript-in-2015) I've been meaning to bring it up, regardless.\n. In theory it does all of the above, but brings ES6 into the mix...I haven't used it enough though to vouch.\n. jspm is a build tool AND a front end module handler (like browserify). More exactly, it models the behavior of NPM.\n. Sort of, yes. But it uses the NPM pattern for require.\n. My thinking is 0.4. I'm not convinced these ideas are fully vetted. There are a lot of pros and cons to the different approaches, and opinions seem to be strong on which direction to go. My sense is there's more to be said (not just by me).\n. Referencing ticket #287 as there are overlapping considerations.\n. Awesome work.\n. Very good news.\n. :+1: What are you thinking?\n. I am in favor of simplicity with extensibility versus a more robust feature. That said, there are some things a framework of this type should JUST DO. For me, a roadmap needs to start there, analyzing top priorities and features. Whittle out the nice to haves from the need to haves.\n. (Personally, I think this could most easily be done w/ Trello. I've never found GitHub to be easy to use in this regard, but if it can be done, I'd like to see it!)\n. Trello username: @roberthall\n. I did a little grooming of the Trello board. Five columns:\n| Ideas | Features | Priorities | Known Issues | In Progress |\n| ...   | ...        | ...      | ...          | ...         |\n1. Ideas: brainstorm, anything goes.\n2. Features: agreed-upon (voted?) roadmap ideas we actually intend to implement.\n3. Priorities: top features to do first.\n4. Known Issues: things that either have to happen for priorities OR things that are already in motion with socketstream.\n5. Roadmap items in progress.\nThe last two columns will be the biggest crossover with GitHub. I also added all the items from this thread that have been brought up under \"ideas.\"\nI propose we pick up where we left off with Prism, with an eye to version 0.4. The current version of SocketStream will be deprecated upon 0.4 release, but supported for a set period of time, with only major bug fixes after that period of time. Something along those lines.\nThoughts?\n. I think I was one of the voices against a rebuild in the past. Having worked a bit more on projects that advance and don't break with maintenance fixes, I'm actually more pro now with regards to building anew and maintaining an older source code.\nA caveat: I don't think we need to completely rewrite SocketStream. It's a really good library. @owenb did an excellent job at that. I think we can take existing functionality, make it more modular where necessary (don't constrain ourselves, but be reasonable), and build something better while maintaining an older code base.\nThe thing about SocketStream, there's not really another library out there right now that does what it does. It's already loosely coupled enough to allow developers to build things up the way they like, which is one of it's main strengths, imho.\nIf I could choose our direction on a roadmap, I would make a few priorities.\n- Don't go overboard on adding new features, at least for starters. Pick the most important aspects of the library that need emphasis and focus there.\n- With those priorities lets be very careful if we decouple the app. I'm all for doing that, but only if we simultaneously add documentation and demos that actually show how things go together. That can go a long way toward satisfying the requirement on \"where do I start\" for users who may come new to SocketStream\n- Lastly, lets make SocketStream an easier, more fun place to contribute. We've tried to do this in the past, and some people have made heroic efforts, but I don't think there's enough community still. It needs to be made easier and fun. Having been a long time observer, with minimal contribution (other than comments), I'm willing to make a substantive effort in this regard. On a personal note, it's never been easy for me to figure out how to fork the project, so this is the main kind of contribution effort I'm talking about.\nIt would be fantastic, @paulbjensen if you didn't feel like you were shouldering this whole thing, and it became a bit more of something with vitality that a community was lifting because it felt awesome to contribute. I'm not sure what all the secret recipe for that is, but I remain committed to this project. Maybe a bit off topic (maybe not?), but it would probably be good to try and figure out how to make that work so no one's feeling overwhelmed.\nI actually had some other thoughts kicking around in my head on this, but they've drifted off. Hopefully as we continue, I can re-up them to my conscience. :)\n. I just threw \"Better contribution documentation\" under priorities on Trello. If anyone disagrees, let me know. :stuck_out_tongue_winking_eye: \n. @paulbjensen can you turn voting on in the trello board (it's under menu > power ups). Might be valuable to see how people vote on different cards, and could help us prioritize. (I don't think voting is the ultimate say, just to be clear, but helpful, yes?)\n. @paulbjensen emailed .pub file.\n. @kulicuu I'm interested in what your saying, but it seems a bit off topic.\n. Hi people. I've been thinking about how to kick the SS dev cycle up a notch, and wondering if anyone is interested in doing some actual google hangouts/skype calls, whatever. (There's also this: https://appear.in/) If we had enough (but not too many) interested people, it might help us to coordinate efforts better.\nThoughts?\n. Cool. Lets set something official up in the New Year.\n. What time on the 4th? Might be hard for me to do...\n. The reason this is tricky is that I'm EST and I'm gone in the morning (which is prime time for you UKers). :+1: I can probably squeeze in an early AM Boston time (between 11:00 and 13:00 UTC), but after morning, I'm really only available from 18:30 UTC on.\n(This should help in conversions http://www.worldtimebuddy.com/est-to-utc-converter.)\nSorry for my limited schedule. If this proves to be too difficult to go back and forth in this thread on times, we can always put together a doodle http://doodle.com/ and try and plan ahead based on that.\n. That works great for me. :+1: \n. we can use https://appear.in/socketstream ... just \"knock\" or DM me your email (for those of you who have my email or twitter handle already) and I'll give you a room key (I locked it down). (Open to alternatives if people have preferences.)\n. @kulicuu  also go here: https://gitter.im/socketstream/socketstream\n. Hi Everyone, I'm closing this issue since we've created a more proactive process for meeting and going over roadmap. If you'd like to be on the roadmap contact list (for meeting times, notes, etc.) go ahead and leave a note here, and we'll figure out how to get contact info, etc.\n. @kulicuu @thepian @paulbjensen you guys want to try hitting another conversation any time soon? I'm on vacation next week\u2014I might be able to find some time. (If anyone thinks its useful.)\n. Just a quick note that there's been a version bump in the last day: https://github.com/Automattic/engine.io/commit/ba530a47624b1a71f05cc172d9b89e49d375d9b5\n. This is going off topic, but since you all have already, I think we need to build in something to SocketStream that allows for Express-like pages\u2014maybe this should be a feature request. But I've been thinking more and more that many applications that are single page end up needing routing that doesn't end up utilizing the web socket. Again, conversation for another thread. I'll open up a ticket and we can brain dump there.\nUpdate: see https://github.com/socketstream/socketstream/issues/488\n. :+1: \n. Sorry, @thepian somehow I missed this. Koa is probably not the right solution\u2014yet\u2014it uses generators which solves a whole host of middleware/connect issues. The problem is that Koa currently requires node 0.11.x for the --harmony flag which exposes generators to your script. And only in 0.11.x and up. So it's iffy in the present\u2014but maybe still something to look at.\nSails is a full on framework, so not applicable here. I was only referencing it as they have a very well-thought-out routing system (fully REST-ful, MVC, fleshed out routing policies, etc.) which borrows heavily from Rails. I've been tinkering with it the last few days, quite impressed with the way it handles routes and exposes sockets, which was what set off this thread in the first place.\n@paulbjensen url for vorka?\n. gotcha.\n. FYI, I'm currently digging into Koa over here: https://github.com/socketstream/ss-examples/tree/feature/ractive-example/ractive-jade-koa. I haven't pushed much up yet, but I'll continue to plug on it. I may ask for a hand and opinions soon.\n. I think that's a good idea\u2014granted that we still allow for defining clients.\n. Point me to the changes and I'll give you some opinions. :)\n. LIKE.\n. Dude. You are rocking it. :dragon:\n. Awesome. I'm going to do a Ractive.js example at some point.\n. Can someone please \u2018splain the @coveralls account?\n. Word. Thx!\n. http://semver.org/ FYI\n. So just really quick, I think we can press forward, like Paul is saying to reach 0.4. BUT.\nThe value of semver is that it gives an outward community something really predictable and reliable to look to.\n- Users will know that any 0.0.x release is just bug fixes (non-breaking),\n- Users will know that any 0.x.x release may include both bug fixes and or improvements or changes to the platform (that are non-breaking and 100% backwards compatible), and,\n- Users will know that any x.x.x release will include backwards incompatible changes or/and be a major milestone change with big enough feature changes to warrant a major release upgrade.\n(This site says it a little better: http://semver.org/)\nBut I think, since we've been talking about 0.4 forever, it makes sense to continue on that path, and after that release start using semver from there on out. (so, 0.4.x for bug fixes, 0.5.x for larger features and improvements, and 1.x.x for breaking changes, for example).\nNot to beat a dead horse, but I think there's massive value in using something people are familiar with.\n. @thepian interesting. If it's truly non breaking then 0.4 would sort of fall in step, with semver. Even so, I would keep it 0.4 for clarity.\nAs to a module, there might be one, but the change I'm proposing is only just something to agree on (or not).\n. Okay, cool. I'm gonna go ahead and call this sufficiently vetted, and close it. We can discuss further (if needed) once the next/0.4 release lands.\n. Ah, okay that's quite a trick. Makes sense to leave them as is then. I'll close.\n. @thepian I have more to say. I'm going to open a new ticket w/ a more general \"improve docs\" question.\n. @luksch tangent\u2014but out of curiosity, what are you using SocketStream for?\n. Cool.\n. I created a pull request for this. @paulbjensen (or someone) pls. review: #517 (and merge at will).\n. @thepian two things; I'm not fluent enough in the testing environment of SS to add one (sorry!), but also, #517 is not a feature for the next branch, but a hotfix on master. The idea is to help out @luksch in the short term on 0.3.\nI do plan to get up to speed on the testing environment. If you feel a test is requisite for this hotfix, feel free. Sorry I can't be of more immediate help.\n. I'll cherry pick it in. (And we can build tests around it in the next branch. win win.)\n. Just to give everyone a quick \"for example,\" I can't find anywhere that gives an installation guide for setting up SocketStream to do development work on the app itself. Fortunately, with a little trial and error I was able to figure it out on my own (npm link!). But there should be a 101 on this. I started writing it. Anyone want to modify it? Did I do it right?\n```\nDeveloping on SocketStream\nFork SocketStream on Github.\nThen install and link the forked SocketStream\ngit clone git@github.com:[your-fork]/socketstream.git\ncd socketstream/\nnpm link\n\nGenerate your app:\nsocketstream new -m [app-name]\n\n(Additional app generate options include -c if you prefer CoffeeScript, -j if you prefer Jade, and -s for Stylus or -l for Less if you prefer a CSS precompiler.)\nNext, run the following commands:\ncd [app-name]\nnpm install\n\nAnd start your app:\nnode app.js\n\n[...more to come, details on pull requests, build process, etc., etc...]\n```\nI know @kulicuu said once he was going to get me running out the gate, but I finally got around to doing it on my own...all these years... ;)\n. @thepian I'll delete the working docs branch and rebranch off of next\u2014I haven't done anything significant yet\u2014but I do plan on working with markdown.\nThis may be a useful tool for us: https://fiddle.md\nWe can take up considerations about JSDocs vs ngdocs vs something else at a later date; it's not the most important aspect of documentation, I agree.\n. updated docs branch: https://github.com/socketstream/socketstream/tree/feature/doc-updates-0.4\n. Hey\u2014so I set up a workspace on Hackpad for a collaborative place to edit docs-in-the-works.\nNaturally, the best place to have the docs is still in .md files under the /docs folder committed in this github repo. But I wanted somewhere where it would be easy to edit stuff a little more on the fly and in a collaborative way. Hackpad is pretty awesome for this kind of stuff (it's better than Google Docs, but that's another topic).\nIt's private, so if you want an invite, just let me know your email (see mine over here: https://github.com/arxpoetica) and I can add you: https://socketstream.hackpad.com/\n. @thepian good question. (I assume by joshing you're referring to linting/hinting?) To my knowledge there's absolutely nothing wrong w/ separate var declarations. I prefer them as it's more readable, less prone to mistake\u2014but I'll follow whichever convention the majority wants. :wink: @paulbjensen opinions?\n. Huh. Interesting. What do you like about it?\n. I was just thinking about this. What's your reason @thepian? I was definitely noticing that all these bots were creating a lot of noise with all the inline comments on pull requests. I suppose that's a good thing\u2014it forces us to go back and clean up unlinted code. But it also makes it hard to look for non-bot comments in pull requests. Thoughts?\n. Let me clarify. I care enormously about linting\u2014it's AS GOOD as tests for catching bugs/errors. It also gives code consistency and sanity. I was only questioning the utility of the bots. There are other techniques for linting.\nI'm fine with or without bots, just wanted to clarify what I see as the value of linting (absolutely) vs. the value of bots (maybe).\n. sounds good.\n. I appreciate moving it into its own repo.\n. that sounds fine\n. /off-topic, but the whole point of semver is not worrying about minor releases like 0.4.x\u2014do as many as needed to keep things working!\n. This appears to be the breaking change: https://github.com/socketstream/socketstream/commit/9bfdad5a84df1e3fdd74e6f2c9de697af4e06968#diff-e0f3678f754a6146e6e9109a7830a48fL96\nEssentially, init was passed ss in the past, but is now conditionally passed ss.root in the case where typeof mod is not a function.\nMost of the current template wrappers (ss-jade, ss-hogan, ss-ractive, ss-coffekup) have init set to a function, but leave the main module alone (which translates to typeof mod === 'object'), so either:\na) most of the template wrappers will need to rewrite their wrappers to access ss OR\nb) we change this back to what it was\nI admit I'm on the fence about this since the current implementation is more inline w/ the formatters API, bringing them inline. Thoughts?\nFor the time being, I'm just going to change my local ss-ractive version (since that's what I'm working off of at the moment), and wait for input.\n. (\nfor reference:\nhttps://github.com/socketstream/ss-jade/blob/master/wrapper.js#L6\nhttps://github.com/socketstream/ss-hogan/blob/master/engine.js#L7\nhttps://github.com/socketstream/ss-ractive/blob/master/engine.js#L7\nhttps://github.com/socketstream/ss-coffeekup/blob/master/engine.js#L5\n)\n. @thepian right, they're technically different. I think they should be the same/similar, though. Thoughts? I think I'd rather have a breaking change and make them the same.\n. Cool & thx. Can you add a ref. to the fix?\n. @thepian there's enough you commented here, I wonder if it should go in a separate issue?\n. Ha. Isn't that a good thing. ;)\n. @paulbjensen any clues where I should start hunting on this one?\n. Amsterdam! Off topic, but I'll be curious of your travels. (For another thread.)\n. Okay. The good news. I dug pretty deep into the SocketStream code base. I now understand way more than I did before. ;)\nThe bad news, I think Koa may be pretty incompatible w/ SocketStream. That's because SocketStream makes pretty heavy assumptions about middleware. It operates using connect() (as the default strategy) (See https://github.com/socketstream/socketstream/blob/master/lib/http/default.strategy.js#L32 and https://github.com/socketstream/socketstream/blob/master/lib/http/index.js#L171). This means SS relies heavily on app.use(function() { ... }), where Koa relies on app.use(function *() { ... }). Note the asterisk. Generators!\nI may still be wrong on this. It may actually be possible to concatenate functions with generators using Koa, but that's a bit beyond me. Still, I'm going to post a code sample (it's the ss-example I've been working on), and show you where I am, and what I think needs to happen, and see if anyone else sees any glaring \"ah-ha\" as to how to get the middleware conjoined.\nAs for this rabbit hole I've gone down, even if I don't end up completing the Koa task, it's been a huge win in terms of understanding the workings of SS. But I will definitely be sad if I can't get this working, even just as a POC.\n. Holy...nix that...I think I just got it working!\nStand by...!...\nUpdate: yes, it's working! I'll post what I've learned when I get a moment.\nHappy, happy!\n. All right, so in essence, here's how you concatenate middleware w/ Koa:\nvar app = koa();\nvar ssMiddleware = ss.http.middleware; // assignment important, since this is a getter\napp.use(function*(next) {\n    yield ssMiddleware.bind(null, this.req, this.res);\n    yield next;\n});\nThis middleware binds req and res onto the Koa this object. It's a bit of a hack, and inefficient (probably), because what's really happening isn't truly concatenated. It's more like two sets of middleware, made available to Koa. Notice also, this doesn't bind Koa back onto SocketStream. Essentially, Koa this.request and this.response are still available, but the SS this.req and this.res are also available to each Koa generator, up the line, since the middleware binds it pre-routes or pre-whatever comes after.\nAlso, it's important to note that the session is only available (in Koa routes) as the store\u2014it doesn't have the added functionality, such as _.bindToSocket, etc., because we haven't loaded it yet. That's still okay, but we just have to handle setting session.userId and delete session.userId on our own, without the SocketStream helpers. This tiny detail took me forever to figure out, which was half my trouble.\nNot perfect, but I'm satisfied. It works. It could be better. Ideally, SocketStream middleware would be made compatible w/ generators, either via a plugin, or some other methodology. I'm a little worn out on dealing w/ this problem, and since it's working, I'm going to let it stand as is for now, and start building out the rest of this app. At some point I might circle back around on this issue and see if I can create my own set of middleware that runs generators. It might take changing some of SocketStreams internals to do such, and that would mean we'd have to loosen the coupling to connect and make either a possibility. Generators or callbacks. ;)\n. @thepian any thoughts on this? ^\n. @kulicuu you might want to also see issue #539 which I opened. Different scenario, but same \u201cshared session\u201d problem. There's additional background cited in that ticket.\nI'll be watching both of these tickets closely.\n. Okay. Not sure I know the distinction. As for well-engineered, I agree. I was thinking this morning that the ss api ought to expose the session in a more meaningful way.\n. Thanks for looking at things. I've been looking at those very files too, logging and digging, etc. I feel like I'm closer to getting the mechanics. Something that I never knew before\u2014by default we're using express-session (part of the connect universe) to handle sessions. That's not necessarily a bad thing, but it's a pretty big \"oh\" and should be documented. Good news is, this situation has made me dig quite a bit to understand the guts of the machine (as you call it).\n. Can you describe the changes you made? I've had a look over. Seems like your passing options and adding a secret in various places. What additionally is going on?\n. Let me see if I'm understanding correctly. In other words, alternatively, the following is now possible:\nss.session.options = {\n    secret: 'some session secret',\n    cookie: {\n        [...settings...]\n    },\n    [...additional session settings...]\n}\nIs this correct? You've provided an API basically to alter/set the session store?\n. I see, I see.\nSO. I think the other issue I've opened is going to actually require a more robust session API. (I think.) I won't elaborate any further here, but I'll open that convo up elsewhere so we can bounce it back and forth.\nIn essence\u2014it's possible (I might be wrong) that it's currently not possible to share sessions w/ some kinds of middleware in our current set up (for example, Koa). Like I said, I'll elaborate elsewhere, so I don't take this particular ticket too far tangent.\n. I think this actually fixed my issue. It started working after I updated. See: https://github.com/socketstream/socketstream/issues/539#issuecomment-106666039\n. Looks good.\n. Note, there's just a little spring cleaning going on in this PR as well as the API secret option.\n. Interesting...\n. For the record, you can maintain immutable code without an added library: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/freeze\n. @thepian I don't disagree\u2014however\u2014currently it's not possible to hook into the middleware for the MIME type in dev mode\u2014unless I'm missing something. _Update_ I'm realizing my comment might be flippant. :P I think you might be right. So, really, this issue might be moot. I'll investigate, and offer a solution to on that google thread. And add documentation. :)\n. :+1: \n. Good idea.\n. Agreed.\n. This is great. Just to be clear, you're suggesting I use this now until or if we bake in actually async/promise functionality?\n. I'm open to other suggestions. Basically\u2014anything to avoid callback hell makes life happy. ;)\n. SocketStream uses Connect under the surface in various places. It might make sense to be more explicit about that relationship, but I'm also not sure I understand what your proposing.\n. Interesting...\n. Can you explain what you mean by \"retired\"\u2014I'm wary of this approach, since I use ss-jade (and maybe ss-engineio) regularly ... ?\n. ah gotcha. thx\n. :+1: :+1: :+1: \n. Excellent, I'll give it a try.\n. Hmm...not working. With the following definition:\ncode: [..., '../node_modules/Template/code', ...]\nI get the following error:\n! Error: /Users/[user]/Documents/workspace/[project]/client/node_modules/Template/code directory not found\nSeeing that /client/ directory still in that path...so if I try adding an extra ../ I get the following:\nCouldn't serve client main, issue=1441074633914 \nENOENT, no such file or directory '/Users/[user]/Documents/workspace/[project]/client/Template/code/template.js'\nclient=N131alA3\n    at Error (native)\n    at Object.fs.openSync (fs.js:500:18)\n    at Object.fs.readFileSync (fs.js:352:15)\n[...etc...]\nmore:\n{\"bundle\":\"js\",\"file\":\"/Template/code/template.js\",\"ext\":\"js\"}\nClues? I have a local (up to date) copy of SocketStream. If you can point me in the right direction, I can try and debug myself.\n. Okay. I'll look into it and possibly do a PR. :snowman: \n. So I'm still following the papertrail, but I was surprised to figure out that the path for finding assets is parsed from request.url at socketstream/lib/client/serve/dev.js:42-46 (as part of serveJS). In other words, it's getting parsed off the query from this string: /assets/main/VJeVNUJp.js?_=[MyTemplate]/code/template.js\nWhat's the reason for doing this? Seems a bit backward.\n. So if no. 3 is true, then it appears to be broken...but I'm still digging into that... ;)\nNot sure what you mean in no. 5. Are you saying that the query parsing is done in another way, but should really be handled by the bundler?\n. Okay, a little further down the rabbit hole. It doesn't look like the final source of the problem, but line 631 in the bundler index file is trying to do a path.join with an incomplete path part. Specifically it looks like the rel variable is not a relative path.\nSo let's say I feed the client definition a path like ../../node_modules/Template/code/template.js, the rel variable somehow comes through as just `/Tribe-Kupuna/code/template.js'. In other words:\npath.join(ss.root,options.dirs.client,rel)\ntransliterated looks like:\npath.join('/Users/[user]/Documents/workspace/[project]','/client','/Template/code/template.js')\nSo...what happened to '../../node_modules'? A little confusing. But it looks like the rel variable is coming from request.url at socketstream/lib/client/serve/dev.js:42-46 as I mentioned above. So maybe that's just a bad way of parsing the variable? Hope this is helping and not just confusing. :P\n. If I'm understanding you correctly, that would be a breaking change? I'm okay with that, but it should be documented.\n. :+1: \n. Yow. It makes sense though. When I tried to debug a few weeks ago, like I said, the path variable was all over the place. It made me wonder if there was a cleaner way of keeping track of and using paths.\n. Hmm. Maybe I've done something bad on my installation w/ nvm. I've done the first two commands above. After running the third, however (socketstream new another-app), I get:\nbash\n[1]    8163 segmentation fault  socketstream new another-app\nI'll keep digging and see what's going on.\n. Same, but 10.10.4.\n. For what it's worth, when I do nvm use 0.12.7, it starts working again. I'm thinking this must (somehow) be a system thing, and not have anything to do w/ SocketStream. But where to begin... :wink: \n. Okay. So I got my app running. Turned out I needed to update my npm dependencies, oops: http://stackoverflow.com/a/32289269/209803 Makes perfect sense.\nHowever, still not clear on why a global build of socketstream would segfault. Here's the which:\nbash\n$ which socketstream\n/Users/[user]/.nvm/versions/node/v4.0.0/bin/socketstream\nI'll keep working on that, and close the issue when I figure it out. I'm sure it's similar to the problem I had in my actual app.\n. Oh weird. Now my global socketstream is working. Strange. Maybe updating my local build tricked the system. I'm not sure what I did, but we're good. Closing.\n. agree. will solve a lot of problems not supporting backward compatibility.\n. FYI, Node 4 is the merger of io.js back into the main Node branch (io is no longer a thing). And yes, it includes lots of new goodies as well as more frequent updates (on Semver). We should definitely add Node 4 to the test suite. Actually, it's going to be a more rapid moving target. We're already on 4.2.1.\n. :+1: :+1: :+1: \n. @thepian thoughts?\n@aaroncalderon just to be clear, what version of SocketStream are you running?\n. :+1: \n. I have not seen a lot of movement on it lately, and I used to be much more active as a participant. @paulbjensen? @thepian?\nI believe @thepian is the current project lead.\n. Currently, @thepian is the only one who can invite you back in (I'm only a member, not an owner).\n. Agreed. Full steam ahead.. ",
    "sveisvei": "+1 on this. \n. Yeah, it doesnt trigger alot of the times - but stuff still works if I dont depend on it.\n. Ill have a look into this with latest master\n. @americanyak ss-clientjade overrides what to do with jade-files, so they are as far as I know incompatible (without some filter based on folderpath or something like that).\n. +1 Same issue here.\n. In the usecase of having both express and ss at the same time, and reusing some of the ss templates, it might make sense to have this option.\n. +1 on this. \n. Yeah, it doesnt trigger alot of the times - but stuff still works if I dont depend on it.\n. Ill have a look into this with latest master\n. @americanyak ss-clientjade overrides what to do with jade-files, so they are as far as I know incompatible (without some filter based on folderpath or something like that).\n. +1 Same issue here.\n. In the usecase of having both express and ss at the same time, and reusing some of the ss templates, it might make sense to have this option.\n. ",
    "shoe": "socketstream: could you give a summary of how this was resolved, for the sake of other people with this problem?\n. socketstream: could you give a summary of how this was resolved, for the sake of other people with this problem?\n. ",
    "tylorr": "I am experiencing this too.\nI got so annoyed with it that I use setTimeout to check if the ready event was fired. And if it wasn't then I call what the ready event would have.\n. I am experiencing this too.\nI got so annoyed with it that I use setTimeout to check if the ready event was fired. And if it wasn't then I call what the ready event would have.\n. ",
    "drauschenbach": "This issue is open for me in 0.3.\nconnect, disconnect, and reconnect fire consistently, but ready fires never. I've got my client configured for ['htmlfile', 'xhr-polling', 'jsonp-polling']. \n. Nothing in the logs about missing session cookies -- logs are clean. I'm not using Express. I just have a fairly empty boilerplate project with a client that registers some ss.server callbacks after window load, to listen for the Socket.IO connect state, and log to console.\n. Without changing any code, I got my ready to fire by pointing my browser at my localhost instance. But my problem is when my server's deployed by Heroku, and my client is a UIWebView within an iPhone app. I'll try and isolate further over time.\n. Well not so fast! My first test was a direct use of Socket.IO with Heroku, from the iPhone UIWebView. ALL of the callbacks fired perfectly, for days on end. connecting, connect_failed, connected, disconnected, reconnecting, reconnected, reconnect_failed. Socket.IO rocks!\nIt's a little regrettable that SocketStream hides some of the more interesting server states, like connecting and reconnecting, which a client can wire up to progress spinners and so on. Maybe because your abstraction has to support SockJS, which does not support those?\nAnyways, Socket.IO works great with Heroku. Heroku might not support WebSocket, and it might also close sockets after 20 seconds, but those state transitions are well within the design criteria of Socket.IO, and I've tested it all and can vouch for it.\n. OK I have read up on the Engine.IO project, and I agree with its design principles, and will enjoy an Engine.IO based SocketStream 0.4.\nFor now, I am achieving the equivalent, by turning off WebSocket transport in my manual Socket.IO client configuration, which avoids that ugly initial 1-5 second delay for setting up a connection. And obviously I am not benefitting from any Engine.IO based auto-upgrade from XHR to WebSocket, since I'm currently with Heroku, which is fine for me for now.\n. Hehe, ya that shows. I totally failed getting SS --> Heroku Redis integration to work, after 2.5 hours. I'll open a different issue on that, just to dump my findings.\n. This could be the following Ember bug: https://github.com/emberjs/ember.js/pull/900\n. Not a SocketStream issue. I was wrong about point #2 above, and have coupled a View class to the template using the templateName field. SocketSteam is not getting in the way.\n. My challenge right now is that I have to make an RPC call to get the server-side session info, to populate my \"current user\" object. And because of that, each and every template of mine has this timing issue, where it has a \"current user not known yet\" state (which is different than \"unauthenticated\"). And so I am accumulating clutter in my templates and code to deal with this.\nMaybe there is a more obvious way. Unlike most example apps I see, my Ember router allows for my pages to be viewed by a guest user, and just certain parts of the page are hidden, and a sign-up dialog shows in the foreground. So the problem is my router routes and outlet setting all happens around 20ms before any RPC call that is launched after a ss.server.on(ready). So it makes it impossible to set up data models to populate controllers in an Ember router's route-on-enter.\nMaybe SocketStream apps need to have an Ember router redirect to a \"fetching session\" state, and then redirect back to where the URL entry point was heading (a deep bookmark). That will flicker, and I will not like it.\n. Ember is being pushed as the framework of choice for SocketStream. And after some headaches with it, I tried Angular, Knockout, and Batman. But those all had even bigger problems with SS, so I'm sticking with Ember. But it remains to be seen how authentication and the Ember router can be integrated, especially when using a deep bookmark as an entry point into the app.\nEach of the other frameworks will have their own integration challenges as well, but I think there's better odds of success if we all rally around a single reference point, and for SS, Ember is it.\nI love Batman. It leaves you with truly beautiful code and templates. And its data bindings are Jade-friendly, and not handlebars-ugly. I think it's deep durable property paths are the state-of-the-art, and the solution to hacks like Ember Data and how it wants to flatten deep documents (because listening to deep property graphs is too hard the Ember way, the authors say). But, it seems to have a flawed event model and state engine at the moment, and half of the time the data changes didn't propagate to all the dependent properties for me, leaving me with pages that acted like they were driven by a random number generator. I'm sure they'll fix it in the long run, but I can't wait this time around.\nI think those other framework's main problems are in two areas: (1) they don't expect you to swap the transport, which you will certainly be doing if you're SocketStream-based, and (2) they don't necessarily take RequireJS into account, and your code can turn ugly fast given that.\n. I sort of found a work-around for this: store more state on the server, where the userId is known. So an Ember router on-route-enter could perform an RPC call, return a future like Ember Data does, then populate the future with the RPC result once it arrives. In my mini-mongo style pseudo-Ember-Data, for me that means letting the server always filter on user id, instead of setting that param in the caller. So my mongo queries include some macros for current-user that handlebars evaluates on the server within my query rpc handler. That kind of solves a security gap anyways.\n. This is more of an Engine.IO question if you ask me. I'm working on the same thing right now. In short, Engine.IO uses document.cookie, which in a Hybrid or web situation would have been populated with the Connect session. But in a stand-alone PhoneGap app, this document.cookie should be pre-populated in advance (and stored in local storage), instead of being left blank. Apparently, the more mature SockJS-client does something equivalent.\n. I've just solved this on my end by avoiding the issue altogether... I switched my app to Hybrid by telling PhoneGap to download an external http URL instead of an embedded one. SockJS is worth a try, but you also need to turn on storage of cookies for file:// URLs so that the cookies get saved between mobile app sessions.\n. Well not exactly. My web app (PhoneGap or otherwise) uses session-scoped cookies. I do this because I don\u2019t implement a global RPC error trap yet, which would have to reload the page as soon as my RPC functions start returning 403 due to the session having been expired by Redis on the server while the client Ember app continues to run.\nOn Jan 9, 2014, at 2:31 PM, mooglin notifications@github.com wrote:\n\n@drauschenbach I tell phonegap to pull from a remote url as well, but I still hit this problem. You're using socketstream/phonegap and are getting session cookies persist between full app restarts.\n\u2014\nReply to this email directly or view it on GitHub.\n. +Like!\n\nOn Jan 16, 2014, at 6:32 PM, Robert Hall notifications@github.com wrote:\n\nI want to have a conversation around this. (@paulbjensen @socketstream-owen) I'm starting to think it might be better to just focus on milestones in changing the current 0.3.x versions. What I propose:\nContinue working on 0.3.x, providing fixes, patches, etc., and not breaking compatibility with current releases.\nAbandon (yes, entirely) the 0.4 work\u2014even though there was so much love that went into it\u2014this might feel like killing a sacred cow, but hear me out\u2014\nAny forward work branches directly off 0.3.x. However, instead of the next major release being 0.4.x, lets name it 0.5.x to avoid any confusion. 0.4 will just be like that empty floor in a building that everyone always passes and wonders what its like...\nWork going toward 0.5 can be forward thinking\u2014we can pick and choose what we change, what is and isn't backward compatible\u2014but unlike 0.4, 0.5 at least maintains some similarity and parity with what went before. This way people who have been using 0.3 in the wild won't feel like it's a completely different system and will be familiar and comfortable with the changes. It also helps toward development in all those regards.\nWhat you say?! 0.4 as abandonware? Well, yes, but that doesn't mean all of Owen's awesome work has to go to waste. Rather, we can slowly pick apart the work he's done in 0.4, picking and choosing more carefully what is wanted (instead of a rapid departure), and over several releases/milestones get closer to what was intended in 0.4. Think of it like what happened with XHTML 2\u2014it was a good attempt, but ultimately a total revamp was needed, and that was the brilliance of HTML5. HTML5 didn't start all over\u2014it built line upon line\u2014but the end product is completely different than what went before.\nI'm hoping to engage in a serious conversation about this. I would love to start focusing again on ONE unified product, and not feel split down the middle. Its just too hard to focus on several products, let alone one.\nAs a final note, remember, I'm not saying lets throw out all of Owen's awesome 0.4 work. Lets just recalibrate and rethink a plan of attack that helps people contribute in a more focused way\u2014\nEspecially with @RomanMinkin's awesome documentation setup. If we follow this new plan, I think we'd be ready to really have an epic do-over.\nWhat does everyone say?\n\u2014\nReply to this email directly or view it on GitHub.\n. This issue is open for me in 0.3.\n\nconnect, disconnect, and reconnect fire consistently, but ready fires never. I've got my client configured for ['htmlfile', 'xhr-polling', 'jsonp-polling']. \n. Nothing in the logs about missing session cookies -- logs are clean. I'm not using Express. I just have a fairly empty boilerplate project with a client that registers some ss.server callbacks after window load, to listen for the Socket.IO connect state, and log to console.\n. Without changing any code, I got my ready to fire by pointing my browser at my localhost instance. But my problem is when my server's deployed by Heroku, and my client is a UIWebView within an iPhone app. I'll try and isolate further over time.\n. Well not so fast! My first test was a direct use of Socket.IO with Heroku, from the iPhone UIWebView. ALL of the callbacks fired perfectly, for days on end. connecting, connect_failed, connected, disconnected, reconnecting, reconnected, reconnect_failed. Socket.IO rocks!\nIt's a little regrettable that SocketStream hides some of the more interesting server states, like connecting and reconnecting, which a client can wire up to progress spinners and so on. Maybe because your abstraction has to support SockJS, which does not support those?\nAnyways, Socket.IO works great with Heroku. Heroku might not support WebSocket, and it might also close sockets after 20 seconds, but those state transitions are well within the design criteria of Socket.IO, and I've tested it all and can vouch for it.\n. OK I have read up on the Engine.IO project, and I agree with its design principles, and will enjoy an Engine.IO based SocketStream 0.4.\nFor now, I am achieving the equivalent, by turning off WebSocket transport in my manual Socket.IO client configuration, which avoids that ugly initial 1-5 second delay for setting up a connection. And obviously I am not benefitting from any Engine.IO based auto-upgrade from XHR to WebSocket, since I'm currently with Heroku, which is fine for me for now.\n. Hehe, ya that shows. I totally failed getting SS --> Heroku Redis integration to work, after 2.5 hours. I'll open a different issue on that, just to dump my findings.\n. This could be the following Ember bug: https://github.com/emberjs/ember.js/pull/900\n. Not a SocketStream issue. I was wrong about point #2 above, and have coupled a View class to the template using the templateName field. SocketSteam is not getting in the way.\n. My challenge right now is that I have to make an RPC call to get the server-side session info, to populate my \"current user\" object. And because of that, each and every template of mine has this timing issue, where it has a \"current user not known yet\" state (which is different than \"unauthenticated\"). And so I am accumulating clutter in my templates and code to deal with this.\nMaybe there is a more obvious way. Unlike most example apps I see, my Ember router allows for my pages to be viewed by a guest user, and just certain parts of the page are hidden, and a sign-up dialog shows in the foreground. So the problem is my router routes and outlet setting all happens around 20ms before any RPC call that is launched after a ss.server.on(ready). So it makes it impossible to set up data models to populate controllers in an Ember router's route-on-enter.\nMaybe SocketStream apps need to have an Ember router redirect to a \"fetching session\" state, and then redirect back to where the URL entry point was heading (a deep bookmark). That will flicker, and I will not like it.\n. Ember is being pushed as the framework of choice for SocketStream. And after some headaches with it, I tried Angular, Knockout, and Batman. But those all had even bigger problems with SS, so I'm sticking with Ember. But it remains to be seen how authentication and the Ember router can be integrated, especially when using a deep bookmark as an entry point into the app.\nEach of the other frameworks will have their own integration challenges as well, but I think there's better odds of success if we all rally around a single reference point, and for SS, Ember is it.\nI love Batman. It leaves you with truly beautiful code and templates. And its data bindings are Jade-friendly, and not handlebars-ugly. I think it's deep durable property paths are the state-of-the-art, and the solution to hacks like Ember Data and how it wants to flatten deep documents (because listening to deep property graphs is too hard the Ember way, the authors say). But, it seems to have a flawed event model and state engine at the moment, and half of the time the data changes didn't propagate to all the dependent properties for me, leaving me with pages that acted like they were driven by a random number generator. I'm sure they'll fix it in the long run, but I can't wait this time around.\nI think those other framework's main problems are in two areas: (1) they don't expect you to swap the transport, which you will certainly be doing if you're SocketStream-based, and (2) they don't necessarily take RequireJS into account, and your code can turn ugly fast given that.\n. I sort of found a work-around for this: store more state on the server, where the userId is known. So an Ember router on-route-enter could perform an RPC call, return a future like Ember Data does, then populate the future with the RPC result once it arrives. In my mini-mongo style pseudo-Ember-Data, for me that means letting the server always filter on user id, instead of setting that param in the caller. So my mongo queries include some macros for current-user that handlebars evaluates on the server within my query rpc handler. That kind of solves a security gap anyways.\n. This is more of an Engine.IO question if you ask me. I'm working on the same thing right now. In short, Engine.IO uses document.cookie, which in a Hybrid or web situation would have been populated with the Connect session. But in a stand-alone PhoneGap app, this document.cookie should be pre-populated in advance (and stored in local storage), instead of being left blank. Apparently, the more mature SockJS-client does something equivalent.\n. I've just solved this on my end by avoiding the issue altogether... I switched my app to Hybrid by telling PhoneGap to download an external http URL instead of an embedded one. SockJS is worth a try, but you also need to turn on storage of cookies for file:// URLs so that the cookies get saved between mobile app sessions.\n. Well not exactly. My web app (PhoneGap or otherwise) uses session-scoped cookies. I do this because I don\u2019t implement a global RPC error trap yet, which would have to reload the page as soon as my RPC functions start returning 403 due to the session having been expired by Redis on the server while the client Ember app continues to run.\nOn Jan 9, 2014, at 2:31 PM, mooglin notifications@github.com wrote:\n\n@drauschenbach I tell phonegap to pull from a remote url as well, but I still hit this problem. You're using socketstream/phonegap and are getting session cookies persist between full app restarts.\n\u2014\nReply to this email directly or view it on GitHub.\n. +Like!\n\nOn Jan 16, 2014, at 6:32 PM, Robert Hall notifications@github.com wrote:\n\nI want to have a conversation around this. (@paulbjensen @socketstream-owen) I'm starting to think it might be better to just focus on milestones in changing the current 0.3.x versions. What I propose:\nContinue working on 0.3.x, providing fixes, patches, etc., and not breaking compatibility with current releases.\nAbandon (yes, entirely) the 0.4 work\u2014even though there was so much love that went into it\u2014this might feel like killing a sacred cow, but hear me out\u2014\nAny forward work branches directly off 0.3.x. However, instead of the next major release being 0.4.x, lets name it 0.5.x to avoid any confusion. 0.4 will just be like that empty floor in a building that everyone always passes and wonders what its like...\nWork going toward 0.5 can be forward thinking\u2014we can pick and choose what we change, what is and isn't backward compatible\u2014but unlike 0.4, 0.5 at least maintains some similarity and parity with what went before. This way people who have been using 0.3 in the wild won't feel like it's a completely different system and will be familiar and comfortable with the changes. It also helps toward development in all those regards.\nWhat you say?! 0.4 as abandonware? Well, yes, but that doesn't mean all of Owen's awesome work has to go to waste. Rather, we can slowly pick apart the work he's done in 0.4, picking and choosing more carefully what is wanted (instead of a rapid departure), and over several releases/milestones get closer to what was intended in 0.4. Think of it like what happened with XHTML 2\u2014it was a good attempt, but ultimately a total revamp was needed, and that was the brilliance of HTML5. HTML5 didn't start all over\u2014it built line upon line\u2014but the end product is completely different than what went before.\nI'm hoping to engage in a serious conversation about this. I would love to start focusing again on ONE unified product, and not feel split down the middle. Its just too hard to focus on several products, let alone one.\nAs a final note, remember, I'm not saying lets throw out all of Owen's awesome 0.4 work. Lets just recalibrate and rethink a plan of attack that helps people contribute in a more focused way\u2014\nEspecially with @RomanMinkin's awesome documentation setup. If we follow this new plan, I think we'd be ready to really have an epic do-over.\nWhat does everyone say?\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "plievone": "Perhaps you would have the current sessionID saved for each of your users, and then you would fetch the session object first from the Connect session store via ss.api.session.find(sessionID, socketID?, cb), but I don't know what happens when the socketID is then null for such requests. But with the session object, one could then call sessionObj.channel.unsubscribe(channel_name)\nOr one could send some kind of \"forceSubscriptionRenewal\" request to the browser, which must then ask for a subscription renewal from the server, before a timeout occurs. Then in a request responder one can unsubscribe or renew the subscription. \n. It would be quite straightforward to use clean-css (https://github.com/GoalSmashers/clean-css) where uglify-js is used for js?\n. Perhaps orhogonal to this issue or not, but SockJS recommends tokens instead of session cookies\nhttps://github.com/sockjs/sockjs-node#authorization\nhttps://github.com/socketstream/ss-sockjs/blob/master/client/wrapper.js#L14-21\nAlso engine.io support might become important (and does not rely on cookies either)\nhttps://github.com/LearnBoost/engine.io/blob/master/test/server.js#L77-86\n. @nponeccop, Yes, and the linking can also be done via a token. One can get the token via many means, such as from HTTP requests to the original domain or via RPC calls, but when one gets hold of the token, one can link the token to the socketid by registering via a RPC call first thing after reconnect. Registering can also keep browser tabs identified. This could be assisted via RPC middleware.\n. @owenb, in engine.io you can get the original handshake request (with cookie headers) as socket.request. \nAlso if one wants to utilize the same connect.cookieParser instance (with same secret etc) one can apply it on the req by filling res and next with null and a nop function. \n. Hi, I just tried CloudFront on SS production mode and it worked well: \n- When creating a CloudFront distribution, one can nowadays select \"Forward Query Strings\" so that that the full path is used as a cache key (as usually expected). So caching can be tested on dev mode too, if needed.\n- When serving SS from example.com, I pointed the CF distribution directly to that origin, and created a CNAME record cdn.example.com -> mydistid.cloudfront.net. So if the browser requests example.com/file.css, it is served through SS (and via intermediate load balancers such as nginx), and if the browser requests cdn.example.com/file.css, the same file is loaded to a local edge node from SS if not already present. One could serve the subdomain(s) differently to get greater control of the flow, but as an exercise this worked well.\n- Then I just prepended http:// cdn.example.com to js and css url generation in SS client/view.js. If HTTPS is used, then as one cannot use own certs on CF (on some other CDNs it is possible), one must use https:// mydistid.cloudfront.net.\n- So now when the first client on each edge location browses to example.com, it will be served html that contains js and css links to CDN (which will fetch the files if needed). As the page itself is not served through CDN, the links can be updated to new versions quickly on build.\nA few notes:\n- SS serves the assets with Cache-Control: public, max-age=30 but for CDN especially it would be better to have more than 30 secs :) CloudFront default without the max-age is 24 hours, but of course in some cases several weeks or a year is preferred, as the \"cache invalidation\" can be done by just starting using different urls. \n- Cloudfront respects client's Accept-Encoding: gzip, deflate header so SS could serve gzipped css and js/template files on most cases (with Vary: Accept-Encoding and Content-Encoding: gzip), and serve the original files only when that header is not present on the request (I tested CloudFront gzipping with Connect's compress and static-middleware, and changing browser configs). But due to SS asset pipeline, one could gzip the minified files already on asset packing stage to separate versions, no need for runtime gzipping. I have usually gzipped large long polling requests with nginx, but for rapid small messages it becomes irrelevant.\n- I didn't use SS cdn-facilities as the cdn domain was more important than the path (which didn't change).\n. Thanks Owen! This helps a lot.\nIn the future, one could perhaps have clients with multiple packages (relatively slowly updated libs vs. agile logic), maybe defined by a detectable array of arrays construct, and so the libs could be shared between clients (by using the hash in the filename without the client name in path, the same contents would map to the same filename automatically). For example, html5-boilerplate uses eight letters from MD5 hash (https://github.com/h5bp/node-build-script/blob/master/tasks/rev.js). Also only the non-existing (i.e. changed) files would need to be written, so unchanged clients would stay in cache. But at this point multiple clients with separate files are more than enough!\nRegarding gzipping, it is doubtful if gzipping the couple of files for each client (file.min.js.gz and file.css-gz or whichever naming convention you choose to use) would introduce problems, one could even spawn the gzip if node's implementation is suspect. I understand the worry if the gzipping would be done thousands of times, but here it would be done only for each defined client on build time. But until then, I might be able to emulate gzipping by defining two versions for each client (original and gzipped), gzipping the other one's assets, and serving them differently based on request header (not request header on the asset itself, but request header to the html index, which is indicative of gzip capability). In that way, the separate client asset versions can be uploaded even to S3 (or some other object storage), which otherwise could not be used as a gzip/non-gzip origin for same files -- here they would be different files, linked from different clients. I emphasize gzipping, as it makes quite a difference on slow networks (e.g. mobile)...\n. > The default cache expiration time will be changed to 30 days (bearing in mind your point about each asset having it's own unique URL).\nHow about some other assets besides the generated JS and CSS? For example, http://code.jquery.com/mobile/1.1.0/jquery.mobile-1.1.0.css refers to url(images/icons-18-white.png), which is http://code.jquery.com/mobile/1.1.0/images/icons-18-white.png. Depending on how usual this situation is, one can:\n- simply manually refer to that css in the html template, outside of the SS client packing system, so that the images/ can be placed under it, and the cache invalidation of the stylesheet and images (as they might be modified occasionally) can be handled separately somehow.\n- just manually edit the correct path of images to style files, but also in this case the cache invalidation of images needs to be handled manually, for example by allowing an arbitrary virtual root in asset serving url, which would map to same file, and changing it when needed (or appending a query string, or manual versioning, etc).\n- modify SS build system so that it copies all the assets under some directory-hash, either in a separate directory (so that they would be invalidated whey their contents change) or under the same directory as the rest of css and js (so that usual css image refs would work without editing, but then the images would be invalidated on each build, when the hash of js etc changes). Invalidating the cache and sharing of assets are conflicting goals...\n. Sorry I forgot to check the dev dependencies too:\n- coffee-script 1.2.0 (latest 1.3.3)\n- mocha 1.0.0 (latest 1.2.0)\n- should 0.6.0 (latest 0.6.3)\n. There is/was a bug in fs.watchFile, possibly related to your Live Reload problems https://github.com/joyent/node/issues/3495\n. Many of those libraries give access to the underlying websocket transport via the connection object. You could check:\n- binaryjs uses slightly modified einaros/ws (https://github.com/binaryjs/streamws), so that writes return true/false.\n- socket.io uses einaros earlier ws implementation I guess\n- einaros/ws is also encapsulated as websocket.io, used in socket.io's next iteration, engine.io (https://github.com/LearnBoost/engine.io)\n- sockjs uses https://github.com/faye/faye-websocket-node\nIt's interesting that the jury is still out whether to upgrade from polling (engine.io) or downgrade from websockets (sockjs): https://groups.google.com/forum/#!topic/sockjs/WSIdcY14ciI\nCombining RPC and streaming might be difficult, and Node's stream API, which BinaryJS mirrors, might still evolve:\nhttps://groups.google.com/forum/#!topic/nodejs-dev/djqqFhrObB8\n. > Hence you can use a .jade file to generate the HTML before it is sent to Hogan, or any other templating engine.\nAh, ok I didn't see that first.\n\nI'm thinking of making Jade client-side templating the default in 0.4 when you run socketstream new -j\n\nI too have become fond of Jade in browser, being skeptical at first. The current runtime.js is quite lean (although they have that rethrow function there still) and the compiler nowadays concatenates most strings together, resulting in quite nice template functions. Nowadays I use {self:true} option for performance reasons, as I might use small templates hundreds of times in the clientside, and that namespace also reduces error messages and makes it easy to spot the variables in the templates (as they are self.variablename etc). In SocketStream the workflow is enjoyable as I might start by playing with bootstrap classes on the main view and then moving snippets to separate templates without having to translate them in between.\nThanks, closing for now.\n. Hi @owenb and @paulbjensen, maybe this pull request is the right place to ask is there a specific reason for you to integrate engine.io the same way as in ss-sockjs (where the cookie had to be sent from clientside), and not in current socketstream style where the cookie is parsed from incoming request? An extra roundtrip in initialization could be important to somebody, and as the cookies are not http-only anymore, they are not as secure. But I see your point about sending the token so that the connection can come from other transports than http too.\n. Also in the wrapper there is an openSocketsById hash which seems like an leftover from ss-sockjs. In engine.io server it is just natively ws.clients, but perhaps you want to maintain a duplicate hash to allow only X-authenticated clients to be communicated to (with event all etc)? In that case the connection should be added to the hash only later when the session id is received.\n. Perhaps you would have the current sessionID saved for each of your users, and then you would fetch the session object first from the Connect session store via ss.api.session.find(sessionID, socketID?, cb), but I don't know what happens when the socketID is then null for such requests. But with the session object, one could then call sessionObj.channel.unsubscribe(channel_name)\nOr one could send some kind of \"forceSubscriptionRenewal\" request to the browser, which must then ask for a subscription renewal from the server, before a timeout occurs. Then in a request responder one can unsubscribe or renew the subscription. \n. It would be quite straightforward to use clean-css (https://github.com/GoalSmashers/clean-css) where uglify-js is used for js?\n. Perhaps orhogonal to this issue or not, but SockJS recommends tokens instead of session cookies\nhttps://github.com/sockjs/sockjs-node#authorization\nhttps://github.com/socketstream/ss-sockjs/blob/master/client/wrapper.js#L14-21\nAlso engine.io support might become important (and does not rely on cookies either)\nhttps://github.com/LearnBoost/engine.io/blob/master/test/server.js#L77-86\n. @nponeccop, Yes, and the linking can also be done via a token. One can get the token via many means, such as from HTTP requests to the original domain or via RPC calls, but when one gets hold of the token, one can link the token to the socketid by registering via a RPC call first thing after reconnect. Registering can also keep browser tabs identified. This could be assisted via RPC middleware.\n. @owenb, in engine.io you can get the original handshake request (with cookie headers) as socket.request. \nAlso if one wants to utilize the same connect.cookieParser instance (with same secret etc) one can apply it on the req by filling res and next with null and a nop function. \n. Hi, I just tried CloudFront on SS production mode and it worked well: \n- When creating a CloudFront distribution, one can nowadays select \"Forward Query Strings\" so that that the full path is used as a cache key (as usually expected). So caching can be tested on dev mode too, if needed.\n- When serving SS from example.com, I pointed the CF distribution directly to that origin, and created a CNAME record cdn.example.com -> mydistid.cloudfront.net. So if the browser requests example.com/file.css, it is served through SS (and via intermediate load balancers such as nginx), and if the browser requests cdn.example.com/file.css, the same file is loaded to a local edge node from SS if not already present. One could serve the subdomain(s) differently to get greater control of the flow, but as an exercise this worked well.\n- Then I just prepended http:// cdn.example.com to js and css url generation in SS client/view.js. If HTTPS is used, then as one cannot use own certs on CF (on some other CDNs it is possible), one must use https:// mydistid.cloudfront.net.\n- So now when the first client on each edge location browses to example.com, it will be served html that contains js and css links to CDN (which will fetch the files if needed). As the page itself is not served through CDN, the links can be updated to new versions quickly on build.\nA few notes:\n- SS serves the assets with Cache-Control: public, max-age=30 but for CDN especially it would be better to have more than 30 secs :) CloudFront default without the max-age is 24 hours, but of course in some cases several weeks or a year is preferred, as the \"cache invalidation\" can be done by just starting using different urls. \n- Cloudfront respects client's Accept-Encoding: gzip, deflate header so SS could serve gzipped css and js/template files on most cases (with Vary: Accept-Encoding and Content-Encoding: gzip), and serve the original files only when that header is not present on the request (I tested CloudFront gzipping with Connect's compress and static-middleware, and changing browser configs). But due to SS asset pipeline, one could gzip the minified files already on asset packing stage to separate versions, no need for runtime gzipping. I have usually gzipped large long polling requests with nginx, but for rapid small messages it becomes irrelevant.\n- I didn't use SS cdn-facilities as the cdn domain was more important than the path (which didn't change).\n. Thanks Owen! This helps a lot.\nIn the future, one could perhaps have clients with multiple packages (relatively slowly updated libs vs. agile logic), maybe defined by a detectable array of arrays construct, and so the libs could be shared between clients (by using the hash in the filename without the client name in path, the same contents would map to the same filename automatically). For example, html5-boilerplate uses eight letters from MD5 hash (https://github.com/h5bp/node-build-script/blob/master/tasks/rev.js). Also only the non-existing (i.e. changed) files would need to be written, so unchanged clients would stay in cache. But at this point multiple clients with separate files are more than enough!\nRegarding gzipping, it is doubtful if gzipping the couple of files for each client (file.min.js.gz and file.css-gz or whichever naming convention you choose to use) would introduce problems, one could even spawn the gzip if node's implementation is suspect. I understand the worry if the gzipping would be done thousands of times, but here it would be done only for each defined client on build time. But until then, I might be able to emulate gzipping by defining two versions for each client (original and gzipped), gzipping the other one's assets, and serving them differently based on request header (not request header on the asset itself, but request header to the html index, which is indicative of gzip capability). In that way, the separate client asset versions can be uploaded even to S3 (or some other object storage), which otherwise could not be used as a gzip/non-gzip origin for same files -- here they would be different files, linked from different clients. I emphasize gzipping, as it makes quite a difference on slow networks (e.g. mobile)...\n. > The default cache expiration time will be changed to 30 days (bearing in mind your point about each asset having it's own unique URL).\nHow about some other assets besides the generated JS and CSS? For example, http://code.jquery.com/mobile/1.1.0/jquery.mobile-1.1.0.css refers to url(images/icons-18-white.png), which is http://code.jquery.com/mobile/1.1.0/images/icons-18-white.png. Depending on how usual this situation is, one can:\n- simply manually refer to that css in the html template, outside of the SS client packing system, so that the images/ can be placed under it, and the cache invalidation of the stylesheet and images (as they might be modified occasionally) can be handled separately somehow.\n- just manually edit the correct path of images to style files, but also in this case the cache invalidation of images needs to be handled manually, for example by allowing an arbitrary virtual root in asset serving url, which would map to same file, and changing it when needed (or appending a query string, or manual versioning, etc).\n- modify SS build system so that it copies all the assets under some directory-hash, either in a separate directory (so that they would be invalidated whey their contents change) or under the same directory as the rest of css and js (so that usual css image refs would work without editing, but then the images would be invalidated on each build, when the hash of js etc changes). Invalidating the cache and sharing of assets are conflicting goals...\n. Sorry I forgot to check the dev dependencies too:\n- coffee-script 1.2.0 (latest 1.3.3)\n- mocha 1.0.0 (latest 1.2.0)\n- should 0.6.0 (latest 0.6.3)\n. There is/was a bug in fs.watchFile, possibly related to your Live Reload problems https://github.com/joyent/node/issues/3495\n. Many of those libraries give access to the underlying websocket transport via the connection object. You could check:\n- binaryjs uses slightly modified einaros/ws (https://github.com/binaryjs/streamws), so that writes return true/false.\n- socket.io uses einaros earlier ws implementation I guess\n- einaros/ws is also encapsulated as websocket.io, used in socket.io's next iteration, engine.io (https://github.com/LearnBoost/engine.io)\n- sockjs uses https://github.com/faye/faye-websocket-node\nIt's interesting that the jury is still out whether to upgrade from polling (engine.io) or downgrade from websockets (sockjs): https://groups.google.com/forum/#!topic/sockjs/WSIdcY14ciI\nCombining RPC and streaming might be difficult, and Node's stream API, which BinaryJS mirrors, might still evolve:\nhttps://groups.google.com/forum/#!topic/nodejs-dev/djqqFhrObB8\n. > Hence you can use a .jade file to generate the HTML before it is sent to Hogan, or any other templating engine.\nAh, ok I didn't see that first.\n\nI'm thinking of making Jade client-side templating the default in 0.4 when you run socketstream new -j\n\nI too have become fond of Jade in browser, being skeptical at first. The current runtime.js is quite lean (although they have that rethrow function there still) and the compiler nowadays concatenates most strings together, resulting in quite nice template functions. Nowadays I use {self:true} option for performance reasons, as I might use small templates hundreds of times in the clientside, and that namespace also reduces error messages and makes it easy to spot the variables in the templates (as they are self.variablename etc). In SocketStream the workflow is enjoyable as I might start by playing with bootstrap classes on the main view and then moving snippets to separate templates without having to translate them in between.\nThanks, closing for now.\n. Hi @owenb and @paulbjensen, maybe this pull request is the right place to ask is there a specific reason for you to integrate engine.io the same way as in ss-sockjs (where the cookie had to be sent from clientside), and not in current socketstream style where the cookie is parsed from incoming request? An extra roundtrip in initialization could be important to somebody, and as the cookies are not http-only anymore, they are not as secure. But I see your point about sending the token so that the connection can come from other transports than http too.\n. Also in the wrapper there is an openSocketsById hash which seems like an leftover from ss-sockjs. In engine.io server it is just natively ws.clients, but perhaps you want to maintain a duplicate hash to allow only X-authenticated clients to be communicated to (with event all etc)? In that case the connection should be added to the hash only later when the session id is received.\n. ",
    "luksch": "any news on this? I am now facing the same requirements\n. thx a lot for a the time and effort you put into this. I really appreciate this. We built our application on socketstream and really hope that the project continues to fly. Unfortunately we don't have any resources to get active here. Maybe there will be time for that in the future, but right now I can't help with any of that - I just want to use it :) so I understand that you can't do everything at once.\n. any chance of having this any time soon?\n. thx for the feedback and the promises! i am looking forward to the fix.\n. Here is my findings so far:\nI start both nodejs processes on localhost (one lisening on port 3000, the other on 3001) and connect to localhost:3001 with my browser.\nabout 1\nI send the messages in question over a channel with the name \"arbChannel\". Here is the call:\nss.publish.channel('arbChannel','arbs:update', arbvestorMessage );\narbvestorMessage is a json object. A client is subscribed to this channel on login via a rpc call, so we have a req object against which we work:\nreq.session.channel.subscribe( 'arbChannel' );\nabout 2\nAll is peachy, if only one nodejs process runs. The MONITOR command on the redis-cli shows messages like this:\nlogin\nredis 127.0.0.1:6379> MONITOR\nOK\n1391615455.171368 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615455.412123 [4 127.0.0.1:44512] \"setex\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"plan\\\":{\\\"plan\\\":2,\\\"beta\\\":false},\\\"userLogin\\\":\\\"testnorm1\\\",\\\"orderId\\\":469,\\\"channels\\\":[],\\\"userId\\\":117}\"\n1391615455.412532 [4 127.0.0.1:44512] \"setex\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"plan\\\":{\\\"plan\\\":2,\\\"beta\\\":false},\\\"userLogin\\\":\\\"testnorm1\\\",\\\"orderId\\\":469,\\\"channels\\\":[\\\"EAQrohplPzY/MgLvn4MJtGvy\\\"],\\\"userId\\\":117}\"\n1391615455.922505 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.003483 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.251686 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.251831 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.261957 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.274368 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.275713 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.576214 [4 127.0.0.1:44512] \"setex\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"plan\\\":{\\\"plan\\\":2,\\\"beta\\\":false},\\\"userLogin\\\":\\\"testnorm1\\\",\\\"orderId\\\":469,\\\"channels\\\":[\\\"EAQrohplPzY/MgLvn4MJtGvy\\\",\\\"arbChannel\\\"],\\\"userId\\\":117}\"\n1391615456.940817 [4 127.0.0.1:44512] \"setex\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"plan\\\":{\\\"plan\\\":2,\\\"beta\\\":false},\\\"userLogin\\\":\\\"testnorm1\\\",\\\"orderId\\\":469,\\\"channels\\\":[\\\"EAQrohplPzY/MgLvn4MJtGvy\\\",\\\"arb:21945169\\\"],\\\"userId\\\":117}\"\n1391615457.019415 [4 127.0.0.1:44512] \"setex\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"plan\\\":{\\\"plan\\\":2,\\\"beta\\\":false},\\\"userLogin\\\":\\\"testnorm1\\\",\\\"orderId\\\":469,\\\"channels\\\":[\\\"EAQrohplPzY/MgLvn4MJtGvy\\\",\\\"arb:21945169\\\",\\\"arbChannel\\\"],\\\"userId\\\":117}\"\n...\nthen a message is sent:\n1391615710.489735 [4 127.0.0.1:44516] \"publish\" \"ss:event\" \"{\\\"t\\\":\\\"channel\\\",\\\"channels\\\":[\\\"arbChannel\\\"],\\\"e\\\":\\\"arbs:update\\\",\\\"p\\\":[{\\\"timeStamp\\\":1391615710489,\\\"...\nstart of new nodejs process on other port:\n1391615842.976420 [0 127.0.0.1:46489] \"info\"\n1391615842.979186 [0 127.0.0.1:46489] \"select\" \"4\"\n1391615842.979269 [4 127.0.0.1:46489] \"select\" \"4\"\n1391615842.979646 [0 127.0.0.1:46493] \"info\"\n1391615842.979768 [0 127.0.0.1:46494] \"info\"\n1391615842.980443 [0 127.0.0.1:46493] \"select\" \"4\"\n1391615842.980796 [0 127.0.0.1:46494] \"select\" \"4\"\n1391615842.980942 [4 127.0.0.1:46494] \"subscribe\" \"ss:event\"\nnow an update looks like this\n1391615865.849659 [4 127.0.0.1:44516] \"publish\" \"ss:event\" \"{\\\"t\\\":\\\"channel\\\",\\\"channels\\\":[\\\"arbChannel\\\"],\\\"e\\\":\\\"arbs:update\\\",\\\"p\\\":[{\\\"timeStamp\\\":1391615865848,\\\"...\n1391615865.939475 [4 127.0.0.1:46493] \"publish\" \"ss:event\" \"{\\\"t\\\":\\\"channel\\\",\\\"channels\\\":[\\\"arbChannel\\\"],\\\"e\\\":\\\"arbs:update\\\",\\\"p\\\":[{\\\"timeStamp\\\":1391615865938,\\\"...\nBoth messages reach the client that is connected to the first nodjs process on port 3001\nabout 3\nThe second nodejs instance runs independently. It runs on a port that can only be reached via tunneling and loads a different run configuration. It is basically a staging area to test out things before deploying. Since we run on live data which is conveniently available on the production server we decided to go this route. most of the time the staging area nodejs process does not serve any clients. If i connect to the nodejs server on port 3000 i also get two messages, one from each nodejs process.\n. any news?\n. Hello Paul. The issue persists for us. I will try to see into the test repo to see if maybe i can reproduce our server behavior. I dealt with it so far by simply turning all node instances off on the server. So far we have only a moderate customer base and all testing is done again on local machines, so it is not a matter of death or life. Still, the issue is very troublesome, if you think about it.\n. I am glad that you could reproduce the issue finally. As I said, we were able to work around this in the past but it gives me definitively a much better feeling to know that you will address the issue.\n. In the end I want two (or more) node processes behind HA proxy serving my customers. I am fine with configuring sticky sessions, but that should really result in ONE session per client that ONE node process answers to. A message sent to all clients should only concern the very clients a node process is attached to. \nIf that is not possible, what would be the correct way out of this? How can I make sure that my clients don't receive the same message from each node process? Or do I need to have to make sure that only one node process actually sends out update messages to all clients? In this case I need to make sure, that I load balance the outgoing messages myself outside of ha-proxy. Not really nice... \nI understand, that you argue that this is not really a bug, but I really don't see the use case of this behaviour.\nI will look into this again in more detail and answer your other questions.\nRegards,\nLukas\n. Hi Paul!\nThanks for getting back to me. To be honest, we are looking hard into other options, i.e. moving away from socketstream as soon as we find time for the needed refactoring. Our project aims at end customers and involves AngularJs on the client side. Socketstream and AngularJs really are not getting along too well anyway, so the issue of not being able to scale horizontally as expected just adds to the already heavy arguments against socketstrem. Too bad for socketstream really, it did have great potential, and I just love the idea of having a nice pub/sub/rpc sub-system. Well, maybe you find time to get back into socketstream and all will be well. I keep my fingers crossed, since we will not have time to change base technologies like socketstream any time soon.\nLukas\n. In the moment I disabled the second node process. The load on our server is moderate enough so that only one process does the job well enough. Still, the issue remains serious, since this bug/feature/whatever prevents simple horizontal scaling. I still can't see the use case of the behavior as it is implemented right now. In what situation is it useful to publish to all sessions for a node instance, even to ones that are not handled by this instance? I just don't get the concept of this, but I may overlook something obvious...\nSorry to not be of much more help here, but i am very busy with other stuff right now. \n. As you see, the issue is well over a year old already. Another two months will not be the end of the world. I am just happy to see that finally socketstream seems alive again. It is such a nice little framework and I would hate to see it die, although I can't put much time into it personally.\n. I recall that I was not really accessing my site via the node port(s) directly but I used HAproxy configured with sticky sessions. Maybe I misconfigured this at that time, I don't exactly remember. \nThe question remains, how would one do what I wanted, meaning not connecting to two running instances in the same browser, but accessing a load balanced installation.\n. That would be good, since we use iojs and I now need to write some extra grunt task to let our deployment system work around this. Very annoying....\n. @arxpoetica\nOur application can be found here: https://app.arbvestor.com \nIn order to see anything you would need to register @ https://arbvestor.com, which is free. If you are into arbitrage betting this could be of use to you. If you just want to have a peek - well do that then :) \nNote that the production system is still on nodejs, not iojs. iojs is on development environment and we want to switch soon.\n. It would be awesome to get this fix in the npm version soon. Thanks everybody for the effort.\n. +1\n. I definitively would love to get the full pub/sub/rpc stuff into a webworker. That would be awesome!\n. It seems that the body parser is now outside the core of connect.\nhttps://www.npmjs.com/package/body-parser\nhttp://stackoverflow.com/questions/24330014/bodyparser-is-deprecated-express-4\n. I fixed our problem by getting rid of the need for body parser altogether. It  was easy, since it was actually a line of code that did not surf any purpose any more. I did not look deeper into this, since I had to go on doing other stuff.\n. any news on this? I am now facing the same requirements\n. thx a lot for a the time and effort you put into this. I really appreciate this. We built our application on socketstream and really hope that the project continues to fly. Unfortunately we don't have any resources to get active here. Maybe there will be time for that in the future, but right now I can't help with any of that - I just want to use it :) so I understand that you can't do everything at once.\n. any chance of having this any time soon?\n. thx for the feedback and the promises! i am looking forward to the fix.\n. Here is my findings so far:\nI start both nodejs processes on localhost (one lisening on port 3000, the other on 3001) and connect to localhost:3001 with my browser.\nabout 1\nI send the messages in question over a channel with the name \"arbChannel\". Here is the call:\nss.publish.channel('arbChannel','arbs:update', arbvestorMessage );\narbvestorMessage is a json object. A client is subscribed to this channel on login via a rpc call, so we have a req object against which we work:\nreq.session.channel.subscribe( 'arbChannel' );\nabout 2\nAll is peachy, if only one nodejs process runs. The MONITOR command on the redis-cli shows messages like this:\nlogin\nredis 127.0.0.1:6379> MONITOR\nOK\n1391615455.171368 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615455.412123 [4 127.0.0.1:44512] \"setex\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"plan\\\":{\\\"plan\\\":2,\\\"beta\\\":false},\\\"userLogin\\\":\\\"testnorm1\\\",\\\"orderId\\\":469,\\\"channels\\\":[],\\\"userId\\\":117}\"\n1391615455.412532 [4 127.0.0.1:44512] \"setex\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"plan\\\":{\\\"plan\\\":2,\\\"beta\\\":false},\\\"userLogin\\\":\\\"testnorm1\\\",\\\"orderId\\\":469,\\\"channels\\\":[\\\"EAQrohplPzY/MgLvn4MJtGvy\\\"],\\\"userId\\\":117}\"\n1391615455.922505 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.003483 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.251686 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.251831 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.261957 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.274368 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.275713 [4 127.0.0.1:44512] \"get\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\"\n1391615456.576214 [4 127.0.0.1:44512] \"setex\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"plan\\\":{\\\"plan\\\":2,\\\"beta\\\":false},\\\"userLogin\\\":\\\"testnorm1\\\",\\\"orderId\\\":469,\\\"channels\\\":[\\\"EAQrohplPzY/MgLvn4MJtGvy\\\",\\\"arbChannel\\\"],\\\"userId\\\":117}\"\n1391615456.940817 [4 127.0.0.1:44512] \"setex\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"plan\\\":{\\\"plan\\\":2,\\\"beta\\\":false},\\\"userLogin\\\":\\\"testnorm1\\\",\\\"orderId\\\":469,\\\"channels\\\":[\\\"EAQrohplPzY/MgLvn4MJtGvy\\\",\\\"arb:21945169\\\"],\\\"userId\\\":117}\"\n1391615457.019415 [4 127.0.0.1:44512] \"setex\" \"sess:EAQrohplPzY/MgLvn4MJtGvy\" \"86400\" \"{\\\"cookie\\\":{\\\"originalMaxAge\\\":null,\\\"expires\\\":null,\\\"secure\\\":false,\\\"httpOnly\\\":false,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"plan\\\":{\\\"plan\\\":2,\\\"beta\\\":false},\\\"userLogin\\\":\\\"testnorm1\\\",\\\"orderId\\\":469,\\\"channels\\\":[\\\"EAQrohplPzY/MgLvn4MJtGvy\\\",\\\"arb:21945169\\\",\\\"arbChannel\\\"],\\\"userId\\\":117}\"\n...\nthen a message is sent:\n1391615710.489735 [4 127.0.0.1:44516] \"publish\" \"ss:event\" \"{\\\"t\\\":\\\"channel\\\",\\\"channels\\\":[\\\"arbChannel\\\"],\\\"e\\\":\\\"arbs:update\\\",\\\"p\\\":[{\\\"timeStamp\\\":1391615710489,\\\"...\nstart of new nodejs process on other port:\n1391615842.976420 [0 127.0.0.1:46489] \"info\"\n1391615842.979186 [0 127.0.0.1:46489] \"select\" \"4\"\n1391615842.979269 [4 127.0.0.1:46489] \"select\" \"4\"\n1391615842.979646 [0 127.0.0.1:46493] \"info\"\n1391615842.979768 [0 127.0.0.1:46494] \"info\"\n1391615842.980443 [0 127.0.0.1:46493] \"select\" \"4\"\n1391615842.980796 [0 127.0.0.1:46494] \"select\" \"4\"\n1391615842.980942 [4 127.0.0.1:46494] \"subscribe\" \"ss:event\"\nnow an update looks like this\n1391615865.849659 [4 127.0.0.1:44516] \"publish\" \"ss:event\" \"{\\\"t\\\":\\\"channel\\\",\\\"channels\\\":[\\\"arbChannel\\\"],\\\"e\\\":\\\"arbs:update\\\",\\\"p\\\":[{\\\"timeStamp\\\":1391615865848,\\\"...\n1391615865.939475 [4 127.0.0.1:46493] \"publish\" \"ss:event\" \"{\\\"t\\\":\\\"channel\\\",\\\"channels\\\":[\\\"arbChannel\\\"],\\\"e\\\":\\\"arbs:update\\\",\\\"p\\\":[{\\\"timeStamp\\\":1391615865938,\\\"...\nBoth messages reach the client that is connected to the first nodjs process on port 3001\nabout 3\nThe second nodejs instance runs independently. It runs on a port that can only be reached via tunneling and loads a different run configuration. It is basically a staging area to test out things before deploying. Since we run on live data which is conveniently available on the production server we decided to go this route. most of the time the staging area nodejs process does not serve any clients. If i connect to the nodejs server on port 3000 i also get two messages, one from each nodejs process.\n. any news?\n. Hello Paul. The issue persists for us. I will try to see into the test repo to see if maybe i can reproduce our server behavior. I dealt with it so far by simply turning all node instances off on the server. So far we have only a moderate customer base and all testing is done again on local machines, so it is not a matter of death or life. Still, the issue is very troublesome, if you think about it.\n. I am glad that you could reproduce the issue finally. As I said, we were able to work around this in the past but it gives me definitively a much better feeling to know that you will address the issue.\n. In the end I want two (or more) node processes behind HA proxy serving my customers. I am fine with configuring sticky sessions, but that should really result in ONE session per client that ONE node process answers to. A message sent to all clients should only concern the very clients a node process is attached to. \nIf that is not possible, what would be the correct way out of this? How can I make sure that my clients don't receive the same message from each node process? Or do I need to have to make sure that only one node process actually sends out update messages to all clients? In this case I need to make sure, that I load balance the outgoing messages myself outside of ha-proxy. Not really nice... \nI understand, that you argue that this is not really a bug, but I really don't see the use case of this behaviour.\nI will look into this again in more detail and answer your other questions.\nRegards,\nLukas\n. Hi Paul!\nThanks for getting back to me. To be honest, we are looking hard into other options, i.e. moving away from socketstream as soon as we find time for the needed refactoring. Our project aims at end customers and involves AngularJs on the client side. Socketstream and AngularJs really are not getting along too well anyway, so the issue of not being able to scale horizontally as expected just adds to the already heavy arguments against socketstrem. Too bad for socketstream really, it did have great potential, and I just love the idea of having a nice pub/sub/rpc sub-system. Well, maybe you find time to get back into socketstream and all will be well. I keep my fingers crossed, since we will not have time to change base technologies like socketstream any time soon.\nLukas\n. In the moment I disabled the second node process. The load on our server is moderate enough so that only one process does the job well enough. Still, the issue remains serious, since this bug/feature/whatever prevents simple horizontal scaling. I still can't see the use case of the behavior as it is implemented right now. In what situation is it useful to publish to all sessions for a node instance, even to ones that are not handled by this instance? I just don't get the concept of this, but I may overlook something obvious...\nSorry to not be of much more help here, but i am very busy with other stuff right now. \n. As you see, the issue is well over a year old already. Another two months will not be the end of the world. I am just happy to see that finally socketstream seems alive again. It is such a nice little framework and I would hate to see it die, although I can't put much time into it personally.\n. I recall that I was not really accessing my site via the node port(s) directly but I used HAproxy configured with sticky sessions. Maybe I misconfigured this at that time, I don't exactly remember. \nThe question remains, how would one do what I wanted, meaning not connecting to two running instances in the same browser, but accessing a load balanced installation.\n. That would be good, since we use iojs and I now need to write some extra grunt task to let our deployment system work around this. Very annoying....\n. @arxpoetica\nOur application can be found here: https://app.arbvestor.com \nIn order to see anything you would need to register @ https://arbvestor.com, which is free. If you are into arbitrage betting this could be of use to you. If you just want to have a peek - well do that then :) \nNote that the production system is still on nodejs, not iojs. iojs is on development environment and we want to switch soon.\n. It would be awesome to get this fix in the npm version soon. Thanks everybody for the effort.\n. +1\n. I definitively would love to get the full pub/sub/rpc stuff into a webworker. That would be awesome!\n. It seems that the body parser is now outside the core of connect.\nhttps://www.npmjs.com/package/body-parser\nhttp://stackoverflow.com/questions/24330014/bodyparser-is-deprecated-express-4\n. I fixed our problem by getting rid of the need for body parser altogether. It  was easy, since it was actually a line of code that did not surf any purpose any more. I did not look deeper into this, since I had to go on doing other stuff.\n. ",
    "kulicuu": "This shouldn't be a problem.  I will attempt an implementation this week.\n. Agree this is critical.  Another I'm interested in, though quite a queue already.\n. The same issue arises now, but the underlying engine is called engine.io\nGoing through the source code under ./node_modules/socketstream/node_modules/engine.io/ looking for something similar to change.  Not happening yet, but learning a bit by reading the code.\n. I want to work on this feature and the whole client bundling module devvs, after doing the connect stuff, which I'm working on this week.\n. This is good to know.  I'm doing some stuff like this in prototypes.\nRight so basically I'm working on something which encompasses this or at least overlaps with this feature request; I'm working on being able to 'publish' server side events.  This feature would be a subset of the use case set.\n. sorta re-opened an oldie:\nhttps://github.com/socketstream/socketstream/issues/252\n. Yes, exactly the same one.\n. This sounds very interesting.  Code snippet of example usage possibility?\nOn Thu, Oct 24, 2013 at 1:54 AM, Paul Jensen notifications@github.comwrote:\n\nThanks. At some point we'll want to document this in the guide, and give a\ndescription of the pros/cons\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/407#issuecomment-26953344\n.\n. I started playing around with this.\nSo for example when it says it expected '===' and only sees '==' I go into the file and change that ?\n. I'm assuming we're trying to return the assignment instead of the conditional as it keeps suggesting.  Any way to turn that warning off? \n. I'm doing the /lib/websocket/transport.  But also started doing some of the http until I saw you already finished that.\n. say Yak, weren't you going to add me to some sort of documentation repo thing?\n. ah thx!\n. Very nice!\nAlso sheepish here.  --been subsumed in new works... (probably was also embarrased to contribute anything too amateur in front end)\n. Great!\n. Yes, although only generally at this point. The engine.io migration turned out not to require such a major change.\n. This is a cool idea.\n\nIt does seem like work should continue on 0.3x, which we are already using\nto deploy systems on.\nIf that's continually improved, and there is possibility of a smooth\ntransition to a 0.5 version from that, well, great!\nOn Fri, Jan 17, 2014 at 3:32 AM, Robert Hall notifications@github.comwrote:\n\nI want to have a conversation around this. (@paulbjensenhttps://github.com/paulbjensen\n@socketstream-owen https://github.com/socketstream-owen) I'm starting\nto think it might be better to just focus on milestones in changing the\ncurrent 0.3.x versions. What I propose:\n1. Continue working on 0.3.x, providing fixes, patches, etc., and not\n   breaking compatibility with current releases.\n2. Abandon (yes, entirely) the 0.4 work\u2014even though there was so much\n   love that went into it\u2014this might feel like killing a sacred cow, but hear\n   me out\u2014\n3. Any forward work branches directly off 0.3.x. However, instead of\n   the next major release being 0.4.x, lets name it 0.5.x to avoid any\n   confusion. 0.4 will just be like that empty floor in a building that\n   everyone always passes and wonders what its like...\n4. Work going toward 0.5 can be forward thinking\u2014we can pick and\n   choose what we change, what is and isn't backward compatible\u2014but unlike\n   0.4, 0.5 at least maintains some similarity and parity with what went\n   before. This way people who have been using 0.3 in the wild won't feel like\n   it's a completely different system and will be familiar and comfortable\n   with the changes. It also helps toward development in all those regards.\nWhat you say?! 0.4 as abandonware? Well, yes, but that doesn't mean all of\nOwen's awesome work has to go to waste. Rather, we can slowly pick apart\nthe work he's done in 0.4, picking and choosing more carefully what is\nwanted (instead of a rapid departure), and over several releases/milestones\nget closer to what was intended in 0.4. Think of it like what happened with\nXHTML 2\u2014it was a good attempt, but ultimately a total revamp was needed,\nand that was the brilliance of HTML5. HTML5 didn't start all over\u2014it built\nline upon line\u2014but the end product is completely different than what went\nbefore.\nI'm hoping to engage in a serious conversation about this. I would love to\nstart focusing again on ONE unified product, and not feel split down\nthe middle. Its just too hard to focus on several products, let alone one.\nAs a final note, remember, I'm not saying lets throw out all of Owen's\nawesome 0.4 work. Lets just recalibrate and rethink a plan of attack that\nhelps people contribute in a more focused way\u2014\nEspecially with @RomanMinkin https://github.com/RomanMinkin's awesome\ndocumentation setup. If we follow this new plan, I think we'd be ready to\nreally have an epic do-over.\nWhat does everyone say?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/425\n.\n. I think Yes.\n. I can look into this anew with the new EngineIo configuration.  I don't understand everything about the use case and requirements for API.\n. What is the issue here ?  Looking for more elaborate explanation of the technical situation.\n. winstonLogg= new (winston.Logger)(\n  transports:[\n    new (winston.transports.Console)({colorize: true})\n    new (winston.transports.File)({filename: './winston.log', colorize:\nfalse, maxsize: 2000000})\n  ]\n)\nss.api.log= winstonLogg.info\nc= ss.api.log\n\nOn Tue, Feb 4, 2014 at 1:54 AM, RomanMinkin notifications@github.comwrote:\n\nHi Evan,\nThanks for doing this, right now we are focusing on linting/testing (#408https://github.com/socketstream/socketstream/issues/408)\nto be able to work with PR more efficient.\nLong story short, would be great if @paulbjensenhttps://github.com/paulbjensencan also take a look, my concern is that we do not have test coverage for\nthat part of code.\nI think passing ss as a parameter around doesn't seem right. Maybe there\nis a way to use dedicated file let's say log.js, require it around with\nnode.js require and in the end assign it to ss object. Then i think it\nwill not be necessary to pass ss.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-34015633\n.\n. Will I encounter problems doing it that way?\n\nI'm doing a Nodejitsu deploy now and having lots of issues with logging,\nbut not really sure where they come from.\nOn Tue, Feb 4, 2014 at 5:03 PM, Evan Lawrence-Hurt <notifications@github.com\n\nwrote:\nThanks Roman, I'll look into options for not passing ss as a parameter and\nlook forward to @paulbjensen https://github.com/paulbjensen 's feedback.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-34067286\n.\n. ah nice.  thx!\n\nOn Tue, Feb 4, 2014 at 6:08 PM, RomanMinkin notifications@github.comwrote:\n\nHi @kulicuu https://github.com/kulicuu,\nNot really =) The problem is that code base has mix of console.log, ss.log,\nect. calls. So we need to replace them all with common log API, which could\nbe hook to whatever developer wants to hook it or just stream into stdoutand\nstderr.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-34075222\n.\n. I'm getting these errors on a Nodejitsu deployment.  I think may be related.\n\n[02/13 09:23:18 GMT+0200][err] TypeError: Object function (msg) {\n[02/13 09:23:18 GMT+0200][err]       // build argument list (level, msg, ... [string interpolate], [{metadata}], [callback])\n[02/13 09:23:18 GMT+0200][err]       var args = [level].concat(Array.prototype.slice.call(arguments));\n[02/13 09:23:18 GMT+0200][err]       target.log.apply(target, args);\n[02/13 09:23:18 GMT+0200][err]     } has no method 'info'\n[02/13 09:23:18 GMT+0200][err]   at start (/opt/run/snapshot/package/node_modules/socketstream/lib/socketstream.js:90:13)\n[02/13 09:23:18 GMT+0200][err]   at Object.exports.start (/opt/run/snapshot/package/node_modules/socketstream/lib/socketstream.js:132:46)\n[02/13 09:23:18 GMT+0200][err]   at Object. (/opt/run/snapshot/package/rubiaceae.iced:260:4)\n[02/13 09:23:18 GMT+0200][err]   at Object. (/opt/run/snapshot/package/rubiaceae.iced:4:1)\n[02/13 09:23:18 GMT+0200][err]   at Module._compile (module.js:456:26)\n[02/13 09:23:20 GMT+0200][out] FIXME production mode\n. It's running locally (even with NODE_ENV=production npm start) and crashing completely in NJ.\n. Dashku is on AWS right?\nOn Thu, Feb 13, 2014 at 11:38 AM, Paul Jensen notifications@github.comwrote:\n\nHi,\nI've tried replicating this error on Dashku's staging server, but it\ndidn't occur.\nHas anyone else encountered this issue?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-34961990\n.\n. I deployed same code to Heroku and no such issue.\n\nmany other issues, but not that one ;/\n. As posted in the SocketStream groups, I can't log in through the session\nbased system.  It just fails.\nIf I log in through the token based system I setup it works but the\nWebSockets handshake fails.\nhttps://groups.google.com/forum/#!topic/socketstream/luRxlDoso3g\nOn Sat, Feb 15, 2014 at 9:09 PM, Paul Jensen notifications@github.comwrote:\n\nHi Wylie, thanks for the update. What are the Heroku issues?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-35164654\n.\n. More: The setup for my app is a tiny bit complex:\n\nFirst of all I startup an Express server and attach SS to it. ( I might\nlike to run this code by you to see if it stands up. )\n1.\nAt root request I don\u2019t serve an SS client, I serve a Jade file I put in\n   a /views folder parallel with /server and /client. This is a simple angular\n   app all built into a single Jade file.\n    2.\nThat\u2019s basically an authorisations page, and if successful the client is\n   served an SS client. I have two login forms on that first page, one which\n   works via normal sessions and the other which works instead with tokens.\nThat\u2019s basically it. In the SS client I\u2019m connecting to remote Redis\ndatabases and running queries via rpc. (checking if username is already\nregistereed sort of thing)\nEven in local runs I\u2019m connecting to remote Redis instances. Open Redis,\nRedis-to-Go, IrisRedis. All three.\nOn Sat, Feb 15, 2014 at 9:19 PM, Joshua Cullick joshua.cullick@gmail.comwrote:\n\nAs posted in the SocketStream groups, I can't log in through the session\nbased system.  It just fails.\nIf I log in through the token based system I setup it works but the\nWebSockets handshake fails.\nhttps://groups.google.com/forum/#!topic/socketstream/luRxlDoso3g\nOn Sat, Feb 15, 2014 at 9:09 PM, Paul Jensen notifications@github.comwrote:\n\nHi Wylie, thanks for the update. What are the Heroku issues?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-35164654\n.\n. Okay I fixed issue number one in Heroku which was not being able to log in via the sessions auth way.  I hadn't had the Connect-Redis variable set correctly to the Redis-to-Go instance I'm using.\n\n\nBut the WebSockets issue is still bad.  It's not working either way.\n. Again, this is the error:\nWebSocket connection to 'ws://whispering-bayou-3276.herokuapp.com/engine.io/default/?uid=0xxxxxxxxxxxxxxx126&transport=websocket&sid=1JxxxxxAC' failed: WebSocket is closed before the connection is established. bartrgate2:1\n. Oh (shite) you just reminded me that's an add-on with Heroku !!!:)\nYeah I knew they didn't support sticky-sessions. It was you (many moons\nago) that clued me into the issue then.  I'd deployed with them before and\nhad upped our position to use two Dynos.  That was when things went bad.\n Back to one and it was fine.  This time I'd just forgotten they don't do\nWebSockets by default only by addon.\nOn the subject of sticky-sessions, there seems to be some kind of\nphilosophical division opening up.  Heroku doesn't want to support\nsticky-sessions, which sort of means they don't want session persistence to\nbe maintained strictly server side but rather passed around in tokens a la\nJsonWebTokens (the links mentioned in the SS-Ggroups post).\nI'm doing both tokens and the traditional session variables (connect).\nI started playing with tokens more or less by accident when I couldn't\nfigure out how to get my non-SS non-WS Angular 1-page-app to work with our\ntraditional sessions protocol (I've since figured it out.)\nI'm not really sure which route I'll take, maybe depends on the host.\nBtw Heroku is AWS, what does that mean to you ?\nAnd how is Linode ?  I'm going to try them this week.\nAnd what do you think / guess might be the issue with NodeJitsu?  Are they\na functional host or pretty erratic ?\n&c...\n:)\nOn Sat, Feb 15, 2014 at 9:54 PM, Paul Jensen notifications@github.comwrote:\n\nHi Wylie,\nAre you using Heroku's websocket support?\nPreviously, we had to use long-polling to handle working with heroku, as\nHeroku does not support sticky-sessions. See this link:\nhttps://coderwall.com/p/h2swda\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-35165993\n.\n. So I added the addon and no WS errors now.\nI'm still not getting anything back on my rpc queries, which probably means it's not connecting to my database or something.  It's a Redis-to-Go instance, but not provisioned through Heroku.  I thought I should just be able to connect to it through the same variables I use locally, which worked also for Connect-Redis.  But it does not seem to be working.\n. I'm using the 3.11 snapshot.  I switched awhile ago to the bleeding edge versions for the Angular templates stuff to work.\n. I was using attribute 'auth' instead of 'pass' for the password so it wasn't loading right.\n. It's not choking on any of my logs anyways, but on the\n\napi.log.info('Starting SocketStream %s in %s mode...'.green, version, env);\nline.\n. I've completely abandoned the Nodejitsu deployment as the Linode is working\nand offers much control.\nFor you \u200bI just tried a jitsu deploy and it again didn't go through again.\nStill no idea why, the Heroku deploy worked fine.\nThe only reason for the Heroku deploy was to demonstrate that it's a\nNodejitsu specific issue, and I'm no longer maintaining the Heroku\ndeployment.\nLinode mainstay for now, and if we need some backup deployment situation\nI'll try AWS, but for now I'm going back to actual programming having spent\nover a week on deployments.\nOn Wed, Feb 19, 2014 at 4:25 PM, Paul Jensen notifications@github.comwrote:\n\nHi @kulicuu https://github.com/kulicuu,\nCould you let me know if you're still experiencing this issue?\nThanks.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/433#issuecomment-35503388\n.\n. Strange, I've encountered this error now on Heroku, and also locally.\n\nI had an app up on Heroku which was working last month.  I took it down but someone asked me to redeploy it. \nI did redeploy, and got the error mentioned above (\"[...] has no method 'info'[...]\"), even though it was still running locally fine.\nI had been using most up to date SocketStream commits in the package.json, (\"github blahblah #master\"), so then I tried rolling back to a previous commit based on idea that maybe there had been breaking changes since then.  After running 'npm install' and 'npm start' I had the same 'no method info' error running locally!  Then reverted package.json to use #master again and ran npm install again and npm start:  same error again on local ! Even though it had been running fine with all of those variables less than one hour before.\n. Is it possible that 'npm install' doesn't detect when the branch master is updated and so doesn't refresh the build when new commits are made?\n. Reverting to this commit b4df865d9936b429bb8469004518e06836a792b8 (Roman Minkin's of Feb 3rd or so) fixed everything on local run and also for Heroku.\nProbably for Nodejitsu as well.\nI think there is some issue with the pluggable logging additions.  Maybe if no one else has these issues though something to do with the combination of those additions and my code... Worth looking into.\n. ```\nwinstonLogg= new (winston.Logger)(\n  transports:[\n    new (winston.transports.Console)({colorize: true})\n    new (winston.transports.File)({filename: './winston.log', colorize: false, maxsize: 2000000})\n  ]\n)\nss.api.log= winstonLogg.info\nc= ss.api.log\n```\nI did these right before the pluggable logging stuff started happening.  I haven't really fully addressed changing it before now, partly because of time and partly because wasn't fully sure it was source of problem.\n. I do recall during the Nodejitsu trials taking this stuff out and error still occurring. \nDuring those tests I removed the Winston dependency and returned all my logging to normal console.log calls.  I might have missed something.\n. In my main project I've dropped Winston entirely and it's just\nc= ss.api.log in the main app.iced file.\n. Removing Winston from the loop fixes things on local but oddly not on Nodejitsu.\nIt would be nice to use Winston with the new pluggable logging additions...\n. Off-topic :: but on subject of SS deploys to Linode :: Thoughts on custom\nNginx front vs something like Forever/-> PM2 or even Phusion Passenger  ?\nI'm halfway in between the latter two : PM2 handling pretty raw SS (https\nimplemented in the app file) but also testing out Phusion, which is\ninteresting.\nOn Mon, Feb 17, 2014 at 8:34 PM, Paul Jensen notifications@github.comwrote:\n\nMerged #434 https://github.com/socketstream/socketstream/pull/434.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/434\n.\n. nix Phusion, their convention is overly opinionated, and in the wrong way.\n\nOn Mon, Feb 17, 2014 at 8:38 PM, wylie joshua.cullick \njoshua.cullick@gmail.com wrote:\n\nOff-topic :: but on subject of SS deploys to Linode :: Thoughts on custom\nNginx front vs something like Forever/-> PM2 or even Phusion Passenger  ?\nI'm halfway in between the latter two : PM2 handling pretty raw SS (https\nimplemented in the app file) but also testing out Phusion, which is\ninteresting.\nOn Mon, Feb 17, 2014 at 8:34 PM, Paul Jensen notifications@github.comwrote:\n\nMerged #434 https://github.com/socketstream/socketstream/pull/434.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/434\n.\n. I'm interested, because I'm supposed to be coordinating right now with an\niOS developer to connect to my SS app as David Zhang discussed in the GG\nthread a few months back.\n\n\nWe're using SocketRocket, and he says I need to provide him with a client\nid?\nI need to give him something for the initial handshake?\nI need with this information to write a custom request responder?\nCould point me in the right direction?\nI'd be happy to look through the relevant code.  As before, my low level\nchops are not there yet, but...\nOn Mon, Feb 17, 2014 at 8:33 PM, Paul Jensen notifications@github.comwrote:\n\nHi,\nI've recently had to update engine.io as part of chassis.io (an engine.iowrapper library), but I haven't got round to sorting it out in SocketStream\n(yet). I welcome any efforts to help out with this.\nWRT the client change, #360https://github.com/socketstream/socketstream/pull/360may be of interest.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/435#issuecomment-35310729\n.\n. This is interesting. I'll help.\nI'm on 'job-market' now so have much more time for this stuff.  My other project is to bring SocketStream's Connect version up to ~3 -- ultimately to make it easier to use Express v4 with it.\nHopefully I can find time to address this one as well, and eventually to bring everything up to date.\n. :) most welcome!\n. So might as well target v1.3.1 as of August 27, 2014.\n. Just started on this today:\n- I'm working on bringing it to 1.4.3\n- If okay, I'm going to use this thread as discussion and notes storage for this process.  If not okay, maybe I'll start another issue and/or run a wiki page devoted to the process -- it's involved and lots of design decisions are available.  I just noticed in the engine.io-client History.md that as of v8.2 engine.io on the client runs great on (web)workers.  Stuff like that is crucial.\n\nhttps://github.com/Automattic/engine.io-client/blob/master/History.md\nhttps://github.com/Automattic/engine.io/blob/master/History.md\n. As for OP (on subject of cookie sent in headers): in 1.4.3 there is a direct sid attribute on the socket.transport now.  Still getting errors or the client... a ways to go yet... but hopefully next few days can maybe get something working. I do have time now.\n. Hilarious, I didn't realise until 5min ago that the client.js file(s) were of the engine.io-client.\nI almost have this working already.  (i think... ;0 )  In the primitive hacked-together sense.  \nHandshake is working and the ~~client is receiving events~~.\n~~Client isn't able to trigger RPCs yet. I think/hope by tomorrow that should be good.~~ \n~~Reversi: It is able to trigger RPCs, actually events are not yet happening perfectly.~~\nBoth events incoming and outgoing RPCs are now working.\nWorking on \"beta_meddle\" branch of my fork.\nI'm using this laTrappe for testing.\nAt the moment I've changed the clientFilename to \"client.js\".  Lot of hacking in \"engine.io/index.js\" also, to good effect.  Will clean up after I'm done.\n. Wow, this is going extremely well.  Almost completely working.  I'm rewriting the wrapper.js file now.  Actually just hacking it together-- proper rewrite / refactor over next couple days.  Very excited to see this coming together so fast!\nOkay it's all functional now.  I'll do a cleanup and refactor tomorrow hopefully will have something ready for a pull request tomorrow.  My branch is off of this (dec 16ish) commit : c0b41fea325b2cbda20e9d187bff864224894f50\nWill need to do some work for the merge (and bughunting) with the later stuff.\n. '@'everybody: THANKS!\n@nhitchins :\n\nre bughunting:  the bughunt I was referring to there have to do with later commits on the master than where I pulled my branch from.  Basically, the other day I started doing SocketStream devvvs for the first time in a long while and started a new fork, and found -- much chagrin -- that the latest master commits fail to load and run my app successfully.  So the branch that I'm developing this engine.io stuff on is branched off from a the commit of dec16 from the master branch.  Now, since I'm assuming that the later commits contain good work, there remains the issue of troubleshooting what troubles have creeped into them.   \nre binary websockets: first I've heard of it. (after reading a tiny bit about it) Sounds great!  It looks like engine.io supports this, so of course I'll consider supporting it to be part of my job here.  At least to give it a good start.  \nother stuff:  As well as binary websockets, there are likely a lot of new features to leverage.  As I mentioned in a post above, the one that really caught my eye was that as of something like v8.0 engine.io-client can be run in a web-worker.  ~~I would assume that this would be a good way to go, but really my deep low-level browser knowledge is not so expert, so would love to hear opinions on this... but my impression is that this would offer developers substantial performance benefits.~~  ~~Researching further I think it runs in web-worker by default ?~~ Looking into this now. [...] Is the whole SocketStream client side running in a web-worker ?  is what I'm trying to grok now.\n. Wish list on engine.io websocket binary API structure ?\n(RPC/serverSocketStreamAPI/client)\n. @nhitchins \nNo gotchas yet, but there are a lot of changes and I'm taking my time with verifying edge cases and pulling all the elements together.  One of the things I'm doing today and next few days maybe is making sure  the debug mode will work.  That's changed a lot so it's something I'm looking into integration-wise.  That's just an example.  A bunch of little things like that.\nautomatic compression sounds great.  doing everything in binary i'll hold off on this week-- but for sure will be thinking about implementation strategies.\nWeb-workers :  Yeah me too-- interested to hear opinions on this.\n. A deep thinking about sessions persistence is the meditation of the week.  Prototyping a tokens-based approach one of the first tasks.\n\nThe new engine.io implementation websockets connection doesn't persist over server restarts or browser reloads.\n. I have engine.io v1.5.1 working with persistent sessions now (I had overlooked something obvious).\n~~I'll have a pull request ready in within an hour (need to clean up the .gitignore file and commit).  Sorry about the false start, ...~~ it's ready.\nWill need to test more, and am still definitely working on the deeper overhaul stuff across the board, but happy to know this has come together unexpectedly.\n. Ah cool I see the issue has been renamed with more elaborate specification.  ;]\n- in the client running the system in a webworker is default automatic..\n. It's upgraded very well, but not yet leveraging all new possibilities.  This will require some design insight and decisions on your (plural) part.  I'm also full-time into a new job, so absent for a bit.\n. This is very interesting.\nI'm not really expert enough to respond in detail but hopefully others will.\nYour recommendations on structuring the client side especially seem promising, but again, I'm not resident expert yet.  I hope some others weigh in.\n. I see my issue but not sure how to fix it yet.\nIn my rpc files I have a require statement at the top: ss= require 'ss'.\nI realised after looking that none of the demos and other projects floating around have this.\nI removed mine and it complains that ss is undefined.  So something in my main app file configuration probably.  I'm using Express and have a lot of configuration middleware details with Connect, https, etc.\n. Some combination of things.  I've gotten the server side fixed, still having some issues but those are AngularJS related I think.\n. Maybe it's because NodeJS cluster module no do sticky sessions.\n. Ah thanks! As it turns out, I got it working with pm2 using their fork mode -x option.  So it's on 4 cores and I seem to be having simultaneous sessions working well on Chrome and Firefox.  I don't know about future scaling and performance and everything but it seems to be working at this level.\nI'll check out your link too, thx!\n. Actually that sticky-session module looks pretty cool.  I guess it just wraps everything.  So maybe if I used that I could go back to using pm2 under its native mode / nJS cluster module ... might get better auto load-balancing ... totally guessing maybes.\n. Before using sticky-session I was pm2 -x -i 4 -n Rubiaceae start sudoStart.js\nNow because sticky-session handles clusterisation:\nI'm using fork mode on pm2 and not splitting it just one prong.\nLike \"maltese\": \"pm2 -x -n rubyMaltese start sudoStart.js\"\nIt was a weird bug which originated on the client side. HTML5 based on a type=\"email\" setting (when it got something that wasn't proper email it sent fritz which->) somehow caused my entire session to reset.  Very weird, anyways, I got rid of it and have no problems now.  \nEverything is quite peachy.\n. (excerpt from my main app file ):\n(metro is an express() app)\n```\nsticky ->\nss.session.store.use 'redis', rtgRedisConfig\n  ss.publish.transport.use 'redis', rtgRedisConfig\nss.session.options.maxAge= 8640000\nsecureServer= https.createServer ssLeo, metro\nss.start secureServer\n  metro.stack = ss.http.middleware.stack.concat(metro.stack)\n  process.on 'uncaughtException', (err) -> \n    c 'Exception caught: ', err\n  return secureServer\n.listen 443\nc cStart \"server started on ports 443\"\n``\n. That's exactly how I do it too !  ThesudoStart.js` referenced above contains:\n(I found this trick some months ago, maybe from you... someone's SocketStream example code somewhere I don't remember which one... I had just googled SocketStream pm2 maybe...)\n```\nrequire('./node_modules/ss-iced/node_modules/iced-coffee-script/lib/coffee-script/coffee-script.js').register()\nrequire('./rubiaceae')\n```\n. > [...]all sessions issues was gone.\nMmm, this didn't happen for me.  If I started pm2 in cluster mode like that it worked okay from a RESTful perspective but the rpcs were not being routed okay.  Total mess, so I had to go to fork mode.\nIt's mysterious to me that sessions worked for you .  Can you verify that you had full cluster mode in pm2 and your clients all being routed (like sticky) to correct servers persistently?\nThat would be interesting because NodeJS cluster mode not supporting sticky session, and P Jensen et al say Ss requires it.\n? I'm confused a bit.  ...I don't have any problems as my situation is working great now, with the sticky-session module for clustering and pm2 just for 'forever' functionality --- I'm just interested in how it is you got pm2 cluster mode to support sticky session by itself.\nI think you may find that your app seems to be working well -- in most ways it is-- but actually isn't; ie heavy rpc usage will reveal that clients sessions are getting mismatched and problems will arise.  In my experience it's not an error that shows up immediately; ie it took me awhile to realise that I was having problems and that I would need to switch to fork mode for those sessions to be persisted/routed correctly.  To elaborate more specifically, I was able to start my app in pm2 in cluster mode using the trick you exhibit, and it seemed to work.  My express RESTful routes worked fine and my SocketStream functionality was working as well, to some extent, the incompleteness of which took a bit of time to manifest. In pm2 cluster mode my rpc's initially went through, and most of them returned good responses, but the more I used the app and mixed things up a bit with heavy usage, ..very quickly chaoes manifested with broken sessions / rpcs getting no responses or confused responses, because of session variables not in place.  Depending on the characteristics of the structure of the app, this may not manifest at all.  Anything sufficiently complex, eg requiring session based auths and roles, you would probably see problems.\n...but I don't know.  Just interested...\n. Yeah this got me thinking more about how I could implement my app to make all my auths token based, then could run with pm2 in cluster mode without sticky-session and no worries. Make new middlewares to check incoming req tokens against Redis database user accounts and so on.   Would be performance or other benefits/penalties vs my current config ?   I dunno.  Interesting question.\nAnswering it myself, probably not so good though it might help optimise clustering mgmt.  Don't like the idea of extra overhead with every rpc message, especially in a usage scenario -- like gaming or intensive realtime interactive data-visualisation data-mapping application -- featuring massive numbers of updates.  Which reminds me that for those applications I'd probably need to make a separate custom transport as per the docs, something even lighter-weight.\n. I actually use JSON web tokens in my current app -- kind of deprecated at the moment, but I went down that road for exploratory reasons.\nDo you see definite benefits to avoiding sticky sessions in favor of JWT ? Or just want to offer choice to the developer ? Bit of both maybe ?\nI'm thinking having the choice open might be greatest for a platform like Ss which wants to offer flexibility and configurability.  Can't see eliminating (sticky) sessions based variables entirely because of the really high message volume, low latency, high frequency applications like gaming and data interactive apps.\nProbably I don't understand the low level of TCP and network hardware very well, but my naive intuition says that in those situations one would want to avoid the overhead of sending a token with every message (suppose messages coming at 30hz).\nOtherwise, sure why not.\n. Ah solved. \nI still haven't had time to respond to your last contributions.\n. i'm curious, what is the significance of this ?  i think i missed some of the history.\n. ah, thanks that's important piece of the puzzle.\n. Oh cool !\nThat sounds much better than what I hacked together:\n... in the last hour, I implemented a solution which:\n- involved server side setInterval [... to ss.api.publish.all \"rollCall\" which is answered by an ss.event.on \"rollCall in the webClient's entry file, ... and a bunch of cool Redis tricks ...\n- It works great, running locally single instance or forked, but when I try to run it clustered with sticky-session it gives a very strange error.  Very early on startup I get a console message which says basically that ss.api.publish is undefined because it can't find the all function to run on 'undefined'.\n  Interesting. As I said it, worked running locally in single instance, and is currently running in my Linode VM forked (pm2 -x -i 4 [...]) fine.  But it folds miserably when running from the main app file I have configured with sticky ie sticky-session.  No idea why yet, and maybe not the best use of my time right now to spend some hour(s) investigating.  But interesting nevertheless.  Recently nvm is configured to v0.10.26.\n  This idea of exposing the close event sounds very much better.\n  (Still, for other reasons, I would like to be able to set my server to perform actions periodically without prompting, so need to figure out the new bug eventually.)\n. :100: \n:)  Very nice !\n. Was having another look at this last night and in the process of going through the entire Ss codebase again realised I'm within visual range of actually grokking it all for the first time.  So I should be able to assist adding stuff like this.  Time is limited currently of course and this isn't absolute highest priority but I'll be consistently returning to it over the coming weeks.  Will refetch the fork and start customizing my own...  then Maybe a pull request isn't too far off.\n...also, will send a stack-trace soon, on my list of things to do for sure is to figure out that crash with the clustered process from the setInterval ss.api.publish.all \"rollcall\", 3000 , but for now (in Dev) just running a singular process server.  Some preview on that: my app structure is heavily indebted for inspiration to your old Dashku, though I've adapted much and complexified much (I have viewControllers, modelControllers, and models in the server, all instantiated from the /server/internals file)... anyways, I have a function which based in a modelController called globalState which is invoked once from internals on startup which 'startsupthesystem\", and in this one I've lodged this new setInterval to constantly check who is out there and capable of responding.  Works on single process, crashes when clustered, even though clustered works without this feature addition.  mmm, yeah so just a preview, will pass along the stack trace when I get around to figuring out how to produce some meaningful ones (pointers on that would be great)... \nAlso, whistl it would clearly be more elegant to have this feature implemented over the lower level engine.io trigger instead of this \"rollcall\" publication, I still want to have the capability of running these higher level persistent periodic signal exchanges (on scaled up clustered systems), so I think it's worth figuring out the nature of the crash, for the reinforcement of the viability of Ss as a resilient platforrm for signal-heavy / signal-intensive RealTimey stuff.\n...So yeah, more to come on that.\nthx!\n. I think I figured out what causing the crash in the clustered run.  Something kind of silly, should have called the startup script later in the start process.  Not positive, but I think it will be easy to reduce and eliminate.  Not sure why it wouldn't show up in the singular version, but a deep read of all the compiled JavaScript (from iced-coffee-script, sticky-session, etc) would probably illuminate that pretty quickly.  Not that I have time for that now, but for the deeper architectural and framework development interests will definitely be doing much of that sometime in medium-term future.\n. Across all instances.  I don't modify any global variables though, everything goes into a Redis cache which is shared.\nI have a modelController call it globStatMC and a model, call it globStatM.  As in Dashku, both are attached to the ss api object by the internals file invoked early in the bootstrapping process.\nSo far so good.  Everthing works with single instance, and everything works with sticky-session.\nThen, later, I realise that after my entire system starts up I want to call a function defined in globStatMC --> globStatM that startupSystem.  Now, if this is single instance it's really not much mystery how to do.  Can invoke from internals even, can invoke after the entire server is on and listening.  But with sticky-session happening it becomes a bit of a riddle.  If it's too early in the cycle outside the sticky-session definition bloc, then I get an error that the ss.api.publish object is undefined; if it's in the bloc then it get's invoked once for every instance, and it's a deluge of redundant calls to this function and an overabundance of copies of the 'publish' events it spawns, essentially freezing the server's ability to handle requests.  I tried putting it after the sticky-session bloc, in my main app file, but there doesn't seem to be any after the bloc.  Outside the indented area and after is still cloned ..  My fix, ugly but good enough, is to just not even try to initiate the startup script during bootstrapping process, but actually to initiate it from an Admin interface via RPC, after all of the sticky-session spawned clusters are already up.  Funny no ?  So the riddle is, how would you invoke a controller, model function internally ?  ..without resorting to an externally triggered (RPC) call ?  Well, I think it's funny.\nAnother thing, I noticed that if I ( a browser ) makes a request to my sticky-sessiond application too early in it's bootstrapping process -- before all instances are fully up and running (which can take nearly ten seconds from issuing the command) -- then it crashes the entire thing and I need to ctrl-C and restart.  Is this an issue you've encountered in production ?  Does this mean you need to use a script to temporarily block access to the relevant ports with iptables during the bootstrapping / startup process ?\nAnyways here an excerpt from my main app file:\n(I think I've attempted all the placements commented out)\n```\nrequire './server/startup'  # placement 1\nsticky ->\nss.session.store.use 'redis', rtgRedisConfig\n  ss.publish.transport.use 'redis', rtgRedisConfig\nss.session.options.maxAge= 8640000\nsecureServer= https.createServer ssLeo, metro\nss.start secureServer\n  metro.stack = ss.http.middleware.stack.concat(metro.stack)\n  #require './server/startup' #placement 2\n  process.on 'uncaughtException', (err) ->\n    c 'Exception caught: ', err\n  return secureServer\n  #require './server/startup' #placement 3\n.listen 443\nc cStart \"server started on ports 443\"\nrequire './server/startup' #placement 4\n```\n. logo: very nice +++++\n. Nice elaborate answer !, sorry about my rather sparse response on the gGroup...\nFollowing up the gG response a bit (will clarify further later if necessary), to go the Express way, you do the stuff in the Gist, and then define routes, at first in the same main app file-- most likely later on you'll want to include them from a separate file.\nNow, since you want the prompt and not just force the download, you could set it up over RPC, the prompt that is.  If the user accepts it then you could either send the webclient a token and validate against that on the GET route or you could validate against a req.session variable.\nIn that case you wouldn't be using res.download but res.sendfile at the end.\nI suppose you could probably also do the res.download thing too, but I haven't had reason to.\nIn my current project I'm working with iOS client in addition to the Angular webclient. For the iOS to server connection, I have to set up the image downloads over RPC with tokens because the iOS HTTP session is not sharing variables with the RPC session for some reason.  The token validation works well. \n. Possible to just remove the 'strict mode' for this one file ?   \nThat's what I did, was fine.  What approach(es) are you thinking ?  Could pass the function in explicitly as an argument, but that's probably painful amount of tedium for not very much.\n. Maybe named function ?  I'm just guessing.  I'll actually look at it later.\n. getBranchFromTree = function(tree, ary, index, i) { \ncould be\ngetBranchFromTree= function getBranchFromTree(tree, ary, index, i) {\nand then\nreturn arguments.callee(tree[ary[i]], ary, index, ++i);\nbecomes\nreturn getBranchFromTree(tree[ary[i]], ary, index, ++i);\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions_and_function_scope/arguments/callee\n. https://github.com/socketstream/socketstream/pull/450\n. No prob and Ouch, :/, similar situation here, :)\n. Auwsome, I think the same.\nI'm so taken with Redis, I don't think the requirement is inappropriate.\n. As you wish.\nHowever, just to point out some things in retreat:\n- it's just a Redis server install.  Not only is it simple process, but for someone making way into building realtime apps this is pretty much mandatory anyway.\n- Getting rid of MemoryStore simplifies things substantially, not only for the build of SocketStream but for the people who are coming in to using it.  Right now it's like : \"hello new people, by default SocketStream has this useless session store system (by implication you should learn how it works), but really we suggest anything serious should use Redis, (by implication if you are serious about your project you should definitely learn how it works)\". So that's two things to learn and understand versus just one.  \nIn the past few weeks I've had to freeze all of my work on frameworks (SocketStream especially) in order to prioritise some work closer to portfolio for job-market activities.  The last thing I was working on SocketStream specific was upgrading Connect to v3, partly but not only for the option of bringing in user-option of packaging Express v4 with the buildup.   Connect v3 is completely different and breaking from v2.  Almost everything (static is maybe the only exception) has been moved out of Connect into middlewares.  I'm not sure what the correspdonding thing to MemoryStore would be under Connect-v3, maybe just https://github.com/expressjs/cookie-session, not sure at the moment.\nBut the point of me writing here is that all of this and upgrading to Connect v3 maybe missing something else:\nhttp://koajs.com/\nI've scarcely had any time to look into that, but I know it's the team behind Express, and that it \"leverages generators\", which gives opportunity to move more terse, efficient and direct functional style in future code.\nIf I could spend full-time on this, I would first go back to the project of bringing in Connect v3 for current versions, and then start working on building something with Koa for future versions.  Or at least experimenting with it, to see if it would work well, with for example, current versions of Engine.io.\nAh well, thanks for the feedback ;0\n. Cool cool.  I understand a bit more about it now.  Recalling the idea to keep the framework setup for initialisation quite minimalistic, unopinionated, simple.\n. As a general condition, I understand and indeed develop with event buses, on AngularJS hooked up to SocketStream RPC and model/controller constructs; but, I don't understand the particular intent and idea of the author of the comment and/or the community intent around same.  iow does the comment still mean anything ?  The question is opening a deep-design discussion in socketstream development, I suppose.\n. Same as the other one, I'm starting to do stuff with this in prototype form-- maybe something this week for a kind of branch pr... i.e. maybe would like to do some pr to branch for some of these.\nAs mentioned on #292 I'm working on something for 'publishing' server side events.  Will be built into the existing publish module.\n. Client option sounds good for introducing this.\n. Do you (plural) prefer jspm over browserify -- futurewise ?\nI had never heard of it before now.  I've been doing a lot of work with Browserify and Gulp, and now set to reproduce some of this functionality in pure Npm scripts.  Working on variety of mutually redundant dev-lines in parallel.\nI guess I'll add this jspm into the mix and see if can do something with it.\n. I started using some new client-side frameworks yesterday, some of which use jspm.  \naurelia, durandal, mithril, ... \nI haven't really figured out jspm but am excited by it.  This week and next I'm dropping it to focus on SocketStream engine and connect, but then I want to do some work integrating some non-Angular client-side frameworks into the upgraded SocketStream developments.\n. Srsly awesome.\n. 5) enhanced project initialisation configuration set: including (e.g.) option to bundle express server.\n. 6) provide specialised transport+ 'custom request responder' configuration (e.g. low-latency low-overhead) 'out-of-the-box' to enable realtime gaming and associated apps; maybe bundle demo game with the demo chat.  (it would be nice to have multiple transport systems working in parallel.  has anyone done that ?)\n. 7) This maybe a bit too blue sky, but we could start to implement peer-to-peer technologies for optimisations over the server-centric model.  e.g. https://peer5.com/\n. Yeah cool I think this idea --keeping core super sparse and simple and having extensible components which can be added by user-whim to their particular configuration needs-- is great.\nThis to me is reminiscent of the Connect/Express build philosophy where they stripped the core down and moved components out to a thriving middleware ecosystem.\n. > if there was a period of 6 months dedicated to a complete rewrite of SocketStream; one where everything was tested properly, where existing features were complete, where the framework was more modular in design[...]\nYes.\n\nand where updating 0.3 apps to 0.4 involved minimal pain, would that be something that the team would be interested in considering?\n\nWould('nt) this constraint constrain the overall power of the new build ?  \nI would think it worthwhile to continue supporting v3, with incremental improvements, and where v4 or whatever had the freedom to break stuff in its development.  \nAs things stand (could change) I'm edging closer to the time where I can devote a significant daily energy resources to the framework r&d stuff in general.  I'm going to be looking at the Primus components very closely indeed at that time.\nI'm interested to hear more about what you see in terms of integration with these (Primus) and other recent and current development ecologies .. of which there are many, Koa comes to mind, but many more.  Especially interested in hearing more about how and why(?) Primus is built in the way it is, what (?) it can and can't do, what (?) we would like our system to be able to do, and so on, and so forth.\nMore later,..\n. Very well on the no-rebuild position and policy.  I was wondering what the different possibilities are, your take(s) on the system as it is and the system as it could be--under a variety of scenarios.  The essence of planning is considering scenarios after all, selecting one to actualise.  \nSo if I understand the gist here, it is to reinforce and consolidate the v3 build.  Which is I think great. \nIn my opinion it would be great to do both a clean-sheet build, and the v3 line continuance.  We all have time-resource issues though, and a clean-sheet build requires an R&D dance to be meaningful.\nThe R&D dance is my next project by the way, which I've actually already started but had to sideline for a bit.  In that project I'm re-engineering (to learn it, not because I think I can do it 'better') SocketStream, and bring in a bunch of Primus components-- all in the same repository.  My anticipation is that some lessons-learned from that can be transferred back into the v3 line of SocketStream via my fork for non-breaking, subtle/incremental improvements.  And other lessons-learned or forms-discovered could be transferred into clean-sheet build prototypes.\n. (as I think of them): Prototypes aren't re-thought; they are created, tested, evaluated, and in most cases, thrown away.  In an r&d environment, there aren't restrictions on what is a good or bad prototype, other than that-- hopefully-- one can learn something from working with it.\nI have said before (above), that I think the idea of an incremental --'evolutionary'-- development line on SocketStream should be pursued.  I don't think a more radical (r&)development line is exclusive of this though, except perhaps by time considerations.  \nRelated note: I don't think there is any way I'm going to be of much use as a framework engineer (on SocketStream or anything else) without doing the r&d thing in my own time and space.  \nI have a hard time thinking of this as 'revolutionary', or really using that word outside of some kind of political context, or maybe say a really disruptive technological innovation.  It's just development research.  Pretty boilerplate process technology.  And as I said before, I think traditional development planning is constituted --in the first place-- by a dispassionate consideration of available scenarios, and then in the second place -- by the selection of one scenario for actualisation, at which point focus is shifted to scenario-building within the constrained scope of that particular development scenario.\nAnyways, sounds like everyone here is at least interested in the incremental development component-- though of course this is not exclusive (meaning can reside in the same dev scenario) with r&d, nor is it exclusive with the process of consideration of technological context.  Things are changing all the time, so it is valuable to do this a lot.  \nI hope that this makes at least a bit of sense.\n. Cool cool on all ! (will email public ssh key )\n. Ha!  no worries my bad actually I was being pedantic for some reason.  :) \nI agree with you on that.\n. Agree with you on that also !\nKeep the core tiny, and then most of the extra functionality can be added in modularised components like in the Connect/Express middleware ecosystem. Or well-documented \"how-to\" stuff.\nOf course, then it becomes our responsibility to produce those components and those \"how-to\"s.\n. ##### A request for engineering OPINIONS:\nWhat you think regarding webrtc (Web-RTC) ?  \n(e.g.): vs WebSockets ?  Good to have both or can do the same tasks equally well with either one ?  If negative on that, would this be a good idea for a module ( 3rd-party / -ware ) for SocketStream moving forward ?\n. Can we make a Websocket implementation that has similar ~~streaming~~/latency*throughput performance and does peer-2-peer ?  I'm really thinking high data throughput generally for games.  And I want P2P capabilities.\nLike can we start a WebSocket 'server' on one web-client and another WebSocket 'client' on another web-client ?\n. I like the API idea.  (more later)\n. That sounds good and I could do that.  \nI'll still have time-resource issues, and the hangouts won't ameliorate that.  They'll be valuable for other reasons though and I agree a good idea.  \nMy complimentary counterpoint is that we (also) should continue to expand our horizons on the written communication front.  In the software world maybe this could be called a classical (i.e. venerable) tradition.  The old Linux news-groups come to mind, threads composed of long-as-necessary & hopefully well-written messages, providing the basis for organisation and process progress.\nThese aren't mutually exclusive approaches.  I'm happy to chat / VoIP and think it could be valuable.\n. 4th Jan I can do.\n. (UTC) anytime 08:00 to 19:00 \n. Very cool !\nOn Sat, Jan 3, 2015 at 4:46 AM, Robert Hall notifications@github.com\nwrote:\n\nThat works great for me. [image: :+1:]\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68580616\n.\n. very good.\n\nOn Sun, Jan 4, 2015 at 1:29 AM, Paul Jensen notifications@github.com\nwrote:\n\nSeems cool, speak tomorrow.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68613905\n.\n. I have a microphone but no camera. (\u2018venerable\u2019 2009 Thinkpad X61)\u2014 might\nbe an issue. wasn\u2019t able to connect to their server just now.\n\ni\u2019m on Skype as well wylie.joshuacullick or same in Gmail/hangouts, or\nwhatever else. hopefully Appear will work though\u2014 I\u2019ll try again later.\n\u200b\nOn Sun, Jan 4, 2015 at 8:53 AM, Wylie JoshuaCullick \nwylie.joshuacullick@gmail.com wrote:\n\nvery good.\nOn Sun, Jan 4, 2015 at 1:29 AM, Paul Jensen notifications@github.com\nwrote:\n\nSeems cool, speak tomorrow.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68613905\n.\n. ah cool!\n\n\nOn Sun, Jan 4, 2015 at 11:27 AM, Paul Jensen notifications@github.com\nwrote:\n\nYou can add ?video=off to the url in order to disable video (screen\nsharing will still work).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68626626\n.\n. worked thanks!\n\nOn Sun, Jan 4, 2015 at 11:28 AM, Wylie JoshuaCullick \nwylie.joshuacullick@gmail.com wrote:\n\nah cool!\nOn Sun, Jan 4, 2015 at 11:27 AM, Paul Jensen notifications@github.com\nwrote:\n\nYou can add ?video=off to the url in order to disable video (screen\nsharing will still work).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68626626\n.\n. supposed to be here :\n\n\nhttps://appear.in/socketstream\nOn Sun, Jan 4, 2015 at 1:07 PM, Henrik Vendelbo notifications@github.com\nwrote:\n\nsure. Is this a hangout? I don't know where to join\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68629095\n.\n. knocked but no answer\n\nOn Sun, Jan 4, 2015 at 1:18 PM, Paul Jensen notifications@github.com\nwrote:\n\nHave you chaps been able to join?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68629399\n.\n. cool\n\nOn Sun, Jan 4, 2015 at 1:27 PM, Paul Jensen notifications@github.com\nwrote:\n\nOk, we're going to try a google hangout, will send invites via email\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68629613\n.\n. Wylie: email: wylie.joshuacullick@gmail.com\nbtw:i\u2019m hoping to have a fresh devEnv setup going next week, and I should\nshare insights with you then.\n\u200b\n\nOn Mon, Jan 5, 2015 at 4:19 PM, Robert Hall notifications@github.com\nwrote:\n\nHi Everyone, I'm closing this issue since we've created a more proactive\nprocess for meeting and going over roadmap. If you'd like to be on the\nroadmap contact list (for meeting times, notes, etc.) go ahead and leave a\nnote here, and we'll figure out how to get contact info, etc.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68713127\n.\n. oh cool !  yeah i'll try to fill in on tests soon.  i've gotten better in that dept recently.   Mocha / chai / supertest ?  In coffeescript ?  Can I add a gulpfile ?\n. Status of this ? Interested in more info.\n. By views you mean sending gulp itself to the browser ?   Can you elaborate.  Is very intruiging but not clear on precise intention. \n. Okay yeah that makes sense.\n. Ah you got it cool !  I've been meaning to get to this, but also wondering  if anyone else could reproduce the error.  cool !\n. No problem and no rush at all ;}\n. Cool cool I'll do the in depth bug report tomorrow.\nThanks for the catch on the package.json file, I fixed it.\nAlso, I just did npm install fresh- ran into serious problems after that with my templates.\nTraced it to new Lodash (v3); they changed some method names around.  Fixed now.  It should work for you.\nOn the app, it's on port 3000, and pretty much everything interesting happening in the console, but you have some buttons which allow to authorise and deauthorise the user session.  And also to ping the auth-protected endpoint.\nI'll try it with master#head tomorrow and let you know what I find.\n. Right so here it is tomorrow.\nI've fixed laTrappe and so you should be able to run it locally. \nI've created a new clone of it and added the line \"socketstream\": \"git://github.com/socketstream/socketstream.git#master\", to the package.json flie.\nThe detailed bug report without inserting logging debris is Nothing.  There is no error output in the server console, and there is no error output in the browser console.\nLooking at the differences between the html page source as delivered we have:\n\nBad\n<!DOCTYPE html>\n<html lang=\"en\" ng-app=\"laTrappe\">\n  <head>\n    <script src=\"/_serveDev/system?ts=1422795256487\" type=\"text/javascript\"></script>\n    <link href=\"/_serveDev/css/laTrappe_local_alpha/main.styl?ts=1422795256487\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\">\n    <script src=\"/_serveDev/code/laTrappe_local_alpha/entry.coffee?ts=1422795256487&pathPrefix=laTrappe_local_alpha\" type=\"text/javascript\"></script>\n    <script src=\"/_serveDev/code/laTrappe_local_alpha/laTrappe.coffee?ts=1422795256487&pathPrefix=laTrappe_local_alpha\" type=\"text/javascript\"></script>\n    <script src=\"/_serveDev/code/laTrappe_local_alpha/lib/angular-animate.js?ts=1422795256487&pathPrefix=laTrappe_local_alpha\" type=\"text/javascript\"></script>\n    <script src=\"/_serveDev/code/laTrappe_local_alpha/lib/angular.js?ts=1422795256487&pathPrefix=laTrappe_local_alpha\" type=\"text/javascript\"></script>\n    <script src=\"/_serveDev/code/laTrappe_local_alpha/lib/lodash.js?ts=1422795256487&pathPrefix=laTrappe_local_alpha\" type=\"text/javascript\"></script>\n    <script src=\"/_serveDev/code/laTrappe_local_alpha/lib/smoothie.js?ts=1422795256487&pathPrefix=laTrappe_local_alpha\" type=\"text/javascript\"></script>\n    <script src=\"/_serveDev/start?ts=1422795256487\" type=\"text/javascript\"></script>\n    <script type=\"text/ng-template\" id=\"panel.html\"><button ng-click=\"authMe()\">authMe</button><button ng-click=\"deAuthMe()\">deAuthMe</button><button ng-click=\"pingProtected()\">pingProtected</button></script>\n    <script type=\"text/ng-template\" id=\"placeholder.html\"></script><title>laTrappe</title>\n    <meta charset=\"utf-8\">\n  </head>\n  <body ng-controller=\"laTrappe\">\n    <panel></panel>\n  </body>\n</html>\nGood\n```\nhtml\n\n\n\n\n\n\n\n\n\n\n\n<button ng-click=\"authMe()\">authMe</button><button ng-click=\"deAuthMe()\">deAuthMe</button><button ng-click=\"pingProtected()\">pingProtected</button>\nlaTrappe\n\n\n\n\n\n\n```\nI've read through the html delivered and it looks exactly the same.  I'm going to guess that the delivered client code pack invoked by the !=socketstream in view.jade is not happening quite right. Will explore further and get back to you.  It's not so simple as seeing some console output so may be a day or two.\n. Okay,\nhere is the good delivery of the code module: (accessed by ctrl-u for the source in Firefox and then clicking the link on first script.\nhttps://gist.github.com/kulicuu/27206afb11851733d4e8\nThe bad one just gives the error CANNOT GET.  \nSo that's basically the bug report as far as that goes.  \nFor something more substantial, I could hunt around with my console logging gear on the server side.  Will get back to you.\n. ###### Update\nI've made another clone to analyze the new static work, not only to debug regarding this issue but also to see your development line here and to think about how to integrate with new work I'm doing with respect to the React integrations.\n. Hey, I want to find the discussion leading up to the development of the new static strategy; where would that be ?\nOr /and, could you describe -- briefly or at length -- what you had in mind to accomplish with the new static strategy ?\n. Wow, cool code.  Lots of work here, not too sure raison d'etre yet, but lots here and it's very interesting.  Noticed will require some modifications (not too difficult) to bring it merge-able with the new Connect v3.3.4, and some of the files modded are the same.\nHave you been able to reproduce the error I'm encountering ?  Again, it's serving the view but not the Javascript, so the entry file is never initialised.\nlaTrappe should be working now let me know if still any issues there.\n. Okay the problem was with the way I was integrating the Express and SocketStream stacks, as seen here.\nI'm okay with dropping this usage and finding a better way.... at any rate it's on my thingstodo list to implement an upgrade to Express v4 and that will require some reworking anyway.  So I'm going to close this.\nThanks!\n. Ah cool thx.  I'm not done with this engine.io thing by any means.  Still wanting to get feedback from community about enhancements possibilities: including possibilities with binary transport (see @nhitchins notes in #435 ) and running the whole thing in a web-worker.  Sorry haven't done anything last few days, but not just leaving it where it is.  ~~I'll take a look at the v1.51 as well.~~ (looked and looks to be 'no change'; but the client is different, so I'll pop that in.)  thx!\n. This same work is in the newer Connect/Engine PR, so I'm closing this.\n. It's been like that since forever I think.  I haven't used the Commander/terminal interface for some time now, so it doesn't really affect me at present, but it's on my list of things to get to.  After the engine;io and connect.  And after the next client build refactor.  Pretty much the last thing, not so much because it's unimportant as that the implementation depends on particularties of the precursor implementations.  \nI think I mentioned this before: it would also be easy to add a builder option to set up an Express app-- this without adding the Express functionality into the core. \"Loosely coupled modules\", so something like ss-express and an option there.\n. Pretty much so yes. ;]  (also was pointing out  a great line too in some esthetic sense--mixing process with logic--although I generally try to avoid suchlike) \n. In my opinion no.  Paul's response implies concur.\nIt's not a big issue at all -- but it is a small issue, and I'm going through the whole framework now, so thought it would be fun and productive to relate findings.  This was one of them.\n. I've changed the line in pr #478 \n. Cool response.  I'll have to come back to this fresh later for further discussion and exploration.\nFor now I can say more good news: I got the new connect working.\n. I'm listening I think you have the parts I'm missing.  I mean your ideas indicate auspicious devv strategies, seems likely to me.    As for certainties, it's all very preliminary.  Connect 3 is working.  I haven't been able to get my app working on Express  4 yet, would like to see the Gisttt of this.\n. I'm thinking of leaving Express out of my apps in the future.  Wasn't really sure what I thought I needed it for-- just wanted to explore its API I think.  Still I mighth like to get 4 working, to create a how-to doc for it.\n. @arxpoetica  I have this already in the sense that I have the unified Express/SocketStream in all my apps for at least year.  (See britvic)\nYou are right in that many aspects of a system don't need to utilise the websocket.  I was using it (the Express component) first of all the serve single page Angular  apps for gate and authorisation pages-- e.g. why load the entire single page app  to unauthorised users ?\nNow I think I could probably figure out how to meet my needs with just Connect, but people building out large HTTP APIs alongside their WebSocket thing might want Express.  So yeah.\n. I was hoping to close it as it's fixed in PR #486 \n. Cool..\n. Also contains a fix to issue #484 .\n. The Codacy testing thing is a bit annoying.  It's just complaining about mixture of single and double quotes, and some of the things it's complaining about are in the new engine.io client code file.  If those people released it, I'm okay with it.\nLet me know if I should be making sure it passes these tests completely, or whatever.\n. It works now afaik.\nClearly needs ot be more and better acceptance testing, so working on that angle as well.\nI'm ignoring the Codacy thing for now as nothing meaningful have I seen from the reports as yet.\n. I'm going to rework this to bring it into line with @thepian 's work on the new static strategy.  Hopefully will have something in a few hours.\n. ~~I was thinking of something similar yesterday.  Will be thinking about it this next week as going through the whole system.~~ edit For some reason completely forgot to mention the approach of bringing in Connect &or Express for this purpose.\n. One approach I'd been considering but never got around to implementing on the system for which I'd had it in mind was to issue single page apps the way the olde http systems served single views in a system, in the sense that sessions would be shared and redundant resources would get traded off on client-side cache.  The immediate application for this is to have a major distinction between landing page app / 'gate' app, and the main app interface as for authorised 'normal' users.\n. I like the fads, provided they are driven by sound engineering intuition.  I think it's a good sign that we have so much ecological richness in the whatever.  Those that persist -- like Express -- are well honed. \n(Koa sounds cool too -- haven't had time to delve )\n. good point.\n. I don't understand your term dev-time middleware .\n. I'm not sure why I failed to mention this before, but this routing for non-Socket pages is precisely why I went initially to integrate Express with SocketStream, which yields the effect.\n@paulbjensen approach even better in the sense of lighter weight, although I suppose some people really want a full Express app alongside the SocketStream stuff.  Documenting the practice would be great.\nAnyways, I'll be working on the Express4 demo-app and/or docs as I just got that working.\n. I've had good luck with this http://angular.github.io/protractor/#/, and I think it should work for non-Angular apps as well.  Anyways I'm starting a branch to work on this.\n. will use this thread for todo list on features -- i.e. defining the acceptance criteria for SocketStream functionality.\nlist of constraints (prelim draft)\n\nshould serve the app\nmiddleware should be active and (sessions ...)\nsessions should persist over browser reloads \nsessions should persist over server restarts (assuming redis sessions)\nwebsockets should work if availablbe (tests should query engineIo on low level api or something custom to effectively guage)\n[much much more ...]\npack assets verified \nstructured logging server performance under various loads [?]\n. I guess to make a protocol where pretty much anyone can register an app within the e2e folder under like /some_apps/someones_test-app_1/.  \n\nObjections ? (for prototyping anyways)\nWill be interesting because of implications for development environment.  Now my test app will embedded in the repository itself, and local file relations will reflect that; currently my test app (laTrappe) is the parent by way of node_module the socketstream development folder.  So that would be different.\nIndividuals mostly self responnsible for writing e2e test suite for their own test apps.\n. Starting to wonder if better to bring them in as node modules via devDependencies.\nFor now I'm just going to have the entire app under an appLibrary folder under an e2e folder.  Can change to another approach later.\nfound: http://git-scm.com/book/en/v2/Git-Tools-Submodules\n. There's a PR with the solution in submodules.\nI think it will be best.\nbtw as soon as master head stabilises over this period I'm going to be much more disciplined about branching, flow, and keeping synced.\n. I think it's kind of there already, in the sense that the minimally viably productive manifestation of the feature structure on the ~~app~~ framework structure is just to be able to manually do acceptance testing over a range of developers' apps, initially your own.\n. Then you can add automated acceptance testing as you see fit, in a way that's specific to this SocketStream dev environment and your app's structure.  I'll be using Protractor for this particular (angular) client of laTrappe's.  I'll probably keep adding clients to lT in other frameworks-- fashionable experiments.\n. Good to remember in this situation the feature isn't for the notional primary consumer of Ss, but for the developer of Ss.   In that sense especially, recommend to exploit it immediately.\nIt's possibly showing the way forward for development and contributions.  some surprise manifest of TDD in Ss.  \nI've changed my development environment around it[this new feature/structural addition], so I'm in an entirely different folder now locally.  As you can see laTrappe is registered as a submodule, so cloning Ss and then invoking it I can bring it in under that folder code from there and run the app.  It's really cool.\n. Nice.\n. I really don't know enough about this yet to make an informed comment.  Sounds good.\nActually I could make some informed comments, but not really about the implementation yet.  One thing maybe pertinent is my current build paradigm, which completely eschews environment variables, instead making distinct app configurations to be executed under the various contexts (devv, staging, wild, etc).\n. Ah cool yeah I should study that git flow thing more.\nAnd I'll start making feature branches then.  (wait though, are you saying branches can't be terminated when their feature is merged to master branch ?)\n. cool understood.\n. I've fetched this branch, npm-installed, and running laTrappe under it serves fine.\n. I just realised my test was no good, because of the way my new development environment is set up.  I need to adjust it somewhat.\n. This would be unit testing of Ss stuff.  The example apps should have their own unit tests kept in their own repositories; on the other hand and at the same time there would be Ss specific e2e tests related to specific apps and even specific configuration states of those apps which be in the e2e folder -- though I haven't figured out how best to organise that.  There's an \"/appLibrary\" folder already, something like that but for specific e2e testing scripts.  Ultimately, these would be documented in the readme and eventually maybe invocable by npm script or gulp script from project root.  Perhaps some canonical e2e acceptance routine before a big PR.\n. I like the idea of having tests close to source-- in my own work the two are in the same file indeed I write the implementation to be self testing and report its status through the console.  That's for prototyping though, and long term goal is for full unit testing coverage across all relevant levels of abstraction.  Maybe in practice not so feasible, but a little pays off a lot in this area.\nAgain I think it's an interesting idea to have the tests close to the source, and I think it makes intuitive sense; however, in this context I think probably not suitable. Why I think this: It's ideosyncratic the way people test; I have some strategy I like and some particular set of libraries and styles I'll use for it--but wouldn't expect other people to have the same.  So it would make sense to allow this to be loosely coupled, to allow some space for multiple non-exclusive developmental approaches to coverage to emerge... et cetera.\n[...]   I've been reading more on Git's submodules.  Really incredible what can be accomplished working creatively with that tool.  For example this notional unit testing module could be added as a submodule.  One nice feature is that submodules are not automatically cloned in on main module clone.  So if someone clones Ss they don't get my submodules without invoking a specific command to request them.  So they can be fairly unobtrusive, even though their presence (minimally nominally visible) helps document the work that's available.\n. Reasonable position.  I don't agree, but it's reasonable.  One compromise would be to put the whole melange into one major test folder.  If that's not okay then I'm happy to test according to local convention. I'll revisit this point another time.\n. Wow.  I'll have to think about that some days before responding.  I'm really excited about submodules--admitedly I'm new to them, but quite taken with the possibilities.\n. Yeah I'm not contemplating extreme measures or anything, whatever is generally accepted will be fine.  How I use them in my other work another issue.\n. I was definitely still thinking more about the way I'll be doing acceptance testing broadly speaking.  For today at least, the priority is emphasisng development on my fork, organising the branches there, making a partially autonomous staging environment there, which could differ somewhat from the upstream, even though designed inclusive with purpose to send stuff there.\n. Jubilations.\n. Both @jokagent 's and @DeLaGuardo 's libs work fine as far as I can tell; the latter even allows to pass coffee-script files into the mix.  (looking at the code suspect would choke on csx, so more work may be relevant on this angle)\nI'm tempted to close this issue now, but going to research+develop a bit more to see what is possible -- e.g. my next step is to verify that I can pass .csx files through @DeLaGuardo 's system and have them work.  Also to see how the other libraries linked above are relevant to Ss.\nReally should do a small demo as well-- could pass for it to be documented.  \nDo we have some kind of library for canonical demos ? Like 'here is the canonical Angular demo app', etc. edit see it's in the documentation site, just the one for Ember.js.   I could work on a few more; one for Angular would be easiest, but also want to do some with Durandal/Aurelia, Mithril, maybe some others or combos.  Still it would be good to have actual repositories with the demos.  And even link to them from the main readme, if they pass muster of  sorts.\n. thanks & Yes, cool idea.\n. Somewhat off-topic --except for the demo-app discussion-- > \nGood news: I now have Express4 working with the newest SocketStream.\nHaven't cleaned the file yet: https://github.com/kulicuu/laTrappe/blob/sIGG/lT_reactVanilla_local.coffee\nIt was a strange hack as it required starting a dummy server (not the one that will be listened on) just in order to get the ss.http.middleware.stack object.  If that's bad hard on resources maybe could put another function into the http module just to get that object without starting a server.\n. @arxpoetica ha thanks!  Actually my Express4 implementation needs work, but hopefully by early next week a demo will be up. \n@thepian ditto(Awesome).\n. Very nice.\n. Yes.\n. :)  I will find time to contribute to this sometime this week.  May be small, but I will.\n. I'm going to research this-- I confess ignorance.  Interested to read other thoughts here.\n. I'm going to try to look through all this stuff this week.  I'm busy with a new job, but should be able to put some hours to this as well.  Preview: Things with both Connect and EngineIo have changed; but there are a bunch of resolution possibilities for this to maintain your functionality.  I'll have more to say on this as soon as I get a chance to look into it fully.\n. Got it thanks.  I'll get to it as soon as I can -- hopefully next few days. \n. Try ss.api.db.set(\"User\", user) and generally alias it .  Also, maybe quoted string for first arg to api addition : ss.api.add(\"db\", client).\n. [edited ...]  Yes , this is the thing I'll be working on next.  At the moment I'm working on another ss-example -- one using webpack, React, and no CoffeeScript at all, just ES6 stuff (I'm using iojs v2) and babel-loader for the client.\n. > Why do you expect the session cookie to be the first or third cookie? Why not look for the cookie name?\nYes great question. I was actually just doing a version that looked for the\ncookie name by for loop, but it wasn\u2019t working for some reason, so wanted\nto add this his is a quick patch. The reason it\u2019s looking for the first or\nthird is that when I was last doing SocketStream development (two months\nago), on the first uncached load the cookie was different than on\nsubsequent runs. I\u2019ll have the name-checking version working a bit later.\nSorry, I\u2019m quickly getting back up to speed here, but just second day.\n\u200b\nOn Tue, May 5, 2015 at 1:52 PM, hulmgulm notifications@github.com wrote:\n\nWhile trying to figuring out our problems with socketstream (\nhttps://groups.google.com/forum/#!topic/socketstream/lCZRU2whpQw) we came\nacross this code too. Why do you expect the session cookie to be the first\nor third cookie? Why not look for the cookie name? Then it doesn't matter\nin which order the cookies are set. According to the error message at the\nend of this function, the cookie should always be connect.sid.\nWe were setting additional cookies a few days ago which led to strange\nproblems like \"undefinded\" or \"true\" as session id. Or to constantly\nchanging sessions ids.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/pull/537#issuecomment-99031860\n.\n. I need to figure out if something changed with the some of the engine dependencies or some intervening code.  (It will be slowly, slowly while I review two months of commits and changes.)\n. Okay it's name detection now.  Works for me on Firefox, Chrome and Chromium. \nMaybe it's the browsers were changing in the meantime, I have to go look at engineio client.  Anyways I think it's good now.\n. fixed., also had to add the trim() for the connect.sid comes with a leading whitespace if you open from a new fresh (or private) browser window.  The cookie is processed differently on subsequent requests.\n. https://github.com/socketstream/ss-examples/tree/master/react-and-coffeescript\n\nI didn't use the CLI script -- don't typically.  Just built the relevant file structure.  Also note there is not a SocketStream dependency listed in the package.json file.  You will want it there or to clone manually (+ npm install) in your node_modules folder, which is what I do in order to develop on SocketStream simultaneously with work on the example app stuff.\n. Yay !\n. Nice info thankyou  ! and it's great to know we have Koa compatibility.\n. I'm getting problems also with the bundling.  I notice in the console \nError: ENOENT: no such file or directory, open '/home/wylie/terebinth/site_card_0/client/static/assets/another/EyeZlTXnN.html'\n18:41:55 web.1  |     at Error (native)\nit's looking for a different file than the one actually created by the bundler, which in this case (verified through Nautilus) is Vye19bNnV.html.\n. The client.id injected into /lib/client/http.js is bad.  \nThe clients argument passed to http.js from lib/client/index.js is an empty object.  Shouldn't it be populated with the defined clients ?\nI may have a fix tomorrow.\n. Even more unpredictable behaviour from the bundler upon casual console based testing today.  All indications are I should step back from the console based testing as it will not be time efficient--long term better to focus on the unit testing and concomitant improving of the understanding of the higher level structure of the system -- in this case the client module. \nIt's been so long since I even ran the unit tests we have -- how is this done ?  I know it's Mocha.  Could we put a readme.md in the /test folder documenting testing structure, strategy, invocation etc ?  Would be nice.\n. ah thanks.\nWould like to document the running of individual test suites, stuff like that.\n. @thepian I know mocha stuff, but documenting it in a readme.md eg:\nhttps://github.com/kulicuu/britvic/tree/master/mocha\nLike it's a good idea to be able to run different suites at different levels checking out individual modules or sometimes working relations between them.\n. background info: (I recall  before all the upgrades to the strategies a hack in the main app file was require to have the sessions automatically transfer over-- something like appending the Express middleware to the SocketStream http stack.  It was never automatic in my experience. [edit: I was using Express added onto the stack back then; don't recall if the native http routes were linked sessionwise with the ws] After the changes this hack was no longer working, so need to find something else... which is fine because the hack was ugly to begin with; it should just be default behaviour.)\nI'm looking into this now.  If anyone is available to chat on gitter about it I'm interested in getting more info about the issue.  \n[update] I've left some investigation notes on Gitter if interested.  tldr: I see the issue basically and sure it has solutions but not so sure which one would be optimal.  Waiting for feedback but will look into it more meanwhile.\n. There are two closely related but distinct issues here.  \nOne has to do with SocketStream's built-in http sessions (connect) handling and the extent of its sharing with the ws (engine.io). [edited Date.now()]  \nThe other, as in the Koa thread above and my own reported issue here at issue 475, has to do with bringing in another library (e.g. Express, Koa) and merging its stack / routes / sessions with SocketStream's.  \nIn the second case, the old community hack(s?) was(ere) broken by the new strategies' code.  I don't see that as necessarily a bad thing, if there is a better way we should be doing it. basically my position at the end of #475 .  Once I realised the source of the bug I just removed the hack and figured that I would figure out a new one when I had to.\nIn the first case, we should definitely have sessions shared in a way that is well-engineered, and will additionally provide an easy way to accomplish the first issue.  Please have a look at the gitter thread for notes, and I'll be online to work/chat on this on Sunday during the day (UTC+2 ) to discuss and hopefully generate a good design solution.   Maybe.  Anyways I'll be looking into it this week.  I'm still kind of not completely familiar with the way all the code fits together.  Yesterday I was browsing the client build stuff to do a new bundler for webpack, and I know that part even less well than the ws and sessions stuff.  I need to diagram I think on paper, which is something I don't do enough of to be really good at ( produce meaningful insight generating diagrams of the abstract machines ). Also I read recently some advice to print source code out on paper, spread it out on a table.  Maybe cut and collage.  ...or just develop better visual memory ... anyways I look forward to chatting hopefully on gitter next week. \n. So I looked into this today.  Once again, I got into the bad habit of just scrambling around through the code like a maze, logging lots of things and watching things happen.  A bit of this is good, but it's just hacking, and as discussed above, what I really need to do is about half that, and then half actually taking the time to diagram the macro picture to properly model the machine as a whole.  Failing to do this, even if I were able to hack together a solution to this or that particular issue, just fails to see forest for the trees and would almost certainly fail to generate good design going forward.  I need to be a bit more patient and once again tomorrow try to model the whole picture -- outside the monitor, on paper, on the table.  \n(this of a much larger and more general (not just SocketStream) conversation/issue I've been thinking about and had to deal with recently in my work, (involving massive failure of a product))... Reengineering issue... check out the book \"Object Oriented Reengineering Patterns)\nThat aside, I think I see the issue. The http module (in the new strategies implementation) seems to create its own session implementation, whereas according to the design of the system, this is the responsibility of the session module.  Http is just supposed to use that, as is the websockets module.  \nClearly a lot of uncoordinated hacking has been happening leading to confusion there and mismatch.  \nI'll be on it tomorrow again.\n. Yes, I'm learning about signed cookies.\n@hulmgulm thanks for the code snippet above.  very good clues.\n. Okay I got it (I think so anyway). Had to set the sessionId to signed cookie value in engine.io thing.  Going to lunch now.  Will clean it up and maybe PR this afternoon. \nQuite.\n. I think this has good fix now with most recent merge, would like to hear results of verification.\n. Right cool, so the problem was something arcane to do with the way cookies are actually handled in this case.  They're signed for security by cookie-parser, but the session handling initialisation for the engine.io wasn't parsing them back to the id that would enable lookup of the session.  So, the initial solution (yesterday) simply used cookieParser's signedCookie function to parse that back in the processSession function in the engine.io transport, with the secret baked in.  Today I added the secret attribute to the session's options object (this can be edited from the main app file with like ss.session.options.secret = \"newSecret\";), and in the websockets loader function in socketstream.js I added session.options to the arguments, and additionally edited all the functions in the chain to the processSession function in engine.io transport index.js.  That's pretty much it.  I alias console.log with c to make it a bit faster to quickly log and unlog a lot of things.\nSome other notes (as they occur to me):\n- There is no need for a setter function for session.options.secret.  It can be edited in the main app file directly as above.  Should be before starting the server , as that's when the loader function are called.\n. Nothing so interesting.  I established a default value for secret in the session (for cookieParser) options.   You can alter it before creating/starting the server.  Before when I'd upgraded the engine.io and connect, I'd neglected to handle the cookie the same on both parts.  So I'm just cleaning up a bug I introduced.\n. I only had to set the secret once.  It's been a couple of weeks.  I'll have a look at it tomorrow.\nI used t.session.options.secret = \"someNewSecret\", like ss.session.options.secret = \"someNewSecret\" once in the main app file. \nhttps://github.com/socketstream/ss-examples/tree/master/react-and-coffeescript\n I think it goes to both, which is why the sessions are now shared between http and engine.  I tested very manually, with console.log and some diagnostic calls from my example app; the thing I should be obligated to is implementing some write-behind-testing unit testing for this. And then later really it's the e2e testing which was a long term goal.\n. I should mention also, it's confusing when the argument name in the invocation is different from the argument name in the definition.  In this case it's api in the invocation and ss in the definition.  It should probably be api in the definition as well.\n. Issues with the fix:\n- The secret \"SocketStream\" is hacked/baked in.  It should be injected as an argument.\n- ~~Testing http requests fresh to the same route '/', I get the same session as the websockets, but when testing other routes, it's not the same.  So there is more work to be done there.~~ Testing just now looked good, but, needs more testing on http routes and sessions.\n. I think it's good now but would like to hear test results from you.\n. @thepian  I'm not sure what you mean about examples or bundling.  \nI'd like to add this library to the package.json for use in SocketStream's server side development.  It may have no use on SocketStream's client side, but I suspect it will.\nEventually I'll elaborate the case here -- for now I just wanted to introduce the idea / solicit feedback and conversation.\n. [a bit more about this]\nFor a long time I'd been deferring learning functional programming properly.   Or declarative vs imperative.\nI've been reading this blog a lot \nhttp://bartoszmilewski.com\nI've also been immersed in a lot of reengineering projects, in particular really a long term thing with a C++ codebase.  \nI considered maybe SocketStream might benefit moving forward from implemention leveraging these tools.  Clearly I can create branch of my fork devoted to it and start there -- but also wanted to hear from you about it.  Also, if the dependency were there on the master branch, it would be possible to (feet wet) start using the API in a small way experimentally, before making really more drastic changes.\n. I don't think there would be any improvement implementation-wise.  (I wonder if) Structure and organisation of the code might be improved substantially; better maintainability.  Just a hunch based on current research.  Really just a guess and indication for more research and experimentation.\nfrom\n\nI am sometimes asked by C++ programmers to give an example of a problem that can\u2019t be solved without monads. This is the wrong kind of question \u2014 it\u2019s like asking if there is a problem that can\u2019t be solved without for loops. Obviously, if your language supports a goto, you can live without for loops. What monads (and for loops) can do for you is to help you structure your code. The use of loops and if statements lets you convert spaghetti code into structured code. Similarly, the use of monads lets you convert imperative code into declarative code. These are the kind of transformations that make code easier to write, understand, maintain, and generalize.\n. also see:\nimmutable-js#the-case-for-immutability\n\nI don't mean to distract from more prosaic near-term goals.  I've really been hit hard with some reengineering problems recently, and high level issues of how to develop complex software systems is very much on my mind these days.  Could say I've adopted a paradigm of continuous reengineering. \nI'm looking at how SocketStream works in some detail, and thinking about ways that it could work better.  Especially given newer tools and techniques.\nGiven SocketStream's current implementation state, there may be exactly zero advantages to such changes other than code organisation, practically merely an esthetic consideration.  On the other hand, such improvements in structure may improve extendibility.\n. For now I'll branch on my fork and play around with it.  I will be looking for examples that I could share here, as you've indicated.  \nmore links list: (will add as find)\n- https://discuss.reactjs.org/t/examples-of-stateless-components-immutable-stores/277/2\n. no stress :)\n. I will contribute to this next week.\n. etstream/lib $ grep -R \"secret in engine.io\"\nwebsocket/transports/engineio/index.js:  c('secret in engine.io', secret);\nmy bad.  I would need to pull latest and some associated tasks before PR for it.\n. fixed at\nhttps://github.com/socketstream/socketstream/commit/495229c25a72de0bf30cfde1c2e2fe6991dd2f9b\n. Why not just make the core router use Connect ? \n. This shouldn't be a problem.  I will attempt an implementation this week.\n. Agree this is critical.  Another I'm interested in, though quite a queue already.\n. The same issue arises now, but the underlying engine is called engine.io\nGoing through the source code under ./node_modules/socketstream/node_modules/engine.io/ looking for something similar to change.  Not happening yet, but learning a bit by reading the code.\n. I want to work on this feature and the whole client bundling module devvs, after doing the connect stuff, which I'm working on this week.\n. This is good to know.  I'm doing some stuff like this in prototypes.\nRight so basically I'm working on something which encompasses this or at least overlaps with this feature request; I'm working on being able to 'publish' server side events.  This feature would be a subset of the use case set.\n. sorta re-opened an oldie:\nhttps://github.com/socketstream/socketstream/issues/252\n. Yes, exactly the same one.\n. This sounds very interesting.  Code snippet of example usage possibility?\nOn Thu, Oct 24, 2013 at 1:54 AM, Paul Jensen notifications@github.comwrote:\n\nThanks. At some point we'll want to document this in the guide, and give a\ndescription of the pros/cons\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/407#issuecomment-26953344\n.\n. I started playing around with this.\nSo for example when it says it expected '===' and only sees '==' I go into the file and change that ?\n. I'm assuming we're trying to return the assignment instead of the conditional as it keeps suggesting.  Any way to turn that warning off? \n. I'm doing the /lib/websocket/transport.  But also started doing some of the http until I saw you already finished that.\n. say Yak, weren't you going to add me to some sort of documentation repo thing?\n. ah thx!\n. Very nice!\nAlso sheepish here.  --been subsumed in new works... (probably was also embarrased to contribute anything too amateur in front end)\n. Great!\n. Yes, although only generally at this point. The engine.io migration turned out not to require such a major change.\n. This is a cool idea.\n\nIt does seem like work should continue on 0.3x, which we are already using\nto deploy systems on.\nIf that's continually improved, and there is possibility of a smooth\ntransition to a 0.5 version from that, well, great!\nOn Fri, Jan 17, 2014 at 3:32 AM, Robert Hall notifications@github.comwrote:\n\nI want to have a conversation around this. (@paulbjensenhttps://github.com/paulbjensen\n@socketstream-owen https://github.com/socketstream-owen) I'm starting\nto think it might be better to just focus on milestones in changing the\ncurrent 0.3.x versions. What I propose:\n1. Continue working on 0.3.x, providing fixes, patches, etc., and not\n   breaking compatibility with current releases.\n2. Abandon (yes, entirely) the 0.4 work\u2014even though there was so much\n   love that went into it\u2014this might feel like killing a sacred cow, but hear\n   me out\u2014\n3. Any forward work branches directly off 0.3.x. However, instead of\n   the next major release being 0.4.x, lets name it 0.5.x to avoid any\n   confusion. 0.4 will just be like that empty floor in a building that\n   everyone always passes and wonders what its like...\n4. Work going toward 0.5 can be forward thinking\u2014we can pick and\n   choose what we change, what is and isn't backward compatible\u2014but unlike\n   0.4, 0.5 at least maintains some similarity and parity with what went\n   before. This way people who have been using 0.3 in the wild won't feel like\n   it's a completely different system and will be familiar and comfortable\n   with the changes. It also helps toward development in all those regards.\nWhat you say?! 0.4 as abandonware? Well, yes, but that doesn't mean all of\nOwen's awesome work has to go to waste. Rather, we can slowly pick apart\nthe work he's done in 0.4, picking and choosing more carefully what is\nwanted (instead of a rapid departure), and over several releases/milestones\nget closer to what was intended in 0.4. Think of it like what happened with\nXHTML 2\u2014it was a good attempt, but ultimately a total revamp was needed,\nand that was the brilliance of HTML5. HTML5 didn't start all over\u2014it built\nline upon line\u2014but the end product is completely different than what went\nbefore.\nI'm hoping to engage in a serious conversation about this. I would love to\nstart focusing again on ONE unified product, and not feel split down\nthe middle. Its just too hard to focus on several products, let alone one.\nAs a final note, remember, I'm not saying lets throw out all of Owen's\nawesome 0.4 work. Lets just recalibrate and rethink a plan of attack that\nhelps people contribute in a more focused way\u2014\nEspecially with @RomanMinkin https://github.com/RomanMinkin's awesome\ndocumentation setup. If we follow this new plan, I think we'd be ready to\nreally have an epic do-over.\nWhat does everyone say?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/425\n.\n. I think Yes.\n. I can look into this anew with the new EngineIo configuration.  I don't understand everything about the use case and requirements for API.\n. What is the issue here ?  Looking for more elaborate explanation of the technical situation.\n. winstonLogg= new (winston.Logger)(\n  transports:[\n    new (winston.transports.Console)({colorize: true})\n    new (winston.transports.File)({filename: './winston.log', colorize:\nfalse, maxsize: 2000000})\n  ]\n)\nss.api.log= winstonLogg.info\nc= ss.api.log\n\nOn Tue, Feb 4, 2014 at 1:54 AM, RomanMinkin notifications@github.comwrote:\n\nHi Evan,\nThanks for doing this, right now we are focusing on linting/testing (#408https://github.com/socketstream/socketstream/issues/408)\nto be able to work with PR more efficient.\nLong story short, would be great if @paulbjensenhttps://github.com/paulbjensencan also take a look, my concern is that we do not have test coverage for\nthat part of code.\nI think passing ss as a parameter around doesn't seem right. Maybe there\nis a way to use dedicated file let's say log.js, require it around with\nnode.js require and in the end assign it to ss object. Then i think it\nwill not be necessary to pass ss.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-34015633\n.\n. Will I encounter problems doing it that way?\n\nI'm doing a Nodejitsu deploy now and having lots of issues with logging,\nbut not really sure where they come from.\nOn Tue, Feb 4, 2014 at 5:03 PM, Evan Lawrence-Hurt <notifications@github.com\n\nwrote:\nThanks Roman, I'll look into options for not passing ss as a parameter and\nlook forward to @paulbjensen https://github.com/paulbjensen 's feedback.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-34067286\n.\n. ah nice.  thx!\n\nOn Tue, Feb 4, 2014 at 6:08 PM, RomanMinkin notifications@github.comwrote:\n\nHi @kulicuu https://github.com/kulicuu,\nNot really =) The problem is that code base has mix of console.log, ss.log,\nect. calls. So we need to replace them all with common log API, which could\nbe hook to whatever developer wants to hook it or just stream into stdoutand\nstderr.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-34075222\n.\n. I'm getting these errors on a Nodejitsu deployment.  I think may be related.\n\n[02/13 09:23:18 GMT+0200][err] TypeError: Object function (msg) {\n[02/13 09:23:18 GMT+0200][err]       // build argument list (level, msg, ... [string interpolate], [{metadata}], [callback])\n[02/13 09:23:18 GMT+0200][err]       var args = [level].concat(Array.prototype.slice.call(arguments));\n[02/13 09:23:18 GMT+0200][err]       target.log.apply(target, args);\n[02/13 09:23:18 GMT+0200][err]     } has no method 'info'\n[02/13 09:23:18 GMT+0200][err]   at start (/opt/run/snapshot/package/node_modules/socketstream/lib/socketstream.js:90:13)\n[02/13 09:23:18 GMT+0200][err]   at Object.exports.start (/opt/run/snapshot/package/node_modules/socketstream/lib/socketstream.js:132:46)\n[02/13 09:23:18 GMT+0200][err]   at Object. (/opt/run/snapshot/package/rubiaceae.iced:260:4)\n[02/13 09:23:18 GMT+0200][err]   at Object. (/opt/run/snapshot/package/rubiaceae.iced:4:1)\n[02/13 09:23:18 GMT+0200][err]   at Module._compile (module.js:456:26)\n[02/13 09:23:20 GMT+0200][out] FIXME production mode\n. It's running locally (even with NODE_ENV=production npm start) and crashing completely in NJ.\n. Dashku is on AWS right?\nOn Thu, Feb 13, 2014 at 11:38 AM, Paul Jensen notifications@github.comwrote:\n\nHi,\nI've tried replicating this error on Dashku's staging server, but it\ndidn't occur.\nHas anyone else encountered this issue?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-34961990\n.\n. I deployed same code to Heroku and no such issue.\n\nmany other issues, but not that one ;/\n. As posted in the SocketStream groups, I can't log in through the session\nbased system.  It just fails.\nIf I log in through the token based system I setup it works but the\nWebSockets handshake fails.\nhttps://groups.google.com/forum/#!topic/socketstream/luRxlDoso3g\nOn Sat, Feb 15, 2014 at 9:09 PM, Paul Jensen notifications@github.comwrote:\n\nHi Wylie, thanks for the update. What are the Heroku issues?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-35164654\n.\n. More: The setup for my app is a tiny bit complex:\n\nFirst of all I startup an Express server and attach SS to it. ( I might\nlike to run this code by you to see if it stands up. )\n1.\nAt root request I don\u2019t serve an SS client, I serve a Jade file I put in\n   a /views folder parallel with /server and /client. This is a simple angular\n   app all built into a single Jade file.\n    2.\nThat\u2019s basically an authorisations page, and if successful the client is\n   served an SS client. I have two login forms on that first page, one which\n   works via normal sessions and the other which works instead with tokens.\nThat\u2019s basically it. In the SS client I\u2019m connecting to remote Redis\ndatabases and running queries via rpc. (checking if username is already\nregistereed sort of thing)\nEven in local runs I\u2019m connecting to remote Redis instances. Open Redis,\nRedis-to-Go, IrisRedis. All three.\nOn Sat, Feb 15, 2014 at 9:19 PM, Joshua Cullick joshua.cullick@gmail.comwrote:\n\nAs posted in the SocketStream groups, I can't log in through the session\nbased system.  It just fails.\nIf I log in through the token based system I setup it works but the\nWebSockets handshake fails.\nhttps://groups.google.com/forum/#!topic/socketstream/luRxlDoso3g\nOn Sat, Feb 15, 2014 at 9:09 PM, Paul Jensen notifications@github.comwrote:\n\nHi Wylie, thanks for the update. What are the Heroku issues?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-35164654\n.\n. Okay I fixed issue number one in Heroku which was not being able to log in via the sessions auth way.  I hadn't had the Connect-Redis variable set correctly to the Redis-to-Go instance I'm using.\n\n\nBut the WebSockets issue is still bad.  It's not working either way.\n. Again, this is the error:\nWebSocket connection to 'ws://whispering-bayou-3276.herokuapp.com/engine.io/default/?uid=0xxxxxxxxxxxxxxx126&transport=websocket&sid=1JxxxxxAC' failed: WebSocket is closed before the connection is established. bartrgate2:1\n. Oh (shite) you just reminded me that's an add-on with Heroku !!!:)\nYeah I knew they didn't support sticky-sessions. It was you (many moons\nago) that clued me into the issue then.  I'd deployed with them before and\nhad upped our position to use two Dynos.  That was when things went bad.\n Back to one and it was fine.  This time I'd just forgotten they don't do\nWebSockets by default only by addon.\nOn the subject of sticky-sessions, there seems to be some kind of\nphilosophical division opening up.  Heroku doesn't want to support\nsticky-sessions, which sort of means they don't want session persistence to\nbe maintained strictly server side but rather passed around in tokens a la\nJsonWebTokens (the links mentioned in the SS-Ggroups post).\nI'm doing both tokens and the traditional session variables (connect).\nI started playing with tokens more or less by accident when I couldn't\nfigure out how to get my non-SS non-WS Angular 1-page-app to work with our\ntraditional sessions protocol (I've since figured it out.)\nI'm not really sure which route I'll take, maybe depends on the host.\nBtw Heroku is AWS, what does that mean to you ?\nAnd how is Linode ?  I'm going to try them this week.\nAnd what do you think / guess might be the issue with NodeJitsu?  Are they\na functional host or pretty erratic ?\n&c...\n:)\nOn Sat, Feb 15, 2014 at 9:54 PM, Paul Jensen notifications@github.comwrote:\n\nHi Wylie,\nAre you using Heroku's websocket support?\nPreviously, we had to use long-polling to handle working with heroku, as\nHeroku does not support sticky-sessions. See this link:\nhttps://coderwall.com/p/h2swda\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/430#issuecomment-35165993\n.\n. So I added the addon and no WS errors now.\nI'm still not getting anything back on my rpc queries, which probably means it's not connecting to my database or something.  It's a Redis-to-Go instance, but not provisioned through Heroku.  I thought I should just be able to connect to it through the same variables I use locally, which worked also for Connect-Redis.  But it does not seem to be working.\n. I'm using the 3.11 snapshot.  I switched awhile ago to the bleeding edge versions for the Angular templates stuff to work.\n. I was using attribute 'auth' instead of 'pass' for the password so it wasn't loading right.\n. It's not choking on any of my logs anyways, but on the\n\napi.log.info('Starting SocketStream %s in %s mode...'.green, version, env);\nline.\n. I've completely abandoned the Nodejitsu deployment as the Linode is working\nand offers much control.\nFor you \u200bI just tried a jitsu deploy and it again didn't go through again.\nStill no idea why, the Heroku deploy worked fine.\nThe only reason for the Heroku deploy was to demonstrate that it's a\nNodejitsu specific issue, and I'm no longer maintaining the Heroku\ndeployment.\nLinode mainstay for now, and if we need some backup deployment situation\nI'll try AWS, but for now I'm going back to actual programming having spent\nover a week on deployments.\nOn Wed, Feb 19, 2014 at 4:25 PM, Paul Jensen notifications@github.comwrote:\n\nHi @kulicuu https://github.com/kulicuu,\nCould you let me know if you're still experiencing this issue?\nThanks.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/433#issuecomment-35503388\n.\n. Strange, I've encountered this error now on Heroku, and also locally.\n\nI had an app up on Heroku which was working last month.  I took it down but someone asked me to redeploy it. \nI did redeploy, and got the error mentioned above (\"[...] has no method 'info'[...]\"), even though it was still running locally fine.\nI had been using most up to date SocketStream commits in the package.json, (\"github blahblah #master\"), so then I tried rolling back to a previous commit based on idea that maybe there had been breaking changes since then.  After running 'npm install' and 'npm start' I had the same 'no method info' error running locally!  Then reverted package.json to use #master again and ran npm install again and npm start:  same error again on local ! Even though it had been running fine with all of those variables less than one hour before.\n. Is it possible that 'npm install' doesn't detect when the branch master is updated and so doesn't refresh the build when new commits are made?\n. Reverting to this commit b4df865d9936b429bb8469004518e06836a792b8 (Roman Minkin's of Feb 3rd or so) fixed everything on local run and also for Heroku.\nProbably for Nodejitsu as well.\nI think there is some issue with the pluggable logging additions.  Maybe if no one else has these issues though something to do with the combination of those additions and my code... Worth looking into.\n. ```\nwinstonLogg= new (winston.Logger)(\n  transports:[\n    new (winston.transports.Console)({colorize: true})\n    new (winston.transports.File)({filename: './winston.log', colorize: false, maxsize: 2000000})\n  ]\n)\nss.api.log= winstonLogg.info\nc= ss.api.log\n```\nI did these right before the pluggable logging stuff started happening.  I haven't really fully addressed changing it before now, partly because of time and partly because wasn't fully sure it was source of problem.\n. I do recall during the Nodejitsu trials taking this stuff out and error still occurring. \nDuring those tests I removed the Winston dependency and returned all my logging to normal console.log calls.  I might have missed something.\n. In my main project I've dropped Winston entirely and it's just\nc= ss.api.log in the main app.iced file.\n. Removing Winston from the loop fixes things on local but oddly not on Nodejitsu.\nIt would be nice to use Winston with the new pluggable logging additions...\n. Off-topic :: but on subject of SS deploys to Linode :: Thoughts on custom\nNginx front vs something like Forever/-> PM2 or even Phusion Passenger  ?\nI'm halfway in between the latter two : PM2 handling pretty raw SS (https\nimplemented in the app file) but also testing out Phusion, which is\ninteresting.\nOn Mon, Feb 17, 2014 at 8:34 PM, Paul Jensen notifications@github.comwrote:\n\nMerged #434 https://github.com/socketstream/socketstream/pull/434.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/434\n.\n. nix Phusion, their convention is overly opinionated, and in the wrong way.\n\nOn Mon, Feb 17, 2014 at 8:38 PM, wylie joshua.cullick \njoshua.cullick@gmail.com wrote:\n\nOff-topic :: but on subject of SS deploys to Linode :: Thoughts on custom\nNginx front vs something like Forever/-> PM2 or even Phusion Passenger  ?\nI'm halfway in between the latter two : PM2 handling pretty raw SS (https\nimplemented in the app file) but also testing out Phusion, which is\ninteresting.\nOn Mon, Feb 17, 2014 at 8:34 PM, Paul Jensen notifications@github.comwrote:\n\nMerged #434 https://github.com/socketstream/socketstream/pull/434.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/434\n.\n. I'm interested, because I'm supposed to be coordinating right now with an\niOS developer to connect to my SS app as David Zhang discussed in the GG\nthread a few months back.\n\n\nWe're using SocketRocket, and he says I need to provide him with a client\nid?\nI need to give him something for the initial handshake?\nI need with this information to write a custom request responder?\nCould point me in the right direction?\nI'd be happy to look through the relevant code.  As before, my low level\nchops are not there yet, but...\nOn Mon, Feb 17, 2014 at 8:33 PM, Paul Jensen notifications@github.comwrote:\n\nHi,\nI've recently had to update engine.io as part of chassis.io (an engine.iowrapper library), but I haven't got round to sorting it out in SocketStream\n(yet). I welcome any efforts to help out with this.\nWRT the client change, #360https://github.com/socketstream/socketstream/pull/360may be of interest.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/435#issuecomment-35310729\n.\n. This is interesting. I'll help.\nI'm on 'job-market' now so have much more time for this stuff.  My other project is to bring SocketStream's Connect version up to ~3 -- ultimately to make it easier to use Express v4 with it.\nHopefully I can find time to address this one as well, and eventually to bring everything up to date.\n. :) most welcome!\n. So might as well target v1.3.1 as of August 27, 2014.\n. Just started on this today:\n- I'm working on bringing it to 1.4.3\n- If okay, I'm going to use this thread as discussion and notes storage for this process.  If not okay, maybe I'll start another issue and/or run a wiki page devoted to the process -- it's involved and lots of design decisions are available.  I just noticed in the engine.io-client History.md that as of v8.2 engine.io on the client runs great on (web)workers.  Stuff like that is crucial.\n\nhttps://github.com/Automattic/engine.io-client/blob/master/History.md\nhttps://github.com/Automattic/engine.io/blob/master/History.md\n. As for OP (on subject of cookie sent in headers): in 1.4.3 there is a direct sid attribute on the socket.transport now.  Still getting errors or the client... a ways to go yet... but hopefully next few days can maybe get something working. I do have time now.\n. Hilarious, I didn't realise until 5min ago that the client.js file(s) were of the engine.io-client.\nI almost have this working already.  (i think... ;0 )  In the primitive hacked-together sense.  \nHandshake is working and the ~~client is receiving events~~.\n~~Client isn't able to trigger RPCs yet. I think/hope by tomorrow that should be good.~~ \n~~Reversi: It is able to trigger RPCs, actually events are not yet happening perfectly.~~\nBoth events incoming and outgoing RPCs are now working.\nWorking on \"beta_meddle\" branch of my fork.\nI'm using this laTrappe for testing.\nAt the moment I've changed the clientFilename to \"client.js\".  Lot of hacking in \"engine.io/index.js\" also, to good effect.  Will clean up after I'm done.\n. Wow, this is going extremely well.  Almost completely working.  I'm rewriting the wrapper.js file now.  Actually just hacking it together-- proper rewrite / refactor over next couple days.  Very excited to see this coming together so fast!\nOkay it's all functional now.  I'll do a cleanup and refactor tomorrow hopefully will have something ready for a pull request tomorrow.  My branch is off of this (dec 16ish) commit : c0b41fea325b2cbda20e9d187bff864224894f50\nWill need to do some work for the merge (and bughunting) with the later stuff.\n. '@'everybody: THANKS!\n@nhitchins :\n\nre bughunting:  the bughunt I was referring to there have to do with later commits on the master than where I pulled my branch from.  Basically, the other day I started doing SocketStream devvvs for the first time in a long while and started a new fork, and found -- much chagrin -- that the latest master commits fail to load and run my app successfully.  So the branch that I'm developing this engine.io stuff on is branched off from a the commit of dec16 from the master branch.  Now, since I'm assuming that the later commits contain good work, there remains the issue of troubleshooting what troubles have creeped into them.   \nre binary websockets: first I've heard of it. (after reading a tiny bit about it) Sounds great!  It looks like engine.io supports this, so of course I'll consider supporting it to be part of my job here.  At least to give it a good start.  \nother stuff:  As well as binary websockets, there are likely a lot of new features to leverage.  As I mentioned in a post above, the one that really caught my eye was that as of something like v8.0 engine.io-client can be run in a web-worker.  ~~I would assume that this would be a good way to go, but really my deep low-level browser knowledge is not so expert, so would love to hear opinions on this... but my impression is that this would offer developers substantial performance benefits.~~  ~~Researching further I think it runs in web-worker by default ?~~ Looking into this now. [...] Is the whole SocketStream client side running in a web-worker ?  is what I'm trying to grok now.\n. Wish list on engine.io websocket binary API structure ?\n(RPC/serverSocketStreamAPI/client)\n. @nhitchins \nNo gotchas yet, but there are a lot of changes and I'm taking my time with verifying edge cases and pulling all the elements together.  One of the things I'm doing today and next few days maybe is making sure  the debug mode will work.  That's changed a lot so it's something I'm looking into integration-wise.  That's just an example.  A bunch of little things like that.\nautomatic compression sounds great.  doing everything in binary i'll hold off on this week-- but for sure will be thinking about implementation strategies.\nWeb-workers :  Yeah me too-- interested to hear opinions on this.\n. A deep thinking about sessions persistence is the meditation of the week.  Prototyping a tokens-based approach one of the first tasks.\n\nThe new engine.io implementation websockets connection doesn't persist over server restarts or browser reloads.\n. I have engine.io v1.5.1 working with persistent sessions now (I had overlooked something obvious).\n~~I'll have a pull request ready in within an hour (need to clean up the .gitignore file and commit).  Sorry about the false start, ...~~ it's ready.\nWill need to test more, and am still definitely working on the deeper overhaul stuff across the board, but happy to know this has come together unexpectedly.\n. Ah cool I see the issue has been renamed with more elaborate specification.  ;]\n- in the client running the system in a webworker is default automatic..\n. It's upgraded very well, but not yet leveraging all new possibilities.  This will require some design insight and decisions on your (plural) part.  I'm also full-time into a new job, so absent for a bit.\n. This is very interesting.\nI'm not really expert enough to respond in detail but hopefully others will.\nYour recommendations on structuring the client side especially seem promising, but again, I'm not resident expert yet.  I hope some others weigh in.\n. I see my issue but not sure how to fix it yet.\nIn my rpc files I have a require statement at the top: ss= require 'ss'.\nI realised after looking that none of the demos and other projects floating around have this.\nI removed mine and it complains that ss is undefined.  So something in my main app file configuration probably.  I'm using Express and have a lot of configuration middleware details with Connect, https, etc.\n. Some combination of things.  I've gotten the server side fixed, still having some issues but those are AngularJS related I think.\n. Maybe it's because NodeJS cluster module no do sticky sessions.\n. Ah thanks! As it turns out, I got it working with pm2 using their fork mode -x option.  So it's on 4 cores and I seem to be having simultaneous sessions working well on Chrome and Firefox.  I don't know about future scaling and performance and everything but it seems to be working at this level.\nI'll check out your link too, thx!\n. Actually that sticky-session module looks pretty cool.  I guess it just wraps everything.  So maybe if I used that I could go back to using pm2 under its native mode / nJS cluster module ... might get better auto load-balancing ... totally guessing maybes.\n. Before using sticky-session I was pm2 -x -i 4 -n Rubiaceae start sudoStart.js\nNow because sticky-session handles clusterisation:\nI'm using fork mode on pm2 and not splitting it just one prong.\nLike \"maltese\": \"pm2 -x -n rubyMaltese start sudoStart.js\"\nIt was a weird bug which originated on the client side. HTML5 based on a type=\"email\" setting (when it got something that wasn't proper email it sent fritz which->) somehow caused my entire session to reset.  Very weird, anyways, I got rid of it and have no problems now.  \nEverything is quite peachy.\n. (excerpt from my main app file ):\n(metro is an express() app)\n```\nsticky ->\nss.session.store.use 'redis', rtgRedisConfig\n  ss.publish.transport.use 'redis', rtgRedisConfig\nss.session.options.maxAge= 8640000\nsecureServer= https.createServer ssLeo, metro\nss.start secureServer\n  metro.stack = ss.http.middleware.stack.concat(metro.stack)\n  process.on 'uncaughtException', (err) -> \n    c 'Exception caught: ', err\n  return secureServer\n.listen 443\nc cStart \"server started on ports 443\"\n``\n. That's exactly how I do it too !  ThesudoStart.js` referenced above contains:\n(I found this trick some months ago, maybe from you... someone's SocketStream example code somewhere I don't remember which one... I had just googled SocketStream pm2 maybe...)\n```\nrequire('./node_modules/ss-iced/node_modules/iced-coffee-script/lib/coffee-script/coffee-script.js').register()\nrequire('./rubiaceae')\n```\n. > [...]all sessions issues was gone.\nMmm, this didn't happen for me.  If I started pm2 in cluster mode like that it worked okay from a RESTful perspective but the rpcs were not being routed okay.  Total mess, so I had to go to fork mode.\nIt's mysterious to me that sessions worked for you .  Can you verify that you had full cluster mode in pm2 and your clients all being routed (like sticky) to correct servers persistently?\nThat would be interesting because NodeJS cluster mode not supporting sticky session, and P Jensen et al say Ss requires it.\n? I'm confused a bit.  ...I don't have any problems as my situation is working great now, with the sticky-session module for clustering and pm2 just for 'forever' functionality --- I'm just interested in how it is you got pm2 cluster mode to support sticky session by itself.\nI think you may find that your app seems to be working well -- in most ways it is-- but actually isn't; ie heavy rpc usage will reveal that clients sessions are getting mismatched and problems will arise.  In my experience it's not an error that shows up immediately; ie it took me awhile to realise that I was having problems and that I would need to switch to fork mode for those sessions to be persisted/routed correctly.  To elaborate more specifically, I was able to start my app in pm2 in cluster mode using the trick you exhibit, and it seemed to work.  My express RESTful routes worked fine and my SocketStream functionality was working as well, to some extent, the incompleteness of which took a bit of time to manifest. In pm2 cluster mode my rpc's initially went through, and most of them returned good responses, but the more I used the app and mixed things up a bit with heavy usage, ..very quickly chaoes manifested with broken sessions / rpcs getting no responses or confused responses, because of session variables not in place.  Depending on the characteristics of the structure of the app, this may not manifest at all.  Anything sufficiently complex, eg requiring session based auths and roles, you would probably see problems.\n...but I don't know.  Just interested...\n. Yeah this got me thinking more about how I could implement my app to make all my auths token based, then could run with pm2 in cluster mode without sticky-session and no worries. Make new middlewares to check incoming req tokens against Redis database user accounts and so on.   Would be performance or other benefits/penalties vs my current config ?   I dunno.  Interesting question.\nAnswering it myself, probably not so good though it might help optimise clustering mgmt.  Don't like the idea of extra overhead with every rpc message, especially in a usage scenario -- like gaming or intensive realtime interactive data-visualisation data-mapping application -- featuring massive numbers of updates.  Which reminds me that for those applications I'd probably need to make a separate custom transport as per the docs, something even lighter-weight.\n. I actually use JSON web tokens in my current app -- kind of deprecated at the moment, but I went down that road for exploratory reasons.\nDo you see definite benefits to avoiding sticky sessions in favor of JWT ? Or just want to offer choice to the developer ? Bit of both maybe ?\nI'm thinking having the choice open might be greatest for a platform like Ss which wants to offer flexibility and configurability.  Can't see eliminating (sticky) sessions based variables entirely because of the really high message volume, low latency, high frequency applications like gaming and data interactive apps.\nProbably I don't understand the low level of TCP and network hardware very well, but my naive intuition says that in those situations one would want to avoid the overhead of sending a token with every message (suppose messages coming at 30hz).\nOtherwise, sure why not.\n. Ah solved. \nI still haven't had time to respond to your last contributions.\n. i'm curious, what is the significance of this ?  i think i missed some of the history.\n. ah, thanks that's important piece of the puzzle.\n. Oh cool !\nThat sounds much better than what I hacked together:\n... in the last hour, I implemented a solution which:\n- involved server side setInterval [... to ss.api.publish.all \"rollCall\" which is answered by an ss.event.on \"rollCall in the webClient's entry file, ... and a bunch of cool Redis tricks ...\n- It works great, running locally single instance or forked, but when I try to run it clustered with sticky-session it gives a very strange error.  Very early on startup I get a console message which says basically that ss.api.publish is undefined because it can't find the all function to run on 'undefined'.\n  Interesting. As I said it, worked running locally in single instance, and is currently running in my Linode VM forked (pm2 -x -i 4 [...]) fine.  But it folds miserably when running from the main app file I have configured with sticky ie sticky-session.  No idea why yet, and maybe not the best use of my time right now to spend some hour(s) investigating.  But interesting nevertheless.  Recently nvm is configured to v0.10.26.\n  This idea of exposing the close event sounds very much better.\n  (Still, for other reasons, I would like to be able to set my server to perform actions periodically without prompting, so need to figure out the new bug eventually.)\n. :100: \n:)  Very nice !\n. Was having another look at this last night and in the process of going through the entire Ss codebase again realised I'm within visual range of actually grokking it all for the first time.  So I should be able to assist adding stuff like this.  Time is limited currently of course and this isn't absolute highest priority but I'll be consistently returning to it over the coming weeks.  Will refetch the fork and start customizing my own...  then Maybe a pull request isn't too far off.\n...also, will send a stack-trace soon, on my list of things to do for sure is to figure out that crash with the clustered process from the setInterval ss.api.publish.all \"rollcall\", 3000 , but for now (in Dev) just running a singular process server.  Some preview on that: my app structure is heavily indebted for inspiration to your old Dashku, though I've adapted much and complexified much (I have viewControllers, modelControllers, and models in the server, all instantiated from the /server/internals file)... anyways, I have a function which based in a modelController called globalState which is invoked once from internals on startup which 'startsupthesystem\", and in this one I've lodged this new setInterval to constantly check who is out there and capable of responding.  Works on single process, crashes when clustered, even though clustered works without this feature addition.  mmm, yeah so just a preview, will pass along the stack trace when I get around to figuring out how to produce some meaningful ones (pointers on that would be great)... \nAlso, whistl it would clearly be more elegant to have this feature implemented over the lower level engine.io trigger instead of this \"rollcall\" publication, I still want to have the capability of running these higher level persistent periodic signal exchanges (on scaled up clustered systems), so I think it's worth figuring out the nature of the crash, for the reinforcement of the viability of Ss as a resilient platforrm for signal-heavy / signal-intensive RealTimey stuff.\n...So yeah, more to come on that.\nthx!\n. I think I figured out what causing the crash in the clustered run.  Something kind of silly, should have called the startup script later in the start process.  Not positive, but I think it will be easy to reduce and eliminate.  Not sure why it wouldn't show up in the singular version, but a deep read of all the compiled JavaScript (from iced-coffee-script, sticky-session, etc) would probably illuminate that pretty quickly.  Not that I have time for that now, but for the deeper architectural and framework development interests will definitely be doing much of that sometime in medium-term future.\n. Across all instances.  I don't modify any global variables though, everything goes into a Redis cache which is shared.\nI have a modelController call it globStatMC and a model, call it globStatM.  As in Dashku, both are attached to the ss api object by the internals file invoked early in the bootstrapping process.\nSo far so good.  Everthing works with single instance, and everything works with sticky-session.\nThen, later, I realise that after my entire system starts up I want to call a function defined in globStatMC --> globStatM that startupSystem.  Now, if this is single instance it's really not much mystery how to do.  Can invoke from internals even, can invoke after the entire server is on and listening.  But with sticky-session happening it becomes a bit of a riddle.  If it's too early in the cycle outside the sticky-session definition bloc, then I get an error that the ss.api.publish object is undefined; if it's in the bloc then it get's invoked once for every instance, and it's a deluge of redundant calls to this function and an overabundance of copies of the 'publish' events it spawns, essentially freezing the server's ability to handle requests.  I tried putting it after the sticky-session bloc, in my main app file, but there doesn't seem to be any after the bloc.  Outside the indented area and after is still cloned ..  My fix, ugly but good enough, is to just not even try to initiate the startup script during bootstrapping process, but actually to initiate it from an Admin interface via RPC, after all of the sticky-session spawned clusters are already up.  Funny no ?  So the riddle is, how would you invoke a controller, model function internally ?  ..without resorting to an externally triggered (RPC) call ?  Well, I think it's funny.\nAnother thing, I noticed that if I ( a browser ) makes a request to my sticky-sessiond application too early in it's bootstrapping process -- before all instances are fully up and running (which can take nearly ten seconds from issuing the command) -- then it crashes the entire thing and I need to ctrl-C and restart.  Is this an issue you've encountered in production ?  Does this mean you need to use a script to temporarily block access to the relevant ports with iptables during the bootstrapping / startup process ?\nAnyways here an excerpt from my main app file:\n(I think I've attempted all the placements commented out)\n```\nrequire './server/startup'  # placement 1\nsticky ->\nss.session.store.use 'redis', rtgRedisConfig\n  ss.publish.transport.use 'redis', rtgRedisConfig\nss.session.options.maxAge= 8640000\nsecureServer= https.createServer ssLeo, metro\nss.start secureServer\n  metro.stack = ss.http.middleware.stack.concat(metro.stack)\n  #require './server/startup' #placement 2\n  process.on 'uncaughtException', (err) ->\n    c 'Exception caught: ', err\n  return secureServer\n  #require './server/startup' #placement 3\n.listen 443\nc cStart \"server started on ports 443\"\nrequire './server/startup' #placement 4\n```\n. logo: very nice +++++\n. Nice elaborate answer !, sorry about my rather sparse response on the gGroup...\nFollowing up the gG response a bit (will clarify further later if necessary), to go the Express way, you do the stuff in the Gist, and then define routes, at first in the same main app file-- most likely later on you'll want to include them from a separate file.\nNow, since you want the prompt and not just force the download, you could set it up over RPC, the prompt that is.  If the user accepts it then you could either send the webclient a token and validate against that on the GET route or you could validate against a req.session variable.\nIn that case you wouldn't be using res.download but res.sendfile at the end.\nI suppose you could probably also do the res.download thing too, but I haven't had reason to.\nIn my current project I'm working with iOS client in addition to the Angular webclient. For the iOS to server connection, I have to set up the image downloads over RPC with tokens because the iOS HTTP session is not sharing variables with the RPC session for some reason.  The token validation works well. \n. Possible to just remove the 'strict mode' for this one file ?   \nThat's what I did, was fine.  What approach(es) are you thinking ?  Could pass the function in explicitly as an argument, but that's probably painful amount of tedium for not very much.\n. Maybe named function ?  I'm just guessing.  I'll actually look at it later.\n. getBranchFromTree = function(tree, ary, index, i) { \ncould be\ngetBranchFromTree= function getBranchFromTree(tree, ary, index, i) {\nand then\nreturn arguments.callee(tree[ary[i]], ary, index, ++i);\nbecomes\nreturn getBranchFromTree(tree[ary[i]], ary, index, ++i);\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions_and_function_scope/arguments/callee\n. https://github.com/socketstream/socketstream/pull/450\n. No prob and Ouch, :/, similar situation here, :)\n. Auwsome, I think the same.\nI'm so taken with Redis, I don't think the requirement is inappropriate.\n. As you wish.\nHowever, just to point out some things in retreat:\n- it's just a Redis server install.  Not only is it simple process, but for someone making way into building realtime apps this is pretty much mandatory anyway.\n- Getting rid of MemoryStore simplifies things substantially, not only for the build of SocketStream but for the people who are coming in to using it.  Right now it's like : \"hello new people, by default SocketStream has this useless session store system (by implication you should learn how it works), but really we suggest anything serious should use Redis, (by implication if you are serious about your project you should definitely learn how it works)\". So that's two things to learn and understand versus just one.  \nIn the past few weeks I've had to freeze all of my work on frameworks (SocketStream especially) in order to prioritise some work closer to portfolio for job-market activities.  The last thing I was working on SocketStream specific was upgrading Connect to v3, partly but not only for the option of bringing in user-option of packaging Express v4 with the buildup.   Connect v3 is completely different and breaking from v2.  Almost everything (static is maybe the only exception) has been moved out of Connect into middlewares.  I'm not sure what the correspdonding thing to MemoryStore would be under Connect-v3, maybe just https://github.com/expressjs/cookie-session, not sure at the moment.\nBut the point of me writing here is that all of this and upgrading to Connect v3 maybe missing something else:\nhttp://koajs.com/\nI've scarcely had any time to look into that, but I know it's the team behind Express, and that it \"leverages generators\", which gives opportunity to move more terse, efficient and direct functional style in future code.\nIf I could spend full-time on this, I would first go back to the project of bringing in Connect v3 for current versions, and then start working on building something with Koa for future versions.  Or at least experimenting with it, to see if it would work well, with for example, current versions of Engine.io.\nAh well, thanks for the feedback ;0\n. Cool cool.  I understand a bit more about it now.  Recalling the idea to keep the framework setup for initialisation quite minimalistic, unopinionated, simple.\n. As a general condition, I understand and indeed develop with event buses, on AngularJS hooked up to SocketStream RPC and model/controller constructs; but, I don't understand the particular intent and idea of the author of the comment and/or the community intent around same.  iow does the comment still mean anything ?  The question is opening a deep-design discussion in socketstream development, I suppose.\n. Same as the other one, I'm starting to do stuff with this in prototype form-- maybe something this week for a kind of branch pr... i.e. maybe would like to do some pr to branch for some of these.\nAs mentioned on #292 I'm working on something for 'publishing' server side events.  Will be built into the existing publish module.\n. Client option sounds good for introducing this.\n. Do you (plural) prefer jspm over browserify -- futurewise ?\nI had never heard of it before now.  I've been doing a lot of work with Browserify and Gulp, and now set to reproduce some of this functionality in pure Npm scripts.  Working on variety of mutually redundant dev-lines in parallel.\nI guess I'll add this jspm into the mix and see if can do something with it.\n. I started using some new client-side frameworks yesterday, some of which use jspm.  \naurelia, durandal, mithril, ... \nI haven't really figured out jspm but am excited by it.  This week and next I'm dropping it to focus on SocketStream engine and connect, but then I want to do some work integrating some non-Angular client-side frameworks into the upgraded SocketStream developments.\n. Srsly awesome.\n. 5) enhanced project initialisation configuration set: including (e.g.) option to bundle express server.\n. 6) provide specialised transport+ 'custom request responder' configuration (e.g. low-latency low-overhead) 'out-of-the-box' to enable realtime gaming and associated apps; maybe bundle demo game with the demo chat.  (it would be nice to have multiple transport systems working in parallel.  has anyone done that ?)\n. 7) This maybe a bit too blue sky, but we could start to implement peer-to-peer technologies for optimisations over the server-centric model.  e.g. https://peer5.com/\n. Yeah cool I think this idea --keeping core super sparse and simple and having extensible components which can be added by user-whim to their particular configuration needs-- is great.\nThis to me is reminiscent of the Connect/Express build philosophy where they stripped the core down and moved components out to a thriving middleware ecosystem.\n. > if there was a period of 6 months dedicated to a complete rewrite of SocketStream; one where everything was tested properly, where existing features were complete, where the framework was more modular in design[...]\nYes.\n\nand where updating 0.3 apps to 0.4 involved minimal pain, would that be something that the team would be interested in considering?\n\nWould('nt) this constraint constrain the overall power of the new build ?  \nI would think it worthwhile to continue supporting v3, with incremental improvements, and where v4 or whatever had the freedom to break stuff in its development.  \nAs things stand (could change) I'm edging closer to the time where I can devote a significant daily energy resources to the framework r&d stuff in general.  I'm going to be looking at the Primus components very closely indeed at that time.\nI'm interested to hear more about what you see in terms of integration with these (Primus) and other recent and current development ecologies .. of which there are many, Koa comes to mind, but many more.  Especially interested in hearing more about how and why(?) Primus is built in the way it is, what (?) it can and can't do, what (?) we would like our system to be able to do, and so on, and so forth.\nMore later,..\n. Very well on the no-rebuild position and policy.  I was wondering what the different possibilities are, your take(s) on the system as it is and the system as it could be--under a variety of scenarios.  The essence of planning is considering scenarios after all, selecting one to actualise.  \nSo if I understand the gist here, it is to reinforce and consolidate the v3 build.  Which is I think great. \nIn my opinion it would be great to do both a clean-sheet build, and the v3 line continuance.  We all have time-resource issues though, and a clean-sheet build requires an R&D dance to be meaningful.\nThe R&D dance is my next project by the way, which I've actually already started but had to sideline for a bit.  In that project I'm re-engineering (to learn it, not because I think I can do it 'better') SocketStream, and bring in a bunch of Primus components-- all in the same repository.  My anticipation is that some lessons-learned from that can be transferred back into the v3 line of SocketStream via my fork for non-breaking, subtle/incremental improvements.  And other lessons-learned or forms-discovered could be transferred into clean-sheet build prototypes.\n. (as I think of them): Prototypes aren't re-thought; they are created, tested, evaluated, and in most cases, thrown away.  In an r&d environment, there aren't restrictions on what is a good or bad prototype, other than that-- hopefully-- one can learn something from working with it.\nI have said before (above), that I think the idea of an incremental --'evolutionary'-- development line on SocketStream should be pursued.  I don't think a more radical (r&)development line is exclusive of this though, except perhaps by time considerations.  \nRelated note: I don't think there is any way I'm going to be of much use as a framework engineer (on SocketStream or anything else) without doing the r&d thing in my own time and space.  \nI have a hard time thinking of this as 'revolutionary', or really using that word outside of some kind of political context, or maybe say a really disruptive technological innovation.  It's just development research.  Pretty boilerplate process technology.  And as I said before, I think traditional development planning is constituted --in the first place-- by a dispassionate consideration of available scenarios, and then in the second place -- by the selection of one scenario for actualisation, at which point focus is shifted to scenario-building within the constrained scope of that particular development scenario.\nAnyways, sounds like everyone here is at least interested in the incremental development component-- though of course this is not exclusive (meaning can reside in the same dev scenario) with r&d, nor is it exclusive with the process of consideration of technological context.  Things are changing all the time, so it is valuable to do this a lot.  \nI hope that this makes at least a bit of sense.\n. Cool cool on all ! (will email public ssh key )\n. Ha!  no worries my bad actually I was being pedantic for some reason.  :) \nI agree with you on that.\n. Agree with you on that also !\nKeep the core tiny, and then most of the extra functionality can be added in modularised components like in the Connect/Express middleware ecosystem. Or well-documented \"how-to\" stuff.\nOf course, then it becomes our responsibility to produce those components and those \"how-to\"s.\n. ##### A request for engineering OPINIONS:\nWhat you think regarding webrtc (Web-RTC) ?  \n(e.g.): vs WebSockets ?  Good to have both or can do the same tasks equally well with either one ?  If negative on that, would this be a good idea for a module ( 3rd-party / -ware ) for SocketStream moving forward ?\n. Can we make a Websocket implementation that has similar ~~streaming~~/latency*throughput performance and does peer-2-peer ?  I'm really thinking high data throughput generally for games.  And I want P2P capabilities.\nLike can we start a WebSocket 'server' on one web-client and another WebSocket 'client' on another web-client ?\n. I like the API idea.  (more later)\n. That sounds good and I could do that.  \nI'll still have time-resource issues, and the hangouts won't ameliorate that.  They'll be valuable for other reasons though and I agree a good idea.  \nMy complimentary counterpoint is that we (also) should continue to expand our horizons on the written communication front.  In the software world maybe this could be called a classical (i.e. venerable) tradition.  The old Linux news-groups come to mind, threads composed of long-as-necessary & hopefully well-written messages, providing the basis for organisation and process progress.\nThese aren't mutually exclusive approaches.  I'm happy to chat / VoIP and think it could be valuable.\n. 4th Jan I can do.\n. (UTC) anytime 08:00 to 19:00 \n. Very cool !\nOn Sat, Jan 3, 2015 at 4:46 AM, Robert Hall notifications@github.com\nwrote:\n\nThat works great for me. [image: :+1:]\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68580616\n.\n. very good.\n\nOn Sun, Jan 4, 2015 at 1:29 AM, Paul Jensen notifications@github.com\nwrote:\n\nSeems cool, speak tomorrow.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68613905\n.\n. I have a microphone but no camera. (\u2018venerable\u2019 2009 Thinkpad X61)\u2014 might\nbe an issue. wasn\u2019t able to connect to their server just now.\n\ni\u2019m on Skype as well wylie.joshuacullick or same in Gmail/hangouts, or\nwhatever else. hopefully Appear will work though\u2014 I\u2019ll try again later.\n\u200b\nOn Sun, Jan 4, 2015 at 8:53 AM, Wylie JoshuaCullick \nwylie.joshuacullick@gmail.com wrote:\n\nvery good.\nOn Sun, Jan 4, 2015 at 1:29 AM, Paul Jensen notifications@github.com\nwrote:\n\nSeems cool, speak tomorrow.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68613905\n.\n. ah cool!\n\n\nOn Sun, Jan 4, 2015 at 11:27 AM, Paul Jensen notifications@github.com\nwrote:\n\nYou can add ?video=off to the url in order to disable video (screen\nsharing will still work).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68626626\n.\n. worked thanks!\n\nOn Sun, Jan 4, 2015 at 11:28 AM, Wylie JoshuaCullick \nwylie.joshuacullick@gmail.com wrote:\n\nah cool!\nOn Sun, Jan 4, 2015 at 11:27 AM, Paul Jensen notifications@github.com\nwrote:\n\nYou can add ?video=off to the url in order to disable video (screen\nsharing will still work).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68626626\n.\n. supposed to be here :\n\n\nhttps://appear.in/socketstream\nOn Sun, Jan 4, 2015 at 1:07 PM, Henrik Vendelbo notifications@github.com\nwrote:\n\nsure. Is this a hangout? I don't know where to join\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68629095\n.\n. knocked but no answer\n\nOn Sun, Jan 4, 2015 at 1:18 PM, Paul Jensen notifications@github.com\nwrote:\n\nHave you chaps been able to join?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68629399\n.\n. cool\n\nOn Sun, Jan 4, 2015 at 1:27 PM, Paul Jensen notifications@github.com\nwrote:\n\nOk, we're going to try a google hangout, will send invites via email\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68629613\n.\n. Wylie: email: wylie.joshuacullick@gmail.com\nbtw:i\u2019m hoping to have a fresh devEnv setup going next week, and I should\nshare insights with you then.\n\u200b\n\nOn Mon, Jan 5, 2015 at 4:19 PM, Robert Hall notifications@github.com\nwrote:\n\nHi Everyone, I'm closing this issue since we've created a more proactive\nprocess for meeting and going over roadmap. If you'd like to be on the\nroadmap contact list (for meeting times, notes, etc.) go ahead and leave a\nnote here, and we'll figure out how to get contact info, etc.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/issues/468#issuecomment-68713127\n.\n. oh cool !  yeah i'll try to fill in on tests soon.  i've gotten better in that dept recently.   Mocha / chai / supertest ?  In coffeescript ?  Can I add a gulpfile ?\n. Status of this ? Interested in more info.\n. By views you mean sending gulp itself to the browser ?   Can you elaborate.  Is very intruiging but not clear on precise intention. \n. Okay yeah that makes sense.\n. Ah you got it cool !  I've been meaning to get to this, but also wondering  if anyone else could reproduce the error.  cool !\n. No problem and no rush at all ;}\n. Cool cool I'll do the in depth bug report tomorrow.\nThanks for the catch on the package.json file, I fixed it.\nAlso, I just did npm install fresh- ran into serious problems after that with my templates.\nTraced it to new Lodash (v3); they changed some method names around.  Fixed now.  It should work for you.\nOn the app, it's on port 3000, and pretty much everything interesting happening in the console, but you have some buttons which allow to authorise and deauthorise the user session.  And also to ping the auth-protected endpoint.\nI'll try it with master#head tomorrow and let you know what I find.\n. Right so here it is tomorrow.\nI've fixed laTrappe and so you should be able to run it locally. \nI've created a new clone of it and added the line \"socketstream\": \"git://github.com/socketstream/socketstream.git#master\", to the package.json flie.\nThe detailed bug report without inserting logging debris is Nothing.  There is no error output in the server console, and there is no error output in the browser console.\nLooking at the differences between the html page source as delivered we have:\n\nBad\n<!DOCTYPE html>\n<html lang=\"en\" ng-app=\"laTrappe\">\n  <head>\n    <script src=\"/_serveDev/system?ts=1422795256487\" type=\"text/javascript\"></script>\n    <link href=\"/_serveDev/css/laTrappe_local_alpha/main.styl?ts=1422795256487\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\">\n    <script src=\"/_serveDev/code/laTrappe_local_alpha/entry.coffee?ts=1422795256487&pathPrefix=laTrappe_local_alpha\" type=\"text/javascript\"></script>\n    <script src=\"/_serveDev/code/laTrappe_local_alpha/laTrappe.coffee?ts=1422795256487&pathPrefix=laTrappe_local_alpha\" type=\"text/javascript\"></script>\n    <script src=\"/_serveDev/code/laTrappe_local_alpha/lib/angular-animate.js?ts=1422795256487&pathPrefix=laTrappe_local_alpha\" type=\"text/javascript\"></script>\n    <script src=\"/_serveDev/code/laTrappe_local_alpha/lib/angular.js?ts=1422795256487&pathPrefix=laTrappe_local_alpha\" type=\"text/javascript\"></script>\n    <script src=\"/_serveDev/code/laTrappe_local_alpha/lib/lodash.js?ts=1422795256487&pathPrefix=laTrappe_local_alpha\" type=\"text/javascript\"></script>\n    <script src=\"/_serveDev/code/laTrappe_local_alpha/lib/smoothie.js?ts=1422795256487&pathPrefix=laTrappe_local_alpha\" type=\"text/javascript\"></script>\n    <script src=\"/_serveDev/start?ts=1422795256487\" type=\"text/javascript\"></script>\n    <script type=\"text/ng-template\" id=\"panel.html\"><button ng-click=\"authMe()\">authMe</button><button ng-click=\"deAuthMe()\">deAuthMe</button><button ng-click=\"pingProtected()\">pingProtected</button></script>\n    <script type=\"text/ng-template\" id=\"placeholder.html\"></script><title>laTrappe</title>\n    <meta charset=\"utf-8\">\n  </head>\n  <body ng-controller=\"laTrappe\">\n    <panel></panel>\n  </body>\n</html>\nGood\n```\nhtml\n\n\n\n\n\n\n\n\n\n\n\n<button ng-click=\"authMe()\">authMe</button><button ng-click=\"deAuthMe()\">deAuthMe</button><button ng-click=\"pingProtected()\">pingProtected</button>\nlaTrappe\n\n\n\n\n\n\n```\nI've read through the html delivered and it looks exactly the same.  I'm going to guess that the delivered client code pack invoked by the !=socketstream in view.jade is not happening quite right. Will explore further and get back to you.  It's not so simple as seeing some console output so may be a day or two.\n. Okay,\nhere is the good delivery of the code module: (accessed by ctrl-u for the source in Firefox and then clicking the link on first script.\nhttps://gist.github.com/kulicuu/27206afb11851733d4e8\nThe bad one just gives the error CANNOT GET.  \nSo that's basically the bug report as far as that goes.  \nFor something more substantial, I could hunt around with my console logging gear on the server side.  Will get back to you.\n. ###### Update\nI've made another clone to analyze the new static work, not only to debug regarding this issue but also to see your development line here and to think about how to integrate with new work I'm doing with respect to the React integrations.\n. Hey, I want to find the discussion leading up to the development of the new static strategy; where would that be ?\nOr /and, could you describe -- briefly or at length -- what you had in mind to accomplish with the new static strategy ?\n. Wow, cool code.  Lots of work here, not too sure raison d'etre yet, but lots here and it's very interesting.  Noticed will require some modifications (not too difficult) to bring it merge-able with the new Connect v3.3.4, and some of the files modded are the same.\nHave you been able to reproduce the error I'm encountering ?  Again, it's serving the view but not the Javascript, so the entry file is never initialised.\nlaTrappe should be working now let me know if still any issues there.\n. Okay the problem was with the way I was integrating the Express and SocketStream stacks, as seen here.\nI'm okay with dropping this usage and finding a better way.... at any rate it's on my thingstodo list to implement an upgrade to Express v4 and that will require some reworking anyway.  So I'm going to close this.\nThanks!\n. Ah cool thx.  I'm not done with this engine.io thing by any means.  Still wanting to get feedback from community about enhancements possibilities: including possibilities with binary transport (see @nhitchins notes in #435 ) and running the whole thing in a web-worker.  Sorry haven't done anything last few days, but not just leaving it where it is.  ~~I'll take a look at the v1.51 as well.~~ (looked and looks to be 'no change'; but the client is different, so I'll pop that in.)  thx!\n. This same work is in the newer Connect/Engine PR, so I'm closing this.\n. It's been like that since forever I think.  I haven't used the Commander/terminal interface for some time now, so it doesn't really affect me at present, but it's on my list of things to get to.  After the engine;io and connect.  And after the next client build refactor.  Pretty much the last thing, not so much because it's unimportant as that the implementation depends on particularties of the precursor implementations.  \nI think I mentioned this before: it would also be easy to add a builder option to set up an Express app-- this without adding the Express functionality into the core. \"Loosely coupled modules\", so something like ss-express and an option there.\n. Pretty much so yes. ;]  (also was pointing out  a great line too in some esthetic sense--mixing process with logic--although I generally try to avoid suchlike) \n. In my opinion no.  Paul's response implies concur.\nIt's not a big issue at all -- but it is a small issue, and I'm going through the whole framework now, so thought it would be fun and productive to relate findings.  This was one of them.\n. I've changed the line in pr #478 \n. Cool response.  I'll have to come back to this fresh later for further discussion and exploration.\nFor now I can say more good news: I got the new connect working.\n. I'm listening I think you have the parts I'm missing.  I mean your ideas indicate auspicious devv strategies, seems likely to me.    As for certainties, it's all very preliminary.  Connect 3 is working.  I haven't been able to get my app working on Express  4 yet, would like to see the Gisttt of this.\n. I'm thinking of leaving Express out of my apps in the future.  Wasn't really sure what I thought I needed it for-- just wanted to explore its API I think.  Still I mighth like to get 4 working, to create a how-to doc for it.\n. @arxpoetica  I have this already in the sense that I have the unified Express/SocketStream in all my apps for at least year.  (See britvic)\nYou are right in that many aspects of a system don't need to utilise the websocket.  I was using it (the Express component) first of all the serve single page Angular  apps for gate and authorisation pages-- e.g. why load the entire single page app  to unauthorised users ?\nNow I think I could probably figure out how to meet my needs with just Connect, but people building out large HTTP APIs alongside their WebSocket thing might want Express.  So yeah.\n. I was hoping to close it as it's fixed in PR #486 \n. Cool..\n. Also contains a fix to issue #484 .\n. The Codacy testing thing is a bit annoying.  It's just complaining about mixture of single and double quotes, and some of the things it's complaining about are in the new engine.io client code file.  If those people released it, I'm okay with it.\nLet me know if I should be making sure it passes these tests completely, or whatever.\n. It works now afaik.\nClearly needs ot be more and better acceptance testing, so working on that angle as well.\nI'm ignoring the Codacy thing for now as nothing meaningful have I seen from the reports as yet.\n. I'm going to rework this to bring it into line with @thepian 's work on the new static strategy.  Hopefully will have something in a few hours.\n. ~~I was thinking of something similar yesterday.  Will be thinking about it this next week as going through the whole system.~~ edit For some reason completely forgot to mention the approach of bringing in Connect &or Express for this purpose.\n. One approach I'd been considering but never got around to implementing on the system for which I'd had it in mind was to issue single page apps the way the olde http systems served single views in a system, in the sense that sessions would be shared and redundant resources would get traded off on client-side cache.  The immediate application for this is to have a major distinction between landing page app / 'gate' app, and the main app interface as for authorised 'normal' users.\n. I like the fads, provided they are driven by sound engineering intuition.  I think it's a good sign that we have so much ecological richness in the whatever.  Those that persist -- like Express -- are well honed. \n(Koa sounds cool too -- haven't had time to delve )\n. good point.\n. I don't understand your term dev-time middleware .\n. I'm not sure why I failed to mention this before, but this routing for non-Socket pages is precisely why I went initially to integrate Express with SocketStream, which yields the effect.\n@paulbjensen approach even better in the sense of lighter weight, although I suppose some people really want a full Express app alongside the SocketStream stuff.  Documenting the practice would be great.\nAnyways, I'll be working on the Express4 demo-app and/or docs as I just got that working.\n. I've had good luck with this http://angular.github.io/protractor/#/, and I think it should work for non-Angular apps as well.  Anyways I'm starting a branch to work on this.\n. will use this thread for todo list on features -- i.e. defining the acceptance criteria for SocketStream functionality.\nlist of constraints (prelim draft)\n\nshould serve the app\nmiddleware should be active and (sessions ...)\nsessions should persist over browser reloads \nsessions should persist over server restarts (assuming redis sessions)\nwebsockets should work if availablbe (tests should query engineIo on low level api or something custom to effectively guage)\n[much much more ...]\npack assets verified \nstructured logging server performance under various loads [?]\n. I guess to make a protocol where pretty much anyone can register an app within the e2e folder under like /some_apps/someones_test-app_1/.  \n\nObjections ? (for prototyping anyways)\nWill be interesting because of implications for development environment.  Now my test app will embedded in the repository itself, and local file relations will reflect that; currently my test app (laTrappe) is the parent by way of node_module the socketstream development folder.  So that would be different.\nIndividuals mostly self responnsible for writing e2e test suite for their own test apps.\n. Starting to wonder if better to bring them in as node modules via devDependencies.\nFor now I'm just going to have the entire app under an appLibrary folder under an e2e folder.  Can change to another approach later.\nfound: http://git-scm.com/book/en/v2/Git-Tools-Submodules\n. There's a PR with the solution in submodules.\nI think it will be best.\nbtw as soon as master head stabilises over this period I'm going to be much more disciplined about branching, flow, and keeping synced.\n. I think it's kind of there already, in the sense that the minimally viably productive manifestation of the feature structure on the ~~app~~ framework structure is just to be able to manually do acceptance testing over a range of developers' apps, initially your own.\n. Then you can add automated acceptance testing as you see fit, in a way that's specific to this SocketStream dev environment and your app's structure.  I'll be using Protractor for this particular (angular) client of laTrappe's.  I'll probably keep adding clients to lT in other frameworks-- fashionable experiments.\n. Good to remember in this situation the feature isn't for the notional primary consumer of Ss, but for the developer of Ss.   In that sense especially, recommend to exploit it immediately.\nIt's possibly showing the way forward for development and contributions.  some surprise manifest of TDD in Ss.  \nI've changed my development environment around it[this new feature/structural addition], so I'm in an entirely different folder now locally.  As you can see laTrappe is registered as a submodule, so cloning Ss and then invoking it I can bring it in under that folder code from there and run the app.  It's really cool.\n. Nice.\n. I really don't know enough about this yet to make an informed comment.  Sounds good.\nActually I could make some informed comments, but not really about the implementation yet.  One thing maybe pertinent is my current build paradigm, which completely eschews environment variables, instead making distinct app configurations to be executed under the various contexts (devv, staging, wild, etc).\n. Ah cool yeah I should study that git flow thing more.\nAnd I'll start making feature branches then.  (wait though, are you saying branches can't be terminated when their feature is merged to master branch ?)\n. cool understood.\n. I've fetched this branch, npm-installed, and running laTrappe under it serves fine.\n. I just realised my test was no good, because of the way my new development environment is set up.  I need to adjust it somewhat.\n. This would be unit testing of Ss stuff.  The example apps should have their own unit tests kept in their own repositories; on the other hand and at the same time there would be Ss specific e2e tests related to specific apps and even specific configuration states of those apps which be in the e2e folder -- though I haven't figured out how best to organise that.  There's an \"/appLibrary\" folder already, something like that but for specific e2e testing scripts.  Ultimately, these would be documented in the readme and eventually maybe invocable by npm script or gulp script from project root.  Perhaps some canonical e2e acceptance routine before a big PR.\n. I like the idea of having tests close to source-- in my own work the two are in the same file indeed I write the implementation to be self testing and report its status through the console.  That's for prototyping though, and long term goal is for full unit testing coverage across all relevant levels of abstraction.  Maybe in practice not so feasible, but a little pays off a lot in this area.\nAgain I think it's an interesting idea to have the tests close to the source, and I think it makes intuitive sense; however, in this context I think probably not suitable. Why I think this: It's ideosyncratic the way people test; I have some strategy I like and some particular set of libraries and styles I'll use for it--but wouldn't expect other people to have the same.  So it would make sense to allow this to be loosely coupled, to allow some space for multiple non-exclusive developmental approaches to coverage to emerge... et cetera.\n[...]   I've been reading more on Git's submodules.  Really incredible what can be accomplished working creatively with that tool.  For example this notional unit testing module could be added as a submodule.  One nice feature is that submodules are not automatically cloned in on main module clone.  So if someone clones Ss they don't get my submodules without invoking a specific command to request them.  So they can be fairly unobtrusive, even though their presence (minimally nominally visible) helps document the work that's available.\n. Reasonable position.  I don't agree, but it's reasonable.  One compromise would be to put the whole melange into one major test folder.  If that's not okay then I'm happy to test according to local convention. I'll revisit this point another time.\n. Wow.  I'll have to think about that some days before responding.  I'm really excited about submodules--admitedly I'm new to them, but quite taken with the possibilities.\n. Yeah I'm not contemplating extreme measures or anything, whatever is generally accepted will be fine.  How I use them in my other work another issue.\n. I was definitely still thinking more about the way I'll be doing acceptance testing broadly speaking.  For today at least, the priority is emphasisng development on my fork, organising the branches there, making a partially autonomous staging environment there, which could differ somewhat from the upstream, even though designed inclusive with purpose to send stuff there.\n. Jubilations.\n. Both @jokagent 's and @DeLaGuardo 's libs work fine as far as I can tell; the latter even allows to pass coffee-script files into the mix.  (looking at the code suspect would choke on csx, so more work may be relevant on this angle)\nI'm tempted to close this issue now, but going to research+develop a bit more to see what is possible -- e.g. my next step is to verify that I can pass .csx files through @DeLaGuardo 's system and have them work.  Also to see how the other libraries linked above are relevant to Ss.\nReally should do a small demo as well-- could pass for it to be documented.  \nDo we have some kind of library for canonical demos ? Like 'here is the canonical Angular demo app', etc. edit see it's in the documentation site, just the one for Ember.js.   I could work on a few more; one for Angular would be easiest, but also want to do some with Durandal/Aurelia, Mithril, maybe some others or combos.  Still it would be good to have actual repositories with the demos.  And even link to them from the main readme, if they pass muster of  sorts.\n. thanks & Yes, cool idea.\n. Somewhat off-topic --except for the demo-app discussion-- > \nGood news: I now have Express4 working with the newest SocketStream.\nHaven't cleaned the file yet: https://github.com/kulicuu/laTrappe/blob/sIGG/lT_reactVanilla_local.coffee\nIt was a strange hack as it required starting a dummy server (not the one that will be listened on) just in order to get the ss.http.middleware.stack object.  If that's bad hard on resources maybe could put another function into the http module just to get that object without starting a server.\n. @arxpoetica ha thanks!  Actually my Express4 implementation needs work, but hopefully by early next week a demo will be up. \n@thepian ditto(Awesome).\n. Very nice.\n. Yes.\n. :)  I will find time to contribute to this sometime this week.  May be small, but I will.\n. I'm going to research this-- I confess ignorance.  Interested to read other thoughts here.\n. I'm going to try to look through all this stuff this week.  I'm busy with a new job, but should be able to put some hours to this as well.  Preview: Things with both Connect and EngineIo have changed; but there are a bunch of resolution possibilities for this to maintain your functionality.  I'll have more to say on this as soon as I get a chance to look into it fully.\n. Got it thanks.  I'll get to it as soon as I can -- hopefully next few days. \n. Try ss.api.db.set(\"User\", user) and generally alias it .  Also, maybe quoted string for first arg to api addition : ss.api.add(\"db\", client).\n. [edited ...]  Yes , this is the thing I'll be working on next.  At the moment I'm working on another ss-example -- one using webpack, React, and no CoffeeScript at all, just ES6 stuff (I'm using iojs v2) and babel-loader for the client.\n. > Why do you expect the session cookie to be the first or third cookie? Why not look for the cookie name?\nYes great question. I was actually just doing a version that looked for the\ncookie name by for loop, but it wasn\u2019t working for some reason, so wanted\nto add this his is a quick patch. The reason it\u2019s looking for the first or\nthird is that when I was last doing SocketStream development (two months\nago), on the first uncached load the cookie was different than on\nsubsequent runs. I\u2019ll have the name-checking version working a bit later.\nSorry, I\u2019m quickly getting back up to speed here, but just second day.\n\u200b\nOn Tue, May 5, 2015 at 1:52 PM, hulmgulm notifications@github.com wrote:\n\nWhile trying to figuring out our problems with socketstream (\nhttps://groups.google.com/forum/#!topic/socketstream/lCZRU2whpQw) we came\nacross this code too. Why do you expect the session cookie to be the first\nor third cookie? Why not look for the cookie name? Then it doesn't matter\nin which order the cookies are set. According to the error message at the\nend of this function, the cookie should always be connect.sid.\nWe were setting additional cookies a few days ago which led to strange\nproblems like \"undefinded\" or \"true\" as session id. Or to constantly\nchanging sessions ids.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/pull/537#issuecomment-99031860\n.\n. I need to figure out if something changed with the some of the engine dependencies or some intervening code.  (It will be slowly, slowly while I review two months of commits and changes.)\n. Okay it's name detection now.  Works for me on Firefox, Chrome and Chromium. \nMaybe it's the browsers were changing in the meantime, I have to go look at engineio client.  Anyways I think it's good now.\n. fixed., also had to add the trim() for the connect.sid comes with a leading whitespace if you open from a new fresh (or private) browser window.  The cookie is processed differently on subsequent requests.\n. https://github.com/socketstream/ss-examples/tree/master/react-and-coffeescript\n\nI didn't use the CLI script -- don't typically.  Just built the relevant file structure.  Also note there is not a SocketStream dependency listed in the package.json file.  You will want it there or to clone manually (+ npm install) in your node_modules folder, which is what I do in order to develop on SocketStream simultaneously with work on the example app stuff.\n. Yay !\n. Nice info thankyou  ! and it's great to know we have Koa compatibility.\n. I'm getting problems also with the bundling.  I notice in the console \nError: ENOENT: no such file or directory, open '/home/wylie/terebinth/site_card_0/client/static/assets/another/EyeZlTXnN.html'\n18:41:55 web.1  |     at Error (native)\nit's looking for a different file than the one actually created by the bundler, which in this case (verified through Nautilus) is Vye19bNnV.html.\n. The client.id injected into /lib/client/http.js is bad.  \nThe clients argument passed to http.js from lib/client/index.js is an empty object.  Shouldn't it be populated with the defined clients ?\nI may have a fix tomorrow.\n. Even more unpredictable behaviour from the bundler upon casual console based testing today.  All indications are I should step back from the console based testing as it will not be time efficient--long term better to focus on the unit testing and concomitant improving of the understanding of the higher level structure of the system -- in this case the client module. \nIt's been so long since I even ran the unit tests we have -- how is this done ?  I know it's Mocha.  Could we put a readme.md in the /test folder documenting testing structure, strategy, invocation etc ?  Would be nice.\n. ah thanks.\nWould like to document the running of individual test suites, stuff like that.\n. @thepian I know mocha stuff, but documenting it in a readme.md eg:\nhttps://github.com/kulicuu/britvic/tree/master/mocha\nLike it's a good idea to be able to run different suites at different levels checking out individual modules or sometimes working relations between them.\n. background info: (I recall  before all the upgrades to the strategies a hack in the main app file was require to have the sessions automatically transfer over-- something like appending the Express middleware to the SocketStream http stack.  It was never automatic in my experience. [edit: I was using Express added onto the stack back then; don't recall if the native http routes were linked sessionwise with the ws] After the changes this hack was no longer working, so need to find something else... which is fine because the hack was ugly to begin with; it should just be default behaviour.)\nI'm looking into this now.  If anyone is available to chat on gitter about it I'm interested in getting more info about the issue.  \n[update] I've left some investigation notes on Gitter if interested.  tldr: I see the issue basically and sure it has solutions but not so sure which one would be optimal.  Waiting for feedback but will look into it more meanwhile.\n. There are two closely related but distinct issues here.  \nOne has to do with SocketStream's built-in http sessions (connect) handling and the extent of its sharing with the ws (engine.io). [edited Date.now()]  \nThe other, as in the Koa thread above and my own reported issue here at issue 475, has to do with bringing in another library (e.g. Express, Koa) and merging its stack / routes / sessions with SocketStream's.  \nIn the second case, the old community hack(s?) was(ere) broken by the new strategies' code.  I don't see that as necessarily a bad thing, if there is a better way we should be doing it. basically my position at the end of #475 .  Once I realised the source of the bug I just removed the hack and figured that I would figure out a new one when I had to.\nIn the first case, we should definitely have sessions shared in a way that is well-engineered, and will additionally provide an easy way to accomplish the first issue.  Please have a look at the gitter thread for notes, and I'll be online to work/chat on this on Sunday during the day (UTC+2 ) to discuss and hopefully generate a good design solution.   Maybe.  Anyways I'll be looking into it this week.  I'm still kind of not completely familiar with the way all the code fits together.  Yesterday I was browsing the client build stuff to do a new bundler for webpack, and I know that part even less well than the ws and sessions stuff.  I need to diagram I think on paper, which is something I don't do enough of to be really good at ( produce meaningful insight generating diagrams of the abstract machines ). Also I read recently some advice to print source code out on paper, spread it out on a table.  Maybe cut and collage.  ...or just develop better visual memory ... anyways I look forward to chatting hopefully on gitter next week. \n. So I looked into this today.  Once again, I got into the bad habit of just scrambling around through the code like a maze, logging lots of things and watching things happen.  A bit of this is good, but it's just hacking, and as discussed above, what I really need to do is about half that, and then half actually taking the time to diagram the macro picture to properly model the machine as a whole.  Failing to do this, even if I were able to hack together a solution to this or that particular issue, just fails to see forest for the trees and would almost certainly fail to generate good design going forward.  I need to be a bit more patient and once again tomorrow try to model the whole picture -- outside the monitor, on paper, on the table.  \n(this of a much larger and more general (not just SocketStream) conversation/issue I've been thinking about and had to deal with recently in my work, (involving massive failure of a product))... Reengineering issue... check out the book \"Object Oriented Reengineering Patterns)\nThat aside, I think I see the issue. The http module (in the new strategies implementation) seems to create its own session implementation, whereas according to the design of the system, this is the responsibility of the session module.  Http is just supposed to use that, as is the websockets module.  \nClearly a lot of uncoordinated hacking has been happening leading to confusion there and mismatch.  \nI'll be on it tomorrow again.\n. Yes, I'm learning about signed cookies.\n@hulmgulm thanks for the code snippet above.  very good clues.\n. Okay I got it (I think so anyway). Had to set the sessionId to signed cookie value in engine.io thing.  Going to lunch now.  Will clean it up and maybe PR this afternoon. \nQuite.\n. I think this has good fix now with most recent merge, would like to hear results of verification.\n. Right cool, so the problem was something arcane to do with the way cookies are actually handled in this case.  They're signed for security by cookie-parser, but the session handling initialisation for the engine.io wasn't parsing them back to the id that would enable lookup of the session.  So, the initial solution (yesterday) simply used cookieParser's signedCookie function to parse that back in the processSession function in the engine.io transport, with the secret baked in.  Today I added the secret attribute to the session's options object (this can be edited from the main app file with like ss.session.options.secret = \"newSecret\";), and in the websockets loader function in socketstream.js I added session.options to the arguments, and additionally edited all the functions in the chain to the processSession function in engine.io transport index.js.  That's pretty much it.  I alias console.log with c to make it a bit faster to quickly log and unlog a lot of things.\nSome other notes (as they occur to me):\n- There is no need for a setter function for session.options.secret.  It can be edited in the main app file directly as above.  Should be before starting the server , as that's when the loader function are called.\n. Nothing so interesting.  I established a default value for secret in the session (for cookieParser) options.   You can alter it before creating/starting the server.  Before when I'd upgraded the engine.io and connect, I'd neglected to handle the cookie the same on both parts.  So I'm just cleaning up a bug I introduced.\n. I only had to set the secret once.  It's been a couple of weeks.  I'll have a look at it tomorrow.\nI used t.session.options.secret = \"someNewSecret\", like ss.session.options.secret = \"someNewSecret\" once in the main app file. \nhttps://github.com/socketstream/ss-examples/tree/master/react-and-coffeescript\n I think it goes to both, which is why the sessions are now shared between http and engine.  I tested very manually, with console.log and some diagnostic calls from my example app; the thing I should be obligated to is implementing some write-behind-testing unit testing for this. And then later really it's the e2e testing which was a long term goal.\n. I should mention also, it's confusing when the argument name in the invocation is different from the argument name in the definition.  In this case it's api in the invocation and ss in the definition.  It should probably be api in the definition as well.\n. Issues with the fix:\n- The secret \"SocketStream\" is hacked/baked in.  It should be injected as an argument.\n- ~~Testing http requests fresh to the same route '/', I get the same session as the websockets, but when testing other routes, it's not the same.  So there is more work to be done there.~~ Testing just now looked good, but, needs more testing on http routes and sessions.\n. I think it's good now but would like to hear test results from you.\n. @thepian  I'm not sure what you mean about examples or bundling.  \nI'd like to add this library to the package.json for use in SocketStream's server side development.  It may have no use on SocketStream's client side, but I suspect it will.\nEventually I'll elaborate the case here -- for now I just wanted to introduce the idea / solicit feedback and conversation.\n. [a bit more about this]\nFor a long time I'd been deferring learning functional programming properly.   Or declarative vs imperative.\nI've been reading this blog a lot \nhttp://bartoszmilewski.com\nI've also been immersed in a lot of reengineering projects, in particular really a long term thing with a C++ codebase.  \nI considered maybe SocketStream might benefit moving forward from implemention leveraging these tools.  Clearly I can create branch of my fork devoted to it and start there -- but also wanted to hear from you about it.  Also, if the dependency were there on the master branch, it would be possible to (feet wet) start using the API in a small way experimentally, before making really more drastic changes.\n. I don't think there would be any improvement implementation-wise.  (I wonder if) Structure and organisation of the code might be improved substantially; better maintainability.  Just a hunch based on current research.  Really just a guess and indication for more research and experimentation.\nfrom\n\nI am sometimes asked by C++ programmers to give an example of a problem that can\u2019t be solved without monads. This is the wrong kind of question \u2014 it\u2019s like asking if there is a problem that can\u2019t be solved without for loops. Obviously, if your language supports a goto, you can live without for loops. What monads (and for loops) can do for you is to help you structure your code. The use of loops and if statements lets you convert spaghetti code into structured code. Similarly, the use of monads lets you convert imperative code into declarative code. These are the kind of transformations that make code easier to write, understand, maintain, and generalize.\n. also see:\nimmutable-js#the-case-for-immutability\n\nI don't mean to distract from more prosaic near-term goals.  I've really been hit hard with some reengineering problems recently, and high level issues of how to develop complex software systems is very much on my mind these days.  Could say I've adopted a paradigm of continuous reengineering. \nI'm looking at how SocketStream works in some detail, and thinking about ways that it could work better.  Especially given newer tools and techniques.\nGiven SocketStream's current implementation state, there may be exactly zero advantages to such changes other than code organisation, practically merely an esthetic consideration.  On the other hand, such improvements in structure may improve extendibility.\n. For now I'll branch on my fork and play around with it.  I will be looking for examples that I could share here, as you've indicated.  \nmore links list: (will add as find)\n- https://discuss.reactjs.org/t/examples-of-stateless-components-immutable-stores/277/2\n. no stress :)\n. I will contribute to this next week.\n. etstream/lib $ grep -R \"secret in engine.io\"\nwebsocket/transports/engineio/index.js:  c('secret in engine.io', secret);\nmy bad.  I would need to pull latest and some associated tasks before PR for it.\n. fixed at\nhttps://github.com/socketstream/socketstream/commit/495229c25a72de0bf30cfde1c2e2fe6991dd2f9b\n. Why not just make the core router use Connect ? \n. ",
    "tpisto": "That's not the case. They are not given then to the browser at all. When I have pure JavaScript version of app.js, then they are minified and concatenated and given to the client. Please try to run \"nodemon app.coffee\" and you'll see the bug.\n. Sorry for maybe bad description. \nss-jade has \"extensions: ['jade'],\"\nss-hogan doesn't have, since \"hogan files\" are not named like myfile.hogan\nAnd thus ss-hogan is not returning \"extensions: [\"hogan\"]\"\nI fixed this issue causing errors in my pull request.\n. That's not the case. They are not given then to the browser at all. When I have pure JavaScript version of app.js, then they are minified and concatenated and given to the client. Please try to run \"nodemon app.coffee\" and you'll see the bug.\n. Sorry for maybe bad description. \nss-jade has \"extensions: ['jade'],\"\nss-hogan doesn't have, since \"hogan files\" are not named like myfile.hogan\nAnd thus ss-hogan is not returning \"extensions: [\"hogan\"]\"\nI fixed this issue causing errors in my pull request.\n. ",
    "mgutz": "So how do you use hogan for views? I don't want to use jade.\n. So how do you use hogan for views? I don't want to use jade.\n. ",
    "jenglish": "Using ss-jade/wrapper.js as a guide, it was pretty straightforward to add Hogan support for views.\nSee here: https://gist.github.com/jenglish/5391231\n. Using ss-jade/wrapper.js as a guide, it was pretty straightforward to add Hogan support for views.\nSee here: https://gist.github.com/jenglish/5391231\n. ",
    "thepian": "http://eric.themoritzfamily.com/websocket-demo-results-v2.html\nhttps://github.com/ericmoritz/wsdemo/blob/results-v1/results.md\nhttps://github.com/socketcluster/socketcluster/\n. https://github.com/rajaraodv/redispubsub\n. Something to compare with that has a very good explanation could be the base for one of the example apps\n. I'm adding a minor modification as part of #465 which allows referencing any code relative to the client folder. That takes care of bower if you include it in client. Not sure about npm if node_modules remain in the project root.\n. You can now do that with what is in the next branch. We just need an example/documentation.\n. @kulicuu If you want to work on this you should pick up #455 \nIt would be really neat, but I think it could easily be left for past 0.4, perhaps 0.4.2, assuming 0.4.1 are fixes based on feedback\n. This can be done as a plugin. I would suggest to treat this a Documentation Request\n. With 0.4 you should be able to make a modified bundler that does what you want. But I suppose we could still have a look at supporting more options for bundling templates.\nOn a project I work on we bundle Angular templates in a javascript and serve them with the code. Although it felt strange to me at first, I must admit that it has few drawbacks I can think of.\nSo I'd like to see more options around template bundling.\n. I think it is important to ensure that you can still explicitly have @import statements in the compiled CSS if that is what you really want to do.\nLESS and SASS formatters make the distinction, so it's important that this is a formatter responsibility not one in the bundler.\nThe simplest solution is to have a CSS Import Combining formatter.\n. The relative URL of assets now work the same in development and production in version 0.4\nIf you want to resolve @import statements in CSS you can make a custom bundler that does it for you.\nSo to me this is fixed.\n. I've done various implementations of this for EssentialJS\nIt turns out that 'console' is a magic keyword on IE8, so you can't even make a variable called console and have it work properly.\nGiven the line \nvar console = {};\nWhen running without the debugger console will evaluate to undefined!\nYou have to convert console calls to something else on the serverside, or provide a console API.\n. I would recommend using an upgraded approach where you can ask for a console API for instance\nss.logger(logic_name) or ss.logger(module)\nThat way you get more benefit and you only have to minimally adjust your habit of writing console....\nI think it deserves a standalone module, and I'd be happy to contribute. Once I have refactored EssentialJS to have a minimal core, I can contribute such a module based on just the core if that sounds like a good idea. Currently Essential is about the size of jQuery which is a bit bulky.\nThe current implementation can be found in https://github.com/essentialjs/EssentialJS/blob/master/js/essentialns.js\nLook for proxyConsole\n. TBH I suggest closing this issue as a wont fix. IE8 is rapidly dying even in Enterprise.\nIn a real setup you should have a build step to ensure that there are no console log statements in your production code, and other libraries take care of this sort of issue.\nThe golden fix would be a plugin that adds init code for legacy browser hacks\n. I don't think this is a Socketstream concern. There are libraries to take care of these, and many approaches. Stubbing, is unfortunately not an option.\n. We now have a branch with a solution\n- view specific constants can be defined in the defintion. They will be global objects in the browser.\n- global constants can be defined with ss.client.send('constant', 'name', 'value')\n- documented\n- constants are passed to formatters\n- locals map supported as well for tempting information\nTODO: \n- template_engine\n- more tests\n- disable live_reload during tests (runs out of handles)\n- document recommendations for writing formatters \n@paulbjensen can you have a quick look if this seems Ok\n. @mdedetrich How does this match what you were doing?\n. This issues is more complicated than the pull request. It is more like early/late loading. \nFor CSS you can choose to load all or just the essentials in the head depending on the size.\nFor JS you want most loaded in body, but shims and shivs are better in the head for consistency.\nThe better solution is to divide CSS and JS into semantic streams that can be placed in the right spot according to the configured policy/strategy.\n. Closing this to make a better issue #525 entry for 0.5\n. We should be able to provide an explicit way of packing resources without starting the server. Ideally I'd like to do it together with the Gulp shortcuts #473 \n. I suggest we do this for 0.4 rather than 0.3\nCould be done in tandem with Gulp integration/support\n. @paulbjensen It seems packing assets was a binary choice for all views rather than per client. Shouldn't that be a flag per client/bundler ?\n. This will be an experimental feature in 0.5 using Gulp underpinnings. You can do it with ss.start('pack-all').\n. now in master\n. I don't see any grunt hint. Do I just install jshint globally and run it on the project?\n. btw, be careful not to go overboard. As an example,\n(_ref = options.packedAssets) !== undefined\nvs \n(_ref = options.packedAssets) != null\nIs not the same test. Quite often null and undefined values are synonymous, so == null is the correct test. eqnull: true should allow such a test.\n. I just saw that as a linting refactoring, and I wanted to point out that the tests are not the same. I personally favour VAR != null, as it will accept anything other than null and undefined such as \"\" or 0.\nIn #465 I have relaxed the linting rules a bit as they seem very aggressive.\n. I'd suggest that we have two jshint files. One for lib and one for unit tests. This way we avoid linting fixtures and other auxiliary files. And we can adjust the rules to fit the purpose\n. That might be a good idea, you might want to drop in quite nasty stuff for fixtures\n. @RomanMinkin what should we do with this story?\nWhile I would love to have no linting issues a lot might be lost when merging with 0.4\nSecondly the linting issues remaining are quite concentrated in engingio.\n. Now we have a commit hook to disallow jshint issues\n. @drauschenbach I will be fixing this in the coming weeks for 0.5, any experience you would like to share on this?\nIs there a documentation page for PhoneGap behavior on cookies/local storage\n. Done\n. @mooglin Are you still having this issue? It seems to be a connection issue around engine.io that may be related to CORS / Cross-site access. Have you tried adding CORS handling middleware to the server?\nI suggest closing this if there is no progress.\n. @mooglin With the improvements in 0.4 you should be able to fix this.\nAssets are in the same location during development and production.\nYou can pass constants to the client by adding them to the client definition.\nObtaining session id through a cookie would be a problem with local files. This should be addressed in 0.4.1 as the general focus.\nFeel free to continue this request/discussion under 0.4.1\n. @luksch Where are you on this? I think this is the only issue with Socketstream that isn't being resolved.\n. That is fine. However I want to have a solid solution of this at a known and reasonable timescale. IMO the best solution is to write a set of tests for the scenarios that must work. Do we have a couple of months runway to get this figured out?\n. Ah is HAproxy exposing multiple servers on different ports on the same public ip and then passing the traffic on to the servers. This would mean that the client would see them as being on the same domain.\nWhat you want to achieve is that the clients are directed to a single server all the time, is that correct ?\nI've never tried using HAproxy, so I don't have an opinion on the best config.\nIt would be great if this is merely a need for clear documentation of production setup.\n. Any news on this?\n. So can this be closed or updated to reflect the current state ?\n. I have created a new story #524  for this, please do the planning there.\n. This is now fixed in 0.4, which we hope to release in a month or so. If you want to try it out check out the next branch. \n. -1\nI think it a bad idea, no matter how appealing it seems. Getting to play with a new thing with the least possibilities of something going wrong is important. Any stone in the road will limit adoption.\nA minimal install is also useful for test environments. Relying on other processes running makes CI setup more complex.\n. Btw, I think Redis is brilliant. Just think it should be a plugin. It could have support in the core. It could even be in the core, but it should remain optional.\n. Do I understand this correctly in that the cookie connect.sid is the current session ID, and you would like a way to set that to JSESSIONID ?\n. @klausb I've created https://github.com/socketstream/socketstream/pull/523 which should fix your issue.\nWhat do you think?\n. If it doesn't solve your issue please reopen, it will be part of 0.3.12\n. Looking forward to that. In my solution I lean more towards creating bundles server-side out of multiple bower files rather than ending up with a pile of individual requires.\n. The good thing about _serveDev is that we can just change the meaning of the URL, as it isn't deployed. Do you have any progress on this?\n. I will soon have something to show on #465 that should solve the problem.\n. http://localhost:9001/#/tutorials/client_side_development\nI've changed the _serveDev/code , css , worker to serve relative to /client rather than the asset specific directory. That would allow you to put bower components into /client/components and specify files directly. Client definitions starting with dot are treated as relative to /client, otherwise as normal.\nOf course you can always require / import from bower components indirectly from the client view source.\nWhat do you think?\n. @paulbjensen Could you have a look at the next branch and see how you like the option to use relative dependencies in client defs.\n. bower listing: https://www.npmjs.com/package/main-bower-files\nsourcePaths gets confused when root is below node_modules base.\nPerhaps there should be a magic directory called modules/ that is meant to mean location in bower or npm. \nMagic paths in project\n- client - the actual client path\n- server - the actual server path\n- modules - look up modules in npm or bower\n. I'm used to building quite large web apps so my solution might be overkill, but if you can sketch how you think it should be done I can help out with an implementation.\n. How about this?\nhttps://github.com/thepian/socketstream/commit/c0bea3c1c3a8bf43d84bd1176dfccfd0d0715165\nIt changes send so it will override any existing sources with same name. It also splits out shims which should be loaded before libs.\n. Pull submitted\n. sorry my mistake leaving in an extra \n. I plan to drop this with the new bundler structure. I doubt anybody uses it, and you can make your own bundler with this behavior if you need it.\n. in my fork I've started working on a bundler abstraction that can be set for a given client. The API wouldn't change, just allows passing a function to ss.client.define\nss.client.define('test', function(ss, router, options) {\n    return {\n       define: function(client,paths) {\n         // client.name and client.bundler is already set\n         // you can set properties on config\n       }\n    };\n},{\n// my paths passed to define\n});\nI'm moving the current bundler behaviour into socketstream/client/bundler/\nWhat do you think?\n. You can then write a bundler with Browserify 3, or even RequireJS if it pans out.\n. Paul would you agree with a slight refinement:\nIn Socketstream the deliverable is self-contained views. Optionally you can extract common assets across the views to reduce the payload size of your views.\n. or is the terminology a client; In Socketstream the deliverable is self-contained clients.\n. Lately I've taken an interest in web pack, it seems better documented than Browserify. But both seem to have active development.\n. Very interesting. I use Browserify at daytime. It find it good, but the documentation is lacking when it gets advanced. The project doesn't quite match what we need, but could be made to work.\nI got interested in web pack as it seems well documented and goes as far as providing hot plugging.\nI think the React guys are very skilled, and jspm seems related to that. I also think ES6 modules is a very very important feature in the near future. As I understand it jspm is a build tool, not a library with an API. To make a plugin or to build Socketstream upon I'm looking for a good alternative. Socket stream internals are possible, but seem very obscure. Web pack should work, but don't interface very well. Perhaps SystemJS might be the best solution, and looks like it is the sort of thing needed.\nI will park my current work with web pack and play with SystemJS.\n. I'm having a look at it, but so far it seems like an better implementation of require.js, which is conceptually very different from browserify and webpack. Hopefully there is more as I get further.\n. That is fine, but it seems like the only way to use it for Socketstream would be a wholesale replacement of how assets are served in development. To me that is at least a third of the codebase. Anyhow I think they way forward is the way I have done it in the current feature branch.\nThe current branch leaves everything working as it does, but allows replacing the bundling per client view.\n. The objective of this task is to make it easier to completely replace how JS/CSS/HTML is bundled on a per view basis, leaving the default bundler to behave as present. I proposed that as the original refactoring attempted two years ago met a lot of resistance for not being backwards compatible.\nI am not trying to pick a winner for a replacement bundler, but rather leaving it up to 3rd party to provide one. Ideally it should be possible to base one on Browserify, RequireJS, WebPack, JSPM or some future fancy.\n. I think I have something close to working. The API seems like a reasonable starting point.\n1) The default bundler is quite small ~150 lines calling common internal code.\n2) Alternate bundlers should be possible\n3) A bit of documentation has been added\n4) I will give a WebPack plugin a shot to see how it is to work with the API\nI would like someone to have a look at the idea of dev time URLs supporting alternate client source file structure. We should also add tests for this.\n. var webpackBundler = require('socketstream/lib/client/bundler/webpack')(web pack);\nThis is an alternate bundler for trying out modern bundling or as a base for your own implementation.\nss.client.define('today', webpackBundler, {\n  view: './views/today.jade',\n  css: './css/today.less',\n  code: './code/today',\n  tmpl: '*'\n});\nIt is my notion that the relative paths can also be used for the standard bundler\n. The default bundler should be pretty much done. I think the only thing remains is a sample browserify/webpack bundler, and perhaps some tests.\n. I think I have a good solution ready in a pull request. I will merge to 'next' if there are no RFCs in a day or two. The next branch will become 0.4\n. Thanks. Got a webpack bundler mostly working, and I think JSPM wouldn't be much of a problem either, or browserify for that matter.\n. Now part of next. Needs more love, but should work.\n. Wouldn't you define a middleware in your socket stream config that adds the headers for your JSON ?\n. 1) Abstracted asset bundling to allow configuring alternate bundling strategies per client. It is now possible to create a bundler based on RequireJS or Browserify 3.\n2) Allow piping production assets to disk through Gulp build streams, or plain Node JS streams.\n3) System assets can be configured specifically and/or provided by the bundler for a client.\n4) Global and per view variables can be configured and provided to CSS,HTML,JS formatters\n. I think that sounds good. I'm currently leaning towards keeping Socketstream a lean framework with basic batteries included but kept very small and easy to conceptually grasp. Most advanced features should be possible through extension points of the default configuration.\nAs a beginner I want 2-3 compelling starting points with reasonable default suited for small projects like prototypes.\nFor a real product I would expect to have to do several integrations some of which are doable but take a bit of effort.\nAs a project owner the last thing I want is for my working solution based on Socketstream to hit a wall and require core rewrite. As long as the internals of the deployed Socketstream can scale pretty much infinitely, I think that qualifies.\nIt seems that your suggestions should be based on detailed How To's that walk you through how to extend your project with plugins, custom code and configuration changes to achieve the objective.\nTo make it work I imagine that some internals will have to be tweaked, but it doesn't sound like fundamental changes or changes of the contracts of 0.3\n. @henrikvendelbo on trello\n. From my perspective I'm not interested in creating a new job for myself, have several as it is. I would prefer to evolve 0.3 with minimal breaking changes and just find places in the interface where we can slot in new features.\nAs an example I'm working on a pluggable bundler responsible for asset concatenation and packing. I hope to make a bundler based on Browserify 3 and support things like Angular template compilation. \nhttps://github.com/thepian/socketstream/tree/master/lib/client\nIt allows you to define a client with a function that manages all bundling instead of the usual paths object.\nss.client.define(\"members\", require('magic-bundler'), {\n  bases: [\"client/app\", \"lib\"],\n  bower: true\n});\nI plan to make some refactoring like this to be used as a new backend for our website.\n. Added a column for API changes, I think it would be good to manage them tightly and separately from implementing actual functionality\n. I like the idea of having rethinking prototypes, but ultimately figuring out how to turn them into evolutions not revolutions.\n. Sorry bad wording \"rethinking prototypes\" for experimenting with changes of Socketstream, coming up with forwardlooking functionality. And then once we know that the feature makes sense, figure out how it can be integrated without breaking compatibility.\n. Personally I'm the first one to come up with innovative technology ideas, but I've been burned by it so much that I really don't like it in \"other peoples libraries\" that I use :-)\nI went with Socketstream because it seems well written, small codebase, and pragmatic. I'd like to keep it that way. After all most things can be done from the outside as a consumer of Socketstream. We should just try to remove obstacles for people to \"get shit done\"\n. Web-RTC is very interesting. It is however a bit privacy challenged. I believe the IE and Safari team are staying away from it for that reason. Access to webcam and microphone is something a lot of people want to have tight control over.\nAs a transport mechanism it is interesting, but how would you do fallback behaviour on IE and Safari ? Communicate via the server?\nI would start with an experimental branch and make a PoC for an App. Then add hooks in Socketstream to allow a plugin to provide an alternate P2P transport. It does seem like a very different concept from Websockets and regular http. The only cross platform application of an abstracted WebRTC interface I can think of is P2P file transfer. Is that really something Socketstream should support ?\nOr are we talking about P2P video/audio streams? Then what is the fallback, Flash?\nAll in all. Very interesting, but not sure about relevance.\n. I'm interested as well, but I think it is something to support with a transport plugin api. I plan to use intercom.io for this to the extent that I need, but I can see the relevance for games.\nThe reality is that realtime web is a small set of use cases, and games are an important one. Made professional trading web apps for banks for a number of years and they are one of the few non gaming/gambling scenarios.\n. Sure just need it in my calendar so I can log in at the time. Will be on holiday, so will have to plan a bit.\n. sure. Is this a hangout? I don't know where to join\n. I don't think I can get it to work. The WiFi here is pretty spotty, so not really a surprise.\nMy main wish for a roadmap is to have a builder based on latest Browserify and/or WebStack.\nSecond wish would be creating a working demo based on Express 4.\n. I'm away Wednesday until Monday, but this time I'm in Europe, so hopefully I will have reliable WiFi whenever it takes place.\n. Because I have a file named that in the /client/static directory\n. I know where it happens. eventMiddleware in http/index.js\nThe comment basically documents the behaviour. It seems that switching to static cache fully is a good idea.\n. I'm making a feature branch to fix the issue and making a strategy setting for overriding a default HTTP resource strategy. Sound good?\n. https://github.com/socketstream/socketstream/tree/feature/470-static-paths\nStill need tests and docs. Any comments?\nAnd of course I need to fix the actual issue.\nThis should make it easy to make a connect 3 strategy or an express strategy\n. fixed\n. I see this as a way to feed views into gulp targets for generating production code. I suppose that there could also be a way to feed gulp tasks into views. I think gulp based formatters should be a thing.\n. by view I mean view definition. ss.client.define\nSo feeding the assets defined in a definition into a gulp task. Say for instance you want to use SS to bundle the view, and then gulp to pack and annotate it.\n. The task support is now in 0.4.4, I run via gulpfile.js in development. It works nicely \n. Do Gulp error handling https://github.com/gulpjs/gulp/issues/216\n. Hmm, looks like I broke something with the static strategy.\n. Sorry, didn't test it yet, was just apologizing as it seems to be my commits.\n. I'd like to fix it. I'm not sure how to run your project though. tried calling\n'coffee laTrappe_local' it cannot locate socket stream\n- fixed by 'npm link socket stream'\nNext problem is redis install. I have redis on my machine through home-brew.\n- fixed that with brew tap gapple/services\n- redis running now\nWhat is your test URL, the index page is blank.\nI tried /laTrappe_local_alpha, but that doesn't seem to be it\nAlso you have a trailing comma in the package.son\n. I'm not sure what to expect with La Trappe. I see issues with Angular template script tags having IDs with the file path, which surely they shouldn't have.\n. Could I ask you to make a detailed bug report. Ideally a test setup that fails. We really want to move towards TDD.\n. Won't fix as ES6 is the future. Pull requests welcome though\n. Perhaps this could be the task to add a couple of tests for live_reload\n. Btw, I just saw live_reload kicking in while running tests. We should also find a way to make it inert while running the tests that do not depend on it being active\n. I'm sure it's trivial, just a reminder to do it :)\n. Is there any reason to support node 0.6 ?\n. I fixed it in master as well while fixing up some require vars\n. Made some improvements\n. As it seems 0.3.12 is the new next release, I would suggest also making a 0.3.13 milestone. Some improvements might be pushed in the future while we are preparing 0.3.12\n. Thanks. How about the idea of having a separate branch used for the next major release? I'm not sure what name to suggest\n- future\n- major\n- next\n. of course!\n. You seem to be right. It must be a leftover. As api = ss, it is redundant as it is available from the init of client overall.\nOn you second point I disagree with you twice.\n1) It isn't a systems entire API, it is an internal API for all modules.\n2) Socketstream isn't a client and a server. It is a single server that bundles code for the client. Sharing functionality between the streaming side, the asset serving side and the bundling side makes perfect sense to me.\nOr are you saying that somehow the client code actually executed in the browser can RPC the api object on the serverside? That would be a very bad idea indeed.\nThat said, I'm only 90% convinced about the patterns for implementing Socketstream. I can't think of a better way to do it though.\n. Excellent. I seem to have Express 4 working, but haven't really gotten to a well rounded setup. Sounds great if we can base things on the latest connect.\nDoes this mean that we should make a connect based Router rather than our own Router implementation ?\n. This is a good discussion, but can we change the title to something actionable. Having tons of unresolved issues detracts from the project\n. Will go in with the bundler\n. I'd like to see this merged before it grows stale.\nHow does it fit with the release schedule, is it supposed to go in the next release. If so conflicts should be resolved, and it should be merged if it works.\nIt looks like this needs to be merged with the http strategy changes.\n. Would you be able to\n1) Clone the repo\n2) Make proposed changes / fix\n3) Make a pull request for your repo\nEven if we tweak your solution, it sounds like a completely reasonable feature request.\n. @paulbjensen Is this now fixed ?\nWhat about test coverage?\n. I think single page applications are just the latest fad. They've been my bread and butter for most of 7 years, but they are a vertical solution hosted within a multi-page reality.\nI think the two will merge as streaming becomes more widely adopted. \nI personally want Socketstream to fit well in a multi page app world. \nHowever I am a little apprehensive about the number of fads going on in Open Source. I want to make\nproductive systems, and I'm wary of basing my work on libraries that will be out of fashion in a couple a years. I also want to be able to find developers with experience. In that respect I expect 90% of Node developers to know Express and not much else, probably also Connect.\n. I don't mind the fads. However I am wary of spending energy on them before they hit critical mass\n. After getting stuck with a refactoring blunder, I'm really curious about routing alternatives for the dev-time middleware. Is Koa or Sails and easy option? or does it require a lot of thought/discussion. I'd prefer to keep all principal / fundamental changes optional to have good continuity.\n. _serveDev is partially for dev-time only. My thinking is that it should be a specific middleware only loaded in dev. It is at least conceptually.\n. Should we replace our Router impl with some existing npm module like 'routes-router' ?\n. @afrozl ss-examples has one for Express4, it is aimed at SocketStream 0.5 which is not stable yet.\n. @arxpoetica Have you looked at some of the changes? Any thoughts?\n. I agree. It is next to impossible to keep a robust implementation without that.\nIdeally it would be twinned with default project generation, the default project skeletons are used to test the framework, and they are tested at the same time.\n. I think you should have an examples directory with a separate package.son, otherwise I would suggest a separate repo called \"socketstream-demo\".\n. When do you see us have the first version of this ready, for 0.3.12 or 0.4 ?\n. The #465 branch is now ready for testing web worker serving.\n. Are anyone using web workers? Is there an app anywhere that I can look at?\n. Paul, are you Ok with this ?\n. The pull request is basically done. Just need to add tests to make sure I haven't broken too much. Feel free to check it out.\n. I've merged with latest master and I have a lot of tests blowing up. If @kulicuu, @lafras-h or @paulbjensen could lend a hand tracking down the issues that would be great. If not I will figure it out. \n. sorted\n. I try to follow \"git flow\" convention and make a feature branch matching an issue. Not sure what else to do.\nI see no problem with having many branches. They should be kept alive though, or they might end up diverging too much. However even then they can be used for reference or revived.\n. By alive I meant: up-to-date with the latest master or next branch (depending on whether they are for the upcoming minor or major release)\n. We should clarify this in docs\n. hmm, interesting, I tried running it against laTrappe, and it shows all red in Chrome fetching CSS/JS.\n. Fixed a typo\n. I think there are two thoughts when it comes to testing code structure. One is to keep it with the source, another is to keep it separate. I find that keeping it separate often comes from Mavens structure of /main and /test.\nFor unit tests I prefer to use the file extension to match the tests I.E. '*.spec.js'. If there are few test specs they can be saved along with the source they test. If there are many they can be put in a sub-package.\nTwo benefits of keeping source and unit tests in the same folder are that you can switch between them without IDE support, and that since they are visually close you are nudged towards writing more tests.\nFor integration, e2e etc the tests are often cross-cutting, so they don't fit very well with the source structure. For those I think they are best placed in a root /test directory.\nNow on to your question, which I've probably misunderstood:\nI don't see any problem with mixing JS and CoffeeScript files in the same source tree, so I would suggest that you put your new test scripts under /test/unit in the appropriate area. That is where the existing tests are (even if I would put them with the source)\nOr are you talking about unit testing of the new examples? In that case I would put it under /test/examples/unit or /examples/test/unit\n. I think we have to have a single test suite in SS. Allowing each contributor to make a whole new setup will become a mess. When you have two it is slightly confusing, when you have 5 it is a mess.\nI think there can still be some variation in how tests are written, but there has to be a minimum level of consistency.\nIf the SS source wasn't consistent and minimal I would have dropped it the first day I looked at it. I would expect many others would too. While it can be frustrating to write code in \"other peoples crappy way\", I don't see a way to avoid it.\nThe only exception would be if there is a large body of work that we are importing and we don't have the resources to refactor it. Then it has to be grafted on, at least initially.\n. I think this is really up to Paul to make a call on. I'm just stating my opinion.\n. I used to love them as well. I use them to make my own development simpler. However they do introduce dependency management in addition to the one with npm.\nAn alternative would be to have an example repository under socket stream say /socketstream/examples and npm publish that as \"socketstream-examples\". We could then put it as a devDependency for socketstream.\n. My solution is to offer a new API where formatters and template_engines are functions that return an instance. They could actually be called with new. That way you can supply a factory function or a constructor, and either will work.\nThe old API with init call will work unchanged for 0.3\nI will try to use a streaming approach like in Gulp so they can be used as part of a build chain as well.\n. @RomanMinkin Didn't you make an Angular template engine? Are you using suffix and prefix?\n. I tried vinyl-fs long time ago. I find streams a bit difficult to Grok, so perhaps it is something to have under the hood and not in the default interface. What I really like is the notion that one file might result in multiple files as output.\nMy current approach is to stick with the current callback api and support returning an Error instead of throwing it, as the throwing is incompatible with async.\nI thought of a promise like (resolve,reject) semantic, but I don't think it adds any power. I think the streaming could be introduced as an internal principle allowing easy extension/integration with gulp tasks. The templateEngine and formatters would run unmodified, but support an alternate API for direct stream implementations.\n@RomanMinkin So only selectFormatter but no suffix or prefix?\n. will be merged as part of #465 \n. Why the capitalised names? Is that required by live-reload?\n. Sounds nice. I would love to see an example of that.\n@paulbjensen I'd like to reiterate a request for a second GitHub repo 'socketstream/examples' for this sort of stuff, we could put it on npm as ss-examples.\n. I've made the repo to put this in,\nhttps://github.com/socketstream/ss-examples\n. It's an app that monitors the PR for drops in test coverage, isn't it. I've never used it so I just assume things. Perhaps Paul can give more details\n. Yes\n. Can we get an acceptance criteria for this, please? Not sure what need to be done other than documenting a bit under contributions\n. I see 0.4 as non-breaking, at least for 99% of users. There are new APIs, but old ones are supported.\nDoes this involve any code change? semver module for instance\n. +1\n. 73% coverage btw. Yes I know even at 100% it won't be enough, but it's rising.\n. Only thing outstanding is nodemon. I don't have time to document, but anybody is welcome to do it.\n. My ignorance knows no bounds. Looking forward to your findings.\n. connect.sid seems to be a cookie controlled by Express/Connect, so it is up to the application dev to configure how the cookie is set. Ideally it should be up to the application design whether this is kept http only.\nDoes engine.io need it in the browser for load balancing ?\n. False alarm, I'm sure all is working fine\n. @kulicuu If you have time I would love to figure out why the ss-example for connect and engine.io doesn't work ATM. Did I break sessions or something else?\n. Where are you accessing this DB? The ss.api is passed to plugins as the variable ss.\nFrom your application, I'd expect you to have a module that exports the database client so you can share it among app modules without involving socketstream.\n. Actually I think writing articles about how to use Socketstream on other destinations is much more important. We should actively try to extend the community. The docs are not great, but they mostly do the job. The ideal would be to recruit someone that has helped make stellar docs on another project.\n. I didn't break it, just wrote a bad test, however the question remains; Fundamentally.\nAre we happy with the current logic?\nYou can assign a template engine to a path. By default it is root. (is root the client dir?)\nYou can't assign it to an extension or a pattern. Perhaps it could be a combination of,\n- The engine suggests a file name pattern or extension\n- The app assigns it to a FS branch.\nSecond Question:\nWhat about prevEngine if you look in wrapTemplate it seems to assign it, but that (at least in my modifications) is a function parameter, so it means nothing.\n. Pushed the tests to the logging branch. We still need tests for subpaths and for custom template engines.\n. Do we know of any engines that rely on prefix/suffix of template markup?\n. I think I understand it now\n. Perhaps add a bit of testing so coverage doesn't suffer?\n. Sure nm, we probably merge from next to master anyway. It would be nice if it was merged to next as well though, so people can test out next without loosing hot fixes.\n. @paulbjensen Could we move tasks to 0.3.13 so 0.3.12 can be released soon ? We are getting close to 0.4 anyway so might as well cut down on 0.3 release scope.\nI cut down outstanding 0.3.12 work to be this plus session stuff. So hopefully we can do it soon.\n. user on npmjs.com is thepian\n. Could you try to branch of next rather than master, I've put quite a bit of additional documentation in there.\nI really do not feel like merging all those comments and converting them to JSDoc.\nI expect that 0.4 topics will be complete within the next month, so that would mean that there is a release candidate for it then in the existing NG Docs format.\n\nOn NG vs JS docs.\nNGDocs don't seem to fit that well with the Socketstream source structure, so the API docs generated are a bit odd, but mostly O.K.\nI'm not that sure that JSDocs is an improvement. When I last worked with it (granted quite a long time ago) they generated quite unattractive output with at structure that wasn't terribly powerful. I recall them as a straight imitation of JavaDoc, which was cool when it came out, but hasn't really evolved in terms of usability.\nFor the examples/tutorials I can imagine we could do better. I assume you are not aiming to use JSDoc for this?\n. I just used bourbon.io ; it's quite nice, I wonder what they made it with\n. Great\n. I think the fundamental strategy should be\n1) Keep a steady stream of improvements to Socketstream (at a manageable pace)\n2) Satisfy one existing fronted dev community at a time\nIMO streaming is a niche feature, so pitching to the converted is not the best use of time. Better to show the usefulness to people that are not used to it.\nI'd like for instance to show really good support for Angular to that community, and then move on to another community.\n. http://samwize.com/2014/01/31/the-best-documentation-generator-for-node/\nhttp://underscorejs.org/docs/underscore.html\n. How about the separate var declarations, does linting(hate autocomplete) complain that they should be one statement?\n. I like the look of it, but lets hear some actual benefits. If we take it will it become a requirement, or optional?\n. I failed to move things into the in progress column, not sure if it's bug or restriction. The interface looks really nice though.\n. Since there seem to be no objections lets try it\n. Reimplemented it for 0.4\nhttps://github.com/socketstream/socketstream/commit/669f000ae9bc22df87b1fb8f064f2c4877d8722a\n. A) Glad for the thumbs up\nB) You can help by trying out 0.4 and reporting any issues you have as soon as possible, it is on the next branch and will be released in beta soon\n. It is now released as 0.4.0-beta\n. Not sure, but we need to be forced to make tests and stick to our linting rules. Personally I don't care about 90% of lint rules as they don't help me read or write the code, but some are a good thing. If there are too many messages we should reduce to a set of rules we can apply and stick to. For code coverage, we have to get to 100%. Refactoring without knowing what is expected and not is impossible. I am making a lot of decisions when refactoring which may or may not be the right ones.\nI would prefer to not use houndci, but I think we will not stay on top of our code rules without it.\n. If we don't use something like hound, I think a commit trigger or watcher is needed\n. Guess nobody cares\n. me too :) I want to follow up to feedback to 0.4 that I saw on the forum first though. I want to be sure there were no bugs introduced in the rewrite.\nI'm hoping @kulicuu will want to work on this, or someone else as I use SockJS myself\n. @kulicuu very interesting as well\n. +1\n. I will have a look at that. Do you know that it is supposed to work with the latest connect?\n. That was my assumption, but the deprecation is express not connect. In connect it seems that just a part is deprecated.\n. @kulicuu Did you read anything about this when upgrading Connect ?\n. @luksch Can you check if connect.bodyParser() is still there? If not this is really a connect issue, then it is missing documentation. I think prepend still works, but I think tests are missing for that.\n. Shouldn't test resources be in the fixtures folder ?\n. Running the tests will remove the README file as part of the pack file management, not so good. I have added a git checkout for the project fixture assets, but that seems like the wrong solution. An improvement on that would be appreciated. Perhaps we just shouldn't have anything checked into the abc directory and have a gitignore for it and the ensure the directory is there before those tests.\n. I'd like to suggest that we stick to merging new features into next (or the traditionally named develop) and leave master for minor fixes to the current release. That way,\n-  'master' releases is currently the 0.4 line.\n-  'legacy' releases is currently the 0.3 line.\n- 'next'(develop) releases is currently the 0.5 line\nThat way we can easily manage fixes, and when we release 0.5 that be comes the new master and 0.6 the next/develop\n. Indeed. Looking at some other possible fixes to squeeze in.\n. Yes I agree, but it still takes me an hour to release making sure nothing is broken. So I don't want to do it every day\n. On a tangentially related note I've noticed that engine-io client is loaded as a library. Shouldn't it be loaded as a CommonJS module ? Perhaps @kulicuu can comment.\n. I don't think it has to be a SocketStream plugin as such(although that is also an option). I merely think that the client code shouldn't be a mandatory library loaded regardless, but rather a system module that will be loaded if needed given the configuration.\n. If you don't find it I will try to write unit tests for 'ss.client.send' to track it down. Shouldn't be hard.\n. Ah, I mistook the API for being like formatter\n. Nothing should be changed from before, it was my mistake copying things around. I never wrote a template engine before, so I didn't know any better. It's fixed now, will do a release.\nIn 0.4 we also support a simpler API for formatters and template_engine. Instead of making an object with an init function, the formatter or engine is that same function. In both cases the first parameter is the Socketstream API.\n. Try npm install now, fixed by commit https://github.com/socketstream/socketstream/commit/19510e350cb7a8e0cf70b749ee8c0b3c5def2d7f\n. I think it is the problem we talked about before. The directory gets deleted when running pack for production I think. Tests should properly insulate this behaviour or we should tweak the logic for cleaning up previous production server starts.\n. Did you realise that you are making this against master (0.4.x) ?\n. I agree. The tests need a done callback. And we need to pass that to pack.\nHowever; I plan to move out the pack logic from load so it can be called as part of a build step. While the current model of \"just run your server whether dev or prod\" is a good default, but there will always be people that need/want more complex production setups.\nI did also think that perhaps we would want to refactor the server load/start as an async waterfall. That way it is easily testable and extensible.\n. @arxpoetica I think it should have an issue, but I think it belongs on our trello board. I am conscious about the impression we give about a long list of open issues.\n. next will need to catch up with master, that is part of the tradeoff. Of course the benefit is that we can take it easy with the 0.5 release and fix 0.4 which I think is quite important.\non your particular case, I don't recognise the problem, so I don't know if it is.\n. Is it hardcoded? It should certainly be read from package.json\n. @ilyador 0.4 should work like 0.3 with only one or two edge cases difference\n. Will be fixed in 0.4.3 with other asset related issues\n. no, I tried to make everything work as before. Are they still the same type?\n. To my knowledge there is 100% test coverage on template output, so I must be missing something.\nCould you have a look at the tests to see if they are as expected?\n. But are they rendered with the hogan template engine or with the default one?\nIt would be so nice if we have coverage to test this stuff\n. Ah. I know what it is ...\nI changed the base path of everything to be client rather than the type specific directory so we can have more bundling freedom. The default ID is encoding the path not the file name, as it should.\nI will make a special case for the templates directory.\n. Your issue is now fixed in the pack-assets-fix branch, misleading name, but it's the remaining work for 0.4.3\n. As a sidenote, if you had checked the unit tests it would be clear that the assertions are wrong as they include templates-.\n. A better fix is now on master\n. My thoughts are 'crap' :(\nI wasn't able to write a unit test for the recognising of existing bundled files, it should be a trivial change but clearly an annoying bug.\nentry.js and index.js should both work as there are unit tests for them. Something must be missing.\nRegarding 2 is the problem with the bundled version ?\n. @kulicuu Isn't that something mocha has documented?\n. @hulmgulm If you have any chance can you test #553 it should solve your issue point two. I think the only left is reusing existing asset files.\n. Got ya\n. Regarding point 1, I'm still trying to write a test that covers this fully.\n. Point 1 will be fixed in 0.4.4, others are on master and will be in 0.4.3\n. @kulicuu Hmm, does this mean that you need to configure the session secret twice in the app ?\nAnd shouldn't the API be like for the client\nss.session.set({ .. });\n. To me that is squarely in the examples / how-to bundle with bower/jspm/browserify category. I will add a documentation flag, sound good ?\n. Is it because they sometimes fail during coverage tests?\n. I'm attempting to extract a fixtures module with fixtures and utilities to reset and cleanup the project fixture before/after each test. Hopefully it will make test runs more stable.\n. Could it have to do with live-reload kicking in and executing more code?\n. I think it was. When I run it with the pack-improvements branch the coverage numbers remain the same\n. fixed in master\n. Wouldn't we want to move away from implementing a general purpose app server?\nI would expect that it is trivial to prepend a middleware which will serve special mime types. In production you should have the static server handle this anyway I would think.\nI'm not against the improvement, just think it is a distraction beyond documenting how to write your own static serving middleware for DEV time. There must be 100+ blog posts that explain how to do this with Connect/Express.\n. We now have an Express 4 example.\n. @paulbjensen I wonder what that 500 error is about, are we behind on coveralls package ?\n. I assume you put angular in libs. Did you make a libs_test as a copy of libs? why?\nThe documentation on libs explains that it's a special case where the file is loaded raw, not as a module. Angular isn't there as you didn't do a require for it, and it will not be a global variable if you do.\n. @EricCat Can you confirm this so I can close the issue?\n. No feedback on this. Working as documented it seems.\n. @havoc74 Since you are a user of ss-console I'd like your opinion on how to best evolve the console for SocketStream 0.5\nDo you have special wishes or any low hanging fruits that could be added/changed ?\n. We have unit tests covering this. My guess is that the new app skeleton needs to be updated somehow.\n. @hulmgulm can you run the test suite on Windows ?\nI'm very disinclined to set up a dev environment on windows, so I would have to rely on others telling me what fails. We have mostly removed any assumptions about path separators, but it could be that we have some issue with assuming a Unix OS somewhere.\n. fixed on master, new project now works on Windows\n. @paulbjensen  does the glob package work on Windows ? It is usually preferable to rolling your own\n. Perhaps we should try using multimatch module.\n. There is now a feature branch using the glob module, if anyone can test on Windows for possible fix that would be great.\n. I think Promises are a bad API, async is much more sane.\nHowever Promises are part of ES6, so we should treat them as a first class citizen. For that reason, I think it is a good suggestion. Promises are introduced natively in node 0.12\n. bookmark / stuff to consider\nhttps://www.discovermeteor.com/patterns/5828399\n. Perhaps the best is to start discussions about how to be the most productive with the async-ness of client-server development.\n. Contrast and review compared to Meteor and see where we can make Socketstream a better production/long-term choice and leave others to offer prototyping framework value.\nhttps://www.quora.com/What-are-some-downsides-of-MeteorJS\n. I think we want to move away from being a middleware framework as fast as possible. connect is 1000x more popular, it is the de-facto approach and it isn't anything we can do better.\nBy 0.5 I'd like to have cut out standard middlewares as dependencies.\n. I'm proposing to reduce what SocketStream does to focus on the streaming. The prepend and append only affect middleware configuration which is something 99% of users will do with a mainstream framework. That whole router code is quite smelly and it seems we have a couple of issues in view matching as a results.\nThe benefit of mainstream frameworks is the vastly bigger volume of people knowing how to solve problem X. For general purpose REST endpoint hosting there are tons of use cases, most of which are not really related to streaming.\nIn most projects the main hurdle is getting to the first release. Reading Pauls resonse I hear, \"SocketStream is a specialised framework squarely focused on top performance in all areas. It might limit your ability to do an MVP fast in order to push you towards performance\".\nI'm curious what the cost is of using Express middleware over SocketStream's approach for the regular endpoints.\n. Perhaps I should just provide an example and support for a way to run a SocketStream App without ss.http.middleware\n. That was my thought. It seems the argument is performance of serving views which puzzles me a bit. I would expect the difference between the alternatives to be on the order of 1ms\n. I'm looking at the various parts of ss.http\nI see require connect in there, but somehow it's not used for making the server. As a user of SS, I find that confusing.\n. I think I have found a better approach than my original suggestion, so I will close the issue\n. This is pretty close to what I plan to release\n@paulbjensen Would love thoughts\n. So SockJS is a second rate citizen?\nI really wish for fewer requires. Internalizing the wiring is fine but I really don't like all the dependencies. They should be passed in the app config.\n. I don't think it should be done like this. I take it ss-engine.io have tweaks that need to be pulled in?\nIn SS 0.5.0 I've essentially retired \nss-engineio \nss-sockjs \nss-jade\nss-sass\nss-less\nI'm really making all the most used plugins redundant while maintaining the support for custom plugins.\nIt's on the next branch and released as a beta.\nss-examples has a working ExpressJS example\nIt will however it will still be possible to use ss-engine.io as an external dependency\n. Retired meaning that they are built-in to 0.5, so you can add('jade') just like you would add('html'). You can make your own Jade formatter if you like, but I don't see any need to maintain ss-jade, so they are just there for people using <0.5\nengineio is built-in today, and I've added sockjs and plan to add ws. Likewise you can make your own transport and use it.\n. Yes, I've noticed. Had trouble on one machine. I would like to fix it, but also wonder about the userbase for iojs\n. iojs passing for latests master, can you check if the issue is resolved?\n. @paulbjensen any news?\n. For me it passes, but when run in a commit hook in Tower it fails due to colors being output. Some test needs a logHook to catch the build dump\n. ah you mean if you run it as a download, not a git repo?\n. removed the git checkout\n. Yes that is already supported in 0.4\nYou can use relative paths in code\nss.client.define('main', {\n    view: 'app.html',\n    css:  ['libs/reset.css', 'app.css'],\n    code: ['libs/jquery.min.js', '../node_modules/somthing/code', 'app'],\n    tmpl: '*'\n  });\nRelative paths are based on the client directory. I wish we had it documented.\n. I have only tried it with using alternate directories within the client directory, but in principle it should work.\nIt is still an open issue to support npm/bower modules installed anywhere in your project.\nclient/bundler/default.test.js:120 tests relative paths within the client dir.\nss.bundler.sourcePaths(paths) determines where source roots are located. If something doesn't work this is the function that needs fixing.\nYour issue seems to be in client/bundler/index.js:278\n. not sure what the question is. Are you referring to the URL scheme during development?\n1) It mimics the location in production to keep them similar and make CSS work the same\n2) It contains the client name, ID and type to use the correct bundler\n3) It contains the path relative to the client directory to support files outside the usual locations\n4) It contains a query to bust the cache during development\n5) The parsing of the query part should be done by the bundler, but hasn't been implemented yet\n. 3) It does work for file within the client directory, so you can load a JS file from outside client/code, but I don't expect it to work with ../elsewhere paths; Although it should. (still an open issue)\nThe idea was to support any asset path to be passed in the URL using the _ parameter. It would be a path relative to the client directory. The file in question would also have that as the logical path in browser source mapping (perhaps relative to project root would be even better, but that is quite a rewrite).\nThe idea was to leave the interpretation of the path to the bundler, but it is still being done in dev.js as it was before.\nThe bundler determines the list of client assets and links them in the HTML view. They are loaded by the browser and the bundler should resolve the paths as well.\nThe issue seems to be with socketstream/lib/client/serve/dev.js:55-57\nIt only interprets ./ not ../\nWhat it should do is ask the bundler to resolve the module\n. I've starting fixing this. The first part of pulling in stuff outside the client directory is an easy fix already on the feature branch. Second part is making require work for anything in the project directory. This means that the path in the bundle should be /client/code/abc.js not /code/abc.js\n. nope, everything working as before. It is all internal to wrapCode and what path modules are registered under which is unspecified. Otherwise it would be for 0.5\n. Lot's of little internal changes though. Started with 40 unit tests to fix, down to 6\n. The feature branch should now allow any client assets to be referenced inside the project using relative paths with the client folder as the starting point\n. We should change the new app template to fetch jquery from node_modules and have jquery be an npm dependency.\n. Perhaps I should change the templateEngine.use path param to be relative to the client. Right now it's relative to the project.\n. in master\n. I run SocketStream 0.5 on the latest NodeJS, all seems fine. I would actually consider making SocketStream 1.0 require NodeJS 4\n. ss.set('server.port',3000);\nss.set('server.port.production',9999);\nss.set('server.port.development',3000);\n. Doc:\nDEBUG=express-session,socketstream,require npm start\n. Hi there, are you talking about 0.5.0 or 0.4.4 ? 0.5.0 is an unstable release for testing only. Thanks for reporting.\nIndeed much is changing. calling start without an http server is now supported to facilitate gulp integration and running pack-all as a task. https://github.com/socketstream/ss-examples/blob/master/express-4-and-js/app.js\nIt means that transporter tests will have to be supported in a different way. There is already a task for that. If you can point me to an example test that doesn't pass anywhere, I'll be happy to fix the issue.\nUpdate: looked into your problem. The function to call would be ss.start('test-socketstream',done). If it works as intended it will go in 0.4.5\n. @cuckoopt Could you try out your tests with this: https://github.com/socketstream/socketstream/pull/590 ?\n. Sorry, I'm unable to keep up with all software details. Node 4 completely missed my radar. We can add Node 4 to the platforms tested. Does that bring Promises and other ES 2015 goodies?\nWith 0.5.0 we are moving away from bundling big dependencies in SocketStream. This means your project is checked for stuff like Jade and Engine.io and you can use the version you are happy with as-long-as it remains API compatible.\nI want to shrink SocketStream to a small bundle of glue that you can stick big pieces on and it will make things work together.\n. That is a cool comment. It does seem like a good linting target for projects. I can't think of any of our code that is done extensively though.\n. Amen. I need that as well. There are quite a number of things to do to make it feasible though.\nIt really is what I am working towards. In 0.5 the cookie session management is factored out into. It is however currently unstable so it doesn't work in production. You can however use it as a point for getting things to work. When #508 is done the next step will be to implement a socketstream-jwt-session module.\nhttps://github.com/socketstream/socketstream-cookie-session\n. @StuartHickey Have a look at socketstream-cookie-session repository, I'm making the session creation pluggable. It might already have enough for you to make token based auth\n.   The client will be built to be loaded with SystemJS EventEmitter2 will take place of EventEmitter\nengineio is based on EventEmitter, SockJS expects the client to be browserified\n. Also consider engine IO config\nhttps://www.npmjs.com/package/engine.io-options-from-url\n. @paulbjensen Perhaps you have an idea what causes this. SockJS doesn't fail\n. It was a bind issue, fixed.\n. just demoing\n. The HTTP side is intended to be essentially static in production. You generate bundles for HTML,CSS and JS. On demand JS is currently only supported on the server, but will be static as well in 0.6 or 0.8\nSo in production the only thing to proxy is the websocket connection and fallback support from SockJS/Engine.io\nWhat I'm essentially saying is that there is nothing in SocketStream itself that needs to be handled in production. You just need to serve the static and assets directories from your HAProxy/Nginx frontend and proxy to the SocketStream server for the connection.\nThere is no particular support for configuring the path for where the fallback XHRs go. You'd have to refer to the transport documentation for that.\n. Hmm, did you just mean the /assets/ URL? I haven't used the feature but when setting packAssets you can set an asset URL rewriting function. Look in docs for cdn\n. @gbraad Is the issue solved for you?\n. btw why would proxy rewrite be an issue, it's pretty standard\n. As mentioned above you can already do that with the CDN configuration for assets. It isn't clear to me what you are trying to achieve though as all HTTP traffic in production should be static assets or SockJS/Engineio traffic.\nIf there is no clear requirement or issue I will have to close this\n. Did you create the app with socket stream new uSee or did you follow the documentation?\nDoes you app.js look like: https://github.com/socketstream/ss-examples/blob/master/legacy-app/app.js ?\n0.5.1 is an unstable release so it may have issues will ship 0.5.2 in the coming week\n. @jerrygzy The newly released 0.5.2 should work for you\n. I will have a look at it. In the meantime 0.4.x is the stable version\n. Sorry I've been quite busy lately, will get back to it ASAP. Version 0.4 is supposed to be the stable version 0.5 is work-in-progress.\nOS X here as well\n. Thanks for the catch\nI will have a look at it. In the meantime 0.4.x is the stable version\n. It is certainly not dead, but I will have to spend a couple of weeks full time to complete what I set out to do with 0.5\nWe do have a version 0.4 which should be working. I guess there might be one or two things outstanding there, but I think it is as good as 0.3\nAdditionally I see HTTP2 as the future of real-time long term. It will work over proxies which websockets will not. That would require a lot of effort to figure out, but to stay relevant I think Socketstream needs to move the needle forward.\nI hope the project can be a community effort though as I have no plans to treat this as a job.\n. http://eric.themoritzfamily.com/websocket-demo-results-v2.html\nhttps://github.com/ericmoritz/wsdemo/blob/results-v1/results.md\nhttps://github.com/socketcluster/socketcluster/\n. https://github.com/rajaraodv/redispubsub\n. Something to compare with that has a very good explanation could be the base for one of the example apps\n. I'm adding a minor modification as part of #465 which allows referencing any code relative to the client folder. That takes care of bower if you include it in client. Not sure about npm if node_modules remain in the project root.\n. You can now do that with what is in the next branch. We just need an example/documentation.\n. @kulicuu If you want to work on this you should pick up #455 \nIt would be really neat, but I think it could easily be left for past 0.4, perhaps 0.4.2, assuming 0.4.1 are fixes based on feedback\n. This can be done as a plugin. I would suggest to treat this a Documentation Request\n. With 0.4 you should be able to make a modified bundler that does what you want. But I suppose we could still have a look at supporting more options for bundling templates.\nOn a project I work on we bundle Angular templates in a javascript and serve them with the code. Although it felt strange to me at first, I must admit that it has few drawbacks I can think of.\nSo I'd like to see more options around template bundling.\n. I think it is important to ensure that you can still explicitly have @import statements in the compiled CSS if that is what you really want to do.\nLESS and SASS formatters make the distinction, so it's important that this is a formatter responsibility not one in the bundler.\nThe simplest solution is to have a CSS Import Combining formatter.\n. The relative URL of assets now work the same in development and production in version 0.4\nIf you want to resolve @import statements in CSS you can make a custom bundler that does it for you.\nSo to me this is fixed.\n. I've done various implementations of this for EssentialJS\nIt turns out that 'console' is a magic keyword on IE8, so you can't even make a variable called console and have it work properly.\nGiven the line \nvar console = {};\nWhen running without the debugger console will evaluate to undefined!\nYou have to convert console calls to something else on the serverside, or provide a console API.\n. I would recommend using an upgraded approach where you can ask for a console API for instance\nss.logger(logic_name) or ss.logger(module)\nThat way you get more benefit and you only have to minimally adjust your habit of writing console....\nI think it deserves a standalone module, and I'd be happy to contribute. Once I have refactored EssentialJS to have a minimal core, I can contribute such a module based on just the core if that sounds like a good idea. Currently Essential is about the size of jQuery which is a bit bulky.\nThe current implementation can be found in https://github.com/essentialjs/EssentialJS/blob/master/js/essentialns.js\nLook for proxyConsole\n. TBH I suggest closing this issue as a wont fix. IE8 is rapidly dying even in Enterprise.\nIn a real setup you should have a build step to ensure that there are no console log statements in your production code, and other libraries take care of this sort of issue.\nThe golden fix would be a plugin that adds init code for legacy browser hacks\n. I don't think this is a Socketstream concern. There are libraries to take care of these, and many approaches. Stubbing, is unfortunately not an option.\n. We now have a branch with a solution\n- view specific constants can be defined in the defintion. They will be global objects in the browser.\n- global constants can be defined with ss.client.send('constant', 'name', 'value')\n- documented\n- constants are passed to formatters\n- locals map supported as well for tempting information\nTODO: \n- template_engine\n- more tests\n- disable live_reload during tests (runs out of handles)\n- document recommendations for writing formatters \n@paulbjensen can you have a quick look if this seems Ok\n. @mdedetrich How does this match what you were doing?\n. This issues is more complicated than the pull request. It is more like early/late loading. \nFor CSS you can choose to load all or just the essentials in the head depending on the size.\nFor JS you want most loaded in body, but shims and shivs are better in the head for consistency.\nThe better solution is to divide CSS and JS into semantic streams that can be placed in the right spot according to the configured policy/strategy.\n. Closing this to make a better issue #525 entry for 0.5\n. We should be able to provide an explicit way of packing resources without starting the server. Ideally I'd like to do it together with the Gulp shortcuts #473 \n. I suggest we do this for 0.4 rather than 0.3\nCould be done in tandem with Gulp integration/support\n. @paulbjensen It seems packing assets was a binary choice for all views rather than per client. Shouldn't that be a flag per client/bundler ?\n. This will be an experimental feature in 0.5 using Gulp underpinnings. You can do it with ss.start('pack-all').\n. now in master\n. I don't see any grunt hint. Do I just install jshint globally and run it on the project?\n. btw, be careful not to go overboard. As an example,\n(_ref = options.packedAssets) !== undefined\nvs \n(_ref = options.packedAssets) != null\nIs not the same test. Quite often null and undefined values are synonymous, so == null is the correct test. eqnull: true should allow such a test.\n. I just saw that as a linting refactoring, and I wanted to point out that the tests are not the same. I personally favour VAR != null, as it will accept anything other than null and undefined such as \"\" or 0.\nIn #465 I have relaxed the linting rules a bit as they seem very aggressive.\n. I'd suggest that we have two jshint files. One for lib and one for unit tests. This way we avoid linting fixtures and other auxiliary files. And we can adjust the rules to fit the purpose\n. That might be a good idea, you might want to drop in quite nasty stuff for fixtures\n. @RomanMinkin what should we do with this story?\nWhile I would love to have no linting issues a lot might be lost when merging with 0.4\nSecondly the linting issues remaining are quite concentrated in engingio.\n. Now we have a commit hook to disallow jshint issues\n. @drauschenbach I will be fixing this in the coming weeks for 0.5, any experience you would like to share on this?\nIs there a documentation page for PhoneGap behavior on cookies/local storage\n. Done\n. @mooglin Are you still having this issue? It seems to be a connection issue around engine.io that may be related to CORS / Cross-site access. Have you tried adding CORS handling middleware to the server?\nI suggest closing this if there is no progress.\n. @mooglin With the improvements in 0.4 you should be able to fix this.\nAssets are in the same location during development and production.\nYou can pass constants to the client by adding them to the client definition.\nObtaining session id through a cookie would be a problem with local files. This should be addressed in 0.4.1 as the general focus.\nFeel free to continue this request/discussion under 0.4.1\n. @luksch Where are you on this? I think this is the only issue with Socketstream that isn't being resolved.\n. That is fine. However I want to have a solid solution of this at a known and reasonable timescale. IMO the best solution is to write a set of tests for the scenarios that must work. Do we have a couple of months runway to get this figured out?\n. Ah is HAproxy exposing multiple servers on different ports on the same public ip and then passing the traffic on to the servers. This would mean that the client would see them as being on the same domain.\nWhat you want to achieve is that the clients are directed to a single server all the time, is that correct ?\nI've never tried using HAproxy, so I don't have an opinion on the best config.\nIt would be great if this is merely a need for clear documentation of production setup.\n. Any news on this?\n. So can this be closed or updated to reflect the current state ?\n. I have created a new story #524  for this, please do the planning there.\n. This is now fixed in 0.4, which we hope to release in a month or so. If you want to try it out check out the next branch. \n. -1\nI think it a bad idea, no matter how appealing it seems. Getting to play with a new thing with the least possibilities of something going wrong is important. Any stone in the road will limit adoption.\nA minimal install is also useful for test environments. Relying on other processes running makes CI setup more complex.\n. Btw, I think Redis is brilliant. Just think it should be a plugin. It could have support in the core. It could even be in the core, but it should remain optional.\n. Do I understand this correctly in that the cookie connect.sid is the current session ID, and you would like a way to set that to JSESSIONID ?\n. @klausb I've created https://github.com/socketstream/socketstream/pull/523 which should fix your issue.\nWhat do you think?\n. If it doesn't solve your issue please reopen, it will be part of 0.3.12\n. Looking forward to that. In my solution I lean more towards creating bundles server-side out of multiple bower files rather than ending up with a pile of individual requires.\n. The good thing about _serveDev is that we can just change the meaning of the URL, as it isn't deployed. Do you have any progress on this?\n. I will soon have something to show on #465 that should solve the problem.\n. http://localhost:9001/#/tutorials/client_side_development\nI've changed the _serveDev/code , css , worker to serve relative to /client rather than the asset specific directory. That would allow you to put bower components into /client/components and specify files directly. Client definitions starting with dot are treated as relative to /client, otherwise as normal.\nOf course you can always require / import from bower components indirectly from the client view source.\nWhat do you think?\n. @paulbjensen Could you have a look at the next branch and see how you like the option to use relative dependencies in client defs.\n. bower listing: https://www.npmjs.com/package/main-bower-files\nsourcePaths gets confused when root is below node_modules base.\nPerhaps there should be a magic directory called modules/ that is meant to mean location in bower or npm. \nMagic paths in project\n- client - the actual client path\n- server - the actual server path\n- modules - look up modules in npm or bower\n. I'm used to building quite large web apps so my solution might be overkill, but if you can sketch how you think it should be done I can help out with an implementation.\n. How about this?\nhttps://github.com/thepian/socketstream/commit/c0bea3c1c3a8bf43d84bd1176dfccfd0d0715165\nIt changes send so it will override any existing sources with same name. It also splits out shims which should be loaded before libs.\n. Pull submitted\n. sorry my mistake leaving in an extra \n. I plan to drop this with the new bundler structure. I doubt anybody uses it, and you can make your own bundler with this behavior if you need it.\n. in my fork I've started working on a bundler abstraction that can be set for a given client. The API wouldn't change, just allows passing a function to ss.client.define\nss.client.define('test', function(ss, router, options) {\n    return {\n       define: function(client,paths) {\n         // client.name and client.bundler is already set\n         // you can set properties on config\n       }\n    };\n},{\n// my paths passed to define\n});\nI'm moving the current bundler behaviour into socketstream/client/bundler/\nWhat do you think?\n. You can then write a bundler with Browserify 3, or even RequireJS if it pans out.\n. Paul would you agree with a slight refinement:\nIn Socketstream the deliverable is self-contained views. Optionally you can extract common assets across the views to reduce the payload size of your views.\n. or is the terminology a client; In Socketstream the deliverable is self-contained clients.\n. Lately I've taken an interest in web pack, it seems better documented than Browserify. But both seem to have active development.\n. Very interesting. I use Browserify at daytime. It find it good, but the documentation is lacking when it gets advanced. The project doesn't quite match what we need, but could be made to work.\nI got interested in web pack as it seems well documented and goes as far as providing hot plugging.\nI think the React guys are very skilled, and jspm seems related to that. I also think ES6 modules is a very very important feature in the near future. As I understand it jspm is a build tool, not a library with an API. To make a plugin or to build Socketstream upon I'm looking for a good alternative. Socket stream internals are possible, but seem very obscure. Web pack should work, but don't interface very well. Perhaps SystemJS might be the best solution, and looks like it is the sort of thing needed.\nI will park my current work with web pack and play with SystemJS.\n. I'm having a look at it, but so far it seems like an better implementation of require.js, which is conceptually very different from browserify and webpack. Hopefully there is more as I get further.\n. That is fine, but it seems like the only way to use it for Socketstream would be a wholesale replacement of how assets are served in development. To me that is at least a third of the codebase. Anyhow I think they way forward is the way I have done it in the current feature branch.\nThe current branch leaves everything working as it does, but allows replacing the bundling per client view.\n. The objective of this task is to make it easier to completely replace how JS/CSS/HTML is bundled on a per view basis, leaving the default bundler to behave as present. I proposed that as the original refactoring attempted two years ago met a lot of resistance for not being backwards compatible.\nI am not trying to pick a winner for a replacement bundler, but rather leaving it up to 3rd party to provide one. Ideally it should be possible to base one on Browserify, RequireJS, WebPack, JSPM or some future fancy.\n. I think I have something close to working. The API seems like a reasonable starting point.\n1) The default bundler is quite small ~150 lines calling common internal code.\n2) Alternate bundlers should be possible\n3) A bit of documentation has been added\n4) I will give a WebPack plugin a shot to see how it is to work with the API\nI would like someone to have a look at the idea of dev time URLs supporting alternate client source file structure. We should also add tests for this.\n. var webpackBundler = require('socketstream/lib/client/bundler/webpack')(web pack);\nThis is an alternate bundler for trying out modern bundling or as a base for your own implementation.\nss.client.define('today', webpackBundler, {\n  view: './views/today.jade',\n  css: './css/today.less',\n  code: './code/today',\n  tmpl: '*'\n});\nIt is my notion that the relative paths can also be used for the standard bundler\n. The default bundler should be pretty much done. I think the only thing remains is a sample browserify/webpack bundler, and perhaps some tests.\n. I think I have a good solution ready in a pull request. I will merge to 'next' if there are no RFCs in a day or two. The next branch will become 0.4\n. Thanks. Got a webpack bundler mostly working, and I think JSPM wouldn't be much of a problem either, or browserify for that matter.\n. Now part of next. Needs more love, but should work.\n. Wouldn't you define a middleware in your socket stream config that adds the headers for your JSON ?\n. 1) Abstracted asset bundling to allow configuring alternate bundling strategies per client. It is now possible to create a bundler based on RequireJS or Browserify 3.\n2) Allow piping production assets to disk through Gulp build streams, or plain Node JS streams.\n3) System assets can be configured specifically and/or provided by the bundler for a client.\n4) Global and per view variables can be configured and provided to CSS,HTML,JS formatters\n. I think that sounds good. I'm currently leaning towards keeping Socketstream a lean framework with basic batteries included but kept very small and easy to conceptually grasp. Most advanced features should be possible through extension points of the default configuration.\nAs a beginner I want 2-3 compelling starting points with reasonable default suited for small projects like prototypes.\nFor a real product I would expect to have to do several integrations some of which are doable but take a bit of effort.\nAs a project owner the last thing I want is for my working solution based on Socketstream to hit a wall and require core rewrite. As long as the internals of the deployed Socketstream can scale pretty much infinitely, I think that qualifies.\nIt seems that your suggestions should be based on detailed How To's that walk you through how to extend your project with plugins, custom code and configuration changes to achieve the objective.\nTo make it work I imagine that some internals will have to be tweaked, but it doesn't sound like fundamental changes or changes of the contracts of 0.3\n. @henrikvendelbo on trello\n. From my perspective I'm not interested in creating a new job for myself, have several as it is. I would prefer to evolve 0.3 with minimal breaking changes and just find places in the interface where we can slot in new features.\nAs an example I'm working on a pluggable bundler responsible for asset concatenation and packing. I hope to make a bundler based on Browserify 3 and support things like Angular template compilation. \nhttps://github.com/thepian/socketstream/tree/master/lib/client\nIt allows you to define a client with a function that manages all bundling instead of the usual paths object.\nss.client.define(\"members\", require('magic-bundler'), {\n  bases: [\"client/app\", \"lib\"],\n  bower: true\n});\nI plan to make some refactoring like this to be used as a new backend for our website.\n. Added a column for API changes, I think it would be good to manage them tightly and separately from implementing actual functionality\n. I like the idea of having rethinking prototypes, but ultimately figuring out how to turn them into evolutions not revolutions.\n. Sorry bad wording \"rethinking prototypes\" for experimenting with changes of Socketstream, coming up with forwardlooking functionality. And then once we know that the feature makes sense, figure out how it can be integrated without breaking compatibility.\n. Personally I'm the first one to come up with innovative technology ideas, but I've been burned by it so much that I really don't like it in \"other peoples libraries\" that I use :-)\nI went with Socketstream because it seems well written, small codebase, and pragmatic. I'd like to keep it that way. After all most things can be done from the outside as a consumer of Socketstream. We should just try to remove obstacles for people to \"get shit done\"\n. Web-RTC is very interesting. It is however a bit privacy challenged. I believe the IE and Safari team are staying away from it for that reason. Access to webcam and microphone is something a lot of people want to have tight control over.\nAs a transport mechanism it is interesting, but how would you do fallback behaviour on IE and Safari ? Communicate via the server?\nI would start with an experimental branch and make a PoC for an App. Then add hooks in Socketstream to allow a plugin to provide an alternate P2P transport. It does seem like a very different concept from Websockets and regular http. The only cross platform application of an abstracted WebRTC interface I can think of is P2P file transfer. Is that really something Socketstream should support ?\nOr are we talking about P2P video/audio streams? Then what is the fallback, Flash?\nAll in all. Very interesting, but not sure about relevance.\n. I'm interested as well, but I think it is something to support with a transport plugin api. I plan to use intercom.io for this to the extent that I need, but I can see the relevance for games.\nThe reality is that realtime web is a small set of use cases, and games are an important one. Made professional trading web apps for banks for a number of years and they are one of the few non gaming/gambling scenarios.\n. Sure just need it in my calendar so I can log in at the time. Will be on holiday, so will have to plan a bit.\n. sure. Is this a hangout? I don't know where to join\n. I don't think I can get it to work. The WiFi here is pretty spotty, so not really a surprise.\nMy main wish for a roadmap is to have a builder based on latest Browserify and/or WebStack.\nSecond wish would be creating a working demo based on Express 4.\n. I'm away Wednesday until Monday, but this time I'm in Europe, so hopefully I will have reliable WiFi whenever it takes place.\n. Because I have a file named that in the /client/static directory\n. I know where it happens. eventMiddleware in http/index.js\nThe comment basically documents the behaviour. It seems that switching to static cache fully is a good idea.\n. I'm making a feature branch to fix the issue and making a strategy setting for overriding a default HTTP resource strategy. Sound good?\n. https://github.com/socketstream/socketstream/tree/feature/470-static-paths\nStill need tests and docs. Any comments?\nAnd of course I need to fix the actual issue.\nThis should make it easy to make a connect 3 strategy or an express strategy\n. fixed\n. I see this as a way to feed views into gulp targets for generating production code. I suppose that there could also be a way to feed gulp tasks into views. I think gulp based formatters should be a thing.\n. by view I mean view definition. ss.client.define\nSo feeding the assets defined in a definition into a gulp task. Say for instance you want to use SS to bundle the view, and then gulp to pack and annotate it.\n. The task support is now in 0.4.4, I run via gulpfile.js in development. It works nicely \n. Do Gulp error handling https://github.com/gulpjs/gulp/issues/216\n. Hmm, looks like I broke something with the static strategy.\n. Sorry, didn't test it yet, was just apologizing as it seems to be my commits.\n. I'd like to fix it. I'm not sure how to run your project though. tried calling\n'coffee laTrappe_local' it cannot locate socket stream\n- fixed by 'npm link socket stream'\nNext problem is redis install. I have redis on my machine through home-brew.\n- fixed that with brew tap gapple/services\n- redis running now\nWhat is your test URL, the index page is blank.\nI tried /laTrappe_local_alpha, but that doesn't seem to be it\nAlso you have a trailing comma in the package.son\n. I'm not sure what to expect with La Trappe. I see issues with Angular template script tags having IDs with the file path, which surely they shouldn't have.\n. Could I ask you to make a detailed bug report. Ideally a test setup that fails. We really want to move towards TDD.\n. Won't fix as ES6 is the future. Pull requests welcome though\n. Perhaps this could be the task to add a couple of tests for live_reload\n. Btw, I just saw live_reload kicking in while running tests. We should also find a way to make it inert while running the tests that do not depend on it being active\n. I'm sure it's trivial, just a reminder to do it :)\n. Is there any reason to support node 0.6 ?\n. I fixed it in master as well while fixing up some require vars\n. Made some improvements\n. As it seems 0.3.12 is the new next release, I would suggest also making a 0.3.13 milestone. Some improvements might be pushed in the future while we are preparing 0.3.12\n. Thanks. How about the idea of having a separate branch used for the next major release? I'm not sure what name to suggest\n- future\n- major\n- next\n. of course!\n. You seem to be right. It must be a leftover. As api = ss, it is redundant as it is available from the init of client overall.\nOn you second point I disagree with you twice.\n1) It isn't a systems entire API, it is an internal API for all modules.\n2) Socketstream isn't a client and a server. It is a single server that bundles code for the client. Sharing functionality between the streaming side, the asset serving side and the bundling side makes perfect sense to me.\nOr are you saying that somehow the client code actually executed in the browser can RPC the api object on the serverside? That would be a very bad idea indeed.\nThat said, I'm only 90% convinced about the patterns for implementing Socketstream. I can't think of a better way to do it though.\n. Excellent. I seem to have Express 4 working, but haven't really gotten to a well rounded setup. Sounds great if we can base things on the latest connect.\nDoes this mean that we should make a connect based Router rather than our own Router implementation ?\n. This is a good discussion, but can we change the title to something actionable. Having tons of unresolved issues detracts from the project\n. Will go in with the bundler\n. I'd like to see this merged before it grows stale.\nHow does it fit with the release schedule, is it supposed to go in the next release. If so conflicts should be resolved, and it should be merged if it works.\nIt looks like this needs to be merged with the http strategy changes.\n. Would you be able to\n1) Clone the repo\n2) Make proposed changes / fix\n3) Make a pull request for your repo\nEven if we tweak your solution, it sounds like a completely reasonable feature request.\n. @paulbjensen Is this now fixed ?\nWhat about test coverage?\n. I think single page applications are just the latest fad. They've been my bread and butter for most of 7 years, but they are a vertical solution hosted within a multi-page reality.\nI think the two will merge as streaming becomes more widely adopted. \nI personally want Socketstream to fit well in a multi page app world. \nHowever I am a little apprehensive about the number of fads going on in Open Source. I want to make\nproductive systems, and I'm wary of basing my work on libraries that will be out of fashion in a couple a years. I also want to be able to find developers with experience. In that respect I expect 90% of Node developers to know Express and not much else, probably also Connect.\n. I don't mind the fads. However I am wary of spending energy on them before they hit critical mass\n. After getting stuck with a refactoring blunder, I'm really curious about routing alternatives for the dev-time middleware. Is Koa or Sails and easy option? or does it require a lot of thought/discussion. I'd prefer to keep all principal / fundamental changes optional to have good continuity.\n. _serveDev is partially for dev-time only. My thinking is that it should be a specific middleware only loaded in dev. It is at least conceptually.\n. Should we replace our Router impl with some existing npm module like 'routes-router' ?\n. @afrozl ss-examples has one for Express4, it is aimed at SocketStream 0.5 which is not stable yet.\n. @arxpoetica Have you looked at some of the changes? Any thoughts?\n. I agree. It is next to impossible to keep a robust implementation without that.\nIdeally it would be twinned with default project generation, the default project skeletons are used to test the framework, and they are tested at the same time.\n. I think you should have an examples directory with a separate package.son, otherwise I would suggest a separate repo called \"socketstream-demo\".\n. When do you see us have the first version of this ready, for 0.3.12 or 0.4 ?\n. The #465 branch is now ready for testing web worker serving.\n. Are anyone using web workers? Is there an app anywhere that I can look at?\n. Paul, are you Ok with this ?\n. The pull request is basically done. Just need to add tests to make sure I haven't broken too much. Feel free to check it out.\n. I've merged with latest master and I have a lot of tests blowing up. If @kulicuu, @lafras-h or @paulbjensen could lend a hand tracking down the issues that would be great. If not I will figure it out. \n. sorted\n. I try to follow \"git flow\" convention and make a feature branch matching an issue. Not sure what else to do.\nI see no problem with having many branches. They should be kept alive though, or they might end up diverging too much. However even then they can be used for reference or revived.\n. By alive I meant: up-to-date with the latest master or next branch (depending on whether they are for the upcoming minor or major release)\n. We should clarify this in docs\n. hmm, interesting, I tried running it against laTrappe, and it shows all red in Chrome fetching CSS/JS.\n. Fixed a typo\n. I think there are two thoughts when it comes to testing code structure. One is to keep it with the source, another is to keep it separate. I find that keeping it separate often comes from Mavens structure of /main and /test.\nFor unit tests I prefer to use the file extension to match the tests I.E. '*.spec.js'. If there are few test specs they can be saved along with the source they test. If there are many they can be put in a sub-package.\nTwo benefits of keeping source and unit tests in the same folder are that you can switch between them without IDE support, and that since they are visually close you are nudged towards writing more tests.\nFor integration, e2e etc the tests are often cross-cutting, so they don't fit very well with the source structure. For those I think they are best placed in a root /test directory.\nNow on to your question, which I've probably misunderstood:\nI don't see any problem with mixing JS and CoffeeScript files in the same source tree, so I would suggest that you put your new test scripts under /test/unit in the appropriate area. That is where the existing tests are (even if I would put them with the source)\nOr are you talking about unit testing of the new examples? In that case I would put it under /test/examples/unit or /examples/test/unit\n. I think we have to have a single test suite in SS. Allowing each contributor to make a whole new setup will become a mess. When you have two it is slightly confusing, when you have 5 it is a mess.\nI think there can still be some variation in how tests are written, but there has to be a minimum level of consistency.\nIf the SS source wasn't consistent and minimal I would have dropped it the first day I looked at it. I would expect many others would too. While it can be frustrating to write code in \"other peoples crappy way\", I don't see a way to avoid it.\nThe only exception would be if there is a large body of work that we are importing and we don't have the resources to refactor it. Then it has to be grafted on, at least initially.\n. I think this is really up to Paul to make a call on. I'm just stating my opinion.\n. I used to love them as well. I use them to make my own development simpler. However they do introduce dependency management in addition to the one with npm.\nAn alternative would be to have an example repository under socket stream say /socketstream/examples and npm publish that as \"socketstream-examples\". We could then put it as a devDependency for socketstream.\n. My solution is to offer a new API where formatters and template_engines are functions that return an instance. They could actually be called with new. That way you can supply a factory function or a constructor, and either will work.\nThe old API with init call will work unchanged for 0.3\nI will try to use a streaming approach like in Gulp so they can be used as part of a build chain as well.\n. @RomanMinkin Didn't you make an Angular template engine? Are you using suffix and prefix?\n. I tried vinyl-fs long time ago. I find streams a bit difficult to Grok, so perhaps it is something to have under the hood and not in the default interface. What I really like is the notion that one file might result in multiple files as output.\nMy current approach is to stick with the current callback api and support returning an Error instead of throwing it, as the throwing is incompatible with async.\nI thought of a promise like (resolve,reject) semantic, but I don't think it adds any power. I think the streaming could be introduced as an internal principle allowing easy extension/integration with gulp tasks. The templateEngine and formatters would run unmodified, but support an alternate API for direct stream implementations.\n@RomanMinkin So only selectFormatter but no suffix or prefix?\n. will be merged as part of #465 \n. Why the capitalised names? Is that required by live-reload?\n. Sounds nice. I would love to see an example of that.\n@paulbjensen I'd like to reiterate a request for a second GitHub repo 'socketstream/examples' for this sort of stuff, we could put it on npm as ss-examples.\n. I've made the repo to put this in,\nhttps://github.com/socketstream/ss-examples\n. It's an app that monitors the PR for drops in test coverage, isn't it. I've never used it so I just assume things. Perhaps Paul can give more details\n. Yes\n. Can we get an acceptance criteria for this, please? Not sure what need to be done other than documenting a bit under contributions\n. I see 0.4 as non-breaking, at least for 99% of users. There are new APIs, but old ones are supported.\nDoes this involve any code change? semver module for instance\n. +1\n. 73% coverage btw. Yes I know even at 100% it won't be enough, but it's rising.\n. Only thing outstanding is nodemon. I don't have time to document, but anybody is welcome to do it.\n. My ignorance knows no bounds. Looking forward to your findings.\n. connect.sid seems to be a cookie controlled by Express/Connect, so it is up to the application dev to configure how the cookie is set. Ideally it should be up to the application design whether this is kept http only.\nDoes engine.io need it in the browser for load balancing ?\n. False alarm, I'm sure all is working fine\n. @kulicuu If you have time I would love to figure out why the ss-example for connect and engine.io doesn't work ATM. Did I break sessions or something else?\n. Where are you accessing this DB? The ss.api is passed to plugins as the variable ss.\nFrom your application, I'd expect you to have a module that exports the database client so you can share it among app modules without involving socketstream.\n. Actually I think writing articles about how to use Socketstream on other destinations is much more important. We should actively try to extend the community. The docs are not great, but they mostly do the job. The ideal would be to recruit someone that has helped make stellar docs on another project.\n. I didn't break it, just wrote a bad test, however the question remains; Fundamentally.\nAre we happy with the current logic?\nYou can assign a template engine to a path. By default it is root. (is root the client dir?)\nYou can't assign it to an extension or a pattern. Perhaps it could be a combination of,\n- The engine suggests a file name pattern or extension\n- The app assigns it to a FS branch.\nSecond Question:\nWhat about prevEngine if you look in wrapTemplate it seems to assign it, but that (at least in my modifications) is a function parameter, so it means nothing.\n. Pushed the tests to the logging branch. We still need tests for subpaths and for custom template engines.\n. Do we know of any engines that rely on prefix/suffix of template markup?\n. I think I understand it now\n. Perhaps add a bit of testing so coverage doesn't suffer?\n. Sure nm, we probably merge from next to master anyway. It would be nice if it was merged to next as well though, so people can test out next without loosing hot fixes.\n. @paulbjensen Could we move tasks to 0.3.13 so 0.3.12 can be released soon ? We are getting close to 0.4 anyway so might as well cut down on 0.3 release scope.\nI cut down outstanding 0.3.12 work to be this plus session stuff. So hopefully we can do it soon.\n. user on npmjs.com is thepian\n. Could you try to branch of next rather than master, I've put quite a bit of additional documentation in there.\nI really do not feel like merging all those comments and converting them to JSDoc.\nI expect that 0.4 topics will be complete within the next month, so that would mean that there is a release candidate for it then in the existing NG Docs format.\n\nOn NG vs JS docs.\nNGDocs don't seem to fit that well with the Socketstream source structure, so the API docs generated are a bit odd, but mostly O.K.\nI'm not that sure that JSDocs is an improvement. When I last worked with it (granted quite a long time ago) they generated quite unattractive output with at structure that wasn't terribly powerful. I recall them as a straight imitation of JavaDoc, which was cool when it came out, but hasn't really evolved in terms of usability.\nFor the examples/tutorials I can imagine we could do better. I assume you are not aiming to use JSDoc for this?\n. I just used bourbon.io ; it's quite nice, I wonder what they made it with\n. Great\n. I think the fundamental strategy should be\n1) Keep a steady stream of improvements to Socketstream (at a manageable pace)\n2) Satisfy one existing fronted dev community at a time\nIMO streaming is a niche feature, so pitching to the converted is not the best use of time. Better to show the usefulness to people that are not used to it.\nI'd like for instance to show really good support for Angular to that community, and then move on to another community.\n. http://samwize.com/2014/01/31/the-best-documentation-generator-for-node/\nhttp://underscorejs.org/docs/underscore.html\n. How about the separate var declarations, does linting(hate autocomplete) complain that they should be one statement?\n. I like the look of it, but lets hear some actual benefits. If we take it will it become a requirement, or optional?\n. I failed to move things into the in progress column, not sure if it's bug or restriction. The interface looks really nice though.\n. Since there seem to be no objections lets try it\n. Reimplemented it for 0.4\nhttps://github.com/socketstream/socketstream/commit/669f000ae9bc22df87b1fb8f064f2c4877d8722a\n. A) Glad for the thumbs up\nB) You can help by trying out 0.4 and reporting any issues you have as soon as possible, it is on the next branch and will be released in beta soon\n. It is now released as 0.4.0-beta\n. Not sure, but we need to be forced to make tests and stick to our linting rules. Personally I don't care about 90% of lint rules as they don't help me read or write the code, but some are a good thing. If there are too many messages we should reduce to a set of rules we can apply and stick to. For code coverage, we have to get to 100%. Refactoring without knowing what is expected and not is impossible. I am making a lot of decisions when refactoring which may or may not be the right ones.\nI would prefer to not use houndci, but I think we will not stay on top of our code rules without it.\n. If we don't use something like hound, I think a commit trigger or watcher is needed\n. Guess nobody cares\n. me too :) I want to follow up to feedback to 0.4 that I saw on the forum first though. I want to be sure there were no bugs introduced in the rewrite.\nI'm hoping @kulicuu will want to work on this, or someone else as I use SockJS myself\n. @kulicuu very interesting as well\n. +1\n. I will have a look at that. Do you know that it is supposed to work with the latest connect?\n. That was my assumption, but the deprecation is express not connect. In connect it seems that just a part is deprecated.\n. @kulicuu Did you read anything about this when upgrading Connect ?\n. @luksch Can you check if connect.bodyParser() is still there? If not this is really a connect issue, then it is missing documentation. I think prepend still works, but I think tests are missing for that.\n. Shouldn't test resources be in the fixtures folder ?\n. Running the tests will remove the README file as part of the pack file management, not so good. I have added a git checkout for the project fixture assets, but that seems like the wrong solution. An improvement on that would be appreciated. Perhaps we just shouldn't have anything checked into the abc directory and have a gitignore for it and the ensure the directory is there before those tests.\n. I'd like to suggest that we stick to merging new features into next (or the traditionally named develop) and leave master for minor fixes to the current release. That way,\n-  'master' releases is currently the 0.4 line.\n-  'legacy' releases is currently the 0.3 line.\n- 'next'(develop) releases is currently the 0.5 line\nThat way we can easily manage fixes, and when we release 0.5 that be comes the new master and 0.6 the next/develop\n. Indeed. Looking at some other possible fixes to squeeze in.\n. Yes I agree, but it still takes me an hour to release making sure nothing is broken. So I don't want to do it every day\n. On a tangentially related note I've noticed that engine-io client is loaded as a library. Shouldn't it be loaded as a CommonJS module ? Perhaps @kulicuu can comment.\n. I don't think it has to be a SocketStream plugin as such(although that is also an option). I merely think that the client code shouldn't be a mandatory library loaded regardless, but rather a system module that will be loaded if needed given the configuration.\n. If you don't find it I will try to write unit tests for 'ss.client.send' to track it down. Shouldn't be hard.\n. Ah, I mistook the API for being like formatter\n. Nothing should be changed from before, it was my mistake copying things around. I never wrote a template engine before, so I didn't know any better. It's fixed now, will do a release.\nIn 0.4 we also support a simpler API for formatters and template_engine. Instead of making an object with an init function, the formatter or engine is that same function. In both cases the first parameter is the Socketstream API.\n. Try npm install now, fixed by commit https://github.com/socketstream/socketstream/commit/19510e350cb7a8e0cf70b749ee8c0b3c5def2d7f\n. I think it is the problem we talked about before. The directory gets deleted when running pack for production I think. Tests should properly insulate this behaviour or we should tweak the logic for cleaning up previous production server starts.\n. Did you realise that you are making this against master (0.4.x) ?\n. I agree. The tests need a done callback. And we need to pass that to pack.\nHowever; I plan to move out the pack logic from load so it can be called as part of a build step. While the current model of \"just run your server whether dev or prod\" is a good default, but there will always be people that need/want more complex production setups.\nI did also think that perhaps we would want to refactor the server load/start as an async waterfall. That way it is easily testable and extensible.\n. @arxpoetica I think it should have an issue, but I think it belongs on our trello board. I am conscious about the impression we give about a long list of open issues.\n. next will need to catch up with master, that is part of the tradeoff. Of course the benefit is that we can take it easy with the 0.5 release and fix 0.4 which I think is quite important.\non your particular case, I don't recognise the problem, so I don't know if it is.\n. Is it hardcoded? It should certainly be read from package.json\n. @ilyador 0.4 should work like 0.3 with only one or two edge cases difference\n. Will be fixed in 0.4.3 with other asset related issues\n. no, I tried to make everything work as before. Are they still the same type?\n. To my knowledge there is 100% test coverage on template output, so I must be missing something.\nCould you have a look at the tests to see if they are as expected?\n. But are they rendered with the hogan template engine or with the default one?\nIt would be so nice if we have coverage to test this stuff\n. Ah. I know what it is ...\nI changed the base path of everything to be client rather than the type specific directory so we can have more bundling freedom. The default ID is encoding the path not the file name, as it should.\nI will make a special case for the templates directory.\n. Your issue is now fixed in the pack-assets-fix branch, misleading name, but it's the remaining work for 0.4.3\n. As a sidenote, if you had checked the unit tests it would be clear that the assertions are wrong as they include templates-.\n. A better fix is now on master\n. My thoughts are 'crap' :(\nI wasn't able to write a unit test for the recognising of existing bundled files, it should be a trivial change but clearly an annoying bug.\nentry.js and index.js should both work as there are unit tests for them. Something must be missing.\nRegarding 2 is the problem with the bundled version ?\n. @kulicuu Isn't that something mocha has documented?\n. @hulmgulm If you have any chance can you test #553 it should solve your issue point two. I think the only left is reusing existing asset files.\n. Got ya\n. Regarding point 1, I'm still trying to write a test that covers this fully.\n. Point 1 will be fixed in 0.4.4, others are on master and will be in 0.4.3\n. @kulicuu Hmm, does this mean that you need to configure the session secret twice in the app ?\nAnd shouldn't the API be like for the client\nss.session.set({ .. });\n. To me that is squarely in the examples / how-to bundle with bower/jspm/browserify category. I will add a documentation flag, sound good ?\n. Is it because they sometimes fail during coverage tests?\n. I'm attempting to extract a fixtures module with fixtures and utilities to reset and cleanup the project fixture before/after each test. Hopefully it will make test runs more stable.\n. Could it have to do with live-reload kicking in and executing more code?\n. I think it was. When I run it with the pack-improvements branch the coverage numbers remain the same\n. fixed in master\n. Wouldn't we want to move away from implementing a general purpose app server?\nI would expect that it is trivial to prepend a middleware which will serve special mime types. In production you should have the static server handle this anyway I would think.\nI'm not against the improvement, just think it is a distraction beyond documenting how to write your own static serving middleware for DEV time. There must be 100+ blog posts that explain how to do this with Connect/Express.\n. We now have an Express 4 example.\n. @paulbjensen I wonder what that 500 error is about, are we behind on coveralls package ?\n. I assume you put angular in libs. Did you make a libs_test as a copy of libs? why?\nThe documentation on libs explains that it's a special case where the file is loaded raw, not as a module. Angular isn't there as you didn't do a require for it, and it will not be a global variable if you do.\n. @EricCat Can you confirm this so I can close the issue?\n. No feedback on this. Working as documented it seems.\n. @havoc74 Since you are a user of ss-console I'd like your opinion on how to best evolve the console for SocketStream 0.5\nDo you have special wishes or any low hanging fruits that could be added/changed ?\n. We have unit tests covering this. My guess is that the new app skeleton needs to be updated somehow.\n. @hulmgulm can you run the test suite on Windows ?\nI'm very disinclined to set up a dev environment on windows, so I would have to rely on others telling me what fails. We have mostly removed any assumptions about path separators, but it could be that we have some issue with assuming a Unix OS somewhere.\n. fixed on master, new project now works on Windows\n. @paulbjensen  does the glob package work on Windows ? It is usually preferable to rolling your own\n. Perhaps we should try using multimatch module.\n. There is now a feature branch using the glob module, if anyone can test on Windows for possible fix that would be great.\n. I think Promises are a bad API, async is much more sane.\nHowever Promises are part of ES6, so we should treat them as a first class citizen. For that reason, I think it is a good suggestion. Promises are introduced natively in node 0.12\n. bookmark / stuff to consider\nhttps://www.discovermeteor.com/patterns/5828399\n. Perhaps the best is to start discussions about how to be the most productive with the async-ness of client-server development.\n. Contrast and review compared to Meteor and see where we can make Socketstream a better production/long-term choice and leave others to offer prototyping framework value.\nhttps://www.quora.com/What-are-some-downsides-of-MeteorJS\n. I think we want to move away from being a middleware framework as fast as possible. connect is 1000x more popular, it is the de-facto approach and it isn't anything we can do better.\nBy 0.5 I'd like to have cut out standard middlewares as dependencies.\n. I'm proposing to reduce what SocketStream does to focus on the streaming. The prepend and append only affect middleware configuration which is something 99% of users will do with a mainstream framework. That whole router code is quite smelly and it seems we have a couple of issues in view matching as a results.\nThe benefit of mainstream frameworks is the vastly bigger volume of people knowing how to solve problem X. For general purpose REST endpoint hosting there are tons of use cases, most of which are not really related to streaming.\nIn most projects the main hurdle is getting to the first release. Reading Pauls resonse I hear, \"SocketStream is a specialised framework squarely focused on top performance in all areas. It might limit your ability to do an MVP fast in order to push you towards performance\".\nI'm curious what the cost is of using Express middleware over SocketStream's approach for the regular endpoints.\n. Perhaps I should just provide an example and support for a way to run a SocketStream App without ss.http.middleware\n. That was my thought. It seems the argument is performance of serving views which puzzles me a bit. I would expect the difference between the alternatives to be on the order of 1ms\n. I'm looking at the various parts of ss.http\nI see require connect in there, but somehow it's not used for making the server. As a user of SS, I find that confusing.\n. I think I have found a better approach than my original suggestion, so I will close the issue\n. This is pretty close to what I plan to release\n@paulbjensen Would love thoughts\n. So SockJS is a second rate citizen?\nI really wish for fewer requires. Internalizing the wiring is fine but I really don't like all the dependencies. They should be passed in the app config.\n. I don't think it should be done like this. I take it ss-engine.io have tweaks that need to be pulled in?\nIn SS 0.5.0 I've essentially retired \nss-engineio \nss-sockjs \nss-jade\nss-sass\nss-less\nI'm really making all the most used plugins redundant while maintaining the support for custom plugins.\nIt's on the next branch and released as a beta.\nss-examples has a working ExpressJS example\nIt will however it will still be possible to use ss-engine.io as an external dependency\n. Retired meaning that they are built-in to 0.5, so you can add('jade') just like you would add('html'). You can make your own Jade formatter if you like, but I don't see any need to maintain ss-jade, so they are just there for people using <0.5\nengineio is built-in today, and I've added sockjs and plan to add ws. Likewise you can make your own transport and use it.\n. Yes, I've noticed. Had trouble on one machine. I would like to fix it, but also wonder about the userbase for iojs\n. iojs passing for latests master, can you check if the issue is resolved?\n. @paulbjensen any news?\n. For me it passes, but when run in a commit hook in Tower it fails due to colors being output. Some test needs a logHook to catch the build dump\n. ah you mean if you run it as a download, not a git repo?\n. removed the git checkout\n. Yes that is already supported in 0.4\nYou can use relative paths in code\nss.client.define('main', {\n    view: 'app.html',\n    css:  ['libs/reset.css', 'app.css'],\n    code: ['libs/jquery.min.js', '../node_modules/somthing/code', 'app'],\n    tmpl: '*'\n  });\nRelative paths are based on the client directory. I wish we had it documented.\n. I have only tried it with using alternate directories within the client directory, but in principle it should work.\nIt is still an open issue to support npm/bower modules installed anywhere in your project.\nclient/bundler/default.test.js:120 tests relative paths within the client dir.\nss.bundler.sourcePaths(paths) determines where source roots are located. If something doesn't work this is the function that needs fixing.\nYour issue seems to be in client/bundler/index.js:278\n. not sure what the question is. Are you referring to the URL scheme during development?\n1) It mimics the location in production to keep them similar and make CSS work the same\n2) It contains the client name, ID and type to use the correct bundler\n3) It contains the path relative to the client directory to support files outside the usual locations\n4) It contains a query to bust the cache during development\n5) The parsing of the query part should be done by the bundler, but hasn't been implemented yet\n. 3) It does work for file within the client directory, so you can load a JS file from outside client/code, but I don't expect it to work with ../elsewhere paths; Although it should. (still an open issue)\nThe idea was to support any asset path to be passed in the URL using the _ parameter. It would be a path relative to the client directory. The file in question would also have that as the logical path in browser source mapping (perhaps relative to project root would be even better, but that is quite a rewrite).\nThe idea was to leave the interpretation of the path to the bundler, but it is still being done in dev.js as it was before.\nThe bundler determines the list of client assets and links them in the HTML view. They are loaded by the browser and the bundler should resolve the paths as well.\nThe issue seems to be with socketstream/lib/client/serve/dev.js:55-57\nIt only interprets ./ not ../\nWhat it should do is ask the bundler to resolve the module\n. I've starting fixing this. The first part of pulling in stuff outside the client directory is an easy fix already on the feature branch. Second part is making require work for anything in the project directory. This means that the path in the bundle should be /client/code/abc.js not /code/abc.js\n. nope, everything working as before. It is all internal to wrapCode and what path modules are registered under which is unspecified. Otherwise it would be for 0.5\n. Lot's of little internal changes though. Started with 40 unit tests to fix, down to 6\n. The feature branch should now allow any client assets to be referenced inside the project using relative paths with the client folder as the starting point\n. We should change the new app template to fetch jquery from node_modules and have jquery be an npm dependency.\n. Perhaps I should change the templateEngine.use path param to be relative to the client. Right now it's relative to the project.\n. in master\n. I run SocketStream 0.5 on the latest NodeJS, all seems fine. I would actually consider making SocketStream 1.0 require NodeJS 4\n. ss.set('server.port',3000);\nss.set('server.port.production',9999);\nss.set('server.port.development',3000);\n. Doc:\nDEBUG=express-session,socketstream,require npm start\n. Hi there, are you talking about 0.5.0 or 0.4.4 ? 0.5.0 is an unstable release for testing only. Thanks for reporting.\nIndeed much is changing. calling start without an http server is now supported to facilitate gulp integration and running pack-all as a task. https://github.com/socketstream/ss-examples/blob/master/express-4-and-js/app.js\nIt means that transporter tests will have to be supported in a different way. There is already a task for that. If you can point me to an example test that doesn't pass anywhere, I'll be happy to fix the issue.\nUpdate: looked into your problem. The function to call would be ss.start('test-socketstream',done). If it works as intended it will go in 0.4.5\n. @cuckoopt Could you try out your tests with this: https://github.com/socketstream/socketstream/pull/590 ?\n. Sorry, I'm unable to keep up with all software details. Node 4 completely missed my radar. We can add Node 4 to the platforms tested. Does that bring Promises and other ES 2015 goodies?\nWith 0.5.0 we are moving away from bundling big dependencies in SocketStream. This means your project is checked for stuff like Jade and Engine.io and you can use the version you are happy with as-long-as it remains API compatible.\nI want to shrink SocketStream to a small bundle of glue that you can stick big pieces on and it will make things work together.\n. That is a cool comment. It does seem like a good linting target for projects. I can't think of any of our code that is done extensively though.\n. Amen. I need that as well. There are quite a number of things to do to make it feasible though.\nIt really is what I am working towards. In 0.5 the cookie session management is factored out into. It is however currently unstable so it doesn't work in production. You can however use it as a point for getting things to work. When #508 is done the next step will be to implement a socketstream-jwt-session module.\nhttps://github.com/socketstream/socketstream-cookie-session\n. @StuartHickey Have a look at socketstream-cookie-session repository, I'm making the session creation pluggable. It might already have enough for you to make token based auth\n.   The client will be built to be loaded with SystemJS EventEmitter2 will take place of EventEmitter\nengineio is based on EventEmitter, SockJS expects the client to be browserified\n. Also consider engine IO config\nhttps://www.npmjs.com/package/engine.io-options-from-url\n. @paulbjensen Perhaps you have an idea what causes this. SockJS doesn't fail\n. It was a bind issue, fixed.\n. just demoing\n. The HTTP side is intended to be essentially static in production. You generate bundles for HTML,CSS and JS. On demand JS is currently only supported on the server, but will be static as well in 0.6 or 0.8\nSo in production the only thing to proxy is the websocket connection and fallback support from SockJS/Engine.io\nWhat I'm essentially saying is that there is nothing in SocketStream itself that needs to be handled in production. You just need to serve the static and assets directories from your HAProxy/Nginx frontend and proxy to the SocketStream server for the connection.\nThere is no particular support for configuring the path for where the fallback XHRs go. You'd have to refer to the transport documentation for that.\n. Hmm, did you just mean the /assets/ URL? I haven't used the feature but when setting packAssets you can set an asset URL rewriting function. Look in docs for cdn\n. @gbraad Is the issue solved for you?\n. btw why would proxy rewrite be an issue, it's pretty standard\n. As mentioned above you can already do that with the CDN configuration for assets. It isn't clear to me what you are trying to achieve though as all HTTP traffic in production should be static assets or SockJS/Engineio traffic.\nIf there is no clear requirement or issue I will have to close this\n. Did you create the app with socket stream new uSee or did you follow the documentation?\nDoes you app.js look like: https://github.com/socketstream/ss-examples/blob/master/legacy-app/app.js ?\n0.5.1 is an unstable release so it may have issues will ship 0.5.2 in the coming week\n. @jerrygzy The newly released 0.5.2 should work for you\n. I will have a look at it. In the meantime 0.4.x is the stable version\n. Sorry I've been quite busy lately, will get back to it ASAP. Version 0.4 is supposed to be the stable version 0.5 is work-in-progress.\nOS X here as well\n. Thanks for the catch\nI will have a look at it. In the meantime 0.4.x is the stable version\n. It is certainly not dead, but I will have to spend a couple of weeks full time to complete what I set out to do with 0.5\nWe do have a version 0.4 which should be working. I guess there might be one or two things outstanding there, but I think it is as good as 0.3\nAdditionally I see HTTP2 as the future of real-time long term. It will work over proxies which websockets will not. That would require a lot of effort to figure out, but to stay relevant I think Socketstream needs to move the needle forward.\nI hope the project can be a community effort though as I have no plans to treat this as a job.\n. ",
    "yusugomori": "Thank you for quick response.\nAnd yes, I'd like to pass custom local vars.\nSo there is no config option yet, right?\n. That is great!\nThank you!\n. Thank you for quick response.\nAnd yes, I'd like to pass custom local vars.\nSo there is no config option yet, right?\n. That is great!\nThank you!\n. ",
    "jbremmer": "I'm experiencing this issue on latest from master.\nFrom client calling login function\n\u21aa rpc:4 app.login\nDebug incoming message >>\n { id: 4,\n  method: 'app.login',\n  params: [ 'usr@srv.com', 'a' ],\n  socketId: '6772954291976945481',\n  clientIp: '127.0.0.1',\n  sessionId: 'zqEXyjLIiHxieElNqs5E3dIp',\n  transport: 'socketio',\n  receivedAt: 1338459324974,\n  use: [Function] }\nwhere I do:\n...\nreq.session.setUserId(doc.email);\nreq.session.user = doc;\nreq.session.save(function(err) {\nconsole.log(\"Session saved:\",req);\n...\nwhich yields: \nSession saved: { id: 4,\n  method: 'app.login',\n  params: [ 'usr@srv.com', 'a' ],\n  socketId: '6772954291976945481',\n  clientIp: '127.0.0.1',\n  sessionId: 'zqEXyjLIiHxieElNqs5E3dIp',\n  transport: 'socketio',\n  receivedAt: 1338459324974,\n  use: [Function],\n  session: \n   { lastAccess: 1338458465412,\n     cookie: \n      { path: '/',\n        _expires: Thu, 31 May 2012 14:15:24 GMT,\n        originalMaxAge: undefined,\n        httpOnly: true },\n     channel: \n      { list: [Function],\n        subscribe: [Function],\n        unsubscribe: [Function],\n        reset: [Function],\n        _bindToSocket: [Function] },\n     setUserId: [Function],\n     _bindToSocket: [Function],\n     save: [Function],\n     userId: 'usr@srv.com',\n     user: \n      { email: 'usr@srv.com',\n        phone: '+44',\n        joined: Thu, 31 May 2012 10:04:40 GMT,\n        verified: true,\n        type: 'ind',\n        _id: 4fc742383643b9b67c000002 } } }\n\u21a9 rpc:4 app.login (10ms)\nWhen I invoke next function, this data is not there:\n\u21aa rpc:1 app.gusr\nDebug incoming message >>\n { id: 1,\n  method: 'app.gusr',\n  params: [],\n  socketId: '5926658152055406305',\n  clientIp: '127.0.0.1',\n  sessionId: 'zqEXyjLIiHxieElNqs5E3dIp',\n  transport: 'socketio',\n  receivedAt: 1338459592482,\n  use: [Function] }\n{ id: 1,\n  method: 'app.gusr',\n  params: [],\n  socketId: '5926658152055406305',\n  clientIp: '127.0.0.1',\n  sessionId: 'zqEXyjLIiHxieElNqs5E3dIp',\n  transport: 'socketio',\n  receivedAt: 1338459592482,\n  use: [Function],\n  session: \n   { lastAccess: 1338458465412,\n     cookie: \n      { path: '/',\n        _expires: Thu, 31 May 2012 14:19:52 GMT,\n        originalMaxAge: undefined,\n        httpOnly: true },\n     channel: \n      { list: [Function],\n        subscribe: [Function],\n        unsubscribe: [Function],\n        reset: [Function],\n        _bindToSocket: [Function] },\n     setUserId: [Function],\n     _bindToSocket: [Function],\n     save: [Function] } }\n\u21a9 rpc:1 app.gusr (2ms)\n. Hi Owen\nYou see, sometimes it's not very practical to have fixed folder structure. Some 3rd party frameworks would have this folder structure fixed and built tool chains around them. For me this mean to work with the two I need tow write separate toolchain to mary them which obviously I don't want to do.\nJacob\n. Owen,\nAbsolutely agree with above statements, I wasn't questioning your direction, just pointing that introducing some flexibility would attract more use cases and scare less of them. \nAfter all I've overcome current limitations and get my 3rd party framework coexisting with SocketStream.\nFollowing line came particularly useful:\napp.use('/resource', express.static('../../someother/resource'));\nbut resulted in some ugly path fixing.\n. Owen,\nThat would help...\n. Owen,\ntried to simplify as much as possible.\nHere goes server side:\nexports.actions = function(req, res, ss) {\n   return {\n       modifyUser : function(uid) {\n            // Some function that updates user based on conditions, ran twice never produce same results\n            User.update( ... , function(e, numberUpdated) {\n                res({\n                    r : numberUpdated\n                });\n            });\n        }\n    }\n}\nand client code:\nss.rpc('app.modifyUser', user.uid, function(d) {\n    console.log(d);\n});\nSo invokig the client code twice with same uid will yield same results even though server returns different numberUpdated each time. When uid is different it will behave properly and return correct results.\n. Well seeing what's on the wire helped as I was able to spot I'm doing assignment not comparison at the very last line before passing result, can't believe how silly...\nSorry to waste your time. \n. My bad, included one of the functions somewhere else and passed null for request.\n. I actually did that, but it didn't helped...\nI also believe that following hard code in websocket/transports/socketio/index.coffee\n```\nprocessSession = (socket) ->\n  return true if socket.sessionId\n# Parse session ID from initial hankshake data\n  try\n    rawCookie = socket.handshake.headers.cookie\n    cookie = qs.parse(rawCookie)\n    sessionId = cookie['connect.sid'].split('.')[0]\n    socket.sessionId = sessionId\n  catch e\n    console.log('Warning: connect.sid session cookie not detected. User may have cookies disabled or session cookie has expired')\n    false\n```\nis also causing problems but even after patching it problem remains.\n. Having done as I was told...\nWas using mongostore instead of redis, switching to redis is helpful as it shows an issue in monitor mode:\n1339152856.068663 \"info\"\n1339152857.806205 \"get\" \"sess:dELB4PDK2VdqnbEGJksVrOKX\"\n1339152913.244874 \"get\" \"sess:dELB4PDK2VdqnbEGJksVrOKX\"\n1339152913.251029 \"setex\" \"sess:undefined\" \"14399\" \"{\\\"lastAccess\\\":1339151896801,\\\"cookie\\\":{\\\"expires\\\":\\\"2012-06-08T14:55:13.245Z\\\",\\\"httpOnly\\\":true,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"userId\\\":\\\"usr@srv.com\\\"}\"\n1339152913.251104 \"setex\" \"sess:undefined\" \"14399\" \"{\\\"lastAccess\\\":1339151896801,\\\"cookie\\\":{\\\"expires\\\":\\\"2012-06-08T14:55:13.245Z\\\",\\\"httpOnly\\\":true,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"userId\\\":\\\"usr@srv.com\\\",\\\"user\\\":{\\\"email\\\":\\\"usr@srv.com\\\",\\\"phone\\\":\\\"+44\\\",\\\"passwd\\\":\\\"86f7e437faa5a7fce15d1ddcb9eaeaea377667b8\\\",\\\"joined\\\":\\\"2012-05-31T10:04:40.099Z\\\",\\\"verified\\\":true,\\\"type\\\":\\\"ind\\\",\\\"_id\\\":\\\"4fc742383643b9b67c000002\\\"}}\"\n1339152967.840794 \"get\" \"sess:BeqPCdGF31T9JrHaYpka4UBm\"\n1339152967.842050 \"setex\" \"sess:BeqPCdGF31T9JrHaYpka4UBm\" \"14400\" \"{\\\"lastAccess\\\":1339152967841,\\\"cookie\\\":{\\\"maxAge\\\":14400000}}\"\n...not sure why though setting user id and saving session operations are having undefined sessionid.\nThis output is corresponding to previous report in terms of flow of actions.\n. Now, turns out I was on RC1 instead of RC2 where problem does not exists. In RC1 while saving there was call to session.sessionId instead of session.id which was causing the problem above.\n. Well, I was thinking more about server-side cookie access in ss rpc methods.\n. The difficulty I'm having is to access the same inside ss rpc responders. So what I would like to do is to for example set cookie on response from within rpc responder function. So far I haven't been able to do that without modifying ss code.\nss.http.middleware.append() and prepend() methods came first to mind but request nor response objects are not directly accesible within rpc responder, same for ss.\n. Yet, cookie fo the session is set. Are you saying that if communication happens through flash sockets session support will not work ?\n. Hence I thought it would be nice to have access to this in rpc methods.\n. Well it could come at a cost of having this with socket.io or whichever transport supporting the same - not ideal but an option.\nThing is, it's really nice to have access to cookies, one could exchange them for browser local store but it's not exactly the same.\n. Thank you all for exhausting explanations. My motivation was to store session data client side in the usual manner (as supported by connect 2.x) plus some other needs, after all I can live with local storage in the browser or cookies as suggested.\n. I'm dealing with two type of clients on mobile devices - browser based (Safari/Chrome) and those are working just fine with current SocketStream. Others are native (iPhone/Android) where I have little chance to patch handshake to set cookie there. \nInstead I've patched socket.io transport in SS so it would always return true from processSession and it works so far, just don't know yet what implications would that have for browser clients.\nFirst implication is of cource Pub/Sub Events not working as there's no session.\n. This is of course assuming ones using SS alone, in my case I'm using it with Express which results in cookie being in fore mentioned format (I've deleted cookie to check if different one is being set, but same format still apply)\n. Well, there is no shortage of these, ex. i18next jsperanto, jed, messageformat. I'm more asking about suggestions on how to use them within socketstream and what's possible future directions on that.\nOn top of regular i18n considerations like prulars, loading, translation standard, there are ones that come with socketstream itself - when to load, where to inject, what about packed assets and so on. Was wondering if anybody did any thinking on that.\n. I came across this while having to generate app cache manifest. As a\nworkaround I get clientid replicating ss wqy of doing it.\nI think the best would be to ask for clientid. So when definig client I get\nclient object back. That could contain appropriate id the could be used\nlater.\nOn Jan 24, 2013 9:27 PM, \"Owen Barnes\" notifications@github.com wrote:\n\nHi there\nA valid issue for sure. I understand you want a list of the client IDs,\nbut what would you expect that API to look like?\nMaybe something like ss.client.all() would return an array of clients\n(each an object containing an ID)?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/328#issuecomment-12671491.\n. I'm experiencing this issue on latest from master.\n\nFrom client calling login function\n\u21aa rpc:4 app.login\nDebug incoming message >>\n { id: 4,\n  method: 'app.login',\n  params: [ 'usr@srv.com', 'a' ],\n  socketId: '6772954291976945481',\n  clientIp: '127.0.0.1',\n  sessionId: 'zqEXyjLIiHxieElNqs5E3dIp',\n  transport: 'socketio',\n  receivedAt: 1338459324974,\n  use: [Function] }\nwhere I do:\n...\nreq.session.setUserId(doc.email);\nreq.session.user = doc;\nreq.session.save(function(err) {\nconsole.log(\"Session saved:\",req);\n...\nwhich yields: \nSession saved: { id: 4,\n  method: 'app.login',\n  params: [ 'usr@srv.com', 'a' ],\n  socketId: '6772954291976945481',\n  clientIp: '127.0.0.1',\n  sessionId: 'zqEXyjLIiHxieElNqs5E3dIp',\n  transport: 'socketio',\n  receivedAt: 1338459324974,\n  use: [Function],\n  session: \n   { lastAccess: 1338458465412,\n     cookie: \n      { path: '/',\n        _expires: Thu, 31 May 2012 14:15:24 GMT,\n        originalMaxAge: undefined,\n        httpOnly: true },\n     channel: \n      { list: [Function],\n        subscribe: [Function],\n        unsubscribe: [Function],\n        reset: [Function],\n        _bindToSocket: [Function] },\n     setUserId: [Function],\n     _bindToSocket: [Function],\n     save: [Function],\n     userId: 'usr@srv.com',\n     user: \n      { email: 'usr@srv.com',\n        phone: '+44',\n        joined: Thu, 31 May 2012 10:04:40 GMT,\n        verified: true,\n        type: 'ind',\n        _id: 4fc742383643b9b67c000002 } } }\n\u21a9 rpc:4 app.login (10ms)\nWhen I invoke next function, this data is not there:\n\u21aa rpc:1 app.gusr\nDebug incoming message >>\n { id: 1,\n  method: 'app.gusr',\n  params: [],\n  socketId: '5926658152055406305',\n  clientIp: '127.0.0.1',\n  sessionId: 'zqEXyjLIiHxieElNqs5E3dIp',\n  transport: 'socketio',\n  receivedAt: 1338459592482,\n  use: [Function] }\n{ id: 1,\n  method: 'app.gusr',\n  params: [],\n  socketId: '5926658152055406305',\n  clientIp: '127.0.0.1',\n  sessionId: 'zqEXyjLIiHxieElNqs5E3dIp',\n  transport: 'socketio',\n  receivedAt: 1338459592482,\n  use: [Function],\n  session: \n   { lastAccess: 1338458465412,\n     cookie: \n      { path: '/',\n        _expires: Thu, 31 May 2012 14:19:52 GMT,\n        originalMaxAge: undefined,\n        httpOnly: true },\n     channel: \n      { list: [Function],\n        subscribe: [Function],\n        unsubscribe: [Function],\n        reset: [Function],\n        _bindToSocket: [Function] },\n     setUserId: [Function],\n     _bindToSocket: [Function],\n     save: [Function] } }\n\u21a9 rpc:1 app.gusr (2ms)\n. Hi Owen\nYou see, sometimes it's not very practical to have fixed folder structure. Some 3rd party frameworks would have this folder structure fixed and built tool chains around them. For me this mean to work with the two I need tow write separate toolchain to mary them which obviously I don't want to do.\nJacob\n. Owen,\nAbsolutely agree with above statements, I wasn't questioning your direction, just pointing that introducing some flexibility would attract more use cases and scare less of them. \nAfter all I've overcome current limitations and get my 3rd party framework coexisting with SocketStream.\nFollowing line came particularly useful:\napp.use('/resource', express.static('../../someother/resource'));\nbut resulted in some ugly path fixing.\n. Owen,\nThat would help...\n. Owen,\ntried to simplify as much as possible.\nHere goes server side:\nexports.actions = function(req, res, ss) {\n   return {\n       modifyUser : function(uid) {\n            // Some function that updates user based on conditions, ran twice never produce same results\n            User.update( ... , function(e, numberUpdated) {\n                res({\n                    r : numberUpdated\n                });\n            });\n        }\n    }\n}\nand client code:\nss.rpc('app.modifyUser', user.uid, function(d) {\n    console.log(d);\n});\nSo invokig the client code twice with same uid will yield same results even though server returns different numberUpdated each time. When uid is different it will behave properly and return correct results.\n. Well seeing what's on the wire helped as I was able to spot I'm doing assignment not comparison at the very last line before passing result, can't believe how silly...\nSorry to waste your time. \n. My bad, included one of the functions somewhere else and passed null for request.\n. I actually did that, but it didn't helped...\nI also believe that following hard code in websocket/transports/socketio/index.coffee\n```\nprocessSession = (socket) ->\n  return true if socket.sessionId\n# Parse session ID from initial hankshake data\n  try\n    rawCookie = socket.handshake.headers.cookie\n    cookie = qs.parse(rawCookie)\n    sessionId = cookie['connect.sid'].split('.')[0]\n    socket.sessionId = sessionId\n  catch e\n    console.log('Warning: connect.sid session cookie not detected. User may have cookies disabled or session cookie has expired')\n    false\n```\nis also causing problems but even after patching it problem remains.\n. Having done as I was told...\nWas using mongostore instead of redis, switching to redis is helpful as it shows an issue in monitor mode:\n1339152856.068663 \"info\"\n1339152857.806205 \"get\" \"sess:dELB4PDK2VdqnbEGJksVrOKX\"\n1339152913.244874 \"get\" \"sess:dELB4PDK2VdqnbEGJksVrOKX\"\n1339152913.251029 \"setex\" \"sess:undefined\" \"14399\" \"{\\\"lastAccess\\\":1339151896801,\\\"cookie\\\":{\\\"expires\\\":\\\"2012-06-08T14:55:13.245Z\\\",\\\"httpOnly\\\":true,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"userId\\\":\\\"usr@srv.com\\\"}\"\n1339152913.251104 \"setex\" \"sess:undefined\" \"14399\" \"{\\\"lastAccess\\\":1339151896801,\\\"cookie\\\":{\\\"expires\\\":\\\"2012-06-08T14:55:13.245Z\\\",\\\"httpOnly\\\":true,\\\"path\\\":\\\"/\\\"},\\\"channel\\\":{},\\\"userId\\\":\\\"usr@srv.com\\\",\\\"user\\\":{\\\"email\\\":\\\"usr@srv.com\\\",\\\"phone\\\":\\\"+44\\\",\\\"passwd\\\":\\\"86f7e437faa5a7fce15d1ddcb9eaeaea377667b8\\\",\\\"joined\\\":\\\"2012-05-31T10:04:40.099Z\\\",\\\"verified\\\":true,\\\"type\\\":\\\"ind\\\",\\\"_id\\\":\\\"4fc742383643b9b67c000002\\\"}}\"\n1339152967.840794 \"get\" \"sess:BeqPCdGF31T9JrHaYpka4UBm\"\n1339152967.842050 \"setex\" \"sess:BeqPCdGF31T9JrHaYpka4UBm\" \"14400\" \"{\\\"lastAccess\\\":1339152967841,\\\"cookie\\\":{\\\"maxAge\\\":14400000}}\"\n...not sure why though setting user id and saving session operations are having undefined sessionid.\nThis output is corresponding to previous report in terms of flow of actions.\n. Now, turns out I was on RC1 instead of RC2 where problem does not exists. In RC1 while saving there was call to session.sessionId instead of session.id which was causing the problem above.\n. Well, I was thinking more about server-side cookie access in ss rpc methods.\n. The difficulty I'm having is to access the same inside ss rpc responders. So what I would like to do is to for example set cookie on response from within rpc responder function. So far I haven't been able to do that without modifying ss code.\nss.http.middleware.append() and prepend() methods came first to mind but request nor response objects are not directly accesible within rpc responder, same for ss.\n. Yet, cookie fo the session is set. Are you saying that if communication happens through flash sockets session support will not work ?\n. Hence I thought it would be nice to have access to this in rpc methods.\n. Well it could come at a cost of having this with socket.io or whichever transport supporting the same - not ideal but an option.\nThing is, it's really nice to have access to cookies, one could exchange them for browser local store but it's not exactly the same.\n. Thank you all for exhausting explanations. My motivation was to store session data client side in the usual manner (as supported by connect 2.x) plus some other needs, after all I can live with local storage in the browser or cookies as suggested.\n. I'm dealing with two type of clients on mobile devices - browser based (Safari/Chrome) and those are working just fine with current SocketStream. Others are native (iPhone/Android) where I have little chance to patch handshake to set cookie there. \nInstead I've patched socket.io transport in SS so it would always return true from processSession and it works so far, just don't know yet what implications would that have for browser clients.\nFirst implication is of cource Pub/Sub Events not working as there's no session.\n. This is of course assuming ones using SS alone, in my case I'm using it with Express which results in cookie being in fore mentioned format (I've deleted cookie to check if different one is being set, but same format still apply)\n. Well, there is no shortage of these, ex. i18next jsperanto, jed, messageformat. I'm more asking about suggestions on how to use them within socketstream and what's possible future directions on that.\nOn top of regular i18n considerations like prulars, loading, translation standard, there are ones that come with socketstream itself - when to load, where to inject, what about packed assets and so on. Was wondering if anybody did any thinking on that.\n. I came across this while having to generate app cache manifest. As a\nworkaround I get clientid replicating ss wqy of doing it.\nI think the best would be to ask for clientid. So when definig client I get\nclient object back. That could contain appropriate id the could be used\nlater.\nOn Jan 24, 2013 9:27 PM, \"Owen Barnes\" notifications@github.com wrote:\n\nHi there\nA valid issue for sure. I understand you want a list of the client IDs,\nbut what would you expect that API to look like?\nMaybe something like ss.client.all() would return an array of clients\n(each an object containing an ID)?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/328#issuecomment-12671491.\n. \n",
    "wmulligan": "One additional idea, I think socketstream should support index.js.\nIf you have a folder called demo, and you put a index.js inside it, a call to require('demo') would execute the index.js.  This is just like NodeJS.\n. Also, if libs is a 'builtin' exception, then i think we should move it outside the code folder and have a libs folder.\n. Yes, that is what I was suggesting.\nPerformance during production should not be any issue, since its just a one time cost at the start of the process.  But I do see your point about developing.\nOne idea is if you store the dependencies of each script, then if a single script gets modified, you just parse that single script for any changes.  You would not need to reparse all the scripts.\nI haven't explored broswerify much, but heres an example of really simple code to find all the require calls inside a script: https://github.com/substack/node-detective\n. Whats the point of the md5 checksum?  I thought socketstream watched each file for changes, so you can use that to determine which file to reparse.\n. Perhaps make it optional?\n. Yes, there is an assumption that programmers won't pass variables into the require statement.\nIf the programmer simply follows that one rule, then the AMD structure can be autogenerated.\n. I think you are over complicating it.  One rule: common sense.\nClearly if you redefine require, it would fail.  Or if you use addition of strings.\nIt might not be the best solution for everyone, but I think most people would find it useful.  As I said, leave it optional.\n. I think the most important thing is to have some solution besides a giant list in app.js of all the files with the correct order.\n. I vote for the 'pre-flight checker'.  I think it is almost necessary if you ware building a large web application with async module loading.\n. One additional idea, I think socketstream should support index.js.\nIf you have a folder called demo, and you put a index.js inside it, a call to require('demo') would execute the index.js.  This is just like NodeJS.\n. Also, if libs is a 'builtin' exception, then i think we should move it outside the code folder and have a libs folder.\n. Yes, that is what I was suggesting.\nPerformance during production should not be any issue, since its just a one time cost at the start of the process.  But I do see your point about developing.\nOne idea is if you store the dependencies of each script, then if a single script gets modified, you just parse that single script for any changes.  You would not need to reparse all the scripts.\nI haven't explored broswerify much, but heres an example of really simple code to find all the require calls inside a script: https://github.com/substack/node-detective\n. Whats the point of the md5 checksum?  I thought socketstream watched each file for changes, so you can use that to determine which file to reparse.\n. Perhaps make it optional?\n. Yes, there is an assumption that programmers won't pass variables into the require statement.\nIf the programmer simply follows that one rule, then the AMD structure can be autogenerated.\n. I think you are over complicating it.  One rule: common sense.\nClearly if you redefine require, it would fail.  Or if you use addition of strings.\nIt might not be the best solution for everyone, but I think most people would find it useful.  As I said, leave it optional.\n. I think the most important thing is to have some solution besides a giant list in app.js of all the files with the correct order.\n. I vote for the 'pre-flight checker'.  I think it is almost necessary if you ware building a large web application with async module loading.\n. ",
    "comerc": "Thanks, it work! If to add in libs - jquery.tmpl.min.js And earlier there was a prefix \"templates-\", but now - \"tmpl-\". For example: $ (' tmpl-my-dir ')\n. Thanks, it work! If to add in libs - jquery.tmpl.min.js And earlier there was a prefix \"templates-\", but now - \"tmpl-\". For example: $ (' tmpl-my-dir ')\n. ",
    "OClement": "Have been struggling with the same issue for a while before finding this (I should have checked first actually, that'll teach me!)\nI would stress the fact that this really would need to be updated on www.socketstream.org\nI also had issues with ss-jade - I've opened an issue on ss-jade project with a workaround\n. Have been struggling with the same issue for a while before finding this (I should have checked first actually, that'll teach me!)\nI would stress the fact that this really would need to be updated on www.socketstream.org\nI also had issues with ss-jade - I've opened an issue on ss-jade project with a workaround\n. ",
    "makela": "I've tested this with Firefox, Chrome and Safari. I think I encountered this because I've developed some other stuff also with localhost domain and those other applications have written some cookie stuff so the cookie wasn't empty when I started.\nBtw. More clean fix would have been to use connect's cookieParser, but it might be overkill for this purpose.\n. I've tested this with Firefox, Chrome and Safari. I think I encountered this because I've developed some other stuff also with localhost domain and those other applications have written some cookie stuff so the cookie wasn't empty when I started.\nBtw. More clean fix would have been to use connect's cookieParser, but it might be overkill for this purpose.\n. ",
    "sntran": "Currently, I'm doing like this\n- Create a rpc server/rpc/user.coffee\n``` coffeescript\nexports.actions = (req, res, ss) ->\n    req.use('session')\ngetCurrent: () ->\n    res(req.session.userId)\n\n``\n- Call the RPC function fromclient/code/app/demo.coffee`\ncoffeescript\nuser = ss.rpc 'user.getCurrent', (response) ->\n  html = HT['login'].render\n    user: response\n    methods: [\"twitter\", \"google\"]\n  $(\"#dashboard\").html(html)\n- Then on my templates/login.jade\nmustache\n{{#user}}\np Hi {{user}}! <a href=\"/logout\">Logout</a>\n{{/user}}\n{{^user}}\np Login with\n{{#methods}}\n<a href=\"/auth/{{.}}\">{{.}}</a>\n{{/methods}}\n{{/user}}\nHowever, I'm not sure this is the best way to do it. It looks like a lot of code.\n. Sorry, I will close it. Thanks!\n. Currently, I'm doing like this\n- Create a rpc server/rpc/user.coffee\n``` coffeescript\nexports.actions = (req, res, ss) ->\n    req.use('session')\ngetCurrent: () ->\n    res(req.session.userId)\n\n``\n- Call the RPC function fromclient/code/app/demo.coffee`\ncoffeescript\nuser = ss.rpc 'user.getCurrent', (response) ->\n  html = HT['login'].render\n    user: response\n    methods: [\"twitter\", \"google\"]\n  $(\"#dashboard\").html(html)\n- Then on my templates/login.jade\nmustache\n{{#user}}\np Hi {{user}}! <a href=\"/logout\">Logout</a>\n{{/user}}\n{{^user}}\np Login with\n{{#methods}}\n<a href=\"/auth/{{.}}\">{{.}}</a>\n{{/methods}}\n{{/user}}\nHowever, I'm not sure this is the best way to do it. It looks like a lot of code.\n. Sorry, I will close it. Thanks!\n. ",
    "trungpham": "Can you document which javascript files are generated by '!= SocketStream' helper function so I can manually include them into the sencha touch html bootstrap file?\nThanks.\n. is there anything dynamic about these files? should we be using checksum instead of timestamp to do cache expiration?\nThis way we don't have to pay the latency penalty when the user comes back to the app the second time.\n. Can you document which javascript files are generated by '!= SocketStream' helper function so I can manually include them into the sencha touch html bootstrap file?\nThanks.\n. is there anything dynamic about these files? should we be using checksum instead of timestamp to do cache expiration?\nThis way we don't have to pay the latency penalty when the user comes back to the app the second time.\n. ",
    "sebv": "Just had the problem, this is how I got it to work, not sure it is the best way:\nin code/libs:  \n1-underscore.js\n2-jquery.min.js\n3-backbone.js\nin code/system:\nbackbone.js: (just a placeholder with the line below, so that it is still possible to do require) \nmodule.exports = window.Backbone\nunderscore.js: (placeholder) \nmodule.exports = window._\nYou'll need to add system to app.js\nIn the client code, I use 'require' in the shared code(like models), but don't use it in client specific code (like view and router) \n. Been experimenting with fs.watch on Mac and behaviour is quite erratic. Can only be relied upon to work once, sometimes sending duplicates signals depending on how the file modif is made. \nThis makes it works, also avoid unnecessary updates. This should behave the same on other systems, the idea being overriding the fileWatcher.watch method depending on the op system.\n2cf65048e74f881914e26de3cc9b0af889cad388\n. This is how coffeescript does it:\nhttps://github.com/jashkenas/coffee-script/blob/master/src/command.coffee#L205\nThere are 2 approaches, using fs.watch or fs.watchFile. One is signal based, the other polls at regular intervals.\nlooks like chokidar is using the polling approach, will give it a try anyway.\n. Just had the problem, this is how I got it to work, not sure it is the best way:\nin code/libs:  \n1-underscore.js\n2-jquery.min.js\n3-backbone.js\nin code/system:\nbackbone.js: (just a placeholder with the line below, so that it is still possible to do require) \nmodule.exports = window.Backbone\nunderscore.js: (placeholder) \nmodule.exports = window._\nYou'll need to add system to app.js\nIn the client code, I use 'require' in the shared code(like models), but don't use it in client specific code (like view and router) \n. Been experimenting with fs.watch on Mac and behaviour is quite erratic. Can only be relied upon to work once, sometimes sending duplicates signals depending on how the file modif is made. \nThis makes it works, also avoid unnecessary updates. This should behave the same on other systems, the idea being overriding the fileWatcher.watch method depending on the op system.\n2cf65048e74f881914e26de3cc9b0af889cad388\n. This is how coffeescript does it:\nhttps://github.com/jashkenas/coffee-script/blob/master/src/command.coffee#L205\nThere are 2 approaches, using fs.watch or fs.watchFile. One is signal based, the other polls at regular intervals.\nlooks like chokidar is using the polling approach, will give it a try anyway.\n. ",
    "davisford": "It has something to do with my global uglify-js install.  I had installed this first to build twitter bootstrap.   I found out if you do things in this order it won't work:\nnpm install uglify-js -g \ngit clone https://github.com/socketstream/socketstream.git && cd socketstream\nsudo npm link\nsocketstream --version ==> FAIL\nDoing this fixed it - perhaps this is common knowledge, I'm not that familiar with how npm does it's thing (yet)\nnpm remove uglify-js -g\ncd socketstream && rm -rf *\ngit clone https://github.com/socketstream/socketstream.git .\nsudo npm link\nnpm install uglify-js -g\nsocketstream --version ==> SUCCESS\n. I was able to resolve this if I carefully specified the correct ordering of things \n``` javascript\nvar app = express.createServer(\n  express.bodyParser()\n, express.static(__dirname + \"/client/static\")\n, ss.http.middleware\n, mongooseAuth.middleware()\n);\nmongooseAuth.helpExpress(app);\napp.get('/', function(req, res) { ... });\napp.listen(3000);\nss.start(app);\n```\n. Hi Owen,\nI was trying to use something like Jade iteration with Hogan...and it\ndoesn't work for the reasons listed on the github issue.  That much I get,\nbut I still don't get why simple iteration doesn't work with Jade if you\ntake Hogan {{ }} out of the equation.\nSee my last response there https://github.com/visionmedia/jade/issues/640 ,\nit is easy to create a simple example with a jade loop and try to iterate\nover objects.\n// in client/templates/foo/bar.jade\neach val, key in obj\n  li #{key} : #{val}\nusage:\nvar html = ss.tmpl['foo-bar'].render({ obj: { zing: \"zang\" }});\nI would expect HTML as =>\nzing: zang\nBut instead I get\n! Errror formatting Jade template\n/etc/datatable.jade:1\n\n1| each val, key in obj\n    2|   li #{key}: #{val}\n\nobj is not defined\nAny idea why this is?  Am I doing it wrong?\nI was able to get poor-man's iteration with just hogan as such:\n// in client/templates/foo/bar.jade\n{{#obj}}\nzing: {{zing}}\n{{/obj}}\nWhich will produce zing: zang\n..but that doesn't iterate over all properties like Jade supports, which\ncan be useful.  Here you must call out the property by name.\nSo, as stated, I was planning on trying to use templating to fill in a\nfancy, editable table with http://datatables.net, but since I could not get\nvery far with this, I opted instead for sending the raw objects to the\nclient via RPC and using the DataTables API to feed it into a table.  This\nis working fine for me now.\nLong story short: I'm past my roadblock, but I would still like to know why\nJade iteration isn't working for me, and if we can make it work, I think it\nwould be useful.\nThanks Owen\nOn Tue, May 15, 2012 at 11:18 AM, Owen Barnes <\nreply@reply.github.com\n\nwrote:\nHey Davis\nCan you let me know where you are with this now and if you still need help?\nBtw I am aware that the Jade/Hogan mix is confusing. I am thinking about\nmaking Jade templating (using\nhttps://github.com/socketstream/ss-clientjade) the default in the next\nmajor release but I want to work with it some more before I confirm that.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/232#issuecomment-5718537\n. Good Lord -- I must not be subscribed to this topic on github, or else gmail is just filtering it all to hell, b/c I never saw all the me-toos.  I honestly don't recall the exact convo we had over IRC, but I can tell you that I just \"worked\" around the problem - I could not get simple things like iteration to work.  \n\nss-jade source is just a call out to the jade \"compiler\" -- seems like the Jade people will have more insight into what is up...that's why I posted over there.\n@owenb we are working with a somewhat crippled Jade integration here, I will also try to take another look into it - I just gave up and moved on last time.\n. I also noticed on the server-side console, these debug messages when the issue happens:\n\u21aa rpc:2 admin.devices.get\n\u21a9 rpc:2 admin.devices.get (5ms)\n\u21a9 rpc:2 admin.devices.get (11ms)\nIf I read that correctly, there is one incoming request that calls admin.devices.get, and two outgoing responses.\nUpon further investigation, I have traced it down to some security middleware that I put in place.\nin server/middleware/security.js\njavascript\nexports.isAdmin = function() {\n  return function (req, res, next) {\n    if (req.session.isAdmin === true) { return next(); }\n    else { return res(new Error('unauthorized')); }\n  };\n}();\nThen in my rpc code I use this middleware:\nin server/rpc/admin/devices.js\n``` javascript\nexports.actions = function (req, res, ss) {\n  req.use('session');\n  req.use('security.isAdmin');  // this middleware causes the extra response\nreturn {\n    get: function () {\n      res('foo', 'bar');\n    }\n  }\n}\n```\nIf I comment out req.use('security.isAdmin'); I don't get the extra response.  I'm not sure why this happens, as I only return an Error from the middleware the user's session state indicates that they are not an admin, otherwise, it just calls next() -- can you explain why\nthis is causing an additional RPC response?\n. Note, if I just change the middleware to be return function (req, res, next) { return next(); } it still responds back two times.\n. I can double confirm it.  I haven't had time to get back to it, but my project has become a bit more complex than the SocketStream demo chat app, so what I'd like to do is create another simple demo chat app, and see if I can reproduce it there.  That way, I can rule out something else in the code that is causing this.\nIf I'm able to reproduce there, I will put the code in github so you can take a look.\n. Here's a chat demo app: https://github.com/davisford/ss-demo\nI'm using express and I spin up express in app.js, and define two separate routes for two separate apps.  In this demo, the apps point to the same resources -- in my real app, they do not, but I made them point to the same thing to keep things simple.\nI use my own middleware on the '/admin' route called security.isAdmin.  In the '/' route, if you go first to http://localhost:3000 the session will be stamped with isAdmin, and if you later request '/admin' the middleware should pass the admin test.\n``` javascript\nvar app = express.createServer(\n  express.bodyParser(),\n  express.static(__dirname + \"/client/static\"),\n  ss.http.middleware\n);\napp.get('/', function (req, res) {\n   req.session.isAdmin = true;\n   req.session.save();\n   req.serveClient('main');\n});\napp.get('/admin', security.isAdmin, function (req, res) {\n  res.serveClient('main');\n});\napp.listen(3000);\nss.start(app);\n```\nTo re-iterate, first hit http://localhost:3000 and then hit http://localhost:3000/admin \nYou should see this in the console:\nmiddleware => security.isAdmin { lastAccess: 1338995818223,\n  cookie: \n   { path: '/',\n     _expires: null,\n     originalMaxAge: null,\n     httpOnly: false },\n  isAdmin: true }\nNow try to send a chat message.  \nThe rpc method looks like this:\n```\nexports.actions = function(req, res, ss) {\n// Example of pre-loading sessions into req.session using internal middleware\n  req.use('session');\n  req.use('security.isAdmin');\n// Uncomment line below to use the middleware defined in server/middleware/example\n  //req.use('example.authenticated')\nreturn {\nsendMessage: function(message) {\n  console.log('RPC sendMessage => '+message);\n  if (message && message.length > 0) {         // Check for blank messages\n    //ss.publish.all('newMessage', message);     // Broadcast the message to everyone\n    console.log('respond true');\n    return res(true);                          // Confirm it was sent to the originating client\n  } else {\n    console.log('respond false');\n    return res(false);\n  }\n}\n\n};\n};\n```\nYou'll see the server calls the RPC function - but the middleware doesn't appear to be executed again -- is this b/c it is memo-ized or something?  Nevertheless, no matter what I pass to res( ) here, the client always receives undefined\nI've seen this problem trying to include my own middleware like this -- the first time it returns undefined and the second time will return the value.  In this particular demo, I am not seeing it return twice from the RPC response, but it is returning undefined and that is a yet another problem.\nIf I comment out the res.use('security.isAdmin'); it returns the value just fine.  Something about including the middleware seems to corrupt it.\nIt could be that I'm doing something completely stupid here, but I was hoping you could take a quick look and clear it up for me (very well may be user error).\n. facepalm ....oh, JavaScript, how I love thee.  Sorry about wasting your time.  I should have caught that.\n. Moved comment over into #259\n. Hi Owen, I tried the fix in #256 and that does resolve it for me.  I guess this is a dupe.  I think the repeated get/setex calls are due to middleware ordering, something else I'm looking into.\n. Seems to be covered in #256\n. I think this seems related to https://github.com/visionmedia/connect-redis/pull/37\nI am trying to track it down in node-inspector -- in connect-redis\nRedisStore.prototype.get = function(sid, fn){\n    sid = this.prefix + sid;\n    debug('GET \"%s\"', sid);\n    this.client.get(sid, function(err, data){\n      if (err) return fn(err);\n      try {\n        if (!data) return fn();\n        data = data.toString();\n        debug('GOT %s', data);\n        fn(null, JSON.parse(data));\n      } catch (err) {\n        fn(err);\n      } \n    });\n  };\nThe catch (err) block is hit, but it seems to be hit without any relation to the try block before it....meaning I think the actual Redis driver catches any errors thrown by callbacks, and re-throws them on next tick.  I'm still trying to find the exact spot this is occurring.\n. Thanks @paulbjensen -- as an aside, I am on #socketstream now if you want to jump on and discuss.  I can repeat this every time...trying to figure out where the root cause is...it is a fairly bizarre issue.   Trying to figure out if it is worth my time to try to create a skeleton project that can repeat the issue.\nFirst, I am trying to run with the HEAD rev of connect-redis and also upgrade Redis itself to see if the problem goes away.\n. I was able to resolve it -- in the rpc I was executing an async mongoosejs query and passing the userId -- which ended up being undefined, producing a bizarro stacktrace with the error caught way up in the redis driver itself.\n. It has something to do with my global uglify-js install.  I had installed this first to build twitter bootstrap.   I found out if you do things in this order it won't work:\nnpm install uglify-js -g \ngit clone https://github.com/socketstream/socketstream.git && cd socketstream\nsudo npm link\nsocketstream --version ==> FAIL\nDoing this fixed it - perhaps this is common knowledge, I'm not that familiar with how npm does it's thing (yet)\nnpm remove uglify-js -g\ncd socketstream && rm -rf *\ngit clone https://github.com/socketstream/socketstream.git .\nsudo npm link\nnpm install uglify-js -g\nsocketstream --version ==> SUCCESS\n. I was able to resolve this if I carefully specified the correct ordering of things \n``` javascript\nvar app = express.createServer(\n  express.bodyParser()\n, express.static(__dirname + \"/client/static\")\n, ss.http.middleware\n, mongooseAuth.middleware()\n);\nmongooseAuth.helpExpress(app);\napp.get('/', function(req, res) { ... });\napp.listen(3000);\nss.start(app);\n```\n. Hi Owen,\nI was trying to use something like Jade iteration with Hogan...and it\ndoesn't work for the reasons listed on the github issue.  That much I get,\nbut I still don't get why simple iteration doesn't work with Jade if you\ntake Hogan {{ }} out of the equation.\nSee my last response there https://github.com/visionmedia/jade/issues/640 ,\nit is easy to create a simple example with a jade loop and try to iterate\nover objects.\n// in client/templates/foo/bar.jade\neach val, key in obj\n  li #{key} : #{val}\nusage:\nvar html = ss.tmpl['foo-bar'].render({ obj: { zing: \"zang\" }});\nI would expect HTML as =>\nzing: zang\nBut instead I get\n! Errror formatting Jade template\n/etc/datatable.jade:1\n\n1| each val, key in obj\n    2|   li #{key}: #{val}\n\nobj is not defined\nAny idea why this is?  Am I doing it wrong?\nI was able to get poor-man's iteration with just hogan as such:\n// in client/templates/foo/bar.jade\n{{#obj}}\nzing: {{zing}}\n{{/obj}}\nWhich will produce zing: zang\n..but that doesn't iterate over all properties like Jade supports, which\ncan be useful.  Here you must call out the property by name.\nSo, as stated, I was planning on trying to use templating to fill in a\nfancy, editable table with http://datatables.net, but since I could not get\nvery far with this, I opted instead for sending the raw objects to the\nclient via RPC and using the DataTables API to feed it into a table.  This\nis working fine for me now.\nLong story short: I'm past my roadblock, but I would still like to know why\nJade iteration isn't working for me, and if we can make it work, I think it\nwould be useful.\nThanks Owen\nOn Tue, May 15, 2012 at 11:18 AM, Owen Barnes <\nreply@reply.github.com\n\nwrote:\nHey Davis\nCan you let me know where you are with this now and if you still need help?\nBtw I am aware that the Jade/Hogan mix is confusing. I am thinking about\nmaking Jade templating (using\nhttps://github.com/socketstream/ss-clientjade) the default in the next\nmajor release but I want to work with it some more before I confirm that.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/232#issuecomment-5718537\n. Good Lord -- I must not be subscribed to this topic on github, or else gmail is just filtering it all to hell, b/c I never saw all the me-toos.  I honestly don't recall the exact convo we had over IRC, but I can tell you that I just \"worked\" around the problem - I could not get simple things like iteration to work.  \n\nss-jade source is just a call out to the jade \"compiler\" -- seems like the Jade people will have more insight into what is up...that's why I posted over there.\n@owenb we are working with a somewhat crippled Jade integration here, I will also try to take another look into it - I just gave up and moved on last time.\n. I also noticed on the server-side console, these debug messages when the issue happens:\n\u21aa rpc:2 admin.devices.get\n\u21a9 rpc:2 admin.devices.get (5ms)\n\u21a9 rpc:2 admin.devices.get (11ms)\nIf I read that correctly, there is one incoming request that calls admin.devices.get, and two outgoing responses.\nUpon further investigation, I have traced it down to some security middleware that I put in place.\nin server/middleware/security.js\njavascript\nexports.isAdmin = function() {\n  return function (req, res, next) {\n    if (req.session.isAdmin === true) { return next(); }\n    else { return res(new Error('unauthorized')); }\n  };\n}();\nThen in my rpc code I use this middleware:\nin server/rpc/admin/devices.js\n``` javascript\nexports.actions = function (req, res, ss) {\n  req.use('session');\n  req.use('security.isAdmin');  // this middleware causes the extra response\nreturn {\n    get: function () {\n      res('foo', 'bar');\n    }\n  }\n}\n```\nIf I comment out req.use('security.isAdmin'); I don't get the extra response.  I'm not sure why this happens, as I only return an Error from the middleware the user's session state indicates that they are not an admin, otherwise, it just calls next() -- can you explain why\nthis is causing an additional RPC response?\n. Note, if I just change the middleware to be return function (req, res, next) { return next(); } it still responds back two times.\n. I can double confirm it.  I haven't had time to get back to it, but my project has become a bit more complex than the SocketStream demo chat app, so what I'd like to do is create another simple demo chat app, and see if I can reproduce it there.  That way, I can rule out something else in the code that is causing this.\nIf I'm able to reproduce there, I will put the code in github so you can take a look.\n. Here's a chat demo app: https://github.com/davisford/ss-demo\nI'm using express and I spin up express in app.js, and define two separate routes for two separate apps.  In this demo, the apps point to the same resources -- in my real app, they do not, but I made them point to the same thing to keep things simple.\nI use my own middleware on the '/admin' route called security.isAdmin.  In the '/' route, if you go first to http://localhost:3000 the session will be stamped with isAdmin, and if you later request '/admin' the middleware should pass the admin test.\n``` javascript\nvar app = express.createServer(\n  express.bodyParser(),\n  express.static(__dirname + \"/client/static\"),\n  ss.http.middleware\n);\napp.get('/', function (req, res) {\n   req.session.isAdmin = true;\n   req.session.save();\n   req.serveClient('main');\n});\napp.get('/admin', security.isAdmin, function (req, res) {\n  res.serveClient('main');\n});\napp.listen(3000);\nss.start(app);\n```\nTo re-iterate, first hit http://localhost:3000 and then hit http://localhost:3000/admin \nYou should see this in the console:\nmiddleware => security.isAdmin { lastAccess: 1338995818223,\n  cookie: \n   { path: '/',\n     _expires: null,\n     originalMaxAge: null,\n     httpOnly: false },\n  isAdmin: true }\nNow try to send a chat message.  \nThe rpc method looks like this:\n```\nexports.actions = function(req, res, ss) {\n// Example of pre-loading sessions into req.session using internal middleware\n  req.use('session');\n  req.use('security.isAdmin');\n// Uncomment line below to use the middleware defined in server/middleware/example\n  //req.use('example.authenticated')\nreturn {\nsendMessage: function(message) {\n  console.log('RPC sendMessage => '+message);\n  if (message && message.length > 0) {         // Check for blank messages\n    //ss.publish.all('newMessage', message);     // Broadcast the message to everyone\n    console.log('respond true');\n    return res(true);                          // Confirm it was sent to the originating client\n  } else {\n    console.log('respond false');\n    return res(false);\n  }\n}\n\n};\n};\n```\nYou'll see the server calls the RPC function - but the middleware doesn't appear to be executed again -- is this b/c it is memo-ized or something?  Nevertheless, no matter what I pass to res( ) here, the client always receives undefined\nI've seen this problem trying to include my own middleware like this -- the first time it returns undefined and the second time will return the value.  In this particular demo, I am not seeing it return twice from the RPC response, but it is returning undefined and that is a yet another problem.\nIf I comment out the res.use('security.isAdmin'); it returns the value just fine.  Something about including the middleware seems to corrupt it.\nIt could be that I'm doing something completely stupid here, but I was hoping you could take a quick look and clear it up for me (very well may be user error).\n. facepalm ....oh, JavaScript, how I love thee.  Sorry about wasting your time.  I should have caught that.\n. Moved comment over into #259\n. Hi Owen, I tried the fix in #256 and that does resolve it for me.  I guess this is a dupe.  I think the repeated get/setex calls are due to middleware ordering, something else I'm looking into.\n. Seems to be covered in #256\n. I think this seems related to https://github.com/visionmedia/connect-redis/pull/37\nI am trying to track it down in node-inspector -- in connect-redis\nRedisStore.prototype.get = function(sid, fn){\n    sid = this.prefix + sid;\n    debug('GET \"%s\"', sid);\n    this.client.get(sid, function(err, data){\n      if (err) return fn(err);\n      try {\n        if (!data) return fn();\n        data = data.toString();\n        debug('GOT %s', data);\n        fn(null, JSON.parse(data));\n      } catch (err) {\n        fn(err);\n      } \n    });\n  };\nThe catch (err) block is hit, but it seems to be hit without any relation to the try block before it....meaning I think the actual Redis driver catches any errors thrown by callbacks, and re-throws them on next tick.  I'm still trying to find the exact spot this is occurring.\n. Thanks @paulbjensen -- as an aside, I am on #socketstream now if you want to jump on and discuss.  I can repeat this every time...trying to figure out where the root cause is...it is a fairly bizarre issue.   Trying to figure out if it is worth my time to try to create a skeleton project that can repeat the issue.\nFirst, I am trying to run with the HEAD rev of connect-redis and also upgrade Redis itself to see if the problem goes away.\n. I was able to resolve it -- in the rpc I was executing an async mongoosejs query and passing the userId -- which ended up being undefined, producing a bizarro stacktrace with the error caught way up in the redis driver itself.\n. ",
    "MaheshBusa": "module.js:471\n    throw err;\n    ^\nError: Cannot find module './lib/parse-js'\n    at Function.Module._resolveFilename (module.js:469:15)\n    at Function.Module._load (module.js:417:25)\n    at Module.require (module.js:497:17)\n    at require (internal/module.js:20:19)\n    at Object. (D:\\Users\\nabusa\\project\\angular-seed-enhanced-master\\\nnode_modules\\karma\\node_modules\\socket.io\\node_modules\\socket.io-client\\node_mod\nules\\uglify-js\\uglify-js.js:14:17)\n    at Module._compile (module.js:570:32)\n    at Object.Module._extensions..js (module.js:579:10)\n    at Module.load (module.js:487:32)\n    at tryModuleLoad (module.js:446:12)\n    at Function.Module._load (module.js:438:3). [\u200e08-\u200eFeb-\u200e17 14:51] Busa, Naga: \nmodule.js:471 \nmodule.js:471\n    throw err;\n    ^\nError: Cannot find module './lib/parse-js'\n    at Function.Module._resolveFilename (module.js:469:15)\n    at Function.Module._load (module.js:417:25)\n    at Module.require (module.js:497:17)\n    at require (internal/module.js:20:19)\n    at Object. (D:\\Users\\nabusa\\project\\angular-seed-enhanced-master\\\nnode_modules\\karma\\node_modules\\socket.io\\node_modules\\socket.io-client\\node_mod\nules\\uglify-js\\uglify-js.js:14:17)\n    at Module._compile (module.js:570:32)\n    at Object.Module._extensions..js (module.js:579:10)\n    at Module.load (module.js:487:32)\n    at tryModuleLoad (module.js:446:12)\n    at Function.Module._load (module.js:438:3) \n. module.js:471\n    throw err;\n    ^\nError: Cannot find module './lib/parse-js'\n    at Function.Module._resolveFilename (module.js:469:15)\n    at Function.Module._load (module.js:417:25)\n    at Module.require (module.js:497:17)\n    at require (internal/module.js:20:19)\n    at Object. (D:\\Users\\nabusa\\project\\angular-seed-enhanced-master\\\nnode_modules\\karma\\node_modules\\socket.io\\node_modules\\socket.io-client\\node_mod\nules\\uglify-js\\uglify-js.js:14:17)\n    at Module._compile (module.js:570:32)\n    at Object.Module._extensions..js (module.js:579:10)\n    at Module.load (module.js:487:32)\n    at tryModuleLoad (module.js:446:12)\n    at Function.Module._load (module.js:438:3). [\u200e08-\u200eFeb-\u200e17 14:51] Busa, Naga: \nmodule.js:471 \nmodule.js:471\n    throw err;\n    ^\nError: Cannot find module './lib/parse-js'\n    at Function.Module._resolveFilename (module.js:469:15)\n    at Function.Module._load (module.js:417:25)\n    at Module.require (module.js:497:17)\n    at require (internal/module.js:20:19)\n    at Object. (D:\\Users\\nabusa\\project\\angular-seed-enhanced-master\\\nnode_modules\\karma\\node_modules\\socket.io\\node_modules\\socket.io-client\\node_mod\nules\\uglify-js\\uglify-js.js:14:17)\n    at Module._compile (module.js:570:32)\n    at Object.Module._extensions..js (module.js:579:10)\n    at Module.load (module.js:487:32)\n    at tryModuleLoad (module.js:446:12)\n    at Function.Module._load (module.js:438:3) \n. ",
    "alexandertrefz": "Is there any Progress on this? I am hitting this problem right now quite a bit on my testing server which make use of the new feature to provide a socket url for socket.io directly. Since i have done that change, i get that cookie error, but only if i go on the \"http\" URL(testing.productname.com) and not if i go to the \"real\" url (host.com:port) that my websockets use. That Fix is really dirty for userland and i would love to avoid it.\n. Is there any Progress on this? I am hitting this problem right now quite a bit on my testing server which make use of the new feature to provide a socket url for socket.io directly. Since i have done that change, i get that cookie error, but only if i go on the \"http\" URL(testing.productname.com) and not if i go to the \"real\" url (host.com:port) that my websockets use. That Fix is really dirty for userland and i would love to avoid it.\n. ",
    "twojcik": "@plievone agree, it would be very helpful :)\n. @plievone agree, it would be very helpful :)\n. ",
    "dhruvbhatia": "FYI, Node v0.80 is now out, which contains the zlib leak fix.\nhttp://blog.nodejs.org/2012/06/25/node-v0-8-0/\nhttps://github.com/joyent/node/issues/2504\n. FYI, Node v0.80 is now out, which contains the zlib leak fix.\nhttp://blog.nodejs.org/2012/06/25/node-v0-8-0/\nhttps://github.com/joyent/node/issues/2504\n. ",
    "mdlawson": "Judging by the fix for the VIM issue (watching for renamed files), I believe that there shouldn't be any problems, as currently the code watches all events. I tested with vim on windows, and everything worked ok there. \nSince chokidar works fine when passed an array of files, it was pretty simple to mirror the old API, but I do think the old API is quite clunky. I do think personally that the whole client configuration structure at the moment feels a bit constricting/odd, but I'm unsure exactly what to do about it. Perhaps exporting all configuration to an external JSON file would allow for a simpler configuration? Ill do a bit of experimenting. \n. I booted up a linux VM to test your issues with vim, and it turns out that the large number of change events are to do with vim making various temporary dot files and a copy of the file ending in ~. I have changed the regex in my code so these files are ignored. This fixes the full browser reloads and the copious change events.\nAs for the two errors you have seen, I wasn't able to reproduce them in testing. Hopefully they were connected to the vim issue. \n. Everything should be fixed now. Using the node path libraries \"extname\" allows for much simpler code, and doesn't cause problems with undefined paths. Any idea how to squash these commits down to one?\nI have tested with all file operations I can think of, moving, renaming, deleting, adding all work perfectly on windows, and css files are correctly identified in each case. \n. Thanks, I guess the only thing that bothers me is why the old implementation didn't cause this, surely the events would trigger in exactly the same way there.\n@owenb Really isn't the right place to put this, but I don't think its worth opening another issue. I guess this would be my ideal \"full\" configuration method, obviously each option would have sensible defaults so you would only have to configure as much as you wanted, and also the ability to define a base configuration for an app would probably be desirable if multiple clients are defined. It also addresses a \"flaw\" as I see it in the current views implementation, if it really must be used as the view engine (and currently it seems you must have a view here), Then it would be desirable to have multiple renderable views, and in this example, automatic routing is implied. Although you do target the framework at single page webapps, I think it would be nice to be able to handle multiple pages, as the whole structure of socketstream is so flexible I can see it being useful on all kinds of projects.\ncoffeescript\nss.client.define 'main', {\n    views:\n        root: \"/client/views/\"\n        pages:\n            index: \"app.jade\"\n            about: \"about.jade\"\n        layout: \"layout.jade\"\n        compile: require \"ss-jade\"\n        watch: true\n    code:\n        root: \"/client/code\"\n        libs: \"libs\"\n        paths: [\"app\"]\n        compile: require \"ss-coffee\"\n        watch: true\n    css:\n        root: \"/client/css\"\n        paths: [\"libs\",\"app.styl\"]\n        compile: require \"ss-stylus\"\n        watch: true\n    tmpl: \n        root: \"/client/tmpl\"\n        paths: [\"*\"]\n        compile: require \"ss-hogan\"\n        watch: true\n}\nAdmittedly I cant really see this somewhat lengthy configuration style being of much interest to you, given the current method. I guess I just wanted to throw it out there!\n. Not sure if you're still interested in this patch, but I've updated everything to match the latest socketstream and chokidar versions, and made the events less lazy. Seeing lots of issues about file watching, so it would be interesting to see how chokidar performs on Mac OS and linux. On windows so far it seems to work really well.\n. fixed, doh!\n. Well, I'll do some testing now, but from an initial scan though chokidar's code, and https://github.com/joyent/node/wiki/API-changes-between-v0.6-and-v0.8, I cant find any changes that should effect chokidar. It's possible that there are undocumented changes in the fs module regarding file watching, as it is in need of a clean up. \nEDIT:\nWell, I couldn't find any issues with live reload using node 0.7.12 on windows, latest socketstream from git. Unsure if 0.8 will have any changes over 0.7.12, couldn't find any builds. These results could be wrong, as I am just using the latest node.exe directly to run a project of mine (multiple versions of node on windows would be a pain)\n. Judging by the fix for the VIM issue (watching for renamed files), I believe that there shouldn't be any problems, as currently the code watches all events. I tested with vim on windows, and everything worked ok there. \nSince chokidar works fine when passed an array of files, it was pretty simple to mirror the old API, but I do think the old API is quite clunky. I do think personally that the whole client configuration structure at the moment feels a bit constricting/odd, but I'm unsure exactly what to do about it. Perhaps exporting all configuration to an external JSON file would allow for a simpler configuration? Ill do a bit of experimenting. \n. I booted up a linux VM to test your issues with vim, and it turns out that the large number of change events are to do with vim making various temporary dot files and a copy of the file ending in ~. I have changed the regex in my code so these files are ignored. This fixes the full browser reloads and the copious change events.\nAs for the two errors you have seen, I wasn't able to reproduce them in testing. Hopefully they were connected to the vim issue. \n. Everything should be fixed now. Using the node path libraries \"extname\" allows for much simpler code, and doesn't cause problems with undefined paths. Any idea how to squash these commits down to one?\nI have tested with all file operations I can think of, moving, renaming, deleting, adding all work perfectly on windows, and css files are correctly identified in each case. \n. Thanks, I guess the only thing that bothers me is why the old implementation didn't cause this, surely the events would trigger in exactly the same way there.\n@owenb Really isn't the right place to put this, but I don't think its worth opening another issue. I guess this would be my ideal \"full\" configuration method, obviously each option would have sensible defaults so you would only have to configure as much as you wanted, and also the ability to define a base configuration for an app would probably be desirable if multiple clients are defined. It also addresses a \"flaw\" as I see it in the current views implementation, if it really must be used as the view engine (and currently it seems you must have a view here), Then it would be desirable to have multiple renderable views, and in this example, automatic routing is implied. Although you do target the framework at single page webapps, I think it would be nice to be able to handle multiple pages, as the whole structure of socketstream is so flexible I can see it being useful on all kinds of projects.\ncoffeescript\nss.client.define 'main', {\n    views:\n        root: \"/client/views/\"\n        pages:\n            index: \"app.jade\"\n            about: \"about.jade\"\n        layout: \"layout.jade\"\n        compile: require \"ss-jade\"\n        watch: true\n    code:\n        root: \"/client/code\"\n        libs: \"libs\"\n        paths: [\"app\"]\n        compile: require \"ss-coffee\"\n        watch: true\n    css:\n        root: \"/client/css\"\n        paths: [\"libs\",\"app.styl\"]\n        compile: require \"ss-stylus\"\n        watch: true\n    tmpl: \n        root: \"/client/tmpl\"\n        paths: [\"*\"]\n        compile: require \"ss-hogan\"\n        watch: true\n}\nAdmittedly I cant really see this somewhat lengthy configuration style being of much interest to you, given the current method. I guess I just wanted to throw it out there!\n. Not sure if you're still interested in this patch, but I've updated everything to match the latest socketstream and chokidar versions, and made the events less lazy. Seeing lots of issues about file watching, so it would be interesting to see how chokidar performs on Mac OS and linux. On windows so far it seems to work really well.\n. fixed, doh!\n. Well, I'll do some testing now, but from an initial scan though chokidar's code, and https://github.com/joyent/node/wiki/API-changes-between-v0.6-and-v0.8, I cant find any changes that should effect chokidar. It's possible that there are undocumented changes in the fs module regarding file watching, as it is in need of a clean up. \nEDIT:\nWell, I couldn't find any issues with live reload using node 0.7.12 on windows, latest socketstream from git. Unsure if 0.8 will have any changes over 0.7.12, couldn't find any builds. These results could be wrong, as I am just using the latest node.exe directly to run a project of mine (multiple versions of node on windows would be a pain)\n. ",
    "madscoaducom": "Hi there.\nI have now tried out @CyberWalrus 's chokidar version in a scenario where I only change a Stylus file (client/css/app.styl), and I have a couple of observations:\nWhen saving change to app.styl it seems that iive_reload acts on both css and file change - and reloads browser instead of just reloading the css (as it did before).\nI have seen two different errors occur in socketstream app when saving a change:\n1) Error: ENOENT, no such file or directory '.....client/css/app.styl'\n2) TypeError: Object Error: ENOENT, lstat '.../client/css/4913' has no method 'split'\nMy setup is Ubuntu 10.4 (fully updated) with latest version of VIM, running node 0.6.15, and I am basically testing with the out-of-the-box demo app.\n. Hi @CyberWalrus, I tried out your new commit, and as you mention it fixes the browser reload.\nI can still provoke the two errors. I didn't have much time but had a brief look at your code and suspect that:\na) you need to guard against the path/filename returned by the watch event being empty (see http://nodejs.org/docs/latest/api/fs.html#fs_filename_argument).\nb) avoid using the filename/path when receiving an \"unlink\" event.\n. I am not sure how the socketstream team would like this done, but you could either use git rebase interactive (http://book.git-scm.com/4_interactive_rebasing.html) or create a new topic branch and merge your changes there and create a new pull request from that branch instead (probably the safest option).\nAs for the \"no such file\" exception (which I can still provoke) - I have investigated further, and it is happening in the css/stylus code compilation. The flow is that: watch sends an \"unlink\" event followed by a \"change\" event (because of VIM save flow). But the unlink event triggers the updateCSS action, which causes the browser to reload the css, causing the exception because the file is not yet in place (wonder if this race condition is related to the single threaded arch of node?) \nAny way, I will try to configure my VIM to work around this problem.\n. Hi Owen.\nNo worries, hadn't thought of that scenario. \nMads\n. Hi,\ncurrently trying to put together a test that can be used to help verify, both existing and proposed solutions.\nI will let you know how it goes.\nbr\nMads\n. Hi Owen.\nI have been doing some testing on @CyberWalrus latest patch. (My setup is still Ubuntu 10.4 + VIM). \nI used nodemon and kept VIM's default save mode (which creates a temp file before replacing the real file). In this setup I was not able to provoke errors related to the fie watching.\nI did occasionally get the race condition when the browser was reloading style sheet changes, but this is not different than in the existing solution. And for VIM this can be worked around changing the write mode:\n:set nowritebackup\nMore importantly, the file is still watched, so further changes gets picked up.\nSo for Ubuntu + VIM it is definitely an improvement.\nMads\n. Forgot to mention that I have tested it with node 0.6.19 and 0.8.0, both on Ubuntu 10.04\n. You're welcome. Let me know if I can help out in any way.\n. HI Owen,\nI know you are busy with the relase of 0.3. So this is just FYI, that I have made a pull request against apitree.js which if accepted will replace this pull request with an update of the apitree.js dependency instead. \nhttps://github.com/andreyvit/apitree.js/pull/1\nMads\n. Hi,\nAndrey has accepted the pull request and published a new version of apitree.js to npm (version 1.1.0).\nI will start testing that with the latest SocketStream code.\nI will close this pull-request, and open a new for an update of the apitree.js dependency when I have done some testing.\nMads\n. Thanks Owen.\n. Hi there.\nI have now tried out @CyberWalrus 's chokidar version in a scenario where I only change a Stylus file (client/css/app.styl), and I have a couple of observations:\nWhen saving change to app.styl it seems that iive_reload acts on both css and file change - and reloads browser instead of just reloading the css (as it did before).\nI have seen two different errors occur in socketstream app when saving a change:\n1) Error: ENOENT, no such file or directory '.....client/css/app.styl'\n2) TypeError: Object Error: ENOENT, lstat '.../client/css/4913' has no method 'split'\nMy setup is Ubuntu 10.4 (fully updated) with latest version of VIM, running node 0.6.15, and I am basically testing with the out-of-the-box demo app.\n. Hi @CyberWalrus, I tried out your new commit, and as you mention it fixes the browser reload.\nI can still provoke the two errors. I didn't have much time but had a brief look at your code and suspect that:\na) you need to guard against the path/filename returned by the watch event being empty (see http://nodejs.org/docs/latest/api/fs.html#fs_filename_argument).\nb) avoid using the filename/path when receiving an \"unlink\" event.\n. I am not sure how the socketstream team would like this done, but you could either use git rebase interactive (http://book.git-scm.com/4_interactive_rebasing.html) or create a new topic branch and merge your changes there and create a new pull request from that branch instead (probably the safest option).\nAs for the \"no such file\" exception (which I can still provoke) - I have investigated further, and it is happening in the css/stylus code compilation. The flow is that: watch sends an \"unlink\" event followed by a \"change\" event (because of VIM save flow). But the unlink event triggers the updateCSS action, which causes the browser to reload the css, causing the exception because the file is not yet in place (wonder if this race condition is related to the single threaded arch of node?) \nAny way, I will try to configure my VIM to work around this problem.\n. Hi Owen.\nNo worries, hadn't thought of that scenario. \nMads\n. Hi,\ncurrently trying to put together a test that can be used to help verify, both existing and proposed solutions.\nI will let you know how it goes.\nbr\nMads\n. Hi Owen.\nI have been doing some testing on @CyberWalrus latest patch. (My setup is still Ubuntu 10.4 + VIM). \nI used nodemon and kept VIM's default save mode (which creates a temp file before replacing the real file). In this setup I was not able to provoke errors related to the fie watching.\nI did occasionally get the race condition when the browser was reloading style sheet changes, but this is not different than in the existing solution. And for VIM this can be worked around changing the write mode:\n:set nowritebackup\nMore importantly, the file is still watched, so further changes gets picked up.\nSo for Ubuntu + VIM it is definitely an improvement.\nMads\n. Forgot to mention that I have tested it with node 0.6.19 and 0.8.0, both on Ubuntu 10.04\n. You're welcome. Let me know if I can help out in any way.\n. HI Owen,\nI know you are busy with the relase of 0.3. So this is just FYI, that I have made a pull request against apitree.js which if accepted will replace this pull request with an update of the apitree.js dependency instead. \nhttps://github.com/andreyvit/apitree.js/pull/1\nMads\n. Hi,\nAndrey has accepted the pull request and published a new version of apitree.js to npm (version 1.1.0).\nI will start testing that with the latest SocketStream code.\nI will close this pull-request, and open a new for an update of the apitree.js dependency when I have done some testing.\nMads\n. Thanks Owen.\n. ",
    "JasonMiesionczek": "I just cleaned out the RC1 code, and the project I created and started from scratch with RC2, get the same error :(\n. Hmm good point. I will move it outside of dropbox and give it a shot.\nThanks.\nOn May 5, 2012 2:31 PM, \"Owen Barnes\" \nreply@reply.github.com\nwrote:\n\nHmm how strange.\nI deleted my local repo and cloned it afresh from Github to see if there\nwas a error, but everything worked find - no problems. That's on OS X.\nThe only thing I can think is that you're running it from Dropbox. It\ncould be that the file watchers (which observe changes) are causing\nproblems with the Live Reload code which does the same.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/228#issuecomment-5529346\n. Yup, that was the issue. Works fine now. Thanks.\n. I did some more testing and discovered that the issue was due to the socketstream code itself being in the dropbox folder. I re-cloned RC2 to a local folder and created a new project in the dropbox folder and it works great. \n. I just cleaned out the RC1 code, and the project I created and started from scratch with RC2, get the same error :(\n. Hmm good point. I will move it outside of dropbox and give it a shot.\nThanks.\nOn May 5, 2012 2:31 PM, \"Owen Barnes\" \nreply@reply.github.com\nwrote:\nHmm how strange.\nI deleted my local repo and cloned it afresh from Github to see if there\nwas a error, but everything worked find - no problems. That's on OS X.\nThe only thing I can think is that you're running it from Dropbox. It\ncould be that the file watchers (which observe changes) are causing\nproblems with the Live Reload code which does the same.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/228#issuecomment-5529346\n. Yup, that was the issue. Works fine now. Thanks.\n. I did some more testing and discovered that the issue was due to the socketstream code itself being in the dropbox folder. I re-cloned RC2 to a local folder and created a new project in the dropbox folder and it works great. \n. \n",
    "ostera": "Haven't got a solution yet.\nBtw, nice presentation @ LNUG.\n. Hey guys, I just had the same problem while trying to do a conditional output. Could you please post the solution in here for future reference?\n. @americanyak\nIt's more like decoupling than removing.\n. @americanyak \nI'm not going to involve in a debate about word semantics, but it's clear that if a component is removed it's both not included and no longer supported, as in not part at all or completely replaced by some other component or whatnot.\nOn the other hand, decoupling is about letting a component be itself on its own, allowing it back again whenever one wants to plug it, yet providing the interface for many more custom, new, different or specific components to fill that same gap.\nDoes that make sense?\n. Fixed using node 0.8.8.\n. Oops, that didn't work at all. Any other way to hook up to the asset pipeline?\n. @paulbjensen I'm actually doing a little test on my local copy before doing a fork/pull-request\nI see how SS uses EventEmitter2 but I can't find a way to get to it from src/client/pack.coffee so I could do an events.emit(\"assets:js:packaged\") or a global events.emit(\"assets:packaged\"). A console.log ss from pack.coffee:~80 shows me no events object, thou if I add one after ss.start server I see an empty one.\nAny ideas? I'll keep researching.\n. Apparently the events object inside the ss object does provide an on function to bind a callback to events, as seen in the ss-console server but from a closer look to the socketstream.js file, it only works for \"registered modules\".\nNo idea what does that mean yet.\n. @owenb thanks for the heads up\nI'm currently trying to hack an eventemitter2 object into the socketstream.js exports so I can use it system wide (yes, there's one there already) but without any luck. Any hints on how to get a global working eventemitter2 object I can use to work this around now? If we just could emit and bind to events with a simple ss.events from anywhere, that would be useful.\n. Of course, api.add. Gotcha.\nFor the folks who wanna try this, below the var events = exports.events = new EventEmitter2(); line in the clients/pack file, just add an api.add(\"events\",events); and you'll be ready to ss.events.emit from wherever you want.\nI just forked to add some events for the assets packaging since that's what I'm needing right now, so feel free to take a look.\nJust remember, bind anything you need before ss.start server-\n. This is coming in 0.4 alongside other server-side events such as the ones I asked for in issue #291.\n. Haven't got a solution yet.\nBtw, nice presentation @ LNUG.\n. Hey guys, I just had the same problem while trying to do a conditional output. Could you please post the solution in here for future reference?\n. @americanyak\nIt's more like decoupling than removing.\n. @americanyak \nI'm not going to involve in a debate about word semantics, but it's clear that if a component is removed it's both not included and no longer supported, as in not part at all or completely replaced by some other component or whatnot.\nOn the other hand, decoupling is about letting a component be itself on its own, allowing it back again whenever one wants to plug it, yet providing the interface for many more custom, new, different or specific components to fill that same gap.\nDoes that make sense?\n. Fixed using node 0.8.8.\n. Oops, that didn't work at all. Any other way to hook up to the asset pipeline?\n. @paulbjensen I'm actually doing a little test on my local copy before doing a fork/pull-request\nI see how SS uses EventEmitter2 but I can't find a way to get to it from src/client/pack.coffee so I could do an events.emit(\"assets:js:packaged\") or a global events.emit(\"assets:packaged\"). A console.log ss from pack.coffee:~80 shows me no events object, thou if I add one after ss.start server I see an empty one.\nAny ideas? I'll keep researching.\n. Apparently the events object inside the ss object does provide an on function to bind a callback to events, as seen in the ss-console server but from a closer look to the socketstream.js file, it only works for \"registered modules\".\nNo idea what does that mean yet.\n. @owenb thanks for the heads up\nI'm currently trying to hack an eventemitter2 object into the socketstream.js exports so I can use it system wide (yes, there's one there already) but without any luck. Any hints on how to get a global working eventemitter2 object I can use to work this around now? If we just could emit and bind to events with a simple ss.events from anywhere, that would be useful.\n. Of course, api.add. Gotcha.\nFor the folks who wanna try this, below the var events = exports.events = new EventEmitter2(); line in the clients/pack file, just add an api.add(\"events\",events); and you'll be ready to ss.events.emit from wherever you want.\nI just forked to add some events for the assets packaging since that's what I'm needing right now, so feel free to take a look.\nJust remember, bind anything you need before ss.start server-\n. This is coming in 0.4 alongside other server-side events such as the ones I asked for in issue #291.\n. ",
    "moiseevigor": "Hi there! ss-passport would be great to have. just add my +1 vote here.\n. Thanks Paul, let me know if I can help somehow, testing/porting. I've found a good app: https://github.com/lefnire/habitrpg\nIt is derby+passport, maybe may help somehow.\n. Hi Paul, thank you! I'm not that skilled with socketstream and nosql db to manage the db interactions, but will try to test strategies. \n. Hi there! ss-passport would be great to have. just add my +1 vote here.\n. Thanks Paul, let me know if I can help somehow, testing/porting. I've found a good app: https://github.com/lefnire/habitrpg\nIt is derby+passport, maybe may help somehow.\n. Hi Paul, thank you! I'm not that skilled with socketstream and nosql db to manage the db interactions, but will try to test strategies. \n. ",
    "hoqqanen": "I'm having the same problem as well while trying to output a variable as a div's id. Could you post the solution? Thanks.\n. I'm having the same problem as well while trying to output a variable as a div's id. Could you post the solution? Thanks.\n. ",
    "mrexroad": "same here. would love to know what was resolved over irc. \n. same here. would love to know what was resolved over irc. \n. ",
    "nisaacson": "Any updates on this? Using straight Jade all the way through would simplify things greatly. Using a mix of Jade and Hogan is messy and leads to these kinds of problems.\n. I ended up switching over the Blade templates https://github.com/bminer/node-blade. I have my 0.3 socketstream app set up to use express as described in the socketstream guide. Once express is set up you can use the blade provided middleware to serves the templates to the client where they are rendered.\n. Any updates on this? Using straight Jade all the way through would simplify things greatly. Using a mix of Jade and Hogan is messy and leads to these kinds of problems.\n. I ended up switching over the Blade templates https://github.com/bminer/node-blade. I have my 0.3 socketstream app set up to use express as described in the socketstream guide. Once express is set up you can use the blade provided middleware to serves the templates to the client where they are rendered.\n. ",
    "mtsr": "Hi Owen,\nThanks for the quick reply. I'm on linux (ubuntu 11.10 specifically).\nI'll see what exact changes trigger the problem and then try to minimally reproduce the issue.\n. If you link the patch, I'll try it.\nCurrently getting mostly enoent errors which I guess are due to temporary files from my ide (webstorm).\nOwen Barnes reply@reply.github.com wrote:\n\nCool, thank you.\nJust to let you know, we're likely going to be using a module soon to handle file change detection. See #227\nIt would be great if you could try that patch before I make the final decision to include it in 0.3.0\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/233#issuecomment-6078474\n. Hi Owen,\n\nThanks for the quick reply. I'm on linux (ubuntu 11.10 specifically).\nI'll see what exact changes trigger the problem and then try to minimally reproduce the issue.\n. If you link the patch, I'll try it.\nCurrently getting mostly enoent errors which I guess are due to temporary files from my ide (webstorm).\nOwen Barnes reply@reply.github.com wrote:\n\nCool, thank you.\nJust to let you know, we're likely going to be using a module soon to handle file change detection. See #227\nIt would be great if you could try that patch before I make the final decision to include it in 0.3.0\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/issues/233#issuecomment-6078474\n. \n",
    "dhruv-bhatia": "Excellent, thanks for the quick response Owen. I look forward to having the option to suppress the messages in the future. Thanks for all the great work thus far! :)\n. Excellent, thanks Owen - works like a charm. :)\n. Hey Owen,\nJust wanted to touch base and provide a follow up on my situation. This should benefit anyone else who wants to run SS under SSL:\nI managed to get SSL running within SS, however Node's SSL performance is very poor at the moment (the core team say SSL optimisations will only be addressed in v0.9.x). As such, I wouldn't recommend running SS as a HTTPS server. Instead, I'm using a SSL terminator (Stunnel) in front of my SS app (which is now just running in HTTP mode) to have HTTPS support on my web server. This works amazingly well and solves the SSL performance issues that Node faces.. benchmarking with blitz.io shows I can handle 10m+ hits a day, all with an average latency of <50ms on a single Linode VPS!\nHowever, I did notice an issue with using an SSL terminator in front of an SS app. Websockets completely dies within Safari/Mobile Safari due to a wss:// & ws:// mismatch error. Basically, an SSL terminator will typically forward :443 to :80, but won't pass wss:// to ws://. Safari doesn't like this, so any WS/RPC calls under this configuration won't actually fire.\nAfter some research, I found that the Socket IO guys added an option that actually fixes this, though it isn't flicked to the right option by default (see https://github.com/LearnBoost/socket.io/commit/6f2270add625e16744aeaf4d82f19a9be0a14ffa).\nAfter changing 'match origin protocol' from false to true within /node_modules/socketstream/node_modules/socket.io/lib/ the WS mismatch is rectified, and all browsers work as expected. So that's essentially how one can achieve production-grade SSL performance within an SS app.\nI know one of the goals is to keep SS quite agnostic as far as the transport mechanism goes, so I don't expect you to expose the match origin protocol option through the SS API, however I just wanted to provide my experiences as I'm sure many others will want to find a way to utilise SSL within their SS apps while still being able to handle large amounts of traffic. :)\n. I kind of resolved this by moving the logic that I wanted to call via both the client and node-cron to a separate node_module file (/node_modules/blah/blah.coffee).\nThis allows me to simply require the blah module and use it within both my app.coffee file (for node-cron) and my rpc files.\n. Updated RPC doc to reflect - see https://github.com/socketstream/socketstream/issues/307\n. You can configure SocketStream to only use XHR Polling by placing the following code within your app.js file:\njavascript\nss.ws.transport.use('socketio', {\n  client: {\n    transports: ['xhr-polling']\n  },\n  server: function(io){\n    io.set('log level', 4)\n  }\n});\n. Hey Owen,\nI noticed that Connect's Session middleware exposes a key option which allows you to override the default connect.sid cookie name, so I figured it may be useful to add this in as an option to SS too - see http://www.senchalabs.org/connect/middleware-session.html\nI did test the changes and everything works as expected, however if compatibility of future SS modules may be an issue then I'm happy to ignore this PR. :)\nCheers!\n. Excellent, thanks for the quick response Owen. I look forward to having the option to suppress the messages in the future. Thanks for all the great work thus far! :)\n. Excellent, thanks Owen - works like a charm. :)\n. Hey Owen,\nJust wanted to touch base and provide a follow up on my situation. This should benefit anyone else who wants to run SS under SSL:\nI managed to get SSL running within SS, however Node's SSL performance is very poor at the moment (the core team say SSL optimisations will only be addressed in v0.9.x). As such, I wouldn't recommend running SS as a HTTPS server. Instead, I'm using a SSL terminator (Stunnel) in front of my SS app (which is now just running in HTTP mode) to have HTTPS support on my web server. This works amazingly well and solves the SSL performance issues that Node faces.. benchmarking with blitz.io shows I can handle 10m+ hits a day, all with an average latency of <50ms on a single Linode VPS!\nHowever, I did notice an issue with using an SSL terminator in front of an SS app. Websockets completely dies within Safari/Mobile Safari due to a wss:// & ws:// mismatch error. Basically, an SSL terminator will typically forward :443 to :80, but won't pass wss:// to ws://. Safari doesn't like this, so any WS/RPC calls under this configuration won't actually fire.\nAfter some research, I found that the Socket IO guys added an option that actually fixes this, though it isn't flicked to the right option by default (see https://github.com/LearnBoost/socket.io/commit/6f2270add625e16744aeaf4d82f19a9be0a14ffa).\nAfter changing 'match origin protocol' from false to true within /node_modules/socketstream/node_modules/socket.io/lib/ the WS mismatch is rectified, and all browsers work as expected. So that's essentially how one can achieve production-grade SSL performance within an SS app.\nI know one of the goals is to keep SS quite agnostic as far as the transport mechanism goes, so I don't expect you to expose the match origin protocol option through the SS API, however I just wanted to provide my experiences as I'm sure many others will want to find a way to utilise SSL within their SS apps while still being able to handle large amounts of traffic. :)\n. I kind of resolved this by moving the logic that I wanted to call via both the client and node-cron to a separate node_module file (/node_modules/blah/blah.coffee).\nThis allows me to simply require the blah module and use it within both my app.coffee file (for node-cron) and my rpc files.\n. Updated RPC doc to reflect - see https://github.com/socketstream/socketstream/issues/307\n. You can configure SocketStream to only use XHR Polling by placing the following code within your app.js file:\njavascript\nss.ws.transport.use('socketio', {\n  client: {\n    transports: ['xhr-polling']\n  },\n  server: function(io){\n    io.set('log level', 4)\n  }\n});\n. Hey Owen,\nI noticed that Connect's Session middleware exposes a key option which allows you to override the default connect.sid cookie name, so I figured it may be useful to add this in as an option to SS too - see http://www.senchalabs.org/connect/middleware-session.html\nI did test the changes and everything works as expected, however if compatibility of future SS modules may be an issue then I'm happy to ignore this PR. :)\nCheers!\n. ",
    "matthiasg": "not sure about it breaking old apps, but it solves the following problem.\nlets say you define a client like this\n// Define a single-page client\nss.client.define('hello', {\n  view: 'hello.html',\n  css:  ['libs'],\n  code: ['libs'],\n  tmpl: '*'\n});\nwhich, by default, is available at \nhttp://localhost:3000/hello\nwhen opening the app with the browser everything is peachy. Also all sub-paths are forwarded to it. \nhttp://localhost:3000/hello/subpath\nNo lets say you want to add parameters to hello:\nhttp://localhost:3000/hello?name=matthias\nThis parameter would be used in the app's code on the client to initiate the application state to show Hello Matthias instead of showing a form asking for the name.\nThis is a standard way for us to define simple state and navigation transitions. This way we can have deep-linking into different pages within our HTML application and is very necessary.\nAs to the question of breaking down older apps, i am not sure since i have not tested any other apps, but looking at the code (which is lacking tests) i would say it behaves almost identically. It strips of all subpaths one by one looking for a matching route, it just starts with the parameters first.\nThat said, this is just a minimal patch. A decent patch should get this 'strategy' out of that area and make it a replacable plugin. That way a user could use crossroads or mapleTree or one of the other routing libraries...or is this already possible and i overlooked it ?\n. sure ... ss.client.define does not, but this does and is setup as default:\n// Serve this client on the root URL\nss.http.route('/myurl', function(req, res){\n  res.serveClient('hello');\n})\ni think routing is a replaceable strategy and the default as it is is fine (with the exception of not properly handling ? arguments).\nobviously users can use more complex routing mechanisms on the server, but maybe in these cases people dont use ss.http.route anyway and thus there is no direct need to make that replaceable since this is simply not used in these scenarios.\nOFFTOPIC: we have started porting a google closure based solution to ss and am quite pleased so far. great framework. we have jasmine based testing and client-side routes using crossroads and it all just works (After building up some sensible class structure into coffeescript (without fat-arrows etc)). We think even offline clients using CEF are easily possible by just 'downloading' the client html page and its links/scripts into a folder. \nIn other words: Keep it up, this is great :)\n. are you trying with or without my patch ?\nwhen i revert to the original code (will check commit hash later) i get my url /test?name=matthias not routed to /test. \n. when i use the original code (RC2) and setup app.js to route:\n// Serve this client on the root URL\nss.http.route('/ipad', function(req, res){\n  res.serveClient('sap-ipad');\n})\nand the call the following url:\n/ipad?accno=123&amp;test=234\ni get \nCannot GET /ipad?accno=123&amp;test=234\nWhich is what i would have expected looking at the routing code. Since it does a literal comparison first on the entire url and then pops segments of until reaching /.\nadding my three lines\nif url.indexOf '?' >= 0\n    sr = url.split('?')      \n  else\n    sr = url.split('/')\nfixes that since it removes the arguments at the end first when no literal match was found before. It then proceeds as before. Basically it just adds a single step to the pipeline.\n. i think i used rc2 , but checked out from github manually. the included readme shows 0.3 RC2 / 2012-05-04 as the top line though. thus i would presume it is rc2. did you test with a newer version ?\n. i just pulled the newest commit 1afeaef20ef338498e508d566b98a33d87b94519, but the problem remains ... (obviously since the code did not change)\nbut i see you are using 'serve' not 'serveClient' as written in the tour or docs. But the behaviour to me is identical.\nare you sure you did not setup a default route to test somewhere ?\n. thanks.... I have finished my review of socketstream and it is well-designed. a number of tests could be added, but it seems pragmatic.\nwe are actively porting a number of our apps to socketstream and are making good progress. \nwe have previously shied away from using any kind of framework since they would dictate to much structure to the application. socketstream on the other hand, delivers the same necessary overhead previously done offline (compiling etc) while getting out of the way when it comes to the structure.\n. this is indeed annoying. \nclosely related is a problem is the too many files error in any decent sized project.\nOne easily reaches the EFILE error. For now we could not yet get ulimit on MacOS Lion to work properly. We managed to increase it to 12288 files, but EFILE errors still appear. Basically we can only use production mode and no nodemon on MacOS right now.\n. works great ...\n. i am having a similar issue. I understand that rpc calls are after HTTP has already taken place. But right now I am looking for the cleanest way to get the user locale from the original call. Now each client is bound to a session. this session gets initiated somewhere through a websocket. but the INITIAL http call which is then upgraded should still be accessible somewhere. and in this initial call it would be great to have access to the original HTTP request as well as the corresponding session in order to transfer knowledge of the http headers into the session.\nany ideas ?\n. not sure about it breaking old apps, but it solves the following problem.\nlets say you define a client like this\n// Define a single-page client\nss.client.define('hello', {\n  view: 'hello.html',\n  css:  ['libs'],\n  code: ['libs'],\n  tmpl: '*'\n});\nwhich, by default, is available at \nhttp://localhost:3000/hello\nwhen opening the app with the browser everything is peachy. Also all sub-paths are forwarded to it. \nhttp://localhost:3000/hello/subpath\nNo lets say you want to add parameters to hello:\nhttp://localhost:3000/hello?name=matthias\nThis parameter would be used in the app's code on the client to initiate the application state to show Hello Matthias instead of showing a form asking for the name.\nThis is a standard way for us to define simple state and navigation transitions. This way we can have deep-linking into different pages within our HTML application and is very necessary.\nAs to the question of breaking down older apps, i am not sure since i have not tested any other apps, but looking at the code (which is lacking tests) i would say it behaves almost identically. It strips of all subpaths one by one looking for a matching route, it just starts with the parameters first.\nThat said, this is just a minimal patch. A decent patch should get this 'strategy' out of that area and make it a replacable plugin. That way a user could use crossroads or mapleTree or one of the other routing libraries...or is this already possible and i overlooked it ?\n. sure ... ss.client.define does not, but this does and is setup as default:\n// Serve this client on the root URL\nss.http.route('/myurl', function(req, res){\n  res.serveClient('hello');\n})\ni think routing is a replaceable strategy and the default as it is is fine (with the exception of not properly handling ? arguments).\nobviously users can use more complex routing mechanisms on the server, but maybe in these cases people dont use ss.http.route anyway and thus there is no direct need to make that replaceable since this is simply not used in these scenarios.\nOFFTOPIC: we have started porting a google closure based solution to ss and am quite pleased so far. great framework. we have jasmine based testing and client-side routes using crossroads and it all just works (After building up some sensible class structure into coffeescript (without fat-arrows etc)). We think even offline clients using CEF are easily possible by just 'downloading' the client html page and its links/scripts into a folder. \nIn other words: Keep it up, this is great :)\n. are you trying with or without my patch ?\nwhen i revert to the original code (will check commit hash later) i get my url /test?name=matthias not routed to /test. \n. when i use the original code (RC2) and setup app.js to route:\n// Serve this client on the root URL\nss.http.route('/ipad', function(req, res){\n  res.serveClient('sap-ipad');\n})\nand the call the following url:\n/ipad?accno=123&amp;test=234\ni get \nCannot GET /ipad?accno=123&amp;test=234\nWhich is what i would have expected looking at the routing code. Since it does a literal comparison first on the entire url and then pops segments of until reaching /.\nadding my three lines\nif url.indexOf '?' >= 0\n    sr = url.split('?')      \n  else\n    sr = url.split('/')\nfixes that since it removes the arguments at the end first when no literal match was found before. It then proceeds as before. Basically it just adds a single step to the pipeline.\n. i think i used rc2 , but checked out from github manually. the included readme shows 0.3 RC2 / 2012-05-04 as the top line though. thus i would presume it is rc2. did you test with a newer version ?\n. i just pulled the newest commit 1afeaef20ef338498e508d566b98a33d87b94519, but the problem remains ... (obviously since the code did not change)\nbut i see you are using 'serve' not 'serveClient' as written in the tour or docs. But the behaviour to me is identical.\nare you sure you did not setup a default route to test somewhere ?\n. thanks.... I have finished my review of socketstream and it is well-designed. a number of tests could be added, but it seems pragmatic.\nwe are actively porting a number of our apps to socketstream and are making good progress. \nwe have previously shied away from using any kind of framework since they would dictate to much structure to the application. socketstream on the other hand, delivers the same necessary overhead previously done offline (compiling etc) while getting out of the way when it comes to the structure.\n. this is indeed annoying. \nclosely related is a problem is the too many files error in any decent sized project.\nOne easily reaches the EFILE error. For now we could not yet get ulimit on MacOS Lion to work properly. We managed to increase it to 12288 files, but EFILE errors still appear. Basically we can only use production mode and no nodemon on MacOS right now.\n. works great ...\n. i am having a similar issue. I understand that rpc calls are after HTTP has already taken place. But right now I am looking for the cleanest way to get the user locale from the original call. Now each client is bound to a session. this session gets initiated somewhere through a websocket. but the INITIAL http call which is then upgraded should still be accessible somewhere. and in this initial call it would be great to have access to the original HTTP request as well as the corresponding session in order to transfer knowledge of the http headers into the session.\nany ideas ?\n. ",
    "timothyjoelwright": "Thanks for your feedback. To respect your preferences for minimal code complexity and performance impact, I'll remove the event emitter and look for the best places to add generic subscribe/unsubscribe function calls to the transport instead. I plan on using this in production for a non-critical project, so any testing you'll be able to offer with the finished module is appreciated!\n. @Owen\nI've been thinking more about this recently as well. We had decided to be adventurous and use SocketStream for several projects instead of our usual stack. All of these projects require some kind of inter-client communication. The increasing popularity of PubNub and Pusher reinforce that this is a feature that's often at the center of many types of apps. If you decide to remove it, would you stick with a modular approach or would we each write our own app-specific sub/sub implementation? A modular transport-type approach would open up to a lot of options beyond redis: RabbitMQ, AMQP, possibly ZeroMQ/crossroads.IO again.\nAs a side note we ran load tests with both PubNub, Pusher, and the current SocketStream pub/sub redis implementation. We decided that Pusher and PubNub weren't necessary options since SocketStream managed the loads within 98% of the best performing option (PubNub). The only benefit that any of these services would offer over a standard non-SS app stack with SocketIO would be the decoupling of the event bus from a specific server (At the expense of 2-5x that of hosting the app itself).\n. Ahh ok - I see the direction you're referring to. Let me know if I can be of any help with testing / implementation / etc!\n. Thanks for your feedback. To respect your preferences for minimal code complexity and performance impact, I'll remove the event emitter and look for the best places to add generic subscribe/unsubscribe function calls to the transport instead. I plan on using this in production for a non-critical project, so any testing you'll be able to offer with the finished module is appreciated!\n. @Owen\nI've been thinking more about this recently as well. We had decided to be adventurous and use SocketStream for several projects instead of our usual stack. All of these projects require some kind of inter-client communication. The increasing popularity of PubNub and Pusher reinforce that this is a feature that's often at the center of many types of apps. If you decide to remove it, would you stick with a modular approach or would we each write our own app-specific sub/sub implementation? A modular transport-type approach would open up to a lot of options beyond redis: RabbitMQ, AMQP, possibly ZeroMQ/crossroads.IO again.\nAs a side note we ran load tests with both PubNub, Pusher, and the current SocketStream pub/sub redis implementation. We decided that Pusher and PubNub weren't necessary options since SocketStream managed the loads within 98% of the best performing option (PubNub). The only benefit that any of these services would offer over a standard non-SS app stack with SocketIO would be the decoupling of the event bus from a specific server (At the expense of 2-5x that of hosting the app itself).\n. Ahh ok - I see the direction you're referring to. Let me know if I can be of any help with testing / implementation / etc!\n. ",
    "floating": "Hey haohello, \nYes you can, there are some things to watch out for though. Depending on the platform PhoneGap has some issues with Socket.io due to local files being loaded with the file:// protocol. I think PhoneGap is working on a universal fix for this but I don't expect it to happen very soon. You will get this error: Origin null is not allowed by Access-Control-Allow-Origin. \nYou can work around this by changing the window location so that you're not loading your index file locally. Just make sure to add the phonegap js file to your client-side libs.\n. @dhruv-bhatia thanks very much for this write up :)\n. Hey haohello, \nYes you can, there are some things to watch out for though. Depending on the platform PhoneGap has some issues with Socket.io due to local files being loaded with the file:// protocol. I think PhoneGap is working on a universal fix for this but I don't expect it to happen very soon. You will get this error: Origin null is not allowed by Access-Control-Allow-Origin. \nYou can work around this by changing the window location so that you're not loading your index file locally. Just make sure to add the phonegap js file to your client-side libs.\n. @dhruv-bhatia thanks very much for this write up :)\n. ",
    "yiwang": "Glab to hear Owen are on this, really wish 0.4 come out soon!\nApache Cordova 2.0 comes with command line tools which shall simplifies setup a lot.\nOn Android, change the URL part super.loadUrl(\"file:///android_asset/www/index.html\"); in the main Java file to http://remote_server/cordova_app will load the remote socketstream app (with cordova.js at client/code). And it seems works  just like point webkit browser (with Cordova enhancement) to a remote URL.\nBut when I try to keep the initial index.html loadUrl(\"file://\") from local and change window.location=\"http://remote_server/cordova_app\" in www/index.html\nI got behavior like gap_poll [https://www.google.com/#q=gap_poll] for SS app.\n. Glab to hear Owen are on this, really wish 0.4 come out soon!\nApache Cordova 2.0 comes with command line tools which shall simplifies setup a lot.\nOn Android, change the URL part super.loadUrl(\"file:///android_asset/www/index.html\"); in the main Java file to http://remote_server/cordova_app will load the remote socketstream app (with cordova.js at client/code). And it seems works  just like point webkit browser (with Cordova enhancement) to a remote URL.\nBut when I try to keep the initial index.html loadUrl(\"file://\") from local and change window.location=\"http://remote_server/cordova_app\" in www/index.html\nI got behavior like gap_poll [https://www.google.com/#q=gap_poll] for SS app.\n. ",
    "jgcartland": "Thanks for the quick reply. (And many thanks for socketstream!)\nSo much to learn, moving from LAMP, and npm just moved further up the list.\n. Thanks for the quick reply. (And many thanks for socketstream!)\nSo much to learn, moving from LAMP, and npm just moved further up the list.\n. ",
    "jcrugzz": "No problem man, keep up the good work. I plan to help out when I can. \n. No problem man, keep up the good work. I plan to help out when I can. \n. ",
    "joustava": "Aarg, nevermind.\nN e e d  t o  require('should')  s o m e w h e r e.\nAlthough it is not that obvious from the doc.\n. Aarg, nevermind.\nN e e d  t o  require('should')  s o m e w h e r e.\nAlthough it is not that obvious from the doc.\n. ",
    "hathvi": "This is intentional. Any files starting with an underscore, period, or that end with a tilde are considered hidden\nSee https://github.com/socketstream/socketstream/blob/master/lib/utils/file.js#L10\n. Never mind.. There's an option to disable auto connect in Socket.IO. /facepalm\n. It would be nice if we could just define arguments that get passed into entry.js\nThe client definition could look something like this\n``` javascript\nss.client.define('main', {\n  view: 'app.html',\n  css: [ 'app.less' ],\n  code: [ 'libs', 'app' ],\n  onEvent: function(req, res) {\n    var config = {\n      facebookAppID: config.get('facebookApplicationID')\n    };\nres(config, req.session.userId);\n\n}\n});\n```\nWhile entry.js looks like this\n``` javascript\nmodule.exports = function(ss, config, userId) {\n  // config.facebookAppID == '1251251251251235';\n  // userId == '511ee60fc404a93c0a00000e'\nss.server.on('ready', function() {\n    // ...\n  });\n};\n```\n. Thanks Owen. While this works, closed issue #298 that was created a while back for Socket.IO is now an issue again. clientIp with a reverse proxy is undefined\n. +1 for this, this feature would be nice\n. This is intentional. Any files starting with an underscore, period, or that end with a tilde are considered hidden\nSee https://github.com/socketstream/socketstream/blob/master/lib/utils/file.js#L10\n. Never mind.. There's an option to disable auto connect in Socket.IO. /facepalm\n. It would be nice if we could just define arguments that get passed into entry.js\nThe client definition could look something like this\n``` javascript\nss.client.define('main', {\n  view: 'app.html',\n  css: [ 'app.less' ],\n  code: [ 'libs', 'app' ],\n  onEvent: function(req, res) {\n    var config = {\n      facebookAppID: config.get('facebookApplicationID')\n    };\nres(config, req.session.userId);\n\n}\n});\n```\nWhile entry.js looks like this\n``` javascript\nmodule.exports = function(ss, config, userId) {\n  // config.facebookAppID == '1251251251251235';\n  // userId == '511ee60fc404a93c0a00000e'\nss.server.on('ready', function() {\n    // ...\n  });\n};\n```\n. Thanks Owen. While this works, closed issue #298 that was created a while back for Socket.IO is now an issue again. clientIp with a reverse proxy is undefined\n. +1 for this, this feature would be nice\n. ",
    "salemgolemugoo": "Thanks!\n. Thanks!\n. ",
    "wiber": "Thanks for the quick reply, \nNo it's not running locally, willsave.me is a self hosted node service. Page renders, but without css and without functions. from your reply I take it it's just me. \nThanks,\nElias\n. Thanks for the quick reply, \nNo it's not running locally, willsave.me is a self hosted node service. Page renders, but without css and without functions. from your reply I take it it's just me. \nThanks,\nElias\n. ",
    "orefalo": "Thank you for the prompt reply Owenb. This is indeed unfortunate.\nWhat would be the best way to send binary over a WS using SS ?\n. Files in chunks - will have a look at the API\nInteresting, I though SocketSteam could use either SockJS or socket.io\n. ok, regarding SockJS - looks like it's not supported https://github.com/sockjs/sockjs-protocol/issues/30\nWill look into socket.io further.\ncheers,\n. Thanks for sharing all these excellent pointers.\n. 1. will do\n2. even better ;-)\n. sorry about that, I feel the pain - it took me several steps to get the indentation right.\n. Ouaou, no doupts, it way easier than editing a wiki page :-/\nHave a look at the playframework repo, https://github.com/playframework/Play20,  https://github.com/playframework/Play20/wiki\nthe github wiki is cloned and bundled at build time in the distribution. You get the best of both words.\n. What's really interesting, is to see how many people contribute to the wiki... \nhttps://github.com/playframework/Play20/wiki/_history\nMost of these people are not official contributors\n. when you create a sample app with \"socketstream create something\"\nthe client hierarchy is\nclient/code/app/app.js\n/app.js\nIt's just too many files/folders with the same name. As a beginner it's hard to understand what a require('/app'); does.\nyou could maybe rename client/code/app/app.js to client/code/app/client_app.js to make it clear.\njust pointing out the issues I found learning the framework.\n. Would you accept a pull req ?\n. client.js\nand then require(\"/client\") from entry.js\n. Thank you for the prompt reply Owenb. This is indeed unfortunate.\nWhat would be the best way to send binary over a WS using SS ?\n. Files in chunks - will have a look at the API\nInteresting, I though SocketSteam could use either SockJS or socket.io\n. ok, regarding SockJS - looks like it's not supported https://github.com/sockjs/sockjs-protocol/issues/30\nWill look into socket.io further.\ncheers,\n. Thanks for sharing all these excellent pointers.\n. 1. will do\n2. even better ;-)\n. sorry about that, I feel the pain - it took me several steps to get the indentation right.\n. Ouaou, no doupts, it way easier than editing a wiki page :-/\nHave a look at the playframework repo, https://github.com/playframework/Play20,  https://github.com/playframework/Play20/wiki\nthe github wiki is cloned and bundled at build time in the distribution. You get the best of both words.\n. What's really interesting, is to see how many people contribute to the wiki... \nhttps://github.com/playframework/Play20/wiki/_history\nMost of these people are not official contributors\n. when you create a sample app with \"socketstream create something\"\nthe client hierarchy is\nclient/code/app/app.js\n/app.js\nIt's just too many files/folders with the same name. As a beginner it's hard to understand what a require('/app'); does.\nyou could maybe rename client/code/app/app.js to client/code/app/client_app.js to make it clear.\njust pointing out the issues I found learning the framework.\n. Would you accept a pull req ?\n. client.js\nand then require(\"/client\") from entry.js\n. ",
    "mooglin": "Has there been any progress on uploading binary data via ws within the context of SocketStream? Trying to have the ss req object tied to upload. Thanks for any updates. \n. @strikeout Could you look at #423 and possibly share the code you're using? Thanks!\n. @drauschenbach So do you think switching the transport to use sock.js would solve the problem? \nss.ws.transport.use(require('ss-sockjs')); \n. @drauschenbach  I tell phonegap to pull from a remote url as well, but I still hit this problem. You're using socketstream/phonegap and are getting session cookies persist between full app restarts?\n. @drauschenbach Ok, I guess I will look into sock.js and see if that solves the issue. @paulbjensen If you come across any details that would help please pass them along. Thanks!\n. Simply switching to sock.js did not change anything. I will keep looking into it, thanks for any help.\n. Ah, great, should've thought to look in the ss-engine repo. I can likely figure out the filenames using the cdn prefixing. \nMy reasoning is to try to automate an asset packer to go between serving remotely in development to packing locally in PhoneGap.\n. My biggest problem now is that I get \"Unable to obtain session ID\" when trying to connect to the remote server from file://myproject/index.html. Have you seen this error before?\n. PhoneGap apps just run as file directories, like opening index.html in your browser from the file system.\n. Has there been any progress on uploading binary data via ws within the context of SocketStream? Trying to have the ss req object tied to upload. Thanks for any updates. \n. @strikeout Could you look at #423 and possibly share the code you're using? Thanks!\n. @drauschenbach So do you think switching the transport to use sock.js would solve the problem? \nss.ws.transport.use(require('ss-sockjs')); \n. @drauschenbach  I tell phonegap to pull from a remote url as well, but I still hit this problem. You're using socketstream/phonegap and are getting session cookies persist between full app restarts?\n. @drauschenbach Ok, I guess I will look into sock.js and see if that solves the issue. @paulbjensen If you come across any details that would help please pass them along. Thanks!\n. Simply switching to sock.js did not change anything. I will keep looking into it, thanks for any help.\n. Ah, great, should've thought to look in the ss-engine repo. I can likely figure out the filenames using the cdn prefixing. \nMy reasoning is to try to automate an asset packer to go between serving remotely in development to packing locally in PhoneGap.\n. My biggest problem now is that I get \"Unable to obtain session ID\" when trying to connect to the remote server from file://myproject/index.html. Have you seen this error before?\n. PhoneGap apps just run as file directories, like opening index.html in your browser from the file system.\n. ",
    "paulmillr": "should be ok on linux, works ok (<1% CPU) on mac. 0.4 is stable because it uses fs polling, when 0.3 is windows-fast because it uses ReadDirectoryChanges. I don't think you can easily have both of them, likely it's a shitty node fs win32 implementation problem. but I'll see what I can do.\nIssues that were fixed with switch to polling fs: paulmillr/chokidar#11, paulmillr/chokidar#7\n. actually it worksforme. Just tested it on windows, 0% of cpu load. perhaps something wrong with your configuration.\ni'm using node 0.8.4\n. it's all here.\ntl;dr 0.3 uses fs.watch on windows, 0.4 uses fs.watchFile. watchFile polls filesystem every 100ms for changes when watch uses some internal badass api to get changes without polling, when they happen or something like that.\nwhereas the watch idea is obviously better, node.js made its api very horrible, not mentioning A LOT of bugs inside (you can even now search nodejs bugtracker and see many open watch bugs). watchFile appeared on windows only with nodejs 0.8, so it can be unperformant / not polished on some configs etc.\n. what do you use for testing cpu load in this case? I installed socketstream 0.3.0, created new proj and did node app.js\n. On mac it's 10% for 1070 files / 41% for 4280 files (which is still only \u2155 of my macbook's cpu time). Still a lot of space for improvement of win ver, I guess.\n. i'll definitely try again to switch to watch, but as i've said this cannot be done until nodejs will fix its 10+ bugs. stability > performance.\n. I have an idea: what happens if you change options.interval in chokidar source code from 100 to ~300-500 (ms) etc?\n. I propose to keep 0.4.0 because\n1. Performance problems on the stuff on windows exist partially because of shitty node fs win32 optimization.\n2. Noone +1-d these performance problems.\n3. Again, 0.4 is much more reliable, especially on windows.\n. @drosen0 \n\nwhat happens if you change options.interval in chokidar source code from 100 to ~300-500 (ms) etc?\n. guys, I have an idea: what do you think about adding a chokidar option that will increase interval for some type of files (images etc) and then test how it\u2019ll work out?\n\nhttps://github.com/paulmillr/chokidar/issues/29\n. Okay guys, I implemented this. Chokidar (on master) now allows to pass binaryInterval option.\nPlease try to set this to e.g. 1000 and post if there were any changes.\n. chokidar 0.5 was released.\n. You can also use usePolling: false chokidar option, pretty sure CPU will be very low with that (though it is unreliable as uses fs.watch).\n. Gaze is not needed. Chokidar has all the needed fixes. I can't reproduce the issue.\n. should be ok on linux, works ok (<1% CPU) on mac. 0.4 is stable because it uses fs polling, when 0.3 is windows-fast because it uses ReadDirectoryChanges. I don't think you can easily have both of them, likely it's a shitty node fs win32 implementation problem. but I'll see what I can do.\nIssues that were fixed with switch to polling fs: paulmillr/chokidar#11, paulmillr/chokidar#7\n. actually it worksforme. Just tested it on windows, 0% of cpu load. perhaps something wrong with your configuration.\ni'm using node 0.8.4\n. it's all here.\ntl;dr 0.3 uses fs.watch on windows, 0.4 uses fs.watchFile. watchFile polls filesystem every 100ms for changes when watch uses some internal badass api to get changes without polling, when they happen or something like that.\nwhereas the watch idea is obviously better, node.js made its api very horrible, not mentioning A LOT of bugs inside (you can even now search nodejs bugtracker and see many open watch bugs). watchFile appeared on windows only with nodejs 0.8, so it can be unperformant / not polished on some configs etc.\n. what do you use for testing cpu load in this case? I installed socketstream 0.3.0, created new proj and did node app.js\n. On mac it's 10% for 1070 files / 41% for 4280 files (which is still only \u2155 of my macbook's cpu time). Still a lot of space for improvement of win ver, I guess.\n. i'll definitely try again to switch to watch, but as i've said this cannot be done until nodejs will fix its 10+ bugs. stability > performance.\n. I have an idea: what happens if you change options.interval in chokidar source code from 100 to ~300-500 (ms) etc?\n. I propose to keep 0.4.0 because\n1. Performance problems on the stuff on windows exist partially because of shitty node fs win32 optimization.\n2. Noone +1-d these performance problems.\n3. Again, 0.4 is much more reliable, especially on windows.\n. @drosen0 \n\nwhat happens if you change options.interval in chokidar source code from 100 to ~300-500 (ms) etc?\n. guys, I have an idea: what do you think about adding a chokidar option that will increase interval for some type of files (images etc) and then test how it\u2019ll work out?\n\nhttps://github.com/paulmillr/chokidar/issues/29\n. Okay guys, I implemented this. Chokidar (on master) now allows to pass binaryInterval option.\nPlease try to set this to e.g. 1000 and post if there were any changes.\n. chokidar 0.5 was released.\n. You can also use usePolling: false chokidar option, pretty sure CPU will be very low with that (though it is unreliable as uses fs.watch).\n. Gaze is not needed. Chokidar has all the needed fixes. I can't reproduce the issue.\n. ",
    "polidore": "This doesn't happen for me on win7 64bit.\n. OK. i don't have that many files, so i may in fact have the problem.  i'll\ntry to test it if i get a chance.\nOn Wed, Aug 22, 2012 at 12:47 PM, David Rosen notifications@github.comwrote:\n\n@polidore https://github.com/polidore I'd be interested to know whether\nthe difference is due to the 64-bit vs 32-bit versions. Just to be sure,\nhave you tried with a large number of watched files? I tested using a new\nSS project, making 512 copies of app.styl, and @paulmillrhttps://github.com/paulmillrtested using 4280 files.\nWhen I get a chance, I'll test this on my wife's iMac which has nearly\nidentical hardware specs to my 4-year-old laptop. I'll also give the\noptions.interval change a test when I get a chance.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/270#issuecomment-7940788.\n. This is fixed.\n. i'll take a look at it monday.\n\nOn Thu, Aug 23, 2012 at 8:04 AM, Owen Barnes notifications@github.comwrote:\n\nI agree. Good point.\nIf you fancy having a crack at this I'd gladly merge it in; otherwise I'll\nadd it to the TODO list.\nBasically we need to change the logic here:\nhttps://github.com/socketstream/socketstream/blob/master/src/http/index.coffee#L92\nso that we parse the URL request, isolate the extension, and pass every\nrequest to the static handler (by calling next()) if it is for a .jpeg,\n.png, etc.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/286#issuecomment-7967423.\n. nice work!\n\nOn Tue, Dec 31, 2013 at 7:19 AM, Paul Jensen notifications@github.comwrote:\n\nClosed #286 https://github.com/socketstream/socketstream/issues/286.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/286\n.\n. Hey, Paul, thanks for the response.  I don't want to connect these two systems at the moment.  \n\nThe issue is not with max age since a normal cookie is generated with my setting of 24hours.  The issue is the way socketstream / connect is handling an invalid connect.sid cookie.\n. I'm going to open a simpler issue here.\n. Hello, Ownen.  Thanks for putting out 0.3.4.\nss-angular is really two projects in one:\n1. It is a client side wrapper of the socketstream apis to angular services.  This allows you to use socketstream rpc and pubsub to update angular models.\n2. It is a one-way (server to client) model synching request responder.  That is, I am using your request responder API to create an entry point for business logic that generates model data.  It allows the client to subscribe to a given model with a \"where clause\", and it keeps track of active requests and polls the business logic for updates.\nI hope this helps you understand it a bit better.   I'm definitely interested in migrating it to 0.4-- to be honest, I build it for my own use and it is not that pretty, so I would think of 0.4 as an opportunity to make it a bit more user-focused.\n. Hey, paul.  Sorry about the tone of the issue above.  I didn't mean to come off as I think I did! \nAnyway, I changed the code to use the HTTP header to get the session instead of sending it over the websocket.  I'm not very experienced in this area, so take a look and see what you think-- you may want to adjust it a bit, but I think this is a better way to do it in general. \nthanks again!\n. If you want to test it, just blow away your sessions in redis / mongo while your connected to your app and refresh.  Prior to this change, you'd hit the exception here without fail:\nhttps://github.com/socketstream/socketstream/blob/master/src/websocket/transports/engineio/wrapper.js#L24\n. Hey any thoughts on this?  I've been using it for a while without issue.\n. sounds great. thanks.\nOn Mon, Mar 25, 2013 at 2:20 PM, Owen Barnes notifications@github.comwrote:\n\nHey Ben\nApologies, I've been so engrossed in 0.4 development these last few weeks\nI've not been spending as much time on 0.3 issues as I should.\nYour patch looks good, but I'm always ultra-cautious when it comes to\nchanging things like this as inevitably it will break something none of us\nhave considered.\nAs soon as I get chance I'll try it out myself and think hard about\nanything which could go wrong. If all looks good I'll merge it in.\nAlso, I'll be in touch shortly regarding Angular integration in 0.4. I\nthink I'm onto something pretty good but want to advance it a bit more\nbefore showing you.\nCheers,\nOwen\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/359#issuecomment-15411159\n.\n. I think #1 works as long as you suppress the httpOnly flag set by connect\non expiring cookies.\nOn Mar 30, 2013 10:16 AM, \"Owen Barnes\" notifications@github.com wrote:\nHi Ben\nI'm working on Sessions support in 0.4 today and I've started thinking\nabout the two approaches here.\n1. The client-side JS reads the session cookie and sends it over the\n   WS (what we have today in 0.3)\n2. We try to obtain the session id server-side by looking at the HTTP\n   headers (what we used to have in socket.io)\nWhile I agree 2 is more reliable if the transport supports it (last time I\nchecked, SockJS doesn't), it has a big problem: it requires the client to\nbe running in a browser.\nThe latest version of 0.4 (which I will push within the next week) has\nseparate modules for the client and server 'realtime' components. Best of\nall, the client can run anywhere - on the browser, or in another Node\nprocess. Thus there is no longer any need for ss-console as you can simple\nconnect to the server using the same client library and use a REPL to\ninvoke RPC commands etc.\nAll this works great already - without sessions support. Figuring out how\nto add this is the hard part.\nI'm going to do some experimenting with ideas today and let you know.\nIdeally I'd like to find a secure and reliable way to do method 1 properly,\neven if cookies expire or don't exist at all.\nOwen\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/359#issuecomment-15675182\n.\n. Yes, thank you.\nOn Sep 28, 2013 7:23 AM, \"Paul Jensen\" notifications@github.com wrote:\nHi,\nWas this issue resolved by the work on the Websockets (#397https://github.com/socketstream/socketstream/pull/397\n)?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/359#issuecomment-25296382\n.\n. Thanks, Strikeout.  Interesting approach, but I use a level7 load balancer that looks at cookie info.\n. I think it's fine, but do you know how to disable httpOnly from connect\nwithout patching it? It didn't seem obvious to me.\n\nMay also make sense to look in header for cookie as a backup if don't\nreceive it in socket.\nOn Apr 14, 2013 9:53 AM, \"Owen Barnes\" notifications@github.com wrote:\n\nHey Ben\nI've had chance to test this and I can confirm it works well. However, I'm\na bit reluctant to merge this in, now that I know 0.4 will not work this\nway.\nAs we discussed, in 0.4 we're going to continue reading and setting\ncookies in the JS client. However, I will make it clear in the docs that,\nif you use SocketStream with Express, you will need to turn off the http\nonly setting on the cookie. I'm hoping this is all that's needed to ensure\neverything works flawlessly each time.\nWould like to hear your thoughts. If you still think there's a strong case\nfor doing a final 0.3 release which uses this code, I'm prepared to\nconsider it. I'm just worried about significantly changing the underlying\nbehaviour at such a late stage in the game.\nCheers,\nOwen\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/360#issuecomment-16351322\n.\n. btw, this didn't seem to be a problem with socketstream when it was using socket.io. \n. I just tried that, and it didn't fix the issue for me.  I just found this issue on engine.io-client project, and I'm guessing it is the problem: \n\nhttps://github.com/LearnBoost/engine.io-client/issues/97\nWhat do you think of that? \n. Check it out, on this line of engine.io: \nhttps://github.com/LearnBoost/engine.io-client/blob/master/lib/transports/polling-xhr.js#L48\nIf the port is set to 443 in the request and you compare it to global.location, it won't match since 443 is the default for https.  When this happens, you get a cross domain request for same domain, which won't send the cookies.  I think I can fix this.\n. I think you try to fix this here:\nhttps://github.com/socketstream/socketstream/blob/master/src/websocket/transports/engineio/client.js#L1318\nBut!\nWhen you do this comparison, you need to do !== for it to work. Watch: \n```\nNumber(\"\") != \"\" \nfalse \n\n\nNumber(\"\") !== \"\" \ntrue \nNumber(\"\") \n0 \n```\n\n\nThat fixes the issue in your wrapper, but this issue remains in engine.io proper when you set the port for standard ports: \nhttps://github.com/LearnBoost/engine.io-client/blob/master/lib/transports/polling-xhr.js#L48\nSo I think it might make sense to just not set the port in the opts when using default ports (443 and 80). \nWhen I fix the above and then clear the port from the options for standard ports, IE9 starts working using same-domain XHR instead of cross-domain.\nI'll submit a pull request just so you can see what I did, but it'll have all my changes including those related to using the http session cookie instead of sending it via the client.\n. I can't do a pull because of my previously open pull, but take a look at the last few commits I made to:\nhttps://github.com/polidore/socketstream\n. I think the way engine.io does it is ok, but it might make sense to be a bit more robust against port mismatches causing cross domain XHRs on the standard 443 / 80 ports since some UAs don't report a port from the URI.\n. THank you!\n. Nice change!\n. This doesn't happen for me on win7 64bit.\n. OK. i don't have that many files, so i may in fact have the problem.  i'll\ntry to test it if i get a chance.\nOn Wed, Aug 22, 2012 at 12:47 PM, David Rosen notifications@github.comwrote:\n\n@polidore https://github.com/polidore I'd be interested to know whether\nthe difference is due to the 64-bit vs 32-bit versions. Just to be sure,\nhave you tried with a large number of watched files? I tested using a new\nSS project, making 512 copies of app.styl, and @paulmillrhttps://github.com/paulmillrtested using 4280 files.\nWhen I get a chance, I'll test this on my wife's iMac which has nearly\nidentical hardware specs to my 4-year-old laptop. I'll also give the\noptions.interval change a test when I get a chance.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/270#issuecomment-7940788.\n. This is fixed.\n. i'll take a look at it monday.\n\nOn Thu, Aug 23, 2012 at 8:04 AM, Owen Barnes notifications@github.comwrote:\n\nI agree. Good point.\nIf you fancy having a crack at this I'd gladly merge it in; otherwise I'll\nadd it to the TODO list.\nBasically we need to change the logic here:\nhttps://github.com/socketstream/socketstream/blob/master/src/http/index.coffee#L92\nso that we parse the URL request, isolate the extension, and pass every\nrequest to the static handler (by calling next()) if it is for a .jpeg,\n.png, etc.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/286#issuecomment-7967423.\n. nice work!\n\nOn Tue, Dec 31, 2013 at 7:19 AM, Paul Jensen notifications@github.comwrote:\n\nClosed #286 https://github.com/socketstream/socketstream/issues/286.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/286\n.\n. Hey, Paul, thanks for the response.  I don't want to connect these two systems at the moment.  \n\nThe issue is not with max age since a normal cookie is generated with my setting of 24hours.  The issue is the way socketstream / connect is handling an invalid connect.sid cookie.\n. I'm going to open a simpler issue here.\n. Hello, Ownen.  Thanks for putting out 0.3.4.\nss-angular is really two projects in one:\n1. It is a client side wrapper of the socketstream apis to angular services.  This allows you to use socketstream rpc and pubsub to update angular models.\n2. It is a one-way (server to client) model synching request responder.  That is, I am using your request responder API to create an entry point for business logic that generates model data.  It allows the client to subscribe to a given model with a \"where clause\", and it keeps track of active requests and polls the business logic for updates.\nI hope this helps you understand it a bit better.   I'm definitely interested in migrating it to 0.4-- to be honest, I build it for my own use and it is not that pretty, so I would think of 0.4 as an opportunity to make it a bit more user-focused.\n. Hey, paul.  Sorry about the tone of the issue above.  I didn't mean to come off as I think I did! \nAnyway, I changed the code to use the HTTP header to get the session instead of sending it over the websocket.  I'm not very experienced in this area, so take a look and see what you think-- you may want to adjust it a bit, but I think this is a better way to do it in general. \nthanks again!\n. If you want to test it, just blow away your sessions in redis / mongo while your connected to your app and refresh.  Prior to this change, you'd hit the exception here without fail:\nhttps://github.com/socketstream/socketstream/blob/master/src/websocket/transports/engineio/wrapper.js#L24\n. Hey any thoughts on this?  I've been using it for a while without issue.\n. sounds great. thanks.\nOn Mon, Mar 25, 2013 at 2:20 PM, Owen Barnes notifications@github.comwrote:\n\nHey Ben\nApologies, I've been so engrossed in 0.4 development these last few weeks\nI've not been spending as much time on 0.3 issues as I should.\nYour patch looks good, but I'm always ultra-cautious when it comes to\nchanging things like this as inevitably it will break something none of us\nhave considered.\nAs soon as I get chance I'll try it out myself and think hard about\nanything which could go wrong. If all looks good I'll merge it in.\nAlso, I'll be in touch shortly regarding Angular integration in 0.4. I\nthink I'm onto something pretty good but want to advance it a bit more\nbefore showing you.\nCheers,\nOwen\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/359#issuecomment-15411159\n.\n. I think #1 works as long as you suppress the httpOnly flag set by connect\non expiring cookies.\nOn Mar 30, 2013 10:16 AM, \"Owen Barnes\" notifications@github.com wrote:\nHi Ben\nI'm working on Sessions support in 0.4 today and I've started thinking\nabout the two approaches here.\n1. The client-side JS reads the session cookie and sends it over the\n   WS (what we have today in 0.3)\n2. We try to obtain the session id server-side by looking at the HTTP\n   headers (what we used to have in socket.io)\nWhile I agree 2 is more reliable if the transport supports it (last time I\nchecked, SockJS doesn't), it has a big problem: it requires the client to\nbe running in a browser.\nThe latest version of 0.4 (which I will push within the next week) has\nseparate modules for the client and server 'realtime' components. Best of\nall, the client can run anywhere - on the browser, or in another Node\nprocess. Thus there is no longer any need for ss-console as you can simple\nconnect to the server using the same client library and use a REPL to\ninvoke RPC commands etc.\nAll this works great already - without sessions support. Figuring out how\nto add this is the hard part.\nI'm going to do some experimenting with ideas today and let you know.\nIdeally I'd like to find a secure and reliable way to do method 1 properly,\neven if cookies expire or don't exist at all.\nOwen\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/359#issuecomment-15675182\n.\n. Yes, thank you.\nOn Sep 28, 2013 7:23 AM, \"Paul Jensen\" notifications@github.com wrote:\nHi,\nWas this issue resolved by the work on the Websockets (#397https://github.com/socketstream/socketstream/pull/397\n)?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/359#issuecomment-25296382\n.\n. Thanks, Strikeout.  Interesting approach, but I use a level7 load balancer that looks at cookie info.\n. I think it's fine, but do you know how to disable httpOnly from connect\nwithout patching it? It didn't seem obvious to me.\n\nMay also make sense to look in header for cookie as a backup if don't\nreceive it in socket.\nOn Apr 14, 2013 9:53 AM, \"Owen Barnes\" notifications@github.com wrote:\n\nHey Ben\nI've had chance to test this and I can confirm it works well. However, I'm\na bit reluctant to merge this in, now that I know 0.4 will not work this\nway.\nAs we discussed, in 0.4 we're going to continue reading and setting\ncookies in the JS client. However, I will make it clear in the docs that,\nif you use SocketStream with Express, you will need to turn off the http\nonly setting on the cookie. I'm hoping this is all that's needed to ensure\neverything works flawlessly each time.\nWould like to hear your thoughts. If you still think there's a strong case\nfor doing a final 0.3 release which uses this code, I'm prepared to\nconsider it. I'm just worried about significantly changing the underlying\nbehaviour at such a late stage in the game.\nCheers,\nOwen\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/pull/360#issuecomment-16351322\n.\n. btw, this didn't seem to be a problem with socketstream when it was using socket.io. \n. I just tried that, and it didn't fix the issue for me.  I just found this issue on engine.io-client project, and I'm guessing it is the problem: \n\nhttps://github.com/LearnBoost/engine.io-client/issues/97\nWhat do you think of that? \n. Check it out, on this line of engine.io: \nhttps://github.com/LearnBoost/engine.io-client/blob/master/lib/transports/polling-xhr.js#L48\nIf the port is set to 443 in the request and you compare it to global.location, it won't match since 443 is the default for https.  When this happens, you get a cross domain request for same domain, which won't send the cookies.  I think I can fix this.\n. I think you try to fix this here:\nhttps://github.com/socketstream/socketstream/blob/master/src/websocket/transports/engineio/client.js#L1318\nBut!\nWhen you do this comparison, you need to do !== for it to work. Watch: \n```\nNumber(\"\") != \"\" \nfalse \n\n\nNumber(\"\") !== \"\" \ntrue \nNumber(\"\") \n0 \n```\n\n\nThat fixes the issue in your wrapper, but this issue remains in engine.io proper when you set the port for standard ports: \nhttps://github.com/LearnBoost/engine.io-client/blob/master/lib/transports/polling-xhr.js#L48\nSo I think it might make sense to just not set the port in the opts when using default ports (443 and 80). \nWhen I fix the above and then clear the port from the options for standard ports, IE9 starts working using same-domain XHR instead of cross-domain.\nI'll submit a pull request just so you can see what I did, but it'll have all my changes including those related to using the http session cookie instead of sending it via the client.\n. I can't do a pull because of my previously open pull, but take a look at the last few commits I made to:\nhttps://github.com/polidore/socketstream\n. I think the way engine.io does it is ok, but it might make sense to be a bit more robust against port mismatches causing cross domain XHRs on the standard 443 / 80 ports since some UAs don't report a port from the URI.\n. THank you!\n. Nice change!\n. ",
    "Wikinaut": "\nPlease can you try to apply a similar change to my fix in EtherpadLite https://github.com/Wikinaut/etherpad-lite/commit/85f5eb38e4334b18c7593282b6e0c93c155d4481 to your code, and let me know your observation.\n\nI mean something like this\n-  io.set('transports', ['xhr-polling']);\n+  io.set('transports', ['jsonp-polling']); // UPDATED 18.08.2012\nsomewhere in your code.\n1. Check in IE8 this setting\n   https://github.com/LearnBoost/socket.io-client/issues/382#issuecomment-4013471\nIs it disabled ? Enable it, if you can. (If you don't have administrator rights, you may not even see the advanced settings tab.)\nUPDATED 18.08.2012\nFor fixing this issue in Etherpad Lite see pull request https://github.com/Pita/etherpad-lite/pull/958/files\n. 1. Please can you try to apply a similar change to my fix in EtherpadLite https://github.com/Wikinaut/etherpad-lite/commit/85f5eb38e4334b18c7593282b6e0c93c155d4481 to your code, and let me know your observation.\nI mean something like this\n-  io.set('transports', ['xhr-polling']);\n+  io.set('transports', ['jsonp-polling']); // UPDATED 18.08.2012\nsomewhere in your code.\n1. Check in IE8 this setting\n   https://github.com/LearnBoost/socket.io-client/issues/382#issuecomment-4013471\nIs it disabled ? Enable it, if you can. (If you don't have administrator rights, you may not even see the advanced settings tab.)\nUPDATED 18.08.2012\nFor fixing this issue in Etherpad Lite see pull request https://github.com/Pita/etherpad-lite/pull/958/files\n. ",
    "travisbot": "This pull request passes (merged eea863ea into 48a98ea0).\n. This pull request passes (merged 2f3d47d1 into 2db0ff4f).\n. This pull request passes (merged eea863ea into 48a98ea0).\n. This pull request passes (merged 2f3d47d1 into 2db0ff4f).\n. ",
    "freezy": "This still seems to be happening. In my case, the browser keeps on reloading all the Javascripts, finally leading to a crash.\nDebugging this kind of behavior is very hard and I nearly abandoned SS because of it. Thanks to @polidore who came up with a solution in the referenced issue above.\n. Not necessarily disabling the log, but being able to provide a different logger would be nice as well. Right now, by overriding ss.api.log this can be accomplished, but doesn't work everywhere, e.g. events still use console.log in the code.\n. This still seems to be happening. In my case, the browser keeps on reloading all the Javascripts, finally leading to a crash.\nDebugging this kind of behavior is very hard and I nearly abandoned SS because of it. Thanks to @polidore who came up with a solution in the referenced issue above.\n. Not necessarily disabling the log, but being able to provide a different logger would be nice as well. Right now, by overriding ss.api.log this can be accomplished, but doesn't work everywhere, e.g. events still use console.log in the code.\n. ",
    "mgan59": "Ran into an issue adding twitter bootstrap and the css files attempt to load fonts/ as static content and socketstream has a meltdown.  I believe this is of a similar issue?  I'm willing to dive in and see if I can't sort this out.  @paulbjensen  do you have existing work on this that I should look at?  Or just jump in?\n. @RomanMinkin  thanks for the input, that fixed my problem.  looks like I was trying to link my fonts within the css folder, not sure why I didn't try the static directory.  thnkx.\n. my bad about the path, hadn't linked my module for development.  let me know if there are any other changes.  thnx.\n. Ran into an issue adding twitter bootstrap and the css files attempt to load fonts/ as static content and socketstream has a meltdown.  I believe this is of a similar issue?  I'm willing to dive in and see if I can't sort this out.  @paulbjensen  do you have existing work on this that I should look at?  Or just jump in?\n. @RomanMinkin  thanks for the input, that fixed my problem.  looks like I was trying to link my fonts within the css folder, not sure why I didn't try the static directory.  thnkx.\n. my bad about the path, hadn't linked my module for development.  let me know if there are any other changes.  thnx.\n. ",
    "Waxolunist": "Have you tried to copy the fonts Folder from Bootstrap into the client static folder?\n. +1 for that cookie.\n. I solved it by adding following file to my cms: \nhttps://github.com/Waxolunist/circlescms/blob/master/lib/minmap.js\nand then in my main file adding following line:\nss.client.formatters.add(require('./lib/minmap.js'));\nThis is a bit of a hack, because the content-type should actually be application/json.\nWould be great if formatters could be more flexible.\n. Because comments are deleted, the client is not aware of these files in production mode. Thus, no complaints.\n. Thx for looking at it. I've seen following post: https://github.com/LearnBoost/socket.io/wiki/Socket.IO-and-firewall-software\n\nThe client js will initially try to connect to port 4000 and fall back to ports 80 or 843, if that doesn't work. I also tested different orders for port 80 and 843, to make sure both work (or not).\n\nSo the client seems to be able of doing this. On the server are both ports open anyway. Maybe this is helping.\n. I know, but I thought the link could maybe help. I am using also engineio (see snippet above).\n. I am investigating this issue at the moment. All I need is to set the port to the openshift websocket port, when an error occurs. How do I add an error listener to the client only?\n. Thx for investigating this. This is a good hint. I will try it after lunch ;) (Having a tough time at work atm so I don't know when I find time.)\nWhen its done, I will open a PR on ss-engine.io. \nSo I am closing this.\n. Actually jade works for me. Can you provide an example? Maybe a Repo? I am using jade in my cms CirclesCMS. You can have a Look there if you want.\n. But its not a custom tag. Its actually the tag for Unescaped Buffered Code, See jade Website.\n. The way its implemented in jade is the right one imho. As tag, maybe as an option its ok. But not as a default.\n. Yes I know that, but that makes my bower components not updateable. I know at the moment a solution supported by socketstream is missing, but I am trying to work around these problems, when possible without changing the assets coming from dependencies.\nI wanted just know why one time the request url gets parsed with the filename as parameter, the other time as it should be.\n. Thanks for clarification.\nYes I am using express. I have written a small static middleware for serving the static fonts (see above). So it works. \nHowever, when using a static folder, I have to change bootstrap and move files around. Which is not a lot in the case of bootstrap, but think of a more advanced widgetset library, which has a lot of sprites, images, fonts and dynamic paths.\nSocketstream is great when it comes to initialize a project. It is very easy to ramp up and start. But when clients get more sophisticated, it starts getting difficult and it feels like fighting the framework, especially on the client side. Every small library is a pain to get to work. You have to move files around, change paths in well established libraries or configure those libraries to fit into the socketstream directories.\nSocketstream is very opinionated about the client side. Being opinionated is not a bad thing at all. I love opinionated frameworks, because they give structure, but opinions should you not hold back.\nFor instance I can not easily use the power of r.js for optimizations. I can not declare dependencies (bootstrap depends on jquery, but I can not express this relationship). I can not use different formatters for the same file extension in different paths. Not able to use dependency managers for the client side. Not able to define multiple pre-processors for the same file. So imho socketstream does not get the client side right at all, even if so stated.\nThe preprocessors are bound to file extensions and paths in the client directory and are very unflexible. Libraries which should get browserified put in that directory, files with that file extension into that directory but not if a formatter should be excluded, and so on, but the days of going to a projects website and download single files are over.\nOn the server side a lot feels right, except, when it comes to serving static files, socketstream reads those files synchronously (I saw at least a lot of sync calls). But the rest is ok, especially the rpc or pub/sub parts.\nI thought a lot about how to structure the client side. My requirements are not difficult:\n- Dependency management with bower as it is\n- Using pre-processors \n- Chain pre-processors\n- Cache the outcome of those pre-processors\n- Save the outcome for production if needed\n- Initialize socketstream on the client side\nI looked at http://www.metalsmith.io/ and http://gulpjs.com/ and some other libraries and wanted to utilize one of those, because they both fulfil most of the above requirements, but I was not able to get it to work without breaking socketstream, too strong is the binding of the client to its directory structure and to weak my knowledge of the internals of socketstream.\nMaybe you should provide a gulp interface for the client. Everything done on the client side (e.g. ss-stylus, ss-jade, browserify) can be done easily with gulp plugins already available.\nSocketstream should therefore concentrate on the server side and provide a default gulp configuration which copies todays client side behaviour, so if not configured otherwise, the behaviour would be the same, which would allow for a smooth transition.\nAdvantages would be \n- higher flexibility on the client side, \n- less issues and PRs for those parts, \n- less repositories to maintain\n- a huge plugin eco system (400+ plugins), which will socketstream never reach, \n- smaller code base.\nPlease, don't understand me wrong, I like socketstream and contributed some small code pieces already, but the restrictions on the client side, make it difficult for me to persuade others and more and more myself, to use it for further development. I like how it evolved in the last months, with a cleaner code base and better documentation, but it still lacks flexibility on the client side.\nWhat's your opinion about transition the client side to an already established library and abandon the socketstream part?\n. I'd like to contribute, but I will not find any time in the next months, as I am starting a new job and my family will grow ;)\nIs there any roadmap for the next versions?\n. Have you tried to copy the fonts Folder from Bootstrap into the client static folder?\n. +1 for that cookie.\n. I solved it by adding following file to my cms: \nhttps://github.com/Waxolunist/circlescms/blob/master/lib/minmap.js\nand then in my main file adding following line:\nss.client.formatters.add(require('./lib/minmap.js'));\nThis is a bit of a hack, because the content-type should actually be application/json.\nWould be great if formatters could be more flexible.\n. Because comments are deleted, the client is not aware of these files in production mode. Thus, no complaints.\n. Thx for looking at it. I've seen following post: https://github.com/LearnBoost/socket.io/wiki/Socket.IO-and-firewall-software\n\nThe client js will initially try to connect to port 4000 and fall back to ports 80 or 843, if that doesn't work. I also tested different orders for port 80 and 843, to make sure both work (or not).\n\nSo the client seems to be able of doing this. On the server are both ports open anyway. Maybe this is helping.\n. I know, but I thought the link could maybe help. I am using also engineio (see snippet above).\n. I am investigating this issue at the moment. All I need is to set the port to the openshift websocket port, when an error occurs. How do I add an error listener to the client only?\n. Thx for investigating this. This is a good hint. I will try it after lunch ;) (Having a tough time at work atm so I don't know when I find time.)\nWhen its done, I will open a PR on ss-engine.io. \nSo I am closing this.\n. Actually jade works for me. Can you provide an example? Maybe a Repo? I am using jade in my cms CirclesCMS. You can have a Look there if you want.\n. But its not a custom tag. Its actually the tag for Unescaped Buffered Code, See jade Website.\n. The way its implemented in jade is the right one imho. As tag, maybe as an option its ok. But not as a default.\n. Yes I know that, but that makes my bower components not updateable. I know at the moment a solution supported by socketstream is missing, but I am trying to work around these problems, when possible without changing the assets coming from dependencies.\nI wanted just know why one time the request url gets parsed with the filename as parameter, the other time as it should be.\n. Thanks for clarification.\nYes I am using express. I have written a small static middleware for serving the static fonts (see above). So it works. \nHowever, when using a static folder, I have to change bootstrap and move files around. Which is not a lot in the case of bootstrap, but think of a more advanced widgetset library, which has a lot of sprites, images, fonts and dynamic paths.\nSocketstream is great when it comes to initialize a project. It is very easy to ramp up and start. But when clients get more sophisticated, it starts getting difficult and it feels like fighting the framework, especially on the client side. Every small library is a pain to get to work. You have to move files around, change paths in well established libraries or configure those libraries to fit into the socketstream directories.\nSocketstream is very opinionated about the client side. Being opinionated is not a bad thing at all. I love opinionated frameworks, because they give structure, but opinions should you not hold back.\nFor instance I can not easily use the power of r.js for optimizations. I can not declare dependencies (bootstrap depends on jquery, but I can not express this relationship). I can not use different formatters for the same file extension in different paths. Not able to use dependency managers for the client side. Not able to define multiple pre-processors for the same file. So imho socketstream does not get the client side right at all, even if so stated.\nThe preprocessors are bound to file extensions and paths in the client directory and are very unflexible. Libraries which should get browserified put in that directory, files with that file extension into that directory but not if a formatter should be excluded, and so on, but the days of going to a projects website and download single files are over.\nOn the server side a lot feels right, except, when it comes to serving static files, socketstream reads those files synchronously (I saw at least a lot of sync calls). But the rest is ok, especially the rpc or pub/sub parts.\nI thought a lot about how to structure the client side. My requirements are not difficult:\n- Dependency management with bower as it is\n- Using pre-processors \n- Chain pre-processors\n- Cache the outcome of those pre-processors\n- Save the outcome for production if needed\n- Initialize socketstream on the client side\nI looked at http://www.metalsmith.io/ and http://gulpjs.com/ and some other libraries and wanted to utilize one of those, because they both fulfil most of the above requirements, but I was not able to get it to work without breaking socketstream, too strong is the binding of the client to its directory structure and to weak my knowledge of the internals of socketstream.\nMaybe you should provide a gulp interface for the client. Everything done on the client side (e.g. ss-stylus, ss-jade, browserify) can be done easily with gulp plugins already available.\nSocketstream should therefore concentrate on the server side and provide a default gulp configuration which copies todays client side behaviour, so if not configured otherwise, the behaviour would be the same, which would allow for a smooth transition.\nAdvantages would be \n- higher flexibility on the client side, \n- less issues and PRs for those parts, \n- less repositories to maintain\n- a huge plugin eco system (400+ plugins), which will socketstream never reach, \n- smaller code base.\nPlease, don't understand me wrong, I like socketstream and contributed some small code pieces already, but the restrictions on the client side, make it difficult for me to persuade others and more and more myself, to use it for further development. I like how it evolved in the last months, with a cleaner code base and better documentation, but it still lacks flexibility on the client side.\nWhat's your opinion about transition the client side to an already established library and abandon the socketstream part?\n. I'd like to contribute, but I will not find any time in the next months, as I am starting a new job and my family will grow ;)\nIs there any roadmap for the next versions?\n. ",
    "RomanMinkin": "Actually problem in the original *.css files. I'm using font-awesome and it works just fine. All you need to do is:\n1. Move fonts folder into client/static/fonts\n2. Move all the *.css file into client/css/\n2. Replace all the entries of ../fonts/ in *.css with  /fonts/\ncss\n@font-face {\n  font-family: 'FontAwesome';\n  src: url('/fonts/fontawesome-webfont.eot?v=4.0.2');\n  src: url('/fonts/fontawesome-webfont.eot?v=4.0.2#iefix') format('embedded-opentype'), url('/fonts/fontawesome-webfont.woff?v=4.0.2') format('woff'), url('/fonts/fontawesome-webfont.ttf?v=4.0.2') format('truetype'), url('/fonts/fontawesome-webfont.svg?v=4.0.2#fontawesomeregular') format('svg');\n  font-weight: normal;\n  font-style: normal;\n}\n. Hey folks,\nFrom the other hand in some cases header <script> templates needed for third party plugins as angular-ui/bootstrap, where templates calls hardcoded as \nJavaScript\ntemplateUrl: 'template/accordion/accordion.html'\nIt's why I came up with ss-angular-templates module for SocketStream.\n. Hi guys,\nI ended up with bower and custom grunt task. Since bower has lack on projects structure/listing in  bower.json file, so I programmatically move  required files for my project from bower_components folder. There is no magic pile or at least i have not found it yet.\nFor instance Twitter Bootstrap v2.3.2 has only links to uncompressed  js and css files in main key in bower.json, so fonts should me managed manually:\nJavaScript\n{\n  \"name\": \"bootstrap\",\n  \"version\": \"2.3.2\",\n  \"main\": [\"./docs/assets/js/bootstrap.js\", \"./docs/assets/css/bootstrap.css\"],\n  \"dependencies\": {\n    \"jquery\": \">=1.8.0 <2.1.0\"\n  }\n}\nThey fixed it only in current master https://github.com/twbs/bootstrap/blob/master/bower.json ,but it's v3.0.x, which has no back capacity with v2.3.x\nAnd there are bunch of examples like that. Some libraries do not even have main key in bower.json.\n. +1 for this!\n. Hi guys,\nI doesn't looks like real SS bug. If you would like to use min files just download and put .map file next to the original one and added it for client-side loading. \nSo for \nhttp://code.jquery.com/jquery-2.0.3.min.js it will be \nhttp://code.jquery.com/jquery-2.0.3.min.map , just replace js with map.\nOtherwise, as I'm doing, use uncompressed  js files, SS anyway does asset packing in production environment, so to me using minified files during development does not make any cense.\np.s. map files make cense if you are going to use unstable external libraries on production  =)\n:+1: to close the issue.\nPlease correct me if i'm wrong ;)\n. If i understand Paul's https://github.com/socketstream/socketstream/issues/381#issuecomment-26125271 right, all we need is just add *.map files serving inside the code directories.\nProbably couple of lines of code, just nobody signed yet -)\n. @paulbjensen ,\nYep, forgot to put that, thanks. We need to update README for this.\n. Hi, \nGuys, just keep in mind, that code has not been linted yet, and it's a huge task ;)\np.s. I almost done with test folder: linting + grunting and once do this i would move my focus to the rest of the  code base.\n. Hi Paul,\nSorry, my bad, I broke original indents in package.json and during restoring made a mistake.\n. @paulbjensen, look like travis-ci.org doesn't have grunt-cli installed. Let me go into this problem, i'll be back soon.\n. @paulbjensen, yeah, already found that too =)\nOk, looks like to have grunt-cli installed locally not so bad.\nI always preferred local dependencies, i do now why i used global this time.\n. You are welcome,\nYes, Grunt 0.4.x requires Node.js version >= 0.8.0. OpenShift supports git hooks which allow to use any of node.js versions. OpenShift has really weird implementation for this.\nAt the same time SocketStream 0.4 requires node.js >= 0.8.0 , because of Streams2 i guess.\n. Done and passed.\n. For now project has 3 test files =) So it's not a big deal to move to NodeUnit. When I started to use TDD and BDD approaches it became clear pretty fast that Mocha, Jasmine, etc. frameworks lack for this issue. I like BDD code writing style, but to be honest in my example NodeUnit looks almost like BDD. One thing, NodeUnit doesn't support nesting as Mocha does, but it does support groups (i do not like deep nesting - i like simplicity), so code may look like:\n``` JavaScript\nexports.GroupName = function (test) {\n    ...\n}\nexports.HttpServer = {\n    setUp: function() {\n    },\n    tearDown: function() {\n    },\n    \"Should start\": function (test) {\n        ...\n    },\n    \"Should stop\": function (test) {\n        ...\n    }\n}\n```\nHere is how i see both frameworks\nNodeUnit:\n\n[ ] BDD \n[ ]  before() / after() - function calls before all tests, But NodeUnit first test in a group always runs first, wthe \n[ ] Tests nesting, not sure if it's a benefit especially for async code\n[x] TDD \n[x] Built-in assertion module\n[x]  test.expect(22) - settable assertions amount, good for testing async functions\n  same with the last test\n[x]  beforeEach() / setUp()\n[x]  afterEach() / tearUp()\n[x] Grunt plugin officially support by team (https://github.com/gruntjs/grunt-contrib-nodeunit)\n\nMocha:\n\n[ ] TDD \n[ ]  test.expect(22) - settable assertions amount, good for testing async functions\n[ ] Grunt plugin officially support by team (https://github.com/pghalliday/grunt-mocha-test)\n[ ] Built-in assertion module\n[x] BDD \n[x] Tests nesting\n[x]  before() - function calls before all tests, but first test in group always runs first\n[x]  beforeEach() / setUp()\n[x]  afterEach() / tearUp()\n\nIn my projects i use NodeUnit for server tests and Karma/Jasmine for e2e.\nWould like to hear any thought about it, maybe i'm wrong somewhere...\n. @paulbjensen , I'll do that. have never heard about Istanbul, but i found Grunt a task https://github.com/taichi/grunt-istanbul so we can use it =)\n. @paulbjensen , do you mean that you are not be able to create nested test tree as describe here https://gist.github.com/repeatingbeats/799136 ;)\n. Hi Paul,\nThanks for the wide answer -) Fair enough. \nBtw i make nodeunit syntax look pretty convenient -)\n\n. Hi @shannonmoeller,\nI wrote test in incorrect way by propose to show that we need to use assertion counting especially with async code. So one missed callback could be uncaught. In another universe where developers write code with no mistakes we do not need it ;)\n. Sorry, wrong branch.\n. ### Update\n- Added 'async' to devdependencies library for async test purpose\n- 'lib/cli/generate.js' linted and beautified\n- To test/unit/cli/generate.test.js added test for default folders on project generation\n@paulbjensen, what do you think about syntax style which I applied in lib/cli/generate.js, to me it's convenient, because al the private statements go under var including functions and then go exports.* and public stuff like that, ex: \n``` JavaScript\n/*\n * New App Generator\n * -----------------\n * Generates skeleton files needed to create a new SocketStream application\n /\n\"use strict\";\nrequire('colors');\nvar fs       = require('fs'),\n    path     = require('path'),\n    util     = require('util'),\n    log      = console.log,\n    dir_mode = '0755',\n// Private\nsuccess = function(name, alternative) {\n  return log(\" \u2713\".green, name, (alternative || '').grey);\n},\n\n// TODO - investigate whether this would be better\n// using the async version of fs.mkdir - PJENSEN\nmakeRootDirectory = function(name) {\n  ...\n\n};\nexports.generate = function(program) {\nvar appjs,\n      codeExtension = program.coffee && 'coffee' || 'js',\n      selectedFormatters = [],\n...\n``\n. Forgot to add that test app generates intotest/results/tests_app_name` to keep root directory clean from test stuff.\n. Hi Paul, \nI'm thinking also about using something like https://github.com/isaacs/minimatch for paths filtering.\nWe can even assign is to ss.api. So setting for files/dirs paths corporation could be the same as Grunt.js uses, which is pretty handy:\nJavaScript\n['tmp']\n['tmp/*']\n['tmp/*.js']\n['tmp/**/*.js']\n['tmp/**/*']\n. Hi Paul,\nThanks, sorry about misspelling, good eye! \nAgree, about minimatch, i think it would be good to put it into lib/utils/fille.js (since SS has all the file system related method there)\nI renamed brosefyExcludePaths to browserifyExcludePaths and I'm going to update docs...\nDo you want to merge it now or wait until minimatch be added?\n. Paul, i just tried demo app created from my pull request, with and w/o browserifyExcludePaths, but i wasn't be able to reproduce. Could you share your code at app.js:25:11 ?\n. No worries, on my way home I was thinking about npm link, but you was faster =)\n. Hi @paulbjensen,\nyeah, my bad, sorry about that.\nBut about case i was looking into \nhttp://www.w3.org/International/O-HTTP-charset\nhttp://www.w3.org/International/questions/qa-headers-charset\nAccording to http://www.ietf.org/rfc/rfc2616.txt\n\n4.2 Message Headers\n...\nEach header field consists of a name followed by a colon (\":\") and the field value. Field names  are case-insensitive.\n\nWe probably can search/add/replace for <meta charset=\"utf-8\">, maybe on asserts packing, w/o asserting it doesn't really need. What do you think?\nAdded fix, thanks!\n. Hi Paul, \nSure, no rush, feel better!\n. You are welcome, Paul! \nYes, i'm using it as a Chrome extension, pretty convenient.\nAlso Chrome->Tools->Developer Tools->Network (tab) shows requests info and has a column `Size/Content: loaded asset/file size (gziped in our case) vs. original size.\nIn my case number for the main HTML changed from 20KB to 4.2KB \n. Cool idea! :+1: \n. My concern is:\nJavaScript\nfunction RPC(req,res,ss){\n  this.req = req;\n  this.res = res;\n  this.ss = ss;\n}\nIt's kinda annoying to put it in each file within server/rpc folder. Maybe it's better to put it outside RPC files. For example put it under ss.api?\n. Hi guys,\nI still think that we need to add code from https://github.com/socketstream/socketstream/pull/407#issuecomment-26646519 to SocketStream src. Not sure where exactly, probably should be in ss.api, maybe inside lib/socketstream.js:\nJavaScript\napi.add('rcpProvider', function(){\n  ...\n  });\n};\nStill kind of ugly, but i think since SS is a framework it should not be up to user, too complicated =)\n...or maye  should be something like following inside app.js:\n``` JavaScript\nvar ss = require('socketstream');\nss.use('rcpProvider');\n```\nThoughts?\n. Hi everyone,\nAn update, I'm finishing linting/testing for lib/http/, PR will be in a few days.\n. Hi @kulicuu,\n==  compares values:\njavascript\n5 == \"5\" // true\n=== compares values and types:\njavascript\n5 === \"5\" // false\nit's better to use === to be sure that values types match.\nSorry about that, in the future I'll notify about the files I'm working on in advance.\n. A little delay over here,\nI used supertest for HTTP testing and discovered an error in terms of using it with Mocha and Assertion counting (it's why prefer I Nodeunit over Mocha with native JavaScript's Object extension ), so I fixed the problem and waiting right now for PR approval https://github.com/visionmedia/supertest/pull/89\n. Is anybody working on anything from the list?\n. Hi Paul,\nThanks for corrections. Fell fee to correct me any time, since english is my second language i'm not a best doc writer =)))))\nI reviewed lib/utils/file.js and found that:\n1. I made refactoring wrong at the first time\n2. We didn't have any tests for public method .readDirSync() in lib/utils/file.js\nSo i did re-refactor the code and added tests:\n1. Fixed description for function isDir() in lib/utils/file.js https://github.com/socketstream/socketstream/pull/410#commitcomment-4411445\n2. Added description for functions and public methods in lib/utils/file.js\n3. Updated public method .readDirSync() in lib/utils/file.js, removed unnecessary variables and IF statements\n4. Added tests and fixtures for .readDirSync()\n. One more update:\n1. Fixed methods descriptions in lib/utils/file.js\n2. Added description and test for .loadPackageJSON() in lib/utils/file.js\n. Paul, there are some errors @travis, let me check...\n. We good.\n. Thanks @pygy , i do my best =)\n. Thanks Paul! I'm preparing a next shot =)\n. Hi everyone!\nI know that you guys already working on a doc site, but I also was looking for solution and finally I found it.\nYou all know Angular.js and it's team came up with quite useful documentation approach, which is in kipping documentation inside source code for consistency.\nAlso that approach allows easily generate docs from source code. So I spent some time and finally figure out how we can use it.\nPlease check out what i got http://romanminkin.github.io/socketstream/docs/\nMy idea was to find a way of generating docs so we can focus on actual development.\nThis is what I have done:\n1. Added  https://npmjs.org/package/grunt-ngdocs - Grunt plugin to create a documentation like AngularJS, and set up Grunt tasks for docs generation\n2. Set up GitHub Pages\n3. Set up account for 3rd party comment platform http://disqus.com\n4. Moved few tutorial examples from original docs to https://github.com/RomanMinkin/socketstream/tree/feature/docs-generator/src/docs , it was not hard generator can work with Mardown format, all i have done is just changed source code examples wrapper  to <pre>\n5. Changed source code description a bit so it match the pattern for lib/http/*.js and lib/utils/file.js\nI just made a small piece to show you how it can look like. If you choose to go with this one, then it relatively easy to support documentation like this.\nEspecially with Grunt tasks for generation.\nSo we can finally have:\n1. Unified way for source code and API documentation creating and support\n2. Unified way for Tutorials documentation creating and support\n3. All in one repository\n4. 3rd party comments platform\n5. On site search through docs/API entries\n6. Free hosting from GinHub\n7. Time saving, so we can work on the project within one repository and do not spend time for supporting ss-home\nI can help with settings.\n. Here are some files which i used for doc generator:\n- https://github.com/RomanMinkin/socketstream/blob/feature/docs-generator/lib/http/index.js\n- https://github.com/RomanMinkin/socketstream/blob/feature/docs-generator/lib/http/router.js\n- https://github.com/RomanMinkin/socketstream/blob/feature/docs-generator/src/docs/tutorials/authentication.ngdoc\nAlso different CSS styles could be applied, my goal was to show that we can minify manual work.\n. I glad you like it guys!\n@paulbjensen , I can finish all docs, create Grunt task for submitting docs to gh-page branch, so literally our work will be just changing the src and running Grunt tasks and promote a PR.\n@americanyak , no worries, i have spent a few month until i finally found simple solution for usage. As i said before i think that developers should be focused on development and all the workflow processes should be automated as much as possible. Would appreciate if you help out with applying styles, once docs generator will be on place. Design is not really my thing =)\n. Hi Paul,\nMy bad, i did update compress version and i didn't' notice that they deprecated compress and staticCache middleware:\nhttps://github.com/senchalabs/connect#middleware\nThese middleware are officially supported by the Connect/Express team:\n- compression - previously compress\nThese middleware previously included with Connect are no longer supported by the Connect/Express team. Use one of these alternatives intead:\n- cookieParser\n  - cookies and keygrip\n- limit\n  - raw-body\n- multipart\n  - connect-multiparty\n  - connect-busboy\n- staticCache\n  - st\np.s. I changed compress version back for now.\n. Ha, i wanted to start topic like that after we figured out docs stuff, but Robert beat me, and i glad that he did it =)\nI agree that new SocketStream needs refactoring and new approach as we started to have it in 0.3.x\nHere are my thoughts. New approach should be centralized instead of decentralized (as it is right now with many separate repositories). Why? Because user (i mean people who use SS) can not keep tracking on multiple ss-* branches and figured out what is if officially supported module and what is not. Users want consistency, stability and simplicity when he get into a new project.\nSo my approach is in having ONE main repository with structure like this:\n/\n    index.js\n    package.json\n    modules/\n        prism/\n            index.js\n            ...\n        rts/\n            index.js\n            ...\n        rts-stream/\n            index.js\n            ...\n        spa/\n            index.js\n            ...\n        spa-livereload/\n            index.js\n            ...\nSo the root index.js is just a proxy require and any module (not from node_modules) can be require within a project as:\nJavaScript\n     var rts     = require('socketstream')('rts'),\n           prism = require('socketstream')('prism');\nBenefits of this approach are:\n- one consistent repository \n- easy to maintain src\n- easy to maintain docs\n- easy to write and run integrated tests (tests which involve multiple modules)\n- easy to to navigate between source code\n- easy for user and new coming to understand what project is\n- finished boxed product\n- in terms of minification and specific builds i can create Grunt task for building custom sets, which can be invoked  like:\n$ grunt build:prism:rts:spa\nAgain if somebody wants to use for example rts, he can install socketstream and just requires what he needs:\nJavaScript\nvar rts = require('socketstream')('rts');\nSo all the third party modules would be just:\nJavaScript\nvar module = require('ss-module');\nI came up with this after i spent some time of figuring out ss 0.4.x dependencies, it was so hard. We defiantly need to move from complicity so simplicity.\nSo what i'm trying to say, yes we need to abandon 0.4 as it is right now and refactor it into, as Robert said, 0.5\nI also like versioning which node.js and angular.js teams are using, it's a semver where even second digit 1.2.x means stable version, and odd means unstable 0.3.x(http://blog.angularjs.org/2012/07/angularjs-10-12-roadmap.html)\nWhat do you think, guys?\n. Hi @ignlg,\nThanks for dong that!\nFYI Makefile has been deprecated instead we are using grunt test for running tests. Checkout CONTRIBUTING.md#working-with-source-code for detailed information.\np.s. Makefile should be removed, i do not  know why we are still keeping it =)\n. Hi @ignlg, thanks!\np.s. since we are using web hook for travis-ci.org it's not necessary to post image with passed tests =) Just a time saver and you always can track your PR's build status.\n. @paul, could you please enable gh-pages support in project settings? I do not have an access there.\n. @paul, please disregard my request, it's working http://socketstream.github.io/socketstream/docs/\nBut it would be cool if you can assign DNS to gh-pages.\n. Hi Paul, \nRight, right, i was doing multiple projects yesterday, i messed it up =)\nNot DNS, could you change menu item 'Docs' link on left hand side at http://socketstream.org from\nhttp://socketstream.org/docs/0.3\nto\nhttp://socketstream.github.io/socketstream/docs/\nSo people who landed on web site be able to read the docs  =)\nAnd yes, we can change styles, i was trying to apply styles from https://github.com/socketstream/ss-home, but decided to come up with docs generation functionality first.\n. Thanks guys!\nPlease use Git Commit Guidelines in future commits and PR's.\n. Hi Evan, \nThanks for doing this, right now we are focusing on linting/testing (https://github.com/socketstream/socketstream/issues/408) to be able to work with PR more efficient. \nLong story short, would be great if @paulbjensen can also take a look, my concern is that we do not have test coverage for that part of code.\nI think passing ss as a parameter around doesn't seem right. Maybe there is a way to use dedicated file let's say log.js, require it around with node.js require and in the end assign it to ss object. Then i think it will not be necessary to pass ss.\n. Hi @kulicuu,\nNot really =) The problem is that code base has mix of console.log, ss.log, ect. calls. So we need to replace them all with common log API, which could be hook to whatever developer wants to hook it or just stream into stdout and stderr.\n. Hi Evan,\nVery cool! Code is much cleaner now, thanks!\nDo you mind to add for lib/utils/log.js\n1. docs notation for as example you can use this one lib/utils/file.js#L82 , the way it show up in our new docs site;\n2. some tests, should be pretty simple , mostly tests for method existence\nPlease checkout our Guidelines for Documentation generation\n. Yeah, Git commit guidelines recently added, it would be great to have, but since your PR was submit before PR git commit guidelines where merged would be cool if you add just one commit with anchor, something like:\n``\nfeat(utils): Addss.api.log` unified logging API\nBREAKING CHANGES\nUse this this instead of that\n```\n. Hi Evan,\nThanks a lot! Let me go through it.\n. One more thing, I just run demo app and there is no output in console, can we make defaults as:\nJavaSctipt\n  l.debug = console.log;\n  l.info  = console.log;\n  l.warn  = console.log;\n  l.error = console.error;\nOtherwise we need to update demo app, which will make it more complicated for new comings =)\nThanks again for your time and test/docs coverage, I really like you clean code style linted and with no white spaces =) Looks like grunt started to give his benefits, i hope we will cover all the project soon =) \n. Thanks Paul, agree, but I think that complete linting/testing should be done as a separate PR according to https://github.com/socketstream/socketstream/issues/408 Juts too much for this PR   imho =)\nSo I would prefer to merge it now to avoid much complications.\n. Well, then tags are perfect place for them =)\nI just noticed that those branches confused new comings.\nDone.\n. Thanks @malditogeek, much better now ;)\n. I like activity tab https://gitter.im/socketstream/socketstream\n. Hi @Waxolunist,\nFonts should be within /client/static folder, let say /client/static/fonts/\nYou also need to change path to all the fonts in all the css files to be relative to /client/static folder, for example:\ncss\n@font-face {\n  font-family: 'FontAwesome';\n  src: url('/fonts/fontawesome-webfont.eot?v=4.0.2');\n  src: url('/fonts/fontawesome-webfont.eot?v=4.0.2#iefix') format('embedded-opentype'), url('/fonts/fontawesome-webfont.woff?v=4.0.2') format('woff'), url('/fonts/fontawesome-webfont.ttf?v=4.0.2') format('truetype'), url('/fonts/fontawesome-webfont.svg?v=4.0.2#fontawesomeregular') format('svg');\n  font-weight: normal;\n  font-style: normal;\n}\n. Got you, answering you question:\nIt's not a big issue, but why do requests to _serveDev get parsed different, than those to assets?\nIt because of internal middleware, which intercepts request before router's middleware: https://github.com/socketstream/socketstream/blob/master/lib/http/index.js#L55\nTo archive you goal we need to change the request/respond model in general, because it has been developed the way to serve assets from hard-defined/static directories.\nI already was thinking about it already, especially how to make SS support Best Practice Recommendations for Angular App Structure\n. @Waxolunist, are you using Express? In this case you can try to add an additional static folder \njavascript\napp.use('/fonts', express.static(path.join(__dirname, 'bower_components/bootstrap/fonts')));\np.s. there is also should be a way to do it with default connect...\n. Hi @Waxolunist,\nFirst of all thanks for righting that!\nSorry for delay. I see what you say. I'm facing the same issues right now, especially when i'm trying to implement recently released Best Practice Recommendations for Angular App Structure\nSo i do understand that eventually SS needs to support more abstract way for assets managing.\nAs may know we abandoned 0.4 version. But even v0.4 had the same assets delivery pattern as v0.3 has right now.\nI have never work with both http://www.metalsmith.io/ and http://gulpjs.com/, so let me check them out.\nit's could be workaround for v0.5, so do you think you would be able to contribute? Unfortunately there are only few people in the project right now who do contribute.\nLet me know what do you think.\n. @thepian , no i made this one https://github.com/RomanMinkin/ss-angular-templates it uses custom formatter function.\nI like streaming idea API idea. What do you think about https://github.com/isaacs/node-glob or https://github.com/wearefractal/vinyl-fs?\ngulp uses the second one.\n. @thepian i did not use them, i found custom template function more powerful.\n. Hey guys, when I was adding ng-docs I also was looking for a better solution, but i did not find anything better at that tome. I was targeting two goals:\n1. Make docs searchable with no back-end required\n2. Internal SecketStream API support, since it's an open source project\nSo ng-docs to me is more like docs provider than docs generator.\nRight now I would take a look at https://stripe.com/docs for 101/Guides and for API make sense to keep ng-docs. Here is a big difference between people who whats to use SS and who wants to contribute.\n. ...forgot to add that I also bright ng-docs for automated change log generation https://github.com/socketstream/socketstream/blob/master/CHANGELOG.md\n. Hi guys it was me, who sent this PR, looks awful  tho ;)\nI wan you to consider using https://waffle.io/socketstream/socketstream for project and PR request management. I'm using it at my work and It's free for open source.\n. @arxpoetica, It's like https://trello.com but works with existing Github issues. or lets say it's like minified sexy JIRA for Github ;)\nHere is an example how Ionicframwork's team uses it https://waffle.io/driftyco/ionic\n. Actually problem in the original *.css files. I'm using font-awesome and it works just fine. All you need to do is:\n1. Move fonts folder into client/static/fonts\n2. Move all the *.css file into client/css/\n2. Replace all the entries of ../fonts/ in *.css with  /fonts/\ncss\n@font-face {\n  font-family: 'FontAwesome';\n  src: url('/fonts/fontawesome-webfont.eot?v=4.0.2');\n  src: url('/fonts/fontawesome-webfont.eot?v=4.0.2#iefix') format('embedded-opentype'), url('/fonts/fontawesome-webfont.woff?v=4.0.2') format('woff'), url('/fonts/fontawesome-webfont.ttf?v=4.0.2') format('truetype'), url('/fonts/fontawesome-webfont.svg?v=4.0.2#fontawesomeregular') format('svg');\n  font-weight: normal;\n  font-style: normal;\n}\n. Hey folks,\nFrom the other hand in some cases header <script> templates needed for third party plugins as angular-ui/bootstrap, where templates calls hardcoded as \nJavaScript\ntemplateUrl: 'template/accordion/accordion.html'\nIt's why I came up with ss-angular-templates module for SocketStream.\n. Hi guys,\nI ended up with bower and custom grunt task. Since bower has lack on projects structure/listing in  bower.json file, so I programmatically move  required files for my project from bower_components folder. There is no magic pile or at least i have not found it yet.\nFor instance Twitter Bootstrap v2.3.2 has only links to uncompressed  js and css files in main key in bower.json, so fonts should me managed manually:\nJavaScript\n{\n  \"name\": \"bootstrap\",\n  \"version\": \"2.3.2\",\n  \"main\": [\"./docs/assets/js/bootstrap.js\", \"./docs/assets/css/bootstrap.css\"],\n  \"dependencies\": {\n    \"jquery\": \">=1.8.0 <2.1.0\"\n  }\n}\nThey fixed it only in current master https://github.com/twbs/bootstrap/blob/master/bower.json ,but it's v3.0.x, which has no back capacity with v2.3.x\nAnd there are bunch of examples like that. Some libraries do not even have main key in bower.json.\n. +1 for this!\n. Hi guys,\nI doesn't looks like real SS bug. If you would like to use min files just download and put .map file next to the original one and added it for client-side loading. \nSo for \nhttp://code.jquery.com/jquery-2.0.3.min.js it will be \nhttp://code.jquery.com/jquery-2.0.3.min.map , just replace js with map.\nOtherwise, as I'm doing, use uncompressed  js files, SS anyway does asset packing in production environment, so to me using minified files during development does not make any cense.\np.s. map files make cense if you are going to use unstable external libraries on production  =)\n:+1: to close the issue.\nPlease correct me if i'm wrong ;)\n. If i understand Paul's https://github.com/socketstream/socketstream/issues/381#issuecomment-26125271 right, all we need is just add *.map files serving inside the code directories.\nProbably couple of lines of code, just nobody signed yet -)\n. @paulbjensen ,\nYep, forgot to put that, thanks. We need to update README for this.\n. Hi, \nGuys, just keep in mind, that code has not been linted yet, and it's a huge task ;)\np.s. I almost done with test folder: linting + grunting and once do this i would move my focus to the rest of the  code base.\n. Hi Paul,\nSorry, my bad, I broke original indents in package.json and during restoring made a mistake.\n. @paulbjensen, look like travis-ci.org doesn't have grunt-cli installed. Let me go into this problem, i'll be back soon.\n. @paulbjensen, yeah, already found that too =)\nOk, looks like to have grunt-cli installed locally not so bad.\nI always preferred local dependencies, i do now why i used global this time.\n. You are welcome,\nYes, Grunt 0.4.x requires Node.js version >= 0.8.0. OpenShift supports git hooks which allow to use any of node.js versions. OpenShift has really weird implementation for this.\nAt the same time SocketStream 0.4 requires node.js >= 0.8.0 , because of Streams2 i guess.\n. Done and passed.\n. For now project has 3 test files =) So it's not a big deal to move to NodeUnit. When I started to use TDD and BDD approaches it became clear pretty fast that Mocha, Jasmine, etc. frameworks lack for this issue. I like BDD code writing style, but to be honest in my example NodeUnit looks almost like BDD. One thing, NodeUnit doesn't support nesting as Mocha does, but it does support groups (i do not like deep nesting - i like simplicity), so code may look like:\n``` JavaScript\nexports.GroupName = function (test) {\n    ...\n}\nexports.HttpServer = {\n    setUp: function() {\n    },\n    tearDown: function() {\n    },\n    \"Should start\": function (test) {\n        ...\n    },\n    \"Should stop\": function (test) {\n        ...\n    }\n}\n```\nHere is how i see both frameworks\nNodeUnit:\n\n[ ] BDD \n[ ]  before() / after() - function calls before all tests, But NodeUnit first test in a group always runs first, wthe \n[ ] Tests nesting, not sure if it's a benefit especially for async code\n[x] TDD \n[x] Built-in assertion module\n[x]  test.expect(22) - settable assertions amount, good for testing async functions\n  same with the last test\n[x]  beforeEach() / setUp()\n[x]  afterEach() / tearUp()\n[x] Grunt plugin officially support by team (https://github.com/gruntjs/grunt-contrib-nodeunit)\n\nMocha:\n\n[ ] TDD \n[ ]  test.expect(22) - settable assertions amount, good for testing async functions\n[ ] Grunt plugin officially support by team (https://github.com/pghalliday/grunt-mocha-test)\n[ ] Built-in assertion module\n[x] BDD \n[x] Tests nesting\n[x]  before() - function calls before all tests, but first test in group always runs first\n[x]  beforeEach() / setUp()\n[x]  afterEach() / tearUp()\n\nIn my projects i use NodeUnit for server tests and Karma/Jasmine for e2e.\nWould like to hear any thought about it, maybe i'm wrong somewhere...\n. @paulbjensen , I'll do that. have never heard about Istanbul, but i found Grunt a task https://github.com/taichi/grunt-istanbul so we can use it =)\n. @paulbjensen , do you mean that you are not be able to create nested test tree as describe here https://gist.github.com/repeatingbeats/799136 ;)\n. Hi Paul,\nThanks for the wide answer -) Fair enough. \nBtw i make nodeunit syntax look pretty convenient -)\n\n. Hi @shannonmoeller,\nI wrote test in incorrect way by propose to show that we need to use assertion counting especially with async code. So one missed callback could be uncaught. In another universe where developers write code with no mistakes we do not need it ;)\n. Sorry, wrong branch.\n. ### Update\n- Added 'async' to devdependencies library for async test purpose\n- 'lib/cli/generate.js' linted and beautified\n- To test/unit/cli/generate.test.js added test for default folders on project generation\n@paulbjensen, what do you think about syntax style which I applied in lib/cli/generate.js, to me it's convenient, because al the private statements go under var including functions and then go exports.* and public stuff like that, ex: \n``` JavaScript\n/*\n * New App Generator\n * -----------------\n * Generates skeleton files needed to create a new SocketStream application\n /\n\"use strict\";\nrequire('colors');\nvar fs       = require('fs'),\n    path     = require('path'),\n    util     = require('util'),\n    log      = console.log,\n    dir_mode = '0755',\n// Private\nsuccess = function(name, alternative) {\n  return log(\" \u2713\".green, name, (alternative || '').grey);\n},\n\n// TODO - investigate whether this would be better\n// using the async version of fs.mkdir - PJENSEN\nmakeRootDirectory = function(name) {\n  ...\n\n};\nexports.generate = function(program) {\nvar appjs,\n      codeExtension = program.coffee && 'coffee' || 'js',\n      selectedFormatters = [],\n...\n``\n. Forgot to add that test app generates intotest/results/tests_app_name` to keep root directory clean from test stuff.\n. Hi Paul, \nI'm thinking also about using something like https://github.com/isaacs/minimatch for paths filtering.\nWe can even assign is to ss.api. So setting for files/dirs paths corporation could be the same as Grunt.js uses, which is pretty handy:\nJavaScript\n['tmp']\n['tmp/*']\n['tmp/*.js']\n['tmp/**/*.js']\n['tmp/**/*']\n. Hi Paul,\nThanks, sorry about misspelling, good eye! \nAgree, about minimatch, i think it would be good to put it into lib/utils/fille.js (since SS has all the file system related method there)\nI renamed brosefyExcludePaths to browserifyExcludePaths and I'm going to update docs...\nDo you want to merge it now or wait until minimatch be added?\n. Paul, i just tried demo app created from my pull request, with and w/o browserifyExcludePaths, but i wasn't be able to reproduce. Could you share your code at app.js:25:11 ?\n. No worries, on my way home I was thinking about npm link, but you was faster =)\n. Hi @paulbjensen,\nyeah, my bad, sorry about that.\nBut about case i was looking into \nhttp://www.w3.org/International/O-HTTP-charset\nhttp://www.w3.org/International/questions/qa-headers-charset\nAccording to http://www.ietf.org/rfc/rfc2616.txt\n\n4.2 Message Headers\n...\nEach header field consists of a name followed by a colon (\":\") and the field value. Field names  are case-insensitive.\n\nWe probably can search/add/replace for <meta charset=\"utf-8\">, maybe on asserts packing, w/o asserting it doesn't really need. What do you think?\nAdded fix, thanks!\n. Hi Paul, \nSure, no rush, feel better!\n. You are welcome, Paul! \nYes, i'm using it as a Chrome extension, pretty convenient.\nAlso Chrome->Tools->Developer Tools->Network (tab) shows requests info and has a column `Size/Content: loaded asset/file size (gziped in our case) vs. original size.\nIn my case number for the main HTML changed from 20KB to 4.2KB \n. Cool idea! :+1: \n. My concern is:\nJavaScript\nfunction RPC(req,res,ss){\n  this.req = req;\n  this.res = res;\n  this.ss = ss;\n}\nIt's kinda annoying to put it in each file within server/rpc folder. Maybe it's better to put it outside RPC files. For example put it under ss.api?\n. Hi guys,\nI still think that we need to add code from https://github.com/socketstream/socketstream/pull/407#issuecomment-26646519 to SocketStream src. Not sure where exactly, probably should be in ss.api, maybe inside lib/socketstream.js:\nJavaScript\napi.add('rcpProvider', function(){\n  ...\n  });\n};\nStill kind of ugly, but i think since SS is a framework it should not be up to user, too complicated =)\n...or maye  should be something like following inside app.js:\n``` JavaScript\nvar ss = require('socketstream');\nss.use('rcpProvider');\n```\nThoughts?\n. Hi everyone,\nAn update, I'm finishing linting/testing for lib/http/, PR will be in a few days.\n. Hi @kulicuu,\n==  compares values:\njavascript\n5 == \"5\" // true\n=== compares values and types:\njavascript\n5 === \"5\" // false\nit's better to use === to be sure that values types match.\nSorry about that, in the future I'll notify about the files I'm working on in advance.\n. A little delay over here,\nI used supertest for HTTP testing and discovered an error in terms of using it with Mocha and Assertion counting (it's why prefer I Nodeunit over Mocha with native JavaScript's Object extension ), so I fixed the problem and waiting right now for PR approval https://github.com/visionmedia/supertest/pull/89\n. Is anybody working on anything from the list?\n. Hi Paul,\nThanks for corrections. Fell fee to correct me any time, since english is my second language i'm not a best doc writer =)))))\nI reviewed lib/utils/file.js and found that:\n1. I made refactoring wrong at the first time\n2. We didn't have any tests for public method .readDirSync() in lib/utils/file.js\nSo i did re-refactor the code and added tests:\n1. Fixed description for function isDir() in lib/utils/file.js https://github.com/socketstream/socketstream/pull/410#commitcomment-4411445\n2. Added description for functions and public methods in lib/utils/file.js\n3. Updated public method .readDirSync() in lib/utils/file.js, removed unnecessary variables and IF statements\n4. Added tests and fixtures for .readDirSync()\n. One more update:\n1. Fixed methods descriptions in lib/utils/file.js\n2. Added description and test for .loadPackageJSON() in lib/utils/file.js\n. Paul, there are some errors @travis, let me check...\n. We good.\n. Thanks @pygy , i do my best =)\n. Thanks Paul! I'm preparing a next shot =)\n. Hi everyone!\nI know that you guys already working on a doc site, but I also was looking for solution and finally I found it.\nYou all know Angular.js and it's team came up with quite useful documentation approach, which is in kipping documentation inside source code for consistency.\nAlso that approach allows easily generate docs from source code. So I spent some time and finally figure out how we can use it.\nPlease check out what i got http://romanminkin.github.io/socketstream/docs/\nMy idea was to find a way of generating docs so we can focus on actual development.\nThis is what I have done:\n1. Added  https://npmjs.org/package/grunt-ngdocs - Grunt plugin to create a documentation like AngularJS, and set up Grunt tasks for docs generation\n2. Set up GitHub Pages\n3. Set up account for 3rd party comment platform http://disqus.com\n4. Moved few tutorial examples from original docs to https://github.com/RomanMinkin/socketstream/tree/feature/docs-generator/src/docs , it was not hard generator can work with Mardown format, all i have done is just changed source code examples wrapper  to <pre>\n5. Changed source code description a bit so it match the pattern for lib/http/*.js and lib/utils/file.js\nI just made a small piece to show you how it can look like. If you choose to go with this one, then it relatively easy to support documentation like this.\nEspecially with Grunt tasks for generation.\nSo we can finally have:\n1. Unified way for source code and API documentation creating and support\n2. Unified way for Tutorials documentation creating and support\n3. All in one repository\n4. 3rd party comments platform\n5. On site search through docs/API entries\n6. Free hosting from GinHub\n7. Time saving, so we can work on the project within one repository and do not spend time for supporting ss-home\nI can help with settings.\n. Here are some files which i used for doc generator:\n- https://github.com/RomanMinkin/socketstream/blob/feature/docs-generator/lib/http/index.js\n- https://github.com/RomanMinkin/socketstream/blob/feature/docs-generator/lib/http/router.js\n- https://github.com/RomanMinkin/socketstream/blob/feature/docs-generator/src/docs/tutorials/authentication.ngdoc\nAlso different CSS styles could be applied, my goal was to show that we can minify manual work.\n. I glad you like it guys!\n@paulbjensen , I can finish all docs, create Grunt task for submitting docs to gh-page branch, so literally our work will be just changing the src and running Grunt tasks and promote a PR.\n@americanyak , no worries, i have spent a few month until i finally found simple solution for usage. As i said before i think that developers should be focused on development and all the workflow processes should be automated as much as possible. Would appreciate if you help out with applying styles, once docs generator will be on place. Design is not really my thing =)\n. Hi Paul,\nMy bad, i did update compress version and i didn't' notice that they deprecated compress and staticCache middleware:\nhttps://github.com/senchalabs/connect#middleware\nThese middleware are officially supported by the Connect/Express team:\n- compression - previously compress\nThese middleware previously included with Connect are no longer supported by the Connect/Express team. Use one of these alternatives intead:\n- cookieParser\n  - cookies and keygrip\n- limit\n  - raw-body\n- multipart\n  - connect-multiparty\n  - connect-busboy\n- staticCache\n  - st\np.s. I changed compress version back for now.\n. Ha, i wanted to start topic like that after we figured out docs stuff, but Robert beat me, and i glad that he did it =)\nI agree that new SocketStream needs refactoring and new approach as we started to have it in 0.3.x\nHere are my thoughts. New approach should be centralized instead of decentralized (as it is right now with many separate repositories). Why? Because user (i mean people who use SS) can not keep tracking on multiple ss-* branches and figured out what is if officially supported module and what is not. Users want consistency, stability and simplicity when he get into a new project.\nSo my approach is in having ONE main repository with structure like this:\n/\n    index.js\n    package.json\n    modules/\n        prism/\n            index.js\n            ...\n        rts/\n            index.js\n            ...\n        rts-stream/\n            index.js\n            ...\n        spa/\n            index.js\n            ...\n        spa-livereload/\n            index.js\n            ...\nSo the root index.js is just a proxy require and any module (not from node_modules) can be require within a project as:\nJavaScript\n     var rts     = require('socketstream')('rts'),\n           prism = require('socketstream')('prism');\nBenefits of this approach are:\n- one consistent repository \n- easy to maintain src\n- easy to maintain docs\n- easy to write and run integrated tests (tests which involve multiple modules)\n- easy to to navigate between source code\n- easy for user and new coming to understand what project is\n- finished boxed product\n- in terms of minification and specific builds i can create Grunt task for building custom sets, which can be invoked  like:\n$ grunt build:prism:rts:spa\nAgain if somebody wants to use for example rts, he can install socketstream and just requires what he needs:\nJavaScript\nvar rts = require('socketstream')('rts');\nSo all the third party modules would be just:\nJavaScript\nvar module = require('ss-module');\nI came up with this after i spent some time of figuring out ss 0.4.x dependencies, it was so hard. We defiantly need to move from complicity so simplicity.\nSo what i'm trying to say, yes we need to abandon 0.4 as it is right now and refactor it into, as Robert said, 0.5\nI also like versioning which node.js and angular.js teams are using, it's a semver where even second digit 1.2.x means stable version, and odd means unstable 0.3.x(http://blog.angularjs.org/2012/07/angularjs-10-12-roadmap.html)\nWhat do you think, guys?\n. Hi @ignlg,\nThanks for dong that!\nFYI Makefile has been deprecated instead we are using grunt test for running tests. Checkout CONTRIBUTING.md#working-with-source-code for detailed information.\np.s. Makefile should be removed, i do not  know why we are still keeping it =)\n. Hi @ignlg, thanks!\np.s. since we are using web hook for travis-ci.org it's not necessary to post image with passed tests =) Just a time saver and you always can track your PR's build status.\n. @paul, could you please enable gh-pages support in project settings? I do not have an access there.\n. @paul, please disregard my request, it's working http://socketstream.github.io/socketstream/docs/\nBut it would be cool if you can assign DNS to gh-pages.\n. Hi Paul, \nRight, right, i was doing multiple projects yesterday, i messed it up =)\nNot DNS, could you change menu item 'Docs' link on left hand side at http://socketstream.org from\nhttp://socketstream.org/docs/0.3\nto\nhttp://socketstream.github.io/socketstream/docs/\nSo people who landed on web site be able to read the docs  =)\nAnd yes, we can change styles, i was trying to apply styles from https://github.com/socketstream/ss-home, but decided to come up with docs generation functionality first.\n. Thanks guys!\nPlease use Git Commit Guidelines in future commits and PR's.\n. Hi Evan, \nThanks for doing this, right now we are focusing on linting/testing (https://github.com/socketstream/socketstream/issues/408) to be able to work with PR more efficient. \nLong story short, would be great if @paulbjensen can also take a look, my concern is that we do not have test coverage for that part of code.\nI think passing ss as a parameter around doesn't seem right. Maybe there is a way to use dedicated file let's say log.js, require it around with node.js require and in the end assign it to ss object. Then i think it will not be necessary to pass ss.\n. Hi @kulicuu,\nNot really =) The problem is that code base has mix of console.log, ss.log, ect. calls. So we need to replace them all with common log API, which could be hook to whatever developer wants to hook it or just stream into stdout and stderr.\n. Hi Evan,\nVery cool! Code is much cleaner now, thanks!\nDo you mind to add for lib/utils/log.js\n1. docs notation for as example you can use this one lib/utils/file.js#L82 , the way it show up in our new docs site;\n2. some tests, should be pretty simple , mostly tests for method existence\nPlease checkout our Guidelines for Documentation generation\n. Yeah, Git commit guidelines recently added, it would be great to have, but since your PR was submit before PR git commit guidelines where merged would be cool if you add just one commit with anchor, something like:\n``\nfeat(utils): Addss.api.log` unified logging API\nBREAKING CHANGES\nUse this this instead of that\n```\n. Hi Evan,\nThanks a lot! Let me go through it.\n. One more thing, I just run demo app and there is no output in console, can we make defaults as:\nJavaSctipt\n  l.debug = console.log;\n  l.info  = console.log;\n  l.warn  = console.log;\n  l.error = console.error;\nOtherwise we need to update demo app, which will make it more complicated for new comings =)\nThanks again for your time and test/docs coverage, I really like you clean code style linted and with no white spaces =) Looks like grunt started to give his benefits, i hope we will cover all the project soon =) \n. Thanks Paul, agree, but I think that complete linting/testing should be done as a separate PR according to https://github.com/socketstream/socketstream/issues/408 Juts too much for this PR   imho =)\nSo I would prefer to merge it now to avoid much complications.\n. Well, then tags are perfect place for them =)\nI just noticed that those branches confused new comings.\nDone.\n. Thanks @malditogeek, much better now ;)\n. I like activity tab https://gitter.im/socketstream/socketstream\n. Hi @Waxolunist,\nFonts should be within /client/static folder, let say /client/static/fonts/\nYou also need to change path to all the fonts in all the css files to be relative to /client/static folder, for example:\ncss\n@font-face {\n  font-family: 'FontAwesome';\n  src: url('/fonts/fontawesome-webfont.eot?v=4.0.2');\n  src: url('/fonts/fontawesome-webfont.eot?v=4.0.2#iefix') format('embedded-opentype'), url('/fonts/fontawesome-webfont.woff?v=4.0.2') format('woff'), url('/fonts/fontawesome-webfont.ttf?v=4.0.2') format('truetype'), url('/fonts/fontawesome-webfont.svg?v=4.0.2#fontawesomeregular') format('svg');\n  font-weight: normal;\n  font-style: normal;\n}\n. Got you, answering you question:\nIt's not a big issue, but why do requests to _serveDev get parsed different, than those to assets?\nIt because of internal middleware, which intercepts request before router's middleware: https://github.com/socketstream/socketstream/blob/master/lib/http/index.js#L55\nTo archive you goal we need to change the request/respond model in general, because it has been developed the way to serve assets from hard-defined/static directories.\nI already was thinking about it already, especially how to make SS support Best Practice Recommendations for Angular App Structure\n. @Waxolunist, are you using Express? In this case you can try to add an additional static folder \njavascript\napp.use('/fonts', express.static(path.join(__dirname, 'bower_components/bootstrap/fonts')));\np.s. there is also should be a way to do it with default connect...\n. Hi @Waxolunist,\nFirst of all thanks for righting that!\nSorry for delay. I see what you say. I'm facing the same issues right now, especially when i'm trying to implement recently released Best Practice Recommendations for Angular App Structure\nSo i do understand that eventually SS needs to support more abstract way for assets managing.\nAs may know we abandoned 0.4 version. But even v0.4 had the same assets delivery pattern as v0.3 has right now.\nI have never work with both http://www.metalsmith.io/ and http://gulpjs.com/, so let me check them out.\nit's could be workaround for v0.5, so do you think you would be able to contribute? Unfortunately there are only few people in the project right now who do contribute.\nLet me know what do you think.\n. @thepian , no i made this one https://github.com/RomanMinkin/ss-angular-templates it uses custom formatter function.\nI like streaming idea API idea. What do you think about https://github.com/isaacs/node-glob or https://github.com/wearefractal/vinyl-fs?\ngulp uses the second one.\n. @thepian i did not use them, i found custom template function more powerful.\n. Hey guys, when I was adding ng-docs I also was looking for a better solution, but i did not find anything better at that tome. I was targeting two goals:\n1. Make docs searchable with no back-end required\n2. Internal SecketStream API support, since it's an open source project\nSo ng-docs to me is more like docs provider than docs generator.\nRight now I would take a look at https://stripe.com/docs for 101/Guides and for API make sense to keep ng-docs. Here is a big difference between people who whats to use SS and who wants to contribute.\n. ...forgot to add that I also bright ng-docs for automated change log generation https://github.com/socketstream/socketstream/blob/master/CHANGELOG.md\n. Hi guys it was me, who sent this PR, looks awful  tho ;)\nI wan you to consider using https://waffle.io/socketstream/socketstream for project and PR request management. I'm using it at my work and It's free for open source.\n. @arxpoetica, It's like https://trello.com but works with existing Github issues. or lets say it's like minified sexy JIRA for Github ;)\nHere is an example how Ionicframwork's team uses it https://waffle.io/driftyco/ionic\n. ",
    "pygy": "I built a quick workaround.\nPut this as ss-npmclient.js at the root of your project, add the relevant module names in the modules array, and run it.\nIt will compile everything and put it in client/code/system/npm.js. From your client code, you can then \nJavaScript\nnpm = require(\"npm\");\nuuid = npm[\"node-uuid\"];\nAll modules referenced in the script below end up in the npm namespace.\nAs it is now, it picks the modules from the node_modules directory at the root of your project. It could be easily  adapted to use a custom set.\nIt requires browserify to be installed system-wide, and will require some modifications to run on Windows.\nTODO: morph it into a full-fledged npm module that extracts info from package.json. \nss-npmclient.js\n``` JavaScript\n! /usr/bin/env node\nmodules = [\"node-uuid\"];\ndest = \"client/code/system/npm.js\";\nbrfcmd = \"browserify\"\ntmpfile = \"__ss_npmclient.tmp\";\nfs = require(\"fs\");\ncp = require(\"child_process\");\nexp = [];\nfor (_i = 0, _len = modules.length; _i < _len; _i++) {\n  m = modules[_i];\n  exp.push(\"exports[\\\"\" + m + \"\\\"] = require (\\\"\" + m + \"\\\");\");\n}\nfs.writeFileSync(tmpfile, exp.join(\"\\n\"));\nbr = cp.execFile(brfcmd, [tmpfile]);\nsrc = [];\nbr.stdout.on(\"data\", function(data) {\n  src.push(data);\n});\nbr.on(\"exit\", function(code) {\n  src = src.join(\"\");\n  pattern = /require(\\\"__ss_npmclient.tmp\\\");\\n})();/;\n  fs.writeFileSync(dest, src.replace(pattern, \"module.exports = $&\"));\n  fs.unlinkSync(tmpfile);\n});\n```\n. a mixin? Sure.\nJavaScript\nvar common_responders = require(...);\n_.extend(RPC.prototype, common_responders);\n. It wouldn't break any normal looking code, since this in the current version is useless.\nI can think of the following breaking behaviors, none of which are likely to occur in practical code:\nJavaScript\nreturn {\n    foo: function(i){ i = i ? parseInt(i,10) : 0; this.call(this, ++i) }, // A stack? Which stack?\n    bar: function(){ if (typeof this !== 'function') throw \"Eeewww\"),\n    baz: function(){ this.__proto__.quux = 6 } // relyng on the fact that \n                                               // Function.prototype is \"global\".\n}\nTo make it short, code that doesn't rely on the nature of this in the handlers will be fine.\n. Still not convinced it should make it for 0.3.3?\nWith the current code, the method object is thrown away after being called. I don't think anyone would use any of the above patterns in real code...\n. I missed your reply too...\nFor all practical purposes the patch is backwards compatible, since the old behavior is still available, bar some quirky abuse of the fact that this in the handler is currently the handler itself, which isn't even documented. I would seriously question the sanity of anyone who would rely on this...\n. > will it need jail break ?\nWhy would it? socket.IO-objc is just an Objective C library. AFAIK,\naccessing sockets is not restricted for iOS apps.\n. I suppose it will complain if you pack the assets, though.\nYou could make a special case and ignore source maps in production mode.\n. You could perhaps disable JSHint for now, then... or update the contributors file to reflect the issue?\n. You need one per API, since you attach the methods to the prototype.\n``` JavaScript\n// store this wherever relevant... \nfunction factory (actions) { // I'm sure there's a better name :-)\n  var RPC = function (req,res,ss){\n    this.req = req;\n    this.res = res;\n    this.ss = ss;\n  }\n  RPC.prototype = actions\n  return RPC\n}\n```\nThen, in server/rpc/demo.js\nJavaScript\nRPC = factory({\n  sendMessage: function(message) {\n    // ...\n  }\n})\n. > Code snippet of example usage possibility?\nIt's all in the first post. Contrast with server/rpc/hello.js.\n. BTW, thanks for accepting this :-)\n. I don't know where to put this either, since files in API are not supposed to require SocketStream. The ss.api object is injected in the exports.actions callback, but the provider must be called outside of it if you want it to be useful.\nMaybe you could put it as a small helper file, either in app/server or in app/server/rpc, using the filter option of apitree to exclude it from the API.\n. Roman this is awesome. I'm glad to see more life poured into this project :-).\n. Isn't it overkill? I'd rather have a grunt task generate static pages from the main repo... \nAdvantages aplenty: server load, googlabiliy, and many others I can't think of right now ;-)\nAny of https://github.com/bevry/docpad, https://github.com/jnordberg/wintersmith or https://github.com/flatiron/blacksmith would do...\nIs there a repo for the web site?\nHaving too many repos is a bad idea. It makes it harder for potential contributors where to find what they're interested in. \nFor that reason, I'm not too keen on the v0.4 approach, which not only modularizes the code (good) but scatters its implementation all over the place.\nI think that everything that is developed by the core team, which is slowly taking form, should be in a central repository. \nOne big, busy changelog is far more motivating than may small ones. It makes the project look alive to external folks too, which is imprtant after the hiatus (Zombie Jesus is back for your brains :-). There's a good vibe around the project right now and we should capitalize on it.\nEncouraging other people to create and maintain external plugins is off course a good idea.\n\nOn another topic: I think it would be nice to separate the documentation for users, plugin writers and the core team (the latter can happily live in comments as it does now).\n. Cool, thanks :-)\nTangentially related: what do you think of this logo update?\n\nI have a few variations on the same theme.\n. Yes, I saw the new logo after doing this one, it is much better than the old one. You may want to use it in the README and make it larger on the site, it is barely recognizable... \n. \ud83d\udc4d \nWorks from here now.  . I built a quick workaround.\nPut this as ss-npmclient.js at the root of your project, add the relevant module names in the modules array, and run it.\nIt will compile everything and put it in client/code/system/npm.js. From your client code, you can then \nJavaScript\nnpm = require(\"npm\");\nuuid = npm[\"node-uuid\"];\nAll modules referenced in the script below end up in the npm namespace.\nAs it is now, it picks the modules from the node_modules directory at the root of your project. It could be easily  adapted to use a custom set.\nIt requires browserify to be installed system-wide, and will require some modifications to run on Windows.\nTODO: morph it into a full-fledged npm module that extracts info from package.json. \nss-npmclient.js\n``` JavaScript\n! /usr/bin/env node\nmodules = [\"node-uuid\"];\ndest = \"client/code/system/npm.js\";\nbrfcmd = \"browserify\"\ntmpfile = \"__ss_npmclient.tmp\";\nfs = require(\"fs\");\ncp = require(\"child_process\");\nexp = [];\nfor (_i = 0, _len = modules.length; _i < _len; _i++) {\n  m = modules[_i];\n  exp.push(\"exports[\\\"\" + m + \"\\\"] = require (\\\"\" + m + \"\\\");\");\n}\nfs.writeFileSync(tmpfile, exp.join(\"\\n\"));\nbr = cp.execFile(brfcmd, [tmpfile]);\nsrc = [];\nbr.stdout.on(\"data\", function(data) {\n  src.push(data);\n});\nbr.on(\"exit\", function(code) {\n  src = src.join(\"\");\n  pattern = /require(\\\"__ss_npmclient.tmp\\\");\\n})();/;\n  fs.writeFileSync(dest, src.replace(pattern, \"module.exports = $&\"));\n  fs.unlinkSync(tmpfile);\n});\n```\n. a mixin? Sure.\nJavaScript\nvar common_responders = require(...);\n_.extend(RPC.prototype, common_responders);\n. It wouldn't break any normal looking code, since this in the current version is useless.\nI can think of the following breaking behaviors, none of which are likely to occur in practical code:\nJavaScript\nreturn {\n    foo: function(i){ i = i ? parseInt(i,10) : 0; this.call(this, ++i) }, // A stack? Which stack?\n    bar: function(){ if (typeof this !== 'function') throw \"Eeewww\"),\n    baz: function(){ this.__proto__.quux = 6 } // relyng on the fact that \n                                               // Function.prototype is \"global\".\n}\nTo make it short, code that doesn't rely on the nature of this in the handlers will be fine.\n. Still not convinced it should make it for 0.3.3?\nWith the current code, the method object is thrown away after being called. I don't think anyone would use any of the above patterns in real code...\n. I missed your reply too...\nFor all practical purposes the patch is backwards compatible, since the old behavior is still available, bar some quirky abuse of the fact that this in the handler is currently the handler itself, which isn't even documented. I would seriously question the sanity of anyone who would rely on this...\n. > will it need jail break ?\nWhy would it? socket.IO-objc is just an Objective C library. AFAIK,\naccessing sockets is not restricted for iOS apps.\n. I suppose it will complain if you pack the assets, though.\nYou could make a special case and ignore source maps in production mode.\n. You could perhaps disable JSHint for now, then... or update the contributors file to reflect the issue?\n. You need one per API, since you attach the methods to the prototype.\n``` JavaScript\n// store this wherever relevant... \nfunction factory (actions) { // I'm sure there's a better name :-)\n  var RPC = function (req,res,ss){\n    this.req = req;\n    this.res = res;\n    this.ss = ss;\n  }\n  RPC.prototype = actions\n  return RPC\n}\n```\nThen, in server/rpc/demo.js\nJavaScript\nRPC = factory({\n  sendMessage: function(message) {\n    // ...\n  }\n})\n. > Code snippet of example usage possibility?\nIt's all in the first post. Contrast with server/rpc/hello.js.\n. BTW, thanks for accepting this :-)\n. I don't know where to put this either, since files in API are not supposed to require SocketStream. The ss.api object is injected in the exports.actions callback, but the provider must be called outside of it if you want it to be useful.\nMaybe you could put it as a small helper file, either in app/server or in app/server/rpc, using the filter option of apitree to exclude it from the API.\n. Roman this is awesome. I'm glad to see more life poured into this project :-).\n. Isn't it overkill? I'd rather have a grunt task generate static pages from the main repo... \nAdvantages aplenty: server load, googlabiliy, and many others I can't think of right now ;-)\nAny of https://github.com/bevry/docpad, https://github.com/jnordberg/wintersmith or https://github.com/flatiron/blacksmith would do...\nIs there a repo for the web site?\nHaving too many repos is a bad idea. It makes it harder for potential contributors where to find what they're interested in. \nFor that reason, I'm not too keen on the v0.4 approach, which not only modularizes the code (good) but scatters its implementation all over the place.\nI think that everything that is developed by the core team, which is slowly taking form, should be in a central repository. \nOne big, busy changelog is far more motivating than may small ones. It makes the project look alive to external folks too, which is imprtant after the hiatus (Zombie Jesus is back for your brains :-). There's a good vibe around the project right now and we should capitalize on it.\nEncouraging other people to create and maintain external plugins is off course a good idea.\n\nOn another topic: I think it would be nice to separate the documentation for users, plugin writers and the core team (the latter can happily live in comments as it does now).\n. Cool, thanks :-)\nTangentially related: what do you think of this logo update?\n\nI have a few variations on the same theme.\n. Yes, I saw the new logo after doing this one, it is much better than the old one. You may want to use it in the README and make it larger on the site, it is barely recognizable... \n. \ud83d\udc4d \nWorks from here now.  . ",
    "kennethkoontz": "Thanks @owenb for the response!\nThe thread doesn't seem to help any. Looks like OP is trying to do the same thing as me but with no luck. This is what I'm doing. With express, I have a few routes that I respond to. However, I can't seem to get the session object in the req for example. One thing said in the thread is that it needs to be setup correctly. Which may be my problem as I'm not sure how to set it up so you can share sessions between ss and express 3.\napp.get('/', function(req, res) {\n  console.log(req.session) // is not defined.\n});\nI'll post more details in a few hours so you can see the whole picture.\n. @owenb So this is what I have right now.\n119 ss.session.store.use('redis');\n120 ss.client.templateEngine.use(require('ss-hogan'));\n121 ss.http.middleware.prepend(ss.http.connect.bodyParser());\n122 ss.http.middleware.append(ea.middleware());\n123 \n124 var app = express.createServer();\n125 app.use('/s', express.static(__dirname + '/server/static'));\n126 app.engine('jade', require('jade').__express);\n127 app.set('view engine', 'jade');\n128 app.set('views', __dirname+ '/server/views');\n129 app.locals({ layout: false });\n130 \n131 app.get('/', function(req, res){\n132   console.log(req.session);\n133   res.render('intro');\n134   //res.serveClient('main');\n135 });\n136 app.get('/about', function(req, res) {\n137   res.render('about');\n138 });\n139   \n140 \n141 server = app.listen(port);\n142 ss.start(server);\n143 \n144 app.stack = app.stack.concat(ss.http.middleware.stack);\n'req.session' in undefined in line 133. Any suggestions?\n. Thanks @owenb for the response!\nThe thread doesn't seem to help any. Looks like OP is trying to do the same thing as me but with no luck. This is what I'm doing. With express, I have a few routes that I respond to. However, I can't seem to get the session object in the req for example. One thing said in the thread is that it needs to be setup correctly. Which may be my problem as I'm not sure how to set it up so you can share sessions between ss and express 3.\napp.get('/', function(req, res) {\n  console.log(req.session) // is not defined.\n});\nI'll post more details in a few hours so you can see the whole picture.\n. @owenb So this is what I have right now.\n119 ss.session.store.use('redis');\n120 ss.client.templateEngine.use(require('ss-hogan'));\n121 ss.http.middleware.prepend(ss.http.connect.bodyParser());\n122 ss.http.middleware.append(ea.middleware());\n123 \n124 var app = express.createServer();\n125 app.use('/s', express.static(__dirname + '/server/static'));\n126 app.engine('jade', require('jade').__express);\n127 app.set('view engine', 'jade');\n128 app.set('views', __dirname+ '/server/views');\n129 app.locals({ layout: false });\n130 \n131 app.get('/', function(req, res){\n132   console.log(req.session);\n133   res.render('intro');\n134   //res.serveClient('main');\n135 });\n136 app.get('/about', function(req, res) {\n137   res.render('about');\n138 });\n139   \n140 \n141 server = app.listen(port);\n142 ss.start(server);\n143 \n144 app.stack = app.stack.concat(ss.http.middleware.stack);\n'req.session' in undefined in line 133. Any suggestions?\n. ",
    "coderarity": "thanks!\n. thanks!\n. ",
    "missinglink": "Related: https://github.com/LearnBoost/socket.io-client/issues/344\n. Related: https://github.com/LearnBoost/socket.io-client/issues/344\n. ",
    "unindented": "I agree with the crazy paths issue. The shared folder would be nice. Really looking forward to 0.4!\n. Awesome, thanks!\n. I agree with the crazy paths issue. The shared folder would be nice. Really looking forward to 0.4!\n. Awesome, thanks!\n. ",
    "hackable": "now ss-sockjs works! thanks\n. Can confirm when same changes are made ss-engine.io also works \n. issue resolved\n. packAssets doesn't pack css import dependencies into one file when in development the css import files are usually served from /_serveDev/css/libs/style.css but in production it  try to fetch it from /assets/libs/style.css and it would as normally return a 404 error unless one copies the file into /assets/ directory so i believe this needs to be fixed.\n. now ss-sockjs works! thanks\n. Can confirm when same changes are made ss-engine.io also works \n. issue resolved\n. packAssets doesn't pack css import dependencies into one file when in development the css import files are usually served from /_serveDev/css/libs/style.css but in production it  try to fetch it from /assets/libs/style.css and it would as normally return a 404 error unless one copies the file into /assets/ directory so i believe this needs to be fixed.\n. ",
    "strikeout": "im using \"nodemon\" to start socketstream and monitor the subdirs so I have instant server-side reloading, plus the client side reloading as well provided by socketstream.\nI bundled this in the npm start command for ease of use, edit your package.json and mod the npm start command to something like \n\"start\":\"npm install && nodemon -x 'iced' app.coffee \",  <<-- im using iced-coffee compiler instead of normal coffeescript for easy async coding, just omit the -x 'iced' part if you dont need it\n. I am developing a socketstream web/phonegap hybrid app and ran into the same issue (phonegap compiled apps cant reliably use cookies at all, only local storage/sqlite etc). \nWhat I did was using the awesome https://github.com/jeremydurham/persist-js to completly replace the connect cookie session-id storage and have engine.io take its websocket-session-id from the persist-storage instead, or ask the server to assign one. this also works with express based everyauth/passport authentication which require the connect.sid cookie for the oauth call-backs from facebook, twitter etc.\nif you like my approach, id be happy to share the code..\n. im using \"nodemon\" to start socketstream and monitor the subdirs so I have instant server-side reloading, plus the client side reloading as well provided by socketstream.\nI bundled this in the npm start command for ease of use, edit your package.json and mod the npm start command to something like \n\"start\":\"npm install && nodemon -x 'iced' app.coffee \",  <<-- im using iced-coffee compiler instead of normal coffeescript for easy async coding, just omit the -x 'iced' part if you dont need it\n. I am developing a socketstream web/phonegap hybrid app and ran into the same issue (phonegap compiled apps cant reliably use cookies at all, only local storage/sqlite etc). \nWhat I did was using the awesome https://github.com/jeremydurham/persist-js to completly replace the connect cookie session-id storage and have engine.io take its websocket-session-id from the persist-storage instead, or ask the server to assign one. this also works with express based everyauth/passport authentication which require the connect.sid cookie for the oauth call-backs from facebook, twitter etc.\nif you like my approach, id be happy to share the code..\n. ",
    "ignlg": "I know that this PR is a little old but I just want to note that it's important to be able to change the cookie key because some load balancers (and cloud services, cloudfoundry i.e.) expect a \"jsessionid\" cookie to balance load with sticky sessions. :)\n. As it was there I thought that it should be maintained. Otherwise it's garbage. Garbage day =)\n. My pleasure :)\n. There's documentation! I've been reading and hacking the code to properly understand the framework. Cool but time/energy/mood waster =( Kudos for this, @RomanMinkin!\n. I know that this PR is a little old but I just want to note that it's important to be able to change the cookie key because some load balancers (and cloud services, cloudfoundry i.e.) expect a \"jsessionid\" cookie to balance load with sticky sessions. :)\n. As it was there I thought that it should be maintained. Otherwise it's garbage. Garbage day =)\n. My pleasure :)\n. There's documentation! I've been reading and hacking the code to properly understand the framework. Cool but time/energy/mood waster =( Kudos for this, @RomanMinkin!\n. ",
    "rngadam": "Absolutely, I don't expect this to be merged immediately. Just wanted to check if if in the direction you want and try to figure out what I missed. Feel free to review line by line and tell me what I should improve.\n. Absolutely, I don't expect this to be merged immediately. Just wanted to check if if in the direction you want and try to figure out what I missed. Feel free to review line by line and tell me what I should improve.\n. ",
    "keepitsimple": "Yes. it looks like the issue was in our redis configuration settings.\n. Yes. it looks like the issue was in our redis configuration settings.\n. ",
    "vli": "How about http://jamuhl.github.com/i18next/ (clientside) and https://github.com/jamuhl/i18next-node (same but for node serverside) ?\n. How about http://jamuhl.github.com/i18next/ (clientside) and https://github.com/jamuhl/i18next-node (same but for node serverside) ?\n. ",
    "halfblood369": "Hi :\nThe commands of \" npm install -g socketstream\" and \"npm install hiredis\" all show the same stacktrace:\nmake || gmake\n'make' \u4e0d\u662f\u5185\u90e8\u6216\u5916\u90e8\u547d\u4ee4\uff0c\u4e5f\u4e0d\u662f\u53ef\u8fd0\u884c\u7684\u7a0b\u5e8f\n\u6216\u6279\u5904\u7406\u6587\u4ef6\u3002\n'gmake' \u4e0d\u662f\u5185\u90e8\u6216\u5916\u90e8\u547d\u4ee4\uff0c\u4e5f\u4e0d\u662f\u53ef\u8fd0\u884c\u7684\u7a0b\u5e8f\n\u6216\u6279\u5904\u7406\u6587\u4ef6\nI use windows 7.\nthank you!\nhalfblood369\n. Oh, thanks!\nMaybe should you mention it in the FAQ.\nThanks so much.\n2012/12/3 Paul Jensen notifications@github.com\n\nHi,\nYou will need to install 'make' for windows, which you can get here:\nhttp://gnuwin32.sourceforge.net/packages/make.htm\nOnce you've done that, make sure to reload your command prompt (so that\nmake is a known command), and then run the commands again.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/325#issuecomment-10950580.\n. Hi :\nThe commands of \" npm install -g socketstream\" and \"npm install hiredis\" all show the same stacktrace:\n\nmake || gmake\n'make' \u4e0d\u662f\u5185\u90e8\u6216\u5916\u90e8\u547d\u4ee4\uff0c\u4e5f\u4e0d\u662f\u53ef\u8fd0\u884c\u7684\u7a0b\u5e8f\n\u6216\u6279\u5904\u7406\u6587\u4ef6\u3002\n'gmake' \u4e0d\u662f\u5185\u90e8\u6216\u5916\u90e8\u547d\u4ee4\uff0c\u4e5f\u4e0d\u662f\u53ef\u8fd0\u884c\u7684\u7a0b\u5e8f\n\u6216\u6279\u5904\u7406\u6587\u4ef6\nI use windows 7.\nthank you!\nhalfblood369\n. Oh, thanks!\nMaybe should you mention it in the FAQ.\nThanks so much.\n2012/12/3 Paul Jensen notifications@github.com\n\nHi,\nYou will need to install 'make' for windows, which you can get here:\nhttp://gnuwin32.sourceforge.net/packages/make.htm\nOnce you've done that, make sure to reload your command prompt (so that\nmake is a known command), and then run the commands again.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/325#issuecomment-10950580.\n. \n",
    "kishorevarma": "will it need jail break ?\n. will it need jail break ?\n. ",
    "jcw": "It looks like this may have broken something. I'm no longer seeing rpc calls come in on the server:\nss.rpc 'host.api', 'fetch', (model) -> ...\nStill investigating... (code at https://github.com/jcw/homemon)\n. I think something changed recently: when I delete node_modules on the Mac and do \"npm install\" again, I get a socketstream 0.3.2 which lists engine.io \nSo now I have the same consistent situation on both Mac and Raspberry PI (my google group post) - both get a SS 0.3.2 with engine-io installed (both failing on my rpc calls - there's also ss-angular in there, so more things I need to check).\nMaybe that package.json change sneaked into the 0.3.2 release by accident? Maybe the github HEAD needs to be bumped to 0.3.2mod or something? I'm not yet familiar enough with npm versioning, so just guessing for now.\n. Curiouser and curiouser. I have indeed installed ss git head once, because I wanted to try out your new code. But all that is supposed to be gone now.\nHave removed the global ss. I still get the engine-io variant everywhere I try.\nHm, I've deleted ~/.npm/socketstream - that seems to restore the proper socket-io setup on the Mac. Progress!\nDoesn't explain why I still get engine-io on the RPi - that one never had any experimental code load. It's a brand new node/npm setup.\n. Ok, Mac resolved and consistent. It's all socket.io and working again now.\nOn RPi, I removed ~/.npm, there's nothing other than npm in the global repo. An npm install in a freshly checked-out homemon clone now gives me socket.io again.\nI have no idea what caused the previous mixup. Will be more careful with versions and git head installs from now on.\nSolved! Thank you for the help.\n. Hmm... are you launching the github clone with \"node app.js\"?\nSome new commits, though they should not affect this.\nAre you using git master? Is there an easy way for me to try that out (without messing up again)?\n. Ok, understand - great way to test with a different version. I just did the same here. And this narrows it down, I think:\nOriginal problem is showing up again: with 0.3.2, the rpc calls (i.e. host.platform and host.api) work and return info - with git master checkout of ss, neither of these two ever get called on the server (server/rpc/host.coffee).\nI'm not sure what to make of the output you mention. Can't see it here.\nI'm using the ss-angular package. Maybe there's an issue with that, not the ss switch to engine.io itself.\n. Sorry to bug you with this, and for the noise on this SS issue, but the homemon project has been renamed to housemon.\n. I've removed the ss-angular package, as I won't be using its approach to model synchronisation after all. This had an effect on some rpc calls, but the issue remains. Perhaps easier to narrow down, since the code is now simpler.\n. If you go to the \"Admin\" tab, you should see a few entries under \"Briqs\". These are obtained from the server via a \"host.api\" fetch RPC call. On my current setup, the list remains empty with the github version of SS. When I add a console.log call to engine/store.coffee, the state.fetch function never gets called (from the clients AppCtrl).\n. Aha, yes - progress! I can get the same message to appear. when putting this line at the end of entry.coffee.\nBut it looks like controllers.coffee never gets started, i.e. that same call doesn't trigger in there. I've tried moving all the Angular startup into the ss.server.on 'ready' callback, and that seems to make a difference. Not working yet, maybe the angular init is interacting with engine.io's startup sequence order.\nI'll try a couple more things - thanks!\nFYI, here's a screenshot of how it looks with the SS 0.3.2 version.\n. Ok, I can confirm that the ss.rpc host.api log call works inside ss.server.on 'ready' - not before\nDidn't find a way yet to make angular startup work that way, so the code in AppCtrl is being called too soon.\nSuccess! I've solved it by moving all RPC calls from Angular startup inside a second ss.server.on 'ready' call.\nSo all in all it works. I probably did things wrong before, but this bug only came to the surface with the engine.io change. New version checked in, but note that the latest code now connects to Redis (you can disable that in local.json).\nThank you for your help in figuring this out, Paul.\n. Oooh, that seems to be it, thanks Paul. Yep, I'm tracking the latest node.js releases during development.\nCould something like this be the way to implement a workaround?\nss.http.middleware.prepend (req, res, next) ->\n  res.on 'error', -> console.log 'http error ignored'\n  next()\nI can't easily force the error, I think.\n. Splendid - I've checked this in, thanks again. Closing the issue, as it's not really ss-specific after all.\n. Not sure we nailed this one... just got that error again, with the above fix included.\nMaybe I added this in the wrong place? Is there a way to somehow list the prepend / append chain?\nGoogling leads to some other reports with similar line numbers - this does still seem to point to 0.8.20:\n- https://github.com/ajaxorg/cloud9/issues/2683\n- http://stackoverflow.com/questions/15045730\n... and one on a Brazilian group: https://groups.google.com/forum/?fromgroups=#!topic/nodebr/MapramwuD98\n. The node world moves fast! Node.js 0.8.21 for Raspberry Pi also became available just now. And on the Mac, homebrew has also been updated. I've updated my 3 setups here now. Let's see how it goes!\n. Everything running fine now. Let's declare victory.\n. In HouseMon, you can install and uninstall modules from the client side - some of them add services on the server end, which then get called via rpc. They need to be removed again on uninstall, because otherwise you get an error when installing for the second time. I tend to avoid server restarts, because this is a long-running monitoring and data-acquisition setup.\nOn second thought - I could probably just \"install\" an empty server \"callback\" object, and then manage the HouseMon services there myself.\n. It looks like this may have broken something. I'm no longer seeing rpc calls come in on the server:\nss.rpc 'host.api', 'fetch', (model) -> ...\nStill investigating... (code at https://github.com/jcw/homemon)\n. I think something changed recently: when I delete node_modules on the Mac and do \"npm install\" again, I get a socketstream 0.3.2 which lists engine.io \nSo now I have the same consistent situation on both Mac and Raspberry PI (my google group post) - both get a SS 0.3.2 with engine-io installed (both failing on my rpc calls - there's also ss-angular in there, so more things I need to check).\nMaybe that package.json change sneaked into the 0.3.2 release by accident? Maybe the github HEAD needs to be bumped to 0.3.2mod or something? I'm not yet familiar enough with npm versioning, so just guessing for now.\n. Curiouser and curiouser. I have indeed installed ss git head once, because I wanted to try out your new code. But all that is supposed to be gone now.\nHave removed the global ss. I still get the engine-io variant everywhere I try.\nHm, I've deleted ~/.npm/socketstream - that seems to restore the proper socket-io setup on the Mac. Progress!\nDoesn't explain why I still get engine-io on the RPi - that one never had any experimental code load. It's a brand new node/npm setup.\n. Ok, Mac resolved and consistent. It's all socket.io and working again now.\nOn RPi, I removed ~/.npm, there's nothing other than npm in the global repo. An npm install in a freshly checked-out homemon clone now gives me socket.io again.\nI have no idea what caused the previous mixup. Will be more careful with versions and git head installs from now on.\nSolved! Thank you for the help.\n. Hmm... are you launching the github clone with \"node app.js\"?\nSome new commits, though they should not affect this.\nAre you using git master? Is there an easy way for me to try that out (without messing up again)?\n. Ok, understand - great way to test with a different version. I just did the same here. And this narrows it down, I think:\nOriginal problem is showing up again: with 0.3.2, the rpc calls (i.e. host.platform and host.api) work and return info - with git master checkout of ss, neither of these two ever get called on the server (server/rpc/host.coffee).\nI'm not sure what to make of the output you mention. Can't see it here.\nI'm using the ss-angular package. Maybe there's an issue with that, not the ss switch to engine.io itself.\n. Sorry to bug you with this, and for the noise on this SS issue, but the homemon project has been renamed to housemon.\n. I've removed the ss-angular package, as I won't be using its approach to model synchronisation after all. This had an effect on some rpc calls, but the issue remains. Perhaps easier to narrow down, since the code is now simpler.\n. If you go to the \"Admin\" tab, you should see a few entries under \"Briqs\". These are obtained from the server via a \"host.api\" fetch RPC call. On my current setup, the list remains empty with the github version of SS. When I add a console.log call to engine/store.coffee, the state.fetch function never gets called (from the clients AppCtrl).\n. Aha, yes - progress! I can get the same message to appear. when putting this line at the end of entry.coffee.\nBut it looks like controllers.coffee never gets started, i.e. that same call doesn't trigger in there. I've tried moving all the Angular startup into the ss.server.on 'ready' callback, and that seems to make a difference. Not working yet, maybe the angular init is interacting with engine.io's startup sequence order.\nI'll try a couple more things - thanks!\nFYI, here's a screenshot of how it looks with the SS 0.3.2 version.\n. Ok, I can confirm that the ss.rpc host.api log call works inside ss.server.on 'ready' - not before\nDidn't find a way yet to make angular startup work that way, so the code in AppCtrl is being called too soon.\nSuccess! I've solved it by moving all RPC calls from Angular startup inside a second ss.server.on 'ready' call.\nSo all in all it works. I probably did things wrong before, but this bug only came to the surface with the engine.io change. New version checked in, but note that the latest code now connects to Redis (you can disable that in local.json).\nThank you for your help in figuring this out, Paul.\n. Oooh, that seems to be it, thanks Paul. Yep, I'm tracking the latest node.js releases during development.\nCould something like this be the way to implement a workaround?\nss.http.middleware.prepend (req, res, next) ->\n  res.on 'error', -> console.log 'http error ignored'\n  next()\nI can't easily force the error, I think.\n. Splendid - I've checked this in, thanks again. Closing the issue, as it's not really ss-specific after all.\n. Not sure we nailed this one... just got that error again, with the above fix included.\nMaybe I added this in the wrong place? Is there a way to somehow list the prepend / append chain?\nGoogling leads to some other reports with similar line numbers - this does still seem to point to 0.8.20:\n- https://github.com/ajaxorg/cloud9/issues/2683\n- http://stackoverflow.com/questions/15045730\n... and one on a Brazilian group: https://groups.google.com/forum/?fromgroups=#!topic/nodebr/MapramwuD98\n. The node world moves fast! Node.js 0.8.21 for Raspberry Pi also became available just now. And on the Mac, homebrew has also been updated. I've updated my 3 setups here now. Let's see how it goes!\n. Everything running fine now. Let's declare victory.\n. In HouseMon, you can install and uninstall modules from the client side - some of them add services on the server end, which then get called via rpc. They need to be removed again on uninstall, because otherwise you get an error when installing for the second time. I tend to avoid server restarts, because this is a long-running monitoring and data-acquisition setup.\nOn second thought - I could probably just \"install\" an empty server \"callback\" object, and then manage the HouseMon services there myself.\n. ",
    "sand123": "As a temporary workaround I used this code before any ss.load.code\n$.ajaxPrefilter( function( options ) {\n        if ( options.url.indexOf('/_serve/')> -1 ) {\n            options.url =  'http://mysite.com:3000' + options.url;\n            options.crossDomain = true;\n        }\n    });\n. You should wait for server ready event, e.g.\njavascript\nss.server.on('ready', function(){ \n            ss.rpc('auth.user', function(res){\n                alert(res)\n            })\n})\nRemember also about  disconnect and reconnect events \n. I actually used 0.3.x branch in production and was satisfied with results, Now I'm starting another node rpc project from the ground and confused about SS as main framework - last commit almost 6 months ago. \n. As a temporary workaround I used this code before any ss.load.code\n$.ajaxPrefilter( function( options ) {\n        if ( options.url.indexOf('/_serve/')> -1 ) {\n            options.url =  'http://mysite.com:3000' + options.url;\n            options.crossDomain = true;\n        }\n    });\n. You should wait for server ready event, e.g.\njavascript\nss.server.on('ready', function(){ \n            ss.rpc('auth.user', function(res){\n                alert(res)\n            })\n})\nRemember also about  disconnect and reconnect events \n. I actually used 0.3.x branch in production and was satisfied with results, Now I'm starting another node rpc project from the ground and confused about SS as main framework - last commit almost 6 months ago. \n. ",
    "thebadger412": "Lol hi again..\nOkay I might be going crazy here but in api there is no publish..\n. I have created a file in /rpc called serial and in that just started playing with ss.api.publish\nbut it said no modules called publish..or it was undefined, so I started digging around \nso then I just created a random directory on computer, installed SS\nand then in node I can view all of ss's methods and when I look in publish or in api I cannot find anything we are talking about.. \nheres a gist\nhttps://gist.github.com/4543612\nHopefully you can see where I am looking, it doesn't appear that the channel method is anywhere?\n. Hey man, I can't get access to my computer with it on till monday,\nHowever I am having another issue with dashku you might be able to shed\nlight on..\nI have tried this on 2 comps now and same error, both ubuntu.. going to try\nwindows soon..\ncloned your dashku repo,\ngot mongo running\ngot redis running.. started it,\nWhen I click sign up though with my data input the server crashes with this\noutput..\nSegmentation Fault (core dumped)\n*\n*\nJust wondered if you have had this problem before?\nCheers\nOn 20 January 2013 00:42, Paul Jensen notifications@github.com wrote:\n\nHi, just wanted to ask if changing the path of the file from rpc/serial.js\nto server/rpc/serial.js did the trick?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/340#issuecomment-12463954.\n. Okay hi, so I am sure I am doing this wrong, I am a total newb but really want to get it working if you could help me..\n\nSo I am using dashku and as @paulbjensen mentioned to me in an email, if I want to communicate with one of his widgets I would have to put the following code in /server/rpc/serial.js\nss = require('socketstream');\nss.api.publish.channel(\"user_<MONGODB_ID_FOR_YOUR_USER>\", 'transmission', {_id: \"YOUR_WIDGET_ID\", randomDataAttribute: randomDataValue});\nSo I created the \"bigNumber\" widget and found out all the relevant id's\nso I have cloned his git and the only thing I have added is that one file in /server/rpc..\nhere is the entire contents of my file\nss = require('socketstream');\nss.api.publish.channel(\"user_<51019b9b821cf8db0d000002>\", 'transmission', {_id: \"51019fe9357865660e000014\", bigNumber: 212});\nand when I run coffee app.coffee I get the following error\nhttps://gist.github.com/4627704\nHopefully someone can just say.. oh no just add a semi colon and it all works wooo\n. I really appreciate the help but try as I might this thing will not work..\nOkay so just so we are clear, the only thing I have done is cloned the dashku git and then created the big number widget.. nothing else\nI am then creating this file \"server.coffee\" in /server/rpc..\nhttps://gist.github.com/4633233\nas you can see it has a few trials in there by me, all of them failed with the same error as before..\nI am thinking there is something else I must have to do to make this work.. like do I need to put some code in the widget or something? because at the minute I just don't know what to do..\nLike I want it so as soon as the server starts it sends this value to bigNumber.. \n. Lol hi again..\nOkay I might be going crazy here but in api there is no publish..\n. I have created a file in /rpc called serial and in that just started playing with ss.api.publish\nbut it said no modules called publish..or it was undefined, so I started digging around \nso then I just created a random directory on computer, installed SS\nand then in node I can view all of ss's methods and when I look in publish or in api I cannot find anything we are talking about.. \nheres a gist\nhttps://gist.github.com/4543612\nHopefully you can see where I am looking, it doesn't appear that the channel method is anywhere?\n. Hey man, I can't get access to my computer with it on till monday,\nHowever I am having another issue with dashku you might be able to shed\nlight on..\nI have tried this on 2 comps now and same error, both ubuntu.. going to try\nwindows soon..\ncloned your dashku repo,\ngot mongo running\ngot redis running.. started it,\nWhen I click sign up though with my data input the server crashes with this\noutput..\nSegmentation Fault (core dumped)\n*\n*\nJust wondered if you have had this problem before?\nCheers\nOn 20 January 2013 00:42, Paul Jensen notifications@github.com wrote:\n\nHi, just wanted to ask if changing the path of the file from rpc/serial.js\nto server/rpc/serial.js did the trick?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/340#issuecomment-12463954.\n. Okay hi, so I am sure I am doing this wrong, I am a total newb but really want to get it working if you could help me..\n\nSo I am using dashku and as @paulbjensen mentioned to me in an email, if I want to communicate with one of his widgets I would have to put the following code in /server/rpc/serial.js\nss = require('socketstream');\nss.api.publish.channel(\"user_<MONGODB_ID_FOR_YOUR_USER>\", 'transmission', {_id: \"YOUR_WIDGET_ID\", randomDataAttribute: randomDataValue});\nSo I created the \"bigNumber\" widget and found out all the relevant id's\nso I have cloned his git and the only thing I have added is that one file in /server/rpc..\nhere is the entire contents of my file\nss = require('socketstream');\nss.api.publish.channel(\"user_<51019b9b821cf8db0d000002>\", 'transmission', {_id: \"51019fe9357865660e000014\", bigNumber: 212});\nand when I run coffee app.coffee I get the following error\nhttps://gist.github.com/4627704\nHopefully someone can just say.. oh no just add a semi colon and it all works wooo\n. I really appreciate the help but try as I might this thing will not work..\nOkay so just so we are clear, the only thing I have done is cloned the dashku git and then created the big number widget.. nothing else\nI am then creating this file \"server.coffee\" in /server/rpc..\nhttps://gist.github.com/4633233\nas you can see it has a few trials in there by me, all of them failed with the same error as before..\nI am thinking there is something else I must have to do to make this work.. like do I need to put some code in the widget or something? because at the minute I just don't know what to do..\nLike I want it so as soon as the server starts it sends this value to bigNumber.. \n. ",
    "lge88": "Sounds good. I am looking forward to seeing the 0.4 version!\n. Sounds good. I am looking forward to seeing the 0.4 version!\n. ",
    "helozjisky": "https://github.com/socketstream/ss-jade\nss.client.formatters.add(require('ss-jade'), {locals: {countries: {}}});\n. https://github.com/socketstream/ss-jade\nss.client.formatters.add(require('ss-jade'), {locals: {countries: {}}});\n. ",
    "brunocoelho": "Should I follow JSLint patterns? There's much more things to change.\n. Could\n. Should I follow JSLint patterns? There's much more things to change.\n. Could\n. ",
    "kraz": "May be i can't explain it good - this is why i wrote a quick app to illustrate the issue:\nhttps://github.com/kraz/ss-pullreq-345\nLong story short:\nThe caching is indeed handled on the client - calling ss.load.code is working as expected (queries the server only at first request),\n\n~~on every client refresh~~, or new request\n\nBut imagine 100 different users keep refreshing the page. Every first call to ss.load.code will force the server to stuff an other (duplicated) value in the queryCache array but with different key because calling ss.load.code calls internally  $.ajax with cache:false which causes a random &_=1359143112452 to be appended on every request.\nThe if options.packAssets && queryCache[request.url] is never true. Because options.packAssets is always undefined and even if we set it to true in app.js the 'request.url` is always different because of the above ajax call method.\nThe issue is not that bad if the app is small with relatively small audience, but i have used to always test with the worst scenarios possible. Just imagine this with 100+ users and application loading (huge) code on demand depending on user pre configured request. Of course its sort of design issue also but still i see flaws in code base.\n. May be i can't explain it good - this is why i wrote a quick app to illustrate the issue:\nhttps://github.com/kraz/ss-pullreq-345\nLong story short:\nThe caching is indeed handled on the client - calling ss.load.code is working as expected (queries the server only at first request),\n\n~~on every client refresh~~, or new request\n\nBut imagine 100 different users keep refreshing the page. Every first call to ss.load.code will force the server to stuff an other (duplicated) value in the queryCache array but with different key because calling ss.load.code calls internally  $.ajax with cache:false which causes a random &_=1359143112452 to be appended on every request.\nThe if options.packAssets && queryCache[request.url] is never true. Because options.packAssets is always undefined and even if we set it to true in app.js the 'request.url` is always different because of the above ajax call method.\nThe issue is not that bad if the app is small with relatively small audience, but i have used to always test with the worst scenarios possible. Just imagine this with 100+ users and application loading (huge) code on demand depending on user pre configured request. Of course its sort of design issue also but still i see flaws in code base.\n. ",
    "Raynos": "@paulbjensen that requires browser plugins. I don't want that. I want something that works like live-reload.\ni.e. drop in a <script src=\"localhost:somePort\"></script> in your app and it's done.\n. I was looking at that. It would work. thanks.\n. @paulbjensen that requires browser plugins. I don't want that. I want something that works like live-reload.\ni.e. drop in a <script src=\"localhost:somePort\"></script> in your app and it's done.\n. I was looking at that. It would work. thanks.\n. ",
    "doraess": "The message that I receive is the following\nevents.js:123\n      listeners[i].apply(this, args);\n                   ^\nTypeError: Cannot call method 'apply' of undefined\n    at Socket.EventEmitter.emit (events.js:123:20)\n    at Socket._destroy.destroyed (net.js:357:10)\n    at process.startup.processNextTick.process._tickCallback (node.js:244:9)\n4 Feb 12:59:51 - [nodemon] app crashed - waiting for file changes before starting...\nAnd my function is the following...\nisoHunt: (query) ->\n    options =\n      uri: \"http://isohunt.com/js/json.php?ihq={0}&start=0&rows=20&sort=seed\".format(query)\n      followAllRedirects: \"true\"\n      followRedirect: \"true\"\n      method: \"POST\"\n    request.post options, (error, response, body) ->\n      if not error\n        ss.publish.all \"torrent\", response\n      else\n        console.log response.statusCode\nAs you can see, a very simple query for torrent list in IsoHunt\n. The message that I receive is the following\nevents.js:123\n      listeners[i].apply(this, args);\n                   ^\nTypeError: Cannot call method 'apply' of undefined\n    at Socket.EventEmitter.emit (events.js:123:20)\n    at Socket._destroy.destroyed (net.js:357:10)\n    at process.startup.processNextTick.process._tickCallback (node.js:244:9)\n4 Feb 12:59:51 - [nodemon] app crashed - waiting for file changes before starting...\nAnd my function is the following...\nisoHunt: (query) ->\n    options =\n      uri: \"http://isohunt.com/js/json.php?ihq={0}&start=0&rows=20&sort=seed\".format(query)\n      followAllRedirects: \"true\"\n      followRedirect: \"true\"\n      method: \"POST\"\n    request.post options, (error, response, body) ->\n      if not error\n        ss.publish.all \"torrent\", response\n      else\n        console.log response.statusCode\nAs you can see, a very simple query for torrent list in IsoHunt\n. ",
    "essentialjs": "It seems like a good options.\nJust as a note. This assumes that you would develop the bulk of the CSS in socket stream. I'm not sure I would do that. Instead I would statically build the bulk of the CSS in a site-wide css file and include that in the HEAD tag. Loading a small-ish CSS file in the body shouldn't be much of an issue, and as far as I recall CSS loading doesn't slow down the page load, as it is async. You just want it before the scripts so they don't delay when the page starts loading the CSS. Chances are that the only improvement is a 50ms reduction in CSS rendering of the page\n. I like the idea of exposing more to event listeners, but I think there is a very easy solution to this particular problem.\nI have solved it in an easy way. You can see it here.\nhttps://github.com/essentialjs/DemoApp/commit/a5d47569414a1d68ec5e9050e7799b2ea5cb6658\nI think the issue should be closed, as you can do it currently without much issue.\n. I'm working on an approach to build standalone assets. It does change the app.js but not the socket stream code. Any comments? \nhttps://github.com/thepian/ss-build\n. I think there are some thoughts in this thread that relate to \"What is Socketstream\". It would good to have an updated mission statement for Socketstream so people know what \"They are getting\".\nTo me r.js was an interesting solution that is appropriate in certain situations, but not the right one for public websites due to async requests nature. Browserify is good for that use case and should be the primary solution in Socketstream. We should actively discourage r.js, but we shouldn't actively support it as it is a very different concept.\nWe could refer to other peoples blogs/articles on the subject like:\nhttp://esa-matti.suuronen.org/blog/2013/03/22/journey-from-requirejs-to-browserify/\n. Please close this and grab #462 instead\n. On a sidetone less 2.0 also outputs source map, so the result is CSS and map, so two files\n. Another TODO is to provide an error CSS output that can be switched on/off with configuration for dev/prod/debug\n. It seems like a good options.\nJust as a note. This assumes that you would develop the bulk of the CSS in socket stream. I'm not sure I would do that. Instead I would statically build the bulk of the CSS in a site-wide css file and include that in the HEAD tag. Loading a small-ish CSS file in the body shouldn't be much of an issue, and as far as I recall CSS loading doesn't slow down the page load, as it is async. You just want it before the scripts so they don't delay when the page starts loading the CSS. Chances are that the only improvement is a 50ms reduction in CSS rendering of the page\n. I like the idea of exposing more to event listeners, but I think there is a very easy solution to this particular problem.\nI have solved it in an easy way. You can see it here.\nhttps://github.com/essentialjs/DemoApp/commit/a5d47569414a1d68ec5e9050e7799b2ea5cb6658\nI think the issue should be closed, as you can do it currently without much issue.\n. I'm working on an approach to build standalone assets. It does change the app.js but not the socket stream code. Any comments? \nhttps://github.com/thepian/ss-build\n. I think there are some thoughts in this thread that relate to \"What is Socketstream\". It would good to have an updated mission statement for Socketstream so people know what \"They are getting\".\nTo me r.js was an interesting solution that is appropriate in certain situations, but not the right one for public websites due to async requests nature. Browserify is good for that use case and should be the primary solution in Socketstream. We should actively discourage r.js, but we shouldn't actively support it as it is a very different concept.\nWe could refer to other peoples blogs/articles on the subject like:\nhttp://esa-matti.suuronen.org/blog/2013/03/22/journey-from-requirejs-to-browserify/\n. Please close this and grab #462 instead\n. On a sidetone less 2.0 also outputs source map, so the result is CSS and map, so two files\n. Another TODO is to provide an error CSS output that can be switched on/off with configuration for dev/prod/debug\n. ",
    "mdedetrich": "Would just like to say that I have been having the same issues, and setting the P3P header fixed my problem\n. Would just like to say that I have been having the same issues, and setting the P3P header fixed my problem\n. ",
    "leoj3n": "You might be interested in http://derbyjs.com/ or https://www.meteor.com/\n. What about http://opalang.org/ or https://github.com/vert-x/vert.x/ ?\n. Well, Opa is already a full stack and is pretty close to JavaScript: https://github.com/MLstate/opalang/wiki/A-tour-of-Opa#familiar-syntax\n. I'm stumbling around these frameworks too, this video is great: http://www.youtube.com/watch?v=LOS1lpWXphs\n@owenb Are you saying SocketStream is lacking basic routing at the moment?\u2014I need to test/play with SS. Tomorrow.\n. You might be interested in http://derbyjs.com/ or https://www.meteor.com/\n. What about http://opalang.org/ or https://github.com/vert-x/vert.x/ ?\n. Well, Opa is already a full stack and is pretty close to JavaScript: https://github.com/MLstate/opalang/wiki/A-tour-of-Opa#familiar-syntax\n. I'm stumbling around these frameworks too, this video is great: http://www.youtube.com/watch?v=LOS1lpWXphs\n@owenb Are you saying SocketStream is lacking basic routing at the moment?\u2014I need to test/play with SS. Tomorrow.\n. ",
    "pocesar": "I found both to be hacky... Meteor package spiderable is a hack to make page states visible to search engines through using Phantomjs because it doesn't render templates on the server and it's not ready for production... derby code is too messy IMHO, wacky app flow, and they enforce stuff. I don't want to use Racer or use their lousy Template engine.\n. I'm not really interested in learning a new language. I've skipped Ruby on Rails completely because of that. I'm really confortable with Javascript/Coffeescript, hence my eager to make the shift off PHP entirely\n. So, a mix of Express and SocketStream in the \"same\" framework, should do it? the only thing I see is that the server/client code sharing might be lost, and that's the real strength I was hoping for. The less code repetition, the better. I was thinking, like Foursquare main page for example, with all the activity that is going on in the website, without a long polling or interval AJAX requests. Is a websocket connection \"expensive\" compared to a stateless request, like AJAX over HTTP?\n@canted my PHP / Javascript library, phery, can make a website \"loadable\" by AJAX, loading only the parts that matter instead of loading the whole site everytime. However, the site can still work without Javascript, since the a tags retain their \"href\" functionality. So, the site is snappier, but at the same time, it's crawlable, since the template is rendered on the server side if it's not called through AJAX, got what I mean? \n. I've started my \"journey\" with a common interface for Socketstream and Express, along with all the bells and whistles people expect from a full blown framework, everything taken from npm, of course, why reinvent the wheel? I'm just making sense of the structure, the wrappers and let's see how it goes :+1: \nthanks for the insights\nEDIT: I'm just thorned if I should start the project using 0.4 prototype or stick with 0.3, hmmm\n. so be it, thanks for everything @owenb \n. I found both to be hacky... Meteor package spiderable is a hack to make page states visible to search engines through using Phantomjs because it doesn't render templates on the server and it's not ready for production... derby code is too messy IMHO, wacky app flow, and they enforce stuff. I don't want to use Racer or use their lousy Template engine.\n. I'm not really interested in learning a new language. I've skipped Ruby on Rails completely because of that. I'm really confortable with Javascript/Coffeescript, hence my eager to make the shift off PHP entirely\n. So, a mix of Express and SocketStream in the \"same\" framework, should do it? the only thing I see is that the server/client code sharing might be lost, and that's the real strength I was hoping for. The less code repetition, the better. I was thinking, like Foursquare main page for example, with all the activity that is going on in the website, without a long polling or interval AJAX requests. Is a websocket connection \"expensive\" compared to a stateless request, like AJAX over HTTP?\n@canted my PHP / Javascript library, phery, can make a website \"loadable\" by AJAX, loading only the parts that matter instead of loading the whole site everytime. However, the site can still work without Javascript, since the a tags retain their \"href\" functionality. So, the site is snappier, but at the same time, it's crawlable, since the template is rendered on the server side if it's not called through AJAX, got what I mean? \n. I've started my \"journey\" with a common interface for Socketstream and Express, along with all the bells and whistles people expect from a full blown framework, everything taken from npm, of course, why reinvent the wheel? I'm just making sense of the structure, the wrappers and let's see how it goes :+1: \nthanks for the insights\nEDIT: I'm just thorned if I should start the project using 0.4 prototype or stick with 0.3, hmmm\n. so be it, thanks for everything @owenb \n. ",
    "hairthing": "It is possible to have pre-rendered, crawlable, non-realtime pages served by express alongside the kind of signin-protected, realtime socketstream apps that Owen describes, which is useful for marketing pages and the like.\n. It is possible to have pre-rendered, crawlable, non-realtime pages served by express alongside the kind of signin-protected, realtime socketstream apps that Owen describes, which is useful for marketing pages and the like.\n. ",
    "rauchg": "@polidore a PR on engine.io is welcome if the issue is there\n. @polidore a PR on engine.io is welcome if the issue is there\n. ",
    "sukazavr": "Thanks a lot!\n. Thanks a lot!\n. ",
    "dzz0615": "Hi @owenb,\nThe file checks are to make sure certain files/directories are still browserified.\nWe need to browserify entry.js, since the app is started via require('/entry');\nThe system and shared directory also always gets browserified. This is for code where it does make sense to be wrapped in a module (e.g. libraries / modules shared with the server).\n. Hi @owenb,\nThe file checks are to make sure certain files/directories are still browserified.\nWe need to browserify entry.js, since the app is started via require('/entry');\nThe system and shared directory also always gets browserified. This is for code where it does make sense to be wrapped in a module (e.g. libraries / modules shared with the server).\n. ",
    "emgeee": "After some trial and error (downloading a lot of versions of node) I've managed to narrow it down to the Node 0.9.4 version of the release. Anyone see anything in the change log that might hint at why it broke?\n. I managed to figure it out and I figure  I'd leave behind some quick notes in the hope of helping someone else out in the future.\nTo begin with, I was able to get one server behind nginx working, however, I was looking for a solution that would scale linearly. This meant making use of nginx's round-robin feature to send different connections to multiple services. Unfortunately, this did not work out of the box because of engine.io's handshake procedure that first begins with XHR requests before upgrading to websockets. There was no guarantee that the same backend server would continue handling the requests so the connection was having a difficult time being established. As a note, when I disabled everything but websockets in engine.io, everything worked as expected, however I needed the XHR fallback so this wasn't really an option.\nTo get around this issue, the trick was to user the nginx stick sessions module found here: https://code.google.com/p/nginx-sticky-module/\nThis means that nginx will route a connection from the same client to the same server. Because sticky sessions relies on setting and reading cookies, we had to offload the SSL layer to nginx, which ended up being a good thing because it frees up more CPU cycles on our nodes for processing things.\nOther than those steps mentioned above, the only other thing we had to do was make sure all workers shared the same redis server. This ensures that no matter which worker a client's request gets routed to, their session persists. Also, using the node cluster module and running each socketstream instance on a different port, this method can be used to scale socketstream across multiple cores/CPUs on the same machine.\n. After some trial and error (downloading a lot of versions of node) I've managed to narrow it down to the Node 0.9.4 version of the release. Anyone see anything in the change log that might hint at why it broke?\n. I managed to figure it out and I figure  I'd leave behind some quick notes in the hope of helping someone else out in the future.\nTo begin with, I was able to get one server behind nginx working, however, I was looking for a solution that would scale linearly. This meant making use of nginx's round-robin feature to send different connections to multiple services. Unfortunately, this did not work out of the box because of engine.io's handshake procedure that first begins with XHR requests before upgrading to websockets. There was no guarantee that the same backend server would continue handling the requests so the connection was having a difficult time being established. As a note, when I disabled everything but websockets in engine.io, everything worked as expected, however I needed the XHR fallback so this wasn't really an option.\nTo get around this issue, the trick was to user the nginx stick sessions module found here: https://code.google.com/p/nginx-sticky-module/\nThis means that nginx will route a connection from the same client to the same server. Because sticky sessions relies on setting and reading cookies, we had to offload the SSL layer to nginx, which ended up being a good thing because it frees up more CPU cycles on our nodes for processing things.\nOther than those steps mentioned above, the only other thing we had to do was make sure all workers shared the same redis server. This ensures that no matter which worker a client's request gets routed to, their session persists. Also, using the node cluster module and running each socketstream instance on a different port, this method can be used to scale socketstream across multiple cores/CPUs on the same machine.\n. ",
    "krsch": "I have the same issue on Node v0.10.10. Everything is fine in npm version of socketstream (0.3.4), but this issue arises in master branch.git bisect finds SHA: 322ec0d. It fails even on the default ss app.\n. Ok, i'll try to change it on monday\n. Ok, i copied the change to src/websocket/transports/engineio/wrapper.js\n. I have the same issue on Node v0.10.10. Everything is fine in npm version of socketstream (0.3.4), but this issue arises in master branch.git bisect finds SHA: 322ec0d. It fails even on the default ss app.\n. Ok, i'll try to change it on monday\n. Ok, i copied the change to src/websocket/transports/engineio/wrapper.js\n. ",
    "pwldp": "I've found!\nIt was my mistake in application code.\n. I've set up nginx ver. 1.4.1 only with one SS backend and it works very fine. I've found those URLs useful:\n- http://siriux.net/2013/06/nginx-and-websockets/\n- https://chrislea.com/2013/02/23/proxying-websockets-with-nginx/\n. I've found!\nIt was my mistake in application code.\n. I've set up nginx ver. 1.4.1 only with one SS backend and it works very fine. I've found those URLs useful:\n- http://siriux.net/2013/06/nginx-and-websockets/\n- https://chrislea.com/2013/02/23/proxying-websockets-with-nginx/\n. ",
    "mattlenz": "@paulbjensen @RomanMinkin Thanks! This sent me in the right direction.\n. @paulbjensen @RomanMinkin Thanks! This sent me in the right direction.\n. ",
    "docgecko": "Ah, the socketstream simlink is created in:\njavascript\n/usr/local/bin\nIts not in the following where all my other npm symlinks are:\njavascript\n/usr/local/share/npm/bin\nI added the PATH to my $PATH and its working now.\nI know this doesn't really belong on this thread but, out of curiosity, do you know why npm has 2 possible locations for symlinks?\n. Ah, the socketstream simlink is created in:\njavascript\n/usr/local/bin\nIts not in the following where all my other npm symlinks are:\njavascript\n/usr/local/share/npm/bin\nI added the PATH to my $PATH and its working now.\nI know this doesn't really belong on this thread but, out of curiosity, do you know why npm has 2 possible locations for symlinks?\n. ",
    "wrouesnel": "I can confirm this bug as well as the workaround fixing it.\nIt's also applies to jQuery 1.10.\n. I can confirm this bug as well as the workaround fixing it.\nIt's also applies to jQuery 1.10.\n. ",
    "tombburnell": "Hi, Thanks for your interest, but we no longer use Socketstream so it does\nnot affect us.\nBest regards,\nTom\nOn Mon, Oct 21, 2013 at 10:15 PM, Paul Jensen notifications@github.comwrote:\n\n@tomhowe https://github.com/tomhowe Could you let us know if this issue\nis still affecting you? I'd like to fix it if it is.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/382#issuecomment-26757260\n.\n. We only stopped using it because we had issues with websockets in our\nnetwork and found that we could achieve what we were attempted with pure\nHTTP just as easily. Will re-consider socketstream once we sort out the\nnetwork issues and have a project that has a greater need for websockets.\nAll the best, Tom\n\nOn Wed, Oct 23, 2013 at 9:41 PM, Paul Jensen notifications@github.comwrote:\n\nThanks Tom. If you have any feedback about SocketStream, I'm open to\nhearing it.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/382#issuecomment-26943643\n.\n. Hi, Thanks for your interest, but we no longer use Socketstream so it does\nnot affect us.\nBest regards,\nTom\n\nOn Mon, Oct 21, 2013 at 10:15 PM, Paul Jensen notifications@github.comwrote:\n\n@tomhowe https://github.com/tomhowe Could you let us know if this issue\nis still affecting you? I'd like to fix it if it is.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/382#issuecomment-26757260\n.\n. We only stopped using it because we had issues with websockets in our\nnetwork and found that we could achieve what we were attempted with pure\nHTTP just as easily. Will re-consider socketstream once we sort out the\nnetwork issues and have a project that has a greater need for websockets.\nAll the best, Tom\n\nOn Wed, Oct 23, 2013 at 9:41 PM, Paul Jensen notifications@github.comwrote:\n\nThanks Tom. If you have any feedback about SocketStream, I'm open to\nhearing it.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/socketstream/socketstream/issues/382#issuecomment-26943643\n.\n. \n",
    "azat-co": "Maybe an offtopic: Mocha support TDD, BDD and Qunit interfaces, so it looks like Mocha test can look like NodeUnit.\nPS: I can here though googling \"Mocha vs. Nodeunit vs. jasmine\".\n. Maybe an offtopic: Mocha support TDD, BDD and Qunit interfaces, so it looks like Mocha test can look like NodeUnit.\nPS: I can here though googling \"Mocha vs. Nodeunit vs. jasmine\".\n. ",
    "shannonmoeller": "I also got here by googling \"nodeunit vs mocha\". I'd like to point out that the OP is misrepresenting mocha because the test was written incorrectly. The invocation of done should be inside the timeout callbacks. Here's a corrected implementation:\n``` js\ndescribe('Test', function() {\n    it('should pass', function(done) {\n        setTimeout(function(){\n            (true).should.be.equal(true);\n            done();\n        }, 300);\n    });\nit('should fail', function(done) {\n    setTimeout(function(){\n        (true).should.be.equal(false);\n        done();\n    }, 100);\n});\n\n});\n```\nThis is not an argument for using Mocha instead of Nodeunit. I'm simply pointing out the error, and therefore the flaw with the logic in the OP.\n. I also got here by googling \"nodeunit vs mocha\". I'd like to point out that the OP is misrepresenting mocha because the test was written incorrectly. The invocation of done should be inside the timeout callbacks. Here's a corrected implementation:\n``` js\ndescribe('Test', function() {\n    it('should pass', function(done) {\n        setTimeout(function(){\n            (true).should.be.equal(true);\n            done();\n        }, 300);\n    });\nit('should fail', function(done) {\n    setTimeout(function(){\n        (true).should.be.equal(false);\n        done();\n    }, 100);\n});\n\n});\n```\nThis is not an argument for using Mocha instead of Nodeunit. I'm simply pointing out the error, and therefore the flaw with the logic in the OP.\n. ",
    "cbayram": "I'm running into the same issue. Leaving the media attribute out (defaults to all) or setting it to \"all\", should apply the linked stylesheet to all media types, including print. This way, the developer could implement media type specific styling in his/her stylesheet. \nOne quick change which could make it more flexible is to simply remove the media=\"screen\" or set it to all in wrap.js\nThanks,\n. I'm running into the same issue. Leaving the media attribute out (defaults to all) or setting it to \"all\", should apply the linked stylesheet to all media types, including print. This way, the developer could implement media type specific styling in his/her stylesheet. \nOne quick change which could make it more flexible is to simply remove the media=\"screen\" or set it to all in wrap.js\nThanks,\n. ",
    "evanlh": "Hi @paulbjensen, I have the same need, came up with the following patch that seems to do the trick but I'm not really sure if it's kosher to put the EventEmitter at the api level. Here's the diff:\ndiff --git a/lib/client/index.js b/lib/client/index.js\nindex c07d077..1ed949c 100644\n--- a/lib/client/index.js\n+++ b/lib/client/index.js\n@@ -209,6 +209,7 @@ module.exports = function(ss, router) {\n               pack(ss, client, options);\n             }\n           }\n+          ss.events.emit('server:finish_pack');\n         }\n       } else {\n         // Else serve files and watch for changes to files in development\ndiff --git a/lib/socketstream.js b/lib/socketstream.js\nindex ae9f665..57a8a45 100644\n--- a/lib/socketstream.js\n+++ b/lib/socketstream.js\n@@ -55,7 +55,7 @@ var api = exports.api = {\n // Create internal Events bus\n // Note: only used by the ss-console module for now. This idea will be expended upon in SocketStream 0.4\n var events = exports.events = new EventEmitter2();\n-\n+api.events = events;\n // Publish Events\n var publish = exports.publish = require('./publish/index')();\nThen in the app itself I just do something like this:\nss.events.on('server:finish_pack', function() {\n  console.log(\"finished packing!\");\n  process.exit(0);\n});\nThoughts? Thanks\n. Thanks Roman, I'll look into options for not passing ss as a parameter and look forward to @paulbjensen 's feedback.\n. Back again! I have pushed changes to this branch-- as suggested, I am now requiring utils/log.js everywhere and no longer passing ss as a parameter. I've also gone ahead and fixed nearly all the jshint errors on all files I touched. (\"nearly all\" == all of the cosmetic and common sense fixes minus anything too invasive or that requires more domain knowledge than I possess.) This is working great using winston on our production app, let me know if there's anything else I can do. Thanks!\n. I've just (sadly) noticed that I haven't been following your Git commit guidelines. I'm guessing this is pretty important, I can do an interactive rebase and clean these up if necessary.\n. Thanks Roman! I believe I've made all the changes you requested, lmk if there's anything else.\n. Thanks guys! @RomanMinkin, changes applied. @paulbjensen, I've added the event argument back.\n. Hi @paulbjensen, I have the same need, came up with the following patch that seems to do the trick but I'm not really sure if it's kosher to put the EventEmitter at the api level. Here's the diff:\ndiff --git a/lib/client/index.js b/lib/client/index.js\nindex c07d077..1ed949c 100644\n--- a/lib/client/index.js\n+++ b/lib/client/index.js\n@@ -209,6 +209,7 @@ module.exports = function(ss, router) {\n               pack(ss, client, options);\n             }\n           }\n+          ss.events.emit('server:finish_pack');\n         }\n       } else {\n         // Else serve files and watch for changes to files in development\ndiff --git a/lib/socketstream.js b/lib/socketstream.js\nindex ae9f665..57a8a45 100644\n--- a/lib/socketstream.js\n+++ b/lib/socketstream.js\n@@ -55,7 +55,7 @@ var api = exports.api = {\n // Create internal Events bus\n // Note: only used by the ss-console module for now. This idea will be expended upon in SocketStream 0.4\n var events = exports.events = new EventEmitter2();\n-\n+api.events = events;\n // Publish Events\n var publish = exports.publish = require('./publish/index')();\nThen in the app itself I just do something like this:\nss.events.on('server:finish_pack', function() {\n  console.log(\"finished packing!\");\n  process.exit(0);\n});\nThoughts? Thanks\n. Thanks Roman, I'll look into options for not passing ss as a parameter and look forward to @paulbjensen 's feedback.\n. Back again! I have pushed changes to this branch-- as suggested, I am now requiring utils/log.js everywhere and no longer passing ss as a parameter. I've also gone ahead and fixed nearly all the jshint errors on all files I touched. (\"nearly all\" == all of the cosmetic and common sense fixes minus anything too invasive or that requires more domain knowledge than I possess.) This is working great using winston on our production app, let me know if there's anything else I can do. Thanks!\n. I've just (sadly) noticed that I haven't been following your Git commit guidelines. I'm guessing this is pretty important, I can do an interactive rebase and clean these up if necessary.\n. Thanks Roman! I believe I've made all the changes you requested, lmk if there's anything else.\n. Thanks guys! @RomanMinkin, changes applied. @paulbjensen, I've added the event argument back.\n. ",
    "klausb": "I don't get it. The gist shows how to start the server from with npm, but does it help to stop the server, when the packing is done?\n. Paul,\nany news on this one?\n/klaus\n. Is that an effect of the latest changes regarding the engine.io update?\nI've currently created a dependency to connect.sid, to control sticky sessions on load balancers.\nIf that's no longer there, what's the proposed strategy?\n. I don't get it. The gist shows how to start the server from with npm, but does it help to stop the server, when the packing is done?\n. Paul,\nany news on this one?\n/klaus\n. Is that an effect of the latest changes regarding the engine.io update?\nI've currently created a dependency to connect.sid, to control sticky sessions on load balancers.\nIf that's no longer there, what's the proposed strategy?\n. ",
    "hackingbeauty": "Thanks Waxolunist, I think I see my problem.  When using an automated html-to-jade converter, the tag  does not get converted to: \n!= SocketStream\nThis may stump people new to SocketServer/Jade.  Perhaps there is a better way to insert static assets in SocketServer instead of a custom tag?\n. Yes, everything is working for me now.  \nThere was just a hiccup in the html to jade conversion process.  This wasn't a bug, just a \"UX\" problem, that's why I recommended changing the way SocketStream inserts its static assets :D\n. Thanks Waxolunist, I think I see my problem.  When using an automated html-to-jade converter, the tag  does not get converted to: \n!= SocketStream\nThis may stump people new to SocketServer/Jade.  Perhaps there is a better way to insert static assets in SocketServer instead of a custom tag?\n. Yes, everything is working for me now.  \nThere was just a hiccup in the html to jade conversion process.  This wasn't a bug, just a \"UX\" problem, that's why I recommended changing the way SocketStream inserts its static assets :D\n. ",
    "DeLaGuardo": "ss-iced wrapper\n. Please, can you check my latest pull request #436. Im update browserify for accept any file extensions. This is easy and fast solution, but it works good.\n. How do you start your app in pm2?\n. It can looks like a weird trick, but anyway...\nim using coffee-script for main app file, and found that starting pm2 process with command pm2 start app.coffee doesn't let me start my app in cluster mode. But with simple wrapper (named server.js) - \nrequire(\"coffee-script\")\nrequire(\"./app\")\nserver start in cluster mode and all sessions issues was gone.\nPS: for iced coffee script you need to use require(\"iced-coffee-script\").register()\n. ss-iced wrapper\n. Please, can you check my latest pull request #436. Im update browserify for accept any file extensions. This is easy and fast solution, but it works good.\n. How do you start your app in pm2?\n. It can looks like a weird trick, but anyway...\nim using coffee-script for main app file, and found that starting pm2 process with command pm2 start app.coffee doesn't let me start my app in cluster mode. But with simple wrapper (named server.js) - \nrequire(\"coffee-script\")\nrequire(\"./app\")\nserver start in cluster mode and all sessions issues was gone.\nPS: for iced coffee script you need to use require(\"iced-coffee-script\").register()\n. ",
    "nhitchins": "update: after digging a little further it looks like the Socket instance being created on the client has been restructured since 0.3.10.  Changing https://github.com/socketstream/socketstream/blob/master/lib/websocket/transports/engineio/index.js#L73 to set rawCookie=socket.request.headers.cookie (regardless of socket.upgraded flag) fixes the issue with issue above with access to cookie data.\nAnother notable change on the client is that the global eio object no longer exposes the socket instance(s), so depending on your needs you may want to expose the socket/transport instance when the connection is created (I needed to be able to read the socket id) https://github.com/socketstream/socketstream/blob/master/lib/websocket/transports/engineio/wrapper.js#L17.  \nAnything i've missed?\n. Doing some more testing, but everything appears to be running ok after the update....there was a few notable changes in the engine.io client that may still require some changes in the ss engineio wrapper. ie. transport 'upgrade' event is now emitted after the upgrade has occurred, etc.\nAnyway, I'll try make some time to submit a PR later and go from there.\n. Yeah my apologies for not putting together a PR on the 0.9 upgrade. Really interested to see how you go with the 1.4.3 upgrade. The ultimate goal would be to get binary websockets working!\nIncase you're still bug hunting, heres a snippit that you may want to look into (the processSession function in websocket/transports/index.js) https://gist.github.com/nhitchins/f2ef70a63331a29427aa#file-index-js\n. @kulicuu \n- I've heavily modified my version of socketstream for a specific use-case so cant submit a PR against it. I'll grab the official release and do some testing when you're close to a final commit. Lets get that happening first. (any gotcha's you've come across with the upgrade so far?)\n- Re: Binary websockets. I'll take a look into this sometime over the next week and report back. I'm pretty sure the engine.io client/server handles Buffer/ArrayBuffer messages with automatic base64 encoding for browsers/transports that don't support binary frames - TBC. Will need to review the SS transport components to figure out what may need to change if anything. I'd be leaning towards sending all messages as binary in preparation for automatic compression: https://github.com/Automattic/socket.io/issues/1148\n- Re: Web workers. I'd be really interested to hear what improvements if any would be gained by wrapping the engine.io client in a web worker. my understanding is that websockets are non-blocking (apart from any processing logic that gets triggered when the data arrives)? Has anyone tried/tested or confirmed this?\n. Looks like support for compression has been added. https://github.com/Automattic/socket.io/issues/1148. I still havent had a chance to review this yet, but now that you've got engine.io up to date it should make it a whole lot easier!\n. update: after digging a little further it looks like the Socket instance being created on the client has been restructured since 0.3.10.  Changing https://github.com/socketstream/socketstream/blob/master/lib/websocket/transports/engineio/index.js#L73 to set rawCookie=socket.request.headers.cookie (regardless of socket.upgraded flag) fixes the issue with issue above with access to cookie data.\nAnother notable change on the client is that the global eio object no longer exposes the socket instance(s), so depending on your needs you may want to expose the socket/transport instance when the connection is created (I needed to be able to read the socket id) https://github.com/socketstream/socketstream/blob/master/lib/websocket/transports/engineio/wrapper.js#L17.  \nAnything i've missed?\n. Doing some more testing, but everything appears to be running ok after the update....there was a few notable changes in the engine.io client that may still require some changes in the ss engineio wrapper. ie. transport 'upgrade' event is now emitted after the upgrade has occurred, etc.\nAnyway, I'll try make some time to submit a PR later and go from there.\n. Yeah my apologies for not putting together a PR on the 0.9 upgrade. Really interested to see how you go with the 1.4.3 upgrade. The ultimate goal would be to get binary websockets working!\nIncase you're still bug hunting, heres a snippit that you may want to look into (the processSession function in websocket/transports/index.js) https://gist.github.com/nhitchins/f2ef70a63331a29427aa#file-index-js\n. @kulicuu \n- I've heavily modified my version of socketstream for a specific use-case so cant submit a PR against it. I'll grab the official release and do some testing when you're close to a final commit. Lets get that happening first. (any gotcha's you've come across with the upgrade so far?)\n- Re: Binary websockets. I'll take a look into this sometime over the next week and report back. I'm pretty sure the engine.io client/server handles Buffer/ArrayBuffer messages with automatic base64 encoding for browsers/transports that don't support binary frames - TBC. Will need to review the SS transport components to figure out what may need to change if anything. I'd be leaning towards sending all messages as binary in preparation for automatic compression: https://github.com/Automattic/socket.io/issues/1148\n- Re: Web workers. I'd be really interested to hear what improvements if any would be gained by wrapping the engine.io client in a web worker. my understanding is that websockets are non-blocking (apart from any processing logic that gets triggered when the data arrives)? Has anyone tried/tested or confirmed this?\n. Looks like support for compression has been added. https://github.com/Automattic/socket.io/issues/1148. I still havent had a chance to review this yet, but now that you've got engine.io up to date it should make it a whole lot easier!\n. ",
    "caitp": "Don't forget to write a test case so that nobody accidentally breaks it in a future commit\n. Don't forget to write a test case so that nobody accidentally breaks it in a future commit\n. ",
    "mmalecki": "Thanks @owenb!\nThanks for feedback @caitp. I looked at the connect cookie middleware code and it seems like we'd need to mock cookie parser factory: https://github.com/senchalabs/connect/blob/15bb7e2598d1f3c18b3063673a6f7900e919ac69/lib/middleware/cookieParser.js#L39\nDo you think it'd be sane to make that a separate unit test instead of putting it in test/unit/http/index.test.js, where rest of our http/connect integration tests are?\n. @paulbjensen the problem with putting it in the same file is that we'd have to mock the global connect cookie parser middleware, which could affect rest of our tests which could affect rest of our tests. I'm not sure if there's a way around it since I'm not too familiar with mocha.\n. @paulbjensen thanks for taking this on! I'm afraid I can't really help with this - lack of process isolation isn't really something I want to fight.\n. Thanks @owenb!\nThanks for feedback @caitp. I looked at the connect cookie middleware code and it seems like we'd need to mock cookie parser factory: https://github.com/senchalabs/connect/blob/15bb7e2598d1f3c18b3063673a6f7900e919ac69/lib/middleware/cookieParser.js#L39\nDo you think it'd be sane to make that a separate unit test instead of putting it in test/unit/http/index.test.js, where rest of our http/connect integration tests are?\n. @paulbjensen the problem with putting it in the same file is that we'd have to mock the global connect cookie parser middleware, which could affect rest of our tests which could affect rest of our tests. I'm not sure if there's a way around it since I'm not too familiar with mocha.\n. @paulbjensen thanks for taking this on! I'm afraid I can't really help with this - lack of process isolation isn't really something I want to fight.\n. ",
    "EricCat": "@paulbjensen You are so great! you explain very very great!! You give me a  brain storm\n. @kulicuu yes, I work with res.download(path), also you give me a great help! thanks\n. Hi @paulbjensen @kulicuu \nI'm sorry to bother again. \nwhen I use the code\n```\nres.download(path, file, function(err){\n      if (err) throw err;\n      console.log('popup download save dialog!');\n})\n```\nThe console.log() can display normal. but the browser can't popup download dialog.\nI think it must be response lack of somethings.\nIt is likely to be this kind of situation? \nhttps://github.com/felixge/node-formidable/issues/169\nDo you have any better ideas?\nThanks\n. @paulbjensen ,yep, I've tried it :) . I've learned from Dashku.\nBut it also cannot work for popup dialog. even cannot get console.log() \n. @paulbjensen yes, it in the /server/rpc/download.js,  but not in \nexports.actions = function (req, res, ss) {\n......\n}\nI put it out of exports.actions. I use \nexports.download = function (req, res) {\n}\nin app.js \n```\nss.http.middleware.prepend(ss.http.connect.json());\nss.http.middleware.prepend(ss.http.connect.urlencoded());\nss.http.middleware.prepend(ss.http.connect.multipart());\nss.http.middleware.prepend(ss.http.connect.query());\nss.http.middleware.prepend(redirect());\nss.http.middleware.append(passport.initialize());\nss.http.middleware.append(passport.session());\nss.http.middleware.append(connectRoute(function(router){\n    router.get('/', passport.authenticate('basic', {session: true}));\n}));\n```\n. @paulbjensen I've tried, but it still doesn't work. \nThanks very much. Now, I knew that don't put some module in /server/rpc. \n. @paulbjensen You are so great! you explain very very great!! You give me a  brain storm\n. @kulicuu yes, I work with res.download(path), also you give me a great help! thanks\n. Hi @paulbjensen @kulicuu \nI'm sorry to bother again. \nwhen I use the code\n```\nres.download(path, file, function(err){\n      if (err) throw err;\n      console.log('popup download save dialog!');\n})\n```\nThe console.log() can display normal. but the browser can't popup download dialog.\nI think it must be response lack of somethings.\nIt is likely to be this kind of situation? \nhttps://github.com/felixge/node-formidable/issues/169\nDo you have any better ideas?\nThanks\n. @paulbjensen ,yep, I've tried it :) . I've learned from Dashku.\nBut it also cannot work for popup dialog. even cannot get console.log() \n. @paulbjensen yes, it in the /server/rpc/download.js,  but not in \nexports.actions = function (req, res, ss) {\n......\n}\nI put it out of exports.actions. I use \nexports.download = function (req, res) {\n}\nin app.js \n```\nss.http.middleware.prepend(ss.http.connect.json());\nss.http.middleware.prepend(ss.http.connect.urlencoded());\nss.http.middleware.prepend(ss.http.connect.multipart());\nss.http.middleware.prepend(ss.http.connect.query());\nss.http.middleware.prepend(redirect());\nss.http.middleware.append(passport.initialize());\nss.http.middleware.append(passport.session());\nss.http.middleware.append(connectRoute(function(router){\n    router.get('/', passport.authenticate('basic', {session: true}));\n}));\n```\n. @paulbjensen I've tried, but it still doesn't work. \nThanks very much. Now, I knew that don't put some module in /server/rpc. \n. ",
    "polpo": "Yes, that'd be great. I'd be glad to create a pull request for this.\n. Yes, that'd be great. I'd be glad to create a pull request for this.\n. ",
    "coveralls": "\nCoverage remained the same when pulling 60e1f50fb5f94fcabcdf7e41cda73e8230a3b2d5 on polpo:master into f4b7ad1d223a204077f296b4f0b8d7d9d19b4aad on socketstream:master.\n. \nCoverage decreased (-40.81%) when pulling c0bea3c1c3a8bf43d84bd1176dfccfd0d0715165 on thepian:master into a38dcd0ae4f745f1acbe27ee44eb5a0dcd2b86aa on socketstream:master.\n. \nCoverage decreased (-41.01%) when pulling 0900a748f6ca5a46c50c7b4059c8f46737a6bcb2 on thepian:master into a38dcd0ae4f745f1acbe27ee44eb5a0dcd2b86aa on socketstream:master.\n. \nCoverage decreased (-41.1%) when pulling c1efdf8e5f88e7cc134200da59dc916e8881326b on thepian:master into a38dcd0ae4f745f1acbe27ee44eb5a0dcd2b86aa on socketstream:master.\n. \nCoverage decreased (-41.39%) when pulling b8edbd36f4096ef0f3c85796dfe2e98ba2085a7e on thepian:master into a38dcd0ae4f745f1acbe27ee44eb5a0dcd2b86aa on socketstream:master.\n. \nCoverage decreased (-41.39%) when pulling 43ce8ddb893944c3a90573b8dbb5e6ef4c95389d on thepian:master into a38dcd0ae4f745f1acbe27ee44eb5a0dcd2b86aa on socketstream:master.\n. \nCoverage decreased (-41.49%) when pulling e550b653f66f2024ed6f14b0cc937b4d9567e326 on thepian:master into a38dcd0ae4f745f1acbe27ee44eb5a0dcd2b86aa on socketstream:master.\n. \nCoverage decreased (-40.81%) when pulling c0bea3c1c3a8bf43d84bd1176dfccfd0d0715165 on thepian:system-assets-override into 28543c51b6b5e1d129309b5a128c8ef03bcb5a7a on socketstream:master.\n. \nCoverage decreased (-41.39%) when pulling 43ce8ddb893944c3a90573b8dbb5e6ef4c95389d on thepian:client-includes-config into 28543c51b6b5e1d129309b5a128c8ef03bcb5a7a on socketstream:master.\n. \nCoverage decreased (-41.1%) when pulling 615c527754a7ee32a0ce227cce89b59181cc693b on thepian:global-require into 28543c51b6b5e1d129309b5a128c8ef03bcb5a7a on socketstream:master.\n. \nCoverage remained the same when pulling 8e6111c9e2ab4f83924fa3b31a15c71c5251c8f4 on seanhussey:patch-1 into 71d2e3c32e6cd32b1e3eee4ae3e83d1d42e9b5b1 on socketstream:master.\n. \nCoverage increased (+0.28%) when pulling c987955122337c6f3ec769cfaa49d85a4bd0f431 on feature/470-static-paths into c0b41fea325b2cbda20e9d187bff864224894f50 on master.\n. \nCoverage increased (+0.47%) when pulling f2fd0ca0c2201887ad5e609717f9e416914e90f6 on feature/470-static-paths into c0b41fea325b2cbda20e9d187bff864224894f50 on master.\n. \nCoverage increased (+0.47%) when pulling dcb2c78e6caef41795293839144e16d5fcfa415f on feature/470-static-paths into c0b41fea325b2cbda20e9d187bff864224894f50 on master.\n. \nCoverage remained the same at 49.68% when pulling 1a83267d1922db49f6838c46e6819280dbd34da3 on quale-quest:issue487 into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on socketstream:master.\n. \nCoverage increased (+0.28%) to 49.95% when pulling d5b67c404957467cb60878216403e1d34ec75f6c on quale-quest:issue487 into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on socketstream:master.\n. \nCoverage increased (+0.28%) to 49.95% when pulling d3df6c2b0a7b7fd05892101bf943f050bc5c7b56 on quale-quest:issue487 into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on socketstream:master.\n. \nCoverage increased (+0.28%) to 49.95% when pulling 872bcec1c39046be203a11e0f09f0790971268d8 on kulicuu:newConnect into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on socketstream:master.\n. \nCoverage increased (+0.28%) to 49.95% when pulling 2a99e458c6e784ed585cdff42e42a0cc80b58246 on kulicuu:newConnect into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on socketstream:master.\n. \nCoverage remained the same at 49.95% when pulling ad8e0289d0af2c58802d1668ca332bc82731d4fa on kulicuu:expressRidDeprecErrors into 5904ff86517565b927ae194bf3c90003fc4bb7d3 on socketstream:master.\n. \nCoverage remained the same at 49.95% when pulling 8234170983114c9795d3ff0de692f07f16ab8c30 on kulicuu:e2e into fc2dc8ea32d6e47a2df32e4866a69b36146a4725 on socketstream:master.\n. \nCoverage decreased (-5.62%) to 44.06% when pulling 148369b63074dc6c825b6622afa95088a21185ea on feature/465-bundler into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on next.\n. \nCoverage decreased (-5.14%) to 44.54% when pulling 795448539d9def98185cbc7a9e626eeb01688bb6 on feature/465-bundler into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on next.\n. \nCoverage increased (+2.34%) to 52.01% when pulling d1beae0417f232db0fdf2fd2d79b707288c70267 on feature/465-bundler into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on next.\n. \nCoverage increased (+2.9%) to 62.67% when pulling b0f963fb737c44aab8d7508447d9a4c7145cb439 on feature/353-client-constants into a86216fedab9b4c6cac56cc8ccf0c29a9560178d on next.\n. \nCoverage decreased (-0.04%) to 62.64% when pulling e133cdfe923f9d0e7a9125acd9c8ccd129c6307a on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+3.48%) to 66.15% when pulling 6565a9c0bd91c44e9169825550a0f59ad6af6d9e on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+4.69%) to 67.36% when pulling ad61b0276e798d76e62d999e0b43ab428af2263c on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+4.69%) to 67.36% when pulling e87ac402f7517d13939d4370376185d51ec885a6 on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+5.01%) to 67.69% when pulling 15b66ed89e8251fe2978272bb42d22b54993ad0b on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+5.08%) to 67.75% when pulling 15b66ed89e8251fe2978272bb42d22b54993ad0b on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+5.15%) to 67.82% when pulling c14129f172b940fda7d908aa94fe463e6039f6cc on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+5.28%) to 67.95% when pulling 9efab599757153b03829ec05317ec444761e7ced on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+5.37%) to 68.05% when pulling 4f9cb6a31aa1ce4f39b5aedc1a3f98cbaa15e21f on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+4.38%) to 67.06% when pulling 498d9c861a0b861a8380ba10b15ed9181eedd470 on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+4.66%) to 67.34% when pulling ebf835aef3e0e4bc9473fb9c84307996e42ca10b on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage decreased (-0.05%) to 49.95% when pulling 18e2ef8df2f62b6ad34752d59de185a5268c952a on hotfix/request-middleware-version-fix into a91f62100d3f106fccd02c70c77ef16f1749ac06 on master.\n. \nCoverage remained the same at 50.0% when pulling d51ec2f316c75114869c3b444d11133dcae7122a on waffle-iron:master into e8a17e99d01e31f865d22d31cf2504674866dcef on socketstream:master.\n. \nCoverage remained the same at 50.0% when pulling 3650845e45ad8d8a9749e0e9f31c4c90e88053a0 on davidsketchdeck:patch-1 into e8a17e99d01e31f865d22d31cf2504674866dcef on socketstream:master.\n. \nCoverage remained the same at 49.95% when pulling 84e608c0925f82dee5cd36e27c1e7924563de979 on waffle-badge-adjustment into 56758210d666e3717b32adcfd3553da6cb0d2059 on master.\n. \nCoverage increased (+0.05%) to 66.69% when pulling f5dd8799c5d524985ffcdbbcf4b8716821b7d1b9 on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.05%) to 66.69% when pulling d7c08284e32e760d48c59f8c2799e7f4b7b19bee on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.05%) to 66.69% when pulling d69f7787ef84cbd9f23411266b104d4904760fa7 on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.05%) to 66.69% when pulling 6917adea6bb440ebbafe0576a11b505416f76cb3 on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.05%) to 66.69% when pulling 08ba1ef6e185b98e0f964b718e3c247dcf855fdc on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.05%) to 66.69% when pulling 2a41ea95804d52444108955bc1041288ab94aba3 on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.47%) to 67.12% when pulling 5d2320188f90f9d228811f459ef43309f3f2eb9f on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.45%) to 67.09% when pulling 845685fd105ce52a8e1150e5816b26e3811fb684 on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.45%) to 67.09% when pulling 71af4fe6e70154221202a299822ca337fecebd74 on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.02%) to 67.21% when pulling 72d6c63189fb0f9f3b1a8de4adb29009529ef88d on feature/454-sessionid into 669f000ae9bc22df87b1fb8f064f2c4877d8722a on next.\n. \nCoverage increased (+0.99%) to 68.17% when pulling 1a5c91f408712a9ceccbe216cd092a26d2309ef8 on feature/490-workers into 33fba3b96ab277d224eb7b057adae84380e9e478 on next.\n. \nCoverage increased (+0.99%) to 68.17% when pulling 87924608e6601a0843709b115863653910bcf4e3 on feature/490-workers into 33fba3b96ab277d224eb7b057adae84380e9e478 on next.\n. \nCoverage increased (+1.93%) to 69.12% when pulling b1a2a11258c045f12b29e3157f497c7319669cf0 on feature/490-workers into 33fba3b96ab277d224eb7b057adae84380e9e478 on next.\n. \nCoverage increased (+1.93%) to 69.12% when pulling c26e403b88fbefd7dedee74a2d54aad54818455d on feature/490-workers into 33fba3b96ab277d224eb7b057adae84380e9e478 on next.\n. \nCoverage increased (+0.15%) to 69.27% when pulling 24ab079f55f886b03a0769bd78868af20e75946f on feature/507-packing into a14c38368ccc13d783f301b1ba8f17977f8f570c on next.\n. \nCoverage increased (+0.15%) to 69.27% when pulling b381cbe900849e2e95f6e3d84c22091c105c3cb6 on feature/507-packing into a14c38368ccc13d783f301b1ba8f17977f8f570c on next.\n. \nCoverage increased (+4.12%) to 73.24% when pulling 320d1243f12fc6ccb1ea46313b9686d7559cf7fd on feature/507-packing into a14c38368ccc13d783f301b1ba8f17977f8f570c on next.\n. \nCoverage increased (+4.26%) to 73.37% when pulling 9c951a128cfcdcffec2a25dd725ba0f0ac02d237 on feature/507-packing into a14c38368ccc13d783f301b1ba8f17977f8f570c on next.\n. \nCoverage increased (+4.32%) to 73.44% when pulling 58cdf76ec861c571393fb2678e8edb6e71103a50 on feature/507-packing into a14c38368ccc13d783f301b1ba8f17977f8f570c on next.\n. \nCoverage increased (+4.32%) to 73.44% when pulling ba5e83fd2090f51a64e0c2ba9bc626d42c091519 on feature/507-packing into a14c38368ccc13d783f301b1ba8f17977f8f570c on next.\n. \nCoverage decreased (-0.07%) to 74.08% when pulling 95ccb9a507b55fc2324650b7545efd6f4008b278 on feature/424-require-file-extensions into aaea0d95941489763e60d4d2d65a5a05a6618476 on next.\n. \nCoverage decreased (-0.19%) to 73.96% when pulling fb162bd37405f6b4f82f622cb0722d18733bf638 on feature/507-browserify-in-bundler into 841a372722f56564168fa9b3c5da376311f8601b on next.\n. \nCoverage decreased (-0.19%) to 73.96% when pulling fb162bd37405f6b4f82f622cb0722d18733bf638 on feature/507-browserify-in-bundler into 841a372722f56564168fa9b3c5da376311f8601b on next.\n. \nCoverage decreased (-0.05%) to 74.09% when pulling 6c2eb58a895be49e8ed9a38d2f69e58d3c36cb1c on feature/507-browserify-in-bundler into 841a372722f56564168fa9b3c5da376311f8601b on next.\n. \nCoverage decreased (-0.05%) to 74.09% when pulling 8eeac72e649886f372ca4c8e459754289dfca268 on feature/507-browserify-in-bundler into 841a372722f56564168fa9b3c5da376311f8601b on next.\n. \nCoverage decreased (-0.05%) to 74.09% when pulling 8eeac72e649886f372ca4c8e459754289dfca268 on feature/507-browserify-in-bundler into 841a372722f56564168fa9b3c5da376311f8601b on next.\n. \nCoverage decreased (-1.89%) to 73.08% when pulling 40954fdfe44257a897e09a0693aa90c5865da992 on feature/separate-cli-generator into 9715757a10749834e085629258b2f853bd99a7cf on master.\n. \nCoverage decreased (-1.78%) to 73.79% when pulling abbdebbcfa9ff9d03ea46e3f75f2c054f56f8e9f on separate-cli-generator-v2 into 815c91330c76d018908c6a4c8594a2f22983e332 on master.\n. \nChanges Unknown when pulling 6bd5ed7af7ad0c86c5126a6a10c5dd4f96ec2141 on feature/separate-cli-generator-v3 into * on next*.\n. \nCoverage remained the same at 75.57% when pulling 2fb9ed7054f3bddead9424a04e45bf01c6ddbc78 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage decreased (-0.07%) to 75.5% when pulling 254bf36eb634c039a06d88adb3e1ed431ea279c6 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage remained the same at 75.57% when pulling 254bf36eb634c039a06d88adb3e1ed431ea279c6 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage decreased (-0.07%) to 75.5% when pulling 405349eeebe2a1cee0ed56d6311b3c22421915e0 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage remained the same at 75.57% when pulling af770c754ea3acd3dbc0bed3812b33902c331e1b on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage remained the same at 75.57% when pulling 0163587efa07b0a9a0764ab2777cd2f479a98c93 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage remained the same at 75.57% when pulling 0163587efa07b0a9a0764ab2777cd2f479a98c93 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage remained the same at 75.57% when pulling 2149570b91be0a25e943f3562577d5035309bdc6 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage remained the same at 75.57% when pulling 894de11e6234928309de733befd5ff62fb929798 on Terebinth:fix_#543 into 4d482ee0340227afd2b2b72562ffe178c75184ca on socketstream:master.\n. \nCoverage increased (+0.78%) to 76.35% when pulling dd7b5ed0858126b86bb2c5928a73aac9b8fa9d47 on feature/lib-publish-tests into f90740d9d78af27907c9dde9ca050bd21975fa73 on master.\n. \nCoverage increased (+0.78%) to 76.35% when pulling dd7b5ed0858126b86bb2c5928a73aac9b8fa9d47 on feature/lib-publish-tests into f90740d9d78af27907c9dde9ca050bd21975fa73 on master.\n. \nCoverage decreased (-0.13%) to 76.22% when pulling ecd7be27a5a615292ba7718b7a4c459cd852d888 on bug/fix-538 into a2921b414afe75ed5f64f0ea94cc6766ffa7ceb4 on master.\n. \nCoverage increased (+0.08%) to 76.36% when pulling 83b11e8f20968af44421028427c75fa5b448b4c2 on feature/added-cli-test into b90361ba3ee6e865d93aac71d203ab56f8604995 on master.\n. \nCoverage increased (+0.55%) to 76.98% when pulling 7f7356e5bfaebcbf10fd57dc7c2f2879c2118fe6 on feature/coexisting-asset-types into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage increased (+0.55%) to 76.98% when pulling 7f7356e5bfaebcbf10fd57dc7c2f2879c2118fe6 on feature/coexisting-asset-types into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage increased (+0.5%) to 76.93% when pulling 5ef3ed025cbafdad4f621ef6c3b4ab7f56a208db on feature/coexisting-asset-types into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage increased (+0.51%) to 76.94% when pulling 10986d945a137d93602b7084383c45dc811dd961 on feature/coexisting-asset-types into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage increased (+0.51%) to 76.94% when pulling 2b527dc84a64e4ed606673fb07c3cca3bd201225 on feature/coexisting-asset-types into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage decreased (-1.47%) to 74.95% when pulling 77fbfbae9f10690e6d3ae50f3b07e80008d49e6f on feature/added-request-test into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage decreased (-1.47%) to 74.95% when pulling 77fbfbae9f10690e6d3ae50f3b07e80008d49e6f on feature/added-request-test into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage increased (+1.94%) to 76.89% when pulling 01718001527aba26501c9c3bf72e7618a325608c on feature/added-request-test into fb1fb883825bc9c903a8be1ee3920ff12547fca5 on master.\n. \nCoverage increased (+0.07%) to 76.96% when pulling 19461975da1538972eec8304d14c8b9bc160d38a on feature/pack-assets-fix into 0add949a30a859fe4225d46bed7fb7b2af7e12ae on master.\n. \nCoverage increased (+0.07%) to 76.96% when pulling de2a732b88e1e53edff8559c9ce1a9368a8aa103 on feature/pack-assets-fix into 0add949a30a859fe4225d46bed7fb7b2af7e12ae on master.\n. \nCoverage increased (+0.1%) to 74.778% when pulling 9df128f5ab20a15ec040df69be191f410f4d0c0b on msand:fix-test-crossplatform into e7cb63d383dc88ff002312f187445d29a86cd41f on socketstream:master.\n. \nCoverage increased (+0.1%) to 74.778% when pulling 9df128f5ab20a15ec040df69be191f410f4d0c0b on msand:fix-test-crossplatform into e7cb63d383dc88ff002312f187445d29a86cd41f on socketstream:master.\n. \nCoverage increased (+0.1%) to 74.778% when pulling 9df128f5ab20a15ec040df69be191f410f4d0c0b on msand:fix-test-crossplatform into e7cb63d383dc88ff002312f187445d29a86cd41f on socketstream:master.\n. \n\nCoverage remained the same at 65.832% when pulling ac4e5ed6893f744fdd9a05c1e6b2dfe45b07aa82 on fix/update-travis-node-versions into 9b25cb2e5ca3fa801ffe07307b4e03dc62a6a483 on develop.\n. \n\nCoverage remained the same at 65.832% when pulling ac4e5ed6893f744fdd9a05c1e6b2dfe45b07aa82 on fix/update-travis-node-versions into 9b25cb2e5ca3fa801ffe07307b4e03dc62a6a483 on develop.\n. \nCoverage remained the same when pulling 60e1f50fb5f94fcabcdf7e41cda73e8230a3b2d5 on polpo:master into f4b7ad1d223a204077f296b4f0b8d7d9d19b4aad on socketstream:master.\n. \nCoverage decreased (-40.81%) when pulling c0bea3c1c3a8bf43d84bd1176dfccfd0d0715165 on thepian:master into a38dcd0ae4f745f1acbe27ee44eb5a0dcd2b86aa on socketstream:master.\n. \nCoverage decreased (-41.01%) when pulling 0900a748f6ca5a46c50c7b4059c8f46737a6bcb2 on thepian:master into a38dcd0ae4f745f1acbe27ee44eb5a0dcd2b86aa on socketstream:master.\n. \nCoverage decreased (-41.1%) when pulling c1efdf8e5f88e7cc134200da59dc916e8881326b on thepian:master into a38dcd0ae4f745f1acbe27ee44eb5a0dcd2b86aa on socketstream:master.\n. \nCoverage decreased (-41.39%) when pulling b8edbd36f4096ef0f3c85796dfe2e98ba2085a7e on thepian:master into a38dcd0ae4f745f1acbe27ee44eb5a0dcd2b86aa on socketstream:master.\n. \nCoverage decreased (-41.39%) when pulling 43ce8ddb893944c3a90573b8dbb5e6ef4c95389d on thepian:master into a38dcd0ae4f745f1acbe27ee44eb5a0dcd2b86aa on socketstream:master.\n. \nCoverage decreased (-41.49%) when pulling e550b653f66f2024ed6f14b0cc937b4d9567e326 on thepian:master into a38dcd0ae4f745f1acbe27ee44eb5a0dcd2b86aa on socketstream:master.\n. \nCoverage decreased (-40.81%) when pulling c0bea3c1c3a8bf43d84bd1176dfccfd0d0715165 on thepian:system-assets-override into 28543c51b6b5e1d129309b5a128c8ef03bcb5a7a on socketstream:master.\n. \nCoverage decreased (-41.39%) when pulling 43ce8ddb893944c3a90573b8dbb5e6ef4c95389d on thepian:client-includes-config into 28543c51b6b5e1d129309b5a128c8ef03bcb5a7a on socketstream:master.\n. \nCoverage decreased (-41.1%) when pulling 615c527754a7ee32a0ce227cce89b59181cc693b on thepian:global-require into 28543c51b6b5e1d129309b5a128c8ef03bcb5a7a on socketstream:master.\n. \nCoverage remained the same when pulling 8e6111c9e2ab4f83924fa3b31a15c71c5251c8f4 on seanhussey:patch-1 into 71d2e3c32e6cd32b1e3eee4ae3e83d1d42e9b5b1 on socketstream:master.\n. \nCoverage increased (+0.28%) when pulling c987955122337c6f3ec769cfaa49d85a4bd0f431 on feature/470-static-paths into c0b41fea325b2cbda20e9d187bff864224894f50 on master.\n. \nCoverage increased (+0.47%) when pulling f2fd0ca0c2201887ad5e609717f9e416914e90f6 on feature/470-static-paths into c0b41fea325b2cbda20e9d187bff864224894f50 on master.\n. \nCoverage increased (+0.47%) when pulling dcb2c78e6caef41795293839144e16d5fcfa415f on feature/470-static-paths into c0b41fea325b2cbda20e9d187bff864224894f50 on master.\n. \nCoverage remained the same at 49.68% when pulling 1a83267d1922db49f6838c46e6819280dbd34da3 on quale-quest:issue487 into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on socketstream:master.\n. \nCoverage increased (+0.28%) to 49.95% when pulling d5b67c404957467cb60878216403e1d34ec75f6c on quale-quest:issue487 into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on socketstream:master.\n. \nCoverage increased (+0.28%) to 49.95% when pulling d3df6c2b0a7b7fd05892101bf943f050bc5c7b56 on quale-quest:issue487 into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on socketstream:master.\n. \nCoverage increased (+0.28%) to 49.95% when pulling 872bcec1c39046be203a11e0f09f0790971268d8 on kulicuu:newConnect into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on socketstream:master.\n. \nCoverage increased (+0.28%) to 49.95% when pulling 2a99e458c6e784ed585cdff42e42a0cc80b58246 on kulicuu:newConnect into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on socketstream:master.\n. \nCoverage remained the same at 49.95% when pulling ad8e0289d0af2c58802d1668ca332bc82731d4fa on kulicuu:expressRidDeprecErrors into 5904ff86517565b927ae194bf3c90003fc4bb7d3 on socketstream:master.\n. \nCoverage remained the same at 49.95% when pulling 8234170983114c9795d3ff0de692f07f16ab8c30 on kulicuu:e2e into fc2dc8ea32d6e47a2df32e4866a69b36146a4725 on socketstream:master.\n. \nCoverage decreased (-5.62%) to 44.06% when pulling 148369b63074dc6c825b6622afa95088a21185ea on feature/465-bundler into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on next.\n. \nCoverage decreased (-5.14%) to 44.54% when pulling 795448539d9def98185cbc7a9e626eeb01688bb6 on feature/465-bundler into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on next.\n. \nCoverage increased (+2.34%) to 52.01% when pulling d1beae0417f232db0fdf2fd2d79b707288c70267 on feature/465-bundler into efbcf5f16d6bc37b6dc443e0366463f04a0f8a96 on next.\n. \nCoverage increased (+2.9%) to 62.67% when pulling b0f963fb737c44aab8d7508447d9a4c7145cb439 on feature/353-client-constants into a86216fedab9b4c6cac56cc8ccf0c29a9560178d on next.\n. \nCoverage decreased (-0.04%) to 62.64% when pulling e133cdfe923f9d0e7a9125acd9c8ccd129c6307a on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+3.48%) to 66.15% when pulling 6565a9c0bd91c44e9169825550a0f59ad6af6d9e on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+4.69%) to 67.36% when pulling ad61b0276e798d76e62d999e0b43ab428af2263c on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+4.69%) to 67.36% when pulling e87ac402f7517d13939d4370376185d51ec885a6 on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+5.01%) to 67.69% when pulling 15b66ed89e8251fe2978272bb42d22b54993ad0b on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+5.08%) to 67.75% when pulling 15b66ed89e8251fe2978272bb42d22b54993ad0b on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+5.15%) to 67.82% when pulling c14129f172b940fda7d908aa94fe463e6039f6cc on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+5.28%) to 67.95% when pulling 9efab599757153b03829ec05317ec444761e7ced on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+5.37%) to 68.05% when pulling 4f9cb6a31aa1ce4f39b5aedc1a3f98cbaa15e21f on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+4.38%) to 67.06% when pulling 498d9c861a0b861a8380ba10b15ed9181eedd470 on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage increased (+4.66%) to 67.34% when pulling ebf835aef3e0e4bc9473fb9c84307996e42ca10b on feature/497-logging into 595fed3c1762dc614dd6a1b7dadbaf5f067e3e35 on next.\n. \nCoverage decreased (-0.05%) to 49.95% when pulling 18e2ef8df2f62b6ad34752d59de185a5268c952a on hotfix/request-middleware-version-fix into a91f62100d3f106fccd02c70c77ef16f1749ac06 on master.\n. \nCoverage remained the same at 50.0% when pulling d51ec2f316c75114869c3b444d11133dcae7122a on waffle-iron:master into e8a17e99d01e31f865d22d31cf2504674866dcef on socketstream:master.\n. \nCoverage remained the same at 50.0% when pulling 3650845e45ad8d8a9749e0e9f31c4c90e88053a0 on davidsketchdeck:patch-1 into e8a17e99d01e31f865d22d31cf2504674866dcef on socketstream:master.\n. \nCoverage remained the same at 49.95% when pulling 84e608c0925f82dee5cd36e27c1e7924563de979 on waffle-badge-adjustment into 56758210d666e3717b32adcfd3553da6cb0d2059 on master.\n. \nCoverage increased (+0.05%) to 66.69% when pulling f5dd8799c5d524985ffcdbbcf4b8716821b7d1b9 on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.05%) to 66.69% when pulling d7c08284e32e760d48c59f8c2799e7f4b7b19bee on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.05%) to 66.69% when pulling d69f7787ef84cbd9f23411266b104d4904760fa7 on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.05%) to 66.69% when pulling 6917adea6bb440ebbafe0576a11b505416f76cb3 on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.05%) to 66.69% when pulling 08ba1ef6e185b98e0f964b718e3c247dcf855fdc on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.05%) to 66.69% when pulling 2a41ea95804d52444108955bc1041288ab94aba3 on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.47%) to 67.12% when pulling 5d2320188f90f9d228811f459ef43309f3f2eb9f on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.45%) to 67.09% when pulling 845685fd105ce52a8e1150e5816b26e3811fb684 on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.45%) to 67.09% when pulling 71af4fe6e70154221202a299822ca337fecebd74 on feature/module-paths into 91ddaa4d4106b54e8dae3ee14c2fbe32cbea3f7b on next.\n. \nCoverage increased (+0.02%) to 67.21% when pulling 72d6c63189fb0f9f3b1a8de4adb29009529ef88d on feature/454-sessionid into 669f000ae9bc22df87b1fb8f064f2c4877d8722a on next.\n. \nCoverage increased (+0.99%) to 68.17% when pulling 1a5c91f408712a9ceccbe216cd092a26d2309ef8 on feature/490-workers into 33fba3b96ab277d224eb7b057adae84380e9e478 on next.\n. \nCoverage increased (+0.99%) to 68.17% when pulling 87924608e6601a0843709b115863653910bcf4e3 on feature/490-workers into 33fba3b96ab277d224eb7b057adae84380e9e478 on next.\n. \nCoverage increased (+1.93%) to 69.12% when pulling b1a2a11258c045f12b29e3157f497c7319669cf0 on feature/490-workers into 33fba3b96ab277d224eb7b057adae84380e9e478 on next.\n. \nCoverage increased (+1.93%) to 69.12% when pulling c26e403b88fbefd7dedee74a2d54aad54818455d on feature/490-workers into 33fba3b96ab277d224eb7b057adae84380e9e478 on next.\n. \nCoverage increased (+0.15%) to 69.27% when pulling 24ab079f55f886b03a0769bd78868af20e75946f on feature/507-packing into a14c38368ccc13d783f301b1ba8f17977f8f570c on next.\n. \nCoverage increased (+0.15%) to 69.27% when pulling b381cbe900849e2e95f6e3d84c22091c105c3cb6 on feature/507-packing into a14c38368ccc13d783f301b1ba8f17977f8f570c on next.\n. \nCoverage increased (+4.12%) to 73.24% when pulling 320d1243f12fc6ccb1ea46313b9686d7559cf7fd on feature/507-packing into a14c38368ccc13d783f301b1ba8f17977f8f570c on next.\n. \nCoverage increased (+4.26%) to 73.37% when pulling 9c951a128cfcdcffec2a25dd725ba0f0ac02d237 on feature/507-packing into a14c38368ccc13d783f301b1ba8f17977f8f570c on next.\n. \nCoverage increased (+4.32%) to 73.44% when pulling 58cdf76ec861c571393fb2678e8edb6e71103a50 on feature/507-packing into a14c38368ccc13d783f301b1ba8f17977f8f570c on next.\n. \nCoverage increased (+4.32%) to 73.44% when pulling ba5e83fd2090f51a64e0c2ba9bc626d42c091519 on feature/507-packing into a14c38368ccc13d783f301b1ba8f17977f8f570c on next.\n. \nCoverage decreased (-0.07%) to 74.08% when pulling 95ccb9a507b55fc2324650b7545efd6f4008b278 on feature/424-require-file-extensions into aaea0d95941489763e60d4d2d65a5a05a6618476 on next.\n. \nCoverage decreased (-0.19%) to 73.96% when pulling fb162bd37405f6b4f82f622cb0722d18733bf638 on feature/507-browserify-in-bundler into 841a372722f56564168fa9b3c5da376311f8601b on next.\n. \nCoverage decreased (-0.19%) to 73.96% when pulling fb162bd37405f6b4f82f622cb0722d18733bf638 on feature/507-browserify-in-bundler into 841a372722f56564168fa9b3c5da376311f8601b on next.\n. \nCoverage decreased (-0.05%) to 74.09% when pulling 6c2eb58a895be49e8ed9a38d2f69e58d3c36cb1c on feature/507-browserify-in-bundler into 841a372722f56564168fa9b3c5da376311f8601b on next.\n. \nCoverage decreased (-0.05%) to 74.09% when pulling 8eeac72e649886f372ca4c8e459754289dfca268 on feature/507-browserify-in-bundler into 841a372722f56564168fa9b3c5da376311f8601b on next.\n. \nCoverage decreased (-0.05%) to 74.09% when pulling 8eeac72e649886f372ca4c8e459754289dfca268 on feature/507-browserify-in-bundler into 841a372722f56564168fa9b3c5da376311f8601b on next.\n. \nCoverage decreased (-1.89%) to 73.08% when pulling 40954fdfe44257a897e09a0693aa90c5865da992 on feature/separate-cli-generator into 9715757a10749834e085629258b2f853bd99a7cf on master.\n. \nCoverage decreased (-1.78%) to 73.79% when pulling abbdebbcfa9ff9d03ea46e3f75f2c054f56f8e9f on separate-cli-generator-v2 into 815c91330c76d018908c6a4c8594a2f22983e332 on master.\n. \nChanges Unknown when pulling 6bd5ed7af7ad0c86c5126a6a10c5dd4f96ec2141 on feature/separate-cli-generator-v3 into * on next*.\n. \nCoverage remained the same at 75.57% when pulling 2fb9ed7054f3bddead9424a04e45bf01c6ddbc78 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage decreased (-0.07%) to 75.5% when pulling 254bf36eb634c039a06d88adb3e1ed431ea279c6 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage remained the same at 75.57% when pulling 254bf36eb634c039a06d88adb3e1ed431ea279c6 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage decreased (-0.07%) to 75.5% when pulling 405349eeebe2a1cee0ed56d6311b3c22421915e0 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage remained the same at 75.57% when pulling af770c754ea3acd3dbc0bed3812b33902c331e1b on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage remained the same at 75.57% when pulling 0163587efa07b0a9a0764ab2777cd2f479a98c93 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage remained the same at 75.57% when pulling 0163587efa07b0a9a0764ab2777cd2f479a98c93 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage remained the same at 75.57% when pulling 2149570b91be0a25e943f3562577d5035309bdc6 on Terebinth:master into 815c91330c76d018908c6a4c8594a2f22983e332 on socketstream:master.\n. \nCoverage remained the same at 75.57% when pulling 894de11e6234928309de733befd5ff62fb929798 on Terebinth:fix_#543 into 4d482ee0340227afd2b2b72562ffe178c75184ca on socketstream:master.\n. \nCoverage increased (+0.78%) to 76.35% when pulling dd7b5ed0858126b86bb2c5928a73aac9b8fa9d47 on feature/lib-publish-tests into f90740d9d78af27907c9dde9ca050bd21975fa73 on master.\n. \nCoverage increased (+0.78%) to 76.35% when pulling dd7b5ed0858126b86bb2c5928a73aac9b8fa9d47 on feature/lib-publish-tests into f90740d9d78af27907c9dde9ca050bd21975fa73 on master.\n. \nCoverage decreased (-0.13%) to 76.22% when pulling ecd7be27a5a615292ba7718b7a4c459cd852d888 on bug/fix-538 into a2921b414afe75ed5f64f0ea94cc6766ffa7ceb4 on master.\n. \nCoverage increased (+0.08%) to 76.36% when pulling 83b11e8f20968af44421028427c75fa5b448b4c2 on feature/added-cli-test into b90361ba3ee6e865d93aac71d203ab56f8604995 on master.\n. \nCoverage increased (+0.55%) to 76.98% when pulling 7f7356e5bfaebcbf10fd57dc7c2f2879c2118fe6 on feature/coexisting-asset-types into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage increased (+0.55%) to 76.98% when pulling 7f7356e5bfaebcbf10fd57dc7c2f2879c2118fe6 on feature/coexisting-asset-types into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage increased (+0.5%) to 76.93% when pulling 5ef3ed025cbafdad4f621ef6c3b4ab7f56a208db on feature/coexisting-asset-types into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage increased (+0.51%) to 76.94% when pulling 10986d945a137d93602b7084383c45dc811dd961 on feature/coexisting-asset-types into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage increased (+0.51%) to 76.94% when pulling 2b527dc84a64e4ed606673fb07c3cca3bd201225 on feature/coexisting-asset-types into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage decreased (-1.47%) to 74.95% when pulling 77fbfbae9f10690e6d3ae50f3b07e80008d49e6f on feature/added-request-test into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage decreased (-1.47%) to 74.95% when pulling 77fbfbae9f10690e6d3ae50f3b07e80008d49e6f on feature/added-request-test into 3cb960fe1473d995c39549dd19129bcd083ba923 on master.\n. \nCoverage increased (+1.94%) to 76.89% when pulling 01718001527aba26501c9c3bf72e7618a325608c on feature/added-request-test into fb1fb883825bc9c903a8be1ee3920ff12547fca5 on master.\n. \nCoverage increased (+0.07%) to 76.96% when pulling 19461975da1538972eec8304d14c8b9bc160d38a on feature/pack-assets-fix into 0add949a30a859fe4225d46bed7fb7b2af7e12ae on master.\n. \nCoverage increased (+0.07%) to 76.96% when pulling de2a732b88e1e53edff8559c9ce1a9368a8aa103 on feature/pack-assets-fix into 0add949a30a859fe4225d46bed7fb7b2af7e12ae on master.\n. \nCoverage increased (+0.1%) to 74.778% when pulling 9df128f5ab20a15ec040df69be191f410f4d0c0b on msand:fix-test-crossplatform into e7cb63d383dc88ff002312f187445d29a86cd41f on socketstream:master.\n. \nCoverage increased (+0.1%) to 74.778% when pulling 9df128f5ab20a15ec040df69be191f410f4d0c0b on msand:fix-test-crossplatform into e7cb63d383dc88ff002312f187445d29a86cd41f on socketstream:master.\n. \nCoverage increased (+0.1%) to 74.778% when pulling 9df128f5ab20a15ec040df69be191f410f4d0c0b on msand:fix-test-crossplatform into e7cb63d383dc88ff002312f187445d29a86cd41f on socketstream:master.\n. \n\nCoverage remained the same at 65.832% when pulling ac4e5ed6893f744fdd9a05c1e6b2dfe45b07aa82 on fix/update-travis-node-versions into 9b25cb2e5ca3fa801ffe07307b4e03dc62a6a483 on develop.\n. \n\nCoverage remained the same at 65.832% when pulling ac4e5ed6893f744fdd9a05c1e6b2dfe45b07aa82 on fix/update-travis-node-versions into 9b25cb2e5ca3fa801ffe07307b4e03dc62a6a483 on develop.\n. ",
    "louh": "@paulbjensen Yes. As @thepian mentioned, I did think that perhaps defining a middleware would be the way to go, but I hadn't had any luck with it (mostly due to my own inexperience and stupidity).\nBasically, assuming I can get Davis to ignore any routes it doesn't explicitly handle (which I think I can) it then passes the route to the server, at which point SocketStream takes over. At this point, SocketStream treats everything like loading the server root `/, sends all the single-page app client files, and Davis reads the route and does what it does - except I don't really want SS to do that! I want SS to either serve my JSON content or delegate those routes to Express. In Express, it would be something as simple as:\napp.get('/path/to/json', function (req, res) {\n   res.set('Content-Type', 'application/json')\n   res.send(200, jsonContent)\n}\nThat's it. I just want SocketStream to let this happen.\nFWIW, this isn't supposed to be an AJAX call for data, because the use case isn't intended for a client side script. The use case here is an administrator requests a data dump of what's on the backend, so the server simply serves up a file that is intended to be downloaded and saved to a local machine. Now, if the easiest way to do this is also via RPC within the SS framework, and we can send a file with the correct headers that way, I am open to that too.\n. Hey @paulbjensen, I think it's definitely on the right track: I gave it a shot before getting pulled onto another project for a few days, but setting up the middleware did seem to successfully be able to send the correct headers for a JSON response, which was exactly the answer to my question. (Now I have some other things to do to send the right data, but that ball is in my court :P)\nThanks!\n. Yes, go ahead.\n. @paulbjensen Yes. As @thepian mentioned, I did think that perhaps defining a middleware would be the way to go, but I hadn't had any luck with it (mostly due to my own inexperience and stupidity).\nBasically, assuming I can get Davis to ignore any routes it doesn't explicitly handle (which I think I can) it then passes the route to the server, at which point SocketStream takes over. At this point, SocketStream treats everything like loading the server root `/, sends all the single-page app client files, and Davis reads the route and does what it does - except I don't really want SS to do that! I want SS to either serve my JSON content or delegate those routes to Express. In Express, it would be something as simple as:\napp.get('/path/to/json', function (req, res) {\n   res.set('Content-Type', 'application/json')\n   res.send(200, jsonContent)\n}\nThat's it. I just want SocketStream to let this happen.\nFWIW, this isn't supposed to be an AJAX call for data, because the use case isn't intended for a client side script. The use case here is an administrator requests a data dump of what's on the backend, so the server simply serves up a file that is intended to be downloaded and saved to a local machine. Now, if the easiest way to do this is also via RPC within the SS framework, and we can send a file with the correct headers that way, I am open to that too.\n. Hey @paulbjensen, I think it's definitely on the right track: I gave it a shot before getting pulled onto another project for a few days, but setting up the middleware did seem to successfully be able to send the correct headers for a JSON response, which was exactly the answer to my question. (Now I have some other things to do to send the right data, but that ball is in my court :P)\nThanks!\n. Yes, go ahead.\n. ",
    "seanhussey": "I think the saying goes \"Never attribute to malice that which is adequately explained by keyboard error.\" :)\n. I think the saying goes \"Never attribute to malice that which is adequately explained by keyboard error.\" :)\n. ",
    "greenpdx": "If there is anything I can do to help, please let me know.\nOn 01/02/2015 11:09 AM, Paul Jensen wrote:\n\nHi, Thanks for filing the issue. I'll take a look into it.\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/socketstream/socketstream/issues/474#issuecomment-68552706.\n. my nodejs is 10.25,  I will try to upgrade it.\n\nshaun\nOn 01/02/2015 11:25 AM, Paul Jensen wrote:\n\nHi @greenpdx https://github.com/greenpdx,\nI had a look at the issue that you mentioned. I haven't been able to \nreplicate the error that you encountered.\nCan I check the following?\n- That you generated a new SocketStream app with default settings\n- What version of Node.js you are using (I am using 0.10.35)\n- That the server/middleware/example.js file exists, and returns a\n  function.\n- That you uncommented line 10 in server/rpc/demo.js\nRegards,\nPaul Jensen\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/socketstream/socketstream/issues/474#issuecomment-68554035.\n. I upgraded to 10.33.  the problem is node-debug.\n\nWhen I run nodejs app.js  it works\nIf I run node-debug I get the error.\nNow how to debug nodejs on the server without using node-debug?\nOn 01/02/2015 11:25 AM, Paul Jensen wrote:\n\nHi @greenpdx https://github.com/greenpdx,\nI had a look at the issue that you mentioned. I haven't been able to \nreplicate the error that you encountered.\nCan I check the following?\n- That you generated a new SocketStream app with default settings\n- What version of Node.js you are using (I am using 0.10.35)\n- That the server/middleware/example.js file exists, and returns a\n  function.\n- That you uncommented line 10 in server/rpc/demo.js\nRegards,\nPaul Jensen\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/socketstream/socketstream/issues/474#issuecomment-68554035.\n. Got the fixed.\n\nthanks\nOn 01/02/2015 11:25 AM, Paul Jensen wrote:\n\nHi @greenpdx https://github.com/greenpdx,\nI had a look at the issue that you mentioned. I haven't been able to \nreplicate the error that you encountered.\nCan I check the following?\n- That you generated a new SocketStream app with default settings\n- What version of Node.js you are using (I am using 0.10.35)\n- That the server/middleware/example.js file exists, and returns a\n  function.\n- That you uncommented line 10 in server/rpc/demo.js\nRegards,\nPaul Jensen\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/socketstream/socketstream/issues/474#issuecomment-68554035.\n. If there is anything I can do to help, please let me know.\n\nOn 01/02/2015 11:09 AM, Paul Jensen wrote:\n\nHi, Thanks for filing the issue. I'll take a look into it.\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/socketstream/socketstream/issues/474#issuecomment-68552706.\n. my nodejs is 10.25,  I will try to upgrade it.\n\nshaun\nOn 01/02/2015 11:25 AM, Paul Jensen wrote:\n\nHi @greenpdx https://github.com/greenpdx,\nI had a look at the issue that you mentioned. I haven't been able to \nreplicate the error that you encountered.\nCan I check the following?\n- That you generated a new SocketStream app with default settings\n- What version of Node.js you are using (I am using 0.10.35)\n- That the server/middleware/example.js file exists, and returns a\n  function.\n- That you uncommented line 10 in server/rpc/demo.js\nRegards,\nPaul Jensen\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/socketstream/socketstream/issues/474#issuecomment-68554035.\n. I upgraded to 10.33.  the problem is node-debug.\n\nWhen I run nodejs app.js  it works\nIf I run node-debug I get the error.\nNow how to debug nodejs on the server without using node-debug?\nOn 01/02/2015 11:25 AM, Paul Jensen wrote:\n\nHi @greenpdx https://github.com/greenpdx,\nI had a look at the issue that you mentioned. I haven't been able to \nreplicate the error that you encountered.\nCan I check the following?\n- That you generated a new SocketStream app with default settings\n- What version of Node.js you are using (I am using 0.10.35)\n- That the server/middleware/example.js file exists, and returns a\n  function.\n- That you uncommented line 10 in server/rpc/demo.js\nRegards,\nPaul Jensen\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/socketstream/socketstream/issues/474#issuecomment-68554035.\n. Got the fixed.\n\nthanks\nOn 01/02/2015 11:25 AM, Paul Jensen wrote:\n\nHi @greenpdx https://github.com/greenpdx,\nI had a look at the issue that you mentioned. I haven't been able to \nreplicate the error that you encountered.\nCan I check the following?\n- That you generated a new SocketStream app with default settings\n- What version of Node.js you are using (I am using 0.10.35)\n- That the server/middleware/example.js file exists, and returns a\n  function.\n- That you uncommented line 10 in server/rpc/demo.js\nRegards,\nPaul Jensen\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/socketstream/socketstream/issues/474#issuecomment-68554035.\n. \n",
    "lafras-h": "The default parameters are almost identical to the original live reload, so the tests should be affected the same, alternatively set the delay very long, or disable altogether.\n. If you refer to DelayTime,GuardTime,Publish,Validate\nI will fix that when I do the revision ... old habits die hard.\nOn 2015/02/22 05:00 PM, Henrik Vendelbo wrote:\n\nWhy the capitalised names? Is that required by live-reload?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/pull/499#issuecomment-75439156.\n. Delay time is the initial, time the first change is delayed for,\nguardTime is the time after the last change.\n\nThis is a new patch, make sure are you running it against a version with \nthe patch in it, check the file live_reload.js refers to guardTime\nalso check the location : is after setting packAssets (more or less)\nif (ss.env === 'production')\n    ss.client.packAssets();\nss.client.set({....\nOn 2015/02/28 12:14 PM, Paul Jensen wrote:\n\nHi,\nIs the |delayTime| attribute meant to delay executing the next reload? I\ntried this code snippet in my app, but it didn't seem to slow down when\nreloads were executed:\n|ss.client.set({\n     onChange: {\n         delayTime:5000,\n         guardTime:8000,\n         validate: function (path, event,action) {\n             console.log('onChangeValidate :', path);\n             return true;\n         },\n         publish:function (path, event,action,pubs) {\n             console.log('onChange.Publish :', action);\n             //modify pubs if needed return null to not send any pubs\n             return pubs;\n         }\n     }\n});\n|\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/pull/499#issuecomment-76520193.\n. The default parameters are almost identical to the original live reload, so the tests should be affected the same, alternatively set the delay very long, or disable altogether.\n. If you refer to DelayTime,GuardTime,Publish,Validate\n\nI will fix that when I do the revision ... old habits die hard.\nOn 2015/02/22 05:00 PM, Henrik Vendelbo wrote:\n\nWhy the capitalised names? Is that required by live-reload?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/pull/499#issuecomment-75439156.\n. Delay time is the initial, time the first change is delayed for,\nguardTime is the time after the last change.\n\nThis is a new patch, make sure are you running it against a version with \nthe patch in it, check the file live_reload.js refers to guardTime\nalso check the location : is after setting packAssets (more or less)\nif (ss.env === 'production')\n    ss.client.packAssets();\nss.client.set({....\nOn 2015/02/28 12:14 PM, Paul Jensen wrote:\n\nHi,\nIs the |delayTime| attribute meant to delay executing the next reload? I\ntried this code snippet in my app, but it didn't seem to slow down when\nreloads were executed:\n|ss.client.set({\n     onChange: {\n         delayTime:5000,\n         guardTime:8000,\n         validate: function (path, event,action) {\n             console.log('onChangeValidate :', path);\n             return true;\n         },\n         publish:function (path, event,action,pubs) {\n             console.log('onChange.Publish :', action);\n             //modify pubs if needed return null to not send any pubs\n             return pubs;\n         }\n     }\n});\n|\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/socketstream/socketstream/pull/499#issuecomment-76520193.\n. \n",
    "afrozl": "@kulicuu - does anything special have to be done to integrate socketstream with Express4?\nI am attempting to integrate socketstream (Dashku) with Express (keystonejs) and running into issues \nhttps://github.com/dashku/dashku/issues/64\n. @kulicuu - does anything special have to be done to integrate socketstream with Express4?\nI am attempting to integrate socketstream (Dashku) with Express (keystonejs) and running into issues \nhttps://github.com/dashku/dashku/issues/64\n. ",
    "expelledboy": "@thepian I see you have an item to support socketcluster. Could you detail briefly what socketcluster is compared to socketstream? They are both large libraries and I am struggling to see whether they are alternatives, or can be integrated.\n. @thepian I see you have an item to support socketcluster. Could you detail briefly what socketcluster is compared to socketstream? They are both large libraries and I am struggling to see whether they are alternatives, or can be integrated.\n. ",
    "auch188": "Hi guys\nThanks for the replies. I figured it out. I needed to call my external Redis db instance directly from the server in my server/rpc/example.js file instead of using ss.api.db.\nPlease close\n. Hi guys\nThanks for the replies. I figured it out. I needed to call my external Redis db instance directly from the server in my server/rpc/example.js file instead of using ss.api.db.\nPlease close\n. ",
    "davidsketchdeck": "A) you guys rock\nB) sorry i was so slow\n--\u00a0\nDavid MackCTO & Co-Founder, SketchDeck\nsketchdeck.com\nSee examples of our work\nOn Sat, Apr 4, 2015 at 1:53 AM, Henrik Vendelbo notifications@github.com\nwrote:\n\nReimplemented it for 0.4\nhttps://github.com/socketstream/socketstream/commit/669f000ae9bc22df87b1fb8f064f2c4877d8722a\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/pull/519#issuecomment-89530588\n. Sure! I\u2019ll try it on an experimental branch of sketchdeck\n\n--\u00a0\nDavid MackCTO & Co-Founder, SketchDeck\nsketchdeck.com\nSee examples of our work\nOn Tue, Apr 7, 2015 at 11:40 AM, Henrik Vendelbo notifications@github.com\nwrote:\n\nA) Glad for the thumbs up\nB) You can help by trying out 0.4 and reporting any issues you have as soon as possible, it is on the next branch and will be released in beta soon\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/pull/519#issuecomment-90693999\n. A) you guys rock\n\nB) sorry i was so slow\n--\u00a0\nDavid MackCTO & Co-Founder, SketchDeck\nsketchdeck.com\nSee examples of our work\nOn Sat, Apr 4, 2015 at 1:53 AM, Henrik Vendelbo notifications@github.com\nwrote:\n\nReimplemented it for 0.4\nhttps://github.com/socketstream/socketstream/commit/669f000ae9bc22df87b1fb8f064f2c4877d8722a\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/pull/519#issuecomment-89530588\n. Sure! I\u2019ll try it on an experimental branch of sketchdeck\n\n--\u00a0\nDavid MackCTO & Co-Founder, SketchDeck\nsketchdeck.com\nSee examples of our work\nOn Tue, Apr 7, 2015 at 11:40 AM, Henrik Vendelbo notifications@github.com\nwrote:\n\nA) Glad for the thumbs up\nB) You can help by trying out 0.4 and reporting any issues you have as soon as possible, it is on the next branch and will be released in beta soon\nReply to this email directly or view it on GitHub:\nhttps://github.com/socketstream/socketstream/pull/519#issuecomment-90693999\n. \n",
    "hulmgulm": "While trying to figuring out our problems with socketstream (https://groups.google.com/forum/#!topic/socketstream/lCZRU2whpQw) we came across this code too. Why do you expect the session cookie to be the first or third cookie? Why not look for the cookie name? Then it doesn't matter in which order the cookies are set. According to the error message at the end of this function, the cookie should always be connect.sid.\nWe were setting additional cookies a few days ago which led to strange problems like \"undefinded\" or \"true\" as session id. Or to constantly changing sessions ids.\n. Looks good with the exception of these \"var c = \" statements\n. Small update:\nwe use connect-route for routing our HTTP requests. I've appended a middleware before the connect-route middleware to add session information to the request object.\nTo get the correct session, I do the following:\nvar sessionId = encodeURIComponent('s:'+signature.sign(req.session.id,socketstream.session.options.secret));\nsocketstream.session.find(sessionId, null, function(session) {\nIs this the intended way to do this?\n. While trying to figuring out our problems with socketstream (https://groups.google.com/forum/#!topic/socketstream/lCZRU2whpQw) we came across this code too. Why do you expect the session cookie to be the first or third cookie? Why not look for the cookie name? Then it doesn't matter in which order the cookies are set. According to the error message at the end of this function, the cookie should always be connect.sid.\nWe were setting additional cookies a few days ago which led to strange problems like \"undefinded\" or \"true\" as session id. Or to constantly changing sessions ids.\n. Looks good with the exception of these \"var c = \" statements\n. Small update:\nwe use connect-route for routing our HTTP requests. I've appended a middleware before the connect-route middleware to add session information to the request object.\nTo get the correct session, I do the following:\nvar sessionId = encodeURIComponent('s:'+signature.sign(req.session.id,socketstream.session.options.secret));\nsocketstream.session.find(sessionId, null, function(session) {\nIs this the intended way to do this?\n. ",
    "ilyador": "Where can I find a 0.4 app example?\n. Where can I find a 0.4 app example?\n. ",
    "ChristianEnchelmaier": "Same issue here, will there be a fix shortly or is there any workaround?\n! Error: C:\\prj\\Dashku\\client\\templates\\* directory not found\n. Hi Paul,\nthanks for the quick reply. The fix worked directly - i've sent u a pull request.\n. Same issue here, will there be a fix shortly or is there any workaround?\n! Error: C:\\prj\\Dashku\\client\\templates\\* directory not found\n. Hi Paul,\nthanks for the quick reply. The fix worked directly - i've sent u a pull request.\n. ",
    "cuckoopt": "I was talking about the 0.4.4, I tried to run the tests with that line both with 0.4.4 and 0.5.0 and in the 2 of them I get\njavascript\n! task failed { [Error: task \"test-socketstream\" is not defined]\n  missingTask: 'test-socketstream',\n  taskList: \n   [ 'start-server',\n     'load-api',\n     'load-socketstream',\n     'serve',\n     'live-assets',\n     'live-reload',\n     'stop-server',\n     'default',\n     'pack-all',\n     'pack-if-needed',\n     'pack-prepare' ] }\n. @thepian Sorry, I didn't test with that branch, I tested with it (without the done callback, outside of the describes) and it seems to be working fine :+1: \nbtw (offtopic) the newer versions will bring the updated deps? it's a bummer to not be using node 4 to installing this... :stuck_out_tongue: \n. I was talking about the 0.4.4, I tried to run the tests with that line both with 0.4.4 and 0.5.0 and in the 2 of them I get\njavascript\n! task failed { [Error: task \"test-socketstream\" is not defined]\n  missingTask: 'test-socketstream',\n  taskList: \n   [ 'start-server',\n     'load-api',\n     'load-socketstream',\n     'serve',\n     'live-assets',\n     'live-reload',\n     'stop-server',\n     'default',\n     'pack-all',\n     'pack-if-needed',\n     'pack-prepare' ] }\n. @thepian Sorry, I didn't test with that branch, I tested with it (without the done callback, outside of the describes) and it seems to be working fine :+1: \nbtw (offtopic) the newer versions will bring the updated deps? it's a bummer to not be using node 4 to installing this... :stuck_out_tongue: \n. ",
    "StuartHickey": "Hi,\nI've been working on getting a simple app up and running using Socketstream and Koa. It's working fairly well so far and I have the authentication path working but I want to add in JWT support. At the moment I return a token after successful login and save that to local storage. I have a number of components where I do RPC calls back to the server to get some data and i want to include the token and then validate it server side and if all is well return the data or return and error if no valid token is supplied. \nAny advice on how to go about this?\nI've seen some discussions in old issues about this but no real conclusions on how to integrate token based authentication with Socketstream. \nAny assistance, and code examples, would be much appreciated. \n.... later on ...\nOk thanks ... good to know it's a high priority for you too. Congrats on the new role by the way!!\n. Hi,\nI've been working on getting a simple app up and running using Socketstream and Koa. It's working fairly well so far and I have the authentication path working but I want to add in JWT support. At the moment I return a token after successful login and save that to local storage. I have a number of components where I do RPC calls back to the server to get some data and i want to include the token and then validate it server side and if all is well return the data or return and error if no valid token is supplied. \nAny advice on how to go about this?\nI've seen some discussions in old issues about this but no real conclusions on how to integrate token based authentication with Socketstream. \nAny assistance, and code examples, would be much appreciated. \n.... later on ...\nOk thanks ... good to know it's a high priority for you too. Congrats on the new role by the way!!\n. ",
    "gbraad": "I haven't been able to look into this further in recent time. The proxy rewrite would not be a problem, but having the flexibility from within socketstream to define the paths would be appreciated, although not essential. It would be considered advanced functionality. Note: the proxy-ing in question is really lightweight and does not involve nginx as it is done on a simple ARM-based device using only Node.js\n. I haven't been able to look into this further in recent time. The proxy rewrite would not be a problem, but having the flexibility from within socketstream to define the paths would be appreciated, although not essential. It would be considered advanced functionality. Note: the proxy-ing in question is really lightweight and does not involve nginx as it is done on a simple ARM-based device using only Node.js\n. ",
    "aaroncalderon": "@arxpoetica  I am using version 5.2\nUnless this is an issue with npm. Is npm supposed to run the npm install on every package it installed? However, this is the first time I see this issue happen with any -g package I install. \nRegards.\n. @paulbjensen Can you please reopen this issue as its partially solved? I have installed the develop branch as my global socketstream module. I accomplished this by cloning the develop git branch to my computer and then using that folder to install the module with npm: npm install -g \"/path/to/git/folder/\"\nHowever I still get the same error for installing new socketstream app (original issue # 1) :\nPlease note that I have set a custom path for my npm installation.\n```\nsocketstream new ss-app2\nmodule.js:338\n    throw err;\n    ^\nError: Cannot find module 'commander'\n    at Function.Module._resolveFilename (module.js:336:15)\n    at Function.Module._load (module.js:286:25)\n    at Module.require (module.js:365:17)\n    at require (module.js:384:17)\n    at Object. (C:\\dev\\npm\\node_modules\\socketstream\\bin\\socketstream:4:15)\n    at Module._compile (module.js:434:26)\n    at Object.Module._extensions..js (module.js:452:10)\n    at Module.load (module.js:355:32)\n    at Function.Module._load (module.js:310:12)\n    at Function.Module.runMain (module.js:475:10)\n```\nAfter getting this error, I did the following:\ncd C:\\dev\\npm\\node_modules\\socketstream\nnpm install\nThe output of that command was as follows:\n```\nnpm WARN deprecated lodash@0.9.2: lodash@<2.0.0 is no longer maintained. Upgrade to lodash@^3.0.0\nnpm WARN optional dep failed, continuing fsevents@1.0.6\nnpm WARN deprecated lodash@1.0.2: lodash@<2.0.0 is no longer maintained. Upgrade to lodash@^3.0.0\n\nspawn-sync@1.0.13 postinstall C:\\dev\\npm\\node_modules\\socketstream\\node_modules\\pre-commit\\node_modules\\cross-spawn\\node_modules\\spawn-sync\nnode postinstall\npre-commit@1.1.2 install C:\\dev\\npm\\node_modules\\socketstream\\node_modules\\pre-commit\nnode install.js\n\nnpm WARN engine hawk@0.10.2: wanted: {\"node\":\"0.8.x\"} (current: {\"node\":\"4.1.1\",\"npm\":\"2.14.4\"})\nnpm WARN engine sntp@0.1.4: wanted: {\"node\":\"0.8.x\"} (current: {\"node\":\"4.1.1\",\"npm\":\"2.14.4\"})\nnpm WARN engine boom@0.3.8: wanted: {\"node\":\"0.8.x\"} (current: {\"node\":\"4.1.1\",\"npm\":\"2.14.4\"})\nnpm WARN engine cryptiles@0.1.3: wanted: {\"node\":\"0.8.x\"} (current: {\"node\":\"4.1.1\",\"npm\":\"2.14.4\"})\nnpm WARN engine hoek@0.7.6: wanted: {\"node\":\"0.8.x\"} (current: {\"node\":\"4.1.1\",\"npm\":\"2.14.4\"})\nsinon-chai@2.8.0 node_modules\\sinon-chai\nconnect-livereload@0.5.4 node_modules\\connect-livereload\nnotes@0.0.4 node_modules\\notes\ngently@0.10.0 node_modules\\gently\nlolex@1.4.0 node_modules\\lolex\nsemver@5.0.3 node_modules\\semver\ncommander@2.8.1 node_modules\\commander\n\u2514\u2500\u2500 graceful-readlink@1.0.1\ncookie-parser@1.4.0 node_modules\\cookie-parser\n\u251c\u2500\u2500 cookie-signature@1.0.6\n\u2514\u2500\u2500 cookie@0.2.2\ngrunt-contrib-clean@0.6.0 node_modules\\grunt-contrib-clean\n\u2514\u2500\u2500 rimraf@2.2.8\nshelljs@0.5.3 node_modules\\shelljs\nexpress-session@1.12.1 node_modules\\express-session\n\u251c\u2500\u2500 on-headers@1.0.1\n\u251c\u2500\u2500 cookie-signature@1.0.6\n\u251c\u2500\u2500 depd@1.1.0\n\u251c\u2500\u2500 crc@3.3.0\n\u2514\u2500\u2500 uid-safe@2.0.0 (base64-url@1.2.1)\nshould@7.1.1 node_modules\\should\n\u251c\u2500\u2500 should-type@0.2.0\n\u251c\u2500\u2500 should-equal@0.5.0\n\u2514\u2500\u2500 should-format@0.3.1\nnpm-dview@2.0.0 node_modules\\npm-dview\n\u251c\u2500\u2500 progress@1.1.8\n\u251c\u2500\u2500 supports-color@3.1.2 (has-flag@1.0.0)\n\u2514\u2500\u2500 cli-table@0.3.1 (colors@1.0.3)\ngrunt-conventional-changelog@4.1.0 node_modules\\grunt-conventional-changelog\n\u251c\u2500\u2500 q@1.4.1\n\u251c\u2500\u2500 plur@2.1.2 (irregular-plurals@1.1.0)\n\u251c\u2500\u2500 chalk@1.1.1 (escape-string-regexp@1.0.4, ansi-styles@2.1.0, supports-color@2.0.0, strip-ansi@3.0.0, has-ansi@2.0.0)\n\u2514\u2500\u2500 concat-stream@1.5.1 (inherits@2.0.1, typedarray@0.0.6, readable-stream@2.0.5)\nchai@3.4.1 node_modules\\chai\n\u251c\u2500\u2500 assertion-error@1.0.1\n\u251c\u2500\u2500 type-detect@1.0.0\n\u2514\u2500\u2500 deep-eql@0.1.3 (type-detect@0.1.1)\ngrunt-ngdocs@0.2.9 node_modules\\grunt-ngdocs\n\u251c\u2500\u2500 marked@0.3.5\n\u2514\u2500\u2500 shelljs@0.3.0\ngrunt-contrib-watch@0.6.1 node_modules\\grunt-contrib-watch\n\u251c\u2500\u2500 async@0.2.10\n\u251c\u2500\u2500 lodash@2.4.2\n\u251c\u2500\u2500 tiny-lr-fork@0.0.5 (debug@0.7.4, qs@0.5.6, faye-websocket@0.4.4, noptify@0.0.3)\n\u2514\u2500\u2500 gaze@0.5.2 (globule@0.1.0)\nsupertest@1.1.0 node_modules\\supertest\n\u251c\u2500\u2500 methods@1.1.1\n\u2514\u2500\u2500 superagent@1.3.0 (extend@1.2.1, cookiejar@2.0.1, methods@1.0.1, reduce-component@1.0.1, component-emitter@1.1.2, mime@1.3.4, qs@2.3.3, readable-stream@1.0.27-1, formidable@1.0.14, form-data@0.2.0)\ngrunt-cli@0.1.13 node_modules\\grunt-cli\n\u251c\u2500\u2500 nopt@1.0.10 (abbrev@1.0.7)\n\u251c\u2500\u2500 resolve@0.3.1\n\u2514\u2500\u2500 findup-sync@0.1.3 (lodash@2.4.2, glob@3.2.11)\nsinon@1.17.2 node_modules\\sinon\n\u251c\u2500\u2500 formatio@1.1.1\n\u251c\u2500\u2500 samsam@1.1.2\n\u251c\u2500\u2500 lolex@1.3.2\n\u2514\u2500\u2500 util@0.10.3 (inherits@2.0.1)\npre-commit@1.1.2 node_modules\\pre-commit\n\u251c\u2500\u2500 which@1.1.2 (is-absolute@0.1.7)\n\u2514\u2500\u2500 cross-spawn@2.0.1 (cross-spawn-async@2.1.1, spawn-sync@1.0.13)\ngrunt@0.4.5 node_modules\\grunt\n\u251c\u2500\u2500 dateformat@1.0.2-1.2.3\n\u251c\u2500\u2500 which@1.0.9\n\u251c\u2500\u2500 async@0.1.22\n\u251c\u2500\u2500 getobject@0.1.0\n\u251c\u2500\u2500 colors@0.6.2\n\u251c\u2500\u2500 lodash@0.9.2\n\u251c\u2500\u2500 rimraf@2.2.8\n\u251c\u2500\u2500 hooker@0.2.3\n\u251c\u2500\u2500 grunt-legacy-util@0.2.0\n\u251c\u2500\u2500 exit@0.1.2\n\u251c\u2500\u2500 nopt@1.0.10 (abbrev@1.0.7)\n\u251c\u2500\u2500 coffee-script@1.3.3\n\u251c\u2500\u2500 iconv-lite@0.2.11\n\u251c\u2500\u2500 underscore.string@2.2.1\n\u251c\u2500\u2500 minimatch@0.2.14 (sigmund@1.0.1, lru-cache@2.7.3)\n\u251c\u2500\u2500 glob@3.1.21 (inherits@1.0.2, graceful-fs@1.2.3)\n\u251c\u2500\u2500 grunt-legacy-log@0.1.3 (grunt-legacy-log-utils@0.1.1, lodash@2.4.2, underscore.string@2.3.3)\n\u251c\u2500\u2500 findup-sync@0.1.3 (lodash@2.4.2, glob@3.2.11)\n\u2514\u2500\u2500 js-yaml@2.0.5 (esprima@1.0.4, argparse@0.1.16)\ngrunt-contrib-connect@0.11.2 node_modules\\grunt-contrib-connect\n\u251c\u2500\u2500 opn@1.0.2\n\u251c\u2500\u2500 async@0.9.2\n\u251c\u2500\u2500 serve-static@1.10.0 (escape-html@1.0.2)\n\u251c\u2500\u2500 portscanner@1.0.0 (async@0.1.15)\n\u251c\u2500\u2500 morgan@1.6.1 (basic-auth@1.0.3, on-headers@1.0.1, depd@1.0.1, on-finished@2.3.0)\n\u251c\u2500\u2500 connect@3.4.0 (finalhandler@0.4.0)\n\u2514\u2500\u2500 serve-index@1.7.2 (escape-html@1.0.2, batch@0.5.2, http-errors@1.3.1, mime-types@2.1.8, accepts@1.2.13)\nmocha@2.3.4 node_modules\\mocha\n\u251c\u2500\u2500 escape-string-regexp@1.0.2\n\u251c\u2500\u2500 commander@2.3.0\n\u251c\u2500\u2500 diff@1.4.0\n\u251c\u2500\u2500 growl@1.8.1\n\u251c\u2500\u2500 supports-color@1.2.0\n\u251c\u2500\u2500 mkdirp@0.5.0 (minimist@0.0.8)\n\u251c\u2500\u2500 jade@0.26.3 (commander@0.6.1, mkdirp@0.3.0)\n\u2514\u2500\u2500 glob@3.2.3 (inherits@2.0.1, graceful-fs@2.0.3, minimatch@0.2.14)\ndgeni@0.4.1 node_modules\\dgeni\n\u251c\u2500\u2500 canonical-path@0.0.2\n\u251c\u2500\u2500 di@0.0.1\n\u251c\u2500\u2500 q@0.9.7\n\u251c\u2500\u2500 lodash@2.4.2\n\u251c\u2500\u2500 validate.js@0.2.0\n\u251c\u2500\u2500 dependency-graph@0.1.0 (underscore@1.4.4)\n\u251c\u2500\u2500 optimist@0.6.1 (wordwrap@0.0.3, minimist@0.0.10)\n\u2514\u2500\u2500 winston@0.7.3 (cycle@1.0.3, async@0.2.10, stack-trace@0.0.9, eyes@0.1.8, colors@0.6.2, pkginfo@0.3.1, request@2.16.6)\ncoveralls@2.11.6 node_modules\\coveralls\n\u251c\u2500\u2500 lcov-parse@0.0.6\n\u251c\u2500\u2500 log-driver@1.2.4\n\u251c\u2500\u2500 minimist@1.2.0\n\u251c\u2500\u2500 js-yaml@3.0.1 (esprima@1.0.4, argparse@0.1.16)\n\u2514\u2500\u2500 request@2.67.0 (forever-agent@0.6.1, aws-sign2@0.6.0, tunnel-agent@0.4.2, is-typedarray@1.0.0, oauth-sign@0.8.0, form-data@1.0.0-rc3, caseless@0.11.0, stringstream@0.0.5, isstream@0.1.2, json-stringify-safe@5.0.1, extend@3.0.0, tough-cookie@2.2.1, qs@5.2.0, node-uuid@1.4.7, mime-types@2.1.8, combined-stream@1.0.5, bl@1.0.0, hawk@3.1.2, http-signature@1.1.0, har-validator@2.0.3)\nchokidar@1.1.0 node_modules\\chokidar\n\u251c\u2500\u2500 path-is-absolute@1.0.0\n\u251c\u2500\u2500 anymatch@1.3.0\n\u251c\u2500\u2500 arrify@1.0.1\n\u251c\u2500\u2500 glob-parent@2.0.0\n\u251c\u2500\u2500 async-each@0.1.6\n\u251c\u2500\u2500 is-glob@2.0.1 (is-extglob@1.0.0)\n\u251c\u2500\u2500 is-binary-path@1.0.1 (binary-extensions@1.4.0)\n\u2514\u2500\u2500 readdirp@2.0.0 (graceful-fs@4.1.2, readable-stream@2.0.5, minimatch@2.0.10)\njshint@2.8.0 node_modules\\jshint\n\u251c\u2500\u2500 strip-json-comments@1.0.4\n\u251c\u2500\u2500 exit@0.1.2\n\u251c\u2500\u2500 shelljs@0.3.0\n\u251c\u2500\u2500 lodash@3.7.0\n\u251c\u2500\u2500 console-browserify@1.1.0 (date-now@0.1.4)\n\u251c\u2500\u2500 cli@0.6.6 (glob@3.2.11)\n\u251c\u2500\u2500 htmlparser2@3.8.3 (domelementtype@1.3.0, entities@1.0.0, domhandler@2.3.0, readable-stream@1.1.13, domutils@1.5.1)\n\u2514\u2500\u2500 minimatch@2.0.10 (brace-expansion@1.1.2)\nistanbul@0.3.22 node_modules\\istanbul\n\u251c\u2500\u2500 abbrev@1.0.7\n\u251c\u2500\u2500 wordwrap@1.0.0\n\u251c\u2500\u2500 nopt@3.0.6\n\u251c\u2500\u2500 esprima@2.5.0\n\u251c\u2500\u2500 once@1.3.3 (wrappy@1.0.1)\n\u251c\u2500\u2500 supports-color@3.1.2 (has-flag@1.0.0)\n\u251c\u2500\u2500 mkdirp@0.5.1 (minimist@0.0.8)\n\u251c\u2500\u2500 which@1.2.1 (is-absolute@0.1.7)\n\u251c\u2500\u2500 escodegen@1.7.1 (estraverse@1.9.3, esutils@2.0.2, esprima@1.2.5, optionator@0.5.0, source-map@0.2.0)\n\u251c\u2500\u2500 js-yaml@3.4.6 (inherit@2.2.2, esprima@2.7.1, argparse@1.0.3)\n\u251c\u2500\u2500 handlebars@4.0.5 (source-map@0.4.4, optimist@0.6.1, uglify-js@2.6.1)\n\u2514\u2500\u2500 fileset@0.2.1 (minimatch@2.0.10)\nfs-extra@0.24.0 node_modules\\fs-extra\n\u251c\u2500\u2500 path-is-absolute@1.0.0\n\u251c\u2500\u2500 jsonfile@2.2.3\n\u251c\u2500\u2500 graceful-fs@4.1.2\n\u2514\u2500\u2500 rimraf@2.5.0 (glob@6.0.2)\ngrunt-concurrent@2.0.4 node_modules\\grunt-concurrent\n\u251c\u2500\u2500 indent-string@2.1.0 (repeating@2.0.0)\n\u2514\u2500\u2500 pad-stream@1.2.0 (split2@1.1.0, repeating@2.0.0, through2@2.0.0, pumpify@1.3.3, meow@3.6.0)\nconventional-changelog@0.4.3 node_modules\\conventional-changelog\n\u251c\u2500\u2500 q@1.4.1\n\u251c\u2500\u2500 add-stream@1.0.0\n\u251c\u2500\u2500 git-semver-tags@1.1.0\n\u251c\u2500\u2500 lodash@3.10.1\n\u251c\u2500\u2500 compare-func@1.3.1 (array-ify@1.0.0, dot-prop@2.2.0)\n\u251c\u2500\u2500 tempfile@1.1.1 (os-tmpdir@1.0.1)\n\u251c\u2500\u2500 dateformat@1.0.12 (get-stdin@4.0.1)\n\u251c\u2500\u2500 through2@2.0.0 (xtend@4.0.1, readable-stream@2.0.5)\n\u251c\u2500\u2500 conventional-commits-parser@0.1.2 (trim-off-newlines@1.0.0, is-text-path@1.0.1, split@1.0.0, JSONStream@1.0.7)\n\u251c\u2500\u2500 git-raw-commits@0.1.2 (split2@1.1.0, dargs@4.0.1, lodash.template@3.6.2)\n\u251c\u2500\u2500 conventional-changelog-writer@0.3.2 (conventional-commits-filter@0.1.1, split@1.0.0, handlebars@3.0.3)\n\u251c\u2500\u2500 get-pkg-repo@0.1.0 (hosted-git-info@2.1.4, normalize-package-data@2.3.5)\n\u2514\u2500\u2500 meow@3.6.0 (trim-newlines@1.0.0, object-assign@4.0.1, minimist@1.2.0, camelcase-keys@2.0.0, loud-rejection@1.2.0, normalize-package-data@2.3.5, redent@1.0.0, read-pkg-up@1.0.1)\nvinyl-fs@2.0.0 node_modules\\vinyl-fs\n\u251c\u2500\u2500 is-valid-glob@0.3.0\n\u251c\u2500\u2500 object-assign@4.0.1\n\u251c\u2500\u2500 graceful-fs@4.1.2\n\u251c\u2500\u2500 strip-bom@2.0.0 (is-utf8@0.2.1)\n\u251c\u2500\u2500 strip-bom-stream@1.0.0 (first-chunk-stream@1.0.0)\n\u251c\u2500\u2500 through2-filter@2.0.0 (xtend@4.0.1)\n\u251c\u2500\u2500 gulp-sourcemaps@1.6.0 (convert-source-map@1.1.2)\n\u251c\u2500\u2500 vinyl@1.1.0 (clone-stats@0.0.1, clone@1.0.2, replace-ext@0.0.1)\n\u251c\u2500\u2500 merge-stream@1.0.0 (readable-stream@2.0.5)\n\u251c\u2500\u2500 mkdirp@0.5.1 (minimist@0.0.8)\n\u251c\u2500\u2500 through2@2.0.0 (xtend@4.0.1, readable-stream@2.0.5)\n\u251c\u2500\u2500 duplexify@3.4.2 (readable-stream@2.0.5, end-of-stream@1.0.0)\n\u2514\u2500\u2500 glob-stream@5.3.1 (unique-stream@2.2.0, extend@3.0.0, to-absolute-glob@0.1.1, glob-parent@2.0.0, through2@0.6.5, ordered-read-streams@0.3.0, micromatch@2.3.7)\n```\nThen I run socketstream new ss-app2 and I get\nsocketstream new ss-app2\nSuccess! Created app 'ss-app2' with:\n \u2713 Basic chat demo (-m for minimal install)\n \u2713 Javascript example code (-c if you prefer CoffeeScript)\n \u2713 Plain HTML for views (-j if you prefer Jade)\n \u2713 Plain CSS (-s if you prefer Stylus, -l for Less)\nNext, run the following commands:\n   cd ss-app2\n   [sudo] npm install\nTo start your app:\n   node app.js\nSo, I follow the instructions and I cd to the ss-app2 folder, and run npm install. Then I open http://localhost:3000/ and I get the sample app. I find some issues with the app though, but that is a work in progress I suppose.\nSo, I believe the second part of the issue has been addressed by #603, but some devDependencies are still not installed.\nRegards\n. @paulbjensen I got it. See below...\nSo,\nI figured it out. I moved commander to dependencies on my local copy of socketstream, then I re installed that folder as my global socketstream. I tried to create the sample app and all went well.\n~~I was not able to create a pull request,~~ so I copied the diff text from GitHub Desktop below. I added the plus and minus signs since they did not copy with my text.\n@@ -41,12 +41,12 @@\n    \"shortid\": \"2.2.2\",\n    \"uglify-js\": \"2.4.24\",\n    \"utils-merge\": \"1.0.0\",\n-    \"uuid\": \"2.0.1\"\n+    \"uuid\": \"2.0.1\",\n+    \"commander\": \"2.8.1\"\n  },\n  \"devDependencies\": {\n    \"chai\": \"^3.3.0\",\n    \"chokidar\": \"~1.1.0\",\n-    \"commander\": \"2.8.1\",\n    \"connect-livereload\": \"~0.5.2\",\n    \"conventional-changelog\": \"^0.4.3\",\n    \"cookie-parser\": \"^1.4.0\",\nUPDATE:\nI got the pull request going, see [https://github.com/socketstream/socketstream/pull/605].\nThanks.\n. @arxpoetica  I am using version 5.2\nUnless this is an issue with npm. Is npm supposed to run the npm install on every package it installed? However, this is the first time I see this issue happen with any -g package I install. \nRegards.\n. @paulbjensen Can you please reopen this issue as its partially solved? I have installed the develop branch as my global socketstream module. I accomplished this by cloning the develop git branch to my computer and then using that folder to install the module with npm: npm install -g \"/path/to/git/folder/\"\nHowever I still get the same error for installing new socketstream app (original issue # 1) :\nPlease note that I have set a custom path for my npm installation.\n```\nsocketstream new ss-app2\nmodule.js:338\n    throw err;\n    ^\nError: Cannot find module 'commander'\n    at Function.Module._resolveFilename (module.js:336:15)\n    at Function.Module._load (module.js:286:25)\n    at Module.require (module.js:365:17)\n    at require (module.js:384:17)\n    at Object. (C:\\dev\\npm\\node_modules\\socketstream\\bin\\socketstream:4:15)\n    at Module._compile (module.js:434:26)\n    at Object.Module._extensions..js (module.js:452:10)\n    at Module.load (module.js:355:32)\n    at Function.Module._load (module.js:310:12)\n    at Function.Module.runMain (module.js:475:10)\n```\nAfter getting this error, I did the following:\ncd C:\\dev\\npm\\node_modules\\socketstream\nnpm install\nThe output of that command was as follows:\n```\nnpm WARN deprecated lodash@0.9.2: lodash@<2.0.0 is no longer maintained. Upgrade to lodash@^3.0.0\nnpm WARN optional dep failed, continuing fsevents@1.0.6\nnpm WARN deprecated lodash@1.0.2: lodash@<2.0.0 is no longer maintained. Upgrade to lodash@^3.0.0\n\nspawn-sync@1.0.13 postinstall C:\\dev\\npm\\node_modules\\socketstream\\node_modules\\pre-commit\\node_modules\\cross-spawn\\node_modules\\spawn-sync\nnode postinstall\npre-commit@1.1.2 install C:\\dev\\npm\\node_modules\\socketstream\\node_modules\\pre-commit\nnode install.js\n\nnpm WARN engine hawk@0.10.2: wanted: {\"node\":\"0.8.x\"} (current: {\"node\":\"4.1.1\",\"npm\":\"2.14.4\"})\nnpm WARN engine sntp@0.1.4: wanted: {\"node\":\"0.8.x\"} (current: {\"node\":\"4.1.1\",\"npm\":\"2.14.4\"})\nnpm WARN engine boom@0.3.8: wanted: {\"node\":\"0.8.x\"} (current: {\"node\":\"4.1.1\",\"npm\":\"2.14.4\"})\nnpm WARN engine cryptiles@0.1.3: wanted: {\"node\":\"0.8.x\"} (current: {\"node\":\"4.1.1\",\"npm\":\"2.14.4\"})\nnpm WARN engine hoek@0.7.6: wanted: {\"node\":\"0.8.x\"} (current: {\"node\":\"4.1.1\",\"npm\":\"2.14.4\"})\nsinon-chai@2.8.0 node_modules\\sinon-chai\nconnect-livereload@0.5.4 node_modules\\connect-livereload\nnotes@0.0.4 node_modules\\notes\ngently@0.10.0 node_modules\\gently\nlolex@1.4.0 node_modules\\lolex\nsemver@5.0.3 node_modules\\semver\ncommander@2.8.1 node_modules\\commander\n\u2514\u2500\u2500 graceful-readlink@1.0.1\ncookie-parser@1.4.0 node_modules\\cookie-parser\n\u251c\u2500\u2500 cookie-signature@1.0.6\n\u2514\u2500\u2500 cookie@0.2.2\ngrunt-contrib-clean@0.6.0 node_modules\\grunt-contrib-clean\n\u2514\u2500\u2500 rimraf@2.2.8\nshelljs@0.5.3 node_modules\\shelljs\nexpress-session@1.12.1 node_modules\\express-session\n\u251c\u2500\u2500 on-headers@1.0.1\n\u251c\u2500\u2500 cookie-signature@1.0.6\n\u251c\u2500\u2500 depd@1.1.0\n\u251c\u2500\u2500 crc@3.3.0\n\u2514\u2500\u2500 uid-safe@2.0.0 (base64-url@1.2.1)\nshould@7.1.1 node_modules\\should\n\u251c\u2500\u2500 should-type@0.2.0\n\u251c\u2500\u2500 should-equal@0.5.0\n\u2514\u2500\u2500 should-format@0.3.1\nnpm-dview@2.0.0 node_modules\\npm-dview\n\u251c\u2500\u2500 progress@1.1.8\n\u251c\u2500\u2500 supports-color@3.1.2 (has-flag@1.0.0)\n\u2514\u2500\u2500 cli-table@0.3.1 (colors@1.0.3)\ngrunt-conventional-changelog@4.1.0 node_modules\\grunt-conventional-changelog\n\u251c\u2500\u2500 q@1.4.1\n\u251c\u2500\u2500 plur@2.1.2 (irregular-plurals@1.1.0)\n\u251c\u2500\u2500 chalk@1.1.1 (escape-string-regexp@1.0.4, ansi-styles@2.1.0, supports-color@2.0.0, strip-ansi@3.0.0, has-ansi@2.0.0)\n\u2514\u2500\u2500 concat-stream@1.5.1 (inherits@2.0.1, typedarray@0.0.6, readable-stream@2.0.5)\nchai@3.4.1 node_modules\\chai\n\u251c\u2500\u2500 assertion-error@1.0.1\n\u251c\u2500\u2500 type-detect@1.0.0\n\u2514\u2500\u2500 deep-eql@0.1.3 (type-detect@0.1.1)\ngrunt-ngdocs@0.2.9 node_modules\\grunt-ngdocs\n\u251c\u2500\u2500 marked@0.3.5\n\u2514\u2500\u2500 shelljs@0.3.0\ngrunt-contrib-watch@0.6.1 node_modules\\grunt-contrib-watch\n\u251c\u2500\u2500 async@0.2.10\n\u251c\u2500\u2500 lodash@2.4.2\n\u251c\u2500\u2500 tiny-lr-fork@0.0.5 (debug@0.7.4, qs@0.5.6, faye-websocket@0.4.4, noptify@0.0.3)\n\u2514\u2500\u2500 gaze@0.5.2 (globule@0.1.0)\nsupertest@1.1.0 node_modules\\supertest\n\u251c\u2500\u2500 methods@1.1.1\n\u2514\u2500\u2500 superagent@1.3.0 (extend@1.2.1, cookiejar@2.0.1, methods@1.0.1, reduce-component@1.0.1, component-emitter@1.1.2, mime@1.3.4, qs@2.3.3, readable-stream@1.0.27-1, formidable@1.0.14, form-data@0.2.0)\ngrunt-cli@0.1.13 node_modules\\grunt-cli\n\u251c\u2500\u2500 nopt@1.0.10 (abbrev@1.0.7)\n\u251c\u2500\u2500 resolve@0.3.1\n\u2514\u2500\u2500 findup-sync@0.1.3 (lodash@2.4.2, glob@3.2.11)\nsinon@1.17.2 node_modules\\sinon\n\u251c\u2500\u2500 formatio@1.1.1\n\u251c\u2500\u2500 samsam@1.1.2\n\u251c\u2500\u2500 lolex@1.3.2\n\u2514\u2500\u2500 util@0.10.3 (inherits@2.0.1)\npre-commit@1.1.2 node_modules\\pre-commit\n\u251c\u2500\u2500 which@1.1.2 (is-absolute@0.1.7)\n\u2514\u2500\u2500 cross-spawn@2.0.1 (cross-spawn-async@2.1.1, spawn-sync@1.0.13)\ngrunt@0.4.5 node_modules\\grunt\n\u251c\u2500\u2500 dateformat@1.0.2-1.2.3\n\u251c\u2500\u2500 which@1.0.9\n\u251c\u2500\u2500 async@0.1.22\n\u251c\u2500\u2500 getobject@0.1.0\n\u251c\u2500\u2500 colors@0.6.2\n\u251c\u2500\u2500 lodash@0.9.2\n\u251c\u2500\u2500 rimraf@2.2.8\n\u251c\u2500\u2500 hooker@0.2.3\n\u251c\u2500\u2500 grunt-legacy-util@0.2.0\n\u251c\u2500\u2500 exit@0.1.2\n\u251c\u2500\u2500 nopt@1.0.10 (abbrev@1.0.7)\n\u251c\u2500\u2500 coffee-script@1.3.3\n\u251c\u2500\u2500 iconv-lite@0.2.11\n\u251c\u2500\u2500 underscore.string@2.2.1\n\u251c\u2500\u2500 minimatch@0.2.14 (sigmund@1.0.1, lru-cache@2.7.3)\n\u251c\u2500\u2500 glob@3.1.21 (inherits@1.0.2, graceful-fs@1.2.3)\n\u251c\u2500\u2500 grunt-legacy-log@0.1.3 (grunt-legacy-log-utils@0.1.1, lodash@2.4.2, underscore.string@2.3.3)\n\u251c\u2500\u2500 findup-sync@0.1.3 (lodash@2.4.2, glob@3.2.11)\n\u2514\u2500\u2500 js-yaml@2.0.5 (esprima@1.0.4, argparse@0.1.16)\ngrunt-contrib-connect@0.11.2 node_modules\\grunt-contrib-connect\n\u251c\u2500\u2500 opn@1.0.2\n\u251c\u2500\u2500 async@0.9.2\n\u251c\u2500\u2500 serve-static@1.10.0 (escape-html@1.0.2)\n\u251c\u2500\u2500 portscanner@1.0.0 (async@0.1.15)\n\u251c\u2500\u2500 morgan@1.6.1 (basic-auth@1.0.3, on-headers@1.0.1, depd@1.0.1, on-finished@2.3.0)\n\u251c\u2500\u2500 connect@3.4.0 (finalhandler@0.4.0)\n\u2514\u2500\u2500 serve-index@1.7.2 (escape-html@1.0.2, batch@0.5.2, http-errors@1.3.1, mime-types@2.1.8, accepts@1.2.13)\nmocha@2.3.4 node_modules\\mocha\n\u251c\u2500\u2500 escape-string-regexp@1.0.2\n\u251c\u2500\u2500 commander@2.3.0\n\u251c\u2500\u2500 diff@1.4.0\n\u251c\u2500\u2500 growl@1.8.1\n\u251c\u2500\u2500 supports-color@1.2.0\n\u251c\u2500\u2500 mkdirp@0.5.0 (minimist@0.0.8)\n\u251c\u2500\u2500 jade@0.26.3 (commander@0.6.1, mkdirp@0.3.0)\n\u2514\u2500\u2500 glob@3.2.3 (inherits@2.0.1, graceful-fs@2.0.3, minimatch@0.2.14)\ndgeni@0.4.1 node_modules\\dgeni\n\u251c\u2500\u2500 canonical-path@0.0.2\n\u251c\u2500\u2500 di@0.0.1\n\u251c\u2500\u2500 q@0.9.7\n\u251c\u2500\u2500 lodash@2.4.2\n\u251c\u2500\u2500 validate.js@0.2.0\n\u251c\u2500\u2500 dependency-graph@0.1.0 (underscore@1.4.4)\n\u251c\u2500\u2500 optimist@0.6.1 (wordwrap@0.0.3, minimist@0.0.10)\n\u2514\u2500\u2500 winston@0.7.3 (cycle@1.0.3, async@0.2.10, stack-trace@0.0.9, eyes@0.1.8, colors@0.6.2, pkginfo@0.3.1, request@2.16.6)\ncoveralls@2.11.6 node_modules\\coveralls\n\u251c\u2500\u2500 lcov-parse@0.0.6\n\u251c\u2500\u2500 log-driver@1.2.4\n\u251c\u2500\u2500 minimist@1.2.0\n\u251c\u2500\u2500 js-yaml@3.0.1 (esprima@1.0.4, argparse@0.1.16)\n\u2514\u2500\u2500 request@2.67.0 (forever-agent@0.6.1, aws-sign2@0.6.0, tunnel-agent@0.4.2, is-typedarray@1.0.0, oauth-sign@0.8.0, form-data@1.0.0-rc3, caseless@0.11.0, stringstream@0.0.5, isstream@0.1.2, json-stringify-safe@5.0.1, extend@3.0.0, tough-cookie@2.2.1, qs@5.2.0, node-uuid@1.4.7, mime-types@2.1.8, combined-stream@1.0.5, bl@1.0.0, hawk@3.1.2, http-signature@1.1.0, har-validator@2.0.3)\nchokidar@1.1.0 node_modules\\chokidar\n\u251c\u2500\u2500 path-is-absolute@1.0.0\n\u251c\u2500\u2500 anymatch@1.3.0\n\u251c\u2500\u2500 arrify@1.0.1\n\u251c\u2500\u2500 glob-parent@2.0.0\n\u251c\u2500\u2500 async-each@0.1.6\n\u251c\u2500\u2500 is-glob@2.0.1 (is-extglob@1.0.0)\n\u251c\u2500\u2500 is-binary-path@1.0.1 (binary-extensions@1.4.0)\n\u2514\u2500\u2500 readdirp@2.0.0 (graceful-fs@4.1.2, readable-stream@2.0.5, minimatch@2.0.10)\njshint@2.8.0 node_modules\\jshint\n\u251c\u2500\u2500 strip-json-comments@1.0.4\n\u251c\u2500\u2500 exit@0.1.2\n\u251c\u2500\u2500 shelljs@0.3.0\n\u251c\u2500\u2500 lodash@3.7.0\n\u251c\u2500\u2500 console-browserify@1.1.0 (date-now@0.1.4)\n\u251c\u2500\u2500 cli@0.6.6 (glob@3.2.11)\n\u251c\u2500\u2500 htmlparser2@3.8.3 (domelementtype@1.3.0, entities@1.0.0, domhandler@2.3.0, readable-stream@1.1.13, domutils@1.5.1)\n\u2514\u2500\u2500 minimatch@2.0.10 (brace-expansion@1.1.2)\nistanbul@0.3.22 node_modules\\istanbul\n\u251c\u2500\u2500 abbrev@1.0.7\n\u251c\u2500\u2500 wordwrap@1.0.0\n\u251c\u2500\u2500 nopt@3.0.6\n\u251c\u2500\u2500 esprima@2.5.0\n\u251c\u2500\u2500 once@1.3.3 (wrappy@1.0.1)\n\u251c\u2500\u2500 supports-color@3.1.2 (has-flag@1.0.0)\n\u251c\u2500\u2500 mkdirp@0.5.1 (minimist@0.0.8)\n\u251c\u2500\u2500 which@1.2.1 (is-absolute@0.1.7)\n\u251c\u2500\u2500 escodegen@1.7.1 (estraverse@1.9.3, esutils@2.0.2, esprima@1.2.5, optionator@0.5.0, source-map@0.2.0)\n\u251c\u2500\u2500 js-yaml@3.4.6 (inherit@2.2.2, esprima@2.7.1, argparse@1.0.3)\n\u251c\u2500\u2500 handlebars@4.0.5 (source-map@0.4.4, optimist@0.6.1, uglify-js@2.6.1)\n\u2514\u2500\u2500 fileset@0.2.1 (minimatch@2.0.10)\nfs-extra@0.24.0 node_modules\\fs-extra\n\u251c\u2500\u2500 path-is-absolute@1.0.0\n\u251c\u2500\u2500 jsonfile@2.2.3\n\u251c\u2500\u2500 graceful-fs@4.1.2\n\u2514\u2500\u2500 rimraf@2.5.0 (glob@6.0.2)\ngrunt-concurrent@2.0.4 node_modules\\grunt-concurrent\n\u251c\u2500\u2500 indent-string@2.1.0 (repeating@2.0.0)\n\u2514\u2500\u2500 pad-stream@1.2.0 (split2@1.1.0, repeating@2.0.0, through2@2.0.0, pumpify@1.3.3, meow@3.6.0)\nconventional-changelog@0.4.3 node_modules\\conventional-changelog\n\u251c\u2500\u2500 q@1.4.1\n\u251c\u2500\u2500 add-stream@1.0.0\n\u251c\u2500\u2500 git-semver-tags@1.1.0\n\u251c\u2500\u2500 lodash@3.10.1\n\u251c\u2500\u2500 compare-func@1.3.1 (array-ify@1.0.0, dot-prop@2.2.0)\n\u251c\u2500\u2500 tempfile@1.1.1 (os-tmpdir@1.0.1)\n\u251c\u2500\u2500 dateformat@1.0.12 (get-stdin@4.0.1)\n\u251c\u2500\u2500 through2@2.0.0 (xtend@4.0.1, readable-stream@2.0.5)\n\u251c\u2500\u2500 conventional-commits-parser@0.1.2 (trim-off-newlines@1.0.0, is-text-path@1.0.1, split@1.0.0, JSONStream@1.0.7)\n\u251c\u2500\u2500 git-raw-commits@0.1.2 (split2@1.1.0, dargs@4.0.1, lodash.template@3.6.2)\n\u251c\u2500\u2500 conventional-changelog-writer@0.3.2 (conventional-commits-filter@0.1.1, split@1.0.0, handlebars@3.0.3)\n\u251c\u2500\u2500 get-pkg-repo@0.1.0 (hosted-git-info@2.1.4, normalize-package-data@2.3.5)\n\u2514\u2500\u2500 meow@3.6.0 (trim-newlines@1.0.0, object-assign@4.0.1, minimist@1.2.0, camelcase-keys@2.0.0, loud-rejection@1.2.0, normalize-package-data@2.3.5, redent@1.0.0, read-pkg-up@1.0.1)\nvinyl-fs@2.0.0 node_modules\\vinyl-fs\n\u251c\u2500\u2500 is-valid-glob@0.3.0\n\u251c\u2500\u2500 object-assign@4.0.1\n\u251c\u2500\u2500 graceful-fs@4.1.2\n\u251c\u2500\u2500 strip-bom@2.0.0 (is-utf8@0.2.1)\n\u251c\u2500\u2500 strip-bom-stream@1.0.0 (first-chunk-stream@1.0.0)\n\u251c\u2500\u2500 through2-filter@2.0.0 (xtend@4.0.1)\n\u251c\u2500\u2500 gulp-sourcemaps@1.6.0 (convert-source-map@1.1.2)\n\u251c\u2500\u2500 vinyl@1.1.0 (clone-stats@0.0.1, clone@1.0.2, replace-ext@0.0.1)\n\u251c\u2500\u2500 merge-stream@1.0.0 (readable-stream@2.0.5)\n\u251c\u2500\u2500 mkdirp@0.5.1 (minimist@0.0.8)\n\u251c\u2500\u2500 through2@2.0.0 (xtend@4.0.1, readable-stream@2.0.5)\n\u251c\u2500\u2500 duplexify@3.4.2 (readable-stream@2.0.5, end-of-stream@1.0.0)\n\u2514\u2500\u2500 glob-stream@5.3.1 (unique-stream@2.2.0, extend@3.0.0, to-absolute-glob@0.1.1, glob-parent@2.0.0, through2@0.6.5, ordered-read-streams@0.3.0, micromatch@2.3.7)\n```\nThen I run socketstream new ss-app2 and I get\nsocketstream new ss-app2\nSuccess! Created app 'ss-app2' with:\n \u2713 Basic chat demo (-m for minimal install)\n \u2713 Javascript example code (-c if you prefer CoffeeScript)\n \u2713 Plain HTML for views (-j if you prefer Jade)\n \u2713 Plain CSS (-s if you prefer Stylus, -l for Less)\nNext, run the following commands:\n   cd ss-app2\n   [sudo] npm install\nTo start your app:\n   node app.js\nSo, I follow the instructions and I cd to the ss-app2 folder, and run npm install. Then I open http://localhost:3000/ and I get the sample app. I find some issues with the app though, but that is a work in progress I suppose.\nSo, I believe the second part of the issue has been addressed by #603, but some devDependencies are still not installed.\nRegards\n. @paulbjensen I got it. See below...\nSo,\nI figured it out. I moved commander to dependencies on my local copy of socketstream, then I re installed that folder as my global socketstream. I tried to create the sample app and all went well.\n~~I was not able to create a pull request,~~ so I copied the diff text from GitHub Desktop below. I added the plus and minus signs since they did not copy with my text.\n@@ -41,12 +41,12 @@\n    \"shortid\": \"2.2.2\",\n    \"uglify-js\": \"2.4.24\",\n    \"utils-merge\": \"1.0.0\",\n-    \"uuid\": \"2.0.1\"\n+    \"uuid\": \"2.0.1\",\n+    \"commander\": \"2.8.1\"\n  },\n  \"devDependencies\": {\n    \"chai\": \"^3.3.0\",\n    \"chokidar\": \"~1.1.0\",\n-    \"commander\": \"2.8.1\",\n    \"connect-livereload\": \"~0.5.2\",\n    \"conventional-changelog\": \"^0.4.3\",\n    \"cookie-parser\": \"^1.4.0\",\nUPDATE:\nI got the pull request going, see [https://github.com/socketstream/socketstream/pull/605].\nThanks.\n. ",
    "dalily": "i have the same probleme Uncaught Error: Cannot find module 'socketstream-session' within '.'\n. Jute for more information i work on Mac OS X, Tnx a lot  @thepian \n. i have the same probleme Uncaught Error: Cannot find module 'socketstream-session' within '.'\n. Jute for more information i work on Mac OS X, Tnx a lot  @thepian \n. ",
    "msand": "@thepian Will you be publishing the socketstream-session package? And what is the current status with the project?\n. Ok, great :)\n. Probably the 0.5.3 version / develop branch. require('socketstream-session') is mentioned in three places: \nhttps://github.com/socketstream/socketstream/blob/develop/lib/websocket/transports/sockjs/wrapper.js#L21\nhttps://github.com/socketstream/socketstream/blob/develop/lib/client/system/modules/socketstream.js#L17\nhttps://github.com/socketstream/socketstream/blob/develop/lib/websocket/transports/engineio/wrapper.js#L25\nBut the socketstream-session package doesn't exist in npm/github. This seems to work at least:\nnpm install -g socketstream@0.5.2\nsocketstream new testssproj\ncd testssproj\nnpm install\nnpm install sockstream@0.5.2\nnpm install chokidar\nnode app.js\nopen localhost:3000\nSo, the relevant parts are probably isolated to this:\nhttps://github.com/socketstream/socketstream/compare/0.5.2...develop\nand https://github.com/socketstream/socketstream-cookie-session. More specifically, these: https://github.com/socketstream/socketstream/compare/ba6d09f6194aef469c5c9c85486a31b15a6bd840...c6d357d2db6f981625a5efe09cdadd8a0533208d. I might be able to help to some extent, we're still using SocketStream in http://infinitewhiteboard.com/ (hobby/side project), and HTTP2 would definitely be a great addition in general.. Fixed in https://github.com/socketstream/socketstream/commit/1ad3f8dbd4c62fedaf3a59a85dd70725c00a2948. Fixed in https://github.com/socketstream/socketstream/commit/1ad3f8dbd4c62fedaf3a59a85dd70725c00a2948. Have you seen this btw? I've implemented a writable stream for responding to rpc requests. Which enables using a webSocket to Stream responses in SocketStream ;) Would love to hear any feedback!\nhttps://github.com/msand/socketstream/commit/21cf61999baa87410adb89248d3bcfefbfde4107\nhttps://github.com/msand/socketstream/compare/fix-test-crossplatform...msand:fix-transport-bundling. @thepian Will you be publishing the socketstream-session package? And what is the current status with the project?\n. Ok, great :)\n. Probably the 0.5.3 version / develop branch. require('socketstream-session') is mentioned in three places: \nhttps://github.com/socketstream/socketstream/blob/develop/lib/websocket/transports/sockjs/wrapper.js#L21\nhttps://github.com/socketstream/socketstream/blob/develop/lib/client/system/modules/socketstream.js#L17\nhttps://github.com/socketstream/socketstream/blob/develop/lib/websocket/transports/engineio/wrapper.js#L25\nBut the socketstream-session package doesn't exist in npm/github. This seems to work at least:\nnpm install -g socketstream@0.5.2\nsocketstream new testssproj\ncd testssproj\nnpm install\nnpm install sockstream@0.5.2\nnpm install chokidar\nnode app.js\nopen localhost:3000\nSo, the relevant parts are probably isolated to this:\nhttps://github.com/socketstream/socketstream/compare/0.5.2...develop\nand https://github.com/socketstream/socketstream-cookie-session. More specifically, these: https://github.com/socketstream/socketstream/compare/ba6d09f6194aef469c5c9c85486a31b15a6bd840...c6d357d2db6f981625a5efe09cdadd8a0533208d. I might be able to help to some extent, we're still using SocketStream in http://infinitewhiteboard.com/ (hobby/side project), and HTTP2 would definitely be a great addition in general.. Fixed in https://github.com/socketstream/socketstream/commit/1ad3f8dbd4c62fedaf3a59a85dd70725c00a2948. Fixed in https://github.com/socketstream/socketstream/commit/1ad3f8dbd4c62fedaf3a59a85dd70725c00a2948. Have you seen this btw? I've implemented a writable stream for responding to rpc requests. Which enables using a webSocket to Stream responses in SocketStream ;) Would love to hear any feedback!\nhttps://github.com/msand/socketstream/commit/21cf61999baa87410adb89248d3bcfefbfde4107\nhttps://github.com/msand/socketstream/compare/fix-test-crossplatform...msand:fix-transport-bundling. ",
    "yanzixiang": "for so long time,the problem happens same here now.. for so long time,the problem happens same here now.. "
}