{
    "half-ogre": "I noted some small corrections, but looks great. :+1: \n. Sorry, meant to :+1: this last night @Haacked. Looks great.\n. I agree whole-heartedly on letting an acual app drive the design for now. I think at some point we need to \"fill in the gaps\" to make Octopi a generally useful lib, but the longer we defer that, and build the API from actual use, the better. :heart:\n. I feel like we should stick the default unless the performance is really bad. The request overhead shouldn't be that bad, and we're bringing the same amount of data over the wire either way.\n. :shipit:\n. Nice! :shipit:\n. This is ready for review @Haacked.\n. Sweet! :shipit:\n. :shipit: \n. > NOTE TO @half-ogre: This new integration test retrieves a private repository, which I think is important to have. But it's going to fail for everybody but us even if they set the environment variables for running integration test. I think that's probably ok for now. If folks complain, we can add one more environment var. Something like SKIP_GITHUBBER_ONLY_TESTS\nSo, the way I'm going to handle this, when I finally get back to writing code, is have it create the private repo using the configured account. That way it will work for anyone.\n. > I'll fix up the RT tests later\nOkay. I'll dig in and see if I can understand how we're doing with the RT asms.\n. Yep, separate seems better.\n. @Haacked: For now, I like going singular. I had another approach in mind, as well, but I need to think on it a bit more and poke around before I pitch it.\n. :shipit:\n. This is ready for your :eyes: @Haacked.\n. Ah, right, I didn't even think about the need for making changes to the reactive client. Thanks for that!\n. Few thoughts:\n- I've not typically seen the culture included\n- Why not use OSVersion.VersionString instead? It gives you all the goods\n- I feel like the OS info should come first in the parenthetical set; I'd expect something like (Windows NT 6.2; WOW64)\n. > Culture is included in most I've seen.\nHuh. I don't see the culture in Chrome right now. I'm cool with adding it regardless; it certainly doesn't hurt.\n\nReasons. I think I tried that, but it didn't give me the 3rd octet of the version and we wanted to know that for GHfW.\n\nWe care about that for the OS version? I can see caring about that for Octokit.net's version, but not the OS version.\nFor the order, let's go with: Octokit.net/{version} ({os}; {cpu}; {culture}). Cool?\n. @Haacked: Do we want to get Environment.OSVersion.Platform in there somewhere as well?\n. > Why are you half-assing this? The unit tests still have namespaces. \nMan, R# let me down. I'll make a sweep through the unit tests and git rid of them all.\n. Nice! :shipit:\n. :shpiit:\n. :shipit:\n. > Also, what do you think of the exception names? I was contemplating changing AuthorizationException to ApiAuthorizationException to make it more specific to Octokit, but at the same time, I like the cleanliness of the current name.\nI kinda like ApiAuthorizationException better, both for collision reasons and because of the derivation. Then again, that doesn't work for TwoFactorAuthorizationException, so yeah, I vote for just AuthorizationException.\n. I'm going to stop putting \"Moar XML doc\" all over the place, and instead just say, \"Please have XML doc for all the public stuff\".\nThis is really good stuff, and I feel bad for all my nit-picks. Once you've gone through and made all the revisions, I'll make another review pass. :heart:\n. > Ok, rather than create another test project, I just added a Reactive folder to Octokit.Tests. We just have to remember to not add that folder to OctokitRT.Tests. Seem reasonable @half-ogre?\nYup.\n. There's still some missing XML doc, but I can get it when I go through the whole thing. :shipit:\n. Should there be a default Timeout? Is us setting a null Timeout going to stomp on any default?\n. > Yeah, let's set it to 100 seconds which happens to be the default. http://msdn.microsoft.com/en-us/library/system.net.http.httpclient.timeout.aspx\nAlternatively, only set it if it's not null, letting HttpClient just do its thing?\n. > Timespan cannot be null, it's a struct.\nI hear ? is what the cool kids use.\n. > Ewww. I'd rather avoid making something that can't be null allow null values. I'd rather just provide the default. :)\nFair enough. It just means if they change we're no longer the same. Can you somehow get to their default and use that as the seed?\n. :shipit:\n. > @half-ogre: did you want to clean up the secrets? \nWill do.\n\nI think we can ship 0.1.0 publicly without a public CI in place.\n\nAgreed.\n. @paulcbetts I think we can do that.\n. @Haacked: I changed test-octowin, so the secrets are all good. I'm going to get as much done as I can on docs and samples, but I say let's get this shipped and we can continue on with that stuff until we're happy with it.\n. So many :sparkles:, these are great changes that make using the connection happier. Can you add a test for passing a Stream as the data object please? Other than that, I say :shipit:\n. :shipit:\n. Nice work @Haacked. This feels like a better API than putting the list in what's returned, even if I don't have a clear idea how we'd turn that into paging down the road.\n. I think either a completely cold observable, or a sort-of cold observable like @jspahrsummers describes, would work nicely for API calls.\n. I'm all for using cold observables everywhere. I think it's simpler and safer by default.\n. If you're going to do it, now's the time. I'd love to see this change.\n. I'd like to.\n. We have a pretty good idea which API calls will throw a 403 for actual authorization reasons, so in unexpected situations it is most likely going to be for rate limiting. I like a specific rate limiting exception because you probably have some general retry logic or message you show the user when you've been rate limited; you'd never catch that on specific calls. I'm not sure about the value of a forbidden exception; feels like you could just catch ApiException and check the status code.\n. I can't recall any real 403s off-hand, actually. We return 404 in most cases so we don't disclose anything.\n. > I do like the idea of having a RateLimitedException and have the Reason property there as there are multiple possible rate limitations.\nYeah, if we think the reasons matter, that seems reasonable.\n. A quick search for 403 against the API docs doesn't yield anything except for rate limiting. Let's see what @pengwynn says, but I suspect a ForbiddenException won't really be useful to anyone.\n. @Haacked Yeah, this is an area that's nigh impossible to write integration tests for.\nYou're right, RateLimitedException doesn't make sense for login attempts exceeded. I like having the two exceptions; they'd be handled in very different ways.\n. I like RateLimitExceededException and LoginAttemptsExceededException. A little longer on the first, a little shorter on the second, and just enough words to clearly indicate what happened.\n. > @half-ogre so I can actually write an integration attempt for max login attempts, but it'd kind of have to run last. :)\nNot only that, but you really need to have the test pause the runner until it resets, as other CI builds can be kicked off right after. For now, I think we don't have an intregration test for this. I'll noodle it.\n. If we care enough I have an idea how we can test this stuff for real (with a separate account in tests that run on a schedule in CI), but I think the unit tests are good enough for now.\n\nI wish we had an api-error-code in those cases so we don't have to rely on the message.\n\nYeah, not having to do string checks would be nice.\n. Preeety. :shipit:\n. I personally feel like there are too many exceptions here. I don't want to create exceptions unless we expect our consumers will actually catch them, especially when we already have a base exception type that has all the information required to properly handle it. So I think for every exception we create, we need to justify it with expected scenarios. A question I ask myself is, what code would I write to handle that exception differently from ApiException? If the difference is only in what message I show to the user, the status code seems like enough.\nOf the ones we have, I like AuthorizationException because I might try to get the user's credential again and retry. Similarly, the 2FA exceptions make sense to me.\nI'm not sure where I'd use ForbiddenException. I know we use it in some cases, but as an API consumer, I don't know what special action I'd take when it was thrown.\nFor LoginAttemptsExceededException, I don't think I'd do anything except show an error to the user. This one is helpful though because the status code alone doesn't tell the whole story.\nDitto RateLimitExceededException, except I could see automatically retrying in some cases.\nAs for the rest that we haven't implemented yet, none of those jump out to me as having a clear reason to exist. But I honestly haven't given each exception enough consideration to say there aren't compelling scenarios where I'd use them.\n. :metal:\n. The API looks good. I like the direction it's headed, and I think it'll be easy to use. I'm going to build some sort of client with it to give it a test run, to get some actual usage feels.\nAnd I think all of the sub-API stuff you listed belongs on IIssuesClient, like @shiftkey.\n. I like everything here save having separate folders for client impl and interface. I like having the close to each other, and there aren't going to be very many interfaces.\n. Is there a middle ground here, where we require at least an app identifier and build the rest of the user agent to include the stuff we want (OS, CPU, Octokit version)?\n. It feels a bit funny to me to mix our agent info and theirs in a single product token and comment, instead of doing a separate, subordinate product token and comment for our stuff after the one they supply. For instance, here's my browser user agent, with several product tokens and comments in order of significance:\nMozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.101 Safari/537.36\nThat seems more in line with RFC 2616. That said, this is something we can change down the road, so I'm not going to push to change it. The downside to doing it the more \"proper\" way is we'd need to validate the user agent they give us, since it's easy to get wrong if you don't know how to make one.\n. I'm good for you to :shipit:, but I wonder it might be a too-rare case for a typed exception.\n. \n:shipit:\n. \n. :shipit:\n. @forki I'm currently thinking NuDoq, as it'll generate Markdown, but first I have to actually finish documenting all the types in Octokit and Octokit.Reactive. :smile:\n. Yeah, I know that pain @forki. I've started this, and should be finished soon.\n. It's not missing @forki, we just didn't update the README. We need to know about your app to construct a user agent (see #98). I'll fix that sample.\n. @forki Have you referenced System.Net.Http and added using System.Net.Http.Headers;?\n. @forki The code snippet in the README isn't intended to be a full example, and is missing a number of other using statements and such as well. It's just to give you a gist of how to use the library. We'll be adding some true samples soon, per #107.\nAs for the other problem you just hit, we're looking at it. I'll create a separate issue for that.\n. > even if it's not intended as a full example. A link to a getting started would be nice.\nYeah, we'll definitely link to the full samples as soon as we have them up. Thanks for letting us know, and for giving that code a go! :smile:\n. > To get that sample in the readme working you have to install the Microsoft.Bcl.* pkgs as that's the System.Threading.Tasks dll it's looking for. Once I installed those pkgs it worked a treat...\n@shiftkey is fixing things up so that you won't have to do that. We'll have a new version up on NuGet shortly.\n. :+1:\n. Sorry @forki, I should have mentioned when I created this issue that we use an environment variable and an xUnit class to run the integration tests. All the code is done, I just need to set the environment variables up on our current CI server (and maybe revisit this when we move to a new CI server).\nI'm so sorry you did that work because I didn't note this adequately!\n. @forki I used http://teamcity.codebetter.com in the past for ColorCode, but I'd rather find a true CI host. Most of the ones out there don't currently quite do all we need (building all branches is a big one).\n. > I repeat \"or even better: open up your CI ;-)\"\nIt's not something that can be opened up.\n. > I have no idea what the status is of TravisCI and Windows - can someone translate this insane issue thread?\nI don't think it's quite ready for public use. Still waiting on the announcement.\n. > How do you mean \"true CI host\"? TeamCity should be able to support building all branches...\nPoor choice of words; sorry. I meant designed to be CI-as-a-service.\n. > How do you mean \"true CI host\"? TeamCity should be able to support building all branches...\nAlso, I didn't mean to say TeamCity doesn't do this.\n. > Hi @ajepst that sounds like exactly what we need. What do we need to do to try it out?\nI think I still have an account there for ColorCode. I'll see if I can dig it up.\n. @hahmed: We love Travis too, but until they have true Windows support it's just not viable.\n@forki, @ajepst: We currently depend on VS being on the CI server for the RT projects.\n. @forki Can you please open a separate issue about VS 2013? I'm not using it yet, and I'm not sure @Haacked is either.\n. CodeBetter CI can't accommodate Octokit.net for now because we need VS 2012 in the server. Internal CI is working for now, so that's okay, and I'll continue to look at other options.\n. I'm going to keep this open just a bit longer until I switch the hooks over to use QED.\n. I've switched the web hook to point at QED for builds, so I'm closing this.\n. :shipit:\n. > @haacked shouldn't this be under the IGitDatabaseClient?\nYes.\n. I like that plan @Haacked, although I think IGitDatabaseClient might be a better name, given the general ambiguity of Data (and in the API it's generally referred to as the Git DB API; not sure why we chose Git Data for the menu).\n. @shiftkey I'm seeing some test failures on this branch, but not the serialization failures. Also, why the heck isn't CI running for anymore!?\n. After fixing up the Release targets and fixing up CI, I see the serialization errors now.\n. cc @shiftkey \n. :shipit:\n. I think breaking changes like this are just fine right now. That's one reason we're version < 1.0. @Haacked, chime in if you disagree.\n. > @half-ogre worked on the serializer recently. Got any ideas?\nSorry I'm late getting to this,.\n\nLet's go with this. It's the easiest solution and should work immediately. Perhaps call the class GitTag for now.\n\n:+1:. For now, I'd like to avoid turning on data contract serialization if we can.\n. > perhaps not catering for the \"_\" in html_url?\nIf so, it's a regression, as that should work just fine (we handle the underscore in many other places). I'll look into this tomorrow morning.\n. :shipit:\n. Not so far\n. I think I know how to get this all working, but it's going to require taking a different approach, so no more CI noise for a bit.\n. Looks good! :shipit:\n. Thanks @xavierdecoster!\n. @Haacked Why do we have that prompt? Shouldn't we just exit after the build is done?\n. :sparkles: \n. I do not trust this shiftkey-tester fellow.\n. What are folks using to run xUnit tests in Xamarin Studio?\n. Maybe the xUnit.net MSbuild task will work via xbuild for now?\n. All these windows and IDEs are just a fad, anyways.\n. > Is there a test runner API in Xamarin Studio?\nI don't think so. I know the old NUnit runner in MonoDevelop was just a normal add-on that didn't use a specific test runner API.\n. Lookin' good. :heart_eyes: \n. :shipit:\n. :heart_eyes: :two_hearts: :heartbeat: \n. \n. :shipit:\n. @Haacked I think there's a place for @shiftkey's idea of Response<T> regardless of etags, but I also like the idea of a cache provider for requests along the lines of what you describe. I think not caching at all is the best default behavior, but making it easy to \"turn on\" simple caching (like what you describe) or drop in your own cache provider would be pretty sweet.\n. > If it's an interface that's intended for others to implement, I tend to like minimalist interfaces implementations.\n\nHowever, if the interface is solely for our testing purposes, I tend to like having the methods on the interface. It makes mocking it easier. :)\n\nYep, we should always favor library consumers, which most of the time means extensions methods in a case like this. But keep in mind we also want to make TDD easy for our library consumers as well, so if it's an interface we expect consumers to stub, we should consider making it part of the impl.\n(This case doesn't seem like a thing a typical consumer would stub.)\n. \n. Sorry @shiftkey, apparently there was a scheduled Azure VM reboot I missed. I guess it's time to bump the priority on making it a Windows service.\n. I'll up the QED timeout for now.\n. (Thanks for finding that in QED @forki!) :heart_eyes: \n. Timeout fixed, but the build still failed: http://half-ogre-qed.cloudapp.net/octokit/octokit.net/builds/897\n. Nicely done. :shipit:\n. Fill in the blanks?\n. An extra 't' in targeting.\n. Capitalize Contribute\n. I don't know, but I'll create as much as possible through the tests for that, and will avoid it.\n. I'm not sure about the different ways we use a 202 in the API off-hand, but generally speaking 202 (Accepted) isn't always appropriate for retry. It doesn't look like we're actually using this anywhere yet, so let's just make sure we're only throwing this in the context of a 202 that actually means retry, and change this code doc to better explain when it will be thrown (i.e., when a 202 means retry in the context of a given API end-point).\n. Should this be nullable for API exceptions, like timeout, that won't have a status code?\n. @niik: We use 202 in this way always for the GitHub API? Is it safe to treat all 202s this way?\n. 401 is an interesting thing for us. Because we're always going against a known set of end-points, we can probably handle 401 more appropriately ourselves than surfacing it to the client; a 401 means we don't know who you are (either because it's a first challenge, or the API couldn't establish identity after the challenge's response). Not saying we shouldn't have this exception and throw it when it applies, but we should think about maybe having something more specific when it makes sense (like, if you try to do something on /user/xxx, and you didn't supply a credential, maybe a CredentialRequired is the best exception, or if 2FA failed, maybe a TwoFactorRequired exception makes more sense; those are both 401 cases). I'm just thinking aloud here, so maybe just ignore me, but generally speaking, I wonder if we can handle most of the 401s more specifically than just throwing a 401 to the caller.\n. Should we just be throwing an API exception here generally for any 4xx or 5xx status code that we don't special-case? For instance, why handle Forbidden specifically, since we're just throwing ApiException; we could just have a block after the special cases that throws ApiException with the status code and description for any error code > 399. \n. I feel ya. There's also the third case of the client timing out, or will it also end up a task cancellation same as if a user cancelled the task explicitly? I wouldn't want to have to catch TaskCanceledException as a way to know if the client timed out waiting for the server. There also another exception that isn't going to have a status code: the server cannot be reach (bad URL, for example).\n. Yeah, this was copy and paste directly from PocoSerializerStrategy, and I changed as little as possible. But I can totally change that.\nAre we going to try Fody or Code Contracts or something?\n. I assume they put it there for a reason, but I would not have thought it possible.\n. No. I'll look at adding some.\n. Missing XML doc\n. It feels strange naming this AuthorizationUpdate now that it is used for both GetOrCreate and Update. That said, I don't have an idea for a better name. We might to run into this in other places, as well. \nActually, looking at the API, these need to be different. AuthroizationUpdate should have add_scopes and remove_scopes, but a NewAuthorization would not.\n. Man, I need to think about this 2FA handling for a bit. It feels funny for this to be here; I would have expected it to somehow be a separate concern handled somewhere else, though I'll admit I'm not sure how that would work. Do we potentially need to do this other places? What API endpoints will issue a 2FA challenge?\n. > This is the only API endpoint that does the 2FA challenge.\nThat makes me feel a little better.\n\nThis way, the user just needs to provide a callback to show whatever UI they need to show in order to collect the 2FA token.\n\nLet's document how this works in the XML doc.\n. clientId should probably be on the next line\n. MIssing XML doc\n. I feel like we should start putting a link to the GitHub API this wraps in the remarks of all our methods.\n. Typo: defines\n. We should start being consistent about when to period and when not to period. Generally on params, since they tend to be fragments, I don't period.\n. Check what?\n. I think it's worth explaining the 2FA part of this overload, either here or in a remarks section.\n. Missing XML doc for <returns>\n. Missing XML doc for <returns>\n. Think about the nouns in English. It's an \"authorization update\" and a \"new authorization\".\n. Maybe \"Thrown when two-factor authentication is enabled and the specified two-factor code is missing or invalid.\"? I assume if they call this overload and two-factor auth isn't enabled it's just a no-op? I know that would never really happen, of course.\n. You can, but I don't think that typically how you'd say it. I personally don't care about the symmetry here, as all it really buys you is Intellisense cribbing. That said, I don't care enough to fight for this, so if you like those better, go for it.\n. Missing XML doc on <returns>\n. The dangling check again.\n. MIssing XML doc in <returns>\n. The dangling check again.\n. Let's put some XML doc here.\n. Some info here about the 2FA flow, or in <remarks>, probably copy and pasted from all the other places. Have I mentioned how much I hate the lack of reuse in XML doc?\n. Is it worth having a test that goes through the callback twice, simulating the user putting in a bad code? Is that me being weird too-serious tester guy?\n. Typo: defines\n. Remove the period\n. This should have an <exceptions> section, right?\n. Should we just put the client secret in the update object?\n. Moar XML doc\n. extra white space?\n. I kinda feel like ApiConnection should match up to the actual HTTP verbs: Put instead of GetOrCreate, Post instead of Create. Make it clear what's happening at the abstraction layer above. Thoughts?\n. :cool:\n. The HttpClient default is false right? Are we cool making this the default?\n. Okay, definitely cool is that's the case, and maybe cool even if it's not.\n. I like the idea of putting the URI somewhere common.\n. What about an ApiUrls static class that has methods like .User() and .Repository(owner, name) and such?\n. Yes! That's how I've written all the tests I've added. The test creates and removes the state it needs.\n. Is it safe to do this in all cases? I guess we could add a marker if we ever find a place where it shouldn't be handled this way.\n. You intentionally remove the trailing newline?\n. ",
    "Haacked": "Ok, I verified this works now. :)\n. Going to merge this one myself. Feel free to review after the fact. Once we publish this, we should get even more strict.\n. WinRT!? Bleh. ;) Hmm, I think I'll have to add this to our build script too.\n. Shit, you can only build WinRT libs on a Win8 box, so we can't build this in Janky. We may need to log an issue to make our library a portable library.\n. This will probably mean removing the code that builds up the middle ware stack ala rack and OWIN. Doesn't seem appropriate to our client api.\n. How's that look @half-ogre?\n. I'll take silence as acquiescence. Plus, I think it won't be too hard to change it if we decide to try a different approach later.\n. Going to merge this in so I can do the rename. Feel free to review after the fact. :)\n. @half-ogre I think we discussed this. The default is 30 items. An org like GitHub will make a LOT of requests to populate it.\nHowever, I think we're fine with this. It'd be nice if we made this configurable and changed it to 100 for GHfW. What do you think?\n. Fine with me. This actually turns out to be a bit of work due to our current design. If we don't do this, our design should be fine for the time being.\n. I think we decided this change was unnecessary.\n. Oh whoops! Sorry @paulcbetts. I meant the String.IsNullOrWhitespace change. I forgot there were other changes. I'll merge this in later.\n. Should we just make a custom exception type (ApiException) and add the response body as a property of it? Dealing with dictionaries seems lame. The original exception could be an inner exception.\n. Looking good! Write dem tests! Any idea why the build fails?\n. Need to figure out a way to add integration tests. This doesn't implement the full notifications API but it's a good start. @half-ogre can I get that squirrel?\n. Thanks! I'll rebase this against master and push one more time here before merging.\n. :shipit:\n. :shipit: Looks good!\n. Since this is existing code, I'm going to merge this in now. @half-ogre feel free to review later if you have concerns about anything.\n. @half-ogre this is a rote change so I went ahead and merged it. Feel free to take a look after the fact. :)\n. @half-ogre beautiful idea.\n. I'll fix up the RT tests later. :shipit:\n. I'mma just merge this. It's straightforward. Feel free to review after the fact @half-ogre \n. This was done by @half-ogre in e1dbeb4551e4913bea181e2b4d0ffe2470328578\n. Wow! Great stuff @spraints! Only one minor suggestion. Please add the \nIReleasesClient Releases { get; }\nproperty to IGitHubClient interface. You added it to the concrete type only. Otherwise, the change looks perfect! :sparkles:\n. Nah.\n. Yeah, i'll set it up.\n. The other potential problem with 1 is I'm not sure how the API handles accepts. For example, as I understand it, the server will give priority to the Accept list in order. Some endpoints might be able to respond to any accept, but there's one specific type that's more appropriate.\nWe might not have that problem, but I need to ping @pengwynn about whether any endpoints can respond to multiple accept types.\n. > The only headache I have with this approach is that contentType is both a required value and something that could be inside the header collection...\nGood point. Since we require it, I think we'll just overwrite what's in the headers collection.\n. Thanks @pengwynn! So it sounds like we should give end-users a choice, but we could give them a restricted set of choices. Just the ones that make sense for each api endpoint.\n. I'm  going to close this for now till it becomes a problem.\n. Ok, well that's what we have today so I can close this issue. The only downside is that GHfW passes nameWithOwner everywhere. I just wrote an extension method within GHfW to handle that.\n. @pengwynn just so I understand, what do the Octokit.rb methods accept today to get a repo? A single \"name with owner\" string?\n. I wish C# let me do shit like this:\nruby\n@owner, @name = repo.split('/')\n. @half-ogre got an opinion on this?\n. I did this in 9a33c68dbc67c9ff18c652492fbfdcdb8d32817b\n. The only thing left to do is to add the corresponding method to Octokit.Reactive's IObservableRepositoriesClient and implementation.\nOther than that, :shipit: Nice work!\n. Well the good thing is it's stupid simple to port methods over to the reactive client. :smile:\n. Culture is included in most I've seen.\nEx...\n\nMozilla/5.0 (iPad; U; CPU OS 3_2_1 like Mac OS X; en-us) AppleWebKit/531.21.10 (KHTML, like Gecko) Mobile/7B405\nWhy not use OSVersion.VersionString instead? It gives you all the goods\n\nReasons. I think I tried that, but it didn't give me the 3rd octet of the version and we wanted to know that for GHfW.\n\nI feel like the OS info should come first in the parenthetical set; I'd expect something like (Windows NT 6.2; WOW64)\n\nYeah, makes sense.\n. > We care about that for the OS version\nYeah, it's how we know the number of XP users etc. Analytics.\n. Octokit.net/{version} ({os}; {cpu}; {culture}) seems good to me.\n. Another option is to require a supplied user agent and never have a default. What do you think?\nI think it might make it slightly less usable as you'll get an exception if the user agent isn't in the correct format.\n. Here's the code I'll use if we decide to have a default.\nstatic string GetDefaultUserAgent()\n        {\n            return string.Format(CultureInfo.InvariantCulture,\n                \"Octokit/{0} ({1}; {2}; {3})\",\n                SolutionInfo.Version,\n                Environment.OSVersion.Version.ToString(3),\n                Environment.Is64BitOperatingSystem ? \"amd64\" : \"x86\",\n                CultureInfo.CurrentCulture.Name);\n        }\n. Why are you half-assing this? The unit tests still have namespaces. :trollface:\nSeriously though, since we use the test class approach, should we just get rid of all namespaces in the unit tests?\n. Let's merge this and do that as a separate PR. :shipit:\n. :shipit:\n. :shipit:\n. :shipi:\n. Doh! :shipit:\n. :shipit:\n. Hmm, I think it may be time to add a separate unit test project: Octokit.Reactive.Tests.\n. @half-ogre Also, what do you think of the exception names? I was contemplating changing AuthorizationException to ApiAuthorizationException to make it more specific to Octokit, but at the same time, I like the cleanliness of the current name.\n. Ok, rather than create another test project, I just added a Reactive folder to Octokit.Tests. We just have to remember to not add that folder to OctokitRT.Tests. Seem reasonable @half-ogre?\n. Gah! I'll take another pass later myself too.\n. Yeah, let's set it to 100 seconds which happens to be the default. http://msdn.microsoft.com/en-us/library/system.net.http.httpclient.timeout.aspx\n. Timespan cannot be null, it's a struct.\n. Ewww. I'd rather avoid making something that can't be null allow null values. I'd rather just provide the default. :)\n. Alternatively, I could set the default for ours to a negative timespan and in that case I don't set it. :)\n. But really, I'm not all that worried about them changing it. 100 seconds seems fine for Octokit. We should set the default to a value we think is appropriate.\n. I'll wait before merging this one. :stuck_out_tongue: \nhttps://github.com/octokit/octokit.net/pull/72\n. :shipit:\n. :fist: :punch: :shipit: \nI admit, I don't think I understood exactly what you were going to do here. But putting the T on each method totally makes sense! :)\n. ping @jeejkang we're getting close to releasing this. Do you know where the Octokit.net illustration is? Or what we need to do to get it on the website when we're ready?\n. Nevermind @jeejkang, I found it! https://github.com/octokit/octokit.github.com/blob/master/images/gundam-dotnet.svg\n. @half-ogre: did you want to clean up the secrets? I think we can ship 0.1.0 publicly without a public CI in place.\n. So getting this shipped is also dependent on getting GHfW release branch shipped. I'll update the release branch after I shower. Just got back from the game. We won! :soccer: \n. :squirrel: \n. @paulcbetts so we're following the lead from the Octokit.cocoa folks here. I believe this is what they do. @jspahrsummers do you have more to say about it?\nWe didn't want our API to reflect the paging nature of the API unnecessarily.\n. > You're handling values as they arrive, instead of after they've all arrived\nWell this isn't exactly true, right? The first value of each page is being handled as it arrives, but the rest of the values of that page of data already arrived but effectively being buffered.\n. Thanks for the clarification @jspahrsummers! @paulcbetts the four points @jspahrsummers mentioned are reasons @half-ogre and I like this approach. It keeps the API surface very simple and clean.\nHowever, I do value your input as the resident Rx guru. Does this convince you or do you have other specific concerns?\n. Note, it keeps the API simple and clean, but it will make properly implemeting things like Take complicated. But that's a problem we have to solve rather than our users. And even if we returned pages of data, we still have to solve it.\n. @paulcbetts That wouldn't work even if we returned an IObservable<List<Repository>> so I'm unconvinced. In that case, you'd get a single page.\n. Also, wouldn't allTheItems.GetType(); return Repository in this case? When you await IObservable<T> I thought you got the first T as the result.\n. > @Haacked It used to be that you got the first T and now it's the last T\nWell in that case, there's no way they'd be confused and think they got \"all the repos\" right? Hard to confuse a single Repository with a collection of them. :smirk: \nIn fact, if we did return List<T> that might be more confusing. They'd have a list of repos and might thing they got all of them when they only got the last page.\nAt least with returning a T, they can't possibly think they got them all.\nPut another way, if someone really did want this to work:\nvar allTheItems = await getAllRepos(); // Get me all the repos\nThen that person should use Octokit and not Octokit.Reactive. In core Octokit, we aggregate every page of repositories up and return them as the result of the Task. We don't really have another option because Task doesn't have a notion of streaming data. Unless we wanted to return a Task that had a property to get the next page of data and they'd need to await that.\nTherefore, if someone choosess to use Octokit.Reactive, I think we should be free to assume some familiarity with Rx.\nSo given that, are there any other concerns we're not seeing here?\n. > @Haacked Why is that more complicated?\nHeh, it's more complicated because my code didn't work. But I just realized the error of my ways and fixed it. It works fine now!\n. > However, after that point, all subscribers receive the same results and the network request is never duplicated.\n@jspahrsummers thanks for chiming in!\nI can definitely see the benefit of this. This makes sure you don't make too many API requests on accident.\nBut does that mean that Retry can't work unless you also wrap your API call in an Observable.Defer (I hope this translates over to that objective-c funny business)?\n. @jspahrsummers Yeah, it's a tricky trade-off. I have a feeling that a lot of people will make mistakes and over subscribe. Then again, I think the only reason people tend to oversubscribe is that most reactive APIs they use are unclear about the behavior and inconsistent. I feel like if they were all either strictly hot or strictly cold, you'd learn the right patterns and not make that mistake. That would also make operations like Retry meaningful.\n. @half-ogre: any last thoughts here?\n. I think we should do this before we call Octokit.net 1.0. This is the direction we're taking with GHfW and there are many advantages to always being cold.\n. I'm going with ForbiddenException right now with a Reason property to try it out. It's less work and I think will meet my needs.\n. Which API calls use 403 for actual authorization reasons?\n. What I've noticed is the docs here says authorization errors return 401 or 404. http://developer.github.com/v3/auth/\nBut this page doesn't mention 401 and only mentions 403. http://developer.github.com/v3/\n/cc @pengwynn \n. I do like the idea of having a RateLimitedException and have the Reason property there as there are multiple possible rate limitations.\n1. Too many login attempts\n2. Too many authenticated api requests\n3. ???\n. So  far, the only 403 I've run into is this one. :)\n. By the way, I don't think this is technically a \"Rate Limit\" exception.\nHere's the full response.\n```\nHTTP/1.1 403 Forbidden\nServer: GitHub.com\nDate: Fri, 18 Oct 2013 02:06:54 GMT\nContent-Type: application/json; charset=utf-8\nStatus: 403 Forbidden\nX-GitHub-Media-Type: github.v3; format=json\nX-Content-Type-Options: nosniff\nContent-Length: 108\nAccess-Control-Allow-Credentials: true\nAccess-Control-Expose-Headers: ETag, Link, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes\nAccess-Control-Allow-Origin: *\nX-GitHub-Request-Id: 3287DA9B:78F1:18AFD795:526097BE\n{\"message\":\"Maximum number of login attempts exceeded\",\"documentation_url\":\"http://developer.github.com/v3\"}\n```\nAccording to the docs here: http://developer.github.com/v3/#rate-limiting\nIf we were being rate limited, we should see the following headers in the response:\nX-RateLimit-Limit: 60\nX-RateLimit-Remaining: 0\nX-RateLimit-Reset: 1377013266\nBut we're not seeing that. \n. The point is, I think we should probably also have a RateLimitedException that exposes those three properties.\nBut in this case, I'm inclined to make this a MaximumLoginAttemptsExceededException. Unless you have a better name.\n. @pengwynn is rate limiting done by IP address?\n@half-ogre integration tests for these exceptions will kill all our other integration tests. :trollface: \n. @half-ogre ok, that's what I'm doing. Got a name for the other one or is the one I proposed fine?\n. @pengwynn what about the max login attempts? What does that mean? Does it reset?\n. @half-ogre so I can actually write an integration attempt for max login attempts, but it'd kind of have to run last. :)\n. @pengwynn  we can mock the response no problem. The problem is that sometimes, the exception message coming from the .com API changes. So it's nice when we have an integration test that actually hits these exceptions on .com so we know when the message changes.\nWe can't rely on the status code because sometimes multiple different messages have the same status code. I wish we had an api-error-code in those cases so we don't have to rely on the message.\n. @half-ogre looking at the Octokit.rb code, seems like a base Forbidden class might not be a bad idea.\n. > Yeah, not having to do string checks would be nice.\nI see that Octokit.rb uses a regex. That's a tiny step up. :stuck_out_tongue: \n. @pengwynn the docs for rate limiting mention the response you get looks like this:\n{\"message\": \"API rate limit exceeded. See http://developer.github.com/v3/#rate-limiting for details.\"}\nI noticed that other error responses now use a documentation_url field. So should this be:\n{\"message\": \"API rate limit exceeded.\", \"documentation_url\": \"See http://developer.github.com/v3/#rate-limiting for details.\"}\n. @pengwynn let me clarify, is the documentation incorrect or that API is returning an incorrect response? :smile:\n. Fixes #85\n. Deal with it. Gonna merge this.\n. Yeah, I'm kind of leaning towards only implementing them as we need them. For example, I'm about to submit a PR to GHfW that shows how the NotFoundException cleans things up a tiny bit. :smile:\n. If you're commenting on the code, it's best to comment on the specific code within the PR or commit.\n. Looks like this is done, no?\n. So the Issues api has some sub-apis:\n- Assignees\n- Comments\n- Events\n- Labels\n- Milestones\nI'm wondering if these should just be top level api clients or if I should have them be \"nested\" within the IssuesClient.\nWe're starting to have a lot of properties of IGitHubClient, so grouping them as properties of IIssuesClient kind of makes sense. It follows the structure we have here: http://developer.github.com/v3/issues/comments/\nBut at the same time, making them top-level can make them more discoverable. But that's not necessarily a good thing if they're not used as often as our main top-level APIs.\nAnyone have thoughts on this?\n. Thanks @paulcbetts! @half-ogre would love for you to take a look at this later too, but I'll go ahead and merge it for now.\n. I'll clean this up and merge it.\n. :shipit: when it can be cleanly merged. :)\n. Fixed by 4683dbd8d4be218ae4683b6081f95c932cfda638\n. I'm going to merge this as I got implicit approval in issue #94. :smile:\n. @paulcbetts do we block by user agent? Couldn't someone just as easily copy our GHfW user agent? BTW, I'm not convinced we should have a default either, but I'm not yet convinced we shouldn't.\n. Ok, I think I'm convinced. @half-ogre, any thoughts?\nI think what I'll do is provide a better exception than the default when the user agent is wrong. You have to format it correctly and that can be a pain for folks.\n. Ok, I think I'll go this route. I'll have them provide required product information and we'll format the user agent for them.\n. Closing this in favor of #100\n. Thanks shiftkey! Hey @half-ogre and @paulcbetts, would love to have your opinion on the API changes given you raised concerns about having a default user agent. Do you feel this addresses the concerns appropriately?\n. > The downside to doing it the more \"proper\" way is we'd need to validate the user agent they give us, since it's easy to get wrong if you don't know how to make one.\nYeah, that's kind of why I went this route.\nHttpRequestMessage gets away with this by exposing the user agent as a HttpHeaderValueCollection<ProductInfoHeaderValue>. So you can add as many ProductInfoHeaderValues as you want.\nI don't think we want to do that.\nIf this were a general purpose browser or http client, I'd agree with you on this. But the clients are only making requests to Github servers. So I'm not sure what the benefit of letting them add extra comments would be. We'll understand what these user agents mean. :)\n. Yeah, we don't strictly need this anymore. It doesn't hurt and it might be nice to have typed exceptions for all the major status codes.\nCould you comment on #89 and I'll merge/close this based on what we decide there?\n. Fuck it. I know the code is good. :shipit:\n. Heh, ok @shiftkey gave me the thumbs up. No cowboy coding here. :smile:\n. :shipit:\n. Ah, if you use Octokit.Reactive:\nvar github = new GitHubClient(new ProductHeaderValue(\"MyAmazingApp\"));\nvar observableClient = new ObservableGitHubClient(github);\nYou can of course combine that into a single statement. We should probably provide an easier to use ctor for ObservableGitHubClient.\n. @forki If you're interested in contributing, that's some low hanging fruit. :smile:\n. I opened a separate issue for the ObservableGitHubClient constructor.\n. Ack! I think I did this as a force of habit. I'm used to writing code that calls tasks from an application and not used to writing task based libraries. :stuck_out_tongue: \nWould you want to send a PR to fix it up? Is there any real difference under the hood for those watching from home?\n. Seems like low hanging fruit for someone interested. :smile:\n. Thanks! When Steve Toub speaks, I listen!\n. @shiftkey can we close this now?\n. > This not only prevents Mono users from using the tool but also prevents it's usage in open source projects.\nNote that we don't distribute these with our code. They're only used to compile the project. You can look at the NuGet packages to see that.\n. Also, see http://haacked.com/archive/2013/10/30/introducing-octokit-net.aspx\n. @paulcbetts nice!\n. :cake: in my face! I messed that one up, but we fixed it. Thanks @shiftkey!\n. Nope!\n. Ha! Well this is less about choosing a build platform and more about doing the right steps in the first place. Right now, we have to manually update our nuspect files for each release. That's dumb.\n. That looks like I'm reading Greek. But tell me something, what does this do?\nfsharp\n NuGet (fun p -> \n        {p with\n            Authors = authors\n            Project = projectName\n            Description = projectDescription                               \n            OutputPath = nugetDir\n            AccessKey = getBuildParamOrDefault \"nugetkey\" \"\"\n            Publish = hasBuildParam \"nugetkey\" }) \"fake.nuspec\"\nIs that generating the nuspec? If so, I'm sold. As long as this'll work on MyGet. :)\n. That is very elegant. I really need to learn F#. Would you like to submit a PR that ports us to Fake?\n. Though we don't need the automatic publish part. I'll do that from MyGet.\n. Also, for Octokit.Reactive, we should just call nuget.exe against the nuspect. I'll update our build script to do that.\n. So if I happen to install a new package into Octokit.csproj, does the script pick that up and fix up the package without me having to do anything?\n. In other words, does it know to add that as a dependency in the resulting package?\n. Looks good! :shipit:\n. \n. > I repeat \"or even better: open up your CI ;-)\"\nI'm not sure we even can just for this project. That would be kind of ideal. Then again, I'd rather do this on something like Travis CI or AppVeyor.\n. Hi @ajepst that sounds like exactly what we need. What do we need to do to try it out?\n. Just one question. I am not sure how to evaluate this. Also, you might need to fix this so it merges.\n. :shipit:\n. Doing the lord's work! :shipit:\n. Thank you!\n\n. Pro tip. If your commit message incudes the text \"Fixes #XXX\", it will close issue XXX when we merge the commit into the master branch. :smile: This Fixes #115\n. @brlinton great! You can look at the other Observable clients to get an idea on what to do. Let me know if I can help in any way. I recommend doing your work in a branch of your clone. :)\n. \nThanks!\n. No, this client should be exposed as a property of IActivitiesClient.\nI'm thinking the interface for this client should be IReferencesClient\n. Yes! Whoops! Sorry about that.\n. If you follow the patterns of the other clients, they should all be \"easy fixes\" to be honest. :smile:\nThis is definitely a good one to start with. I'm happy to help if you run into problems.\n. Hopefully people will read the comments and see it's being worked on before they waste their time on it. I guess I could assign it to myself since you're not a member of the Octokit organization.\n. Great question! Let me answer the second part first:\n\nI noticed not all observable clients have been added and can't see the reason why?\n\nSome clients are \"sub-clients\". For example, when you navigate to the Issues API you'll notice there's an endpoint for issues. But in the right navbar, there are these other APIs such as Assignees and Milestones.\nWe've tried to mirror this structure. So the IObservableMilestoneClient isn't a direct property of IObservableGitHubClient. Instead, it's a property of the IObservableIssuesClient. And thus you can get to it by going to client.Issues.Milestones.\n\nShould IObservableTagsClient be added to the IObservableGitHubClient?\n\nThis case is slightly different from the Issues scenario because there is no top level DB API. It's just a grouping of apis. However, I still think it might be beneficial to group all these DB related clients as properties of some GitData property.\nSo what I'd suggest is this:\nAdd the interface IGitDataClient. This interface would not have any methods. It would just have properties. Add IObservableTagsClient as a property of this new interface. Add this new interface as a property of IObservableGitClient\n/cc @half-ogre seem legit to you?\n. :thumbsup: to IGitDatabaseClient and have the property be GitDatabase.\n. Ah, good question. No, all of the client classes in Octokit.Reactive should have Observable in the name.\nOctokit\npublic interface IGitDatabaseClient\n{\n    ITagsClient Tag { get; }\n    IBlobsClient Blob { get; }\n    // ...\n}\n```\npublic interface IGitHubClient\n{\n    // ... new property\n    IGitDatabaseClient GitDatabase { get; }\n// ... existing properties\n\n}\n```\nOctokit.Reactive\npublic interface IObservableGitDatabaseClient\n{\n    IObservableTagsClient Tag { get; }\n    IObservableBlobsClient Blob { get; }\n    // ...\n}\n```\npublic interface IGitHubClient\n{\n    // ... new property\n    IObservableGitDatabaseClient GitDatabase { get; }\n// ... existing properties\n}\n```\n. @hahmed Thanks for offering to chip in. Take a look at the other clients, especially the Orgs client to get an idea of how clients are implemented.\nFor example, instead of ICollection we use IReadOnlyList.\nWe also tend to create classes specifically for creating and updating entities. For example, we'd have a NewTeam and a TeamUpdate class for the Create and Update methods.\nAlso, for the enum, use standard .NET naming conventions (aka Pascal casing) for the fields: Admin, Push, Pull.\nOur JSON serializer will fix it up to match what is expected by the API.\n\nThen should I add a property onto the org class called\n\nNo, you'll need to create an ITeamsClient interface and implement it TeamsClient. Then add a property to IOrganizationsClient named Team of type ITeamsClient. make sense?\n. @hahmed go aheand and open a pull request. Just prefix it with WIP to let us know it's in progress. Much easier to discuss this in the pull request.\n\nhttp://blog.myget.org/post/2013/10/14/GitHub-Commit-Status-API-now-supported.aspx\n\nIn pseudocode\ninterface IOrganizationsClient {\n    ITeamsClient Team { get; }\n}\n. > Does that mean you want the Teams Api to be only available to end users via OrgsClient.\nYep. We're trying to map our API to the structure of the GitHub API http://developer.github.com/v3/orgs/\nFor context see: https://github.com/octokit/octokit.net/issues/131#issuecomment-27599500\n. :cool: I found a potential issue with the PR. But most of it looks great!\n. Hmm, hey @pengwynn. Any ideas why these fields are not documented?\nThey sound useful so I'm inclined to add them. But for now, don't worry about it till we hear back.\n. Thanks a lot for submitting this! I had one comment on something that looks incorrect to me.\nAlso, would love to see some unit tests (or at the very least, an integration test).\n. Thanks!\n\n. All the tests pass on my machine. Weird.\n. In fact, all the tests pass on my machine in both DEBUG and RELEASE builds.\n. Ha! I think I see the problem. :smile:\n. OK, I have to run. I can repro this when running build.cmd locally.\n. Whoops! So in general, you should always do your work in a branch. Even when you're working in a fork. It makes these things easier.\nProbably the easiest way to fix this is to create a new branch and cherry pick your two commits into that branch.\ngit checkout -b issue-comments-uri\ngit cp 998fb\ngit cp feb73\nThat way, the branch issue-comments-uri will have just the two commits you made. At that point, you can push this new branch to your fork.\ngit push origin issue-comments-uri\nThen visit your fork on GitHub and there'll be a convenient button there to create a pull request.\n. At this point, your fork's master branch is still messed up. We can fix that up.\nYou should have a remote named upstream that points to the original octokit repository. To very, run:\ngit remote -v\nIf you don't have a remote named upstream, you can run this command:\ngit remote add upstream https://github.com/octokit/octokit.net.git\nAfter that, you should get your master up to date with the upstream master. \ngit checkout master\ngit fetch upstream\ngit reset upstream/master --hard\nThis is one reason why I suggest always doing your work in a branch. Your fork's master should always match upstream master.\nHope that helps!\n. Ok, It's going to take me some time to review this. Thank you very much for submitting it!\nOne thing I wanted to point out right away:\n\nNuget packages are restored\n\nWe decided not to restore packages with Octokit. It's a relatively small library with very few dependencies. We simply commit the packages into the /packages folder. For an application with a lot of NuGet dependencies, I would definitely restore packages. But for Octokit, we're not.\n. So if I understand this correctly, when we're ready to create a new release, we'll just add a release note with the new version and everything gets updated to that version? That's pretty nice!\n. One more thing. We can't remove cibuild.ps1. For now, we should just change it to call into the fake script just like build.cmd does. cibuild.ps1 is a convention for our internal build server. We're planning to move to a public CI server, but we're in the middle of it right now.\n. Man, I'm very excited about this change. This may be the nudge for me to finally learn F#. :smile: I'm trying it out on my local machine right now. :thumbsup: \n. One more thing (I know I'm asking for a lot). Check out this commit https://github.com/octokit/octokit.net/commit/818593bf3f99911134a844832c13d848a6ccb678\nWe have 2 different unit test projects that are in the same directory. I changed them to build to different directories. We'll have to account for that change here.\n. Regarding the open question, I think Environment.NewLine is correct. Unfortunately the release notes feature of NuGet needs some serious work. We had hoped to add support for a subset of Markdown, but I don't think anyone's gotten to it.\n. I don't think anything's left. Let me try this out.\n. Oh, one last thing. Could you bring back cibuild.ps1 and have it run the build?\n. So I got latest and tried to run cibuild.ps1 and I got an error. Does it work for you? It says .\\tools\\FAKE.Core\\tools\\Fake.exe doesn't exist. Should we commit that tool?\n. We probably should add that directory to the .gitignore so that my git working directory isn't dirty after I run the build, right?\n. Ok, i'm testing it locally. BUild seems to work fine. Just 1 test failed during my test run.\n. Also, do you mind merging master into this or rebasing against our master? I can't automatically merge this.\n. Ah, so the failing test is an integration test and it's on my machine. Maximum number of login attempts exceeded No need to worry about that.\nOne thing I noticed in looking at the build output is that the tests run more than once each. I'd expect to see one test run for each of the following:\n- Octokit.Tests.dll\n- Octokit.Tests-NetCore45.dll\n- Octokit.Tests.Integration\nThoughts?\n. How do we make build.fsx parameterized? I think it'd be nice if we could call it with the configuration we want to build. So you pass in Debug or Release\n. Very nice! \nOne last question, hopefully. When I run script/cibuild.ps1 here's all the output I see.\n\nBefore, I remember seeing a bunch of output and that it ran the unit tests. Did you change that? It's fine, I just want to make sure what I'm seeing is correct.\n. You are absolutely correct! I assumed it was something in your build script, but it was ours. Nevermind. :)\n. @forki, Thank you for your persistence with this change! This is great work! I'm probably going to convert a lot of my projects to use this approach. :)\n\n. > I assume it's all captured in $output.\nYep. I remember now. We don't want to fill our build reports with a bunch of useless output, so we capture it and only display it all if it fails.\nHowever, I'd love to display a brief summary on success. I think the way to do that is to add \"markers\" in the FAKE output we produce and then have parse that out in the cibuild.ps1' andWrite-Output` just that portion.\nIt's not urgent, so I won't worry about it now.\n. Hmm, looks like there are 17 commits in here with stuff from other people. Did you make a mistake with rebasing?\n. Ah, in general I prefer to wait for them to land. For example, I found an issue with one of @dahlbyk's changes. Now that issue is in your branch too. :)\n. Whoa! That looks like a braindead bug. Thanks for the fix!\n. Is this ready for review? The description says \"Placeholder for work...\". Not sure what you mean by that.\nIf this is work in progress, we tend to like prefixing the title with \"WIP:\".\n. Are you running Windows 8?\n. Can you paste in the exact error you're getting? Everything builds fine for me. Have you installed the Windows 8 SDK?\n. http://msdn.microsoft.com/en-us/windows/hardware/hh852363.aspx\n. Nice work! The one thing that's missing is there's no way to reach this client. Probably need to add a property to IIssuesClient.\nIIssueCommentsClient Comment { get; }\nAnd the implementation.\nAfter that, I'm happy to merge this. Are you up for implementing the Observable version of this in Octokit.Reactive?\n. >  I have pulled the latest master branch from upstream and it has the latest commits\nI assume you pulled those into your fork's local master, right?\n\nAm I going to screw anything up in the pull request if I rebase the branch to the latest master?\n\nThat should be fine. But when in doubt, create a \"save point\".\ngit co issue-comments-uri\ngit branch issue-comments-uri-bak\nThat'll create a branch that's a copy of your current branch.\nThen rebase against the latest master and force push to your fork's branch and you should be a-ok.\n. Thanks!\n\n. Thanks!\n. Allow my merging of this PR to stand in as my yes. :thumbsup: \n. I mean, \"yes\", I do not disagree.\n. Thanks! :+1: \n. Check out the class JsonHttpPipelineTests.TheDeserializeResponseMethod.\nYou should add a test there. Perhaps something like (but please fix this):\n```\n            [Fact]\n            public void DeserializesResponseWithObjectHavingDataMemberMapping()\n            {\n                const string data = @\"{\"\"tag\"\":\"\"tag-name\"\", ...OTHER PROPERTIES...}\";\n                var response = new ApiResponse\n                {\n                    Body = SimpleJson.SerializeObject(data),\n                    ContentType = \"application/json\"\n                };\n                var jsonPipeline = new JsonHttpPipeline();\n            jsonPipeline.DeserializeResponse(response);\n\n            Assert.NotNull(response.BodyAsObject);\n            Assert.Equal(\"tag-name\", response.BodyAsObject.Name);\n        }\n\n```\n. @half-ogre worked on the serializer recently. Got any ideas?\n. > Rename the Tag class to something other than tag and rename the Name property to Tag so that automatic property binding works\nLet's go with this. It's the easiest solution and should work immediately. Perhaps call the class GitTag for now.\n. Which test is failing? Also, this branch can't be merged. You'll need to update it with the latest from upstream master. Do you know how to do that?\n. The 2 private repos test failures are fine since your account doesn't allow it. The MissingMethodException sounds like a problem we fixed recently. So hopefully an update fixes all that. :)\n. Thanks! This is good work!\n\nI went ahead and merged this. Could you clean up the this. stuff up in a separate PR?\nAs for integration tests, if you have time later, they'd be appreciated. But this is fine going in now.\n. Nice work so far. I ran out of time to review this, so I'll get back to it later. Do you know how to rebase this against the upstream master? If not, don't worry about it for now.\n. Nice! Thanks!\n\n. We should set code analysis to run by default on every build.\n. CodeAnalysis is a built in part of VS2012 now. So I was just going to set it on the project.\n. No, it would be. Code Analysis is actually part of MsBuild.\nmsbuild MySolution.sln /p:RunCodeAnalysis=true\nWe can just set it in the project file though. Should we do this only for the Release builds? I'm not sure. It might be nice to do it for all builds. But I'd wait till nothing breaks first. :)\n. > Have you managed to get this running on your CI box?\nYeah, it works fine. We use it for GHfW.\nFor Octokit, we need VS on the CI box anyways because we build a Win8 library. :(\n. I added code analysis to our Release build so it runs on CI successfully. See https://github.com/octokit/octokit.net/pull/166 for details.\n\nSet ComVisible(false) on the generated SolutionInfo.cs file to resolve some warnings.\n\nI personally think this is wrong. This takes the choice away from the developer. If you want to set ComVisible(false), I think you should probably do it on AssemblyInfo per project. Or better yet, Fake should generate SolutionInfo as a Partial class so we can add assembly attributes into our own non-generated partial SolutionInfo.\n. > I personally think this is wrong.\nOk, never mind. I just realized this is configurable in the build. Doh!\n. > Wow, I didn't know Win8 lib builds need VS. MS are often too IDE focused\nIt makes me :rage: with the heat of a 1000 :sunny: \n. Thanks @shiftkey and everyone involved!\n. Nice work. I made some nitpicky commenst, but they can be addressed in a separate PR. Imma gonna merge this. :)\n\n. How's this coming? Need any help?\n. Delete the .\\tools\\FAKE.Core folder and then run the build.\n. Good work! Please address the comments I made. Also, please update your fork from upstream master (if you don't know how, I'll help you) and then run the following command:\n.\\build FixProjects\nThat will make sure the new files you added are also added to the MonoAndroind and Monotouch projects (they're not in the solution).\nThanks!\n. And you tested the crap out of this, right? :smile:\nThis is great work! Thanks!\n\n. :shipit: but do heed my note about SimpleJson please. :+1: \n. Flawless victory!\n. Delete the tools/FAKE.Core folder and run build.cmd again. It'll reinstall itself with the latest version.\n. @ninjanye I recently fixed up a bunch of CA errors. Did you update your fork from master recently?\n. If you don't mind, please address those fxcop errors. That's really weird. :smile:\n. Great stuff! Just a few comments and we need to nail down that class name. I like Identity for now.\nOne more thing, if you don't mind. We need to add the files that you added to Octokit-mono.csproj to the other two Mono projects. But they need to be edited by hand.\n- Octokit-MonoAndroid.csproj\n- Octokit-Monotouch.csproj\nI'll merge this whether you do this or not (assuming you fix everything else) but I'd be ever so grateful. :smile:\n. Send a new PR for that fix please. \n. \nThanks!\n. Actually, never mind. I cherry picked that commit from you. Would you mind submitting that as a PR to https://github.com/simplejson/simplejson\nIf we end up upgrading our SimpleJson, I don't want our code to break again. :)\n. Yep! That's the one. My mistake!\n. @SimonCropp Can you try it out?\n. Great question! For context, check out my response to a similar question: https://github.com/octokit/octokit.net/issues/131#issuecomment-27599500\nIn this case, I think we want an Activity property of IGitHubClient. Make it an IActivityClient that only has properties. Add the client you wrote as a property named Event. For consistency, you might need to rename the client you wrote to IActivityEventsClient and IObservableActivityEventsClient. Or should it be *ActivitiesEventsClient Naming is hard.\n. Yeah, I don't think we use events anywhere else in Octokit so IEventsClient would be fine.\n. So to summarise:\n```\ninterface IGitHubClient {\n    IActivitiesClient Activity { get; }\n}\ninterface IActivitiesClient {\n    IEventsClient Event { get; }\n}\n```\nLet's try that out for size.\n. IEventsClient\n. > So we are going to add one more layer to map to what the GitHub docs have?\nYep. That's been our approach. If we don't like it, we can change it later. But I think it helps for now because we don't have much in the way of Octokit docs, but we have a rich set of API docs. This allows us to just tell folks our object model maps the API.\n. It needs me to review it. :stuck_out_tongue:  I'm going to review it now. However there's one thing I already noticed.\nWe have other projects that we need to include the new files in. For example, right click on Octokit.Tests-NetCore45, click the \"Show all files\" button, and include the new test you wrote in the project.\nDo the same for the new files that you added to Octokit.cspoj for the following projects:\n- Octokit-NetCore45.csproj\n- Octokit-Mono.csproj\nAnd if you're feeling really generous, do it for:\n- Octokit-MonoAndroid.csproj\n- Octokit-Monotouch.csproj\nThese last two require hand editing. If you can't get to it, I'll do it. :smile:\n. Great work! Not a lot of comments. Only one more essential thing.\nIn the same way that you added an Activity property to IGitHubClient, we need to do the same for IObservableGitHubClient\nSo it'll follow the same exact pattern.\n- IObservableActivitiesClient <- With a property named Event of type IObservableEventsClient\n- ObservableActivitiesClient\n- IObservableGitHubClient.Activity property\n. \nThanks!\n. > When the code gets around to getting the nextPageUri, the old parameters are still there and overwrite the good parameters that are in the nextPageUri given by GH's api.\nThis would be very bad if that's the case. Perhaps we need an integration test that creates a bunch of milestones and then runs through this.\n@shiftkey did you test for this by any chance? Is this a concern?\n. What do you need that for?\n. Thanks! Good catches.\n\n. Thank you so much for this. This is great work. I had a few nitpicky comments.\nI appreciate that you remembered to add the project files to the NetCor45 project. Most people (myself included) forget. Could you also add them to:\n- Octokit-Monotouch.csproj\n- Octokit-MonoAndroid.csproj\nUnfortunately, I could not add these to the Solution so they're easy to miss.\n. I think those project types only work in Xamarin Studio. Is that right @paulcbetts. So for now, manually editing them is our only recourse. Or installing Xamarin Studio and opening them in there.\n. How's this coming along? Need any help? Looks like it's out of date with upstream master. Do you know how to update it?\n. Great! Carry on! :cake: \n. A few more comments. Almost there! Please merge upstream master into your branch (or rebase it if you're into that sort of thing).\nAfterwards, delete the \"tools\\FAKE.Core\" and then run build.cmd again. Our new build script will add any missing .cs files to the mono projects for you so you don't have to worry about it anymore. :smile:\n. Looking good! I had a few comments. If you'd like, let's iterate on this and get it in and perhaps you could do the Observable client as a separate PR. Would that be cool?\n. Ah, so this PR doesn't include a way to navigate to this client. I think we just need to add a property to IOrganizationsClient for this. I'll do it.\n\n. I'll do it. :)\n. Did it work?\n. I'm going to accept a couple more PRs today and then update this branch. :)\n. Is this ready for review or a work in progress? Also, you may want to rebase this against upstream master or merge master into your fork. Either way is fine.\n. > How do I do a git rebase onto upstream master?\nHeh, this is #DangerZone so be sure to \"back up\" your current work by creating a new branch.\ngit co org-teams\ngit branch org-teams-bak\nYou should have a remote named upstream that points to the original octokit repository. To very, run:\ngit remote -v\nIf you don't have a remote named upstream, you can run this command:\ngit remote add upstream https://github.com/octokit/octokit.net.git\nNow we're ready to go. All we need to do is fetch the upstream master now and rebase against it.\ngit fetch upstream\ngit rebase upstream/master\nAfter that, you can force push to your branch.\ngit push origin org-teams --force\nKeep in mind, force pushing is a bad idea for shared branches. Only do this for a branch that you're the only one committing to. :smile:\n. Yeah, that doesn't look right. So this is why we created that backup branch.\nWe can simply get back to your original state like so:\ngit co org-teams-bak\ngit branch -D org-teams\ngit co -b org-teams\ngit push origin org-teams --force\nThen try this. Let's get your local master up to date with upstream master.\ngit co master\ngit fetch upstream\ngit reset upstream/master --hard\ngit push origin master\nThis should get your fork's master up to date with what's on octokit/octokit.net.\nThen, you can simply do this:\ngit co org-teams\ngit merge master\nThat'll merge master into your branch. You'll need to deal with any conflicts along the way.\nThen\ngit push origin org-teams\n. Ok, it looks like you need to update your fork with upstream master again. I fixed a few bugs in the build. Hopefully that'll get you going on the right path.\n. Ok, I'm not sure you've merged the latest into your fork. That output you showed shouldn't happen.\ngit co master\nfit fetch upstream\ngit reset upstream/master --hard\ngit co org-teams\ngit merge master\n^^^ Try that and run the script again.\n. > The code for octokit.Reactive is not there - I am assuming you want that to be a new PR, so I will wait for feedback on this PR and if it gets merged I can have a crack at that.\nSounds good! I had a couple comments.\n. I'll look into the build failure. Did you see my comment here? https://github.com/octokit/octokit.net/pull/181#discussion_r7491448\n. Delete your local .\\tools\\FAKE.Core folder and then run the build. I think I'll make build.cmd automatically update it if it exists.\n. \nThanks a lot!\n. :sparkles: :cool: :sparkles:\n. Thanks! :thumbsup: \n. Heh, thanks!\n. @half-ogre I think the FAKE guy put that in there when he was helping to port our build to FAKE. Not sure why. I should have caught that.\nGood news is, we should be able to build our packages on MyGet now. :)\n. > b) edit the SimpleJsonSerializer to scrub '-' from enum values coming in\nThat actually seems safe to me. A C# property can never have a - so we'd be ok here.\n. Did you delete it locally or on the server? I was able to grab the branch and push what you had to a hahmed/search-api branch on octokit.net. So if you need to fork it again, do so and then work in that branch.\n. :shipit:\n. Great work! \nYou forgot to add the property to IObservableOrganizationMembersClient. I'll merge this and do it myself. It's simple enough and I have no idea what timezone you're in. :)\n. \n. No problem! Isn't it like 6 AM there?!\n. Thanks! Unfortunately we haven't set up our CI to build external PR branches just yet, so I'm going to merge this into my own branch and push it up so I can fix the build before we merge this. :)\n. > With the latest Fake build do I still need to add the files to the other projects?\nNot manually. Just run .\\script\\build.cmd in the root of the repository to fix it up.\n. Yep! So some folks pointed me to https://code.google.com/p/gyp/\nUnfortunately that requires Ruby. I'm thinking that something F# based as part of the build might be cool. But my key requirement is that contributors should be able to use Visual Studio to add files to the \"source\" project Octokit.csproj in this case, and all the other project files could be generated or fixed up.\n. > Wouldn't copying the comments to implementations just lead to having to maintain the documentation in two (or more) places?\nYes, it does. It'd be nice if we had an automated way to do this.\n\nIf I'm not mistaken Visual Studio currently uses Interface documentation comments if there's not an explicit documentation comment on the implementation, in essence achieving the desired result already.\nNot certain that this is the case in Xamarin but it would seem likely.\n\nI don't believe that's the case. I think plugins like Resharper do this, but a vanilla Visual Studio will use the comments on the specific reference you have. So if you have a reference to IFoo it'll use comments on IFoo. But if you have a reference to the concrete Foo, it'll use comments from Foo whether or not Foo implements IFoo.\nIf this has changed, I'd be happy to know!\n. > In addition to the client API's is there a desire/need to document other public interfaces?\nWe'd like to eventually doc everything. So any docs you contribute is much appreciated.\n\nAlso might give the automation some thought if I find the time for it. Seems as if it shouldn't be terribly difficult at first glance.\n\n:heart: :heart: :heart:\n. > It seems to me that a system where we leave implementations uncommented and only generate comments during build, comments that never make it back into the source, might be the way to go here.\nYeah, I think that could be a good interim solution. We could ignore any comments on the actual implementation.\nIdeally, we'd get these comments back into the source and simply always overwrite implementation comments with the interface comments.\nRoslyn sounds like a good bet to me!\n. >  I was just concerned that there might be cases where an implementation should have different documentation than the interface/base type, in which case copying the comments into the source instantly becomes a lot less pretty.\nI'm not too worried about that. We can tackle that issue when we run into it. :smile:\n\nAlso confirmed that I could complete the whole process from finding the missing doc comments, copying them and outputting the new source. So now it's just a matter of putting it all into a nice little package, which will probably take longer :)\n\n\nExciting!\n. Amazing. /cc @half-ogre \n. /cc @shiftkey \n. So the FAKE folks might do this\n\nnow that we are abe to detect missing files we might add a \"fix it\" task.\nstay tuned.\n. You guys are amazing! You get a chuck norris!\n\n\n. Oooh, duplicate detection would be amazing. That often happens due to git merges. @forki maybe consider adding that? :smile: \n. > I saw a dull task, and thought I'd see how easy it was to contribute\nHa! Thanks a lot!\n\n. Good catch! :thumbsup: \n. Yeah, but on the website it's displayed as 48x48 on the package search results page and 128x128 on the package details page. I'll create a 128x128 and see if that scales down better. Otherwise we can meet somewhere in the middle.\n. \n\n. > Not sure how to merge all of these into the pr #189  done something wrong here.\nThis is fine. I closed that one. I'll review this one instead.\n\nBy the way - I have 3 failing tests.\nSearch Repo\nSearch Code\nSearch Issues\n\nBesides these failing tests, is this PR done and ready for review? Maybe I can look into those tests.\n. > By the way - something is not right here... You cannot see all the files I have made changes to?\n\nI think it may be because I am merging my changes into the branch hahmed/search-api - which contains all the previous changes I have already done?\n\nYep. This should have been created against octokit\\master. No worries. It's a holiday here and I'm travelling soon so it may be a bit of a delay before I get to it. @shiftkey you around to review?\n. Yeah, https://www.myget.org/feed/octokit/package/Octokit\nI'll push a new NuGet release on the main gallery soon too.\n. Hmm, when you create a repository, just set AutoInit to true. That'll create a non-empty repository.\n. Or am I missing something?\n. yay!\n. \n^^^ This is what @forki did to our old crappy build.\n. Thanks! We really needed this!\n. We won't see the effects until we publish a new package.\n. Actually, NuGet added the ability to edit package metadata online. I'll try it. :)\n. I'm going to bet we don't handle that at all, but I haven't tried it. We might need to customize this case. Either \"files\" is a dynamic object OR files deserializes into a dictionary. The dictionary approach is my preference.\n. If \"files\" is a Dictionary<File> I wonder if this just works.\n. I guess it depends on whether it's useful to look up files by name. If not, then an IReadOnlyList<File> makes sense.\n. Not likely so i agree with the list. :)\n. @SimonCropp look over here https://github.com/octokit/octokit.net/blob/master/Octokit/Http/SimpleJsonSerializer.cs\n. 1. Yes\n2. Yes.\n3. Not sure.\nOn Wed, Nov 13, 2013 at 5:48 PM, Simon Cropp notifications@github.comwrote:\n\nok so i noticed you guys already support dictionary. so i am being lazy\nand leaving it as that for now :)\nbefore i do a PR i have a couple of questions.\n1. Do u want a PR to master?\n2. Should I be reusing the common User for Gist.User and GistFork.User?\n3. In my test Gist.User returns null. Is this because i am doing point\n   2 wrong?\nSimonCropp@0b0661ahttps://github.com/SimonCropp/octokit.net/commit/0b0661aa1e74aa84bed2c21d3a2abf1d0b3c7713\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/issues/215#issuecomment-28453023\n.\n. Ah, let's make sure we're requesting the v3 media type then.\n. > This was not added to the list of things to do\n\nYeah, I got lazy. If you see any other missing things, please do create an issue. :smile:\n\nIf you do want this feature please let me know so I will open a PR.\n\nYes please! :sparkles: \n. Looks good so far! Bring on the :beers:. I'm thirsty for more.\n. Looks good! \n\n. maybe we can bribe @bradwilson.\n. Or log a bug here: http://xunit.codeplex.com/workitem/list/basic :(\n. Build.cmd is prompting. I thought we removed that prompt. It shouldn't have any sort of user interaction like that.\n. Fine with me\n. I've been pretty busy lately. I'll try to review this over the weekend or on Monday.\n. @hahmed wow! There's a huge amount of work to implement this API. Great stuff! Hope you don't mind my nitpicky comments.\nThere's a lot of places where you try to not send a parameter when it's not specified. I think that's probably not necessary. Might as well just make sure our request objects have the default value set and be fine passing them all. That way you can use the ToParametersDictionary method and get rid of a lot of code.\n. @hahmed looks like you'll need to update this branch from upstream master.\n. Thanks for the PR. A few minor changes suggested but this is coming along well and is much appreciated! You probably need to merge upstream master into this now (or rebase it if you're into that sort of thing). :smile:\n. Great work! I had a couple more minor style comments. Also, be sure to merge upstream master into your branch (or rebase it if you're so inclined).\n. > What do you think of creating two extra environment variables:\nMaybe we can punt on these specific integration tests for now.\n. I'll let @shiftkey chime in here as he's been closer to this than I have. :)\n. @shiftkey got any time to look at this again?\n. Nice catch! :+1: \n. @warrenbuckley No problem! THanks for getting involved. Also, try to avoid adding the GlobalSuppression.cs file. It added it as a binary file which probably means it encoded it as UTF-16. We shouldn't need to add that file at all hopefully.\n. > as you can tell I am fairly new to all of this. So I appreciate your patience & great feedback.\n\nFingers crossed third time is a charm\n\nNo worries! Glad to have you helping out! This is a great project to start learning to contribute to OSS. I'm happy to help.\n. @warrenbuckley Great! I'm just waiting to hear about the rationale for the Contents API before I start thinking about how to handle it. :)\n. @shiftkey what are the typical use cases for this method. Will the caller know in advance? Perhaps we need a ContentResponse class with a Type enum and methods ValueAsFile and ValueAsDirectory where one is null if the other is populated. I'm not sure people need to know in advance. \n. @shiftkey I look forward to the results of your experiment.\n\n. Whoa, what happened there? Looks like a bad merge.\n. @Therzok care to help @rgmills with the commands needed to fix this up? Or perhaps do it and submit a new PR with his branch?\n. @Therzok Why don't you do that and push to a branch under your account.\nbash\ngit reset --hard d2e0490\ngit rebase upstream/master\ngit checkout -b my-branch\ngit push origin my-branch\nThen you issue a PR and we'll close this one.\n. But choose a better name than \"my-branch\" :stuck_out_tongue: \n. :thumbsup: \n. Since this affects tests and I trust you, :shipit: when you're done. :)\n. I'd love to see the number of tests run in the success output. I've had situations where I had too many skipped tests and noticed it only because the output had an absurdly low number.\n. This is fantastic! We should probably create an issue per client. That way we can start pushing for new contributors to jump in. :)\n. Do it.\n. Thanks!\n\n. @khellang Can you remind me why we needed the BodyWrapper class?\n. Ah, right. Maybe BodyResponse is a better name, but no need to change it for now.\n. Or RequestBody!\n. This is a great start! Thank you so much for this.\n. :thumbsup: \n. Very cool! I'll try it out on Monday.\n. \nThis is really great! Thanks!\n. Is this being driven by a real application need or a theoretical need?\nI'm a :thumbsdown: on it as far as ObservableRepositoriesClient is concerned. You should simply do:\nclient.GetReposOrWhateverItIsCalled().Take(100); // This will request enough \"pages\" to get the 100\nAs much as possible, we've tried to drive implementation based on actual application needs. We also want to make the API fit the idioms of the language. So the Observable API should match the Rx + Linq idioms and the user shouldn't have to think about paging. Paging should be handled transparently as an implementation detail of the API.\nFor the Task based APIs, that might be much more difficult and we might need to resort to parameter passing. But it's a lower level API anyways.\nJust to be clear, I'm not totally opposed to it, we've just been successful with extracting the implementation patterns based on what we needed in GHfW and I want to continue with that focus. Having a real application need really helps clarify our thinking about how it should be implemented.\n/cc @half-ogre \n. p.s.\nFor the observable clients, Skip will still issue all the requests. That might be a case where sending the page parameter is more efficient.\nWe've been using a HATEOAS approach so far which makes it very flexible for clients. The response has the next page. I wonder if we could continue this approach by issuing HEAD requests for Skip.\n. > But I still need all the results, I just want them delivered as they come in...\nThat's how it works today.\nclient.GetAll().Subscribe(repo => /* Get them as they arrive. Does not wait for them all to be made. */);\nThe Get* methods return an IObservable<Repository>. https://github.com/octokit/octokit.net/blob/master/Octokit.Reactive/Clients/IObservableRepositoriesClient.cs#L63\n. Make sure you're using the ObservableGitHubClient.\n. Thanks! \n. Hey @tpeczek, this broke a couple of tests that need to be updated to take into account the change to use BodyWrapper. Want to take a crack at it? /cc @shiftkey\n. @shiftkey done!\n.  Nice job!\n. Did #262 not fix the issue?\n. DOH!\n. Thanks! I guess first come, first serve. :)\n. Thanks though!\n. :shipit:\n. \nUgh, nothing is ever easy. I think we should continue down this path. It'll eventually get fixed. Maybe we can keep an old .sln/.csproj file around for a bit if we get complaints.\n. Now that Releases is released, I assume we can use application/vnd.github.v3 now.\n. /cc @technoweenie does that ^^^ sound right to you?\n. Thanks!\n. \n. It's a good start!\n. I like the first option. With the observable API, we could have calling Dispose on the subscription cancel subsequent requests.\n. How cool will it be when Octokit uses Octokit to deploy and release Octokit. :)\n. @pmacn Just document the interfaces and then run the .\\script\\build script and it'll apply the comments to the concrete class.\n. \n. And thanks again for that contribution. I'll try hard to remember to associate @pmacn with that. :) In fact, that's one of the things i'm excited to demonstrate on Monday!\n. Probably need to merge master into this again.\n. Looking pretty good to me. Just need you to light up that green button so I can merge it. :smile:\n. \n. Whoa. Looks like that's missing a Received call.\ncsharp\ngitHubClient.Connection.Received(1).GetAsync<IReadOnlyList<User>>(\n        new Uri(\"orgs/org/members\", UriKind.Relative), null, null);\n. In fact, all these tests are suspect. :(\n. I'll fix it.\n. No worries. I sent a PR with a fix. :)\nOn Sun, Jan 12, 2014 at 1:54 PM, Henrik Andersson\nnotifications@github.comwrote:\n\nThat'd be my fault, sorry! [image: :disappointed:]\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/issues/300#issuecomment-32135352\n.\n. > To actually work wouldn't they have to await the call to GetAll to make sure that it has time to run.\n\nNot for our unit tests. For our integration tests, that would be true. Our unit tests simply check that we call through to the connection correctly. We don't mock up the entire request chain.\n. Ah! Cool. So we can close this issue then?\n. It's all good.\n\n. Yeah, I think we should make this easier to inject. That's pretty ugly, but at least it's possible now. :)\n. Could we start with just making it easier to inject the IWebProxy\n. :shipit: \n. I was actually thinking of maybe making it easy to set the IWebProxy on the top IGitHubClient object. But that's based on an assumption that no matter what you used to implement IHttpClient it would support IWebProxy.\n. But I'm :thumbsup: for this for now. :)\n. Pondering? That's too much credit for what I'm doing.\n:shipit:\n:ship: it\n. Keeping us busy!\n\n. Oh man, I need this for organization members.\n. Hmm, this failed the build. Try running .\\build.cmd and see if it adds the Mono files to the right projects. Then commit those changes to your branch.\n. This was picked up by @johnduhart in #495. \n. Go ahead and fix in your branch.\n. Yeah, with reflection and linq, these types of tests are really easy to write. Sometimes you run into weird tricky cases, but a few choice extension methods can help clean those up.\n. DebuggerDisplay all the things!\n. I think RepositoryTag is fine since this is the only place that I could find where this structure is used. If there were more than one place, then a more generic name would be appropriate.\n. We have a precedence for little enhancements like this: https://github.com/octokit/octokit.net/blob/master/Octokit.Reactive/Helpers/AuthorizationExtensions.cs\nSo I'm not opposed to it if it feels core. Like it's a very very common scenario. But if we start to see too many of these, we may want to consider another wrapper library. But for now, I wouldn't be opposed to putting something like this in Octokit.csproj.\n. Ah, so this has to be in a separate Octokit.Win8 library. But correct me if I'm wrong, is the actual behavior Win 8 specific? Or does it just happen to use Win8 specific libraries but could be generalized?\n. > showing a browser and getting some data from the result of the user's interaction is what the class does\nAh, that seems important since that's the preferred approach for OAuth when it comes to 3rd party apps. So if we did that generically, I'd want it in Octokit core. I'm wondering if this Octokit.WindowsRuntime library is important enough for us to bother with it. Is there a demand?\n. Look at you, always skating to where the puck is going.\n\n. :thumbsup: \n. Nice! :shipit:\n. Thanks! In the future, put \"closes #386\" in your commit message or in the PR message and merging the PR will automatically close the issue. :smile:\n. What @pmacn said. If there are other URL methods misnamed like this, we should fix those in a separate PR. :)\n. For this specific rename, do it in your PR for #331. If you find other misnamed methods, I'd prefer that be done in a separate PR.\n. If it's possible to write an integration test, we would definitely prefer it. You could do it in a separate PR if you want to get the code in. We haven't been requiring them because in some cases, they're very hard to get set up. But it would make us smile to have them.\n. \nNice! Very clean. If you don't mind, I made some comments about the lack of comments. If you have time to address those in another PR, that'd be great.\n. Looking good so far. Just realized this is still WIP. :)\n. Feel free to add the integration tests in another PR. Nice work! :thumbsup: \n. Is there a reason this is a separate project and not just part of our existing unit test suite?\n. Is that because these currently fail? It seems like these should be a part of our regular unit tests. They're kind of different than CheckProjects in that these are directly related to the design of our code much like our unit tests are. But if there's good reasons to keep them separated, that's :cool: too. \n. I guess as long as they're in the build, that's fine. My only concern is a practical one. Tests that aren't in the unit test project don't get run as often. For slow tests such as integration tests, that's fine.\nBut for tests like these, that means people won't find they've broken the conventions until they push and we run the test suite for them using QED. Most people are not likely to see them. But I could be wrong. Maybe folks run all tests all the time?\nIn any case, just an observation. Carry on. It's nice to have such tests at all. :)\n. @shiftkey \n. For reference, this is how Octokit.objc does it: https://github.com/octokit/octokit.objc/blob/master/OctoKit/OCTResponse.m#L22\nMaybe our clients need to return response objects and not just the actual entities.\n. Ok, I woke up at 5 AM with a bit of inspiration about this I want to run by you. :smile:\nLet's take a step back and think about what the purpose of etags are in the first place. For the most part, they make caches more efficient in order to reduce bandwidth. They potentially reduce load on the server if the server has an efficient means to determine whether an entity has changed.\nSo why should a client to Octokit.net care? Well, it allows them to make conditional requests which don't count against their rate limit. But this is a lot of work for a client to manage properly.\nWhat if we did it for them?\nWe could maintain an in-memory cache of requests and responses indexed by etag. So if you call GetRepositoriesForCurrent, we'd make a conditional request and if it's not modified, we'd return the set from the cache.\nThis in-memory cache could be replaced with other implementations. For example, you could inject a SQLite backed cache instead of an in-memory one.\nWe don't have to be a perfect cache to be effective. We could use the most recently used approach if memory consumption was crazy. \nAlternatively, we could just automatically cache the etag (and not the response data) and just provide a method to make the conditional request test. This would allow clients to test if their cache is up to date.\n. @half-ogre any thoughts on this?\n. /cc @paulcbetts for your thoughts. Sounds like we might be able to plug-in Akavache.Http.\n. @shiftkey when you get a moment. :)\n. Hi @vktr, do you have interest in finishing the work for this PR? This would be nice to get in an upcoming release.\n. @vktr that's not an error on your end.\n. \n. BTW, there's an alternate way to create a pull request using an issue number: http://developer.github.com/v3/pulls/#create-a-pull-request\nIt looks like this PR doesn't support that. Perhaps we can log another issue for that just to track it.\n. Lo and behold! Once again, you are way ahead of me Mr. @shiftkey.\n. \n. Thanks! I'll take a look.\n. \nThanks!\n. > It shouldn't be too hard to compile this conditionally for .NET 4.5 and keep on going without ETags in WinRT.\nThat gets my vote. I have a feeling @paulcbetts will come along with a crossplat lib that fixes that.\n. Awesome! Can't wait to get this in. @niik, once you merge/rebase master onto this branch I'll merge it if you're happy with it.\n. @niik @shiftkey, any time to take another look at this?\n. > The problem with the Wininet cache is that it is fairly broken...\nIs this documented somewhere? That seems like a serious bug.\nThanks for chiming in @darrelmiller!\n. @darrelmiller Wow. I pinged someone I know at MS to see if he can get the right folks to look at it. I noticed there's been no answer and it's 6 months old.\n. :thumbsup: \n. Yeah, if it's likely to be deprecated, let's not add it in the first place. I don't like adding already obsoleted methods.\n. I did singular for the property names because Users.Get makes me think it's getting all users vs User.Get is clear it's one. But for the type name, I like the plural to match (more or less) the API. So :thumbsup: to IActivityClient as Activity is both singular and plural so we can't be wrong.\n. I agree with @shiftkey. We've deliberately not cut a 1.0 release for this reason. Also, Octokit on NuGet has 557 downloads. I think people will survive.\nIt's a disappointingly low count, but we haven't really put our marketing muscle into it yet.\n. We might want to add more information when the assert fails. Here's an example I got today.\nSystem.Exception : Missing observable methods\n---- Assert.Equal() Failure\nExpected: String[] { }\nActual: String[] { \"get_Email\" }\nNot sure what to do with that.\n. :thumbsup: Thanks @shiftkey.\n. Doh! I'll add these files.\n. From an API perspective, CannotCreatePrivateRepositoryOnFreePlanException is the same thing as PrivateRepositoryQuotaExceededException in that we get the same response. So if we wanted to distinguish that, we'd have to do it from context we have on the client side.\n. This is ready for review when someone has time. :)\n. If it's an interface that's intended for others to implement, I tend to like minimalist interfaces implementations. The implementer only has to implement a single method and gets the extensions for free.\nWhereas if the interface has two methods, but one trivially calls the other, why make the implementer bother with implementing both? And worse, why give them the possibility of doing it wrong? That's why as a general principle of API design, I tend to not like overloads on interfaces and prefer extension methods.\nHowever, if the interface is solely for our testing purposes, I tend to like having the methods on the interface. It makes mocking it easier. :) However, if you write manual mocks, it actually makes it harder!\n. > (This case doesn't seem like a thing a typical consumer would stub.)\nAnd in this case, stubbing the one method is pretty easy. :)\n. Hell yeah!\n\n. > I have one issue: the JSON deserializer didn't match _links to Links; at the moment it's set to _links in Octokit/Clients/ActivitiesClient.cs\nI submitted a PR to address the _links issue. Once that's in, let's update this.\n. \n. @shiftkey or @half-ogre mind reviewing this?\n. Yes please!\n. Yeah yeah! I'm reviewing it. :stuck_out_tongue: \n. \n. \n. Going to pull this for now.\n. whoops.\n. Ok, this is ready now.\n. @pmacn well if you use NuGet to create a package based on the .csproj file (one of several ways to create a package), it scans the packages.config file of the project and adds all those as dependencies to your package. This doesn't affect Octokit because we use a different process and explicitly specify a nuspec file. But it's just a good practice. :smile:\n. paulcbetts: how do we make this portable without it?\n. Also, this will require updating the Octokit.nuspec file to include the new dependencies. NuGet now supports grouping dependencies by target framework. I don't want the net45 version to have these new dependencies because it doesn't need them.\n``` xml\n\n\n\n\n\n\n\n\n\n\n\n``\n. I think all we expose isProductHeaderValue` which is super easy to abstract.\n. @shiftkey feel free. :)\n. @trsneed: I'm not sure i follow. What \"hardcoded\" elements would you need to add to the nuspec here?\n\nI have not found a way to build a single package without adding a reference to Octokit itself on Microsoft.Net.Http,\n\nWell you should only need to add references to Microsoft.* for anything that's not .NET 4.5. In the nuspec, that would be something like:\n``` xml\n\n\n\n\n\n\n\n```\n^^^ What that does is ensure that Microsoft.Net.Http is a dependency when targetting any framework except .NET 4.5. For .NET 4.5, there are no dependencies.\n. Hi @phantomtypist, any plans to continue this work?\n. C'mon @phantomtypist! Octokit is more important than YOUR HOUSE!\n:stuck_out_tongue: \nGood luck with the renovations. :house: -> :house_with_garden: \n. This looks good to me. Once the build passes I'm :shipit: on this.\n. \n. Two sets of NuGet packages is very bad for libraries that other libraries depend on. What package should they reference? This might not be as big a deal for Octokit.net.\nI believe that eventually, strong naming as we know it will be burnt down by the CLR team and replaced with something better.\nUsing Octokit in Visual Studio seems like a core scenario to me. I would be :thumbsup: to taking the JSON.NET approach.\n1. Strong name Octokit.net and Octokit.Reactive.\n2. Freeze the assembly version at 1.0.0. The CLR assembly version of these DLLs would never change again.\n3. Continue to increment the NuGet version.\nIn this plan, NuGet becomes the unit of deployment, not the assembly as has traditionally been the case with .NET.\nBy freezing the assembly version, we don't have to worry about binding redirect problems in the future. Octokit is pre-release right now so I don't care about introducing breaking changes like this at the moment.\n. Also, while you should never rely on strong name keys to verify an assembly, I do worry that people still do. So we should consider having a set of private keys in the project for builds and another set for the official releases that we keep private.\nThe alternative is just to have one set of SN keys and have them in the project and hope people by now understand SN verification is a bad idea.\n. @shiftkey what paul writes about is a non-issue if we just include the official snk in the solution. Problem solved.\nRemember, we're not doing this for security reasons. We're doing it so people can use Octokit.net within a Visual Studio extension. I bet you can see the appeal of that to me. :wink:\n. > I mean, I currently use ReactiveUI in a Visual Studio Extension, I don't know where this \"You must SN every binary\" is coming from\nPeople keep telling me this :poop:. If we don't need to sign it, then let's not. What the hell? Can I get some good intel here? :smirk:\n. I go play :soccer: and this is what I come back to?\n\nNo matter what you do no one will be completely happy but that is the best solution I have found for keeping the most people happy.\n\n@JamesNK, are you happy with this? Would you do it again? Would you do it for a library like Octokit.net which is different in nature than JSON.NET. I'm just curious about your opinion given your experience.\nI mentioned that Octokit.net is different in nature and I should explain what I mean. JSON.net is a pretty fundamental library. It's the type of library that many other libraries need to reference. Thus the applications that reference those libraries are affected if JSON.NET doesn't strong name.\nBut I don't expect many other shared libraries will reference Octokit.net. I'd expect it would be referenced directly by applications. Therefore my gut is that the need to strong name is not as strong.\nIf my assumption is correct, strong name isn't the only solution to the issues raised here. We could offer another Octokit.Source package that contained the source code for Octokit.net which would then get compiled into your own application. The strong name issue in that case goes away.\n. In theory, someone could write an Install.ps1 for a NuGet package that checked the target and if it was strong named, would strong name the assemblies (@davidfowl can correct me if I'm wrong). Even if it's not possible, it should be possible and a PR to NuGet could fix that.\nWe could even include a strong name key in the package for this script to use so the strong name is consistent.\nThis doesn't solve every possible dependency graph situation, but for a large number of cases I think it would be just fine. If it made this perma-headache-thread go away, then I'd be open to including such a script in our package.\nBut the Octokit.net team isn't going to write that. We have more pressing matters like completing the library to contend with.\n. So it occurred to me we could do an intermediate step that would help some folks and even be simpler.\nInclude the Octokit.net strong name key in the package and a PowerShell script that people can use to strong name Octokit.net.\nbash\nInstall-Package Octokit.net\nSign-Package Octokit.net\nThe Sign-Package script just signs every assembly that was in the lib folder.\nThis would be much easier to implement than the fully automatic approach I outlined. Ultimately, we would want something fully automatic. But this could be a good stepping stone to that.\n. > @Haacked that makes it incompatible with package restore though, as you'd need to check in the signed assemblies.\n:poop: you're right. Forgot about that.\nNever mind. Burn it all to the ground.\n. ClickOnce doesn't require signed assemblies. Irrelevant to this discussion.\n. Allow me to clarify, it does not require strong named assemblies.\n. Also, it looks like you created this off an old master branch. Please fetch and merge origin/master into your branch. Or rebase your branch off origin/master. Either way.\n. Great stuff! I'm going to run our build server against it and then I'll merge it once it passes.\n. Thank you! \n. According to this \n\nThe payloads for all hooks mirror the payloads for the Event types, with the exception of the original push event, which has a more detailed payload.\n\nSo as we build out these event types, we'll end up with most of them except the push event.\n. @philoushka We'd accept a contribution. Feel free to fix anything wrong with our PushEvent class. I honestly haven't looked very closely at it so I'm not sure why it's different from the documentation. What's important to me is a working implementation. So if you're actually using this, then your contribution would be really valuable!\n. Looks good! Just merge in (or rebase against) master so I can hit that green button. :)\n. Hmm, I still can't merge it. It says there are conflicts. Did you make sure to fetch latest?\n. \n^^^ That's what I'm seeing. That indicates that your branch isn't up to date with master on the server.\n. Try running\nbash\n.\\build.cmd FixProjects\n. And then commit those changes and push.\n. Ok, I'll take a look at it tomorrow.\n. So it looks like you pushed it in a conflicted state. When I pulled it locally, there was still a merge conflict left to resolve. I resolved it and pushed it to a new branch.\n.  thanks for your contribution!\n. Oh, w e recently received a pull request that fixed it, but I bet it didn't fix the test. Mind just fixing it?\n. I think I added readonly collections to SimpleJson. So maybe just upgrade?\n. Nice work @shiftkey!\n. Whoops, forgot to choose an emoji. :stars: :v: \n. Yeah. But obviously use the returned message and not that literal string. :stuck_out_tongue: \n. Flawless Victory!\n. So good. Just some really nitpicky shit. Also, it's not automatically mergeable. :smile:\n. Great stuff!\n. :mushroom: :sparkles:\n. > the history accurately reflects what happened. Are you trying to hide information from people? \nUmm, yeah. That's why we use Git and not SVN! :stuck_out_tongue: \nThat's neither here nor there. Well done!\n. Thanks so much for submitting a pull request! I really appreciate it. There's a few comments I made on it.\n. Run build.cmd FixProjects and commit changes.\n. Just an update. i'm looking into this right now and will push a new PR that incorporates these PRs.\n. Ok, I'm going to take this in a slightly different direction. Rather than have different types for Submodule, File, Directory, I'm just going to have a single type that has the union of all the properties. The properties not in use will simply be null in the response. This ends up keeping things really simple. I'll post a PR soon for comment.\n. Closing in favor of #649\n. Thanks @shiftkey \n. So the suggestion here is to change the signature of the Get method of IReferencesClient\nfrom\ncsharp\nTask<Reference> Get(string owner, string name, string reference);\ntoo\ncsharp\nTask<IReadOnlyList<Reference>> Get(string owner, string name, string reference);\n. @hknielsen yeah, we'll have to do some detection and just wrap a single ref in an array.\n. Closing per comment in #511\n. I vaguely remember a discussion with the API team about size not being accurate and deprecated. \nI was told it wasn't worth using. I think it was @technoweenie or @pengwynn who told me that.\n. @jasonrudolph is there a cheap way to determine if a repository is empty? Could we get an is_empty property to replace size on repository?\n. The build failure doesn't appear to be related to this change. It seems we have a 300 second timeout for the integration tests and the tests are taking longer than that to run. I'm trying to figure out where that timeout is specified.\n. /cc @half-ogre @shiftkey please see previous comment in case you have an idea.\n. Hmm, according to our FAKE build, the integration test timeout should be 10 minutes. @forki do you think this is a bug in FAKE? Or is something else timing this out?\nfsharp\nTarget \"IntegrationTests\" (fun _ ->\n    if hasBuildParam \"OCTOKIT_GITHUBUSERNAME\" && hasBuildParam \"OCTOKIT_GITHUBPASSWORD\" then\n        !! (sprintf \"./Octokit.Tests.Integration/bin/%s/**/Octokit.Tests.Integration.dll\" buildMode)\n        |> xUnit (fun p -> \n                {p with \n                    XmlOutput = true\n                    Verbose = false\n                    OutputDir = testResultsDir\n                    TimeOut = TimeSpan.FromMinutes 10.0  })\n. Or might this be a QED setting @half-ogre?\n. @forki what do you mean the \"correct\" timeout? 5 min? If so, how do we change it? Or do you mean it's not FAKE causing this?\n. Ah, seems like a legit failure this time?\n. Ack, there are conflicts so I can't merge this yet.\n. @kzu would you mind adding the corresponding new methods to IObservableTeamsClient?\n. The CI is manually launched for now since we want don't want to run arbitrary third party code automatically. :smile:\n. The failure seems unrelated to these changes.\n. \n. \nThanks @kzu!\n. We await your new PR. :smile:\n. > Given how much we actually depend on this, this seems like a good thing.\nDo you mean \"given how little we depend on this?\" If so, I agree. Make it so.\n. Ok, I'll hit the merge button after we get the CI running again.\n. Thanks @paulcbetts!\n. Herp derp.\n.  thanks!\n. We could run the unit tests in parallel, but not the integration tests.\n. Done in #462\n. Ugh! I should have caught this in the initial review because I make this same mistake every time and think to myself, \"ALWAYS CHECK EVERY CONFIG!\"\n\n. @shiftkey you happy with this? :ramen:\n. I hear Rx is dead.\n. :ramen:\n. > Would it be worth rolling together the url formatting with the redirect?\nNot in Octokit.net. After all, what exactly is a redirect? That would require we add a reference to System.Web. We're agnostic to ASP.NET etc. We could consider an Octokit.AspNet or Octokit.Contrib library that had such things.\n. :ramen:\n. If there's no more comments, would love to get this merged and shipped so I can get that blog post out. I'll ship the NuGet package.\n. Rather than a wiki, maybe we should create a gh-pages Jekyll site with docs.\n. @JacobCZ it'd be under one hood. It'd be a branch of this very repository and could be versioned with the code base. We could even make it part of the http://octokit.github.io/ site.\n. Yeah, let's do that for now.\n. @JacobCZ in the meanwhile, I hope this blog post helps you get going. http://haacked.com/archive/2014/04/24/octokit-oauth/\n. So we just shipped an improvement to the wikis. https://github.com/blog/1828-wikis-now-with-more-love\nI'm now open to trying them out as our documentation. @shiftkey what do you think? Experiment with it?\n. I'm down for that. @shiftkey? If you agree, I'll create the branch.\n. :thumbsup: to whatever @shiftkey says here. :smile:\n. Thanks! :thumbsup: \n. Seems like this is complete by itself. Should the encoding q parameter be another PR?\n. So is this ready to merge? Any tests?\n. Oh, I meant is there a unit test for this specific change?\n. @shiftkey this look good to you?\n. Ok @shiftkey, I won't.\n. :metal:\n. I thought I had fixed this. Be careful with the fix. When the value is from an enum, we should lower case it. But if it's a value coming from \"user input\" we can't. For example, the OAuth methods have a state parameter that's a CSRF token and casing matters there.\n. Hi @Gentlehag we'd love to have your help! Did you follow the instructions here? https://github.com/octokit/octokit.net/blob/master/CONTRIBUTING.md\nThe skipped tests are most likely integration tests. Those go against github.com so you have to create a test account and set up your environment if you want to run those. It's not strictly necessary if you're making small contributions as we'll run the tests on our CI server. But if you plan to do major contributions, it's nice to set up.\nOur tests are broken down into unit and integration tests. I think we currently have a few broken integration tests that we're working to fix unfortunately. Our unit tests should all pass. I hope that helps.\n. I believe the GitHub api expects lowercase (but I could be wrong). I think we should change the test and not the EnumExtensions\n. Wow, I wonder how that got out of sync! Thanks! \n. \n. Why are you calling task.Wait(). Instead, just use the await keyword.\ncsharp\nvar response = await _client.Oauth.CreateAccessToken(new Octokit.OauthTokenRequest(ExtLibs.ConfigVars.Get(\"clientID\"), ExtLibs.ConfigVars.Get(\"clientSecret\"), model.code));\nIf there's some reason you can't do that, access the task's Result property.\ncsharp\nvar task = _client.Oauth.CreateAccessToken(new Octokit.OauthTokenRequest(ExtLibs.ConfigVars.Get(\"clientID\"), ExtLibs.ConfigVars.Get(\"clientSecret\"), model.code));\nvar response =  task.Result;\n. Hi @johnduhart, I'll try and review this soon. Any plans to finish the integration tests soon?\n. Either is fine: merge or Rebase. Whatever is easier.\n. Never come back!\n. Hi @nasko83, this looks like it's coming along. Are you planning to finish this?\n. :thumbsup: other than the one commonwealth typo. :trollface: \n. Should this go in the main Octokit package or perhaps a special samples package? For example, we may want to create Octokit.Linqpad and Octokit.Reactive.Linqpad.\n. I think the issues for me is I have no idea how many people use LINQPad. I don't use it so this feature doesn't really matter much to me. Will there be other tools that want their own proprietary formats in our packages?\nIf a lot of you DO use LINQPad, I will relent and go with it because I don't feel too strongly about it.\n. could someone post what an example might look like? Perhaps if we could link to the examples in the README and make sure they're human readable as well as LINQPad readable, I'd be more favorable. That way they're useful to folks who don't have LINQPad installed.\nAlso, I'm concerned about the maintenance cost of these samples over time. If they're not compiled and run as part of our CI, then they'll bit rot over time. Would someone sign up and figure out a way to do that? (Roslyn to the rescue?)\n. > Con is the package has some extra text files if you don't use LinqPad.\nSo I'm :+1: for adding these to the main package if we:\n- [ ] Write useful samples that we can link to in the README and can be read nicely online.\n- [ ] Make sure our CI validates the samples somehow.\n. > I was planning to use that feature in the CI build to make sure the commits don't break the samples.\n:+1: \n. Ack! I'll look at cutting a release tomorrow.\n. I have a PR with a fix now.\n. I just pushed Octokit 0.3.5 to NuGet. Please try it out. https://www.nuget.org/packages/octokit\n. One minor nit, otherwise looks aces.\n. Hmm, I noticed we use number elsewhere in that class. Not sure why, but oh well. :smile:\n. Sure!\nOn Mon, Jun 9, 2014 at 5:40 PM, Cameron MacFarland <notifications@github.com\n\nwrote:\n@Haacked https://github.com/Haacked Want me to fix that too?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/507#issuecomment-45561952.\n. Let's go with number when it means \"issue number\" and make sure the doc comment is correct. Thanks a lot for your help!\n. \n. @haagenson thanks for looking into this. I'm going to see if we can get this fixed on the github.com side of things.\n. Looks great! Any idea when you'll get to the integration tests?\n. That failure seems unrelated to your work. Thanks!\n. \n. Whoops, I thought I had merged it, but I got distracted. :smile:\n. I think there's a good reason for that code. @half-ogre wrote it and might remember.\n\nHere's what I propose. Let's add an attribute called [AlwaysInclude] or something like that. If that attribute is on the property, we always include it in the serialized JSON. This code path is under our control.\n. It is? Looking at the code you linked to it looks like the line:\nvar value = getter.Value(input);\nWe could just query \"getter\" for its attributes. I'm not in front of the keyboard to try it out though.\n. @shiftkey is on :fire:\n. :thumbsup: \n. \n. Whoops, can't merge it.\n. Killing it!\n. :thumbsup: to option 1\n. Nice work!\n. I'm fine with skipping them for now until we get things set up properly.\n. The one test that failed is due to not configuring OCTOKIT_GITHUBORGANIZATION which I just did.\n. :thumbsup:\n. What is the Octokit.exe/Octokit.exe.csproj file for? Seems unrelated to this PR.\n. That looks like a brand new file your commit added. I don't see it in the main repository. Probably safe to delete the \"Octokit.exe\" folder and commit that and push.\n. Hmm, after thinking about this, I have a simpler idea. The only header I really need to override is accepts.\n. Great! The CONTRIBUTING.md guide has some info about how we set up environment variables for integration tests. We do have the tests create the repositories they need in the setup.\nHere's a good example: https://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/TreeClientTests.cs\n. Thanks!\n\n. This is looking good. Would you be interested in adding the observable counterparts too?\n. I ran our conventions tests and it points out:\n\nMethods not found on interface IObservableTeamsClient which are required:\n- AddMember\n- AddRepository\n- RemoveMember\n- RemoveRepository\n\nWould you be willing to add those?\n. Excellent work!\n\n. I try to avoid static properties like this.\nFor example, you may have 2-different octokit instances (github.com and some github enterprise) instance and this would make it impossible to have different timeouts for each.\nIf you want to set a default for all requests that can be easily overridden, I think the default timeout should an instance property on IGitHubClient.\nWhat do you think @shiftkey \n. Thanks Matt!\n. Thanks! Yeah, we need to look into that test separately.\n. Thanks!\n\n. I think size was left out because of future deprecation. It's very difficult to obtain a meaningful number.\n. These are all great points and make sense for updates. We should not require the existing data to be there. Especially if the API doesn't require that.\n. LOL at the bug! Seems like an easy fix. Want to give it a try yourself and send a pull request? :smile:\n. Hmm, I believe the file size limit is 50MB. https://help.github.com/articles/working-with-large-files\nI'm not aware if there's a different limit for unauthenticated users. Want to try that first? If it doesn't work, I can dig into it more.\n. Thanks! :+1: \n. Whoops! Clipboard error.\n. > Still think you should dogfood in Octokit's own build script ;-)\nWe would love help in that. :smile:\n. > Can we use the currently build Octokit.dll?\nWell that and Octokit.Reactive.dll. But I'm not sure I understand the question. What else would we use?\n\nWhich files do you want to release\n\nRight now we use the default release approach of zipping up the source code. But it'd be nice if the release contained both nuget packages too.\n. OH! Like you want to use the Octokit we build to publish itself. That's crazy. But interesting. Yeah, I guess we use the last known good one. But maybe copy it somewhere other than build output?\n. > So we just have to build a nice zip right? \n\nWhich files do you want to have in it?\n\nI'll be honest, I haven't looked at it closely. I thought creating a release automatically gives you links to the zip of the source. So we'd only need to add two package files to the release. One for Octokit and one for Octokit.Reactive.\n. :thumbsup: on release notes.\n. \n. Thanks for the report! I have a bad feeling we used to have a custom edit to SimpleJson that's been lost with an upgrade. Though I thought we updated SimpleJson proper to support readonly collection deserialization.\n. We wanted as few dependencies as possible. Our original goal was to have a single drop-in dll. Not sure if we care so much anymore.\n. Looks good to me!\n. Should we allow changing it after the Connection has been created? For example, could it be a property (with a default value) so we don't need to add another ctor overload?\n. Minor nits on the release notes. Otherwise looks good.\n. > To enable proxy authentication (against the current Windows user) you can just set WebRequest.DefaultWebProxy.Credentials = CredentialCache.DefaultCredentials;, no need to configure something in Octokit...\nI assume you mean that the app developer who is using Octokit just needs to set that code, right? What are the implications of doing that?\n. Thanks! I added a few commits of stylistic changes.\n\n. This is great! I just have a few nitpicky comments, but otherwise this looks very well done! :+1: \n. \n. Yo @shiftkey when you get a moment. :smile: Also, look at that, AppVeyor Green!!!\n. This seems to include a ton of commits. Did you create your branch off of master?\n. We're about to ship https://github.com/octokit/octokit.net/pull/621 which I believe has it.\n. Ah, sounds like an oversight. Want to submit a PR? I'm thinking that it might make sense to add a Contributor type that inherits User and adds a public int Contributions { get; set; } property. Seem legit @shiftkey?\n. :shipit:\n. Nice work. One minor nit that can be addressed later. I have a bad memory for these things, but I thought we all agreed that summaries are full sentences and thus require punctuation. But parameters, for example, are fragments and don't end in periods. We should memorialize whatever we decide into a style guide for comments. :smile: I seem to remember @half-ogre having opinions on this.\n. Yeah, that parameter is not named correctly. I think the way I'd prefer we fix this is to have two RepositoryExistsException constructors.\n``` csharp\npublic RepositoryExistsException(\n            string organization,\n            string name,\n            Uri baseAddress,\n            ApiValidationException innerException);\nand\npublic RepositoryExistsException(\n            string name,\n            Uri baseAddress,\n            ApiValidationException innerException)\n```\nThe first one is called if the exception is for an organization. It should not allow a null organization value. The second one is called if the exception is for the current user.\nIt's up to the caller to determine which ctor to call.\n. We use it in GHfW to provide a clear and useful error message to the user.\n. I made one comment, but it could be addressed in another PR if you agree. This looks good!\n\n. :shipit:\n. :shipit:\n. Is this waiting on anything or may I merge it?\n. Because we're pre 1.0, I'm inclined to just remove these methods rather than obsolete them.\n. Could someone try this out? I think it's ready to merge. :cake:\n. Something keeps fucking with the whitespace. I suspect it's the documentation rewriter. Anyways, this should be good I hope. I'm up too late again. :smile: so I'm going to sleep and hope the build is green.\n:package: \n. I like the using approach. :+1: \n. Nobody's working on this currently. Feel free.\n. Code looks good. Just a question, don't we have tests that require a free account? If we do, we might need to have 2-test accounts rather than this boolean conditional.\n. Love this. :smile:\n\n. Quite possibly! I'll test it out.\n. Also, it looks like there were some new model types I missed when I merged master in.\n. SimpleJson doesn't support readonly dictionaries. And yet another yak appears!\n. Ok, I created a PR to simple-json. In the meanwhile, I'll just edit our copy directly.\n. Ok, I think this is ready. Would love some :eyes: on it. Thanks for the excellent review so far @khellang.\n. > Is there a reason for sometimes using IReadOnlyCollection over IReadOnlyList\nGood question. I don't see any benefit to using collection over list here. List provides an indexer which can be handy.\n. :shaved_ice: \n. :pineapple: \n. :thumbsup: to release notes\n. > Keep scraping client interfaces for parameter- and return types to determine request- and response models.\nI like this option. It's harder, but gives a better result. Who's afraid of hard?\n. Sounds good.\n. I'm not sure I understand. Walk what tree?\n. Oh wait, I understand now. Yeah, we have to iterate the properties of the returned models looking for types we haven't seen yet.\n. Fun, right?! :laughing: \n. Well definitely keep track of the types you've already seen.\n. :wolf: \n. Ok, merged master in. Hopefully this is good. :smile:\n:tanabata_tree: \n. bump to Mr. @shiftkey \n. :poop: I just merged another PR into master that breaks this PR. Doh!\n. \n. \n. Looks good to me. Perhaps a PR to https://github.com/github/gitignore/blob/master/VisualStudio.gitignore is also in order.\n. \n. Thanks!\n. These models are basically data objects so I don't like 1 or 3 for that reason. They aren't meant to have any behavior.\nI like 2. Each object should have a default constructor (so we can deserialize them) and a constructor that fully populates it.\nWould you be interested in submitting a PR to introduce those ctors? :smile:\n. I'm a fan of immutability too, but I think using readonly fields instead of properties will introduce more problems than it solves.\nFirst of all, I think we want to stick with properties. Data binding infrastructure in much of .NET depends on properties, not fields. It might not make sense to bind to these objects, but I don't want to prevent it. Also, it gives us the freedom to change the implementation of the property in the future should we ever have a good reason to do so.\nAlso, a readonly field currently doesn't guarantee immutability. It just so happens via a fluke of implementation that you can set a readonly field via reflection, but as Eric Lippert points out...\n\nI note also that just because you can in some implementation today does not mean that you can on every implementation for all time. I am not aware of any place where we document that readonly fields must be mutable via reflection. As far as I know, a conforming implementation of the CLI is perfectly free to implement readonly fields such that they throw exceptions when mutated via reflection after the constructor is done\n\nThe point here is while we can't rely on this behavior, it is possible today negating the immutability guarantee. Our current implementation is every bit as immutable as one with readonly fields.\nLastly, if the implementation ever did change, it would considerably complicate our deserialization of these objects.\nFor all these reasons, I would rather stick with the way we currently do them. Until the language supports immutable as a first class construct, the best we can do is provide a \"verbal\" guarantee of immutability. :smile:\n. > There are a lot of code analysis warnings about URIs as Strings. Let me know what the preferred way to resolve this is and I'll apply the fix across the board in this PR.\nMy inclination is to pass in Uri and call ToString() on them when setting the property. These constructors aren't used in normal usage. They're primarily there for testing and in the rare case someone needs to override a behavior and explicitly create these types. In those cases, why not require a URI. @shiftkey any thoughts?\nI think we should get rid of the obsolete properties in this PR. It's about time. :smile:\n. > So that's what I'd favour for this - as long as the ctors are protected, whatever.\nMost of the ctors are public. The point of them is to allow people to create these instances without having to subclass them.\n. This is really great! It's tedious work and very much appreciated!\n\n. BTW, now that we have proper ctors, we don't need all the model properties to have protected setters. Probably best to make them private.\n. I share a similar concern. I worry it could end up being fragile. For example, are we sure setting all those repositories matches the exact state a real Repository would be in when initialized from a path? Can we guarantee that for all time?\nI like the idea of a RepositoryUnitOfWork or RepositoryContext class (for lack of a better name) or even a RepositoryScope class. That class is disposable and exposes a vanilla Repository property. Pretty much what @shiftkey suggested.\n. Could you post the request and response from a Fiddler trace (with private details ommitted of course) in here?\n. Ah! That's almost certainly it. If you clone the repo, apply that fix, and try it out, it'll probably work.\nWould you be interested in fixing it and submitting a pull request? If you need help with that process, I'm happy to help. :smile:\n. @aneville probably the easiest way to test with your app is to compile your app, then replace the Octokit.dll with the patched version and then run your app.\n. @aneville in general, it's best not to commit to master. Create a branch for your work and commit it there. The reason for this is if there are new changes to master upstream (aka new changes to master in octokit/octokit.net), it's easier to update master on your fork with those changes from upstream and then either merge them into your branch or rebase your branch against them.\nWhen you create a pull request, it'll do the right thing and create the pull request against the upstream master. Does that make sense?\n. @aneville Cool! We're happy to help. We follow something we call The GitHub Flow. There's a lot of good guides if you need more background info here: https://guides.github.com/\nAnd of course, the Octokit maintainers are happy to help when we can, though we get :arrow_down: :droplet: at times.\n. Looks good to me. Too bad we can't make the branch query string parameter dynamic. :smile:\n. \n. Yes, it looks like we're missing that property. Want to submit a pull request that adds it in?\n. Pro-tip: In your commit message, you can put \"fixes #689\" in the body of the message to indicate that commit fixes #689. That way, when this PR is merged, it'll also close that issue. :smile:\n. \n. Looks good! Please add an argument to the existing constructor to populate this property just like we do with the other properties.\n. \n. Hmm, try unloading that project.\n. @shiftkey @DaveWM if I understand this correctly, it seems like we should remove the deprecated property from our client API. I'm guessing WatchersCount can go away as long as we have a SubscribersCount property?\n. I'd rather have the property name match the api field name as much as possible. We're not 1.0 yet, we can do whatever the hell we want. :stuck_out_tongue:  Let's just match the API canonical names.\n. :stuck_out_tongue: It's just my preference. I think it's a good rule of thumb. But I'm open to strong arguments to the contrary in specific cases. :smile:\n. Also, if we're all in agreement, would you like to submit a PR with this change @DaveWM?\n. I approve this message. We need to make sure we account for it in the release notes.\n. We just haven't gotten around to it. Would love a PR that implements as many as you feel like. And then open a new issue with a list of the remaining for others to implement?\n. :cool: Personally, I think it should be called \"Poshtokit\" :stuck_out_tongue:  :octocat: \n. \n. Flawless victory!\n. God I would love it if we could drop it. I am not set up to test it and it would be one lest thing to worry about. @thedillonb At this point, I'm ready to trust your call on this. I assume you've tested it out a bit?\n. Nice!\n. \n. I'm happy! :smile:\n. \n. You may well be the first person we've run into who's tried to implement our IHttpClient! :smile:\nWould welcome some PRs that improve the API.\n. \n. Ah. Ok. Mind sending a pull request? We should just make that ctor empty and allow setting the term property.\n. Flawless Victory! :sparkles:\n\n. :thumbsup: on release notes.\n. I need to rebase this real quick.\n. :station: \n. @shiftkey is looking into this. At this point, I think we should temporarily stop using SourceLink. @khellang, mind removing the following two lines and pushing again and see if it builds correctly?\nhttps://github.com/octokit/octokit.net/blob/master/build.fsx#L189-L190 \n. :sparkles: Thanks!\n. :heart_eyes: :+1: \n. :yum: \n. > Currently when you retrieve a commit from {user}/{repo]/commits you get this payload for the Author and Committer:\n@shiftkey that's not exactly correct.\nIf you look at https://developer.github.com/v3/repos/commits/#get-a-single-commit you'll see the payload looks more like (bunch of stuff cut out):\njs\n{\n  \"commit\": {\n    \"author\": {\n      \"name\": \"Monalisa Octocat\",\n      \"email\": \"support@github.com\",\n      \"date\": \"2011-04-14T16:00:49Z\"\n    },\n    \"committer\": {\n      \"name\": \"Monalisa Octocat\",\n      \"email\": \"support@github.com\",\n      \"date\": \"2011-04-14T16:00:49Z\"\n      },\n   }\n  \"author\": {\n    \"login\": \"octocat\",\n    \"id\": 1,...\n  }\n  \"committer\": {\n    \"login\": \"octocat\",\n    \"id\": 1,...\n  }\n}\nSo note that GitHubCommit has Author and Committer properties. But it also has an inner Commit property that also has an Author and Committer.\nGitHubCommit represents a commit database record which includes things like comments etc. The Author and Committer properties of GitHubCommit represents GitHub accounts if it could match one up. The inner Commit property of GitHubCommit represents the raw Git commit and its Author and Committer properties represent the basic information that Git has for the commit.\nThe one thing I haven't had time to determine is what happens on the GitHubCommit response if it couldn't match up the Author with an account. I assume it just returns the simple form. @pengwynn @jasonrudolph do you know what happens for sure? I'd love a pointer to the code. :smile:\n. @jasonrudolph That's kind of what I hoped would happen. :smile: Makes it easier for us connoisseurs of statically typed languages.\n. I'm going to push a new PR with these changes and some of my fixes on top of them.\n. This is on my list, but it will take me some time to really think it through. Corner me at BUILD. :smile: :cocktail: \n. > (@haacked jump in here if you disagree with this direction)\nMay I jump in here if I don't disagree? :sparkles:\n. I like the ClientOptions route. It reminds me of the the ProcessStartInfo approach. In fact, maybe we could call it ClientInfo or something like that.\nI do think we should retain the simpler .ctors with the most common options.\n. > You want to port the existing ctors on GitHubClient over to this ClientInfo class?\nNot necessarily. I just mean I want to retain some of the existing ctors along with new ones that accept ClientInfo\n. :spaghetti: \n. :sparkles: Thanks!\n. > Crazy idea, but maybe make the model classes partial which then lets people make extensions (or ship an official opt-in extensions library) to the models and clients accordingly.\n\nAny thoughts?\n\nPartial classes are a compilation hack. They have no meaning once the binary has been produced. In other words, you can only extend a partial class with your partial class if you're compiled to the same assembly.\n. Well the root problem is that our API doesn't support this. You'll have to email support@github.com for that. So your code has to create a request per issue and that's going to be slow. It might be possible to do this with our search endpoint, but I haven't tried that out.\nIf you don't mind the N+1 problem, I think the approach you took is fine. We want to keep Octokit.net closely aligned with the API. If there's a strong demand for it, we could consider an Octokit.Extensions package with these meta types, but this is the first we've heard of it.\n. Hi. We'll handle this via the normal support channels. But what you're running into is definitely related to contention with another Visual Studio Extension. We're both installing different versions of the same assembly and the other extension won and broke us. :frowning: \nWe're working on a fix.\n. Looks good to me! :sparkles:\n. Looks good to me. Just one question.\n. Oh yeah, good catch! \n. Thanks! What testing have you done on this?\n. Yeah, they probably should inherit from ApiException.\n. Hi @warrenbuckley, I wonder if the model binding is having trouble. Can you verify by sniffing the network what the data looks like that's being passed to your method? Also, as an FYI, the method name has \"receive\" misspelled. :smile:\nOne thing you could try is changing the argument type for payload to a string and see what the JSON looks like.\nI noticed that the setters for PullRequestEventPayload are protected. This might be causing problems with the model binder.\n. > This was also where my thought process went to. Perhaps we need to plug in a model binder that does things the SimpleJson way?\nI'm starting to wonder if making the setters protected is causing more pain than it's worth.\n. Yeah, we should test these scenarios out.\n. Here's the formatted JSON. This doesn't look like the pull request payload.\njs\n{\n   \"zen\":\"Half measures are as bad as nothing at all.\",\n   \"hook_id\":5154329,\n   \"hook\":{\n      \"url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/hooks/5154329\",\n      \"test_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/hooks/5154329/test\",\n      \"ping_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/hooks/5154329/pings\",\n      \"id\":5154329,\n      \"name\":\"web\",\n      \"active\":true,\n      \"events\":[\n         \"pull_request\"\n      ],\n      \"config\":{\n         \"url\":\"http://3c2a18de.ngrok.com/umbraco/api/GitHubWebHook/ReceiveWebHook\",\n         \"content_type\":\"json\",\n         \"insecure_ssl\":\"0\",\n         \"secret\":\"********\"\n      },\n      \"last_response\":{\n         \"code\":null,\n         \"status\":\"unused\",\n         \"message\":null\n      },\n      \"updated_at\":\"2015-06-25T08:40:45Z\",\n      \"created_at\":\"2015-06-25T08:40:45Z\"\n   },\n   \"repository\":{\n      \"id\":37732545,\n      \"name\":\"Umbraco-Identity-Playground\",\n      \"full_name\":\"warrenbuckley/Umbraco-Identity-Playground\",\n      \"owner\":{\n         \"login\":\"warrenbuckley\",\n         \"id\":1389894,\n         \"avatar_url\":\"https://avatars.githubusercontent.com/u/1389894?v=3\",\n         \"gravatar_id\":\"\",\n         \"url\":\"https://api.github.com/users/warrenbuckley\",\n         \"html_url\":\"https://github.com/warrenbuckley\",\n         \"followers_url\":\"https://api.github.com/users/warrenbuckley/followers\",\n         \"following_url\":\"https://api.github.com/users/warrenbuckley/following{/other_user}\",\n         \"gists_url\":\"https://api.github.com/users/warrenbuckley/gists{/gist_id}\",\n         \"starred_url\":\"https://api.github.com/users/warrenbuckley/starred{/owner}{/repo}\",\n         \"subscriptions_url\":\"https://api.github.com/users/warrenbuckley/subscriptions\",\n         \"organizations_url\":\"https://api.github.com/users/warrenbuckley/orgs\",\n         \"repos_url\":\"https://api.github.com/users/warrenbuckley/repos\",\n         \"events_url\":\"https://api.github.com/users/warrenbuckley/events{/privacy}\",\n         \"received_events_url\":\"https://api.github.com/users/warrenbuckley/received_events\",\n         \"type\":\"User\",\n         \"site_admin\":false\n      },\n      \"private\":false,\n      \"html_url\":\"https://github.com/warrenbuckley/Umbraco-Identity-Playground\",\n      \"description\":\"Experiments with Umbraco 7.3 beta & Identity\",\n      \"fork\":false,\n      \"url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground\",\n      \"forks_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/forks\",\n      \"keys_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/keys{/key_id}\",\n      \"collaborators_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/collaborators{/collaborator}\",\n      \"teams_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/teams\",\n      \"hooks_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/hooks\",\n      \"issue_events_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/issues/events{/number}\",\n      \"events_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/events\",\n      \"assignees_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/assignees{/user}\",\n      \"branches_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/branches{/branch}\",\n      \"tags_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/tags\",\n      \"blobs_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/git/blobs{/sha}\",\n      \"git_tags_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/git/tags{/sha}\",\n      \"git_refs_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/git/refs{/sha}\",\n      \"trees_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/git/trees{/sha}\",\n      \"statuses_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/statuses/{sha}\",\n      \"languages_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/languages\",\n      \"stargazers_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/stargazers\",\n      \"contributors_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/contributors\",\n      \"subscribers_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/subscribers\",\n      \"subscription_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/subscription\",\n      \"commits_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/commits{/sha}\",\n      \"git_commits_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/git/commits{/sha}\",\n      \"comments_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/comments{/number}\",\n      \"issue_comment_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/issues/comments{/number}\",\n      \"contents_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/contents/{+path}\",\n      \"compare_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/compare/{base}...{head}\",\n      \"merges_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/merges\",\n      \"archive_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/{archive_format}{/ref}\",\n      \"downloads_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/downloads\",\n      \"issues_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/issues{/number}\",\n      \"pulls_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/pulls{/number}\",\n      \"milestones_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/milestones{/number}\",\n      \"notifications_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/notifications{?since,all,participating}\",\n      \"labels_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/labels{/name}\",\n      \"releases_url\":\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/releases{/id}\",\n      \"created_at\":\"2015-06-19T16:15:46Z\",\n      \"updated_at\":\"2015-06-19T16:38:46Z\",\n      \"pushed_at\":\"2015-06-24T17:40:18Z\",\n      \"git_url\":\"git://github.com/warrenbuckley/Umbraco-Identity-Playground.git\",\n      \"ssh_url\":\"git@github.com:warrenbuckley/Umbraco-Identity-Playground.git\",\n      \"clone_url\":\"https://github.com/warrenbuckley/Umbraco-Identity-Playground.git\",\n      \"svn_url\":\"https://github.com/warrenbuckley/Umbraco-Identity-Playground\",\n      \"homepage\":null,\n      \"size\":0,\n      \"stargazers_count\":0,\n      \"watchers_count\":0,\n      \"language\":\"JavaScript\",\n      \"has_issues\":true,\n      \"has_downloads\":true,\n      \"has_wiki\":true,\n      \"has_pages\":false,\n      \"forks_count\":0,\n      \"mirror_url\":null,\n      \"open_issues_count\":0,\n      \"forks\":0,\n      \"open_issues\":0,\n      \"watchers\":0,\n      \"default_branch\":\"master\"\n   },\n   \"sender\":{\n      \"login\":\"warrenbuckley\",\n      \"id\":1389894,\n      \"avatar_url\":\"https://avatars.githubusercontent.com/u/1389894?v=3\",\n      \"gravatar_id\":\"\",\n      \"url\":\"https://api.github.com/users/warrenbuckley\",\n      \"html_url\":\"https://github.com/warrenbuckley\",\n      \"followers_url\":\"https://api.github.com/users/warrenbuckley/followers\",\n      \"following_url\":\"https://api.github.com/users/warrenbuckley/following{/other_user}\",\n      \"gists_url\":\"https://api.github.com/users/warrenbuckley/gists{/gist_id}\",\n      \"starred_url\":\"https://api.github.com/users/warrenbuckley/starred{/owner}{/repo}\",\n      \"subscriptions_url\":\"https://api.github.com/users/warrenbuckley/subscriptions\",\n      \"organizations_url\":\"https://api.github.com/users/warrenbuckley/orgs\",\n      \"repos_url\":\"https://api.github.com/users/warrenbuckley/repos\",\n      \"events_url\":\"https://api.github.com/users/warrenbuckley/events{/privacy}\",\n      \"received_events_url\":\"https://api.github.com/users/warrenbuckley/received_events\",\n      \"type\":\"User\",\n      \"site_admin\":false\n   }\n}\nLooking at the list of payloads, I don't recognize this one. Notice the first property is \"zen\" which makes me think you've configured the \"Ping Webhook\" to call this URL.\n. > OK I will check & verify by triggering a real PR on the repo to see what happens & what data I get & post back here shortly.\nYeah, maybe you're getting more than one request calling that URL or something and you're breaking into the one that fails, but not the one that succeeds.\n. Ok, we're making progress here.\nTry replacing this line where you use JSON.NET:\ncsharp\nvar payload = JsonConvert.DeserializeObject<PullRequestEventPayload>(payloadString);\nWith this:\ncsharp\nnew Octokit.Internal.SimpleJsonSerializer().Deserialize<PullRequestEventPayload>(payloadString);\nAlso, post the formatted JSON you're receiving here if that doesn't work.\n. > Agreed. As a workaround, I'd love to see if we can tweak the default model binders so that they can deserialize Octokit types properly.\nHow so? Like contribute it back to ASP.NET MVC? That wouldn't help the legions of people on the current version.\nOr were you thinking we'd provide a method to register a model binder? I feel like that adds too much friction. I think the easiest solution is to change those setters to public and just tell people \"don't mutate this shit.\" :frowning: \n. > Nah, was more thinking about a custom model binder. Anyway, the \"don't mutate this shit\" is a reasonable alternative if we have to go down that path...\nI thought of that too, but it's unnecessary friction. And it only solves the issue for one framework. I don't know how Nancy or other web frameworks do it.\nWe can limit this change to just the types that are web hook payloads. All the other types are responses to requests initiated by a a call via the Octokit clients. But these webhook payloads are different. They're callbacks that will be received by arbitrary code so we should put fewer restraints on them.\n. @shiftkey Hmm, should we simply omit \"since=\" if the value is MinValue?\n. :sparkles:\n. > Are you trying to use it on .NET Core (dnxcore)?\nI haven't tried this yet, but we'd like to make sure it works on this platform. Any tips?\n. :+1: to the idea.\n. > Can an OauthTokenRequest constructor be added that takes all parameters as SecureStrings (System.Security.SecureString) instead of just normal strings?\nHmm, as I think about it more, help me understand why you'd want this? After all, the information in the token request is going to be sent as part of the HTTP request. So if you're trying to hide it from the caller, they can just use Fiddler to see the information.\n. I feel like this provides a false sense of security. Convince me otherwise. :smile:\n. This is looking pretty good. Anything needing specific review?\n. @shiftkey should I merge this?\n. :sparkles: all around.\n. Interesting. Could you post a Fiddler trace?\n. And just to clarify, if you make this request to a different repository that does have commits, it returns just fine with no error?\n. Ok, I have a repro myself and I'm working on a fix.\n. :+1: on this. Is our CI having an issue?\n. > If I re-purpose the existing RateLimit model then any consumer code doesn't need to handle the (logically) same data twice\nYeah, I don't think we're likely to change RateLimit in any way that would change them in one place, but not the other. As far as I can tell, they're the same type in the back-end. So I think re-using RateLimit and not introducing a new type is the way to go. :smile:\nThanks for the contribution!\n. Thanks for your contribution!\n\n. > Surely there must be a \"thumbs up\" accreditation section somewhere in Linkedin .... off to go look\nLOL! It's a GitHub special accreditation. Much better than LinkedIn.\n. Try calling ConfigureAwait(false) like this:\nvar user = await github.User.Get(\"half-ogre\").ConfigureAwait(false);\n. Hmm, it's unclear to me why this would not work in VS2013 but work in your unit test context. Have you run a Fiddler trace to make sure the request is going out?\n. Looks good. The title suggests this is a WIP. Is that still the case or is this good to merge?\n. @Red-Folder No problem! Thanks for continuing to work on this and good luck finding a new job!\n. Thanks!\n\n. Rather than accepting a null value, I wonder if we should have a special value. For example, we could have a static ApiConnection.EmptyBody property that's just an empty object and use that for cases when you're supposed to pass in an empty body. I try and avoid overloading null like this because it's hard to determine if you passed null as a mistake or intentionally.\nAlso, what happens if you just pass in new object() right now as the data argument. Does that do the right thing today?\n. I think @shiftkey misunderstood the question. If I understand correctly, you want to create a personal access token with a specific scope using Octokit.\nThat is possible using the authorizations API.\nIn Octokit, you'd do something like this:\ncsharp\nvar github = new GitHubClient(new ProductHeaderValue(\"MyAmazingApp\"));\nvar newAuthorization = new NewAuthorization(\"Notes for this\", new [] { \"public_repo\" });\nvar authorization = await github.Authorization.Create(client, clientSecret, newAuthorization);\nConsole.WriteLine(user.Followers + \" folks love the half ogre!\");\nThat creates an authorization with the scope that...\n\nGrants read/write access to code, commit statuses, collaborators, and deployment statuses for public repositories and organizations. Also required for starring public repositories.\n\nThe list of scopes is located here: https://developer.github.com/v3/oauth/#scopes\nI don't see one that limits scope to just viewing pull requests.\n. Ah, I misunderstood too! So the code I showed creates an Application Authorization. It's an OAuth token that authorizes an application to perform actions. You can see these listed here: https://github.com/settings/applications\nIf you require a Personal Access Token (listed here https://github.com/settings/tokens) then you'll need to go through the Web Flow as @shiftkey mentioned.\nSince that flow is an OAuth token exchange workflow, there's really not a good way for Octokit to just handle it for you.\nWe could probably implement some libraries for WPF apps to initiate the web flow at some point. I think that'd be a nice to have and would at least make this much simpler for people to implement.\n. > @Haacked honestly, I'm looking to do this with client-side automation so these would be in a command-line or powershell environment.\nOh, in that case why would you need to create an access token? After all, you have a chicken and egg problem here. Your script, in order to create a token, would need some credentials to have the authorization to create the token.\nSo instead of giving your script a username and password, manually create an authorization token once, and give that to your script.\nPerhaps I'm missing something.\n\nRight now I'm looking at hitting http://api.github.com/v3/authorization, catching a failure, look at the header for 2fa failure codes, and then asking for the 2fa bit. In theory, with that - I should be able to acquire a token, store it, and reuse it as needed.\n\nYep, that's about right.\nIn Octokit.Reactive we have a GetOrCreateApplicationAuthentication method that handles part of this flow for you. You can pass in a Func that gets called if the initial request fails because of a 2fa error.\nWe don't have a Task based version yet, but I'd love to add one at some point. That code was pretty much pulled from GitHub for Windows which is all Rx based.\n. > it requires the end user to have access to VS2015 to build it...\nIt does? I tried to avoid using any new C# features. What did I do wrong?\n. @shiftkey nope. You might have seen my github/VisualStudio PR. Note that there's no way this would be green if I used C# 6 features, right?\n. @shiftkey can this be merged?\n. I'm ok with either making it public or maybe adding a method to read it as a binary stream/array.\n. @shiftkey you ok with this?\n. >  I noticed in the API that there is a download link for each asset. However, while I could use that if necessary I'd like to be able to read the raw file so that I can display the information on the project website.\nOn IGitHubClient there's a Connection property. You can use that for making arbitrary requests. If the content is HTML, you can call GetHtml. If the content is binary, you might want to use System.Net.HttpClient directly as Octokit isn't designed for requesting arbitrary binary files.\n. The default implementation of ToString for most objects is to return the type name. So what you're seeing is the type name of the response object which is ApiResponse<string>.\nThat type has a Body property. You need to look at that.\nSo in DownloadReleaseNotes change that last line with the return statement to return the body:\ncsharp\nreturn response.Body;\n. \n. I commented on the PR.\n. Flawless Victory\n\n. Hmm, the build failure is unrelated to this code change. Also, that test works on my machine. /cc @shiftkey. I'll merge this change and we can look into that test failure separately.\nThanks @Eilon!\n. \n. I'll fix it up.\n. @naveensrinivasan go for it!\n. I assigned myself so nobody takes it. But go ahead and work on it @naveensrinivasan \n. :sparkles: Thanks!\nGitHub Selfie is broken for me so I'll give you an oldie.\n\n. \nGreat work @shiftkey! So excited to see the fast turnaround on this release. :smile:\n. Thanks for your contribution!\n\n. This is now live on NuGet as of version 0.16.0!\n. Interesting. Want to help us do all that?\n. Done! I'll let you know when I get it approved.\n. @naveensrinivasan ok, I have the subscription, but not sure what I need to do next.\n. Hey @naveensrinivasan do you happen to have time to review this PR for me?\n. Thanks!\n. This is now live on NuGet as of version 0.16.0!\n. Doh! Seems like low hanging fruit. Interested in sending a PR?\n. I think @adamralph was already planning to.\n. Great bug report @forki and great bug explanation @naveensrinivasan!\nAre either of you interested in providing a PR to fix it?\n. Excellent!\n. :cool: Did you test this out?\n. > Yes, I checked in the test before the actual fix that was causing the CI to fail the build.\nOk, I just wanted to make sure you actually tested the Upload to Releases with this fix.\n. \n. Thanks!!!\n. > It's blocking the whole F# ecosystem at the moment\nYikes! I'll try and get a release out soon.\n. @forki cool, got a sec to sanity check the release notes here? https://github.com/octokit/octokit.net/pull/898\n. This is now live on NuGet as of version 0.16.0!\n. Hmm, I don't see it either. Perhaps @pengwynn would know.\n. Guess what?! There's [a way to lock issues via the API now! It's in preview mode, but if someone wants to tackle it, that would be great!\n. \n. This is now live on NuGet as of version 0.16.0!\n. @forki could you do me a favor? Pull down this branch and run .\\build.cmd CreatePackages\nIt's failing for me. :frowning: \n. @forki have a great trip! Who will fix the F# ecosystem in your place once we get these packages published?\n. Thanks!\n. Flawless victory!\n\n. Thanks!\n\n. The failure doesn't seem to be related to your change. I'm rebuilding to see if it'll pass this time. We need to figure out why that test fails sometimes.\n. Thanks! Flawless victory!\n\n. > Why not use octokit to release to github?\nWe just haven't gotten around to it. But if you want to set that up, I'd be eternally grateful.\n. :+1: \n. That looks like a legit failure. We have some unit tests that check that models follow our conventions.\n. > Thanks fixed that!. It is failing again in the StopsMakingNewRequestsWhenTakeIsFulfilled\nI restarted the build. I haven't had time to look into why that test fails sometimes. It's worrying.\n. Looks good to me!\n. Thanks!\n\n. Looks good! Feel free to continue.\n. Looks good! :sparkles:\n. @eilon do eeet!\n. Since @shiftkey is on vacation and these are mostly XML comment changes, I'm going to YOLO merge this. Feel free to review later!\n. /cc @willsb wanted to make sure you saw this change.\n. > My bad, didn't know about this one. But why was GitHubCommit changed back to use Author instead of Committer? (that was the initial issue)\nBecause according to the docs here, the author and committer for a GitHubCommit correspond to a GitHub account (aka Author).\nThe commit property of GitHubCommit also has author and committer but those correspond to Committer.\nI think the confusion stems from the fact that the API returns GitHub objects as well as Git objects and Octokit.net has confused the two in some places.\nA Committer is the minimal signature that a Git commit contains {'name', 'email', 'date'}. GitHub will try to associate a committer (and author) of a Git commit to a GitHub account. It can't always do that and now that I think about it, I'm not sure what it responds when it can't.\n. I commented on the original issue\n. > Currently there are 2 constructors, one that takes the required (name, config and url) parameters and defaults the optional (contentType, secret and insecureSsl) parameters and one that takes all parameters.\nFunny you should mention this. I just submitted a PR that includes some guidelines around our model objects. https://github.com/octokit/octokit.net/blob/consolidate-committer-info/Octokit/Models/README.md\nFor request objects (such as this), I think optional parameters should simply be read/write properties and required parameters are read only and go in the constructor. Does that make sense?\n. > I've no idea if this is also required for netcore45. I tried it out in a sample netcore45 project but the whole notion of referencing framework assemblies explicitly doesn't even seem to exist there.\nHey @Eilon! Got any suggestions about this?\n. \n. > Are you talking nullable or present? Is there more or less pain for a field to be present and null vs absent altogether?\nThey're more or less equivalent in our case.\nThe situation I'm thinking about is there are cases where the concrete type might have an int property that can be missing or null, in which case it needs to be a Nullable<int> property. But there may be other API endpoints where that same property cannot be null and I'd like to have the property be an int that cannot be null. I might run into problems implementing that interface with the same concrete type. \n. :sparkles:\n. Ok, the fact that it always says gitignore_template at the beginning of the string appears to be a bug in our API. Let's not rely on the bug behavior.\n. Use the EndsWith. It'll be future proof. Hopefully.\n. :+1: \n. I vote for Gitter simply because github/VisualStudio is already there and I want to avoid a million different chat systems. :stuck_out_tongue: \n. https://gitter.im/octokit/octokit.net\nDONE!\n. :thumbsup:\n. \n. Could you use Fiddler2 to post the request and response you get? Be sure to remove the line of the request header that contains your authorization token. It's the line that starts with \"Authorization:\".\n. @pengwynn do you have any ideas on this?\n. > IMO we should move the SourceLink , CreateOctokitPackage, CreateOctokitReactivePackage\n\nhttps://github.com/octokit/octokit.net/blob/master/build.fsx#L114-181 to the new deploy.fsx and then we could sourcelink and publish the nuget package as part of deploying.\n\nSounds good to me.\n. Closed by #976\n. This PR appears to be abandoned. I'm opening up a new one #970 to supersede this one.\n. If someone wants to submit a PR for it, we'd accept it. :smile:\n. Hi @chenjiaming93 \nYou just need to run the following command locally and then commit the changes.\n.\\build FixProjects\nIt's all described in our CONTRIBUTING document.\n. Awww yeah!\n. Be careful with --force. It rewrites history on the server. It's probably fine in this case, but if you ever do it to master on a shared project, you'll be making a lot of people unhappy. :smile:\n. Nice! I know @Eilon was just asking me if we could switch Octokit.net to VS 2015. I think he even offered to help. \ud83d\ude1b \n. I would set the doc warnings as warnings and not errors and assign it to me to fix later.\n. What if we name these GetAllContentsByRef and GetAllContentsByPath?\n. :bread: Back to you.\n. Hmm, @naveensrinivasan, the branch still has conflicts that need to be resolved.\n. I don't believe there's any way to do that. Why can't you provide the client id and secret?\n. > Not sure why I closed this, would still like to see the aforementioned API implemented eventually :)\nUnfortunately, this is not the repository to log that request. I think an API that doesn't require those things and doesn't use the Web Flow would have major security concerns. You could email support@github.com to make such a request and provide more context on what goals you're trying to accomplish.\n. > only for the library to support that API call to create a personal access token.\nHmm, I'm confused. Do you want the library to support the web flow? If the web API doesn't have an endpoint for us to create an authorization token without the client secret, how would we implement that in the client library.\n. Ah! Got it. Want to submit a pull request implementing that change? I think we just need to add an overload to AuthorizationsClient.\n. @ryangribble I would love it if you completed the PR. There's a couple ways to do it.\n- Fork octokit/octokit.net, check out the remove-merged-property branch in your fork, make the necessary changes, and create a new PR that targets the remove-merged-property branch.\nAlternatively,\n- Fork octokit/octokit.net, check out the remove-merged-property branch in your fork, make the necessary changes, and create a new PR that targets the master branch, and I'll close this one.\n. I'm hesitant to take this because SimpleJson.cs is a dependency we pull in from NuGet. Have you tried the latest version to see if it already has a fix?\nIf not, could you submit a PR upstream to https://github.com/facebook-csharp-sdk/simple-json?\nI worry that the next time we upgrade, we'll break this. At least the unit test will catch it though. :smile:\n. Ok, as long as the PR is upstream, I'll take this one.\n. > IMO the nuget package using appevyor should be from the main instread for all the PR's disable_publish_on_pr: true this would make the consumers point an use the latest stable version of the main instead of waiting for the release.\n:thumbsup:\n. I changed the feed to https://ci.appveyor.com/nuget/octokit-net.\n. Thanks @naveensrinivasan!\n. > Do you want to publish on PR's disable_publish_on_pr: true ?\nNope.\n. Although, I can see the benefit of that setting for testing. Until someone asks for it, I'll leave everything the way it is.\n. I think we should just show the Response payload. It'll omit the fields that don't exist.\n. @asizikov Yeah, if that's easy. @shiftkey what do you think?\n. Happy New Year! @chenjiaming93 were you still planning to add integration tests?\n. Closing in favor of #982\n. A few comments.\n``` csharp\nvar info = new ClientInfo\n{\n    AppName = \"my-cool-app\",\n    Credentials = new Credentials(\"my-token\"),\n    Server = \"https://enterprise.my-work.com\",\n    UseDefaultProxy = true\n};\nvar http = HttpClientFactory.Create(info);\n```\nOne concern about this I forgot to bring up is that http here tends to be used as a singleton in many cases. And for the most part, that's fine. But ClientInfo is mutable here. Are we copying the values when we create the HTTP client?\nOtherwise, we could run into subtle race conditions and concurrency issues if people change the values of the ClientInfo instance after the fact.\n. Another comment, I think we need to enumerate a list of the type of settings people want globally vs per request to make sure this effort is worth doing as-is.\nFor example, as discussed in #985, Timeout to me seems like a per-request setting, though I'm OK with exposing a global DefaultTimeout property.\nAnother issue with the ClientInfo is by using properties to initialize it, we don't let the type system help people do the right thing by default.\nFor example, the reason we use ProductHeaderValue as a required ctor parameter today is because on the back end, the GitHub API requires a valid User Agent and getting the format for the user agent correct is actually trickier than one might expect.\nNow, we could have overloads that let people specify an AppName and we create the ProductHeaderValue instead. I'm fine with that.\n``` csharp\nvar info = new ClientInfo(new ProductHeaderValue(\"my-cool-app\", \"1.0\")\n{\n    Credentials = new Credentials(\"my-token\"),\n    Server = \"https://enterprise.my-work.com\",\n    UseDefaultProxy = true\n};\nor\nvar info = new ClientInfo(\"my-cool-app\")\n{\n    Credentials = new Credentials(\"my-token\"),\n    Server = \"https://enterprise.my-work.com\",\n    UseDefaultProxy = true\n};\n```\n. I think we could probably trim the constructors list down to...\ncsharp\npublic GitHubClient(ProductHeaderValue productInformation) { } \npublic GitHubClient(ProductHeaderValue productInformation, ICredentialStore credentialStore) { } \npublic GitHubClient(ProductHeaderValue productInformation, ICredentialStore credentialStore, Uri baseAddress) { } \npublic GitHubClient(ClientInfo info) { }\npublic GitHubClient(HttpClient httpClient) { }\nMy thinking is that given that ProductHeaderValue is that the only reason to specify a baseAddress is if you're calling GitHub Enterprise in which case, you must provide credentials. Thus the GitHubClient(ProductHeaderValue, Uri) is kind of pointless.\nTo make this even easier to use for one off scripts, we could even allow string overloads for product header where we would parse them and throw if they're invalid.\nFor example:\ncsharp\nvar client = new GitHubClient(\"Haackinator\");\nor\nvar client = new GitHubClient(\"Haackinator/3000\");\nThough I like that the ProductHeaderValue argument makes it impossible to get wrong, and this has the potential to throw exceptions.\n. I didn't even know this was here or what it did. :stuck_out_tongue: \n. Nice! Maybe a next step would be to have the script use Octokit.net to help you create the test accounts if you don't have them!\nNerd snipe\n. > Not possible through the API :(\n\nDarn.\n. The potential for abuse is high for github.com. We get enough spammer accounts without making it even easier to automate. :)\n. :sparkles: Really nicely done @shiftkey!\n\n. Nicely done! The only issue I had is with the white space formatting.\n. > Thank you guys!\nNo! THANK YOU HENRIK! :smile:\n. :kimono: \n. Does that deploy NuGet packages on every merge to master? I'd like to avoid that. I was trying to set it up so it would only deploy from a branch named \"release\" when we tag that release.\n. @alfhenrik Yeah. Further down on that page, you can also Build on Tags (GitHub only). I set that up in our appveyor, but it didn't seem to work. However, it's possible I did something wrong.\n. > but it looks like webhooks weren't being delivered over the weekend\nI had set the octokit/octokit.net webhook to only send push because someone suggested that solved the problem for them including pull requests and avoids the triple build issue. But it just occurred to me that might only work for pull requests pushed to this repository and not for pull requests pushed to a fork of this repository. So I changed the webhook just not to also send pull requests.\n. @shiftkey so did you change octokit/octokit.net's webhook to point to the new one?\n. It looks like it. :sparkles: Nice work!\n. @ryangribble Interesting. I think there are two potential ideal solutions.\n1. If GitHub gave more granularity in Webhooks when sending pushes to build. You could contact https://github.com/c and suggest that.\n2. If AppVeyor gave us more options to control which branch of a pull request gets built. This is similar to your intermediary service suggestion. @FeodorFitsner is pretty responsive and might be willing to consider that change. :smile:\n. > create a new key in the test might be a bit challenging to do\nWhy is that? My brain had a core dump and I don't retain any context at all about this code path. :stuck_out_tongue: \n. Sounds good to me. @shiftkey?\n. > I stumbled upon it a while ago but got sad at the fact it wasn't OSS. I also have some reservations about the licensing of the components (having been bitten by this in the past) but let's see what comes up.\nAh, that could be problematic.\n. LOL! Thanks!\n. > I updated master head with the new commit so that the PR is not mergeable (not sure if it's the best way to do this.\nSeems reasonable to me.\nThe funny part is that this branch is also not mergeable and I got confused for a second about what you were making not mergeable. :stuck_out_tongue: Please fix up this branch so we can merge it in. Thanks!\n. Looks good to me!\n\n. > Yep, so after some digging I found the specific error was when trying to add a label to a repo with credentials that didn't have write access to that repo.\nSo is the issue you want a specific exception?\nA lot of our API endpoints return 404 to avoid information disclosure. So we can't tell you that it's an access denied necessarily. We could give an exception specific to the action such as RepoLabelFailedException. But I'm not sure that's all that valuable. You kind of know what you were doing, right?\n. > Just a more specific message.\nKids these days. Always asking for useful relevant information in exception messages. IN MY DAY WE GOT \"Unexpected error occurred\" AND WE WERE GRATEFUL AN EXCEPTION EVEN OCCURRED!\n:stuck_out_tongue: \n. Oh boy. So our convention is something that we can't currently capture with R# rules today (afaik).\n- Do use String when calling static methods of System.String.\nex: String.Format(...)\n- Do use string when specifying a type such as the return type of a method, an argument, a field, a property.\nex: void DoStuff(string foo);\n. > What about new string?\nDo we do that anywhere? :stuck_out_tongue:\nThe general principle I have in my head is that when we're using System.String like a primitive, we use the C# shorthand syntax. Hence string for return types, etc.\nWhen we use it like a type, I like it to look like a type. Hence String.Format, String.Empty, etc.\nHence I'd prefer new String() or new Int32() over new string() and new int(). Anyone know if we can configure R# or VS rules to follow that convention? Or am I being too picky?\n. I wrote a blog post about the convention. I'm seriously considering changing my mind given that the corefx team has their guidelines and to be quite honest, I hate fighting defaults and I hate arguing every single convention.\nI'd rather have a one-time argument where we decide on a set of conventions someone else maintains and when people complain about any given convention, we tell them to take it up with the dotnet team. :stuck_out_tongue: \n. > I can reopen the PR if you so desire\nSure. I'd love to hear @shiftkey's thoughts on this.\n. \n. This doesn't change any of the API return types yet. I just wanted to take a baby step here. The next step will probably be to define interfaces.\n. The reason I like the suffix is it makes it easier to find the set of related types when using intellisense or looking at the directory structure. For example, if you start typing Account you'll see all the types starting with that. I'm not too attached though.\n. I don't have time to follow-up on this anymore and you're right, it's not worth the effort.. :+1: \n. :+1: \n. Thanks!\n. Looks good to me. Thanks!\n. I like where this is headed! I agree with the naming suggestions @shiftkey proposed.\n. > Do you need that empty commit rebased out?\nYes please. :smile:\n. Nicely done! Thanks a lot! :+1: \n. I dig it.\n:+1: \n. Thanks!\n. This is a great start. Might be nice to show an example of creating an issue. Also, what happens if you call Add(\"some-label\"); where some-label is not an existing issue. I assume it fails.\n. I'll merge this in, but it would be great to expand on it. Thanks!\n. BTW, you don't have to create a new PR. You can always force push to the existing PR branch.\n. Looks good! Not sure why the travis build is failing. Clicking on the Details link takes me to a place where I can't see the actual build output or reason for failure. /cc @shiftkey @naveensrinivasan \n. :thumbsup:\n. Hi @M-Zuber, we're using NSubstitute.\nBut I'm confused by what you wrote. Are you saying that if you pass something other than null you get a test failure? Or if you omit that last argument?\nAlso, connection.Get returns a Task so you need to set up that return value.\n. The only downside is that if you implement the interface, you only need to implement the one Get method and you know the extension method is implemented correctly with regard to that one method. Now, implementers have to implement both and implement them correctly.\nHaving said that, this really does clean up the tests and API and reduces pain and it's a really really simple method so I'm :+1: \n. Hmm, looks like RepositoryPagesClientTests is failing but that's unrelated to this change. @shiftkey known issue?\n. @paladique you could merge master into your branch and push. Or, if you're feeling adventurous, rebase your branch against master and force push to this branch.\n. \n. I think that exception message tells you everything you need to know:\n\nMust have push access to view repository collaborators.\n\nSo unless you have push access to the repository (octokit/octokit.net), you can't view repository collaborators. Try changing the call to a repository that you have access to (such as one of your own) and see if the call succeeds.\n. Thanks! :sparkles:\n. We should try and get something out soonish. :smile:\n. Self merge FTW! This PR appeals to my OCD nature. :sparkles:\n. Nice catch!\n. We should do a Roslyn analyzer to not allow absolute Uri in Octokit.net since I can't think of any place where they would be allowed. We can always suppress in those cases where they're necessary.\n(attempted nerd snipe)\n. That's a helper class for when you're implementing a server side web hook target. For example, on gtihub.com you can configure a repository to request a URL every time a new repository is created.\nWell, now you need to implement that endpoint. If you happen to be using ASP.NET MVC for example, you could add an action method that accepts this class (and use the JSON model binder) and receive the payload.\nWe should document this better. Or consider moving to its own library.\n. Thanks! :sparkles:\n. @ryangribble That would be nice. So basically if the file isn't on disk, remove it? I'd love that.\n. Which reminds me, I started a project called ProjectCop that could handle this. Someday I'll ship it.\n. :sparkles: Flawless Victory! :sparkles:\nThis looks great! The only comment I have is that if we add new targets, we'll have to add more methods to this class. We could consider adding a method that takes in a raw target string, but I don't think we need to do that now. Maybe this API very rarely changes.\n\n. > Yeah we had a bit of discussion on the issue #1026 about which way to go and ended up with the multiple methods.\nAh, cool. Yeah, I like it. I'm just thinking about adding one additional method as a failsafe. But I don't want to do that yet.\n\nThanks for merging!\n\nThanks for contributing!\n. > What would the failsafe be, out of interest?\nA method that took a target request object (or string). That way, if Enterprise ever added a new target string syntax, you wouldn't have to wait for the next Octokit.net to start calling it.\n. > I am new to this open source work that's why i am little afraid for now.\nWelcome!\nWe're all friendly here. We love having people help out in any way they see fit. We all have other responsibilities because of our work, so we can be slow to reply sometimes. But don't hesitate to ask questions. We want your first open source experience to be great so maybe you'll contribute again! :smile:\n. Well done!\n\n. > @Haacked is it really you in the gif?\nYup!\n. Where should I put the documentation? In the README?\n. It requests the one unathenticated endpoint in a GitHub Enterprise instance.\n. Hey @niik would like your input here. I relaxed the check based on some comments from @shana. I'd like to use this method in both Desktop and GHfVS so we're consistent.\nBasically, we check the response for a couple headers even if the request gets thrown an ApiException.\n. gitHub.Enterprise.Probe.Probe(new Uri(\"enterpriseBaseUrl\"));\nThat Probe.Probe looks awkward. It's not helped by the fact that Probe is both a noun and a verb. What do you think about changing the method name to Examine since that's what a probe does.\ngitHub.Enterprise.Probe.Examine(new Uri(\"enterpriseBaseUrl\"));\n. Another thought, we could simply put the Probe method on Enterprise.\ngithub.Enterprise.Probe(new Uri(...));\n. I kind of like that latter approach better to be honest, but would like to hear others thoughts.\n. @shana I like that approach.\n. One thought that just occurred to me. The reason why it's an \"Enterprise Probe\" today is that there's no need to probe if the base URL is \"github.com\" or \"api.github.com\". We can just assume it's GitHub.com the website and not something else.\nHowever, I could imagine someone wanting to probe for capabilities in the future, in which this API could be the starting point for that.\n. Ok, trying to get this back on track, I'm cool with the original suggestion you had @shana. Especially since you offered to do it. :stuck_out_tongue: \n. Sure!\n. > Is there room to consider creating a wrapper for this?\nYes! Probably should be an extension method. That would be a good way to indicate that this is a wrapper and not a 1-1 mapping with an API call.\n\nIf so, is there also a way to cut down on the calls? Or would it just be for the users convenience?\n\nNot that I know of. It would be a nice convenience method.\n. In the Octokit project we have a Helpers directory. You'll notice we have extension classes in there. For example, in this case, perhaps call it a ReferenceClientExtensions or ReferenceExtensions or something like that.\n. > OK I have renamed to LdapDistinguishedName and used the Parameter(Key = \"ldap_dn\")] attribute to set the API field name, how does it look now?\nAnd that worked?\n. > @shiftkey He probably bumped into the same problem I had - every single project in the solution that references Octokit suddenly wanted to have the Bcl, Bcl.Build and Http packages added to them, which amounts to a ton of build errors and quite a bit of changes. OTOH, removing this extraneous .targets reference was so much simpler...\nYeah, and I don't think we need those anymore, do we? We can choose to not support the platforms that required them. :smile:\n. Yeah, that looks like an oversight on our part. It think we should add an overload that accepts an enum with the available permission options.\n. Want to submit a PR?\n. > Please accept my apologies\nLOLOLOL! No apologies necessary. You're usually correct. I happen to be taking a break to try and respond to all the OSS projects I maintain so the timing was lucky.\n. @ryangribble you're exactly right, it should be a request object. I was being lazy with my words. :smile:\n. Looking good! One minor question.\n.  Thanks!\n. > Unless there was some intention that this helper method was exposed to octokit consumers to do stuff with. It's pretty basic anyway, not sure if there would be a real world use case. @Haacked ?\nWe use these extension methods in GitHub Desktop. I'd like to keep them, but :+1: to renaming it from ModelExtensions to something more specific. I think the intent was we'd have more extension methods for working with models, but so far, we don't. :smile:\n. > or do you really want it to be an extension method on PublicKey itself?\nI think the benefit of the extension methods is it made the helper class more discoverable. As you pointed out, the helper class is not a response class so most users of Octokit.net won't know it exists.\nHowever, I don't feel too strongly either way, so whatever you feel is the best design here.\n. > This is built on top of #1108 which is not yet merged\nUmm, this is 1108. :stuck_out_tongue: \n. \n. IEqualityComparer makes sense to me. IComparable is more for sorting items. Doesn't seem like a thing you'd do with response objects.\n. > I pushed up the final change\nThe description still says \"Do not merge!\" :laughing: \n. @ryangribble after looking into it, we only use HasSameDataAs. Let's drop the extension methods and I'll just move them into our own code.\n. :shipit:\n. \n. So the behavior you see is exactly what I'd expect because the API doesn't stream the response to us. What happens is we request page 1, when we get the response, we stream them to the subscriber and make request 2. When that request returns, we stream page 2 and make the request for page 3.\nNotice that each timed chunk is 30 results. That's exactly the default page size.\n. > the delay looked like the cumulative time spent fetching those requests\nIf that were the case, we'd see a really long delay followed by every item being printed with nearly the same timestamp. Instead, we're seeing timestamps chunked in groups of 30.\n. Martin Fowler has a great post about using mocks and stubs. http://www.martinfowler.com/articles/mocksArentStubs.html\nIn general, I prefer state based testing over interaction testing. With Octokit.net, sometimes that's really difficult by the nature of what we're doing.\nBut in this case, I'd be fine with passing the actual seralizer because it's return value is deterministic. However, I'm also fine with the format that @ryangribble and @shiftkey proposed.\n. :+1: \n. :+1: to all of this.\n. > That's kind of how I feel about the upcoming pagination PRs - having a separate entry for each PR feels noisy, and I'd rather roll it all up into one item to summarize.\nAgreed.\nAlso, I think we should only look at PRs for release notes comments. It'll reduce the number of times we might have double notes (issue and associated PR) and it keeps us in the discipline of always submitting a PR for changes.\nI don't think we need to worry about \"trusted\" authors. Instead, when we review a PR that should have a release note, we can simply edit any comment that has the release note to fit what we want. In fact, the release note should be part of the review and we should encourage PR submitters to try and articulate what the note should be and then we can edit it if it needs editing.\nBTW, I :heart: where this is going. When we come up with something good here, I'll want to use it on every OSS project I'm on. :smile:\n. :sparkles: I'm excited to see this added. We want to signal to people that they are welcome to contribute and that we care about having an inclusive welcoming environment for all contributors.\n. @shiftkey should the email address be support@github.com?\n. > @Haacked I'd love it to be more specific than that, so that it goes directly to the right people\nPlease don't make it go just to me. :stuck_out_tongue: What did you have in mind?\n. \ud83c\udf89 . I would love to remove all namespaces from unit and integration tests. They really don't serve a purpose for our tests. Namespaces are useful for libraries that you reference in order to disambiguate class names. But you never reference a set of unit tests for your own code. At least, we don't need to support that if you do for some wild reason. :stuck_out_tongue: \n. Split it up. I worry that one big fat PR will cause problems for everybody else. :)\n. In general, each of these should be individual pull requests. However, in this case, the PR is small enough I'll allow it. :smile: I'll let @shiftkey take a look and merge it.\n. > I have some reservations about the SimpleJson changes, mostly due to that file being an external dependency we pull in. Are you able to revert that change?\nGood catch! Yes, we don't want to change that file. That breaks NuGet's ability to detect if there are any changes or not when upgrading the package.\n. @devkhan the link @shiftkey provides points out some of the potential compatibility issues with optional arguments. They were designed for COM interop, not for public APIs.\ncsharp\npublic Task<IReadOnlyList<Release>> GetAll(string owner, string name, ApiOptions options);\npublic Task<IReadOnlyList<Release>> GetAll(string owner, string name);\nAnother benefit of having overloads is with the optional parameter approach you can't distinguish between the case where the user passed in a null value explicitly by mistake, or if they left it out.\nFor example, the following is a mistake and should throw an ArgumentNullException. Clearly the programmer made a mistake.\ncsharp\nApiOptions options = null;\nclient.GetAll(\"foo\", \"bar\", options);\nThey either should set options to something, or just omit that argument. Having two overloads makes that clear.\ncsharp\nclient.GetAll(\"foo\", \"bar\", null); // Throws ArgumentNullException\nclient.GetAll(\"foo\", \"bar\"); // Just fine. Programmer's intentions are clear.\n. > nostalgic due to my C++ experience\nHeh. I've never had the experience of being nostalgic for C++. :wink:\nI was glad to move on. Out of curiosity, what about C++ makes the optional parameters different?\n. Thanks! In general I'd rather we just clean these up as we go along. Unused using statements don't hurt anything. Having said that, this definitely appeals to my OCD tendencies so I'll allow it just this once! :smile:.\n. These are definitely being used.\n. :heart: Ok, I made a comment on the Id thing. If you fix up the docs, I'll merge this if @shiftkey is :+1: on the code changes (I didn't really look at that).\n. Just a couple minor nits  on the release notes. Otherwise, this release is exciting!\n. \n. > do we want to make this available under GitHubClient?\nUnder the current design of the code, turns out to be not so easy. And you might not want the probe to use the same credentials registered with the GitHubClient anyways. We could try it the way it is for now and change it if we hear anything from people.\n\nis it worth writing up some docs around this? Even just a quick sample?\n\nSure!\n. @ryangribble @shiftkey I finally got around to adding the proposed ctor.\n. These test failures on Mono don't seem to be related to anything I've done. @shiftkey thoughts?\n. Ah, thanks for the info @ryangribble and thanks for merging @shiftkey!\n. One minor nit, otherwise :+1: to the release notes.\n. :tada:\n\n. \n. . The Git Credential Manager does not come into play here. Octokit.net is a library for making https calls to the GitHub API.\nThe fact that those calls failed during the 1 hour window where GitHub shut down support for TLS 1 and 1.1 tells me this is an issue with making the https calls.\n@Korporal @hgleaves-ncuadmin I suspect you are running on .NET 4.5. There are a few solutions.\n\nUpgrade to .Net 4.6+. It supports TLS 1.2 by default.\nThere's a registry hack to make your machine use TLS 1.2 by default, but search for it and use it at your own risk. \ud83d\udc80 \n\n@ryangribble we can make Octokit set TLS 1.2 by default by running the following code very early.\ncsharp\nServicePointManager.SecurityProtocol = SecurityProtocolType.Tls12;\nHope that helps!. TROLOLOLOL DOH!\n. Use Ensure.ArgumentNotNullOrEmptyString(userAgent, \"userAgent\");\n. This block is not needed if you use Ensure.ArgumentNotNullOrEmptyString above.\n. Also, if the user agent is incorrectly formatted, HttpClient will fail the request. Might be interesting to try and validate that here. But you don't need to for this PR.\n. We have a ConditionalAttribute we wrote for GHfW that's like this. Seems like it comes up a lot and might be useful to put in some common test library down the road. Nothing to do for now though.\n. Do any of our tests hit private repos or require configuring a user that must be a member of a specific org? I could see that being a problem down the road.\n. Eww trailing commas to nowhere. Ewwww..\n. So we do this on every 202 in GHfW seen here: https://github.com/github/Windows/commit/e716c4b32157475dbfcfd5147f7fd89c2d1ee031\n@niik any reason for that? Maybe in Octokit, we don't automatically retry and let the caller do it, but I'd like to get more background on this first.\n. ping @pengwynn. ^^^ Any thoughts on the above question?\n. Agreed. I was going to address that once I start re-implementing GHfW's handling of this using Octokit. But that's generally the approach I'm thinking. Perhaps those exceptions derive from this or we might simply add a property to this. I haven't really thought that through yet.\n. Good question! I was doing what we're doing in GHfW but after searching the code, it doesn't make sense. :) I thought we might be keying off the exception message but we're not.\n. For some reason, that rubs me the wrong way. If the server times out, we'll get a HttpStatusCode.RequestTimeout. If the task is cancelled, I think we probably shouldn't wrap that in an ApiException because it really wasn't an exception with the API. I think that implies the user cancelled the action (which we really don't allow just yet).\nAgain, I was just mimicing the existing code but I think this is a case where that's a bad idea. I'll fix it.\n. @spraints I'll look into this. This is the first time we've run into this situation so we just didn't create a way to easily override it just yet.\nFor the most part, we don't want callers to have to think about what accept to pass so we want to bake in the right defaults.\n. Thanks! Are there many cases where people would want to pass in a different media type?\n. Ensure.ArgumentNotNull(input, \"input\");\nI ported the Ensure class over here. :)\n. I like defensive programming. But out of curiosity, is this even possible?\n. Are there unit tests of this change in behavior?\n. I would like to use Fody. I just haven't gotten around to it.\n. This is the only API endpoint that does the 2FA challenge. We didn't want arbitrary requests sending SMS messages.\nNote that the consumer could handle 2FA on their own pretty much in the same we we do here. However it's a bit tricky to do right so I thought this would be a nice convenience method. This way, the user just needs to provide a callback to show whatever UI they need to show in order to collect the 2FA token.\n. Ah, right. I'll create a NewAuthorization and update AuthorizationUpdate. One thing I don't like is the asymmetry of those names. Should it be AuthorizationCreation instead of NewAuthorization. Or perhaps AuthorizationNew which is a little weird. :)\n. You could also say it's an \"updated authorization\" and a \"new authorization\".\n. Umm, yeah. That'd be awesome.\n. Yeah, I can make that change.\n. Fucking great catch! I have a test for that in GHfW against the Octokit.Reactive code, but no test for this against the Task based code. And sure enough, there's a bug. :)\n. Actually, are we sure we want to automatically re-prompt for a bad code? Or should we allow the caller to catch that and decide for themselves?\n. Ok, I looked at the GHfW code, and we throw when the user enters an invalid code. I think this is the right behavior. This makes it easy for the caller to decide to show the UI again or not.\n. Actually, I think it's true. Let me double check.\n. It defaults to true. I checked the code.\n. @half-ogre So I basically had to duplicate the endpoint here. The reason is we don't have a Task based method exposed that gets one page  of repositories. I'm not sure we should have such a thing exposed.\nSome ideas to make this better:\n1. Expose each endpoint url as a property of the IRepositoriesClient interface.\n2. Expose a GetPage method, but make it internal and exposed to Octokit.Internal.\n3. Expose GetPage method as protected and make this class inherit RepositoriesClient.\n4. Just not worry about it. Some duplication is fine.\n5. ???\n. @paulcbetts I'll buy you the finest beer if you can make this test pass. Basically, if someone uses Take on the observable, we want to stop the \"expansion\" once the Take is fulfilled.\n. So in some cases, it has to be a parameterized url so it can't be a Uri, but either has to be a UriTemplate if we expose it, or a method to get the Uri.\nI thought of another way to do this that doesn't expose anything new to the API and gives us time to think of another approach. I'll put the code to get the Uri for each endpoint in a shared and linked .cs file. That way they're compiled into both projects, but I don't have to deal with how to expose them in the API yet.\nSeems legit?\n. @half-ogre I'll do that.\n. Nevermind, I got it working.\n. NO BEER 4 U!\n. Sure. :)\n. So should we do this instead?\nvar httpOptions = new HttpClientHandler { AllowAutoRedirect = request.AllowAutoRedirect }\nif (httpOptions.SupportsAutomaticDecompression)\n{\n    httpOptions.AutomaticDecompression = DecompressionMethods.GZip | DecompressionMethods.Deflate;\n}\nWe want to make Octokit a cross-platform library eventually so this seems to make sense to play it safe.\n. Doh!\n. I was just about to merge. ;) I'll fix this.\n. What is this GUID? You just reusing them like they're going out of style?\n. Ah, I see. For a sec I thought you were adding new projects with the same GUId. Nevermind. :)\n. Thanks for doing this! So the pattern we're using is to have a flat observable stream of elements. With tasks, we can't do that because they can only return one thing.\nSee https://github.com/octokit/octokit.net/blob/master/Octokit.Reactive/Clients/ObservableSshKeysClient.cs#L33-L36 for an example of how we flatten this.\n. See my previous comment. This should return IObservable<User>\n. I'm not sure the parameters is needed. The nextPageUrl is returned as part of the previous page's response in the Link header. I would assume it would be a fully formed URL for retrieving the next page of results. See the pagination docs for the GitHub API for more details. Were you finding that this was not the case?\nThe accepts parameter, on the other hand, makes total sense!\n. we made a conscious decision to commit our packages to Git. If we want to change that, we should discuss that as part of a separate issue.\n. You'll need to revert this change too. :smile:\n. LOL.\n. Actually, don't we already apply the parameters to the URL before we call this? If we do that, we never need to worry about it here.\n. > This is our only chance to apply parameters - without passing them in here, they're not respected.\nAh right. Why'd you remove the accepts parameter? That seems like it should be necessary if we need to pass something other than the default. Or do we not need to do that here?\n\nknow of a public repo with more than a page worth of Milestones for testing purposes?\n\nI don't offhand. I suppose we could create one. We could have the integration test create one. By default, it's 30 a page.\n. Don't forget to doc comment this field. :smile:\n. I think this might need to be Id per our serialization rules.\n. How does this know to build the Release configuration? By default, isn't it the Debug?\n. Ah, so after I ran git clean -xdf the build failed. But it's because my VS is on a Debug configuration. When I changed VS to use a release config, it ran the tests.\n. Sorry to be very nitpicky, but this should be SetsChildClients since the ctor is singular. :smile:\n. :heart: the formatting here!\n. Please indent the Justification. If it wasn't indented elsewhere, then it's probably wrong there. R# has been doing funny things lately.\n. Revert this please as we discussed.\n. Remove the attribute and name the class GitTag unless someone comes up with a better name. :smile: An alternative could be TagReference\n. Revert this change as we discussed.\n. Rename this property to Tag\n. For string arguments, I also like to check empty strings.\nawait AssertEx.Throws<ArgumentException>(async () => await client.Get(\"\", \"name\", 1);\nawait AssertEx.Throws<ArgumentException>(async () => await client.Get(\"owner\", \"\", 1));\n. Maybe pick at least one property to assert.\nAssert.Equal(1, response.BodyAsObject.Id);\n. Wrong client. :stuck_out_tongue_winking_eye:  I think you meant new IssueCommentsClient(null);.\n. Doc comment please.\n. Doc comment please.\n. Please copy the doc comments from the IIssuesEventsClient interface over the implementations. Thanks!\n. Doc comment please.\n. Couldn't we replace Actor here with our existing User type and get rid of the Actor class?\n. Doc comment please.\n. This change will get lost when we upgrade SimpleJson. Please send a PR upstream. https://github.com/facebook-csharp-sdk/simple-json\n. I'm a little confused. How does putting this using on Connection fix things? Why only Connection and not any of the other classes?\n. Maybe add it to where the other TagClient tests are.\n. This line is very long. Can you concatenate strings so any given line isn't longer than 120 char?\n. no biggie. It's just to make it easier to review on GitHub.com. :smile:\n. \"no need for this. here.\"\n. No need for this. here or anywhere really. We only use this. when it's absolutely needed.\n. Ah shoot, this broke the unit tests. I should have been more careful in reviewing this. You can't use Local here. It should be UTC. Our build server is in a different time zone than you are. :)\n. If you do that, change the 14 to 13 to match your expected result.\n. A Task can only return a single result, it makes sense that the result of a task-based method would be a Task<IReadOnlyList<T>>. But here, we are in the powerful world of Reactive Extensions. An IObservable interface represents an asynchronous sequence of results and can support more than one. So this method should return an IObservable<IssueComment>\nFor an example of this, check out the milestones client.\n. See previous comment about IObservable\n. Yeah, let's leave this as-is. Your unit test will catch it if we ever lose this change because upstream doesn't take it.\n. Yeah. I'm fine with merging this now and removing it later when SimpleJson takes the change.\n. Why not just use Contains here? Also, an Ordinal comparison should be fine. Is there a casing for ??\n. Better to have Substring(1) here, right?\n. Though I do realize, if you did have unescaped question marks elsewhere, this would be invalid anyways.\n. Isn't there a StringSplitOptions or something you could use here?\n. PullRequestRequest hah! I guess that's a consequence of our current naming scheme. It's fiiiiine. I just had to comment as I LOL'd.\n. Looks like you fat-fingered an \"N\" here. :stuck_out_tongue: \n. Please get rid of the above three empty new lines.\n. Our ToParameterDictionary automatically converts property names to lower case. You only need to use the ParameterAttribute if you need to deviate from our default conventions. So it's safe to remove these attributes here.\n. Mind adding comments to these three properties?\n. Ah, I see. Yep.\n. Sad that if the URI is not an absolutel URI you can't still grab uri.Query. What a shitty API.\n. Getting happy with the Enter key here, eh? Just one newline between methods is fine. :smile: \n. Please also add this to the Octokit.Tests-NetCore45.csproj project.\n. If you're trying to have the summary be three paragraphs, you should use the <para> tag http://msdn.microsoft.com/en-us/library/x640hcd2(v=vs.110).aspx. New lines are ignored in XML.\nExample:\n<summary>\n<para>\nParagraph 1\n</para>\n<para>\nParagraph 2\n</para>\n</summary>\n. Remove empty line please.\n. See earlier comment on <para>\n. Remove newline.\n. So just my preference, but if I break up a line with a bunch of conditionals, I tend to go all or none. So I would put a newline just before the && here. :smile:\n. Please remove extra newline.\n. Please add this to Octokit-NetCore45.csproj\n. Please add this to Octokit-NetCore45.csproj\n. This can be made readonly\n. Hmm, I think this ought to be an enum but I'm not sure of the range of types we have. I don't think this field is open ended. /cc @pengwynn. Any thoughts here?\n. :thumbsup: \n. This url should be \"orgs/username/teams\". Also, instead of username try using orgName to be more descriptive.\n. rename client to connection and orgs to client :smile:\n. Name isn't clear to me. Perhaps, DoesNotChangePassedInDictionary.\n. The brace below really misses the code above and wants to be closer to it. Maybe get rid of this gulf of a newline that stands between the two.\n. Url should be a Uri, right?\n. Make Url a URI. I wonder if we should make Commit inherit GitReference. Hmm.\n. Why this name change? Tagger doesn't seem correct either. We already have a User class. Maybe this should be Identity? @half-ogre or @shiftkey any thoughts?\n. The expanse is so vast! Please mind the gaps. :stuck_out_tongue: \n. Sorry, I meant the type should be Uri and not string\n. > the class does help distinguish the role, even if it's the same data underneath\nWell the property name does that. By that logic, we shouldn't use string here but have a NameString class. :stuck_out_tongue: \nThese are core git concepts. They're unlikely to change much right? And if they do, then they'd all change.\nI think the real question is, are these actually the same type of thing or not as far as Git is concerned? I kind of think they are.\n. Actually, I think this should be an Organization. Note that sometimes the API examples don't show all possible fields. For example, if you are an owner of the repository, you might get extra fields depending on the object being returned.\n. Doc comment please.\n. Doc comment please.\n. If you merge with latest, you'll see I added a doc comment to the Member property. You can use that as an example for this.\n. I don't think this works for objects that are part of the body of the request. ParameterAttribute only works for query string parameter.\nI think we need to update our Json serializer to split PascalCased property names into names with underscores. That way we don't need any attribute here.\n. If the only thing we need from this is the status code, maybe we should make this return Task<HttpStatusCode>. That would give you exactly what you need without exposing more than we need to.\n. Please add the param comments.\n/// <param name=\"owner\">The owner of the repository</param>\n        /// <param name=\"name\">The name of the repository</param>\nAlso change the argument name repo to name to be consistent with our other methods. Thanks!\n. Please document the user param.\n/// <param name=\"user\">The login of the user</param>\n. Doc parameters please. :)\n. This method isn't defined on the IStarredClient interface. Is there a reason for that?\n. This should probably also be on the IStarredClient interface.\n. This should probably also be on the IStarredClient interface.\n. This should probably also be on the IStarredClient interface.\n. This should probably also be on the IStarredClient interface. Also, please document the method.\n. ArgumentNotNullOrEmptyString\n. Please document this method and make sure it's also defined on the IStarredClient interface.\n. ArgumentNotNullOrEmptyString\n. We do this pattern above several times. Might be good to encapsulate it in a method.\nreturn EnsureStatusIsNoContent(response.StatusCode);\n. I should have mentioned this earlier. Star should be a property of IActivitiesClient not IGitHubClient. We're trying to follow the structure that we have in the API docs: http://developer.github.com/v3/activity/starring/ So starring is a \"sub-client\" of Activities.\n. :thumbsup: \n. This new method RunForStatus seems overkill and unecessary. It essentially duplicates the code of Run\nInstead, why not just do this here:\nvar response = await Run<object>(new Request\n{\n    Method = HttpMethod.Delete,\n    BaseAddress = BaseAddress,\n    Endpoint = uri\n});\nreturn response.StatusCode;\n. Nah. On second thought I think the code is fine as is. :smile: \n. No need for this newline. The closing brace wants to be closer to his friend, the last method. :smile:\n. Hmm, could this be the result of a bad search and replace? Shouldn't this URL be orgs/{0}/teams?\n. Hmm, this looks wrong. I think the old test was still valid.\n. I think the way it was is still correct.\n. :thumbsup: \n. I sometimes just name the method EnsureArguments to keep it short. :)\n. And let's assert a little more than it's not null. :smile:\n. Perhaps we should add our own Range class and have Minimum and Maximum be nullable integers. That would enable >=500 by simply setting Minimum to 500 and Maximum null.\n. Please follow the Framework Design Guidelines for the enumeration names. These should be:\nGreaterThan\nLessThan\netc...\n. Note, the Range class could have some useful helper methods. For example,\nRange.Exactly(100) would be return new Range(minimum: 100, maximum: 100); Note that Range should probably be an immutable struct.\nRange.AtMost(100) would be new Range(minimum: null, maximum: 100);\nRange.AtLeast(100) would be new Range(minimum: 100, maximum: null);\n(Or maybe they should be GreaterThan and LessThan. Whatever.\n. This method shouldn't be directly on the IRepositoriesClient. Instead, we probably need a new IRepositoryContentsClient (and associated implementation) client.\nThis is a point of a lot of confusion so I just wrote up a note on the project structure that hopefully explains this.\n. Mind adding documentation comments to each of these properties?\n. Also, I think ResponseType can only be one of two types: File or Directory. Maybe we should make it an enum.\n. Actually, there's also submodule and symlink.\n. New lines are at a premium. We must do all we can to conserve  them. :stuck_out_tongue: \n. Oh boy. I just took a look at the API and if the contents is a directory, it returns an array of content files, not a single file. This is kind of tricky because we don't want to return an object here.\nNot sure why that returns an array for a directory to be honest.\n. > Should I rename the property to Type so that the JSON parser can map it to the property, but I think it will create a suppression message if I remember.\nYeah, name it Type. The suppression message should be added inline and not to the GlobalSuppressions file.\n. Hmm, let me find out more information about why this is the way it is.\nHey @pengwynn! I would have expected a directory to be a JSON object containing properties about the directory and a property containing an array of the files in the directory. Can you explain the rationale for the current approach? http://developer.github.com/v3/repos/contents/#get-contents\nBut this returns an array of what I assume are just the contents of the directory. Is that right?\n. This doesn't smell right to me. Methods should validate the arguments passed in, but not necessarily the properties of those arguments. If the Body of a comment should never be null or empty, then it's probably up to the PullRequestReviewCommentCreate to verify that, not every method that it's passed to. Are there cases where it's fine for Body to be null?\n. Related to my earlier comment, if Body should never be null, then let's make it a read only property and pass it into the constructor for this class. Then we can ensure it's not null or empty in the constructor.\n. Is this Parameter necessary? I thought we would do this transformation automatically.\n. Please remove this newline so it's clearer that the comment applies to the next three lines.\n. Need to double check that this can never be null. For example, is UpdatedAt set when an pull request is created but hasn't been edited yet? /cc @pengwynn what's the general pattern for updated_at in the API? I have a feeling it's not consistent everywhere.\n. I assume the search term should never be null or empty right? Perhaps add an Ensure.ArgumentNotNullOrEmptyString here.\n. Make the setter private since we pass this in the constructor.\n. Instead of making this nullable, I'd rather we just default it to Desc in the constructor. Nullable enums are kind of annoying. :)\n. Don't suppress this. Just pass CultureInfo.InvariantCulture into the ToString methods.\n. The above four lines could be condensed into:\nvar d = new Dictionary<string, string>{\n    { \"q\", Term },\n    { \"page\", Page.ToString(CultureInfo.InvariantCulture) },\n    { \"per_page\", PerPageToString(CultureInfo.InvariantCulture) },\n};\nBut is there any reason why we're not just using the ToParametersDictionary method here?\n. Probably should make this inherit the RequestParameters class so you get the ToParametersDictionary method for free.\n. Should probably inherit from RequestParameters See comment here: https://github.com/octokit/octokit.net/pull/226/files#r7878104\n. Heh heh. These comments add nothing. I think we can read. :stuck_out_tongue: \n. Probably clearer to name this LessThanOrEqualTo. That might get rid of the need to suppress this too.\n. GreaterThanOrEqualTo\n. Ensure term is not null or empty.\n. private set\n. Get rid of this method and use the ToParametersDictionary method instead.\n. Please don't suppress this one. For more details: http://haacked.com/archive/2010/08/10/versioning-issues-with-optional-arguments.aspx\nThe constructor should only have parameters that are required. The caller can set the properties of the object for all the optional fields. \n. Don't suppress this. The default format for ToString did change once. Best to be explicit.\n. At this point, add a using System.Diagnostics.CodeAnalysis; to the top of this file and shorten the attribute declarations. It's just noisy otherwise.\n. Are all these parameters required? \nIf so, we should ensure all of them are not null nor empty and make the properties read-only.\nIf not, then we don't need to pass them in the constructor since the properties can be set.\n. Might be nice to implement the Delete method so we can do proper cleanup of the gists we create in this test.\n. Don't suppress this. Just make the setter privater.\ncsharp\npublic IDictionary<string, string> Files { get; private set; }\nSince the dictionary is initialized in the constructor, there's no need to make it settable.\n. These private members are not necessary. The code is a bit cleaner if we use auto properties. Also, please move the constructor to be consistent with our other code. :smile:\n``` csharp\npublic class PullRequestReviewCommentCreate : RequestParameters\n{\n    /// \n    /// Creates a comment\n    /// \n    /// The text of the comment\n    /// The SHA of the commit to comment on\n    /// The relative path of the file to comment on\n    /// The line index in the diff to comment on\n    public PullRequestReviewCommentCreate(string body, string commitId, string path, int position)\n    {\n        Ensure.ArgumentNotNullOrEmptyString(body, \"body\");\n        Ensure.ArgumentNotNullOrEmptyString(commitId, \"commitId\");\n        Ensure.ArgumentNotNullOrEmptyString(path, \"path\");\n    Body = body;\n    CommitId = commitId;\n    Path = path;\n    Position = position;\n}\n\n/// <summary>\n/// The text of the comment.\n/// </summary>\npublic string Body { get; private set; }\n\n/// <summary>\n/// The SHA of the commit to comment on.\n/// </summary>\npublic string CommitId { get, private set; }\n\n/// <summary>\n/// The relative path of the file to comment on.\n/// </summary>\npublic string Path { get; private set; }\n\n/// <summary>\n/// The line index in the diff to comment on.\n/// </summary>\npublic int Position { get; private set; }\n\n}\n```\n. See previous comment about auto properties.\n. See previous previous comment about auto properties.\n. Please use regular auto properties.\npublic string Title { get; private set; }\nAnd set them in the constructor. Octokit handles the proper casing.\n. No, feel free. :)\n. What does \"instatiate\" mean? :trollface:\nI believe you typo'd this. Should be \"Instantiate\"\n. Hmm, this should be more descriptive. Maybe, \"A client for GitHub's Git Database API that lets you update raw Git objects.\"\n. There's a few other typos like this. I won't comment them all. :smile:\n. Make sure to change it on the interface only. Not on the concrete class. Our build script will fix up the comments on the concrete class.\n. What is a \"repo\". :stuck_out_tongue: We generally use name. If it's not clear that it's a repository, I'd prefer repositoryName\n. Could this be a Uri? Ditto for the others. ReposUrl probably can't be because of ssh.\n. Go ahead and add a using System.Diagnostics.CodeAnalysis; to the top so we can shorten all these to just [SuppressMessage(...)]\n. I'm starting to wonder if we should just disable CA1716. @shiftkey any thoughts?\n. Doc comments?\n. LOL. \"initrode\". Awesome.\n. \n. organization.name isn't an argument to this method so we shouldn't throw an argument exception.\nIn fact, a question worth figuring out is can you change the name of an organization via the API? If so, then we need to have two parameters to this method. One would be a string that's the name of the organization, and the other would be the OrganizationUpdate that has the new values for the org.\n. We never return arrays. That should be an IReadOnlyList<EmailAddress>\n. If emails is null, this should throw an ArgumentNullException. If it's empty, an ArgumentException is appropriate.\n. Couldn't this also result in an empty array?\n. Mind adding doc comments to these methods?\n. Any reason you fully qualified the Unit typename? Looks like we have a using System.Reactive above.\n. Hey buddy. What are you doing way over there on the right. Come over here. It's ok, we won't bite. Perhaps one tab in like you do elsewhere. :smile:\n. ^^^ Indentation is off.\n. Ignore this change. This was a different road I was planning to take, but decided against. I'll revert it.\n. Documentation? It's fine to do it later. :)\n. I did a search through the API and I didn't find any exceptions. So \"yeeeeahhhh?????\". :smile:\n. What's up with the indentation in this file. Everything is indented a lot except the first declaration. Please adjust. Thanks!\n. Sounds good to me. I'm hoping xUnit adds a Task based Assert.Throws soon.\n. Nope. That asserts that it's exactly that type. I want to test the is a relationship. Unfortunately there's not a built in assertion for exactly this.\n. Well I think it reads just fine, but I could add AssertEx.IsNotAssignableFrom\n. Or...\ncsharp\npublic static void IsReadOnlyCollection<T>(object instance) where T : class\n{\n    var collection = instance as ICollection<T>;\n    Assert.True(collection == null || collection.IsReadOnly);\n}\n. Even better.\ncsharp\npublic static void IsReadOnlyCollection<T>(object instance) where T : class\n{\n    var collection = instance as ICollection<T>;\n    // The collection == null case is for .NET 4.0\n    Assert.True(instance is IReadOnlyCollection<T> && (collection == null || collection.IsReadOnly));\n}\n. Nitpick nanny! Please add a space before the :\n. Space before the : gracias!\n. Space before the : danke.\n. Space before the :\n. I think this should be protected. Whether it should be disposed is pretty much entirely dependent on which ctor you call, right? We can make that decision for them with the other ctors as you've already done. @shiftkey thoughts?\n. BTW, it feels like we're exposing an implementation detail, which is why I'd rather not expose it to callers.\n. Well those are more primitive constructs, so maybe there's a reason for it. I'd like to do without and add it if a scenario pops up. After all, someone can still inherit and call the right ctor so we wouldn't be totally preventing it. :)\n. Please remove the newline.\n. This curly brace is so far from his homies. Maybe remove that newline up there so he can be closer.\n. Clean up the extra newline por favor.\n. Another lonely curly brase.\n. Heh, I just noticed our intermediate path is still Net40. Doesn't matter, but it's odd. :smile:\n. I'm not sure this change ever affected users so probably doesn't need to be in the release notes.\n. I'm torn. I want to give credit. But these release notes appear in the NuGet package and as such, end users don't care if tests are tidied up or not.\n. 4 commits for this one line change?\n. Are you trynna pad your contribution graph? :stuck_out_tongue: \n. This attribute requires that you actually have a private (or internal) property named DebuggerDisplay that returns a string. We usually only show a couple property values in such a property. The ones you'd want most to see in a debugger.\n. Also needs a DebuggerDisplay property added to the class.\n. This looks like the wrong method call. :smile:\n. This comment refers to get-branch. I think that's the wrong URL.\n. ^^^ :trollface: (I actually don't care. Just wondering if you do.)\n. The quoted name doesn't match the argument name.\n. Validate these arguments. I'm about ready to use Fody.NullGuard all over this library. I've had good results with that. You :thumbsup: to that?\n. Always be validating.\n. :trollface:\n. That little red mark there means the file doesn't end with a line ending. Some folks really care about that sort of thing. Others don't. it's like removing and sorting namespaces. I always do it, but I don't block a review for it. ;)\n. LOL :trollface: Here's what I seey\n\n\nOne of the reasons for needing the line ending is so you can stage lines and hunks in git gui, if there is no line endings it will give an error.\n\nThat's just horrible. Git Gui should handle that.\n. I have a feeling FixProjects did that. :frowning: \n. Probably not.\n. This file doesn't actually exist so I removed it from the .csproj along with this other change.\n. ^^^ Wat? Why would owner ever be null? Using a null value to indicate an organization is weird to me. An organization can be the owner.\n. Nevermind, I get it.\n. This seems redundant. I thought we automatically lowercase in ToParameter when it's an enum.\n. Looks good to me. Though we potentially call prop.ToString() twice in this method. It's not a free call so might be worth caching that value in a temporary variable.\n. /organise/organize because this is murrica!\n. Can you name that parameteridas we do elsewhere?\n. Yeah.\n. No need for this newline between the closing semi-colon and the code above.\n. So many newlines! Let's delete one of these.\n. Amazing thatCollectiondoesn't haveAddRange.\n. Much better name than I proposed!\n. Ugh, it sucks that we have to duplicate this logic. I wonder if we can convince @prabirshrestha to add more properties toGetDelegate`.\n. Sounds good. What did you have in mind?\n. Yeah, either we add this documentation to every method, or remove it from here. Ideally, it'd be on every method. But I'd be happy with removing for now.\n. Seems legit. We probably should get better about documenting the exceptions.\n. \"Implement ability\" is the work we did. It's not what's new in the release. How about,\n\"New: Method to add repository to team...\"\n. \"are now nullable\"\n. Whitespace.\n. We should ensure the TimeSpan is not negative.\nAlso, today I learned that TimeSpan.Duration gives you the absolute value of the TimeSpan. I don't think we should use that here because I feel if someone passes us a negative TimeSpan they probably fucked up and should know about it.\n. Shouldn't files be capitalized? Is it a property name?\n. \u00af_(\u30c4)_/\u00af\n. The reason I didn't ignore it before is I didn't want the build script to have to install it every single time. That adds unnecessary time for something that doesn't change often. Instead, when we upgrade, you just delete it and run the script once, and then commit it.\nBut I'm open to changing it if you feel it's better this way.\n. :cool: I forgot about the machine cache. And I was the PM at the time!\n. \"bollocks\" is the technical term, right?\n. Good catch!\n. Whitespace before the \"{\" would be an invalid JSON response so we'd be fubar anyways.\n. In another PR. I have some upcoming improvements to how we do serialization.\n. We shouldn't initialize them in the ctors for these types because they'll just get replaced when SimpleJson deserializes the json into an object. It uses the private setters to set the collection.\n. Just a follow-up. For \"request models\" what you described is exactly correct. The ctor should instantiate the collection and the setter should be private. I made that change. Let me know if you find any cases I missed.\n. Hmmm, I might want to start using GhostDoc again. It helps with the boilerplate ctor descriptions etc. What's in the .xml doc? Would we want to include this in the repo if we start using GhostDoc?\n. @shiftkey what do you think?\n. No objections. In fact, I meant to make this change everywhere. We should never be using StartNew just to wrap an object in a task.\n. In looking at this, shouldn't we always be passing in baseAddress to RepositoryExistsException. Why would we only pass it in if we know your org?\n. Ah! Good catch.\n. For a response object, they might be necessary for the serializer to work.\n. I think because it wasn't being used anywhere. Do we need it? Easier to add it later than remove it.\n. I don't think we need it, but it may be useful to people who call IHttpClient directly. For example, we use this extension method in GHfW.\n. We can always add the extension method to the GHfW side and remove it from here. I don't feel strongly either way other than leaning towards being lazy. :stuck_out_tongue: \n. Hmm, I guess not. I could make it internal till someone complains.\n. > Ideally I'd like everything under Octokit.Internal to be marked as internal - my thinking on this is that if there's a compelling case to make a type public, it shouldn't be in this namespace.\nHmm, that's not the original intent I had for this namespace. It wasn't to mark types as internal. The keyword suffices for that.\nIt's specifically for types that most people don't need to see directly, but many, if not most, need to use. For example, ApiResponse is in this namespace.\nMost users can get by importing just the Octokit namespace and these other types won't \"pollute\" their namespace, but are still usable as return values. If they need these types directly, they can import Octokit.Internal.\nI'm not opposed to making these specific case internal. I just wanted to clarify why we have Octokit.Internal in the first place. Maybe a better name for that namespace is in order. I wonder if Octokit.Internals is slightly better to distinguish between the keyword and the fact that these types represent the internal workings of the lib. :smile:\n. Why is this named DisposableRepository2 and not just DisposableRepository?\n. Not a fan of calling Wait here. I'd rather this method return Task<DisposableRepository>. Then users can just await the call to this.\n. > But this is the method that will be used within the using statement, which is not awaitable?\nSays who?! :smile:\nIt's perfectly fine to have an await within a using block. http://stackoverflow.com/questions/16566547/do-using-statements-and-await-keywords-play-nicely-in-c-sharp\n. > This is due to fact that we don't have access to the owner's name if it's an account and not an organization.\nAh. And we don't have access to the name because when we do operations for the current account, the name isn't needed as part of the URL. Right?\nThat was confusing to me and I should know that. :stuck_out_tongue: \n. These last two Ensure.ArgumentNotNullOrEmptyString calls should be in the constructor of NewMerge not here. We reserve argument null exceptions for when the argument is null, not when a property of the argument is null.\n. The pattern we use for request objects like this is that the ctor should only accept values that are absolutely required. Thus we should ensure that @base and head are not null nor empty. commitMessage is optional so it shouldn't be a parameter to the ctor.\n. Since Base is required and set by the ctor, make this a readonly property.\n. Make this readonly\n. Ah, this won't compile with your last changes.\n. Nitpick Nathan says one newline will do where two are present.\n. I'm wary of passing in arrays given they can be mutated. At the very least, we should probably set Scopes to a copy of the arry, right?\n. Are scopes always required? If so, maybe this should be readonly?\n. Nevermind, I noticed we have an empty ctor.\n. I guess we have the same problem with the property setter. We can maybe worry about this separately as a general problem and not in this PR.\n. This is a little confusing. I assume repo here should actually be the repo name and repo owner. For example, octokit/octokit.net as opposed to just octokit.net.\nI think we should probably use the pattern we use elsewhere and have separate parameters for the owner and the name and then concatenate it ourselves.\ncsharp\npublic SearchCodeRequest(string term, string owner, string name)...\n/cc @shiftkey for thoughts in case I'm missing something.\n. I don't understand. Are you saying we can't use AccountType here because the API endpoint that needs UserType returns \"Organization\" and the API endpoint that needs AccountType returns \"Org\"? Ugh.\n. Extra newline.\n. /khanify api inconsistency\nI think AccountType is the best name. So here's an idea. Make the search one AccountSearchType or AccountRequestType and keep this one AccountType.\nWhat do you think? My reasoning is I bet people will see this one much more often than they'll use the search api so I want to give this one the nice name.\n. Tears? What for?\n. Yeah, this is now correct, no? Before it wasn't.\n. Ha! I let R# sort it out.\n. I really want to get Fody.NullGuard integrated into this. So I do care, but not that much.\n. Nice catch!\n. Couldn't this fail if there's no value here? Or do we always seed this with a value?\n. Since the repository list will always be a finite collection, should this be an IReadOnlyCollection<string>? And could it not simply inherit a concrete class at that point?\n. Well there's List that'll work. :stuck_out_tongue: Also, it looks like this is supposed to be a mutable collection right now, so maybe List would make more sense than ReadOnlyCollection<T>. Or we could go the immutable route and have Add always return a new collection.\nI just think having this implement IEnumerable<T> is not right. At minimum, ICollection<T> would make more sense.\n. We try to avoid abbreviations. So I'd call this MiscellaneousRateLimit\n. I'd rather we just use RateLimit and not this class. The name of this class is too similar to ResourceRateLimits. The data we show in this response and in the headers are the same and not likely to change (as we try and avoid breaking changes).\n. Per my previous suggestion, I think this should be ResourceRateLimit and the property types should be RateLimit\n. :+1: \n. Hmm, do we actually need locks here? If someone is reading the value just as another thread is writing the value, it sort of doesn't matter who wins. After all, the read value will only be slightly outdated.\nIn other words, I don't see any problems with race conditions in this case as this isn't data that's timing sensitive. I don't think torn reads are a problem because these are 32 bit references.\nThis value is going to be set on every request, I'd rather avoid a lock here unless it's absolutely needed.\n. I've been taking the Benevolent Dictator role. :stuck_out_tongue:\nI'd like to hear from @khellang if there are specific concerns with removing the locks. If not, let's remove them.\n. :thumbsup:\nLet's remove the locks, but make sure we comment it and explain why so if someone else comes along, they understand why there's shared mutable state.\nAlso, one idea we should do is to set LastApiInfo to a copy of the ApiInfo to reduce the sharing of mutable state. In fact, I think LastApiInfo should be a method GetLastApiInfo and it should always return a copy of the last ApiInfo\nThat way, Octokit is in control of the lifetime of that object and a consumer can't inadvertently keep the object around longer than expected. Thoughts?\n. When would this be null though?\n. As a minor code style, I think this should use object initializer syntax.\ncsharp\nreturn new RateLimit\n{\n    Limit = this.Limit,\n    Remaining = this.Remaining,\n    ResetAsUtcEpochSeconds = this.ResetAsUtcEpochSeconds\n}\n. Is that the proper expansion? Or should it be ?name=example name.txt&label=labeltext\n. We could probably upgrade our compiler to use C# 6 if someone wants to take a crack at it. As long as we don't break our other platforms.\n. I'm currently fixing this, but according to the docs here: https://developer.github.com/v3/pulls/#merge-a-pull-request-merge-button\nThis is not optional and it should be CommitMessage. Did you happen to see something that suggests otherwise?\n. Well the response is message but the request is commit_message. The docs are actually a bit unclear on this so I'll ask @pengwynn for clarification.\n. Hey @pengwynn, I mentioned this in the chat room, but figured a GitHub comment message was less transient.\nAccording to the docs if you don't specify a since it defaults to Time.now which doesn't make sense to me as there can't be any notifications since now at the time you make this request.\nIt makes more sense that Time.now is the default for before, not since. Are the docs wrong?\n. Honestly, I'd rather not have this method and only have the TimeSpan I think it promotes better practices. Also, if we really want this overload, we can add it as an extension method to the interface.\n. We should probably validate that the TimeSpan is not negative as a negative value is almost certainly a programmer error. I'd throw an ArgumentOutOfRange exception.\n. Validate the TimeSpan argument here too please.\n. /wether/whether\n. Please add a space after the period before the word \"Supported\"\n. Space after the period.\n. Space after \"the\"\n. Space after \"payloads.\"\n. Let's quote \"web\" here.\n. This line looks like it doesn't belong.\n. Remove \"JSON\" here.\n. What happens if Config contains a duplicate key? We should test that scenario and define what we expect to happen.\n. Yeah, I kind of lean towards throwing an exception. Quietly overriding values could be surprising. Also, if you choose to use the NewRepositoryWebHook we should alert you to the fact if you're doing it wrong.\n. I love it! However, the logo is HUGE and takes up so much space. Let's use a normal image tag and size it to a reasonable size.\n. :+1: \n. Minor nit but there should be a space after \"updated,\" there. :smile:\n. Let's completely remove the merged constructor parameter. Merged will be a calculated property. So this should be Merged = MergedAt.HasValue.\n. Lets remove this property and constructor parameter since it's deprecated.\n. Yes, that's what I'm referring to. We should remove MergeCommitSha\n. Why was this file removed?\n. Please separate methods with newlines.\n. Add a space after the comma.\n. Newline between previous method and start of this one.\n. No need for two newlines though. :stuck_out_tongue: \n. This comment isn't accurate. The parameter is a TimeSpan, not an integer representing milliseconds.\n. I would reorder path and reference. The reason is the other overload to this method takes in owner, name, reference. If the user is calling that overload, then decides, no, they want to call this one, they only need to tack on the path parameter. They don't need to re-order parameters. Based on my experience, this is a common source of API call errors.\n. Remove extraneous newline here.\n. I'll fix it.\n. Unstable NuGet packages that track the master branch of this repository are available at \n. This PR is perfect so I'm going to nitpick on the extraneous line endings between the return statement and closing brace. :stuck_out_tongue: \n. Remove the extra line break.\n. Ha! Ghost Doc. :stuck_out_tongue: \n. If memory serves me, we do need the default ctor for serialization.\n. Seems legit to me. That's what GHfVS does. @niik, any opinion?\n. Should we validate that branchName doesn't already start with refs/heads/? I could imagine that might be a point of confusion in calling this overload and a nice exception message would be helpful. Then again, what if they really wanted the ref to be named refs/heads/refs/heads. I mean, that's probably silly sauce and we should just tell them to call the original Create method in that case.\n. > I also wasnt sure if I could set what the \"api name\" of a given property is\nYes, it's possible via the Parameter attribute. Here's one example.\n. > I didnt realise we could \"control\" what words are allowed.\nThat's done via the CustomDictionary.xml file (it's in the \"Build\" solution folder). I'd rather not add DN as a custom word though and use the full name for the C# API and use the ParameterAttribute to control the JSON name.\n. Close! :smile:\nI was thinking something more specific.\ncsharp\nthrow new ArgumentException(String.Format(CultureInfo.InvariantCulture, \"The specified branch name '{0}' appears to be a ref name and not a branch name because it starts with the string 'refs/heads'. Either specify just the branch name or use the Create method if you need to specify the full ref name\", branchName), \"branchName\");\n. But wouldn't a request for \"github.com\" also succeed in that case? For a general purpose method, we'll need to distinguish between requests for github.com and github enterprise.\n. I think I'll just validate that the URL is not github.com\n. Because this client is only used for Enterprise, we should consider adding a check to the constructor that ensures that the ApiConnection.Connection.BaseUrl is an Enterprise URL and if not, throw an exception that indicates that this client only works for GH:E. That would require that we create this instance lazily of course.\nPerhaps an idea for a separate PR.\n. This is a private method. No need  to obsolete it.\n. I think of these as being like contracts. I want them as close to the call-site as possible. Semantically, I think of these arguments being invalid for this method.\nEventually, we'll replace many of these with Fody NullGuard which will throw the exception at the call site.\n. I'd like to leave it as-is so we stay true to the original CoC. We take a pretty relaxed approach to our \"professional setting\" so telling jokes and being silly is fine as long as the jokes aren't demeaning or exclusive of others along the lines described. So probably fine to make the joke about VB the programming language, but not jokes that demean women.\nAlso, we understand that people make mistakes and have different ideas about what is considered appropriate. We're not going to hell-ban you for the first infraction unless it's way over the line.\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nConsider this document the start of the conversation, not the end. For the most part, I don't see anything in here so far that goes against the spirit of this. Everyone that's participated has been pretty great. We've had a few bad eggs, but most were still somewhat respectful.\n. \"has been added\" is passive voice and kind of redundant. How about\n\nPagination  support lets  you control how much ...\n. Ah, after looking down, I see that \"Pagination Support\" is being called out in a special manner and isn't in the bulleted list. Maybe we should call out why. For example:\nThe big focus of this release is pagination support. Pagination support lets you control...\n. We've run into a case where we might not be able to rely on this assumption. :cry:\n. However, relying on this is safe because if they strip this out, it would break GitHub Enterprise.\n. Why are we removing the return description? If that's a direction we want to take, might as well remove the entire /// <returns></returns> line.\n. It's very unlikely that an enum is going to have a huge number of elements. And we only need to iterate once and cache the result. An enum change would require recompilation. So I'm happy with ENUMeration. :stuck_out_tongue: \n. We should cache the result of this in a dictionary of dictionaries (probably Dictionary<Type, Dictionary<Enum, string>>.) That way, the next time we try to serialize an enum value, we don't have to do this iteration. It'll be a very fast lookup.\n. Weird, that syntax should work according to this article.\n\nIn any case, the return tags are currently worthless, but that's because we've simply been parroting the return type. We don't need to do that because the return type describes itself! Instead, we should use this tag to describe the intent of the returned value. But then again, that's usually already described in the summary. So :thumbsup: to getting rid of these and only use them when there's something particular interesting about the return value we need to describe that isn't described by the type.\n. Yup!\n. This could be declared readonly\n. This fallback block is the same as the one earlier (line 106). Maybe restructure this so there's no duplication here.\n. So one point of confusion is that the bug states the bug is in serialization. But this is changing deserialization code. Could you add some tests to SimpleJsonSerializerTests.cs that demonstrate the problem and are fixed by this code?\n. Nevermind. I see that you fixed both directions. I wrote some tests I'll add.\n. We've always followed the .NET Framework Design Guidelines for capitalization. \n\nThe two abbreviations that can be used in identifiers are ID and OK. In Pascal-cased identifiers they should appear as Id, and Ok. If used as the first word in a camel-cased identifier, they should appear as id and ok, respectively.\n\nSo I think it should be Id.\n. The , but here feels like the second clause contrasts with the first, but it really goes hand in hand with it. How about,\n\"This method is no longer supported through the API and has been removed from Octokit.net.\" or something like that?\n. A personal access token is an OAuth token.\nHow about we just say\n\nThere are two options supported by the API - basic and OAuth (ex. personal access token) authentication.\n\nThen there's no need to add anything else.\n. Maybe this should say \"Added support to test whether a URL points to a GitHub Enterprise instance\"\n. Wow. :scream: \n. Yeah, that's a very subtle breaking change. Probably best to use an overload.\nSomeday I'd like to write a Base64Content type. :smile: rather than using strings for everything.\n. Alternatively:\ncsharp\nServicePointManager.SecurityProtocol |= SecurityProtocolType.Tls12;\n\ud83d\ude1b . ",
    "ben": "I'm pretty sure this isn't in keeping with how you'd do things with the intention of deploying to NuGet, but I don't know how to make it right.\n. :+1: \n. ",
    "paulcbetts": "I don't see how this is unnecessary, we have to have a user agent, and even if the API doesn't 403, it would certainly make our lives easier at GitHub.com the website\n. :cool:\n. @Haacked That might be reasonable, yeah\n. No clue but it's hella jacked\n. +1 to not taking nameWithOwner.\n. @Haacked Looks like they're all in the same Illustrator file on that place that we go to check chat hwhoops\n. Any way we can get this out by Thursday so I can use it for this week's episode of Live Coding?\n. So, I actually am not so sure about this change - streaming the results in usually ends up in more complicated code for the caller and I usually prefer an IO>\n. IO<List<T>>\n. Here's the other reason you don't want to do this:\n``` cs\nvar allTheItems = await getAllRepos();\nallTheItems.GetType();     // Cool I've got all the repos!\n\n\n\nRepository             // What the fuck I've only got the last one?!?!\n```\n. @Haacked It used to be that you got the first T and now it's the last T\n. :shipit:\n. Not super excited about breaking compatibility here.\n. @half-ogre Legit; from a philosophical perspective I agree as well\n. Seems legit. :shipit:.\n. I'm very :-1: on this - we should explode unless the user explicitly sets a user agent. We could append a bunch of useful stuff on the string they give though. Having a default user agent means that when we go to ban the abusive Octokit user who inevitably uses the default string because they're lazy, we now have trouble distinguishing them from everyone else using the default\n. >  do we block by user agent?\n\n\n\nWe can sometimes in a pinch, if somebody's affecting the reliability of the site.\n\nCouldn't someone just as easily copy our GHfW user agent?\n\nI think the worry here isn't explicitly malicious people (you're totally right), it's being able to recognize / contact / mitigate people who are doing it by accident or because they're not good at the codez.\n. > Is there a middle ground here, where we require at least an app identifier and build the rest of the user agent to include the stuff we want (OS, CPU, Octokit version)?\nYeah, I think regardless of what the user puts as the user agent, the one we actually send includes all of the OS info\n. :+1: :+1: :+1: :+1: :+1: :+1: :+1: :+1: :+1: :+1: :+1: :+1: :+1: :+1: \n. :+1: to fixing this, it'll save an extra marshalling stuff back to the calling SyncContext (i.e. the \"You called this on UI thread so Imma make sure it comes back on UI thread\" stuff).\n. Agree with what @justinvp says, any time we legit use await, we have to suffix it with .ConfigureAwait(false). \n. > This not only prevents Mono users from using the tool but also prevents it's usage in open source projects\nI'm going to submit a PR to add Xamarin.* / Mono builds, and they won't have any reference to Microsoft.Bcl.Async\n. @ajepst Does Travis CI support very recent version of Mono? That would honestly get us like 95% of the value of CI, the platform differences should be really quite minimal.\n. Mono 3.x is 4.5 compatible\n. > I think those project types only work in Xamarin Studio. Is that right @paulcbetts. So for now, manually editing them is our only recourse. Or installing Xamarin Studio and opening them in there.\nThey work in Visual Studio, but only if you have a Xamarin license which costs a fair amount of :moneybag:. Don't worry about verifying the build or anything, just add in the files. If it works in Octokit.csproj it almost certainly works in the Mono version too.\n. No XUnit support in Xamarin, NUnit or bust when it comes to XS. :-/\n. @half-ogre Yeah, or just running them from the CLI runner is fine\n. This is great! One thing I noticed is that the URL of Gist is a constant, but since GitHub Enterprise ships with its own Gist, we should parameterize this. The URL of Enterprise Gist is always \"/gist\" (i.e. \"https://theurlofmycoolGHEnterpriseInstance/gist\")\n. @shiftkey Never mind, I am an idiot, for some reason I remembered that the Gist API was hosted under a different root. Carry on...\n. Xamarin Studio will be fine, there is no such silly thing as Code Analysis\n. @azuresdkci Dear Azure SDK CI - since you are a computer program, I suspect you can definitely code this up faster than any of us pathetic meatbags could!\n. As of recent, all we need to do is target Profile78 and everything will be :moneybag:, possibly linking to Microsoft.Net.Http (but on Xamarin.* they won't be used, the system one will trump it)\n. Now that Xam Studio fully supports NuGet, this is way easier, it'll almost certainly Just Work as long as you target profile 78\n. > Is the same as Windows8 but in phone OS.\nhahahahahahahahahahahahahahaha\n\nI am looking for a .xap file app of github somewhere in github, an official GH WP8 app.\n\nGitHub doesn't have any plans to build an official WP8 app at the moment, but our mobile pages should work great with WP8 - try visiting github.com from your WP8 phone.\n. Your use of not-completely-finished PRs with TODOs is :sparkling_heart: +:100:\n. Why do you need WebRequest to get ETags? Won't it just be in HttpResponseMessage.Content.Headers? We don't have to implement general HTTP caching, we know that ETags work and If-None-Match, you can totally read all of that via HttpClient\n. @niik This should be good to go, :metal:\n. We've already shipped public releases, the :sailboat: has sailed on this one. Don't Break People\u2122\n. > And for the tests project I had to add a reference to Microsoft.Bcl.Build, to tackle a warning.\nNope nope nope nope nope nope nope that dumb thing causes infinite annoyance. Veto anything that references Microsoft.Bcl.Build.\n. Do any of our public interfaces directly expose HttpClient types? I think we can do this a better way, where the PCL version only declares interfaces, and the platform version actually implements them. That way, we can create a Octokit-WP8 project that references Microsoft.* and leaves them out of all the other builds.\nCheck out Akavache for an example of this, where the PCL version only sets up interfaces, and the platform version actually brings the implementation. This is the counterintuitive part of PCLs, where the app version will actually replace the PCL version, and the app version can do more.\n. > Hi. Does this mean that we will have a github WP8 app?\nNo.\n. @trsneed Great work!\n. @Haacked I mean, I currently use ReactiveUI in a Visual Studio Extension, I don't know where this \"You must SN every binary\" is coming from\n. > Also, if you didn't strong name sign, you do risk a name collision with another extension.\nlol ok\n\ntemplate wizards do require strong name signing, but only because they must be installed into the GAC\n\nIf you install Octokit into the GAC you've got bigger problems\n\nIf your package exposes a public API which other extensions consume, you might be referencing a common DLL as the other people consuming your public API.\n\nThis has happened before with libgit2sharp, it's the one legitimate reason you might want to SN.\n. If someone's going to bear the suffering of Strong Naming, it's going to be the people who want it, not the Open Source community and everyone else sane who doesn't want it. -:100: to strong naming. \n. I'm reminded of a Richard M. Stallman Quote:\n\"This is where I am great. I am great at being very, very stubborn and ignoring all sorts of reasons why you should change your goal, reasons that many other people will be susceptible to. Many people want to be on the winning side. I didn't give a damn about that. I wanted to be on the side that was right, and even if I didn't win, at least I was going to give it a good try.\"\n. @GeertvanHorrik Here's my previous write-up of this issue:\nhttps://github.com/reactiveui/ReactiveUI/issues/43#issuecomment-37471892\nShort version: SN fucks with the \"Getting started contributing\" story and the \"Build my version from source\" story\n. @hazzik Be nice. This is your last warning.\n. Alright guys, I've come up with an innovative new proposal - if you maintain an Open Source project, please consider following my lead:\nhttp://log.paulbetts.org/a-modest-proposal-strong-naming-carbon-offsets\nIf you ever learn one thing from Economics, it's that 'people always respond to incentives'. \n. What's the benefit of this? Windows 8.0 still has like 60%+ of Windows Store marketshare and we're not using any Windows 8.1 features\n. It sounds like 'size' isn't that super useful, but 'isEmpty' might be, /cc @pengwynn @jasonrudolph @sorry-i-cant-cc-github-api-but-wrong-org\n. \n. Hubot img me Jonny Lee Miller 2015\n\n. @christophwille I believe the Portable package needs to target Profile259 instead of 78. Can you create a PR to do this? If that sounds Scary\u2122 let me know and I can help you out with it.\n. @christophwille Cool!\n. Cool - will this also ensure the NuGet package gets correctly generated? (i.e. the portable string includes wpa81?)\n. > I'm not sure i understand the build failure that is present here, how has the addition of wpa81 to the pcl targets caused NSubstitute to not exist in the tests (for all of the test projects)?\nNot sure, this may be unrelated\n. Nope. Thanks @hippiehunter! \n. Breaks literally every piece of software written using Octokit, for literally zero tangible benefits to users of the library. Easy decision.\n. Well, so I don't want just an \"Ensure\", I want to explain why you need it\n. Oh wait, this is in Connection, there it's fine\n. Always be Comma'ing\n. Hwh\u00e6t\n. The GUID here is the ProjectGuid from the csproj file - the change here should just be a rename\n. No, I make a new GUID for projects by copying an existing one, editing them by hand and adding random changes, because it's easier than creating a new project from scratch since every IDE is super opinionated about directory structure :-/\n. These people are animals.\n. Apparently Windows App Store applications are sentient and therefore have preferences\n. ",
    "spraints": "I moved the releases API into ReleasesClient.\n. Thanks @Haacked! Things are pretty well-organized, so it was pretty easy to find the right places for things. IGitHubClient has a Releases property now.\n. :cool:\n. Is there a better way to do this? This works, but feels weird. I tried using \"application/vnd.github.v3+json;charset=utf-8, application/vnd.github.manifold-preview\" as the Accept header for all requests, but that didn't seem to work. I should look at how octokit.rb does it. Or @pengwynn, do you have a suggestion?\n. ",
    "shiftkey": "cc @ammeep\n. @haacked do you think this is worth keeping around?\n. > 1. Change our default accept header to have a list containing the two known Accept values we know about. (I believe Accept is a list).\nI like this option because it's less invasive (and how often do we need to be explicit with the Accept header - let alone allow our customers to choose different/incorrect Accept headers) because the method signature could become this:\npublic async Task<TOther> Upload<TOther>(Uri uri, Stream rawData, string contentType, \nDictionary<string,string> headers = null)\nAnd then inside that you merge together whatever was provided with the default values:\n```\nheaders = headers ?? new Dictionary();\nif (!headers.ContainsKey(\"Accept\") {\n  headers.Add(\"Accept\", \"application/vnd.github.manifold-preview\");\n}\nvar response = await Connection.PostRawAsync(uri, rawData, headers);\nreturn response.BodyAsObject;\n``\n. The only headache I have with this approach is thatcontentType` is both a required value and something that could be inside the header collection...\n. I think the whole nameWithOwner thing could confuse users. :+1: on separate parameters...\n. \nI ENDORSE THIS PRODUCT AND/OR SERVICE\n:shipit:\n. :shipit:\n. If you need an extra pair of hands to help get it out the door, just shout\n. b u m p\n. :thumbsup: we can plan this as a standalone release to reduce impact downstream \n. Seems legit, and some nice :lipstick: in there as well.\n:shipit: (with or without my suggestion)\n. +1 to having these things inside to IIssuesClient - they're all kinda intertwined concepts (I can't use labels elsewhere, milestones relate closely to issues, etc).\n. Looks good :shipit:\n. A++ WOULD REVIEW AGAIN\n:shipit:\n. :shipit:\n. After hacking on some code samples with @haacked for his Octokit talk, I'd rather we didn't focus on doing 1-1 API docs.\nI'd rather we focus on scenarios that users might be interested in - perhaps others can submit theirs as well - to go beyond the basics.\nThoughts?\n. Not heading down the generated path - https://github.com/octokit/octokit.net/pull/948 is moving along nicely.\n. We've just published 0.1.1 to NuGet which fixes this issue with Microsoft.Threading.Tasks\nhttps://www.nuget.org/packages/Octokit/0.1.1\n. > Is there any real difference under the hood for those watching from home?\nAt the IL level I suspect there's some unnecessary wrapping and unwrapping of tasks, but that's something we can chip away at over time.\n. @Haacked :boom:\n. @ericschultz #117 has dropped the Microsoft.Bcl.* packages and targets .NET45\n. I have no idea what the status is of TravisCI and Windows - can someone translate this insane issue thread?\n. Whoops, curse that magic syntax\n. @forki done\nhttps://github.com/octokit/octokit.net/blob/master/README.md#build-server\n. Seems legit :thumbsup: \n. @pltaylor it's always easy to be OCD with someone else's code\n. System.MissingMethodException : Method not found: \n'System.Threading.Tasks.Task`1<System.Collections.Generic.IReadOnlyList`1<Octokit.Repository>>\n Octokit.RepositoriesClient.GetAllForUser(System.String)'.\nI can see the same thing here. Investigating.\n. Appears to be some shims we had in for .NET 4.5 compatibility are no longer necessary. Sending up a PR now.\n. #139 will fix this issue (ignoring the test weirdness)\n. @haacked shouldn't this be under the IGitDatabaseClient? \n. Closed via #153 \n. @alfhenrik that seems like the most logical approach\n. > Searching Issues\n\nSearching Code\nSearching Users\n\nCaptured here: #274 #275 #276 \n. @forki sounds about right. We should update the notes to indicate that.\n. @forki \nAt this stage we are not able to make this into a Portable Class Library because of the licensing issues with HttpClient and non-Windows platforms. We hope this changes in the future, but must soldier on as-is.\nOctokit.net has a separate solution which uses the Mono HttpClient implementation here so you can build this in Xamarin Studio.\nIn terms of pre-Windows 8 support, you won't be able to run the Octokit-NetCore45 tests either (the tests are actually run within a Windows Store app last I checked). \nHow should we proceed?\n. @jugglingnutcase you're using VS2013, right? \nI think there might be a Windows 8/Windows 8.1 tooling difference here that we need to catch. I'll reopen this as a reminder to investigate it further.\n. @jugglingnutcase do you have VS2012 installed as well? \nI have a theory on what's happening, but don't have an environment with just VS2013 to prove it.\n. @jugglingnutcase ok, so my theory goes:\n- VS2012 supports building Windows 8 Store Apps\n- Octokit uses a Windows 8 Store App for the Octokit-Net45Core project\n- VS2013 supports building Windows 8.1 Store Apps (and strongly suggests upgrading your Windows 8 Store App to Winodws 8.1).\n- you're being nagged to upgrade the project to Windows 8.1, because you don't have the Windows 8 tools\n\n. These changes will become redundant when we switch over to PCL builds in #218 \nThe only significant change is that PCL + VS2012 + CodeAnalysis is impacted (you need to upgrade to VS2013 to get those benefits) but we can work around that while people transition.\n. @adamchester what's your OS? \n. @adamchester that's bizarre, it's exactly the same as what I've got. Which SKU of VS2013?\n. @adamchester can you share a gist of the diagnostic MSBuild output for machine? \nMight help me to spot if it's something VS2012-related that we should :fire: down\n. @adamchester nevermind, I think I've spotted the issue.\n\nIn the Octokit-NetCore45 project can you switch that to Windows 8.1 and see if that fixes it?\n. Oh, and you'll need to change the target framework the Octokit.Tests-NetCore45 to .NET 4.5.1.\n. @adamchester well there goes that idea.\nI've got a bunch of logistical things to chase up this afternoon, but tonight/tomorrow I'll test it out on a Win8.1/VS2013-only VM to see if I can recreate it.\n. @forki should this be a closed PR?\n. > and I noticed the usual MIT license stamp, but at the .NET 4.5 grade, that is conflict of interest.\nI'm not clear on what this exactly means.\n\nRationally, this tells me there is no separation between specific paradigms for target audiences (who either work with or without THEORY).\n\nSame thing - what's the licensing issue you think is happening here?\n. > Ok, never mind. I just realized this is configurable in the build. Doh!\nCorrectamundo.\n\nWow, I didn't know Win8 lib builds need VS.\n\nI think it's more \"running the tests\" than the actual building of libraries.\n. > i plan to include tests and ping someone when i think they're ready for review.\nSounds great!\n\n. > Hop on the force push :trolleybus: :trollface:\nR E B A S E\nF O R\nL I F E\n. At the moment the branch needs to have the merge conflict resolved.\nOnce you've got master up to date, switch to your branch and run this:\ngit checkout starred-client\ngit merge master\nThen push that merge commit up and it should \"go green\".\nRegarding the other things, there's not much left:\n- List Stargazers\n- Check if you are starring a repository\n- Star a repository\n- Unstar a repository\nThe last two are probably closely related, but it's up to you as to how you'd like to approach it.\n@half-ogre do we have any pointers on getting test data into the integration test suite? It'd be nice if we could setup the test data as part of the setup/teardown of these tests...\n. @SimonCropp most likely. We don't want to use the DataContractJsonSerializerStrategy inside SimpleJson but I suspect that we might have to change that soon.\n. @half-ogre Even with renaming the field to Html_Url the problem is still there. Also Url is not mapped either for Issue (?!?!)...\n. @SimonCropp \n\nis this expected?\n\nNo. There's a test here for deserializing an issue, but we don't check the specific properties. \nSee https://github.com/octokit/octokit.net/pull/153 for some related discussion on serialization.\n. Confirmed issue with upstream, here's a patch: https://github.com/facebook-csharp-sdk/simple-json/pull/41\n. Because we use them a lot:\n\n. @Haacked I've got an upstream PR for SimpleJson here https://github.com/facebook-csharp-sdk/simple-json/pull/41 which I'll add that to.\n. It's to do with the ApplyParameters extension we use. Here's a failing test:\n```\n[Fact]\npublic void DoesNotDropPageFromQueryStringWhenUsingParameters()\n{\n    var uri = new Uri(\"https://api.github.com/repositories/1/milestones?state=closed&sort=due_date&direction=asc&page=2\");\nvar parameters = new Dictionary<string, string> { { \"state\", \"open\" }, { \"sort\", \"other\"} };\n\nvar actual = uri.ApplyParameters(parameters);\n\nAssert.True(actual.Query.Contains(\"page=2\"));\n\n}\n```\ncc @Haacked if he wants to look into this fix\n. I've started a PR for this fix here\nhttps://github.com/octokit/octokit.net/tree/milestones-kill-your-rate-limit\nI haven't confirmed the milestones client works as expected, but that's easy to chase down now...\n. > When the code gets around to getting the nextPageUri, the old parameters are still there and overwrite the good parameters that are in the nextPageUri given by GH's api.\nSounds like something overlooked as part of the tests but I'm not sure what. Let me explain:\nhttps://github.com/octokit/octokit.net/blob/master/Octokit.Tests/Helpers/UriExtensionsTests.cs#L66\n```\n[Fact]\npublic void CombinesExistingParametersWithNewParameters()\n{\n    var uri = new Uri(\"https://api.github.com/repositories/1/milestones?state=closed&sort=due_date&direction=asc&page=2\");\nvar parameters = new Dictionary<string, string> { { \"state\", \"open\" }, { \"sort\", \"other\"} };\n\nvar actual = uri.ApplyParameters(parameters);\n\nAssert.True(actual.Query.Contains(\"state=open\")); // overwritten\nAssert.True(actual.Query.Contains(\"sort=other\")); // overwritten\nAssert.True(actual.Query.Contains(\"direction=asc\"));  // existing\nAssert.True(actual.Query.Contains(\"page=2\"));  // existing\n\n}\n```\nThis test covers\n- ensuring that new values overwrite existing values when generating the URL\n- that existing values are not stripped out of a URL\nBut if something higher-up in the chain is passing incorrect parameters into this (the fact that it's getting stuck at page 2 makes me think that's the case), it's gonna probably get stuck in that loop.\n@jugglingnutcase I'll have a look at your branch and see if I can see what's happening here.\n. See https://github.com/octokit/octokit.net/pull/190 for the fix. Apologies.\n. @jpsullivan don't thank us, thank @forki! :grinning:\n. @jpsullivan I've dropped a few comments in based on my testing and review. It's coming together!\n. @jpsullivan don't sweat it, take your time.\n. @jpsullivan anything left on this? \nI'll review it the next time I have internet access but let me know if there's anything particular I should look at.\n. @jpsullivan :sparkles:\n. @alfhenrik whoops \nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Clients/OrganizationMembersClient.cs#L194\nNice spot\n. Couple of little things to clean up, but you'll also need to merge master into here to resolve the issue with the ApiInfo.cs file.\nLooking good otherwise :metal:\n. @pltaylor if you've got master up to date, run this:\ngit checkout ImplementBlobsApi\ngit merge master\nThis will pull in the latest changes - and you should see a conflict that needs to be resolved.\n. There's a couple of issues here which needs to be fixed:\n- Some files are missing from the Mono* projects - just run .\\build.cmd FixProjects and that'll sync them\n- the Octokit.Tests.Clients.BlobClientTests+TheCreateMethod.PostsToCorrectUrl fails -  should it be a BlobReference on the assert?\n. If you could run .\\build.cmd FixProjects to sync the new files with the Mono* projects that'd be :sparkles:\n. Thanks for the contribution!\n\n. You'll need to merge master into this branch (probably some csproj conflicts yay!)\nEDIT: nope, ApiUrls.cs\n. I updated the Mono* files inline and merged this in by hand. Thanks for the work.\n\n. @pltaylor that's okay. \nI made a change recently to the script to make it more thorough after some changes slipped through, so it's not your fault.\n. I've been going back and forth on a couple of minor issues with @pmacn here\nhttps://github.com/pmacn/CommentPulldown\nAside from that, I think this is done!\n. > Ideally, contributors would only need to add a file to Octokit.csproj and run a build script (or even better just compile the solution) and we'd automatically add it to the other projects. \nA post-build step to update specific csproj files sounds like the simplest way to get things done. Only friction might be with modifying a csproj file as part of a build, but shouldn't be too hard to spike.\n. @Haacked +:100: love it\n. @forki that build issue is fixed over on ~~#207~~ EDIT: #208  \n@ninjanye all the magic is just in the build.fsx file but other stuff can probably be found in the FAKE repo.\n. From the spec:\n\nA URL for the image to use as the icon for the package in the Manage NuGet Packages dialog box. This should be a 32x32-pixel .png file that has a transparent background.\n\nThe current one is 337x310px - so we should probably change that.\n. Aside from the failing tests and a bit of excess whitespace, this looks good @hahmed \n. @hahmed my psychic debugger thinks you need to get master up to date before doing the rebase\n. Thanks for picking this one up @andreasohlund. \nLet's see where we want that test data to live, but aside from that I'm happy with this change.\n. So http://developer.github.com/v3/repos/releases/#create-a-release has an undocumented feature where it rejects you for having an empty repository:\n{\n   \"message\":\"Validation Failed\",\n    \"documentation_url\":\"http://developer.github.com/v3/repos/releases/#create-a-release\",\n    \"errors\":[\n        { \"resource\":\"Release\",\n          \"code\":\"custom\",\n          \"message\":\"Repository is empty.\"\n        } \n    ]\n}\nThus, we can't implement this test in an automated way until we implement:\n- blobs - see #188\n- trees - see #194\n- probably references too - #130\n. I've extracted the build script differences to another PR, and added notes about what needs to be updated after that\n. @Haacked aha!\n. All looks good from here\n\n. Thanks! \n\n. ProTip: remember to git clean -xdf to tidy up any old versions of FAKE floating around\n. Nevermind, turns out I was just behind the curve\nhttp://www.nuget.org/packages/ScriptCs.Octokit\ncc @alfhenrik\n. I wouldn't trust him either\n. @SimonCropp it would be better but for the sake of not overcomplicating the deserializing hooks (or breaking things completely) you can just enumerate the dictionary:\n```\npublic class Gist \n{\n  public IDictionary Files { get; set; }\n}\n// elsewhere\nforeach(var file in gist.Files)\n{\n  // do stuff\n}\n```\n. Regarding question 3:\n\nNote: When using the v3 media type the \u201cuser\u201d field will become \u201cowner\u201d\n\nI think this is now the default behaviour.\n\n. Fairly certain we've sorted this with #225. Closing.\n. @xabikos we're following the layout of the documentation site to be consistent with how users would explore it\n\nIn this case Comments are under Gists, so I'd expect Comments to be a subclient of Gist:\nvar comments = client.Gist.Comments.GetAll(\"id\");\n. @xabikos I've opened up #247 to track the Gists Comments API, which is somewhat different to the Gists API.\nFeel free to leave a comment there if you've got any other questions.\n. Keep in mind that #239 is underway for creating gists\n. > Regarding the gists shall I make a pull request for every one of above check boxes or only when all of them are finished?\nDoing it incrementally makes for easier code reviews on my end, but up to you. The checkboxes are just there to ensure that duplication of work isn't happening\n. :boom: it's merged in\n. Oh, and Immutable Collections are also part of this change.\n. I'll grab this today because I Might Have Already Started This\nOops.\n. No longer relevant\n. > Want me to include the reactive version in this PR or a new PR?\nMight as well do it now...\n. Excellent stuff! Thanks for the contribution\n\n. Oh, this was fixed a long long time ago.\n. From six months ago: https://twitter.com/citizenmatt/statuses/308942893614243840\n. Closing this out as low-priority - we'll be focusing on .NET Core support for Octokit soon (and that'll let us run the CLI tests everywhere) - after that we'll wait for the upstream support - or get involved there...\n. Looks like lots of the groundwork is in there for the rest of the Gist API - is that part of the plan or am I getting ahead of myself?\nA few little whitespace issues, and that failing test, but it looks promising so far!\n\n. @SimonCropp \n\nhappy to continue with the rest in the background. it is mostly manual work.\n\nI'm cool with that. Stub out out the other methods  with a NotImplementedException(\"You can submit a pull request for this to https://github.com/octokit/octokit.net/\") exception so we don't forget them. cc @haacked\n\nthe next thing I need is http://developer.github.com/v3/git/ is anyone working on this?\n\nBlobs and Trees are underway #188 and #194 - which I'll review again and probably merge in today for a 0.1.5 release early next week.\n. In it's current form, the magic \"Merge pull request\" button is disabled.\nI think the .csproj changes from master need to be merged in.\nI'll also just run through the latest changes just in case I missed something.\n. Oh, and run .\\build.cmd FixProjects to sync the new files across the Mono* projects :sparkles:\n. .\\build.cmd FixProjects\nThe system cannot find the path specified.\n(Q)uit, (Enter) runs the build again\n\nAre you running it from Powershell or cmd or something crazy I haven't tested on?\n. @SimonCropp do a git clean -xdf to clear up that file. \ncc @forki to remind me to review that script and try-catch the way out\n. @SimonCropp I'm able to see this issue on master - digging a bit deeper into it\n. @Haacked \n\nBuild.cmd is prompting. \n\nIt still is. Let me fix it.\n@SimonCropp your %LOCALAPPDATA%\\NuGet\\Cache\\ is probably like this\n\n@forki I'm still seeing the 0KB file be downloaded to the local cache - are you able to publish a new release?\n. Running FAKE.Core.2.1.758-alpha is now kicking off the build, but there's a different issue here with the generated SolutionInfo.cs file.\ninternal static class AssemblyVersionInformation {\n        internal const string Version = \"0.1.5\";\n    }\n}\nThat closing brace is causing some compile issues.\n. @SimonCropp I'm still seeing the broken SolutionInfo.cs file in FAKE version 2.1.766. \n@forki is there something I'm missing?\n. @forki that's fine - happens to the best of us. Let me know when it's :cool: and we can try again\n. @forki got it\n@SimonCropp looks good, would be nice to test that some of the properties on the gist response - like Owner for example - is not null\nLet's see if @haacked has any issues \n. Given that sort behaves differently for each scenario, perhaps it's easier to have separate classes for each request type, and making this class look like this:\nvar client = new SearchClient();\nvar repositories = client.Search(new RepositoriesRequest(\"SearchTerm\"));\nvar code = client.Search(new CodeRequest(\"SearchTerm\"));\nAnd so on. \nThis could let us tailor each class to specific scenarios, like:\nq=addClass+in:file+language:js+repo:jquery/jquery\ncould be presented as:\nvar query = new RepositoriesRequest(\"addClass\", In.File);\nquery.Language = \"js\";\nquery.Repo = \"jquery/jquery\";\nGiven all the parameters map to querystring terms, it should make testing a lot easier.\n. The other thing I'd like to explore with this is making the search parameters more .NET-friendly, rather than using raw strings:\nstars:10..20 could be written as:\nvar request = ...;\nrequest.Stars.Minimum = 10;\nrequest.Stars.Maximum = 20;\nBut then >=500 is an acceptable input, which can't quite be mapped to the same pattern due to the > or >= distinction...\n. I'd like to see some integration tests for these search results - they might change over time, but at least we can do some basic checks that we're using the API right.\nI'm happy to defer to strings in the short-term until someone has some better ideas for the filtering...\n. A general ProTip when experimenting with API design - use some tests to represent how the API should be used.\nIt'll help you spot Weird Things early and because you're using the API you suffer in the same way your users probably will...\n. I'd love to write a test like this:\n```\n[Fact]\npublic void TestingTheSizeQualifier()\n{\n    var connection = Substitute.For();\n    var client = new SearchClient(connection);\nvar request = new RepositoriesRequest(\"something\", Greater.Than(50), Less.ThanOrEqualTo(100));\nclient.SearchRepo(request);\n\nconnection.Received().GetAll<Repository>(Arg.Is<Uri>(u => u.ToString() == \"search/repositories\"), Arg.Any<Dictionary<string, string>>());\n\n}\n```\n. @hahmed yes, rather than fiddling around with properties you have the ctor overloads which guide you down that path\nBut there's also other options in there (languages, size, path, extensions, etc) but we can argue about those approaches later...\n. @hahmed I'll give it a closer look this afternoon (will be in transit but online wherever possible)\n. @hahmed I'll have a look at it tomorrow while I'm waiting for a flight\n. Ok, I'm gonna land this one in master and open some issues to track tidying up things like \n- getting documentation more consistent\n- integration tests\n- code tidy-up and consistency\nThis will help us iterate over the search API as we charge towards V1.\nThanks for the hard work on this.\n. @hahmed I'm not clear on what you need me to do. I can't see the branch listed here so I assume you tidied it up:\nhttps://github.com/hahmed/octokit.net/branches\n. Ah, yes. Don't stress about those, they're easy to clean up...\n. Nice spot - thanks for the patch!\n. @gabrielweyer \n\nFor the Create method should I also ensure that the HttpStatus is 201?\n\nIf we don't get a 201, we should throw an exception here, perhaps something like ApiException with a helpful message...\n. > Am I supposed to do anything with Custom media types?\nLet's not worry about it for now. If someone really wants it, we can discuss it when that comes up.\n\nnumber is implemented as Int32 currently, should we use Int64 instead (ie Facebook API)?\n\nI'd lean towards Int32 but perhaps I'm too short-sighted :trollface:\n@pengwynn should we assume at some point in the future that a repository may have more than 2^32 pull requests - or are we getting ahead of ourselves?\n. > I didn't write any integration tests as it would require at least two users. \nCould we write some tests where a user comments on their own pull request?\nAnd we have helper methods inside other tests to create sample repositories which are cleaned up after the test finishes - that should help you get some of the way.\nThe other piece is creating a new blob, tree, commit, branch and then pull request - I'm not sure how far along that is.\n. Oops, missed one:\n\nSimpleJson can't deserialize fields starting with an underscore (_links for example). Is this the expected behavior? \n\nCorrect. But this is a different format to the ones we've dealt with earlier - like Issues for example.\nStatus: 200 OK\nLink: <https://api.github.com/resource?page=2>; rel=\"next\",\n      <https://api.github.com/resource?page=5>; rel=\"last\"\nX-RateLimit-Limit: 5000\nX-RateLimit-Remaining: 4999\nIn the Issues case, we map the Link header values to the ApiInfo class inside ApiResponse.\nIn the example above, the links are in the response.\n@pengwynn \n- we should be consistent with how links are representing in the API, so which approach is \"the right one\"? \n- And I assume that, as it's a breaking change, we need to address this in the next version of the API...\n. And don't worry about the _links parameters - if someone needs it, we can deal with it then\n. > How can I access the Http Code in my Create method?\nSomething like this?\nvar response = await ApiConnection.PostAsync<PullRequestReviewComment>(ApiUrls.PullRequestReviewComments(owner, name, number), comment);\n                                 .ConfigureAwait(false);\nif (response.StatusCode != HttpStatusCode.Created)\n{\n    throw new ApiException(\"Invalid Status Code returned. Expected a 201\", response.StatusCode);\n}\nreturn response.BodyAsObject;\n. @gabrielweyer \n\nbuild.fsx is rewriting incorrectly SolutionInfo.cs\n\nIs that the issue where it would regenerate the SolutionInfo.cs with an extra } on the end? Run git clean -xdf to ensure you have the latest build of FAKE and try again...\n\nThrowsTwoFactorChallengeFailedExceptionWhenProvidedCodeIsIncorrect is failing\n\nCan you provide some details about how this is failing?\n. @gabrielweyer thanks, I've captured that in #250\n. After reviewing the epic search API #226 this just needs to have master merged in. \n\nWe still need Create a Fork and Create a Pull Request. Then I can start the testing. We also need to create a second test user in order to fork the repository (I don't think you can fork your own repository).\n\nCorrect. But we don't need to fork to create a pull request. If we just use a branch for the pull request does that still mean you are able to write an integration test for this?\n. @gabrielweyer - so pull requests is now in master via #360. \nWould you like me to dust off this PR or would you like to wrap this up and :ship: it?\n. @Haacked @gabrielweyer this looks pretty great (the tests all pass locally)!\nThere's some cosmetic changes which I'll add in as part of getting this mergeable again. I'll see if I can speed up the tests as well while I'm in there.\nI'll do this in a separate PR.\n. Also a good spot! Thanks! \n\n. So given we appear to have two different behaviours (return one file or return a collection of files) perhaps we should split this out into two method for convenience:\nTask<ContentsResponse> GetFile(string owner, string name, string path);\nTask<ContentsResponse[]> GetDirectory(string owner, string name, string path);\nIt doesn't match 1-1 with the API, and there's a couple of scenarios I can think of that are weird:\n- Call GetDirectory with a file path - get array with one value\n- Call GetFile with a folder path - error?\n- How do we handle symlinks? Do we even care about symlinks?\n. @haacked let me experiment with the API to see what feels natural. I'll get back to you on this cc @warrenbuckley \n. I can push up this branch later, but here's a quick brain dump of what I spiked up:\nI left ContentResponse as-is except for one change:\n/// <summary>\n/// The size of the file\n/// </summary>\npublic int? Size { get; set; }\nI had some tests which would try and set Size to null and fail miserably, which can only work for a nullable value type.\nAnyway, back to the story:\nWrite Some Damn Tests\nI started with this test, to get the README file from a repo:\n```\n[IntegrationTest]\npublic async Task GetContentForReadmeReturnsAnItem()\n{\n    var client = new GitHubClient(new ProductHeaderValue(\"OctokitTests\"))\n    {\n        Credentials = Helper.Credentials\n    };\n    var fixture = client.Repository.Content;\n//  note the different method name here\nvar result = await fixture.GetFile(\"octokit\", \"octokit.net\", \"README.md\");\n\nAssert.NotNull(result);\nAssert.True(result.Size > 0);\n\n}\n```\nThen I wanted this test to do something similar, but against a given folder:\n```\n[IntegrationTest]\npublic async Task GetContentForASpecificFolder()\n{\n    var client = new GitHubClient(new ProductHeaderValue(\"OctokitTests\"))\n    {\n        Credentials = Helper.Credentials\n    };\n    var fixture = client.Repository.Content;\n// I'm still not sold on this name, but it works for the moment\nvar result = await fixture.GetContents(\"octokit\", \"octokit.net\", \"Octokit\");\n\nAssert.NotNull(result);\nAssert.NotEmpty(result);\n\n}\n```\nAnd then I wanted to get the contents at the root of the repository:\n```\n[IntegrationTest]\npublic async Task GetContentForRootReturnsList()\n{\n    var client = new GitHubClient(new ProductHeaderValue(\"OctokitTests\"))\n    {\n        Credentials = Helper.Credentials\n    };\n    var fixture = client.Repository.Content;\n// we need an overload here where you don't pass in a path\nvar result = await fixture.GetContents(\"octokit\", \"octokit.net\");\n\nAssert.NotNull(result);\nAssert.NotEmpty(result);\n\n}\n```\nAnd lastly, I wanted to be able to filter on files and folders (these are just extension methods using .Where):\n```\n[IntegrationTest]\npublic async Task GetContentForASpecificFolderUsesExtensionMethods()\n{\n    var client = new GitHubClient(new ProductHeaderValue(\"OctokitTests\"))\n    {\n        Credentials = Helper.Credentials\n    };\n    var fixture = client.Repository.Content;\nvar result = await fixture.GetContents(\"octokit\", \"octokit.net\");\n\nAssert.NotEmpty(result.Files());\nAssert.NotEmpty(result.Directories());\n\n}\n```\nWhat does that leave us with?\nThis is the interface for IRepositoryContentClient at the end of this spike:\npublic interface IRepositoryContentsClient\n{\n    Task<IReadOnlyList<ContentsResponse>> GetContents(string owner, string name);\n    Task<IReadOnlyList<ContentsResponse>> GetContents(string owner, string name, string path);\n    Task<ContentsResponse> GetFile(string owner, string name, string path);\n   }\nI like GetContents over GetFolders/GetFiles as it sticks a bit closer to the concepts in the API.\nWhat Sucks About This\n\nI still don't like reusing the ContentResponse class everywhere, but the differences between a Dir and File type are small enough (and easy enough to hide away behind extension methods).\nThe actual Content properties aren't being populated on the files. I suspect that's related to the media type used - you should pass application/vnd.github.v3.raw to get the content as well.\n. @warrenbuckley don't close this PR - my experiment was building on what you've already done.\n\nThis is just feedback for how I'd go about it - feel free to incorporate it into your PR.\nI think breaking out GetContent into multiple explicit methods is the best way to go about it right now.\n. > Is it possible to merge your changes into my PR and collaborate that way on it?\nLet me tidy up the branch into these steps:\n- the change to ContentResponse\n- the extension methods for Files() and Folders()\n- the API changes for IRepositoryContentsClient\n- the integration tests\nAnd then you can merge these into your branch (like you would when working with master)\n. I've published this up under get-content-spike - \nhttps://github.com/octokit/octokit.net/tree/get-content-spike\ngit remote add upstream https://github.com/octokit/octokit.net.git\ngit fetch upstream\n. Oh, and don't forget to run .\\build FixProjects to sync the new files with the Mono* projects\n. @warrenbuckley anything I can do to help this along?\n. @warrenbuckley that's ok, just ensuring I'm not neglecting things I need to look at.\nDrop me a line when you're ready to review.\n. Oh, and you'll need to run .\\build FixProjects to add the new files to the Mono* projects...\n. Closing in favour of #434 \n. @riteshventurepact .Get(\"username\") returns a Task<User> - so you need to await this operation to get the result...\n. \n:shipit:\n. \n. > It's yours if you want it :smile:\nReal talk: I love how people get to this stuff before I can get around to it. Thanks!\n. > I'd love some feedback on how you'd like the GetAll overload that takes the subNamespace parameter. I think it might be better to use a enum value here. Do you do any validation on the client anywhere?\nThe sub-namespace is a handy way organise similar references - heads and tags are some of the common conventions, pulls is another one you might have seen - but I don't think there's value in constraining it to a specific enum.\nWhen a sub-namepsace doesn't exist, the server returns 404 - we should check for that and propagate a more helpful exception to the user.\n. Looking good so far, most of the feedback is about cosmetic stuff and typos.\nSome integration tests would be awesome (we have helpers for creating repositories and disposing them at the end of the test) but I don't consider it a blocker to merging this in.\nThat \"sub-namespace not found\" code path I think is the only technical thing I'd like resolved at this stage.\n. Were you going to drop the namespace additions for the tests?\n. I've opened #242 for us to track that 404 path, and I'll commit a failing integration test so we don't forget about it either.\nThanks for the contribution!\n\n. @paulcbetts shouldn't this overload cover us for Enterprise instances?\nvar client = new GitHubClient(new ProductHeaderValue(\"MyCoolApp\") new Uri(https://theurlofmycoolGHEnterpriseInstance/\"));\n...\n// other things here\n...\nvar gist = client.Gist.Create(newGist);\nOr am I missing something?\n. Looking good, just a couple of minor things and I think this is ready to :ship:\n. Looking good, just needs you to merge master into your branch so you can test against the latest upstream changes\n. @rgmills you might need to reset your branch back to d2e04905e6658c106c3a4fa1ead34830c3d977e2 and try that merge again\n. It's kinda fiddly, which is why I put it aside but here's the abridged version:\n- internally, ApiConnection.GetAll<T> just calls ApiPagination.GetAllPages\nhttps://github.com/octokit/octokit.net/blob/bc8269789fb3776ee024ce942ec4ff70c501e670/Octokit/Http/ApiConnection.cs#L112\n- ApiPagination.GetAllPages will enumerate all pages and likely return an empty collection\nPerhaps we should have a consistent response inside ApiPagination.GetAllPages when you get a 404\nThe example I'd like to get passing as part of this is #242 - because when you specify a namespace that is not valid, you should get a specific error message rather than an empty collection.\nhttps://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/ReferencesClientTests.cs#L66\n. @alfhenrik I like it\n. @half-ogre seeing how QED likes this change, I'm gonna merge it in\n. Closed via #288\n. As these are just tests and minor fixes, and @half-ogre is rather happy, and the build is green, I'm gonna merge them in and keep working on these\n. As I started doing some refactoring in here, I'm going to rework this PR to address these things separately:\n- updating the build scripts to create and use an OAuth token instead of credentials\n- test improvements\n- refactoring and adding overloads to make the API better\n. I'm reasonably happy with the current state of the build scripts.\nAnd Appveyor plugs in nicely (it does test discovery and package generation so we don't need to have it run the same script).\nhttps://ci.appveyor.com/project/Haacked15676/octokit-net/build/1.0.40\nIf anything nice comes up, I'll address it separately.\n. Oh @alfhenrik you are awesome! Thanks for taking the time to do this...\n. Oh, and I just realised that we might need to review that the IObservable versions are also in sync. \nBut that's just wrapping these, so I'm happy to push that out til after this.\n. @pmacn correct! (I've pulled it from the list)\nhttps://github.com/octokit/octokit.net/commit/924543dab7e14ee1858b497d34734a537aec8087\n. @khellang opened: #317\n. Closing this as the tasks identified have been spun off\n. There's #239 and #271 which are implementing various parts of the Gist API in progress, but nothing specifically for Gist Comments.\nMake it so!\n. Oops, there it is too: #252 \nMy bad. I'll close this one out now too.\n. @forki Xamarin Studio will continue to be supported. \nI just don't want to support both VS2012 and VS2013 while the differences between the platforms are so vast...\n. Just re-tested that Octokit solutions can be opened in VS2013 and Xamarin Studio v5.\n. Haven't seen this one in many weeks.\n. I'm happy to merge this in and keep refining it over time. Any objections @haacked?\n. Thanks @pmacn for helping with this.\n\n. Closed via #256 \n. @VikramShetty thanks for the code review. I've left some notes to ensure we keep our documentation consistent as we work through the API...\n. @VikramShetty looking good, just that minor whitespace issue and I'm happy to merge this in\n. @VikramShetty thanks for the contribution, and welcome to GitHub!\n\n. @andrerod looking good so far, just a few little things about documentation\nI'd also :heart: some tests if you've got time!\n. @andrerod can you also run .\\build FixProjects to sync the new files with the Mono* projects?\n. Right, I'm all happy with this now. Thank for the contribution!\n\n. @pmacn\nSo I'm trying to update Rx to v2.2 and I get this build error:\n\nC:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit\\Octokit.csproj(289,5): error : Assembly file not found\n\nLine 289 matches up with the <PullDownComments /> task\nAny input on how to debug what's happening here - or where the source to this lives?\n. @pmacn I've opened up this PR which resolves my issue https://github.com/pmacn/CommentPulldown/pull/2\n. Octoclippy? NOOOOOOOOOOO!\nBut seriously, that's just a fun little thing that you've stumbled upon. \nNo plans to do any Serious Business with it - it'll just be our little secret.\n. \n. Hey @haacked can you add me to the MyGet feed (same name as here) so I can investigate where my builds are going?\n. Dropped a couple of commits in to get the unit tests and integration tests passing. \nWill publish a release candidate package up to MyGet when I next get an opportunity...\n. Here's the feed URL if you want to test out the install/upgrade experience to ensure I haven't missed something:\nhttps://www.myget.org/F/octokit/\nInstall-Package Octokit -Source https://www.myget.org/F/octokit/\nInstall-Package Octokit.Reactive -Source https://www.myget.org/F/octokit/\n. It's a Festivus Miracle!\nhttps://www.nuget.org/packages/Octokit/0.1.6\nhttps://www.nuget.org/packages/Octokit.Reactive/0.1.6\n. @ben-biddington Interesting. \n- Which test runner are you using?\n- What error are you seeing?\n. Scratch that, I know where this is occurring: #262 /cc @Haacked \n. @Haacked the issue was fixed but the tests needed to be updated to reflect using BodyWrapper<T>\n. What @hahmed said. This is where the magic happens:\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Models/Request/MilestoneRequest.cs\n. Looks good - just a few little things to tidy up. \nI've opened up #277 to cover the integration test - we should have all the necessary bits to do this lying around.\n. You'll need to run .\\build FixProjects to include the Branch.cs file in with the Mono* projects...\n. @goalie7960 so we can pass arguments to build.cmd to specify custom tasks - that's how the FixProjects task is invoked.\nSo running .\\build.cmd FixProjects from the command line is how you can do that.\nOh, and you'll need to merge master into the branch to resolve some merge conflicts with the ApiUrls.cs file.\n. Thanks!\n\n. You'll need to run .\\build FixProjects to include the DateTimeExtensions.cs file in with the Mono* projects...\n. Thanks!\n. You'll need to run .\\build FixProjects to sync these new files with the Mono* projects...\nAside from that, the tests are all passing and there's a few minor issues around naming things.\n. Thanks!\n\n. So this happened! :metal: :tada: :dancer: \n. Correct! Thanks for the fix!\n. Done in 91811330d992ce566e444c8cdd0fb4c6436ed405\n. Considering this was something only really relevant to my testing, and how long it's sat here without love (and being finished), I'm gonna let this go...\n. Just rebased on top of master\n. @paulcbetts Yeah, this is mostly a reminder for me to double-check this once I close out #284 \n. Updated description with tasks to perform\n. @paulcbetts yeah, just making a sanity check list to run through here\n. ### Monotouch\n\nMonodroid\n\n. So I just stumbled upon this little factoid:\n\nI agree that not having PCL support in Express is very unfortunate. That\u2019s why we are planning on addressing this concern in the next release.\n\nhttp://msopentech.com/blog/2013/10/14/net-team-makes-portable-class-library-pcl-available-platforms/#comment-4501\nMe: \n\nWhy does it matter? I wanted to ensure that people could contribute to this without needing to have a paid version of VS. So I tested VS2013 Express for Windows Desktop and encountered this issue.\nI know it's a moot point, but it's a barrier to entry.\n</rant>\n. @Haacked agreed, I'm happy to let this one sit for a while\n@dsplaisted @terrajobst can you shed some light on the sort of timelines that we could anticipate for seeing PCL support in the Express SKUs of Visual Studio. A 2013 Update? Or VS201X?\n. Closing in favour of #401 \n. @technoweenie thanks!\n. Fantastic stuff!\n\n. ProTip: pull requests will update as you add changes to a branch.\nAlternatively, you can just force push your branch and the PR will update too. No need to close and reopen it! :metal:\n. I love it when a plan comes together\n\n. @hahmed one of the things I'd like to challenge you on is how those unit tests actually validate the parameters you set in the query.\nSo we have a test like this:\n[Fact]\npublic void TestingTheInQualifier()\n{\n    var connection = Substitute.For<IApiConnection>();\n    var client = new SearchClient(connection);\n    //get users where the fullname contains 'github'\n    var request = new SearchUsersRequest(\"github\");\n    request.In = new[] { UserInQualifier.Fullname };\n    client.SearchUsers(request);\n    connection.Received().GetAll<User>(Arg.Is<Uri>(u => u.ToString() == \"search/users\"), Arg.Any<Dictionary<string, string>>());\n}\nWe know that the q value on the querystring parameter should contain something, so why not check it within the test, like this?\nconnection.Received().GetAll<User>(\n    Arg.Is<Uri>(u => u.ToString() == \"search/users\"),\n    Arg.Is<Dictionary<string, string>>(d => d[\"q\"] == \"???\"));\ncc @alfhenrik as this is relevant to #290\n. There's a few failing tests here because the enum types, such as Language and AccountType, that don't specify the parameter values necessary to map them to the lower-case values...\n. @hahmed if you're running .\\build you might have hit this issue #353 \nAlternatively, you can run .\\script\\cibuild.ps1 which is the same script the build server runs (takes a bit longer)\n. \nThanks!\n. @alfhenrik oops, I meant to merge that in last night. Done!\n. > Didn't quite get all lines down to 80'ish...but should be better now.\nThat's why I said \"or thereabouts\" :grinning: - much more easier to read now.\nThe changes look great, just curious if we can make the tests a bit more robust...\n. \ncc @hahmed\n. > Alright. I'll admit it, there was probably no good reason for using StartsWith and Contains instead of hard coded strings\nDon't sweat it. We're only human.\n. @hahmed I'd prefer to test that we're sending the correct query format to the GitHub API (harder), rather than that the parameters are populated as expected (easier).\n. I'm really interested in the external behaviour of these actions - i.e. what the client sends to the server.\nTesting properties in this fashion is just testing a layer away from the important bits.\n. #301 was merged in, so you should be unblocked now\n. Fix them projects! :)\n. \nReally like how this turned out - thanks for all the hard work on this!\n. Hey yo @haacked can I merge this in?\n. Citation: http://msdn.microsoft.com/en-us/library/8kb3ddd4(v=vs.110).aspx\nThanks for spotting this.\n\n. For the moment I'm happy to leave this behaviour as-is .\nI'll leave this open as a reminder to indicate in the documentation that release tags need to be searched via the references, unless someone has a better idea...\n. >  Maybe start a lobbying group to have the API behavior changed ;)\ncc @pengwynn I'll see if I can chase you up :soon: about this :)\n. @SeanKilleen yeah, let's just document it rather than trying to be too clever here. Happy to discuss in a new issue.. I prefer the first option because it takes away the pain of having to implement the \"poll until you get a 200\" logic - which could be implemented in wildly different ways by different developers causing all sorts of headaches...\n. @pmacn :thumbsup:\n. @ammeep .\\build FixProjects to sync up the Mono* projects\n. > It likes to use arrays of ints everywhere.\nYep, transforming this into a dataset that's easier to traverse is :green_heart: from me.\nA quick way to get started would be to tailor the response based on the specific API you're calling, which seems like you're already on that path.\nA crazy idea: encapsulate the data behind a more human-friendly API in the response.\npublic class PunchCardStats \n{\n    public int GetTotal(DateTime pointInTime) { ... }\n    public int GetTotal(DateTime startTime, TimeSpan timeSpan) { ... }\n}\nrather than exposing the array directly (well you could do that anyway)...\n. Got those tests passing, now reading it a bit more closely\n. A few little places in the new tests where parameters are crammed together, but I'm definitely into whitespace OCD now in terms of reviewing.\n. I'm happy to merge this in as a first pass for the feature - we can refine the data we return to the user in the future based on what users would like.\nPing me when you're happy with the whitespace stuff and I'll :shipit: \n. \n. > When trying to use the name Deployment for the response model the compiler complains with:\n\nCA1724: Type Names Should Not Match Namespaces\n\nThat looks like a CodeAnalysis error. I feel like we should be ignoring it.\n. \n. It's your branch at this point, I'm not fussed whether you merge master in or rebase to update it. What you'll see here is the commits appear after the last comment (if rebasing).\nUp to you.\n. :sparkles: and this is why we have code reviews :grinning: \n. @KonradIT I have a pull requests open here #284 which will enable you to use the one binary to target .NET45/Win8/WP8. \nIt's a significant change, so I'm holding off until I can close out most of the outstanding pull requests.\nIs that what you're looking for?\n. @KonradIT this repo is for working with the GitHub API, rather than the site itself.\nIf there's something specific you're having issues with, please contact support@github.com so we can investigate further.\n. @hahmed it still says \"WIP:\" in the PR - is there anything left to implement on this?\n:thumbsup: on this change, hopefully this tidies up a bunch of our boilerplate code\n. Given we already discussed a bunch of this over in https://github.com/hahmed/octokit.net/pull/1, I don't have anything else really to find fault with.\n\n. So you could define your own implementation of IHttpClient which accepts a proxy server configuration: https://gist.github.com/shiftkey/8402772\nAnd then this snippet is how you can inject it into a GitHubClient:\nvar proxy = new WebProxy(/* your details here */);\nvar client = new HttpClientWithProxyAdapter(proxy);\nvar credentialStore = new InMemoryCredentialStore(new Credentials(\"username\", \"password\"));\nvar connection = new Connection(\n    new ProductHeaderValue(\"MyCoolApp\"), \n    GitHubClient.GitHubApiUrl, \n    credentialStore, \n    client,\n    new SimpleJsonSerializer());\nvar client = new GitHubClient(connection);\nI'll leave this issue open to see if we can make this easier to inject...\n. So what about these two changes?\n- an overload to pass in a custom IHttpClient - along with the ProductHeaderValue to the Connection ctor\n- bring in that custom IHttpClient in the gist \n. @haacked as in an optional constructor into HttpClientAdapter? Sure\n. #302 has been reworked to drop the need to create a different type for supporting proxies\n. Moving this to #107\n. > I was actually thinking of maybe making it easy to set the IWebProxy on the top IGitHubClient object. \nWith how Connection and IHttpClient interact I think it's gonna be a bit of a mess to setup internally for small gains.\nSo is that a :ship: or are you still pondering this?\n. Look at all these new endpoints http://developer.github.com/changes/2014-03-18-paginating-method-changes/\n. Gonna punt on this and do it incrementally.\n. Thanks!\n. Upon reading this I realised that this GetEmails method is not aligned with the other methods we have which return collections.\nIt should be this (in IUsersClient):\nTask<IReadOnlyList<EmailAddress>> GetEmails();\nUpdate the implementation to the same signature and you can use .GetAll<EmailAddress> and thus not worry about modifying SimpleJson.\n. One last little fix:\nhttps://github.com/octokit/octokit.net/blob/fadf18288f51b171d206f608d25ad9ac8ba23eba/Octokit.Tests/Clients/UsersClientTests.cs#L105\nThis test should now check for GetAll, not Get\n. @lbargaoanu I think this might be related to the test account used. \nCan you open a separate issue for that so we can investigate further?\n. Thanks!\n. ProTip: once you open a PR you can push new commits to your branch and the PR will automagically update to include them. \n. @AndyCross thanks for starting this one off.\nOne of the design goals we've been aiming for with Octokit is to structure these clients to mirror the Documentation structure (i.e. the sidebar here: http://developer.github.com/v3/)\nAs you can:\n- get all hooks\n- get a single hook\n- create a hook\n- edit a hook\n- delete a hook\n- test a hook\nI think it's worth extracting this code into a IHooksClient (or whatever name makes sense). You don't have to implement all these right now, but it'd make that sample become:\nvar hooks = await authedClient.Repository.Hooks.GetAll(\"owner\", \"repo\");\n. [EDIT] added link to relevant issues\n. CSC : error CS2001: Source file 'Clients\\IRepositoryForksClient.cs' could not be found [C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit\\Octokit.csproj]\nCSC : error CS2001: Source file 'Clients\\RepositoryForksClient.cs' could not be found [C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit\\Octokit.csproj]\nCSC : error CS2001: Source file 'Models\\Request\\NewRepositoryFork.cs' could not be found [C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit\\Octokit.csproj]\nCSC : error CS2001: Source file 'Clients\\IRepositoryForksClient.cs' could not be found [C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit\\Octokit-NetCore45.csproj]\nCSC : error CS2001: Source file 'Clients\\RepositoryForksClient.cs' could not be found [C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit\\Octokit-NetCore45.csproj]\nCSC : error CS2001: Source file 'Models\\Request\\NewRepositoryFork.cs' could not be found [C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit\\Octokit-NetCore45.csproj]\n\nLooks like some files are missing from the Forks components...\n. It's looking good. Unfortunately there's been a lot of change in master since you started this, so they need to be updated before I can merge this in.\n. Thanks Steffen!\n. You know what? I don't even care that this is just for a single method. This is great, have a gif!\n\nThanks for the contribution!\n. @pmacn git commit --amend like it never even happened :trollface: \n. Use the Force (Push), Luke!\ngit push origin {branch} --force\n. \n. @lbargaoanu looking good, couple of ideas for what to do next:\n- could we isolate this under a [Trait] from xUnitContrib so it won't run by default with the existing tests\n- could this be a FAKE step, like CheckClients which runs this test and lets you see which projects are failing\n. Right, I might have been imagining that. \nThe alternative would be to create a Octokit.Conventions project which we can run using the existing xUnit script.\n. Another interesting test to investigate:\n[DebuggerDisplay(\"{DebuggerDisplay,nq}\")]\npublic class RepositoryHookConfiguration { }\n. > Sorry, but I'm missing your point about RepositoryHookConfiguration.\nMy bad, I should have been clearer.\nSomeone opened a PR where they annotated their model classes with [DebuggerDisplay] attributes. I'm probably getting ahead of myself (as in, I don't have a consensus from the contributors here whether they're :thumbsup: or :thumbsdown: on it) here but it'd be nice to do this across the codebase to make the debug experience nicer.\n\nI know it's a hack, but rather than create a separate project it would be easier to simply comment the Fact attribute on the method. \n\nOk, we can address that in a separate PR.\n\nIt's only run on demand after all.\n\nYep, but I'm lazy and don't really want to remember to uncomment it and recompile the thing. :grinning: \n. In because peer pressure\n. My gut feeling is that it's a security measure to prevent leakage of sensitive data - I can call this on an account which isn't a member of the repo and get the same thing. \ncc @pengwynn \n. @pengwynn yep, it's a public repo so a 403 definitely makes sense here\n. > I put these in here simply as a way to put the idea forward. I probably should have put them in their own pull request. I got carried away, my bad.\nLet's address those separately - personally I don't mind seeing the null parameters there, but I'm open to alternatives...\n. Ok, I think this one is good to go. Merge master in and :boom:\n. Seems legit. I can do this today. \n. Forever uploading... :(\n. Oh, and it's LIVE! LIVE! LIVE! https://www.nuget.org/packages/Octokit/0.1.8\n. Extensions are fine when they work across all the platforms supported.\nThe problem with the snippet above is that it depends on WebAuthenticationBroker which is Win8-specific. Moving to PCLs will kill off our ability to #ifdef in functionality like this at all.\n. @Haacked showing a browser and getting some data from the result of the user's interaction is what the class does - we could hide that behind an abstraction (I know @dsplaisted has shown how to do that with PCLs before) but it then means we need to write a similar abstraction for desktop.\nIn the short term perhaps shipping a Octokit.WindowsRuntime project might be easier - when multiple platforms want it, then we revisit generalizing the feature...\n. > Is there a demand?\nI'll leave it up to everyone else. I'm just trying to think a couple of steps ahead...\n. It's been a while since this thread last had any activity.\nI think the push towards doing more with HttpMessageHandler that's available to the consumer to craft and control means we can keep the library simpler.\nPlease chime in over on #781 if you have any ideas for scenarios we should keep in mind.\n. @pmacn I really need to go back and revive those PRs that are languishing there, unloved...\n. @Haacked just pushed a little fix to turn of xUnit's verbose output for unit tests, so you don't see the Tests complete: X of Y noise when browsing for failing tests...\n. Closing this out. Thanks @thedillonb! \n. Closing this out as #795 completed the missing bits\n. This finally landed in #649 \n. Actually completed in #776 and will go out in v0.12.0\n. @farezv you may as well just ask questions here \n. Indeed! Marking as completed!\n. >  it looks like there currently is no way to create an organisation using the API (or I am blind)?\nCorrect\n\nMaybe I shouldn't close the issue, so we have a record of why these tests fail.\n\n+:100:\n. > I like how this issue is labelled as easy-fix :stuck_out_tongue_winking_eye:\nOops, fixed\n. TheCreateMethodForUser.CreateANewPrivateRepository was moved over to [PaidAccountTest] in https://github.com/octokit/octokit.net/pull/656. \nTheCreateMethodForOrganization.CreateANewPublicRepository was moved over to [OrganizationTest] in https://github.com/octokit/octokit.net/pull/634.\nI think that's all that needed to be done here. :hocho: \n. > I'm not quite sure about the naming of the API client, maybe FollowersClient would be a better name...\nAs Followers are a concept only relevant to users - you can have watchers and stargazers on repositories - I'm happy to simplify it to IFollowersClient\n. The build is sad...\n\"C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit.sln\" (Build target) (1) ->\n       \"C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit\\Octokit-Mono.csproj\" (default target) (9) ->\n       (CoreCompile target) -> \n         CSC : error CS2001: Source file 'Clients\\IUserFollowersClient.cs' could not be found [C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit\\Octokit-Mono.csproj]\n         CSC : error CS2001: Source file 'Clients\\UserFollowersClient.cs' could not be found [C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit\\Octokit-Mono.csproj]\n. If you merge master into your branch, that test will pass. Not sure why it's like that...\n\n. > CheckClientInterfaces fails as before. Something is rotten here :).\nThat wasn't the test I was referring to - see the CI server output here.\nAnyway, running it again. Let's see how this goes...\n. > Is there a reason this is a separate project and not just part of our existing unit test suite?\nI wanted to run this like we do CheckProjects - so instead of running all the tests, you just run this one test (or perhaps just the convention tests).\n. > Is that because these currently fail?\nI suspect so, but that's probably because we missed some coding conventions. But we're testing that the API surface is consistent here, rather than the behaviour of components - that's why I'm leaning towards testing these at a different spot...\n. @Haacked if we include this as it's own step in the .\\build script, is that a good compromise?\n. This has been merged in. I've also opened #361 to track the failing convention tests.\n. Relates to #361 \n. \nSounds great, let's do it!\n. Looking back on this, I'm kinda neutral on the idea.\nCan we think about some other areas here where things can be improved?\n. This has been sitting here a while. Please drop a comment in here if someone gets sufficiently caremad enough to tackle this.\n. \nWait, I mean :thumbsup:\n. @tbondy760 I think I know this one (I'm awful at batch files basically), so I'm glad you found it!\nRe: contributing, it sounds like a permissions issue. If you fork the Octokit.net repo and push your branch to your fork, you can then send us a pull request with the change.\nHappy to work through any other headaches you have getting started!\n. Fixed via #353 \n. Can you run .\\Build FixProjects to add the new files to the Mono* projects?\n. Aside from merging master into here to resolve the csproj differences, I've got nothing else to say about this PR. Thanks for the work!\n\n. \n. > Maybe our clients need to return response objects and not just the actual entities\nI think that's the best place to put this data. It kinda sucks, but a simple abstraction to expose the HTTP data is the easiest way to do it:\ncsharp\npublic interface IResponse<T>\n{\n    public string ETag { get; }\n    // other fields\n    public T Data { get; }\n}\nHow this mixes with our Task<T>/IObservable<T> responses is probably something worth spiking - I think it's a rather significant change...\n. Fun fact: we currently have this IApiRespose type which captures the relevant fields to do this:\n``` csharp\npublic interface IApiResponse\n{\n   T Body { get; }\nIResponse HttpResponse { get; }\n}\npublic interface IResponse\n{\n    object Body { get; }\nIReadOnlyDictionary<string, string> Headers { get; }\n\nApiInfo ApiInfo { get; }\n\nHttpStatusCode StatusCode { get; }\n\nstring ContentType { get; }\n\n}\n```\nThe part that I don't think we've tackled is how to apply the ETag on subsequent requests. I like pushing this down to the HTTP layer, so perhaps a wrapper like Octokit.Caching is still the way to go.\nAnyway, I'm leaning towards doing more HttpMessageHandler-based stuff through things like #808 - taking that to it's logical conclusion would likely support something like this... \n. > I'm very new at this.\nAll good - we were all newbies once :grinning: \n. @tbondy760 thanks for the patch! \n\nI think those contributing guidelines need some :heart: because it's been a while since we initially wrote them.\n. Always be fixing dem projects...\n. @alfhenrik \n\nIs that something we could (possibly) include as a post build task in the project file...?\n\nI'm kinda on the fence about this, but I'm definitely biased (as I've been involved with writing all the scripts for Octokit).\nIf someone wants to take a stab at it I'm happy to review and see how it fits with my workflow...\n. Thanks @vktr \n\n. Looks like we've had some overlap with #323, which I've just merged into master.\nI've left the DELETE task open here #366 as there's a couple of questions about it.\n. Looks great! :cake: \n. Thanks @forki!\n. > Might be worth explaining what publish the branch to GitHub means perhaps with an example like other cases: git push origin your-branch-name.\n:thumbsup:\n\nIt might be worth linking to the ReSharper team settings too.\n\nThey're kinda boring, but I'll call out some of the non-standard things we do in a Coding Style section.\n. Ok, so I'm organising these files into three documents:\n- README - the introduction, what people see first\n- CONTRIBUTING - the nuts and bolts of the project\n- DEPLOYMENT - the \"how to ship a release\" steps\nI think that should cover the three audiences (visitor, interested/contributor and the person doing the release)\n. Ok, I'm gonna merge this in and address the git-specific issue in another PR.\n. dropped the [WIP] tag\nReady to review\n. @Haacked you mean this? https://github.com/octokit/octokit.net/issues/372 :trollface:\n. This is the raw output\n```\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.IActivitiesClient) [FAIL]\nAssert.Equal() Failure\n   Position: First difference is at position 9\n   Expected: get_Starring\n   Actual:   get_Starred\n   Stack Trace:\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(38,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.IWatchedClient) [FAIL]\n   Assert.Equal() Failure\n   Position: First difference is at position 5\n   Expected: CheckWatched\n   Actual:   CheckStarred\n   Stack Trace:\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(38,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.ISearchClient) [FAIL]\n   Assert.Equal() Failure\n   Position: First difference is at position 0\n   Expected: search\n   Actual:   request\n   Stack Trace:\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(95,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckParameters(MethodInfo mainMethod, MethodInfo observableMethod)\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(42,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.IIssuesLabelsClient) [FAI\nL]\n   System.TypeLoadException : Could not load type 'Octokit.Reactive.IObservableIssuesLabelsClient' from assembly 'Octoki\nt.Reactive, Version=0.1.8.0, Culture=neutral, PublicKeyToken=null'.\n   Stack Trace:\n      at System.Reflection.RuntimeAssembly.GetType(RuntimeAssembly assembly, String name, Boolean throwOnError, Boolean\nignoreCase, ObjectHandleOnStack type)\n      at System.Reflection.RuntimeAssembly.GetType(String name, Boolean throwOnError, Boolean ignoreCase)\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(33,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.IReferencesClient) [FAIL]\nAssert.Equal() Failure\n   Position: First difference is at position 6\n   Expected: GetAllForSubNamespace\n   Actual:   GetAll\n   Stack Trace:\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(38,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.IBlobsClient) [FAIL]\n   System.TypeLoadException : Could not load type 'Octokit.Reactive.IObservableBlobsClient' from assembly 'Octokit.React\nive, Version=0.1.8.0, Culture=neutral, PublicKeyToken=null'.\n   Stack Trace:\n      at System.Reflection.RuntimeAssembly.GetType(RuntimeAssembly assembly, String name, Boolean throwOnError, Boolean\nignoreCase, ObjectHandleOnStack type)\n      at System.Reflection.RuntimeAssembly.GetType(String name, Boolean throwOnError, Boolean ignoreCase)\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(33,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.IRepoCollaboratorsClient)\n [FAIL]\n   Assert.Equal() Failure\n   Position: First difference is at position 0\n   Expected: owner\n   Actual:   name\n   Stack Trace:\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(95,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckParameters(MethodInfo mainMethod, MethodInfo observableMethod)\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(42,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.ITeamsClient) [FAIL]\n   System.TypeLoadException : Could not load type 'Octokit.Reactive.IObservableTeamsClient' from assembly 'Octokit.React\nive, Version=0.1.8.0, Culture=neutral, PublicKeyToken=null'.\n   Stack Trace:\n      at System.Reflection.RuntimeAssembly.GetType(RuntimeAssembly assembly, String name, Boolean throwOnError, Boolean\nignoreCase, ObjectHandleOnStack type)\n      at System.Reflection.RuntimeAssembly.GetType(String name, Boolean throwOnError, Boolean ignoreCase)\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(33,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.IGitDatabaseClient) [FAIL\n]\n   Assert.Equal() Failure\n   Expected: 5\n   Actual:   10\n   Stack Trace:\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(38,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.IIssueCommentsClient) [FA\nIL]\n   Assert.Equal() Failure\n   Expected: 6\n   Actual:   5\n   Stack Trace:\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(38,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.IIssuesClient) [FAIL]\n   Assert.Equal() Failure\n   Expected: 16\n   Actual:   13\n   Stack Trace:\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(38,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.IOrganizationsClient) [FA\nIL]\n   Assert.Equal() Failure\n   Position: First difference is at position 8\n   Expected: get_Team\n   Actual:   get_Teams\n   Stack Trace:\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(38,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.IGitHubClient) [FAIL]\n   Assert.Equal() Failure\n   Expected: 14\n   Actual:   12\n   Stack Trace:\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(38,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(clientInterface: Octokit.IRepositoriesClient) [FAI\nL]\n   Assert.Equal() Failure\n   Expected: 12\n   Actual:   10\n   Stack Trace:\n      c:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests.Conventions\\SyncObservableClients.cs(38,0): at\nOctokit.Tests.Conventions.SyncObservableClients.CheckClientInterfaces(Type clientInterface)\n``\n. @ammeep see #376 - it's mostly done aside from the DebuggerDisplay ones which I'm kinda procrastinating on...\n. Oops, this was done ages ago. :trolleybus: \n. At this point we're down to 6 failures which are mostly method mismatches.\n- [x] implementIObservableIssuesCommentClient.Delete- [x] implementIObservableIssuesLabelClient- [x] add missing properties toIObservableIssuesClient- [x] add missing properties toIObservableGitHubClient- [x] add missing property/method toIObservableRepositoriesClient- [x] add missing property toIUsersClient`\n. Well that wasn't as hard as I feared...\n. @khellang I've captured some tasks here #363 for making the diagnostics even better (I don't want to debug the tests to interrogate the specific failures)\n. Rebased because yolo.\nPaging @haacked to the thread for a :eyes: \n. Nevermind @haacked, I've got a lot of things which depend on this change\n. @pmacn a couple of little improvements to make, but so so happy to see some bad tests corrected along the way!\n\n. Thanks!\n. master: Run test finished: 103 run (0:07:51.3919591)\nniik/support-etags-through-wininet: Run test finished: 103 run (0:10:13.4192345)\nUh, that's interesting. Let me dig into it some more...\n. Let's take a step back: https://github.com/octokit/octokit.net/issues/530\n. @niik I haven't nuked the branch, I'll see if I can get that branch merged into master as a first step \n. Relates to #361 and #346 \n. And this is unblocked if someone wants to add it in\n. Looks like #976 was merged to finally address this. It's available in v0.18. Moving on.\n. > We've already shipped public releases, the :sailboat: has sailed on this one.\nNot sure I agree with this. We're pre 1.0 still and there's a lot of work to do yet before we get there. \n. We're doing an API audit in #1038 and have marked a few things as obsolete in the most recent release. \nI think we settled on singular for the naming convention, but we'll use that to keep things up to date (and later enforce this via convention/integration tests)\n. I'll merge master into this tomorrow, but aside from that I think this is ready for review\n. It's green, quick, ship it @haacked!\n. :shipit:\n. Just pushed a little fix for the impacted tests (it converts DebuggerDisplay into a value to send to the API, oops)\n. \n. :ship:\n. Step 1: You haven't added the Reactive interface:\n\nStep 2: You haven't added the right methods:\n\nStep 3: You have additional methods which aren't important:\n\n. > Don't know if it'll affect anything, but generally I like to use Environment.NewLine\nYeah, I've been in a rush and a bit lazy. I'll make sure to tidy that up now...\n. \n. \n. \n. \n. Dropped the [WIP] tag as this is ready for review\n. Thanks!\n. Thanks!\n. Looks good. \nPerhaps making the test a bit more readable by using IsNotType is the only improvement I can think of...\n. :shipit:\n. A couple of failing serialization tests in there. Good times...\n. v0.2.2 has upgraded SimpleJson to 0.34.0...\n. @Haacked can we internalize ProductHeaderValue in a separate PR to nudge us towards this Brave New World?\n. This is looking pretty great @trsneed. \nI had a stab at this a while ago #284 but I like your approach of doing it side-by-side for the moment.\nI'll pull down the changes and have a play, I've already got lots of people asking for this!\n. Ok, so the only headache with this PR is that if you try and install Octokit.Reactive into a PCL project you'll get rejected.\nI've opened https://github.com/octokit/octokit.net/issues/435 to track this, but it's not a blocker for me.\n. Thanks for this. \n\nNow to put together another release.\n. @phantomtypist yep, don't sweat it\n. Looking good @phantomtypist! \nAny plans for tests for the AddMember/RemoveMember/GetRepositories methods?\n. @phantomtypist apologies for not coming back to review this PR properly. Thanks for the hard work you've done with it.\nAs it's been a while, there's been other contributions and conventions tests added which I've pulled in and merged. I'm also not sure what state #331 is in, so I'm gonna review it over in #795\n. @niik yeah, i'll do another run today and see if I get the same results\n. Ok, so there's two things in here which I'll address separately:\nSigning Assemblies\nWhile I appreciate there are scenarios where assemblies need to be signed (sup VS), I'm fairly sure this isn't something we're interested in doing currently. \nI'll open up an issue and let people thrash it out there (I know many people who are opposed to it, but I'll make sure they play nice).\nIf we were to sign these assemblies, we should do it with a proper key so that we can verify official releases. \nFxCop rules\nI want to fix these, rather add exclusions to the solution. Can you open an issue with some more details so we can address this correctly?\n. I hate it when @paulcbetts writes what I wanted to\nhttps://github.com/reactiveui/ReactiveUI/issues/43#issuecomment-37471892\n\nEvery time a new contributor comes along, they now have to have an extremely demotivating fight with Visual Studio to get the project to build, or to replace the official binaries with ones they've built for testing.\n\nAnyone have a sample/blog post around about doing this without touching the csproj files so we can avoid this pain?\nBut I'd lean towards Authenticode signing for this sort of thing, because It's The Real Deal.\n. > Can I get some good intel here? :smirk:\nThis seems like an interesting breakdown of the VSIX situation: http://stackoverflow.com/a/16452046/1363815\nReasons for strong naming:\n\nAlso, if you didn't strong name sign, you do risk a name collision with another extension. \ntemplate wizards do require strong name signing, but only because they must be installed into the GAC\nIf your package exposes a public API which other extensions consume, you might be referencing a common DLL as the other people consuming your public API. \nIf you created a DLL called \"Package.dll\" and another extension also did, and neither of you strong name signed your binaries, it's possible the CLR will get a bit confused here. So if you weren't strong name signing, make sure your assembly name is \"unique enough\" to avoid this risk.\n\nReasons against:\n\nIf you are already VSIX-deployable and don't need anything in the GAC, then no, Visual Studio makes no requirement that you are strong name signed.\n\nEmphasis mine\n. @GeertvanHorrik out of curiousity - why the two different keys?\n. Ok, so we've got a bunch of feedback about how to address the onboarding experience, and how to freeze the assembly version to ensure maximum compatibility. That's all fine.\nHowever what still isn't resolved for me is about the when strong-naming is necessary, and the impact of not strong-naming (as we're doing currently). Yes, I know many teams do strong-naming still, but I'm not satisfied with doing it for the sake of doing it.\nI've seen some mentions of scenarios above, so let me call out the specific scenarios I've seen mentioned so far:\n- installing into the GAC (some VS extensions require this)\n- VS extensibility scenarios where it's possible to have two different versions of an assembly in an appdomain\nWhat else have I missed? What war stories do other people have that we need to be aware of?\n. @jbogard \n\nso that means anyone that strong names their assembly for any reason whatsoever cannot use this library.\n\n:cool:\nGiven I haven't had to SN something of my own free will in many, many moons, I'd love to hear why people are doing this...\n. @hazzik\n\nSo the problem here is to decide what you need - do you want more users of your library or not.\n\nI started this discussion as a way to hear more about how/where people are using strong naming, in particular situations where they needed strong naming to use Octokit.net. As someone who doesn't need strong naming, the input from others has been great to clarify things for me - as well as the various gotchas we've found from others who do SN on their projects.\n\nIf you do so, then sign the fcking assembly and go ahead. If you don't care about your users - continue to think up the reasons like \"my god does not allow me to sign my assemblies\".\n\nWe also had a long JabbR chat last week with some of the chaps at Microsoft about the strong naming situation. You should check it out (should be the afternoon of Friday 25th in your timezone). \nIf we were violently opposed to strong naming, we probably wouldn't be having this discussion. \n. \n. @PureKrome yes. We'll follow up in the next few days.\n. Looks like the forks parameter is being included in the search term.\n\n. https://github.com/octokit/octokit.net/blob/master/Octokit/Models/Request/SearchRepositoriesRequest.cs#L142\nThis line looks so lonesome (and possibly duplicated)\n. \n. What version of Octokit.net are you using?\nEDIT: reproducible with 0.2.1 from NuGet - let's see if i can get this into an integration test\n. Ok, so we overlooked something with the JSON that wasn't caught with the code we wrote previous:\n\nI had a bash at switching over to a new response type here https://github.com/octokit/octokit.net/pull/412\npublic class SearchRepositoryResult\n    {\n        public int TotalCount { get; set; }\n        public IReadOnlyList<Repository> Items { get; set; }\n    }\n}\nBut our build of SimpleJson doesn't deserialize read-only collection properties :cry:\nping @hahmed @alfhenrik \n. @haacked :cool:, i'll test this out here \n. This fix has been published in Octokit v0.2.2\nhttps://www.nuget.org/packages/octokit/0.2.2\n. Removed [WIP] tag, ready for review\n. I'm not sure what I was asking for here. I'll close this until someone else cares enough to translate.\n. @Haacked you're right. I'll focus on the API changes.\n. I've also opened:\n- #424 to address a muted test\n- #423 to surface new validation messages when creating a repository\n. This is live:\nhttps://www.nuget.org/packages/octokit/0.2.2\nhttps://www.nuget.org/packages/octokit.reactive/0.2.2\n. You've got two options when listing issues - for the current user:\nvar issues = await _github.Issue.GetAllForCurrent(request);\nBut this doesn't let you filter on specific repositories - you could do the filtering on the client-side though, but that's not great.\nThe alternative is to use GetForRepository above and filter by username:\nhttp://developer.github.com/v3/issues/#list-issues-for-a-repository\n\nassignee: Can be the name of a user. Pass in none for issues with no assigned user, and * for issues assigned to any user. Default: *\nmentioned: A user that\u2019s mentioned in the issue.\n\nBut those aren't surfaced in our current version of Octokit.net - bah humbug...\n. @rprouse this fix has gone out in the v0.3.0 release\n. What even are cultures. Thanks for the patch.\n\n. Addresses one of the features in #333\n. Right, review away\n. @hknielsen I have integration tests in here which use the live real API.\nI'm happy to refine that model in another PR, just wanted to flag the possible duplication here.\n. Added task to update commit model returned from API\n. @hknielsen all good, I've made that change here. \nLet me know if there's anything else I've overlooked here...\n. Let everyone sleep on it. I don't think there'll be any sudden issues...\nOn Wed, Mar 19, 2014 at 9:33 PM, Harald Kj\u00e6r Nielsen \nnotifications@github.com wrote:\n\nWhen will this get merged?\n\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/pull/428#issuecomment-38027472\n.\n. @Haacked should be all sorted, let me know if I've missed anything...\n. Come back QED we miss you cc @half-ogre \n. @half-ogre :heart: was mostly curious why the build was marked as red when it was some trivial refactoring, but now it's green I can sleep at night!\n. Leaving this marked as [WIP] while I review the PCL changes proposed here: https://github.com/octokit/octokit.net/pull/401\n. @paulcbetts it's basically a toolchain issue forcing this upgrade. \n\nI'm not a huge fan either, I'd rather switch to the PCL projects but that's A Big Change Also.\n. @adamchester if that's the case, this change becomes hella simple. \nLet me know how that goes and I'll rework this PR to suit.\n. > (which I'm running as we speak... perhaps part of the problem was a missing VS setup feature?)\nI think this is something that @paulcbetts has hit with ReactiveUI (he's using VS2012 due to not wanting to upgrade like this). I wonder if there's a way we could script this as part of a bootstrap experience...\n. And by \"script this\" I actually mean\n- check you have VS2012 or VS2013\n- if you only have VS2013, run the same commands to install the compatibility tools\n. @adamchester thanks for digging deeper\n\nI'll tweak this PR so we only add in those GUIDs and re-test on my end.\n. \nSo despite this lovely warning from VS, I can build the solution in VS and run the tests under .\\build - which seems to be a fine compromise...\n. Rewrote PR description to make the bad ideas go away.\nUpdated title.\nRemoved [WIP] description.\n. @adamchester looking forward to it\n. > Is there some reason to keep the RX references targeting net40?\nNo, likely just some legacy NuGet stuff.\n\nIf there is a reason, then according to this link, we could probably remove the requiresReinstallation attribute, to remove the warning.\n\n:thumbsup:\n. @adamchester is there anything in particular left to work on with this?\n. Just needs a merge/rebase on top of master and this is good to :ship:\n. Thanks for the patch!\n\n. There's definitely some overlap between this and #428 \n. > I moved GetReadme and GetReadmeHtml to the new IRepositoryContentsClient to reflect the API better and obsoleted the old methods.\n:thumbsup:\n\nAlso, if you want me to strip the first commit (changed RepositoryComments to Comments and PullRequest to PullRequests), please shout out.\n\n:thumbsup:\n. > @shiftkey Does that :+1: mean that you want me to strip the commit? :stuck_out_tongue_closed_eyes:\nMy bad, pre-coffee me can be unclear. No, that's fine as-is.\n. @khellang :thumbsup: to keep going\n. @khellang let's do the simplest thing that could possibly work and iterate from there\n- implement a Get which takes a path and returns a file\n- if the response is a collection (how to check this depends on the implementation), Get should throw to indicate the path is not a file\n- implement a GetForDirectory which takes a path and returns a list of items\n- if the response is an item, GetForDirectory should throw an exception to indicate the path is a file\n- other bad things happen due to misusing the API, just bubble them up to the user\nHow does that feel?\n. > if the response is an item, GetForDirectory should throw an exception to indicate the path is a file\nOne note on this, you can tell it's an item based on the content property:\n{\n  \"type\": \"file\",\n  \"encoding\": \"base64\",\n  \"size\": 5362,\n  \"name\": \"README.md\",\n  \"path\": \"README.md\",\n  \"content\": \"encoded content ...\",\n  \"sha\": \"3d21ec53a331a6f037a91c368710b99387d012c1\",\n  \"url\": \"https://api.github.com/repos/pengwynn/octokit/contents/README.md\",\n  \"git_url\": \"https://api.github.com/repos/pengwynn/octokit/git/blobs/3d21ec53a331a6f037a91c368710b99387d012c1\",\n  \"html_url\": \"https://github.com/pengwynn/octokit/blob/master/README.md\",\n  \"_links\": {\n    \"git\": \"https://api.github.com/repos/pengwynn/octokit/git/blobs/3d21ec53a331a6f037a91c368710b99387d012c1\",\n    \"self\": \"https://api.github.com/repos/pengwynn/octokit/contents/README.md\",\n    \"html\": \"https://github.com/pengwynn/octokit/blob/master/README.md\"\n  }\n}\n. @thedillonb signs point to no. \nI think it has a way to go anyway, because we were still discussing how the API should look even then...\n. @drusellers I'm going to see if I can spend the next couple of weeks on clearing out the backlog of PRs - see the next major release here https://github.com/octokit/octokit.net/milestones/v0.6%20-%20Chocolate-Covered%20Yaks\nThis one didn't make the cut because I'm still not sold on the API. I need to think on this some more before I can work out a way through it. Let me know if this is something that you're interested in contributing to, and I'll bump it up my priority list to revisit.\n. @khellang will you be at Summit? If so, that'll give me a hard deadline to put pen to paper... :stuck_out_tongue: \n. Dropping this from the VS2015 milestone - we're still waiting on upstream support for DNX Core from Rx.NET\n. Nice :eyes: there @Haacked!\n. Am I understanding this right - you're posting to a custom API with this FullIssue entity, which is then propagated onto the GitHub API? With the Markdown and the rendered HTML?\n. Right, I misread the context. My bad.\nThis all seems rather legit. Is it worth throwing any tests into the mix?\n. > an optional overload to the /repos/:owner/:repo/statuses/:ref endpoint which accepts a context\nDone\n\nan overload to /repos/:owner/:repo/commits/:ref/status which returns the collection of statuses (don't deprecate the existing endpoint)\n\nI'm not going to implement this. One Way To Do The Job or something...\n. :sparkles: :sparkles: :sparkles: thanks for confirming @pengwynn \n. Say the word and I'll shut it down. But it was entertaining to correlate the data I saw with the subsequent API responses...\n. @jspahrsummers perhaps, but that's still a second API call to make\n. https://github.com/octokit/octokit.net/pull/434 is what you want, but it's not quite ready yet. :soon:!\n. @bursteg that'd be greatly appreciated! How different is it to what's been done in #434?\n. @Roman1991 this was added in https://github.com/octokit/octokit.net/pull/649 which was released in v0.6.2\n@bursteg I'm not sure if you were referring to Get a Blob - which uses the Git object SHA for lookup, or Get Contents which lets you specify the relative path to the file.\nIf you think there's something that can be improved in the BlobsClient feel free to add some more details here or discuss this in a PR.\n. Thanks!\n. \n. I'm gonna merge this in and see if I can help out with QED stuff next week.\n. I think you're hitting on a permissions issue here.\nCan you try this snippet here (replace with the right details, of course) to see if you can reach the /repos/:owner/:repo/releases endpoint (instead of a specific release as you've been doing in the above case):\nvar client = new GitHubClient(new ProductHeaderValue(\"appName\"));\nclient.Credentials = new Credentials(login, password);\nvar releases = client.Releases.GetAll(\"owner\", \"repo\").Result;\nIf that one is also returning a 404, I'd recommend contacting GitHub Support so we can troubleshoot further...\n. > I got 304 Not modified and an empty JSON array.\nNot sure about the 304 Not Modified (that could just be browser headers triggering caching) but the empty JSON array makes me think the repository doesn't have any releases associated with it - which means trying to get /repos/:owner/:repo/releases/1 is properly failing as expected - because the release doesn't exist...\nDoes that make sense?\n. I need more information about the scenario that's triggering this - can you email support@github.com with some details so we can discuss this further?\n. Ok, so as we found out, the answer for this specific repository is to fetch the tags instead:\nvar client = CreateGitHubClient();\nvar tags = await github.Repository.GetAllTags(\"octokit\", \"octokit.net\");\nAssert.True(tags.Any(t => t.Name == \"v0.1.0\"));\nRelevant docs: https://developer.github.com/v3/repos/#list-tags\n. IObservableTeamsClient and ObservableTeamsClient need to be updated to also drop the Team prefix from their methods.\nAside from that this is looking :gem: :gem: :gem:\n. Given how much we actually depend on this, this seems like a good thing.\n@haacked @trsneed thoughts?\n. @Haacked yeah, that's what my brain meant to say\n. I'm 99% sure this is a deserialization issue.\nIs this against a public repository I can test against?\n. So the source for that is here (I'm fairly certain we're using the latest bits, if not that's easy to fix tomorrow):\nhttps://github.com/facebook-csharp-sdk/reflection-utils/blob/master/src/ReflectionUtils/ReflectionUtils.cs#L91\n. Well now I feel like a clown. \nIf you don't send me a PR I'll do it in the morning (and ship a release). :cool:?\n. My psychic debugger suspects this is a Debug/Release mode issue and that we only did it for Debug configurations\n. Looks like we're finally running integration tests and Bad Things Are Happening.\nI'll test locally tomorrow and publish a new release if it's all clear.\n. Nudge nudge, wink wink: https://xunit.codeplex.com/workitem/9747\n. Also, this is still a thing to be wary of with our current Appveyor setup...\n. I've looked into enabling parallel builds with xUnit 2 but am hitting some issues with the integration tests running in parallel. My psychic debugger thinks this is related to contention with making requests to the same remote server...\n. Just tested this out, and it does shave off a couple of seconds:\nBefore\n```\n=== TEST EXECUTION SUMMARY ===\n   Octokit.Tests  Total: 1026, Errors: 0, Failed: 0, Skipped: 0, Time: 8.756s\n   Octokit.Tests-NetCore45  Total: 588, Errors: 0, Failed: 0, Skipped: 0, Time: 5.373s\n   Octokit.Tests-Portable  Total: 588, Errors: 0, Failed: 0, Skipped: 0, Time: 5.332s\nUnitTests   00:00:41.2409233\n```\nAfter\n```\n=== TEST EXECUTION SUMMARY ===\n   Octokit.Tests  Total: 1026, Errors: 0, Failed: 0, Skipped: 0, Time: 5.372s\n   Octokit.Tests-NetCore45  Total: 588, Errors: 0, Failed: 0, Skipped: 0, Time: 3.219s\n   Octokit.Tests-Portable  Total: 588, Errors: 0, Failed: 0, Skipped: 0, Time: 3.240s\nUnitTests   00:00:40.7780810\n``\n. Running the tests in the new VS test runner suffers the same problem as the command line, so I'd like to get to the bottom of this issue. But I can work around it in the meantime and run batches of tests...\n. Still occurring on master, let's discuss it over on #477 \n. :shipit:\n. @nigel-sampson let me know if you're happy with this change. The build failures are related to unrelated tests - I won't have a chance to look into them until after the holiday break.\n. Looking great so far. Just needs theObservable` version to make the convention tests pass...\n. @JacobCZ we've got a suite of integration tests which we use to test the library against the API.\nWhat would you like to see in terms of documentation? \n. Something that'd be even easier to do (and portable to either a wiki or a gh-pages site) would be just a set of Markdown files under docs. Seem legit?\n. @Papalamus this seems to have been overlooked. I've opened https://github.com/octokit/octokit.net/issues/686 to track adding it to the API\n. Not sure why I didn't raise this sooner, but I like how ReadTheDocs does this. Here's ReactiveUI's as an example: http://reactiveui.readthedocs.org/en/latest/ - and the relevant PR - https://github.com/reactiveui/ReactiveUI/pull/771\nThis is slightly different from the gh-pages approach for a couple of reasons:\n- it's markdown'd already - we've got some docs as a starting point\n- docs are alongside the code - easier to keep things in sync than with Pages\n- docs use tags to represent versions - we don't get this for free with a vanilla Pages site\nFor style and stuff we can work on that after getting something going - I just feel this is a better starting point that a vanilla pages site.\n. > Would we care too much about having documentation for different versions for octokit.net?\nIt's something you get \"for free\" if you're tagging releases (like we are) - so I don't see it as much work for us.  But yeah, it's a minor bonus.\n. @hahmed yeah, I should have some time to set up the basics tonight.\nIdeally it should just keep redeploying off of webhook activity for a certain branch.\n. Due to the . in the project name :cry: the URL it gave me is http://octokitnet.readthedocs.org/en/latest/.\nGonna set up the other bits now and open a brief PR to get things going.\nEDIT: look at that, it's automatically picked up the existing docs. Glorious :sparkles:\n. @hahmed I've opened up #948 to track this work. There's a whole bunch of details here about the mkdocs format (which we're using here): http://mkdocs.readthedocs.org/en/stable/\nHappy to discuss things in PRs targeting the documentation branch, and we can just iterate on stuff quickly while we get a feel for what this might look like.\n. It's the second parameter:\nvar client = new GitHubClient(new ProductHeaderValue(\"OctokitTests\"));\nclient.Credentials = // TODO: authenticate\nvar releaseWithNoUpdate = new ReleaseUpdate(\"0.1\") { Draft = true };\nvar release = await client.Release.CreateRelease(\"owner\", \"someRepository\", releaseWithNoUpdate);\n. Yeah, you're probably right. \nI'll address those integration tests in another PR.\n. @Haacked the tests now fail for a different reason (malformed URL not returning results) rather than the NullReferenceException which was previously occurring. I don't think it's worth spending more time on this fix.\n. Oh, right. I'll add a unit test to catch this regression...\n. So that last failing test is this one:\nPullRequestsClientTests.CanBeMerged [FAIL]\n   Octokit.ApiException : Pull Request is not mergeable\nAnd that's unrelated to all this. If it's still occurring after the merge I'll log an issue and investigate.\n. :thumbsup:\n. Thanks!\n. Skimmed the FAKE docs and couldn't find it documented.\n@forki have you had this requested before? Would you like a PR?\nThe docs are plain and simple: pass -Symbols to nuget pack\n. But that option requires using a project file. It should also support just providing a nuspec file, right?\nnuget pack MyPackage.nuspec -Symbols\n. @forki all good. Once I've levelled up my F#-fu I might take a swing at it. \nBut for now I can workaround it  by using a plain old nuspec.\n. With #602 merged into master, I'm going to close this out. \nI could create a specific symbols package and publish it to symbol source, but the fact that this now works without configuring symbols I'm happy to call this done...\n. Haven't seen this one in a while.\n. Totally legit.\nSend in a PR if it's really getting on your sensibilities :grinning:\n. Right, it looks like @paulcbetts has conflicting feels on this.\n@GavinOsborn I'll let you and him duke it out in that PR about the right way to do things...\n. \nPR incoming\n. I believe the ApiValidationException is being raised because the release doesn't exist (or it doesn't match with an existing release).\nEither you need to create the release first:\nvar data = new ReleaseUpdate(\"my-cool-release\");\nvar release = cli.Release.CreateRelease(\"some-user\", \"some-repo\", data);\nOr retrieve it from the API:\nvar allReleases = releasesClient.GetAll(\"some-user\", \"some-repo\");\nvar release = allReleases.Last();\nThe id field on the release is what you need to then start uploading release assets.\n. Are you able to run Fiddler and share with me the raw request/response data? You can scrub anything that might be sensitive (the payload, for example) but I need more details to understand the situation...\n. EDIT: So the implementation is fine, you just need to move the stream back to the start:\nStream str = new MemoryStream();\nvar _bytes = File.ReadAllBytes(ReleaseZipPath);\nstr.Write(_bytes, 0, _bytes.Length);\nstr.Seek(0, SeekOrigin.Begin);\nIf you don't do that, the library will start reading from the end of the file.\n. @adamralph thanks for following this up\n. If I'm up at 2:30am I'd certainly keep an eye out for it :trollface:\n. @adamralph nope, in Australia at the moment (UTC+10)\n. Just to echo what @khellang said - the profile isn't the best place to look for their email address, because it might be private. I hope we deprecate that in the future.\nInstead, use the User Emails endpoint, as this gives you significantly more context. We let users specify multiple email addresses so their commits can be associated to their account.\n. @Mariowukunkun we've tried supporting .NET 4 in Octokit in the past, but have stopped doing it for a couple of reasons:\n- we're not fans of the Microsoft.Bcl.Async magic that's used to bring async/await back to .NET 4\n- we're deprecating .NET 4 support for other projects we look after, because of lack of demand\n- the combination of .NET45 + PCL + Mono* support is enough coverage over modern platforms\n. Ready for review :lollipop: \n. Seems reasonable. Let me pull it down and test it out!\n. > My bad, fixed quickly all the Resharper's warning.\nI think this is just the .csproj being configured incorrectly and R# getting over-enthusiastic! \n. \nThanks for the contribution!\n. Well, I Am An Idiot...\n\n. \nGreat stuff @gabrielweyer!\n. \n. > Is this pull request dead or is it still expected to be merged?\nIt's not mergeable in it's current form, so some more work is necessary on top of the current tasks.\n\nIs it only waiting for integration tests that are missing before it can be merged?\n\nAs above, there's been a lot of change since this PR was last worked on.\n\nWhere is the code located, so that the tests can be added, if they are only the missing prerequisites?\n\nYou can find the branch here: https://github.com/johnduhart/octokit.net/tree/pr-313\nEDIT: here's some CLI magic to get your hands on this branch\ngit remote add johnduhart https://github.com/johnduhart/octokit.net.git\ngit fetch johnduhart\ngit checkout pr-313\n. At this stage we're not looking to support .NET 4 - there's some details here on the why of doing this:\nhttps://github.com/octokit/octokit.net/pull/489#issuecomment-43387381\n. I can't accept this PR in it's current form for a couple of reasons:\n- this PR cannot be merged into master in it's current form - it's waaaaaaay out of date!\n- Microsoft.Net.Http is already available under packages\n- it's adding references to .NET 4.5 projects that don't require it.\nThere's a couple of ways forward if we want this in. The first is to add a standalone project for Octokit targeting .NET4. You can see the other platforms it targets are listed here.\n\nThe Octokit project is the reference project, targeting .NET 4.5, with other projects added to target specific platforms.\nThe second way is to update the Octokit.Portable project to target .NET 4 too. It already uses Microsoft.Net.Http, and so needs some shims to replace the missing behaviour.\nI think the second option is an easier way to do this.\n. That feature is so far from ready it's not funny...\n. @FeodorFitsner  :heart_eyes: :heart_eyes: :heart_eyes: :heart_eyes: :heart_eyes: \nYeah, I'm not going to look into porting over those tests at the moment. I'll look into it in a future PR.\n. > I don't think it make sense to submit PR for v1.9, but I hope to make 2.0 through. In the meantime, we'll publish our version of xUnit to GitHub with runners on nuget.org.\nYeah, I'd certainly like to see if xUnit 2.0 would take those patches. \n. @FeodorFitsner mind if I email you through a few GitHub-related feedback things? (the email address on your profile, that is)\n. List all pull requests is the problem one.\nAnd indeed, using MergedAt.HasValue instead is the workaround.\nLet me see if I can't fix the backend myself so I don't need to update the client.\n. :star: \n. Found myself looking at Mergeable again for a side-project - turns out the list of pull requests doesn't return the field, and it's now computed on-the-fly:\n\nThe value of the mergeable attribute can be true, false, or null. If the value is null, this means that the mergeability hasn't been computed yet, and a background job was started to compute it. Give the job a few moments to complete, and then submit the request again. When the job is complete, the response will include a non-null value for the mergeable attribute.\n\nWill test against the latest release and see what else needs to be done. Closing out as \"alot of time has passed\".\n. Possibly related to https://github.com/octokit/octokit.net/issues/352\n. Going to move this to post-v1 as I think this is hard to do without impacting existing APIs\n. > I'm currently using the former in some test code - but doesn't feel correct to add to a PR.\nI think 1) is going to be a more maintainable solution in the long-term. The other solution means deserializing becomes a two-step operation (read the content, then read the headers). Would love to hear your concerns.\n. As this requires significant thought - and likely significant changes to the API responses - as well as there exists the ability to get this data using IGitHubClient.GetLastApiInfo() I'm happy to close this out for now.\nI've opened https://github.com/octokit/octokit.net/issues/1142 to add some documentation for this feature before I forget.\n. Taking this off my radar for the foreseeable future.\n. > Should this go in the main Octokit package or perhaps a special samples package?\nThe general guidance from the Linqpad site is to contain them in the main package:\n\n\nUpdate your NuGet packing script to copy your samples into a folder called linqpad-samples.\nAdd the linqpad-samples tag to your NuGet submission to ensure free access.\n\n\nI gather this means the user will have them automagically after installing (rather than digging around for a second package). The site says you can have a separate package - if you're so inclined - but I'm not sure of the harm here if we do keep it all in one spot. \nAlso, I'm not sure what that last step means. \n. I think you're probably right.\nWant to throw some tests in here around editing a release, to confirm it?\n. You have the power!\n. > I just wasn't sure how unstable the API is.\nThe release APIs haven't changed in a while, and anything in the pipeline will be handled in the same way we do previews for new features or breaking changes (opt-in).\n. @distantcam it's because of the WinRT projects (they're targeting 8.0 still, but minor detail).\nI'm happy to do the PR testing on that OS if you don't have it, and we're rolling out the ability to do CI for those platforms :soon: so it'll catch things up front.\n. Once this is merged in I'll create a new release...\n. Squashed and merged in at 5f1a3fd9bb8a3630023e4a21ee1301b8ba3b0ab2\n. @haagenson welcome!\n\nHave most of you changed to VS 2013 locally and just not checked in?\n\nYes, but there's not really much to check in. One could make the projects/solution VS2013-only, but there's only been a couple of things that restrict us supporting VS2012 as well. \nIf you find there's changes we should be making (given VS2013 Update 2 has just dropped) then I'm happy to review a PR about it. For example, this could be worded better :wink:\n\nThe next problem I'm running into is during the code analysis against the octokit.portable project. For some reason, it is failing to output the results to the code analysis xml file. \n\nThe combination of Portable Class Libraries + Code Analysis just didn't work in VS2012. This is why we went to targeting VS2013 - because they fixed it there.\nLet me know if there's any other specific questions you have.\n. @schani that's interesting. We're using SimpleJson for this so perhaps we should also publish it there...\n@prabirshrestha have you seen this before? would you like it sent upstream?\n. @schani do you have a (regression) test which causes this to fail? \nI'd like to see this for myself and capture it for posterity.\n. @schani thanks, I'll do some digging into it to see if we can address this without needing to update SimpleJson...\n. Ok, so the problem comes down to this line:\n\"hireable\": null,\nThat doesn't map to a bool field - so :boom: :boom: :boom:.\nAs an interim fix, I'll make this field nullable so it works on both the platforms.\nI'll see if I can get this fixed in the actual API for a future release, because it really should return false for organizations...\ncc @pengwynn \n. As this isn't an issue with SimpleJson, I've opened #522 which fixes the bug.\n. @forki thanks! \nRemind me to shout you a :cocktail: next time we cross paths, as a thank you for keeping on top of this!\n. Turns out we specifically strip null values when serializing. Ho hum.\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Http/SimpleJsonSerializer.cs#L31\nAnd at that point we already have the mapped JSON properties (instead of the .NET properties) so my trick of using an opt-in attribute to indicate when the null should be set doesn't work.\nHopefully I'm just missing something about the IJsonSerializerStrategy \n.  cc @Haacked @prabirshrestha for their thoughts on this\n. Here's the spike: https://github.com/octokit/octokit.net/compare/unassign-issue-from-milestone?expand=1\n. > Here's what I propose. Let's add an attribute called [AlwaysInclude] or something like that. If that attribute is on the property, we always include it in the serialized JSON. This code path is under our control.\nThat's the path I went down, but the point where we ignore the null values is too late in the pipeline for us to reflect over the input object and look for annotations like this...\n. \nIt's not the .NET types we're using here, so the custom attributes from the property are not brought across :crying_cat_face: \n. \n. You're using the Search APIs here, but there definitely needs to be the All enum defined here:\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Models/Request/IssueRequest.cs#L71\nIf you're feeling courageous, you can submit a pull request to fix that and add a test here to show the All flag is used correctly:\nhttps://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/IssuesClientTests.cs\nI'm happy to review and help you get started.\n. @farezv you're right, it's been fixed!\n. The search APIs are slightly different to the the issues API.\nhttps://developer.github.com/v3/search/#search-issues\nIf you don't specify the State value, you'll get both Open and Closed issues.\nYou can test this out using Caliburn.Micro again:\n```\nvar request = new SearchIssuesRequest(\"phone\");\nrequest.Repo = \"caliburn-micro/caliburn.micro\";\nvar issues = await _gitHubClient.Search.SearchIssues(request);\nAssert.NotEmpty(issues.Items.Where(x => x.State == ItemState.Closed));\nAssert.NotEmpty(issues.Items.Where(x => x.State == ItemState.Open));\n```\n. :monkey:\n. \n. > Is there a preference to how I implement that portion @shiftkey / @haacked?\nSituations where I think it should be parameters in the method:\n- small number of parameters\n- all the parameters are required\n- the parameters are used in the URL, rather than the request payload\nIn this case, not all of the parameters are required, so I think having a CommitRequest parameter is totally fine here...\n. If you can just merge master into this branch, see the tests run (and probably fail) again - and perhaps tidy up that last line, I'm happy to merge it in...\n. \nThanks for the contribution @haagenson! \n. > The current implementation is only an in-memory store.\nI think that's a \"good enough\" option for now for our use case, but perhaps down the track someone might want to implement their own backing store for it (imagine a service who wants to push that memory usage out of process, for example).\n. \n. Status update: I'm ranting and raving over in #781 about first class support for HttpClient/HttpMessageHandler - once I get that right I think this will be trivial to add - and I already have crazy ideas in my head about how to do it...\n. @darrelmiller so if I head down the road towards something like this does that make your life easier or harder?\n. These failing tests are unrelated to the current PR:\nUserKeysClientTests.GetAll\nObservableRespositoryDeployKeysClientTests.CanRetrieveADeployKey\nRepositoriesClientTests+TheCreateMethodForUser.ThrowsPrivateRepositoryQuotaExceededExceptionWhenOverQuota\nAside from that, this is ready for review...\n. No idea who set that up, but :thumbsup: to removing it.\nI know we were able to reach someone who does maintenance on these servers to get some stuff installed, but I've completely forgotten who it was. For some reason I think @paulcbetts and @dtchepak might know...\n. @ajepst are you able to archive that build? It's no longer (or never?) been used, so it's just wasting space and resources over there...\n. \nThanks @ajepst! \n. ThrowsPrivateRepositoryQuotaExceededExceptionWhenOverQuota and UserKeysClientTests.GetAll are likely due to the account used, the other is more concerning...\n. If these aren't being skipped when running CI, they will be :soon:\n. Right, that makes me feel less terrible\n\n. So the build for the commit failed for an unrelated reason: \nhttps://ci.appveyor.com/project/Haacked15676/octokit-net/build/1.0.117\nBut the build for the merge commit succeeded:\nhttps://ci.appveyor.com/project/Haacked15676/octokit-net/build/1.0.118\nAnyway, it's Friday and the beers are beckoning. I'm calling this :thumbsup:...\n. \n\nAnd added an #if around using in RequestParameters.cs\n\nNice spot! I haven't seen this come up when building in Xamarin Studio but totally a nice thing to have here.\n. The Search APIs require a search term, so that's obviously not what you're looking for.\nIf you know what repository you want, the Issues API will do the trick:\nhttps://developer.github.com/v3/issues/#list-issues-for-a-repository\nvar client = new GitHubClient();\n var issues = await client.Issues.GetForRepository(\"owner\", \"repository\",\n            new RepositoryIssueRequest {  });\nHowever we've found https://github.com/octokit/octokit.net/issues/517 which means you can't search for \"All\" issues at the moment.\n. @Sebyd that's an integration test I've seen fail infrequently - I'm less concerned about that as it's not related to the current changes...\n. @haagenson apologies for letting this languish and ignoring the CI issue (which looks like an intermittent issue). Thanks for submitting it.\nI've dusted this code off, updated it to our latest conventions and APIs and reopened it as #794. \n. @kevfromireland if you can include an integration test (and Skip it with a note) so we can see what it should do, I think that's good enough for now...\n. Resolved via #546\n. Octokit will target v3 of the API by default (see https://github.com/octokit/octokit.net/blob/master/Octokit/Http/JsonHttpPipeline.cs#L32) but when we pull in a preview feature we'll opt-in to the feature using a new header, like this https://github.com/octokit/octokit.net/blob/master/Octokit/Clients/DeploymentStatusClient.cs#L15. For everything else, it should just work.\nI've started on some docs explaining how to get started with Octokit here: https://github.com/octokit/octokit.net/blob/shiftkey-patch-1/docs/getting-started.md but the basics is that you just specify the server to connect to:\nvar ghe = new Uri(\"https://github.myenterprise.com/\");\nvar client = new GitHubClient(new ProductHeaderValue(\"my-cool-app\"), ghe);\nIf you're seeing some weirdness with the responses from your GitHub Enterprise server I'd love to hear more details - what's not working, what the request/response headers look like, etc.\n. We don't have any plans, but there are a number of Python libraries out there to interact with the GitHub API - check the list here:\nhttps://developer.github.com/libraries/\nI'd check out PyGitHub - that seems to be available for Python 2 and 3 and targets v3 of the API...\n. Due to an outstanding bug when using Portable Class Libraries + Code Analysis (it would throw a StackOverflowException), we no longer support building Octokit on VS2012.\nI'm not sure why the BNB platform is being selected in that first screenshot, but I'd highly recommend getting your hands on VS2013 if you can.\n. :thumbsup: to merging the two tests together.\nI actually like CanListClosedIssues better as it tests an issue is ignored, but totally up to you...\n. hey @haacked how do you feel about this change?\n. :thumbsup: on moving it into the abstraction.\nThe other part of me is thinking that we could(should?) isolate this to just releases itself, rather than make it global.\nI haven't had a chance to look at how this would look (or how hard it'd be to plug in)...\n. Going to close this in favour of whatever we agree on in #587 - thanks for starting the discussion @Arakis \n. \n. Oh man, this looks amazing :sparkles: :heart: :metal: Sorry for not looking at this earlier!\n. Yeah, I've been fighting with the CI builds recently and it comes down to the integration tests. At this point I'm just going to pull them because they're more trouble than they're worth.\n. This looks pretty great! Just that coding convention issue - you can see this issue by running the ConventionTests project.\nOnce that's in I'll rebase this on top of release-0.6 and send it out to the world!\n. Merged in here: 06e8616fa0eaca373d4167bdd7ff6001553f6ecc - should go out in v0.5.3\nThanks!\n. No particular reason, I suspect they just weren't of interest to those who were contributing to it...\n. Just remove that Size parameter and I'm happy to merge this in!\n. Thanks! \n\n. Looking good, just some minor feedback and questions...\n. @thedillonb\n\nI'm only adamant about the PATCH stuff because when I created CodeHub for iOS I found that if the fields were not completely nullable then I had to make a initial request to get the data so that I could set the non-nullable fields on the update request.\n\nThat's a great point - I have been designed the update flow for these components based on the assumption that the old data is readily available. \nI'm just trying to figure out the best way to incorporate these changes - I love that we're staying close to the API conventions, I'm just trying to keep in mind the developers who are coming upon this API for the first time. \n. I hit something similar a while ago with https://github.com/octokit/octokit.net/issues/516. TL;DR: there's some times when we need to send null on a PATCH, but they're very rare - and we have those hooks now.\n. I've cherry-picked this into the next release https://github.com/octokit/octokit.net/pull/591. \nThanks for the hard work and great discussion!\n\n. @thedillonb apologies, I'm looking to put together another release later this week - I'll make sure we get that back in https://github.com/octokit/octokit.net/issues/715\n. @thedillonb at least this time I'll make sure to keep a regression test around for Future Me to ensure I remember this :trollface:\n. We've actually made a start on the documentation under the docs folder:\nhttps://github.com/octokit/octokit.net/tree/master/docs\nYou can see a writeup about how Releases work here:\nhttps://github.com/octokit/octokit.net/blob/master/docs/releases.md\nFor those things that aren't covered by docs, we've got a suite of integration tests which should demonstrate how other areas of the library work:\nhttps://github.com/octokit/octokit.net/tree/master/Octokit.Tests.Integration/Clients\n. Not sure why that build is failing, but the build script is happily passing on my machine.\nI'll dig into that later.\n. Resolved in #576 \n. We don't have specific helpers for doing error reporting, but this is a rough script that could do the job:\nvar client = new GitHubClient(new ProductHeaderValue(\"New\"));\nclient.Credentials = // needs to authenticate to create an issue against the API\nvar body = \"put the exception details here\";\nvar newIssue = new NewIssue(\"CurrentDomain_UnhandledException report\")\n{\n    Body = body\n};\nvar issue = client.Issue.Create(\"owner\", \"repo\", newIssue).Wait();\n. You can't create ad-hoc labels, but you can add existing labels when you create an issue:\nvar newIssue = new NewIssue(\"CurrentDomain_UnhandledException report\")\nnewIssue.Labels.Add(\"bug\");\n...\n. @Haacked this is for the Releases API\n@distantcam I've not seen anything documented about size limits here: https://developer.github.com/v3/repos/releases/#upload-a-release-asset so i'm now looking behind the scenes for more information...\n. Right, so it sounds like we need to merge https://github.com/octokit/octokit.net/pull/554 in\n. @distantcam can you sit Fiddler in between and see that it's not an exception from the backend you're seeing (i.e. that it actually times out)?\n. :cool: so we know where the problem lies at least\n. Addressed indirectly in #587 which went out in v0.5.3\n. Not sure why I missed this initial discussion, but here's my thoughts:\n- why are we doing this? to let those who want to manage their dependencies by hand do bypass NuGet\n- don't bother with PDBs or other files, just the binaries\n- the root folder should contain the platform flavours, with Octokit.dll and Octokit.Reactive.dll (if applicable) in place\n- the PR just uploads Octokit.dll, which might not be suitable for non-desktop apps\nI'm not sure of the demand for this for non-desktop apps, so I'm happy to just start with a net45/Octokit.dll zip file if that makes your situation easier to work with...\n. Taking this off my watch-list. @forki feel free to get in touch if you want to revive this idea.\n. @forki apologies for that - the class itself is in the wrong namespace and so it was updated incorrectly when we changed the response models over to be readonly properties.\nIf you like I can revert that change for 0.7.1 which I was aiming to ship tomorrow my time.\n. I've opened up https://github.com/octokit/octokit.net/issues/721 to address this anyway - it's wasn't in the right location, which lead to the problem at hand...\nOnce I've dealt with some of the urgent issues (like Mono* support) and the other outstanding PRs, I'll come back to this. Thanks again for the initial spike.\n. @forki it's all good, I'm mostly annoyed at myself for not picking that issue (and also for letting the release languish for so long).\n. /khanify tests\n. The last outstanding issue is related to the AppVeyor build agent erroring out while updating the test results. I've raised a support ticket here to see if we can get it resolved:\nhttp://help.appveyor.com/discussions/problems/807-build-agent-reporting-communicationexception-when-updating-test-results\n. \n. I've captured https://github.com/octokit/octokit.net/issues/580 to make our API rate limiting a bit nicer when running CI (AppVeyor runs a build for the branch update and the merge commit for the PR) so this is exhausting our API limits damn fast:\n\nGonna merge this in and cut a release before I go completely insane...\n. Oops, yeah, that's an oversight:\nIf you're feeling courageous, you could add the xmldoc paths to each package and test out the result by running:\n.\\build CreatePackages\n. This will be published out in 0.5.1\n. Resolved by #575 - hoping to get this out in a new release this week \n. \n. The NSubstitute thing is unrelated, fixing it over here #572 \n. Thanks!\n. Hi @Sebyd - this is a good start, and there's more opportunity for contributions here if you're keen!\n. \nI can recreate this. Gonna add it to #572 \n. I've removed this method in #656 as it was no longer necessary.\nIf it comes back somehow I'll try and grab a Fiddler log of the problem\n. I already hit this as part of #572 - I just need to push through the last step and ensure the build is now green.\n. As soon as I can do that, I'll publish another release!\n. Can I get a :thumbsup: on these release notes @haacked?\n. This is live! https://www.nuget.org/packages/Octokit/0.5.0\n. To be honest, I'm happy to avoid all the \"JSON.net hell\" problems by internalizing our JSON dependency and doing a bit more work... \n. > Can you elaborate?\nJSON.NET has been around for many years now (I think it goes back to .NET v1.1) and over time it's become very popular, so popular that Microsoft is now using it in their web frameworks, instead of duplicating effort with the DataContractSerializer.\nIt's one of the most popular NuGet packages out there, and the downside to this is that many other packages depend on it. So when package A depends on version XYZ of JSON.NET, and package B depends on an different version of JSON.NET, you might get issues like:\n- unable to upgrade as existing/new packages depend on incompatible versions\n- strong naming issues (not so bad these days as the AssemblyInfoVersion is fixed for major releases)\nBut JSON.NET is relatively stable library these days at the core so you should be able to depend on the latest version and be happy, but I've been happy with using SimpleJson (and contributing some patches upstream for things I've needed) and the benefit of SimpleJson is that it's internalized, so it bypasses all the possible incompatibilities you might see when dealing with NuGet dependencies...\n. Closed in #581 \n. > I understand that the original code was able to serialize/deserialize list into comma separated values.\nTo be honest, I'm not so sure it ever did. It would deserialize if the value was an array: [ \"repository\", \"user\" ] but in this case it appears to have been a comma-separated list for the longest time: \"repository,user\". \nI've got a fix for this in https://github.com/octokit/octokit.net/pull/581 which I'll push out with v0.5\n\nAnother one is when deserializing a bool that can be null (It happens when receiving a webhook callback with mergeable property that is \"bool\" but had a null value in the payload). \n\nDo you have a sample test which will demonstrate this? I'd love to capture a regression test for it and review the webhooks part of the API for any others like it...\n. I'll close this out and review #584 when I get a chance :v:\n. JetBrains doesn't support xUnit in-the-box, but you can find the addin here: http://www.jetbrains.com/resharper/plugins/\n. Looking good, just a bunch of little things. \nI'd love some unit tests if it's possible to ensure we don't break things in the future.\n. > Sure, I will try to find some time to add tests. It was easier to test it directly from my app than to dig into how tests are organize in Octokit.\nFeel free to shamelessly borrow from the existing test suite. There's many examples under the Octokit.Tests/Clients namespace: https://github.com/octokit/octokit.net/tree/master/Octokit.Tests/Clients\n. Closing this PR in favour of #776 \n. Dropping this from the milestone, it's not a blocker\n. :boot: this one for now. If I get caremad enough I'll come back.\n. I didn't even get to include a rocking screenshot before it was merged? :stuck_out_tongue: \n\n. Putting this to [WIP] until I get feedback that this approach feels right...\n. I'm not hearing any objections from the crowd on this one? Is this thing on?\n. @Haacked \n\nShould we allow changing it after the Connection has been created?\n\nAs in overriding a hypothetical IConnection.Timeout property? Perhaps. That would be relatively easy to expose if you want to do things more granularly.\n\nSetting the timeout for all requests is ok, but I think it would be more useful to set a timeout for a specific upload call, as it may be significantly larger than the default for other calls.\n\nSure, but what's the harm in doing this globally? I'd love to avoid over-complicating this API, I just wish I had a second example to go alongside uploading assets to say doing it globally is a saner approach.\n\nAlso, again specific to uploads, is it worth setting the timeout to null?\n\nOK, this one interests me. HttpClient.Timeout isn't a nullable TimeSpan but you could just pass it TimeSpan.MaxValue and achieve the same effect...\nPerhaps that's the compromise here, so you can do this sort of code:\nvar client = new GitHubClient(new ProductHeaderValue(\"my-cool-app\"));\n...\nclient.Connection.Timeout = TimeSpan.MaxValue;\nvar asset = await client.Release.UploadAsset(release, assetUpload);\n@distantcam do you keep the GitHubClient around for multiple actions? Or would you dispose of it after the uploads are done?\n. @distantcam fair enough, I've got a couple of ideas for isolating it just to Releases. I'll see how they feel.\n. Alright, how does that test look and feel? \nhttps://github.com/octokit/octokit.net/pull/587/files#diff-eafe4a5f92fff13edb4d8f5110616c9eR206\n. > That ContinueWith gives me the heebie jeebies.\nYeah, it's Not The Best. Open to other suggestions to contain that side-effect.\nI don't want to be passing the timeout all the way through for the Post - perhaps there's some other pattern I can use here... \n. Ok, so I threw away all that previous work and went down the path of just making UploadAsset support overriding.\n@Haacked @distantcam let me know how that feels\n. :monkey: \n. :apple:\n. Some of the integration tests are failing, but I'm gonna take this in because I no longer trust my CI setup :cry:\n. :heart: \n. :heart:\n. :ok_hand: i'll clean those up. Thanks!\n. This is live https://www.nuget.org/packages/octokit/0.5.2\n. A historical example of this is around READMEs for a repository.\nYou can grab the raw Markdown like this:\ncs\nvar readme = await client.Repository.GetReadme(\"octokit\", \"octokit.net\");\nvar content = readme.Content;\n/// and some time later grab the HTML\nvar html = await readme.GetHtmlContent();\nOr just go straight to the HTML:\ncs\nvar html = await client.Repository.GetReadmeHtml(\"octokit\", \"octokit.net\");\nNow I'm not saying this is a good example, but I would definitely lean towards hiding away the HTTP plumbing and making it clear through the API what you're getting.\nAt a hand-waving level there's a couple goals I have in mind:\n- make it easy to discover where you can get different content types (lol Intellisense lol)\n- make it easy to switch between content types, without having to change your code significantly\n@thedillonb If you want to kick around some ideas, what did you have in mind for the client API? Are there things you think we should be doing differently?\n. So @ammeep and I just kicked around a couple of things and I noticed that the beta behaviour is no longer supported: https://developer.github.com/v3/versions/#beta\nWe don't actually lock the version to v3 anywhere in the codebase, so I think that's something we can/should do in the short term to ensure consistency.\nThere was also a gap in my reply that I didn't acknowledge which @ammeep raised about letting the user specify the Accept header. I'm not averse to trying that out, but given the usages are relatively specific (we know which endpoints support different media types, and it's mostly around content) we've avoided doing this up until now - or the contributors have been happy to just consume Markdown.\nI thought there was another place where we did this but I can't find a good example here to point to history. So I'm :cool: with someone proposing a better solution than what we've currently got. PR review comments might be a good candidate for this, as that API is done.\n. > We can easily support this without creating a whole new set of types to deseralize onto.\nThat'd be a good thing to test out before we dive into this - does our current deserializer support mapping \"body\" or \"body_html\" or \"body_text\" to the same CLR property?\n. WebRequest.GetSystemWebProxy and CredentialCache.DefaultCredentials aren't available for the PCL Profile259 or NetCore45 profiles we're targeting. Hmmm.\n. Yeah, there's a bunch of cross-platform headaches I'd need to solve here (for example, did you know WebProxy doesn't exist in NETCore45? Good times all round)\n. \n. Fixed in #608 and shipped in v0.6.0\n. Greetings, friend!\n. Would you be interesting in submitting a PR for it? It should be as easy as editing ReleaseAsset\n. You'll probably need to fork the repository and create a new branch for these changes - take a look at this to help get you started: https://help.github.com/articles/fork-a-repo/\n. Perhaps this is just because Naming Things Is Hard, but IssuesClient has two method which are intended to mirror the API docs: https://developer.github.com/v3/issues/#list-issues\n- GetAllForCurrent() - /issues\n- GetAllForOwnedAndMemberRepositories() - /user/issues\nLet me know if this can be improved at all...\n. > And none has the issues created by that authenticate user in repositories of other users.\n@delarua428 I checked the admin tools and you don't appear to be a member of other organizations or external repositories, so that might explain why these lists are the same. Can you elaborate on what you're expecting to see here?\n. @delarua428 ok thanks! that gives me more to look into!\n. I don't think we're able to bring in that TubCode/TubCodeRepo issue due to the repository not being one you belong to.\ncc @pengwynn to confirm this is by design\n. Repository Hooks is currently in-flight https://github.com/octokit/octokit.net/pull/495\n. @pengwynn ah yes, we can totally do that today!\nvar request = new SearchIssuesRequest(\"lol\"); // ugh, perhaps this isn't mandatory\nrequest.Involves = \"delarua428\";\nvar issues = await _gitHubClient.Search.SearchIssues(request);\n. My first reaction when reviewing this PR:\n\n. > I would like this solution to work for our private repositories on GitHub, but we need a compatible authentication mechanism for raw content that works with srcsrv.dll in Windows\nI'm around this week too - hanging out in the ASP.NET track. Hit me up.\n. I might be doing this wrong, but I tried to open the modified PDBs in PdbXtract and I get this error:\nERROR:  PdbParser_WorkCompleted():  An exception occured in worker thread:  PdbParser_DoWork():  Failed to parse PDB signature:  Invalid page size:  512\nI even trashed my line endings to ensure I was doing the same behaviour as AppVeyor:\ngit config core.autocrlf input\ngit rm --cached -r .\ngit reset --hard\nThoughts?\n. Couple of random notes:\n- SourceLink is not executed as part of the CreatePackages* step - should I include that?\n- Running SourceLink manually is broken on my machine - but that's my totally fault\nStarting Target: SourceLink\nsource linking C:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit\\bin\\Release\\Net45\\Octokit.pdb\nC:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit\\bin\\Release\\Net45>\"C:\\Program Files (x86)\\Windows Kits\\8.1\\Debuggers\\x64\\srcsrv\\pdbstr.exe\" -w -s:srcsrv -i:\"Octokit.pdb.srcsrv\" -p:\"Octokit.pdb\"\nRunning build failed.\nError:\nMicrosoft.Build.Exceptions.InvalidProjectFileException: The imported project \"C:\\Program Files (x86)\\MSBuild\\Microsoft\\WindowsXaml\\v11.0\\Microsoft.Windows.UI.Xaml.CSharp.targets\" was not found. Confirm that the path in the <Import> declaration is correct, and that the file exists on disk.  C:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit\\Octokit-\nnetcore45.csproj\n   at Microsoft.Build.Shared.ProjectErrorUtilities.ThrowInvalidProject(String errorSubCategoryResourceName, IElementLoca\ntion elementLocation, String resourceName, Object[] args)\n   at Microsoft.Build.Shared.ProjectErrorUtilities.ThrowInvalidProject(IElementLocation elementLocation, String resource\nName, Object arg0)\n   at Microsoft.Build.Evaluation.Evaluator`4.ExpandAndLoadImports(String directoryOfImportingFile, String importExpressi\nonEscaped, ProjectImportElement importElement)\n   at Microsoft.Build.Evaluation.Evaluator`4.EvaluateImportElement(String directoryOfImportingFile, ProjectImportElement\n importElement)\n   at Microsoft.Build.Evaluation.Evaluator`4.PerformDepthFirstPass(ProjectRootElement currentProjectOrImport)\n   at Microsoft.Build.Evaluation.Evaluator`4.Evaluate()\n   at Microsoft.Build.Evaluation.Evaluator`4.Evaluate(IEvaluatorData`4 data, ProjectRootElement root, ProjectLoadSetting\ns loadSettings, Int32 maxNodeCount, PropertyDictionary`1 environmentProperties, ILoggingService loggingService, IItemFac\ntory`2 itemFactory, IToolsetProvider toolsetProvider, ProjectRootElementCache projectRootElementCache, BuildEventContext\n buildEventContext, ProjectInstance projectInstanceIfAnyForDebuggerOnly)\n   at Microsoft.Build.Evaluation.Project.ReevaluateIfNecessary(ILoggingService loggingServiceForEvaluation)\n   at Microsoft.Build.Evaluation.Project.Initialize(IDictionary`2 globalProperties, String toolsVersion, String subTools\netVersion, ProjectLoadSettings loadSettings)\n   at Microsoft.Build.Evaluation.Project..ctor(String projectFile, IDictionary`2 globalProperties, String toolsVersion,\nString subToolsetVersion, ProjectCollection projectCollection, ProjectLoadSettings loadSettings)\n   at SourceLink.VsBuild.Project.Load.Static(String proj, IEnumerable`1 globalProps) in C:\\projects\\sourcelink\\SourceLin\nk\\VsProj.fs:line 15\n   at SourceLink.VsBuild.Project.LoadRelease.Static(String proj) in C:\\projects\\sourcelink\\SourceLink\\VsProj.fs:line 16\n   at FSI_0002.clo@108-16.Invoke(String pf) in C:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\build.fsx:line 109\n   at Microsoft.FSharp.Collections.SeqModule.Iterate[T](FSharpFunc`2 action, IEnumerable`1 source)\n   at FSI_0002.clo@101-15.Invoke(Unit _arg9) in C:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\build.fsx:line 104\n   at Fake.TargetHelper.runTarget@310(String targetName) in D:\\code\\fake\\src\\app\\FakeLib\\TargetHelper.fs:line 321\n. > Can you try srctool -x file.pdb first?\nYeah, this was PEBKAC on my part. It's all good now.\n. \n. > You are correct that it needs to be run before creating the packages.\nI'll fix that up once I've merged release-0.6 back into master.\n. Thanks for this - was great to catch up with you yesterday and talk about all this stuff!\n\n. > How should I follow up about getting the private repository support working?\nSend me an email - details in my profile.\n. Disregards - #587 will replace this\n. cc @prabirshrestha to see if you are interested in these changes:\n- https://github.com/mge/octokit.net/commit/29ae144d8ea5c1fae0a7c836f9e0cba2e9ce0771\n- https://github.com/mge/octokit.net/commit/808ffe6081a541c94ae541bd5f960027457371d0\n. Thanks for the PR and the detailed writeup @mge.\nThis all looks good, I'm just trying to wrap my head around whether this https://github.com/mge/octokit.net/commit/29ae144d8ea5c1fae0a7c836f9e0cba2e9ce0771 will introduce some side-effects elsewhere - it's been a while since I've been inside the SimpleJson source.\nPerhaps @prabirshrestha will know more.\n. Thanks for this @mge - I'll give this a test against our integration test suite before pushing it out in the next release! \n. @gbaychev what I'd like to do with this issue is make it more discoverable - for example, from C# you could specify an enum for 2FADisabled, which is then transformed to the appropriate string under the hood when calling the API.\n@SimonCropp this might be an adequate workaround for your use case\n. @haacked @SimonCropp :ok_hand: looks good to me!\n. @SimonCropp yes https://developer.github.com/changes/2014-09-05-removing-gravatar-id/ and I've added https://github.com/octokit/octokit.net/issues/613 to deprecate it in the future...\n. I can have a look behind the scenes at why you might be encountering seeing this error sporadically.\nIf you have a X-GitHub-Request-Id on the response that will help to correlate things on our end.\n. @sharwell\n\n@shiftkey This seems like a good place to propose an update to the API, where \"\" is treated as not having a user assigned. Do you have a place where users can file proposals like this?\n\nI'll pass this onto the API team for them to consider.\nFYI https://developer.github.com/v3/issues/#create-an-issue @pengwynn \n. @SimonCropp that's the plan! :thumbsup:\n. @gbaychev I don't believe so. Be my guest!\n. Fixed in #622 and will go out in v0.6.1\n. Re: naming things, I can see the documentation refers to Collaborators rather than Contributors in the API:\nhttps://developer.github.com/v3/repos/collaborators/\nBut on the website they're called Contributors\nhttps://github.com/octokit/octokit.net/graphs/contributors\nIn An Ideal World, I'd like the names of our things to reflect the API directly, but I'm happy to take RepositoryContributor at the moment until we get a chance to revisit this all the places we use identity - User/Author/Assignee/Members/Collaborator/Contributor all come to mind.\n. A couple of little polish things - the rest look good :sparkles:\n. I'd like to get  0.5.3 release out (which is just #605) but there's been extra things land in master recently which I'd like to tighten up before shipping a 0.6.x release.\n- Optimist Me- next week sometime\n- Pessimist Me - add a week to the optimistic guess\n. @mkchandler my apologies, it didn't make it into 0.5.3 - https://github.com/octokit/octokit.net/releases/tag/v0.5.3\nIt'll be out in 0.6.0 along with some other fixes - https://github.com/octokit/octokit.net/pull/621\n. @RobPethick yes, that'd be great - let's close this out!\n. GIven how recent this report is - and how it's the same set of AV products - I suspect this is a false positive.\nI've not gotten any love from Ad-aware when reporting these false positives in the past (F-Secure, on the other hand, have been awesome) - any tips for getting in touch with these teams?\n. Support ticket raised with BitDefender - let's see what happens next!\n. > Tell me if you want the commits squashed after a review\nPhilosophically speaking, I don't like squashing PR commits. But that's a discussion for another day.\n. > BTW, the docs on the new endpoint is way off compared to what you actually get back over the wire\nWell I guess we should update the docs. I can look into that as part of reviewing this.\n. @khellang :thumbsup: added to my review queue\n. \n. Unfortunately we don't have a good way to do paging in the Task-based API currently.\nWe do have a way to pass a datetime range to search on (perhaps that might help to constrain it): https://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/RepositoryCommitsClientTests.cs#L76-L82\nI'd love some ideas about how this API could look, without making it mandatory to specify for each request.\nOur Rx-based clients have paging built in, so you could do something like this:\nvar client = new ObservableGitHubClient(\"OctokitTests\");\nvar commits = await client.Repository.Commits.Get(\"octokit\", \"octokit.net\", \"HEAD\").Take(5).ToArray();\n. > what's the simplest way to get the SHA of HEAD commit in the master branch?\nAs you know the branch, you can do it like this:\nvar client = new GitHubClient(new ProductHeaderValue(\"OctokitTests\"));\nvar reference = await client.GitDatabase.Reference.Get(\"octokit\", \"octokit.net\", \"heads/master\");\nvar sha = reference.Object.Sha;\nPS: Oops, it should be ObservableGitHubClient in that last snippet. Updated.\n. I'll close this out unless others have questions around paging...\n. Oh whatever\n. If you're following along on this PR and wondering about the change breaking your dev environment, it really shouldn't (because thankfully .gitattributes has been storing these line endings as LF in the repo).\nYou might need to refresh your working directory to get rid of the CRLF line endings.\nJust run this within the repository once:\n\ngit config core.autocrlf input\ngit rm -r -cached .\ngit reset --hard\n. @haacked ready to review\n\nI'm publishing up a new package to MyGet to ensure the right commit is used to generate the symbols.\n. I'll send it out in the morning (my time) so I can keep an eye on it a bit.\n. @kzu I can include that URL in the README/CONTRIBUTING docs if you think that will help others.\nI haven't bothered with creating pre-release packages, but perhaps using AppVeyor to do this isn't such a bad idea...\n. This is live! https://www.nuget.org/packages/octokit\n. Would it be worthwhile linking to the blog post in the xml-docs too?\n/// <remarks>\n/// For more details: https://developer.github.com/changes/2014-09-05-removing-gravatar-id/\n/// </remarks>\n. \n. @SimonCropp that's an interesting idea - got an example or writeup on the benefits of capturing these situations as automated tests?\n. @SimonCropp a simpler version could be like this:\n- use reflection to find property\n - if exists, check marked as Obsolete\nThat means you have a documented deprecation in the codebase, and don't need to go back and modify the test once it is removed...\n. Fixed in #624\n. > Many integration tests are failing, is that to be expected?\nDepends on the context (rate-limiting might be involved) - CI seems to be happy, but that's skipping the integration tests.\nHappy to look at specific errors - let's take it to another issue to this...\n. > I ran the tests again and only a few are failing, they're completely unrelated to my changes so I'll create a new issue to address them.\nYeah, I don't believe those failures are due to this PR. :heart: for digging into it...\n. Yep, this is something I overlooked as part of a PR review.\nThanks for a) noticing and b) addressing it.\n\n. Fixed in https://github.com/octokit/octokit.net/pull/1240 and will be available in the next Octokit release...\n. This looks pretty great. \nI'd like us to be more careful with breaking API changes, should we introduce this as an overload and mark the current one as [Obsolete], rather than break this outright?\ncc @SimonCropp for feelpinions on this.\n. > do we care about it being a breaking API change?\nIf we don't want to [Obsolete] here I can document it as a breaking change - here's an example where I did a bunch of these. But given it should be relatively straightforward to port over, I think taking the hit is fine...\n. I'm leaning towards being gentle as a rule of thumb.\nI can write up some notes in CONTRIBUTING to make this a proper discussion :soon:\n. @SimonCropp I'll see what @gbaychev thinks about it.\nAlso cc @Haacked for thoughts on managing breaking changes better.\n. @gbaychev I'm happy to wait for it - take your time.\n. CI is failing as there's a method missing from the IObservable interface:\nIOrganizationMembersClient\n...\n - System.Threading.Tasks.Task`1[System.Collections.Generic.IReadOnlyList`1[Octokit.User]] GetAll(String org)\n - System.Threading.Tasks.Task`1[System.Collections.Generic.IReadOnlyList`1[Octokit.User]] GetAll(String org, OrganizationMembersFilter filter)\n - System.Threading.Tasks.Task`1[System.Collections.Generic.IReadOnlyList`1[Octokit.User]] GetAll(String org, String filter)\nIObservableOrganizationMembersClient\n...\n- System.IObservable`1[Octokit.User] GetAll(String org)\n- System.IObservable`1[Octokit.User] GetAll(String org, OrganizationMembersFilter filter)\nJust gotta bring back the old string,string overload and mark it as obsolete there...\n. > Should I add a type.IsEnum check?\nYep, I like this idea - I don't believe we need to add a DebuggerDisplay attribute for our enums.\n. @gbaychev Pro Tip: add the email address you've used on this branch to your GitHub profile: https://github.com/settings/emails\n. \n. Side note, it looks like the IntegrationTests step isn't working in appveyor.yml:\n\nI'm actually okay with this for the moment - I always make sure to run all the integration tests before shipping a release...\n. Just one more thing - mute the test output:\n\n. Long story short - this takes the number of CI warnings from 2917 down to 1911.\nReady for review\n. > We should memorialize whatever we decide into a style guide for comments.\n:thumbsup::thumbsup::thumbsup::thumbsup::thumbsup:\n. Oh man, the details on this are just fantastic! :sparkles: \nI've created a milestone to incorporate all these test improvements. Once I've migrated the tests over to xUnit 2.0, this should be easier to add in...\n. I'm contemplating burning that exception to the ground (or just using the original URL rather than tying it to the login details).\n. I really think we should just pass in the repository URL to the exception - whether it's an org or a user repo doesn't really matter here, right?\n. Thanks!\n. Ready for review :moon:\n. Thanks @gbaychev!\n. I think this is different from the rate limiting - and perhaps the bulk inserting of issues is triggering it over time? \n@pengwynn what sort of actions would trigger this message from the API:\n\nYou have triggered an abuse detection mechanism and have been temporarily blocked from content creation. Please retry your request again later.\n. @pengwynn we should be deserializing the URL out here - sounds like a job for some documentation on my end :wink:\n. Just need to address the Code Analysis error (InvariantCulture dat thing):\n\nc:\\projects\\octokit-net\\Octokit\\Models\\Request\\RequestParameters.cs(88): error CA1304: Microsoft.Globalization : Because the behavior of 'string.ToLower()' could vary based on the current user's locale settings, replace this call in 'RequestParameters.GetValueFunc(Type)' with a call to 'string.ToLower(CultureInfo)'. If the result of 'string.ToLower(CultureInfo)' will be displayed to the user, specify 'CultureInfo.CurrentCulture' as the 'CultureInfo' parameter. Otherwise, if the result will be stored and accessed by software, such as when it is persisted to disk or to a database, specify 'CultureInfo.InvariantCulture'. [C:\\projects\\octokit-net\\Octokit\\Octokit.csproj]\n969  Code Analysis Complete -- 1 error(s), 0 warning(s)\n. Thanks!\n. Seems legit. Thanks!\n. > Wouldn't it just be easier to use IssueEvent everywhere and allow it to be null when you're accessing the collection of events in respect of an issue?\nMy only issue with this change would be that the end-user might be expecting Issue to be present at some point when querying for events. Sure, we'd be reducing by one the models we need manage. But having that field hang around might be confusing.\n. I believe these are two different discussions - whereas #593 is about how to handle different media types for the same endpoint without creating models for each situation, this is about being able to reuse models against different endpoints. Do you agree?\n. \n. \n. This is ready for review\n. @joshvera hold off until @haacked has had a chance to :eyes: over it.\nI might also do an intermediate release before this - as there have been significant changes to the internals which I'd like to get out separately https://github.com/octokit/octokit.net/pull/662 https://github.com/octokit/octokit.net/pull/658\n. @erangeljr that's weird, I just ran the integration tests and I can see this work as expected.\nIf you want to be really, really sure, just add an assert to this test that the BrowserDownloadUrl on the retrieved asset is not null.\n. Thanks for this @erangeljr!\n. I'll have a look at this when I'm back on the grid tomorrow :v:\n. Code and tests look pretty great. Just a few nagging questions :metal:\n. \n.  \n. Ready for review :cow2: \n. > Just a question, don't we have tests that require a free account?\nI don't believe so - the test account I use has a micro plan, so I would be seeing different failures here.\n. Rebased on top of master to make the merge conflict go away :boom::camel:\n. > Maybe there should be a convention test that verifies that collections are of the right type? \n:heart::heart::heart::heart::heart: https://github.com/octokit/octokit.net/issues/660\n. \n. Can I get a :thumbsup: on the release notes? Everything else is ready to roll out after that...\n. And we're live: https://www.nuget.org/packages/Octokit/0.6.2\n. Let's divide and conquer on it - they're not exactly coupled together.\n. @khellang herp derp. Yeah, that's Definitely An Issue...\n. - Namespaces: we've tried to avoid avoided namespaces below Octokit for everything public.\n- Marker Interfaces: I'm Not A Fan\n- Attributes: pass\nYeah, the test infrastructure bit us in the rear this time - we should have added a check here to fail the test if the collection of models discovered was empty.\n. @khellang could be unused - i'd love some more details!\n. :apple:\n. A couple of thoughts on public/internal changes, but this is looking pretty amazing.\nNeeds a merge with master, but aside from that I think we're close to :ship:ing this.\nIf you're interested in drafting up the Breaking Changes for this we can start setting up a 0.7 release asap.\n. :moon:\n. \n. > Ugh. Now the DebuggerDisplay test fails.\nLOL. So sorry!\n. I'm happy with this cleanup - @haacked had a chance to look at it?\n. \n. No upstream changes necessary, as this was added in https://github.com/github/gitignore/pull/1035 and we found a duplicate rule in https://github.com/github/gitignore/pull/1292 which was reverted. \n. Thanks @Zoltu!\n. \n. Thanks @Zoltu! \n. > If someone can point me at some existing tests that validate the json deserializer behaves correctly in certain scenarios (like when the property is missing) I can add some test coverage.\nWe're using SimpleJSON for the serializer - we have some tests here for the related features that we need.\nI believe the truncated property should always be present when deserializing the JSON, so unless you can think of some integration tests to add I wouldn't stress about it too much.\n. > I don't know of a public repo returns a truncated tree so that is difficult to integration test.\nDon't worry about it. Happy to leave this as-is.\n. Thanks!\n. > In those cases, why not require a URI. @shiftkey any thoughts?\nThe rule is basically:\n\nA type declares a method with a string parameter whose name contains \"uri\", \"Uri\", \"urn\", \"Urn\", \"url\", or \"Url\" and the type does not declare a corresponding overload that takes a System.Uri parameter.\n\nMy first instinct was \"Could we mute this rule?\" And yes, adding this element to Octokit.ruleset kills off these warnings: <Rule Id=\"CA1054\" Action=\"None\" />\nSo that's what I'd favour for this - as long as the ctors are protected, whatever.  \n\nI think we should get rid of the obsolete properties in this PR. \n\n:thumbsup:\n. @rajeshgupthar thanks for starting on this. I had some hacky code lying around to tackle this same problem, so I added some thoughts about the approach I went for versus where you went into the mix.\nI think you're on the right track :thumbsup:\n. Apologies for not getting back to this earlier:\n\nWhat concerns you with the reflection code in DisposableRepository class? Do you find it buggy? or Am i breaking any rules/conventions by having it there?\n\nIn general, I favour composition over inheritance when it comes to situations where you're working with test doubles. It's purely a personal preference in this case - if you were to instantiate the Repository object and keep it around as a property on the DisposableRepository class, you'd achieve the same effect.\nI'll let @haacked chime in here about how he feels about this PR.\n. After further reflection on this, and @kristianhald showing me some tricks using xUnit test fixtures to abstract this away in #776, I need to gather my thoughts and update the original issue again.\nThanks for the work you've put in here @rajeshgupthar, and apologies for not being clear on what I wanted...\n. Nice spot!\n. We're already planning other breaking changes for this release, so I'm happy to take this in and add it to the release notes.\n\n. If I haven't covered this in #647 I definitely should\n. If you need it urgently, open a PR against master for it. #683 is about some upcoming breaking changes, and I've been pulled off that for the moment so it's somewhat stalled...\n. The Authorization API changes will go out in the next release (0.7.1), if you're looking for something to pick up again :trollface:\n. @alfhenrik my goal for this week is to finish up #647 and get it ready for review :tada:\n. @Blecki do you know what version of Mono you're running?\n. This appears to be an issue how we're using HttpClient on Linux (still occurring in 0.6.2):\n```\nSystem.FormatException: Invalid format.\nat System.Net.Http.Headers.HttpHeaders.AddInternal (System.String name, IEnumerable1 values, System.Net.Http.Headers.HeaderInfo headerInfo, Boolean ignoreInvalid) [0x00000] in <filename unknown>:0\nat System.Net.Http.Headers.HttpHeaders.Add (System.String name, IEnumerable1 values) [0x00000] in :0\nat System.Net.Http.Headers.HttpHeaders.Add (System.String name, System.String value) [0x00000] in :0\nat Octokit.Internal.HttpClientAdapter.BuildRequestMessage (IRequest request) [0x00000] in :0 \n--- End of stack trace from previous location where exception was thrown ---\nat System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw () [0x00000] in :0\nat System.Runtime.CompilerServices.ConfiguredTaskAwaitable1+ConfiguredTaskAwaiter[Octokit.IResponse1[Octokit.SearchCodeResult]].GetResult () [0x00000] in :0\nat Octokit.Connection+d__1f1[Octokit.SearchCodeResult].MoveNext () [0x00000] in <filename unknown>:0\n--- End of stack trace from previous location where exception was thrown ---\nat System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw () [0x00000] in <filename unknown>:0\nat System.Runtime.CompilerServices.ConfiguredTaskAwaitable1+ConfiguredTaskAwaiter[Octokit.IResponse1[Octokit.SearchCodeResult]].GetResult () [0x00000] in <filename unknown>:0\nat Octokit.Connection+<Run>d__1b1[Octokit.SearchCodeResult].MoveNext () [0x00000] in :0\n--- End of stack trace from previous location where exception was thrown ---\nat System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw () [0x00000] in :0\nat System.Runtime.CompilerServices.ConfiguredTaskAwaitable1+ConfiguredTaskAwaiter[Octokit.IResponse1[Octokit.SearchCodeResult]].GetResult () [0x00000] in :0\nat Octokit.ApiConnection+d__0`1[Octokit.SearchCodeResult].MoveNext () [0x00000] in :0\n```\nI now have a proper dev environment, let's see if I can isolate where exactly it's falling over.\n. So I've settled on the simplest repro to trigger this:\n``` csharp\nvar message = new HttpRequestMessage (\n    HttpMethod.Get,\n    \"https://api.github.com/\"\n);\nmessage.Headers.Add (\"Accepts\", \"application/vnd.github.v3+json; charset=utf-8\");\n// and this is the line that blows up\nmessage.Headers.Add (\"User-Agent\", \"ha-ha-mono (Unix 3.13.0; amd64; en-US; Octokit 0.6.3)\");\n```\nWorks on Windows, so likely an implementation issue with System.Net.Http.Headers.HttpRequestHeaders on Mono.\n:cool:\n. I'll just leave this here: https://github.com/mono/mono/blob/5728c1a3dd946119e566f7afe7bf79b85f82f89d/mcs/class/System.Net.Http/System.Net.Http.Headers/HttpHeaders.cs#L179-L223\n. As a workaround until we can get a fix into Mono proper, we could use TryAddWithoutValidation for the User-Agent header value:\nmessage.Headers.TryAddWithoutValidation(\"User-Agent\", \"ha-ha-mono (Unix 3.13.0; amd64; en-US; Octokit 0.6.3)\");\nThoughts @haacked?\n. @akoeplinger thanks for confirming it's been fixed before I went stepping through the source :heart:\n. @thedillonb could you try this script and see if it's not a different problem?\n```\nvar message = new HttpRequestMessage (\n    HttpMethod.Get,\n    \"https://api.github.com/\"\n);\nmessage.Headers.Add (\"Accepts\", \"application/vnd.github.v3+json; charset=utf-8\");\n// and this is the line that blows up\nmessage.Headers.Add (\"User-Agent\", \"ha-ha-mono (Unix 3.13.0; amd64; en-US; Octokit 0.7.0)\");\n```\n@akoeplinger thoughts?\n. I can re-test this against Mono 3.12 and dig into it further. Gimme a day or so.\n. @thedillonb yep, this is a different issue:\nvar request = new HttpRequestMessage ();\nrequest.Headers.Add (\"Accept\", \"application/vnd.github.moondragon+json; charset=utf-8,application/vnd.github.v3+json; charset=utf-8\");\nThis was a change in #709 and the , in here appears to be the issue (space or no space after doesn't make a difference). cc @akoeplinger \n\nIf I reference the Octokit-Mono.dll then I have a bad time :-1:\n\nThat makes sense - Octokit-Portable references a different System.Net.Http to the one in Octokit-Mono\n. I've fixed this issue incidentally by shipping #734 which dropped the multiple Accept headers. When I get around to addressing how we handle preview APIs properly, I'll keep this workaround in mind.\n. We've been meaning to setup an official account on AppVeyor for Octokit - currently it's just using one of our personal accounts. \n. \n. @alfhenrik the endpoint which takes a since doesn't exist, so I've left this open.\nPagination is also different for the public repository APIs:\nLink: <https://api.github.com/repositories?since=364>; rel=\"next\"\nInstead of the default:\nLink: <https://api.github.com/resource?page=2>; rel=\"next\",\n      <https://api.github.com/resource?page=5>; rel=\"last\"\nBut we can deal with that in #760 or :boot: to a subsequent PR.\n. Reopening this one as the work done in #774 neglected to catch a scenario with pagination that was specific to this API:\n- the Link has a since parameter older than the specified id\n- when invoking the next link, GetAll will overwrite the parameter with the original id\n- forever paging :sob:\nIf you revert 26a8bf0e818ad8a620987e13d5ed7b1b8bacfa01 you'll get this PR back at least. \n. Shipped in 0.11.0\n. Already up to RC3, let's start over\n. From what I can tell, the rejection is due to the branch not being in a mergeable state:\nhttps://developer.github.com/v3/pulls/#response-if-merge-cannot-be-performed\nIf you view the PR on the website, do you see a green \"Merge\" button or a greyed out button?\n. Fixed in #695\n. Hello yes this is a pull request\n. >  Maybe this could be done passing the pagination ability to the caller of the method.\nThis is something I need to think about again. I should open a discussion somewhere on this...\n. This looks great! :metal: If you can mute that slow test I'm happy to merge this in!\n. \n. Yeah, those tests names could be so much better.\nIf you'd like to have a go at updating these, I'd be more than happy to review it and suggest changes.\n. Thanks!\n. \n. Thanks!\n. @kenshinthebattosai you're welcome to submit pull requests against any of the outstanding issues - drop a comment into the issue if you see something you'd like to take on\n. @kbilsted you'll need VS2013 to open the solution locally\n. > I have VS2013, it opens a window telling me windows 8.1 is required.\nThat's just for some specific projects which use NetCore. Don't worry about it!\n. @DavidStrickland0 #776 is almost wrapped up and ready to merge, so forking a repository should go out in the next release!\n. I'll drop a note in here when it's been released, but #776 has been merged into master \n. @DavidStrickland0 @kbilsted this is now available in v0.12 on NuGet.\n. @DaveWM I think this is actually a bug in the GitHub API - https://api.github.com/repos/octokit/octokit.net\ncc @pengwynn \n. @pengwynn thanks for the details\n. @haacked gah, you're right - we can still fix this.\nWe could map subscribers_count to WatchersCount instead of deprecating the property altogether. How does that feel?\n. Fiiiiine :stuck_out_tongue: \n. > It's just my preference. I think it's a good rule of thumb. \nI'm just being pre-caffeine silly here. As the behaviour isn't going to change for the lifetime of v3, I'm :thumbsup: with hiding away this incorrect field.\n. Once I get #702 out the door, I'll pull in a bunch of these fixes and do a follow-up release.\n. @BrisingrAerowing sounds interesting! I can't wait to see what you make! \nI can add a note to the README about related projects once you have something to show off - there's also a ScriptCs.Octokit project which I should point people to cc @alfhenrik.\nI'll leave this open until I can do that.\n. @BrisingrAerowing feel free to submit a PR once you've got something cool to show off!\n. A quick thought: perhaps get all events for the repository?\nvar events = await client.Issue.Events.GetForRepository(user, repository);\nvar filteredEvents = events.Where(a =>\n    a.Event == EventInfoState.Labeled || a.Event == EventInfoState.Unlabeled).ToList();\nThis will handle the pagination work, however it has an upper limit on the data you can retrieve (I forget how high this goes, but unfortunately it's not configurable currently) so some old data might not be available.\n. Looks like something related to Issue Events - am I on the right track?\n. @janovesk that's weird, I could have sworn we'd handled _ elsewhere in the codebase...\n. Yes! My memory does works from time to time!\n. If you'd like this to go out sooner (hint: yes), can you target release-candidate?\nI'm aiming to do some end-to-end testing on Monday for that and ship it if nothing dramatic comes up.\n. :thumbsup:\n. Cherry-picked into the release-candidate branch due to my own bad life choices\n. Thanks!\n. @janovesk I've been testing a 0.7.0 release over the last few days (which has some significant internals changes - details here) - after that there's a few minor bugfixes which I'll bundle up later this week...\n. I've got no more blockers on this, so I'll be publishing up a bugfix release in the next day or so.\n. Ready for review\n. Did a quick check of the docs to see if there would be any problems with old GHE installs. 11.10.340 has this value, as does 2.0.\nShould I worry about a fallback value nonetheless?\n. @joshvera I can add a test for this. I'm pretty sure (because of how enums work) is that it'll default to User (the first value), so that was why I was thinking about making it nullable. \n. As this is introducing further breaking changes (and we're not so urgent on getting this out the door), I'll retarget this against master and not hold up shipping the release.\n. \n. @thedillonb It's been a while since I opened Xamarin Studio (expired subscriptions also doesn't help), so I'm not quite sure whether I can/should drop it.\n. I'm happy to accept this PR, but I'll also open a discussion about whether we need to support separate MonoTouch/MonoDroid projects these days...\n. > God I would love it if we could drop it. \nhttps://github.com/octokit/octokit.net/issues/719\n\n. Ready for review\n. This is live https://www.nuget.org/packages/octokit/0.7.1\ncc @forki @erichexter\n. @forki :thumbsup:\n. Fixed in #724 and shipped in v0.7.1\n. \n. Oops, meant to target release-candidate\n. \n. Ready for review :metal:\n. @haacked when you get a moment, could I get a :thumbsup: on this? If you're too busy that's :cool:\n. Thanks @alfhenrik!\n. cc @haacked as he's more familiar with the serialization rules than I am\n. Thanks for the feedback @omidkrad, however this is just the repository for managing the .NET wrapper around the GitHub API. \nYou can contact the API developers directly by using support@github.com to discuss this further.\n. cc @haacked\n. \nBut more seriously, this is something we've kicked around a bunch in the past - I've not settled on a design I'm personally happy with, but https://github.com/octokit/octokit.net/issues/352  https://github.com/octokit/octokit.net/pull/369 and https://github.com/nigel-sampson/octokit.caching are interesting discussions to follow.\nI definitely think our recent changes has made this harder - thanks for the specifics on issues you're encountering...\n. Would it be possible to add some tests for this? I'm not sure how valuable it'd be to target references that might be transient, but look at the integration tests in RepositoryContentsClientTests for some inspiration.\n. Looks good, just a couple of documentation-related things.\nI'll kick the tires on the tests today and see what shakes out :v:\n. > I was able to get around the Integration Tests time out issue, by just running my Integration Tests from VS.\nYeah, that's what I do too (because it doesn't enforce the timeout :wink:)\n. All looks pretty great to me. Thanks for finishing off this feature!\n\n. If you're testing this in 0.7.x this might involve the changes to the /user/repos endpoint documented here - are you seeing organization repositories in the API response?\n. Yeah, that doesn't sound good at all. I thought I might have messed something up recently but #691 is the only one I can think of - and it's not merged yet.\nCan you grab a sample repsonse from Fiddler (just one, not all 100 :grinning:) and send it to me over email or Skype?\n. And this is live https://www.nuget.org/packages/Octokit/0.7.2\n. subscribers_count is no longer returned from the API for this endpoint. The only two counters we return here are stargazers_count (the number of users who have starred a repo) and watchers_count - which we are no longer showing because it's not correct and to be deprecated as per #699\n\nThe right way to retrieve the watchers for the repository is to use the Watching API:\nvar client = new GitHubClient(new ProductHeaderValue(\"testing-wp-octokit\"));\nclient.Credentials = new Credentials(\"...\");\nvar watchers = await client.Activity.Watching.GetAllWatchers(\"christophwille\", \"viennarealtime\");\n@christophwille let me know if I've missed anything \n. > There's a bit of a hack in the GitHubSerializerStrategy class (in SimpleJsonSerializer.cs) to get it to deserialize the payload to the correct type.\nThat's the best place to put it. \n\nAlso, not sure if you'd prefer the tests for this to be in a separate file (currently in EventsClientsTests.cs).\n\nNot really fussed by this. Would it be possible to get a couple of integration tests in place as well?\n. > I'll have a go at the integration tests for the simpler event types (commit comment, issue comment, etc.), but testing the events you get when you create a PR, push to a repo, fork a repo, etc. would be a lot harder.\nIf you can find some archived events which you can fetch by a specific id that might be easier to test...\n. Tests are :thumbsup: - just that change with [Fact] -> [IntegrationTest] to ensure credentials are setup right.\n. \n. @erichexter perhaps this is something missing from the docs - is this a public repository I could run a test against to confirm this behaviour?\n. @erichexter :heart: \n. Weird, I couldn't trigger the issue using this test harness (against b3859cf6eecc510d484d7f846e855fd07952a0b0):\n[IntegrationTest]\npublic async Task ReturnsACollection()\n{\n    var github = Helper.GetAuthenticatedClient();\n    var events = await github.Activity.Events.GetAllForRepository(\"waffleio\", \"waffle.io\");\n    Assert.NotEmpty(events);\n}\n@erichexter am I missing something?\n. Found it: https://api.github.com/repos/waffleio/waffle.io/issues/events/142230057\n. @darrencamp thanks!\nI'll follow up with the team whether this should be documented, but for now I think we should just Fix The Bug.\n. This will go out in the next release\n. This has been deployed in v0.8.0\n. I'll pause here before going further and see if people have feedback on this approach.\n. Went back and forth with @JakeGinnivan about this API stuff, and he pointed out that this change will make the task returned from DeferredRequest cold. And that's going against the Task-based Asynchronous Pattern book which recommends starting the task as early as possible.\n\n\"All tasks returned from TAP methods must be \u201chot.\u201d If a TAP method internally uses a Task\u2019s constructor to instantiate the task to be returned, the TAP method must call Start on the Task object prior to returning it. Consumers of a TAP method may safely assume that the returned task is \u201chot,\u201d and should not attempt to call Start on any Task returned from a TAP method. Calling Start on a \u201chot\u201d task will result in an InvalidOperationException (this check is handled automatically by the Task class).\"\n\nI don't think this is impossible to do within our current infrastructure, but right now I need to be mindful of this.\n. Been thinking on different approaches. Closing this one for now.\n. Thanks!\n. @joshvera just going to give this a once-over to ensure it matches up with our other conventions before merging\n. @haacked thanks. I'll publish this up after the weekend :v:\n. And this is live https://www.nuget.org/packages/Octokit/0.7.3\n. @Aaronontheweb thanks for the feedback! When I saw the tweet earlier today I was really excited to see what was on the way!\n\nHowever, one of the things I found a little frustrating was that there doesn't seem to be any options for timing out an Octokit call - some of the _gitHubClient.Activity.Starring.GetAllForUser(starrer) calls we make take an exceptionally long time to return. \n\nYeah, this is something I've been putting off and pushing out for a while.\nHere's a TL:DR on the situation as it stands:\n- the API support pagination using the Link header whenever sets of results are returned\n- Octokit will auto-follow the pagination results until it's reached the end of the set\n- the end user will get the entire result set\nAnd this sucks for anything involved with wanting to control the # of pages returned or cancel an in-flight request.\n\nAnd in some cases the calls never get completed and silently fail.\n\nIf you can recreate this (quite often it's related to a specific user account) I'd love to investigate this further.\n\nCould very well be an issue with how we're using the SDK, but regardless I'd like to have the option to time out individual requests.\n\nYep, there's a couple of options at hand - and making it all work in an uncomplicated way is something I'll need to start working on Real Soon. With Rx, disposing the subscription is generally considered The Right Way to do that, so I'm not really worried about that scenario right now.\nA couple of ideas (one or the other or both could land in the framework):\n- the pagination work in #740 would help you constrain how much data you want. The initial feedback I've got on this seems promising, but it's a big change to everything so I don't want to rush it.\n- HttpClient supports providing a CancellationToken when it's making a request - perhaps we should have overloads on the GetAll operation so that you can cancel the in-flight requests (this should also kill the pagination, but I need to confirm this). This feels better than reinventing the wheel.\nI'd love to hear more about your scenario (is pagination better than cancellation?) so I can focus things in the short-term.\n\nI see that in #587 you added the ability to set a default timeout across the entire connection - glad I know about it now but it's not obvious or easy to find :p\n\nThat would work for a single request - we added this because uploading release assets takes a while - but for our scenario where we reset the timer for each request (due to pagination) it probably won't be enforced.\n. I'm feeling that #760 is a more familiar option for developers than cancellation tokens (and more useful in general):\n``` csharp\n[IntegrationTest]\npublic async Task CanPageRepositories()\n{\n    var github = Helper.GetAuthenticatedClient();\nvar options = new ApiOptions { PageSize = 10, PageCount = 1 };\nvar repositories = await github.Repository.GetAllForCurrent(options);\n\nAssert.Equal(10, repositories.Count);\n\n}\n```\nOnce that lands on master I'll close this out.\nLet me know if you have any other thoughts on either approach.\n. This is a recent change as the API team wanted to close the security hole around letting third party integrations read the tokens that a user has:\nhttps://developer.github.com/changes/2015-02-20-migration-period-removing-authorizations-token/\nIf you still want to access the Token you can use the GetOrCreateApplicationAuthentication method without setting NewAuthorization.Fingerprint. It won't return you all the authorizations, but for specific cases it should be a good enough workaround.\nI've written a test here which demonstrates this behaviour:\nhttps://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/AuthorizationClientTests.cs#L10-L53\n\nis there any way to using GitHub API with Personal access tokens. or taking token with basic authorization?\n\nI'm not sure I understand the question. Could you expand on what you're trying to do here?\n. :thumbsup:\n. Definitely have the first option. If the second option is easy enough to add in, I'd happily accept it as well...\n. Note: #808 will complete this feature (by introducing GetArchive which follows the received 302) and the old GetArchiveLink will be obsoleted in a future release.\n. @somedave thanks for the detailed writeup.\nWe have similar behaviour for starring and unstarring Gists, and I've not seen the integration tests fail in this way.\nFor a starting point, I'd add a failing integration test for this - steal some of the code from here and adapt it accordingly to get you started.\n. Woah, lots of words here. Sorry to hear about all this pain you're going through just to run my tests :cry:\n\nI guess that makes this an xUnit problem, so I'll see if I can follow up there.\n\nHold off on raising this until I've upgraded to xUnit 2.0 RC4 in #725 - I've encountered a similar issue in the past which was subsequently fixed by the team.\n\nSure enough, after a little more digging with additional personal tokens, I learned that starring a repository requires the public_repo OAuth scope and not the user scope - which doesn't make a whole lot of sense to me since user lets you view stars and it seems like starring should be a user-focused activity, but whatever.\n\nThis sounds like something I should document in the tests. I'm gonna keep this open and update the title to reflect what went down.\n. @somedave I'll drop a comment in #725 when that's merged\n. @daveaglick apologies for not getting back to you sooner.\nWe're now running xUnit 2 RTM tests on master - could you have a go at running the tests again and see if the problem is still present?\n. @daveaglick thanks for confirming\n. Could you add the IssueEventTests file to the Octokit.Tests-NetCore45 project?\n. There's also an integration test you can write around this bug:\n[IntegrationTest]\npublic async Task CanDeserializeUnsubscribeEvent()\n{\n    var client = Helper.GetAuthenticatedClient();\n    var issue = await client.Issue.Events.Get(\"waffleio\",\"waffle.io\", 142230057);\n    Assert.Equal(EventInfoState.Unsubscribed, issue.Event);\n}\n. Flawless Victory!\n\n. LGTM\n. \n. Code looks good. Just waiting on the green build and the merge conflict, otherwise :thumbsup:\n. \n. And by YOLO I mean \"I'm gonna look into why this broke SourceLink\"\n. @khellang SourceLink requires the files to end in LF to index correctly - so if you don't have git config core.autocrlf input set you're just gonna keep seeing those warnings.\nI thought I'd documented that somewhere, but I've added a reminder https://github.com/octokit/octokit.net/issues/756\n. @khellang I've just enabled it for this repository, but I'll elaborate on the setup further in that issue.\n. Just one failing test to look at:\nOctokit.Tests.Clients.StatisticsClientTests+TheGetCommitActivityForTheLastYearMethod.RequestsCorrectUrl [FAIL]\nNSubstitute.Exceptions.ReceivedCallsException : Expected to receive a call matching:\n    GetQueuedOperation<IEnumerable`1>(/repos/username/repositoryName/stats/commit_activity, any CancellationToken)\n    Actually received no matching calls.\n. Don't worry about it @khellang, I tracked this down to https://github.com/octokit/octokit.net/commit/37534f9c0c61d5a317430e63c17ee712595316f2. You can cherry-pick that in...\n. \n. Also, SourceLink really didn't like this PR: https://github.com/octokit/octokit.net/pull/754 - why?\n. @alfhenrik could it be that the mock setup isn't returning the right object any more? Aside from that I'm not quite sure...\n. @naveensrinivasan probably not - the branch history makes it look like I was hacking it in (which I was). I'll see if I can rebase it on top of the current master, otherwise I might gradually roll it out (use Roslyn to suggest code fixes, rather than fail the build?)\n. @naveensrinivasan yep, totally understandable. I had an idea to make this easier to roll out, now that we're on VS2015. I'll see if I can bash that out so that this can be rolled out incrementally (and others can chime in).\n. After #1105 came up again I realised I wanted to revive this PR. So I've dropped every instance of updating the API here for just one endpoint, so the diff is less noisy. ~~There's a broken test here I need to fix, but the diff is mostly ready for review.~~ IT'S GREEN! IT'S GREEN!\nWould love some feedback on this, as I think it's something we could roll out incrementally once we have the core pieces in place.\n. Alright, pausing here feels good.\nI'll annotate some of the interesting bits to help with the review process.\n. > The only annoyance/concern is around the fact that with so many overloads on ApiConnection, it looks like it's going to possibly be a bit trickier when writing unit tests where the NSubstitute mocks start to need things like (Dictionary<string, string>) null and so on. Not sure if there's any way to avoid that though.\nIf we structure the overloads right (that is, funnel the various GetAll overloads into one implementation), perhaps we'll see negligible changes to the tests, e.g.\n``` csharp\npublic Task> GetAll(string owner, string name)\n{\n    Ensure.ArgumentNotNullOrEmptyString(owner, \"owner\");\n    Ensure.ArgumentNotNullOrEmptyString(name, \"repository\");\n// call the overload which requires ApiOptions\nreturn GetAll(owner, name, ApiOptions.None);\n\n}\n```\nAnd if the actual implementation ends up invoking the IConnection.Get<T> with the maximum parameter count, we might have something resembling consistency...\n``` csharp\nvar client = Substitute.For();\nclient.Received().GetAll(Arg.Is(u => u.ToString() == \"repos/fake/repo/releases\"),\n    null,\n    \"application/vnd.github.v3\",\n    Args.ApiOptions);\n```\n. @ryangribble you've done plenty to contribute to Octokit in recent times, so your feedback here is totally welcome! :heart:\n. @ryangribble feeling pretty good about the direction of this looking at the last couple of tweaks in e93dc53e8c234f0c4f44b35bbc9f7de0648b5346\n. ~~Just a heads up, this build isn't triggering our AppVeyor CI checks - chasing up with the support team about what's happening.~~ nevermind, fixed\n. @haacked are you able to have a look over this and see how you feel about this?\n. I'll prep my script to generate the tasks for this, and then merge this in (probably tomorrow) so we can get this rolled out across the entire library in time for the next release...\n. And the milestone is opened https://github.com/octokit/octokit.net/milestones/Pagination%20Support so I'm going to merge this in finally...\n. The public setter has been removed due to it clashing with an FxCop rule. I thought I had an integration test to demo this specific endpoint, but I don't.\nThe collection is already instantiated in the constructor so it's just a matter of adding elements to the collection:\nvar request = new RepositoryIssuesRequest { State = ItemState.Closed };\nrequest.Labels.Add(\"Client Name\");\n_gitHubclient.Issue.GetForRepository(\n    \"Org name\",\n    \"Repo name\",\n    request)\nIf you feel up to improving this API, I can reopen this issue and we can discuss it further...\n. > The .Add(), why create a new label? It takes in a string, so just putting the label name is good, yeah?\nGah, my bad. This is what happens when you reply to things late at night.\nI'll edit that snippet above to reflect this.\n. Heh, was waiting to see when I'd be back in this code. Removing one label isn't a scenario I'd thought about when I was in https://github.com/octokit/octokit.net/pull/718.\nPerhaps a method AddLabels that takes an enumerable of labels? Would that make you happier?\ncc @thedillonb\n. > Am curious why we treat Labels different and leave as (null / no change) but don't do the same for the others such as Body? \nThe milestone and labels are handled slightly differently to the other fields in the API on PATCH: https://developer.github.com/v3/issues/#edit-an-issue\nI know I can make this clearer in our API, this feedback is great :sparkles:\n. Just waiting on that greeeeeen.\n. @NikolayIT not sure - were you waiting the complete \"get actual content\" step as well? that code hasn't been implemented yet...\n. @alfhenrik if you find yourself still struggling to make time for it, I'm happy to short this PR and just merge in the archive link stuff.\n. \n. @NikolayIT this just went out in v0.11 - https://www.nuget.org/packages/Octokit/0.11.0\n. Thanks!\n. Fixed in #771\n. Fixed in #771\n. :thumbsup: might have some overlap with the convention test I added in #760 but I'm fine for them to co-exist for a while...\n. Fixed in #771\n. >  this would be caught in the SyncObservableInterfaces test though...so might not be urgently needed.\nThat was my thinking on this too. I think we can drop this unless there's another reason to test the observable interfaces explicitly...\n. Thanks heaps for working through this!\n. Fixed in #771\n. > This thread moves out of the async method \nThis sounds like the intended behaviour of async/await...\n\nand execution stops.\n\nBut this definitely isn't right at all.\nA couple of questions:\n- If you set a breakpoint on the line after the method, do you ever see it get hit?\n- Could execution be stopping due to an unhandled or first-chance exception? The Output window might have some clues.\n- What if you were to try a GitHub resource instead of a GitHub Enterprise URL? Does the same thing happen?\n. What about if you do this?\nvar contents = client.Repository.Content.GetContents(\"owner\", \"reponame\", \"FilePath\"); \ncontents.Wait();\nvar result = contents.Result;\nIt's hard to say what might be causing the task to not execute (I'm not sure what sort of application you're running here) but this is how you can force the program to block until the task completes.\n\nBy GitHub resourse do you mean GitHub local client?\n\nRather than point to your GitHub Enterprise environment, could you try it against GitHub?\nvar github = new GitHubClient(new ProductHeaderValue(\"OctokitTests\"));\nvar readme = await github.Repository.Content.GetReadme(\"octokit\", \"octokit.net\");\nDebug.Assert(\"README.md\" == readme.Name);\nIf that works, perhaps there's some networking-specific problem at play here...\n. Closing this until more information is made available\n. Looks good, just a couple of minor things.\n. A couple of questions :dog:\n. Thanks!\n. > SocketException (0x271d): An attempt was made to access a socket in a way forbidden by its access permissions]\nIs this consistently occurring on Azure?\nThis looks like it's an environment-specific problem, not quite sure what I can do from Octokit itself to address this...\n. @erichexter that'd be great. if you have any extra details I can reopen this issue.\n. @kristianhald thanks for reviving this PR, I'll walk through it in the coming day or so and let you know how I feel about it...\n. Just had a look at the merge conflict, and it seems to be related to files being added to both csproj files. You'll pick it up if you try to merge master into your branch.\n. @kristianhald thanks for this (and also thanks to @AndyCross and @johnduhart for getting this started). A few questions about the design and some places to clean up, but this is some really fantastic work already!\n. @kristianhald apologies for the delay - I've just gotten back from BUILD so am digging myself out of inbox hell. I'll add this to the list of things to review today. There's a merge conflict with the branch, but we can address that separate to the changes here.\n. @kristianhald looking good, just a bit of cleanup for the tests and merging master in and I'm happy to take this.\n. Just that one test attribute and this is good to merge!\nEDIT: whatever, I'm impatient. I'll fix that up on master.\n. Thanks for the amazing work @kristianhald \n\n. This is up on NuGet :metal:\n. I've not documented it, but I've adapted one of our integration tests to illustrate this API:\ncsharp\n[IntegrationTest]\npublic async Task CanGetListOfCommitsByPath()\n{\n    var client = new GitHubClient(new ProductHeaderValue(\"my-cool-app\"));\n    var request = new CommitRequest { Path = \"Octokit.Reactive/IObservableGitHubClient.cs\" };\n    var list = await client.Repository.Commits.GetAll(\"octokit\", \"octokit.net\", request);\n}\n. @willsb I think CommitEntity is a better term :grinning: - and you're more than welcome to make a start on it\n. \n. > @shiftkey that's not exactly correct.\n@Haacked this issue was so long ago that I suspect you're right (and/or I probably didn't make it clear).\n:thumbsup: to the work in #916 \n. Some CI failures in the CI process.\n- I think the serialization should work without the _ in Organization_Member\n- TypeInfo is the new Type - likely some extension method needs to be added for PCL-based platforms.\nDo we need to send any preview flags as part of updating this API?\n. > Corner me at BUILD. :smile: :cocktail:\nWord :cocktail: \n. > Should I pull-request mine lonely crutch in such good code? \nLet's discuss your workaround in a different thread to this. It's on my roadmap, I'm just trying to figure out the best way to get there right now...\n. Update: aiming to land repository redirects over in #808 as a way to figure out the HttpMessageHandler API\n. With #808 almost ready to go out the door, I found myself with a quiet moment to reflect on how to improve the initialization of GitHubClient - there's a number of overloads available which take different parameters, and it's not quite easy to navigate.\nI'd like to simplify this down to a number of options which are set by the user (this is just a demo):\ncsharp\nvar options = new ClientOptions\n{\n    AppName = \"my-cool-app\",\n    Credentials = new Credentials(\"my-token\"),\n    Server = \"https://enterprise.my-work.com\",\n    UseDefaultProxy = true\n};\nAnd as these are all HTTP-specific, they could be transformed into a HttpMessageHandler\ncsharp\nvar handler = OctokitMessageHandlerFactory.Create(options);\nvar client = new GitHubClient(handler);\nThis could also be the extensibility hook for doing more flexibile things at the HTTP level: \ncsharp\nvar handler = OctokitMessageHandlerFactory.Create(options);\nvar cachingHandler = new CachingMessageHandler { InnerHandler = handler };\nvar client = new GitHubClient(cachingHandler);\nI need to think a bunch about how to transition things carefully, but the wheels are already turning...\n. @darrelmiller \n\nfrom someone who just wants to plug in an extra piece of middleware.\n\nThat's something I've had in mind for a while (@haacked jump in here if you disagree with this direction) and ultimately we're re-implementing a bunch of the middleware currently - and I'd just love to get out of the way of those who want to dive in.\nThe ClientOptions could be a constructor interface on top of this, for consumers who don't want to go deep. There's some assumptions we've made (authentication, user-agent, etc) that these brave souls should be aware of, but I think a good goal here would be \"here's my handler, plug this into Octokit\" so that everything just works... \n. @Haacked \n\nI do think we should retain the simpler .ctors with the most common options.\n\nYou want to port the existing ctors on GitHubClient over to this ClientInfo class?\n. Seeing how we're all roughly on the same page here, I'm going to open up a new issue to track the roadmap and break down the work better.\n. @Haacked okay, I'll keep that in mind\n. @M-Zuber yuuup, I typed it up in a rush. I'll update it.\n. Fixed in #799\n. \n. Fixed in #792\n. \n. I'm indifferent on this as it's not something I use day-to-day. But if there's sufficient interest in this use case I would be happy to review a contribution about it....\n. @M-Zuber :thumbsup: to clarifying the docs as a good first step\n. Thanks!\n. I've marked IsMember as obsolete here with a note to use GetMembership and be consistent.\nEverything else is new APIs. Ready for review.\n. :ship:ed. I can't be bothered waiting for CI to complete (it passed before).\n. > As can be seen in some of the commits, a number of expected exception types had to be changed. \nThis is likely due to the fact we don't assert the exception type in that helper method I wrote. Oops.\n. @M-Zuber try this:\ncsharp\nawait Assert.ThrowsAsync<ArgumentNullException>(() => client.Create(null, \"name\", new NewBlob()).ToTask());\n. \nThanks @M-Zuber! \n. @dennisan the first parameter to Create should be owner of the repository, not your account:\nvar issue = await issuesClient.Create(\"mspnp\", \"roadmaptest\", newIssue);\nThat should get you back to a happy place.\nAs a sanity check, do you think we should warn the user if they try and specify more than just the repo name in that second parameter?\n. > Octokit.ForbiddenException : You have triggered an abuse detection mechanism and have been temporarily blocked from content creation. Please retry your request again later.\nNot much else I can do from here :grin:  (I hit this from time to time as well).\n. I think this test is more to see if alfhenrik is following anyone. It shouldn't depend on the user account running the tests. Do you agree @alfhenrik?\n. :thumbsup:\n. Also, we should confirm that message is actually optional while we're in there...\n. @alfhenrik it's now available in v0.12 on NuGet.\n. \n. Published: https://www.nuget.org/packages/Octokit/0.12.0\n. tools\\Octokit.CodeFormatter\\tools\\CodeFormatter.exe Octokit/Octokit.csproj /nocopyright\nOctokit.csproj\nERROR: Type loading error detected. In order to run this tool you need either Visual Studio 2015 or Microsoft Build Tool\ns 2015 tools installed.\n- Could not load file or assembly 'Microsoft.Build, Version=14.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a'\nor one of its dependencies. The system cannot find the file specified.\nmutter mutter mutter\n. Reviving this now that we're on VS2015. Go AppVeyor Go!\n. @darrelmiller if you're working on your fork and it's in a branch I know about, I can pull in your changes into this PR...\n. @darrelmiller your latest changes are applied onto this PR - thanks for that :sparkling_heart:.\ni'll look at those failing tests, and putting together some additional tests for the GitHub API.\n. Just added a passing test against the new redirects - I'll add some more later this week, but this is feeling rather close...\n. Added in a test for issue creation and finding a repository. Ready for review.\n. Just added one more little task before I'm happy with this.\n. Extracted #817 rather than drag this out any longer.\nReady for review :dog: \n. @haacked would love some :eyes: on this before I merge it and continue down the path of extracting more HTTP-friendly abstractions...\n. > If you are actually using the CredentialCache with credentials associated to the correct origin server, then when you redirect to a URL with the same host then the credentials are carried over.\nYep, I'd like to address this at some point - we should mimic this behaviour in our abstraction and move it into HttpClient.\n. @haacked bump for code review plz\n. \nI'll run through the integration tests and see if I can put together a :ship: on Monday (my time).\n. Thanks @alfhenrik for the sanity check!\n. Not currently, but it's been raised previously: #504\n. @Red-Folder you're right. I was thinking about it from the \"i need this info\" side rather than the fact you can get it in either place.\n\nI'm currently having a play at both. Hopefully produce a PR for the MiscellaneousClient some point next week.\n\nI think this is going to be easier to knock out than the details in #504, but I suspect we'll need both eventually. Thanks for looking into it!\n. The API only differentiates between authenticated and unauthenticated requests:\n\nFor requests using Basic Authentication or OAuth, you can make up to 5,000 requests per hour. For unauthenticated requests, the rate limit allows you to make up to 60 requests per hour. \n\nAre you not seeing that occur when the request passes through Fiddler?\n. Alternatively, you can block on the result (but this makes me sad whenever I have to write this code) so await is definitely The Recommended Way\u2122:\nvar kita = client.Repository.Create(newRepo).Result;\n. @elbaloo i'm not sure, probably just some docs (oh, and to merge master in).\n. Closing this in favour of #934\n. \n. And this is live https://www.nuget.org/packages/Octokit/0.13.0\n. So I think this is a rather straight-forward fix for someone who wants to grab it cc @smathilakath\nInside StatisticsClient we define the URLs with a leading /\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Clients/StatisticsClient.cs#L46\nvar endpoint = \"/repos/{0}/{1}/stats/contributors\".FormatUri(owner, repositoryName);\nThis means the HttpClient ignores the /api/v3/ prefix when interacting with an Enterprise server, generating a 404...\n. @khellang I think it was just an unintentional oversight at the time.\n. @gsscoder thanks for the details. It's a bit weird the way we add the System.Net.Http reference, but this is the first failure I've heard about it.\nWhat version of VS are you running?\n. @khellang when you're seeing it fail, what sort of project setup are you trying to add it to?\n. > Was able to install the package successfully from the Package Manager Console, but not through the Manage Nuget Packages UI.\nI guess I need to raise this upstream if it's still around. Thanks for the extra details all.\n. I've kinda sat on this for a while rather than report it upstream so maybe it's been fixed, but if someone is keen to confirm it's still occurring on NuGet v3 I'll help them to navigate the process of reporting this.\n. Yep. And with the port to .NET Core that's underway, the change to use the System.Net.Http NuGet package instead of directly referencing System.Net.Http as mentioned in https://github.com/octokit/octokit.net/issues/1419#issuecomment-267457741 should resolve this. . @ironfist not sure why await would behaving differently to .Wait() here, let alone Fiddler warning us, so let's dig into it.\nFor reference, here's the HTTP traffic from one of the integration tests around label creation. If you see something different on your end, that might be a clue:\n```\nPOST https://api.github.com/repos/shiftkey-tester/public-repo-20150623053815973/labels HTTP/1.1\nAccept: application/vnd.github.v3+json; charset=utf-8\nUser-Agent: OctokitTests (Win32NT 6.3.9600; amd64; en-US; Octokit 0.13.0)\nAuthorization: [snip details here]\nContent-Type: application/x-www-form-urlencoded; charset=utf-8\nHost: api.github.com\nContent-Length: 41\nExpect: 100-continue\nAccept-Encoding: gzip, deflate\n{\"name\":\"test label 1b\",\"color\":\"FFFFFF\"}\n```\nreturns\n```\nHTTP/1.1 201 Created\nServer: GitHub.com\nDate: Tue, 23 Jun 2015 05:38:18 GMT\nContent-Type: application/json; charset=utf-8\nContent-Length: 149\nStatus: 201 Created\n[snip other headers here]\n{\"url\":\"https://api.github.com/repos/shiftkey-tester/public-repo-20150623053815973/labels/test%20label%201b\",\"name\":\"test label 1b\",\"color\":\"FFFFFF\"}\n```\nAlso, if you change that .Wait() slightly do you get a valid label for the response? Or something different?\ncsharp\nvar task = github.Issue.Labels.Create(AppConfig.GitHubOrg, repo, new NewLabel(\"refactor\", \"fbca04\"));\nvar label = task.Result;\n. Yeah, that's real weird. Thanks for the log details, I'll see if this is Enterprise-specific or just something else altogether...\n. I must confess that I keep procrastinating on doing something to make Octokit integrate better with the ASP.NET stack. Thanks for bringing this to our attention.\n\nI noticed that the setters for PullRequestEventPayload are protected. This might be causing problems with the model binder.\n\nThis was also where my thought process went to. Perhaps we need to plug in a model binder that does things the SimpleJson way?\n. @haacked I wonder if we're making it hard/impossible for JSON.NET to deserialize with protected setters. Surely there's a quick way to test this suspicion at least...\n. As a more general-purpose solution, would it be worth seeing if we can change the JSON.NET behaviour in the model binding? \n. > However it would be nice that I do not need to do this and that the model binding in .NET would deserialze to the PullRequestEventPayload object.\nAgreed. As a workaround, I'd love to see if we can tweak the default model binders so that they can deserialize Octokit types properly. Otherwise, we're stuck with reverting those protected settings I guess...\nI have a side-project which is a webapp and Octokit.net fits in with it, so I think I'm going to feel this pain when it comes time to go down this path. Thanks for logging this anyway!\n. > How so? Like contribute it back to ASP.NET MVC? \nNah, was more thinking about a custom model binder. Anyway, the \"don't mutate this shit\" is a reasonable alternative if we have to go down that path...\n. :thumbsup:\n. @AlfredoMS do you have a specific test that I can run locally to see if I can spot which field isn't being mapped correctly?\n. \n@AlfredoMS let me know if you see it come back\n. @thedillonb thanks for the info, I'll pass it on to the API team\n. Rather than go through all the hoops for duplicating this internally, I'll just cc @pengwynn here and bug him in chat when I wake up tomorrow:\n- since=0001-01-01T00%3A00%3A00Z isn't considered a valid date under /notifications\n- since=2001-01-01T00%3A00%3A00Z works fine\n- probably just some edge case thing that was introduced recently\n. @haacked possibly, but I think that just hides the problem for scenarios where the range is actually invalid...\n. @dampir I do like enforcing some validation within Octokit to catch this, with a sensible error message delivered to the caller\n. Starting Target: SourceLink\nsource indexing C:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\bin\\Release\\Net45\\Octokit.pdb\nsource indexing C:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\bin\\Release\\NetCore45\\Octokit.pdb\nsource indexing C:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\bin\\Release\\Portable\\Octokit.pdb\nsource indexing C:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit.Reactive\\bin\\Release\\Net45\\Octokit.Reactive.pdb\nFinished Target: SourceLink\nLGTM - thanks @ctaggart! \n. Oh cool, the Win8 project. You're running Windows 10?\n. Oh, interesting. I'm not sure what the story is with Windows Store Apps + VS2015 but that gives me enough to reproduce it at least.\n. > I likely mucked something up installing, uninstalling, reinstalling, edit, reinstalling, etc... various Windows Kits and versions of Visual Studio.\nPossibly. But this is something I can verify without too much hassle.\nMy only concern is that the IDE doesn't let you download the bits you need...\n. Just tested this out on my version of VS2015RC, and I get this error too:\n\nC:\\Users\\shifkey\\Documents\\GitHub\\octokit.net\\Octokit\\Octokit-NetCore45.csproj : error  : The imported project \"C:\\Program Files (x86)\\MSBuild\\Microsoft\\WindowsXaml\\v12.0\\Microsoft.Windows.UI.Xaml.CSharp.targets\" was not found. Confirm that the path in the  declaration is correct, and that the file exists on disk.  C:\\Users\\shifkey\\Documents\\GitHub\\octokit.net\\Octokit\\Octokit-NetCore45.csproj\n\nI this this section where you enable the \"Tools for Maintaining Store apps for Windows 8\" bits is the way out of this - testing to confirm it...\n. Nope, that didn't change anything. I'll leave this open until July 20 and revisit it then.\n. @whoisj I had to fix some CI issues with MSBuild v14 - see #846 - however transitioning to VS2015 completely is something I'm still mulling over - it likely means I can't support VS2013 due to MSBuild migrations for the Store Apps projects, so I need to do it carefully.\nHang tight. \n. Asynchronously, perhaps.\nNot sure how much time I can dedicate directly, but happy to give feedback on stuff.\n. We did this in #956\n. Thanks for reporting this.\nThis method will change in the next release but I'll review this once #808 lands (as the 302 behaviour there affects this code).\n. @naveensrinivasan :sparkles::sparkles::sparkles::sparkles::sparkles: thanks for looking into this and getting it working.\n. @naveensrinivasan there's some VS2015 changes I need to handle (obsoleting Win8.0 support in particular) - I'd like to tackle this after I've got that in place and addressed some of the outstanding build/deployment issues.\n. @naveensrinivasan the VS2015 support is here https://github.com/octokit/octokit.net/pull/956 going to let it sit for a couple of days before closing. I might have a chance to play around with DNX support in the meantime, but feel free to target that branch if you've got stuff to share!\n. @naveensrinivasan it's not something I'm looking into - I'd like to ensure that contributors are happy with the VS2015 migration before I look at new language features... \n. Let's put the C# 6 discussions aside for now, but I'm keen to see us get DNX builds out now we're on VS2015. If someone is keen (or more familiar) with porting existing projects to the new platform I'm happy to jam with them on this.\nYou can see my previous attempt in #960 - it's close, but PCL support continues to torment me (as well as CI). \n. @khellang as part of this change I wanted to replace the existing csproj files that Octokit is currently building (it's nice that MSBuild now tells me via errors).\nHowever the one that I can never get right is Profile259. I've had various other people show me how they got it to work for their projects but it's never really mapped to how we've configured things with Octokit - I'm probably missing something, and would love to be shown how easy it actually is.\n. > What do you mean by \"get right\"?\nBasically, I'd love a framework inside project.json for \".NETPortable,Version=v4.5,Profile=Profile259\" to Just Work. \n\nI think we should just ditch ...\n\nFair, but one of the reasons I was bashing my head against having all the currently supported platforms inside a project.json file is that it'll then generate the correct NuGet package - and I'd like to drop the hand-crafted work that we do there.\nI've also not thought about how transitioning to project.json impacts the MonoDevelop/Xamarin Studio side - @naveensrinivasan anything we should be keep in mind?\n\nAnd aim for a single project.json with dotnet5.1, which is roughly the same as Profile259 (it has the same targets). \n\nThis seems fine. I just want to ensure we continue to support our existing platforms alongside the new dotnet/netstandard stuff...\n. Closing this out in favour of #1115 \n. That seems reasonable. I'm not sure if it's available in the PCL target we've chosen, but we can find that out easily enough.\nThoughts @Haacked?\n. An even better example: https://api.github.com/search/issues?q=repo:aspnet/dnx+repo:aspnet/dnvm+repo:aspnet/Hosting+repo:aspnet/DependencyInjection+repo:aspnet/HttpAbstractions+repo:aspnet/KestrelHttpServer+repo:aspnet/WebListner+repo:aspnet/Helios+repo:aspnet/Logging+repo:aspnet/Configuration+repo:aspnet/Options+repo:aspnet/BasicMiddleware+repo:aspnet/CORS+repo:aspnet/WebSockets+repo:aspnet/Localization+repo:aspnet/ResponseCaching+repo:aspnet/Session+repo:aspnet/FileSystem+repo:aspnet/DataProtection+repo:aspnet/Caching+repo:aspnet/HttpClient+repo:aspnet/UserSecrets+repo:aspnet/homebrew-dnx+repo:aspnet/benchmarks+type:pr+state:open&sort=created&order=desc&per_page=100\n. @damianedwards @M-Zuber writing up a walkthrough of the search options available - how does this read?\n. @khellang good point - if I'm breaking the API here I'll see if I can do better than just a collection\n. @haacked not really, I should write an example for SearchCodeRequest.cs because that's impacted by this change. But I think everything in the code is :sparkles:. I'll add a note.\n. @haacked sure, I just like putting docs in front of me - because otherwise they'll never get written :trolleybus:\n. @wdhodges to be honest, WebForms isn't something I've used for many years - so it's not something I've had in mind. If you're using .NET 4.5 it should all just work, and here's a good intro for testing that it all works. \nThe rest of the docs are here\nhttps://github.com/octokit/octokit.net/tree/master/docs\nbut if there's specific things you're interested in that aren't documented, let me know and I can add those to my backlog...\n. Appveyor's not very happy with me right now, but this is live: https://www.nuget.org/packages/Octokit/0.14.0\n. Oops, created this twice somehow\n. > What's up with the CI build?\nIt's been bumped to MSBuild 14.0 which is triggering a neat PCL/FxCop issue. Reported here\n. @khellang nah, I wanted to stick with v12 for the moment.\nI fought a bunch with the toolchain today, couldn't find a way out. It's a minor thing (I don't need to run FxCop on the PCL build as the code is shared) but an annoyance nonetheless.\n. > I had hoped the CI build would tell me, but no luck there either\ni got you bb. Once @haacked has had a chance to chime in I'll test things on VS2015 proper.\n. @haacked yeah, it's a VS2015 issue (Code Analysis yay) which we got accidentally upgraded to a few days ago details here.\nI'll address it in #835 which is the base branch for this PR.\n. The platform restrictions were actually related to the Mono* support - we weren't allowed to use those packages on non-Windows OSes. The Mono project for Octokit was/is still targeting .NET 4.5.\nWe drew the line there as our \"baseline\" for a couple of reasons:\n- The Task Parallel Library implementation received a lot of love in .NET 4.5, and is noticeably faster. We use tasks everywhere in Octokit, so we were happy as pigs in mud.\n- Portable Class Library support (even though it wasn't there at the time) had a sweet spot Profile259 which correlated to .NET 4.5 across all the platforms.\n- Dropping down to a PCL profile which included .NET 4.0 had a very limited subset of APIs - we'd have to re-implement even more.\nI'm not really interested in supporting Yet Another Platform\u2122 because this adds pain for new contributors as well as myself - I know of some people who have forked and are building Octokit from source, so perhaps that's an option here? \nAnd .NET 4.5 support is ending at the end of 2015, so I'll be taking some time out to review and simplify the platforms I target.\nLet me know if you have any other questions on this.\n. > 4.5 support ending? \nIt's outlined here: https://support.microsoft.com/en-us/gp/framework_faq?wa=wsignin1.0\n\nMicrosoft recommends that customers and developers using .NET Framework 4, 4.5, or 4.5.1 complete the in-place update to .NET Framework 4.5.2 by January 12, 2016 to continue receiving technical support and security updates.\n. \n. This is working on my VM with VS2015\n\n```\nMicrosoft (R) Build Engine version 14.0.23107.0\nCopyright (C) Microsoft Corporation. All rights reserved.\nOctokit-NetCore45 -> C:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit\\bin\\Release\\NetCore45\\Octokit.dll\n  Running Code Analysis...\n  Octokit -> C:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit\\bin\\Release\\Net45\\Octokit.dll\n  Running Code Analysis...\n  Octokit-Portable -> C:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit\\bin\\Release\\Portable\\Octokit.dll\n  Octokit-Mono -> C:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit\\bin\\Release\\Mono\\Octokit.dll\n  Octokit.Tests-Portable -> C:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests\\bin\\Release\\Portable\\Oct\n  okit.Tests-Portable.dll\n  Code Analysis Complete -- 0 error(s), 0 warning(s)\n  Code Analysis Complete -- 0 error(s), 0 warning(s)\n  Octokit.Tests-NetCore45 -> C:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests\\bin\\Release\\NetCore45\\O\n  ctokit.Tests-NetCore45.dll\n  Octokit.Reactive -> C:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Reactive\\bin\\Release\\Net45\\Octokit.R\n  eactive.dll\n  Running Code Analysis...\n  Code Analysis Complete -- 0 error(s), 0 warning(s)\n  Octokit.Tests -> C:\\Users\\brendanforster\\Documents\\GitHub\\octokit.net\\Octokit.Tests\\bin\\Release\\Net45\\Octokit.Tests.d\n  ll\n```\nBut I still see CI using an earlier version of MSBuild and running Code Analysis for the PCL project (ignoring the flag I set). I've chosen \"Visual Studio 2015\" for the build server - perhaps that needs to propagate.\n. I have no idea what this task was for, but we need to port the DocPlagiarizer code over to a Roslyn analyzer or something. I'll open that in #849\n. @Red-Folder it looks like there's a merge conflict with this branch - AppVeyor should go green after that's been addressed.\n. @Red-Folder given this is a new feature (and the test is written) I'm happy to take it in as-is. \nDon't stress too much about running the integration tests, it's certainly the toughest part of contributing (and something I need to revisit).\n. Yeah, I'm not surprised it's largely unchanged from then. Given it's value is in extracting docs from interfaces, we could switch it off to help support the x-plat experience.\nGiven it was built ontop of earlier builds of Roslyn, I'd like to see if we can port it over to the now-RTM analyzers that are in the box. I've not had a look at how this would work outside of VS2015, so any knowledge or war stories would be great to help us decide the transition.\n. We're tracking #971 to bring this functionality back, so I'm closing this out as #995 removed this.\n. We did this in #956 \n. This PR escalated quickly. Going to close this out and just focus on getting it all running on VS2015.\n. @AmadeusW interesting exception - can you tell me whether you're running this from a console application or within an ASP.NET app?\n. Interesting.\n@shana have you seen this before? any tips?\n. There's definitely something unclear about this API - you can see a test I've written to download an asset here:\nhttps://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/ReleasesClientTests.cs#L186-L206\nIn this case, I've done the download slightly different:\nvar response = await client.Connection.Get<object>(new Uri(asset.Url), new Dictionary<string, string>(), \"application/octet-stream\");\nI think something weird is happening with the deserialization if you don't specify the appropriate Accepts header (probably defaulting to JSON, which would explain something null-ing out.\n. @kdolan well that's not great!\nIs this a repository I can test out (even privately?) - perhaps there's some edge case here I haven't seen before while working on this area...\n. @kdolan thanks, I'll check it out\n. I'm pretty sure that /:user/:repo/releases/:id needs to be called with Accept: application/json as this is returning the payload of release assets:\nhttps://developer.github.com/v3/repos/releases/#get-a-single-release\n\nIt would appear then that maybe the BrowserDownloadUrl is what needs to be used\n\nCorrect\n\nhowever, whenever I try to download the file using postman I get a 404 (because it is a private repo) and token authentication does not appear to work for the browser download URL.\n\nOkay, this definitely sounds interesting. Do you see the Authorization header being set when you use the BrowserDownloadUrl value?\n. @naveensrinivasan \n\nlet me know if you want me to do PR on this?\n\nThat'd be great!\n. @Red-Folder I'd suggest a couple of calls:\n- ETag can be found by creating a new repository - that should be easy enough\n- Links are a bit trickier (because most of our existing APIs are going to follow them as part of pagination). You might be able to check for the last value after the pagination is done - so something like \"list your repos\" might work for you.\n- X-OAuth-Scopes and X-Accepted-OAuth-Scopes require the caller to be configured with token authentication - that depends on the OCTOKIT_OAUTHTOKEN environment variable being set, but the caller might not have this setup.\n. @davidalpert thanks for finding this and fixing it!\n\n. Looks good to me!\n\n. @haacked did a demo of this for an ASP.NET app https://github.com/Haacked/octokit-oauth-demo\nI've not looked at doing this for a client-side flow, but the current advice is described here.\n. Adding this to the VS2015 milestone as it requires the end user to have access to VS2015 to build it...\n. @haacked apologies, I mixed this up with another PR - I thought I saw some nameof usage in here.\n. >  Note that there's no way this would be green if I used C# 6 features, right?\nCI is running against MSBuild v14, so compiler support for these new features is available. But yes, as @khellang pointed out we've locked the projects to C# 5...\n. > Have you thought about when you'd like to cross over to the greener C# 6 side?\nNot until after the VS2015 migration is done at the earliest...\n. \n. \n. @RandomlyKnighted GetHtml is just a shortcut to set the Accepts headers when making a request. The server is free to ignore this or just give us something else, and that's what's happening here.\nThe problem is with this section:\ncsharp\nforeach (var asset in assets)\n{\n    if (asset.Name.Equals(\"release-notes.html\"))\n    {\n        assetURL = asset.Url; // this line\n    }\n}\nasset.Url points to the JSON payload for the file - here's an example from the docs https://developer.github.com/v3/repos/releases/#get-a-single-release-asset\nIf you want the contents of this file, you'll need to use the asset.BrowserDownloadUrl instead.\n. @RandomlyKnighted correct\n. This is really great! Thanks for picking this up!\nIf you feel like scoring some extra credit it'd be great to add an integration test so we can use the real API. If you're not confident, that's okay - just let me know and I'll add it to the backlog (and can add some other pointers).\n. > I didn't want to add another one as I'm not sure it asserts anything useful?\nTo be honest, that's basically what I'd love to see here. Something simple to catch regressions which reflects the usage of this API. \n\nPerhaps I'm misunderstanding the tests?\n\nThe integration tests are there to catch anything unexpected changing between the API we expect (i.e. the library) and the API we have (i.e. the server). It's something I always run as part of doing each release, so if we can keep it in sync I'll be a happy maintainer.\n. > I would like to find all the issues that have at least one of these labels, but from the results I think that are selected only the issues have all these labels.\nCurrently this is a limitation of how the upstream API works, so we're stuck at \"find issues tagged with all labels\" or \"request per label\".\nI'm not sure how clever we should be on the client about this to hide away this limit, but I'm open to suggestions.\n. @lucamorelli fair point. However it'd change the behaviour of the API, which existing consumers might be reliant upon.\n. > I'm reading the list of the Pull Request list of a repository looking for all the merge, but I noticed the property Merged is always false, \nI think this is a serialization issue - there's no merged field sent by the server, so it should be marked as obsolete in favour of using MergedAt. See an earlier discussion on this (at least I think it's the right thing I was ranting about) https://github.com/octokit/octokit.net/issues/502\n\nAnother thing: How can I find the final commit generated at the end of the merge?\n\nThe MergeCommitSha property should be set when the pull request has been merged, but a quick scan of some old PRs indicates that it doesn't match the expected Git commit. \n@pengwynn I'm looking at https://github.com/octokit/octokit.net/pull/857 and I see a comment about https://github.com/octokit/octokit.net/commit/1776ca1086a861b81bd499aaf8a0dd9da76ca4ce being the merge commit.\n\nHowever when I retrieve it from the API I get a different value: https://api.github.com/repos/octokit/octokit.net/pulls/587\nmerge_commit_sha=e27e3c3c9fafe3b69b238b478981587837fd62f0 appears to be a server-side commit (possibly the merge after it was last pushed).\nThere's another issue which I'm poking into about how a different value appears when this PR is listed in /pulls?state=closed which I still need to dig into, but let me know if I'm missing something obvious...\n. The MergedAt change is now available in v0.18. I think we're good here.\nI've got a side project which depends on whether a pull request is mergeable (rather than past-tense merged), so once I've updated that I'll come back to this to see if there's any extra work to do here.\n. This idea intrigues me, but I'd like to settle on a vision for the package before starting down the path of writing code:\n- what problem is this trying to solve?\n- what belongs here rather than in the core packages? are there common things that consumers are implementing?\n- is there another way to satisfy this problem, without introducing a new package?\n  - documented examples\n  - interactive samples ala LINQPad #505 \n. @M-Zuber all good, happy to leave this open and see what sort of interest it garners...\n. > So #1243 is relevant to this.\nAt this point I think it's easier for us to enhance the actual response objects - especially when it's something additive and we know it'll be supported.\n\nseems to have resulted in crickets\n\n:cry: \n. Looks like CommitsClient.Get should return the files element from the server, however the typed Commit response doesn't have the property.\n. @lucamorelli I think this new property needs to be added to Commit -  see https://github.com/octokit/octokit.net/pull/696 for a similar scenario\n. I'll leave this open as an opportunity for someone to add it in.\n. This works for me on the latest Octokit release (v0.18):\n[IntegrationTest]\npublic async Task CanGetFilesInCommit()\n{\n    var commit = await client.Repository.Commit.Get(\"octokit\", \"octokit.net\", \"65a22f4d2cff94a286ac3e96440c810c5509196f\");\n    Assert.NotEmpty(commit.Files);\n}\nClosing this out as I'm not sure what else we need to do here.\n. @dimitrisTim can you please open a new issue with more information and/or a code sample of what you're trying to achieve? Thanks! \n. > However if you are testing with an auth token, then the current credentials will not have the login (just the auth token).\nThat's a great point. Nice spot!\n\nOk ... mental note to self - if using Personal Access Token for integration testing - make sure if has the relevant Scopes (was missing delete_repo)\n\nThere's a way to check what scopes you have defined, but I've not spent much time with this. We could investigate scripting this out to verify it.\n. @Red-Folder digging my way out from under a heap of psychic debt at the moment, so i'm not quite sure when I'll get to investigating this. But thanks for reporting it! \n. Bumping this and opening it up for investigating, because I've seen it while testing #989\n. @Red-Folder it's all good. I wish I had a better answer for you about what might be happening but I've got many Windmills\u2122 to Tilt At\u2122* at the moment...\n* citation\n. :shipit:\n. Correct :cry:\n. :thumbsup: I've been meaning to obsolete this endpoint\n. > You must not insert the repository name into the Head string... I've opened a separate issue to clarify the docs to prevent anyone else struggling for hours with the same thing.\nCorrect. The only time you need to specify more than the branch name for the Head is when you're creating a pull request against another repository (fork -> upstream is the most common scenario).\n. > In addition, Octokit should validate the format and throw if it's invalid.\nThinking out loud here, the scenario we had in #879 was that this was an invalid ref mikeparker:prcreator-testing/branch-to-merge. Refs can be namespaced, e.g: shiftkey/my-cool-feature - and as edge-case as it might be, prcreator-testing/branch-to-merge could also be a valid ref. Without hitting the API, we can't verify it.\nPerhaps a better error message here (it's pretty easy to test this against the real API) with a reference to the docs page for creating a PR to help diagnose?\nI don't want to make this area too clever, but I empathise with the lack of docs in general.\n. @mikeparker thanks for reminding me about this.\n\nif anyone thinks it should be bumped down a bit \n\nLet's put it in after Getting Started\n. > How do I get Repo the issue belongs to?\nUnfortunately the raw JSON doesn't contain anything related to the repository. I'd recommend parsing the HtmlUrl property on the issue (you could look at everything before /issues in the URL).\n\nFor each of these issues I want the comments on them.\n\nThere's a comments_url property on the raw JSON which we're not surfacing. We should do that.\nAlternatively, you could just go and fetch it directly:\n```\nvar issues = await GitHub.Issue.GetAllForCurrent();\nforeach (var issue in issues)\n{\n    var comments = await GitHub.Issue.Comment. GetAllForIssue(\"owner\", \"repo\", issue.Id);\n}\n```\n. Opened https://github.com/octokit/octokit.net/issues/883 to address the missing property\n. Fixed in #884 \n. :ship:ed https://www.nuget.org/packages/Octokit/0.15.0\n. :thumbsup: thanks!\n. As this is related to the GitHub product itself, rather than the API clients, I'm going to close it out.\nFor reference, the API is now returning locked properties for issues in Octokit (but not Pull Requests, so https://github.com/octokit/octokit.net/issues/1084 is that task). When the other stuff becomes available, we'll expose it in Octokit.\n. The relevant docs:\n- https://developer.github.com/v3/issues/#lock-an-issue\n- https://developer.github.com/v3/issues/#unlock-an-issue\n. @prayankmathur which branch is this for? If you could open a pull request it will run against our CI infrastructure - and let us see what the failures might be about...\n. \nxref https://github.com/octokit/octokit.net/issues/756\n. I don't mind putting together a proper packaging script (these conventions seem nice) - it'll just need some checks before to ensure everything is setup correctly.\n. @naveensrinivasan is this still occurring for you after we setup CI for the Mono builds?\n. @naveensrinivasan please reopen if this is still occurring\n. @haacked I had a go at rebasing this branch but encountered some conflicts.\nI'm not sure I was doing it right - would love some feedback on bringing this up to date.\n. I knew this PR looked familiar! Let's close this out!\n. Thanks for digging into this. Hopefully now I'm back I can help out with improving things around the build side.\n. Looks like there's a csproj merge conflict here :cry:\n. I don't think that second build is ever going to complete, so I'm gonna merge this in.\nThanks again @alfhenrik!\n. Apologies for the delay, and thanks for working on this!\n\n. \n. Thanks for this - I merged in the csproj conflict so this is :ship:ed!\n. Blocked on https://github.com/ctaggart/SourceLink/issues/106\n. Was able to workaround the SourceLink issue in https://github.com/shiftkey/octokit.net/commit/e389f08153d19cc0a9902fff9fc671cdce01f765 with a bit of F# munging. Now to tidy up everything else.\n. @ctaggart thanks for looking into it!\n. Just did a run-through of this process with a fresh clone, and here's the process:\n- git clone ... - note that the core.autocrlf thing isn't set because it's an implementation detail\n- ./build as per the README - I've kept this script around but it now shells out to bootstrap, build and then test scripts.\nSo the big headache we had previous was that SourceLink required the core.autocrlf setting to be a certain value - otherwise shit just breaks. Here's what happens now as part of the bootstrap step:\n```\n\n./script/bootstrap\nWARNING: core.autocrlf not configured correctly for repository\nYou will have problems with generate the source indexing during packaging.\n\nBut guess what? I can set this up for you!\nThis will overwrite any changes in your local working tree.\nIf you want to continue, press Y.\nPress any other key to skip this.\nWould you like me to configure this: Y\nDone!\nInstalling dependencies...\nPackage \"FAKE.Core\" is already installed.\nPackage \"xunit.runner.console\" is already installed.\nPackage \"SourceLink.Fake\" is already installed.\nPackage \"FSharp.Data\" is already installed.\n```\nThis means less hunting around in docs for setting this value (and then remembering to run some other git commands afterwards). We can also guard against this when packaging:\n```\n\n./script/package\nC:\\Users\\shiftkey\\Documents\\GitHub\\test\\octokit.net\\script\\package.ps1 : core.autocrlf not configured correctly for\nrepository\nAt line:1 char:1\n+ ./script/package\n+ ~~~~~~~~~~~~~~~~\n    + CategoryInfo          : NotSpecified: (:) [Write-Error], WriteErrorException\n    + FullyQualifiedErrorId : Microsoft.PowerShell.Commands.WriteErrorException,package.ps1\n\nC:\\Users\\shiftkey\\Documents\\GitHub\\test\\octokit.net\\script\\package.ps1 : Run ./script/bootstrap to set correct state\nfor packaging\nAt line:1 char:1\n+ ./script/package\n+ ~~~~~~~~~~~~~~~~\n    + CategoryInfo          : NotSpecified: (:) [Write-Error], WriteErrorException\n    + FullyQualifiedErrorId : Microsoft.PowerShell.Commands.WriteErrorException,package.ps1\n```\nCould probably be a bit more friendly. But anyway...\n- After doing your ./build it's a one-liner to package things up:\n```\nC:\\Users\\shiftkey\\Documents\\GitHub\\test\\octokit.net [some-better-build-scripts]> ./script/package\nPatching FAKE app.config to workaround assembly binding issue...\nCreating packages...\nBuilding project with version: LocalBuild\nShortened DependencyGraph for Target CreatePackages:\n<== CreatePackages\n   <== SourceLink\n   <== CreateOctokitPackage\n   <== CreateOctokitReactivePackage\nThe resulting target order is:\n - SourceLink\n - CreateOctokitPackage\n - CreateOctokitReactivePackage\n - CreatePackages\nStarting Target: SourceLink\n...\nFinished Target: SourceLink\nStarting Target: CreateOctokitPackage\n...\nFinished Target: CreatePackages\n...\n```\nThe scripts are now more composition-friendly, not sure how others feel about this granularity though...\n. Closing this one out in favour of addressing more concrete issues as they are identified, like:\n- versioning packages from CI for better automation\n- writing up the release documentation\n- probably some other things\n. @aaron-comyn oops, totally missed that last message. \nThanks for the details, and there's actually some things we do under the hood to take the control away from you here - the Content property is a .NET string and we decorate it with a [SerializeAsBase64] attribute so that the user doesn't need to remember to do that. That's clearly not what you're looking for here, and I'm grateful for that example using the Git Data API.\nI've opened https://github.com/octokit/octokit.net/issues/1143 to track this feature as a parity item.\n. I'm kinda indifferent on which we choose (I neglect both really equally, so I don't really have a horse in the race) but I think sticking to one would be better.\nAre there specific features from either platform you're really attached to?\n. Yep, I don't mind doing that to take away that invitation pain...\n. Hearing news like this concerns me a bit:\n\nI got on the phone with a couple of Slack people last week, and they have decided not to support infinitely large public communities. Slack wants to focus on building team communication software, and groups like Reactiflux don't fit into that.\n...\nThe only way we could stay with Slack would be to cap our user base at < 8k. Probably around 1-3K. This obviously doesn't work for an open community. The most important thing about our community is that it's open and anyone can join in less than a minute. So when new people want to join the conversation, it's very low friction. We obviously can't keep the friction low if we start moderating accounts to keep our numbers low.\n\nI know we wouldn't be at that scale for a while, but it's in the back of my mind.\ncc @pengwynn \n. Feels @haacked?\n. Not really. As all the API calls for Octokit are done over HTTP/S we're kinda restricted to using the Authorization header.\n. > How about the HTTP credentials helper thingies? \nThese store the username/password/token somewhere on the local machine. Those would be usable in Octokit if you extract it, but this is often tied to the Git installation (Octokit doesn't depend on git.exe)\n\nI don't use them myself (I'm an SSH man) but I don't suppose there's anything built into Octokit for talking to them?\n\nAfraid not, because they're two very different ways to authenticate:\n- SSH is session-based (connect to remote machine) versus HTTP's request/response model\n- with public-key infrastructure like this, keys can be managed better between actors compared to credentials\n- all this occurs on a different port (22 versus 80/443)\nIf you're looking for an alternative to providing your HTTP credentials, you could look at Personal Access Tokens or having an app create authorizations on a user's behalf.\n. This seems to have a whole bunch of unnecessary commits (the branch is so stale at this point it'd probably be easier to rebase and bring it up to date). Thoughts @elbaloo?\n. > Could it be that StandardAjaxv0.1.2-df225a37-acb9-4e02-acc6-a517a88956d2 is private? If so, does the token have that scope?\nI can see this branch on the repo, so I don't believe it's that.\nThanks for the repro, and sorry for the delay. I'll have a look at recreating the issue on my end.\n. So I took the same parameters from above and ran the same steps from the repro:\n```\nPOST https://api.github.com/repos/SnowflakePowered-Packages/snowball-packages/pulls HTTP/1.1\nAccept: application/vnd.github.quicksilver-preview+json; charset=utf-8, application/vnd.github.v3+json; charset=utf-8\nUser-Agent: Octokit-Test-Bench (Win32NT 6.2.9200; amd64; en-US; Octokit 0.16.0)\nAuthorization: Token [redacted]\nContent-Type: application/x-www-form-urlencoded; charset=utf-8\nHost: api.github.com\nContent-Length: 123\nExpect: 100-continue\nAccept-Encoding: gzip, deflate\nConnection: Keep-Alive\n{\"title\":\"This is just a test\",\"base\":\"master\",\"head\":\"RonnChyran:StandardAjaxv0.1.2-df225a37-acb9-4e02-acc6-a517a88956d2\"}\n```\nAnd the PR was created successfully - https://github.com/SnowflakePowered-Packages/snowball-packages/pull/2:\n```\nHTTP/1.1 201 Created\nServer: GitHub.com\nDate: Mon, 12 Oct 2015 10:05:26 GMT\nContent-Type: application/json; charset=utf-8\nContent-Length: 16484\nStatus: 201 Created\nX-RateLimit-Limit: 5000\nX-RateLimit-Remaining: 4999\nX-RateLimit-Reset: 1444647926\nCache-Control: private, max-age=60, s-maxage=60\nETag: \"bc7e3d03794f3beeb32704dda5bf1cd0\"\nX-OAuth-Scopes: gist, repo, user\nX-Accepted-OAuth-Scopes: \nLocation: https://api.github.com/repos/SnowflakePowered-Packages/snowball-packages/pulls/2\nVary: Accept, Authorization, Cookie, X-GitHub-OTP\nX-GitHub-Media-Type: github.v3; param=quicksilver-preview; format=json\nX-XSS-Protection: 1; mode=block\nX-Frame-Options: deny\nContent-Security-Policy: default-src 'none'\nAccess-Control-Allow-Credentials: true\nAccess-Control-Expose-Headers: ETag, Link, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval\nAccess-Control-Allow-Origin: *\nX-GitHub-Request-Id: 5883D9F2:AB2E:592639E:561B85E5\nStrict-Transport-Security: max-age=31536000; includeSubdomains; preload\nX-Content-Type-Options: nosniff\nVary: Accept-Encoding\nX-Served-By: 593010132f82159af0ded24b4932e109\n{\n  \"url\":\"https://api.github.com/repos/SnowflakePowered-Packages/snowball-packages/pulls/2\",\n  ...\n}\n```\nSo what I believe might be happening here is that the is published, but the delay between that occurring and creating the PR is too short (so the PR isn't created because it can't \"find\" the branch).\n@RonnChyran if you were to run through the steps again, could you note the delay between creating the reference here and then creating the pull request in Fiddler?\n. > Part of deploying release's involves manually creating ReleaseNotes based on PR's merged from the previous git tag to now\nI'd like to do this separately for a couple of reasons:\n- internal things unrelated to public changes are not listed in the release notes\n- calling out multiple contributors on a PR (look at commit authors as well as the PR owner) is also something I like to do for each release\n- the PR titles are often rough or incomplete, and I like to clean them up before publishing\nThere's a related project GitReleaseNotes which is also in this vein which I think can help here, or something similar to your script, but for now can we punt on addressing that here?\n. @naveensrinivasan this is looking really great, thanks for taking the time to work through on this.\nI'll have a play around with it next week, just a couple of questions about the parameters used to identify the GitHub account owner (versus the organization the repository belongs to).\n. @naveensrinivasan I still like the idea of this, I'm just trying to figure out the best way to incorporate this into our processes - for example, AppVeyor supports publishing GitHub releases too.\n. @adamralph fair enough - and packages are already created locally. I'm just trying to tackle two different things here which are tangentially related to publishing releases:\n- the ability to publish pre-release packages automagically - I'd love to steal what libgit2sharp has done and repurpose that here\n- publishing official releases without needing my environment - that's a bit tricker, but builds upon the previous step\nYou can see what this looks like when you drive it from config rather than the server's settings...\n. @elbaloo apologies for the delay - this looks great! It just needs a merge from master to address the csproj conflicts...\n. @chenjiaming93 a couple of little things to tidy up, but this is looking great!\n. Closing in favour of #957 \n. This also looks like it has the changes in #935 and #936 - are you able to use the trick from #947 and just cherry-pick this one commit?\n\ngit cherry-pick 09051a03\n. Closing in favour of #957\n. @chenjiaming93 have you committed and pushed the changes to the project file to your branch? I can only see the original error occurring...\n. Closing in favour of #947 \n. I'll take this in and then rework my stuff in #924 to be x-plat friendly. Just that one question.\n. @naveensrinivasan sorry, I should have been clearer. As this is new code (around an area we don't currently support) I'm happy to take this in and then iterate on it.\n. @alfhenrik yeah, that should be a bool?.\n\nI'll leave it up to you, but if I spot it during my next test run I'll address it then.\n. Kinda puzzled why we're only noticing this now. Whatever, the test suite did it's job :metal:\nThanks!\n\n. I always run the integration tests before a release, so perhaps it's just a recent change...\n. I think this is good to go. @Haacked?\n. Ugh, we really should have the response payload in that error message so it's easier to follow.\nCan you put Fiddler in between and see what the response payload looks like?\nI'm not aware of anything recent with the Releases API changing, but I can bug them if we spot something weird.\n. I think I had problems with the VS extension for this when I last looked at it, but I'm not opposed to taking in something if others would like it.\nI'm also leaning towards using a code formatter ala golang (see #807) to automate this. \n. There seems to be some changes in here related to the issue search. Could you refresh my memory on which issue those changes are addressing?\n. @chenjiaming93 \nGiven there's some other branches for Pull Request Assignee and Pull Request Merged, you could have a go at rewriting this branch to contain just those commits.\nI'll walk you through the process to explain what's happening. You should have a remote named origin and one names upstream, you can check them like this:\n\ngit remote -vv\n\nIf you only see origin listed, run this:\n\ngit remote add upstream https://github.com/octokit/octokit.net.git\n\nAnd now you've done that, ensure you've got the latest changes from both repositories:\n\ngit fetch --all\n\nWe'll switch to our branch we're working on:\n\ngit checkout arbitrarymarkdown\n\nAnd we're going to put it back to whatever is the latest from upstream:\n\ngit reset upstream/master --hard\n\nIf at this point you feel unsure about continuing, this is how you get back to your previous state:\n\ngit reset origin/arbitrarymarkdown --hard\n\nNow, we're going to add those three commits onto our new branch:\n\ngit cherry-pick cde7254d\ngit cherry-pick 7c1c86fc9\ngit cherry-pick b084d9f5\n\nOnce you've tested out things with a .\\build BuildApp, you can push this to reset the PR:\n\ngit push origin arbitrarymarkdown --force\n. Closing in favour of #957\n. Just organized the existing documentation under something resembling a hierarchy:\n\n\nI'm sure there's stuff you'd like to see in here - sound off!\n. After getting a good(-ish) night's sleep I think there's a few sections we can define here:\n- Introduction - walk through the basics of using Octokit in your app\n- Features - explain the various parts of the API with some sample code\n- Guides - more complex examples and scenarios\n- Internals - discussions about the architecture and how it all works\n- Contributing - things current and potential contributors should read\n. Once this goes green, I'll merge it and try splitting out some documentation tasks if people want to dive into this.\n. Oops, it's targeting master. Do you mind reopening against documentation?\n. Just one little question. Everything else is :gem:\n. Sorry, a couple more things while I'm in here.\n. \n. If you want to get rid of those changes:\n\ngit reset octokit/documentation --hard\ngit cherry-pick d80b8a31\n\nand then force push it away...\n. @hahmed that's the one!\n. Making pre-release builds of master available is something I'd like to do, but there's various other infrastructure needs that I need to address first (VS2015, scriptable releases, x-plat).\nI'll leave this open to remind me.\n. I think so - once we've merged a PR, it's an indicator that master should be in a usable state.\n. We're already creating these packages as part of the CI build, but there's a few enhancements we need before we can complete this:\n- implement versioning scheme for pre-release packages - see what libgit2sharp has done here for example\n- detect whether build should be packaged and do this after the build is completed.\nWe've already added notes about the pre-release feed in the README, not sure what else we've missed.\n. Opening this up as up-for-grabs for someone who wants to dive into Appveyor customizations...\n. @eriawan I'm not sure what \"daily LKG\" stands for. Thanks!\n. > My two cents we should have a sample that produces some result.\nI think this is a nice goal, but perhaps we can address this elsewhere - with more interactive or detailed examples? For these sections, we should be focusing on understanding the API options available.\n. Thanks!\n. @Haacked it looks like the xml-doc warnings are causing the build to fail incorrectly. I really don't want to go through and triage it all, but maybe I have to?\n. @Haacked good point, I'll do that now and see if the build is happy with that...\n. \n. I'll also pull in #935 as that just has a bit of feedback to address.\n. This work is still outstanding.\nFor reference, here's the documentation: https://developer.github.com/v3/repos/contents/#create-a-file\nI think extending CreateFileRequest to provide this new parameter is the best way to go about it.\nI'd also have a look at UpdateFileRequest (and the docs https://developer.github.com/v3/repos/contents/#update-a-file) as the changes should be similar for both action.\n. @M-Zuber I think a new ctor taking the branch name is good enough here\n. @M-Zuber also, thanks for noticing the base class before it was too late :grin:\n. While dropping the constraint means that you can get to the root of the repository, I think this behaviour is still unclear. Would it be smarter to have an overload that doesn't take a path?\ncsharp\npublic async Task<IReadOnlyList<RepositoryContent>> GetAllContents(string owner, string name)\n. @naveensrinivasan you're right, I hadn't thought about the refs side. While we are adding in a lot of overloads here, I think they all end up going through one method - so we should be fine.\n. Looks like some extra changes are in here. I've extracted the relevant commits to #1064 to bring this up to date.\n. cc @khellang \n. @naveensrinivasan yeah, that's on my list once I get to the bottom of the various build issues I've found switching over to use project.json for building multiple projects\n. @naveensrinivasan nah, I'm going to close this out due to frustration (and things moving around again).\n. This markup shows the build's \"unknown\" badge:\n[![Build Status](https://travis-ci.org/octokit/octokit.net.svg)](https://travis-ci.org/octokit/octokit.net)\ni.e.\n\n@naveensrinivasan if you can add a new commit to this branch you should see it trigger (I've enabled it only when the .travis.yml file is present..).\n. @naveensrinivasan I'd say this is because the badge status is looking at the default branch (which hasn't been built yet!)\n. Looks like the AppVeyor error is a bit different to what we're tracking in #983 \n. @naveensrinivasan ~~if you merge master into this it should be ready to merge and close out!~~\nEDIT: no, nevermind. I forgot what past me wrote above.\n. Oh wait, that build error is on me to fix. I'll take this in :metal:\n. @Haacked wrote a sample a while ago about using Octokit to do the OAuth dance (it's in an MVC app, but the concepts are the same). The blog post and sample code should help you wire everything up.\nAs an aside, I'd strongly recommend against storing the user's credentials directly. OAuth was designed so that your application would have a token delegated to you by the user, which they can then revoke in the future if they feel the need.\n. @eiriktsarpalis we already have an override for the timeout when uploading a release asset. Apologies for not mentioning it earlier:\nfsharp\nlet assetUpload = new ReleaseAssetUpload(fi.Name,\"application/octet-stream\",fs, Nullable (TimeSpan.FromMinutes(5.0)))\nCan you confirm this addresses the issue?\n. I must confess that it's been a while since this was last raised https://github.com/octokit/octokit.net/issues/567 - and given how people seem to be care when this gets in the way I'm going to look at whether it's possible to just remove this limitation. How does that feel @eiriktsarpalis @naveensrinivasan? \nI'll follow up in #965 about the global change for timeout, because there's other tangential stuff to talk about there.\n. Yeah, this is something I'd like to make available to consumers - I've just been grappling with how to get there due to how we're currently using HttpClient - see #781 for all the details.\nYour solution highlights the pain we're currently in with respect to overloads to GitHubClient, and most of the ctor parameters can actually be used for HttpClient. I don't feel great about layering more on there, but perhaps that's a reasonable short-term fix.\nIt's been almost six months since I last thought about this, so I'll go back to this and revisit that topic.\n. @naveensrinivasan @Haacked yes, if you're on VS2015 you should be able to run it from the command line: .\\build FormatCode\nIf that's not working As Advertised\u2122, I can investigate further.\n. @naveensrinivasan first off, thanks for working on this. I should have made my reservations about adding another ctor parameter clearer, as I'd been trying to think of a better solution to this problem but was sidetracked as usual.\nI'm not enthusiastic about adding in yet another ctor parameter to GitHubClient - mostly due to the current complexity of how timeouts work with the HTTP stack, which you've called out elsewhere. The other concern I have here is about supporting this long-term - at some point I'd love to support a smaller set of ctors on GitHubClient, but that's a debate that has yet to happen so I'm just speaking for myself right now.\nSo, while I feel awful for closing this PR, I'm trying to make amends by opening a discussion about making the whole HTTP stack more friendly to Octokit consumers #984. I've also opened the first PR which takes us down that path #985 so we can talk about tangible things. I'd love your feedback on either (or both!) topic, as I don't think there's as much work involved as I previously expected - we just need to sit down and work through it...\n. This will go out in the next release (v0.19?)\n. @ferventcoder thanks for the details. Having a look now into whether it's serialization-related.\n. @ferventcoder seems to be related to serialization on our end. Which account is associated with making the API requests?\n. GitHub\n. But whether the fix is there or something in Octokit is something I need to confirm. How long ago was the first known incident of this?\n. @ferventcoder I wasn't able to recreate it using the serialization logic we use, and I was laid up today with a crook back. On my list for tomorrow, any extra help reproducing it would be :sparkles::heart:\n. @ferventcoder @naveensrinivasan apologies for not getting back to this yesterday. Thanks for troubleshooting! :metal:\n. I think we should have closed this out a while ago @ferventcoder let me know if you see it again.\n. Literally just discussing this headache with @haacked. Contemplating scraping the website to get this list.\n. Nevermind, looks like @naveensrinivasan might have already cracked this:\nhttps://twitter.com/snaveen/status/674384982803136513\n\n. @naveensrinivasan this is so good! I'm kinda buried in work-related stuff this week but I'll try and make time to look into this...\n. Closing this out in favour of #1038 - will spin more work out from that.\n. Authorizations need an application id and secret, so that the user knows the context of why the token was created, and can revoke them at a later date.\n. > With everything I've read the id and secret need to be kept (not surprisingly) secret, but that's not possible if the code is open source.\nTotally agree, but there's many ways to do this - for example, we use environment variables we manage the credentials for the integration test suite:\nhttps://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Helper.cs\n. @dail8859 correct\n. Closing in favour of #997\n. Nope. I'd like to port these rules over to Roslyn analyzers and code fixes so they Just Work Wherever\u2122.\nI'd be fine with disabling those when running outside of VS, or just :fire: it as things are relatively stable right now - it was a great help in the early days as the codebase was being built up.\n. Now that #995 has been merged (removing this dependency) I'd like to see if we can bring it over as an analyzer - DocPlagiarizer was built using old versions of the Roslyn API, so I'm sure there's some way to port it.\n. @Haacked @asizikov  make it so!\n. @asizikov yeah, that's #983 \n. @asizikov if you merge master into your branch you should have a green build again\n. @asizikov thanks!\n\n. Looking good so far @chenjiaming93! \nA couple of things I'd like to verify as part of integration tests:\n- that we're able to deserialize a release correctly using this endpoint\n- what happens when no releases exist for a repository?\n. @chenjiaming93 we have some existing tests which use the real GitHub API - let's add a couple of tests for this endpoint there: https://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/ReleasesClientTests.cs\nA couple of tests I think we can do to complete this feature:\n- \"get the latest release for Octokit\" - we get a non-null Release back\n- \"get the latest release for a new repository\" -> get a helpful error back\n\nIf there is no latest release, are we expected to get a Null JSON or we a 500 error?\n\nI'm honestly not sure - let's find out by writing the test!\nI think the end result should be a custom exception that we throw to the user. There's a detailed example here for how we handle when creating a repository fails - I think you'll have to do something similar and try-catch the call and then check if the error is something we're familiar with. \n. I've moved the integration tests out to #1086 rather than hold this up any longer.\nThanks for the contribution @chenjiaming93! \n. Had a look at this and found it to be a larger yak than previously anticipated. Problems to address:\n- lprun doesn't have an easy way to install certain packages - it's probably using %APPDATA%\\NuGet\\NuGet.Config\n- nuget.exe has a way to manage these sources from the CLI so we could script it, but perhaps we're not allowed to do this on AppVeyor. I gather this will be the same thing for TravisCI.\n- if we can do this, we should clean up after it done\n- what about if the build fails - does FAKE have a good way to run cleanup scripts?\n. @naveensrinivasan :thumbsup:\n. A thought based on re-reading the docs just now:\n\nLINQPad also supports the ref directive for referencing additional assemblies. You can specify the assembly either via its filename (including the directory if it's outside the .NET Framework) or its fully qualified name (if it's in the GAC): \n\nFor the purposes of CI, could we reference local packages (and the just-compiled assemblies) - rather than fighting with all the conventions of NuGet packaging?\nIt could work like this:\n- take the file from version control and read it into memory: \n```\n\nOctokit\nOctokit.Reactive\nRx-Main\nOctokit\nSystem.Reactive.Linq\nSystem.Threading.Tasks\n\nasync Task Main(string[] args)\n{\n    ...\n```\n- replace the XML element with a new payload referencing local files:\n```\n// replaces \"Octokit\"\nref C:\\users\\shiftkey\\code\\Octokit\\Octokit\\bin\\Release\\net45\\Octokit.dll;\n// replaces \"Octokit.Reactive\"\nref C:\\users\\shiftkey\\code\\Octokit\\Octokit.Reactive\\bin\\Release\\net45\\Octokit.Reactive.dll;\n// or we could just reference all the Rx-Main packages here, because we're lazy\nref C:\\users\\shiftkey\\code\\Octokit\\packages\\System.Reactive.Linq\\lib\\net45\\System.Reactive.Linq.dll;\n// extract these namespaces from the XML\nusing Octokit;\nusing System.Reactive.Linq;\nusing System.Threading.Tasks;\nasync Task Main(string[] args)\n{\n    ...\n``\n- pass this new file tolprun.exeand verify the current code works\n. Bumping this as the API changes we're doing here won't be caught by thelprun` changes...\n. I wanted to be sure our stuff was working fine before shipping this latest release, so I ended up writing the code I needed for the above steps into an integration test:\nhttps://github.com/octokit/octokit.net/blob/b4476f173944c93a9500949a467c4bd91a474639/Octokit.Tests.Integration/SelfTests.cs\nI've muted the previous ValidateLINQPadSamples with a note if someone wants to get involved with porting that back to F# so you can run it inline - it's not hard, just XML parsing and writing files and checking process output for messages :trollface:\n. As this issue has changed a lot since first reporting, I've opened a fresh issue #1081 with the remaining work to close this out.\n. @haacked \n\n\nBut ClientInfo is mutable here. Are we copying the values when we create the HTTP client?\nAnother issue with the ClientInfo is by using properties to initialize it, we don't let the type system help people do the right thing by default.\n\n\nCaptured these as tasks over in #985 \n\nNow, we could have overloads that let people specify an AppName and we create the ProductHeaderValue instead. I'm fine with that.\n\nI went down this path initially, but some tests we have have formats which I couldn't map to ProductHeaderValue correctly - likely due to using a version or comments. Thanks for opening #991 to dig into this.\n. > As you can see; only one instance.\nOh cool, I legit thought something else was happening underneath. I thought @darrelmiller was scolding me about this at some stage but I can't find an issue about it.\n\nThat means that if I'm limited to a theoritical limit of 300 Octokit requests per servers per 4 minutes which translates to 1.25 requests per seconds.\n\nKeep in mind that Octokit will follow pagination links if a request has more results, so if you are using a GetAll API and the repository is non-trivial in terms of activity it's not a 1-1 mapping of request/response here.\n\nIf I exceed that, I break the limit of the sandbox.\n\nWhat does \"break\" here entail? And how might we glean what the source of that \"break\" might be?\n. > Would this be the time to try and introduce a way to use the lib without any auth - as can be done if using the api directly?\nTo be honest, I'd make it hard to use this library without auth. The API is very restrictive\u00a0unless you're using an Authorization header, and I don't really see much value in fighting against the API on this front.\nIn the earlier samples, I had a snippet like this:\n``` csharp\nvar info = new ClientInfo\n{\n    AppName = \"my-cool-app\",\n    Credentials = new Credentials(\"my-token\"),\n    Server = \"https://enterprise.my-work.com\",\n    UseDefaultProxy = true\n};\nvar http = HttpClientFactory.Create(info);\nvar client = new GitHubClient(http);\n```\nWe don't currently do this, but I'd like for the Credentials to be an option you pass into ClientInfo - for most scenarios, I think this will satisfy their use case.\n. @M-Zuber okay, so this is what I've currently got:\n``` csharp\n[IntegrationTest]\npublic void Setup()\n{\n    // TODO: what other options may we get here\n    var info = new ClientInfo\n    {\n       Timeout = TimeSpan.MaxValue\n    };\n // generate the client you need\n var client = HttpClientFactory.Create(info);\n\n // TODO: we probably need to guard here that we have enough\n //       information to use this client against the GitHub API\n var github = new GitHubClient(new Connection(new ProductHeaderValue(\"The Future?\"), client));\n\n}\n```\nThe goal here (eventually?) is to find that right balance between convenience and customization\n. > There are some use cases though where no auth is needed and it just gets in the way.\nSure, and the rate-limiting will kick in quick enough for you to know. Anyway, nice feedback to know :sparkles:\n. > This would need to be done before creating any new GitHubClient?\n\nOr is there room for an overload that just takes the info and calls HttpClientFactory internally?\n\nNot necessarily - this is what @Haacked and I are probably going to debate about in here.\nOn the one hand, most consumers won't care about the HTTP stack and just want to supply enough data to get going - a user-agent and perhaps some credentials. That scenario probably favours calling HttpClientFactory internally, like we did before.\nOn the other, if you're wanting to tweak some settings (proxy, timeout, or even some extensibility that the HttpMessageHandler pattern supports) then you're probably going to be happy with doing the setup yourself - or perhaps bringing your own HttpClient implementation.\n. > Assuming I have time to contribute with code also - where you suggest I start?\nLet's make sure this is the right direction, then I'll extract the tasks necessary to move on from there...\n. So this is the current set of ctors that Octokit supports:\ncsharp\npublic GitHubClient(ProductHeaderValue productInformation) { } \npublic GitHubClient(ProductHeaderValue productInformation, Uri baseAddress) { } \npublic GitHubClient(ProductHeaderValue productInformation, ICredentialStore credentialStore, Uri baseAddress) { } \npublic GitHubClient(ProductHeaderValue productInformation, ICredentialStore credentialStore) { } \npublic GitHubClient(IConnection connection) { }\nPersonally, I think this is kinda crazy. Let's take a step back and ask what we're trying to do here:\n- make it easy to get started \n- make it easy to configure the GitHubClient after you're familiar with the basics\nWe're not able to remove the productInformation constraint (this becomes part of the User-Agent parameter) but all of the others can possibly live under ClientInfo:\nvar info = new ClientInfo\n{\n    AppName = \"my-cool-app\",\n    Credentials = new Credentials(\"my-token\"),\n    Server = \"https://enterprise.my-work.com\",\n    UseDefaultProxy = true\n};\nTo ease the transition, we could keep these around (and map them to a ClientInfo internally to help with the transition) alongside the new ctors:\ncsharp\npublic GitHubClient(ProductHeaderValue productInformation) { } \npublic GitHubClient(ProductHeaderValue productInformation, Uri baseAddress) { } \npublic GitHubClient(ProductHeaderValue productInformation, ICredentialStore credentialStore, Uri baseAddress) { } \npublic GitHubClient(ProductHeaderValue productInformation, ICredentialStore credentialStore) { } \n// public GitHubClient(IConnection connection) { }\npublic GitHubClient(ClientInfo info) { }\npublic GitHubClient(HttpClient httpClient) { }\nThoughts?\n. I've identified some properties on IGitHubClient and IConnection that may be worth removing while we're in here making these changes - see 0581dcb1e3c3c46fe8217972cdf157c39fb7b434\n. And this is what composing a GitHubClient currently looks like:\n`` csharp\nvar info = new ClientInfo\n{\n    UserAgent = \"my-cool-app\",\n    // TODO: make this of typeCredentials` - no need to keep the store here\n    Credentials = new InMemoryCredentialStore(new Credentials(\"my-token-here\")),\n    Server = new Uri(\"https://github.my-cool-enterprise.com\"),\n    Timeout = TimeSpan.MaxValue,\n};\nvar github = new GitHubClient(info);\n```\n. @distantcam\nAs discussed in #963 we suspect the per-endpoint override (as in uploading release assets) will be ignored by the global setting - I'd love to get some more insight into that scenario as I know you've dealt with that in the past.\nPutting that aside (it's still To Be Resolved\u2122) I'm not planning to remove that behaviour around setting per-request overrides (especially for uploading release assets) from Octokit, but we still lack a way for users to set a timeout globally. This change makes it easier to achieve this, but isn't the only reason why we're going down this path.\n\nFrom an API point of view I'd like to see an optional RequestOptions object that I can pass, which modifies the behaviour of that web call, but doesn't affect all calls.\n\nThis feels not unlike #760 which was around giving more control to pagination options for endpoints that return collections. What other parts of a request might you looking to modify, generally speaking?\n. @distantcam \n\nAs for HttpClient, it would be nice if I can create my own instance, passing in a custom HttpMessageHandler that wraps the Octokit's RedirectHandler.\n\nI think this will be infinitely easier to do after this. I have some rough ideas in mind around extending the stack, but I may need to re-jig the System.Net.Http abstractions I'm using to get to a point where scenarios like yours are supported.\n. > For most of the communication a 60s timeout is fine, and only for the upload would I want to change that timeout.\nSo you're not seeing an issue with the current 100s limit we have? That's something I want to confirm - or investigate further because I'm rather puzzled by it all.\ncc @naveensrinivasan \n. @naveensrinivasan @distantcam thanks for the details. I think there needs to be some changes here around how Octokit supports timeout that satisfies both the global and specific requests:\n1. if the endpoint specifies a timeout, convert this to a cancellation token and apply to the request\n2. if a global setting is specified, convert into a cancellation token and apply to the request\n3. whatever the provided HttpClient has configured for Timeout\nWe don't support that second scenario (perhaps that's the way out of this) and now I'm really grumpy at HttpClient.Timeout because I think it can still ruin this plan (not either of your faults).\nWill think on a solution some more.\n. Closing this out to take this off my plate. Don't worry, it'll return in some way, shape or colour.\n. Thanks for this!\n. > Nice! Maybe a next step would be to have the script use Octokit.net to help you create the test accounts if you don't have them!\nNot possible through the API :(\n. Tweaking the output a bit to make things clearer:\n```\n\n.\\script\\configure-integration-tests.ps1\n\nBIG FREAKING WARNING!!!!!\nYou should use a test account when running the Octokit integration tests!\nshiftkey-tester found as the configured account name\nWant to change this? Press Y, otherwise we'll move on:\nSet the account password to use for the integration tests (optional):\nXXX found as the configured OAuth token\nWant to change this? Press Y, otherwise we'll move on:\nDo you have private repositories associated with your test account? Press Y to set this, otherwise we'll skip it:\nshiftkey-tester-org-blah-blah found as the configured organization name\nWant to change this? Press Y, otherwise we'll move on:\nWant to remove this optional value, press Y:\nXXX found as the configured application ClientID\nWant to change this? Press Y, otherwise we'll move on:\nWant to remove this optional value, press Y:\nXXX found as the configured application Secret\nWant to change this? Press Y, otherwise we'll move on:\nWant to remove this optional value, press Y:\n```\n. :apple:\n. Thanks @alfhenrik! \n. One little nit, everything else seems great!\n. :boom::camel:\n. I had some luck with this on an old project - this is the current AppVeyor config we're using to deploy to GitHub Releases and Chocolatey:\n\nhttps://github.com/Code52/carnac/blob/master/appveyor.yml#L22-L37\n. Oh yes, I was totally lazy and made it deploy whenever master is updated.\n\nHow I created that file was roughly like this: \n- get the configuration setup right in the admin portal\n- generate the right appveyor.yml config file through the portal (sensitive values get encrypted)\n- add that to source control\n. This is something I'll be looking at next week. Thanks @alfhenrik for that extra info.\n. > /usr/lib/mono/xbuild/12.0/bin/Microsoft.Common.targets:  warning : Reference 'NSubstitute, Version=1.8.0.0, Culture=neutral, PublicKeyToken=92dd2e9066daa5ca, processorArchitecture=MSIL' not resolved\nIs package restore not working as expected?\n. @naveensrinivasan thanks, I'll see if that pesky test is a repeatable failure\n. And now I'm kinda curious why AppVeyor isn't reporting the status of this PRs...\n. @akoeplinger thanks for the review comments! :heart:\n. @naveensrinivasan as this is targeting master, do you mind merging master in to address this conflict and verify the state of the mono build?\n. @naveensrinivasan ugh, feel free to mute that test and I'll open an issue to investigate\n. @naveensrinivasan thanks again, outstanding stuff!\n\n. @ryangribble welcome aboard, just had a quick look at this and it looks really good! Thanks for the hard work kicking this off!\n\nAdded new function, not sure if anything more to do?\n\nThe Octokit.Reactive project is intended to be API-equivalent to the Octokit project, but returning IObservable<T> instead of Task<T>. I think what you've done is just enough, however CI isn't kicking in so I need to look at that...\n. Integration tests are passing on my end :thumbsup:\n@Haacked how do you feel about the API design here? Anything stand out for feedback?\n. @ryangribble Pro Tip\u2122: don't forget to add your work account to your GitHub profile, so those last commits are linked to your profile. Or just amend the author info and push -f to your branch.\n. @ryangribble that test seems to be rather flaky :disappointed: \n. @ryangribble that's fine, happy to merge this in after the Travis build goes green and iterate on this further...\n. Thanks @ryangribble! \n\n. As the webhooks weren't configured, I pulled this down and ran the relevant tests :thumbsup: :tada:\nThanks for closing this out @ryangribble! \n. Yep, definitely not needed any more! Nice spot!\n. @haacked ah, okay. I traced the triple commit status issue to a legacy commit status, so now we should only see (up to) two statuses when PR is created against this repository. \nThe multiple builds issue is actually due to two things occurring - a build for the tip of the PR branch, and a build for the merged commit (the PR branch merged into master, if it does cleanly merge). I'm not sure of a way to switch that off, but I think the default webhook settings are now correct. Make sense? \n. @haacked I'll let you remove the old project configuration from AppVeyor and :thumbsup: this PR.\n. > so did you change octokit/octokit.net's webhook to point to the new one?\n\n. @ryangribble yeah, I'm not too fussed about it, but I do like verifying the branch tip as well as the merge commit. But yes, it's exactly the same issue - here's how AppVeyor displays it:\n\n. @Anubhav10 you're right, creating an authorization without a fingerprint is still supported, so perhaps we need to keep this test around.\n@M-Zuber apologies for missing those messages from back in December. What did you find when you were looking into those tests? And do you think we need to do anything in here given the previous statement?\n. The test still passes, so I'm going to chalk this up to eager obsoleting. I can't see a mention of this being removed in the future, so I'm happy to keep this test around.\nThanks @Anubhav10 and @M-Zuber for looking into this.\n. @M-Zuber let me know what you find out!\n. @Anubhav10 @devkhan if someone wants to submit the PR to unskip it I can verify and close this out.\n. @haacked we'd need a way to emulate this sort of operation:\n```\n\nssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n```\n\nand then use the public key contents\n. @Haacked @ryangribble definitely worth exploring - I stumbled upon it a while ago but got sad at the fact it wasn't OSS. I also have some reservations about the licensing of the components (having been bitten by this in the past) but let's see what comes up.\n. I like this and really have nothing further to add. :tada: \nGonna let this sit for a bit and see if others have feedback.\n. @ryangribble did you want to include this in the integration test script\nhttps://github.com/octokit/octokit.net/blob/master/script/configure-integration-tests.ps1\nI think it should work as-is as an optional variable, and the alias could be something like \"GitHub Enterprise server\"\n. Thanks!\n. :shipit:\n. Thanks @gabrielweyer!\n. > Do we want to add those too?\nSure!\n. > I didn't run the build script locally, I'm a bad man :cold_sweat:\n\n. This feels like our generic 404 exception (which the API typically returns when a repository doesn't exist) - do you have a snippet that I can use to explore this further?\n. @distantcam that'd be great. I can then generalize it and turn this issue into something we can improve more broadly...\n. @ryangribble @devkhan maybe we should verify that a 404 exception also has these details - I recall a PR where we were submitting some more information (the raw JSON payload) so let's see what we're getting currently before we close this out...\n. @devkhan nah, I don't think it's that complex - try accessing a repository that doesn't exist, for example\n. @devkhan @ryangribble The AggregateException raised is classic TPL behaviour. You want to have a look at what's set on it's InnerException - which seems to be the 404 you're interested in...\n. @alfhenrik yes - oops!\n. Okay, so here's my thoughts on this:\n- String.Method definitely feels more Type-y, and I do empathise with the mental \"jump\" that occurs if you come across a string.Method\n- For other types that have aliases in C# (long, int, etc) I don't really recall having the same hassle - in fact, I kinda squirm if i see Int64 or Int32 mentioned explicitly.\n- The using statement arguments are kinda trivial for me - there's likely other things in the System namespace which you'll need, aside from String.\nFor the sake of consistency, I'm :thumbsup: on moving it all to string.\n. @khellang \n\nhow's the C#6/project.json stuff going? \n\nGiven we're all on VS2015 now, this is possibly something worth entertaining (although there might be work to bring the Mono side up to parity once #995 lands).\n. @M-Zuber I'll open an issue after merging the Mono PR\n. @Haacked while we're being a bit pedantic with types - how attached are you to the Simple suffix? I think the name is good, I just keep expecting to see it as a prefix, e.g. SimpleAccount, SimpleOrganization.\nI do like UserWithIdentity - which is also a suffix - so perhaps I'm just in a \"naming things is hard\" phase of the review process...\n. @haacked :thumbsup:\n. Possibly related - should we reference the CodeFormatter project added in #807?\nIf so, I need to update this repo to reflect it's intent...\n. @M-Zuber this feels like it could be part of the documentation we're putting together in #948. Do you agree?\n. Let's take this in and then expand on it in some documentation.\nThanks @M-Zuber! \n. Fixed in #1019\n. @prayankmathur that's an excellent point - I've called out the three tasks I think need to be done here https://github.com/octokit/octokit.net/pull/1017#issuecomment-166488913 but let me look at the current state of affairs and open fresh issues (rather than this vague one).\nI'll leave this open until I have linked to the new tasks here.\n. @gabrielweyer thanks for the extra details - it sounds like there's a lot of inter-related stuff here.\nCould we break this down into a couple of PRs, so it's easier to review?\n- the incorrect and missing fields thing should totally go in first - let's clean that up and get it correct\n- as /repos/:owner/:repo/issues/events exists at activity/events and issues/events in the API docs, let's keep both methods around under the relevant clients.\n- supporting and deserializing events which may be implemented in the future - in EventsClientTests\n. I'll leave this open until @gabrielweyer has had a chance to :thumbsup: my feedback about splitting this into multiple PRs.\n. @gabrielweyer all good, i'll be doing the same :metal: :beers: \n. Timing comparisons (AppVeyor):\nA recent master build\nBuildApp: 34.3364396\nUnitTest: 1:17.4205865\nConventionTest: 08.0352399\nOverall: 4 min 7 sec\nThis PR\nBuildApp: 33.3524274\nUnitTest: 2:03.5065247 \nConventionTest: 09.5384184 \nOverall: 4 min 53 sec\nSo the difference is basically in the unit tests project. Joy.\n. I'm :-1: on reverting the xUnit update here to get those extra seconds back - I'd rather us be on the latest stable releases and then look to speed things up by improving the CI process. \n. packages/System.Net.Http.2.0.20710.0/System.Net.Http.2.0.20710.0.nupkg should be removed from this PR, as it's covered by #1018 \n. @M-Zuber the rogue packages entry is still present\n. curl: (7) Failed connect to storage.bos.xamarin.com:80; Operation timed out\nThe command \"curl -sS http://storage.bos.xamarin.com/bot-provisioning/PortableReferenceAssemblies-2014-04-14.zip > /tmp/pcl-assemblies.zip\" failed and exited with 7 during .\n@naveensrinivasan have you seen this before?\n. @naveensrinivasan it was failing for me on multiple builds yesterday (both for OS X and Linux) but seems to have come good today. Thanks for the :eyes:.\n. \n@M-Zuber thanks!\n. Thanks @RobPethick!\n. @ryangribble the first snippet could be distilled down to this:\nEnterprise.SearchIndexing.Queue(string owner)\nEnterprise.SearchIndexing.Queue(string owner, string repository)\nEnterprise.SearchIndexing.QueueAll(string owner)\nEnterprise.SearchIndexing.QueueAllIssues(string owner, string repository)\nEnterprise.SearchIndexing.QueueAllIssues(string owner)\nEnterprise.SearchIndexing.QueueAllCode(string owner, string repository)\nEnterprise.SearchIndexing.QueueAllCode(string owner)\nBut the second could also work. Happy to go with whatever feels natural once you're writing the plumbing inside the client.\n. > however it also \"eats\" the dash character in my username, resulting in\n\n\nSo do you think I should implement 2 different response classes, one for single actions and one for multiple actions... or attempt to figure out/fix why the serializer is \"eating\" the hyphen?!\n\nIdeally, I'd like to deal with the latter - are you able to isolate this in a test to the deserializer step? (i.e. just use the JSON and try to deserialize to the list) \n. @ryangribble excellent find! I'll look over that PR to see if I can understand why we might have done that.\n\nI removed line 93 and unit tests are passing, just running integration tests now... though there's always the risk that not enough tests around this area exist.\n\nI can also look over the integration tests as part of this review, to sanity check things...\n. > Would you rather handle this json deserialize hyphen problem on a new issue/PR or shall I include it in this one?\nI'd like to address that in isolation, so a separate PR would be :sparkles:\n. \n. @ryangribble :metal: thanks!\n. Fixed in #1068\n. Whoops! The auto-closing of PRs didn't catch this one. Done! \n. @asizikov yes - another one that missed the \"auto-close on PR\" boat! Thanks for reminding me!\n. Or should we name this GitData to match with the section header?\n. > Has this been an issue before (conflict of endpoint name in API and section header?)\nNo, just me thinking out loud.\n. And credit to @naveensrinivasan for starting this off in https://github.com/octokit/octokit.net/issues/968#issuecomment-163066719\n. Not sure how much people want to review this, but it's relatively self-contained so I'm happy to let it sit over the break...\n. > Re the CodeAnalysis that you are bulding, I think this is a complement.\nI agree. I think there's some post-compilation stuff that we can verify easily via tests (especially when comparing the documented APIs to what's been implemented) and this has already been helpful in that regard.\n. I'm putting the CodeAnalysis stuff aside for now to focus on other things.\nSomeone is more than welcome to pick it up in my place, and I'm happy to help shape it.\n. Now that a bunch of open tasks have been resolved, I should merge in those changes and try running the tests again - and of course get some actual data from the audit so I can hopefully test further details.\nPutting back to WIP\n. Was able to rebase this branch and see it only raises 5 API errors, but I'm going to close this PR and revisit the overall process for incorporating this properly:\n- I'd like it to be outside the current suite of integration tests\n- The rules engine is not intuitive at all (hell, I barely understand what I've done here)\n- What to do about the violations that I've suppressed?\n\n. > Do we want to use the property CommitUrl that hasn't yet been documented?\nI'm tentatively :thumbsup: on this, but I'll let @Haacked throw his 2c in as well before we close this out.\n. @M-Zuber I think you can make this change without renaming types - perhaps some extra changes are causing the build failures to creep in...\n. > Okay, so the wanted change is just the properties on the RepositoriesClients?\nCorrect. Let's keep it simple!\n\nI'll start over in a new branch, if that's okay. A little simpler for me\n\nIf you're fine with force-pushing this branch to blow away the current changes, I'm fine with that. Otherwise just open a new PR.\n. > Force push is fun :smile: \n\n. > BTW I noticed that there seems to be no tests for this property. Is this on purpose?\nNo, likely just something that was overlooked. Tracking that in #1045\n. @M-Zuber thanks!\n. Looking good, just a few little suggestions on Naming Things\u2122\n. @ryangribble looks good to me, thanks for the work!\n. Merge conflicts :cry: \n. A couple of little formatting things, everything else seems :gem:\n. LGTM\n. @M-Zuber you might be right - from the docs:\n\nOtherwise, only users with access to the repository are returned in the collaborators list.\n\nI suspect pull wouldn't give you much data, but I haven't looked into it.\nTo test this out, you could use a newly-created repository and add/remove collaborators from there before tearing it down...\n. @wdhodges @naveensrinivasan the published version of the Getting Started guide is probably worth looking at: \nhttp://octokitnet.readthedocs.org/en/documentation/getting-started/\nThere's also a section about Issues \nhttp://octokitnet.readthedocs.org/en/documentation/issues/\nIf there's things that you don't find clear, let us know and we can refine them\n. @naveensrinivasan it'll appear when the documentation branch has been merged: https://github.com/octokit/octokit.net/tree/documentation#documentation\n. As #948 has been merged and the README now has a Documentation section\nhttps://github.com/octokit/octokit.net#documentation\nI'm going to close this out.\n. @ryangribble excellent questions!\n\nOut of interest with octokit.net contributions, is there a preference between rebase on master vs merging master?\n\nI'm not fussed by either approach, but merging master does help keep make the code review process easier to follow on my end.\n\nSimilarly is there a preference to squash the commits down once it's ready to go in, or you aren't bothered by the larger number of in progress commits etc?\n\nI'm really not a fan of squashing together dozens of commits when it's done - but you're right about those scenarios where people just want to commit stuff before it's ready. I know I should care about ensuring each commit in each PR builds and passes all tests, but I don't. As long as the history is readable and easy to follow, I'm happy.\n. Just bouncing a question off @haacked about simplifying the code to invoke the endpoint, everything else is :gem: \n. @ryangribble looking great - just one excess set of braces in the test.\n\nLooks like that previous OSX build failure was sporadic as they have now passed after i pushed up a couple of unrelated :lipstick: commits\n\nI've opened #1076 to start tracking these more seriously than I previously have.\n. \n. Just nudged the problem builds and it's now all good. Will keep an eye out for other flakiness.\n. This is the interesting bit:\n\nThis returns a sha but when trying to make a tree based on this blob I get error that that sha is not a valid blob.\n\nI could put together a test to reproduce this issue (for example, something like this) but I'd love to see a sample from @twcclegg about how he is creating the tree - the blob contents might not be the root cause here....\n. This test works for me\n``` csharp\n[IntegrationTest]\npublic async Task CanCreateATreeWithXml()\n{\n    var blob = new NewBlob\n    {\n        Content = \"\ufeff<?xml version=\\\"1.0\\\" encoding=\\\"utf-16\\\"?>\\r\\n\\r\\n\",\n        Encoding = EncodingType.Utf8\n    };\nvar createdBlob = await _github.Git.Blob.Create(_context.RepositoryOwner, _context.RepositoryName, blob);\n\nvar newTree = new NewTree();\nnewTree.Tree.Add(new NewTreeItem\n{\n    Type = TreeType.Blob,\n    Path = \"foo.xml\",\n    Sha = createdBlob.Sha,\n    Mode = FileMode.File\n});\n\nvar result = await _fixture.Create(_context.RepositoryOwner, _context.RepositoryName, newTree);\n\nAssert.NotNull(result);\n\n}\n```\nYou can see the created tree here: https://api.github.com/repos/shiftkey-tester/public-repo-20160306095953730/git/trees/710653b5331f19af77762c86d5adafda81a4b052\n. @devkhan possibly - I'd love a sample to see how @twcclegg's usage differs from mine...\n. Reopening this to get it addressed in the documentation\n. @JakesCode could you link to where in the docs you found this _issuesClient? I think I know the place, but if someone else wants to dive in and fix it first it'd be greatly appreciated...\n. This was merged into master late last week! \nhttp://octokitnet.readthedocs.org/en/latest/issues/\n. @JakesCode looks good - in the future just go straight to the PR, no need to open an issue\n. I have zero issues with this PR. Thanks for the effort @RobPethick! \n. > Would there be any opposition to supporting this in Octokit?\nNo objections here  - and thanks for logging it as it's not something I thought about when doing the API audit!\n. @daveaglick all good, there's some CI friction that I need to look into at some stage\n. @daveaglick thanks for this, and apologies for not getting to it weeks ago :grin: \n. > The following is an undocumented endpoint. ...  Should it be included?\nLet's stick to things which are documented for now.\n\nThe response includes an error field which seems to be mapped to the ApiError class. Does that get included in the model?\n\nI think I'm fine with using ApiError here, but it's hard to say whether there's more properties which aren't displayed in the sample responses included here...\n. > not sure how to fix the errors re missing files.\n.\\build FixProjects should add all files from Octokit.csproj to the cascading projects...\n. Holding off on merging this until I can give a better answer on what is happening with #1062 \n. Found out why #1062 is occurring and it's an orthogonal discussion to this. \nJust a couple of comments about naming things (favouring simpler wherever possible). Everything else looks :gem:\n. There's also a merge conflict that needs a bit of love here...\n. @M-Zuber quick! merged!\n. @M-Zuber \nSo NSubstitute takes a different tact to other mocking frameworks by making the proxy object transparent (no Mock<T> anywhere), and using extension methods on the object to verify behaviour. This is the purpose of the .Received() extension method, but it's a bit obscure because it still returns your IApiConnection.\nSo from the value returned from .Receieved() you then declare the method you expected to be invoked - using the Arg helper class to do expression-based checks of the arguments provided during the test.\n\nWithout the null on the last line the test will fail on an Ensure check that the uri is null, but it is not clear why it is needed or what it does.\n\nI gather this is occurring due to the overloads on Get but it's hard to say specifically without a bit more context. So it sounds like the Get<T>(Uri uri) code was failing the test, but Get<T>(Uri uri, IDictionary<string, string> parameters) was making the test pass - does that sound right to you?\nAlso, if an Ensure check isn't occurring I suspect some actual code is being invoked. Do you recall where that was?\nHappy to run up the tests myself in #1061 if there's a specific way to trigger what you're seeing.\n. Well, this is interesting:\n\nBy dropping the null it now uses an extension method - which explains why you're seeing real code run at that point. However it doesn't quite fully explain why the uri is null, but I'm sure they're related...\n. So we have a few of these extension methods but I'm not sure whether we should:\na) move them back into IApiConnection as they aren't really complicated and will clean up the tests\nb) properly investigate why the mock object created isn't handling the received Uri correctly - perhaps it's never worked...\nFavouring a) right now (I tested this with Get<T> and was able to remove a few tests which were doing this null anti-pattern to make the tests pass) but I'll let this sit for a bit.\n. Opened #1063 to address this specific problem. Feedback/suggestions welcome.\n. @Haacked yeah, agreed on the need to implement this explicitly. If we had multiple implementations I'd probably explore something else...\n. Ready for review\n. Actually, given #959 went through a review by myself and @haacked I'm just going to merge this in so I can get it into the next release...\n. @M-Zuber let's see what we can do in the PR. If that doesn't progress, we can extract a task from that like we've done in the past.\n. Unfortunately Octokit is limited by what is available through the GitHub API - there are some Git operations available but there's no equivalent to \"clone\" available.\nI'd recommend looking at libgit2sharp which is a C# library for working with local repositories. Here's what the clone operation looks like in code:\ncsharp\nRepository.Clone(\"https://github.com/libgit2/libgit2sharp.git\", \"path/to/repo\");\nOr if you need to authenticate:\ncsharp\nvar co = new CloneOptions();\nco.CredentialsProvider = (_url, _user, _cred) => new UsernamePasswordCredentials { Username = \"Username\", Password = \"Password\" };\nRepository.Clone(\"https://github.com/libgit2/libgit2sharp.git\", \"path/to/repo\", co);\nThere's more examples in their wiki.\n. @lbrader that's a pretty accurate way to think about it\n. @paladique just some xml-docs changes which are making CI cry currently:\n1) Building ./Octokit.sln failed with exitcode 1. \n  2) CS1572: Clients\\ObservableUserAdministrationClient.cs(17,26): XML comment has a param tag for 'client', but there is no parameter by that name \n  3) CS1573: Clients\\ObservableUserAdministrationClient.cs(18,77): Parameter 'userAdministrationClient' has no matching param tag in the XML comment for 'ObservableUserAdministrationClient.ObservableUserAdministrationClient(IUserAdministrationClient)' (but other parameters do)\n. @haacked\n\nHmm, looks like RepositoryPagesClientTests is failing but that's unrelated to this change\n\nYou're right. This somehow slipped through the initial PR passing CI https://github.com/octokit/octokit.net/pull/1061/files#r50933117 - but the fix 5ca6633cb133ca8db4f2be17c2ebb0e26a446d64 is now in master.\nPerhaps this branch was created before, in which case a merge or cherry-pick should pull in the fix...\n. \nGreat work @paladique, and thanks for the contribution!\n. Likely an oversight. You can probably reuse the Milestone model we use for an issue if someone wants to add this in.\n. > I didn't have the WP8.1 SDK or something\nSeems plausible\n. @ryangribble wow, this is great! Thanks for catching this!\n\nIm not sure what settings you guys run the integration tests under for octokit.net so I have set the integration tests that would have triggered these conditions, to SKIP for now. \n\nThis is fine, and while I use a separate account for testing I'm not sure what might work for it around organizations. I'm aiming to prepare a new release this week, so I'll look into that (probably needs an extensibility point :sad:) while I'm preparing and testing everything...\n. \n. @ryangribble this is so good!\n\nJust a few conceptual questions about the EnterpriseHelper changes, and apologies for introducing the merge conflict on the csproj files!\n. > Did the travis build automatically retry or did someone kick it off again? \nNope, it was me.\n\nIs there any way (apart from pushing another commit) for plebs to get the builds to try again?  :grinning:\n\nI'm afraid not. We're looking into the Mono issues and where they might be hiding, but that's going to take some time. I'll keep an eye on the build state as part of reviewing - if you're happy that the error isn't your fault just comment so I know you've looked at it.\n. I'm gonna take this in without that bit of :lipstick:. Thanks @ryangribble!\n\n. > Is the parser something that is decoupled enough that it could be separated into a separate project?\nIt's tied to SimpleJson, which we use as an internal dependency. We've submitted some patches upstream to SimpleJson.cs, but SimpleJsonSerializer is the hooks for us to control how to serialize and deserialize objects in the context of Octokit.\nFor me, I guess it comes down to whether you're happy with how you're using the current Octokit APIs, or whether there's a different way (or abstraction?) you'd like to use. Then we could talk about extracting the models and serialization logic - I gather that's the bit you're really interested in here, rather than just the JSON pieces.\nOne such scenario that I need to flesh out is consuming webhooks - I'd want to reuse the models (and thus the deserialization rules) we already have, but how they plug into an MVC app is very different.\n\nas an aside - why would anyone need/use yet another json parser? \n\nWe avoid paying the JSON.NET tax here by internalizing our JSON logic, and while you can plug in your own serializer it's deep in the bowels of Octokit, so I wouldn't worry about needing to do that... \n. @M-Zuber it's all good, happy to talk further about it\n\nSo the json parser + serialization being internal don't bother me - but how simple do you think it would be to copy out the code and dump it into a project with different models?\n\nI don't think it'd be much work - I'm pretty sure someone has repurposed this codebase (or been inspired by it) to apply it to a different sort of API. I forget the product, it came through via Twitter.\nThe serializer rules are kind of tweaked to what the GitHub API expects - but it's nothing special.\nHere's a bit of a brain dump of some of the more quirky features on offer beyond that: \n- with request models, null values are not sent by default\n- you opt into those with a [SerializeNull] attribute\n- managing the formatting of properties when serializing/deserializing - server expects Ruby style (like review_comment_url) and client expects .NET style (like ReviewCommentUrl)\n- a few different ways to override this when deserializing - e.g. enum serialization, map JSON property to different response\n- converting text to base64 when sending is done through [SerializeAsBase64] so the user doesn't care about the implementation details\nI'm :thumbsup: if someone wants to extract these relevant bits and explore making it more general purpose for API clients.\n. > It may very well have been me :grinning:, as I have been sitting on this for a long time\nNah, it wasn't you - I'm pretty sure it was for the Confluence API but I think they were speaking more generally in terms of the Octokit architecture\n. @Haacked @eilon on my list for this week, hopefully tomorrow\n. [Linux] Timeout? https://gist.github.com/shiftkey/777ce24a06cb1f4c60ca\n. [Linux] \"Got a SIGSEGV while executing native code.\" https://gist.github.com/shiftkey/ab637423fd610e1dc0ce\n. @Haacked I wanted to get this in before cutting a release :grin: \n. @Haacked can I get a :thumbsup:?\n. As this is just sprinkling some attributes around, I'm going to just self-merge this:\n\n. Have dropped the [WIP] tag and am running the tests once more. Planning to publish this tomorrow morning AEDST, so going to let it sit overnight for others to look over...\n. @ryangribble there's already a lot to go out here :grin: but I'll try and get into the rhythm of more regular releases now the audit stuff is under control...\n. :ship:ed - see https://www.nuget.org/packages/Octokit/0.18.0 and  https://www.nuget.org/packages/Octokit.Reactive/0.18.0 \n. @hahmed can we capture this as a failing integration test in the repo?\n. @hahmed that seems good enough for me - and if you could mark the test as [Fact (Skip=\"see https://github.com/octokit/octokit.net/issues/1082 for investigating this failing test\")] this will help link back to this discussion\n. > So I dont think removing All from the enum is good.\nAlso, we should be marking things as [Obsolete] before removing them. Because we're nice like that.\n. I like where this is heading. If it were me, I'd probably introduce a new enum in the search API instead of sharing the ItemState enum as it doesn't support All.\nThis feels like we're going to need to introduce a breaking change here as part of the new enum. But that's fine. Just a heads up.\n. LGTM :thumbsup:\n. Gotta rebase once #1087 is merged\n. Ready for review\n. > (attempted nerd snipe)\n\n. Thanks!\n. The list of files in the project cascade from the default project out to the others, so you won't see the default project update. Sounds like it's by design, but I'd love to hear about what was responsible for adding the files to the Mono* projects - perhaps something else is involved here...\n. @Thwaitesy @ryangribble apologies for the delay, I'm aiming to get through these by the end of the week. Thankfully we just did a big release, so the next one should be a bit easier to manage...\n. Code looks good, tests all pass, and it got a pretty great review too...\n\n. @ryangribble thanks for getting to the bottom of this, and for adding in those tests!\n. @ryangribble :boot:ed and :eyes:ing\n. @ryangribble thanks for the heads-up, I'll make sure to prioritize these reviews before any other Octokit stuff as I know merging csproj changes is all kinds of terrible right now :grin:\n. @ryangribble #1073 has been merged :metal:\n. @M-Zuber @ryangribble thanks for the initial review :gem:\n@Sarmad93 I think writing these tests is actually easier that you suspect - we have a lot of tests already defined for RepositoryClient, and you can likely repurpose some of the existing tests that @ryangribble linked to.\nThe goal of these tests is to verify a small piece of behaviour - in this case, what we're interested in is the mapping of the parameters on the request to the URL that gets invoked by the client. The setup is what's called AAA syntax - Arrange, Act and Assert, and they're intended to be short, easy to read and quick to execute.\nHave a read of the links above, feel free to ask questions - but don't be afraid to take a shot at it :grin:\n. Ooooooh!\n\nGonna look this over and cc @shana for a bit of review :eyes: when she has a moment.\n. @haacked only extra bit i can think of here is a bit of documentation on using this. Thoughts?\n. @haacked the content for the documentation site is under docs - and the hierarchy for http://octokitnet.readthedocs.org/en/latest/ is here - not sure where it fits best, open to suggestions...\n. >  Is it for octokit to do smart stuff internally, or just providing an API where someone writing an application like GitHub Desktop could allow users to enter a repo URL and it would be able to probe if its Enterprise or not?\nIt's the latter - basically a helper method for someone to verify the user-specified input is a valid GitHub Enterprise server.\n. Just added a couple of tasks to get this over the line. I'm happy with the current implementation.\n. Merge conflict is sorted, but I'm still trying to find a simple code sample here to illustrate the issue - currently you need to create it manually, like this:\ncsharp\nvar probe = new EnterpriseProbe(productHeader, httpClient);\nvar result = await probe.Probe(new Uri(\"enterpriseBaseUrl\"));\nif (result != EnterpriseProbeResult.Ok)\n{\n    // not valid\n}\nThoughts @haacked @shana on how we could simplify this?\n. @shana sorry, I should have been more clear. I wanted to put this into the \"Getting Started\" page but there's some setup of the dependencies that EnterpriseProbe needs before I can use any code sample for the probe. Do I also do that here, as painful as it is to create these?\nOr perhaps I could leverage the GitHubClient setup and move EnterpriseProbe into GitHubClient, like this:\ncsharp\nvar github = new GitHubClient(...);\nvar result = await gitHub.Enterprise.Probe.Probe(new Uri(\"enterpriseBaseUrl\"));\nif (result != EnterpriseProbeResult.Ok)\n{\n    // not valid\n}\nBut that's also kinda backward, as GitHubClient requires the base URL...\n. Yeah, I like the direction that @shana is proposing about internalizing it - you've already specified the URL in the ctor, so leave the internal plumbing to Octokit.\nOther thoughts:\n- I'm unsure about having the probe returning DotCom - this feels a lot like our internal lingo, but as you could invoke this on an instance without the URL set, which would be DotCom behaviour.\n- What if this were a method off GitHubClient.Enterprise? that's originally why we wrote this probing code, and keeping it near there might be more contextual than having it off GitHubClient \n. Closing this one out as it's gone very stale.\nI'll leave the branch around if someone wants to pick this up later.\n. @M-Zuber good point. I'm fine with putting them in there for now (we've done the same thing in Octokit.Tests but it also has some test classes which confuses things further). Let's keep going down that path and add a new test class for the extensions in Helpers for now, we'll clean it up later...\n. @M-Zuber did you mean to link to GetReference? If so, yes, I think that's useful to extract somewhere if you'd like to reuse it...\n. @ryangribble thanks for those notes, very informative!\n\nHowever I later found that when a GitHub Enterprise instance has LDAP enabled, all requests that return a User or Team even the general GET calls, include a ldap_dn field, so I have added LdapDn field to the User and Team response objects, the xml doc notes it is GitHub Enterprise only.  This seemed preferable than having to have special types when you wanted the ldap field and it shouldnt hurt any non enterprise users having this null property on those objects.\n\nWell that's certainly an interesting undocumented feature! Hooray for JSON. Yeah, this seems fair given how the server is behaving. cc @haacked for objections (if any)\n\nSo I added overrides to ApiConnection and Connection classes to suit this situation (POST with no body, that returns a <T> response object).\nSimilar to the RepositoryContext helper, I added a helper that allows the integration tests to create a team to run the tests, then clean it up afterwards.\n\n:thumbsup:\n\nUpdateTeamMapping - Team must exist (obviously) and specified LDAP distinguished name is NOT validated.  It can be set to something that doesnt exist and is regarded as a succesful API call (and the new LDAP binding is visible in the team settings on the gui etc).\n(The team will then be disabled on the next LDAP sync when it realises the group is invalid)\n\nI'll have a chat with the team and see if this is supposed to be the behaviour here.\n\nThe integration tests require a GitHub enterprise instance so wont run as part of Octokit builds currently.  Futhermore this API requires the GHE instance has LDAP binding enabled.  Also note that I have had to censor the \"distinguished name\" properties used in the integration tests so they arent company specific.  \nThe integration tests also do NOT run against the \"current user\" because you dont want to mess with changing the LDAP binding on the user running the tests and potenitally disabling the account or otherwise losing access...  So the integration tests have a _testUser property declared at the top of the class\n\n:thumbsup: \n\n(at the moment that user has to exist, as the method to add users is not implemented... though even when it was, in an LDAP enabled server any user you create would have to have a valid LDAP binding in the first place i suspect!)\n\nThis seems plausible.\n\nBut at least this API is now implemented and anyone who wants/needs to use it can.  We just potentially wont have frictionless integration test execution...\n\nYeah, I appreciate the complexities here. Will have a chat with the team and see if they have any thoughts on this so I can also test out LDAP behaviour.\n. @ryangribble just calling out a couple of cleanup opportunities with async/await. Everything else is :gem:\n. > Want me to raise another PR to clean them all up?\nLet's come back to this after we've got some of these existing PRs closed out. It's not urgent.\n. \n. It's weird, because in 38ef6302ec25d8246361e80cb89bd496ff318dc2 I've now installed Microsoft.Net.Http which depends on Microsoft.Bcl.Build and Microsoft.Bcl - but they're not referenced. But no references are updated in the csproj.\nI think I need Microsoft.Net.Http here but perhaps I'm missing something... \n. So I'm pretty sure this is just the side-effect of me being lazy with updating packages in #1018. References have been a bit manual in the past so I updated the packages in 38ef6302ec25d8246361e80cb89bd496ff318dc2 - perhaps I didn't build-to-flush-the-changes-to-disk for that project (other projects have the same change).\nBut even though no assemblies are referenced in the main project, it's still adding in the EnsureNuGetPackageBuildImports here - which is technically not necessary here.\n. > Maybe it only adds the references if it's a portable project? (I have no clue)\nThere's at least two assemblies in net45 which aren't referenced by the project:\n\nshiftkey@BRENDANFORS36E0  ~/Documents/GitHub/octokit.net/packages/Microsoft.Net.Http.2.2.29/lib/net45 (master)\n$ ls\nensureRedirect.xml               System.Net.Http.Primitives.dll*\nSystem.Net.Http.Extensions.dll*  System.Net.Http.Primitives.xml\nSystem.Net.Http.Extensions.XML\n\nBut they're not referenced explicitly, so perhaps I'm just lucky here.\n. @ryangribble which errors are we talking about? The Microsoft.Bcl and Microsoft.Bcl.Build packages are there to help smooth over issues when targeting certain platforms - net45 is rather modern, so it's mostly acting as a no-op here. Happy to share more based on past experiences, I'm just not sure what we're looking for here...\n. @shana\n\nevery single project in the solution that references Octokit suddenly wanted to have the Bcl, Bcl.Build and Http packages added to them\n\nAh, that issue. If that's the case then I'm :thumbsup: for this change. In fact, we could probably do away with the new packages specified here - I think that's also to blame here, and the nuspec should reflect the correct dependencies needed when installing the package...\n. @shana it's meant to link to Octokit/packages.config but the browser can't scroll far enough :cry: \n. @ryangribble those errors are interesting.\nThe first one is totally legit, and something we should be able to resolve here, but the second and third ones seem new, because they're not resolving the valid configuration files in that folder. Guess we should try and log that upstream at least while we're in here dealing with this.\n. @ryangribble oh no, I get those errors. I just wasn't paying attention after updating.\nAnyway, the issue seems to be inside Microsoft.Bcl.Build:\n<ValidatePackageReferences Packages=\"@(ValidatePackages)\"\n                               ReferencingProject=\"$(BclBuildReferencingProject)\"\n                               ReferencingProjectPackagesConfig=\"$(BclBuildReferencingProjectConfig)\"\n                               ReferencedProject=\"$(MSBuildProjectFullPath)\"\n                               ReferencedProjectPackagesConfig=\"$(MSBuildProjectDirectory)\\packages.config\"\n                               TreatWarningsAsErrors=\"$(TreatWarningsAsErrors)\" />\nIt seems like this doesn't care that packages.$(MSBuildProjectName).config is also a valid name - I can't find the official docs on this, which concerns me a bit...\n. @shana that's fine\n. @shana thanks for this! @ryangribble unfortunately this doesn't resolve the issues we're seeing.\n. > So potentially on our NewTeam and UpdateTeam request model classes, we should mark that field as Obsolete\n\ud83d\udc4d \n. @ryangribble nice spot - yep, that's a bug\n. Added the easy-fix label as I think this is good for someone new to contribute. I'd also like to see a unit test for this to verify that we're passing through the right value.\n. Fixed by #1113\n. @Anubhav10 that sounds like it's on the right track - I'd love to review the work you've done here...\n. @ryangribble what version of GitHub Enterprise are you running?\n. @ryangribble I'm also not sure of a real-world example with that sheer number of tags, so I could test it on my end to understand the behaviour better. Asking around.\n. Just ran a simple test against https://github.com/fsprojects/Paket to illustrate some of the pain that's occurring here (note that Paket only has 1185 tags): \n\nOr statistically:\n```\nRequest Count:   40\nBytes Sent:      15,169     (headers:15,169; body:0)\nBytes Received:  116,598        (headers:58,451; body:58,147)\nACTUAL PERFORMANCE\nRequests started at:        13:34:26.051\nResponses completed at: 13:34:40.223\nSequence (clock) duration:  00:00:14.1719851\nAggregate Session duration: 00:00:13.948\nRESPONSE CODES\nHTTP/200:   40\nRESPONSE BYTES (by Content-Type)\n   ~headers~: 58,451\n\napplication/json: 58,147\n```\nLook at that cascading, it's so beautiful...\nSwitching over to this._gitHubClient.Git.Reference.GetAllForSubNamespace(owner, repo, \"tags\"); only requires one request to get all the required references.\n```\nRequest Count:   1\nBytes Sent:      405        (headers:405; body:0)\nBytes Received:  344,903        (headers:1,165; body:343,738)\nACTUAL PERFORMANCE\nClientConnected:    13:36:02.963\nClientBeginRequest: 13:36:03.854\nGotRequestHeaders:  13:36:03.854\nClientDoneRequest:  13:36:03.854\nDetermine Gateway:  0ms\nDNS Lookup:         0ms\nTCP/IP Connect: 0ms\nHTTPS Handshake:    0ms\nServerConnected:    13:36:03.244\nFiddlerBeginRequest:    13:36:03.854\nServerGotRequest:   13:36:03.854\nServerBeginResponse:    13:36:04.229\nGotResponseHeaders: 13:36:04.229\nServerDoneResponse: 13:36:04.745\nClientBeginResponse:    13:36:04.745\nClientDoneResponse: 13:36:04.745\nOverall Elapsed:    00:00:00.8917767\n\nRESPONSE BYTES (by Content-Type)\napplication/json: 343,738\n       ~headers~: 1,165\n```\nWe haven't tweaked the pagination defaults in Octokit (so it defaults to 30 as per the docs) but that could be a quick win for situations like this. I'm thinking about ways to introduce this broadly across the codebase, so the caller can control it if they want, but that's in #760 and has kinda stalled.\n. I knew this code lived somewhere (ignore the second TODO comment):\n// TODO: this should be under Users to align with the API docs\n// TODO: this should be named PublicKeys to align with the API docs\n/// <summary>\n/// Access GitHub's Public Keys API.\n/// </summary>\n/// <remarks>\n/// Refer to the API docmentation for more information: https://developer.github.com/v3/users/keys/\n/// </remarks>\npublic ISshKeysClient SshKey { get; private set; }\nSo yes, the methods on ISshKeysClient should be added to IUserKeysClient - and IGitHubClient.SshKey should be marked as obsolete for removal as it doesn't align with the API.\n. :thumbsup: to obsoleting the methods rather than the types - that's going to put it in front of impacted users much more clearly\n. And :thumbsup: to obsoleting SshKey - the API documentation refers to \"public keys\" so let's follow that convention...\n. Let's port those extension methods over to PublicKey and mark the SshKey variants as obsolete.\nEDIT: good point on the \"only used in tests\" thing. Mark these versions as obsolete, move the new variants into the tests (we don't have a shared project for test helpers, which might get in the way here).\n. Fixed in #1132\n. @mathieukempe not sure whether this is an outstanding issue, but here's how I'd do this without using ApiConnection directly (this is using 0.18.0):\ncsharp\nvar client = new GitHubClient(\"something\");\nclient.Credentials = new Credentials(_token);\nvar contents = await client.Repository.Content.GetAllContents(owner, repo, path, branch)\nvar file = contents[0].Content;\n. @mathieukempe to be honest, I'm not sure how this might be deadlocking.\nWe have the ConfigureAwait setup inside GetAll so perhaps making this method async/await might change the behaviour (rather than blocking using .Result).\n. @zzzprojects thanks for the extra info - I've opened #1248 which cleans this up\n. @michael-kokorin flawless victory!\n\n. @Haacked thanks for the extra info. It didn't quite match up with what I was seeing from the network traffic (the delay looked like the cumulative time spent fetching those requests), so here's me embedding some extra tracing and running it against master again:\n\nI also felt I ran into this while doing #760, as well as a few little pet projects, so I'll go back and test that again...\n. Just tested #760 and this behaviour remains the same. Closing it out as PEBKAC.\n. @prayankmathur we have a few outstanding tasks marked easy-fix - please check them out!\n. Someone asked me in another channel to summarize .NET Core in relation to the .NET Framework. Here's a quick brain dump:\n- .NET Core is a subset of the .NET Framework which runs on Windows, Linux,\n  OSX and other operating systems\n- The CoreCLR (the runtime for .NET Core)\n  is an open source repository\n- Core libraries for .NET Core is distributed via NuGet packages - the \n  CoreFX repository has all the source for\n  the .NET Core libraries\n- Various APIs have not been ported over to .NET Core\n  - features which are Windows-specific - e.g. WPF, WinForms\n  - features which are not suitable for their v1 target of running webapps\n  - APIs which are not intended to be supported long-term\n- The other part of this project the dotnet CLI,\n  which allows you to build and run programs which target .NET Core from the\n  command line - this is just now available to test, but not quite v1\nThis is different to the Portable Class Library targets, which were designed to simplify the platforms you targeted, but were limited to where .NET was already running - e.g. Mono/Xamarin/.NET Framework\nOctokit.net already has a PCL profile that's suitable to migrate to .NET Core, so most of the work around this will likely involve migrating to the project.json format to define the dependencies and platforms that Octokit needs to support, and also testing to verify that there are no unexpected issues with running on .NET Core so that we're ready to be used when .NET Core 1.0 RTMs\n. @devkhan currently we juggle different csproj files for each target. I think a bulk of the work will be in porting those over to a unified project.json file - this will then allow us to add the new targets for the various .NET Platform Standards available around .NET Core and verify that these can be built (we might need to introduce some #ifdef but I think that's minor).\nAfter that, we'd need to look at packaging as project.json can also be used to create packages \"for free\" - but we do some customization like incorporate Linqpad samples and SourceLink the PDBs so the source can be stepped through easily.\n. > And it will generate different NuGet packages for different targets?\nOne package (with multiple targets inside) is generated from a project.json file - hence the unification stuff. But this also raises headaches as we have been building the package from hand before.\n\nAlso, the Mono and Xamarin ones will still be kept as different projects or they are going to be dissolved in favour of the X-platform .NET Core? \n\nThey should stay around - the platforms are mentioned in the .NET Platform Standards document linked to above, but I've not explored this in practice.\n\nI read a blog, which said that setting dotnet as target in project.json means we are specifying that our project is compatible with any platform our dependencies are compatible. So, does this mean we will have to make sure we have no dependencies which are not available on .NET Core?\n\nKind of. dotnet was the name intended for to represent various API sets - to simplify targetting various flavours of .NET. That article is now not accurate - these are now named netstandard, but the details are largely the same.\nHow this looks in practice is that you specify the version of netstandard inside a project.json file, like this:\n{\n    // other stuff here\n    \"frameworks\": {\n        \"net40\": {\n           // other stuff here \n        },\n        \"net45\": {\n           // other stuff here \n        },\n        \"net46\": {\n           // other stuff here \n        },\n        \"netstandard1.0\": {\n           // other stuff here \n        },\n        \"netstandard1.3\": {\n           // other stuff here \n        },\n        \"sl5\": {\n           // other stuff here \n        }\n    }\n}\nThe new dotnet CLI tools will then try and build your code for each of the framework entries defined, and the build outputs become the contents of the NuGet package.\nHave a closer read of this document about .NET Platform Standards as they've gone into a lot more detail - and it's more up-to-date.\n. @devkhan I'd like to keep the existing platforms around for now - there may be some platform-specific features that aren't present in the netstandard equivalent. I'm involved with another project which is undergoing that process, so I definitely believe it's acheivable.\n. @prayankmathur\n\nHow exactly do we port a csproj file to project.json\n\nThere are no tools to convert a csproj over to project.json, but it's easy to add a project.json (and the .xproj) alongside the existing .csproj to help with the transition. An earlier example of this can be seen here although that's rather out of date.\n\nDo we have to do it manually defining each and every dependency as mentioned here or is there a tool available ?\n\nOne of the benefits of this new approach is that you can define a dependencies array that will use packages (or local projects) which are applied to all frameworks - instead of duplicating entries.\n\nAnd once that is done, we then need to modify the build.fsx file to incorporate the changes ?\n\nWe may not need to change much here. If not, we'll need to look at using the dotnet CLI tools here... \n\nYou mean Nuget packages right ?\n\nYes\n. @devkhan exactly - one project.json file can target many frameworks, and can replace the multiple csproj files we currently maintain. Because the project.json file supports wildcard expressions to include code, like this:\n{\n    \"compile\": \"*.cs\",\n    \"exclude\": \"buggy/**/*.cs\",\n    \"publishExclude\": \"something/**/*.*\",\n    \"resource\": \"embed/**/*.*\"\n}\nWe can drop the .\\build FixProjects script we have to ensure all the csproj files are in sync - and no more merge conflicts from csproj files!!! \n. @prayankmathur 2 months of part-time work (this could just be a few hours each week), including integrating this into the process, shipping preview packages and testing, plus allowing for unexpected upstream issues that might occur with pre-release packages feel about right...\n. @ikourfaln I've been experimenting with .NET Core for the upcoming RC2 bits (not on this project, on something more complex). My current focus is wrapping up the ApiOptions release, and by the time that's done I think the RC2 tooling bits like dotnet cli should be ready for mainstream.\nHowever I've got way too much on my plate these days (and over the coming months) and none of it needs .NET Core support, so I'd love it if someone stepped up for this based on needing it for their usage...\n. @alfhenrik now that Rx.NET preview packages supporting .NET Core are available - details here - this is now something we can start exploring. You're more than welcome to dive in!\n. Okay, so now I can finally talk about porting Rx.NET to .NET Core, have a look at our setup for one of the projects:\nhttps://github.com/Reactive-Extensions/Rx.NET/blob/master/Rx.NET/Source/System.Reactive.Core/project.json\nFeel free to repurpose this to suit - these bits are ready for GA in a couple of weeks.\n. Closing this out in favour of #1419 which has more information and is more recent.. @devkhan\nHere's some of my thoughts on this:\n- regarding \"Too many ctor's\" - I believe this we can resolve this as a side-effect of making HttpClient a first-class feature. There's a number of ctor dependencies in Octokit which we can (and perhaps should) delegate to the HTTP abstraction, such as:\n  - BaseAddress\n  - Timeout\n  - perhaps even Credentials?\nI wouldn't focus on this area first, but instead keep this in mind as you're exploring how we're using the HTTP stack inside Octokit. \n- per-request options are still something we'll need to support - but I'd recommend keeping this as simple as possible. A HttpClient can set it's own Timeout which is applied to all requests (irrespective of what we try and set for each request) so I fear we'll have some issues here troubleshooting just what was set for a request.\n- switching over to Refit or Retrofit means we might be able to clean up some of our plumbing, but I don't think it will really help us out here. They use a different set of conventions for organizing things, and the work required to port things over would be orthogonal to this work around letting users provide their own HttpClient instance for our HTTP operations.\nI guess the thing to bring this thread together is that we've had various requests in the past to be able to plug things into Octokit's HTTP stack, such as custom caching:\ncsharp\nvar httpCache = new HttpCache(new InMemoryContentStore());\nvar cachingHandler = new HttpCacheHandler(httpClientHandler, httpCache);\nvar client = new HttpClient(cachingHandler);\n...\nWe also introduced following HTTP redirects natively into Octokit in #808 after it became a feature of the GitHub API, so we know we can customize our plumbing to suit - how we let others do the same is what I'd like to solve here...\nHope this helps!\n. @devkhan we've started a discussion in #1074 about that - the serializations are specific to Octokit's request/response models and the API itself (and SimpleJson is internalized too), so I'd love to understand the scenarios and value that extracting it would permit...\n. @devkhan \n\nSince this should be added as a header to every request, I think its better to move in into the client.\n\nThis seems reasonable, however we need to ensure that a User-Agent header is set.\n\nI want to discuss this project in detail, and long conversation might not be a good fit here. Can you chat on Gitter?\n\nI'd rather do things publicly wherever possible, as there are others here who are familiar with Octokit and may be able to answer your questions - rather than myself being a blocker. But yes, I can keep an eye on Gitter...\n. > So then, how much work is left in this project?\n\nSidenote: Why didn't you merged that PR?\n\nDon't take my previous work as gospel here - I was exploring it and opened the PR to gather feedback. It didn't really get to the point where it was mergeable due to how much is involved with the HTTP stack, but hopefully the lessons learned help out with the work on this PR...\n. While we're in here, could you look at making the whitespace consistent? It's probably my fault that there's some inconsistencies in here...\n. @Anubhav10 this looks good - just that one improvement to the message and some cleanup of the whitespace and I think this is good to go!\n. @Anubhav10 excellent, thanks for this!\n\n. @devkhan we have a large suite of tests which will help catch any unexpected behaviour, so please investigate and see if this can be cleaned up.\n. Some initial thoughts:\n- the /repositories/:id/ is not included in the response payload for a repository, e.g. https://api.github.com/repos/octokit/octokit.net or https://api.github.com/repositories/7528679\n- the only place I can find a mention of this is in the search results API\n- I can see octokit.rb has support for passing an Integer here. I can't see an equivalent for octokit.objc but perhaps I'm not looking in the right spot.\n\nIf one desires to build an application that is resilient to change (e.g., repositories changing names, changing owners, owners changing name, etc.) then the application should be built against the repositories API rather than the repos API.\n\nThis should be covered by the API supporting redirects which Octokit now follows correctly. \n\nThis is still not great though as it can race and lead to very unexpected behavior if you are in the middle of a complex transaction (spanning multiple API calls) when the repository moves out from under you.\n\nI'd love to hear more about this scenario and what you're looking to build here. With most of our operations (whether returning a task or an observable) we're interested in getting the data as soon as possible. If that scenario isn't suitable for your use case, perhaps there's something we can be doing in Octokit to address this. \n. @Zoltu thanks for the extra information - and yes, there are certainly ways to subvert the process.\nI had a chat with one of the API team just now and he told me that we intend to support /repositories/:id (even if it isn't documented) in the long term. I think I'm going to spin this out into a GSoC task for someone who is interested in contributing - unless someone else wants to claim it...\n. I've opened this up as a potential GSoC activity over in https://github.com/github/mentorships/issues/112\n. @heshuimu have a look at our documentation - http://octokitnet.readthedocs.org/ - it's not 100% covered, but will give you an idea of the basics. Also, the open pull requests for the repository will give you an idea of what's in flight and how we work...\n. @dampir that all sounds reasonable\n. This will be available in Octokit 0.21 which is almost ready to :ship:\n. I'd love to hear a bit more about what you're trying to do. Please have a read of this section of our README and open a new issue with some more details...\n. Fixed by #1131 \n. @AlexP11223 thanks!\n. > Perhaps @shiftkey can advise between the preference of adding a Default enum element (that has a blank property value causing nothing to be specified) vs allowing nullable properties?\nI'd rather these be optional parameters as that's the precedence we have for handling values that may be set. And as per the docs, there's documented default behaviour here for all these values if they're not set:\n\nI have some concerns that I should have raised earlier. Consider this scenario:\ncsharp\nvar request = new RepositoryRequest\n{\n   Visibility = RepositoryVisibility.Public,\n   Type = RepositoryType.Owner\n};\nThis is a valid object to create, however it will fail during the request. Do we guard against that, or just bubble up the exception to the user? There's an escape hatch we have to override RequestParameters.ToParametersDictionary and verify that a valid set of parameters are provided - and throw otherwise.\nAnyway, :thumbsup: to throwing more unit tests into this area - RequestParameters is very important, and I'd hate to introduce something unexpected here.\n. Looks good to me! Thanks @AlexP11223!\n\nAnd thanks @M-Zuber @ryangribble for helping out with the review!\n. To follow up on @ryangribble's summary, if they're not testing the actual serialized result (which I'm pretty sure is most of them) we can just simplify things to indicate that we don't care. For example:\n``` csharp\n[Fact]\npublic async Task RunsConfiguredAppWithAppropriateEnv()\n{\n    var httpClient = Substitute.For();\n    IResponse response = new Response();\n    httpClient.Send(Args.Request, Args.CancellationToken).Returns(Task.FromResult(response));\n    var connection = new Connection(new ProductHeaderValue(\"OctokitTests\"),\n        _exampleUri,\n        Substitute.For(),\n        httpClient,\n        Substitute.For());\nawait connection.Patch<string>(new Uri(\"endpoint\", UriKind.Relative), new object());\n\nhttpClient.Received(1).Send(Arg.Is<IRequest>(req =>\n    req.BaseAddress == _exampleUri &&\n    req.Body != null &&\n    req.Method == HttpVerb.Patch &&\n    req.ContentType == \"application/x-www-form-urlencoded\" &&\n    req.Endpoint == new Uri(\"endpoint\", UriKind.Relative)), Args.CancellationToken);\n\n}\n```\nOr you could drop the req.Body verification - but I favour some correctness here if you think it's relevant to the test...\n. I had a quick look at this and here's a test that reproduces the issue:\n``` csharp\n[IntegrationTest]\npublic async Task CanFilterByMilestone()\n{\n    const string expected = \"my first milestone\";\n    var milestone = await _issuesClient.Milestone.Create(_context.RepositoryOwner, _context.RepositoryName, new NewMilestone(expected));\nvar newIssue1 = new NewIssue(\"An issue\") { Body = \"words words words hello there\", Milestone = milestone.Number };\nvar newIssue2 = new NewIssue(\"Another issue\") { Body = \"some other words\" };\nawait _issuesClient.Create(_context.RepositoryOwner, _context.RepositoryName, newIssue1);\nawait _issuesClient.Create(_context.RepositoryOwner, _context.RepositoryName, newIssue2);\n\nvar allIssues = await _issuesClient.GetAllForRepository(_context.RepositoryOwner, _context.RepositoryName,\n    new RepositoryIssueRequest());\n\nAssert.Equal(2, allIssues.Count);\n\nvar issuesInMilestone = await _issuesClient.GetAllForRepository(_context.RepositoryOwner, _context.RepositoryName,\n    new RepositoryIssueRequest { Milestone = expected });\n\nAssert.Equal(1, issuesInMilestone.Count);\n\nvar issuesWithoutMilestone = await _issuesClient.GetAllForRepository(_context.RepositoryOwner, _context.RepositoryName,\n    new RepositoryIssueRequest { Milestone = \"none\" });\n\nAssert.Equal(1, issuesWithoutMilestone.Count);\n\n}\n```\nThe solution however is a bit more complicated. Checkout out the API docs:\n- milestone - integer or string\n\nIf an integer is passed, it should refer to a milestone by its number field. If the string * is passed, issues with any milestone are accepted. If the string none is passed, issues without milestones are returned.\n\n\n. @ryangribble ah, so there's a convention we use here to indicate when a method depends on the current user - we call the method GetAllForCurrent() and don't pass in any parameters...\n. @ryangribble looks good to me - I've updated the title to reflect the work necessary\n. @ryangribble this sounds like a grand idea! I've got the code lying around which I used to create the starting point for this release, but let's try out including the summary for the next release.\n. @ryangribble @haacked thanks for the speedy replies. I'll close this out when I've updated the labels.\n@ryangribble did you want to open an issue for the release notes stuff so we can hash out how that might work separate to this?\n. @ryangribble all good, I've plenty to keep me busy anyway :wink:\n. @M-Zuber I'm leaning towards something simple because of two reasons:\n1) I built the basic flow out as Octokit API calls in about 5mins\n2) This feels like a nice use case for Octokit\n. I also removed enhancement (any issues tagged with this are now tagged with feature) and removed api-cleanup - there was one issue and that's now tagged as up-for-grabs\n. A bit more cleanup - post-v1 has been removed (I'll bring in a v1 tag as we get close to API completion) and I've added meta to indicate open discussions (things that aren't quite issues).\n. Alright, time to end this labelling spree...\n. This has been published to NuGet:\n- https://www.nuget.org/packages/Octokit/0.19.0\n- https://www.nuget.org/packages/Octokit.Reactive/0.19.0\n. > can we also please rename the unit test classes?\n:thumbsup:\n\nIm not sure why the method name GetAll didnt trigger it but GetAllForCurrentdoes, but you can suppress it \n\nI forget the exact reasons, but I gather FxCop just doesn't like methods without parameters (even though these return something more complex than a value)...\nEDIT: nevermind, MSDN has my back:\n\nA public or protected method has a name that starts with Get, takes no parameters, and returns a value that is not an array.\n. @ryangribble it does not, no...\n. @ryangribble I'm on it\n. This all looks good to me. I'll let @ryangribble hit the big green button on it (it won't go out in v0.19, but that's a minor thing).\n. release_notes: Renamed IUserKeysClient.GetAll() to IUserKeysClient.GetAllForCurrent() \n. @ryangribble thanks for working on this. I'll have a look over it in the next day or so and see if I can answer your questions as well...\n. @ryangribble haven't forgotten about this, aiming to get to it today\n. @ryangribble looking over this change, I'm :thumbsup: to just removing this as it'll be covered by the breaking change\n. Just one more code comment to tidy up and I think this is good.\n\n@ryangribble how does this read for the breaking changes documentation:\n\nDecoupled request and response models usage of ItemState enum due to API rules. When querying for issues, milestones or pull requests these now use ItemStateFilter, and response models continue to use ItemState. \n. @prayankmathur correct, this one https://github.com/octokit/octokit.net/pull/1140#discussion_r57465473\n. @ryangribble over to you \u270a \n. release_notes: Add importers field to IMiscellaneousClient.Meta response\n. @alfhenrik ugh, yep, missed this one.\n\nThanks for letting me know, I'll edit the GitHub release to include that change...\n. For reference, I added this comment to the GitHub release:\n\nItemStateFilter has been introduced to separate it from the search APIs, which still use ItemState. This affects IssueRequest.State, PullRequestRequest.State and MilestoneRequest.State. You'll need to rename any enum usages from ItemState to ItemStateFilter.\n\n@alfhenrik can I get a :thumbsup: that this matches with what you were seeing?\n. > should the status field be implemented as an enum in octokit?\nI like this, as judging by the documentation it should have a finite set of values.\n. @devkhan \n\nI noticed that there is a GetRedirect() method on ApiConnection, which serves our exact purpose but doesn't have an overload which takes the accepts parameter. But it is marked obsolete as Octokit now follows redirects automatically, so what should be done?\n\nThis was a decision made a while ago when repository redirects were added. We decided to make the client behave the same and never surface 301/302 responses to the consumer - simply follow these and return the content at the end.\n\nSo, while Octokit has the ability to download raw files, it can't be utilised as the Get() methods only return the deserialized objects.\n\nWhat sort of raw object are we talking about here? I ask because for our repository archive downloads, we return a Task<byte[]> which the user then converts into the expected archive format.\n. @devkhan I think that's the best way to do it here, but I haven't delved deeply into this PR (apologies!). With the repository archive endpoint, the user can specify the format to download too (ZIP or TAR) - is that an option here as well?\n. @devkhan if there's no option then the xml-docs should just explain the details to the user. Keep it simple!\n. \n. @laedit go for it - there might be some things to catch when serializing/deserialzing but I'm happy to review things and ensure a smooth transition\n. @ryangribble uh, that's, neat! Will have a look....\n. @ryangribble I was able to re-send the webhook to AppVeyor but the Travis integration doesn't have that option. Oh well, it should trigger when the PR is next synced...\n. Stopping here to let this sit and hopefully gather feedback.\nOtherwise I'll merge it in a couple of days...\n. Me right now:\n\n\nWe could add the concept that a comment made on an issue/PR with specific wording, can \"set\" what the release notes should say for that issue.\n\nI like this - I'm fine with reading all the issues for this syntax - we can also look at the author to ensure it's someone trusted (whatever that means)\n\nIf not present it could either fail the release notes process, or fall back to using the actual issue title\nFor example, if the issue is \"Error xxxxx when loading my public repositories\" we might make a comment saying\n\nYeah, the PR titles often need a bit of love. I wouldn't fail the process here. Just grab the title and use it as a placeholder, e.g. \"CLARIFY: Error xxxxx when loading my public repositories\"\n\nthis could be even further extended for example if there was a comment for \"breaking changes\" then \n\nI'm still not settled on a syntax for breaking changes in the release notes (I'd rather explain things in a human friendly way), so perhaps we should just use a label to flag PRs that have breaking changes and see what happens next?\n\nShould every PR be associated with an issue or do we need to handle release notes sometimes being for a PR item and other times being for one (or more) fixed issues via a PR?\n\nLet's not assume every PR has an issue associated with it. The IDs I use in the release notes are for the PR, as the contribution is the thing I care about here. So let's continue down that path.\n\nFor each PR/issue we can get the commits/authors so we can continue the tradition of @mention each author against that line item\n\nIf we're going to script this, we should look at the author of the PR commits as well as the person who opened the PR.\n\nIf @shiftkey wants to mention anybody who \"assisted\" even if that was reporting an issue or taking part in review/discussions, we could also build up a list of commenters on all the PR's in a release then have a general \"thanks to the following who were part of helping with this release\" or something similar at the end of the release notes\n\nYES. I'd love to shout out to people who helped with reviewing. Let's do this!\n\nDo standalone commits (ie commit on master that wasn't associated with a pull request) need to be handled?\n\nNope. I want everything to go (including my stuff) through a PR, even if it's trivial.\nOne little thing that I don't have a good answer for is how multiple PRs can span a feature. But let's cross that bridge later.\n. @ryangribble\n\nIs there a need to group these together?\n\nPerhaps, perhaps not. Here's a recent example from v0.19:\n\nAdd support for Visibility and Affiliation to repository search - #1096, #1132 via @Sarmad93, @AlexP11223\n\nThe first PR was to implement the feature, and the second was to address a regression that was introduced not caught during review. I didn't feel that the second PR warranted it's own line as it was within the context of the same release.\nThat's kind of how I feel about the upcoming pagination PRs - having a separate entry for each PR feels noisy, and I'd rather roll it all up into one item to summarize.\nOut of those suggestions, the milestone one actually feels the best fit - I'll have a bunch of issues which are all linked to that initial feature, and I don't want to publish this release until it's all merged. We could look for a milestone and group items in that way separate to all this - or just \"squash\" together the PRs and contributors into a single item...\nThoughts?\n. @ryangribble are you able to crack open HttpResponse response and see what it has set? I'm pretty sure there's some implementation differences between release assets on GitHub.com and GHE, so I'd love to know more about your setup...\n. @ryangribble yeah, that's more information - I was hoping for something more instructive than a HTTP 500 but that's fine, I can work with that. I'll test on another GHE service to see if I can trigger the same thing with a private repository.\n. @ryangribble that's great news!\n. > I know about that, but that didn't work if the PR opener doesn't have appropriate access rights to close the issue.\nI don't believe this is the case. Please mention Fixes #XXX in the PR title. \n. Fixed in #1312\n. GetAllEmoji doesn't support pagination. I'll need to figure out a way to exclude that when it comes time to verify this.\nEDIT: and neither does GetAllGitIgnoreTemplates\n. Actually, dropping myself from this as MiscellaneousClient doesn't use IApiConnection here - just IConnection - and this doesn't have any of the ApiOptions overloads available.\nCome back to this after all the others are done.\n. As List All Licenses also lacks pagination this really isn't feasible to implement (or hack around). Closing it out.\n. Parking this one because of a bug with the API for GetAllForSubNamespace:\n``` bash\n$ new_content=$(curl \"https://api.github.com/repos/octokit/octokit.net/git/refs?per_page=5\")\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  1823  100  1823    0     0   1394      0  0:00:01  0:00:01 --:--:--  1393\n$ jq length <<< \"$new_content\"\n5\nnote the namespace added here\n$ content=$(curl \"https://api.github.com/repos/octokit/octokit.net/git/refs/heads?per_page=5\")\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  5227  100  5227    0     0   3399      0  0:00:01  0:00:01 --:--:--  3398\nthe pagination is ignored, everything is returned\n$ jq length <<< \"$content\"                                                                \n14\n```\n. @dampir  :thumbsup:\n. I'll see if I can open this PR today and hopefully wrap up this release this week :metal:\n. Fixed in #1310\n. Closing this out as the underlying API doesn't support pagination.\n. Done in #1307\n. @devkhan you're right, let's skip this\n. This was fixed in #1336\n. @prayankmathur given it's not related to this feature, a separate PR would be nice for a couple of reasons:\n- we can review it separate to this\n- given it's a simpler change, it's likely to get merged in quicker\nI'll leave it up to you whether you'd like to extract that to a new branch.\n. @prayankmathur this looks like it contains work from #1140 (open) and #1196 (merged). Are you able to rebase the branch so that this only contains the work related to the locking and unlocking of issues?\n. @prayankmathur this is getting closer - just added some things that I found while trying to get the tests to run... \n. I'm happy with the integration test now passing, and the minor stuff remaining can be sorted out later.\nThanks @prayankmathur!\n. Integration tests passing, no issues with the code - this is just great! Thanks @devkhan!\n\n. @devkhan let's not rush through these - we're discussing some API changes in #1190, and doing reviews per-client is easier for us to ensure we don't miss anything...\n. Yep, this has been merged in #1145\n. @dampir yeah, email addresses are tricky. Let's not worry about integration testing pagination on those.\nEDIT: the big reason why I'm conservative here is that we're assuming some state about the user's account that may not be true between contributors. It's easier to do this with repositories we create in tests, or public repositories with some known state, so I'm happy to just keep tests which depend on user's data simple.\n. > Since these weren't in @shiftkey's example implementation I'm wondering whether they should be included here or not.\nUnless there's a compelling reason to add them I'd like to remove these changes.\nThe big issue with introducing the ApiOptions.None singleton is that ApiOptions's properties are still mutable - potentially introducing strange behaviour if you happen to mutate the global instance - so I'd rather it just return a new instance each time you get a value.\nThe alternative here is to remove the setters so you can enforce read-only values, but the necessary ctors to support this felt more verbose so that's why I ended up here.\n. Those changes look good. Added a couple of comments around the integration tests.\nI'll get @ryangribble to have another look once those are addressed.\n. @dampir just an FYI - there's no need to @mention me in these PRs and comments unless there's a specific question you need answered from me - I get the notifications either way :grin:\n. Alright, quick brain dump:\n- as Octokit is being used in many places, we should be [Obsoleting] before removing any APIs.\n- the [Obsolete] comment should indicate what the caller needs to update\n- for the most part, the code should continue to work while obsolete\n  - allowAutoRedirect is one exception I can think of, but as we're all-in on redirects then I can live with that\nThe $64000 question of course is \"how long should these be obsolete for before removing them?\"\nI might be being totally arbitrary here, but 2 releases feels like a good number - just in case callers happen to skip a release. We've been rather slow with releases lately (~1 month and ~2 months between the last three releases) but if we get moving to a more frequent cadence of releases (hint: yes, we should) then we can re-evaluate this and perhaps move to a time-based approach.\n. > Should we include the release in the obsolete message?\nMaybe? Having the release number there may mean they'll go and read the release notes - but perhaps the details in the message are enough for them to understand...\n\nI agree, but for devil's advocacy do accepted (& actually used) guidelines exist for this kind of thing?\n\n\"It depends\" is really the best answer I can come up with, and this probably comes down to support lifecycles. On one hand, $vendor may need to support obsolete features in an API until the next major release. On the other hand, some OSS library may choose to ignore SemVer and arbitrarily introduce breaking changes because move fast and break stuff.\nTechnically we're pre-1.0 so SemVer is not very opinionated about this, but I'd favour being more conservative in general. In my mind 1.0 is having GitHub v3 API support covered and some necessary infrastructure changes in place - but we can act like post-1.0 right now with respect to obsoleting changes...\n. > Happy with that approach for .20 release?\nYes, very happy\n. @M-Zuber I think we should drop usages of the allowAutoRedirect parameter and possibly remove it - if that's already been marked as obsolete...\n. @rogertinsley welcome!\nTo be perfectly honest, the only bits of feedback I have are minor - this is really nice work!\nOne suggestion - if you wanted to add another integration test where you:\n- create a repository\n- make a commit through the API, get the new SHA\n- verify the SHA from this new endpoint matches what you got earlier\nI think that'll give us enough coverage for this endpoint to close this out.\n. > Im not sure where @shiftkey stands on integration tests for observable clients - given that alot are missing, and it's pretty much only ever calling the regular client anyway... perhaps all we need are unit tests for observable clients...\nThis is essentially my views - if the implementation is just calling the Task-based API, then additional integration tests for the Observables are just doubling up. But yes, :thumbsup: to additional unit tests. \n. @rogertinsley this all looks good! I can't wait for the next one.\nI'll let @ryangribble have the final word.\n. @prayankmathur yep, but I'd rather just deal with the single commit - instead of all the preceding commits.\nHere's a way to reset this branch to just contain that commit:\n// if you have your remotes already configured, skip this step\ngit remote add upstream https://github.com/octokit/octokit.net.git -f \n// ensure we're on the right branch\ngit checkout UpdateIssue\n// reset this branch to the latest version in development\ngit reset upstream/master --hard\n// add just one commit to the new branch\ngit cherry-pick 5118d8d\n// push these changes to reset the branch\ngit push origin UpdateIssue --force\n. @prayankmathur I generally don't obsess over everyone running FormatCode as part of every pull request. For me, it was there to run periodically to ensure everything was up to (a) standard.\nAs you can see, all it caught here was a bunch of excess whitespace - so this is minor thing for me.\n@ryangribble I'm not going to stress about this too much. Thanks for being on top of it!\n. @ryangribble captured in #1201\n. @Haacked I'd love it to be more specific than that, so that it goes directly to the right people\n. @Haacked something like conduct+octokit.net@github.com but I need to bug some people internally to ensure we're all on the same page before confirming it...\n. Yeah, this fell off our radar due to Other Priorities\u2122.\nI'm taking next week off (computer-free) so I'll pick this up when I'm back.\n. Updated the guidelines to use a real email address. Aside from some logistics work on my end this is ready to merge. Over to you @haacked.. Seconding everything @ryangribble just said above...\n\n. @devkhan I'm neutral on this.\nOn the one hand, I think code coverage is a questionable metric for code quality. Fowler sums it up nicely in that it should be used to look for untested code, not as a general metric.\nOn the other, if someone thinks it's worth setting up, they are welcome to explore options and see how Octokit integrates with this. Ultimately I'm more interested in finding the code that isn't covered by tests, than the statistic itself. \n. Setting this to a meta discussion.\n. @devkhan nope, this is fine to log - I'll leave this as an easy contribution for someone to get started on...\n. > is this OK or is there another way you'd prefer to guard against this?\nI'm a bit \ud83d\udc4e on the guard clause as-is but I'll sleep on it - or we can discuss it in a separate PR.\nEverything else is :gem:\n. @ryangribble I'd love to script out something so we can verify all these URIs are correctly formatted, rather that bake that behaviour into HttpClientAdapter which may go away if we move to having HttpClient at our core. I think we could probably hack something quick and dirty together with reflection to cover ourselves...\n. @ryangribble thanks!\n. release_notes: RepositoriesClient.GetAllPublic() failed on GitHub Enterprise usage due to incorrect Uri formatting\n. @dampir \n\nHave I open issue for each of them? Or I could create just PR without appropriate issue?\n\nSave time, just go straight to the PR - especially for things like cleanup and/or refactoring.\n. I'm pretty sure this was something I was tracking as part of auditing everything in https://github.com/octokit/octokit.net/pull/1038/ but I'd need to remember just what past me was doing there...\n. Just a heads up - removing the namespaces is likely to cause a whole bunch of indenting changes to the test suite. It's a minor nuisance but things like git blame will then be full of lies...\n. @M-Zuber that's exactly the issue, and why I kinda put it aside when I started finding these \ud83d\ude22\n. > Is there a setting that prevents VS from tacking on namespace parts to match the file system?\nUnfortunately it seems to be R# only\n. @M-Zuber assigning myself to look at this tomorrow\n. I have some reservations about the SimpleJson changes, mostly due to that file being an external dependency we pull in. Are you able to revert that change?\n. @dampir excellent, thanks!\n. I'd rather not introduce optional parameters here for fear of versioning issues down the track, and also for having to write code like this inside the implementation:\ncsharp\npublic Task<IReadOnlyList<Release>> GetAll(string owner, string name, ApiOptions options = null)\n{\n   options = options ?? ApiOptions.None;\n   // other code here\n}\n. @devkhan in response to your second question:\n\nSecondly, modifying the test for the overloads requires you to check for Args.ApiOptions, neither ApiOptions.None nor Arg.Any<ApiOptions>(ApiOptions.None) work. Why is that so?\n\nBecause ApiOptions.None is just a plain old instance of ApiOptions, testing for a specific instance is tricky. You could check it has the default values set, but as the whole purpose of the class is to just carry around values, I didn't really focus on it here.\nOur helper  Args.ApiOptions is just a wrapper around Args.Any<ApiOption>() - if you wanted to test for specific values on ApiOptions you could use Arg.Any<ApiOptions>(o => o.Page == 2) to make this clearer. I'll leave it up to you how far you want to take this...\n. @devkhan I can't see anything interesting in my inbox\n. @devkhan apologies, that's not what I meant. I saw the stuff about your proposal but couldn't find anything else...\n. Aside from adding some new tests, I could only find one little thing of feedback. Looking good @devkhan! \n. @ryangribble okay, I'll bite :grin:\nYou're right, this isn't a blocker. And it's only one situation. But I'd like these PRs to focus on adding the ApiOptions overloads wherever possible so I can get the release out as soon as possible. That's why I'm calling out coding style things in these PRs.\n\nMy personal preference is to use the underscore, which is also something that resharper suggests, and as mentioned the coreFx coding style also defines.\n\nThis is one place I don't like the R# defaults, let alone the CoreFX coding style, as I feel it adds unnecessary noise to the code - and not everyone runs R#.\nHappy to have a discussion on this and where my thoughts are at. I'd also remove all usages of private for example, as that's considered the default behaviour for visibility...\n. @devkhan @ryangribble I won't hold up merging this for the single change. Let's hash it out in that related issue. \n. @SamTheDev this looks like it's progressing nicely :metal:\n. @SamTheDev I added a bunch of suggestions to your initial tests, what you have there is rather close\n. @SamTheDev almost there, just that one last test to update!\n. @SamTheDev excellent, I'm going to hit the big green button now. Thanks for the contribution!\n\n. @prayankmathur looks like some tests need to be updated\n. @prayankmathur you're right - I'll correct that and open a separate PR for it...\n. @prayankmathur this is looking good.\nWe don't seem to have any integration tests for the RepositoryPagesClient, but that seems to be covered by the ObservableRepositoryPagesClientTests tests. Would you mind adding that in now, at least just for the new GetAll methods we're adding here?\n. @prayankmathur \n\nWhy are there no integration tests for the methods in the RespositoryPagesClient?\n\nProbably something that was missed at the time. Given this is a read-only interface it should be easy to use the Octokit.NET repository (or something similar) and craft some simple tests to get our coverage up...\n. > So should i do the honors and include them too ?\n\n. @ryangribble @prayankmathur looks like there's some limitations with accessing the Pages API based on the docs:\n\nInformation about the site and the builds can only be accessed by authenticated owners, even though the websites are public.\n\nThis is going to cause headaches, and perhaps we need to do this setup:\n- create the repository \n- publish something to gh-pages\n- check build staus\n- teardown the repository\nThis will likely mean most of the tests here are excessive...\n. @prayankmathur that sounds great! Leave one test with an \"[IntegrationTest(Skip= \"These tests require repository admin rights - see https://github.com/octokit/octokit.net/issues/XXX for discussion\")] so we can link to the related discussion...\n. @prayankmathur it's defined in AppVeyor's config file - https://github.com/octokit/octokit.net/blob/master/appveyor.yml#L3-L7\n. I'm not sure what the current state of this PR is, so I'm moving this to #1304 so I can merge this new code in (with the skipped test).\n. @dampir excellent, thanks!\n. Just rebased this due to a merge conflict. @ryangribble can I get a :thumbsup: here?\n. @ryangribble yeah, looks like #1212 also touched these files. Given the difference is now minor, I'll skip it. \n. @dampir LGTM\n\n. @ryangribble \n\nwhat do you reckon to :fire:ing IApiConnection.GetRedirect(), eventhough it wasnt marked obsolete? Note that the concrete implementation, as well as multiple other places regarding Redirects and ArchiveLinks HAVE been obsolete for 100+ days\n\nI'd be breaking my own rule here, and covering over an oversight of mine. Let's add the [Obsolete] to the interface and leave it alone for this release.\n. This all seems good to me. @ryangribble anything else to add here?\n. @dampir excellent pick up! \ud83d\udc4f \n. @M-Zuber be careful, the repository issue search on the website is likely to be a bit different to what's available through the API. Someone asked me a while ago about this and I'm pretty sure -label doesn't work through the API when looking at repository issues, for example.\n@ryangribble regarding your question about the properties, an alternative might be ExcludeLabels. Personally, I don't think that users should need to know or care that you need to do a - prefix, so this is a good direction to head.\n. @ryangribble I haven't forgotten, just been digging myself out from under work since I got back to Oz last week and needed a bit of mundane work to take a break. I'll pick this up tomorrow.\n. @ryangribble looking over the recent questions:\n\nThe following fields were not implemented for exclusion for listed reasons:\n- Type,In,No,Is\n  These failed integration tests, API doesnt support negating these\n\nWorks for me.\n\n\nCreated,Updated,Merged,Closed,Comments\n  These date/range fields already support greater/less than and \"between\" syntax, so having an exclusion option doesnt really make sense so I didnt attempt to implement/test\n\n\nYep, I like this too.\n\n\nTeam\n  I didnt get time to find a suitable repo that has teams being @mentioned in issues, to run integration tests against\n\n\nThis is fine. We'll cross that bridge if we have to.\n\n\nUser\n  Not tested.\n  Does it make sense to do a search for something in all repos EXCEPT those owned by a user or organisation?\n\n\nHappy to kick this can down the road until someone comes looking for it.\n\n\nRepos\n  Not tested.\n  Does it make sense to do a search in all repos EXCEPT some specified?\n\n\nI guess if you wanted to offload more of the search work onto the API. But again, really edge case. :boot: this for now.\n. Changes look good, integration tests are working fine on my end.\nI'm happy with the direction, happy to give it another look now that I finally got around to answering your questions...\n. :thumbsup: to PR -> PullRequest - and :heart: for doing the obsoletion already\n:thumbsup: for No\n. @ryangribble +:100: nice work!\n. Just a heads up: #1238 has a fix for the Travis issue - feel free to cherry-pick 8ec4bf388c674c1ce5f09f8c8ad88a470ce7f4d9 so you can verify this PR is still correct\n. @dampir thanks!\n. > Can we add inconsistencies like this to be resolved in FormatCode command?\nThere's no real project-specific rules defined in Octokit.CodeFormatter and writing Roslyn analyzers is a bit tricky if you're not familiar with the concepts.\n\nGuess after we choose name convention for these classes, we can add additional checks in Conventions test rather in FormatCode.\n\nThis feels a bit easier to add and will be caught earlier.\n. Closing this after the work done in #1246. Please open a new issue if there are further ideas about this.\n. Just a heads up: #1238 has a fix for the Travis issue - feel free to cherry-pick 8ec4bf388c674c1ce5f09f8c8ad88a470ce7f4d9 so you can verify this PR is still correct\n. > Revealed a bug with an existing field GitHubServicesSha not being deserialised properly, added a fix to this PR\nIt's weird that this is failing - the UpperCamelCase to upper_camel_case looks like it should work here but perhaps I'm missing something. Anyway, happy to take this in here...\n. @ryangribble this all seems great :sparkles: just the little message which is really, really minor \n. > I think the capital H in \"GitHub\" was causing it\nAh yes, that makes sense :skull: \n. \n. Implemented in #1245\n. @devkhan just added a task to ensure the files are synced across all the projects\n. LGTM :thumbsup:\n. @devkhan don't worry about it. I think this area of the codebase is rather boring and unit tests are good enough coverage for the error code handling...\n. > it would be great if i can change the author of the older commits as well, is there an easy way to do that ?\nYou should check your email addresses defined on GitHub as well\n. @SamTheDev just did a pass over all the files in this PR, mostly focusing on the test changes. Looking good!\n. It looks like a .swp file was committed in c32dfbec13ae7212b99ba451176822194dddc500 - are you able to remove that from the history?\n. Just one more little bit of cleanup that was missed. I'll verify the tests later this week as I'm on terrible internets right now...\n. Oh, and that merge conflict :cry:\n. @SamTheDev up to you - I'd suggest just merging master in again...\n. @SamTheDev just this one comment https://github.com/octokit/octokit.net/pull/1240/files#r58579094\n. Cross-referencing https://github.com/octokit/octokit.net/issues/1251 again to remind myself about digging into that...\n. @SamTheDev thanks!\n. @tidusjar which version of Mono?\n. A quick test indicates repository should be available at the GetAllForCurrent endpoint. I'd need to test GetAllForOrganization as well but don't have the right setup to confirm this right now:\n```\n{\n    \"url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/issues\\/1\",\n    \"repository_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\",\n    \"labels_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/issues\\/1\\/labels{\\/name}\",\n    \"comments_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/issues\\/1\\/comments\",\n    \"events_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/issues\\/1\\/events\",\n    \"html_url\": \"https:\\/\\/github.com\\/shiftkey-tester\\/public-repo-20151222021054458\\/issues\\/1\",\n    \"id\": 123397029,\n    \"number\": 1,\n    \"title\": \"Integration test issue\",\n    \"user\": {\n      \"login\": \"shiftkey-tester\",\n      \"id\": 5151713,\n      \"avatar_url\": \"https:\\/\\/avatars.githubusercontent.com\\/u\\/5151713?v=3\",\n      \"gravatar_id\": \"\",\n      \"url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\",\n      \"html_url\": \"https:\\/\\/github.com\\/shiftkey-tester\",\n      \"followers_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/followers\",\n      \"following_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/following{\\/other_user}\",\n      \"gists_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/gists{\\/gist_id}\",\n      \"starred_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/starred{\\/owner}{\\/repo}\",\n      \"subscriptions_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/subscriptions\",\n      \"organizations_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/orgs\",\n      \"repos_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/repos\",\n      \"events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/events{\\/privacy}\",\n      \"received_events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/received_events\",\n      \"type\": \"User\",\n      \"site_admin\": false\n    },\n    \"labels\": [\n],\n\"state\": \"open\",\n\"locked\": false,\n\"assignee\": {\n  \"login\": \"shiftkey-tester\",\n  \"id\": 5151713,\n  \"avatar_url\": \"https:\\/\\/avatars.githubusercontent.com\\/u\\/5151713?v=3\",\n  \"gravatar_id\": \"\",\n  \"url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\",\n  \"html_url\": \"https:\\/\\/github.com\\/shiftkey-tester\",\n  \"followers_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/followers\",\n  \"following_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/following{\\/other_user}\",\n  \"gists_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/gists{\\/gist_id}\",\n  \"starred_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/starred{\\/owner}{\\/repo}\",\n  \"subscriptions_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/subscriptions\",\n  \"organizations_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/orgs\",\n  \"repos_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/repos\",\n  \"events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/events{\\/privacy}\",\n  \"received_events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/received_events\",\n  \"type\": \"User\",\n  \"site_admin\": false\n},\n\"milestone\": null,\n\"comments\": 0,\n\"created_at\": \"2015-12-22T02:10:56Z\",\n\"updated_at\": \"2015-12-22T02:10:56Z\",\n\"closed_at\": null,\n\"repository\": {\n  \"id\": 48404947,\n  \"name\": \"public-repo-20151222021054458\",\n  \"full_name\": \"shiftkey-tester\\/public-repo-20151222021054458\",\n  \"owner\": {\n    \"login\": \"shiftkey-tester\",\n    \"id\": 5151713,\n    \"avatar_url\": \"https:\\/\\/avatars.githubusercontent.com\\/u\\/5151713?v=3\",\n    \"gravatar_id\": \"\",\n    \"url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\",\n    \"html_url\": \"https:\\/\\/github.com\\/shiftkey-tester\",\n    \"followers_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/followers\",\n    \"following_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/following{\\/other_user}\",\n    \"gists_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/gists{\\/gist_id}\",\n    \"starred_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/starred{\\/owner}{\\/repo}\",\n    \"subscriptions_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/subscriptions\",\n    \"organizations_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/orgs\",\n    \"repos_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/repos\",\n    \"events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/events{\\/privacy}\",\n    \"received_events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey-tester\\/received_events\",\n    \"type\": \"User\",\n    \"site_admin\": false\n  },\n  \"private\": false,\n  \"html_url\": \"https:\\/\\/github.com\\/shiftkey-tester\\/public-repo-20151222021054458\",\n  \"description\": null,\n  \"fork\": false,\n  \"url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\",\n  \"forks_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/forks\",\n  \"keys_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/keys{\\/key_id}\",\n  \"collaborators_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/collaborators{\\/collaborator}\",\n  \"teams_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/teams\",\n  \"hooks_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/hooks\",\n  \"issue_events_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/issues\\/events{\\/number}\",\n  \"events_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/events\",\n  \"assignees_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/assignees{\\/user}\",\n  \"branches_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/branches{\\/branch}\",\n  \"tags_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/tags\",\n  \"blobs_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/git\\/blobs{\\/sha}\",\n  \"git_tags_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/git\\/tags{\\/sha}\",\n  \"git_refs_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/git\\/refs{\\/sha}\",\n  \"trees_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/git\\/trees{\\/sha}\",\n  \"statuses_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/statuses\\/{sha}\",\n  \"languages_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/languages\",\n  \"stargazers_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/stargazers\",\n  \"contributors_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/contributors\",\n  \"subscribers_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/subscribers\",\n  \"subscription_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/subscription\",\n  \"commits_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/commits{\\/sha}\",\n  \"git_commits_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/git\\/commits{\\/sha}\",\n  \"comments_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/comments{\\/number}\",\n  \"issue_comment_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/issues\\/comments{\\/number}\",\n  \"contents_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/contents\\/{+path}\",\n  \"compare_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/compare\\/{base}...{head}\",\n  \"merges_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/merges\",\n  \"archive_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/{archive_format}{\\/ref}\",\n  \"downloads_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/downloads\",\n  \"issues_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/issues{\\/number}\",\n  \"pulls_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/pulls{\\/number}\",\n  \"milestones_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/milestones{\\/number}\",\n  \"notifications_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/notifications{?since,all,participating}\",\n  \"labels_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/labels{\\/name}\",\n  \"releases_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/releases{\\/id}\",\n  \"deployments_url\": \"https:\\/\\/api.github.com\\/repos\\/shiftkey-tester\\/public-repo-20151222021054458\\/deployments\",\n  \"created_at\": \"2015-12-22T02:10:55Z\",\n  \"updated_at\": \"2015-12-22T02:10:55Z\",\n  \"pushed_at\": \"2015-12-22T02:10:55Z\",\n  \"git_url\": \"git:\\/\\/github.com\\/shiftkey-tester\\/public-repo-20151222021054458.git\",\n  \"ssh_url\": \"git@github.com:shiftkey-tester\\/public-repo-20151222021054458.git\",\n  \"clone_url\": \"https:\\/\\/github.com\\/shiftkey-tester\\/public-repo-20151222021054458.git\",\n  \"svn_url\": \"https:\\/\\/github.com\\/shiftkey-tester\\/public-repo-20151222021054458\",\n  \"homepage\": null,\n  \"size\": 0,\n  \"stargazers_count\": 0,\n  \"watchers_count\": 0,\n  \"language\": null,\n  \"has_issues\": true,\n  \"has_downloads\": true,\n  \"has_wiki\": true,\n  \"has_pages\": false,\n  \"forks_count\": 0,\n  \"mirror_url\": null,\n  \"open_issues_count\": 1,\n  \"forks\": 0,\n  \"open_issues\": 1,\n  \"watchers\": 0,\n  \"default_branch\": \"master\"\n},\n\"body\": null\n\n}\n```\nWhether we should bake this into Octokit.NET however, I'm not so sure. It might be considered undocumented behaviour...\n. So I had a chat with our API team about this and it's just a documenation oversight. For v3 of the API there should be a Repository property off of the root Issue - now, whether we can (or should) use the existing one or not is something for us to check out.\n. Updated issue to clarify what needs to be done and mark it as up-for-grabs\n. So I like the CoreFx coding style with a few extra changes. Let me elaborate:\n- We use _camelCase for internal and private fields and use readonly where possible\nThis is helpful to understand context quickly when dealing with large, complex classes with lots of internal fields and variables. But I don't feel Octokit is at that stage (nor should it be aiming for that). We have lots of small classes composed together, and for the most part the fields we use can be made readonly which is the big headache with mixing fields and local variables (accidentally setting a field instead of a variable).\nSo I'd simplify this to \"We use camelCase for internal and private fields and use readonly where possible\"\n- We always specify the visibility, even if it's the default\nAgain, this is a noise versus value thing for me. I like removing private wherever it comes up as that's the default visibility.\nI'd change this to Specify the visibility unless it is private, in which case it should be removed\n. @ryangribble so I'm pretty sure I can adapt the .vssettings file from corefx to address those two. And I guess the R# rules file. I think those alongside with adding this to CONTRIBUTING.md (or something similar) should be good enough.\nI'll let others chime in here before I do anything about it.\n. @Sarmad93 thanks for starting this off. I added a couple of comments to help us complete this feature and verify we're doing everything right...\n. @Sarmad93 looking at those errors, I think something wasn't set correctly. You can run the same script again to view and update the values that the tests need.\n. Just putting this back to WIP until we can confirm the integration test setup script is correct.\n. @Sarmad93 some of the integration tests depend on the account being in a certain state - I've tried to keep it as runnable as possible for everyone, but differences do creep in which means they can fail.\nIf you want to focus on just your test, I'd suggest running it from in Visual Studio.\n. @Sarmad93 \n\nThe one which confuses me the 3rd parameter string twoFactorAuthenticationCode Should i pass null here? \n\nYou can specify null fine here.\n\nor i should update the position of parameters in overloaded put in IConnection class so that make Accept Header third input parameter and leave twoFactorAuthenticationCode without initializing it.\n\nDon't reorder the parameters as part of this PR. I'm not really sure why twoFactorAuthenticationCode is so pervasive in the IConnection signatures but let's avoid that for now...\n. @Sarmad93 I'm not angry, I just like to delete code whenever possible :fire:\n. @Sarmad93 I'm happy with that integration test - let's wrap this up and get it merged!\n. @Sarmad93 excellent, thanks!\n. \n. > (what's so special about events client since it seems to be used EVERYWHERE in the convention tests @shiftkey ?? :grinning:)\nI cannot recall why - but it goes way, way back to 2375a16aa05e0bb7211d089b43b9ced1a97af45d. :thumbsup: to using IGitHubClient\n. > I've marked it in my notes \"Tidy up conv. tests\", so it would be my next PR \n:thumbsup: to addressing our other usages after this PR lands\n. Aside from the merge conflict and the suggestion above, this is ready to merge! :metal:\n. @devkhan @dampir \n\nI don't completely understand what happened here, as this PR contains commits from other PRs also. \n\nI think this is due to me squashing the PRs yesterday when doing the merge. This wasn't intentional, however I do like how it's simplified the history...\nEDIT: I'm also not 100% sure this branch is correctly rebased (otherwise you wouldn't see the Merge branch 'master' of https://github.com/octokit/octokit.net into commits in this branch). I'm about to :airplane: so I'll sanity check this when I land...\n. @devkhan I think @dampir needs to update upstream/master or ensure they're using the right remote for the rebase - my psychic debugger thinks that an earlier master was used here, which would explain the commits we're seeing here...\n. @dampir just that one comment https://github.com/octokit/octokit.net/pull/1246#discussion_r60029583 about the cleanup and this is good to go. I'll hold off on other merges so that we can get this in!\n. @dampir yes, just waiting on CI to pass\n. > Also due to this, the IObservable<GitHubCommit> GetAll(string owner, string name, CommitRequest request, ApiOptions options) function doesn't return a list and am not able to write a test for it.\nSee this example for mapping the observable into a list.\n\nAlso, where to mention ApiOptions.None and where to mention New ApiOptions()\n\nI think we should stick to ApiOptions.None for the \"default\" values wherever possible, unless you want to test how specific options are used in tests. I couldn't find a usage of new ApiOptions() - could you elaborate?\n. @prayankmathur have these failing tests been committed to this PR yet?\n. @prayankmathur you need to add using System.Reactive.Linq; to the top of the tests class to get the awaiter to work...\n. @prayankmathur is the task list up to date? This seems to be close to closing out...\n. > but there are no unit tests for the remaining methods of the RespositoryCommitClient\nThis is fine. Let's get those last couple of feedback items addressed and we can close this out.\n. Ugh, I made that test fail. Let me understand what the right answer is here...\n. @prayankmathur thanks!\n. For reference, ConfigureAwait(false) is what libraries such as Octokit need to do when doing async/await internally, and we know we don't need the \"context\". You can read more about this stuff from this MSDN link\n. @ryangribble I just wanted to call out that I was able to drop some usages of async / await and there might have been a reason to keep them around...\n. release_notes: added ConfigureAwait(false) to numerous locations to prevent deadlock scenarios for ASP.NET and WinForms users\n. Here's some example events that I've found which break our current code for parsing activities...\n- A subscription event:\n``` json\n{\n  \"id\": 691197253,\n  \"url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/events\\/691197253\",\n  \"actor\": {\n    \"login\": \"ryangribble\",\n    \"id\": 5425163,\n    \"avatar_url\": \"https:\\/\\/avatars.githubusercontent.com\\/u\\/5425163?v=3\",\n    \"gravatar_id\": \"\",\n    \"url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\",\n    \"html_url\": \"https:\\/\\/github.com\\/ryangribble\",\n    \"followers_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/followers\",\n    \"following_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/following{\\/other_user}\",\n    \"gists_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/gists{\\/gist_id}\",\n    \"starred_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/starred{\\/owner}{\\/repo}\",\n    \"subscriptions_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/subscriptions\",\n    \"organizations_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/orgs\",\n    \"repos_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/repos\",\n    \"events_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/events{\\/privacy}\",\n    \"received_events_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/received_events\",\n    \"type\": \"User\",\n    \"site_admin\": false\n  },\n  \"event\": \"subscribed\",\n  \"commit_id\": null,\n  \"commit_url\": null,\n  \"created_at\": \"2016-06-14T00:31:49Z\",\n  \"issue\": {\n    \"url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1377\",\n    \"repository_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\",\n    \"labels_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1377\\/labels{\\/name}\",\n    \"comments_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1377\\/comments\",\n    \"events_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1377\\/events\",\n    \"html_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1377\",\n    \"id\": 160073758,\n    \"number\": 1377,\n    \"title\": \"v0.20 - Probably Australian\",\n    \"user\": {\n      \"login\": \"shiftkey\",\n      \"id\": 359239,\n      \"avatar_url\": \"https:\\/\\/avatars.githubusercontent.com\\/u\\/359239?v=3\",\n      \"gravatar_id\": \"\",\n      \"url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\",\n      \"html_url\": \"https:\\/\\/github.com\\/shiftkey\",\n      \"followers_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/followers\",\n      \"following_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/following{\\/other_user}\",\n      \"gists_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/gists{\\/gist_id}\",\n      \"starred_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/starred{\\/owner}{\\/repo}\",\n      \"subscriptions_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/subscriptions\",\n      \"organizations_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/orgs\",\n      \"repos_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/repos\",\n      \"events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/events{\\/privacy}\",\n      \"received_events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/received_events\",\n      \"type\": \"User\",\n      \"site_admin\": true\n    },\n    \"labels\": [\n],\n\"state\": \"open\",\n\"locked\": false,\n\"assignee\": null,\n\"milestone\": null,\n\"comments\": 0,\n\"created_at\": \"2016-06-14T00:31:49Z\",\n\"updated_at\": \"2016-06-14T01:37:00Z\",\n\"closed_at\": null,\n\"pull_request\": {\n  \"url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/pulls\\/1377\",\n  \"html_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1377\",\n  \"diff_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1377.diff\",\n  \"patch_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1377.patch\"\n},\n\"body\": \"- [x] release notes\\r\\n- [x] version bump\\r\\n- [ ] integration tests all pass\\r\\n- [ ] :thumbsup: from @Haacked or @ryangribble \\r\\n- [ ] tag and publish to NuGet\\r\\n- [ ] :shipit:\"\n\n}\n}\n```\n- A mentioned event:\n``` json\n{\n  \"id\": 691197252,\n  \"url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/events\\/691197252\",\n  \"actor\": {\n    \"login\": \"ryangribble\",\n    \"id\": 5425163,\n    \"avatar_url\": \"https:\\/\\/avatars.githubusercontent.com\\/u\\/5425163?v=3\",\n    \"gravatar_id\": \"\",\n    \"url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\",\n    \"html_url\": \"https:\\/\\/github.com\\/ryangribble\",\n    \"followers_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/followers\",\n    \"following_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/following{\\/other_user}\",\n    \"gists_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/gists{\\/gist_id}\",\n    \"starred_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/starred{\\/owner}{\\/repo}\",\n    \"subscriptions_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/subscriptions\",\n    \"organizations_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/orgs\",\n    \"repos_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/repos\",\n    \"events_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/events{\\/privacy}\",\n    \"received_events_url\": \"https:\\/\\/api.github.com\\/users\\/ryangribble\\/received_events\",\n    \"type\": \"User\",\n    \"site_admin\": false\n  },\n  \"event\": \"mentioned\",\n  \"commit_id\": null,\n  \"commit_url\": null,\n  \"created_at\": \"2016-06-14T00:31:49Z\",\n  \"issue\": {\n    \"url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1377\",\n    \"repository_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\",\n    \"labels_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1377\\/labels{\\/name}\",\n    \"comments_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1377\\/comments\",\n    \"events_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1377\\/events\",\n    \"html_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1377\",\n    \"id\": 160073758,\n    \"number\": 1377,\n    \"title\": \"v0.20 - Probably Australian\",\n    \"user\": {\n      \"login\": \"shiftkey\",\n      \"id\": 359239,\n      \"avatar_url\": \"https:\\/\\/avatars.githubusercontent.com\\/u\\/359239?v=3\",\n      \"gravatar_id\": \"\",\n      \"url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\",\n      \"html_url\": \"https:\\/\\/github.com\\/shiftkey\",\n      \"followers_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/followers\",\n      \"following_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/following{\\/other_user}\",\n      \"gists_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/gists{\\/gist_id}\",\n      \"starred_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/starred{\\/owner}{\\/repo}\",\n      \"subscriptions_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/subscriptions\",\n      \"organizations_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/orgs\",\n      \"repos_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/repos\",\n      \"events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/events{\\/privacy}\",\n      \"received_events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/received_events\",\n      \"type\": \"User\",\n      \"site_admin\": true\n    },\n    \"labels\": [\n],\n\"state\": \"open\",\n\"locked\": false,\n\"assignee\": null,\n\"milestone\": null,\n\"comments\": 0,\n\"created_at\": \"2016-06-14T00:31:49Z\",\n\"updated_at\": \"2016-06-14T01:37:00Z\",\n\"closed_at\": null,\n\"pull_request\": {\n  \"url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/pulls\\/1377\",\n  \"html_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1377\",\n  \"diff_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1377.diff\",\n  \"patch_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1377.patch\"\n},\n\"body\": \"- [x] release notes\\r\\n- [x] version bump\\r\\n- [ ] integration tests all pass\\r\\n- [ ] :thumbsup: from @Haacked or @ryangribble \\r\\n- [ ] tag and publish to NuGet\\r\\n- [ ] :shipit:\"\n\n}\n}\n```\n- A head ref deleted (associated with a PR?):\n``` json\n{\n  \"id\": 691192852,\n  \"url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/events\\/691192852\",\n  \"actor\": {\n    \"login\": \"shiftkey\",\n    \"id\": 359239,\n    \"avatar_url\": \"https:\\/\\/avatars.githubusercontent.com\\/u\\/359239?v=3\",\n    \"gravatar_id\": \"\",\n    \"url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\",\n    \"html_url\": \"https:\\/\\/github.com\\/shiftkey\",\n    \"followers_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/followers\",\n    \"following_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/following{\\/other_user}\",\n    \"gists_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/gists{\\/gist_id}\",\n    \"starred_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/starred{\\/owner}{\\/repo}\",\n    \"subscriptions_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/subscriptions\",\n    \"organizations_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/orgs\",\n    \"repos_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/repos\",\n    \"events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/events{\\/privacy}\",\n    \"received_events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/received_events\",\n    \"type\": \"User\",\n    \"site_admin\": true\n  },\n  \"event\": \"head_ref_deleted\",\n  \"commit_id\": null,\n  \"commit_url\": null,\n  \"created_at\": \"2016-06-14T00:24:31Z\",\n  \"issue\": {\n    \"url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1376\",\n    \"repository_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\",\n    \"labels_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1376\\/labels{\\/name}\",\n    \"comments_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1376\\/comments\",\n    \"events_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1376\\/events\",\n    \"html_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1376\",\n    \"id\": 160071899,\n    \"number\": 1376,\n    \"title\": \"lock to an earlier version of mono\",\n    \"user\": {\n      \"login\": \"shiftkey\",\n      \"id\": 359239,\n      \"avatar_url\": \"https:\\/\\/avatars.githubusercontent.com\\/u\\/359239?v=3\",\n      \"gravatar_id\": \"\",\n      \"url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\",\n      \"html_url\": \"https:\\/\\/github.com\\/shiftkey\",\n      \"followers_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/followers\",\n      \"following_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/following{\\/other_user}\",\n      \"gists_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/gists{\\/gist_id}\",\n      \"starred_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/starred{\\/owner}{\\/repo}\",\n      \"subscriptions_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/subscriptions\",\n      \"organizations_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/orgs\",\n      \"repos_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/repos\",\n      \"events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/events{\\/privacy}\",\n      \"received_events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/received_events\",\n      \"type\": \"User\",\n      \"site_admin\": true\n    },\n    \"labels\": [\n],\n\"state\": \"closed\",\n\"locked\": false,\n\"assignee\": null,\n\"milestone\": null,\n\"comments\": 0,\n\"created_at\": \"2016-06-14T00:12:21Z\",\n\"updated_at\": \"2016-06-14T00:24:29Z\",\n\"closed_at\": \"2016-06-14T00:24:29Z\",\n\"pull_request\": {\n  \"url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/pulls\\/1376\",\n  \"html_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1376\",\n  \"diff_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1376.diff\",\n  \"patch_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1376.patch\"\n},\n\"body\": \"Travis is currently in an interesting spot where `latest` means it'll use Mono **4.4.0** when building and testing on OS X, and **4.2.3** when building and testing on Linux.\\r\\n\\r\\nUnfortunately this means the OS X builds are exhibiting some strange behaviour:\\r\\n\\r\\n - a [wall of Chinese text](https:\\/\\/twitter.com\\/shiftkey\\/status\\/742500043769274369) in the `BuildMono` step\\r\\n - `* Assertion at metadata.c:3643, condition 'ptr' not met` when running the PCL tests\\r\\n\\r\\nExample build output: https:\\/\\/travis-ci.org\\/octokit\\/octokit.net\\/jobs\\/137385011\\r\\n\\r\\nI found the flag to force a specific version of Mono for both platforms, and that seems to do the trick here.\\r\\n\\r\\n@dampir @ErikSchierboom @shaggygi @alfhenrik @maddin2016 I think you're all encountering this on your PRs, feel free to merge `master` or cherry-pick this commit into your branch after I confirm this resolves the issue.\"\n\n}\n}\n```\n- A PR has been closed (this one was merged):\n``` json\n{\n  \"id\": 691192839,\n  \"url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/events\\/691192839\",\n  \"actor\": {\n    \"login\": \"shiftkey\",\n    \"id\": 359239,\n    \"avatar_url\": \"https:\\/\\/avatars.githubusercontent.com\\/u\\/359239?v=3\",\n    \"gravatar_id\": \"\",\n    \"url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\",\n    \"html_url\": \"https:\\/\\/github.com\\/shiftkey\",\n    \"followers_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/followers\",\n    \"following_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/following{\\/other_user}\",\n    \"gists_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/gists{\\/gist_id}\",\n    \"starred_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/starred{\\/owner}{\\/repo}\",\n    \"subscriptions_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/subscriptions\",\n    \"organizations_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/orgs\",\n    \"repos_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/repos\",\n    \"events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/events{\\/privacy}\",\n    \"received_events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/received_events\",\n    \"type\": \"User\",\n    \"site_admin\": true\n  },\n  \"event\": \"closed\",\n  \"commit_id\": null,\n  \"commit_url\": null,\n  \"created_at\": \"2016-06-14T00:24:29Z\",\n  \"issue\": {\n    \"url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1376\",\n    \"repository_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\",\n    \"labels_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1376\\/labels{\\/name}\",\n    \"comments_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1376\\/comments\",\n    \"events_url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/issues\\/1376\\/events\",\n    \"html_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1376\",\n    \"id\": 160071899,\n    \"number\": 1376,\n    \"title\": \"lock to an earlier version of mono\",\n    \"user\": {\n      \"login\": \"shiftkey\",\n      \"id\": 359239,\n      \"avatar_url\": \"https:\\/\\/avatars.githubusercontent.com\\/u\\/359239?v=3\",\n      \"gravatar_id\": \"\",\n      \"url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\",\n      \"html_url\": \"https:\\/\\/github.com\\/shiftkey\",\n      \"followers_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/followers\",\n      \"following_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/following{\\/other_user}\",\n      \"gists_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/gists{\\/gist_id}\",\n      \"starred_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/starred{\\/owner}{\\/repo}\",\n      \"subscriptions_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/subscriptions\",\n      \"organizations_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/orgs\",\n      \"repos_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/repos\",\n      \"events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/events{\\/privacy}\",\n      \"received_events_url\": \"https:\\/\\/api.github.com\\/users\\/shiftkey\\/received_events\",\n      \"type\": \"User\",\n      \"site_admin\": true\n    },\n    \"labels\": [\n],\n\"state\": \"closed\",\n\"locked\": false,\n\"assignee\": null,\n\"milestone\": null,\n\"comments\": 0,\n\"created_at\": \"2016-06-14T00:12:21Z\",\n\"updated_at\": \"2016-06-14T00:24:29Z\",\n\"closed_at\": \"2016-06-14T00:24:29Z\",\n\"pull_request\": {\n  \"url\": \"https:\\/\\/api.github.com\\/repos\\/octokit\\/octokit.net\\/pulls\\/1376\",\n  \"html_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1376\",\n  \"diff_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1376.diff\",\n  \"patch_url\": \"https:\\/\\/github.com\\/octokit\\/octokit.net\\/pull\\/1376.patch\"\n},\n\"body\": \"Travis is currently in an interesting spot where `latest` means it'll use Mono **4.4.0** when building and testing on OS X, and **4.2.3** when building and testing on Linux.\\r\\n\\r\\nUnfortunately this means the OS X builds are exhibiting some strange behaviour:\\r\\n\\r\\n - a [wall of Chinese text](https:\\/\\/twitter.com\\/shiftkey\\/status\\/742500043769274369) in the `BuildMono` step\\r\\n - `* Assertion at metadata.c:3643, condition 'ptr' not met` when running the PCL tests\\r\\n\\r\\nExample build output: https:\\/\\/travis-ci.org\\/octokit\\/octokit.net\\/jobs\\/137385011\\r\\n\\r\\nI found the flag to force a specific version of Mono for both platforms, and that seems to do the trick here.\\r\\n\\r\\n@dampir @ErikSchierboom @shaggygi @alfhenrik @maddin2016 I think you're all encountering this on your PRs, feel free to merge `master` or cherry-pick this commit into your branch after I confirm this resolves the issue.\"\n\n}\n}\n``\n. I think we need to review and/or revamp this area of the code - there's lots of values here that don't seem to be deserializing correctly even after you hack around the missing field that triggers the crash, so perhaps we need to rethink how to go about this...\n. I've disabled the integration tests around this code in 0f90d20e3015d7e405160f9348544c7dd5ac16b0 - if someone wants to start digging into this, I'd look at getting those running again.\n. @alfhenrik both worked for me, but given History\u2122 I'd recommend usingapplication/vnd.github.cryptographer-preview` here.\nI'll speak to the team to confirm this is right and get the docs addressed.\n. @Andychochocho sounds good!\n. @radu-matei @caseycraig when it comes to deprecating properties and types we should follow this pattern:\n- mark the existing property or type as [Obsolete] so that it's easier to find all references\n- add in a new property or type with the correct name\n- update all usages internally to point to the new method \n- add a comment to the [Obsolete] to indicate what needs to be done (i.e. use the new property)\nThis means we don't break existing consumers when they update, and we indicate what needs to be done to migrate...\n. @mderriey sounds good!\n. Could you add a comment to #1115 about migrating that package, and any other details about why this package is considered obsolete? We've been talking about .NET Core support for a while, and that bit of information sounds useful to us...\n. I believe this is just a typo - note the d that's included on the C# property: \n\ndoes not contain a property for the \"merge_base_commit\" field. The closest it has is \"MergedBaseCommit\", however it always returns \"null\".\n\nWith Octokit we map properties using conventions, which would explain what happened (or didn't happen) here.\nWe have a bunch of tests around compare in RepositoryCommitsClientTests.cs but I can't see us verifying this property explicitly...\n. @kivancmuslu I can help to co-ordinate a hotfix release (currently there's a lot of new features on master) if someone is interested in tidying this up in a PR:\n- add the new property\n- mark the old one as obsolete\n- add a test to verify this behaviour\n. @kivancmuslu \n\nJust a quick question: when the typo is fixed, does parsing (and the correct value filling in) happen automatically or do I need to update the parse logic as well?\n\nNo need to worry about changing the parsing logic - for reference it's this component that does the deserializing and this is the magic rule for mapping properties from C# to JSON\n. @SamTheDev excellent, thanks!\n. > This is out of the scope of this PR. Should i add them in here anyway ?\nThis is fine. I'm happy with this PR as-is so I'm going to take this in right now. Thanks!\n. @SamTheDev your needed GetAndFlattenAllPages changes seems like it'll overlap with what's been done in #1247 (in particular https://github.com/octokit/octokit.net/pull/1247#discussion_r58698529). \nWe're close to getting that sorted, so if you can hold off on that until we merge you should be able to pull in those changes...\n. @SamTheDev this is getting close - the namespace changes are the only real blocker, but those new test helpers are an interesting question... \n. @SamTheDev not really, but rather than using reflection I'd recommend switching our usages over to nameof(arg) from C# 6. We migrated to VS2015 a while ago, and now that things have settled down I think we can hit the switch on using features like that...\n. @SamTheDev you need to do it up a level, e.g.\ncsharp\nEnsure.ArgumentNotNullOrEmptyString(id, nameof(id));\n. @SamTheDev correct\n. @M-Zuber \n\nWhat about extension methods? \n\nExtension methods are just syntactic sugar on top of regular methods, so I'm not sure how they'd get around the same problems as mentioned above. However I'd love to be proven wrong if it helps make things more readable...\n. @SamTheDev aside from the merge conflict, I think this is good to go!\n. @SamTheDev @M-Zuber feel free to move this discussion about Ensure out to a fresh issue, if you want to explore it further...\n. @SamTheDev looks like a new convention test is in your way:\nOctokit.Tests.Conventions.MissingClientConstructorTestMethodException : Constructor test method is missing GistsClientTests.\nSee #1246 for more information\n. > In the test, I specifically compared a commit with itself since the test only\n\ncares whether the property is filled correctly or not, it is not testing whether\nthe internal computation is correct or not.\n\n:thumbsup: nice work!\n. @kivancmuslu thanks for submitting this! I literally have no feedback to give aside from this:\n\n. :shipit:\n. @ryangribble apologies again for the delay on this - the approach seems fine, added a few comments\nDigging into the original PR comment:\nAPI Uri's\nI'm fine with isolating that rewriting behaviour as near to the Management Console functionality as possible. We might have a better idea for handling it down the track.\nAuthenticating\nAlso fine. Just something we need to live with, it seems.\n\nThe irksome thing is that the password is essentiall in clear text on the end of the Url but im not sure if that's really any different to it being in the HTTP headers for regular calls anyway...\n\nIf you're using HTTPS and everything is setup correctly on the server, after the initial handshake between server and client the contents of requests (whether it's the request line or the Authorization header) are considered encrypted.\nWhat the heck is up with parameters containing json strings?!!\nGosh that's some beautiful API design :trollface:\n\nIf anyone is able to show me how to get this working in a more \"normal\" way for octokit where the request object is serialized using the builtin SimpleJsonSerializer in the normal pipeline, I would love to see what I missed bercause I feel like I tried so many attempts and still couldnt crack it without going the form encoded route.\n\nPretty much all of Octokit's serialization has been built off the assumption you're serializing an object to the request body. This is outside that sandbox, so I think we're stuck for now. If SimpleJson is all you need, perhaps we could make the serializer a first class feature on the client, so the code might look like this:\n``` csharp\npublic Task EditMaintenanceMode(UpdateMaintenanceRequest maintenance, string managementConsolePassword)\n{\n    // guard clauses and other setup\nvar payload = \"maintenance=\" + this.Serializer.Serialize(maintenance);\n\nreturn ApiConnection.Post<MaintenanceModeResponse>(endpoint,  payload);\n\n}\n```\nI'd need to think about what that might break in terms of testability by baking it into ApiClient, and what other scenarios this would help us cover. Also, are there more scenarios where the JSON sent needs to be wildly flexible beyond our simple serializer attributes? Perhaps this won't be worth investing in...\nWhat the heck is up with the time handling?!!\nI'll just leave this here:\n\nOkay, now to actually be constructive.\n- When sending a value as part of the request, it sounds like we should be able to send an ISO 8601 string, right?\n- When receiving a value as part of the response, why bother being clever with the parsing? Just serve it up as a string, if the API is going to try and be clever with what it presents.\nI've ask the team about this API and whether others have felt the same pain.\nSpecifying \"when\" parameter in EditMaintenanceMode()\nThese all seem fair. I'd perhaps drop FromChronicString in case it does get obsoleted, but that's a minor feel.\nMaintenanceModeStatus as an enum\nAdded environment var for management console password for integration tests\n:thumbsup: to both\n. @M-Zuber I think this is a good thing to do, but I'll leave it up to someone who is brave enough (and knows enough reflection) to dive into this and make it work broadly (think methods versus properties and interfaces versus all implementations available).\n. The error message itself suggests something is interfering with the TLS handshaking that your computer and api.github.com. This often occurs when the client isn't able to validate the certificate it gets from the server. If you have a look at the stack trace for that error it'll likely be deep inside the bowels of System.Net.Http stack - way beyond anything that Octokit can control.\nMy gut feeling is that this is still certificate related - browsers will often look at their own certificate store (sup Firefox) rather than defer to what is installed with the OS (which is what .NET does).\n\ud83c\udf35 \ud83c\udf35 \ud83c\udf35 WARNING: DANGER ZONE \ud83c\udf35 \ud83c\udf35 \ud83c\udf35 \nWhat I'd like you to do is tweak the main part of the program to do this:\n``` csharp\nusing Octokit;\nusing System;\nusing System.Threading.Tasks;\n// add these usings\nusing System.Net;\nusing System.Net.Security;\nusing System.Security.Cryptography.X509Certificates;\n... \nstatic void Main(string[] args)\n{\n    // add this event handler\n    ServicePointManager.ServerCertificateValidationCallback += new RemoteCertificateValidationCallback(AlwaysGoodCertificate);\nTask task = Do();\ntask.Wait();\nConsole.ReadKey();\n\n}\n// add this callback\nstatic bool AlwaysGoodCertificate(object sender, X509Certificate certificate, X509Chain chain, SslPolicyErrors policyErrors)\n{\n    // add a breakpoint here, this will tell you what the error is\n    var errors = policyErrors;\nreturn true;\n\n}\n```\nYou can then view at the certificates that were received as part of the handshaking and see what the error is that you're receiving. But do not keep this code around once you find the problem - you should fix it and then cleanup this code, as bypassing SSL/TLS handshaking is crazy dangerous in general.\n. > I get an exception before this line is executed.\nIt's hard to say without more information what's happening here. \n\nAccessing GitHub API via browser works OK.\n\nWhich browser?\n. @dampir this is great, and I'll queue up some unrelated test tweaks that I found while reviewing for when it's time to ship! Thanks!\n. @ryangribble thanks for the :eyes:, I think there's a bunch of new test coverage here I can do but given how many overloads there are I'm trying to keep this as focused as possible.\n. I also took some time out in 1b2d009e3a33b966fa78e0b3b8883a7863797bd6 to document the return values from the API. Let me know if you have any feedback on the words.\n. Lots of the pagination endpoints here require you to have org access, so rather than getting too bogged down in pagination I'm going to skip those tests.\n. Can I get a :thumbsup: here before I close this out?\n. @drasticactions no problem, it's what the tests are there for!\n. release_notes:\nBreaking Change: IEventsClient.GetAllForRepository was incorrectly retrieving issue events before this release. Use the new IEventsClient.GetAllIssuesForRepository method if you still require issues, or continue to use IEventsClient.GetAllForRepository if you require all repository events...\n. @drasticactions thanks for the contribution!\n. And as it's your first contribution to Octokit, we should celebrate!\n\n. @radu-matei thanks for checking!\n. @dampir a couple of unnecessary introduced changes, but aside from that this looks good. :heart: seeing the inlined URLs being extracted!\n. @dampir apologies for the delay!\n. Tests look good, just that one typo and this is good to go.\n. I'm not sure how we can optimize this \"all files and then all commits\" scenario but there's a few optimizations I can think of. Apologies if this doesn't compile, I'm writing it from scratch.\nFirst, you can grab all the files which exist on a given branch like this:\ncsharp\nvar tipCommit = await client.Repository.Commit.Get(Owner, Name, \"master\");\nvar allPaths = tipCommit.Files.Select(f => f.Filename);\nThen, you can query for all commits associated with a given file:\n``` csharp\nvar stats = new Dictionary();\nforeach (var path in allPaths)\n{\n    var request = new CommitRequest { Path = \"path/to/file.cs\" };\n    var commitsForFile = await client.Repository.Commit.GetAll(Owner, Name, request);\n    stats.Add(path, commitsForFile.Length);\n}\n```\nIt's still time-consuming, but now the number of requests necessary is (1 + file count) instead of (1 + commit count).\n. Oh yes, silly me - the tip commit doesn't reflect the whole tree, just the files changed in that commit!\nI'm glad the rest helped though!\n. \n. @ja1984 I'd love to see this land with some preview support. As it looks like the reactions model are the same shape whether it is for issues, issue comments, pull requests or review comments we can roll this out gradually. The first PR can add the model, set the preview header and add some tests - and the others can follow.\nI've renamed this task to focus on issue comments, and I'll open tasks for the other areas.\n. @lrz-hal that's fine, thanks for the heads up!\n. @ryangribble I'm not locked into the approach that I've chosen, so I can be talked off this ledge.\nThere's a couple of places in the API documentation where the structure doesn't reflect the underlying resources (for example, Pull Requests) and this one I'm pushing back on for a couple of reasons:\n- it's new code and also a preview API\n- the new endpoints build on existing resources\n- for context, having these alongside existing clients might make more sense than bundling them all together\nI can see from the documentation side how it's easier to group these new methods together, however it didn't feel natural to me when I was comparing it to how things are currently structured.\nThoughts?\n. @maddin2016 I've grouped up all the open issues under the reactions label:\nhttps://github.com/octokit/octokit.net/issues?q=is%3Aissue+is%3Aopen+label%3Areactions\n. :thumbsup: to bringing it all under the root Reaction class. I'll go through and clarify those issues now.\n. @ryangribble can I get a :thumbsup: here before I merge this in?\n. @ryangribble it's because anything related to Pages requires the account to be an administrator of the repository: https://github.com/octokit/octokit.net/issues/1263\n. @ryangribble good point. I'll add the test so we don't forget it and then close this out...\n. @dampir \ud83d\udc4d \n. @dampir can you try defining the test as public async Task to see if that addresses it at all?\n. > I've fixed errors in tests, accidentally I've used Args.ApiOptions instead of ApiOptions.None and it gives strange result: in parallel tests falls, but in single thread they executed successfully. \nSo I don't know the full answer here for the runtime quirks when running tests but I can at least recommend we don't use Args.ApiOptions (the wrapper around NSubstitute's assert helper Arg.Any<ApiOption>()) unless you're asserting, instead of ApiOptions.None (which is the Octokit model).\nNot sure if we need to do anything else here, but something to be mindful of...\n. Changes look good on my end. I'll let @ryangribble chime in, otherwise I'll merge it after my talk is done tomorrow.\nThanks @dampir!\n. @joe307bad when you mean details, what exactly are you looking to get out of the API? \nAlso, a similar question was asked in https://github.com/octokit/octokit.net/issues/1293 and we walk through some options there...\n. > I came up with this question when I noticed the GitHubCommit.Stats property was null when accessing directly from the results of Commit.GetAll.\nYeah, unfortunately the response for GetAll doesn't have the stats or files changed in a commit - here's the example payload.\nIf you're aggregating the stats for a range of commits, what about if you were to compare two commits, like this?\n```\nvar commits = await client.Repository.Commit.GetAll(\"joe307bad\", \"portfolio_wp\");\nvar first = commits.First();\nvar last = commits.Last();\nvar result = await client.Repository.Commit.Compare(\"joe307bad\", \"portfolio_wp\", last.Sha, first.Sha);\nvar files = result.Files;\nvar totalAdded = files.Sum(f => f.Additions);\nvar totalDeleted = files.Sum(f => f.Deletions);\n```\nThis isn't as granular as checking each commit, but might work for your scenario...\n. @joe307bad the short version of the long story is that GetAll becomes expensive to execute when you have to dig into the underlying tree/s and blobs and work out the changes between it and the parent commit, for each commit in the range of history.\nClosing this out for now. Best of luck!\n. Not sure I understand the problem completely, but here's a quick brain dump:\n- the commits in a PR cannot be changed while under review - to change existing commits you need to rewrite the branch directly and push, which will then sync the PR on GitHub\n- when the PR is synced (aka updated) you could verify the commit messages for the commits to be merged, and then set a failed commit status for the tip of the branch - see these docs\n- you could programmatically merge a PR and specify the commit title/description - see these docs\n- there is a pull_request webhook event named closed that you can use to know when the PR was merged (it'll have a property merged=true set). But this even occurs after the merge.\n. Unfortunately that sort of web hook (enforce merge commit message) isn't available currently. I'm not sure of alternatives aside from what you've mentioned above... \n. @ryangribble I like that idea. Some people might not, but if you're looking for process then it's the easiest way to lock it down...\n. Closing this out as I think we've covered a bunch of alternatives to the proposed requirements.\n. Let's not worry about this one - because of the nuance of serving up a directory versus serving up a file, I don't expect pagination to be added here anytime soon.\n. Looking at the docs for Get Contents, you have these headers returned:\n\n\nApologies @dampir - I really don't think it's worth implementing this, and I should have caught it when opening the original issue... \n. @dampir I'm happy to leave it open.\n. Gonna merge this in and we can come back to that open question about running the tests cc @ryangribble \n. @maddin2016 yeah, I don't see the point in duplicating all the types here where they're structurally the same...\n. Closing this out in favour of #1335 which is going for the standalone client approach.\n. Seconding what @ryangribble said - it's not something Octokit or the GitHub API supports.\n. This all seems reasonable. I'm in transit today (again) but I'll give it a closer look tomorrow when I'm jetlagged.\n. Fantastic stuff @dampir! Thanks!\n. > So what we are going to do here?\nFor the sake of simplicity, let's open a separate issue to talk about the integration tests and what we should do there (your notes seem accurate) and focus on the API changes in this PR.\n. This looks good, just that merge conflict to sort out...\n. @adamralph you are correct in that support isn't there.\nI haven't had a chance to review all the areas where it's needed (I'm trying to wrap up the pagination release right now) but I'd love to see this happen.\ncc @shana @paladique - we were discussing this just after it was made public.\n. @adamralph I'll defer to @shana and @paladique to talk about their urgency for this being implemented, my focus is currently on other things at the moment... \n. @adamralph we're usually keen to get preview support into the APIs (we've not been burned by this yet) so expect it before GitHub drops the preview support and makes it part of the official API...\n. > Which has a nicer feel to everybody?\nA\n. @maddin2016 it looks like some of the new tests are failing on CI - are you able to have a look at them and run them locally? It should be debuggable from the VS Test Explorer.\n. @maddin2016 the ID you're using in the test (42) doesn't match with the ID in the expected URL (1)\n. @maddin2016 this is getting close! We just have a couple of convention tests failing as some classes are missing a constructor test:\n\nOctokit.Tests.Conventions.MissingClientConstructorTestClassException : Constructor test class is missing Octokit.Tests.Reactive.ObservableCommitCommentReactionClientTests.\n...\nOctokit.Tests.Conventions.MissingClientConstructorTestClassException : Constructor test class is missing Octokit.Tests.Reactive.ObservablePullRequestReviewCommentReactionsClientTests.\n\nEach of these classes should have an inner test class to ensure the constructor is being tested:\ncsharp\npublic class ObservableCommitCommentReactionClientTests\n{\n    public class TheCtor\n    {\n        [Fact]\n        public void EnsuresNonNullArguments()\n        {\n            // TODO: test here\n        }\n    }\n   // ...\n. @maddin2016 there's also a couple of missing test classes for the new observable clients:\n- ObservableReactionsClientTests.cs\n- ObservableIssueReactionsClientTests.cs\n- ObservableIssueCommentReactionsClientTests.cs\n. @maddin2016 if you run this command from the root of the repository it should synchronize the files to the necessary csproj files:\n\n.\\build FixProjects\n. @maddin2016 @ryangribble I'm really not sure what xbuild is getting confused at here. I'll test it out on one of my VMs and see if I can understand it...\n. @maddin2016 I've opened a PR to get this build fix into your branch https://github.com/maddin2016/octokit.net/pull/1\n\nI think there's some other things around files that we'll need to get back to, but for now this should get us back to CI green...\n. @maddin2016 yes, there's a minor issue right now:\n\n. @maddin2016 @dampir this most recent one was due to a lovely little error inside glibc:\n*** glibc detected *** /usr/bin/mono: double free or corruption (out): 0x00007f27ec2fd6c0 ***\n. @ryangribble not sure, gonna look into it today now I have some bandwidth\n. @ryangribble I can see a bunch of failures with the common thread being the use of Mono 4.4.0 - which came out a couple of weeks ago.\nLooking into whether I can choose a specific version and verify this is a regression...\n. I'm pretty sure https://github.com/octokit/octokit.net/pull/1376 is The ~~Hero~~ Fix We Need Right Now\u2122 \n. @dampir this looks good, add in that new integration test and this is good to :ship:\n. Alright, ready for review finally...\n. I'd like to run through the integration tests today and get this stuff ready for release. Are we cool with merging this?\n. @dsplaisted thanks for adding in the new test. This will go out with a release early next week! :metal:\n. @maddin2016 I'm going to hold off on reviewing this until we get #1335 merged in.\nAlso cc @paladique\n. @maddin2016 this is looking really good. I focused on the integration tests just now as I plan to go on a bender cleaning them up and getting them working better/quicker, but I'll give the rest a pass tomorrow.\n. I still need to come back and ponder on the changes to serialization here. Apologies for the delay.\nOh, and there's a merge conflict here too @maddin2016 \ud83d\ude22 \n. Just waiting on this to go green, everything else is :gem:\n. Fantastic stuff @alfhenrik!\n\n. @dampir this is looking really good - just a few pointers on the documentation while we're in here updating things. I think once we settle on the reviews for the first couple of these PRs that it should really fly through!\n. \ud83d\udc4d to the additional integration tests here\n. :thumbsup: to the additional integration tests here\nJust that last bit of docs changes and this is good to go!\n. @dampir ugh, merge conflicts :cry:\n. @ryangribble @dampir I'm happy to go through and clean those tests up independent of this work\n. @dampir are you able to rebase this branch? There's a lot of changes in here which seem unrelated to the initial PR, and make reviewing much more tedious...\n. :thumbsup: to the added integration tests\n. :thumbsup: to the new integration tests, even they're all still skipped...\n. @dampir there seem to be some failing tests in here, not sure if that's on your radar...\n. Tests look good. Just some guard clauses that was previously overlooked and :fire: the <returns> tags and this is good to go!\n. > What do you think? Should I add null checks?\nI think we should be consistent here with how we accept nulls. We've been favouring throwing when someone passes a null for the request arguments, so I think we should do the same here.\n. Just :fire: the <returns> tests here and I think this is good to merge...\n. Just :fire: the <returns> tests here and I think this is good to merge...\n. Tests look good, just some wording to clean up in the docs and removing the empty <return></returns> elements...\n. Just :fire: the <returns> tests here and I think this is good to merge...\n. Just :fire: the <returns> tests here and I think this is good to merge...\n. @shaggygi it'd be nice to add an integration test to MilestonesClientTests to verify these new properties are deserialized correctly, but aside from that this is looking good!\n. @shaggygi lots of the existing tests are written in the \"arrange-act-assert\" pattern, so feel free to steal from them if you're looking for guidance...\n. Merge conflict aside, just :fire: the <returns> tests here and I think this is good to merge...\n. Tests are good. Just some tweaks to the documentation and this is good to :ship:\n. Tests and code look good. Let's just :fire: the <returns> statements in here.\n. Code and tests look good. Just gotta :fire: the <return> statements.\n. Tests are good. I'm just wrestling with the code comments (again).\n. I've opened #1409 to do the naming changes in the future - I'm sure I've merged a PR with this change already, so let's come back after.\n. @dampir do you have a example of the failing test? I came across this a while ago, and I thought I wrote up an issue but perhaps I didn't...\n. Ah, I did: #1251\n. Closing this one in favour of #1251 - I'll add some notes in there about what I've found recently...\n. Pending any feedback on the words from @Haacked or @ryangribble this is good to go.\nAiming to do it early Wedneday AEST so I have the day to monitor it in case something unexpected occurs...\n. @Haacked @ryangribble thanks for the feedback, I'll incorporate that once I'm done with breakfast.\n. @ryangribble I'll do another pass over the PRs merged to see if I can find other notable [Obsolete] changes - I think #1224 is relevant here\n. :ship:ed\n- https://www.nuget.org/packages/Octokit/0.20.0\n- https://www.nuget.org/packages/Octokit.Reactive/0.20.0\n. This one also needs to :fire: the <return> statements...\n. Tests look good, just need to :fire: the <returns> tags here\n. This HTTP request seems to work for me:\n```\n\ncurl https://api.github.com/search/code\\?q\\=filename:project.json+repo:brandonlw/Psychson\n{\n  \"total_count\": 0,\n  \"incomplete_results\": false,\n  \"items\": [\n\n]\n}\n```\nWhich corresponds to this code with Octokit v0.20:\n``` csharp\nvar request = new SearchCodeRequest\n{\n    FileName = \"project.json\",\n    Repos = new RepositoryCollection\n    {\n        \"brandonlw/Psychson\"\n    }\n};\nvar results = await client.Search.SearchCode(request);\nvar count = results.TotalCount;\n```\nBut both of these queries don't return results, which seems to be the same as the web result mentioned above. Swapping in dotnet/corefx for the repository entry then returns 571 results.\nNot sure what I'm missing here @dsplaisted, let me know if I've missed something...\n. Yep, I see the same failure now.\n```\n\ncurl https://api.github.com/search/code\\?q\\=filename:project.json+repo:adamcaudill/Psychson\n{\n  \"message\": \"Validation Failed\",\n  \"errors\": [\n    {\n      \"message\": \"The listed users and repositories cannot be searched either because the resources do not exist or you do not have permission to view them.\",\n      \"resource\": \"Search\",\n      \"field\": \"q\",\n      \"code\": \"invalid\"\n    }\n  ],\n  \"documentation_url\": \"https://developer.github.com/v3/search/\"\n}\n```\nIs there a way via the API to check if the user (or repo) ID has been changed?\n\nOctokit.net follows these redirects directly - but the search endpoints doesn't give us that context. If you hit the endpoint you should receive a 301 with a response like this:\n```\n\ncurl https://api.github.com/repos/adamcaudill/Psychson\n{\n  \"message\": \"Moved Permanently\",\n  \"url\": \"https://api.github.com/repositories/24504893\",\n  \"documentation_url\": \"https://developer.github.com/v3/#http-redirects\"\n}\n```\n\nAnd then a GET gives you the new repository name:\n```\n\ncurl https://api.github.com/repositories/24504893\n{\n  \"id\": 24504893,\n  \"name\": \"Psychson\",\n  \"full_name\": \"brandonlw/Psychson\",\n  \"owner\": {\n    ...\n  },\n  ...\n}\n```\n. Closing this out as a limitation with the search endpoint (and not something we can fix in the client).\n\nOn the upside, it's been acknowledged\n. Tests are good. Just need to remove the empty <returns></returns> elements.\n. Tests are good. Just need to remove the empty <returns></returns> elements.\n. No tests to worry about here. Just need to remove the empty <returns></returns> elements.\n. @ryangribble excellent point! I left that note in here to just indicate whether I'd looked at the tests as part of reviewing. Perhaps @dampir has found something which means those tests aren't possible?\n. Tests are good. Just need to remove the empty <returns></returns> elements.\n. Tests are good. Just need to remove the empty <returns></returns> elements.\n. Tests are good. Just need to remove the empty <returns></returns> elements.\n. > What's the reason for using RedirectHandler instead of using the built-in redirection handling?\nFrom MSDN:\n\nThe Authorization header is cleared on auto-redirects and HttpWebRequest automatically tries to re-authenticate to the redirected location. \n\nBecause of how the GitHub API hides private resources and returns a 404 Not Found, we need to be a bit clever here and set the Authorization header explicitly.\n. For reference, here's the source for HttpClient.CancelPendingRequests() - looks like it's just cleaning up a cancellation token.\n. @maddin2016 thanks for digging into this! I've made a note to look at that PR when I get a spare moment...\n. @Sarmad93 looking good, just a few little things to clean up. Love that integration test \ud83d\ude0d \n. @Sarmad93 @ryangribble thanks for waiting for me. Just that one comment and I think this is good to go!\n. @Sarmad93 looks good, thanks for this!\n\n. @maddin2016 it'd be much easier to investigate the behaviour when the code is handy - let's look into that after opening the PR...\n. #1398 has been merged\n. Seconding what @ryangribble said - this is a limitation of the server-side, and unfortunately due to us sharing models this is giving consumers false hope that it should be available...\n. @ryangribble that's what i'm leaning towards, but I need to think more on how we can make this maintainable because it could be a lot of work to migrate and keep in sync...\n. Code looks good, a couple of questions:\n- do we want to make this available under GitHubClient?\n- is it worth writing up some docs around this? Even just a quick sample?\n. > unit tests are failing after merge. should i rollback?\nIt looks like some upstream changes needed to have the preview API applied - this is the commit which fixes it for me, feel free to cherry-pick it in:\nhttps://github.com/shiftkey/octokit.net/commit/7e94dbcb8beaed625c8bd1e78269fd8cc0ffdf92\nLooking at the integration tests now to confirm this is all that's needed...\n. I'm seeing a few integration tests fail with this exception:\n- Octokit.ForbiddenException : Insufficient scopes for reacting to this Issue.\nExamples:\n- IssuesClientTests.CanDeserializeIssue\n- PullRequestReviewCommentReactionsClientTests.CanCreateReaction\nNot sure whether this is related to my setup or something I need to investigate further.\n. @dsplaisted :thumbsup: to relaxing the regex to include _- I did a quick test of other special characters and the only one I could find permitted is a -\n. > > Maybe someone third should test it.\n\nYep probably a good idea\n\n:eyes:\n. \n. Just throwing myself on as a reminder to sit down and properly understand this change \ud83e\udd18\n. @maddin2016 have you had a chance to look at those failing tests?\n. @maddin2016 I'll look at those failing tests and see if I can help\n. > One thing I would like to comment is that we now have two public send methods in HttpClientAdapter. Both are asynchronous but one is called Send and the other SendAsync. Is this ok?\nThis is fine. I'd rather not break this API now, and come back to it when we want to let people provide their own HttpClient implementation.\n. @maddin2016 i like where this is heading, and I think this is close to merging in.\nI'd like to push this out as a release on it's own so we can verify it in isolation from other features being rolled out :metal:\n. @ryangribble I'm okay with locking that down if it means resolving this redirect issue - it was supposed to be a black box and I'm not really hearing anyone reimplement our IHttpClient without significant pain - and they'll likely be not using this stuff anyway.\nIf someone comes up with a good use case for needing to poke the request content after we lock this down, then I'm all ears...\n. @maddin2016 yep, those comments are fine. Just a couple of tweaks I think to get this ready to merge.\n. Thanks for wrapping this up while I was off sick last week.\n\n. @tebeco there's documentation about enabling source debugging for Octokit here: http://octokitnet.readthedocs.io/en/latest/debugging-source/\nThis will mean you don't need to worry about referencing the source.\n\nOctokit is not compliant with ConsoleApp if consoleApp is buit with 4.6.1\nIt seems to crash a \"MethodNotAllowed\" exception if i'm targetting 4.5\n\nCould you confirm which version is the problem?\n. > wich version of what ?\nWhich version of the .NET Framework you are targeting - are you saying that both .NET 4.5 and 4.6.1 are affected?\nThese are the steps that I used in Visual Studio 2015 Update 3 to see if I can understand the issue as you see it:\n- create a new console application targeting .NET 4.6.1\n- In NuGet Package Console, run this command: Install-Package Octokit\n- replace the contents of Program with this:\n``` csharp\nclass Program\n{\n    static void Main(string[] args)\n    {\n        Run().Wait();\n    }\nprivate static async Task Run()\n{\n    var client = new GitHubClient(\n        new ProductHeaderValue(\"Octokit.samples\"), new Uri(\"https://corp.github.pouet/\"));\n\n    var reponame = \"testing-repo-creation-\" + Environment.TickCount;\n    client.Credentials = new Credentials(\"a12345bcd\"); // populate the whole token here\n\n    var newRepo = new NewRepository(reponame)\n    {\n        AutoInit = true\n    };\n\n    var repository = await client.Repository.Create(newRepo);\n} // set a breakpoint here\n\n}\n``\n- set a breakpoint inside the closing bracket of theRun()method\n-F5` to run the console app \nI tested this code against a recent version of GitHub Enterprise and didn't encounter an issue. Could you confirm that these steps work for you?\n\nNo tricks, then it will crash\nMy guess is that the framework 4.6.1 changed BCL for the stack octokit uses (from 4.5)\n\nI couldn't find anything using the above repro steps, so I need more information to help troubleshoot further. Given you're not able to catch any sort of exceptions, I fear something isn't right with your installation of VS (or .NET).\nWhat about if you had a console app that was just this? Does that also let you handle the error within the debugger?\ncsharp\nclass Program\n{\n    static void Main(string[] args)\n    {\n        throw new NotImplementedException();\n    }\n}\n. > I strongly recommend the move to .net 461 to avoid this kind of behavior since there's been lots of changes in the BCL around httpClient & so on\nThanks for the suggestion, but I'm very hesitant to drop this compatibility as I have an application that's been using Octokit targeting .NET 4.5 for 2+ years and I've not had any users encounter this issue.\n\n... not always I really don't get it it's like there's a cache but when I got the exception, I play with the user agent and it seems to works again. Like there's a 50/50 chance\n\nThis is interesting, and not something I've seen before. Do you have a stack trace that illustrates the error when this occurs?\n. I'm going to close this out as I'm not sure what the next steps are to resolve this.\n. A++ WOULD REVIEW AGAIN\n. A couple of questions I have:\n- Are you capturing the rate limiting information when you encounter this error? I'd love to confirm that is reflecting reality so that clients know when they are able to reconnect to the resource.\nHere's a quick snippet:\ncsharp\nvar github = new GitHubClient(...);\n...\nvar rateLimit = github.GetLastApiInfo().RateLimit;\n- are there other resources you're encountering this on, or is it only Issue Events for Repository?\n. @ryangribble here you go #1440 \n. As a first step, if someone wants to have a look at getting a simple .NET Core project (name it Octokit.Next or whatever) building on Appveyor within our existing build scripts. That should open us up to scaling this out so more people can help out.\nI've even got a branch started a while ago which ports one of the projects with a project.json that was working locally.\n. @mderriey it was mostly me experimenting at the time with the API surface required to target each netstandard flavour, but I was also following what we did with Rx.NET.\nAnd of course I'll defer to the documentation around the .NET Platform Standard on this.\n. @strich we have an Octokit.Next project and tests building in CI. If someone wants to start building against the Octokit source and targeting new platforms they're more than welcome to dive in.\nI'd recommend using the include options in buildOptions, rather than copying the same source into the new folder.\ne.g:\njs\n...\n\"buildOptions\": {\n  \"compile\": {\n    \"include\": [\n      \"../Octokit/*.cs\"\n    ]\n  }\n}\n...\n. @strich Appveyor and Travis are already setup to build and run tests for this Octokit.Next project - you can see this in action here. Aside for the requirements for .NET Core you shouldn't need anything else.\nI also started a branch a while ago to see what sort of source changes were necessary, but that was before we started the Octokit.Next stuff so I'd use that only for reference...\n. @strich the project is relatively vanilla because MSBuild does weird things when you mix csproj and xproj/project.json in the same directory. I also wanted to transition things gradually, without interfering with people who wanted to contribute new features and fixes and might not have the latest tools installed.\n. @ghuntley the use of [Serializable] was more of a correctness thing than anything core to Octokit's behaviour, so don't let that get in the way of anything serious. I think the most interesting dependency is System.Net.Http so I think that sets a floor of netstandard1.1 for which version to target.\nI think this would affect existing users of Profile259 (from memory that's closer to netstandard1.0) but I'm okay with deprecating that.\nAnd yes, I'm :thumbsup: on borrowing your work on the pipeline stuff. I hope @ryangribble is already all over that :grin:\nI'm also :thumbsup: to bumping to System.Reactive as part of this work - that's probably a good point to semver up to 1.x finally.. @mderriey @ryangribble @DamianEdwards the state of the tooling has been an issue for me, and was one of the reasons I deferring the porting work. Ideally I'd love for this stuff to \"just work\" for new contributors who stumble upon this, and having to be on bleeding-edge stuff isn't something that everyone is keen to do. \n\nAre you moving straight to the new CSPROJ project format as you go (meaning you'll need >=VS2017 RC or latest dotnet CLI builds)?\n\nPersonally, requiring VS2017 when it's still RC doesn't feel great. I know the benefits are there from the tooling side to skip project.json completely, the only concern I have is about how opening these projects in an incompatible version of VS works currently - probably something I can test myself. \nI'm not really actively working on .NET stuff these days, aside from supporting existing projects and helping them with porting wherever I can, so I'm going to defer to the others in this thread - especially @mderriey who has been championing this work - about whether they want to move up to VS2017 sooner.\nIf the infrastructure is there to support the new csproj changes (and it sounds like Appveyor is close to supporting VS2017 bits), then we can make it clearer to end users to go and grab VS2017 Community if they want to get involved.\n\nAlso, please note you should drop your reference to Microsoft.Net.Http and instead just depend on NETStandard.Library which brings in System.Net.Http. \n\nGreat to hear :sparkles:\n. @mderriey it's the github-windows account on Appveyor, and if it's something available through the admin panel I can set that for you directly.... @ryangribble we can close this out, right?. @Sarmad93 looks good to me!\n\n. \n. \n. \n. @shaggygi you would have to repopulate the issues in the new repository after forking\n. @shaggygi unfortunately there isn't a method to do this all in one API call\n. @shaggygi I'm not aware of a way through the GitHub API to script forking repositories. However, if you've already created the repository you can rename it through the API.\nThis snippet from @M-Zuber is an example of doing the rename:\n``` csharp\nprivate static async Task Rename()\n{\n  var apiClient = new GitHubClient(new Octokit.ProductHeaderValue(\"Issue-Managment\")) / Put credentials here /;\n  var repoName = $\"test-{DateTime.UtcNow.ToBinary()}\";\n  var repo = await apiClient.Repository.Create(new NewRepository(repoName));\n  Console.WriteLine($\"Created repo {repo.Name} under {repo.Owner.Login}\");\nrepo = await apiClient.Repository.Edit(repo.Owner.Login, repo.Name, new RepositoryUpdate { Name = $\"{repo.Name} ll {repo.Name}\" });\n  Console.WriteLine($\"Repo renamed to {repo.Name}\");\n}\n``\n. Similar to #1425, you can setHasIssues` when editing the repository through the API to change this behaviour...\n. @bmd-benita what do you get back from the server when the file is GitLFS-enabled?\n. I don't believe this has changed since I last checked. We're limited by what's available and supported in the GitHub API, so I recommend contacting GitHub Support about the underlying issue.\nIf we see documentation about this we can then support it in Octokit, we can revisit this.. If you can render HTML in your WPF app (using the WebBrowser control or something like CefSharp), then you can just use Octokit.NET to generate the GitHub-flavoured Markdown directly:\ncsharp\nvar github = new GitHubClient(/* setup */);\nvar html = await github.Miscellaneous.RenderRawMarkdown(\"This is a **test**\");\nI'm not aware of any libraries that support client-side rendering of GitHub-flavoured Markdown, but you can see an old SO thread discussing some options.\nI'll leave this open for a bit to see if anyone else has bright ideas here...\n. @shaggygi97test unfortunately we can't set the avatar when updating the user. This is still a manual task :cry:\n. @ryangribble @haacked @dampir any feedback on the release notes before I :ship: this tomorrow?\n. This has shipped:\n- https://www.nuget.org/packages/Octokit/0.21.0\n- https://www.nuget.org/packages/Octokit.Reactive/0.21.0\n. @ryangribble thanks for the sanity check. I called out #1402 in the previous release, and I'll add the others here.\n. This is shipped (again)\n. @ryangribble added to my list\n. @shaggygi I'm afraid this isn't currently supported, and I'm not sure of an ETA for it\n. @shaggygi it's not currently a supported feature of the GitHub API\n. @ryangribble if GitLink gives us the same end result, then I'm fine with switching. I forget the backstory and why they didn't team up with SourceLink way back in the day...\n. @ryangribble just gave it a look over, a few little comments but nothing serious\n:thumbsup: merge at your leisure\n. @ryangribble that all seems great :sparkles:\n. @maddin2016 @ryangribble great to see this land :tada: I'll prep a release for it (and whatever else is on master) this week...\n. @ryangribble so that's #1441 and #1443?\n. @ryangribble :thumbsup:\n. @ryangribble let me know if there's any other obsoletions I've missed here\n. > Im not sure how to summarize the nicely in the release notes though!\nI'll give it a shot - thanks for the initial start!\n. This is shipped:\n- https://www.nuget.org/packages/Octokit/0.22.0\n- https://www.nuget.org/packages/Octokit.Reactive/0.22.0\n. \nI'll pull this in to the next release (not the one currently being prepared).\n. > Since this is an identifier field, it should really be at least an uint (they can't be negative, can they?)\nAnd no, uint cannot be negative\n. @ryangribble  to be clear - I'm :thumbsup: on using long here due to the implicit behaviour of int saving a lot of breaking change. Just wanted to make the behaviour of uint clear here \ud83d\ude00 \n. > The API doesn't return -1 at any time in identifier fields, does it?\nNot that I've encountered.\n\nNor does octokit do that to signify some invalid state condition?\n\nNo\n. > I was wondering, it's not like I want to have more work, but... this is technically an ABI change.\nThis is true, and after the whole discussion in #1464 I'm pondering how often I want to break the API as broadly as this (even if it is still pre 1.0 in semver land, this stuff sucks).\nGiven numeric ids are not going to be a part of the GraphQL API and I think we'll be supporting the v3 API for a while, that looming September 2017 deadline is my only concern about getting this in...\n. >  How many versions do obsolete methods usually last for?\nWe usually leave them around for at least one or two releases.\n. Excellent points @ryangribble. Let's do this.\n. :sparkles:\n. @di48l069 there's an example in the documentation about passing in a Personal Access Token\n. @di48l069 that seems fine\n. @jaredpar yeah, silly 1-based pagination \ud83d\ude1e  - let me know if there's any way we can make this clearer. \nIf you drop the pagination overload the GitHub API will return 30 entities per response, and when it finds Link Headers in the response headers it'll continue to make new requests.\nIf you're not really looking for a specific page of results, and just want stuff faster than the defaults, I'd just set the PageSize:\n// fetch all items, 100 at a time\nvar batchPagination = new ApiOptions\n{\n    PageSize = 100\n};\n. @ryangribble code looks good, and AppVeyor is running these on PRs now so I'm \ud83d\udc4d to merging\n@mderriey fantastic stuff, thanks for jumping on this!\n\n. \n. Can you provide a failing test here, so we can verify the issue?\n. Yeah, I'm pretty sure this stuff is broken and needs some love https://github.com/octokit/octokit.net/issues/1251 \ud83d\ude22 \n. > QUESTION1: How to get all issues?\nGetAllForCurrent() will return the issues created and assigned to the current user. My psychic debugger thinks you haven't specified any credentials on your GitHubClient - the 404 typically occurs when you're not authenticated for a certain resource.\nCheck out the Authenticated Access section in the documentation for how to set this.\n\nQUESTION2: Why does the exception refers to a file that is not on my HDD? C:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Clients\\ApiPagination.cs:36\n\nThese paths are embedded into the PDB files at build time. If you'd like to step through the source, here's a guide to getting that working.\n. @Abdelkrim aha! \nThis is a permissions issue with your OAuth app - your application is only setup to request user and notifications scope, but everything issues requires at least public_repo scope.\n\nOnce you enable that, you should receive an empty response instead of the 404 error.\n. @mderriey the reason why I suggest getting a trivial .NET Core thing building is that I fear there's lots of integration hassles waiting for us getting this running on both Travis and Appveyor.\n. @mderriey I like where this is heading. If it's too hard to run both the original build and this new build (for example, if we hit timeouts with CI), then let's verify we can test the .NET Core project from the command line at least\n. > The new build does execute tests, but I'm sure you saw that, so I must miss something.\nYes, I wasn't clear. Am I able to run the same command locally? Or are there other dependencies I need.\n\nfor the time being, are we happy to duplicate source files in the new projects? Having both .csproj and project.json seems to be causing issues with MSBuild wanting more target frameworks in the project.json\n\nI'd rather not do this, and the MSBuild issues are similar to what I was seeing a while ago. \n\nif it turns out netstandard1.1 is all we need, are we happy to have it as the only target?\n\nI'm fine with targeting this initially as a new platform, as adding in extra platforms is rather straightforward. My main focus initially is ensuring we support the current platforms in project.json as well...\n. > As long as you have the dotnet CLI, then yeah, you can execute the build target to run .NET Core tests.\nDo you think it's worth installing the dotnet CLI locally, like we do for Rx.NET?\n. @mderriey all good points \ud83d\udc4d \n. @mderriey nope, this is me restarting the build :rage1: \n. This seems to be an upstream problem \ud83d\ude1e \n\nUnhandled Exception: System.TypeInitializationException: The type initializer for 'Crypto' threw an exception. ---> System.TypeInitializationException: The type initializer for 'CryptoInitializer' threw an exception. ---> System.DllNotFoundException: Unable to load DLL 'System.Security.Cryptography.Native': The specified module could not be found.\n. @mderriey that's fine, we can keep an eye on it over time.\n\nThanks for getting started on this!\n\n. > I could have squashed all these commits, it's a bit embarrassing to be honest.\nEh, it's fine. Onward and upward.\n. @dampir nice work!\n. I'm really not keen to do this, because everything in the Octokit API (ignoring Octokit.Reactive which just wraps it) returns a Task. And I'll point to the documentation the NServiceBus crew put out explaining why they don't do this either (yeah, they also refer to this project, whatever).\nBut I asked @terrajobst if this was actually a thing:\n@shiftkey methods running async operations should return Task and should end with Async.\u2014 Immo Landwerth (@terrajobst) September 12, 2016\nBut if people are really into doing this, and are willing to put in the work to migrate things properly - rather than just break the world - then I won't stand in the way.\nFeels @ryangribble @alfhenrik @dampir @haacked?\n. cc @shana @grokys @paladique for additional feels\n. > In my opinion, that's even worse because now the async suffix means nothing in Octokit.\n@terrajobst thanks for putting it so succintly :sparkles:\n. > I'm not an expert in Octokit, but it sounds to me as if this would mean virtually marking all methods as obsolete, which will have significant impact on the consumers. \nFor reference, here's how it would affect Octokit:\n- 668 public methods returning Task<T>\n- Of these, 96 are public async Task<T> \n- 81 public methods returning Task\n- Of these, 4 are public async Task \n. Oh, and another interesting data point - the earliest commit on this project was from late April 2012, a few months before .NET 4.5 was released. The code was extracted from GitHub for Windows, but that gives you an idea of how far back this decision probably went...\n. @dotMorten true, but the new *Async APIs in the BCL weren't added until .NET 4.5\n. Alright, that's enough.\n. This seems plausible according to the reference source, but I'm not sure why this code shouldn't return an empty enumerable when there are no values in the response:\ncsharp\ndata.Select(kvp => new RepositoryLanguage(kvp.Key, kvp.Value)).ToList()\n. @tang-jason are you referring to this limit?\n\nFor requests using Basic Authentication or OAuth, you can make up to 5,000 requests per hour. \n\nUnauthenticated requests are much lower (60 per hour), and I highly recommend using authentication for interacting with the GitHub API...\n. @tang-jason if you're only interested in doing something with your account, I'd recommend creating a Personal Access Token with the permissions it needs. The Getting Started guide should then help you get started with Octokit.net.\nIf you want to support other users running your app, you'll need to create an OAuth application so that users delegate permissions to your app and give you a token - instead of storing their credentials. This sample walks you through how to integrate this into a web application.\n. @tang-jason if it's going to be a headless task I'd recommend going with a Personal Access Token - but I don't know much about your setup and what data it needs to access through the GitHub API.\nI'll close this out as those are the two core scenarios for authenticated access.\n. Alternatively, client.User.GpgKey.Create() is the other \"key\" that the GitHub API supports.\nClosing this out as implemented.\n. Assigning to myself to remember and investigate\n. Assigning myself but I hope others can also :eyes: over the changes and get a feel for it all :metal:\n. I'm impatient and Travis is having issues\n#yolo\n. Unfortunately the Get the README endpoint doesn't support providing a path - that's the behaviour we're using in Octokit.\nThe Get Contents API supports providing a path, and looks like this in Octokit:\ncsharp\nvar files = await client.Repository.Content.GetAllContents(\"octokit\", \"octokit.net\", \"docs/git-database.md\");\nvar text = files[0].Content;\nHowever we don't support providing a custom media type so you could get the rendered markdown. #593 is the open issue discussing that.\n. @ryangribble :sparkles: gonna pull this in for the release\n. @ryangribble @maddin2016 the documentation seems to suggest this is supported :wink:\n\n. @abdulrehmangill excellent spot! Thanks!\n. \nYeah, I think this is a necessary evil of await for library code - whileCloneHttpRequestMessageAsync has it's own await and ConfigureAwait usage this doesn't mean callers know about it - it only sees Task<T> rather than the narrowed ConfiguredTaskAwaitable<T>.\n@zzzprojects I'm concerned that your code using .Result - which will block the current thread - doesn't reflect reality. Are you able to provide a small sample WinForms app which uses async void or equivalent, so I can see this behaviour for myself?\n. Okay, now I'm confused.\n\nUsing .Result allows resolving the task for a non-asynchronous application like mine. If I don't call Result, the code will simply continue to run without the task necessary terminated.\n\nWhether you call .Wait() on the task or use .Result directly, this will block the current thread until the task has completed. This is different to how ICriticalNotifyCompletion (the interface which .ConfigureAwait(false) returns) works around scheduling continuations.\n\nNop, I cannot provide any async void that will not work, since if I create an async method, the UI will not be blocked.\n\nI'm not sure I follow - if you're awaiting on the result of a task, it will be made available to you when it's ready. Like this:\n``` csharp\npublic static Task CreateGist(string description, Dictionary files)\n{\n    var github = CreateClient();\n// CREATE new gist\nvar newGist = new NewGist {Description = description, Public = true};\n\n// ADD file\nforeach (var file in files)\n{\n    newGist.Files.Add(file.Key, file.Value);\n}\n\n// START TASK\nreturn github.Gist.Create(newGist);\n\n}\n// note: this method can also be \"async void\" but returning\n//       a Task is nicer so that callers can await this too\npublic static async Task DoSomething()\n{\n    // CREATE gist\n    var gist = await CreateGist(description, files);\n// DO something else after the gist has been created\nDoSomethingElse(gist);\n\n}\n```\nI'm not clear on the behaviour you're seeing - is it deadlocking, or just blocking the current thread?\n. > It's a deadlocking. The thread is deadlocked with the UI thread.\nThis is what I needed to hear. Thanks.\nIf you're not interested in submitting a PR I'll add this to my task list for the week.\n. @zzzprojects single-line is preferred, yes\n. @ryangribble I've added those two PRs to my checklist\n. I'll open up some tasks for those integration tests I've muted here tomorrow.\n. @ryangribble yeah, still shooting for Thursday. I'll look over #1477 in the morning and check the tests are good to go.\n. @ryangribble cool, I'll throw some feedback in that PR to see if we should partially ship it\n. Oops, missed this yesterday due to other commitments. I'll push this out this afternoon.\n. Published:\n- https://www.nuget.org/packages/Octokit/0.23.0\n- https://www.nuget.org/packages/Octokit.Reactive/0.23.0\n. @zzzprojects thanks!\n. @StanleyGoldman these failures appear related to the unit tests - check the mocks locally as they may need to be updated.\nAlso, have you checked the Slow Tests section in the CONTRIBUTING docs? That should help you setup your environment for testing.\n. @StanleyGoldman thanks!\n. @jsauvexamarin it's been a while since I've looked at our Xamarin Studio support (I'm pretty sure my license expired too), so I'm not quite sure how to proceed here.\nWe've had Microsoft.Net.Http as a dependency for a while - it's technically a PCL as well, so I'm not sure whether something has changed and we should target something else for the Xamarin platforms.\n\nWhy is the dependency resolution choking on Microsoft.Net.Http.2.0.20505 when the package config clearly contains a reference to version 2.2.29?:\n\nCheck out the nuspec as that should be more relevant to the issue here (we don't restrict to a certain version).\n. > I'll submit a PR soon when it's ready.\nSo this PR is no longer needed?\n. @M-Zuber thanks!\n. Nope, looks like the GitHub API is now using PullRequest.Comment to return Review Comments rather than comments on the PR itself. I'll ask around and see what's changed.\nI'm not sure how long this is guaranteed to work, but here's my workaround:\nvar comments = await client.Issue.Comment.GetAllForIssue(\"dotnet\", \"roslyn\", 14645);\nConsole.WriteLine(comments.Count);\n. @pjc0247 I'm not clear what you were looking for in terms of options here - could you elaborate?\nEDIT: ah yes, I see what's missing. I'll open an issue for this.\n. @ryangribble I think this is a separate issue to #1500. If this endpoint is now serving up different data, we need to address this as a breaking change (introduce PullRequest.ReviewComment and obsolete PullRequest.Comment maybe?). From the docs\n\nAll actions against teams require at a minimum an authenticated user who is a member of the Owners team in the :org being managed. Additionally, OAuth users require the \"read:org\" scope.\n. There's an outstanding convention test failing here:\n\nOctokit.Tests.Conventions.InterfaceMissingMethodsException : Methods not found on interface IObservableRepositoriesClient which are required:\n       - get_Deployments\nI'm not sure how I feel about the pluralization change on the whole, especially when we made a lot of changes to IGitHubClient to drop these...\n. @ivandrofly excellent spot - thanks!\n. @mderriey I'd leave net45 in there unless you're having specific issues with it. \n\nCongrats to the both of you on getting this preview out! Keep up the awesome work \ud83d\udc96!. @ryangribble @andrejo-msft @M-Zuber this all seems reasonable :thumbsup:. Not sure if you found a solution, but here's mine:\ncsharp\nvar commit = await client.Repository.Commit.Get(\"octokit\", \"octokit.net\", \"195de68\");\nvar author = commit.Commit.Author.Date;\n// this might be different in some cases, for example merges\nvar committer = commit.Commit.Committer.Date;. The second parameter is the unique identifier for a pull request. For example, #1503 is the identifier for this pull request: https://github.com/octokit/octokit.net/pull/1503\nIf you just want to enumerate all open pull requests, use this method:\nvar pullRequests = await client.PullRequest.GetAllForRepository(\"octokit\", \"octokit.net\");\nvar first = pullRequests[0];\nvar number = first.Number;\n\nMoreover, if doesn't exist a pull request in a repo, octokit throws me an exception..\n\nThis is due to a 404 being returned from the GitHub API - we just surface that because we don't have any data to give the caller.\n. I got you @damianh \n\n. @SeanKilleen I'm glad this was relatively easy to solve!\n\n. PullRequestCommit won't have their Files entries populated. See #1522 for how to resolve those.\nIf you look at the commit response for that change, it appears to be a new feature of the GitHub API, likely related to how we're trying to defer our diff rendering wherever possible.\n\nInstead of patch being defined, you have a contents_uri which if you follow, returns the Base64 encoded diff of the change:\n\nSupporting this new field is probably easy to roll into an update, if someone wants to add it to the right response object.. @l1salvatore because the patch property on the JSON isn't populated. Not directly, due to how the Pull Request API is designed.\nBut you can combine two API calls to do this:\n```csharp\nvar owner = \"octokit\";\nvar repository = \"octokit.net\";\nvar id = 1520;\n// retrieve the commits in a given pull request\nvar commits = await client.PullRequest.Commits(owner, repository, id);\n// use whatever commit you want to lookup in here\nvar firstCommit = commits[0].Sha;\n// look at the commit details to find the list of files          \nvar commit = await client.Repository.Commit.Get(owner, repository, firstCommit);\nConsole.WriteLine($\"Found ${commit.Files.Count} files in commit\");\n``. ![](https://cloud.githubusercontent.com/assets/359239/21754985/3f8c09bc-d65f-11e6-8e5a-a941b5ca5dc7.gif)\n. @aniket-aurea do you have an example URL that I can use to confirm this is related to [EventInfoState](https://github.com/octokit/octokit.net/blob/c9b2c1260bc87b7782d4fd9645d43a8885203923/Octokit/Models/Response/EventInfo.cs#L74) not having this value?. @JohnGoldsmith unfortunately theSha` property here represents the blob of the file, not the commit where the file was last modified. That's why you're seeing the 404 Not Found when asking for it to resolve a commit.\n\nI'm trying to get hold of the last commit object from the sha of a content object.\n\nI'm not quite sure of an easy way to get this data - you could walk through the commits starting from the tip of the branch, like this:\nvar request = new CommitRequest()\n{\n    Path = targetFolder,\n    Sha = targetBranch\n};\nvar commits = await client.Repository.Commit.GetAll(owner, reponame, request);\nBy default these aren't pre-populated, so you'd have to make a second call to get the changes in each commit.. @JohnGoldsmith I'm glad you were able to workaround the issue! :sparkles:\nLeaving this open for someone to address the suggestion that the comment on this line needs to be updated:\n\nI see the the xml comment on Sha says 'SHA of the last commit that modified this content' if I'm reading in the right place. Should this be 'SHA of this content blob' or does it have different uses in other places?. @jparnell8839 ah yes, I know what's happened here. Here's the commit where we removed the code, which previously had an Obsolete message: https://github.com/octokit/octokit.net/commit/2cc2ccda622e0774094e8449802eb63c2044da98\n\nOriginally we had client.Release but we wanted to align the Octokit API with how the GitHub documentation organizes it's endpoints. This meant moving it under Repository, like this page: https://developer.github.com/v3/repos/releases/\nOf course, this doesn't address how we keep the documentation in sync for when the API changes. I don't have any good answers on this - but we can currently test Linqpad snippets against the real binaries and catch failures at the CI stage, if that's something we want to leverage more broadly.... The Id field isn't used in any of the APIs (Number is the recommended identifier) but for the sake of completeness if someone wants to add in the field this is the response model.. \n. @pthivierge can you provide a sample for what you're calling, so we can reproduce it on our end?. @ryangribble left a couple of minor comments, everything else is :gem:. > This rule is mostly pedantic in a sense it will limit the expressiveness of naming class/method/property, and it's easier and faster (in compile time) to just suppress it on project scope, not at different source on class/method/property.\nI disagree. The explicitness of this rule means violations (whether necessary or otherwise) are easier to identify. Doing things at a project level makes it easier to ignore these sorts of issues.. @ryangribble ugh, CI failures on macOS\n\nThe command \"curl -o \"/tmp/mdk.pkg\" -fL http://download.mono-project.com/archive/4.2.3/macos-10-x86/MonoFramework-MDK-4.2.3.macos10.xamarin.x86.pkg\" failed and exited with 56 during .\n. @ryangribble :shipit:. This is not available through the API.. > Potentially with dotnetcore, we dont even need to worry about TravisCI and could just use Appveyor instead... Thoughts @shiftkey ?\n\n:thumbsup: especially to drop macOS - not being dependent on those will speed up things significantly!. Here's where we introduced the Obsolete rule: https://github.com/octokit/octokit.net/commit/e31ac8659a124079a696c84bfb22f67c759bd6d5\nAnd this made it into the v0.23 release - https://github.com/octokit/octokit.net/releases/tag/v0.23.0\nI think this is fine to remove the ctor from the next update @eriawan! :thumbsup:. @eriawan I don't think so. Thanks for the contribution!\n\n. Unfortunately not.\nThe docs for doing OAuth without the web flow involves signing in with basic authentication and creating an authorization on behalf of the user. But that still requires their input.\nAlternatively, if the user can provide a personal access token you can use that for credentials and get a higher rate limit - however it's not associated with your application.. > Do you think creating a personal access key to be associated with the application so that it can have its higher rate limit would be a good idea?\nThe OAuth token represents the relationship between a user and an application - that doesn't feel relevant here as it sounds like you don't need to have everyone authenticate against the application. Personal access tokens are great for testing and prototyping, but they are tied to a real account - combining whatever the real account has access to with the scopes you give the token. \nSo there's a concept called \"machine accounts\" which I'll point out here. From the Terms of Services page:\n\nA machine account is an account set up by an individual human who accepts the Terms on behalf of the account, provides a valid email address, and is responsible for its actions. A machine account is used exclusively for performing automated tasks. Multiple users may direct the actions of a machine account, but the owner of the account is ultimately responsible for the machine's actions. You may maintain no more than one free machine account in addition to your free personal account.\n\nWhat I'd do to simplify things without having to worry about OAuth:\n\ncreate a machine account, add it as a member of your organization and give it access to the appropriate teams and repositories it needs to get stuff done\ngenerate a personal access token for the machine account, ensuring it has just the appropriate scopes set that it needs\nset that token GitHubClient.Credentials whenever your chatbot needs to interact with the GitHub API\n\nIt avoids the whole OAuth application setup and management, but it doesn't sound like something you need here. . @joensindholt the reason is they're two different code paths (and that we don't look at the exception for the second one):\n\n\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Clients/RepoCollaboratorsClient.cs#L151-L158\n\n\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Clients/RepoCollaboratorsClient.cs#L171-L186\n\n\nI gather surfacing the AuthorizationException is probably the better thing to do here - if you're keen to contribute a fix I can guide you through the process.. If you've got VS2015 installed, you should be able to just open the solution and build it locally.\nThere's a bunch of additional things in our CONTRIBUTING.md docs - running tests, etc - and this overview of the code is probably helpful.. I'm not across the history of the .IsTrue() extension method - it does seem to look functionally correct:\nhttps://github.com/octokit/octokit.net/blob/c9b2c1260bc87b7782d4fd9645d43a8885203923/Octokit/Helpers/ApiExtensions.cs#L105\nBut it does overlook that the underlying connection will raise an exception before the caller has had a chance to look at the response:\nhttps://github.com/octokit/octokit.net/blob/3c818934b8b3b4cdc5472bf01e869c07343c3928/Octokit/Http/Connection.cs#L597\nSo the try-catch is still necessary, but it should be more granular and only look for the NotFoundException.. Weird - the source looks rather mundane, and the endpoint also seems boring: https://developer.github.com/v3/activity/notifications/#mark-as-read. >  Not sure if this is a recent thing or it's always been like this, as there are no integration tests for this method currently.\nSigh. I'll check it out. Thanks for digging into it @ryangribble! . @ryangribble If you PUT with an empty JSON object you get the correct behaviour without having to specify anything in the payload. And I'm pretty sure that PUT without a body isn't typical HTTP behaviour (the server may think \"you haven't given me an entity to update, what am I supposed to do here?\" and returning a 400 like it's doing here seems reasonable).\nAnyway, #1579 should fix it\n. :shipit:. \nIs there any particular feedback you need from me?. Or maybe they should just go back to string if we're not getting anything from using Uri due to the increased allocations?. @mderriey I really don't think we're getting much out of returning Uris - and they're boring enough that the caller can new Uri() the result if they need it explicitly.\nLet's make them all string.. > I'm having second thoughts about the Request models though. My thinking has kind of come around to the fact that these are meant to be proper Url's so allowing people to pass \"any old string\" may not be great. Thoughts?\nYeah, I'm less into doing this for request models now because of how invalid input might be rejected - we're not doing anything explicit here with validating, but it's still a decent constraint to make callers follow.\nI can only see NewCommitStatus updated here - @mderriey how many would change here if we enforced Uri on the*Url request model properties?\n. @mderriey I like those suggestions \ud83d\udc4d . > Is that fine by you or would you rather not check request models at all?\nThis is fine - it's good to be explicit here.. @mderriey i got you. From the integration tests:\ncsharp\nvar client = new GitHubClient(/*...*/);\nvar licenses = await client.Miscellaneous.GetAllLicenses();\nAssert.True(result.Count > 2);\nAssert.Contains(result, license => license.Key == \"mit\");\nPlease let me know if there's anything more you want from this endpoint.. > I have a problem with the delete methods. \nThis one? https://developer.github.com/v3/pulls/review_requests/#delete-a-review-request\n\nAccording to the docs it should only return appropriate result code, but in practice it does return an object similar to the create method.\n\nThis seems like an inconsistency - they should be returning 204 No Content for success. I'll poke around and talk with the team to confirm this is the intended behaviour. Let's not surface the response here and just use Task, as long as the status codes are reliable enough.. @ronaksharma8 it's a pre-release package, so you'll have to provide -Pre to install this version. @lynnfaraday :thumbsup: all seems reasonable. I'll let @ryangribble or someone else have a look before I merge it. . Yeah, this is a convenience thing.\n\nSince there's also a bug restoring Rx-Main right now, \n\nWeird. Would love to hear more about this one - I gather it's because Rx-Main is unlisted and we haven't had a chance to land the migration to System.Reactive, but restore shouldn't be affected by that.. Of course, because LINQPad doesn't know about specific versions...\n\nYep, burn those references to the ground @NickCraver  :fire: :fire: :fire: :fire: :fire: :fire:. @nickcraver so there's no need to also remove Octokit.Reactive from these files?. @NickCraver cool, I'll take this in then. Thanks!. Yeah, #1591 should fix these. But given how often new events are introduced I really think deserializing to string with more flexibility for callers to then map it to something is a more sane long-term strategy for this area \ud83e\udd14 .. First one is easy:\nc#\nvar client = new GitHubClient(/* ... */);\nvar repos = await client.Repository.GetAllForOrg(\"org\");\nSecond one is only partially possible:\nc#\nvar client = new GitHubClient(/* ... */);\nvar branches = await client.Repository.GetAllBranches(\"org\", \"repo\");\nThe response returned for each branch doesn't give you much - just a link to the commit - and so you'll need to lookup that commit to find the timestamp.. \n. var users = await client.Search.SearchUsers(new SearchUsersRequest(\"asd@asd.com\"));. @tnaoto thanks for noticing this!. I'm honestly not sure which version of the .NET Framework is supported by Unity 3D.\nIf it is earlier than 4.0, we don't have plans to support it due to the heavy usage of the Task Parallel Library. And we dropped 4.0 support a while ago because there were significant gains to using .NET 4.5.\nA supported version of .NET Standard is almost ready - I think the target is .NET Standard 1.1 - but that may not be a solution here.. @EmpireWorld that's what I'd recommend - use the endpoint and snippet examples from https://developer.github.com/v3/ and have a bit of JSON parsing of the response to get the data you need in C# objects.\nYou could extract the relevant source file for the response models from our Octokit/Models/Response folder and add them into your project to save time with models and parsing, but I'd recommend getting familiar with the API first.. @AzureMLTest @khellang I'm mostly neutral on this due to the fact that it doesn't hurt me in my day-to-day work, but I'll defer to @ryangribble and @mderriey who have been doing a lot of work recently on getting .NET Standard support in on whether they want to support this at some stage.\nAnd :thumbsup: to StrongNamer as an escape hatch for this.. Looks like this isn't specific to Octokit.net - https://github.com/philschatz/octokat.js/issues/169\nGut feeling is something server-side has changed - I'll do some digging through the support channels and see if I can get an idea of what's changed recently.. @ferventcoder a configuration fix has been deployed a few hours ago - are you able to see if that fixes the issue on your end?. @SleepyBandit thanks for confirming. I'll close this out for now.\n@ferventcoder please let me know if you see any other issues.. @ferventcoder yeah, that last error was before the update was deployed.. @PavelBansky can you link to the documentation you are looking at?. Looks like we don't have that overload: https://github.com/octokit/octokit.net/blob/master/Octokit/Clients/PullRequestReviewCommentsClient.cs#L250\nGiven that was originally implemented a while ago and this feels like a new change, I guess it'd be nice to see if someone was keen to add this support in.. This is not supported through the GitHub API.. @watsonlu thanks!. @markwilkie thanks for the interest, but I'd recommend doing that as a standalone library.. @Korporal I don't trust .Result in general, and there's better ways to work with tasks these days. \nThis code works for me:\ncs\ntry\n{\n    var master = \"cda714bef60d3c787ee3db2512025cde46d02dba\";\n    var commit = await client.Repository.Commit.Get(\"octokit\", \"octokit.net\", master + \"777\");\n}\ncatch (NotFoundException ex)\n{\n  // handle commit not found\n}. @Korporal I'm not sure which version of the .NET Framework you're running on (this was with 4.5.2) but I think that's the root cause. Anyway, I'm glad you were able to handle the exception!. @Korporal please provide a sample of the code you're using - the API is different to the website, so maybe there's some things that can be clarified when we're talking about the same code.. > I'm hoping there's a programmatic way to get a \"no\" to the question \"Is this commit (550C9D40) in the upstream repo?\".\nI don't think so. I think this behaviour came about because it was hard to find a commit within a network of repositories without knowing which fork had it - the exact opposite of what you'd expect.\nWhat I'd do is compare two branches, like this:\nhttps://github.com/octokit/octokit.net/compare/master...Korporal:master\nThis maps to the API as https://api.github.com/repos/octokit/octokit.net/compare/master...Korporal:master\nAnd shows your new commit:\n\n. I Am Not A Lawyer, but I'd mostly say:\n\nrespect the license associated with the code\nto avoid confusion with the Octokit group of libraries, a name change would be :gem:\nattribution is always nice (but not required). Are you looking for the Content API, that lets you read directories or files in a repository?\n\nvar contents = await client.Repository.Content.GetAllContents(\"octocat\", \"Spoon-Knife\");\nThis should give you a list of folders and files at the root of the repository.. Release notes look good, and thanks to everyone who contributed to this - especially @ryangribble and @mderriey for the .NET Core work!\n\n. Looks good to me \ud83d\udc4d . Sadly this is a limit of the payload that's returned from the API itself.\nThis is the entire payload we get:\n[\n  {\n    \"id\": 1,\n    \"url\": \"https://api.github.com/repos/octocat/Hello-World/issues/comments/1\",\n    \"html_url\": \"https://github.com/octocat/Hello-World/issues/1347#issuecomment-1\",\n    \"body\": \"Me too\",\n    \"user\": {\n      \"login\": \"octocat\",\n      \"id\": 1,\n      \"avatar_url\": \"https://github.com/images/error/octocat_happy.gif\",\n      \"gravatar_id\": \"\",\n      \"url\": \"https://api.github.com/users/octocat\",\n      \"html_url\": \"https://github.com/octocat\",\n      \"followers_url\": \"https://api.github.com/users/octocat/followers\",\n      \"following_url\": \"https://api.github.com/users/octocat/following{/other_user}\",\n      \"gists_url\": \"https://api.github.com/users/octocat/gists{/gist_id}\",\n      \"starred_url\": \"https://api.github.com/users/octocat/starred{/owner}{/repo}\",\n      \"subscriptions_url\": \"https://api.github.com/users/octocat/subscriptions\",\n      \"organizations_url\": \"https://api.github.com/users/octocat/orgs\",\n      \"repos_url\": \"https://api.github.com/users/octocat/repos\",\n      \"events_url\": \"https://api.github.com/users/octocat/events{/privacy}\",\n      \"received_events_url\": \"https://api.github.com/users/octocat/received_events\",\n      \"type\": \"User\",\n      \"site_admin\": false\n    },\n    \"created_at\": \"2011-04-14T16:00:49Z\",\n    \"updated_at\": \"2011-04-14T16:00:49Z\"\n  }\n]. @ryangribble @vishrutshah unless it's something that's available and documented via the https://developer.github.com/ site, it's not something that should be in Octokit.net.. @ryangribble :thumbsup:. Also, keep in mind that any new features in the GitHub API are not going to be backported to v3.\nI've been chatting with the other Octokit teams a bit about what this means for Octokit.net, and need to grab some time with @ryangribble, @mderriey and whoever else is interested to sketch this out further.. @it19862 as the README isn't part of the returned search results, you'll need to make a follow-up query to read the README for a given repository.\nI've tried to tweak your sample to illustrate this - hope it helps!\n```c#\nvar result = await client.Search.SearchRepo(request);\nfor (int s = 0; s < 3; s++)\n{\n    var vr = result.Items[s];\n    var id = vr.Id;\nvar readme = await client.Repository.Content.GetReadme(id);\nvar rawText = readme.Content;\n\n}\n```. \n. > Using Get actually provides more fields, but now all the fields say true for Mergeable, even for PR's that say CI check has failed and says \"Merging is blocked\"\nThe Mergeable field is compute-intensive, so it's only exposed on Get - see the details here.\nI think we have an old issue about differentiating GetAll from Get to make this clearer, but it's been a while since I last came across a discussion about this.\nAlso note that Mergeable is purely for whether the branch can be merged into the base branch. Things like Commit Statuses should be used to look at the CI checks, and Required Status Checks to determine which need to pass before the branch can be merged.. > The only bad thing is that I doubt we\u00b4ll be able to include details when it\u00b4s safe to try again because the github api itself doesn\u00b4t provide enough information, it just returns a 403 and a generic message.\nRate limiting headers are sent on every response from the API. And this is available from Octokit too.. @ryangribble seems legit \ud83e\udd37\u200d\u2642\ufe0f . @ryangribble has Travis moved some cheese around?\n```\nE: Package 'dotnet-dev-1.0.1' has no installation candidate\nThe command \"sudo apt-get install -qq dotnet-dev-1.0.1\" failed and exited with 100 during .\nYour build has been stopped.\n``. @pizycki I think this might be related to the branch name - it looks like you're creating it from the current time, and if that doesn't exist the repository wouldn't know where to create the new commit from. What if you used a fixed branch name to confirm that thePUT` is working as expected?. @pizycki I'm glad you were able to get to the bottom of it!. Seconding using the repository statistics endpoints - this is supported in Octokit.net, and it will do the heavy lifting for you... . @hyan23 this is not currently supported by the GitHub API, and so you might have to fall back to working with the Git repository via a local clone to get that information.. @itaibh can you provide some more context for this change? Also, this might be worth upstreaming to SimpleJson if it's useful more broadly.... @itaibh thanks for the extra info. I found #825 where you commented earlier.\n\nThis is a GitHub bug, probably, but still, such a convention should be supported (and it would have saved me hours of debugging).\n\nIn your other comment you mention this:\n\nAlso, from the timing it seems the problem had returned only recently (about two weeks ago).\n\nIf this is a recent regression then I'd love to try and chase this down, because we should be consistent with these fields. If you can point me to a repository which fired a webhook with the wrong format for created_at and pushed_at in the payload I can chase that up internally and confirm it's been resolved while we discuss this fix.. Closing this out due to inactivity. @mirsaeedi I'd recommend GetAllForRepository but also:\n\nusing the pagination API so you get more results per page:\nusing a local cache for past review comments and only querying for values since the most recent stored entry\n\n```c#\nvar options = new ApiOptions { PageSize = 100 };\nDateTimeOffset since =  / /;\nvar request = new PullRequestReviewCommentRequest { Since = since };\nvar pullRequestComments = await _client.PullRequest.ReviewComment.GetAllForRepository(\"owner\", \"repo\", request, options);\n```. @mirsaeedi I would still recommend investing in a backing store (like a database) so that you can easily store the PR comments and work with them locally, so you can research as many repositories as desired while working within the API limits. \nThe 5000 requests/hr limit is a server-side restriction of the GitHub API, and the Octokit client is not able to circumvent this.. > A mitigation to this could be a change in GetAllForRepository to wait for a sufficient amount of time, in case of reaching the limit. And, automatically starting to fetch data again after that.\nI'll defer to @ryangribble on this from an earlier thread: https://github.com/octokit/octokit.net/issues/1711#issuecomment-342463086\n\nwe generally shy away from implementing higher order logic like making composite/multiple API calls on behalf of the consumer, or building in retry/throttling type behaviour in the library itself, because there are too many potential use cases to implement in a way that would suit everyone.\n\nThe rate limiting API is available in Octokit.net, so that callers can handle this themselves.. @itaibh we have the build.sh scripts at the root of the repository that's used on Travis and seems to be targeting .NET Core:\n./build.sh --linksources=true\nDoes that give you the same error if you're on .NET Core 1.x without having to change the .csproj files?. You probably want the Compare Commits API:\nvar compare = await client.Repository.Commit.Compare(owner, repo, \"master\", \"branch\")\nThat will list out the whole file list, and it has some limits which are mentioned in the docs, but that should do the trick.. @hgleaves-ncuadmin can you post up a snippet of the code you're using?. @hgleaves-ncuadmin the Branches API only includes the SHA of the commit associated with each branch, but this can be used to get the full commit information:\nc#\nvar branches = await client.Repository.Branch.GetAll(repo.Id);\nforeach (var branch in branches)\n{\n    var result = await client.Repository.Commit.Get(repo.Id, branch.Commit.Sha);\n    var authorDate = result.Commit.Author.Date;\n    // these might be different values, in which case this will probably be later (and more accurate)\n    var committerDate = result.Commit.Author.Date;\n}. @ryangribble @Korporal yeah, those are the only two tricks I know about.\n\nIs the merge operation described above in 2.) , supported by Octokit?\n\nYes\n```c#\nvar newMerge = new NewMerge(\"master\", branchName) { CommitMessage = \"merge commit to master from integrationtests\" };\nvar result = await client.Repository.Merging.Create(owner, name, newMerge);\n```. I thought I'd be able to leverage our JSON deserializer to convert the list of issues to a string, like this:\nc#\nvar serializer = new Octokit.Internal.SimpleJsonSerializer();\nvar text = serializer.Serialize(issues);\nvar recreatedIssues = serializer.Deserialize<IReadOnlyList<Issue>>(text);\nHowever it blows up on the second line with this error:\nValue '' is not a valid 'ItemState' enum value.\nI also tested this with JSON.NET to confirm it wasn't our deserializer to blame, but it has the same error.\nOur SimpleJsonSerializer has a bunch of domain-specific rules and conventions for mapping JSON to .NET objects, but I bet we're not applying the rules enough to be able to round-trip an object through it. . @Cyberboss if you'd like to contribute this, the file you need to change is here and I think all you need to do is add a new property:\ncsharp\n public bool MaintainerCanModify { get; protected set; }\nAnd then add an additional parameter to the second constructor:\ncsharp\npublic PullRequest( /* ... */ , bool locked, bool maintainerCanModify, IReadOnlyList<User> requestedReviewers)\n{\n     // other code\n     Locked = locked;\n     MaintainerCanModify = maintainerCanModify;\n     RequestedReviewers = requestedReviewers;\n}. > Okay, but being stuck on the await to complete for 10+ minutes kinda kills the point of using this library for me.\n@Dorky106 the default behaviour of GetAll is to follow pagination hints and fetch all records related to an API. If you're on a repository with thousands of releases, this might explain why the request is taking so long to complete.\nIf you only want to get a subset of these releases, there is an overload that takes an ApiOptions object which lets you control how much data you want:\nc#\nvar firstTen = new ApiOptions\n{\n    PageSize = 10,\n    PageCount = 1\n};\nvar releases = client.Repository.Release.GetAll(\"Dorky106\", \"BetterTrees\", firstTen).Result;\nThere's also the GetLatest API that is intended to just get the latest release:\nc#\nvar release = client.Repository.Release.GetLatest(\"Dorky106\", \"BetterTrees\").Result;\n. @Korporal the first issue that I can see is that most of the GetAll APIs return Task<IReadonlyList<T>> which is a more concrete abstraction than IEnumerable<T>, so I'm not sure how a drop-in replacement would work when that signature needs to change. But don't be afraid to experiment with a different implementation if you think this might help for better lazy-loading scenarios.. > I've not really done much with IObservable and need to devote some time to it.\n@Korporal IObservable is a push-based way of enumerating values, which is a bit different to what you had in mind. So I'm going to share some reservations of mine about this change, and provide some hints as to where you should be looking.\nI'm quietly worried about breaking the behaviour of GetAll here to achieve lazy loading (because it's there in the name - Get All) and IEnumerable is basically a synchronous interface (MoveNext() does block, so if you're going to make a network request when you need a new page it's still not going to be a great experience for the consumer).\nI'd recommend instead looking at IAsyncEnumerable and in particular IAsyncEnumerator which is part of Ix.NET.\nThe signature for IAsyncEnumerator is much closer to what you are looking for in terms of an asynchronous enumerable:\nTask<bool> MoveNext(CancellationToken cancellationToken);\nThere's been very early discussions about making this a part of the BCL and supporting the ability to foreach over these like you would a regular IEnumerable, but I'm not involved with them at all so you'll have to keep up with Mads Torgensen et al and future C# language features.. @StefH that isn't supported by the GitHub API, which is a constraint on what can be supported in Octokit.. @egee-irl the Octokit libraries don't really care about the source of the token, as it will always send Authorization: Token {token} when making requests. But the source of a token is important for organizations.\nPersonal access tokens:\n\nare created by the user, and are restricted to the scopes the user assigns when creating them.\ncan access organization data unless the organization has enabled SAML single-sign on - then personal access tokens need to be authorized\n\nOAuth applications:\n\nneed to be approved by the user before they can create an access token\nmay also need to be approved by the organization to access the organization data\n\nMy gut feeling  is that the organization has enabled \"OAuth App access restrictions\" which means that applications need to be approved by the organization admin before the app can access the organization data. \nCan you confirm that?. @Korporal you probably want to follow along with https://github.com/octokit/octokit.net/pull/1738 and the original issue https://github.com/octokit/octokit.net/issues/1727. @davidhouweling the problem seems to be this value:\n\"created_at\": \"2018-03-19T21:55:16.620+00:00\",\nThat's different to other datetime formats that the GitHub API returns:\n\"created_at\": \"2016-05-11T15:59:00Z\",\n  \"updated_at\": \"2018-03-19T20:39:05Z\",\n  \"pushed_at\": \"2018-03-19T18:26:49Z\",. @davidhouweling please reach out to https://github.com/contact and point them at this discussion - I think it's a bug with this particular endpoint.. > is there a reason we are so strict on the parsing in the code and not just use DateTime.Parse and let the internal .NET engine determine the value?\nWe're strict because the GitHub API docs clearly document the format of datetime values with timezone offsets, and I believe this is something that needs to be fixed on the server.. @davidhouweling can you retest this? I think we've fixed the datetime formatting on this endpoint so that it's now consistent with the others.. For reference, I wrote a similar thing a while ago in a hurry that was designed for batch tasks and doing as much work as possible with the available quota:\n\nCLI-focused - displays messages around available quota while working\nfail-fast - once you've exceeded your quota, show when you can start over and exit\n\nIt's not as exhaustive as the initial example, but also doesn't wait for your quota to reset - just wanted to illustrate that there are different approaches here around rate-limiting.. > Looks like the linux build failed while installing .NET, though I am not familiar enough with travis to know if that is fixable in code or not.\nI don't believe this issue is related to your contribution. I've restarted the build to see if it's repeatable (and thus probably an infrastructure issue).. I'd recommend checking these three things:\n\nNo need to provide the uri parameter when creating the GitHubClient for GitHub.com\nCheck there are new commits on the branch in the fork\nEnsure you're using a real repository \n\nThe latter two things are likely to trigger the \"Validation failed\" error from the server. Closing this out for now unless someone is interesting in championing this effort. It'll require a lot of work on internals to support properly alongside the current Task and Observable versions, and I'd rather the maintainers support getting the newer v3 API features supported in the library.. @Disturbing when you get the current user, there's a Plan property that contains the details:\n```csharp\nvar user = await client.User.Current();\nif (user.Plan.PrivateRepos > 0)\n{\n    Console.WriteLine(\"User has ability to create private repositories...\")\n}\n```. > ... Because only users with write access can assign labels to issues\nI'm pretty sure it's this. Gonna close it out without more information.. @iamnotstanley I broke this line down so it wasn't so long, but it's that first line that should resolve the ambiguous reference:\nc#\nvar location = System.Windows.Application.ResourceAssembly.Location;\nvar versionInfo = System.Diagnostics.FileVersionInfo.GetVersionInfo(location);\ncurrentVersion = Convert.ToString(versionInfo.ProductVersion).TrimStart('v'); // AssemblyInformationalVersion. I haven't tried this myself, but this SO answer suggests you might be able to get away with just using the Git Data API:\n\n\nGet upstream ref /repos/upstream/repo/git/refs/heads/master, and get the hash from it\nUpdate your fork PATCH /repos/my/repo/git/refs/heads/master with the same hash\n\n\nHow this might look with Octokit.NET (the code compiles but No Guarantees\u2122 on anything else):\n```c#\nvar upstreamMaster = await client.Git.Reference.Get(\"upstream\", \"repo\", \"heads/master\");\nvar newSha = upstreamMaster.Object.Sha;\nConsole.WriteLine($\"The master branch on upstream/repo is {newSha}\");\nvar forkMaster = await client.Git.Reference.Update(\"fork\", \"repo\", \"heads/master\", new ReferenceUpdate(newSha));\nvar updatedSha = forkMaster.Object.Sha;\nConsole.WriteLine($\"The master branch on fork/repo is {updatedSha}\");\n```. @jlindner Octokit is for interacting with the GitHub API, rather than local Git repositories. If you want to do a local sparse checkout your best bet is the Git command line.. @rquackenbush \nc#\nawait client.Git.Reference.Delete(\"owner\", \"name\", \"tags/some-tag-name-goes-here\");. @FantasticFiasco given the broad API surface already supported, do you have any thoughts on how we'd support this through the internals? I guess we'd need to pass this all the way down to HttpClient but it'd be neat to confirm the impact of this on a single API function before moving ahead with this.\nWe have the ability to write convention tests to ensure things are consistent, but we should also figure out a migration path to transition to this before we got and introduce a change like this that will likely affect every API function.. @FantasticFiasco is that something you're interested in exploring and/or championing?. @totoroyyb are you able to share a runnable code sample of the issue? It looks like a deserialization issue but having the right steps to trigger it will significantly help with troubleshooting.. @xied75 this isn't currently supported and I don't think we have plans for it, but there are existing solutions to interact with the Windows Credential Manager, like this https://stackoverflow.com/a/17747020/1363815. @Cyberboss we might still be able to get that in - are you able to add in the right fix to CheckRunUpdate?. @StanleyGoldman is this related to the total_count field (that feels a response from a search API, but /apps/installations/ doesn't seem to behave like one) or was there some other questions/curiosities you had?. > Issues can be raised by anyone, but only users with write access can set labels on issues.\nYep, this is the issue. If you add @gRally-Issues as a collaborator to the gRally/dev repository this will work fine.. @NikosSyris this is not available from the GitHub Commit API because of how the Git object model works.\nThe closest approximation is looking at the commit timestamp (in most cases they should be the same) for the commit where this file was added to the Git repository:\n```c#\nvar commit = await client.Repository.Commit.Get(\"octokit\", \"octokit.net\", \"master\");\nvar authorDate = commit.Commit.Author.Date;\nvar committerDate = commit.Commit.Committer.Date; \n```. > That is quite possible..\nHere, read: https://www.jetbrains.com/buy/opensource/. @NikosSyris we're limited by what's supported in the HTTP API - https://developer.github.com/v3/search/#search-code. @Dalmirog thanks for the details - I looked at the JSON payload being sent in the API docs and I don't see repository being populated, so I suspect this is just a limitation of us using the same class to where the API doesn't return everything.\nAlso, just a heads up: new ApiOptions { PageSize = int.MaxValue } will still only return a maximum of 100 items.. @WowItsDoge please note that the API docs indicate this will default to open issues.\nIf you're doing queries that you know are going to return a lot of data, you should enable pagination:\nC#\nvar openIssues = await client.Issue.GetAllForRepository(\"tensorflow\", \"tensorflow\", new ApiOptions { PageSize = 100 });\nConsole.WriteLine($\"Issues found by default: {openIssues.Count}\");\nWith this query I see 1827 issues, similar to your case.\nIf I change up the query to pass in a RepositoryIssueRequest object, like this:\nC#\n var allIssues = await client.Issue.GetAllForRepository(\n    \"tensorflow\",\n    \"tensorflow\",\n    new RepositoryIssueRequest { State = ItemStateFilter.All },\n    new ApiOptions { PageSize = 100 });\nConsole.WriteLine($\"Issues found with filter set: {allIssues.Count}\");\nI now get 22333 open and closed issues. I'm not sure why the disparity between the stats on the website and the API, but I'll leave that as an exercise for you to figure out. \n. @it19862 You should be able to just splat the archive bytes to disk:\nC#\nvar archiveBytes = await github.Repository.Content.GetArchive(\"octokit\", \"octokit.net\", ArchiveFormat.Zipball);\nSystem.IO.File.WriteAllBytes(@\"C:\\Temp\\repository-archive.zip\", archiveBytes);\nIf you want to programatically interact with the archive, there are many APIs out there like System.IO.Compression and SharpZipLib that will accept the byte array you received from the GitHub API.. @it19862 it returns a Task<RepositoryContentLicense>, so you need to await on it to get the result:\nC#\nvar repoLicense = await client.Repository.GetLicenseContents(\"octokit\", \"octokit.net\");\n. @it19862 that seems like you're on the right track. I'm not sure how to address this, but feel free to open more specific issues like #1886 if you have further questions.. @it19862 you can omit the Language parameter to search for any language:\nc#\nvar request = new SearchRepositoriesRequest(\"mvc client side framework\");\nvar repos = await client.Search.SearchRepo(request);\nConsole.WriteLine($\"Found {repos.TotalCount} repos\");. The Page parameter is the one you want:\nc#\nvar request = new SearchRepositoriesRequest(\"mvc client side framework\");\nrequest.Page = 2;\nvar repos = await client.Search.SearchRepo(request);. Building up a DataTable is outside the scope of the Octokit.net project. I'd recommend using Stackoverflow or similar to troubleshoot.. @it19862 the GitHub API doesn't support searching for multiple languages, so it's not possible to do this search using the Octokit libraries.\n. @it19862 \"run multiple searches use the same search term with a different desired language\" is the closest you're going to get to the desired behaviour, but you might also need to do some filtering and merging of results to prevent duplicates.. @EranAvraham please ensure you are authenticating the GitHubClient as part of making the API call, and that you do have access to that repository. The examples here should help you get started.. This feels like you don't have the repo token scope set, which grants access to private repositories. More info about scopes can be found here.. I don't believe this is related to the GitHub API. @patricknolan an issue can belong to multiple project boards, so I'm not sure that's a supported case via the API. I don't expect this to make into v3, which Octokit.net relies on, but you can use the GraphQL API (v4) and query for it like this:\n\nThere's a beta C# library for it over here if you'd like to get access to that: https://github.com/octokit/octokit.graphql.net\n. Closing this out as I don't expect GitHub's v3 API to add support for this.. @patricknolan\n\nI have a repository with one pre-release created, if I use the GitHubClient to get the latest release it errors. In this scenario I would expect it to return null rather than an error.\n\nIn this case we're just mirroring the GitHub API and sending you the response we get. If you think this behaviour could be improved, this is the code to change.\nWe generally follow this pattern where we need to handle a specific exception and not propagate it to the caller:\ntry\n{\n   // code that might throw\n}\ncatch (NotFoundException)\n{\n  // return something else\n}\nI've got mixed feelings on returning null here, but that's likely because I'm not writing much C# these days. If you think that's fine, have a shot at submitting a change and ensuring the docs reflect this new behaviour..\n\nAlso, is it possible to have a get latest release and a get latest pre-release? \n\nI'm afraid not. This isn't supported by the GitHub API.\n. I'm going to second what @ryangribble said here - NotFoundException is something I'd prefer to throw here rather than returning null.. @patricknolan I restarted the problem build - let's see if it goes green. You can use the Compare two commits API to get the list of commits between two refs (up to 250 of them).\nThis does not contain the changes in each commit, but you can build up the details programatically:\n```c#\nvar @base = \"v2.5.16\";\nvar head = \"v2.5.17\";\nvar commits = new List();\nvar response = await client.Repository.Commit.Compare(\"vuejs\", \"vue\", @base, head);\nConsole.WriteLine($\"There are {response.TotalCommits} between these two refs\\n\");\nforeach (var c in response.Commits)\n{\n    var detailedCommit = await client.Repository.Commit.Get(\"vuejs\", \"vue\", c.Sha);\n    commits.Add(detailedCommit);\n}\nforeach (var c in commits)\n{\n    Console.WriteLine($\"Found commit {c.Sha} - {c.Commit.Message}\");\n    foreach (var f in c.Files)\n    {\n        Console.WriteLine($\" - {f.Filename}\");\n    }\n    Console.WriteLine();\n}\n```\nThis is what the output looks like for me:\n```\nThere are 4 between these two refs\nFound commit c28f79290d57240c607d8cec3b3413b49702e1fb - fix: fix potential xss vulnerability in ssr\n - src/platforms/web/server/modules/attrs.js\n - src/platforms/web/server/util.js\n - src/server/optimizing-compiler/runtime-helpers.js\n - test/ssr/ssr-string.spec.js\nFound commit b3c5e642295b4c0722e76fb9ba3e8bf1b8ce43bc - chore: minor tweaks\n - src/platforms/web/server/util.js\n - test/unit/features/directives/model-checkbox.spec.js\nFound commit 7e75b79b618ae8a2a4d7621306e1119c4bcbf952 - build: build 2.5.17\n - dist/vue.common.js\n - dist/vue.esm.js\n - dist/vue.js\n - dist/vue.min.js\n - dist/vue.runtime.common.js\n - dist/vue.runtime.esm.js\n - dist/vue.runtime.js\n - dist/vue.runtime.min.js\n - packages/vue-server-renderer/basic.js\n - packages/vue-server-renderer/build.js\n - packages/vue-server-renderer/package.json\n - packages/vue-template-compiler/browser.js\n - packages/vue-template-compiler/build.js\n - packages/vue-template-compiler/package.json\nFound commit 636c9b4ef17f2062720b677cbbe613f146f4d4db - build: release 2.5.17\n - package.json\n```\nHope this helps!\n. There's no unified API for this, and what's in #1906 should support most of the cases:\n\nMerge commits include the Pull Request number and look like this: https://github.com/desktop/desktop/commit/d841b98656245b0fbee07dcd6c0357f51138146f\nSquashed pull requests also include the Pull Request number, but have a different format: https://github.com/octokit/octokit.net/commit/eb9c112c032449e9a0b42fdabf54d676cde7351a\nRebased pull requests will likely have their commits rewritten, so identify their source is likely even tricker (and not something I've explored)\n\n. I'm going to close this out because it's not something currently provided in the GitHub API, and some workarounds have been suggested.. @AnoojNair because there aren't any releases listed in the repository - just the existing tags https://github.com/jashkenas/backbone/releases\nYou want to enumerate the tags themselves, which supports pagination options:\nc#\nconst tags = await client.Repository.GetAllTags(\"jashkenas\", \"backbone\");\n. @AnoojNair the third parameter in Release.Get is the release ID, not the tag itself. The API docs have more details about it.\nIf you want to get details about a specific tag you should use the Tag API:\nc#\nvar tag = await client.GitDatabase.Tag.Get(\"jorgebucaran\", \"hyperapp\", \"1.2.8\");. Offhand I'm not sure how they differ (I thought it'd be creation date but it doesn't look like that).\nPlease get in touch with GitHub Support if you'd like a better answer, because Octokit doesn't have control over either list.. > I know there are millions of users on GitHub and getting a full list in one API call is impossible, but I thing even a direct wrapper for the original all users API would help.\n@acaly if you're interested in contributing that endpoint let us know, I'm not sure how we overlooked that.\n. Also, if you're wanting to work over public GitHub data I'd look at the BigQuery data set that's available: https://blog.github.com/2017-01-19-github-data-ready-for-you-to-explore-with-bigquery/. @l1salvatore  \"Validation Failed\" is a generic error that the server sends if it can't resolve the search request. Can you provide the full snippet of code you are running that triggers the failure, so we can try and reproduce it on our end?. These are all available on the Repository API response:\nc#\nvar r = await client.Repository.Get(owner, repository);\nConsole.WriteLine($\"Repository has {r.SubscribersCount} subscribers, {r.StargazersCount} stargazers and {r. ForksCount} forks\"); . @SIkebe the code that you've linked to was last updated in 2013, so I'm not surprised the docs are a bit out of sync with that. Is there some example code that isn't working as expected? It'd be great to start this discussion around something concrete.. You need to await on the previous line:\nvar releases = await client.Repository.Release.GetAll(\"octokit\", \"octokit.net\");\nI've opened #1924 to resolve this. > Was this supposed to be a joke?\nYes. It was a very old commit in the repository https://github.com/octokit/octokit.net/commit/dafab8af04839455838cd3fde11d139174162faa. @Eilon thanks for the report and the snippet - I've been able to get this into a integration test and see the behaviour for myself. This is down to the serializing of IssueUpdate sending a null Milestone rather than omitting the field from the JSON payload if it's not cleared by the user.\nA cleaner workaround if you have the issue from the API would be to use issue.ToUpdate() which gives you the pre-populated milestone and issues ready for you to then augment, so you don't need to manually enumerate things yourself (Assignees are also caught up in this null behaviour, in case you're using that in these issues).\n```c#\nvar issue = await gitHub.Issue.Get(\"owner\", \"repo\", issueNumber);\nvar issueUpdate = issue.ToUpdate();\nissueUpdate.AddLabel(\"some label\");\nawait gitHub.Issue.Update(\"owner\", \"repo\", issueNumber, issueUpdate);\n``. @Eilon do you have a code snippet I can work with?. @bchavez thanks!. @astrohart please note that thereference` parameter has some caveats about what you can pass in:\nhttps://github.com/octokit/octokit.net/blob/8cd893d6d4a7f062871caed7a555511d45579bdc/Octokit/Clients/ReferencesClient.cs#L274. I think we did this because we envisioned the typical use case would provide just the local ref name, rather than the fully-qualified namespace for the ref. But we can re-evaluate that decision in #1934 and see if it's worth a breaking change.. One thing I'll add to this is that some API functions are associated with the authenticated user, and you could just use this to get repositories after you have credentials configured:\nc#\nclient.Credentials = ...\nvar repos = await client.Repository.GetAllForCurrent();\nI forget the defaults for this API call, but if you know what you want you can pass in additional parameters to get the sorts of repositories you need:\nc#\nclient.Credentials = ...\nvar request = new RepositoryRequest() { };\nvar repos = await client.Repository.GetAllForCurrent(request);. @mzolotarenko if you want to optimize for large data sets being returns, using a PageSize of 100 means that fewer requests are needed to enumerate all the records that satisfy the criteria (the API uses pagination underneath).\n\nBut in fact request should return about 11 records.\n\nAre you referring to 11 commits or 11 pages of commits here?. For reference: https://developer.github.com/v3/issues/labels/#list-labels-on-an-issue\n@patriksvensson seems legit - please open a PR for it. @shahabhijeet my best guess is that you're not using the right value for the head parameter. If it's coming from a fork, the head parameter needs to be of the format username:branch.. @Dre-Tas the only other example that comes to mind is downloading the entire repository as an archive (ZIP or TAR):\nvar archiveBytes = await client.Repository.Content.GetArchive(\"octokit\", \"octokit.net\", ArchiveFormat.Zipball);\nThis will return a byte array which you can then stream to disk and work with locally to extract the files you need.. @Dre-Tas we're limited by what the GitHub API supports, so I'm going to close this out now that we've outlined the options available.. /khanify comma\n. Commas do not grow on trees, y'all...\n. Is it worth testing some HTML here, like this?\n<html><body><h1>502 Bad Gateway</h1>\nThe server returned an invalid or incomplete response.\n</body></html>\n. :thumbsup:\n. Whitespace OCD\n. I do like how much this tidies up the overall code :sparkles:\n. D O C U M E N T A T I O N :green_heart: \n. > \"But I don't think we care all that much\"\nlol /nope\n. Yo dawg, I heard you like xml docs\n. Documentation?\n. My whitespace OCD is acting up a bit - can we tidy up the :this code here so it's consistent?\n. So close!\nI like this style (the first one is right, the others aren't)\n: this(new GitHubClient ...\n. Do we need to be making these changes at the same time? Can we deal with these in a separate PR?\n. Ah yes, proceed :metal:\n. @haacked it's a new line below, not deleting packaging/\n. @Haacked if we get this fixed upstream then we won't need this code, which means the ReflectionUtils method is also unnecessary. Right?\n. If that PR gets merged in, we won't have to have this hack around. \nSo I'm cool with leaving it as-is and helping get it fixed upstream.\n. There most certainly is. Thanks for reminding me.\n. Because I use the index further down.\nWill tidy up the Ordinal/OrdinalIgnoreCase. \n. \n. :thumbsup:\n. I'd prefer to keep these separate rather than have a centralized Entity (whatever it's name is)\n- it's only three properties that are common\n- what if these change in the future - then we'd have to split them\n- the class does help distinguish the role, even if it's the same data underneath\n. We should have this as test scaffolding rather than depending on a specific repo\ncc @Haacked @half-ogre \n. Sweet. I think I've got a PR here which updates this test to use generated data.\nI'll merge this one in and then get @haacked to review my PR.\n. I've consciously moved this here rather than do it in the ctor setup as it's only relevant to this test. \nAny objections?\n. Drop the regions\n. The test is also checking for empty strings - can this test name reflect that?\n. Or that\n. Create only returns a SHA, not the entire blob. This should be a different type (BlobReference?) to prevent confusion when users see missing fields.\n. kill this whitespace\n. throw a comment in here so we remember the reason for this change and don't delete it by accident\n. The API call is a PUT without data, so I think having an overload like this:\nTask Put(Uri uri)\non IConnection/Connection is perfectly reasonable\n. I'm happy with leaving it as Add because the API refers to it as \"Add Collaborator\"\n. This should be #add-collaborator here, not #get \n. This should be #remove-collaborator here, not #get\n. Drop the Client suffix from here to be consistent with the other properties\n. Merged doesn't return a response - you need to check the status code to see whether a pull request has been merged:\n204 No Content indicates it has been merged\n404 Not Found indicates it has not been merged\n. See this code for a similar example\n. These tests are expecting a GetAll<SearchCode> method, not GetAll<User> - that's why the tests fail...\nEDIT: actually, this one is correct. It's the others that are wrong, but you get the gist of it.\n. These tests are expecting a GetAll<Repository> method, not GetAll<User>...\n. :boom: the whitespace\n. These tests are expecting a GetAll<SearchCode> method, not GetAll<User>...\n. It's expecting a GetAll<Issue> method, not GetAll<User>...\n. Something like Creates or replaces the API resource at the specified URI. here\n. W H I T E S P A C E\n. W H I T E S P A C E\n. W H I T E S P A C E\n. This should be looking for something like gists/1\n. Is this necessary?\n. Let's drop it, If it comes up with the latest R# we can revisit it then.\n. a little less whitespace\n. doot\n. bamf\n. How do we want to handle \">=500\"?\n. So I just put this little spike together:\n```\npublic string MergeParameters()\n{\n    var parameters = new List();\nif (!String.IsNullOrWhiteSpace(In))\n{\n    parameters.Add(String.Format(\"in:{0}\", In));\n}\n\nif (!String.IsNullOrWhiteSpace(Size))\n{\n    parameters.Add(String.Format(\"size:{0}\", Size));\n}\n\nreturn String.Join(\"+\", parameters);\n\n}\n```\nYou still have the whole \"is it empty?\" check but I think it reads a bit better overall...\n. This line will not actually give you a response. Let me explain.\nWhen I send this:\nGET /repos/octokit/octokit.net/pulls/228/comments HTTP/1.1\nUser-Agent: Fiddler\nHost: api.github.com\nAccept: application/vnd.github.v3+json\nI get this (modified for succinctness):\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nStatus: 200 OK\nX-GitHub-Media-Type: github.v3; format=json\nContent-Length: 2\nX-GitHub-Request-Id: 836BB839:1D7D:9CEF144:528A472E\nSwitching it over to /issues/ is the fix:\nGET /repos/octokit/octokit.net/issues/228/comments HTTP/1.1\nUser-Agent: Fiddler\nHost: api.github.com\nAccept: application/vnd.github.v3+json\nwhich gives me: \nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nStatus: 200 OK\nX-GitHub-Media-Type: github.v3; format=json\nContent-Length: 9901\nX-GitHub-Request-Id: 836BB839:1D7D:9D669B1:528A4B4B\nWhy am I raising this? Because the data from the API for the Pull Request uses a mix of /pulls/ and /issues/ - the documentation only mentions /pulls/:\n{\n  \"url\": \"https://api.github.com/repos/octokit/octokit.net/pulls/228\",\n  ...\n  \"_links\": {\n    \"self\": {\n      \"href\": \"https://api.github.com/repos/octokit/octokit.net/pulls/228\"\n    },\n    \"html\": {\n      \"href\": \"https://github.com/octokit/octokit.net/pull/228\"\n    },\n    \"issue\": {\n      \"href\": \"https://api.github.com/repos/octokit/octokit.net/issues/228\"\n    },\n    \"comments\": {\n      \"href\": \"https://api.github.com/repos/octokit/octokit.net/issues/228/comments\"\n    },\n    \"review_comments\": {\n      \"href\": \"https://api.github.com/repos/octokit/octokit.net/pulls/228/comments\"\n    },\n    \"statuses\": {\n      \"href\": \"https://api.github.com/repos/octokit/octokit.net/statuses/a01857ecd5b6e1b0acb9f51a8230375c87c03f51\"\n    }\n  },\n  ... \n}\ncc @pengwynn \n. @gabrielweyer I think you might be right on this one. \nThis is why I shouldn't do code reviews without coffee - you miss tiny details like that :)\n. Deleting code? I can get behind this\n. Looks good to me!\n. Nice :lipstick: change - can we drop the whitespace between this and the other using statements?\n. As above - kill ze whitespace\n. This is something i was agonizing about too when I was reviewing this code last week.\nDo we:\n- stick to having namespaces everywhere, because That's How It's Always Been - and suffer with long test names?\n- drop namespaces everywhere for our test projects, because they're just noise around our proper test names?\nI'm tending towards the latter, but let's see what @half-ogre and @haacked think (oh, and anyone else reading this)\n. Ok, so this is evidently a deliberate thing. \nI'm not a huge fan of formatting the using statements in this way. I just ensure that they're tidy (clean up unused usings) and ordered alphabetically (except for the System.* bits). \n. The not Tha\n. The instead of Tha\n. What about a test here for the non-sub-namespace overload?\n. The instead of Tha\n. You know the drill :grin:\n. I'd love to see a syntax which just melts away all the ceremony here, like this:\nnewGist.Files.Add(\"myGistTestFile.cs\", \"new GistsClient(connection).Create();\");\nI'm :cool: with doing mapping behind the scenes to a JsonObject - given how the API expects data - but we control everything beyond that.\n. This is fine (it's something we hide from the consumer of the library), but let's cut the long line length down by moving the properties of the anonymous type onto the next line, like this:\nvar gist = new { \n    Description = newGist.Description, \n    Public = newGist.Public, \n    Files = filesAsJsonObject\n};\n. I think this file is simple enough that we can kill it off. Any objections @haacked?\n. If they add new fields to the API which are mandatory, it should require a breaking change to the API.\nLet's call YAGNI on it for now...\n. And we can work around new optional properties too - provide overloads that won't impact existing clients, provide default values, etc etc\n. Why don't we just set Files to a dictionary in the constructor (and make the setter private) so you don't have to worry about this?\n. Throw some whitespace between using statements and the namespace\n. Not sure what happened here, (merging master perhaps clobbering your changes?) but I've got a compiler error here:\nOctokit\\Clients\\RepositoriesClient.cs(15,18,15,36): error CS0535: 'Octokit.RepositoriesClient' does not implement interface member 'Octokit.IRepositoriesClient.PullRequest'\n. This has been renamed to Team in another PR. Be mindful when you merge master into this branch - your local change will probably persist.\n. Should these be properties we send across the wire? \n{\n  \"title\": \"Amazing new feature\",\n  \"body\": \"Please pull this in!\",\n  \"head\": \"octocat:new-feature\",\n  \"base\": \"master\"\n}\n. These files have now moved under Clients to make it consistent with the unit tests.\nMove PullRequestClientTests into this folder and delete any *ClientTests which are at the root.\nYes, csproj files are terrible. Apologies.\n. We have a working Trees implementation! And some tests which use it!\nHere's an example: https://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/CommitsClientTests.cs#L30\n. Kill it with :fire:\n. Using GetAsync<object> here will cause NSubstitute to fail the test because it was expecting something like this:\nconnection.Received().Get<PullRequestMerge>(Arg.Is<Uri>(u => u.ToString() == \"repos/fake/repo/pulls/42/merge\"), null);\nEnsure you've got the right overload and the right generic parameters.\n. Same with this test, I think it's expecting a different overload to the one you're using\n. Move these out to our ApiUrls class:\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Helpers/ApiUrls.cs\n. This isn't really related to a header. What about \"The request to authenticate\"?\n. We should have a summary here. What about \"Authenticate a request using the basic access authentication scheme\"?\n. While this is technically correct, for the sake of consistency I'd like this to be something like \"The credentials to attach to the request\"\nHere's an example from another PR, to contrast:\n/// <typeparam name=\"T\">The type to map the response to</typeparam>\n/// <param name=\"uri\">URI endpoint to send request to</param>\n/// <param name=\"body\">The object to serialize as the body of the request</param>\n/// <param name=\"twoFactorAuthenticationCode\">Two factory authentication code to use</param>\n. I'm being whitespace OCD right here - could you make it just one space between Token and (sent instead of two spaces?\n. It'd be great if you could document these signatures like how we document the other clients.\nThere's probably things in here which aren't relevant to your use case...\n/// <summary>\n/// Gets a specific <see cref=\"Authorization\"/> for the authenticated user.\n/// </summary>\n/// <remarks>\n/// This method requires authentication.\n/// See the <a href=\"http://developer.github.com/v3/oauth/#get-a-single-authorization\">API documentation</a> for more information.\n/// </remarks>\n/// <param name=\"id\">The ID of the <see cref=\"Authorization\"/> to get</param>\n/// <exception cref=\"AuthorizationException\">\n/// Thrown when the current user does not have permission to make this request.\n/// </exception>\n/// <exception cref=\"ApiException\">Thrown when a general API error occurs.</exception>\n/// <returns>The specified <see cref=\"Authorization\"/>.</returns>\n. Excess whitespace, nooooooo!\n. :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: :sparkles: \n. Don't forget to implement IDisposable so we clean up the repository correctly after the test (this is just an xUnit convention)\n. This should be \"repos/{0}/{1}/issues/{2}/labels\"\nhttp://developer.github.com/v3/issues/labels/#list-labels-on-an-issue\n. When you're testing NSubstitute mocks, you'll need to ensure the right generic parameters are specified.\nSo these tests should look for <Label> - that's one of the reasons why these tests fail\n. Same as above - check for <Label> here.\nOh, and the URL should be /repos/:owner/:repo/labels - drop the /issues/ part\n. Lucky last - switch to <Label> and drop /issues/ from the URL\n. The color value must not contain the leading # \nCan we do some validation in here to ensure users supply this in the correct format?\n. As above - drop the # from these tests\n. And one last #\n. You can just await on these - given we're inside an async Task test\n. So there's something in here where a new repository has a bunch of default labels for issues. So we get 8 instead of 2 in this test.\nI'll look into whether there's a way to create an actually \"empty\" repository...\n. cc @pengwynn I don't see an option here I can specify to make the repository not have the default labels\nhttp://developer.github.com/v3/repos/#create\n. I think this logic needs to be flipped, because valid inputs end up throwing the exception\n. Not that I'm a Regex guru, but could you just condense this down to:\n\\A\\b[0-9a-fA-F]{6}\\b\\Z\nand make the if statement more terse?\n. cc @haacked for his regex opinions:\nhttp://developer.github.com/v3/issues/labels/#create-a-label\n{\n  \"name\": \"API\",\n  \"color\": \"FFFFFF\"\n}\n\ncolor: Required. A 6 character hex code, without the leading #, identifying the color.\n. Could the length check be added to the Regex check? \nAnd I think the null check will be caught by the regex too so that's probably redundant here...\n. Search your feelings, this isn't necessary :grin:\n. typo in: \"lenient\" here\n\nAlso, spaces between the // and the comment text would be :metal:\n. So while I was testing this method I was seeing 100 pages of results from /gists/public\n- should we make this a smaller window? \n- we're not really checking here for a specific number of results\n- integration tests can still be fast :trollface:\n. You were right, this throws a different exception to the one we want.\nWe've been using ctor checks (like this one) to catch most of the bad input like that. Would that be worth plugging into these classes?\n. > As for the ctor check, i'm using the property setter to set the value in the constructor, \nIt'd be good to enforce such checks for the ctor anyway (\"let's send a null label name to the API!\" for example) \n. Exactly (well, ArgumentNotNullOrEmptyString specifically but I wasn't clear on that)\n. This is the label name, right?\n. Same thing, label name instead of color name\n. Ok, let's capitalize Color here (and in the other case) and I think I'm done with \"things to find wrong\" here :grinning: \n. Oh! I'm an idiot. Ignore previous remarks. These should just be the parameter names, not a description. \nSo \"name\" and \"color\" are what should live here.\n. Citation: https://github.com/octokit/octokit.net/blob/master/Octokit/Helpers/Ensure.cs#L32\n. I think the merge went bad. \nStrip out the invalid markup and ensure that all *ClientTests.cs files live under \\Clients\\\n. We have tests for creating blobs/trees/commits now!\nCheck out this test for an example\n. This depends on #173 which is getting close to done\n. Delete the whitespace here and below to make the using statements align\n. Only one newline is necessary between methods\n. Drop this newline to make the coding style consistent\n. And just one more little whitespace here\n. EDIT: nevermind, I'd rather get this in and then tidy up the docs for the next release.\n. Should these be using the XML Documentation syntax for generics?\n. I think we can just replace this with \"s\" - as this matches the ISO 8601 spec\nCitation: MSDN\n. Could you add some XML documentation to this? Feel free to base it on the other methods in this code file...\n. Some XML docs here would be :sparkles:\n. Should we be doing some pre-population of data here - and validating we get a gist back rather than just checking for null?\n. We also document the properties on the models we use for requests and responses.\nHere's an example: https://github.com/octokit/octokit.net/blob/master/Octokit/Models/Response/Gist.cs\n. Given these parameters are of type FooRequest, can we change the parameter names to request to be more descriptive?\n. Should this be something like \n\nCreates the relative URI for searching repositories \n. We've centralized these URIs in the ApiUrls class. Can you extract this to that class?\n. These tests are failing because the .GetAll<Repository> should be .GetAll<User>\n. Trim these lines at 80 char or thereabouts...\n. Any particular reason why you chose to use StartsWith and Contains rather than just hard-coding the strings?\n\nI think tests should be tolerable, but given the possible set of query terms is large, is it worth being more terse with these checks? \nEDIT: terse, not succinct. So doing d[\"q\"] == \"pub\" for example in the test above. \n. That'd be fantastic\n. Calling .ToString() on an enum will ignore whatever [Parameter] you have set, so this definitely feels like a bug.\n\nOr, will the API accept Descending as the value of the order parameter?\n\nNo, it doesn't even return valid search results\n. Because we're dropping the RequestParameters base class here, we lose this method here which was taking care of the mapping of values to the expected API parameters:\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Models/Request/RequestParameters.cs#L22\nPerhaps we need to make the other magic in that class available as an extension method, so you could do something like this:\nvar d = new Dictionary<string, string>();\nd.Add(\"page\", Page.ToString());\nd.Add(\"per_page\", PerPage.ToString());\nd.Add(\"sort\", Sort.ToParameter());\nd.Add(\"order\", Order.ToParameter());\n...\nSo we can reuse the logic across different enums...\n. Using my test account I actually have a verified email address, which fails this test.\nShould we just be checking the first email is the primary one?\n. Could we move the URLs into a <remarks> element and instead make a friendly sentence for each of these?\n. Clean up the excess whitespace here\n. Any benefits to using Lazy<T> here over just new-ing it up? \n. This one? https://github.com/octokit/octokit.net/blob/7bfbb72379b155bf74d06f4d3855b4e1c4a46efa/Octokit/Models/Response/Readme.cs#L25\nThat's an edge case because we don't want to do the rendering until as late as possible. Let's keep it simple for the moment. \n. Why not set _client here to client.Repository.Hooks here and eliminate some duplication below?\n. What about a test here that we surface a NotFoundException when the id does not exist in the repo?\n. > It's not in this direct code path, instead handled however core api exceptions are\nFair, but still a good thing to check that this client is behaving consistently, right?\n. Take your time, I'm just reviewing bits and pieces as it evolves.\nI just skimmed for other examples where we check and throw this exeption but we haven't written tests for them. \nHappy to leave it for now...\n. I don't think we need to worry about this whitespace tidy-up here.\n. This should be returning an IObservableRepositoryHooksClient to match the interface\n. Revert this change - it's no longer necessary\n. Nice :eyes:!\n. Clean up this unused using statement\n. This should be \"something\"\n. @nulltoken yes, yes it should\n. One or the other. Given we use ids in many other places, and the FooRequest entity for parameters relating to the operation - rather than the entity itself - perhaps Number should be removed instead...\n. :thumbsup:\n. A :lipstick: change - bring this back up to the previous line and let the : breathe with some whitespace\n. Just add a using System.Diagnostics.CodeAnalysis; to this file and clean up this duplication.\n. Plans to bring back this integration test?\n. :boom: this line\n. A few places that don't have the <return> value specified...\n. :fire: this down\n. Tidy up the return value docs in this file and I think this is ready to :ship:\n. > Maybe simply check that it returns an email at all?\n:thumbsup: Let's start simple and go from there\n. If you make this method return a Task then you can await on it (like you do with AssertEx.Throws) and the tests will past as part of the CI build script.\n. Finish up the returns elements here and I think this is ready to :ship:\n. Tidy up these using statements\n. Oh dear, is this the new rules in VS2013 ordering the using statements alphabetically - instead of System.* first?\n. Is it worth using await here to make this more readable? cc @Haacked \n. I'm going to singularize this to ConventionTests\n. Just adding some docs here while passing through...\n. Rx note: when you await on an observable you're doing the same thing as a .First() (which is now deprecated in Rx).\nThe test itself is just checking we get something back, which is fine, but just something to watch for. If you wanted all the results, you could await client.GetAll().ToArray()\n. > The reason for the change in default behavior is due to the fact that Windows App Store applications prefer to have \"Windows.\" at the top of the file rather than \"System.\"\n\n. Should we also be .ConfigureAwait(false)-ing here?\n. Wait, what? That seems to be related to HttpWebRequest - you're still seeing that behaviour with HttpClient?\n. \n. We should pass this cancellation token into _httpClient.Send<T> to make the FxCop warning go away...\n. FYI: https://github.com/facebook-csharp-sdk/simple-json is where to go for this\ncc @prabirshrestha\n. Let this little fella breathe a bit\n. We don't actually need to do the inner async and await for this test - AssertEx.Throws accepts a Func<Task> here and takes care of the unwrapping...\n. Same thing here: drop the inner async and await\n. :metal: to naming things better\n. :metal:\n. :metal:\n. :metal:\n. Just grab those two I've highlighted - there's enough value in here to not dilly-dally further...\n. \n. Hey! I'm saving them for a rainy day! :trollface:\n. The docs themselves are pluralized, and I know we've been explicitly avoiding this on the properties themselves. Moving that discussion over to here: #375\n. :arrow_up:\n. Because of too little whitespace at the end of the file? I'm :cool: with that, then...\n. Wait, I see this one now - wasn't visible on the summary page (?!?!?)\n\n. Assert.IsNotType<ICollection<PunchCardPoint>>(punchCard.PunchPoints) ?\n. :arrow_up:\n. :arrow_up:\n. :arrow_up:\n. Of course it does, silly me.\nWhat about an custom assert that does the opposite of Assert.IsAssignableFrom to make this a bit more descriptive?\n. :thumbsup: to IsReadOnlyCollection\n. :thumbsup: it's an implementation detail, so let's not confuse ppl\n. Oh, and we need to update SimpleJson to support read-only dictionaries at some stage...\n. I just borrowed the values from a new Windows Store App project. But it's basically project magic so whatever...\n. L O L maaaaaaybe\n. I do like this approach as we get towards 1.0 and better structure the clients. Thanks!\n. It's in the base class\n. Care about what?\n. Right, so the PR summary screen is trolling me again:\n\n. Can you update the CONTRIBUTING.md docs to include this new field? Also, do you want to support running both user and org tests in the same context?\n. Let me test to see if I can understand the why of this endpoint\n. Do we need to make this public?\n. :thumbsup:\n. I think you're right. Let me confirm.\n. Hahahaha, it makes things worse: q=phone+state:+repo:caliburn-micro/caliburn.micro\nNote how state is not defined :crying_cat_face: :crying_cat_face: :crying_cat_face: :crying_cat_face: \n. Feels a bit dirty, but should do the trick...\n. @Haacked what are your thoughts about adding in preview features like this?\n. Nice spot!\n. Should we setup a GitHub account so we can bring multiple projects under the one umbrella?\n. You need to apply the Parameter attributes to the RepoSearchSort enum above to get that last failing test passing.\nThen it's ready to :ship:!\n. ApiUrls has become a big class with everything intermixed. Moving forward, I think we should break it out so that things are easier to navigate.\n. As part of code reviews, if you're modifying/adding URLs - move it out to a separate partial class.\n. Hrm. Given how generic the ApiException is, is this worth doing? cc @haacked\n. Might as well refactor this to tidy it up a bit now you're referencing it above...\n. Or make more specific exceptions for those situations where we know a post-condition can trigger it...\n. I'm :cool: with documenting the specific ApiValidationException here in the xml-docs, while we think about how we want to do this better globally...\n. flot -> flat\n. This test is actually creating two commits - CreateTheWorld creates the first commit, and then the second commit is added above.\n. I'm curious if we can eliminate the duplication here and pass in both the octokit.nuspec file and Octokit.symbols.nuspec file here...\n. As @haacked mentioned here https://github.com/octokit/octokit.net/issues/559#issuecomment-54698236 this field is marked for future deprecation...\n. We don't need this change. :fire: it.\n. Not sure why it'd target an older version, but we can't support VS2012 or lower due to a WONTFIX issue with PCL + CodeAnalysis...\n. Once I get this build back to green I was planning to ship a release. This change will be included - it's a minor thing, but the HTML you now get back is slightly different...\n. We actually have these defined inline in UsersClient - could you update those usages to point to this method?\n. If you're feeling up for the challenge, methods which use these URLs could be implemented in RepositoryCommitsClient as the data returned should be the same format as before...\n. Good point, this is no longer necessary (and Head below!)\n. Not so sure about this one - Name is required here, and I think having a default ctor might put this entity into an invalid state...\n. If the only valid result here is true perhaps just make the return parameter here a Task...\n. I don't want to be enforcing sealed everywhere. \nIf you're brave enough to be subclassing arbitrary things, I'm not going to stand in your way.\n. My psychic debugger here thinks you were adding these by hand.\nWe have a magic script to do this: just run .\\build FixProjects from the root of the project and it'll take care of this (if you've got it all added to the Octokit.csproj file.\n. Any reason why we've added this?\n. There's a coding convention here we're enforcing via the test suite - methods with different overloads should be in the same order for the observable interface as they are for the task-based interface. \nIf you move this below the MarkAsReadForRepository(string owner, string name) method this will now pass.\n. Bring this ctor back, the empty list of Labels is used in various tests.\n. I'm not so sold on this change, for two reasons:\n- it should either be true or false as per the docs https://developer.github.com/v3/repos/releases/#edit-a-release\n- while setting these to null means the values won't be sent, I'm not sure this flow is intuitive to users (maybe this is related to the first point).\nAs I was writing tests for this area I got annoyed at the process of taking a release, editing it and then publishing the change. So that was the motivation for the Release.ToUpdate() helper method.\n. I wish I had more notes here because my memory is shot right now on why I made tagName a mandatory field.\nI suspect it's due to that \"use the one model for two operations\" issue you called out earlier...\n. :cool:\n. It's actually an accidental side-effect (we could sort on parameter counts and all that using reflection to be more tolerant)...\n. :thumbsup:\n. As this is documented under Repos -> Hooks, can this be moved to a property on IRepositoryHooksClient? \nThis will also keep the top level API less cluttered.\n. Can we get some tracing here when you don't have pdbstr in $PATH?\n. Also, any preference here for specifying the x86 or x64 version of pdbstr.exe? \n. Ok, so I found out you're choosing x64 when resolving this: https://github.com/ctaggart/SourceLink/blob/7db862a3de00599958eeb57c5a09483731647eb6/SourceLink/Pdbstr.fs :cool::cool::cool::cool::cool:\n. I'm happy to let that error bubble up to the user. :thumbsup: to dropping this check.\n. Fiiiiiiine I'll merge those together better\n. :heart: updating the test name as well\n. Is the Statistics step here a refactoring typo?\n. Any particular reason to virtual-ize these? Should we be doing it for all of them?\n. s/on GitHub/on a GitHub/\n. Yeah, I was thinking about the API field here which probably isn't right. Will update.\n. I think this change should be fine - I'm testing this on a vanilla VS2013 Update 4 VM, so perhaps this is some hangover from VS2012... \n. This is just so the files aren't committed. NuGet should skip installation if the folder exists on disk, and the caching should mean it doesn't hit the network after the first installation. :cool:?\n. Should this guard against null for EncodedContent?\n. dat newline\n. You could probably :fire: this foreach loop and populate _membersWhichShouldPublishNull directly:\n_membersWhichShouldPublishNull = propertiesAndFields.Where(p => p.SerializeNull)\n    .Select(member => type.FullName + \"-\" + member.JsonFieldName)\n    .ToList();\nBut this code is already much more simpler than what was there before :sparkles:\n. Or even make my hacky workaround go away completely \u00af\\(\u00b0_o)/\u00af\n. Urgh, I need to renew my Xamarin license and ensure everything still builds there...\n. Paranoia check: could this break if we get whitespace around the {}? (it's probably unlikely)\n. We've got a couple of different ways to dispose of repositories when we create them in the scope of an integration test (mostly I believe it's around using IDisposable in tests to use xUnit hooks.\nNot a blocker on shipping this feature, but I'd like to unify these: https://github.com/octokit/octokit.net/issues/655\n. :ok_hand:\n. :ok_hand:\n. This change reduces some resource contention when parallelizing tests (but isn't the only problem).\nDo you have any objections to this @haacked?\n. IDictionary subclasses IEnumerable, so some of our tests which return Dictionary<T1,T2> were being caught here and deserialized incorrectly.\nFeel free to submit a PR to make this a bit more cleaner.\n. Just tidied up this function to behave like GetEmoji while I was in changing IDictionary to Dictionary\n. I'll clean that up against master once this is merged in.\n. Someone would need to convince me of the value of GhostDoc -  I have nothing but bad memories from the time I last touched it.\n:thumbsup: to ignoring for now\n. Add in a test for this commit - it has multiple statuses, so you can test that we're handling collections correctly: https://github.com/libgit2/libgit2sharp/commit/f54529997b6ad841be524654d9e9074ab8e7d41d\n. R# 9 update?\n. IReadOnlyList<CommitStatus> here\n. Also, I can see a Task.Factory.StartNew inside HttpClientHandler.SendAsync that also causes contention (I see four requests enter, but none complete). \n\n. Until I get around to codifying a R# settings file for it, let's :fire: these automagic changes...\n. :ok_hand: \n. s/Has/Have\n. s/Has/Have\n. :heart::heart::heart::heart::heart:\n. Is MediaTypeType necessary here, or just a refactoring mistype?\n. This seems to be the only property that didn't survive the refactor intact. Any particular reasons why?\n. This was marked as [Obsolete] (probably by me). Do we need it?\n. Let's use the same rule that's in the official repo: *.ide/\nhttps://github.com/github/gitignore/blob/master/VisualStudio.gitignore#L22-L23\n. Remove this line\n. Remove this line\n. Not sure how I feel about adding in public default constructors. @haacked?\n. Yes, that would do it :metal:\n. Yeah, that's fine. I'll run the tests for this and confirm it's all kosher.\n. Yeah, this bit me upgrading to vLatest this week. \nI didn't mind calling out CancellationToken.None for these few usages, so I guess I'm debating cosmetics and shortcuts here. Happy to bring it back :tada:\n. :thumbsup: to lazy, that work hasn't made it into a GHfW PR yet.\nIf I get caremad about it again, I'll PR it separately.\n. This is just the integration test project being nested. I'll undo this, not a blocker.\n. Do we need this to be public? The namespace intent is confusing me...\n. Tests are :sparkles:, just giving this another :eyes: \n. As above, do we need to make this public?\n. Ideally I'd like everything under Octokit.Internal to be marked as internal - my thinking on this is that if there's a compelling case to make a type public, it shouldn't be in this namespace.\nHappy to do a once-over on this after this PR (before the next major release), just calling this out as it's a new type.\n. Rather than introducing extra abstractions for GitHubClient and RepositoryClient, you could do this inside CreateDisposableRepository:\nvar repository = await client.Repository.Create(newRepository);\nreturn DisposableRepository.InitFromRepository(repository);\n. I'd love to not need the inheritance in this class, but instead have tests access the repository directly through a property, e.g:\npublic class DisposableRepository : IDisposable\n{\n    public Repository Repository { get; private set; }\n    public static DisposableRepository Init(Repository repository)\n    { \n         var disp = new DisposableRepository() { Repository = repository };\n         return disp;\n    }\n    /* IDisposable code here */\n}\nBut that means we'd need to change the tests to read that inner property. I'm somewhat neutral on which approach is better, but the reflection code in here concerns me a bit.\n. :cool:\n. I'll cut a release branch for All The Breaking Changes before merging this, so we can think on this issue further.\n. :ok_hand: \n. Rename this to Initialize - I think there's enough detail from the API surface to indicate we're working with repositories here.\n. Yes, this should include the owner property.\nFor example, https://api.github.com/search/code?q=addClass+repo:jquery returns a validation error. But https://api.github.com/search/code?q=addClass+repo:jquery/jquery returns an array of results.\n. @joshvera my testing of this (and a part of the HTTP spec I neglected to recall) indicates that the first match of an Accept value is the one the server will use. In this case, we'd need to put the preview API first.\n\n. I'm not so sold on this name. AccountType is used for a certain request, but Org doesn't map to Organization.\n. This is now in-flight https://github.com/octokit/octokit.net/pull/702\n. Sorry, I should have been clearer here:\n- This link indicates when using the Search APIs you use type:org in the request parameters.\n- This link shows the response you get back has \"type\": \"Organization\" in the response when searching on users or organizations everywhere else.\n. :ok_hand:\n. If you could throw a Skip on this test, it'd be greatly appreciated - this test is going to run for a long, long, long time\n. The biggest change from where we were is the XunitTestCase ctors - I stole this code from the https://github.com/xunit/samples.xunit repo.\n. I'd like to add skipped tests to the repo with a helpful message to explain why it's occurring, but for now I'm cool to drop this...\n. less hacks, less upset\n. You can add Forkee to the CustomDictionary.xml to make this error go away\n. I'm not sure why these references are necessary.\nCould you :fire: this one and the one in Octokit.Tests-Portable?\n. :fire: unused reference\n. Can you drop all this excess namespace and just have Octokit here?\n. :arrow_up:\n. :arrow_up:\n. :arrow_up:\n. :arrow_up:\n. :arrow_up:\n. :arrow_up:\n. :arrow_up:\n. Would it be worth extracting this to an extension method for better readability?\n. Not something I'll block this on. I wonder if @haacked has any opinions on this.\n. Suuuuuuuuure :P\n. This might also be how we support different media types in the response without hard-coding :shit: everywhere. Added a task to explore this further.\ncc @ammeep @thedillonb \n. So I could :fire: this awaiter and make the user call .ToTask() for these methods.\nIt's less magical, but takes away the hot/cold issue.\n. Yeah, I'm not sure I can magic up a type here that's both Hot and also modifiable using WithOptions.\nSo I'm weighing up varying degrees of breaking changes to see how they feel.\n. > The API itself has changed from hot to cold and existing code now needs to .ToTask()\nYes, any existing API calls will no longer magically work with await. So you're updating anyway.\n. :memo: a summary for this method?\n. Is it worth asserting the action succeeded here?\n. :memo: a summary here for the method?\n. :cry:\n. Just general sadness at the need to SelectMany. It's fiiiiine.\n. Octokit.Tests.Conventions.ModelTests.ResponseModelsHaveGetterOnlyProperties(modelType: typeof(Octokit.License)) [FAIL]\n      Assert.True() Failure\n      Stack Trace:\n         Octokit.Tests.Conventions\\ModelTests.cs(31,0): at Octokit.Tests.Conventions.ModelTests.ResponseModelsHaveGetterOnlyProperties(Type modelType)\nFinished: Octokit.Tests.Conventions.DLL\n. :star2:\n. :lipstick: indenting\n. I'm indifferent on which way is correct, but either this one is right or the new code below is right.\n. :sparkles:\n. :sparkles:\n. That sounds about right, but they're calling the right API there at least...\n. I think this test is going to run forever, but I'll mute this as part of preparing the next release\n. :lipstick: Assert.NotEmpty here to make these two statements redundant\n. :lipstick: Task.FromResult here there and everywhere?\n. Would it be worth making this a required parameter?\n. :fire: unnecessary using statement\n. :fire: unnecessary using statement.\n. :grey_question: we've turned off parallelization here as part of running the integration tests, so these guards aren't necessary. Do you think they're useful to have anyway when running these hooks tests?\n. Ah, now I'm seeing the other valuable part!\n. cc @haacked as this might be a better way for us to simplify the setup and teardown of repositories in tests that we were throwing around in #655 \n. Swap these out in the new tests for the Assert.ThrowsAsync<> that ship with xUnit 2.0 - it'll mean the inner async/await goes away as well...\n. Opened https://github.com/octokit/octokit.net/issues/782 to address this in our other tests.\n. :lipstick: make the contents of the property definition a oneliner\n. :lipstick: make the contents of the property definition a oneliner\n. Inside our serializer we'll take the C# values and lowercase them, so these overrides aren't really necessary.\nWhere they do become helpful is where you want to show a completely different value.\nFeel free to drop them.\n. If we don't need to send any data with the payload for a POST, can we live without this class?\n. As above, if we've got an empty class here I think we can just do away with it for now.\n. Ok, now that I understand the reason for the empty classes let me see if I can suggest an alternative:\nGiven both these methods should return 204 No Content, should we be inspecting the response code? With many of our Delete actions we use Task<HttpStatusCode> to check that nothing unexpected happened (see WatchedClient.UnwatchRepo for an example).\nWe don't have an equivalent overload for Post right now that fits this scenario, but given you have two scenarios here which seem to fit it I think it's worth incorporating.\ne.g:\n/// <summary>\n/// Performs an asynchronous HTTP POST request.\n/// </summary>\n/// <param name=\"uri\">URI endpoint to send request to</param>\n/// <returns><seealso cref=\"IResponse\"/> representing the received HTTP response</returns>\nTask<HttpStatusCode> Post(Uri uri);\nThoughts?\n. Could we just use object here? \n. Or could we make it a collection type that helps the user understand what sort of payload they're sending?\n. Same question as above - I think this could be a dictionary of string pairs\n. :memo: this should remain as TwoFactorChallengeFailedException\n. :lipstick: indenting\n. I think this should also be Post as per https://developer.github.com/v3/oauth_authorizations/#create-a-new-authorization\n. I really really really think this should be a Put as per https://developer.github.com/v3/oauth_authorizations/#get-or-create-an-authorization-for-a-specific-app\n. This should be Authorization not Authentication :lipstick:\n. And this one :lipstick:\n. Wait, what?\n. :lipstick: the inner async/await pair can be scrubbed from these files, i.e. () => client.Forks....\n. :fire: unnecessary using statement\n. :lipstick: drop the inner async/await pair for these\n. :lipstick: just use Helper.GetAuthenticatedClient() for these integration tests\n. Because we maintain an set of IObservable<T> APIs that mirror this, the build server is currently complaining.\nTo fix this, you'll need to add the new method to IObservableRepositoryContentsClient and implement it over there too.\n. This should be IObservable<RepositoryContent>\n. Check the method above and steal the GetAndFlattenAllPages code to unwrap this list\n. Just a heads-up - this change also traps application/json output which breaks serialization (I should have caught this). I've updated it for the latest release to be more strict: https://github.com/octokit/octokit.net/blob/master/Octokit/Http/HttpClientAdapter.cs#L86\n. In #771 we added a rule to the test suite to ensure all methods which returned a IReadOnlyList<T> were named with the prefix GetAll - if you update this name and the related observable method name you should be :sparkles:\n. Change this attribute to [OrganizationTest] so that it only runs if you have the right environment variables set :metal:\n. I had a look into this, and it turns out the rule is working this way due to:\n- open brace always on a newline\n- close brace (where trivial) is moved on to the same line\nIf someone wants to fight me on this and put it back, they're more than welcome to poke around and see if they can fix this over on my CodeFormatter fork - it's BraceNewLineRule you want to look at...\n. @darrelmiller I'm almost inclined to obsolete request.AllowAutoRedirect and simplify things - as we need to control this behaviour in our very specific way. Any objections?\n. It was one of the first things I'd removed when refactoring earlier attempts. Good enough for me :fire::fire::fire::fire::fire:\n. Fun fact - you can also have Add(string nameWithOwner) here and both sorts will happily work with the collection initializer syntax.\n@haacked should we support both? I still like the succinctness of writing them inline rather than splitting them out...\n. :thumbsup: to more specialized collection\nNot sure if the PCL library might get in the way of using a concrete class here though...\n. Looks like these files need to be unified...\n. While I love the explicitness here, I think letting this fall through to the Assert.Equals is totally fine to simplify the tests...\n. I think this can live outside the #if\n. Does this need to be public?\n. I'm not sure where we ended up with this - is it ResourceRateLimit or RateLimit?\n. Yeah, I don't know why we'd need this set. Nice spot! \n. I wonder if this will be reverted the next time I run it through the FAKE build script...\n. This was a regression in #860 as ResetAsUtcEpochSeconds is the source of truth from the response (I should have called out the ignoreThisField earlier). Anyway, the test caught this so yay tests!\n. :thumbsup: done on line 182\n. l o l\n. Do we need to pass in the MONO flag here?\n. via @haacked from some other PR:\n\nYeah, they probably should inherit from ApiException.\n. via @haacked from some other PR:\nYeah, they probably should inherit from ApiException.\n. :thumbsup:\n. Should this be named GITHUBOWNER to indicate this is specific to the GitHub API (rather than the Git repository)?\n\nAnd octokit is an organization, so this is just going to fail miserably with the default. Not sure what to put here, so let's leave it empty.\n. GITHUBPASSWORD?\n. I can see it's also used to find the right remote (I have both my fork and the upstream octokit repos tracked as remotes, so perhaps this needs to be two variables?\n. OCD: GitHub not Github\n. This seems to be working on Mono master - is there a specific build we should be using here to ensure this works on Mono, or is it too early to rely on this fix being present?\n. Apologies, I wasn't clear.\nI was suggesting this be renamed from GITPASSWORD to GITHUBPASSWORD.\n. :ok_hand: \n. I wouldn't worry about other types here...\n. :lipstick: bring this up to the previous line, and a space after the ,\n. :lipstick: align all of these with a trailing , on each line (where relevant)\n. This seems unrelated to the other changes - could you add it back in?\n. typo: Arbitrry -> Arbitrary\n. This test description should mention that it's interested in the markdown endpoint.\n. :lipstick: insert a newline between the { and the [Fact] to give each test some space\n. :thumbsup:\n. And here\n. And here\n. And after this line\n. If we're demonstrating DateRange here could we drop this usage and just include DateRange.Between here?\n. This seems a bit basic - could we jazz this up a bit?\ne.g.\n\nTo search for repositories using Octokit you need to create a SearchRepositoriesRequest and populate it with the search criteria.\n. It'd be nice to have an example below this around how to use this with a GitHubClient, if only to see something like:\n\ncsharp\nvar results = await gitHubClient.Search.SearchRepositories(request);\nor whatever it's supposed to do...\n. > That's cool, would this be better served at the top?\nYeah! Let's do that!\n. :lipstick: single here should work fine too\n.await?\n. And should this be _after_ therequestctors defined below?\n. Let's not worry about the comment here.\n.SearchUsersRequest. :thumbsup: I think we should keep this second line around instead of both\n. Could we clean this up so it looks like theString.Equalscall above?\n. I might have been too eager with this, given you needEndsWithto verify this. Disregard.\n. Duplicated file (it's also underModels/Common) - the newproject.jsonfile found this twice and it triggered a compilation error.\n. I'm not 100% clear on this value - if this is disabled, it would mean packages aren't created for PRs - which is the inspiration for this change. Or am I mis-understanding something?\n. :lipstick: perhaps make this singular i.e.LatestRelease. The convention with previous release entries has been \"#PR via @author\" - could you bring the #PR forward for each item?\n. Double ## here\n. This should be the final URL - https://travis-ci.org/octokit/octokit.net - could you update this badge?\n. Do you see the \"No builds for this repository\" message at that above URL?\n. :lipstick: this namespace doesn't seem necessary\n. :lipstick:The version of the product(i.e. drop theGets`)?\n. As this is a response object, this will currently fail our checks for public setters.\nFor serialization purposes, protected set will work fine - but we also define ctors (like in Branch above) for scenarios where you may need to set it up in a certain way.\nYou can see these failures by running this from the repo root:\n\n.\\build BuildApp\n.\\build ConventionTests\n. :arrow_up: as above\n. I'm also seeing this property fail the convention test but this makes zero sense. Perhaps we're not liking private set here?\n. > I guess the difference is that IssueUpdate is a Request model object, whilst in this case the RequiredStatusChecks are in the Response section?\n\nThat's exactly right - there's some PATCH specific behaviour around labels, and that's the solution we ended up with.\nFor response object, I wouldn't worry about the Add* and Clear* methods - a ctor which accepts a collection to use is going to be easier for consumers to work with around testing...\n. Sorry to jump in here before this goes further off the rails, but thanks @khellang for reminding me about the intent of this test.\nICollection<T> has the mutable Add, Remove and Clear - so even if it's a read-only property, it can be manipulated arbitrarily after the object is created. We're trying to discourage that, so we use IReadOnlyList<T> on our collections.\nAn example of that is CommitActivity - https://github.com/octokit/octokit.net/blob/master/Octokit/Models/Response/CommitActivity.cs - if we could update RequiredStatusChecks.Contexts to be a more specific interface than ICollection<T> and then drop this change we should be able to get back to a green build...\n. Can you keep this [Fact] around with the Skip attribute set?\n[Fact(Skip = \"See https://github.com/octokit/octokit.net/issues/1011 for issue to investigate this further\")]\n. :lipstick: this just seems to be some mixed up \\ and / path separators - can we unify these?\n. @naveensrinivasan sorry, I should have been clearer here - these new entries are just duplicates of previous ones - can you :fire: them to simplify the diff?\n. :thumbsup:\n. The licenses API? Yeah, there's two usages in MiscellaneousClient which could use a bit of :lipstick: to tidy up at some stage.\nLet's define a field on the test class which gets reused here, and then look at the other usages separately.\n. Eh, I'll clean this up after master goes green again.\n. :lipstick: Perhaps make this message a bit more concise:\n\nNotifications are now available under the Activities client. This will be removed in a future update.\n. See other comment about obsolete message\n. Should we make this a bit clearer and use xml-doc notation on the Credentials property in here?\n. :thumbsup:\n. Let's name this something like StableVersion as its the replacement for the releases API now that's out of preview\n. This is related to repository redirects and then the latest stable version - could we rename it to something like RedirectsPreviewThenStableVersionJson ?\n. It can probably be cleaned up so that the defaults are loaded in...\n. :lipstick: move this up outside the namespace with the other usings\n. :lipstick: indenting\n. Nice spot! :heart:\n. :lipstick: clean this up\n. Could we swap these calls to await ApiConnection.Get<AdminStatsRepos>(endpoint)?\n\nMight also need a .ConfigureAwait(false) if we're not doing this inside the connection...\n. Is this necessary?\n. The empty ctors. I ask because we've gone back and forth on how the response models should be structured in the past - previously the properties were public set-ers, but then we switched over to protected set to indicate which were required.\ncc @haacked for feels\n. The main benefit for using protected set was around testability, but I'm not sure that's so important now in hindsight...\n. Ugh, that's a good point - I had a look at some other response models and found they also have an empty ctor - hold off on making that change, I'll let @Haacked refresh my memory here...\n. @Haacked thoughts on how we could simplify this method?\nFor reference, here's the signature from the docs:\n\nAnd it seems like we're stuck with getting a loose dictionary of values irrespective of the endpoint we use.\n. Were these raised because of specific errors with tests?\n. Unless there's a unique resource here, these can safely drop the Builds prefix to be consistent... \n. I'm happy to refactor this to be GetLatest and drop the unnecessary suffix\n. :thumbsup:\n. @ryangribble thanks for the extra context. I'm not feeling strongly either way at this stage, I was just reflecting on how we don't really have a good example of another API that passes in an enum like this.\nFor most of the existing API endpoints the parameters are bundled up into a single class - the XYZRequest overloads - but that's not really useful here. Whether you go with one method taking an enum of N values, or N methods each representing one endpoint, the only differences beyond the semantics are:\n- does one or the other make more sense to the consumer?\n- does one or the other make the implementation code easier or harder?\nFor me, I think it's a little weird to always get an AdminStats response model back, even if I only asked for users. After the first time it failed, and I'd go \"ah, I want the Users property\" and update the code, but I'd love to :fire: the friction off completely.\nDo you think we'd get reuse from the existing response models you've created if we went down the \"one method per endpoint\" scenario? It's going to introduce more methods, but I think they'll be a lot more succinct (and simplify the tests a bit) if we can leverage the serialization cheats we've got to just get back the data we need.\n. Uh, cool? :thumbsup:\n. Can has some words?\n. Unique to GetAll\n. @ryangribble all good, and understandable :grin:\n. This will need a rename (and to call the right method on IRepositoryPagesClient)\n. Drop the Builds suffix from here as well\n. Not sure how these tests should have passed before the merge, as I managed to break an old PR when I merged master back in. See 5ca6633cb133ca8db4f2be17c2ebb0e26a446d64 for the fix to these tests.\n. Nah, I'll merge that first pass at the documentation into master - so the fix will land there soon.\n. :lipstick: duplicate sets of braces here\n. :heart_eyes: this is a great idea\n. :grey_question: rather than the abbreviation, would it be worth just prefixing these properties with Enterprise to make this a bit more readable? Or is that redundant given we're already in EnterpriseHelper...\n. :grey_question: I kinda liked having ENTERPRISE in this environment variable - could you tell me about what motivated this change?\n. This is a good bit of :lipstick: :thumbsup:\n. :heart_eyes: :heart_eyes: :heart_eyes: :heart_eyes: :heart_eyes: :heart_eyes: :heart_eyes: \n. :thumbsup:\n. Editor's note: we're not quite on C# 6 here :cry: \n. Perhaps we can catch an ApiException below and interrogate the headers there...\n. s/workink/working/\n. s/Branche/Branch/\n. The only reservation I had was that this value was being used elsewhere and some enum values depended on this, but then I saw those places were calling RemoveHyphenAndUnderscore and saw it had us covered:\nstatic string RemoveHyphenAndUnderscore(string stringValue)\n{\n    // remove '-' from values coming in to be able to enum utf-8\n    stringValue = stringValue.Replace(\"-\", \"\");\n    // remove '-' from values coming in to be able to enum EventInfoState names with underscores in them. Like \"head_ref_deleted\" \n    stringValue = stringValue.Replace(\"_\", \"\");\n    return stringValue;\n}\n. Is it worth doing any cleanup here after creating the organization?\n. :lipstick: as observable is only used here you can await the previous line:\nvar organization = await _github.Enterprise.Organization.Create(newOrganization);\n. :thumbsup:\n. Of course as soon as I realised that I should read the documentation I realise that \"there's no endpoint\". So that's a pretty good reason to not do that. Nevermind.\n. :thumbsup:\n. The contents of this class have fallen out of the refactoring to get pagination into the app.\nI found myself duplicating this for the Task and Observable APIs, so this ended up as the simplest abstraction that could do both.\nPerhaps I'll go further with the refactoring to get this feeling more natural, but for now it does the job.\n. I'm somewhat concerned about this becoming a \"bucket\" to put all the stuff we don't really know how to put elsewhere, but ultimately this is what the user should pass through to the library to tweak the defaults.\n. I feel so awful about this escape hatch. But _nextPageFunc() currently returns a task to indicate it has results. There's no real equivalent here to indicate we should bail out, so I'm going down this path.\nThankfully tests caught some stupid things I'd assumed, like null.ConfigureAwait(false) is a dumb idea.\n. If I get a :thumbsup: and land this PR, I can then run this test and extract tasks to get things update accordingly.\nFor now, it's not so noisy...\n. Also, that should say Enable instead of Disable.\n. We haven't implemented IEqualityComparer on the response models, so I'm being lazy here.\nIf anyone else cares about this I'll take it to a separate discussion.\n. @ryangribble good point - yeah, I'll undo this change\n. I shouldn't need to pass null in here. I'll investigate further and see what other options I have here.\n. :boom: https://github.com/octokit/octokit.net/issues/1109\n. The suppressed messages here and my OCD feelings about abbreviated names makes me wonder if this is something we could do better. Or do you think LdapDn more broadly acceptable than LdapDistinguishedNames?\n. Alternatively, I think this could be added to the CustomDictionary.xml at the root of the repository.\n. I think we can get away with dropping the async/await pair here, right?\n. I think we can get away with dropping the async/await pair here, right?\n. @BigAlInTheHouse I'm not sure I follow\n. Let's tweak this message: Press Y to change this value, otherwise we'll move on\n. This is an old comment from before I actually implemented the optional parameters. Feel free to remove this :fire:\n. :thumbsup:\n. I like the former link, but they're both focused on interactions with the website - perhaps we can just rewrite this paragraph...\n. Godddd who wrote this? What a bunch of nonsense and crimes against grammar.\n. Done in the Slow Tests section. Not sure how this comment ended up here shrug\n. Moved this up into the previous bullet list so it's literally the first thing you see...\n. Weird, it's working for me now:\n\n. I rewrote this whole section to just have CLI instructions (and ensure they have latest master). Let me know how it feels to you.\n. This test will likely break if the user's account has more than one account - what about if we just did a Assert.NotEmpty(emails) here too?\n. This one is less likely to break than the previous one, but let's drop it anyway...\n. Nice spot!\n. Could we add a verb to this method? Say something like GetSha1?\n. Make this async Task as this is more test-runner friendly...\n. I'm not sure how much this will break, but I'd love to get the Reference that CreateTheWorld returns - it should contain a Sha.\nSo rather than invoking GetSha1 twice below, you invoke it once and compare that SHA to the one you have here.\nDoes that make sense?\n. And the CI test won't fail like it currently is...\n. Given this is a \"virtual\" group of contributors and spanning just about all the continents, I'm open to elaborating on what this might mean to our situation. This also feels like a bit of a catch-all phrase, so perhaps we can be more specific here. \nWill ponder on it, but open to suggestions...\n. Not sure how this got introduced (I've seen VS do this from time to time, and it's not exactly repeatable). Are you able to revert these?\n```\n\nset this file to whatever is on master\ngit checkout master -- packages/repositories.config\namend this comment\ngit add .\ngit commit --amend\nforce push to rewrite this PR\ngit push origin misspelt-documentation --force\n``\n. :lipstick: let's make thisAssert.NotEmpty(membersInBoth);. Can you change this method signature to be(owner, name, reference, options)?\n. Nice catch!\n. Apologies: I inverted this assert earlier - this should beAssert.Empty. We should be able to get away with just using theGetAlloverload that takesendpointandoptions, right?\n. Rather than duplicating all these rules,GetAll(owner, name, reference)should just callGetAll(owner, name, reference, ApiOptions.None). This comment seems to be incorrect - it's used for issues/milestones/pull requests.\n. Don't worry about the quotation marks here\n. If we're going to[Obsolete]All` here, or just remove it, we should update the docs accordingly...\n. Personally I'd lean towards \"no\", but I'll let @Haacked chime in here as well and see if we agree or not on this...\n. Given not all of the tests need this range of commits, do you think it'd be useful to introduce some new code here for the more complex deployment scenarios?\n. Don't change this to call the same code that the app does - let's keep this as-is to verify we're also formatting the URL correctly...\n. > I think of these as being like contracts. I want them as close to the call-site as possible. \n\n:thumbsup:\n. Sorry, I should clarify this before you go and fix it:\n- The line below is very similar to the actual implementation inside the new GetAll method you've defined. So rather than call _connection.GetAndFlattenPages<T>(...) here, why not just call GetAll(owner, name, reference, ApiOptions.None); here?\n- We've been discussing what to do with the Ensure usages in the case where we call a different overload. We've settled on keeping these around, even if they are duplicated checks. So don't clean them up here.\nMake sense?\n. @dampir while I like making this initial code more generic (and extending it to do multiple commits) I think we can extract this from the constructor and just have a standalone method or methods.\nA couple of reasons:\n- we're creating 6 commits for every test run, even though many of them only need one\n- by moving the creation of the commits closer to the test itself, we can make the intent clearer\n- we're doing a lot of .Result here, which blocks the current thread as you can't await in a constructor. By moving this async code closer into the test itself, we can leverage async/await better - which the test runner supports \n. @SamTheDev here's the related discussion https://github.com/octokit/octokit.net/pull/1218#discussion_r57460248\n. You can use Assert.False or Assert.True here to make these a bit more succinct.\n. Assert.True or Assert.False in this test too\n. Given this usage will look like this:\nawait github.Issue.LockIssue(\"owner\", \"name\", 1);\nPerhaps we can drop the Issue suffix here, to give:\nawait github.Issue.Lock(\"owner\", \"name\", 1);\nThoughts @haacked @ryangribble?\n. As per the blog post we need to pass in a custom Accept header here (as well as for the Unlock action below)\n. Let's put this back to their expected format, instead of using ApiUrls here.\n. Let's put this back to their expected format, instead of using ApiUrls here.\n. Like we mentioned earlier, can you bring back the Ensure arguments for owner and name here?\n. :lipstick: indenting (and bring the null onto it's own line)\n. :lipstick: indenting (and bring the null onto it's own line)\n. :lipstick: indenting (and bring the null onto it's own line)\n. I'm not a fan of using _ or m_ prefixes for private fields like this. Could you change this back?\n. Like we mentioned earlier, can you bring back the Ensure arguments for owner and name here?\n. :lipstick: this should be TheGetAllMethod\n. We should be checking retrieved.Locked here, right?\n. retrieved.Locked here too\n. Actually, you should be returned the updated Issue from Lock and Unlock here - to simplify this test (and do less network calls) you could assign this returned value to retrieved...\nEDIT: nevermind, I didn't understand the API correctly. Disregard this, but we need to change the method signature for Lock.\n. This is not quite the right overload, and sadly ApiConnection doesn't quite have an easy way to do this.\nThis works for me:\ncsharp\nreturn ApiConnection.Put<Issue>(ApiUrls.IssueLock(owner, name, number), new object(), null, AcceptHeaders.IssueLockingUnlockingApiPreview);\n. This endpoint doesn't return any data, so it needs to return a Task.\n. This isn't the right overload, and we don't have an equivalent that let's us specify an Accepts value.\nWe should add this to IApiConnection and implement it, something like this (the name is the least-worst option that came to mind given it'll clash with the other :cry:):\ncsharp\nTask DeleteWith(Uri uri, string accepts);\n. Can you add the Ensure argument for org here?\n. Given master will actually change over time, we'd need to be careful here about what we're testing.\nFor example, you could lock this to 1335f37c6cde55de09c086cda283e70e0dfc339e which has 5 statuses and won't change. This means the first three tests will pass currently.\n. Given we're working with five commit statuses, you could change this PageSize to 2 so that you can get these other tests working as expected...\n. Swap options out for Args.ApiOptions here\n. :thumbsup:\n. > we could just go with adding an overload for Delete(Uri uri, object data, string accepts) and then pass null as the body\nI don't think we can pass null here, but everything else is :thumbsup: from me\n. asynchronously\n. asynchronously\n. These are going to be breaking changes for the unfortunate few which might be trying to use these - we need to leave the old ones around and mark them as obsolete\n. This test will fail as we changed the page size above...\n. Yes please\n. Let's make this really specific - what about something like: [Obsolete(\"Please use the IGitHubClient overload constructor\")]\n. This is a coding style thing, which is cool and all but there's no other changes around here.\nCan we revert this to simplify the diff?\n. Is this a necessary change?\n. We should probably check (\"\", \"name\", ApiOptions.None) and (\"owner\", \"\", ApiOptions.None) as well\n. :fire: this file\n. Do you know what this rule represents?\n. It looks like we're not asserting anything about this object, so I think we should revert this change. :cool:?\n. Could we assert something here about the commit title or message versus what we actually committed, to indicate this was squashed?\n. One suggestion - look at the commit:\nvar commit = await _github.Repository.Commit.Get(_context.RepositoryOwner, _context.RepositoryName, result.Sha);\n// TODO: something interesting goes here\n...\n. This will be handled by the next FormatCode call, so let's :boot: addressing this...\n. This is the eternal struggle between the FAKE script and FormatCode - see https://github.com/shiftkey/Octokit.CodeFormatter/issues/2 for how I'd like to tackle this...\n. Need to Ensure things here as well\n. > Should we be passing ApiOptions.None rather than null? \nYes\n. > I wonder if there is a cleaner way to rationalise all the overloads here to just call through to one implementation method\nI think this is achievable if we make this new GetPagesWithOptions<T> method the endpoint. I'll call out in other places how we can achieve this.\n. Actually, just make the body of GetAndFlattenAllPages<T>(this IConnection connection, Uri url, ApiOptions options) call into your new code:\ncsharp\nreturn connection.GetAndFlattenAllPages<T>(url, new Dictionary<string, string>(), options);\nThis should then leave you with the obsolete GetPagesWithOptions<T>(Uri uri, ApiOptions options, Func<Uri, ApiOptions, IObservable<IApiResponse<List<T>>>> getPageFunc) which can be safely deleted.\n. I don't believe the test failure is related to this PR.\nHere's what I can see: https://github.com/octokit/octokit.net/issues/1251\n. I think this one was overlooked with the cleanup\n. Make this class public, I think the test discoverer will miss these currently...\n. This one is interesting as my test account doesn't have any followers. Not sure how we should handle this...\n. :lipstick: you can use Args.EmptyDictionary and Args.ApiOptions here rather than the NSubstitute-specific mocks\n. We're close to getting this in, so I think I'm less worried about making this change here...\n. This all seems fine, and the integration tests are working fine on my side :shipit:\n. :lipstick: use Args.EmptyDictionary and Args.ApiOptions here rather than the NSubstitute-specific mocks\n. Oh yes, this isn't your fault. I'm just thinking aloud here about how to make these tests more adaptable to other contributors...\n. Do you think we could simplify the parameter creation to one local variable, rather than creating new values everywhere they're used?\ne.g.\n``` csharp\nvar header = new ProductHeaderValue(\"UnitTest\");\nAssert.Throws(() => new GitHubClient(header, (ICredentialStore)null));\n```\nThis might help with the readability of these tests...\n. typo: Respository -> Repository\n. So close - this should assert \"repos/fake/repo/commits\"\n. We're having an ongoing discussion about dropping namespaces from all our test classes - https://github.com/octokit/octokit.net/issues/1208 - it kind of goes against the standards for .NET but we think it has some benefits in places like the test runner output.\nAre you able to drop this namespace and re-indent this file? It should simplify this diff a bit as well...\n. As mentioned below, can we drop this namespace from our new test class and re-indent this file?\n. I like DictionaryWithApiOptions for the general case, but these feel very specific to gists.\nShould these live here, or do you think they should live closer to the tests themselves?\n. Nice spot :sparkles:\n. And nice work fixing up these too!\n. @SamTheDev if you feel like they are being used many times and the readability is necessary, define them in the classes. Otherwise just inline them.\n. We'll circle around to that later and get R# to play along (I'm pretty sure that's R#, it is on my machine at least)\n. Did this change get lost?\n. Nice spot! :eyes:\n. This should be using something in the Octokit project, right? So something like IGitHubClient?\n. Yep, I'm missing some context here https://github.com/octokit/octokit.net/pull/1246#issuecomment-206358328\ncc @ryangribble \n. I think these should all be [IntegrationTest] to ensure they only run when you have an integration test account setup.\n. Trying to think of a more succinct way to describe this, but coming up empty \ud83d\udc4c \n. Semantics, but perhaps Dictionary<string,Action<SearchIssuesRequest, DateRange>> instead of crafting tuples?\n. :thumbsup: just my 80-chars-per-line OCD acting up. I'll undo this.\n. yes, yes we are\n. I think this is a side-effect of .\\build FormatCode - I'm tracking this in https://github.com/shiftkey/Octokit.CodeFormatter/issues/2\n. :lipstick: rename this to .PullRequest\n. Don't forget to pass options in here...\n. :thumbsup: one property per line\n. I think the only issue I have with this PR is that we've changed the behaviour of the existing GetAllForRepository method. This is fine, we just need to call it out in the release notes.\n. @dampir was the commit pushed?\n. @dampir apologies, I didn't see the comments being folded up so I assumed it was still to-be-done\n. This reference isn't necessary\n. I'm not sure why these using statements are needed\n. Perhaps the name on this should be Blobs to indicate it's not going to return a single value?\n. typo: s/Al/All\n. Not sure how this crept in, but this project reference shouldn't be needed :fire: :fire: :fire:\n. Nice pickup!\n. Oops, nice spot!\n. Oh, this is just reordering. Anyway, :sparkles: for reordering!\n. This seems reasonable. I'm not sure how we feel about creating multiple organizations for each test run - @ryangribble do you think this is worth doing simply to test pagination?\n. It'd be cool to uncomment this test and see if we can get it working. I can help verify this (we don't run them on CI because they're hitting the actual API).\n. Let's remove this :fire:\n. EDIT: oops, I'd messed up the test and not specified PageCount. Amended below:\n``` csharp\n[IntegrationTest]\npublic async Task CanRetrievePagesOfPublicStarWatchers()\n{\n    var owner = \"octokit\";\n    var name = \"octokit.net\";\nvar firstPageOptions = new ApiOptions\n{\n    PageSize = 5,\n    PageCount = 1,\n    StartPage = 1\n};\n\nvar firstPage = await _fixture.GetAllStargazersWithTimestamps(owner, name, firstPageOptions);\n\nvar secondPageOptions = new ApiOptions\n{\n    PageSize = 5,\n    PageCount = 1,\n    StartPage = 2\n};\n\nvar secondPage = await _fixture.GetAllStargazersWithTimestamps(owner, name, secondPageOptions);\nAssert.Equal(5, firstPage.Count);\nAssert.Equal(5, secondPage.Count);\n\nAssert.NotEqual(firstPage[0].User.Id, secondPage[0].User.Id);\nAssert.NotEqual(firstPage[1].User.Id, secondPage[1].User.Id);\nAssert.NotEqual(firstPage[2].User.Id, secondPage[2].User.Id);\nAssert.NotEqual(firstPage[3].User.Id, secondPage[3].User.Id);\nAssert.NotEqual(firstPage[4].User.Id, secondPage[4].User.Id);\n\n}\n``\n. @dampir good to hear :heart:\n. Nice pickup @dampir - this was doing my head in yesterday!\n. @maddin2016 :thumbsup:\n. Each test creates the same five hooks, so we need to verify the count of the list to beN-1. This property is unrelated to the test itself, so cleaning it up...\n. This branch was removed on the repository :cry:\n. \u2b06\ufe0f \n. Not really needed, but I found this while looking into #1374 / #1251 \n. @alfhenrik all good, once I realised what was happening it was an easy fix \ud83d\ude00 \n. :lipstick:Assert.NotEmpty(comments)?\n. I think this reads better as \"**An** IObservable ...\" rather than \"**A** IObservable ...\"\n. Rather than call this out everywhere for the file, I'll just come back and check after this comment is folded away\n. Same thing here: \"**An** IObservable ...\" rather than \"**A** IObservable ...\"\n. Add a comment on the end here \"... indicating completion\" because theUnitpart really isn't interesting here...\n. Same thing as \u2b06\ufe0f \n. This method is technically returningTask>` but I'm not really familiar enough with the markup in here to confirm what this should look like \ud83d\ude15 \nSomething like this?\n\nA <see cref=\"Task{IReadOnlyPagedCollection{CommitComment}}\"/> for the specified repository. \n\nThere's a few places where this is necessary. Let me know if this doesn't work and I can dig deeper.\n. Same thing here, gotta wrap this in a Task<>\n. We could document the return value like this (same with the method above):\n\nA <see cref=\"Task\"/> representing the asynchronous operation\n. :lipstick: sort these references so System.* appear first\n. :lipstick: drop the private modifier here (it's a pet peeve of mine, but the other fields also lack this)\n. If this is only referenced once, you might as well inline it into the method on line 51. Otherwise there's two usages in the test that can be replaced with this field. Up to you.\n. :lipstick: .Any() has an overload which takes a predicate, so this can be simplified to:\n\ncsharp\nAssert.True(addAssignees.Assignees.Any(x => x.Name == _context.RepositoryOwner));\n. Same thing here, but Assert.False\n. Don't worry about this one. If we've got something else here we're in for a world of pain in general...\n. You'll need to use issue.Number here and on the other actions below (the user-friendly id) rather than issue.Id (essentially the database column).\n. Oh, and x.Name is not the user's account name - and not always populated from every endpoint.\nUse x.Login here if you want to check the account name.\n. :lipstick: we're fetching both and doing a mix of assertions here:\n- could we order this so we set and assert retrieved, and then set and assert all?\n- could we use multiple Assert.True expressions here, rather than one big one sprinkled with &&s?\n. :lipstick: Assert.Equal(1, closed.Assignees.Count) is nicer here because we get both values when it fails.\n. :lipstick: Assert.Equal(_context.RepositoryOwner, closed.Assignees[0].Login) will give us both values if this test fails\n. :lipstick: Assert.Equal(2, issue.Assignees.Count) to get the value if this test fails\n. Given 1171 is now a closed issue, is it worth keeping this around? Could we build a fresh repository to test GetAllForRepository, rather than querying for all the issues in the Octokit repository?\nIf not, I like this sort of test (it takes 21sec on my machine though):\n``` csharp\nvar request = new RepositoryIssueRequest { State = ItemStateFilter.All };\nvar issues = await _issuesClient.GetAllForRepository(\"octokit\", \"octokit.net\", request);\nAssert.True(issues.Any(x => x.Assignees.Count > 1));\n``\n. This is an interesting change - can you tell me what motivated this?\n. Ok cool. Let me dig into this further asToUpdateshouldn't create theLabelsarray by default unless it already exists on the issue. There's some [assumptions](https://developer.github.com/v3/issues/#edit-an-issue) about what wePOST` as part of editing an issue that may have changed (emphasis mine):\n\nLabels to associate with this issue. Pass one or more Labels to replace the set of Labels on this Issue. Send an empty array ([ ]) to clear all Labels from the Issue. NOTE: Only users with push access can set labels for issues. Labels are silently dropped otherwise.\n. It's pretty close, but looking at the rendered markup doesn't really satisfy me (this isn't your fault):\n\n\nDo you think it's worth keeping these return values around at all? It's all rather boring and repetitive...\n. @ryangribble it's all good, I just need to cast my mind back to the earlier discussions about this.\n718 is the original PR where I implementing this, and to TL;DR it:\n\ninitially, the result from ToUpdate() should have a value of null for Labels - this is how we say \"don't change anything\" to the server as part of the update, as labels won't be serialized\nif you invoke update.AddLabel(\"label\") we create a new list lazily, and this collection replaces whatever labels are previously set on the server\nif you invoke update.ClearLabels() this creates an empty list, to indicate that all labels should be removed as part of the update \n\nIt's might come across as a bit explicit, but I like the verbosity that it gives you in the code.\nAnyway, coming back to this change. It looks like we're populating the Labels array from what exists in the issue, and while that's similar to the original intent I didn't want users to be manipulating the Labels collection directly to remove labels - I wanted to see them use the first-class AddLabel and ClearLabel methods on IssueUpdate.\n. Let's clear these <return> tags - I'm not sure it's worth all the back-and-forth for the value it gives us\n. Apologies, I should have been clearer - the whole <returns></returns> element can be removed from these docs.\n. I should have been clearer - the whole <returns></returns> element can be removed from these docs.\n. Let's just remove the whole <return></return> elements wherever we're touching methods in these files.\n. Let's just remove these empty elements wherever we've created them here.\n. :lipstick: reorder these so System.* is before the rest...\n. :lipstick: ordering\n. :lipstick: why not compare both enums here?\n. Would it be worth renaming this repository to make it's purpose more clear? \n. There's a coding convention here that I guess needs to be documented properly. Despite these files living in Octokit/Models/Responses the corresponding namespace for these is just Octokit. This means new using statements are unnecessary for consumers (and for this PR).\n. This shouldn't be necessary when the namespace is updated as per the other comment below...\n. As mentioned elsewhere, this should be unnecessary after renaming the namespace...\n. whoops - great pickup @dampir!\n. While it's technically correct to await in these tests, I've not seen this affect the test behaviour - as we're interested in what was invoked, rather than the result returned. Although, saying it out loud like that makes me feel like we're just asking for some neat race condition to come along and cause us issues...\n. Do we need some documentation here?\n. Text should refer to id\n. Text should refer to id\n. Text should refer to id\n. Text should refer to id\n. Text should refer to id\n. Text should refer to id\n. Text should refer to id\n. Text should refer to id\n. Text should refer to id\n. Text should refer to id\n. Text should refer to id\n. Text should refer to id\n. Text should refer to id\n. Text should refer to id\n. Let's :fire: these empty <returns></returns> elements\n. I love it! \ud83d\udc4f \n. :heart:\n. Ensure.ArgumentNotNullOrEmptyString for owner and name while we're in here\n. Let's make the casing consistent: ID -> id\n. Let's name this one and the one above. What about something like A new deployment status to create. ?\n. I won't say remove this, but let's await Task.Delay(1000); here so I don't feel so bad about merging this \ud83d\ude01 \n. await here\n. Convert to await\n. and await here\n. await here\n. This one is another ID versus id thing. I'm not sure which one is better (or more correct).\n@ryangribble @haacked feels?\n. Good point. Let's come back to it.\n. Nevermind, we'll come back to this later.\n. Can we revert this namespace addition to simplify the diff?\n. I think you need to bring back the custom Accept header here to get that test passing...\n. Is there a reason why we've removed this file?\n. Ensure.ArgumentNotNull(request, \"request\")\n. Ensure.ArgumentNotNull(request, \"request\")\n. Ensure.ArgumentNotNull(request, \"request\")\n. Ensure.ArgumentNotNull(request, \"request\")\n. I'm not sure I understand - this is a new method we're adding here?\n. Should we allow null here for RepositoryForksListRequest? We've been restricting this elsewhere in the codebase, and it feels weird to leave this one here. We can call this out in the release notes if you think that's important...\n. The reactions created above are one-per-issue. So we only expect 1 here, not 4. Or perhaps we can simplify the test?\n. Similarly, if we're reacting to the most recently updated issue we'd need to look for the Laugh reaction here.\n. Somewhat related - we have other tests here which use this repository, but this repository doesn't seem to exist any more cc @alfhenrik \n. Can we :fire: this commented-out code?\n. I think my philosophy here is trending towards \"keep them separate\", so this is fine...\n. Cool, I'll update the PR title so I know - please remove it when you're ready to go around again...\n. > Any ideas?\nI'm happy to punt on the receiving end of the repository invitation and leave an open issue to track that, because we don't really have the infrastructure right now to support multiple accounts...\n. We don't seem to be await-ing in these tests. Let's add those in or drop the outer async...\n. I don't see this value being used anywhere (I suspect it also wasn't used before).\n. This override also doesn't seem necessary now.\n. :lipstick: let's :fire: these commented lines\n. Could we make this test assert the state of master and :fire: this comment?\n. Minor nit: the asserts below will cover whenever any of these values are null\n. :lipstick: break this out under a <remarks> section\n. Could this ctor be made a bit friendlier by having an overload which doesn't require passing new string[0] ?\n. :fire: - the next assert will cover this\n. Should this string be EnterpriseHelper.ManagementConsolePassword ?\n. We don't seem to be doing any asserting here? Will the request will fail here if the GHE server is not in the right state?\n. :lipstick: maybe just a new Uri(\"/\" + endpoint.ToString()); here to simplify it\n. Can this be internal?\n. :lipstick: rather than doing this as two steps, you could pass in the base address here and move that logic out so it's just one call:\n``` csharp\npublic static Uri EnterpriseManagementConsoleMaintenance(string managementConsolePassword, Uri baseAddress)\n{\n    if (baseAddress != null\n        && baseAddress.ToString().EndsWith(\"/api/v3/\", StringComparison.OrdinalIgnoreCase))\n    {\n        // note: leading slash here means the /api/v3/ prefix inherited from baseAddress is ignored\n        return \"/setup/api/maintenance?api_key={0}\".FormatUri(managementConsolePassword);\n    }\nreturn \"setup/api/maintenance?api_key={0}\".FormatUri(managementConsolePassword);\n\n}\n```\nAnd this usage becomes: \ncsharp\nvar endpoint = ApiUrls.EnterpriseManagementConsoleMaintenance(managementConsolePassword, ApiConnection.Connection.BaseAddress);\nIt's a bit more duplication inside ApiUrls, but perhaps there's other GHE-based APIs that we need to do this for...\n. \n. I think these tests need a specific attribute that verifies the existence of OCTOKIT_GHE_CONSOLEPASSWORD\n. It might sound excessive, but perhaps a StringBuilder in here would make some of this Concat code easier to read...\n. Ensure.ArgumentNotNullOrEmptyString\n. > Or are you saying we should actually assert this here anyway? Or potentially do it using a Context helper class, with the destructor implementing the \"reset\" logic?\nI'm neutral on this, but I guess if \"ensure maintenance mode is off\" needs to be done with each test it should be done in teardown. Just me misreading the test a bit.\n. Huh. Weird.\n. Can we put the existing build steps in here, so they both run?\n. Same thing here, let's keep the existing tasks around\n. @ryangribble @Haacked how do we feel about this breaking change? Should we instead introduce overloads?\n. It's also still called Collaborators in here due to someone copy-pasting things. Could you update that?\n. There seems to be a signature issue with this function:\n```\nError:\n    build.fsx(138,9): error FS0001: This expression was expected to have type\n        unit\n    but here has type\n        'a -> unit\n\n```\nThrowing a |> ignore on the end seems to do the trick :trollface:\nfsharp\nFake.DotNetCli.Test (fun p ->\n    { p with\n        WorkingDir = d }) |> ignore\n. Fair point - I just pulled it down to do a .\\build but I guess that's now handled by something else.... Could these be cased as LineCommented and CommitCommented? Or is this a deserialization issue?. Assert.NotEmpty here too?. @ryangribble I thought we could do something like this here?\ncsharp\n[Parameter(Value = \"linecommented\")]\nLineCommented,\n[Parameter(Value = \"commitcommented\")]\nCommitCommented\n. If it doesn't follow the conventions, you can exclude it here:\nhttps://github.com/octokit/octokit.net/blob/3345f76fc9a499aca6f49defb345a7926ceb4c87/Octokit.Tests.Conventions/PaginationTests.cs#L96-L105. lol. suggestion\n            // GitHub API requires TLS1.2 as of February 2018. suggestion\n            // Even though this is an AppDomain wide setting, the decision was made for Octokit to. suggestion\n            // make changes outside Octokit to continue to work with GitHub API. suggestion\n            // .NET Framework\u00a0before 4.6 did not enable TLS1.2 by default. Move this code comment out into the Markdown text. suggestion\n    var octokitRepo = await ghClient.Repository.Get(\"octokit\", \"ocktokit.net\");. suggestion\npublic async Task CreatePullRequestFromFork(). suggestion\n    var pullRequest = await ghClient.PullRequest.Create(\"octokit\", \"octokit.net\", newPr);. suggestion\n    var alternatePr = await ghClient.PullRequest.Create(octokitRepo.Id, newPr);. ",
    "pengwynn": "Many methods support multiple media types, but you can only pass a single value. Comment bodies and pull request formats are the big ones. Check the media type docs for the scoop.\n. Prolly need to think about ID-based overloads at some point, too, because that's where we're headed. \nsh\n\u276f curl -I https://api.github.com/repos/rails/rails/issues | grep Link\nLink: <https://api.github.com/repositories/8514/issues?page=2>; rel=\"next\", <https://api.github.com/repositories/8514/issues?page=26>; rel=\"last\"\nAccess-Control-Expose-Headers: ETag, Link, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes\nI actually used URL-based arguments for most of the new Releases stuff in Octokit.rb, because Hypermedia:\nruby\ndef update_release(url, options = {})\n    options[:accept] ||= PREVIEW_MEDIA_TYPE\n    patch url, options\nend\nI'm considering doing some args massaging to allow you to pass a URL or \"owner/repo\", id for all methods across the API that currently need that, encouraging folks to embrace Hypermedia. It's silly how many times we have to deconstruct a URL to get name_with_owner just to regurgitate it back to build a URL again.\n. A  Repository argument object that parses a few formats.\n. Related: https://twitter.com/pengwynn/status/269194675460648960\n. :heart:\n. Octokit.rb uses inheritance, but I think either approach will work. Be sure to catch those 401 variants, too.\nRate limiting goes like this:\n| Type | Rate | Based on |\n| --- | :-: | :-: |\n| Unauthenticated | 60/hr | IP |\n| Basic Auth | 5000/hr | Username |\n| OAuth | App's rate/hr (default 5000) | Username |\n. Oh, sorry. Max login attempts is by IP and is 10/minute.\n. Is there anything in your world like Webmock? This is how we do it.\n. I'd love to see some domain error codes in there one day.\n. Yup.\n. Sorry, the docs should be updated with:\n{\"message\": \"API rate limit exceeded for [key]\", \"documentation_url\": \"http://developer.github.com/v3/#rate-limiting for details.\"}\nNote the `s/See//g.\n. Yup, those are legit. It looks like we need to update our docs. Patches welcome. :smile_cat: \n. > should we assume at some point in the future that a repository may have more than 2^32 pull requests - or are we getting ahead of ourselves\nNotification and Comment resources might lead us to introduce ID columns as strings in a future version, but I don't think we'll need to do that for scoped numbers like Pull Requests or Issues. \n\nwe should be consistent with how links are representing in the API, so which approach is \"the right one\"?\n\nWhile some resources have a _links hash, all of those relations can be found elsewhere in the resource in a *url attribute. Most collection resources have a Link header with pagination-related link relations, but those aren't in the resource body.\n. You have to be an admin for the repository to see the teams. We 404 in many places in the API to prevent leaking private repositories, though 403 might be a better option in this case.\n. default_branch is the way forward. We added it to the API output, but we couldn't remove master_branch until the v3 media type. We'll be switching the API to return v3 by default soon.\n. > cc @pengwynn to confirm this is by design\nYup. The /issues API call predates the new Issues UI behavior, but you should be able to get the same results from the Search API.\n. @sbohlen: You're running afoul of our new abuse safeguards for public repositories. How many operations are you performing per-issue? Are you adding labels by updating the issue or applying multiple labels at once?\n@shiftkey: Does Octokit.net present the documentation_url for exceptions? Here's how Octokit.rb handles this flavor of 403 and presents the error.\n. It's confusing but that's expected, because history.\nYou'll find what the UI calls \"Watchers\" in the subscribers_count field for API resources.\n. @Haacked: Locking isn't currently available via the API. I've referenced this issue on the internal feature request for that one.\n. > I'll have to think through how we handle the fact that the monolith may have nullable properties that should not be nullable on the interface. We'll figure something out.\nAre you talking nullable or present? Is there more or less pain for a field to be present and null vs absent altogether?\nEither way, the :imp: might be in the details, but I think interfaces could be a pragmatic approach. \n. @RonnChyran @Haacked: Looks like this one is blocked by third-party application restrictions. \n. > may I suggest adding a note about that to the API docs?\nThanks for suggesting, @RonnChyran. I've added that scenario to the troubleshooting guide.\n. We use 202 in a number of contexts. In addition to the Stats API mentioned above, we also return a 202 when a repo is forked and you definitely don't want to auto-retry there. I think we'll also be using 202 to signal a Release Asset retry when we get a chance to implement it. See https://github.com/github/alambic/issues/28.\n. Hmm, that seems like specific info to have up in your pipeline. FWIW, Octokit.rb follows a simple philosophy of providing positional arguments for required information and an options hash for passing arbitrary info to the server:\n``` ruby\nFetch a README with Accept header for HTML format\nOctokit.readme 'al3x/sovereign', :accept => 'application/vnd.github.html'\n```\nWe even allow some headers to be passed as first class options (as :accept in this case instead of :headers => {:accept => ''}). This allows us to use the same method to get a pull request back as JSON, .diff, or .patch from a single method.\nI know this doesn't translate 1-to-1 in static languages, but as a consumer of APIs I appreciate it when my libraries remove the tedium of calling HTTP while exposing its raw power when I need it. Then I'm not left waiting on a library for every API update enhancement.\nJust my $.02. @jspahrsummers may have more applicable feedback.\n. I should have mentioned that we do pass the preview media type when required, but we allow it to be overridden from user input:\nruby\ndef releases(repo, options = {})\n  options[:accept] ||= PREVIEW_MEDIA_TYPE\n  paginate \"repos/#{Repository.new(repo)}/releases\", options\nend\n. It's a tradeoff. There is a list but it grows over time.\n. Not at the moment, just in the docs.\n. The Contents API is optimized for getting the contents of a path. As the note at the top of that section points out, the Trees API can be used to get a list of files recursively. Does that help?\n. Oh, I see the problem now. Actually, I'm not sure of the rationale there. Maybe @jasonrudolph or @ymendel could help.\n. No such option exists in the API or on the web site.\n. ",
    "jeejkang": ":heart: \n. ",
    "jspahrsummers": "Yes, octokit.objc returns a signal of each individual object result. I'd argue that this makes for less complicated and more optimized code, since:\n1. You're handling values uniformly\n2. You're handling values as they arrive, instead of after they've all arrived\n3. You can be oblivious to how many pages there are, and how big each page is\n4. You can apply transformative operators (like Select and Where) to the whole result set\nIn ReactiveCocoa, at least, there are operators to turn a Signal<T> into Signal<Array<T>> if desired \u2014\u00a0but signals/observables are explicitly modeling streams anyways, so why not just take advantage of that?\n. @Haacked Yeah, sorry for being unclear \u2014 I meant vs. sending a list of all results (which may or may not be what @paulcbetts was suggesting).\nTo be clearer, there are distinct advantages over both sending lists per page and sending a list of all results.\n. @Haacked Why is that more complicated?\nIn octokit.objc, the algorithm works like this:\n1. Create a cold signal representing the page to retrieve.\n2. Send each result to the subscriber.\n3. After all results, start at step 1 again, and concatenate with that signal.\nThis way, disposal naturally cancels any further pagination, and this percolates down to operators like Take.\n. Here, we see the async/await in its natural habitat: disaster.\n. :+1:\noctokit.objc does something similar, in that it returns a cold signal (observable) that doesn't begin until subscription. However, after that point, all subscribers receive the same results and the network request is never duplicated.\nI've gone back and forth on whether that's really a good thing (vs. an actually cold signal), but it may be worth thinking about.\nSeparately, one of the things I want to do for ReactiveCocoa 3.0 is focus a lot more on cold signals \u2014 perhaps even removing some ways to create hot ones \u2014\u00a0for exactly the reasons you mention. We'll see how that pans out.\n. It does mean that, yes. That's a great point in favor of making it completely cold.\n. You should be able to put this parameter on every request without ill effect.\n. > It sounds like 'size' isn't that super useful, but 'isEmpty' might be\nYou could try to fetch a list of refs instead. Assumably that'd be empty for an empty repo?\n. Why not wait until there's a specific need for it?\n. ",
    "hahmed": "IssuesClientTests\nLooks like the calls below should be update and not create? (stumbled upon this whilst I am writing my test for teams api - update_team method).\n```\n    public class TheUpdateMethod\n    {\n        [Fact]\n        public void PostsToCorrectUrl()\n        {\n            var issueUpdate = new IssueUpdate();\n            var connection = Substitute.For();\n            var client = new IssuesClient(connection);\n        client.Update(\"fake\", \"repo\", 42, issueUpdate);\n\n        connection.Received().Patch<Issue>(Arg.Is<Uri>(u => u.ToString() == \"repos/fake/repo/issues/42\"),\n            issueUpdate);\n    }\n\n    [Fact]\n    public async Task EnsuresArgumentsNotNull()\n    {\n        var connection = Substitute.For<IApiConnection>();\n        var client = new IssuesClient(connection);\n\n        AssertEx.Throws<ArgumentNullException>(async () => await\n            client.Create(null, \"name\", new NewIssue(\"title\")));\n        AssertEx.Throws<ArgumentException>(async () => await\n            client.Create(\"\", \"name\", new NewIssue(\"x\")));\n        AssertEx.Throws<ArgumentNullException>(async () => await\n            client.Create(\"owner\", null, new NewIssue(\"x\")));\n        AssertEx.Throws<ArgumentException>(async () => await\n            client.Create(\"owner\", \"\", new NewIssue(\"x\")));\n        AssertEx.Throws<ArgumentNullException>(async () => await\n            client.Create(\"owner\", \"name\", null));\n    }\n}\n\n```\n. @Haacked sorry my bad!\n. @Haacked @half-ogre You can use Travis CI - I personally feel that is way better.\nhttp://stackoverflow.com/questions/16751772/how-do-i-use-travis-ci-with-c-sharp-or-f#answer-16751773\nI can see this project already runs on Mono? Not too sure about powershell though... \nhttps://travis-ci.org/hahmed/octokit.net\nMy build is failing for some reason...\n. @Haacked how do you want org teams to be implemented (I am new to this so please bear with me).\nWould something like this work?\n```\n   /// \n    /// organization teams\n    /// \n    public class Team\n    {\n        /// \n        /// team name\n        /// \n        public string Name { get; set; }\n    /// <summary>\n    /// team id\n    /// </summary>\n    public int Id { get; set; }\n\n    public Permission Permissions { get; set; }\n\n    public ICollection<User> Members { get; set; }\n\n    public ICollection<Repository> Repositories { get; set; }\n}\n\npublic enum Permission\n{\n    /// <summary>\n    ///  team members can pull, push and administer these repositories.\n    /// </summary>\n    admin,\n\n    /// <summary>\n    /// team members can pull and push, but not administer these repositories\n    /// </summary>\n    push,\n\n    /// <summary>\n    /// team members can pull, but not push to or administer these repositories\n    /// </summary>\n    pull\n}\n\n```\nThen should I add a property onto the org class called\npublic Team Teams {get; set;}\nJust wondering what the best way to go about this is... Thanks.\n. @Haacked It's cool, love to help - hope I can be of help.\nSo far I got:\nhttps://github.com/hahmed/octokit.net/commit/c44b18e947e3a928009e026313246c37c5a3a0a1\nNever understood this bit:\n\nThen add a property to IOrganizationsClient named Team of type ITeamsClient.\n. @Haacked Does that mean you want the Teams Api to be only available to end users via OrgsClient.\n\nFor example:\nOrgsClient.Team.GetAllTeams(string org);\nOrgsClient.Team.NewTeam(string name, Permission permission = Permission.Pull) //(default param)\netc.\nI assumed you wanted the TeamClient to be separate like I did so in my PR?\n. @Haacked if the above pr gets merged I think that is everything that I needed to implement this feature. Let me know if I have missed anything so I can get this feature fully wrapped up.\n. @Haacked that pr #226 is hopefully with the correct base. I think the commits look ok only 1 o/s issue then that should be cool.\n. Sorry about messing up with the other 2 PR's\n. o/s issues for search api\nFor all 3 below I have implemented the basic search api - however we need to add all the qualifiers to get this fully working, similar to Searching Repos.\nI will hopefully start on one of them pretty soon unless someone else decides to jump at it before me. (If anyone does, please do open a separate PR for each item below please)\nSearching Issues\nSearching Code\nSearching Users \n. Work in progress... Just going to do a rebase now.\n. @Haacked How do I do a git rebase onto upstream master?\n. @Haacked have I messed this up? I cannot tell... defo dangerzone lol.\n. @Haacked sweet! Merge conflict fixed.\n. For some reason this is failing because of [below] - anyone have any ideas?\nBuild FAILED.\n\"C:\\Projects\\octokit.net\\Octokit.sln\" (Build target) (1) ->\n   \"C:\\Projects\\octokit.net\\Octokit\\Octokit-NetCore45.csproj\" (default targe\nt) (5) ->\n       (CoreCompile target) ->\n         Clients\\IOrganizationsClient.cs(19,9): error CS0246: The type or namesp\nace name 'ITeamsClient' could not be found (are you missing a using directive or\n an assembly reference?) [C:\\Projects\\octokit.net\\Octokit\\Octokit-NetCore45.cspr\noj]\n         Clients\\OrganizationsClient.cs(29,16): error CS0246: The type or namesp\nace name 'ITeamsClient' could not be found (are you missing a using directive or\n an assembly reference?) [C:\\Projects\\octokit.net\\Octokit\\Octokit-NetCore45.cspr\noj]\n\"C:\\Projects\\octokit.net\\Octokit.sln\" (Build target) (1) ->\n   \"C:\\Projects\\octokit.net\\Octokit\\Octokit-Mono.csproj\" (default target) (9\n) ->\n         Clients\\OrganizationsClient.cs(29,16): error CS0246: The type or namesp\nace name 'ITeamsClient' could not be found (are you missing a using directive or\n an assembly reference?) [C:\\Projects\\octokit.net\\Octokit\\Octokit-Mono.csproj]\n         Clients\\IOrganizationsClient.cs(19,9): error CS0246: The type or namesp\nace name 'ITeamsClient' could not be found (are you missing a using directive or\n an assembly reference?) [C:\\Projects\\octokit.net\\Octokit\\Octokit-Mono.csproj]\n0 Warning(s)\n4 Error(s)\nTime Elapsed 00:00:20.81\nRunning build failed.\nError:\nBuilding ./Octokit.sln failed.\n   at Fake.MSBuildHelper.build(FSharpFunc`2 setParams, String project)\n   at Fake.MSBuildHelper.MSBuildWithProjectProperties@240.Invoke(String project)\nat Microsoft.FSharp.Primitives.Basics.List.iterT\n   at Fake.MSBuildHelper.MSBuildWithProjectProperties(String outputPath, String\ntargets, FSharpFunc2 properties, IEnumerable1 projects)\n   at Fake.MSBuildHelper.MSBuild@250-1.Invoke(IEnumerable`1 projects)\n   at FSI_0001.clo@43-3.Invoke(Unit _arg3) in C:\\Projects\\octokit.net\\build.fsx:\nline 44\n   at Fake.TargetHelper.runTarget@284(String targetName)\n\nBuild Time Report\nTarget         Duration\n\nClean          00:00:00.0652982\nAssemblyInfo   00:00:00.0154656\nTotal:         00:00:21.8387490\nStatus:        Failure\n1) Building ./Octokit.sln failed.\n  2) CS0246: Clients\\IOrganizationsClient.cs(19,9): The type or namespace name '\nITeamsClient' could not be found (are you missing a using directive or an assemb\nly reference?)\n  3) CS0246: Clients\\OrganizationsClient.cs(29,16): The type or namespace name '\nITeamsClient' could not be found (are you missing a using directive or an assemb\nly reference?)\n  4) CS0246: Clients\\OrganizationsClient.cs(29,16): The type or namespace name '\nITeamsClient' could not be found (are you missing a using directive or an assemb\nly reference?)\n  5) CS0246: Clients\\IOrganizationsClient.cs(19,9): The type or namespace name '\nITeamsClient' could not be found (are you missing a using directive or an assemb\nly reference?)\n(Q)uit, (Enter) runs the build again\n. I think I added the files to the netcore45 and mono lib but the project is still failing.\nI get:\nBuild FAILED.\n\"C:\\Projects\\octokit.net\\Octokit.sln\" (Build target) (1) ->\n   \"C:\\Projects\\octokit.net\\Octokit\\Octokit-NetCore45.csproj\" (default targe\nt) (2) ->\n       (_GetDefaultResourceLanguage target) ->\n         C:\\Program Files (x86)\\MSBuild\\Microsoft\\VisualStudio\\v12.0\\AppxPackage\n\\Microsoft.AppXPackage.Targets(2626,9): warning APPX1901: The DefaultLanguage pr\noperty is either missing from the project file or does not have a value. The fal\nlback language is set to the Visual Studio language: en-GB. [C:\\Projects\\octokit\n.net\\Octokit\\Octokit-NetCore45.csproj]\n\"C:\\Projects\\octokit.net\\Octokit.sln\" (Build target) (1) ->\n   \"C:\\Projects\\octokit.net\\Octokit\\Octokit-Mono.csproj\" (default target) (8\n) ->\n       (CoreCompile target) ->\n         Clients\\OrganizationsClient.cs(29,16): error CS0246: The type or namesp\nace name 'ITeamsClient' could not be found (are you missing a using directive or\n an assembly reference?) [C:\\Projects\\octokit.net\\Octokit\\Octokit-Mono.csproj]\n         Clients\\IOrganizationsClient.cs(19,9): error CS0246: The type or namesp\nace name 'ITeamsClient' could not be found (are you missing a using directive or\n an assembly reference?) [C:\\Projects\\octokit.net\\Octokit\\Octokit-Mono.csproj]\n1 Warning(s)\n2 Error(s)\nTime Elapsed 00:00:16.60\nRunning build failed.\nError:\nBuilding ./Octokit.sln failed.\n   at Fake.MSBuildHelper.build(FSharpFunc`2 setParams, String project)\n   at Fake.MSBuildHelper.MSBuildWithProjectProperties@240.Invoke(String project)\nat Microsoft.FSharp.Primitives.Basics.List.iterT\n   at Fake.MSBuildHelper.MSBuildWithProjectProperties(String outputPath, String\ntargets, FSharpFunc2 properties, IEnumerable1 projects)\n   at Fake.MSBuildHelper.MSBuild@250-1.Invoke(IEnumerable`1 projects)\n   at FSI_0001.clo@43-3.Invoke(Unit _arg3) in C:\\Projects\\octokit.net\\build.fsx:\nline 44\n   at Fake.TargetHelper.runTarget@284(String targetName)\n\nBuild Time Report\nTarget         Duration\n\nClean          00:00:00.0772344\nAssemblyInfo   00:00:00.0134185\nTotal:         00:00:18.0443914\nStatus:        Failure\n1) Building ./Octokit.sln failed.\n  2) CS0246: Clients\\OrganizationsClient.cs(29,16): The type or namespace name '\nITeamsClient' could not be found (are you missing a using directive or an assemb\nly reference?)\n  3) CS0246: Clients\\IOrganizationsClient.cs(19,9): The type or namespace name '\nITeamsClient' could not be found (are you missing a using directive or an assembly reference?)\n\n(Q)uit, (Enter) runs the build again\n. @Haacked sweet that's done now.\nStill getting this though:\n407 total, 1 failed, 1 skipped, took 10.881 seconds\nRunning build failed.\nError:\nSystem.Exception: xUnit test failed.\n   at Fake.XUnitHelper.xUnit@62.Invoke(String assembly)\n   at Microsoft.FSharp.Collections.SeqModule.IterateT\n   at Fake.XUnitHelper.xUnit(FSharpFunc2 setParams, IEnumerable1 assemblies)\n   at FSI_0001.clo@48-4.Invoke(Unit _arg4) in C:\\Projects\\octokit.net\\build.fsx:\nline 49\n   at Fake.TargetHelper.runTarget@284(String targetName)\n\nBuild Time Report\nTarget         Duration\n\nClean          00:00:00.0981773\nAssemblyInfo   00:00:00.0191360\nBuildApp       00:00:18.9605569\nTotal:         00:00:37.4800148\nStatus:        Failure\n1) System.Exception: xUnit test failed.\n   at Fake.XUnitHelper.xUnit@62.Invoke(String assembly)\n   at Microsoft.FSharp.Collections.SeqModule.IterateT\n   at Fake.XUnitHelper.xUnit(FSharpFunc2 setParams, IEnumerable1 assemblies)\n   at FSI_0001.clo@48-4.Invoke(Unit _arg4) in C:\\Projects\\octokit.net\\build.fsx:\nline 49\nat Fake.TargetHelper.runTarget@284(String targetName)\n(Q)uit, (Enter) runs the build again\n. @Haacked I have merged into master again but the same issue as above appears when I run that script. Not sure what I am doing wrong?\n. That is fixed now - I can confirm the build is completing successfully. Anything else you want me to do for this PR?\nUpdate: realised I have not implemented the update team method, just going to do that now.\n. This looks complete to me know - let me know if I have missed anything. Thanks.\n. The code for octokit.Reactive is not there - I am assuming you want that to be a new PR, so I will wait for feedback on this PR and if it gets merged I can have a crack at that.\n. I have added all those changes however I get a build error. Not sure what it is:\nbuild.fsx(45,21): error FS0039: The value, constructor, namespace or type 'Proje\nctSystem' is not defined\n(Q)uit, (Enter) runs the build again\n. Sorry - cant believe I missed  that. I have this building now. Do I need to rebase again or is this good to go?\n. Thank you - my first real contribution to any open source software, learned a lot especially about git.\n. @Haacked I deleted my repo as I kinda forgot about this PR. That means I cannot really checkout this PR? What should I do - close this PR and start again? Or can I checkout this PR and make more additions?\n. deleted it from Github.com - I hope I still got a local copy, I think I may have will need to check it out. Else I will work on https://github.com/octokit/octokit.net/tree/hahmed/search-api\n. Yes this PR is ready for review: \nI need some feedback on my class - SearchTerm \nMore specifically the sort property.\nHow do you want this to be implemented? Shall I change it to a string? Rather than an enum?\nFor http://developer.github.com/v3/search/#search-repositories\nsort\nOptional Sort field. One of stars, forks, or updated. If not provided, results are sorted by best match.\nhttp://developer.github.com/v3/search/#search-code\nsort\nOptional Sort field. Can only be indexed, which indicates how recently a file has been indexed by the GitHub search infrastructure. If not provided, results are sorted by best match.\nhttp://developer.github.com/v3/search/#search-issues\nsort\nOptional Sort field. One of comments, created, or updated. If not provided, results are sorted by best match.\nhttp://developer.github.com/v3/search/#search-users\nsort\nOptional Sort field. One of followers, repositories, or joined. If not provided, results are sorted by best match.\nI wanted this class to be used for all 4 searches - not sure how to implement that. I could create 4 classes and have each Search take in 1 specific class that will only contain the options for that search so SearchRepoTerm or SearchCodeTerm (for lack of better naming).\nIf I turn the property sort into a string then we are leaving it upto Github.com to deal with the query string, if invalid it will ignore? I can then clearly document this in the code - inside the interface and class SearchClient and ISearchClient what the valid values are for this property?\n. By the way - something is not right here... You cannot see all the files I have made changes to? \nI think it may be because I am merging my changes into the branch hahmed/search-api - which contains all the previous changes I have already done? \n. @Haacked it's cool.\n. @shiftkey looks like this PR needs to be closed and open a new one that will get merged into master? I am merging my changes onto the incorrect branch?\nHow do you want me to do this? Thanks\n. @shiftkey what do you want me to do about: https://github.com/octokit/octokit.net/pull/203#issuecomment-28184709 ?\n. That rebase looks real ugly... Something went :boom: \n. replaced with #226\n. @Haacked done and done. :sweet_potato: \n. PR is at: #220 \n@Haacked It's cool - I would have just opened the PR I created but I was unsure how you guys wanted things to be done, but next time I will open a PR :thumbsup: \n. @shiftkey all that is done now. Want me to include the reactive version in this PR or a new PR?\n. @shiftkey that's everything now hopefully. Anything else missing?\n. @shiftkey it's cool. Thanks for the reviewing and feedback.\n. SpecFlow appears to support both windows and mono http://www.specflow.org/documentation/Unit-Test-Providers/ but I have never personally used it before.\n. The only thing I need some review on is https://github.com/octokit/octokit.net/pull/203#issuecomment-28184709\n. That was the main reason why I left that all as strings as there was a lot off possible options...\n. > But then >=500 is an acceptable input, which can't quite be mapped to the same pattern due to the > or >= distinction...\nYep - that one baffled me...\n\nstars:10..20 could be written as:\n\nI like your suggestion for that - this could work...\n. > I'd like to see some integration tests for these search results - they might change over time, but at least we can do some basic checks that we're using the API right.\nCool I will get around to this hopefully this weekend.\n@Haacked any suggestions on how we can add the extensive list of qualifiers as proper .net objects as opposed to strings?\n. @shiftkey thanks for the tip - much appreciated :thumbsup:  \nI will write out some tests and see how this feels. \nDoes the implementation look a bit off ideal to you?\nI thought about what yourself and @Haacked mentioned and I tried to design the class SizeQualifier accordingly, then apply the same principles to the other search qualifiers like In etc.\n. @shiftkey that looks sweet - so basically add an overload to my ctor that allows you to instantiate Size In or other search qualifiers.\n. @shiftkey got those tests you wanted.\n. @shiftkey I got all those qualifiers and searching in with tests for each. I hope that is fine?\nI need some pointers on how to implement https://help.github.com/articles/searching-repositories#created-and-last-updated\nIt is very similar to the Range class - I could create a similar class that takes in a Date and the relevant qualifier?\n. Are you guys cool with the PR? It seems as though this searching has a lot of stuff in it, do you want it to be broken down a but more? A new PR for Searching Issues, Code, Users or just merge it all into one?\nThe foundations have been done for them but looking at searching repos implementation there is a whole lot going on. That is without the depth of testing @shiftkey wanted?\n. Managed to get the DateRange class in which deals with the updated and created qualifiers. \nI think I am about done with searching repos. \nThat is all the features needed to fully search repos and it is ready for review, please let me know where I could improve on.\nThanks\n. > There's a huge amount of work to implement this API.\n@Haacked lol - github's fault for making their search so good.\n\nHope you don't mind my nitpicky comments.\n\nDon't mind - I appreciate it actually.\n\nThere's a lot of places where you try to not send a parameter when it's not specified.\n\nCool let me look at why - something was going through my mind at that moment, I think it was because of a lot of experimenting going on. I agree it's best to pass on the defaults especially for stuff like enums.\n. @Haacked I got those fixes done. I have a comment at https://github.com/octokit/octokit.net/pull/226#discussion_r7886710\nLet me know how you want me to deal with https://github.com/octokit/octokit.net/pull/226#discussion_r7887007\nJust so we are on the same page.\n1. Searching Issues - basic implementation done\n2. Searching Code - basic\n3. Searching Users - basic\n   A new PR will need to be opened to extend the searching abilities for all 3 above (i.e. adding the search qualifiers).\n4. Searching Repos - hopefully this PR is a full implementation for that with the tests too. :smiley: \n. @Haacked that's all in now and I have merged into master. \nLet me know what else you want me to do to get this merged in. \nThanks\n. @shiftkey cool let me know what you got I made some of those fixes anyway. With regards to optional ctor args [https://github.com/octokit/octokit.net/pull/226#commitcomment-4738657] @Haacked mentioned to not do that here https://github.com/octokit/octokit.net/pull/226#discussion_r7878116 [one of the diff comments - quoting some of it below].\n\nPlease don't suppress this one. For more details: http://haacked.com/archive/2010/08/10/versioning-issues-with-optional-arguments.aspx\nThe constructor should only have parameters that are required. The caller can set the properties of the object for all the optional fields.\n\nIf you want I can add some overloads but I don't think that will be of any benefit? Optional args are better but we are trying to avoid what @Haacked said so the next best thing is to instantiate the Search Request with only the search term then customize your search however you want - we don't care.\nNote - if we go down this route we will offer some consistency to our users with the 3 other search requests (code, issues and users).\nI have one suggestion that will work sweetly - that would be to instantiate the object then maybe chain the other search terms.\n```\nvar search = new SearchRepositoriesRequest(\"octoko\")\n                         .In(new[] { InQualifier.Description })\n                         .Size(whatever)\n                         .Language(Lanugage,Go);\n```\nIf that can even be implemented like that?\nLet me know what you are thinking with this...\n. @Haacked @shiftkey do you guys feel this is good to merge? :smile: \n. @shiftkey ok cool thanks.\nSorry if I did a bit too much work on this in one go - I should have broken it down into smaller steps by doing a simple search then gone on to extend the searching in more detail in simple digestible PR's. Lesson learnt though.\n. > @hahmed looks like you'll need to update this branch from upstream master.\n@Haacked that's done.\n. @Haacked @shiftkey if there is anything I can do to help push this along please let me know. I have updated this with  the master branch now.\n. @shiftkey it's cool, if you want. You can cc me in anything.\nI have a few other things I need to do I will look to implement them in smaller portions hopefully. (if anyone else has not taken the issue).\n. @shiftkey can the branch hahmed/search-api be removed please - mistake on my part. Thanks\n. @shiftkey sorry I should have been more clearer - I meant https://github.com/octokit/octokit.net/tree/hahmed/search-api\n. @riteshventurepact can you try var user = await github.User.Get('riteshventurepact');\nLooks like the await keyword is missing...\n. @stephenweaver \nThe GitHub api at http://developer.github.com/v3/issues/milestones/#parameters says that you can only get open or closed milestones. The default is open.\nIf you want to get the closed milestones - you can use the overloaded method.\n```\nprivate List getMilestones(string owner, string name)\n{\n   return github.Issue.Milestone.GetForRepository(owner, name, \n            new Octokit.MilestoneRequest{ State = ItemState.Closed })\n            .Result.ToList();\n}\n```\n. @shiftkey all done now :smile: \n. I got this :zap:\n. @shiftkey ready for review :smile: \n. When i get a moment tomorrow i will look at this. I agree the qualifiers should be tested a bit better.\n. > We know that the q value on the querystring parameter should contain something, so why not check it within the test, like this?\n@shiftkey I agree - I will implement this as per your suggestion.\n. @shiftkey ready for review.\n. @shiftkey thank's will fix them, to be honest I cannot see any failing tests (I mentioned this last time), everything just keeps on passing for some reason, I need to look into why I cannot see any failing tests, something must be broken with my scripts (I never made any updates to that at all).\n. @shiftkey now that I have merged into master, I can run .\\build,cmd and I can see 11 failing tests - oh my :smile: \n. @shiftkey that's all done now. All tests are passing, anything else I missed, please let me know.\n. Lol... amazing!\n. :thumbsup:  with that suggestion\n. > The changes look great, just curious if we can make the tests a bit more robust...\nWhy not test out each search request? Every qualifier too? e.g. In, Author etc.\n```\n            [Fact]\n            public void TestingQualifiers()\n            {\n                var request = new SearchIssuesRequest(\"something\");\n                Assert.Equal(\"something\", request.Term);\n            }\n```\nThat way we can assert each property does what it should? Quite a lot of tests to add mind you...\n. Just a suggestion:\nOne thing that I was thinking about whilst I was implementing the search api was ensure everything get's appending correctly to the term.\nI wanted to expose a TermAndQualifiers property so we can better test the output\npublic\n{\n   get { return Term + (mergedParameters.IsNotBlank() ? \"+\" + mergedParameters : \"\"); }\n}\nThen we can test what the final string should actually look like, for example github search for a user called mike:\nAssert.Equals(\"mike+type:user\", request.TermAndQualifiers);\n. The reason for sort:\npublic abstract string Sort\n    {\n        get;\n    }\nAll searches - Search/Repo, Search/Users, Search/Issues, Search/Files have sort added to the query string, so we can get inherited class to simply pass us the string representation of whatever Sort means to them.\n. Nope... forgot to remove that. Was not sure if you wanted to add anything else to this.\n. @shiftkey removed the WIP... ready for review now.\n. Should we really implement this feature?\nhttps://github.com/github/hub/commit/4f70dd126f46dec14fc341c97c18efae417743c7\n. @shiftkey  Any :eyes: over this would be great, cannot figure out why on earth the tests are failing.\n. > This line looks so lonesome (and possibly duplicated)\nThat line is fine... [from github] https://help.github.com/articles/searching-repositories#forks\nThe second way is to specify whether forked repositories should be included in results at all. By default, forked repositories are not shown. You can choose to include forked repositories by adding fork:true to your search. Or, if you only want forked repositories, add fork:only to your search. For example:\ngithub fork:true\nMatches all repositories containing the word \"github,\" including forked ones\ngithub fork:only\nMatches all repositories that are forked containing the word \"github\"\ngithub\nMatches all repositories that contain the word \"github,\" that are not forks\n. > Looks like the forks parameter is being included in the search term.\nAhhh - ok cool, need to fix this problem. Thanks for your review, I tried everything to figure out what went wrong. Let me think some things through and I will push my changes through.\n. Only one failing test, \"sort\" will see if I can wrap that up tomorrow.\n. @shiftkey I have managed to get everything working except one test, any eyes over this would be great. The test that is failing is the sort test. Cannot see why... Thanks!\n. Bump... :smile: \n. @shiftkey this is ready to ship now, thanks for your help.\nIt's really weird but once I rebased to master, I found an error with another test.\nThis had nothing to do with my code, can you verify? Or am I seeing :star: :star2: :stars: \nThat trailing dash should not be there...\nhttps://github.com/octokit/octokit.net/blob/master/Octokit.Tests/Clients/TeamsClientTests.cs#L181\n\n. @Haacked sure\n. @Haacked @shiftkey  this is ready to :ship:\n. @shiftkey is this specific to the api?\nhttp://developer.github.com/v3/search/#search-code\nThose docs state, that we only really need the search term? If that is incorrect the api would need to be updated.\nLet's say we go into github.com, https://github.com/search?q=k&type=Code\nWe are not really searching any repos specifically.\nThis is quite an easy fix, to the class SearchCodeRequest we just need to add the repo as an argument that is required.\nSomething like this...\npublic SearchCodeRequest(string term, string repo) : base(term) { }\nIf you can confirm, I will open a new PR for this...\n. If you notice in your example you said: https://api.github.com/search/code?q=addClass+repo:jquery/jquery \nthe repo name is jquery/jquery, whereas in the test:\nTestingTheRepoAndPathAndExtensionQualifiers\nThe repo name is octokit.net, would this also fail? it should be octokit/ocokit.net?\nDo we simply document this better so users understand a repo is actually the full name i.e. octokit/ocokit.net or is that understood?\n. @Haacked @shiftkey why not go with the jekyll option, I do not mind getting the experiment rolling?\nThat way we can be consistent with our ruby brethren. \nhttps://github.com/octokit/octokit.rb/tree/gh-pages\nAnyhow if you do decide to go down that route, would you mind creating the gh-pages branch and nuking it for me, so I can start from there?\nBetter than me creating a PR that contains deletions to sooo many files, I can simply start with jekyll new when I make my first PR for the documentation.\n- Get all documentation on one page (then split them up as we go along into tabs or whatever)\n- We need a link to an svg of the octokit.net logo\n- Use the markdown docs already created as the content for now\nLet me know your thoughts on this.\n. @shiftkey readthedocs is cool too :+1: aspnet vnext is using that. The default styles look really good.\nWould we care too much about having documentation for different versions for octokit.net? Seems like an overkill for this library.\n. Ok, we will need to create an account for readthedocs and import the markdown files into it I think. \nShall I let you handle the account creation so admin rights are on your end - assuming that's how it works? (Never used it before but more than willing to help out on this).\n. @Haacked not sure why it failed, related to something else...\nPullRequestsClientTests.CanGetCommitsAndCommentCount [FAIL]\n48   Assert.Equal() Failure\n49   Expected: 2\n50   Actual:   1\n. :+1: \nLooks really good, love the way this is shaping out to be.\n. Sorry about that, done.\n. @shiftkey That's done now.\n. Let me know how that change works for ya.\n. Ok done those fixes.\n. @shiftkey force push it away? Sorry, I do not have a clue what that means.\ngit push origin docs-search-users --force ?\n. I just get an everything is up to date. Nothing has changed in this PR. Looks like I am doing something wrong. @Haacked thanks for the heads up, I will keep that in mind.\n. Granted it does not compile, however documentation is generally letting the user know how to use the api in a more digestible way. I see the docs as complementing the code and tests.\nThere have been too many times where I do not have a clue about a library, I simply want to pick up an example that just works. I do agree that maybe after each feature we have a working example? Or simply a few working examples in it's own tab?\ncc/ @shiftkey \n. Thanks\nLooks like I will have to use the code below to check if the current user is a collaborator.\nvar allRepos = await _githubClient.Repository.GetAllForCurrent();\nvar IsCollaborator = allRepos.Any(x=> x.FullName == repository.FullName);\n. I added a working example of the search api in my sample:\nhttps://github.com/hahmed/Sprint/blob/master/Sprint/Controllers/HomeController.cs#L118\n. @shiftkey yep sure.\nSo I just need to write a failing test for:\nhttps://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/SearchClientTests.cs\nFor example the below would be a valid failing integration test?\n```\n    [Fact]\n    public async Task SearchForAllIssuesFails()\n    {\n        var request = new SearchIssuesRequest(\"phone\");\n        request.Repos.Add(\"caliburn-micro\", \"caliburn.micro\");\n        request.State = ItemState.All;\n    var issues = await _gitHubClient.Search.SearchIssues(request);\n\n    Assert.NotEmpty(issues.Items);\n}\n\n```\n. @shiftkey done.\nhttps://github.com/octokit/octokit.net/pull/1083\n. Or alternatively on the line: https://github.com/octokit/octokit.net/blob/master/Octokit/Models/Request/SearchIssuesRequest.cs#L248\nWe can simply change the code from:\nif (State.HasValue)\n            {\n                parameters.Add(string.Format(CultureInfo.InvariantCulture, \"state:{0}\", State.Value.ToParameter()));\n            }\nto\nif (State.HasValue && State != ItemState.All)\n            {\n                parameters.Add(string.Format(CultureInfo.InvariantCulture, \"state:{0}\", State.Value.ToParameter()));\n            }\nor something along those lines... just a far simpler change IMHO. Maybe add a link to the api/issue to explain if needs be.\n. @ryangribble State.All does exist... just implicitly e.g.\nhttps://github.com/search?p=3&q=repo%3Arails%2Frails&ref=searchresults&type=Issues&utf8=%E2%9C%93\nThe result above returns both open and closed issues. Hence my suggestion - remove the param from being added on the condition State != ItemState.All Regardless of which way this is implemented - the search issues needs to give back:\n1. open issues\n2. closed issues\n3. open and closed issues\nIf there are any other areas of the code where ItemState.All is relevant, append it to the parameters. If not - do not add it, we just need to ensure the expected results match the GitHub api.\n-EDIT-\nUnless passing in null refers to search both open and closed issues...? Then yeah - we should create a new enum as suggested.\n. > requires VS2015 Update 3 + additional tooling to contribute (you'll be prompted on first open)\nIf we can use visual studio code to contribute to ocotkit - that con  would be addressed. \ud83d\ude04 \n. I personally this this is wrong - from the api we only get back a little bit of info.\nhttp://developer.github.com/v3/orgs/teams/#response-3\nWe should have a class for this called BaseUser or something similar with only 4 props.\n\"organization\": {\n\"login\": \"github\",\n\"id\": 1,\n\"url\": \"https://api.github.com/orgs/github\",\n\"avatar_url\": \"https://github.com/images/error/octocat_happy.gif\"\n}\nLet me know anyway...\n. I agree - it seems as though this will crop up a few times, best to have some conventions in place to avoid this. Do you want that fix in this PR?\n. Looks like it already does it... So I dont need to do anything more than remove that attribute.\nclass GitHubSerializerStrategy : PocoJsonSerializerStrategy\n    {\n        protected override string MapClrMemberNameToJsonFieldName(string clrPropertyName)\n        {\n            return clrPropertyName.ToRubyCase();\n        }\nWhich points to: \npublic static string ToRubyCase(this string propertyName)\n    {\n        Ensure.ArgumentNotNullOrEmptyString(propertyName, \"s\");\n        return string.Join(\"_\", propertyName.SplitUpperCase()).ToLowerInvariant();\n    }\n. It was - I think I had a failing test with orgs/{0}/teams so I changed it to organizations/{0}/teams - I will revert to orgs/{0}/teams and test it all out again, if the build passes then sweet else I will let you know. Thanks for your review.\n. Cannot believe I glossed over the Api :cry: that's real bad lol.\n. Is this correct? Looking at the docs I think it is? As it is a PUT request. http://developer.github.com/v3/repos/collaborators/#add-collaborator\n. This guy right here looks incorrect. We should have: ApiConnection.Put(endpoint); (no overload currently available but I wanted to confirm that my thinking on this is ok?)\n. @shiftkey how do you want me to add the qualifiers? I am not too certain the best way to go about doing this.\nSay you have 0 qualifiers in place - you can simply add the qualifier.\nElse if you have 1 qualifier there already we will need to append + to the next qualifier to be added?\n. let github handle it? its what the ruby version does? I do agree we need to make this read a lot better.\nhttps://github.com/octokit/octokit.rb/blob/master/lib/octokit/client/search.rb\n. @shiftkey how about something like this? Would this be a better fit for what you want?\nThe way I see it is - if a user wants a specific operator i.e. Size you must instantiate the class. That way we can force certain operators to be applied to our query variable.\nIf Size != null get the tostring() and add it onto the params...\n. We can stick the operators in here and if possible - reuse through the other searches?\n. Use an actual object here rather than a string...\n. @shiftkey is this better?\n. Forks is a little bit complicated so I am taking this one step at a time... \n. Also - do you want me to hide the properties? Do users really need to know that much detail. If you want me to use ctor's to instantiate the search then we should only show users what the need to see right?\nso line 77 above - should not be possible?\n. I have had a look at this and been thinking about this... The base class simple gets all public props and adds them to the query string right? (That is what I am assuming from looking at that code).\nIf so that would be incorrect behaviour for all 4 searches that we are trying to implement. We have lots of qualifier (public properties) that need to be appended to the property Term.\nAll 4 classes will eventually look like Octokit/Models/Request/SearchRepositoriesRequest.cs\nThis class contains all the qualifiers fully implemented however the other 3 searches [code, issues, users] contains only a few basic properties. I did that to get it off the ground, atm your suggestion would be better suited for those 3 classes (inherit from RequestParameters). \nDoes that make sense? You seem to agree as you did not mention for me to get the SearchRepositoriesRequest class inherit from RequestParameters.\nFor this implementation I will update as accordingly but it would have to change to be more like SearchRepositoriesRequest.\n. > For this implementation I will update as accordingly but it would have to change to be more like SearchRepositoriesRequest\nOr a better implementation of what I have done :smile: \n. ok cool - so the only required parameter for this would be Term.\nHow would I deal with @shiftkey 's comment about how he would like this method to be instantiated?  https://github.com/octokit/octokit.net/pull/226#issuecomment-28716486\nShould I add a whole bunch of overloads to this class?\n. My bad - that's been fixed now.\n. http://developer.github.com/v3/search/#search-issues?\n. @alfhenrik @shiftkey not sure if it matters (probably me just nitpicking) wondering if there is any use adding a link to: https://help.github.com/articles/searching-issues#author same with all other qualifiers?\n. @alfhenrik thanks! :thumbsup: \n. @shiftkey thanks, nearly ready for review now, just updated all tests. I am rebasing now too.\n. That's cool...\nWhilst I was writing this, I was thinking... will you want us to describe the daterange class as this is a documentation, or for now will we simply expand on the documentation as and when?\n. That's cool, would this be better served at the top? I mean... assuming that we have already told the user about creating a githubclient, we could simply say at the top of this page. \nvar results = await gitHubClient.Search.SearchRepositories(request);\nThen pass in any of the request objects below e.g. SearchRepositoriesRequest etc. What do you think?\nEDIT: I meant underneath the Search Repositories heading.\n. @shiftkey done.\n. Done.\n. ",
    "forki": "Do you have special tool you'd like to use?\n@tpetricek created https://github.com/tpetricek/FSharp.Formatting which can be used to create something like http://fsharp.github.io/FAKE/apidocs/index.html \nNot sure how good it works on C# projects.\n. \nIt seems this doesn't work at the moment.\n. > > documenting all the types in Octokit and Octokit.Reactive\nYou should start today. Otherwise you have this marathon like me (see https://twitter.com/sforkmann/status/396421858855096321)\n18 days and I'm not finished ;-)\n. Thanks. At the moment I'm lost.\n. If I look at the specs at https://github.com/octokit/octokit.net/blob/fe9cece77f1427f8971f8ece2d8388b09c5b97d4/Octokit.Tests.Integration/UsersClientTests.cs I don't see the problem.\nvar github = new GitHubClient(new ProductHeaderValue(\"MyAmazingApp\"));\nlooks like the test. But it doesn't compile here.\nI use Octokit.Reactive via Nuget.\n. \nProductHeaderValue is missing\n. haha.\nPlease fix it until the next 1000 devs are complaining ;-)\n. I mean it would be cool to be the first contributor (apart from github) but you published blog posts ;-)\n. \nI switched to plain Octokit - same here.\n. @Haacked  Please reopen\n. Please add this to the readme. VS2013 is not telling me I have to add it.\nThen I get:\n\n. ok this one is really weird. I can't reference the dll. \nNeed to investigate. But please add System.Net.Http to the docs.\n. even if it's not intended  as a full example. A link to a getting started would be nice.\n. Thanks.\n. #109 is not resolved.\n. Shameless plug: https://github.com/fsharp/FAKE - it even works on mono (sometimes).\n. just saying.. \nhttps://github.com/fsharp/FAKE/blob/master/build.fsx#L129\n. It's generating the nuspec (by replacing placeholders in https://github.com/fsharp/FAKE/blob/master/fake.nuspec), building the package and (if it's finding the key in the params) it publishes it on the nuget server.\n. yep I'd like to do that :-)\n. I'll send you a PR tomorrow. \nJust to clarify the ' (fun p ->  {p with ..}) ' part. The idea is: we give you a default record with all the properties filled in by our best knowledge (e.g. we search for nuget.exe in every subfolder). And now you can overwrite it. \n. @Haacked is https://github.com/forki/octokit.net/commit/538eff647881ed909dd934ff060481dacff9d048#diff-6074983490330a0aac1bd23c958232d7R67 what you meant?\n. Hi,\nI added a IntegrationTest target for this. But how do you want to specify the user?\nEvironment-Variable? Build-Param? Constant?\nhttps://github.com/forki/octokit.net/commit/bcb723ec5fae076d9fc45b7b41afb1e08177cbd2#diff-6074983490330a0aac1bd23c958232d7R39\nCheers,\nSteffen\n. No it's all fine. Then my solution will work out of the box.\n. yep integration tests work. see https://github.com/octokit-integration-tests\nYou can set it using environment variables OR in the build.bat like:\n\n. http://teamcity.codebetter.com\n. or even better: open up your CI ;-)\n. I repeat \"or even better: open up your CI ;-)\"\n. Let me rephrase that: I don't know any public .NET CI server apart from http://teamcity.codebetter.com \n. I'm tracking my progress for #116 at http://teamcity.codebetter.com/viewType.html?buildTypeId=bt1120\nIt compiles locally but seems there are some bits missing on the CI server.\n. @half-ogre actually it's worse. On my machine with VS2013 I get:\nFile 'Windows.props' not found. See http://go.microsoft.com/fwlink/?prd=12395&pver=1.0&plcid=0x409&ar=MSDN&sar=PlatformMultiTargeting&o1=&o2=Windows for more information.  Octokit-NetCore45\nOn the VS2012 machine the build is ok.\n. see #143 \n. you should link the QED build in the readme\n. > > So if I understand this correctly, when we're ready to create a new release, we'll just add a release note with the new version and everything gets updated to that version? \nYep.\n. @Haacked Anything left?\n. I'm not sure if ba5057a is what you need for the CI server but it runs the build ;-)\n. Ahh sorry. In the build.cmd it's downloding FAKE. Have to do the same here\n. I thought I did this!?\n. BTW: One day when https://nuget.codeplex.com/SourceControl/changeset/d8712b1cf06c2f05c59b9c4de0b19cceeaeef1b9 is released we should remove the \"if\" statement and trust NuGet.\nAt the moment NuGet reinstalls even if it is the same package.\n. https://github.com/forki/octokit.net/blob/63f93ee7be18c638dc0394cf6e1f60ba9f71cfbf/.gitignore#L71 should ignore FAKE.\n. > >  Just 1 test failed during my test run.\nIs this related to the build? All UnitTests pass on my machine.\n. 877aec6 is rebased.\n. have to investigate this.\n. Maybe https://github.com/octokit/octokit.net/blob/877aec6ecf3f2ae8597c8fab40b38291016e7d72/build.fsx#L46 matches old stuff and we have to clean this path.\nCan you git clean -xdf and see if it only runs once?\n. Does 2841441 help?\n. .\\build Default Debug  ===> Runs Debug build\n.\\build Default Release ===> Runs Release build\n.\\build ===> Runs Release build\n.\\build BuildApp  ===> Runs Clean target and BuildApp in Release mode\n. Not a Powershell expert, but I think this has to do with the way you (?) wrote the original build script. see https://github.com/forki/octokit.net/blob/84cf1755f2d00342f2d388a006a0ac84c23d7bb4/script/cibuild.ps1#L84 \nI assume it's all captured in $output.\n. if you want to have this logged on the console than I can probably google how to do it.\n. I think the problem is related to http://stackoverflow.com/questions/13038996/can-you-build-win-8-apps-on-windows-7-with-vs-2012 \nIt's probably not VS2013. It's that I use a Win7 PC in this case.\n. Is it possible to convert this into a portable lib? https://github.com/dnauck/Portable.Licensing claims that it woks in the windows store and can be built on Win7.\n. I mean one day you want to support mono, right?\n. @Haacked Please reopen. It's not fixed.\n. I can live with working on my Win8 box.\n. That's just FAKE reporting that MSBuild exited with code 1. The interesting part is above in the MSBuild output. Can you show more? \n. Ah yes. I didn't read your comment correctly. So FAKE reports 'File 'Windows.props' not found'.\nSorry I can't help. I don't know where to get this file.\n. Yep.  I reverted that package split in FAKE for the moment since it broke all kinds of important stuff. \n. Fixed in FAKE 2.1.528-alpha on Nuget\nAs a reminder: Since Nuget 1.7.x always installs FAKE even if no newer version is detected on nuget.org I introduced \nhttps://github.com/octokit/octokit.net/blob/9f974884fb788460e51af9e4c80b36519dc54325/build.cmd#L5 to keep local builds fast.\nSo you have to delete the ./tools/FAKE/ to get the latest version.\nOn your CI server this should be no problem since it should clean all subfolders and retrieve FAKE on every build run.\n. @Haacked du you want the fxcop task to run during the \"normal\" build or only on CI? \nThere is a (very small) tutorial at http://fsharp.github.io/FAKE/fxcop.html.\nBut what do we do if the dev has no FxCop installed?\n- Do you want to skip the task? And print a message like we do with the IntegrationTests.\n- Do you want to fail the build?\n- Do you want to commit FxCop into the repo? Could be a license issue\n. And so this will be something which is not checked during CI build?\n. I try to fix this in FAKE to keep it backwards compatible.\n. Ok. seems to work. I put the generated AssemblyInfo class into the System namespace. This is already opened  in Octokit so it doesn't break.\nSee https://github.com/fsharp/FAKE/commit/e291eb80652e5260f35aabe16ca43d74e82ea8a7\n. So yay it found it's first bug ;-) \n. now that we are abe to detect missing files we might add a \"fix it\" task.\nstay tuned.\n. See https://github.com/octokit/octokit.net/pull/199\n. duplicate detection should be easy now...\n. \nMaybe I find time for the autofix tomorrow.\n. F# FTW\n. Autofix for duplicates files can be found in #210\n. See my latest pull request. It addresses this issue \n. Actually I broke fake for one or two hours. Sorry about that.  Maybe you got a broken version. Can you delete tools/fake and retry? \n. Still broken??  Wtf \n. I'm really sorry. I hope it works now. Something broke during nuget push. \nIt teaches me a lesson to finally release FAKE 2.0 in order to detach the important projects from the prerelease channel. \nI think everyone is already using 2.x so it should be ok\n. This is so embarrassing. \nI reverted FAKE to a good version. Octokit now builds on my machine. \nI promise to release FAKE 2 today and then we can move Octokit and other important projects on the stable release channel.\nI'm really sorry that I broke it. But I will give my best to improve it.\n. Thanks.\nPlease try again the \"good\" (old) version is already on nuget. \n. I think that's something the ci server should display in the status result line. It's probably also something we could improve in fake. \n. What about Xamarin Studio?\n. The  Azure SDK CI has commits on github.\n\n. I think I found it. Oh myy I should better review pull requests...\n. Ok. Seems to work now.\n. Since it says 300s and we often use 5min default I assume the bug is somewhere in FAKE. I'll investigate. But usually we give a different error message.\n. OK I checked. I think FAKE uses the correct timeout.\n. I meant from looking at code at https://github.com/fsharp/FAKE/blob/develop/src/app/FakeLib/UnitTest/XUnitHelper.fs#L112 I'm pretty sure FAKE is using the specified 10min timeout and doesn't cause the build to fail.\nAlso the reported message in the build log is\nERROR: The process (2068) exceeded the timeout (300s); terminating now.\nbut in FAKE we throw something different (see https://github.com/fsharp/FAKE/blob/develop/src/app/FakeLib/ProcessHelper.fs#L84).\nI assume this is coming from QED\n. And here it is:\nhttps://github.com/half-ogre/qed/blob/ac7f39fe4cbb6e412d1e0bb90d7850733e5e2346/qed/Functions/FailTimedOutBuilds.cs#L14\nhttps://github.com/half-ogre/qed/blob/677f488479d5d3530a342119882909ce50e62a0e/qed/Functions/RunProcess.cs#L51\n. Turns out the github text search box is a really good blame tool ;-) \n. see https://github.com/fsharp/FAKE/blob/develop/src/app/FakeLib/NuGet/NugetHelper.fs#L307 it's already implemented. but be warned it might be buggy.\n. FAKE's current implementation is probably based on ancient Nuget.exe. Pull requests are very welcome. \n. I have to thank you - works like a charme https://github.com/fsprojects/Paket/blob/master/build.fsx#L286\nStill think you should dogfood in Octokit's own build script ;-)\n. ^^ gives me 404\n. What I meant is: the build script retrieves the last octokit version from\nnuget in order to publish the new one. That's a bit of a problem with\nstatic typing. Hen and egg if you will.\nOn Sep 19, 2014 10:13 PM, \"Phil Haack\" notifications@github.com wrote:\n\nCan we use the currently build Octokit.dll?\nWell that and Octokit.Reactive.dll. But I'm not sure I understand the\nquestion. What else would we use?\nWhich files do you want to release\nRight now we use the default release approach of zipping up the source\ncode. But it'd be nice if the release contained both nuget packages too.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/571#issuecomment-56228606.\n. So we just have to build a nice zip  right? \nWhich files do you want to have in it? \n. Yes it gives you links to the source, but since everyone uses git source\nzips do not make much sense\nOn Sep 20, 2014 1:01 AM, \"Phil Haack\" notifications@github.com wrote:\nSo we just have to build a nice zip right?\nWhich files do you want to have in it?\nI'll be honest, I haven't looked at it closely. I thought creating a\nrelease automatically gives you links to the zip of the source. So we'd\nonly need to add two package files to the release. One for Octokit and one\nfor Octokit.Reactive.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/571#issuecomment-56246510.\n. > why are we doing this? to let those who want to manage their dependencies by hand do bypass NuGet\n\nActually the idea was to dogfood Octokit Relases API since basically the whole F# ecosystem (and all the new C# projects that use https://github.com/fsprojects/ProjectScaffold) now uses Octokit with this script ;-)\nIt would probably have shown that https://github.com/fsharp/FAKE/commit/7fcbd023443c20bacaf658548334b5e19b48c5ed is needed with the latest octokit release. A breaking change which is not listed in the release notes.\n. No all is well. Paket takes care of that. Everybody I know is using the\ngithub link feature and automatically gets my \"patch\".\nStill I'd love to Octokit dogfooding itself.\nOn Feb 24, 2015 10:15 AM, \"Brendan Forster\" notifications@github.com\nwrote:\n\n@forki https://github.com/forki apologies for that - the class itself\nis in the wrong namespace and so it was updated incorrectly when we changed\nthe response models over to be readonly properties.\nIf you like I can revert that change for 0.7.1 which I was aiming to ship\ntomorrow my time.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/571#issuecomment-75722435.\n. Sorry if this sounded angry. Actually I'm really really happy about the combination of FAKE+Paket+Octokit. It works very well in practice. It works so well that according to https://github.com/fsprojects/Paket/releases I have already pushed 548 releases of Paket alone. \n. please keep me updated about this. I need to update https://github.com/fsharp/FAKE/blob/master/modules/Octokit/Octokit.fsx when you change it again.\n. So it's indeed a changed API and can be fixed in Octokit? Awesome. Can't\nwait to \"paket update nuget Octokit\".\nOn Sep 16, 2015 2:17 AM, \"Phil Haack\" notifications@github.com wrote:\nExcellent!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/894#issuecomment-140585772\n.\n. Very cool. Are you going to release this as a hot fix? It's blocking the whole F# ecosystem at the moment ;-) \n. Yes. Thanks to projectscaffold project everybody uses Octokit. ;-)\n\nThanks again to both of you. Really appreciate this.\nOn Sep 17, 2015 8:07 PM, \"Phil Haack\" notifications@github.com wrote:\n\nIt's blocking the whole F# ecosystem at the moment\nYikes! I'll try and get a release out soon.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/895#issuecomment-141169218.\n. Lol. Made my day.\nOn Sep 17, 2015 21:56, \"Phil Haack\" notifications@github.com wrote:\n@forki https://github.com/forki cool, got a sec to sanity check the\nrelease notes here? #898 https://github.com/octokit/octokit.net/pull/898\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/895#issuecomment-141207626.\n. works like a charme. thanks so much. \n\n\n. :heart:\n. Would love to,  but I just started my vacation. I'm off sailing for one week. Sorry \n. That's easy. People will just do \"paket update nuget Octokit\" and\neverything will work again. ;-)\nSee you in a week\nOn Sep 17, 2015 22:39, \"Phil Haack\" notifications@github.com wrote:\n\n@forki https://github.com/forki have a great trip! Who will fix the F#\necosystem in your place once we get these packages published?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/898#issuecomment-141221908.\n. Ok. I tried again. Now it works again. But earlier today I had 5 failed deploys from 2 machines. Maybe something was flaky. \n. That's your nuget output folder. I think that's ok to ignore.\n. I moved these from the SolutionInfo.cs over to the specific AssemblyInfo.cs\n. Note to myself: Don't touch the last line of a file. Add the stuff in the middle, that's easier for the diff tool.\n. If we pin FAKE to a blessed version then we don't need to work around nuget.\n. \n",
    "tpetricek": "The tool is F#-only at the moment. If people are interested in making that C# compatible, then I can explain what would have to be done to support that (and I'd be glad to accept pull request :-)), but it is not currently on my todo list for the project.\n. ",
    "hnrkndrssn": "I started a WP8 app a while back, using a custom GitHub API implementation, I could repurpose that app and clean it up if that would be useful as a sample. :smiley: \n. To get that sample in the readme working you have to install the Microsoft.Bcl.* pkgs as that's the System.Threading.Tasks dll it's looking for. Once I installed those pkgs it worked a treat...\n. :thumbsup: \n. Yep, tested and it works like a charm\n. I'd like to take a stab at this one, I'm assuming this will be a \"sub-client\" of the OrganizationsClient?\n. Cool, since that's the way I've started implementing it :smile:\nThank you and regards,\nHenrik Andersson\nSent from my Windows Phone\n\nFrom: Brendan Forster\nSent: 4/11/2013 17:45\nTo: octokit/octokit.net\nCc: Henrik Andersson\nSubject: Re: [octokit.net] Implement Orgs Members API (#133)\n@alfhenrik that seems like the most logical approach\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/issues/133#issuecomment-27668007\n. Sounds good to me :thumbsup:\n. Yea, I just thought of that as I was walking to the train...I'll add it when I get home from work!\n\nFrom: Phil Haack\nSent: 6/11/2013 5:59\nTo: octokit/octokit.net\nCc: Henrik Andersson\nSubject: Re: [octokit.net] WIP - Implement Orgs Members API (#174)\nAh, so this PR doesn't include a way to navigate to this client. I think we just need to add a property to IOrganizationsClient for this. I'll do it.\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/pull/174#issuecomment-27806923\n. Alrighty then, thanks! :smiley:\n\nFrom: Phil Haack\nSent: 6/11/2013 6:03\nTo: octokit/octokit.net\nCc: Henrik Andersson\nSubject: Re: [octokit.net] WIP - Implement Orgs Members API (#174)\nI'll do it. :)\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/pull/174#issuecomment-27807316\n. I am working on this.\n. D'Oh! Again, thank you for adding it :grin:\nPS I'm in Brisbane, Aus so UTC+10 :smile:\n\nFrom: Phil Haack\nSent: 8/11/2013 3:38\nTo: octokit/octokit.net\nCc: Henrik Andersson\nSubject: Re: [octokit.net] Implement Observable Orgs Members API (#191)\nGreat work!\nYou forgot to add the property to IObservableOrganizationMembersClient. I'll merge this and do it myself. It's simple enough and I have no idea what timezone you're in. :)\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/pull/191#issuecomment-27988221\n. Almost, 5:15 AM right now :wink:\nDate: Thu, 7 Nov 2013 11:15:18 -0800\nFrom: notifications@github.com\nTo: octokit.net@noreply.github.com\nCC: henrik.a.andersson@outlook.com\nSubject: Re: [octokit.net] Implement Observable Orgs Members API (#191)\nNo problem! Isn't it like 6 AM there?!\n\u2014\nReply to this email directly or view it on GitHub.                  \n. Sorry 'bout that :grinning: \n. Let's see if I have understood this one correctly...\nFor example in the ReferencesClient we have GetAll and GetAllForSubNamespace, which call ApiConnection.GetAll<>.\nNow, instead of calling ApiConnection.GetAll<> we'll create a new GetAllAsync<> on ApiConnection which will, in addition to what the existing call to ApiConnection.GetPage<> does, BUT also check the HttpStatusCode of the response and if it's a 404 return a human friendly error message?\nAnd this should be done for all the GetAll type methods?\n. OK, I'll see if I can come up with some ingenious solution to said problem :laughing: \n. We could pass in the URI being called to the ApiPagination.GetAllPages and in the event of a 404, we return a NotFoundException with an error message of _[URI] was not found._?\nThat would at least inform the user specifically what was not found, instead of just _Not Found_.\nNew signature of ApiPagination.GetAllPages would be:\nGetAllPages<T>(Func<Task<IReadOnlyPagedCollection<T>>> getFirstPage, Uri uri)\nSo the example test for #242 would look like:\n```\n[IntegrationTest]\npublic async Task CanGetErrorForInvalidNamespace()\n{\n    var owner = \"octokit\";\n    var repo = \"octokit.net\";\n    var subNamespace = \"666\";\nvar result = await AssertEx.Throws<NotFoundException>(\n    async () => { await _fixture.GetAllForSubNamespace(owner, repo, subNamespace); });\nAssert.Equal(string.Format(\"{0} was not found.\", ApiUrls.Reference(owner, repo, subNamespace)), result.Message);\n\n}\n```\nHappy to discuss, I have made changes locally with the above scenario in mind, I can send it through PR for review if you like.\n. So I started going through the API doco to see what's missing in the current master branch, I only got to Pull Requests, I'll go through the rest tonight.\n~~NOTE I haven't crossreferenced with current PRs yet, will do that as well and put a reference next to any items that have PRs against them.~~\nAlright, I think this is the list of what's left to do, and any related PRs that exists.\nActivities\n- [ ] #325 http://developer.github.com/v3/activity/feeds/\n- [ ] #326 http://developer.github.com/v3/activity/notifications/\n- [ ] #327 http://developer.github.com/v3/activity/watching/\nIGistClient #328\n- [ ] http://developer.github.com/v3/gists/#list-gists - PR #271 \n- [ ] http://developer.github.com/v3/gists/#create-a-gist - PR #239 \n- [ ] http://developer.github.com/v3/gists/#edit-a-gist\n- [ ] http://developer.github.com/v3/gists/#star-a-gist - PR #271 \n- [ ] http://developer.github.com/v3/gists/#unstar-a-gist - PR #271 \n- [ ] http://developer.github.com/v3/gists/#check-if-a-gist-is-starred\n- [ ] http://developer.github.com/v3/gists/#fork-a-gist\n- [ ] http://developer.github.com/v3/gists/#delete-a-gist - PR #271 \nITreesClient #329\n- [ ] http://developer.github.com/v3/git/trees/#get-a-tree-recursively\nIIssueCommentsClient\n- [x] http://developer.github.com/v3/issues/comments/#delete-a-comment - PR #315 MERGED\nIIssuesLabelsClient\n- [x] http://developer.github.com/v3/issues/labels/#add-labels-to-an-issue PR #316 MERGED\n- [x] http://developer.github.com/v3/issues/labels/#remove-a-label-from-an-issue PR #316 MERGED\n- [x] http://developer.github.com/v3/issues/labels/#replace-all-labels-for-an-issue PR #316 MERGED\n- [x] http://developer.github.com/v3/issues/labels/#remove-all-labels-from-an-issue PR #316 MERGED\n- [x] http://developer.github.com/v3/issues/labels/#get-labels-for-every-issue-in-a-milestone PR #316 MERGED\nIOrganizationsClient #330\n- [ ] http://developer.github.com/v3/orgs/#edit-an-organization\nITeamsClient #331\n- [ ] http://developer.github.com/v3/orgs/teams/#get-team\n- [ ] http://developer.github.com/v3/orgs/teams/#list-team-members\n- [ ] http://developer.github.com/v3/orgs/teams/#get-team-member\n- [ ] http://developer.github.com/v3/orgs/teams/#add-team-member\n- [ ] http://developer.github.com/v3/orgs/teams/#remove-team-member\n- [ ] http://developer.github.com/v3/orgs/teams/#list-team-repos\n- [ ] http://developer.github.com/v3/orgs/teams/#get-team-repo\n- [ ] http://developer.github.com/v3/orgs/teams/#add-team-repo\n- [ ] http://developer.github.com/v3/orgs/teams/#remove-team-repo\n- [ ] http://developer.github.com/v3/orgs/teams/#list-user-teams\nPull Requests\n- [ ] http://developer.github.com/v3/pulls/ - PR #173 \n- [ ] http://developer.github.com/v3/pulls/comments/ - PR #228 \nIRepositoriesClient\n- [ ] http://developer.github.com/v3/repos/#list-contributors - PR #319 \n- [ ] http://developer.github.com/v3/repos/#list-languages - PR #319 \n- [ ] http://developer.github.com/v3/repos/#list-teams - PR #319 \n- [ ] http://developer.github.com/v3/repos/#list-tags - PR #319 \n- [ ] http://developer.github.com/v3/repos/#get-branch - PR #319 \n- [ ] http://developer.github.com/v3/repos/#edit - PR #319 \nRepositories\n- [ ] #332 http://developer.github.com/v3/repos/comments/\n- [ ] #333 http://developer.github.com/v3/repos/commits/\n- [ ] #334 http://developer.github.com/v3/repos/contents/\n- [ ] #335 http://developer.github.com/v3/repos/keys/\n- [ ] http://developer.github.com/v3/repos/deployments/ - PR #298\n- [ ] http://developer.github.com/v3/repos/downloads/ - This is deprecated, any use to implement?\n- [ ] #336 http://developer.github.com/v3/repos/forks/\n- [ ] http://developer.github.com/v3/repos/hooks/ - PR #313\n- [ ] #337 http://developer.github.com/v3/repos/merging/\n- [ ] #338 http://developer.github.com/v3/repos/releases/\n- [ ] http://developer.github.com/v3/repos/statistics/ - PR #296\nSearch\n- [x] http://developer.github.com/v3/search/#search-repositories\n- [x] http://developer.github.com/v3/search/#search-code - PR #311 MERGED\n- [ ] http://developer.github.com/v3/search/#search-users - PR #289\n- [ ] ~~http://developer.github.com/v3/search/legacy/~~\nUsers\n- [ ] #341 http://developer.github.com/v3/users/emails/\n- [ ] #339 http://developer.github.com/v3/users/followers/\n- [ ] #340 http://developer.github.com/v3/users/keys/\n. Aww shucks! :blush: :sparkler: \n. @shiftkey alright, list updated with what I think is THE list of outstanding items to be completed ;) You'll have it done by the weekend right, with busted hand and all? :grimacing: \n. Sounds like a good plan :+1: \n. I can have a look at those when I get back from work!\n. Has anyone started work on this?\nIf not, I can start work on it.\n. Hmm...should have checked the source I guess...bcae7efddef11c241dfb88afcae5d625c41be032 implements all the Gist Comments API methods...or am I missing something...\n. I'll take this one\n. I'll take this one\n. As the System.Net.Http assembly is part of the .NET framework this should suffice?\n<frameworkAssemblies>\n    <frameworkAssembly assemblyName=\"System.Net.Http\" />\n</frameworkAssemblies>\n. Damn, forgot to rebase from master...closing and sending a new PR...\n. D'oh, of course they do :+1:...:hangsheadinshame:\n. It's nice innit :-D\n\nFrom: Brendan Forster\nSent: 5/01/2014 10:43\nTo: octokit/octokit.net\nCc: Henrik Andersson\nSubject: Re: [octokit.net] Return a more helpful error message if an invalid refs path is provided (#288)\nI love it when a plan comes together\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/pull/288#issuecomment-31593157\n. :+1: \n. This is ready for review. Just waiting for #293 so I can remove Skip on a few tests.\ncc @shiftkey \n. Sweeet, I'll update the skipped tests tonight :grinning: \n. Dun, and ready for review :sparkles: \n. Didn't quite get all lines down to 80'ish...but should be better now.\n...even an extra one in the Search Code tests...ooops..:grin:\n. While testing this, I found that the query should be formatted like q=searchterm+params but the code currently does q=searchterm params, I have updated the code to:\nvar mergedParameters = MergeParameters();\nd.Add(\"q\", Term + (mergedParameters.IsNotBlank() ? \"+\" + mergedParameters : \"\"));\nI just want to check if that is an acceptable solution.\n. Alright. I'll admit it, there was probably no good reason for using StartsWith and Contains instead of hard coded strings :disappointed: ...have refactored to use hard coded strings instead.\n. That's what d[\"q\"] does, as it checks each property on the request and creates the query string from that.\n. :thumbsup: \n. Ready for another round of review now after move to use BaseSearchRequest\ncc @shiftkey \n. Awesome, we got there in the end :) Thanks for all the feedback!\n. According to the documentation, http://git-scm.com/book/en/Git-Internals-Git-References#Tags, they consider these types of lightweight tags just a reference, so that might make it a bit more eligible to call the References API if it receives a 404 from the Tags API...\n. That ^ :grin: \n. That'd be my fault, sorry! :disappointed: \n. Sounds good to me!\n\nFrom: Haroon\nSent: 13/01/2014 19:38\nTo: octokit/octokit.net\nCc: Henrik Andersson\nSubject: [octokit.net] WIP: Base class for searching GitHub (#301)\nWe are repeating a lot of logic inside the searches, hopefully this class will allow us to simply our searching.\nI will close https://github.com/hahmed/octokit.net/pull/1 so we can keep our discussions on the octokit repo (if anyone else has any input).\nHow do you want this to be merged?\nI have created the base class, so we can now iterate on it till it's right...\nOnce this is merged - we can open a PR for every search to inherit from base class? @alfhenrik can then use it for his PR https://github.com/octokit/octokit.net/pull/290 and I can also use it for https://github.com/octokit/octokit.net/pull/289\ncc:// @shiftkey  @alfhenrik\nYou can merge this Pull Request by running:\ngit pull https://github.com/hahmed/octokit.net search-base-class\nOr you can view, comment on it, or merge it online at:\nhttps://github.com/octokit/octokit.net/pull/301\n-- Commit Summary --\n- base class for searching\n-- File Changes --\nA Octokit/Models/Request/SearchBase.cs (90)\n-- Patch Links --\nhttps://github.com/octokit/octokit.net/pull/301.patch\nhttps://github.com/octokit/octokit.net/pull/301.diff\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/pull/301\n. Organization Members? (as per http://developer.github.com/changes/2013-12-13-paginating-org-members/)\n. Well, I've learnt from the best :grinning: :heart: \n. hmm...something went horribly wrong this morning clearly :confused: \nIt was supposed to be a Carlton from Fresh Prince dance gif...not forever uploading..I blame Telstra!\n. \n. This has been fixed\n. Someone has started it, here -> https://github.com/octokit/octokit.net/pull/231 \n. Unless you're user account that is used by the unit tests is a paid account (which has private repos available) CreatesANewPrivateRepository will always fail.\nCreatesANewPublicRepository fails for me as well, I'll investigate.\n. // TODO: Create the org as part of the test <- that has something to do with it...unless you've created a test organisation on GitHub already (var orgLogin = Helper.UserName + \"-org\";) this will fail until that TODO is actioned, and it looks like there currently is no way to create an organisation using the API (or I am blind)? @shiftkey \nI created a test organisation within my test user account and re-ran the test and it runs successfully.\n. I like how this issue is labelled as easy-fix :stuck_out_tongue_winking_eye: \n:+1: for keeping this open\n. I'm not quite sure about the naming of the API client, maybe FollowersClient would be a better name...feedback appreciated. :sparkles: \n. This is pretty much ready for a review while I write up some integration tests :smile:\ncc @shiftkey \n. :+1: I'll get on that tonight\n. I think that should do it now :smile: \n. Here goes :pray: \n. @shiftkey when you got a :hourglass_flowing_sand: could you cast your :eyes: over this one, I've merged in the latest changes from master so this should be :white_check_mark: now\n. Dem projects got me again :'(\n\nFrom: Brendan Forster\nSent: 1/02/2014 10:07\nTo: octokit/octokit.net\nCc: Henrik Andersson\nSubject: Re: [octokit.net] Implement User Followers API (#343)\nThe build is sad...\n\"C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit.sln\" (Build target) (1) ->\n       \"C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit\\Octokit-Mono.csproj\" (default target) (9) ->\n       (CoreCompile target) ->\n         CSC : error CS2001: Source file 'Clients\\IUserFollowersClient.cs' could not be found [C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit\\Octokit-Mono.csproj]\n         CSC : error CS2001: Source file 'Clients\\UserFollowersClient.cs' could not be found [C:\\Users\\half-ogre\\GitHub\\qed\\qed\\bin\\Release\\.repositories\\octokit\\octokit.net\\Octokit\\Octokit-Mono.csproj]\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/pull/343#issuecomment-33855435\n. Yep I'll address your comments in a separate PR :-)\n\nFrom: Phil Haack\nSent: 2/02/2014 10:18\nTo: octokit/octokit.net\nCc: Henrik Andersson\nSubject: Re: [octokit.net] Implement User Followers API (#343)\n\nNice! Very clean. If you don't mind, I made some comments about the lack of comments. If you have time to address those in another PR, that'd be great.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/pull/343#issuecomment-33887863\n. Thanks, always good to get an early review done, gives me more time to fix it up :grin: \n. Just adding some integration tests, other than that this is ready for review.\n. :+1: \n. :+1:\n. Just a note: you would create the topic branch off the master branch in your fork, and then send the PR from that topic branch to the master branch of the main repo.\n. Is that something we could (possibly) include as a post build task in the project file...?\n. In CONTRIBUTING.md, maybe we could mention the use of WIP PRs with a TODO list and how that is useful as it'll show that someone is working on an issue, and also helps the contributor to think about what needs to be done.\nOr, to put a comment in the issue they have decided to work on.\n. :+1: for it to be it's own package\n. > Also, I'm not sure what that last step means.\nFrom the nuget.org docs\ntags\nA space-delimited list of tags and keywords that describe the package. This information is used to help make sure users can find the package using searches in the Add Package Reference dialog box or filtering in the Package Manager Console window.\nI guess LINQPad might be using that to determine if the package should be shown in the free version or not...\n. And after thinking about this a bit more, I'd like to revise my vote for it to be in it's own package...as if I'm interested in the LINQPad samples, I'm obviously wanting to do something with octokit and then I'd have to install both the samples package AND the actual package...\n. As this is just waiting for me to do integration tests, the main changes are ready for review if someone has the time. :grin: \n. I'll try and get them done in the next couple of days\n. Integration tests are now dun! :smile: \n// @Haacked \n. @Haacked anything else missing before this can be merged?\n. :sparkling_heart: \n. Sorry, totally missed that PR...\n. @shiftkey you want to implement it in your PR above, or should I keep it in with mine?\n. No urgency here :) was just looking to start contributing again :cake: \n. :+1: \n. I'll pick up this one plus #652, #653 and #654 as they're all in the same area\n. Currently blocked due to breaking changes in https://github.com/octokit/octokit.net/pull/647\n. Does the GetAllPublic(int since) still need implementing, or is there still something to figure out in regards to Pagination?\n. While browsing issues to fix I found that this can be closed...it was fixed in 68c4c98270517fabd1bcd3de7f5fe4d68c97ba8d :smile: \n. \n. :dancers: :confetti_ball: \n. This should now be :ok_hand: for review, as long as the AppVeyour build doesn't go :boom: :wink: \n/cc @shiftkey \n. Dun! :triumph: \nSide Note: I was able to get around the Integration Tests time out issue, by just running my Integration Tests from VS.\n. I'll take this one, and #746 as it's in the same area\n. I'll take a :athletic_shoe: :football: at this one\n. Looking at Octokit.rb the Get Archive Link method just returns the URL returned in the Location header, so I started thinking and thought I'd ask, for Octokit.net should we provide two methods:\n- one that just returns the URL in the Location header, and \n- one that (somehow) follows the redirect and returns the contents of the archive?\n. First option is the easy one :grinning: It's the second one that will take some :thought_balloon: \n. Just waiting for the :white_check_mark: from AppVeyor :smiley: \n. While writing some tests for ObservableRepositoriesClient.GetAllPublic(int since) I ran into some issues...in ConnectionExtensions.GetPages the resp.HttpResponse.ApiInfo object is null, the same test but calling ObservableRepositoriesClient.GetAllPublic() works just fine...is this something that you are aware of (couldn't find any raised issues on the matter)? If not, I can dive into some debugging to try and find the culprit :smile:\n. No idea :grimacing: will take a look later on tonight and see if I can figure out what is going wrong.\n. Well...colour me :flushed: turns out the issue was the person typing on the keyboard. I hadn't setup the mock object properly. :sob: It's working now that I've got it setup correctly.\n. That'd be my fault, I was trying to come up w with a good solution for getting the contents of the file and then we got super busy at work.\nI might have some time this weekend to have another look at it again.\n\nFrom: Nikolay Kostovmailto:notifications@github.com\nSent: \u200e23/\u200e04/\u200e2015 0:29\nTo: octokit/octokit.netmailto:octokit.net@noreply.github.com\nCc: Henrik Anderssonmailto:henrik.a.andersson@outlook.com\nSubject: Re: [octokit.net] Repository Get Archive Link (#765)\nWhen this will be merged?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/pull/765#issuecomment-95206669\n. Happy for you to merge this PR now, and I'll send a new one for the content stuff :+1: \n. Nice little sample of what errors for this convention test will look like :grimacing: https://ci.appveyor.com/project/Haacked15676/octokit-net/build/1.0.847/tests\n. As long as AppVeyor gives me a nice green :white_check_mark: this is ready for review\ncc @shiftkey \n. Dropped :smiley: \n. This is ready for review\ncc @shiftkey \n. Test updated and muted\n. Questions answered :fist:  :v:\n. :v: :ok_hand: \n. Yes, the test is to return all the users a specific user (alfhenrik in this case) is following.\nI must admit though that it is a bit confusing due to the namings here..perhaps it should be GetAllFollowers instead of GetAllFollowing...\n. And I may have actually broken the test as I cleared all users I was following...oops\n. Since I ~~want~~ need this, I'll send a PR for it\n. Champion! Thanking you very much :cake:\n\nFrom: Brendan Forstermailto:notifications@github.com\nSent: \u200e19/\u200e05/\u200e2015 18:55\nTo: octokit/octokit.netmailto:octokit.net@noreply.github.com\nCc: Henrik Anderssonmailto:henrik.a.andersson@outlook.com\nSubject: Re: [octokit.net] Add SHA property to MergePullRequest (#804)\n@alfhenrik it's now available in v0.12 on NuGet.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/issues/804#issuecomment-103403534\n. :shipit: :trollface: :grinning: \n. Other than those {} being a few spaces short, I'm liking it :+1: :+1: Will certainly make it easier to ensure that the codeformatting stays the same :grin: \n. Yep, sounds good to me. \nReading the API docs, the purpose of that endpoint is to redirect to the actual content so we should probably adhere to that I guess :smile:\nAnd if someone is crying out for functionality to get just the link then we can reconsider and add that back in.\n. \n. Thanks for the reminder to update ScriptCs.Octokit to latest octokit.net :grin:\n. I've just tried to get my little vNext app running on dnxcore50 (on OSX) and there's a couple of kinks with the HttpClient support on *nix systems at the moment dotnet/corefx#2155, now I haven't tried it on a Windows machine so can't say if it'll work or not there, but it seems that it should...might have some time next week to test it out if no one else beats me to it.\nRunning on dnx451 works though.\n. I can take this one, ease my way back into Octokit again :laughing: \n. OK, so it seems that the CommitsClient.Get function isn't returning any Files property in the response and according to the API docs it isn't expected to be returned.\nSo, perhaps you're looking for the RepositoryCommitsClient.Get as this returns all files changed in a commit of the specified SHA, and this is also specified in the API Docs.\n. I can confirm I'm seeing the same thing as @Red-Folder, running the test in VS fails with a timeout. Start Fiddler, then run the test in VS and the test passes. I'll see if I can dig a bit deeper and figure out what is going on.\n. I'm unable to replicate this error locally, even running the same commands that AppVeyor runs (i.e. the git commands to get the code) yields a successful unit test run :cry: Could it perhaps be something environmental to AppVeyor...\n. I'm installing VS2013 on my Server 2012 R2 dev machine and will test it on there as well\n. Everything works fine on my 2012R2 dev machine as well...so I'm quite stump as to why it would be failing on AppVeyor...\n. Yea, needs to have the setter as protected... :)\n. Yes, it should just be as easy as adding that property to the class and a ctor parameter. :grinning: \n. I'll take this one :)\n. :+1: will update PR tonight\n. NewRepositoryWebHook now conforms to the model request guidelines of required properties are added as ctor parameters with read-only properties and optional properties are added as read-write properties.\nAlso added a method, ToRequest(), that merges the passed in config object with the webhook specific config properties that is used when passing the object to the API.\nFailing test is the known StopsMakingNewRequestsWhenTakeIsFulfilled.\n. We now throw an exception with a more helpful message if the user has added any webhook specific config values to the config parameter in the ctor.\nCome to think of it, I need to do a bit of refactoring to clean this up a bit...\n. I think this is now done, just awaiting the :white_check_mark: of approval from AppVeyor\n. crap, totally missed your comment... :disappointed: will try and fix it up as soon as possible.\n. OK, merge conflicts sorted, now just waiting for AppVeyor\n. :+1: \n. Hahah, that's pretty funny :grinning: \n. Looks good, I like it :+1: \n. :+1: \n. Out of the two, I like Slack better, but I'm :cool: with either.\n. That's a bit unfortunate...I like Slack a lot, but if that's their stance, then perhaps Gitter would be a better alternative...\n. This guy https://github.com/octokit/octokit.net/blob/master/Octokit/Models/Request/NewRepository.cs#L43 should be bool? as it's an optional parameter...\nI can send a PR or leave it for someone else to get their feet wet with contributing to octokit :smile: \n. As was I when I discovered it, I'm guessing we don't run the integration tests that often anymore as they take forever (aka timesout)?\n. :+1: \n. This is looking awesome! :+1: \n. Oooh, this looks interesting :)\n. Hello,\nYou could do the following:\nvar client = new GitHubClient(new ProductHeaderValue(\"my-cool-app\"));\nvar basicAuth = new Credentials(\"username\", \"password\"); // NOTE: not real credentials\nclient.Credentials = basicAuth;\nvar userTask = await client.User.Current();\n// Or if you don't do async/await\n// var userTask = client.User.Current();\n// var user = userTask.Result; <-- This call will fail if you passed bad credentials\nThe call to client.User.Current(); will fail if the credentials are wrong.\nHope that helps!\n. To use the GitHub login page to authenticate your users you should follow the OAuth web flow described here https://developer.github.com/v3/oauth/#web-application-flow\n\nFrom: Kamranmailto:notifications@github.com\nSent: \u200e14/\u200e11/\u200e2015 18:30\nTo: octokit/octokit.netmailto:octokit.net@noreply.github.com\nCc: Henrik Anderssonmailto:henrik.a.andersson@outlook.com\nSubject: Re: [octokit.net] How to use this package in ASP.NET Web forms? (#962)\nSo where should i use ClientId and SecretId ?\nAnd do you think its true to get Users username and password?\nIs there any way to use this package to Authenticate user with GitHub login page?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/issues/962#issuecomment-156669443\n. I can take this if no one else has started it\n. LGTM :+1: \n. \n:sob: \n. Yep, can understand that :grinning: \n. D'Oh, white space!\n. Whitespace gone the way of the dodo \ud83d\ude0a \n. \nTo be back submitting OSS PRs again!\nThank you guys!\n. LGTM :smiley: \n. According to this you can specify conditional build configurations depending on branches\n. :cold_sweat: that took a lot more effort than I expected, but I finally got it working by adding the below to appveyor.yml\ndeploy:\n- provider: NuGet\n  server: <yournugetfeed> # Remove to push to NuGet.org\n  api_key:\n    secure: <secureapikeyfromappveyor>\n  skip_symbols: true\n  artifact: /octokit.*\\.nupkg/\n  on:\n    branch: release\n    APPVEYOR_REPO_TAG: true\nThere is one caveat to this, it will push an extra package and I have not been able to get the build to not include it...\npackaging\\Octokit.0.17.0.nupkg\npackaging\\Octokit.Reactive.0.17.0.nupkg\ntools\\Octokit.CodeFormatter\\Octokit.CodeFormatter.nupkg\n. \n:rocket: :fireworks: :tada: :confetti_ball: \nThe below works a treat\ninit:\n  - git config --global core.autocrlf input\nbuild_script:\n  - cmd: build.cmd BuildApp\n  - cmd: build.cmd UnitTests\n  - cmd: build.cmd ConventionTests\n  - cmd: build.cmd CreatePackages\ntest: off\nnuget:\n  account_feed: true\n  project_feed: true\nartifacts:\n- path: 'packaging\\octokit*.nupkg'\n  name: OctokitPackages\ndeploy:\n- provider: NuGet\n  server: \n  api_key:\n    secure: \n  skip_symbols: true\n  artifact: OctokitPackages\n  on:\n    branch: release\n    APPVEYOR_REPO_TAG: true\n. Isn't this a duplicate of #904? :smiley: \n. As I'm about to embark on a new .NET Core side project in which I'd (most likely) like to use Octokit I can have a look into this one\n. I'm sorry to say it but, I thought I was in a position to have a crack at this, but it turns out I'm not...so I'm walking away from it. Thought I'd just mention it here so if someone else wanted to pick it up they don't need to confirm the status from my side.\n. @shiftkey it seems this fix didn't make it in to the Breaking Changes section of the release notes (I realised as it broke a couple of my scripts after I upgraded to latest), mind having a look and adding it in there?\n. I was using RepositoryIssueRequest but it inherits the State property from IssueRequest so all good.\n. Just tested this again, and it seems that this bug is still around \ud83d\ude1e . If no-one else has already picked this one up, I'll jump on it.\n. OK, so the blog post specifies the preview header as application/vnd.github.cryptographer-preview while the GPG Keys doco specifies the preview header as application/vnd.github.cryptographer-preview+sha...so the question is, which one is correct? \nI'm going to go with the one from the doco for now to get started.\n. @shiftkey cheers, I'll update my PR later tonight\n. I'll get a start on this and add in a few TODOs to use the AcceptHeaders.ReactionsPreview property being introduced in #1335 \n. There's #1295, #1296, #1297 and #1298 to add Reactions to the various payloads.\n. RE: renaming IssueCommentReactions, perhaps just naming it Reactions is better? \nI know #1335 is adding a Reaction model, but that is different to this one...but is it going to get confusing?\n@shiftkey @ryangribble thoughts?\n. Yep, or I could add the AcceptsHeader in this PR (which would cause a slight merge conflict in #1335), but it looks like #1335 is almost ready for a merge so I have no problem with waiting \ud83d\ude04 \n. \ud83c\udf89 look at all those \ud83d\udc9a builds! Clearly @shiftkey's mono fix worked \ud83d\ude01 \n. \ud83d\udc4d will do it tonight\n. PR updated to use new AcceptHeaders.ReactionsPreview instead of local variable. Just waiting for \ud83d\udc9a \ud83d\udc9a from the running builds\n. Oh, you are too kind sir! \ud83d\ude04 \n. Thanks @ryangribble, I've pushed fixes for your comments.\n. No problem, I'll do that soon\n. Rebased and ready for review again\n. Looks like NSubstitute now support .NET Core\n. All tests are now passing \ud83c\udf89 so this is ready for someone to cast their \ud83d\udc40 over \ud83d\ude01 \n. Thanks @dampir, I'll add in the necessary overloads and tests\n. > I also realised, we should be adding paging support to any GetAllxxx() type methods (ie an overload taking ApiOptions class, with the default method passing ApiOptions.None through to it). Again, assuming paging is actually supported on that end point of course.\nLooking at the API docs, it doesn't look like the endpoint supports paging, but I'll do some Fiddlering to see if it might actually support it, just being undocumented.\nWell, Fiddlering confirms that the endpoint does support paging, I'll add that in as well\n. OK, this should now be good to go\n. Pretty sure that TravisCI failure isn't because of me...looks like that random build failure we've seen before...\n. Other than some superfluous whitespace, this looks good to me \ud83d\udc4d \n. I've run through all the tests locally and it's all \ud83d\udc9a  I'm happy with these changes \ud83d\ude01 \n. Apart from (possibly) a couple of missing XMLDocs, the code looks good to me \ud83d\udc4d \n. Looks good to me!\n. Do I count? \ud83d\ude03 Code looks good to me \ud83d\udc4d. I'd like to put my face on this one. And while I'm in the area, I'd like to put my face on this one too. > You can now use the affiliation parameter with the List collaborators endpoint to filter a repository's collaborators by their affiliation type.\nThere is already a CollaboratorRequest class that is used when creating/updating a collaborator to set their permissions and I don't think I can re-use this class for the affiliation parameter (looking at the code it'd add all the properties of the class to the query string)? \nShould I add a new class ListCollaboratorRequest(?) with the Affiliation property and use that for the List collaborators endpoint?\n\nThe Create team endpoint now offers the maintainers parameter which will allow you to add team maintainers upon creation.\n\nLooks like this has already been implemented https://github.com/octokit/octokit.net/blob/master/Octokit/Models/Request/NewTeam.cs#L43. > create a machine account, add it as a member of your organization and give it access to the appropriate teams and repositories it needs to get stuff done\nThis is what we've done with our slack bot for releasing Octopus and it works well! \ud83d\ude04 . @ryangribble sounds like a good plan, I was actually thinking that myself this morning when I was pushing the latest commits. Happy to rename to PermissionLevel as that's what we're checking here.. Hmm...OK, running tests from command line works for me (not sure what I was doing this morning), looks like it's ReSharper's test runner that gets into a weird state...so that's fine. Closing this.. Fixed that last nameof issue. I'll have a look at pagination support, I (probably incorrectly) assumed it would have the same issue as the previous PR. Cheers @ryangribble, I'll hopefully get to it tomorrow or on the weekend.. I'm just gonna update the test accounts used for the tests I did earlier as I've used my real account in some of them. . I'll \ud83d\ude4c for this one.. I'll take this one. The existing IMigrationsClient.GetAll method is the only .GetAll method I could find in all clients that has a return value of Task<List<T>>, this makes for some fugly code that needs to use .ToList() on the call to the new .GetAll with ApiOptions from the existing .GetAll method. \nShould I refactor the existing method to return a Task<IReadOnlyList<T>> instead to be consistent with all the other .GetAll methods?\n~It also seems it's one of only a few that use async/await, i.e. return await ApiConnection.Get<List<Migration>>(endpoint, null, AcceptHeaders.MigrationsApiPreview).ConfigureAwait(false);.~\n~Should I refactor this to remove the async/await, again to be consistent with the other clients...? (although, that would mean changing all the methods in that class so might not be worth it here)~. I'll put my hand up to get this sorted. Aaaand I ran into the you are limited to sending 50 invitations to a repository per 24 hour period limit...\nI'll be back!. I'm not sure I should be counted as a key contributor any more...\n. Looks like this was implemented in https://github.com/octokit/octokit.net/pull/1845. I started looking into this, but had a thought before I did any work on it. \nWould it be necessary to have the warning in the intellisense of every method (that's a lot of copy-\ud83c\udf5d) or would it be enough to add it just to the intellisense of the class and constructor?. Should this issue be closed as the sample for the docs has been added?. Thanks @ryangribble, no rush \ud83d\ude03 . I think I found the list of languages https://github.com/github/linguist/blob/master/lib/linguist/languages.yml. I'm sure there was a valid reason at the time why I went with StartsWith and Contains, but I'll take a look and see if we can be more terse as suggested.\n. Alright, I'll add that\n. Something I found last night redoing these tests is that the order parameter is coming back as Descending, but after having a look at the API docs here http://developer.github.com/v3/search/#parameters-2 I realised the order parameter is either asc or desc.\nThe SortDirection enum (https://github.com/octokit/octokit.net/blob/master/Octokit/Models/Request/IssueRequest.cs#L91) values has a Parameter(Value=\"\") attribute applied to it, so should that automagically :sparkles: convert Descending to desc or is there something that needs to be done.\nOr, will the API accept Descending as the value of the  order parameter?\ncc @shiftkey \n. I'll take a look tonight\n. We could do this (a rough first attempt):\n```\nstatic class SortDirectionExtensions\n{\n    public static string ToParameter(this SortDirection sortDirection)\n    {\n        var member = sortDirection.GetType().GetMember(sortDirection.ToString()).FirstOrDefault();\n        if (member == null) return null;\n    var attribute = member.GetCustomAttributes(typeof(ParameterAttribute), false)\n        .Cast<ParameterAttribute>()\n        .FirstOrDefault();\n\n    return attribute != null ? attribute.Value : null;\n}\n\n}\n```\n. Or this even, so it can be used on more than just the SortDirection enum\n```\n    public static string ToParameter(this Enum prop)\n    {\n        if (prop == null) return null;\n    var member = prop.GetType().GetMember(prop.ToString()).FirstOrDefault();\n    if (member == null) return null;\n\n    var attribute = member.GetCustomAttributes(typeof(ParameterAttribute), false)\n        .Cast<ParameterAttribute>()\n        .FirstOrDefault();\n\n    return attribute != null ? attribute.Value : null;\n}\n\n```\ncc @shiftkey \n. You could add System.Collections.Generic in a using statement together with the other usings at the top, makes the method a bit cleaner.\n. Same here...\n. Same as with the ones below\n. and here :)\n. Shouldn't the file name be BaseSearchRequest.cs?\n. Yessir!\n. :lipstick: should be ClientSuffix\n. good :eyes:!\n. Currently, yes it most likely will :smile: but when I created the test, it ran for a few seconds, so I can at least say I tested the feature :grimacing: \nI'll mute it when I do the fix for the comment below.\n. Yep, certainly as if you wanted to find ALL public repos you'd just call the parameterless GetAllPublic method :see_no_evil: \n. Uhm.......\ud83d\ude32\nI have no idea where that would have come from...I will of course remove said reference quicker than quick \ud83d\ude01\n\nFrom: Brendan Forstermailto:notifications@github.com\nSent: \u200e23/\u200e04/\u200e2015 3:10\nTo: octokit/octokit.netmailto:octokit.net@noreply.github.com\nCc: Henrik Anderssonmailto:henrik.a.andersson@outlook.com\nSubject: Re: [octokit.net] Repository Get Archive Link (#765)\n\n@@ -1,5 +1,6 @@\n \ufeffusing System;\n using System.Reactive.Threading.Tasks;\n+using Microsoft.SqlServer.Server;\n\nWait, what?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/pull/765/files#r28893592\n. That's what ctrl-c, ctrl-v gets you, shouldn't trust previous methods in same class :innocent: (just kidding)\n. This looks a bit odd to me :hushed: \n. aaaahhh...sorry, I must have forgotten to put on my :eyeglasses: when I looked over this...it was the indentation that got me...:nothingtoseehere: :movealong: :flushed:\n. I would've thought I did see something that suggested that the Message property was optional, but can't for the life of me remember (or find) where.\n. So right now, it will fail with the following error An item with the same key has already been added. :bomb: This is of course due to the way the equality comparison on a key value pair checks the object, not just the key.\nSo we can introduce a custom equality comparer\n``` csharp\npublic class WebHookConfigComparer : IEqualityComparer>\n    {\n        public bool Equals(KeyValuePair x, KeyValuePair y)\n        {\n            return x.Key == y.Key;\n        }\n    public int GetHashCode(KeyValuePair<string, string> obj)\n    {\n        return obj.Key.GetHashCode();\n    }\n}\n\n```\nand use that like this\ncsharp\nvar allConfigs = Config.Union(new Dictionary<string, string>\n            {\n                { \"url\", Url },\n                { \"content_type\", ContentType.ToParameter() },\n                { \"secret\", Secret },\n                { \"insecure_ssl\", InsecureSsl.ToString() }\n            }, new WebHookConfigComparer());\nThis way we will only include distinct key/value pairs based on the key itself, the value that would be used is the one that was passed in the config parameter in the ctor. Personally I'm leaning to that we should be using the values of the NewRepositoryWebHook properties to override the values in the config parameter...although, maybe we should throw a helpful error message if they pass web hook specific config values in the config parameter...thoughts?\n. Yea, I'm not too keen of unexpected behaviour of a framework :smile: so I'm happy to return an error message if duplicate keys exists.\n. Yes, that is correct. We handle casing and _s automatically. I.e. html_url maps to HtmlUrl\n. \ud83d\udca9 sorry! \ud83d\ude07 \n. Yes of course...not sure what I was thinking there \ud83d\ude15 \n. That's very odd as I'm pretty sure I copied those from the API documentation...I'll fix it and check the docs if there might something pointing to just http.\nAh, the original comment I copied from (in IIssuesEventsClient) has http instead of https...that'll teach me for blindly copy-pasting \ud83d\ude04 \n. Unnecessary whitespace \ud83d\ude00 \n. Done\n. And done\n. XMLDocs for consistency?\n. Here too\n. whistling I was just testing you \ud83d\ude09. well, that's embarrassing... \ud83d\ude0a . (that'd be because of my copy-\ud83c\udf5d  \ud83d\ude04). I'll double check. So I just tested it, and it seems that _gitHub.Organization.Member.Delete() does not remove pending invitations. No, that's my 2FA test account \ud83d\ude42 . \ud83d\udc4d . Hmm...I think this was an involentary change.... ",
    "pltaylor": "I didn't phrase the fix correctly in the pull request.  Please close this.\n. Is there anything left in this issue?\n. I'm good with OCD.  Honestly some days I need a little more.\n. Is there anything left on this?\n. Ok I tried to rebase on Octokit.Net master to get the build to function properly, and now I have a pull request that has a bunch of other peoples commits in it.  Any suggestions on how to fix this PR?\n. Thank you for the help.  Not used to working with pull requests and this has definitely been a learning experience.\n. Comment edited for clarification.\n. I have a commit with tests in it, but before I push it up I am having problems with the build.  The Build command is complaining that it is missing the Microsoft.Windows.UI.Xaml.Csharp.targets file.  It has this same error on the master branch as well.  Any thoughts on fixing the build so I can run the tests that I wrote and make sure they run correctly?\n. Yes.\n. It appears a reboot fixed it.\n. This is ready for review now.\n. I'm up for implementing the Observable version if you guys are up for some hand holding.  Honestly the reactive portion of this project was what interested me as I have been looking for an excuse to learn/play with it.\n. Ok...and now for a little more Git handholding:)  I have my issue-comments-uri branch.  I have pulled the latest master branch from upstream and it has the latest commits, including the one I am interested in the ObservableIssueClient commit.  Am I going to screw anything up in the pull request if I rebase the branch to the latest master?\n. This is ready for review now.  It has the observable class and tests to go along with it.\n. p.s. you are correct that I pulled upstream master into my master branch.\n. Where should this be exposed?  Directly in GitHubClient or is there a better place?\n. I was struggling with the naming myself.  In the issue you refer to an 'Activity', but the Github documentation really only refers to 'Events'.  I seriously considered just IEventsClient and drop the activity name all together.  http://developer.github.com/v3/activity/events/ (And now that I type this and paste the doc. link in I see /activity/events!!!  Damn naming.)\n. So much for jumping the gun....Which would you prefer?  IEventsClient, or IActivityEventsClient?\n. OK....so the class structure will be IGitHubClient.Activity.Event.GetAll();  So we are going to add one more layer to map to what the GitHub docs have?\n. I'm good with it...consistency beats creativity ever freaking time.\n. Is there anything else this needs?\n. All makes sense.  Let me dig away on those.\n. That should be everything except the enum deal.  Please triple check the hand edited mono files...cause they are hand edited :)\n. Is there a list of possible encoding types somewhere in the documentation?\n. That is a completely reasonable way to read the docs and I missed it.  Enum coming up.\n. Ok...this isn't as easy as I thought it would be.   'Utf-8' isn't a valid value for an enum, and if I use just use 'Utf8' the Json serializer fails to de-serialize correctly.  The options I see to go forward are a) leave it a string b) edit the SimpleJsonSerializer to scrub '-' from enum values coming in c) use a method that I don't know about...yet.\n. Can you clarify how you would like me to fix the merge problem?\n. Definitely have to give credit where credit is due....the FAKE team did an awesome thing with that fix projects command.\n. There is another conflict in apiurls....it is probably from my other PR....give me a second and I'll merge it back into master and push it up.\n. That is weird.  I ran the command and committed the new project files before the merge and after the merge they disappeared.\n. With the latest Fake build do I still need to add the files to the other projects?\n. I did it manually for this PR, but it is fantastic to know I won't have to in the future!!\n. I'm sorry this needed the mono files updated.  I thought I did that.\n. Thanks for the scapegoat...but I did it manually....so the blame, as insignificant as it may be, rests over here.\n. I saw this in some of the other clients and had no idea what was going on.  So I went with what made most sense to me.  Def. makes sense now that you put it that way.\n. I admit....it was a cop out to make it a string.  It certainly makes sense to make it an enum if we know the values.\n. Is there an api for getting the current list of events?  (Just thinking out loud here)\n. @Haacked I say we just leave it a string for now then.\n. ",
    "justinvp": "Also worth mentioning: for any (valid) remaining uses of async/await, consider using ConfigureAwait(false) to avoid the marshaling costs that @paulcbetts mentions.\nStephen Toub says it best:\n\nAs a library implementer, it\u2019s a best practice to always use ConfigureAwait(false) on all of your awaits, unless you have a specific reason not to; this is good not only to help avoid these kinds of deadlock problems, but also for performance, as it avoids unnecessary marshaling costs.\n. \n",
    "Porges": "R# can automate (simple instances of) this - search & replace:\nasync Task<$T$> $id$($args$)\n{\n    return await $ex$;\n}\nWith:\nTask<$T$> $id$($args$)\n{\n    return $ex$;\n}\nWith the appropriate placeholders - you should constrain ex to Task<$T$> or you'll get invalid replacements where there's an implicit conversion (i.e. Task<T> isn't covariant in T), or when awaiting observables.\nUnfortunately R# bug RSRP-274520 makes this harder than it should be (R# strips the comments and access modifier from any methods affected), so you can't really use automated replace.\nAt the least this helps to locate them, it's something I've added to my custom patterns catalogue.\n. ",
    "dahlbyk": "\n@forki I used http://teamcity.codebetter.com in the past for ColorCode, but I'd rather find a true CI host. Most of the ones out there don't currently quite do all we need (building all branches is a big one).\n\nHow do you mean \"true CI host\"? TeamCity should be able to support building all branches... /cc @ajepst\n. @brlinton I'll take care of an IObservableMilestonesClient for you to use in IObservableIssuesClient\n. > what's the best way to incorporate your changes?\nTo rebase your changes on mine:\ngit pull --rebase https://github.com/dahlbyk/octokit.net.git ObservableMilestones\n. More better?\n. Prereq for #126\n. Now with \u221e more tests, though no integration test that exercises paging.\n. Sorry for missing the IObservableAssigneesClient references here - you probably want to include ObservableAssigneesClient as well.\n. It's not an issue, it's a feature.\n. Blah, thought I'd checked on that in a different client but I appear to have been looking at the wrong thing. Will fix.\n. Maybe Returns the <see cref=\"Uri\"/> for the specified comment.?\n. \"...for the comments of a specified comment\" still sounds weird. This URL identifies an individual comment, not more than one.\n. Let me take a closer look at this - I'm pretty sure we need parameters for the initial call but you're probably right that it's redundant for successive calls. Assuming that's the case, how does this look?\n``` diff\n         public static IObservable GetAndFlattenAllPages(this IConnection connection, Uri url, IDictionary parameters = null, string accepts = null)\n         {\n-            return GetPages(url, nextPageUrl => connection.GetAsync>(nextPageUrl, parameters, accepts).ToObservable());\n+            return GetPages(url, parameters, (pageUrl, pageParams) => connection.GetAsync>(pageUrl, pageParams, accepts).ToObservable());\n         }\n\nstatic IObservable GetPages(Uri uri,\nFunc>>> getPageFunc)\nstatic IObservable GetPages(Uri uri, IDictionary parameters,\nFunc, IObservable>>> getPageFunc)\n         {\nreturn getPageFunc(uri).Expand(resp =>\nreturn getPageFunc(uri, parameters).Expand(resp =>\n             {\n                 var nextPageUrl = resp.ApiInfo.GetNextPageUrl();\n                 return nextPageUrl == null\n                     ? Observable.Empty>>()\n: Observable.Defer(() => getPageFunc(nextPageUrl));\n: Observable.Defer(() => getPageFunc(nextPageUrl, null));\n             })\n             .Where(resp => resp != null)\n             .SelectMany(resp => resp.BodyAsObject);\n``\n. This is our only chance to apply parameters - without passing them in here, they're not respected. I don't suppose you or your colleagues know of a public repo with more than a page worth of Milestones for testing purposes? At least for the first page, this does correctly apply parameters.\n. > Ah right. Why'd you remove theaccepts` parameter? That seems like it should be necessary if we need to pass something other than the default. Or do we not need to do that here?\n\nMilestonesClient doesn't pass accepts, so I'm not either. I believe it's still correctly wired up in GetAndFlattenAllPages though.\n. ",
    "ajepst": "Hi all, I run the CodeBetterCI server, (thanks for the ping, @dahlbyk) and you're welcome to host this project on CodeBetterCI if it meets your needs, since all we require is an open source license, which I see you have. BTW, Your MIT license would be nicer if it had a title on it, though you do at least have the title on your README-take pull requests?\nRegarding your question about branches, see this post by Hadi: http://blog.jetbrains.com/teamcity/2013/02/automatically-building-pull-requests-from-github-with-teamcity/\nIt's talking about pull requests, but given that they're branches, it should be easy to configure something similar for other sorts of branches. (Hopefully I'm not completely mischaracterizing that since I'm talking to people who would actually know..ahem.)\nAnyway, if you have other questions about http://teamcity.codebetter.com or TeamCity's capabilities, let me know and I'd be happy to help!\n. Anyone can create an account over there - of course I can reset passwords if you need it, @half-ogre ! http://codebetter.com/codebetter-ci/ has a bit of info about the build server - mostly about what is NOT on the build agents. Anyway, once you log in, you'll see at the top is a little yellow box with a link to a bit of info about a form to request access (easy to make sure we get all the info we need if you fill that out) Fill that out and I'll get your build set up.... and whoever you want to be an admin on the project can be-just specify who you want. (can be multiple people)\n. @hahmed TravisCI is GREAT but doesn't support Windows/actual .Net, and though the same project can do both, it's a) not a freebee to get it running\\continuing to run on both, and b) having CI for one and not the other (either way) is definitely not \"enough\"-we support Mono too (some people like their stuff all in one place) and I see the trouble they have getting their builds all to work at the same time, especially initially. If you all want to support Mono and not .Net, TravisCI will be enough. Otherwise, you're stuck with me too. Given the way TravisCI operates-not to mention that insane thread @shiftkey linked, it's hard to imagine them supporting a Windows build anytime soon, if ever, given their approach and the current automation-unfriendliness of Windows... at least as compared to Linux.\n@forki Looks like that build will need to run on our newer server that supports .net 4.5... I just moved that build over (builds get moved there on an as-needed basis until we work out upgrading all the servers). But your main problem is that it looks like we're missing a targets file your project is expecting. (no VS on the servers) Easiest fix - I'll see if I have it locally and copy it up. Or maybe you have it if I don't. We'll get it working. (Also, I've got the same id everywhere, email me at gmail or tweet me if you'd like to take this off-thread)\n. Honestly, I'm not that familiar with TravisCI's capabilities, so can't help\nyou there, unfortunately-I can speak for CodeBetterCI, though, which has a\nMono build agent you're welcome to use-and if it doesn't have a version of\nMono that works for you, we can fix that.\nOn Wed, Nov 13, 2013 at 5:44 PM, Paul Betts notifications-at-github.com|github|\nj4464d63qt@sneakemail.com wrote:\n\n@ajepst https://github.com/ajepst Does Travis CI support very recent\nversion of Mono? That would honestly get us like 95% of the value of CI,\nthe platform differences should be really quite minimal.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/issues/119#issuecomment-28446007\n.\n. Hi, James has been less involved lately - but I'll be happy to help. First, @adamralph , you should be able to turn off notifications after you log in by clicking on your name at the top right, and then selecting the notifications rules tab.  Or, I'd be happy to archive the build if you want to go that way.\n. absolutely, I'll go ahead and do that.\n\nOn Thu, Jul 10, 2014 at 5:47 PM, Brendan Forster notifications-at-github.com\n|github| j4464d63qt@sneakemail.com wrote:\n\n@ajepst https://github.com/ajepst are you able to archive that build?\nIt's no longer (or never?) been used, so it's just wasting space and\nresources over there...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/532#issuecomment-48674649..\n. \n",
    "brlinton": "I'd love to help, but am crazy new at this - just cloned the repository and looking through it now.\n. @Haacked thanks!  I'm having trouble executing all of the tests after working through the setup / build instructions - 32 of them fail with a System.MissingMethodException on a Task method.  Looks like it's tied to test classes with async tests?\n. Thanks @dahlbyk, as I was working on it I just realized I need that too :+1: - what's the best way to incorporate your changes?  Should I just wait until it gets merged into master?\n. @shiftkey that took care of the test issues on my side, except for four of the integration tests (creating a new private / public repository, retriving closed issues, and \"IsALukeWarmObservable\").  I would expect the private repository test to fail with the account I'm using but it looks like it's creating public repos just fine.\n. Here's a pull request - let me know what I can do to make it better!\nhttps://github.com/octokit/octokit.net/pull/145\n. @Haacked I wasn't sure how to handle incorporating dependent changes.  Should I just wait until the others are merged into master and send a separate pull request?  I'm a bit new at this and not sure what the best practice is.\n. Cool, thanks for the heads up.  I'll wait until the Reactive Milestone work is pulled in and try again.  Should I submit a new PR when my changes are ready or attempt to rebase / clean up this branch?\n. ",
    "sleppin": "@Haacked Looking at the sources the client should be implemented in the IGitHubClient interface exposing itself as a property.\nAm I right? \n. Okay, I'm going to implement the References API in the ActivityClient.\nThx for the heads-up!\n. ",
    "ninjanye": "I'd like to contribute.  Since the 'easy-fixes' have all been gobbled up I thought I'd take a crack at one of the API implementations.  Would this one be a good place to start? Seems to be one of the easier ones to implement...\n. Ok, thanks.  I'll get cracking... do I need to publicly mark this issue as something I am working on or could someone else come along and fix it up quick-sharp?\n. No, don't worry, just wanted to be sure I wasn't missing anything\n. Should IObservableTagsClient be added to the IObservableGitHubClient? I noticed not all observable clients have been added and can't see the reason why?\n. Thanks for the speedy response guys.  That sounds good to me, I'll implement that now.\n. Just to clarify IGitDatabaseClient should live in the Ocktokit.Reactive project but should not be IObservableGitDatabaseClient\n. I thought as much but just wanted to clarify.  Thanks again.\n. Hope the PR is ok (usual first time nerves).  Thank you both for your guidance through this.  If the Tags implementation is ok I'd be happy to try and complete the remaining DB API tasks.\n. I managed to get the serializer to work by enabling the DataContractSerializer (in SimpleJson.cs).  Not sure if I should be altering that file so please let me know if I have to find an alternative solution.  From what I can tell the options would be one of the following:\n- Rename the Tag class to something other than tag and rename the Name property to Tag so that automatic property binding works\n- Implement attribute recognition on the POCOJsonSerializer (similar to DataContractSerializer but we would be able to identify our own attribute to recognize and not rely on DataContract exising on the class in question)\nThanks again for your patience.\n. Please disregard my last commit. The DataContractJsonSerializer did not resolve the issue.  I'll re-visit this in the morning, however I believe one of the above alternative solutions may now be required...\n. I've implemented the above changes and my tests are all passing, however after pulling the latest version of master an running the new build script (which is great) I receive test failures.  I've gone through these and they don't appear to be caused by me as they were all passing pre merge\nHere is the result of the build:\n\n. Yeah, I've been trying to keep it up to date with upstream master but will update again as it has been a while.\nRe the failing tests: When I run in test explorer inside VS2012 all tests pass except 2 which create private repo's (not allowed on my test account).  When I run the build.cmd in powershell 37 tests fail, all of which are throw System.MissingMethodException as in the screenshot.\nI was kind of hoping Issue #162 which referenced this pull request was related?\n. Fingers crossed.  I've merged with master and re-pushed. Let me know if you need anything else. FYI: I haven't been able to create any integration tests as yet as I am reliant on some other api's, which have yet to be developed as yet.  I hope that doesn't cause too much of an issue although it is something I plan to do.\n. I'll fix up the this keywords (can blame my Resharper settings for that).  I will also update the other issues you raised in a new PR.  Thanks for making my first OSS contribution as painless as possible.  I'll try and tackle some of the other DB APIs once the tags api is cleaned up.\nP.S. Loving the gifs\n. I have just pushed the Commits API implementation. Hope it is ok\n. I noticed that each time I ran build.cmd it replaces my shared SolutionInfo.cs with a previous version (version without AssemblyVersionInformation as an internal static)\n. Deleting the tools/FAKE.Core folder fixed the SolutionInfo.cs issue.  But unfortunately the build falls over on Code Analysis errors (that are not present when building in VS).  These errors are not on classes I have created, however I am happy to fix this up if it has not already been raised elsewhere.\nThanks for the quick feedback\n. I did just before pushing but i'll try again\nUpdate: Just pulled again.  `build.cmd' still has CA errors.  There are only 2 but they are repeated a few times\n: (-1,0): CA1704 : Microsoft.Naming : Correct the spelling of 'Color' in member name 'Label.Color'\n: (-1,0): CA1704 : Microsoft.Naming : Correct the spelling of 'Prerelease' in member name 'Release.Prerelease'\n. I can do the mono fixes with the rest of the fixes.  I'll have to do this tomorrow now as approaching 1am and head is getting a tad fuzzy.  Should be ready for you when you hit the office tomorrow.  Will set the title back to WIP:\n. Hopefully I have fixed all the issues you mentioned.  Turns out the CA errors were because my very british environment couldn't forgive you for leaving the 'u' out of Colour :smiley:\n. I have also noticed that when #SIMPLE_JSON_TYPEINFO is defined in SimpleJson.cs the json deserialization does not deserialize inherited properties.  I managed to reproduce this in a test and have made a fix in a new branch \nhttps://github.com/ninjanye/octokit.net/commit/7d389853ff81e4b7823a9e2d8449a1107cb36573.  \nSimpleJson.cs : Line 1723 - 1745\nLet me know if you want me to PR this as it may be beyond the realms of what you want me to tampa with.\ncc: @half-ogre (I think I remember this is your domain)\n. @Haacked  By https://github.com/simplejson/simplejson\ndo you mean... \nhttps://github.com/facebook-csharp-sdk/simple-json\n. @forki @haacked does it also identify duplicates? I noticed one of the proj files had a duplicate interface and no implementation class added\n. This stuff is awesome... Where can I learn this voodoo?\n. I haven't seen any of these types of tests currently in the project so this might need removing (or moving) however it was useful for me identify some errors with my class structure\n. Yeah, sorry.  Let myself down a little there... will correct it\n. I used the name from the response of the api...\nhttp://developer.github.com/v3/git/commits/#get-a-commit\nIt represents the parents and tree objects\n. I had the same thought and was going to ask you about it.  I think a lot of objects can inherit from GitReference\nUnderstand re the Uri type now\n. Changed the name as the same definition is being used for a Tagger a Committer and an Author.  I'm not happy with the name either but it was the best I could come up with...\n. ",
    "gabrielweyer": "@Haacked I started to work on this one and implemented \"List comments on a pull request\" but the returned object has a few extra fields compare to the documentation (diff_hunk, original_position, original_commit_id, html_url, pull_request_url, _links). As they're not documented I'm wondering if I should I also read those fields?\n. @pengwynn I sent a pull request :smile: \n. Thank you for the feedback, I'll start to work on it tomorrow.\n. > If we don't get a 201, we should throw an exception here, perhaps something like ApiException with a helpful message...\nHow can I access the Http Code in my Create method?\n\nCould we write some tests where a user comments on their own pull request?\n\nSo I experimented with two users of mine:\n1. You can't fork an empty repository\n2. You can't fork your own repository\nThe way write integration tests would then be:\n1. User A creates a repository\n2. User A creates a blob\n3. User A creates a tree\n4. User A creates a commit\n5. User B forks the repository\n6. User B creates a blob\n7. User B creates a tree\n8. User B creates a commit\n9. User B creates a pull request\nAfter this we can finally start to create / edit / delete / get review comments :smile: \nA few API are still missing:\n- Create a blob\n- Create a tree\n- Create a fork\n- Create a pull request\nI wrote one integration test that will be ignored for the moment as we need more features in order to test this. As soon as those features are ready I will happily add all the other needed integration tests.\nI removed the _links field from the object as the three links are present in other fields anyway.\n. > Something like this?\nYes this worked perfectly. I commited the change.\n. I incorporated the changes that you suggested.\nAccording to my testing UpdatedAt is set to the value of CreatedAt when creating a comment.\nAfter merging master into my branch I encountered a few issues:\n- build.fsx is rewriting incorrectly SolutionInfo.cs\n- ThrowsTwoFactorChallengeFailedExceptionWhenProvidedCodeIsIncorrect is failing\n. @shiftkey \nI ran git clean -xdf and it fixed the issue for SolutionInfo.cs :smile: \nI also can't reproduce the failing test anymore! The test would fail occasionally before but I ran the build.cmd script multiple times and couldn't get it to fail again. The output of build.cmd in PowerShell is really different from what I was having before so It's probably because I has some old artifacts somewhere.\nHey looks like I spoke too fast! The test failed again on my 5th build:\n```\nTest assembly: D:\\Code\\open-source\\octokit\\Octokit.Tests\\bin\\Release\\NetCore45\\Octokit.Tests-NetCore45.dll\nOctokit.Tests.Clients.AuthorizationsClientTests+TheGetOrCreateApplicationAuthenticationMethod.ThrowsTwoFactorChallengeFailedExceptionWhenProvidedCodeIsIncorrect [FAIL]\n   NSubstitute.Exceptions.ReceivedCallsException : Expected to receive a call matching:\n        GetOrCreateApplicationAuthentication(\"clientId\", \"secret\", any NewAuthorization, \"wrong-code\")\n   Actually received no matching calls.\n   Stack Trace:\n      at NSubstitute.Core.ReceivedCallsExceptionThrower.Throw(ICallSpecification callSpecification, IEnumerable1 matchingCalls, IEnumerable1 nonMatchingCalls, Quantity requiredQuantity)\n      at NSubstitute.Routing.Handlers.CheckReceivedCallsHandler.Handle(ICall call)\n      at NSubstitute.Routing.Route.<>c__DisplayClass3.b__0(ICallHandler x)\n      at System.Linq.Enumerable.WhereSelectArrayIterator2.MoveNext()\n      at System.Linq.Enumerable.FirstOrDefault[TSource](IEnumerable1 source, Func`2 predicate)\n      at NSubstitute.Routing.Route.Handle(ICall call)\n      at NSubstitute.Core.CallRouter.Route(ICall call)\n      at NSubstitute.Proxies.CastleDynamicProxy.CastleForwardingInterceptor.Intercept(IInvocation invocation)\n      at Castle.DynamicProxy.AbstractInvocation.Proceed()\n      at Castle.Proxies.IAuthorizationsClientProxy.GetOrCreateApplicationAuthentication(String clientId, String clientSecret, NewAuthorization newAuthorization, String twoFactorAuthenticationCode)\n      d:\\Code\\open-source\\octokit\\Octokit.Tests\\Clients\\AuthorizationsClientTests.cs(232,0): at Octokit.Tests.Clients.AuthorizationsClientTests.TheGetOrCreateApplicationAuthenticationMethod.d__38.MoveNext()\n393 total, 1 failed, 0 skipped, took 3.056 seconds\nRunning build failed.\nError:\nSystem.Exception: xUnit test failed on D:\\Code\\open-source\\octokit\\Octokit.Tests\\bin\\Release\\Net45\\Octokit.Tests.dll, D:\\Code\\open-source\\octokit\\Octokit.Tests\\bin\\Release\\NetCore45\\Octokit.Tests-NetCore45.dll.\n   at Microsoft.FSharp.Core.Operators.FailWithT\n   at Microsoft.FSharp.Collections.SeqModule.IterateT\n   at Fake.XUnitHelper.xUnit(FSharpFunc2 setParams, IEnumerable1 assemblies)\n   at FSI_0001.clo@64-6.Invoke(Unit _arg6) in D:\\Code\\open-source\\octokit\\build.fsx:line 65\n   at Fake.TargetHelper.runTarget@291(String targetName)\n```\nMost likely a race condition as it doesn't fail consistently.\n. @Haacked @shiftkey Do I need to do any other change?\n. @Haacked I replaced the read only fields by private setters in the auto properties and moved the constructors at the top.\n. @shiftkey I fixed the integration project. I also integrated blob and tree creation into my integration test.\nWe still need Create a Fork and Create a Pull Request. Then I can start the testing. We also need to create a second test user in order to fork the repository (I don't think you can fork your own repository). What do you think of creating two extra environment variables:\n- OCTOKIT_GITHUBUSERNAME_2\n- OCTOKIT_GITHUBPASSWORD_2\nOf course this means that each developer will need two testing accounts.\n. In this case (and if you're happy with the changes I made) I think we're done :smile: \n. @shiftkey You're right. We don't need a fork in order to create a pull request. You can branch your own repository, commit a file and then you can create a pull request.\nHowever I still need Create a Pull Request to be implemented in order to be able to write the integration tests.\n. @shiftkey Sorry that it took so long. I've been extremely lazy :flushed: I wrote best case integration tests. Let me know if you want tests for when things go wrong too. If not I think we can close this one!\nAlso I took the liberty to extend the timeout of the integration tests to 20 minutes (from 10) as it was consistently timing out before running all the tests on my machine.\n. @shiftkey anything else you need me to do finish up?\n. @shiftkey This should do it. I was just wondering if we should have different commit objects as the returned payloads are different. If not the work is done :smile: \nI would consider throwing a more meaningful error when the JSON deserialization is failing. I was getting a meaningless NullRef, it should probably be wrapped in a try catch and rethrow with the name of the property and the value.\n. @shiftkey should be fixed now :smile_cat: \n. My bad, fixed too quickly all the Resharper's warning. Will remember this for next time. Anyway I removed the namespace. Let me know if there is any other issue.\n. @iss0 Are you still working on this?\n. I somehow managed to confuse myself (again) and used an email address instead of a username for OCTOKIT_GITHUBUSERNAME. I ran the tests again and only a few are failing, they're completely unrelated to my changes so I'll create a new issue to address them.\n. RepositoryExistsException has also logic around the account being an organization or not.\nThe easiest way to fix this without changing the behavior would be to replace this line:\nAssert.Equal(Helper.Credentials.Login, thrown.Owner);\nBy\nAssert.Equal(\"There is already a repository named '\" + repoName + \"' for the current account.\", thrown.Message);\nBut that're more like putting a band aid. It doesn't seem to be the right way of handling this case (ie if name is null then it's not an organization)\n. Let me do a quick PR to see how this would like :smile: \n. :bowtie: \n. Added everything that was missing. Left out gravatar_id from the user payload as it has been deprecated.\n. I didn't run the build script locally, I'm a bad man :cold_sweat: \n. I'll take a stab at this.\n. @shiftkey you can close this one, I'll open some other PR over time (probably after the Christmas break as I'm not taking my laptop with me).\n. There are three different type of comments to consider here:\n1. The issue comments\n2. The pull request comments\n3. The pull request review comments\nWhat I was supposed to implement was the pull request review comments. On my pull request it didn't return any result because there was no review comment. Since you just added one now there is one result (and there will be two after I post this one :smile:) .\nI think this page of the API documentation needs to be updated as this is where you're supposed to fetch the comments associated with a pull request. We would then need to update this issue accordingly.\nDoes that make sense (I might be completely mistaken as I'm brand new to the Github API)?\n. Sorry when you said:\n\nif Body should never be null, then let's make it a read only property and pass it into the constructor for this class. \n\nI assumed that you wanted a readonly field :smile: In fact you wanted an auto property with a private setter. I'll do the changes.\n. In the previous version of the code ExistingRepositoryWebUrl was being set only if the owner is an organization. This is due to fact that we don't have access to the owner's name if it's an account and not an organization.\n. > Ah. And we don't have access to the name because when we do operations for the current account, the name isn't needed as part of the URL. Right?\nExactly :smile: at least the integration test is passing now!\n. :+1: pushed another commit fixing this.\n. ",
    "jrsconfitto": "i still see this issue on my Surface Pro on Windows 8.1. Is this something that the new licensing agreements and #219 will fix?\nWhen i build through build.cmd i see:\nError:\nBuilding ./Octokit.sln failed with exitcode 1.\n   at Fake.MSBuildHelper.build(FSharpFunc`2 setParams, String project)\n   at Fake.MSBuildHelper.MSBuildWithProjectProperties@245.Invoke(String project)\n   at Microsoft.FSharp.Primitives.Basics.List.iter[T](FSharpFunc`2 f, FSharpList`1 x)\n   at Fake.MSBuildHelper.MSBuildWithProjectProperties(String outputPath, String targets, FSharpFunc`2 properties, IEnumerable`1 projects)\n   at Fake.MSBuildHelper.MSBuild@255-1.Invoke(IEnumerable`1 projects)\n   at FSI_0001.clo@59-5.Invoke(Unit _arg5) in [redacted]src\\octokit.net\\build.fsx:line 60\n   at Fake.TargetHelper.runTarget@284(String targetName)\nand then the message described at the top.\ni'm glad to see i'm not the only one that sees this message. For a while i felt like i was taking crazy pills.\nAlso, when i visit the link for more information i land on a search page. It's extremely helpful :rage1:.\n. Sure! Here's a gist of what's immediately above along with the entire output from running one build.\n. Yeah, VS2013.\n. Unfortunately, not on this machine. I have it installed on a Win 7 machine. Can we use that? If not, i don't mind installing VS 2012 today.\n. Not sure. When i make that switch:\n\n...and rebuild. i still get yelled at:\n\ni thought i registered with their developer program/whatever to put out Windows Store apps. i'll make sure that's up to date as well and see if that helps me build this project.\n. VS2012 downloads are hard to find now. Maybe tomorrow i can dig around the MSDN dvd collection...\n. i plan to include tests and ping someone when i think they're ready for review.\n. Hop on the force push :trolleybus: :trollface:\n. Y U shift from key git practices like force push?\n. OK, @shiftkey! i want to fill out the rest of the starring API, but i'll make those separate PRs (unless you think it'd be good to do them here).\n. Sorry, i didn't see the merge conflict (too bad it's not shown right on GitHub to the person submitting the PR as well). Or am i just missing something?\ni know there's not much left, but i figured i'd get whatever input i could before moving on. i've already got them in the works...\nThanks for the explicit instructions :smile: \n. i'm hoping that does it... although i've busted the build on my machine here in the process <sad trombone>.\n. > do we have any pointers on getting test data into the integration test suite? It'd be nice if we could setup the test data as part of the setup/teardown of these tests...\nAs far as the tests, i can copy some json responses into the test fixtures and construct some tests around that. i don't mind throwing in my own API responses for stuff like stars. Is that what you are asking about here, @shiftkey?\n. Thanks for the checkup @Haacked, i really appreciate it.\ni have a few commits that have been sitting around on my machine for a while that i haven't pushed up. i'll shove them up here and then ask a few questions i have.\n. OK, that implements all of the starring API (if my memory serves).\ni would like to add more tests and would appreciate some direction in what tests you'd like added. While that's going on, i think this is ready for some review!\ni did change the DeleteAsync to return Task<IResponse<object>> in this commit so i could verify that i was getting a NoContent back from the request. i think that was OK, but i want to call it out as something you may want to look at.\n. i also had trouble getting the FAKE builds going on my machine :frowning:. Sorry about that.\nRight now i get:\nbuild.fsx(45,21): error FS0039: The value, constructor, namespace or type 'ProjectSystem' is not defined\nAny ideas on why that might happen and how i can fix it?\n. Funny, i just pulled from upstream this morning. This project is speedy.\nThanks @Haacked, i'll get on it.\n. OK, ready for another round of review?\n. OK, i took care of your latest suggestions.\ni changed the name of the client variable in activities from Star to Starring and i left the client name as StarredClient. i'm not sure if that's the way to go, but i tried to make it closer to GitHub's API docs.\n. Tests!? bwahahahahaha. Yeah, i tested this a lot, using both unit tests and a little console app just to make sure i wasn't living in a dream world where all unit tests pass, but nothing actually works (Pleasantville, maybe?).\nThanks for the encouragement and the review, @Haacked! :metal: \n. Aight, let me come at you bro :smiling_imp: \nIt's probably my own misunderstandings about this codebase, but i'm becoming less convinced of that. i'm not entirely confident about this, so please bear with me while i lay it out (in many, many words).\ni think that Skipped test might be important because i'm seeing the correct next page Uri overwritten by old parameters when running through the ApplyParameters method. i'm only seeing this happen in situations where parameters are passed into the GetPage method. \nReproduction\ni tried to reproduce this using the Milestones client in the master branch, but i don't know any repos with enough milestones for more than 2 pages (:rage:)! Maybe you know a good one to test? Make sure you pass some request parameters into the original API call.\ni've seen this behavior crop up when developing my own PR based around the starred API. Try the following:\n- Fetch up to this commit in my PR\n- Use the following code:\n``` c#\nvar APIConn = new ApiConnection(Conn);\nStarredClient sClient = new StarredClient(APIConn);\nvar starRequest = new StarredRequest()\n{\n    SortProperty = StarredSort.Updated,\n    SortDirection = SortDirection.Descending\n};\nvar stars = sClient.GetAllForCurrent(starRequest).Result;\n```\nWhen i run this, i get stuck in a bad state always requesting page 2 while the next Uri shows page 3 in the query string.\nWhat i think is happening\nSeems to me this only crops up when passing request parameters into the original call because this leaves parameters non-null in the GetPage method (ref).\nWhen the code gets around to getting the nextPageUri, the old parameters are still there and overwrite the good parameters that are in the nextPageUri given by GH's api.\nThe End?\ni hope that was clear enough. i'm still reasoning through how all this is happening in my head. Thanks for letting me externally process a bit.\nThoughts? Am i just Doing It Wrong?\n. I'm hoping to write a test for this when i get a chance. A failing test would be a lot better than my wall of text!\n. Bummer, a per_page parameter would be super helpful right now. i guess i'll add that to my personal list of PRs to create.\n. Just a convenience for the way i was thinking to add to the Milestones client integration tests. i wouldn't have to create very many milestones to test over a few pages.\n. Sorry, that wasn't super relevant to this...\n. Not a problem, thanks!\n. Have y'all had enough? Or are you thirsty for more?\n\n. OK, @Haacked. Care to throw some :eyes: over this one? \n. :wink: \n. i realized that 404s show up as NotFound exceptions, which means they would never even hit that block of code. It seems funny to me to write an Ensure type method like:\nc#\nif (response.StatusCode != HttpStatusCode.NoContent)\n{\n  throw new ApiException(\"Invalid Status Code returned. Expected a 204\", response.StatusCode);\n}\nreturn true;\nDo we want to be that guarded about the status codes returned?\n. Maybe it would be good to push this kind of thing out into an extension method so other clients can use it? Something that would look like: statusCode.EnsureAcceptableStatus(acceptableStatusCodes);\n. Wow, that make so much sense. i totally missed that.\n. :smiley: \n. ",
    "khellang": "Not sure if it's related, but I'm also having trouble building the sln in VS2013. 3 out of 4 builds break with the following errors/warnings:\n\nAnyone seen this before?\n. @adamchester I actually managed to get rid of the errors (not the warnings) by performing this hack. Don't know what other consequences it might have, though. :worried:\n. Thanks for great feedback! I also think it would be better to just drop the namespaces. They provide no value in the test project, I just added them for consistency. \nThe whitespace in the using directives is a result of R#'s \"optimize using directives\", there should be a DotSettings for the sln with a separate one for test projects so it would be easier for contributors to follow the coding/naming style. Want me to file an issue?\nI'll fix the stuff mentioned ASAP :wink:\nBTW, I had trouble building the sln in VS2013. The build seems very brittle, about 3 out of 4 builds breaks with an error complaining about code analysis. I'll add a screenshot to #143\n. One more thing. The GetAll with sub-namespace, what do you think of the name? I see that other clients have GetFor and GetAllFor names. Should we call it GetAllForSubNamespace?\n. @shiftkey Now the only thing missing is the 404 check and error message :smile:\n. > we might need to review that the IObservable versions are also in sync\nSounds like a ~~unit~~ convention test :wink:\n. Uuuh. I don't really remember :confused: I think it might be because the API expects an object and not just a string;\njson\n{\n  \"body\": \"Just commenting for the sake of commenting\"\n}\nIs it causing problems?\n. If anything, it's a BodyRequest :wink: https://github.com/octokit/octokit.net/blob/1cea52eefa67d094e165b5f06a2d9dbad0330490/Octokit/Clients/GistCommentsClient.cs#L56\n. Nooooo! This is not in yet? Has someone started on this? :smile:\n. :+1: \n. I :heart: these convention tests! Great for contributors (get instant feedback from CI), great for you guys (don't have to nag contributors). Win-win! :grin:\n\n. Let's move this (the part not related to Octokit specifically) over to the OSS .NET repo so it's easier for the framework team to follow/participate in the discussion... oh, wait... :wink:\n. Excuse my ignorance, but what's the reason to force strong named assemblies to only reference other stong named assemblies in the first place?\nEDIT I found this\n\nWhen you reference a strong-named assembly, you expect to get certain benefits, such as versioning and naming protection. If the strong-named assembly then references an assembly with a simple name, which does not have these benefits, you lose the benefits you would derive from using a strong-named assembly and revert to DLL conflicts. Therefore, strong-named assemblies can only reference other strong-named assemblies.\n. I moved GetReadme and GetReadmeHtml to the new IRepositoryContentsClient to reflect the API better and obsoleted the old methods. Hope that's OK :smile:\n. Also, if you want me to strip the first commit (changed RepositoryComments to Comments and PullRequest to PullRequests), please shout out.\n. @shiftkey Does that :+1: mean that you want me to strip the commit? :stuck_out_tongue_closed_eyes: \n. Uuuh, I just saw #231. It hasn't been updated in 3 months. Should I still follow through with this or wait for the other PR to land?\n. To get the actual content, how do you feel about having a single method Task<IReadOnlyList<DirectoryContent>> GetForPath(string owner, string name, string path) which gets the parent directory and checks if the requested content is a file, dir, symlink or submodule. It then returns either a list with a single file, symlink or submodule, or a directory listing. We could then provide extension methods that has relevant return values (and other validation?), e.g. FileContent, SymlinkContent or SubmoduleContent. This means that you don't have to know what type the content is before doing the call, but you have to cast (OfType<T>) afterwards. I pushed a commit to show what I mean. It's basically what @jasonrudolph mentioned in #231.\n. Actually, the more I think about it, the more I'm leaning towards differentiating GetFile, GetSymlink, GetContents, etc. and just throw if you mess up. Most clients would start out at the root anyway, right? So it would be easy to switch on the type when enumerating from there. In that way you don't get the overhead of fetching the parent directory and checking the type up front...\n. Hey guys! Sorry I haven't been able to pull this through. I might have some cycles this weekend to take a look at it again. \n\n@shiftkey Do we really want to do it this way? E.g. get parent folder and check whether it's a file/directory/symlink etc. or do we just want to make the user check or know up front?\n. @shiftkey Yes! Let's take the pragmatic approach :smile: It felt a bit wrong to do 2 API calls for each requested file/directory.\n. I can also punch the code if we nail the desired API down :smile:\n. @shiftkey Yep :smile: Looking forward to the spec. then :wink:\n. :+1:\n. Getting repository commits is not implemented yet. See #333. Feel free to give implementing it a shot and send a PR :wink:\nThe method you've found can also get a specific commit, but with a lot less data than the repository commit endpoint. The reference parameter is actually a commit SHA, I think it's just badly named. \nAlso check out the documentation for repository commits and git data commits. The API should match the documentation pretty well.\n. You can get a list of the authenticated user's emails through IUserEmailsClient: \nvar emails = client.User.Email.GetAll()\nRead about the endpoint here :smile:\n. Also, there's a note in the documentation for the user endpoint:\n\nNote: The returned email is the user\u2019s publicly visible email address (or null if the user has not specified a public email address in their profile).\n. What resource is this related to? According to the docs, it'll only be present when fetching a single PR. Looks like merged_at and merged_by will be there for most resources.\n. You could possibly change it to a property with a backing field, then in the getter, if the field is empty, return MergedAt.HasValue?\n. There's only so much an external contributor can do :wink:\n. BTW, the docs on the new endpoint is way off compared to what you actually get back over the wire :stuck_out_tongue_closed_eyes: \n. Rebased and made setters protected to address #650 :smile:\n. :fire: DotSettings - done :ok_hand: \n. Also, does https://github.com/octokit/octokit.net/commit/1e1039ff244fda2d8ca4b78f4da6f136160b6b4f mean that all List<T> properties etc. can be converted to IReadOnlyList<T>?\n. Changed test in https://github.com/khellang/octokit.net/commit/619a282572672dad9cde718850d0e218b96b62e0 to verify handling of readonly collections, and it works beatifully :grin: Maybe there should be a convention test that verifies that collections are of the right type? Is there a reason for sometimes using IReadOnlyCollection<T> over IReadOnlyList<T>?\n. Maybe also expand this to check that properties have protected setters? I can take this after #658 is in :smile:\n. LOL. Doesn't look like the convention test that checks for DebuggerDisplayAttribute checks response models at all. It gets the method return types from the client interfaces, but those are Task<T> and Task<IReadOnlyList<T>> etc., so they're filtered out using the TypeExtensions.IsModel method. I think we need to unwrap those types first... See https://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Conventions/DebuggerDisplayOnModels.cs#L29\n. OK, the reason there's all this stuff going on is because it's hard to identify request/response models (everything is same assembly, same namespace etc.).\n\nHere are some suggestions:\n1. Introduce namespaces (breaking, ugly)\n2. Add marker interfaces, IRequestModel and IResponseModel.\n   - This could further be enforced by adding generic constraints on IApiConnection's methods.\n3. Add attributes, RequestModelAttribute and ResponseModelAttribute.\n4. Keep scraping client interfaces for parameter- and return types to determine request- and response models.\nWhat do you think?\n. Alright. I'll just check if the return type is generic, get the generic parameter(s), check if the its assembly is Octokit, if it is, return it, otherwise, recurse. Sounds like a plan?\n. Soooo... There are 89 files in the response model folder, but I only detect 59 types in the tests. I guess this is because many of the models isn't top-level and thus isn't exposed through an interface. Do you want me to walk the tree to pick up non-top-level models as well? \u00af(\u00b0_o)/\u00af\n. The tree of type dependencies :smile: A RepositoryTag has a property with type GitReference, which again has a property with type User etc.\n. Yeah :smile:\n. There has to be a circular reference in there somewhere as well :grin:\n. Now I got up to 71 :stuck_out_tongue: Looks like 8 of the files are enums, which are filtered out. Wonder what the remaining 10 files are... could they be unused?\n. Hey! Collections! Same problems as earlier. Forgot to unwrap generic types :smile: Now I got 'em all - and 13 new failing tests :smirk: I'll fix those tomorrow.\n. Ugh. Now the DebuggerDisplay test fails. Have to fix that tomorrow :smile:\n. > LOL. So sorry!\nIt's all fun :grin:\n. This PR got a bit out of hand. Once I started finding more models, the good old DebuggerDisplay test started failing as well. Anyway, now all model should have read-only properties and a DebuggerDisplayAttribute (with corresponding property) :grin: This makes #660 a super quick-fix.\n. \n. Wouldn't it be cool if it was possible to - ahem - re-target PRs? :innocent: \n. Is there some sort of server-side cache? Cache invalidation is Really Hard\u2122\n. What's up with these newline warnings? Some .gitattributes TARFUN? :confused: \n\nwarning: CRLF will be replaced by LF in Octokit/Clients/AssigneesClient.cs.\nThe file will have its original line endings in your working directory.\nwarning: CRLF will be replaced by LF in Octokit/Clients/FollowersClient.cs.\nThe file will have its original line endings in your working directory.\nwarning: CRLF will be replaced by LF in Octokit/Clients/GistsClient.cs.\nThe file will have its original line endings in your working directory.\nwarning: CRLF will be replaced by LF in Octokit/Clients/OAuthClient.cs.\nThe file will have its original line endings in your working directory.\nwarning: CRLF will be replaced by LF in Octokit/Clients/PullRequestsClient.cs.\nThe file will have its original line endings in your working directory.\nwarning: CRLF will be replaced by LF in Octokit/Clients/RepoCollaboratorsClient.cs.\nThe file will have its original line endings in your working directory.\nwarning: CRLF will be replaced by LF in Octokit/Clients/StarredClient.cs.\nThe file will have its original line endings in your working directory.\nwarning: CRLF will be replaced by LF in Octokit/Clients/TeamsClient.cs.\nThe file will have its original line endings in your working directory.\n\nGit insists that the files has changed, even though they haven't. At least not intentionally :stuck_out_tongue_closed_eyes: \n. Is that a good setting to use, globally? I guess I have it on true (on Windows) now. Isn't there some way to set it and check it into the repo?\n. WTF? :confused: \n\nStarting Target: SourceLink\nsource linking C:\\projects\\octokit-net\\Octokit\\bin\\Release\\Net45\\Octokit.pdb \n1 source files do not have matching checksums in the git repository \nno checksum match found for C:\\projects\\octokit-net\\Octokit\\Clients\\MiscellaneousClient.cs \nRunning build failed.\nError:\nSystem.Exception: 1 source files do not have matching checksums in the git repository\n   at FSI_0001.SourceLink.GitRepo.VerifyChecksums(GitRepo x, IEnumerable1 files) in C:\\projects\\octokit-net\\tools\\SourceLink.Fake\\tools\\SourceLink.fsx:line 36\n   at FSI_0001.Build.clo@103-16.Invoke(String pf) in C:\\projects\\octokit-net\\build.fsx:line 107\n   at Microsoft.FSharp.Collections.SeqModule.Iterate[T](FSharpFunc2 action, IEnumerable1 source)\n   at FSI_0001.Build.clo@97-15.Invoke(Unit _arg9) in C:\\projects\\octokit-net\\build.fsx:line 99\n   at Fake.TargetHelper.runTarget@317(String targetName) in D:\\code\\fake\\src\\app\\FakeLib\\TargetHelper.fs:line 331\n. I give up :sob: \n. Ok, here we go again... :smile:\n. Phew! :sweat: \n. Sounds like...CommitCommitter:trollface: \n. Nice! :fire: dat trailing whitespace! Maybe you should change theCopyright \u00a9 Microsoft 2012thingy while you're at it :wink:\n. @shiftkey Why do you define the endpoint URIs inline and not inApiUrls? Going away from it?\n. I've seen this a :hankey:-load of times. I think it's a NuGet bug. Could you try running$error[0].Exception.ToString()` in the Package Manager Console?\n. @shiftkey It's been a while since I saw it, but in my previous job I used to get it all the time (when installing packages referencing System.Net.Http). I can't really remember anything special about the project setup, just a regular .NET 4.5 class library or web app, all in C#.\n. @shiftkey There were PCLs involved in the sln though. Maybe even referenced by the projects, but I can't imagine why that would matter... :confused: \n. I can take a stab at this. Been porting quite a few projects lately. I probably won't have time until the new year arrives, though.\n. > but PCL support continues to torment me\n\nWhat does this mean? Do you still want to target a PCL profile?\n. > However the one that I can never get right is Profile259.\nWhat do you mean by \"get right\"?\nI think we should just ditch\n- Octokit-Mono.csproj\n- Octokit-MonoAndroid.csproj\n- Octokit-Monotouch.csproj\n- Octokit-Portable.csproj\n- Octokit-netcore45.csproj\n- Octokit.csproj\nAnd aim for a single project.json with dotnet5.1, which is roughly the same as Profile259 (it has the same targets). That should also be Future-Proof\u2122, until netstandard1.0 takes over.\n. Like this; https://github.com/khellang/serilog/commit/15eaf8c9b97617d8a840d88d0c6db10146064849\n. Also, SecureString is being removed/internalized with .NET Core.\nSee https://github.com/dotnet/apireviews/tree/master/2015-07-14-securestring and https://github.com/pallavit/corefx/commit/612bf7ee4ef454c9bb9ebdf69970d70cf7b3dec3\n. What about creating a specialized object for holding the repos? This way you could use a custom collection initializer, forcing the user to specify both owner and repo name.\n. Sent a PR at #842\n. What's up with the CI build?\n. Something like this (just the other way)? http://kristian.hellang.com/building-csharp-6-code-with-appveyor/\n. I'm not really sure if this builds, because I get all sorts of errors in VS 2015. I had hoped the CI build would tell me, but no luck there either :stuck_out_tongue: \n. @Red-Folder I sent you a PR at https://github.com/Red-Folder/octokit.net/pull/1, I still haven't addressed the threading issue, though.\n. @Nasicus You should be fine using the regular Octokit package as well, the Octokit.Reactive package just wraps the former with IObservable<T> overloads. The API should be exectly the same, just install Octokit and replace ObservableGitHubClient with GitHubClient :smile:\nThe problem with the current approach is that you're awaiting an IObservable<GitHubCommit>, which will return the last result. See Rx and Await: Some Notes.\nIf you really want to use the reactive API, you should correctly subscribe to the observable, using the Subscribe method. Its callback argument will be called for each GitHubCommit in the repository.\n. Also, hopefully, Visual Studio would complain since LangVersion is set to 5 :wink:\n. Have you thought about when you'd like to cross over to the greener C# 6 side?\n. In addition, Octokit should validate the format and throw if it's invalid.\n. :clap: \n. :shipit:\n. Ugh. That didn't work so well...\n\n[00:00:00] Build started\n[00:00:02] git config --global core.autocrlf input\n[00:00:02] git clone -q https://github.com/octokit/octokit.net.git C:\\projects\\octokit-net\n[00:02:32] fatal: early EOF\n[00:02:32] fatal: The remote end hung up unexpectedly\n[00:02:32] fatal: index-pack failed\n[00:02:32] error: RPC failed; result=18, HTTP code = 200\n[00:02:32] Command exited with code 128\n. :shipit: \n. > I might run into problems implementing that interface with the same concrete type.\n\nExplicit implementations might be your friend here :smile:\n. Y NO SLACK?\n. Phone, phone, phone -> Slack :wink: Also, Gitter is kinda buggy :cry: \n. The only thing that suck with Slack is the invitation model, but we recently set up slackin for Nancy and it works like a charm.\nJust spin up https://github.com/rauchg/slackin and give it an API key.\n. @M-Zuber What kind of integration are you looking for?\n. There's also https://rocket.chat/ :wink:\n. @naveensrinivasan The dotnet TFMs are gone and replaced by netstandard1.0 - netstandard1.4.  See the platform standard docs. There's no point in trying to use it yet, cause there's no (stable) tooling that supports it.\n. You probably want to track https://github.com/dotnet/corefx/issues/4367 for this.\n. Ping @prabirshrestha and ask what he's been up to? :wink:\n. How is that different? You're still creating a new HttpClient, right?. And what's the reason you can't do the same with GitHubClient?. No, it creates a HttpClient per GitHubClient instance. This is the code path when creating a GitHubClient:\nhttps://github.com/octokit/octokit.net/blob/90b0a7c551e840312dd535a0ca285da5650f00ba/Octokit/GitHubClient.cs#L28-L29\nhttps://github.com/octokit/octokit.net/blob/90b0a7c551e840312dd535a0ca285da5650f00ba/Octokit/Http/Connection.cs#L113-L114\nhttps://github.com/octokit/octokit.net/blob/90b0a7c551e840312dd535a0ca285da5650f00ba/Octokit/Http/HttpClientAdapter.cs#L26-L35\nAnd this actually sends the request:\nhttps://github.com/octokit/octokit.net/blob/90b0a7c551e840312dd535a0ca285da5650f00ba/Octokit/Http/HttpClientAdapter.cs#L178-L184\nAs you can see; only one instance. Did you actually get into problems with connection limits, or did you just assume that you would?. > Even if new HttpClient instances were created for each request, that shouldn't mean new connections for each one.\nI think that's exactly what it means, which is why it's advised against:\n\nHttpClient is intended to be instantiated once and reused throughout the life of an application.\nThe following conditions can result in SocketException errors:\n\nCreating a new HttpClient instance per request.\nServer under heavy load.\n\nCreating a new HttpClient instance per request can exhaust the available sockets.\n\nRelated info:\nhttps://blogs.msdn.microsoft.com/shacorn/2016/10/21/best-practices-for-using-httpclient-on-services/\nhttps://medium.com/@nuno.caneco/c-httpclient-should-not-be-disposed-or-should-it-45d2a8f568bc\nhttps://www.codeproject.com/Articles/1194406/Using-HttpClient-As-It-Was-Intended-Because-You-re\nhttps://aspnetmonsters.com/2016/08/2016-08-27-httpclientwrong/\nhttp://www.nimaara.com/2016/11/01/beware-of-the-net-httpclient/\nA static instance can also be problematic, which is why ASP.NET Core 2.1 introduced HttpClientFactory. There's also an ongoing issue about it in corefx.. :shipit: This needs a rebase, though. @shiftkey how's the C#6/project.json stuff going? Most of these should be converted to interpolated strings at some point :smile:\n. There shouldn't be a need to open a new PR. I think the steps should be something along the lines of\n- git checkout uppercase-is-not-always-right // make sure you're on the right branch\n- git remote add upstream git@github.com:octokit/octokit.net.git // if you haven't already, add a new origin to the upstream repository\n- git pull --rebase upstream master // fetch the latest changes from upstream master and rebase on top of it\n- git push -f origin uppercase-is-not-always-right // push the changes :sparkles:\n. > Anyone know if we can configure R# or VS rules to follow that convention? Or am I being too picky?\nNope. It's either the keyword or the CLR type. Keyword is default :smile:\n. :shipit::heart:\n. I think you should be able to tweak Markdig to render GFM pretty close to what GitHub itself does, if you want to avoid the roundtripping. It supports fenced code blocks, task lists, tables, as well as many other extensions.\n. BTW, this was recently announced as a breaking change on the dev blog as well.\n. I approve of this :+1: Though there are other overrides of this as well; https://github.com/octokit/octokit.net/search?q=GetObjectData\n. Is this change still needed after #1595?. You should be able to trigger a new build by rebasing this branch. @mderriey If you rebase this branch, mderriey/1582-change-model-url-properties-to-string, on top of octokit/master and force push, it should trigger a new build. This PR would probably be a good exercise for squashing as well \ud83d\ude09 . What about making EventInfo.Event some kinda union type between string and EventInfoState. It would just be a simple wrapper around a string, but would allow you to call something like TryParse(out EventInfoState) to get an enum version. That way, if the event type is new (missing from the enum), you could still handle it as a string, and it won't blow up when new types are added.\nThe type could also have an implicit conversion to EventInfoState that would continue to throw if the value is invalid. This would make it (more or less) backwards compatible.. Had to run out for lunch, but I may or may not have a PR brewing, using something like\n```csharp\n[DebuggerDisplay(\"{DebuggerDisplay,nq}\")]\n[SuppressMessage(\"Microsoft.Naming\", \"CA1711:IdentifiersShouldNotHaveIncorrectSuffix\")]\npublic struct StringEnum : IEquatable>\n    where TEnum : struct\n{\n    private readonly string _value;\nprivate TEnum? _parsedValue;\n\npublic StringEnum(TEnum parsedValue)\n    : this(parsedValue.ToString())\n{\n    _parsedValue = parsedValue;\n}\n\npublic StringEnum(string value)\n{\n    _value = value;\n    _parsedValue = null;\n}\n\npublic string Value\n{\n    get { return _value; }\n}\n\npublic TEnum ParsedValue\n{\n    get { return _parsedValue ?? (_parsedValue = ParseValue()).Value; }\n}\n\ninternal string DebuggerDisplay\n{\n    get { return Value; }\n}\n\npublic bool TryParse(out TEnum value)\n{\n    if (string.IsNullOrEmpty(Value))\n    {\n        value = default(TEnum);\n        return false;\n    }\n\n    return Enum.TryParse(Value, ignoreCase: true, result: out value);\n}\n\npublic bool Equals(StringEnum<TEnum> other)\n{\n    return string.Equals(Value, other.Value, StringComparison.OrdinalIgnoreCase);\n}\n\npublic override bool Equals(object obj)\n{\n    if (ReferenceEquals(null, obj))\n    {\n        return false;\n    }\n\n    return obj is StringEnum<TEnum> && Equals((StringEnum<TEnum>) obj);\n}\n\npublic override int GetHashCode()\n{\n    return Value != null ? StringComparer.OrdinalIgnoreCase.GetHashCode(Value) : 0;\n}\n\npublic static bool operator ==(StringEnum<TEnum> left, StringEnum<TEnum> right)\n{\n    return left.Equals(right);\n}\n\npublic static bool operator !=(StringEnum<TEnum> left, StringEnum<TEnum> right)\n{\n    return !left.Equals(right);\n}\n\npublic static implicit operator StringEnum<TEnum>(string value)\n{\n    return new StringEnum<TEnum>(value);\n}\n\npublic static implicit operator StringEnum<TEnum>(TEnum parsedValue)\n{\n    return new StringEnum<TEnum>(parsedValue);\n}\n\npublic override string ToString()\n{\n    return Value ?? \"null\";\n}\n\nprivate TEnum ParseValue()\n{\n    TEnum value;\n    if (TryParse(out value))\n    {\n        return value;\n    }\n\n    throw new ArgumentException(string.Format(\n        CultureInfo.InvariantCulture,\n        \"Value '{0}' is not a valid '{1}' enum value.\",\n        ToString(),\n        typeof(TEnum).Name));\n}\n\n}\n```\nIt's basically a drop-in replacement of the existing enum, with no additional code changes necessary because of the implicit conversion.. Nice! Thanks for correcting my sloppy work, @ryangribble :wink: Hopefully the solution will be easier to build (and run the full test suite) once the migration to SDK-based csproj goes through. \nRight now, it failed to load a couple of projects etc., to it wasn't straight forward to just run the full test suite.. @ryangribble I rebased this branch to resolve a conflict. You should probably do a pull before you start work on it \ud83d\ude09 . I'm thinking about changing the names of the values in StringEnum to Value (parsed) and RawValue or StringValue. People would generally be interested in the parsed value, and not the string value. It makes sense to change the parsed value property to something shorter. What do you think?. > Although I do wonder if it's too much of a surprise for a property called Value to potentially throw an exception?\n@ryangribble Well, that's more or less what it does today, except it'll throw when deserializing. We've essentially deferred throwing to the call site.\nWith this PR, the situation has improved, because the user can now use the TryParse method once they get an exception, without waiting for a new Octokit release with the new values.\nWhat we really want. is steer people away from the Value (and StringValue) properties and over to the TryParse method. That's the only way the API will be \"future proof\" when new enum values are added. The question is; how do we accomplish that?. Yes, with C# 7, you have the following alternatives:\ncsharp\nif (model.StringEnumProperty.TryParse(out var value))\n{\n    // access value\n}\nor, if we add Destructure extension methods to StringEnum<T>:\n```csharp\nvar (success, value) = model.StringEnumProperty;\nif (success)\n{\n    // access value\n}\n```\nI'm not sure which I like/loathe the most \ud83d\ude1d . The only enum left is Language. It's pretty hairy and I'm thinking about just adding it to the ignore list for now. What do you think?\nLanguage probably shouldn't be an enum in the first place because enums are for (more or less) fixed sets. Languages are definitely not a fixed set \ud83d\ude1b . > Not sure how we missed it but StringEnum.Equals was comparing itself to itself, rather than itself to other LOL!\nOuch. That's embarrassing... Good catch! \ud83d\ude16\n\nSort out Language enum (I'm keen to not exclude it from the tests and even change the request models to use StringEnum<Language>\n\nYeah, I think that makes sense. I wonder if there are other request model enums that could benefit by doing this? I guess Language is a good start.\n\nConsider if we want to add Destructure extensions for C# 7 (may as well, right?)\n\nYeah, I figured I'd stay away from C# 6/7 features for now. There's quite a few things that could be simplified, but I think that should be a separate PR :smile:. > Do we also have to change the serialization code to indicate how to serialize StringEnum<TEnum> instances?\nI'd expect the serializer to just fall back to a call to ToString, which should give the correct value, but we have to verify that \ud83d\ude04 . > are you sure we dont want to add destructure extensions now?\nI think we can manage without them and potentially add them with a big C# 7 upgrade PR later.. Didn't see this until now. Looks really good! :heart:. @ryangribble Thank you! \u2764\ufe0f . This was a fun PR! :heart:. I think the docs explains the strategy pretty clearly, though I haven't seen any work on this yet. If you're going to read the epic thread, I suggest you get some popcorn :wink:\nLately, there's been quite a few projects pointing to StrongNamer for questions like these. The library lets you transparently and automatically sign the assemblies you reference as part of the build process.. Looks like some usages of GetAllBranches hasn't been changed though \ud83d\ude15 . Octokit is only concerned about the GitHub API, which coincidentally exposes some primitive git metadata, but probably not at the level you're after. Sounds like you might want to use something like libgit2sharp for this. Possibly in combination with Octokit.. Would it be more convenient to provide a type wrapping the payload JSON? So you could add a method like DeserializeAs<T>(), which would deserialize the JSON into the specified type using the built-in serializer and settings?. > I am not following what this gains?\nIt gives you a really convenient way to deserialize the JSON into the type you provide, using the custom (GitHub-specific) JSON (de-)serialization settings.. > Do you think there is a use case for consumers providing their own type?\nYes, the use case is that there might be no official type for the payload yet, and you're blocked until next release. Isn't this what we're trying to fix?\n\nif someone was going to go to that effort it would be preferable they send a PR to add the model officially so everyone can use it?\n\nYes, that would be preferable. But this will let them do the work and unblock themselves first, then submit a PR :smile:\n\ncurrently you just \"have to know\" that you can cast the Payload to another type via activity.Payload as PulRequestEventPayload but there is no evidence you can do this, and no indication on what type you should use.\n\nWhat if it's a new payload type that doesn't have a type yet?\n\nIm not sure if ActivityPayload itself should be a wrapper class, similar to the StringEnum you implemented @khellang that contains the json string and can provide it as raw json or deserialized to a specific payload type, or whether we would just have a DeserializePayloadAs<T> method on the Activity object itself.\n\nIn my opinion, this problem is the exact same problem as the StringEnum problem. We don't control the payload types and new ones can be introduced at any moment. When that happens, users that want to handle that payload needs to wait for a new release (or, I guess, do the casting).\nIs this generic enough for a Payload<T>? I'm om the phone, so don't have 100% control on the door of this thing.... Yay! We've saved 6,5KB! \ud83d\ude09 . Looks like a legit failure:\nFailed   Octokit.Tests.SimpleJsonSerializerTests+TheSerializeMethod.HandlesEnum\nError Message:\n System.ArgumentException : Value '' is not a valid 'SomeEnum' enum value.. Well, the internal represenation will be string.Empty if null is passed:\nhttps://github.com/octokit/octokit.net/blob/bf0688517f4dfe5c33c5fd1786c19d31275205af/Octokit/Models/Response/StringEnum.cs#L32\nthen it'll default to default(TEnum) if you try to parse it:\nhttps://github.com/octokit/octokit.net/blob/bf0688517f4dfe5c33c5fd1786c19d31275205af/Octokit/Models/Response/StringEnum.cs#L69-L73. > I've tweaked .Value to return default(T) rather than throw an exception but I'm also wondering whether it should even be \"valid\" to pass a null into the ctor.\nBut doesn't that default the purpose of .Value? Isn't the point that it should throw an exception so you have to handle \"unknown\" values explicitly. Silently falling back to default(T) would make the application continue to run, but possibly with incorrect values.. > My reasoning is, if the response may contain nulls or omit a field, then the response class should just declare that member as a nullable type, just like we would do for a regular enum field. Only drama is any current response classes that are relying on the ctor allowing nulls to be passed in will need to be found and changed to declare as nullable. We've got pretty decent integration test coverage though so I'm considering doing this.\nAgreed. I think the current behavior (null throwing) should be expected (it is invalid after all), and the solution should be to make the response property nullable instead of silently falling back to default(T).. Yeah, I can't see anything wrong with it \ud83d\ude09 LGTM!. I think this should be tackled with https://github.com/octokit/octokit.net/issues/984. It would also make it play nicer with the new ASP.NET Core HttpClientFactory \ud83d\udc4d . There's no need... https://github.com/octokit/octokit.net/pull/1926. Since the property below now is called Content instead of Contents, maybe these should be changed as well? :smile:\n. Same with these...\n. Aaaand here...\n. You get the point :wink:\n. Can these be removed now? There are about 12 of them...\n. Thinking about it, shouldn't collection properties be initialized in the constructors and have private setters? I assume SimpleJson supports it since it supports protected setters?\n. It's a really nice tool when having to do a lot of XML docs :smile: The file is for custom settings and ignore words etc. for spell checking. GhostDoc generates it automatically for each solution I open, so I figured I might as well ignore it so I don't accidentally commit it. If you want it in the repo, I'll drop the commit :smile:\nHere's a default file:\nxml\n<GhostDoc>\n  <SpellChecker>\n    <IncludeExtensions>\n    </IncludeExtensions>\n    <IgnoreExtensions>\n    </IgnoreExtensions>\n    <IgnoreFiles>\n    </IgnoreFiles>\n  </SpellChecker>\n<HelpConfigurations selected=\"HelpFile\">\n  <HelpConfiguration name=\"HelpFile\">\n    <OutputPath>.\\Help</OutputPath>\n    <HelpFileName>Project</HelpFileName>\n    <ImageFolderPath />\n    <HtmlFormats>\n      <HtmlHelp>true</HtmlHelp>\n      <MSHelpViewer>false</MSHelpViewer>\n      <MSHelp2>false</MSHelp2>\n      <Website>false</Website>\n    </HtmlFormats>\n    <IncludeScopes>\n      <Public>true</Public>\n      <Internal>false</Internal>\n      <Protected>false</Protected>\n      <Private>false</Private>\n      <Inherited>true</Inherited>\n      <InheritedFromReferences>true</InheritedFromReferences>\n      <EnableTags>false</EnableTags>\n      <TagList />\n    </IncludeScopes>\n    <ResolveCrefLinks>true</ResolveCrefLinks>\n    <HeaderText />\n    <FooterText />\n    <SelectedProjects />\n  </HelpConfiguration>\n</HelpConfigurations>\n</GhostDoc>\n. No idea really. The lines were added automatically when opening the sln with R# 9. Want me to remove it?\n. Just changed the existing test. It didn't really test what we wanted (more or less just copied from the test above :stuck_out_tongue:).\n. IReadOnlyList<GitReference>?\n. Maybe it's a good idea to standardize on either IReadOnlyList<T> or IReadOnlyCollection<T>?\n. IReadOnlyList<WeeklyHash>?\n. Same here...\n. And here :smile:\n. Gotta love those convention tests :wink:\n. I guess I should've added these to most (all?) parameters in the other response class ctors as well, but wanted to keep to the issue at hand. Do we care?\n. These tests are also present in RepositoryContentsClientTests :confused: \n. I actually had both in there, but decided to delete the overload. I guess it doesn't hurt to have it in, since we still do the same, full, validation :smile:\n. I added a commit with the single string overloads, you can just strip them out if you decide you don't want both.\n. The only reason it implements IEnumerable<string> is because it's needed for collection initializers to work. I had originally implemented ICollection<string>, but landed on IEnumerable in the original implementation because it didn't allow simple strings.\n. This sounds like an interface for the ApiInfo itself. What about IApiInfoProvider, it seems to be more in line with the comments as well?\n. This does not have to be set here and IMO it's not a HTTP concern at all. All requests go trough Connection.RunRequest so I think it would be better to move this up a level.\n. This does not feel right. API info is not a HTTP concern (see previous comment for a potention solution).\n. Also, what about threading? Should there be a lock introduced here?\n. I think it's fine to remove the locks, it's probably a bit too much. I just brought it up because there's now some shared, mutable state going on.\n. SGTM :+1:\n. Couldn't this affect someone? It's now outputting HTML instead of XML, right?\n. I dunno. I thought maybe AppVeyor or someone might've picked it up. Just thought I'd ask :smile:\n. Why should collection properties with private setters be mutable?\n. This fails because the collection itself is mutable. It should be changed to an IReadOnlyCollection. The proposed fix makes no sense. There's already a different test that checks for setter access. :smile:\n. But this is totally out of scope for this test, and it actually makes it incorrect. This test checks that \"Response Models Have Read Only Collections\". Making it skip properties with private setters also makes it allow mutable collections, which defeats the test in the first place. There's already a test that checks for non-public setters.\n. ConfigureAwait(false)?\n. I don't think this state machine is necessary. Assert.ThrowsAsync expects a Task, which GetAllContents already returns :smile:\n. Why is this setting it to the exact same thing as the ctor?\n. Isn't this (more or less) the \"round-trip (ToString(\"o\")) format\" (ISO 8601) spelled out?\n. > Which make me realise Im currently setting the intial state in destructor but actually should always be setting OFF :smile: \n:+1: \n. Hey, if it doesn't work -- it doesn't work. Who am I to say what should and shouldn't work :wink: I think I'd ping the API team at GitHub about this, though, as it seems to me that it should be more forgiving with the values it accepts.\n. nameof? Might as well change all of them if you decide to go for it.. Can these type have other properties that should be Uri? Is it worth doing the check on type + property instead?. Also, ProTip\u2122: You can use nameof for properties on a type, i.e. nameof(AuthorizationUpdate.NoteUrl) :smile:. Oh, sorry. I just assumed this project used C# 6 by now (given that C# 7 has since been released), but I see the LangVersion elements from https://github.com/octokit/octokit.net/pull/820 are still there.... Is this needed?. This feels dirty. Does it need to be an instance method? Can we make this either a) a static method or b) a static field in StringEnum?. Same here.... > Although more work to change 42 enums, I think Im keen on my earlier suggestion of being explicit with [Parameter()] attributes on every enum member, enforced via convention test, and relied on by the deserializer\nI agree. Explicit is better. This lets us simplify the serializer as well. Want to check in the convention test? I can go through and add attributes.. Actually, why not do both?. I think this might've been a bug:\n\nWhat to sort results by. Either due_on or completeness. Default: due_on\n- https://developer.github.com/v3/issues/milestones/. This might've been a bug as well:\nQualifies which fields are searched. With this qualifier you can restrict the search to just the username (login), public email (email), full name (fullname), or any combination of these.\n- https://developer.github.com/v3/search/#search-users. I couldn't find this in the documentation, but I figured it was deprecated anyway, so... \u00af\\_(\u30c4)_/\u00af. I found this in the documentation, but not here, so just added it while I was there \ud83d\ude04. I excluded some enums from the test because they're not used in the actual API (I couldn't find documentation on them, at least. I think it might be worth crawling the request/response models and find enum types instead of looping through all in the assembly.. Brought it back from the dead \ud83d\udc4d . We really need to get rid of these before this PR is merged. Allocating a SimpleJsonSerializer every time a StringEnum is created and parsed is hella expensive when it comes to GC. I tried making it static, but for some reason tests started failing, so it seems it actually mutates some internal state, which sucks \ud83d\ude22 . Awesome! LGTM \u2764\ufe0f . How can StringValue be null at this point?. You've already verified in the ctor that _stringValue can't be null?. Couldn't this potentially lead to incorrect behavior?\n\nIf you have an uninitialized property, it means that the payload is missing the property, which means it's optional, but Octokit has modeled it as required (by it not being nullable).\nBy just silently falling back to the default value, you could potentially give the user the incorrect default (who decides what the \"default value\" is?). > But from a technical point of view - the same would be true of an enum property on a response class now wouldn't it?\nYes, but that doesn't make it any less wrong \ud83d\ude09 There's a reason you should always declare all value-type properties as nullable when binding to external input. It's the only way to check whether that input actually existed, or if it's just the default (uninitialized) value.\n\nI guess the question is, should an incorrectly not nullable StringEnum<T> behave the same as an incorrectly not nullable regular enum?\n\nI vote \"no\", simply because it's a nice way to \"flush out\" mistakes where we've assumed something was required, but was actually optional.. Let's say you have a model:\ncsharp\npublic class UpdateAccount\n{\n    public Guid Id { get; set; }\n    public decimal Amount { get; set; }\n}\nAnd someone posts\njson\n{ \"id\": \"3d216536-0869-4c9d-b2b7-2a735498c634\" }\nYou'd end up with account.Amount == 0, which would be pretty bad.\nInstead, you'd want to declare it nullable and be able to check account.Amount.HasValue and issue a validation error.. Yeah, I guess it wouldn't hurt.. By forwarding these ctors to the new DateTimeOffset overloads, the behavior has changed by taking the time into account. That could be a breaking change.\nI think the safest thing to do is to keep the existing logic (as @ryangribble noted in #1904) for these ctors and use the new (and improved) format for the new DateTimeOffset ctors.. What will the zzz component be here, given you're using the DateTime property and not the DateTimeOffset itself?. But what is that offset? DateTime doesn't store a separate offset.. See https://docs.microsoft.com/en-us/dotnet/api/system.datetimeoffset.datetime?view=netframework-4.7.2#remarks. I'd probably store this pattern in a constant and reuse it throughout.. Nit: Patten -> Pattern. Is it worth pointing out the preferred API and why you'd use it? Something like\n\nThis constructor doesn't use the time component of the specified DateTime. Please use the overload accepting a DateTimeOffset, which also supports time.. Does this compile? \ud83e\udd14. These are not ctors. Maybe also change these to reflect the recommended APIs?. I'm thinking it might be better to just use ToString(DatePattern, CultureInfo.InvariantCulture) and string concatenation or interpolation than the current format strings.... I'm thinking something like query = FormattableString.Invariant($\"{from.ToString(DateTimePattern)}..{to.ToString(DateTimePattern)}\"); \ud83d\ude04 . \n",
    "adamchester": "Yes @khellang, I get those too. I believe it's related to this issue somehow.\n. @khellang Actually, I misread those; I don't get the CA errors, but I do get the warnings\n\n. Any movement here? I'd love to take some easy-fix items but I still can't get it to build.\n. Win 8.1 vs2013... I assume at this stage I need win 8 with 2012?\n. I've never had 2012 on this machine. I'm on 2013 pro.\n. Do you mean run build.cmd with some argument that turns on diagnostic logging level?\n. OK, after doing that, this is my local git diff.\nThe build fails still, here is the output:\n\"c:\\My\\repo\\octokit.net\\Octokit.sln\" (Build target) (1) ->\n\"c:\\My\\repo\\octokit.net\\Octokit\\Octokit-NetCore45.csproj\" (default target) (5) ->\n(_GetSdkToolPaths target) ->\n  C:\\Program Files (x86)\\MSBuild\\Microsoft\\VisualStudio\\v12.0\\AppxPackage\\Microsoft.AppXPackage.Targets(451,9):\nerror APPX1639: File 'Windows.props' not found. See http://go.microsoft.com/fwlink/?prd=12395&pver=1.0&plcid=0x4\n09&ar=MSDN&sar=PlatformMultiTargeting&o1=&o2=Windows for more information. [c:\\My\\repo\\octokit.net\\Octokit\\Octok\nit-NetCore45.csproj]\n. OK, I'll stay right here and wait for you, hurry back :smile: \n. Just realised this is a duplicate of #143 \n. Confirmed - it works!\n. Actually, if we only add the GUIDs, VS2013 asks if I want to install windows 8 support:\n\nClicking this launches VS2013 setup (which I'm running as we speak... perhaps part of the problem was a missing VS setup feature?)\n. Trying now...\n. Yes, after VS2013 setup completed, the solution builds.\nSo, without those GUIDs, VS2013 is not able to recognise that the csproj requires windows 8 tooling, and gives the obscure errors during build/compile.\n. @shiftkey thanks for your help\n. @shiftkey I am preparing a PR for a few very minor changes to remove some build warnings, including one you mentioned above.\n. Is there some reason to keep the RX references targeting net40?\nIf there is a reason, then according to this link, we could probably remove the requiresReinstallation attribute, to remove the warning.\n\nIf we detect that any of your packages were affected by the retargeting or upgrade, we\u2019ll produce immediate build errors to let you know. In addition to the immediate build error, we also persist a requireReinstallation=\"true\" flag in your packages.config file for all packages that were affected by the retargeting, and each subsequent build in Visual Studio will raise a build warnings for those packages.\n. That's all for this one I think. \n. Done.\n. Where's my animated gif?\n. :smile: \n. Was this the little magic?\n. I tried lots of GUIDs, but not these specific ones.\n. @Haacked the history accurately reflects what happened. Are you trying to hide information from people? :stuck_out_tongue_winking_eye: \n. \n",
    "VirtualLobster": "I fixed this issue by changing the main project (start up project) from .Net 4.5 to 4.5.1\nI'm using VS2013. \nHope that helps!\n. ",
    "Dzonatas": "Non-standard and UNSTANDARD code is not compatible. Over.\n. ",
    "knunery": "I added the missing comments and removed the redundant Actor class.  I think I did the rebase against upstream master okay:)  \nThank you for reviewing the pull request!\n. My take away from the docs is that the encoding is utf-8 or base64. http://developer.github.com/v3/git/blobs/\n. ",
    "adamralph": "Have you managed to get this running on your CI box? I've found it either needs VS installed (something I hate resorting to) or it needs several hoops jumping through (copying DLL's etc.) to get it working.\n. Wow, I didn't know Win8 lib builds need VS. MS are often too IDE focused :unamused:\n. Oh, and I also forgot to branch, ah well, I think the demo was useful even if the resulting PR wasn't :wink:. I'll send another PR from a branch to supersede this one.\n. I also get 11 failures from a fresh clone. My test output is here https://gist.github.com/adamralph/523469f5c100cd0dd786\nIt looks like 5 of them are integration tests, but there also tests failing from Octokit.Tests.dll, Octokit.Tests-NetCore45.dll and Octokit.Tests-Portable.dll.\nIt seems to be the same 2 tests in each of those 3 assemblies:\n- Octokit.Tests.Clients.SearchClientTests+TheSearchIssuesMethod.TestingTheStateQualifier_Closed\n- Octokit.Tests.Clients.SearchClientTests+TheSearchIssuesMethod.TestingTheStateQualifier_Open\n. Got it. It's a casing issue. The test is expecting \"something+state:Open\" but the SUT is producing \"something+state:open\" due to this line https://github.com/octokit/octokit.net/blob/master/Octokit/Helpers/EnumExtensions.cs#L24.\nI can PR this. Which way round do you want it? Should the SUT change or the test change?\nWould you mind waiting until tomorrow evening for a PR? This is perfect for a live contribution demo for my 'Open Source: Get Involved' user group talk tomorrow evening and is a chance for the project to get some public exposure.\n. To confirm, after changing the test to expect lower case, build.cmd is green so this will resolve this issue.\nI can send the PR with that change, or I can make the test case-insensitive, or I can change EnumExtensions not to convert to lower case. Just say the word.\n. I've also tested changing EnumExtensions to not convert to lower case and that also results in a green build.\nSo either way works.\n. Cool. Will do.\n. NP, I'll send the PR today at about 16:30-17:00 UTC. It would be ultra cool if it got accepted during my talk :sunglasses:.\n. @shiftkey Are you not in San Francisco? I thought that was UTC-7? 09:30-10:00 for you?\n. Ahhh of course, remote working. So jealous :cry:\n. Recently @ajepst and @maartenba have been servicing most of my requests.\n. @ajepst I went to that tab this morning and added a rule specifically for octokit.net which only sends me an email when the first failed or first succesful build happens. I guess this will mask the rule which is inherited from the all users group (which I can't alter), for octokit.net only? It's not at all obvious from the UI what the order of precedence is.\n. OK, I've just spotted the help box on the right. It looks like that will indeed solve my immediate issue.\n. :thumbsup: thanks all\nOn 11 Jul 2014 04:19, \"Brendan Forster\" notifications@github.com wrote:\n\nClosed #532 https://github.com/octokit/octokit.net/issues/532.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/532#event-140473175.\n. I see. I think that's the kind of answer I was expecting.\n\nHow about the HTTP credentials helper thingies? I don't use them myself (I'm an SSH man) but I don't suppose there's anything built into Octokit for talking to them? Or some other .NET wrapper somewhere you're aware of?\n. > I don't use them myself (I'm an SSH man) but I don't suppose there's anything built into Octokit for talking to them?\nI actually meant for talking to the HTTP credential helpers. I realise that SSH is something completely different to HTTP/HTTPS (and in that regard I'm not really sure why I asked the initial question).\nI will indeed use a Personal Access Token because I'm using 2FA anyway.\nYeah, an app authorisation would be the right way to do this for an app I'm planning to distribute but this just a spiked console app for trying some things out. I kind of wanted to avoid having to put my personal access token into config/setting an environment variable/prompting for a password whilst I'm spiking this and I'm also switching machines as I travel around.\nAnyway, the ROI on taking this further is not worth it. If this spike ever becomes a thing then it will end up as a windows service somewhere and we already have a general solution for storing credentials in that scenario.\nThanks for the answers!\n. FWIW, I think it's always better to have your processes baked into source, rather than clicky clicky config on a CI server. That said, there are options for CI config in source, e.g. .travis.yml, appveyor.yml.\n. The one thing I'd probably do differently to that example is to put as much as possible into something decoupled from appveyor, e.g build.fsx. IMHO config specific to a CI platform, e.g. .travis.yml, appveyor.yml should be minimal and for the heavy lifting it should call out to something which can run anywhere.\n. BTW- I tried switching an issue from using the CSV list to using multiple assignees instead, but our automation didn't pick it up, so I'm guessing that Octokit/the API only respects the first person assigned to the issue. Or something like that.\n. The code I pointed out is for the query, of course. I could also just retrieve all issues, and look through the list of assignees, but it seems like that list is also not yet exposed. Octokit.Issue only has a singular Assignee property.\n. @shiftkey by chance, do you know if the API exposes it yet? I guess I could drop down to bare metal temporarily, depending on how soon you think Octokit might get his.\n. @ryangribble thanks very much for the info. Very useful. We don't have enormous urgency to support this in our automation so we may just wait for this to come out of preview (and be supported in Octokit) but in the meantime, if we do experiment with it, we'll report back and let you know how we get on.\n. @paladique @shana has any progress been made on this?\n. @shana looking back through this issue, I don't think I've been specific enough about my use case, and I'm not convinced that #1339 supports it.\nI want to search for issues assigned to a particular user. Currently, using RepositoryIssueRequest an issue will only be returned if the user is the first assignee on the issue. If the user is the 2nd, 3rd, 4th assignee, etc. the issue will not be returned. Can you confirm that #1339 will fix this?\n. @shana thanks I did so https://github.com/octokit/octokit.net/pull/1339#issuecomment-231397033\nAlso, it turns out my immediate use case is solved already, without requiring changes to Octokit: https://github.com/octokit/octokit.net/pull/1339#issuecomment-231408854\n. I want to search for issues assigned to a particular user. Currently, using RepositoryIssueRequest, an issue will only be returned if the user is the first assignee on the issue. If the user is the 2nd, 3rd, 4th assignee, etc. the issue will not be returned. Will this PR fix that?\n. OK, strike my last comment. Issues are returned regardless of whether the user is the first assignee or not.\nIt was actually a filter in our code that excluded the issues, since it was examining Issue.Assignee which is indeed the first assignee.\nI've worked around it for now, and I can see that this PR adds Issue.Assignees so all is good.\n. Indeed! :unamused: \n. ",
    "SimonCropp": "perhaps not catering for the \"_\" in html_url?\n. well it is either add some custom serialization or rename the property :)\n. did a find usages on octokit for Issue.HtmlUrl and Issue.Url  and got nothing.\nis this expected?\n. should there be an issue.json here https://github.com/octokit/octokit.net/tree/master/Octokit.Tests/Fixtures with related tests?\n. @shiftkey why bother with Uri? wouldnt a string be sufficient ?\n. @shiftkey fair enough\n. i was just doing that :)\n. @Haacked @shiftkey  i notice 0.1.3 is out. did this one make it into the release?\n. https://github.com/octokit/octokit.net/releases/tag/v0.1.3\n\n\"Fixed bug in applying query parameters that could cause paging to continually request the same page\"\n\nlooks like it. so shall we close this?\n. Works on my machine\n. related to #216 \n. I may have time to look into this on the weekend. \n. @Haacked but while we are here what is the value in returning a response like that? would not a simple list be better?\n. @shiftkey r u sure you would not prefer \npublic IList<File> Files { get; set; }\nand handle the fact that it is a dictionary internally?\n. well u can still look up by name since the name is also on the file. would just need a linq statement instead of a dictionary lookup.  I think in this case there will be little perf difference. unless people have 1000s of files a gist... is this likely?\n. collaboration FTW :)\n. BTW is there any other place where you guys are doing custom deserialization so i can follow the same approach/conventions?\n. ok so i noticed you guys already support dictionary. so i am being lazy and leaving it as that for now :)\nbefore i do a PR i have a couple of questions.\n1. Do u want a PR to master?\n2. Should I be reusing the common User for Gist.User and GistFork.User?\n3. In my test Gist.User returns null. Is this because i am doing point 2 wrong?\nhttps://github.com/SimonCropp/octokit.net/commit/0b0661aa1e74aa84bed2c21d3a2abf1d0b3c7713\n. @shiftkey well I only needed Get. happy to continue with the rest in the background. it is mostly manual work.\nthe next thing I need is http://developer.github.com/v3/git/  is anyone working on this?\n. @shiftkey @Haacked   turns out secrets gists have a non-numeric id. so dont merge this yet\n. @shiftkey so can this be merged?\n. @shiftkey \n.\\build.cmd FixProjects\nThe system cannot find the path specified.\n(Q)uit, (Enter) runs the build again\n. was running in CMD. but fails in powerhell as well\nbut i did notice another error flick up for a second. had to print screen it\n\n. same error\nseems u have a bunch of stuff that assume existence of tools\\FAKE.Core\\ which does not exist on my machine\n. sooo. can we merge this one ;)\n. @Haacked @shiftkey happy to screen share if u guys want to troubleshoot on my machine\n. @shiftkey yep i have a 0byte file.\n. @forki did u unlist 757? 756 looks good but i cant see 757. if u want to get nuget to fix it u prob need to push a fixed version with a higher number than the broken one\n. @shiftkey so the projects are now synced. anything else?\n. @shiftkey well my intent was actually to do some serialization tests on a future PR. but I initially wanted to \"make it work\" then iterate on that\n. Merged and Closed = Win :) \n\n. note the VSIX+share appdomain issue also exists for msbuild tasks. in some cases you can have multiple slns sharing the same msbuild appdomain. SN does avoid this.\nBut this should be a deployment concern for people writing a task or VSIX.\nOptions \n- ILMerge your dependencies and then SN the result\n- manage your own appdomain to ensure isolation.\n. @shiftkey also the VS extensibility story can be answered with \"ILMerge and then SN the result\"\n. @jbogard \n\nanyone that strong names their assembly for any reason whatsoever cannot use this library.\n\nThat is not technically correct. They have the option of either strong naming this lib themselves or ILMerge and then SNing the result\n. @hazzik evidence is not required to \"not do something\". @shiftkey is asking for \"reasons to SN\" that have a stronger backing \"because I need to SN\". \nMost orgs think SN provides some kind of extra security which is false. We already have agreement from some MS guys to remove mentions of the word \"security\" from the strong naming doco on MSDN.  \nAlso here https://github.com/octokit/octokit.net/issues/405#issuecomment-41351198 @shiftkey has articulated the two legit reasons for people wanting SN. that being \n- installing into the GAC \n- extensibility scenarios where it's possible to have two different versions of an assembly in an appdomain\nI will add another one\n- tools that place an artificial requirement on assemblies being SNed. eg MS CRM\nAll of the above cases can be worked around using several mechanisms\n- ILMerge \n- rebuilding from source\n- SNing the assembly yourself\n- creating a SN wrapper that runs a non SN assembly (yes a SNed assembly can load end execute a non-SNed assembly) \n- careful use of assembly loading and AppDomains\n\nSo the problem is just made up by people who are to scared to press one button in VS to sign an assembly, or by people who \"suffer\" from binding redirects \"pain\" (never had this before)\n\nI suffer the pain of SN and binding redirects regularly. My paying clients also suffer this pain with regular support incidents basically being \"you need to fix your binding redirects\". \nSo the pain it causes is real, just as the pain of not SN is real for others. This discussion is about which pain is better suffered and how many people will suffer that pain\n- using SN and suffering assembly loading+binding redirect issues; or\n- not using SN and forcing people to ILMerge/workaround\nFrom my experience, once you have ruled out the people who are requesting SN for security reasons, the number of people who legitimately need SN is so small that it is not worth SNing\nAlso I should note that, as the author of a MSBuild Task, I am one of the people who has a legitimate cause to use SN. \n. @glennblock it should be noted that the approach taken by @JamesNK has negative effects on those people who actually do need to GAC. Since the version is not updated on every release it is a last one wins case. So you could have a case where two apps install on one machine, both GAC diff file-versions but same assembly-version and now one app wont work.\nNot saying this is a bad approach, just that you should be aware of the side effects.\nI wonder if @JamesNK had had many issue with the above effecting his users??\n. @hazzik of the \"reasons for needing SN\" i listed above which one do you most regularly fall into?\n. @hazzik can you contact some of your users and find out why they need things to be signed? it is the actual users we want feedback from.\nI would appreciate it.\n. @glennblock \n\nIsn't the more common issue here the virality\n\nDisagree. \nRemoving the virility would most likely address the artificial requirements of \"we need thing to be SNed for security\" or \"because my manager told me to\". Since these teams will be allowed to SN their assemblies in ignorance of the fact that things they reference are not SNed\nHowever it would not address and of the legitimate uses that i mentioned here https://github.com/octokit/octokit.net/issues/405#issuecomment-41640976\nBut I admit removing the virality would prob make the arguments disappear. the people who understand what SN is actually useful and really need it can use the work-arounds. the rest can continue under the perception of \"SN is about security and I am being secure by using it\"\nis that too cynical? \n. @damianh ILMerge can be called as a .net assembly and u can use c# code from within MSBuild ;)\n. @damianh lol. no. hence the  ;)\n. @iancooper re  \"the security benefits,\" http://stackoverflow.com/a/22977177/53158 \n\nthe Runtime only checks the strong name signing key/cert but does not Hash the DLL/EXE to match the key\n. cool. thanks\n. @shiftkey yeah that is a valid work around. but agree if the filter is one of two known values lets make it an enum\n. PR... I was hoping u would say that\n. @mkchandler i have time. ETA saturday\n. @Haacked @shiftkey is gravatar_id deprecated? https://api.github.com/repos/particular/nservicebus/contributors\n. so should this be [Obsolete] for a few versions? https://github.com/octokit/octokit.net/blob/master/Octokit/Models/Response/User.cs#L16\n. @shiftkey @Haacked  so there was already a Contributor so i created a RepositoryContributor. not happy with it, any better ideas?\n. @shiftkey ok i think i have addressed all your concerns. I also squashed\n. Any timeline on the release this might be included in. Just wondering if I can delay my usage so I can just run with the proper nuget\n. i would have added a forget-me-not test. ie \"if version greater than x and GravatarId exists (reflection) throw exception\"\n. @shiftkey not really. i just prefer not to rely on my brain to remind me of these things. if u can automate reminders then it is less mental tax in the future.\n\nAs an aside on my projects i use this https://github.com/Fody/Obsolete#build-error-mode  to automate the thing. but did not want to push my pet project onto your pet project \n. @shiftkey sooo unit test to self destruct the obsolete member in some future version?\n. minor doco fix but looks good to me. \ndo we care about it being a breaking API change?\n. @shiftkey could also go with an \"obsolete old and add overload\". but your call on how gentle you want to be\n. @shiftkey so r u going get @gbaychev  to do the overload in this PR? if not i can do it after the merge\n. resharper did that on its own. i suspect if u update to latest resharper it would do the same for you.\nWant me to roll it back?\n. um wow. how did i screw that up\n. fixed\n. remarks are not meant to be inside summary\n. ",
    "jpsullivan": ":thumbsup: \n. No problem!  Happy to help :)\nAlready working on patching up those little things.  As for the MonoTouch and MonoAndroid projects, I see them included within the solution, but as you can see they aren't \"included\" yet.  I can certainly add the references manually, but I figured I'd check to make sure that something hasn't gotten screwed up with my development environment.\n\nThanks again for the great lib, you guys!  Can't wait to contribute more :metal:\n. Ah, gotcha gotcha.  That makes much more sense.\n. Sure do, just haven't gotten the time to dedicate to it these last couple days unfortunately. Planning on getting everything taken care of this weekend, though! \n. So I'm pretty sure that this is all taken care of, but it should be noted that integration tests can't really be done until the Trees API is implemented (unless I'm missing something here).  I'm a little hesitant to call this \"done\" until those are implemented, but as far as I can tell, I've added in everything I can.\nAs always, feel free to let me know if I screwed up anything!\n. Done and done.  Loving that little utility to handle adding in all of the referenced .cs files!  Very handy. :+1: \n. @forki you're doing the Lords work, my son.  :beers: \n. Thanks a lot man!  Sorry that it seems kinda like amateur hour up in here... I'll get these patched up pronto.\n. @shiftkey Yep, still working on a few more details, particularly getting the integration tests sorted out now that I see Trees have been implemented.  Will let you know when this is all ready for a review, though.\n. No problem, man. Sorry I never ended up finishing it... We've been in crunch mode at the office for a while now and I really haven't had any time to give octokit any love :(\nThanks for all the help!\n. Ahaha, yeah I was wondering how you guys would react to that.  I got a good laugh out of that as well :)\n. Ah, good point.  I was actually poking around the other day and noticed that this was now in upstream's master, but was wondering what why I wasn't seeing it in my branch.  I suppose I just assumed this would make it into my branch if I fetched from upstream. \n. Ooo nice! Upon writing that test I don't believe it was in there (or maybe I just hadn't merged upstream).  I'll work around that now :+1: \n. ",
    "pmacn": "Wouldn't copying the comments to implementations just lead to having to maintain the documentation in two (or more) places?\nIf I'm not mistaken Visual Studio currently uses Interface documentation comments if there's not an explicit documentation comment on the implementation, in essence achieving the desired result already.\nNot certain that this is the case in Xamarin but it would seem likely.\nJust wanted to double check that this hadn't been overlooked before I started digging in.\n. > I don't believe that's the case. I think plugins like Resharper do this, but a vanilla Visual Studio will use the comments on the specific reference you have. So if you have a reference to IFoo it'll use comments on IFoo. But if you have a reference to the concrete Foo, it'll use comments from Foo whether or not Foo implements IFoo.\nSeems I am mistaken as this is indeed the case in 2012, I have not been able to check 2013 yet to verify that it's still the same there. Guess that's one of the drawbacks of always working with Resharper.\nI'll send a PR later tonight with the ones I have so far once I check that noone else has covered them yet.\nIn addition to the client API's is there a desire/need to document other public interfaces?\nAlso might give the automation some thought if I find the time for it. Seems as if it shouldn't be terribly difficult at first glance.\n. I few points regarding automation.\nIt seems to me that a system where we leave implementations uncommented and only generate comments during build, comments that never make it back into the source, might be the way to go here.\nThis way we don't have to somehow keep track of which implementation comments were copied from base types and which ones were entered manually (assuming that there might be cases where we would want documentation that differs from the base type). Something that I'd think would have to be handled either with a custom marker of some type or by just deciding that all comments are inherited and overwritten every time. (Or some variation thereof)\nImplementing a custom build task that checks all types in the solution and finds the comments that should be copied is quite trivial using Roslyn. (Already threw together something that does this during lunch) I'm not yet familiar enough with Roslyn to say if it's as easy to actually do the copy and output the new source.\nCould also be that there are better alternatives than Roslyn for this specific task, it was just the first option that came to mind. (Ok, the second one that came to mind after going \"No, not writing my own parser for this\")\nJust some first thoughts, if anyone has extensive experience in this area now would be a great time to chime in ;)\n. Always overwriting the comments and pulling them into the regular source would be easier than trying to keep them out. I was just concerned that there might be cases where an implementation should have different documentation than the interface/base type, in which case copying the comments into the source instantly becomes a lot less pretty.\nAlso confirmed that I could complete the whole process from finding the missing doc comments, copying them and outputting the new source. So now it's just a matter of putting it all into a nice little package, which will probably take longer :)\n. At this point I have a build task that does the following:\n- It pulls comments from interface declarations down to class declarations if the class implements only one interface.\n- If a class implements more than one interface no comments are copied to the class declaration. \n- It pulls comments from interface members to implementation members. No consideration has been given to checking if a member exists on more than one interface.\n- Compares existing comments to avoid copying if the comments are already in place.\n- Maintains the correct indentation by checking the indentation before the declaration that it's being copied to.\n- Keeps any trivia that is not a documentation comment before the declaration that it's being copied to, to preserve regular comments and white space.\nThings we might want to change/add:\n- It currently does not copy comments from base classes to sub classes. Didn't see many base classes in the octokit code base so didn't make this a priority.\n- Make it skip comments if a member exists on more than one interface that's being inherited. Especially since the current behavior is rather unpredictable :)\nI should be able to get a PR for this sometime this weekend if nothing else comes up.\n. http://developer.github.com/v3/repos/#list-branches\nlooks as if it's already implemented\njust noticed as I was working on the repository ones\n. @alfhenrik  #319 should cover all of the ones listed under IRepositoriesClient\n. I could have sworn I left a comment on this, I guess not. My imaginary comment went something like this.\n\nWhat does \"instatiate\" mean? :trollface:\n\nWow, that's all.. wow. Will fix.\n\nHmm, this should be more descriptive. Maybe, \"A client for GitHub's Git Database API that lets you update raw Git objects.\"\n\nI'll expand this to \"A client for GitHub's Git Database API\" for now and maybe add a second descriptive line to all of these down the line.\n. The build task currently only runs when building Octokit. To make it also run for Octokit.Reactive all that's needed is to make the same changes to that project file.\nPlus, the name CustomBuildTasks is probably way too generic since it only really contains one task. It was a bad day for names, I'll rename it. :)\n~~It also currently does something with the very first line in any file that it rewrites, I'm trying to figure out exactly what it is that it's doing so that I can make it stop.~~\n. Seems the reason the first line was changing in every changed file was because I was not writing the Utf-8 Byte Order Mark to file. This has been fixed in the following commit.\n. That is rather confusing, the only reason I can think of that you would get that is if any of the libraries for the build task itself are missing or if you have broken references in the project.\nI'll put up a repo with the source for it tonight, sadly it's kinda been put on the back burner and I haven't had time to pretty it up. But nothing like having it sitting public to pressure you into fixing it, right?\n. https://github.com/pmacn/CommentPulldown\nYou would debug this by going into Project Properties -> Debug -> Start action - > Start External Program should point to a copy of MSbuild. I've been using C:\\Windows\\Microsoft.NET\\Framework\\v4.0.30319\\MSBuild.exe\nThen you add the path to the octokit.net project that you're having issues building in the \"Command line arguments\" box\nHit Debug and presto\n. One of the downsides of going down that route is that now you have to map a Reference to a GitTag, but it might be the price we have to pay. At least we won't have to map them the other direction since there's no updating for tags.\nMakes me wonder what the reason is for the API to not return lightweight tags at /repos/:owner/:repo/git/tags/, it seems as if it should considering that they are returned by git tag -l\n. I guess I'd say it depends on whether we want octokit to conform more to the web API, or to the Git implementation. I would assume it's the former in which case it should probably be left as is. Maybe start a lobbying group to have the API behavior changed ;)\n. Just a suggestion. You might want to make sure that the client methods (the non-reactive ones, not sure how Rx deals with cancellation yet) have overloads that take cancellation tokens if the calls could take long enough that a client would want to cancel.\n. Assuming no one else has started work on this yet, I will take it on.\n- [x] List Deployments\n- [x] Create a Deployment\n- [x] List Deployment Statuses\n- [x] Create a Deployment Status\n. Have most of this finished including some integration tests at https://github.com/pmacn/octokit.net/commits/deployments_client ; But have a language issue and a few other things I want to resolve before sending the pull request. \nWhen trying to use the name Deployment for the response model the compiler complains with:\nCA1724: Type Names Should Not Match Namespaces\nThe conflict is with System.Deployment.Internals\nSo I've currently gone with the name GitDeployment which I feel is a reasonable compromise although not completely satisfying. Currently leaning towards changing it to RepositoryDeployment as it is more in line with the API. But figured I should reach out for some input on the issue since it is part of the public API of the library.\nAnother option obviously would just be to suppress the error and use Deployment despite the warning.\n. Yes, it is. I assumed it was a warning (it was showing as a warning on msdn) escalated to an error because of build settings and figured there might be a reason for it. I didn't investigate further at the time. If someone really wants to use System.Deployment together with Octokit they can always give fully qualified names, I will go ahead and change the name to Deployment for the response model.\n. Note to self, forgot to doc comment the ApiUrls.\nDoing that tomorrow.\nAlso need to add remarks on some of the API methods with links to the documentation\n. I know, I built that. ;) The issue here was that I forgot to comment the ApiUrl methods I added, just a minor thing but it looked as if most the other ones were documented so I figured I should as well.\nOne of these days I'll set up my gravatar to make me a little more recognizable :)\n. Awesome! Good luck with the talk/demo, wish I could go but wrong part of the country. I do have some plans to flesh that project out further and maybe have it become an actual useful project of its own. But, time and such.\nAnyway, I think those added commits has me fairly satisfied with this PR. Unless tomorrow also turns into playing star wars with the kid I should hopefully get the Rx one started/done. But that will be a separate PR.\n. The reactive clients are completed with the exception of some unit tests which are at the moment proving a lot more complex than initially thought, #300 \nThey do however depend on a few things in this pull request so I'm holding off sending a PR for now.\n. Was going to rebase this onto the changes that have already been pushed to master but after doing that locally I'm drawing a blank as to whether I can actually get that into the same PR somehow. Or do I have to open up a new PR?\nSeems like it would be rewriting history at that point and probably not something that would work, but the coffee hasn't quite hit yet.\n. On second thought, I'm not even sure why I was trying to do that. Especially since there doesn't seem to be any issues with the pull request. I wonder if someone replaced my coffee with decaf. These are clearly ramblings of a madman and should be ignored.\n. Pushing the reactive clients into this PR as well\n. Yeah, not sure what I was thinking there. Clearly I need to write 100 \"only use async void for fire and forget\" on the white board.\n. Seems I also mucked up some stuff when getting the reactive client onto this branch. Calling the wrong method in some tests, etc. If only I'd have been drunk so I had an excuse.\nAlso seems as if testing arguments is going be an issue on the create methods since they just call into the non-reactive client. Which is being Substituted. (We do have a number of other tests in our test suite that seem to be the same way. They're just not awaited so they don't actually do anything.\n(TheUpdateMethod.EnsuresArgumentsNotNull in ObservableIssuesClientTests.cs as an example)\nSo I could either add the checks in the Create method on the reactive client and the tests will pass but we'll be performing the same Ensure calls twice in actual use.\n(This seems to be the route taken with TheCreateMethod.EnsureNonNullArguments in ObservableCommitClientTests.cs)\nOr we could just be happy that it tests that the non-reactive client is being called. Knowing that it in turn is covered by argument tests.\nA third option would be to make the substituted GitHubClient return an actual non-reactive client for the reactive client to call into. That way we get our tests on the reactive client so that the requirement is not forgotten in case it's one day decided that it should no longer call into the non-reactive client.\n. My vote is for the third option.\n. The functionality gotten from AssertEx.ThrowsWhenGivenWhitespaceArgument could be had using the assertion methods in #319 instead.\n. And this should all be fixed now, unless I'm blind and missing something. It's amazing how quickly I go blind when looking at my own code compared to others.\n. Merged in master and fixed the whitespace issues\n. To actually work wouldn't they have to await the call to GetAll to make sure that it has time to run.\n```\n[Fact]\npublic async Task RequestsCorrectUrl()\n{\n    var gitHubClient = Substitute.For();\n    var client = new ObservableEventsClient(gitHubClient);\nawait client.GetAll();\n\ngitHubClient\n    .Connection\n    .Received(1)\n    .GetAsync<IReadOnlyList<Activity>>(new Uri(\"events\", UriKind.Relative), null, null);\n\n}\n```\nWhich then opens up Pandora's box with a whole horde of other issues. Now that the code actually gets called the NSubstitute object quickly fails as it returns nulls in places where they are not allowed.\nIn this case the first failure seems to be in ConnectionExtensions.GetPages<T> but once that one is resolved there are more.\nIt seems to me that the most reliable option here might be to fake IResponse<T> and IConnection.\nThe response requires a moderate amount of faking (BodyAsObject, ApiInfo.GetNextPageUrl() but GetNextPageUrl is also an extension method so we'd have to fake the ApiInfo rather than the method) while the connection requires less.\nThen build an actual GitHubClient using those. It starts to get quite tedious at this point and a lot of code for what seemingly should be simple tests.\nBeen messing around some and we should be able to build a \"FakeConnectionBuilder\" that would be able to take a starting url and a collection of items, then automatically build the fake responses and connection from that.\nA simpler option would just be to convert GetAndFlattenAllPages<T> to an interface method rather than an extension method. Since that is what's making it so hard to fake. But at that point we're really just testing how GetAll does something and the tests will have to change whenever implementation does.\nUnless I'm missing something really obvious these are seeming more and more as if they'll be a real chore to test.\nHoping that I'm wrong.\nAnyway, it's now too late and my brain has stopped working.\n. > Our unit tests simply check that we call through to the connection correctly\nYeah, I wasn't trying to imply that we should be mocking \"the internets! all of it!\". sorry if it came across as such.\nSo the first flag that indicated to me that something was wrong here was when I rewrote the tests like so\n```\n[Fact]\npublic void RequestsCorrectUrl()\n{\n    var gitHubClient = Substitute.For();\n    var client = new ObservableOrganizationMembersClient(gitHubClient);\nclient.GetAll(\"org\");\n\ngitHubClient.Connection.Received(1).GetAsync<IReadOnlyList<User>>(\n    new Uri(\"orgs/org/members\", UriKind.Relative), null, null);\n\n}\n```\nand then got this exception\nException Message:\nNSubstitute.Exceptions.ReceivedCallsException : Expected to receive exactly 1 call matching:\n    GetAsync<IReadOnlyList<User>(orgs/org/members, <null>, <null>)\nActually received no matching calls.\nAs it turns out, NSubstitute gives you no help whatsoever with type parameters and my issue was that I did not change IReadOnlyList to List.\n(silly early post and edit because ctrl-enter is evil)\nAnyway, the above led me to have a quick look at the implementation of GetAndFlattenAllPages. Which at the time  looked to me as if even the first call to GetAsync was deferred (in which case it would never be called unless GetAll was awaited, etc etc), which just turns out to be wrong.\n. If jumping to conclusions was an Olympic sport that might have gotten me a spot in the games!\n. Yeah, all done being wrong for now.\n. Figured I'd do a client at a time, that one only had one method  missing ;)\n. Typos in commit messages are pretty bawse, wtb spellcheck?\nWant me to fix the message and redo or just want to fix it when you merge it in? Assuming there's some way to replace my commit message at that point.\n. I'd still have to delete the remote branch and PR though, right? Or am I missing some git magic?\n. voodoo! done :)\n. :+1:  on DebuggerDisplay\n. So just a somewhat misleading response but at least functional :) Guess that means an integration test would have to be quite a lot more involved. Since the ITeamsClient isn't implemented yet I'll just scrap it for now.\n. Of course, that all makes a lot more sense now. I had completely forgotten about private repositories and was wondering how giving a more descriptive http response code would give away any sensitive data.\n. /// Optional. Gets or sets whether to the enable the wiki for the repository.\nI guess that's what I get for copying existing comments and then modifying them. Forgot to remove the first \"the\". And apparently I did it for all of the comments that have the same format. I'll sort that out after work.\n. Or maybe on the lunch break, because waiting until after work is just too long.\n. Regarding AssertEx.DoesNotAllowNullArguments and DoesNotAllowEmptyStringArguments.\nI put these in here simply as a way to put the idea forward. I probably should have put them in their own pull request. I got carried away, my bad.\nIf it's not something we're interested in I'll take them out and replace with the old tests for ensures.\n. Removed the assertion methods and cleaned up the commits.\n. @shiftkey merged~\n. I did just realize that I didn't add a DebuggerDisplayAttribute on the RepositoryUpdate class however\n. @shiftkey Should be all done now\n. Also looks as if this was already implemented in a different pull request.\nShould have checked and not just put my trust in the list :)\n. I'll update this to just add the Add method, however the current implementation has it sitting on the UsersClient and I created a separate UserEmailsClient for it.\nDo we want to keep them on the UsersClient or should it be on a separate client as the API structure would suggest?\n. > I really need to go back and revive those PRs that are languishing there, unloved...\nTheir cries keep me up at night!\nIf it helps at all I can have a look at some of the ones that aren't mine and at least give a :+1:  or :-1: (I could possibly even be nice and give suggestions/comments rather than just a thumbs down)\n. Sorry about the delay haven't been able to get around to it until now.\n. I think this has everything in it now. Except for the Delete method not being implemented because of the issues mentioned above.\n- [x] Client\n- [x] ReactiveClient\n- [x] Documentation comments\n- [x] Unit tests\n- [x] Integration tests\n- [x] DebuggerDisplay on EmailAddress.\n. I'm receiving the following two errors when trying to run build.cmd all of a sudden\nRunning build failed.\nError:\nSystem.Exception: Start of process C:\\Windows\\Microsoft.NET\\Framework\\v4.0.30319 failed. Access is denied\n   at Fake.ProcessHelper.ExecProcessWithLambdas@68-16.Invoke(String message)\n   at Fake.ProcessHelper.ExecProcessWithLambdas(FSharpFunc`2 configProcessStartInfoF, TimeSpan timeOut, Boolean silent, FSharpFunc`2 errorF, FSharpFunc`2 messageF)\n   at Fake.MSBuildHelper.build(FSharpFunc`2 setParams, String project)\n   at Fake.MSBuildHelper.MSBuildWithProjectProperties@271.Invoke(String project)\n   at Microsoft.FSharp.Primitives.Basics.List.iter[T](FSharpFunc`2 f, FSharpList`1 x)\n   at Fake.MSBuildHelper.MSBuildWithProjectProperties(String outputPath, String targets, FSharpFunc`2 properties, IEnumerable`1 projects)\n   at Fake.MSBuildHelper.MSBuild@281-1.Invoke(IEnumerable`1 projects)\n   at FSI_0001.clo@60-5.Invoke(Unit _arg5) in E:\\Git\\octokit.net.backup\\build.fsx:line 61\n   at Fake.TargetHelper.runTarget@290(String targetName)\nand\n1) System.Exception: Start of process C:\\Windows\\Microsoft.NET\\Framework\\v4.0.30319 failed. Access is denied\n   at Fake.ProcessHelper.ExecProcessWithLambdas@68-16.Invoke(String message)\n   at Fake.ProcessHelper.ExecProcessWithLambdas(FSharpFunc`2 configProcessStartInfoF, TimeSpan timeOut, Boolean silent, FSharpFunc`2 errorF, FSharpFunc`2 messageF)\n   at Fake.MSBuildHelper.build(FSharpFunc`2 setParams, String project)\n   at Fake.MSBuildHelper.MSBuildWithProjectProperties@271.Invoke(String project)\n   at Microsoft.FSharp.Primitives.Basics.List.iter[T](FSharpFunc`2 f, FSharpList`1 x)\n   at Fake.MSBuildHelper.MSBuildWithProjectProperties(String outputPath, String targets, FSharpFunc`2 properties, IEnumerable`1 projects)\n   at Fake.MSBuildHelper.MSBuild@281-1.Invoke(IEnumerable`1 projects)\n   at FSI_0001.clo@60-5.Invoke(Unit _arg5) in E:\\Git\\octokit.net.backup\\build.fsx:line 61\n   at Fake.TargetHelper.runTarget@290(String targetName)\n. Apparently the above two messages was because I had a custom environmental variable set called MSBUILD that pointed to that directory. Something I had set up for a different build.\n. > \u2022Rename the \"TeamsUpdateOrDelete\" method to \"Team\"\n:+1:\nMy vote would be for that as Uri's are about resources and the resource being identified is a team\n. Some of them will be failing, specifically ones that require a paid account. Not sure about the one you're mentioning specifically as I haven't had a look at it yet. But I would say that you're probably safe :)\n. Not bugging anyone :) You can always start your PR as a work in progress and see where it goes from there. Just add WIP to the title of your PR.\n. Agreed. In addition to the ease of composing queries it also gives the\ncompositions clearer semantic meaning. That and it always feels nice\nto reduce the use of primitives.\n. :+1:\n. I kinda like what they have going on over in octokit.rb for this, akin to exposing an IResponse GetLastResponse() method/property/whatnot either on the connection or the client.\nSnipped from the https://github.com/octokit/octokit.rb readme\nuser      = Octokit.user 'andrewpthorp'\nresponse  = Octokit.last_response\netag      = response.headers[:etag]\n. Pretty sure this approach will still cause issues with the reactive client methods that go through GetAndFlattenAllPages since there's no simple way to know when there's a new last IResponse available.\nUnless you expose an IObservable<IResponse> Responses { get; } on the reactive clients. Although initially that just sounds silly, I'll let it simmer.\n. I didn't wake up at 5am! Mainly because I didn't get to bed until 1.\nBut this pretty much covers what I was thinking as I was falling asleep. Just caching request/response pairs.\nAlthough I was envisioning a setup where the client was simply given the option to turn on/off caching and then optionally change the \"cache provider\" (i.e. the in-memory, file system, SQLite alternatives) Also possibly make the cache modular in some way so that you could share a cache between client instances. Not sure if people are going to be constructing clients left and right.\n. Fixed the GetOrCreateApplicationAuthentication test and merged in master while I was at it.\n. @shiftkey Guess maybe I should put in a little comment as well.\nAll done! :)\n. I'll get this one, I could use the break\n. And then life happened. Should be able to start this soon\n. Good question, I'm not really sure at this point. I have this all finished since quite a while back but have been very busy with a tiring search and haven't had time to push it up. @shiftkey @Haacked  is this something we still want to introduce? If so should it be introduced as already [Obsolete].\nIf it's something that we do want I'll try and do the final polish and get this up. Sadly my VS2013 trial expired :trollface: and I currently only own a license for 2010. But as I said it's all already done and I just need to look it over once more.\n. > OverPrivateRepositoryQuotaException\nPrivateRepositoryQuotaExceededException\n\nCannotCreatePrivateRepositoryOnFreePlanException\n\nI don't think this can be improved on. It's perfection.\n. Helps if I'm not commenting on the individual commits, so that it's actually visible here.\n. Excellent, looks good to me. :star:\nMaybe adding some documentation comments to the model classes as well for extra fun and profit!\n. This should have had a wip in the title but my internet died as I was putting it in :) I'll send a second\n. Oh never even considered that. Think I just subconsciously assumed that it would not become a dependency since there's nothing in the lib folder. I'll get on updating the package as well, thanks~\n. If the version number was to be frozen. What would the benefit be to freeze it indefinitely as opposed to updating it for major releases (i.e. breaking changes)? Don't we want it to break at a predictable time if the assemblies are not actually compatible?\nAlso this :+1:\n\nI don't think that will be a problem for this project as it will probably be a top level package.\n\nWas going to say that I would also rather see the key be public and checked into the repository. But considering the above statement, using a private key becomes much less of an issue and I really have no preference one way or another re: public vs. private :key:\nIn summary I would say Sign it!\nIf we have to freeze the version number (not convinced that we do) at least update for major releases.\nNo preference on public/private key for official releases.\n. Yes, there was a reason for this being out and I thought I put a comment in about it. I was obviously mistaken.\nWhat I wanted to do was to try and replace it with something that would pass for everyone. Maybe simply check that it returns an email at all?\nI guess another option would just be to have anyone who wants to run these change the email on their test account?\n(Not sure if that's doable and it might leave a lot of test accounts with forgotten and un-retrievable passwords? :)\n. How dare they! And yeah, unless one of my add-ins is messing with it that seems to be the case.\n. Tools -> Options -> Text Editor -> C# -> Advanced ->\n  Place 'System' directives first when sorting usings\nIs not checked by default since VS 2012 according to this\n. Haha, the nonsensical justification aside the cause for my wonky sorting seems to be correct and it should now do what it's supposed to.\n. > which is now deprecated in Rx\nWasn't aware that it's been deprecated. I'll just make the test more Rxish in a separate PR.\nBut yes, my intention with the test was just to see that we got at least one EmailAddress back.\n. My own conventions sneaking in there. I generally line up arguments either all on new lines or lined up with the first argument. Dot-notation indentation is a whole other story.\n. Tabs snuck in somehow! thought I had it set to automatically un-tabify .cs files\n. Yeah there are more places where we do this. I just left them because it was already in place and it still does what's intended.\n\nWant me to just clean it up throughout the projects where it can be removed? \n. Indulging in a little bit of self gratification\n. DebuggerDisplay maybe?\nYou might be right on this one. I thought I saw it being returned by a client call but now see that it's a property of Feeds. In which case the convention tests won't care about the DebuggerDisplay\n. see :arrow_up:\n. For this to work you also need a private string property named DebuggerDisplay on the class that returns the value to display in the debugger.\nLooks as if @ammeep made them internal in her DebuggerDisplay frenzy. Might want to stick to that rather than private for the sake of convention.\n. client is somewhat misleading as a variable name here. connection perhaps? :)\n. See my updated comment above, was writing it as you entered yours\n. Ok, I completely missed this.. this file seems a little lost in Octokit/Models/Response/\n. Changing Assert.Throws to AssertEx.Throws here simply because I was in the file and I'm having a change of heart about preferring Assert over AssertEx.\nUsed to prefer Assert.Throws over AssertEx.Throws simply on the merit of it being a standard xUnit assertion.\nBut now AssertEx.Throws for these makes more sense to me as it means we would not have to rewrite the test if the argument validation would ever happen to be handled after an internal await. Granted that seems like a silly thing to ever do, but at least with AssertEx it's one less reason to ever have to rewrite the test.\n. ",
    "andreasohlund": "This one blows as well:\n```\nHTTP/1.1 200 OK\nServer: GitHub.com\nDate: Sat, 09 Nov 2013 13:00:33 GMT\nContent-Type: application/json; charset=utf-8\nStatus: 200 OK\nX-RateLimit-Limit: 5000\nX-RateLimit-Remaining: 4928\nX-RateLimit-Reset: 1384004333\nCache-Control: private, max-age=60, s-maxage=60\nETag: \"8ed3ff42a0d7756fa1b009d7fc1b77e8\"\nVary: Accept, Authorization, Cookie\nX-GitHub-Media-Type: github.beta; param=manifold-preview\nX-Content-Type-Options: nosniff\nAccess-Control-Allow-Credentials: true\nAccess-Control-Expose-Headers: ETag, Link, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes\nAccess-Control-Allow-Origin: *\nX-GitHub-Request-Id: 5AE3E374:784A:38EC9A:527E31F1\nVary: Accept-Encoding\nContent-Length: 606\n[{\"url\":\"https://api.github.com/repos/Particular/ServiceInsight/releases/76774\",\"assets_url\":\"https://api.github.com/repos/Particular/ServiceInsight/releases/76774/assets\",\"upload_url\":\"https://uploads.github.com/repos/Particular/ServiceInsight/releases/76774/assets{?name}\",\"html_url\":\"https://github.com/Particular/ServiceInsight/releases/untagged-abf8c32468de9e39039a\",\"id\":76774,\"tag_name\":\"1.0.0-Beta\",\"target_commitish\":\"master\",\"name\":\"1.0.0-Beta\",\"body\":\"Tbd\",\"draft\":true,\"prerelease\":true,\"created_at\":\"2013-10-26T08:51:00Z\",\"published_at\":null,\"assets\":[],\"tarball_url\":null,\"zipball_url\":null}]\n```\n. Could it be that the published_at needs to be nullable?\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Models/Response/Release.cs#L21\n. Thanks, do you guys have CI setup so I can get a updated nuget?\nSent from my iPhone\n\nOn 9 nov 2013, at 17:26, Brendan Forster notifications@github.com wrote:\nClosed #204 via #205.\n\u2014\nReply to this email directly or view it on GitHub.\n. Thanks Phil!\n\nSent from my iPhone\n\nOn 10 nov 2013, at 08:03, Phil Haack notifications@github.com wrote:\nYeah, https://www.myget.org/feed/octokit/package/Octokit\nI'll push a new NuGet release on the main gallery soon too.\n\u2014\nReply to this email directly or view it on GitHub.\n. Thanks, what is your eta for pull + release?(desperately need it :)\n\nAnd yes testing against one of our repos is the mother of all brittle tests:)\nSent from my iPhone\n\nOn 9 nov 2013, at 17:02, Brendan Forster notifications@github.com wrote:\nThanks for picking this one up @andreasohlund.\nLet's see where we want that test data to live, but aside from that I'm happy with this change.\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "JPomichael": "\uff1f\n\u53d1\u81ea\u6211\u7684 iPhone\n\u5728 2013-11-11\uff0c14:10\uff0c\"Phil Haack\" notifications@github.com \u5199\u9053\uff1a\n\nyay!\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "xabikos": "I've start implement the gist API. Shall I also implement the comments API as a subclient of Gist or I have to open a new issue?\n. @shiftkey thanks for the reply. I'll continue implementing the gists API and maybe afterwards implement the comments API as well. Regarding the gists shall I make a pull request for every one of above check boxes or only when all of them are finished? \n. Thanks @shiftkey for remind it to me :+1: \n. I made a pull request for some of the methods related to gists. I created a topic branch (implement-gist-api) when I for the repository and worked on this branch. I made the pull request and didn't merge my topic branch to the master first. Is this correct? This is my first attempt for a pull request.\n. Except the above comment I have a question regarding the check if a gist is stared method. We have to make  a get request to /gists/:id/star url and based on the response code (204, 404) return true or false. I couldn't find an easy solution to access the response code through API connection. Any suggestions on how to implement this? Shall I add an extra method to API connection to access the request response?\n. Done!\n. I fixed this but I don't know why it's still as not fixed. I noticed the other comments are disappeared when I pushed the required changes in my branch.\n. Thanks for the useful comment. I'll follow this convention from now on. I guess I don't have to change something regarding this for my pull request.\n. I was thinking of this as well but I can't figure a generic way to create some gists and then test against these. Is acceptable to create some gists with my personal test account and use these for testing?\nCould you also look at my last comment on the corresponding Issue for gists ( #216 )\n. ",
    "bradwilson": "Is there a test runner API in Xamarin Studio?\n. We aren't particularly interested in making GUI runners, so chances are we wouldn't do this. We would be happy to help a third party write a runner if someone is so motivated.\n. xUnit.net should support mono just fine (console runner, MSBuild runner via xbuild).\n. ",
    "jchannon": "Slight update on this - https://forums.xamarin.com/discussion/17864/how-i-can-run-xunit-tests-from-xamarin-studio?\n. What @jen20 said!\n. ",
    "warrenbuckley": "@Haacked thanks for the feedback moved code as suggested & removed GlobalSuppression.cs file as well.\nLet me know what else I need to do, to get this accepted please.\n. @Haacked as you can tell I am fairly new to all of this. So I appreciate your patience & great feedback.\nFingers crossed third time is a charm\n. @Haacked just pushed up your suggestion to the ContentsResponse object. Adding in comments & the enum (however having a slight issue with it & was hoping you could advise please)\n. @Haacked for my little own pet project rolled back to .NET HTTP Client in the mean time.\nLet me know what has been decided when you hear, so I can make the necessary changes as required.\nThanks :octocat: \n. Hiya Guys @Haacked & @shiftkey \nLooking forward to hearing what I will need to do or how I can help out, even if you take this task over & I just do testing.\nCheers,\nWarren\n. @shiftkey sounds like you go this well under control now. Shall I close my pull request or something & let you continue with this?\n. @shiftkey OK I won't close this PR then. Is it possible to merge your changes into my PR and collaborate that way on it?\nYes I think you are right about GetContent having multiple methods is the best apporach\n. @shiftkey I have been extremly busy with work & personal stuff this week :-1: \nSo I haven't had a chance to look at this at all and currently not sure when I will get the time. I would still love to contribute but don't want to see me holding this up, so free free to jump in take over to get this closed & fixed.\nThanks,\nWarren\n. @Haacked thanks for spotting my bad typo :smile: \nI have tried this @Haacked & @shiftkey \n``` csharp\n[VerifyGitHubWebHook]\n[HttpPost]\npublic HttpResponseMessage ReceiveWebHook()\n{\n    //From the webhook JSON payload we get POSTed to us\n    //Deserialize it to a object - take from Octokit GitHub's .NET API client\n    var payloadString = Request.Content.ReadAsStringAsync().Result;\n//Map JSON string to object\nvar payload = JsonConvert.DeserializeObject<PullRequestEventPayload>(payloadString);\n\n//Check the state, is it closed & merged = true\n//Means was accepted & put back into repo\n//Thus assign contributor badge to member\nif (payload.PullRequest.State == ItemState.Closed && payload.PullRequest.Merged)\n{\n    //Do stuff here\n}\n\n//Always need to return 200 OK back to GitHub otherwise they will stop sending data to us\nreturn Request.CreateResponse(HttpStatusCode.OK);\n\n}\n```\npayloadString has the following value \n\"{\\\"zen\\\":\\\"Half measures are as bad as nothing at all.\\\",\\\"hook_id\\\":5154329,\\\"hook\\\":{\\\"url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/hooks/5154329\\\",\\\"test_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/hooks/5154329/test\\\",\\\"ping_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/hooks/5154329/pings\\\",\\\"id\\\":5154329,\\\"name\\\":\\\"web\\\",\\\"active\\\":true,\\\"events\\\":[\\\"pull_request\\\"],\\\"config\\\":{\\\"url\\\":\\\"http://3c2a18de.ngrok.com/umbraco/api/GitHubWebHook/ReceiveWebHook\\\",\\\"content_type\\\":\\\"json\\\",\\\"insecure_ssl\\\":\\\"0\\\",\\\"secret\\\":\\\"********\\\"},\\\"last_response\\\":{\\\"code\\\":null,\\\"status\\\":\\\"unused\\\",\\\"message\\\":null},\\\"updated_at\\\":\\\"2015-06-25T08:40:45Z\\\",\\\"created_at\\\":\\\"2015-06-25T08:40:45Z\\\"},\\\"repository\\\":{\\\"id\\\":37732545,\\\"name\\\":\\\"Umbraco-Identity-Playground\\\",\\\"full_name\\\":\\\"warrenbuckley/Umbraco-Identity-Playground\\\",\\\"owner\\\":{\\\"login\\\":\\\"warrenbuckley\\\",\\\"id\\\":1389894,\\\"avatar_url\\\":\\\"https://avatars.githubusercontent.com/u/1389894?v=3\\\",\\\"gravatar_id\\\":\\\"\\\",\\\"url\\\":\\\"https://api.github.com/users/warrenbuckley\\\",\\\"html_url\\\":\\\"https://github.com/warrenbuckley\\\",\\\"followers_url\\\":\\\"https://api.github.com/users/warrenbuckley/followers\\\",\\\"following_url\\\":\\\"https://api.github.com/users/warrenbuckley/following{/other_user}\\\",\\\"gists_url\\\":\\\"https://api.github.com/users/warrenbuckley/gists{/gist_id}\\\",\\\"starred_url\\\":\\\"https://api.github.com/users/warrenbuckley/starred{/owner}{/repo}\\\",\\\"subscriptions_url\\\":\\\"https://api.github.com/users/warrenbuckley/subscriptions\\\",\\\"organizations_url\\\":\\\"https://api.github.com/users/warrenbuckley/orgs\\\",\\\"repos_url\\\":\\\"https://api.github.com/users/warrenbuckley/repos\\\",\\\"events_url\\\":\\\"https://api.github.com/users/warrenbuckley/events{/privacy}\\\",\\\"received_events_url\\\":\\\"https://api.github.com/users/warrenbuckley/received_events\\\",\\\"type\\\":\\\"User\\\",\\\"site_admin\\\":false},\\\"private\\\":false,\\\"html_url\\\":\\\"https://github.com/warrenbuckley/Umbraco-Identity-Playground\\\",\\\"description\\\":\\\"Experiments with Umbraco 7.3 beta & Identity\\\",\\\"fork\\\":false,\\\"url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground\\\",\\\"forks_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/forks\\\",\\\"keys_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/keys{/key_id}\\\",\\\"collaborators_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/collaborators{/collaborator}\\\",\\\"teams_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/teams\\\",\\\"hooks_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/hooks\\\",\\\"issue_events_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/issues/events{/number}\\\",\\\"events_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/events\\\",\\\"assignees_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/assignees{/user}\\\",\\\"branches_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/branches{/branch}\\\",\\\"tags_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/tags\\\",\\\"blobs_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/git/blobs{/sha}\\\",\\\"git_tags_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/git/tags{/sha}\\\",\\\"git_refs_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/git/refs{/sha}\\\",\\\"trees_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/git/trees{/sha}\\\",\\\"statuses_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/statuses/{sha}\\\",\\\"languages_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/languages\\\",\\\"stargazers_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/stargazers\\\",\\\"contributors_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/contributors\\\",\\\"subscribers_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/subscribers\\\",\\\"subscription_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/subscription\\\",\\\"commits_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/commits{/sha}\\\",\\\"git_commits_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/git/commits{/sha}\\\",\\\"comments_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/comments{/number}\\\",\\\"issue_comment_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/issues/comments{/number}\\\",\\\"contents_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/contents/{+path}\\\",\\\"compare_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/compare/{base}...{head}\\\",\\\"merges_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/merges\\\",\\\"archive_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/{archive_format}{/ref}\\\",\\\"downloads_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/downloads\\\",\\\"issues_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/issues{/number}\\\",\\\"pulls_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/pulls{/number}\\\",\\\"milestones_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/milestones{/number}\\\",\\\"notifications_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/notifications{?since,all,participating}\\\",\\\"labels_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/labels{/name}\\\",\\\"releases_url\\\":\\\"https://api.github.com/repos/warrenbuckley/Umbraco-Identity-Playground/releases{/id}\\\",\\\"created_at\\\":\\\"2015-06-19T16:15:46Z\\\",\\\"updated_at\\\":\\\"2015-06-19T16:38:46Z\\\",\\\"pushed_at\\\":\\\"2015-06-24T17:40:18Z\\\",\\\"git_url\\\":\\\"git://github.com/warrenbuckley/Umbraco-Identity-Playground.git\\\",\\\"ssh_url\\\":\\\"git@github.com:warrenbuckley/Umbraco-Identity-Playground.git\\\",\\\"clone_url\\\":\\\"https://github.com/warrenbuckley/Umbraco-Identity-Playground.git\\\",\\\"svn_url\\\":\\\"https://github.com/warrenbuckley/Umbraco-Identity-Playground\\\",\\\"homepage\\\":null,\\\"size\\\":0,\\\"stargazers_count\\\":0,\\\"watchers_count\\\":0,\\\"language\\\":\\\"JavaScript\\\",\\\"has_issues\\\":true,\\\"has_downloads\\\":true,\\\"has_wiki\\\":true,\\\"has_pages\\\":false,\\\"forks_count\\\":0,\\\"mirror_url\\\":null,\\\"open_issues_count\\\":0,\\\"forks\\\":0,\\\"open_issues\\\":0,\\\"watchers\\\":0,\\\"default_branch\\\":\\\"master\\\"},\\\"sender\\\":{\\\"login\\\":\\\"warrenbuckley\\\",\\\"id\\\":1389894,\\\"avatar_url\\\":\\\"https://avatars.githubusercontent.com/u/1389894?v=3\\\",\\\"gravatar_id\\\":\\\"\\\",\\\"url\\\":\\\"https://api.github.com/users/warrenbuckley\\\",\\\"html_url\\\":\\\"https://github.com/warrenbuckley\\\",\\\"followers_url\\\":\\\"https://api.github.com/users/warrenbuckley/followers\\\",\\\"following_url\\\":\\\"https://api.github.com/users/warrenbuckley/following{/other_user}\\\",\\\"gists_url\\\":\\\"https://api.github.com/users/warrenbuckley/gists{/gist_id}\\\",\\\"starred_url\\\":\\\"https://api.github.com/users/warrenbuckley/starred{/owner}{/repo}\\\",\\\"subscriptions_url\\\":\\\"https://api.github.com/users/warrenbuckley/subscriptions\\\",\\\"organizations_url\\\":\\\"https://api.github.com/users/warrenbuckley/orgs\\\",\\\"repos_url\\\":\\\"https://api.github.com/users/warrenbuckley/repos\\\",\\\"events_url\\\":\\\"https://api.github.com/users/warrenbuckley/events{/privacy}\\\",\\\"received_events_url\\\":\\\"https://api.github.com/users/warrenbuckley/received_events\\\",\\\"type\\\":\\\"User\\\",\\\"site_admin\\\":false}}\"\nAnd when we get to payload where JSON.NET is trying to deserialize it back to PullRequestEventPayload I get this\n\n. Hopefully you can offer some advice on this guys @Haacked & @shiftkey as I don't ideally want to create a ton of POCOs myself to map all of this data if you guys seem to have done it.\n. This is what I have setup & configured @Haacked \n\nOK I will check & verify by triggering a real PR on the repo to see what happens & what data I get & post back here shortly.\n. Here is a quick video @Haacked & @shiftkey apologies for the muttering but even with the more neater correct payload being sent without the zen stuff it still fails to deserialise.\nhttps://www.youtube.com/watch?v=ac_dAWNfcRg\n. @Haacked Woohoo thanks that worked!\nHowever it would be nice that I do not need to do this and that the model binding in .NET would deserialze to the PullRequestEventPayload object.\nAs I think this is not obvious or clear that I would need to use your own Serializer to do this.\n. Closing this, but if anyone searched for this & needs to know here is some sample code thanks to Chris Klug blog post - http://chris.59north.com/post/Integrating-with-Github-Webhooks-using-OWIN\n``` csharp\npublic class VerifyGitHubWebHook : ActionFilterAttribute\n{\n    /// \n    /// When the attribute is decorated on an Umbraco WebApi Controller\n    /// First check payload was posted from GitHub & not spoofed\n    /// \n    /// \n    public override void OnActionExecuting(HttpActionContext actionContext)\n    {\n        try\n        {\n            //HTTP Request\n            var request = actionContext.Request;\n        //Get the auth header that\n        var authHeader = request.Headers.GetValues(\"X-Hub-Signature\").FirstOrDefault();\n\n        //If auth header does not exist - unathorised\n        if (authHeader == null)\n        {\n            //Return a HTTP 401 Unauthorised header\n            actionContext.Response = new HttpResponseMessage(HttpStatusCode.Unauthorized);\n        }\n\n\n        //Now we have the auth header value - try & decode to verify against env variable\n        if (!IsValidToken(authHeader, request))\n        {\n            //Return a HTTP 401 Unauthorised header\n            actionContext.Response = new HttpResponseMessage(HttpStatusCode.Unauthorized);\n        }\n        else\n        {\n            //Return a HTTP 200 OK\n            actionContext.Response = new HttpResponseMessage(HttpStatusCode.OK);\n        }\n\n    }\n    catch (Exception)\n    {\n        //Return a HTTP 401 Unauthorised header\n        actionContext.Response = new HttpResponseMessage(HttpStatusCode.Unauthorized);\n    }\n\n    //Continue as normal\n    base.OnActionExecuting(actionContext);\n}\n\n/// <summary>\n/// http://chris.59north.com/post/Integrating-with-Github-Webhooks-using-OWIN\n/// </summary>\n/// <returns></returns>\nprivate bool IsValidToken(string payloadToken, HttpRequestMessage request)\n{\n    //Get token stored on enviroment\n    var serverToken = Environment.GetEnvironmentVariable(\"githubToken\");\n    //var serverToken = \"superSecretFOO\";\n\n    //Need to get the actual content of the request - JSON payload\n    //As this payload is signed/encoded with our key\n    var jsonPayload = request.Content.ReadAsStringAsync().Result;\n\n    //Verify the payloadToken starts with sha1\n    var vals = payloadToken.Split('=');\n    if (vals[0] != \"sha1\")\n    {\n        return false;\n    }\n\n\n    var encoding = new System.Text.ASCIIEncoding();\n    var keyByte = encoding.GetBytes(serverToken);\n\n    var hmacsha1 = new HMACSHA1(keyByte);\n\n    var messageBytes = encoding.GetBytes(jsonPayload);\n    var hashmessage = hmacsha1.ComputeHash(messageBytes);\n    var hash = hashmessage.Aggregate(\"\", (current, t) => current + t.ToString(\"X2\"));\n\n    return hash.Equals(vals[1], StringComparison.OrdinalIgnoreCase);\n}\n\n}\n```\n. Sorry Phil,\nI am fairly new to all of this, so please bare with me, whilst I try to understand your comments and make the necessary changes/updates to fix the pull request.\nAny guidance or pointers would be appreciate.\nThanks,\nWarren :+1: \n. @Haacked heya no problem I can add comments to the properties now & add in the enum for the ResponseType.\nShould I rename the property to Type so that the JSON parser can map it to the property, but I think it will create a suppression message if I remember.\nJust trying to debug an issue currently that I get a null response, think its something to do with the JSON received back from the API & mapping back to the this object. Any quick pointers or ideas please?\nAs not all responses from the API contain the Content property in the JSON object returned.\n. @Haacked old habits die hard\n. @Haacked ah ok that makes sense with the issue I just posted about null mapping to the object. Any ideas on how best to resolve/tackle this please?\n. @Haacked I have added the Enum & the inline suppression message as you suggested, but when doing my tests (using it in a WebAPI for my tests) the Type property in the JSON returned is 0 as opposed to the Enum value of File or Dir to match the API value.\nDoes the Enum need to be lower case to match the values the API returns?\n. @pengwynn & @Haacked I am currently only interested in trying to implement the Contents API at the moment.\nSo I suppose my question still stands how best to resolve this issue of the Contents API either returingn a single JSON object or an array.\n. ",
    "rgmills": "I tried again, let me know if it's still hosed.  If it is, I might need some help.  First time working across repos and all that jazz.\n. Thanks folks! Sorry, I'm a horrible person and dropped off the planet for a bit.\n. Agreed.  Intent for the NewGistFile and extra ceremony was API wouldn't have to change if another property was exposed.  Granted, if the API will look the same for v3, then it's entirely unnecessary.\n. Agreed. Intent was to support any additional properties that might become available.  However, if the API for create is set in stone, then absolutely no need for the extra class.\n. Would it be too far out of scope to go ahead and implement the read of the Gist APIs in the PR?\n. ",
    "Therzok": "Can this PR be fixed up? :D\n. @Haacked the only way to fix this would be rebasing and force pushing, merging wouldn't help one bit, so a pull request won't do.\nThe way I would do it would be:\ngit reset --hard d2e0490\ngit rebase upstream/master\ngit push --force origin/create-gists\n(or whichever is the upstream to octokit/octokit.net)\n. Oh, true, yea. XD\n. I think this can be closed.\n. I think this can be closed? Or is there something useful that would require porting to #391 ?\n. Notes:\nI have added tests for IObservable sync.\nI have squashed the test commits into the first test addition commit due to test file being moved. That means commits between the test addition and full api implementation do not build.\n. Ping @Haacked =D\n. Pushed again, thanks!\nIt was using tabs since it was MonoDevelop's default. Fixed now.\n. No problem! I just needed this merged. :octocat: \n. ",
    "andrerod": "That's why one should not work past given hours of the day :) \nAnyhow, I've seen this one https://github.com/octokit/octokit.net/issues/246 and noticed the labels thing as i've hit it. Not top pri though as you probably figured.\n. @paulcbetts if this looks good i'll add some tests as well.\n. @shiftkey updated.\n. @shiftkey Good point. Updated again. (also added IDisposable for events which was also missing)\n. Done\n. @shiftkey : updated and added the same validation logic on the update class.\n. You're welcome! Thanks for the effort and for taking it.\n. p.s.- don't forget to close the associated issue.\n. @Haacked done ?\n. @Haacked Added. Sorry about that. Looking at it, it seemed like only methods that return anything other than a task would have an implementation here.\n. Meh. Argument null is probably the right exception anyways. So I think you were actually right although both would work.\nAs for the ctor check, i'm using the property setter to set the value in the constructor, so this check will happen there as well so IMO I think we're good in that regard. Unless you have a different opinion :)\n. I added the null checks in the ctor. Is that what you had in mind ?\n. I renamed the properties to both start with lower case and match the name of the attributes. I think it looks more consistent like this (matching the exact parameter name), but if you want the capitalization, I can change it.\nFrom: Brendan Forster [mailto:notifications@github.com]\nSent: 8 de dezembro de 2013 16:37\nTo: octokit/octokit.net\nCc: Andr\u00e9 Rodrigues\nSubject: Re: [octokit.net] Implement labels CRUD (#256)\nIn Octokit/Models/Request/LabelUpdate.cs:\n\n@@ -0,0 +1,41 @@\n+\ufeffusing System;\n+using System.Text.RegularExpressions;\n+\n+namespace Octokit\n+{\n-    public class LabelUpdate\n-    {\n- private string _color;\n+\n- public LabelUpdate(string name, string color)\n- {\n- Ensure.ArgumentNotNullOrEmptyString(name, \"Label name can't be null\");\n- Ensure.ArgumentNotNullOrEmptyString(color, \"color can't be null\");\n\nOk, let's capitalize Color here (and in the other case) and I think I'm done with \"things to find wrong\" here [:grinning:]\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/pull/256/files#r8185076.\n. Yup. Updated.\nFrom: Brendan Forster [mailto:notifications@github.com]\nSent: 8 de dezembro de 2013 16:41\nTo: octokit/octokit.net\nCc: Andr\u00e9 Rodrigues\nSubject: Re: [octokit.net] Implement labels CRUD (#256)\nIn Octokit/Models/Request/NewLabel.cs:\n\n@@ -0,0 +1,44 @@\n+\ufeffusing System;\n+using System.Text.RegularExpressions;\n+\n+namespace Octokit\n+{\n-    /// \n\n/// Describes a new label to create via the  method.\n\n/// \n\n\npublic class NewLabel\n\n{\nprivate string _color;\n\n+\n- public NewLabel(string name, string color)\n- {\n- Ensure.ArgumentNotNullOrEmptyString(name, \"name can't be null\");\n\nCitation: https://github.com/octokit/octokit.net/blob/master/Octokit/Helpers/Ensure.cs#L32\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/pull/256/files#r8185092.\n. ",
    "VikramShetty": "Thank you @shiftkey for your guidance. This will definitely help us to ensure our documentation is consistent.\n. @shiftkey I think you can go ahead with merge now. Thanks for approving my first ever github checkin\n. ",
    "niik": ":+1: :heart:\n. > Is this being driven by a real application need or a theoretical need?\nYes, I'm the one who got the ball running on this one. I need it for GHfW and @shiftkey was kind enough to help out.\n\nYou should simply do client.GetReposOrWhateverItIsCalled().Take(100);\n\nBut I still need all the results, I just want them delivered as they come in, I don't want to wait for all requests to be made. Also, looking at the repositories client the methods are just names \"GetAll*\" and that returns a full collection object once everything is done. I don't see how a .Take would help me here but then again this is the first time I've looked at Octokit so I might be looking at the wrong place entirely.\n\nPaging should be handled transparently as an implementation detail of the API.\n\nAs I could actually get the results as they come in as opposed to sitting around waiting for all requests to be made and had a way of cancelling when I got what I need I guess that'd be fine. What if I only want the first page of repositories returned from a search for example though (admittedly contrived example)?\n. > That's how it works today. The Get* methods return an IObservable.\nLooks like I got confused by our internal wrapper client in GHfW, that was the thing which collected all results. Well, in that case I'm golden. All I have to do is use a Window so that I only update the UI once for each response and not once per repo. Thanks @Haacked\n. > That gets my vote.\nDone, Mono and WinRT is excluded from this.\n. > Why do you need WebRequest to get ETags?\nSo the point here is that by using WebRequest we get the caching provided by WinInet for free. Octokit never even has to know about ETags or Last-Modified, Expires or s-maxage and all that crap. It's completely transparent and it'll use the system web cache to persist responses to disk.\n. @shiftkey #403 is part of this and I believe you still want that, no?\n. There we go, ready for review again. That last commit fixes some tests that I had inadvertently broken by doing the baseaddress+endpoint join myself instead of in httpclient.\n. These notes looks good to me :+1: \n. @Haacked see https://github.com/github/Windows/pull/1091 and https://github.com/github/github/pull/11054 for all teh backgrounds.\nIn the GitHub API 202 means that they've queued up a resque job and that the results will be available in a bit. It's also the reason I wrote RetryWithBackoffStrategy .\n. The documentation is conflicting and this probably isn't a problem anymore but there's a property on the handler called SupportsAutomaticDecompression. The docs says that if that's false and one tries to assign to AutomaticDecompression it'll throw an exception. I think this dates back to the time where HttpClient couldn't use compression on Windows Phone but they included a managed compression algorithm now so that shouldn't be the case anymore.\nAnway, ranting. It's more or less an ideological question for you to ponder :) Maybe we want the exception?\n. @shiftkey Good point, lemme fix that up\n. HttpClient uses HttpWebRequest for this request\n. @Haacked so this mirrors the HttpClient ctor and also stuff like StreamWriter. What I'm saying is this is not one of my new weird ideas :)\n. @Haacked Good point. I'll fix it.\n. ",
    "M-Zuber": "Completed with this release\n. I would like to second the notion of not using gh-pages. There is a project I contribute to,  and updating the docs are a pain in ...  ... \nIn other news,  there is  a little nifty tool I saw recently : http://classeur.io/.  I wonder if that can be hooked up which might make it easier /simpler to write the docs, which in turn ups the chance of them getting written. \n. I would also prefer to have a separate package \n. ## This is not an attempt to give an answer to OPs question, but to try and get a handle on what would be affected\nWhat enums would this apply for?\nSome points before your eyes glaze over as you read the list:\n- Quite a number of the enums use the ParameterAttribute to set the actual value as needed by/from the server\n- Some of the enums are not part of the client/server traffic\n- The list may be moot as there is a high probability that a fix will only be in SimpleJson\nWe have the following:  (links are from my fork as I am pulling from Visual Studio)\n- AuthenticationType\n- ArchiveFormat\n- OrganizationMembersFilter\n- OrganizationMembersRole\n- TwoFactorType\n- IssueFilter\n- ItemStateFilter\n- ItemState\n- IssueSort\n- SortDirection\n- MilestoneSort\n- DeployTask\n- WebHookContentType\n- Permission\n- PullRequestSort\n- Sort\n- RepositoryType\n- RepositorySort\n- RepositoryVisibility\n- RepositoryAffiliation\n- CodeSearchSort\n- CodeInQualifier\n- IssueSearchSort\n- IssueTypeQualifier\n- IssueInQualifier\n- IssueIsQualifier\n- IssueNoMetadataQualifier\n- SearchQualifierOperator\n- InQualifier\n- Language\n- RepoSearchSort\n- ForkQualifier\n- AccountSearchType\n- UserInQualifier\n- UsersSearchSort\n- StarredSort\n- AccountType\n- EncodingType\n- EnforcementLevel\n- CommitState\n- ContentType\n- DeploymentState\n- EventInfoState\n- MigrationState\n- PagesBuildStatus\n- PullRequestReviewCommentSort\n- ReactionType\n- InvitationPermissionType\n- TaggedType\n- TeamMembership\n- TreeType\n- VerificationReason\n. Shouldn't Assert.TaskThrows be Assert.ThrowsAsync?\n. I've been thinking about this some more and am starting to lean towards just providing a warning in the doc - comments. \nBut I will leave this open in case a discussion develops \n. is this the correct spot to put it in?\n. Crazy idea, but maybe make the model classes partial which then lets people make extensions (or ship an official opt-in extensions library) to the models and clients accordingly.\nAny thoughts? \n. forgot that..., can we hide this under a rock so no one ever finds it? :scream: :flushed: \nIs there a solution that exists for extending the models in a simple way?\nThe goal I have in my head is that a consumer that wants to stick to the official API they can, but they can also access objects that are a little easier to navigate through.\n. Understood.  Thanks for listening.  Only the future can tell what will become of this. \n. As can be seen in some of the commits, a number of expected exception types had to be changed. Please let me know if there is an issue with this.\n. @shiftkey for the Reactive tests when I remove the inner async / await, it complains that it needs an explicit conversion to Task.\nWhich is the better option:\n``` c#\nawait Assert.ThrowsAsync(() => (Task)client.Create(null, \"name\", new NewBlob()));\n//or leave the inner async/await\nawait Assert.ThrowsAsync(async () => await client.Create(null, \"name\", new NewBlob()));\n``\n. @shiftkey If the finalAppVeyor` builds succeeds then this is pretty much done.\nOne thing that I did not do is places where the call was not awaited where left that way after updating the method call.\n. @shiftkey\n\n. I never found a solution better then to ignore it. When it is a sign of a real problem, it will show up in the ci \n. Closed as @alfhenrik is now following an account\n. You need to await the call to Create as it is Task based.\n. :thumbs-up: to this.  I need it for a project I am building, and was planning to either call the api myself or loop the requests\n. It reads quite nicely. \nThe examples are very nice to have, a bonus would be a simple run down of the properties available even if they don't have examples.  (I would be willing to try and do a PR once this in) \n. Preaching to the choir, but I fully agree with @khellang \n. > what problem is this trying to solve?\n\nare there common things that consumers are implementing?\n\nThis would allow users to have optimized / official? code to use that doesn't necessarily match the api\nI can not answer for what others are implementing (but that is the beauty of Issues that we can find out :smile: ),\nbut for myself I am working on a whole set of extensions that connects the different calls into a more OO structure as opposed to matching the api, plus some more ideas that are currently only fluff in my head :cloud: \np.s. What gave me the final push to open this was #866  \n\nwhat belongs here rather than in the core packages?\n\nInitially anything that isn't a 1-1 (or however exact you decide) to the api goes into the extensions\n\nis there another way to satisfy this problem, without introducing a new package?\n- documented examples\n- interactive samples ala LINQPad #505\n\nIn some instances these options maybe a better solution, but without seeing what others might have to add, I have trouble giving an example\n. After #883 and #885 this may not be as needed, but it could still be nice to have properties with the actual objects and not just an url location. \n. So #1243 is relevant to this.\n@shiftkey I would say we can close this out as:\n\n@M-Zuber all good, happy to leave this open and see what sort of interest it garners...\n\nseems to have resulted in crickets\n. So ill close this and we can just enhance objects as requested. \nEnhancement of response objects is actually the main thing I was trying to get from this. \n. This is awesome. Let's me throw out ~200 loc and tests! \n. Thank you, I appreciate the work. This will probably help me a lot. \nJust a small request -  any possibility of getting an example of using the new property to load the comments? \n. I actually kinda want both. They can serve different kinds of discussions\n. I enjoy Slack so don't mind Slack only. Gitter on the phone is a bit of a pain, but it's still better the Github itself :wink:\nThe main selling point of gitter for me is the integration. If Slack has something similar then I'll withdraw my gitter vote. \n. Now that my computer started listening to me again ( I swear to God some days it behaves worse then a two year old), I was able to check the Slack integration with Github and it looks nice.\nThe main difference is in Gitter the information is displayed in a dedicated side bar, while Slack treats each event as just another message.\ntl;dr I've been converted to Slack\n. https://sameroom.io/blog/connecting-a-channel-in-slack-to-a-room-in-gitter/\nhttps://sameroom.io/pricing\nI am not sure how the pricing would work, but maybe there is a similar free option. \n. There is also a new player in town: http://www.ryver.com/\nI have played with it a bit and it is quite nice actually\n. Re capping the search history, I just saw this:http://techcrunch.com/2015/11/30/slackarchive-gives-you-public-chat-archive-for-free/\n@ferventcoder\n. True. Just thought it interesting. \nI anyways strongly recommend gitter. \nRyvver is nice for teams, but I don't see any integration points right now \n. I think no integrations will make it rough. But in my interactions with them,  they have proven very open to suggestions and make changes quickly \n. Ryvver has zapier and OData for integrations. Not super exciting \n. The property already exists here\nDo you want a PR to add it to the constructor?\n. :grinning: \nI'll send a PR in the morning.\n\nI think a new ctor taking the branch name is good enough here\n\nI assume in addition?\n~~Every class in the inheritance chain should get such an overload added?~~ I have been dumber, nothing to see here move along\n. If what I am saying is irrelevant, I will delete the comment to avoid clutter.\nWould this be the time to try and introduce a way to use the lib without any auth - as can be done if using the api directly?\n(I guess minimally you need PHV?)\n. I know it might be a lot to ask, but is it possible to put the smallest, most relevant code sample at the end of the first comment?\nOr am I the only one that feels it would be useful?\n. > To be honest, I'd make it hard to use this library without auth. The API is very restrictive unless you're using an Authorization header, and I don't really see much value in fighting against the API on this front\nThere are some use cases though where no auth is needed and it just gets in the way.\nToday for example I was having trouble searching through the projects I had starred.\nIn 2 minutes I had a simple script that downloaded all my stars and filtered - with no auth needed.\nBut its not a big enough problem to make a real issue out of it, so bowing out on this one\n. Looks simple enough\n\n// generate the client you need\n     var client = HttpClientFactory.Create(info);\n\nThis would need to be done before creating any new GitHubClient?\nOr is there room for an overload that just takes the info and calls HttpClientFactory internally?\n. From a first glance, it looks nice,\nAssuming I have time to contribute with code also - where you suggest I start?\n. c#\npublic GitHubClient(ProductHeaderValue productInformation) { } \npublic GitHubClient(ClientInfo info) { }\npublic GitHubClient(HttpClient httpClient) { }\nThis is what the final situation will be once the dust settles, and there is no need for back compat (v1 maybe)?\nIf so, it looks good to me.\nOTOH, I agree with @distantcam that there needs to be a way to adjust the values on a per request basis.\n. > OTOH, I agree with @distantcam that there needs to be a way to adjust the values on a per request basis.\nI have given it some more thought, and I think this is a separate point.\nI woulds like to be able to do something like the following:\n``` c#\nvar info = new ClientInfo\n{\n    // Defaults for most endpoints.\n};\nvar github = new GitHubClient(info);\nvar releaseInfo = new ClientInfo\n{\n  // Any overrides specific for this endpoint.\n}\ngithub.Releases.SetOptions(releaseInfo);\n```\nAs I believe such a scenario is for more advanced users, it is okay to ask them to perform the extra steps.\nobviously if the api is fluent then its nicer:\n``` c#\nvar info = new ClientInfo\n{\n    // Defaults for most endpoints.\n};\nvar releaseInfo = new ClientInfo\n{\n  // Any overrides specific for this endpoint.\n}\n// How exactly this should work  I am not sure\n// Either separate methods for each endpoint, or some game with genrics/enum - just no magic strings \nvar github = new GitHubClient(info).SetOptionsForReleases(releaseInfo);\n``\n. This is already a big step up.\nWhen I first tried contributing I had trouble setting things up as I had never used environment variables before.\nHaving even a simple script like this would have been a major help\n. Looks great to me. :+1:\nthank you for your hard work and apologies if i came across snappy above\n. Meta all the things!!! \n. looking into this\n. What I have so far on this:\nTheCanCreateAndGetAuthorizationByFingerprint` test does almost the exact same thing. (some asserts maybe can be added based on the test w/o fingerprint)\nIf the behavior is that NewAuthorization needs a fingerprint, then there is more involved then just removing the old test.\nThe model has to be also updated.\nWill wait here on feedback before opening PR\n. :wave:\n@shiftkey @ tting you as I remembered to not rely on other notifications \n. @shiftkey  I'll have to get back to you after the weekend. I do not remember exactly what I found.\nMost probably pretty much the same as @Anubhav10, but ill dig it out again.\n. I would like to try this one.\n. Lets start with Works On My Machine\u2122...\nIf I run it by itself\nI ran all the tests using the built in test runner of vs - the fails where unrelated to this.\nAlso when does Appveyor run integration tests?\nor will it never?\n. So of appveyor we have spoken. \nOf the rest of this issue we have not\n. @shiftkey @tting you as I remembered to not rely on other notifications \n. I'll do the rebase when my Internet is not from my phone :grin:\nDoes that mean  making a new PR? Haven't rebased in a while \n. NP. \nYou guys where not around in gitter and @shiftkey seemed to not know this twitter. \nI will close this and reopen a new PR that adds to the documentation. What is the target file? Contributing.md?\n. What about new string? \n. While I have come around to @Haacked's way of thinking in this regard,\nhaving a set of guidelines that is not our fault can be very useful.\nOne point that has not been mentioned is people new to C#. It may be confusing to them as in a lot of cases the existence of the BCL types is not even known to them. Sticking to the keywords may be less confusing.\nI can reopen the PR if you so desire\n. Here is what happened on twitter today\n. :joy: That sums up the thread so perfectly. \nThank you for the patience. \n. @shiftkey can I open a WIP for the string.format work? \n. Oh yes,  that should definitely be mentioned. \nThe way I am leaning is too link from contributing. md to a CustomCodingConventions.md file. \n. But that will have to wait until I am not on my phone. \n(also editing a comment) \n. This specific pull request or the new file? \nNew file yes,  this not (as I see it) \nAs a side note: responding through email takes an awful long time to show up... \n. I'd like to try and take this\n. Fixed\n.  \nI guess this is why packages is usually in the .gitignore  \u00af(\u30c4)/\u00af\nI'll fix it when I'm in the office\n. Done and rebased\n. I'd like to take this\nEDIT: This will take some research and planning, but I do plan on doing it\n. Per #1088, is a similar server side model wanted for OrganizationWebHooks? \n. From my side of things: Go right ahead. I never got started.\nGood luck!\n. I'll do this\n. I would like to try this. Seems like the simplest option to hang on as a gateway into more hardcore stuff\n. Have fun, you might want to look #1042 for inspiration :grinning: \n. :tanabata_tree: \n. I'll take this\n. Has this been an issue before (conflict of endpoint name in API and section header?)\nIf there is no precedence, my feeling is to stick with the actual api \n. Glad someone agrees with me ;) \n. From a quick glance-over this looks very nice. :+1: \nRe the CodeAnalysis that you are bulding, I think this is a complement. One is for the developer, the other for maintainers. (Also existence of method vs implementation)\n. Okay, so the wanted change is just the properties on the RepositoriesClients?\nI'll start over in a new branch, if that's okay. A little simpler for me\n. Force push is fun :smile: \nI'll be back\n. @shiftkey that gif more then accurately describes what I just went through\nCI y u no pas??? EDIT: I think I fixed him\n. BTW I noticed that there seems to be no tests for this property. Is this on purpose?\n. Do you need that empty commit rebased out?\n. git history was messed up real bad.\nOpening a new PR @ #1057\n. I'll take this.\n(only right as it's my fault it is here :stuck_out_tongue:)\n. okay, so this seems to be quite complicated (and possibly the reason tests were not written previously)\nYou can not get collaborator data if you do not have push access to the repository.\n@shiftkey what do you say?\n. Thanks for that input.\nWell I guess I am going to sacrifice my user to lots of notifications :) (or make yet another one :)\nHope to get to this soon\n. I am not sure why the builds are failing :(\nI did not add a separate test for the Add method as it is used in both tests already written.\nAlso there is no test for the delete method - should it be added?\n. Try:\nclient.Issue.Create\nOn mobile so can't be that much more helpful. Apologies \n. I believe I am done, but not sure how to fix the errors re missing files.\ncc @shiftkey or @Haacked \n. Should be done then. Thanks for the help\n. :tada: The errors are not my fault (I think :smile: )\n@shiftkey this should be complete for real now\n. :+1:\n. @shiftkey it is ready for a re-review\n. @shiftkey look quick, it is still green :smile: \n. :laughing: \nThank you for all help. This PR helped me much better understand the structure of octokit.\n. > But I'm confused by what you wrote. Are you saying that if you pass something other than null you get a test failure? Or if you omit that last argument?\nIf I omit the last argument.\n\nAlso, connection.Get returns a Task so you need to set up that return value.\n\nI was just following most other tests, where all that is being checked is the fact the correct url was touched.\n\nAlso, if an Ensure check isn't occurring I suspect some actual code is being invoked. Do you recall where that was?\n\nIt is being invoked and therefore failing as it sees the URI as null.\n\nI gather this is occurring due to the overloads on Get but it's hard to say specifically without a bit more context. So it sounds like the Get(Uri uri) code was failing the test, but Get(Uri uri, IDictionary parameters) was making the test pass - does that sound right to you?\n\nThis sounds exactly right to me, a simple repro is too take the test here and remove the null. (this way you could use code theoretically already on your machine)\nWhat is more confusing for me is that this line: connection.Received().GetAll<RepositoryHook>(Arg.Is<Uri>(u => u.ToString() == \"repos/fake/repo/hooks\")); does not need the null to pass... It seems to be related to whether the call returns a single object or a List\n. I realized that tests where not mentioned in this issue.\n@shiftkey do you think they should be added as a requirement to the existing PR, or a separate issue opened up?\n. Thank you for responding. Apologies if I was not clear enough. \nI'm asking about the serializer not in the context of octokit.net. \nFor example there is this api which has no wrappers. I would like to create one modeled after the octokit way. \nSince there are multiple such apis, a project template with the folder structure setup would be nice. \nIn order to make it even better, I want to include code wherever it makes sense. \nSo the json parser + serialization being internal don't bother me - but how simple do you think it would be to copy out the code and dump it into a project with different models? \n. > I'm pretty sure someone has repurposed this codebase (or been inspired by it) to apply it to a different sort of API. I forget the product, it came through via Twitter.\nIt may very well have been me :grinning:, as I have been sitting on this for a long time\n\nI'm :thumbsup: if someone wants to extract these relevant bits and explore making it more general purpose for API clients.\n\nThank you very much for the information. I'm going to start the exploration. Hopefully it won't take too long to get something out into the open\n. \u00af(\u30c4)/\u00af \nThey have nice docs btw :wink: \n. [Linux] \"Got a SIGSEGV while executing native code.\" https://gist.github.com/M-Zuber/7efea02cbf47fb310131982bbfcbd63b\nhttps://travis-ci.org/octokit/octokit.net/builds/129625518\n. @prayankmathur How then would someone search for all issues?\n. Sounds great.\nOpen a Pull Request?\n. @ryangribble Thank you for pointing that out.\n@prayankmathur My suggestion would be to\n- Create a new enum ExpandedItemState (or the like, @ryangribble  might have a better name)\n- Find all the places the ItemState enumeration is used, and check the corresponding api docs\n  - Where All is a valid option, use the new enum.\n. > I like where this is heading. If it were me, I'd probably introduce a new enum in the search API instead of sharing the ItemState enum as it doesn't support All.\nSo the opposite of what I suggested, which does make more sense as it is much less of a change :)\n. Could you please open a PR?\nIf you are not sure how that works, may I suggest watching this video? (the whole series actually is quite nice)\n. So here is the story:\nI did a git pull on a computer that I had not done so for a while.\nFor some reason it updated all the .csproj files correctly - except for the default.\nWeirder is that once I included the files manually - git told me that there were changes in the .csproj - namely lines not in the right place.\nSo it knew the files existed and where supposed to be included but VS did not.\nIs it possible because I had VS open during this whole saga?\noh, btw I am not on Git for Windows fast loop so that should not be the problem #troll\n. Thank you for catching the typo! \nI should be able to add unit tests after the weekend. \nWould you test anything in the unit tests other then that the correct url was called? \nThe integration test can create, update, and then delete a file on the same branch. Sounds good to you? \n. I wasn't able to get the unit tests to work, hopefully the integration test will be enough\n. @ryangribble thank you for the PR. I asked a question there. \n. YAY!!  I got a Stevie!! :grinning:\n. There seems to be a lot white space that could be cleaned up. \nIf you are using visual studio 2013 or higher, pressing ctrl + K, d should take care of the formatting. Otherwise it will just have to take the time that it takes. \n. I apologize for being picky, it is an issue that I have.\nOther then the little things I pointed out, it looks awesome :+1: \n. :smile: \n. LGTM, but I do not have commit rights, so you will have to wait for one of the maintainers to confirm and merge.\nHow do you feel about trying to add some tests for these changes in the meantime?\n. Good luck!\n. Noice!! \n:shipit:\n. :blushing:\n. In agreement with @shana (Someone needs to make a thesaurus for things to say instead of +1 :wink: )\n. Is there a file for such extensions? \nIf not where do I put it? \n. Where do I put the tests?\nThe Helpers folder in the integration tests projects seems to be for helpers for the tests, so do i just add a test to the file for the IReferencesClient?\n. @shiftkey this code could be useful in other places as well. \nCan I /Should I move it into the extension class, create a helper class, or duplicate it?\n. :+1: , but in the end I did not need it (pending review of pr)\n. :joy:\n. And here I was talking bad about you.\n\nPlease accept my apologies :smile: \n. I'm on my phone so I was only able to fix the spelling. \nI'll assume the errors from ci are due to merge conflicts. \nWill deal with it when I'm in the office //@shiftkey \n. @Haacked is this good to go?\n. @Haacked any chance we can wrap this up without more merge conflicts :wink: \n. Mad skills with the ball :grinning:\n. Do we really want to go through the port now? \nWait a week or two and see if they come up with a a date and based on that decide if we will wait for RC2 to start porting? \nIf we are starting now I would say the first thing to figure out is nuget package creation. \nSay pick two random profiles from the list we want to support and see what it takes to get the build to produce the packages correctly \n. > Just fyi, the GSoC student proposal application period starts March 14 and ends March 29, and the official coding period for the program doesn't start before May 29. \"Now\" is quite a ways away for GSoC :smile:\nI missed that connection :grinning: \n. My best guess is that it was meant to be passed on here\nThat class controls how serialization happens, but provides a ctor that sets a default implementation, so it seems not passing it on was overlooked.\n. I would think so. \nA PR is probably a good way to get feedback. \nWorst case scenario you change the PR to remove the parameter from the ctor\n. LGTM, but I would say there should be a check/manual set to default for the type parameter if either visibility or affiliation are set.\njust my 2\u00a2\n. The failing tests seem to be due to the fact that they pass in Substitute.For<IJsonSerializer>().\nI am attempting to debug further to try and understand what the fix should be.\n. That would have to be the call of @Haacked or @shiftkey as they should be more familiar with what exactly is going on in the test.\nAnd the truth is, it does not make sense for that change to be breaking the test anyways so I would vote for some more investigation first.\n. I'm honestly not sure myself...\nDo you know if there is a way to set a breakpoint within the lamda on line 322?\n. That gave me an idea, I'll get back to you in a bit.\n. TL;DR use the substitute also for setting up the data.\nInstead of this I wrote this:\nc#\n var serializer = Substitute.For<IJsonSerializer>();\nstring data = serializer.Serialize(new object());\nvar httpClient = Substitute.For<IHttpClient>();\nIResponse response = new Response();\n httpClient.Send(Args.Request, Args.CancellationToken).Returns(Task.FromResult(response));\nvar connection = new Connection(new ProductHeaderValue(\"OctokitTests\"),\n      _exampleUri,\n      Substitute.For<ICredentialStore>(),\n      httpClient,\n      serializer);\n. I was very tired last night and not paying attention to the point raised by @ryangribble , namely that no mock was set for the Serialize call.\nPersonally I would mock that call and test that body == data in order to not leave holes in the test. You can not always know what edge case will be protected against by having that in the test.\n. Follow @ryangribble's recommendation\n. You shouldn't need to mock the object being passed in.\nYou want to do something like:\nc#\nvar serializer = Substitute.For<IJsonSerializer>();\nserializer.Serialize(body)\n   .Returns(SimpleJson.SerializeObject(body));\nwhich is setting up the mock IJsonSerializer to use the SimpleJson impl.\nWarning I do not know if the above works, but I believe that is at least the correct concept.\n. @shiftkey's variant works , but not yours\n. I ran your test exactly as above and get the following :(\n\n. @ryangribble - hanging my head. I am going to sleep for a month or so and then I'll come back :)\n. No, I wasn't paying enough attention and reporting false findings, thats all.\n. I'd like to take this one. Will do it now.\n. Added a reaction (kudos BTW - awesome work!!).\nI really like @ryangribble's proposal. Wonder if we want to incorporate some other tools though - ala https://github.com/GitTools/GitReleaseNotes\n. A lot of new names this time around!! \nNoice!!\n. This all looks lovely :sparkling_heart: \nMaybe once a syntax is decided on, you can make an pullrequest_template?\nedit: Oh and the actual script/code should be a separate repo IMO\n. brain fart: Should we include the release in the obsolete message? (the release that is current when the change is made || a reviewer can just say - add in \"in release x.x.x)\n. >  but 2 releases feels like a good number\nI agree, but for devil's advocacy do accepted (& actually used) guidelines exist for this kind of thing?\n. Sounds good to me.\nI have some Real Life\u2122 to take care of, and then I will try and post back with a sorting of Obsolete methods based on release\n. > Happy with that approach for .20 release?\nIf the answer is yes, I would like to do that PR\n. ApiConnection.GetRedirect() depends on IConnection.Get(... allowAutoRedirect)\nIt currently did this: return connection.Get<T>(uri, null, null, false);.\nShould I just drop the last param?\n. :clap: Nice stuff!\nWelcome to OSS :smile: \n. :shipit: \n. @shiftkey bump\n. Other than my comment (which is more a question really) it LGTM!\n\nI have one question about integration tests for (Observable)AuthorizationsClient. There are no any integration tests for these clients, so should I add it?\n\nMy (non-maintainer) opinion is - if the tests follow existing conventions and coding styles - test away.\n. Yeah, I've had the email for that issue pinned since it was opened - because some day I will download the code and do a real review :laughing: \n. > These 2 are also potentially \"awkwardly\" named\nIMO The client name is a bit off. If our gospel is the API docs, they should be\nIStarringClient\nIWatchingClient\nEither way Watch and Star can also be adjective-iy so\nc#\n\\Octokit\\Clients\\IActivitiesClient.cs(19):    IStarredClient Star { get; }\n\\Octokit\\Clients\\IActivitiesClient.cs(24):    IWatchedClient Watch { get; }\nwould not be so jarring ( :stuck_out_tongue_closed_eyes: ) IMO\nIn the same vein the StarredRequest class name feels off to me\n. Would you be open to one fat PR that rips out all namespace parts lower than what matches the project? \nOr shall I split it up? \n. ~~What do you mean by indenting changes?~~\nBased on my next comment I think I understand what you where saying, @shiftkey \n. An example of what things look like now is\n\n@Haacked do you want to just drop the .Clients or drop the namespace altogether (like :arrow_down: )?\n\n. IMO I would do the first option. having a namespace that matches the project name does not create noise (at least to me) - and that is what is included in the default.\nIs there a setting that prevents VS from tacking on namespace parts to match the file system?\n. I am voting for leaving a namespace that matches the project name, but dropping any further levels.\nFiles that currently have no namespace can stay that way.\nI would also include adding a test to Conventions to the PR.\n@shiftkey @Haacked @ryangribble any feedback please?\n. Yeah I meant the the test should only fail if there is a namespace and it doesn't match the project \n. So how do we reach a consensus on this, so I can either code or close?\n. @ryangribble done\n. :sob: \nThat's what I get for pushing my machines RAM too hard. The error in VS hadn't show up by the time the commit was pushed....\nI'll wait for @shiftkey's response (may have to wait until after #build :smile: ) and follow his recommendation\n. I'm good to do the work, but on the road ATM. \nWill attempt to get to it in the next day or two\n. @shiftkey @ryangribble rebased and updated code with regards to .GetRedirect.\nWould love if I could get some :eyes: on the changes to make sure that the changes are correct.\n. A few things off the top of my head:\n- Have a test that uses a label starting with a hyphen and exclude it\n  - Codifies the reasoning behind having that separate list\n- Can a username also start with a -?\n  - If so, excluding issues by a given user would also necessitate a similar construct\nEdit:\nReal bran-fart this time: If a number of filterable items can start with a - (meaning to actually filter you'd need to do a --), maybe make a .Not property that contains a nested SearchIssuesRequest? (I know crazy idea but you only live once or something)\n. \nIt works on (almost) anything\n\n\nHave a test that uses a label starting with a hyphen and exclude it\n\nWith the way it's been implemented the label name doesn't really matter. I have a unit test that checks when 2 labels are specified in NotLabel we get the expected -label:label1 -label:label2 arguments. Also I added an integration test that searches octokit.net repo for \"up-for-grabs\" labelled issues and a 2nd search for NOT \"up-for-grabs\" labelled issues, then checks to make sure the lists are unique\n\nWhat I was trying to say was have a test that looks for a label that starts with a - so as to show that it is legal for a label to start with that char, and it will not be treated as negation if such a label exists.\nNot showing that NotLabel will exclude it, but that Label/Term will include it\n. - :embarrassed: guess I just assumed the api was being dogfooded. \n- as someone who wrote (albeit a simple one) a query language, hiding syntax behind human readable properties is A Very Good Thing\u2122\n. > Although Im thinking perhaps for future proofing (If it does turn out that lots more fields can be negated or even the fact that it's likely in the future more fields would be able to be), I could perhaps move to having a new class to hold all the exclusions (and thus refer to them as normal names like Label).\nThat is pretty much what I was trying to say with this :arrow_down:, and your example implementation is nicer :smile: \n\nEdit:\nReal bran-fart this time: If a number of filterable items can start with a - (meaning to actually filter you'd need to do a --), maybe make a .Not property that contains a nested SearchIssuesRequest? (I know crazy idea but you only live once or something)\n. > It could well be that the API accepts more options than the doco says, but for now Im thinking of just implementing what the doc says (where labels are the only things that can be excluded).\n\nSounds good to me, I just wanted to bring up such a possibility\n. > Created,Updated,Merged,Closed,Comments\n\nThese date/range fields already support greater/less than and \"between\" syntax, so having an exclusion option doesnt really make sense so I didnt attempt to implement/test\n\nI would say to yes implement (assuming support) as some users may find it easier conceptually to use .Exclusions (BTW great job on naming)\nMight be open to doing a PR into this PR for those fields.\n\nUser\nNot tested.\nDoes it make sense to do a search for something in all repos EXCEPT those owned by a user or organisation?\nRepos\nNot tested.\nDoes it make sense to do a search in all repos EXCEPT some specified?\n\nI vote for yes as I have done both in the past.\nOne example that covers both is looking for something .Net Core related - but not in anything from Microsoft & Microsoft related repositories.\n. Checks like this are in theory possible, but would require a lot of hard coding (not that that is a bad thing, just something to keep in mind).\nAnd I second @dampir's suggestion that they go into Conventions and not FormatCode\n. One thing to pay attention to is that requesting a specific issue will not return the repository key.\nHow would you suggest we deal with this?\n. What about extension methods? (other than being ugly :wink:) \n. Welcome and thank you!\nI'd like to offer some pointers that will help get the ci build green and the PR merged. \n1. Some tests where impacted as the expected url has now changed. (when I am back in front of a proper machine I will try and link to them)\n2. The new method should be added to the IEventsClient interface. \n3. IObservableEventsClient should also be updated, as well as the implementing class. \nIf I can help in any way, just let me know. \n. @shiftkey fixed\n. Documentation wise I swing either way, but for implementations - definitely feel each client that needs reactions should have such a method. \nOne idea that I have no idea if it's feasible as I'm not checking code is to have an interface that defines the reaction methods and then clients that expose that will provide specific implementation \n. Overall looks pretty solid to me.\nout of curiousity, @lrz-hal is your test account?\n. When I first started contributing to octokit.net I did the same thing :laughing: \n. :tada: \nLooks great!!\nalthough someone with more experience than me like @ryangribble should also have a look\n. Some nitpicking on the tests, but otherwise looks clean enough.\nI just have some an itch to try and make a generic solution, but I don't think it will end up looking too nice.\n(something along the lines of the urls being based of a type param...)\n. I personally prefer A, but don't mind B that much.\n@ryangribble do we really gain by having Issue.Comment and not IssueComment though? I see that that is how it's done on the Repository client, but since we are dealing with a small limited set of methods it might make sense for it to sit directly under Reactions.\n. updated -> A\n. Maybe we should consider adding an attribute to properties that contain mappings of potential names for the deserializer.\nFor example, \n[OtherNames(\"sha\")] \nPublic string ID {get} ;\nAlthough this will only work if the type is the same . You can't delete issues on github in any anyway as,  only close them. \n. I agree with @ryangribble. \nTo add to that, these overloads where added in 0.21 which was only the release before last.\n. Beat you to it \ud83d\ude03 \n. While this would take away one of the main pushes I have to learn F#,\nI think this will lower the bar for new contributors and therefore very welcome.\n. Looks good to me from what I can tell. I'm working on trying to figure this out.\nIf we come up with something that works, there are a number of other tests that are currently skipped for the same reason of needing admin rights\n. The main issue I am hitting is generating any sort of traffic.\nCalling new WebClient().DownloadStringTaskAsync(...) does not seem to register as a hit.\nI see two options:\n1. Assert referrers.Count is 0\n2. Create a browser object, navigate to url, ect, ect.\nIs there another option I am missing?\n. I'm not sure how that is different then what we already have with the user, org, and access token set in environment variables? \n. \ud83d\udc4d thanks for pointing that out, will get to them soon\n. Done \ud83d\ude3a \n. That approach makes the most sense.\nWould be cool if the serializer could phone home on error and open an issue to add the new value to the enum.\n. Feels good to me . That idea was only to allow us to then properly add the values into the enum, but I don't see a way to have octokit.net phone home from someones app, without them getting upset about it.\nAs long as we can safely parse any value by having a Unknown member to fallback on, that should be good enough for the medium term. xxxRaw sounds better to me as well. I'd like to try and do this one if it's still available . I want something small in order to get back into things.\nLets see if I can get this one done fast enough to start tackling those also \ud83d\ude00 . How exactly do you want the additional ctors to look?\nCurrently there are 2: one that takes only a BranchProtectionRequiredStatusChecksUpdate, and the other that takes a BranchProtectionPushRestrictionsUpdate in addition.\nBased on my understanding of the docs: You can, and should, pass required_pull_request_reviews as well. While this is not required currently, it should be treated as such and will be soon.,  the BranchProtectionRequiredPullRequestReviewsUpdate object is different in that it can not be disabled by passing in null.\nThis would lead to a total of 3 ctors:\n- BranchProtectionRequiredPullRequestReviewsUpdate + BranchProtectionRequiredStatusChecksUpdate\n- BranchProtectionRequiredPullRequestReviewsUpdate + BranchProtectionPushRestrictionsUpdate\n- All three\nDoes that make sense?. Hmmm... Had not thought of it that way, and you are probably correct.\nBut the docs seem to imply otherwise as for the older params they specify pass in null to disable while for the new param they don't.\nSo I am going to assume you are correct, and try to write an integration test proving it.. I didn't get to writing the tests yet, but am making a pr just to get another set of  \ud83d\udc40 on it as soon as possible. > The names are getting pretty long though! I wonder if instead of BranchProtectionRequiredPullRequestReviewsUpdate we can get away with BranchProtectionRequiredReviewsUpdate instead. What do you think?\nBranchProtectionRequiredReviewsUpdate sounds good enough to me\nI am also pretty sure that you are correct, I just made my initial code based off of my understanding of the docs. I was a bit too daft to go check the UI \ud83d\ude06 . @ryangribble while I am fixing the naming for the new object, should I shorten the other names, or make that a separate pr?. Thank you for the nudge\nHad a rough spot in my personal life, and then my computer needed to be repaved. \nI will do my best to finish this up by the end of the week. \nA decent amount of the code is already written, I just have to polish and push. I would want to incorporate those changes before I push, as some of my changes might not be needed.\nWill try and put something together soon for a review. Based on the tests I tried updating, and the UI, any IncludeAdmin is ignored if it is not at the top level of the BranchProtectionSettings\nShould I just make those changes as part of this PR, or make a new one that updates the existing code in master, and then rebase this PR on top of it?. To be more accurate, it seems that (as per docs I suppose) if any of the update objects pass in true for includeAdmins the top level setting is set as true\nAs evidenced by this screenshot of the docs\n\n. @shiftkey or @ryangribble any tips on how to proceed with this?\nThe main issue is that we need to obsolete all ctors that accept the include_admins param, as setting it in one object can be overriden by another, or by the top level param (which still needs to be added). Thanks for picking this one up, and my apologies for dropping the ball. One little thought, but otherwise LGTM\n. \ud83d\udc4d Thank you!\n. What DI are you using?\nYou should be able to set the credentials in DI setup, and when it gets passed to the controller it is fully ready to use. I'm not that experienced in DI, but do you have an option of calling something like container.GetInstance<IGithubClient>(), registration of which is set to pull token from logged in user?\nI know that it is not the cleanest solution, others may have a better one.. I meant that instead of relying on injection into the controller, inject the Autofac container itself and call container.Resolve, which - if I understood correctly - can be registered to use dynamic values to create the instance.\nThere are a number of projects that might have useful code, when I get back I'll try and look for them.. My apologies, I remembered wrong.\nThe posts I had seen only dealt with the actual login, not how you would deal with using the combination of DI.\nhere they are anyways, in case they help you with something.\nhttp://www.jerriepelser.com/blog/owin-oauth-provider-github/\nhttp://www.jerriepelser.com/blog/using-aspnet-oauth-providers-without-identity/\nhttp://haacked.com/archive/2014/04/24/octokit-oauth/. @ryangribble might have something more helpful to add. Looks good to me!\nI will try and get #1523 up to snuff to try and squeeze it into this release.. oo.. that is probably related to Integrations. https://github.com/vadimdemedes/trevor might also be useful in debugging the travis issues\nEDIT: Do'h now I see it uses docker, it is probably just an implementation of the official guidlines. ]. \ud83d\udc4c . @ryangribble I am working on implementing this, but there is a question of just how many constructors to add\n\nDo we tell people that if they want to set EnforceAdmins they have to use the fullest ctor, or add another two?\n(once this lands, #1523 is going to be adding a few more as well..). so n+1 with n being the number of properties on the class? Sounds good to me.\nAn interesting item in the docs that @shiftkey might have some insight on is the fact that the include_admins property on some of the sub classes is marked as required, but in testing I've done, it does not effect the end result.\nMy personal vote is then to obsolete it as it can cause confusion.\nedit: a quote from the announcement\n\nThis will be a breaking change in the near future. To make the transition easier, we're allowing you to set admin settings the old way by passing include_admins for required_status_checks or required_pull_request_reviews on the general update branch protection endpoint until ~April 21, 2017~ May 2, 2017. At that point, the only way to change your admin settings will be to pass enforce_admins, and passing include_admins will receive 404 responses.. I am trying to implement this methods: https://developer.github.com/v3/repos/branches/#add-admin-enforcement-of-protected-branch, but running into trouble since there is no IApiConnection.Post overload that does not take data - but that will take an accepts header.\nDue to that, the unit tests are failing. The unit tests for RemoveAdminEnforcement are failing for some odd reason... okaayy....\nWrote up the integration tests, and include_admins is still required - even though it might be ignored if the enforce_admins param is passed in.\nWill rollback the removal and push, but do we obsolete it - or just leave it alone until it is no longer respected by the api?. I think I am done with this @ryangribble \nJust one breaking change as outlined in the pr description.. So lets wait a day or two and give AV another kick and see what happens\nAt this point the property is not used anywhere - it just exists on the class so taking it off will be quick. There is also the question of those two unit tests that are failing for some reason. I am quite sure that they are implemented exactly the same way as other tests for methods with the same kind of code. Sure, did a rebase.\nthose commits got included by mistake when I was doing some commit cleanup. Review comments addressed.. @ryangribble You want to try re-running AV and see what happens with re to the include_admins param?. \ud83d\ude06 I am still pedantic enough to run integration test locally\nwill ping in a few once I push changes. @ryangribble \n\nwe should be good to go\nalong the way found out why the unit tests where not working. Woot!\nThanks for working through this with me, feels so good to get back into OSS\n. LGTM. . I might be able to pick this one up, what would the simplest way to do that @ryangribble ?. I pushed the changes up to https://github.com/M-Zuber/octokit.net/tree/jozefizso-feature/1586-repository-license\nlet me know if there is anything else that needs to be done. . Sounds good, \nWas planning on doing all 3, just wanted to see if I missed anything . > Would it be more convenient to provide a type wrapping the payload JSON? So you could add a method like DeserializeAs(), which would deserialize the JSON into the specified type using the built-in serializer and settings?\nI am not following what this gains?. Other than that one comment, it LGTM. \ud83d\udc4d from me, thank you for working so hard on this release!. \u2728\n\ud83d\udc4d. LGTM. . LGTM. I threw this code into LinqPad and it seems to run fine\n```cs\nvar g = new GitHubClient(new ProductHeaderValue(\"test-bug-report\"));\nvar x = g.PullRequest.Review.GetAll(\"octokit\", \"octokit.net\", 1648).GetAwaiter().GetResult();\n// lingpad specific, instead of Console.Write...\nx.Dump();\n```\nWhat happens if you remove your custom IHttpClient entirely instead of just calling the default one from within the custom one?. \ud83d\udc4d Keep us updated so we can try and help. Where you able to work around the issue of things taking too long?. While you have been explicit that this is a WIP,  could you please explain the difference between this and https://github.com/octokit/octokit.net/blob/master/Octokit/Models/Request/PullRequestReviewCommentReplyCreate.cs ?\n(best would be if you could update the PR description). \ud83d\udc4d. client.Repository.Release.GetAll is an asynchronous function so you will need to await it first, making your sample look like\nc#\nvar tmp = await client.Repository.Release.GetAll(\"Dorky106\", \"BetterTrees\");\nvar latest = tmp[0];. Implementation as well, I believe . That would show up when a user does client.RepositoryStatistics before dotting into an actual method?\nIf so, then you have my +1. LGTM if I still count :). Can you share some code?\nWithout knowing anything it looks the object is getting converted to a string automatically, and since ToString is not overriden, you just get the type name\nYou can see here for more information on ToString. Try changing <li>@issue</li> to <li>@issue.Title</li>. If I recall correctly the ctors are used during deserialization.. Here are the related tests that I found if it helps any:\nhttps://github.com/octokit/octokit.net/blob/3147ddd6941bc45fbe5fb2a2a958eb61e10edf4a/Octokit.Tests.Integration/Clients/IssuesLabelsClientTests.cs\nhttps://github.com/octokit/octokit.net/blob/3147ddd6941bc45fbe5fb2a2a958eb61e10edf4a/Octokit.Tests/Clients/IssuesLabelsClientTests.cs\nhttps://github.com/octokit/octokit.net/blob/3147ddd6941bc45fbe5fb2a2a958eb61e10edf4a/Octokit.Tests/Reactive/ObservableIssuesLabelsClientTests.cs. Now I really understand the power of the ?. operator \n. This ensures that current consumers won't get null\n. See above\n. Since I added the Error Property the conventon test picked it up\n. Unique in what aspect?\nThe Get returns metadata about the pages site and the other endpoints return metadata about the builds.\nI am fine with dropping the suffix though\n. Sorry I missed that :sad:\n. Doh! \nI was going to remove that. Should I open a new PR? \n. Should probably be or organization member\n. and user should be or user\n. and user should be or user\n. Should be The visibility no? \n. I would think it should be The affiliation\n. white space\n. white space\n. white space\n. the should probably be lower case\n. The owner should be changed to The affiliation\n. What do you mean by this?\n. ~~Copy paste error :smile:~~\n~~Will fix when I'm back by a machine.~~\n~~It is needed. If removed the test completes, but fails with a message that no error was thrown.~~\nEDIT: Drunk VS had me today/\n. The parameter name is branchName. I would hope that should be enough, but I do not see a problem with adding that check.\n. Is this about what you had in mind @Haacked?\n. Serious question: Some of use come from a more relaxed definition of professional setting in general, or at least when it comes to projects done on private time.\nIs it worth it/is there a way at all to reword this bit so as not to cause confusion due to the dry (American based) meaning?\n. I'm not sure why but in the rest of the lib the <returns> are left empty.\nWe should either stick with that - or start here as change (which would necessitate going back and changing the entire code base) \n. This should be in the singular - Hook to be consistent with the other sub-client properties\n. This should be in the singular - Hook to be consistent with the other sub-client properties (will flow from a refactor of the interface but figured I'd mention it here also)\n. This method does not seem to be doing anything. Could you please explain it's purpose?\n. Namespace parts should be uppercased\n. This should be in the singular - Hook to be consistent with the other sub-client properties\n. @ryangribble is the master of consistency around here, but I believe that (in a separate  PR) IObservableRepositoriesClient (and probably IRepositoriesClient) would need to be changed also\n. There is no corresponding parameter for this, so the Appeyor build is failing\n. But as far as I can see the method is just returning the config dictionary passed in...\n(after Union with an empty dictionary and then ToDictionary for some reason)\n. Can you rename the folder to uppercase? Or drop that part of the namespace?\n. Will do.\nbeing consistently consistent can be hard :)\n. Opened #1207 to go into this a bit more\n. opened - #1208\n. public static Uri Blob(string owner, string name) existed already, so you would need to add the [Obsolete] attribute - with a message pointing to the new method, and a new method of public static Uri Blobs(string owner, string name).\n. Enums can not be null unless specified as ?\n(see here for more information)\n. Actually you should be using Paramater attributes on the enum value, which enables them to be automatically serialized, and then you do not need this switch. (goes along with this comment)\nsee here for an example\n. This should be EnumReaction type.\n. Naming things is hard (\u2122 by @shiftkey :stuck_out_tongue_winking_eye:) but this one kinda grates on me.\n. You should hardcode the header string, so it serves as a sanity check against misspelling.\n. I didn't pull down the code to test it, but shouldn't you be able to just do Content = content?\n. You check if NewReaction is null, so probably want to have a test here on that as well\n. If the tests are for the CommitCommentReactionClient subclient, why not create that as the client here instead of the higher level?\n. It has been discussed previously that the AcceptHeaders should preferably be hardcoded so as to act as a sanity test against spelling mistakes\n. So you would then check each subclient in each method? Might make the tests a bit noisy.\nAlso, I would suggest changing the name of the class here\n. No, they should only be hardcoded in the tests. In actual implementation code they should be accessed through the AcceptHeaders class\n. Oops! my bad, sorry :fearful: \nI meant to comment on the test. Either way here is a previous discussion about it\n. In some places you kept the ()  when using object initialization syntax and others not\n. yes. But, but, then I won't know when someone runs the integration tests \ud83d\ude01. Isn't this 2017 update 3?. > so couldn't follow our normal deprecation schedule\nso we couldn't . Is there a way to make it clearer what is happening here?\nas a newcomer to the codebase might be confused by null being equated with an empty array. From the perspective of an external user, I think what you have is a nice solution.\nMy worry is more on someone coming along later trying to contribute, and not understanding the code comment\nMaybe something like API requires an object with empty members to be passed in order to disable these checks?. Will be or already is?. ",
    "lbargaoanu": "This should be closed.\n. I guess it should be closed.\n. I think it's done.\n. Done.\n. Done :) But two tests fail. CreatesANewPrivateRepository with \"422 Unprocessable Entity\nValidation Failed name can't be private. You are over your quota.\" and CreatesANewPublicRepository with \"404 Not Found\". It seems unrelated.\n. I can take this. ConventionTests depends upon ApprovalTests, Castle and NUnit. It might be easier to do it by hand or customize the generated code.\n. https://github.com/lbargaoanu/octokit.net/blob/convention-test/Octokit.Tests/Reactive/SyncObservableClients.cs\nMany interfaces fail the test, but I don't see false positives.\n. http://fsharp.github.io/FAKE/apidocs/fake-xunithelper-xunitparams.html\nMaybe I'm missing something but I don't see how you can specify a trait to exclude.\n. Sorry, but I'm missing your point about RepositoryHookConfiguration.\nI know it's a hack, but rather than create a separate project it would be easier to simply comment the Fact attribute on the method. It's only run on demand after all.\n. This should be closed.\n. Reproduced for CreatesANewPublicRepository from outside VS.\nPOST /orgs/testbal-org/repos HTTP/1.1\n{\"name\":\"public-org-repo-20140124012209011\"}\nHTTP/1.1 404 Not Found\n{\"message\":\"Not Found\",\"documentation_url\":\"http://developer.github.com/v3\"}\n. The same here. Maybe I shouldn't close the issue, so we have a record of why these tests fail.\n. I merged master into my branch and I see no changes. CheckClientInterfaces fails as before. Something is rotten here :).\n. I see now :). Well, after I merged master, I ran the unit tests again and they all pass.\n. Can we merge this with #346? Because in order to implement that one I had to refactor a little.\n. This should be closed.\n. I can take this.\n. This should be closed.\n. I think the problem is with the async delegate. We should have similar with AssertEx.Throws, AssertEx.DoesNotThrow. Or simply call Star and Unstar without Assert.\n. Yes. Fixed.\n. ",
    "tpeczek": "@Haacked \nWell I should have catch that in the first place, so I will be happy to fix that.\n/cc @shiftkey \n. @Haacked  @shiftkey \nWorking on it, I will provide pull request as soon as possible\n. @Haacked  @shiftkey \nYou can choose which one you want now :).\n. ",
    "ben-biddington": "@Haacked @shiftkey @tpeczek #268 resolves it if you like\n. ",
    "goalie7960": "I've updated the documentation stuff you requested.  I ran build.cmd and didn't see any errors, not sure how else to verify the FixProjects thing.\n. Merged and projects have been fixed.\n. going to close this, will reopen when i'm ready\n. ",
    "technoweenie": "Haven't needed it for a couple months :) http://developer.github.com/changes/2013-11-04-releases-api-is-official/\n. ",
    "ammeep": "We must have this! Will get cracking on this tonight :dancer: \n. These set of API's are a little different to what we already have in that the operations are expensive. On the first request the calculation of the stats is queued up and you are returned a 202. You retry the request until the job is complete and a 200 is returned.\nShould Get be responsible for tracking the 202, and 200. Or do we provide a pair of operations - one to queue the job, and another to wait for its completion?\nThe downside with the latter - the 'wait for completion' method would still need to take into account that the stats might need to be recalculated server side (which will happen on each push to master)\nI prefer the first option, but does anyone have any thoughts on how we want this to look on our client API?\n. One question I have - this API is not exactly user friendly. It likes to use arrays of ints everywhere. I would be keen to add some smarts to the objects being returned so that these are useable. For example \nGet the number of commits per hour in each day\nReturns: [ [2, 14, 25], ......]\nWhich actually means:\n\nEach array contains the day number, hour number, and number of commits:\n0-6: Sunday - Saturday\n0-23: Hour of day\nNumber of commits\n\nWhat do people think if we beefed up the models being returned from the statistics client to make this a much more consumable/understandable object.\n. > .\\build FixProjects to sync up the Mono* projects\n:heart_eyes: \n\nA crazy idea: encapsulate the data behind a more human-friendly API in the response. rather than exposing the array directly (well you could do that anyway)...\n\nThis is exactly what I was thinking :boom: love it. I'm not fussed on exposing the underlying array, we should be able to wing it so that people don't need this.\n. Anyone keen to give this puppy a review? It seems there are a bunch of tests in master that are also broken in this branch. Debugger displays missing etc - I fixed up those added in this PR. Apart from that. Keen for feedback :+1: \n. > we can refine the data we return to the user in the future based on what users would like.\n:+1: \n@shiftkey  ping... I'm happy with this now.\n. I don't mind grabbing this one - it's gotta be done.\n. All good yeah, they are kinda lame grunt work. I'll do em tonight :)\n. @shiftkey the tests in DebuggerDisplayOnModels now pass :+1: \n. This looks good to me @Haacked  :ship: it\n. @Haacked  Doh - that one slipped through the cracks :open_mouth:  My intention was to provide an overload. Any reason why you prefer extension methods?  Either is fine with me.\n. I'm convinced - Extension method it is :+1: \n. :heart: it\nWould it be worth rolling together the url formatting with the redirect?\nclient.Oauth.RedirectToLogin(request);\n\nI hear Rx is dead. \n\nIt's totally done for :laughing: \n. > That would require we add a reference to System.Web.\nAh, of course it would! :+1:\n. Good question! \nUsing versioned media types like application/vnd.github.v3+json are a great way for the API to stay backwards compatible between versions. Right now, Octokit.net only needs to support v3. It is foreseeable that when the API revs to v4 we would need to provide v4 types to serialize from and deserialize to.\nWith that in mind, I don't think we should openly invite people to change the Accept header because, as a client wrapper I think it is our job to provide client side compatibility between media types. \nWe could provide a way to amend the Accept header with text or html for example. Sorta like a mixed mode response. Octokit.net would always default to v3+json but allows you to specify an optional mode. \nBecause application/vnd.github.v3.html+json for example only add's an extra property body_html and does not remove or change the response structure beyond that, the client side remains compatible. \n. > We don't actually lock the version to v3 anywhere in the codebase, so I think that's something we can/should do in the short term to ensure consistency.\n\n:+1: \nabout letting the user specify the Accept header.\n\nThis should not be free form though. Perhaps as simple as an enum for each of the version3 types we support. Open to ideas. \nLike I said, because we are talking about media types within a version, each of these 'sub media types' only add extra properties to existing types. We can easily support this without creating a whole new set of types to deseralize onto.\n. They wouldn't need to be the same CLR property. Having three separate properties would be legit, if you specify a mixed mode media type, you know that you expect body_html to have a value. \n. Also that was the entire point of this change. My bad.\n. ",
    "SeanKilleen": "Bumping this because it's pretty old.\nI'm thinking it would make sense to close this in lieu of a new ticket referencing this and suggesting the documentation changes that came from @shiftkey's comment: https://github.com/octokit/octokit.net/issues/295#issuecomment-32185849\nLet me know if that's the right approach here; I'm happy to write up the new ticket.. I took a quick stab at this in #1530.. Given @shiftkey's last comments on this and that it's > 6 months old, should we close this out?. @shiftkey happy to write this up as I just used it and it seems pretty straightforward.\nDo you have a preference for where it should live in the docs? Wasn't sure if it makes sense to devote an entire markdown doc to it or to throw it into getting-started.md.. Bumping this; would be nice to actually get it in.\nFor the sake of merging this, could it make sense to use support@github.com for now and add a follow-up issue to add a more specific e-mail address when one is available? Seems like a quick win to get this in; plus, you know that someone will be manning the e-mail there.\nIf you want to give them the ability to filter, maybe using an e-mail trick like support+octokitnet+conduct@github.com could do what you're looking for? Would still go to support but they'd be able to route based on the to address.. I believe this was closed via #1489.. I believe this is now closed via #1501.. I'm using the GetLastApiInfo() as part of a quick console app I'm writing and can confirm it works as expected for me (null on first call, populated for subsequent calls).. @101shipit if you're creating a new instance of the client per request, the client likely won't ever have the \"last request\". May want to look at how many instances you're creating within your DI setup.. @101shipit so to make sure I understand, the issue is basically:\n| Action | GetLastApiInfo() Result | | \n| ------- | ------------------------- | - | \n| Non-search API call | null | \u2705 |\n| 2 non-search API calls | has result | \u2705 | \n| Search API call | null | \u2705 | \n| 2 search API calls | null | \u274c |\nIs that correct?. Annnnd nevermind -- it turns out the solution is to better read the contrib guide, which clearly mentions the powershell for the environment variables. Totally missed that somehow.\n. @ryangribble based on your review:\n\u2705 Added link to Github API\n\u2705 Added note on authenticated rate limits vs anonymous\n\u2705 Fixed the typo.\n\u2705 Updated the PR text/title to reflect the smaller scope you preferred\nThe build seems to be failing on Travis, but that seems unrelated since I didn't modify the build script. :). @ryangribble ready for review again at your leisure. Thanks for taking the time to be so thorough. And happy new year!. @ryangribble sounds good. I'll plan to tackle this in the following way: \n\nCreate a new Exception Inheriting from ForbiddenException\nModify Connection.cs to throw the new exception (with tests)\nAdd the Retry-After as a readonly field within the constructor based on the headers from the IResponse that are passed in.. @ryangribble any preferences on what to do if the Retry-After header isn't present or can't be parsed? We could default to a number, e.g. 60 seconds, or we could make the field a nullable int. \n\nFor now, will proceed with idea of a default value of 60 seconds.. Sure thing -- I'll make those adjustments.. Also, I added the failing test back. Normally my preference would have been to open a new PR against #1529 but this works fine too.. @ryangribble / @shiftkey ready for review at your leisure.. @ryangribble one thing I wanted to check on here. I see a build failure telling me to add an override for GetObjectData to the exception. I see that ApiException does this.\nHowever, AbuseException inherits from ForbiddenException, and ForbiddenException does not have this override, yet does not see this error on build.\nShould I:\n\nAdd overrides to both ForbiddenException and AbuseException as part of this PR?\nSuppress this warning and open an issue to fix later?\nSuppress this warning and fuggedaboudit?\nSomething else I'm not seeing?\n\nI noticed on the ApiException that it's marked as [SecurityCritical] so I didn't want to make any assumptions.. @ryangribble ahhh, I see. Thanks! This is likely due to the RetryAfterSeconds property, which makes sense. Will get that cleaned up ASAP and then it should be good to go.. @ryangribble changes have been made to present the value as a nullable int and default to null when it can't be parsed.. It appears the TravisCI build is failing on the XCode build job -- an error related to Octokit.StatisticsClient AFAIK.\nNot sure if this is transient or actually caused by something I did (it seems like the former).\nAdvice? Not sure I can kick off another build manually.. @ryangribble mind giving the code a second look? Should be much more compact now and the new test file has been re-organized (I left ConnectionTests in a similar state to as I found it, due to not wanting to arbitrate the conventions).\nI inverted some if statements which led to some negatives inside the ifs, but I don't think it compromised on clarity. (let me know if you differ).. @ryangribble OK, I think we should be good to go now? Give it another pass. . Oh, I can trigger it. :)\nStand by. I'll build & drop this into a project and send some screenshots / output.. @ryangribble OK, I:\n\nBuilt my branch locally using .\\build BuildApp \nI then referenced it directly from a project. \nI set up this project to create 10 actors in parallel issuing github requests for the same auth token, thus triggering the abuse mechanism after a short period.\n\n:white_check_mark: Here it is in the logs throwing the Octokit.AbuseException:\n\n\n\nThen I had the actor's supervisor detect an AbuseException and log out to the console the number of seconds before trying again.\n:white_check_mark: This shows that RetryAfterSeconds is performing as expected: \n\n\n. @ryangribble thanks for the guidance along the way! . \ud83d\udc4d Got it, makes sense. I'll put together a PR to un-skip this test and fix it via the decision here.. @ryangribble ready for your review.\n\nI couldn't think of too many more tests that needed adding, and ApiErrorMessageSafe is already covered by 50+ tests so I think we're good there. Happy to add any more if you think of them though. It's also a protected property so I couldn't test it directly, which was my original plan.. \ud83d\udc4d Great feedback; will do.. \ud83d\udc4d Nice catch, thanks.. Fixed.. This has been done.. @ryangribble done.. \ud83d\udc4d done.. @ryangribble sure, makes sense. I'll clean it up and compact it so you can take a second pass.. @ryangribble makes sense. I'll reformat. Sorry, should've paid more attention to the existing conventions. They tend to be my preference anyway; I think I was likely being hasty.. @ryangribble nice catch; fixed.. ",
    "KonradIT": "I am looking for a .xap file app of github somewhere in github, an official GH WP8 app.\n. @paulcbetts I use GitHub on my WP8 phone, and I can't edit the files, when I change to desktop view to edit files, the style.css fails and the \"commit changes\" button does not work\n. Hi. Does this mean that we will have a github WP8 app?\n. ",
    "ghost": "It's like populating a volume with enumerated objects, so if there's an arseload of clients in the GetAll, then it's going to take a while. This is going to be seriously looked at as, \"why are you querying me for how many I've got if you don't want to do anything to my contents\" and the program itself, were it sentient, would say you're wasting its time.\nIf ConnectionExtensions.GetPages then queries those attached to those clients, further delaying the purposeless process, then the \"Stay-Alive\" purpose behind this do-nothing call should probably be stated, somehow. It still has a value in keeping a connection alive; perhaps the mistake is in the definitions.\nKind of like relegating each program to it's own full-OS VM instead of assigning each app another username that has the option of messing up the base system. Ridiculous to fake at that point, when \"events\" return null; but only when simple TCP/IP services like pingback? (Y/N) then {verified} is easier than coming up with a whole new method that does fuck all.\nregards,\n-djm\nDate: Sun, 12 Jan 2014 21:51:34 -0800\nFrom: notifications@github.com\nTo: octokit.net@noreply.github.com\nSubject: Re: [octokit.net] Reactive client unit tests that do nothing (#300)\nTo actually work wouldn't they have to await the call to GetAll to make sure that it has time to run.\n[Fact]\npublic async Task RequestsCorrectUrl()\n{\n    var gitHubClient = Substitute.For();\n    var client = new ObservableEventsClient(gitHubClient);\n```\nawait client.GetAll();\ngitHubClient\n    .Connection\n    .Received(1)\n    .GetAsync>(new Uri(\"events\", UriKind.Relative), null, null);\n```\n}\nWhich then opens up Pandora's box with a whole horde of other issues. Now that the code actually\ngets called the NSubstitute object quickly fails as it returns nulls in places where they are not allowed.\nIn this case the first failure seems to be in ConnectionExtensions.GetPages but once that one is resolved there are more.\nIt seems to me that the most reliable option here might be to fake IResponse and IConnection.\nThe response requires a moderate amount of faking (BodyAsObject, ApiInfo.GetNextPageUrl() but GetNextPageUrl is also an extension method so we'd have to fake the ApiInfo rather than the method) while the connection requires less.\nThen build an actual GitHubClient using those. It starts to get quite tedious at this point and a lot of code for what seemingly should be simple tests.\nBeen messing around some and we should be able to build a \"FakeConnectionBuilder\" that would be able to take a starting url and a collection of items, then automatically build the fake responses and connection from that.\nA simpler option would just be to convert GetAndFlattenAllPages to an interface method rather than an extension method. Since that is what's making it so hard to fake. But at that point we're really just testing how GetAll does something and the tests will have to change whenever implementation does.\nUnless I'm missing something really obvious these are seeming more and more as if they'll be a real chore to test.\nHoping that I'm wrong.\nAnyway, it's now too late and my brain has stopped working.\n\u2014\nReply to this email directly or view it on GitHub.                  \n. Because it's easier\nOn Thu, May 5, 2016 at 6:19 AM, Radu Matei notifications@github.com wrote:\n\nWhat should be the course of action: adding a new property and modifying\nall references to it? (In this scenario, what happens with the old\nproperty?)\nOr renaming Keys to GitSshKeys directly?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/1253#issuecomment-217127810\n. It's an octodecimal hypermobius?\nOn May 14, 2016 8:21 AM, \"dimitrisTim\" notifications@github.com wrote:\nI am trying to get every file that has been changed in a repo, by every\ncommit. Then I store the files in a list, so that I can count how many\ntimes every file has been changed.\nCode:\nvar commitsAll = await client.Repository.Commit.GetAll (Owner, Name);\nforeach (var com in commitsAll) {\nvar commit = await client.Repository.Commit.Get (Owner, Name, com.Sha);\nvar files = commit.Files; //get changed files for every commit\nforeach (var f in files) {\nif (!fileNames.Contains (f.Filename))\nfileNames.Add (f.Filename); //add the filename in a list\nfileCounter [fileNames.IndexOf (f.Filename)]++;\nHowever, if the number of commits is high (let's say 1000), this method is\ntotally slow and useless. Any thoughts?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/1293\n. @ryangribble Thank you\n. @ryangribble Can I maybe invite you to my private repro can you give me a quick example on how to add credentials (personal access token) so I can download from my private repro\n. @shiftkey Thanks just what i'm looking for!\n. @shiftkey  Please see attachment is this best way to do token part?\nReleaseInfo.zip\n. @ryangribble Thank you so much.Its work. @ryangribble   I want to do that scenario from local cloned repository, Is there any way to that?. \n",
    "xkrt": "Public Gists (https://api.github.com/gists/public)\n. Yep, I forgot, 0.2.1 from NuGet.\n. ",
    "AndyCross": "I failed to update the RX component.\n. I thought similar; just wanted to make a small change to get started. I'll work on the basis you suggest.\n. I've refactored to a RepositoryClient.Hooks approach; I've also implemented GetHookById and will be adding in other methods (currently throwing NotImplementedException from the client). \nCan you feedback on the approach to the RepositoryClient.Hooks while I implement the others?\n. I have added further method implementations; \nI have a concern around the TEST method which requires a 0 byte body to be sent it seems; I've implemented this with an empty stub class as the Post body, which works in my production environment but please do review the implementation in terms of style.\n. Any further work required following git add snafu?\n. I've added a merge in from the upstream master, it pulled in some mono assembly that I had an issue with file copying (linking?) via the csproj, but that has been resolved now. \nHopefully this is now merge compatible.\n. @Haacked --c597449 fixes it up; the build.cmd now works locally.\n. Sure!\nSent from my Windows Phone\n\nFrom: John Du Hartmailto:notifications@github.com\nSent: \u00fd19/\u00fd05/\u00fd2014 20:17\nTo: octokit/octokit.netmailto:octokit.net@noreply.github.com\nCc: Andy Crossmailto:andy@elastacloud.com\nSubject: Re: [octokit.net] Implement Repository Hooks & Repository Forks (#313)\nCan I pick this up @AndyCrosshttps://github.com/AndyCross? I'd like to get this functionality in.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/pull/313#issuecomment-43544421.\n. #313 implements this\n. Very marginal given how lightweight that ctor is; I was following an example from a Readme method on RepoClient; but that is much more heavyweight. Happy to take your lead and refactor if req.\n. Cool, I'll pull out the lazy loading. Agreed on simplicity.\n-----Original Message-----\nFrom: \"Brendan Forster\" notifications@github.com\nSent: \u200e20/\u200e01/\u200e2014 19:08\nTo: \"octokit/octokit.net\" octokit.net@noreply.github.com\nCc: \"Andy Cross\" andy@elastacloud.com\nSubject: Re: [octokit.net] Implement Repository Hooks (#313)\nIn Octokit.Reactive/Clients/ObservableRepositoriesClient.cs:\n\n@@ -17,6 +18,8 @@ public ObservableRepositoriesClient(IGitHubClient client)\n             _client = client.Repository;\n             _connection = client.Connection;\n             CommitStatus = new ObservableCommitStatusClient(client);\n-            var apiConnection = new ApiConnection(_connection);\n-            _hooks = new Lazy( () => new RepositoryHooksClient(apiConnection));\n  This one? https://github.com/octokit/octokit.net/blob/7bfbb72379b155bf74d06f4d3855b4e1c4a46efa/Octokit/Models/Response/Readme.cs#L25\n  That's an edge case because we don't want to do the rendering until as late as possible. Let's keep it simple for the moment. \n  \u2014\n  Reply to this email directly or view it on GitHub.\n. It's not in this direct code path, instead handled however core api exceptions are. Unless i misunderstand you :)\n\n\nFrom: Brendan Forstermailto:notifications@github.com\nSent: \u00fd20/\u00fd01/\u00fd2014 19:12\nTo: octokit/octokit.netmailto:octokit.net@noreply.github.com\nCc: Andy Crossmailto:andy@elastacloud.com\nSubject: Re: [octokit.net] Implement Repository Hooks (#313)\nIn Octokit.Tests/Clients/RepositoryHooksClientTest.cs:\n\n\nclient.Hooks.Get(\"fake\", \"repo\");\n  +\nconnection.Received().GetAll(Arg.Is(u => u.ToString() == \"repos/fake/repo/hooks\"));\n}\n  +\n[Fact]\npublic async Task EnsuresNonNullArguments()\n{\nvar client = new RepositoriesClient(Substitute.For());\n  +\nawait AssertEx.Throws(async () => await client.Hooks.Get(null, \"name\"));\nawait AssertEx.Throws(async () => await client.Hooks.Get(\"owner\", null));\n}\n}\n  +\npublic class TheGetByIdMethod\n\n\nWhat about a test here that we surface a NotFoundException when the id does not exist in the repo?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/pull/313/files#r9014830.\n. I'll write the test in the AM (I'm GMT) so +07:00 offset. Honestly, I can't see the value now but hope the test writing will show me your thinking. Currently I can only see mocking out an exception throw to see that the client throws the exception, which is testing only nSubstitute. However it's 22:35, I'm stacked up on stuff for tonight and I'd rather write the code tomorrow than argue ;-)\nThanks for the peer review so far <3\n\nFrom: Brendan Forster notifications@github.com\nSent: 20 January 2014 22:30\nTo: octokit/octokit.net\nCc: Andy Cross\nSubject: Re: [octokit.net] Implement Repository Hooks (#313)\nIn Octokit.Tests/Clients/RepositoryHooksClientTest.cs:\n\n\nclient.Hooks.Get(\"fake\", \"repo\");\n  +\nconnection.Received().GetAll(Arg.Is(u => u.ToString() == \"repos/fake/repo/hooks\"));\n}\n  +\n[Fact]\npublic async Task EnsuresNonNullArguments()\n{\nvar client = new RepositoriesClient(Substitute.For());\n  +\nawait AssertEx.Throws(async () => await client.Hooks.Get(null, \"name\"));\nawait AssertEx.Throws(async () => await client.Hooks.Get(\"owner\", null));\n}\n}\n  +\npublic class TheGetByIdMethod\n\n\nIt's not in this direct code path, instead handled however core api exceptions are\nFair, but still a good thing to check that this client is behaving consistently, right?\n\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/pull/313/files#r9020872.\n. I'll refactor when I remove the Lazy\n\nFrom: Brendan Forster notifications@github.com\nSent: 20 January 2014 23:01\nTo: octokit/octokit.net\nCc: Andy Cross\nSubject: Re: [octokit.net] Implement Repository Hooks (#313)\nIn Octokit.Reactive/Clients/ObservableRepositoriesClient.cs:\n\n@@ -108,5 +111,14 @@ public IObservable GetReadmeHtml(string owner, string name)\n         }\npublic IObservableCommitStatusClient CommitStatus { get; private set; }\n-        Lazy _hooks;\n  +\n-        /// \n\n/// Gets a client for GitHub's Repository Hooks\n\n/// \n\n\npublic IRepositoryHooksClient Hooks\n\n\n\nThis should be returning an IObservableRepositoryHooksClient to match the interface\n\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/pull/313/files#r9021747.\n. ",
    "johnduhart": "Can I pick this up @AndyCross? I'd like to get this functionality in.\n. > Have each test only create the parts of the world it needs and not clean up the world.\nThis is no good either as it could lead to unintentional contamination between tests.\n. Huh? Was this PR an accident?\n. That PR was never completed. If you want you can pick up where I left off at #495 \n. ",
    "dsplaisted": "I don't think that you absolutely have to supply an implementation of the abstraction on all the platforms you support.  On other platforms you can require the user to supply the implementation of the abstraction if needed.  Certainly it would be nice if you did it for all platforms, but better to have an in-the-box implementation in just WinStore than none at all.\nI think it would be great to have a library that supplied a portable way of doing OAuth.  Maybe this could go in https://github.com/paulcbetts/splat, or it could be its own thing.\nHere's a great post on how to deal with this kind of stuff: http://blog.stephencleary.com/2012/11/portable-class-library-enlightenment.html\n. OK, debugging a bit more, it looks like the issue is I'm actually searching the adamcaudill/Psychson.  The web interface redirects this to brandonlw/Psychson, but the API is giving the failure I describe.  Is there a way via the API to check if the user (or repo) ID has been changed?\n. OctoKit is setting AllowAutoRedirect to false on the HttpMessageHandler, and then wrapping it with another handler which handles the redirection explicitly.\nIt appears that RedirectHandler is causing the problem somehow.  If I set AllowAutoRedirect to true and remove the RedirectHandler, the problem goes away.\nWhat's the reason for using RedirectHandler instead of using the built-in redirection handling?\n. ",
    "sgwill": "The #386 pull request should close this issue.\n. Thanks! Will do.\n. I updated the Test to be clearer, and added the DebuggerDisplay attribute just on Feed. I'll wait for the _link pull request https://github.com/octokit/octokit.net/pull/387, then fix _link.\n. Now that https://github.com/octokit/octokit.net/pull/387 is closed I was able to fix the _links name. Should be all set.\n. Could have some guidance with DebuggerDisplay messages? What sort of messages would you like to see for objects like FeedLinks? It seems there are too many links to be able to display well in the debugger.\n. Yikes! Good catch.\n. ",
    "thedillonb": "I've taken a crack at these in #558 \n. Is this still being worked on?\n. Sweet! Any reason why the CI build seems to always fail? I've submitted a few PR, this being the more complex, but they all seemed to have failed\n. Done! \n. Thanks for the review @shiftkey! I hope my comments make sense. I'm only adamant about the PATCH stuff because when I created CodeHub for iOS I found that if the fields were not completely nullable then I had to make a initial request to get the data so that I could set the non-nullable fields on the update request. This meant longer waiting for people whos internet connection was not up to snuff so I'm trying to avoid those issues here as I move all my code from (https://github.com/thedillonb/GitHubSharp) which I wrote when there was no official .NET client, to this repository.\n. @Haacked @shiftkey, Hey guys, with the new release 0.7 it looks like the changes I made to the IssueUpdate were reverted (f3d4b751cc7c255748c972a19b76467f0a50f39f - I think). With the reversion, it looks like you are unable to set the Labels to null, which as we discussed above, prevents you from not modifying that field during the PATCH. E.g. You either have to know what the labels were set to previously, or you'll end up unsetting them all (empty array = no labels)\n. @shiftkey, It's all good. Just wanted to make sure someone was aware of it. Let me know if there's any way I can assist.\n. @shiftkey I agree with you 100% about hiding away the HTTP plumbing and I do like how the GetReadmeHtml is implemented vs the GetReadme, especially since they return different data structures.\nI guess what my real question was is regarding how, if at all, this can be applied to something like the comments of commits, pull requests, etc... since body_html or body_text fields come and go based on the media type where (on which objects) do you stick these members?\nFor example, \n1. Do you take existing response objects like CommitComment and stick in a \"BodyHtml\" member which may or may not get filled based on what the media type is? Perhaps the GetComment method has another parameter withHtml which triggers the media switch from json to json+html.\n2. Do you mimic what GetReadme has done and create a whole new function GetCommentHtml which returns a CommitCommentHtml object which inherits from CommitComment and adds the \"BodyHtml\" memeber.\n. Haha, yeah I just caught that too.\n. I forgot I tied the pull request to this issue so it closed it without discussion about the second part of this issue. @shiftkey, do you have any suggestion about the second paragraph in the issue? Should I throw this into a new issue for discussion? I'd rather not opent his back up just for a discussion.\n. > But having that field hang around might be confusing.\nVery true, however, and maybe these are mistakes that will be fixed in the future, there exists response objects, such as GitReference or GitHubCommit which seem to have properties that are unused (null) or populated based on which request was used. \n. Actually, the more I think about it I think you're right to avoid fields that don't belong there - if nothing else than to avoid confusion. Although, this means we might have a greater number of permutation of some models, especially when media-types are introduced. \nThe discussion on #593 seems to have ended with the idea that we could just put all potential fields into the model and allow some to be null/populated based on which media-type is chosen. However, we might want to revist that...\n. You're right. Although, while this discussion is a specific one around the IssueEvent and EventInfo objects my ultimiate goal was to determine the answer to the following:\n\nGiven a request, should you have properties in the response object that are always null (unused)?\n\nIf the answer is no then it justifies keeping IssueEvent and EventInfo seperate because even though they differ by the Issue field it still means that I'm not reusing a response DTO which when I make request A it populates Issue and when I make request B it does not.\nIt also means that each media-type must have a seperate response object for that media-type (and thus, a seperate method call e.g. GetCommentsHtml vs GetCommentsText, etc..). Because I can't put Body, BodyHtml and BodyText in the Comment response model because given a certain media-type some of those properties will always be null. (Also, the 'full' media-type populates a BodyHtml and BodyText (and I think the regular Body) which  means I can't juse reuse a single Body field)\nIf the answer is yes then it means we should be able to save ourselves different permutations of the same response model and put properties that can sometimes be unused. That would then suggest we should be able to combine IssueEvent and EventInfo since it's OK that sometimes the Issue property is populated and sometimes its not.\nThe answer to this question actually solves #593.\n. I should state, so I don't look like an idiot whos just making changes and not testing them, that I am testing the changes with other projects.\n. I just upgraded to the 0.7.0 release and started seeing this issue. I am (apparently) running Mono 3.12.0 but still seeing this issue.\n\n```\nusing System;\nusing Octokit;\nusing Octokit.Internal;\nnamespace TestOctokit\n{\n    class MainClass\n    {\n        public static void Main (string[] args)\n        {\n            var cr = new Credentials(/ REDACTED /);\n            var client = new GitHubClient(new ProductHeaderValue(\"CodeHub\"), new InMemoryCredentialStore(cr));\n            var notification = client.Notification.GetAllForCurrent();\n            notification.Wait();\n            Console.WriteLine(notification.Result);\n        }\n    }\n}\n```\nIs the code I used to generate this\n. @shiftkey, I just ran your repro code without problem on my setup. Perhaps this is a different issue?\nI just build the project from master, created a dummy console project and referenced the Octokit-Portable.dll - no Issue. If I reference the Octokit-Mono.dll then I have a bad time :-1: \n. Looks like it has been fixed in Mono master.\n@akoeplinger, in your example above where you are just using two Add calls, what is the type of request.Headers? Isn't it a Dictionary<string, string> thus arn't you just overriding the first with the second?\nI'm getting away with just request.Headers[\"Accept\"] = \"application/vnd.github.v3+json; charset=utf-8\"; in a custom IHttpClient implementation for now.\n. With the portable version out, is there even a need for the Monotouch/Monoandroid versions? Attempting to track down my issue with the Invalid Format exception I accidently opened the XamarinStudio solution. But I'm not sure that it's even needed anymore?\n. @shiftkey, sounds good to me!\n. I'd also be pretty interested to hear what any experts have to suggest. I've been using the portable version and having had any issue. \n. Prepare to laugh as I found an easy way around this by abusing some objects. Basically just inherited the HttpClientAdapter, made those methods public so I could build the request/response, and referenced that.\n```\n    public class OctokitModernHttpClient : IHttpClient\n    {\n        private readonly MessageBuilder _messageBuilder = new MessageBuilder();\n    /// <summary>\n    /// Sends the specified request and returns a response.\n    /// </summary>\n    /// <param name=\"request\">A <see cref=\"IRequest\"/> that represents the HTTP request</param>\n    /// <param name=\"cancellationToken\">Used to cancel the request</param>\n    /// <returns>A <see cref=\"Task\" /> of <see cref=\"IResponse\"/></returns>\n    public async Task<IResponse> Send(IRequest request, CancellationToken cancellationToken)\n    {\n        if (request == null)\n            throw new ArgumentNullException(\"request\");\n\n        var httpOptions = new NativeMessageHandler\n        {\n            AllowAutoRedirect = request.AllowAutoRedirect\n        };\n        if (httpOptions.SupportsAutomaticDecompression)\n        {\n            httpOptions.AutomaticDecompression = DecompressionMethods.GZip | DecompressionMethods.Deflate;\n        }\n\n        var http = new HttpClient(httpOptions)\n        {\n            BaseAddress = request.BaseAddress,\n            Timeout = request.Timeout\n        };\n        using (var requestMessage = _messageBuilder.BuildRequestMessage(request))\n        {\n            // Make the request\n            var responseMessage = await http.SendAsync(requestMessage, HttpCompletionOption.ResponseContentRead, cancellationToken)\n                .ConfigureAwait(false);\n            return await _messageBuilder.BuildResponse(responseMessage).ConfigureAwait(false);\n        }\n    }\n\n    /// <summary>\n    /// This class' only purpose is so I can call the helper methods.\n    /// </summary>\n    private class MessageBuilder : HttpClientAdapter\n    {\n        public new HttpRequestMessage BuildRequestMessage(IRequest request)\n        {\n            return base.BuildRequestMessage(request);\n        }\n\n        public new Task<IResponse> BuildResponse(HttpResponseMessage responseMessage)\n        {\n            return base.BuildResponse(responseMessage);\n        }\n    }\n}\n\n```\n. I can definitely come up with a PR. My two big use cases for toying around with the IHttpClient are:\n- Instantiate a different HttpClient Handler (in this cause it's the ModernHttpClient)\n- Utilize an on-disk caching via Akavache which means the IResponse object should be in one way shape or form available for serialization and if not, it should be easy to persist the object in another class and then reform the IResponse object after deserialization.\nI think this will be relatively easy as much of the logic is all right there but just needs a visability change or  adjustment to make it slightly more flexable. Either way, I'll post a PR soon.\n. As a consumer of this library, literally anything than what is currently being done now would be preferable. Not having access to the raw JSON payload for all of the unimplemented activity types means that I need to resort to executing a raw request and parse into my own types - which is really unfortunate. The addition of this change would be really helpful.  . As @ryangribble pointed out, this is unnecessary if you use the overloads of GetAllContentsByRef which drop the path and default to the root dir.. I figured the tests would fail. Regardless, just wanted to throw something up to get discussion moving on this. Either we allow empty strings to be passed as \"paths\" or we allow \"/\" to be passed and alter the logic following the format of the URL to prevent a double slash.. @ryangribble well thats embarrassing. Good point. Didn't think to consider the other overloads. Those will do. I'll close the PR and issue. Thanks for pointing that out. . Ah yeah, I must'a blacked out or something. I'll remove that guy.\n. The PATCH verb is a tricky beast. Based on the nature of the PATCH  verb I believe it quite reasonable to have all fields nullable (unless the documentation states required) so that it may adhere to the PATCh standard (https://developer.github.com/v3/#http-verbs):\n\nUsed for updating resources with partial JSON data. For instance, an Issue resource has title and body attributes. A PATCH request may accept one or more of the attributes to update the resource.\n\nIt's not necessarily that a value must be true or false because in a PATCH request a null (or absence of a value/field) is a reasonable request as well. For example: If this was still a non-nullable field it would mean that the serialize would serialize the value whether you set it or not. However, this is not desirable. I, as a user, don't want to be forced in sending data that I don't want to change. This means that if I wanted to update the title of the Release I must also know the previous state of the \"Draft\" field so that I may maintain it's value.\n. This follows the other comment I made about the importance that the PATCH model object be completely nullable with the exception of the required fields. In this case, there is a drastic difference between the labels field being null and it being an empty list. For example: If I want to change the title of an issue and only the title when I instantiate this IssueUpdate model it automatically sets the Labels to an empty list. When I send the request, the serializer will serialize the request as:\n{\"Name\": \"New Name\", \"Labels\": []}\nwhich GitHub will interpret as \"i want this issue to have no labels\". However, what really should have happened is that, because the \"Labels\" was null, the serialize did not serialize the field:\n{\"Name\": \"New Name\"}\nand thus GitHub did not modify the Labels resource on the other side and only modified the title.\n. Whoa, that's pretty cool. I didn't even think you could enforce something like that. Very cool!\n. That's embarrassing. Fixed in latest commit.. ",
    "phantomtypist": "I started working on this issue and ran into something I wanted your feedback on.\nI am implementing the \"Get Team\" part of the API.  In the Octokit.ApiUrls class, there is already a method called \"TeamsUpdateOrDelete\".  The Uri for getting a team is also the same Uri as updating and deleting a team.  I'd rather not reference the method \"TeamsUpdateOrDelete\" in the TeamsClient.Get method I am implementing as I think it would cause confusion later on.\nI came up with two options and wanted your opinions on them or if you think a better approach is available:\n- Rename the \"TeamsUpdateOrDelete\" method to \"Team\"\n- Create a new \"GetTeam\" or \"Team\" method.  Now granted, doing it this way would introduce two methods that retrieve the same Uri.  I'm not sure how I feel about this option.\nI was leaning more towards option 1, but I defer to you now rather than later in the PR.\nThanks.\n@alfhenrik @Haacked \n. Would you guys prefer something like this method renaming be done in a PR separate from the new features in issue 331?\n. Thanks!\n. So I finished working on the first part of this issue that \"gets a team\".  Everything in the build.cmd script works fine except for when I run the integration tests.  FYI, I created a \"test\" GitHub account and added the username and password as Environment variables on my Windows machine.\nThere seem to be a bunch of them failing that don't seem related to the teams stuff I worked on.\nFor example:\n- PullRequestsClientTests.CanBeMerged [FAIL] > Octokit.ApiException : Pull Request is not mergeable.\nI forked from the master branch of Octokit.NET.  I had an assumption that everything would work, but maybe I did something wrong?  None of the files generating the integration errors had changes in any of my commits.\nDoes this sound like I'm doing something wrong?\n. Ok.  Sorry to keep bugging your team, but this is my first time contributing to this project.\nIs it okay to do a PR for just the first bullet on this issue or would you like me to complete the entire issue?\n. I noticed that one of the clients OrganizationsClient has xUnit tests in Octokit.Tests, but no integration tests in Octokit.Tests.Integration.\nI made a test class in Octokit.Tests to pass the build script.  Did you want or require me to create integration tests for the Teams code I'm working on in this issue?\n. I'll do the integration tests in a separate PR down the road.\n. YES!  I've been spending too much time renovating my house.  I'll continue working on the PR this long weekend.\n. I'm not looking forward to updating the repo in the PR tonight @Haacked \nThis is what happens when you neglect things ;)\n. :disappointed: AppVeyor build fails because private repo quota exceeded in test account.\n. @shiftkey Yep, unit tests coming.\n. LOL.\nThis is an issue on another public project I try to help with.\nLet me throw this idea out there that I've been toying around with.  (Disclaimer: I've seen the idea on a few projects so it's not an original idea.)\nWhat if we were to set up the build server to generate two different sets of assemblies, one Strong-Name signed and one not signed?  As a byproduct it would also generate two sets of NuGet packages.  The unsigned NuGet package would continue to have the same name.  The signed NuGet package would be named something along the lines of \"Octokit-Signed\".\nThe one downside to introducing signed assemblies, only, is that it could lead to assembly version redirect issues for end-users.  log4net ran into this issue and got a little backlash from it.\nI'd like to think it makes people on both sides of the fence happy.  Thoughts?\n\n. @Haacked, I do agree that two NuGet packages are a bad idea.  That's why the other project I'm involved in hasn't proceeded in any direction yet.\nFreezing the assembly versions would work to resolve the binding redirect (I forgot the name for that) problems.  I can't think of any downside to this off the top of my mind, but can you think of any?\n. +1 @davidfowl \n\nI'm going to suggest something radical because it's 2 AM and I should be sleeping. Everyone in the .NET OSS community should just stop strong naming everything. This will have network effects and eventually the GAC and strong naming in general will die on its own :smile:\nSomebody should make a logo for this movement.\n\n+1 @mythz \n\nEventually I've had to add support for strong naming in ServiceStack v4 as it's a popular requested feature of ServiceStack's enterprise customers who wish to use it in enterprise products (e.g. SharePoint) that mandate it. But as I didn't want to burden the majority of the user-base (myself included) who don't want it, I've added a parallel track of Signed packages with a .Signed suffix \n\nI originally said that just having a separate NuGet package that is SN'd  would make everyone happy.  It satisfies both parties on the opposite sides of the fence until strong naming is removed from .NET.\n. Really, if we had a second NuGet package that is SN'd for the people that need it, we wouldn't be here arguing and all this time spent could be used doing better things.  When the day comes that SN'ing is removed from .NET, then you can deprecate that NuGet package.\n. True.  I guess it should be assumed it can happen in any of the API methods.\n. What are your thoughts if I add an exception tag for ApiValidationException on this method?\nIt would be raised if someone tried adding an organization as a member to the team (https://developer.github.com/v3/orgs/teams/#add-team-member)\n. ",
    "haagenson": "This can be closed now.  I completed the outstanding item in #529 \n. On large test suites like this in the past where setting up was important, I've seen and used \"the world\" caching.  Essentially, a test creates something if it needs it and then caches it.  The cache is checked before each test's data setup to see if it was already cached during that test session.  I've only used this with the built in mstest, but it might work with xunit as well?\n. This was implemented on #529 and merged yesterday.\n. That's perfect @shiftkey.  I've got the project up and running with VS 2013 without any hitches so far.  I'll be perusing the open issues as I learn the code base.  Hopefully soon I'll have a pull request for some minor changes just to get that process under my belt.\n. @johnduhart well that makes it pretty simple then.  That leaves the review of array notation and the deserialize as the key stuff left to look over.\n. Looking over the array notation that I used, I'm not sure that needs to change.  All of the array index accessors are in positive result test methods.  I'm still waiting for review of the changes to the SimpleJSON class from that repository.  Assuming that is accepted, this is probably ready for being accepted as well, unless someone else sees something I'm missing.\n. @shiftkey @Haacked In regards to this Pull Request and Item #439.  I've been looking pretty heavily at the GitHub API and the typical patterns for the URI.  #439 shows an example when an array is returned.  Looking at that GET request however, it should return an array, even if there is a single object, and the GitHub API does just that.\nThe only time an object is returned is when the reference matches an endpoint, such as a branch commit when doing refs/heads/master or a specific pull commit refs/pull/507/head or other similar items.  However, when not at an endpoint, an array is returned refs/heads even if there is a single object being returned.\nAfter looking into this much more closely, I think we should close this Issue and #439 without any changes.  I'd like to have your opinions, and anyone else's, for that matter.\n. I believe this is ready to be merged.  I completed the implementations for GetAll and Get.  I also created a number of unit tests.  The AppVeyor build is failing, but it isn't due to any of the changes in my change set I believe.\n@shiftkey / @Haacked \nCan you guys take a look?\nThanks\n. just finished with the cleanup and merging master back to my branches\nthis should be ready assuming the build (mostly) passes\n. Added a pull request to the Simple JSON Project as well at facebook-csharp-sdk/simple-json#63 for the deserialization changes I made to SimpleJSON.cs\n. ",
    "farezv": "Nobody is working on this right? Can I start with this issue? I'm completely new to the project though. Would starting a new [WIP] PR with questions/concerns be the best approach? Thoughts @shiftkey & @Haacked? \n. Looking to jump-in and noticed this issue may have been solved with #550. Does this need to be closed @shiftkey?\n. ",
    "kdrvn": "Aren't those implemented under the ISshKeysClient?\n. ",
    "tbondy760": "Or perhaps not. Cannot publish my branch. Contributing does not seem as straightforward as https://github.com/octokit/octokit.net/blob/master/CONTRIBUTING.md leads one to believe. Sigh!\n. K. I see it now - I must have missed that the first time in  guidelines for contributing\n\nPush your changes to a topic branch in your fork *of the repository.\n\nI'm very new at this.\n. ",
    "nigel-sampson": "Done\n. Whoops, sorted\n. I have a naive implementation of the discussed approach at https://github.com/nigel-sampson/octokit.caching\n. No, I'm posting to the GitHub API directly. By changing the accepts header I can post the markdown, and when getting issues get both the markdown and html in one request.\nIn the above code I'm making use of the Octokit connection and parsing etc but need to send the custom accepts header. \nHowever some of the underlying methods for Patch and Get don't expose an overload that takes accepts.\n. Done :-)\n. I'm just using the repository search so it's not against any particular repository. \nThe line that's failing is https://github.com/octokit/octokit.net/blob/master/Octokit/SimpleJson.cs#L1444\nReflectionUtils.IsTypeGenericeCollectionInterface(type) is returning true in a Net45 app and false in NetCore45\n. It looks like the problem is ultimately caused by SIMPLE_JSON_READONLY_COLLECTIONS not being defined on Octokit NetCore45\n. Something is still weird here, testing from source confirms the bug is resolved. However using Octokit from nuget (version 0.3.2) the bug is still occurring. Checking the assembly in dotPeek shows that it wasn't compiled with the flag SIMPLE_JSON_READONLY_COLLECTIONS\n. of course, I'm an idiot :-/\n. @shiftkey just tested a release build for win8 with no worries.\nthanks again\n. I created a naive implementation of the latter solution by creating a custom http client https://github.com/nigel-sampson/octokit.caching\n. Given my code the new overload wouldn't matter but I imagine it could be helpful to other people. It's enough for me to know this intended behaviour.\nAm curious why we treat Labels different and leave as (null / no change) but don't do the same for the others such as Body? (unless that behaviour has changed as well).\n. Yeah I just discovered the IssueUpdate.Milestone null vs new int?().\nThanks\n. ",
    "darrelmiller": "If you plug in Tavis.HttpCache it will transparently take advantage of Etags/LastModified assuming you allow the response to be privately cached.  It will automatically convert a GET into a conditional if the cached response is stale and will serve the response from the cache if a 304 comes back.\n. @niik The problem with the Wininet cache is that it is fairly broken when it comes to Etags and freshness.  Once a representation becomes stale, any future 304s with new freshness information fail to update the freshness of the cached representation, so from that point on, every request goes back to the server.\nI wrote a replacement for Wininet that plugs into HttpClient here https://github.com/tavis-software/Tavis.PrivateCache and I started to integrate with Octokit, but haven't had chance to work on it recently.\n. @Haacked I provided repro code and full details here http://stackoverflow.com/questions/20925934/why-is-this-304-response-not-updating-the-freshness-of-the-locally-cached-resour\n@grumpydev has confirmed that he experienced the same behaviour.  IE does not have the same problem with WinInet cache, so I'm guessing the issue is somewhere between HttpWebRequest and WinINetCache.\n. I am happy to help in any way I can.  My recent blog post on the Vary header (http://bizcoder.com/the-insanity-of-the-vary-header) was my first step to fixing the current vary implementation and the next major task is do a persistent storage mechanism.  The current implementation is only an in-memory store.\n. Oh, where oh where are the other 48 hours I need in a day.\n\n. Yesterday I did a major update to my HTTPCache to fix the problems with the way the vary header is handled.  I also renamed it because how it can handle being a shared cache too!  This also caused a change to the storage interface.  Next step is to produce a persistent storage mechanism.\n. @shiftkey Much easier.  Adding my cache would look pretty much exactly like you showed it in the example.\n. @thedillonb Should be straightforward to use a different HttpClientHandler with the changes in https://github.com/octokit/octokit.net/pull/808\n. Regarding the redirect issue, I've been using this https://gist.github.com/darrelmiller/a3baeb6976acd9f23243 in one of my client applications to replace the autoredirect done by HttpWebRequest.  It could use some love, but it might be an ok starting point.\n. @shiftkey  Take a look at this and let me know what you think https://github.com/darrelmiller/octokit.net/commit/e5d7d6e5f0990202cbd9677843620485c046229a\nI'm having trouble getting the tests to run at the moment, so it isn't tested.  Just consider it an idea.\nI optionally allow passing in a HttpMessageHandler into HttpClientAdapter.  I store a HttpClient instance as a field and reuse it.  \nIn order to allow auto redirects to be turned on and off, I use the HttpRequestMessage.Properties collection to relay the setting to the new redirect message handler.\n. I like the fact that your proposed GitHubClient extensibility model mirrors the standard HttpClient model.  It hides all the IHttpClient, IConnection, HttpClientAdapter stuff from someone who just wants to plug in an extra piece of middleware.\n. I just noticed the RedirectHandler CopyResult uses a .Result.  That's because I pulled the code from a .net 4.0 project.  It should probably be fixed to use async/await.  I'd do it but I'm not sure how to add a commit to a PR.\n. 1) I'm not doing redirect counting to limit redirects.  I can fix that.\n2) I'm not checking host before copying auth header.  I can fix that.\n3) Currently I change the method on a 301 or 302 because it is allowed.  Changing the behaviour to not change the method is easy enough.\n. I have done all the fixes to the RedirectHandler and added a bunch of tests for it.  However, I have absolutely no @!#$@#$ clue how to push the changes up to anywhere on Github.\nI pulled down the pr/808 branch and made the changes there, but am unable to push that branch with the fixes to my fork.\n\n. @shiftkey I don't really know how.  But I succeeded in pushing my changes to my fork.  https://github.com/darrelmiller/octokit.net/commit/cf9c84506454013a007bc10db53a6bd9dd5a5a75\n. Couple of comments:  \nThe 301 and 302 behaviour is now different to what HttpWebRequest does by default.  But the new behaviour is what was originally intended for 301/302. (Possibly the most useful diagram I have ever seen on this subject is here https://tools.ietf.org/html/rfc7238#section-1)\nKeeping the auth header around based on host is consistent with what the .Net CredentialCache does.  However, based on my interpretation of the HTTP specs, it should really be based on the realm.  Which would require a 401 dance to find out the new realm.  I would file this under \"nice idea in theory but no-one does it\".  The pedant in me felt the need to mention it.\n. :+1: \n. Just one observation that would probably have been much more useful before we started all this.\nIf you are actually using the CredentialCache with credentials associated to the correct origin server, then when you redirect to a URL with the same host then the credentials are carried over.  Using a credential cache avoids setting creds in a default header and takes care of applying the correct credentials on every request.   \nMaybe it shouldn't be the responsibility of redirection code to be carrying over the authorization header.\n. Funny you should mention that, but I just finished writing an AuthenticationService/HttpCredentialCache that plugs into the message handler pipeline.  It's not on Github yet though.\n. This is a known issue with redirects.  There is a PR in the works to fix this issue #808\n. It felt like a nice feature to have, but I'm struggling to think of a scenario where I would actually need it.\n. I think this would only fail if someone pre-filled the property with a value that cannot be cast to an int.  A value is assigned to the property when it is initially created, right after this If ends. \n. ",
    "vktr": "@Haacked, certainly - sorry for the six month delay. I've fixed the method arguments, updated the IObservableOrganizationsClient and did other small things to make the build and tests pass.\nHowever, the AppVeyor fails with the error \"Specify which project or solution file to use because the folder contains more than one project or solution file.\". Is this an error on my end?\n. :+1:\nIt looks good. I noticed you mention the integration tests in the readme but maybe it's good to do it in the contributing guidelines as well?\n. ",
    "lsinger": "A common sentiment I hear from developers who want to help in open source is that they simply don't know where to start. They say they're missing two things: a) pointers to how the code is organized and b) pointers to areas that could use help the most / have the most obvious low-hanging fruit that could get a novice started. \n. ",
    "nulltoken": ":+1::bomb::boom::fire:\nStrangely qed build 673 doesn't appear in the recent builds lists. Caching issue?\n/cc @half-ogre \n. Shouldn't it be Updates a pull request..``?\n. As thePullRequestUpdatealready bears the issue number, couldn't we drop this parameter?\n. However, going down this road may require to updateMergePullRequestso that it also bears a number.\n. > perhapsNumber` should be removed instead...\n:+1:\n. Maybe Updates... here as well?\n. ZOMG! A missing trailing newline :trollface: \n. Shouldn't this be pluralized?\n. Maybe here as well?\n. E_TOOMANYSPACES\n. Linus is crying... :trolleybus: \n. ",
    "erangeljr": "Hello @ammeep Do you know what links you want to be returned. I've found a few related to billing/account management and making a private repo a public one on the Help Site. Is there something more specific you're envisioning. Thanks. \n. Hmmm... @shiftkey I was testing using a different method as a starting point. Thanks for the input. \nI added the assert not null to the retrieve asset and pushed my commit up. \n. ",
    "elbaloo": "Still wanted?\n. Want some help here? What is missing?\n. I'm trying to figure out why these two new exceptions don't inherit from ApiException... isn't it desirable? Noticed it while working on the integration tests since they don't have ApiError member.\n. Worked a bit on this on #931.\n\nNo idea where to document this tho.\n. @shiftkey I agree.\nI think the best is to leave and close this and #819 for history and I'll reference them in a new PR.\n. Rebased and submitted via #934.\n. Could it be that StandardAjaxv0.1.2-df225a37-acb9-4e02-acc6-a517a88956d2 is\nprivate? If so, does the token have that scope?\n\nvrce\nOn Oct 9, 2015 8:08 PM, \"Ronny Chan\" notifications@github.com wrote:\n\nSure, here is the request\nPOST https://api.github.com/repos/SnowflakePowered-Packages/snowball-packages/pulls HTTP/1.1\nAccept: application/vnd.github.quicksilver-preview+json; charset=utf-8, application/vnd.github.v3+json; charset=utf-8\nUser-Agent: snowball (Win32NT 6.2.9200; amd64; en-CA; Octokit 0.16.0)\nAuthorization: Token [Redacted]\nContent-Type: application/x-www-form-urlencoded; charset=utf-8\nHost: api.github.com\nContent-Length: 134\nExpect: 100-continue\nAccept-Encoding: gzip, deflate\n{\"title\":\"Add Plugin StandardAjax v0.1.2\",\"base\":\"master\",\"head\":\"RonnChyran:StandardAjaxv0.1.2-df225a37-acb9-4e02-acc6-a517a88956d2\"}\nAnd here is the response\nHTTP/1.1 404 Not Found\nServer: GitHub.com\nDate: Sat, 10 Oct 2015 01:02:21 GMT\nContent-Type: application/json; charset=utf-8\nStatus: 404 Not Found\nX-RateLimit-Limit: 5000\nX-RateLimit-Remaining: 4964\nX-RateLimit-Reset: 1444439859\nX-OAuth-Scopes: public_repo, repo:status, repo, user, repo_deployment\nX-Accepted-OAuth-Scopes:\nX-OAuth-Client-Id: [Redacted]\nX-GitHub-Media-Type: github.v3; param=quicksilver-preview; format=json\nX-XSS-Protection: 1; mode=block\nX-Frame-Options: deny\nContent-Security-Policy: default-src 'none'\nAccess-Control-Allow-Credentials: true\nAccess-Control-Expose-Headers: ETag, Link, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval\nAccess-Control-Allow-Origin: *\nX-GitHub-Request-Id: D83A5B09:161C9:31899DC:5618639D\nStrict-Transport-Security: max-age=31536000; includeSubdomains; preload\nX-Content-Type-Options: nosniff\nContent-Length: 106\n{\"message\":\"Not Found\",\"documentation_url\":\"https://developer.github.com/v3/pulls/#create-a-pull-request\"}\nSource code for what I'm trying to do is here\nhttps://github.com/RonnChyran/snowflake/blob/4baaacd0b223965c59a2299aada8005862a2d9f7/Snowflake.Packaging/Publishing/PublishActions.cs#L116\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/932#issuecomment-147019486\n.\n. Disregard my previous comment. That's a branch not a repo and scopes are in the response anyway... It's late, I'm going to bed xD\n. @Haacked / @shiftkey let me know if this looks ok.\nbtw, I changed the messages to be those that the github api returns.\n. This can be closed.\n. \n",
    "trsneed": "Everything builds and tests fine without it. I just wanted to minimize my warning footprint. 8bbf2bf can be rolled back or not merged. Whichever is easier. \n. I need a bit of guidance on item 5 I have gone down the rabbit hole on both and think I like implementing a solution that has a separate portable nuget package, instead of trying to manhandle the nuspec. I am a huge fan of the current process for building the nuget package, and I think dirtying up the huspec with hardcoded elements is a bad deal. :toilet: \nI can do whatever to get this feature 'shipped' just need to know what the consensus is :rabbit: \nAfter playing in nuspec and the build scripts, I personally prefer building a 'portable' nuget. I have not found a way to build a single package without adding a reference to Octokit itself on Microsoft.Net.Http, though maybe that is what we want?\n. Thanks, Phil. Appears the nuget server (internal corporate) I was using was a tad out of date. Started using myget to test everything, much better :thumbsup: \n. Removing WIP tag, this builds and nuget packages deploy as I would expect. Still wrapping my head around git (Paul Betts video helped), hence the abundance of commits. \nThe only project that references Microsoft packages is the Portable project, as @paulcbetts requested. \n. Cool! I didn't think of the reactive project until now :sweat:. I am happy to tackle #435 in a similar manner in the morning (Central Daylight Time), if no one gets to it by then. \nA very interesting part of this, to me, was tackling automating nuget and the build steps. That is a very nifty way to build a package without any thought.\n. Think I got it all, apologies. I will update my resharper to match your style.\n. I think I got it right (let me know if I didnt), through powershell and the Github for Windows app. Gave me a much deeper understanding of git. :thumbsup: \n. :thumbsup:\n. ",
    "rprouse": "I figured you would might not want this, but made the changes for my needs\nso offered it up. I am happy to maintain my fork for my needs. I will enter\nthe code analysis issue and jump into the signing debate, we had the same\none on the nunit team recently.\nOn 2014-02-28 12:19 AM, \"Brendan Forster\" notifications@github.com wrote:\n\nOk, so there's two things in here which I'll address separately:\nSigning Assemblies\nWhile I appreciate there are scenarios where assemblies need to be signed\n(sup VS), I'm fairly sure this isn't something we're interested in doing\ncurrently.\nI'll open up an issue and let people thrash it out there (I know many\npeople who are opposed to it, but I'll make sure they play nice).\nIf we were to sign these assemblies, we should do it with a proper key so\nthat we can verify official releases.\nFxCop rules\nI want to fix these, rather add exclusions to the solution. Can you open\nan issue with some more details so we can address this correctly?\n\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/pull/404#issuecomment-36322754\n.\n. I submitted the pull request, so I will be the first to jump into the fray.\n\nFirst, let's make sure it is clear what we are talking about. This issue is about Strong-Name Signing, not signing the code with an SSL certificate purchased from a signing authority.\nStrong-Name signing just provides managed assemblies with a globally unique identity, whereas the second is used to verify the publisher of the application, in this case GitHub. The signing key for strong naming is just a key that a developer creates on the command line and checks into the repository. Ideally they would be secured, but that does not work for open source projects.\nPublic libraries should always be strong named otherwise they cannot be used by applications that are strong named or in Click-Once deployments. In my case, I am working on a Visual Studio extension which should be strong named. I can get around it, but that will limit what I can do in the extension.\nLook around at most of the most popular non-Microsoft open source libraries, they are all signed and are not putting artificial limitations on their users. Here is a short list, Newtonsoft.Json, NUnit, NLog, Ninject, DotNetOpenAuth, log4net, AutoMapper, Castle (Windsor, MonoRail, etc). In all cases, their keys are in their repositories.\nIf you want to troll around your bin directory and see what is signed, sn -T Ninject.dll\nSo, to sum up, Strong-Name signing costs you nothing and allows your library to be used everywhere and play nice with others.\nOkay, who's next? Gloves off, Internet fight time...\n\n. @Haacked, I also agree that two sets of NuGet packages is a very bad idea, especially if you do freeze the assembly version number which takes away the only downside that I know of. We've been having the same discussions over on the NUnit team recently, but at least we have the advantage that unit tests are recompiled often.\nAs for keeping the key private, if you want to, you could have the build check for the existence of a key and generate one if it doesn't exist. Then you just need to drop the key in on the build server.\nThat said, from my experience, most open source projects just check it into the repository. I think the downsides of that are much lower than the consequence of ever losing the official key which would be a breaking change if you had to regenerate it. Plus there is just the headache of keeping track of the official key and making sure it is always used for the production builds.\n. I was thinking more about freezing the assembly version number and wonder if it is necessary for this project. There are usually only problems for libraries that tend to get pulled in from other libraries. For example, when a project uses two NuGet packages that reference different versions of log4net. \nI don't think that will be a problem for this project as it will probably be a top level package. \n. If this ends up getting the thumbs up, I would be happy to take my original pull request and incorporate whatever is decided here. Just let me know. \n. I am the one working on the Visual Studio extension. Not signing the extension is not causing any major problems for me and as long as I keep my assembly names unique, I shouldn't have a problem. \nIt does prevent anyone from creating a Visual Studio template extension with wizards which is a possible usage, but to be honest I can't think of an Octokit.net use case for a wizard. Maybe automatically create and populate a Github repository for new solutions?  Actually, that would be kind of cool :+1: \n@paulcbetts, I've done template wizards before. It isn't Octokit that needs to be in the GAC, just the wizard, but it means that the rest of the extension (not in the GAC) needs to be signed and therefore all the assemblies you use with it.\nIf anyone is interested in checking out or helping me beta test the Visual Studio extension, add a comment to https://github.com/rprouse/GitHubExtension/issues/47 and I will get in touch.\n. @jen20, Visual Studio extensions do not have to be signed, it is just strongly recommended that they are signed. If two extensions use Octokit and it is not signed, then the first one loaded wins. As @davkean says above, if they are using different versions of Octokit, one extension will likely be broken.\nI have been working on a Visual Studio extension, so this is a concern for me. For now, since I don't know of any other extensions, I have decided to not sign, but I would prefer it if I could. Originally, I forked octokit, added it as a submodule and signed it. \nUntil this issue is decided, I decided to leave my extension unsigned because I don't want to bother with keeping my fork up to date. Once I am ready to release the extension, I think I will need to sign it so I am voting for signing Octokit if just to save me the work of signing it myself.\n. Cool, I looked at the API and saw assignee, mentioned and creator and thought Octokit.net would map the enum values in IssueFilter to that. I am already fetching all the open issues for the repository, so I can do the filtering on the client.\nGetAllForCurrent doesn't work for me. I am working on a repository-centric workflow for a Visual Studio extension. My thought is that when you are working in Visual Studio, you want to see the issues for the code you are working on, not those for every repository you have access to.\nNow that I know how the API works, I can carry on. Can we leave this issue open low priority to add assignee, mentioned and creator to GetForRepository?\n. Wow @shiftkey, you are quick. You've got the pull request done before I finished typing my reply. Good work :+1: \n. Thanks @shiftkey, I am adding additional logging to my extension. Next time it happens I will hopefully have the information I need. :+1: \n. Thanks for your help. It was the empty string for assignee, it needs to be null. I did some experimenting, milestone also needs to be null, not 0 and it is the same for updating the issue.\nI was confused by the API docs that says permission errors cause the various fields to be silently dropped. I incorrectly assumed that the API would be more forgiving because of that.\n. ",
    "akoeplinger": "+1 on freezing the AssemblyVersion number. The AssemblyFileVersion can be used to store the real version number instead.\nIf I'm not mistaken, you could increment the assembly version on major releases (i.e. 1.0.0, 2.0.0, 3.0.0) as those would be breaking and require recompilation anyway when following SemVer?\n. I basically agree with what @jen20 said, however I think we can make it less painful for people that still need SN - by improving the tooling.\nNuGet could simply apply SN with a provided key to any non-SN assemblies when it detects you want to install it into a SN-project.\nThis was already discussed at length in this thread a few years ago and the conclusion by @Haacked and @davidebbo was that auto-signing was a viable option. Did anybody of you change your opinion on this since then?\nGranted, there will be issues and edge cases, but IMHO in the majority of cases this should it make it less painful.\n. @Haacked that makes it incompatible with package restore though, as you'd need to check in the signed assemblies.\nThe NuGet team is now working on v3, so it might be a good time to fix this in the tooling.\n. @shiftkey your repro works fine on the latest Mono 3.12.0 release.\n@Trevoke can you try updating Mono as shown here: http://www.mono-project.com/docs/getting-started/install/linux/\n. @thedillonb yep, I see the same on Mono 3.12 and Mono master with your repro code, so it looks like @shiftkey's repro code didn't fully get to the root of the problem :cry: Would be interesting to know which header value causes this so the Mono guys can fix it.\n. @shiftkey I filed a Xamarin bug for this: https://bugzilla.xamarin.com/show_bug.cgi?id=27352\nNote that you can workaround this by just split Add() into multiple calls (this works on Mono 3.12 as well):\nrequest.Headers.Add (\"Accept\", \"application/vnd.github.moondragon+json; charset=utf-8\");\nrequest.Headers.Add (\"Accept\", \"application/vnd.github.v3+json; charset=utf-8\");\n. @thedillonb it isn't overriding, multiple Add() calls are fine. The type is HttpRequestHeaders.\n. You shouldn't need this, the PCL assemblies are preinstalled on Travis.\n. This shouldn't be required, xbuild converts backslashes to slashes on Unix.\n. Mono 4.2 should support ToolsVersion 14.0, with which Mono did you test it?\n. I think you meant https://travis-ci.org/naveensrinivasan/octokit.net/jobs/96850533.\nIf you look at the actual build log, the error there is from something completely unrelated (System.TypeInitializationException: The type initializer for 'System.Collections.Generic.List'1' threw an exception. ---> System.Threading.ThreadAbortException: during tests).\n. Interesting, thanks. Looks like the default xbuild script invokes xbuild 12.0, which is probably why this happens. Not sure if that's intended, I'll take a closer look.\n. PCL has nothing to do with it, that's just a coincidence (the random ThreadAbortException looks like a Mono bug).\n. ",
    "fahadash": "We have a huge application that we are trying to use ReactiveUI in. Our application is strongly named and it is up to our architects to allow removal of strong-naming which they refuse to. Now we are having a catch-22 with this ReactiveUI. Paul (I respect this guy) has not come up with a good reason not to have ReactiveUI strongly-named.\nI have never had trouble getting public libraries from NuGet because they generally are all strongly-named. We cannot maintain a branch just for strong-naming, it would be an extra effort for not a good reason. \n. Would that be possible to have only the releases that are on Nuget Gallery signed so users can \"use\" your library? \nPeople who don't wan't it signed can come to your github page and download the releases/sources. Any issue with that ?\n. @rprouse  I believe either my question was misunderstood or I am missing something here... I am not talking about any Extension to VS. I am simply talking about the auto downloading and referencing process of nuget.\nIf we could get libraries on Nuget.org signed so we could easily use \"Install-Package packageId\" command to download and reference library without thinking if my application is signed or not. That would be great.\n. ",
    "jbogard": "I tried creating an unsigned package. People unhappy. I tried creating two packages. People unhappy. Eventually I just went with signing the assembly, freezing the assembly version at just major/minor versions, and nobody has complained since. I think the reality is this is the most accessible, least bad choice.\n. Maybe my project is different, but I've never received in 6 years anyone asking to remove strong naming. Only to put it in. I error'd on the side of inclusion and maybe (?) pain for some, versus exclusion.\nI also dual licensed my project, which I didn't care about, but also led to inclusion for folks that can only accept MIT or Apache. But what can I say, I'm a pleaser.\n. @GeertvanHorrik to add to those pros:\n3) Strong-named assemblies can only reference other strong-named assemblies. For me, this meant I locked out a ton of folks from using my library\n4) Some companies have arcane, insane policies around strong-naming ALL THE THINGS. It's not the developer's policy, so why punish them.\nUltimately, my assembly versioning policy removed most (or nearly all) the pain of strong naming. I reversed my position as it was really pride that was the only thing keeping me from strong-naming. But, this really only applies to my library and how it was being used, referenced and applied. Dunno about OctoKit but thought I'd share my experiences.\n. I still don't understand how SN fucks up the \"Get started contributing\". Developers pull down the source, compile in VS, and they have a signed version of the assembly. Or run the build, whatever. Where's the contributor pain exactly? I'm not trying to be an ass, I'm genuinely curious.\nThe only time I've truly had problems with SN is when I try to recompile MS stuff and they don't distribute the key. I get around this by putting the key in the repo and removing build/revision numbers from the assembly version. Seems pretty straightforward to me, what am I missing?\n. A strong named assembly can only reference other strong named assemblies. Weak named can reference both. @shiftkey so that means anyone that strong names their assembly for any reason whatsoever cannot use this library.\n. This is functionally correct, however. When I suggested this to folks using\nAutoMapper when I removed strong-naming, I got...less than enthusiastic\nresponses. That's just not a viable option. There's no\nright-click-reference-click-strong-name in Visual Studio, making this\nchoice a non-starter.\nI also distribute as a PCL and a platform extension library. It's even\nharder to modify an assembly's references to point to now a strong-named\nassembly.\n\u200b\n. @phillip-haydon i really am curious what pain you're having. I removed the SN for AutoMapper 3.0, despite zero complaints, only to receive a number of requests to put it back in. Since I put it back in, zero complaints. From my project, the number of people negatively affected and complained about SN was zero (including myself). The number of people negatively affected and complained about lack of SN was more than zero.\nIt's getting close to 1M downloads of AutoMapper and literally nobody has asked that SN be removed, or even complained about it being SN'd. I took it away, and the complaints came in. This is one of those things that needs to come from a specific need or pain that users are actually experiencing.\n. @phillip-haydon sorry w.r.t. this comment https://github.com/octokit/octokit.net/issues/405#issuecomment-41636013\n. @phantomtypist I wouldn't do a separate package for existing projects. I tried that and it was both confusing and difficult to manage for users. It's too easy for the packages to get mixed in a solution - and when you have packages that depend on your package, everyone has to create these dual packages. Which they won't.\n. > NuGet tried to solve the binding redirect problem (I wrote that code!) and it just doesn't work\nWell THAT explains it! ;)\n. @davidfowl I don't think this thread is whether or not SN is \"Good\" but whether or not it's necessary. Application-level frameworks like Nancy.Fx aren't typically referenced by other libraries, so there's not a clear benefit to SN them.\nTool/utility libraries like JSON.Net and AutoMapper do make sense to SN because they're much more likely to be referenced by other libraries/extensions. I SN my assembly not because I want to but because enough people want it and the people that don't need it aren't feeling any pain with it. Pretty much a no-brainer for me.\n@davkean The pain I've heard the most is really around the strict match binding policy. Even without SN NuGet has similar issues in resolving common dependencies of multiple packages.\n. ",
    "GeertvanHorrik": "I agree with @jbogard. I was strong naming first, nobody complained. Then someone convinced me that strong naming was bad (at least, it should be banned). However I get more and more requests to strong name it again. The downsides of strong naming are:\n1) ???\nAnd the pros are:\n1) People can decide whether they want to strong name themselves (both ways are working with strong named assemblies)\n2) You can use assembly redirects in your config files (and then it is up to the user whether he wants to redirect breaking changes versions (as in 3.x => 4.x)\nI know strong naming is nonsense for some, but as long as the users are happy, why not? It's not that it costs you money, takes a lot of time or is very complex.\n. @jbogard \n3 == 1\n4) Agree, but is probably the reason why we \"need\" 1 ;-)\n. Depends on the \"right\" side. Everyone likes to be a visionary, the one that knew what had to be done. I just look at your latest message:\n\"If someone's going to bear the suffering of Strong Naming, it's going to be the people who want it, not the Open Source community and everyone else sane who doesn't want it\"\n1) What \"suffering\"?\n2) I am part of the Open Source community, and what is wrong with strong naming?\nSo can you please elaborate with actual arguments? I really want to add it to the list of cons in my previous posts, but I cannot put wise quotes there...\n. From what I understand, you consider \"strong naming\" an enormous entry level burden to take when entering a project. I do this in my SolutionAssemblyInfo (shared over all projects):\n```\npragma warning disable 1699    // 1699 = Use command line option '/keyfile' or appropriate project settings instead of 'AssemblyKeyFile'\nif SIGN_ASSEMBLIES\n// Sign assembly (this is relative to the obj output directory)\nif X86 || X64\n[assembly: AssemblyKeyFile(@\"........\\Catel.snk\")]\nelse\n[assembly: AssemblyKeyFile(@\"......\\Catel.snk\")]\nendif\nendif\n```\nEvery junior developer can build this, or am I missing the big clue here?\nAnd about new versions, you can redirect them (in case you are working on a diff. version than you are currently using on existing projects).\n. @shiftkey The keys must be relative to the obj folder (so even when you change the output (the default bin folder), the obj files are used for strong naming). For AnyCPU, this is easy (obj), but for x86 and x64, the obj contains an additional directory which you must \"step up\". So the keys are exactly the same, just different paths to conquer.\n. I think we haven't reached a consensus yet, and I hope we can do that in a professional (non personal opinionated) way. I will try to list the pros & cons again. If you have additional pros and/or cons, please list them here:\nCons\n1) Assembly redirects can be a pain\n2) You cannot update assemblies separately. For example, you have product X which uses Y. Both are strong named and both have a newer version (thus X has a dependency on Y vNext). With strong naming you cannot handle this scenario (but as a developer, I would strongly recommend to update Y anyways).\nPros\n1) People can decide whether they want to strong name themselves (both ways are working with strong named assemblies)\n2) You can use assembly redirects in your config files (and then it is up to the user whether he wants to redirect breaking changes versions (as in 3.x => 4.x)\n3) Assemblies can be used in the GAC\n4) You can load multiple assemblies with different versions (think for example of serializable objects (please, don't start a discussion on serialization techniques here)\n5) You can use the product with NuGet in products that require strong named assemblies (Sharepoint for example if I am not mistaken)\n6) No need to mess around with ILMerge\nI hear some people that see strong naming as a major drawback / pain. I hope they can add their cons to the list so the decision is not taken on personal emotions. Note that I didn't add security as pros because I don't think (and already mentioned in this thread) strong naming != security.\nIn the end I really don't care what it will be, as long as it is best for most people.\n. @nberardi Although at first sight this might look like a solution, I think it is out of scope for this discussion. As @jbogard pointed out, he had 2 libs ([lib] and [lib]-signed => users were unhappy). I see more cons to that solution, which I will point out below:\n1) NuGet packages will double in size. I know most people are happy with providing a single platform or using PCL, but I want to provide \"true PCL\". Because I ship a core assembly with PDB (people can step through the source code), my packages are already 4,64 MB => meaning over 9 MB with that solution.\n2) What if I decide to SN a package after I have referenced a library (or vice versa), but I know we already have this mess when you change from NET40 => NET45 or any other platform change\nAs I noted earlier, I think this is out of scope for this discussion and will not solve the problem on the short term (which we are looking for, right?). On the long term I think this should be covered by either the NuGet team or the .NET platform team.\n. @phillip-haydon Then apparently you haven't read the discussion correctly.... :-(\nThe ones that see that you simply cannot remove SN by ignoring it: me, @davkean, @jbogard, @JamesNK \nUnfortunately this thread is becoming too emotional for some. Too bad, we really could have come somewhere with the right arguments.\n. ",
    "JamesNK": "Note of caution about freezing the assembly version: If someone GACs an old version of your library with the same version then every application will automatically prioritize the GACed assembly over the assembly in the /bin folder.\nThe scheme I have settled on with json.net is to increment the assembly version only for major releases (i.e., infrequently) to balance the possibility of old versions being GACed vs the need for binding redirects.\nNo matter what you do no one will be completely happy but that is the best solution I have found for keeping the most people happy.\n. \n. > @JamesNK, are you happy with this? Would you do it again? Would you do it for a library like Octokit.net which is different in nature than JSON.NET. I'm just curious about your opinion given your experience.\n@Haacked I'd sign again. Binding redirects can suck for people, and I've done my best to minimize the need for them, but it is no where near as bad as telling someone they need to ILMerge your library.\nI have noticed a lot of people don't understand strong naming, and blame other problems on it. Back in the day I released a new version of Json.NET that had a relatively uncommon breaking change in it and that was the version Web API picked up. Unfortunately RavenDB was hit by the breaking change. Lots of people incorrectly blamed strong naming but really the two frameworks/apps depended on incompatible versions of Json.NET and until RavenDB was updated to the new version of Json.NET there were going to be problems, and it had nothing to do with strong naming.\nI don't think Octokit.NET is terribly dissimilar to Json.NET - it is more likely that the app will depend on it directly rather than through libraries which is good because binding redirects will be needed less but at the end of the day it will still be deployed with applications. I don't think the reasons behind strong naming are terribly good but you have a choice of either going with it or spending time educating every developer/company who wants to use Octokit.NET and is strong naming on why they shouldn't strong name. I'm pragmatic and tend to go with what keeps the library usable to the most people.\nEdit:\nI should add that Json.NET gets a ludicrous number of downloads these days and I never hear about strong naming any more. I think when I released Json.NET 6, which incremented the assembly version for the first time in a couple of years I saw a SO question by someone about bindings and a couple of tweets with the same question and that was it, out of 1/2 million downloads.\nDo I hear about minor breaking changes I introduce to Json.NET: yes, but again that has nothing to do with strong naming :smiley: \n. ",
    "JakeGinnivan": "The main argument is \"my boss makes me do it\" or I need to GAC/Allow multiple in a single appdomain, we could mitigate this by creating a tool/exe/msbuild task which allowed you to easily strong name everything in the build output folder (which is not signed), optionally ILMerging everything in before it signs?\n. @GeertvanHorrik to remove the pain, people stop revving version numbers. So then if v1.0.0 is GACed then I want to use v1.8.0 I cannot GAC it.\nIf your scenario is multiple versions in an appdomain (for example msbuild tasks), then the first one to load wins. So I build a project with v1.0.0 of a task, then I build another project which is using v1.8.0 I will actually get v1.0.0 and everything will blow up in a hard to debug way\n. Still a breaking change. The API itself has changed from hot to cold and existing code now needs to .ToTask()\nRight?\n. ",
    "hazzik": "For me it seems that you try to sag under folks who love monkey-patch and binary update all the things, when you yell arguments like 'the \"Getting started contributing\" story', and 'the \"Build my version from source\" story' and 'binding redirects pain'. \nSo the problem here is to decide what you need - do you want more users of your library or not. If you do so, then sign the fcking assembly and go ahead. If you don't care about your users - continue to think up the reasons like \"my god does not allow me to sign my assemblies\".\n. C'mon, @phillip-haydon, do you want to discuss how you suffer from signing assemblies? Did you go to your local church or a psychotherapist to discuss that? \n. @phillip-haydon there is an \"or\" between church and psychotherapist.\nBut the huge benefits of signing that then users who need to sign their shit for whatever reasons can use your signed shit. \n. @shiftkey, it is just my general opinion on that religious \"problem\", it does not related to Oktokit.net, nor to you directly. \nI fully agree with @jbogard  as he said that by removing signing or not signing a project you will just drop a lot of your currrent or potential users. And as he said - no one ever asked to remove strong naming from an assembly. \nSo the problem is just made up by people who are to scared to press one button in VS to sing an assembly, or by people who \"suffer\" from binding redirects \"pain\" (never had this before), or by people who love to do monkey patching by dropping assemblies into a bin folder.\n. > Benefits of Signing:\n\n\n\n\u041a\u0430\u043a\u0438\u0435 \u0432\u0430\u0448\u0438 \u0434\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c\u0441\u0442\u0432\u0430?\n\n. > All of the above cases can be worked around using several mechanisms\nI don't want to do any workarounds, I just want it to work without any efforts. \nJust because all these \"work-arounds\" make much more problems than \"binding redirects\" issue. Just because you do not upgrade your dependencies every minute, but build your software every minute.\nSo let's discuss initial issue and work-arounds.\n1. Binding redirect issue.\n   - Happens some times when you upgrade your dependencies\n   - requires 5 seconds to fix.\n2. ILMerge\n   - Need to ILMerge every time you try to release\n   - Consumes 1-5 minutes each time your build your release\n   - Needs at least one hour to configure\n3. SNing the assembly yourself\n   - Need to sign the assembly every time you want to upgrade your dependency\n   - You can not use nuget\n   - Needs some time to implement\n4. Wrapper / AppDomain - I'm not such crazy to implement this.\n. > (code smell)\nHA-HA-HA\nFck it is so ridiculous.\n. A long time ago I was working on a project when we were signing projects, and so we had to decide to do this \"workarounds\" or not to use the fcking unsigned library. Guess what my team chose? \nSo my IMO: if you are doing some public shit - sign the fcking assembly. You can do whatever you want with your private stuff: ILMerging, include as source, include as source intro resource and compile, encode as brainfuck and execute with interpreter written in javascript. \n. @SimonCropp by the reason: I do public available assembly and for whatever reasons some of my users want it to be signed.\n. @paulcbetts I'm nicer than ever. \nPS: I'm Russian and you can not scare my by any warnings.\n. If some one really suffers from fixing binding redirects errors, or his religion does not allow to use binding redirects at all, then he needs to use \nsn.exe -Vr <assembly>\n. @paulcbetts \n\nif you maintain an Open Source project, please consider following my lead:\nhttp://log.paulbetts.org/a-modest-proposal-strong-naming-carbon-offsets\n\nOf-course this is not going to work: it is the same issue as having two separate NuGet packages (Package + Package.Signed) or trying to rename your library. \n. @davkean\n\nWhat is the ongoing pain? Is it just the binding policy? Or is there something else that I'm missing?\n\nIt is just a position \"I don't want to sign my assemblies, because I don't want to sign my assemblies\", or as my 4-yo says: \"Just because\"\n. @mythz if I want to create a library which depends on your stuff what package/assembly shall I reference? Correct. I need to have 3 separated packages of my own library.\n. @phillip-haydon it seems that you did not attend elementary schools and no one taught you how to count.\n. ",
    "PureKrome": "oh wow! @hazzik \n\nSo it looks like there are some suggestions for people to do things like this:\n\nor ILMerge and then SNing the result\n\nUm, is it just me or that sounds like crazy-talk? Like, just because we can do it .. doesn't mean we should be doing it. What ever happened to Keeping thingS Simple?\n\nMy question about all of this, is this: \n1. Who are your users?\n2. How will those users access this Octokit eg. (nuGet? clone + build?)\n3. What is the easiest way to use/consume OctoKit for these user, in their solutions?\nIf the users are mostly Visual Studio Extension builders .. then some of the arguments (above) about SN + VIX might take preference. \nIf the users are mostly ~~dark matter developers (oops. these folks don't use non MS libraries) or~~ your avg joe public making web sites or phone apps or maybe a desktop app ... then really, really do they cared about SN? \nOr putting it another way, does having the library not signed make it easier for these type of users to easily consume OctoKit in their solutions?\n\nA tiny part of me wonders if the vocal minority are those people who QQ for SN. The flip side - is it really hard for -them- (if they are a minority) to clone + SN + build it, themselves?\n\nIf you have to SN it, then I've been a fan of the 'best of the worst' solutions to this: lock down the aseembly and use NuGet versions.\n\n\nNow for some useless opinion..\nPersonally, people who are using the GAC still (eg My boss makes me do it [sigh..] , etc)  ...\n\n(But my opinion doesn't help solve this important question, though :blush: )\nMy brain is too small ... I'll just go back and hide in Jabbr.\n\n. @SimonCropp Great comment! :+1: That all made sense :smile: \n\n\nFrom my experience, once you have ruled out the people who are requesting SN for security reasons, the number of people who legitimately need SN is so small that it is not worth SNing\n\nIt's metrics like this (if they could be .. grabbed), I think will help the OctoKit Krew determine which way they will decide to go, IMO.\nI've been under the (non scientific) guess that the numbers of SN people are small (and at times, a vocal minority) - which is why I've been a fan of not SN'ing stuff. And being OSS, these folks can just clone+SN+Build.\nSo yeah .. who's the majority user base here?\nMeanwhile .. while typing this comment\n\nHazzik commented just now\nJust because all these \"work-arounds\" make much more problems than \"binding redirects\" issue. Just because you do not upgrade your dependencies every minute.\n\n\nThis is what Binding Redirects (code smell) makes me think of...\n\nWhich leaves us with ...\n\n. @synhershko So are you saying that you guys/gals are \n1. trying to remove SN from Lucene.NET's NuGet packages for various reasons (?? can you share those war stories here, so the OctoKit Krew can get some more intel..)\n2. If you need an SN assembly, manually download it from a link u provide. Which means, you compile an SN version and provide both SN and not-SN assemblies for manual download?\n. Or @phantomtypist .. follow Itamar's comment and have an not-SN'd package on NuGet .. and maybe pop open a ReadMe.txt file which says in big ascii art: go here for a SN assembled, if you need it.\nOther people have said having multi-packages == confusion.\n. @davkean Great to see you here, in the convo!\nQuick newbie question (and trying very hard not to side track this convo): what is the reason for offering SN, anymore? Can't it be removed** from .NET vNext & VS vNext so this convo can be finally archived at the Computer History Museum? Does .NET still need it, to exist to solve problems for the -majority- user base?\nI also totally understand that, regardless, that doesn't help OctoKit & every other OSS package in the short term - hence trying not to side track this convo.\n** Not saying that's easy .. but asking if it could be sorta-realistic-possible.\n. :+1: @davkean ! \n\n\n@Octokit Krew - after all of this - has it helped you folks re: making a decision?\n. ",
    "phillip-haydon": "Signing is bad despite what argument @hazzik can come up with. Don't sign. Too much pain signing. \n. Well I'm lucky, I don't go to church or follow any religious cults such as Christianity, so I don't have any need to see a psychotherapist.\nI don't really want to discuss how I suffer from signing, but we can discuss the benefits of signing:\nBenefits of Signing:\n\n. Pretty sure he falls into the \"I feel it gives me a sense of security and because my boss told me so\"\n. @paulcbetts sorry its my fault. I'm winding him up. \n. @paulbatum when you ILMerge you would flag it as internalise which would hide the API from the user, allowing the user to continue to reference what ever version they wanted.\nThis is what RavenDB had to do when JSON.net became signed. (if my understanding of the issue was correct)\n. Of course there's two, there's your one that you use internally for your library, and the one the consumer of your library uses, you don't use the consumers version, you use the version you internalised. \nThe person consuming your library doesn't even know you're using automapper. \n. Then you've designed your API poorly in my opinion, you would need to expose your API for writing the consumers models to your implementation of AutoMapper, you're only using AutoMapper for your internal conversion of their DTOs to your own correct? So I would assume you only need them to register the classes that need to be converted from/to.\nBut right now it sounds like you've forced the dependency of AutoMapper onto the consumer, not for your internal use, that's bad because you're forced into a life long dependency on AutoMapper. If you wanted to change AutoMapper for ValueInjector, you can't because you've given an explicit dependency to the consumer to configure on AutoMapper. \n. I can only comment on what I know, you asked about AutoMapper, I'm saying that you can internalise AutoMapper for your internal use, and this fixes the SN issue. \nBut you're saying that the user will have 2 AutoMappers now, that's simply not true. The only reason they would have two AutoMappers is because you are exposing the AutoMapper dependency to the consumer, so your design prevents you from being able internalise.\nThis is a problem with your design, not with the fact that SN can be solved by internalising AutoMapper.\n. Huh? I've had no problem. I was answering his question... \n-----Original Message-----\nFrom: \"Jimmy Bogard\" notifications@github.com\nSent: \u200e4/\u200e29/\u200e2014 8:43 PM\nTo: \"octokit/octokit.net\" octokit.net@noreply.github.com\nCc: \"Phillip Haydon\" phillip.haydon@gmail.com\nSubject: Re: [octokit.net] Signed Octokit Releases - Yea or Nay? (#405)\n@phillip-haydon i really am curious what pain you're having. I removed the SN for AutoMapper 3.0, despite zero complaints, only to receive a number of requests to put it back in. Since I put it back in, zero complaints. From my project, the number of people negatively affected and complained about SN was zero (including myself). The number of people negatively affected and complained about lack of SN was more than zero.\nIt's getting close to 1M downloads of AutoMapper and literally nobody has asked that SN be removed, or even complained about it being SN'd. I took it away, and the complaints came in. This is one of those things that needs to come from a specific need or pain that users are actually experiencing.\n\u2014\nReply to this email directly or view it on GitHub.\n. So far:\n39 people have contributed to this thread:\nThose in favour of removing SN: 38 people\nThose in favour of keeping SN: @hazzik\n. Jeez, I'm beginning to think all those in favour of SN are the same people who lack any sense of humour. \nSorry guys!\n. No Async suffix for Nancy. :)\n. ",
    "glennblock": "If you can get away with it, I'd vote nay! Binding redirects and having to deal with GAC issues have caused me so much personal pain in my years of using .NET (which are many). If you have to do it, @JamesNK's approach of only incrementing the assembly version for major versions seems reasonable. So far we've been able to skirt having to deal with this on the projects I work on. I hope sincerely we can continue to do that.\n. @SimonCropp I agree it's not perfect. It does address the virality of signing,  but I can see how it doesn't completely solve the GAC issue / creates new issues.\n. Isn't the more common issue here the virality? That a strong-named assembly can only reference other strong-named assemblies i.e. if we ship a library that is SN, it can't depend on Oktokit unless Oktokit itself is also SN?\n. I remember when I was in patterns & practices we had so many people wanting us to have signed Prism assemblies for this reason. It had nothing to do with GAC and everything to do with the fact that signed assemblies wanted to depend on Prism.\n. @SimonCropp I see your point on not solving the VS issue. My point is that the majority of requests from SN (in terms of numbers) don't stem from VS extension authoring requirements (at least based on what I have seen).\n. \"I would've preferred it if strong naming had never existed\" :clap: \n. @haacked what about Mono/Xamarin? won't relying on a PS script inhibit\nusage on Mono?\nOn Tue, Apr 29, 2014 at 8:50 AM, Phil Haack notifications@github.comwrote:\n\n@Haacked https://github.com/Haacked that makes it incompatible with\npackage restore though, as you'd need to check in the signed assemblies.\n[image: :poop:] you're right. Forgot about that.\nNever mind. Burn it all to the ground.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/issues/405#issuecomment-41694033\n.\n. @davidfowl \n\n\n. @davkean thanks for contributing and listening.\n. ",
    "thecodejunkie": "The Nancy nugets have well over 300k downloads and every now and then we get a question about strong-naming. Not a single one of them have been able to provide any tangible resigning beyond that a work policy requires it (for security reasons or other) or that they have a dependency on another strong named assembly. For the \"security related\" cases, not a single one have been able to provide us with an explanation was a signed assembly, from a couple of random people, would be able to provide them in terms of security - we're a not a \"trusted authority\" in any way + many OSS projects that sign assemblies put the key in the repository - further negating the security aspect.\nThe headache grows when the strong-named assembly is frequently updated (and version bumped). I would advice against SN, but if you have to then please know your audience and make the path that causes the least amount of pain for the majority. Without having any firm metrics to fall back on, I am pretty sure that you have more non-SN-shop users than SN-shop users (due to the nature of the library). It is my personal opinion that VS extension authors are also in a clear minority and want this for convenience reasons..\nThe \"Assembly X is strong-named so I need your assembly to be signed as well\"-argument is the worst one. I for one won't help fuel a fire that someone else started\n. @hazzik or (if we flip the coin) if anyone really suffers from the lack of strong-naming they can sign it themselves? \n. @distantcam vs. the friction that strong-naming does cause in many scenarios (as mentioned by previous posters) + you have to realise that a vast majority of signed assemblies has not taken the signing approach chosen by JSON.NET. Even if they had, it is not without friction. Jeremy Miller wrote a post about it recently http://jeremydmiller.com/2014/04/28/fubumvc-lessons-learned-strong-naming-woes-and-workarounds/\n. ",
    "distantcam": "@thecodejunkie  I think the point against \"they can sign it themselves\" is then it's harder to consume the library than simply invoking nuget.\n. .linq files have a little bit of XML header, and then the actual code. They are very human readable.\nFor example https://github.com/naveensrinivasan/octokit-linqpad-samples/blob/master/1-introducing-octokit.linq\nLinqPad can run scripts on the command line (https://www.linqpad.net/lprun.aspx) and output them. Then you could use approval tests on the output.\nAnd if I have any sway over it, I'd like to see the samples in the main package. That way if you use LinqPad to experiment with nugets (which is a common use case of LinqPad) the samples are right there. Con is the package has some extra text files if you don't use LinqPad.\n. @shiftkey Did you want me to fix it too? It's a pretty quick fix, I just wasn't sure how unstable the API is.\n. @shiftkey (Windows 8.1 required) Well, that makes it difficult to build the project. :-1:\n. @itmuse I've fixed it, but my fix hasn't been pushed to NuGet yet. @Haacked @shiftkey \n. @Haacked LOL looks like I copied the wrong parameter name. https://github.com/octokit/octokit.net/blob/master/Octokit/Clients/IReleasesClient.cs#L37\n. @Haacked Want me to fix that too?\n. @Haacked Ah, number comes from issue number. Given that it might be better to be consistent, otherwise files like https://github.com/octokit/octokit.net/blob/master/Octokit/Helpers/ApiUrls.cs are going to have a mixture of id and number.\nSo which is better?\n. @Haacked Done\n. \n. @Haacked Turns out I was authenticating first.\n. Ok, so a colleague reported hitting a file limit of 20Mb. Meanwhile I was having issues with 10Mb.\nI suspect this is the culprit. https://github.com/octokit/octokit.net/blob/master/Octokit/Http/Request.cs#L14\nThe connection is timing out before the upload is complete. Yay for Australian internet speeds.\n. @shiftkey Yep, not seeing an error from the wire, so it's definitely a timeout. Also the exception I was getting was a Task Cancellation which I'm guessing comes from the HttpClient.\n. Setting the timeout for all requests is ok, but I think it would be more useful to set a timeout for a specific upload call, as it may be significantly larger than the default for other calls.\nAlso, again specific to uploads, is it worth setting the timeout to null?\n. Typically we keep the client for a few actions, mostly create the draft release + upload assets to that draft.\nUsually upload timeouts would be large, so setting it globally I don't want to wait 60 minutes to find out the release creation was the one that timed out. Being able to change the default between calls is ok, but it just feels a bit icky to me.\nHttpClient.Timeout supports a value of Infinite so that would work instead of null.\nAlso, here's where I'm using Octokit. https://github.com/Particular/GitHubReleaseNotes/blob/master/src/App/Program.cs\n. That ContinueWith gives me the heebie jeebies.\n. Yes it was 0.7.1.\nI don't know if I'm seeing my organizations or not because after about 100 pages I tend to stop debugging. It's downloading all the repos, not just mine.\n. Yep, solved my problem thanks.\n. :-1: \nSo my problem here is that certain properties (timeout for example) I would want to set per endpoint I use (long for uploading an attachment to a release, short default for the rest) rather than setting at a global connection level.\nFrom an API point of view I'd like to see an optional RequestOptions object that I can pass, which modifies the behaviour of that web call, but doesn't affect all calls.\nAs for HttpClient, it would be nice if I can create my own instance, passing in a custom HttpMessageHandler that wraps the Octokit's RedirectHandler.\n. > I'd love to get some more insight into that scenario as I know you've been dealt with that in the past.\nOk the scenario was this - we have automatic scripts to deploy releases to GitHub. The script does various things:\n- Find matching milestone for release version\n- Create Release for the tag, with compiled notes from the milestones issues.\n- Attach compiled release to the GitHub release\n- Close the milestone\n- Publish the release\nWe hit a problem with attaching the compiled binary to the release. If the binary was too large the timeout would cause the upload to fail. So we upped the timeout to several hours.\nThe problem is, I don't want any of the other tasks to wait several hours if they're going to timeout. For most of the communication a 60s timeout is fine, and only for the upload would I want to change that timeout.\nIf you're interested, our release project that uses Octokit.net is https://github.com/Particular/GitHubReleaseNotes\n\nWhat other parts of a request might you looking to modify, generally speaking?\n\nWell, I was looking into handling the request caching to avoid using up the API limit when polling a repo for changes. So I was trying to support #352.\nSo I guess what I'm really after here is a way to poll a repo for changes, and then have some automation happen because of that change. And suddenly as I write this I realized webhooks is a much better solution to this problem. Oh well.\n. > So you're not seeing an issue with the current 100s limit we have?\nNot currently no. The upload was bigger but we've trimmed it down and it hasn't been a problem in a while.\n. Yep, so after some digging I found the specific error was when trying to add a label to a repo with credentials that didn't have write access to that repo.\nI can email you a script if that'll help.\n. > So is the issue you want a specific exception?\nJust a more specific message. Not Found: 404 trying to retrieve resource https://api.github.com/...[specific endpoint] would be useful.\n\nYou kind of know what you were doing, right?\n\n\n. @ryangribble Url parsing is what I meant when I said there's no easy way to tell which repo an issue came from. ;)\nAlso I agree it doesn't make sense for octokit to do another API call behind the scenes, since I was trying to avoid excess API calls to begin with.\nI guess the problem then is at the API layer and maybe this problem could be elevated to them?\n. The two SendData methods are very similar. I can see a modified-one-but-not-the-other error in your future.\n. ",
    "aaronpowell": "Recently the Lucene.NET developers have been talking about ditching strong naming from the project starting with the next version - http://mail-archives.apache.org/mod_mbox/lucenenet-dev/201404.mbox/%3CCAHTr4ZubJCApjQF32noJ_i1nwbDp_pdweFa9FCeNaEEfacYRRA%40mail.gmail.com%3E and it could be worth reading through the thread on there as well to get their perspective on the problem.\nFor the record it is actually at a vote now - http://mail-archives.apache.org/mod_mbox/lucenenet-dev/201404.mbox/%3CCAHTr4ZsWmJ8VT9NpoHkhza93DH%3Dnu_BedYcUg9Rx1KUQ1VX2Qg%40mail.gmail.com%3E\n\n\nAnd that's the end of that chapter\n. \n",
    "mythz": "I've also wasted more time on strong naming binding redirects than I care to repeat, and I've been strongly opposed to strong naming ever since which IMO it's incompatible with OSS and continuous delivery that disrupts the iterative OSS workflow, introducing friction in forking, making use of customized builds and contributing back changes.\nIf you make your SN key public, just so forks can actually test their customized builds than that pretty much negates one of the major reasons why CIO's were asking for it in the first place (i.e. under the perception of increased security), in this case all we're left with is that we need to strong name to support existing users who can only use strong named dlls, with the original rationale negated.\nEventually I've had to add support for strong naming in ServiceStack v4 as it's a popular requested feature of ServiceStack's enterprise customers who wish to use it in enterprise products (e.g. SharePoint) that mandate it. But as I didn't want to burden the majority of the user-base (myself included) who don't want it, I've added a parallel track of Signed packages with a .Signed suffix (https://servicestack.net/download#signed). It takes more effort on my side, but with this approach we can mitigate the effects of strong naming to only customers who really want it and are more likely hardened to deal with their effects.\nThe one exception is the ServiceStack.Interfaces project which is always signed as it provided the most value with the least impact since only the binaries that requires sharing is the DTO dll which only needs a dependency on SS.Interfaces, and the only way for them to be shared with both Signed/Unsigned projects is to be signed. It's done in the least intrusive way where we keep the [AssemblyVersion] constant and resort to updating [AssemblyFileVersion] to report the true version number. Because its Signed only we're realistically able to make \"official\" changes and builds of ServiceStack.Interfaces and not any of the forks who are maintaining their own customized builds. This is only manageable because SS.Interfaces is rarely updated so has created minimal friction, it does mean anyone else either have to workaround solutions not making changes to SS.Interfaces or propose changes that have to be implemented on my side, then notify them when updated builds are available.\nI would've preferred it if strong naming had never existed, if it didn't CIO's would've thought twice if it was justified, if it was concluded some verification was needed, then the simplest solution that worked would've been created and not the unnecessary complexity imposed on us today causing an artificial divide between signed and unsigned packages and the support burden it generates. It doesn't in most other platforms and they're better off without this imposed artificial complexity that continues to plague .NET to this day.\nIn future I see both the GAC and strong naming being marginalized whose benefits doesn't justify their existence. SN makes more sense if software was sealed and delivered waterfall, but by its nature software is continually evolving and updating where we're striving for fast iteration times, continuous delivery and replay-able automation. \nWe're pretty far from this in .NET (and may never get there during our Careers), but I see the nirvana dev environment is to move to a more live-reload source-based module system where we can simply reference GitHub repos as dependencies and be able to run C#/F# as source files directly (i.e. by-passing devs seeing/dealing with dlls or other interim artefacts themselves) which I also see as one of the major appeals of projects like ScriptCS. Making a change in this world is just editing source code + hitting replay, likewise making a change upstream is simply updating modules after merging your pull-request (or can even switch reference to use your own fork). There's no place for strong naming in this world, it only hinders it. \n. @EddieGarmon \nHow does this sound:\nThe failure is not in _ its in the devs who haven't devoted the necessary time into researching how to appropriately deal with its side-effects and intricacies resulting from the unnecessary complexity that was imposed upon them. These devs are also selfish in not appropriately allotting a part of their development time to help diagnose their user base  issues, which they're morally obliged to do given the majority users never wanted to deal with  and have expected their software to work transparently across updates and integration with 3rd party packages. By subscribing to be a .NET OSS developer you're expected to adhere to the unspoken rules of Enterprise .NET and pay the  tax which overrides any OSS philosophies you may have or believed you have concluding from the fact that no other platform incurs this burden. A good mantra to remind you of your duty as an OSS .NET developer is:\n\nThe needs of the Enterprise few overrides the needs over the OSS many\n\nDont blame ___, blame the ecosystem and surrounding tools for not understanding it properly.\n\nBy strong naming all you are doing is perpetuating an unnecessary complexity that should have never existed. #nomorestrongnaming\n. @hazzik \nHaving separate .Signed packages has worked well enough in practice for ServiceStack. It takes strong naming away from the default packages and localizes issues to only users who really need it.\nNo the position is: I shouldn't have to subject our entire user base and any potential contributors to un-necessary friction because of the few that need it.\n. @hazzik the default packages unless you want signed versions, in which case the signed packages.\n. @davkean For the last few years I've managed to avoid any SN issues by ensuring all packages remained unsigned. During this time the only issue affecting ServiceStack packages were having to maintain a new Log4Net adapter when Log4Net bumped their version: https://github.com/ServiceStackV3/ServiceStack.Logging\nWe've been able to mitigate this by ensuring app code never had concrete references to Log4Net impls and instead only bind to the impl/dep-free interfaces maintained in ServiceStack.Interfaces. In this way only the host project decides which single concrete version of Log4Net gets used in order to avoid having to run dlls with different SN versions of the same library in the same app domain.\nLeading up to this I've suffered the normal SN binding hell of trying to make use of components with different dependencies on different versions of SN libraries where the solution ended up being to drop down and implement a custom assembly resolver to implement manual Assembly resolution, which needed to be revisited again when some SN dependencies upgraded.\nNow the pain point is primarily the overhead of maintaining parallel Signed packages which was only added in v4 based on some enterprise Customer demand. Ultimately I've decided on this as the best strategy with the least impact. The primary friction is with the Signed-only ServiceStack.Interfaces project which effectively every other project depends and I'm only able to create \"official\" builds for, this is manageable as this project is rarely updated so for the most part doesn't inhibit contributions.\nIn the end, I'm hoping the ultimate solution in future revolves around unsigned dlls.\n. I'm going to go ahead and give my primary vote for removing:\n\nthe viral-ness of strong names so enterprises to reference OSS projects that didn't.\n\nWhich IMO would alleviate the primary pressure facing OSS projects into releasing signed versions of their libraries. \nEffectively some form of \"We need signed versions because we can only use signed versions\" is the only rationale I've ever received for making signed versions of my libraries available.\n. ",
    "paulbatum": "Going to ask a stupid question and I am not even going to use any funny gifs. My team at Microsoft builds an Azure service and we ship our sdks on NuGet. Our sdks are integrated into the tooling experience in Visual Studio so they have to be strong name signed - we have no choice in the matter.\nIf you trace the dependency chain for one of our libraries, you will find it includes several projects discussed in this thread. Automapper, json.net, etc.\nMy stupid question: what would you have my team do if the libraries in question stopped distributing strong named versions on NuGet? The only answer I can glean so far from this thread is to ILmerge. I'll admit I haven't actually gone through the exercise of trying this out, but doesn't this have some major problems? Firstly I don't think this works for frameworks that support rich extensibility. E.g if we IL merge in some version of automapper, how can our users reference and configure automapper themselves and have our framework pickup those changes? Secondly, I no longer get the very nice behavior of the user being prompted to accept the license of each of our dependencies.\nI genuinely am not interested into getting involved in the religious debate here. I just want to understand How To Make My Stuff Work(tm).\n. But that doesn't work. Now there are two automappers. There needs to be\njust one, or the developer experience suffers. Automapper isn't an\nimplementation detail for us - it's an important part of the dev experience.\nOn Tuesday, April 29, 2014, Phillip Haydon notifications@github.com wrote:\n\n@paulbatum https://github.com/paulbatum when you ILMerge you would flag\nit as internalise which would hide the API from the user, allowing the user\nto continue to reference what ever version they wanted.\nThis is what RavenDB had to do when JSON.net became signed. (if my\nunderstanding of the issue was correct)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/issues/405#issuecomment-41650587\n.\n. I am not sure how to state it any clearer: Automapper is not an\nimplementation detail for us. Our framework is not a black box.\n\nOn Tuesday, April 29, 2014, Phillip Haydon notifications@github.com wrote:\n\nOf course there's two, there's your one that you use internally for your\nlibrary, and the one the consumer of your library uses, you don't use the\nconsumers version, you use the version you internalised.\nThe person consuming your library doesn't even know you're using\nautomapper.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/issues/405#issuecomment-41650986\n.\n. Unfortunately I haven't given you the necessary context because I am in bed\non my phone and I should be sleeping. Can we avoid the design debate and\ncontinue the discussion with my constraints as described? If we throw an\nargument about how to and how not to design a framework into the mix this\nthread will probably gain sentience and destroy us all.\n\nOn Tuesday, April 29, 2014, Phillip Haydon notifications@github.com wrote:\n\nThen you've designed your API poorly in my opinion, you would need to\nexpose your API for writing the consumers models to your implementation of\nAutoMapper, you're only using AutoMapper for your internal conversion of\ntheir DTOs to your own correct? So I would assume you only need them to\nregister the classes that need to be converted from/to.\nBut right now it sounds like you've forced the dependency of AutoMapper\nonto the consumer, not for your internal use, that's bad because you're\nforced into a life long dependency on AutoMapper. If you wanted to change\nAutoMapper for ValueInjector, you can't because you've given an explicit\ndependency to the consumer to configure on AutoMapper.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/issues/405#issuecomment-41651585\n.\n. @phillip-haydon Try to imagine an opinionated .net based web stack that is hosted as a service and you might understand our scenario better. I think your assumption about hiding the dependency makes sense if you are talking about a library that acts as a black box, but that is simply not the case here.\n\n@simoncropp wrong team, and not constructive to the purpose of this thread. \n. ",
    "PaulStovell": "@paulbatum one example is in RavenDB where some parts of JSON.NET are interalized, but public and nested under their namespace. So when declaring properties you can do:\n[Newtonsoft.Json.JsonProperty]   // For the real JSON.NET\n[Raven.Imports.Newtonsoft.Json.JsonProperty] // For Raven's\npublic string Foo { get; set; }\nIt's actually nice because you can specify different serialisation options for different use cases. Likewise, AutoMapper uses a lot of static configuration (IIRC, it has been a while) so having a separate copy from a separate namespace might allow people to customise the way you use it, without affecting other libraries that use it. \nNot suggesting that this is the answer to \"should we SN or not\", just pointing out a shade of grey between \"reference a strong-named assembly\" and \"ILMerge and internalize\". I think it would be quite bad if everyone did this. \n. @davidfowl eventually that will happen. Unfortunately there's a large company located somewhere in Redmond that make a lot of platforms that still demand strong named assemblies :) \n. ",
    "davidfowl": "I'm going to suggest something radical because it's 2 AM and I should be sleeping. Everyone in the .NET OSS community should just stop strong naming everything. This will have network effects and eventually the GAC and strong naming in general will die on its own :smile: \nSomebody should make a logo for this movement.\n. @davkean Glad to see you made it here David. If people want side by side they can rename the binaries (because for some reason the CLR ignores the version of assemblies without a strong name). Like I said on twitter, if you start with the existing solution that is strong naming, then it looks like you can't live without it.\nThe truth is, other platforms have solved these problems and they don't have or need strong naming. .NET is not special, we just chose to be different and it causes more problems than it's worth. \nIf we somehow the community could organize itself and stop strong naming things, we would be better off.\n. @fahadash you know what would be even better? If we could all organize instead of trying to hack our tooling to make half assed solutions to things. NuGet tried to solve the binding redirect problem (I wrote that code!) and it just doesn't work. The power is in the hands of the library authors.\n. @FransBouma Exactly, name and version work for most scenarios and the binding policy already works the way it should when you don't strong name. \nGiven that:\nWhy not just make it non viral first then fix the binding policy for those that have to keep strong naming (no matter how strange that reason is)?\nCan anyone think of an example of another platform with something like strong naming? Whenever I see people explain why strong naming is good or why they need to strong name they gloss over the fact that everybody else on the planet has the same problems and have found better ways to solve them.\n. The experience of installing netstandard 1.x packages on .NET Framework brings up that scary dialog. I've seen projects multi target to net4x and netstandard because of it.. > so does that count as \"guidance\" that the preference is to avoid the scary dialog, thus we should continue to support net4X as well as netstandard1.1?\nThat might be the least jarring upgrade. I would start with those tfms and test the install on various platforms.\n\nAnd to clarify your tweet from the other day, we also should add a netstandard2.0 target to provide a better dependency story for those on newer .NET Core platforms?\n\nYes. We should do that. The idea is to reduce the dependency closure on .NET Core 2.x and above.\n\nAnd should keep our netstandard1.1 target since that's the only way people on earlier Mono/Xamarin and .NET Core 1.x can access the library?\n\nThat's an interesting question. You should probably keep it around for now otherwise it'd be a breaking change. At some point though you'll need to cut the cord (like when the support for these older platform runs out).. ",
    "damianh": "ILMerge is still an MSR project that I think are run by the same people that run code contracts and pex. i.e. it's a tough call to rely on this stuff. (ILRepack seems to be showing some promise)\n* Really wish ILMerge / declaring references as private / internal was a first-class compile-time concern *\n. @SimonCropp Yeah, but not quite first-class up-in-your-face enough (imho)\n. I was also considering charging for signed packages https://twitter.com/randompunter/status/426463075919990786 . Let me know you get any subscribers @paulcbetts :D\n.     (await _gitHubClient.Organization.Member.GetAll(_organization, OrganizationMembersFilter.TwoFactorAuthenticationDisabled))\nI hate when this happens.. :)\nOn 21 Dec 2016 5:12 a.m., \"Brendan Forster\" notifications@github.com\nwrote:\n\nI got you @damianh https://github.com/damianh\nhttps://cloud.githubusercontent.com/assets/359239/21377136/5dc28db2-c78b-11e6-9b4e-d04c0e68ec2f.gif\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/1518#issuecomment-268431158,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AADgXC1Jaon1oLdxzpUeIir1WECvUlchks5rKKc6gaJpZM4LR4B_\n.\n. \n",
    "jen20": "My 2\u00a2 - if someone finds a library useful enough to want to use and wants to strong name (for whatever reason), it should be them that feels 100% of the pain involved in strong naming it - they should absolutely have to build it themselves and strong name it in order to extract whatever benefit they perceive there being.\n. @nberardi's suggestion of treating strong naming as a separate platform has a :+1: from me in principle, though I'm not sure whether that comes with other problems.\n. @davkean Re:\n\n2) If you want your library to be able to be deployed to an application with a plug-in-like environment (such as Visual Studio) strong naming is a requirement (assuming you don't want to force ILMerge on devs).\n\nMy experience is that VS extensions do not have to be strong named unless they are wizards - is that not the case anymore?\n. @paulcbetts :+1: \n. ",
    "iancooper": "I ban strong naming and the GAC everywhere I work - it's a trade-off between maintainability and security, and the security benefits, particularly for OSS libraries are so weak that they don't override the maintainability benefits of not having SN. I'm honestly gobsmacked to discover that people still use SN and the GAC. No one I know has been using a SN/GAC approach post the first five years or so of .NET where they all got burned badly enough to kick it out. My estimation of anyone using SN falls, very rapidly.\n. I think it's worth noting that the GAC was trying to solve a problem from the Win32 DLL/COM era when folks were sufficiently short of diskspace that installing multiple versions of a library on a user's machine (for it was pretty much client server in those days) that saving disk space by installing into the System directory looked tempting, but resulted in collisions as different packages overwrote dependencies or updated shared ones.\nNow it's possible devices still have that issue, or folks want sufficiently small downloads for clients that use of the GAC is still popular, but for my part the constraints that made me want to deploy in anything other than side-by-side mode have long gone away. So I'm uncertain why folks continue to deploy to the GAC. I'm sure someone might be able to enlighten me, but I have not used it for a long time.\nOnce you move away from the GAC the issue with trusting an assembly that you download tends to lessen. IMO signed assemblies are about defending you from someone inserting a version of an assembly into the GAC which compromises consumers of that asembly. Drop the GAC and that goes away.\nI'm uncertain whether that signed assemblies is still the best mechanism to then use in a package manager - it was built for something else. Establishing the credentials of a publisher, for their own packages, and the dependencies that they require needs a mechanism that is tolerant to binary compatible differences in those dependencies. Strong naming doesn't provide enough protection, once the GAC is dead, to force us to put up with incompatibility based on version increments that are not a breaking change to the public api of an assembly. \n. But do we think that extensions are a big enough use case that we should sign every assembly within a package manager? In terms of maintainability strong naming makes solutions more brittle, so we would want to see a benefit that makes that loss of facility a reasonable tradeoff. Are extensions really that common a use case for that to be true? \n. @paulcbetts http://en.wikipedia.org/wiki/Nudge_theory :-)\n. ",
    "Mpdreamz": "Strong naming is a real pain and easy to get wrong. I wish I never had to familiarise myself with it and would have wished strong naming never exisited. \nHaving said that:\nJust don't strong name is a mantra I would love to adopt but my main OSS project is a library that is often used by folks hooking up Elasticsearch with i.e Sharepoint or other frameworks that need strong named assemblies. The mantra is easier to hold up (or atleast an easier sell) for OSS frameworks vs libraries.\nI too follow @JamesNK approach and still see it as best of both worlds. \nAs much as I detest strong naming the greater goal is to service the most people and @JamesNK 's approach does just that so I'm not convinced I should drop that just because I do not agree with the necessity.\n. Just to add fuel to the discussion strong naming assemblies post nuget instal won't always work:\nMy project has 2 packages PackageA > PackageB \nBoth are separate nuget installable packages but PackageA depends on PackageB If there was a post nuget strong name process on A and B then A won't be able to load B anymore because of a pubblickeytoken mismatch.\nMy dumb approach to strong naming has always been to do an sn.exe sign post build but doing this on two separate dlls that depend on eachother will cause the link between them to break. So now I'm signing from visual studio / msbuild and have a complicated pre build event (both in the csproj files as well as the main FAKE build script) that generates a key to sign with in the right place before building so contributers can still checkout and F5. \nhttps://github.com/elasticsearch/elasticsearch-net/blob/master/build/build.fsx#L62\nBut sn.exe to create the keys is not something I can install locally from my build script so i have to redistribute sn.exe. Unlike i.e nUnit runners which I can install from nuget:\nhttps://github.com/elasticsearch/elasticsearch-net/blob/master/build.bat#L18\nThis whole process should be a lot easier. The key reference is not relative by default if you hook it up from within visual studio. If the key does not exist in the location it should be way easier to generate one in place. \nSDK's should really be put in nuget as @haacked already blogged about wonderfully\nI guess my point is that strong naming is not always something ILmerge or sn.exe post nuget install can solve.\n@nberardi just tweeted something which to me presents a very nice middle ground:\nhttps://twitter.com/nberardi/status/461094608513273856\n. @phantomtypist for a long while I had Package and Package.Signed but if your product consists of multiple separate libraries it ends up bloating nuget searches tremendously..\n. ",
    "nberardi": "Thanks @Mpdreamz it occurred to me after reading this thread that the problem isn't SN, it is what SN does to projects that rely on NuGet.  However that doesn't negate the case for SN, any more or less than shipping out multiple versions of the same assembly for different frameworks does.\nHere is my suggestion.  Why not treat SN as a separate platform/framework in NuGet.  Something like: net40-sn for a signed version of a .NET 4.0 library.\nIf we had the following NuGet library:\n\\lib\\net40\n\\lib\\net40-sn\nWhen adding this to a signed library, it would use the SN version, when adding this to a non signed library it would use the unsigned version.  And since this is merely a convention, it wouldn't effect any libraries that currently us the net40 for signed libraries, because if SN isn't present than everything would simply used the net40 libraries.\nWhat do you think, or am I totally off the wall, or suggesting something that has already been discussed to death?\n. @paulcbetts :+1: \n. ",
    "synhershko": "I'm a committer for Lucene.NET, and we are pushing hard to removing strong naming. I went ahead and discussed this in length here: http://code972.com/blog/2014/04/68-ditching-strong-naming-for-lucene-net\nI'm assuming most place which require SN, and their process can't really change easily, will also likely not being using nuget anyway (big corporate, government agencies, etc). While this is not always the case, I'm happy with assuming this and redirecting them to the download page.\n. ",
    "gluck": "Feels good seeing I wasn't alone in feeling the pain with SN.\nI support that the right choice :tm: is to drop it.\n(If only because it'll force the development of proper tooling around it, e.g. auto-signing by NuGet ?)\nThe one approach I strongly advice against is to SN with a private key (as in \"not in the public repository\").\nIt goes strongly against OSS in the sense that I need to ask the maintainer for a release/patch if I don't want to end up re-compiling every dll that depend on it, and you can't rely that much on people you don't pay.\nI've been hit by this and we since moved to a fork (although w/o any change) of the so-called OSS library (IKVM, not to name it), just to sign it with our key, and be able to patch it if the need arise.\nThis is just sad, so you get my +1, even if I know it'll mean changes on my side (we moved to ~~ILMerge~~ ILRepack but still kept SN, for no good reaon).\n:+1: \n. @davkean IMO (and experience), merging is a better solution for this, because you don't get runtimes surprises e.g.:\nOctokit has some static state (not arguing it's clean code :tm:), Extension1 wants it set to A, Extension2 wants it set to B, it works if they don't use the same Octokit library, and starts breaking when they match (and both are installed).\nIMO (been there, done that) SN has been abused for extension frameworks because it was the closest thing to match the need (isolation) w/o resorting to dark arts (ILMerge), but it doesn't make it right.\n. ",
    "davkean": "Here's my thoughts:\n1) SN'ing the binaries after the fact (via ildasm/ilasm) is not going to help if a developer has other dependencies that they don't own that have built against the non-strong named versions. These AssemblyRefs will also need to be fixed up.\n2) If you want your library to be able to be deployed to an application with a plug-in-like environment (such as Visual Studio) strong naming is a requirement (assuming you don't want to force ILMerge on devs). \nIf you don't, extensions with two different versions of the same library will break each other. We won't load non-strong named assemblies side-by-side, so whichever extension gets loaded first wins - if that happens to be an earlier version, then the one expecting a later version will break.\nIf that environment uses the default Load-based (as opposed to LoadFrom) plug-in system, then incrementing version every release will also be a requirement, as GAC'ing your library is going to be the only way to load it side-by-side.\n3) With regards to the binding redirects, a couple of options:\n- Rely on NuGet to generate them. Unfortunately, its logic was lacking for our situations which lead to:\n- Having the package automatically generate them to reduce the pain. We took this approach for our packages, such as HttpClient, Async, etc. The downside is that you need to hook onto build via a targets file, which leads to package restore issues.\n- You could point consumers to turn on Automatic Binding Redirects, a feature we added in Visual Studio 2013. By default it is only enabled for new 4.5.1 applications, but devs can turn it on for existing projects targeting older versions.\n. @jen20 Read the rest of the paragraph. :)\nThe extensions don't have to be signed, but if you want your library to play nicely in that environment you will need to be signed. Imagine this setup:\nExtension1 -> Octokit v1\nExtension2 -> Octokit v2\nIf Octokit isn't signed, and Extension1 gets loaded first, Extension2 will be loaded and bound against Octokit v1 breaking it if it was expecting any v2 behavior or APIs. If Octokit is signed, then we will load both versions of it side-by-side.\nIf Extension1 or Extension2 are loaded in the Load context (as opposed to the typical LoadFrom context), then they will also need to have different assembly versions as they will need to be dropped in the GAC to be loaded side-by-side.\n. @davidfowl It's more than renaming the binary - you will rebuild the library itself and then rebuild anything with a dependency against it. The binder's not going to look in a binary called \"MyOctokit.dll\" if you build against an assembly with the name of \"Octokit\". It's not as simple as you are making it out.\nThe other problem, is that extension writers aren't thinking about side-by-side, these issues are only found after they've shipped and playing in an extension ecosystem. If you want to run these plug-in environments (and it sounds like Octokit does), then you want to make sure these things \"just work\".\n. @gluck \n\nOctokit has some static state (not arguing it's clean code :tm:), Extension1 wants it set to A, Extension2 wants it set to B, it works if they don't use the same Octokit library, and starts breaking when they match (and both are installed).\n\nThat won't happen in a LoadFrom side-by-side world. Both extensions will see a separate copy of Octokit (assuming it's strong named).\n. @iancooper \n\nBut do we think that extensions are a big enough use case that we should sign every assembly within a package manager? \n\nThat's exactly for you guys to figure out. :) \nEveryone can look back with hindsight (wonderful thing isn't it) and agree that strong naming is a complex over-engineered system, but if you look back with what they were trying to solve (sandboxing + dll hell), it would have made a lot of sense at the time. Now with sandboxing dead, everyone equates strong naming == strict binding policy. \nWe can make blanket statements like \"no one should strong name\" but this isn't a solution. I think it is unrealistic to think that the ecosystem is going to change overnight to stop using strong naming (especially given there are existing requirements for being strong named), therefore I think time would be better spent coming up with short-term and long term strategies to make this painless.\nDo we have a current list of pain points that you run into when you start strong naming? Here's the ones I've gathered:\n1. Binding policy - requiring consumers to apply binding redirects if they have a versioning conflict\n2. The annoyance with needing to create a strong name key, associate multiple projects with it (VS tooling doesn't help with this)\n3. Being able to rebuild a OSS binary from same sources, drop it in as a replacement and have it just run (for example, MVC)\nAre there more?\n. @damianh @paulcbetts Can you provide more information about the ongoing pain of strong names? ie Once gone through the pain of strong naming, and checked the private key into the tree. What is the ongoing pain? Is it just the binding policy? Or is there something else that I'm missing?\n. @mythz Can you write 1 or 2 sentences of the friction both on you and your consumers? Not trying to troll here, want to make sure that my team (.NET Framework) aren't missing any pain points here.\n. (Standard disclaimer: This is entirely my opinion and does not represent Microsoft's)\n@PureKrome Good question. There's not a single bit that we can flip and everything is good[1]. The foundation of a significant number of features are built on top of them. The ones that I can think of the top of my head are: GAC, cross-AppDomain sharing, partial trust, framework unification, retargeting/portability (mscorlib-based PCL), fusion, shadow-copying, binding policy (publisher/machine/app policy, codebase refs, etc), app-local security servicing, side-by-side assembly loads, SQL CLR, plus a few more internal (to the CLR) features. This does not include any downstream impact on the tools & infrastructure built on top of the framework[2]\nIf we were to completely remove the concept of strong names, we would need to make a decision about existing features that use it, do we remove the feature completely (partial trust would probably be an example in this bucket)? Or do we tweak these features (like Jared mentioned) to move away from requiring strong names (app-local security servicing would probably be an example)?\nIf we do the former, this new framework looks very different to the previous version, and massively hurts adoption because a lot of code that relied on the features need to be changed or rewritten.\nAs with any feature in any given project, the later needs to be offset against other features[3], and/or alternatives that could achieve similar result. For example, Phone[4], Silverlight & Store inherited strong names - but not the binding policy that required a strict match. This for the most part removed the \"in your face\" part of strong names from those platforms. @davidfowl also proposed removing the viral-ness of strong names, which would enable enterprises that opt'd into strong names, to reference OSS projects that didn't.\nThoughts?\n[1] Funnily enough we have tens of other conditional/#if'd for a lot of features from v1/v2, including COM, serialization, generics, but not strong names! :)\n[2] A good example would be any tool that made a decision on key to do something different. For example, I know immediately that some of the designers in VS and Blend would be broken by removing strong names.\n[3] Have you seen our new JIT? What about .NET Native?\n[4] Phone went as far as hiding the UI for creating strong names from project properties.\n. Thanks folks. Appreciate the feedback. For those that want provide feedback back to my team offline, you can contact me offline via my github alias @ microsoft.com.\n. ",
    "avanderhoorn": "Not sure if this helps and may have already been covered (this is way too much for me to read through atm), but the way we solved this with Glimpse is by publish an unsigned copy to Nuget and we try and make it easy for people to sign if they want to.\nFor us this has been discussed a few time, most notably:\n- https://groups.google.com/forum/#!topic/getglimpse-dev/pXXazMOOdjE\n- https://github.com/Glimpse/Glimpse/issues/324\n. ",
    "jaredpar": "@rprouse the other option is to simply rename the Octokit DLL that you reference in your VS extension from octokit.dll to octokit-mine.dll.  That will prevent load collisions with other extensions.\nThe scenario laid out by @davkean is very real and something I deal with daily.  Today I use SN on my extension libraries because it's easy and it works.  Using a mangled DLL name would also solve the problem but it does have a bit more overhead than SN.  Probably some .csproj changes or a post-processing step.  \nPerhaps the first step is simply showing people how to do this properly?  Give people an existing solution to pattern off of.  Maybe there is already one available that I'm missing.  If so please do point me towards it.  But until there is a tutorial / guide out there to not using SN for this scenario I don't think there will be much initiative to change.  \nYes I realize I could help write that guide.  May do it the next time I find myself with a bought of insomnia \n. @PureKrome \n\nCan't it be removed from .Net vNext & VS vNext ... \n\nThis question requires more context.  Anything in .Net can be removed if you are willing to pay the price involved for removing it :) \nI think a better way of going about this is to list the capabilities that SN provides or SN is relied upon for.  The ones I'm aware of are as follows (probably missed a few) \n1. It is a pre-requisite for inclusion in the GAC\n2. It allows for SxS in process execution of different assembly versions \n3. Binding redirect policies\nIf SN was removed it's hard to see how the GAC could be reliably implemented.  It's rooted in the idea of strong versioning.   If SN was removed then presumably anyone could overwrite anyone else's assembly in the GAC hence it loses its authoritative nature.  I'm sure plenty of people on this thread would like to see the GAC die though but fact is that it's there, it's heavily used and IMHO there is no way Microsoft will give up on it.  \nSN is not a requirement for 2 but just a handy convenience.  If you removed SN people could just start mangling assembly names to get the same effect.  \nI'm not enough of an expert on 3 to comment too intelligently about it.  Others in this thread have covered this though.\n. Experimentally I've found that i'm actually hurting myself here with ApiOptions.  If I forgo pagination and use the overload without ApiOptions the same call completes in just a few seconds.  \nAm I just using ApiOptions in some unsupported way here? \n. @dampir good call.  Switching StartPage to 1 fixed the issue.  \nIn general though is this the correct way to approach queries where a large number of issues are going to be returned?  Or if I'm going to process them all in batch anyways should I just query without any pagination? \n. @shiftkey once you know it's 1 based it's pretty easy to use.  \nI think the only way to make it clearer is to error in some way in the case of a 0 value.  It seems like that would be possible given the structure of ApiOptions.  But I've only used this API in a pretty limited fashion, so it's possible I'm not considering valid use cases.  \n\nIf you're not really looking for a specific page of results, and just want stuff faster than the defaults, I'd just set the PageSize:\n\nI was mostly trying to be conscious of now downloading the entire dotnet/roslyn issue database in a single go \ud83d\ude04.  Paging seemed to be the best way to achieve that. \n. Thanks for the work around.  That got me unblocked.\n. > I just want to clarify with @jaredpar you said this is how you expect it to work, not necessarily that it used to work like this and has since changed, right?\nCorrect.  The code sample I posted is just my expectation of how the API should work. . ",
    "EddieGarmon": "The failure is not in SN. It is in the devs and tools that do not know how to do proper SxS deployment, which is what SN was designed to solve.\nTools such as VS, and especially Nuget are to blame for the issues with improper sub-dependency version conflicts (ie JSON.Net). Nuget should know the version specific assembly dependency graph, and automatically do correct side by side deployments. I originally made sure Simple.Owin would support multiple versions in one app domain. See App.config and DempApp.csproj in eddiegarmon/simple.owin@b8bfbc91678992c6bc2db552638668b55ac899b2 as an example of what the tools should do.\nDon't blame SN, blame and fix the tools\nBy not strong naming, all you are going to do is limit the number of possible consumers.\n. Demis, I agree it should have never existed, but it does, and we the OSS .NET community have to live with it whether we like it or not.\nThere are really only 3 things WE the community can do:\n1 - Don't strong name, and limit our user base (tell the others to just buck-up cowboy, how sweet)\n2 - Sign with a song and dance convention that doesn't really solve the problem. (probably works in most cases)\n3 - Teach everyone to do proper SxS or Fix the tools. Don't tell me its my responsibility to add the feature, or that I am bowing to the Enterprise. SxS is a core tenant of library consumption, just do it right. Nuget was supposed to make it easy for everyone to use cool new bits, with a right click. When you propose that enablement scenario, you get what you asked for, usage by the non-trained. \n. ",
    "DavidZidar": "A little late to the party and this may not be relevant to Octokit.net, but imagine you are building a WPF application that you want to deploy via ClickOnce and you find this great library that does a lot of fancy stuff you need.\nBut it just happens that ClickOnce requires signed assemblies, so you try to use ILMerge, but ILMerge does not support WPF. Now you're in a world of pain.\n. ",
    "FransBouma": "I think a lot of problems already will go away if the strict binding policies with assemblies is changed a bit. Today, an assembly has a version with 4 elements: Major.Minor.Build.Revision. It doesn't matter however which one is changed: if the assembly has a strong name, the assembly is seen as different by Fusion and it requires a redirect. \nIf this is changed a bit, it will solve a lot of problems: What if fusion looks at it this way: All assemblies which share the same strong name and the same Major.Minor.Build version are equal, and the one with the highest Revision number is loaded. This is then controlled by an assembly scoped attribute which is by default 'off' (so if it's not there, Fusion will use the old behavior). One could extend this to let that controlling attribute tell Fusion which elements in the version can be considered 'equal' among all versions, it gives full control over what's loaded to the developer, as it should be, as the developer knows whether a change is breaking or not. \nThis way, one could fix non breaking bugs in an assembly, strong name it and simply bump the Revision number. With the additional attribute in place in the assembly, it's just a drop-in replacement, no redirects needed. If a breaking change is added, the developer can decide to bump the build nr or minor version, to make sure the user of the assembly recompiles their code and is aware that the change is breaking: a drop-in replacement won't work, as intended, as it's a breaking change.\nThis also solves the need for the workaround of using the fileversion as the real version with a revision number, as changing that today doesn't ripple down to users of your assembly when a bugfix release is published. \nI for one need strict binding policy based on versions. I don't care whether an assembly is signed or not, I think no-one really does these days, the main issue is solely about the version based binding. My runtime ships with OData support code, however as it has to support OData v1-3, I have to reference the WCF Data Services 5.6.1 assembly. There's a v6.x already but it ships with OData v4 only and isn't backwards compatible. Without strict binding policies, it would be expected that my code will load WCF Data Services v6.x, which shouldn't happen, the dependency is on v5.6.x \nThis is just an example. As my runtime is in the middle of app -> runtime -> another_assembly, one would think that without strong names my life would be easier as changes in the strong name of 'another_assembly' would go away, but those are solely related to binding policy and it is required that I control the dependency on 'another_assembly', as a breaking change in 'another_assembly' will break my runtime and therefore 'app'. No binding policy, no way to control that dependency. \nAnd please 'nuget already solved that' isn't correct. Not every assembly is on nuget.\n@khellang: it's enforced to ensure that the whole 'chain' is secure/trustworthy. At least that was the theory from 10+ years ago when signatures were still checked. A->B->C. If A is signed, it doesn't mean anything unless B is signed too. \n. @davidfowl aren't assembly versions ignored if the assembly isn't strongly named? I.e. isn't Fusion loading the one with the highest version number no matter what the reference says? http://support.microsoft.com/kb/556041\nI.o.w.: if assemblies aren't strongly named, versions are ignored, which makes it impossible to take a dependency on vX.Y.Z \n. ",
    "skoon": "What if we added strong name redirection? \n\n. ",
    "philoushka": "I'm interested in contributing to this. I'm confused though on why the push event would be excluded. It's actually the one class I'm interested in using in my app. Why is the push is being excluded?\nBelow is a screen cap of what's actually being sent for a push. It's a bit different from the documented Push event!\n1. Would you accept a Push model class along with the other events?\n2. If so, how should I deal with the difference between the documented push event and the actual data being pushed?\n\n. ",
    "erichexter": "Would you take implementations for the Create and Delete Payloads ?\nIf so, what else needs to be done for this? \n- [ ]  implementing the classes in the ActivityPayloads folder.\n- [ ] Add serialization tests to https://github.com/octokit/octokit.net/blob/master/Octokit.Tests/Clients/EventsClientTests.cs\n. I saw that method, I just assumed, it would not include the issue events in that repo, looking at the api docs, it made me think, it would just include team member adds, and other repo level events.  I will try that out and see I was just being an ID10T.\n. That seems to be working for me.  It would be nice if the rest endpoint supported some filtering, so that I could just pull down the event types I am looking for, but this seems to do the jop  Thanks @shiftkey \n. I still get this error: on nuget version 7.1, Is this a different problem?\nI see the following line which stripes out hyphens but not the underscores. \nhttps://github.com/octokit/octokit.net/blob/4d2bc143b305e65d59ed8d8404f6e1b1e5858dbb/Octokit/Http/SimpleJsonSerializer.cs#L93\nException:\nRequested value 'head_ref_deleted' was not found.\nException Details: System.ArgumentException: Requested value 'head_ref_deleted' was not found.\nSource Error: \nLine 42: \nLine 43:             IReadOnlyList response = await client.Issue.GetForRepository(user, repository, new RepositoryIssueRequest() { State = ItemState.All });\nLine 44:             IReadOnlyList events = await client.Issue.Events.GetForRepository(user, repository);\nStack Trace: \n[ArgumentException: Requested value 'head_ref_deleted' was not found.]\n   System.EnumResult.SetFailure(ParseFailureKind failure, String failureMessageID, Object failureMessageFormatArgument) +4288471\n   System.Enum.TryParseEnum(Type enumType, String value, Boolean ignoreCase, EnumResult& parseResult) +11176061\n   System.Enum.Parse(Type enumType, String value, Boolean ignoreCase) +78\n   Octokit.Internal.GitHubSerializerStrategy.DeserializeObject(Object value, Type type) in c:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Http\\SimpleJsonSerializer.cs:94\n   Octokit.PocoJsonSerializerStrategy.DeserializeObject(Object value, Type type) in c:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\SimpleJson.cs:1449\n   Octokit.Internal.GitHubSerializerStrategy.DeserializeObject(Object value, Type type) in c:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Http\\SimpleJsonSerializer.cs:118\n   Octokit.PocoJsonSerializerStrategy.DeserializeObject(Object value, Type type) in c:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\SimpleJson.cs:1476\n   Octokit.Internal.GitHubSerializerStrategy.DeserializeObject(Object value, Type type) in c:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Http\\SimpleJsonSerializer.cs:118\n   Octokit.SimpleJson.DeserializeObject(String json, Type type, IJsonSerializerStrategy jsonSerializerStrategy) in c:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\SimpleJson.cs:580\n   Octokit.SimpleJson.DeserializeObject(String json, IJsonSerializerStrategy jsonSerializerStrategy) in c:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\SimpleJson.cs:592\n   Octokit.Internal.SimpleJsonSerializer.Deserialize(String json) in c:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Http\\SimpleJsonSerializer.cs:21\n   Octokit.Internal.JsonHttpPipeline.DeserializeResponse(IResponse response) in c:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Http\\JsonHttpPipeline.cs:66\n   Octokit.d__1f1.MoveNext() in c:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Http\\Connection.cs:437\n   System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) +93\n   System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +52\n   System.Runtime.CompilerServices.ConfiguredTaskAwaiter.GetResult() +24\n   Octokit.Internal.<GetNextPage>d__0.MoveNext() in c:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Http\\ReadOnlyPagedCollection.cs:31\n   System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) +93\n   System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +52\n   System.Runtime.CompilerServices.ConfiguredTaskAwaiter.GetResult() +24\n   Octokit.<GetAllPages>d__01.MoveNext() in c:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Clients\\ApiPagination.cs:28\n   System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) +93\n   System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +52\n   System.Runtime.CompilerServices.TaskAwaiter1.GetResult() +24\n   OctokitDemo.Controllers.<Create>d__3b.MoveNext() in c:\\Users\\Eric\\Documents\\Github\\octokit-oauth-demo\\OctokitDemo\\Controllers\\Cfd.cs:44\n   System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) +93\n   System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +52\n   System.Runtime.CompilerServices.TaskAwaiter1.GetResult() +24\n   OctokitDemo.Controllers.d__d.MoveNext() in c:\\Users\\Eric\\Documents\\Github\\octokit-oauth-demo\\OctokitDemo\\Controllers\\HomeController.cs:85\n   System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) +93\n   System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +52\n   System.Runtime.CompilerServices.TaskAwaiter.GetResult() +21\n   System.Threading.Tasks.TaskHelpersExtensions.ThrowIfFaulted(Task task) +61\n   System.Web.Mvc.Async.TaskAsyncActionDescriptor.EndExecute(IAsyncResult asyncResult) +114\n   System.Web.Mvc.Async.<>c__DisplayClass37.b__36(IAsyncResult asyncResult) +66\n   System.Web.Mvc.Async.WrappedAsyncResult1.CallEndDelegate(IAsyncResult asyncResult) +47\n   System.Web.Mvc.Async.WrappedAsyncResultBase1.End() +135\n   System.Web.Mvc.Async.AsyncResultWrapper.End(IAsyncResult asyncResult, Object tag) +102\n   System.Web.Mvc.Async.AsyncControllerActionInvoker.EndInvokeActionMethod(IAsyncResult asyncResult) +49\n   System.Web.Mvc.Async.AsyncInvocationWithFilters.b__3d() +117\n   System.Web.Mvc.Async.<>c__DisplayClass46.b__3f() +323\n   System.Web.Mvc.Async.<>c__DisplayClass33.b__32(IAsyncResult asyncResult) +44\n   System.Web.Mvc.Async.WrappedAsyncResult1.CallEndDelegate(IAsyncResult asyncResult) +47\n   System.Web.Mvc.Async.WrappedAsyncResultBase1.End() +135\n   System.Web.Mvc.Async.AsyncResultWrapper.End(IAsyncResult asyncResult, Object tag) +102\n   System.Web.Mvc.Async.AsyncControllerActionInvoker.EndInvokeActionMethodWithFilters(IAsyncResult asyncResult) +50\n   System.Web.Mvc.Async.<>c__DisplayClass2b.b__1c() +72\n   System.Web.Mvc.Async.<>c__DisplayClass21.b__1e(IAsyncResult asyncResult) +185\n   System.Web.Mvc.Async.WrappedAsyncResult1.CallEndDelegate(IAsyncResult asyncResult) +42\n   System.Web.Mvc.Async.WrappedAsyncResultBase1.End() +132\n   System.Web.Mvc.Async.AsyncResultWrapper.End(IAsyncResult asyncResult, Object tag) +56\n   System.Web.Mvc.Async.AsyncControllerActionInvoker.EndInvokeAction(IAsyncResult asyncResult) +40\n   System.Web.Mvc.Controller.b__1d(IAsyncResult asyncResult, ExecuteCoreState innerState) +34\n   System.Web.Mvc.Async.WrappedAsyncVoid1.CallEndDelegate(IAsyncResult asyncResult) +70\n   System.Web.Mvc.Async.WrappedAsyncResultBase1.End() +138\n   System.Web.Mvc.Async.AsyncResultWrapper.End(IAsyncResult asyncResult, Object tag) +59\n   System.Web.Mvc.Async.AsyncResultWrapper.End(IAsyncResult asyncResult, Object tag) +40\n   System.Web.Mvc.Controller.EndExecuteCore(IAsyncResult asyncResult) +44\n   System.Web.Mvc.Controller.b__15(IAsyncResult asyncResult, Controller controller) +39\n   System.Web.Mvc.Async.WrappedAsyncVoid1.CallEndDelegate(IAsyncResult asyncResult) +62\n   System.Web.Mvc.Async.WrappedAsyncResultBase1.End() +138\n   System.Web.Mvc.Async.AsyncResultWrapper.End(IAsyncResult asyncResult, Object tag) +59\n   System.Web.Mvc.Async.AsyncResultWrapper.End(IAsyncResult asyncResult, Object tag) +40\n   System.Web.Mvc.Controller.EndExecute(IAsyncResult asyncResult) +39\n   System.Web.Mvc.Controller.System.Web.Mvc.Async.IAsyncController.EndExecute(IAsyncResult asyncResult) +39\n   System.Web.Mvc.MvcHandler.b__5(IAsyncResult asyncResult, ProcessRequestState innerState) +39\n   System.Web.Mvc.Async.WrappedAsyncVoid1.CallEndDelegate(IAsyncResult asyncResult) +70\n   System.Web.Mvc.Async.WrappedAsyncResultBase1.End() +138\n   System.Web.Mvc.Async.AsyncResultWrapper.End(IAsyncResult asyncResult, Object tag) +59\n   System.Web.Mvc.Async.AsyncResultWrapper.End(IAsyncResult asyncResult, Object tag) +40\n   System.Web.Mvc.MvcHandler.EndProcessRequest(IAsyncResult asyncResult) +40\n   System.Web.Mvc.MvcHandler.System.Web.IHttpAsyncHandler.EndProcessRequest(IAsyncResult result) +38\n   System.Web.CallHandlerExecutionStep.OnAsyncHandlerCompletion(IAsyncResult ar) +129\n. Boom, mic drop. You guys are all over this. good stuff\n. That made my day\nOn Tuesday, February 24, 2015, Phil Haack notifications@github.com wrote:\n\n[image: thumbsup-lift-head]\nhttps://cloud.githubusercontent.com/assets/19977/6362095/0f9b21e4-bc3e-11e4-88e5-b6c0a7b9877a.gif\n\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/720#issuecomment-75877942.\n\n\nEric Hexter\nblog | http://Hex.LosTechies.com\ninfo | http://www.linkedin.com/in/erichexter\n. It is a public repository. I got the error running the command on\nhttps://github.com/waffleio/waffle.io\nEric Hexter\nblog | http://Hex.LosTechies.com\ninfo | http://www.linkedin.com/in/erichexter\nOn Mon, Mar 9, 2015 at 4:36 AM, Brendan Forster notifications@github.com\nwrote:\n\n@erichexter https://github.com/erichexter perhaps this is something\nmissing from the docs - is this a public repository I could run a test\nagainst to confirm this behaviour?\n\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/738#issuecomment-77823441.\n. So I was using client.Issue not client.Activity \n\nclient.Issue.Events.GetForRepository(user, repository);\n. It is consistent on azure, not super critical for me as this is just a\nlarge repo I use to test my app (and the api). I will contact some of my\nazure friends to see if they can shed some light on this and maybe this\nwould go into some sort of FAQ on the wiki (?)\nEric Hexter\nblog | http://Hex.LosTechies.com\ninfo | http://www.linkedin.com/in/erichexter\nOn Mon, Mar 23, 2015 at 5:02 PM, Brendan Forster notifications@github.com\nwrote:\n\nSocketException (0x271d): An attempt was made to access a socket in a way\nforbidden by its access permissions]\nIs this consistently occurring on Azure?\nThis looks like it's an environment-specific problem, not quite sure what\nI can do from Octokit itself to address this...\n\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/775#issuecomment-85222883.\n. I did not, I was able to reproduce it but I ended up moving my project to a\nvirtual machine and I never had this problem. If you have a simple test\ncase to reproduce it I can connect you with a azure architect who said he\nwould troubleshoot it.\n\nOn Thursday, May 21, 2015, jbkielis notifications@github.com wrote:\n\nWere you ever able to find out the cause of this issue? Thanks.\n\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/775#issuecomment-104395632\n.\n\n\nEric Hexter\nblog | http://Hex.LosTechies.com\ninfo | http://www.linkedin.com/in/erichexter\n. ",
    "wfroese": "Is that what you were looking for?\n. I did. The commit history looks like it contains everything in master as well. And now the build is failing too, so I'll look into that...\n. It looks like the latest thing merged into master is pull request #410, and the build is now telling me that a file from that commit is missing in Octokit-MonoAndroid.csproj, Octokit-Monotouch.csproj, etc.\nNot really sure where to go from here...\n. If it still won't let you merge, then I'm at a loss unfortunately. Doing a fetch does nothing (because it's presumably up to date), and the same happens for merging master into this branch. \n. Oh geez. Thanks Phil!\n. ",
    "heytherewill": "Will new InvalidGitignoreTemplateException(\"gitignore_template is an unknown gitignore template.\"); suffice?\n. What's the current status of this one? Are any bits of this closed PR relevant? May I start working on it?\n. I really wanna get my feet wet on OSS, and this bug seems like a good start. Can I call it mine and fix it? \nAlso, I can't think of a name other than CommitCommitter lol\n. @shiftkey Okay, I'll take a look at it this weekend. Just commenting here to let everyone aware :)\n. May I? Should I?\n. I agree, I just wanted something to work on while I travel :disappointed: \n. Oh, boy, the test failed\n\n. All set! If anything else needs to be done, just let me know once this gets reviewed, @Haacked\n. My bad, didn't know about this one. But why was GitHubCommit changed back to use Author instead of Committer? (that was the initial issue)\n. hmm, it seems like the build failed due to #904 \n. Should I wait until the bug is fixed to continue with this one or use the EndsWith alternative?\n. ",
    "hknielsen": "Have you testet your compare on the live API? Since your datamodel is not correct. I startet to make mine the same way but the commit model is not good enough :)\nLook at this: https://github.com/hknielsen/octokit.net/commit/9c17bd3db8ec77dd5d2383bc312182131a758be4\n. @shiftkey As I can see you just count the commits, but not whats in them. The Commit model has a extra level, so you wont get the message or tree.\nYou could just add it here, since it does not really show anything about the commit besides the sha that you can use?\n. @shiftkey If you wont do it, I can just add it based on you pull request? :) the problem is I need the messages in the commit, thats why im so focust about it\n. :+1: thanks\n. When will this get merged?\n. no problem, nice work :) ive updated from the comments,pushed it too fast without reviewing it myself :D so thanks for the the comments\n. Hmm somehow the projects:\nOctokit-Monotouch\nOctokit-MonoAndroid\nFails for me, I cant open them in VS, but then I wonder why all the projects need them added, why not have a model assembly so they automatically added?\n. Done :) thanks awesome!\n. @shiftkey @Haacked  Yes perfect, good that it isnt a complex implementation :) If you just change your model ill close my pull request\n. Closing pull request cause duplicate in logic from #428\n. Maybe the method should return a list of refs? Since the API can return it like this\n. Yes, but if there is only one element it looks like its not an array of items but only that item, a little annoying :)\n. @Haacked  yeah, ill maybe have a pull request tomorrow if you guys havet added anything \n. Ah I see, never used that atribute but I can now see how its used :) ive decided that the inherited class had the necessary information for this class\n. ah :D fail\n. needs the DebuggerDisplay\n. ah sorry yes :P\n. Fody looks interresting, but needs alot of work when adding to a large project :) But something thats needed to get looked at\n. One of the reasons for needing the line ending is so you can stage lines and hunks in git gui, if there is no line endings it will give an error.\n. Yes I agree, have been thinking about making one that works and is better then that awfull tool :)\nIn my team we have made stylecop apart of the solution build so it always checks for the lineending, dont know if code analyzer have the same option but its maybe its something to add \n. ",
    "drusellers": ":+1: \n. What's the current blocker? Is there a punch list of what needs doing?\n. :+1: \n. ",
    "Woland2k": "Just in case someone really wants to use new Contents API before the official merge is done, I created an implementation for delete/create/update APIs. It is very raw, but at least you don't have to it yourself. Here is a fork: https://github.com/VirtoCommerce/octokit.net\n. Great, can't wait to see the updates!\n. ",
    "jasonrudolph": "\nI vaguely remember a discussion with the API team about size not being accurate and deprecated. \nI was told it wasn't worth using.\n\nThat's good advice. :-)\nThe size property represents KB on disk, but it can be wildly misleading for repositories with many forks due to the way git stores the network on disk. Since the size property is not a reliable/intuitive source of information, we will likely remove it in a future version of the API.\n. > The one thing I haven't had time to determine is what happens on the GitHubCommit response if it couldn't match up the Author with an account. I assume it just returns the simple form. @pengwynn @jasonrudolph do you know what happens for sure? I'd love a pointer to the code. :smile:\nIf the author doesn't map to a GitHub account, then the top-level author attribute has a null value. The same goes for the committer. Example:\ncurl https://api.github.com/repos/android/platform_system_core/commits/8731d30085b02012487552d8ad6d95c0ac9a8d4d\njs\n{\n  \"sha\": \"8731d30085b02012487552d8ad6d95c0ac9a8d4d\",\n  \"commit\": {\n    \"author\": {\n      \"name\": \"Sami Tolvanen\",\n      \"email\": \"samitolvanen@google.com\",\n      \"date\": \"2015-09-28T15:43:43Z\"\n    },\n    \"committer\": {\n      \"name\": \"Sami Tolvanen\",\n      \"email\": \"samitolvanen@google.com\",\n      \"date\": \"2015-09-28T15:52:38Z\"\n    },\n    // ...\n  },\n  // ...\n  \"author\": null,\n  \"committer\": null,\n  // ...\n}\n. Thanks for digging into this, @shiftkey. :zap:\n\n@jasonrudolph anything I've missed here?\n\nMy C# leaves much to be desired, but @kdaigle and I sketched out this plaintext spec that might help answer your question:\n\n\nMUST follow redirect requests if HTTP status code is 301, 302, or 307. (These are the redirect codes actively used by the GitHub API.)\nMUST redirect a 30x status code if the HTTP method is HEAD, OPTIONS, GET, POST, PUT, PATCH, or DELETE.\nMUST use the original request's HTTP method when following a redirect where the HTTP status code is 307.\nSHOULD use the original request's HTTP method when following a redirect where the HTTP status code is 301 or 302.\nMUST use the original request's authentication credentials when following a redirect where the original host matches the redirect host.\nMUST NOT use the original request's authentication credentials when following a redirect where the original host does not match the redirect host.\nSHOULD only follow 3 redirects.\n\n\nDoes that help?\n. > The 301 and 302 behaviour is now different to what HttpWebRequest does by default.  But the new behaviour is what was originally intended for 301/302. (Possibly the most useful diagram I have ever seen on this subject is here https://tools.ietf.org/html/rfc7238#section-1)\n@darrelmiller: Thanks for linking to that diagram. Wonderfully succinct and useful. :zap:\n. @darrelmiller @shiftkey: :clap: :star2:\n. This specific design decision predates my work on the API. Changing it would break existing clients that depend on the current behavior. So, we expect it to continue to work this way for the foreseeable future.\n. > So I suppose my question still stands how best to resolve this issue of the Contents API either returingn a single JSON object or an array.\nIf you need to predetermine whether the response will be an array or a hash, you could get that information by fetching the contents of the parent directory first. For example, suppose you want to make this request:\nGET https://api.github.com/repos/twbs/bootstrap/contents/js\nAnd you want to know whether the response will be an array or a hash. You could first make a request to:\nGET https://api.github.com/repos/twbs/bootstrap/contents\nThe response will provide an array of items in the root directory:\n...\n  {\n    \"name\": \"js\",\n    \"path\": \"js\",\n    ...\n    \"type\": \"dir\",\n   ...\n  },\n...\nIf the type is dir, you will know that it's a directory. With that information, you can safely expect to get an array in response to this request:\nGET https://api.github.com/repos/twbs/bootstrap/contents/js\nDoes that help?\n. ",
    "bursteg": "I have implemented the code required to add the contents suppurt to the blobs client. I am happy to share or contribute back if you want.\n. ",
    "chester89": "I just entered https://api.github.com/repos/:owner/:repo/releases in my\nbrowser and I got 304 Not modified and an empty JSON array. I guess that\nmeans I can access the repository.\n2014-04-08 1:07 GMT+04:00 Brendan Forster notifications@github.com:\n\nI think you're hitting on a permissions issue here.\nCan you try this snippet here (replace with the right details, of course)\nto see if you can reach the /repos/:owner/:repo/releases endpoint (instead\nof a specific release as you've been doing in the above case):\nvar client = new GitHubClient(new ProductHeaderValue(\"appName\"));\nclient.Credentials = new Credentials(login, password);\nvar releases = client.Releases.GetAll(\"owner\", \"repo\").Result;\nIf that one is also returning a 404, I'd recommend contacting GitHub\nSupport so we can troubleshoot further...\n\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/issues/448#issuecomment-39783847\n.\n\n\n\u00f3 \u00d5\u00d7\u00c1\u00d6\u00c5\u00ce\u00c9\u00c5\u00cd,\n\u00fe\u00c5\u00d2\u00cd\u00a3\u00ce\u00ce\u00cf\u00d7 \u00e7\u00cc\u00c5\u00c2,\n\u00d4\u00c5\u00cc. (916) 314-9324\n. The explanation does make sense, except that I'm sure repo have releases -\nthey are on the \"Releases\" page.\nI just tried getting first release and got this:\n{\n  \"message\": \"Not Found\",\n  \"documentation_url\": \"https://developer.github.com/v3\"\n}\n2014-04-08 3:07 GMT+04:00 Brendan Forster notifications@github.com:\n\nI got 304 Not modified and an empty JSON array.\nNot sure about the 304 Not Modified (that could just be browser headers\ntriggering caching) but the empty JSON array makes me think the repository\ndoesn't have any releases associated with it - which means trying to get\n/repos/:owner/:repo/releases/1 is properly failing as expected - because\nthe release doesn't exist...\nDoes that make sense?\n\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/issues/448#issuecomment-39794788\n.\n\n\n\u00f3 \u00d5\u00d7\u00c1\u00d6\u00c5\u00ce\u00c9\u00c5\u00cd,\n\u00fe\u00c5\u00d2\u00cd\u00a3\u00ce\u00ce\u00cf\u00d7 \u00e7\u00cc\u00c5\u00c2,\n\u00d4\u00c5\u00cc. (916) 314-9324\n. Sure, will do.\n2014-04-08 3:12 GMT+04:00 Brendan Forster notifications@github.com:\n\nI need more information about the scenario that's triggering this - can\nyou email support@github.com with some details so we can discuss this\nfurther?\n\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/issues/448#issuecomment-39795119\n.\n\n\n\u00f3 \u00d5\u00d7\u00c1\u00d6\u00c5\u00ce\u00c9\u00c5\u00cd,\n\u00fe\u00c5\u00d2\u00cd\u00a3\u00ce\u00ce\u00cf\u00d7 \u00e7\u00cc\u00c5\u00c2,\n\u00d4\u00c5\u00cc. (916) 314-9324\n. ",
    "kzu": "Rebased and fixed remaining conflicts. \nI need this merge so that I can continue working on the rest of Teams API ;)\n. don't merge yet. got a build error\n. Now it's ready :)\n. Done :)\nJust noticed how the CI works :)\nAlso added missing null checks\n. Done! :)\n. Hehe, you're welcome. I'll work more on the team client since I need all the functionality of the underlying github API, a lot of which is missing currently. Hopefully I'll find the time sooner than later :)\n. +1!\n. +1 to private repos!!!\n. Now it's ready :). /cc @Haacked \n. kindly requesting a new release that contains the fix :)\n/cc @Haacked \n. The shipped Octokit 0.5.3 does not include this commit :(\n. > publish preview builds to MyGet\nWhat's the feed for that?\n. Found it: https://www.myget.org/F/octokit \n:)\n. FWIW, this is a blocker in our case for using the library :(. Verified the fix by pushing this PR from the AppVeyor artifact to https://www.nuget.org/packages/Kzu.Octokit and updating my azure function that uses the previously failing github statuses. It now works like a charm :)\nSo, no longer a blocker, but would surely like to drop using the (unlisted) PR package.. @ryangribble makes sense to migrate over to long elsewhere. Maybe that could be part of another issue/pr? For my limited (and immediate) blocker, the CommitStatus is the only place where I've found this to be an issue (so far). \nAmended the commit to include the ctor type change. \nThanks!. I think so. Even for organization tests, you always needs a valid user with ownership of the org. \nTeam tests don't work for users since it appears only orgs can own teams (just realized of this because I got errors trying with a user, and it's not doable on the website either)\n. CONTRIBUTING.md doc updated!\n. ",
    "hmemcpy": "\n. ",
    "JacobCZ": "First, i'd like to apologise if my ticket sounded offensive, but i was a bit angry... By documentation i mean a website or at least a text document, where all the functions will be described and maybe even with some examples like authorization etc...\n. @shiftkey maybe if you make a wiki in this repo and give me access to it, i may be able to dig through the in-code doc and put together some tutorials/examples/whatever...\n. @Haacked sure, but i think it's better to have it \"under one hood\"... And the wiki is made for this so..\n. @Haacked all right... so, when you make it, please let me know, i'd like to help you with the docs..\n. ",
    "Papalamus": "Sorry for  intervening, but is there a way to request list of public repositories as in https://developer.github.com/v3/repos/#list-all-public-repositories  ?\n. ",
    "M3gaFr3ak": "thanks\n. ",
    "shiftkey-tester": "Don't actually merge this in\n. Let's not break this yet. We've got a few things we should clean up that are far more urgent than this...\n. This should be ## not  ###\n. ",
    "GavinOsborn": "Will do.\n. This issue is about the inconsistent nature of a single class - one way or another this will get fixed by #479. I'll not submit a PR for this.\n. ",
    "nfMalde": "Hi, i checked now the Release. The ID is correct.\nAlso like in your Example i removed the .Wait();  but also no result.\nHere my code: \n``` c#\n        GitHubClient client = new GitHubClient(new ProductHeaderValue(\"MyAmazingApp\"));\n        client.Credentials = new Credentials(AccessToken);\n        var releaseCLient = client.Release;\n\n        Stream str = new MemoryStream();\n        var _bytes = File.ReadAllBytes(ReleaseZipPath);\n        str.Write(_bytes, 0, _bytes.Length);\n\n\n        var rT = releaseCLient.UploadAsset(_release, new ReleaseAssetUpload()\n        {\n            ContentType = \"application/zip\",\n            FileName = Path.GetFileName(ReleaseZipPath),\n            RawData = str\n        });\n\n```\nif i wait for the task, I  get the same Error Message like above. \n. Sure :-)\nI first installed now  Fiddler. Never used it Sorry ^^\nRequest:\ntext\nPOST /repos/nfMalde/Ren.CMS.NET/releases/302963/assets?name=v0_1_01_fullPackage.zip HTTP/1.1\nAccept: application/vnd.github.v3\nUser-Agent: MyAmazingApp (Win32NT 6.2.9200; amd64; de-DE; Octokit 0.3.4)\nAuthorization: < CENSORED >\nContent-Type: application/zip\nHost: uploads.github.com\nContent-Length: 0\nAccept-Encoding: gzip, deflate\nResponse:\ntext\nHTTP/1.1 422 status code 422\nCache-Control: no-cache\nContent-Length: 252\nContent-Security-Policy: default-src 'none'\nContent-Type: application/json; charset=utf-8\nStrict-Transport-Security: max-age=2592000\nX-Accepted-Oauth-Scopes: repo\nX-Content-Type-Options: nosniff\nX-Frame-Options: deny\nX-Github-Media-Type: github.v3\nX-Github-Request-Id: 233d3c3d-d3e4-11e3-8926-84ca9bcf5de2\nX-Oauth-Scopes: gist, repo, user\nX-Xss-Protection: 1; mode=block\nDate: Sun, 04 May 2014 23:30:54 GMT\nTextview:\njson\n{\"message\":\"Validation Failed\",\"request_id\":\"233d3c3d-d3e4-11e3-8926-84ca9bcf5de2\",\"documentation_url\":\"https://developer.github.com/v3\",\"errors\":[{\"resource\":\"ReleaseAsset\",\"code\":\"custom\",\"field\":\"size\",\"message\":\"size is not included in the list\"}]}\nSomehow...the Content-Length is empty (0)  i think thats the Problem.\nMhm.\n. ",
    "BoasE": "Sorry for my late reply. I'm glad that this will be fixed :+1:  @Haacked  yes I followed the guidelines forked and created my branch.\n. Thanks for your hint :-)\n. ",
    "gitspirit": "Any plans to merge it into master?\n. ",
    "kristianhald": "Three questions.\n1) Is this pull request dead or is it still expected to be merged?\n2) Is it only waiting for integration tests that are missing before it can be merged?\n3) Where is the code located, so that the tests can be added, if they are only the missing prerequisites?\n. Working on this, but is slow going, as I can not execute the tests with my Resharper. I can see that the update to the XUnit tests has been merged into master and I have tried running the tests on master and it works very well on my computer.\nWhat is the prefered way of getting master into my feature branch. Can I just do a merge from master to my branch or do I need to rebase it (As the original pr is old there is alot of manually handling the rebase).\n. I'll look at the pull request to determine if I can make the necessary changes so that it can be merged.\n. The pr is ready for review, if possible.\n. Sounds good. Thank you very much. If you find something I will find time during the week to correct it, so that we can finish it up.\n. Hi @shiftkey thanks for the comments on the code and the design. I have cleaned it up and added the Post method. \nI have added to each of your comments a short description of the change I have made in the code and I have tried keeping the changes in their own commits, so that you can compare the changes.\nThe 'Changed await AssertEx.Throws' to 'Assert.ThrowsAsync' is wrong. I accidentally also removed the 'await'. They have been added again to the tests in a later commit.\nI ran a bit out of time here at the last moment, so I hope everything is ok. Please write back in regards to any changes that needs to be added.\n. hi @shiftkey, Just wanted to make certain that the code is ok and not missing anything. I did the merge and solved the conflicts. I think that the merge from master must be done close to the merge to master. If the code changes are ok, I will do another merge.\n. Thanks for the review @shiftkey. I will look into the issues tonight after work.\n. @shiftkey, review changes have been made, including a merge handling the conflicts.\nI hope everything is well else you know how to get a hold of me :email:\n. Thanks and thanks for the merge. :ok_hand:\n. Yeah. There were two reasons for why I want to use collection fixtures. Never tried them before, but I do like them and would like to have them in other test frameworks. :smile:\nThe first and foremost reason is that for all/alot of my tests I only want to create my repositories and other readonly states once for all tests, so to minimize the times I am hitting the github Api. If I run all the tests in Octokit I will be throttled by github.\nThe second reason is that it helps encapsulate the creation and disposal logic, though it is a bit indirect and requires people to know them.\nI looked at the code and not having read it for 2-3 weeks, I have some suggestions which I would like to run by you guys.\nI define the name of the collection as a constant string in the collection class:\nC#\n    [CollectionDefinition(CollectionDefinitionName)]\n    public class RepositoriesHooksCollection : ICollectionFixture<RepositoriesHooksFixture>\n    {\n      public const string CollectionDefinitionName = \"Repositories Hooks Collection\";\n    }\nWhich I then use in the 'CollectionDefinition' attribute. On each test class instead of writing the string name of the collection, I use the constant string defined in the collection class:\n``` C#\n        [Collection(RepositoriesHooksCollection.CollectionDefinitionName)]\n        public class TheGetAllMethod\n        {\n            readonly RepositoriesHooksFixture _fixture;\n        public TheGetAllMethod(RepositoriesHooksFixture fixture)\n        {\n\n```\nThat should make it a bit less brittle than before.\nFurthermore the RepositoriesHooksCollection class is very small and very closely tied to the RepositoriesHooksFixture class. Would it be an idea to move the collection class into the same file as the fixture class. I am not normally a big fan of having two class inside the same file.\n. :pensive: Oops. Apologies. Has been removed.\n. :pensive: Has been removed.\n. Replaced the assertions in the forks and hooks unit tests.\n. :one: lined\n. :one: lined\n. Sounds good. They have been removed.\n. Sounds like a good way to go. Especially if the pattern is already being used for one of the other http methods.\nI have implemented a suggestion of the solution. \nWhen I am done with the rest of the review comments I will push them to the pr branch.\n. Changed from the dynamic type to Dictionary.\nI had to place the config in the constructor of the 'EditRepositoryHook' with a default argumentless constructor also.\nThe reason being the code analysis requires the dictionary not to have a public 'set' and I needed the Config property to be default 'null', because else the edit call would overwrite the config settings even if the user did not provide any.\n. Gone @ :gun: point. They wanted soo much to :zzz:\n. :pensive: Has been removed.\n. Gone @ :gun: point. They wanted soo much to :zzz:\nDid the same changes in 'RepositoryHooksClientTests'.\n. ",
    "FeodorFitsner": "Adding @Haacked ...\nA new build worker image has been deployed based on Windows Server 2012 R2 with Windows apps support and PCL. This image is default. Octokit build works like a charm :)\nBuild console log: https://ci.appveyor.com/project/appvyr/octokit-net\nappveyor.yml: https://github.com/FeodorFitsner/octokit.net/blob/master/appveyor.yml\nshallow_clone there is an experimental feature (and not yet documented :) that allows downloading specific GitHub commit via zipball. You can remove it to use git colne way.\nBuild takes aprox 5 minutes (max run time is 30 min).\nIntegration with messages:\n- to capture messages from msbuild.exe you can add/logger:\"C:\\Program Files\\AppVeyor\\BuildAgent\\Appveyor.MSBuildLogger.dll\"parameter.\n- capturingxunit` test results is trickier. Unlike NUnit or VSTest.Console xUnit doesn't provide extensibility mechanism to plug into test results sink, so we deploy to build workers our own patched version xUnit with built-in AV logging (very much like the one for TeamCity). I don't think it make sense to submit PR for v1.9, but I hope to make 2.0 through. In the meantime, we'll publish our version of xUnit to GitHub with runners on nuget.org.\nPlease let me know if you have any questions.\n. Cool, will keep you posted!\n. Sure, please do! We love feedback! :)\n. You see two builds if both feature branch and PR are in the same repo. With forked repos this works nice as you get PR build only in the master repo.\nRegarding commit status - to set PR status the status should be set on branch commit, not a virtual \"merge\" commit - at least AppVeyor does that right now, last time I tried setting status on merge commit it didn't change PR status.\nI don't know yet what would be the best strategy to implement prevention of branch commit build if that commit participates in PR(s). When you do a push to feature branch, usually \"push\" event comes first (guaranteed?), then \"sync\" events for all affected PRs. How do we know that commit is part of PR(s), not a regular \"working\" commit? Check all commits of all PRs? This could be slow.\n. ",
    "Red-Folder": "Couple of options maybe:\n1) Use the suggestion mentioned in #352 of storing the last ApiInfo.\n- Add a ApiInfo property to HttpClientAdapter (LastApiInfo).\n- Set the LastApiInfo in HttpClientAdapter.Send (amend the return BuildResponse)\n- In your code, manually new the HttpClientAdapter (so you can keep a reference), manually new a Connection (using the HttpClientAdapter) and pass into GitHubClient\n- In your code, call an API, then use your reference to HttpClientAdapter to get the LastApiInfo\n2) Create a base class for all Api models.  Within the base call, store the ApiInfo.  Given that some Octokit call will have multiple GitHub Api call, possible store all ApiInfo responses for each call (1 per page?).\nI'm currently using the former in some test code - but doesn't feel correct to add to a PR.\n. Gonna have a go at option 1 and produce a PR for review (hopefully next 24 hours)\nBasically just going to provide a property on the client which calls through to connection which calls through the HTTPClientAdaptor (which will store the last ApiInfo during the Send).\nPutting the chained calls all the way through the stack avoids having to keep a reference to the HttpClientAdaptor - which makes it easier for the user.\n. Is this not different to #504?  #504 asked to get the rate limits per API call (included in the headers)\nThis request asked for the rate limits as part of the MiscellaneousClient - a discrete API request.\nI'm currently having a play at both.  Hopefully produce a PR for the MiscellaneousClient some point next week.\n. Functionality added in commit #848 \nBelieve this can now be closed\n. Further thoughts on point 1;\nIf I re-purpose the existing RateLimit model then any consumer code doesn't need to handle the (logically) same data twice\n. @Haacked AppVeyor isn't building, is this because the original ResourceRateLimit.cs comment is still open, or is it something wrong with the code?\nOriginally I though it was the code - that I needed to put some #if !NETFX_CORE blocks round attributes.  But I've made changes to that an it doesn't seem to make any change.\n. Ok, green now.  Now I leave it alone and get some sleep.\nLessons learnt this evening:\n1. Do a fetch & merge from upstream BEFORE pushing\n2. How to use Meld\n3. That I should double check everything is as I expect in the commit\n4. Run the automated tests (even after I make the smallest possible change that in no possible way could break the solution)\n5. I should have gone to bed about 2 hours ago.  I'm too old to be up past midnight anymore\nOn a more serious note;\n- Appreciate the feedback & assistance given - please keep it coming.\n- I still need to run the integration tests (for some reason I cant make run yet - keep getting bad credentials)\n. Is it wrong that after 20+ years in IT, I'm seeing a 6 second vine from Phil Hacck as my most glowing accreditation?\nSurely there must be a \"thumbs up\" accreditation section somewhere in Linkedin .... off to go look\n. @khellang Great stuff.  I'll pull in over the weekend\n. Can anyone recommend a good Api call to use for the integration test?\nI'm current using the Rate Limit call - but this doesn't include links, oauth scope, accepted oauth scope, & etag,in the ApiInfo.  I'd like an Api call which will populate all of these for testing\n. @shiftkey Added further integration tests now - seems to cover all bases if a little repetitive.  I've added a new test attribute for Personal Access Token - the OAuth/ AcceptedOAuth test uses that attribute.\n. Hi guys, any further feedback on this one?\nI'm in danger of losing my dev environment in the next few days so would like to get this PR boxed off.\nThanks\n. Could someone have a look over my cloning logic.  Seems to work - but I could do with a fresh set of eyes on it.\nNote that I'm having to do new String(originalString.ToCharArray()) as nothing else (string.Copy for example) seems to work with portable version.\n. @Haacked Sorry Phil, I'd not been chasing this.  I'd lost my dev environment & between jobs (must find new job before wife makes me paint more fences).\nDev environment back up and running.  Will make the two minor tweaks you mention above then should be good to merge.  Probably today or tomorrow\n. Pops head above the parapet ... \"Looks good to go\"\n(Prepares to duck back down quickly)\n. Ah ... excellent.  A second thumbs up to add to the collection.\nI've added a whole section on my bio page for them ;)\nhttp://www.red-folder.com/Home/MyBio (then scroll down).  One day I'll setup the anchors, make the site size correctly, finish it, etc, etc, blah, blah\n. Also noted that this breaks other Integration tests:\nCreateHook in RespositoriesHooksFeature\nBasically anything that will be using Helper.Credentials.Login\n. Arggggg ... keep hitting:\nOctokit.ForbiddenException : You have triggered an abuse detection mechanism and have been temporarily blocked from content creation. Please retry your request again later.\nRelated to: https://developer.github.com/v3/#abuse-rate-limits\nMay need to introduce a sleep into the integration tests somewhere to void hitting\n. Ok ... mental note to self - if using Personal Access Token for integration testing - make sure if has the relevant Scopes (was missing delete_repo)\n. Following integration tests seems to fail if using OAuth, but not username/ password:\n- PullRequestsClientTests.CanSortPullRequests\nFollowing integration tests fail regardless of credentials:\n- RepositoryDeployKeysClientTests.CanRetrieveAllDeployKeys - Validation Failed\n- ObservableRespositoryDeployKeysClientTests.CanRetrieveAllDeployKeys - Observable version of the above\n- Octokit.Tests.Integration.RedirectTests.CanCreateIssueOnRedirectedRepository - A task was cancelled (think this is timing out)\n. Ok, the 2 x DeployKeys fails where due to test fragility - I've logged those as a separate issues #873\n. Separated out the CanCreateIssueOnRedirectedRepository as a separate issue #874\nI think this is actually a bug in the core redirect code, rather than the Integration tests\n. Seems to be something odd ...\nIf I run from VS, it seems to time out on the send of the new request (following the redirect).\nYet, I run Fiddler, and it all works.  Disable Fiddler Traffic Capture and it times out.  Re-enable and it works.\n. @shiftkey Any thoughts on this?  Do you see the same problem?\n. @shiftkey Sorry - I didn't get much further in my investigation than noted above.\nI seem to remember that I felt it was something to do with a connection being held open and it causing blocking (maybe some reference not being released correctly) - but it is likely to be something quite low level if the problem \"disappears\" when Fiddler is involved.\nI have no scientific proof for my theory ;)\nI'll have a another go when I get a chance (maybe wireshark or something similar will be less obtrusive than Fiddler and give some indication if the connection is still open)\n. Ok, update on progress.  I'm using an old version of the code (not pulled for about 3 months) ... but can recreate the problem for the Octokit.Tests.Integration.RedirectTests.CanCreateIssueOnRedirectedRepository test.\nAs originally, if I run the test from VS, it hangs/ times out.  Yes if I run with Fiddler, then I have no problem.\nSo I've run with Wireshark ... I've included a summary below (good luck to anyone that can understand it).  From what I guess, it appears to have 2 TSL requests (which we'd expect) the handshakes, setup etc all seem fine.\nHowever with both, api.github.com are providing in FIN/ ACK - which is closing the connection.  \nThen some time later, we get the RST/ ACK from the client (for some reason I have my laptop set up as www.x.com) - this seems to be the timeout.\nI wonder if something is going wrong with the HTTPClient not correctly handling the FIN/ ACK.\nEqually, I could be heading down the wrong rabbit hole.\nWireshark summary:\nNo.     Time           Source                Destination           Protocol Length     Info\n  12084 20.266681      www.x.com             api.github.com        TCP                 51068 \u2192 https [SYN] Seq=0 Win=8192 Len=0 MSS=1460 WS=256 SACK_PERM=1\n  12383 20.389320      api.github.com        www.x.com             TCP                 https \u2192 51068 [SYN, ACK] Seq=0 Ack=1 Win=28720 Len=0 MSS=1436 SACK_PERM=1 WS=1024\n  12384 20.389436      www.x.com             api.github.com        TCP                 51068 \u2192 https [ACK] Seq=1 Ack=1 Win=66048 Len=0\n  12386 20.390796      www.x.com             api.github.com        TLSv1               Client Hello\n  12423 20.505202      api.github.com        www.x.com             TLSv1               Server Hello\n  12424 20.506190      api.github.com        www.x.com             TLSv1               Certificate\n  12425 20.506252      www.x.com             api.github.com        TCP                 51068 \u2192 https [ACK] Seq=127 Ack=2873 Win=66048 Len=0\n  12426 20.506303      api.github.com        www.x.com             TLSv1               Server Key Exchange\n  12427 20.509106      www.x.com             api.github.com        TLSv1               Client Key Exchange, Change Cipher Spec, Encrypted Handshake Message\n  12433 20.620525      api.github.com        www.x.com             TLSv1               Change Cipher Spec, Encrypted Handshake Message\n  12434 20.622086      www.x.com             api.github.com        TLSv1               Application Data\n  12443 20.735373      api.github.com        www.x.com             TCP                 https \u2192 51068 [ACK] Seq=3085 Ack=826 Win=31744 Len=0 [ETHERNET FRAME CHECK SEQUENCE INCORRECT]\n  12444 20.735793      api.github.com        www.x.com             TLSv1               Application Data\n  12445 20.736676      www.x.com             api.github.com        TLSv1               Application Data\n  12477 20.883513      api.github.com        www.x.com             TCP                 https \u2192 51068 [ACK] Seq=3138 Ack=927 Win=31744 Len=0 [ETHERNET FRAME CHECK SEQUENCE INCORRECT]\n  12478 20.893246      api.github.com        www.x.com             TLSv1               Application Data\n  12479 20.896213      www.x.com             api.github.com        TCP                 51074 \u2192 https [SYN] Seq=0 Win=8192 Len=0 MSS=1460 WS=256 SACK_PERM=1\n  12493 20.944785      www.x.com             api.github.com        TCP                 51068 \u2192 https [ACK] Seq=927 Ack=4327 Win=66048 Len=0\n  12574 21.033572      api.github.com        www.x.com             TCP                 https \u2192 51074 [SYN, ACK] Seq=0 Ack=1 Win=28720 Len=0 MSS=1436 SACK_PERM=1 WS=1024\n  12575 21.033654      www.x.com             api.github.com        TCP                 51074 \u2192 https [ACK] Seq=1 Ack=1 Win=66048 Len=0\n  12582 21.034242      www.x.com             api.github.com        TLSv1               Client Hello\n  12911 21.208703      api.github.com        www.x.com             TLSv1               Server Hello, Change Cipher Spec, Encrypted Handshake Message\n  12918 21.210139      www.x.com             api.github.com        TLSv1               Change Cipher Spec, Encrypted Handshake Message, Application Data\n  13262 21.361958      api.github.com        www.x.com             TCP                 https \u2192 51074 [ACK] Seq=146 Ack=735 Win=31744 Len=0 [ETHERNET FRAME CHECK SEQUENCE INCORRECT]\n  13263 21.361995      api.github.com        www.x.com             TLSv1               Application Data\n  13264 21.362275      www.x.com             api.github.com        TLSv1               Application Data\n  13626 21.524183      api.github.com        www.x.com             TCP                 https \u2192 51074 [ACK] Seq=199 Ack=836 Win=31744 Len=0 [ETHERNET FRAME CHECK SEQUENCE INCORRECT]\n  13781 21.640681      api.github.com        www.x.com             TLSv1               Application Data\n  13782 21.641520      api.github.com        www.x.com             TLSv1               Application Data\n  13783 21.641586      www.x.com             api.github.com        TCP                 51074 \u2192 https [ACK] Seq=836 Ack=2993 Win=66048 Len=0\n  13784 21.641929      api.github.com        www.x.com             TLSv1               Application Data\n  13798 21.684186      www.x.com             api.github.com        TLSv1               Application Data\n  13804 21.796589      api.github.com        www.x.com             TCP                 https \u2192 51074 [ACK] Seq=3158 Ack=1273 Win=32768 Len=0 [ETHERNET FRAME CHECK SEQUENCE INCORRECT]\n  13813 21.899594      api.github.com        www.x.com             TLSv1               Application Data\n  13814 21.901602      api.github.com        www.x.com             TLSv1               Application Data\n  13815 21.901795      www.x.com             api.github.com        TCP                 51074 \u2192 https [ACK] Seq=1273 Ack=4880 Win=66048 Len=0\n  13816 21.915542      www.x.com             api.github.com        TLSv1               Application Data\n  13838 22.029272      api.github.com        www.x.com             TCP                 https \u2192 51074 [ACK] Seq=4880 Ack=1822 Win=33792 Len=0 [ETHERNET FRAME CHECK SEQUENCE INCORRECT]\n  13839 22.029363      api.github.com        www.x.com             TLSv1               Application Data\n  13840 22.029761      www.x.com             api.github.com        TLSv1               Application Data\n  13865 22.179555      api.github.com        www.x.com             TCP                 https \u2192 51074 [ACK] Seq=4933 Ack=1955 Win=34816 Len=0 [ETHERNET FRAME CHECK SEQUENCE INCORRECT]\n  13866 22.182841      api.github.com        www.x.com             TLSv1               Application Data\n  13981 22.233155      www.x.com             api.github.com        TCP                 51074 \u2192 https [ACK] Seq=1955 Ack=6122 Win=64768 Len=0\n  24010 30.907642      api.github.com        www.x.com             TLSv1               Encrypted Alert\n  24011 30.907692      api.github.com        www.x.com             TCP                 https \u2192 51068 [FIN, ACK] Seq=4364 Ack=927 Win=31744 Len=0\n  24012 30.907732      www.x.com             api.github.com        TCP                 51068 \u2192 https [ACK] Seq=927 Ack=4365 Win=65792 Len=0\n  25679 32.192455      api.github.com        www.x.com             TLSv1               Encrypted Alert\n  25680 32.192795      api.github.com        www.x.com             TCP                 https \u2192 51074 [FIN, ACK] Seq=6159 Ack=1955 Win=34816 Len=0\n  25681 32.192840      www.x.com             api.github.com        TCP                 51074 \u2192 https [ACK] Seq=1955 Ack=6160 Win=64768 Len=0\n  59738 121.915049     www.x.com             api.github.com        TCP                 51074 \u2192 https [RST, ACK] Seq=1955 Ack=6160 Win=0 Len=0\n  59749 122.845391     www.x.com             api.github.com        TCP                 51068 \u2192 https [RST, ACK] Seq=927 Ack=4365 Win=0 Len=0\n. This is a bit of a drive-by ... spotted this article about the use of HttpClient -> http://aspnetmonsters.com/2016/08/2016-08-27-httpclientwrong/\nThis feels as if it may be related to this problem.\nNot had a chance to run through the code (and not likely to in the near future) ... but figured I'd throw this in while passing.  Hope it helps.\n. @ryangribble Excellent news.  Great stuff\n. Ok, a bit of playing later ... I believe I have it.  Here is sample code:\n```\n// Setup tasks\nvar credentials = new Octokit.Credentials(_username, _key);\nvar connection = new Octokit.Connection(new Octokit.ProductHeaderValue(\"Red-Folder.Playground\"))\n{\n    Credentials = credentials\n};\nvar client = new Octokit.GitHubClient(connection);\nvar parent = await client.Git.Reference.Get(_username, _repo, \"heads/master\");\nvar latestCommit = await client.Git.Commit.Get(_username, _repo, parent.Object.Sha);\nvar currentTree = await client.Git.Tree.GetRecursive(_username, _repo, latestCommit.Tree.Sha);\n// Create a new tree from the current tree\nvar nt = new NewTree();\ncurrentTree.Tree\n            .Where(x => x.Type != TreeType.Tree)\n            .Select(x => new NewTreeItem\n            {\n                Path = x.Path,\n                Mode = x.Mode,\n                Type = x.Type,\n                Sha = x.Sha\n            })\n            .ToList()\n            .ForEach(x => nt.Tree.Add(x));\n// Remove a file\nvar toRemove = nt.Tree.Where(x => x.Path.Equals(\"2017-01-29/TestFile.txt\")).First();\nnt.Tree.Remove(toRemove);\n// Submit the tree, commit and point master at it\nvar newTree = await client.Git.Tree.Create(_username, _repo, nt);\nvar newCommit = new NewCommit($\"Testing commit\", newTree.Sha, parent.Object.Sha);\nvar commit = await client.Git.Commit.Create(_username, _repo, newCommit);\nawait client.Git.Reference.Update(_username, _repo, \"heads/master\", new ReferenceUpdate(commit.Sha));\n```. I'd appreciate any feedback on if this is an appropriate approach.\nNote, that I need to remove all the Tree Type nodes as without this, no change is made.\nAssuming this is a reasonable hack - would it be a good idea to add a constructor to NewTree which accepts the current tree?  (Happy to do the PR if this makes sense)\n. Hi @ryangribble - thanks for the comments\nYou are 100% correct - there is a base tree.  This works great for additions (and I suspect update, but not tried).\nIt doesn't however support delete.\nFrom the research I've done, I believe that to delete - the only method is to clone the entire existing tree (without setting the base tree).  And then either omit or remove the files you wish to delete from the NewTree before submitting it.\nIf you see the comment in the API docs for the base_tree property - while not explicit in about how it should be used for deleting items, it does point in that direction.  And a few blog posts have backed that up.\nSo yes, I would agree this seems a rather cumbersome approach - I believe it is the appropriate approach.  (although always happy to be proved wrong) . Removing the Tree types was taken from this blog post (see section 5b) -> http://www.levibotelho.com/development/commit-a-file-with-the-github-api\nOriginally I had the above code without the removal of the Tree type - everything seemed to work (I got 201 Created rather than 500 as mentioned in Levi's post).  However, when I looked at the commit on Github it showed as no changes had been made.\nAdd that single line:\n.Where(x => x.Type != TreeType.Tree)\nAnd everything seems to be working.\nI suspect that having the Tree type in there is the equivalent of setting the base tree (I'd expect them to be same Tree ... not checked that though).  As such including the \"last\" Tree as an object in the list, I believe git is using that as it's base, then applying any additions or updates in the list (of which there are none).  The absence of a file in the list has no affect, as the removed file will have already been pulled in when it took the \"last\" tree.\nThat last part is speculation on my part ;) . Changed now to use RateLimit\n. Changed as suggested\n. Done\n. Looking into it now\n. Just to clarify, is this the NotNull check?  What about the other NotNull tests further down - lose them as well to make more readable?\n. Will do.  I changed all this when I thought it was causing the appveyor problems (there was reasoning behind my thinking but I won't bore you)\n. As above - introduced (incorrectly) as trying to fix appveyor.  Will change.\n. I assumed the above was yes & yes\n. Three models in use:\n1. Originally MiscRateLimit -> Changed to MiscellaneousRateLimit to avoid abbreviation\n2. Originally ResourceRateLimits -> Changes to ResourceRateLimit \n3. Originally ResourceRateLimit -> Changes to use existing RateLimit\nHopefully that makes sense\n. @khellang I've added this for the thread safety.  Thoughts welcome\n. @khellang I moved the setting of the LastApiInfo before HandleErrors so that the LastApiInfo is still set even if an exception is thrown from the HandleErrors\n. @khellang @Haacked I'm easy either way - with locking/ without\nWhat's the preferred method of resolving coding decisions?  A well argued debate between respectful & collaborate peers?  Rocks/ Paper/ Scissors?  A fight to the death?\n(is it wrong to hope for the last one)\n. (Off topic)\nPlease tell me someone out there is photoshoping the below - replacing with @Haacked and the Octocat (not saying which way round)\n\n. Extra points for explaining why I needed to add this null check.  For some reason bundles of tests fail without it (comment and see what happens).  I think it is something to do with how the mocking framework is handling the object - but can't understand why it touches it.\n. Fair point.\nI really not sure why I need this line at all - but something blew up within the mocking framework so I added everything and kitchen sink.\nMaybe went a tad overboard ;)\n. ",
    "naveensrinivasan": "@Haacked  I wanted to check if this something that we want to do now.\nIMHO having samples would greatly improve people using this for their needs. I think linqpad is a great tool for doing that without much of ceremony. I use it very often to try out new API's. \nBased on this I forked  @shiftkey https://github.com/naveensrinivasan/octokit-linqpad-samples and updated with some more samples.  \nI updated the octokit's Nuspec locally with the linqpad-samples \n\nand when I use this nuget package it comes up with the samples in linqpad\n\n\nIf it is interesting, then I could a do a PR with \n- the samples, \n- updated the build to include the linqpad samples and\n- also include a test to make sure any changes don't break the samples.\n. I agree it could more of like Octokit.Samples where we could use one of the options as Linqpad and we could use the same samples for XS/VS project sample. \n. Here is a sample  Octokit.samples.0.0.1.nupkg which would automatically show up in the linqpad samples.\nShould it be original nuget package or should be a separate nuget package?\n. The linqpad has compilation options for compile check.  https://www.linqpad.net/lprun.aspx\n\nThe -compileonly switch tells lprun to check that the query will compile, without actually running anything.\n\nI was planning to use that feature in the CI build to make sure the commits don't break the samples.\n. Implemented this in https://github.com/octokit/octokit.net/pull/921\n. @shiftkey  Are we planning to bring this into the main branch? \n. @shiftkey  Thanks! Paging would be a feature would cause me to go directly to the API because it does not exists. \n. @shiftkey  That would be awesome! I would certainly try and contribute to it. \n. You could get all the contents of the branch using the overload client.Repository.Content.GetAllContents  which takes the reference as the last parameter.\nI am able to get all the contents of the branch and master including the sub-directories. Here is a sample.\n```\nasync Task Main(string[] args)\n{\n    var owner = \"octokit\";\n    var reponame = \"octokit.net\";\nGitHubClient client = new GitHubClient(new Octokit.ProductHeaderValue(\"Octokit.samples\"));\nclient.Credentials = new Credentials(Util.GetPassword(\"github\"));\nvar branchcontents = await client.Repository.Content.GetAllContents(owner,reponame,\"/Octokit.Reactive/Properties\",\"codeformatter\");\nvar mastercontents = await client.Repository.Content.GetAllContents(owner,reponame,\"/Octokit.Reactive/Properties\");\nbranchcontents .Dump();\nmastercontents.Dump();\nbranchcontents = await client.Repository.Content.GetAllContents(owner,reponame,\"/\",\"codeformatter\");\nmastercontents = await client.Repository.Content.GetAllContents(owner,reponame,\"/\");\n\nbranchcontents .Dump();\nmastercontents.Dump();\n\n}\n``\n. @ostruk  Yes you are right. It is a bug.\n. Have ran into this. Don't know how to bypass this.\n. With the latest release of beta8 I was able to get the Octokit working on thednxcore50`.\nI had to make changes to the nuspec to include the System.Net.Http instead of Microsoft.Net.Http for coreclr because coreclr does not have Microsoft.Net.Http. Here are the changes https://github.com/octokit/octokit.net/commit/0f23ff9f4a12990453ad72836885030a98dd81c3.\nAnd here is sample of Octokit that is working on the coreclr.\nhttps://github.com/naveensrinivasan/OctokitCoreClrSample\nThe sample also has the beta nuget package which could be used directly to test it.\n. When are planning to support dnxcore? Could we have a beta branch?\n. Thanks! Is there a VS2015 branch that I could clone?\n. @shiftkey Cool! will do that. Thanks!\n. @shiftkey  When are planning to move to C# 6.0?\n. > And aim for a single project.json with dotnet5.1, which is roughly the same as Profile259 (it has the > same targets). That should also be Future-Proof\u2122, until netstandard1.0 takes over.\n:+1: \n. DocPlagiarizer has a bug on mono also which make's hard to compile on non-windows platform.  The repo hasn't been updated since Feb 2014 https://github.com/pmacn/DocPlagiarizer. Do we fork this and fix it or do you want to move away form this?\n. I figure out the reason for this It is because  content-type is application/octet-stream on the response and the code does not handle that.  It handles image,zip,x-gzip. \nhttps://github.com/octokit/octokit.net/blob/1266ac0f3a366f033061d0c1cc0785bc3c9f5bd3/Octokit/Http/HttpClientAdapter.cs#L80\nBecause it is binary type and we read as string in the else block that is what is causing the corruption. And that is why it does not fail for text files.\nI tried including that and it works. I am able to download the release and the file isn't corrupted.\n@shiftkey  let me know if you want me to do PR on this?\n. :+1: \n. I guess this could be security reason so that you don't extract a malware.\nhttps://github.com/octokit/octokit.net/blob/e6e7c3d393160fabe4cc48dd6c410db2a19b7e72/Octokit/Models/Response/RepositoryContent.cs#L34-48\n@Haacked \n. Thanks!\n. Can I take this one?\n. I was able to remove the references to those files and I was able to compile the project.\n. Yes, I can do PR for this.\n. Here is the response from Xamarin. The author of the project would have to apply for the license. \n\nHi Naveen,\nThanks for letting me know!\nThe author of the project needs to apply for the subscription and if it is a group open source project, \nall will need to apply separately with a note of who else is working on the project.\nBest,\nAndrey\n\n@Haacked Could you apply for this? https://resources.xamarin.com/open-source-contributor.html\n. Did you get the license for yourself ? If you have the email can you forward it I could apply for the \n\nall will need to apply separately with a note of who else is working on the project. \n\nand then use that specific license to supply in build server\n. @Haacked I'll do that.\n. Looks good to me  :+1: \n. I will send a PR on this.\n. Sure. Thanks!\n. The reason for the failure is because the release api has an optional argument called label along with name which is required\nhttps://developer.github.com/v3/repos/releases/#upload-a-release-asset\nThe releaseclient code UploadAsset method https://github.com/octokit/octokit.net/blob/9198f80e5d1880344040d5652645000b151cc071/Octokit/Clients/ReleasesClient.cs#L161 invokes the ExpandUriTemplate method https://github.com/octokit/octokit.net/blob/6aa323c8ffb26cdf5ac2721da72c169a1795e32f/Octokit/Helpers/StringExtensions.cs#L48 which does not expand the name parameter for the api which is required because it expects only one parameter which is the bug. \n\nThis is causing the api throw an error with Invalid name for request because request name was not provided in the call. \nHere is a sample code to recreate this issue\n```\nvoid Main()\n{\n//replace the token, username,repositoryName\nvar username = \"naveensrinivasan\";\nvar token = \"REPLACE_TOKEN\";\nvar repositoryName = \"TestUpload\";\n\nIReleasesClient _releaseClient;\n\n\nvar stream = new FileStream(@\"c:\\temp\\test.txt\",System.IO.FileMode.Open);\n\nvar github = new GitHubClient(new ProductHeaderValue(\"test\"));\ngithub.Credentials = new Credentials(token);\n\n_releaseClient = github.Release;\n\nvar releaseWithNoUpdate = new NewRelease(\"0.5\") { Draft = true };\nvar release = _releaseClient\n    .Create(username, repositoryName, releaseWithNoUpdate)\n    .Result;\n\nvar newAsset = new ReleaseAssetUpload(\"hello-world.txt\", \"text/plain\", stream, null);\nvar result = _releaseClient.UploadAsset(release, newAsset).Result;\n\n}\n// Define other methods and classes here\n```\n. I can take this one.\n. This one should be closed. \n. Yes, I checked in the test before the actual fix that was causing the CI to fail the build.\n. Yes, I tested the Upload to releases with this fix.\nhttps://github.com/naveensrinivasan/TestUpload/releases\n. Even I couldn't replicate it locally. \n. I will take this one! Thanks\n. Thanks fixed that!. It is failing again in the StopsMakingNewRequestsWhenTakeIsFulfilled\n. This could be something which could help in solving this.\nhttps://github.com/akavache/Akavache/commit/e7ac5d1eea22cb2685bf93542eff8aea6f9c5d90\n. The build failed due to #904\n. The build failed because of StopsMakingNewRequestsWhenTakeIsFulfilled\n. The build fails because of #904 StopsMakingNewRequestsWhenTakeIsFulfilled\n. When the API dose not  officially support it then why build a hack around it? \n. @shiftkey / @Haacked  Could we create one of these options? \n. Done!\n. IMO we should move the SourceLink , CreateOctokitPackage, CreateOctokitReactivePackage\nhttps://github.com/octokit/octokit.net/blob/master/build.fsx#L114-181 to the new deploy.fsx and then we could sourcelink and publish the nuget package as part of deploying.\nThoughts?\n. The default target in deploy.cmd is CreatePackages\nHere is the argument list deploy.cmd\n1. Target -  CreatePackages , ReleaseToGithub\n2. GITOWNER - The default is octokit if nothing is provided. This is used for releasing to github\n3. GITPASSWORD - This is used for releasing to Github . I use the https://github.com/settings/tokens\n4. NUGETKEY - The nuget key is used for deploying to nuget \nI wasn't able to deploy to nuget because I don't have private nuget key to deploy octokit.\nI was able to ReleaseToGithub.\nHere is the run from the ReleaseToGithub\n```\nBuilding project with version: LocalBuild\nShortened DependencyGraph for Target ReleaseToGithub:\n<== ReleaseToGithub\n   <== CreatePackages\n      <== SourceLink\n         <== All\n      <== CreateOctokitPackage\n      <== CreateOctokitReactivePackage\nThe resulting target order is:\n - All\n - SourceLink\n - CreateOctokitPackage\n - CreateOctokitReactivePackage\n - CreatePackages\n - ReleaseToGithub\nStarting Target: All\nFinished Target: All\nStarting Target: SourceLink (==> All)\nsource indexing C:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\Octokit\\bin\\Re\nlease\\Net45\\Octokit.pdb\nsource indexing C:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\Octokit\\bin\\Re\nlease\\NetCore45\\Octokit.pdb\nsource indexing C:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\Octokit\\bin\\Re\nlease\\Portable\\Octokit.pdb\nsource indexing C:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\Octokit.Reacti\nve\\bin\\Release\\Net45\\Octokit.Reactive.pdb\nFinished Target: SourceLink\nStarting Target: CreateOctokitPackage\nDeleting contents of ./packaging/octokit\\lib/net45/\nDeleting contents of ./packaging/octokit\\lib/netcore45/\nDeleting contents of ./packaging/octokit\\lib/portable-net45+wp80+win+wpa81/\nCreating .nuspec file at C:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\packa\nging\\octokit\\octokit.0.17.0.nuspec\nCreated nuspec file C:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\packaging\\\noctokit\\octokit.0.17.0.nuspec\nC:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\tools\\NuGet\\nuget.exe pack -Ve\nrsion 0.17.0 -OutputDirectory \"C:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\n\\packaging\" \"octokit.0.17.0.nuspec\"\nDeleting C:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\packaging\\octokit\\oct\nokit.0.17.0.nuspec\nC:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\tools\\NuGet\\nuget.exe push \"C:\n\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\packaging\\Octokit.0.17.0.nupkg\"\nPRIVATEKEY  in WorkingDir: C:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\pac\nkaging\\octokit Trials left: 5\nPushing Octokit 0.17.0 to the NuGet gallery (https://www.nuget.org)...\nFailed to process request. 'The specified API key is invalid or does not have pe\nrmission to access the specified package.'.\nThe remote server returned an error: (403) Forbidden..\nC:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\tools\\NuGet\\nuget.exe push \"C:\n\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\packaging\\Octokit.0.17.0.nupkg\"\nPRIVATEKEY  in WorkingDir: C:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\pac\nkaging\\octokit Trials left: 4\nPushing Octokit 0.17.0 to the NuGet gallery (https://www.nuget.org)...\nFailed to process request. 'The specified API key is invalid or does not have pe\nrmission to access the specified package.'.\nThe remote server returned an error: (403) Forbidden..\nC:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\tools\\NuGet\\nuget.exe push \"C:\n\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\packaging\\Octokit.0.17.0.nupkg\"\nPRIVATEKEY  in WorkingDir: C:\\Users\\nsrinivasan\\Documents\\GitHub\\octokit.net\\pac\nkaging\\octokit Trials left: 3\n```\n. Part of deploying release's involves manually creating ReleaseNotes based on PR's merged from the previous git tag to now. \nWhy not automate this?\nhttps://gist.github.com/naveensrinivasan/d267667cf7b7dd017b90\nThis is what I was able to produce this using octokit from v0.16.0 tag to now. This is not perfect but it would avoid manually looking for each PR. \n- Created build.sh  @naveensrinivasan\n- Add .com links to PrivateRepositoryQuotaExceededException #389 @elbaloo\n- Updated with the logo  @naveensrinivasan\n- Fixes for FAKE Xunit warning  @naveensrinivasan\n- add System to required framework assemblies for net45  @adamralph\n- Consolidate committer info  @Haacked\n- Add a bunch of XML doc comments  @Haacked\n- Disposable repositories #655 @willsb\n- Clarify why convention tests are failing #907 @khellang\n- Making Encodedcontent public #861 #861 @naveensrinivasan\n- Updated the readme with reactive octokit.  @naveensrinivasan\n- Changes GitHubCommit.Author/Committer #779 @willsb\n- Build fix for Xamarin Studio Solution  @naveensrinivasan\n- Add Events URL to the Issue class.  @alfhenrik\n- Updated test target names in the shipping releases doc  @alfhenrik\n- Release of v0.16 - ironic ties  @Haacked\nWould this be useful @Haacked / @shiftkey ? If so then I could make it as part of this PR.\n. Sounds good. :+1: \n. @shiftkey What do you want to do this PR?\n. @shiftkey If you are going to pull this then can I  close this PR?\n. Thanks. I was thinking we should start supporting mono, its just the question of making the builds ready for it. The code supports it. Once the build scripts are ready for non-windows we could even enable builds on https://travis-ci.org/\n. I was trying to deploy Paket to forked repo and I got this. I agree I would prefer Response payload.\n```\nPaket.exe 2.15.6 is up to date.\nPaket version 2.15.6.0\n1 second - ready.\nBuilding project with version: LocalBuild\nShortened DependencyGraph for Target ReleaseGitHub:\n<== ReleaseGitHub\nThe resulting target order is:\n - ReleaseGitHub\nStarting Target: ReleaseGitHub\nC:\\Program Files (x86)\\Git\\bin\\git.exe remote -v\nC:\\Program Files (x86)\\Git\\bin\\git.exe add . --all\nC:\\Program Files (x86)\\Git\\bin\\git.exe commit -m \"Bump version to 2.15.6\"\nOn branch master\nYour branch is up-to-date with 'origin/master'.\nnothing to commit, working directory clean\nOn branch master\nC:\\Program Files (x86)\\Git\\bin\\git.exe status\nC:\\Program Files (x86)\\Git\\bin\\git.exe --version\nC:\\Program Files (x86)\\Git\\bin\\git.exe --version\nUsername for 'https://github.com': naveensrinivasan\nPassword for 'https://naveensrinivasan@github.com':\nEverything up-to-date\nC:\\Program Files (x86)\\Git\\bin\\git.exe tag 2.15.6\nUsername for 'https://github.com': naveensrinivasan\nPassword for 'https://naveensrinivasan@github.com':\nEverything up-to-date\nRunning build failed.\nError:\nSystem.AggregateException: One or more errors occurred. ---> Octokit.NotFoundExc\neption: Not Found\n   at Octokit.Connection.HandleErrors(IResponse response) in c:\\dev\\octokit.net\\\nOctokit\\Http\\Connection.cs:line 564\n   at Octokit.Connection.d__2b.MoveNext() in c:\\dev\\octokit.net\\Octo\nkit\\Http\\Connection.cs:line 546\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNot\nification(Task task)\n   at Octokit.Connection.d__271.MoveNext() in c:\\dev\\octokit.net\\Octokit\\H\nttp\\Connection.cs:line 531\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNot\nification(Task task)\n   at Octokit.ApiConnection.<Post>d__121.MoveNext() in c:\\dev\\octokit.net\\Octok\nit\\Http\\ApiConnection.cs:line 0\n   --- End of inner exception stack trace ---\n   at Microsoft.FSharp.Control.AsyncBuilderImpl.commita\n   at Fake.TargetHelper.runSingleTarget(TargetTemplate1 target) in C:\\code\\fake\n\\src\\app\\FakeLib\\TargetHelper.fs:line 483\n---> (Inner Exception #0) Octokit.NotFoundException: Not Found\n   at Octokit.Connection.HandleErrors(IResponse response) in c:\\dev\\octokit.net\\\nOctokit\\Http\\Connection.cs:line 564\n   at Octokit.Connection.<RunRequest>d__2b.MoveNext() in c:\\dev\\octokit.net\\Octo\nkit\\Http\\Connection.cs:line 546\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNot\nification(Task task)\n   at Octokit.Connection.<Run>d__271.MoveNext() in c:\\dev\\octokit.net\\Octokit\\H\nttp\\Connection.cs:line 531\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNot\nification(Task task)\n   at Octokit.ApiConnection.d__12`1.MoveNext() in c:\\dev\\octokit.net\\Octok\nit\\Http\\ApiConnection.cs:line 0<---\nSystem.AggregateException: One or more errors occurred. ---> Octokit.NotFoundExc\neption: Not Found\n   at Octokit.Connection.HandleErrors(IResponse response) in c:\\dev\\octokit.net\\\nOctokit\\Http\\Connection.cs:line 564\n   at Octokit.Connection.d__2b.MoveNext() in c:\\dev\\octokit.net\\Octo\nkit\\Http\\Connection.cs:line 546\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNot\nification(Task task)\n   at Octokit.Connection.d__271.MoveNext() in c:\\dev\\octokit.net\\Octokit\\H\nttp\\Connection.cs:line 531\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNot\nification(Task task)\n   at Octokit.ApiConnection.<Post>d__121.MoveNext() in c:\\dev\\octokit.net\\Octok\nit\\Http\\ApiConnection.cs:line 0\n   --- End of inner exception stack trace ---\n   at Microsoft.FSharp.Control.AsyncBuilderImpl.commita\n   at Fake.TargetHelper.runSingleTarget(TargetTemplate1 target) in C:\\code\\fake\n\\src\\app\\FakeLib\\TargetHelper.fs:line 483\n---> (Inner Exception #0) Octokit.NotFoundException: Not Found\n   at Octokit.Connection.HandleErrors(IResponse response) in c:\\dev\\octokit.net\\\nOctokit\\Http\\Connection.cs:line 564\n   at Octokit.Connection.<RunRequest>d__2b.MoveNext() in c:\\dev\\octokit.net\\Octo\nkit\\Http\\Connection.cs:line 546\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNot\nification(Task task)\n   at Octokit.Connection.<Run>d__271.MoveNext() in c:\\dev\\octokit.net\\Octokit\\H\nttp\\Connection.cs:line 531\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNot\nification(Task task)\n   at Octokit.ApiConnection.d__12`1.MoveNext() in c:\\dev\\octokit.net\\Octok\nit\\Http\\ApiConnection.cs:line 0<---\n\nBuild Time Report\nNo target was successfully completed\n```\n. This is what we get in the Response Payload Body. \n{\"message\":\"Not Found\",\"documentation_url\":\"https://developer.github.com/v3\"}\nWould this alone help?\n. Code formatter :+1: \n. Do you want to do it just for master? \n. ```\nvar request = new SearchCodeRequest(\"auth\")\n{\n    // maybe we want to restrict the search to the file only\n    In = new[] { CodeInQualifier.File },\n// how about we find a file based on a certain language\nLanguage = Language.JavaScript,\n\n// do we want to search forks too?\nForks = true,\n\n// find files that are above 1000 bytes\nSize = Range.GreaterThan(1000),\n\n// we may want to restrict the search to the path of a file\nPath = \"app/assets\",\n\n// we may want to restrict the file based on file extension\nExtension = \"json\",\n\n// restrict search to a specific file name\nFileName = \"app.json\",\n\n// search within a users or orgs repo\nUser = \"dhh\"\n\n};\n```\nThe above sample does not produce a result. My two cents we should have a sample that produces some result.\n. :+1: \n. Because ref also could be another overload , would these be OK?\ncsharp\npublic async Task<IReadOnlyList<RepositoryContent>> GetAllContents(string owner, string name,string ref)\ncsharp\npublic async Task<IReadOnlyList<RepositoryContent>> GetAllContents(string owner, string name)\n. @shiftkey \ncsharp\npublic async Task<IReadOnlyList<RepositoryContent>> GetAllContents(string owner, string name, string reference)\nCannot have this because there is already another overload with the same parameter types\ncsharp\npublic async Task<IReadOnlyList<RepositoryContent>> GetAllContents(string owner, string name, string path)\nWhat do you want to do?\n. Sounds good to me! \n. Implemented changes. The method names are GetAllContents and GetAllContentsByRef. I reused the  GetAllContents name because in one of the overloads we don't pass the path and it does not make sense to have a function name as  GetAllContentsByPath and don't have the path in argument.\n. Done with the changes.\n. Switching to new \u2018dotnet\u2019 target framework monikers   \nhttps://github.com/aspnet/Announcements/issues/98\n. Included the travis ci for the coreclr    https://github.com/octokit/octokit.net/pull/961\n. @shiftkey  Do you want to continue with this branch? I would like to contribute to move to coreclr.\n. @shiftkey  I pushed the changes https://travis-ci.org/octokit/octokit.net/jobs/95660459 and it build successfully. I don't know why it is showing as build unknow.\n. :joy: \n. The reason for the TaskCanceledExceptions is because the  default HttpClient Timeout is 100 seconds. \nI tried changing in the sample from Nullable<TimeSpan>()  to new TimeSpan(0, 10, 0) to see if that would fix. But the HttpClientAdapter that is implemented does not set the timeout passed in the request to the HttpClient. The Timeout is being used only used in the CancellationTokenSource https://github.com/octokit/octokit.net/blob/f0111aa72239da06c6268ae0c47562957f6603bc/Octokit/Http/HttpClientAdapter.cs#L53-65\n~~This is a bug. The Timeout property should set to the TimeSpan set in the Request.~~\nI'll do a PR for this. \nBy the time if you want a workaround you could have a HttpClient class that implements IHttpClient and pass that to the Connection class like this.\ncsharp\n    var client = new Connection(new Octokit.ProductHeaderValue(\"uploadrelease\"),new YourOwnHttpClient())\n. @shiftkey If I am not wrong the timeout is only for that request which is cancellation token. But http would time out all the request when it reaches 100 seconds https://msdn.microsoft.com/en-us/library/system.net.httpwebrequest.timeout(v=vs.100).aspx . @eiriktsarpalis  is using the same http client with multiple simultaneous concurrent requests.\n. Wasn't aware of that. \n. Fixed the line breaks and spaces. @shiftkey Will the CodeFormatter  address these line breaks and spaces?\n. When I branched the VS2015  branch wasn't available. Will do that going forward. Thanks! \n. @shiftkey  Not an issue. :+1:\n. @ferventcoder  Do you have a code sample to recreate this?\n. I was able to create a gist using contents https://gist.github.com/ferventcoder/83fa0e5b93202537aa25#file-zbad-json and here is the gist that was created https://gist.github.com/naveensrinivasan/9952f4284509d0b43e94\nand here is the code I used to create the gist https://gist.github.com/naveensrinivasan/09cb24b661178fe72b9f\n. No, I am able to reproduce it from your files. From the quick look it looks like an issue with the JsonSerializer on the octokit.net client.\n. It is this line which is causing the issue \n==> default:  S\u25a1e\u25a1r\u25a1v\u25a1i\u25a1c\u25a1e\u25a1 \u25a1\"\u25a1A\u25a1p\u25a1a\u25a1c\u25a1h\u25a1e\u25a1D\u25a1S\u25a1\"\u25a1 \u25a1i\u25a1n\u25a1s\u25a1t\u25a1a\u25a1l\u25a1l\u25a1e\u25a1d\u25a1 \u25a1s\u25a1u\u25a1c\u25a1c\u25a1e\u25a1s\u25a1s\u25a1f\u25a1u\u25a1l\u25a1l\u25a1y\u25a1!\u25a1\nwhich is in line 733 in install.txt\nI converted the string to char and corresponding int values. You could see the \"0\" which isn't getting converted to valid json in the json serializer. That is the bug.\n```\n= 61 \n= 61 \n\n62 \n  32 \nd 100 \ne 101 \nf 102 \na 97 \nu 117 \nl 108 \nt 116 \n: 58 \n  32 \n  32 \nS 83 \n\u25a1 0 \ne 101 \n\u25a1 0 \nr 114 \n\u25a1 0 \nv 118 \n\u25a1 0 \ni 105 \n\u25a1 0 \nc 99 \n\u25a1 0 \ne 101 \n\u25a1 0 \n  32 \n\u25a1 0 \n\" 34 \n\u25a1 0 \nA 65 \n\u25a1 0 \np 112 \n\u25a1 0 \na 97 \n\u25a1 0 \nc 99 \n\u25a1 0 \nh 104 \n\u25a1 0 \ne 101 \n\u25a1 0 \nD 68 \n\u25a1 0 \nS 83 \n\u25a1 0 \n\" 34 \n\u25a1 0 \n  32 \n\u25a1 0 \ni 105 \n\u25a1 0 \nn 110 \n\u25a1 0 \ns 115 \n\u25a1 0 \nt 116 \n\u25a1 0 \na 97 \n\u25a1 0 \nl 108 \n\u25a1 0 \nl 108 \n\u25a1 0 \ne 101 \n\u25a1 0 \nd 100 \n\u25a1 0 \n  32 \n\u25a1 0 \ns 115 \n\u25a1 0 \nu 117 \n\u25a1 0 \nc 99 \n\u25a1 0 \nc 99 \n\u25a1 0 \ne 101 \n\u25a1 0 \ns 115 \n\u25a1 0 \ns 115 \n\u25a1 0 \nf 102 \n\u25a1 0 \nu 117 \n\u25a1 0 \nl 108 \n\u25a1 0 \nl 108 \n\u25a1 0 \ny 121 \n\u25a1 0 \n! 33 \n\u25a1 0 \n\n```\nI took the same content and tried to convert to json.net and I looks like it handles these characters\n```\n default:  C:\\\\tools\\r\\n==> default:  apacheds service will be installed\\r\\n==> default:  S\\u0000e\\u0000r\\u0000v\\u0000i\\u0000c\\u0000e\\u0000 \\u0000\\\\\"\\u0000A\\u0000p\\u0000a\\u0000c\\u0000h\\u0000e\\u0000D\\u0000S\\u0000\\\\\"\\u0000 \\u0000i\\u0000n\\u0000s\\u0000t\\u0000a\\u0000l\\u0000l\\u0000e\\u0000d\\u0000 \\u0000s\\u0000u\\u0000c\\u0000c\\u0000e\\u0000s\\u0000s\\u0000f\\u0000u\\u0000l\\u0000l\\u0000y\\u0000!\\u0000\\r\\n==> default:\n```\n. Thanks. I will submit a PR for this. \n. @ferventcoder  Yes, it should. I am hoping to get it done by the weekend.\n. @ferventcoder I have the code fixed in this branch. https://github.com/naveensrinivasan/octokit.net/tree/json-serialization  \nhttps://github.com/naveensrinivasan/octokit.net/commit/fafa5365d106ba74c38ddca6a970c15a80302fb5\nI don't have test's checked in. I was able to upload the files you had issue with this fix. https://gist.github.com/naveensrinivasan/57cadd2e7df0e2a42066.\n. @ferventcoder I have submitted a PR. I will try and make a change to the build in a PR which will include this fix and provide a nuget package in appveyor so that you could test without going through the hazzle of building it.\n. @ferventcoder  Here is a nuget package with latest fix https://ci.appveyor.com/nuget/octokit-net-naveen You don't need to build it locally :smile: \n. @ferventcoder  Figured out what was the reason. The nuget package you are using is correct. It was overwritten by my other commits.\nThe issue was ,I was commiting other changes based on the master that didn't have this change and nuget package was generated on the appevyor on commits to the branch.\nI have re-ran the build on the same commit which had my fix for Json serialization on the appveyor to get the excat fix for the nuget package you could test.\nIf you have a linqpad installed please download this linq query  and update the foldername to the package-verifier\\src\\chocolatey.package.verifier.tests.integration\\context\\failinggists location\nand also provide the github credential client.Credentials = new Credentials(Util.GetPassword(\"github\")); and it will upload all the gists that were failing for you. \nhttp://share.linqpad.net/sdnngn.linq\nI have tested it with all the failing test and everything is working as expected. \nHere are the gists uploaded  with the latest fix\nhttps://gist.github.com/naveensrinivasan\nand the nuget url is https://ci.appveyor.com/nuget/octokit-net-naveen\nlet me know if you have any issues. \nJust wished I thought about this before commiting other changes.\nI apologize for not thinking through! \n. > Still have not had an error related to unicode.\n:+1: \n. https://gist.github.com/naveensrinivasan/58fa8eb57e61535f10db\n. Cool :+1: \n. OK Cool!  I like to use XS on mac to code and this is a bottle neck.\n. @Haacked  I looked for that first before making the change. https://github.com/facebook-csharp-sdk/simple-json hasn't been updated in the last 20 months. There is already a PR with this fix for the main repo which is still pending from April. That's the reason for making a change in this repo.\nI understand your concerns. What do you want to do?\n. IMO the nuget package using appevyor should be from the main instread for all the PR's disable_publish_on_pr: true this would make the consumers point an use the latest stable version of the main instead of  waiting for the release.\n. @Haacked  Do you want to publish on PR's  disable_publish_on_pr: true ?\n. I am going to fix the specific example to get it working and open another issue to address this for every check-in.\n. @shiftkey  Will look into this next week. \n. @shiftkey Clone this repo https://github.com/naveensrinivasan/octokit-test which has the  testing-data folder. Then run this octokit-release-upload-concurrent.linq in linqpad.  We could reproduce the exception where the Http time's out. In this sample the code is trying to upload 11 files concurrently to GitHub Release.\n. @shiftkey  OSX file system isn't case sensitive which is causing me an issue. So it works on mine but does not work on the linux. \nTook care of NSubstitute.The issue was the NET40 was uppercase instead of net40 which is the actual case.\n. Now I could see this test's failing much more often on mono StopsMakingNewRequestsWhenTakeIsFulfilled\n. @shiftkey  I am done with these changes.\n. @shiftkey I am done with changes. There is a conflict on the README.MD\n. @shiftkey Will do that. Thanks\n. @shiftkey  I resolved the conflict. The build failed :tired_face:  in appveyor and linux because of StopsMakingNewRequestsWhenTakeIsFulfilled \n. @shiftkey Thanks! Done!\n. @shiftkey Got it done! Thanks\n. And also the test's are failing.\nOctokit.Tests.Conventions.SyncObservableClients.CheckObservableClients(clientInterface: typeof(Octokit.IIssueCommentsClient)) [FAIL]\n      Octokit.Tests.Conventions.ParameterMismatchException : Parameter 0 for method IObservableIssueCommentsClient.Get must be \"Int32 id\" but is \"String name\"\n      Stack Trace:\n           at Octokit.Tests.Conventions.SyncObservableClients.CheckParameters (System.Reflection.MethodInfo mainMethod, System.Reflection.MethodInfo observableMethod) <0x39abc28 + 0x00157> in <filename unknown>:0 \n           at Octokit.Tests.Conventions.SyncObservableClients.CheckMethod (System.Reflection.MethodInfo mainMethod, System.Reflection.MethodInfo observableMethod) <0x39aab70 + 0x0006f> in <filename unknown>:0 \n           at Octokit.Tests.Conventions.SyncObservableClients+<CheckObservableClients>c__AnonStorey1.<>m__0 () <0x39aab40 + 0x0001f> in <filename unknown>:0 \n           at Octokit.Tests.Helpers.AssertEx.WithMessage (System.Action assert, System.String message) <0x39aaa50 + 0x0000e> in <filename unknown>:0 \n           at Octokit.Tests.Conventions.SyncObservableClients.CheckObservableClients (System.Type clientInterface) <0x39a8c48 + 0x00337> in <filename unknown>:0 \n           at (wrapper managed-to-native) System.Reflection.MonoMethod:InternalInvoke (System.Reflection.MonoMethod,object,object[],System.Exception&)\n           at System.Reflection.MonoMethod.Invoke (System.Object obj, BindingFlags invokeAttr, System.Reflection.Binder binder, System.Object[] parameters, System.Globalization.CultureInfo culture) <0x2edda28 + 0x00093> in <filename unknown>:0 \nFinished:    Octokit.Tests.Conventions\n. @shiftkey  it is for the PortableReferenceAssemblies that we get from the xamarin. Looks like it is failing to get it failure because of  timeout. Did you try re-running the build on the same commit? \n. @shiftkey Thanks. :metal: \n. Do we want to use the property  CommitUrl that hasn't yet been documented? \n. https://github.com/octokit/octokit.net/tree/master/samples/linqpad-samples\nhttps://github.com/octokit/octokit.net/tree/master/docs\nThese would probably help in getting started.\n. @shiftkey  Do we want to add the above link to README.md?\n. @RobPethick @shiftkey  Nothing is wrong. It just timed out on linux and but was successful on OSX. We are good.\n. @shiftkey  Thanks for pulling this in.\n. Also the convention test are failing because of observables.\n```\nThe resulting target order is:\n - ConventionTests\nStarting Target: ConventionTests \nmono  /Users/naveen/code/octokit.net/tools/xunit.runner.console/tools/xunit.console.exe \"/Users/naveen/code/octokit.net/Octokit.Tests.Conventions/bin/Release/Octokit.Tests.Conventions.dll\" -parallel none -html \"./testresults/xunit.html\" \nxUnit.net console test runner (64-bit .NET 4.0.30319.17020)\nCopyright (C) 2015 Outercurve Foundation.\nDiscovering: Octokit.Tests.Conventions\nDiscovered:  Octokit.Tests.Conventions\nStarting:    Octokit.Tests.Conventions\n   Octokit.Tests.Conventions.SyncObservableClients.CheckObservableClients(clientInterface: typeof(Octokit.IUsersClient)) [FAIL]\n      Octokit.Tests.Conventions.InterfaceMissingMethodsException : Methods not found on interface IObservableUsersClient which are required:\n       - get_Administration\n      Stack Trace:\n         (0,0): at Octokit.Tests.Conventions.SyncObservableClients.CheckObservableClients (System.Type clientInterface)\n            at (wrapper managed-to-native) System.Reflection.MonoMethod:InternalInvoke (System.Reflection.MonoMethod,object,object[],System.Exception&)\n         (0,0): at System.Reflection.MonoMethod.Invoke (System.Object obj, BindingFlags invokeAttr, System.Reflection.Binder binder, System.Object[] parameters, System.Globalization.CultureInfo culture)\nFinished:    Octokit.Tests.Conventions\n``\n. This is an issue https://github.com/octokit/octokit.net/issues/963 . Here is a workaround https://github.com/fsharp/FAKE/pull/1048\n. I don't think we need PCL. Let me check that and get back. I have been really busy with work and haven't had a chance to look at these issues.\n. @shiftkey The link is dead and there aren't any files. Could you try removing the pcl reference from the script and try it without that? \n. @khellang AFAIK it wasn't used. If it affects someone, I could change it to XML.\n. How about this one http://haacked.com/images/haacked_com/WindowsLiveWriter/IntroducingOctokit.NET_D8EF/octokit-dotnet_2.png?\n. It is for conditional compilation toMONO. I don't think so.\n.GITHUBPASSWORDis used while publishing the release. You could use https://github.com/settings/tokens. If you don't provide this argument then console would prompt it while deploying. It is an optional argument. \n.isRunningOnMonois used forSourceLink. Sourcelink is excluded on mono https://github.com/fsharp/FAKE/blob/master/build.fsx#L304\n. Fixed it.\n. I don't know if the response content type could be anything else other thanapplication/octet-stream. From the test's that I have done with API  forzipandtxtthe response content type has only beenapplication/octet-stream. Do we need the other types?\n. I would prefer code that would compile. This one will fail to compile because there is duplication ofIn`\n. @shiftkey You could update it when you get a travis-ci setup for octokit.net . I won't know the exact URL until one is setup. \n. I tried it and it doesn't work.\n\nBuilding project: ./Octokit-Mono.sln\n  xbuild  ./Octokit-Mono.sln /t:Build /tv:14.0 /v:m  /p:RestorePackages=\"False\" >/p:Configuration=\"Release\" >/logger:Fake.MsBuildLogger+ErrorLogger,\"/home/travis/build/naveensrinivasan/octokit.net/tools/FAKE.Core/tools/FakeLib.dll\"\nxbuild  ./Octokit-Mono.sln /t:Build /tv:14.0 /v:m  /p:RestorePackages=\"False\" >/p:Configuration=\"Release\" >/logger:Fake.MsBuildLogger+ErrorLogger,\"/home/travis/build/naveensrinivasan/octokit.net/tools/F>>AKE.Core/tools/FakeLib.dll\"\nXBuild Engine Version 12.0\nMono, Version 4.2.1.0\nCopyright (C) 2005-2013 Various Mono authors\nMSBUILD: error MSBUILD0000: Unknown tools version: '14.0' . Known versions: '2.0' '3.0' '3.5' '4.0' '12.0'\nRunning build failed.\nError:\nBuilding ./Octokit-Mono.sln failed with exitcode 1.\n\nhttps://travis-ci.org/naveensrinivasan/octokit.net/jobs/96853565\n. I tried this one also. It works on OSX but fails on linux for the same commit.\nOSX - https://travis-ci.org/naveensrinivasan/octokit.net/jobs/96858329\nlinux - https://travis-ci.org/naveensrinivasan/octokit.net/jobs/96858330\n. But it works on OSX and fails on linux. The same code. Do you know why? \nAnd when I include PCL it does not fail every time.\n. OK. Thanks. \n. This const string is duplicated in 3 methods. Could we declare it at the class level and use it?\n. ",
    "itmuse": "@distantcam  I find that also cannot edit assets,should you fix it ?\n. @distantcam ok, thanks much!\n. ",
    "izuzak": "This is still an issue, as far as I can tell. Looking at the code, the ApiUrls.ReleaseAssets template is generating an incorrect URI for specific release assets:\n\"repos/{0}/{1}/releases/{2}/assets/{3}\".FormatUri(owner, name, releaseId, assetId);\nNotice that the release id is a part of the above URI template. However, the release id should not be a part of the URI template, as documented here:\n/repos/:owner/:repo/releases/assets/:id\nI suspect that the EditAsset method should be using the ApiUrls.Assets template, and not the ApiUrls.ReleaseAssets template? /cc @distantcam @shiftkey @Haacked \nThe description of the ApiUrls.Assets template seems to be incorrect as well. That URI doesn't return \"all the assets for the specified repository\". It returns a specific asset, defined by the passed in asset id. \n. ",
    "andrewlader": "Any idea when this will be addressed?  As is, you cannot edit a release.  Thus, if I create a draft release, I cannot edit it so that it is published.  Waiting for the next NuGet release :smile: \n. Just validated that version 0.3.5 allows me to pass the necessary Release ID on the call to EditRelease(), and thus publish a draft release.  Thank you!  :white_check_mark: \n. ",
    "prabirshrestha": "@schani @shiftkey  fell free to send a PR to SimpleJson with the test that breaks and fixes this problem. Haven't seen this before.\n. @schani Tested this using SimpleJson in .NET and it correctly sets the name.\n``` c#\nvar user = SimpleJson.DeserializeObject(\"{\\n  \\\"login\\\": \\\"mono\\\",\\n  \\\"id\\\": 53395,\\n  \\\"avatar_url\\\": \\\"https://avatars.githubusercontent.com/u/53395?\\\",\\n  \\\"gravatar_id\\\": \\\"f275a99c0b4e6044d3e81daf445f8174\\\",\\n  \\\"url\\\": \\\"https://api.github.com/users/mono\\\",\\n  \\\"html_url\\\": \\\"https://github.com/mono\\\",\\n  \\\"followers_url\\\": \\\"https://api.github.com/users/mono/followers\\\",\\n  \\\"following_url\\\": \\\"https://api.github.com/users/mono/following{/other_user}\\\",\\n  \\\"gists_url\\\": \\\"https://api.github.com/users/mono/gists{/gist_id}\\\",\\n  \\\"starred_url\\\": \\\"https://api.github.com/users/mono/starred{/owner}{/repo}\\\",\\n  \\\"subscriptions_url\\\": \\\"https://api.github.com/users/mono/subscriptions\\\",\\n  \\\"organizations_url\\\": \\\"https://api.github.com/users/mono/orgs\\\",\\n  \\\"repos_url\\\": \\\"https://api.github.com/users/mono/repos\\\",\\n  \\\"events_url\\\": \\\"https://api.github.com/users/mono/events{/privacy}\\\",\\n  \\\"received_events_url\\\": \\\"https://api.github.com/users/mono/received_events\\\",\\n  \\\"type\\\": \\\"Organization\\\",\\n  \\\"site_admin\\\": false,\\n  \\\"name\\\": \\\"Mono Project\\\",\\n  \\\"company\\\": null,\\n  \\\"blog\\\": \\\"http://mono-project.com\\\",\\n  \\\"location\\\": \\\"Boston, MA\\\",\\n  \\\"email\\\": \\\"mono@xamarin.com\\\",\\n  \\\"hireable\\\": null,\\n  \\\"bio\\\": null,\\n  \\\"public_repos\\\": 161,\\n  \\\"public_gists\\\": 0,\\n  \\\"followers\\\": 0,\\n  \\\"following\\\": 0,\\n  \\\"created_at\\\": \\\"2009-02-10T17:53:17Z\\\",\\n  \\\"updated_at\\\": \\\"2014-06-16T18:56:30Z\\\"\\n}\\n\");\nConsole.WriteLine(\"Hello World: {0}\", user.name);\npublic class User : Account\n{\n}\npublic class Account\n{\n    public string name { get; set; }\n}\n```\n@shiftkey This was the PR you sent that fixed it. https://github.com/facebook-csharp-sdk/simple-json/pull/49\n@schani The only think I can think of this might be breaking is if Xamarin doesn't implement this api correctly. Can you check what this returns on Xamarin and .NET.\n``` c#\npublic static IEnumerable GetProperties(Type type)\n{\nif SIMPLE_JSON_TYPEINFO\nreturn type.GetRuntimeProperties();\n\nelse\nreturn type.GetProperties(BindingFlags.Instance | BindingFlags.Public | BindingFlags.NonPublic | BindingFlags.Static);\n\nendif\n}\n``\n. @schani ExecuteGetProperties(typeof(Ocktokit.User))` on Xamarin and desktop .NET 4.5 from Microsoft (not mono) and see if the number of properties returned are different.\n. ",
    "schani": "This test program exhibits the bug for me:\n```\nusing System;\nusing Octokit;\nusing System.Threading.Tasks;\nusing Octokit.Internal;\nnamespace Test {\n    class MainClass {\n        public static void Main (string[] args) {\n            var s = new SimpleJsonSerializer();\n            var user = s.Deserialize(\"{\\n  \\\"login\\\": \\\"mono\\\",\\n  \\\"id\\\": 53395,\\n  \\\"avatar_url\\\": \\\"https://avatars.githubusercontent.com/u/53395?\\\",\\n  \\\"gravatar_id\\\": \\\"f275a99c0b4e6044d3e81daf445f8174\\\",\\n  \\\"url\\\": \\\"https://api.github.com/users/mono\\\",\\n  \\\"html_url\\\": \\\"https://github.com/mono\\\",\\n  \\\"followers_url\\\": \\\"https://api.github.com/users/mono/followers\\\",\\n  \\\"following_url\\\": \\\"https://api.github.com/users/mono/following{/other_user}\\\",\\n  \\\"gists_url\\\": \\\"https://api.github.com/users/mono/gists{/gist_id}\\\",\\n  \\\"starred_url\\\": \\\"https://api.github.com/users/mono/starred{/owner}{/repo}\\\",\\n  \\\"subscriptions_url\\\": \\\"https://api.github.com/users/mono/subscriptions\\\",\\n  \\\"organizations_url\\\": \\\"https://api.github.com/users/mono/orgs\\\",\\n  \\\"repos_url\\\": \\\"https://api.github.com/users/mono/repos\\\",\\n  \\\"events_url\\\": \\\"https://api.github.com/users/mono/events{/privacy}\\\",\\n  \\\"received_events_url\\\": \\\"https://api.github.com/users/mono/received_events\\\",\\n  \\\"type\\\": \\\"Organization\\\",\\n  \\\"site_admin\\\": false,\\n  \\\"name\\\": \\\"Mono Project\\\",\\n  \\\"company\\\": null,\\n  \\\"blog\\\": \\\"http://mono-project.com\\\",\\n  \\\"location\\\": \\\"Boston, MA\\\",\\n  \\\"email\\\": \\\"mono@xamarin.com\\\",\\n  \\\"hireable\\\": null,\\n  \\\"bio\\\": null,\\n  \\\"public_repos\\\": 161,\\n  \\\"public_gists\\\": 0,\\n  \\\"followers\\\": 0,\\n  \\\"following\\\": 0,\\n  \\\"created_at\\\": \\\"2009-02-10T17:53:17Z\\\",\\n  \\\"updated_at\\\": \\\"2014-06-16T18:56:30Z\\\"\\n}\\n\");\n            Console.WriteLine (\"Hello World: {0}\", user.Name);\n        }\n    }\n}\n```\n. I'm not sure what you're asking me to check.\n. They both report the same properties:\n26 props:\nprop GravatarId\nprop SiteAdmin\nprop DebuggerDisplay\nprop AvatarUrl\nprop Bio\nprop Blog\nprop Collaborators\nprop Company\nprop CreatedAt\nprop DiskUsage\nprop Email\nprop Followers\nprop Following\nprop Hireable\nprop HtmlUrl\nprop Id\nprop Location\nprop Login\nprop Name\nprop OwnedPrivateRepos\nprop Plan\nprop PrivateGists\nprop PublicGists\nprop PublicRepos\nprop TotalPrivateRepos\nprop Url\n. ",
    "dtchepak": "@shiftkey I normally ping @codebetterci. I think @jameskovacs does (or did) a lot of the work on this.\n. ",
    "tomithychen": "Thanks, you're right, this API was what I was really looking for.\nThere was a small typo in the above (it's \"Issue\" instead of \"Issues\"):\nvar client = new GitHubClient();\n var issues = await client.Issue.GetForRepository(\"owner\", \"repository\",\n            new RepositoryIssueRequest {  });\n. ",
    "Sebyd": "I only added the methods. Octokit/Helpers/ApiUrls.cs is the only one that matters. When I commited, this file was also shown as changed. I don't know what it is and because of that I didn't hit the \"revert changes\" button.\n. I checked the status of my commit and it fails on one of your tests.\nTest assembly: C:\\projects\\octokit-net\\clean-up-after-tests\\bin\\Debug\\Octokit.Tests.Integration.dll\n46 \n47..........................................PullRequestsClientTests.CanGetCommitsAndCommentCount [FAIL]\n48   Assert.Equal() Failure\n49   Expected: 2\n50   Actual:   1\n51   Stack Trace:\n52      c:\\projects\\octokit-net\\Octokit.Tests.Integration\\Clients\\PullRequestsClientTests.cs(214,0): at PullRequestsClientTests.d__67.MoveNext()\nCould you solve that, please ?\nThanks\n. ",
    "kevfromireland": "I have an integration test for this as well, but wasn't sure what the project policy is on those. It seems quite brittle unless I create known teams and known repositories in the test setup?\n. Do you want to take it without the integration test, or would you prefer that got in their first?\n. ",
    "MitjaBezensek": "Yeah I agree, maybe I didn't write it clearly enough.\n. ",
    "Arakis": "Because i edited the file via github directly and did a copy and paste from a rdp session, a binary char was \"injected\" somehwere in the file (my fault). I removed it, but you will see \"binary data\" in the diff. Just ignore this, the file is now clean.\n. ",
    "turt2live": "I have tried a very simple solution, but it didn't work :(\nI'll look into it more and make a PR if I get the chance/have the time. \n. ",
    "JoyLeeSoft": "Thanks! It was helpful!!\n. And one more question sir...\nHow can i specific label? example...\nLabel l = new Label();\nl.Name = \"Bug\";\nl.Color = Red;\nissue.AddLabel(l);\nlike this..\nThanks.\n. Thanks a lot! it was very helpful!!!\n. ",
    "tamasflamich": "Awesome! Thank you very much!\n. ",
    "hippiehunter": "I created a PR for this https://github.com/octokit/octokit.net/pull/575\n. Based on the contents of Octokit.nuspec it looks like the supported frameworks stuff is being derived by nuget.exe but ive never used the implicit stuff to determine frameworks before so i don't really know if there is something hidden elsewhere.\nEdit: build.fsx is what determines the nuget package construction i will modify the PR with this once the NSubstitute failure is figured out.\n. I'm not sure i understand the build failure that is present here, how has the addition of wpa81 to the pcl targets caused NSubstitute to not exist in the tests (for all of the test projects)?\n. Is anything else required here?\n. the PCL retargeting dialog adds that rather intentionally when targeting wpa81, wp81 or win81, \n. ",
    "christophwille": "Just so you know why I asked in the first place: OctoCentral Thanks!\n. ",
    "jrowies": "You're welcome :)\n. Cool, thanks!\n. ",
    "xoofx": "Btw, I was wondering why octokit is not using JSON.net?\n. > To be honest, I'm happy to avoid all the \"JSON.net hell\" problems by internalizing our JSON dependency and doing a bit more work... \nCan you elaborate? I have not worked much with JSON.net, so can't really comment on the problem you point, but I would be glad to know more details about your griefs about it (that could help!)\n. This is the json I received on a webhook: https://gist.github.com/xoofx/36ee523a1a24f7566bcf \nI first tried to deserialize this with a simple object with something like this:\n``` C#\nprivate class PullRequestPayload\n{\n    public string Action { get; set; }\npublic int Number { get; set; }\n\npublic PullRequest PullRequest { get; set; }\n\npublic Repository Repository { get; set; }\n\npublic Author Sender { get; set; }\n\n}\n[...]\nvar serializer = new SimpleJsonSerializer();\npayload = serializer.Deserialize(json);\n```\nBut you know what, I just tested it and it is working fine... :sweat_smile: \nOk, forget about the bool fix then, I must have drunk  :beers: \n. > Looking good, just a bunch of little things. \nThanks, I have fixed the remaining issues.\n\nI'd love some unit tests if it's possible to ensure we don't break things in the future.\n\nSure, I will try to find some time to add tests. It was easier to test it directly from my app than to dig into how tests are organize in Octokit.\n. FYI, I just released SharpCLABot, the project that is using these WebHooks API.\nI will take some time in the coming days to provide some official tests of the web hook API.\n. This is to tag Namespace provider to false (actually I just pushed also Models.Request and Http folders), as Octokit is developed in a single namespace, these folders should be removed from namespace providers (otherwise I see the namespace description with a warning with tools like ReSharper)\n. Ah, sorry, didn't look at this script. Will run it again. Maybe using \"shared projects\" from VS2013 will avoid the need for this kind of scripts...\nThis is fixed by commit 48c659a24a765294d07cad94d63e58384f1a25f9\n. This is fixed by commit 41b38c478563a3671652e1e35867cb8445e62945\n. This is fixed by commit b93d5f7ff71ae0cd5c68e028aa03c066fcc793c2\n. This is to fix namespace providers, as Octokit is developed under a single namespace, all subfolders should be unmarked as namespace providers.\n. ",
    "vasily-kirichenko": "Yes, please add this. \n. ",
    "schlamar": "Octokit is already using the system web proxy on .NET per default, only authentication is not enabled. To enable proxy authentication (against the current Windows user) you can just set WebRequest.DefaultWebProxy.Credentials = CredentialCache.DefaultCredentials;, no need to configure something in Octokit...\n. > I assume you mean that the app developer who is using Octokit just needs to set that code, right?\nYes that would be probably the correct way (or update the app.config, see link below).\n\nWhat are the implications of doing that?\n\nThis should have no bad implications at all. Please note that this does only NTLM/Kerberos style authentication and never Basic/Digest, so your credentials are never exposed to a rogue proxy.\nI'm not sure why this isn't enabled per default in .Net. See here for additionally comments: https://visualstudio.uservoice.com/forums/121579-visual-studio-2015/suggestions/2397357-fix-it-so-that-net-apps-can-access-http-thru-auth\n. ",
    "iss0": "Ok, I'll have look. I guess it is pretty easy. \n. !###, I think I made a mistake with the PR. :-/\n. ",
    "javierdlrm": "Sorry I don't know if I use it the right way but in the three forms bellow written, the two methods return me the same list. And none has the issues created by that authenticate user in repositories of other users.\n```\n        var forCurrent = await client.Issue.GetAllForCurrent();\n        var forOwnerAndMember = await client.Issue.GetAllForOwnedAndMemberRepositories();\n    var forCurrent2 = await client.Issue.GetAllForCurrent(new Octokit.IssueRequest() { Filter = Octokit.IssueFilter.Created });\n    var forOwnerAndMember2 = await client.Issue.GetAllForOwnedAndMemberRepositories(new Octokit.IssueRequest() { Filter = Octokit.IssueFilter.Created });\n\n    var forCurrent3 = await client.Issue.GetAllForCurrent(new Octokit.IssueRequest() { Filter = Octokit.IssueFilter.All });\n    var forOwnerAndMember3 = await client.Issue.GetAllForOwnedAndMemberRepositories(new Octokit.IssueRequest() { Filter = Octokit.IssueFilter.All });\n\n```\n. What I want to achieve is to obtain a list of issues that appear on this image. (The first page when I sign in)\n\nBut the issues that I've created in repositories of another user (TubCode), do not appear in any list using these methods... For example TubCode/TubCodeRepo  Issue pruebaTub prueba.\nThanks for your time.\n. Ok, Thanks!\nI have other question.\nIs this API docs https://developer.github.com/v3/repos/forks/ not yet implemented in Octokit.Net? or are there other methods to obtain the list of forks https://developer.github.com/v3/repos/forks/#list-forks in a repository?\n. Thanks a lot!  I've got the list that I wanted with the Search API.\nRegarding forks, I will try to complete the Forks API.\n. ",
    "ctaggart": "I do not modify the pdb files using my code. It is being modified using the Winows pdbstr.exe. I usually test using srctool and Visual Studio. Can you try srctool -x file.pdb first?\nPS C:\\Projects\\octokit.net> cmd /c where pdbstr.exe\nC:\\Program Files (x86)\\Windows Kits\\8.0\\Debuggers\\x64\\srcsrv\\pdbstr.exe\nPS C:\\Projects\\octokit.net> cmd /c where srctool\nC:\\Program Files (x86)\\Windows Kits\\8.0\\Debuggers\\x64\\srcsrv\\srctool.exe\nPS C:\\Projects\\octokit.net> srctool -x Octokit\\bin\\Release\\Net45\\Octokit.dll\n. However you want to do it. In the appveyor.xml file that I added, I just added the SourceLink target there. You are correct that it needs to be run before creating the packages.\n. I downloaded the nupkg files build on appveyor and put them on a local file folder feed.\nhttps://ci.appveyor.com/project/Haacked15676/octokit-net/build/1.0.325/artifacts\nI created a new test project using those packages, set a break point and stepped into the source that downloaded on demand. Here is the source:\n```\nopen Octokit\n[]\nlet main argv = \n    let github = GitHubClient(ProductHeaderValue \"MyAmazingApp\")\n    let user = github.User.Get \"half-ogre\" |> Async.AwaitTask |> Async.RunSynchronously\n    printfn \"%d folks love the half ogre!\" user.Followers\n    0\n```\nScreenshot as proof:\n\nScreenshot of actual download:\n\n. Great meeting you! I really appreciate your enthusiasm about this. \nHow should I follow up about getting the private repository support working? I plan on hunting down some more details soon.\n. You can use 1.0.0 now if you wish. :-) It is the same. Annoucement probably\ntommorrow.\nOn Jul 2, 2015 8:39 PM, \"Brendan Forster\" notifications@github.com wrote:\n\nMerged #829 https://github.com/octokit/octokit.net/pull/829.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/829#event-347060877.\n. Me too! I'll take a look this week.\n. Once you upgrade to the MSBuild 15 tooling, adding in SourceLink v2 is a piece of cake. I recommend it just being a follow-up pull request. Ping me when this is merged and I can assist. Rx.NET just merged source link support and is a good example, in addition to the aspnet mvc PR files.. > Ability to run sourcelink on local builds\nBy default sourcelink is running only on CI server. Ill add a cake parameter allowing us to run sourcelink locally if required. When this parameter is passed to Cake, we can set /p:ci=true parameter on the DotNetBuild task which will cause sourcelink to run. Not sure what other side effects of setting ci=true are though... Alternatively I can investigate how to control running sourcelink or not with a specific parameter maybe\n\nYou could set the environment variables or msbuild properties of CI or SourceLinkCreate to true. They are not case sensitive. See this code for details.\n\nShow sourcelink output in build script output\nCurrently the log doesnt show any of this output unless you set verbosity (passing /v:n to the build task). But that of course shows HEAPS of other output when ideally there would be a way to just see the sourcelink info (or even just the result of dotnet sourcelink test). Let me know if there is anything like that @ctaggart or whether I have to go with verbose mode?\n\n2.1 will be a lot less verbose. It will not print all the source files. I'll probably publish to NuGet Gallery the latest prerelease soon if it passes tests.. SourceLink 2.1.0 is out :-). You are the first to get it working on Travis! Thanks. I'll look to see how you got msbuild 15 running there. With 2.1, you can also just test nupkg files.. It is literally downloading all the source files 1 by 1. I added an up for grabs to speed this up. How fast is your internet connection compared to AppVeyor and Travis CI?. The if Pdbstr.tryFind().IsSome then line isn't needed. Would you like me to remove it? With it removed, you would get this error when not found.\n. Done.\n. ",
    "tabro": "I consider the implementation ready for review.\nThe pullrequest contains the following:\n- Implementation of a MergingClient that implements the github v3 merging api (https://developer.github.com/v3/repos/merging/)\n- Extension of the RepositoryClient and ObservableRepositoryClient with the MergingClient/ObservableMergingClient\n- UnitTests of the MergingClient\n- IntegrationsTest of the MergingClient\n. Some context on why I added the Merging api:\nAt job I wanted to optimize our deployment process by automating merging of our main development branch into a branch that reflects the currently live baseline.\nI tried using the PullRequest api, however since pull requests creates no-ff merges, we get bubble-commits instead of a simple ff merge.\nSo since there was no implementation of the merging API i decided to write it.\n. @Haacked Cool - I corrected the findings! :+1: \n. @Haacked Fixed - build is green again.\n. Ah - doh - I will fix it quickly..\n. ",
    "sharwell": "This is something we're planning to generalize, since it is a strong indicator of unintended behavior:\nhttps://github.com/DotNetAnalyzers/AsyncUsageAnalyzers/issues/5\n. ",
    "gbaychev": "I think it is already implemented, unless I'm looking at the wrong place. See 58bae6f9fca7080aa84c55de27f96195c2d8608e If it is done, could you close this issue, guys?\n. Yep, makes sense. Tomorrow/the day after tomorrow I'll do it.\n. Hi, guys, can I snatch this issue? Anybody working on it?\n. @shiftkey Nice! :) I'll try to send you something in a few days.\n. Yep, it is a good idea, it is done :)\n. :beers: \n. Yeah, breaking the API is not nice, I'll add the overload and fix the doco, but I can do it tomorrow, because today I'm flying. If that is not OK with you guys, then @SimonCropp can go ahead and do it.\n. Hello, I've fixed the xml doc and restored the old api (now marked as obsolete). Interestingly enough as I was syncing my fork, git could not fast forward the stuff, so there is perhaps one unneeded commit. If this is a problem and you have an idea how to fix it, I'm all ears.\n.  Sorry, I totally forgot about this. It is added now, but I've checked the output from the build more carefully and it seems that the Convention tests are failing, because the OrganizationMembersFilter enum has no DebuggerDisplayAttribute. Adding it to an enum does not make much sense to me, but there is the Type.IsModel extension method (TypeExtensions.cs), which determines whether a type should be checked for the attribute or not. Should I add a type.IsEnum check? Or there is another possibility?\n. It should be OK now.\n. Done\n. ",
    "mkchandler": "Just ran in to this issue today. @SimonCropp, if you don't have time for a pull request, let me know and I can help.\n. @SimonCropp :+1: \n. I see this was merged in to master and v0.5.3 was released, but I'm not seeing these changes in the v0.5.3 NuGet package. Was it somehow withheld from the release?\n. Sounds good :+1: Thanks\n. @M-Zuber Any updates on this? . @M-Zuber No worries! Life happens, I definitely understand :-). ",
    "RobPethick": "@shiftkey looks like you've done some work updating CONTRIBUTING.md and adding a powershell script to help with this, so I have just added a comment in the helper, reckon it is worth a PR?\n. I'd like to work on this one\n. I'd like to work on this one\n. I'll take this. And implement as Git as I think matching the API is best.\n. Thanks @shiftkey  updated :)\n. Putting up a new PR due to needing to rebase my branch onto master\n. @shiftkey any idea why this is failing? It looks like it is complaining about building Tests-Portable but it seems to build locally just fine for me have I missed something?\n. @naveensrinivasan Ah I thought it might be something like that thanks for confirming\n. ",
    "Miramac": "yes, i  suspect this is a false positive too ;-)\nmy admin is reporting the file to GData right now. Unfortunately you do not get feedback from GData, they are simply whitelist the file.\n. It seems to be normal again! Today I had no problems with the Windows GitHub client and GData.\nVirusTotal also gives his OK: https://www.virustotal.com/en/file/0896d3d87243177bab623ced8a1c17e6b143fb4831031592bd427ab2dabe0162/analysis/1418139685/\nI close the Issue.\n. ",
    "omidkrad": "Putting aside paging for the moment, what's the simplest way to get the SHA of HEAD commit in the master branch?\nBTW, I was not able to run your code snippet. I get: 'Octokit.Reactive.ObservableIssuesClient' does not have a definition for 'Repository'\n. Great, thank you Brendan @shiftkey\n. This is common. See these for examples of data hosted on GitHub:\n- http://data.okfn.org/data\n- http://dataprotocols.org/\n. ",
    "dampir": "@ryangribble, @shiftkey could this one be closed as solved because Octokit.NET in one little step from release with pagination support?\n. I know it is the old question, but have some info about it.\n\nsince=0001-01-01T00%3A00%3A00Z isn't considered a valid date under /notifications\n  since=2001-01-01T00%3A00%3A00Z works fine\n  probably just some edge case thing that was introduced recently\n\nIt is not exactly a corner case, because issue arises from dates in range from 0001-01-01 00:00:00 to 0999-12-31 23:59:59 i.e. when year is less that 1000 (YYYY < 1000). So, the next query not work too:\ncurl --user \"user:pass\" \n\"https://api.github.com/notifications?all=false&participating=false&since=0999-12-1T23%3A59%3A59Z\"\nAnd further, it is looks like issue is total. I've checked the next query and it is fails too:\ncurl --user \"user:pass\" \"https://api.github.com/user/issues?since=0999-12-31T23%3A59%3A59Z\"\nSo, I guess there is some issue (or it is a feature?) with validation schema on API side. Maybe makes sense add some common validation on date fields in Octokit.Net, like the next one:\ncsharp\nEnsures.ArgumentInValidRange(date, \"date\"); // fails if date less that 1000-01-01 00:00:00\n/cc @shiftkey, @ryangribble \n. @shiftkey I think this could be closed for now :+1: \n. [MAC OS] \n\nAssertion at metadata.c:3643, condition `ptr' not met\n\nhttps://gist.github.com/dampir/b96ee54c5153d8b6f5aed65340ba6e9e\nhttps://travis-ci.org/octokit/octokit.net/jobs/136667692\n. Hello, @shiftkey! I want to implement this idea during GSoC 2016. I know that application period starting since 15 March and I will send my proposal after this date with usage of application form, but I have done some investigation of this task right now.\nI think that we could create overloaded method that use repository Id as main parameter for each method that use owner and repo name as their parameters. This is @Zoltu example:\n``` csharp\npublic interface IBlobsClient\n{\n    Task Create(String owner, String name, NewBlob newBlob);\n    Task Create(String id, NewBlob newBlob);\nTask<Blob> Get(String owner, String name, String reference);\nTask<Blob> Get(String id, String reference);\n\n}\n```\nI found about 29 client interfaces in Octokit project that use owner and name of repository parameters, so we could create overload for each of theirs methods (I have counted about 175 methods in these interfaces).\nI think that usage of such overloads is more preferable  than creation some kind of abstract concept of Repo (as was suggested by @Zoltu in first message), because we get more simple and clean interfaces.\nSo, my proposal is create overload for each method that use owner and name parameters now and create test case for each of them.\n. This post describes the work I've done for the GSoC 2016. Here are presented all PRs that I've created in order to add support into Octokit.NET for lookup by repository Id throughout GitHub APIs. I'm going to send the link to this post as work product submission for final evaluation of GSoC 2016. \nHere are additional links:\n- Octokit.NET 0.21 - first release of Octokit.NET with the repository Id support. Here is a cite from release notes:\n\nThis release adds support across Octokit.net for providing the repository Id\nrather than a name/owner pair. The repository Id does not change when transferring\nownership of a repository, and is more robust for API callers. This work\nwas lead by @dampir as part of Google Summer of Code 2016.\n- Merged repository id PRs - the link on merged PRs that I've created during GSoC 2016.\n\nI want to say big thank you for all people that help me during GSoC period, especially for my mentor @shiftkey. :+1: :pray:  Also I want to say big thank you for @ryangribble for help in review and merge of so big amount of PRs. :+1:  :pray:\nFull list of clients that were changed during GSoC 2016:\n- [x] Collaborators #1387 (IRepoCollaboratorsClient, IObservableRepoCollaboratorsClient)\n- [x] Comments #1344 (IRepositoryCommentsClient, IObservableRepositoryCommentsClient)\n- [x] Commits #1345 (IRepositoryCommitsClient, IObservableRepositoryCommitsClient)\n- [x] Contents #1348 (IRepositoryContentsClient, IObservableRepositoryContentsClient)\n- [x] Deploy Keys #1351 (IRepositoryDeployKeysClient, IObservableRepositoryDeployKeysClient)\n- [x] Deployments #1352 (IDeploymentsClient, IObservableDeploymentsClient)\n- [x] Forks #1356 (IRepositoryForksClient, IObservableRepositoryForksClient)\n- [x] Merging #1346 (IMergingClient, IObservableMergingClient)\n- [x] Pages #1357 (IRepositoryPagesClient, IObservableRepositoryPagesClient)\n- [x] Releases #1370 (IReleasesClient, IObservableReleasesClient)\n- [x] Statistics #1371 (IStatisticsClient, IObservableStatisticsClient)\n- [x] Statuses #1360 (ICommitStatusClient, IObservableCommitStatusClient)\n- [x] Webhooks #1361 (IRepositoryHooksClient, IObservableRepositoryHooksClient)\n- [x] Blobs #1362 (IBlobsClient, IObservableBlobsClient) \n- [x] Assignees #1367  (IAssigneesClient, IObservableAssigneesClient)\n- [x] Commits #1366 (ICommitsClient, IObservableCommitsClient) \n- [x] DeploymentStatus #1368 (IDeploymentStatusClient, IObservableDeploymentStatusClient) \n- [x] Events #1375 (IEventsClient, IObservableEventsClient)\n- [x] Issue Comments #1379 (IIssueCommentsClient, IObservableIssueCommentsClient)\n- [x] Issues #1380 (IIssuesClient, IObservableIssuesClient)\n- [x] Issue Events #1373 (IIssuesEventsClient, IObservableEventsClient)\n- [x] Issue Labels #1393 (IIssuesLabelsClient, IObservableIssuesLabelsClient)\n- [x] Milestones #1392 (IMilestonesClient, IObservableMilestonesClient)\n- [x] Notifications #1390 (INotificationsClient, IObservableNotificationsClient)\n- [x] Pull Requests #1394 (IPullRequestsClient, IObservablePullRequestsClient) \n- [x] References  #1391 (IReferencesClient, IObservableIeferencesClient)\n- [x] Starring #1389 (IStarredClient, IObservableStarredClient)\n- [x] Tags #1363 (ITagsClient, IObservableTagsClient)\n- [x] Git Trees #1369 (ITreesClient, IObservableTreesClient)\n- [x] Watching #1372 (IWatchedClient, IObservableWatchedClient)\n- [x] Commit Comment Reactions #1382 (ICommitCommentReactionsClient, IObservableCommitCommentReactionsClient)\n- [x] Issue Comment Reactions #1383 (IIssueCommentReactionsClient, IObservableIssueCommentReactionsClient)\n- [x] Issue Reactions #1384 (IIssueReactionsClient, IObservableIssueReactionsClient)\n- [x] Pull Request Review Comment Reactions #1385  (IPullRequestReviewCommentReactionsClient, IObservablePullRequestReviewCommentReactionsClient)\n- [x] Pull Request Review Comments #1395 (IPullRequestReviewCommentsClient, \n  IObservablePullRequestReviewCommentsClient)\n- [x] Repositories #1397 (IRepositoriesClient, IObservableRepositoriesClient)\n. @ryangribble tnx, I will do that in future. For some reasons I've used \"refers\" instead of \"fixes\" :smile: \n@devkhan As far as in github blog post nothing mentioned about rights, I guess auto close should work.\nMaybe you confused with this: Closing issues via commit messages?\n. @ryangribble sorry, I forgot \"fixes\" magic word in PR :dizzy_face:  Can be closed for now :+1: \n. This method \ncs\nTask<IReadOnlyList<User>> GetAll(String org, String filter)\nwas fired by 0a0829d5\n. I guess here only one method should be updated.\nTask<IReadOnlyList<ReleaseAsset>> GetAllAssets(String owner, String name, Int32 id)\nGetAll method is already implemented.\n. Can be closed now.\n. @shiftkey , @ryangribble \nIt is hard to say why, but this client does not have ApiOptions overload at this moment. Please reopen it , I'll deliver ApiOptions overloads here as far as possible.\n. Can be closed now I guess.\n. @shiftkey, I have one question about integration tests for IObservableUserEmailsClient. \nIn aa3ce0d you're added test ReturnsDistinctResultsBasedOnStartPage for IObservableReleaseClient.\nHow can I implement such tests for IObservableUserEmailsClient and IUserEmailsClient? \nI use my fake github account for integration test and there is exists only one email. \n. > @dampir yeah, email addresses are tricky. Let's not worry about integration testing pagination on those. \nTnx, I removed unnecessary tests.\n@ryangribble\n@shiftkey\nI am fully agree with you about \"ApiOptions\" Singleton (especially, mutability breaks Singleton approach) and \"GetResponse\" overload. Both of these changes were made in order to implement needed unit/integration tests.\nI removed Singleton and overload of \"GetResponse\" extension. Also I rewrote necessary tests a little bit.\n. @shiftkey Ohh, sorry for that! I don't know that GitHub so smart. I not going to do that in future!\n. > Thanks for going the extra mile to address my consistency nitpicks!\n@shiftkey,\n@ryangribble \nThx for your patient and detailed explanations! :+1: \n. I added new integration tests in last commits.\n/cc @ryangribble \n. Tests for Linux (Mono) aren't passed for some reasons... \n. Yep, I thought about separate PR for each type of changes, so I'm going to create small PR in further, because all changes are small and quite simple. There are some common code cleanups that I want to provide. \n. @devkhan, everything is done.\n. Changes has been reverted. I'll exclude that file from Resharer's analysis.\n. > After adding ApiOptions overload to the methods, we change the implementation of the old method to just call the new one with ApiOptions.None. Why don't we just write one method and use default values of ApiOptions.None?\n@devkhan, I am agree with such approach, it could be very convenient, because instead of 2 method in interface we will have only one with default parameter. Since there are not so many overloads were added, we can do refactor easily at this stage.\nUnfortunately, we can't use not compile-time constant as default parameter for method. So, the next code will be irrelevant:\ncs\npublic Task<IReadOnlyList<Release>> GetAll(string owner, string name, ApiOptions options = new ApiOptions())\n{\n// ApiOptions options = new ApiOptions() is irrelevant construction for default parameter in C#.\n}\nAlso, we can't use null as default value for ApiOptions, it cause unnecessary null checking inside internal code. So, we use new ApiOptions() as default value of options parameter and we should use \"the old good\" overload without any C# syntax sugar. \n. I've done some refactorings, pls, check this out whenever possible.\n/cc @shiftkey @ryangribble \n. @shiftkey I've fixed all remarks, pls take a look.\n. @ryangribble I've added new ObservableAssigneesClientTests. Pls, take a look.\n. @shiftkey, all checks, pls, check this out whenever you want :)\n. @devkhan Guess after we choose name convention for these classes, we can add additional checks in Conventions test rather in FormatCode. Anyway, it would be very cool to have such additional check.\n. @ryangribble, thanks, I am very glad :+1: \nI am agree, the way I've located the assembly is smell a little bit :smirk:. I found that way here: https://github.com/octokit/octokit.net/blob/f354d1bf00ff7606b46489e3a915e1428414bc47/Octokit.Tests.Conventions/SyncObservableClients.cs#L123\nI'll think a little bit and will try to deliver more common way.\n. Yeah, I'm agree about GitHubClientTests, it is looks very good for this purpose :+1: . Fixed!\n. > I wonder whether we should change all the other Convention tests over to using those top level types too instead of EventsClient/ObservableEventsClient etc (perhaps in another PR, or perhaps on this one if it is reworded to \"Add convention test for Ctor constructor and tidy up other convention tests\"...\nI've marked it in my notes \"Tidy up conv. tests\", so it would be my next PR :+1: \nBy the way, I've found some incosistency in method's name that test constructor, I going to add additional check for that, if nobody minds :smile: \n. In order to deliver more consistency I've added new convention check. Now each test class \"TheCtor\" should have method EnsuresNonNullArguments that test a client constructor against null arguments. Please take a look.\n. @shiftkey what I can do in order to fix merge conflict?\n. @devkhan , great thanks, rebase passed.\n. @devkhan , yes, I did. Is it an error?\n. Unfortunately, I can't say what I did exactly, because it was my first \"git rebase\" at all. Now I am not so sure that I did right \"git pull\" from upstream before rebase. Can I do something that can help fix this situation?\nThere were some errors after rebase (not about merge, but about push), so I searched errors over internet and tried to fix that.\n. @devkhan , I going to use --force next time, thanks!\n. @shiftkey I've revert rebase and repeat it again today. Please, check this out whenever possible :smile: \n. @shiftkey thank you, all remarks were fixed. Ready to merge, I guess :+1: \n. Hello @prayankmathur! I'm working on #1120 and as part of this feature I should add overloads to\nI(Observable)RepositoryCommentsClient. But it's depends on this feature too, could you come back and finish this feature?:smile:\n. @shiftkey, @ryangribble  this one can be close for now :+1: \n. Hi @SamTheDev! Are you going to return here and continue the work on this issue?:smile: If no, please send a message here, I will assign it for myself :smile: \n. I guess this PR can be closed for now :+1:\n/cc @shiftkey, @ryangribble\n. @shiftkey, @ryangribble I think it is ready to review and merge after travis restart.\n. @ryangribble , you're absolutely right! Fixed!\n. Hi, @devkhan! Are you going to continue your work on this issue in near future :smile:? Just in order to do #1120 pagination support milestone should be done, so if you are not going to continue in near future I'm mark this one to do by myself :smile: \n. @devkhan thank you for fast response, I've marked this issue in my notepad. Anyway there is a lot of other \"pagination support\" issues that should be done before, so there is chance that I can not make it in time before 5th June :smile:\n. All checks passed, pls review PR whenever possible.\n/cc @shiftkey, @ryangribble\n. Travis-ci falls again, please rerun it whenever possible.\n/cc @shiftkey , @ryangribble \n. Could anybody merge it if there is no problems?\n/cc @shiftkey, @ryangribble \n. @ryangribble yes and don't have any suspicions why it failed...\nI've figured out - OrganizationMembersClient.cs is missed during rebase I don't know why :dizzy_face: \n. Hope it is fixed in the last commit. Merge/rebase always makes my cry :cry: \n\n. > seeing the inlined URLs being extracted!\nWithout it I can't properly generate new urls to access API by repo id :smile: \nHope it would be merged as far as possible in order I can pull out these new urls.\n. @shiftkey all remarks are fixed. Could you merge it, please?\n. @shiftkey, @ryangribble could you merge it please? I want to start implement my GSOC proposal goal and this PR is the important part of it :pray: \n. @shiftkey all fine, thanks! :smile: \n. @ryangribble yes, you're definitely right! I also think that \"ApiOptions\" release should be deliver before \"repositoryId\" one.\nMaybe it is would be useful, here is the list of clients that should get \"repositoryId\" overloads \nthrough GSoC 2016. I've marked items that have already ApiOptions overloads, \nadded issue link with [WIP] prefix if issue has been grabbed by someone \nand just added link to open issue if there is nobody is working on this one, bolded items haven't pagination support:\n- [x] Collaborators #1170 (IRepoCollaboratorsClient, IObservableRepoCollaboratorsClient)\n- [x] Comments ~~#1262~~, #1310 (IRepositoryCommentsClient, IObservableRepositoryCommentsClient)\n- [x] Commits #1173 (IRepositoryCommitsClient, IObservableRepositoryCommitsClient)\n- [x] Contents #1174 (IRepositoryContentsClient, IObservableRepositoryContentsClient)\n- [x] Deploy Keys #1175 (IRepositoryDeployKeysClient, IObservableRepositoryDeployKeysClient)\n- [x] Deployments #1151 (IDeploymentsClient, IObservableDeploymentsClient)\n- [x] Forks #1176 (IRepositoryForksClient, IObservableRepositoryForksClient)\n- [x] Merging (IMergingClient, IObservableMergingClient)\n- [x] Pages #1304 (IRepositoryPagesClient, IObservableRepositoryPagesClient)\n- [x] Releases #1169 (IReleasesClient, IObservableReleasesClient)\n- [x] Statistics (IStatisticsClient, IObservableStatisticsClient)\n~~There is no issue, but I think that it should be added because of IStatisticsClient.GetContributors(string owner, string repositoryName) method?\nAm I right?~~\n   It's looks like [Statistics](https://developer.github.com/v3/repos/statistics/#get-contributors-list-with-additions-deletions-and-commit-counts) do not support pagination at this time. The [query ](https://api.github.com/repos/octokit/octokit.net/stats/contributors?page=2&per_page=5) returns whole statistics instead paginated results. It is similar to #1315.\n\n\n[x] Statuses #1150 (ICommitStatusClient, IObservableCommitStatusClient)\n[x] Webhooks #1177 (IRepositoryHooksClient, IObservableRepositoryHooksClient)\n\nI think that I could do these issues with ApiOptions before work on repositoryId overloads, as far as I can.\n05/28/2016\nAll items from this list are done.\n. @shiftkey, @ryangribble please review these PR whenever possible, it's done.\n. Somehow these tests are working on my machine from time to time and do not work on CI at all. I've tried to understand what is wrong with RequestsTheCorrectUrlWithApiOptions test case, but I haven't saw any errors. It's looks like multithread error somewhere and at this moment I can't find out where it is.\nIt is failed test and it should work but it don't.\n``` cs\n[Fact]\n            public async void RequestsTheCorrectUrlWithApiOptions()\n            {\n                var connection = Substitute.For();\n                var client = new ReleasesClient(connection);\n            var options = new ApiOptions\n            {\n                StartPage = 1,\n                PageCount = 1,\n                PageSize = 1\n            };\n\n            await client.GetAllAssets(\"fake\", \"repo\", 1, options);\n\n            connection.Received().GetAll<ReleaseAsset>(Arg.Is<Uri>(u => u.ToString() == \"repos/fake/repo/releases/1/assets\"),\n                null,\n                \"application/vnd.github.v3\", options);\n        }\n\n```\n. @shiftkey yeah, I fixed that, it's my misspell. But anyway, the tests failed. As I see there is must be call received by ApiConnection Substitution. And these tests is working on my PC for now. But CI cannot pass them. I really confused such situation..\n. @shiftkey, @ryangribble I've fixed errors in tests, accidentally I've used Args.ApiOptions instead of ApiOptions.None and it gives strange result: in parallel tests falls, but in single thread they executed successfully. I found this info [Unit Test fails on Run All but not on Run Selected Tests with all selected`](http://stackoverflow.com/questions/14349512/unit-test-fails-on-run-all-but-not-on-run-selected-tests-with-all-selected) and fixed this error. So, now all tests are passed.\n. > Not sure if we need to do anything else here, but something to be mindful of...\nYeah, definitely no any changes have to be done in such situation, it is just interesting behaviour that blowed my mind for 2 days :smiley:. Maybe it would be useful information for someone :+1: \n. @ryangribble all remarks were fixed :+1: \nSIGSEGV again on Mono :cry: \n. ~~@shiftkey , @ryangribble I think that something wrong with Travis CI or AppVeyor. As in #1308, some tests that worked before, now are broken. For instance, in the last build log \nOctokit.Tests.Reactive.ObservableGistsTests+TheGetAllStarredMethod.RequestsTheCorrectUrlWithSince is failed without reason. And my new methods (RequestsCorrectUrlWithApiOptions) not working too. It looks like some bug on NSubstitute.~~\nErrors are fixed, they were the same as here #1308 (copy-paste hell :smile: )\n. @shiftkey , @ryangribble all errors are fixed, just another mono SEGENV error. Please, merge whenever possible.\n. @shiftkey , @ryangribble all errors were fixed, please merge whenever you have time :smile:\n. @ryangribble all remarks were fixed!\n. Hi @lrz-hal ! I see you haven't implemented Observable version of new methods. Unfortunately in this case CI cannot be passed successfully. Also you have to add new unit tests for Observable client, as far as new integration tests for new methods.\n. Tests are passed, but Mono SIGABRT fails again.\n. @ryangribble all remarks were fixed, thanks! SIGSEGV again :cry: \n@shiftkey I want to add that Statistics do not support pagination as I mentioned in #1305, also I opened an issue #1315 for further discussion, but maybe it is overkill and we can solve this question here.\n. @ryangribble good remark, fixed :smile: !\n. I'm going to fix that, but I can't use standard approach \"create new method, fix all usages, mark old methods by Obsolete attribute\", because in this case type of parameters is equal (string). So it will be breaking change in this case. In what way it should be fixed?\n. Yeah, all worked :smile: ! I'm not insisting on fixing in any case, just I was wonder :scream_cat:  when I found it. And yes, breaking changes are very bad, but I thought that since version of Octocit.NET is far from 1.0 and maybe users are ready to breaking changes, so it can be fixed as far as it was located.\n. If so, I don't mind if it would be closed :+1: \n. No, I haven't. Unfortunately, I don't know a lot of about enterprise integration test procedure, so do it at your discretion :smile: \nAnyway, if there is exists an possibility to provide me test enterprise credentials for period of GSoC, I think that I could run and debug enterprise integration tests by myself :+1: \n. > GitHub Enterprise is a version of GitHub that an organization hosts on their own servers (either on prem or cloud). They do have a free 45 day trial though, so potenitally you could spin one up if you have AWS or Azure credit, or enough hardware at home for the minimum spec (16GB RAM).\nThank you for good explanation, now I really get it.\n\nBut it really isn't necessary\n\nIf so, I really hope that there are not so many clients that should use Enterprise API (throughout my GSoC) :smile: \n. @shiftkey I going to handle this merge conflict tomorrow, not have access to PC at this moment (I had a 2 day trip to Moscow in US embassy to get visa, so tomorrow I'm going to be home and I will fix that \ud83d\udc4d )\n. @shiftkey I've rebased this one, just plesky travis failed again. Please merge it whenever possible :+1: \n. @maddin2016  I guess nobody knows it. Here is #1076 where such fails are logged.\n. @shiftkey please rerun Travis, it failed again :cry: \n. @ryangribble yep, you are right, I've found 2 places where Args.ApiOptions used instead of ApiOptions.None \ud83d\udc4d \n. @shiftkey it is looks like I have to review all 26 existent repositoryId PRs to fix XML documentation things, because I've used similar pattern to write docs. So, I'm going through it as slowly and methodically as possible do it :+1:  But, firstly, I want add repositoryId PRs  for new Reactions clients (they are simple and small :+1: )\n\nI think once we settle on the reviews for the first couple of these PRs that it should really fly through!\n\nI glad to hear that :+1:  Let's do this :smile: \n. @shiftkey I've updated XML docs according your remarks. Please review it whenever possible and if all ok, I'm going to pass through other PRs and update their docs.\n. @shiftkey I've cleared XML docs here. I suppose I should clear  in every PR that I've done for repository id, because they are similar these ones.\n. @shiftkey sorry, missed this! Fixed :+1: \n. no need to update , they are empty.\n. @shiftkey done :+1: \n. I haven't changed XML docs here, so lets it stay as is.\n. I've cleared  tags here.\n. I've clear  tags here.\n. @ryangribble I've removed  tags here.\n. @ryangribble could you review it and merge? Or we are have to waiting while @shiftkey review this too?\n. @ryangribble I've fixed all remarks\n. I've cleared  tags here.\n. @shiftkey I've add only 2 new guards, but I think it would be a breaking change, because of initial method implementations:\nrequest == null\n                ? ApiConnection.GetAll<Repository>(ApiUrls.RepositoryForks(owner, name), options) :\n                ApiConnection.GetAll<Repository>(ApiUrls.RepositoryForks(owner, name), request.ToParametersDictionary(), options);\nWhat do you think? Should I add null checks?\n. @shiftkey I agree with you, just I remember that there was other such case in codebase that allow pass null as correct parameter and we left it without additional null checks because of breaking changes (cannot find it right now). Anyway, I'm going to fix this in next 1-2 days :+1: \n. @shiftkey done!\n. @ryangribble please rerun travis here, it fails again because of seg fault.\n. I've cleared  tags here.\n. @shiftkey done!\n. @shiftkey it is looks like here another bug in travis build.\n. I've cleared  tags here.\n. @shiftkey done!\n. @ryangribble please rerun this too :+1: \n. I've cleared  tags here.\n. @shiftkey I've done it, please check this out whenever possible :+1: \n. I've cleared  tags here.\n. @shiftkey  done!\n. @ryangribble please rerun it too :+1: \n. I've cleared  tags here.\n. @shiftkey done!\n. I've cleared  tags here.\n. @shiftkey done!\n. @ryangribble please add RepositoryId milestone mark here too :+1: \n. I've cleared  tags here.\n. @shiftkey I've removed  tags here.\n. I've cleared  tags here.\n. @shiftkey done!\n. I've cleared  tags here.\n. I've cleared  tags here.\n. @ryangribble I've fixed integration tests and removed  tags, please check this out :+1: I hope that I've fixed all issue places.\n. @ryangribble  I've fixed all remarks \ud83d\udc4d \n. I've cleared  tags here.\n. @shiftkey done!\n. @ryangribble please rerun Travis whenever possible :+1: \n. I've cleared  tags here.\n. @shiftkey I've removed  tags here.\n. @ryangribble please rerun Travis whenever possible :+1: \n. I've cleared  tags here.\n. @shiftkey I've burned  tags \ud83d\udc4d \n. @shiftkey I've fixed all stuff except docs :+1: \n. @ryangribble please rerun Travis whenever possible :+1: \n. I've cleared  tags here.\n. I've cleared  tags here.\n. @shiftkey I've worked on your remarks, please review it whenever possible :+1: \n. @ryangribble please rerun it, Travis fails again :cry: \n. I've cleared  tags here.\n. @shiftkey  done!\n. I've cleared  tags here.\n. @ryangribble could you rerun Travis and assign RepositoryId milestone here?\n. @ryangribble could you rerun Travis and assign RepositoryId milestone here?\n. I've cleared  tags here.\n. @ryangribble could you rerun Travis and assign RepositoryId milestone here?\n. I've cleared  tags here.\n. @shiftkey done!\n. I've cleared  tags here.\n. @shiftkey done!\n. @shiftkey It could be closed, all overloads were added.\n. I've cleared  tags here.\n. @shiftkey, @ryangribble not sure why I did that (revert integration tests), it was made accidentaly  I guess. Anyway, now it is fixed. Also, I removed  tags.\n. I've cleared  tags here.\n. @ryangribble done! I'll try to clear all returns tags in RepositoryId PRs.\n. I've cleared  tags here.\n. @ryangribble done :+1: \n. No need clear  tags, they are clean.\n. no need to clear  tags, they are clean.\n. I've cleared  tags here.\n. @shiftkey done!\n. I've cleared  tags here.\n. @shiftkey done!\n. I've cleared  tags here.\n. @shiftkey done!\n. @ryangribble thank you for positive feedback :+1: \n. @maddin2016 I guess @shiftkey talking about his comments in your last commits. If you delete commented/dead code and do something else it can be merged.\nhttps://github.com/octokit/octokit.net/pull/1411/files#diff-6792693a30870bb1388f1ae706bbedd7R265\n. @alfhenrik since version 0.21.1 every \"owner/name\" method has overload that use repository id instead of owner/name pair. Could you add it in your PR?\n@ryangribble not sure, but I think that now every new clients have to have repostoryId overload for each owner/name method, aren't they?\n. @shana I knew that consistent naming in repository Id implementation could be useful someday, but I don't even supposed that it would be so soon :smile: \nBest code practices in action :+1:\n. @jaredpar I think that this behaviour due to StartPage = 0. Did you try change StartPage to 1?\n. @aetos382 good catch! The fix of this issue looks very simple and if you need this fix as ASAP just change attribute value on Language enum.\nSo, this one SearchRepositoriesRequest.cs#L449\ncsharp\n [Parameter(Value = \"C#\")]\n CSharp,\nshould be changed on:\ncsharp\n [Parameter(Value = \"CSharp\")]\n CSharp,\nAnyway, I made some investigation why integration tests in Octokit didn't catch this issue. It's quite interesting thing! Octokit have integration test for SearchCodeRequest SearchClientTests.cs#L436: \n``` csharp\n    [IntegrationTest]\n    public async Task SearchForExcludedLanguage()\n    {\n        var language = Language.CSharp;\n    // Search for issues by include filter\n    var request = new SearchIssuesRequest(\"octokit\");\n    request.Language = language;\n\n    var issues = await _gitHubClient.Search.SearchIssues(request);\n\n    // Ensure we found issues\n    Assert.NotEmpty(issues.Items);\n\n    // Search for issues by exclude filter\n    var excludeRequest = new SearchIssuesRequest(\"octokit\");\n    excludeRequest.Exclusions = new SearchIssuesRequestExclusions\n    {\n        Language = language\n    };\n\n    var otherIssues = await _gitHubClient.Search.SearchIssues(excludeRequest);\n\n    // Ensure we found issues\n    Assert.NotEmpty(otherIssues.Items);\n\n    // Ensure no items from the first search are in the results for the second\n    Assert.DoesNotContain(issues.Items, x1 => otherIssues.Items.Any(x2 => x2.Id == x1.Id));\n}\n\n```\nAs you can see to create SearchIssuesRequest class the constructor with one parameter is used:\ncsharp\nvar request = new SearchIssuesRequest(\"octokit\");\nThe GitHub Search Code Api has some restrictions and one of them is:\n\nYou must always include at least one search term when searching source code. For example, searching for language:go is not valid, while amazing language:go is.\n\nSo, how this test can be correct in case of this bug with '#' symbol? Answer is simple: this test is correct  but not for C#. Instead of sending search request for C# it is sending request on C language!\n``` csharp\n    [IntegrationTest]\n    public async Task SearchForExcludedLanguage()\n    {\n        var language = Language.CSharp;\n    // Search for issues by include filter\n    var request = new SearchIssuesRequest(\"octokit\");\n    request.Language = language;\n\n    // generated URL: \"https://api.github.com/search/?page=1&per_page=100&order=desc&q=GitHub+language:C\"\n    // Search issues on C language instead of C#\n    var issues = await _gitHubClient.Search.SearchIssues(request);\n\n    // Ensure we found issues\n    Assert.NotEmpty(issues.Items);\n\n    // Search for issues by exclude filter\n    var excludeRequest = new SearchIssuesRequest(\"octokit\");\n    excludeRequest.Exclusions = new SearchIssuesRequestExclusions\n    {\n        Language = language\n    };\n\n    var otherIssues = await _gitHubClient.Search.SearchIssues(excludeRequest);\n\n    // Ensure we found issues\n    Assert.NotEmpty(otherIssues.Items);\n\n    // Ensure no items from the first search are in the results for the second\n    Assert.DoesNotContain(issues.Items, x1 => otherIssues.Items.Any(x2 => x2.Id == x1.Id));\n}\n\n```\n@aetos382  in order to use SearchIssuesRequest in right way you have to use the next constructor:\ncsharp\n        /// <summary>\n        /// Search using a specify keyword\n        /// </summary>\n        /// <param name=\"term\">The term to filter on</param>\n        public SearchIssuesRequest(string term) : base(term)\n        {\n            Repos = new RepositoryCollection();\n        }\nand do not use SearchIssuesRequest parameterless constructor that created for correct Json deserialization.\nI'm going to create PR to fix this bug.\n. Mark every method that return Task as obsolete it means mark Octokit.NET as obsolete (Observable methods are just wrappers). And I think that this is unacceptable for now. Time for such code convention decision is gone for Octokit. \n\nConsistency, predictability and readability of an API is not zero benefit. \n\nI definitely agree with that, but not in case of Octokit and Async suffix. Octokit is fully asynchronous library, each method in each client is async. This .NET Framework 4.5 library and it doesn't have any legacy API that uses obsolete asynchronous programming patterns (such as APM or EAP). So, I think that in case of Octokit Async suffix not so valuable and can be omitted.\n\nThe main reason I suggested this was that when starting with the API this completely throw me off. I knew what I wanted had to be async, but I couldn't find any async methods. \n\nMaybe, it will be nice add remark about lack of Async suffix in README.md with accent on the fact that Octokit is fully async?\n. Tnx, @devkhan, you're absolutely right, usage of Any is more convenient in this situation. Fixed in ad3b782.\n. Yes, sure, I going to fix it right now!\n. Ok, I had some doubts about this test case too. I going to remove it, thx!\n. Yeah, I changed it :+1: \nFind one more TheGetAllMethods in GistsClientTests.cs, but not changed.\n. For some reasons VS do not show ending whitespaces in own diff tool. Is my mistake, fixed.\n. Yeah, I agree, I like the consistency too :+1: Fixed,\n. I updated method's documentation.\n. I'm fully agree, will be fixed in the next commits. Now I unmarked items in PR todo list, so WIP :)\n. I'm fully agree, fixed in the next commits. Also, I reviewed other places where ApiOptions is used and update the tests accordingly.\n. Done!\n. Done!\n. cs\nEnsure.ArgumentNotNullOrEmptyString(owner, \"owner\");\nEnsure.ArgumentNotNullOrEmptyString(name, \"name\");\nShould we save these checks here in GetAll(string owner, string name) if we have them in overloaded method GetAll(string owner, string name, ApiOptions options) too? \n. Fixed.\n. Do you mean, I should move creation of these additional commits from test constructor to each ApiOption test method?\n. All reasons sounds reasonable :) I'll refactor it.\n. No problem. So I will not change that in future.\n. Yep)\n. Oh, I missed some places, sorry! Fixed.\n. Fixed (I guess :) )\n. I have one remarks about it. Yes, it is breaking changes, but this fully incorrect items (Elixer, Unified _Paralel _ C), these items never works correctly and if somebody use these then he doesn't  get any search results. Anyway, I reverted older items back and added new correct items. Hope they will be removed in further release :bowtie:.\n. Could you add here:\ncs\nEnsure.ArgumentNotNullOrEmptyString(owner, \"owner\");\nEnsure.ArgumentNotNullOrEmptyString(name, \"name\");\nWe have discussion about it here. \n. Could you add here:\ncs\nEnsure.ArgumentNotNullOrEmptyString(owner, \"owner\");\nEnsure.ArgumentNotNullOrEmptyString(name, \"name\");\nEnsure.ArgumentNotNull(request, \"request\");\nWe have discussion about it here. \n. Could you add new line here?\n. I guess, it's unintended changes here. Could revert it?\n. As long as you changed XML documentation, could you add adjust  tag here and on other places?\nYou could use this pattern:\n/// <returns>The <see cref=\"EmailAddress\"/>es for the authenticated user.</returns>\nI know that is not marked in issue description, but I think as long as we change xml docs, we can adjust it a little bit :smile: \n. I agree :+1:  Fixed.\n. Unfortunately, yes! Fixed :+1: \n. @shiftkey nice spot, I think that usage of interface instead of implementation would be appropriate\nhere.\n. Yeah, you're absolutely right!\n. Yep, fixed, tnx!\n. Yes, sure. Fixed!\n. @shiftkey, yes, now parameter has name \"labelName\" in Label method.Here is commit       0da6f0e\n. @shiftkey no problem! :smile:\n. Yep, fixed!\n. I removed all unused usings in the file.\n. I agree, I'll fix that. Should I rename public static Uri Blob(string owner, string name) overload too?\n. @M-Zuber thank you! Done!\n. Unintended newlines?\n. Unintended tab?\n. Unintended newline?\n. I think one empty line would be enough :smile: \n. No, at all! Fixed!\n. forgot to return it back. Fixed :+1: \n. Yeah, it is overkill :+1: \n. yep, it is overkill really!\n. Yep, you're right! I've missed opportunity to use substitution of IApiConnection instead of new Readme constructor. Fixed :+1: \n. It's cool, especially if take into account that I wrote these tests blindly :smile: \nFixed!\n. @shiftkey, sorry, I've forgotten push my commits with integration tests. There are a lot of new ones :+1: \n. ApiOptions.None have to be used here \ud83d\udc4d \n. The same as previous remark \ud83d\udc4d \n. @ryangribble yes, you're right :+1: , always forget about back compatibility, it is looks like I've been developing enterprise software enough to forgot that back compatibility is important part of software development. Fixed!\n. @ryangribble :+1: Fixed!\n. Unfortunately, VS do not understand such XML tags:\n<see cref=\"Task{IReadOnlyList{T}}\"/>\n\n. @shiftkey please see the pattern I've used here #1384, maybe it would be fine?\nA <see cref=\"Task{T}\"/> of <see cref=\"IReadOnlyList{Reactions}\"/> representing <see cref=\"Reaction\"/>s for a specified issue.\n. I don't think so, it is really tedious and boring. I just tried to be self-consistent in work on GSoC. So, what we decide here? Clear  tags at all or change it in the other manner?\n. @shiftkey done :+1: \n. @shiftkey done :+1: \n. @shiftkey done :+1: \n. @Haacked We've discussed this here with @shiftkey. And yep, I'll remove /// <returns></returns> in next commits when other things will be reviewed :+1: \n. @ryangribble Yes, I tried to standardise all tests to use async and there is no failed tests without async Task return type. I've just tried be consiistent in sense that awaitable methods have to be called with usage of await keyword.\n@shiftkey I don't understood your last sentence, do you mean that this change from void to async Task is going to produce some troubles with multithreading?\n. @ryangribble yep, sure, I'm going to fix this for now!\n. Oh, yeah! Thank you @ryangribble \ud83d\udc4d  So, there are no any issues with it because we don't use return results for any purposes \ud83d\udc4d \n. Anyway, I've definitely used the same pattern for all RepositoryId PRs (ID in upper case) and if you decide to change a case of ID it would be pretty easy to do as one action in further PR, after all repositoryId ones will be merged :+1: \n. I think here it would be a breaking change, isn't it?\n. I think here it would be a breaking change, isn't it?\n. done!\n. done!\n. I've removed this file because it is fully similar to non-reactive implementation. and usually we have integration tests for non-reactive clients, because reactive ones use non-reactive clients internally.If it not sounds reasonable I going to revert it back :+1: \n. Good point, I will remove async now.\n. ",
    "Mikelss": "Hacker\n. ",
    "sbohlen": "Figured as much.  My code actually gets jammed up (the ForbiddenException mentioned above) long before I even get to perform any update operations :(  instead, it actually 100% reliably dies immediately after the first 20 calls to the API to create one each of the first 20 of the 57 issues I'm trying to add/create/insert.\nFWIW, my pseudo-algorithm that does the work looks generally like this ...\n1. read 57 records into a collection from the CSV file\n2. loop through the collection of records from the CSV, calling the API once each for each record to create a corresponding new GitHub issue entry; if this worked, this would presumably be 57 API calls\n3. loop through the records in the CSV to assemble the necessary metadata for the update of each GitHub issue, calling the API once each for each GitHub issue I want to update; if this worked, this too would presumably be another 57 API calls\nWhen I run my code against just 10 records, all three of the above steps work just fine and I get exactly the issues and updates appearing in my test-repo on GitHub just as expected.  However, when I attempt to run all 57 records, after the first 20 records are processed in Step 2 (e.g., 20 calls to the API to create new issues) I reliably receive the ForbiddenException as mentioned. \nFWIW, even if my code were to get past the 57 insert/create calls in Step 3, the scope of the update I am attempting for each GitHub issue includes just the status (e.g., CLOSED) and adding a tag or two in most cases.\nTo perform the updates, I'm using the Update method on this library's IssuesClient (see https://github.com/octokit/octokit.net/blob/master/Octokit/Clients/IssuesClient.cs#L221) to perform this update and passing it a single instance of the IssueUpdate object (see https://github.com/octokit/octokit.net/blob/master/Octokit/Models/Request/IssueUpdate.cs) populated with the entirety of the changes I want to apply.  My impression of this method is that its making only a single API call to pass the entirety of the update metadata at once so I'd assume that my updates aren't the trigger here.\nMy observation seems to be that after 20 calls to create/insert new GitHub issues I reliably receive the ForbiddenException.  Is there some other way that I should be trying to insert new GitHub issues programmatically?  Or is using the API for this purpose maybe just not something that's really supported on public repos due to your anti-DoS policies?\nAlso, another thought: if there's no way around this due to your anti-DoS ruleset for the API, can you advise the duration between create/insert calls for which I should be pausing in order to artificially slow down the frequency of my calls to the API to create the issues so as not to collide with your rule?\nSince (once it works!) this is just a one-off run of this process for me and there are only 57 issues, TBH I don't really care if I have to let it run overnight with a 1? 5? 10? minute Thread.Sleep() call inserted in between iterations through my collection of records ...\nCould something like that be a possible work-around...?\nThanks again for any input here~! \n. Just circling back on this to offer back my own solution in case anyone should hit upon the same limitation in their interactions with the GitHub API: trial and error has permitted me to reverse-engineer that the limits on create API calls (at least for issues!) appear to be as follows:\n- a max of 20 API calls within a 1-minute period\nEventually I was able to solve this by following my own advice of artificially reducing the frequency of calls to the CREATE parts of the API to permit my code to fall below the threshold that seems to be triggering the violation of the anti-abuse rules. \nI added a line in my code to temporarily suspend/pause my thread making the API calls for 70s (60s + a comfortable margin of 10 additional seconds) after every 20th call to the API.  Using this approach, I was ultimately able to complete the full programmatic import (and subsequent updates) of all 57 of my issues.\nFor the insert/create of all 57 issues, this added two pauses of ~70s each to my processing time, but for my (non-high-performance) needs this overhead was still entirely acceptable.  Since the update actions aren't similarly limited (beyond the 5000 API calls per day permitted by an authenticated user), there was no need to insert the same 'pause' logic into the update processing API calls in my code.\nHope this helps someone else who finds themselves faced with the same challenges in trying to interact with public repos; for now I'll close this as not being anything really requiring action (beyond perhaps a consideration for a possible mention somewhere in the general API docs re: what the throttling parameters are for the CREATE-related API calls on public repos even when you're properly authenticated -- and that this suspend-until-restricted-duration-passes pattern is a potential work-around to those limits that still remains true to the intent of the API throttling/anti-abuse rules).\nThanks again for the help/guidance; much appreciated!\n. ",
    "thiagobustamante": "Thanks a lot. It was very useful to me. \n. ",
    "joshvera": "@shiftkey Sorry for missing this. Looks good to me. :+1: to merge?\n. :+1: \n. @shiftkey :+1:\n. @shiftkey I think it's alright if we don't. Will this crash if given a JSON dictionary without this key?\n. @shiftkey I see, I don\u2019t think we should consider that valid.\n. :ship: \n. ",
    "devkhan": "Should be closed?\n. As @Haacked mentioned, these are the ctors which are actually required:\n\nc#\npublic GitHubClient(ProductHeaderValue productInformation) { } \npublic GitHubClient(ProductHeaderValue productInformation, ICredentialStore credentialStore) { } \npublic GitHubClient(ProductHeaderValue productInformation, ICredentialStore credentialStore, Uri baseAddress) { } \npublic GitHubClient(ClientInfo info) { }\npublic GitHubClient(HttpClient httpClient) { }\n\nBut I think that if we only keep these:\npublic GitHubClient(ClientInfo info) { }\npublic GitHubClient(HttpClient httpClient) { }\nwith throwing exceptions in case ProductHeaderValue is not provided in info, it will be easier to maintain and forces user to follow a convention for providing config info. We can make a handful of ctors for ClientInfo. What do you think?\n. Its passing for me also. Should we un-skip it?\n. This should be :closed_lock_with_key: .\n. I dug through the code and found out that errors are handled in Connection.HandleErrors(), which just throws the an ApiException if the status code > 400. I can extend it to show a message based on the end-point.\nAlso, a possible solution is that we provide HandleError() with some info about what was requested so that it can throw a more informative message with the exception. What should be done?\n. I can try this out, but I'll need @distantcam to provide more details on how was he accessing the API?\n. Tried deleting a repo without access:\n\nTried accessing a repo which doesn't exists:\n\nShould there be any more information?\n@distantcam Is this similar to what your were getting or something else?\n. @ryangribble This is not command window, its scriptcs code, so I guess it is showing the correct response. Also, I tried a legit call and the response was correct, so this shouldn't be a problem. Or am I missing something?\n. Also, I think the Not Found is because the GitHub API gives just \"Not Found\" as message on 404.\nSo, what should be done next?\n. @ryangribble I would also like to work on this, can I help?\n. I guess not. :cry: \n. I want to work on this. Any pointers anyone?\nOr maybe I'll try it myself first. :pray: \n. @ryangribble Can I still help writing models, requests, tests, etc.?\nI know I won't be able to to do integration tests, but still. I'll submit them to your fork.\n. Can you post the stack trace?\n. This doesn't show the exact exception, can you post the complete stack trace including the exception that is thrown?\n. Just a guess, can you try explicitly specifying the encoding, e.g. \"utf-8\" of the NewBlob ?\n. Well, I'm not sure on this, but the GitHub API is responding with a 422 Unprocessable Entity Status, Octokit is just throwing exception because of the 422, therefore, it must be a problem with the GitHub API.\nMaybe someone inside GitHub can help, @shiftkey ?\n. Also, the error message says:\n\ntree.sha 0180e978c65bdba55f6a2021c6f0a3a94a2cf9df is not a valid blob.\n\nCan you try manually making a request to respective API-endpoint to check whether the given blob actually exists or not?\nAnd, @shiftkey how about changing this test instead to include an escaped \" (it will test the exact scenario)?\n. So, it means the problem might be in the way @twcclegg is calling the API?\n. Can be closed now.\n. @shiftkey What parts of the project we will be needing to re-write to make this .NET Core compatible? I mean, how much code is there which is .NET Framework specific and not available in .NET Core or is never going to be?\n. So, the different types of project which target .NET Framework e.g. Octokit, Octokit-Net45, Octokit-Portable, etc. will be unified in a single codebase and project.json. And it will generate different NuGet packages for different targets?\nAlso, the Mono and Xamarin ones will still be kept as different projects or they are going to be dissolved in favour of the X-platform .NET Core? What is going to happen to them?\nI read a blog, which said that setting dotnet as target in project.json means we are specifying that our project is compatible with any platform our dependencies are compatible. So, does this mean we will have to make sure we have no dependencies which are not available on .NET Core?\nAm I on the right track?\n. @shiftkey Thanks for clearing that out. :+1: One question though, from here, .NET Core (netstandard) class libs are already supported on some of these platforms, e.g. net45, net46, win8, etc. So, will they also be continued or merged into one?\nP.S. Next time, I'll ask you on Gitter.\n. @prayankmathur I guess it is done by hand right now. But there must be tools available.\nMaybe we will have a unified project.josn which will target the current .NET Framework, .Net45 and PCL, which all have different projects right now. And the project.json will just contain definitions for different targets (their dependencies). You can take a look at the target-the-coreclr branch for reference.\n@shiftkey can confirm.\n. Okay, I have read the mentioned issues, I understand about how things have been proceeded so far and agree with all of the points made by @shiftkey and @Haacked. I also get the type of abstractions has been planned. And after almost a week of reading docs, timing out tests, digging through the code, and following related issues transitively(there were too many), I had some thoughts about this particular topic. So, here I go: \n- Too many ctor's - While I was going through the issues, I have seen @shiftkey expressing his views about having already so many ctor's for GitHubClient and adding more is not going to help the situation. I think that default(optional) parameters can be a possible solution for this. We can something like this:\ncsharp\npublic GitHubClient(\n    ProductHeaderValue productInformation, \n    ICredentialStore credentialStore = null, \n    Uri baseAddress = \"https://api.github.com\",\n    IConnection connection = null)\n{\n    if(credentialStore == null)\n    {\n         // Instantiate a CredentialStore.\n    }\n}\nMay be named parameters can help here. I don't know about the conventions to be followed here or does this even go well with the use cases.\n- Per-request options - @distantcam once mentioned about having per-request basis options. Can we use something a like an ClientOptions class which may have options for different types of API to be used, e.g. Release, Gist, Issue, which may have different timeouts and some other options to be passed on HttpClient. Will it be feasible?\n- And there is a completely different thing in my mind. Can we use @paulcbetts Refit for delegating most of our tasks. As we are already talking about having a type of abstraction to de-couple the HttpClient, we can completely delegate the HTTP + Serialization work to Refit. Square's Retrofit uses a similar kind of abstraction (it uses OkHttp for it HTTP work. I don't know about the performance of Refit, maybe @paulcbetts can help. Or, we can fork Refit and decouple the HTTP and Serialization work and allow anyone to plug in their ISerializer too (which is also possible right now). \nNote: I know this may sound crazy, but it just occurred to me as I have worked with Retrofit and I really like how its structured.\n\nPlease, be gentle with me, I am new to this project. I really respect this your opinion, these are just some of my crazy thoughts. And please, provide feedback on this.\n. @shiftkey Can you please review this now? I would really like you feedback on this, so that I can get a more clear idea about how to proceed.\n. @shiftkey Can we also pull out the serialization part out of Octokit.NET and server as a separate packages? \nI know that users can still pass in an IJsonSerializer to provide their own serializer, but if we move the serialization work out of Octokit, others can also contribute community-powered Serialization packages for Octokit, e.g. Nancy has different NuGets for different serializers. \nIs it possible? Or is it outside the scope of this project?\n. Thanks @shiftkey, I'll go through them first.\n. While on the topic of delegating things to HttpClient, should ProductHeaderValue be specified in the client or not? Since this should be added as a header to every request, I think its better to move in into the client. Users wanting to use other clients, can just add a custom header for this. IGitHubClient passes it on to IConnection anyways.\nP.S.: @shiftkey I want to discuss this project in detail, and long conversation might not be a good fit here. Can you chat on Gitter?\n. @shiftkey I looked at #985, and it seems like you have done much of the work, e.g. marking obsoletes, creating stubs, etc. So then, how much work is left in this project?\nSidenote: Why didn't you merged that PR?\n. That's good, cause it will be useful as a great reference. :+1: \n. So, it should be passed on?\nShould I open a PR?\n. @shiftkey @M-Zuber Please, take a look at the mentioned PR @ #1133.\n. Yes, in fact it is because of it. I tried passing an actual object of SimpleJsonSerializer, and the test passed.\nCan we pass an actual object, instead of a substitute?\n. I'm ok with whatever you want to do. Can you tell me where should I look into to learn further more about this?\n. I don't think we can break at one condition, but if we break down the compound && condition into several lines, we can surely put breakpoints on each one of them.\n. It is a clever trick, but due to lack of experience, I can't say whether we should use this or not. @shiftkey, feedback?\n. @ryangribble thanks for explaining :bow: It did filled some gaps in my knowledge. And, now that I understand the project better, I can tackle the problem at hand.\n@shiftkey thanks. I will surely first try to keep the correctness intact as much as possible. Let me get back to you.\nJust to be sure: I should try to configure the object's substitute in a way that httpClient.Send's IRequest param expects it to be, so that it correctly mocks the current situation?\n. @ryangribble I tried to change the substitute, but the point is IReuqest doesn't enforce any restrictions on the Body param except being an object, and I think that's ok because the failing tests are the one which check for general HTTP requests. So, @M-Zuber solution seems enough.\nAnything else should I add?\n. I have applied @M-Zuber 's fix to the failing tests. Now the question is, how to better mock the request body?\n. > ... IJsonSerializer is now correctly passed through thanks to your fix, meaning that down in the guts of constructing the http call to the API, the \"data\" of the response body is null (because the substitute hasnt been configured to return any data when Serialize() is called on it). This means that the Assert on httpClient.Send() is failing, since it did not receive a call that matched what we specified (specifically, the body data is now null rather than it being \"\" as expected)\n\n@M-Zuber 's example is setting the expected body data to be the (null) return of the mocked serializer... which does make the test pass, however I would probably recommend instead to configure the mock to return the data we want since that is more in keeping with the unit testing approach and would also be applicable in other situations where we had a \"real\" body instead of a new object() as in this case...\n\nI tried substituting the new object() with something like:\ncsharp\nSubstitute.For<IObject>().ToString().Returns(\"\"); // I defined a dummy IObject. :P\nwhich does passes the test, but as @ryangribble said, I don't how it will provide checking mechanism for other types of request (as this is a simple Patch request, we are simply passing in a plain object, but what about other cases where body will be different)?\nHow should I mock the object being passed to the connection.Patch() or to serializer.Serialize()?\n. But then again won't it be the same as before, when directly SimpleJson.SerializeObject was being called instead of the interface's Serialize()? \nI mean, we won't be \"mocking\" the body.\nP.S.: When I tried it, the tests were failing. :cry: \n. I currently don't have access to my system, so I'll make the changes later, but it should work just fine.\n. It is deterministic because we are passing SimpleJson as serailizer and we know its result, but what if the user passes a different serializer (maybe with a different serialization strategy). I'm not sure, but s it possible?\n. @M-Zuber Did I made a mistake?\n. Thanks everyone. @M-Zuber @ryangribble @Haacked @shiftkey \n. @ryangribble The build is failing for other projects, do I need add all the files there too?\n. Thanks @ryangribble, I will try my best. And I'd would still need your and others' help.\n. @ryangribble @shiftkey Can anybody tell me why CanBeDeserialized() test is failing?\nStack trace:\n\nIt fails here:\n\n. @ryangribble Thanks for the detailed feedback. I was also eagerly waiting for someone to get me into the \"mindset\". Now that I know much better about the philosophy of Octokit, I'll adhere to it.\n\n... Migrations client lives under a menu item called Migration and does not belong under the Enterprise API.\nThis means, you actually need to create a \"IMigrationClient\" that lives in IGitHubClient, then a IMigrationClient that lives in MigrationsClient...\n\nThankfully, it came up before running .\\build.cmd FixProjects\nI know it my fault that I didn't first checked the docs, but since you said an Enterprise instance is needed for this, I just assumed it is a part of Enterprise API. I'll keep this in mind in the future.\nAlso, a question, does it mean we have to create an IMigrationsClient and an ISourceImportClient (may be in the future) inside an IMigrationClient and that will go under the IGitHubClient?\n\nNaming things (TM) and Order of methods\n\nI was having a hard time Naming Things (TM), its now cleared now, and I'll follow the conventions from now on. :+1: \n\nAnd, I was about to ask where to put the AcceptHeader, thanks for clearing that out.\n\nIf you have a look at all other Response model objects, you will notice they have a default/parameterless constructor! That's all your problem boils down to... 1 line! haha :sob:\n\nThat was such a nightmare. Thank you so much. :100: \n. @ryangribble The GitHub API docs list the Migration->Migrations API as the \"Enterprise Migrations API\", but does not list it under the Enterprise section, so should I add into a new section for Migration or let it stay in the Enterprise section?\n. Thanks. As the GitHub API docs says.\nAnd, I just put them on the next line to improve readability because of long parameters list. But project's conventions are more important, I'll change them. Should I change this in the tests also?\n. @ryangribble The GitHub API docs refer the Migrations API as the \"Enterprise Migrations API\", so while I will keep it out of the enterprise directory, should I prefix it with Enterprise or not as ...\n\nwe live and die by the API structure in the sidebar, therefore when using Octokit we should match that structure. \n\nSo, what should I do?\n. @ryangribble I still have to write the integration tests, though. I'll try to get them done as soon as possible.\n. @ryangribble I've added the integration tests but I have a couple of questions:\n- The GetArchive() test is failing. Maybe it is returning a string and I'm doing something wrong. Can you please look into it? Here is the API method, see if needs modification.\n- The DELETE based end-points throws \"Accept header error\", but how do we specify the preview header in the DELETE methods, all the other preview API's also doesn't specify it in their DELETE method.\n. @ryangribble Thanks a lot for the thorough review, I'll get back to you once I fix all these issues.\n. @ryangribble I've re-implemented the integration tests using the world-building approach. All the tests are passing except GetArchive(), that must be because that end-point actually redirects to the tar.gz archive, and since Octokit is configured to auto-follow redirect, it never actually gets a string in the result. What should I do here? Download the file and give it to the user or restrict the auto-redirect?\nWhichever may be the case, I'll need you help implementing it.\n. Other API such as \"Releases\" actually return an object which contains a download_url, but this end-point directly downloads a file using a redirect. Now, there are two options:\n- Either download the file ourselves by setting the content-type as application/x-gzip and setting the return type as Task<File>.\n- Or do not follow the redirect and return the URL returned in the 302 response and letting the user download the file itself whichever way they want.\n. @ryangribble I noticed that there is a GetRedirect() method on ApiConnection, which serves our exact purpose but doesn't have an overload which takes the accepts parameter. But it is marked obsolete as Octokit now follows redirects automatically, so what should be done?\nAlso, I noticed that ApiConnection is actually able to get the complete file, but it stored inside its IApiResponse.HttpResponse.Body property, whereas the Get() method returns the IApiReponse.Body property which is null. So, while Octokit has the ability to download raw files, it can't be utilised as the Get() methods only return the deserialized objects. @shiftkey Can you clarify on what should be done?\n. > our repository archive downloads, we return a Task<byte[]> which the user then converts into the expected archive format.\n@shiftkey Thanks for clearing that out, so it means I should return the archive as a byte[] and let the user decide how it wants to save it?\n. I don't think so as the API only mention the response as application/x-gzip. I'll let the user decide then.\n. @ryangribble @shiftkey I've changed the GetArchvie() to return a byte array and I've also tested it manually by saving it to a file and it contain the repos defined in the migration, so everything works fine now.\nThis is complete, AFAIK, you can now review and merge. Let me know if I've missed something.\n. @shiftkey Should I add ApiOptions overloads (for pagination support) to this client as well?\n. Sure. I was trying to implement that and I am confused on many points so it's better to open a new PR.\n. @ryangribble Can you please restart the Travis build?\n. @ryangribble Sure, I'll get to it as soon as I get some time off my exams.\n. @ryangribble The Linux build is failing, maybe a mono issue. Please, look into it. :pray: \n. Yeah, another PR has been merged since my rebase. Fixed.\n. @ryangribble @shiftkey \nIt was a great experience, I hope to contribute more in future.\nThanks a :100: to both of you. It wouldn't have been possible without you.\n. Can be closed now.\n. Can be closed now.\n. @ryangribble I know about that, but that didn't work if the PR opener doesn't have appropriate access rights to close the issue. Maybe I'm wrong, I don't know for sure.\n. Can be closed now.\n. Can be closed now.\n. Can be closed now.\n. Can be closed now.\n. The mentioned methods are obsolete and marked for removal. And User.Keys.* are advised instead. Do we still need to add the ApiOptions overloads to these or #1183 will suffice?\n. @ryangribble The CI builds are passing now. Review and merge whenever you want to. :smile:\n. @shiftkey Should I now start the bulk changes for Pagination Support?\n. @shiftkey Okay, as you say, but may be we can try a few similar ones?\n. Since I'm already implementing the Migrations API, should I take this up after I am finished with that?\n. @ryangribble Sure, I'll try to make it production-ready ASAP.\n. ~~I think you applied the patch for it in the same branch of another PR. You should have created another branch for this PR, as it will unnecessary show the old commits.~~ Done.\nIt looks good otherwise. :+1: \n. Let me take care of this. :smiley: \n. The Migration API has an internal Enterprise Migrations client, so that causes troubles if I follow this. As I can't name both of them Migration, so I have named the internal one as IMigrationsClient Migrations and IMigrationClient. The only difference is the plurality. What should be done in such a case?\nHere is the explaination by @ryangribble.\n\nKeeping this aside, I feel that since we follow the GitHub API, should we also make clients nested as in the docs and make the sub-clients as internal namespcaces. This will also solve the problem of Migrations API as we can then have something like Octokit.Migration.IMigration Migration, keeping them singular. Is something like this even possible?\n. @dampir Can you make the list in the first comment a to-do list? Or if everything is done, ignore this.\n. I agree on this for null values, but according to current implementation, if we keep the default value ApiOptions.None, we wouldn't need to write the ?? syntax and the non-null check. Are there any other problems which will arise due to this?\n. @Haacked I read the article, it made clear the intentions and problems which arise due to optional parameters. I guess I was just being nostalgic due to my C++ experience.\nThanks to both of you.\n. > what about C++ makes the optional parameters different?\nNothing. It was at the time when I only knew C++ and less code seemed better. :disappointed: \n. @shiftkey Thanks for clearing that out.\nSidenote: I know this is off-topic but I've sent you an email. Can you please check? :pray: \n. @shiftkey Is my proposal really that boring?\n. @shiftkey I'm sorry if it seemed inappropriate, I was just kidding. Anyway, now I've uploaded the final proposal on GSoC website. Hope you like it. :pray: \n. @prayankmathur There is some code at places which is not covered by tests. I have encountered this situation in the TeamsClient also, so I think we should add tests wherever they are missing.\n. Can we add inconsistencies like this to be resolved in FormatCode command? Automating this will remove any inconsistencies introduced by humans. Is something like this possible?\n. Can be closed now.\n. @ryangribble The Travis Linux build is failing. Can you please review?\n. Should I add some integration tests using one of the repos from http://github.com/github/dmca ?\n. @Sarmad93 Your has conflicts with master, and that's why the CI builds are not running. Try to rebase your branch.\n. What did you do exactly?\n. Did you updated you master from upstream first? You have to do that as that will fetch all the latest commits made in the main repo's master. Then you have to do the following to resolve conflicts:\n``` bash\ngit checkout \ngit rebase master\nResolve any conflicts that may arise manually\nThen marked them resolved by:\ngit add .\nThen continue rebasing:\ngit rebase --continue\nFinally do a force push:\ngit push --force origin \n```\nLet me what happens after doing the above steps. :+1: \n. Did you resolved the conflicting files and then did rebase --continue?\nRemember, you have to keep performing rebase --continue, conflict resolution and git add . till all the commits are rebased successfully.\n. @Sarmad93 I tried rebasing your branch on my own in my fork. As you can see below:\n\nUnfortunately, there are some changes also in the commtis made by others which are already merged in master. So, what I would suggest is, that you note down the shas of the commits you have made, the ones listed in the image (but in your fork). Then do the following:\ngit\ngit checkout Squash_Commit\ngit checkout -b sc-temp # For backup\ngit checkout Squash_Commit\ngit reset --hard HEAD~200 # Go back well enough in history\ngit pull upstream master # Update from octokit's master\ngit cherry-pick <sha> # Do for all shas noted down before\ngit push --force origin Squash_Commit\nLet me know what happens then.\n. And if there are any conflicts while cherry-picking, resolve them and commit too.\n. The reasons of those errors are the diffs which are inserted into the files on conflicts. I also think that a new PR may be better or if the conversation here is relevant, you can go actually delete your branch locally and then recreate it from the latest upstream master, and then re-do your work on top of it. And finally, do a force push.\n. @Sarmad93 Glad I could help. You don't need to call me \"Sir\", we're all here to help each other. And I'm happy this PR is finally merged. Keep up the good work. :+1: \n. @dampir Maybe rebasing can help, try this:\n``` powershell\ngit checkout ctor-conventions \ngit rebase upstream/master \nResolve any merge conflicts that arise, mark them resolved with:\ngit add . \ngit rebase --continue\nRepeat above two steps until done.\n```\nTo be on the safe side, try this on a temp branch forked from the main first.\n. @dampir This looks odd as it contains commits from other PRs also. Did you update master from the main repo before rebasing?\n. I don't completely understand what happened here, as this PR contains commits from other PRs also. But as there are no conflicts, maybe it will auto-resolve once merged. I think someone with experience can help out, @ryangribble @shiftkey ?\nP. S.: You should look into the failing builds so it can be merged quickly.\n. > There were some errors after rebase (not about merge, but about push), so I searched errors over internet and tried to fix that.\nThat maybe because you need to --force a push after a rebase (as you have effectively changed the history).\n. Just a wild guess, but can you try opening api.github.com in VS's internal browser?\nIt may be informative if it is a certificate related problem, AFAIK.\n. @dampir I know this is getting stale, but I'm really swamped right now between my exams and GSoC. I'll probably complete this after 5th. If this needs to be done before that, go ahead. Otherwise, I'll do it later.\nI'm sorry for the delay.\n. @dampir Good. I hope you complete all of these fast enough, but if there's too much work, I'd hop in. :+1: \n. This has been completed in #1326.\n. Thanks. I'll close the old one.\n. @shiftkey I've added the Verification object inside Commit and not directly under GitHubCommit according to the API.\nAlso, I don't know whether we should create a class for the signature and payload fields, so I've just marked them as strings for now. Please let me know if they should get their own classes.\n. @ryangribble Yeah, I recently started using Xamarin, so didn't noticed the tabs/spaces. Will fix it after #1398 is merged. Thanks.\n. I think that Arg.Any<ApiOptions>() is sufficient here, instead of the elaborate lambda. But its fine for total correctness, I guess.\n. :+1: \n. I know, I just copy-pasted from the docs, I'll correct them.\n. Actually, I was doing this on Xamarin Studio on OS X. :disappointed: \nBut still, why didn't it happened to all the items?\n. I also thought of adding it, but since it will be checked in the internal GetAll, I skipped it. Should I add here too?\n. That was added because the CanBeDeserialized test was failing. You told me about this fix, remember?\n. Will do it, but I've also mentioned it in #1207 as this is a special case caused by the API docs.\n. I'm really sorry for this, I'll fix this. Thanks.\n. This is unintended, right?\n. Oops! Will correct it. :+1: \n. I think you made a mistake here. Shouldn't it be \"repos/fake/repo/collaborators\"?\n. ",
    "MicahZoltu": "Fixed.  Copied and pasted straight from https://github.com/github/gitignore/blob/master/VisualStudio.gitignore.\n. Investigating test failures.\n. Test failures fixed.\n. Fixing missing observable methods (and some bad tests)...\n. I added a json parser test just to prove what happens if an attribute is missing.\nI don't know of a public repo returns a truncated tree so that is difficult to integration test.  Even with the recursive flag set to 1, getting the full tree for octokit still doesn't truncate.  Also, such an integration test would be brittle if GitHub changes the truncation level.  Given all of that, I'm going to forgo an integration test unless someone really wants it and can recommend a repo to test against or a way to force truncation.\n. I'll get a PR put together for this.\n. I removed the obsolete properties.\nFor the warning about URL as a string, I went with the rule suggested by @shiftkey since there wasn't an agreement in this thread and it was by far the easier solution.\nI moved all of the constructors to above the properties per http://www.stylecop.com/docs/SA1201.html since there doesn't appear to be a hard and fast standard and a good portion of the response models that already had constructors followed this style.\nI created default constructors for all of the response models since it appears SimpleJson needs them to work correctly (tests failed without).\nFinally, I changed a couple (maybe it ended up only being one) response model from public setter to private setter to match all of the others.\n. Unfortunately, I am pretty sure that repository redirects can be subverted by new repositories and new users.  If I create Zoltu/Foo, then rename it to Zoltu/Bar, I can then create a new Zoltu/Foo.  If someone tries to go to Zoltu/Foo before I created the new Zoltu/Foo they will correctly be redirected. If they try to navigate to Zoltu/Foo after I create the new repository though they will be taken to the new repository.\nTo make matters worse, in the case of a name change a malicious user can actually mount an attack.  Lets say Google decides to change their name to Abc within the GitHub organization.  If they don't have the foresight to also create a new user to reclaim the Google name then a malicious user can create a user named Google and copy all of Google's repositories over from Abc.  Now they can inject subtle backdoors, security holes, etc. into every repository and anyone who is going to Google/Foo (because they have a bookmark or old link in a blogpost etc) they will instead get Google/Foo + evil code.\nSee: https://help.github.com/articles/what-happens-when-i-change-my-username/\nYou are right, the /repositories/:id endpoint is not documented well, and I am not sure why that is.  I can only assume it is because most users are familiar with the owner/name nomenclature and having a second endpoint with an id that no one ever sees could be confusing to new API users.\nAs for what I am doing in my project, I am maniuplating repository objects via the GitHub API, primarily because library support for the GitHub API is superior to library support for the git protocol (which is a separate can of worms).  In this case, interacting with a git repository via Octokit from an application is significantly easier than trying to use something like libgit2 (or any of the wrappers around it), especially when you want to work with the repository in-memory (not clone to disk).\nThe most important bit for my scenario is that I am saving repository references in my own database for extended periods of time that would make my application susceptible to the above type of attack.  At the least, I would need to save the id and resolve it to an owner/repo before doing any real work (which occurs over the span of about a minute).  This would limit the surface area of an attack down to a small enough window of time that it is no longer an immediate problem.\nPerhaps as a middle-ground, there could be a single method in Octokit that allows me to resolve an id into a owner/repo?  I believe at the moment I am going to have to manually hit the API (without Octokit) in order to do that resolution before proceeding to use Octokit.\n. Fixed.\n. Fixed.\n. ",
    "rajeshgupthar": "Many test classes have the setup and tear down in constructor and the Dispose method. I have left alone them as it is and just fixed the try/finally in RepositoriesClientTests.cs. I hope this should be fine.\nThe doubt that I have is, if all tests disposes off the created repository properly, then how come there are some repositories left out after running the integration tests?\n. @shiftkey What concerns you with the reflection code in DisposableRepository class? Do you find it buggy? or Am i breaking any rules/conventions by having it there?\nApart from this, should I consider this pull request as closed?\n. I agree, it should be DisposableRepository. I had earlier created another class by the name DisposableRepository hence this class got its name as DisposableRepository2.\n. But this is the method that will be used within the using statement, which is not awaitable? Did I go wrong somewhere?\n. Oops, my bad. Implemented the methods as Task as suggested.\n. ",
    "Trevoke": "bash\n$ mono --version\nMono JIT compiler version 3.2.8 (Debian 3.2.8+dfsg-4ubuntu1)\nCopyright (C) 2002-2014 Novell, Inc, Xamarin Inc and Contributors. www.mono-project.com\n    TLS:           __thread\n    SIGSEGV:       altstack\n    Notifications: epoll\n    Architecture:  amd64\n    Disabled:      none\n    Misc:          softdebug\n    LLVM:          supported, not enabled.\n    GC:            sgen\nRunning on Ubuntu 14.04.1 LTS -- a very recent image from Digital Ocean.\n. By the way, if this wasn't clear, I'm working with Blecki on this, so what I pasted is what Blecki's version is.\n. ",
    "rms81": "Hi,\nDo you mind that I try to implement this one?\n. Pull request created. #691\n. Done\n. Of course. I will do that.\nOn Tue, Feb 24, 2015 at 9:07 AM, Brendan Forster notifications@github.com\nwrote:\n\nIn Octokit.Tests.Integration/Clients/RepositoriesClientTests.cs\nhttps://github.com/octokit/octokit.net/pull/691#discussion_r25237269:\n\n@@ -534,6 +534,19 @@ public class TheGetMethod\n         }\n     }\n-    public class TheGetAllPublicMethod\n-    {\n-        [IntegrationTest]\n\nIf you could throw a Skip on this test, it'd be greatly appreciated -\nthis test is going to run for a long, long, long time\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/691/files#r25237269.\n. \n",
    "needlina": "@shiftkey is Green...\n\n. @Haacked i did it ^^\n. @shiftkey \ni think my explain was not enough,, sorry\nactually i'm using github enterprise, so i dont wanna create \"Developer application\" that their own.\nso i dont use ClientId, ClientSecret properties,,,,\nthats why i wanna use Personal access tokens. i want 'Users' can take GitHub API with their own token... of course, they has id and password but is just only the way to get Autorization to get token,,\nsimply, process that i want is,, user id and password \"basic authorization\" -> getting personal token -> create GitHubClients with 'the token'\ni want this process ^^ can i do process with Octokit? \ni hope you could get it! sorry for my poor explain! thank you :))\n. ",
    "aneville": "I haven't used that before but I'll figure it out shortly. In the meantime I can tell you that I have tried this several times with multiple organizations and have not received any emails from github. After searching through the octokit code I found this function in Helpers/ApiUrls:\n/// <summary>\n    /// returns the <see cref=\"Uri\"/> for team member\n    /// </summary>\n    /// <param name=\"id\">The team id</param>\n    /// <param name=\"login\">The user login.</param>\n    public static Uri TeamMember(int id, string login)\n    {\n        return \"teams/{0}/members/{1}\".FormatUri(id, login);\n    }\nwhich uses the deprecated api endpoint and is used in this function inside /Clients/TeamClients:\n```\n    /// \n    /// Add a member to the team\n    /// \n    /// Thrown when a general API error occurs.\n    /// \n    public Task AddMember(int id, string login)\n    {\n        Ensure.ArgumentNotNullOrEmptyString(login, \"login\");\n    var endpoint = ApiUrls.TeamMember(id, login);\n    return ApiConnection.Put(endpoint);\n}\n\n```\n. So we can start from there while I figure out how to use Fiddler trace.\n. I would be very interested in fixing it however I would need a bit of assistance on that part. I have only been using GIT for about 2 weeks but it's very interesting and I've always found helpful code here. I'll start by cloning and seeing if I can get it to work for me. Then I'll ask about the pull request process once I'm ready. I appreciate the quick replies!\n. So I've got the project cloned locally and the fix is done but I'm a bit stuck on the testing part. I'm a little unclear on how to generate the DLL so I can use it in my main project, unless there's a better way to test.\nEDIT: and also I believe the response from the new endpoint is slightly different than the old so more changes will be needed than simply modifying the endpoint\n. @Haacked I must have been having a friday afternoon brain fart cause I got it working first thing this morning. So I've made the change to the TeamMember function but I left the TeamMembers function the same because that endpoint seems to still be current. I have the windows GIT client now so I'll attempt to commit to master and I think that's all I'll have to do. If there's anything I should know about pull requests in general just let me know! \n. @Haacked I think so, so I'll make a separate branch for myself and then make a pull request. Still new to this whole process but I think I'm getting the hang of it. Apparently I've setup my current system to only commit to the master branch. Maybe I should restructure things. Thanks for the tip!\n. @Haacked Ha I was literally just reading over GitHub Flow as I saw the email get here. I've got the Github for windows client running and I'm trying to figure out how to do a pull request on there. I made a branch but I can't figure out the UI so I'll keep reading. Thanks for the guides! I'll be reviewing them next! \n. So I've created a pull request and updated the test cases that I missed. Nothing really compares to actually doing a pull request for understanding how it works so thanks for the opportunity! Feeling a lot more confident in how this works now. If there's anything else I need to do just let me know.\n@Haacked Thanks for the help!\n. I'll remember the fixes tip thanks! \nAlso! Best thumbs up ever, 10/10\n. Nevermind after some searching I found it. Just not in the constructor method. My bad!\n. ",
    "artfuldev": "Was looking to be of more help, but then, seems like only GitHub Staff can contribute to the code? Kindly correct me if I'm wrong.\n. ",
    "kbilsted": "I would require serious amounts of support to pull that off. I can't even open the csproj under windows 7 which I'm currently using.\nAlso it's a bit unclear to me what the outstanding issues are and why the PR was closed in the first place\n. I have VS2013, it opens a window telling me windows 8.1 is required.\n. Sure I can ignore that, but when I then build from within VS all hell breaks loose. Hundreds of warnings and errors.\n. Cheers\n. What is the status of this PR? I really need the features it adds.\n. @shiftkey   Great stuff. As long as I know this is on your radar, I can wait a few more cycles :-)\n. ",
    "DavidStrickland0": "Anyone get anywhere on this one? Is pr 495 still the best spot to start from?\n. Appreciate the work. Thanks\n. ",
    "DaveWM": "@shiftkey @pengwynn Thanks guys :)\n. @Haacked @shiftkey I've made a PR (#701), just removed the WatchersCount property. Probably a good idea to remove this even though it's still on the api, just to avoid confusion\n. Cool, I'll spend some time on it over the weekend\n. Hey guys, I've made a PR for this (#737). I've implemented 9 of the 25 types of event payload. It may need cleaning up a bit, see the comments on the PR\n. There's a bit of a hack in the GitHubSerializerStrategy class (in SimpleJsonSerializer.cs) to get it to deserialize the payload to the correct type. Also, not sure if you'd prefer the tests for this to be in a separate file (currently in EventsClientsTests.cs).\n. I'll have a go at the integration tests for the simpler event types (commit comment, issue comment, etc.), but testing the events you get when you create a PR, push to a repo, fork a repo, etc. would be a lot harder.\n. @shiftkey I've added the integration tests, they don't cover all the event types but they're better than nothing :)\n. no problem - done :)\n. Personally, I'd prefer to keep it how it is - but I'm happy to change it to an extension method if you want.\n. Sure\n. I'm going to blame resharper for this one :P\n. Cool, will do\n. ",
    "kfrancis": "Thanks for the feedback @Haacked @shiftkey \n. ",
    "janovesk": "Yes, EventInfoState should have Head_Ref_Deleted and Head_Ref_Restored as members instead of HeadRefDeleted and HeadRefRestored. \n. PR for this: https://github.com/octokit/octokit.net/pull/711\n. @erichexter Unfortunately that PR, which was included in 0.7.1, did not work out very well. There is a follow up [https://github.com/octokit/octokit.net/pull/727]. It is already merged, so I'm guessing it should be in the next release. \n. :thumbsup: Do you know when the next release is due, @shiftkey?\n. Great stuff! :-)\n. ",
    "alisabzevari": "I tried to fix the issue but I found something else:\nThis is not a valid request:\nhttps://api.github.com/search/code?q=in:file+repo:jquery/jquery\nIn the error message it says \"Searches that use qualifiers only are not allowed.\" but this request is valid:\nhttps://api.github.com/search/code?q=language:js+repo:jquery/jquery\nI think there is a misconception in API.\n. ",
    "alexgyori": "I added a pull request adding no-args constructor since I needed the feature.\n. ",
    "basildk": "Think i will give this a go. Seems like an easy code-fix so i can focus on understanding the github workflow.\n. ",
    "darrencamp": "I'm going to have a go at fixing this one.\n. ",
    "Aaronontheweb": "\nHttpClient supports providing a CancellationToken when it's making a request - perhaps we should have overloads on the GetAll operation so that you can cancel the in-flight requests (this should also kill the pagination, but I need to confirm this). This feels better than reinventing the wheel.\n\nThis is my preference - feels idiomatic :)\n\nIf you can recreate this (quite often it's related to a specific user account) I'd love to investigate this further.\n\nThat's what it looks like - I didn't dig in with something like Fiddler to see what was happening at the HTTP level but we weren't receiving any rate limit exceptions or anything like that. If I had to guess, these long-running queries were for users who had starred a large number of repositories. The \"Robert Scoble\" effect for Github :p \nIn our scenario cancellation is the preferred way of doing it - being able to mark N number of requests as failed and return partial results from the operations that were successful is what's most appropriate in our specific scenario, although it's worth noting that our scenario is for educational purposes only :p \n\n@Aaronontheweb thanks for the feedback! When I saw the tweet earlier today I was really excited to see what was on the way!\n\nWe announced it to our attendees (who've done the previous two units over the past couple of weeks) this morning - seems like a hit so far: https://twitter.com/petabridge/status/575371782741364736\n. ",
    "daveaglick": "Are there any known issues with timing on the integration tests? I've set up a test account and organization, set the environment variables, gotten the tests to run, etc. However, most of the tests are failing with a NotFoundException. When I look at the test account, I do see a whole bunch of time-stamped repositories were created, so it's not a credentials problem. I obviously need to get past execution of the existing tests before thinking about creating new ones...\n. Also, has anyone else reported issues getting the tests to show up in Visual Studio (I'm using VS 2013 Pro Update 4)? My Test Explorer is empty and I've attempted to clear the cache as recommended at http://xunit.github.io/docs/running-tests-in-vs.html without success. It would be easier to troubleshoot the issues I'm having with the integration tests if I could run them in isolation from VS and/or debug them without having to use the build script each time. Unfortunately, I'm not familiar enough with FAKE, F#, or xUnit to figure out from the FAKE script what commands to run from the prompt.\n. So it turns out I'm getting the following exception from the xUnit test runner during discover:\n[xUnit.net 00:00:01.6462406] Exception discovering tests from Octokit.Tests.Integration.dll: System.TypeLoadException: Method 'Find' in type 'Xunit.Sdk.XunitTestFrameworkDiscoverer' from assembly 'xunit.execution, Version=2.0.0.2785, Culture=neutral, PublicKeyToken=8d05b1bb7a6fdb6c' does not have an implementation.\nI guess that makes this an xUnit problem, so I'll see if I can follow up there.\nSorry for the comment flood. Just getting frustrated that it's taking me several hours to set up the build and test environment for what is probably going to be a five minute fix. I'll keep pounding away and try not to spam the issue any more than I have to until I get everything ready for patching.\n. So I know I promised I'd keep the comments to a minimum, but this is just too strange.\nFirst, I could not get the Visual Studio xUnit runner to work for the life of me. I played around with it some more and finally got it to consistently hang on discovering tests in Octokit.Tests.Integration.dll:\n------ Discover test started ------\n[xUnit.net 00:00:00.0001109] Discovery started\n[xUnit.net 00:00:00.3930384] Discovery starting: clean-up-after-tests.exe\n[xUnit.net 00:00:00.4190934] Discovery finished: clean-up-after-tests.exe (0 tests)\n[xUnit.net 00:00:00.4529852] Skipping: Octokit.Reactive.dll (no reference to xUnit.net)\n[xUnit.net 00:00:00.8203221] Discovery starting: Octokit.Tests.Conventions.dll\n[xUnit.net 00:00:04.5343658] Discovery finished: Octokit.Tests.Conventions.dll (279 tests)\n[xUnit.net 00:00:04.9149537] Discovery starting: Octokit.Tests.Integration.dll\nCan't get past that point though so, okay, no VS test runner. Figured out how to run from the command line:\n```\ne:\\Code\\octokit.net>tools\\xunit.runners\\tools\\xunit.console.exe Octokit.Tests.Integration\\bin\\Debug\\Octokit.Tests.Integration.dll -method \"GistsClientTests.CanStarAndUnstarAGist\"\nxUnit.net console test runner (64-bit .NET 4.0.30319.34209)\nCopyright (C) 2014 Outercurve Foundation.\nDiscovering: Octokit.Tests.Integration\nDiscovered:  Octokit.Tests.Integration\nStarting:    Octokit.Tests.Integration\n   GistsClientTests.CanStarAndUnstarAGist [FAIL]\n      Assert.True() Failure\n      Stack Trace:\n         Octokit.Tests.Integration\\Clients\\GistsClientTests.cs(64,0): at GistsClientTests.d__10.MoveNext()\n         --- End of stack trace from previous location where exception was thrown ---\n            at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n            at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n         --- End of stack trace from previous location where exception was thrown ---\n            at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n            at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n         --- End of stack trace from previous location where exception was thrown ---\n            at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n            at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\nFinished:    Octokit.Tests.Integration\n=== TEST EXECUTION SUMMARY ===\n   Octokit.Tests.Integration  Total: 1, Errors: 0, Failed: 1, Skipped: 0, Time: 1.900s\n```\nThe problem is, the test kept failing on different lines. Sometimes it would be the first assertion, sometimes the second, etc. That led me to think it might be a timing problem. I finally got it to consistently succeed by changing the test code (notice the Thread.Sleep() calls in-between each API invocation):\n```\n[IntegrationTest]\npublic async Task CanStarAndUnstarAGist()\n{\n    await _fixture.Star(testGistId);\nSystem.Threading.Thread.Sleep(10000);\n\nvar isStarredTrue = await _fixture.IsStarred(testGistId);\nAssert.True(isStarredTrue);\n\nSystem.Threading.Thread.Sleep(10000);\n\nawait _fixture.Unstar(testGistId);\n\nSystem.Threading.Thread.Sleep(10000);\n\nvar isStarredFalse = await _fixture.IsStarred(testGistId);\nAssert.False(isStarredFalse);\n\n}\n```\nIt looks like it's got to be a fairly long time too - 4 or 6 seconds wouldn't pass consistently. So that got this test passing, but all the other integration tests are a mess on my system. Most fail at arbitrary assertion points that seem to change from one run to the next. That probably just suggests more timing problems, but it does make it hard/impossible to run the entire test suite.\nSo that's where I'm at, but here's the really, really strange thing - when the CanStarAndUnstarAGist() test failed part way through, this is what I saw in the GitHub UI:\n\nI waited for a solid 5 minutes thinking it might be some sort of eventual consistency problem, but it never changed. I also tried looking at it in a different browser in case there was some sort of browser caching going on, but it was the same. Once I got the test to pass using the sleep calls, it started acting normally again.\n\nSo anyway, I've had about as much of this as I can take for a day. I'll come back tomorrow and attempt a test case and WIP PR for starring repos, though at this point it wouldn't surprise me if the issue I initially saw was somehow related to all these other timing problems and isolated to my own environment.\n. Okay, okay, I know I said I'd wait until tomorrow - so sue me.\nI wrote a test, and that unexpectedly worked without any additional modifications (with Thread.Sleep() calls) but I still couldn't get my little test case to work. In fact, attempting to star from the same user account and same repository in the test and then in LINQPad produced different results until I noticed one difference: the integration tests authenticate with username and password while the LINQPad test I was doing authenticated with a token.\nThis works (result == true and repository gets starred):\nGitHubClient github = new GitHubClient(new ProductHeaderValue(\"My Product\"));\ngithub.Credentials = new Credentials(\"[username]\", \"[password]\");\nvar result = await github.Activity.Starring.StarRepo(\"octokit\", \"octokit.net\");\nThis does not work (result == false, but no exception, and repository does not get starred):\nGitHubClient github = new GitHubClient(new ProductHeaderValue(\"My Product\"));\ngithub.Credentials = new Credentials(\"[valid token]\");\nvar result = await github.Activity.Starring.StarRepo(\"octokit\", \"octokit.net\");\nI know the token is valid because I can do other things with it like list all the repositories starred by that user.\nThis throws a AuthorizationException (I just changed one character in the token):\nGitHubClient github = new GitHubClient(new ProductHeaderValue(\"My Product\"));\ngithub.Credentials = new Credentials(\"[invalid token]\");\nvar result = await github.Activity.Starring.StarRepo(\"octokit\", \"octokit.net\");\nSo I'm thinking maybe at this point I don't fully understand the GitHub starring API. Sure enough, after a little more digging with additional personal tokens, I learned that starring a repository requires the public_repo OAuth scope and not the user scope - which doesn't make a whole lot of sense to me since user lets you view stars and it seems like starring should be a user-focused activity, but whatever.\nProblem solved. Congrats - I'm an idiot and there's nothing wrong with Octokit! (Though I'll add that the odd behavior of the UI after starring through the API is still really strange)\n. > Woah, lots of words here.\nI tend to do that :)\nThanks for continuing to see this through. Just let me know when/if it would be helpful for me to rerun the tests or try anything else out.\n. Awesome - works great now:\n\nNo issues with the VS test runner in VS 2013. Tests that were previously failing or required timeouts appear to be working fine now too.\n. I'm seeing this too, including the odd behavior that it works when Fiddler is open. I thought I was going crazy. It's happening for me on calls to GitHubClient.Issue.GetAllForRepository() - anytime the repo has been redirected, the call hangs and then eventually times out.\n. Sorry, CI is coming up with errors I didn't catch on my local machine. Almost got it hammered out. I'll squash when I'm done and let you know when this is good for review.\n. Okay, this should be good to go now. Travis is still reporting an error - looks like something in Octokit.Tests-Portable, but I don't know how to make heads or tails of it. Just let me know if it's something else I need to clean up.\n. :thumbsup: Thanks, no problem!\n. The Fiddler thing has been noted before in #874\n. I am also seeing this on other endpoints like repositories and issues. Also running queries in parallel via a Task.WhenAll() call.. I'm game for a PR. My instinct is to use the ConcurrentDictionary class to handle this. I also think the cache will need to use thread-safe dictionaries as it's values since those sub-dictionaries are also potentially accessed concurrently.\nLet me know if you think I should be using ReflectionUtils.ThreadSafeDictionary instead. It looks like it's optimized for computing new values for a specific key on get misses. It appears it assumes that every key has one corresponding correct value that can be computed by a delegate (I.e., a dictionary that maps types to their constructor - a given type has a specific constructor). If I'm understanding it correctly, that doesn't seem like an ideal fit here.. Interesting - yeah, mine only contained 1.0.4 under the netcoreapp folder. Given that you got both, I wonder if having different global versions changes the local install. Or maybe my work firewall is getting in the way of one or more bits (it\u2019s pretty aggressive).\nI think I\u2019ve got the latest SDK, but could be behind a minor release or two. I\u2019ll check next time I\u2019m in front of my workstation and try to figure out what\u2019s actually going on.. dotnet --version reports I've got 2.1.4 so I wonder if this may be some kind of regression, though it's not clear to me how the local install of the SDK would impact the bootstrapping process since it downloads it's own SDK.\nI'll keep digging. It wasn't a big deal for me personally since I just opened VS and built/tested from there, but now it's a mystery why it's not working and I want/need to get to the bottom of it.. Turns out it's working fine now that I'm out of the office. I now see both the 1.1.1 and the 1.0.4 folders under dotnet/shared/Microsoft.NETCore.App. I'll attribute this to the aggressive SSL inspection my corporate firewall does - must have blocked one or another of the bootstrapped downloads.. I don\u2019t, same problem - it was happening about 1 in 20 runs in my project where I Task.WhenAll() the projects endpoint for around 40 projects. It hasn\u2019t happened since switching to this build, but that could just be because of luck. It\u2019s so intermittent, it\u2019s hard to tell.\nLet me see if I can come up with anything - maybe by targeting just at the cache and pumping in hundreds of types or something I can get it to repro.. I tried over the weekend and couldn't come up with anything reliable. I did get it to fail a few times under observation, but nothing that would hold up in a test suite.. \ud83d\udc4d . You mean the empty ctors or the whole wrapping classes?\n. Ah, gotcha. I just assumed they were needed by the model deserializer. If it can instantiate models without the empty public ctor, I'm fine removing them.\n. ",
    "dail8859": "Would love to see something to provide pagination, especially with etags not being supported. Using this to make unauthenticated requests is almost pointless since you can hit your rate limit so quickly. :(\n. With everything I've read the id and secret need to be kept (not surprisingly) secret, but that's not possible if the code is open source. \nReading the API docs and using curl it's quite easy to create a new authorization without an id or secret, and I was just wanting to be able to do that from the library.\n. So...then anyone wanting to develop the code would have to create their own id and secret just to build it? \n. Hmm OK. Sounds like a pain. Thanks for the info though. \n. Not sure why I closed this, would still like to see the aforementioned API implemented eventually :)\n. Just to clarify, I'm not requesting any changes to the web API, only for the library to support that API call to create a personal access token. \nIt's how the (previously supported) Github android app did it.\n. I apologize, it is very possible I'm just using some wrong terminology, so here's an example. \nReferencing this document, and using curl, you can see I can create a new personal access token. \n\nWas just wanting to be able to do that with Octokit.net\n. I'll have to pass :)\n. ",
    "ryangribble": "Well im not sure if i count as your \"someone else\" being relatively new to contributing on octokit.net, however I've reviewed the changes and have made a few comments inline.\nIn general as an end user this is great and gives all the expected/desired flexibility in setting page size, number of pages and start page number.\nAs a contributor I think the implementation makes sense and is done in a way that seems fitting with the style of octokit.net once you dig down into those lower ApiConnection type areas.\nThe only annoyance/concern is around the fact that with so many overloads on ApiConnection, it looks like it's going to possibly be a bit trickier when writing unit tests where the NSubstitute mocks start to need things like (Dictionary<string, string>) null and so on.  Not sure if there's any way to avoid that though.\nFrom the perspective of \"someone else\" I give it double thumbs :+1: :+1: \n\n. Looks good!  Takes care of my quibble around unit test parameter checking voodoo\nless nulls in one's life are always a good thing :+1: \n. Whoops! \nNeed to dig into this to see why there isn't an integration test that failed . @jamesqo just looking at this one... are you referring to the fact that GetAllContents(string owner, string name, string path) is enforcing path to not be null or empty?\nIf that's the case can't you just call GetAllContents(string owner, string name) overload instead?. Hmmm this pre-dates my involvement, I can see mentions of it not working for enterprise but no detail as to how/why its not working \nSo to clarify, is the problem that following redirects doesn't work for GHE in a proxied environment, or actually that NOTHING works when behind a proxy? \nI'm not sure how to test this either, thankfully we got rid of web proxies at my work! \ud83d\ude01\nHappy to review a pull request though if you are able to debug in your environment and make a change that works for you... . Hi @steveoh what target framework was the project and what version of octokit package?\nCould you also mention the vs2017 update level and the output of dotnet info? . Im on VS2017 15.7.4 and can't reproduce this.  I added Octokit 0.31 to an sdk format net461 project and it worked fine.  I also tried a VS2015 csproj format .NET Framework 4.6.1 targetted project, and again it worked ok.\nIs your project existing or brand new?  Is it the new Sdk style csproj project or the older VS2015 style?  Is it repeatable/can you share the csproj?  Or provide a minimal repro?. In the earlier case it seemed to be an upstream API issue where a date time string was being sent as an int64 (unix epoch time) then it fixed itself (ie the upstream API problem was fixed).\nI think it'd be best if you raise a new issue for what you're facing, please include the json payload and code sample on the new issue \ud83d\ude04 . If you can raise a new issue including a code snippet and the json response we can have a look at what's going on there. or grant the correct scope to your auth token?. I can reproduce what you are seeing where the GitHub API does honour the request when the token is provided as the password, no matter what username is specified.  I guess this is just how it behaves so there isn't anything we should really worry about in that case...\nHowever I CAN'T reproduce your first case (using the token as it is normally intended to be used, via the OAUTH type constructor and authenticator in octokit).\nThis is a personal access token right?  And in addition to the token scopes, you have ensured the given user (who owns the token) has the correct permissions on the repository in question?\nI can create a client with a .Credentials = New Credentials(\"MyTokenHere\") and then succesfully create issues etc.\nAre you able to post a more complete code sample for the first issue?\n. Thanks for the bump and reference, this has actually been fixed by changes in #1411 and the failing test has been unskipped, looks like I forgot to come back and close this :grinning:\n. Just going through old open PR's...\nIm pretty sure what this PR was covering, has been implemented on PR #1096 (issue #1065) and later tweaked on PR #1132 (Issue #1107) \n@shiftkey if you agree, we can close this one\n. Im going to close this one out since it never quite got there, and we are now moving to CAKE anyway.  The good news is we intend to get deployment/packaging/publishing handled in the CAKE scripts :+1:. Howdy folks, I was just digging into this issue myself (merged always being false on all pull request, even those that have been merged) and came across this PR as well as 2 issues and some other PRs etc.  It seems in the various shuffling that change Merged field to be a calculated field hasnt actually made it through\nIs the best course of action for someone to submit a new PR or can this current one be updated and merged in?  If you want me to do it let me know.  In the meantime I can obviously use the workaround of pr.MergedAt.HasValue\nCheers\n. I do want to get master merges automatically releasing pre release to nuget (but they are currently available on the appveyor feed so if people really want to use them they can). \nIn terms of running nightly integration tests, that's a cool idea but we actually have so many integration tests they can't be easily run in one go due to github API rate limits... There are also some tests that seem sensitive to timings and can fail one time but succeed on a rerun...  \nsome work/thought would be needed to figure out a solution to these issues before we can run integration tests automatically . Hi @pmiossec \nGiven its still open I don't believe it would be fixed. \nYou mentioned in git-tfs project that you built a custom version of octokit with this fixed... If you'd like to send a PR with the fix I'll work with you to get it merged \ud83d\udc4d . Hi @mikasoukhov can you provide more details?  \n\na complete code sample showing the octokit call?  \nindication on how large your release asset is?\nat what point do you get the exception?\n\nthanks. Sorry, by full sample I meant \"relevant\" code, so what you've posted is fine :+1:\nCan you try setting the TimeOut property on ReleaseAssetUpload request object as well?  \ncsharp\nvar assetUpload = new ReleaseAssetUpload\n{\n    FileName = Path.GetFileName(attach),\n    ContentType = \"application/zip\",\n    RawData = archiveContents,\n    TimeOut = TimeSpan.FromMinutes(30)\n};\nI have to dig more to see whether this is required, but it would be worth a try.... @Haacked you can close this one off, #997 has been created in it's place.  Cheers!\n. Hey @AArnott \nI'll need to read through this very old issue to completely grok what it was all about, but yes you can pass in your own HttpClient into one of the ctors for GitHubClient and then do whatever you want. You can also do like we do in our unit tests and pass in a mocked out IConnection... Or I guess you also could just mock out the IGitHubClient entirely. \nI guess it depends what you are trying to test, because if you go right down to the http client level you are really now testing octokit itself rather than just your code that's using octokit . Sorry the constructor I meant was on Connection and allows you to provide your own HttpMessageHandler\ncsharp\nvar connection = new Connection(new ProductHeaderValue(\"my-cool-app\"),\n    new HttpClientAdapter(() => myHttpMessageHandler));\nvar client = new GitHubClient(connection);. We were looking into record/replay type fixtures last year and @shiftkey  started a csharp implementation of \"vcr\" (a ruby record/replay based fixtures http fixtures library) and started looking at what we'd need to do in octokit to adapt to using it... \nyou might find interesting: https://github.com/shiftkey/vcr-sharp. Were you using any IOC containers or anything that might cause multiple GitHubClient instances to be declared?\nGenerally whenever these types of things comes up around HttpClient, it does seem to be mostly solvable using the existing options provided in Octokit, and it is more just a lack of discoverability/documentation causing users to be unaware of them.  \nThe override on Connection that lets you specify an IHttpClient implementation means you could roll your own (admittedly a bit onerous given the number of methods to implement) or you can use the Octokit implementation of this interface (HttpClientAdapter) which lets you specify your own HttpMessageHandler.\nIn terms of Octokit's Http extensibility, I wonder if now .NET Core has the new HttpClientFactory stuff, we should consider reworking Octokit to use this (and allow the user to pass in their own)?. No worries Ill fix up those protected set and parameterised ctor's shortly\nRegarding API design at first (and you can see on my earlier commits) I was following the octokit.rb implementation of having ProtectBranch() and UnprotectBranch() calls, however this didnt really suit the design of octokit.net which is more focused on having an Edit() method for an entity, and passing in the xxxUpdate model object with the changes... so I re-implemented as a single EditBranch()  function\n. @shiftkey good catch thanks, email should be fixed now\n. LOL so I was just testing this against our GitHub Enterprise on premises installation, and it looks like the preview API isnt actually in GitHub Enterprise version 2.4.2 (eventhough the actual Branch Protection features are).  Will need to wait for Enterprise to include the API feature before we can actually use this stuff in our tooling :smile: \n. RequiredStatusChecks.Context is now an IReadonlyList, implemented as per CommitActivity example\nRemoved convention test hack\nAlso rebased on latest master\n. Unsure about the AppVeyor test failure.  All unit tests are passing for me locally?\n. Looks like the rerun tests all passed etc \nIs there anything further needed from me? \n. I really dont like the idea of referring to the test projects from the implementation classes (if that's what you meant) so what Ive done is created a AcceptHeaders helper class with the preview header defined, and changed the imlpementation to use that.  \nThe tests are left as is, as I believe it's good practice to have each test specify what it's success criteria are, rather than use some commonly defined thing (that could be changed later unaware of the implication to tests that were using it).  \nIve also got a separate branch and will follow this up with a new PR (after this one is accepted) where Ive gone and cleaned up all uses of Accepts headers (eg the licenses API as well as the standard json and html payloads etc) to use the new helper class, and remove the hardcoded strings from multiple places in implementation classes.  Here's the commit in question: https://github.com/TattsGroup/octokit.net/commit/44eb17135f1d62eb42733511801342831ad04ed6\nLet's get this PR merged first though, then I'll follow up with the general Accepts Headers tidy ups for all usages...\nAlso rebased on latest master\n. > The multiple builds issue is actually due to two things occurring - a build for the tip of the PR branch, and a build for the merged commit (the PR branch merged into master, if it does cleanly merge). I'm not sure of a way to switch that off, but I think the default webhook settings are now correct. Make sense?\nHey guys, interesting situation because we are running into similar things ourselves with our on-prem GithUb enterprise and Teamcity.  Hopefully not telling everyone what they already know but each pull request has 2 \"branches\" /refs/pull/999/head (which is the head of the PR) and /refs/pull/999/merge (which is a potential merge commit of the PR with the target branch, eg master).  So when doing CI builds ideally you want to build the \"merge\" one and not the \"head\" one, since it doesnt really matter if the PR itself builds, what we care about is whether master builds once the PR is merged\nBut if you are using the commit status API to set build status on the PR/commits, then when the status is pushed, that changes the commit hash on the /merge branch which then fires off another build etc.  Unfortunately we havent figured out a neat way of dealing with this as yet so we are stuck building /head of PR's when we really want to be building /merge\nIs this similar to the \"multiple builds\" issue you are referring to with octokit and appveyor?  If there are any solutions Id be all ears.  One thing is we could send the webhooks to an intermediary service that would analyze the github/PR etc and then figure out whether it was only a commit status update or a \"real change\" and only relay the build to TeamCity if it was a \"real change\".  But that's getting pretty nasty :)\n. Resolved by #1135 \n. Hey so as part of working on fixing #1106 I came across this skipped test.\nAt work we use Chillkat.net (x64 x86) when we need to generate SSH keys in c# code...\nIm not sure if nuget packages work on linux/OSX builds, but then it seems like the Integration Tests dont run on those platforms anyway right?  So would chillkat be a viable option?\nLet me know if I should pursue this...\nMy plan would be to add chillkat nuget reference to Octokit.Integration.Tests project, and use it to create helper context extension method GitHubClient.CreatePublicKeyContext to create a public key and delete it again when going out of scope.  Then I should be able to re-enable this test and things should be pretty reliable as we wont trip over any issues if keys still existed from previous runs, since we'd be creating a new key everytime (and also cleaning it up, unless anything goes wrong)\n. I'll try to find what license pertains to their freeware libraries, like the SSH one I'm referring to \nhttp://www.chilkatsoft.com/sshkey-features.asp\n. OK, added it to the helper script as an optional variable\n. The ApiException class already has properties on it that provide the message, status code, array of errors etc.  Im not sure if this issue is saying an even more specific message is required or whether the full abilities of the ApiException class were not being used\neg from ApiExceptionTests.cs\n``` csharp\n[Fact]\npublic void CreatesGitHubErrorFromJsonResponse()\n{\n    var response = new Response(\n        HttpStatusCode.GatewayTimeout,\n        @\"{\"\"errors\"\":[{\"\"code\"\":\"\"custom\"\",\"\"field\"\":\"\"key\"\",\"\"message\"\":\"\"key is \" +\n                @\"already in use\"\",\"\"resource\"\":\"\"PublicKey\"\"}],\"\"message\"\":\"\"Validation Failed\"\"}\",\n        new Dictionary(),\n        \"application/json\"\n    );\nvar exception = new ApiException(response);\n\nAssert.Equal(\"Validation Failed\", exception.ApiError.Message);\nAssert.Equal(\"key is already in use\", exception.ApiError.Errors.First().Message);\nAssert.Equal(HttpStatusCode.GatewayTimeout, exception.StatusCode);\n\n}\n``\n. You're not actually calling the method properly there... They are async calls so you need to await the result, otherwise you're actually dealing with aTask`\ncsharp\nvar result = await client.Repository.Get(\"octokit\", \"fake-repo\")\nYou'd need to wrap that in a try/catch then see what data you get on the thrown exception \n. Oops sorry I see you did try to say .Result on the call. I dont think you can really do such async stuff on console/immediate window, hence errors about tasks not having a property called \"Result\" etc\nit's easier to just write an integration test or something so you can execute the actual code fragment \"properly\" \n. Ah ok... Sorry am on my phone at the moment! \nI see now the first error you posted was saying .Result isn't a valid member...  that's because Delete actually isn't a Task but just a Task. But yes it looks like the exception is still what you wanted to look at \nIn both cases the exception you've received, you want to inspect the ApiError objects on it, to see what information is there on the .Message and .Errors (as per that unit test I posted earlier) \n. Im wanting to close out old PRs if they aren't ever going to see the light of day.\nAre we still wanting to head in this direction?  Eg creating things like AccountSimple, UserSimple, PullRequestSimple and so on?\nI do see the benefit in terms of not misleading users by showing fields existing on objects that arent populated unless you've called the \"load single object\" API call...  But I do wonder how much extra work is involved to split all the classes and figure out which fields belong in the Simple vs the Full objects, adding all the new overloads and obsoleting the current ones, rewriting tests etc.  Im wondering if the benefit is worth that initial and ongoing work?. I'll take this\n. I'll take this one next\n. Im working on this one at the moment\n. Do you have access to a GitHub Enterprise environment (this is on premise version of github) ?\n. Yeah if you have a look at the API docs linked above, there are some specific APIs that only the on premises \"GitHub Enterprise\" supports.  We use GHE at my work so I've been working on fleshing out the support for these in my spare time.  Happy for anyone to help of course, but obviously there are a few barriers to entry - namely that you have a GitHub Enterprise license!\n. You can assign this one to me too\n. Im going to take this one  too\nQuestion: Given the various options that are passed in to this API call as \"target\" parameter, what would be the preferred approach?  I was thinking of creating individual methods for the various options...  I haven't found a similar API elsewhere yet, though Im not familiar with the entire API.\nTarget                      Description\n:owner                      A user or organization account.\n:owner/:repository          A repository.\n:owner/*                    All of a user or organization's repositories.\n:owner/:repository/issues   All the issues in a repository.\n:owner/*/issues             All the issues in all of a user or organization's repositories.\n:owner/:repository/code     All the source code in a repository.\n:owner/*/code               All the source code in all of a user or organization's repositories.\nSo my proposal would be to create functions similar to:\nEnterprise.SearchIndexing.QueueOwner(string owner)\nEnterprise.SearchIndexing.QueueRepository(string owner, string repository)\nEnterprise.SearchIndexing.QueueAllRepositoriesForOwner(string owner)\nEnterprise.SearchIndexing.QueueAllIssuesForRepository(string owner, string repository)\nEnterprise.SearchIndexing.QueueAllIssuesForOwner(string owner)\nEnterprise.SearchIndexing.QueueAllCodeForRepository(string owner, string repository)\nEnterprise.SearchIndexing.QueueAllCodeForOwner(string owner)\nSound OK?\n. Or another approach would be to have a single method with overrides for owner, or owner+repo, and an enum to specify the scoping\n```\nEnterprise.SearchIndexing.QueueJob(string owner, IndexTypeOwner indexType)\nEnterprise.SearchIndexing.QueueJob(string owner, string repository, IndexTypeRepository indexType)\nenum IndexTypeOwner\n{\nOwner,\nAllRepositories,\nAllIssues,\nAllCode\n}\nenum IndexTypeRepository\n{\nRepository,\nIssues,\nCode\n}\n```\n:question: \n. So I implemented most of this last night, your distilled version felt pretty natural @shiftkey \nhttps://github.com/TattsGroup/octokit.net/commit/7da92d8592c57847c177e72ebab7e5870ddbfb78\nJust need to do the Reactive classes\nThe only \"fun\" thing so far is that the \"single\" queue actions (like owner and repo) endpoints return a single \"message\" response element like\n{\n   \"message\":\"User \\\"ryan-gribble\\\" was added to the indexing queue\"\n}\nWhilst the other \"QueueAll\" type endpoints return an array of messages, like \n{\n   \"message\":[\n      \"Repository \\\"ryan-gribble/public-repo-20160202020400602\\\" was added to the indexing queue\",\n      \"Repository \\\"ryan-gribble/public-repo-20160202022240540\\\" was added to the indexing queue\",\n      \"Repository \\\"ryan-gribble/public-repo-20160202022354531\\\" was added to the indexing queue\",\n      \"Repository \\\"ryan-gribble/public-repo-20160202023154471\\\" was added to the indexing queue\",\n      \"Repository \\\"ryan-gribble/public-repo-20160202023156249\\\" was added to the indexing queue\",\n      \"Repository \\\"ryan-gribble/public-repo-20160202023157339\\\" was added to the indexing queue\",\n      \"Repository \\\"ryan-gribble/public-repo-20160202023331579\\\" was added to the indexing queue\",\n      \"Repository \\\"ryan-gribble/public-repo-20160202023433230\\\" was added to the indexing queue\",\n      \"Repository \\\"ryan-gribble/public-repo-20160202023434613\\\" was added to the indexing queue\",\n      \"Repository \\\"ryan-gribble/public-repo-20160202023435691\\\" was added to the indexing queue\"\n   ]\n}\nIt looks like the json parser does handle deserializing the single message element into the response model class with IReadOnlyList<string> Message however it also \"eats\" the dash character in my username, resulting in\nUser \"ryangribble\" was added to the indexing queue\nRather than\nUser \"ryan-gribble\" was added to the indexing queue\nSo do you think I should implement 2 different response classes, one for single actions and one for multiple actions... or attempt to figure out/fix why the serializer is \"eating\" the hyphen?!\n@shiftkey ?\n. :+1: ok will take a look tonight\n. Yep a failing test like this shows the problem.  \n```\n            [Fact]\n            public void DoesntEatHyphensForBreakfast()\n            {\n                const string data = @\"{\"\"message\"\":\"\"my-test-string\"\"}\";\n                var httpResponse = new Response(\n                    HttpStatusCode.OK,\n                    data,\n                    new Dictionary(),\n                    \"application/json\");\n                var jsonPipeline = new JsonHttpPipeline();\n            var response = jsonPipeline.DeserializeResponse<SearchIndexingResponse>(httpResponse);\n            Assert.Equal(\"my-test-string\", response.Body.Message[0]);\n            // Fails due to returned value \"myteststring\"\n        }\n\n```\nIll either fix it, or raise an issue and Ignore the test (noting the issue number).  Just want to finish off implementing this SearchIndexing api first\n. So the responsible line is https://github.com/octokit/octokit.net/blob/master/Octokit/Http/SimpleJsonSerializer.cs#L93\nstringValue = stringValue.Replace(\"-\", \"\");\nLooking at when it was added on PR #727 https://github.com/janovesk/octokit.net/commit/46e572131f7175b3a85a6a86d62b139c49d22111 ...\nIt looks to me like the problem of handling underscores in enum values should be taken care of by the RemoveHyphenAndUnderscore(stringValue) calls added for Enum and nullable Enum types, so im not sure why the first stringValue = stringValue.Replace(\"-\", \"\"); was also introduced.  \nI removed line 93 and unit tests are passing, just running integration tests now... though there's always the risk that not enough tests around this area exist.\n@janovesk if you remember anything from back then, do let us know!\n. Yep, I removed the line and all current unit and integration tests passed, including the ones for property values with underscores added back in that PR, so it's a good sign. \nOf course if we don't have test coverage for every scenario we may miss something, but the best way to handle that IMO is to add tests if/when something breaks. Judging by the existing tests it looks like there's been a good culture of adhering to that approach (as well as ensuring tests are added with any new functionality), so one assumes the tests we currently have already assert behaviour complies with any previous reported shenanigans. \nThis situation was a pretty out lying  edge case I guess, attempting to deserialize a string into a IReadonlyList<string> (due to previous comment regarding differences in the message response from queueing a single item vs queueing all repositories/issues) \nWould you rather handle this json deserialize hyphen problem on a new issue/PR or shall I include it in this one? \nAs an aside it seems some of the integration tests (unrelated to this change) aren't consistently passing first time, but do pass after one or more retries so I might flag that for follow up ad well \n. Done (#1094) and also completed this Search Indexing API (#1095)\n. > I'm not 100% sure what this is all about, but it's in preview mode so it's not that urgent\nFYI :\nhttps://help.github.com/enterprise/2.4/admin/guides/migrations/about-migrations/\n\nA migration is the process of transferring data from a source location (either a GitHub.com organization or a GitHub Enterprise instance) to a target GitHub Enterprise instance. Migrations can be used to transfer your data when changing platforms or upgrading hardware on your instance.\n. Similar to #1024 you need to be on GitHub Enterprise to do this one :wink: \n. Sure, feel free to create all the models classes interfaces and so on and let me know your branch etc.\n\nI wasnt planning on doing this one for a while anyway, as im not really across what these migrations are about (migrating code from one github to another involving zips and files etc i think!) and dont really have a use for them at the moment...  Once I've done the #1024 this issue will be the last major Enterprise API missing, so for completeness sake I do want to do it... but definitely not as a priority\n. Implemented by #1141\n. Just going through open issues and noticed this one was fixed in #1058 and should be closed\n. No worries, naming things is the hardest part so always keen for feedback :stuck_out_tongue: \n. Cool, I'll push some changes later this week when I'm back (currently overseas) \n. Hey guys, Im back from holidays and have pushed up some renames as well as merged latest master into my branch.  Let me know what you think of the names\n. Hey all, im back from holidays - any feedback on this GitHub Enterprise support?  I plan to implement more of the open issues for Enterprise API support, but want to make sure im on the right track first :)\n. Thanks for the feedback, I've fixed up the async stuff and updated to latest master.\nOut of interest with octokit.net contributions, is there a preference between rebase on master vs merging master?  Similarly is there a preference to squash the commits down once it's ready to go in, or you aren't bothered by the larger number of in progress commits etc?\n. @shiftkey as discussed I've rewritten this to use individual methods for each admin stats type, removed the enum, added unit and integration tests for all the new methods.  Let me know what you think!\nFYI I still need to run the integration tests against our enterprise instance at work tomorrow, so DONT MERGE just yet!  I'll advise once integration tests are complete.  \nGiven we are going to be adding more Enterprise API calls to Octokit.net, we need to think about whether we can get access to a GitHub Enterprise instance from the automated builds so they can cover off the Enterprise Integration Tests.  @Haacked ?\nOn previously merged PR's I had added a [GitHubEnterpriseTest] test attribute, so the tests are only detected when the OCTOKIT_GITHUBENTERPRISEURL environment variable is present, but specifying that also then uses that enterprise instance for the normal integration tests and there's no specific GHE environment vars for user/password/token etc either.  If there is desire to get GitHub Enterprise integration tests as part of the automated process (considering we are planning on adding coverage for all the enterprise endpoints, I think this would be a good idea!) then I will do some more work in another PR to create explicit integration helper class for dealing with GHE including all the required stuff (user, password, token, organization etc etc).\n. OK so I went ahead and did the mentioned integration test tidy ups too.  I havent added it to this branch/PR yet as I didnt want to complicate the review process of the actual AdminStats API implementation.  I will probably push it through in another PR once this one is merged?\nHere is the commit though if you're interested https://github.com/TattsGroup/octokit.net/commit/a9421e662cc2dcb21fc169f9767a34faf59cd55f\n. All integration tests passed against my enterprise instance so this should be good to merge (from my perspective)\nNot sure why the AppVeyor and Travis builds are failing on unit tests... they are all passing for me locally.  Any ideas?\n. I think it's something to do with the different overrides of the ApiConnection.Get() method and the extension method Get(Uri) calling the base Get(Uri, null)\nAh never mind, I just realised there are changes on master I havent pulled in yet which sort out the issue with Get(uri) coming through to the ApiConnection as Get(uri, null), and of course my branch works but the builds are building the result of merging this with master...  \ndoh!  Stand by... :grinning: \n. ok after merge the AppVeyor build is ok, but 1 of the travis builds (OSX) failed (but Linux was ok).  I cant quite tell what the OSX problem was, seems to have blown up trying to discover tests in Octokit.Tests-Portable\nI did add my GitHub Enterprise unit test classes to this project, eventhough the \"FixProjects\" build command didn't do it itself.  Should I not have done that?\n. Looks like that previous OSX build failure was sporadic as they have now passed after i pushed up a couple of unrelated :lipstick: commits\nI think im done with this PR now @shiftkey \n. I've rebased this now that the AdminStats PR #1049 has been merged so it should be good for review/merge!\n. Looks like the Travis build failure is unrelated, @shiftkey  ?\n. Did the travis build automatically retry or did someone kick it off again?  Is there any way (apart from pushing another commit) for plebs to get the builds to try again?  :grinning: \n. Hey @shiftkey not sure if you may have forgotten about this one, but ive pulled latest master over again and the builds are still passing.  Should be ready for a LGTM :tongue: \n. Here's a new one we hadn't seen before.  Perhaps just temporary issue communicating with nuget or something...\n[Linux] The command \"nuget restore Octokit-Mono.sln\" failed and exited with 139 during .\nhttps://travis-ci.org/octokit/octokit.net/jobs/115926780\n. [Linux] Timeout\nSame as this one previously\nhttps://travis-ci.org/octokit/octokit.net/jobs/116884393\n. didnt want to include #1073 ?  :laughing: \n. Hi @mderriey \nAs far as I can gather, in order to test the LinqPad samples the proposal is that during the build, we rewrite the linqpad files to use local reference to the octokit DLLs (ie those that were just built) instead of pulling nuget packages (which dont contain the very latest changes in the build) then execute them to ensure they dont have any errors.  @shiftkey even ended up writing an example in c#\n\nI didn't really understand why that test should be ported to F#\n\nThe octokit.net build system is currently using FAKE, which I assume means we need that \"rewrite linqpad files to contain local references and execute them\" code to be in F# as a native task in the build.  \n\nWhere should the test be moved to?\n\nIm guessing it wouldnt be a test anymore but more so a task in the build script\n. Have to be a bit careful here because ItemState enumeration is used in many places (Milestones, Events, Pull Requests, Issues, and more) and sometimes all is a vaild option and sometimes not?\nEg SearchIssueRequest (only open and closed are allowed) vs IssueRequest (where open closed and all) are allowed\nhttps://developer.github.com/v3/search/#search-issues\nhttps://developer.github.com/v3/issues/#list-issues\nSo I dont think removing All from the enum is good.  Perhaps a new enum is needed and those places where only open/closed state is allowed, are changed to the new enum?\n. yeah, its preferable to not show an option (ie an All entry in Enum) to a user when it doesn't actually exist in the GitHub API like that.  I'd make a new enum called SearchItemState or ItemStateSimple or something like that, and use that on the Search functions (and anywhere else that might be limited to only open/closed).  I'd also update the XmlDoc comments on the ItemStateSimple? State parameter of SearchIssueRequest to note that leaving it unspecified will enact the GitHub default\n. Thanks for the PR!  Ive just made a comment on the PR and basically said that after seeing the proposed changes, i've backflipped on what was said above!\nPlease check #1140 for my comments and let's continue the discussion there :grinning: \n. So just a note on this topic, what ive found is FixProjects will add files from Octokit into all the other projects.  But if you then decide you want to remove that file, the FixProjects command doesnt REMOVE files from the sub projects.  It would be nice for FixProjects to remove files :grinning:\n. Hey @M-Zuber \nThis should be an awesome function, a tool we are writing at the moment has a need to push a file directly into a specific branch too :grinning: \nI noticed one typo of a class name in XmlDoc comments, ive flagged above.\nAlso could I suggest ensuring we keep the tests up to date with at least these 2 items?\n- update the unit tests to cover off the addition of the new branch parameter\n- add an integration test to prove it actually creates the file on the specified branch\nLet me know if you want some help adding the tests\n. Yeah if you look at the \"crud\" integration test I'd probably do the same actions as that, but specifying a named branch \nFor unit test since the url is the same anyway, you could check that the CreateFileRequest object passed through, has the correct path/message/content/branch present in it.  Eg  have look at PassesRequestObject() test here\n. Hey @M-Zuber that looks good... your integration test is passing for me here.\nOn the topic of unit tests, your change was mostly to a Request object and it doesnt look like there are many unit tests of those things in octokit.net.  \nHowever if you are interested, I did just send you a pull request that implements unit tests on the CreateFile() DeleteFile() and UpdateFile() calls in RepositoryClient, including making sure your new branch field is correctly passed through to the underlying ApiClient.  What ive found with Octokit unit tests for API clients typically check \n- calls the correct URL\n- passes through the request object\n- checks parameters for nulls and throws exceptions if paramter is required\nhttps://github.com/M-Zuber/octokit.net/pull/2\n. I don't have commit rights, am sitting on a few pending PR's myself \ud83d\ude00\n. @shiftkey Linux build failure looks unrelated to me. Looks like a timeout in the octokit.tests-portable \n. @shiftkey Linux build failure looks unrelated. It's the \"type initializer for list threw exception\" variant \n. Could you guys kick off the travis build again when you have a sec?  Failure was unrelated\n. Dont forget that #1073 needs to go first, then this one, then #1022  :grinning: \n. Awesome, this has now been rebased on master and should be ready for review and merge\n. @shiftkey builds passed, ready when you are :)\n. Yeah we had a bit of discussion on the issue #1026 about which way to go and ended up with the multiple methods.  Thanks for merging!\n. > Ah, cool. Yeah, I like it. I'm just thinking about adding one additional method as a failsafe. But I don't want to do that yet.\nWhat would the failsafe be, out of interest?\n\nThanks for contributing!\nIt's a pleasure on such a weel organised dotnet OSS project.  My goal is to implement all the GitHub Enterprise API's currently unsupported.  I think im just down to the Setup Console now (which is pretty big) as well as some extra methods on User Administration that are enterprise only.  \n\neg normal API doco for User Administration:\nhttps://developer.github.com/v3/users/administration/\nvs Enterprise API doco for User Administration\nhttps://developer.github.com/enterprise/2.5/v3/users/administration/\nHeaps more nice methods to create/delete users, impersonation tokens, etc.  Fun times :grinning: \n. Nice idea, I'll add it in the next couple of days! \n. Regarding Unit Tests, I'd suggest it would be good to add a couple more similar to these:\nTheGetAllForCurrentMethod.CanFilterByType()\nTheGetAllForCurrentMethod.CanFilterBySort()\nTheGetAllForCurrentMethod.CanFilterBySortDirection()\neg\nCanFilterByVisibility\nCanFilterByAffiliation\n. Potentially a specific section on \"working with GitHub Enterprise\" in the docs?\nIm still not entirely sure what the intention of this probe method is for.  Is it for octokit to do smart stuff internally, or just providing an API where someone writing an application like GitHub Desktop could allow users to enter a repo URL and it would be able to probe if its Enterprise or not?\n. I like the idea of making this more like a GetCapabilities client/request.\nAlso, this may be a dumb question but what if someone has a hostfile entry or DNS alias to point \"external.github\" at \"github.com\".  To me it seems like rather than assume that \"only\" github.com is \"DotCom\" you sort of want to probe/confirm even \"DotCom\" capability, rather than going only off the URL?\n. wow, cant believe the builds passed straight up.  not even one mismatched xmldoc comment :grinning: \n\n. OK now that #1073 and #1095 are merged, ive rebased this guy.  Builds have passed too.\nShould be easier to review now @shiftkey @Haacked \nPlease note the notes/comments I put in the PR about some design decisions/considerations I made\n. OK I have renamed to LdapDistinguishedName and used the Parameter(Key = \"ldap_dn\")] attribute to set the API field name, how does it look now?\n. > And that worked?\nyep!  Had a bit of a delay due to not getting a chance to rerun the integration tests against an LDAP enabled GHE server, but that's all done now and the renamed fields have worked fine :grinning: \nIve alsomerged latest master in...  builds have passed for all platforms\nI think we should be good to hit the button on this one @Haacked @shiftkey \n. ok I can remove those...\nI've actually done that on alot of the API methods ive added in the last few pull requests.  Want me to raise another PR to clean them all up?\neg:\n/Octokit/Clients/Enterprise/EnterpriseAdminStatsClient.cs#L58\n/Octokit/Clients/Enterprise/EnterpriseLicenseClient.cs#L28\n/Octokit/Clients/Enterprise/EnterpriseOrganizationClient.cs#L31\n/Octokit/Clients/Enterprise/EnterpriseSearchIndexingClient.cs#L33\n. Yeah I went on a rampage trying to fix this but wasn't sure about what this bcl thing is, and given the number of reference updates etc I ended up making, I didn't bother submitting the PR haha. Would be nice to get rid of the annoying errors \n. > @ryangribble which errors are we talking about? \nDo you mean you dont see the below errors @shiftkey ?  They dont actually stop the build, but they do show up as errors (Im using VS2015 Update 1 incase that's related)\nProjects that reference Octokit.csproj say they want to have the Bcl.Build reference due to referencing the Octokit project that has that.  \nThen other errors complain that Octokit.Tests project doesnt have a packages config file (it's named packages.Octokit.Tests.config rather than  packages.config).  No doubt if it could find the right file the test projects would also complain about missing references that the Octokit.Tests project has...\nOften I seem to have the errors from all of the sub projects (eg Reactive, Portable, NetCore45, Mono) but then today when I went to grab this screenshot, it's only Octokit.Reactive that's doing it.  Very odd!\n\n. so do you not get those errors?  What IDE are you using?\nAnd is upstream in this case Visual Studio itself or nuget or this Build.Bcl package?\n. So far the best I've found is somebody with the exact same problem on SO, but they've just hacked/patched the Bcl.Build.targets file, to include the $(MSBuildProjectName) in the path of the ReferencedProjectPackagesConfig.  Which obviously isnt going to dynamically handle either packages.config or packages.$(MSBuildProjectName).config\nhttp://stackoverflow.com/questions/32254228/installed-project-specific-nuget-packages-not-being-recognized\n. Just a question on this out of interest... \n\nI think we should add an overload that accepts an enum with the available permission options.\n\nAre you saying @Haacked that this body parameter should actually be explicitly in the overloaded function, or should it be what appears to be the \"usual\" Octokit way where a Request object is passed in?\nJust trying to get a feel for the octokit.net conventions, most I had come across seem to use the request object approach, so was surprised to see you mention adding an overload directly taking the enum paramter (unless i misunderstood)\nEnum directly in Ad function\n```\nenum CollaboratorPermission { Read, Write, Admin }\nTask Add(string owner, string repo, string user, CollaboratorPermission permission);\n```\nvs\nUsing a request object\n```\nenum CollaboratorPermission { Read, Write, Admin }\npublic class CollaboratorUpdate\n{\n   public CollaboratorPermission Permission { get; set; }\n}\nTask Add(string owner, string repo, string user, CollaboratorUpdate update);\n``\n. Sweet, my understanding remains intact \ud83d\ude01\n. Also note that as part of this GitHub API change, they indicated that thepermissionparameter when creating and editing Teams is deprecated.  So potentially on ourNewTeamandUpdateTeamrequest model classes, we should mark that field asObsolete`\n. This was implemented in #1410 but I will raise a new issue to cover this other comment:\n\nAlso note that as part of this GitHub API change, they indicated that the permission parameter when creating and editing Teams is deprecated. So potentially on our NewTeam and UpdateTeam request model classes, we should mark that field as Obsolete. Looks like that function inadvertently passes String.Empty rather than the reference parameter into the next call in the chain \n\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Clients/RepositoryContentsClient.cs#L241\nIn the meantime you should be able to use the overload that takes an additional TimeSpan argument (pass in 60 minutes if you want the same behaviour as the overload you are wanting to use), to work around the issue. \n. > I knew this code lived somewhere\n\nAh right, we even use that SshKeyClient at the moment but I was tunnel visioning on the User.Keys side of things and didnt think that they are the same thing!\nSo yes, the methods on ISshKeysClient should be added to IUserKeysClient - and IGitHubClient.SshKey should be marked as obsolete for removal as it doesn't align with the API.\ni'm in the process of doing this now, all the methods are transferred but I have some questions about the obsolescence stuff\n\nI've marked IGitHubClient.SshKey obsolete but that doesn't actually flag several use cases...  So should we actually also mark GitHubClient.SshKey obsolete (that gets anybody using a GitHubClient rather than an IGitHubClient).   Then we need of course the Observable and IObservable versions as well.  Do we go as far to make the actual class SshKeysClient or it's interface ISshKeysClient obsolete so that anybody who directly creates those clients would get the warning?  \nGiven so many places are required to really catch most use cases, I wonder would it actually be better to simply mark the actual Get() GetAll() Create() Delete() methods as obsolete (on the interface and concrete SshKeysClient), that way it doesnt matter whether the consumer uses interfaces or concrete class, the top level client or the low level client... if they invoke any of the methods, they will be advised to move away from them?\nSo apart from the question on the best way to obsolete something, I've also reviewed the associated code/classes and found that the SshKey and SshKeyInfo classes probably need to be obsoleted as well.\nThe only place SshKey is used is within the SshKeysClient so once that's obsoleted and eventually removed, it seems the SshKey response object should go too?  The PublicKey class has all the same fields and is used in UserKeysClient which aligns with the API terminology of referring to public keys rather than ssh keys.\nAnd how about this ModelExtensions class?\nAs per the TODO comment it only deals with SshKeys and should have been renamed to something less generic... but Im more so interested in whether I need to create equivalent extension class/methods for PublicKey class (and thus create PublicKeyInfo class too) or can these extensions just be dropped (when SshKey is dropped, after having been obsolete for a while)?  These ModelExtensions are only used in the unit/integration tests (within Octokit) though Im not sure if the intention was that consumers of Octokit would use these helper extension methods to do stuff with the contents of keys?\n. > EDIT: good point on the \"only used in tests\" thing. Mark these versions as obsolete, move the new variants into the tests (we don't have a shared project for test helpers, which might get in the way here).\nFurther investigation showed that these extension methods arent even used by any tests other than the unit tests FOR the extension methods themselves (ie ModelExtensionTests.cs)\nPerhaps the 3 extension methods and PublicKeyInfo class dont even need to be created at all?\nUnless there was some intention that this helper method was exposed to octokit consumers to do stuff with.  It's pretty basic anyway, not sure if there would be a real world use case.  @Haacked ?\n. So given that SshKeyInfo isnt a response class but just a helper class, what would say if we created the PublicKeyInfo class to replace it, and in it's constructor it took a PublicKey item eg var keyInfo = new PublicKeyInfo(key) and/or had static PublicKeyInfo.FromPublicKey(PublicKey key) or do you really want it to be an extension method on PublicKey itself?\n. Lol, too many PR's! Meant to say #1099\n. Now #1099 is merged, this one has been rebased and squahsed, builds/tests passing... \nready for your attention @shiftkey @Haacked \nThanks\n. Just to clarify, I didnt have a current \"real world\" use case, it was more I was in the same situation as you... when writing unit tests for octokit.net API implementation, it would have been useful to just check that the passed response object was \"equal\" to the one I expected, rather than having to check various sub properties of the object\neg \nhttps://github.com/TattsGroup/octokit.net/blob/enterprise-useradministration/Octokit.Tests/Clients/UserAdministrationClientTests.cs#L143\nIm sure I could have written those checks better anyways :P\n. This was fixed by #1248 (apart from a few additional ones which were possibly introduced after #1248 anyway... #1483 is tackling those)\n. I pushed up the final change, to implement the extension methods as mentioned in #1106 \nMac and Linux builds failed but I can't see anything obvious...  @shiftkey can you spot anything or do they just need a kick?\n. > The description still says \"Do not merge!\" :laughing:\nAh yeah, I meant I'd finished coding but still needed to rebase once the other PR's were merged\nWhich is now done!  Finger's crossed the builds behave this time :grinning: \n. Damn, we were on a roll there for several days where the linux/osx builds didnt have any issues, but it seems we are back to the System.TypeInitializationException: The type initializer for 'System.Collections.Generic.List1' threw an exception. ---> System.Threading.ThreadAbortException:` issue :angry:\nI don't think it's related to any changes, just another case of #1076 \n. Cool thanks for giving the builds a kick!\n@shiftkey are you happy with the obsolete approach?\n@Haacked i kept the extension methods pretty much as they were so I assume that works for you guys in the desktop client.  Would be interested to know if you use all 3 extension methods or whether any of them could be dropped...\n. > Let's drop the extension methods and I'll just move them into our own code.\nDone\n. Any other feedback before I hit the button?\n. Woohoo, my first self merged PR.  That deserves a celebration :beers: \n\n. Nice pickup, thanks for the contribution!\n\n. Unfortunately we are sometimes seeing unrelated failures on the linux and/or OSX travis CI builds.\n1076\n. :+1: \n. With this change, won't there still be an issue if you set a non Default value for visibility or affiliation, since the Type property still has a value specified that will cause a parameter item to be sent through?\nSo you'd either have to add your ParameterValue(\"\")Default option to Type as well or perhaps another approach is to make the enum properties on RepositoryRequest be nullable, that way when they arent specified they wont set anything in the parameter array?\neg\ncsharp\npublic class RepositoryRequest : RequestParameters\n{\n    public RepositoryType? Type { get; set; }\n    public RepositorySort? Sort { get; set; }\n    public SortDirection? Direction { get; set; }\n    public RepositoryVisibility? Visibility { get; set; }\n    public RepositoryAffiliation? Affiliation { get; set; }\n}\nWhichever way it's done, I agree with @M-Zuber it would be useful to check the RepositoryRequest in GetAllForCurrent() and throw an error if \"invalid\" combination is specified by the consumer\neg:\nif ((request.Visibility != null || request.Affiliation != null) && request.Type != null)\n{\n    throw new ArgumentException(\"If you specify Visibility or Affiliation, you cannot specify Type.\");\n}\nPerhaps @shiftkey can advise between the preference of adding a Default enum element (that has a blank property value causing nothing to be specified) vs allowing nullable properties?\nAlso when I'm adding functionality to Octokit, I always try to add tests as well, so that from now on we can assert that this problem never re-appears down the track.\nIn this case I would add unit tests to cover:\n- RepositoryRequest - when null (in my example) or .Default (in your example) is specified for each property, that corresponding parameter name does not appear in the parameter dictionary created by request.ToParametersDictionary() \n- RepositoriesClient.GetAllForCurrent() throws the expected exception when incorrect combination of flags is provided\n. Nice work on the parameter array unit test :)\nWhile we're here I wonder if we should tweak the DebuggerDisplay() on RepositoryRequest since it doesnt list the Affiliation or Visibility properties plus it outputs field names for the other fields that can now be blank?\n. > For null values, shoud we output something like Visibility:  or remove the property from the output?\nI think the way you've done it is good (if the values are null, don't mention them at all).\nLGTM - I'll just wait for a +1 from @shiftkey before merging\n. Hey @devkhan thanks for contributing the fix and this is a great opportunity for you to gain experience in the area of open source contributions and familiarity with mock based unit testing! :)\nThe purpose of the Octokit.net unit tests is to verify expected behaviour but run totally self contained locally (ie not calling out to any github.com api calls and the like).  So the NSubstitute mocks are used to mock out any of these expensive/external API calls so that the tests run quickly and against controlled data.\nMocks help us achieve the Unit Testing \"Arrange, Act, Assert\" pattern.\n- Arrange is where we setup our input data and configure our mocks\n  (ie, \"when you receive a call that looks like this, reply with this data\") \n- Act is where we make the call we are actually testing\n- Assert is where we then use our mocks or the returned data to make various assertions about what we expected to happen (which throw an exception and fail the test if the conditions we test for didnt occur)\n  (ie, \"assert that when I called the Users.GetAll() client call, the underlying httpConnection received a Get<User>(...) call with parameters that contain specific values we wanted (like the expectedUrl, input parameters etc)\"\nSo anyway, the reason those tests are now failing is that the substituted IJsonSerializer is now correctly passed through thanks to your fix, meaning that down in the guts of constructing the http call to the API, the \"data\" of the response body is null (because the substitute hasnt been configured to return  any data when Serialize() is called on it).  This means that the Assert on httpClient.Send() is failing, since it did not receive a call that matched what we specified (specifically, the body data is now null rather than it being \"\" as expected)\n@M-Zuber 's example is setting the expected body data to be the (null) return of the mocked serializer... which does make the test pass, however I would probably recommend instead to configure the mock to return the data we want since that is more in keeping with the unit testing approach and would also be applicable in other situations where we had a \"real\" body instead of a new object() as in this case.  \nWe can also add an assert to ensure that the IJsonSerializer Received() 1 call to Serialize() thus proving it was correctly passed through.\nDoes that give you enough information @devkhan to tackle correcting the failing unit tests yourself?\nTo give an example of how I would probably fix these unit tests (explanatory comments like this aren't required, im just adding them to walk you through what's happening):  \n``` csharp\n[Fact]\npublic async Task RunsConfiguredAppWithAppropriateEnv()\n{\n    // Arrange\n// - Setup request body and expected data\nvar body = new object();\nstring expectedData = SimpleJson.SerializeObject(body);\n\n// - Setup IJsonSerializer mock to return expectedData when Serialize() is called\nvar serializer = Substitute.For<IJsonSerializer>();\nserializer.Serialize(body)\n    .Returns(expectedData);\n\n// - Setup IHttpClient mock to return a response object when Send() is called\nIResponse response = new Response();\nvar httpClient = Substitute.For<IHttpClient>();\nhttpClient.Send(Args.Request, Args.CancellationToken)\n    .Returns(Task.FromResult(response));\n\n// Act\n\n// - Create our connection object\nvar connection = new Connection(new ProductHeaderValue(\"OctokitTests\"),\n    _exampleUri,\n    Substitute.For<ICredentialStore>(),\n    httpClient,\n    serializer);\n\n// - Make the Patch() call\nawait connection.Patch<string>(new Uri(\"endpoint\", UriKind.Relative), body);\n\n// Assert\n\n// - Verify JsonSerializer.serialize() was called with body object\nserializer.Received(1).Serialize(body);\n\n// - Verify HttpClient.Send() was called with all the correct arguments\nhttpClient.Received(1).Send(Arg.Is<IRequest>(req =>\n    req.BaseAddress == _exampleUri &&\n    (string)req.Body == expectedData &&\n    req.Method == HttpVerb.Patch &&\n    req.ContentType == \"application/x-www-form-urlencoded\" &&\n    req.Endpoint == new Uri(\"endpoint\", UriKind.Relative)), Args.CancellationToken);\n\n}\n```\n. Personally I do prefer to either do like I did and declare the body and the expected serialised data (even if blank) or do like @shiftkey and indicate you don't care to check the body at all \nAnyway, just give it a go however you think and push up your changes and we can have a look \n. does the test I posted earlier work for you?  what about the variant @shiftkey  posted?\n. > @shiftkey's variant works , but not yours\n@shiftkey's is fine to go with.  But just for completeness sake... mine should work too!  Did you replace the entire RunsConfiguredAppWithAppropriateEnv() test with my test from above?  It passes for me!\n. @M-Zuber that sounds like you dont actually have the \"fix\" from this PR in place?\nhttps://github.com/octokit/octokit.net/pull/1133/files#diff-af38d3b1f8ffea99f4957f21d0d6271eR136\nIt also shows that my test asserts the Serializer passed in is actually used, whilst the other tests didnt actually check this.  Whether this is something these particular tests SHOULD test (or whether it should be covered off by another test) is up for debate though :)\n. > No, I wasn't paying enough attention and reporting false findings, thats all.\nHehe, we've all been there.  Pretty funny you did all the right stuff on the tests, but forgot to actually implement the fix that started the entire PR!  :laughing: \n. Thanks for your work @devkhan and good discussion by all :)\nDespite using the SimpleJsonSerializer for the tests, I feel like now you've added the mock to check that the passed in ISerializer is actually being used, that gives us some good coverage if a consumer ever does want to use their own ISerializer\n. \n. >  but has not been ported over\nIsn't it this call UserKeysClient.GetAll() ? \n(which I did port over in #1112 )\n. ok cool, so this task can be simplified to simply renaming GetAll() to GetAllForCurrent() on\n- UserKeysClient/IUserKeysClient\n- ObservableUserKeysClient/IObservableUserKeysClient\n- And the unit and/or integration tests for the above\n. :+1:\nAnother suggestion that can make the release notes generation more automatable is that you can add a comment to an issue or PR that will define what the release note item should say.\nFor example, an Issue might say \"Error is thrown when XYZ happens\" but you want the release notes to say something else, so you make a comment\n\nrelease_notes: XYZ could throw an error in some cases, this is now fixed!\n\nThe release notes generation process now just needs to see if a PR or issue has this \"release_notes\" comment on it and use that instead of the title.  Could even fail the release process if any item it needs to include, doesnt have this \"field\" on it.  You can also \"lock it down\" so that only certain user's comments will be seen as valid \"release_notes\" text and so on.\nThis can then be maintained as we groom/merge PRs and close issues etc, so the actual process of creating release notes doesnt involve any rewording or massaging and can eventually be fully automated\n. > @ryangribble did you want to open an issue for the release notes stuff so we can hash out how that might work separate to this?\nYep Ill do it (over the weekend) :grinning: \n. Just me being pedantic, but now the method has been renamed, can we also please rename the unit test classes?\neg class TheGetAllMethod should now be class TheGetAllForCurrentMethod here and here\nAlso AppVeyor build seems to be throwing a Code Analysis CA1024 error\n\nMSBUILD : error CA1024: Microsoft.Design : Change 'IUserKeysClient.GetAllForCurrent()' to a property if appropriate. [C:\\projects\\octokit-net\\Octokit\\Octokit.csproj]\n\nIm not sure why the method name GetAlldidnt trigger it but GetAllForCurrentdoes, but you can suppress it (varoius examples through the codebase like here\n. That doesn't explain why it didn't trip the error previously when called GetAll though does it? \n. Hmm the build failures look like they couldn't talk to nuget.org at the time... \nI kicked off the Travis build again and that's now passed. Don't think I have access to do the same on Appveyor @Haacked @shiftkey \n. \n. so after having a look at the changes on the PR I have to say that I am backflipping a little on what i said in the issue #1082 !!\nIt looks like almost all usages of ItemState only allow values of Open or Closed.  Eg issues, milestones and pull request objects, as well as the NewXXX and UpdateXXX Request classes for these.  It doesn't really make sense to me, to use an enum called ItemStateFilter (that s described as being used for search filtering) on all of these objects and new/update message classes.  It looks like pretty much the ONLY place that seems to allow All as an option to State is the List Issues/Milestones/Pull Requests type calls.\nSo Im wondering if perhaps we should:\n- Keep ItemState enum but flag the All value as [Deprecated] (to be removed in future)\n- Keep using this ItemState enum on all the existing places such as Issue Milestone and PullRequest objects and the NewXXX UpdateXXX request classes for them\n- Introduce the new ItemStateFilter enum, allowing open,closed,all and use it only on the `XXXRequest`` classes that are used for the \"list\" methods\nThat means less \"overall\" change, and the more sensible approach that ItemState is used for actual items and creating/updating them... whilst the ItemStateFilter is used when listing them\n. Yep pretty much, and [Obsolete] the ItemState.All item\n. > @ryangribble \n\nBut then we come back to the same issue, that the user who is using octokit doesn't get all the issues on using ItemState.All\n\nI'm not sure I follow?   The search API would no longer take ItemState as an option (it would be ItemStateFilter)  so they wouldn't be able to specify it anymore? \n. hi @prayankmathur, as with the other PR it would be great if you could give this one a nice title and description when you can!  :grinning: \nIn terms of your latest changes, Im still seeing several uses of ItemStateFilter where I dont think they are valid.\nTo recap:\nItemStateFilter allows values Open, Closed, All and is used on operations that can accept all 3 values - namely the \"List\" calls under Issues, Milestones, PullRequest API clients\n(eg client.Issues.GetAll(new IssueRequest(State: ItemStateFilter.All))\nItemState allows only Open and Closed (with \"All\" being marked [Deprecated], to be removed next release) and is used on operations where only Open or Closed are valid states.\nThe Search API client is the example that triggered this issue to be raised, \neg client.Search.SearchIssues(new SearchIssuesRequest(State: ItemState.Open)) \nhowever there are also several other use cases, such as updating an Issue/Milestone/PullRequest and creating a Milestone where the state can only be open or closed.  \nYour latest changes show IssueUpdate MilestoneUpdate NewMilestone and PullRequestUpdate classes as all using ItemStateFilter but shouldn't they be using ItemState since only open and closed are valid values for all of these?\n. Looking really good!  \nDown to very nitpick type comments now... Ive flagged a few whitespace and XmlDoc tidy ups\nThe TravisCI build failure on linux was an environmental issue and not related to your changes... I've given it a kick\n@shiftkey - im thinking since this is a breaking change anyhow (replacing ItemState with ItemStateFilter on the xxxSearch Request objects)... perhaps there is no need to Obselete the ItemState.All value and we can simply remove it as part of the breaking change.  There shouldn't really be anyone using ItemState.All on Issue/PR/Milestone update/create anyway since it isn't a valid operation (not sure how the API handles it if requested actually!).  Do you agree with not needing to Obsolete ItemState.All ?\n. Just a reminder @shiftkey I was waiting for your guidance on whether the ItemState.All needs to be obsoleted, since it's already a \"breaking change\" replacing ItemState with ItemStateFilter on any place that All was ever a valid option anyway...\n\nim thinking since this is a breaking change anyhow (replacing ItemState with ItemStateFilter on the xxxSearch Request objects)... perhaps there is no need to Obselete the ItemState.All value and we can simply remove it as part of the breaking change. There shouldn't really be anyone using ItemState.All on Issue/PR/Milestone update/create anyway since it isn't a valid operation (not sure how the API handles it if requested actually!). Do you agree with not needing to Obsolete ItemState.All ?\n. Hi guys, sorry for the delay I had a little break over the long weekend :)\n\nIt's looking great now @prayankmathur... \nIve marked up a couple of (final!) comment tweaks, and also noted that as per above, no need to [Obsolete] the ItemState.All option anymore - just :fire: it\n. And with that, I think we are done with this one!  Thanks for persisting through all the nitty gritty review :laughing: \n\n. Yeah, you have to run the build script locally, with \"FixProjects\" target - this adds any new files added to octokit project, to the other mono/core/etc projects \nInstructions in the contributors doc \n. So I was reading the documentation about this feature and it turns out I was incorrect in saying you need github enterprise for this API \nThese API calls cover the process of extracting repositories from github.com or github enterprise,  that can later be imported into github enterprise. The API is in preview mode only and on covers the export side, there doesn't appear to be anything on import side yet. \nAlso this preview API isn't yet available on github enterprise as of latest 2.5 version (according to docs at least)  so at the moment it seems only possible to do against github.com (usually new features make it into the next ghe feature release so I'd expect to see them in 2.6, potentially with the import side implemented as well or possibly not) \nGood news is this means you should be able to do all the testing and integration tests etc yourself @devkhan \n. Hey @devkhan \nGreat job getting a good head start on this :grinning:  Implementing a whole new \"client\" is a pretty maojr job, so there are quite a few things we'll need to cover to get you over the line!  We really appreciate your contribution so please don't be put off by the following feedback, I'm trying to make it as detailed and explanatory as possible so that we can quickly get you into the \"mindset\" of an octokit developer :rocket:\nAPI Client Structure\nWe try to structure the API clients in octokit to be inline with the GitHub API.  If you have a look at the sidebar in the API docs, the Migrations client lives under a menu item called Migration and does not belong under the Enterprise API.\nThis means, you actually need to create a \"IMigrationClient\" that lives in IGitHubClient, then a IMigrationClient that lives in MigrationsClient.  Yes this is confusing since there is Migration->Migrations and also confusing since the docs refer to it as the Enterprise Migration API, but we live and die by the API structure in the sidebar, therefore when using Octokit we should match that structure.  eg client.Migrations.Migration.Start()\n\nAs an aside, it looks like this Migration/Migrations API actually got moved to this top level location late February, previously it was under the Organizations API.  I see there is also a new Source Import API under Migration that I will raise an issue for shortly!\nNaming things (TM)\nIf you have a look at some other Client APIs for inspiration, you'll see there are some naming conventions in Octokit which should be consistent.  For example, since it's the Migrations API, you wouldnt call the List Migrations method GetMigrations() (since that would be client.Migration.Migrations.GetMigrations() !!! ).  We normally name the \"list\" methods Get() (for a single instance) GetAll() (for all instances) and GetAllForCurrent() (for all instances for the current user, when it's something a user can own, like repositories, publickeys etc.  So i'd suggest the names for the methods in this API should be\nStart a migration: Start()\nList of migrations: GetAll()\nStatus of migration: Get()\nDownload migration archive: GetArchive()\nDelete migration archive: DeleteArchive()\nUnlock repository: UnlockRepository()\nOrder of Methods\nIn a similar line of thought, I personally try to have the \"order\" of the method calls in my client, match those shown in the API.  So in your case, you've listed them as \nStatus, List, Start, Download, Delete, Unlock\nwhereas the API docs list them in a slightly different order \nStart, List, Status, Download, Delete, Unlock\nPersonally I'd prefer to match the order to the API docs as it makes it easier to review and check for completeness etc :grinning:\nOther Notes\n\nDont forget to set the custom accepts header to enable this preview functionality, otherwise it wont actually work when you do it \"for real\".  Have a look at the AcceptHeaders.ProtectedBranchesApiPreview as an example on how to do this.  Basically you will add a new entry into that AcceptHeaders helper class, then on your API methods you will need to pass that accept header to the ApiConnection.Post/Get/Delete methods\n  \nWith your serialization problem, the tiniest little things can sometimes cause so much trouble!!!\n  If you have a look at all other Response model objects, you will notice they have a default/parameterless constructor!  That's all your problem boils down to... 1 line!  haha :sob: \n\nInternally the SimpleJsonSerializer builds up that ConstructorCache and in your Migration class, it can't find a constructor to use, since you only provided one that takes all the parameters!  Adding a default constructor should get you past this hurdle!\n  public Migration() { }.  Same issue will be with your StartMigrationRequest request object.  If you want to have a unit test that tests the deserialization, it will need a default ctor\n. > Thank god, it came up before running .\\build.cmd FixProjects\nIndeed!  We have an open issue #1092 suggesting to make \"FixProjects\" build task remove items from the slave projects, if the items no longer exist on disk... we've all \"been there\" when we rename something and have to go hacking around in those other projects to set the world right again.  Unfortunately I am too chicken to tackle the F# build script to see what's involved in doing that!\n\nAlso, a question, does it mean we have to create an IMigrationsClient and an ISourceImportClient (may be in the future) inside an IMigrationClient and that will go under the IGitHubClient?\n\nYep!  I think this is the first time they've given us 2 such similarly named things as parent/child, but the structure is a \"Migration\" entry, with \"Migrations\" and \"Source Import\" under that.  So although it's a bit odd to have client.Migrations.Migration.GetAll() etc, that's what they've come up with, so that's what we'll implement :grimacing: \n. Yeah, I mentioned earlier it is confusing since they doi call it the \"Enterprise Migrations API\" but with octokit.net, we base the Clients class structure on the API structure (as shown in the sidebar on the doc site) and not the name... so GitHubClient.Migration.Migrations is what you should go with (and similarly move all the models, tests etc out of the Enterprise folders)\n. Also from a consistency point of view, in the Client interfaces and implementations you've got method parameters on separate lines\ncsharp\nTask<Migration> Start(\n   string org,\n   StartMigrationRequest migration);\nWhereas to be consistent with the existing Clients in the code base, they should be\ncsharp\nTask<Migration> Start(string org, StartMigrationRequest migration);\n. > Should I change this in the tests also?\nI was only referring to the method declarations, and the test methods dont take any parameters so it;s not applicable to those... \n. > So, what should I do?\nThe mentions of \"Enterprise Migrations\" is only at the landing page for the parent \"Migration\" page.  Everywhere else shows \"Migrations\" - eg the URL, the sidebar, the actual page title etc.  This seems to be the first example I can find where the \"title\" of an API as shown on it's parent's landing page is not consistent with it's name in the side bar and on it's own page!\nThis API was already only recently moved/relocated to this spot, so I assume this is it's new home now, and if anything it may be losing the \"Enterprise\" nomenclature... Perhaps @shiftkey or @Haacked can get the inside word on whether this is being renamed \"to\" or \"away\" from \"Enterprise\" Migrations API on it's parent page?\nThis is the only place it's called \"Enterprise Migrations\"\n\nEverywhere else it's just \"Migrations\"\n\n\n\nI think your latest revision is great though - IMigrationClient being the top level parent, and IMigrationsClient being the lower level migrations API.  The amusing thing is that due to our policy in octokit of naming the API client property in the singular, we still end up with client.Migration.Migration.GetAll() :sob: \nBut I do think the way you've got it now is the most consistent and inline with the standards set throughout octokit (rather than breaking the singular property naming rule or calling it EnterpriseMigration eventhough its not called that in most places in the doc)...  so Im happy with how it's ended up!\n. This PR is looking great now!!!  Great effort on the testing coverage and everything is looking nicely consistent and thorough!  :+1: \nI think there's just the one indentation issue with the json in the model test... and the fact that other PR merges have caused you to be out of date with master which you'll need to rebase or merge (sorry!)\nIll pull this down and run through the tests etc myself in the next couple of days\n. @devkhan ill pull your stuff down and have a look through it in the next couple of days\nthanks!\n. Hey @devkhan , sorry for the delay in getting to this one.  Ive made a number of comments against file diffs for you to go through which should give you some pointers.\nRegarding the integration tests, there are a few things here:\n- they currently are creating a lot of migration requests - eg almost every test is requesting a migration of all repo's in the configured organization.\n- they also assume the organization HAS repos which potentially may not be the case...\n- the download archive method - I think you cant download the archive until the migration status is \"exported\".  I had to add a while loop to that test, sleep for a few seconds and check the status again (using GetMigration) until it reported \"exported\" and then I was able to call the DownloadArchive function.\n- the DownloadArchive API call issues a redirect to the download link for the archive, andoctokit automatically follows redirects.  In my case at least, this was an 80+MB file (as i had a clone of octokit.net repo in my test organisation) and took a few minutes to download\nFor the tests to be succesful and efficient we cant rely on or pre-suppose any existence of data, beyond the information provided through integration test setup (ie user, password, apikey, organization).  So ideally we want to create whatever data we need for the tests, and wherever possible we want to clean up after ourselves as well (eg who wants to have 100s or 1000s of repos in their test org, because they ran the test a number of times).  Luckily we have some examples in octokit of doing this, and some helper classes and methods to help you out :grinning: \nWe want to use the \"CreateTheWorld()\" type approach, that we are using in some other ingration tests (a good one to look at is MergingClientTests.cs .  We'll essentially have a single test class for this MigrationsClientTests with a constructor that will setup all the data it needs (eg repositories, content in those repositories and kick off the migration).  Then you will have the normal test methods you've already written for the other methods, and finally implement IDisposable and clean up after ourselves where we can (eg we can delete the repos but we cant really stop the pending migrations, however it could be that deleting the repos deletes those migrations anyway, we'll have to see).  It shouldnt be a big deal anyway since the API docs say that any created migration archives are removed after 7 days anyway, so the main thing for me is that our test repos get removed once we're done.\nWe have helper classes for RepositoryContext and an extension method on IGitHubClient that can create these temporary repositories, and they implement IDisposable which will then delete the repositories on github.com when the tests wind up (well more precisely, when your test class Dispose() method calls Dispose() on the contexts).  You can steal/borrow some code from the CreateTheWorld() implementation in MergingClientTests.cs to populate those repos with a couple of commits/content so they arent empty... and the last thing to do in the constructor phase, is actually initiate the migration request (since all the other test methods need a migration to be requested).\nThen have your normal test methods, to run through the Get, GetAll, DownloadArchive (remembering to check/wait for appropriate exported status) and UnlockRepository test methods, against that list of created/known repositories.  (although the usual approach is a separate test class per method, in situation like this I reckon it's OK to make all the test methods in the one class, so they can use the contexts setup in the constructor.  Another option would be to have the test method classes, inherit the base class, so they can access the contexts... either would work.\nImplement IDisposable on the test class, so you can override Dispose() and explicitly dispose the contexts (which will delete the repositories from the user's test organization on github.com) and will hopefully leave things mostly tidy over many test ezxecutions.\nI've knocked up a quick gist to demonstrate what I'm talking about.\n. Also question for @shiftkey ... should the status field be implemented as an enum in octokit?\nIm thinking yes, since we have things like ItemState as an enum, eventhough the api returns that as a text field.  \nIn the case of Migratoin status, the API docs do specifically list all the possible values, so using an enum would be the way to go?\nhttps://developer.github.com/v3/migration/migrations/#get-the-status-of-a-migration\n. i believe other download URLs like the files on \"Releases\" API will follow the redirect and download the file so Id assume similar can be done here.  I've not looked into it deeply myself but if you have a look at the Releases API i think there would be some similarities there\n. Sounds good, but how about raising a separate issue and doing it on a new branch/PR so we can get this one over the line without any bigger changes\nim just reviewing this one now...\n. hey @devkhan it's looking pretty good and the integration tests run ok for me.  Only have 2 items of feedback:\n- The skipped integration test - we dont really want to have tests flagged as Skip as generally it indicates \"something wrong\" or needs to be addressed.  I think in this case, just remove the whole [IntegrationTest] attribute from that guy, and treat it like a helper method (eg like CreateTheWorld())\n- When creating the RepositoryContext items you should use the helper function to give them a timestamped name.  This way each time the test runs it has unique names for the repos, and has no chance of clashing with repos that might already exist (eg from a previously failed test run or anyting else).  So basically just change those 3 repo creations to use the helper function like this:\ncsharp\n_repos.Add(await _gitHub.CreateRepositoryContext(_orgName, new NewRepository(Helper.MakeNameWithTimestamp(\"migrationtest-repo1\"))\n. @devkhan sorry for the stuff around but can you get this up to date with master again please and we can merge it in?\n. This looks good now...  @shiftkey did you want to confirm you were happy with the \"raw\" byte array return or shall I just hit the button\nedit actually sorry it's showing merge conflicts, not sure if this is due to other PR's merged or there were still conflicts after your rebase \nSorry @devkhan can you rebase again? \n. I'm going to merge this in as it's been a long hard slog for you @devkhan!\nGood work on implementing a brand new API from scratch!\n\n. Noticed this issue was fixed in #1524. Hey @Anubhav10 thanks heaps for the contribution!  Ive done a first pass review and made several comments... Hopefully you don't think Im being overly picky!  This is a fantastic contribution and in general you've nailed all the key elements - eg standard and observable implementations, great unit and integration tests, added any new files to all the csproj projects and so on.  \nIn terms of the feedback ive commented - most are around tidy up things like whitespace and I also highlighted a couple of things around consistency in naming/doc - eg http vs https on API doc links, or using organizationName rather than org for the parameters.   I realize that there are already some instances of inconsistencies within octokit in these areas but I guess my approach is when adding new work to try to conform with the \"majority\" consistency, and then hopefully we will also start to tackle the minority items that are inconsistent.  You also seem to have made a couple of inadvertent edits to the csproj files around nuget package version and app.config binding redirects etc.\nTo address a couple of specific things:\n- Your comment about integration tests not running - it looks like you're setting \"octokit\" org in the test fixture, whereas you should be using a specific integration testing organization that you setup for yourself (accessed via the Helper class).  I made a more detailed comment in the location where this was being done\n- With unit tests, when there are parameters that are being checked for empty strings as well as null (eg Ensure.ArgumentNotNullOrEmptyString(organizationName)) you should add a unit test that verifies that.  So in your case, you've added the EnsuresNonNullArguments() unit test, but you could also add a EnsuresNonEmptyArguments() test that checks the exceptions are thrown when \"\" are passed in for the various arguments that shouldn't be allowed (such as the org name).  If you search the code base, there should be some other examples of that if you need to see.\n- Your [PleaseReview] comments about NotNull assertions on HookId are not required, as hookId being an int can never be null :grinning: \n. @shiftkey neither appveyor or travis builds seemed to fire on this one?  The fact this is a change about organization hooks and had the \"octokit\" organisation mentioned in integration tests, hopefully is just a co-incidence!  :grinning: \n. Hi @Norbo11 this PR was not completed and thus hasn't been merged. Looks good!  I've marked up a few grammar errors, broken links etc :grinning: \n. :shipit: \n. > One little thing that I don't have a good answer for is how multiple PRs can span a feature. But let's cross that bridge later.\nI guess you are referring to here to a large body of work (eg implementing your API Pagination changes) that is implemented via multiple PRs?  In some ways I wonder if just having each PR be listable is ok - eg \"Added pagination support to xxx client\"  \"added pagination support to yyy client\".  Is there a need to group these together?  \nif so some possibilities would be:\n- use more feature labels - like feature-pagination and then that allows you to further group the PRs under the features area, into higher level features (eg pagination in that case)\n- use a single issue for the parent feature and link to it in the multiple PRs\n- use an optional milestone to relate multiple PRs - if milestone is set you can group or consolidate PRs for that milestone into their own subsection (or single line item with comma separated PR numbers)\n. for anyone who hadnt seen: https://github.com/shiftkey/hermes\nI dont know if I want to tackle fsharp at this point though LOL so I may just contribute cerebrally :grinning: \nHaving a look at what @shiftkey has produced so far I think we could benefit from adding a new label (in addition to feature and bugfix) to group up all of the recent items around fixing inconsistencies and tidying things up - something like code quality as the label name\nI also think we can start \"decorating\" the PR's with the special comment to set what the release notes text for that PR should be, as the raw list is all over the shop :sob:.  Ideally we will do this as we go, but for this time around I'll go back to all the merged PR's and add it.  The tool will need to find the latest appropriate comment and use that text if found, rather than the PR title if on.\nAt this stage I think we should keep it simple and just have the comment match a regex like ^release_notes:\\W*(?<notes>.*)$ (using SingleLine option and taking the match group \"notes\")\n. Hey @shiftkey \nWhen using the \"own HttpClient method and the BrowserDownloadUrl this is the succesful HttpResponse when the repo is PUBLIC \n{StatusCode: 200, ReasonPhrase: 'OK', Version: 1.1, Content: System.Net.Http.StreamContent, Headers:\n{\n  Content-Security-Policy: default-src 'none'\n  Strict-Transport-Security: max-age=31557600\n  Timing-Allow-Origin: http://<server_address>\n  X-Content-Type-Options: nosniff\n  X-Frame-Options: deny\n  X-Github-Request-Id: 114fb5d2-e96f-11e5-8c5e-f83dbbbe5aa3\n  X-Xss-Protection: 1; mode=block\n  Date: Sun, 13 Mar 2016 22:58:14 GMT\n  ETag: \"9dbf6181186028788201b4be584f7972f02df99ccf4ad339108772b9f71bbda9\"\n  Server: GitHub.com\n  Content-Length: 530\n  Content-Disposition: attachment; filename=myfile.json\n  Content-Type: application/octet-stream\n  Last-Modified: Sun, 13 Mar 2016 12:34:49 GMT\n}}\n    Content: {System.Net.Http.StreamContent}\n    Headers: {Content-Security-Policy: default-src 'none'\nStrict-Transport-Security: max-age=31557600\nTiming-Allow-Origin: http://<server_address>\nX-Content-Type-Options: nosniff\nX-Frame-Options: deny\nX-Github-Request-Id: 114fb5d2-e96f-11e5-8c5e-f83dbbbe5aa3\nX-Xss-Protection: 1; mode=block\nDate: Sun, 13 Mar 2016 22:58:14 GMT\nETag: \"9dbf6181186028788201b4be584f7972f02df99ccf4ad339108772b9f71bbda9\"\nServer: GitHub.com\n}\n    IsSuccessStatusCode: true\n    ReasonPhrase: \"OK\"\n    RequestMessage: {Method: GET, RequestUri: 'http://<server_address>/storage/releases/1/files/2', Version: 1.1, Content: <null>, Headers:\n{\n  Authorization: token <my_personal_token>\n  Accept: application/octet-stream\n}}\n    StatusCode: OK\n    Version: {1.1}\nAnd this is the HttpResponse when repo is PRIVATE\n{StatusCode: 500, ReasonPhrase: 'Internal Server Error', Version: 1.1, Content: System.Net.Http.StreamContent, Headers:\n{\n  Status: 500 Internal Server Error\n  X-OAuth-Scopes: admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete_repo, gist, notifications, repo, user\n  X-Accepted-OAuth-Scopes: \n  X-GitHub-Media-Type: unknown\n  X-XSS-Protection: 1; mode=block\n  X-Frame-Options: deny\n  Content-Security-Policy: default-src 'none'\n  Access-Control-Allow-Credentials: true\n  Access-Control-Expose-Headers: ETag, Link, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval\n  Access-Control-Allow-Origin: *\n  X-GitHub-Request-Id: de978608-8e67-4e3b-9311-f3a9620df0c2\n  X-Content-Type-Options: nosniff\n  Date: Sun, 13 Mar 2016 22:59:51 GMT\n  Server: GitHub.com\n  Content-Length: 95\n  Content-Type: application/json; charset=utf-8\n}}\n    Content: {System.Net.Http.StreamContent}\n    Headers: {Status: 500 Internal Server Error\nX-OAuth-Scopes: admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete_repo, gist, notifications, repo, user\nX-Accepted-OAuth-Scopes: \nX-GitHub-Media-Type: unknown\nX-XSS-Protection: 1; mode=block\nX-Frame-Options: deny\nContent-Security-Policy: default-src 'none'\nAccess-Control-Allow-Credentials: true\nAccess-Control-Expose-Headers: ETag, Link, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval\nAccess-Control-Allow-Origin: *\nX-GitHub-Request-Id: de978608-8e67-4e3b-9311-f3a9620df0c2\nX-Content-Type-Options: nosniff\nDate: Sun, 13 Mar 2016 22:59:51 GMT\nServer: GitHub.com\n}\n    IsSuccessStatusCode: false\n    ReasonPhrase: \"Internal Server Error\"\n    RequestMessage: {Method: GET, RequestUri: 'http://<server_address>/api/v3/repos/Organization/RepoName/releases/assets/2', Version: 1.1, Content: <null>, Headers:\n{\n  Authorization: token <my_personal_token>\n  Accept: application/octet-stream\n}}\n    StatusCode: InternalServerError\n    Version: {1.1}\nIs that enough information?  This is just printing ?response in the immediate window.  I obfuscated a couple of things like server address, org/repo and access token...\nIf there is a better way to \"crack open\" the HttpResponse let me know what you meant :grinning:\n. Github enterprise 2.5.2 was released overnight and the release notes mention this \nhttps://enterprise.github.com/releases/2.5.2/notes\n\nDownloading a release asset from a private repository with the Releases API failed with an internal server error.\n\nSounds hopeful! I will retest and advise... \n. Updated my test GHE instance to 2.5.2 and verified that downloading release assets on private repositories now works fine.  \nIt works as expected using both approaches outlined in my first post - ie Octokit's Connection.Get<Byte[]>(assetUrl ...) on the Api URL and using a custom HttpRequest to hit the BrowserDownloadUrl)\nClosing out this issue!\n. Fixed in #1198\n. Fyi for anyone not aware of this github feature, if when you mention an issue in PR, you use words like \"fixes #1151\" or \"resolves #1151\" \"fixes #issue\" then the issue is automatically closed when PR merged. So including those words in your PR will avoid needing to manually close out issues \ud83d\ude01 \n. Fixed by #1321\n. Implemented in PR #1190 \n. Hi @prayankmathur , could I suggest that you reword the pull request title and description to contain a little bit more details about what it's about?\nYou certainly want to link to the issue #896 but also would be good to say a few words here about it so everyone doesnt have to click through to the issue to see what this PR is about.\neg something like this:\nTitle:\n\nImplement Lock/Unlock functionality for Issues\n\nDescription:\n\nThis PR implements the locking and unlocking funcitonality for Issues\nFixes #896\nAlso includes Unit and Integration Tests\n\nAlso from a quick look, this pull request includes your changes for ther other PR about ItemState/ItemStateFilter etc, which makes it hard to review the diffs in isolation.  Ideally you would either do the work on separate branches, or once one PR gets merged, you can merge master into your branch and we will then see the \"true\" differences in this PR\n. Just noting for reference that the status of this PR is\n- Waiting for #1140 to be merged and then have this PR's commits tidied up (due to this PR being built ontop of #1140)\n- Waiting on @prayankmathur to split out the test fix for UpdateIssue to another PR and remove the commit from this one\n. Yes you should rename it too.  In integration or unit tests, you are directly referencing the IObserableIssuesClient which might be what is throwing you off here...\nRemember that \"regular\" users of octokit will be accessing both the standard or observable clients, through the \"proper\" heierarchy\neg \n``` csharp\nvar client = new ObservableGitHubClient( ... );\nawait client.Issue.Lock(owner, name, 1);\n```\n. Also dont forget you've got merge conflicts so either merge master into your branch, or rebase your branch on master and force push\n. Looks like you're ontop of the test failures which is :+1: \nIve highlighted a couple of REALLY minor consistency issues around naming unit tests (now the methods have been renamed)\n. Regarding the actual implementation of Lock and Unlock methods (which are API PUT methods that return a 204 response on success) I suggest we should implement them similarly to  OrganizationMembers.Publicize()\nIn other words, check for that 204 response and return a Task<bool> to indicate success\n. > Also should I implement the Lock/Unlock methods as suggested by @ryangribble which would return \n\nTask\n\nYes please :grinning: @shiftkey also gave this a :+1: so we are in agreement that when the API docs mention a 204 response as success... you can check for that and return Task<bool> accordingly.  Link to existing example: OrganizationMembers.Publicize()\n. Hi @devkhan \nWe'll typically hold off from reviewing PR's until the CI builds are passing... You should be able to click through and see what caused the failures :grinning:\n. Hey @devkhan - nice pickup!  However, @shiftkey is actually already tackling a revamp of the CONTRIBUTOR doc in #1145 \n. Certainly, but it's definitely best to get one over the line before working on the next.l :grinning: \nInfact, I haven't yet started on #1024 which would be a higher priority IMO, if you wanted to knock off some of that coding :stuck_out_tongue_winking_eye: \n. Just a query regarding adding the additional overload to Connection.GetResponse() and changing the ApiOptions.None to a Singleton implementation.  \nSince these weren't in @shiftkey's example implementation I'm wondering whether they should be included here or not.  \nThere are already lots of overloads on GetResponse etc so we should only add them if absolutely necessary.  Im not sure if in this case it was necessary or just a convenience?\nSimilarly with the singleton for ApiOptions.None - performance improvement is surely negligible and not really a major concern.  The other point about unit testing... we have plenty of examples of Model classes that need to be compared in Unit Tests and some discussions have occured around implementing IEquality for Model classes or using extension/comparison methods etc.  Im not sure that the singleton approach for this one specific edge case (so that you can use object equality of options == ApiOptions.None) is worth it?\nI defer to @shiftkey for opinion on both matters, I am mainly coming at it from the point of \"if this is the first time we are introducing something\" it should be thought about in the context of the whole project and not just this PR\n. Ive reviewed the changes and it's looking pretty good!  \nMy \"consistency is king!\" OCD shone through a little though sorry :grinning:\nTo explain where that's coming from: on a code base such as this one, consistency and clarity are very important - they enable new contributors and users/consumers to more easily gain an understanding as to how octokit works.  There will often be a better or more efficient way to write test code - however if you're going to be the \"first instance\" of deviating from the general approach adhered to within a class/file (or in an ideal world even an APIclient or the whole codebase!), it should be intentional and communicated.  \nSo I guess what Im saying is, lets definitely try to keep consistency within the same file, if not the whole API client (and ideally code base!)\n. Thanks for going the extra mile to address my consistency nitpicks!\n\n. So given that theres a pretty massive gap between the ones that are 200+ days since obsoleted, and a bunch sitting at around the ~80-100 mark... we should be pretty safe to remove all the really old stuff?\n:fire: these\nSearchIssuesRequest ctor(term, owner, name) 241 days\nIRepositoryContentsClient.GetArchiveLink() 289 days\nIConnection.Get<T>(... allowAutoRedirect) 290 days\nITeamsClient.IsMember() 299 days\nRepository.SubscribersCount 378 days\nRepository.Organization 384 days\nIOrganizationMembersClient.GetAll(string org, string filter) 454 days \nApiUrls.Members() 454 days\nAnd keep the following for now\nISshKeysClient and associated SshKey class, helpers etc 29 days\nIAuthorizationsClient.RevokeAllApplicationAuthentications() 43 days\nGitHubClient.Release 82 days\nGitHubClient.GitDatabase 82 days\nIRepositoriesClient.CommitStatus 83 days\nApiConnection.GetRedirect() 98 days\nHappy with that approach for .20 release?\n. Im thinking that we should just :fire: the ApiConnection.GetRedirect() function, since it was the only place that was using that Get overload anyway.  I realise it was in my list to \"keep\" but at 110 days since obsolete, and given we are already removing the Connection related redirect flag (which isn't honoured anyway) I'm voting we sharpen the axe and just :fire: all 3 ?  \nApiConnection.GetRedirect()\nIConnection.Task<IApiResponse<T>> Get<T>(Uri uri, IDictionary<string, string> parameters, string accepts, bool allowAutoRedirect)\nConnection.Task<IApiResponse<T>> Get<T>(Uri uri, IDictionary<string, string> parameters, string accepts, bool allowAutoRedirect)\n. Great first contribution :clap: \nI agree with @shiftkey regarding adding verb for GetSha1() and the extra integration test (look around for other examples that use the repository context helper to create a repo for the test then automatically clean it up afterwards)... \nI've also raised one minor nitpick on consistency/wording in the tests \n. This looks good!  \nBut I noticed there are no Unit or Integration tests for the ObservableRepositoryCommitsClient.\nI realise this was like that before this PR... Some parts of the code base (particularly observable implementations) don't have tests around them, but as we touch these areas ideally we should start to correct that problem.  Without tests there really could be something lurking in there making the observable implementation not work and we dont want to find out from end users if possible!\nSo at a minimum, I'd like to see tests added for the Observable GetSha1() method that has been added... And ideally - tests for ALL the methods in this observable client could be added!  :grinning:\nIf you have a look at some existing examples of Observable client unit and integration tests you will find that the unit tests of observable would have a CallsIntoClient type test (that checks the underlying regular client method is called with appropriate args), as well as EnsuresNonNullArguments and EnsuresNonEmptyArguments tests as appropriate (depending on what parameters the call takes and whether they have checks for nulls/empty string).  Also a test for the Ctor guarding against a null client argument.\nIm not sure where @shiftkey stands on integration tests for observable clients - given that alot are missing, and it's pretty much only ever calling the regular client anyway... perhaps all we need are unit tests for observable clients... \nBut in my contributions I do typically add integration tests, I pretty much copy/paste the regular client test, modify it to use the observable client and also like to write it as per below, so it's obvious the item is an observable (eventhough you could simply await it inline).  This is just personal preference.\ncsharp\nvar observable = _fixture.GetSha1(x,x,x);\nvar sha1 = await observable;\n. Oops!  Looks like just a minor issue there with the \"NotNull\" test checking empty strings, and the \"NonEmpty\" test checking nulls!  If you can just fix that up we are good to go\nAlso given @shiftkey's comment let's ditch the integration test for the observable implementation, since it's just calling the real client anyway.  SORRY!\n. > I've learnt a lot about the codebase and how to contribute with this PR and you guys haven't scared me off either\nGreat to hear!  Bring on the next one, this one LGTM\n\n. Apart from fixing the mentioned issue, this commit also seems to have applied some whitespace/bracket reformatting across a number of files.  \nThis isn't necessarily a problem but I do like to see it explicitly mentioned in your PR comments, if you've done something like that, firstly to give an indication that it's a deliberate action on your part, and not some inadvertent/unintended action that you weren't even aware of... and secondly so that you can give your reasoning/justification as to how you made the change and why etc... (eg did you run something over the entire code base and these were the only files that weren't \"in spec\" or otherwise how come \"only\" ~20 files are affected?)\n. > @ryangribble I'm not going to stress about this too much. Thanks for being on top of it!\nAll good!  My approach with such \"off topic\" changes is I'll normally question them if the PR author didnt mention them themselves...  If they do mention it, then they aren't \"off topic\" anymore and thus no need to question!\nAnd yeah, I hadnt actually seen the FormatCode build command until I was poling around the other day too... perhaps it should be added to the contributors.md.  Not as a \"you must run this\" but more so as a \"if you want to, here it is\"\n. I agree it'd be nice to merge this in.  Obviously GitHub staffers will need to make the call about what email address to use (and whether we can use support@github.com for now)...  ping @shiftkey @Haacked . > I have one question about integration tests for (Observable)AuthorizationsClient. There are no any integration tests for these clients, so should I add it?\nMy vote is yes!  Ideally we want to have unit and integration tests for everything.  Some older stuff doesnt have that coverage, but the next time we touch something in that area, ideally we would also add the tests for that client, at a minimum implementing the tests for the methods you've touched (eg in this case the GetAll() method, but if time allows writing \"full\" tests for all of the methods in that Client would be great as it will increase our coverage\nSometime soon I'd like to write something that will highlight the clients/methods that dont have unit or integration test coverage, and raise issues in the repo for them to be implemented\n. Looking awesome now :grinning: And thanks for taking care of those additional tests on the previously implemented ApiOptions clients as well.\nGreat job @dampir!\n\n. > Tests for Linux (Mono) aren't passed for some reasons...\nUnfortunately there are some sporadic TravisCI failures... we are tracking them here: #1076 \nI kicked it off again and has passed now.  Thanks for your efforts in getting things nicely consistent in the codebase!\n\n. :+1: \n. > I'm a bit :-1: on the guard clause as-is but I'll sleep on it - or we can discuss it in a separate PR.\n\nYeah it was a bit clunky due to code analysis not allowing combining a Uri and string and also the StartsWith() needing to have StringCompareInfo set etc.\n\nI'm not a huge fan of the guard either... but given that we aren't running integration tests against github enterprise it pretty much means that we could break any \"normal\" call from working against GHE if we miss that innocuous leading slash when reviewing PRs.  \nOther things I considered were doing something in the FormatUri() extension method, or having a convention test that checked the endpoint Uris in ApiArls.cs helper class... but in both cases that didn't protect against a contribution that doesnt use the helper class or extension method (assuming we dont pull up the contributor in the PR and ask them to use the helper class and extension method).  \nThen we have the other situation of any consumers of octokit that are using the client.Connection.Get<T> etc methods, and passing in their own endpoint Uri.  Perhaps we dont need to \"stop\" them since they can fix their code (although whether they would know that the HTTP 406 is because the Uri fragments got eaten due to a leading slash, and not being able to easily debug right down into the guts of the octokit plumbing, it would lead to much hair pulling!!).\nBut yeah my main concern was the fact we can inadvertently break API methods from working on Enterprise and it doesnt get picked up in tests or at runtime.  We could throw an exception I guess (again, that's too late if we've shipped the release though!).  So that's how I came to the conclusion that there doesnt seem to be a reason NOT to trim leading slashes off.  The check that it isnt an AboluteUri is needed because when dealing with multple paginated calls, the subsequent requests have the full absolute Uri in the endpoint...\n. OK ive reverted the change in HttpClientAdapter for now, and will just push this PR in with the correction to the URI's\nWill raise a new issue for the \n\nscript out something so we can verify all these URIs are correctly formatted\n\npart...\n. :+1: \n. Pretty clear cut, may as well merge these ones quickly :grinning:\n. I just did a quick search through the code base and found a few properties of clients that are not singular \n```\n\\Octokit\\Clients\\IActivitiesClient.cs(14):    IEventsClient Events { get; }\n\\Octokit\\Clients\\IActivitiesClient.cs(29):    IFeedsClient Feeds { get; }\n\\Octokit\\Clients\\IActivitiesClient.cs(34):    INotificationsClient Notifications { get; }\n\\Octokit\\Clients\\IIssuesClient.cs(25):        IIssuesEventsClient Events { get; }\n\\Octokit\\Clients\\IIssuesClient.cs(35):        IIssuesLabelsClient Labels { get; }\n\\Octokit\\Clients\\IRepositoriesClient.cs(33):  IRepositoryCommentsClient RepositoryComments { get; }\n\\Octokit\\Clients\\IRepositoriesClient.cs(49):  IRepositoryDeployKeysClient DeployKeys { get; }\n\\Octokit\\Clients\\IRepositoriesClient.cs(215): IRepositoryHooksClient Hooks { get; }\n\\Octokit\\Clients\\IRepositoriesClient.cs(221): IRepositoryForksClient Forks { get; }\n\\Octokit\\Clients\\IUsersClient.cs(28):         IUserKeysClient Keys { get; }\n\\Octokit\\Clients\\IUsersClient.cs(59):         IFollowersClient Followers { get; }\n```\nThese 2 are also potenitally \"awkwardly\" named, although the property name does match the API doc, and im not sure if a \"better\" naming for these \"action\" based -ing words exists!\n\\Octokit\\Clients\\IActivitiesClient.cs(19):    IStarredClient Starring { get; }\n\\Octokit\\Clients\\IActivitiesClient.cs(24):    IWatchedClient Watching { get; }\n. It's very unfortunate because not even thinking about files where extra namespace levels were added due to folder path, we seem to have a real mix of unit and integration tests where some files have a namespace and others have none.  My OCD wants things to be consistent, particularly now it's been brought to attention (:trollface:) , but yeah im not sure if the code/indentation churn is worth it...\n\nI would also include adding a test to Conventions to the PR.\n\nPretty tough to do when there is inconsistency in the files.  Or are you saying the convention test would \"pass\" if there is no namespace OR a namespace matching project, and would only fail when a namespace was present that didn't match the project?\n. :+1: \n. Although, there are plenty of existing cases of naming class variables with the underscore, and its also as per the CoreFx coding style which @Haacked mentoned we are generally following...  \nMy take is, as long as the PR has made the class consistent (ie all cases of private members are using underscore notation) that it is OK and actually means we are standardising towards the coreFx standards.\nIn this case there is only 1 private variable so the change does look isolated but at the same time, it IS consistent (as the entire file is now using underscore notation).  Although the entire PR is not consistent because the regular client integration tests have 2 cases of local class variables which werent converted to underscore notation (only the reactive client tests were).  So personally I'd say I am happy with moving any instances to underscore notation where they exist, as long as all instances are done in the PR... but I dont presume to override @shiftkey's request :grinning: just proividing my 2 cents\nMy personal preference is to use the underscore, which is also something that resharper suggests, and as mentioned the coreFx coding style also defines.  Similar to that other discussion and blog post by @Haacked between string.Format and String.Format I think the conclusion was, no point fighting everyone over your personal preference - if we can just point to some other standard then it's generally a lot less effort :grinning: \nPerhaps if this change is reverted then we can have a meta discussion to talk about how seriously we adopt the CoreFx style or not etc?\n. > But I'd like these PRs to focus on adding the ApiOptions overloads wherever possible so I can get the release out as soon as possible. That's why I'm calling out coding style things in these PRs.\nMakes sense... I'll raise a meta discussion about coding styles for further deliberations :grinning:\n. Looks good now.  Yeah I realise often these little inconsistencies are already in the files, but whenever we are touching files I like to clean whatever we can up as we go :+1: \n. You know the answer's gonna be yes :grinning:  We always like moar tests\n\n. Ive made a couple of minor comments.  Also it seems like there are no unit tests for Observable client.\n\nAlso is there a way to check GetLatest returns the latest build, because i couldn't find a way.\n\nIm not too familiar with the Pages side of things, I'll have a look but it could be as  you say, no way to know if it's truly the latest or not.  As long as you are calling the right endpoint etc (as verified by unit tests) you have to trust the github api will return latest when we ask for it :grinning: \n. > Just rebased this due to a merge conflict. @ryangribble can I get a :thumbsup: here?\nGiven the tests are passing, I wasn't going to look too deeply, but I did notice that the title of commit and PR \"ensure observable method calls overload with ApiOptions\" isnt actually evident in the code changes - which are only tidying up whitespace formatting and changing the mock asertion to ANY dictionary rather than empty dictionary.\nIm assuming the actual change to call the correct overload was already in master, and the rebase is hiding that here?  Should the PR be reworded to \"tidy up/tweak test\" ?\n:+1: in any case as clearly things are working, so this is more just a wording excercise :grinning: \n. Looks OK to me and ive retried the travis build.  Will leave to @shiftkey to bring this one home since he had raised specific points \n. > one small item to draw attention to is this question\nAs per my reply on #1194 I suggest we should just :fire: the ApiExtensions.GetRedirect() method\n. Oops, it looks like there is one more reference in ApiConnection and IApiConnection with GetRedirect()\nThe problem is, the concrete implementation was made obsolete 111 days ago, but the interface member hasnt been marked obsolete at all! :sob: \nBut if we have to keep this, then it means we have to keep the ApiExtension one around as well, but that seems kinda pointless since the GetRedirect() will never actually get a HTTP 302 response anyway and thus will always throw an exception\n@shiftkey what do you reckon to :fire:ing IApiConnection.GetRedirect(), eventhough it wasnt marked obsolete?  Note that the concrete implementation, as well as multiple other places regarding Redirects and ArchiveLinks HAVE been obsolete for 100+ days\n. so @M-Zuber just chasing up on this one, I take it you are good to rebase to latest master and also tackle the redirect methods according to @shiftkey's comments\n. All good!  I love that feeling of cleaning things up :grinning: \n. \n. Looks good, we also normally have 2 unit test methods, to assert these (non null and non empty)  checks, have a look at other examples (sorry I'd link you one but on my phone \ud83d\ude00) \n. :+1: :+1: :+1: :+1: :+1: \n. Thanks for the feedback :+1: \nUnless Im missing something, I dont see anything in the API docs about being able to \"negate\" any of the other filter types though...\nThe only thing mentioned is labels (-label:labelname vs label:labelname) and keywords (specifying NOT fish instead of fish as the search term).\n\nHave a test that uses a label starting with a hyphen and exclude it\n\nWith the way it's been implemented the label name doesn't really matter.   I have a unit test that checks when 2 labels are specified in NotLabel we get the expected -label:label1 -label:label2 arguments.  Also I added an integration test that searches octokit.net repo for \"up-for-grabs\" labelled issues and a 2nd search for NOT \"up-for-grabs\" labelled issues, then checks to make sure the lists are unique\n. - rebased on latest master\n- renamed NotLabels to ExcludeLabels\n- I also tidied up an inconsistency that was irking me.  We refer to pull requests as PullRequest pretty much everywhere in octokit.net - except the IssueTypeQualifier.PR enum value.  So to maintain consistent naming and terminology, Ive added IssueTypeQualifier.PullRequest to that enum and flagged the PR value as [Obsolete] so it can be removed sometime down the track :smile: \n\nguess I just assumed the api was being dogfooded.\n\nIt could well be that the API accepts more options than the doco says, but for now Im thinking of just implementing what the doc says (where labels are the only things that can be excluded).  \nAlthough Im thinking perhaps for future proofing (If it does turn out that lots more fields can be negated or even the fact that it's likely in the future more fields would be able to be), I could perhaps move to having a new class to hold all the exclusions (and thus refer to them as normal names like Label).\ncsharp\nnew SearchIssuesRequest(\"fish\")\n{\n  Type = IssueTypeQualifier.PullRequest,\n  Is = IssueIsQualifier.Merged,\n  Exclusions = new SearchIssuesExclusions\n  {\n      Labels = new[] { \"label1\", \"label2\" },\n      Author = \"M-Zuber\" // Docs dont say this is supported but this is where more exclude fields could go if/when added\n  }\n}\nThoughts?  Is collecting any exclusions under a sub class, preferable to ending up with multiple properties like ExcludeLabels ExcludeAuthor ExcludeMentions ExcludeTeam and so on?\n. OK so ive just pushed up a change that has moved the exclusions fields out into a subclass, as discussed above.  So they are now accessed via SearchIssuesRequest.Exclusions\neg\n``` csharp\n    // Search for PullRequests that dont have \"skip-release-notes\" label\n    var request = new SearchIssuesRequest();\n    request.Type = IssueTypeQualifier.PullRequest;\n    request.Repos.Add(\"octokit\", \"octokit.net\");\n    request.Exclusions = new SearchIssuesRequestExclusions\n    {\n        Labels = new[] { \"skip-release-notes\" }\n    };\nvar pullRequests = await _gitHubClient.Search.SearchIssues(request);\n\n```\nRegarding which fields are supported, I did some poking at the API and determined that it actually does support quite a few fields in \"exclusion\" syntax, in addition to the mentioned \"label\" field.\nSo the following fields have been implemented in the Exceptions parameters:\n- Author, Assignee, Mentions, Commenter, Involves, State, Labels, Language, Status, Head, Base\n  These were all tested and work correctly - integration tests are added to assert this.\n  Although not mentioned in the docs (except Labels), these do seem useful (ie to search for items where Assignee is not me, or shiftkey is not mentioned etc)\nThe following fields were not implemented for exclusion for listed reasons:\n- Type,In,No,Is\n  These failed integration tests, API doesnt support negating these\n- Created,Updated,Merged,Closed,Comments\n  These date/range fields already support greater/less than and \"between\" syntax, so having an exclusion option doesnt really make sense so I didnt attempt to implement/test\n- Team\n  I didnt get time to find a suitable repo that has teams being @mentioned in issues, to run integration tests against\n- User\n  Not tested.\n  Does it make sense to do a search for something in all repos EXCEPT those owned by a user or organisation?\n- Repos\n  Not tested.\n  Does it make sense to do a search in all repos EXCEPT some specified?\nThoughts? \nWill definitely need some guidance from @Haacked and @shiftkey on this\nOn the one hand it seems prudent to only implement the mentioned label field for exclusion and \"dangerous\" to implement something that isnt listed in the API docs.  But on the other, being able to exclude by author, target branch etc have real life beneficial use cases, and the API clearly does support them (and the integration tests will detect if they ever cease to work)...\n. Cool... i didnt actually even test/probe those options to see whether api accepts excluding them or not... i will look into it since those use cases do sound reasonable\n. Hey @shiftkey just a reminder that I'm waiting on some input from your good self before I take any next steps :grinning: \nI know you've been on the road etc, hoping that since you've assigned this to yourself it is somewhere on your list to get to :crystal_ball: \n. Thanks @shiftkey ill tidy up those few things raised and rebase etc\nThere was also I guess 2 other things I just wanted a specific \ud83d\udc4d  from you on:\n\nI also tidied up an inconsistency that was irking me. We refer to pull requests as PullRequest pretty much everywhere in octokit.net - except the IssueTypeQualifier.PR enum value. So to maintain consistent naming and terminology, Ive added IssueTypeQualifier.PullRequest to that enum and flagged the PR value as [Obsolete] so it can be removed sometime down the track :smile:\n\nand\n\nSimilarly, the \"missing metadata\" search option, ive called the class property No to match the query property in API docs no, and gone with IssueNoMetadataQualifier as the enum name. Open to better suggestions...\n. All feedback addressed, merged latest master and bashed Travis until it finally got a green run! \n. Nice work! :+1: \n. Yep considering we aren't \"making\" people run the format code step, nor is there an easy way to enforce that, adding things to convention tests would be the preferred option \n. > It's weird that this is failing - the UpperCamelCase to upper_camel_case looks like it should work here but perhaps I'm missing something. Anyway, happy to take this in here...\n\nI think the capital H in \"GitHub\" was causing it to be looking for git_hub_services_sha rather than github_services_sha\nBut yeah in any case, it was null before this change, but is now populated correctly.  And it's a greeat example of why integration tests should check all fields and not just selected fields :grinning:\n. :+1: \n. Just wondering if you're aware you've got 2 separate github accounts involved here... @SamTheDev is what you're logged into github.com as, but all your commits are coming from @UsamTheDev :grinning: \n. not sure about being logged in from VS but its all down to the email address associated with the commits.  All I do is have a couple of email addresses (eg work and personal) both associated with my one github account and things work fine that way.  Im not sure in your situation with the added complexity of one of those email addresses already belonging to \"another\" github user (ie your 2econd account).  Perhaps if you change that account's email address first, then add both email addresses to your main account.  Alternatively, just change your VS settings so the email address is the right one and not worry about the historic commits (although its always nice to have all your commits against your own account so the contributors page is accurate!)\n. Useful info thanks. \nPerhaps we could treat it like obsoleting items where we remove things a number of releases after they are no longer supported/needed.  Eg we could decide the latest octokit will only support (for example) the last 2 GHE feature versions, and base such removals on that. \nAlthough I guess if there's no harm in sending them \"forever\" that gives the widest possible support with the least effort :grinning: \n. This is kinda interesting because if you look at the actual API response data it doesnt include any information about the repository that we even COULD populate into octokit.  There is a repository_url field, that is not currently deserialized into the octokit.net response models for Issue but then if you were happy to parse a URL field there are already plenty (Url, HtmlUrl, CommentsUrl, EventsUrl) to choose from...\nAlthough your suggestion makes sense from a usability point of view, it doesn't seem appropriate for octokit ~~to make multiple API calls behind the scenes~~ (edit: im not even sure there IS an api call that can tell you the repo an issue came from?!), nor do we want to \"invent\" fields on entities that arent actually returned from the API (@shiftkey will correct me if I'm wrong on this, as I do think we have a couple of calculated fields here and there...)\nThe Search API is the same - it doesn't include org or repo information on the returned issue responses.\nIt's weird when you think about it, since exactly as you've pointed out, whenever dealing with \"Issue\" objects, you no longer easily know where they came from!\nI guess at the moment I'd tend towards calling GetAllForOrganization() then parsing the repo from the Url or HtmlUrl field, rather than calling \"GetAllForRepository()\" on each of the 51 repos...\n. yeah maybe @shiftkey or @Haacked can escalate that one internally, though I guess any of us can also send github commentary/request like this externally too\nI agree with your sentitment although id say \"there is no ~~easy~~cringe-free way\" since parsing the url is \"easy\" just makes us cringe hehe :trollface: \n. Ah I should have thought about that as I encountered similar things (eg fields present in responses that aren't shown in the doco) like on GHE when ldap is enabled, user/org responses contain an ldap_dn field \nI reckon if it's in the json response we can put it in octokit. Worst case it ends up null if the field is ever not there anymore but it seems extremely unlikely that would happen?\n. So do you think it's feasible to essentially have our own copy of that md file, with our preferred tweaks, then reinforce it with convention tests? Eg it should be easy enough to have tests that make sure private visibility is not specified and variable names never contain underscores \n. > how can i make sure my test are passing? do i need to make a separate testing account for this?\n\nthanks.\n\n@Sarmad93 yeah you should create a test account because the integration tests do things like create repos and other things.  Generally they try to clean up after themselves where possible, but definitely you want a separate test account to do this under.\nRefer to the integration test sectino in Contributors Guide for information about how to run the tests (essentially there's a powershell script to help you define those environment variables)\n. Im not in a position to pull your code down and run it myself just now, but eyeballing your changes, yes that looks correct in specifying the accept header on the ApiConnection.Put<T> call.  The real test is whether your integration tests succeed, and the merged PR was squashed rather than merged!\nHowever on the unit test mock verification you shouldnt use AcceptHeaders.xxxxx there (instead hardcode the expected header string) - we want the unit test to independently verify the implementation code, so we dont want to \"share\" that AcceptHeaders helper between implementation and tests (otherwise a bug/typo in the helper class will still pass the unit test!).  Same way we manually check the Url that is called rather than use the ApiUrl helper method :grinning: \nRegarding the integration test assertion, is there also a way to verify the commitTitle specified was correctly applied?\n. Hey @Sarmad93, I'd definitely like to ensure these new GitHub features make it into the next octokit release so if time is an issue for you to get back onto this (totally understandable!) just let me know if you want someone to pick it up from here :grinning: \n. If you want to keep working on it you're more than welcome to! \nIt looks like you were at the point where we needed you to confirm your integration test settings...  Easiest way is just to close visual studio, rerun the powershell script and ensure they are all set correctly, then have another go at running integration tests\n. From my perspective this is :gem:! \nI've checked all the added Ctor tests are newing up the correct client :+1: very thorough and consistent! \nMy only comment is the way you locate the assembly by using EventsClientTests type. There's nothing special/significant about that type so I'd rather some alternative way of finding the assembly either by name or a more common/top level class or something like that \n. > I'll think a little bit and will try to deliver more common way. \nI wasn't aware this is how some other convention tests are doing it, they were before my involvement.  To me it would \"seem\" nicer to locate the assembly using the top level types like IGitHubClient IObservableGitHubClient and for tests GitHubClientTests rather than IEventsClient (what's so special about events client since it seems to be used EVERYWHERE in the convention tests @shiftkey ?? :grinning:)\nBut from the perspective that this is already being done elsewhere, I won't bikeshed over this!\n. Cool! I wonder whether we should change all the other Convention tests over to using those top level types too instead of EventsClient/ObservableEventsClient etc (perhaps in another PR, or perhaps on this one if it is reworded to \"Add convention test for Ctor constructor and tidy up other convention tests\"...\n. > as I found myself refactoring in some of the Enterprise API clients\nNot sure what you were referring to, I only saw the mentinoed async/await/ConfigureAwait(false) changes... But everything looks :+1: \n. ah cool, there was no reason to them I think at the time I didnt really realise that if you are just awaiting the call and returning it anyway, yuo can just remove the async and await and simply return the awaitable call.  There's only the odd few cases where we do something with the response before returning.\nAll changes on this PR look :+1: to me\n. Fixed by #1365\n. Nice pick up on the broken link, although your change is still linking to shiftkey/octokit.net fork rather than octokit/octokit.net ??\n. Just as an FYI I tried unskipping the tests originally skipped in #1374 (that issue was closed in favour of this issue)... and found that they are now passing.  Not sure if that is ALL the impacted tests that are being talked about here, or just some... \nSee https://github.com/octokit/octokit.net/pull/1539/commits/2f0ca4a09feeef20ebd2d14094d109fb435d1acd for the tests that have been unskipped. I've been digging into the Events/Activity area recently and found that #1490 fixed the problem that this issue was tracking, so closing it out. Replaced by #1310\n. @shiftkey this is another one where im pretty much waiting for you or @Haacked or someone \"official\" to provide some feedback/help, if you can add it to your list :grinning: \n. @shiftkey just a gentle reminder about this PR \ud83d\ude00  I know you've been travelling etc, I've been a bit preoccupied with some other things recently myself, but should be ready to get back into finishing off the enterprise api's now, pending advice/feedback on what I'd found with this PR\n. thanks for the comments.  Ill revisit this soon with those comments in mind and see what a fresh perspective brings.\nI think I've already got a branch somewhere where I at least used the serializer to build the JSON string but from memory I still couldnt get it to be accepted in the request body and had to go with the URLEncoded approach.\n. OK I think all comments have been addressed \nI've also changed the request object side of things so the structure matches what the API expects, and I can use SimpleJsonSerializer to build the json string.  \nThe usage is now new MaintenanceUpdate(new MaintenanceUpdateDetails(true, \"next tuesday at 5pm\")) - the nested class isn't ideal but that's how the API object needs to be (ie top level item name maintenance that then contains the enabled/when attributes).\nI still need to UrlFormEncode the request rather than have it in the request body, so Ive made a new class similar to RequestParameters that helps with this and can be used on future ones too (eg the management console settings API).  So at least it's now using a consistent/standard approach to generating the encoded parameters and using the SimpleJsonSerializer too\n. Rebased and assigned to @shiftkey for review :trollface: \n. There's a couple more places where you've accidentally referred to a class in the wrong assembly and thus not found the right client interface classes :grinning: \n. it's hard to review these changes, but Im grasping at straws to find anything major here \ud83d\ude00 \n. > I also took some time out in 1b2d009 to document the return values from the API. Let me know if you have any feedback on the words.\nI noticed you are using <seealso cref=\"\" when most other cases in the code base are using <see cref=\"\" - is there any reason for using one over the other?\nThe wording sounds reasonable although I wonder whether the effort involved to doc all return values is worth it, since they are pretty self evident... and it then sorta means we have to go and add them to allll the rest of the codebase.  I guess the same could be said for doccing most parameters in general though and if we didnt do it then we would have no doc anywhere.  Does this mean you intend us to start the process of docing return value on everything from now on?\n. LGTM! \n. Hi, \nThanks for reaching out... \nI haven't runtime tested this as I'm not at a computer currently, but if you have a look at the API docs for the search user call and the example json response, it doesn't return a full User object (with the properties you are wanting), it only appears to return a smaller subset of information. \nUnfortunately if you need those fields it looks like you'll need to load the full User using the User.Get() call, passing the login field from the search result. \n. The builds failed after recent rebase? \n. looks like OrganizationMembersFilter and OrganizationMembersRole are also missing\n. Hey @alfhenrik that's awesome! \nJust a heads up that some other related changes are occurring in #1335 (for creating and deleting the reactions)... For this issue you'd want to use the same ReactionType enum created there etc \n. @maddin2016 are you still planning on doing #1296 #1297 and #1298 ?\n. fixed by #1335 \n. Hi @ErikSchierboom, this one is actually implemented on PR #1335 which is about to be merged, sorry!\nBut there are some other \"Reactions\" related work not yet done, mostly the ones to include reaction information in the responses for Issues, PullRequestReviewComments etc\n1295, #1296, #1297 and #1298\n@alfhenrik has #1295 covered in PR #1341 , but the other 3 havent yet had any PRs pushed up...\nThere's also #1249 that hasn't been picked up yet, which looks quite interesting!\n. fixed by #1335 \n. @shiftkey I have a question over the proposed implementation of these reaction calls.  \nIn the github API docs, these all sit underneath a top level \"Reactions\" section... so wouldnt that mean for octokit.net we should be creating a new ReactionsClient with the various methods under that, rather than adding CreateReaction() methods under each of the Repository PullRequest, Commit, Comment etc clients?\n. That's what's getting me a bit unstuck though...  The delete method deletes ANY reaction, so it doesn't seem good to duplicate that on all the commit pull request issue issue comment etc clients. But having delete sitting out on it's own under a Reactions client isn't intuitive either. This is why I was questioning why we wouldn't just parallel the official documentation structure and have it all under \"Reactions\" client \nAre there precedents where octokit doesn't align with the API docs currently? There are plenty of things we could move around and group together that would make more sense but we haven't done so (i assume because that diverges from the API documentation layout) \nI'm really not phased either way I just like to clarify my own understanding of our guidelines/decisions to follow \n. fixed by #1335 \n. fixed by #1335 \n. Looks pretty good, although I didn't see integration tests that actually test the pagination... Is that because there isn't a suitable repo that has enough responses? \n. Yeah I saw the existing test was skipped, I guess I was just questioning whether there should still be the pagination test written, then also skipped? \nThe code changes look fine though so \ud83d\udc4d if you aren't concerned about the missing test \n. I'll have a proper thorough look at this on the weekend \nBut I just wanted to say that I'm wondering from a high level release management perspective, if it might be a good approach to get the ApiOptions pagination work finished first, then cut a new octokit release (as there a number of fixes/changes that would be good to get released), prior to embarking on the large changes to implement the repositoryID overloads.  I'm definitely not saying you shouldn't work on these but I'd be keen to get a release happening soon. Perhaps we don't need all ApiOptions done and perhaps it doesn't matter if some repositoryID changes are in that release either, although it also does seem clean to think that the next release would have all the ApiOptions pagination in it, then the next release all the repositoryID changes \n. Cool, nice find!  I'll review these tomorrow \n. Pesky travis!  All :gem: now, thanks!\n. \ud83d\udc4d \n. Cool looks good!\n. one other suggestion i have is that by using the commit status API and protected branches features, you can effectively \"stop\" PR's from being merged if the status checks havent passed.  You could potentially set a status check as pending that will never be passed, thus stopping the users from merging PRs on github.com web site.  Then you provide them with your own tool/script/webUI that will set the required commit status to PASS and then merge the PR for them (customising the merge commit message to your requirements in the process) \n. Yeah commit statuses and protected branches offer great flexibility from \"carrot\" based suggestions to \"stick\" based enforcement depending on individual teams/repos needs\n. Looking good, ive made a few comments.\nBUT the big thing that's bothering me is... if the underlynig github API appears to not actually support pagination for these methods, then we can't implement the ApiOptions overloads as it would give users the misconception that they could request paginated results.  \n@shiftkey might want to chime in on this, but my thoughts would be that we shouldnt implement this, until/unless it turns out to be a github API issue that is later resolved...\n. good pickup although I also see that variables inside the test are named hooksCount and so on, so probably should fix up those other copy/paste errors where \"hooks\" is used, at the same time?\n. So this is an inconsistency but not actually a \"problem\" currently right?  Because inside the Observable implementation it does pass the correct order of parameters through to the normal client.\nId be tempted to say that although inconsistencies are annoying, we shouldnt make a breaking change just to order the parameters in the observable client the same as the normal client...\n. This one doesn't require GitHub Enterprise (i take it you already realised that based on the strikethrough text)\nI recently pushed up #1342 which addresses #1319, but I haven't done anything on this issue yet, so feel free to take this if you want!\n. :gem: \n. Great work :+1: \n. :clap: \n. Have you got a github enterprise instance to run the integration tests against or would you like me to do that? \n. > Anyway, if there is exists an possibility to provide me test enterprise credentials for period of GSoC, I think that I could run and debug enterprise integration tests by myself :+1:\nGitHub Enterprise is a version of GitHub that an organization hosts on their own servers (either on prem or cloud).  They do have a free 45 day trial though, so potenitally you could spin one up if you have AWS or Azure credit, or enough hardware at home for the minimum spec (16GB RAM).  But it really isn't necessary\nI've pulled your stuff down and ran all the integration tests, you've just got one issue which ill highlight\n. I think it's ok creating the orgs, my test ghe instance already has a number of random organisations created from other tests I'd written previously... They don't really affect anything and anyone running integration tests on ghe should be using a dedicated  dev instance anyway \n. Hi @maddin2016 many thanks for your first contribution!  \nIn general everything looks pretty good.  I do have an outstanding query with @shiftkey on the corresponding issue #1302, regarding his proposed design/location of these reaction calls as it seemed like putting them under each section (comment, commit, pull request, issue section, etc) is not inline with the github API docs/structure which I thought was a general goal/rule in octokit,net to stay as close to the official API as possible.\nBut in the meantime while we wait for an answer, we can work through the changes you've submitted and I'll highlight a few minor consistency/nitpick type things to get you familiar with contributing to the project :+1: \nAlso as an FYI, when working on PR if you mention the magic words \"fixes #1302 in your PR body, then when we merge the PR it will automatically mark the issue as closed... so it's a good habit to get into :grinning: \n. Feel free to discuss any of the feedback if you don't agree!  I try to give detailed feedback around things, simply to get contributors into the groove of our approach/thinking.  Sometimes this may come across as critical but that's not the intention!  We appreciate all contributions and are very keen to work with you to ensure you have good experiences contributing to open source dotnet projects :grinning: \n. PS, with the \"fixed #1302\" tip i mentioned, even if you add that now (by editing your PR body) it will close the issue when the PR is merged.\n. ReactionType was my suggestion. That matches the terminology in API docs too... \nAlso the more we go through these specifics (request response types are common across all, there's only a single delete method for any reaction etc), the more I reckon it makes sense it all lives under a top level \"Reactions\" client. \nIf you're happy to do it, I'd love to see a PR providing that option so we can see how it feels \n. Well all PR's are experimental until they are merged or abandoned so feel free to raise a PR for whatever you want \n. :shipit: \n. I don't believe so... \nYou can download an archive of the entire repository at any specified reference (branch, commit, tag etc)  in zip or tar format, using the client.Repository.Content.GetArchive() calls, but that's a copy at a point in time, not the entire repo including history and commits etc. \nIf you want to do an actual git clone, I think you'd have to look into libgit2 or shell out to the git cmdline \n. thanks @dampir you are pumping these out in such a short time now! and so consistent :grinning: \n\n. Changes were only announced a few days ago so yeah, not implemented in octokit just yet! \ud83d\ude00 \nThese are the details of the API changes if it helps:\nhttps://developer.github.com/changes/2016-5-27-multiple-assignees/\nListing and creating and editing issues has new \"assignees\" parameter but there isn't any mention of the search API behaviour although you would hope it would now return an issue where the user was among the multiple assignees. \nYou need to set the custom accept header to enable the preview mode so hopefully once that's specified, the search query may work as you want. Otherwise you'd have to grab all (open?) issues then query over the assignees \n. yeah sorry if that was misleading, from my observations such features sit in \"preview\" for a looooong time, so we definitely look to expose the preview functionality in octokit.net as soon as we can :grinning: \n. Thanks for showing us a standalone reactions client implementation :+1:\nIn terms of \"Naming Things\" currently this has CreateReaction() and GetAll() methods which to me seems inconsistent...  Im thinking we should either use Create() and GetAll() or CreateReaction() and GetAllReactions()\nSo I guess to decide betweeen the this standalone API implementation vs h #1325 implementation, we can look at what the usage would be like:\n``` csharp\n// A\n// top level Reactions client, shorter names Create/GetAll\nclient.Reaction.Comment.Create()\nclient.Reaction.Comment.GetAll()\nclient.Reaction.Issue.Create()\nclient.Reaction.Issue.GetAll()\nclient.Reaction.Issue.Comment.Create()\nclient.Reaction.Issue.Comment.GetAll()\nclient.Reaction.Delete()\n// B\n// top level Reactions client, longer names Create/GetAll\nclient.Reaction.Comment.CreateReaction()\nclient.Reaction.Comment.GetAllReactions()\nclient.Reaction.Issue.CreateReaction()\nclient.Reaction.Issue.GetAllReactions()\nclient.Reaction.Issue.Comment.CreateReaction()\nclient.Reaction.Issue.Comment.GetAllReactions()\nclient.Reaction.Delete()\n// C\n// under each existing client, like #1325 implementation\nclient.Repository.Comment.CreateReaction()\nclient.Repository.Comment.GetAllReactions()\nclient.Repository.Issue.CreateReaction()\nclient.Repository.Issue.GetAllReactions()\nclient.Repository.Issue.Comment.CreateReaction()\nclient.Repository.Issue.Comment.GetAllReactions()\nclient.Reaction.Delete() // standalone delete method\n```\nWhich has a nicer feel to everybody?\n. also another thing is the GetAllReactions() method will probably need to implement the ApiOptions overload to support the pagination work that is almost complete\n. > @ryangribble do we really gain by having Issue.Comment and not IssueComment though? I see that that is how it's done on the Repository client, but since we are dealing with a small limited set of methods it might make sense for it to sit directly under Reactions.\nYep I wondered the same myself :)  Either would be fine\n. Ive labeled the 3 options A B C now - can you guys just clarify what you meant by first/second implementations?\n. Cool we shall go with A then\nIn terms of naming the actual clients, I think it should be singular on the \"entity\" and plural on the \"Reactions\" part.  eg CommitCommentReactionsClient IssueReactionsClient etc.  If people disagree and think it should be plural on both, that's OK... but at the moment there is inconsistency \neg:\nObservableCommitCommentReactionsClient (this has singular \"Comment\")\nCommitCommentsReactionsClient (this has plural \"Comments\")\nAlso just note this is the name of the class.  For the name of the variable we always do singular\neg\nclient.Reaction.IssueComment.Create()\n. > @ryangribble do you mean client.Reaction.CommitComment? Another suggestion client.Reaction.Commit.Comment. Same for client.Reaction.Issue.Comment. I think it should be more structured. e.g In future maybe it's possible to create reactions for commits. Then you have client.Reaction.CommitComment and client.Reaction.Commit. What do you think? Or i'm too picky :smile_cat:\nI do see the appeal of it being more structured but in this case my vote would be on not creating nested/empty clients that only contained subclients.  I dont think reactions would be likely at a commit level, and they will never be on a PullRequest object, since a PullRequest is an Issue in API terms, for things like comments/title/body... so the IssueReactions will already handle putting reactions on PRs...\nSo I would probably go this way:\ncsharp\nclient.Reaction.CommitComment.Create()\nclient.Reaction.CommitComment.GetAll()\nclient.Reaction.Issue.Create()\nclient.Reaction.Issue.GetAll()\nclient.Reaction.IssueComment.Create()\nclient.Reaction.IssueComment.GetAll()\nclient.Reaction.PullRequestReviewComment.Create()\nclient.Reaction.PullRequestReviewComment.GetAll()\nclient.Reaction.Delete()\nand in terms of class names\ncsharp\nI/(Observable)ReactionsClient\nI/(Observable)CommitCommentReactionsClient\nI/(Observable)IssueReactionsClient\nI/(Observable)IssueCommentReactionsClient\nI/(Observable)PullRequestReviewCommentReactionsClient\n. The Travis build failures are due to missing files? \n. This is looking really good, I think the only thing left is integration tests?\n. well, it's fun being on the \"bleeding edge\" !!!\nGitHub API changes blog today announced a change to the payload received when creation reactions...\ninstead of only the UserId in the response, they now inlcude a full User object in the response.  So we'll need to change that in Reaction.cs\n. @maddin2016 the new changes look good, you'll just need to merge or rebase on latest master after some other PR's were merged\n. 2 integration tests failed for me when creating comments on issues, need to use Number rather than Id field of Issue.  Ive also highlighted a couple of grammatical/typos in xml comments\n. No need to apologise!  :grinning: \nThere was actually a few more places I found, I sent a PR to your branch. Once that's merged I think we are :gem: and ready to merge!\n. I dont know what is up with TravisCI i've retried like 10 times and always gets the same error.  But it's not anything to do with this PR specifically since other PRs are getting the same error.  So either it's something that's been merged to master (pretty sure I havent merged anything that didnt pass all builds though) or else travis has some kind of consistent issue...  \nAny ideas @shiftkey ?\n. With the 0.20 release \ud83d\udea2 'ed and the travis issues resolved, it's finally time to merge this puppy!\nGood work @maddin2016 congratulations on your first major contribution!  It's been a bit of a drawn out one this time around but hopefully it's been a good experience \ud83d\udc4d \n\n. there's some weird/inconsistent test failures here... is it a similar case to what occured in #1169 where Args.ApiOptions is used instead of ApiOptions.None causing issues with parallel running unit tests?\nQuote from @shiftkey \n\nSo I don't know the full answer here for the runtime quirks when running tests but I can at least recommend we don't use Args.ApiOptions (the wrapper around NSubstitute's assert helper Arg.Any()) unless you're asserting, instead of ApiOptions.None (which is the Octokit model).\nNot sure if we need to do anything else here, but something to be mindful of...\n. These 2 new calls actually belong under the AssigneesClient(https://github.com/octokit/octokit.net/blob/master/Octokit/Clients/AssigneesClient.cs).  \n\nThe API documentation here shows existing calls like \"List Available Assignees\" and \"Check Assignees\" which are implemented in this client already, so now these 2 new preview methods \"Add assignees to issue\" and \"Remove assignees from issue\" have been added, they should be added to this AssignessClient as well, not to IssuesClient directly.\nI also am not sold on having a special IssueAssignees class that inherits Issue and adds the new Assignees property.  There are plenty of other examples where a particular field is on a response object and can sometimes be null depending on which API call was made or other factors... but we dont want to have too much split in the object model and have all these special objects that extend the base one and just add one field.  So I would suggest simpy adding the Assignees property to Issue model object.  \nThe new assignees field is also going to be returned on the \"Create an Issue\" and \"Edit an Issue\" calls on IssuesClient, and I'd actually be quite surprised if it also wasn't going to be returned on the \"List Issues\" and \"Get a single issue\" methods.  The API docs don't indicate they have the preview functionality at the moment but it could even be a missed API doc update... or perhaps they really dont return the new field now, but surely in the future it must be planned (why wouldnt you want to know multiple assignees details when listing issues?!).  Therefore if we include Assignees on the Issue object, we wont need to change anything in the future if thoe calls do start returning the info\nOn a side note, I've got some local changes done for the Create and Edit issue calls, I might send a pull request to your fork @maddin2016 and then you can pull them into this PR?\n. > I'd actually be quite surprised if it also wasn't going to be returned on the \"List Issues\" and \"Get a single issue\" methods\nOK so I just did some poking... I added Assignees field to the Issue model class, and added the new preview header to the IssuesClient.Get() and IssuesClient.GetAllForRepository() calls and the new field IS populated in the response object :tada:   So definitely go with including this on the base issue and we can also set the accepts header on the Get/List calls.  \ncsharp\nvar issue = await _issuesClient.Get(\"octokit\", \"octokit.net\", 1171);\n\n@shiftkey @paladique @shana could you possibly find out if an API docs update was missed for the Get and List issues calls supporting the new multiple assignees and taking the preview header?\n. Hey @maddin2016 looking good :+1: , I've marked up some comments.  \n1335 is the priority to get over the line first though...\n. The preview period for multiple assignees is over now, so I guess in this specific situation it's not an issue anymore \nIt's still a valid question though, but the idea of adding all those overloads to take string[] in what is already a large number of overloads etc, I'd say it should only be done when/where necessary, assuming it actually works \n. Agreed.  After chatting with @shiftkey we agreed to let my label changes go in, although as mentioned above,we want to add a RemoveLabel() helper function on IssueUpdate to remove a single label from the list, so users aren't ever needing to directly manipulate the list contents.  Are you ok to do that @maddin2016  ?. As far as the GitHub API is structured, PullRequests are the same as Issues regarding core concepts such as retrieving comments, assigning, labeling etc.  There is no separate API for PullRequests for these things, you actually just use the Issues API to do them for PullRequests too\nSo the good news is your change is already done.  The bad news is we STILL havent merged this, sorry!  I have xmas holidays after tomorrow and will definitely get ontop of the couple of PRs I need to review ;). @Eilon yes I see what you're saying although the github API docs don't show that field on pull request objects. It might be an undocumented case I guess we can poke github.com and see if the field is in the response \nIt's the same as labels and comments, eventhough they apply to PR's you get them from the issue call . As you say, the actual setting of multiple assignees can only be done via Issues API but at least the Assignees property is returned on PR's so we can add that field to PullRequest response class.  That is fine to be done on another PR to save making further changes on this one.  I'll do another/final review of this PR and look to merge it tonight. @maddin2016 are you able to tick the box to enable me to push commits into this PR?  I've done some testing of this and written a couple of integration tests and also found that a couple of changes were needed to actually make this work!. Thanks, Ive pushed up a few commits \n- added integration tests for IssueUpdate.Assignees usage\n- fixed issue where Assignees and Assignee can't both be specified on the request.  API docs indicate Assignee is deprecated, so I have [Obsoleted] this field, and stopped including it in Issue.ToUpdate()\n- I also ended up implementing the Assignees field on PullRequest response object since it was quick/easy\n@maddin2016 are you able to review my changes and confirm the integration tests are running for you?. Wow this has gotta be one of the longest PR's we've had in ages but I think we are finally done!\nThanks @maddin2016 we got there in the end \ud83d\ude01 \n. Yep, hope to have a new release out soon!  . Yeah naming things is hard (tm) :trollface: \nPerhaps this one in the response payloads could be called ReactionSummary since it has counts of each type and the a TotalCount etc.\n. Looking good... I guess we'll wait on #1335 for the AcceptHeaders value... \n. yep I was gonna say you could just add that here too, if you go by the same name as #1335 it wont be much of an issue\n. @alfhenrik #1335 is now merged so you can merge/rebase and update your accepts header usage whenever you're ready :+1:\n. This one is ready to merge in, can I get someone to :eyes: over this and :+1: if it looks alright?\n. Looks good!  I've made a few comments\n. sorry @alfhenrik , this just needs a rebase/merge due to some other PR's I merged (probably just AcceptHeaders.cs changes)\n. Cool, I just sent a PR to your branch to bring your GpgKeyContext class inline with the other context helpers we just tweaked\nalso found the integration tests you added were failing sometimes... turned out there was a missing await \n. \n. This is looking good, however it would be nice to have a class level variable in the tests to hold the repositoryId rather than having \"magic\" numbers 22718025 and 7528679 sprinkled throughout the tests?\n. although  I suppose it's no different to hardcoding the owner and name like the existing tests do... it just feels less intuitive when it's an int\nvar list = await _fixture.GetAll(\"octokit\", \"octokit.net\", request);\nvar list = await _fixture.GetAll(7528679, request);\nvar firstCommit = await _fixture.GetAll(\"shiftkey\", \"ReactiveGit\", startOptions);\nvar firstCommit = await _fixture.GetAll(22718025, startOptions);\n. This one is good to merge, once the empty <returns></returns> tags are removed :+1:\n. Actually, since the methods in this client already had empty <returns></returns> tags, I don't think this  needs to be addressed in this PR since you didn't clear the tags.  Another PR can clean this up\n. >  I'm still not satisfied with naming of TeamRepositoryUpdate. Any other suggestions?\nYou could go with AddTeamRepositoryRequest or RepositoryPermissionRequest or something like that...\nAlso it would be nice to specify the AcceptsHeader for this preview functionality, like I did on #1319 so that this functionality works on GHE 2.5 (before the preview period had ended).  This also would save the need to add the Put overload on Connection class etc at this time...\n. It would be good to add integration tests for the new parameter? \nYou can use repositorycontext and teamcontext helpers to create repo/teams for the test then they'll be removed when the test finishes \n. Yep that's on the right track... although what if the test user's organisation has no teams created?\nSimilar to the RepositoryContext There is also an (incorrectly named!) EnterpriseTeamContext helper that can create a team on the fly and then destroy it when it goes out of scope.  Using this would make the test more reliable and not require any specially configured test organisation.  \nAnother thing that I like to do in integration tests is not only assert the returned object from that update call, but actually make a \"Get\" call (in this case, something like client.Team.GetAllRepositories() and check the returned repository in there also indicates the permission level you requested was infact correctly applied.\nAs an aside, while you're at it you could rename that EnterpriseTeamContext class and helper method to TeamContext rather than EnterpriseTeamContext since they are not actually GitHub Enterprise specific... Im not sure why I named it that!\n. argh sorry @maddin2016 I gave you a bit of a bum steer on that TeamsContext thing, it actually is hardcoded to use EnterpriseHelper class under the covers which means it uses a different set of test environment variables etc.  Ive made some changes locally to rejig the integration test helpers so that they can be agnostic to whether github.com or github enterprise is being used.  Ill send a PR to your branch in a minute that will hopefully sort everything out! :grinning: \n. Congrats @maddin2016 on your first merged octokit Pull Request!\nWe really appreciate the contributions :grinning: \n\n. duplicate of #1350 \n. No reason for it to be missing...  just historical really,and evidently nobody has raised it/needed it until now \n. :+1: tested locally and confirmed the field is populated on Get of a single issue (not on list multiple issues though, but that is down to the API)\nJust waiting to get travisCI passing then ill merge this\n. release_notes: Added ClosedBy property to Issue response object\n. Looks good :+1: \n. Any missing properties are not likely to be intentional, more so just historic or accidental. \nWould you be happy to send a pull request that adds the property?\n. Great!  Let us know if you need any help :+1: \n. so what you've got there is actually a unit test, that is providing a hardcoded json framgent and testing the deserialisation logic only.  \nThis is great, but what @shiftkey was referring to was adding an integration test (a test that actually runs against github.com) to the MilestoneClientTests .  There is already a test there CanRetrieveOneMilestone that you could just add some more asserts to, to prove that your new fields are being returned correctly.\neg:\ncsharp\n// existing assert\nAssert.Equal(\"a milestone\", result.Title); \n// Add your asserts:\nAssert.Equal(\"xxxx\", result.HtmlUrl);\nAssert.Equal(\"xxxx\", result.LabelsUrl);\netc\nIn relation to your unit test, to check the value of the creator property you would just do something like Assert.Equal(\"shiftkey\", response.Body.Creator.Login); and so on\n. As general comments on this change, I'm :+1: for including useful fields like HtmlUrl UpdatedAt and even Id for a milestone (and various other objects/models)... \nbut I'm not sure about things like LabelsUrl.  Simply because those fields are API hypermedia links (eg in this case, the API url to get the labels for this milestone).  Since octokit already provides that information via interfaecs and clients (eg the IssuesLabelsClient.GetAllForMilestone() call), Im not sure we need to include this field on the Milestone object itself.  Or more to the point, if we do include LabelsUrl then we should include all the other xxxUrl fields (like events, starred, followers, following, gists, etc).  \n@shiftkey might have an opinion on this, but my 2c would be to remove LabelsUrl from this change...\n. Ive just commented on how to tet the Creator property in your tests.\nOther than that, you just need to update latest master into your branch and we should be good!\n. So looking at your fork of the repo, it seems you merged your change into the master branch in YOUR fork, and wherever you sent this PR from doesnt actually exist anymore (did you delete your fork and re-fork it or something?  Or just delete the branch it used to be on perhaps?).  Anyway, I think you're going to need to close this PR and recreate it, once youve moved your work to a suitable branch.  At least the work you did is not lost though!  :grinning: \nIm not sure how much you've already read or not, so dont be offended if Im telling you something you already know, but as a contributor you have a fork of this repo under your own user space (this is referred to as origin and then you have this main repository (referred to as upstream).  Your local clone on your system will already have an origin remote pointing at your fork, and you should add an upstream remote pointing here (if you haven't already).\nYou should never make any changes in your master branch, instead you need to Sync your fork with upstream to keep your master inline with master here.  \nTo do any work, you cut a branch from latest master, make your changes on that branch.  Always keep that branch up to date with master here (eg if we merge another PR before yours, you should pull master into your pending branch and your PR will update accordingly).  Eventually you send a PR from your fork/branch to the master branch here.  Only when that PR is merged should you then sync your master with upstream master (ie you should never push your changes into master on your side yourself, your master should only ever be synched with upstream/master\nIm not sure about Visual Studio git GUI specifically, it may make it possible for you to just deal with upstream/master directly, and not have to really worry about origin/master much at all.  When teaching people git I tend to encourage consistent initial use of the basic command line commands, to gain the underlying understanding of what is actually happening.  Then we move to GUIs - a religious and contentious space :)  My personal preference is SourceTree but there are many options - GitHub Desktop, Git Extensions, and even VS2015 as you've mentioned (just make sure you're on the very latest Update and also add the GitHub Extension for some nice sugar when dealing with GitHub).\nAnyway, what we need to do to fix you up is:\n- Add your upstream remote if you dont already have it\n- Move your changes to a branch and push it to your fork\n- Reset your origin/master to upstream/master and force push it to your fork\n- Ensure your branch is up to date with upstream/master\n- And then of course raise a new PR for this milestone work\nThen you should be :gem:\nOff the top of my head, these would be the commands to do this, forgive any typos/syntax errors :grinning:\n- Add your upstream remote if you dont already have it\ngit remote add upstream https://github.com/octokit/octokit.net.git\n- Move your changes to a branch and push it to your fork\n```\ngit checkout -b milestones-properties\nthis next command just ensures you are up to date with your own master\ngit pull origin master\ngit push origin milestones-properties\n``\n- Reset yourorigin/mastertoupstream/master`\ngit checkout master\ngit reset --hard upstream/master\ngit push -f origin master\n- Ensure your branch is up to date with upstream/master\n```\ngit checkout milestones-properties\ngit pull upstream master\nfix any merge issues etc\ngit push origin milestones-properties\n```\nThen you can raise the new PR\nHope that helps?\n. > If I look at the deployments API, the response does not contain any of the new information. Is that correct?\nTry changing the GetAll methods to also include the new preview Accepts header, it could be the documentation wasn't updated fully because normally the extra information is also returned in payloads when specifying the preview header\n. Yep! Sounds good \n. @ErikSchierboom it's looking pretty good :grinning:  There are a couple of failed convention tests if you check the build results, due to mutable properties (a couple of fields you added have a public setter rather than protected) which need to be tidied up.\nAnd other than that, it'd be really awesome to see the existing integration tests for Depoloyments and DeploymentStatus updated/added to ensure these new fields are functioning correctly against the real github API.  If you havent already set yourself up for integration tests, check the details in the CONTRIBUTING guide (namely, create a separate test account on github.com so you don't impact your real account, and use the provided powershell script to configure your integration test settings).\nLooks like there are already a range of integration tests so it could just be as simple as enhancing some of them to assert that key fields are actually populated rather than just Assert.NotNull(deployment) and so on\n. > except for the AutoInactive property which isn't returned by the API.\nJust to clarify this statement - are you saying this is an issue, or just meaning that it isnt meant to be returned (since it sounds like it''s more a field on the update request, not on an actual deployment or DeploymentStatus itself?)\n. Yep agreed, just wanted to clarify you meant that too :)\nIve done a final review and also pulled your branch and run the integration tests etc... \nThis is :gem: and ready to go... congratulations on your first octokit contribution!\n. \n. Some of the integration tests are failing for me, I think because you have hardcoded the RepositoryId to 252774 but since the tests are creating a repository on the fly I think you will need to use _context.Repository.Id\n. This one is good, apart from the <returns></returns> tags :+1:\n. :+1: thanks for this, I was scratching my head being unfamiliar with cross platform stuff\n. > Pending any feedback on the words \n- \"Add Migrations API for Enterprise instances\".\n  This is a bit ambiguous as the API does work on github.com and GHE.  Also this is a preview API so may as well mention that, since it's mentioned on various other items.\n  Suggest rewording to \"Add Migrations Preview API\" or \"Add Migrations Preview API for migrating repositories to GitHub Enterprise\"\n- The details on #1139 has via ryangribble but should be via @M-Zuber \n- Looking at #1139 again I think we also may have made a breaking change (renaming GetAll() to GetALlForCurrent without obsoleting the old metho?)\n- I also recall us having other changes where we [Obsoleted] stuff but I can't track them down at the moment!\n. > No tests to worry about here\nI can't remember why there aren't any integration tests with this change.  The commit history shows they were added but then reverted but I can't find any comment/discussion as to why.  Can someone jog my memory?\n. Yeah I know there were some cases (like the activity one requiring  user other than the one running the tests etc) but cant find mention of anything specific to the collaborators stuff.  Will wait for @dampir to advise\n. This one still has the empty <returns> tags, but once they're removed it should be good to merge.\nOn that note, if you are able to fixup those <returns> tags on ALL your PR's it will make it faster to get these merged\n. This one is good, except for the <returns></returns> tags\n. Looking good!  \n\n. \n. Great stuff @dampir I couldn't spot anything missed, I also pulled down your branch and ran all the integration tests succesfully.  You've also fixed up plenty of other things like missing integration tests for the existing owner/name methods and even fixed a couple of bugs with the old code too :+1:\n. \n. I'll let @shiftkey hit the button since he reviewed this one, but it looks good to me @Sarmad93\n. @Norbo11 no progress per se, this wasn't a list of things to implement as many of them aren't desired/required (due to being API url fields or previously deprecated fields etc). \nIt's great you've found one that should be added!  would you consider sending a PR to include it? \nThanks . I'm not sure what the actual reason is for that upstream API behaviour/design but I do see multiple references in the API docs saying that the push event is specifically different payload between the webhook and the events API \nhttps://developer.github.com/webhooks/#payloads\nhttps://developer.github.com/v3/activity/events/types/#pushevent\nI guess that confirms its expected behaviour but if you wanted your know WHY you could perhaps try contacting github support and asking? . How different are the response payloads?  Would be great if you could post an example commit json response from both cases so we can see how many fields aren't returned. \nYou're right in that generally we use the same model for the same thing (eg a PullRequest) eventhough some API responses (eg a GetAll type request) don't include all of the fields that are returned from a single object Get request.\nIt sounds reasonable to make this field nullable (and perhaps any others that are in the same boat) rather than splitting out a new object model, unless there are heaps of discrepancies . Hi @niltor,\nThere aren't any plans to add every extra field en-masse because some of them could be being deprecated and so on... \nBut certainly if anyone comes across a field that is provided by the API but not defined in octokit.net it can be added to the response models via a pull request. Is there a particular missing field you've encountered? . @devkhan looks like you need to adjust your tab settings as most files are showing whitespace/alignment issues\n. Also, @Sarmad93 has a PR at #1398 that is aiming to add this verification info to the Commit class as part of the Git Data => Commits client, so you should probably wait nutil #1398 is merged, then the accepts header and verification classes etc will already be there.  Then this PR just needs to set the preview header on the Repository commits calls and add the unit and integration tests etc.\n. Still got merge conflicts on this one, also dont forget about the tab/space issues :grinning:\n. It's weird though as this should have worked I thought...  Surely this isn't the first time we have an enum with an overriden value on a request message? \nMaybe it's [Parameter(Key=)] that is required, rather than [Parameter(Value=)]\nIt would be good to make that integration test loop through all enum values and \"create reaction\" for each one of them, that would have picked this up in the beginning. I thought we already did that, or at least made the integration test use the enum value that did have the custom override value, but perhaps I'm thinking of the \"Get reaction\" payload and not the create reaction one \n. > so maybe this is really the first time this happens or i'm wrong :confused:\nSo there are a fair few other occurences of Enum's on request classes that have [Parameter(Value = \"xxx\")] attribute.  Did you want to test these through the serializer to see if they also have the problem?\nHere's a couple but there are more than these\nMilestoneSort.DueDate\nSortDirection.Ascending\nSortDirection.Descending\nDeployTask.DeployMigrations\nPullRequestSort.LongRunning\n. Although the ParametersDictionary approach does fix things, I guess my thoughts are that since a change is needed in SimpleJsonSerializer on the Deserialize side anyway, we may as well also fix it in the Serialize side.  But I don't think it's necessary to write that logic yourself, as there is a .ToParameter() extension method in EnumExtensionMethods that already handles retrieving the custom parameter if present, otherwise uses lowercase string.  So something like this works, and then we dont need NewReaction to inherit RequestParameters:\ncsharp\nprotected override object SerializeEnum(Enum p)\n{\n    return p.ToParameter();\n}\n. Yeah I ran into this myself yesterday.  Unfortunately looking at the API docs example shows that the GitHub API really only returns a couple of Url's (Html, Diff, Patch) for the Pull Request, and not the entire object which would indeed be handy.\nIn my case I ended up using the Search Issue API to get a list of PRs for a specific repo that were merged in a specific date range, THEN i fired off concurrent async calls to load those subset of PR's individually.  This still turned out to be much faster than loading all PRs for the repo with the single PullRequest.GetAllForRepository() call (as under the covers, that pages through multiple results).  Also the GetAll call will get slower as the repository grows, whereas the search + parallel PR load is a bit more constrained since the commit (date) ranges (in our case at least) are for only a handful of 2 week iterations rather than the entire repository so it doesnt get that much worse on larger repositories, and then the actual number of PRs we have to load are a much smaller number and again, not going to be AS impacted by growing repository.  Plus running them in parallel helps with speeding them up :grinning: \nI also get the commits of each PR, the comments of each PR and the merge commit of each PR.  These all require separate calls as well, but doing it in parallel takes the edge off.  It ends up taking a few seconds to get all of the above information (which we use to create release notes).\nI can post some example code if it's helpful\n. > sharing models\nDo you think we should have some cut down models named something like PullRequestStub or IssuePullRequestInfo for these cases?\n. Thanks @Haacked , i've just pushed a couple of commits to this branch to suppress the code analysis rule violation that failed the build, and also tidied up the ctor doc and getting-started example.\nOnce the builds are passing i'll merge this in\n. Looking good!  For consistency, it would be great if you could add an integration test that tests all reaction types, to the original IssueComment reaction payload work that was done on previous PR?  :grinning: \n. Yeah I reckon replacing that test with your one that creates a repo/issue/comment, then adds each reaction type today it, then retrieves them and checks the fields \n. There are still some failing unit tests with missing preview header.  Also I noticed a couple of new repositoryId based calls from other merged PRs now also needed the preview header applied.\nIf you cherry pick this commit https://github.com/TattsGroup/octokit.net/commit/1185da2bdd670246e54759638d406fed9317d12a it should hopefully get everything green :+1: \n. ~~And here is a commit showing what I meant with tidying up the reaction payloads tests, handling Get and GetAll methods and covering all reaction types:~~\nhttps://github.com/TattsGroup/octokit.net/commit/e319f0ea056ca190f56e09c2ebb5943502c7fc01\n~~Something like this could be done for the other 3 clients (Issues, PullRequestReviewComments, CommitComments)~~\nActually ive almost got all of them done, Ill send a PR to your branch :grinning: \n. Not sure what you mean as the PR merged ok?  \nAnyway hopefully it's all good now. Can you run the new integration tests to confirm they work for you? \n. woohoo!\n\n. Yep I was about to post this too \ud83d\ude00\nPretty major changes, as previously all protection settings were done via 1 object and the single \"update branch\" endpoint,  whereas now protection is pulled apart into various sub components (enabled,  required contexts, user/team push restrictions)  but overall a much better approach  for the feature :+1:\n. For complete coverage of all the new API endpoints we will need to add 40 methods!\nGiven that some are only a \"convenience\" (since you can manage everything with the top level endpoints anyway), this issue will cover implementing the following top level methods:\ncsharp\n        Task<BranchProtectionSettings> GetBranchProtection(string owner, string name, string branch);\n        Task<BranchProtectionSettings> GetBranchProtection(int repositoryId, string branch);\n        Task<BranchProtectionSettings> UpdateBranchProtection(string owner, string name, string branch, BranchProtectionSettingsUpdate update);\n        Task<BranchProtectionSettings> UpdateBranchProtection(int repositoryId, string branch, BranchProtectionSettingsUpdate update);\n        Task<bool> DeleteBranchProtection(string owner, string name, string branch);\n        Task<bool> DeleteBranchProtection(int repositoryId, string branch);\nAnd the remainder will be moved to new issues\n``` csharp\n        Task GetRequiredStatusChecks(string owner, string name, string branch);\n        Task GetRequiredStatusChecks(int repositoryId, string branch);\n        Task UpdateRequiredStatusChecks(string owner, string name, string branch, BranchProtectionRequiredStatusChecks update);\n        Task UpdateRequiredStatusChecks(int repositoryId, string branch, BranchProtectionRequiredStatusChecks update);\n        Task DeleteRequiredStatusChecks(string owner, string name, string branch);\n        Task DeleteRequiredStatusChecks(int repositoryId, string branch);\n    Task<IReadOnlyList<string>> GetRequiredStatusCheckContexts(string owner, string name, string branch);\n    Task<IReadOnlyList<string>> GetRequiredStatusCheckContexts(int repositoryId, string branch);\n    Task<IReadOnlyList<string>> UpdateRequiredStatusCheckContexts(string owner, string name, string branch, IReadOnlyList<string> contexts);\n    Task<IReadOnlyList<string>> UpdateRequiredStatusCheckContexts(int repositoryId, string branch, IReadOnlyList<string> contexts);\n    Task<IReadOnlyList<string>> AddRequiredStatusCheckContext(string owner, string name, string branch, string context);\n    Task<IReadOnlyList<string>> AddRequiredStatusCheckContext(int repositoryId, string branch, string context);\n    Task<IReadOnlyList<string>> DeleteRequiredStatusCheckContext(string owner, string name, string branch, string context);\n    Task<IReadOnlyList<string>> DeleteRequiredStatusCheckContext(int repositoryId, string branch, string context);\n\n    Task<ProtectedBranchRestrictions> GetProtectedBranchRestrictions(string owner, string name, string branch);\n    Task<ProtectedBranchRestrictions> GetProtectedBranchRestrictions(int repositoryId, string branch);\n    Task<bool> DeleteProtectedBranchRestrictions(string owner, string name, string branch);\n    Task<bool> DeleteProtectedBranchRestrictions(int repositoryId, string branch);\n\n    Task<IReadOnlyList<Team>> GetProtectedBranchTeamRestrictions(string owner, string name, string branch);\n    Task<IReadOnlyList<Team>> GetProtectedBranchTeamRestrictions(int repositoryId, string branch);\n    Task<IReadOnlyList<Team>> SetProtectedBranchTeamRestrictions(string owner, string name, string branch, IReadOnlyList<string> teams);\n    Task<IReadOnlyList<Team>> SetProtectedBranchTeamRestrictions(int repositoryId, string branch, IReadOnlyList<string> teams);\n    Task<IReadOnlyList<Team>> AddProtectedBranchTeamRestriction(string owner, string name, string branch, string team);\n    Task<IReadOnlyList<Team>> AddProtectedBranchTeamRestriction(int repositoryId, string branch, string team);\n    Task<IReadOnlyList<Team>> DeleteProtectedBranchTeamRestriction(string owner, string name, string branch);\n    Task<IReadOnlyList<Team>> DeleteProtectedBranchTeamRestriction(int repositoryId, string branch);\n\n    Task<IReadOnlyList<User>> GetProtectedBranchUserRestrictions(string owner, string name, string branch);\n    Task<IReadOnlyList<User>> GetProtectedBranchUserRestrictions(int repositoryId, string branch);\n    Task<IReadOnlyList<User>> SetProtectedBranchUserRestrictions(string owner, string name, string branch, IReadOnlyList<string> users);\n    Task<IReadOnlyList<User>> SetProtectedBranchUserRestrictions(int repositoryId, string branch, IReadOnlyList<string> users);\n    Task<IReadOnlyList<User>> AddProtectedBranchUserRestriction(string owner, string name, string branch, string user);\n    Task<IReadOnlyList<User>> AddProtectedBranchUserRestriction(int repositoryId, string branch, string user);\n    Task<IReadOnlyList<User>> DeleteProtectedBranchUserRestriction(string owner, string name, string branch);\n    Task<IReadOnlyList<User>> DeleteProtectedBranchUserRestriction(int repositoryId, string branch);\n\n``\n. We often have inconsistent travis failures on linux and/or OSX. I've restarted them to see if they pass this time, but it would be good for someone who knows that ecosystem to figure out the root cause and if there's something we can do to avoid the failures.  We were tracking them here #1076 \n. Build is failing convention tests due to missing unit test class forTheCtorinRepositoryInvitationsClientTests.cs`\n. Nice work @maddin2016 !  :grinning:  I've made a few comments on various diffs, and also have some overall comments:\nAPI Calls that return no payload\nWith the calls that dont return a payload, you'll note the API docs do actually indicate that a \"success\" is a Http 204 (NoContent).  So that means we can actually implement these calls (Accept, Decline, Delete) return a Task<bool> and then you can actually get the HttpStatusCode and return true or false accordingly.  There are several examples of this in the code base already, one such example is TeamsClient.RemoveMembership() if you want to take a look at how it's done\nXmlDoc comments\nThere are some cases where the XmlDoc comments are not consistent or mention incorrect return types.  I realise some of this is because the comment you may have copied was, itself, incorrect, but we should aim to have correct comments at leats for new work we are adding.  So instead of IReadOnlyPagedCollection you should be saying IReadonlyList or whatever the actual return type is.  Also we have been discussing the <returns> doc tags and came to the decision that unless something specific needs to be called out about the function, it isn't really adding any benefit to document \"the obvious\" eg \"returns a collection of repository invites\".  So you also have the option to completely remove <returns> tag from any functions where it is not adding value by having it :+1:\n. There is some inconsistency with variable naming for the invitation Id (id on the Accept/Decline endpoints, but invitationId on the GetAll endpoints).  It would be good to have consistent naming for this - either always id or always invitationId\nThe <returns> tags still have some tweaks required to be correct/useful - I'd actually suggest just completely removing the entire <returns>xxxx</returns> doc comment, since they really aren't adding any value by repeating what the function return value is anyway\n. It seems like it timed out on a build step.  I dont have AppVeyor access so unless you have another commit to push we will need to wait for @shiftkey to give it a kick\nSo earlier you mentioned you had issues where the invitation email was never received.  Is that still the case or is everything working now?\n. So Im running the integration tests from my test account, invitnig my real account and i get no email and no notification on github about being invited.  yet if i explicitly visit the HtmlUrl property in the response then it does say ive been invited and i can accept/decline.\nYet when i interactively use my test account and invite my real account to a repo, i get an email and the github notifications section shows it there... :confused:\nThis is all on a personal account of my tes repo.  I guess given that comment in api docs about organization repos, we should see if anything is different when using the test user's organization rather than personal repo\n. Also confirming that yes the permissions only applies to organization repos.  so probably should update the Xml doc comments on the parameter to the Invite() method to specify that\nPersonal repo\n\nOrg repo\n\nBut still doesnt explain why the email and github notifications arent received for invites done through the API preview (but they are actually created as evidenced by the invite link working for the invitee, and the collaborators section showing the pending invite from the inviters side)\nI also tested with the integration test using an organization repository - same situation - my account shows no notification and i get no email, but the invite IS actually in the system\n. Oh nice, you decided to tackle #1101 while you're in this area? Thanks! \nOn the topic of the email/notifications not occuring, I contacted github support and they confirm they can reproduce it, they are logging an internal issue, so we shouldn't need to worry about that aspect at least \n. Nice work on the overloads for Add() and Invite() to make the permissions parameter optional, since it doest apply to non organization repositories :+1:\nLooking at that though, since #1387 added an overload to the Add() method that takes repositoryId rather than owner and repositoryName parameters, we probably need the same on the new Invite() method (as long as it does actually work).\n. Also as part of the repositoryId work, @dampir was trying to be consistent with always using name for the repositoryName parameter rather than previously a mix of name repo repoName repositoryName etc\nSo since he standardised on name, are you able to change repo to name in your Add() method?\n. > Anything more to do?\nIntegration tests for Delete() and Edit() ?\n. Also it seems with the existing integration tests you are inviting YOURSELF to a test repository you created.  And this actually seems to work, with the invite showing up in the system.\nSo given it seems to work to invite yourself, then you probably CAN have tests for Accept() and Decline()  ?\n. > Unfortunately not. I always catch an NotFoundexception if try to decline and accept with the same account. I have tested it with different accounts. There i can accept and decline the invitiations.\nIt seems to work for me?  Eg this passes:\n``` csharp\n        [IntegrationTest]\n        public async Task CanDeclineInvitation()\n        {\n            var github = Helper.GetAuthenticatedClient();\n            var repoName = Helper.MakeNameWithTimestamp(\"public-repo\");\n        using (var context = await github.CreateRepositoryContext(new NewRepository(repoName)))\n        {\n            var fixture = github.Repository.Collaborator;\n            var permission = new CollaboratorRequest(Permission.Push);\n\n            // invite a collaborator\n            var response = await fixture.Invite(context.RepositoryOwner, context.RepositoryName, context.RepositoryOwner, permission);\n\n            Assert.Equal(context.RepositoryOwner, response.Invitee.Login);\n            Assert.Equal(InvitationPermissionType.Write, response.Permissions);\n\n            // Decline the invitation\n            var declined = await github.Repository.Invitation.Decline(response.Id);\n\n            Assert.True(declined);\n        }\n    }\n\n```\n. :+1: write them and I'll check them my side. What error do you get? \n. Your test works fine on my side :+1: \n\nSo if you can also add an \"Accept\" invitation integration test I will double check that too and then I think we are good!\nNot sure what might be the issue with your 404?  I guess it means the invitation doesnt exist but its strange, in my case I can even login to github with my test account and see the invitation etc.  And there's nothing special about my test account, its just a free account. :confused: \n. Yep. that Accept test works for me too.\n\nMaybe someone third should test it.\n\nYep probably a good idea\n. Hey @maddin2016 I was pondering why accepting/declining a self invite might work for me and not you... one thing that came to mind is that I currently have my integration test configuration setup to use username and password only (i.e I have not specified an apikey/personal access token in the environment vars).  How have you got yours setup?  If you have an access token defined, try not specifying one, just to see if that makes any difference.\n. Nice one!\nOK so I reckon this is good to :ship: but let's get a :+1: from @shiftkey first\n. \n. Just a quick update on\n\nOn the topic of the email/notifications not occuring, I contacted github support and they confirm they can reproduce it, they are logging an internal issue, so we shouldn't need to worry about that aspect at least\n\nGitHub support notified me recently that they had pushed a fix for this, and I can confirm that emails are now being received when creating invites with octokit :+1: \n. I have just been troubleshooting a problem with the GitHub Enterprise management console stuff I'm implementing at the moment, where I was getting hanging tasks in my integration tests... it turns out it's the same problem you are fixing here!  :grinning: (management console uses redirects which as we've seen seems to trigger this behaviour).\nThe good news is, with your fix in place (modified a bit) I no longer get the deadlock :grinning:\nYour code changes were pretty hard to diff due to moving the functions around in the file.  I actually re-organised it so the GetSuccessfulResponse and CopyRequest functions were last in the class, which then made the diff line up much nicer and revealed only a few lines of difference.  This let me spot a few places where you are not doing exactly what the old code did which I've highlighted in the review comments.  \nI fixed these locally, plus fixed up a few async/await type issues and renamed GetSuccessfulResponse to SendAsync and everything is working :gem: for me now with the problem I was facing.  I added what I ended up with to this gist if you wanted to see\nThere is still the matter of other failed unit tests around redirects and so on to tackle though...\n. Yeah I dont think we want to add these properties to IResponse just so we can \"test\" what request was used.\nI had a go at re-jigging the tests with the new redirect handling like you've got in this PR.  I found that inside the redirect method, I had to pre-save off the original request's content so it could be later added to the request for the redirected Url, as by that stage a Object has been disposed exception was thrown when trying to access the original request's content directly.  With this change, and some modifications to the test/mocks I was able to get all the tests passing, except for the Assert that tries to verify that same field (response.RequestMessage.Content).  If you wanted to take a look at what I did, the commit is here: https://github.com/TattsGroup/octokit.net/commit/c6f6654b87a1c1f6a66c5f99e1cd1654e10dc288\n. From memory the main issue i found with these changes was that you can no longer \"reach in\" and access the original request message (response.Request. Content)  as it's been disposed. \nI'm not sure if anything really needs to do this (it was only the integration test that was doing it in our code) \n. Hey so I pulled these changes down and was going through things one final time and I decided to unskip the failing test from #874 now that we \"should\" be handling redirects properly.  And unfortunately it failed :rage:   The problem was something related to the way I had saved off the content stream from the original request, and the new content still had a reference to that old stream.\nSo anyway, I did some more digging and have come up with a revised implementation that doesn't have issues with content streams and looks tidier too.  With this fix all the existing tests are passing and unskipping the one from #874 now works too :+1:\nThe commit is https://github.com/TattsGroup/octokit.net/commit/168ea4133080575ea41e3b7d84edaf3fe4ef57c6, if you wanted to cherrypick it @maddin2016 and take a look?\n. That's the whole problem, you can't get the content stream ad it's been disposed \n. @maddin2016 were you happy with that change? Can you confirm all the related integration tests are working for you, including the one I unskipped? \n. Awesome stuff, I'll merge this in then\n. Thanks @maddin2016 \n\n. Can you please post your example code here or in a gist or repo?\n. someone mentioned something on gitter chat that there may have been some changes to Api rate limits from memory.\nHave you tried passing an ApiOptions to the GetAll call and specifying a high records per page size to override whatever the default is?  That way if the default was changed to something lower, but it still allows you to request more per page, you might be OK.\nIn general I was bumping up against some of the same types of issues, where as repositories grow older/larger, our query performance (mainly around generating release notes between any 2 arbitrary points) started to suffer.  I was able to make some efficiency improvements with some of my queries (eg instead of loading all PR's for the repo I used the issue search API to find issues of type PR that are merged between the commit timestamps of the from/to commits I wanted release notes for) and then load those ones with individual  Get calls but in parallel... this scales much better in a repo with growing numbers of PRs.\nSo in your particular use case, what is the outcome you are trying to achieve?  There may be ways we can suggest to make your code more scalable as repositories grow larger, rather than always retrieving every single issue event since the beginning of time.  \nEg another thing I do for my release notes I need to know the merge commit of the PR's, which you can only find from the \"merge\" event.  Originally I used to get all issue event for the whole repo, but this grew too slow (i didnt run into your issue, just really lengthy query times) so with the above optimisations I now only run this query for the singular issues (PRs) i know i am interested in and by using Tasks to run things in parallel, achieved a pretty scalable query that is only affected by the number of PRs in a release, rather than the size of the repo\nOr if you are using the issue events to know \"what is happening\" in the repo, then you could instead configure webhooks to hit your service so you get told of each event as it happens, and can process them in the singular context rather than \"all events for the whole repo\"\nHere's a gist showing the approach I mentioned - using parallel tasks to load a smaller set of individual Get calls, rather than using GetAll calls. https://gist.github.com/ryangribble/c91ea7ca54cff6907a5c2cb8025f3579\n. :shipit: \n. Whether in conjunction with this or not, i'd also like to look at moving the builds over to CAKE rather than FAKE...\n. No, nothing blocking it... it looks like all the dependencies are supporting dotnet core now \n. IM happy with the approach suggested by @mderriey in getting the main 3 projects going on netstandard 1.1 first then looking at what to do next.  I'm also :+1: to the Rx approach of the capability based #ifdefs. Hi @DamianEdwards ,  @mderriey is doing most of this work and I've been changing our build script over from FAKE to CAKE. \nAs time goes on i think its more and more likely we do jump onto the \"new\" csproj project system. Last I heard there were still problems with the tests/explorer in vs2017 but things change so quickly that may be old info?\nWe'll certainly take your advice on the system.net.http stuff \ud83d\udc4d\nThe main outstanding thing for me in terms of actually getting this dnx build out there is that we previously do source linking in the pdb files and it hasn't seemed that any of the available options (sourcelink gitlink etc) are yet supporting dotnet core projects most of them were also not bothering with project.json and waiting till the new csproj format.  This reminds me I need to go and look at where those guys are at now it's been a few more weeks down the track \ud83d\ude00 . Btw see #1503 for where we are at with this work so far . indeed!. Changes look good to me!\n. Interesting question, there's nothing in the github API for git LFS specifically. I'd assume if you really need to do this you'd need to manipulate an actual git workspace using git cmdline or maybe libgit2 \nAs an aside I wouldn't expect dll or xml files to normally be setup to use LFS, it's normally only for huge files compared to typical dll or xml files \n. G'day @gep13 \nIt looks to be related to those specific users.  In the 108 commits in your comparison, there are 5 commits with Author == null (and Committer == null when it was the same as author) and all 5 of them are from 3 unique contributors.  Also there are no other commits from these contributors in this comparison range that DO provide Author/Committer details.  In other words, ALL commits from these 3 authors present with this problem.\nI've confirmed that the actual json response has this field as null (ie there is nothing happening inside octokit deserializer, this is coming from the github api itself)\njson\n{\n      \"sha\": \"e61ec08215107576c2dea8cb080db9d61f1f1780\",\n      \"commit\": {\n        \"author\": {\n          \"name\": \"Scott Mackay\",\n          \"email\": \"scott.mackay@maclean.co.uk\",\n          \"date\": \"2016-06-02T16:43:17Z\"\n        },\n        \"committer\": {\n          \"name\": \"Gary Ewan Park\",\n          \"email\": \"gep13@gep13.co.uk\",\n          \"date\": \"2016-07-14T20:30:49Z\"\n        },\n        \"message\": \"(GH-960) Add configuration for default NuGet source\",\n        \"tree\": {\n          \"sha\": \"cdde0902a97c65bd1444c658cf9593eb8935c661\",\n          \"url\": \"https://api.github.com/repos/cake-build/cake/git/trees/cdde0902a97c65bd1444c658cf9593eb8935c661\"\n        },\n        \"url\": \"https://api.github.com/repos/cake-build/cake/git/commits/e61ec08215107576c2dea8cb080db9d61f1f1780\",\n        \"comment_count\": 0\n      },\n      \"url\": \"https://api.github.com/repos/cake-build/cake/commits/e61ec08215107576c2dea8cb080db9d61f1f1780\",\n      \"html_url\": \"https://github.com/cake-build/cake/commit/e61ec08215107576c2dea8cb080db9d61f1f1780\",\n      \"comments_url\": \"https://api.github.com/repos/cake-build/cake/commits/e61ec08215107576c2dea8cb080db9d61f1f1780/comments\",\n---> \"author\": null,\n      \"committer\": {\n        \"login\": \"gep13\",\n        \"id\": 1271146,\n        \"avatar_url\": \"https://avatars.githubusercontent.com/u/1271146?v=3\",\n        \"gravatar_id\": \"\",\n        \"url\": \"https://api.github.com/users/gep13\",\n        \"html_url\": \"https://github.com/gep13\",\n        \"followers_url\": \"https://api.github.com/users/gep13/followers\",\n        \"following_url\": \"https://api.github.com/users/gep13/following{/other_user}\",\n        \"gists_url\": \"https://api.github.com/users/gep13/gists{/gist_id}\",\n        \"starred_url\": \"https://api.github.com/users/gep13/starred{/owner}{/repo}\",\n        \"subscriptions_url\": \"https://api.github.com/users/gep13/subscriptions\",\n        \"organizations_url\": \"https://api.github.com/users/gep13/orgs\",\n        \"repos_url\": \"https://api.github.com/users/gep13/repos\",\n        \"events_url\": \"https://api.github.com/users/gep13/events{/privacy}\",\n        \"received_events_url\": \"https://api.github.com/users/gep13/received_events\",\n        \"type\": \"User\",\n        \"site_admin\": false\n      },\n      \"parents\": [\n        {\n          \"sha\": \"a3a26d74be0cac4ea820ce74bc4a96ce7dfd6358\",\n          \"url\": \"https://api.github.com/repos/cake-build/cake/commits/a3a26d74be0cac4ea820ce74bc4a96ce7dfd6358\",\n          \"html_url\": \"https://github.com/cake-build/cake/commit/a3a26d74be0cac4ea820ce74bc4a96ce7dfd6358\"\n        }\n      ]\n    },\nYou can also see this fact if you look at the commits themselves:\nhttps://github.com/cake-build/cake/commit/e61ec08215107576c2dea8cb080db9d61f1f1780, https://github.com/cake-build/cake/commit/0ddbae23114a3d33f44f9058cebfa7e817082855, https://github.com/cake-build/cake/commit/545ce71f3cf6b9ac25fb2249a47e6f811b63a31f, https://github.com/cake-build/cake/commit/5faa048cf153527cadd510a68a48a3d50b6e1974, https://github.com/cake-build/cake/commit/3f948dbe1297f1cf025cf87a7ee5c6f9f721338f\nThe author is NOT a normal hyperlink to a github user profile, instead it is just the \"display name\" of the author, according to the git commit data:\n\nSame in the commit list of the repo, we only see the git author name and not the github author's hyperlinked profile\n\nIn terms of the GitHub API object model, the items returned in the comparison results are what we call GithubCommits that have \"github\" info on them - things like organization/owner, and full \"user\" objects for Author and Commiter (in these cases this info is null).  Then there is also a Commit object that is more the pure \"git\" info, which include author/commiter details from an underlying git point of view (so you get the author's Name and Email, but not any github specific info like login)... just like any git client would show.\n\nSo if your intention is to generate a list of people who contributed commits, potentially you could go with commit.Commit.Author.Name rather than the github login, or possibly the github author.login is null, fallback to using the git author name instead.\nNow you've raised this here I realise I actually ran into this just the other day on our GitHub Enterprise instance where when I retrieved commits from a pull request not all Author fields were populated.  I didn't dig into it too much and just ended up using Commit.Author.Name instead... but I think it's likely to be the same thing.\nMaybe privacy settings on those users or email verification status?  I might ping github support about this to see if there is an explanation\n. PS I listened to your DNR podcast on cake recently and although I knew it was out there it's motivated me to put it on the todo list to go and check it out!  :+1:  octokit is using fake I dont know how @shiftkey would feel if I suggested moving to cake, but as a c# guy who doesn't know f# (another todo list item!) I find I have a mental barrier to touching the build scripts :grinning: \nI havent looked as yet, but I was thinking it'd be cool to have some \"github\" tasks in cake (using octokit.net of course!) if you don't already...  Creating PRs, tags, releases, pulling data for release notes etc.  I guess you could always just use octokit.net from c# but some aliases might be cool\n. >  I do commit using a few email addresses \nAre all the email addresses linked to your github profile? \n. Assuming the email address on the commits being discussed here is one that isn't, that would explain it \nIdeally you should add all your email addresses you use in git, under your github profile so you get stats for commits made via that email \n. > @ryangribble after associating the emails with the account, should I expect to see a non null in the response of the octokit call?\nyep!  Once the email address is \"claimed\" the output will contain the expected github Author.  \nAs there's nothing to stop this happening on any future commit/author, it's probably a good idea to implement the fallback to commit.Commit?.Author?.Name when commit.Author?.Login is null\n. Oh dear!  I saw it mentioned 0.21 was shipping tomorrow so I didn't review it earlier (that was a task for tonight)  :grinning \nI'll check these amendments out soon \n. I've run my own \"PR's merged between 2 refs\" code against this release and found another couple of PRs that aren't currently in the list:\nPR#1398 Updated git data commit response with signature verification object via @Sarmad93\nPR#1402 Fix serialization of enum value attributes via @maddin2016\nPR#1341 Include reactions on issue comments via @alfhenrik\n. ~~Weird, I'll need to look at why 1402 comes up in my query, \ud83d\ude00~~\nI was confused when you said \"previous release\" (I thought you mean v0.20) so all good.  \nMy query was from v0.20.0...master so 1402 coming up is correct, I just failed when seeing what you'd already listed in the release notes :grinning: \n. This is all looking rather \ud83d\udc8e to me! Ive run the integration tests too \ud83d\udc4d \nOne thing I noticed was a quick count of the \"events\" listed in the timeline API doc (21) is a couple more than values declared in the EventInfoState enum (19), so is there possibly another couple of values that need to be added to this enum in addition to the cross referenced one you added?\n. > @ryangribble not sure, but I think that now every new clients have to have repostoryId overload for each owner/name method, aren't they?\nGood pickup, I actualy realised this myself overnight (the things you think about while going to sleep, lol!)\nYes we should be adding repositoryId overload of any method that takes owner/name (as long as it actually works of course!).\nI also realised, we should be adding paging support to any GetAllxxx() type methods (ie an overload taking ApiOptions class, with the default method passing ApiOptions.None through to it).  Again, assuming paging is actually supported on that end point of course.\n. Nice work!  Everything looking good, ill just pull down your branch and run through the integration tests  :+1:\n. I just noticed missing XmlDoc comments on the 2 new functions added to ApiUrls.cs helper class which we probably should add, since every other function in that class has doc tags currently...\nOnce that's done I'm good to merge :grinning: \n. \n. Looks like all the tests passing, just needs some  \ud83d\udc40 from someone before merging \n. whitespace fixed, thanks \ud83d\ude00 \n. Do you have push access to the repository? The github API docs say that setting labels requires push access and if you don't have that, any labels (and assignees etc) are dropped \n. Could be, depending on what scopes you've granted the personal access token You could also attempt user/pwd just to see if it changes anything \nOtherwise if you want to post your code sample we can take a look? \n. Are you referring to attachments on the issue? There doesn't appear to be any GitHub API method to do this, it seems only available through the webUI \n. > SourceLink support (there's a nice helper for FAKE, but I gather there's a way to do it directly for our scenario)\nJust on this point, I stumbled upon GitLink which sounds like it may do the same thing as what SourceLink currently does.  CAKE has built-in aliases for GitLink\n- GitLinkRunner\u200b.Run(DirectoryPath, \u200bGitLinkSettings)\u200b\n. Hmmm so it turns out both SourceLink and GitLink dont support dotnetcore project.json and .xproj files which is a bit of a bummer in terms of our own dotnetcore move (which isnt strictly related to moving to CAKE however I was kind of intending to do it all at the same time)\nGitLink aren't planning on doing anything until project.json goes away (although Im not sure when that actually will occur), and SourceLink were waiting for upstream depedencies as of a few months ago which are hopefully now in place so there could be hope there...\n. Yep all sounds good.  The cake stuff i was playing with already is using GitVersion see here\nSo far i mostly based my cake stuff off Bddfy cake scripts but I'll take a look at akavache\n. Closed by #1581 . @shiftkey let me know if you want to \ud83d\udc40 this over or if you're happy for me to merge based on @alfhenrik's review \n. Ive fixed the comments and :lipstick: just waiting for any suggestions on that comment regarding a nicer ctor.  But otherwise this can be merged\n. OK ive implemented the user and team push restrictions settings be classes derived from Collection<string> which means we can now offer nicer ctors to better configure those options, rather than having to pass empty arrays etc\n``` csharp\n// Only admins can push\nnew BranchProtectionPushRestrictionsUpdate();\n// Specify some teams that can push\nnew BranchProtectionPushRestrictionsUpdate(\n    new BranchProtectionTeamCollection { \"my-team1\", \"my-team2\" });\n// specify some users that can push\nnew BranchProtectionPushRestrictionsUpdate(\n    new BranchProtectionUserCollection { \"user1\", \"user2\" });\n// spceify both teams AND users that can push\nnew BranchProtectionPushRestrictionsUpdate(\n    new BranchProtectionTeamCollection { \"my-team1\", \"my-team2\" },\n    new BranchProtectionUserCollection { \"user1\", \"user2\" });\n``\n. Also I realise some of the names are pretty verbose (egBranchProtectionRequiredStatusChecks) but that's because most of the simpler names (egRequiredStatusChecks) are still taken by the previous implementation which we've flagged as[Obsolete]` but still need to keep around for another release or 2... \n. Yes you should do any changes on top of those changes but you can just branch from my branch (ie don't have to wait for it to be merged) \n. > These naming convention tests fails because i have named methods for example GetProtectedBranchUserRestrictions. Should we rename to GetAllProtectedUserRestrictions?\nI guess you could.  I wonder whether that method \"actually\" supports pagination though.  that convention test just thinks that any method that returns a List<> and starts with Get...() supports pagination.  \nMaybe if you make a version that takes ApiOptions then see if it actually does paginate when you send up a page size of 1?  Then based on whether it supports pagination or not, we can figure out whether to rename the method so it complies, or whether to modify the convention test to not include these methods\n. > But if you delete more then one context it returns an empty array.\nAs long as we correctly deserialized the empty array I think this would be fine/expected.  Does it not work currently or were you just clarifying?\n. So in the GetClientInterfaces() method in PaginationTests.cs I can see it does exclude the IStatisticsClient from that list, but in your case you probably dont want to exclude the whole IRepositoryBranches client since some methods DO paginate.  So I guess that means you'd have to exclude the actual methods in the test itself, ie where it calls clientInterface.GetMethodsOrdered() you could add a where clause to exclude the known methods (or use a new attribute eg [ExcludeFromPaginationConventionTest] or whatever)\n. As far as I know even if the api doesnt support pagination, you should still have the observable implementation return an IObservable<User> and not an IObservable<IReadOnlyList<User>>\nTherefore all client methods should comply with the SyncObservableClients convention test and there is no need to skip it.\n~~Im pretty sure even the methods that DO paginate actually grab ALL pages from the non reactive client first, as they call .ToList().ToObservable() on them (the ToList() forcing the entire enumerable to be retrieved upfront).  So you should be able to do the same thing on these calls.~~\nOops... i was wrong on that part but anyway I think in your case you should still be able to force the List<T> to an IObservable<T> by calling client.GetBlah().ToObservable().SelectMany(x => x); which if you look through the code base there are a few instances of this already (eg in MiscellaneousClient, UserEmailsClient, UserGpgKeysClient, UserKeysClient)\n. And regarding the attribute, I agree that specific named [ExcludeFromPaginationConventionTest] attribute is preferable to a generic [ExcludeFromTest] attribute since the latter impies it's excluded from all tests which isnt the case.  Plus gtiven the above comments there is no need to exclude these things from more than 1 test at the moment anyway, so go with [ExcludeFromPaginationConventionTest]\n. Sorry for the shifting goal posts @maddin2016  but what I did in #1441 with the user and team push restrictions was introduced specific classes rather than just using List<string> so I think we need to use those classes in these changes too \n. No it's not in the return types it's in the request types\n. > I have correct my comment.\nah cool, sorry :grinning:  Yes :+1: that's what I meant - change the team/user inputs that are IReadOnlyList<string> to BranchProtectionTeamCollection or BranchProtectionUserCollection instead\n. The specific classes came about because I had a request that needed to take users and/or teams so without them having different types we couldn't provide nice constructor options \nContexts is fine to leave as strings, IMO \n. Hey @maddin2016 I'll pull this down on the weekend and go through it :grinning: \n. OK Ive had a go through this so here is some review comments:\nI realise youve named things exactly as I mapped out in the issue, but unfortunately I seem to have been inconsistent there in that I called some methods that REPLACE settings as UpdateBlah and others as SetBlah.  \nUpdate is more in line with terminology used in the rest of the code base, so Im thinking we should rename\nSetProtectedBranchTeamRestrictions => UpdateProtectedBranchTeamRestrictions\nSetProtectedBranchUserRestrictions => UpdateProtectedBranchUserRestrictions\n. Hey @maddin2016 great job, a few more comments marked up regarding some team2 test contexts still not being disposed, and also some xml comments.\nA couple of other things I picked up:\n- There are many cases of spurious /> at the end of the summary field in xml comment text like this:\n/// <summary>\n/// Remove user restrictions for the specified branch ***/>***\n/// </summary>\n- There seems to be alot of the [ExcludeFromPaginationTest] attributes on methods when I thought only some of the Getxxxx methods would need that.  It's currently on Add Delete and Update methods too\nAnd now for something a bit more general\n- As you know the Team/User restrictions only apply to organization owned repos.  So there is actually no need to have xxxxForOrgRepo tests for the status check/contexts endpoint tests.  Since there is no difference to running these for an organization vs personal repo.  In the case of the main top level methods I implemented, I did need to test the UpdateBranchProtection() method for both personal repos (status checks only) and organization repos (setting status checks AND push restrictions), which is why I had to have tests covering both types.  So I say :fire: the xxxxForOrgRepo tests you've got for the status check/context endpoints since we dont want to maintain these tests if they arent actually needed\n  - On that note, it would be good to include in the xml comments field a mention on the restriction related endpoints \"(applies only to Organization owned repositories)\" like I did on the ctor parameters of the BranchProtectionSettingsUpdate class, just so that users are informed not to use those methods on personal repos\n. I ended up fixing up some of the comments/wording related ones, if you want to cherry pick this commit: https://github.com/TattsGroup/octokit.net/commit/a28da43f9600f68c9c79cdbf09f766b9f5db973b :grinning: \n. Those methods were removed in #1458 in master... I think maybe your merge missed those files?  But your later commit seems to sort things out now\n. Ive succesfully run all the integration tests etc :+1:\nI think all the comments made have been addressed except for updating the xml comments to say \"(applies only to Organization owned repositories)\" on the restrictions, user restrictions and team restrictions methods\n. here's one i \"prepared earlier\" if you want it :stuck_out_tongue: \nhttps://github.com/TattsGroup/octokit.net/commit/e7fc6d5d34288fc4dbf4ed530ac4f4e85dc81a90\n. Sorry for the delay @maddin2016 :grinning: \nIve run through this again, including the integration tests, and it's good to go!  Thanks for your patience\n\n. Rather than only including the moving of methods to the branches API it would be good to get the top level branch protection stuff in this release.  It's ready to merge apart from :lipstick: #1407 \n. No, just #1441 .  That's enough to manage branch protections with the new API structure.  #1443 isnt ready yet, and is also just gravy (allows more granular editing of portions of branch protection, but they al lcan be set by the top level methods in #1441 anyway).\nSo yeah id like #1441 in this release if possible :)  Just addressing your comments now\n. Id also like to include #1450 in this release since its a trivial change but a much awaited feature\n. I corrected one typo but I've realised I missed obsoleting some of the stuff on the observable interface... also now that the new branch protection methods are implemented we can actual direct users to the alternative/replacement methods rather than just saying those old ones \"will cease to work\".  Ill push a PR to fix up the wording etc now - #1452\nIn terms of the branch protection stuff I dont know if its worth calling it out in the release notes somehow or not, but basically branch protection works fairly differently now (all due to the upstream changes made in github api).\nPreviously:\n- Branch objects inclued a Protection field which contained all the branch protection settings, and you could enable/disable branch protection using the client.Repository.EditBranch() method (also now moved to client.Repository.Branch.Edit()).  \nNow:\n- Branch objects have a bool Protected property, and an additional endpoint is required (client.Repository.Branch.GetBranchProtection() to get the actual protection settings (but it throws a 404 exception if protection is not actually enabled so you have to check that Branch.Protected flag first).  You edit protection settings using client.Repository.Branch.UpdateBranchProtection() and you disable protection using client.Repository.Branch.DeleteBranchProtection()\nIm not sure how to summarize the nicely in the release notes though!\n. Sounds reasonable \nIt should be changed in all the places we use RepositoryId as a parameter too though \n. changing to uint would be a breaking change for every single place changed, whereas long will implicitly allow an int to be passed so isnt a breaking change in the majority of the places touched in this PR.\nThe only place I can see currently that would be a breaking change is the change to long for the Repository.Id on the response class and even then only in some cases depending on the consuming code.  We'll need to include something in the release notes on that.\n. the release is done now so should be good to rebase this and merge it in.  There might be a couple of new methods added in recent PRs that would have missed the initial int => long conversion too....\n. yep 2 releases is the current agreed \"standard\" for obsoleting things.\nJust on this - im not getting why the change from int to long is such a \"breaking\" change.  Won't the majority of cases happily continue to work without any changes even once they take this update?  I think given pre 1.0 we could be flexible on this.  The Async method suffixes was a totally different proposition requiring nearly every line of code interacting with octokit to have to be changed.  Conversely with this repositoryId change, there would be nowhere near as many code changes, if any at all?\n. Given its delivered via nuget there wouldn't be any supported way to update to the new version WITHOUT also compiling against it though right? \nObviously @shiftkey can have the final say but based on these points I think we should not worry about it \n- not a breaking change for almost all use cases \n- amount of work/churn to obsolete int methods is large \n- int methods were only recently added anyway, further reducing the target audience that could be affected \n. > BTW, this was recently announced as a breaking change on the dev blog as well.\nI saw this thismorning but incorrectly assumed we'd be fine since they were just making some fields not returned in some cases, which happens quite commonly.  Obviously being non nullable int's wasn't too happy though :grin: \n. Yep, based on the API structure that sounds good, and it would be a child Traffic property under the existing RepositoriesClient so we would access it like client.Repository.Traffic.GetAllReferrers()\n. Thanks for the quick fix!\n\n. You would need to use credentials (personal access token) that has access to the private repository, which may not be desirable. \nIf you are determined to use github release files as your file storage then perhaps another way would be to have a public repo that only contains a readme file and release notes etc that you could create/mirror your releases in and have your download msi there etc. You could also have issues turned on in that public repo so your users could raise issues with you\n. Just having a new year's clean of open PR's - I'd like to either get the wording fixed up as @Haacked requested or drop this PR. Awesome stuff!\nSo I can't comment on the fsharp code itself but from an operational sense it appears this task runs and succeeds so thats good!\n\nA couple of comments\n- It might be nice to output the real name of the linqpad sample file somewhere in that build log as the actual task only mentions the temporary file obviously (or perhaps we could make the temporary filenames consist of a randomly generated portion followed by the actual filename like 123abc-1-introducing-octokit.linq, 123abc-2-releases.linq etc)\n- Would be nice to see what does a build failure look like - eg do we see enough info in the output to know what sample was wrong etc?\n- On this PR you should be able to remove any old code (that skipped test etc) that wont be needed anymore\n- Finally if you mention the issue you are fixing like this \"fixes #xxx\" in your PR description, the issue will automatically be closed when the PR is merged :+1:\n. > Regarding the issue ID in the PR description, sorry about that, I'm still struggling with this notion. I thought it was meant to be in a commit message. I'm not sure I can update the PR description now - clicking the Edit button allows me to update the title but now the description\nAh my apologies, I didnt see it in the commit.  That should also close the issue.  Personally i prefer to put it in the PR as people may not read the commit comments and it also adds the github reference link to the PR data... but it's all good!\nPS you can edit the PR body/1st comment with the pencil icon (as opposed to the edit button which is the title and base branch)\n. @shiftkey did you want to look over the F# code or you happy to merge this based on the fact the new tests do succesfully run?\n. I guess integration tests still prove everything is wired up correctly, even if there aren't any meaningful stats...  \nI take it we can't point the calls at an existing repository due to permissions? \n. Hi @maddin2016 \nDo you think you could add some integration tests then flag them as Skipped due to requiring admin permissions.  This way I can at least run these locally (after changing the repostory to something I do have admin permissions on and unskipping the tests) to ensure the functionality is working as intended?\n. Hey @maddin2016 \nThanks for adding the tests - lucky we did because there was actually an issue with timestamps!  \ud83d\ude00 \nI pulled everything down and ran through it, and these are the things I changed:\n- RepositoryId was recently changed from int to long in #1445 so the repositoryId parameters in this new API need to be long now too\n- The timestamp field in the Api responses is in unix utc time, and doesn't deserialize into a DateTimeOffset directly, causing exceptions on the View and Clone methods when the repository actually had some data to return for these calls\n- I wasnt a fan of naming the item level classes View and Clone since they are a bit too generic IMO\n- I also thought naming some methods GetAllxxx() when they don't support pagination we can use the new [ExcludeFromPaginationConventionTests] so we can call them GetReferrers() and GetPaths() which is more inline with what they do (it's not all referrers, just referrers from last 14 days etc)\n- Integration tests were added for owner/name methods but not for repositoryId methods\nAs I was working through things I ended up making local fixes anyhow, so I've pushed a commit that addresses these already if you want to cherry pick it in: https://github.com/TattsGroup/octokit.net/commit/b145bb30d1a8848a160bd13bc0f9818f22be9b7f\nIf you are interested in how we handle the timestamp thing, basically in other areas of the codebase we have a pattern already, where we add a long TimestampAsUtcEpochSeconds field to take the deserialized value (using the Parameter override to map it to timestamp) and then add a DateTimeOffset Timestamp getter property that uses a helper function to convert the unix time into DateTimeOffset.  it looks something like this (and you'll see these fixes in my commit):\n``` csharp\n        [Parameter(Key = \"ignoreThisField\")]\n        public DateTimeOffset Timestamp\n        {\n            get { return TimestampAsUtcEpochSeconds.FromUnixTime(); }\n        }\n    [Parameter(Key = \"timestamp\")]\n    public long TimestampAsUtcEpochSeconds { get; protected set; }\n\n```\nLet me know what you think of my changes\n. Thanks for another great contribution @maddin2016  \ud83d\ude00 \n\n. Not that it's really required but my 2c is definitely in agreement that the \ud83d\udea2 had sailed on this \nAs @shiftkey said if someone honestly feels passionately enough about this to make ALL the changes in a non breaking way I'd help get the PR through but I definitely don't intend to do it \ud83d\ude1d\n. Do you mean SSH key?  If so it's at client.User.GitSshKey.Create()\n. We raised issue #1447 to implement this, and @maddin2016 has done the work in PR #1457  which should be merged soon. So it should be in the next release \ud83d\udc4d \n. Hi @malamour-work thanks heaps for your contribution!  :grinning: \nA couple of things for you:\nBreaking changes to public interfaces/methods\nBeing a public API we do need to be careful about not breaking existing users and the renamed methods in ApiUrls class would currently be a \"breaking\" change for people.  Whilst they are just helper methods, given they are public we could have users that are using them and as such I believe they would fall under our obligation to not make breaking changes without going through the normal process (see below).\nIt makes sense to rename the existing ApiUrls.Organizations() to ApiUrls.UserOrganizations() as you've done but technically that means the old name can't be used for the new \"all organizations\" URL since it needs to be obsoleted.  You'll need to use a different name for that one such as ApiUrls.AllOrganizations().\nMaintaining naming consistency\nWe try to follow a naming convention where GetAll gets the given resource, GetAllForCurrent() is for the current user, GetAllForUser() is for a nominated user etc.  So in this case, GetAllOrganizations() should really just be named GetAll() since they are in the organizations client already.  I realize you went with this option because the other methods were already just called GetAll but infact they SHOULD have been called GetAllForUser(string login) all this time... So it would be cool if you could rename GetAll(string user) => GetAllForUser(string login) as part of this change, and implement GetAll() as your new method rather than calling it GetAllOrganizations().  Any renames would be done following the \"normal process\" outlined below.\nProcess for breaking changes:\nCreate the new method/implementation/classes and mark any old ones as \n[Obsolete(\"Please use OrganizationsClient.GetAllForUser() instead.  This method will be removed in a future version\")]\nWe wait at least 2 releases before removing the obsolete items from the code base.  This gives users some notice (in the form of compiler warnings) before things change on them :+1: \nLet me know if you need any help with this and thanks for stepping up to correct this missing functionality!\n. Another thing I just realized is that the API docs mentions this \"List organizations\" API method is not paginated like normal methods (pagesize, count etc), and instead just uses the since parameter.  So you wont be able to take ApiOptions in your method signature, instead you'll need a custom request class with the Since parameter.  You can have a look at the Repositories.GetAllPublic(PublicRepositoryRequest request) method for some ideas on how to tackle that\n. Thanks @malamour-work sorry I hadnt had a chance over the weekend to look at this.  I will try and do it tonight.  \nHave you actually run the integration tests?  I notice they are flagged as GitHubEnterprise (because they create organizations to then run the tests against, and create organizations is not avaialble on github.com only github enterprise).  For something like a GET call, we could potentially run the test against github.com but I guess that becomes hard since we dont know what organization ID to use as the since parameter (and as time marches on, any ID used in the test will start to become further and further back in time, leading to the test retrieving larger amounts of orgs until it eventually times out!).  So probably leaving the tests as GitHubEnterprise tests is fine, but we do just need to make sure they actually run succesfully of course :grinning:  \nI wll pull this down and run the tests etc and get back to you\n. Sorry for the delay on this one \ud83d\ude2d \nIve run the integration tests and made a couple of tweaks and pushed them back up.\nThis LGTM now - many thanks for your PR and particularly working through all the review comments \ud83d\ude00 \n. Assuming I am understanding what you're referring to, I believe the API field name (and hence the octokit member name) is StargazersCount (on the Repository class) \n. Ah sorry, indeed you are correct \nThere is a watchers_count field in the API response that is not currently implemented in octokit.net. It should be a simple change, just adding a member called WatchersCount to the Repository object \nTypically missing fields like this are added as people run into them, but I would actually like to proactively add useful missing fields. I started the first step by auditing API response fields that are missing from our response model classes in #1400 (and sure enough, these watcher fields are listed) \n. Hey so I actually stumbled upon an old issue #699 that explains this WatchersCount property was actually deprecated and SubscribersCount is the field you want to use for this...  But then SubscribersCount field was also deprecated/removed in issue #736.  So apparently the \"correct\" way to retrieve this info is using the \"Watchers\" API WatchedClient.GetAllWatchers() instead.\nAlthough, since the API response still include the SubscribersCount field (showing the correct value of 125 for this repo, for example) and the linked blog in #699 mentions they will be supported indefinitely in API v3, perhaps it would be OK to add the field back in again.\n@shiftkey or @Haacked care to comment on these historic issues?  From my perspective, if SubscribersCount is still being returned AND contains the correct value, it was possibly premature to remove it and require additional API calls to get that information?\nIve created PR #1473 to add SubscribersCount field back, as well as a couple of others that were missing (as per #1400)\n. If it works then may as well include the ApiOptions overloads :+1:\n. Putting together a new release is next on my list!  \nIn the meantime now this is merged to master, it will be in the nuget packages on our appveyor feed here: https://ci.appveyor.com/nuget/octokit-net. Is some one able to give this one a :+1: ?  I'd like to merge it in. Closing this off as it's now been incorporated into #1503. Github support replied and confirmed there was some upstream problems which they've pushed fixes for. \nWith those fixes, the Get and Update integration tests I added are now passing :+1:\nStill seems to be an issue with Create call which I've asked support to look into \n. Support reply regarding create method:\n\nTurns out that this isn't a problem in the code, but the documentation -- it was originally intended for the feature to be supported by the endpoints to fetch and modify a repository, even though the documentation says it should be supported by the endpoint for creating a repository (the documentation shouldn't have said that). We'll be updating the documentation to reflect this.\n\nSo I'll remove the create method tomorrow then this PR can be merged \n. OK this is now good to go, I've removed the CreateRepository changes, but left the commit in the history incase github do end up supporting it, we can resurrect it\n. How are you executing FixProjects?  Are you up to date with latest master?  \nThis change to build.cmd bootstrap script updated the nuget restore command to grab a later version of FAKE that brought dotnet core tasks.  It was 14 days ago so I assume you already must have that commit, but from the error message you're getting it looks like FAKE doesn't recognize DotNetCli tasks which would indicate you arent on that later version that the bootstrap script should be updating to?\n. Naming things is always hard \ud83d\ude00 what you've suggested sounds fine \nAlthough you probably know me well enough to know that I always have an opinion :grinning: so if discussion is wanted over naming of the request/response model classes, my 2c is that \"Project\"  is already a sufficient enough entity to name everything with so I probably would use \"Project\" \"ProjectCard\" \"ProjectColumn\" rather than \"RepositoryProjectXxx\".  For example a pull request, issue etc all belong to a repository but we don't call them \"RepositoryPullRequest\" \"RepositoryIssue\" \nThat's just my thoughts, not saying you have to rename everything (unless you agree with my assertions) \n. Yeah I guess I can only vouch for things since I've been contributing so for anything that pre-dates that I reserve the right to say I wouldn't have named it that, haha \ud83d\ude02 \nA note on hooks though - you can have repo or organisation level hooks so in the case at least, it's necessary to denote the type/level of hook. Infact invitations also might exist at both repo an org levels? \n. Hey @maddin2016 sorry for not getting stuck into this yet!  It's a busy time of year...\nNot sure if you saw but some changes were recently announced regarding this preview API.  Do you think it just impacts your endpoints and function parameters or does it also mean the actual calls need to live in a different place?\nGitHub Developer Blog - Changes to Projects API\n. Yep this aligns with th API docs structure so I think it's the way to go. I guess this (significant changes) is the  risk we run when implementing these preview APIs \ud83d\ude02 \n. > But there is still the question if we only implement the new endpoints projects/.../:id?\nYeah definitely only do the new ones, since the old ones will be gone in the next couple of weeks anyway\n. Hey @maddin2016 \nIve finally got around to pulling this down.  I had to make some changes to integration tests but other than that everything is looking :gem:\nAny chance you can give me permission to push my change to your branch by ticking the box on the right? ----->\n\n. OK ive pushed up the test changes and also updated to latest master\nTo explain what i did with the tests:  There is no need to use GHE stuff for the tests as we dont need to create an organization, we can just create projects in the test user's existing organization.  Also had to tweak some of the asserts to only ensure the created projects existed in the returned values rather than the count being 2 (since existing projects may cause there to be more than 2).  I also simplified the helper functions to not pass around an entire repository context object but just the repository Id, and finally fixed a couple of bugs where repository name was being used instead of organization name :+1:\nAll integration tests that are there are passing for me (and you should be able to run them all too) but I guess as you've pointed out, there still appear to be some methods that dont have tests. Yes, I merged in latest master and will just do a final review and integration test run tonight, then it can be merged :tada:. Hey @maddin2016 did you check if the Projects API supports pagination?  Currently there are no GetAll methods implemented with ApiOptions overloads. Soooo close!!!!\nIf you can add the ApiOptions overloads please @maddin2016 then we can merge it in \ud83d\ude00 \n\n. Changes look good :+1:\nWe also normally have integration tests that prove the pagination is working - such as these ones for the PullRequest client. @maddin2016 Im putting together a new release shortly, just wondering if you want some help with the integration tests for the pagination?. I thought we were still waiting for more integration tests to be added... I'll need to have a look . Hey so I think ive tidied this one up.  While I was adding the missing pagination tests, I actually discovered there were some new methods and fields that hadnt been implemented back when this was first started\nAll the tests are passing, including integration tests but it'd be great if someone can take a sanity check \ud83d\udc40 before I hit the button?  @maddin2016 @mderriey @M-Zuber \n. Thanks @maddin2016 for the ground work on this one!\n. release_notes:  Implement Projects API (Preview). Hi @zzzprojects thanks for the heads up \u261d \nBut the one you highlighted looks ok to me? It's an internal function, and inside that function the only await call DOES have ConfigureAwait(false) on there already? \nHappy for you to send a pull request for any you find to discuss/review further \n. I'd like to include #1477 if upstream github API fix for create repository call gets resolved before the release ETA\nAlso I just ran into a minor overlooked thing caused by #1445 today which I've just pushed PR #1485 for, which should be included in the release\n. Are you still shooting for Thursday release or going to go earlier?\nRegarding #1477 I checked just now and the behaviour is unchanged.  It's reasonably safe to \ud83d\udea2 anyway since it just means that allowed merge method fields are ignored on repo creation, and the respective response fields are returned null in the response to the Create() call as well.  Once github.com is rectified, our Create method and integration test should pass.  \nMeanwhile the Edit() and Get() repository methods work fine, so the workaround is to create a repo then use the Edit() method to set the allowed merge methods.  I'd like to get support out for configuring those merge methods if we can, since it's a popular feature and it'd be good to support it this quickly after it was anounced.  Thoughts?\n. If the Create() method is still no good, we could back out those changes if you aren't  happy to release it in that state while waiting for github API fix.  It will still be useful to release the Update() and Get() Repository methods since the functionality can totally be exercised with them \n. Turns out it's a doco error and the create method isn't going to support the feature at this time, so I'll fix up that PR tomorrow \n. #1477 is updated and good to \ud83d\udea2 \n. one other way could be to create a \"shared\" octokit-test organisation and repo and user, then embed a personal access token for that user into our test code.  This could either be used to run those [RequiresOrgOwner] type tests under, or could also be used behind the scenes to add the user's configured test account to the organization as an owner, so the tests would then work\n. A shared organisation that all octokit contributors test account  would be added to (using API key hardcoded in the code base) with appropriate permissions so the tests requiring owner permissions would work (and the data would be real since the repos are existing and not created just for the test) \n. +1 on not making a breaking change\nThe overload approach you've gone with seems ok to me :+1:\n. Sorry for the delay @laedit \nThis LGTM and the integration tests are \ud83d\udc4c plus the revisions make it a non breaking change \ud83d\ude00 \nThanks for the contribution!\n. Thanks for the PR \ud83d\udc4d \nAdding the HtmlUrl is \ud83d\udc8e - this is the url to this milestone on github.com and definitely should be included \nBut fields like LabelsUrl generally wouldn't be added to octokit.net, since we aim to provide a c# model over the github API, we don't normally expose the internal API hypermedia url links to the end user. \nInstead we provide access to the associated API endpoint through the object model, in this case it's at client.Issues.Labels.GetAllForMilestone()\nGiven the above, are you cool to drop off that labels field from the PR? If not let us know your use case and we can discuss \ud83d\ude00\n. Sorry for the delay, have been having a bit of no home computer time this week :)\nThanks for the PR!\n\n. Given that #1500 is opened, are we happy to close this one?\n. OK so did you get confirmation that this had changed upstream?  \nI thought for as long as Ive been using octokit it was like this - Eg since PullRequests are also/actually Issues, the \"comments\" you see on the discussion area were always obtained from getting them from the Issue API, and the \"comments\" on the PullRequest API were always the \"review\" comments... even before   all the changes to make code reviews a native/first class concept.  \nI just want to clarify with @jaredpar you said this is how you expect it to work, not necessarily that it used to work like this and has since changed, right?\nI dont disagree that we could rename the PullRequest.Comment API cliient to PullRequest.ReviewComment but just trying to quantify whether this was an upstream change or just a legacy/confusing name scenario. OK, since this was just an expectation thing rather than any kind of breaking change, Im going to close this issue out.  Ive also raised #1511 to tweak the naming of PullRequest.Comment to PullRequest.ReviewComment to make the naming clearer and better aligned with the API docs. Hey @goateey \nWhat level of access to the organisation/repo do the user credentials you are providing for the API call have?  In order to list out admins you would need to be an owner of the organisation I'm pretty sure \n. Yes the API call you highlighted  is already implemented in octokit as client.Organization.Team.GetAllRepositories()\nAnd the reason why the first call you mentioned doesnt work anymore is that the github API only returns limited team information on the \"get teams for repo\" call, as you can see in the api docs here.  I cant be certain but I think this all changed when the organization permissions were revamped back in September 2015.\nThe interesting thing is that in GitHub Enterprise this change was in 2.4 so Im not sure why you weren't already running into this.  Perhaps it was only when those organization changes came out of preview and then whichever subsequent GHE release (2.5 or 2.6) that made it into?\nAnyway try out the Team.GetAllRepositories() and let us know if that works for you?\n. Yeah, for better or worse the octokit convention is for singularly named clients. \nIt's not really fitting to change just this one item to pluralised form \n. Interesting! It looks like DeploymentsClient was moved under Repository back in 2014 and removed from the IGitHubClient interface, but inadvertently left behind in the GitHubClient concrete class \ud83d\ude1d \nNice pickup!\n\nHmm... looks like some changes are required in ObservableDeploymentStatusClient.cs too... WIP.\n\nNo worries, Ive marked [WIP] in the PR title - just edit that out when it's ready for review/merging\n. Just getting back on top of things, looks like this one is good to go\nMany thanks for the contribution!\n. Hi @pjc0247 sorry for the delay in responding.\nThe builds are currently failing unit test let me know if you need help with it\n. Sorry for the delay, this looks good to merge now!  \nMany thanks for the contribution, and for your patience :)\n. Evidently th new reviews stuff has added some new event types to this API (and probably to webhooks as well) \nI think it's hard to track this sort of thing with a concrete enum as we don't want to break everytime an upstream event type gets added. Yet making it a string loses some niceties as well. \nI'd propose we could shoot for a best of both worlds approach involving \n- have an Unknown enum member and catch any failed deserialization so this value can be used rather than failing\n- add a BlahText property to always provide what the actual returned value was  \nThoughts? \n. Any thoughts from @shiftkey @maddin2016 @M-Zuber about this enum approach?\n. I can't help on the Fake front so much, but I'd like to combine the CAKE changes I was working on  (#1440 / #1476)  with this branch since it seems logical to me to do the cake switch as part of the dotnet core work. I should be able to do some work on this this weekend . I merged your changes in with mine from #1476 and built+tested everything fine on AppVeyor using the Cake build \ud83d\ude01 \nBasically the cake build is doing GitVersion to calculate version number, package restore, build, test and then packaging nuget packages, setup as artifacts in AppVeyor.  I also removed the Octokit.Next projects since they were just a sample before you got stuck into the real thing.\nAs youll see from the commands in the AppVeyor.yml file - to run the build you just change into ./build directory and dotnet restore dotnet run the Cake.Frosting build project.  Or if you want to debug the build you simply open up /build/build.sln in Visual Studio and hit F5.  Ultimately I will make it easier to run a build (eg a bootstrap build.ps1 in the root directory) but for now its just the 2 commands, until we actually delete the Fake f# and associated scripts\nTake a look at it on branch https://github.com/TattsGroup/octokit.net/tree/port-to-dotnet-core and merge it into your branch if you think it's a go :+1:. In terms of the #defines \n\n\nSome code is referencing HAS_REGEX_COMPILED_OPTIONS but this isnt defined for any project.  Im thinking the net45 one should set this?  There are also perhaps other #defines in a similar boat (eg code that uses them but no projects define them, or projects that define something which isnt actually used anywhere in code)\n\n\nThe HAS_TYPEINFO define is used to wrap most calls to GetTypeInfo() but there are some in the code base that are \"unguarded\".  Is this a problem?  If it's not a problem, then why do we need to guard any of them?\n\n\n. This is really great stuff @mderriey I can't spot anything too serious and everything is locally working for me including builds in VS2015 and cake script, unit tests, integration tests etc.  \nI guess the next steps are to actually prove things are working (eg a running dotnet core app on on mac/linux/windows using octokit.core library) as well as a traditional full framework dotnet app on windows using the newly built library.  We can also work on our nuget packages (AppVeyor should be spitting them out) to see if they are working etc...  \nThe last piece of the puzzle was source linking in the PDB files but I dont think either of the 2 options mentioned (SourceLink and GitLink) will work for us at this time.  I found another fork/derivative recently that Im going to look at PdbGit. Wow that's awesome! Have you actually tried source debugging the built dll/pdb? . Im also not very across this stuff either by the way.  My basic understanding is that source linking allows stepping into the source of a nuget loaded dll without requiring symbol servers etc.  It somehow embeds the links of the files on github into the PDB file.\nSourceLink and GitLink both scraped csproj files and so on, so they werent compatible with dotnet core (due to project.json) but then even with the \"new\" csproj for dotnet core now, I suspect they will still need to be changed since the csproj doesnt actually contain all files anymore and just has globs etc.  PdbGit was another one I found which seemed to take a different approach and you pointed at the actual PDB files rather than the source project file, although I have no idea if that means it would work with dotnet core PDB files or not etc...  It's pretty much stuff that needs to be researched... and in the meantime I believe one or both of SourceLink/GitLink are making moves to support dotnet core now that the new project structure is here.\nIn terms of PdbGit it probably makes sense that an AppVeyor build from a PR in this repo wouldnt know to reference files/commits from the contributors fork/branch and is instead trying to hit the official repo... although it's weird that the commit hash doesnt seem to exist anywhere :grining: \nI guess we can always look at the PdbGit source code or reach out to the author to answer some of these questions.  It also could be possible to pass parameters to PdbGit for the SHA and repository to use (but then Im not sure if AppVeyor even knows those details).\nIt's not really important to build source linked PDB files from pending PR's though anyway... we really just want the \"official\" builds from the octokit repo to have that capability.  What I'd like to do when we cut over to this dotnet core and CAKE stuff, is have every build from master branch publish a pre-release package to nuget.org, and then periodically do the \"official\" releases like we do now. \n. Yep I think we can publish a prerelease alpha package off this branch (without source linking in the PDB) so we can play around with it further in test projects and get something in the hands of our users so they can kick the tyres too.  \nIf you also want to play with writing a CAKE helper that uses that octokit dotnetcore library to find out the correct URL to pass to PdbGit so source linking of pending PR builds works from the contributors source branch that's cool from a \"nailed it!\" perspective... although not \"necessary\" if you dont want to, since I dont think we would ever publish packages from a pending PR.  \nI do plan to step up the release frequency this year, including automatic publishing by the CAKE build script of every merged PR to master as a prerelease package to nuget, but I dont think packages from inflight PR's would be a thing wanted or needed.  Still, for \"science\" it could be cool to see if you can get it working \ud83d\ude1b . @mderriey and I have made a few more tweaks and all the integration tests are now passing.\nI'm pleased to announce we now have Pre-Release packages up on NuGet!\nhttps://www.nuget.org/packages/Octokit/0.24.1-alpha0001\nhttps://www.nuget.org/packages/Octokit.Reactive/0.24.1-alpha0001. Im going to merge this PR into the dotnetcore branch I just created.\nWe can then correct any further issues via specific targeted PR's for better tracking.\nIve also created a Milestone to track everything related to dotnetcore. @mderriey - you sir are a LEGEND :+1:\n\n. What I meant by that comment was to have a string field containing the actual API response as well as the enum field containing the (attempted) deserialized enum value. \nEg say the field is public EventType Event,  you would also have a field public string EventText\n. > So, that means that we search all response types which have an enum, add a string field for that enum, and add a new member UnknownType for that enum. Right?\nYep that's what I was suggesting, although am interested in feedback from yourself and others, if this \"feels\" good.... Sorry @maddin2016 I may not have been clear enough here.  The changes you've made wont achieve the desired result if you consider this example using your method\n``` csharp\npublic class SampleResponse\n{\n   public enum MyEnum { Value1, Value2, Unknown };\npublic MyEnum? MyProperty { get; protected set; }\npublic string MyPropertyText { get { return MyProperty.ToString(); }\n}\n```\nAnd say the API response contains json { my_property: \"value3\" }\nWith your current changes we will get MyEnum.Unknown for MyProperty and \"Unknown\" for MyPropertyText but what we actually want to get is the unrecognized string \"value3\" for MyPropertyText.\nThere is also the case that when the field is null you will throw an exception trying to call .ToString() on it.\nSo what we actually need to do is something similar to the way we sometimes handle unix timestamps where we map the actual api response field (my_property) to the string field (MyPropertyText), and then have the enum field just have a get only property that attempts the enum parse (falling back to .Unknown if it couldn't parse and returning null if the string value was null).\nsomething like this:\n``` csharp\n    public enum MyEnum\n    {\n        Value1,\n        Value2,\n        Unknown\n    }\npublic class SampleResponse\n{\n    [Parameter(Key = \"ignoreThisField\")]\n    public MyEnum? MyProperty { get { return MyPropertyText.ParseEnumWithDefault<MyEnum>(MyEnum.Unknown); } }\n\n    [Parameter(Key = \"my_property\")]\n    public string MyPropertyText { get; protected set; }\n}\n\n```\nWith the helper function ParseEnumWithDefaut<TEnum>() being added to the StringExtensions class\nStringExtensions.cs\n``` csharp\n        public static TEnum? ParseEnumWithDefault(this string input, TEnum defaultValue) where TEnum : struct\n        {\n            if (input == null) return null;\n        TEnum value;\n        return Enum.TryParse(input, out value) ? value : defaultValue;\n    }\n\n```\nThoughts?\n. Cool...  A couple more thoughts:\n\n\nWe shouldnt change the signature of the ctor's as they are public and it would be a breaking change.  I guess we can still take the enum field in the ctor then assign it to the xxxxText property like StatusText = status.ToString()\n\n\nI guess the helper function doing the enum parsing needs to handle the transition from snake case to camel case too, like the JsonSerializer does.  Eg the text value might be \"client_interface\" which we need to parse into xxxx.ClientInterface so it will need to convert snake_case to CamelCase first before trying to parse the value?\n\n\nNeed to think about how to test we have these changes correct.  We already have some serialization unit tests for response classes but I'd be suggesting that for each response class we touched, we add unit tests where we feed a json string containing a valid response and one containing a valid response EXCEPT the enum value is one that doesnt match the enum, and then assert all fields on the returned objects are as expected\n\n\nWill there be any performance impact?  Previously the deserializer was caching enum deserializations so we were basically only \"figuring out\" each enum once no matter how many objects of that response type were encountered.  Now we dont have any of that overhead but everytime the enum field is accessed we are parsing the string to an enum.  If this does cause performance impact I guess we could set the enum field's value whenever we set the text value (ie the ctor and the setter of the text property) rather than everytime we access it.  It may not even affect performance though\n\n\nIm not sure if these changes are getting to kludgy though, need some feedback from @shiftkey if we are heading too far down a rabbit hole.  I guess the alternative was throwing exceptions whenever an API response changed which wasnt great either :)\n. Bump @shiftkey if you want to comment at all?\nIm happy to proceed with this change... My most recent points for consideration still stand.\nAnd a couple of further points:\n\n\nI tend to agree with the comments about naming the placeholder value something more obvious... such as OctokitUnsupportedValue rather than just Unknown\n\n\nContinuing the second guessing over \"Naming things\", Im wondering if xxxRaw is better than xxxText for the string property that will hold the raw actual response.  Thoughts?\n\n\nSince going down this road will impose the requirement on all future changes to handle enums on response classes in this way I would like us to \"enforce\" this by adding to our convention tests\n\nfind all enums that are used in Response classes and ensure they have this UnknownApiValue placeholder value\nfind all Response classes that have an enum typed member (eg Blah) and ensure they have a string BlahText property. Nope, this one can be closed in favour of #1595 :+1:.  GetLastApInfo() returns the ApiInfo from the last call that was made - so you need to have made another \"regular\" call using the same GitHubClient instance, prior to calling GetLastApiInfo() in order to get data back?\n\nIf that's not the issue, can you please provide a code sample reproducing the problem?  Ive just run through the integration tests locally and they are passing OK on my side.... While looking at something else I found the reason for this!  \nThis condition causes a null ApiInfo object to be stored as LastApiInfo if any of the various properties are null.  In my case I was debugging something and the Api response did NOT have an ETag header, which meant the ApiInfo object was then not attempted to be stored.  \nThe fix would be remove that condition and just guard against any of the sub elements being null but still clone as much of the ApiInfo object as is present.. Hey, if you have a read of #1470 there is some explanation there, but basically the fields you mentioned aren't the correct ones.  There was a SubscribersCount field which was correct but it was deprecated and replaced with a separate API call.  So the current official way to get this info is via a call to the client.Activity.Watching.GetAllWatchers() call.  \nHowever as the SubscribersCount field was confirmed as being supported for the lifetime of the GitHub API v3, I actually suggested re-instating this field in PR #1473 which is not yet merged. #1473 should have resolved this with the SubscribersCount field . Yeah pretty much, although the obsolete message wording should be more in line with other examples in the code base. It also needs to be done in both the interface definition and the concrete implementation and also for the Observable client/interface \nAnd yes updating any other test code should be done now, so that later on the removal of the deprecated endpoint is simple/surgical . What I actually meant was to make the same rename to the variable name in the observable API client structure...  But you are spot on that the internals of the observable methods will also need to be tweaked to call the new client's path\nIf you're keen to work on this just push up a PR with your progress and we can work through it there \ud83d\udc4d . All yours @M-Zuber !. Unless you prefer the organization ones I also just raised #1513 and #1514 in which case Im happy to knock over this protected branches one since Im pretty familiar with this area.  \nUp to you though, if you want to do this one that's cool. I would have thought passing null means review isn't required at all, then passing the object means review IS required (with the boolean indicating whether admins also have to comply with it or not). If you can't pass null how do you indicate no review is required? . Yeah it looks like the naming conventions have been a bit out of whack with this one.  \"normally\" we would have XxxRequest on a GetAll endpoint, and NewXxx/UpdateXxx on any create/update endpoints... but in this case the CollaboratorRequest name has aleady been used \ud83d\ude2c \nSo yeah I would say :+1: to this\n\nShould I add a new class ListCollaboratorRequest(?) with the Affiliation property and use that for the List collaborators endpoint?\n. If you just want to ask a question you could use the gitter chat room also \n\nDocumentation on rate limiting is here: https://developer.github.com/v3/#rate-limiting\n. Great work...  Many thanks for your contribution, this is good to go!\n\n. release_notes: Rename PullRequest.Comment to PullRequest.ReviewComment for better accuracy. Hi @l1salvatore \ncan you post some sample code to demonstrate what you're trying please? . https://help.github.com/articles/creating-and-highlighting-code-blocks/. As @shiftkey already pointed out, this contents_uri field is not currently supported in Octokit.  \nThe \"fix\" is to add a ContentsUri field to the correct response class (I think this is GitHubCommitFile and possibly PullRequestFile too) and then you would be able to get the Uri for the contents of these large diffs.  You could then access them via a HTTP call. Looking pretty good so far :+1:\nThe names are getting pretty long though!  I wonder if instead of BranchProtectionRequiredPullRequestReviewsUpdate we can get away with BranchProtectionRequiredReviewsUpdate instead.\nWhat do you think @M-Zuber ?\nIn terms of the \"test whether @ryangribble is right\" thing, Im pretty positive it's going to be how I said. \neg if you look at the webUI below, passing the item as null controls the \"require reviews before merging\" checkbox, whilst passing the IncludeAdmins as true/false controls the Include Administrators checkbox.  If you always pass up the object, how will you ever configure branch protection to NOT require a review?\n\nTests will reveal soon enough I guess \ud83d\ude1b . As is the case with preview API's there is also the possibility of shifting goal posts! \nSome changes were recently announced to this that will need to be taken into account too \nhttps://developer.github.com/changes/2017-03-22-protected-branches-admin-improvements/\n@m-zuber did you want to push up the code you do have so far? . Hope you don't mind @M-Zuber but I've taken over this PR \ud83d\ude00\nI realized that we don't have much time before we have to pass the new required_pull_request_reviews field in all branch protection calls, otherwise they will stop working when the API becomes official in less than a week\nFirst post has been updated.... OK this should be good!  All integration tests are passing.  \nJust needs a sanity check for typos etc. release_notes:  Implement RequiredPullRequestReviews support in IRepositoryBranchesClient.UpdateBranchProtection and additional granular methods to GetReviewEnforcement, UpdateReviewEnforcement and RemoveReviewEnforcement. advisories: This release contains the necessary Octokit changes to specify the required_pull_request_reviews field on Branch Protection updates, which becomes mandatory when the Protected Branches API graduates from preview mode on the 1st September. I think breaking it up is good, so we can include the basic information asap . Awesome stuff, thanks so much for the additional clarity in the docs and congrats @SeanKilleen on the first merged contribution of 2017!  Happy New Year \ud83c\udf89 \n\n. Apart from adding enum values that are missing and waiting for another release, we also have a proposal to handle these at runtime here  #1504 . Yeah looks like that's an incorrectly documented field and should be fixed up... apologies for the bum steer!  \ud83d\ude2e \n. Comment clarified in #1534 - thanks!. Hey @SeanKilleen that sounds like a great idea \n\ninherit this exception type from Forbidden exception and supply the Retry-After value directly in the Exception?\n\nThis option sounds \ud83d\udc4d to me . Personally im not a fan of a non official default that we make up ourselves.  I think make it nullable and if the value can't be parsed/isn't present then return null. So to me it looks like you only need to override GetObjectData() if you have extra properties on the class.  ForbiddenException doesn't have any properties of it's own so it doesn't have to do this, but your AbuseException class does have a property, so I think that explains why the error occurs on AbuseException and not on ForbiddenException.\nSo to correctly implement the [Serializable] attribute (and satisfy the code analysis CA2240 error), it sounds like you do need to provide a GetObjectData() override on AbuseException.  And it also needs to be marked as [SecurityCritical] due to what was mentioned in #1493 (essentially it needs to match the base class method being overridden). Also regarding the test that you removed because it was failing due to #1529 im thinking so we dont lose the test maybe add it back in and skip it for now.  That way we have a test that captures the problem and a good way to test a fix later, by unskipping that test?. OK yep this is all looking \ud83d\udc8e \nOne final question - have you actually managed to get a runtime test performed, just to try and ensure that the exception was correctly thrown and the retry value was present and parsed?  Or is it too hard to actually trigger the abuse conditions?. Thanks for that \ud83d\ude00 \nI think we're done here!\n. Is this related to something I found when working on a PR here: https://github.com/octokit/octokit.net/pull/1415  ?\nIf you see the 2nd bullet point where I talk about the attempted ApiError deserialization never returning a null and thus never falling back to the text payload.... Just refreshing my memory with this stuff and yes I agree with your suggestion.  \nSpecifically I think the 2nd suggested fix would be the way to go, since we can \"fix\" it in one place, rather than needing to fix it in every place that currently has ApiErrorMessageSafe ?? \"default error text\"\nAnd this is a different situation to what I commented about above - in that case I found that a compeltely invalid json structure in the error message was still returning a default/empty ApiError object because the deserializer creates an object then tries to populate any fields that match the setter properties.  This led to code that was never really getting what it expected, since ApiError itself could never be null.  Your case is slightly different since it would also happen if there was valid json error payload but the message field was empty string or not present.. Yep that's it.  Basically it was just relocated from client.Release to client.Repository.Release\nIt's an interesting point though about how to keep documented code samples up to date.  I guess some sort of system where the linqpad snippets (which we can automatically test) are embedded into documentation... But that implies a built docs system whereas currently we really just have a limited number of markdown files. Glad you got it working @jparnell8839 \nJust to reply to this:\n\nit needs await, so I had to put it in an async method. And you cannot make Main() asynchronous.\n\nFYI in c# you can force an async call to be run in a blocking fashion (and thus can be run from your Main() method, by using the .Result like this:\nvar releases = client.Repository.Release.GetAll(\"octokit\", \"octokit.net\").Result;\nAlso in terms of this:\n\n(because \"ocktokit\" doesn't have any releases, go figure)\n\nThis doesn't sound right as there are a number of octokit releases!  When I run some sample code based off what you posted, I get the expected 48 releases\n\n. @YunLi1988 can you share your use case?  My concern is that by adding this Id field which as @shiftkey says isnt actually used for any other API calls, it will just lead to confusion with users using Id instead of Number. OK no worries, we can just make sure that the XmlDoc comments on this Id field are sufficiently explanatory to hopefully avoid users mistakenly using it when they really want pullrequest.Number\nAre you going to have a crack at adding this field to PullRequest class @YunLi1988 ?  Happy to guide you through it!  It's pretty much just a case of adding the field to the class (and including it in the constructor) then ensuring we check that field is returned in an (existing) integration test. Awesome!  Well basically you just need to add the new field long Id to the PullRequest response class here and also include it in the constructor here.  You can look at all the existing fields of that response class to get an idea of what is required.\nThe octokit deserializer will take care of populating the field etc, so the only other thing to do would be to update an integration test (for example this one here) and add an assertion that the new field is populated correctly - eg `Assert.NotNull(result.Id); \nHave a crack (fork the repo, create a branch, make some changes) then raise a pending Pull Request here, and we can work through any changes there!  Good luck :grinning:. Fixed by #1537 . Hi @wanjizheng \nYes it does look like we don't currenly have the Add organization member endpoint implemented.  \nHowever as a workaround, as documented here, users can also be invited by adding them to a Team in the Organization (which we do have implemented as IGitHubClient.Organization.Team.AddMembership here) and I also believe you can invite a user by inviting them as a repository collaborator (which we have implemented as client.Repository.Collaborator.Invite() here)\nWe will keep this issue open to track implementing Add organization membership as client.Organization.AddOrUpdateMembership(). Poking around in this area thanks to @alfhenrik #1639  #1640 revealed we also have to implement\nRemove organization membership as client.Organization.DeleteMembership(). I wouldnt think so @SameerSawla as this would be imposed by the github API for abuse reasons.  You could contact github support and ask the question though.\nUnder what circumstances do you need to invite more than 50 people to an organisation every 24 hours?. Sweet as!  Thanks for taking the time to correct this misleading comment!! \ud83d\udc4d \n. Hi @vmikeska , yes it should be implemented - something like the following should work:\n``` csharp\nvar client = new GitHubClient(new ProductHeaderValue(\"LabelExample\"))\n    {\n        Credentials = new Credentials(xxxxx / add user/pwd or apikey as appropriate /);\n    };\n// Retrieve all labels available in a given repository\nvar labels = await client.Issue.Labels.GetAllForRepository(\"octokit\", \"octokit.net\");\n```\nPlease let me know if this is what you were looking for! \ud83d\ude00 . Ive edited that comment myself since you had allowed contributors to push to your branch :grinning: and Ive also notified github support of the undocumented value so they can consider updating the docs\nThanks @lynnfaraday and congratulations on your first contribution to octokit.net \ud83c\udf89 \n. (just waiting to get Travis CI happy before hitting the button) . release_notes: Fix IssueTimelineClient deserialization exceptions by adding new EventInfoState values. > I am not familiar with git hub. somehow I cannot find the comments I received in my email.\nIf the comments were on some lines of code that have since been replaced, then github collapses it into a \"outdated\" section.  You can click that to see the comments again:\n\n\n\nOnce you are done with this one, can you assign another entrylevel task?\n\nThat's awesome!  All of our issues with a tag of \"up for grabs\" are meant to be easy enough for new contributors to tackle.  You can choose anything that takes your fancy but if you really want a suggestion how about https://github.com/octokit/octokit.net/issues/1514 \ud83d\ude00   When you find an issue you want to work on, Just comment on that issue that you want to take a look at it (this makes sure we dont have multiple people trying to fix the same thing!).  Create a branch on your fork of the repo (I notice you used your master branch for this PR, instead you should create a branch and do the work there, so your master branch can just be a identical copy of this repo's master branch) push that branch up and raise a pull request.  Put [WIP] ( meaning work in progress) in the PR title, and we can then work together as you make the change.  It's totally fine to raise the [WIP] pull request early in the process so we can collaborate rather than waiting until you've done lots of coding!  . Many thanks @YunLi1988 for this enhancement, and congratulations on your first octokit.net contribution!  \n\n. PS: I noticed the commits on this PR are from a different email address than your github profile, so they arent linked together.  You should add your other email address to your profile so the commits are associated with your github account!  \ud83d\udc4d . Yes, the way we tend to do it is create a Factory class which gets injected by DI, and that Factory class (which can be initially setup with your common values such as the AppName and the Url (if using GitHub Enterprise) etc) knows how to generate a client with the credentials you give it from your lower context...\neg \n``` csharp\nusing System;\nusing Octokit;\nnamespace Api.Providers.GitHub\n{\n    public class GitHubClientFactory : IGitHubClientFactory\n    {\n        private readonly string _serverUrl;\n        private readonly string _appName;\n    public GitHubClientFactory(string serverUrl, string appName)\n    {\n        _serverUrl = serverUrl;\n        _appName = appName;\n    }\n\n    public IGitHubClient CreateClient(string apiKey)\n    {\n        return new GitHubClient(new ProductHeaderValue(_appName), new Uri(_serverUrl))\n        {\n            Credentials = new Credentials(apiKey)\n        };\n    }\n}\n\n}\n``. CLosing this out as answered :+1:. Ive fixed a good handful of integration tests, some of them were really quite strange (likeAccountType.Bot` now being a thing!).\nAll integration tests are now passing!. OK I think this is good to go, just waiting for an \ud83d\udc40 from @shiftkey or @Haacked . Well, here goes nothing!\n\n. Published:\nhttps://www.nuget.org/packages/Octokit/0.24.0\nhttps://www.nuget.org/packages/Octokit.Reactive/0.24.0. This is good, thanks @SeanKilleen!\nNot sure what is up with AppVeyor, all our builds seem to be stuck \"queued\" today.  Will see if it's fixed by tomorrow. release_notes: Unparseable ApiErrors should now fall back to better default error messages. . \ud83e\udd14 I initially fixed this as a commit on the release branch while fixing a broken integration test...  But then I thought this should probably be in release notes which means I needed it on a PR \ud83d\ude00 . Do either of your methods work when the file is not \"large\" ?. Yes you already asked this in #1521 and it looks like the Patch field is not provided on those responses (thus it is null).  There is discussion on that issue about another field that could be useful (but isnt currently supported in Octokit)\nLet's continue discussions over on #1521 and close this duplicate issue. Considering the builds are passing this must be good \ud83d\ude00 \nWhile looking through this I noticed that in the Octokit.ruleset file is this comment \n\nThis ruleset only includes the rules we care about. I'll be adding new ones as we fix our codebase.\n\nBut if Im understanding the actual ruleset file correctly, I think actually we are actually opting in to ALL rules except 7 specific exemptions.  If that's correct, perhaps while we are \ud83d\udc40 at this part of the project we can update that comment.  Something like \"This ruleset enables all of the Microsoft CodeAnalysis rules, with a few deliberate exceptions\".\nThoughts?. . @mderriey this is working nicely :+1:\nOne enhancement request I have is to add an info message to the log to state that it's generating a temporary csproj (so it's less confusing that the formatting tool then mentions csproj when we are a dotnetcore project)\n```\nFormatCode\nFormatting code of Octokit\n`  Generating temporary csproj file` <== add something like this\nOctokit.csproj\n        Syntax Pass\n        Local Semantic Pass\n        Global Semantic Pass\n```. Awesome :grinning:\nIf you can just merge/rebase on the target branch to pull in that travis fix, I can hit the button once the builds are \ud83d\udc9a . \n\n. Ive tested this and it's :gem:\nIn terms of consistency with the older FAKE builds, this task was called ValidateLINQPadSamples rather than RunLinqPadSamples.  Do you think we should rename it?  If not then can you double check there are no docs anywhere that need to be updated?\nAlso, from an OCD point of view (and I realise it was like this under FAKE anyway!) it would be nice if the samples were done in logical 1,2,3...10 order rather than alphabetical (1,10,2,3).  Or do you think it would be too ugly to add an .OrderBy() lambda to the query (considering it has to split the string, check if it's numeric, etc etc)? \ud83d\ude1b  Or perhaps we could just rename the sample files to be 01-xxxxxx.  Thoughts?. Love your work! \nJust waiting to see what is up with travisCI builds... . Ah nice, I couldnt see anything that correlated with Travis failures but as you say I guess they fixed their OSX image and the workaround is now no longer required\nThis is ready to \ud83d\udea2 . . Hi @guilhermecorsino many thanks for taking up this feature enhancement!\nThe progress looks good so far!  \nA couple of comments:\nIf we look at the official API docs I can see that the request to \"Add or Update Organization Membership\" actually takes a parameter to indicate the role the user should have (eg Mmber, Admin).  So that means you would create a new Request model object (eg OrganizationMembershipUpdate) that has a Role property of that enum type.\nAnd looking at the response model returned, currently you have this defined as a single enum however it is actually a response object that includes State, Role, Oragnization and User fields.  So you will actually want your OrganizationMembership be a response class that has these fields on it, and rename your enum to something like OrganizationMembershipStatus\nIf you add some integration tests it will be easy to test this call against the real github.com - make sure you follow the details in our contributors section about how to configure the integration test settings (and of course, make sure you have setup a test github account and organization so you arent using your real account, if you havent already)\nLet me know if you want more detailed help or if you are happy to have a crack at addressing these. :+1:. What you did should have worked \nMaybe it's the full stop at the end of the line?! . Awesome stuff @mderriey \nSo going forward I'd like to have each pull request merged to master automatically push a pre release package to nuget. I think we could use beta tag in this case rather than alpha (which I used for the dotnetcore stuff since it was pretty experimental and also not in master yet) \nMapping things out as to how I could see this working, do you think this sounds good? \n0.24 last release \nMerge a PR to master : 0.25.0-beta0001 to nuget \nMerge next PR to master: 0.25.0-beta0002 to nuget \nMerge another PR to master: 0.25.0-beta0003 to nuget \nCreate release branch release/0.25.0: create draft release in repo (and nothing to nuget yet) \nUpdate release notes, tweak tests etc on release branch: update draft release with latest release notes (nothing to nuget)\nPublish draft release (tags master): 0.25.0 to nuget \nMerge PR to master: 0.26.0-beta0001 to nuget \netc . Yeah we can discuss the release creation/updating etc on #1545 \nIn terms of this change though, does the configuration achieve the numbering that I mentioned in my previous comment? . Yep, I'm guessing we have to tag the repo with -beta0001 in order for the next merge to master to get - beta0002 and so on? Not that it's a problem, just that we currently don't tag . Ok yeah so I was wondering how it kept track of the 1,2,3 if there was nothing in the repo \ud83d\ude00  so it counts the commits, clever! Does that mean if a PR was merged instead of squashed (thus there might be 5 commits to master rather than 1) it would jump from beta0001 to beta0006? . Yeah we squash PR's normally since it keeps the history cleaner. I think it's ok \ud83d\udc4c . Hi @ArsenShnurkov \nThanks for the correction \ud83d\ude00 \nI may as well merge this (eventhough all these projects will be going away once we merge the dotnetcore branch). Hi @pthivierge it looks like the API response field for timestampmay now be a formatted  time string rather than the long value Unix epoch time that it used to be, back when we implemented it \nSuch is the nature of preview API features I guess! \nWe should confirm this has changed on a few example repos and if so change the field type to DateTimeOffset. Yes, the easy \"fix\" is to add the missing value to the enumeration, similar to #1536\nWe are also kicking around a new approach to enums in #1504 which would at least stop exceptions from being thrown whenever GitHub adds a new event type. Thanks @mderriey for the fix!\nso it looks like appveyor builds are not playing nice.  and the travis linux builds are failing due to that same dotnetcore related issue that you fixed on the dotnetcore branch.  Did you want to cherry pick that travis fix into this branch so we can get master building?\nI will try and figure out what the problem with AppVeyor is!. OK so the appveyor problem turned out to be account feed no longer being allowed for public projects.  We actually arent using this feed anyway but our appveyor.yml had the settings in it which I've now removed.\nhttp://help.appveyor.com/discussions/problems/6024-build-stalled-prompting-for-nuget-permissions. Thanks for the fix @mderriey (and finally!  TravisCI and AppVeyor are passing again :) )\n. release_notes: Fix RepositoryTrafficClient to handle upstream API change in timestamps from Unix epoch time to ISO8601. Hi @alexperovich \nThere is a bit of history behind this field, but it looks like it has been changed again (without an api change notification being posted on the api blog).\nOriginally, this field did not actually include the merge commit of a PR but was the internal \"test commit\" of the PR merged with the base branch, and wasnt updated to the resultant SHA when thr PR was actually merged.  It was then deprecated from the github API, and we removed it from octokit.net to avoid confusion.\nThis was the deprecation comments back then, from upstream:\nThe merge_commit_sha attribute holds the SHA of the test merge commit; however, this attribute is deprecated and is scheduled for removal in the next version of the API. The Boolean mergeable attribute will remain to indicate whether the pull request can be automatically merged.\nBut looking at the API docs now, it appears this field is BACK and actually does contain a useful value! \ud83c\udf89 \nhttps://developer.github.com/v3/pulls/#get-a-single-pull-request\n```\nEach time the pull request receives new commits, GitHub creates a merge commit to test whether the pull request can be automatically merged into the base branch. (This test commit is not added to the base branch or the head branch.)\nThe value of the merge_commit_sha attribute changes depending on the state of the pull request. Before a pull request is merged, the merge_commit_sha attribute holds the SHA of the test merge commit. After a pull request is merged, the attribute changes depending on how the pull request was merged:\n\nIf the pull request was merged as a merge commit, the attribute represents the SHA of the merge commit.\nIf the pull request was merged via a squash, the attribute represents the SHA of the squashed commit on the base branch.\nIf the pull request was rebased, the attribute represents the commit that the base branch was updated to.\n```\n\nI'm happy to merge this change and get the field added again, however could you please update the field comment to contain a synopsis of the above information?\nMy suggestion (not particularly elegant, if you can do better!) would be something like:\n/// <summary>\n/// The test/merge/squash/rebase commit hash, depending on the state of the pull request and if/how it was merged\n/// </summary>. Nailed it!\n\nThanks @alexperovich for picking this up \ud83d\udc4d . release_notes: Add support for the newly resurrected PullRequest.MergeCommitSha property. If someone can have a \ud83d\udc40 over this before I merge it, that would be great!  \ud83d\ude00 . @shiftkey should be good now.  I also agree on minimising the number of code analysis rules we \"opt out\" of at a project level :+1:. kicked the builds and they are \u2705 now. @shiftkey not sure if you wanted to close out reviewing this or not.  Ill merge it in a day or two if I haven't heard back. release_notes: Fix more IssueTimelineClient deserialization exceptions by adding more new EventInfoState values. Thanks @ivandrofly for the correction... Out of interest did you actually run into a situation where exceptions were being thrown by these extension methods? . Whoops forgot about this one!\nCheers @ivandrofly . Hi @zeppaman  thanks for reaching out. \nThe good news is, the Releases client is implemented, you will find it at client.Repository.Release rather than client.Release\nThe bad news is that the documentation is out of date! If you would consider sending a pull request to correct the offending doc file that would be wonderful! \nOtherwise we can raise an issue for somebody to fix it up \ud83d\udc4d . @patriksvensson @gep13 did you guys have any guidance on \"the best\" way to get the DotNetCorePack Cake task to use the desired version number on the nuget package.  As mentioned in the PR there are a number of possible ways, interested in what \"the standard\" should be. @patriksvensson thanks for advising to go with option 2 for the dotnet core pack \ud83d\ude00 Although it seems when providing the full version via the /p:Version= argument, there isn't any need to also keep the VersionSuffix property.\nWe actually do have a nuget.config already, as we have been using cake.frosting for a while on our previous project.json setup... perhaps you were looking at our master branch rather than dotnetcore branch?\nThanks for the help and again - thanks for cake.frosting it's been going well for us :+1:\n@ctaggart thanks for the offer of assistance, as you say it's super easy to add sourcelink 2.0 support with the new msbuild tooling - pretty much just plan on copying one of the other PRs you've already done, but we'll certainly let you know if we can't sort it!. OK so appveyor is now building OK but ive been battling with travisCI unsuccesfully, running into a permissions error.  \nI just realised though that im not even sure if the cake tasks we have would work on linux... we include tools/nuget.exe in our repo and it seems this is picked up/used by the ToolInstaller class in cake script, to install our GitVersion and OctokitCodeFormatter tools.  So if we wanted that to work i think we would need to get the linux compatible nuget.exe and run it via mono nuget install on the TravisCI linux and mac boxes... GitVersion.exe is the same thing (can be run via mono i beleive).  our code formatter tool doesnt support non windows platform, but its not actually used in the default build target so would be ok.\nPotentially with dotnetcore, we dont even need to worry about TravisCI and could just use Appveyor instead...  Thoughts @shiftkey  ?  . > Hey @ryangribble what's left to get this one merged?\n\nDo you want to get SourceLink in this one or in a separate one as @ctaggart suggested?\n\nYeah a separate PR for SourceLink sounds good.\nIn terms of this one, the only thing left was to either get TravisCI working or drop it.  I guess we did have agreement to drop it, but a part of me still wants to pursue it \"for science\" if nothing else \ud83d\ude1b \nI just pushed a commit that adjusted the NuGet.exe that is in our repo's permissions and this actually has seen the Travis linux build able to install tools (Cake's internals appear to correctly handle running NuGet.exe via mono nuget.exe when it needs to) and it's now failing trying to run GitVersion commandline.  Again, GitVersion does actually support running via mono but it could be that Cake doesn't handle this internally.  Assuming we can get GitVersion working, the only other thing that may not be possible on linux/osx is the LinqPad samples (we could skip them on these platforms perhaps) and the code formatter (which doesnt run as part of a CI build anyway).\nLet me know if you think im flogging a dead horse!. Haha yeah although my current debug method (push commit and wait for TravisCI) has some pretty poor feedback loops \ud83d\ude1d   I really should look into the docker image stuff!. woot so GitVersion is now running on TravisCI via Mono hehehe\nNext problem is the projects trying to build for net45. @mderriey \ud83d\udc4f \ud83d\udc4f \n. Nice, hopefully that last commit makes the OSX builds more stable \n@mderriey I think we're done here, did you want to take a final look over and give me a \ud83d\udc4d to hit the button? . After the item ha been marked obsolete for a couple on releases its fine to remove it, so go with option 1 \ud83d\udc4d . Sorry for the delay on this one @eriawan I was planning on just running the integration tests but hadnt had time.  Can pick it up on the next release anyway.\nWe actually need to remove all the obsolete items from -2 releases ago. No need to wait! That would be great thanks \ud83d\ude00. release_notes: Remove obsolete constructor of RepositoryUpdate request class. Glad you figured it out! \nIt'd be good if you could leave the issue here and update with the solution incase others run into the same situation . Hi @cokochiaki can you please explain why this should be reverted? Thanks . dotnetcore is now merged, so these projects/solutions no longer exist. Agree that a \"machine account\" with a personal access token sounds like the way to handle this.  We also have a release/helper bot that uses this approach.\nIm going to close out this issue but feel free to comment further or re-open if you need to @nating . OK so this worked \ud83d\ude00 \ud83c\udf89 \n\n\nBut I'd like to make a couple of enhancements \n\n\n[ ] Ability to run sourcelink on local builds\nBy default sourcelink is running only on CI server.  Ill add a cake parameter allowing us to run sourcelink locally if required.  When this parameter is passed to Cake, we can set /p:ci=true parameter on the DotNetBuild task which will cause sourcelink to run.  Not sure what other side effects of setting ci=true are though...  Alternatively I can investigate how to control running sourcelink or not with a specific parameter maybe...\n\n\n[ ] Show sourcelink output in build script output\nCurrently the log doesnt show any of this output unless you set verbosity (passing /v:n to the build task).  But that of course shows HEAPS of other output when ideally there would be a way to just see the sourcelink info (or even just the result of dotnet sourcelink test). Let me know if there is anything like that @ctaggart or whether I have to go with verbose mode?. > 2.1 will be a lot less verbose. It will not print all the source files. I'll probably publish to NuGet Gallery the latest prerelease soon if it passes tests.\n\n\nI didnt mind the verbosity of the sourcelink output itself, the main problem was since it's part of the \"build\" task, when I set verbosity I got loads of build related output from MSBuild (when i really just wanted the sourelink output).\nFor the time being ive actually removed the builtin MSBuild sourcelink test, and running my own cake task to do a sourcelink test on the produced assemblies, so our build output shows that sourcelink was verified.. Builds are green, I'm happy if you are :+1: @mderriey \nFrom the appveyor build log:\n\nTravisCI:\n\n. Oh nice!  I'll change my step to run after packaging and use the nupkg files instead, as the way I was getting the dll assemblies was assuming a few things! \nRegarding travis yeah we had a few hoops to jump  but between @mderriey and I we got it working! Most of the magic will be in travis.yml and build.sh and a little in our cake build (running nuget and gitversion via mono) . Yeah it did take a noticable amount of time but as @ctaggart said it is checking each file on github's checksum against that stored in the embedded pdb so it was expected.  it seems to be faster on the subsequent assemblies so I'm guessing some caching must be involved?\nAlso when comparing to previous builds Im not sure if the SourceLink.Test msbuild target was even actually running once @mderriey introduced the SourceLinkCreate msbuild parameter setting.  From the brief look I had, the CI parameter would run create and test actions, but the SourceLinkCreate parameter only controlled creation, and a separate SourceLinkTest parameter controlled the testing.  See here.. > Do you prefer running it as part of the dotnet build?\nI prefer running it separately as I liked the idea of seeing output/validation of the sourcelink data.  Perhaps in the future if the msbuild sourcelink test target can log the \"sourcelink test on xxxx succesful\" when msbuild logging verbosity is the default, then we could remove the explicit step, but for now im happy!. One other thing I just thought about... when you run sourcelink test \"before pushing\" it gets 404 failures because that commit hash doesnt exist on github.com.  So perhaps that is the reason for seeing execution time take longer locally. . release_notes: Provide SourceLink capability for Octokit and Octokit.Reactive assemblies. Im not sure of the historic reasons, but it looks like there are 12 places where the response.IsTrue() is guarded by a try/catch that eats the exception and returns false instead.  For consistency, if they are to be changed I'd like to see them all changed.\nIm also not sure how to treat this behavioural change as some consumers could be impacted by exceptions being thrown when previously they received a false return.  Although it does seem the exceptions would only occur in true error situations, since a response of 404 or 204 will cause false/true to be returned.\nAny thoughts @shiftkey  ?. Actually of those 12 instances it looks like all but 2 are actually using catch (NotFoundException) { } as opposed to catch { } \nThe former is \"correct\" because it will have the logic that a HTTP 404 (NotFound) will return false a 204 (NoContent) means true and any other status (like your authorization exception) will be thrown.\nSo rather than how you've changed it in this PR, if you just make the catch be for NotFoundException only, that should achieve the desired result.  If you could also fix up the the other one while you're at it, that would be swell!\nFYI there are also 40-50 matches of other code/methods where they check for a HTTP 204/404 for success only they dont use that handy HttpResponse.IsTrue() extension method :grinning:.  Looking at most of those it looks like they are also behaving \"correctly\" in that a true/false return results on a 204/404 and an exception on any other status code.... Great!  Thanks @joensindholt . . ugh so I was giong to merge this but the builds are actually red \ud83d\ude22 \n. Yeah that was just a demonstration project anyway and it seems the appveyor image and dotnet core tooling doesn't like it anymore. Will be superseded by our proper dotnet core port soon anyway, so ive removed it from master for now \nThanks! . Ive poked around with this, and it looks like the last_read_at parameter is required.  Not sure if this is a recent thing or it's always been like this, as there are no integration tests for this method currently.\nFor now, you can call the method using the following code and it should work OK (specifying no time in the MarkAsReadRequest passes null for the argument)\nawait client.Activity.Notifications.MarkAsRead(new MarkAsReadRequest())\nThe easiest fix for this would be to change the parameter-less MarkAsRead() implementation to simply do return MarkAsRead(new MarkAsReadRequest()). I think this would be an uncommonly used method, so there's no telling how long it may have been like this for upstream (possibly forever?!). The MarkAsReadForRepository() methods suffer from the same problem.  I wrote some integration tests and found they also are failing.\nPushing up fixes now.... PS, there are also a handful of other API clients where PUT is called without providing a body.  \nI'll do some poking to see if this also causes HTTP 400 errors and follow up on a separate PR if fixes are required. If someone can give this a quick \ud83d\udc40 I'll hit the button . release_notes: Fix NotificationsClient.MarkAsRead() exception by specifying a payload body in the PUT request. Anyone able to take a \ud83d\udc40 to check what I've done seems sensible?\n@101shipit @shiftkey. . release_notes: Fix connection.GetLastApiInfo() was returning null in some situations. Nothing specific, unless you can spot anything I've missed! . Could it be be because it squashed the PR instead of merge maybe? . Ive pushed a merge commit and the conflicts aren't showing now.  It's interesting because locally the only 2 files on the merge were 2 csproj files, yet the github web interface was claiming conflicts in the linqpad files as well.  \ud83e\udd14 . FYI I've pushed a PR to do the mentioned doc updates (and as it turns out, a few more cleanup type tasks). \n Once #1600 is merged into dotnetcore, we should be good to hit the button on this PR!. OK people, I'm going to do it... see you on the other side \ud83d\ude01 \n. Sounds good. You could also add a convention test @mderriey,  to keep us consistent going forward :D. You'll want to use the RepositoryContentsClient in octokit \nOne good source  of sample code is the integration tests eg this one retrieves the contents of a folder: https://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/RepositoryContentsClientTests.cs#L95. Thanks @eriawan I will have a review this long weekend but just a note on those last couple of commits.  I think those tests can be completely removed as there should already be tests for the Repository.Branch.Get/GetAll methods in the appropriate file, so the tests in the RepositoryClientTests wouldnt be needed anymore since those methods are now removed from RepositoryClient.  Let me know if I'm not making sense, I'm on my phone \ud83d\ude1b . It looking pretty good, but the obsolete RepositoryContentsClientTests tests should be removed on this PR too, not much point in doing 2 PR's for the one change. Superceded by #1622. I reckon we may as well do request models as well . I kicked it and it's Green now... Travis builds seem to be frustratingly flaky \ud83d\ude22 \nI'm having second thoughts about the Request models though.  My thinking has kind of come around to the fact that these are meant to be proper Url's so allowing people to pass \"any old string\" may not be great.  Thoughts?\nI also had a look at other places we use Uri type such as some helper functions or the GitHubClient itself, and I don't think any of those cases need to be turned to string.  So I guess pending a thought on whether Request models should or shouldn't be converted to string this should be good to merge.\nAlso obviously this is a breaking change but I think just getting it in and flagging it in the release notes is preferable than waiting out 2 releases with the current properties marked [Obsolete] - given our pre 1.0 status I'm thinking that should be OK.... Those few request models seem ok to me... \nI'd be interested in what currently happens if a user provides a string that is NOT a properly formatted Url for those properties... If the upstream API rejects it anyway then it's a no brainer to enforce the Uri on our side. If they are somehow allowed through then we'd need to think about whether we want to potentially prevent users from doing something they could be doing currently . Since GitHub introduced the \"squash\" action directly when merging PR button \u2764\ufe0f \u2764\ufe0f I never bother to explicitly squash the branch anymore \ud83d\ude1b \nSO in terms of the Request models Im just trying to catch up here... did we end up with ANY of them needing to be Uri or did they all end up being string because the upstream api does accept non Uri's?  If there are no real examples of existing request models that must be Uri we probably shouldn't have the convention test since it would stand to reason that future api calls implemented would likely follow the same upstream behaviour (and thus we should use string rather than Uri in future too?). Thanks for the recap @mderriey .  So i pulled down your changes and played a bit and actually there are NO other Request models with Url properties except the ones you've excluded anyway.  So im thinking how about we actually change the test to \"RequestModelsHaveUrlPropertiesOfTypeString\" and enforce that we use strings for these.  Given that the only existing 4 request models with these properties are all accepted as strings upstream anyway it seems likely that future upstream API fields would be similar.\n``` csharp\n    [Theory]\n    [MemberData(\"RequestModelTypes\")]\n    public void RequestModelsHaveUrlPropertiesOfTypeString(Type modelType)\n    {\n        var propertiesWithInvalidType = modelType\n            .GetProperties()\n            .Where(x => x.Name.EndsWith(\"Url\"))\n            .Where(x => x.PropertyType != typeof(string))\n            .ToList();\n    if (propertiesWithInvalidType.Count > 0)\n    {\n        throw new InvalidUrlPropertyTypeException(modelType, typeof(string), propertiesWithInvalidType);\n    }\n}\n\n```. > Maybe the tests should only test types that do have *Url properties...\nYeah i guess at the moment the MemberData is all response types which does artificially inflate the test cases needlessly...  It's fine if you want to write a new function that only gets models that DO have the property that EndsWith(\"Url\") if you want to\nSimilarly, it's fine if you want to combine back to one test case that does Request+Response models, or to leave it as is :+1:. Thanks @mderriey this is looking \ud83d\udc8e now, Ill hit the button. . Indeed there are a couple of unimplemented calls that would be under IRepositoriesClient endpoint.\nWould you be interested in making these modifications @azubanov  ?\nFirstly, we could have license information included in existing calls that return Repository objects.  To do this we need to add the licenses preview API header (AcceptHeaders.LicensesApiPreview) in the underlying Http Get requests of those client calls (eg client.Repository.Get(owner, repo)) and then add a License License property to the Repository response class.\nSecondly there actually is a \"Get a repository's license\" call which you linked to.  This would be suitable as a new call in the IRepositoriesClient such as Task<RepositoryLicense> GetLicenseContents(); and implement the RepositoryLicense response model (from the api doc it looks like this response may be different to the existing license responses). Welcome @gdziadkiewicz - thanks for contributing to octokit!  \nI'll mark up a few quick \"house keeping\" things in a review, but it looks like you'll need a bit of guidance about the API request/response models etc as I can see a couple of things that are going to trip things up. In terms of more structural things, there are 2 main things i've spotted so far\n\n\nWith the response models, it looks like you are creating a PullRequestReviewCreate model for the return of this call, however my take on the api docs is that this call actually just returns a PullRequest object.  So in this case I don't believe we need a new response model, it should just use PullRequest.  However it looks like we DO need to include some new fields on the PullRequest model (namely the IReadOnlyList<User> RequestedReviewers property).\n\n\nThere are usually \"undocumented\" api endpoints for each call that has a repository specified...  The traditional/documented calls are for owner and name, but there is usually another one taking the long repositoryId instead - refer #1120 for more details.  If you take a look at some other pull request related calls you should see the repositoryId based calls and what the ApiUrl formatting looks like.  As part of making this change we need to implement the repositoryId versions of these calls (unless for some reason it turns out they arent supported... the only way to tell is to probe the github api and see if they work!). One other thing we need to sort out with this new API is whether it supports Pagination or not.  If it does, we need to have overloads for the GetAll methods that take ApiOptions. This is looking \ud83d\udc8e  @gdziadkiewicz \n\n\nThanks for all your work on this... I'll pull it down tonight and run through the integration tests, then should be good to merge \ud83d\udc4f . Integration tests are good, although we still need to add the pagination integration tests (eg https://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/ReleasesClientTests.cs#L200-L310 ). OK the test worked for me, i made a couple of tidy ups.  Im having a heck of a time with the test accounts though.  Due to using octocat, my test account got banned/flagged for abuse!  I got in unlocked and tried to create 2 test accounts \"octokitnet-test1\" and \"octokitnet-test2\" to use for these tests but those accounts are also now flagged (eventhough they didnt have any activity).  I managed to get all the tests to pass by using my real username and a friend's real username, but I dont want to check that change in.. The 2 test accounts I created (and am using in the integration tests) should be unblocked now and the tests are working for me.  \nCan I get you to review the changes I pushed up @gdziadkiewicz and let me know you're happy?  Once you give the thumbs up Im good to merge this in. \nGreat work @gdziadkiewicz thanks for contributing this new API implementation to octokit!. release_notes: Implement Pull Request Review Requests API (Preview). This sounds really weird.\nCan you post more details (eg the type of application and whether this is during a single application life cycle or across separate program executions) and also the exception and stack trace details of the initial exception and also the one \"after connection restored\"? . . release_notes: Fix even more IssueTimelineClient deserialization exceptions by adding even more new EventInfoState values (this is getting old!). release_notes: Remove unused Rx-Main dependency from LINQPad samples. We had a sort of proof of concept of a way to handle this in #1504 which essentially would see all response enums contain an extra member (eg OctokitUnsupportedValue) that could be used when encountering an unknown value, whilst also exposing a string xxxxxRaw property containing the unparsed api return value.  But it didn't necessarily feel quite right so I hadn't pushed it too hard.  I do quite like the elegance of @khellang's suggestion above. Even better :+1:. Closing this since the specific missing properties is resolved in #1591 and the ongoing improvements to handle Enums in a more resilient fashion is in #1595. So we don't currently regularly release alpha packages to nuget... that one release was actually a special case to expose our dotnetcore port to a wider audience\nYou can add the appveyor CI feed to your nuget settings and pull packages from there if you need \nMy plan is once we've merged the dotnetcore and CAKE build script (should be soon) we'll look at automating pre release packages pushed to nuget on each PR merged to master\n. @This is cool!  I've pulled it down to have a play.\nI think we should convert ALL response models that have an enum property, to wrap it in StringEnum<>\nI've pushed a a convention test to pick them all up, and help us ensure we keep to this convention moving forward :+1:\nNext, Ill push up some changes to the actual response models to satisfy the convention tests. Hmm so there are a few curve balls when actually running this... \nIn our SimpleJsonSerializer we take care of converting github api values that contain hyphens or underscores into our C# enum values, for example utf-8 in GitHub API is Utf8 in Octokit, and base_ref_changed is BaseRefChanged so the current implementation fails in ParsedValue to parse enum values from strings that contain these characters.  Our deserializer also handles having properties added to enum values to allow us to customize what string representation a given enum value should have, for example in the Reaction API, we have api value of +1 which maps to c# enum value of Plus1.  \nIt's not nice to duplicate this \"API enum strategy\" code in both the JsonSerializer and the StringEnum.ParseValue() so I've rejigged the SimpleJsonSerializer to expose a DeserializeEnum(string value, Type type) function, that can now be used in both places.  Let me know what you think, Im about to push the commit up. I also found that in the implicit conversion of TEnum to StringEnum<TEnum> the ctor needed to serialize the passed in TEnum value to a string using our \"GitHub API strategy\" rather than just ToString() (so that we get the \"correct\" string value taking into account property mappings etc)... otherwise something like this was failing in Integration Tests:\nAssert.Equal(ReactionType.Plus1, response.Content)\nThis is because when ToString() was used, the StringEnum.Value property was \"Plus1\" when it needs to be \"+1\" in order to match the true StringEnum<ReactionType> as returned fro the API call (due to the custom [Property(value=\"+1\")] attribute on those enum values, to map the GitHub api string to our eunm name).\nWith the DeserializeEnum and SerializeEnum changes I've just pushed up, I now have a bunch of integration tests working without needing any code changes.\nGiven the nature of these changes, I'll look at getting a full integration test run done as part of merging this PR (the CI builds dont run integration tests). Ive now run all the integration tests on this branch and confirmed everything is good :+1:. lol I already had done some work locally but all good... ive pushed up the convention test for the Parameter attribute on enum members. Yes I was thinking the same about having maybe StringValue and Value.  \nAlthough I do wonder if it's too much of a surprise for a property called Value to potentially throw an exception?. Yeah agree it's better than current explosions \ud83d\ude01 \nIn terms of getting people over to using TryParse I guess the most we can do is update some doco/examples with some guidance (and perhaps write our integration tests that access enums in the same way we would expect others to access enums).\nThe problem for me is that I personally find out vars a real ugly pain and feel like they hamper efforts to have clean/elegant code when you have to declare the variable on a separate line etc... but that is obviously the standard way c# handles these type of things currently (in c# 7 there is an inline out var option i believe, and of course tuples to think about, but for now it seems TryParse is the way to go, and at least people have an option in their own control to deal with unknown API response exceptions without having to wait for a new release that added the new enum members. \u2764\ufe0f Awesome pickups @khellang on those enum values that have been incorrect forever \ud83d\ude1b \nSo as I see it, now we have [Parameter()] attributes on all the enums so now we can take the bold step of removing the magic \"eat hyphens and underscores\" in the deserializer to truly cement this change and make sure we are obeying only the explicit parameter definitions.\nBut in order to do this, literally EVERY response/request enum must have the attribute, so that means we either have to get Language done too, or we turn it into a string.  I guess from a search request perspective, we want to give users a helpful hand in letting them pick from nicely named languages, rather than needing to know the exact string/case the API wants, so I think there is value in providing it as an enum.  But Im thinking perhaps this would be a case where if we make it a StringEnum on the Rerquest model, users also have an option to provide a string value (if the API has a language we dont yet support) . \nNot sure how we missed it but StringEnum.Equals was comparing itself to itself, rather than itself to other LOL!\nLuckily it was causing an integration test for Repository Migrations to fail (the test creates a migration and loops until the status is Exported (a StringEnum value) but the test was not waiting for the correct status due to the StringEnum Equals comparison not actually comparing against the \"other\" value). I changed the SImpleJsonSerializer to get rid of the magic hyphen/underscore eating, and have run all integration tests locally, so Im going to push those changes up.\nThe few remaining things I want us to tackle on this PR are\nsort out Language enum (I'm keen to not exclude it from the tests and even change the Request model to use StringEnum<Language> \nConsider if we want to add Destructure extensions for c# 7 (may as well, right?)\nWrite up a doc page about how octokit now deals with enums and how consuers should be accessing them\nIll add a TODO list to the first post. Yep!  Sounds about right :+1:. Looks like it's only the Search related requests, as other places that deal with language (eg responses for repositories, repository languages, gists) are already just using strings.. OK so based on our conversations in https://github.com/khellang/octokit.net/issues/1 we are going to leave the Language enum alone for now... so I think this PR is done from a dev point of view.  @khellang are you sure we dont want to add destructure extensions now?  \nThe last thing to do is write up some doc/guidance about how we handle response enums (and see whether any existing doc/samples should be changed). Awesome, I think we're done in terms of coding! \njust need to get something written up in docs about the new enum usage . Finally got some time to knock up a quick doc file on using StringEnum<TEnum, if you guys can take a look and make any suggestions/corrections!. Ok so I finally got my test account banning/flagging issues sorted and ran through all integration tests... Lucky too, as there were 2 event states that use a hyphen rather than underscore that I picked up \nAppveyor isn't posting back to github for some reason but it did complete successfully so I'm going to merge this shortly :+1:. Thanks @khellang for your work on this!\n. release_notes: Provide a robust way to handle unknown enum values returned by GitHub API, to prevent deserialization errors until the enum values can be added to octokit. Maybe just 1 ctor taking each single option and 1 ctor taking all options? . Yeah sounds like it won't be unhonoured very soon. Probably no time to even obsolete it, may need to just remove it. Given its a preview API these things sometimes down occur . I think in that case we normally pass an empty body eg new object() . Based on that API updates blog though, it sounds like as of May 2nd (even in US timezone that's mere hours away) the include_admins may start to cause an error if present?. Sounds like a plan \ud83d\udc4d \nAre you able to rebase your branch on master (or merge master into it) so the diffs of all the Url/string changes etc arent shown on this PR?. AppVeyor only runs unit/convention tests, so to really see what github api thinks of those fields we need to run integration tests locally\nGiven this anouncement though, I'm pretty sure we will be good to remove include_admins now \ud83d\ude1b . Rollin rollin rollin!\nThanks @M-Zuber \ud83d\ude00 \n\n. release_notes: Enhance RepositoryBranchesClient to support Admin Enforcement changes. I think it's fine, I prefer not to force push a branch that others may have pulled already. . . release_notes: Fix Issue documentation samples (GetForRepository() should be GetForRepository()). I wasn't aware of the history (definitely enjoyed reading the epic thread! :popcorn:)\nI am also from the \"don't have a strong opinion\" stance.  The fact it hasn't come up in the 15 months I've been contributing to Octokit would seem to indicate it isnt a hugely requested feature.  Given there are things like StrongNamer now to let others effectively make any of their dependencies strongly named when they need it, without needing the library to be strong named for all other users... is there an actual need to do anything in octokit.net here?\n@AzureMLTest are you able to use StrongNamer on your side to satisfy your requirements?  If there is a valid reason why it's not suitable then we can look at implementing it here, but I didnt like the sound of locking down assembly versions (as I am shooting for full automated builds and releases to nuget) or the fact that this could cause our existing users issues with redirects etc.. Hey @Red-Folder I haven't played too much with the Tree API so I was poking around trying to figure out the answer to your question.  It doesn't sound \"right\" that you'd have to strip things from the list though \nLooking at the API docs https://developer.github.com/v3/git/trees/#create-a-tree I do see that there is a base_tree field that can be set to the sha of the tree you want to update, and we've implemented this BaseTree in NewTree request model. \nSo rather than loop through the entire recursive tree and add them to a new tree, perhaps you can just have a new tree with the changes you wanted, and set it's BaseTree to the sha of the current tree, avoiding the need to include all the other things you didn't actually want to change... Did you try doing that at all? \nIn terms of adding this kind of logic to octokit, currently we haven't provided accelerator/composite methods that make multiple API calls,  and are more focused on providing equivalence to the underlying API methods. So I'd say it's better to have a documented example of \"how to perform complex tasks with octokit\" but probably shy away from directly implementing such things. Happy to discuss though . Ah ok I didn't appreciate the fact that there's no way to delete something except to omit it from a whole new tree ! \nWhat's with needing to exclude anything of type Tree from the new tree though? Did you figure out why that's necessary?  . release_notes: Fix Release documentation samples (ReleaseUpdate should be NewRelease). Hey @jamesqo \nMaybe try our new dotnetcore (netstandard1.1) library and see if that works better. It's not an official release on nuget just yet, but a prerelease package is available if you specify Prerelease flag to get it. Or you could change your feed to our appveyor one . What version of the library are you using? . Ah yep that was our alpha dotnetcore build and won't support source\ndebugging because at the time SourceLink tooling didn't exist for\ndotnetcore.\nPrevious releases it should work...\nAnd the good news that it's already now re/implemented in our dotnetcore\nwork, so will be there in the next release (occuring soon, as few as a\ncouple of things get sorted out).\nYou can grab the  current master build off our appveyor feed if you want to\ntry it out now\nOn 10 Jun 2017 22:47, \"James Ko\" notifications@github.com wrote:\n@ryangribble https://github.com/ryangribble 0.24.1-alpha0001.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/1614#issuecomment-307563124,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AFLIC3qJN24lvsAlMa_y7XP41ZXWcybqks5sCpBsgaJpZM4N1_2U\n.\n. Using 0.23 or the master branch build from appveyor? . For the dotnetcore version on appveyor, you need to be in vs2017 and using the \"new\" sourcelink option \nDetails here : https://github.com/ctaggart/SourceLink. Hi @suchja \n\nBased on the discussion in #1243 I thought this will work.\n\nThe discussion in #1243 actually mentions the following:\n\nOne thing to pay attention to is that requesting a specific issue will not return the repository key.\n\nSo it seems the upstream API response only includes the Repository information sometimes.  Im assuming the logic might be that the API doesn't lookup/include the Repository information, when you had to specify the repository in the API call in the first place.  eg when querying a single or multiple issues from a specified repository, I guess you \"already know\" what the repository is?\nLooking at the tests added in PR #1292 (the \"fix\" for #1243) it seems the only expected responses that do include Repository field are\n- GetAllForCurrent()\n- GetAllForOwnedAndMemberRepositories()\n- GetAllForOrganization(). Hmm so typically we don't so document or note all of the cases where certain fields are or aren't included in API responses, but I can see in this case it would be helpful to do so. \nSo in terms of documentation there is this page but I don't feel like it would be that discoverable there... \nPerhaps the best way to note that this field is not always returned  is to add a note in the xmldoc comment here saying something like the field is only included on queries that span multiple repositories, or something similar. Having it in the xmldoc text means it will show up in intellisense whenever a user is referencing the field in code. Hey @aqwert \nI'd be happy to use the approach they took in the StackExchange one you linked - catch the exception if thrown, and maybe just set the platform/architecture values to \"unknown\" in that case... \nIt would be great if you wanted to fire a PR in to do this!. Just circling back on this one, is this still something you would be interested in contributing @aqwert  ?. No need to apologise :grinning: . Hey @aqwert we were doing some work in this area in #1660 and I included an attempted fix for this issue. \n Are you able to test whether that fixes the issue for you?  You can get the nuget packages for that PR from the appveyor feed. Yeah, currently we have PullRequestReviewRequests and PullRequestReviewComments implemented, but not the actual PullRequestReview's themselves.\nIll mark the issue as \"up for grabs\", is it something you'd like to work on?. Thanks @M-Zuber and @khellang for the LGTM's \ud83d\ude01 . ~~Isn't Config already public in the base NewRepositoryHook class?~~ (never mind, i see it's private set\nPerhaps we just need to add a ctor on NewRepositoryHook that takes all the properties this class has (Name, Config, Events, Active) and use that from the NewRepositoryWebHook.ToRequest() ?  . Not specifically,  but a quick look indicated that the properties of NewRepositoryWebHook are actually put into the Config dictionary so it could get messy if that underlying field can be directly changed as well?  . release_notes: Remove methods and members that were marked [Obsolete] in 0.23 or earlier. Thanks @ctolkien it looks OK, but I'm just wondering what happens if we call ToRequest() on the same  object twice? Since the first one  mutates the underlying Config dictionary, won't the second time throw the exception because the keys are already in the dictionary? . \nThanks @ctolkien . release_notes: NewRepositoryWebHook no longer discards base WebHook fields if they are set. release_notes: NewRepositoryWebHook.ToRequest() no longer discards existing fields if they are set. Hi @patelhrp7 \nHow about this overload on RepositoryContentsClient? . Octokit.net is built you interface with github.com (or github enterprise) API, it doesn't operate on local git repos, sorry. You could look at libgit2 if you want to do local repo stuff . Using the Add and Remove methods is the intended behaviour, similar to adding repositories to search criteria or labels to issues.   Yyou can see some implementations in the integration tests here https://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/IssuesClientTests.cs . Actually there are AddAssignee,  RemoveAssignee  and ClearAssignee methods in IssueUpdate class too \n\nPossible, but at the very least update doco?! :)\n\nFor sure, did you you find incorrect reference somewhere? Would you be able to send a PR to correct? . Thanks @khellang I'm going to close this issue out . Thanks @dvdstelt! \nThere is actually AddAssignee() (and Remove and Clear)  methods that are better to use than the underlying reference type's Add() method if you could update the samples to use that. Same for labels . Thanks @jozefizso !. Hi @jozefizso just checking if you planned to progress this PR any further?. Awesome, yeah i just did a test myself and verified that application/vnd.github.mercy-preview+json,application/vnd.github.scarlet-witch-preview+json returns both code_of_conduct and topics on the returned repository object, so it's nice to see it does support multiple headers when required.\nLeaving the old squash/merge method preview header there is good, in terms of supporting older GitHub Enterprise versions that still have that API in preview.\nSo :+1: on the multiple headers, but can we be explicit about them in the unit test, and also maybe do a more elegant implementation than AcceptHeaders.Foo + \",\" + AcceptHeaders.Bar?\nEg how about a a Concat() function on the AcceptHeaders class?\npublic static string Concat(params string[] headers)\n{\n    return string.Join(\",\", headers);\n}\nSo the usage could be AcceptHeaders.Concat(AcceptHeaders.Foo, AcceptHeaders.Bar) ?. If you want to keep it as a constant maybe forget about the concat function bur declare a new const like \"SquashCommitAndLicensePreviee\" that can be used everywhere required? . Oh sorry, I didnt seem to get notification that you had pushed changes (maybe because you rebase/force pushed).  I'll have a final review . Everything looks pretty good with what's been done so far :+1:\nHowever I realised that we need to add the preview header to more of the calls in IRepositoriesClient so that license info is included in the Repository objects returned.  Eg GetAllForOrg() GetAllForUser() GetAllForCurrent() etc and probably even Create and Edit in theory?. Fair enough regarding the Create() call.\nChanges look good but the one other thing you may not be aware of is that the Reactive implementations make their own API calls for GetAll methods (whereas for single item responses they just pass through the call to the normal API client)... so there are a number of equivalent GetAllPublic() GetAllForOrg() etc calls in ObservableRepositoriesClient that will need the new preview header defined as well.\neg:  https://github.com/octokit/octokit.net/blob/master/Octokit.Reactive/Clients/ObservableRepositoriesClient.cs#L232. @jozefizso just wondering if you still wanted to finish this one off or if you'd like some help to add the ObservableRepositoriesClient stuff?. Simplest in terms of implementation or git branches etc @M-Zuber?\nIf you mean the latter you can just add a remote to @jozefizso's fork then create a local branch from there, that way the original commits are attributes to @jozefizso and the continuation to you. Push it up to your repo and I can update this PR (assuming @jozefizso has ticked the box to allow me to push to the branch) . @M-Zuber you could also do something like this\ngit checkout -b jozefizso-feature/1586-repository-license master\ngit pull https://github.com/jozefizso/octokit.net.git feature/1586-repository-license. Sorry @M-Zuber I must have missed this one!  I've merged your changes into this PR and fixed up a couple of impacted unit tests.  Hopefully get a green build now.... release_notes:  Implement support for Repository Licenses, including adding License property to Repository response model, adding SpxId field to LicenseMetadata response model and a new IRepositoriesClient.GetLicenseContents() call. @alfhenrik how about we do a PR for each of your check list items rather than one massive one? Makes it easier to review and each one is delivering incremental value. I can review this one as soon as I can, and you can start  a new branch for the next one on the list . This is all looking good from a functional/complete perspective... but I'd just like to think about the name of the permissions enum.  We already have an enum Permission that is used when setting permissions with values read write and admin.  In this case there is an extra value none but I dont like calling the response object CollaboratorPermission and the enum CollaboratorPermissions as they are too similar, plus to align with Permission enum, the enum should be singular rather than plural.\nI think keep the response class as CollaboratorPermission and find a new name for the enum - what about EffectivePermission or PermissionLevel?. Thanks muchly @alfhenrik \n. release_notes: Implement ReviewPermission() functionality for OrganizationMembersClient (Preview API). Thanks for advising, can you confirm which nuget package version you're using? \nAlso if you could add a failing test via a PR that would be awesome and help confirm a fix \nCC @mderriey . Thanks @mderriey for taking a look, I hadn't got to it yet!\nAgree that integration tests in both frameworks is going to be painful!\n\ntake a JSON response and try to deserialise it?\n\nThis sounds like a reasonable idea - add some more unit tests around deserializing JSON responses so we can run them for both target frameworks quickly\n. I need to review how that code works but it would be great if you could send a PR to implement the missing payload class! \nin terms of a workaround you could obviously call the github API yourself or use the lower level octokit Connection Get method, but really the easiest way would be to implement the payload class and then use the nuget package from our appveyor feed, until the next official release to nuget.org . I poked a bit more into this and have proposed a workaround that will allow any unsupported event types to be accessed as Json...  please provide input on PR #1645. I've raised #1646 to cover the fact that there are various missing event payloads, so I'll close this issue.  If you feel like implementing the DeleteEvent please send a PR over!  There is some guidance in #1646 about how to implement a new payload. Yeah this would definitely be a cool feature to add!  According to the docs \"most API functions\" will support ETag and/or Last-Modified header... which can be specified in If-NoneMatch or If-ModifiedSince headers on requests, which will return 304 Not Modified response rather than actual data, if no new content was present since the specified ETag/timestamp.\nThe trick is, how to implement it gracefully!\nWe currently expose the ETag (and can also add the LastModified field) header values via the exiting GetLastApiInfo() method, so we are essentially covered on that side of things...\nIn terms of specifying the ETag or ModifiedSince values on requests in a broad/elegant way, we could think about adding support for these on our ApiOptions class which we currently use to specify pagination related settings.  The problem there is that only GetAll methods supported pagination so they were the only ones that had overloads added that take an ApiOptions parameter.  But I guess they are also the most important ones where you want to do ETag based efficient calls anyway.  If it was a single entity \"Get\" request there really isnt much benefit in using this kind of functionality - it's only the \"GetAll\" requests where it would be most useful...  do you agree with that reasoning?\nThings to think about\n- Should we support ETag and Last-Modified?  What happens if one is specified and the API doesnt support it - hopefully this results in an Api error with clear indication of the problem, I'd be happy to bubble that up to the user\n\n\nCan we identify any candidates that are NOT GetAll type calls, that would be good to have this functionality on?  If so we might want to look at having a base ApiOptions that only supports these fields, and change what is currently ApiOptions to something like ApiPaginationOptions that inherits the base one and add the pagination fields.  That way we could use the base one on non GetAll functions\n\n\nHow should we behave when the 304 response is received?  Simply return empty collections?. Hmm that's weird, I also have the .NET core 2.0.0 stuff installed too and things seem to be fine for me using Cake (unsurprising this works as it automatically downloads version 1.0.1 locally if the detected version is not 1.0.1) and VS2017 on windows.  Haven't tried on Mac recently... What environment/method are you using?\n\n\n```\nC:>dotnet --version\n2.0.0-preview2-006497\nC:>where dotnet\nC:\\Program Files\\dotnet\\dotnet.exe\n``. Just tried rawdotnet testfrom commandline in theOctokit.Tests` directory and that worked too.\nNot that Im against adding the global.json per se, just trying to understand why it doesnt seem necessary in my setup.\nHaving a read of this overview it also sounds like SDK 2 tools should be able to do everything for 1.x projects, the only slight affect of having the 2.0 stuff installed is that by default dotnet new would create a 2.x targeting project (unless you have a global.json saying otherwise).. I also found some of the integration tests were failing for me due to using your specific test organization and usernames, but substituting them with the configured test settings (Helper.Organization and Helper.Username) got them working.  I've pushed up that commit.  All tests are now passing for me :+1:. FYI I've hitup GitHub support about the lack of pagination support on the GET endpoint... if they confirm it's a bug we can reinstate this on a future PR.\nThanks @alfhenrik!\n. release_notes: Implement Organization OutsideCollaborators API (Preview). Also need to poke the API to see whether pagination is supported on the \"list\" GetAll() calls and if so, add ApiOptions overloads. There are still a few cases of \"Invite\" rather than \"Invitation\" in various test classes etc, but other than that it looks good!. FYI ive confirmed that the Teams and Organization \"list invites\" methods DO support pagination, so we need ApiOptions overloads on those calls.\nFor the integration tests I have a couple of users you can invite so there are 2 pending invites.  Then you can do pagination tests with PageSize=1\n``` csharp\n            using (var teamContext = await _gitHub.CreateTeamContext(Helper.Organization, new NewTeam(Helper.MakeNameWithTimestamp(\"team\"))))\n            {\n                await _gitHub.Organization.Team.AddMembership(teamContext.TeamId, \"octokitnet-test1\");\n                await _gitHub.Organization.Team.AddMembership(teamContext.TeamId, \"octokitnet-test2\");\n            var pendingInvitations = await _gitHub.Organization.Team.GetAllPendingInvitations(teamContext.TeamId, new ApiOptions { PageSize = 1 });\n            Assert.Equal(1, pendingInvitations.Count);\n            // etc\n        }\n\n```. I just pushed up a couple of tweaks but everything is looking good.  Just have one question I'll mark up now. Hitting the button!  Thanks @alfhenrik \n. release_notes: Implement GetAllPendingInvitations() functionality for OrganizationMembersClient and TeamsClient (Preview API). Hi @Korporal, glad you sorted it out yourself... did you want to post a code snippet of what you ended up with, so someone with the same question can see your solution?. Yeah I was about to say the same thing, my repro gets the expected 404 (NotFoundException).  Using .Result is not great and depending on what your hosting app was it can cause infinite hangs.  Although that might mean we have a .ConfigureAwait(false); missing somewhere.... Since this isn't specifically an octokit issue I'd suggest you make sure your feedback is sent to github support (you could also ask them if there is a way you can tell if a commit is in the main repo or a fork via the API... It's not clear if you already did that or not :grinning:) . Actually I just realised that there are unit tests here covering each of the payload deserialization (using hardcoded json responses) so im not sure if we need the integration tests or not.  On the one hand they are useful since there's no telling whether the upstream API responses may look different to the hardcoded test fixtures but the rarer events do pose a problem in finding them within the 300 events/90day limits on the GitHub events API. @shiftkey @khellang would appreciate your thoughts on this from an implementation POV\n@Norbo11 would this workaround be useful to you, given you had raised #1635 covering the DeleteEvent payload being unsupported currently?. > It gives you a really convenient way to deserialize the JSON into the type you provide, using the custom (GitHub-specific) JSON (de-)serialization settings.\nDo you think there is a use case for consumers providing their own type?  Given how specific the deserializer rules are (eg mapping ruby/snake case to c# camel case, using our [Property] attribute on members or enums to determine the API field mappings etc...  The class has to be \"just right\" and if someone was going to go to that effort it would be preferable they send a PR to add the model officially so everyone can use it?\nThat said I do still like the idea not so that people can BYO response class but more so because it could provide a bit more discoverability and compile time guidance than we currently have.\nEg currently you just \"have to know\" that you can cast the Payload to another type via activity.Payload as PulRequestEventPayload but there is no evidence you can do this, and no indication on what type you should use.\nWhereas if we implemented a method like DeserializeAs<T>() where T: ActivityPayload users would hopefully disover the fact it can be deserialized AND get a compile time check that they are at least specifying a class that derives from ActivityPayload.  \nIm not sure if ActivityPayload itself should be a wrapper class, similar to the StringEnum you implemented @khellang that contains the json string and can provide it as raw json or deserialized to a specific payload type, or whether we would just have a DeserializePayloadAs<T> method on the Activity object itself.  . We could return a dynamic object but I'm not a huge fan of them (and you could do that for yourself anyway from the json string if you want). We also could return our JsonObject class  which I believe comes from \"simple json\" which we use internally as the basis of the deserializer.... \nI figured the string json was the most flexible though . Thanks for the feedback @thedillonb, as you can see above we had a few options regarding how to actually implement this, however I agree that anything is better than how things are now!\nI'll aim to pick this back up and at least get something in . Just noting that StatusEvent will be implemented in #1732 once merged. Nice work guys! I'm thinking we should enable the convention tests on both targets too? \nYeah I was looking at the travis failure, didn't get too far as yet. It complains about the test runner path although we aren't even setting one. The cake guys have merged some PR's recently to add newer dotnet tooling support so we could try updating and seeing if any new options help . Yep I'd been researching this on and off today too and had come across the same item you linked. \nMy thoughts were to work around it as you say, by not running net45 2 targeted tests on non windows platforms . Nice one @mderriey \nI noticed in the appveyor log that there are 4 extra unit tests discovered in net452 target compared to netcoreapp1.0 which is interesting . Since we've got AppVeyor anyway I'm pretty happy with skipping the net452 target unit/convention tests on TravisCI until/if it can \"just work\" without jumping through lots of hoops. Let me know if you're happy for me to :shipit: @mderriey . Thanks @mderriey \n. Ive got a few tweaks I'd like to push up, are you able to turn on the \"allow edits from maintainers\" option in the right hand side bar of this Pull Request?\n\n. Oh I see, I didnt realise you were using master branch in your fork.  As a general advice it's best to use a named branch in your repo so that your master doesn't diverge from upstream (eg this repo) master.. Not yet, integration tests need a lot of work. \nThere's a few tricky things (including the fact that you can't approve/request changes on your own pull request) so I'm just working on a couple of things for this which I'll push up tonight . Ok so I ended up making allowances for specifying a secondary test account which is used to create the PR (so the main test account can perform all review actions on it) \nI also fixed up some of the status enums, the delete methods weren't working and also adding comments to the review wasn't quite right. That's why I always like to go hard on the integration test coverage \ud83d\ude00\nTake a look at what I pushed up and let me know of any comments/issues . Thanks @hartra344 this is a great addition, I'm sure lot's of users will love being able to manage PR Reviews.  Congratulations on your first contribution to octokit.net \ud83c\udf89 \n. release_notes: Implement Pull Request Reviews API. @alfhenrik once this is merged, we should be good to (re)implement pagination support for #1639 . release_notes: Fix pagination on API calls that use Uri parameters (typically for requests that include some form of filtering). release_notes: Implement pagination support for OrganizationOutsideCollaboratorsClient.GetAll() method. Project support ha been merged to master but isn't in an official build yet. If you grab the nuget package from our appveyor fed it should be there. \nWhat you want to do is create a project card for an issue - you specify the issue's id (globally unique id, not the repo issue number) as ContentId and Issue as ContentType.  I think you also need to specify the columnId the card will go into (there are separate API clients for getting the details of the configured columns for a project etc) \ncsharp\nvar newCard = new NewProjectCard(issueId, ProjectCardContentType.Issue);\n        var result = await client.Repository.Project.Card.Create(columnId, newCard);. @mderriey could you have a sanity \ud83d\udc40 before I merge this?. release_notes: Fixed RepositoryCommitsClient.GetSha1() to correctly obtain the sha1 of the specified commit, after the API went from preview to official. Can someone have a final check of the Advisories and Breaking Changes section I added to the release notes?. Travis is having capacity issues with OSX builds, it's been queued for serveral hours.  Given it's just doc updates since the last succesful builds Im going to hit the button on this release!\nEveryone stand back...\n. Thanks @devedse , interesting to see how you are using octokit\n. Yes right, need to check if it's dash or underscore as I copied that kebab cased one from the blog post . OK hopefully that reads better now, thanks @mderriey . All systems are go!\n. The cases where API does support pagination and we havent implemented it, have been excluded from convention tests and issues raised to fix each client.. release_notes: Add convention tests to enforce API Pagination support and naming conventions. Downloading the artifacts from AppVeyor, things are looking pretty :gem:\nNuget package info/version is \u2705 \nAssembly/File Version is numeric 0.27.0 \u2705 \nProduct version includes the pre-release version (in this case, -PullRequest1660) \u2705 \n. release_notes: Assembly versioning, NuGet package metadata and inter-package version dependencies should now be correct, after automating them via the build process. @mderriey can you take a \ud83d\udc40 and let me know what you think?. Fixed up the wording.\nThe version dependency of Octokit.Reactive on Octokit is annoying... things were looking so nice and straight forward!  We will have to dig into this. OK sounds like for the time being we need to use a workaround of specifying the version on the dotnet restore.  This is because the \\Octokit.Reactive\\obj\\project.assets.json file is used for the dotnet pack version dependency stuff, and it's contents are set at dotnet restore time. \nhttps://github.com/NuGet/Home/issues/4337\nTesting locally looks good, let's see what ApVeyor spits out. \n\n. release_notes: Octokit can now run in environments where PlatformNotSupported exception was encountered when initializing the API connection (eg AWS Lambda). > Should I refactor the existing method to return a Task> instead to be consistent with all the other .GetAll methods?\nSounds good to me \ud83d\udc4d. release_notes: Implement additional fields in Team response and NewTeam and UpdateTeam requests, for Privacy, Maintainers and Description where they were missing. advisories: NewTeam.Permission has been changed to a nullable type Permission? and will no longer be sent unless explicitly set. Im going to merge this today unless anyone has any concerns. release_notes: Implement team membership enhancements for role (Maintainer or Member) and state (Active or Pending) including new methods TeamsClient.AddOrEditMembership() and TeamsClient.GetMembershipDetails() and updating TeamsClient.GetAllMembers() to allow filtering by role.. anyone able to have a \ud83d\udc40 at this?  Id like to merge this and #1682 then cut a new release. Thanks @M-Zuber I've updated the obsolete message to be more consistent with others. Thanks @sepharg!\nCould you please add an integration test that verifies all returned repos are from the requested organization?\nAre there any other missing filter options on code search that we should implement at the same time? . Thanks @sepharg , I ran the integration test but it failed due to specifying a blank search term and using the incorrect owner Url \ud83d\ude00   But I've pushed a couple of fixes to your branch and its all \u2705 now\nI'll just wait for AppVeyor and TravisCI to give the go ahead then I'll be right to merge it!. release_notes: Implement Organization filter in ISearchClient.SearchCode(). Awesome stuff @sepharg thanks heaps for the contribution!  Hope to see more from you in the future \ud83d\ude00 \n. No worries, due to how many integration tests we have, we cant run them from AppVeyor or Travis at the moment!  I will pull down the branch and run them locally before merging a PR.\nWhat IDE are you using?  To run individual tests we would normally use the Test Runner in Visual Studio 2017.  There is also some setup required which is covered in the CONTRIBUTING guide.  If you do want any help to get your environment setup, drop into our gitter chat and we can help you\nThanks again for the PR!. Thanks for the fix @mderriey! \nIn vs2017 alot of these csproj properties can even be set in the GUI... Just have to remember to look! . release_notes: Intellisense should once again be available for Octokit libraries - sorry about that!. Confirmed by consuming the nuget packages from the AppVeyor CI feed :+1:\nMany thanks @mderriey \n. release_notes: BranchProtection response class EnforceAdmins now provides a standard ctor allowing it to be mocked if required. . release_notes: ISearchClient.SearchRepo() now uses the correct values for the Forks search qualifiers (Include or Only). This is a pretty minor change, and the tests I added are passing, but it would be good if someone can give it a quick \ud83d\udc40  to make sure I havent missed anything. thanks @M-Zuber . release_notes: Implement Nested Teams API (Preview). Looking into this a bit more I think it's because my calling application is running various tasks in parallel - it must be hitting a timing issue with the Dictionary<Type, Dictionary<object, object>> _cachedEnums from GitHubSerializerStrategy of which we have a static instance in SimpleJsonSerializer!  static readonly GitHubSerializerStrategy _serializationStrategy = new GitHubSerializerStrategy(); thus making it not threadsafe.\nTracing through the code, if (_cachedEnums[type].ContainsKey(value)) is returning false but when it then attempts to _cachedEnums[type].Add(value, parsed); it throws the exception that the key already esxists (another thread has just put it in there).\nIt seems an easy fix would be to change _cachedEnumsto the ThreadsafeDictionary helper class like other parts of SimpleJson are using (or we could use the framework's ConcurrentDictionary). Interestingly it looks like this unit test run just ran into this issue. Yep it doesn't matter which endpoints as it's related to the internals of the deserializer class.  The workaround at the moment is to use separate instances of GitHubClient for each thread.  The proper fix is to implement thread safe dictionaries which I hope to get to when I have a chance (but PR's are very much welcome as well! \ud83d\ude00 ). Im not sure where the 4e2918d5f8cd4a4461eca1d6da37eda1 comes from sorry!  There appears to be a different value for each file in the pull requestr.  Perhaps its a blob or tree SHA or something else you might be able to get at, via the git data api? . In terms of the original problem raised in the issue it sounds like you were getting into crazy async/await territory and getting a deadlock situation... we \"should\" have all of our awaits properly configured with .ConfigureAwait(false) as per #1248 but it's possible to have missed some.  I'll flick through the particular calls and double check.\nIn terms of your comment about needing to make so many API calls, yes indeed it is the case with REST APIs but the good news is that GitHub have a GraphQL API available in preview, which is an entirely different paradigm and allows you to make single requests grabbing graphs of information (eg pull requests meeting some criteria, with user comment and commit details, but only the fields you want instead of the entire objects etc) rather than lots and lots of REST calls.  There is also some great work going on in an Octokit implementation for this at Octokit.GraphQL which is currently in Alpha, if you wanted to kick the tyres :+1:. \ud83c\udfa2 . . Whilst I'm not opposed to the change, were you aware that there are already overloads (that don't take a path parameter) which operate on the root directory of the repository?\nhttps://github.com/octokit/octokit.net/blob/1e474f8556018ade97cc2d065aadb73aade74ca9/Octokit/Clients/IRepositoryContentsClient.cs#L48\nhttps://github.com/octokit/octokit.net/blob/1e474f8556018ade97cc2d065aadb73aade74ca9/Octokit/Clients/IRepositoryContentsClient.cs#L58\nhttps://github.com/octokit/octokit.net/blob/1e474f8556018ade97cc2d065aadb73aade74ca9/Octokit/Clients/IRepositoryContentsClient.cs#L96\nhttps://github.com/octokit/octokit.net/blob/1e474f8556018ade97cc2d065aadb73aade74ca9/Octokit/Clients/IRepositoryContentsClient.cs#L108\n. It obviously isn't too discoverable though, given you didn't spot them...  \nIf we implicitly support an empty string via a different overload anyway, I dont have an issue with allowing the empty string to be explicitly passed in as path.  So I'd be happy to still take this PR if you got the tests passing and updated the XmlDoc comment for the parameter to note that \"Pass empty string for the root directory\". I also can't find much in the REST API spec for this info.  The repo statistics are probably the closest thing?\nhttps://developer.github.com/v3/repos/statistics/. I think most of the data for the other tabs (community, traffic,forks etc) is available in the API, but some of the sections like PULSE or NETWORK do not appear to be exposed directly in the API\nhttps://developer.github.com/v3/repos/community/\nhttps://developer.github.com/v3/repos/traffic/\nhttps://developer.github.com/v3/repos/forks/\nSome of these things are implemented in octokit.net and some wont be (but we are always happy to work with you to implement things that are wanted/needed!). Thanks @prashantvc . Thanks @gdziadkiewicz looking forward to it as you make progress :)\nBy the way, it looks like your master branch isnt up to date with this repo's master branch, so you might want to rebase your branch on upstream/master. No worries, I will take a look. We need ti updates these tests to use dual test accounts (as inviting octocat user is probably what has caused your test account to get flagged)\nIf you look elsewhere we have a [DualAccountTest] setup where you have 2 test accounts configured, so your main one can invite your second one, without upsetting a \"real\" user like octocat . release_notes: Add pagination support to RepositoryInvitationsClient. Nice one @gdziadkiewicz thanks for addressing those review items and thanks for another completed PR  \ud83d\udc4d \n. Thanks @pmiossec !\nAny reason why you've gone with an extra function call rather than adding a parameter to the constructors?  In your usage would you only set this larger timeout value right before you do an assett upload, and then reset it again for other calls, or would you set the timeout once globally and have all calls use the larger timeout value?. Yeah the constructors are a bit messy... I agree perhaps leave it to the discrete method call.  Since it is more likely people would change timeout only when uploading a large asset, then change timeout back again afterwards, this should be ok. Can you set \"The timeout value\" xml comment on the other cases too please? \u263a\nLast thing, it would be great to have a unit test that \"proves\" this works. \nSomething like mock out an IHttpClient then create a githubclient/connection using the mock, call the new SetTimeout method and verify the mock's timeout was changed. \nI'm on my phone so can't say exactly how to do it right now, let me know if you need more help . Thanks @pmiossec I just mad a couple of tidy ups to the xml comments and renamed the function to SetRequestTimeout from SetRequestsTimeout for consistency with the codebase :+1:. release_notes: You can now use IGitHubClient.SetRequestTimeout(TimeSpan timeout) to set a custom timeout, particularly useful for lengthy operations such as uploading release assets.. Thanks heaps @pmiossec !\n. No apology necessary,  we all do this in our spare time when life permits \ud83d\ude1d \njust wanted to make sure you weren't stuck . I've raised a ticket with GitHub support about the API pagination not being honoured for the subnamespace call\nRepro:\n\u2705  https://api.github.com/repos/octokit/octokit.net/git/refs?per_page=1\n\ud83d\udc80 https://api.github.com/repos/octokit/octokit.net/git/refs/tags?per_page=1\n. To get the travis build passing, pull in latest master to your branch :+1:\nIn terms of the pagination issue up stream, GitHub support confirmed it's a problem although it looks like it still isnt fixed.  I think it should be fine to leave it implemented in octokit as is, since hopefully they will fix it eventually \ud83d\ude01 . release_notes: Add pagination support to ReferencesClient. Thanks @gdziadkiewicz !!!\n. Thanks @scovetta! . release_notes: Correct rendering of HttpClient documentation page. Hi @it19862 \nWe have upgraded to .NET Core project system so you will need Visual Studio 2017 to open the solution.  Alternatively you can use VSCode, or our CAKE build scripts, as mentioned in the CONTRIBUTING guide\nI do notice we still have a mention of Visual Studio 2015 on that page - sorry!  We need to update this to say VS2017 \ud83d\ude1b . Thanks @kzu I'm mobile at the moment but I'll check this out over the weekend . Just taking a look at this now... the ctor of the CommitStatus class should be updated from int to long as well...\nOnce that's done I should be good to merge :+1:. We've started using long for newer response models we've added but still have int in use in lots of places.  We probably need to think about broader changes to update alot of these to long otherwise it seems like eventually we will run into these overflow problems elsewhere.  \nFrom a quick search:\n\\Models\\Response\\Account.cs(104)\n\\Models\\Response\\Author.cs(34)\n\\Models\\Response\\Authorization.cs(36)\n\\Models\\Response\\CommitComment.cs(30)\n\\Models\\Response\\DeployKey.cs(19)\n\\Models\\Response\\Deployment.cs(32)\n\\Models\\Response\\DeploymentStatus.cs(30)\n\\Models\\Response\\EventInfo.cs(29)\n\\Models\\Response\\GistComment.cs(25)\n\\Models\\Response\\GpgKey.cs(13)\n\\Models\\Response\\Issue.cs(43)\n\\Models\\Response\\IssueComment.cs(27)\n\\Models\\Response\\IssueEvent.cs(29)\n\\Models\\Response\\Migration.cs(49)\n\\Models\\Response\\OrganizationMembershipInvitation.cs(25)\n\\Models\\Response\\Project.cs(39)\n\\Models\\Response\\ProjectCard.cs(36)\n\\Models\\Response\\ProjectColumn.cs(24)\n\\Models\\Response\\PublicKey.cs(19)\n\\Models\\Response\\PullRequestReviewComment.cs(44)\n\\Models\\Response\\Reaction.cs(43)\n\\Models\\Response\\Release.cs(49)\n\\Models\\Response\\ReleaseAsset.cs(30)\n\\Models\\Response\\RepositoryHook.cs(28)\n\\Models\\Response\\RepositoryInvitation.cs(37)\n\\Models\\Response\\SourceInfo.cs(10)\n\\Models\\Response\\Team.cs(37)\n\\Models\\Response\\TimelineEventInfo.cs(27). Thanks for updating the ctor. Yeah looks we best get this released ASAP\n\n. release_notes: Update CommitStatus.Id field from int to long to prevent overflow exceptions. advisories: This release has been pushed out in response to CommitStatus.Id on GitHub exceeding Int32.MaxValue.  We've made this field a long now... sorry about that!. v0.28 has been pushed to NuGet, can you guys please confirm we are good?!  Thanks. Are you saying you want to access the \"topics\" for a given repo?. Hi @it19862 \nWhat are Topics?\n\"Chrome extension\" is a TOPIC.\nA Repository can have as many TOPICs as the owner wants.\nBUT a TOPIC does not own a repository... it is like a tag or label on a repository, that can group repositories together that have similar topics.  \nDoes that make sense?\nHere is some further information: \nhttps://github.com/blog/2309-introducing-topics\nhttps://help.github.com/articles/about-topics/\nCan we search for repositories by topic?\nYes It is possible to search for repositories with a topic: https://help.github.com/articles/searching-repositories/#search-by-repository-topic\nBut we have not implemented TOPICS in octokit.net yet!\nTo implement this support we would need to:\n- Add Topic field to Repository and use preview header to enable the field to be returned from the API\n- Add Topic field to SearchRepositoriesRequest so you can search by topic\n- Add Topics field to SearchRepositoriesRequest so you can search by number of topics. I've raised #1707 to cover implementing this support in Octokit. The API documentation for Repository search is here: https://developer.github.com/v3/search/#search-repositories\nAnswer to your questions:\n\n\nOption 2\n\n\nI believe the search keywords are \"AND\" logic by default.\napi github is api AND github\n\"api github\" is \"api github\" as a phrase\n\n\nGithub.com search by default searches Name AND Description.  https://help.github.com/articles/searching-repositories/#search-by-repository-topic\n(but you can search in README as well by specifying the in: qualifier. Im not sure what the problem is, but the projects definitely work in VS2017 for other developers/contributors of this project, and myself on several different machines.\n\n\nFrom your error message it sounds like you somehow don't have the .NET Core SDK installed. There is a work on progress PR #1721 but the contributors dropped off. I'm currently focusing on the checks API stuff so it would be wonderful if you could help on that PR if you've got a use case for the topics support @MikhailTymchukDX? . Hi @BarbourSmith , the documentation you are referring to is for octokit.js the javascript API client, whilst this is the c# client.  It looks like we still haven't had any traction on finishing that old PR #1721 off, so as of now Repository Topics are still not supported in the c# client unfortauntely \ud83d\ude1e . Thanks @alanmcgovern, as you've realised we've already had #1703 submitted so I'll close this one :+1:. . If you load a single PullRequest with Get operation, is the field populated then? \nSome response fields are only provided on a single record request and not on a GetAll request.\n. Yes. \nAs @shiftkey outlined, if you want to check the commit status values you can do that with other API calls . Hi @sepharg, we generally shy away from implementing higher order logic like making composite/multiple API calls on behalf of the consumer, or building in retry/throttling type behaviour in the library itself, because there are too many potential use cases to implement in a way that would suit everyone. \nThe rate limit and abuse exception classes should include details on  when it's safe to try again, so consumers can implement their own response to this, in a way that suits their particular implementation. . Yes I ran into this myself and have a local build using that implicit package reference to get around it \nWe don't actually target netcoreapp 1.1 intentionally, it's just that the newer build tools automatically use 1.6.1 netstandard library meta package (which aws lambda build tools detect and think you are netcoreapp 1.1)\nI was hoping lambda would support 2.0 already . From what I saw the pretty much indicated they wouldn't be likely to support 1.1 eventhough it's now LTS \ud83d\ude1d\nI'll push up a PR for the local change I was using for my octokit lambda demo . Can you foresee any issues with this @mderriey @shiftkey  ?. release_notes: Ensure the netstandard1.1 targeted package is compatible with AWS Lambda netcoreapp1.0 environment, by explicitly specifying the NetStandard.Library meta-package version. I don't think this should break anything based on my own testing, but there's only one real way to find out...\n. Thanks @gdziadkiewicz it definitely pays to have more obvious \"warning\" \n. release_notes: Add InReplyToId property to PullRequestReviewComment response model, to indicate when a comment is in reply to another comment. Thanks @thedillonb  \ud83c\udf86 \n\n. Whoa I didn't even realise we had an ApiClient in the codebase that didn't use the ApiClient base class, nice pickup! \ud83c\udf89 \nI guess the only thing is that in order to prove these changes are good, we will need integration tests for all the methods in this client, not just the paginated ones \ud83d\ude09 . This is already implemented as CreateReply \ud83d\ude2e. Thanks @hnrkndrssn \nClosed by #1845. Hi @MuazOthman just wondering if you still want this PR kept open?. Hi @jozefizso it would be awesome if you wanted to pick this one up! . Thanks @shaggygi \n. TravisCI is having some sort of issue at the moment, I'll check back later and see if it's working. Cool, found some guidance here that indicated the 1.0.1 sdk package isnt available in the package feed travis is now using.  Updated to 1.0.4 and all is well again :+1:. release_notes: Add UpdatedAt property to Milestone response model, to indicate when it was last updated. Oh this is probably my fault as I raised #1717 without realising it is already implemented as CrrateReply rather than an overload of Create. @grokys how does this look?. release_notes: OAuthClient now handles GitHub Enterprise instances correctly in CreateAccessToken() and GetGitHubLoginUrl() methods. Hey @adriangodong, we haven't implemented any of the github apps stuff yet so definitely keen to see what you come up with . Hi @Xwilarg \nThe github API returns sparser results when getting \"all\" objects, compared to when getting a single object. \nIf you load a single commit, the Files member should be present then\neg\nclientGitHub.Repository.Commit.Get(r.Id, c.Sha)\nObviously this is inefficient to do this for many commits so ideally you can have some way to filter down on the commits you need to load first . Ouch, I'm not sure it's a good idea to try and do all that raw processing yourself\nWhat about the repository statistics endpoints, maybe the contributor breakdown there would give you something useful? \nhttps://developer.github.com/v3/repos/statistics/#get-contributors-list-with-additions-deletions-and-commit-counts. Hi @grapehunter I've updated PR #1726 to fix the CreateAccessToken url, does that look good to you?\n\nBy the way,please take serveral minutes to check all address of enterprise, it's a horrible disaster\n\nDo you have any other examples? I use octokit against our GHE instance and haven't found any incorrect url's with the methods I'm calling... . shall we close this one in favour of #1738 ?. Hi @itaibh \nThanks for the PR... in order to better understand your intentions could you please provide a brief description?   also to understand whether you think you are \"done\" or not, would could you please mark [WIP] in the title if you aren't done yet, and also provide a task list that are checked/unchecked, so we know what you still aim to do? \nEg in this case a new payload class needs to be added to the special switch statement in the deserializer code and of course we need tests to prove it actually works \ud83d\ude01. Looks good @itaibh , if you have finished working on it, can you remove [WIP] (work in progress) from the PR title so we know it's ready ffrom your perspective?. release_notes: Support StatusEvent payloads, using new response model StatusEventPayload. Thanks @itaibh and congratulations on your first octokit contribution!\n. The github API returns sparser results for \"GetAll\" type queries, so you might need to load each PR individually to have all fields fully populated.\nOnce you have the list from your search query, try loading each one with PullRequest.Get() and check if the fields have the data you want?\nIf you check out my Octokit.ReleaseNotes project there is an example of taking a list of PR's and loading all the details about them in parallel which might be useful for you here . We try to keep Octokit as an API wrapper that reflects the upstream GitHub API structure and calls, so since the upstream API doesn't have a mechanism to flag that you want \"fully populated\" responses in \"Get All\" type requests (presumably for performance reasons), it's not really something that would be implemented in Octokit either.\nNote, the successor to the v3 REST API is the v4 GraphQL API and GraphQL allows more control over specifying exactly what fields you want returned in responses etc.  This isnt something we support in Octokit today but is something we are looking at (you of course could talk to it with your own code or another library though). Can you add unit tests that deserialize example json with both formats of date fields? . Can't remember off the tip of my head, I think it's Unix epoch time...  we have a helper method elsewhere in the code base . Here you go :  https://github.com/octokit/octokit.net/blob/c9b2c1260bc87b7782d4fd9645d43a8885203923/Octokit/Helpers/UnixTimeStampExtensions.cs#L16\nIt's an extension method on long. As a follow up we should review other places we are using the extension method FromUnixTime() or otherwise dealing with long members for dates on API responses, and consider changing them to simply be DateTimeOffset now that the deserializer will automatically handle the conversion :+1:. Refer #825 and #1731 for related disussions. release_notes: Octokit now handles DateTime and DateTimeOffset response fields whose API response is in an unexpected Unix epoch time format. Thanks @itaibh \n. Hmmm our examples in integration tests often create new branches (create a git blob, then a tree, then a  then a commit, then a branch) \nhttps://github.com/octokit/octokit.net/blob/5e892325218600499a9943b4ff4ebd190e5a82ad/Octokit.Tests.Integration/Clients/PullRequestReviewRequestsClientTests.cs#L260\nIn those cases the repo already is initialised so the commit is created with a parent commit of the existing master branch commit, but checking the docs for creating a commit says if you specify a blank parent sha it's written to the root of the repo. \nSo hopefully you could try that? . Hi @mirsaeedi the reasoning is simply that the remaining API rate limit is returned in the response headers of all calls, so we may as well provide a mechanism to access that information :)\nIt would be awesome if you wanted to send a PR to implement the actual Rate Limit API though, then users can choose the method that is more appropriate for them :+1:. Fixed by #1742. I'll take a look in the next day or two thanks\nWe still need to add unit tests and integration tests though \ud83e\udd23. At a minimum we need unit tests before I'm comfortable to merge new features, and then before cutting a release (which I plan to do as soon as this feature is in) I also need to run integration tests to ensure things actually work! \nI'm happy to help with the tests if you like, also not too worried about the review size, as I prefer to deliver a feature and it's tests in one merge to master :+1: . What are you running the integration tests via?  Most of the contributors to the project are using Visual Studio 2017 and to be honest, that's probably the only way to effectively run the integration tests are there are way too many of them to run \"everything\" at once from command line or CAKE build task etc, so you really want the ability to select which tests to run. Ah sorry, I thought you had previously made a comment about doing this on linux!\nIn VS2017 in the test explorer you should be able to just select \"Debug Selected Tests\" rather than \"Run Selected Tests\" and it should then hit breakpoints that you have setup.\nUnfortunately with automated tests (and perhaps specifically XUnit) you cant actually get console output to print as it gets swallowed.  There seems to be a long and sordid internet debate/commenting on this issue if you google it Im sure you can read lots about why this is so \ud83d\ude01   If you really have to see something you can write text to a file which is horrible \ud83d\ude31 but generally debugging with breakpoints should \"just work\".... \nBack to the topic of this PR I was just checking out the API docs for the GitHub Apps implementation and it looks like we have a bit of reworking to do of the structure and naming of things.  Apologies for not noticing this sooner, and I appreciate you had picked up another PR that had already set this direciton... but it's important that we have consistency with the official docs and the upstream API we are wrapping, as well as consistency across the code base in terms of naming things and structure.  Feel free to let me know if you aren't keen to make these changes, and I can take over instead :+1:\nWe want to match the octokit structure to the API doc structure, so given the docs are like this:\n\nWe shouldn't really have GitHubClient.Application and GitHubClient.Installation both at that top level (the Installation should be a child of Application).   Also instead of Application it should be named GitHubApp (as a property) and GitHubAppsClient (class name) so we match the terminology of the API docs as well.\nInfact looking at it more, that whole \"Installations\" area is actually a different set of API calls that are used once you are authenticated as a GitHubApp installation (same as the \"Marketplace\" area)...\nThe calls being implemented in this pull request are \nget the authenticated github app\ncreate new installation token\nlist installations for user \nall of which actually live in the \"GitHubApps\" section (not in the \"Installations\" section or in an \"Access Tokens\" section).  This is all rather confusing but appears to be the way it is in the official upstream API\n \ud83e\udd14 \nSo what I actually think we need to do is\n- delete the InstallationsClient and AccessTokensClient classes\n- rename ApplicationsClient to GitHubAppsClient \n- implement all 3 methods in GitHubAppsClient using consistent octokit method naming which would be called \n  - GetCurrent()\n  - CreateInstallationToken()\n  - GetAllInstallationsForCurrent(). Sorry @itaibh I had somehow missed that you had pushed the requested changes a while ago... Will get stuck into reviewing them tonight\nCheers . @itaibh it's on the list to review, have been quite busy sorry!. This is tough to review sorry as it's a brand new area.  A few things I noticed\n\n\nApplication response model already exists from years ago and is being re-used here, but doesnt have all of the fields of the actual response object and also has a Url field which doesnt map.  We may have to create a new GitHubApp response model for this stuff\n\n\nWe probably need to implement more of the endpoints such as Get for an app, GetInstallation for an installation and GetAllForUser in order to support GitHubApp stuff enough to be useful to end users?\n\n\nXmlDocument tags on the clients and response model fields will be necessary to provide intellisense guidance to users\n\n\nIntegration tests - we need to figure out how/if we can flesh out our integration test framework to handle doing these calls as a GitHubApp\n\n\nSome of the endpoints (such as list installations or generate installation token) require being authenticated as the GitHubApp which means we have to do the FWT token stuff and so on, we might need to think about whether we provide helper methods around this or just expect the consumers to have created the JWT from their app's certificate etc already. Oh, forgot to mention that the initial round of requested changed regarding naming things and re-arranging the methods etc looks pretty good, thanks :+1:. ive pushed up some of the mentioned stuff (implenting the Get(string slug) method to get an app, and also implementing the GitHubApp response model instead of re-using Application.. Before it goes to master we need xmldoc comments, unit tests and integration tests at a minimum. \n\n\nBut as I mentioned I think we also need a more complete implementation and some solution around the JWT tokens as what we have so far probably isn't enough for end users to make good use of at the moment... So you disagree? \nIf you want to test what we have so far, you can get nuget packages from this PR build from our appveyor feed :+1:. From my perspective we currently have no evidence that these calls even work because we don't have working integration tests. Unit tests make sure we call the correct url or correctly assert nulls etc but we need integration test to prove we actually \"work\" and handle the response from the API \nWe also need xmldoc comments on the client methods and member attributes of the response classes. \nAnd given this is a new/complex feature we also need a sample/doc page about how to do this GitHubApp stuff  \nSo do you already have a working example where you create a signed JWT token using the private cert of an authorised app? . Im happy with the approach to split it, and yes I do agree the JWT stuff doesnt necessarily belong in Octokit (however we need to be able to do it for integration tests, and we need to be able to tell users HOW to do it, so maybe your GitHubJWT stuff in todo-bot could be pulled out into it's own nuget package?).  \nEven if we split the PR up in order to deliver the foundational Credential and token creation parts first, Im still keen to abide by our standards of each piece needing to tick certain boxes to merge to master (namely consistency in naming/code base hygiene, unit test coverage, integration test that excercises the function, xml doc comments for intellisense guidance and any updates to samples/documentation which particularly for GitHubApps being an entire new thing, is important). That's awesome, although if it's targeting netstandard 2.0 we won't be able to use it since we are targeting netstandard 1.1... Does it require anything that isn't available for 1.1?. > .NET Core 1.0 has limited support for PEM files. I did not try .NET Core 1.1 since AWS Lambda has never supported the version. AWS Lambda recently added support for 2.0 and that cleared all the issues.\n\nThe test project itself can target netcoreapp2.0 and use both netstandard1.1 and netstandard2.0 libraries without issue. I'd expect Octokit stays at netstandard1.1 but any consumer that wants to use this specific library to generate JWT will need to run on netcoreapp2.0.\nIf I have some time, I can try out .NET Core 1.1 and see if there's any issue.\n\nYes this is true, we can make the test projects netcoreapp2.0 however I guess the thing to think about is more just a design principle that in general a library should target the lowest netstandard version it can get away with, in order to be able to be used by the largest possible number of applications, whilst an application should target the highest possible netstandard version that supports the platforms it should be run on.  So being a library I would suggest the JWT should target a lower netstandard if possible.  Also don't be confused between netstandard and netcoreapp (netstandard1.1  is still supported by netcoreapp1.0 so can still run on AWS Lambda (prior to them implementing netcoreapp2.0 runtime (as long as you use the explicit metapackage reference 1.6.0 like we had to do in #1713). I've pushed up some changes... let me know what you think @itaibh . \nI agree this can just be \"initial support\" but that doesn't mean we get to skip the \"standard\" things that get a PR mergeable - unit tests, integration tests and documentation \ud83d\ude09 \nI also reverted some unrelated commits that were fixing up stuff in other files unrelated to GitHubApps - let's keep this PR focused on GitHubApps implementation so it is easier to review and look at new PR's for those other fixups (incidentally I had also already made some of the same XmlDoc corrections for missing attributes, which ive pushed up on #1779)\nFrom my perspective the remaining things to do on this PR are to implement Unit Tests for the Reactive client, and to hopefully get at least a basic integration test working (eg authenticate as a test GitHubApp with JWT token, create an installation token, then access some other endpoint).  Now that @adriangodong has provided the GitHub.JWT package I think this should be doable. > sorry for the merges and reverts, my git client got me confused a little bit. \ud83d\ude33\nHmm your last commit actually reverted all the changes I made \ud83d\ude2e \nIll push up a commit to re-instate them!. \n. @itaibh im not sure what's going on but you seem to be doing merges and reverting changes we already have in master back to previously (bad) versions.\nEG:\n\n. OK ive updated the integration tests to netstandard2.0 and using your library to generate the JWT automatically @adriangodong (thanks! \ud83d\udc8e )\nIve also had a first crack at writing up some doco if everyone could please have a look\nLast issue to look at is the builds being broken because we need the 2.0 runtime on our appveyor and travis images now.... > wrapped in an empty Installation object, perhaps we should do something about it\nYeah it's not so nice using the whole response class when only the Id property is returned. Could you create a new response class for this? Maybe it could be calledInstallationSummary or InstallationPayload...\n\nI think you should mention that in the docs to help developers get the access token for an installation in case they need it for tasks like creating status notifications\n\nHow do you envisage people using it (via receiving the event as a webhook or by querying the activity events API?).   Supporting webhooks better is something I'd like to add (on a separate PR!) because at the moment users would have to use our deserializer directly... Is that what you do in your implementation using octokit?  \nCan you provide a code sample or add to the doc file I started to show how you would envisage using the activity payload installation id currently?  . Thanks for the updates but for consistency with the rest of the octokit.net approach I don't want to have \"comfort\" methods in response models that call client api's etc so could this please be removed? It's just there are hundreds of places this could be done, so it doesn't make sense to only do it here, and it's not something I'd want to start doing and proliferating across the code base. Our design is aimed at being a c# wrapper around the upstream API and mirroring the structure and behaviour of that\nSo while it's a great idea it doesn't belong in the core library... Perhaps if it's something you want to undertake, you could develop an \"extensions\" repo with its own nuget package, that uses extension methods and so on, to provide the more object oriented comfort features you are wanting. . Today is the day folks!  Sorry for the delays, I was trying to chase down sourcelink issues on TravisCI which I thought may have been related to moving to the SDK2.0 tooling but probably weren't in the end.  Since the GitHubJWT library doesnt require netcoreapp2 anyomre anyway, I wont worry about tooling updates in this PR.\nAppreciate the patience and many thanks to everyone who helped with this PR, especially @adriangodong and @itaibh.  Integration tests have been passing as I've been running them every now and then for the last few weeks so I'm happy to merge this and start putting together the next release \ud83d\ude01 \n\n. release_notes: Add initial support for GitHub Apps, see the documentation for further information. Many thanks @mirsaeedi !  I just wanted to check that there aren't any other missing fields for this response class while we're here, but it looks like this was the only missing one :+1:. release_notes: Add PullRequestReviewId property to PullRequestReviewComment response model, to indicate which PullRequestReview the comment is related to. . > Because when GetAllForRepository is running I don't have any access to GetLastApiInfo() method via events or callbacks\nThe GetAllXXX() methods will all have an override that takes an ApiOptions parameter, that allows you to specify the StartPage (amongst other pagination settings).  When you don't pass an ApiOptions to the call, octokit automatically retrieves all pages for you, which sounds like where you are going to run into trouble on large repositories.\nBut you can easily control this yourself by writing your own loop that uses ApiOptions to get 1 page, then check your remaining rate limit and either delay or go around the loop again.. Yep definitely keen to add the node_id fields and would be great to get a PR!\nDue to the large number of response objects (and even larger number of method calls) that will include this field (and now need to include the jean-grey preview header) there is going to be an unfortunate amount of code churn (every Http Get/Post etc will have to specify the accepts header) PLUS all the unit tests have to be adjusted since there is one that checks the URL and headers for each call \ud83e\udd14 \nI'd be open to doing this in a more sane way for this sweeping change, until it's out of preview.  Perhaps appending this accepts header onto EVERY call we make, in the Connection.SendDataInternal() method (that every call ultimately routes through) could be an option.  This means it's provided on every call and also means unit tests don't need adjusting (because they are testing against the higher level Connection methods).  A quick hack doing this shows only 3 unit tests that will need adjusting...\nIn my previous experience with GitHub API I haven't seen issues when sending accepts headers to calls which don't actually want them (they just appear to be ignored) but I suppose there is some level of risk in doing this on EVERY CALL\n@shiftkey @kytrinyx what do you think about the risk (or otherwise) of sending the jean-grey header on all API calls?. Tagging @gr2m for thoughts on accept header abuse too \ud83d\ude01 . Just to loop back on this one, there are some fundamental differences between octokit.net being a c# based \"object oriented\" implementation, vs octokit/js being more dynamic that come into play here.  On the javascript side, you can give users control over preview headers if you want, and simply return them back the dynamic json responses without strong typing (assuming even if you wanted to provide typescript typings for the responses, you wouldnt easily be able to support different types of responses (eg Repository and RepositoryWithLicensePreviewEnabled)?\nMeanwhile on the c# side here, we are deserializing API responses into explicit response objects that are strongly typed.  This means octokit.net itself pretty much needs to decide if we will enable a preview feature and modify the response object accordingly or not.  It's not really something that could easily be made opt in/out.  In theory for the ones that simply add a field, we could allow opting out of it, and the response object would just have a null for the new field.  But sometimes preview features actually change the shape of the response, and we wouldnt be able to support old and new in an elegant way.\nIn general i think the user base is pretty happy to be ever marching forward, and supporting whatever preview functions come along with the ride \ud83d\ude01 \nWhat I was specifically getting at with looping a few other people into this conversation was my thoughts that to easily implement the graphQL node id on sooo many calls, it would be good if we simply used the preview header on all requests (even those that technically dont support it).  Given the upstream API ignores preview headers that arent relevant to it, this seemed like a pretty pragmatic approach to implement this approach without requiring huge code changes (which would then get reverted when the API is no longer in preview).. This is out of preview now anyway, so we dont have to worry about the preview header stuff which complicated things given the large number of endpoints \nNow we can simply add the new field to all of the affected response models . Fixes #1737. Thanks so much @mirsaeedi for tidying up this doco!\n. release_notes: Updated Rate Limits documentation and samples. Fully supported \ud83d\ude01. Fyi we actually support net core 1.0 onwards...\nThough I think it would be better to state netstandard 1.1 rather than a net core version, and possibly hyperlink it to Microsoft page showing the netstandard versions and what each one aligns with . I've updated the PR to show what I mean... do you think this is sufficient?. Yes, .NET Standard versions are cumulative, so by supporting .NET Standard 1.1 any framework that implements 1.1 or later, will be able to consume Octokit\n. release_notes: Update supported platforms in README.md to include .NET Standard 1.1. I don't think so, it's the same as for full framework we state we support 4.5. (we don't explicitly state this also means 4.6 4.6.1 4.6.2 4.7 etc, that's just how .NET framework works) . I believe the build actually does work even for net45 target framework on Linux in TravisCI, because the TravisCI instance is setup with Mono framework. If you don't want to put Mono on your instance, you can edit VSCode's build task configuration (located in .vscode/tasks.json file) and add additional commandline arguments to the dotnet build command, to specify --framework netstandard1.1\neg:\njson\n{\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"taskName\": \"build\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"build\",\n                \"${workspaceFolder}/Octokit/Octokit.csproj\",\n                \"--framework\",\n                \"netstandard1.1\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        }\n    ]\n}\nalthough that is for just one csproj.  you cant do this at the sln level because libraries target netstandard1.1 while test projects target netcoreapp1.0 \ud83e\udd14 \nWe could probably have a better story for development on linux and OSX platforms by either providing some vscode config files in the repo and/or getting the CAKE build script to be fed an option not to build the net45 stuff . Hey @Korporal \nI do believe you are in luck \ud83d\ude04 \nYou can use the Compare Commits call using branch names, and going across forks (see the note there about using USERNAME:branch format for the fork branch)  and the response includes AheadBy and BehindBy summary info :+1: \nSomething like this will hopefully work! \nclient.Repository.Commit.Compare(owner, repo, \"master\", \"USERNAME:branch\")\nPlease let us know if this does the job for you  . I'm thinking if you compared \"master\" to that \"commit sha\" and it HAD already been merged, then the comparison result would indicate (BehindBy >= 0 && AheadBy == 0). However if you are talking about cherry picking commits or squash merges etc I don't think this would work . Glad it's working for you \ud83d\udc4d  . What is your current dotnet SDK installed in the path?\ndotnet --version\nI just tested on a windows machine that has 2.1.2 sdk reported by the above command.  When running the octokit build script it downloads the 1.0.1 runtime into the local .dotnet directory and everything proceeds to work fine.  In order to support the netcoreapp1.0 for AWS Lambda, we did have to use an ImplicitMetaPackageReference setting in the csproj files to stop the build tooling automatically going up to a 1.1 equivalent.  It's all clear as mud but would be interested to know what SDK you currently have (and if not at least 2.1.2 like mine, does upgrading your system to the same as my test box, make things work!?). Also in my case, after the download of the 1.0.1 framework ps1 file and it executing, the .dotnet\\Shared\\Microsoft.NETCore.App\\ contains both 1.0.4 and 1.1.1 folders (it sounds like yours only included 1.0.4 for some reason?). It's funny because I think technically any later sdk could build the projects but in order to execute the test projects (netcoreapp1.0) you need the specific runtime. \nPlus the fact we are using cake frosting as a build script also means you need a runtime for that (and also I just noticed we are targeting netcoreapp1.1 for the cake build project)\nEven the fact the build.ps1 wrapper downloads the runtime if you don't already have it is just to try and make things easier rather than just failing and telling the user to go install the right runtime \nWe can certainly look into making things a bit more consistent. Thanks!  I will run this through integration tests locally tonight, I may even look to add an integration test that uses a Task.WhenAll concurrency to reproduce the problem and confirm this fixes it :+1:. Really struggling to produce a repro of the issue, so i can test the fix \ud83d\ude2c \nIf you have any repro code, let me know @daveaglick  . I've run all the integration tests and am happy with this change.  It would be nice to have a repro test but I've been throwing all sorts of parallel things together, using mocked responses, just the enum deserializer, even running against the actual github API and havent even managed to trigger the failure condition (before this fix is applied).\nUnless you've come up with anything @daveaglick I think it's going to be a YOLO merge for this one \ud83d\ude1d . Cool well given I've run the integration tests succesfully locally, and neither of us are able to get a reliably reproducible scenario, Im happy to merge this :+1:\nThanks heaps for contributing this fix @daveaglick !\n\n. release_notes: Using the same GitHubClient instance from multiple threads in parallel will no longer throw occasional exceptions, after making the GitHubSerializerStrategy internals thread-safe. so is the answer here that in the comparison sense, it doesn report on the commit/file level of the BEHIND changes?  Just like if you have a PR that is behind master, github.com doesnt show you the changes your PR \"doesn't\" have in it's branches, only \"what would change in the base branch if you merge this PR\".  Could you diff in the other direction (B->A rather than A->B) if you want to get the reverse changes?. Sure, feel free to send a PR to clarify this field. You could also include a link to the official docs in a Remarks tag as well, similar to what we do on method calls . having a quick look it seems like you have tab characters there rather than spaces?. that's weird... when im attempting to edit it in the browser editor, they are showing as tabs for me.  The cursor jumps the whole thing in one go, whereas the lines above/below it are moving 1 space at a time. \n I wonder if something is somehow cached on your web browser?\nIll try and edit one of them in the browser editor and see if it works. Yeah that worked ok for me.  Must be something strange happening on your browser\nWhat does my commit https://github.com/octokit/octokit.net/pull/1751/commits/a1d582ef32ed30a5a22034b24db03c09ecb92d73 look like to you?. > From my phone, looks like the remarks are lined up and now the params are off (or are still off, can't recall if last night they too were misaligned).\nOops i think I just missed that line 25 one.  \nAnyway I think all files are fixed now, things look OK from this end at least!. release_notes: Clarified ProductHeaderValue usage to align with GitHub API Docs. Thanks @WeiseCreations for the contribution!\n\n\ud83d\ude01 \ud83d\ude01 \ud83d\ude01 . FYI @IAmHughes some of the commits on this PR are from an unknown (to GitHub) email address, and won't count in your contributions graph.  You can add it as a secondary email address to your profile so that they are included in your account/contributions :+1:\n\n. True, it doesn't have the question mark... But I'm pretty sure everything is tracked by the email address of ultimately. My only issue is it looks odd in the auto generated release notes :\ud83d\ude01\nSome info here https://help.github.com/articles/why-are-my-commits-linked-to-the-wrong-user/. Anonymous email as in it's from a domain github won't recognise? . Thinking about this though, I'm not sure the first sentence makes sense... To me, the files in the comparison dont necessarily correlate to the AheadBy and BehindBy figures do they?  To my understanding, those are the number of commits the head branch is ahead and/or behind the base branch by... but if you consider that even a single file could contain multiple differences that are caused by commits on either the target or the base branch, so the one file has both \"ahead\" and \"behind\" commits to it?  Therefore a file doesnt necessarily constitute an \"Ahead\" or \"Behind\" change.\nThere is however a Status field on each file which indicates whether it is added, removed, edited, in conflict etc... is that more what you wanted?  There is also info on each file about how many lines were added/removed/changed.\nAlso, to answer the actual question (eventhough I dont think you need this in this case)\n\nIs it possible to get the common ancestor?\n\nYes - the MergeBaseCommit property on the CompareResult response is the common ancestor.\nSome more reading on this:\nhttps://stackoverflow.com/a/47817580/5963205\nhttps://stackoverflow.com/a/36627354/5963205. In your example I'd expect x1.txt to have status Added and x2.txt to have status Removed\nSo I think you could still get this info from the files list (status field) of the compare result, rather than needing to resort together common ancestors and so on? . Actually I think I'm probably wrong on that, on my phone so can't verify right now . @Korporal perhaps reaching out to GitHub support is the best approach on this one too.  If you do, could you post the response?. Hi @Andrew-Hanlon \nYou can specify the branch name or any commit sha to start listing commits from, using the CommitRequestrequest model via this overload method . Yeah we try to reflect the upstream github API as much as possible, and that's definitely an oddly named parameter (probably historical reasons). In general github API seem to support a branch,  tag or commit sha in most of the places that want a commit so it's always worth trying\nWe also do try to bubble up these types of guidance/parameter info via xml comments which should appear as intellisense info inside any IDE that supports it, so you should be able to discover/explore these annotations as you are playing with the library \ud83d\udc4d  . Hi @asapferg \nthanks for highlighting this, would you consider contributing a PR to fix this? \nIt's very easy to add a field in octokit, just add the member to the response model with the right name Visibility and it will be populated.. Uh oh... I presume it is probably related to this\nhttps://developer.github.com/changes/2018-02-01-weak-crypto-removal-notice/\nAccording to that the SSL deprecation was in place for one hour just now, and will be permanently disabled on the 22nd\nAssuming you are just using the standard octokit client (with its built-in http provider) it looks like we may need to do something here ASAP \nCan you please confirm \n- you are using the standard octokit client (built in http client)? \n- what octokit.net package version you are on \n- what target framework and platform your app is (eg which framework or core version, is it console app, winforms, Web API, asp.net etc) \n- is it working again now that the 1 hour test has ended? \nI'm going to edit the title of this issue too btw \nThanks . That's correct @Korporal, as @Haacked says, octokit uses the built in http client in .NET Framework, and any apps on earlier than framework 4.6 don't have TLS1.2 available by default (but it can be enabled with that snippet above). \nEventhough it only affects apps targeting earlier framework, since we do support those frameworks and github API connections won't work without this after the 22nd, we'll incorporate this into octokit and push a release soon. \nAffected clients can also include the fix themselves if they can't update for whatever reason. . Hi @asapferg thanks for the PR!  Having a look at the doco, and my own API responses it seems like the visibility property can have a value of private, public or null so it would be best to represent this as an enum rather than just a string.  We have a special StringEnum<T> wrapper class to use for these cases so we can have the benefit of an enum but also be guarded against possible new values being introduced upstream.\nWould you like to have a crack at changing it to a StringEnum<T> type?  Otherwise let me know and I can push a change onto your branch that does this :+1:. #1760 is merged now, if you wanted to merge or rebase master into this branch and see if that clears up the failed tests. Something a bit weird with your merge caused lots of commits to show up. I fixed it up for you and also ran integration tests to make sure things work.  Found an old skipped test that works now so was able to unskip it \ud83d\ude00 . Many thanks for the contribution @asapferg !\n. release_notes: Add Visibility property to EmailAddress response model, to indicate whether a primary email address is Public or Private. @Korporal @Haacked @shiftkey . advisories: On February 22, 2018 19:00 UTC, GitHub will disable permanently the use of weak cryptogrpahic standards.  Applications targeting .NET Framework 4.5.x will be affected, as that framework does not enable the now required protocol (TLS1.2) by default.  This octokit.net release will automatically enable this protocol, when the GitHubClient is constructed.  Note that applications targeting .NET Framework 4.6+ or .NET Core should already have TLS1.2 enabled by default, and this release does nothing with enabled protocols on those platforms.. advisories:  Affected clients that are unable to update octokit.net, can include their own code change to enable TLS1.2 as an alternative to updating to this release.. release_notes: Add TLS1.2 to enabled security protocols (.NET Framework 4.5 only) to avoid SSL connectivity errors when GitHub deprecates weak algorithms on February 22. release_notes: Remove deserializer enum cache miss by correcting the case of AccountType parameter values. Yeah am working on a fix but it gets pretty hairy, I think the fact the StringEnum wrapper had the implicit operator to a string type means you can technically set it to null eventhough you really shouldn't be able to (since its a value type struct) \nIt can also be null if it's a member of a parent class that gets newed up (leaving the StringEnum as a null). \nI'm trying to change its default behaviour to be more like an enum value type (ie default to default(T)) and make it no longer accept nulls in the ctor but I'm now worried how many response models might then blow up because they should really have been made nullable StringEnum<T>?. The serualizer doesn't know about TryParse though, it just calls Value which throws an exception because empty string isn't a valid enum member. \nI've tweaked .Value to return default(T) rather than throw an exception but I'm also wondering whether it should even be \"valid\" to pass a null into the ctor. \nMy reasoning is, if the response may contain nulls or omit a field, then the response class should just declare that member as a nullable type, just like we would do for a regular enum field. Only drama is any current response classes that are relying on the ctor allowing nulls to be passed in will need to be found and changed to declare as nullable. We've got pretty decent integration test coverage though so I'm considering doing this . @khellang could you take a look at the latest stuff?  It contains the commits that change the StringEnum<T> behaviour such that a null passed into the ctor now throws an exception, and an initialised member of type StringEnum<T> now returnss default(T) for Value property.  Thus, it behaves in line with a regular enum.\nI've then gone down the rabbit hole in fixing the serialization side of things.  Ultimately i found the serializer was saving out the entire StringEnum struct as json (ie enumerating all properties and including string_value and value etc) so Ive added special handling for types of StringEnum<T> to get the enum value and then serialize it like a normal enum (taking into account [Parameter()] attributes and the like.. let's see how this looks.  I've removed that \"fallback default(T) behaviour.  But still asserting that null can't be passed into the ctor.\nThe only slightly hinky part is that the serializer blows up on a class with an uninitialized (not nullable) StringEnum<T> member.  Now as you say, given we use this on response classes and not on request classes AND the fact that anywhere it is used it should be declared nullable if it is infact optional... I guess this is OK that the test has that peculiarity (could always make the test class have a ctor that mandates the members be supplied/initialized). Is this looking OK to you @khellang  ?\nJust running through all the integration tests now. Integration tests are \ud83d\udc8e . release_notes: Deserializer now handles nullable StringEnum<T> members. I cant seem to see anything telling in the API responses for comparing commits... and I'm not aware of anything else that could have this info, sorry \ud83e\udd14 \n@shiftkey anything i've missed?. I'll close this out, given you've posted the response from github support. Yeah we only serialise request models, not response models\n@shiftkey the particular error you ran into is with a stringenum wrapper with an empty /unspecified value, which actually happens to be something I ran into with #1760 and am working on fixing\nThere could well be other round trip serialise/deserialise problems after that one is fixed though . @mylodeon I'm interested in doing something about your stated problem (some way to save/load our response objects) but in the meantime there potentially could be other options for you to explore to\nFor example which GetAllForRepository call is this (issues, PR's, commits, etc)? If you don't actually need ALL of them you can use pagination to query data in more manageable chunks, or use search Api's to specify criteria to hone in on what you are looking for (eg PR's of a certain state or issues with a particular tag or whatever)\nYou could also declare your own DTO class with the fields you care about and use automapper to map our responses to your DTO's which you would then be able to persist/serialise as you need to. In my case I'm doing this and storing certain objects via entity framework in a database. Final thought... Because we try to have immutable response classes all the parameters have protected setters and the only way to create them is via a constructor... so I wouldn't think normal desetializers like newtonsoft would be able to instantiate our objects (unless it handles classes where only the constructor can be used)? So I'm thinking using our own serializer/deserializer is probably the only way that is likely to be able to handle things easily. release_notes: Add MergeableState property to PullRequest response model, to indicate additional information about why a pull request can't be merged. . Nothing specific at the moment. Webhook payloads are generally aligned with the activity event response classes but in terms of actually receiving a webhook, extractibg the event type from the http header and then deserialising the payload - octokit doesn't do that sort of thing. \nIt also doesn't belong in the core library IMO however I think it would be appropriate to  have a wrapper/extension nuget package that provided this, similar to how its being done on the node.js octokit modules https://www.npmjs.com/package/@octokit/webhooks. Sounds good! . Thanks @Cyberboss and congrats on your first contribution to the repo!\n. release_notes: Support PullRequestReviewEvent payloads using new response model PullRequestReviewEventPayload. Many thanks @Kaneraz \n . release_notes: Added PreviousFileName field to PullRequestFile response. @Cyberboss just letting you know I havent fogotten about this!  I've been out of town but will get to this this week.  I wanted to add the new field to some integration tests just to prove that it is being exercised correctly. I went to add this to integration tests, only to realise that it only has effect when the PR is from a fork of a repo, back to the repo...  all of our integration tests are for PR's within the same repo and this new field is always false in that case.  So I've done some manual testing of create, update and get requests, and am satisfied this additional field is working :+1:\nI also found 1 minor change was required, as the setter for the new field on NewPullRequest was not accessible\nMany thanks @Cyberboss for another contribution!\n. release_notes: Add MaintainerCanModify field to PullRequest response and NewPullRequest and UpdatePullRequest requests. I'm not sure there is anything specific we can say here regarding octokit. \nWe aim to wrap the upstream REST API, but of course some endpoints are not implemented yet \ud83d\ude01\nIt sounds like your queries are really related to how the github API works and the design decisions around github apps and which endpoints are enabled for apps or not... These are best directed at github support or the github platform forum . So this is a windows forms app?   It's definitely not right that a call should take 10 minutes. If you are able to post more of your code we could try running it on another system. \nYou could also just simplify your example and test your above code in a console application, to see if it has the same problem. From your original issue text )reading via email) I was wondering if you werent aware we had the ApiOptions pagination settings, and users already can write a loop that retrieves each page one by one as they need them (you can also generally specify a larger ItemsPerPage value than the default eg default might be 20 but you can often request 100 per page).  \nBut after your edits and further discussion it seems you just want this to be more abstracted away from the user and effectively to stream chunks of records to the user as they enumerate through the collection?  Isn't that what the Reactive IObservable stuff is meant for?\nIn any case, feel free to play around with whatever implementation you like and put up a PR for discussion/feels...  We do try to avoid breaking changes but we can figure that part out once there is an actual \"better\" implementation to consider. I haven't played with GitHubApps myself but from the documentation there are only a specific set of endpoints they can use \nhttps://developer.github.com/v3/apps/available-endpoints/. That article is written in the past, before GitHubApps existed as they do today. It talks about application oauth flow and as far as I know should still be correct/accurate. \nGitHubApps are a new type of integration which have their own authentication method involving generating a signed time bound JWT token using the private cert of the GitHubApp and always have the identity of the app (or an installation of the app) and don't actually impersonate a user like the earlier oauth flow effectively does. GitHubApps also can only access a selected subset of endpoints . Should this clarification also be made to the other methods in this client? . Hey @Cyberboss, can you tick the \"Allow edits from maintainers\" option on this PR, as I have made this doc update for the other places reference parameter is used (also updated the implementation class, and the IObservableReferencesClient interface and implementation as well) but am unable to push the changes. ah indeed, i was on the wrong branch (you had 2 that were similar) \ud83e\udd26\u200d\u2642\ufe0f . let me know if the updates look ok. release_notes: Clarify the usage of reference parameter in IReferencesClient methods. release_notes: Correct missing/incorrect XmlDoc entries for parameters on some methods. release_notes: Removed a number of [Obsolete] methods, members and constructors inline with our standard deprecation schedule. advisories: The following [Obsolete] items have been removed from octokit, please use the indicated replacements:\nClient Methods\n- OranizationsClient.GetAll() => GetAllForUser()\n- PullRequestsClient.Comment => ReviewComment\n- RepositoryBranchesClient.GetRequiredStatusChecksContexts() => GetAllRequiredStatusChecksContexts()\n- RepositoryBranchesClient.GetProtectedBranchTeamRestrictions() => GetAllProtectedBranchTeamRestrictions()\n- RepositoryBranchesClient.GetProtectedBranchUserRestrictions() => GetAllProtectedBranchUserRestrictions()\n- RepositoryTrafficClient.GetReferrers() => GetAllReferrers()\n- RepositoryTrafficClient.GetPaths() => GetAllPaths()\n- TeamsClient.GetMembership() => GetMembershipDetails()\n- TeamsClient.AddMembership() => AddOrEditMembership()\n- TeamsClient.AddMembership() => AddOrEditMembership()\nRequest Models\n- Remove unwanted ctor's from BranchProtectionUpdateSettings and UpdateTeam\n- NewIssue Assignee => Assignees\n- IssueUpdate Assignee => Assignees\nResponse Models\n- TeamMembership => TeamMembershipDetails. ooh yeah!!  love that nice and tidy build output now \ud83d\udc8e \n. release_notes: Parameter names in validation exception messages are now derived from the parameters themselves, rather than a literal string that was hopefully kept up to date. Love your work @itaibh thanks for helping with the code base consistency \ud83d\ude00 \nSoo many files \ud83d\ude1b - I took a \"spot check\" approach LOL \n. Hi @Licho1,\nWould this be because your assembly doesn't have an InformationalVersionAttribute set or is it not even possible to work around? . release_notes: Update Octokit build tooling to use .NET SDK 2.x (note that this is only an SDK tooling update - Octokit and Octokit.Reactive libraries are still targeting netstandard1.1). Hi @davidhouweling \nIf you're running it through fiddler are you able to post the json response so we can check it against the response object model? Obviously it's a date field but there are a few in the response so would be easy to see exactly which one it is... \nThe mention of 2 calls being made is also interesting, as we do not have any built in retries or anything like that... Could you please post the fiddler details of those too? . Also (and im struggling to remember the complete ins and outs of it) I think I found that DateTime.Parse actually didnt fully honour some of the formatting we receive from GitHub formatted dates (around the \"Z\" character I think).  Ill see if i can find a discussion. Hey @CraigLager \nIt looks like this was a recently added feature last month: https://developer.github.com/changes/2018-02-22-label-description-search-preview/\nAs well as a Description field, there are also some other fields we are missing (Id and Default for example)...\nBased on that feature announcement, the NewLabel and UpdateLabel requests can also be updated to add in the new Description field.\nTo enable this new field, we will have to add the preview header application/vnd.github.symmetra-preview+json to any calls returning, creating or updating labels\nIt would be wonderful if you were willing to contribute any of this support.  If you are, let us know... happy to give further guidance if you require :+1:. Thanks @mkArtakMSFT, \nJust wondering did you just specify the milestone \"foo\" as the search term, or did you specify like \"&milestone=foo\"?\nIt should be easy to add the extra query option, would be great if you could send a pull request through?  :grinning: . release_notes: Add the ability to search issues by milestones, using SearchIssuesRequest.Milestone. Thanks @mkArtak for the PR and congrats on your first contribution to Octokit!\n. Maybe CommitPayload if it appears in places other than push event . Using Webhooks is preferable since github will notify you when something happens, rather than you having to poll for changes\nYou would need to setup a push event webhook, then filter for the branch yourself . Thanks @txdv \n. release_notes: Tidy up code formatting in docs/samples. I'm a bit hesitant to include things like this in the core library, as we try to keep it as much of a lightweight wrapper around the upstream GitHub api as possible.  This is why we don't have \"composite\" actions (involving multiple API calls) or built in caching.  I think it's difficult to match the different use cases and expectations of users when you start doing things like this.  Particularly in this example, it could end up \"sleeping\" for almost an hour.  (I'm also questioning why it has a hardcoded 1 second sleep, after any response is received?)   \nThanks for sharing though, and we can keep this here as an example for anyone wanting to know how they could wrap calls to automatically handle rate limit or abuse retries.  One thing I've been thinking about, is creating a separate NuGet package for Octokit.Extensions that could include more of these additional helpers, without having them in the \"officially supported\" library.... > @ryangribble It makes sense to not include in the base library for your reasons. However, by having the rate limit information return in the header, it is very easy for first time users to almost immediately hit the limit and then have to wade through a lot of documentation to figure out how to prevent it. Thus my recommendation. \nMy concern is that if there was a \"magic\" wrapper that helped people wait out the rate limit then they are even less likely to know what they are doing (or the potential impact they may be causing).  We'd then have people thinking that \"octokit took 30 minutes to execute a simple query\" and things like that \ud83d\ude2e \nI'd definitely be for improving any documentation that wasn't clear in how things work, although I did think we specifically called out how rate limiting works and highlighted the fact that you need to use authenticated requests if you want to be given the more generous rate limits from GitHub.\n\nThe \"1 second\" is from some of the documentation as a recommendation. If it can be removed, I'll remove it from the post so others don't include it if they reuse it.\n\nDid you have a link to this?  The implementation as provided always waits 1 second AFTER a successful response... I think you should only wait if an abuse or rate limit was hit, which your code already does. \n Im not sure it makes sense to always delay 1 second AFTER a successful response\n\nAnother thought, given the challenge of using the library for multiple calls or \"composite\" calls, may be to develop a queue into which the user can submit calls and have the rate limiting done for them. If that is something you'd consider, I'm willing to do the the initial development work on it. I'm just looking for ways to keep others from hitting the problems I did and having to spend all the time wading through the docs to get a workable solution.\n\nAgain, I think things like this really fall out of the domain of an API wrapper... there are so many different ways people may want to implement queuing, rate limit handling or caching, we don't really want the additional complexity in this library.  If you wanted to put together your own extension package, or provide a gist with the code samples, I'd be happy to take a look at the approach, but it wouldn't be something we would include in the core library :+1:. Yeah it was a travis issue\nThis looks good @tasadar2, are we able to add an integration test as well? . thanks @tasadar2 !\nI pushed some tidy ups to the integration tests.\nI also added the implementation for repositoryId as well (all API calls that use owner/repo also have a corresponding endpoint that takes the repositoryId instead).\nDo you mind reviewing the changes I made and let me know if you are good for this to be merged?  \ud83d\ude4f . release_notes: Add an overload to IReleasesClient.Get() that allows retrieving a Release by the associated tag. Thanks @tasadar2 and congrats on your first contribution!\n. Hi @MikhailTymchukDX \nNested Teams is currently a preview API feature which means we have to include a special accepts header in any calls which deal with teams. It looks like our initial implementation in #1682 only did this on the actual TeamsClient methods and missed these other calls in other API clients which deal with teams such as the one you're using (and possibly others?) \nIt's a pretty simple fix, we just need to include the AcceptHeaders.NestedTeamsPreview on any other calls that deal with teams... It would be awesome if you wanted to tackle this and send a PR that fixes this! . Hi @MikhailTymchukDX \nI've done some additional testing and it seems like this is the way the upstream API is behaving at the moment.  Eventhough we are now including the correct preview header, it seems to just make the response include the parent attribute on the team... but doesnt actually seem to include child teams of the parent team that has repository access. \nI'll ask the folks at GitHub if this is intended behaviour or not, because I would agree with you, that the expected outcome would be all teams are listed, even those that have inherited their permissions on the repo via their parent team... Sorry for not closing the loop on this, what I got from folks at GitHub was that they did have an internal issue about this, but also that the documentation does't actualy say this is how it should work (in terms of the sample response)...\nI don't think it's unreasonable to expect child teams should be included though as that is how other endpoints behave... \nBut yes I would say you should also contact support yourself if you want to provide your added feedback about this feature. not sure about those failing integration tests, as they work for me.  \nHave you got your integration environment and test account configured, as per CONTRIBUTING.md?\nDo any integration tests work for you at the moment?. I've put the tests back to specifying the expected accepts header.  Also reinstated the branch protection preview header on the calls it had been removed (this would drop support for earlier enterprise versions where it's still required to be enabled).  We can specify both headers on these calls (for branch protection AND nested teams support). release_notes: \nEnabled additional methods for preview \"Nested Teams\" support:\n  - IRepositoriesClient.GetAllTeams()\n  - IRepositoryBranchesClient.GetAllProtectedBranchTeamRestrictions()\n  - IRepositoryBranchesClient.UpdateProtectedBranchTeamRestrictions()\n  - IRepositoryBranchesClient.AddProtectedBranchTeamRestrictions()\n  - IRepositoryBranchesClient.DeleteProtectedBranchTeamRestrictions(). many thanks @MikhailTymchukDX and congrats on your first contribution to octokit!\n\n. Hey @tasadar2 , thanks for this PR.  I'll need a bit of time to go through it\nIn the meantime, I've merged some other PR's so this one needs a rebase or merge from master.  Thanks!. > I did not find a good overload for a null payload with accept headers. And adding the obvious overload for this scenario would cause ambiguous call issues. So I ended up passing new object() as the payload for the Delete and TriggerDownload methods.\nThat's all good, we've done the same in a few other places as well, when Post or Delete methods don't have a payload.  The overloads on the IConnection calss are a bit out of hand unfortunately, but because they are public it will be a breaking change to clean things up and we try to avoid breaking changes where possible.\n\nIntegration tests are passing using our enterprise instance.\nThat's good to know.  We have an enterprise instance too, but I've never looked into pre-receive environments as yet. Hey @tasadar2 sorry for the delay!  I finally got a chance to run the integration tests against a GHE instance... made a couple of tweaks as you can see in the commits :+1:\n\nThings are good to go from my perspective if you can please review the changes I just pushed up and let me know if you're good too?\n. awesome stuff @tasadar2 I'd love us to get even more GitHub Enterprise features implemented :+1:\nIt reminds me I have some stale PR's that I should rebase and get merged (#1269, #1415 ). . release_notes: Implement Pre Receive Environments API (Preview) for GitHub Enterprise. The request code looks correct and is similar to working examples I use.\nOne thing I note is, when using github.com you don't need to provide a Uri argument to GitHubClient constructor (and actually the Uri should be the API address not the webUi). Although I don't think that would be your issue maybe try without doing that?\nOther than that, does your fork's master branch contain valid commits that could be raised in a PR to the target you are specifying? \nAs a final note, I noticed your test code is targeting THIS repository - we'd prefer if people didn't raise unnecessary PR's or issues in this repo for testing purposes please \ud83d\ude0c (you can create a test account and repo then fork that and use for your own testing). . Hehe I was actually digging into this and wrote a similar test last night myself :grinning:  yours is better though :+1: \nMine did include base class properties but we had even more legit fails in that case... Eg ApplicationAuthorization which inherits Authorization but doesn't allow setting the base class properties via the ctor. . In any case, Im happy to proceed with fixing these failing tests on this PR and see how the changes look.  If you are keen feel free to get stuck into them, otherwise I should have some time later tonight hopefully :+1:\n\nModel type 'Octokit.CommitComment' is missing a constructor with all properties.\nModel type 'Octokit.IssueComment' is missing a constructor with all properties.\nModel type 'Octokit.RenameInfo' is missing a constructor with all properties.\nModel type 'Octokit.Authorization' is missing a constructor with all properties.\nModel type 'Octokit.PullRequestReviewComment' is missing a constructor with all properties.\nModel type 'Octokit.PunchCard' is missing a constructor with all properties.\nModel type 'Octokit.Page' is missing a constructor with all properties.\nModel type 'Octokit.Commit' is missing a constructor with all properties.\nModel type 'Octokit.RateLimit' is missing a constructor with all properties.\nModel type 'Octokit.BranchProtectionRequiredReviews' is missing a constructor with all properties.\nModel type 'Octokit.SourceInfo' is missing a constructor with all properties.\nModel type 'Octokit.Verification' is missing a constructor with all properties.\nModel type 'Octokit.Activity' is missing a constructor with all properties.\nModel type 'Octokit.GitTag' is missing a constructor with all properties.\nModel type 'Octokit.ActivityPayload' is missing a constructor with all properties.\nModel type 'Octokit.DeploymentStatus' is missing a constructor with all properties.\nModel type 'Octokit.Team' is missing a constructor with all properties.\nModel type 'Octokit.Reference' is missing a constructor with all properties.\nModel type 'Octokit.GpgKey' is missing a constructor with all properties.\nModel type 'Octokit.Deployment' is missing a constructor with all properties.\nModel type 'Octokit.CollaboratorPermission' is missing a constructor with all properties.\nModel type 'Octokit.Issue' is missing a constructor with all properties.\nModel type 'Octokit.ReactionSummary' is missing a constructor with all properties.\nModel type 'Octokit.TeamMembershipDetails' is missing a constructor with all properties.\n. I should also mention if we encounter any cases where it doesn't make sense to abide by the convention we can introduce an attribute (decorated at the response class declaration level) to suppress the test for that class, and filter them out in the test . release_notes;  Added convention tests to ensure Response classes have a ctor that exposes all properties (to support mocking). OK so if we include the base class stuff, there are 4 offences.  User and Organization have issues because they pass through the hardcoded AccountType enum value.\n\nThen we have ApplicationAuthorization which actually doesn't call it's base ctor at all (quite odd!)\nhttps://github.com/octokit/octokit.net/blob/c9b2c1260bc87b7782d4fd9645d43a8885203923/Octokit/Models/Response/ApplicationAuthorization.cs#L16\nand Merge which again doesn't pass through to it's base ctor at all\nhttps://github.com/octokit/octokit.net/blob/c9b2c1260bc87b7782d4fd9645d43a8885203923/Octokit/Models/Response/Merge.cs#L13. In terms of the latter 2 I think it will be fine to just add the base ctor to the existing one, and all of the existing parameters that go with it. After all, these ctor really are only useful for creating mock responses, our deserializer uses the parameter less one, and the protected setter properties so the blast radius is pretty small on these and I like the idea of enforcing the convention that all fields could be mocked\nI'm terms of the first 2 I'm thinking the best approach is to add an attribute but rather than suppressing the whole test, the attribute could take a parameter of field names to be exempt. That way we can still enforce the other fields are present, but exempt the Account Type field since it's not valid to create an Organization with any other type\nSound good? . Awesome thanks @tasadar2 \nI've just pushed a change to shorten the attribute name, as although technically correct, that length was hurting my head \ud83e\udd15  \ud83e\udd23 . release_notes: Ensure all response models have appropriate ctor's to allow mocking, and enforce with a convention test. Thanks @tasadar2 \ud83d\udc4f \n. Are you suggesting this could be used instead of the normal or IObservable clients, or in addition to them?\nMy initial reaction is that I wouldn't be too keen to simply add yet MORE duplicates of every client/method, at least not while we have other higher priority things to implement... however happy to have a discussion about this (or anything really!) if you have further thoughts \ud83d\ude01 . Thanks @Cyberboss for jumping on this so quickly... this is an awesome feature and we are very keen to get it implemented in octokit.net \ud83d\ude00 \nI just had a quick \ud83d\udc40at this stage, I should have some more time over the weekend, but here is what jumped out immediately:\n\n\n\"List\" methods should be named GetAllForReference and GetAllForCheckSuite\n\n\nThe annotations shouldnt be in a separate client as we structure our clients based on the API doc structure, so in this case there would be a top level IChecksClient with sub clients of ICheckRunsClient and ICheckSuitesClient.   Annotations would just be methods such as ICheckRunsClient.GetAllAnnotations\n\n\nWe will need to expand our GitHubApp permission class to contain the new check permission\n\n\nA lot of sealed and internal classes which should just be public\n\n\nYou forgot to include the AcceptHeaders.ChecksApiPreview in all the ApiConnection calls \ud83d\ude00 \n\n\nWatch out for the URI's as the owner/repo ones are repos/:owner/:repo/etc whilst the repository ID ones are repositories/:id/etc (you currently have /repositories/ for all). there's alot to review here, would be better to focus on one client at a time, and ensure unit tests and integration tests are passing \ud83d\ude09 \n\n\nA couple of other consistency things:\n\n\nto maintain consistency with other clients, can we list the owner/repo version of a method first, then the repository_id version?  This is because we are POC'ing some code generation tools so consistent ordering is going to be important\n\n\nsimilary, the naming convention for clients is that the class name is plural (which you've done, eg IGitHubCheckRunsClient) but the accessor method is singular.  so in terms of usage, we should be github.Check.Run.GetAllForReference() rather than github.Checks.Runs.GetAllForReference(). yeah ideally in interfaces and implementation classes.  Hopefully the code base is reasonably consistent with this already. Ive split this PR up, to make it easier to get it done.  Please see #1846 for the Check Suites side of things.  Then we can get the Check Runs side done.... Looking pretty \ud83d\udc8e @jozefizso \n\n\nI realised we also need to add preview header into the various GetAll methods in ObservableIssuesLabelsClient as these don't call through to the normal client.\neg: \nhttps://github.com/octokit/octokit.net/blob/master/Octokit.Reactive/Clients/ObservableIssuesLabelsClient.cs#L74. Looks like you got them all \ud83e\udd17\nI'll do a final review tonight...  things are looking pretty good! . advisories: Note that the IssuesLabelsClient.RemoveFromIssue() methods which previously had no return value, will now return an IReadonlyList<Label>.  This change is source compatible but not binary compatible.. release_notes: Implement support for Label API Improvements, including additional fields (Description and Default), emoji support and searching for labels (SearchClient.SearchLabels()). @jozefizso I found a few more methods that needed the preview header, and also decided to implement the final part of the \"enhanced labels API changes\", being the \"search for labels\" call.\nAre you able to review what I've pushed up?  \ud83d\ude4f . Thanks @jozefizso !!!\n. Hi @ghiboz\nwhat permission do you have on the target repository? \n... Because only users with write access can assign labels to issues. release_notes: Fixed error in \"Create Release\" doc sample . Thanks @mungojam . release_notes: Improved the \"Upload Release Asset\" doc sample. Thanks @mungojam . release_notes: Add GraphQL NodeId property to all affected response models. :wave: Hi @sotiriszegiannis \nThe permissions for the actual access token look quite broad, but it would then still depend on what permission the user has on the repo in question, and what exactly you are trying to update.\nCan you provide more details on what you are doing (a code sample would be great)? \nThanks . Coming along nicely \ud83d\udc4d . < Sorry to bug you with this but I'm new to this open source thing and I'm not sure where to ask, so I'll do it in this \"thread\".\n\nMy implementation of the API seems correct to me, I've checked the JSON serializer and (to me at least) it seems like it should be working, but the request sent never actually adds the teams it passes as team_id. Other than that, the integration tests (org -> user and user -> org w/o teams) pass.\n\nWe appreciate all contributions so don't worry if you are new at this.  You've done a great job so far \ud83d\ude00 \nIn terms of the behaviour not seeming to apply the requested teams, I will pull down your branch and run through the tests on my end to see if I also get the same result.\n\nOn another note, about the other end point: it's not listed in the api. It only mentions POST /repos/:owner/:repo/transfer, not repositories/:id/transfer. Is this a case of incomplete documentation? Or does it actually not exist?\nIf it does exist but isn't listed, am I even supposed to try and implement it?\n\nYes these endpoints aren't listed in the docs at every place, however I think \"somewhere\" in the docs they do state that any endpoint taking /repo/:owner/:name also has a /repositories/:id version, and a while ago we decided to implement these in octokit.net for every endpoint (where they exist) because they provide a safer way of interacting with things.  Relevant discussion is here: #1120\nSo yeah, it would be great if we could implement the repositoryId versions as well (assuming they do exist, which they should!). What I think we can do for now is skip the failing tests with a comment saying \"The upstream API doesn't seem to be applying requested Teams at this time\". Good news, I heard back from the folks at github and it sounds like the docs have a typo - the parameter is actually called team_ids so let's rename it and see if your tests then work! . Yeah the travis thing isn't anything you have done... We are unfortunately running into sporadic failures in the sourcelink test step which seem to be network issues. It's happening to others as well . > Everything you asked for in this last batch is fixed, so I'll wait your next revision.\nLOL - you know what?  I think we are \ud83d\udc8e here!  (just waiting to get TravisCI passing) and we will be good to go!. release_notes:  Implement Repository Transfer API (Preview) (RepositoriesClient.Transfer()). \nCongrats on your first octokit.net contribution @wqferr - it is very much appreciated!  Fingers crossed you are keen to keep contributing!. Nobody would really be constructing the RepositoryStatisticsClient themselves I dont think, so probably just in the actual class description intellisense would be fine.  I also think this would be fine since that paralllels what the official docs do (a single call out at the top, for the whole client) rather than repeating it on each method :+1:. sorry @crhairr , I didn't fully tweak to the fact that the docs site auto publishes from master whilst the nuget releases are only when I decide to cut a release...\nI've been falling into the trap of \"just waiting for that one last PR to be done\" before cutting a release, but it's no excuse \ud83d\ude2d \nI'll look to publish one over the weekend!\n. All good, I need to release more frequently, particularly when there are doc changes that get auto published from master... \nI've pushed out a release, please give our GitHub App support a go, and provide any feedback! . Awesome! What method are you using to do the JWT creation out of interest? . the fact we target netstandard1.1 meant we couldn't easily pull in the crypto stuff necessary, but we did refer people to use the GitHubJwt library (and we infact use this in our integration tests as well). \nAre you using a particular nuget package to do the JWT or just the crypto code in your app itself?  I'd also love to know details on what you're building as it'd be great to know what users we are catering to.  If it's not open source, feel free to DM me on twitter. OK, finally finished debugging weird AppVeyor and TravisCI issues and everything is good to go, if I can get a :+1: from someone \ud83d\ude00 . OK I'm hitting the button!\n. I've been wondering about these things too.\nGiven we already have a netstandard1.1 target, according to the .NET Standard compatibility matrix, this alone should already be usable by .NET Framework 4.5 (as long as you use .NET Core SDK 2+ tooling).  So do we even need a net45 target anymore in the first place?  \nI also wonder, if we have the net45 target for people that somehow cant get off that framework, then is it \"just as difficult\" for them to move to 4.5.2 as it would be to 4.6+ (in other words is their issue that making ANY changes is not possible)?  \nCan you share your use case and project frameworks/versions etc and what restrictions you are operating in?  Also can you see any reason why you wouldnt be able to use the netstandard1.1 target, and whether that would work in VSCode?. hmmm so to unpack what you're saying, a full framework app will choose the highest available full framework target but wont ever use a netstandard target even if one exists at a \"higher\" feature level than the full framework option?  Eg a net472 app choosing a net45 version rather than netstandard2.0? yeesh\nWhy then wouldnt we actually prefer to only support netstandard1.x and 2.0 and drop net45/452 entirely?  Is it just the \"ugliness\" of all the included dependencies?  If we had to trade that off against people using later frameworks never being able to tap into the netstandard targets, Im tempted to just do netstandard only?\nIs the following the justification you were thinking, as to why you are including each target?\nnet452 - provide an option for people on \"legacy\" full framework but prefer the supported 4.5.2 option as well as having a targetting pack available allowing use of vscode etc\nnet4X - fuller framework offering to not need to use polyfills, full framework apps will prefer this over the net452 target if they can use it\nnetstandard1.1 - low netstandard offering, based on compatibility matrix would provide an option for things like netoreapp1.0, mono 4.6, xamarin IOS/android/Mac versions prior to the latest and greatest etc (although all of these could also use up to netstandard1.6 so why the 1.1 - the main difference between 1.1 and 1.6 seems to be full framework 4.5/4.5.1/4.6 but you highlighted above that a full framework app would never consume a netstandard library if it also had a netXX option in the same package)?\nnetstandard2.0 - re-baselining on the fuller API surface as per @davidfowl's comment above \nedit: updated based on more thinking/reading. \ud83d\udc4b welcome @davidfowl \nso does that count as \"guidance\" that the preference is to avoid the scary dialog, thus we should continue to support net4X as well as netstandard1.1?  \nAnd to clarify your tweet from the other day, we also should add a netstandard2.0 target to provide a better dependency story for those on newer .NET Core platforms?  And should keep our netstandard1.1 target since that's the only way people on earlier Mono/Xamarin and .NET Core 1.x can access the library?\nAssuming yes, then I guess the result of this Issue discussion is that we should change our current target frameworks (net45,netstandard1.1) to net452,netstandard1.1,netstandard2.0 instead\n. Interesting... this comment_deleted event appears to be undocumented at this stage.\nThanks for finding this @mirsaeedi !  :+1:. release_notes: Add new EventInfoState values (MarkedAsDuplicate, UnmarkedAsDuplicate and CommentDeleted). Hi @mirsaeedi , thanks for the suggestion!. release_notes: Clarify the rate limit Reset field is in UTC. Hi @baonguyen96 \nCan you provide the c# code that produced the error?\nThe API link you provided (getting all repos for a user) doesn't correlate to the the stack trace.  RepositoriesClient.GetAllLanguages() would correspond to https://api.github.com/repos/vinhhoa1/RPG-ZombiesTCC/languages\nWe definitely dont want an exception like this occurring, but I just want to get the repro code in this issue for completeness :+1:. @baonguyen96 can you please take a look at #1831 and let me know if that would suit your needs?  Do you have a preference between returning an empty list or returning a null?  I went with empty list. release_notes: Remove nuget dependency on SourceLink.Create.GitHub package. Hi @MartinDawson , \nThanks for the feedback, and sorry that the walkthrough hasn't managed to convey enough clear detail! \nWe try to strike a balance between re-iterating what the official GitHub documentation says, but not wanting to include too much of their detail in case they change something and ours is then out of date or incorrect.  We therefore include several links to the official docs, and expect that Octokit users should familiarize themselves with those concepts first, before reading our walkthrough.  \nDo you think we need to be more explicit in stating the expectations that users should be following the official doc links, before running through our walkthrough?  \nDo you think we got the balance wrong, and need to include some more overall details about the relationship of PEM certificate => JWT Token => Installation Access Token (eventhough the official docs do cover that)?\nI'll have a crack at reworking the doc, it would be great if you could review what I come up with and provide feedback! :+1:. @MartinDawson could you have a read of this and provide feedback \ud83d\ude4f \nThanks!. release_notes: Revise GitHub Apps walkthrough documentation to provide more clarity. Hmm... I believe that endpoint requires being authenticated as a user, and you are not a user, you are an installation of a GitHub App.  When the app is installed by the user, they choose which repositories it can access (pick from a list, or choose \"All\").  \nIf you look at the API docs, there will be a little \"i\" indicating when the endpoint is accessible by GitHub App or not.\nEG The \"get current user's repos\" is not enabled for GitHub Apps\nhttps://developer.github.com/v3/repos/#list-your-repositories\n\nThe \"get a user's repos\" is though... if you know what username is you want to check\nhttps://developer.github.com/v3/repos/#list-user-repositories\n\nBut I think what you actually may be wanting to do, is get a list of repos the Installation has access to?  \nIf that's the case, then that would be this endpoint but unfortunately we haven't got that implemented in octokit.net yet.  So far we have implemented the basic GitHubApp support such as authentication, listing installations and the various core response models...  You can still do plenty if you know you have access to a repo (eg you received a webhook from it) but we cant yet enumerate/determine all repositories the app can access until we implement those additional endpoints sorry \ud83d\ude4f \nAlthough we hope to get to it as soon as we can, we often tend to be driven by user needs and contributions - so it would be great if you were willing to have a crack at implementing this.  Even just as a headstart, contributions are very useful and appreciated!  :+1:. cc @baonguyen96. release_notes: Fix exception in RepositoriesClient.GetAllLanguages() when no languages exist. Can you provide a small example of what you mean, as I'm not seeing how \"marking all methods as virtual\" really helps you that much, as then you would have to implement basically everything yourself. \nYou already can use your own HttpClient with octokit - so that would be one place you could intercept and handle particular HTTP responses (such as throttling on rate limit exceptions, or automatically retrying).  \nThere are also fantastic libraries such as Polly that would enable you to wrap existing octokit calls with policy handlers to retry or delay things.. Nice one @mirsaeedi \nObviously it's not ideal for you to have copies of the octokit source code in your repo though, so let's find a way to expose the minimum seams needed for you to be able to hook in your extensions.  I'd prefer not to just make all these things public or virtual, however Im sure we could come up with something.  Eg do you only ever need to respond to exceptions?  If so, perhaps we can add a hook into the \"HandleErrors\" section, allowing you to respond differently to the various exceptions at that point.. The GitHub API is not the best way to do hardcore git data manipulation stuff.  Whilst it does have the rudimentary ability to create blobs/trees, commits and references etc, I dont think it would be that easy to get the exact commits from upstream into your fork.  \nSo if you do want to follow the \"traditional pattern\" of git fetch/pull from upstream and push to origin, you should look at libgit2 or interoperating a commandline git client.\nIf you are happy to take a more GitHub based approach (rather than git approach), that WOULD be possible via the API, you could automatically raise a Pull Request from the upstream branch to your fork's branch, then automatically merge it, using the merge option for \"rebase merging\".  I think this would avoid you getting a merge commit on your fork's branch, and thus being transparently up to date with upstream.... git line ending configuration are super complex.  Git clients can have their own settings, repositories can specify their own settings via .gitattributes file, sometimes on a per file/pattern basis, and so on.  Clients can auto convert line endings locally and preserve linux line endings in the repo.\nIf you aren't going to use an actual git client to operate on a file system clone of a git repo (and thus get all the EOL logic for free) I would say you should just pick a line ending (linux format would be my reccomendation) and use that.. Hey @Cyberboss \nThis is ringing a bell... need to look through old issues to see if I can find it.. OK yeah, so that answer is that an overload already exists that has no path parameter, and does the root dir.\nhttps://github.com/octokit/octokit.net/blob/ef1994d86f2a741b0ffbae119631a80083a42608/Octokit/Clients/RepositoryContentsClient.cs#L154-L163\nPreviously an issue and PR #1688 & #1689 were raised to \"fix\" this, but were closed when they realised there was an overload that allowed this already.  As I commented there though, I would be happy to allow empty string on the path overloads as well, if you do want to get a PR in.. Hi @matthid have already fixed in #1822 and will push a new release soon . release_notes: Implemented New API parameters for Project Card archiving (Preview) including ProjectCard.Archived, ProjectCardUpdate.Archived and new ProjectCardRequest request. Thanks @adriangodong :+1: . Unfortunately these changes will break the PushEventPayload class when used with the Events API\nAs mentioned in your linked issue, the problem is that the GitHub push webhook uses vastly different payload/objects to the push event in the events API.\nWhat we need to do here is make \"new\" response models for the webhook side of things, rather than modifying the event side of things.\nI'd suggest renaming all the \"new\" ones as PushWebhookXXX\nSo in other words\n- Instead of changing the PushEventPayload class to have extra/conflicting fields, create a new PushWebhookPayload class\n- Rename CommitPayload to PushWebhookCommit\n- Instead of changing the Commiter class to have extra/conflicting fields, create a new PushWebhookCommitter class\n. im not really sure what you mean sorry.  The push event that we already have, is from the events API activity stream calls, whereas the push event you want is from a webhook.  We currently dont have any code to directly handle a webhook, however if you create the response class you can still use our deserializer to pass the json payload to, and populate the response model.\nAs a first step can you create the response models and push them up?  Then we can see what the best way is to deserialize the webhook payload. In terms of the deserializer code, you might be getting hung up on some of the magic that is in there, for the events API endpoints (but that doesn't have any bearing on what you're trying to do with webhooks).  The magic stuff is to handle Activity responses, which have a Payload property of type ActivtyPayload with some special deserializer code that actually deserializes these as the derived classes.  \nFor a basic webhook, you won't use any of that stuff though... you would have your own API/webserver which receives the webhook.  You would check the X-GitHub-Event http header, and based on the value you would know what webhook type it is and thus what webhook payload type to use.  Then you would call the octokit deserializer, and provide the actual class you want to deserialize into.  \nEg\n``` csharp\nvar eventHeader = \"push\";\nvar payload = \"\";\nif (eventHeader == \"push\")\n{\n  var push = new SimpleJsonSerializer().Deserialize(payload);\n}\nelse if (eventHeader == \"check_run\")\n{\n  var checkRun = new SimpleJsonSerializer().Deserialize(payload);\n}\n```\nThis is the bare bones way to do it... I'm keen to think about how we could add some helpers to the library to make it easier.  The problem is it's not possible to at runtime dynamically deserialize the payload into a specific response type, that the user can know at compile time.  We can do the ugly trick like we do with the event APIs, where the user only gets a base class, which the deserializer has populated with an inheritted/derived class, but the user has to somehow know this, and cast it to the correct type, but I really dont like that.  \nAnother way I was thinking we could do it, is by allowing the user to register their delegate code for the given types they care about, and we could then run that.  This has the advantage of being strongly typed at compile time.  It might look something like this:\n``` csharp\n// Setup code\nOctokit.Webhooks.RegisterWebhookHandler(WebhookType.Push, x => {\n  // x is a PushWebhookPayload\n});\nOctokit.Webhooks.RegisterWebhookHandler(WebhookType.CheckRun, x => {\n  // x is a CheckRunEventPayload\n});\n// When receiving a webhook\nvar headers = request.Headers;\nvar payload = request.Body;\nOctokit.Webhooks.Process(header, payload); // this would switch on the hook type found in the headers, then call any registered handler, passing the deserialized/strongly typed response model into the delegate provided by the user\n```\nNow whether this stuff would belong in this core library or in an addon package Octokit.Webhooks Im still on the fence about.  I'd actually love to provide some common middle ware type approach that could actually handle the webserver/listening part of things too, so that makes me lean towards a separate library to do this stuff\nBut in terms of this PR I think we can just get the response models defined, and see if you can confirm that the first code sample I provided (using the Octokit deserializer directly) is working for you.  We also have heaps more webhook payloads to implement if you want to add any others while you're here :+1:. Hmmm I must have missed that last commit that says it addresses the review comments, I will take a look at this review again . Thanks @jguevara for pointing out we are missing support for Archived.\nI figured it would be even better if we implemented the full archiving API changes so that we can archive repositories using octokit, and search for archived/unarchived repositories and issues/PRs too, so Ive pushed those changes up to your branch \ud83d\ude00 . release_notes: Implement support for Archiving repositories including adding Archived property to Repository response model, adding the ability to archive a repository via UpdateRepository.Archived request, and filtering repo/issues searches with SearchRepositoriesRequest.Archived and SearchIssuesRequest.Archived. Thanks @jguevara !\n. @Cyberboss @StanleyGoldman do you reckon you could take a look before I hit the button?. Yeah check suite's by themself are fairly useless, I'll merge this PR soon and then rebase the check-runs branch and create that PR\nI just realised I missed some integration tests for the repositoryId versions of all the methods for check suites, so I'll add those first then merge . release_notes: Implemented Check Suites component of New Checks Api (Public Beta). @Cyberboss @StanleyGoldman let me know what you think. release_notes: Implemented Check Runs component of New Checks Api (Public Beta). . Thanks for your help in kick-starting this @Cyberboss \ud83d\udc4d. Yes a code sample will be useful however I'd say it's probably just that we don't have a payload class implemented for that particular event. Unfortunately this is an area where we have very sparse coverage (and it would be great if you wanted to help out, you could contribute any missing payload classes in a PR!)\nThese are the ones we have currently: https://github.com/octokit/octokit.net/tree/master/Octokit/Models/Response/ActivityPayloads. Argh!  Yeah, looks like they changed the documentation on the 18th July to say that field is no longer required!\nI will quickly add another PR before I ship this release. Actually I decided to just commit it here on the release branch.  Look ok now @Cyberboss  ?. OK I think this is good to go, will :shipit: in a few hours . Hmmm if this field allows nulls then we probably need to fix it in NewCheckRun request, and CheckRun response as well? \nhttps://github.com/Cyberboss/octokit.net/blob/2388138d33c0f401257c7fe31b6db417464fb60f/Octokit/Models/Request/NewCheckRun.cs#L50\nhttps://github.com/Cyberboss/octokit.net/blob/2388138d33c0f401257c7fe31b6db417464fb60f/Octokit/Models/Response/CheckRun.cs#L71. If it's not allowed to be null on creation then that should be marked as a required field for NewCheckRun then\nBeing null on the update does make sense though, so as not to overwrite the start time, however it wasn't evident whether an update \"adds\" to the initially created CheckRun or whether it \"replaces\" it with an updated one\nI'll need to do some playing around before deciding exactly what this fix needs to cover . release_notes: Adjust StartedAt and Status fields of NewCheckRun and CheckRunUpdate requests, to allow null values, avoiding resetting these to default values when not specified. I tweaked the fields based on checking with GitHub folks on the detailed workings of these requests :+1:\nThanks @Cyberboss for spotting this \n\n. Thanks @d-a-s and sorry for the confusion \ud83d\ude4f \nYour PR actually raises another /facepalm issue which is that the subclient is not named according to our conventions - it should be singular (client.GitHubApp.XXX instead of client.GitHubApps.XXX) - how did we miss that! \ud83e\udd23\nWe will need to look at fixing this up although since there is already a release with GitHubApps we will need to deprecate the old property name over a couple of releases.\nThanks for fixing up the docs!. . release_notes: Fixed code samples in GitHub Apps sample docs to use the correct sub client property name. :eyes: . I think the last thing to do is unit tests for the observable client and ideally integration tests (at least for the things we can easily setup). OK I think im done with adding unit and integration tests for EVERYTHING.  Glad I did this too, as it found a few problems!  \ud83d\ude00 . Hey @StanleyGoldman these latest changes I already had a separate PR for #1857 and I also did them in a way that keeps the old models working for GHE 2.14 since it won't get these changes\nI think I did forget to add the start/end column members but we can just add that to the other PR and keep this one focused on the app/installation endpoints . release_notes: Implement additional endpoints for GitHub Apps to find installations for a given organization, repository or user. release_notes: Implement GitHub Apps Installation API to allow listing all repositories a GitHub App Installation or GitHub App authenticated user has access to. I think these are good to go!\n. I think I've managed to get these changes done to support github.com and also leave the old models/methods intact to continue supporting GHE 2.14\n@shiftkey @StanleyGoldman could you cast your \ud83d\udc40 over this just to double check? \ud83d\ude4f . release_notes: Implement new/changed fields on CheckRunAnnotation response and NewCheckRunAnnotation request models - replace Filename with Path, WarningLevel with AnnotationLevel and add StartColumn and EndColumn. advisories: Due to upstream breaking changes in the CheckRuns API, using check runs against github.com will require using the new/renamed fields on CheckRunAnnotation response and NewCheckRunAnnotation request models.  However the old fields are maintained in octokit.net (marked as deprecated) to continue supporting GitHub Enterprise 2.14, which will not receive these changes.  Users of GHE 2.14 should use the old fields, whilst users of github.com should update to use the new fields. release_notes: Add new method CheckSuitesClient.Rerequest() and mark the old CheckSuitesClient.Request() method as deprecated (this will no longer function on github.com but will continue to be supported on GitHub Enterprise 2.14). After some internal advice, it turns out the /app/installations/... route has been supported since June 2017 so even for GHE we don't need to keep the old one around.  I'll remove the CreateInstallationTokenPreview() method that was added in this PR. Closing this, replaced with #1860. release_notes: Adjust GitHub App Installation Access Token route in line with announced API changes. Hi @ghiboz \nIssues can be raised by anyone, but only users with write access can set labels on issues.\nDo the credentials you're using have write access to the repository? . Yes it is - you need to have write access to the repository to apply the label though. You can use the issues API to set the label on the PR (PR's are also Issues, in API terms) . In github API terms, a pull request is actually a special type of issue (you \nmay have noticed on github that the issue number and pull request number are shared/unique across issues and PR's! ) \nSo you can actually use most of the issue API calls to do things to pull requests (get comments, set labels, milestones, assignees etc) \nso once you create the PR you can use the IssueUpdate request to update it and set the label . Yep! Let us know if you have any problems doing this\nYou can also see the official mention of this in the github docs here: https://developer.github.com/v3/pulls/#labels-assignees-and-milestones. \n. Hi @MylioBill I haven't had a chance to attempt to repro this myself yet as I've been on mobile only.\nGiven there's been no updates I'd guess this is an upstream github API change - the question is whether it's intentional or not. \nYou said removing existing labels fails but adding labels works. Does adding a label and then trying to remove it, result in the same behaviour? \nOut of interest, do these labels in question have emojis in them, or the description field set at all? . Cool, I found out what the problem is here.  Turns out we were accidentally passing a string preview header into the Delete() method as a message body.  This has been the case for sometime and been working OK (I ran these integration tests just a few days ago myself) so something on github.com must have changed where it is validating the body of the DELETE request instead of ignoring it as it must have done previously.\nhttps://github.com/octokit/octokit.net/blob/74dc51a6f567395d0c46d97f7270f959d671573e/Octokit/Http/IApiConnection.cs#L329\nI will put a fix in the next build but in the meantime you could probably use the client.Issue.Update() method to update your issue and remove the label. Hey @StanleyGoldman this is awesome! I've been wanting to get coverage stuff in place. I'm not sure about coverlet, I was planning on following what John Skeet has on https://github.com/nodatime/nodatime (using dotcover I believe) . Hmm I had a feeling you could get dotcover for free on open source projects . Sadly I let this one drift and I'm struggling to get back up to speed on it \ud83d\ude33 \nApart from the obvious merge conflicts, it seems like some other things could possibly need looking at now due to the passage of time... for example this is using a local implementation that runs coverlet.exe as a cake tool directly, whereas the linked issue indicates this may now be merged into the Cake.Coverlet library.\nIm also wanting to understand the implications of changing pdb type to portable, and can spot a few things (like hardcoded paths to coverlet.exe) that should be tidied up (declare coverlet path in a more central place, etc). release_notes: IssueLabelsClient.RemoveFromIssue() no longer fails with a HTTP 400 \"Bad Request\" error from the GitHub Api. Heya @Dalmirog!\nIt's a pretty long history behind this, a pretty good description is in https://github.com/octokit/octokit.net/issues/1616 as well as the other PR's and issues referenced there\nLong story short - only some API issue responses include the repository attribute but to avoid too much mess on our side we generally just have one response model. Hey @mirsaeedi sorry I didn't have a chance to look at this yet... The documentation you linked to is for graphQL API, but this field is also being returned in REST API responses?\nIn the constructors can you remove the =null parts as we don't use default/optional parameters anywhere else so I'd like to stay consistent with that . Oh yes sorry it only looked at the first link and not the others!\nI understand the attempt to make it non breaking but these are only response classes which nobody would really be creating anyway (except in mocked tests) and just from a consistency point of view we don't do this anywhere else so I'd rather not do it now . is this field provided in every API response that returns comments?  If not, it should be nullable (so it can be null when the API doesnt provide it). releaes_notes: Added AuthorAssociation field to IssueComment, PullRequestReview and PullRequestReviewComment response models. Thanks @mirsaeedi !\n. Hi @it19862 \nThere is a lot method to get repository contents in zip format but I don't believe the API had anything for unzipped (although you could loop through and download every file individually it would probably be better to just download the zip then extract it) \nhttps://github.com/octokit/octokit.net/blob/74dc51a6f567395d0c46d97f7270f959d671573e/Octokit/Clients/IRepositoryContentsClient.cs#L158. release_notes: Corrected the issues sample code to use the correct ItemStateFilter enumeration . Thanks @sebastienros! :clap: . Hey @collinbarrett, ApiOptions is our class that controls pagination, but there should be an overload taking the CommitRequest request model, that allows you to provide the filtering details such as path, sha, etc.\nGive that a go and let us know how it goes! . Hi @it19862 \nYou should be able to access a repository license information using the .License property of a Repository class (returned from client.Repository.Get()) \nhttps://github.com/octokit/octokit.net/blob/74dc51a6f567395d0c46d97f7270f959d671573e/Octokit/Models/Response/Repository.cs#L109\nAnd you should be able to get the license file contents using client.Repository.GetLicenseContents()\nhttps://github.com/octokit/octokit.net/blob/74dc51a6f567395d0c46d97f7270f959d671573e/Octokit/Clients/IRepositoriesClient.cs#L562. Hey @MikhailTymchukDX,\nNested Teams support in github means that this is expected behaviour. If a team has a parent team then that child team does \"own\" all the repos they inherit from the parent. \nThe reason your test curl API call doesn't show this, is that nested teams is still in preview mode and requires a custom header to be passed to enable the preview feature. But once the preview is over, the default API behaviour will change to this anyway so there isn't much to be gained in holding onto the old behaviour. \nIn octokit.net we typically implement the preview features because our users generally want the latest and greatest, and unfortunately it's not possible to opt out (except by using a previous version before we implemented the bested teams stuff). As mentioned, it's a dead end to keep relying on the old behaviour anyway so you'll have to adapt at some point \ud83d\ude01\nhttps://developer.github.com/changes/2017-08-30-preview-nested-teams/\nHttps://developer.github.com/v3/teams/#check-if-a-team-manages-a-repository. No worries! \nI don't personally think it's counter intuitive since it's just an inheritance mechanism - so a child team should have all the permissions/repos/access that it's parent does... But everyone does think about things differently! \nWhat's your use case for wanting to not be told about repos that are accessible via inheritance? \nYou should definitely leave your feedback for the github API team on the developer site! . Hey @MartinDawson I'm not entirely sure what you're getting at sorry, it doesn't seem to be related to octokit.net\nYour comment about storing an access token in a cookie/session doesn't sound correct though - if you have human interaction you should use the oauth flow, and if you are a bot type system then you could store an access token in the app settings rather than a session, or better yet use a github app for more granular control on things \nHave you read the info on the github developer site about authentication options? \nhttps://developer.github.com/v3/#authentication\nIf you do have an issue related to this library (octokit.net) can you please clarify a bit more? \nThanks . Ah sorry I thought you were referring to a personal access token \nSo it sounds like the fact there's a chrome extension involved is a complicating factor?  I'm still not quite putting everything together here though sorry - are you developing a chrome extension yourself and trying to have it perform the oauth flow (I can't see how that works since you need github to hit a url to perform some of the flow) or are you saying you have a chrome extension installed that is somehow affecting what you're trying to do with an asp.net website that is trying to do oauth flow with github? . Sorry for the delay @MartinDawson, I'll take a look at reviewing this, this week . Hi @it19862 those are called repository topics. We don't have support in octokit for them just yet, there was an in progress PR but it hasn't been completed. See #1707 and #1721 \nIt would be awesome If you'd like to contribute by helping to complete that PR! . Hey @it19862 ,\nYes you can do this using the IRepositoryContentsClient.GetReadmeHtml() method\nhttps://github.com/octokit/octokit.net/blob/74dc51a6f567395d0c46d97f7270f959d671573e/Octokit/Clients/IRepositoryContentsClient.cs#L140\neg \ncsharp\nvar readmeHtml = await client.Repository.Content.GetReadmeHtml(owner, repo);\nHope that helps!. Hey @Cyberboss sorry I haven't reviewed yet, I'll take a look this week :+1: . Hey @jozefizso :wave:\nThanks for working on this! I'm travelling for work at the moment but will take a look this week and give you some feedback . release_notes: Implement TeamDiscussions API (Preview). Great stuff @jozefizso thank you!!\n. Oops, I just ran the integration tests and had to fix up one failure.  Then I realised there were no integration tests for Get() and GetAll() so I've implemented those.\nWhile doing that though I discovered that we dont have any unit or integration tests here for the ObservableTeamDiscussionsClient methods, which we need.\nAlso the GetAll() method takes a sort parameter if you look at the docs, so we need to create a TeamDiscussionRequest class with SortDirection SortMethod property, and update the GetAll() methods like this:\n``` csharp\npublic Task> GetAll(int teamId, TeamDiscussionRequest request,  ApiOptions options)\n{\n    ...\nreturn ApiConnection.GetAll<TeamDiscussion>(endpoint, request.ToParametersDictionary(), AcceptHeader, options);\n\n}\n```\nI've put a couple of tasks in the pull request body, let me know if you're happy to tackle these or if you'd like me to. Hi @Itmolen1 , Im not quite following your question sorry... to do an OAUTH flow you need to redirect the user to interact with GitHub to provide authorization, then GitHub will hit your API back with a code which you can then exchange for an auth token.\nhttps://github.com/octokit/octokit.net/blob/master/docs/oauth-flow.md\nDoes that help or have I misunderstood your question?. Hi @it19862 \nThis information isnt returned by the underlying API (https://developer.github.com/v3/search) so it isn't possible for us to do this in Octokit.\nIt might be worth looking into the GraphQL API and seeing whether it has this information. > If you think that's fine, have a shot at submitting a change and ensuring the docs reflect this new behaviour..\nWhen the GitHub API returns a 404 we throw a NotFoundException - I'm not sure we want to start changing this behaviour in only some cases to return null instead?. Hi @masakaya :wave:\nIn GitHub API terms, all pull requests are also issues.  So when it comes to things like assignees, labels, etc you can use the issues API calls to get those details for PR's as well.\nJust make sure you use the pullRequest.Number field, when calling any issue related endpoint.\neg\n``` csharp\nvar prNumber = 123;\n// Get the labels for PR #123\nvar labels = await client.Issue.Labels.GetAllForIssue(owner, repo, prNumber);\n// Labels are also returned as part of issue objects so get the whole \"issue\" record for PR #123\nvar issue = await client.Issue.Get(owner, repo, prNumber);\n// And output the name of the first label\nConsole.WriteLine(issue.Labels[0].Name);\n```\nHope that helps!. Hi @patricknolan,\nSince octokit is a client for the github API, we can't add any method that isn't already provided by github API itself\nhttps://developer.github.com/v3/repos/releases/\nSo yes to get the 2nd most recent release you would need to use the GetAll method then take the 2nd item. However I don't think you'd need to sort them yourself as the API should already return them in reverse chronological order. Furthermore if you use the ApiOptions overload you can request only 1 page of results and that will keep things to an efficient single call (our default behaviour is to loop through and call all pages, so you should use the override to control this)\nSee raw API response showing a single page of reverse chronological ordered results:\nhttps://api.github.com/repos/octokit/octokit.net/releases. Hi @patricknolan \nYes it does look like we ignore the time component at the moment.  \nI'm not sure if this is because the time support was added to GitHub after octokit had implemented request or whether it was just an oversight.\nhttps://github.com/octokit/octokit.net/blob/8407369485541b1fce28f1c9c8d5bf5852579c57/Octokit/Models/Request/SearchRepositoriesRequest.cs#L307-L324\nhttps://github.com/octokit/octokit.net/blob/8407369485541b1fce28f1c9c8d5bf5852579c57/Octokit/Models/Request/SearchRepositoriesRequest.cs#L331\nWhat we could do in order to not affect existing behaviour is keep the existing ctors that accept DateTime and mark them [Obsolete], having them continue to only format the query string as YYYYMMDD, then add new ctors that take DateTimeOffset types (giving us timezone info as well) and being formatted out to the full ISO8601 timestamp format including time zone info.  \nThoughts?  \nIf you are keen to send a PR that would be awesome :+1:. :wave: Hi @patricknolan \nThanks for picking this back up!  I'm just trying to get back up to speed...  The changes look pretty good now. \nJust on the [Obsolete] messages, I can see previously I suggested that this wording might be more clear... what do you think?\n\nIn terms of the [Obsolete] messages, can we use these please?\n\"This ctor does not support the time component or timezone and will be removed in a future release. Please use the DateTimeOffset overload instead\"\n\"This method does not support the time component or timezone and will be removed in a future release. Please use the DateTimeOffset overload instead\". As a user you can't rerun them, I've kicked them off again . Yep I think we're good now!  Thanks @patricknolan :+1: \ud83d\udea2 \n\n. You can also identify the merged PR using the issue events API, so the way I've done it in the past is to load all PR's for the equivalent date range, then select only those whose merge event is in the commit list from the comparison API\nCode example we use for our release notes generation is here:\nhttps://github.com/ryangribble/Octokit.ReleaseNotes/blob/master/ReleaseNotes.cs#L241. . release_notes: Implement Require Multiple Approving Reviews for Protected Branches (Preview). breaking_change: BranchProtectionRequiredReviewsUpdate requires new RequiredApprovingReviewCount to be specified when created. releae_notes: Add Slug field to Team response. Hi @crmann1 \nThanks for picking this up! \nSorry for the issue - it looks like an unfortunate side effect of the way later frameworks handle the default case, as obviously by \"or\" ing the value onto the existing setting we were attempting to mitigate old frameworks by ADDING TLS1. 2 to the existing settings! Being an app domain wide setting it's not something we did lightly however we did feel it was the best choice considering github moving to TLS1. 2 would have caused alot of octokit uses on earlier frameworks to stop working, and having each user need to discover what the problem is and then add a line of code to their app seemed pretty messy, thus we put something in the library.\nYour proposed fix looks good, would you like to send it across as a PR? . I've pushed a fix for this, FYI #1936 . Hi @patriksvensson, some of these older endpoints or requests have had fields added to them over time which we've missed in octokit!\nIt would be awesome if you want to send in a PR. \nFYI our convention for optional fields is they should be nullable and should be set via object initialisation syntax (ie not via the ctor) if that helps! \ud83d\ude4f . release_notes: Add additional optional fields Login and AllowSignup to OauthLoginRequest request . \nThanks @patriksvensson sorry for not getting back to this earlier \ud83d\ude4f . Hi :wave:\nWhich download_url property are you referring to? \nThe \"search code\" API response has various fields, which should all be implemented in the octokit.net response model. There is Url GitUrl and HtmlUrl \nhttps://developer.github.com/v3/search/#search-code\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Models/Response/SearchCode.cs\nAlso if you want to get the content of files you can use octokit to do this using the RepositoryContentsClient client,\neg client.Repository.Content.GetXXX(). Ah ok, the API response in your screenshot is not from a \"search code\" query, which is what your octokit.net code is doing.\nTo make the request in your screenshot you would use the repository contents API, client.Repository.Content.GetAlContents() which returns a list of objects of type RepositoryContent which does have the DownloadUrl field you are looking for\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Clients/RepositoryContentsClient.cs#L68. GetAllContents returns a list, so you'd need to access the items in the list using the normal ways you do that in c# (such as iterating the list in a loop, using an index or using c# linq queries like First() Last() Where() etc) . Nice one!. yep, re-triggered appveyor and it's green now\nThanks @devlead . release_notes: Add Labels to PullRequest response model. Thanks @ItsVeryWindy and sorry for the delay!!\n. > both will work on api.github.com and GHE 2.16. Only the former will work on GHE 2.15 and below\nBased on this issue, It sounds like the \"old\" way (ie the raw array, current implementation in this library) is somehow not actually being supported on dotcom.... Actually, I just confirmed the integration tests that use this method are fine, so I think perhaps @Eilon you may have been onto something here \ud83d\ude1d \n\nCould be I was doing something bonkers.\n\n\nI'll close this issue but please re-open it if you do find something further on this...\nAs a separate concern, we should implement support for the newer API call schema, but it does look like GitHub Api is accepting the old array format (generally they are very good with backward compatibility and gating schema changes behind preview headers etc)\n. Hey @Vogel612, this is cool for building locally on a mac/Linux but the only thing is that on travisCI Mac and Linux builds we actually DO build the full framework as the build agent is setup with mono \nSo maybe rather than hardcoding noframework=true in build.sh this should be passed in so we can set false in travis? \nAlso I think the tool install step of the build might still be a problem on Mac/Linux if you don't have mono as it uses nuget (from mono) to pull down gitversion doesn't it ?. I'm thinking if we had \"nofullframework\" mode for local use only, it could skip running gitversion as well as not build the net45 targets you've already implemented . Yep that's what i was thinking - love the warning you added by the way :+1:\nA couple of other thoughts (apologies im on mobile at the moment so I dont have links to affected source code lines etc)\n- We should skip the \"ToolInstaller\" of Gitversion and CodeFormatter tools when running in this mode (since it will fail if mono/nuget etc arent present)\n- The code formatter also wouldn't work on linux/mac without mono (it may even not work WITH mono, i havent tried!) so perhaps that build task should log a warning if it is ever executed in NoFramework mode rather than trying to do stuff and blowing up (assuming it does blow up!)\n- you could change default behaviour of build.sh to run in NoFramework mode by default (so things work for linux/mac local users \"out of the box\".  But then change travis.yml so that it still builds the full framework stuff on tarvis\n- I wonder if it would be clearer to name the mode \"CoreOnly\" rather than \"NoFramework\" and invert the logic (!$NoFramework in the csproj conditions is a bit of a confusing double negative)... thoughts?. > . My bash is somewhere between bad and gruesome, so I don't want to mess around there\nI year ya \ud83e\udd23  \nhow about this though - the cake script could default CoreOnly to be true for Windows and false otherwise. Travis can pass in false which should override the default value.  The bash script should already pass through any parameter provided to it (you should see some already being passed in the travis yml) . The linksources parameter is a good example to follow. Travis passes it in, nothing special for it in the build.sh (it passes all parameters through to cake) and the cake build uses the value provided or uses a default if none specified (here https://github.com/octokit/octokit.net/blob/master/build/Lifetime.cs#L14) \nWe can follow similar approach except default for CoreOnly will be conditional on windows or not \nMy aim here is for a contributor locally on Linux or OSX just runs build.sh and everything just works (without losing anything on the Windows or travis/appveyor side) . There's a section in the build that explicitly logs the value of the parameters, could we add the CoreOnly one to that?\nThis is looking good! I'll do a test on my MacBook today \ud83d\ude01. Great stuff!  Tested on my macbook tonight, works perfectly :+1:\nIs this ready for merging, from your perspective @Vogel612 . Ah sorry @Vogel612 I've been on holidays this week, I'll try to get to it today \ud83d\ude2c. It's all good... I'm doing some serious juggling at the moment so poking is fine/necessary \ud83d\ude00 \nSo I was just doing some final testing and found an issue where on Windows in both VS2017 and dotnet cmdline, it now is only building the netstandard1.1 targets instead of netstandard1.1 and net45.  Makes sense I guess since only Cake currently has the logic to set this flag appropriately\nIf I were to propose the ideal result of this PR, it would be:\n\u2705 Cake builds on CI (appveyor and travis, all OS'es), build both platforms\n\u2705 Cake builds on linux/mac build only netstandard1.1\n\u2705 Cake builds on windows build both platforms\n\u2705 local \"native\" builds on linux/mac build only netstandard1.1\n\u274c  local \"native\" builds on windows build both platforms\nSo far we have 4 out of 5.  Maybe we need to actually set a default value for CoreOnly in MSBuild land, by detecting if on Windows or not?. yeah, sounds like the IsOsPlatform() is the recommended option.  I tested on windows adding your 2nd option to the csproj files and it appears to work :+1:. Tested on windows and mac, plus reviewed the travis and appveyor builds and everything is looking great!  5 out of 5!\nwoohoo!  \n\nThanks for working on this @Vogel612 . release_notes: Adjust Cake and native build configurations to allow building on OSX/Linux out of the box. Hi @GMouron, thanks for this!  It looks good although one thing I noticed when checking the docs is that the create event payload has  master_branch and description fields as well, so it would seem a good idea to add them to the response model in this PR.  What do you think?\nhttps://developer.github.com/v3/activity/events/types/#createevent. >> as well as the content of the events sent by github for the creation of a branch which does not contain them, I've decided to omit these here since, from my understanding, they will never be part of the payload we receive\nOctokit.net uses these payload response classes for the results from \"Activity Event\" Api, which does include repository events and thus does include these fields.\nThe response classes can also be used to deserialise webhook payloads, although we dont natively have support for webhooks, so users doing this would be having to call the SipleJsonSerializer themselves currently.\nSo I think the extra fields should be included, since the current main supported use case in Octokit (the events API) would use them.  They would then just be null for anyone using them from a webhook perspective.\nWhen we implement native webhook support we can consider whether to re-use these payload classes or have new ones specifically for the webhook payloads. release_notes: Support CreateEvent and DeleteEvent payloads, using new response models CreateEventPayload and DeleteEventPayload. Thanks @GMouron!  (we have quite a few payload events that aren't implemented - it would be great if you wanted to add more!)\n. Any reason why you've removed the .dotsettings resharper settings file @astrohart  ?. I'm ok with this change - I agree it is robust and handles both the \"existing\" behaviour where refs/ wasnt specified in the argument, plus works with \"new\" behaviour where you quite rightly point out, a ref received from another endpoint should be able to be passed straight into the delete method and work.\nIt actually stems from the GitHub Api documentation itself, where it indicates the URI for patch and delete calls is /repos/:owner/:repo/git/refs/:ref (ie :ref should not include prefix of refs/) yet on the create call requires the \"fully qualified ref\" to be specified:\n\nref | string | Required. The name of the fully qualified reference (ie:\u00a0refs/heads/master). If it doesn't start with 'refs' and have at least two slashes, it will be rejected.\n\nNevertheless I think this change makes things less surprising and better for users so I'm cool with it... \nI would ask 2 things though:\n- if we no longer require the ref to be formatted in a particular way, could we remove that XmlComment in the code, that tells users not to pass in refs/ ?\n- Since the Update (patch) endpoint has the same behaviour, can we ensure this is also updated/tested in octokit with similar changes?  (i am on mobile so haven't checked if it uses the same ApiUrl overload and/or has the same comment guidance about not passing refs/ in). Hi @Dre-Tas \n\nenabling the user to login through his/her GitHub credentials (email and password), improving the experience.\n\nIm not sure if this is an improved experience, considering that with a token the user has at least some ability to limit your application to certain scopes/functionality, whereas by providing you with their username and password they are open to your application being able to do ANYTHING they can do themselves!\nWith that comment aside though, what you are running into is perhaps a case of unfortunately named parameters.  A GitHub user has a login (their handle - in my case ryangribble) and an email address. \n You can log in to GitHub with either of those (try it on the login screen yourself!).\nMeanwhile the GitHub API requires the actual login field (not the email address) as that is directly used in the URI's to API routes that are called.\nNot to worry though, you can get information about the \"current\" user (ie the one you are authenticating as) using:\ncsharp\nvar user = await client.User.Current();\nYou can then use the user.Login parameter in the other API calls you need to make.\nHope that helps!. release_notes: Prevent previous Tls1.2 fix for earlier frameworks from interfering with .NET 4.7+ SecurityProtocolType.SystemDefault configuration. Hi @aurecchia \nI assume you mean without making an additional \"per repo\" call?  I'm not aware of anything additional to the old conversation you've linked...\nYou could contact github support and see if they have anything else to suggest?\nThe graphQL API would also be an option to retrieve repos with commits/files/branches/refs provides some similar entity that helps determine if they're empty or not, without making multiple calls. You could check out https://github.com/octokit/octokit.graphql.net in that case.... I didn't have anything specific in mind but if you already had other reasons to make individual calls per repo then presumably getting commits, files refs or similar things would reveal the repo was empty\nI'll close out this issue but do let us know if you have any further thoughts or findings . Yeah we use long for id fields on new response classes but something older ones could potentially do with an update. I was actually trying to get info from github internally about which id's were 32bit and which were 64bit but this discussion reminds me I never did get the list \ud83e\udd23. Thanks @matt-richardson \n . I've been meaning to push a release already however there wasn't anything that was urgent/pressing. This PR changes that though so I'll try to do it in the next few days. \nIn the meantime you can pull the package built from merging this PR from our appveyor nuget feed if you need to get back up and running \ud83d\udc4d. Good catch, thanks!. Thanks @shahabhijeet . release_notes: Added sample covering how to create a PR from a fork. Hi @guilhermemoschen \nit would be great to support this new feature, would you be keen to work on a PR to add it? . Thanks @Potapy4 :+1:. release_notes: Add Id field to Label response model. Welcome back @hnrkndrssn!\nI'll have a :eyes: when I can . release_notes: Added pagination support to CommitCommentReactionsClient, IssueCommentReactionsClient, IssueReactionsClient and PullRequestReviewCommentReactionsClient. . release_notes: Added pagination support to MigrationsClient. This looks :+1: to me. . Hi @benmcmorran \nDid you have any more background or context on this change?\nIt seems github docs have changed and I cant actually find the list of language codes that are supported. \n And many of our tests are using values of Csharp or Ruby which have the same name and value haha.\nBut even looking at your C++ example Im find that when doing searches with C++ it is actualy returning results for repo's with language of just C.  Meanwhile using cpp does only find C++ language type repos.  So perhaps our parameter value for the CPlusPlus entry should be cpp and not C++ anyway???\nI cant seem to find the list of languages in docs anywhere anymore...\nhttps://api.github.com/search/repositories?q=test+language:CPlusPlus (clearly wrong, there are all sorts of repos returned)\nhttps://api.github.com/search/repositories?q=test+language:C++ (this still seems incorrect as you get C results)\nhttps://api.github.com/search/repositories?q=test+language:cpp (this is now returning C++ results). I also noticed while reviewing that there is another API preview involving a new field members_allowed_repository_creation_type on Get/Update Organisation endpoints.  Should we include that field also or worry about it on another PR?  (Note that it's possible to specify multiple preview headers using the AcceptHeaders.Concat() helper method). :+1: . Unless I'm totally wrong on this, I thought the <remarks> tag didnt appear in intellisense - and it was only <summary> that does?\nI'm also wondering whether we should embed the full text from GitHub here (what if the text changes in the future?) or whether we could just have a simpler note like \"Note that the GitHub API uses caching on these endpoints, see https://developer.github.com/v3/repos/statistics/#a-word-about-caching for futther details\". FYI this one is implemented similar to the IssueUpdate object with it's list of Labels.  Implemented as a List with public get and private set, then AddLabel() and ClearLabels() functions that manipulate the local private list.\nI guess the difference is that IssueUpdate is a Request model object, whilst in this case the RequiredStatusChecks are in the Response section?  I can make it protected rather than private I guess\n. Oops, can't actually set it to protected or a compile error occurs\nI made a tweak to the convention tests to allow lists that have a private setter, let me know if that's OK\nSee this commit: https://github.com/octokit/octokit.net/commit/eb0106711e201d4046d668d91cccf84009f62fa5\n. Done: https://github.com/TattsGroup/octokit.net/commit/37df149b3ec70b38dfcef858171a239551fa07e1\n. Done: https://github.com/TattsGroup/octokit.net/commit/37df149b3ec70b38dfcef858171a239551fa07e1\n. Just saw the comment about Add* and Clear* methods so they have gone the way of the dodo now :) \n. this change makes it so collection properties with private setters are NOT added to the mutable list.  Otherwise convention tests were failing saying that these properties werent obeying the Response object rules\nThat said, this was just a possible fix that seemed to work for me... definitely looking for feedback from main contributors and can easily remove this commit if required (and try to find another way to satisfy the convention tests)\n. Roger that, I'm the first to admit I haven't quite dealt with this many convention tests etc before, I was definitely hacking my way to success \ud83d\ude00\nI'll see what I can do with the Contexts collection and ditch this incorrect convention test modification \n. I was following an example I saw in another part of the code base where the preview header was defined each time, but I can change it to a class level. \nShould the unit tests use the same define or their own class level define or specify string  each time? \n. At first I wrote all the code based on the github API example, assuming the admin stats endpoint would always send back the \"collection of stats\" regardless of what you asked for, and if you only asked for say \"repos\" then the other items wouldnt be present (and thus would end up null in my c# object).\nBut when doing the integration testing what i actually found was that only the \"All\" method returns back the outside collection (ie collection of stats entries), and all of the other \"specific\" requests only send back their specific json fragment and not the outer collection.  The API doc site only has the \"All\" example and not an example for say \"repo\" so this was a bit of an unexpected surprise :)\nSince I'd already coded it to have an Enum for the type of stats being requested, I took the \"easy\" way out and just populated the specific node in the AdminStats collection that is returned by the ALL stats call.  This meant there is 1 function, 1 return object (with field/s populated as appropriate), and an Enum to specify the type of stats you want.\nThe alternative was to remove the enum and add specific functions for every type of request.\neg\nTask<AdminStats> GetAllStatistics()\nTask<AdminStatsRepo> GetRepoStatistics()\nTask<AdminStatsPullRequest> GetPullRequestStatistics()\nand so on.\nAs an end user I felt happy enough with the 1 function/1 return class/enum to specify what I want (most people would probably just request ALL stats anyway im assuming).  I felt like that was preferable to adding all the methods etc.  But a factor in that was the fact I'd already written most of the code that way...\nIf you think it's more fitting with the rest of octokit.net, let me know and i can change it to the 11 specific functions for each request\n. > Do you think we'd get reuse from the existing response models you've created if we went down the \"one method per endpoint\" scenario? It's going to introduce more methods, but I think they'll be a lot more succinct (and simplify the tests a bit) if we can leverage the serialization cheats we've got to just get back the data we need.\nYes the response models will all be re-usable, you can see in the switch statement I am basically already calling each endpoint and receiving its response object, im just populating the into the \"AdminStats\" parent collection and returning that.  As I think I said the main thing was that I'd already implemented it one way and then found out at integration testing that it behaves a bit differently when requesting specific stats vs all stats, and the api doc example only has one for the \"all\" case.  Writing individual methods is probably the way to go, it's just annoying that that means heaps more unit and integration tests, where the current tests can just foreach through the enum and cover all 11 request types in the one set of tests).  Ill stop being lazy and rework things to see how it looks :)\n. ah nice pickup...  Just pushed up that fix, hopefully the builds work :grimacing: \n. So originally I had this stuff sitting in amongst the existing Helper class and so needed to be very explicit about whether referring to normal or enterprise.  Even when I moved the enterprise stuff out into EnterpriseHelper I still felt like it was a good thing to be very explicit and obvious that we are dealing with a different set of settings here, than those configured for regular github.\nBut in hindsight since it's in EnterpriseHelper class anyway, it's probably ok to just call these parmeters UserName Credentials etc rather than GHEUserName GHECredentials and so on.\nSo I think ill just name these back to their \"standard\" names\n. So originally that was my \"hack\" to allow me to run regular integration tests against a GitHub enterprise instance.  But now that I've officially added an EnterpriseHelper class it isnt appropriate to refer to this (in normal helper) as Enterprise URL.  This item still remains so that someone COULD point \"all\" integration tests at another instance (eg enterprise) if they wanted, by setting the CustomURL.  But the difference is, that all the other paramters like username, password, apitoken etc would be coming from the \"regular\" settings.\nMeanwhile for tests that explicitly require/target GitHub Enterprise, we use the EnterpriseHelper class which has it's own setup for username, password, api key and so on.  \nBasically this means that I can have my workstation configured to run integration tests against github.com and enteprise integration tests against my enterprise instance... Plus if I ever need to run the \"normal\" integration tests against my enterprise instance, I can set the CUSTOM_URL property.\nHope that makes sense\n. Typo in the xml doc with the cref to the class name\n. yeah i think i saw another observable test somewhere that was always getting the observable firs , then awaiting it... so thats how ive written all of my observable tests too\n. Dont feel too bad :grinning: It seems like an acceptable compromise in order to implement the \"bail out\" without having to totally change the entire way Octokit.net has looped through all the paged responses until now...\n. Just a note on usage of AcceptHeaders helper from unit test land...\nWhen I implemented the AcceptHeaders helper class, it was purposely only used in implementation code, and left any unit tests still needing to \"hardcode\" the expected headers value.  This was in order to follow the principle that the tests shouldn't just echo something from the implementation side lest there ever be a bug in the implementation side and the test just passes blindly.  Just mentioning it incase you accidentally used it here.  This would be the first case of it's usage in test land so thought it worth pointing out.\nI guess I modelled it similarly to how RequestsCorrectUrl unit tests always hardcode the expected url rather than using the ApiUrls helper class like the implementation side does.  Doing a quick check now, it seems this rule has been broken for ApiUrls a couple of times, although only about 6 usages in unit tests, out of a total of 419\n. This is pretty :hankey: but I guess managing the overloads of the classes like ApiConnection gets pretty tricky with yet another option, and no way for the compiler to know when you call GetAll(string, null) which of the 2 parameter overloads you intended.  Though it would be nice to see whether the overloads can be consolidated to avoid this (or is the intention that things like the accepts header of timeout would shift into this new ApiOptions parameter?  Even so I guess to maintain backwards compat, most of the overloads would have to stay (or can we just cop a breaking change, given something like implementing pagination support is pretty major, and you arent actually out of beta yet)?\n. Ive hit this quite a few times when writing tests as well.  Would be great to be able to do Equality on the response models (and request models for that matter).  If you start a separate discussion I'd be interested to see what the plans are, however for this PR I'd say the test above is fine\n. This could just be my inexperience with the way these things are working.  \nThe Microsoft Code Analysis stuff wanted me to put LdapDN but when you do that, the json serialiser tried to look for field called ldap_d_n so in order to get the API field ldap_dn deserialized I had to use ldapDn on the c# side, and suppress the warnings about \"Dn\" not being spelled or cased correctly.\nI didnt realise we could \"control\" what words are allowed.  Does that apply to the Microsoft Code Analysis stuff or the API field formatting stuff, or both?  There seems to be heaps of Suppress rules int he codebase for spelling and abbreviations, perhaps there needs to be a concerted effort to get rid of as many as possible, in favour of adding recognized words to this custom dictionary?\nI also wasnt sure if I could set what the \"api name\" of a given property is (ive seen it done on Enum entries, but then also seen mention that that method didnt work on both serialisation and deserialization).  If that is indeed possible then I could rename the field LdapDinstinguishedName and just \"tag\" it as ldap_dn for API purposes.  If this is posible, can you point me at a good example?\n. Is this line necessary?  The parameter array was still created correctly for me, even without this line...\n. Ah fair enough, I must admit I just quickly put the nullable properties on the request object and ran the existing integration tests which passed...  ~~From what you're saying we might need more tests since the current ones didn't pick up the problem you highlighted...~~ oops, obviously I don't have your new test which looks like it covers those scenarios \ud83d\ude00\n. Might be worth mentioning here that after running the script, environment vars won't be picked up by visual studio until it's restarted.  This may even apply to powershell or command prompt that you are using if running the build script too? \n. an  'up-for-grabs' label (\"an\" rather than \"a\")?\nAlso this link goes to the issue search page which is including all up-for-grabs items both opened and closed.  Should it only be for opened?\nhttps://github.com/octokit/octokit.net/labels/up-for-grabs\n. This anchor doesnt actually exist on that page...  Did you actually mean it to be https://help.github.com/articles/creating-and-deleting-branches-within-your-repository/#creating-a-branch \nOr perhaps the \"Next Steps\" anchor on the \"fork\" page?\nhttps://help.github.com/articles/fork-a-repo/#next-steps\n. english :trollface: \n. Might be good to explain how to mention the issue in the PR, since there's a few cases of people saying \"fixed issue nnn\" rather than \"fixed issue #nnn\").  I tried to find a good/official link but unfortunately there is nothing concise... there is a 5 year old \"introducing issue mentions\" blog post (too old) the closing issues via commit message (more about commit messages than PR text), and things like mastering issues are perhaps too much detail.  \nSo maybe just a few more words here like \n\nwhich issue/issues are being addressed, using the #1145 notation\n. Some things that will increase the chance that your pull request is accepted~~.~~:\n\n(end with colon rather than full stop)\n. This property shouldnt be needed \n. Perhaps say \"Items\" rather than \"Issues\"\nAlso Im not sure if we should say \"(default)\" here, since the default behaviour would technically be based on the place of usage (eg on the State field of IssueRequest PullRequestRequest etc is where you could mention what the default value is for that operation)\n. use lowercase for consistency, also there is an extraneious space space after \"open\"\neg:\n\n/// \"open\", \"closed\" or \"all\" to filter by state.  Default is \"open\".\n. This is where I would mention the default\n. Extraneous space?  ItemState state[remove-this-space], ItemStateFilter\n. Revert comment back to previous value\n/// Whether the issue is open or closed.\n. As per my other comment Im thinking we actually can just remove this guy and not need to Obsolete it, since we are making a breaking change anyway.  Waiting for @shiftkey to confirm.  If we DO need to obsolete it though, the warning message should be reworded, since this is not a \"method\".  Something like\nThis value is obsolete and will be removed in a future version.  For Request operations please use ItemStateFilter.All.  For Search, Create and Update operations, \"all\" is not a valid option.\n. Can we revert this back to TheGetAllMethod rather than pluralising it?  Not because there aren't more than one method now, but more just for consistency with the rest of the code base... \n. whitespace?\n. This shared _emailClient is used by 2 of the 3 tests in this class, with the other 1 test declaring it's own client...\n\nMy personal preference is to share as little between tests as possible, as it makes them more straight forward and resilient to unintended changes down the track...  \nMy main point though is consistency...  :grinning:  Not even considering the 2 tests vs 1 test inconsistency I mentioned, we also have the fact that ALL the other tests/methods in this file which arent being changed (and infact alot of the code base at large) are doing things a certain way, so it makes it inconsistent to take a new coding style, used only on the GetAll methods...\n. Minor note that the wording should be \"Ensures\" rather than \"Ensure\".  Since the test shoudl read TheGetSha1Method.EnsuresNonNullArguments() :grinning:\nAlso this test is checking Null and Empty arguments.  In other places ive seen us implement this as 2 test methods eg EnsuresNonNullArguments() and EnsuresNonEmptyArguments()\n. Should be TheGetSha1Method\n. indentation\n. Sorry, to clarify I'm saying the indentation here doesn't look correct... \n. I wonder with these ApiOptions implementations, if there should actually be a unit test for this exception throw.  (And same in ObservableAuthorizationsClient)\nTheGetAllMethod ... EnsuresArgumentsNotNull()\n. This test and the one before it (RequestsCorrectUrl()) are both checking the same thing.  Perhaps this one should check that the specific ApiOptions object specified was passed through to the client.  Eg instead of using ApiOptions.None, declare one containing some page size/skip settings, then verify it is actually seen on the Received() call?\nI realise you were just following the reference implementation but Im just wondering before we go through and implement ALL the pagination PR's we should settle on a good set of test coverage.  There are only 1 or 2 merged so far, so we can easily go back and add the extra unit test to those if we decide it's needed.  The main thing is, it would be done on all the remaining issues as they are merged.\nMy 2c is that as much as possible gets covered by the unit tests! :grinning:\n. Yep, there has been a move towards ensuring all property names for clients are singular (#53 #1035 #1036 #375 #1038), \nso I agree these should be IOrganizationHooksClient Hook { get; private set; }\nIt also makes me realise we have quite a few other clients that still need to get resolved!\n. There are already 2 other existing classes in here with that lowercase name.  I agree it doesnt look nice but from a consistency point of view, this PR is consistent with all other occurences.  A separate issue/PR can be raised to tidy this up \n. local class variable should be named _organizationFixture and be readonly if possible\n. method variable shouldn't be named with underscore\n. I had a look at RepositoriesHooksFixture but it appears to be \"correct\" ie class variables are readonly and named with underscores, while method variables do not have underscores.\nMust've just been something that happened inadvertently on your side after you copied that class and modified it for Org hooks?\n. > I already changed the name on the other 2 classes as well should I undo the changes?\nWhatever you prefer.  I was trying to avoid you needing to tackle more problems on this PR that were already existing (I also wasnt sure what the repercussions of renaming that folder and or namespace might be) which is why I thought a separate PR gets it off your plate.  But if you've done it then no big deal!\n. Agree... also it seems like it isnt doing anything with the url and contentType parameters passed in\n. As agreed by @shiftkey we can just DROP the All option here, no need to mark it [Obsolete] anymore\n. Let's word this \"Items that are open\"\n. Let's word this \"Items that are closed\"\n. all is not a valid option here so this comment can be reverted back to what it was\n. Perhaps word this consistently with the other Request objects, eg:\n\nWhich PullRequests to get.  The default is < see cref=\"ItemStateFilter.Open\"/>.\n. Yep I like the sound of .Lock() and .Unlock() :+1: \n. Yep, see AcceptHeaders.cs helper class members/usages, for how we do this\n. Extra whitespace line introduced here :)\n. I guess this now should be \"TheLockMethod\"\n. \"TheUnlockMethod\"\n. Wording for the unit tests should read TheBlahMethod....DoesSomething\n\nSo...\nTheUnlockMethod->UnlocksIssue\n(note Unlocks rather than Unlock)\n. \"LocksIssue\"\n. > The name is the least-worst option that came to mind given it'll clash with the other\nThe inconsistency of overloads for Post Put Delete and Get makes me :cry: too!\nRather than introduce the first/only occurence of this \"{verb}With\" terminology to get around the overload collisions, perhaps in this case we could just go with adding an overload for\nDelete(Uri uri, object data, string accepts) and then pass null as the body\nApiConnection.Delete(ApiUrls.IssueLock(owner, name, number), null, AcceptHeaders.IssueLockingUnlockingApiPreview)\nTo me this seems slightly less ugly than adding in a new terminology\nOr alternatively, perhaps the \"With\" terminology is a good idea, and we could (on a separate PR) introduce a whole new set of \"With\" overloads, and start to obsolete the old ones\neg\nGetWithCustomAccept<T>()\nPutWithCustomAccept<T>()\nDeleteWithCustomAccept<T>()\nPostWithCustomAccept<T>()\n. Given that the API does return a HTTP 204 NoContent response when \"succesful\" the way ive seen this implemented in octokit in other places (eg OrganizationMembers.Publicize()) is that the Octokit call returns a Task then internally it calls the Connection.Put and checks the HTTP response.  If a 204 was received then \"true\" is returned, otherwise false (or an exception of course, for 404/500/other stuff handled by the plumbing inside Connection class)\n. extraneous whitespace here? 2 spaces in ///..<remarks> instead of 1.\nSeems to be the case on a few of the xmldoc sections in multiple files in this PR\nAlso should the description of <param name=\"options\"> be the same between observable and regular client concrete and interfaces?  Currently across the 4 places, there are 3 different wordings\n\nOptions for changing the behaviour of the API\nOptions to change the behaviour of the API\nOptions to change the API response\n. whitespace\n. whitespace\n. missing space in between uri and object\n. Is this change intended?  Probably best to revert this one\n. This should reflect the method name which was renamed, so TheStartMethod()\n. Probably include \"Can\" in the test name, since all the others have it?  CanDeleteArchive\n. Probably include \"Can\" in the test name, since all the others have it?  CanUnlockRepository\n. oops!  There's a few spaces at the beginning of this string!\n. Id say this ctor can be ditched.  If we just provide one where you specify repositories (and the 2 bools are default to false) and one where you specify all 3 parameters, I think that is enough...\n. This file is still living in /Enterprise/ folder in the source tree\n. Now you're using the Accepts Header, all the mock Connection.Received() checks will need to include that parameter as well (and any others if you had to use an overload that takes Dictionary params or whatever else) (and just a reminder that in the unit test, you should hardcode the expected accept header string ie dont just use the AcceptHeaders helper class... otherwise if there was ever a typo in it, the unit tests would pass!  So we specify it \"again\" on the unit test side)\n\nEg this one would be something like:\ncsharpp\nconnection.Received().Get<string>(\n    Arg.Is<Uri>(u => u.ToString() == \"orgs/fake/migrations/69/archive\"),\n    null,\n    \"application/vnd.github.wyandotte-preview+json\");\n. Minor nitpick but since this test's purpose is to assert the correct Url is hit, you shouldnt \"also\" verify the request body was passed (there is another test for that later).  So you can use Arg.IsAny()here\n. This property name should beMigrations(this will fix the failing convention test which ensures that all properties/methods on the normal interfaces are also present on the observable interfaces.  Currently it thinksMigrationsis missing, because it's calledMigrationhere butMigrationson the normal client interface...\n. You dont need to hit the environment vars directly here... you can useHelper.Organization(which behind the scenes has already retrieved the env vars etc)\n. Need to specify the preview accepts header here.  Currently theApiConnection.Delete()doesn't have an override that allows this.  One is actually being added as part of another PR that is pending currently: #1185 so you could copy those changes toIApiConnectionApiConnectionIConnectionandConnectionclasses to get your side going (or wait until that PR is merged, then when you merge or rebase master you will pick it up)\n. Sorry I wasnt clear... I didnt mean the parameterless constructor (which is required for Json deserialiser) Im only suggesting to drop the one that my line comment starts on - the one that takes theListand 1bool. agree that this is (the only one ive seen so far) a weird naming thing in github API that makes it hard for us to follow our rules.  But the convention test will fail if you dont have the same property name inIObservableMigrationClientthat you used inIMigrationClient. Are we meant to check theoptionsparameter fornullhere?\n. Is this right?  ShouldntsecondCommitbe an entirely different set of 5 commits tofirstCommitthusfirst[1]shouldnt equalsecond[0]?\n. obviuosly you've needed more overloads here for calls that use dictionary of parameters and also ApiOptions (and also it looks like we may yet have another requirement for aGetAllcall that needs to takeApiOptionsand uses  anaccepts` header.\nI wonder if there is a cleaner way to rationalise all the overloads here to just call through to one implementation method, passing default/empty parameters for the dictionary and acceptheader etc...  rather than having the pagination setup call etc in more than one place.\n@shiftkey can advise on the approach here\n. Are we meant to use ApiOptions.None rather than new ApiOptions() ?\n. Have you configured your integration test settings with a test user (and test organization that this user is an owner of) created specifically for running the integration tests (so as not to mess up your personal account or rate limits etc)?\nThen in integration tests, you can get that configured organization just with Helper.Organization (same as you can get the integration user with Helper.UserName)\n. Should we be passing ApiOptions.None rather than null? I haven't been too involved in these changes to date...  What do other merged ApiOptions changes do in similar situation? \n. Can you also add a EnsuresNonEmptyArguments() test function that passes \"\" into the variuos parameters and ensures exceptions are thrown?\n. Shouldnt the status code here be the HTTP 451 (not Forbidden?)\n. No need to apologosie!  Everyone's contributions are much appreciated  :grinning: \n. This is from the wrong assembly, should be IGitHubClient ?\n. This is from the wrong assembly, should be IGitHubClient ?\n. really minor nitpick but the equivalent code in other unit tests in this file are all on one line, while these ones are indented/split...\n. are we missing one case here where the owner, name and request are provided, but null for the options?\n. here too (case where options is null)\n. the first repo creation has the GitIgnoreTemplate, LicenseTemplate on the same line, but the next 2 have these on separate lines.  would be nice to :lipstick: these to be consistent with eachother\n. Nice spot, thanks\n. Poor old Tuples everyone hates them!  Yep good idea not sure how I ended up with <List<Tuple< instead of just a Dictionary< hahah :grinning: \nThese are now tidied up\n. Lol, nice pickup!\n. this should be labelName right?\n. nice pickup!\n. is there a need to declare info => here?\n. For the null checks dont we just need to check each argument is null, not also checking multiple arguments null at the same time?  So in this function all the ones with more than one argument being null at the same time, can be removed I think\n. Same on all the empty string checks as above comment on null checks.  Each parameter needs to be checked, but not combinations of multiple parameters\n. What's the reasoning behind adding this additional constructor?  I notice it's only used in the Observable tests, but couldnt they just pass in the IApiConnection and use the existing constructor, rather than passing in an IConnection and having an entire new constructor (and mostly duplicated logic)?  Apologies if i've missed something, as im on my phone :grinning: \n. As mentioned on another PR, checking for multiple parameters null or empty at the same time is not serving a purpose as far as I can tell?\n. same here\n. any reason to change this? Since all the other cases do the await rather than .Wait() ?\n. Nice pickup :+1: \n. overkill on the null and empty string checks\n. and here\n. .Name is null - you should use .Login field and then everything is green!  :tada: \n. should insert one blank line in between class declarations\n. the name of the test class should reflect the name of the method.  In this case the method is called CreateReaction so the test class should be called TheCreateReactionMethod\n. blank line between function declarations\n. and here\n. blank line and test class name to match the method\n. Wording \"The reaction for \" is a bit odd (and also has an extra space on the end of the string).\nPerhaps \"The reaction\" or \"The reaction to create\" would be better\n. This URL doesnt go anywhere.  Is it meant to be /reactions/ rather than /repos/ ?\n. Can you please rename this to ReactionsPreview or similar (to indicate it's a preview functionality)\n. Should also check Ensure.ArgumentNotNull() on the reaction request object\n. This response object is returned for creating reactions on CommitComments, Issues, IssueComments and PullRequestReviewComments, so it should probably be called something more generic like Reaction rather than CommitCommentReaction\n. I'd suggest the enum be named ReactionType since below ive suggested the actual response class is called Reaction\n. The api doco seems to indicate the string is \"+1\" and \"-1\" for these, but you've got their API string value as plus_one and minus_one.  Just checking if this was intentional?\n. If you look at other enums in octokit.net we dont normally assign integer values to the enum members\n. Maybe a good idea to assert the fields of the response message (eg confirm that the ReactionType you requested is what was actually set).  Also given the other comment about plus_one vs +1 perhaps looping through all of the available ReactionType enum values and creating each one woudl be good, just to prove that all of them are defined correctly\n. unintended whitespace change\n. we normally use a singular form for the variable name and a plural form for the class.  so in this case\nCommitComment = new CommitCommentReactionsClient()\n. Bit of whitespace to tidy up at the end of this line\n. possible whitespace here too\n. I think the default serialization will handle these standard values like Laugh, Confused, Heart etc and only the +1 and -1 would need a [Parameter] attribute?\n. Extra whitespace line?  (Nitpick, I know!!)\n. On the unit tests side, we usually hardcode the expectedUri... as a minor safety net to guard against typos in the ApiUrls helper class, or inadvertent edits etc\n. Similarly, we hardcode the accept header value on unit tests so we dont have the unit test and implementation code both relying on the AcceptHeaders helper class\n. Nice pickup catering for the new API pagination options that were only recently introduced to octokit.net :+1:\n. While you were away, I believe it was decided to move towards \"singular\" property names for sub clients (but plaralised class names) - one such mention is in #1207 .  \nSo for any new clients being added we should probably follow this convention, thus IObservableUserGpgKeysClient GpgKey { get; } (and IUserGpgKeysClient GpgKey { get; } on IUsersClient)\n. There already exists a RepositoryPermission enum that has the same values so I think you could just use that\n. You shouldn't need to specify [Parameter] tag except in unusual cases.  The default serialization will handle converting between github API format and octokit.net's more c# representation\neg:\nlowercase_separated_with_underscores <=> LowercaseSeparatedWithUnderscores\nOnly when a property name on our side doesn't match the above conversion, do you need to explicitly define a [Parameter] tag\n. It looks like the previous implementation allowed the request object to be null however you are now enforcing that it can't be null which would be a breaking change for some existing users...\n. Same thing here, if the call previously allowed options == null then we need to preserve that behaviour\n. these should be RemoveAssignees rather than AddAssignees\n. you dont need to test combinations of more than one field being null or empty at a time, since the first assert to match, will throw an exception.\nIn other words if there are 3 input fields that have NotNull asserts, there should be 3 test cases (each one specifying null for 1 field and valid value for the other fields), eg:\nnull, \"name\", 2, newAssignee\n\"owner\", null, 2, newAssignee\n\"owner\", \"name\", 2, null\n. This last one isnt needed since you already have checked both owner and name field being blank\n. Ideally the parameter order should match the field order as per below, for consistency.  eg put the assignees parameter after assignee and before milestone\n. these need to be reworked to test null and \"\" values for any applicable field... at the moment null is not checked for owner or repo\n. same here, rework to cover each parameter being null and \"\"\n. Dont forget to add an integration test for CanRemoveAssignees method :grinning: \n. This test fails for me...\nCreating a comment needs the issue.Number rather than issue.Id passed in\n. The other tests are disposing of their _context explicitly  by implementing IDisposable but not this one.  Not sure if it's required or not but all 4 approaches should be consistent\n. need issue.Number rather than issue.Id here\n. \"a~~n~~ specified Issue Comment\"\n. an => a\n. an => a\n. an => a\n. an => a\n. an => a\n. inadvertent?\n. That was actually my  commit I sent over to @maddin2016's branch. Sorry if it's not correct but it seemed to me .ToUpdate() shouldn't clear the labels from an issue? \n. To test for creators fields (it's just a User object) you should just be able to use similar to the following:\ncsharp\nAssert.Equal(Helper.UserName, result.Creator.Login);\n. To test for creators fields (it's just a User object) you should just be able to use similar to the following:\ncsharp\nAssert.Equal(\"shiftkey\", result.Creator.Login);\nAssert.Equal(1641780, result.Creator.Id);\netc\n. Yeah that's a bit odd (IMO!).\nI'd expect .ToUpdate() to give me a \"perfect\" replica of the issue, including Labels/Assignees/whatever that I can then use to update the Issue.  \nI see what you're saying about prefering AddLabel() and ClearLabels() to direct list manipulation, but if you consider the use case of where I want to add a label to something, I cant just ToUpdate() and then .AddLabel(newLabel) because that would remove all the other labels.  So I would need more code to explicitly set the labels to whatever they were originally (which perhaps if im now in some other function I dont even have the original Issue object anymore, I only have the IssueUpdate I'd passed in?  It just seems like this behaviour is a bit odd and means ToUpdate() didnt actually create me a \"usable\" IssueUpdate request for my intended usage.  Conversely if we DID include the exiting labels, and possibly fleshed things out with a RemoveLabel() call as well as the AddLabel() and ClearLabels() you still have a way to do everything without direct manipulation but also cater for all intended usages?\nIt also makes me wonder now, if this is the way we currently handle multiple labels on an issue, does that mean the multiple Assignees functionality added in this PR should also take this approach?  Is the main use case REPLACING assignees or ADDING/REMOVING one of multiple assignees?  Id say the fact that the enhancement is here in the first place means multiple assignees are desirable so we wouldnt want to do things that remove other assignees...\n. @shiftkey you might want to take a look at this too.  It's another \"tweak\" id made when pushing some changes over to @maddin2016 .  I think it's because now with the multiple assignees support, this field can actually be null, but we dont want to send it in as such or else it wiped out all the other assignees.  But I also may not have been aware of historic things similar to how I may have messed up the Labels handling currently being discussed!  So if you could check this out too and have a think about it etc to make sure I've done the right thing here?\n. looks like a tab/whitespace issue here (and in other places)\n. Also, we don't want to use implementation logic as part of the test, so rather than using the AcceptHeaders helper, can you hardcode the expected header in the tests?\n. Maybe name this SignatureVerificationPreview just for consistency with all the other preview headers?\n. Extra whitespace line here\n. Is Reason perhaps too generic here?\n. Although I definitely want integration tests to try every enum value, I dont think we need to be this verbose (plus in the future if more reactions are added, we'd need to remember to add them to this test).\nSo what about something like this instead?  It loops through all values of the enumeration and tests each one:\n``` csharp\nforeach (ReactionType reactionType in Enum.GetValues(typeof(ReactionType)))\n{\n    var newReaction = new NewReaction(reactionType);\nvar reaction = await _github.Reaction.CommitComment.Create(_context.RepositoryOwner, _context.RepositoryName, result.Id, newReaction);\n\nAssert.IsType<Reaction>(reaction);\nAssert.Equal(reactionType, reaction.Content);\nAssert.Equal(result.User.Id, reaction.User.Id);\n\n}\n``\n. You can simplifyArg.Is(s => s == \"application/vnd.github.squirrel-girl-preview\")to just\"application/vnd.github.squirrel-girl-preview\". From a consistency perspective, can we not declare this class level subclient, and just use_github.Reaction.Create()` etc where requried?  Simply because we dont have class levels for any other subclients in the test so we shouldnt add one now\n. Given we had issues with the Plus1 and Minus1 on the other reactions stuff, It'd be good to ensure our integration test covers deserializing all reaction summary fields.\nHow had would it be to have a unique value for each of the reactions, eg 5x Plus1's, 4x Minus1's, 3x Hooray, 2x Heart, 1x Laugh, 0x Confused ?\n. Would be good for @shiftkey or @Haacked to comment on whether they're happy with this change to deserializer.  Is this the most elegant way of doing this and would there be any concerns around performance?  Just wondering, since it's looping for every value of every enum and checking for custom attribute, when the majority of enums/values dont have one.\n. I mean have that number of each reaction on an issue then the integration test can retrieve that issue and check each one is desetialzed properly by asserting the unique number \n. yeah im not saying there is a better way of doing it or that it does/doesn't have performance impacts, just asking the question and looking for more opinions.  \nIm not a an of hardcoded strings or a new attribute, if anything had to be done, I would probably do similar to how the serializer pre-caches all the constructors of the model objects, and do some sort of pre-cache of enum items and their value (custom or default), then it would be a quick look up of that list here in the deserializer.  \nIt may not even be necessary though, which is why i refer to @shiftkey\n. i meant that we would setup an issue comment somewhere on github that has 5 users react with \":confused:\" and 4 users react with \":heart:\" and 3 users react with \":+1:\" etc, then the integration test would check each of these.\n```\nvar retrieved = await _github.Repository.Comment.Get(\"octokit\", \"octokit.net\", commentId);\nAssert.Equals(5, received.Reactions.Confused);\nAssert.Equals(4, received.Reactions.Heart);\nAssert.Equals(3, received.Reactions.Plus1);\netc\n```\nBut it was just a thought and it's not a particularly good one because it cant be setup in code easily (as you would need up to 5 individual test users to be able to create the reactions) and even setting one up manually involves co-ordination of multiple people and is then also able to start failing if any other user ever added an unwanted reaction to it!\nSo let's just settle for the integration test\n- creating a repository/issue/comment (you are already doing this)\n- adding 1 reaction of each type to it (currently you only add 1 reactoin type, so we dont know if we are failing to deserialize any of the other fields in the reaction summary part of the payload)\n- assert each reaction in the response payload had a count of 1 and total had a count of 6\nat least that tests all fields deserialized ok\n. cool so to paraphrase/clarify you are saying we dont need to upfront cache everything, but we may as well keep a running cache of anything we've already evaluated so we dont have to do it more than once?\n. yeah I would probably suggest a tidy up that when you loop through each value of the enum you are only storing those with the [Parameter] attribute in the dictionary, you may as well store those that dont have the attribute (using the fallback code) here too.  \nThat way you can just have an approach similar to this (pseudocode)\n```\nif Type Is Enum\n{\n   if Type is not in cache\n      add it to cache (all fields both custom attribute and non attribute)\nif Type is now in cache (it should be at this point!)\n      return the value from cache\n   else\n     throw exception (we shouldnt really ever get here!)\n}\n```\nand if the add it to cache code is too lengthy, that could possibly be split out into a separate helper function in the class AddTypeToEnumParameterCache() or whatever :+1:\n. Nice pickup :+1:\n. oh dear is this another place we missed passnig the ApiOptions through, on the previous changes?  nice pickup\n. Is this required?  I had a look at most RequestsCorrectUrl() tests and they aren't async Task<> they are just void\n. if this is changed to 1 here, should it also be changed in the existing owner/name test? ReturnsCorrectCountOfReleasesWithStart()\n. Actually it looks like there is inconsistency in the code base with both async and regular examples... but im interested whether you were trying to standardise to always being async or whether you actually had a failing test here?\n. hmmm confusing, it says this is an outdated diff but i cant see where it was changed back :confused:\n. Ah here it is!  This is set to StartPage = 1 here, but in the non repository Id test it is 2.  It would be good to have these consistent (eventhough it doesnt really affect the result)\n. he is saying that using await is the \"correct\" way, and we may just be lucky that we havent seen a timing issue when not using await\n. Can we add an overload that doesn't take the httpClient and instead defaults it to new HttpClientAdapter(HttpMessageHandlerFactory.CreateDefault)  ?\nThis is consistent with the way most normal users would be using octokit, e.g they dont really have any idea about IHttpClient or the fact that a default one can be created using the HttpMessageHandlerFactory.  And yes I do acknowledge the documentation example does show how to use the handler factory, but I think it would be more inline with the overloads on GitHubClient (well, really it's the Connection class) to not have to specify it for regular use\n. I think for consistency, this variable should be named repositoryId\n. this should be named as per the method being tested, eg TheInviteMethod\n. should probably have a unit test for when InvitiationUpdate parameter is null\n. how about when the user parameter is empty string?\n. Add case for whitespace being passed as user\n. copy and paste issue?  Assumedly this should be named CallsInviteOnRegularDeploymentsClient\n. Incorrect return type for this function\n. There is already a RepositoryPermissions enum that should be used for these values\n. According to the API docs, this function should actually take a request object stating the permissions for the user to  have.  This is missing from the Add() method which you would have copied for the Invite() method (an issue #1101 is raised for that but hasn't been fixed yet).  But we may as well at least include the permissions request on this PR for the Invite() method\n. ~~I made a previous comment that the permissions are actually provided on the initial Invite() as well as on this update (and infact will also be added to the Add() method on the collaborators client, when #1101 is fixed), so this class could probably be re-used for all cases.  This means it should be renamed to something like CollaboratorRequest rather than InvitationUpdate~~\n. Ah indeed you are right :grinning: the List Invite and Edit Invite calls do have this admin/write/read options.  But the Add and Invite methods need the Admin/Push/Pull.  So i guess you should keep what you have here and use them for List and Edit...  but additionally you should add a CollaboratorRequest class that uses the RepositoryPermission enum for it's permissions attribute, and use that on the Invite() method (and Add() method for when we do #1101)\n. Missed a rename here (id => repositoryId)\n. remove <returns> line as it's empty anyway\n. remove <returns> line as it's incorrect (should be Observable not IReadOnlyList) but also it's not adding any value to simply say what the return type is, so just :fire: the whole line\n. :fire: <returns> line \n. :fire: <returns> line \n. typo\n\"o~~t~~f the repository\"\nActually looks like this is in 8 different places - i wont mark them all but please fix all\n. :fire: <returns> line \n. :fire: <returns> line \n. :fire: <returns> line \n. :fire: <returns> line \n. :fire: <returns> line \n. :fire: <returns> line \n. :fire: <returns> line \n. :fire: <returns> line \n. :fire: <returns> line \n. :fire: <returns> line \n. This should probably say \"for a single repository invitation\"\n. \"for a single invitation of the current user\"\n. I'm actually wondering whether we should just be using the existing RepositoryPermissionRequest request class for this (currently used in TeamsClient.AddRepository()).  Not sure what @shiftkey thinks about re-using a request model in different clients (eg TeamsClient and RepoCollaboratorsClient) vs keeping them separate, incase they ever diverge\n. >  you cannot delete a repo until there is a pending invitation\nDid you mean cannot delete when there is a pending invite?  If so then I guess you could Delete the invitation at the end of the test (before the context goes out of scope and deletes the repo)?\nIm not sure about why the email is not received.  I will try some invites myself when I can...  Does the account you are inviting have an email configured and verified and perhaps also check it's notification settings?\n. Are you sure an exception isnt happening in the fixture.Invite() method?  When an exception is thrown, that will cause the using (var context) { } to go out of scope and then if you are debugging you WILL see it doint the disposal/deletion.  But I'd say the true problem is your fixture.Invite() has thrown an exception\n. this is comparing the same variable.  the old code was newRequest vs request\n. Is this intentional?  the old code was newRequest here rather than request\n. Is this intentional?  the old code was newRequest here rather than request\n. this method isnt really needed as it just awaits the call then returns the result without doing anything with it.\nI think you could just move the actual await _http.SendAsync() call to line #55 where SendRequest() is called currently\n. missing a .ConfigureAwait(false) here i think\n. Ah right!  \nThe deserializer creates a \"constructor cache\" of all the constructors for the response objects, which it uses to instantiate the class, then it uses the protected setter properties to populate any fields it finds in the json payload, on the object it created.\nBut it can't use constructors that take parameters so all model classes actually require a parameterless constructor, which we have missed on the RepositoryInvitation class!\nWe should probably have a convention test that catches this... I've raised an issue for it (#1413) and submitted a fix (#1414)\n. for consistency with all the other response class ctors, can you put this on a single line?\npublic RepositoryInvitation() { }\n. We actually had a problem with the merged PR for IssueComment reactions, where the Plus1 and Minus1 reaction types were broken, so we decided to change the integration tests to cover every reaction type using foreach loops.\nBut it looks like we only did integration tests for the single item Get() requests, and didnt actually think about the GetAll() multiple item calls for all payload types, maybe just this one since it already had a \"multiple issues\" test.\nHow about we remove the reactions from this test, but add new test for CanGetReactionPayloadForMultipleItemss) test to all of the payload types.  And also write that test in a more efficient way, ie using the same looping that the single tests use?  The test code that creates an item and adds all reactions to it, could be pulled out into a CreateXWithReactions() function and then called once for the single test and multiple times for the multiple tests etc\n. I think there is just this comment to fix up still\n. Im not sure if we should have a parameterless constructor and a default value of Push here... let's :fire: this and just leave the constructor that forces the user to state explictly what permission they want the invitee to have\n. Since this is a request object, we should put some XmlDoc on this constructor, to give the users intellisense.  Check out RepositoryPermissionRequest for an example\n. Since this is a request object, we should put some XmlDoc on this field.  Check out RepositoryPermissionRequest for an example\n. I guess the API default only really applies if we dont pass the field at all?\nI dont really have a problem with having to explicitly specify the permission when constructing the object, but if you feel strongly enough about it feel free to keep the default constructor, just make sure to add an XmlDoc comment to state that it defaults to Push access\n. > Ah. That's right. Failure of mine. So if i understand it correct, i we don't set the CollaboratorRequest the api sets push as the default value. Right?\nI think so.  but from a consistency point of view we dont do optional parameters that much.  I think in this case it's ok to always pass the request object and only have the ctor to explicitly state the permission required.  Nothing wrong with being explicit, particularly when its something like granting access to someone\n. > So then we should have two overloads for Add and Invite in RepoCollaboratorsClient!? Because the docs say Only valid on organization-owned repositories.\nI missed that in the docs.  Im confused whether it is saying the \"permissions\" attribute is only applicable to org repositories, or the whole \"Add collaborator\" endpoint.\n. this sounds good :+1:\n. For consistency with other simliar clients/endpoints, this should be \ncsharp\ncatch (NotFoundException)\nrather than catching any type of exception\n. For consistency with other simliar clients/endpoints, this should be \ncsharp\ncatch (NotFoundException)\nrather than catching any type of exception\n. For consistency with other simliar clients/endpoints, this should be \ncsharp\ncatch (NotFoundException)\nrather than catching any type of exception\n. For consistency with other simliar clients/endpoints, this should be \ncsharp\ncatch (NotFoundException)\nrather than catching any type of exception\n. csharp\ncatch (NotFoundException)\n. an programming => a programming\n. There are actually 4 (not 3) items that Reactions are supported for:  commit comments, issues, issue comments, pull request review comments\n. Minor nitpick but the doc comments added in this PR have a mix of http and https on the URLs... \ud83d\ude09 \n. XmlDoc comment on this function\n. And here\n. // => ///\n. Uri string is not the right format here\n. The restrictions request object has a string[] for teams and a string[] for users so it didnt seem possible to offer a ctor that takes only teams and one that takes only users, since it's the same parameter signature for both.  Also a null isnt allowed, it must be an empty list.  I thought about letting users pass in null but then changing that to a new string[] but didn't like the idea of changing what the user sent in.  \nIf you have any ideas, let me know?\n. From memory I wrote these tests to always return maintenance mode status back to a consistent state afterwards, so this was just ensuring matinenance mode was OFF after the test which turned it ON.  Or are you saying we should actually assert this here anyway?  Or potentially do it using a Context helper class, with the destructor implementing the \"reset\" logic?\n. There was some issue with one of the code analysis rules not letting you form Uri's from strings but Ill take another look\n. I think this was left in this state through sheer frustration, but im sure it should be possible to at least have a class that serializes to a json string using our existing SimpleJsonSerializer\n. sounds good\n. i was thinking perhaps like how we have the RequestParameters class that has the ToParametersDictionary() that we could maybe extend this (or add a new similar class) that would provide a ToFormUrlEncoded() method on it, which would provide a way to have any request class be able to have it's key/value pairs formatted up to suit the required style here (eg  key=value&key2=value2)\n. indeed it is :blush: \nI'll see if the GHE API is happy to just receive the out of the box .ToString(\"o\") format\n. this is a helper context class to be used via a using statement wrapping a test.  So a test that sets maintenance ON, needs to ensure that maintenance was OFF to begin with and vice versa, hence the intial state and setting it in the ctor.\nBut also we dont want to leave GHE in maintenance mode after a test (since that is pretty useless for any subsequent tests) so the destructor should be ensuring maintenance mode is OFF again.  Which make me realise Im currently setting the intial state in destructor but actually should always be setting OFF :grinning: \n. > I'll see if the GHE API is happy to just receive the out of the box .ToString(\"o\") format\n@khellang : No dice! :stuck_out_tongue: \nAn internal server error 500 is thrown when using this format.\nI did some poking and found that all of these values cause the 500 error\n2016-08-16T21:15:06.9332018+00:00 // ToUniversalTime().ToString(\"o\")\n2016-08-17T07:05:06.9332018+10:00 // .ToString(\"o\")\n2016-08-16T21:15:06+00:00 // UTC with custom format removing the fffffff component\n2016-08-17T07:05:06+10:00 // Local time with custom format removing the fffffff component\n2016-08-16T21:15:06+0000 // UTC with custom format removing the fffffff component and removing colon in time zone\n2016-08-17T07:05:06+1000 // Local time with custom format removing the fffffff component and removing colon in time zone\n2016-08-16T21:15:06+00 // UTC with custom format removing the fffffff component and only 2 digits for time zone\n2016-08-17T07:05:06+10 // Local time with custom format removing the fffffff component and only 2 digits for time zone\nAnd these formats work:\n`2016-08-16T21:15:06Z` // .ToUniversalTime() with custom format using a static \"Z\" for zulu timezone\n`2016-08-16T21:15:06.9332018Z` // .ToUniversalTime() with custom format including fffffff and using a static \"Z\" for zulu timezone\nSo yeah basically it's the timezone designator that the GHE API seems to only accept when it is \"Z\" and not any of the other (valid ISO8601) values.  The other time components seem to be fine (eg having milliseconds or not, etc)\n. @shiftkey can you shed any light on the behaviour this test is asserting?  It seems that when you added support for Organizatino/User \"type\" on Account, you made it nullable and then have this test here to prove that it's null when deserializing a json fragment that is not a user/org/account at all.\nMeanwhile in this PR I found that the deserializer instantiating the requested class even when the json had no matching fields seemed to go against what other parts of the code were expecting (linked in PR body) so i changed it to only instantiate class when it finds at least 1 expected field in the json, otherwise it returns a null object.  This test here is the only place (we have test coverage for at least) that seems to be impacted by this.\n. ive been thinking this over and I guess if we introduced our own UsernameList and TeamNameList classes that basically just wrapped string[] then we could provide suitable ctors that took only users, only teams or both.  Is it worth doing something like this?\n. @khellang can you confirm you're good with my attempts above basically proving that it does seem to require being done this way and not the built in \"O\" format?\n. Method name doesnt match class name\n. Method name doesnt match class name\n. Method name doesnt match class name\n. Method name doesnt match class name\n. this context should be disposed when finished so could either put it in a using () block or add it to the class variables like _orgRepoContext and add to the class'es Dispose() event\nThis comment applies to several places where a team2 is being created\n. Test name should be AddsXXX rather than AddXXX\n. Test name should be AddsXXX rather than AddXXX\n. The branch protection team restrictions started off with 1 team in them, and this test (hopefully) change the protection to team2 instead.  but just asserting the count of team restrictions is 1 doesnt really prove that the update worked (what if it didnt work and the original team is the one that was returned?).  So perhaps assert on the team's name rather than just the count?\n. since you are accessing restriction.Users.Count anyway there isnt a need to assert that restrictions and restrictions.Users arent null.  The Count assert will fail if any of those were null anyway\n. AddXXX => AddsXXX\n. AddXXX => AddsXXX\n. since these are status contexts can we not call them \"newMember\" but something like \"build2\" or \"deploy\" or whatever?\n. AddXXX => AddsXXX\n. AddXXX => AddsXXX\n. How about making this method UPDATE the status checks to a different number of contexts than they started with.  eg there were 2 to start with, so make this test Update it to only 1.  Otherwise perhaps this method didnt do anyting and the count of 2 is juts the original 2 still there?  :grinning:\n. ~~Edit~~ Replace\n. ~~Edit~~ Replace\n. ~~Edit~~ Replace\n. ~~Edit~~ Replace\n. this context isnt being disposed\n. this context isnt being disposed\n. this context isnt being disposed\n. Id like to steer away from these class level variables (that are only used in one place anyway) in favour of just returning the Urls in the helper method below\n. Extra text here from cut+paste :grinning:\nReturns the  that returns all of the organizations ~~for the currently logged in user~~\n. Since this isn't actually using ApiOptions it should be named something else, perhaps RequestsTheCorrectUrlWithRequestParameter\n. Looks like leading whitespace in the string? \n. Id say this is the one failing, if you have a look at what the previous code was\n. We should use Enum.TryParse()  method here, rather than deliberately throwing/catching an exception \n. ah yeah sorry i didnt look at the diff context and see now that it's inside a non generic method etc, so the way you've done it is ok. This should be passing through the options variable rather than ApiOptions.None. This should be passing through the options variable rather than ApiOptions.None. Cards => Card. Columns => Column. Projects => Project. Projects => Project. Columns => Column. Cards => Card. These tests aren't right.  They arent failing but they also aren't correct.  It may be something to do with the multiple nested subclients on the end of the .Received() call\nbut this observable method doesnt actually call into the IGitHubClient method, it calls the _connection.GetAndFlattenPages() method and thus this test should be checking for gitHubClient.Connection.Received(1).Get..... and this one too. Can we add a helper function for RemoveAssignee(string name) here, so we are consistent with how Labels are now being handled?. minor spacing issue (put else on it's own line). Separate the old member and the new member with a line of whitespace, and dont forget to add XmlDoc for the new member\neg:\n``` csharp\n/// \n/// Client for managing comments.\n/// \n[Obsolete(\"Please use IObservablePullRequestsClient.ReviewComment. This will be removed in a future version\")]\nIObservablePullRequestReviewCommentsClient Comment { get; }               \n/// \n/// Client for managing review comments.\n/// \nIObservablePullRequestReviewCommentsClient ReviewComment { get; }\n``. We still need theComment` endpoint to function so let's make it a getter only, and have it return the new client\neg\ncsharp\npublic IObservablePullRequestReviewCommentsClient Comment { get { return this.ReviewComment; } }. Same comments about whitespace and XmlDoc here. fix formatting (whitespace) here for consistency. I guess this comment should say \"Client for managing review comments\" now?. same comments around getter only, whitespace, and xmldoc wording change. since format is being set above and included in all cases, I think this line may be spurious?\ninfact do we even really need this hardcoded WindowsRT/Windows8 etc stuff below @shiftkey? \nCan this NETFX_CORE case here just be removed and either user Environment or RuntimeInformation according to the HAS_ENVIRONMENT preprocessor definition now added?. what is \"OctokitBidon\" ?. extra whitespace line (there are a few similar occurences on other files).  this is definitely sraping the bottom of the barrel in terms of what I can pick up in review!. this block could be written the same as here for consistency. OctokitBidOn again. ToIHaveLeft => DoIHaveLeft. Maybe add a hyperlink to the github API docs \"rate limiting\" section? Also maybe it's worth mentioning that an authenticated client has a much higher limit than anonymous . I think it would be better to link to this page since it provides info about rate limits etc, rather than the link you had (which is the doc for the actual \"Get Rate Limit\" API call). Let's say \"a significantly higher limit\" here since its's a big difference. if we are going to CAKE from fake anyway this F# voodoo may not be required anymore :). Extra whitespace line. Extra whitespace line. Missing a whitespace line after this line. To me it seems a bit overkill to have a property, default property and 2 private functions, all related to pulling the value out of the headers and parsing it.  I think maintainability would be higher if it was a single function called from the ctor that took the HttpResponse as input and returned the int? parsed value.  It also eliminates the need to declare a default value, as the function could just return null at the end if all the TrypGetHeader TryParse and >= 0 tests didnt satisfy\nIm happy to discuss if you feel things are more granularly testable with the current implementation but this was my initial thought around maintainability/readability.... The style/verbage used in the naming of the test fixtures isn't too consistent with (most) of the other octokit tests (or more precisely, the direction/consistency we are meandering towards)\nWe normally word the test fixture naming with sub classes for the functions eg TheConstructor TheParseRetryHeaderMethod etc, and then the name of the [Fixture] test functions is like HandlesEmptyHeader HandlesNullHeader CorrectlyParsesValue and so on. \nSo that way we end up with common english sounding\nAbuseExceptionTests=>TheConstructor=>CorrectlyDeterminesRetryAfterValue \nand so on. > should've paid more attention to the existing conventions. \nWe have a fairly large code base and some of it has not needed to be touched for quite a while, so it's certainly not all consistent! As we go forward (and as we work with new contributors) we are taking a greater focus on ensuring consistency at least in anything new we implement, so thanks for jumping through these hoops with me :+1:. I think this line is redundant since the following int.TryParse() will handle null or whitespace strings and return false, right?. Nice pickup thanks! \nThe ctor isn't actually used by the deserializer to create the response objects (it uses the field setters) but from a consistency point of view I should have include the new field in the ctor . I think we can advise upstream github support this value is missing from their docs, so rather than saying this I think we can just give it an actual description? \nEg Base branch of the pull request was changed. It would be good to use long data type, since github could well have more than \"max int\" pull requests! . Can we please reword this to \"The internal Id for this pull request (not the pull request number).\" ?\nAnd could you edit the comment on Issue.Id to be similar?  \"The internal Id for this issue (not the issue number).\"\nThanks \ud83d\ude00 . In terms of running the integration tests, you need to configure your development environment (and is strongly recomended you setup a separate github account to use for the integration tests).  More info is documented here in the contributors guide. And in terms of the TravisCI build sometimes we get an unrelated problem where it blows up in TravisCI and is not related to your changes.  We have to kick off another build (or the next commit pushed will obviously trigger a new build as well).  I see your latest commit, the builds have all passed :+1:. This int field can never be null so I'm thinking we will need to assert something else here (eg Assert.True(pullRequests[0].Id > 0). Cool I was able to do this myself!  Thanks \ud83d\ude00 . The API value is all lowercase, pretty sure if we do camel case on our side we'll be looking for an underscore in the API value . Yeah so on looking into this more I realised we dont even need to tag with the Parameter() since these are only response enums and our deserializer removes underscores and does a case insensitive Enum.Parse() anyway :+1:. I just converted the project.json to csproj with VS2017 so I guess this is historic.  Ill update it and see how we go!. wording seems a little off here.  Maybe it could be \"....  but are not of type String\". Our convention is to use plural for the client name (which you've done PullRequestReviewRequestsClient) but to use singular for the sub-client property accessors.  So in this case rather than ReviewRequests it should just be ReviewRequest. Just FYI that we add the xmldoc comments to the interfaces and the client implementations, so once you are done with the changes please add the xmldoc comments to all the conrete methods as well :+1:. ReviewRequests => ReviewRequest. and here. Dont forget to add this new property to the ctor of the response class as well. {2} and {3} should now be {1} and {2} I guess.... Does this clause about Release type need to be here?  Eventhough it may be a Response model, if it is part of a client method parameters then it technically is a Request parameter as well, so probably shouldn't be excluded from Request model tests.... It seems it is currently, eventhough I agree the implicit conversion should mean it's not.  \nIve traced the reason:  \nEncodingType.Utf8 corresponds to an api value of utf-8 but our response enum doesn't include a custom [Parameter()] attribute on the members.  We still deserialize the API value OK, since the deserializer removes underscores and hyphens... but when we are converting this back the other way (ie with the changes I made in StringEnum's ctor we have no way to know that EncodingType.Utf8 should be utf-8.  \nTo fix this, of course we could add the attribute to this enum, but there is nothing that stops this situation from existing on any other enum value that is only used in API responses.  When an enum is used in a request we HAVE to know what the correct api string value is, but when only used in responses we dont currently (need to) know the value.\nOne possibility would be to enforce (via convention test) that all enums (both request and response) have custom [Parameter()] attributes set.  Although this could be a fair few edits, it is the most explicit and obvious approach.  It would also let us remove the \"magic\" removal of hypens and underscores in the deserializer, instead only ever relying on explicit parameter mapping attributes.  Thoughts?. I was trying to avoid changing too much about the current deserializer code.  Both the underlying GitHubSerializationStrategy (which implements an interface) and the actual SimpleJsonSerializer both use instance methods rather than statics.. The xml docs are missing in this class. Minor quibble but the method names of the tests should be worded as actions, eg GetsAdminEnforcement rather than GetAdminEnforcement.\nThis is so that the fully qualified test case names look like:  TheGetAdminEnforcementMethod.GetsAdminEnforcement. Missing xmlDoc in this class. Should there be a ctor taking just the EnforceAdmins bool (and setting the other 2 class members to null) ?. FYI I quickly wrote the convention tests locally to assert this and there are 42 enums that have at least 1 member that doesnt have the [Parameter()] attribute specified.\nIm not averse to fixing them ALL up as part of this PR, since this PR is effectively \"redoing\" how we do enums.. I guess another way to tackle this could be to change the equality operator between 2 StringEnum<TEnum> to compare their ParsedValue (if both of them succesfully can TryParse()) and if not, fall back to comparing the underlying string value as it currently does.\nThis would mean in the case of\n{ Value = \"utf8\", ParsedValue = EncodingType.Utf8 } (implicitly converted from EncodingType.Utf8)\n{ Value = \"utf-8\", ParsedValue = EncodingType.Utf8 } (deserialized from api response \"utf-8\")\nThey would correctly be seen as \"equal\".\nThoughts?\nAlthough more work to change 42 enums, I think Im keen on my earlier suggestion of being explicit with [Parameter()] attributes on every enum member, enforced via convention test, and relied on by the deserializer. When refering to the created RepositoryContext I'd prefer we use _context.RepositoryOwner rather than Helper.UserName - just to keep from making assumptions about the internal workings of repository context . Does this need to be a class level const since it's only used in 1 place?. Ditto with this one, if it's not re-used multiple times it doesn't need to be a class level const. In other integration tests we use \"octocat\" as our contributor user, so it'd be good to use it here too.  The added bonus is that M-Zuber would be able to run these tests lol \ud83d\ude1b . For consistency it would be nice to create the base state using the same process/code that the CreateTheWorld() functions in the PullRequestsClientTests use:   https://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/PullRequestsClientTests.cs#L931-L993\nThat way we have consistency in how we create Pull Requests for integration tests. OK so this is really weird!  The API docs do say due_on however I was running some tests and these were now failing.  When I play around with things it looks like actually the docs are incorrect and our codebase was correct - a value of due_date provides the correct behavior whilst due_on does not!\nhttps://api.github.com/repos/ryangribble-test/public-repo-20170506070755114/milestones?sort=due_on&direction=asc\nhttps://api.github.com/repos/ryangribble-test/public-repo-20170506070755114/milestones?sort=due_on&direction=desc\n( both of these produce the same response (milestone1, milestone2)\nhttps://api.github.com/repos/ryangribble-test/public-repo-20170506070755114/milestones?sort=due_date&direction=asc\nhttps://api.github.com/repos/ryangribble-test/public-repo-20170506070755114/milestones?sort=due_date&direction=desc\n(these ones correctly return the expected reverse order of eachother). Haha \ud83d\ude00 \nyeah as I said there are a fair few inconsistencies with how integration tests are being done across the code base so I just try to focus on new integration tests being done in the preferred way, and perhaps one day we could even go back and restyle the existing ones!. To keep consistency, can we name these \"CanxxxxWithRepositoryId\" ?. Again, for consistency let's just go with CreateTheWorld(). For consistency, use EnsuresNonNull rather than EnsuresNotNull.  Despite the fact the latter actually sounds better, across the codebase we have 585 cases of NonNull and only 5 of NotNull so we need to go with consistency \ud83e\udd14 . Ive pushed up changes to set this back to \"due_date\" (and also contacted GitHub support to ask them about the doc/api correctness for this call). I think this is a bug...   Looks like the IssueCommentRequest object uses PullRequestReviewCommentSort but should actually use IssueCommentSort. minor nitpick but existing convention tests match the assembly to that of IGitHubClient rather than hardcode \"Octokit\".  I guess we'd never change assemblies but I feel like it's cleaner to not hardcode it... ?. Looks like the class name (and filename) are incorrect here:\nPullRequestsReviewRequestClientTests =>  PullRequestReviewRequestsClientTests. this is my test organization rather than a user, which is causing tests to fail.  (my test user is ryangribble-testing although)\nAlso it should be possible to prove pagination works with only 2 collaborators (just adjust the pagesizes in the ApiOptions in the tests to 1 rather than 2). Yeah that does seem like a logic flaw. The idea of the cache is to obviously \"speed up\" the enum deserialization by not having to evaluate the Parameter property on an enum value more than once \nBut that seems to be a logic issue where only the first enum member encountered would be added to the cache...  then next time (for the same enum type) the enum type would already be in the cache (but not other members) and it would actually never look at the parameter property on other members and only do a Enum.Parse on them\nUnless I'm missing something,  this line should have actually led to bugs where we ignored the parameter attribute on any enum members other than the first one encountered? How has this not led to other problems in the past! :confused:\nSo yes I think removing that line is fine but now I want to understand how  this hasn't already caused us problems before! . Yep I confirmed this was a bug, and added a failing test to repro it.  If the same SimpleJsonSerializer instance tried to deserialize a subsequent enum value that required the Parameter attribute (ie EncodingType \"ascii\" followed by \"utf-8\") it would throw an exception as it hadn't cached the other enum members, and tried to do a simple Enum.Parse() on \"utf-8\".\nI've made the fix identified by @mderriey and confirmed this test now passes, plus changed the StringEnum to use a static SimpleJsonSerializer and verified the other tests are passing.\nIll push the commits up if you want to have a look @khellang and @mderriey . inadvertent?. Once you get into integration tests I think you'll find the URL for the repositoryId based endpoints is /repositories/<id> rather than /repos/<id>. \"PreviewPermission\" should be \"ReviewPermission\" \ud83d\ude01. \"PreviewPermission\" should be \"ReviewPermission\" \ud83d\ude01 . grammar nitpick \ud83d\ude00 \n~~are not~~ is not \n(this occurs in multiple xmldoc comments). If the API doesn't support pagination then we can remove all the ApiOptions overloaded method, right?. Across the assertions in this PR there are a mixture of \"org\" and nameof(org) - let's standardise on nameof() for all new ones added in the PR?. missing nameof here. please name the variable number since a pull request also has an internal long Id field which we dont want to confuse here.\nThis comment applies to multiple files on the PR - if you can please fixup all references to pull request numbers to be called number \ud83d\udc93 . Since we are already in the PullRequestsClient class, this member should just be named Review (then it would be accessed like client.PullRequest.Review.Create()\nSimilar to how eg we have ReviewRequest rather than PullRequestReviewRequest\nI also like to place it in the class in the same location that the API doc structure/tree indicate, so in this case it should be above ReviewComment and ReviewRequest. whitespace. With all new additions, we are trying to standardise on the slightly \"better\" implementation of getting the name of the parameter.\nnameof(client) rather than \"client\"\nAre you able to change all occurences in Ensure.xxxx() calls to use nameof() \ud83d\ude00 . For consistency can we have a whitespace line separating the Ensure's and the following statement?. put this guy before the 2 above (to align with the ordering in the github docs\n\n. whitespace. whitespace. Is this right?  This method actually creates the pull request review (not just a comment), right?. Review rather than PullRequestReview and ideally order it above the other 2 to match API doc layout (my OCD tendency sorry!). Incorrect XmlDocs throughout this file. This should be an enum since it has specific allowed values (the same as the Submit action it looks like, so the same enum could be used)\n. XmlDoc comments need updating. Use camel case for the enum members (but keep the [Parameter] tags in place to specify the actual Api values\neg\n``` csharp\npublic enum PullRequestReviewSubmitEvents\n{\n[Parameter(Value = \"APPROVE\")]\nApprove,\n[Parameter(Value = \"REQUEST_CHANGES\")]\nRequestChanges,\n[Parameter(Value = \"COMMENT\")]\nComment\n}\n```\nAlso perhaps rename the enum since it can be used for both Submit and Create actions. Im thinking this Id field should be long rather than int so that we don't have growing pains in the future. Should be an enum. Several places mention \"comment\" when they should say \"review\". From a \"naming things\" perspective we have a convention where we name the classes/interfaces as a plural - eg in this case IObservablePullRequestReviewsClient if you are able to rename the classes/interfaces and files?. We will need to poke the API to see whether this GetAllComments method needs to support ApiOptions overloads for pagination. Missing XmlDoc comment. This one is called Invites but the team one is called Invitations.  Should we be consistent?  (the API doc URLs seem to use invitations terminology for both). whitespace nitpick \ud83d\ude28 . Normally we declare enums in the Response/Request model area rather than directly in the client dont we?. whitespace. whitespace. let's call this PullRequestReviewState. Let's call this PullRequestReviewEvent. remove extra whitespace line. remove extra whitespace line. remove extra whitespace line. remove extra whitespace line. remove extra whitespace line. tab alignment. Incorrect comment. reword to \"Submits a pull request review\". remove extra whitespace line. remove extra whitespace line. remove extra whitespace line. Just double checking, we cant use _gitHub.Organization.Member.Delete() here?\n. Typo? . Ah ok... I could enable 2FA on one of the octokit test accounts if you think that's a better idea? . Ah whoops I think I just did a replace all 2014 -> 2017... thanks!. Yep I agree, this is not great but it's the best I could come up with \ud83d\ude21 \nIm not sure why this API endpoint is different to the other branch protection ones!  Normally to \"disable\" a protection setting, you can send a null for the object but in this case to disable the item, you have to send an empty bodied member.\nSo basically to be disabled, as per the following screen shot, we have to send an instance of the class but with no members (ie the Teams/Users array are null)\n\nTo enable the dismiss restriction and have only admins (as per next screenshot) you send empty Teams/Users arrays.\n\nTo specify teams/users you populate them\n\nSo given that we need to somehow have either the empty bodied class or empty array or populated arrays, what i came up with was the ctor thqat takes a bool for whether the restriction is enabled (admin only, thus empty team/user list)... or disabled (null arrays, so the class has an empty body).\nI tried to explain the usage in the xmldoc comments which users hopefully see in intellisense.\nIf you have any better ideas for implementation let me know!. Ah right, sorry I misunderstood! Yes that code comment is poorly worded, I will update thanks! . We can drop these Exception details from xmldoc comments... it's not that they aren't informative but just for consistency purposes (since we don't include this detail on any/many other documented calls).  Just <summary> and <param> entries is fine. Apart from the spelling mistake (useful has one L :)) I don't like the phrasing of the sentence sorry\nHow abou:\n\n/// Set the GitHub Api request timeout.\n/// Useful to set a specific timeout for lengthy operations, such as uploading release assets. Can we simplify to just simply:\nThe timeout value\n\n?. We actually need to cover all null cases for the new 4 parameter overload, so that means 4 additional test cases (eg the 3 above this, but with options specified, then the 4th one is the one you've added.\nLet me know if this doesn't make sense :). Same here, we need (1, null, options) and (1, \"subnamespace\", null). we also need empty string test cases for the 4 parameter overload (and below for the 3 parameter one 1, \"\", options)). Do you have more details on why you removed the parallel async code in these tests?. The nested loops are a bit clunky, is there a more succinct way to express this?  \neg Assert.False(firstRefsPage.Any(x => secondRefsPage.Contains(x)));. Looks like you forgot to assign the passed in variable to the class member, within the constructor. Can we please update these to the newer style using nameof(owner) rather than hardcoded string \"owner\" ?. I'd rather be explicit about exactly what Accept Headers are being validated in unit tests, rather than saying \"any accept header\" is fine.  So can we remove this and be explicit in all the tests?. Yep fair enough to leave the \"any\" in place for these tests since they don't aim to test the actual endpoint . @gdziadkiewicz just checking you saw my message asking why the WhenAll was removed from here?. another assertion to refactor here. and here. and here. OK I think this might be #1683 causing issues when running in parallel.  It's funny because it works OK for me - it's all down to timing I guess!\nIm not a fan of using .Result though since it's a real hack around async code...  Maybe this can be written as a foreach (var repoName in repoNames) loop that creates the contexts one by one and adds them to a list.. Let's use pagesize=1 and just create 2 test repos. can you please fix this .Result like you did for the other one?. can you please fix this .Result like you did for the other one?. Let's use pagesize=1 and just create 2 test repos. Let's use pagesize=1 and just create 2 test repos. maybe could you add .Asserts that test CreatedAt and UpdatedAt fields get the values expected?  . Does a response to GetOrganization populate this field (the API docs don't show it but I'm not able to test a real response from my phone right now). If it's not on Organization then this field would need to be moved to User rather than the Account base class . We use singular for client property names, so can this be Installation ?. We use singular for client property names, so can this be Installation ?. for any Ensure checks can we please use nameof(request) rather than \"request\" ?  . We use plural for client class names, so can this be ApplicationsClient ?. IApplicationsClient. whitespace. Installation. since this is an existing public method, we want to avoid making a breaking change if possible, so typically we would add another method with the new signature. again, to avoid a breaking change (even a parameter with a default value can still be a breaking change binarily speaking) you should add new ctor/s for these changes. Installation. are these TODO comments going to be actioned in this PR?. See this link, for example\nhttps://haacked.com/archive/2010/08/10/versioning-issues-with-optional-arguments.aspx/. Can we use,await syntax here to avoid the .Result below? . According to the docs the Rate property is deprecated so our docs should actually steer people towards the proper field (.Resource.Core) . Could probably also mention the search API rate limit in the code sample too . can we implement these missing fields?  Should be pretty straight forward:\n\"permissions\": {\n      \"metadata\": \"read\",\n      \"contents\": \"read\",\n      \"issues\": \"write\",\n      \"single_file\": \"write\"\n    },\n    \"events\": [\n      \"push\",\n      \"pull_request\"\n    ],. For consistency, we need to add /// <summary> and /// <remarks> Xml comments, like all the other client access properties in this class. Can we make Id AppId and TargetId be long rather than int  data type, incase they are global across GitHub and we eventually may run into MaxInt type problems?. It seems to still be null in the case where you have a class that has a member of StringEnum<T> that is unitialized.  We want this to return default(T) so it behaves like a normal enum\n. I added a test to repro this here: https://github.com/octokit/octokit.net/pull/1760/files#diff-728143ef4b5a14ceed6d74d06f9c9df7R62\nthis is certainly doing my head in!. right... I was losing sight of the fact we only use this StringEnum<T> in response models, because the unit tests are using dummy classes where it's possible to declare classes with uninitialised members and so on.\nBut from a technical point of view - the same would be true of an enum property on a response class now wouldn't it?  If it was not marked nullable, and the API response didnt specify it, then we will be providing the \"incorrect\" default enum value on the response model instead of a null.  \nI guess the question is, should an incorrectly not nullable StringEnum<T> behave the same as an incorrectly not nullable regular enum? . should we enforce no empty strings here too?. The API response actually has a null value rather than the string \"null\" so what we need to do is make this property nullable (eg StringEnum<EmailVisibility>? Visibility). Need to remove this All option from the enum as it wont deserialize correctly anyway, plus we can make the property above nullable, to handle this case. (and note that this will not deserialize currently, but once #1760 is in, this should then work!). this aint gonna work \ud83d\ude1d . Something happened to whitespace/alignment here? . I think we should make this nullable bool? MaintainerCanModify because responses that return lists of pull requests will not return this field, so rather than indicate it as false in that case, we should indicate it as null. Could we reword this slightly?\n\"Whether maintainers of the base repository can push to the HEAD branch\". we only want mandatory parameters to be in the constructor, so this can be removed sorry!  Good news is, all those tests don't need to be modified (and the bad news is you have to undo all the test modifications LOL). This should be nullable bool? since it's an optional parameter.  That way when the user doesnt set it, we dont send anything in the request, and thus we default to whatever the API default is (which is important in this case since the API default is true, and if we leave this non nullable we would default to sending false). This should also be nullable bool? so that the user is able to not specify a value and have it not change this property on the PR they are updating. We have previuosly discussed this and dont have a problem in using the string interpolation $\"blah {var} blah\" however would prefer this to be done across the code base in a consistent way via a Milestone and one/many PR'sspecifically making only that change (so it's easier to review)... rather than randomly using it in a few places while 100s of existing cases are still doing it \"the old way\").. Im not so keen on the automatic quoting here.  Firstly, because other search criteria (eg Labels) don't do this, so this would mean behavior isnt consistent...  Secondly because if a user already specified quotes themselves, this would then end up double quoting their input.  \nThoughts?. I do agree with you from a usability point of view and yeah as mentioned my concern is about overall library consistency, so for me I would be happy to keep the auto-quoting in place here, provided:\n- We handle the case if the user DOES provide quotes - either by stripping theirs to add yours, or by only adding quotes if there arent already some there etc (or by testing/proving that a double quoted milestone still \"works\" and thus isnt actually a problem)\n- We consider adding quotes is now something we should be doing in any similar cases in the future, and ideally also look at any existing places where this could be fixed up (on a new issue/PR). :+1:\nOh one other thing I remembered while poking around into this side of things... we will probably also want to add milestone support to the SearchIssuesRequestExclusions request, assuming it's possible to search for items that DONT have a given milestone. Can we please hardcode the expected accept header values? If the test uses the same variable that the implementation does, we would never pick up a typo in the value so we prefer the tests to be independent (this applies to all the accept headers usage in the tests). FYI, the octokit serializer/deserializer will automatically handle converting between ruby snake case (image_url) and c# camel case ImageUrl based on the capitalization converting to underscores... so you don't need to specify [Parameter()] attributes unless there is a mismatch.  So most of the attributes added in this PR can actually be removed.  (note, the exception is on Enum members, where the attribute is still required!). I think for consistency with the rest of the code base, it would be good to avoid an Update request inheriting from the New request, and instead implement the required fields directly in this class. Can we use long for the Id field, just in case we ever reach max int?  Probably wouldnt happen on pre receive environments, but as a general policy all Id fields should be long (we got bitten by PullRequest Status Ids in the past!). id rather keep consistency with the rest of the test code base - ie just specify the actual expected header string and not a central reference point. do you know if the Name or ImageUrl are required parameters for the update call?  Wondering if there should be a constructor that takes these . response class needs parameterless ctor and ctor taking/setting all properties. response class needs the 2 ctors mentioned previously. why do you say it doesnt follow the standard rules?  From the response in the docs it indicates it should support \"normal\" pagination:\n\n. that said, if there is a case where it doesnt follow normal conventions, another option rather than excluding the whole client interface as @shiftkey mentioned, is that we also have an attributes which can suppress pagination conventions for naming and/or ApiOptions overloads, on a per method basis :+1:\n[ExcludeFromPaginationNamingConventionTest] and [ExcludeFromPaginationApiOptionsConventionTest]. I think this will need to be named Default to match the json response field . To be consistent with the rest of the library, the request model constructor should only take required parameters. Optional parameters can be set via object initializer pattern . Optional field shouldn't be in the ctor . XmlDoc comments should be added to this class including it's ctor/s and the public properties. We would normally use IReadOnlyList<int> rather than a normal int[] array\ntake a look at other request models for examples (eg here). You could probably do something more succinctly like:\n`` csharp\nstring.Format(CultureInfo.InvariantCulture, \"NewOwner: {0}, TeamId: {1}\", \n   NewOwner,  \n   string.Join(\",\", TeamId ?? \"null\"));. this method could probably just take anIEnumerablerather thanIReadOnlyListand would then be more reusable for checking other potential lists in the future. These names should actually reflect the method name, which isTransfer.  So what we would do here is have one test class calledTheTransferMethodand then have[IntegrationTest]methods calledTransfersFromOrgToUser(for the \"normal\" endpoint) andTransfersFromOrgToUserWithRepositoryId(for the repositoryId endpoint). by convention we always name the parameterrepositoryId(this comment applies to all the places it is currently namedid). to be consistent with your other method names, this should beByIdrather thanWithId. eventhough this would throw an exception if the repo didnt exist under the requested owner (thus failing the test), I think i'd still prefer to see some kind ofAssert` in each test, for consistency.\neg: Assert.Equal(newOwner, transferred.Owner.Login);. we dont want to rely on the test org having to have existing teams.  We have a TeamContext that can handle creating a team and destroying it again when it goes out of scope.  So you could rewrite these tests to something like this:\n``` csharp\n        [IntegrationTest]\n        public async Task TransfersFromUserToOrgWithTeams()\n        {\n            // FIXME API doesn't add teams when transferring to an organization\n            var github = Helper.GetAuthenticatedClient();\n            var newTeam = new NewTeam(Helper.MakeNameWithTimestamp(\"team\"));      \n            var newRepo = new NewRepository(Helper.MakeNameWithTimestamp(\"transferred-repo\"));\n            var newOwner = Helper.Organization;\n        using (var teamContext = await github.CreateTeamContext(Helper.Organization, newTeam))\n        using (var repoContext = await github.CreateRepositoryContext(newRepo))\n        {\n            var transfer = new RepositoryTransfer(newOwner, new int[] { teamContext.TeamId });\n            await github.Repository.Transfer(repoContext.RepositoryOwner, repoContext.RepositoryName, transfer);\n\n            var repoTeams = await github.Repository.GetAllTeams(repoContext.RepositoryId);\n\n            Assert.True(repoTeams.Any(x => x.Id == teamContext.TeamId));\n        }\n    }\n\n``. All of these tests are actually not running properly becauseAssert.ThrowsAsyncmust beawaited, otherwise it runs in the background and is not actually checked.  These tests should actually be failing right now, because the method isn't guarding againstnulland emty strings!. needs to beawait'ed. needs to beawait'ed. This is missing theEnsure.ArgumentNotNullOrEmptyString()checks forcurrentOwner,nameandEnsure.ArgumentNotNull()check forrepositoryTransfer(and the unit tests are not picking it up due to not beingawait'ed). This is missing theEnsure.ArgumentNotNull()check forrepositoryTransfer(and the unit tests are not picking it up due to not beingawait`'ed)\nTheses also should be added to the Observable client (even though it calls through to this method anyway, our convention is to do the Ensure.xxx tests in both clients). If the above owner/name method has XmlDoc comments provided then we should add them for this repositoryId one too. I dont think we need this remark . The wording on this remark is a bit odd (what do you mean by \"invalid description\"?).  Also <remarks> objects aren't visibile in intellisense AFAIK, so I would suggest removing this remark, and instead what I normally do is type a brief explanation in brackets of the description of the param element itself \neg\n/// <param name=\"teamId\">A list of team Ids to add to the repository after the transfer (only applies to Organization owned repositories).</param>\n. ditto here.  I would remove this  and put (only applies to Organization owned repositories) in the . Add Ensure.xxx guards. Add Ensure.xxx guards. rename to owner. rename to owner. rename to owner. rename to owner. rename to owner. The response payload actually doesn't have that field, only the request seems to . after checking internally, turns out this was an oversight and title will be added to this response, so I've added it to the mode :+1:  Also I realised I still had it in the ctor anyway, even though the class didn't have the property, which is probably what you were pointing out anyway!  \ud83e\udd23 . this entire file is spurious and should be removed. this test shouldnt need to be commented out. this function is unrelated to this PR and should be removed. no changes to this file should be necessary, so revert this whitespace change. no changes to this file should be necessary, so revert this change. I would say this should live under Models/Response/ActivityPayloads with the others. The property name should be singular, eg github.App.Installation.xxxx. I wonder if this should be named GetRepositoryInstallationForCurrent() since it uses the currently authenticated GitHub App... or otherwise FindRepositoryInstallation()? . also we need to support the repositoryId version of this call in addition to the owner/repo version. comment says repository but should be organization. incorrect params. GetOrganizationInstallationForCurrent or FindOrganizationInstallation?. GetUserInstallationForCurrent ?  Or FindUserInstallation?. The docs says this endpoint uses an installation token, not a JWT... and this would get repositories of an installation rather than a github app (which would have many installations each with potentially many repos)\nSo let's go with \"List repositories of the authenticated installation (requires Installation Token auth)\" or something similar. same as above. Comment probably needs to indicate this requires a user to server OAuth token. Same here, it needs to use Date only, not Date+Time. This still has the old spelling.  Im not sure you even can parameterize the format string like this anyway?!. I'd prefer the unit test actually tests the formatted string eg '2014-1-1'T'020406 1000' (or whatever it should be)\nOtherwise these tests are susceptible to whatever formatting bug may exist inside DateRange class.  \nEG Im pretty sure the way you've implemented it at the moment isn't correctly formatting the string, yet all these tests pass (because you are using the DateRange class to test the DateRange class! \ud83e\udd23 . Can we use the string values here rather than the AcceptHeaders.xxx variables?  (I realise you were just updating what is already there, but we must have somehow missed this previously!). This sub client should be put under TeamsClient rather than OrganizationsClient, based on the API docs structure:\n\nAlso can we please make the property should be singular and just be called Discussion?  We would access it like  client.Team.Discussion.Get(). can we please name the variable NewTeamDiscussion newTeamDiscussion here and in the implementation?\nsuggestion\n        IObservable<TeamDiscussion> Create(int teamId, NewTeamDiscussion newTeamDiscussion);. can we please name the variable UpdateTeamDiscussion updateTeamDiscussion here and in the implementation?\nsuggestion\n        IObservable<TeamDiscussion> Update(int teamId, int number, UpdateTeamDiscussion updateTeamDiscussion);. Can this field descriptor just be \"The team discussion number.\" on all methods it appears?\nsuggestion\n        /// <param name=\"number\">The team discussion number.</param>. suggestion\n        /// <param name=\"number\">The team discussion number.</param>. Move to TeamsClient. suggestion\n    /// A client for GitHub's Team Discussions API.. I think this is an old comment from where this was copied from, and it doesnt really make too much sense (referring to ApiConnectionTests.cs).  I think we can just remove this whole  section. Move to TeamsClient. suggestion\n        Task<TeamDiscussion> Create(int teamId, NewTeamDiscussion newTeamDiscussion);. suggestion\n        Task<TeamDiscussion> Update(int teamId, int number, UpdateTeamDiscussion updateTeamDiscussion);. suggestion\n        /// <param name=\"number\">The team discussion number.</param>. move to TeamsClient. Move to TeamsClient. suggestion\n    /// A client for GitHub's Team Discussions API.. XmlComments are missing from all the methods in this class (just copy the ones from the interface). Since this is an optional field it should probably be nullable (bool? Private) so that if the user doesn't set it, we dont send it to the API. Eventhough the default value is false anyway, there is a difference between us always sending false and us only sending a value when the user explicitly sets it.. since both fields are optional there should be no parameters in the ctor. allow optional field to be set via object initializer syntax\nsuggestion\n        public string Title { get; set; }. XmlComments missing for all the methods in this class (just copy the ones from interface). Mandatory field which gets set via the ctor, so this property should be private set\nsuggestion\n        public string Title { get; private set; }. Mandatory field which gets set via the ctor, so this property should be private set\nsuggestion\n        public string Body { get; private set; }. We want to access this API like client.Team.Discussion.Get() so this property name should just be Discussion\nsuggestion\n        IObservableTeamDiscussionsClient Discussion { get; }. We want to access this API like client.Team.Discussion.Get() so this property name should just be Discussion\nsuggestion\n        ITeamDiscussionsClient Discussion { get; }. I also just noticed this commented out property?. minor nit: missing a whitespace line. The fields in the PushWebhookCommitter are not a superset of Committer so we shouldn't use inheritance here.  We should just make this response model contain the fields that the webhook payload will have:\njson\n      \"committer\": {\n        \"name\": \"baxterthehacker\",\n        \"email\": \"baxterthehacker@users.noreply.github.com\",\n        \"username\": \"baxterthehacker\"\n      },. can you clarify what this resharper setting does?. should this be an enum?. should this be a StringEnum<T> ?. ",
    "alandball": "Hi, thanks for the quick response. The .Add(), why create a new label? It takes in a string, so just putting the label name is good, yeah?\n. ",
    "NikolayIT": "When this will be merged?\n. @shiftkey I only need link to the archive. :) And this is related to my #784\n. @shiftkey, awesome! Thanks!\n. ",
    "jackahuja": "I am not getting any content or exception for the variable. By GitHub resourse do you mean GitHub local client? Also I am getting the status of the thread as \nId = 1, Status = WaitingForActivation, Method = \"{null}\", Result = \"{Not yet computed}\".\n. Hi, thanks, I will try this and let you know.\nOn 31-Mar-2015 5:32 PM, \"Brendan Forster\" notifications@github.com wrote:\n\nWhat about if you do this?\nvar contents = client.Repository.Content.GetContents(\"owner\", \"reponame\", \"FilePath\");\ncontents.Wait();\nvar result = contents.Result;\nIt's hard to say what might be causing the task to not execute (I'm not\nsure what sort of application you're running here) but this is how you can\nforce the program to block until the task completes.\nBy GitHub resourse do you mean GitHub local client?\nRather than point to your GitHub Enterprise environment, could you try it\nagainst GitHub?\nvar github = new GitHubClient(new ProductHeaderValue(\"OctokitTests\"));\nvar readme = await github.Repository.Content.GetReadme(\"octokit\", \"octokit.net\");\nDebug.Assert(\"README.md\" == readme.Name);\nIf that works, perhaps there's some networking-specific problem at play\nhere...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/773#issuecomment-88061015.\n. \n",
    "jbkielis": "Were you ever able to find out the cause of this issue?  Thanks.\n. ",
    "pavel-b-novikov": "(passing by) Just encountered with support of repository redirects. Forced to checkout sources and \"invent crutch\" there making IRequest mutable in part of endpoint. \nYou should write that redirects are not supported on main page.\nActually redirects works but loosing auth information. And in case of bulk repo queries it leads to \"rate limit\" exception. \nShould I pull-request mine lonely crutch in such good code?\n. ",
    "SplitInfinity": "I am able to get the contents of a repository's root directory by passing in \"/\" as the path, but I am unsure if this is due to changes made after this issue was opened.\n. ",
    "ostruk": ":+1: \n\"/\" only works if you're retrieving master branch. If you're retrieving some other branch it defaults to master branch, because the generated url is actually invalid: \"contents//?ref=branch-name\". Remove the check for empty string when specifying path.\n. I have 7 files on my master branch, and 6 on my custom branch (\"ostruk-branch\" does not have \"added.js\").\nWhen I call\nvar all = await client.Repository.Content.GetAllContents(\"UW-demo\", \"multiJs\", \"/\", \"ostruk-branch\");\nI get 7 files, same as if I called without \"ostruk-branch\". When I inspect the code, I can see it attempts to make a call to\nhttps://api.github.com/repos/UW-demo/multiJs/contents//?ref=ostruk-branch\nwhere you can see that all files have \"?ref=master\" by them, indicating they are being pulled from the master branch. If I change the url to\nhttps://api.github.com/repos/UW-demo/multiJs/contents/?ref=ostruk-branch\n, which is equivalent to passing \"'\" for path argument, then response is correct.\nI'm using 0.16.0.\nThanks!\n. ",
    "jamesqo": "Can we reopen this issue? The fix was accidentally undone during https://github.com/octokit/octokit.net/pull/1348 and I'm running into it again.. I just ran into this error. For some reason, it looks like the argument validation was added back during https://github.com/octokit/octokit.net/pull/1348 and no one took notice.. @ryangribble Thanks for the advice! I just tried installing the prerelease package and it works perfectly. :heart:. @ryangribble 0.24.1-alpha0001.. @ryangribble I am trying with a .NET Framework app, but it's not working there either.\n\nProof that I've enabled the source server setting:\n\n. This is using 0.24 (the one that doesn't support .NET Core).. @ryangribble I just tried again, using the latest AppVeyor build with a .NET Core app, and it doesn't work there either. Not sure what I could be doing wrong on my end \ud83d\ude41 . @ryangribble I already had both SourceLink v1 and v2 enabled and was using VS2017. I ended up git cloning the repo and inserting a new test to diagnose the issue. Regardless, thanks very much for your help :smile:\nI'm closing this issue for now, but if anyone else has had problems with debugging too, comment and I'll reopen.. I looked into this a little bit. It seems that when you go to https://api.github.com/repos/jamesqo/Repository/contents, which corresponds to GetAllContents on the root directory, the content of each file will not be returned. However, passing in the file name to GetAllContents (I wasn't aware you could do that, I thought it only worked with directories) returns its content.. ",
    "dennisan": "yes, I would recommend a warning if the repo name contains delimiters such as / or .   It looks like native GIT api takes \"owner/repo\" from what I read so that was throwing me off.  Also, I suggest that the exception message mentions that its the named repo that could not be found. \n. Thanks for the quick reply also\n. ",
    "squeakyD": "It's still not fixed for Github Enterprise.  Please could this be revisited?\nhttp://octokitnet.readthedocs.io/en/latest/http-client/\n. The reason why this doesn't work is because what I need to do is pass in the GHE URL, i.e.\nvar client = new GitHubClient(new ProductHeaderValue(\"my-cool-app\"), new Uri(\"https:// .... \"));\nHowever only the way you can currently add a proxy in code is:\n`\n var proxy = new WebProxy(new Uri(\"http://proxyarray.service.group:8080\"), true);\n            proxy.Credentials = CredentialCache.DefaultCredentials;\n            IHttpClient httpClient = (IHttpClient)HttpMessageHandlerFactory.CreateDefault(proxy);\n        var connection = new Connection(new ProductHeaderValue(\"my-cool-app\"),\n            new HttpClientAdapter(() => HttpMessageHandlerFactory.CreateDefault(proxy)));\n        var client = new GitHubClient(connection);\n\nThe problem is that there is no constructor that can take an IConnection and a URL.. ",
    "olegkap": "You can also provide a handler directly:\n                var connection = new Connection(\n                    new ProductHeaderValue(\"my-cool-app\"),\n                    new HttpClientAdapter(() => new HttpClientHandler {\n                        Proxy = new WebProxy(this.Configuration[\"Proxy:Address\"]),\n                        UseProxy = true\n                    }));\n                var client = new GitHubClient(connection);.\n",
    "cdaapi": "So a bit more investigation...\nThe test code I have is \nclient = new GitHubClient(new ProductHeaderValue(\"OMHToken\"));\n        client.Credentials = new Credentials(\"cdaapi\", \"<<password>>\");\n        Task<IReadOnlyList<RepositoryContent>> xx = client.Repository.Content.GetAllContents(\"openEHR\", \"CKM-mirror\", \"local/archetypes/\" + routePathid + \"/\");\n        IReadOnlyList<RepositoryContent> myList = await xx;\nWhen this code is executed Fiddle shows two calls to the API\n#  Result  Protocol    Host    URL Body    Caching Content-Type    Process Comments       Custom   \n 1056   302 HTTPS   api.github.com  /repos/openEHR/CKM-mirror/contents/local/archetypes/demographic/    0       text/html;charset=utf-8   iisexpress:7824           \n 1091   200 HTTPS   api.github.com  /repositories/5150654/contents/local/archetypes/demographic 3,257   public, max-age=60, s-maxage=60 application/json; charset=utf-8 iisexpress:7824\nThe first call has the Authorization Header set, the returning headers show X-RateLimit-Limit: 5000\nHowever the second call has no Authorization Header set and as such has X-RateLimit-Limit: 60\nThe HTTP response on the first call is a 302 suggesting a redirect to a different URL, in doing so it is dropping the auth credentials. \n. ",
    "sumodmadhavan": "I am interested.\n. ",
    "gsscoder": "@shiftkey, absolutely no problem... This happened in Visual Studio 2013 Community Edition (Update 4).\nIn the attempt to post more data as asked by @khellang, NuGet was not able to connect and grabbed package from local cache: this time the dependency was correctly set and the package added to the project.\nPackage Manager session:\nPowerShell\nPM> Install-Package Octokit\nThe source at All [(Aggregate source)] is unreachable. Falling back to NuGet Local Cache at C:\\Users\\vmuser\\AppData\\Local\\NuGet\\Cache\nInstalling 'Octokit 0.13.0'.\nSuccessfully installed 'Octokit 0.13.0'.\nAdding 'Octokit 0.13.0' to ConsoleApplication13.\nSuccessfully added 'Octokit 0.13.0' to ConsoleApplication13.\nI know that $error[0].Exception.ToString() was for the first case, anyway I've executed it also now. Here the result:\nPowerShell\nPM> $error[0].Exception.ToString()\nSystem.InvalidOperationException: Failed to add reference to 'System.Net.Http'. Please make sure that it is in the Global Assembly Cache. ---> System.NullReferenceException\n: Object reference not set to an instance of an object. ---> System.NullReferenceException: Object reference not set to an instance of an object.\n   at Microsoft.VisualStudio.FSharp.ProjectSystem.AssemblyReferenceNode.AddToProjectFileAndTryResolve(String assemblyInclude)\n   at Microsoft.VisualStudio.FSharp.ProjectSystem.AssemblyReferenceNode..ctor(Int32 dummy, ProjectNode root, String assemblyName)\n   at Microsoft.VisualStudio.FSharp.ProjectSystem.ReferenceContainerNode.CreateAssemblyReferenceNode(String assemblyInclude, AddReferenceDialogTab tab, Boolean isFullPath)\n   at Microsoft.VisualStudio.FSharp.ProjectSystem.ReferenceContainerNode.CreateFileComponent(VSCOMPONENTSELECTORDATA selectorData, AddReferenceDialogTab tab)\n   at Microsoft.VisualStudio.FSharp.ProjectSystem.ReferenceContainerNode.CreateReferenceNode(VSCOMPONENTSELECTORDATA selectorData)\n   at Microsoft.VisualStudio.FSharp.ProjectSystem.ReferenceContainerNode.AddReferenceFromSelectorData(VSCOMPONENTSELECTORDATA selectorData)\n   at Microsoft.VisualStudio.FSharp.ProjectSystem.Automation.OAReferences.<>c__DisplayClass1.<Add>b__0()\n   at Microsoft.VisualStudio.Shell.InvokableFunction`1.InvokeMethod()\n   at Microsoft.VisualStudio.Shell.InvokableBase.Invoke()\n   --- End of inner exception stack trace ---\n   at Microsoft.VisualStudio.Shell.ThreadHelper.InvokeOnUIThread(InvokableBase invokable)\n   at Microsoft.VisualStudio.Shell.ThreadHelper.Invoke[TResult](Func`1 method)\n   at Microsoft.VisualStudio.FSharp.ProjectSystem.Automation.OAReferences.Add(String bstrPath)\n   at NuGet.VisualStudio.VsProjectSystem.AddGacReference(String name)\n   at NuGet.VisualStudio.FSharpProjectSystem.AddGacReference(String name)\n   at NuGet.VisualStudio.VsProjectSystem.AddFrameworkReference(String name)\n   --- End of inner exception stack trace ---\n   at NuGet.VisualStudio.VsProjectSystem.AddFrameworkReference(String name)\n   at NuGet.ProjectManager.ExtractPackageFilesToProject(IPackage package)\n   at NuGet.ProjectManager.AddPackageReferenceToProject(IPackage package)\n   at NuGet.ProjectManager.Execute(PackageOperation operation)\n   at NuGet.ProjectManager.Execute(IPackage package, IPackageOperationResolver resolver)\n   at NuGet.ProjectManager.AddPackageReference(IPackage package, Boolean ignoreDependencies, Boolean allowPrereleaseVersions)\n   at NuGet.VisualStudio.VsPackageManager.<>c__DisplayClass83.<AddPackageReference>b__85()\n   at NuGet.VisualStudio.VsPackageManager.RunProjectAction(IProjectManager projectManager, Action action)\n   at NuGet.VisualStudio.VsPackageManager.AddPackageReference(IProjectManager projectManager, IPackage package, Boolean ignoreDependencies, Boolean allowPrereleaseVersions)\n   at NuGet.VisualStudio.VsPackageManager.<>c__DisplayClass3.<InstallPackage>b__7()\n   at NuGet.VisualStudio.VsPackageManager.RunSolutionAction(Action action)\n   at NuGet.VisualStudio.VsPackageManager.InstallPackage(IProjectManager projectManager, String packageId, SemanticVersion version, Boolean ignoreDependencies, Boolean allo\nwPrereleaseVersions, Boolean skipAssemblyReferences, ILogger logger)\n   at NuGet.VisualStudio.VsPackageManager.InstallPackage(IProjectManager projectManager, String packageId, SemanticVersion version, Boolean ignoreDependencies, Boolean allo\nwPrereleaseVersions, ILogger logger)\n   at NuGet.PowerShell.Commands.InstallPackageCommand.InstallPackage(IVsPackageManager packageManager)\n   at NuGet.PowerShell.Commands.InstallPackageCommand.ProcessRecordCore()\n   at NuGet.PowerShell.Commands.NuGetBaseCommand.ProcessRecord()\nPM>\nIf you want, I can try lately if I can reproduce the problem and post again $error[0].Exception.ToString() result.\n. ",
    "gep13": "I have just ran into this same problem.  Using Visual Studio 2015.  Was able to install the package successfully from the Package Manager Console, but not through the Manage Nuget Packages UI.\n. Sorry about all the notifications about my commit comment.  I didn't realise that they would show up here :smile_cat: \n. Thank you so much for digging into this!\n\n@ryangribble said...\nI might ping github support about this to see if there is an explanation\n\nIf you could I would really appreciate it.\nThe idea was really to create the list that you can see here:\nhttp://cakebuild.net/blog/2016/07/cake-v0-15-0-released\n\nWhich is a link to that person's GitHub profile page.  I can certainly fall back to using the Display Name for that user in the case where the Login name isn't provided.\n@adamhathcock @markrendle @wwwlicious you were the three users that were not included in the list that I generated using Octokit for our blog post.  Are you aware of any issues with your account regarding email verification status, that would stop this being shown.  Or any security restrictions that you have put on our account to stop this information coming through?  Thanks!\n. > @ryangribble said...\n\nPS I listened to your DNR podcast on cake recently and although I knew it was out there it's motivated me to put it on the todo list to go and check it out!  :+1:\nI havent looked as yet, but I was thinking it'd be cool to have some \"github\" tasks in cake (using octokit.net of course!) if you don't already...\n\nWoot!  Glad to hear that it helped motivate you to look into it! :smile: \nWe have an Addin for doing some command line Git things.  You can find this here, but nothing directly against the GitHub API.  Although, we do have support for GitReleaseManager which uses Octokit under the hood to allow the generation of a GitHub release with release notes based on Issues/PR's in a milestone, uploading assets into a release, publishing a release, and then closing a milestone, etc,\nThe reason that this question came up was that I was planning on adding support for generating a list of contributors in a release to GitReleaseManager, which I thought would be a useful addition.\nWould love to hear if you have any other thoughts in this area, or if you wanted to create a Cake.GitHub addin.\n. @ryangribble after associating the emails with the account, should I expect to see a non null in the response of the octokit call?\n. @markrendle I retrospectively added you too the blog post :smile:\n. > @ryangribble said...\n\nyep! Once the email address is \"claimed\" the output will contain the expected github Author.\n\nPerfect!  I have just confirmed that this is now the case.  I now get the Author property populated for both @markrendle and @wwwlicious.  The only one that is still not populated is @adamhathcock but I am going to assume that this is the same issue.\n\n@ryangribble said...\nAs there's nothing to stop this happening on any future commit/author, it's probably a good idea to implement the fallback to commit.Commit?.Author?.Name when commit.Author?.Login is null\n\nAgreed, I will go that.\nI am going to go ahead and close this, thanks for all your help!\n. > @adamhathcock said...\n\nI'm sure my email is the same issue because I did fixes at work with git instead of home. I'll fix my profile. Thanks!\n\nPerfect, thank you! :smile: \n. @ryangribble that is an interesting approach with running GitVersion on non-windows!  Great thinking!. ",
    "steveoh": "coworker hit this today on a fresh vs2017 install.\n\nHe added system.net.http manually\n@ryangribble \ntarget framework 4.6.1\noctokit version 0.31\nvs version 15.8\ndotnet info\n\n. It was an existing project with the old project format. \nI was helping my coworker add proevergreen to this project and it happened. Proevergreen has a dependency on octokit. . ",
    "ironfist": "Ok, here's Fiddlers raw output for the request when I use await.  We are using Enterprise GitHub, so I've fudged the URL a little:\nPOST http://github.myorg.com/api/v3/repos/appdev/skillsmatrix/labels HTTP/1.1\nAccept: application/vnd.github.v3+json; charset=utf-8\nUser-Agent: appdev-hook-processor (Win32NT 6.1.7601; amd64; en-US; Octokit 0.13.0)\nAuthorization: Basic cnVpc2pvYnM6bjBkQGJ0Y2g=\nContent-Type: application/x-www-form-urlencoded; charset=utf-8\nHost: github.beav.com\nContent-Length: 33\nExpect: 100-continue\nAccept-Encoding: gzip, deflate\nProxy-Connection: Keep-Alive\nLooks like there is no json at the bottom!  Wha!\nHere's the response:\n```\nHTTP/1.1 408 Request body incomplete\nDate: Wed, 24 Jun 2015 18:15:31 GMT\nContent-Type: text/html; charset=UTF-8\nConnection: close\nCache-Control: no-cache, must-revalidate\nTimestamp: 14:15:31.674\nThe request body did not contain the specified number of bytes. Got 0, expected 33                      \n```\nNow if I use task.Result like you asked:\n```\nPOST http://github.myorg.com/api/v3/repos/appdev/skillsmatrix/labels HTTP/1.1\nAccept: application/vnd.github.v3+json; charset=utf-8\nUser-Agent: appdev-hook-processor (Win32NT 6.1.7601; amd64; en-US; Octokit 0.13.0)\nAuthorization: Basic cnVpc2pvYnM6bjBkQGJ0Y2g=\nContent-Type: application/x-www-form-urlencoded; charset=utf-8\nHost: github.beav.com\nContent-Length: 33\nExpect: 100-continue\nAccept-Encoding: gzip, deflate\nConnection: Keep-Alive\n{\"name\":\"defer\",\"color\":\"c7def8\"}\n```\nYay, json!\nAnd response:\n```\nHTTP/1.1 201 Created\nServer: GitHub.com\nDate: Wed, 24 Jun 2015 18:20:29 GMT\nContent-Type: application/json; charset=utf-8\nContent-Length: 110\nStatus: 201 Created\nCache-Control: private, max-age=60, s-maxage=60\nETag: \"e0f42e11dee9e870e9eb01c686b97114\"\nLocation: http://github.myorg.com/api/v3/repos/appdev/skillsmatrix/labels/defer\nVary: Accept, Authorization, Cookie, X-GitHub-OTP\nX-GitHub-Media-Type: github.v3; format=json\nX-XSS-Protection: 1; mode=block\nX-Frame-Options: deny\nContent-Security-Policy: default-src 'none'\nAccess-Control-Allow-Credentials: true\nAccess-Control-Expose-Headers: ETag, Link, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval\nAccess-Control-Allow-Origin: *\nX-GitHub-Request-Id: 1ef1f9cc-d56c-4577-9ba3-a002ee913ea1\nX-Content-Type-Options: nosniff\n{\"url\":\"http://github.myorg.com/api/v3/repos/appdev/skillsmatrix/labels/defer\",\"name\":\"defer\",\"color\":\"c7def8\"}\n```\nUnfortunately, I can't use the Result way because that forces it to be synchronous.  I'll be processing these in mass, so I need it to be asynchronous.  Must be something with the await/async...... ?\n. ",
    "AlfredoMS": "Hey, I just hit this issue but the workaround provided earlier isn't working for me.\nI'm using this:\nC#\nvar content = Request.Content.ReadAsStringAsync().Result;\nvar payload = new Octokit.Internal.SimpleJsonSerializer().Deserialize<PullRequestEventPayload>(content);\nBut I'm seeing an exception:\nSystem.InvalidCastException occurred\n  HResult=-2147467262\n  Message=Invalid cast from 'System.Int64' to 'System.DateTimeOffset'.\n  Source=mscorlib\n  StackTrace:\n       at System.Convert.DefaultToType(IConvertible value, Type targetType, IFormatProvider provider)\nThis is the payload I received:\n``` json\n{\n  \"ref\": \"refs/heads/test2\",\n  \"before\": \"0000000000000000000000000000000000000000\",\n  \"after\": \"e3c6a7823d1073135fb71aa643d7bb1f73a2fd2f\",\n  \"created\": true,\n  \"deleted\": false,\n  \"forced\": true,\n  \"base_ref\": null,\n  \"compare\": \"https://github.com/AlfredoMS/DemoRepo/commit/e3c6a7823d10\",\n  \"commits\": [\n    {\n      \"id\": \"e3c6a7823d1073135fb71aa643d7bb1f73a2fd2f\",\n      \"distinct\": true,\n      \"message\": \"Add file2\",\n      \"timestamp\": \"2015-08-28T14:32:52-07:00\",\n      \"url\": \"https://github.com/AlfredoMS/DemoRepo/commit/e3c6a7823d1073135fb71aa643d7bb1f73a2fd2f\",\n      \"author\": {\n        \"name\": \"Alfredo Menendez Sancho\",\n        \"email\": \"alfremen@microsoft.com\",\n        \"username\": \"AlfredoMS\"\n      },\n      \"committer\": {\n        \"name\": \"Alfredo Menendez Sancho\",\n        \"email\": \"alfremen@microsoft.com\",\n        \"username\": \"AlfredoMS\"\n      },\n      \"added\": [\n        \"file2.txt\"\n      ],\n      \"removed\": [\n  ],\n  \"modified\": [\n\n  ]\n}\n\n],\n  \"head_commit\": {\n    \"id\": \"e3c6a7823d1073135fb71aa643d7bb1f73a2fd2f\",\n    \"distinct\": true,\n    \"message\": \"Add file2\",\n    \"timestamp\": \"2015-08-28T14:32:52-07:00\",\n    \"url\": \"https://github.com/AlfredoMS/DemoRepo/commit/e3c6a7823d1073135fb71aa643d7bb1f73a2fd2f\",\n    \"author\": {\n      \"name\": \"Alfredo Menendez Sancho\",\n      \"email\": \"alfremen@microsoft.com\",\n      \"username\": \"AlfredoMS\"\n    },\n    \"committer\": {\n      \"name\": \"Alfredo Menendez Sancho\",\n      \"email\": \"alfremen@microsoft.com\",\n      \"username\": \"AlfredoMS\"\n    },\n    \"added\": [\n      \"file2.txt\"\n    ],\n    \"removed\": [\n],\n\"modified\": [\n\n]\n\n},\n  \"repository\": {\n    \"id\": 41393892,\n    \"name\": \"DemoRepo\",\n    \"full_name\": \"AlfredoMS/DemoRepo\",\n    \"owner\": {\n      \"name\": \"AlfredoMS\",\n      \"email\": \"alfremen@microsoft.com\"\n    },\n    \"private\": false,\n    \"html_url\": \"https://github.com/AlfredoMS/DemoRepo\",\n    \"description\": \"Repo used for demo/test/experimental purposes\",\n    \"fork\": false,\n    \"url\": \"https://github.com/AlfredoMS/DemoRepo\",\n    \"forks_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/forks\",\n    \"keys_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/keys{/key_id}\",\n    \"collaborators_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/collaborators{/collaborator}\",\n    \"teams_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/teams\",\n    \"hooks_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/hooks\",\n    \"issue_events_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/issues/events{/number}\",\n    \"events_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/events\",\n    \"assignees_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/assignees{/user}\",\n    \"branches_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/branches{/branch}\",\n    \"tags_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/tags\",\n    \"blobs_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/git/blobs{/sha}\",\n    \"git_tags_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/git/tags{/sha}\",\n    \"git_refs_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/git/refs{/sha}\",\n    \"trees_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/git/trees{/sha}\",\n    \"statuses_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/statuses/{sha}\",\n    \"languages_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/languages\",\n    \"stargazers_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/stargazers\",\n    \"contributors_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/contributors\",\n    \"subscribers_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/subscribers\",\n    \"subscription_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/subscription\",\n    \"commits_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/commits{/sha}\",\n    \"git_commits_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/git/commits{/sha}\",\n    \"comments_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/comments{/number}\",\n    \"issue_comment_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/issues/comments{/number}\",\n    \"contents_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/contents/{+path}\",\n    \"compare_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/compare/{base}...{head}\",\n    \"merges_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/merges\",\n    \"archive_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/{archive_format}{/ref}\",\n    \"downloads_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/downloads\",\n    \"issues_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/issues{/number}\",\n    \"pulls_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/pulls{/number}\",\n    \"milestones_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/milestones{/number}\",\n    \"notifications_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/notifications{?since,all,participating}\",\n    \"labels_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/labels{/name}\",\n    \"releases_url\": \"https://api.github.com/repos/AlfredoMS/DemoRepo/releases{/id}\",\n    \"created_at\": 1440546712,\n    \"updated_at\": \"2015-08-25T23:51:52Z\",\n    \"pushed_at\": 1440797587,\n    \"git_url\": \"git://github.com/AlfredoMS/DemoRepo.git\",\n    \"ssh_url\": \"git@github.com:AlfredoMS/DemoRepo.git\",\n    \"clone_url\": \"https://github.com/AlfredoMS/DemoRepo.git\",\n    \"svn_url\": \"https://github.com/AlfredoMS/DemoRepo\",\n    \"homepage\": null,\n    \"size\": 0,\n    \"stargazers_count\": 0,\n    \"watchers_count\": 0,\n    \"language\": null,\n    \"has_issues\": true,\n    \"has_downloads\": true,\n    \"has_wiki\": true,\n    \"has_pages\": false,\n    \"forks_count\": 0,\n    \"mirror_url\": null,\n    \"open_issues_count\": 1,\n    \"forks\": 0,\n    \"open_issues\": 1,\n    \"watchers\": 0,\n    \"default_branch\": \"master\",\n    \"stargazers\": 0,\n    \"master_branch\": \"master\"\n  },\n  \"pusher\": {\n    \"name\": \"AlfredoMS\",\n    \"email\": \"alfremen@microsoft.com\"\n  },\n  \"sender\": {\n    \"login\": \"AlfredoMS\",\n    \"id\": 6474954,\n    \"avatar_url\": \"https://avatars.githubusercontent.com/u/6474954?v=3\",\n    \"gravatar_id\": \"\",\n    \"url\": \"https://api.github.com/users/AlfredoMS\",\n    \"html_url\": \"https://github.com/AlfredoMS\",\n    \"followers_url\": \"https://api.github.com/users/AlfredoMS/followers\",\n    \"following_url\": \"https://api.github.com/users/AlfredoMS/following{/other_user}\",\n    \"gists_url\": \"https://api.github.com/users/AlfredoMS/gists{/gist_id}\",\n    \"starred_url\": \"https://api.github.com/users/AlfredoMS/starred{/owner}{/repo}\",\n    \"subscriptions_url\": \"https://api.github.com/users/AlfredoMS/subscriptions\",\n    \"organizations_url\": \"https://api.github.com/users/AlfredoMS/orgs\",\n    \"repos_url\": \"https://api.github.com/users/AlfredoMS/repos\",\n    \"events_url\": \"https://api.github.com/users/AlfredoMS/events{/privacy}\",\n    \"received_events_url\": \"https://api.github.com/users/AlfredoMS/received_events\",\n    \"type\": \"User\",\n    \"site_admin\": false\n  }\n}\n```\nAny ideas?\n. @shiftkey, So I made a simple console app that consumes the json I posted an then tries to parse it:\nC#\nstring inputJson = File.ReadAllText(\"payload.json\");\nPullRequestEventPayload payload = new Octokit.Internal.SimpleJsonSerializer().Deserialize<PullRequestEventPayload>(inputJson);\nI found the exception by being thrown in this line https://github.com/octokit/octokit.net/blob/e6e7c3d393160fabe4cc48dd6c410db2a19b7e72/Octokit/SimpleJson.cs#L1397\nThis happens when trying to parse \"created_at\" and \"pushed_at\" inside \"repository\".\nApparently it expects it to be a string to be checked for DateTimeOffset (https://github.com/octokit/octokit.net/blob/e6e7c3d393160fabe4cc48dd6c410db2a19b7e72/Octokit/SimpleJson.cs#L1356)\nAccording to the API documentation these two members should have a format like \"2011-09-06T20:39:23Z\" (as shown in https://developer.github.com/v3/repos/hooks/) but it is instead receiving a long number, in this case:\n\"created_at\": 1440546712,\n    \"updated_at\": \"2015-08-25T23:51:52Z\",\n    \"pushed_at\": 1440797587,\nexcept, update_at is in the expected format, so I'm not sure what is going on.\n. Update: without doing anything I started getting payloads with the right date format, so this is working.\n. ",
    "hisuwh": "I've just had the same problem as @AlfredoMS \nIs their a new issue for this or should I open a new one?. What I found was a merged pull request didn't parse correctly but open ones did. ",
    "itaibh": "I see the same problem here. Seems \"created_at\" and \"pushed_at\" are in unix epoch representation, while \"updated_at\" is in ISO representation.\nAlso, from the timing it seems the problem had returned only recently (about two weeks ago).\nIs there anything I can do to ignore or correctly parse those fields?. Another thing - I see it sometimes happens and sometimes not. Perhaps it depends on the state of the current PR.. In some cases GitHub sends wrong date format for the \"created_at\" and \"pushed_at\" fields. This is a GitHub bug, probably, but still, such a convention should be supported (and it would have saved me hours of debugging).\nBack in 2015 there was an open issue on this, which I commented on today, but I can't find it right now. I'm sending this from my phone, and don't have the full attention to provide more info right now.. I'm experimenting with web hooks on my own fork of spoon-knife.\nI noticed that it happens for some push events.\nEDIT: It seems to happen on all push events.\nOn Mon, Jan 1, 2018, 23:07 Brendan Forster notifications@github.com wrote:\n\n@itaibh https://github.com/itaibh thanks for the extra info. I found\n825 https://github.com/octokit/octokit.net/issues/825 where you\ncommented earlier.\nThis is a GitHub bug, probably, but still, such a convention should be\nsupported (and it would have saved me hours of debugging).\nIn your other comment you mention this:\nAlso, from the timing it seems the problem had returned only recently\n(about two weeks ago).\nIf this is a recent regression then I'd love to try and chase this down,\nbecause we should be consistent with these fields. If you can point me to a\nrepository which fired a webhook with the wrong format for created_at and\npushed_at in the payload I can chase that up internally and confirm it's\nbeen resolved while we discuss this fix.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/1731#issuecomment-354677337,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAImtw4tvzrtwRnZqiVmVWAWM138SbiQks5tGUkSgaJpZM4RQGL1\n.\n. Hi @ryangribble!\nThank you. I consider it ready, and have removed the [WIP] tag.. @ryangribble I'm not sure I actually got it right. How does that number represents time? Is it actually a file time? or is it the number of seconds since the Unix Epoch?. Thanks. I made the required changes and pushed, as you can see. I also updated a bit the solution folder structure (virtual structure) so all the tests projects are bound together under the \"Tests\" solution folder. I hope that's okay. If you don't like it, feel free to remove it from the PR.. Done!. bump. bump. All done!. Done. OK, then.\nTell me what tests are still missing and I'll add them to my backlog.. OK, then I'll get to it when I have the time, which currently I don't have enough of \ud83d\ude03 \nI think I'll start with fixing according to your review notes, implement the missing parts that are straight-forward.\nI'll read what you wrote about tests, check out the demo project.\n\nRegarding tests, I'll just say that I currently use this code in a project here where I work, and for what we need, it is working and tested, so I think it can be merged, just so it won't get too big a merge. May I suggest that'll once I push the fixes you requested, you'll merge it and open another issue for tests?. In that case I'll be glad to have some help writing the tests. Especially integration tests that require connecting to GitHub. I didn't look yet at the demo projects and I currently work on completing the reviewed code.. I added some unit tests, but I don't know how to run the integration tests.. Now I figured out how to run the Integration tests, but I don't know how to set up a test account (I created a new account, added a new organization, created a PAT, ran the configuration script, even installed the app I wrote), and for some reason I can't debug it (it constantly fails to attach the debugger).\n@ryangribble Can you please help?. I am using Visual Studio 2017, that was the only version I managed to open the solution in.\nBut I can't get it to debug the integration tests.. How can I print to the log (output pane, show output from tests) in an integration test? Perhaps I can debug \"the old way\".... @ryangribble You mean something like this? (See above changes, https://github.com/octokit/octokit.net/pull/1738/commits/3211fc7fdfb98ee074a11ed16972b26759b6cce4 ) . What about adding methods specifically inside Installation and such, making it more OOP like? I mean, why write this:\nc#\nlong installationId = myInstallation.Id;\nAccessToken accessToken = await client.GitHubApps.CreateInstallationToken(installationId)\nwhen you can write this:\nc#\nAccessToken accessToken = await myInstallation.CreateToken();. @ryangribble Can you please take another look at this PR? Thanks.. Hi there, @ryangribble!\nDid you have a chance to take a look on the changes? Do you have any comments?. Thanks, @ryangribble!\nI fixed the build (it seems you forgot to update a test) and now all tests pass.\nCan you please merge it to the master now? I think the rest of the review notes we can fix in a later time.. Hi @ryangribble,\nI already added all the required unit test (I used other unit tests as reference to what is needed, so if I missed something please tell me).\nI don't know how to write integration tests nor how to run them locally. I tried once (even twice \ud83d\ude03), and I get connection errors of various types. I started adding the GitHubAppsClientTests integration tests, but since I can't debug it locally I can't continue. I know for sure it doesn't throw exception, as the main function is getting called.\nRegarding missing XML comments - what comments are missing exactly? I'm only asking because when I build the project I already get tons of \"missing xml comment for publicly visible type or member\" warnings, most of them for data fields, so I didn't bother adding XML comments for the new data fields. I did try to add XML comments to all new methods, so please tell me if I missed anything.\nRegarding the more complete implementation and some solution around JWT tokens - up until I started writing this feature it was not implemented at all (no JWT token, I don't know what FWT token is), so I think users get at least something which allows them to start writing extensions, don't you agree?\nI already use it in code that is going to be integrated into production soon, and I don't think there'll be too big a change after the fixes you request, if any.\nPlease tell me what you think.. I've added and fixed some XML documentation tags.\nI also want you to notice the name of this PR - it states this is an \"initial support ...\", not \"complete support ...\". Just saying.. sorry for the merges and reverts, my git client got me confused a little bit. :flushed:\n. @ryangribble Hmmm... seems like the last merge messed things up. I'm on it.. @ryangribble Done (until further requests.). @ryangribble I read your docs. Looks good!\nI just added a new feature allowing to get the Installation ID (wrapped in an empty Installation object, perhaps we should do something about it) from any event's payload. I think you should mention that in the docs to help developers get the access token for an installation in case they need it for tasks like creating status notifications.. Turns out I didn't have the correct version of .Net Core installed (I only installed version 2.x, while the project requires version 1.x). Also, I had to remove net45 and net452 from the <TargetFrameworks> tag. Thing is, I can't commit such a change. Any reason why the Linux tools doesn't just ignore any missing framework?. The Travis build failed on a non-related issue (it couldn't install mono because of connection timeout) and I can't run the build again.\n@ryangribble Can you please rebuild? (and merge?). Fixed in #1844 . I just tried that, and I don't know when to create a new PushWebhookPayload instance.\nI mean, I do need to deserialize it from a JSON coming from the server, but the name the server sends is the same as of a regular push event.\nAm I missing something?. @ryangribble Any news regarding my question?. @ryangribble I merged with latest changes on master with my changes. Hopefully I did it right.\nAll the new PushWebhook* classes are here, but now I need to deserialize them, and I don't know how to distinguish between the PushWebhookEvent payload and the PushEvent payload in SimpleJsonSerializer.cs in the GetPayloadType(string activityType) method.\nCan you review it please and try to help me figure it out?. @GMouron fine by me \ud83d\ude03 . Done.. But I see there is AhtorizationsClient and ActivitiesClient, in fact only ApplicationClient is in singular form.... Already did in some places. Will change that one too.. Oh, sorry, I see now what you meant. Will fix.. Are you sure? AFAIK the run time takes care about it.... Not at the moment. They are merely placeholders so I won't forget where I need to add them.. This is a brand new feature of C# and won't compile on older versions of the compiler. Are you sure you want to switch to this?. ",
    "GMouron": "In case someone comes here (like I did) and is not, let's say, American :)\nThe code is actually incorrect.\nYou should use the UTF-8 encoding and nt the Ascii Encoding.\nSo the line var encoding = new System.Text.ASCIIEncoding(); should be var encoding = new System.Text.UTF8Encoding();\nAt first, it worked fine for me but then it started to \"randomly\" fail, the reason was I had accented characters in the content of the payload.. Hello, @ryangribble @itaibh , I'm actually interested in this PR.\nMay I fork it and make the modifications asked so it can land on master ?\nI don't know exactly what's the etiquette in this kind of situation since there is no news since July 30th .... Actually, I see that @itaibh did make the modifications asked by the code review. Hello, any idea of when this could land on master ?\nAnd another slightly related question, when do you usually make a new release from master ?\nThanks :). > Hi @GMouron, thanks for this! It looks good although one thing I noticed when checking the docs is that the create event payload has master_branch and description fields as well, so it would seem a good idea to add them to the response model in this PR. What do you think?\n\nhttps://developer.github.com/v3/activity/events/types/#createevent\n\nHello, yes, it mentions those 2 properties, however, the doc mentions that webhooks do not receive repository creation events :\n\nNote: webhooks will not receive this event for created repositories. Additionally, webhooks will not receive this event for tags if more than three tags are pushed at once.\n\nAnd when I see the explaination of those 2 fields :\n\nmaster_branch | string | The name of the repository's default branch (usually\u00a0master).\ndescription | string | The repository's current description.\n\nas well as the content of the events sent by github for the creation of a branch which does not contain them, I've decided to omit these here since, from my understanding, they will never be part of the payload we receive. OK, I'll be adding them then :). And done :). > Thanks @GMouron! (we have quite a few payload events that aren't implemented - it would be great if you wanted to add more!)\n\n\n\nHi, I might take a look into that a bit later but I really needed those ones and I have to first take care of the code that depends on them \ud83d\ude04 . fixed :). ",
    "gistofj": "Windows 8.1 + patches :confused: \n. > Oh, interesting. I'm not sure what the story is with Windows Store Apps + VS2015 but that gives me enough to reproduce it at least.\nIs that the issue? I likely mucked something up installing, uninstalling, reinstalling, edit, reinstalling, etc... various Windows Kits and versions of Visual Studio.\nVery unfortunate, but not something I can easily recover from. Luckily it sounds like it is mostly my problem... is that correct?\n. Do you have a URL for the \"bits [I] need\"? If so, I could try to grab them... some how.\n. @shiftkey any luck? :smirk: \n. Hanging. :-) In the meantime, do you have any time to assist/advise on a separate but related project?\n. Thanks - looks like a manual setup then and not something Octokit handles. Is that a correct assessment?\n. @Haacked honestly, I'm looking to do this with client-side automation so these would be in a command-line or powershell environment. I'd have access to interactive sessions however, so I suppose WPF would be acceptable. I think the biggest hurdle will be 2fa.\nRight now I'm looking at hitting http://api.github.com/v3/authorization, catching a failure, look at the header for 2fa failure codes, and then asking for the 2fa bit. In theory, with that - I should be able to acquire a token, store it, and reuse it as needed.\nSounds about right?\n. ",
    "qin-nz": "My code is following:\ncsharp\n  public ActionResult DeployWebsite()\n        {\n            var deployId = Guid.NewGuid();\n            var deploys = new WebsiteDeploy(deployId) ;\n            deploy.StartFullDeploy();\n            return RedirectToAction(\"DeployLog\");\n        }\ncsharp\n  public void StartFullDeploy()\n        {\n            FullDeployAsync();\n        }\ncsharp\n  public async Task FullDeployAsync()\n        {\n            try\n            {\n                var masterDirectory = await DownloadMasterFromGithub().ConfigureAwait(false);\n                Log(\"\u6210\u529f\u4e0b\u8f7d\u6587\u4ef6\");\n            }\n            catch (Exception ex)\n            {\n                Log(\"\u51fa\u73b0\u5f02\u5e38\");\n            }\n        }\n. ",
    "Eilon": "@shiftkey I'm using Octokit in a DNX app on .NET Framework 4.5 just fine. Are you trying to use it on .NET Core (dnxcore)?\n. Yeah I'm using dnx451 only right now. For dnxcore50 it's a matter of compiling against that target framework and making all the tests run. We're (Microsoft) working on that guidance right now, but there are a few bits and pieces that aren't quite in place to make it a super smooth story across the board.\n. @wdhodges what exactly are you looking for? Ultimately Octokit is mostly a bunch of async API calls - you could bind the results to a GridView or whatever you want.\n. https://github.com/octokit/octokit.net/issues/875\n. Thanks!\n. If that's all it takes I can send a PR.\n. @Haacked because reasons.\n. Yessir!\n. Sweet, I didn't even have to write any code :smile: \n. Sorry not sure about netcore45 as I've never really use that. But this change as-is certainly seems to fix a real issue.\n. I talked to @anurse and he wasn't super sure. There is a concept of reference assemblies for netcore45 (Windows Phone, effectively), but either way a typical Windows Phone app effectively references everything on the system anyway (the dependencies are trimmed later).\nSo as such, I think this change is good as-is.\n. @Haacked I strongly suspect that GIF will get reused now :smile: \n. Looks :shipit: to me!\n. Yeah working on a PR :smile: Had to update some VS stuff to try to get everything to compile (I didn't have the WP8.1 SDK or something).\n. PR sent out: #1075 \n. Thanks dude! Now looking forward to the next release of Octokit :smile: \n. Cool.\n. Per my latest comment at https://github.com/octokit/octokit.net/pull/1339#issuecomment-268691145, I think this should also include adding this for PullRequest (and not just Issue).. Can we add support for multiple-assignees in PullRequest.cs as well? It ought to be basically the same as the change for Issue.cs.\nI desperately need this change for my app! \ud83d\ude04 . @ryangribble I think the Octokit.PullRequest type needs to be modified to have the new property, no? E.g. when I call gitHubClient.PullRequest.GetAllForRepository(owner, name) and get back an IReadOnlyList<PullRequest> I need that property, no?. @maddin2016 are you saying the data for multiple PR assignees isn't even on the wire?. Yeah I kept wondering why things like Comment count were always 0 for PRs. Kind of frustrating that I have to make additional calls for each PR I'm interested in... kind of blows away the rate limit with the amount of data I'm crunching!. Working just fine for me too, using 0.23.0 in an ASP.NET Core app.. OK looks like I can call:\nc#\nIssue.Labels.AddToIssue(......);\nTo more easily do what I want. But the issue above still seems valid.. Note: Looks like Issue.Labels.AddToIssue() doesn't work due to an Octokit bug (https://github.com/octokit/octokit.net/issues/1928), and also due to a GitHub issue anyway.. Here's the code I have to do to work around this issue:\n```c#\n            var issue = await gitHub.Issue.Get(\"owner\", \"repo\", issueNumber);\n        var issueUpdate = new IssueUpdate\n        {\n            Milestone = issue.Milestone?.Number // Have to re-set milestone because otherwise it gets cleared out. See https://github.com/octokit/octokit.net/issues/1927\n        };\n        issueUpdate.AddLabel(\"some label\");\n        // Add all existing labels to the update so that they don't get removed\n        foreach (var label in issue.Labels)\n        {\n            issueUpdate.AddLabel(label.Name);\n        }\n\n        await gitHub.Issue.Update(\"owner\", \"repo\", issueNumber, issueUpdate);\n\n```\n. BTW I don't see the problem with Assignee: I tested it out by only setting milestone and labels, and the existing assignee(s) on the issue remained.. BTW sorry I haven't had a chance to make a full repro. I will try to find time to provide more info. And BTW I was using this with GitHub.com, not GHE. The support person who I reported the general problem to said they couldn't repro it using the documented API call, so I'm not sure what problem I had with that. Could be I was doing something bonkers.. Yay!. Does this need to also be in the ctor of the type to get populated?. ",
    "eliah-hecht-zocdoc": "Here's the request as captured by Fiddler:\nGET https://api.github.com/repos/eliah-hecht-zocdoc/test/stats/contributors HTTP/1.1\nAccept: application/vnd.github.v3+json; charset=utf-8\nUser-Agent: ZocDuck (Win32NT 6.1.7601; amd64; en-US; Octokit 0.13.0)\nAuthorization: Token [redacted]\nHost: api.github.com\nAccept-Encoding: gzip, deflate\nAnd the response:\nHTTP/1.1 204 No Content\nServer: GitHub.com\nDate: Fri, 07 Aug 2015 14:47:34 GMT\nStatus: 204 No Content\nX-RateLimit-Limit: 5000\nX-RateLimit-Remaining: 4982\nX-RateLimit-Reset: 1438962403\nX-XSS-Protection: 1; mode=block\nX-Frame-Options: deny\nContent-Security-Policy: default-src 'none'\nAccess-Control-Allow-Credentials: true\nAccess-Control-Expose-Headers: ETag, Link, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval\nAccess-Control-Allow-Origin: *\nX-GitHub-Request-Id: 482B875E:6D94:1203408E:55C4C506\nStrict-Transport-Security: max-age=31536000; includeSubdomains; preload\nX-Content-Type-Options: nosniff\nVary: Accept-Encoding\nX-Served-By: 01d096e6cfe28f8aea352e988c332cd3\n. ",
    "poisonous-milk": "Added Merged Qualifier.Received Code Analysis Warning \"Excessive Cyclomatic Complexity\". \nThen added   [System.Diagnostics.CodeAnalysis.SuppressMessage(\"Microsoft.Maintainability\", \"CA1502:AvoidExcessiveComplexity\")] to ignore that warning.\n. See https://developer.github.com/v3/pulls/#get-a-single-pull-request\n\"The merge_commit_sha attribute holds the SHA of the test merge commit; however, this attribute is deprecated and is scheduled for removal in the next version of the API. The Boolean mergeable attribute will remain to indicate whether the pull request can be automatically merged.\"\nI think we need to set Merged to MergedAt.HasValue? or any other ideas? \n. it only appears on AppVeyor... Even though I am committing the same content, I cannot duplicate it\n. Cannot find a parameter in Created/Updated API that can clarify the type of the file. \n. My build in visual studio is good. \nI am confused by the BuildApp process. It seems that it will generate 3 new projects called Mono-touch , Netcore 45 and Portable. I'll try to find out those how those files had gone missing.  I think Netcore 45 is Octokit proj, Mono-touch is just Octokit Mono, and Portable is just Portable. The file sharing among these 3 projs is really confusing. \n. failed due to #904 @Haacked \n. @shiftkey \nThose are about #839\nMy bad. I should create a new branch of master when I started implementing this API. I will soon submit a new version without dependency on my earlier commits. \n. @shiftkey  no problem.  I will do that. Thx\n. I'm gonna do that if possible. \nCreateFileRequest contains that parameter. \n. im gonna check this.\n. awesome\n. I have added tests. This one is similar to GetRelease API. Just replaced release id with \"latest\".  In the tests for getrelease we are only checking if we can receive the get request at that endpoint and throw proper exceptions when missing arguments. If there is no latest release, are we expected to get a Null JSON or we a  500 error? \n. @shiftkey  I see. I will add integration tests soon.\n. @khalidabuhakmeh  I am busy with my final exams this week. I will add integration tests this weekend.\n. @Haacked  I'm just back to school. Will start working tmr\n. well. Another quuestion is merge-commit-sha. It is suggested that we use Mergeable instead of merge-commit-sha. Shall we also remove that? \nhttps://developer.github.com/v3/pulls/#get-a-single-pull-request\n. ",
    "Pilchard123": "4.5 support ending? Good to know, that'll make things much easier for me.\nThanks for taking the time to explain in more detail, as well. :)\n. ",
    "AmadeusW": "The code works when I use var user = github.User.Get(\"half-ogre\").Result;, but this breaks the await-async pattern.\n. I was running it from Visual Studio extension in VS 2015 (RTM).\nTo get my request to work, I started a new process from within the extension, which was a console app. It worked there.\nWould using an appdomain help in this case?\n. I've created a unit test that executes the same Octokit code as the Visual Studio extension.\nAll of the following work when executed a unit test context, but neither works in the Visual Studio extension.\n- var user = await github.User.Get(\"half-ogre\");,\n- var user = github.User.Get(\"half-ogre\").Result;.\n- var user = await github.User.Get(\"half-ogre\").ConfigureAwait(false); \nI will port this to VS2013 and test it there\n. Visual Studio 2013 is also frozen. For the last few days I can't reproduce the exception - code just hangs.\n. Thank you all for help!\n@Haacked fiddler has shown that the request has completed and GitHub returned a response.\nThis helped me detect a deadlock I created by misunderstanding of the async pattern. \nThe exception I posted at the beginning of the thread didn't seem to come to play and just confused me. \n. ",
    "shana": "I just ran your sample code from the onclick handler of a ToolWindow:\n```\n        async void button1_Click(object sender, RoutedEventArgs e)\n        {\n            await Connect();\n        }\n    async Task<string> Connect()\n    {\n        try {\n            GitHubClient client = new GitHubClient(new ProductHeaderValue(\"my.test.app\"));\n            var user = await client.User.Get(\"half-ogre\");\n            MessageBox.Show(string.Format(CultureInfo.CurrentUICulture, \"Invoked '{0}'\", user.Followers), \"ToolWindow1\");\n        }\n        catch (Exception ex)\n        {\n            MessageBox.Show(string.Format(CultureInfo.CurrentUICulture, \"Exception '{0}'\", ex), \"ToolWindow1\");\n        }\n        return string.Empty;\n    }\n\n```\nIt worked fine, showing a messagebox with \"Invoked '75'\".\nYour stacktrace suggests the calling thread is aborted just as the request is being built, which means it's not a timeout on the http side, but the environment aborting the thread. It might be that the way you call your CreateGist method is causing the thread to abort early, for some reason. Are you invoking it from the main thread, or from another thread? \n. @Haacked On GHfVS, this probe only runs if the url is not github.com, that check happens way before this. Unsure whether that would be a useful assumption here or not though :P\nEDIT: nvm, I see you're following the same logic here.\n. @shiftkey You mean a simple usage example? I think it should probably show what the return codes mean (Ok vs Failed vs NotFound), so people know how to properly handle them.\n. @shiftkey yeah, that's awkward, EnterpriseProbe requires GitHubClient, not the other way around. In VS I have MEF for this, which basically means that the probe constructor gets the productHeader and httpClient info from MEF, and whoever calls probe gets an instance of EnterpriseProbe through its constructor. That basically boils down to the example you had - do a new, await the probe, check the result - but the new is split off and done earlier.\nSo I think the example you first posted is appropriate for a simple usage. I think it's more important to clearly show what the return codes mean - Ok, Failed and NotFound - so people know how to handle them. How the EnterpriseProbe instance gets created is really a secondary thing, methinks. We could also have a static Probe method on EnterpriseProbe for a quick one-off, for scenarios where that makes sense.\n. Not to derail the whole thing, but I was looking at it and it feels like this shouldn't actually be a separate class specifically to poke enterprise, at least not as a public API.\nCorrect me if I'm wrong: The goal here is to identify whether the remote server is a github instance, and if it is, whether it's an enterprise instance, right? With that in mind, the solution should probably be a method that returns what type of server it is - dotcom, enterprise, other (not github) or unknown (unable to determine).  Since GitHubClient encapsulates server information, the method should probably live here, so something like\n```\nenum ServerType {\n DotCom,\n Enterprise,\n Other,\n Unknown (or NotFound?)\n}\nclass GitHubClient {\n public ServerType GetServerType() {}\n```\nThe EnterpriseProbe class can be kept as an internal implementation of the probe, and the GetServerType() method calls it if the uri is not dotcom.\nWhat do you think? (I'm happy to patch up the PR if you agree on this approach, I know you're crazy busy these days)\n. @shiftkey Not sure why the original code was written like that. In my code, calling EnterpriseProbe always happens together with determining what the server is - so I only call it if it's not a dotcom, and sometimes will check if it's an enterprise for authentication purposes. So enterprise probe is actually just half of the logic of identifying what the server is, and is pretty much always used in that way. By itself is not terribly useful, it needs to be combined with \"is this github.com, yes/no? is this enterprise, yes/no?\"\n\nI'm unsure about having the probe returning DotCom - this feels a lot like our internal lingo, but as you could invoke this on an instance without the URL set, which would be DotCom behaviour.\n\nThe url is always set, it's just defaulting to \"github.com\" :wink:\nIt's actually important to distinguish between dotcom and non-dotcom github servers, because authentication differs for those,the UI may be different depending on which one is it, and if it's neither, UI must be hidden in my case, so I need to know that as well. This is why I'm suggesting having a server identification method that tells me what type of server it is, rather than something that's enterprise-specific.\n. > However, I could imagine someone wanting to probe for capabilities in the future, in which this API could be the starting point for that.\nYeah, I actually already do something like that for wikis, and it would be nice if instead of manually firing probes I could just ask for capabilities from the API.\n. @ryangribble If the url isn't \"github.com\", then we poke it to see whether it is a github instance, and if it is, we classify it as an enterprise instance. In your scenario this would be a false positive (or negative?), but in practice it doesn't change much, clients will still know that the server is a github instance that they can interact with.\nDistinguishing between a github.com and a github enterprise instance is not enough to tell a client what the server can actually do - the only important bit of information they can get out of it is whether the server is a github server or not. The only reason we're actually distinguishing between github.com and an enterprise instance is because we know that enterprise instances can potentially support only a subset of authentication types if they're older, so we're using the url as a shortcut to only run the fallback code if it's a github server but it's not github.com (which we know supports all the things).\nAgain, in your scenario, if the url is aliased, a client would fallback to handling the server more carefully, so it's not a big deal if there's a false positive because of that.\nConcrete server capabilities checks I think should probably be done in separate calls, since all of these things require poking the server and aren't always needed by a client. In this way, we end up with a \"Is this a server we can talk to?\" call and \"Ah, it is! So I want to use this feature, is it available?\" calls.\n. @Haacked haha, yes... should I just push to this branch?\n. Damnit, sorry, I dropped the ball on this one \ud83d\ude1e\n. Maybe it only adds the references if it's a portable project? (I have no clue)\nI merged this into my GHfVS branch and it's building/working happily, fyi.\n. @shiftkey He probably bumped into the same problem I had - every single project in the solution that references Octokit suddenly wanted to have the Bcl, Bcl.Build and Http packages added to them, which amounts to a ton of build errors and quite a bit of changes. OTOH, removing this extraneous .targets reference was so much simpler...\n. > In fact, we could probably do away with the new packages specified here \nNot sure which ones you mean? (it doesn't actually link to a specific point in the diff probably because it's at the bottom of the page and can't scroll down more haha we should probably fix that at some point sigh anyways...)\n. @shiftkey Ah, indeed. I can certainly :fire: those as well!\n. @shiftkey I've killed the nuget references too. FWIW, I don't get the Octokit.Tests errors because I'm only building Octokit and Octokit.Reactive on VS (I trust you to run the tests :wink: )\n. > If we are starting now I would say the first thing to figure out is nuget package creation. \n@M-Zuber Just fyi, the GSoC student proposal application period starts March 14 and ends March 29, and the official coding period for the program doesn't start before May 29. \"Now\" is quite a ways away for GSoC :smile: \n. #### GSoC Students\nMake sure you read https://github.com/github/mentorships/issues/100 and http://write.flossmanuals.net/gsocstudentguide/what-is-google-summer-of-code/ and understand how the program works, how proposals are submitted, and all the milestones involved.\n. #### GSoC Students\nMake sure you read https://github.com/github/mentorships/issues/101 and http://write.flossmanuals.net/gsocstudentguide/what-is-google-summer-of-code/ and understand how the program works, how proposals are submitted, and all the milestones involved.\n. Looks like @paladique will start working on this in the next few days so hopefully you'll have this very soon \ud83d\ude04 \n. @adamralph I believe so, there's an open PR by another contributor that adds this. I'm not sure what the status of it is, looks like it's bumped against some architectural issues and it's not finished yet. Work is ongoing at https://github.com/octokit/octokit.net/issues/1339.\n. @adamralph That is a very good question. I think it's best if you post this use case in #1339 so that everyone is aware of it.\n. Ah, indeed! I'll hunt those down and update.\n. All places that use repositoryId hunted down and fixed...\n. Right, uint can't be negative, but I was wondering more about the identifier field itself. The API doesn't return -1 at any time in identifier fields, does it? Nor does octokit do that to signify some invalid state condition?\nI'm just curious, we can't change the type sign now since code assumes it for conversion purposes, just wondering of anything is taking advantage of the sign for something.\n. \u2728 \nBTW, thank you for being so consistent about naming things, it was way easier than I thought to fix all the tests! \u2764\ufe0f \n. PR updated against latest master.\nI was wondering, it's not like I want to have more work, but... this is technically an ABI change. Should I be obsoleting the existing methods that take an int and adding overloads that take a long, and redirecting the int implementations to long as appropriate?\n. > This is true, and after the whole discussion in #1464 I'm pondering how often I want to break the API as broadly as this (even if it is still pre 1.0 in semver land, this stuff sucks).\nYes, that one got me thinking about the breakage too. Also all the latest obsolete methods that are now gone and caused a bunch of conflicts on my rebase :-P\n\nGiven numeric ids are not going to be a part of the GraphQL API and I think we'll be supporting the v3 API for a while, that looming September 2017 deadline is my only concern about getting this in...\n\nLoooom. Well, I've only got myself to blame on this one, really. I'll add overloads for all the APIs and redirect as needed to avoid breakage. How many versions do obsolete methods usually last for?\n. It's up to you peeps. As far as the runtime is concerned, int->long is a breaking change at the ABI level, i.e., it'll throw methodnotfoundexception if you get the long version and you compiled against the int version. Since you don't sign the assembly, the runtime is free to provide whatever is already loaded in the domain, which might or might not be the actual specific version that is ABI compatible with what you built against.\nBut, since this is a < 0.x library and you don't sign it, there's no stringent compatibility requirement and it's going to blow up in people's faces anyway in shared appdomain scenarios, so \u00af(\u30c4)/\u00af\n. > Given its delivered via nuget there wouldn't be any supported way to update to the new version WITHOUT also compiling against it though right?\nWeeeeell actually (:trollface:), bla bla bla signing bla versioning bla runtime loader bla plugin model bla horrible explosion. There's a whole signing/versioning/plugin model discussion on that one and it's not relevant for this case \ud83d\ude04 \nWhen updating the nuget package and compiling against the new version, things should not break at all at compile time because implicit casts for wider numeric types are a thing. There might be silly people out there invoking octokit via reflection, that'll break them (but they probably deserve it? \u00af(\u30c4)/\u00af)\n. As I recall, the reason .NET has Async suffixes all over the place is because the original API was not async, and to maintain compatibility, instead of making the API async-first (as MS wanted), they instead added the Async suffix. MS decided not to break the API and every user out there even though an async-first API was their preferred choice.\nThe irony of creating new APIs outside of the original framework (and octokit is not a part of the .NET class libraries, it is an independent entity that has its own identity and API design decisions) and making them sync-first with Async suffixes for the async behaviour is, well, ironic?\n. What I found while poking at enterprise responses is that if it throws an exception, it might still be an enterprise server, it just might be configured to not let you poke without authentication, even if this entry point is supposed to be unauthenticated. In this case, the exception will have the response, so this can look for that (I do it like so here)\n. Could just do \n.Catch(ex => (ex as ApiException)?.HttpResponse ?? null);\nhere so the IsEnterpriseResponse below can handle both successful and failed http requests in one go. For the purposes of the check, we don't really care if it's successful, we just care to poke at the headers to see who's responding, right?\n. Ah good ol' C# 6. I guess\n```\nIResponse response = null;\ntry\n{\n    response = await httpClient.Send(request);\n}\ncatch (ApiException ex)\n{\n    response = ex.HttpResponse;\n}\ncatch\n{\n}\nreturn response == null\n    ? EnterpriseProbeResult.Failed\n    : (IsEnterpriseResponse(response)\n        ? EnterpriseProbeResult.Ok\n        : EnterpriseProbeResult.NotFound);\n```\nshould work equally well.\n. Looks like you got a merge failure here.\n. Apologies for the drive-thru comment, but maybe what we should actually have is a standard group of SetLabel/AppendLabel/ClearLabels methods to clearly allow for all the possible ways of manipulating the list (replacing/appending/clearing) so that users won't be tempted to manipulate the list directly and can trust the methods to do what is required? And then apply the same pattern to all multiple categorization lists (assignees, etc).\n. ",
    "kdolan": "Unsupported \"application/octet-stream\"\n{Octokit.ApiException: Unsupported 'Accept' header: [\"application/octet-stream\"]. Must accept 'application/json'.\n   at Octokit.Connection.HandleErrors(IResponse response) in octokit.net\\Octokit\\Http\\Connection.cs:line 550}\n. @shiftkey I just made a public repo for what I am trying to do. Basically an auto updater that downloads a zip file and then extracts it. In the repo I used the Nuget package but I've also used the project source with the same result.\nhttps://github.com/kdolan/AutoUpdater\n. @shiftkey After some more trouble shooting this appears to be an issue with the API/request. The error above is from the API not from this codebase. I verified this using postman. It would appear then that maybe the BrowserDownloadUrl is what needs to be used, however, whenever I try to download the file using postman I get a 404 (because it is a private repo) and token authentication does not appear to work for the browser download URL.\n\n\n. ``` c#\nvar request = client.Release.GetAll(\"kdolan\", \"AutoUpdater\");\nvar releases = await request;\nvar latest = releases[0];\nvar latestAsset = await client.Release.GetAllAssets(\"kdolan\", \"AutoUpdater\", latest.Id);\n//Download Release.zip here\nvar response = await client.Connection.Get(new Uri(latestAsset[0].Url), new Dictionary(), \"application/octet-stream\");\nbyte[] bytes = Encoding.ASCII.GetBytes(response.HttpResponse.Body.ToString()); ;\nFile.WriteAllBytes(\"Release.zip\", bytes);\n```\nThis code is working for me; I was targeting the wrong API Endpoint. However, the actual writing of the zip file to disk does not seem to always work. The release for AutoUpdater just has a small text file in it and this code works fine, however, when I try other repos with larger Release Zips then the Zip file written is corrupt/incomplete. \n. ",
    "davidalpert": "@Haacked tried your suggestion of an Empty static instead of null; moved it to it's own class to avoid coupling Connection to depend on ApiConnection while ApiConnection depends on IConnection.\nTake a look. All tests pass. Ran .\\build FixProjects to add ResponseBody.cs to all projects. And it fixed my use case. :+1: \n. ",
    "Nasicus": "@khellang Thanks for this fast and good answer!\nLooks like I'm a complete idiot - I have no idea how I could miss that the GetAll method is also available within the Octokit project and not only in Octokit.Reactive.... (I was so sure it isn't...)\nDidn't know that part about Rx and Await  - so at least I learned something while making a fool of myself.\nAnyway thanks again - I'll close this.\n. ",
    "yufeih": "Thanks, you guys rocks.\n. ",
    "tylerbhughes": "I used the GetHtml method to pull the HTMl file from GitHub like so.\n``` csharp\n        private async Task DownloadReleaseNotes()\n        {\n            var request = client.Release.GetAll(\"ligershark\", \"side-waffle\");\n        var releases = await request;\n        var latestRelease = releases[0];\n\n        var assets = await client.Release.GetAllAssets(\"ligershark\", \"side-waffle\", latestRelease.Id);\n        string assetURL = \"\";\n\n        foreach (var asset in assets)\n        {\n            if (asset.Name.Equals(\"release-notes.html\"))\n            {\n                assetURL = asset.Url;\n            }\n        }\n\n        var response = await client.Connection.GetHtml(new Uri(assetURL, UriKind.Absolute));\n\n        return response.ToString();\n    }\n\n```\nI then created a separate function in order to pull the string out of the Task.\ncsharp\n        public string GetReleaseNotes()\n        {\n            return DownloadReleaseNotes().Result;\n        }\nHowever, when I loaded the string on to the webpage all that displayed was Octokit.Internal.ApiResponse1[System.String];What am I missing? Am I forgetting to do something in order to get that HTML string?\n. It's returning a json string for the file. I thought getHTML would return the HTML of the actual file uploaded?\n. @Haacked did I misunderstand the use of the getHTML method?\n. @shiftkey so just to be clearasset.BrowserDownloadUrl` will get me the URL of the file itself so that i can download it and just read the file directly from the disk?\n. ",
    "fffej": "I had a quick look at the tests, but didn't see an obvious way to add a good test.\nThe closest example to crib seems to be SearchForfunctionInCode, but this just makes a request and asserts the response is not empty.  I didn't want to add another one as I'm not sure it asserts anything useful?  Perhaps I'm misunderstanding the tests?\n. How's that for size?\n. ",
    "smbogan": "Nevermind, I missed in the API documentation that it is not returned.\n. ",
    "lucamorelli": "I supposed was an API problem. I don't think is very necessary to implement this inside the library, the mail point is that in this scenario I have do multiple calls to the server, implement this at API level could be a way to optimize the calls.\n. do you have any suggestion on how can I solve this problem?\n. thanks for the info, in the end I seen that comparing commit I can obtain the informations I need. May be nice to have this info directly in the commit, just to avoid another server call, but at the moment using compare is fine for me.\n. ",
    "dimitrisTim": "I am trying to use the client.Repository.Commit.Get method, to get every file that a commit has changed. But if the commits are too many (let's say more that 1000), this method of obtaining the info is very slow. Any thoughts?\n. Thanks a lot. That was the other idea I had but didn't know how to implement. It works, with a change on how you get the file paths:\ncsharp\nvar files = await client.Git.Tree.GetRecursive (Owner,Name, \"master\"); \nvar filePaths = files.Tree.Select (x => x.Path);\nvar stats = new Dictionary<string, int>();\nforeach (var path in filePaths)\n{\n    var request = new CommitRequest { Path = path };\n        var commitsForFile = await client.Repository.Commit.GetAll(Owner, Name,request);\n    stats.Add(path, commitsForFile.Count);\n}\nThanks again for your help and fast response!!\n. ",
    "immeraufdemhund": "Just ran into this sort of in production. Was trying to access enterprise repository to auto log a issue. Kept trying to create an issue using my auth token  and I was getting error 404. After much trial and error found out I had to use the new Credentials(string, string) overload when creating a client.. We created a test repo for testing and created a auth token with every possible option checked. Testing \n```\n.Credentials = New Credentials(\"MyTokenHere\") //fails\n.Credentials = New Credentials(\"MyUserName\", \"MyTokenHere\") //works\n.Credentials = New Credentials(\"SomeMadeUpName\", \"MyTokenHere\") //works\n```\nyes i really used SomeMadeUpName  :) I laughed that it worked.. ",
    "mikeparker": "If the related PR is merged can this issue be closed? @Eilon \n. Finally figured this out. You must not insert the repository name into the Head string... I've opened a separate issue to clarify the docs to prevent anyone else struggling for hours with the same thing.\n. I think at minimum emphasising the format of the base and head refs in the docs is good enough. In particular, the base ref doesn't include the username, but the head ref does (I havent checked what happens if you specify the username in the base ref too, maybe it works?)\nAm I right in saying that the GitHub API could return a more helpful error message here, if the branch doesn't exist, because its returning 3 confusing error messages simply because the caller is specifying an invalid branch? It says \"base sha\" and \"head sha\" empty or not specified, and \"No commits between [the specified branches]\". If this is the case then perhaps this is an issue for the main github API, but it would super awesome if Octokit could fix up the error message but perhaps \"nice to have\".\n. Great, i'll check it out. Thanks for the detailed response. I think it'd be great if there was a way of specifying a fuller return data structure, or even a batch 'fully populate' command, but I'm sure I can work around it with the code you've pasted. Thanks again!. Ok great, it looks like GraphQL is the way to go in the future. thanks again. ",
    "wvdvegt": "Any plans to support this (for example Open Live Writer integration)\n. ",
    "geek0r": "nic0r! :smiley: \n. ",
    "Eonasdan": "slightly related https://github.com/twbs/no-carrier/issues/3\n. \n. ",
    "cvrebert": "Finally! :smile: \n. ",
    "prayankmathur": "@shiftkey \n@cvrebert \nI have added the function in the IssueClients class.\nCould you please tell me what all unit and integration tests to add ?\n---------EDIT----------\nI have added the unit as well as the integration tests.\nI cannot run the integration tests as they skip because of a lack of a test account.\nThe unit tests are passing fine on my system, but they seem to have a problem running on appveyor. If you could have a look and tell me what's the problem !!.\nThanks\n. @shiftkey \n@gabrielweyer \nWhat needs to be done here then ?\nI followed your discussion here and since the method is implemented in a different class, do i need to remove it from there, or just have to add the new method in the EventsClient class or both ?\n. @shiftkey  To do the above I removed \"All\" from the ItemState enum.\nAnd regarding the failing integration tests, by simply removing the query for ItemState.All .\nhttps://github.com/prayankmathur/octokit.net/blob/master/Octokit.Tests.Integration/Clients/SearchClientTests.cs#L94\nAlso from the IssueClientTests.cs  https://github.com/prayankmathur/octokit.net/blob/master/Octokit.Tests.Integration/Clients/IssuesClientTests.cs#L162\nand the build succeeded.\nhttps://ci.appveyor.com/project/prayankmathur/octokit-net\nDoes this do the needful ?\n. @M-Zuber \n\"All\" isn't supported by the github API.\nIt is only a filter.\nTo search for it you need not have to mention any ItemState.\n. @ryangribble  @M-Zuber @shiftkey \nWhat should be done here ?\n. @M-Zuber \nWill get to it.\n. @shiftkey \nI will look into as to where all the changes are to made and then get back here.\n. @hahmed  that won't do much good because then we need to check if \"All\" state exists for that particular parameter or not and there are a lot of parameters.\n. @ryangribble  @shiftkey @hahmed \nI have created the new enum by the name ItemStateFilter\nAnd read the docs and made changes everywhere as said by @M-Zuber \nAlso made the corresponding changes in the unit as well as integration tests.\nThe build was successful link\nMy forked repository is here\n. @M-Zuber\n:+1: \njust opened the PR .\nAnd thanks for the video link. :smile: \n. Hello developers\nI am Prayank Mathur, currently pursuing my final yr in Computer Science & Engineering from Indian School of Mines, Dhanbad. \nI have had previous experience working in the C#  .NET framework where i developed an automation tool for Microsoft IDC during my summer internship last year. The main aim was to create an automation tool that can automate the testing of the daily builds of Word Android app on various android devices.\nI also developed an Employee Database Management System for Tata Steel in vb using the .NET framework during  summer'14.\nI have done 2 mini projects on C# .NET framework too.\nhttps://github.com/prayankmathur/\nI am really interested in the octokit project and would like to get started on the same. Please suggest me with some warm up tasks. I have read the above mentioned document.\nThanks\nRegards\nPrayank Mathur\n. > currently we juggle different csproj files for each target. I think a bulk of the work will be in porting those over to a unified project.json file - this will then allow us to add the new targets for the various .NET Platform Standards available around .NET Core\n@shiftkey \n@devkhan \nHow exactly do we port a csproj file to project.json\nDo we have to do it manually defining each and every dependency as mentioned here or is there a tool available ?\nAnd once that is done, we then need to modify the build.fsx file to incorporate the changes ?\nAnd after that see what all errors creep in and try to rectify it using #if \nAm i right ?\n\nAfter that, we'd need to look at packaging as project.json can also be used to create packages \"for free\"\n\nYou mean Nuget packages right ?\n. @shiftkey\nDo you believe this task is gonna take 2 months if we only have to do things that is discussed in this meta issue.\nI think we can finish it fast once everything is figured out step by step on how to do it .\nAm i right or this is gonna take time because i haven't have any experience in writing a project. json from .csproj ?\n. @ryangribble \nSo basically, just reverse the names of the enum !! :P \n. @ryangribble \nBut then we come back to the same issue, that the user who is using octokit doesn't get all the issues on using ItemState.All\n. @ryangribble \nI have made the changes. Take a look.\n. @ryangribble \nThanks for clearing that out. I got a little confused.\nI have made the necessary changes.\nTake a look.\nAnd i hope you like the title. :grinning: \n. @ryangribble \nI made the changes specified by you.\nThanks for helping me out !! :smile: \n. @shiftkey \nWhich one ?\nThe one you mentioned in the diff ?\n. @shiftkey \nWill remove the quotation marks right away.\n. @shiftkey\nMade the changes.Take a look.\n. @ryangribble \nI have made the necessary changes. Take a look. \n. @ryangribble \nThe more I am able to improve octokit the better. :grinning: \n. @shiftkey \nThe build passed the checks here i guess.\nTake a look at the unit and integration tests.\n. @ryangribble\nChanged the title. Sorry for the trouble. Actually i did branch out this issue, but it turned out that i branched it from my master branch which consisted of the previous bug(which i hadn't branched).\nIf you could take the trouble of going through the other PR first, then it could solve the issue.\n. @ryangribble \n@shiftkey \nI found that this function was not correct.\nSo corrected that too in the same PR.\nHope that it is fine.\n. @shiftkey \nI ll open a separate PR.\n. @ryangribble \nI was waiting for #1140 to be merged.\nBut now i have opened a separate PR for the UpdateMethod function correction.\n. @shiftkey \nI have made the necessary changes. Please take a look.\n. @shiftkey @ryangribble \nShould i rename the reactive function also ?\nBecause then it's usage would be like\n\nclient.Lock(owner, name, 1);\n\nCurrently its like \n\nclient.LockIssue(owner, name, 1)\n. @ryangribble \nYeah, forgot that :grin: \nwill make the changes.\n. @ryangribble \nThe changes are made successfully. You can now finally take a look. :grinning: \n\n----EDIT----\ntravis CI failed because of a system failure\n. @ryangribble \n@shiftkey \nRight now, I will try to implement the \n\nDelete(Uri uri, object data, string accepts)\n\nAnd then later on we can open up a new PR.\nIs that Fine ?\nAnd please review the implementation of the Delete method. I was somewhat confused on how to do that.\nAlso should I implement the Lock/Unlock methods as suggested by @ryangribble  which would return \nTask<bool>\n. @shiftkey \n@ryangribble \nJust a gentle reminder to go see the changes that i made in this PR.\n. @shiftkey\n:+1: \n. @devkhan \nActually i removed the changes from the previous pull request and opened a new PR so that changes can be merged quickly, as suggested by @shiftkey .\n. @shiftkey\nThanks !! .\nMade the changes accordingly.\n. @ryangribble \nI ran this command too ./build FormatCode\nActually i was not hoping for so many changes because i was hoping other contributors would be knowing this and i read it from the gitter chat group. Plus, last time you had to point out a lot of stuff (the tiny nitpicks), therefore i used the above command.\nI ll mention it from next time what all changes i am making. :grin:\n. @shiftkey \nMade the changes. Take a look.\n. @shiftkey \nYeah, I was doing that.\nAlso, shouldn't there be a change here too, like the one that you suggested.\n. @shiftkey \nI have added the integration tests as you said. Please take a look.\n. @ryangribble \nI changed the description to\n\nOptions to change the API response\n\nAnd i guess it should be same.\n. @ryangribble \nI have removed the whitespaces. Actually I copy pasted the description from the function above and therefore the whitespace crept in everywhere.\nPlease take a look.\n. @ryangribble \n@shiftkey \nWhy are there no integration tests for the methods in the RespositoryPagesClient ?\nI have added the tests for the GetAll\nwhat about the remaining methods.\n. @shiftkey \nSo should i do the honors and include them too ? :grinning:\n. @shiftkey \n@ryangribble \nI have added some tests for the functions.\nPlease take a look.\nAlso is there a way to check GetLatest returns the latest build, because i couldn't find a way.\n. @shiftkey \nSo i should remove those excessive tests and then maybe open up a separate issue to create this setup ?\n. @shiftkey \nHow do I know that appveyor is running/skipping the test that i mentioned to skip ?\n. @shiftkey \n@ryangribble \nI require some help in implementing the GetAndFlattenAllPages overload that i have implemented. I don't think if it is correct.\nAlso due to this, the IObservable<GitHubCommit> GetAll(string owner, string name, CommitRequest request, ApiOptions options) function doesn't return a list and am not able to write a test for it.\nAlso, where to mention  ApiOptions.None and where to mention New ApiOptions(). I mean how to know the difference, because someplaces i find one and some places the other.\n. @shiftkey\nSo the problem that I am facing is that await  _repositoryCommitsClient.GetAll(string owner, string name, CommitRequest request, ApiOptions options).ToList() wasn't working previously, (as the example you have mentioned suggests but it's function calls pass through the same set of functions, ie, connection.GetAndFlattenAllPages<T>(uri, parameters, options, Func<>)\nAnd I am unable to figure out what can be done to make it work. :grin:\n. @shiftkey \nYeah, i have commented them.\nBut i'll change that and then commit it again so that you can see it properly\n. @shiftkey \nthanks !!\ngot it working. :smiley: \n. @shiftkey \nyeah, added the unit tests too.\nbut there are no unit tests for the remaining methods of the RespositoryCommitClient\n. @shiftkey \nHave made the final set of changes which you said.\nPlease take a look.\n. @shiftkey \nChanged the class name too.\n. @shiftkey \nSorry for such a small mistake.\nTakes a whole lot of time to find and correct them. :cry: \n. Yeah, my bad :grin: \nHave made the changes\n. @shiftkey\nUpdated the comment.\nIs it correct now ?\n. @shiftkey Removed the quotation marks. :smile: \n. @shiftkey \nWhy is this function showing changes.\nI had opened a seperate PR to change it which has been merged.\nThe function has changed also here\nHad to remove it to remove conflicts.\n. @ryangribble \nI don't think so because we are passing null from another overload\n. @ryangribble \nNo, it isn't.\nActually i was trying to check something.\n. ",
    "ghuntley": "\nIndeed, I was in the middle of stealing your fake build.fsx|build.cmd|build.sh for ReactiveUI and ran into the same SourceLink error. script/* seems like a good convention, will check out what you have done up in #924 for inspiration. Any tips/advice appreciated, if something good is cooked up I don't see why this pattern couldn't be applied everywhere (tm) for .NET oss.\n. Yo.\nAlright, I had a poke around whilst reviewing @mderriey's progress and there's some stuff bouncing around in my head that needs to be discussed before progressing further.\nFirst up I think the title of this discussion is incorrect; the focus should not be on porting to netcore - it should be a discussion about what netstandard profile this library should migrate to and how to handle [Serializable]\nCurrently, Octokit has separate projects for net45, netcore45, mono, monodroid and Profile259. This seems strange as there doesn't appear to be any  solid platform specific reasons for doing this apart from [Serializable] jankyness with exceptions. All of these platforms could be \ud83d\udd25 and converted into a single project that targets netstandard v1.x after converting to the reflection API that was introduced back in the portable class library days - @mderriey's PR has initial WIP conversion of the reflection API. \nFrom there you can lift the Akavache build/release pipleine; see https://github.com/octokit/octokit.net/issues/1440#issuecomment-261141143 AND get rid of TravisCI \ud83c\udf89  as you no longer need to generate a mono assembly.\nAnother thing that needs discussing is the migration to a newer version of System.Reactive that supports netstandard and in doing so might warrant bumping the major depending on how you interpret semver as if I remember right there was some strong naming changes + major version of the dependency was changed:\nhttps://docs.microsoft.com/en-us/dotnet/articles/core/versions/index#semantic-versioning\n. Had a convo with Oren today about Rx3.0/RxUI - he recommends going to System.Reactive v3.1.1 as that won't force net45 consumers into installing the netstandard lib dependency. . Heads up AppVeyor w/VS2017 is in beta/opt-in. See https://github.com/appveyor/ci/issues/1179. @shiftkey go post in the appveyor thread linked above and once added you can select from admin panel.. Yo @shiftkey and @ryangribble  I'd suggest using gitversion to automatically version your releases and generating release notes using GitReleaseManager which automatically builds RELEASENOTES/GitHub Releases from closed github issues + github tags. \nSee https://github.com/reactiveui/ReactiveUI/blob/develop/GitReleaseManager.yaml  and https://github.com/reactiveui/ReactiveUI/blob/develop/GitVersion.yml\nDoing RELEASENOTES.md by hand and versioning from it is something I regret and am glad to :fire: in RxUI 7.0\n+1 on using cake but steal the akavache implementation as it includes release workflows and automatic versioning -  https://github.com/akavache/Akavache/blob/develop/build.cake\n+1 to using GitLink as SourceLink is weird with CRLF's.\n. Additionally, once netstandard migration is done you can move 100% to appveyor and get rid of travisci.\n. Yo @ryangribble check out https://github.com/octokit/octokit.net/issues/1440#issuecomment-261141143. If you want to bluejeans / chat about this stuff let me know.\n. ",
    "aaron-comyn": "The Github API documentation makes no reference to any kind of binary parameter on CreateFile or UpdateFile, but it looks like they accept an 'encoding' parameter.  Octokit.net seems to be using the default of UTF-8 even for base64 text - supposedly the same issue can be resolved in Octokit.js by setting the encoding of binary text to 'base64'.\nSame issue with a pull request showing a 'working' solution.  Relevant update:\njavascript\n               content =\n                content: content,\n                encoding: 'base64'\n\nFrom poking around the code it looks like adding a new property to the CreateFileRequest object (CreateFileRequest.cs), that mapped to the appropriate encoding parameter (or a prop called \"IsBinary\" that would serialize properly), would do the trick. That parameter would propagate all the way through to the API through the ApiConnection, it's just a matter of finding the correct structure for the encoding values :)\n. The API does not list the \"encoding\" parameter in its Repository Content docs, but it accepts/returns an encoding, and uses a specific 'base64' encoding parameter elsewhere for binary operations...  Encoding = EncodingType.Base64 is how it's handled on BLOBs.\nAs a matter of definition: arguably this is a pure API inconsistency, or a documentation oversight... the workflow of Git and GitHub allow it in single operation.  Perhaps updating the docs would be better, either making the encoding parameter official, or clarifying that the RepositoryContent API doesn't handle binary data.  No hacks needed ;)\n\nFeel free to close the issue - I opened it primarily to provide a path for any other people stuck on the API inconsistency, not everyone is comfortable with the BLOB DB.\nUpload of a single binary file: \n```\nlet repoOwner = \"me\"\nlet repoName = \"myrepo\"\nlet github = new GitHubClient(new ProductHeaderValue(\"name\"), Credentials = new Credentials(secrets))\nlet gitdb = github.GitDatabase\nlet gitblobs = github.GitDatabase.Blob\nlet runAsyncFunc (f:Task<'a>) = f.Result\nlet (~%%) asyncFunc = runAsyncFunc asyncFunc\nmember this.Update filePath encodedFileContents =\n    let file = new NewBlob(Encoding = EncodingType.Base64, Content = (encodedFileContents))\n    let blob = %% gitblobs.Create(repoOwner, repoName, file)\nlet master =  %% gitdb.Reference.Get(repoOwner, repoName, @\"heads/master\")\nlet baseTree = %% gitdb.Commit.Get(repoOwner, repoName, master.Object.Sha)\n\nlet nt = new NewTree(BaseTree = baseTree.Sha)\nnt.Tree.Add(new NewTreeItem(Path = filePath, Mode = \"100755\", Type = TreeType.Blob, Sha = blob.Sha ))\n\nlet newTree = %% gitdb.Tree.Create(repoOwner, repoName, nt)\nlet newCommit = new NewCommit(@\"[Automatic] metadata update of \" + filePath, newTree.Sha, [ master.Object.Sha ])\n\nlet commit =  %% gitdb.Commit.Create(repoOwner, repoName, newCommit)\nlet ref = %% gitdb.Reference.Update(repoOwner, repoName, @\"heads/master\", new ReferenceUpdate(commit.Sha))\n()\n\n```\n. ",
    "ferventcoder": "Slack also caps search history... If it weren't for that, slack would be nice.\n. I tend to grab urls from gitter discussions to use in issues and emails.\n. Looks interesting, but not built in so it presents a point of failure. Plus you can't see the entire conversation surrounding it, only messages that you search for. Not exactly apples and apples. :)\n. I saw ryver a few weeks ago. I agree that it looks interesting. We'll see how they do given how nice slack is.\n. I just realized I didn't share the error output (it's not really helpful):\nThere are 1 exceptions of 'ApiException'.Octokit.ApiException: Problems parsing JSON\n   at Octokit.Connection.HandleErrors(IResponse response) in c:\\dev\\octokit.net\\Octokit\\Http\\Connection.cs:line 569\n   at Octokit.Connection.<RunRequest>d__2b.MoveNext() in c:\\dev\\octokit.net\\Octokit\\Http\\Connection.cs:line 547\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at Octokit.Connection.<Run>d__27`1.MoveNext() in c:\\dev\\octokit.net\\Octokit\\Http\\Connection.cs:line 531\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at Octokit.ApiConnection.<Post>d__12`1.MoveNext() in c:\\dev\\octokit.net\\Octokit\\Http\\ApiConnection.cs:line 195\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at chocolatey.package.verifier.infrastructure.app.services.GistService.<create_gist>d__4.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at chocolatey.package.verifier.infrastructure.app.tasks.CreateGistTask.<create_gist>d__4.MoveNext()\n. I should mention that upgrading to 0.16.0 didn't resolve the issue.\nHere's one that just failed:\n```\nPOST https://api.github.com/gists HTTP/1.1\nAccept: application/vnd.github.quicksilver-preview+json; charset=utf-8, application/vnd.github.v3+json; charset=utf-8\nUser-Agent: ChocolateyPackageVerifier (Win32NT 6.2.9200; amd64; en-US; Octokit 0.16.0)\nAuthorization: Token [REDACTED]\nContent-Type: application/x-www-form-urlencoded; charset=utf-8\nHost: api.github.com\nContent-Length: 31161\nExpect: 100-continue\nAccept-Encoding: gzip, deflate\n{\"description\":\"AquaSnap v1.12.3 - Passed - Package Tests Results\",\"public\":true,\"files\":{\"Summary.md\":{\"content\":\"AquaSnap v1.12.3 - Passed - Package Test Results\\r\\n * https://chocolatey.org/packages/AquaSnap/1.12.3\\r\\n * Tested 01 Dec 2015 05:06:54 +00:00\\r\\n * Tested against win2012r2x64 (Windows Server 2012 R2 x64)\\r\\n * Tested with chocolatey-package-verifier service v0.3.0-15-g6c3a108 (Instance: Existing1)\\r\\n * Install was successful.\\r\\n * Uninstall failed (allowed). Note that the process may have hung, indicating a not completely silent uninstall. This is usually seen when the last entry in the log is calling the uninstall.\"},\"Install.txt\":{\"content\":\"==> default: Running provisioner: shell...\\r\\n    default: Running: shell/VagrantAction.ps1 as c:\\tmp\\vagrant-shell.ps1\\r\\n==> default: Chocolatey is running on Windows v 6.3.9600.0\\r\\n==> default: Attempting to delete file \\\"C:/ProgramData/chocolatey/choco.exe.old\\\".\\r\\n==> default: Attempting to delete file \\\"C:\\ProgramData\\chocolatey\\choco.exe.old\\\".\\r\\n==> default: Command line: \\\"C:\\ProgramData\\chocolatey\\choco.exe\\\" install AquaSnap --version 1.12.3 -fdvy\\r\\n==> default: Received arguments: install AquaSnap --version 1.12.3 -fdvy\\r\\n==> default: NOTE: Hiding sensitive configuration data! Please double and triple \\r\\n==> default:  check to be sure no sensitive data is shown, especially if copying \\r\\n==> default:  output to a gist for review.\\r\\n==> default: Configuration: CommandName='install'|\\r\\n==> default: CacheLocation='C:\\Users\\ADMINI~1\\AppData\\Local\\Temp'|\\r\\n==> default: ContainsLegacyPackageInstalls='True'|\\r\\n==> default: CommandExecutionTimeoutSeconds='2700'|\\r\\n==> default: Sources='https://chocolatey.org/api/v2/'|Debug='True'|Verbose='True'|\\r\\n==> default: Force='True'|Noop='False'|HelpRequested='False'|RegularOutput='True'|\\r\\n==> default: QuietOutput='False'|PromptForConfirmation='False'|AcceptLicense='True'|\\r\\n==> default: AllowUnofficialBuild='False'|Input='AquaSnap'|Version='1.12.3'|\\r\\n==> default: AllVersions='False'|SkipPackageInstallProvider='False'|\\r\\n==> default: PackageNames='AquaSnap'|Prerelease='False'|ForceX86='False'|\\r\\n==> default: OverrideArguments='False'|NotSilent='False'|IgnoreDependencies='False'|\\r\\n==> default: AllowMultipleVersions='False'|AllowDowngrade='False'|\\r\\n==> default: ForceDependencies='False'|Information.PlatformType='Windows'|\\r\\n==> default: Information.PlatformVersion='6.3.9600.0'|\\r\\n==> default: Information.PlatformName='Windows Server 2012 R2'|\\r\\n==> default: Information.ChocolateyVersion='0.9.9.11'|\\r\\n==> default: Information.ChocolateyProductVersion='0.9.9.11'|\\r\\n==> default: Information.FullName='choco, Version=0.9.9.11, Culture=neutral, PublicKeyToken=79d02ea9cad655eb'|\\r\\n==> default: \\r\\n==> default: Information.Is64Bit='True'|Information.IsInteractive='False'|\\r\\n==> default: Information.IsUserAdministrator='True'|\\r\\n==> default: Information.IsProcessElevated='True'|Features.AutoUninstaller='True'|\\r\\n==> default: Features.CheckSumFiles='True'|Features.FailOnAutoUninstaller='False'|\\r\\n==> default: ListCommand.LocalOnly='False'|\\r\\n==> default: ListCommand.IncludeRegistryPrograms='False'|\\r\\n==> default: UpgradeCommand.FailOnUnfound='False'|\\r\\n==> default: UpgradeCommand.FailOnNotInstalled='False'|\\r\\n==> default: UpgradeCommand.NotifyOnlyAvailableUpgrades='False'|\\r\\n==> default: NewCommand.AutomaticPackage='False'|SourceCommand.Command='unknown'|\\r\\n==> default: SourceCommand.Priority='0'|FeatureCommand.Command='unknown'|\\r\\n==> default: ConfigCommand.Command='unknown'|PushCommand.TimeoutInSeconds='0'|\\r\\n==> default: PinCommand.Command='unknown'|\\r\\n==> default: _ Chocolatey:ChocolateyInstallCommand - Normal Run Mode \\r\\n==> default: Installing the following packages:\\r\\n==> default: AquaSnap\\r\\n==> default: By installing you accept licenses for the packages.\\r\\n==> default: [NuGet] Installing 'AquaSnap 1.12.3'.\\r\\n==> default: \\r\\n==> default: [NuGet] Added file 'AquaSnap.png' to folder 'AquaSnap'.\\r\\n==> default: [NuGet] Added file 'ChocolateyInstall.ps1' to folder 'AquaSnap\\tools'.\\r\\n==> default: [NuGet] Added file 'ChocolateyUninstall.ps1' to folder 'AquaSnap\\tools'.\\r\\n==> default: [NuGet] Added file 'AquaSnap.nupkg' to folder 'AquaSnap'.\\r\\n==> default: [NuGet] Successfully installed 'AquaSnap 1.12.3'.\\r\\n==> default: \\r\\n==> default: AquaSnap v1.12.3 (forced)\\r\\n==> default: Contents of 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyInstall.ps1':\\r\\n==> default: $packageName = 'AquaSnap'\\r\\n==> default: $installerType = 'msi'\\r\\n==> default: $url  = 'http://www.nurgo-software.com/download/AquaSnap.msi'\\r\\n==> default: $silentArgs = '/qb'\\r\\n==> default: $validExitCodes = @(0)\\r\\n==> default: \\r\\n==> default: Install-ChocolateyPackage \\\"$packageName\\\" \\\"$installerType\\\" \\\"$silentArgs\\\" \\\"$url\\\" \\\"$url\\\" -validExitCodes $validExitCodes\\r\\n==> default: Calling command ['\\\"C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\\\" -NoProfile -NoLogo -ExecutionPolicy Bypass -Command \\\"[System.Threading.Thread]::CurrentThread.CurrentCulture = '';[System.Threading.Thread]::CurrentThread.CurrentUICulture = ''; \\r\\n==> default: & import-module -name 'C:\\ProgramData\\chocolatey\\helpers\\chocolateyInstaller.psm1'; & 'C:\\ProgramData\\chocolatey\\helpers\\chocolateyScriptRunner.ps1' -packageScript 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyInstall.ps1' -installArguments '' -p\\r\\n==> default: ackageParameters ''\\\"']\\r\\n==> default:  DEBUG: Posh version is 4.0\\r\\n==> default: \\r\\n==> default:  VERBOSE: Exporting function 'Get-BinRoot'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-ChecksumValid'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-ChocolateyUnzip'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-ChocolateyWebFile'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-EnvironmentVariable'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-EnvironmentVariableNames'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-FtpFile'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-ProcessorBits'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-UACEnabled'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-VirusCheckValid'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-WebFile'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-WebHeaders'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-BinFile'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyDesktopLink'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyEnvironmentVariable'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyExplorerMenuItem'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyFileAssociation'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyInstallPackage'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyPackage'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyPath'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyPinnedTaskBarItem'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyPowershellCommand'.\\r\\n==> default: \\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyShortcut'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyVsixPackage'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-Vsix'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyZipPackage'.\\r\\n==> default:  VERBOSE: Exporting function 'Set-EnvironmentVariable'.\\r\\n==> default:  VERBOSE: Exporting function 'Start-ChocolateyProcessAsAdmin'.\\r\\n==> default:  VERBOSE: Exporting function 'Test-ProcessAdminRights'.\\r\\n==> default:  VERBOSE: Exporting function 'Uninstall-BinFile'.\\r\\n==> default:  VERBOSE: Exporting function 'Uninstall-ChocolateyPackage'.\\r\\n==> default:  VERBOSE: Exporting function 'UnInstall-ChocolateyZipPackage'.\\r\\n==> default:  VERBOSE: Exporting function 'Update-SessionEnvironment'.\\r\\n==> default:  VERBOSE: Exporting function 'Write-ChocolateyFailure'.\\r\\n==> default:  VERBOSE: Exporting function 'Write-ChocolateySuccess'.\\r\\n==> default:  VERBOSE: Exporting function 'Write-FileUpdateLog'.\\r\\n==> default:  VERBOSE: Exporting alias 'Generate-BinFile'.\\r\\n==> default:  VERBOSE: Exporting alias 'Add-BinFile'.\\r\\n==> default:  VERBOSE: Exporting alias 'Remove-BinFile'.\\r\\n==> default:  DEBUG: Running 'Install-ChocolateyPackage' for AquaSnap with \\r\\n==> default:  url:'http://www.nurgo-software.com/download/AquaSnap.msi', args: '/qb', \\r\\n==> default:  fileType: 'msi', url64bit: \\r\\n==> default:  'http://www.nurgo-software.com/download/AquaSnap.msi', checksum: '', \\r\\n==> default:  checksumType: '', checksum64: '', checksumType64: '', validExitCodes: '0' \\r\\n==> default:  DEBUG: Running 'Get-ChocolateyWebFile' for AquaSnap with \\r\\n==> default:  url:'http://www.nurgo-software.com/download/AquaSnap.msi', \\r\\n==> default:  fileFullPath:'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\chocolatey\\AquaSnap\\1.12.3\\A\\r\\n==> default:  quaSnapInstall.msi', \\r\\n==> default:  url64bit:'http://www.nurgo-software.com/download/AquaSnap.msi', checksum: '', \\r\\n==> default:  checksumType: '', checksum64: '', checksumType64: ''\\r\\n==> default:  DEBUG: Running 'Get-ProcessorBits'\\r\\n==> default:  DEBUG: CPU is 64 bit\\r\\n==> default: \\r\\n==> default:  DEBUG: Setting url to 'http://www.nurgo-software.com/download/AquaSnap.msi' and\\r\\n==> default:   bitPackage to 64\\r\\n==> default:  DEBUG: Running 'Get-WebHeaders' with \\r\\n==> default:  url:'http://www.nurgo-software.com/download/AquaSnap.msi', userAgent: \\r\\n==> default:  'chocolatey command line'\\r\\n==> default:  DEBUG: Setting the UserAgent to 'chocolatey command line'\\r\\n==> default: \\r\\n==> default:  DEBUG: Request Headers:\\r\\n==> default:  DEBUG:   'Accept':'/'\\r\\n==> default:  DEBUG:   'User-Agent':'chocolatey command line'\\r\\n==> default:  DEBUG: Response Headers:\\r\\n==> default:  DEBUG:   'Connection':'keep-alive'\\r\\n==> default:  DEBUG:   'X-Cacheable':'Cacheable'\\r\\n==> default:  DEBUG:   'X-CDN-Geo':'chi'\\r\\n==> default:  DEBUG:   'X-CDN-Geo-IP':'46.105.194.69'\\r\\n==> default:  DEBUG:   'X-CDN-Any-IP':'213.186.33.107'\\r\\n==> default:  DEBUG:   'Accept-Ranges':'bytes'\\r\\n==> default:  DEBUG:   'Content-Length':'3950779'\\r\\n==> default:  DEBUG:   'Cache-Control':'max-age=1'\\r\\n==> default:  DEBUG:   'Content-Type':'application/x-msdownload'\\r\\n==> default:  DEBUG:   'Date':'Tue, 01 Dec 2015 05:06:01 GMT'\\r\\n==> default:  DEBUG:   'Expires':'Tue, 01 Dec 2015 05:06:02 GMT'\\r\\n==> default:  DEBUG:   'Last-Modified':'Wed, 23 Sep 2015 20:06:55 GMT'\\r\\n==> default:  Downloading AquaSnap 64 bit\\r\\n==> default: \\r\\n==> default:    from 'http://www.nurgo-software.com/download/AquaSnap.msi'\\r\\n==> default:  DEBUG: Running 'Get-WebFile' for \\r\\n==> default: \\r\\n==> default:  C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\chocolatey\\AquaSnap\\1.12.3\\AquaSnapInstall\\r\\n==> default:  .msi with url:'http://www.nurgo-software.com/download/AquaSnap.msi', userAgent:\\r\\n==> default:   'chocolatey command line' \\r\\n==> default:  DEBUG: Setting the UserAgent to 'chocolatey command line'\\r\\n==> default:  DEBUG: Checking that \\r\\n==> default: \\r\\n==> default:  'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\chocolatey\\AquaSnap\\1.12.3\\AquaSnapInstal\\r\\n==> default:  l.msi' is the size we expect it to be.\\r\\n==> default:  DEBUG: Verifying package provided checksum of '' for \\r\\n==> default:  'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\chocolatey\\AquaSnap\\1.12.3\\AquaSnapInstal\\r\\n==> default:  l.msi'.\\r\\n==> default:  DEBUG: Running 'Get-ChecksumValid' with \\r\\n==> default:  file:'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\chocolatey\\AquaSnap\\1.12.3\\AquaSnapI\\r\\n==> default:  nstall.msi', checksum: '', checksumType: ''\\r\\n==> default:  DEBUG: Running 'Install-ChocolateyInstallPackage' for AquaSnap with \\r\\n==> default:  file:'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\chocolatey\\AquaSnap\\1.12.3\\AquaSnapI\\r\\n==> default:  nstall.msi', args: '/qb', fileType: 'msi', validExitCodes: '0' \\r\\n==> default:  Installing AquaSnap...\\r\\n==> default:  DEBUG: Running 'Start-ChocolateyProcessAsAdmin' with exeToRun:'msiexec', \\r\\n==> default: \\r\\n==> default:  statements: '/i \\r\\n==> default:  \\\"C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\chocolatey\\AquaSnap\\1.12.3\\AquaSnapInstal\\r\\n==> default:  l.msi\\\" /qb ' \\r\\n==> default:  DEBUG: Elevating Permissions and running msiexec /i \\r\\n==> default:  \\\"C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\chocolatey\\AquaSnap\\1.12.3\\AquaSnapInstal\\r\\n==> default:  l.msi\\\" /qb . This may take a while, depending on the statements.\\r\\n==> default:  DEBUG: Finishing 'Start-ChocolateyProcessAsAdmin'\\r\\n==> default: \\r\\n==> default:  AquaSnap has been installed.\\r\\n==> default: Command ['\\\"C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\\\" -NoProfile -NoLogo -ExecutionPolicy Bypass -Command \\\"[System.Threading.Thread]::CurrentThread.CurrentCulture = '';[System.Threading.Thread]::CurrentThread.CurrentUICulture = ''; & import\\r\\n==> default: -module -name 'C:\\ProgramData\\chocolatey\\helpers\\chocolateyInstaller.psm1'; & 'C:\\ProgramData\\chocolatey\\helpers\\chocolateyScriptRunner.ps1' -packageScript 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyInstall.ps1' -installArguments '' -packageParameters ''\\\"'] exited with '0'\\r\\n==> default: Calling command ['\\\"shutdown\\\" /a']\\r\\n==> default: Command ['\\\"shutdown\\\" /a'] exited with '1116'\\r\\n==> default: Capturing package files in 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap'\\r\\n==> default:  Found 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\AquaSnap.nupkg'\\r\\n==> default:   with checksum '09E7A0EB3FEA0E9A12E04E207E0FE017'\\r\\n==> default:  Found 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\AquaSnap.png'\\r\\n==> default:   with checksum '937E0B688A818F30C7CC82D56EEB6E71'\\r\\n==> default:  Found 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyInstall.ps1'\\r\\n==> default:   with checksum '9C9613385ED336A2651E864FC6D504AF'\\r\\n==> default:  Found 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyUninstall.ps1'\\r\\n==> default:   with checksum '647C65CFE58320FE0F48C9FD36856B99'\\r\\n==> default: Attempting to create directory \\\"C:\\ProgramData\\chocolatey\\extensions\\\".\\r\\n==> default: Adding 'Hidden' attribute(s) to 'C:\\ProgramData\\chocolatey\\.chocolatey'.\\r\\n==> default: Attempting to create directory \\\"C:\\ProgramData\\chocolatey\\.chocolatey\\AquaSnap.1.12.3\\\".\\r\\n==> default: Attempting to copy \\\"C:\\ProgramData\\chocolatey\\.chocolatey\\AquaSnap.1.12.3\\.registry.update\\\"\\r\\n==> default: \\r\\n==> default:  to \\\"C:\\ProgramData\\chocolatey\\.chocolatey\\AquaSnap.1.12.3\\.registry\\\".\\r\\n==> default: Attempting to delete file \\\"C:\\ProgramData\\chocolatey\\.chocolatey\\AquaSnap.1.12.3\\.registry.update\\\".\\r\\n==> default: Attempting to copy \\\"C:\\ProgramData\\chocolatey\\.chocolatey\\AquaSnap.1.12.3\\.files.update\\\"\\r\\n==> default: \\r\\n==> default:  to \\\"C:\\ProgramData\\chocolatey\\.chocolatey\\AquaSnap.1.12.3\\.files\\\".\\r\\n==> default: Attempting to delete file \\\"C:\\ProgramData\\chocolatey\\.chocolatey\\AquaSnap.1.12.3\\.files.update\\\".\\r\\n==> default: Attempting to delete file \\\"C:\\ProgramData\\chocolatey\\.chocolatey\\AquaSnap.1.12.3\\.sxs\\\".\\r\\n==> default: Attempting to delete file \\\"C:\\ProgramData\\chocolatey\\.chocolatey\\AquaSnap.1.12.3\\.pin\\\".\\r\\n==> default:  The install of aquasnap was successful.\\r\\n==> default: Chocolatey installed 1/1 package(s). 0 package(s) failed.\\r\\n==> default:  See the log for details (C:\\ProgramData\\chocolatey\\logs\\chocolatey.log).\\r\\n==> default: Exiting with 0\\r\\n\"},\"RegistrySnapshot.xml\":{\"content\":\"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\\r\\n\\r\\n  S-1-5-21-1953236517-242735908-2433092285-500\\r\\n  \\r\\n    \\r\\n      Registry32\\r\\n      HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\{4D8AEE74-4B7E-4591-904F-46CFDE2329E2}\\r\\n      \\r\\n      C:\\Program Files (x86)\\AquaSnap\\\\r\\n      MsiExec.exe /X{4D8AEE74-4B7E-4591-904F-46CFDE2329E2}\\r\\n      false\\r\\n      http://www.nurgo-software.com?utm_source=AquaSnap&utm_medium=application\\r\\n      20151201\\r\\n      C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\chocolatey\\AquaSnap\\1.12.3\\\\r\\n      1033\\r\\n      17760257\\r\\n      1\\r\\n      15\\r\\n      false\\r\\n      true\\r\\n      false\\r\\n      true\\r\\n      false\\r\\n      \\r\\n      \\r\\n    \\r\\n  \\r\\n\"},\"FilesSnapshot.xml\":{\"content\":\"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\\r\\n\\r\\n  \\r\\n    \\r\\n    \\r\\n    \\r\\n    \\r\\n  \\r\\n\"},\"Uninstall.txt\":{\"content\":\"==> default: Running provisioner: shell...\\r\\n    default: Running: shell/VagrantAction.ps1 as c:\\tmp\\vagrant-shell.ps1\\r\\n==> default: Chocolatey is running on Windows v 6.3.9600.0\\r\\n==> default: Attempting to delete file \\\"C:/ProgramData/chocolatey/choco.exe.old\\\".\\r\\n==> default: Attempting to delete file \\\"C:\\ProgramData\\chocolatey\\choco.exe.old\\\".\\r\\n==> default: Command line: \\\"C:\\ProgramData\\chocolatey\\choco.exe\\\" uninstall AquaSnap --version 1.12.3 -dvy\\r\\n==> default: Received arguments: uninstall AquaSnap --version 1.12.3 -dvy\\r\\n==> default: NOTE: Hiding sensitive configuration data! Please double and triple \\r\\n==> default:  check to be sure no sensitive data is shown, especially if copying \\r\\n==> default:  output to a gist for review.\\r\\n==> default: Configuration: CommandName='uninstall'|\\r\\n==> default: CacheLocation='C:\\Users\\ADMINI~1\\AppData\\Local\\Temp'|\\r\\n==> default: ContainsLegacyPackageInstalls='True'|\\r\\n==> default: CommandExecutionTimeoutSeconds='2700'|\\r\\n==> default: Sources='https://chocolatey.org/api/v2/'|Debug='True'|Verbose='True'|\\r\\n==> default: Force='False'|Noop='False'|HelpRequested='False'|RegularOutput='True'|\\r\\n==> default: QuietOutput='False'|PromptForConfirmation='False'|AcceptLicense='True'|\\r\\n==> default: \\r\\n==> default: AllowUnofficialBuild='False'|Input='AquaSnap'|Version='1.12.3'|\\r\\n==> default: AllVersions='False'|SkipPackageInstallProvider='False'|\\r\\n==> default: PackageNames='AquaSnap'|Prerelease='False'|ForceX86='False'|\\r\\n==> default: OverrideArguments='False'|NotSilent='False'|IgnoreDependencies='False'|\\r\\n==> default: AllowMultipleVersions='False'|AllowDowngrade='False'|\\r\\n==> default: ForceDependencies='False'|Information.PlatformType='Windows'|\\r\\n==> default: Information.PlatformVersion='6.3.9600.0'|\\r\\n==> default: Information.PlatformName='Windows Server 2012 R2'|\\r\\n==> default: Information.ChocolateyVersion='0.9.9.11'|\\r\\n==> default: Information.ChocolateyProductVersion='0.9.9.11'|\\r\\n==> default: Information.FullName='choco, Version=0.9.9.11, Culture=neutral, PublicKeyToken=79d02ea9cad655eb'|\\r\\n==> default: \\r\\n==> default: Information.Is64Bit='True'|Information.IsInteractive='False'|\\r\\n==> default: Information.IsUserAdministrator='True'|\\r\\n==> default: Information.IsProcessElevated='True'|Features.AutoUninstaller='True'|\\r\\n==> default: Features.CheckSumFiles='True'|Features.FailOnAutoUninstaller='False'|\\r\\n==> default: ListCommand.LocalOnly='False'|\\r\\n==> default: ListCommand.IncludeRegistryPrograms='False'|\\r\\n==> default: UpgradeCommand.FailOnUnfound='False'|\\r\\n==> default: UpgradeCommand.FailOnNotInstalled='False'|\\r\\n==> default: UpgradeCommand.NotifyOnlyAvailableUpgrades='False'|\\r\\n==> default: NewCommand.AutomaticPackage='False'|SourceCommand.Command='unknown'|\\r\\n==> default: SourceCommand.Priority='0'|FeatureCommand.Command='unknown'|\\r\\n==> default: ConfigCommand.Command='unknown'|PushCommand.TimeoutInSeconds='0'|\\r\\n==> default: PinCommand.Command='unknown'|\\r\\n==> default: _ Chocolatey:ChocolateyUninstallCommand - Normal Run Mode \\r\\n==> default: Uninstalling the following packages:\\r\\n==> default: AquaSnap\\r\\n==> default: Attempting to create directory \\\"C:\\ProgramData\\chocolatey\\lib-bkp\\\".\\r\\n==> default: \\r\\n==> default: Backing up existing AquaSnap prior to upgrade.\\r\\n==> default: Moving 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap'\\r\\n==> default:  to 'C:\\ProgramData\\chocolatey\\lib-bkp\\AquaSnap'\\r\\n==> default: Attempting to create directory \\\"C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\\".\\r\\n==> default: \\r\\n==> default: Attempting to copy \\\"C:\\ProgramData\\chocolatey\\lib-bkp\\AquaSnap\\AquaSnap.nupkg\\\"\\r\\n==> default:  to \\\"C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\AquaSnap.nupkg\\\".\\r\\n==> default: Attempting to copy \\\"C:\\ProgramData\\chocolatey\\lib-bkp\\AquaSnap\\AquaSnap.png\\\"\\r\\n==> default:  to \\\"C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\AquaSnap.png\\\".\\r\\n==> default: Attempting to create directory \\\"C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\\".\\r\\n==> default: Attempting to copy \\\"C:\\ProgramData\\chocolatey\\lib-bkp\\AquaSnap\\tools\\ChocolateyInstall.ps1\\\"\\r\\n==> default:  to \\\"C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyInstall.ps1\\\".\\r\\n==> default: Attempting to copy \\\"C:\\ProgramData\\chocolatey\\lib-bkp\\AquaSnap\\tools\\ChocolateyUninstall.ps1\\\"\\r\\n==> default:  to \\\"C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyUninstall.ps1\\\".\\r\\n==> default: Capturing package files in 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap'\\r\\n==> default: \\r\\n==> default:  Found 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\AquaSnap.nupkg'\\r\\n==> default:   with checksum '09E7A0EB3FEA0E9A12E04E207E0FE017'\\r\\n==> default:  Found 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\AquaSnap.png'\\r\\n==> default:   with checksum '937E0B688A818F30C7CC82D56EEB6E71'\\r\\n==> default:  Found 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyInstall.ps1'\\r\\n==> default:   with checksum '9C9613385ED336A2651E864FC6D504AF'\\r\\n==> default:  Found 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyUninstall.ps1'\\r\\n==> default:   with checksum '647C65CFE58320FE0F48C9FD36856B99'\\r\\n==> default: [NuGet] Uninstalling 'AquaSnap 1.12.3'.\\r\\n==> default: \\r\\n==> default: \\r\\n==> default: AquaSnap v1.12.3\\r\\n==> default: Contents of 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyUninstall.ps1':\\r\\n==> default: \\r\\n==> default: $package = 'AquaSnap'\\r\\n==> default: \\r\\n==> default: try {\\r\\n==> default: \\r\\n==> default:   # HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\r\\n==> default:   # HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\\\r\\n==> default:   # http://stackoverflow.com/questions/450027/uninstalling-an-msi-file-from-the-command-line-without-using-msiexec\\r\\n==> default:   $msiArgs = \\\"/X{E0527016-B2F4-4EEB-97F6-A2B8C46196CA} /qb-! REBOOT=ReallySuppress\\\"\\r\\n==> default:   Start-ChocolateyProcessAsAdmin \\\"$msiArgs\\\" 'msiexec'\\r\\n==> default: \\r\\n==> default:   Write-ChocolateySuccess $package\\r\\n==> default: } catch {\\r\\n==> default:   Write-ChocolateyFailure $package \\\"$($.Exception.Message)\\\"\\r\\n==> default:   throw\\r\\n==> default: }\\r\\n==> default: \\r\\n==> default: Calling command ['\\\"C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\\\" -NoProfile -NoLogo -ExecutionPolicy Bypass -Command \\\"[System.Threading.Thread]::CurrentThread.CurrentCulture = '';[System.Threading.Thread]::CurrentThread.CurrentUICulture = ''; & import-module -name 'C:\\ProgramData\\chocolatey\\helpers\\chocolateyInstaller.psm1'; & 'C:\\ProgramData\\chocolatey\\helpers\\chocolateyScriptRunner.ps1' -packageScript 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyUninstall.ps1' -installArguments '' -packageParameters ''\\\"']\\r\\n==> default:  DEBUG: Posh version is 4.0\\r\\n==> default:  DEBUG: Loading community extensions\\r\\n==> default: \\r\\n==> default:  VERBOSE: Exporting function 'Get-BinRoot'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-ChecksumValid'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-ChocolateyUnzip'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-ChocolateyWebFile'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-EnvironmentVariable'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-EnvironmentVariableNames'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-FtpFile'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-ProcessorBits'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-UACEnabled'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-VirusCheckValid'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-WebFile'.\\r\\n==> default:  VERBOSE: Exporting function 'Get-WebHeaders'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-BinFile'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyDesktopLink'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyEnvironmentVariable'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyExplorerMenuItem'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyFileAssociation'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyInstallPackage'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyPackage'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyPath'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyPinnedTaskBarItem'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyPowershellCommand'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyShortcut'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyVsixPackage'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-Vsix'.\\r\\n==> default:  VERBOSE: Exporting function 'Install-ChocolateyZipPackage'.\\r\\n==> default:  VERBOSE: Exporting function 'Set-EnvironmentVariable'.\\r\\n==> default:  VERBOSE: Exporting function 'Start-ChocolateyProcessAsAdmin'.\\r\\n==> default:  VERBOSE: Exporting function 'Test-ProcessAdminRights'.\\r\\n==> default:  VERBOSE: Exporting function 'Uninstall-BinFile'.\\r\\n==> default:  VERBOSE: Exporting function 'Uninstall-ChocolateyPackage'.\\r\\n==> default:  VERBOSE: Exporting function 'UnInstall-ChocolateyZipPackage'.\\r\\n==> default:  VERBOSE: Exporting function 'Update-SessionEnvironment'.\\r\\n==> default:  VERBOSE: Exporting function 'Write-ChocolateyFailure'.\\r\\n==> default: \\r\\n==> default:  VERBOSE: Exporting function 'Write-ChocolateySuccess'.\\r\\n==> default:  VERBOSE: Exporting function 'Write-FileUpdateLog'.\\r\\n==> default:  VERBOSE: Exporting alias 'Generate-BinFile'.\\r\\n==> default:  VERBOSE: Exporting alias 'Add-BinFile'.\\r\\n==> default:  VERBOSE: Exporting alias 'Remove-BinFile'.\\r\\n==> default:  DEBUG: Running 'Start-ChocolateyProcessAsAdmin' with exeToRun:'msiexec', \\r\\n==> default:  statements: '/X{E0527016-B2F4-4EEB-97F6-A2B8C46196CA} /qb-! \\r\\n==> default:  REBOOT=ReallySuppress' \\r\\n==> default:  DEBUG: Elevating Permissions and running msiexec \\r\\n==> default:  /X{E0527016-B2F4-4EEB-97F6-A2B8C46196CA} /qb-! REBOOT=ReallySuppress. This may \\r\\n==> default:  take a while, depending on the statements.\\r\\n==> default:  T h i s   a c t i o n   i s   o n l y   v a l i d   f o r   p r o d u c t s   t h a t   a r e   c u r r e n t l y   i n s t a l l e d . \\r\\n==> default:   \\r\\n==> default:   WARNING: Write-ChocolateyFailure is deprecated. If you are the package \\r\\n==> default: \\r\\n==> default:  maintainer, please use 'throw $_.Exception' instead.\\r\\n==> default:  [ERROR] Running msiexec with /X{E0527016-B2F4-4EEB-97F6-A2B8C46196CA} /qb-! \\r\\n==> default: \\r\\n==> default:  REBOOT=ReallySuppress was not successful. Exit code was '1605' Error Message: \\r\\n==> default:  .\\r\\n==> default:  At C:\\ProgramData\\chocolatey\\helpers\\functions\\Write-ChocolateyFailure.ps1:24 \\r\\n==> default:  char:3\\r\\n==> default:  +   throw \\\"$failureMessage\\\"\\r\\n==> default:  +   ~~~~~~~~~~~~~~~~~~~~~~~\\r\\n==> default:      + CategoryInfo          : OperationStopped: ([ERROR] Running...or Message: \\r\\n==> default:  .:String) [], RuntimeException\\r\\n==> default:      + FullyQualifiedErrorId : [ERROR] Running msiexec with /X{E0527016-B2F4-4E \\r\\n==> default:     EB-97F6-A2B8C46196CA} /qb-! REBOOT=ReallySuppress was not successful. Exit  \\r\\n==> default:     code was '1605' Error Message: \\r\\n==> default:  .\\r\\n==> default: Command ['\\\"C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\\\" -NoProfile -NoLogo -ExecutionPolicy Bypass -Command \\\"[System.Threading.Thread]::CurrentThread.CurrentCulture = '';[System.Threading.Thread]::CurrentThread.CurrentUICulture = ''; & import-module -name 'C:\\ProgramData\\chocolatey\\helpers\\chocolateyInstaller.psm1'; & 'C:\\ProgramData\\chocolatey\\helpers\\chocolateyScriptRunner.ps1' -packageScript 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyUninstall.ps1' -installArguments '' -packageParameters ''\\\"'] exited with '1'\\r\\n==> default: Calling command ['\\\"shutdown\\\" /a']\\r\\n==> default: Command ['\\\"shutdown\\\" /a'] exited with '1116'\\r\\n==> default: aquasnap uninstall not successful.\\r\\n==> default: Error while running 'C:\\ProgramData\\chocolatey\\lib\\AquaSnap\\tools\\ChocolateyUninstall.ps1'.\\r\\n==> default:  See log for details.\\r\\n==> default: AquaSnap not uninstalled. An error occurred during uninstall:\\r\\n==> default:  aquasnap uninstall not successful.\\r\\n==> default: \\r\\n==> default: Chocolatey uninstalled 0/1 packages. 1 packages failed.\\r\\n==> default:  See the log for details (C:\\ProgramData\\chocolatey\\logs\\chocolatey.log).\\r\\n==> default: Failures\\r\\n==> default:  - aquasnap\\r\\n==> default: Exiting with 1\\r\\n[ERROR] The following WinRM command responded with a non-zero exit status.\\r\\n[ERROR] Vagrant assumes that this means the command failed!\\r\\n[ERROR] powershell -ExecutionPolicy Bypass -OutputFormat Text -file c:\\tmp\\vagrant-shell.ps1\\r\\n[ERROR] Stdout from the command:\\r\\n[ERROR] Stderr from the command:\\r\\n\"}}}\n```\nResponse:\n```\nHTTP/1.1 400 Bad Request\nServer: GitHub.com\nDate: Tue, 01 Dec 2015 05:06:55 GMT\nContent-Type: application/json; charset=utf-8\nContent-Length: 110\nStatus: 400 Bad Request\nX-RateLimit-Limit: 5000\nX-RateLimit-Remaining: 4988\nX-RateLimit-Reset: 1448947321\nX-OAuth-Scopes: gist, notifications, public_repo, read:org, read:public_key, repo:status, user\nX-Accepted-OAuth-Scopes: \nX-GitHub-Media-Type: github.v3; param=quicksilver-preview; format=json\nX-XSS-Protection: 1; mode=block\nX-Frame-Options: deny\nContent-Security-Policy: default-src 'none'\nAccess-Control-Allow-Credentials: true\nAccess-Control-Expose-Headers: ETag, Link, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval\nAccess-Control-Allow-Origin: *\nStrict-Transport-Security: max-age=31536000; includeSubdomains; preload\nX-Content-Type-Options: nosniff\nX-GitHub-Request-Id: [REDACTED]\n{\"message\":\"Problems parsing JSON\",\"documentation_url\":\"https://developer.github.com/v3/gists/#create-a-gist\"}\n``\n. @shiftkey It's [choco-bot](https://github.com/choco-bot)\n. @shiftkey when you say \"our end\" - do you mean octokit or the github endpoint?\n. About since I've been running this thing...So at least a week or more.\n. First error email related to Gist creation wasSat, Nov 21, 2015 at 9:58 AM CST`\n. So it looks like the same packages' gists will end up throwing the error (so the earlier statement was incorrect).\n. @shiftkey any news here?\n. @naveensrinivasan scroll up. Ignore the zbad.json. Those were from when I first started trying to decipher the issue and thought content-length might have something to do with it.\n. I will produce a failing code sample for octokit tonight (or tomorrow).\n. sure thing. Give me about 20 minutes or so\n. Okay, well that took a little longer - https://github.com/chocolatey/package-verifier/blob/344ba7ebf0dbbc7b4b99146f4b63d7589868ba89/src/chocolatey.package.verifier.tests.integration/infastructure.app/services/GistServiceSpecs.cs#L41-L83\nHere are the files:\nhttps://github.com/chocolatey/package-verifier/tree/344ba7ebf0dbbc7b4b99146f4b63d7589868ba89/src/chocolatey.package.verifier.tests.integration/context/gist\nIn the app.config file (in the tests project) you will need to insert github creds. \n. Fails every time for my user. I haven't tried it as a different user yet.\n. I'm collecting some more of these. Let me know if you need more than one failing one to determine the issue.\n. @naveensrinivasan awesome! I can test out a fix whenever you have one available. :)\n. Small correction - line 735 - https://github.com/chocolatey/package-verifier/blob/344ba7ebf0dbbc7b4b99146f4b63d7589868ba89/src/chocolatey.package.verifier.tests.integration/context/gist/Install.txt#L735\n. @naveensrinivasan It's always encoding. Great job finding that! \n. NSSM stdout there causing that ball of fun. I imagine that with some others that don't depend on NSSM, it's likely some other stdout encoding format fun :/\n. @naveensrinivasan sweet! Thanks! I imagine this would cover all unicode then?\n. @naveensrinivasan Awesome! I look forward to it. Very timely for me. :)\n. I'll see if I can take a look at this later today. :+1: \n. Just a couple changes since last release so far - https://github.com/octokit/octokit.net/compare/57b1e6cdb03fa1e98acc53142d3feeb28b90f6e5...master (or if you prefer https://github.com/octokit/octokit.net/compare/v0.16.0...master).\n. Everytime I turn around I need to install another .net framework version. Is 4.6 a known thing for building this for 4.5? - This is coming from lprun.exe - it's in https://github.com/octokit/octokit.net/tree/master/tools/LINQPad\nI just told lprun.exe it works with 4.5 for now ;) \n    <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5.2\" />\n. Initial findings are mixed. I watched a package that is known to fail and it failed. Another one passed just fine.\n. I turned back on recording gists and will get you the output of those.\n. This one finally passed though! https://gist.github.com/choco-bot/a2f154acf5b57bae0d7a\n. @naveensrinivasan here are some more failing items https://github.com/chocolatey/package-verifier/tree/master/src/chocolatey.package.verifier.tests.integration/context/failinggists\n. To be clear the command I used to grab the package was  nuget install octokit -source https://ci.appveyor.com/nuget/octokit-net-naveen/ -pre and it pulled down 0.17.0. Let me know if that is not correct (I also don't see where the nuget package was published in https://ci.appveyor.com/project/Haacked15676/octokit-net/build/1.0.1474 tho).\n. https://gitter.im/chocolatey/chocolatey.org?at=5664f3305057376520dbe2f8 - looking great so far! \n. Still have not had an error related to unicode.\n. Everything is good! We've run the verifier now with almost 12,000 gists!\nhttps://gist.github.com/choco-bot/\nOn Tuesday, February 2, 2016, Brendan Forster notifications@github.com\nwrote:\n\nI think we should have closed this out a while ago @ferventcoder\nhttps://github.com/ferventcoder let me know if you see it again.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/967#issuecomment-178885961\n.\n\n\nRob\n\"Be passionate in all you do\"\nhttp://codebetter.com/robreynolds\nhttp://ferventcoder.com\nhttps://twitter.com/ferventcoder\n. Sweet. :)\n. Apologies as well - prolly not the right place to file this. @shiftkey looks like things are rolling again - https://gist.github.com/choco-bot.\nNote that the last noted time the service gave us an error was at 13:54 CDT:\n\n2017-05-15 18:54:04,965 [42] ERROR chocolatey-package-verifier had error(s):\nThere are 2 exceptions of 'ApplicationException'.System.ApplicationException: Error creating Gist for bazel v0.5.0-rc4. The service will try to test the package again later. Until then enjoy this error log heartbeat. The service is still running, yay! ---> Octokit.ApiException: \n\n~~~sh\n413 Request Entity Too Large\n\n413 Request Entity Too Large\nnginx\n\n\n[..snip..]\n~~~\nNote that the bazel package testing gist creation was successful an hour ago - https://gist.github.com/choco-bot/e292af89f9d777d15348bc524ec03739. @shiftkey fantastic customer service there. I def owe you a drink next time I see you!. ",
    "chyyran": "Sure, here is the request\n``` http\nPOST https://api.github.com/repos/SnowflakePowered-Packages/snowball-packages/pulls HTTP/1.1\nAccept: application/vnd.github.quicksilver-preview+json; charset=utf-8, application/vnd.github.v3+json; charset=utf-8\nUser-Agent: snowball (Win32NT 6.2.9200; amd64; en-CA; Octokit 0.16.0)\nAuthorization: Token [Redacted]\nContent-Type: application/x-www-form-urlencoded; charset=utf-8\nHost: api.github.com\nContent-Length: 134\nExpect: 100-continue\nAccept-Encoding: gzip, deflate\n{\"title\":\"Add Plugin StandardAjax v0.1.2\",\"base\":\"master\",\"head\":\"RonnChyran:StandardAjaxv0.1.2-df225a37-acb9-4e02-acc6-a517a88956d2\"}\n```\nAnd here is the response\n``` http\nHTTP/1.1 404 Not Found\nServer: GitHub.com\nDate: Sat, 10 Oct 2015 01:02:21 GMT\nContent-Type: application/json; charset=utf-8\nStatus: 404 Not Found\nX-RateLimit-Limit: 5000\nX-RateLimit-Remaining: 4964\nX-RateLimit-Reset: 1444439859\nX-OAuth-Scopes: public_repo, repo:status, repo, user, repo_deployment\nX-Accepted-OAuth-Scopes: \nX-OAuth-Client-Id: [Redacted]\nX-GitHub-Media-Type: github.v3; param=quicksilver-preview; format=json\nX-XSS-Protection: 1; mode=block\nX-Frame-Options: deny\nContent-Security-Policy: default-src 'none'\nAccess-Control-Allow-Credentials: true\nAccess-Control-Expose-Headers: ETag, Link, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval\nAccess-Control-Allow-Origin: *\nX-GitHub-Request-Id: D83A5B09:161C9:31899DC:5618639D\nStrict-Transport-Security: max-age=31536000; includeSubdomains; preload\nX-Content-Type-Options: nosniff\nContent-Length: 106\n{\"message\":\"Not Found\",\"documentation_url\":\"https://developer.github.com/v3/pulls/#create-a-pull-request\"}\n```\nHere is the link to the branch the PR belongs to: https://github.com/RonnChyran/snowball-packages/tree/StandardAjaxv0.1.2-df225a37-acb9-4e02-acc6-a517a88956d2, while the target repository is at https://github.com/SnowflakePowered-Packages/snowball-packages\nSource code for what I'm trying to do is here. \n. Anyone have an idea of what's going on with why it's not working?\n. @pengwynn I've disabled the restrictions on the target repository and it seems to working now.\nThanks for all the help, may I suggest adding a note about that to the API docs?\n. ",
    "eriawan": "@shiftkey \n\nI think so - once we've merged a PR, it's an indicator that master should be in a usable state.\n\nAre we going to have a specific daily LKG as well?. @shiftkey \nI mean a daily build but it can be considered as build that meets the passing unit tests and integration tests (if any), hence it's called Last Known Good build.. @ryangribble just a suggestion, I think it's easier to suppress CA warnings as project scope instead of class/method/property scope for CA rule of 1704. \ud83d\ude42 \nThis rule is mostly pedantic in a sense it will limit the expressiveness of naming class/method/property, and it's easier and faster (in compile time) to just suppress it on project scope, not at different source on class/method/property.\n. Thanks for the prompt response, @shiftkey \ud83d\udc4d \n\nI think this is fine to remove the ctor from the next update @eriawan! \ud83d\udc4d\n\nok, so what do you think is the best? here are the solutions to choose:\n\nDo you mean to remove the obsoleted parameterless ctor in the RepositoryUpdate? Then we will have many changes on the tests, although it is quite straightforward and it's easy to change. It is also easier to check all of the diffs on the PR, therefore it's easier to review.\nOr we could do the otherwise, by changing the usages of all of parameterless ctor by replacing with ctor with 'name' parameter instead. Then we could mark the ObsoleteAttribute to always resolved as error instead of just compile warning, to really deprecate this constructor and to tell the consumer of this class to not to use it anymore. For example: [Obsolete(\"Please use the ctor RepositoryUpdate(string name) as Name is a required field\", true)] (I prefer this solution \ud83d\ude42 )\n\nLet me know what you think, I'll create a PR for any one of those.. @ryangribble PR #1569  has been submitted.\ncc @shiftkey . @shiftkey @ryangribble please review.. @ryangribble any updates on this? Do you want me to wait for other work in progress to be completed before approving and merging my PR?\ncc @shiftkey . You're welcome, @shiftkey \ud83d\udc4d \n. @ryangribble no problem! \ud83d\ude42 \nI'll try to fix the remaining obsoleted items in a separate PR. Or do you want me to wait until you finish your integration test?\nthanks for the reply \ud83d\udc4d . Aha, the check comes. I'm fixing it now.. @ryangribble and @shiftkey \nI have done removals of some obsoleted methods, and also checked the unit tests. Please review \ud83d\ude42 \nUpdate 1:\nOne thing is, the build on travis CI failed. I couldn't find the cause. Do you want to be fixed or checked?. Thanks @ryangribble ! \ud83d\ude42 \nYes, I agree about the tests removed. I think I can remove those tests on a separate PR.\nI'll move on to next PR to remove those test after you finish reviewing this PR. Have a good weekend! \ud83d\udc4d . Thanks for your reply, @ryangribble \nOK, in this PR I will add more commits that remove the obsolete RepositoryContentsClientTests unit tests.. @ryangribble already done? \napologize for the long delay. thanks for the update!. ",
    "A-Programmer": "So where should i use ClientId and SecretId ?\nAnd do you think its true to get Users username and password?\nIs there any way to use this package to Authenticate user with GitHub login page?\n. And one more question, can i use this structure for Google and Facebook?\n. ",
    "eiriktsarpalis": "Do you have any updates on this fix? Thanks.\n. ",
    "pmiossec": "I am confronted to this bug :( It is still there in the new 0.23 release.\nIt make the upload of release asset feature completly useless...\nDo you think if the this bug will be fixed ?\nI could perhaps take some time to do a PR but how do you want to fix it?\n1. Set a huge Timeout on the HttpClient\n2. Expose a Timeout property\n3. (Potentialy) Update the Timeout at each request depending of the request timeout?\n. Is this bug be fixed?\nI can't find it in the release not or in the issues or PR linked.\nSeems not :(\nCould it be fixed by at least rising the timeout?. >Any reason why you've gone with an extra function call rather than adding a parameter to the constructors? [...] \nYou guessed right. \nIn the fix I made, I just hardcoded the timeout value to fulfil our needs that was just uploading an asset ;-)\nBut but because that is a library, we can't enforce a use that will not fit to every use. Timeouts could be useful.\nSo, indeed, I provide this method to be able to change it just before uploading an asset (and set it back to a normal value just after).\nBut you are right, I can also add an optional parameter to the constructor to make it more convenient to use. I will do it. . >But you are right, I can also add an optional parameter to the constructor to make it more convenient to use.\nIn fact, I had a look and I didn't find to make the API friendly to use without doubling the number of constructor of GitHubClient and Connection classes. I'm not sure to willing to do that anymore..... @ryangribble I have made the changes suggested.... done.. Ok I will do it.\nI think I will replace it by a link towards the HttpClient.Timeout doc. What do you think of that?\nOr completely remove? (it will be a shame because it could be useful) . I push the fix.... ",
    "mikasoukhov": "The problem still exist\nclient.SetRequestTimeout(TimeSpan.FromMinutes(30));\nVersion 0.29.0.0. Unfortunately, I cannot provide the full code.\nThe upload fails on following lines (file size is about 200mb)\n```\nvar client = new GitHubClient(new ProductHeaderValue(repo))\n            {\n                Credentials = new Credentials(\"grgtgrtgth\")\n            };\n        client.SetRequestTimeout(TimeSpan.FromMinutes(30)); // timeout looks like about 1-2 min, not 30 min at all.\n\n.....\nusing (var archiveContents = File.Open(attach, System.IO.FileMode.Open))\n            {\n                var assetUpload = new ReleaseAssetUpload\n                {\n                    FileName = Path.GetFileName(attach),\n                    ContentType = \"application/zip\",\n                    RawData = archiveContents,\n                };\n            client.Repository.Release.UploadAsset(release, assetUpload).Wait(); // <-- exception\n        }\n\n```. ",
    "ChristianTrolleMikkelsen": "Sorry i misread the api.\n. in octokit\n. ",
    "asizikov": "@shiftkey could you please share your vision about the message format?\n. @Haacked so I just should store raw unparsed payload in the ApiException? Ok, will update the PR tomorrow. Thanks for quick reply!\n. Hmm, the build seems to be broken. I guess it's not related to my changes.\nAnyway, here is the new output sample: \nOctokit.ApiException: Validation Failed\n{\"errors\":[{\"code\":\"custom\",\"field\":\"key\",\"message\":\"key is already in use\",\"resource\":\"PublicKey\"}],\"message\":\"Validation Failed\"}\n. oh, cool, you're aware of it :+1:\n. Aaand it's green now! :white_check_mark: \n. @shiftkey Am I right: this issue was already fixed by #1043 ?\n. yup, it doesn't. \nDeleted.\n. ",
    "khalidabuhakmeh": "Any update on this issue?\n. ",
    "AArnott": "I'm just now starting to use Octokit.NET. I have a bunch of tests that verify my octokit code comes up with the right results, but that require live queries to github.com. The network dependency itself is unfortunate, but github also throttles down to 403's rather quickly such that we have to disable our tests.\nI'd very much like to mock up the network traffic. I can do this if I could supply the HttpMessageHandler or HttpClient that the GitHubClient class uses, but I don't see any API to do that. Is this possible?  Is making that possible what this issue is all about?. > but yes you can pass in your own HttpClient into one of the ctors for GitHubClient and then do whatever you want\nIf only that were true. Alas, no GitHubClient ctor accepts an HttpClient as a parameter.\nImplementing IConnection looks much more laborious than implementing HttpMessageHandler because it has dozens of members instead of just one. And mocking up IGitHubClient assumes that I know how GitHubClient is supposed to work, but I don't. My tests should include executing actual GitHubClient code (and github.com server code, the first time) so that I verify I'm using the class correctly. If I mock up IGitHubClient then I can make it behave how I think it should behave rather than testing my code with how it actually behaves.\nMy strategy with other server-connected SDKs has been to inject my own HttpMessageHandler that records the operations the first time (while I'm writing the tests). Then I check in the recording so that all subsequent test runs can \"play back\" that network traffic and thus confirm that (assuming the server doesn't change behavior) my code continues to work.. Thanks! That's a bit out of the way, so I don't think I would have discovered that for a while. But assuming all networking calls will go through my message handler, that looks like it'll work great.. Given vcr-sharp is abandoned, I started up a project of my own at https://github.com/aarnott/HttpClientEcho\nIt's not ready for use yet, but I hope to get it usable within a week.. Even if new HttpClient instances were created for each request, that shouldn't mean new connections for each one. HttpClient is just a glorified front for older networking APIs in .NET that are already smart enough to reuse connections across multiple requests (if KeepAlive is set to true, anyway, IIRC).. ",
    "MaximRouiller": "Let me add you some details on why Octokit.NET for me is broken under Azure Functions.\nI'm currently on a project using Azure Durable Functions. This runs under a consumption plan which itself is hosted within the App Service Sandbox. \nThis is interesting but what you're interested about in this massive page is called the Numerical Sandbox Limits. \n\nEverything in there is basically moot except one. Connections. It's limited at 300 per server on which it runs on. Azure Functions initially starts with one server executing all of your functions. Then it starts to scale up to 2, 3, N servers. Each of those \"servers\" have that 300 limit.\nIf you are creating a new HttpClient every time a request is made, you end up running out of sockets as Windows waits 240 seconds to completely close the socket. That means that if I'm limited to a theoritical limit of 300 Octokit requests per servers per 4 minutes which translates to 1.25 requests per seconds. If I exceed that, I break the limit of the sandbox.\nThis literally makes Octokit unusable for Azure Functions on a consumption plan. \nThis led me to go bare metal and use something like this: \nhttps://gist.github.com/MaximRouiller/74ae40aa994579393f52747e78f26441\n```csharp\nHttpClient client = new HttpClient();\nclient.BaseAddress = new Uri(\"https://api.github.com\");\nvar token = \"\";\nclient.DefaultRequestHeaders.UserAgent.Add(new System.Net.Http.Headers.ProductInfoHeaderValue(\"AppName\", \"1.0\"));\nclient.DefaultRequestHeaders.Accept.Add(new System.Net.Http.Headers.MediaTypeWithQualityHeaderValue(\"application/json\"));\nclient.DefaultRequestHeaders.Authorization = new System.Net.Http.Headers.AuthenticationHeaderValue(\"Token\", token);\nvar response = await client.GetAsync(\"/user\");\n```\nThis allows me better control over the HttpClient and will allow me to survive the Connection sandbox limits.\nIf you have any questions, please fire away.. I store it as static on my class.. From discussions with @shiftkey, it creates an HttpClient per request and is not saved statically or reused. Can we confirm?. @khellang I did get into issues. I had both errors from the sandbox itself and actual \"permission exception\" from the TCP stack rejecting new sockets opening.\nThat being confirmed, I'll check if there are other places where things might crash.. I don't think Octokit was the issue. I think it might be due internally in how Durable Functions works.\nI have a workaround in place. I've already talked to the team to make sure we don't need a workaround. So either increasing limits of the sandbox or changing the Durable Functions defaults.\nLet's see what they do.. ",
    "Anubhav10": "I was going through the API documentation, 'Get-or-create an authorization for a specific app' and 'Get-or-create an authorization for a specific app and fingerprint' are both supported. Why do you want to :fire: this test?\nlink to documentation- https://developer.github.com/v3/oauth_authorizations/\n. This is what I found. I was about to open a PR when I spotted the without fingerprint in the documentation. The code for CanCreateAndGetAuthorizationWithoutFingerprint and CanCreateAndGetAuthorizationByFingerprint is almost the same. In without fingerprint when creating authorization, it checked for tokenlasteight and hashedtoken values too. But it doesn't do so in  with fingerprint. By reading the comments it seems like it was assumed these were returned only when they were requested the second time(which is not so according to the documentation) and not when they were created.\nAlso I had removed the newauthorizations overloaded constructor without the fingerprint parameter(as now it was a required thing), but it was being used at multiple places, like creating personal tokens etc, so I kept it.\nIn the documentation, in the Deprecation Notice it says that \"token is still supported\" in both Get-or-create an authorization for a specific app' and 'Get-or-create an authorization for a specific app and fingerprint'. So does this mean that they'll remove this is future? Because if they do CanCreateAndGetAuthorizationByFingerprint  and CanCreateAndGetAuthorizationWithoutFingerprint both will fail as there is an assert statement to check that token value isn't whitespace or null\n. @shiftkey this test is passing in VS Tests. Also the repo is being created and deleted. Please give some more details about the problem.\n. I would like to work on this\n. I have fixed the issue. For an optional value it gives the option to change or remove the value, for a necessary value it doesn't give an option. this is how it looks like now.\n\nPlease tell me if its what you wanted, and I'll send a pull request.\nthe files at the top has a TODO-\" # TODO: this should indicate whether a variable is required or optional.\" It indicates if the property if required or optional when setting the value, where else should it indicate?\n. I'll do the suggested changes. Yesterday, the Travis CI build was failing, how come it passed today? I tried to understand why it was failing but I couldn't. \n. @shiftkey The whitespace inconsistency was in my code and was my fault. I have removed the TODO comment and changed the message.\n. 6 integration tests I made are failing(All in OrganizationHooksClientTests.cs). I think this is because authenticated user has to be an admin of the organization being managed and OAuth tokens require the admin:org_hook scope.\nNeed some help, i can't figure out how to go about it. \nEDIT- Octokit.Tests tests I added are passing\n. Thanks for the review. I'll make these changes as soon as possible. It may take a few days as I have my mid-sem exams in the next week.\n. Sorry for the delay. I have made the changes\n1. Changed organizationName to org\n2. Added EnsuresNonEmptyArguments() in OrganizationHooksClientTest.cs\n3. Fixed the problems in integrationTests I added for org webhooks after adding the test account\n4. And other changes as asked by @ryangribble \nAbout the csproj and app.config changes, there was a problem in the test runner in my VS. It wasn't showing any tests. So, I updated all the Nuget Packages(It was a solution on stackoverflow), it still didn't work. I guess the update made those changes. There was a merge conflict when I commiting this time in the csproj, I have replaced these files with the one in master.\nThere are references to the documentation in https. Do you want me to change them all?\nThe integration tests have been skipped for OrganizationMemberClientTest, and the reasons given are \"Admin/Member filter doesn't work unless the requester is an organization member\" ,\"TwoFactor filter can't be used unless the requester is an organization owner\". These problems will come in org webhooks too, unless one is the admin of the org the tests will fail, so should I skip them?\nOne Of the integration test is failing. Test Name: Octokit.Tests.Integration.Clients.OrganizationHooksClientTests+TheCreateMethod.CreateAWebHookForTestOrganization.  The reason it is failing is that the 'active' value I send is false, but in the created hook active value is true. I guess this is a problem in the GitHub API.\nAlso the value of secret is returned as 'HMAC hex digest of the body, using the secret as the key' I guess( there are **) instead of the secret, so I have commented the assert to check the value of config, and remove the secret for now. This test will pass if we change the active to true in assert check, but that won't be right!! :grinning: \n. The travis-ci build is passing this time!! :grinning: \n. I added these properties based on the iobservablerepositoriesclient, it was 'Hooks' there. I thought that is how it should be named here too. I'll change it if you want\n. It creates a expected config, which is then compared with the returned config in the response\n. The folder 'fixtures' was already created. I had to use the lowercase.\n. I'll make this change! Thanks!\n. I already changed the name on the other 2 classes as well should I undo the changes?\n. Then the same problem would be there in RepositoriesHooksFixture\n. I'll undo the changes in the 2 classes and make it Fixtures in the classes I am adding here\n. done\n. done. Renaming the folder doesn't affect the namespace. Its just to organize things. My bad.\n. done\n. The integration tests weren't working, and the error was something related to fixtures, hence I tried out some things maybe then it got changed.\n. ",
    "wdhodges": "Thank you guys for your speed replies!\n. ",
    "jakeip8888": "Install-Package Microsoft.Owin.Security.OpenIdConnect\n. ",
    "twcclegg": "at Octokit.Connection.HandleErrors(IResponse response) in C:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Http\\Connection.cs:line 563\n   at Octokit.Connection.<RunRequest>d__51.MoveNext() in C:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Http\\Connection.cs:line 545\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at Octokit.Connection.<Run>d__50`1.MoveNext() in C:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Http\\Connection.cs:line 530\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at Octokit.ApiConnection.<Post>d__17`1.MoveNext() in C:\\Users\\shiftkey\\Documents\\GitHub\\octokit.net\\Octokit\\Http\\ApiConnection.cs:line 0\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()\n   at ReleaseTool.GitHub.<CreateTreeForBlob>d__22.MoveNext() in C:\\Users\\tclegg.OFFICE\\Documents\\GitHub\\ReleaseTool\\GitHub.cs:line 113\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()\n   at ReleaseTool.GitHub.<CreateCommitForBlob>d__23.MoveNext() in C:\\Users\\tclegg.OFFICE\\Documents\\GitHub\\ReleaseTool\\GitHub.cs:line 130\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()\n   at ReleaseTool.GitHub.<UpdateConfigTemplate>d__33.MoveNext() in C:\\Users\\tclegg.OFFICE\\Documents\\GitHub\\ReleaseTool\\GitHub.cs:line 252\n. It is throwing out of the first if in HandleErrors in Connection.cs https://github.com/octokit/octokit.net/blob/master/Octokit/Http/Connection.cs#L578\nresponse:\n-       response    {Octokit.Internal.Response} Octokit.IResponse {Octokit.Internal.Response}\n-       ApiInfo {Octokit.ApiInfo}   Octokit.ApiInfo\n+       AcceptedOauthScopes Count = 0   System.Collections.Generic.IReadOnlyList<string> {System.Collections.ObjectModel.ReadOnlyCollection<string>}\n        Etag    null    string\n+       Links   Count = 0   System.Collections.Generic.IReadOnlyDictionary<string, System.Uri> {System.Collections.ObjectModel.ReadOnlyDictionary<string, System.Uri>}\n+       OauthScopes Count = 3   System.Collections.Generic.IReadOnlyList<string> {System.Collections.ObjectModel.ReadOnlyCollection<string>}\n+       RateLimit   Limit 5000, Remaining 4961, Reset 03/04/2016 20:29:31 +00:00    Octokit.RateLimit\n        Body    \"{\\\"message\\\":\\\"tree.sha 0180e978c65bdba55f6a2021c6f0a3a94a2cf9df is not a valid blob\\\",\\\"documentation_url\\\":\\\"https://developer.github.com/v3/git/trees/#create-a-tree\\\"}\"    object {string}\n        ContentType \"application/json\"  string\n-       Headers Count = 17  System.Collections.Generic.IReadOnlyDictionary<string, string> {System.Collections.ObjectModel.ReadOnlyDictionary<string, string>}\n+       [0] {[Status, 422 Unprocessable Entity]}    System.Collections.Generic.KeyValuePair<string, string>\n+       [1] {[X-RateLimit-Limit, 5000]} System.Collections.Generic.KeyValuePair<string, string>\n+       [2] {[X-RateLimit-Remaining, 4961]} System.Collections.Generic.KeyValuePair<string, string>\n+       [3] {[X-RateLimit-Reset, 1457123371]}   System.Collections.Generic.KeyValuePair<string, string>\n+       [4] {[X-OAuth-Scopes, gist, repo, user]}    System.Collections.Generic.KeyValuePair<string, string>\n+       [5] {[X-Accepted-OAuth-Scopes, ]}   System.Collections.Generic.KeyValuePair<string, string>\n+       [6] {[X-GitHub-Media-Type, github.v3; param=quicksilver-preview; format=json]}  System.Collections.Generic.KeyValuePair<string, string>\n+       [7] {[Access-Control-Expose-Headers, ETag, Link, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval]}  System.Collections.Generic.KeyValuePair<string, string>\n+       [8] {[Access-Control-Allow-Origin, *]}  System.Collections.Generic.KeyValuePair<string, string>\n+       [9] {[Content-Security-Policy, default-src 'none']} System.Collections.Generic.KeyValuePair<string, string>\n+       [10]    {[Strict-Transport-Security, max-age=31536000; includeSubdomains; preload]} System.Collections.Generic.KeyValuePair<string, string>\n+       [11]    {[X-Content-Type-Options, nosniff]} System.Collections.Generic.KeyValuePair<string, string>\n+       [12]    {[X-Frame-Options, deny]}   System.Collections.Generic.KeyValuePair<string, string>\n+       [13]    {[X-XSS-Protection, 1; mode=block]} System.Collections.Generic.KeyValuePair<string, string>\n+       [14]    {[X-GitHub-Request-Id, CF0878E2:16F34:3D34B0E:56D9E2E7]}    System.Collections.Generic.KeyValuePair<string, string>\n+       [15]    {[Date, Fri, 04 Mar 2016 19:32:57 GMT]} System.Collections.Generic.KeyValuePair<string, string>\n+       [16]    {[Server, GitHub.com]}  System.Collections.Generic.KeyValuePair<string, string>\n+       Raw View        \n        StatusCode  422 System.Net.HttpStatusCode\nexceptionFunc:\n-       exceptionFunc   {Method = {System.Exception <.cctor>b__59_1(Octokit.IResponse)}}    System.Func<Octokit.IResponse, System.Exception>\n+       Method  {System.Exception <.cctor>b__59_1(Octokit.IResponse)}   System.Reflection.MethodInfo {System.Reflection.RuntimeMethodInfo}\n        Target  {Octokit.Connection.<>c}    object {Octokit.Connection.<>c}\n+       _invocationCount    {0} System.IntPtr\n        _invocationList null    object\n+       _methodBase {System.Exception <.cctor>b__59_1(Octokit.IResponse)}   object {System.Reflection.RuntimeMethodInfo}\n+       _methodPtr  {4877544}   System.IntPtr\n+       _methodPtrAux   {0} System.IntPtr\n        _target {Octokit.Connection.<>c}    object {Octokit.Connection.<>c}\nCall Stack at that point:\n```\n\nOctokit.dll!Octokit.Connection.HandleErrors(Octokit.IResponse response) Line 578    C#\n    Octokit.dll!Octokit.Connection.RunRequest(Octokit.Internal.IRequest request, System.Threading.CancellationToken cancellationToken) Line 560 C#\n    [Resuming Async Method] \n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.MoveNextRunner.InvokeMoveNext(object stateMachine)  Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.MoveNextRunner.Run()    Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.OutputAsyncCausalityEvents.AnonymousMethod__0() Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.ContinuationWrapper.Invoke()    Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.TaskAwaiter.OutputWaitEtwEvents.AnonymousMethod__0()   Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.ContinuationWrapper.Invoke()    Unknown\n    mscorlib.dll!System.Threading.Tasks.AwaitTaskContinuation.RunOrScheduleAction(System.Action action, bool allowInlining, ref System.Threading.Tasks.Task currentTask)    Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.FinishContinuations()  Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.FinishStageThree() Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.TrySetResult(System.__Canon result)    Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncTaskMethodBuilder.SetResult(Octokit.IResponse result)  Unknown\n    Octokit.dll!Octokit.Internal.HttpClientAdapter.Send(Octokit.Internal.IRequest request, System.Threading.CancellationToken cancellationToken) Line 50    C#\n    [Resuming Async Method] \n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.MoveNextRunner.InvokeMoveNext(object stateMachine)  Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.MoveNextRunner.Run()    Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.OutputAsyncCausalityEvents.AnonymousMethod__0() Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.ContinuationWrapper.Invoke()    Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.TaskAwaiter.OutputWaitEtwEvents.AnonymousMethod__0()   Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.ContinuationWrapper.Invoke()    Unknown\n    mscorlib.dll!System.Threading.Tasks.AwaitTaskContinuation.RunOrScheduleAction(System.Action action, bool allowInlining, ref System.Threading.Tasks.Task currentTask)    Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.FinishContinuations()  Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.FinishStageThree() Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.TrySetResult(System.__Canon result)    Unknown\n    mscorlib.dll!System.Threading.Tasks.TaskCompletionSource.TrySetResult(System.__Canon result)    Unknown\n    System.Net.Http.dll!System.Net.Http.HttpClient.SetTaskCompleted(System.Net.Http.HttpRequestMessage request, System.Threading.CancellationTokenSource cancellationTokenSource, System.Threading.Tasks.TaskCompletionSource tcs, System.Net.Http.HttpResponseMessage response)   Unknown\n    System.Net.Http.dll!System.Net.Http.HttpClient.StartContentBuffering.AnonymousMethod__0(System.Threading.Tasks.Task contentTask)    Unknown\n    mscorlib.dll!System.Threading.Tasks.ContinuationTaskFromTask.InnerInvoke()  Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.Execute()  Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.ExecutionContextCallback(object obj)   Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.ExecuteWithThreadLocal(ref System.Threading.Tasks.Task currentTaskSlot)    Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.ExecuteEntry(bool bPreventDoubleExecution) Unknown\n    mscorlib.dll!System.Threading.Tasks.ThreadPoolTaskScheduler.TryExecuteTaskInline(System.Threading.Tasks.Task task, bool taskWasPreviouslyQueued)    Unknown\n    mscorlib.dll!System.Threading.Tasks.TaskScheduler.TryRunInline(System.Threading.Tasks.Task task, bool taskWasPreviouslyQueued)  Unknown\n    mscorlib.dll!System.Threading.Tasks.TaskContinuation.InlineIfPossibleOrElseQueue(System.Threading.Tasks.Task task, bool needsProtection)    Unknown\n    mscorlib.dll!System.Threading.Tasks.StandardTaskContinuation.Run(System.Threading.Tasks.Task completedTask, bool bCanInlineContinuationTask)    Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.ContinueWithCore(System.Threading.Tasks.Task continuationTask, System.Threading.Tasks.TaskScheduler scheduler, System.Threading.CancellationToken cancellationToken, System.Threading.Tasks.TaskContinuationOptions options)   Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.ContinueWith(System.Action continuationAction, System.Threading.Tasks.TaskScheduler scheduler, System.Threading.CancellationToken cancellationToken, System.Threading.Tasks.TaskContinuationOptions continuationOptions, ref System.Threading.StackCrawlMark stackMark)   Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.ContinueWith(System.Action continuationAction, System.Threading.CancellationToken cancellationToken, System.Threading.Tasks.TaskContinuationOptions continuationOptions, System.Threading.Tasks.TaskScheduler scheduler)  Unknown\n    System.Net.Http.dll!System.Net.Http.HttpUtilities.ContinueWithStandard(System.Threading.Tasks.Task task, System.Action continuation)   Unknown\n    System.Net.Http.dll!System.Net.Http.HttpClient.StartContentBuffering(System.Net.Http.HttpRequestMessage request, System.Threading.CancellationTokenSource cancellationTokenSource, System.Threading.Tasks.TaskCompletionSource tcs, System.Net.Http.HttpResponseMessage response)  Unknown\n    System.Net.Http.dll!System.Net.Http.HttpClient.SendAsync.AnonymousMethod__0(System.Threading.Tasks.Task task)  Unknown\n    mscorlib.dll!System.Threading.Tasks.ContinuationTaskFromResultTask.InnerInvoke()   Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.Execute()  Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.ExecutionContextCallback(object obj)   Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.ExecuteWithThreadLocal(ref System.Threading.Tasks.Task currentTaskSlot)    Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.ExecuteEntry(bool bPreventDoubleExecution) Unknown\n    mscorlib.dll!System.Threading.Tasks.ThreadPoolTaskScheduler.TryExecuteTaskInline(System.Threading.Tasks.Task task, bool taskWasPreviouslyQueued)    Unknown\n    mscorlib.dll!System.Threading.Tasks.TaskScheduler.TryRunInline(System.Threading.Tasks.Task task, bool taskWasPreviouslyQueued)  Unknown\n    mscorlib.dll!System.Threading.Tasks.TaskContinuation.InlineIfPossibleOrElseQueue(System.Threading.Tasks.Task task, bool needsProtection)    Unknown\n    mscorlib.dll!System.Threading.Tasks.StandardTaskContinuation.Run(System.Threading.Tasks.Task completedTask, bool bCanInlineContinuationTask)    Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.FinishContinuations()  Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.FinishStageThree() Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.TrySetResult(System.__Canon result)    Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncTaskMethodBuilder.SetResult(System.Net.Http.HttpResponseMessage result)  Unknown\n    Octokit.dll!Octokit.Internal.RedirectHandler.SendAsync(System.Net.Http.HttpRequestMessage request, System.Threading.CancellationToken cancellationToken) Line 237   C#\n    [Resuming Async Method] \n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.MoveNextRunner.InvokeMoveNext(object stateMachine)  Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.MoveNextRunner.Run()    Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.OutputAsyncCausalityEvents.AnonymousMethod__0() Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.ContinuationWrapper.Invoke()    Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.TaskAwaiter.OutputWaitEtwEvents.AnonymousMethod__0()   Unknown\n    mscorlib.dll!System.Runtime.CompilerServices.AsyncMethodBuilderCore.ContinuationWrapper.Invoke()    Unknown\n    mscorlib.dll!System.Threading.Tasks.AwaitTaskContinuation.RunOrScheduleAction(System.Action action, bool allowInlining, ref System.Threading.Tasks.Task currentTask)    Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.FinishContinuations()  Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.FinishStageThree() Unknown\n    mscorlib.dll!System.Threading.Tasks.Task.TrySetResult(System.__Canon result)    Unknown\n    mscorlib.dll!System.Threading.Tasks.TaskCompletionSource.TrySetResult(System.__Canon result)    Unknown\n    System.Net.Http.dll!System.Net.Http.HttpClientHandler.GetResponseCallback(System.IAsyncResult ar)   Unknown\n    System.dll!System.Net.LazyAsyncResult.Complete(System.IntPtr userToken) Unknown\n    System.dll!System.Net.ContextAwareResult.CompleteCallback(object state) Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state) Unknown\n    System.dll!System.Net.ContextAwareResult.Complete(System.IntPtr userToken)  Unknown\n    System.dll!System.Net.LazyAsyncResult.ProtectedInvokeCallback(object result, System.IntPtr userToken)   Unknown\n    System.dll!System.Net.HttpWebRequest.ProcessResponse()  Unknown\n    System.dll!System.Net.HttpWebRequest.SetResponse(System.Net.CoreResponseData coreResponseData)  Unknown\n    System.dll!System.Net.HttpWebRequest.SetAndOrProcessResponse(object responseOrException)    Unknown\n    System.dll!System.Net.ConnectionReturnResult.SetResponses(System.Net.ConnectionReturnResult returnResult)   Unknown\n    System.dll!System.Net.Connection.ReadComplete(int bytesRead, System.Net.WebExceptionStatus errorStatus) Unknown\n    System.dll!System.Net.Connection.ReadCallback(System.IAsyncResult asyncResult)  Unknown\n    System.dll!System.Net.Connection.ReadCallbackWrapper(System.IAsyncResult asyncResult)   Unknown\n    System.dll!System.Net.LazyAsyncResult.Complete(System.IntPtr userToken) Unknown\n    System.dll!System.Net.LazyAsyncResult.ProtectedInvokeCallback(object result, System.IntPtr userToken)   Unknown\n    System.dll!System.Net.Security._SslStream.ProcessFrameBody(int readBytes, byte[] buffer, int offset, int count, System.Net.AsyncProtocolRequest asyncRequest)   Unknown\n    System.dll!System.Net.Security._SslStream.ReadFrameCallback(System.Net.AsyncProtocolRequest asyncRequest)   Unknown\n    System.dll!System.Net.AsyncProtocolRequest.CompleteRequest(int result)  Unknown\n    System.dll!System.Net.FixedSizeReader.CheckCompletionBeforeNextRead(int bytes)  Unknown\n    System.dll!System.Net.FixedSizeReader.ReadCallback(System.IAsyncResult transportResult) Unknown\n    System.dll!System.Net.LazyAsyncResult.Complete(System.IntPtr userToken) Unknown\n    System.dll!System.Net.ContextAwareResult.CompleteCallback(object state) Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state, bool preserveSyncCtx)   Unknown\n    mscorlib.dll!System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, object state) Unknown\n    System.dll!System.Net.ContextAwareResult.Complete(System.IntPtr userToken)  Unknown\n    System.dll!System.Net.LazyAsyncResult.ProtectedInvokeCallback(object result, System.IntPtr userToken)   Unknown\n    System.dll!System.Net.Sockets.BaseOverlappedAsyncResult.CompletionPortCallback(uint errorCode, uint numBytes, System.Threading.NativeOverlapped nativeOverlapped)  Unknown\n    mscorlib.dll!System.Threading._IOCompletionCallback.PerformIOCompletionCallback(uint errorCode, uint numBytes, System.Threading.NativeOverlapped pOVERLAP) Unknown\n    [Async Call]  \n    Octokit.dll!Octokit.Connection.Run(Octokit.Internal.IRequest request, System.Threading.CancellationToken cancellationToken) Line 539  C#\n    [Async Call]  \n    Octokit.dll!Octokit.ApiConnection.Post(System.Uri uri, object data, string accepts, string contentType) Line 224  C#\n    [Async Call]  \n    ReleaseTool.exe!ReleaseTool.GitHub.CreateTreeForBlob(string repo, string sha, System.Collections.Generic.ICollection filePath, Octokit.BlobReference blob) Line 113 C#\n    [Async Call]  \n    ReleaseTool.exe!ReleaseTool.GitHub.CreateCommitForBlob(string repo, int number, string parent, System.Collections.Generic.ICollection templatePath, Octokit.BlobReference blob) Line 130    C#\n    [Async Call]  \n    ReleaseTool.exe!ReleaseTool.GitHub.UpdateConfigTemplate(string repo, int number, System.Collections.Generic.ICollection repoPath, System.Collections.Generic.ICollection templatePath) Line 252 C#\n``\n. AddingEncoding = EncodingType.Utf8` to the NewBlob did not cause any change in behavior.\n. I will look tomorrow into simplifying my usage and provide a test that reproduces the issue. Thanks. \n. In trying to reduce my code to the minimum I changed things such that the test started passing. It seems it was somehow specific to one of my repos, on other repos everything worked fine. Closing this issue. Thanks again.\n. \n",
    "JakesCode": "Thanks, this fixed it. \n. I was just confused as to where \"_issuesClient\" came from, as I suspect others will/would be - maybe clarifying that would help others.\n. @shiftkey Done and done.\nhttps://github.com/octokit/octokit.net/pull/1054\n. ",
    "Sarmad93": "I will try to implement this.\n. @M-Zuber thanks for correction! i am fixing this.\n. @M-Zuber is it right now? if there are any mistakes further please let me know. thanks\n. I can understand your point as this is an official repository of github api wrapper, these things(comment typos etc) really matter. I will push another commit when i will reach home.thanks again for correction. I appreciate it.\n. Hi @M-Zuber  i need your help one more time :smile:  please review this when you are free.thanks\n. @ryangribble unit tests :confused: it is difficult for me to write solid unit test i doubt that i will miss something in testing. it would be good if any one with testing knowledge should write test for these properties. what do you say? \n. yes @shiftkey you are absolutely right :+1: I am new to this open source work that's why i am little afraid for now. As i was reading the links above i realized that i have lot to learn. Your code base has nice documentation and nice language idioms especially linq queries are written very well. what we learn in our programming classes is totally different here in open source world. Thanks :smile: \n. Ok i will try to write unit test similar to above links tonight and will ask for the help if i get stuck.\n. Thank you everyone for helping me out especially @M-Zuber for initial review. You guys are really helpful.  :smiley:\n. @Haacked is it really you in the gif? :laughing: \n.  hi @ryangribble hope you are fine. this one looks easy i want to do this one :smile: \nbut regarding the tests i will certainly bother you when i will implement this :grinning: \nand :+1: for clean and nice instructions.\n. oops look like i did some thing wrong and haven't pushed required changes\n. @shiftkey thanks for guiding me. Sure we wil complete this one :+1: \n. hi @shiftkey i am doing changes in integration test. when i ran build i saw that integration test were actually not running(skipping) because of some error\n\nOCTOKIT_GITHUBUSERNAME and OCTOKIT_GITHUBPASSWORD environment variables are not set.\n\nhow can i make sure my test are passing? do i need to make a separate testing account for this?\nthanks. \n. @ryangribble  i will test these against testing account but i am pushing some changes could you please review these especially header functionality? i am not sure how this header parameter functionality works. i am stuck at this one need little help.\n. sorry for incomplete commits this smartgit github client really has some weird behavior :angry: doesn't always add all files to staging area. \n. @ryangribble thanks for the code review :satisfied: yes i need to test these on testing account now.\nRegarding AcceptHeaders.xxxxx in unit test, you explained very well i need to pass header as string in parameter :+1: \n. i have configured my test account for integration test by running script in scripts\\ configure-integration-tests.ps1 now i am getting some other errors from Octokit\\GitHubClient.cs . i thinks my username and password is not updating from script. how can i resolve this?\n\n. i am stuck in this testing phase :disappointed: \n. @ryangribble yes i have been busy for last days and last time i remember i was stuck on integration test setup and i wasn't sure where to add parameter(header) in post request so i stopped working on this :tired_face: got  tired. you can assign this to someone else. Really sorry i could not made it. \n. @ryangribble  i made a test account and set the script against testing account but after setting up the script i was getting these errors. why these test are failing? most of the test in PullRequestsClientTests.csare failing..they made me annoyed  :smiley: an exception is thrown from connection.cs file. something is not setting up or there is some thing wrong in response :confused:\n\n. @ryangribble also when i build project in visual studio 2015 i get this error also \n\n. unit tests + convention tests build is passing locally but not here? :confused: \n. @devkhan  still not building?\n. @devkhan i did only this git rebase master and all that happened as you can see above :D\n. @devkhan on step 4(git rebase --continue) i am getting this. :confused: \n\n. @devkhan  i think something terrible has happened to my source tree. i added and resolved all conflicts iteratively but still appveyor is showing :x:\n. @devkhan sir first i would to thank you so much for your time and efforts :+1: i think this pr has gone to some fatal condition.. appveyor build is generating some strange errors :laughing: \n. @devkhan i have to redo this in a single commit. maybe it will solve the problem.\n. i want to get back on this. i have free time for a while :smile: . I need a little help.\nregarding passing the Header in put request i think i need to pass it in PullRequestClient.Merge . This merge method returns PullRequestMerge model object. In return statement the put method takes 4 input arguments. The one which confuses me the 3rd parameter string twoFactorAuthenticationCode Should i pass null here? or dummy text or i should update the position of parameters in overloaded put in IConnection class so that make Accept Header third input parameter and leave twoFactorAuthenticationCode without initializing it.\n\n. @shiftkey could you please review changes i have made especially for Accept header?\nIntegration tests are not working for me. so i have tested it on creating new project and using access token. it works fine for me and squashes more than one commit into a single commit. kindly if you pull this code and run the integration test by yourself so that it could be verified that it is working as it  intended to be :smile: \n. @shiftkey  Really sorry for that... i accidentally add all the files to staging area without observing closely...i will fix this and push new changes..sorry again if this made you angry..\n. @shiftkey done.\n. @shiftkey @ryangribble as always thanks for your code review and guidance :+1: you guyz helped me to finish it to end.\n@devkhan sir you taught me how to resolve merge/rebase conflict rightly,appreciate your efforts.\n. @shiftkey i want to grab this one :smiley: \n. :+1:  for review. Fixing this. \n. Right..@ryangribble thanks for the review. :smile:\n. @shiftkey \n\nthanks for waiting for me\n\nyeh no worries. i already knew your absence when i saw your tweet about your off for a week :wink: \n. \n. @shiftkey\n\n. Hi @nolanblew  are u still out/busy...i would like to work on this one what do u say?. \ud83d\ude04  i will open a pull request this weekend.. Quite busy with work in weekdays..will try my best to manage some time this weekend and start working on it.. @hartra344  \ud83d\udc4d  . No this is not necessary. but i thought i should also make changes in ObservablePullRequestsClientTests.cs .I wasn't sure that i should initialize property here or leave it as it was.. what do you say should i remove this?\n. yes you are right..i should revert it now. :+1: \n. sure i will add assert statement here. :smiley: \n. :+1: \n. ok...\n. right. fixing this. :+1: \n. ",
    "lbrader": "Thanks Brendan, quite helpful redirect.  I have public cloning operation working with libgit2sharp.\nI do like Octokit and was quite successful in working directly on GITHUB.    But realized after working trying to branch, fork that I couldn\u2019t get a local copy.\nSo am I wrong in thinking the rule of thumb is:\n- Use Octokit for manipulating GITHUB directly\n- Use libgit2sharp for manipulating your Local GITHUB Repository.\nLarry\nFrom: Brendan Forster [mailto:notifications@github.com]\nSent: Tuesday, January 26, 2016 4:27 PM\nTo: octokit/octokit.net octokit.net@noreply.github.com\nCc: Larry Brader lbrader@microsoft.com\nSubject: Re: [octokit.net] example of clone a repository (#1066)\nUnfortunately Octokit is limited by what is available through the GitHub API - there are some Git operations there's no equivalent to \"clone\" available.\nI'd recommend looking at libgit2sharphttps://github.com/libgit2/libgit2sharp which is a C# library for working with local repositories. Here's what the clone operation looks like in code:\nRepository.Clone(\"https://github.com/libgit2/libgit2sharp.git\", \"path/to/repo\");\nOr if you need to authenticate:\nvar co = new CloneOptions();\nco.CredentialsProvider = (_url, _user, _cred) => new UsernamePasswordCredentials { Username = \"Username\", Password = \"Password\" };\nRepository.Clone(\"https://github.com/libgit2/libgit2sharp.git\", \"path/to/repo\", co);\nThere's more examples in their wikihttps://github.com/libgit2/libgit2sharp/wiki/.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/octokit/octokit.net/issues/1066#issuecomment-175310923.\n. Thanks!  And great work on Octokit.\nFrom: Ryan Gribble [mailto:notifications@github.com]\nSent: Wednesday, June 8, 2016 5:30 AM\nTo: octokit/octokit.net octokit.net@noreply.github.com\nCc: Larry Brader lbrader@microsoft.com; Author author@noreply.github.com\nSubject: Re: [octokit/octokit.net] How do I get an Issue \"closed_by\" data? (#1350)\nClosed #1350https://github.com/octokit/octokit.net/issues/1350 via #1353https://github.com/octokit/octokit.net/pull/1353.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/octokit/octokit.net/issues/1350#event-685701709, or mute the threadhttps://github.com/notifications/unsubscribe/AB1Lqr_i54JNnnwJi1Kxci8wAHzcZamOks5qJrXAgaJpZM4IweO0.\n. ",
    "paladique": ":tada: \n. Oh wow :sparkles: this is awesome work!\n. @maddin2016 So I was :thought_balloon: about this last night too before I saw this! My vote is client.Issue, purely because of how the API is set up and I'm assuming that's the first place users would look.\nVery curious to see everyone else's thoughts though, my second vote was Assignees\n. @maddin2016 I'll take a look over it, and make any comments I might have :question: on but I'll leave all final merges, decisions, etc to @shiftkey and co.\n. ",
    "onatbas": "Thank you @naveensrinivasan for pointing me in the right direction. I just needed a quick commandline tool so what I did is that I just added a timeout to the default Http client in the HttpClientAdapter here. I know It's ugly (I had to turn off Code Analysis for that !) but it works for me.\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Http/HttpClientAdapter.cs\nThanks. \n. ",
    "mderriey": "I'd like to give it a shot.\nBear with my ignorance, I didn't really understand why that test should be ported to F#. I read through #983 and you mentioned that it could be run inline. Could you shed some light?\nAlso, would you be able to provide some guidance for the first steps to take to get going? Where should the test be moved to?\nThanks!\n. Thanks a lot for the explanations, it makes more sense now.\nI'll have a look at the build scripts to see if we already have custom build steps or something alike that I can use as a starting point.\nStill, if you have more info/guidance, it'll be very appreciated.\nThanks again!\n. Hey,\nI'd like to give this one a shot.\nFrom the looks of it, what has been done in #1398 can be reused.\nCheers\n. Is anything blocking this issue at the moment? I'd like to help if that's OK.\n. Great. I'll start with something to kick off a discussion around it.\nIn the meantime, if you think of anything I should be aware of, please let me know. Thanks.\n. sweet, thanks for pointing that out.\nwhat was the rationale behind defining several netstandard targets? I thought if you build for netstandard1.x, then any library targeting netstandard1.y where y >= x can reference it. Totally possible that I'm wrong, though, as I have very limited exposure to .NET Core.\n. An approach I would use is to get rid of all the .csproj files and create project.json to replace them. Since project.json allows multi-targetting, then the solution would not contain as many different flavours of the Octokit project, but only the main one that would be built for several targets.\nYou can find several examples of projects that have been ported to .NET Core, but one @shiftkey mentioned earlier, having worked on it, is Rx.NET.\nI hope this helps.\n. I'll spend some time working on this very soon.\nMy intent is to port the main 3 projects to netstandard1.1. Then we'll talk about all the other platforms we need to target and how we'll do it. I quite like how Rx.NET was ported, with conditional compilation symbols that map to capabilities more than platforms.\nI'll create a PR early to open a discussion\n. @shiftkey / @ryangribble if/when you have some time, could you please take a look at @ghuntley's comment above? thanks :+1: . Hi @DamianEdwards , we only reference Microsoft.Net.Http for the net45 TFM. NETStandard.Library is used when targeting netstandard1.1, as you can see here.\nI'll leave it to @shiftkey and @ryangribble to decide whether we make the move to the new csproj system with VS 2017 RC. As it's available in AppVeyor, it shouldn't too much of an issue.. > we only reference Microsoft.Net.Http for the net45 TFM.\nDid I really write this? That's embarassing. Point taken, will remove it altogether.\n\nAre you moving straight to the new CSPROJ project format as you go (meaning you'll need >=VS2017 RC or latest dotnet CLI builds)?\n\nI tried the one-way upgrade over the WE with the latest VS 2017 RC. Didn't go well as the upgrade didn't work when opening the solution. I'll have another look this week. I know @NickCraver did it for MiniProfiler so I'll have a look at how he got it done.. @shiftkey I'm giving the move to VS 2017 RC a go, could you tell me to which account is the octokit organisation linked to in AppVeyor so I can ask them to enable VS 2017 for us? Cheers. @shiftkey Cheers. I don't think it's available in the UI for now as there's a dedicated thread for people to ask that it gets enabled for their accounts. I'll do it. Thanks again.\nEdit: OK, you beat me to it. Thanks!. @shiftkey / @ryangribble \nI have a WIP branch named port-to-dotnet-core-vs-2017. I'm waiting for AppVeyor to enable the VS 2017 RC image on the account and I'll create a PR to see if things are running smoothly.\nA couple of issues I encountered on the way:\n\n.nuspec files don't exist anymore and the NuGet package metadata is now stored in the .csproj so I had to hardcode the current version in there. We could work around that but I went the easy way until we see if we continue on this path\nMSBuild chokes when the NuGet package version contains -* as this was done here. I removed it for now\nSince the new dotnet cli doesn't recognise project.json files anymore, I transformed tools.project.json which we use to install GitVersion to an empty .csproj. I have no idea if that's the way to go\n\nAny feedback is welcome!\nThanks. Thanks for the input!\nLast commits output the original name of the sample before running it through LINQPad and remove the C# test.\nRegarding the issue ID in the PR description, sorry about that, I'm still struggling with this notion. I thought it was meant to be in a commit message. I'm not sure I can update the PR description now - clicking the Edit button allows me to update the title but now the description\n. I'm struggling a bit to gauge how simple the .NET Core has to be.\nIs the intent realy only to have a .NET Core, no matter how small it is, to build on AppVeyor? Or do we want to try tackling the porting to the existing projects to .NET Core?\nThanks!\n/cc @shiftkey \n. For the sake of simplicity, I went with a separate VS solution containing a very simple class library and a unit tests project.\nIt took a few trial and error tries to get it working on Travis CI.\n. Is that a good enough baseline to start with the port? How should we proceed?\n. Sure, I'll bring the existing build targets back.\n\nIf it's too hard to run both the original build and this new build (for example, if we hit timeouts with CI), then let's verify we can test the .NET Core project from the command line at least\n\nI didn't get this part, sorry. The new build does execute tests, but I'm sure you saw that, so I must miss something.\nAlso, a couple of random questions:\n- for the time being, are we happy to duplicate source files in the new projects? Having both .csproj and project.json seems to be causing issues with MSBuild wanting more target frameworks in the project.json\n- if it turns out netstandard1.1 is all we need, are we happy to have it as the only target?\n. > Yes, I wasn't clear. Am I able to run the same command locally? Or are there other dependencies I need.\nAs long as you have the dotnet CLI, then yeah, you can execute the build target to run .NET Core tests.\n\nI'd rather not do this, and the MSBuild issues are similar to what I was seeing a while ago.\n\nUnderstood. Will investigate on this a bit more by having a look at the branch you mentioned before.\n\nI'm fine with targeting this initially as a new platform, as adding in extra platforms is rather straightforward. My main focus initially is ensuring we support the current platforms in project.json as well...\n\nThat's consistent with what you said just before.\nFinally, the build timed out on Travis with both the existing and the new build. Can we kick off a new one without pushing changes to that branch just in case?\n. Hmm.\nI'd say no. Let's say you're willing to work on the port to .NET Core, you'll need to install .NET Core runtime and tooling anyway. Another argument for not installing it as part of the build is that both AppVeyor and Travis support it, which saves us from installing it ourselves on the build agents.\nDoes that answer your question?\n. Cool.\nI've just noticed another build started on Travis for this commit - use mono 4.2.3 as latest successful builds show this version was used.\nDid you start this explicitly or does Travis have a retry mechanism when a build times out?\n. Well that's weird, the last build passed but this one didn't, the only change being to bring back linux again and adding a condition around if the OS is OSX to link libs.\n@shiftkey could you please restart the build for that last commit when you have some time? And just in case, could you check the last commit see if I did something wrong? My bash-fu is not very good.\n. Great, thanks! \ud83d\udc4d\nLet's just hope the build won't be too flakey.\nI'll start working on moving existing platforms to project.json. If I understand this right, and if all the current platforms are supported by project.json, we could end up with only one Octokit project in the solution.\nSome posts I want to keep as a reference here:\n- https://oren.codes/2016/02/08/project-json-all-the-things/\n- https://docs.nuget.org/consume/projectjson-intro\nThanks again!\n. @shiftkey Thanks!\nI could have squashed all these commits, it's a bit embarrassing to be honest.\n. Ditto. Great work getting this back on track :+1:. I'm struggling to get the FAKE script running. If a kind soul comes by and spots the error \ud83e\udd17 Otherwise I'll take another look at it a bit later.. Sweet, that'd be great!. Wow, great, I'll take a look at it soon. Thanks :+1:. Thank you so much @ryangribble!\nNext steps:\n\nget the integration test project ported too, and restored/built/tested in CI\nbump System.Reactive to v3.x\n\n@shiftkey based on https://github.com/octokit/octokit.net/issues/1419#issuecomment-263150006, should I just get rid of net45 and keep just netstandard1.1?. @shiftkey / @ryangribble \nThe integration test project has been ported to netstandard1.1 and it turns out System.Reactive had already been bumped to 3.x since it's the only version compatible with netstandard.\nWhat I think would be good is for you to have a look at some specific methods that were ported to .NET Core and see if you're happy with the implementation:\n\nFormatUserAgent of Connection\nA fix on a test to check the body contains expected values. The original implementation was trowing a 'object' does not contain a definition for 'fingerprint'\nA change in SimpleJson since SerializationException doesn't exist in netstandard land\n\nThere might be others, I'll have deeper look.\nCould you also let me know what you think is missing / what we have to focus on to get closer to a merge?\nThanks for the support, it's really appreciated \ud83d\udc4d . Thanks for the review @ryangribble, much appreciated. I pushed some changes according to your comments.\nYou were right for the HAS_REGEX_COMPILED_OPTIONS, it was meant for net45 but I forgot it.\nI made some changes to the reflection code based on a trick @Haacked used, which is to define the GetTypeInfo method for platforms that don't have it. This way, you can use GetTypeInfo consistently in your code without having to guard for it. A few other extensions methods were created to create missing APIs in netstandard1.1  that exist in net45, like GetProperty or GetMember.. @ryangribble regarding making sure everything works, do you want to publish a pre-release package on NuGet and asking people who are keen to try to update and make sure their apps still work? Or were you leaning towards us making sure it looks OK?. My bash-fu is not great, I'll have a look at what happens later.\nYou can now use .\\build.cmd and it will invoke CAKE. Parameters can be specified with the --name=value syntax.\nHere are the parameters I found in the build project and their default values:\n| Parameter name  | Default value | Other possible values                           |\n|-----------------|---------------|-------------------------------------------------|\n| target        | Default     | Dotnet-Unit-Tests, Dotnet-Integration-Tests |\n| configuration | Release     | Debug                                         |\n| forcepublish  | false       | true                                          |. @shiftkey / @ryangribble I updated the build files so they use the CAKE build.\nHow do you think you'll integrate PdbGit in the process? It looks to me that we need to hook this into the CAKE pipeline since NuGet packages are created as part of it. A very quick search leads me to think that we can't just execute an .exe from CAKE, we'd need to create some code that wraps that execution. Is this correct?\nCheers!. Alright, I took a shot at integrating PdbGit in the CAKE pipeline. It was quickly put together and possibly not very robust, but it works on both my local and AppVeyor.. Edit:\nI tried with the symbols NuGet package artifacts of the latest AppVeyor build. I can see VS trying to load a file from GitHub. It doesn't work though as it's trying to get the file from the octokit.net organisation repository, which is the first issue. The second thing is what I suppose is the commit SHA it's linking to, and I can't find it in either octokit.net/octokit#master not mderriey/octokit.net#port-to-dotnet-core.\nAgain, this is all very new to me so maybe I'm making false assumptions.\n\nI haven't :confounded:. The instructions look pretty simple but every time I tried it in the past I was never able to make it work...\nSorry about that. Do you think you could give it a go? If not I'll try my luck once again :+1: \nAs an aside, I'm very new to source linking, so please forgive my ignorance. Could you tell me why neither SourceLink nor GitLink would work?. Alright, after cloning the repo like AppVeyor does, posh-git shows me that 326116e commit SHA that PdbGit uses to link sources. I don't know where it comes from, though.\nSo what I did is a fresh clone of the repository that lives under my account, built it, created a console application pointing to the newly built assembly with the modified pdb next to it, and gave it a go.\nIt partially works, in the sense that I can F11 into the code from the Octokit assembly, but it's off by a line in the file that I tried. Trying to set a breakpoint on a specific line of code would have VS show a popup saying The following breakpoint cannot be set [...] The breakpoint failed to bind.\n\n```csharp\nclass Program\n{\n    static void Main(string[] args)\n    {\n        var task = DoWork();\n        task.GetAwaiter().GetResult();\n    }\nstatic async Task DoWork()\n{\n    var client = new Octokit.GitHubClient(new Octokit.ProductHeaderValue(\"OctokitSourceLinking\"));\n    var repo = await client.Repository.Get(\"mderriey\", \"octokit.net\");\n}\n\n}\n``. Unfortunately this doesn't work. As far as AppVeyor is concerned, the repo comes fromoctokit.net/octokit`. I know it's not a big deal but I wanted to see if I could get this working.\nNow here's a crazy: how about we publish a prerelease package of Octokit targeting netstandard1.1 and use it in this PR to get the correct repo and commit information since AppVeyor gives us the PR number? I know it's a very small test and won't cover much, though.\nWhat are your thoughts?. Exciting! Great work @ryangribble \ud83d\udc4d . Closing this PR as we decided to break them into several PRs so we don't end up with unrelated work in a PR.\nNew issues were created: #1546, #1547, #1548.\nEdit: @ryangribble, I tried creating these issues with the dotnetcore milestone, but it didn't work. Maybe I can't. Would you mind doing it please?. Opening the ruleset file in VS 2015 shows you're right. All rules should raise an error, except the 7 we explicitly disabled.. @ryangribble \ud83d\udc4d to that.. @ryangribble I'm happy to rename it to what it was before. Validate is much closer to what the task is doing, as running them doesn't add any value per-se.\nFor the samples names, I'd lean towards renaming the files so they all have two digits - so 01-xxxxx. It keeps the task focused on executing the samples and it's something we can check in the future in PRs if we add some more.. Hmm, I remember adding a command to the TravisCI config for macOS to link openssl libs where the dotnet CLI was looking for them. Now it fails saying the files already exist, so maybe they fixed it. I removed it and we'll see what happens \ud83d\ude09 . Hey @ryangribble could we discuss what else needs to be done to get this merged?. Closing this one as it's dead. Happy to open a new one when deemed necessary.. @ryangribble any idea why this issue - and the other ones - didn't get closed? I thought putting the correct message in the PR description would do the trick. Or do you need to put it in the commit message when you squash the commits into one while merging the PR?. @ryangribble beta sounds fine!\nAs to the workflow you described, it matches what I had in mind, too.\nMaybe we don't need to go into that much detail right now, but with the sentence Update release notes, tweak tests etc on release branch: update draft release with latest release notes (nothing to nuget), does it mean the CAKE build should update the draft release? If so, maybe we can discuss that outside of this PR, but I'd be keen to know more about it.\nI'll make the change straight away.. Yes, it will. the increment: Minor will increment the minor version by default, so after a tag v0.24.0, the next version will be 0.25.0. Since we use ContinuousDeployment, a new version will be created after every commit, but the new version will affect the pre-release tag, not the minor.\nI hope this makes sense.. Ah, sorry, I must not be clear enough.\nThere's no need to tag the repo. The reason is that ContinuousDeployment always uses pre-release tags when it calculates a version. It will get the latest base version - most probably from a tag - then applies the increment specified - in our case Minor - then uses the specified pre-release tag so that each commit has a different version.\nThe thing to keep in mind is that the increment will be applied only once between two tags, and the pre-release tag comes the config of the branch, not from a git tag.\nIn our case:\n\nmaster, tagged with v0.24.0\na PR is merged to master; the base version comes from the tag, it's 0.24.0, the increment is Minor, so the new version is 0.25.0. but as we use ContinuousDeployment, we apply the beta tag, so final version is 0.25.0-beta0001\nanother PR is merged to master. all the steps from above are exactly the same, except the final version is 0.25.0-beta0002 because it's the second commit since the tag\nanother PR to master. same thing, version is now 0.25.0-beta0003\n\nDoes this make things clearer?. I just tried, and yes, it will be incremented by how many commits the PR branch contains. I hadn't thought about that. Is this a problem? I saw you squashed my previous PRs, do you do this for PRs that target master, too?. Indeed, it looks like both the views and clones now use a formatted string. Good catch, @ryangribble.\nLooking through the codebase, I could only find that timestamp pattern in 2 classes, RepositoryTrafficView and RepositoryTrafficClone.\nI should be able to get a PR in.. Hey @ryangribble \nI cherry-picked the commit but this time the Linux build failed. Could you please queue another one when you have the chance?\nCheers.. Cheers!. Sweet! Will definitely take a loot at it.\nI also think xUnit now supports cross-targetting test projects, so we could run them in the net45 and netstandard1.1 contexts.\nThanks for that.. I also think that we can ditch TravisCI. Maybe it was needed before because some specific platform variants had to be built with Mono but it's not the case anymore with .NET Core.. I checked out the PR base branch, and running .\\build.ps1 worked as expected. The Package task created the expected version of NuGet packages. I think you can check this one off.\nI had a look at how source linking was enabled in both the Mvc repo and Rx.NET. Looks very simple. I'll have to dig a bit deeper to understand where the IsTestProject property being used.\nThanks for that, good effort!. Hey @ryangribble what's left to get this one merged?\nDo you want to get SourceLink in this one or in a separate one as @ctaggart suggested?. I don't see the value in getting the build working on Travis, but I understand you want to give it a go. Plus, that way we'll find out if CAKE's internals support using mono for all the tools when on Linux/macOS.\nI also found that page in the docs talking about troubleshooting issues on Travis locally with Docker containers: https://docs.travis-ci.com/user/common-build-problems/#Troubleshooting-Locally-in-a-Docker-Image.\nI'll give it a look later today.. I thought GUIDs in .csproj were a thing of the past, but Visual Studio still comes with surprises :wink:.\nSweet, thank you, :shipit:!. It will be merged back into #1567, closing.. That's great @ryangribble!. I don't explain it, but running dotnet sourcelink test as part of the Cake build is much much longer than running it directly; When I tried before pushing, it took a good 2 minutes as part of the Cake build, and maybe 4-5 seconds from a PowerShell console.\n@ryangribble do you see the same behaviour? Is it worth looking into it?. Hmm, must be something with my machine, it took ~40 seconds on AppVeyor and Travis CI.. @ctaggart in this case, I'm using a 100Mb/s link.\n@ryangribble you're right, I don't think it was, and this was intentional. I like the fact that we're explicitly testing that source linking works. Do you prefer running it as part of the dotnet build?\nIf not, I'm happy with the current state of things \ud83d\ude03 . I thought about that, too, I pushed before running it locally as the sourcelink test passed. It's not a big deal, really, I thought it would also take a long time on CI, but it turns out it's not, so it's not really an issue IMO.. I'm confused. How can there still be conflicts when master was just merged into dotnetcore? Have I not done what I think I've done?. Right, that makes sense. I think it does. So this happens because we lost the merge commit from master to dotnetcore?. @shiftkey I'm happy to do this.\nWould you rather have them as string or Uri?\nSo far, 43 classes have at least one property named or suffixed with Url that are not Uri.\nOn the other hand, 27 classes have at least one property named or suffixed with Url that are all typed as Uri.. Cool, will do!. @shiftkey @ryangribble could you please review when you have a chance?\nI assumed from the wording of the associated issue that this only had to apply to the response models. Let me know if you want to expand this to request models, too, it will be a quick change.. @shiftkey @ryangribble Only 4 request models have *Url properties which are not Uri, so the change should be pretty quick and easy.\nOne more thing; The current logic to get all the request models is to analyse all the parameters of all the methods on the client interfaces. It turns out that the Release response model is a parameter of the UploadAssetData method on IReleasesClient.\nThat hasn't been a problem before since the tests always include the response models and we selectively choose if we want the request models.\nI see a couple of options available here:\n\na quick hack to exclude the Release type from the request model types - as it's done for IStatisticsClient\nduplicate the Release type to make it a request model type. This would mean duplicate also the inner types.\n\nAny preference, or maybe another idea since I don't have the full picture?\nEdit:\nSo the UploadAssetData method only uses the UploadUrl property of the Release object it takes as a parameter. If you want to be strict about request/response models separation, the method could take only the tokenized upload URL of the release instead of the whole object.. I have a couple of commits ready to go that implement the first option, that is the Release type is excluded from request model types.\nHere are the changes that'd br brought in should you decide to go ahead with this approach: https://github.com/mderriey/octokit.net/compare/1582-change-model-url-properties-to-string...mderriey:change-request-model-url-properties-to-uri. Here's what I found out:\n\nAuthorizationUpdate.NoteUrl and NewAuthorization.NoteUrl are both optional properties and will accept any string; I called the API endpoints with a value of not a URL and the calls succeeded\nNewCommitStatus.TargetUrl needs to use the https scheme, but doesn't necessarily require a valid Uri; the API rejected not a URL but accepted https://not a URL - which will throw if used in Uri ctor\n\nI didn't know how to test the properties on NewDeploymentStatus as I couldn't figure how to create a deployment in the first place despite the associated API documentation. @ryangribble @shiftkey quick update on this\nI played around with the deployment status API.\nNewDeploymentStatus.LogUrl and NewDeploymentStatus.EnvironmentUrl are only enforced to start with https, but can be invalid Uri - like https://not a URL.\nGoing from there, I would suggest:\n\nleaving NoteUrl on AuthorizationUpdate and NewAuthorization as string since the API will accept any value\nleaving TargetUrl on NewCommitStatus as string since a valid Uri is not enforced - it just needs to start with https\nleaving LogUrl and EnvironmentUrl of NewDeploymentStatus as string for the same reason as above. @shiftkey Cool, thanks.\n\nI still kept the integration test which checks that request models have *Url properties of type string, but excluded the types we talked about earlier from it.\nIs that fine by you or would you rather not check request models at all?. I think the AppVeyor build failed because the NuGet v2 feed is experiencing issues\n\nI don't know how the Travis one passed, though. Local NuGet cache?. @ryangribble @ryangribble Could one of you trigger a new AppVeyor build?\nIf it's green and you're happy with the current state of the PR, I think this is good to go.. @shiftkey Thanks! :+1: \n@khellang Forgive my ignorance, could you explain a bit more? I usually add an empty commit when I want to do this, but keen to learn if there's a better way.. Here's how it went:\n\nAfter the convention test was created, 3 types were found having string properties\nCalling the API endpoints associated with these types showed that they didn't need to be Uri as, well, the upstream API doesn't enforce valid URLs\nThe convention test was modified to add those 3 types as exceptions\n\nIn other words, all the request model types but these three have Uri properties. I don't know the API well enough to determine if the other request model types should have Uri properties.. @ryangribble Haha,that's funny. I hadn't looked that closely. Thanks for that. Maybe the tests should only test types that do have *Url properties...\nSince it's only the excluded types, maybe we can go back to the scenario we had at some point with one convention test checking request and response model types at the same time? Would that work or would you prefer having two separate tests?. I went with:\n\nfiltering the test input to get only the types that do have at least one *Url property\nmerge back the tests into one. I'm keen to help to get this one across if that's OK.\n\nFor the Language stuff, my understanding is as follows:\n\nWe have to decorate every member with a Parameter attribute, to follow what @khellang has been doing for the other enums\nChange all the request/response types that use Language to use StringEnum<Language>\nStop treating Language as a special case in the convention test\n\nIs this correct?. Do we also have to change the serialization code to indicate how to serialize StringEnum<TEnum> instances?. > I'd expect the serializer to just fall back to a call to ToString, which should give the correct value, but we have to verify that \ud83d\ude04\nI just noticed that search request models explicitly define how they're serialised through the MergedQualifiers method.. @ryangribble LYW! :+1:. LGTM @ryangribble, thanks for taking the time to do this.. on second thought, is that even needed? or would you rather rebase it and force push when ready to merge?. Great, I'll take a look at this quickly. Thanks for taking the bite on this one!. @ryangribble That looks great, thanks again. I made a few minor changes, could you please have a look?. Ooh crap I missed this one!! Thank youuuuu. I don't have a strong opinion on the subject as I've never used it/experienced any pain with it.\nI'd lean towards StrongNamer as the process seems straightforward.. I tracked this back to https://github.com/octokit/octokit.net/commit/ac49d2ad09fd41677aec32c3b842d64488770124 where conditional compilation symbols were apparently not brought over correctly from .xproj to .csproj.\nIt should be an easy fix, but I think it's also a great opportunity to maybe have a look at running tests against both targets, net45 and netstandard1.1.\nI'm happy to have a stab at this one.\n@ryangribble since it would be, in my opinion, too heavy to run integration tests against both targets, what would be the best way to reproduce this in a failing test? take a JSON response and try to deserialise it?. Funny, I initially had an empty commit stating that tests were failing after adding the .NET 4.5 target. AppVeyor wouldn't build the PR as it found it was non-mergeable.. After asking for help on Twitter, @leastprivilege and @patriksvensson suggested disabling AppDomains when running tests.\nThat took the net452 run from 2min+ to 12 seconds on my machine :+1:\nEdit:\nThe AppVeyor build took:\n\n17 seconds for netcoreapp1.0\n18 seconds for net452\n\n@ryangribble the thing is Travis builds are broken since we brought back full framework.\nAny idea on how to tackle this?. After a bit of research, it looks like using dotnet test against net452 when using mono is not supported for now: https://github.com/Microsoft/vstest/issues/679\nA possible workaround is to change the Cake process so that the tests are run only against netcoreapp1.0 when not on Windows.\nWhat do you think @ryangribble?. I think the issue is specific to dotnet test. Using the console runner or dotnet xunit should work. Do you know if a Cake wrapper exists for the latter?. @ryangribble I saw the 4 additional tests, too.\nI found out they come from tests such as this one where we make sure exceptions can be hydrated from serialized data.\nBinaryFormatter doesn't exist in .NET Core so they only get run against full .NET framework.. Hmm, I was trialling using dotnet-xunit and those serialization tests break when not using app domains:\nOctokit.Tests.Exceptions.ApiExceptionTests+TheConstructor.CanPopulateObjectFromSerializedData [FAIL]\n  System.Runtime.Serialization.SerializationException : Unable to find assembly 'Octokit, Version=0.24.0.0, Culture=neutral, PublicKeyToken=null'.\n  Stack Trace:\n       at System.Runtime.Serialization.Formatters.Binary.BinaryAssemblyInfo.GetAssembly()\n       at System.Runtime.Serialization.Formatters.Binary.ObjectReader.GetType(BinaryAssemblyInfo assemblyInfo, String name)\n       at System.Runtime.Serialization.Formatters.Binary.ObjectMap..ctor(String objectName, String[] memberNames, BinaryTypeEnum[] binaryTypeEnumA, Object[] typeInformationA, Int32[] memberAssemIds, ObjectReader objectReader, Int32 objectId, BinaryAssemblyInfo assemblyInfo, SizedArray assemIdToAssemblyTable)\n       at System.Runtime.Serialization.Formatters.Binary.__BinaryParser.ReadObjectWithMapTyped(BinaryObjectWithMapTyped record)\n       at System.Runtime.Serialization.Formatters.Binary.__BinaryParser.Run()\n       at System.Runtime.Serialization.Formatters.Binary.ObjectReader.Deserialize(HeaderHandler handler, __BinaryParser serParser, Boolean fCheck, Boolean isCrossAppDomain, IMethodCallMessage methodCallMessage)\n       at System.Runtime.Serialization.Formatters.Binary.BinaryFormatter.Deserialize(Stream serializationStream, HeaderHandler handler, Boolean fCheck, Boolean isCrossAppDomain, IMethodCallMessage methodCallMessage)\nSome googling took me to https://github.com/xunit/xunit/issues/758. I'm already out of my league, but from what I understand, not using app domains affects assembly loading.\nAnother thing is I can't reproduce the slowness if I use dotnet-xunit with app domains enabled against net452.\n\u03bb  dotnet xunit -configuration Release -nobuild\nDetecting target frameworks in Octokit.Tests.csproj...\nLocating binaries for framework netcoreapp1.0...\nRunning .NET Core tests for framework netcoreapp1.0...\nxUnit.net Console Runner (64-bit .NET Core 4.6.25211.02)\n  Discovering: Octokit.Tests\n  Discovered:  Octokit.Tests\n  Starting:    Octokit.Tests\n    Octokit.Tests.Reactive.ObservableRepositoriesClientTests+TheGetAllForCurrentMethod.StopsMakingNewRequestsWhenTakeIsFulfilled [SKIP]\n      See https://github.com/octokit/octokit.net/issues/1011 for issue to investigate this further\n  Finished:    Octokit.Tests\n=== TEST EXECUTION SUMMARY ===\n   Octokit.Tests  Total: 2790, Errors: 0, Failed: 0, Skipped: 1, Time: 3.578s\nLocating binaries for framework net452...\nRunning desktop CLR tests for framework net452...\nxUnit.net Console Runner (64-bit Desktop .NET 4.0.30319.42000)\n  Discovering: Octokit.Tests\n  Discovered:  Octokit.Tests\n  Starting:    Octokit.Tests\n    Octokit.Tests.Reactive.ObservableRepositoriesClientTests+TheGetAllForCurrentMethod.StopsMakingNewRequestsWhenTakeIsFulfilled [SKIP]\n      See https://github.com/octokit/octokit.net/issues/1011 for issue to investigate this further\n  Finished:    Octokit.Tests\n=== TEST EXECUTION SUMMARY ===\n   Octokit.Tests  Total: 2794, Errors: 0, Failed: 0, Skipped: 1, Time: 4.945s. @ryangribble Alright, let's do this. I'll still investigate see if there's something we can do about it.\nThanks for your help @patriksvensson!. I had a look, and it all looks great; those release notes look :gem:!\nI had another look at the PR that brought the GitVersion config file to refresh the memory, and it makes sense that master has a prerelease tag since we use GitHubFlow. Tagging master after merging this PR should definitely produce 0.25.0.\nThanks for driving that release, great effort!\n\n. It all reads well to me.. Not a deal breaker, but in the advisories section, the field is kebab-cased where the API and the associated PR use the snake_cased version.. Thank you. Looks great!. It looks fantastic!\nOne thing I noticed is that in the NuGet Package Explorer screenshot for the Octokit.Reactive package, the dependency on Octokit mentions the default 0.0.0-dev version even though it looks these packages have been produced by the Cake build since the package itself has the correct version calculated by GitVersion. That seems a bit strange...\nAlso, if I had to nitpick, I'd say dotnetcore in the description reads funny to me and if I was a consumer of the package, it'd make more sense for me to read .NET Core or .NET Standard.\n. How good would it be if that fixed it!. Blinging \ud83d\udcaf! \n\n. Thanks for the wording change.\nMassive kudos for the GitHub-fu!\n:shipit: . OK so things changed a bit as @ryangribble and I realised that the tests for the GetAll method need at least 2 review requests to test the pagination works as expected. Managing 3 accounts in the code would get a bit difficult, so it was decided to use a static repo for these tests. See the octokitnet-test organisation and the specific PR we use for these tests.\nThis change means that the state sharing between tests doesn't happen as much as the GetAll method would have been the one benefit from it the most, as we have 6 test methods for it.\nWe still take advantage of it, though, but only in one place.\nMore than happy to get feedback on this.\nThe whole thing feels somewhat over-engineered with the abstract class, so feel free to bounce ideas around!. Closing as it feels heavy compared to what it achieves.. @ryangribble That all looks good to me. Thanks again for that polished release.. maybe there's an easier way than (fun p -> p) to return the input parameter as is\n. since Fake.DotNetCli.Build accepts a seq<string>, I went this way, taking example on other tasks. I don't know if it's right to do it this way since there's no globbing involved\n. noted, thanks. for now I removed the WindowsRT/Windows8 specific stuff since I don't think the target is to create platform-specific packages.. sorry, some hacky stuff I must have done at the beginning and forgot to remove them.. \ud83d\udd25 them all!. done, thank you.. I'm happy to remove the FAKE file and edit the build.cmd and build.sh to mimic what happens on AppVeyor. Sorry about the confusion.. It seems there's a new, stable version of this package on NuGet. Any specific reason to use this pre-release one?. Same as above. Same as above. nit: extra empty line. nit: extra empty line. You wouldn't believe it took me 5 good minutes to come up with that weird wording, would you? :wink:. I went for consistency here. not knowing what versions of VS contributors use, even if I guess it's safe they use a recent enough version. The .NET Core port should be merged in the near future, and since the new .csproj involves using VS 2017+, these updates will be totally safe then.. You're right, they can. At the moment they don't, so I felt like checking for the type was enough.. No worries at all, thanks for spotting this. I didn't even know C# 6 was explicitly disabled. I'll take a look at the places in the dotnetcore branch tomorrow and use new features where possible.. thanks!. You're right. I rushed through this.. I think I found the issue. The enum cache dictionary is not filled with all the values of a specific enum, but only with the value we want to deserialize when calling the method. This means the dictionary only ever contains one parsed value per enum type.\nAfter removing this line, tests pass when StringEnum has a static instance of SimpleJsonSerializer. Am I missing something here and this is the desired behaviour?. ",
    "Thwaitesy": "@ryangribble when do you think this will be merged?\n. ",
    "AlexP11223": "What do you mean by \"be smarter with the defaults\"?\nDo we need to add something like Default/NotSpecified (with null value) as a default value to Visibility and Affiliation enums?\n. I made the properties nullable instead of Default enum parameters and added unit tests for RepositoryRequest ToParamatersDictionary.\n. Yeah, I was thinking about DebuggerDisplay too yesterday.:)\nFor null values, shoud we output something like Visibility: <null> or remove the property from the output?\n. Without this line it does not go into if (propertyType.IsEnumeration()) and somehow produces \"All\" instead of \"all\" + does not use [Parameter] attribute.\n. ",
    "mathieukempe": "@shiftkey thanks for the example of code\nThe issue seems to be when I call the code in the controller asp.net mvc 5\n``` c#\n    public class HomeController : Controller\n    {\n        public ActionResult Index()\n        {\n            var client = new GitHubClient(new ProductHeaderValue(\"something\"), new InMemoryCredentialStore(new Credentials(\"my api key\")));\n        var content = client.Repository.Content.GetAllContents(\"owner\", \"repo\",\n            \"path\").Result;\n\n\n\n        return View();\n    }\n\n```\nThe call to GetAllContents hang\nThe same code in a console app work.\n. ",
    "zzzprojects": "There is a lot of ConfigureAwait(false) missing in all the projects.\nBy example, the method \"client.Repository.Content.GetAllContents(...)\" didn't work in my WinForm application because of UI Blocking.\nI just fixed RedirectHandler.SendAsync to add ConfigureAwait to all methods and it worked.\n. That doesn't matter. \nThe SendAsync method is asynchronous, and since you don't use ConfigureAwait(false) for this method, the UI will be blocked. So yes, the function inside (CloneHttpRequestMessageAsync) doesn't block the UI however, the line await CloneHttpRequestMessageAsync(request); do.\nBy example, this method in my WinForm application is blocked if I use your latest version. By just adding the ConfigureAway(false) everywhere it's now working.\n``` csharp\npublic static void CreateGist(string description, Dictionary files)\n{\n    var github = CreateClient();\n// CREATE new gist\nvar newGist = new NewGist {Description = description, Public = true};\n\n// ADD file\nforeach (var file in files)\n{\n    newGist.Files.Add(file.Key, file.Value);\n}\n\n// EXECUTE\nvar result = github.Gist.Create(newGist).Result;\n\n}\n```\nI may be wrong but a third party library should use ConfigureAwait(false) everywhere the await is used.\nDo you want me to put await & ConfigureAwait on the same line whenever is possible? I think there is only one place which I have to keep the multiline for readability.\n. > Are you able to provide a small sample WinForms app which uses async void or equivalent, so I can see this behaviour for myself?\nThe problem is right here. Since the library is missing a few ConfigureAwait and the API doesn't provide any non-asynchronous method, you force people to use an async method for not blocking the UI which is bad.\nNop, I cannot provide any async void that will not work, since if I create an async method, the UI will not be blocked.\nUsing .Result allows resolving the task for a non-asynchronous application like mine. If I don't call Result, the code will simply continue to run without the task necessary terminated.\nUsing this example: \n``` csharp\n// CREATE gist\nCreateGist(description, files);\n// DO something else after the gist has been created\nDoSomethingElse();\n```\nWithout .Result\nThe method DoSomethingElse() is called before the gist is created since the task to create the gist is currently running.\nWith .Result\nThe method DoSomethingElse is called after the Gist is created because we forced the result/task completion.\nThe user from the issue #1111 had the same problem as me. I'm pretty sure plenty of people tried your library and stopped because it was \"not working\". So yes, using .Result when none non-asynchronous method is provided reflect the reality ;)\n. It's a deadlocking. The thread is deadlocked with the UI thread.\nLook at your code, you FORCED the user to use an async method and that's really bad. Most people doesn't understand how async method work, so that's why I avoid them.\nThis is what I want:\n``` csharp\npublic static void CreateGist(string description, Dictionary files)\n{\n    var github = CreateClient();\n// CREATE new gist\nvar newGist = new NewGist {Description = description, Public = true};\n\n// ADD file\nforeach (var file in files)\n{\n    newGist.Files.Add(file.Key, file.Value);\n}\n\n// START and COMPLETE TASK\ngithub.Gist.Create(newGist).Result;\n\n}\npublic static DoSomething()\n{\n    // CREATE gist\n    CreateGist(description, files);\n// DO something else after the gist has been created\nDoSomethingElse(gist);\n\n}\n```\nImagine a legacy application where the DoSomething method already exists. You forced an existing method to be changed to use now an async Task and to use await operator. Furthermore, if the DoSomething method is now async, every method called it must now be async... and... well, that's just becoming worse and worse.\nWhat could have been few seconds changes by simply calling .Result now become a mess because the library FORCE all methods using the API to also use async method.\nAnyway, from my part, I just downloaded the source and added all missing ConfigureAwait(false) which took 5 minutes and I can now use the library with .Result\n. I will be happy to do it tomorrow.\nAll I need to know is the answer to the following question:\nDo you want me to put await & ConfigureAwait on the same line whenever is possible? I think there is only one place which I have to keep the multiline for readability.\n. Pull request for issue #1483\n. ",
    "michael-kokorin": "Fixes bug #1102 \n. ",
    "ikourfaln": "Hi,\nOK, as I said before (#1257), CoreCLR has a functioning HttpClient (System.Net.Http), it is included in .NET 4.5 and .NET Core, so it will work on ASP.NET Core.\nUse System.Net.Http.HttpClient to communicate over HTTP with GitHub web services. And you need to remove Microsoft.Net.Http (whitch it depend to two other packages :wink:).\nSo Depends on the version. When using the version System.Net.Http >= v4 Which works with both dnx451 and dnxcore50, Microsoft.Net.Http.HttpClient is depricated bcz its already in System.Net.Http.\nPS: as you can see here System.Net.Http < v4, System.Net.Http it depend on Microsoft.Net.Http\n. So @shiftkey. whats the status of this issue ?!\n. ",
    "radu-matei": "I don't think that converting to project.json is going to be required, since all .NET projects will use the .csproj file.\n\nAfter looking at our choices, it was apparent that it would be easier to move .NET Core projects to .csproj/MSBuild so all .NET projects use the same tooling and build system. (More on this here.)\n\nIn a couple of weeks the RTM will be released, so I think it would be a great moment to start working on porting to .NET Core.\nWhat do you people think?\n. What should be the course of action: adding a new property and modifying all references to it? (In this scenario, what happens with the old property?)\nOr renaming Keys to GitSshKeys directly?\n. @caseycraig I don't really understand your comment.\nWhat is easier?\n. I would also like to contribute to the .NET Core port, so count me in when it all starts :D\n. Updates on .csproj and MSBuild.\nhttps://blogs.msdn.microsoft.com/dotnet/2016/10/19/net-core-tooling-in-visual-studio-15/\n. ",
    "heshuimu": "Hi @shiftkey, \nSo I stumbled into this while browsing through the GSoC idea list, and yes I am interested in working on this. I have done C# programming for the past few years (in Unity3D, to be specific). \nI am fairly new to this project, though. Are there any ways, may I ask, that I could catch up with the project other than reading through the repo?\nThanks! I really appreciate it! \n. @shiftkey Thank you sir! I appreciate it!\n. ",
    "l17719": "Hello.\nWhile i was browsing the ideas list for GSoC i came across your project and i'm interested in working with this project. I've done some work in C# in the past years, some of it as a junior developer for some small to mid companies and also some internships in order to get my bearings on what's to come when i'm finished with my degree. That asides, i'm fairly new to the project as well and i'm now on the process of reading the docs and i've got the project migrated to my machine.\nAlso i'm currently checking the easy-fix items listed and see if i can help out any way. I think that's a good idea on how to connect with the project and see it's inner workings.\n. ",
    "rahutchinson": "Sorry about this... \n. :+1: \n. ",
    "aleksandr-samila": "@shiftkey Thank you, seems I misunderstood their docs.\nadded extra logic to get milestone number\n```\n...\nif (milestone != \"\")\n{\n    var connection = new Connection(new ProductHeaderValue(\"MyCompany\"))\n    {\n        Credentials = new Credentials(token)\n    };\nvar aConnection = new ApiConnection(connection);\nvar mClient = new MilestonesClient(aConnection);\n\nvar milestones = mClient.GetAllForRepository(\"MyCompany\", repoName, new MilestoneRequest\n{\n    State = ItemState.All\n});\n\nvar mDictionary = milestones.Result.ToDictionary(m => m.Title);\n\nif (mDictionary.ContainsKey(milestone))\n{\n    var mNumber = mDictionary[milestone];\n\n    repositoryIssueRequest.Milestone = mNumber.Number.ToString();\n}\n\n} \n...\n```\nNow it works.\n. ",
    "laedit": "If that's ok I want to contribute on this one.\nAbout how to do it,  I think that the simplest is to add an EncodingType Encoding property, potentially add the corresponding constructors and remove the SerializeAsBase64 attribute on Content property.\nAnd if you want to avoid any breaking change on this, deal with the base64 in the existing constructors.\nWhat do you think?\n. @shiftkey @Haacked is that what you have in mind? Or do you prefer another way?\n. @ryangribble  No problem, thanks for the merge :smile: . ",
    "Norbo11": "Did the organization hooks client get removed at any point, or did it never make it into Octokit? It appears that GitHubClient.Organization.Hooks no longer exists.... Is there any progress on getting some of these fields added? I'm currently having to work around the non-existent \"before\" field in PushEventPayload, for example. . Sure, I can do that at some point this week. Also, I was wondering why, when accessing the Events API, the \"deleted\" field is not included in PushEvent payloads. I'm not talking about Octokit in particular, I mean the actual Events API payload, which I assumed would return the same payload as the event delivered through i.e. a web hook?. Okay, thanks a lot, I'll see what I can find.. @ryangribble Yes, this exactly what I need - then I can use something like JsonConvert in order to deserialize the object into my own DeleteEventPayload class which contains all the fields which I need to access.\nBut what would be even better is not having to create this class at all, have Octokit deserialize into some kind of dynamic object instead, so that I can access its fields however I like.. ",
    "rogertinsley": "Thanks @shiftkey, I'll make the changes that you've suggested :+1: \n. I've made the changes you both have suggested.\nAre you happy with the integration test approach? I've used a similar approach to other tests in the same class, that is to use CreateTheWorld to create repo & commit. Get the Sha1 and compare that it hasn't changed. \n. I've updated CreateTheWorld to return a Task<Reference> and compare it against the GetSha1 and the class TheSha1Method methods should be async\n. I've added unit and integrations tests for the ObservableRepositoryCommitsClient, specifically the GetSha1 method.\n. No problem - I've removed the integration test and updated the unit test. \nI've learnt a lot about the codebase and how to contribute with this PR and you guys haven't scared me off either :grin: so I'm going to pick up some more up-for-grabs :smile:\n. Thanks - updated it, I'm getting there :smile: \n. ",
    "SamTheDev": "Hi @shiftkey I need some help/codeReview with the IntegrationTests part pls \n. @shiftkey  I've implemented your suggestions, thx man (y)\n. WooooHoo... Look mom i made it to master, ...Thx to you @shiftkey \n\n. @ryangribble Yes, that might be an issue that need to be reported, the thing is that i am sending commits from vs, and even though i am logged in as @SamTheDev, the commits keep coming as @UsamTheDev (another Github account i've created once for testing purposes ) \n\nTo fix this mess i am guessing that i need to merge the two accounts, not sure how to do that, you can probably save me the googling time :^3\n. Yes, changing the email in the vs settings pane did solve the issue, thx... it would be great if i can change the author of the older commits as well, is there an easy way to do that ?\n. @shiftkey Yes that did it (after deleting the other github account )..thx\n. > It looks like a .swp file was committed in c32dfbe - are you able to remove that from the history?\ndone.\n. Yy, my bad ...I believe that's because i touched ReleasesClientTests in 7f93dad, should i undo the changes on that file ?\n. @shiftkey that should do it, right ?\n. @shiftkey done.\n. Conflicts resolved.\n. The GitsComments ClientS here don't test the gistId against null or empty string in any of the other implemented methods (+ some missing tests).\nThis is out of the scope of this PR. Should i add them in here anyway ?\n. In order to pass the since DateTimeOffset parameter as long with the ApiOptions parameter to some of the GetAll* methods, An overload to the GetAndFlattenAllPagesmethod that accept both a ParametersDictionaryand An ApiOptionsseems to be missing !\nshould i add it as an extension method to the ConnectionExtensionsclass ?\nor do something like this ? :\n```\n public IObservable GetAll(DateTimeOffset since, ApiOptions options)\n        {\n            Ensure.ArgumentNotNull(options, \"options\");\n        var request = new GistRequest(since);\n        return _connection.GetAndFlattenAllPages<Gist>(ApiUrls.Gist(), Pagination.Setup(request.ToParametersDictionary(), options));\n    }\n\n``\n. @shiftkey Ok, got it (y)\n. @shiftkey conflicts resolved, ready for review/merge :}\n. @shiftkey one more thing and this is probably not the right place to ask, but haven't you guys thought of better implementation to theArgumentNotNullOrEmptyString`method so you won't pass the parameter name each time ? using reflexion may be ? \n. Or using something like this:\n```\npublic static void ArgumentNotNull([ValidatedNotNull]object value)\n{\n       if (value != null) return;\n   throw new ArgumentNullException(NameOf(() => value));\n\n}\npublic static string NameOf(Expression> memberExpression)\n{          \n       return ((MemberExpression)memberExpression.Body).Member.Name;\n}\npublic static void ArgumentNotNullOrEmptyString([ValidatedNotNull]string value)\n{                      \n      ArgumentNotNull(value);\n      if (!string.IsNullOrWhiteSpace(value)) return;\n         throw new ArgumentException(\"String cannot be empty\", NameOf(()=>value));\n}\n```\nor this ain't worth the effort ?\n. @shiftkey that's what i 've tried at first but using nameofinside a method will always return the name of the method's parameter's name  instead of the passed parameter name :\npublic static void ArgumentNotNullOrEmptyString([ValidatedNotNull]string value)\n{                        \n      ArgumentNotNull(value);\n      if (!string.IsNullOrWhiteSpace(value)) return;\n         throw new ArgumentException(\"String cannot be empty\", nameof(value));\n}\nnameof(value) here will return always \"value\", and i couldn't find a hack around that :/\n. @shiftkey i guess, there are no escape from passing 2 params then\n. @shiftkey conflicts resolved.\n. @shiftkey fixed\n. Oooo i totally forget about it, sorry about that @shiftkey , thx @dampir you are the man :+1: \n. Ok\n. > Rather than duplicating all these rules, GetAll(owner, name, reference) should just call GetAll(owner, name, reference, ApiOptions.None)\nYea agreed i will fix that in the next commits \n. > We've been discussing what to do with the Ensur e usages in the case where we call a different overload. We've settled on keeping these around, even if they are duplicated checks. So don't clean them up here.\nI am not sure why to !, a link to the discussion would be helpful, thanks (y)\n. @shiftkey And could you take a look at the Integration Tests :pray: ?\n. I forget to commit that one...My bad \n. I have absolutely no idea what auto generate that line !!, i will keep an eye on this file in the future.\n. @shiftkey pls, i need some help with the GetAllForAnOrganization Method's IntegrationTests  ! since the user must be authenticated and the organisation must be associated with that particular user ! \n. @ryangribble thx, i miss configured some of the settings, i will try to fix the failing test then i will report back.\n. All tests passed.\n. TheGetAllForRepositoryMethod's tests are still failing for some reason !?\n. All those tests passed, I've tried them using a test account with 3 followers!\n. I see, I need to get use to this ugly underline then :/\n\n. yes indeed both DictionaryWithApiOptionsand DictionaryWithApiOptionsAndSinceare specific to  GitsClient, it doesn't feel right to put them in Arg.cs, should i define them in both GistsClientTestsand ObservableGistsTestsor remove them entirely and use the expression each time ?\n. @shiftkey done.\n. ",
    "tidusjar": "@shiftkey Trying to find out now (I'm not having the issue) will report back when I find out.\n. Updated the Mono package and it now works. Thanks.\n. ",
    "pmn": "Outside of the larger conversation of when to stop sending the preview header, I chatted with a few folks about this here and verified that nothing will break if the preview header continues to be used after the feature has shipped. Any media type that is not supported or no longer supported will default back to application/vnd.github.v3+json. \nThat being said, I'll leave the conversation around how to handle preview features in Octokit.NET to @Haacked and @shiftkey as they may have some preferences around that. \n. ",
    "ErikSchierboom": "I'll try and have a go at this.\n. I'd like to give this a try :)\n. @ryangribble Should I also be adding the fields added to the NewDeployment and NewDeploymentStatus clases to the Deployment and DeploymentStatus classes? I do get returned values for these new fields in the HTTP response, so I could map them.\n. @ryangribble I've updated the PR with some tests.\n. I'll get on it!\n. @ryangribble The builds are now successful :) I have also added integration tests for the newly added properties, except for the AutoInactive property which isn't returned by the API.\n. @ryangribble As far as I can tell, it makes sense to not return that field as it appears to be intended for use only when creating/updating.\n. Great! Thanks for the help.\n\n. Thanks! I've rebased my PR.\n. ",
    "kivancmuslu": "I also thought it was something simple. Thanks for the quick response @shiftkey!\n. @shiftkey, no promises on the delivery time, but I will see what I can do during the weekend. \nJust a quick question: when the typo is fixed, does parsing (and the correct value filling in) happen automatically or do I need to update the parse logic as well?\nI am an Octokit consumer, but am very new to how Octokit internally works. Sorry if the question is obvious.\n. ",
    "joaope": "Hi! I'm grabbing this one up if it's ok with you.\n. ",
    "MikhailTymchukDX": "Well, I did this, but breakpoint can not be hit - I get an exception before this line is executed.\n. @devkhan I can not reach this url from inside VS:\n\n@shiftkey I tried IE 11 and Chrome, both OK.\nHowever, Firefox gives me this:\n\n. Thanks everyone for helping, I found the cause of the problem.\nIt was ESET Antivirus bug, that blocks all HTTPS requests until explicitly allowed.\nChrome an IE were in exclusion lists, so they work OK.\n. Not implemented yet?\nWhat are options to search by topics?. Hi @ryangribble \nI installed prerelease NuGet package Octokit.0.30.0-PullRequest1798 to test these changes.\nHowever, code behavior is not changed \ud83d\ude1e \nMoreover, I found, that Octokit returns only bottom team for some repos (while still returning top parent team for the first case):\ncs\nvar teams = client.Repository.GetAllTeams(\"DevExpress-Examples\", \"custom-template-class-e1\").Result.Select(t => t.Name);\nAm I missing something?\nI can provide you a sample project, but I don't want to expose my access token. Can I send you the sample project in a secure way?. Any update on this? Should I contact myself with the support?. Hi @ryangribble \nHere are these tests:\n\n. Thanks for such a detailed answer!\nPersonally, I'm disappointed, because the new behavior feels counter-intuitive.\nHowever, it's not related to Octokit.NET itself, so I'm closing this issue.. > What's your use case for wanting to not be told about repos that are accessible via inheritance?\nMy recent task was to update a set of repos in selected child teams only. I just realized that I updated not only child team repos, but repos from the parent team. Hopefully, that did not brought any side effects, I just spend more time on that.\nOne noticeable thing about repos in inherited teams is that when you use a site to explore nested team repos, you can not distinguish repos in a child team from repos in parent team.\nOur org structure has some top-level teams with a bunch of repos in it and smaller child teams with repos too.\nSo, when you navigate to a child team you can see more than 100 repos combined in a single list. It's hard to understand the real structure of the teams content.\n\nYou should definitely leave your feedback for the github API team on the developer site!\n\nI already emailed them several times about it and other Teams API bugs. . @ryangribble Do you mind if I create static class like TestAcceptHeaders to avoid copy-pasting?. ",
    "elv1s42": "@ryangribble thanks!\nI did not notice that in API docs and expected to see full objects.\nLooks like this is not an issue at all. \nI will try your approach, thanks.\n. ",
    "drasticactions": "Yeah, realised that after I submitted it that I broke the tests, and then saw everywhere else it was impacted. I'll fix it after.\n. Alright, test should be passing and code should be working now in the normal and observable classes. Let me know if it's all good.\n. ",
    "martinscholz83": "@shiftkey, i take this issue and #1297 and #1298 if this ok. But I will wait of merge #1295 because of ReactionSummary\n. Oops :see_no_evil: Of course!!! I didn't recognized that #1341 was merged. Thanks for the update\n. So then each client should also have a get method. Right?\n. For me the api not feels (I dont find a better word for it) naturally. If you look at the api docs, there are root objects like gists, repositories, issues and reactions. All except reactions ( i exclude labels because i dont understand why they stay under issues. For me labels are also root objects because i can get and create labels for repositories and labels for issues. But this belongs to another discussion) implement the same schema. repos/owner/issues -> repos/owner/issues/comments repos/owner/issues/event and then comes reactions repos/owner/issues/comments/reactions. Why not repos/owner/reactions/issues repos/owner/reactions/issues/comments or repos/owner/reactions/repositories/ and so on. So for this i'm with @ryangribble. But i don't want (in germany whe say \"to offend on sb. toes\" :smile: ) because im very new to this. But this would maybe the way i would do it.\n. \ud83d\udc4d \n. Hi @ryangribble, ~~is there any option to try this out. Because i dont have access to github enterprise.~~ And second question, is there someone still working on this issue?\n. :+1: \n. Jap,\n@lrz-hal is my \"now\" my testaccount. I have run the integration tests :smile: \n. Thanks!! If this looks good i will continue on reactions for other types like issues, ...\n. Hi @ryangribble. Many thanks. I'm very excited to make my first pull request for a project :smiley:  In the meantime i have created a new standalone ReactionClient where i implement a Delete Method like in #1303. Should i create a new branch and make a pull request. Or should i wait until this pull request is closed or adopted?\n. Ok. I will do this in the future. Thanks for all the suggestions\n. Another thing i would like to discuss. So far we have a request client NewCommitCommentReaction and a response client CommitCommentReaction. Would it not be better to have one request and one response client (eg NewReaction, Reaction) for all the different types? Because in the reactions doc https://developer.github.com/v3/reactions/ response and request are always the same for types.\n. Any ideas for naming EnumReaction??\n. Ok. Then i will start on this. I leave a comment for this topic #1302 \n. Is there any experimental branch where i can create pull requests?\n. :+1:  for implementation A.  This seems to be the cleanest option.\n. Updated A\n. @ryangribble  do you mean client.Reaction.CommitComment? Another suggestion client.Reaction.Commit.Comment. Same for client.Reaction.Issue.Comment. I think it should be more structured. e.g In future maybe it's possible to create reactions for commits. Then you have client.Reaction.CommitComment and client.Reaction.Commit. What do you think? Or i'm too picky \ud83d\ude38 \n. Ok. Then if it's ok for all I would create the remaining Clients.\nOn Tue, May 31, 2016 at 7:49 AM -0700, \"Ryan Gribble\" notifications@github.com wrote:\n\n@ryangribble do you mean client.Reaction.CommitComment? Another suggestion client.Reaction.Commit.Comment. Same for client.Reaction.Issue.Comment. I think it should be more structured. e.g In future maybe it's possible to create reactions for commits. Then you have client.Reaction.CommitComment and client.Reaction.Commit. What do you think? Or i'm too picky :smile_cat:\n\nI do see the appeal of it being more structured but in this case my vote would be on not creating nested/empty clients that only contained subclients.\nSo I would probably go this way:\ncsharp\nclient.Reaction.CommitComment.Create()\nclient.Reaction.CommitComment.GetAll()\nclient.Reaction.Issue.Create()\nclient.Reaction.Issue.GetAll()\nclient.Reaction.IssueComment.Create()\nclient.Reaction.IssueComment.GetAll()\nclient.Reaction.PullRequestReviewComment.Create()\nclient.Reaction.PullRequestReviewComment.GetAll()\nclient.Reaction.Delete()\nand in terms of class names\ncsharp\nI/(Observable)ReactionsClient\nI/(Observable)CommitCommentReactionsClient\nI/(Observable)IssueReactionsClient\nI/(Observable)IssueCommentReactionsClient\nI/(Observable)PullRequestReviewCommentReactionsClient\n\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/pull/1335#issuecomment-222712559\n. Ok. Then if it's ok for all I would create the remaining Clients\n. I'm done with the remaining clients and the deletion method.\n. I have run them locally. Test explorer says NSubstitute.Exceptions.ReceivedCallsException : Expected to receive a call matching:\n    GetAll<Reaction>(u => (u.ToString() == \"repos/fake/repo/comments/1/reactions\"), \"application/vnd.github.squirrel-girl-preview\")\nActually received no matching calls.\nReceived 1 non-matching call (non-matching arguments indicated with '*' characters):\n    GetAll<Reaction>(*repos/fake/repo/comments/42/reactions*, \"application/vnd.github.squirrel-girl-preview\") \nHere is the line of code connection.Received().GetAll<Reaction>(Arg.Is<Uri>(u => u.ToString() == \"repos/fake/repo/issues/comments/1/reactions\"), \"application/vnd.github.squirrel-girl-preview\");\nWhat's wrong with it? Should i hardcoded the uri?\n. oops :see_no_evil: \n. I take care of it\n. Thanks for the hints. I will carry out this ASAP\n. Sorry for forgetting the unit Tests :fearful:\n. Do you know what files are missing? I'm not so familiar with travis\n. FixProjects doesn't synchronize anything.\n. Maybe it has to do with your comment on <ProjectReference Include=\"..\\Octokit\\Octokit-Mono.csproj\">\n. Did you mean i should removed this reference?\n. Are there any issues with appveyor?\n. Looks good. I will ad some more integration tests and then i think we are ready.\n. can someone tell me why travis-ci sometimes work and sometimes not :sob: \n. There is actually an issue #1350 where the closedBy Attribute is missing in Issue.cs. I have also seen that the reactions attribute is also missing if you request an single issue. So i came to the question should reactions are only get by client.Reactions.Issue.GetAll() or should is also be possible to get them by requesting a single issue. Same for CommitComments, etc\n. :see_no_evil: Thanks\n. Todo: change tests\n. Sorry for the grammatical errors\n. :smile_cat: \n. :tada: :tada: :tada: \n\n definitely!! It's so much fun to work on this project. \n. Thank you \ud83d\ude04  What do you think where to place AddAssignees?\n. Ok. Then I place the method under Issue. Is there something more to do?\n. Ok. Then I roll back and add the Assignees property to Issue class. In the meantime i added method to remove assignees\n. I would come back to this issue and have one question. In the IssuesClient it is possible to add Assignees in the Create and Edit method and also to get assignees in payloads for Get methods if we add the preview header for multiple assignees. But it is also possible to get a reactions summary payload if we add the accept header for reactions. So now the question how to add multiple accept headers for that calls?\n. What if we change accepts from string to array. This is certainly not the last time where we have to add multiple AcceptHeaders, right?\n. Thanks for that Info :thumbsup: So I will remove that accept headers. And I correct my comment from yesterday. Maybe it it's ok in such a situation where we have to add multiple accept headers if we do something like this AcceptHeaders.X + \",\" + AcceptHeaders.Y\n. @shiftkey and @ryangribble do you think that's ready for :ship: ? Because it sounds really important\n. Hi @ryangribble, that's ok. Hi @ryangribble, any news?. I have tested and the get response contains the assignees field and the comments count. It doesn't contains labels. What currently not works is to add assignees against the pull request api.. @ryangribble, i think that adding multiple assignees for pull requests is yet not supported by the api. Maybe we should merge this one and open a new PR??. @ryangribble, integration tests work for me.. Good things come to those who wait \ud83d\ude38 . @ryangribble, is there something more to do or is this fine?\n. Something like that?\n. :tada: :smiley: @ryangribble  many thanks for your help!!\n. That's right. ClosedBy Attribute is missing. @shiftkey, is there any reason why this attribute is missing. Otherwise we can added to Issue.cs. As an aside, Reactions are also missing.\n. This is because if you rename an repo or change the owner you get an 301 moved permanently. In  Octokit.Internal.HttpMessageHandlerFactory we set AllowAutoRedirect = false\n```\nnamespace Octokit.Internal\n{\n    public static class HttpMessageHandlerFactory\n    {\n        public static HttpMessageHandler CreateDefault()\n        {\n            return CreateDefault(null);\n        }\n    [SuppressMessage(\"Microsoft.Usage\", \"CA1801:ReviewUnusedParameters\", MessageId = \"proxy\")]\n    [SuppressMessage(\"Microsoft.Reliability\", \"CA2000:Dispose objects before losing scope\")]\n    public static HttpMessageHandler CreateDefault(IWebProxy proxy)\n    {\n        var handler = new HttpClientHandler\n        {\n            AllowAutoRedirect = false\n        };\n\nif !PORTABLE\n        if (handler.SupportsAutomaticDecompression)\n        {\n            handler.AutomaticDecompression = DecompressionMethods.GZip | DecompressionMethods.Deflate;\n        }\n        if (handler.SupportsProxy && proxy != null)\n        {\n            handler.UseProxy = true;\n            handler.Proxy = proxy;\n        }\n\nendif\n        return handler;\n    }\n}\n\n}\n```\nI have tested to set this to true, and voila, i get an response which contains the new owner. @ryangribble @shiftkey can you say which consequence it has to set this to true.\n. It must have something to do with the new Request.\nresponse = await SendAsync(newRequest, cancellationToken).ConfigureAwait(false);\nIt only works for the first time. If you call it again, then you end in an error. \nBut If i cancel all pending requests for _http before you send a new request it works.\n```\n public async Task Send(IRequest request, CancellationToken cancellationToken)\n        {\n            Ensure.ArgumentNotNull(request, \"request\");\n        var cancellationTokenForRequest = GetCancellationTokenForRequest(request, cancellationToken);\n\n        using (var requestMessage = BuildRequestMessage(request))\n        {\n            // Make the request\n            var responseMessage = await _http.SendAsync(requestMessage, HttpCompletionOption.ResponseContentRead, cancellationTokenForRequest).ConfigureAwait(false);\n            _http.CancelPendingRequests();\n            return await BuildResponse(responseMessage).ConfigureAwait(false);\n        }\n    }\n\n```\nI don't know why but it seems that the first redirect request is not completed succesfully. I will try to find out why.\n. The only fix for me is to call _http.CancelPendingRequests() after you get the response. Because for any reason i don't know there is still a request pending which maybe has the same signatur or anything else. I have no idea. @shiftkey what do you think.\n. I think it has to do with the following line. It seems that there is the same request sending twice. But i don't know why because we are building a new request object :sweat: \n. @shiftkey i have create pull request #1411. There i put the logic for redirects outside of the delegating handler. Because for any reason if delegating handler sends the same request twice, and this is not possible. The other solution is to cancel alle pending requests see my comment below.\n. Hi @ryangribble , i would take this issue.\n. Hi @ryangribble @shiftkey i'm almost finished with this issue. There is one strange thing with this api. I have create an integration test to send an invitation. The callback from the api ist fine, but it sends no invitation (email). I have tested this also with a real example. Can you confirm this behavior? \n. Any ideas why .net core does not have method GetField()?\nhttps://github.com/dotnet/corefx/blob/master/src/System.Reflection.TypeExtensions/src/System/Reflection/TypeExtensions.CoreCLR.cs/#L66\n. I actually can not test if this work with .net core.\n. I have tested all variations [Parameter(Key = \"+1\")]. But if you step trough the serialization process \nprotected virtual bool TrySerializeKnownTypes(object input, out object output)\n        {\n            bool returnValue = true;\n            if (input is DateTime)\n                output = ((DateTime)input).ToUniversalTime().ToString(Iso8601Format[0], CultureInfo.InvariantCulture);\n            else if (input is DateTimeOffset)\n                output = ((DateTimeOffset)input).ToUniversalTime().ToString(Iso8601Format[0], CultureInfo.InvariantCulture);\n            else if (input is Guid)\n                output = ((Guid)input).ToString(\"D\");\n            else if (input is Uri)\n                output = input.ToString();\n            else\n            {\n                Enum inputEnum = input as Enum;\n                if (inputEnum != null)\n                    output = SerializeEnum(inputEnum);\n                else\n                {\n                    returnValue = false;\n                    output = null;\n                }\n            }\n            return returnValue;\n        }\nand then\nrotected override object SerializeEnum(Enum p)\n            {               \n                return p.ToString().ToLowerInvariant();\n            }\nso maybe this is really the first time this happens or i'm wrong :confused: \n. There are also problems when converting back to enum. In SimpleJsonSerializer.cs -1 becomes 1\nbecause of \n// remove '-' from values coming in to be able to enum utf-8\n                        stringValue = RemoveHyphenAndUnderscore(stringValue);\n                        return Enum.Parse(type, stringValue, ignoreCase: true);\nAnd +1 is converted to Minus1 :weary: \n. Maybe we should use hardcoded strings for ReactionType?\n. Here is maybe another solution. For example if you have +1  how Enum.Parse should parse it to the\nright value?\n. In think i know where the issue comes from. All the enums with parameters are used Requests which inherits from Requestparameter. For example MilestoneRequest\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Models/Request/MilestoneRequest.cs#L11\nIn the Apiconnection call you see request.ToParametersDictionary() which internally use reflections to get the parameter attribute\n/// <summary>\n        /// Converts the derived object into a dictionary that can be used to supply query string parameters.\n        /// </summary>\n        /// <returns></returns>\n        public virtual IDictionary<string, string> ToParametersDictionary()\n        {\n            var map = _propertiesMap.GetOrAdd(GetType(), GetPropertyParametersForType);\n            return (from property in map\n                    let value = property.GetValue(this)\n                    let key = property.Key\n                    where value != null\n                    select new { key, value }).ToDictionary(kvp => kvp.key, kvp => kvp.value);\n        }\nIn ReactionsClient we pass reactions as a normal parameter\nreturn ApiConnection.Post<Reaction>(ApiUrls.CommitCommentReactions(owner, name, number), reaction, AcceptHeaders.ReactionsPreview);\nwhich is serialized by\nasync Task<IApiResponse<T>> Run<T>(IRequest request, CancellationToken cancellationToken)\n        {\n            _jsonPipeline.SerializeRequest(request);\n            var response = await RunRequest(request, cancellationToken).ConfigureAwait(false);\n            return _jsonPipeline.DeserializeResponse<T>(response);\n        }\nSo the solution for this first problem is to inherit NewReactiion from RequestParameters and change the Api call for all reaction clients. I have tested this and it works as expected.\npublic class NewReaction : RequestParameters\nreturn ApiConnection.Post<Reaction>(ApiUrls.CommitCommentReactions(owner, name, number), reaction.ToParametersDictionary(), AcceptHeaders.ReactionsPreview);\nThe second problem is if you get a payload which is serialzed. This only happens at one place.\nhttps://github.com/octokit/octokit.net/blob/master/Octokit/Http/SimpleJsonSerializer.cs#L79\nSo here i think the only solution is from my last commit\nhttps://github.com/octokit/octokit.net/pull/1402/commits/4c05be81d43c38ae447db0e90d85fc44233a9d3d#diff-2e183b0cbda11827ea1db237ac05ce00R106\nSo if you dont't do this and you have a parameter like +1 you never know if Enum.Parse parse it to right enum value.\nPlease correct me if i'm wrong\n. @ryangribble p.ToParameter() works perfectly :tada: \n. Can you look on my last commit. Maybe someone has another solution. (Maybe simpler).\n. \n. Do you mean here\nhttps://github.com/octokit/octokit.net/blob/master/Octokit.Tests.Integration/Clients/IssueCommentsClientTests.cs#L21\n. unit tests are failing after merge. should i rollback?\n. Is there something more to do with this request?\n. @shiftkey i have cherry-pick your commit. test are now passing :+1: \n. These failing integration test was my mistake :hushed: \n. I wasn't able to merge your request. So i have to create a branch of yours, resolve conflicts, and then create a pull request internally. Very confusing :confused:. But now all should be fine\n. I think the conflict came from your pull request. Because in the meantime i have made a change in my branch:see_no_evil: Tests run perfectly!!\n. :tada: :tada: \n\n. I think i'm done. appveyor test is failing :sweat: \n. i'm now writing the ~~unit~~ integration tests\n. Is it ok to use the octokat account for the invitations?\n. Used to set the permission for a collaborator.\nThe permission to grant the collaborator on this repository.\n??\n. What's with the default constructor. Should we let the user decide?\n. For summary:\n Add and Invite Methods should have the permissions attribute with note Only valid on organization-owned repositories. Right?\n. Ah. Right. This I have forgot to tell you :grin:\n. I reduce the integration tests to only receive invitations. Tests for accept and decline not possible yet. Anything more to do?\n. Unfortunately not. I always catch an NotFoundexception if try to decline and accept with the same account. I have tested it with different accounts. There i can accept and decline the invitiations.\n. I still don't get this test working :confused: \n```\n[IntegrationTest]\n        public async Task CanDeclineInvitation()\n        {\n            var github = Helper.GetAuthenticatedClient();\n            var repoName = Helper.MakeNameWithTimestamp(\"public-repo\");\n        using (var context = await github.CreateRepositoryContext(new NewRepository(repoName)))\n        {\n            var fixture = github.Repository.Collaborator;\n            var permission = new CollaboratorRequest(Permission.Push);\n\n            // invite a collaborator\n            var response = await fixture.Invite(context.RepositoryOwner, context.RepositoryName, context.RepositoryOwner, permission);\n\n            Assert.Equal(context.RepositoryOwner, response.Invitee.Login);\n            Assert.Equal(InvitationPermissionType.Write, response.Permissions);\n\n            // Decline the invitation\n            var declined = await github.Repository.Invitation.Decline(response.Id);\n\n            Assert.True(declined);\n        }\n    }\n\n```\nShould i though write these tests although they don't work with my account?\n. In that try catch block I get an 404 NotFoundException. Later I can send you detailed informations.\nOn Tue, Jul 19, 2016 at 1:15 PM +0200, \"Ryan Gribble\" notifications@github.com wrote:\n:+1: write them and I'll check them my side. What error do you get?\n\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/octokit/octokit.net/pull/1410#issuecomment-233602356\n. If i login i can also see that invitation. But i can't accept or decline it with octokit. But if it works with your account then maybe its not an issue. Maybe someone third should test it.\n. \n100 points :tada: That's it.\n. :joy:  That last gif\n. I rewrite the failed unit tests\n. Not really. Maybe in the next few days. What i have seen is that we have to completely rewright tests for redirects. Yet they are in RedirectHandlerTests but i think we should move them to HttpClientAdapterTests because redirecting is now handled directly in there. What do you think?\n. Hi @shiftkey. I have sit down and think about these failing redirect tests. Here is an approach in which i have move one test into HttpClientAdapterTests. Because redirecting is handled by this class. But to translate tests i have to create a new property RequestMessage for class Response to get access to the RequestMessage. What do you think? So this is really a first approach!!\n. I have try to copy these other tests and have find that is not possible to copy them 1 to 1. Because i always have to create new properties for IResponse and IRequest like Authorization. What is the intent for these both classes instead of using HttpRequestMessage and HttpResponse. Because you anyway translate them into HttpRequestMessage like here\n. Oh man, it's time for holidays :dizzy_face:  I rollback all my comments and add the changes form ryan. Now all should be fine, expect that one failure ryan described\n\nAssert that tries to verify that same field (response.RequestMessage.Content).\n. One thing I would like to comment is that we now have two public send methods in HttpClientAdapter. Both are asynchronous but one is called Send and the other SendAsync. Is this ok?\n. @shiftkey this means these changes from @ryangribble are ok?\n. Something I can do to get ready?\n. Thanks for that hint @dampir. I thought there where unresolved things because of\nI'm not sure if anything really needs to do this (it was only the integration test that was doing it in our code)\n\nI will asap fix the comments from @shiftkey.\n. Hi @ryangribble, do you mean test CanCreateIssueOnRedirectedRepository? Maybe it is better to clone the request after we get the respone? Only for design\n``` C#\n            // Send initial response\n            var response = await _http.SendAsync(request, HttpCompletionOption.ResponseContentRead, cancellationToken).ConfigureAwait(false);\n        // Can't redirect without somewhere to redirect to.\n        if (response.Headers.Location == null)\n        {\n            return response;\n        }\n\n// Clone the request/content incase we get a redirect\nvar clonedRequest = await CloneHttpRequestMessageAsync(request);\n```\n. Ok, that makes sense\n. All tests including that one you have uncomment work for me. So i think we're done, right?\n. \n. \nThat's a lot. I will see what i can do if it's ok.\n. Should i wait until #1441 is merged before to start?\n. In the delete method for the required status checks contexts the API says it returns an array. This is ok if you delete one context.\nRequest\n[\n  \"continuous-integration/jenkins\"\n]\nReponse\n[\n  \"continuous-integration/jenkins\"\n]\nBut if you delete more then one context it returns an empty array.\nRequest\n[\n  \"continuous-integration/jenkins\",\n  \"continuous-integration/travis-ci\"\n]\nReponse\n[\n]\nexpected\n[\n  \"continuous-integration/jenkins\",\n  \"continuous-integration/travis-ci\"\n]\n@shiftkey @ryangribble can you confirm this?\n. These naming convention tests fails because i have named methods for example  GetProtectedBranchUserRestrictions. Should we rename to GetAllProtectedUserRestrictions?\n. It's just for clarifiying.\n. So, i have tested all the api endpoints and no one support pagination. So @ryangribble we have to exclude all the new methods from the convention test. Is there any flag we can set to exclude these methods? In the meantime i start to write the unit tests for the new methods.\n. Hi @ryangribble. In my last commits i have created an attribute ExcludeFromTest to filter the new methods. I have exclude these methods in PaginationTests and in SyncObservableClients. Can you also have look of the return types for the observable methods. Because they don't support pagination they have to be for example IObservable<IReadOnlyList<User>> instead of IObservable<User>. Is that correct?\n. ExcludeFromPaginationTestAttribute is better but i use this Attribute also to exclude from SyncObservableClients. Should i create two attributes?\n. Hi @ryangribble, can you please give a feedback. I think this PR is ready.\n. That make sense. So you mean instead of ~~returning Task<IReadOnlyList<Team>> SetProtectedBranchTeamRestrictions we should return Task<BranchProtectionTeamCollection> SetProtectedBranchTeamRestrictions~~ public Task<IReadOnlyList<Team>> SetProtectedBranchTeamRestrictions(string owner, string name, string branch, IReadOnlyList<string> teams) we should do this public Task<IReadOnlyList<Team>> SetProtectedBranchTeamRestrictions(string owner, string name, string branch, BranchProtectionTeamCollection teams)\n. I have correct my commit.\n. What about IReadOnlyList<string> contexts Should we also create a more specific class instead of a List<string> or we don't need this because there is no difference between them.\n. Hey @ryangribble, is this ready for \ud83d\udea2?\n. @ryangribble, thanks for your review!!\n. Very nice \ud83d\ude38 Thanks!! The undisposed contexts i will fix.\n. @ryangribble, i see that the GetRedirect method is coming from your branch. I have removed this method. Is that ok?\n. > applies only to Organization owned repositories\n\ud83d\ude48 \ud83d\udc4d \n. youre awesome \ud83c\udf89 \ud83d\ude01 \n. Hi @shiftkey, is this ready for \ud83d\udea2. I ask because of preventing and maintaining conflicts if there are changes in master.\n. \ud83d\udc4d \ud83c\udf89 \n. Hi @ryangribble, i would like to take this issue. I would create a new client IRepositoryTrafficClient!?\n. Maybe someone has a better naming for TrafficeDayOrWeek \ud83d\ude38 \n. @ryangribble, what about integration tests for this feature. The only thing we can test is that the result is not null :expressionless:. And of course the result count is 0.. Should i do that?\n. Yeap, you need to have push access.\n. \n. Hi @ryangribble, is this ready for \ud83d\udea2?\n. Hi @ryangribble, thanks for your review. I have read on the format of timestamp. Is there any explanation why it's this format? And yes, View is realy a bit to common \ud83d\ude01. The renaiming of GetAllxxx() makes sense. I already have this in mind but i don't know wheter it woul be correct. So many thanks for your fixes \ud83d\udc4d \n. And the renaming of the repsitory id's i have forgotten, because i already did this in another PR :sweat_smile:\n. Many thanks @ryangribble \n\n. Looks like a nice project \ud83d\ude00 In the API they say that pagination is currently not supported. But i've tested with two projects and i can paginate (get the Link Header)!!??\n. So should we go on with pagination?\n. Ok. I create PR for this\n. Hey @ryangribble. I try to FixProjects and get this\n```\nbuild.fsx(120,14): error FS0039: The value, constructor, namespace or type 'DotNetCli' is not defined\nCACHING WARNING\nthis might happen after Updates...\nplease open a issue on FAKE and /cc @matthid ONLY IF this happens reproducibly)\nError: System.Exception: We could not find a type similar to '.$FSI_0001_Build$fsx' containing a 'main@' method in the cached assembly (./.fake/build.fsx_857B7771.dll)!\n   bei Fake.FSIHelper.runScriptCached@328-4.Invoke(String message) in C:\\code\\fake\\src\\app\\FakeLib\\FSIHelper.fs:Zeile 328.\n   bei Yaaf.FSharp.Scripting.Helper.consoleCapturea in C:\\code\\fake\\src\\app\\FakeLib\\FSIHelper.fs:Zeile 512.\nUnable to access C:\\Users\\scholzmartin\\Documents\\GitHub\\octokit.net.fake\\build.fsx_857B7771.dll\nFsiEvaluationException:\nError:\n    build.fsx(120,14): error FS0039: The value, constructor, namespace or type 'DotNetCli' is not defined\n\nOutput: [Loading C:\\Users\\scholzmartin\\Documents\\GitHub\\octokit.net\\tools\\SourceLink.Fake\\tools\\SourceLink.fsx\n         Loading C:\\Users\\scholzmartin\\Documents\\GitHub\\octokit.net\\build.fsx]\n``\n. Mmhh, but i'm currently up to date with master\n![image](https://cloud.githubusercontent.com/assets/19551763/18949723/d763a740-863c-11e6-9f53-9363526b46e7.png)\n. i have looked in tools folder an it seems that i still have fake version 4.28 installed. How can get update fake. Normalybuild.cmdshould do this, right?\n. Ok, i've got it. I have renamed theFAKE.Corefolder in tools and then run the build script again. Now it works. It seems thatnuget.exedoesn't override the existing version.\n. ~~mmh, but now there are untracked files for theFAKE.CoreFolder. How can i exclude this folder? It seems that the exclusion ingitignoreis not recognizing this new folder.~~\n. I don't have delete the renamed folder \ud83d\ude38\n. Hi @ryangribble, how would we named [this](https://developer.github.com/v3/repos/projects/#move-a-column).RepositoryProjectColumnMove`??\n. > Although you probably know me well enough to know that I always have an opinion \ud83d\ude00\nI know \ud83d\ude04 \ud83d\ude38 . But i wasn't sure because there are sometimes classes which be called different. For eg.\nPullRequestRequest.cs and on the other side there is RepositoryIssueRequest.cs. So i agree with you that Projectsounds better then RepositoryProject. So i think will rename them.\n. Or another examples are RepositoryInvitation.cs, RepositoryTag.cs, RepositoryHook.cs, and there are lot more, mmhhh \ud83d\ude15 \n. Hopefully no one reads this \ud83d\ude1c \nOk, that make sense. So i agree as long as there are only projects for n<=1 types we call them Project.\n. \nPhew ... tests are finished. So i think it's time to review.\n. Hi @ryangribble, wow, that's a lot of changes. So i have to step through. Please correct me if i'm wrong\n1. There are 2 new endpoints List organization projects and Create organization projects\n2. The responses and the request of this two are same like for public projects. So i think they stay under the same client RepositoryProjectsClient and we name them GetAllForOrganization and CreateForOrganization\n3. /repos/:owner/:repo/projects/:number endpoints are deprecated and will be removed on 10. November. So i think we should wait for 10. November before we add this feature into client. So we can  already remove these endpoints and only use the new  id endpoints /projects/:id\nOr do you think we should add these changes now and remove them after 10. November? Do we have some work with scopes on client side?\n. Hey @ryangribble, it was a little late yesterday \ud83d\ude34 . I just now realize that they completly reorganized the projects api. So i think like you say they need to live in a different place.\n1. I would create a client ProjectsClient with the api calls only for projects.\n2. Then i would create two new seperated clients for project cards and project columns ProjectCardsClient and ProjectColumnsClient\nWhat do you say?\n. Yeap, but i think it's the right way to add these preview features instead of waiting until they are finished!! Ok then i will rewrite clients and hope that they don't switch back \ud83d\ude38 But there is still the question if we only implement the new endpoints projects/.../:id?\n. \n\n\ud83c\udf89 \ud83c\udf89\n. So ... i have rewrite clients. Things to do is change the tests.\n. Soo, all is rewritten. \nHopefully they don't change api again\n\n\ud83d\ude38 \n. Integration test's all have passed except the one for Organization. @ryangribble can you please test\n. @ryangribble, Edit from maintainers is enabled. @markwilkie, thanks for that tip. I can confirm that is if 'issue' is lowercase it returns an error. @ryangribble, @shiftkey do you think thats an error by the api? Because in all other api such parameters are lowercase.. I have set Parameter(Value=\"Issue\"). Now client works.. @ryangribble, do you have the chance to push your changes for integration tests. Because i forgot to test to create a card from an issue.. Hey @ryangribble, happy new year \ud83c\udf89 Seems this is ready to \ud83d\udea2 ?. I also added ApiOptions for ProjectCards and ProjectColumns.. Hey @ryangribble, I'm currently on the road. Tomorrow I add the missing test's so that we quickly can close this PR. \ud83d\udc4d to @M-Zuber\n. @ryangribble, waht do you mean with \n\nadd a BlahText property to always provide what the actual returned value was\n. So, that means that we search all response types which have  an enum, add a string field for that enum, and add a new member UnknownType for that enum. Right?. I think it's a good solution. My only concerns was that we miss if any new values are added by the api. So like @M-Zuber says, we should implement a mechanism which inform us if there is a new added member.. Ok, then lets go this way.. Ok. Now it's clear to me. I already had this in mind, but i don't know how to implement. Many thanks!!. Ok, then i wait for feedback from @shiftkey before going on.. And what we should discuss is the naiming of the new member Unknown. Here enum member is called unknown. I know this not an enum used by any response, but what if they implement such an member by the api.. :tada: \ud83d\udc4d . I thought it would be cleaner if all Tests for Reactions are at one place. So there is only subclass for commit comments yet.\n. In other places like here var endpoint = ApiUrls.Releases(owner, name);\n            return ApiConnection.Post<Release>(endpoint, data, AcceptHeaders.StableVersion); they are not hardcoded. Why here? Are they obsolete and should be hardcoded everywhere?\n. Ok. I asked because you point to class CommitCommentReactionClient.cs\n. Ohh. That's right. No good Name for a test. I will split tests into separate classes.\n. I have integrate this test into CommitCommentReactionsClientTests.cs\n. ok. i have copied this form another test. eg ObservableRepositoryCommentsClientTests.cs\n. Is it ok to add the test into AddAssignees and rename test into CanAddAndRemoveAssigness?\n. I have a strange behavior in visual studio. Vsual Studio tells me that it cannot resolve typ or namespace for types that came from namespace Octokit. But that comes first since yesterday. \n\n\nSo yes, this was inadvertent.\n. I'm also change x.Name to x.Login\n. Done\n. Because in json String we add labels.\n\"\"labels\"\": [\n{\n    \"\"url\"\": \"\"https://api.github.com/repos/octocat/Hello-World/labels/bug\"\",\n    \"\"name\"\": \"\"bug\"\",\n    \"\"color\"\": \"\"f29513\"\"\n}\nSo this test will always fails if we test null.\n. That's great!\n. Same for PullRequest\n. That i have proposed in an old comment in Stand-Alone-Reaction-Client but it was rejected because of not necessary :neutral_face: \n. Something like this ?\nConfused = 0,\n        Laugh = 1,\n        Heart = 2,\n        Hooray = 3,\n        [Parameter(Value = \"+1\")]\n        Plus1 = 4,\n        [Parameter(Value = \"-1\")]\n        Minus1 = 5,\n. Can you give me an example. I think I have a Blackout :dizzy_face:\n. Maybe we should use hardcoded strings. Because i have no idea how we can deserialize enum properly without to loop trough all the enum values and check if it has an attribute or not.\n. Or we create a customAttribute class DeserializeProperlyAttribute for example. And then\npublic override object DeserializeObject(object value, Type type)\n            {\n                var stringValue = value as string;\n                var jsonValue = value as JsonObject;\n                if (stringValue != null)\n                {\n                    if (ReflectionUtils.GetTypeInfo(type).IsEnum)\n                    {\n                        if(Attribute.IsDefined(type, typeof(DeserializeProperlyAttribute)))\n                        {\n                            //first try to get all custom attributes\n                            var fields = type.GetRuntimeFields();\n                            foreach (var field in fields)\n                            {\n                                var attribute = (ParameterAttribute)field.GetCustomAttribute(typeof(ParameterAttribute));\n                                if (attribute != null)\n                                {\n                                    if (attribute.Value.Equals(value))\n                                        return field.GetValue(null);\n                                }\n                            }\n                        }\n                        // remove '-' from values coming in to be able to enum utf-8\n                        stringValue = RemoveHyphenAndUnderscore(stringValue);\n                        return Enum.Parse(type, stringValue, ignoreCase: true);\n                    }\n. Ok. Then i would implement loops like in #1402 for reaction types.\n. I've ended with \nhttps://github.com/octokit/octokit.net/pull/1402/files#diff-2e183b0cbda11827ea1db237ac05ce00R120\nBecause we need to store the value that comes from the api like blob or open and not the name of the enum field Blob, Open. If we store the name of the field we every time have to parse between these two values. Please correct me if i'm wrong.\n. That's right. But the RepositoryPermission enum uses admin, push, pull and we need admin, write, read. So because of that i created a new enum\n. This test always fails because context is trying to delete this repo and you cannot delete a repo until there is a pending invitation. And yes, it still not sending any email. Next question is, how should i write integration tests for invitations. Is there any test client where user can send invitations to?\n. youre right. When there is a pending invite. Ok. Then i use my lrz-hal account.\n. @ryangribble there is some problem with deleting the invitation\n``` c#\nusing (var context = await github.CreateRepositoryContext(new NewRepository(repoName)))\n            {\n                var fixture = github.Repository.Collaborator;\n                var permission = new CollaboratorRequest();\n            // invite a collaborator\n            var response = await fixture.Invite(context.RepositoryOwner, context.RepositoryName, \"lrz-hal\", permission);\n\n            Assert.Equal(\"lrz-hal\", response.Invitee.Login);\n            Assert.Equal(InvitationPermissionType.Write, response.Permissions);\n\n            var deleteInvite = await github.Repository.Invitation.Delete(context.Repository.Id, response.Id);\n        }\n\n```\nThe problem is when fixture.invite is calling, in the same moment context is trying to delete the repo. So i cannot delete the invitation, because i don't reach that call!!??\n. Dispose of RepositoryContext is calling too early.\n. It breakes here with RepositoryInvitation :sweat: But it tells me not why. Is there someting wrong with RepositoryInvitation?\n. :tada: That's awesome!! So then my comment \n\nyou cannot delete a repo until there is a pending invitation\n\nis wrong. It deletes the repo and the invitation.\n. In the api the default value is push. So i thought it would be correct. \n. Ah. That's right. Failure of mine. So if i understand it correct, i we don't set the CollaboratorRequest the api sets push as the default value. Right?\n. So then we should have two overloads for Add and Invite in RepoCollaboratorsClient!? Because the docs say Only valid on organization-owned repositories.\n. This is still WIP. I actually don't know how to implement integration tests for Repository Invitations because i need two contexts. One for sending the invitation and one for accept and decline the invitation. Any ideas?\n. :see_no_evil: :+1: \n. To use TryParse i need an instance TEnum. How can i achieve this from Type type\nEnum.TryParse(stringValue, true, ????);. :+1: . :see_no_evil: . ",
    "ErikSchierboomTest": "Ouch, not the best of choices on my part :) I'll look at one of the other issues.\n. ",
    "lrz-hal": "HI Shiftkey,\ni'm working on this feature for commits, issues, .... Is this Ok?\n. Ok. Thanks for the notes. I will add this asap.\n. ",
    "joe307bad": "I had actually seen that question and formulated the above code based on that.\nI am mainly looking to get the commit stats (which seems like a pretty small piece of data) without having to make a separate Commit.Get request for each individual commit returned from Commit.GetAll. This seemed like an inefficient way to get a small piece of data associated with all commits.\nI thought my question differed from the one you referenced since that question is requesting to get deeper file information associated with every commit so it was understandable that a separate Commit.Get was required.\nI came up with this question when I noticed the GitHubCommit.Stats property was null when accessing directly from the results of Commit.GetAll.\nThanks for the response!\n. That's an interesting approach. I am actually just looking to output a simple list of most recent commits and minor details on each commit. I felt the commit message, commit date, and commit stats would provide a good snapshot for a commit, which is why I was surprised commit stats were not in the commit payload you referenced. \nThanks for the help.\n. ",
    "raytam513": "hi shiftkey,\nThanks for the quick response!  I understand the the commit message inside the PR can't be changes.  What I want to do is tack on a string to the pull request merge commit message.\nRight now in GitHub website when I click on the merge pull request button my commit message for the merge is prepopulated with \"Merge pull request #5 from ragnarok513/test\".  If my branch name was named Bug-123-urgent_issue_with_homepage, I want to parse out the text \"Bug-123-\" and prepend it to my merge commit message so that my merge has this message \"Bug-123-Merge pull request #5 from ragnarok513/test\"\n. Some context for you....\nMy users are going to be directed to use the Github website to initiate and complete pull requests.  I have a webhook that enforces that the pull request must also have my custom labels attached before merging.  I need to also enforce that the pull request commit message starts with something like \"Bug-123\".  I didn't find a capability to validate the pull request commit message so my alternate idea was to prepend the commit message with part of the branch name\n. ",
    "k122085": "Alright. Thank you for the response.\n. ",
    "jonnii": "@maddin2016 @shiftkey @ryangribble would be great to have this one in... . Would it be possible to cut a new release with this?. What's left to get this over the line? Anything I can do to help?. @MuazOthman if you add me I'll see what I can do. . ",
    "shaggygi": "Yes, I'll look into the PR.\n. @shiftkey Thanks for feedback.  I was thinking I should have added tests based on the contribution notes, but didn't know exactly where being new to this repository.  I will review what you mentioned and try to add soon.\n. I added a test using BlobClientTests as example.  Did not verify Creator property, but left a TODO comment.  If you know of a similar test to verify User, let me know and I can update.\n. After reviewing/learning more about the API structure, I think I agree with @ryangribble on removing LabelsUrl.  It is nice to have the property included, but logic is already in place for IssuesLabelsClient.  I will remove and commit soon.  I originally added similar to others since it was returned in the JSON.\n. @ryangribble well, i've completely screw this up.  your suggestions worked on the user for test.  something went weird when merging and last file changes are not showing up.  many reverts/tries on my branch trying to understand more about VS/Git.  any thoughts on steps to address... it is clear one of my first few times on this :frowning: \n. @ryangribble I really appreciate the info.  Like you mentioned, I have the changes so I can add later.  I'm going to go ahead and close the PR and review your notes (and more about Git terminology).  I'll circle back soon and attempt another PR when ready.\n. I was able to do this as mentioned, but wasn't sure if there as a call that could do in one attempt instead of individually.  I also had to add the labels and assignees one at time, as well.  @shiftkey  Are you saying this is the case or is there a method to copy the entire issue(s) contents (body, labels, assignees, etc.) to new fork at one time?\nThanks again for the help.\n. That did the trick @shiftkey Thanks!\n. Yes, just came across this property.  Thanks\n. Thx for info.\n. Came across this today, but is for UWP.\nhttp://docs.uwpcommunitytoolkit.com/en/dev/controls/MarkdownTextBlock/\n. Maybe one day.  Thx for the reply.\n. Yes, I wanted to know if there was a way to attach a file via the API like you would when dragging/dropping on the Issue in GitHub website.  Basically, I want to programmatically create an Issue, add some markdown comments and attached a file.  It seems like there would be some type of method to do this.  If Octokit is currently not able to do so, do you know the next steps to take in determining if it possible?  Thx for the help.\nI came across this, but it appears to perform in web as you mentioned.\nhttps://github.com/blog/1347-issue-attachments\nhttps://help.github.com/articles/file-attachments-on-issues-and-pull-requests/\n. @shiftkey Thanks for the info.  If I could ask one more question.... do you mean it is not supported in Octokit or it is not a supported feature in GitHub in general?  Meaning, you don't know of ETA coming with GitHub?  Thanks again.\n. Any update on finalizing and when it will be added to NuGet package?  I'm looking forward to this feature.  Great work :+1: . @ryangribble thanks for working on this.  Do you know when this will be added to nuget package?. @ryangribble thank you. @maddin2016 @ryangribble any updates when this will be added? Just curious.  Thx. @ryangribble as usual, that did the trick.  thanks for your help \ud83d\ude04 . ",
    "AlenPelin": "+1\n. ",
    "BaconSoap": "We were looking at using the distinct field on commits specifically (to cut down on processing). There's a bit of weirdness there in that it's on the webhook commit response, but not on the GET /commit response, and as best I can tell OctoKit uses the same model for both. Would that be a nullable bool (seems easier to add from a 'I could make a PR for this' standpoint)? Or would it need to be split out into two models, one for commits from the API & one for commits from a webhook payload?. I compared what I get from a saved webhook (push event vs from the api) and added the results/diff in a gist.\nKey points:\n\nwebhook uses Id, commit uses Sha\nwebhook has lists of files affected, api does not (and requires generating a diff)\nwebhook his a distinct field, commit doesn't (which makes sense given distinct is only valid at that point in time)\napi has info about the tree/parents of the commit, and the webhook doesn't\n\n(It turns out that I had actually been using a reimplemented model locally which was how I've been parsing pushes in the first place).\nI think the worst difference is that it uses different property names to refer to the same thing - like id vs sha.. ",
    "niltor": "so , how do we do these  missing fields? any plans?\n. @ryangribble ok,got it. . ",
    "tebeco": "Of course the code is copy pasted from :\nhttps://github.com/octokit/octokit.net/blob/master/samples/linqpad-samples/6-create-repository.linq\nChanges :\n- \".Dump\" method extension seems to comes from linqPad only so I've deleted lines\n- I've replaced \"client.GitDatabase.xxx\" by \"client.Git\" since this is obsolete code.\n- Used a new ProductHeaderValue\n- used my Entreprise Account line 21\n- replace line 27 with OAuth token : client.Cred = new Cred(\"tokenAsString\");\n- replaced line 30 with associated mail\nCrash on line 38\n. Ok so I just had a lucky Guess\nOctokit is not compliant with ConsoleApp if consoleApp is buit with 4.6.1\nIt seems to crash a \"MethodNotAllowed\" exception if i'm targetting 4.5\n. @ryangribble any idea for the MethodNotAllowed ?\nLet's say that :\n- my Entreprise expose Github on : https://corp.github.pouet/\n- My account is on : https://corp.github.pouet/tebeco\n- I created an OAuth token : a12345bcd\nThe generated request has the following params when it's rejected ::\n(File Connection.cs line 543)\n\nrequest.BaseAdress : https://corp.github.pouet/api/v3\nrequest.EndPoint : {user/repos}\nrequest.Body : \"{\\\"name\\\":\\\"SampleRepo\\\"}\"\nrequest.Method : \"POST\"\nrequest.Parameters : Count = 0\nrequest.Headers[0] : {[Accept, application/vnd.github.quicksilver-preview+json;......]}\nrequest.Headers[1] : {[User-Agent, myProductHeaderValue]}\nrequest.Headers[2] : {[Authorization, Token a12345bcd]}\n. wich version of what ?\n\nI've cloned \"Octokit\" and added a console app INSIDE the solution\nthis consoleApp is using framework 4.6.1\nAnd this project has a \"Project reference\" to the Octokit.net project\nNo tricks, then it will crash\nMy guess is that the framework 4.6.1 changed BCL for the stack octokit uses (from 4.5)\n. So ...\nThe fact that I catch nothing is only happening if I use Octokit inside a \nConsoleApp 461               KO\nConsoleApp is 4.5             OK\nWebApi 461                       OK\nI can catch any exception without issue in any configuration/plateform or whatever in any project BUT the configuration octokit + consoleApp 461\nMy guess is that there's a segfault or something like that. It seems that VisualStudio unload the AppDomain \"the hardway\".\nAnd since octokit is using \"Web\" BCL classes and these one changed ... I think it comes from that\nFYI : the oldest framework supported is 4.5.1 and octokit uses 4.5\nI've moved octokit to .net 4.6.1 it solves this crash\nI strongly recommend the move to .net 461 to avoid this kind of behavior since there's been lots of changes in the BCL around httpClient & so on\n. For the \"MethodNoAllowed\" issue\nIt seems that :\n\nnew ProductHeaderValue(\"Octokit.samples\")\n\ndoes not allow me to set a custom values ... it works perfectly until I change it with :\n\nnew ProductHeaderValue(\"abc\")\n\n... not always I really don't get it it's like there's a cache but when I got the exception, I play with the user agent and it seems to works again. Like there's a 50/50 chance\nI really don't get it\n. ",
    "andrejo-msft": "Brendan, I did in fact collect this data in the process of troubleshooting.\nThis is from memory and reflects what I saw on Friday.\n- Issues GetAllFromRepository() can be done without additional ApiOptions added.\n- Comments GetAllFromRepository() gets stuck in the loop that I see if ApiOptions are not set. However, if I provide a number of pages larger than the number needed as part of the ApiOptions, it only uses the appropriate number of calls to the GitHub API.\n- Events GetAllFromRepository() gets stuck in the loop that I see if ApiOptions are not set. If I tell the call to get 100 pages \u2013 even if the number of pages needed are more than that \u2013 it will use 100 calls of my account\u2019s 5000/hr to get that information\u2026but return the correct number of events.\nI did not observe other GetAllFromRepository() calls.\nWhen I let the Events GetAllFromRepository() gather without bounds, it will send off ~1100 calls to GitHub, then respond with the error that I saw.\nRyan, good questions. I will get back to you when I get into work on Monday.\n. @ryangribble - we use Octokit to push GitHub issue data into our internal bug tracking system, allowing those who are looking at larger trends within the organization to not have to jump over to GitHub to understand our project.\nGH issues, comments, and events are used to update our tracking bugs. Because GetAllFromRepository's ApiOptions only cover page size and number of entries, the initial version of the code asked for the entire repo, then parsed the output down to only the updated comments. Not exactly efficient. Our repo is still small enough to make this possible. I was looking at better ways to get the work done before the issue I mention above showed up on Friday.\nWhat would be ideal would be to ask only for the comments or events that take place since a certain timestamp (the last hour of comments, for example). It'd be useful to have a similar RepositoryRequest for comments and events as we do for issues.\nAs you point out, some of this could also be done using RepositoryIssueRequest {Since = ...} and just getting events or comments for those issues. However, it'd also be useful to not have the API misbehave and use too many calls for a particular event request.\n. I like that rather a lot. Otherwise, we\u2019ll continue to hit one-off issues such as these every time a new set of features around issue events are released.\n-Drew\nFrom: Ryan Gribble [mailto:notifications@github.com]\nSent: Friday, November 11, 2016 1:56 PM\nTo: octokit/octokit.net octokit.net@noreply.github.com\nCc: Drew Johnson Drew.Johnson@microsoft.com; Author author@noreply.github.com\nSubject: Re: [octokit/octokit.net] Event types not covered by EventInfo API appearing in event stream, causing argument exception (#1502)\nEvidently th new reviews stuff has added some new event types to this API (and probably to webhooks as well)\nI think it's hard to track this sort of thing with a concrete enum as we don't want to break everytime an upstream event type gets added. Yet making it a string loses some niceties as well.\nI'd propose we could shoot for a best of both worlds approach involving\n-   have an Unknown enum member and catch any failed deserialization so this value can be used rather than failing\n-   add a BlahText property to always provide what the actual returned value was\nThoughts?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/octokit/octokit.net/issues/1502#issuecomment-260064660, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AFY0NVhaVhFkkI_WUYesi2O2EvwxwUpjks5q9ORfgaJpZM4KwJtu.\n. There is always the trouble of a partner reusing a synthetic value (ie: 'unknown'). unknown is probably sufficient, but more descriptive naming may lessen the risk.\nAn additional positive of more descriptive naming is that an external developer seeing the event type will know that this is an artifact of the octokit library as opposed to something odd with the REST api. octokit_unsupported_type or simply octokit_unsupported might be an alternative.\nThat said, thank you, @maddin2016. This will be a useful feature for our team.. Hey, folks. Any more thought on this\u00a0PR? We\u00a0are seeing more issues of the kind\u00a0noted above in the original issue.. This looks like another iteration of 'X event type was not found, so Octokit crashes.'. ",
    "strich": "Hey folks. Can I get a summary or where we're at on this? I may be interested in helping out.\n. I'm not sure I understand. It would be good if this Next project was at least setup to whatever standard the others are - I have no idea what requirements you have around your build processes, etc. Maybe you could prepare the project, even if it is broken, so people can more readily refactor code?\n. Unfortunately I do not know enough about VS projects to figure out how to include the Octokit files in the Next project by reference - IE not copied - and still be able to build and view the project as if it were a normal VS project.\n. ",
    "DamianEdwards": "@shiftkey hello sir! Are you currently working on this? Are you moving straight to the new CSPROJ project format as you go (meaning you'll need >=VS2017 RC or latest dotnet CLI builds)?\nAlso, please note you should drop your reference to Microsoft.Net.Http and instead just depend on NETStandard.Library which brings in System.Net.Http. The Microsoft.Net.Http package is hella old now and won't be moved into the shiny .NET Standard world.. ",
    "bmd-benita": "@shiftkey  The file itself. \nI have tracked .dat, .dat.gz, .xml, .dll for Git LFS. I want to get these files (download the files) to my local computer from the application using Octokit. \n. ",
    "rquackenbush": "Any update on this? I'm interested in doing the same thing.. Thanks! I hadn't noticed the .Git member.. ",
    "wwwlicious": "@gep13 There is nothing I'm aware of, I do commit using a few email addresses across a few machines and apps so things aren't always consistent, but my main account email is private and have two-factor auth enabled if that makes any difference?\nGuess I'm just a :snowflake: lol\n. No they aren't\n[Edit] I've just added maclean email to my profile, does this fix the link to my profile?\n. ",
    "markrendle": "If it helps, my commit and push was done using the GitHub desktop client for Windows, which is the only thing that works with the corporate network I was on.\nGoing into Options shows that I do have name and email set though.\n. Ah, but email somehow got set to one I didn't have in my Profile, an omission I have now rectified; alas, too late to make it into Gary's blog post.\n. ",
    "adamhathcock": "I'm sure my email is the same issue because I did fixes at work with git instead of home.  I'll fix my profile.  Thanks!\n. ",
    "BigAlInTheHouse": "Get in contact with me when you're ready thks\nOn Aug 4, 2016 11:40 PM, \"Brendan Forster\" notifications@github.com wrote:\n\n@ryangribble https://github.com/ryangribble added to my list\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/1437#issuecomment-237753446,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AHT9JcS7AHraiC8uOvi9-U5JBrgTIexIks5qcr6YgaJpZM4JcXjT\n.\n. existen datos ahora.\n\nALG Services\nOn Dec 12, 2016 7:52 AM, \"Ryan Gribble\" notifications@github.com wrote:\n\nAs per this blog anouncement\nhttps://developer.github.com/v3/repos/branches/#update-branch-protection\nthe ProtectedBranches API has a new required_pull_request_reviews object\n-\nOn the existing UpdateBranchProtection method (add to our\n   BranchProtectionSettingsUpdate request object, which will require a\n   few ctors to be added to cater for the different combinations of the 3\n   fields being provided/not provided)\n   -\nReturned by the existing GetBranchProtection method (add to our\n   BranchProtectionSettings response object)\n   -\nOn new methods to Get\n   https://developer.github.com/v3/repos/branches/#get-pull-request-review-enforcement-of-protected-branch,\n   Update\n   https://developer.github.com/v3/repos/branches/#update-pull-request-review-enforcement-of-protected-branch,\n   Remove\n   https://developer.github.com/v3/repos/branches/#remove-pull-request-review-enforcement-of-protected-branch\n   the required review enforcement\n   - GET /repos/:owner/:repo/branches/:branch/protection/required_\n      pull_request_reviews\n      - PATCH /repos/:owner/:repo/branches/:branch/protection/required_\n      pull_request_reviews\n      - DELETE /repos/:owner/:repo/branches/:branch/protection/required_\n      pull_request_reviews\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/1512, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AHT9JR2bogRk_V-YxTRgGfH2WI5lhKClks5rHVGzgaJpZM4LKkUR\n.\n. +namespace\n. What should you need me do?\n. \n",
    "martinnormark": "I do have push access. The token I'm using is a Personal Access Token - perhaps that is not enough?\n. Doh, I messed up the permissions so in fact the user didn't have push access to the repo. Thanks for your input.\n. ",
    "aetos382": "Please test this.\n``` csharp\nvar client = new GitHubClient(new ProductHeaderValue(\"SearchCodeSample\"));\nvar searchCodeRequest = new SearchCodeRequest\n{\n    Language = Language.CSharp\n};\nsearchCodeRequest.Repos.Add(\"octokit/octokit.net\");\n// generated URL: \"https://api.github.com/search/code?page=1&per_page=100&order=desc&q=language:C#+repo:octokit/octokit.net\"\n// expected URL : \"https://api.github.com/search/code?page=1&per_page=100&order=desc&q=language:CSharp+repo:octokit/octokit.net\"\nvar result = client.Search.SearchCode(searchCodeRequest).Result;\n```\nPlease find the entire code.\n. ",
    "Abdelkrim": "Dear @shiftkey , as you can see, the credentials are present.\nI have used the 'token authentication' mechanism as you can see on the screenshot.\nQUESTION1: The Login is equal to 'null', is it the expected behaviour? \nQUESTION2: From that point, how could I get the login of the authenticated user?\nINFO: here is the deployed app, note that my issues' list is empty; you might have a different result: https://githubstratex.azurewebsites.net\n\n. Dear @shiftkey  this is correct, I can read the issues of the registered user now!\nMany thanks!\n. ",
    "terrajobst": "Here is how I see this:\n- When deciding on guidelines, consistency trumps virtually everything else. Developers don't just use one component of .NET, they use a ton of .NET components. So even if an entire component is exclusively async, staying consistent with other components that offer both async and sync APIs helps. It also helps in code reviews because calling a method that is suffixed with Async but is not awaited is almost always a bug.\n- We do not perform breaking changes. Sometimes, guidelines come to be after a given API has shipped. That's unfortunate, which is why we have a special support group at Microsoft where we can cry, pet each other's back and drink hoppy beverages to deal with it. But that's how the cookie crumbles.\nSo consistency is important, but breaking people's code just because it doesn't meet certain guidelines is silly and directly interferes with the reason we have guidelines in the first place: making our customers successful. Of course, you could offer additional overloads that are properly named but then your component uses both naming conventions and code base will most likely ending up with calling a mixture. In my opinion, that's even worse because now the async suffix means nothing in Octokit.\nSo I'd be in favor of closing as won't fix.\n/cc @stephentoub\n. @dotMorten \n\nThat also takes care of @terrajobst's worry that we'll have a mix of coding patterns throughout the code. That's quickly taken care off by cleaning up the build warnings.\n\nI'm not an expert in Octokit, but it sounds to me as if this would mean virtually marking all methods as obsolete, which will have significant impact on the consumers. That still seems excessive to me.\n. ",
    "dotMorten": "The main reason I suggested this was that when starting with the API this completely throw me off. I knew what I wanted had to be async, but I couldn't find any async methods. It's also really inconvenient not instantly knowing you need to put await in front of some code, but have to go look at the signature.\nAs @terrajobst said this is why coding guidelines are important and when working with multiple libraries it can really throw off a developer.\n@shana I don't think the reasons you present are correct (it sounds more like rumors and doesn't really fit with other things that were in .NET before Tasks - take a look at what they did to WebClient for instance). It's just as much about readability, eases code-reviews etc. Just because we have async/await doesn't mean multithreading problems gets any easier (besides the less code needed), and it's nice when the code explicitly calls out that there's context switching, it's non-blocking, likely long-running etc.\nRegarding @paulcbetts's comment:\n\nBreaks literally every piece of software written using Octokit, for literally zero tangible benefits to users of the library\n\nNo. Consistency, predictability and readability of an API is not zero benefit. Secondly as I mentioned, when you provide the new overloads, you mark the old ones obsolete, and hide them from intellisense. That means you won't see the old overloads clouding up intellisense, they'll still work and users gets warnings telling them to move to the new ones. That also takes care of @terrajobst's worry that we'll have a mix of coding patterns throughout the code. That's quickly taken care off by cleaning up the build warnings.\n. That's fair. I knew it was a longshot to begin with, but my OCD just couldn't handle it \ud83d\ude00 \n. @shiftkey Task has been around since 4.0 / 2010 \ud83d\ude1c \n. > This .NET Framework 4.5 library and it doesn't have any legacy API that uses obsolete asynchronous programming pattern\nI don't see how that has anything to do with following the common .NET coding patterns for Task-returning methods, and it is completely ignoring the arguments for postfixing with async that has been stated above that has nothing to do with any legacy .NET.\nI get the argument that at this point you don't want to change your naming mistake - the ship has sailed and it is what it is..\nHowever I don't see how any other of the arguments presented in the entire thread against fixing the naming are valid. Those are all rooted in \"I just don't like it\", but that's the beauty of coding guidelines: They don't care :-)\n. No worries. \nIf you do change your mind, I have a code analyzer that'll auto-fix it in one big swoop. I could probably even tweak it a little to keep the old ones and mark them hidden and obsolete, so it would avoid the breaking changes.\n. @peteraritchie The API style should follow common .net conventions. It's a huge mistake to have different APIs that you use together use different API styles. If this is the \"API style\" for octokit, let me be frank and say it uses the wrong style. Octokit isn't the only API one codes against in an app. But if you're fine with that, so be it.\n\nThe point isn't to delineate asynchronous methods, it's too delineate deviations from the established api style.\n\nSorry. But no. \n. ",
    "grokys": "While do I see @dotMorten's point, and I'm a great believer in following style guidelines, I think @terrajobst put it best, in that not making breaking changes is more important. I certainly don't relish going through my codebases adding Async to the end of each call, and I imagine that for really heavy users of octokit this would be a real burden.\nSo yeah, @dotMorten has a good point, but the ship has sailed on this I think.\n. \ud83d\udc4d This is something we need over at github/VisualStudio as well.. ",
    "peteraritchie": "I think @Shana said it very succinctly. To prefix all methods (or even a majority) with Async is just rote, it misses the point of the convention. The point isn't to delineate asynchronous methods, it's too delineate deviations from the established api style. The established api style being either synchronous or asynchronous. Given an api with an asynchronous style, the convention should be the other way. For the deviating methods to be suffixed with Sync.\n. ",
    "aaronhoffman": "I'll need to double check. I believe that was the exception and stack trace I was seeing, but I agree that the .ToList() should not return null.\n. ",
    "tang-jason": "@shiftkey Yes, I think so. How do I get the 5,000 requests per hour? Sorry, totally new to this. \n. @shiftkey Thanks so much for the link. Looking at the OAuth setup, I am not sure what to put in the Homepage URL and Authorization callback URL since this console application will/might be running in the VM and triggered by task scheduler. \n. @shiftkey Looks like PAT will do. I got what I needed. Thanks for the pointers and help! Very appreciated. :+1: \n. Awesome! Thanks for the update @ryangribble  \ud83d\udc4d \n. @ryangribble  Isn't the StargazersCount referring to \"Star\". Take octokit for example, it has \n\nWatch: 123 \nStar: 1052 \nFork: 531\n\n\"Watch\" is the one I am looking for. \n. ",
    "malamour-work": "Hi @ryangribble \nThanks for your time and for the review. I did the modification you have requested.\n. Hi @ryangribble \nI have obsoleted the old ApiUrls.Organizations() and created the integration tests like you requested.\nIf anything else let me know.\nThanks\n. ",
    "markwilkie": "I found an additional problem when adding an issue card to a project column using projectCardsClient.Create.  GitHub wants the word 'Issue', not 'issue' for context-type.  (https://developer.github.com/v3/projects/cards/#create-a-project-card)  However, in EnumExtensions, it ToLowers the property.  I'm not 100% sure the ramifications, so I'm not submitting a fix.  However, I can confirm that when I remove the ToLower, I can add a card.. ",
    "StanleyGoldman": "Done\n. Hmm, I might need some help understanding why the integration tests fail.\nI supplied a username, organization, and token in Octokit.Tests.Integration.Helper and the rest seemed to work for me.\n. Hey @shiftkey I didn't see the Slow Tests documentation, I will definitely give it a try tonight.\nIt's just odd because I did what I feel was an equivalent locally, which passed during tests.\nI'll let you know how it goes.\n. @shiftkey Good to go.\n. For sure, I was playing with the branch a few days ago.\nWill update today.. I also just realized I was playing with check-runs which is based on this.\nI have a few comments there for when you create that pull request.. I'm still dogfooding these.\nThe documentation on these APIs kind of leave me a bit confused.\nSo yea, I need to actually test them all in order to understand what data they are really getting.. I'm noticing a nuanced difference in the way some responses are delivered that is throwing this off..\nhttps://developer.github.com/v3/apps/installations/#response\n\nhttps://developer.github.com/v3/repos/#response\n\n. cc: @shiftkey \u261d\ufe0f . Nvm, I learned things today.... Yea, I was just mentally unprepared for things to be different between api calls like that.. First off, sorry about my sloppiness, I was rushing so I can go and dogfood this. Thanks for reviewing.\n\nI'm gonna start up a new pull request that targets this one, and I'll go through all of the GitHub Apps docs and make sure they are correct and link out correctly.\nThe ForCurrent moniker resonates better with me for some reason. I'll also wait for \u261d\ufe0f to make sure they are consistent.\nI'll make sure the docs I add have relevant links to the auth pages in the api.\nAre there any other undocumented patters I should be looking for? \ud83d\ude3c \n\n. I was gonna send the latest changes in a separate pull request, but then i got lazy.. Your changes so far get a \ud83d\udc4d from me.. Ah my bad, I was not aware of the nuance.. All looks good here! \ud83d\udc4d . So far I'm having issues using coverlet to generate coverage. Opened an issue with them: https://github.com/tonerdo/coverlet/issues/188. Hey @ryangribble. Yea, I've just been on a code coverage spree lately.\nI got coverlet and codecov working with https://github.com/octokit/octokit.graphql.net and https://github.com/justaprogrammer/MSBuildLogOctokitChecker\nI'm using OpenCover and codecov for https://github.com/github/VisualStudio\nI'm just having trouble with coverlet and this project, so hopefully they can help me out.. Also, wouldn't you have to get a license of dotcover for this?. That is quite possible... Okay. Well I don't know how to feel about code coverage tools. I can't find a comparison of dotCover vs other similar tools, but I did manage to get coverlet operational thanks to help from some of their users. We can use another tool in it's place as they all support a common output format.\nNow i'm struggling with codecov.io. I have it integrated but I can't seem to get their report uploader to work correctly.. @ryangribble I logged some issues for remaining work, but I think this is good to merge.. @ryangribble I've also been MIA on this, so it's not just you.\nI'll update the PR and dependencies used.\nAnd yea, we'll have to find out some more information regarding PDB types.\n. \ud83d\udc4b Hi @ziranquliu I'm going to assume you pushed this by accident.. \n. lmao, fastest approval ever. Missing a property for Title.. Odd, okay... ",
    "jsauvexamarin": "I've actually already begun to take it upon myself to convert the csproj files over to supporting the unified Xamarin.iOS APIs. It's mostly just matter of swapping out the project type GUIDs in the csproj's, and then referencing the new targets.\nI'm working on a fork. I should have a PR ready sometime in the next 24 hours. :)\n. I'll make sure the entire solution is buttoned up before I submit\n. @shiftkey, here's the PR: https://github.com/octokit/octokit.net/pull/1492\n. Instead of modifying the existing projects, I think I will just add two new projects that target the Xamarin unified iOS API: \n- Octokit-Xamarin.iOS\n- Octokit.Reactive-Xamarin.iOS\nI'll submit a PR soon when it's ready.\n. Correct. I'll submit a new one.\n. ",
    "Ygilany": "@jsauvexamarin were you able to fix this? I'd really appreciate it if you would point me to a solution or even a workaround for this.. ",
    "pjc0247": "@shiftkey But.. I think there's no API which can handle optional parameters in /repos/:owner/:repo/issues/comments.\nIssue.Comment.GetAllForRepository\nPullRequest.Comment.GetAllForRepository\nThanks\n. @ryangribble finally understood. they already have 2 parameters which contain pagenation data....\nsorry for messy commits.. Ah... thanks.. @ryangribble sry, I'm not famillar with unit testing. I'll make a fix.. ",
    "goateey": "The authenticated user is Site admin and owner of all orgs.. Github version is 2.6.9.... it worked before migrating from 2.4.3\n. The below curl gets me what i want but how can this be achieved via Octokit ?\ncurl -u username:password https://github.MyCompany.com/api/v3/teams//repos -k\n. @ryangribble  - thanks that worked.\nwe migrated recently from 2.4.3 to 2.6.9 and the contractor who was working on this task had his contract ended. So been pulled on to this task... \nThanks a lot for the help... appreciate it!\n. ",
    "ivandrofly": "Updated /cc @shiftkey | @ryangribble \nHmm... looks like some changes are required in ObservableDeploymentStatusClient.cs too... WIP.\n. > did you actually run into a situation where exceptions were being thrown by these extension methods?\nNope, just trying to be consistent with methods present inside StringExtensions.cs :). Deployment is already aligned with API docs\n. Broken!!!\n. Sure ;)\n. ",
    "l1salvatore": "Sorry, but how access to commits and files of pullrequest? I only access with PullRequest.commits and PullRequest.files.\nEDIT: Oh , y can access with the number . Thanks :) . For num As Integer = 1 To _searchRepositoryResultList.Count Step 1\n            Dim _PullRequests = Await github.Repository.PullRequest.GetAllForRepository(_searchRepositoryResultList.Item(num).Items(0).Id)\n            For Each pull As Octokit.PullRequest In _PullRequests\n                Dim PullRequestCommits = Await github.Repository.PullRequest.Commits(_searchRepositoryResultList.Item(num).Items(0).Id, pull.Number)\n                Dim PullRequestFiles = Await github.Repository.PullRequest.Files(_searchRepositoryResultList.Item(num).Items(0).Id, pull.Number)\n                Dim pullreq As New PullRequest(pull.Title + String.Format(\" #{0}\", pull.Number), pull.CreatedAt)\n                pullreq.SetDescription(pull.Body)\n                pullreq.SetLanguage(ParseLanguage(listarepos.Item(num).GetNombre))\n                pullreq.SetAuthor(pull.User.Login)\n                For Each com As PullRequestCommit In PullRequestCommits\n                    If Date.Now.Subtract(com.Commit.Committer.Date.Date).Days <= max Then\n                        Dim newcommit As New Commit(com.Sha)\n                        newcommit.SetDate(com.Commit.Committer.Date)\n                        newcommit.SetName(pull.Title)\n                        For Each f As PullRequestFile In PullRequestFiles\n                            If (Not fileNames.Contains(f.FileName)) Then\n                               If f.Changes > 0 Then\n                                    fileNames.Add(f.FileName)\n                                    fileStatus.Add(f.Status)\n                                    filePatch.Add(f.Patch)\n                                    newcommit.AddFile(f.FileName, Parse(f.Patch), ParseNumLine(f.Patch))\n                                    Debug.Print(ParseNumLine(f.Patch))\n                                End If\n                            End If\n                        Next\n                        pullreq.AddCommit(newcommit)\n                    End If\n                Next\n                listarepos.Item(num).AddPR(pullreq)\n            Next\n        Next. Sorry, i don't know how put entirely as code. I have edited the text. So i have 3 collections: All repositories of a given list, All pull request for each repository, and all files for each pull request. \nThere is a file in the collection that has as .patch the Nothing value. But the .patch is not empty, there is text.. \nSorry, i don't understand. Why gives me Nothing in the .patch field?. Reopen this issue and its possible solution and for example this content https://api.github.com/repos/Microsoft/azure-docs.ja-jp/contents/articles/virtual-machines/virtual-machines-windows-migration-classic-resource-manager.md?ref=08ba86851de2eac6f0f30e8953a8779aaa6db259 . How i do to access via Octokit? Sorry for a question in the issue thread. But in the chatroom nobody answer yet. ",
    "101shipit": "mmmh, ok can't get it working, always just returns null. Assume it's something weird with my setup and dependency injection perhaps.\nWill close this off anyway.. Actually it seems to work fine for most client requests except for when calling the search api.\nIf calling gitHubClient.Search.SearchIssues(search) for example then gitHubClient.GetLastApiInfo() is returning null\nIs this because the search api has separate rate limits from the rest of the api?. yes. ",
    "bmeverett": "Is this what you're looking for? And then should the tests be modified to use ReviewComment now?. Ok and just to be clear about the Observables. That would require changing  IObservablePullRequestReviewCommentsClient.GetComment(long repositoryId, int number) and IObservable<PullRequestReviewComment> GetComment(string owner, string name, int number) correct? \nAnd does anything need to be done with Task<PullRequestReviewComment> GetComment(string owner, string name, int number)?. I changed this in the PullRequestClient as well as the ObservablePullRequestClient Should we change it anywhere else at this time?. @ryangribble I have made the requested changes. . ",
    "aniket-aurea": "Thanks, this sounds great.\nI don't have a url as this is a private repo.\nBut I saw atleast 1 other status apart from the one mentioned in the\nticket, that gave the same exception.\nYes the problem did occur during de-serialization by Newtonsoft, as the\nEnum did not have the value.\nI have made this field string in my classes till a fix is available, and am\nusing the rest API till then.\nHope this helps.\n[image: Aurea] http://go.aurea.com/e/23432/2015-11-05/3brlh6/1191512291\nwww.aurea.com\nOn Mon, Jan 9, 2017 at 10:15 AM, Ryan Gribble notifications@github.com\nwrote:\n\nApart from adding enum values that are missing, we also have a proposal to\nhandle these at runtime here #1504\nhttps://github.com/octokit/octokit.net/pull/1504\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/octokit/octokit.net/issues/1525#issuecomment-271210733,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AVliLcx9Ybne0cy3jxmgn0dVkbU2ldd9ks5rQbuAgaJpZM4LW5fH\n.\n. \n",
    "JohnGoldsmith": "That's great.  Thanks very much @shiftkey \nI've amended based on your help as follows:\n```\nforeach (var c in contents)\n{\n    $\"\\n{c.Name} - {c.Sha}\".Dump();\n    try\n    {\n        var request = new CommitRequest()\n        {\n            Path = targetFolder,\n            Sha = targetBranch\n        };\n        var commits = await client.Repository.Commit.GetAll(owner, reponame, request);\n    foreach (var cmt in commits)\n    {\n        var commitWithFiles = await client.Repository.Commit.Get(owner, reponame, cmt.Sha); \n        foreach (var f in commitWithFiles.Files)\n        {\n            if (f.Sha == c.Sha)\n            {\n                $\"Found file {f.Sha} in commit {commitWithFiles.Sha}\".Dump();\n                $\"Commit msg - {commitWithFiles.Commit.Message}\".Dump();\n                $\"See commit - {commitWithFiles.HtmlUrl}\".Dump();\n            }\n        } \n    }\n}\ncatch (NotFoundException ex)\n{\n    ex.Dump();\n}\n\n}\n```\n...which results in the following:\n```\nMain.groovy - 55dcb458fcebd324d5344b5ac99c109ac694cc52\nFound file 55dcb458fcebd324d5344b5ac99c109ac694cc52 in commit e650f374002f860d56ecad63b6fab7387a607642\nCommit msg - Fixed a typo in a tested value of division (comment and actual didn't acgree)\nSee commit - https://github.com/githubtraining/hellogitworld/commit/e650f374002f860d56ecad63b6fab7387a607642\nSquare.groovy - fde331951be7ee45857487ffff1ff50ad8c90d7d\nFound file fde331951be7ee45857487ffff1ff50ad8c90d7d in commit dc64fe4ab8618a5be491a9fca46f1585585ea44e\nCommit msg - Refactored squaring into a separate class\nSee commit - https://github.com/githubtraining/hellogitworld/commit/dc64fe4ab8618a5be491a9fca46f1585585ea44e\nSubtract.groovy - 726e5252ccafd9d8fc661ed5ca5c665f24d4bc22\nFound file 726e5252ccafd9d8fc661ed5ca5c665f24d4bc22 in commit 3c9306fcc7c41a88a37514a1f4c8d43459eaf966\nCommit msg - Added subtract feture\nSee commit - https://github.com/githubtraining/hellogitworld/commit/3c9306fcc7c41a88a37514a1f4c8d43459eaf966\nSum.groovy - 9f221918607d78c1db3f6c6d5afa68a66b1146a8\nFound file 9f221918607d78c1db3f6c6d5afa68a66b1146a8 in commit 09b08e4b4d54a26653c847b88dfa8139826417ae\nCommit msg - Added sum function and test call\nSee commit - https://github.com/githubtraining/hellogitworld/commit/09b08e4b4d54a26653c847b88dfa8139826417ae\n```\nI see the the xml comment on Sha says 'SHA of the last commit that modified this content' if I'm reading in the right place.  Should this be 'SHA of this content blob' or does it have different uses in other places?\nAnyway, thanks again - it's a great help.\nJohn\n. Well it's helped progress my git understanding so good things have come out of it :). Hi, Have made the change in PR #1534 . My pleasure.  I glad to have helped move the project along in such a significant way.. ",
    "jparnell8839": "How would I call that? I'm not familiar with the GitHub API and/or how to read it. Am I anywhere close to the nail?\nstatic void Main(string[] args)\n{\n    var client = new GitHubClient(new ProductHeaderValue(\"my-cool-app\"));\n    var releases = client.Repository.Release.GetAll(\"octokit\",\"ocktokit.net\");\n    Console.ReadKey();\n}. Well, that was a fun bit of troubleshooting, but I got it to work... it needs await, so I had to put it in an async method. And you cannot make Main() asynchronous.\nAs well, the try...catch is there in case there are no releases and/or typos in the GetAll() method (because \"ocktokit\" doesn't have any releases, go figure)\nSo for any Google stumblers, here's the code:\n```\nusing System;\nusing Octokit;\nnamespace ConsoleApplication1\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            GetReleases();\n            Console.ReadKey();\n        }\n    static async void GetReleases()\n    {\n        try\n        {\n            var client = new GitHubClient(new ProductHeaderValue(\"my-cool-app\"));\n            var releases = await client.Repository.Release.GetAll(\"octokit\", \"octokit.net\");\n            var latest = releases[0];\n            Console.WriteLine(\n                       \"The latest release is tagged at {0} and is named {1}\",\n                       latest.TagName,\n                       latest.Name);\n        }\n        catch (Exception ex)\n        {\n            Console.WriteLine(ex.Message);\n        }\n\n    }\n}\n\n}\n```\n. @ryangribble  I did not know about the .Result call... good info to have! Asynchronous methods are something new to me.\nAnd yes, you're right, \"octokit\" has many releases. \"ocktokit\" (notice the extra k), on the other hand does not. Typos will getcha every time, and I'm glad I got one in my first testing, because while this was a simple typo, there may actually be a project that doesn't have any releases, and will throw an exception.. ",
    "YunLi1988": "Thanks @shiftkey @ryangribble for the quick response! My usage scenario is when integrating pullrequests for different repos, the numbers are no longer identical. For now I can use repo + number as the ID to differentiate them. But it would be super helpful for me to use the official id unified by github. Thanks again!. I would like to help and please let me know more.. I have send out this pull request for review. https://github.com/octokit/octokit.net/pull/1537  \nThanks a lot for your guidance. . I am not familiar with git hub. somehow I cannot find the comments I received in my email.\nOnce you are done with this one, can you assign another entrylevel task?. Got it. You did suggest long. I checked other class like issue, comment, they all using int type id. used int for consistency issue. As you mentioned we have more pullrequest than int can support already, I am going to change it to long again. \nBTW, one of the check Travis CI build failed. I tried to read the log, but did not found any intuitive information. Do you mind to share me some tips on looking at that log?. Another thing is when I run the integration test, there is an authorizationException : bad credentials been thrown. Does that mean I need to change certain credentials to run the tests or I did not set some configurations right?. Thanks for the catch. I am going to update that. I am assuming all internal ids  are larger than 0.. ",
    "SameerSawla": "Hello guys, was anybody able to get past or have a work around for limit of 50 invitations requests per 24 hour ?. ",
    "vmikeska": "Hi @ryangribble, yes, thank you very much, was exactly it!. ",
    "lynnfaraday": "@ryangribble Oh cool, thanks for fixing that.  Beat me to it :). ",
    "jennet": "Autofac in Startup.Services.cs in a standard MVC 5 app. \nCurrently in Startup I have:\n    var gitHubClient = new GitHubClient(new ProductHeaderValue(\"appname\"));\nbuilder.RegisterInstance(gitHubClient).As<IGitHubClient>();\nA user will need to login before I can get at their access token.. I should have clarified that I'm using this in conjunction with an OWIN GitHub external login provider. So depending on the logged in user there will be different credentials. Not during application start. I need to add the Credentials after it's been passed to the controller . That doesn't feel like the right thing to do here, but if you can supply code/links then I'll take a look into that approach, for sure.. I've just noticed in the GitHubClient code the comment to only use the Credentials getter/setter if you only use a single hard-coded credential. \nI'll read up on ICredentialStore.. I had a bit of a fail with ICredentialStore, but in amongst my googlings I saw this blog post which set the Credentials a slightly different way.\nBy setting the Credentials in this way (actually it's more long-winded than this for error checking but you get the idea) :\n_gitHubClient.Connection.Credentials = new Credentials(accessToken);\nmy code works fine with the GHC passed to the controller via DI and then setting the credentials based on the logged in user in the controller method.\nThis may not be best practise (given that comment on GitHubClient.Credentials) so if anyone explain how to do it correctly that would be great. For now I'll get on with other work ;-). ",
    "somewhatabstract": "I think the client is supposed to be one per credential rather than using the same one for multiple credentials. For that reason, I would expect the DI to be configured to create a new GitHubClient instance per injection request and probably, to have that require the credentials to be injected accordingly.\nIn fact, I'm not sure  it makes sense to inject an IGitHubClient directly but instead to inject your own provider object that can create clients based on credentials you give it.\ninterface IGitHubClientProvider\n{\n    IGitHubClient GetClientForUser(UserContext context);\n}\nSomething like that; then the provider can lookup the creds for the given user and provide the appropriate client back.. ",
    "ReCoDev": "They both work with small files and sometimes with larger ones (the limit seems above 10m but not much further ). ",
    "Narasimhamurthygn": "How to download the products Zip file (products are their in the Nested gitRepos) using tree ? . ",
    "guilhermecorsino": "Hi @ryangribble ! \nI've got it and I'm going to start with these alters, thank you so much.   \ud83d\udc4d\ud83d\udc4d\ud83d\udc4d. ",
    "pthivierge": "@shiftkey , below  is what I am calling.\n@ryangribble, thanks for helping out, let me know if you need more details.\npublic class PluginParams\n{\n    /// <summary>\n    /// The organization name to search for\n    /// </summary>\n    public string GitHubOwner { get; set; }\n\n    /// <summary>\n    /// Application credentials token to use to connect to GitHub\n    /// <see cref=\"https://github.com/settings/tokens\"/>\n    /// </summary>\n    public string GithubCredentialToken { get; set; }\n\n    /// <summary>\n    /// Name of the product that is using octokit\n    /// </summary>\n    public string GitHubProductName { get; set; }\n\n}\n\npublic static GitHubClient GetGitHubClient(PluginParams settings)\n{\n    var github = new GitHubClient(new ProductHeaderValue(settings.GitHubProductName));\n    github.Connection.Credentials = new Credentials(settings.GithubCredentialToken);\n    return github;\n}\n\nvar github = GitHubCommon.GetGitHubClient(settings);\n\n// Read repositories from GitHub\nvar repos = github.Repository.GetAllForOrg(settings.GitHubOwner).Result;\n\nforeach (var repo in repos)\n{\n    var targetRepoElement = GitHubCommon.FindRepositoryById(orgElement, settings, repo.Id.ToString());\n\n    // FAILS in those two methods\n    var clonesTask = github.Repository.Traffic.GetClones(repo.Id, new RepositoryTrafficRequest(TrafficDayOrWeek.Day));\n    var viewsTask = github.Repository.Traffic.GetViews(repo.Id, new RepositoryTrafficRequest(TrafficDayOrWeek.Day));`\n\n    Task.WaitAll(clonesTask, viewsTask);\n    // do stuff here\n\n}\n\n. @ryangribble, where in the code may I change the type? Maybe I can test it... :) . Thanks a lot guys! Good job :). ",
    "patriksvensson": "@ryangribble Here is an example of setting the desired version number with the new dotnet SDK (1.0.0).\ncsharp\nDotNetCorePack(project.FullPath, new DotNetCorePackSettings \n        {\n            Configuration = config,\n            OutputDirectory = \"./.artifacts\",\n            VersionSuffix = version.Suffix,\n            NoBuild = true,\n            Verbose = false,\n            ArgumentCustomization = args => args\n                .Append(\"/p:Version={0}\", version.GetSemanticVersion())\n                .Append(\"--include-symbols --include-source\") // For symbols\n        });. @ryangribble I also noticed that you do not include a NuGet.config in your build directory which you should since Cake.Frosting only exists on MyGet at the moment.\nExample here: https://github.com/cake-build/frosting/blob/develop/build/nuget.config. We were running tests on Mono for Cake under 4.5.2 before, so this should be possible. Have you considered using the xunit console runner for running the 4.5.2 tests on Mono?\nI can't remember exactly what we were doing, but we've been cross compiling for net452 and netstandard1.6 since july last year. I can take a look later when I have some free time.. Yes, assembly loading is affected. We had to remove support for things like TypeConverterAttribute in Cake when turning off AppDomains in tests.\nYou can use context.Xunit2 after importing the Cake.Common.Tools.Xunit namespace to use the xunit console runner.. Oooh, that's a nice surprise! Thanks @khellang \ud83d\ude04 . I see that there already is a PR for this (#1946) so I'm closing this one.. ",
    "guardrex": "I simply made an implementation mistake, so it didn't have value. Sorry for the bother.. ",
    "nating": "Thanks for getting back Brendan. That's unfortunate.\nWe are building a chatbot to interact with GitHub and were hoping it could scale to more than 60 queries per hour. Do you think creating a personal access key to be associated with the application so that it can have its higher rate limit would be a good idea?. Thank you all for your help. We set up a machine account for the application and are achieving our higher rate-limit.. ",
    "joensindholt": "I would very much like to look at doing a fix. I see you have a \"How to Contribute\", but if you have further information I'd like it - this being my first time ;). I'll give it a shot - thanks. Sounds fair - I'll change it.. I have reintroduced the try...catch blocks but this time only for NotFoundException. I did it in both the Add methods as requested.. Yes, I saw that but I convinced myself it wasn't due to the changes in this PR. Partly because #1571 fails the exact same way, partly because it loos like something related to .net core?. No - thank you :). ",
    "aalok05": "yes it's definitely weird. ",
    "NickCraver": "+1 on consistency, and a selfish +1 on strings (for performance reasons). I'd value consistency more overall, though.. \\o/ thanks @mderriey and @ryangribble!. \n^ the LINQPad experience :)\n. Done: PR is #1593. I didn't hit any issues with that one, so erred on the side of minimal changes as always :) Just verified on another fresh install: no issues as far as I can see.. <3. ",
    "azubanov": "Hello, shiftkey!\nYes there is no way to get license information about particular repository.\nPlease take a look at my link: https://developer.github.com/v3/licenses/#get-a-repositorys-license. Hello ryangribble!\nSounds interesting :)\nIf this issue be still active in two weeks, I'll take a look.. ",
    "gdziadkiewicz": "RepositoryId work, I have just checked them and added methods for them in code.\nI have a problem with the delete methods. According to the docs it should only return appropriate result code, but in practice it does return an object similar to the create method. Should I stick to the docs and return Task or should I return Task<PullRequest> as this is what is really returned in response?. I am investigating the pagination support in GetAll method ATM.. @ryangribble Can you check my latest changes? I've reduced the number of users and adjusted the tests. How do you feel about leaving my test user in the tests? It would be nice to have some kind of octocatPrime user for the tests.. @ryangribble LGTM \ud83d\udc4d . Hi @ryangribble Thanks for the out-of-date tip, I didn't notice it. Right now I am unable to run my integration tests due to my test account being flagged. Could you run them? I believe that the general work is done and can be reviewed.. Ok, I will change it.. Changed it and tested it.. @ryangribble I will work on it today. I was low on spare time in past few days, sorry for the delay.. @ryangribble\nI have added the missing unit tests, added and ran integration tests, but there is a problem - GetAllForSubNamespace endpoint ignores requested pagination. Do you have any idea how to handle that?. I didn't notice that this is already implemented. . I'll change it :) But in my defense: I've take it from RepositoryCollaboratorClientTests.cs and ran the test.. Inlined it.. Inlined it.. Changed it.. I've changed the method name and it's code to be like PullRequestClientTests.CreateTheWorld, but without second branch creation and with baked-in pull request creation. . Added it.. @ryangribble Sorry for the delay. The WhenAll version throws:\nSystem.NullReferenceException : Object reference not set to an instance of an object.\n   at System.Collections.Generic.Dictionary`2.Insert(TKey key, TValue value, Boolean add)\n   at Octokit.Internal.SimpleJsonSerializer.GitHubSerializerStrategy.DeserializeEnumHelper(String value, Type type)\n   at Octokit.Internal.SimpleJsonSerializer.GitHubSerializerStrategy.DeserializeObject(Object value, Type type)\n   at Octokit.PocoJsonSerializerStrategy.DeserializeObject(Object value, Type type)\n   at Octokit.Internal.SimpleJsonSerializer.GitHubSerializerStrategy.DeserializeObject(Object value, Type type)\n   at Octokit.PocoJsonSerializerStrategy.DeserializeObject(Object value, Type type)\n   at Octokit.Internal.SimpleJsonSerializer.GitHubSerializerStrategy.DeserializeObject(Object value, Type type)\n   at Octokit.SimpleJson.DeserializeObject(String json, Type type, IJsonSerializerStrategy jsonSerializerStrategy)\n   at Octokit.SimpleJson.DeserializeObject[T](String json, IJsonSerializerStrategy jsonSerializerStrategy)\n   at Octokit.Internal.SimpleJsonSerializer.Deserialize[T](String json)\n   at Octokit.Internal.JsonHttpPipeline.DeserializeResponse[T](IResponse response)\n   at Octokit.Connection.<Run>d__56`1.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.ConfiguredTaskAwaitable`1.ConfiguredTaskAwaiter.GetResult()\n   at Octokit.ApiConnection.<Post>d__22`1.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.ConfiguredTaskAwaitable`1.ConfiguredTaskAwaiter.GetResult()\n   at Octokit.RepositoriesClient.<Create>d__3.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()\n   at Octokit.Tests.Integration.Helpers.GithubClientExtensions.<CreateRepositoryContext>d__2.MoveNext() in C:\\Repos\\octokit.net\\Octokit.Tests.Integration\\Helpers\\GithubClientExtensions.cs:line 24\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()\n   at RepositoryInvitationsClientTests.TheGetAllForCurrentMethod.<ReturnsCorrectCountOfInvitationsWithStart>d__1.MoveNext() in C:\\Repos\\octokit.net\\Octokit.Tests.Integration\\Clients\\RepositoryInvitationsClientTests.cs:line 191\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task). Changed it.. Changed it.. Done.. Done.. Done.. Done.. Done.. Done.. Done.. Done.. ",
    "Victov": "This happens in one life cycle. Restarting the program after the internet connection is makes everything function perfectly again. It's a very basic console application that takes some data from github and interprets it for some data analytics purpose. It all works perfectly fine when the internet connection is never interupted.\nThe problem seems to be an AuthorizationException. I tried setting the credentials again when connection was restored, but that did not fix the problem. \nI also tried re-creating the entire GithubClient object when internet connection was restored, but that also did not fix the problem. See the attached screenshot.\n\n. Nevermind, a unit test I had written was interfering and changed the API key. There's nothing wrong.... ",
    "karelz": "FYI: I have validated the changes on all dotnet/Roslyn repo. All 3 cases I hit there (https://github.com/octokit/octokit.net/issues/1594#issuecomment-297652513) were addressed by this list.. And RemovedFromProject event -- dotnet/roslyn issue 35, after local fix to address AddedToProject ...\nI like your idea to not hardcoding all events, make the list more resilient ... but of course I know near 0 about Octokit.net design ;). Thanks for the link to the PR. I just hit 'MovedColumnsInProject' ... I will grab the list from the PR ;). Great, thanks!\nOut of curiosity: What is cadence for your NuGet alpha releases? Last nuget.org alpha build is from January. I'd like to know when I can stop using the project-to-project reference. Not a high pri ... but would be nice.\nIf there is anything I can help with to release new alpha version, please let me know. If it is not over my head or super-costly, I will be happy to help.. ok, I'll use the AppVeyor CI feed (I think I already added it anyway, then I realized it is not fixed either there yet ;-) - I just forgot about it ...)\nThanks!. ",
    "EmpireWorld": "So what should i do?\nDo i use GitHub HTTP API?. ",
    "philschatz": "Thanks for taking a look into it!\n/cc @SleepyBandit so they can track the progress of this issue. ",
    "SleepyBandit": "I will confirm, this is fixed for me. Github support had me test it this morning and it worked for 3 different files of differing sizes above the 700KB threshold I was having issues with when it occurred.. ",
    "PavelBansky": "@shiftkey I'm looking at this:\nhttps://developer.github.com/v3/pulls/reviews/#create-a-pull-request-review\nSpecifically:\ncomments | array of draft review comment objects\nI would like to submit several pull request comments/review comments in batch. I don't want to trigger pull request comment event after every single comment, but rather when I'm done commenting.. ",
    "suchja": "I see. I couldn't find any documentation about this. In case I can be of any help (meaning I would help to create some more documentation or fix existing) please point me to the proper process. . ",
    "aqwert": "thanks, I will see what I can do but it won't be for a while... off on holiday for a couple of weeks from tomorrow.. I will look at this tomorrow. Sorry for the delay. ",
    "nolanblew": "I'm out till July 10th, so if someone wants to take it before then be my guest!. @Sarmad93 Sorry I misread your question - yes go ahead and take it!. @Sarmad93 Any progress updates with the branch?. ",
    "hartra344": "Sorry I noticed this hadn't had any traction in almost a month and started working on it yesterday for my own uses. I started a PR, only really need to finish writing integration tests. Will likely add more integration tests . @ryangribble I think I got everything you requested. Also it seems Travis-CI might be having some issues that are unrelated to my commits.. Think I got everything. @ryangribble should already be on :) \n\n. Ready to ship? \ud83d\ude03\n\n. Thanks for taking the extra look at the integration tests. I had run into the same issues you mentioned when trying to create them and then completely forgot to come back to it. Took a look at your changes though everything LGTM \ud83d\ude04 . ok I was mostly going off the API docs which showed pagination support in the response\n\n. Just realized I did this in the wrong file. Will do it in right file and leave this here for now since you said you're standardizing on it anyway. ",
    "ctolkien": "Is there an issue with making the Config protected set ? That would allow this descendent class to make changes to the config without needing to create a new instance.. @ryangribble  - I'll put together a PR, can review from there.. @ryangribble  - care to review https://github.com/octokit/octokit.net/pull/1623 ?. @ryangribble  - Off the top of my head, I'm not sure of the behaviour of the Linq bits there.\nLet me write some more tests for that scenario.. @ryangribble - you're right in that subsequent ToRequests throw in that there is a check in place for existing entries in config...\nTwo options, we can modify the original code to include the Events and Active properties:\ncsharp\nreturn new NewRepositoryHook(Name, config)\n{\n    Active = Active,\n    Events = Events\n};\nThis is less invasive, but I feel is brittle. If there are new properties are added then we need to also add them to this list...\nThe other option is to have the explicit NewRepositoryWebHook properties override any of the matching properties that were explicitly passed into config.\ncsharp\nvar config = new Dictionary<string, string>\n{\n    { \"url\" = \"http://urlpassedinconfig.com\" }\n};\nvar hook = new NewRepositoryWebHook(\"web\", config, \"http://urlpassedtowebhook.com\");\nvar request = create.ToRequest();\nAssert.Equal(request.Config[\"url\"], \"http://urlpassedtowebhook.com\");\nIn this case, it would use http://urlpassedtowebhook.com;\nI prefer the latter. In this case we would remove the check for duplicate properties.\n. @ryangribble  - FYI, I've updated this PR to reflect the latter option outlined above.. Looks like it.... Removing that line.. ",
    "PoLaKoSz": "Oh, I see GitHub API v3: /Users/Octokit/Repos/.\n\"stargazers_count\": 1307,\n    \"watchers_count\": 1307,\n    \"watchers\": 1307,\nIn fact:\n\nThanks anyway.. ",
    "dvdstelt": "Possible, but at the very least update doco?! :). I'm okay to close this then, btw.. I will @ryangribble, very busy atm cleaning up work before I go on holiday. Can this stay open for a short while longer? I might do it while on vacation. :-). ",
    "jozefizso": "I will take a look at it.. This is my take on implementing IRepositoriesClient.GetLicenseContents()\nIt fixes the LicenseMetadata to include new attributes returned by GitHub.\nGetting Repository will include the license information ~~- this may be a breaking change, as I changed the API Preview header.~~ - the API supports Squash Commit and License preview headers.\n. GitHub API supports multiple preview values in the Accept header separated by comma, or the API may send multiple Accept headers.\nI tried this scenario, because to implement #1707 the client will need to indicate is supports License Preview and Topics Preview API.\nI left the Squash Commit Preview, because I was not sure it is still required.. Sure, I can concat it. I opted for non-elegant but more performant code, because it's compiled constant now.. The Concat() method looks good.. @ryangribble anything else I should fix here?. I put License Preview API header to more RepositoryClient calls. I did not add it to Create() method because it had no effect there. License is updated with delay after the repository is created (with AutoInit=true) and GitHub will not report the license immediately.. Sorry, I don't have time now to implement ObservableRepositoriesClient.. Yes, maintainers can update this pull request.. Is this being working on? Do you need help with getting this implementation done?. sure. I think I will have time to implement this one.. Added the header to observable client. I hope I didn't miss come calls.. It looks good. I've fixed the documentation a bit.. I think I implemented all requested changes.. I will look at it. Give me few days.. I introduced this specifically for the IsALukeWarmObservable tests, because these tests already does not care about the actual URI. I think it makes this test more readable and maintainable.\nIf Accept headers are correct is tested in different set of tests which are specialized for this.. sure. Ok, I will use AnyAcceptHeaders in observable tests.. Moved to IObservableTeamsClient. I tried to fix other comments as well in the file.. ",
    "Korporal": "OK I found a way, NP.. @ryangribble - Hi, I would but having confusing problems, see ticket 1642.. Here's more detail\nThe code below is simply experimental\npublic void OnNext(Repository value)\n        {\n            var c = client.Commit.Get(id, commit+\"777\").Result;\n        }\nwithout the \"777\" appended it works, I get a real commit object back and its valid. When I append the \"777\" to force the reference to be a non-existent reference, it simply hangs, the .Result never materializes.\n. @shiftkey - Hi, thanks that's very helpful and works (although I actually get an AggregateExcedption but the inner exception is indeed NotFoundException).. @shiftkey - I'll try to get around to this later today. But Github confirmed that being able to see a commit that's only on a fork using a URL that targets the upstream is expected behaviour - at the browser/URL level anyway.\nI am forming the opinion that forks are nothing more than \"virtual views\" of a repo, for the forks made by John and Mary, all existing branches get cloned as (for example) Mary.master and John.master. Then Mary and John when perusing their forks are actually simply seeing their own branches but with the name prefix stripped away.\nSo there really is only one repo and the appearance of forks as distinct repos is illusory, but this is just what I think I don't know for certain.. @shiftkey - Here, I just forked the Octokit repo and then manually added a simple commit to my \"master\" branch, however using this URL:\nhttps://github.com/octokit/octokit.net/commit/550c9d405c24c162d43d20b1363b3c5b5fea30af\nIt appears that it's \"in\" the base repo, the one from which I forked ! Additionally the page gives no indication that the commit is really only on a persons fork.\nClicking \"Browse files\" gives me this page:\nhttps://github.com/octokit/octokit.net/tree/550c9d405c24c162d43d20b1363b3c5b5fea30af\nThe API calls I am making share this behavior.\nIncidentally I use the same personal credentials when testing my code as I use to login here (for time being anyway).\nI'm hoping there's a programmatic way to get a \"no\" to the question \"Is this commit (550C9D40) in the upstream repo?\".\n. @shiftkey - Hi, well I'll consider what you suggested. But in my case I don't care about branches as such. I want to reliably know if the commit is anywhere within the main (which I call \"principal\") repo or in a fork of that repo. The behavior is counter-intuitive I think and it would be neat of Github would think about this and perhaps add a new API endpoint or option.. Looking forward to leveraging this, I'm just at the earliest stages of planning a GitHub App so this PR is very timely. May I suggest also that adding even a small amount of documentation about this could prove very helpful.. @ryangribble - This is EXACTLY what I wanted and works like a dream!!\nNow (of course) I have another question. If I want to know if the tip of some branch (a commit) is definitely present (merged into) some other like \"master\", is that easy too?\n. @ryangribble - You're right and I do simply want to know if all of the branches commits are on master.\nThx\n. @shiftkey - Hi,\nIm seeing compare results that have non-zero for BehindBy - yet the collection \"Commits\" is always empty, as is \"Files\", is this expected? \nIf I see AheadBy as non-zero these collections are populated....\n. @ryangribble - Yes, \"diffing\" in reverse is an interesting suggestion, I'll certainly play with that and try to update this issue with what I find.\n. @ryangribble Hi, imagine two branches that initially point at some common commit \"root\" then one one branch I add a file X1.txt and commit while on the other branch I add a file X2.txt and commit.\nNow the compare between these two branches will show AheadBy = 1 and BehindBy = 1.\nThe files list will be X1.txt and X2.txt - this is current behavior.\nHowever the file X1.txt appears ONLY on the first branch and the file X2.txt appears ONLY on the second branch.\nThat's what I'm seeking and I think I can get this from the common ancestor.\nMy motive here is to see what would be impacted if I were to merge one branch into another, by which I mean if I were to merge branch A into branch B, what on branch B would be impacted by such a merge.\nClearly only files modified on branch A would be impacted by such a merge, files modified on branch B that were not modified in branch A would not be impacted (by the merge).\n. @ryangribble - Hi,\nThe goal here (which is really what this is about) is to answer the following question:\nWhat files/folders would be changed in branch X if we were to merge branch Y into it.\nNothing in branch X can influence the answer to this question. Branch X may contain several changes to some file, but if that file is not touched by branch Y then that file will not be impacted by a merge of Y into X.\nThe motive for the question itself is to enable us to try to answer another question like this:\nIf we merge branch Y into branch X would that invalidate the (time consuming QA) testing of the apps we just did for the project represented by branch X? if so which apps would it invalidate?\n. @ryangribble - Hi.\nIt did spontaneously resume around an hour or so later, I was going to mention this here but now that I see your remark I wanted to add more detail for you.\nSmartgit was impacted (but oddly a coworker had no issue, perhaps his Smartgit is setup differently).\nThe experiment app I was working on has this Nuget package defintion:\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<packages>\n  <package id=\"Octokit\" version=\"0.28.0\" targetFramework=\"net45\" />\n</packages>\nIt is a .Net console app created in Visual Studio 2017.\nThe first three lines of code that do anything with Git are:\n```\n var client = new GitHubClient(new ProductHeaderValue(\"myappname\"));\n client.Credentials = new Credentials(\"myuserid\", ConfigurationManager.AppSettings[\"Password\"]);\n var repo = client.Repository.Get(\"myorg\", \"myrepo\").Result;\n```\nIt was that last line above that was executing when the exception was thrown.\nThe console app's target framework is .Net 4.5\nDo you guys think that Octokit users may have problems once we hit the 22nd Feb?\n(PS I'm the same user I just have two accounts a normal one and an admin one we use for managing our company repos).\n. @ptoomey3 @ryangribble - Hi,\nI've never even heard of this Git credentials manager! So far as I'm aware I do not have this installed.\nMaybe this is something used by MS tools (e.g. Visual Studio) that need to manage access to Git?\n. @Haacked - Hi,\nIs it the case that an app which simply performs this during its startup:\nServicePointManager.SecurityProtocol = SecurityProtocolType.Tls12;\nWill thereafter automatically uses TLS 1.2 whenever it makes outbound SSL connection requests?\nThx. Many thanks @ryangribble this is much appreciated!\n. @ryangribble @shiftkey Hi,\nI got this reply from Github:\nHi Korporal,\nThanks for reaching out. That's an interesting question -- I think there are two ways to do that currently:\n1) create a pull request and then fetch the pull request via the API: https://developer.github.com/v3/pulls/#get-a-single-pull-request. The \"mergeable\" field will tell you if the pull request can be merged without conflicts (i.e. whether the two branches are mergeable in Git without conflicts)\n2) create a temporary branch pointing at the same commit as the base branch (e.g. via https://developer.github.com/v3/git/refs/#create-a-reference) and then merge the head into the temporary branch via https://developer.github.com/v3/repos/merging/#perform-a-merge. If the merge succeeds -- then there were no conflicts. If the merge fails -- there were conflicts.\nThere's no endpoint specifically for the purpose you described as \"to see if a pull request were created, would there be merge conflicts\". \nHope this helps.\nBest,\nIvan\n====================\nIs the merge operation described above in 2.) , supported by Octokit?\nThx. @ryangribble - Thanks, I'll probably write some kind of support stuff and perhaps share it here if I think its decent!. @Dorky106 the await keyword 'returns' the IEnumerable after the asynchronous operation (represented by the task) completes. When execution first hits the await operation, the task gets started and your code actually returns at that point, to its caller. When the operation completes the system causes the next line after await to execute, usually on the same thread that began the operation.. @Dorky106 - For an initial test kind of thing you can do (as I have when playing around) use:\nvar releases = client.Repository.Release.GetAll(\"Dorky106\", \"BetterTrees\").Result;\nThat will synchronously (as they refer to it) wait inside the 'Result' property and your code will behave more intuitively but it will still take the same time. There's no asynchronous code then and it's a bit easier to fathom when experimenting.\nIf the call is taking 10 minutes then is that unreasonable? I strongly suspect that the delay will be at GitHub themselves rather than Octokit. Are you unwittingly pulling a large volume of data?\nI've experienced rather lengthy delays myself on some things like getting all branches that meet some compare condition with another branch, that requires a compare operation on each branch and these seem to take some time. (like 45 seconds for like 30 odd branches).\nAlso note - I can see that GetAll( ) has overloads which take a ApiOptions object, seems you can get the data back as a number of \"pages\" and specify the size of each page. This may enable you to get say a few back at a time and display these or whatever as the results come back rather than waiting and doing nothing while the whole set is transferred.\nOut of curiosity, how many items are returned for these lengthy operations?\nYou could write some helper code that encapsulates that paging and perhaps uses a page size of say 20 yet yield return each item one at a time. This way the caller would see what seems like a continuous set of results but in reality they are being pulled 20 at a time in quick succession.\nPerhaps Octokit itself already provides a \"paging-set to IEnumerable\" helper somewhere...\n. @shiftkey @ryangribble - Hi,\nI was curious about how I'd implement an alternative \"GetAll\" into Octokit, I can see it's defined deep down as a member of the IApiConnectionclass. What I was curious about is implementing an alternative that returnsIEnumerable<T> and under the hood uses pagination to get pages \"on demand\", this is a pattern I've used before with other REST services.\nIn that pattern I simply get the first page, then do something like this:\n```\npage = GetFirstPage();\nwhile (page.ItemsRemaining)\n{\n   foreach (item in page)\n    {\n       yield return item;\n    }\npage = GetNextPage();\n}\n```\nI'm sure you get the idea, the big question I have for you is how to introduce this without breaking existing consumers of the interface IApiConnection.\nThis patterns only goes to the network to get more items as and when the caller is enumerating items and there are no more items left in the \"current\" page. So if caller was enumerating something like\nGetAll(...).Where(...).First(20);\nThen only as many network calls as are necessary would be made to get the first matching 20 items and no more, this is a potentially huge saving for certain kinds of data extraction.\n. @shiftkey - OK yes, that's true - very interesting to explore options here and yes - lazy loading - is exactly the term I was seeking!\n. @shiftkey - Would the team here regard a change to IApiPagination a breaking change? The interface is public but seems to perform a purely internal role. I'm considering a small change to the definition of GetAllPagesthat could (I think) make it straightforward to introduce lazy pagination with zero changes to consumers of Octokit.\n. @ryangribble - Hi, yes you may be correct and its better to leverage IObservable than implement a lazy paging mechanism. I've not really done much with IObservable and need to devote some time to it. \nSo far as the paging goes, yes I did see ApiOptionsand was considering making start page zero (0) act as a sentinel so the underlying logic in Octokit could detect that value and then do the lazy paging, but that all depends on whether changing the signature of the method in IApiPaginationwould be regarded as a breaking change or not.\nIf that signature could be tweaked I think I have a rather neat way of adding this lazy paging while maintaining the integrity of all other existing interfaces.\nI can't imagine any scenario where a consumer of Octokit would need to ever access IApiPagination because it seems to be of purely internal significance.\nI may just play with this when I get some time and show you guys what I end up with just out of academic interest.\n. @shiftkey - Thanks for the additional info on IObservable, much appreciated. Also just to be very clear I was not suggesting any change to GetAllonly the method signature in IApiPagination, no other existing public interface or method signature would change.\nI created a system last year that used T4 templates along with a method defintion XML file to generate a client class around a REST service (which has hundreds of JSON classes and hundreds of endpoints).\nIn that design some methods in the XML get generated as TWO methods in the generated client class(es), these were paginated methods similar what I see in Octokit. When the T4 translated such a method is created a paged based conventional method where caller can enumerate the pages easily and another method (name had 'Seq' appended, an F# convention) which did something like this, internally enumerates pages and yield returns each item.\nIt's particularly useful for scenarios where the caller is doing a.First() or .Take() operation because the caller is unaware of the pagination and the system pulls only as many pages as are required to satisfy the .First() or .Take() if the caller really does want all pages \"at once\" then .ToList() gives them that.\nSo if I did spend any time here on this (and I'm more academically interested in how I'd do it than anything else) the only existing public interface that I think I'd need to change is the method signature inIApiPaginationwhich I suspects is of no interest to any Octokit consumers (I may be wrong of course).\nOn a very separate topic I'm developing a system to pull data in various ways from GitHub and I think you'd urge me to leverage the reactive version of Octokit here, is that true? If so is there anything missing from the current reactive version that's present in the ordinary version? The consumer in this case will be a .Net Core Web App by the way.\nThanks\n. @ryangribble - Hi, Yes I have asked the question on the Github forum a week ago about endpoints and GitHub app, so far no reply. I can also see that the document you guys refer to is about an OAuth App not a GitHub App so my case isn't the same. . OK I found out!. @itaibh - Just a minor simplification, this Format could be removed I think and use instead:\nreturn $\"{nameof(Token)}: {Token}, {nameof(ExpiresAt)}: {ExpiresAt}\";. I agree with Ryan, I was not intentionally suggesting we do this piecemeal, I saw some earlier PR that used this string interpolation so I assumed it was established across the project, but if it isn't I agree 100% that this should be a dedicated focused PR that changes this across the board.. ",
    "Hollywood": "I can hop on this one. @ryangribble . ",
    "devedse": "Yeah it's not much \ud83d\ude1c, but since I'm using Octokit since recently to actually create this pull request, I thought, why not optimize your repo as well ;). . ",
    "sepharg": "hi @ryangribble sure, I\u00b4ll add an integration test. As far as I\u00b4m aware that was the only missing field. @ryangribble everything good to go if you think it's all fine. @ryangribble sorry about the tests, it was pretty hard to have them running locally and I couldn\u00b4t find a way to run my test in isolation, then i saw the build green and thought it must have run ok\nanyway great collaboration, and I certainly hope to help more in the future! :). I'm using Visual Studio 2017 with Resharper. I followed the guide and tried to run the test but I had issues, next time I'll drop a message in the chat so that I can get it running locally. \nNo worries, happy to be of help and contribute to the community!. I see @ryangribble, it\u00b4s a fair point.\nThe only bad thing is that I doubt we\u00b4ll be able to include details when it\u00b4s safe to try again because the github api itself doesn\u00b4t provide enough information, it just returns a 403 and a generic message.. ",
    "kingofzeal": "I changed to use the default client, effectively doing:\nvar client = new GitHubClient(new ProductHeaderValue(\"GithubDashboard\"));\nvar reviews = await client.PullRequest.Review.GetAll(\"octokit\", \"octokit.net\", 1648);\nAnd it is still hanging.\nSpinning up a new Console Application, this doesn't seem to occur.\nI reviewed and refactored my project to be a little easier to follow - I was doing some heavy linq, including an AsParallel() call, and after removing that and refactoring to use a single thread for the heavy lifting everything seems to work, but this isn't ideal as the application would need to get branch, pull and review information from multiple repositories (which in this case can take 1-2 minutes to obtain). \nI'll see if I can find a way to replicate this issue more reliably (or determine if it's just user error).. After refactoring I can't seem to replicate the issue. \nI have a feeling it was related to how I was making the requests (via long complex awaited linq statement, which has nested awaited linq statements that I probably wasn't handling properly). I've since changed it to be a little more sensible, and everything works as expected. \nThanks for the help!. Well, I was able to re-implement the way I was trying to speed things up (using .AsParallel() on virtually every collection), but it's still taking some time - mostly because there are so many requests (one for the user, plus two per repo they have access to (branch + PR list) and one per open PR (for reviews)). \nIt would be nice if I could batch requests to the API, or if more information came back on certain calls (like having Reviews come back as part of a PR request), but until the API supports it I'll have to live with what I have.. ",
    "Huhuhuhu12345": "Wow. ",
    "sxg611": "Ok, seems like the information that is exposed doesn't fit what I need. Thanks for your help. ",
    "it19862": "@ryangribble\nIf to open in VS2017 I receive \"an output\"\nC: \\ Users \\ admin \\ Documents \\ Visual Studio 2015 \\ Projects \\ prm \\ github \\ octokit.net \\ octokit.net_Projects_prm \\ Octokit \\ Octokit.csproj: error: imported project \"C: \\ Program Files (x86) \\ Microsoft Visual Studio \\ 2017 \\ Community \\ MSBuild \\ Sdks \\ Microsoft.NET.Sdk \\ Sdk \\ Sdk.props \"was not found. Verify that the path in the  declaration is correct, and make sure that there is a file on the drive. C: \\ Users \\ admin \\ Documents \\ Visual Studio 2015 \\ Projects \\ prm \\ github \\ octokit.net \\ octokit.net_Projects_prm \\ Octokit \\ Octokit.csproj\nC: \\ Users \\ admin \\ Documents \\ Visual Studio 2015 \\ Projects \\ prm \\ github \\ octokit.net \\ octokit.net_Projects_prm \\ Octokit.Reactive \\ Octokit.Reactive.csproj: error: imported project \"C: \\ Program Files (x86) \\ Microsoft Visual Studio \\ 2017 \\ Community \\ MSBuild \\ Sdks \\ Microsoft.NET.Sdk \\ Sdk \\ Sdk.props \"was not found. Verify that the path in the  declaration is correct, and make sure that there is a file on the drive. C: \\ Users \\ admin \\ Documents \\ Visual Studio 2015 \\ Projects \\ prm \\ github \\ octokit.net \\ octokit.net_Projects_prm \\ Octokit.Reactive \\ Octokit.Reactive.csproj\nC: \\ Users \\ admin \\ Documents \\ Visual Studio 2015 \\ Projects \\ prm \\ github \\ octokit.net \\ octokit.net_Projects_prm \\ Octokit.Tests \\ Octokit.Tests.csproj: error: imported project \"C: \\ Program Files (x86) \\ Microsoft Visual Studio \\ 2017 \\ Community \\ MSBuild \\ Sdks \\ Microsoft.NET.Sdk \\ Sdk \\ Sdk.props \"was not found. Verify that the path in the  declaration is correct, and make sure that there is a file on the drive. C: \\ Users \\ admin \\ Documents \\ Visual Studio 2015 \\ Projects \\ prm \\ github \\ octokit.net \\ octokit.net_Projects_prm \\ Octokit.Tests \\ Octokit.Tests.csproj\nC: \\ Users \\ admin \\ Documents \\ Visual Studio 2015 \\ Projects \\ prm \\ github \\ octokit.net \\ octokit.net_Projects_prm \\ Octokit.Tests.Conventions \\ Octokit.Tests.Conventions.csproj: error: imported project \"C: \\ Program Files (x86) \\ Microsoft Visual Studio \\ 2017 \\ Community \\ MSBuild \\ Sdks \\ Microsoft.NET.Sdk \\ Sdk \\ Sdk.props \"was not found. Verify that the path in the  declaration is correct, and make sure that there is a file on the drive. C: \\ Users \\ admin \\ Documents \\ Visual Studio 2015 \\ Projects \\ prm \\ github \\ octokit.net \\ octokit.net_Projects_prm \\ Octokit.Tests.Conventions \\ Octokit.Tests.Conventions.csproj\nC: \\ Users \\ admin \\ Documents \\ Visual Studio 2015 \\ Projects \\ prm \\ github \\ octokit.net \\ octokit.net_Projects_prm \\ Octokit.Tests.Integration \\ Octokit.Tests.Integration.csproj: error: imported project \"C: \\ Program Files (x86) \\ Microsoft Visual Studio \\ 2017 \\ Community \\ MSBuild \\ Sdks \\ Microsoft.NET.Sdk \\ Sdk \\ Sdk.props \"was not found. Verify that the path in the  declaration is correct, and make sure that there is a file on the drive. C: \\ Users \\ admin \\ Documents \\ Visual Studio 2015 \\ Projects \\ prm \\ github \\ octokit.net \\ octokit.net_Projects_prm \\ Octokit.Tests.Integration \\ Octokit.Tests.Integration.csproj\npicture link \nQuestion.\nHow to be?. @ryangribble \nI'm sorry, I still do not understand the structure of \"github.com\".\nHow to understand the place github.com/topics/chrome-extensions\n\"Chrome extension\" is the theme in which the repositories are located?\nor\n\"Chrome extension\" - a repository in which there are nested repositories?\n\"Chrome extension\" contains 95 pieces of repositories.\nQuestion\nHow to search in the files \"README.MD\", which are located in repositories (95 pieces of repositories) in the topic \"Chrome extension\" (https://github.com/topics/chrome-extensions)?\nFor example.\nSimilar topic \"API\" (https://github.com/topics/api) contains 9039 pieces of repositories.\nPS\nSorry if the question (answer) is difficult to perceive.\nI do not know much English.\nI use - translate.google. @ryangribble  Could you show a code example.\nI try to do ... but I can't. @ryangribble \nCould you show a code example.\nI try to do ... but I can't\nvar repoLicen = client.Repository.GetLicenseContents(\"octokit\", \"octokit.net\");\nvar licen = repoLicen.li???. Changed the variable \"request\":\n- was \"var\" - became \"SearchRepositoriesRequest\";\n- was \"local\" - became \"global\";\nChanged the method \"SearchReposit (string searchQuery_str, string lang_str)\"\n- added the argument \"bool null_flg\" - became \"SearchReposit (string searchQuery_str, string lang_str, bool null_flg)\";\n- added check \"bool null_flg\";\nif (null_flg == false)\n{\nrequest = new SearchRepositoriesRequest (searchQuery_str);\n}\nThe code looks like this\n``SearchRepositoriesRequest request;\n    public async Task SearchReposit(string searchQuery_str, string lang_str, bool null_flg)\n            {\n                //SearchRepositoriesRequest request = new SearchRepositoriesRequest();\n                // \u041f\u043e\u0438\u0441\u043a \u043f\u043e \"\u0420\u0435\u043e\u0437\u0438\u0442\u0430\u0440\u0438\u044f\u043c\"\n                // if (request == null) // \u043e\u0448\u0431\n                if (null_flg == false)\n                {\n                     request = new SearchRepositoriesRequest(searchQuery_str); // mvc client side framework - \u0421\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0441\u043a\u043e\u0439 \u0441\u0442\u043e\u0440\u043e\u043d\u044b mvc         \n                    // return request; \n                }\n            switch (lang_str)\n            {\n               case \"C#\":\n                   request.Language = Language.CSharp;\n                   break;                \n            }\n\n            var resultRepo = await client.Search.SearchRepo(request);\n\n            // \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0440\u0435\u043f\u043e\u0437\u0438\u0442\u0430\u0440\u0438\u0435\u0432\n            decimal countRepo_dec = Convert.ToDecimal(resultRepo.TotalCount);\n\n            // \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0440\u0435\u043f\u043e\u0437\u0438\u0442\u0430\u0440\u0438\u0435\u0432. \u0424\u043e\u0440\u043c\u0430\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435\n            string countRepo_str = formatValue(countRepo_dec);\n\n            return countRepo_str;            \n        }\n\n\nprivate async void button1_Click(object sender, EventArgs e)\n        {\n            // \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043f\u043e\u0438\u0441\u043a\u043e\u0432\u0443\u044e \u0444\u0440\u0430\u0437\u0443\n            string searchQuery_str = Search_txB.Text;\n            string lang_str;\n            bool null_flg;\n\n\n            // \u041f\u043e\u0438\u0441\u043a \u043f\u043e \u0440\u0435\u043f\u043e\u0437\u0438\u0442\u0430\u0440\u0438\u044f\u043c. \"\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\"\n            lang_str = \"\";\n            null_flg = false;\n            var countRepo = await SearchReposit(searchQuery_str, lang_str, null_flg);\n            null_flg = true;\n\n            label5.Text = countRepo;\n\n            // \u041f\u043e\u0438\u0441\u043a \u043f\u043e \u0440\u0435\u043f\u043e\u0437\u0438\u0442\u0430\u0440\u0438\u044f\u043c. \"\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\"            \n            lang_str = \"C#\";\n            var countRepoLang = await SearchReposit(searchQuery_str, lang_str, null_flg);\n\n            label7.Text = countRepoLang;\n\n        }`\n\n```\nWill this be a normal decision or can it be made more competently?\n. @shiftkey  Can you recommend any other ways to get a multi-language collection of repositories?\nUsing another library?\nOr filter the search results?. ",
    "alanmcgovern": "oh, i just pushed the same thing, looks like it was the same commit too - https://github.com/octokit/octokit.net/pull/1708. +1\nThanks!. Yup, latest release is working like a charm. Internal tools are functioning again! :D. ",
    "BarbourSmith": "What is the status of this? The documentation implies that it is working, but it says \"For example: \" but the example has not been written yet\nEdit: It seems like the octokit documentation may be pulling directly from the GitHub api documentation which would explain the discrepancy . Sorry guys, I didn't realize I was in the c# client... \ud83d\ude2c . ",
    "joewstroman": "Using Get actually provides more fields, but now all the fields say true for Mergeable, even for PR's that say CI check has failed and says \"Merging is blocked\". So Mergeable only signifies if there are merge conflicts?. ",
    "adriangodong": "AWS policy is to support LTS version only, and 2.0 is current. 1.1 moved to LTS when 2.0 is out back in August, so I'm asking AWS as well for their timeline/commitment to add support for 1.1.. Awesome! I'm blocked on signing the JWT in .NET Standard, should be smooth sailing once that's out of the way. \ud83e\udd1e . Yep, the other PR looks good. Closing this one.. @itaibh Thank you for picking this up! My original goal was only to do the bearer token authentication but stuck on some incompatibility with .NET Core 1.0. Let me know if you have any questions on my code.. Chiming a little bit here. I've managed to use my initial commits, created GitHub JWT, and use PEM from filesystem or env var. You can check this PR https://github.com/adriangodong/todo-bot/pull/6 for details.\nIt does require .NET Standard 2.0 to make the JWT part working.. Also, would it be prudent to split this PR into several parts:\n Foundational work (new authentication option + access token client)\n GitHub JWT -- I'd argue this can be a separate package. Octokit can take a token string, not caring how to create it.\n* Other clients (installation, etc.). GitHubJwt is now a Nuget package.. .NET Core 1.0 has limited support for PEM files. I did not try .NET Core 1.1 since AWS Lambda has never supported the version. AWS Lambda recently added support for 2.0 and that cleared all the issues.\nThe test project itself can target netcoreapp2.0 and use both netstandard1.1 and netstandard2.0 libraries without issue. I'd expect Octokit stays at netstandard1.1 but any consumer that wants to use this specific library to generate JWT will need to run on netcoreapp2.0.\nIf I have some time, I can try out .NET Core 1.1 and see if there's any issue.. @ryangribble @itaibh I've created a netstandard1.4 targeted GitHubJwt PR. This will not get merged until I get the tests pass. With small modification, 1 out of 2 of the test passes on netcoreapp1.1.\nAdd the custom feed https://ci.appveyor.com/nuget/githubjwt and install the version you want to try out. I'd recommend trying out 0.0.1-2-g457db9a.\n. ",
    "wqferr": "Me and @eduardoscsouza will give this one a shot.. Thank you for such an in depth reply.\nI'll do these things asap, although I'm a bit in a hurry this next week.\n\nTo do:\n- [x] Add unit tests for the Transfer client methods in RepositoriesClientTest\n- [x] Implement 2nd endpoint (if it exists (it probably does)) that takes the repository Id /repositories/:id/transfer\n- [x] Use IReadOnlyList rather than a normal int[] array for TeamId\n- [x] Do something more succinct for DebuggerDisplay property in RepositoryTransfer\n- [x] Make Ensure.NotNullOrEmptyList into Ensure.NotNullOrEmptyEnumerable\n- [x] XmlDoc comments should be added to RepositoryTransfer\n- [x] Implement and run integration tests\n\nThis list was merged with the main \"to do\" list.\nEdit: add \"to do\" list\nEdit 2: add quotes to \"\\\"to do\\\" list\". Sorry to bug you with this but I'm new to this open source thing and I'm not sure where to ask, so I'll do it in this \"thread\".\nMy implementation of the API seems correct to me, I've checked the JSON serializer and (to me at least) it seems like it should be working, but the request sent never actually adds the teams it passes as team_id. Other than that, the integration tests (org -> user and user -> org w/o teams) pass.\nOn another note, about the other end point: it's not listed in the api. It only mentions POST /repos/:owner/:repo/transfer, not repositories/:id/transfer. Is this a case of incomplete documentation? Or does it actually not exist?\nIf it does exist but isn't listed, am I even supposed to try and implement it?. Integration tests work like a charm now, thanks for the help!\nStill working on the other points (yes, I realize I put the awaits in the wrong place for the unit tests), but it's 2 AM and I really need to sleep.. What is with this Travis CI test? It seems really inconsistent.\nTwice the branch passed it in one commit, then I changed XmlDoc in the next one and it stops passing with some error associated with linksource.\nShould I be doing something to fix it? I have no idea.. >since you've done such an amazing job so far\nAww, you're going to make me blush. Anyway, thanks!\nEverything you asked for in this last batch is fixed, so I'll wait your next revision.. Fair enough, I didn't think that one through. I'll change this right now.. Oops.. ",
    "MuazOthman": "@ryangribble sorry for the late response, it's crunch time at work these days! Please keep this open if possible, I'll try to get back to it as soon as I get the chance.. That would be great! The checklist above can provide guidance to what's still to do.\nI can add you to my repo if you want and you're welcome to pick it up there.. @jonnii I just invited you, thanks for offering to help. ",
    "pizycki": "I create branch with that name just before attempting to create new file. You can check my program right here https://github.com/pizycki/DevoWeek/blob/octokit/DevoWeek/Program.fs#L39\nEdit:\nI found a bug in my code. I was trying to create a file that already exists on base branch.\nThe file creation works fine :)\nThanks for your reply and for Octokit, its great :). ",
    "Xwilarg": "I'll try that, thanks.\nMy goal was to count how many changes each user did in one project, so I have to iterate through each files and commits... ",
    "hyan23": "hi, @ryangribble \nCan I apply pagination on a commit's files array in some way? Because there is cutoff on up to 300 files for each client.Repository.Commit.Get request, BTW the repository I am working on sometimes performs a large merge operation which results more than 10, 000 changed files, If I can't use pagination, Is there any other way to get the complete changed file list of a specific commit? Thanks.\n. That's exactly my plan B, and shall be working fine, thank you for your kindly response:). ",
    "mirsaeedi": "@ryangribble  Actually, I found that Rate Limit API has been implemented before. I will update the documentation.\ngitHubeclient.Miscellaneous.GetRateLimits();. @shiftkey Thanks for your prompt reply. In some repositories, because of a large amount of data, even using pagination with big page sizes won't solve the above problem. besides that, I'm working on a research that I need to fetch all of the review related information from top repositories to analyze them afterward, so practically the second solution is not suitable for my scenario. . @shiftkey, Of course, I'm using a backing store to save data. However, storing is a different concern from fetching data from servers. The problem is that practically GetAllForRepository is useless in scenarios where you need more than 5000 requests to fetch all of the data. \nA mitigation to this could be a change in GetAllForRepository to wait for a sufficient amount of time, in case of reaching the limit. And, automatically starting to fetch data again after that.. @shiftkey The problem with the current API is that when I call GetAllForRepository then I have no way to control its behavior by myself. Because when GetAllForRepository is running I don't have any access to GetLastApiInfo() method via events or callbacks. I should wait till I catch the Rate Limit Exceeded exception and act accordingly.\nI'm really sorry to bother, your API is really awesome and I just wanted to make a contribution to improve it, based on the experience I had with it.. @ryangribble  I tried to satisfy your points in my new commit.. I just saw this thread. I got the idea from @ryangribble and I solved the rate limiting issue and the retry policy by using Polly and DelegatingHandler of HttpClient. I created a library to share my code with other folks.\nResponse and ApiInfoParser classes and BuildResponse method are copied exactly from the octokit's source code. I had to copy them because they weren't defined as public classes and methods.. I noticed there are 2 more Events that are not defined in EventInfoState. So, I added them in my 2nd commit.. @ryangribble Thanks for your prompt reply.\nYes, you are right! I forgot that I can solve it using DelegatingHandler of HttpClient. I planned to do it using Dynamic Proxies.\nUsing my own HttpClient, means that I need to create a chain of DelegatingHandlers  to act appropriately based on Github's response. However, in this case, I need to have access to some of the ocktokit's classes which now have internal modifiers and are not exposed to third-party bits.\nFor example, in my own custom DelegatingHandler, I need to parse the raw http response and be able to extract the type of exceptions (RateLimitExceededException,LoginAttemptsExceededException,etc). However, since Reponse class is internal and Connection.HandleErrors(IResponse) is private, i have to reimplement the logic which makes my solution unreliable. Because in this case I need to always make sure my implementation is always consistent with Github's future response format. \nI believe having access to some of the internal methods and classes of octokit, makes it possible for us to rely on its always consistent and tested codebase.. @ryangribble following your suggestion, I implemented a mechanism to deal with rate limiting and possible http exceptions. I would be very happy if you could review my code. I shared it here.. Thanks @ryangribble \nMy main requirement is to have a retry policy to deal with exceptions such as timeouts, HTTP related errors, and GitHub related errors.\nI don't know how adding a hook into the HandleErrors can help us to implement a retry policy. In addition, timeouts and HTTP related errors happen before reaching the HandleErrors method.\nI thought a lot about this matter and I came to this point that having a custom DelegatingHandler, maybe is the most practical way to achieve retry-able actions.. Hey @ryangribble, yeah as you can see from the links, this field is returned in REST api responses.\nI will remove the optional parameter. I put it in this way to not break existing codes.. it's done. @ryangribble . I replaced the Rate property with the .Resource.Core. Also, I added a sample for the search API.. ",
    "haidelber": "I've been following this PR for 2 weeks now as I need this feature in one product I'm currently developing. I'd really appreciate the integration.\nThe security handling is sufficient enough in the current implementation via ICredentialStore. I could contribute with doc and some samples on how to implement these for:\n\nAccess as GitHubApp\nAccess as GitHubApp installation. \n",
    "Cyberboss": "Been playing around with this some and it seems to work well. I know it's\nWIP but the lack of /installation/repositories is a bit of a downer\nseeing as you need it to associate webhook payloads with installation\ntokens afaik.\nOn Mar 7, 2018 2:33 AM, \"Itai Bar-Haim\" notifications@github.com wrote:\n\nsorry for the merges and reverts, my git client got me confused a little\nbit. \ud83d\ude33\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/1738#issuecomment-371049663,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AHywejJ6naAztR-z48IVx6-21j41dhnyks5tb41BgaJpZM4Rax8k\n.\n. Yeah I'll add that too. Hmm, that's odd, it's checked on my end.. For the reordering, is that just the interface or the implementation as well?. Stepping into this, I've found that the URL that gets GET'd in the end is https://api.github.com/repositories/3234987/contents//?ref=d728a08b4288b8445b14444d2e5e330b735f4d17\n\nNotice the double slash? In the end this ends up redirecting back to https://api.github.com/repositories/3234987/contents giving me the slightly different results. Ok, so changing dir from \"/\" to \"\" and stepping over this line:\nhttps://github.com/octokit/octokit.net/blob/a1d3c7a7d13a6856ee647c6aa2bf02ffb2fe97d6/Octokit/Clients/RepositoryContentsClient.cs#L126\n(Same line on master)\nAllowed the request to run as expected\nSolution would be to one or both of the following:\na) Properly handle \"/\" passed as a path to the repo content apis\nb) Allow empty path strings as valid parameters. Read this over in email a few times, forgot to say, looks good. Late to the party, but the CheckRunUpdate constructor requires a name field where it should be optional. https://developer.github.com/v3/checks/runs/#update-a-check-run. It's not allowed to be null in those two iirc. Only when the check run is\nupdated.\nOn Sun, Jul 22, 2018, 4:10 PM Ryan Gribble notifications@github.com wrote:\n\nHmmm if this field allows nulls then we probably need to fix it in\nNewCheckRun request, and CheckRun response as well?\nhttps://github.com/Cyberboss/octokit.net/blob/2388138d33c0f401257c7fe31b6db417464fb60f/Octokit/Models/Request/NewCheckRun.cs#L50\nhttps://github.com/Cyberboss/octokit.net/blob/2388138d33c0f401257c7fe31b6db417464fb60f/Octokit/Models/Response/CheckRun.cs#L71\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/octokit/octokit.net/pull/1852#issuecomment-406893250,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AHyweueVc72UnKyTwig5vJR1ClkqKYxRks5uJNw1gaJpZM4VaC-j\n.\n. Oof I thought this was newer than it was. GitHub. Listing check runs for a reference or check-suite doesn't follow the standard pagination rules for most other APIs. Advice?. I'm more so talking about how the returned json isn't a direct list, but an object instead\n\njson\n{\n  \"total_count\": 1,\n  \"check_runs\": [\n    {\n      ...\n    }\n  ]\n}\nDoes the pagination already handle this?. This is how I ended up implementing the GetAll methods with object responses. Pagination on it's own doesn't handle the model. Also, how would this translate to the reactive methods?. ",
    "gr2m": "My current stance on the preview headers is to be very transparent about it and not to set any preview headers by default. I would make it simple to set them though as end users (including setting multiple headers as they can be combined) so that they are sent with any following request by default\n. FYI this was a recent change, both will work on api.github.com and GHE 2.16. Only the former will work on GHE 2.15 and below. ",
    "kytrinyx": "/cc @tarebyte @bkeepers. ",
    "bkeepers": "I agree with @gr2m's stance. However, it'd be nice to give end-users a way of turning this on when instantiating the client. For example, Do any of the clients support something like this?\nrb\nclient = Octokit::Client.new(:headers => {\n  \"Accept\" => \"application/vnd.github.jean-grey-preview+json\"\n}). ",
    "ShalokShalom": "Yep. .NET Standard and up?. So mean that higher versions are also supported? Might be confusing otherwise. . ",
    "IAmHughes": "Working on it now, thanks. If someone wants to attempt to edit the files themselves to see about indentation, I'd be curious to know what you see on your end. For me, even using the GitHub.com editior and removing all whitespace, removing the CRLF (or LF) and then redoing the indentation still isn't fixing it, which is why I'm fairly certain it's just a UI bug on comparing branches for the pull request UI.. I know it appears that way but it's gotta be a bug. Even using the in browser editor they are spaces for me.. Thanks Ryan,\nI'm at the airport about to hop on a flight or I'd do it, haha. For me, all local files had spaces and on my fork they were spaces in browser. I committed multiple times deleting the line(s) and retyping with spaces.\nIt may be a cache issue, but I went ahead and submitted a bug report to GitHub with steps I took just in case.. From my phone, looks like the remarks are lined up and now the params are off (or are still off, can't recall if last night they too were misaligned).\nI apologize for you having to go to try to fix something as simple as tabs versus spaces, heh.. Thanks @ryangribble for the fix and merge. #teamwork #tabsarebetter #savethekeystrokes\nWish editors would resolve tab/space things on their own, heh. I swear all my local copies showed spaces only using Atom, VS, even notepad++ haha.. @ryangribble I don't see the ? icon that should tell me which email is under the commit. Any help? Thanks for pointing it out!\nI've been changing some things (such as my profile name) on my account, that may be the issue.. ah well. i dont mind :P. Unfortunately I believe its due to the anonymous email I use as part of GitHub's privacy on profiles (options 2/3 of the diagnoses). Both fixes listed actually say that there's not a way to fix old commits.. Non anonymous as in on your profile at GitHub, there's a privacy setting to hide your email. https://help.github.com/articles/about-commit-email-addresses/, see bold \"Keep your email address private\". ",
    "Andrew-Hanlon": "Amazing, thank you @ryangribble - works like a charm. I hadn't realized the Sha  parameter in the CommitRequest could accept the branch name. Much appreciated!. ",
    "chrobles": "Sure thing, I'll give it a shot.. Hey @ryangribble, thanks for the input. I'll take a crack at this!\nUpdate: @ryangribble, I have changed it to a StringEnum<T>.. Thank you for all the help @ryangribble ! Couldn't have done it without you \ud83d\ude04 . Done, let me know how these changes look. Thanks for the continued help on this!. ",
    "hgleaves-ncuadmin": "@shiftkey - Hi\nHere's a small part of it:\nvar principal_branches = client.Repository.Branch.GetAll(repo.Id).Result;\nI'd like to enumerate that sequence in date order.\nThx\n. @shiftkey - Much appreciated!. @ryangribble - I'm unfamiliar with the TLS stuff, did Octokit fail for me yesterday because it has to be changed, the code must change? or is it a firewall change? a SSL certificate change?\n. ",
    "ptoomey3": "I'm not familiar with the details of this project. But, given it is Windows oriented, might it make use of the git credential manager for windows (whether directly or indirectly)? If so, that could be the source of the issue. As noted in the blog post, one must run version 1.14.0 (or greater) to be compatible with TLS 1.2. . > Maybe this is something used by MS tools (e.g. Visual Studio) that need to manage access to Git?\nYes, it is used by a fair number of Windows tools to manage credentials to git. So, I wouldn't be surprised if it was in use. But, I'll wait for @ryangribble to weigh in with a more informed assessment of the internals of Oktokit.net.. ",
    "mylodeon": "@ryangribble Thanks! I'm using this for issues. For now I am doing SearchIssues to work around it. But it does mean I can't use LINQ to form the majority of my filtering and processing - I have to format my reports effectively into a Github-compatible requests. It's fine for \"pre-designed\" reports, but not great for REPL-style quick queries.\nDTOs with Automapper is like... hard work :). j/k. I can do that as an option if need be.. ",
    "Dorky106": "Just to make sure I am doing this correctly as it freezes at GetAll\nGetAll(Owner, Name)\nOwner = owner of the repo\nName = Name of repo\npublic static async Task GetReleases(string GIT_URL)\n```\n        {\n            System.Net.ServicePointManager.SecurityProtocol = SecurityProtocolType.Tls12;\n            Octokit.Release release = null;\n        try\n        {\n            string[] tmp = Form1.Instance.githubID.Split(':');\n            var client = new Octokit.GitHubClient(new Octokit.ProductHeaderValue(tmp[0]));\n            var basicAuth = new Octokit.Credentials(Username, Password);\n            //client.Credentials = basicAuth;\n            var releases = await client.Repository.Release.GetAll(\"Dorky106\", \"BetterTrees\");\n            release = releases[0];\n\n            Console.WriteLine(GIT_URL + \" got release!\");\n        }\n        catch (Exception ex)\n        {\n            Form1.Instance.ErrorOut(GIT_URL + \"\\n\" + ex.ToString());\n        }\n        return release;\n    }\n\n```. Okay, but being stuck on the await to complete for 10+ minutes kinda kills the point of using this library for me.\nAs no one is going to want to wait 10+ minutes for something to finish a simple task.. I was testing on a repo with 3 releases, and even getlatest was taking ten minutes.\nAlready gave up and just made a readonly token to use and removed the need for github info. (As this was really all I tried using this lib for was to make sign-ins needed instead of a token). ",
    "StefH": "Another question:\nIt seems that it's not possible to get all releases from an organization?\nc#\nvar releases = client.Repository.Release.GetAll(\"WireMock-Net\", \"WireMock.Net\").Result;\n// releases has no values ?\nI'm using oktokit version 0.32.0. ",
    "ianfixes": "\ngrossly unclear\n\nI agree completely.  Adding this info here (since this came up during my troubleshooting search):\nI hesitated to grant my oauth token the scope for \"Full control of private repositories\" (repo), because it didn't sound read-only.  A better description would be \"Access all aspects of public and private repositories\", and public_repo would add more clarity if it was the first sub-scope listed underneath.\nBut you do need the top-level repo scope checked, or your queries for private repos will just return an empty array (no errors).. ",
    "Licho1": "It indeed is because the final assembly is missing and AssemblyInformationalVersion and you can add this attribute to your assembly as a workaround.. ",
    "davidhouweling": "Hi @ryangribble thanks for getting back to me so promptly.\nFiddler response received:\nJSON\n{\n  \"id\":8207388,\n  \"repository\":{\n    \"id\":125925210,\n    \"name\":\"repo_for_david.houweling-thetrainline.com\",\n    \"full_name\":\"trainlinerecruitment/repo_for_david.houweling-thetrainline.com\",\n    \"owner\":{\n      \"login\":\"trainlinerecruitment\",\n      \"id\":30077446,\n      \"avatar_url\":\"https://avatars1.githubusercontent.com/u/30077446?v=4\",\n      \"gravatar_id\":\"\",\n      \"url\":\"https://api.github.com/users/trainlinerecruitment\",\n      \"html_url\":\"https://github.com/trainlinerecruitment\",\n      \"followers_url\":\"https://api.github.com/users/trainlinerecruitment/followers\",\n      \"following_url\":\"https://api.github.com/users/trainlinerecruitment/following{/other_user}\",\n      \"gists_url\":\"https://api.github.com/users/trainlinerecruitment/gists{/gist_id}\",\n      \"starred_url\":\"https://api.github.com/users/trainlinerecruitment/starred{/owner}{/repo}\",\n      \"subscriptions_url\":\"https://api.github.com/users/trainlinerecruitment/subscriptions\",\n      \"organizations_url\":\"https://api.github.com/users/trainlinerecruitment/orgs\",\n      \"repos_url\":\"https://api.github.com/users/trainlinerecruitment/repos\",\n      \"events_url\":\"https://api.github.com/users/trainlinerecruitment/events{/privacy}\",\n      \"received_events_url\":\"https://api.github.com/users/trainlinerecruitment/received_events\",\n      \"type\":\"Organization\",\n      \"site_admin\":false\n    },\n    \"private\":true,\n    \"html_url\":\"https://github.com/trainlinerecruitment/repo_for_david.houweling-thetrainline.com\",\n    \"description\":null,\n    \"fork\":false,\n    \"url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com\",\n    \"forks_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/forks\",\n    \"keys_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/keys{/key_id}\",\n    \"collaborators_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/collaborators{/collaborator}\",\n    \"teams_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/teams\",\n    \"hooks_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/hooks\",\n    \"issue_events_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/issues/events{/number}\",\n    \"events_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/events\",\n    \"assignees_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/assignees{/user}\",\n    \"branches_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/branches{/branch}\",\n    \"tags_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/tags\",\n    \"blobs_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/git/blobs{/sha}\",\n    \"git_tags_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/git/tags{/sha}\",\n    \"git_refs_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/git/refs{/sha}\",\n    \"trees_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/git/trees{/sha}\",\n    \"statuses_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/statuses/{sha}\",\n    \"languages_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/languages\",\n    \"stargazers_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/stargazers\",\n    \"contributors_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/contributors\",\n    \"subscribers_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/subscribers\",\n    \"subscription_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/subscription\",\n    \"commits_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/commits{/sha}\",\n    \"git_commits_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/git/commits{/sha}\",\n    \"comments_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/comments{/number}\",\n    \"issue_comment_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/issues/comments{/number}\",\n    \"contents_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/contents/{+path}\",\n    \"compare_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/compare/{base}...{head}\",\n    \"merges_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/merges\",\n    \"archive_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/{archive_format}{/ref}\",\n    \"downloads_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/downloads\",\n    \"issues_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/issues{/number}\",\n    \"pulls_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/pulls{/number}\",\n    \"milestones_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/milestones{/number}\",\n    \"notifications_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/notifications{?since,all,participating}\",\n    \"labels_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/labels{/name}\",\n    \"releases_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/releases{/id}\",\n    \"deployments_url\":\"https://api.github.com/repos/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/deployments\"\n  },\n  \"invitee\":{\n    \"login\":\"davidhouweling\",\n    \"id\":9696959,\n    \"avatar_url\":\"https://avatars0.githubusercontent.com/u/9696959?v=4\",\n    \"gravatar_id\":\"\",\n    \"url\":\"https://api.github.com/users/davidhouweling\",\n    \"html_url\":\"https://github.com/davidhouweling\",\n    \"followers_url\":\"https://api.github.com/users/davidhouweling/followers\",\n    \"following_url\":\"https://api.github.com/users/davidhouweling/following{/other_user}\",\n    \"gists_url\":\"https://api.github.com/users/davidhouweling/gists{/gist_id}\",\n    \"starred_url\":\"https://api.github.com/users/davidhouweling/starred{/owner}{/repo}\",\n    \"subscriptions_url\":\"https://api.github.com/users/davidhouweling/subscriptions\",\n    \"organizations_url\":\"https://api.github.com/users/davidhouweling/orgs\",\n    \"repos_url\":\"https://api.github.com/users/davidhouweling/repos\",\n    \"events_url\":\"https://api.github.com/users/davidhouweling/events{/privacy}\",\n    \"received_events_url\":\"https://api.github.com/users/davidhouweling/received_events\",\n    \"type\":\"User\",\n    \"site_admin\":false\n  },\n  \"inviter\":{\n    \"login\":\"thetrainconductor\",\n    \"id\":2421357,\n    \"avatar_url\":\"https://avatars2.githubusercontent.com/u/2421357?v=4\",\n    \"gravatar_id\":\"\",\n    \"url\":\"https://api.github.com/users/thetrainconductor\",\n    \"html_url\":\"https://github.com/thetrainconductor\",\n    \"followers_url\":\"https://api.github.com/users/thetrainconductor/followers\",\n    \"following_url\":\"https://api.github.com/users/thetrainconductor/following{/other_user}\",\n    \"gists_url\":\"https://api.github.com/users/thetrainconductor/gists{/gist_id}\",\n    \"starred_url\":\"https://api.github.com/users/thetrainconductor/starred{/owner}{/repo}\",\n    \"subscriptions_url\":\"https://api.github.com/users/thetrainconductor/subscriptions\",\n    \"organizations_url\":\"https://api.github.com/users/thetrainconductor/orgs\",\n    \"repos_url\":\"https://api.github.com/users/thetrainconductor/repos\",\n    \"events_url\":\"https://api.github.com/users/thetrainconductor/events{/privacy}\",\n    \"received_events_url\":\"https://api.github.com/users/thetrainconductor/received_events\",\n    \"type\":\"User\",\n    \"site_admin\":false\n  },\n  \"permissions\":\"write\",\n  \"created_at\":\"2018-03-19T21:55:16.620+00:00\",\n  \"url\":\"https://api.github.com/user/repository_invitations/8207388\",\n  \"html_url\":\"https://github.com/trainlinerecruitment/repo_for_david.houweling-thetrainline.com/invitations\"\n}\nInteresting I didn't see the second call this time. In any case, this JSON file will help.. Interesting, i guess this needs to be taken into account? I am calling github.com so it isn't an enterprise based issue.. @shiftkey I have sent them a message as requested. Shall we give it a few days and see if they get back to us accordingly?\nI wonder, given GitHub is a reliable enough source, is there a reason Octokit is so strict on the parsing in the code and not just use DateTime.Parse and let the internal .NET engine determine the value?. Yes it seems there is a bit of confusion on the GitHub side as the documentation is saying that it would look like the UTC style, but the link they point to as an example is the Zulu style.. Closing as GitHub said they've resolved this. Will reopen if I encounter again.. ",
    "mkArtakMSFT": "Looking through the code I found the Term property. Will try to see whether this will do it.. So yes, passing the term as a constructor parameter to the SearchIssueRequest did it. Still, leaving this option as an ask to consider exposing Milestones property on the request.. Hi @ryangribble. I ended up using it as I would in GitHub search: milestone: myMilestoneName. It worked just fine. I'll try to submit a PR with the proposal.. ",
    "mkArtak": "@ryangribble, do you have any other comments?. Done, @ryangribble. Good suggestion!. I was trying to keep the code simple, so decided to add quotes for all the cases, rather than add them only when there are spaces in the value. Sure, from consistency perspective I see your point.\nThat will then leave the responsibility of specifying quotes on the user.\nLet's play this out, and assume that the Milestone property is already available. From the library user's perspective, I would just see a property to set the milestone filter, so I'll apply whatever my milestone value is. I shouldn't really add a layer on top of the library I use which should be aware of the internals of how the interaction with GitHub works. And that \"quoting\" is actually an internal behavior.\nThe bottom line is, if we won't add quotes we force the library users to be aware of the internals of GitHub search API. So I still believe that adding quotes is correct. Even more, I would prefer to get another issue filed to add the quotes across all the other properties too (where applicable of course).\nThoughts?\n. Cool, thanks @ryangribble. I'll update the code to make sure quotes are added only if there aren't already.\nAs for the second point, I'll file an issue to address that in the future.. After some experimentation it looks like a milestone can have \" as part of its name. That means, that we can't assume that the quotes the user will provide in the milestone property are to wrap it. Rather, those are just part of the milestone name. Here is a sample search output to confirm this:\n\nWhen searching with just additional double quotes, or without - the search returns nothing:\n\n\nSo searching the way I did in the first image is correct, which is - to escape all existing quotes and to always wrap the milestone with double quotes. I'm going to implement that way.\n. ",
    "kristianjaeger": "Thanks, @ryangribble ! Good to know.  Cheers.. ",
    "dahall": "@ryangribble It makes sense to not include in the base library for your reasons. However, by having the rate limit information return in the header, it is very easy for first time users to almost immediately hit the limit and then have to wade through a lot of documentation to figure out how to prevent it. Thus my recommendation. The \"1 second\" is from some of the documentation as a recommendation. If it can be removed, I'll remove it from the post so others don't include it if they reuse it.. Another thought, given the challenge of using the library for multiple calls or \"composite\" calls, may be to develop a queue into which the user can submit calls and have the rate limiting done for them. If that is something you'd consider, I'm willing to do the the initial development work on it. I'm just looking for ways to keep others from hitting the problems I did and having to spend all the time wading through the docs to get a workable solution.. ",
    "tasadar2": "Looks like the linux build failed while installing .NET, though I am not familiar enough with travis to know if that is fixable in code or not.. I added some integration tests.. Thanks @ryangribble\nI did not know the repositoryId endpoints were that widely interchangeable, good to know.\nAlso looks like some integration tests assume the history of the octokit repo persists. I'll keep that in mind for the next PR.\nYour changes look good to me\n. The response classes are using implied parameterless constructors, so that is probably why the convention tests passed, and is for sure why the integration tests pass. I will get some constructors with all parameters added, which will require the explicit parameterless one as well.. Changes look good to me.. Thanks for going through the ctors.\nI didn't see a good way through reflection to determine what base ctor was being called. We could open the rule up to all members by removing the DeclaringType condition. The scenario I was trying to solve for was for the ctors that pass explicit values to their base ctor. As mentioned, these could be ignored with attributes if it makes sense.\nEx. AccountType in https://github.com/octokit/octokit.net/blob/c9b2c1260bc87b7782d4fd9645d43a8885203923/Octokit/Models/Response/Organization.cs#L12-L13. Sounds good.\nI was thinking the same thing with excluding individual properties rather than the whole class. Pushed an update which should account for those last scenarios.. Good call, i'll update that. I split these up, also updated the tests to account for optional values. Nice to find a serializer that accounts for that, I automatically assumed I would need an attribute;). Both are optional, and I have integration tests for omitting one or the other.\nThe call also works when no parameters are passed, although that doesn't really serve a purpose.\nSo, we could\n1. Add an integration test for the update nothing scenario\n2. Create a constructor that ensures that at least one value is set. Can't really do separate constructors as both values are strings.\n3. Leave it as is. Updated. Updated. ",
    "Disturbing": "What about the user's organization, because at the moment PrivateRepos is showing as zero.. ",
    "sotiriszegiannis": "Hi @ryangribble \nyour comment pointed me in the right direction and i solved my issue. Here 's a brief description of the issue:There was an organization git account with many repos and personal accounts. One of the personal accounts was the token issuer that i was using to access the and update the issues. More specifically  i was trying to edit the description of the organizational account's issues, through the personal account's token. Although the personal account had almost all scopes checked, the permissions for the organizational's repos were all read only! So even though i could edit and update any issues that i was creating through the personal account's token i couldn't edit existing issues from the organization. We had a couple of solutions around  this.\n1.One of them was to change the role of the personal account inside the organization.\n \nbut that was rejected since it gave great control to the account and that was not desired from the organization's part. I can't blame them!\n2.The other solution was to change the repository's default default member permissions.\n\nThat was rejected too because that would give all the collaborators the power to edit issues except from the personal account whose token i was using.\nSo because non of the above solution was secure proof a third suggestion was put on the table. For each repo ,that the personal account i was using needed write access, would change the default repo permission for my account.\n\nNow i had already thought about that and for me that would be the best scenario too, but the thing is that there are more than 1400 repos that my account would need write access. That means that unless we do it through the git api, some pure fellow will have to go inside each and every repo and change permissions! We still haven't decided. For the time being it seems that the lazy fellows in the the organization just decided to change the account's role from member to owner. To be continued..... ",
    "crhairr": "I didn't mean to come off so pushy! I actually really like Octokit, and I was just hoping to use the GitHubApps features that were in the docs. Poking around the repo, I could see lots of good stuff, and the code looks to be in great shape, so I couldn't see a reason not to publish.\nThanks for a great tool!. I just swapped out my code for handling the GitHub installation auth token generation for Octokit's and it works like a charm. Thanks!. We are signing the IntegrationId using the pem-formatted private key generated by GitHub. It would be awesome if the complete JWT signature functionality was included in your API, but I can see why you might leave that part up to the user.. We're using Org.BouncyCastle.Crypto for reading the PEM file and converting it into a valid key, and Microsoft.IdentityModel.Tokens for handling the JWT library. These are available in .NET Core 1.0.. ",
    "psibernetic": "The issue at hand is <TargetFrameworks>netstandard1.1;net45</TargetFrameworks> referencing net45 in a target framework will fail builds if you don't have the targeting pack installed, which isn't available. \nUsing netstandard1.1 does work fine, but the package vs framework proliferation is a little ugly honestly, it would look like you are installing a ton of dependencies, but they are just framework redirects. \nFor that reason I have been targeting 452 explicitly in my packages, but that causes yet another issue, but one I think you have avoided by targeting so low, but useful info anyway: framework prefers framework, so even on 472 the 45(2) dll will be chosen over any compatible netstandard version. Leads to issues where you may use polyfills for lower framework versions, but desire to use built-in stuff in higher (AsyncLocal for instance). So, then you have to target a higher framework version too.\nAlso, there is this consideration, semi-related since we are talking about targeting:\n\nAll said my pattern has been: <TargetFrameworks>netstandard1.X;netstandard2.0;net452;net4X</TargetFrameworks>  where 4X is the highest framework I would LIKE features from, to omit polyfills if necessary.. Issue #1745 from January is a pretty prime example of the hassle.. Yeah that my understanding for the most part. \nOnly the netstandard2.0 piece is a little confusing. I think you edited to match my understanding, but it is as such: netstandard2.0 targets net46+ on the framework side, so if you were only targeting that already in say netstandard1.6 then just re-baseline on 2.0 instead, BUT if you targeted lower, then include both.\nSo the end result is netstandard1.1;netstandard2.0. \nWhat I'm not sure about is: does the framework preference issue apply when checking for nuget package updates? If so it could lead to a scenario where clients don't get new package versions until they uninstall and reinstall the package. This is probably worth a test.... I quickly was able to confirm that issue does not occur, whew!\nAlso, this is what the experience will look like for framework users when you switch to netstandard only.\n\n. ",
    "baonguyen96": "@ryangribble  Sure here is the link to the source code: https://github.com/baonguyen96/GitData/blob/dev/GitData/Storage/Repository.cs\nParticularly, it breaks on line 41 (language = await ....) when I call the API to retrieve all languages and any of the language is null:\nc#\nIReadOnlyList<Octokit.RepositoryLanguage> languages = null;\nTask.Run(async () =>\n{\n                languages = await githubClient.Repository.GetAllLanguages(octokitRepository.Owner.Login, Name);\n}).GetAwaiter().GetResult();\nThis exception does not happen when a repository has at least 1 language.. @ryangribble yes I definitely prefer the empty list to null. Thank you.. ",
    "danielstreba": "@shiftkey Wow, thanks for the quick answer! That solved it.. ",
    "Jericho": "@ryangribble thank you for the suggestions. I would prefer to stick with octokit so your second suggestion is particularly interresting to me. Can you point me to a sample that demonstrates how to create a PR from upstream into my fork, how to automerge, etc.?. @shiftkey your suggestion works like a charm and so much simpler that anything I tried so far. Thanks\nIn case anybody is curious here's my code to update my fork if it's behind the upstream repo:\ncsharp\nvar fork = await _githubClient.Repository.Get(\"my_username\", \"the_repo_name\").ConfigureAwait(false);\nvar upstream = fork.Parent;\nvar compareResult = await _githubClient.Repository.Commit.Compare(upstream.Owner.Login, upstream.Name, upstream.DefaultBranch, $\"{fork.Owner.Login}:{fork.DefaultBranch}\").ConfigureAwait(false);\nif (compareResult.BehindBy > 0)\n{\n    var upstreamBranchReference = await _githubClient.Git.Reference.Get(upstream.Owner.Login, upstream.Name, $\"heads/{upstream.DefaultBranch}\").ConfigureAwait(false);\n    await _githubClient.Git.Reference.Update(fork.Owner.Login, fork.Name, $\"heads/{fork.DefaultBranch}\", new ReferenceUpdate(upstreamBranchReference.Object.Sha)).ConfigureAwait(false);\n}\n. ",
    "lethall": "Just ran into this as well.  Either use the overload that doesn't take the path, or substitute a dot (.) for the slash (/) .\nIn fact, the API supports a named parameter (path) so it can be explicitly stated rather than using the position (?path=/&ref=) so the best of all worlds would be to make this patch:\n```\nFrom a05dcfcaea1c2f978dbd62e67f1e5e5bd6030426 Mon Sep 17 00:00:00 2001\nFrom: Lee Hall lhall@javafoundry.com\nDate: Thu, 13 Dec 2018 17:47:28 -0500\nSubject: [PATCH] Bug 1837 - use path parameter\n\nOctokit/Helpers/ApiUrls.cs | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\ndiff --git a/Octokit/Helpers/ApiUrls.cs b/Octokit/Helpers/ApiUrls.cs\nindex 1b77364a..b2662f9f 100644\n--- a/Octokit/Helpers/ApiUrls.cs\n+++ b/Octokit/Helpers/ApiUrls.cs\n@@ -3328,7 +3328,7 @@ public static Uri RepositoryContent(long repositoryId, string path)\n         /// The  for getting the contents of the specified repository and path\n         public static Uri RepositoryContent(long repositoryId, string path, string reference)\n         {\n-            return \"repositories/{0}/contents/{1}?ref={2}\".FormatUri(repositoryId, path, reference);\n+            return \"repositories/{0}/contents?path={1}&ref={2}\".FormatUri(repositoryId, path, reference);\n         }\n     /// <summary>\n\n--\n2.17.0\n```\n. ",
    "FantasticFiasco": "Without knowing the code base by hard, I guess that the implementation would start at the API surface, and the cancellation token would be passed down to the HTTP client where it would be used twice:\n\nWhen the request is sent\nWhen the response is read\n\nI agree that a spike of the implementation could be done on a small subset of the API surface, but in an ideal world this would be implemented on the complete API surface.. I would love to, but cannot truthfully commit to the implementation due to other priorities, at least for some months to come. Sorry.. Close this issue if you think #984 will add support for disposing the HTTP client.\nAnd you are correct, with the release of HttpClientFactory it seems that we now have enough guidance on how to the HTTP client in combination with Octokit .NET.. ",
    "totoroyyb": "Thanks for checking out. It seems Octokit just doesn't have a payload class for these.\nI'd like to help out, and if there's anything I can help, I'll make a PR!\nThanks for all.. ",
    "xied75": "@shiftkey Thanks for the head up. \ud83d\udc4d . ",
    "ghiboz": "thanks! it works. ",
    "stt106": "@ryangribble thanks for the reply. Sorry but I am new to the package so not sure I fully understand you.\nOn the doc, I see I can add a label to a NewIssue like \nvar myNewIssue = new NewIssue(\"Issue with dropdown menu\");\nmyNewIssue.Labels.Add(\"bug\");\nI am creating a pull request using \n```\nvar github = new GitHubClient(new ProductHeaderValue(config.User), \n                                      new Uri(\"https://simhub.simcorp.com\"),\n                                      Credentials = Credentials(config.Password));\n   var pr = github.PullRequest.Create(\"Foo\", \"Bar\", \n        new NewPullRequest(\"PR title\", branchName, \"master\"));\n\n``\nThere is noLabelsproperty onPullRequesthence unsure where/how to add the label to a pull request.. @ryangribble  thanks again for the reply. Just to confirm that I understand you correctly. Once I have a PR e.g.pr`, then I will do something like this:\nvar issueUpdate = new IssueUpdate();\nissueUpdate.Labels.Add(\"some label\");\n// pass in pr.Number below\ngitHub.Issue.Update(\"owner\", \"repo name\", pr.Number, issueUpdate);\nI guess the key is passing pr.Number as the issue number in the Update method?. ",
    "MylioBill": "Adding a label, then removing it results in the exception.  No emojis or descriptions in the labels that have the issue.. Stack info in case it's useful\nat Octokit.Connection.HandleErrors(IResponse response)\n   at Octokit.Connection.<RunRequest>d__58.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.ConfiguredTaskAwaitable`1.ConfiguredTaskAwaiter.GetResult()\n   at Octokit.Connection.<Run>d__57`1.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.ConfiguredTaskAwaitable`1.ConfiguredTaskAwaiter.GetResult()\n   at Octokit.ApiConnection.<Delete>d__37`1.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()\n   at MylioGitHub.GitHub.<RemoveLabelFromIssue>d__23.MoveNext() in C:\\Git\\Mylio\\tools\\Github\\Triage\\Triage\\GitHub.cs:line 260\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.GetResult()\n   at MylioGitHub.MylioGitHubForm.<ApplyLabels>d__51.MoveNext() in C:\\Git\\Mylio\\tools\\Github\\Triage\\Triage\\MylioGitHubForm.cs:line 781\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.GetResult()\n   at MylioGitHub.MylioGitHubForm.<BtnApply_Click>d__55.MoveNext() in C:\\Git\\Mylio\\tools\\Github\\Triage\\Triage\\MylioGitHubForm.cs:line 836. Using IssueUpdate sidesteps the issue. Thanks!. ",
    "codecov[bot]": "Codecov Report\n\n:exclamation: No coverage uploaded for pull request base (master@d34aa80). Click here to learn what that means.\nThe diff coverage is n/a.\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1866   +/-\n=========================================\n  Coverage          ?   77.57%         \n=========================================\n  Files             ?      527         \n  Lines             ?    18208         \n  Branches          ?        0         \n=========================================\n  Hits              ?    14125         \n  Misses            ?     4083         \n  Partials          ?        0\n```\n. ",
    "tonerdo": "Just checking if you're encountering any issues with Coverlet that's preventing this from getting merged. ",
    "Dalmirog": "I noticed Issue.CommentsUrl does have a value. Perhaps I should be using that URL instead? I couldn't find a way to use it with the client in any of the repository's examples and tests.\nSorry for all my .NET noobness :(. ",
    "WowItsDoge": "Thank you for your help!\nThe preselected filter shows just ~14,000 issues.\n\nWhen removing the filter, the number of issues founds equals the number of issues returned by to API, which are ~22,000. So this explains the different numbers :)\n\n. ",
    "collinbarrett": "Wow. I don't know how I missed that. Thanks!. ",
    "MartinDawson": "In the docs OAUTH flow example you save the accessToken in a session and then access it in different actions.\n```c#\npublic async Task Authorize(string code, string state)\n{\n    if (String.IsNullOrEmpty(code))\n        return RedirectToAction(\"Index\");\nvar expectedState = Session[\"CSRF:State\"] as string;\nif (state != expectedState) throw new InvalidOperationException(\"SECURITY FAIL!\");\nSession[\"CSRF:State\"] = null;\n\nvar request = new OauthTokenRequest(clientId, clientSecret, code);\nvar token = await client.Oauth.CreateAccessToken(request);\nSession[\"OAuthToken\"] = token.AccessToken;\n\nreturn RedirectToAction(\"Index\");\n\n}\n```\n```c#\n// repositories which include public and private repositories.\npublic async Task Index()\n{\n    var accessToken = Session[\"OAuthToken\"] as string;\n    if (accessToken != null)\n    {\n        client.Credentials = new Credentials(accessToken);\n    var repositories = await client.Repository.GetAllForCurrent();\n}\n\n/* TODO: all the rest of the webapp */\n\n}\n```\nThis works fine for when I am do this on my own localhost but when I try to do this through my Google Extension for GitHub the cookies are never persisted and so the session is always empty.\nIs their any other way than using Session to get the credentials for each action?. Yeah, thanks for the help.\nHere's the full flow:\nI am creating a chrome extension for GitHub, similar to ZenHub extension. This chrome extension inject a button on the GitHub page. See screenshot below.\n\nThis button then calls my /setup route on my server when clicked.\nI'm using GraphQL for my backend and not rest API but it shouldn't make a difference.\n```c#\npublic override object MutateAndGetPayload(MutationInputs inputs, ResolveFieldContext context)\n{\n    var c = context.UserContext.As();\n    var csrf = Password.Generate(24, 1);\nc.HttpContext.Session.SetString(\"CSRF\", csrf);\n\nvar request = new Octokit.OauthLoginRequest(Env.GetString(\"CLIENT_ID\"))\n{\n    Scopes = { \"repo\" },\n    State = csrf,\n};\nvar redirectUri = inputs.Get<string>(\"redirectUrl\");\n\n_logger.Log(LogLevel.Debug, $\"csrf set: {csrf}\");\n\nif (redirectUri != null)\n{\n    request.RedirectUri = new Uri($\"{Env.GetString(\"APP_URL\")}/setupCallback?redirectUrl={redirectUri}\");\n}\n\nvar oAuthLoginUrl = _client.Oauth.GetGitHubLoginUrl(request);\n\nreturn new {\n    oAuthLoginUrl\n};\n\n}\n```\nI then redirect to that redirectUrl on my client side immediately.\nIn the /setupCallback I do this:\n```c#\nField>()\n    .Argument>(\"code\", \"The code for the setup\")\n    .Argument>(\"state\", \"The CSRF protection state\")\n    .Name(\"setupCallback\")\n    .ResolveAsync(async c =>\n    {\n        var context = c.UserContext.As();\n        var expectedState = context.HttpContext.Session.GetString(\"CSRF\");\n        var state = c.GetArgument(\"state\");\n        var code = c.GetArgument(\"code\");\n    if (state != expectedState) {\n        logger.Log(LogLevel.Error, $\"state: ${state} does not match code: ${code}\");\n\n        throw new InvalidOperationException(\"Security fail\");\n    }\n\n    context.HttpContext.Session.SetString(\"CSRF\", \"\");\n    var request = new Octokit.OauthTokenRequest(Env.GetString(\"CLIENT_ID\"), Env.GetString(\"CLIENT_SECRET\"), code);\n    var token = await _client.Oauth.CreateAccessToken(request);\n    _client.Credentials = new Octokit.Credentials(token.AccessToken);\n\n    context.HttpContext.Session.SetString(\"GitHubToken\", token.AccessToken);\n\n    return true;\n});\n\n```\nAnd then in different requests I try to set the credentials again but the gitHubToken is always null...\n```c#\nField>>()\n    .Name(\"organizations\")\n    .ResolveAsync(async c =>\n    {\n        var gitHubToken= context.HttpContext.Session.GetString(\"GitHubToken\"); // Not working\n        _client.Credentials = new Octokit.Credentials(gitHubToken);\n    var user = await _client.User.Current();\n    var organizations = _organizationService.GetOrganizations(user.Id);\n\n    return organizations;\n});\n\n```\nSo basically the user will be on GitHub.com but hitting my server through my chrome extension.\nThe CSRF session variable is fine and works for some reason but the GitHubToken session variable never does.\nThis is only a problem when trying to do this through my chrome extension.\n. Figured it out. Session wasn't working properly because for CORS you need to set samesite mode for cookies to none.\n```c#\n            app.UseCookiePolicy(new CookiePolicyOptions\n            {\n                MinimumSameSitePolicy = SameSiteMode.None\n            });\n        app.UseSession(new SessionOptions {\n            Cookie = new CookieBuilder\n            {\n                Name = \".AspNetCore.Session\",\n                SameSite = SameSiteMode.None,\n            }\n        });\n\n```. ",
    "EranAvraham": "I'm using OAuth authentication with active token, and able to get data of the public repositories but not the private. \nAnd yes, I can access this repository on browser.\nI think it's related to the \"visibility\" property which is not exposed in the .net api. @shiftkey  - Thanks a lot! I added control to the token and it did the job \ud83d\udc4d . ",
    "hodgeheg1110": "In my ASP.NET Core Controller:\nC#\nvar token = System.IO.File.ReadAllText(\"token.txt\");\n            var client = new GitHubClient(new ProductHeaderValue(\"BehavTrackReportBugs1\"));\n            var tokenAuth = new Credentials(token);\n            client.Credentials = tokenAuth;\n            var allIssues = new RepositoryIssueRequest\n            {\n               Filter = IssueFilter.All,\n               State = ItemStateFilter.All\n            }; \n            var getAllIssues = client.Issue.GetAllForRepository(\"Hodgeheg1110\", \"BehavTrackReportBugs\", allIssues).Result.ToList();\n            ViewBag.issueList = getAllIssues;\n            return View();\nIn View:\n```C#\n@foreach (var issue in ViewBag.issueList) \n{\n @issue\n};\n```\n. > \n\nTry changing <li>@issue</li> to <li>@issue.Title</li>\n\nThank you!!! That solved it. \ud83d\ude03 . ",
    "Itmolen1": "i want to show Product,Product Category, and then Variant in select 2 in option using jquery with MVC 5.\ncan someone help me ? i am new in jquery. ",
    "patricknolan": "Hi @shiftkey thanks for the response.\nWas hoping I could get any it may be related to.. Thanks @ryangribble using the ApiOptions is a good idea.. Hey @ryangribble your suggestion solves the issue and is probably the best approach for backwards compatibility. I'll send a PR soon.. Hi @ryangribble build failed but cause does'nt seem to be related to my changes.. Hi @ryangribble and @khellang when you get a chance let me know what you think!. Hi @khellang all done.. Hi @ryangribble and @khellang,,\nHas taken me a while to make changes due to other commitments, however, I have now made the changes advised.\nLet me know what you think.. Hi @ryangribble changes for [Obsolete] messages have been done. The CI failed, however, it may be an intermittent error as I don't believe the changes could have caused this to fail. I'm not sure how to invoke the CI again without an additional check-in?. Thanks @ryangribble. You ok for this to be merged now?. Hi @khellang the zzz includes the timezone offset which I believe is correct. \nHowever, you're right these changes affect the behaviour. I'll update and re-submit.. Hi sorry you are right @khellang. I was trying to do to code this while also doing my job which was a mistake. I'll fix in my next PR.. Hi @khellang I've included this suggestion aswell.\nI've also updated the relevant unit tests to use a Theory which tests both the DateTime and DateTimeOffset strategies.. Thanks @khellang good pickup. Just made both changes and checked-in.. Hi @khellang you're thinking something like this? \nquery = $\"{from.ToString(DateTimePattern, CultureInfo.InvariantCulture)}..{to.ToString(DateTimePattern, CultureInfo.InvariantCulture)}\";. Hi @ryangribble \nHas taken me a while to make these changes due to other commitments, however, they're now there.\nLet me know what you think.. ",
    "masakaya": "Hi @ryangribble \nThank to you  I got Label information as a pull request unit.\nThank you again.. ",
    "AnoojNair": "@shiftkey Thanks a lot :) That helped.\n. ",
    "Dre-Tas": "Thanks for your reply @ryangribble !\nWhat I'm looking for is what I underlined in the image below:\n\nThat in the image is just a test from a public repo, but putting that url (underlined in red in the image) as the address parameter in my WebClient.DownloadFile I'm able to download the actual file.\nIf I try to use Url, GitUrl or HtmlUrl I can't download the file.\nAm I looking at the wrong thing / in the wrong place?\n(I'm fairly new to programming so sometime I make very basic mistakes)\nThanks!. I just tried and I can actually see that I get the object (if I show the message box with the Count) but then I can't seem to find the DownloadUrl field you're mentioning:\n\nWhat am I doing wrong?\nThanks a lot!!. It worked!!\n\nThanks so much @ryangribble !!. Thanks @shiftkey for your reply.\nI'm afraid that downloading the whole repo wouldn't be too efficient in my case.\nI just used a workaround for now, which is to load zipped folders in my repo. This means folders become files that can normally be downloaded through the DownloadUrl property and then, as soon as they get downloaded I'm able to unzip them and delete the original zipped folder.\nSide benefit is also that it takes less space and less time to commit/push.. ",
    "devlead": "Don't think the SourceLink eror is Cake related could be that I'm hitting ctaggart/SourceLink#322\nTravis Mac & Linux seems happy.\nLTS .NET SDK is 2.1.500, might be worth updating.. ",
    "Vogel612": "\nAlso I think the tool install step of the build might still be a problem on Mac/Linux if you don't have mono as it uses nuget (from mono) to pull down gitversion doesn't it ?\n\nYes, the tool install step requires nuget. GitVersion is then executed through mono (cf. tools/gitversion_wrapper.sh). \n\nSo maybe rather than hardcoding noframework=true in build.sh this should be passed in so we can set false in travis?\n\nI'm happy to remove the hardcoding there.\n\nCurrently I'm building locally by sidestepping the GitVersion invocation and returning a hardcoded JSON because neither mono nor dotnet invoke the downloaded binary without error. (mono segfaults and dotnet is missing a library).\nI did install nuget, which depends on mono to fix the step in the first place. \nIIUC the tools are required for determining the version (which could possibly be implemented differently in the build project's GitVersionRunner?) and to format the code.\nIf you want, I can try messing around with both these issues.\nDo give me a heads up what type of solution you had in mind :). Sidenote: I'm currently running into issues trying to replace GitVersion.CommandLine (3.6.2) as Tool-Dependency with GitVersionCommon (4.0.0) as NuGet package. The NativeBinaries from LibGit2Sharp are currently binding to curl & openssl with a version apparently deprecated for security reasons.\nLibGit2Sharp is looking at replacing that native binding, but unfortunately that has not happened yet. As such I am unable to replace the GitVersion related code right now.. @ryangribble were you thinking something along these lines? Happy to make some more adjustments :+1:. > We should skip the \"ToolInstaller\" of Gitversion and CodeFormatter tools when running in this mode (since it will fail if mono/nuget etc arent present)\nDone\n\nThe code formatter also wouldn't work on linux/mac without mono (it may even not work WITH mono, i havent tried!) so perhaps that build task should log a warning if it is ever executed in NoFramework mode rather than trying to do stuff and blowing up (assuming it does blow up!)\n\nThe code formatter only runs on windows in the first place, but since we're not downloading the tools for CoreOnly builds, I added an explicit check to the ShouldRun implementation of the task.\n\nyou could change default behaviour of build.sh to run in NoFramework mode by default (so things work for linux/mac local users \"out of the box\". But then change travis.yml so that it still builds the full framework stuff on tarvis\n\ntravis invokes the buildscript. Changing the buildscript's default would involve creating an explicit switch to turn off the default. My bash is somewhere between bad and gruesome, so I don't want to mess around there\n\nI wonder if it would be clearer to name the mode \"CoreOnly\" rather than \"NoFramework\" and invert the logic (!$NoFramework in the csproj conditions is a bit of a confusing double negative)... thoughts?\n\nAgreed and done. @ryangribble could you kick travis for me? It seems there has been a timeout in the LinkSources check. Anytime :). @ryangribble poke: what's the latest on this?. @ryangribble poke: Do tell me when I start to seriously annoy you with this, otherwise I'll keep more or less regularly poking you here :wink: . rough quick-patch: Add <CoreOnly Condition=\"$(CoreOnly) == '' and $(OS) == 'Windows NT'\">False</CoreOnly> to all property groups involved? Can you verify for me that this fixes the native windows build?\nAlternatively <CoreOnly Condition=\"$(CoreOnly) == '' and $([MSBuild]::IsOsPlatform('Windows'))\">False</CoreOnly> seems to be the preferred solution in the issue you linked. . ",
    "jcansdale": "Sorry, I didn't mean to target upstream. \ud83d\ude0a\nClosing.... ",
    "astrohart": "@shiftkey Well, golly gee wilikers!  But the docs at here clearly show the line\nvar tag = await client.Git.Tags.Get(\"octokit\", \"octokit.net\", \"v1.0.0\");\nThe third parameter above is called reference and the relevant parameter of ReferenceClient.Delete is also called reference which is misleading.  I think it does not matter what summary comments are in place, but there are no docs on https://octokitnet.readthedocs.io for this method and I am using the fact that parameters named the same should take the same data.  Or at least the value of a (from above) tag.Ref property; that would seem to make intuitive sense.  Here, tag.Ref property would have the value refs/tags/v1.0.0.  When I glibly throw it in to ReferencesClient.Delete then the URI is formatted improperly.\nI am going to submit a pull request with some more fault-tolerant code.\n. @shiftkey, thanks for pointing that out, and you're correct.  This code works:\n```\n       / Assuming the client variable is a GitHubClient that is properly authenticated and\n          that repoOwner and repoName reference a repository to which I have full permissions /\n    var refs = await client.Git.Reference.GetAll(repoOwner, repoName);\n\nforeach (var tagRef in refs)\n{\n    if (!tagRef.Ref.Contains(\"v0.7.3\"))\n        continue;\n\n    await client.Git.Reference.Delete(repoOwner,\n        repoName, tagRef.Ref.Replace(\"refs/\", string.Empty));\n}\n\nHowever, the extrastring.Replacecall just seems so superfluous.. Created pull request #1934 to fix this, by adding code to the ApiUrls.Reference method's second overload to remove occurrences of the stringrefs/from the value of thereferenceName``` parameter before formatting the URI.. @shiftkey The change I propose is pretty fault-tolerant.. ",
    "mzolotarenko": "@shiftkey, by 11 records I meant 11 commits. And from my point of view it's not a case of big data querying.. ",
    "aurecchia": "Hi @ryangribble ,\nThank you for the quick reply. Yes, I was more interested in avoiding other requests. I assume that when you wrote \"without making and additional call\" you had the contents endpoint in mind, correct?\nIn any case this is just for an internal statistics tool, nothing that needs to run in production, and having empty repositories is an exception, so for now just checking the size should be  fine. \nI'll keep in mind that the graphQL API as an alternative, thanks for the suggestion.. ",
    "matt-richardson": "Thanks for the quick response. Whats your thoughts around when this could make it into a release?. ",
    "shahabhijeet": "@shiftkey I was able to get more details, now I get this\n{\"message\":\"Validation Failed\",\"errors\":[{\"resource\":\"PullRequest\",\"field\":\"base\",\"code\":\"invalid\"}],\"documentation_url\":\"https://developer.github.com/v3/pulls/#create-a-pull-request\"}\nAnd so far I have tried the format for base as\norganizationName:master\norganizationName/repositoryName:master\nRepositoryName:master\nnothing seems to work.\nSo what would be good to know is, if I had to create a pull request from my fork against octokit master branch, what are the values I should be using for head and base\nis it\nHead ==> shahabhijeet:branchName\nBase ==> octokit:master or octokit/octokit.net:master or octokit.net:master. @ryangribble is creating a PullRequest from user fork supported?\nIf yes would be great to get a sample on how to create a PR. Appreciate your help.. Got it working the following worked for me\nIf I am creating a PR from my fork (shahabhijeet) and branch (bugFix) against octokit.net  master branch\nNewPullRequest newPr = new NewPullRequest(\"Myfirstpr\", \"shahabhijeet:bugFix\", \"master\"). ",
    "guilhermemoschen": "Yes, I think I can try to do it ;). ",
    "benmcmorran": "I initially ran into this when I was attempting to write a tool to download a bunch of C/C++ repos, but most of my results ended up being Java instead. That's a good catch though about C++ not actually returning C++ results. I had only played with the web search, which does correctly handle c++ as a language. Looking back at my results, it looks like I only ended up with C repositories in my dataset.. I pushed another commit to fix the C++ case.. ",
    "aroben": "You can remove the -e whatever flags. Those are used by GHfW to keep those files around to speed up subsequent CI builds, but I don't think you have those files in Nocto?\n. Probably want to remove this right?\n. ",
    "mihaimaruseac": "Note: Always use a sane editor like Vim or Emacs.\n. ",
    "kiwipom": "formattedParameters ?\n. ",
    "Kaneraz": "Ah, sorry about that.. ",
    "tyadav492": "path parameter is not accepting any special char like '#' and space. I am trying to retrieve files form directory and i am getting not found exception and under same root directory it is getting all file which does not have any special char.\nI have two sub directories : 1) C# Code  and 2) TestApp. i am able to access TestApp but not \"C# Code\" as it is throwing not found exception. suggest me any solution for this as i am not able to rename the directory sue to some reason.. "
}