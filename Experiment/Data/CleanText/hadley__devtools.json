{
    "hadley": "Have a go with the latest version - I think I've fixed it.\n. I've now decided this isn't necessary - install() will get you this behaviour, and it's nice to be able to interactively experiment with internal functions during development.\n. The problem is that I have no control over <<- - it's always going to work in the global environment, instead of the environment in which devtools is loading all the other code.  Could you provide a bit more info about what you're doing with the globals?  There might be a better way to set them up.\n. You've made two changes in that code - one to source then attach, and the other to use global environment as the parent.  Would you mind testing to figure out which is the important change?\n. Thanks Jeff - I'll incorporate that change when I get a chance\n. Hmmmm, this change breaks with S4 because of the way method tables work - the environment needs to be attached before the class definition functions are run,\n. Yes, it's hard to replicate regular package loading exactly because so many of the key functions are internal, and nothing is really documented.  One day I'll be able to do better!\n. Not so important now that devtools makes it easier to build packages on windows.\n. Outside the scope of the package.\n. In general, need better run time dependency checking.  For development versions, maybe specify a date that is checked against the Packaged description field?  (Plus check to ensure that you couldn't distribute a package with such a dependency).  Also need to look at what ruby gems do.\n. Not needed - better to use standard R version system.  See gganova for one approach to this, and ggplot + scales for another.\n. I've had that problem intermittently too, but I've never been able to track it down.  Are you using my roxygen or cran roxygen?\n. One possible means of tracking the problem down would be to create a file called Users inside your package directory.  Then when roxygen tries to create that path, it will raise an error, and the traceback should help me narrow down the problem.  Thanks!\n. I'll close it for now.  If you do manage to recreate the problem in the future, maybe trying to make a file that the current process can't write would force the issue.  Thanks!\n. Fixed some time ago :/\n. Done.\n. What version of R are you using? It's definitely find.package in 2.13\n. Which problem persists? Issues are bit easier to work with if you stick to one problem per issue.\n. I'm not sure how to fix this bug - it's because when you load a new package it gets placed in the search path before your package, and so it can't find the functions. I'm not sure how R resolved this pre-namespaces.  \nYou can work around it by doing load_all(\"pkg\", T) after the package has been loaded.\n. For posterity, here are a couple of things that I thought might work but didn't :(\n```\nload_all(\"ggplot2\")\nsetHook(packageEvent(\"maps\", \"attach\"), \n  function(...) load_all(\"ggplot2\", TRUE))\nlibrary(maps)\nm <- map_data(\"world\")\nsetHook(packageEvent(\"Hmisc\", \"attach\"), \n  function(...) load_all(\"ggplot2\", TRUE))\nmean_cl_boot(1:100)\nmean_cl_boot(1:100)\nload_all(\"ggplot2\")\nsetHook(packageEvent(\"Hmisc\", \"attach\"), function(...) {\n  env <- as.environment(\"package:ggplot2\")\n  detach(\"package:ggplot2\")\n  attach(env, name = \"package:ggplot2\", warn.conflicts = FALSE)\n})\nmean_cl_boot(1:100)\n``\n. I'd rather figure out how to solve it properly ;)  I'll keep thinking about it.\n. There are hints at a solution at: http://stackoverflow.com/questions/8637107/parent-env-x-confusion.  Devtools needs to generate an appropriate namespace environment that the package environment inherits from.\n. All suggested packages are now loaded automatically to work around this problem.\n. Have you lookeddev_mode? \n. Could you please also re-document?\n. Yeah, generally you shouldn't check in derived files, but R packages are pretty useless without them, so I tend to check them in. \n. Yeah, build is not exported, because I didn't realise anyone would need it.  What are you using it for?\n. I think you wantR CMD build --binaryrather thanR CMD install --build, and you'll now get what you want withbuild(\"CIPinnipedAnalysis\", binary = TRUE).  Please let me know if you have any problems.  I'll probably push a new version of devtools to cran by the end of the week.\n. Ooops, just pusheddirname` fix.\nAs far as I know R CMD install --build is now deprecated, and you can't expect it to continue to work in future versions of R.\n. Can I ask why you're moving to r-forge?\n. One of the motivations for devtools is to make it easier for my users to get development versions, and install_github does make it pretty easy.  I figure if you want to try using a development version it's worthwhile to have a small barrier for entry - if you're not willing to put a little time into it, you're probably not the right person to be trying an unreleased version.\n. Are you using roxygen2?  Document just calls roxygen, so any issues should be filed at https://github.com/klutometis/roxygen\n. I think that should fix it.  Would you mind testing?  Thanks!\n. Ooops, that's an error!  I'll fix it when I get a chance.\n. Fixed.\n. So that dependencies are looked for in the right location.\n. And when that's done, modify run_examples(strict = T) to install the package in a temporary location, modify libpaths and then use library instead of load_all\n. Did this actually happen to you?\n. I think devmode could check that all directories below the path look like packages (i.e. they contain a DESCRIPTION) file, and issue a warning if not.\n. Oh good point.  A better check for a built package is the the R directory contains an .rdx file, or there is Meta directory with Rd.rds\n. Oooh, I ran into this yesterday.  Thanks for the fix!\n. This is fixed in R 2.14.  Until then, use the cran version.\n. I like the idea, but a better implementation would be to just use normalizePath(x, mustWork = F).  Then we should have separate error messages for the directory not existing and the directory not being a package.\n. Hmmm.  In that case str_replace(normalizePath(path, mustWork = F, winslash = \"/\"), \"/$\", \"\") should do the trick.\n. I just checked the code and it should be loading both imports and depends packages.\n. Currently the namespace roclet doesn't modify DESCRIPTION.  It's on the to do list. \n. Reproducible code:\nR\ninstall_github(\"mcmcTools\", \"cboettig\")\ninstall_github(\"wrightscape\", \"cboettig\")\n. You can set envars: see tempfile\n. Works for me - which I think means that you need to set TMP to point to a writeable directory.\n. Would you mind extracting out an install_url function?\n. Hmmm, that's really a roxygen2 bug.  But devtools could use with_locale more librerally\n. Are you sure? What version of R are you using?  I get this:\n``` R\n\nstr(.Platform)\nList of 8\n $ OS.type   : chr \"unix\"\n $ file.sep  : chr \"/\"\n $ dynlib.ext: chr \".so\"\n $ GUI       : chr \"X11\"\n $ endian    : chr \"little\"\n $ pkgType   : chr \"mac.binary.leopard\"\n $ path.sep  : chr \":\"\n $ r_arch    : chr \"x86_64\"\n``\n. Hmm, weird.  Could you please also provide yoursessionInfo()`?\n. Fixed in 7b5056cfc88485e218c8ae06a2f1c6ac53919af5.\n. This is a good idea, but now I think it's outside the scope of devtools.\n. I like the idea, but I think the current prompt is too verbose.  I think it should be short enough that it can be turned on by default.  \n\nAlso the .old_prompt variable shouldn't live in the global environment.  Use local to create a place for it to live.\n. I don't know if I'd describe it as popular, but as far as I know it's the nicest idiom for expressing that task.\n. Could you please also add a note to the NEWS?\n. See extensive discussion in #3.\n. Not obviously possible - and discussion with Luke suggest it's a bad idea.\n. Do you want something more than what tools::resaveRdaFiles provides?\n. Well, the actual check is already called as part of check(), and it's not something you need to do very often, so I'd prefer to leave it out to keep the package simpler.\n. Oh hmm, I'm pretty sure the message used to tell you to use that function - that's how I found out about it.\n. I like it - I'll pull it in when I'm next working on devtools.\n. Could you please give me the output from has_devel\n. Could you please try:\n``` R\nbuilt_path <- build(pkg, tempdir())\n  devtools:::R(paste(\"CMD check \", built_path, sep = \"\"), tempdir())\n```\nwhere pkg is the full path to your package.  Something must be going wrong with the generation of the R CMD check command.\n. Ok, can you please run the following code and report the output?\n``` R\nr_path <- shQuote(file.path(R.home(\"bin\"), \"R\"))\noptions <- paste(\"CMD check \", pkg, sep = \"\")\nif (.Platform$OS.type == \"windows\") {\n  lc <- \"(SET LC_ALL=C) && \"\n} else {\n  lc <- \"LC_ALL=C \"\n}\npaste(lc, r_path, \" \", options, sep = \"\")\n``\n. I'm closing this issue since it seems like a StatET problem.\n. How about having a file calleddevtools-install.rin the root directory of the package?  It would besource()d on install.\n. Actually, I think it would have to bedevtools-build.rand it would be run prior to build.\n. No, scratch that, because then that would cause problems when you're working on local projects.\n. I think my main question is whether this script should run for both and local and remote installs, or just remote.  If just remote, it may need a slightly different name.\n. Or is that better to do in a make file?\n. I think I'm going to close this issue - it's relatively low priority and I think should probably be solved server side with better systems for automated building of R packages.\n. 1. I'm not convinced this problem shouldn't be solved by providing built packages from the build system (e.g. travis). Then existing tools take care of making sure the correct versions of build-time dependencies are installed.\n2. Can't rely on makefiles because many users won't have make. \n. 1. Yes, those tools are a pain currently, but I think that's the right approach to the problem. If, for example, r-forge was actually a distributed R build server, we probably wouldn't be having this conversation.\n2. A window user installing a package without compiled code does not currently need Rtools, and so does not have make. Also not sure ifmakeavailable on the OS X command line without installing the xcode command line tools.\n. @krlmlr Can you please start a new issue? I think the important things to discuss are how to record build time dependencies (version BuildDepends field) and what operations should be baked in.\n. Can you please try with the development version? I  think it's fixed there.\n. Could you please send the output fromhas_devel()andsessionInfo()?  Thanks!\n. Weird - it works for me. It may be something to do with your long temporary directory path - for metempdir()gives\"/tmp/RtmpmPFSaB\". Are you still having this problem with the latest devel version?\n. Could you trySys.setenv(TMPDIR = \"/tmp\")and then re-installing.\n. Hnnnm that did'n't seem to take.  Can you have a look in that temporary directory and see if there's anything there?\n. Closing, since I can't reproduce, and no one else seems to be having the problem.  Sorry!\n. What version of devtools are you using? Can you please try the development version?  \n. Could you provide the output fromRCurl::curlVersion()- it may be that RCurl on windows is not supporting the correct ssl version.\n. Weird - that all looks ok to me (not that I know much about Curl).  I'm at a loss.  \n. The namespace reordering is a bug in roxygen2 and should be fixed in the next release.  I'd rather not add features in devtools to work around bugs in other packages (especially when I also maintain the other package!)\n. I like it - should be simple to implement too.\n. Fixed in df9accc93f85a01cd222185e6c7f19bb6746b0fa\n. Could you please add a note to NEWS, and then I'll pull in.\n. May want to attempt to do it a function at a time to make checking easier.  Key piece is probably to install package in temporary library, and then use appropriate libpath environment to evaluate code.   This may be a simple hack torun_examplesto useclean_source` with appropriate libpath. \n. Should also return timings for all examples, and have option to continue on error.\n. Are you using the development version?  The code looks like it should work:\n``` R\ninstall_deps <- function(pkg = NULL) {\n  pkg <- as.package(pkg)\n  deps <- c(parse_deps(pkg$depends), parse_deps(pkg$imports), \n    parse_deps(pkg$linkingto))\n# Remove packages that are already installed\n  not.installed <- function(x) length(find.package(x, quiet = TRUE)) == 0\n  deps <- Filter(not.installed, deps)\nif (length(deps) == 0) return(invisible())\nmessage(\"Installing dependencies for \", pkg$package, \":\\n\", \n    paste(deps, collapse = \", \"))\n  install.packages(deps)\n  invisible(deps)\n}\n``\n. I really like the idea, but I'd prefer a somewhat different implementation - could you please pull out the version finding code into something likefind_version_from_date?\n. I'm going to close this for now - I think this probably belongs in a more general package bundling framework.\n. I've made all the install methods pass ... ontoinstall.packages- I'd rather do this than special casing every install option ;)\n. I think you're missing a function of the style:bisect <- function(pkg, fun) {...}, which sets up all the scaffolding and then starts the bisect.\n. I was expecting thatbisect_load_and_testwould automatically create those skeleton files.\n. Ok, that makes sense.\n.read.dcf(\"DESCRIPTION\")[[1,1]]. \n. You'll also need thecharacter.onlyargument tolibrary`.\n. Duplicate of #74\n. Even more minimally:\nR\nload_all(\"lubridate\")\ndocument(\"lubridate\")\nwhich is presumably happening because we get two sets of classes defined in two different environments.\n. Probably the best solution to this is to run in a separate R instance, and some how manually capture the caches and save to disk.\n. Another approach\n``` R\nlibrary(parallel)\nsafe_expr <- function(expr) mccollect(mcparallel(expr))[[1]]\nsafe_expr(a <- 1:10)\nsafe_expr(library(ggplot2))\na\nqplot\n``\n. I think you'll need to ask Dirk and Romain what the preferred way to do this during development is.\n. The main thing is actually ftpUpload. I do realise RCurl is a bit more of hassle for Linux users, but the focus of devtools is really on windows and mac developers. I expect that people on Linux should find installing packages and compiling from source a little easier. \n. I did have it as a suggests originally, and I do wish it wasn't such a hassle to install, but I think it makes a lot of things easier to write.  I wish that there was a better C/C++ lib - I don't know if you've actually looked at curl at all, but it is totally crazy.  All operations are controlled with global flags and there only like 3 functions that actually do anything.\n. Are you using the Rgui?\n. The basic problem is that the RGui doesn't inherit the environmental variables from the command line.  This is one reason that I prefer to use the command line for everything.\n. I'd recommend working withinstall_url- then all other install methods will follow natural.  I thinksubdiris probably an ok param name.\n. I wonder if we also need aninstall_rforgefunction.\n. Anyone have any repos I can test this on?\n. Hmmm, yes, because I'm checking for a specific directory on the path, rather than for the availability of certain executables.  Maybe I should check ifls.exeandgcc.exe` run ok, and if not, warn that rtools is not installed in standard location, or that paths are not set correctly.\n. Could you please run \nR\n  loc <- unname(Sys.which(c(\"ls.exe\", \"gcc.exe\")))\n  all(loc != \"\")\nand let me know what the result is?\n. I fixed the first commit on the plane.  What does the second one do?\n. Would you mind rebasing on to master?\n. Oh, could you also please add a note to the news?\n. It will when 2.14 comes out.  But also note that CRAN runs R-devel.\n. Oh hmm.  Do you need anything apart from the ability to supply additional command line args?\n. At end of version.  10 characters from sha.\n. So I read the R version definition more closely and it's not possible to add it to the version.  So I think we'll need to add something to the description, and then write functions to display it automatically.\n. Is there any way to get that off github (for install_github)?\n. I now don't see this approach working at all - I think it's better to rely on carefully incrementing version numbers (even if those versions never end up on CRAN).\n. This looks really great thanks!  But there's some conflict between the documentation you generated and the existing documentation (my guess would be line endings) and it's creating a lot of spurious changes.  Could you resubmit without roxygenisation so I can more easily take a closer look?\nThanks!\n. Thanks! I've added a few style comments.\n. Looks good - I'll pull in the next chance I get.\n. Could you please rebase against master?\n. That's a bad error message - it should complain that that url doesn't exist.\n. Duplicate of #82\n. Hmmm, I wonder if I also need to quote it in system.r\n. But how do you use this in practice?  It seems like devtools needs someway to override system.file when loading packages.\n. Or even better, I could have a standard environment that pkg_env inherited from, which could contain all the functions that devtools needs to override.\n. I'm going to close this pull request because I think something based on environments is a better approach, but it's not obvious how that would work.  Initial exploration (which doesn't work) at https://github.com/hadley/devtools/tree/system-file\n. Is there a reason you're not setting .libPaths() ?\n. Hmm, that's kind of the point of dev_mode but I can see it wouldn't cover all cases.  I'll implement as part of #69\n. And should randomly reorganise answers to force you to actually read them.\n. Again, this should probably actually be a job for roxygen2.\n. Hmmm, I suspect it's some corruption or failure to download of the zipfile.  Can you try and get a copy of (e.g.) /tmp/Rtmpd7zQav/RWordPress.zip and see if it looks ok?\n. How many bytes is the file?\n. And are you using a proxy?\n. Hmmm - maybe because https://github.com/duncantl/RWordPress/zipball gives a 404? And https://github.com/duncantl/RWordPress says \"nothing to see here\"\n. Once I get httr on CRAN, I can use it, and then it should be possible to give more informative errors in case of http problems - I suspect that's what's happening here.\n. Would you mind removing cd from this pull request? I think it needs a bit more thought - you can already do setwd(\"../../..\")\n. I manually merged in the commit with the typo fixes - thanks!\n. Ooops, thanks!  Would also mind adding a small note to NEWS?\n. I think the current solution is to do load_all(ggplot2, T)\n. Hmmm, yes, this is basically a problem because I can't figure out how to imitate a namespace.  I'll have another shot at it this summer.\n. Do you think you could contribute a couple of minimal packages that I could use as test cases for this?\n. I think that's fixed in the devel version.\n. Hmmm, I wonder if this should just be the default behaviour - you are using __dev__tools after all!\n. I was wondering why devtools shouldn't always assume you want to keep the code.\n. What would the consequences be of making this the default behaviour?\n. A few more small changes - thanks!\n. Could you please also add a bullet point to NEWS, including crediting yourself?\n. Could you please check I correctly captured your logic?  It works for me on windows with R 2.15.\n. I think this is resolved in the latest version of R - and if not, Duncan Murdoch has been working on it to improve it whenever you're using source/sys.source.\n. See options(show.error.locations) in 2.15.1\n. Can you please update your branch to master so I can easily pull? \n. No pressure, but this is the last thing I need before I can release the next version of devtools ;)\n. Looks good - thanks!\n. Cool - thanks!  Could you please also point me towards an R package on bitbucket that I could test the code with?\n. Thanks Winston - I've closed this and fixed the problem in staticdocs.\n. Thanks Winston!\n. Do you know your proxy settings?  You might be able to do:\nR\nlibrary(httr)\nset_config(use_proxy(...))\ninstall_github(...)\n. Unfortunately it's just too much of a hassle to support download.file :(\n. Fixed in the dev version.\n. Can you please try the dev version?  I think it should be fixed. \nYou should be able to bootstrap yourself up with \nR\nlibrary(devtools)\nsource_url(\"https://raw.github.com/hadley/devtools/master/R/zzz.r\")\n.onAttach()\ninstall_github(\"devtools\")\n. If sourcing doesn't work, try copying and pasting.\n. I go back and forth on this, but generally I think it's good practice to add a user-readable note to NEWS at the same time you make the change - usually you want to word things slightly different for users vs. developers.\n. This may actually be a more appropriate job for roxygen - it could inspect the source code for the function and only add if there wasn't already an exist import for that function.  That would make it easier to override when there are multiple possible choices.\n. Moved to https://github.com/klutometis/roxygen/issues/105\n. Could you please also add a bullet point to NEWS?  (just add it above the last version's header)\n. Merged and pulled in 2b4270918519c629142d79f76b85cb9faec406f3\n. Thanks!\n. No - and I don't see an easy way to do this.  You can use show_rd to see the documentation for a file in a source package though.\n. It's moderately difficult because you need to build up an index from topic to Rd file by looking at all the Rd files.\n. Hmmm, the problem is then keeping the index in sync after you roxygenise - although I guess document could also update it.  And I think we'd just modify show_rd so it could either accept the name of a topic or a file name.\n. Hmmm, I could probably figure out how to create those files with roxygen, and then people would have to put them in .gitignore or similar. \n. I think this will be called dev_help or maybe devhelp\n. I wonder if using normalizePath is sufficient\n. I like the idea, but I'm still conflicted on requiring an external git dependency, and when I went down this road before I couldn't figure out where to draw the line - what git functions should be wrapped?\n. Is it possible to easily install from a specific tag?  If it's easy to do from the url, that'd be a nice feature to have.\n. And maybe this should actually be two methods install_svn (or maybe install_svn_url) and install_svn_bioconductor ?\n. Can you remind me again why this is necessary? You can get development versions of all bioconductor packages from the dev repo.\n. Another option would be to write a minimal svn client: https://gist.github.com/3494506\n. Given the lack of discussion, I'm going to close.  We can re-open if you have a strong use case.\n. You can do show_rd(, \"filename\") - I'd rather not start making exceptions to the basic devtools syntax.  That said, I think I'd like to explore the options of overriding ? to make it possible to access development help like you access normal help.\n. It should be even simpler than that - with simple authentication you should only need to pass the correct user/password combo to the standard install_github GET request\n. Hi Laura,\nDoes the package .tar.gz file actually exist?\nHadley\n. Hmmm - why are you using Rtools 216?  I think you want Rtools 215.\n. Could you check the output when you run build()?  If you unzip the package that it creates, does it look ok?\n. Hmmmm, I wonder if it's because there's a space in your path name - could you try it from a different directory?  (If it doesn't work because of a space, it's a bug in devtools, but this will help me track it down)\n. No problems - glad you figured it out!\n. This will not be trivial - we'll need to replicate the parsing currently in tools:::Rd2ex\n. Cool!  Does it need a test case?\n. I think I like the basic idea (apart from using package.skeleton, which provides little additional value, and I particularly dislike extracting functions out of environments.  \nCould you please also read my style guide: https://github.com/hadley/devtools/wiki/Style ?\n. Pulled in with some Hadleyfication in d77b9ddab5b837dc7d3c55c718209af02ff388e8.  Thanks!\n. Thanks!  Fixed in spirit in dda2ab59c0ec7e71cf7525878fbbe4486879af67\n. I guess we'll need some tests for this too :(\n. NEWS?\n. Thanks! Ended up going in a slightly different direction, but the impetus to fix it was appreciated.  Let me know what you think of my changes.\n. Are you sure that's true?  I think vignettes are supposed to be self-contained - if you wanted to get data from data/, shouldn't you just be using the data() function?\n. That would be useful\n. I don't think we need to worry about it - the main point is to have flag that makes it possible to see if dev_mode is on.  To recreate it, you'd rerun dev_mode in the new session\n. If we go down this route, we need some way of indicating which devtools functions work with packages and which with paths.\n. I just meant we needed to be clear in the docs, not that the package objects (which most users will never see).\n. Fixed all the issues you mentioned - thanks!\n. (needs dev httr)\n``` R\nlibrary(httr)\nlibrary(stringr)\nhost <- \"https://api.github.com\"\nGET /repos/:user/:repo/pulls/:number\nr <- GET(host, path = \"repos/hadley/devtools/pulls/133\")\nstop_for_status(r)\nhead <- content(r)$head\nhead$repo$full_name\nhead$ref\nhead$sha\nGET /repos/:user/:repo/:archive_format/:ref\npath <- str_c(\"repos/\", head$repo$full_name, \"/zipball/\", head$ref)\nr <- GET(host, path = path)\nwriteBin(tempfile(), content(r))\n``\n. Looks good!\n. Looks good - merge whenever you're ready.\n. Does this still happen? Or is it fixed in recent R?\n. It would also be useful to make these functions available to help check/inspect your namespace file.  i.e. to completemissing_s3it might be useful to be easily able to list all the functions/objects not exported by a package.\n. Maybe that connects more closely to #36 - it would be helpful to have better ways to understand how functions are interconnected and what functions you have exposed to the public.\n. Fixes #118\n. I think this is ready to merge in.\n. What's the advantage of reading.Renviron?\n. But that's ok -R()` already captures your libpath from your current session.\n. Code (with corrections) moved to https://gist.github.com/3427128\n. But I don't think this belongs in devtools, because of the additional requirement on git.\n. This is a good idea, but now I think outside the scope of devtools.\n. Looks good!\n. This a roxygen bug - will be fixed in roxygen3/2\n. There are also problems with RCurl\n```\n\nunload(inst(\"RCurl\"))\nunloadNamespace(\"RCurl\") not successful. Forcing unload.\ngetClass(\"EnumerationValue\")\nExtended class definition ( \"ClassUnionRepresentation\" )\nVirtual Class \"EnumerationValue\" [package \"RCurl\"]\n\nNo Slots, prototype of class \"numeric\"\n``\n. Hmmm, weird, now neither do I.\n. I think that's becauseload_all` doesn't fully support S4 yet.  @wch will hopefully fix it soon :)\n. If you can recreate this bug with the latest dev version, please let us know.\n. That looks like an httr bug.  What version are you using? Have you installed a version from github?\n. I think that bug is from an old version of stringr?  I'd recommending updating all your packages.\n. Could it be that the dependencies aren't getting installed first?\nOn Saturday, October 6, 2012, Winston Chang wrote:\n\nI think there may also be a bug in install.packages() when Ncpus is\nlarge. Some of these packages fail to install when I use 32 threads, but\nsome install fine when I use 2. Yet more install fine when I use 1. Maybe\nthe problem is with Makefiles that don't properly handle that many threads?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/166#issuecomment-9195560.\n\n\nRStudio / Rice University\nhttp://had.co.nz/\n. @professorbeautiful I think that's a different problem - this is issue related to load_all not R CMD install\n. @jayweiler could you please file a fresh issue with a minimal reprex?\n. This is the first time we're adding an external dependency on git, so it will need some thought.\n. It looks good - I'll pull next time I'm working on devtools.\n. Cool - thanks!\n. Check for Sys.which(\"pdflatex\")\n. And pass --no-manual, --no-vignettes to build and check.\n. You do export(generic) and exportMethods(class) so I don't think this is a bug in devtools.\n. Duplicate of #161\n. I think this is probably also a duplicate of #161\n. Closed in fa70de671b8a76606c3f52e5ab301eb0de233149\n. @wch I think we need an environment of functions that need to be patched for devtools loaded packages - these would always be copied into the package namespace, and would include system.file to start with.\n. Since system.file only returns a path if the file exists, I think you can make the algorithm a little simpler.  Just look in look in \"/inst/x\" and if it's not in there look in \"/x\".\nYour other objections:\n- I don't care about find.package or path.package - system.file is the most commonly used\n- It only matters for functions in the development package, otherwise system.file should point to the installed locatio\n- We haven't encountered problems with lib.loc /libpath yet, so let's not worry about them ;)\n. Is this still a bug? Or was it related to the .libPath issues in check_cran?\n. Sounds good.  Not sure if the option to check is necessary.\n. For the  CRAN incoming version check, it would be good if we could pull that code out and perform it separately in release()\n. I was worried about the case where you run release(check = F), having just passed check(), not knowing that you haven't checked for existing cran package. \n. Could you describe your use case? I'd rather solve it in general a wrapper function, rather than having to add lib to every install function.\n. Ok, let's merge.  @jjallaire do you mind rebasing?  Thanks!\n. See also #171\n. Toss? I think our assumption for devtools is that users will have the latest version of R.\n. We don't currently have a good solution, but it's something we're thinking about at RStudio.\n. It isn't too technically challenging, but we need something that will also work for standalone projects, and we want to avoid making any data structure choices that restrict future innovation.\n. Closing because currently outside the scope of devtools.\n. Looks good, but could you please put spaces around =, and add a line to the NEWS? \n. It's not exactly the same, but it's getting closer each version.  Since we use imports and not depends, the depends code hasn't been tested as well, but bug reports like this help us prioritise features for new versions.\n. Yeah, this was probably related to the fact we weren't loading any packages in depends.\n. Closed in fa70de671b8a76606c3f52e5ab301eb0de233149\n. document runs load_all, which is needed because roxygen works dynamically, not statically, so needs to be able to load and execute all your code.  I suspect #188 will probably remedy most of your problems.\n. Can you try with the dev version? We recently checked a set of changes from JJ to improve C++ handling.\n. Works for me in a package with C++ code.\n. Oooh, you're using modules.  Could you please file a new bug (referencing load_all as the root of the problem)?\n. The problem is that I think you need more info: for a binary package to work reliably, you also need the OS and the R version.\n. But that also needs to be stored in the url somehow. OS probably isn't such a big problem (since there's the standard prefix difference), but R version definitely needs to be in there.\n. Closing, since storing arbitrary files on github has now been deprecated.\n. See https://gist.github.com/4485745 for unloading & reloading\n. Closing because outside the scope of devtools.\n. Maybe just an ignore argument?\n. It's because all the on.exits need add = TRUE :pensive: \n. It's so easy to install Rtools - what problem would this solve?\n. @jlaake If there's a problem with Rtools path detection, please report it - unless people report bugs I can't make it better. My experience is that it works in about 95% of cases: the last time I taught a class using it, all 20 or so windows users didn't have any problems.\n@bbolker It's not that I think it's a bad idea, I just need to understand the motivation. If it's relatively simple to make work, I'd be happy to accept a patch, although I'm not sure exactly where the problem might lie since devtools just wraps the standard R way of installing packages.\n173 is definitely fixable.\n. The other approach is to develop a better service for building binaries - ideally something that would watch a github repo and automatically build a package on specified events (e.g. every change, every day, every tag etc).\n. http://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2012/12/05#n2012-12-05 may also have something to do with it.\n. @jlaake yes, that's on the long term to do list.  The next version of devtools will attempt to remove the pdftex dependency.\n. Closing, but I'm happy to accept a patch if someone (e.g. @bbolker) implements. \n. Fixed in 3edb1f1\n. Did you set any options when installing Rtools?\n. Don't worry about reinstalling, I just wanted to know if you did something unusual. \nCould you please give me the output of utils::readRegistry(\"SOFTWARE\\\\R-core\\\\Rtools\", hive = \"HLM\", view = \"32-bit\") ?\n. Thanks for that - I figured out it was a bug in the branch where the registry entry wasn't present (which isn't commonly tested).\n. Thanks for those pointers - I think we definitely need to include that logic in devtools. And I agree we should only do the path manip when absolutely necessary.\nIf I do recode in R, is there some way we could both use going forward?  Should we consider an Rtools package?\n. Replaced with #214\n. Can no longer reproduce.\n. Looks good.\n. Tracking https://github.com/wch/r-source/commits/trunk/doc/manual/R-ints.texi is a good start.  That also finds https://github.com/wch/r-source/commit/c24fab3645e0d9dd95a05989163492d9d2da8fec#doc/manual/R-ints.texi\n. Ideally there would be some way to subscribe to the changes so we at least get notified by (e.g.) email, but I don't know a service that does that.  Maybe we could include it as part of the release process?\n. I'm trying out an RSS feed generated by http://page2rss.com/rss/e2ccc8ae441d2ff7a9f2f797a887bcba\n. We seem to be fairly reliably catching these, so I'm going to close\n. I think removing the Windows consideration is fine.\n. That's probably because .check_packages() probably runs the authors code somewhere.\n. Fixed and rebased against master.\n. Replaced with #214\n. Looks good - just need to add an entry to NEWS\n. Looks good!\n. Can we do this for check() too?\n. Just a strongly worded warning should be sufficient. It'll be helpful for classes. \n. Could you please rebase?\n. The downside is that you are no longer protected against Rd files that were created for previous versions of the documentation and need to be removed.  That's a much more common scenario for me, so I'd prefer the old behaviour.\n. Another option would be some ability to override these settings on a package basis.  Or have other special cleaning code that gets run automatically.  (e.g. for devtools it could print a message to check the internals manual).\n. Fixed in Dev version. \n. Ideas for test cases:\nR\nsetClass(\"A\")\nsetClass(\"B\")\nsetClassUnion(\"AB\", c(\"A\", \"B\"))\nwith exportClass(A, B, AB)\nAnd for depending on an external package:\n``` R\nsetClass(\"mle2\", \"mle\")\nsetClass(\"A\")\nsetClassUnion(\"mleA\", c(\"mle\", \"A\"))\nsetClassUnion(\"mle2A\", c(\"mle2\", \"A\"))\n```\nexporting all the classes and importing mle from stats4.\nThere are probably other edge cases, but I think those two would be the most common.\n. @wch There's nothing better - it's on my to do list next time I work on testthat.\n. Weird. But that makes me realise we also need an expect_null assertion. \n. Closed as duplicate of #214 \n. Yes, you are supposed to commit them.  It's a compromise, because otherwise the dependencies start to get heavy.\n. This is really a roxygen problem, so I'm going to close this issue.\n. This is a problem because recent versions of devtools avoid leaving latex build artefacts in your latex directory.  It does this by setting the latex working directory to a temporary directory, which obviously means it can't find your images.  It might be better to use -output-directory=DIR rather than modifying the working directory.\n. Or even better (maybe) just do a fake/partial package install and copy back in, a la compile_dll\n. RStudio takes care of, and otherwise outside scope of devtools.\n. Are you running the dev version? This should be fixed there. \n. If it doesn't work, can you please provide the output of system.file(\"extdata\", \"DellSurveyWave2.xlsx\", package=\"tbgSurvey\") run from within load_all()\n. Please installing the dev version using the instructions at https://gist.github.com/4506250\n. Can you try again now? I just pushed a better version.\n. Great, thanks!\n. That's an old version of devtools - just use the one from cran, and if you still have a problem please open a new issue.\n. While I don't object to this patch in principle, in practice I'd rather get the custom repository situation fixed first, and then build the supporting code for the user.\n. Well long term, we want to, but it's not something we've started working on yet.  Rather than code at this point, I'd rather see a write up of your proposed archive structure, and a discussion of the pros and cons vs. the CRAN system.\nOne way forward that we thought about was to develop a rails/sinartra application with an interface that mimics the current CRAN directory structure, but has a better backend storage mechanism, and would be easier to build something more intelligent on top of.\n. I don't know of any documentation - I think you'd need to reverse engineer it from the existing CRAN structure, and the source code for install.packages.  I don't think it's too complicated though.\n. Did we fix this?\n. Nope, it still fails:\n``` R\n\ntest_package(\"devtools\")\n  Checks : .\n  Dependencies : ..............\n  Documentation checks : ...\n  Compiled DLLs : ..............1\n  Imports : .....\n  Load: collate : ......\n  Load hooks : ...............................\n  Metadata : .................\n  Namespace : .............................\n  Rtools tests \n```\n\nso perhaps it's something to do with the path munging in the rtools tests?\n. When run from devtools::check() (but not otherwise), this line causes R to crash: with_rtools_path(\"inst/tests/rtools-2.15/\", Sys.which(\"ls.exe\"))\n. Doesn't seem to happen any more :smile: \n. Have you tried using sysdata.rda?\n. @imanuelcostigan - that's exactly the purpose for which sysdata.rda (well it's defined for internal use, but you should be able to export it) - it lives in R/ not data/\n. @wch I think this is a namespace bug - when export_all is false, datasets should still be available, even though they're not explicitly exported in the NAMESPACE\n. Maybe it's a bug in load_data - currently the dataset in data/ are getting loaded into the namespace environment - but maybe they should be loaded into the package env?\n. I made a quick fix to local4, but I'll come back to this again when I'm re-reading/re-writing the evaluation chapter.\n. Hmmm, the first problem looks like it's because you have .R and .r files in R/ and all the files in DESCRIPTION collate have .r extensions.  This may be a bug in roxygen (if you're using that to generate collate) or possible some sort of case sensitivity mismatch (if you're on windows)\n. It now installs for me.\n. That was fixed in f51994d70f0a577dd2d0f604877d82c5dbb2e866 - you'll need the development version.\n. @BrianDiggs plus another bug I fixed a couple of weeks ago. It's a bit harder to resolve for windows users, since I don't know how to easily install the dev version of devtools without devtools :/\n. @BrianDiggs but how do they get the devtools used to do the first build?\n. @CharlesCara in the interim, if you used RTools215 everything will just work.\n. @CharlesCara: yes, because they just changed that in the last week or two. Grrrr.\n. You shouldn't have to delete any registry entries - devtools should find\nthe correct version automatically.\nOn Monday, February 11, 2013, CharlesCara wrote:\n\nYes it works now. Thank you very much.\nAs a reference for anyone else who hits this problem, I needed to upgrade\nRTools to 3.0 and make sure the Windows registry had no reference to\nearlier versions of RTools.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/249#issuecomment-13373780..\n\n\nChief Scientist, RStudio\nhttp://had.co.nz/\n. I'll let @jjallaire tackle this one.   Thanks for trying it out!\n. Test package is for use outside of devtools - you want test()\n. Doesn't test_check avoid that problem? I think remember encountering that problem and writing some code to fix it.\n. Actually, looking at the first few lines of test_package, I see:\nR\n  # Ensure that test package returns silently if called recursively - this\n  # will occur if test-all.R ends up in the same directory as all the other\n  # tests.\n  if (test_env$in_test) return(invisible())\n  test_env$in_test <- TRUE\n  on.exit(test_env$in_test <- FALSE)\nso certainly the intent is to not get stuck in an infinite loop. If that's not working for you, could you please open a new issue with a reproducible set of steps? Thanks!\n. load_all(reset = TRUE, export_all = FALSE) should do it.\nIt does this because it's my expectation (and practice) that you want to test functions that the user can't see.  The role of unit tests is not to catch export problems.\n. Yeah, that probably should be an option for documentation too (and do same thing for run examples).  We need an easy way to tell devtools to run these command in a separate process.\n. @wch The downside of doing that is you can no longer interact with the tests (e.g.) with browser()\n. I'm going to put this aside for now - I don't think there's any solution that works better than the current approximation without introducing other major problems.  In the long run, we made be able to solve this within Rstudio, by taking advantage of existing Rstudio code for interacting with sub-processes.\n. Do you mean it would hash the downloaded file and compare it to your sha1?\n. I think this is actually a R5 bug.  Minimal reproducible example:\n``` R\nA <- setRefClass(\"A\", fields = list(x = \"logical\"),\n  methods = list(initialize = function(...) {\n    x <<- FALSE\n    initFields(...)\n}))\nA$new()\nquote <- as.character\nA$new()\n```\n. Response from John Chambers:\n\nNothing to do with initFields.  If you trace your redefined quote(), it's called from the <<- assignment of x.\nThe \"x\" element in the environment for the reference class object is implemented as an active binding in order to enforce the class when assigning the field.\nEffectively that makes the assignment behave like a reference class method, and so ends up doing as() and getting back to the malware version of quote().\nThe fix will be to  have a more bullet proof (and perhaps more efficient) version of the active binding generated for fields.  A better design anyway, but this will take a little re-organization because the current default binding function is generated by some code manipulation.\nMeanwhile the workaround is: Don't do what the revised subject heading says.\n. It needs to be run in an environment that can access non-exported objects so you can test them.  I'm not sure what environment I picked when I wrote testthat, but it's unlikely to the be right one, given that we now know way more about environments and namespaces.\n. I'm pretty sure it is right - it's run in an environment that inherits from the package namespace. Tests should be run there so they can access private functions/variables.  See #260 for real problem.\n. Could you please run find_rtools(TRUE) and include the output? Thanks!\n. I think I found the bug in my regexp - can you please try installing the (hopefully) fixed version at https://www.dropbox.com/s/xhyuwbjbzpvcb3i/devtools_1.1.zip and let me know if it works?\n. @Brent-Dickinson can you please try installing https://dl.dropbox.com/u/41902/devtools_1.1.zip ?\n. Try https://dl.dropboxusercontent.com/u/41902/devtools_1.1.99.zip and I'm working on submitting it to cran later today.\n. Did you explore the tar error?\n. I would start by reducing the paths so you don't get that tar error.\n. It's now called call_tree and I've fixed the wiki.  Thanks for pointing it out!\n. It'd be cool to make an interactive html version where you could expand and collapse...\n. Hmmm, we need to figure out what R CMD check does in this situation.\n. I think that must have changed, because I started using the C locale after a bug that took me hours to track down because CRAN was running my code in the C locale.\n. Hmmm, my reading of http://cran.r-project.org/doc/manuals/R-exts.html#Encoding-issues suggests that learning about non-ASCII characters during check is desirable - the best way to represent utf-8 in strings is to use the \"\\u123\" string escape.\n\nMaybe it should be conditional on whether or not the package has Encoding: UTF-8 in the description and the OS is not windows?\n. For devtools, it should be LC_ALL=C because that's currently the lowest common denominator on cran checkers.\n. Fixed in R-devel. \n. I'd rather they break devtools so we find out about them and fix them.\n. Again, this probably should be done by an alternative package distribution service.\n. Could you please also add a line to the NEWS?\n. And thinking about it more, can you provide a use case?\n. In the absence of a compelling use case, I'm going to close this. Feel free to re-open though.\n. Hmmm, I think it's generally best practice to check in NAMESPACE and rd files - R basically has no way to declare build/install dependencies, and it's common practice to install directly from a source code repo.\n. Yeah, I understand - I just think currently it's best practice for R packages to include NAMESPACE and rd files in the source, even though they're automatically generated.  Eventually devtools might gain support for pre-install actions.\n. Maybe just sessionInfo() ? \n. Do you want to add to source_gist too?\n. Closed by 3f3125c62b7853c0ea8c65d2e3f0c1da058eebdf\n. Fixed in c607d0f44a93fa596524622985f42af984a8cd1c\n. Thanks!\n. Looks good to me\n. Sure - at least a warning message would be useful: \"NAMESPACE has changed since last full reload\".\n. It's not the exports that's the problem - it's the imports.  i.e. you add @imports, document(), then load_all() and you can't find the function\n. This isn't too hard to add, but it's a lot of fiddly argument passing. It's not high on my priority list, but I'd happily review a pull request (I'd recommend starting by adding a dependencies argument to  install_deps)\n. Putting in .Rbuildignore is an acceptable compromise for now.\n. This is probably R's fault, but I'll take a look.\n. Yeah, all install_github does is download the package and then call R CMD install, so I think the blame is with R on this one.\n. Works for me, once I put the vignette in the vignettes directory (where it should live)\n. I can't reproduce the message - if there's nothing in vignettes, build_vignettes() does nothing for me.\n. I don't think it's possible to install an arbitrary version of an R-forge package without svn installed (and I definitely don't want to add a dependency on svn).  I don't think R-forge is a particularly good platform for developing R packages, so in general, this ranks fairly low on my priority list (but I'd review a pull request if one was provided)\n. Would you mind constructing one pull request that uses @importFrom digest digest and modifies the DESCRIPTION?\n. Please provide a reproducible example including exactly the error message\nyou receive.  Do you usually use a proxy to connect to the Internet?\nHadley\nOn Wednesday, May 1, 2013, boulby69 wrote:\n\nHello,\nI have tried to install r packgage from gihub especially rcharts an i have\nthis error message : http client error (403)\nI follow your steps with the lines command :require(devtools)\ninstall_github('rCharts', 'ramnathv')\nI retried for other packages and i have the same error message, so i think\nthe problem come to devtools?\nAny sugestions?\nBest regards\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/293\n.\n\n\nChief Scientist, RStudio\nhttp://had.co.nz/\n. It's probably a network configuration problem at your end.  You can however\nfollow the link\nhttps://api.github.com/repos/ramnathv/rCharts/zipball/masterin your\nbrowser, download the file and then install it with\ninstall(path/to/rCharts.zip)\nOn Wed, May 1, 2013 at 7:16 AM, boulby69 notifications@github.com wrote:\n\nHello,\nI want to install some R package enable on github like Rcharts for\nexample, but when i launch the R command : require(devtools)\ninstall_github('rCharts', 'ramnathv')\nand i have this message:\nInstalling github repo(s) rCharts/master from ramnathv\nInstalling rCharts.zip from\nhttps://api.github.com/repos/ramnathv/rCharts/zipball/master\nError: http client error (403)\nI am not behind proxy, butmaybe the problem could be a configuration of my\nfirewall box (internet provider)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/293#issuecomment-17277180\n.\n\n\nChief Scientist, RStudio\nhttp://had.co.nz/\n. @csgillespie It's likely to be a network config problem on the user's side. \n. You need devtools 1.2 (the current CRAN version) for this to work.\n. I can't reproduce with the latest version of devtools.  Can you please try again and if it still doesn't work, provide output from sessionInfo()? Thanks!\n. I just noticed that today too.  I'll fix in the near future.\n. Was fixed in d15962ece20fee55b3b22e2cda2e8250c32af4b0\n. Same as #292, and now fixed :)\n. @jjallaire any thoughts? What do you do for RStudio?\n. I think install() should probably be made to work on local compressed files.  This should be a fairly simple fix.\n. Roxygen2 actually tries to wrap the lines so they don't spill over, but I guess my threshold was higher than that for R :/.  I'll take a look in the next couple of weeks hopefully.\n. No advice currently, but we're hoping to solve this through some sort of build service.  Until then, unfortunately you need to figure out how to manage two separate R versions on your machine :(\n. Fixed in 414d6b6\n. Can you provide a pointer to the API docs?\n. Could you please check that this works? Thanks!\n. Would you mind describing your use case?\n. Cool, I'd love to talk about it in person.\n. Maybe a better strategy would just to be add an argument called git_args, a string that would be passed on as is to the git command.\n. Well that was easy ;)  Could you please also add a bullet point to NEWS, thanking yourself for the contribution?\n. Perfect - for future reference, a pull request tracks a branch, so as long as you work in the same branch you don't need to file a new pull request.\n. Fixed in d0d73e5, b7311bb, c9a0fa3, etc\n. Fixed by Duncan Murdoch in R, but should put in a temporary directory instead of inst/doc\n. No easy way to override the directory that buildVignettes() uses - probably responsibility of package author anyway.\n. What are you using the output for?\n. I think the easiest approach would be to wrap system2, which can send stdout and stderr to arbitrary files (not connections as I mis-remberered)\n. Yes - the way system tries to set environmental variables (pasting in front of the command) does not work across platforms\nI think there's some way to get the result code by looking at an attribute of the output.\n. Per discussion on R-devel, it looks like this would need a totally different approach.\n. Hmmmm, good question.  There's currently no way to pass build args from check() - perhaps it needs a parameter build_args? \nWhy don't you want a full multiarch build on windows?\n. Thanks - I never noticed this because I've set the option.\n. @wch is in charge of 2.15 compatibility, so he can have a look ;)\n. I think the original diagnosis and fix was incorrect - keep.source doesn't actually have any effect in this case, because I'm already explicitly suppling srcfile to parse.\n. You're going to need to provide a test case because we can't reproduce the problem, and we've also looked at the source code for all the r versions involved and can't see how it would have worked. \n. Can you please try installing https://dl.dropboxusercontent.com/u/41902/devtools_1.3.zip ?\nHadley\n. I like that idea better, but I still need convincing that devtools should add an extra support to r-forge (more than the current subdir argument).  I also don't like having install working differently to all the other devtools functions, and searching subdirectories for description files is substantially more difficult to explain and understand.  I don't think the r-forge layout is a particular common convention, and given the unreliability of r-forge, I don't think it's something that devtools should encourage people to use. I'm also not sure what you find unappealing about an install_rforge function.\n. Thanks, that's helpful.  Here's a quick point-by-point response:\n- CI: I really don't think that rforge is that useful for CI because it is so unreliable - i.e. some build servers will not work for weeks. On github you can use travis (http://yihui.name/en/2013/04/travis-ci-general-purpose/), and I expect other services will exist in the future.\n- Extra files: you can put these in the regular package structure, and ignore with .Rbuildignore\n- Multiple packages per repo: this is currently outside the scope of devtools.\nSo I really don't think there are any benefits to adopting the R-forge package layout, especially given that github has alternative conventions (e.g. the gh-pages branch)\n. I'd be willing to add an install_rforge function, but I'd prefer not to have special logic threaded through the rest of the installation functions.\n. I'd rather fix the collate roclet so it works correctly.  Why don't you want to use it?\n. FYI the next version of the collate roclet only actually does something if you need non-alphabetic collation.\n. Maybe this should go into https://github.com/klutometis/roxygen/pull/142 ? It's really something that should be stored in package metadata so that if multiple people are collaborating on the same package, they get the same results from roxygen.\n. @WastlM I did consider both of those options. The problem with a separate file is that you need to then add it to .Rbuildignore. The problem with a special tag is that there's no support in roxygen2 for \"global\" tags, so to find it, I have to spider through every code block.  \nIn an ideal world, there'd be some standard way of describing build-time vs. use-time dependencies in the DESCRIPTION, but that's unlikely to happen.\n. What if unzip just used unzip = getOption(\"unzip\") internally?\n. I'd appreciate you trying this out and letting me know if it fixes the problem.\n. Any thoughts on some simple tests?\n. Could you point me to a package that fails because of this problem?\n. Thanks. That's a really funky way of using .Rbuildignore! \n. Thanks. Could you please also add a bullet point to NEWS?\n. @kornl yes, you need to merge the upstream branch and resolve the conflict.  Thanks!\n. Would you also mind squashing the commits into one?  Thanks!\n. Can you tell me a bit more about your installation? c:/opt/ is an unusual place for R to be installed.\nAnd what do you mean by running it by hand?\n. FYI installing everything in paths with spaces should now work, as far as I know.  (And it's a bug if it doesn't).\n. We'll only go to 4 spaces over my dead body ;)\n. Closed in eb9ff03ef258f7d449eb24e2d853768712fe222b\n. It looks like the error is in document() not in check - try check(document = F)\n. I think Section 1.1.5 implies that you should either explicitly load utils in your data file, or use utils::read.csv\n. It's worth trying an explicit library(magrittr), even though it shouldn't have any impact.\n. I recommend using a data-raw directory for that purpose: http://r-pkgs.had.co.nz/data.html#data-data\n. It doesn't look like it.  What about patching check() to return r_cmd_check_path in the case of failure, and then you could add custom handling?  Alternatively, we could add the check_dir param to check() and pass that on down to check_r_cmd()\n. @sritchie73  I'd recommend noting this discussion in the bug report. Do you also have a long uid?\n. Closing, since it seems to be an R-core bug.\n. Oops, done!\n. How are you calling run_examples()?\n. I don't get that error with run_examples, but I do get a lot of warnings with load_all() and a few with document().  I'd work on fixing those first.   You might also want to check that you're exporting all the needed functions/generics by running load_all(export_all = FALSE)\n. I can't reproduce with a fresh checkout. If you can make a reproducible example I'm happy to look into it further.\n. Hmmm, actually there's a bit of a recursion problem here - to build the vignettes you usually need to have install the package first. So it might be better to install the package, then build the vingnettes, then reinstall. Not sure how R CMD build gets around this.\n. @rpruim probably not :( My sense is that CRAN is getting increasingly hostile to any additional documentation not generated by the vignette process. What additional files are you trying to include?\n. Could you please provide a reproducible example?\n. It does recompile the package, it just doesn't have to start from scratch.  Maybe it would be be better to describe local = FALSE since TRUE is now the default?  Build artefacts = .o, .so etc files, plus anything else your makefile might have made. In some sense local = FALSE is equivalent to make clean, then make.\n. @sfuj  It'd be useful if you could post the correct url\n. To fix this properly, we should probably use the github api to look up the correct url from the id. This would prevent it from breaking in the future if github changes formats again.\n. I wonder a little about the fragility of the comment parsing code. An alternative approach would be to use the github api:\n``` r\nlibrary(httr)\ngithub_sha <- function(owner, repo, ref = \"master\") {\n  url <- sprintf(\"https://api.github.com/repos/%s/%s/git/refs/heads/%s\", \n    owner, repo, ref)\ncontent(GET(url), \"parsed\", \"application/json\")\n}\ngithub_sha(\"hadley\", \"ggplot2\")$object$sha\n```\nOn the other hand, the comment is documented in https://www.kernel.org/pub/software/scm/git/docs/git-archive.html\n. Ok, I think that's reasonable, it seems relatively that unlikely that github would change their zipball without notice.\nOne other small style thing: can you please surround = with spaces?\n. There doesn't seem to be an automatic check/warning if there's no trailing newline in DESCRIPTION, so we need to handle either situation, and but we should probably be polite and leave a trailing newline (even though I don't think R depends on that)\n. It just occured to me that this isn't enough - we also need the username, repo name (might be different from package) and subdir. We want also want to flag if it's a private repo (i.e. needs username and password to download)\n. Looks good, but one last style change - can you please remove the extraneous return statements?\n. Sorry I meant NULL, not return (NULL)\n. Sorry forgot one last thing - can you please add a bullet point to NEWS briefly describing the change and crediting yourself?\n. Thanks!\n. @randy3k except that many packages don't use releases, and the goal of install_github() is to get you the latest dev version, not the latest released version (which you'd normally get from CRAN)\n@krlmlr how about something like install_github(\"user/repo@_latest\"), install_github(\"user/repo@_released\")?\n. @randy3k replacing CRAN is outside the scope of devtools.\n@krlmlr I don't think we need both latest and released. Maybe we should pick a name that otherwise can't be used as a tag - e.g. \"They cannot have ASCII control characters (i.e. bytes whose values are lower than \\040, or \\177 DEL), space, tilde ~, caret ^, or colon : anywhere.\". \n. @krlmlr Or we could go crazy and do user/repo@\u2022 or similar ;)\n. What do you want to do about it? Since R has relaxed the definition of a valid DESCRIPTION I think we should too?\n. Oh hmmmm, good question. You're the 2.15 compatibility expert.\n. That sounds reasonable. Can you add an explicit error message to the vignettes stuff for 2.15?\n. Could you please give me the output of .libPaths()? \n. The exact form of the path is super important - can you please just replace each directory name with a random string?\n. That's a network shared drive?  How are you setting your lib paths?\n. I doubt the write permissions are the issue - I'm just trying to figure out what's going wrong. \nDoes install.packages() work?\n. Could you please try installing the latest devel version by downloading https://dl.dropboxusercontent.com/u/41902/devtools_1.3.99.zip and then installing from a local zip file from within R?\n. Can you please confirm the output of .libPaths() has four slashes but the path printed out by install_github (after --library) only has two slashes?\n. And if so, could you try changing your .libPath() to use // and see if that works with devtools?\n. Another idea - can you bind that network address to a drive letter? Then try setting .libPaths() without any // or \\\\\\\\\n. You need to either do fromJSON(content(json, \"text\")) or content(json, \"parsed\")\n. Looks good. Can you please add a line to the NEWS crediting yourself?  (Add it under 1.4 since that hasn't quite made it to cran yet)\n. Thanks!\n. Thanks!\n. Do you still get this problem?\n. It should be at least invisible, and vapply would be nice.\n. Done in https://github.com/hadley/devtools/commit/3f3125c62b7853c0ea8c65d2e3f0c1da058eebdf\n. Patches are welcome ;)\n. Now done for local installs.\n. Moving away from this to putting including examples in unit tests (if needed)\n. Subsumed by knit in rstudio.\n. This hasn't been a problem lately, so I think it's no longer needed.\n. Would you mind also adding a bullet point to NEWS? We still haven't released 1.4, so it can go in the existing lists.\n. Perfect. Thanks\n. Could you provide a reproducible example? I can't recreate.\n. I think this is fixed in the dev version. Can you confirm @wch ?\n. I don't think we can fix this - install_version() only works with CRAN because it assumes the availability of a /src/contrib/Meta/archive.rds\" file.\n. Did you rebuild/re-install all your packages when upgrading to mavericks? You may need to.\n. I'm not sure if update.packages is adequate - it will check the R version, not the compiler version used to build the packages.\n. Also, try installing Rcpp from source\n. I'm reasonably certain that this isn't a devtools problem, because devtools just uses the regular R tools to install, but I may be wrong. I had to mess around quite a bit before I got everything compiling happily on Mavericks.\n. I wonder if it's because you have an non-ascii character in your path (\"Configuraci\u00f3n\") - could you try setting your temporary directory to a path with just ascii characters (with Sys.setenv(TMP = \"C:/simple/path\")) ?\n. Could you please send me the results of tempdir()?\n. Could you please send me the results of tempdir()?\n. Your error is unrelated to this bug. Please install the latest dev version of devtools. \n. Sure. I'd be happy to review a pull request.\n. Could you redo against master? Unfortunately it was just slightly too late to make it for this version\n. Closing for now, since I don't think this is a devtools problem.\n. @krlmlr just fixed those issues. They're run to discover exactly the sort of problem that just occurred :) (github changing how API requests need to be made).  I need to push a fix to cran for that problem, so I'll include this too, once @wch and I are happy with the parsing strategy.\n. @krlmlr what's wrong with the tests?\n. Can you rebase against master and squash please? Please also add a note to NEWS, and expand the repo param docs a little.\n. Thanks!\n. Seems to be fixed now.\n. Yes, patches are welcome ;)\n. Done!\n. This bug is triggered by pkgVignettes() which I use to determine if the package has any vignettes - so I think this is an R bug.\n. @lgatto as a workaround, remove the empty line at the end of your DESCRIPTION?\n. Why is rgl a dependency on devtools??\n. Thanks!\n. Also could you remove the bitbucket.user option - we're moving away from that to a full specification of the github repo and username.\n. I like that idea, but I think it's outside the scope of devtools.\nAnother approach is to put a browser()/breakpoint in the first line of the function.\n. I think this is a great idea, but possibly is a more natural fit for packrat.\n. This is out of scope of devtools, but I agree that it's an important. I think there are some other initiatives in progress where this will happen naturally - it's a common use case, and we won't forget about it.\n. Don't know of any mocking frameworks in R, sorry :/ Not even sure how you'd attack the problem - I guess you could temporarily functions in the right environment.\n. I think putting them all in create gets a bit heavy - create now will add an Rstudio project file because it makes the initial step much easier for Rstudio users. I tried that with testing but it didn't feel right, so I made test() add it if missing (and desired by the user). Then add_travis() is completely stand alone. I'm not sure what would go in a default README, and package doc boilerplate is already added by create.\n. I don't think it can be completely automatic, because people have different styles of grouping together tests into contexts (and it's domain specific). But we should be able to do better than nothing.\n. I'm going to close this issue since there's now add_test_infrastructure(), but I'll keeping thinking about the general problem.\n. Waiting on release of roxygen \"4.0.1.99\" for exports of is_s3_method\n. Closed in 94db7b2\n. Could you provide a simple reproducible example?\n. Ok - so the problem is only if there's a trailing empty line?\n. Ok, so this probably requires some refactoring of install_github() etc.\n. Fixed by #439\n. Thanks!\n. Should these packages be installed if deps = NA, or just if deps = T?\n. Here's one interpretation: deps = NA means (approximately) get run-time dependencies, and deps = T means get build-time dependencies. So it should be added only when deps = TRUE,  but install_github() should probably use deps = T since you have to build the package.\n. They're not intuitive, but they're standard for install.packages\n. I think it's important to have a BuildDepends field because that can be used to check that you have (e.g.) the right version of roxygen2.\n. I think this is best handled elsewhere. Currently install_github() is a very common way to install packages and having to run additional code before installation is going to add a lot of complexity. \n. I wonder what happens if I just remove this check. \n. Related to #173\n. That file doesn't exist any more - have you moved those definitions elsewhere?\n. Where can I get tmcn from?  \nAlternatively, would you mind creating a minimal reproducible package that illustrates this problem?\n. Could you please also add a brief note to NEWS.md?\n. Are you using the latest version of roxygen2? It should recreate the NAMESPACE file from scratch every time.\n. Are you sure you don't have another @importFrom x y elsewhere?\n. Ah, the problem is that document() first needs to run load_all() to load the package, and once you've broken the namespace there's no way to load it.  In this scenario I usually just undo the change in git. \n. Any chance that you're doing a lot calls to github? You might be getting rate limited.  You can get more details with\nR\nlibrary(httr)\nwith_config(verbose(), source_gist(\"https://gist.github.com/jeffwong/5101679\") )\n. According to the http spec, header names are case-insensitive so it should be fine.\n. Yeah, it looks like you've been rate limited:\n< X-RateLimit-Limit: 60\n< X-RateLimit-Remaining: 0\n< X-RateLimit-Reset: 1389134558\n. This is an R/OS setting. Have you read http://stackoverflow.com/questions/20408250/default-options-setting-for-unzip ?\n. I think this would be relatively easy to implement, but I don't know anything about how an internal github repo works. Is the url structure the same? How do you login?\n. Want to try submitting a pull request to add this functioanlity?\n. See also https://gist.github.com/mbannert/8403801 - I think this patch resolves that problem.\n. Right, you need to set the options in your .Rprofile.  But perhaps this whole technique relies on knowledge of how options that few people actually have, especially when you're just starting out developing packages.\n. I think that's a better idea, but it still needs to be controllable with options - I'm probably the only one who uses them, but they're super useful to me.\n. Yes, collate is no longer a roclet because it needs slightly different semantics. You can run update_collate() instead.\n. I'd recommend looking at the scripts we use for travis with R: https://github.com/craigcitro/r-travis/blob/master/scripts/travis-tool.sh\n. My expectation is that you'll create a NAMESPACE file using roxygen, so generating something by hand is potentially misleading.\n. Could you please update the docs so that R CMD check passes?\nI'd also wonder if we should deprecate auth_user and password in favour of this method.\n. You can deprecate like branch is deprecated\n. @jeroenooms could you please re-roxygenise. Deprecation with a warning would also be useful.\n. Unfortunately this is a base R problem. We've reported it, but R core is not interested in fixing it.\n. Either just use load_all() or use Build & Reload (in Rstudio, other IDEs may have something similar)\n. Have you looked at where that string occurs in the package?\n. It looks like an en-dash between 1171 and 1181. That's ok in utf-8, but windows doesn't support it. Change it to - and I bet your problem will go away.\n. @tbates I'd be happy to review a pull request that implemented that for roxygen2 ;)\n. It's not an embedded null - it's the dash between 1171 and 1181.  Look closely at the following two lines:\n1171\u20131181: copied from your comment\n1171-1181: manually entered hyphen\n. @klmr it's not obvious that it's a bug anywhere - if you put non-ascii in a file without a specified encoding, what is R supposed to do?\n. Thanks.  I'm also thinking about making the default to build on both r-release and r-devel. What do you think?\n. Awesome, thanks.\n. You probably had the dev version of httr installed which always sets a UA\n. From another package:\n``` r\nsha1 <- function(n = 10) {\n  sha <- git(\"rev-parse\", paste0(\"--short=\", n), \"HEAD\")\n  if (uncommitted()) sha1 <- paste0(sha, \"*\")\n  sha\n}\nuncommitted <- function() {\n  system(\"git diff-index --quiet --cached HEAD\") == 1 ||\n    system(\"git diff-files --quiet\") == 1\n}\n``\n. Done.\n. Do you use a proxy?\n. I can fix that withnormalizePath()`. @jjallaire might also need to the RStudio code.\n. Grrr, the docs say \"It will match paths case-insensitively and return the canonical case.\"\n. Would you mind trying again with this version?\n```\ndevtools::build_github_devtools()\nRestart R before continuing\ninstall.packages(\"devtools.zip\", repos = NULL)\nRemove the package after installation\nunlink(\"devtools.zip\")\n``\n. Sorry, try again, that was a dumb thinko.\n. Ooops, only fixed problem in one place. Try now.\n. That's just duringR CMD check?\n. Thanks! I've had that problem too, but never managed to get to the source. Given that it only seems to occur with RJSONIO, I'd wonder if something there is set up incorrectly in the NAMESPACE or dynamic function registration.\n. I've basically abandoned RSJONIO because of this problem. It doesn't seem worth the effort to figure out exactly what's going wrong.\n. You'll have to take that up with the shiny maintainers ;)\n. Looks good. A few minor points inline.\n. Great. Could you please add a bullet point to NEWS.md briefly describing the change and thanking yourself (via your github username)\n. Thanks. @jjallaire if you get a chance, it'd be great if the rstudio defaults matched this.\n. 1.POSTto http://xmpalantir.wu.ac.at/cransubmit/ with fieldsname,email,uploaded_file,comment.\n2. Parse response which should containpkg_id. Resubmit with samenameandemail. Addpolicy_check= 1\n. You might be able to work around it by setting the env car TMP to something without accents. \n. Could you please send me the results oftempdir()before the TMP var fix? I want to add an automatic warning message to devtools\n. @jjallaire is there a way to find out the default value ofgetOption(\"browser\")before it's overridden by Rstudio?\n. @jjallaire not high priority, but could rstudio learn to pass through unrecognised url schemes?\n. And it looks like it's NULL on windows\n. Definitelywith_options(c(scipen=999), ...).  I can't remember the exact case, but working with ... can be problematic in the restore step (on.exit(set(old)))\n. Thanks!\n. Ooops, thanks for the catch. Can you also thank yourself in the README? eg.(thanks to @brentonk). Thanks!\n. Maybe that's now just a matter of savingpackageDescription()somewhere?\n. Yes, better to useRemoteSha.\n. Maybe just replace line 229 withsession_info()`?\n. Thanks!\n. Thanks!\n. Thanks!\n. Yes, that's a good point.  But I'd like a bit more notification for the user. In httr, I have this code for informing when I get values from an env var:\nR\n  if (missing(secret)) {\n    env_name <- str_c(toupper(appname), \"_CONSUMER_SECRET\")\n    secret <- Sys.getenv(env_name)\n    if (secret == \"\") {\n      warning(\"Couldn't find secret in environment variable \", env_name,\n        call. = FALSE)\n      secret <- NULL\n    } else {\n      message(\"Using secret stored in environment variable \", env_name)  \n    }\n  }\n. Can you send me a reproducible example? It works for me.\n. I'm pretty sure you also need private repo checked.\nOn Thursday, March 20, 2014, Imanuel Costigan notifications@github.com\nwrote:\n\nMy fork is working fine for public repos. It's giving me 406 errors for my\nprivate repos. What options are ticked in your Account Settings >\nApplications > Edit personal access token (for devtools)?\nI have:\n1. repo\n2. user\n3. gist\nticked. The others are blank.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/442#issuecomment-38245062\n.\n\n\nhttp://had.co.nz/\n. I'm sure I tested it before I committed the original code, but it's definitely working now. \n. Thanks!\n. I wonder if it's better to get it from an envvar - I think that's more customary.\n. In that pretty much every package that stores sensitive data using env vars. it's no harder for the user - if they don't know the usual ways they can still use Sys.setenv\n. I merged in my own version since that seemed to be easier than telling you exactly what I wanted and then having you write it!\n(And yes, please leave pull requests open otherwise I'm unlikely to see them)\n. 1. As you are aware, CRAN maintainers sometimes require things that are not tested by for R CMD check. When this happens we add our own checks - this is why check() does more than just run R CMD check --as-cran.\n2. Sometimes our own checks add false positives. False positives are a part of automated checking.\n3. \"Never attribute to malice that which can be adequately explained by stupidity.\"\n4. We will fix the bug, and we're happy to review a pull request.\n. Closing as it's a dup.\n. Have no idea why I wanted this or where you would record it.\n. Closed in 312fab7\n. Done in 312fab7\n. Done in 6e5caadf0e4974bf410b22d7c00ae1af24964e23\n. Can you please provide a reproducible example (i.e. a pointer to your package) ?\n. It's suggests, not suggest.\n. Could you please provide a reproducible example? (i.e. a pointer to the package).  The fact that it's complaining about methods called . is interesting.\n. I'd say the problem is that your regular expression also captured files in the R directly. It's not obvious to me how that regular expression matched the wrong files, but it certainly matches the symptoms.\n. I'm thinking that the next major version of devtools should include this and other github related code.\n. Duplicate of #387 \n. The whole point of rstudioapi is that you don't need rstudio installed. \n@wch I think this means that rstudioapi should be in imports, not suggest.\n. I'm pretty sure rstudioapi belongs in imports, because the goal of the package is abstract away code which checks if rstudio is running. Adding extra code to check if rstudioapi is installed sort of defeats the purpose. (The check is probably coming from inside dev_help()\n. See comment on that issue - you probably have a non-ASCII character in the doc (this has bitten me twice recently)\n. Resolution is probably #507\n. Lots of things. Mostly changes related to R CMD check/R CMD build and vignettes.\n. Can you please do that? install_github(\"klutometis/roxygen\"); devtools::document().\n. Could you provide some justification for these proposed changes?\n. But why are you doing that? It's better to use useDynLib directive in the NAMESPACE.\n. That wasn't a regression it was a deliberate change. The problem is that there's two uses of install github:\n1. For user.  Needs vignettes to be built so needs suggested packages. \n2. For developer or as prereq. Doesn't need vignettes. But probably want suggested packages so that you can run all tests. \nI'm not sure how to better differentiate these use cases. \n. Oh got it!\n. Does this still fail for you?\n. I think it's probably a dup of https://github.com/klutometis/roxygen/issues/261\n. Looks the like the tests are failing and you need some minor doc tweaks.\n. Sounds good, feel free to merge.\n. Are you seeing the travis failures locally?\n. Looks good to merge\n. @lbraglia Awesome - thanks for the debugging!\n. This looks great! Could you please merge/rebase against master, document with roxygen2 4.0.1 and add a bullet point to NEWS.md?\n. Something is not quite right with your PR, because you're pulling in a few changes that I've made too\n. Thanks!\n. Would you mind making this more minimal? i.e. don't use github_api_host() and github_api_config().  That will make it easier to combine with #506.\n. Thanks!\n. Hmmm, I think this is a strong argument to move back to the old url. I don't think people using devtools::install_github should have to worry about API keys etc.\n. It's unlikely that they'd change such an important url without notice (or a redirect), so I don't think it's a huge problem (and if they do, I can always release a patched devtools). The problem with rate limiting seems like more of a problem in practice.\n. Do you want to update this (or start afresh?) now that 509 is in?\n. I really would prefer something a little more descriptive than * - ideally something like _release.\n. That sounds good. But hold off on making any changes. I'm going to attempt to simplify install_github() - it's accumulated quite a lot of cruft and I find it hard to understand what's going on.\n. Could you please rebase against my latest changes? And *release sounds good.\n. I like @*release.\n. I no longer think that this is the responsibility of devtools.\n. I think this is out of scope for devtools.  Might tackle it if we tackle package installation in general for the child of packrat and devtools.\n. Each individual assertion takes more than a few minutes to run?\n. Oh I see what you mean. The problem is in how R CMD check is displaying the output of the tests, and I don't see how to get around that.\n. No, devtools does not currently support C function renaming.\n. I think putting files in R/ that are not loaded is a bad idea. I'd recommend putting it in a different directory (I use data-raw/) and then r-build-ignoring that directory.\n. Thanks!\n. If we use dependency injection, then auto_test_package() could still live in testthat. I'm still torn about where it belongs, but probably testthat is a better home.\n. I'm not sure if there's a way to do this automatically. Do you have any thoughts?\n. I think this is complicated to do in general, but I'd be happy to review a PR if you disagree.\n. You can already pass arbitrary options using config(), but I don't think recommending ssl.verifypeer = FALSE is a good idea. It's better to figure out what the underlying problem is - it seems unlikely that it's the same problem as that blog post, because httr supplies it's own certificate store (more modern than RCurl's) and uses it by default.\nIt's possible that this might be related to heartbleed and some top-level certificates being revoked. In that case, trying the instructions on http://curl.haxx.se/docs/caextract.html might be helpful.\n. The reason why this isn't a problem on mac is described at http://curl.haxx.se/mail/archive-2013-10/0036.html\n. You should be able to use httr::with_config\n. How are you loading the shared object? With library.dynam() in zzz.R, or with useDynLib in the NAMESPACE?\n. Due to the way that data table works, I'm pretty sure you need to put it in either Depends or Imports.\n. Thanks!\n. Trying no-path-rtools branch - need to make sure this works on win builder.\n. Can't do this for devtools because CRAN's win builder uses the path, not the registry.\n. We don't use --as-cran because this isn't exactly what CRAN does, and we want to skip some of the more expensive tests (like for version dependencies).\n. What happens when you run find_rtools(TRUE)?\n. Agreed that this would be nice, but I think it needs to done as a part of a general dependency handling mechanism. Might end up as part of packrat, or part of some child of packrat and devtools.\n. Thanks!\n. Thanks!\n. Have looked at what install_github() already does in terms of saving the SHA?\n. Ah ok. I'd say this is outside of the scope of devtools - I'm basically not sold on the benefits of incrementing version automatically.\nI would accept a PR for an improved version of sessionInfo() though ;)\n. Hmmm, hard to see how nsreg() could have a bug in it.  Is it possible that you might have a compiler mismatch somewhere?\n. Normally because R randomly crashes ;)  Typically I get random crashes when I have I've compiled a package against a different version of Rcpp that I've loaded, or if for some reason I've switched compilers between building Rcpp and building another package.\n. When encountering this sort of problem in the past, I've often had to resolve it by deleting my complete library and reinstalling everything\n. The problem is that you're on windows - and on windows, you can't use devtools to install itself. I think you can build() the package, then install it the usual way through the GUI.\n. I think the problem is that you're probably not restarting R enough - on windows, you can't properly re-install a package when it's loaded. So after building the package, restart R and don't load devtools.\n. Thanks! Two comments: \n1. I'm not sure repo_path is the right name for that parameter. Maybe github_url?\n2. Maybe it should be a separate function, install_github_enterprise(), which could then pull the github url from an environment variable or R option so you didn't have to set it every time?\ncc @cscheid, @hilaryparker\n. @hilaryparker btw the way @ghuiber was inspired to start writing packages (and hence this pull request) because of your packages blog post :smile: \n. I'd make install_github_enterprise() take a github_url argument, and then have install_github() call it with https://github.com. To implement Tim's idea, you'd write a function that guessed the enterprise url (probably from Sys.getenv(), or getOption() or both) and then make that the default argument to github_url.\n. The build looks like it's failing for other reasons - I think because I haven't updated the docs for some previous changes that I made.\n. Now it fails for a legitimate reason - check https://travis-ci.org/hadley/devtools/builds/28599041#L963\n. Looks like I broke something in decompress. Will take a look tomorrow when I'm back at a computer \n. Now that the install_github() refactoring is complete, this is really easy for me to implement. I also think now that it doesn't need it's own function. \nIt's not quite as nice as your implementation (since you have always have to specify host), but that does have the advantage of being more explicit/reproducible.\n. I made it C a long time ago because that's what CRAN used to use - and I had a horrible problem that took hours to resolve. But I now think that time has passed :)\n. Thanks!\n. I'd prefer to use some simple S3 dispatch. \n. Yes, exactly, except I'd write the last bit as ref_params <- modifyList(params, github_ref(ref))\n. Thanks!\n. Thanks!\n. Can you please do a pull request? It'll be easier to manage discussion there.\n. Could you please figure out why this makes the existing tests fail?  It would also be really helpful if you could construct a test case that illustrates this bug.\n. Could you please figure out why this makes the existing tests fail?  It would also be really helpful if you could construct a test case that illustrates this bug.\n. Thanks!\n. Thanks!\n. The rd files are generated by roxygen from comments in the R sources. Would you mind changing the source?\n. Yes, because tracking them makes installing packages for non-developers much much easier.\n. Thanks!\n. Just use with_libpaths()\n. Because I don't think you should be changing libraries inside a function. Why do you want this arg?\n. You need a much stronger argument than that because the code quality of install.packages() is quite low.\n. Can you please rebase/merge my changes to find_gist() to use new github API wrapper functions?\n. I'm going to close this now in recognition that it's been open for almost three years (\ud83d\ude31) with no action. Thanks for your work on this issue!. It's not your fault, it's mine!. I think I can just remove gsub(\"\\\\\\\\\", \"/\", x, fixed = TRUE) - it looks like it has too much escaping anyway.\n. Dup of #397.\n. Most likely to be binary-source incompatibility from Rcpp (at least that's what's caused it for me in the past). Try update.packages(checkBuilt = T).\n. @jjallaire I think this might be a problem related to recent changes in rstudio rtools detection?\n@dmenne does devtools::build() work ok?\n. I'd rather write our own session_info\n. Could we make it more table like?  e.g. for the packages, print out a data frame with columns package, version, and loaded. (I don't think we need to separate out base packages)\n. Maybe something like this:\n``` R\n  loaded_pkg <- grep(\"^package:\", search(), value = TRUE)\n  loaded_pkg <- sub(\"^package:\", \"\", packages)\n  attached_pkg <- setdiff(loadedNamespaces(), loaded_pkg)\n  loaded <- rep(c(TRUE, FALSE), c(length(loaded_pkg), length(attached_pkg)))\npkgs <- data.frame(\n    package = c(loaded_pkg, attached_pkg),\n    loaded = ifelse(loaded, \"*\", \"\"),\n    stringsAsFactors = FALSE\n  )\n  pkgs$version <- vapply(pkgs$package, \n    function(x) as.character(packageVersion(x)), \n    character(1)\n  )\n  pkgs <- pkgs[order(pkgs$package), , drop = FALSE]\n  rownames(pkgs) <- NULL\n``\n. Right, if you're usingAuthors@R, you shouldn't use maintainer or author. \n. I think that's a code idea, but out of scope for devtools.\n. What doesfind_rtools(TRUE)` return?\n. Makes sense. Could you please also add a bullet to NEWS?\n. Thanks!\n. When does it crash?\n. Maybe try 1.95-4.3? It looks like that was just released - I suspect that was a quick fix for the problem you're seeing in .2.\n. Duplicate of #532 - in short, wait until the RCurl 1.95-4.3 binaries are available for windows and try again.\n. Go to https://github.com/hadley/devtools and click \"unwatch\" at the\ntop-right.\nHadley\nOn Thu, Aug 21, 2014 at 5:06 PM, Tim Payer notifications@github.com wrote:\n\nHi Hadley,\nI just took the Coursera course on R programming and have some how got a\nflood of your email traffic from GitHub.\nHow can \"unsubscribe\"?\nTim\nOn Thu, Aug 21, 2014 at 2:11 PM, Hadley Wickham notifications@github.com\nwrote:\n\nClosed #534 https://github.com/hadley/devtools/issues/534 via 6c35693\n<\nhttps://github.com/hadley/devtools/commit/6c356930fcf072599f1eee7e504f286255c3af92\n.\n\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/534#event-155795294.\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/534#issuecomment-52991808.\n\n\nhttp://had.co.nz/\n. Can you please file a reproducible example at https://github.com/klutometis/roxygen/issues?\n. Sounds reasonable to me. Some test cases would be nice.\n. Can you please try the dev version? I've made some improvements to the install process.\n. Ok, can you please send a reproducible example?\n. Could you make a zip file with similar structure and email it to me?\n. I'm pretty sure that should do the trick - let me know if you still have problems.\n. I'm going to close for now, but I'm happy to review a PR.\n. Can you point to the complete source of  utility.R?\n. Could you please email me utility.R?\n. Thanks - I can recreate the problem locally and I'll take a look.\n. Fixed in https://github.com/klutometis/roxygen/commit/c5159bc289403d6b401292db9e8037596099a959\n. Decided against this again. Better to start with create() - otherwise RStudio won't pick up on this being a package.\n. Also need to give actual @useDynLib command.\n. Thanks!\n. You need to install Xcode.\n. I think this is mostly a packrat feature. But devtools needs to do better job of capturing metadata when installing packages. See my PR for details. \n. Regardless it would be good to share as much code as possible. \nSorry was a branch - https://github.com/hadley/devtools/compare/install-refactor\nOn my phone so apologies for terseness. \n. The main use case is when reporting bugs so you can see exactly what versions are installed. But this is useful there too - thanks!\n. Thanks!\n. Let's skip this - I don't thinking installing >60 packages/hour is likely to be common. If it is, we can add more logic to github_GET to check for rate limiting and offer advice (i.e. use a PAT).\n. Use the args arg to install().\n. This is how devtools use to work, and I think the current system is actually a big improvement. I think it actually makes your life much easier to deal with these issues as they crop up, rather than in one big batch at the end.\nAlso, my current recommendation is to avoid @import and @importFrom and be explicit about where functions come from with foo::bar(). That makes your code easier to read, and avoids some of the problems you're experiencing.\n. It's unlikely that :: will add overhead unless it's inside a very tight loop. If profiling does reveal that it's a problem then you can fix it with @importFrom or similar.\n. Thanks!\n. Thanks!\n. Since I don't use this code very frequency, could you or @wch please provide a test case or two?\n. I don't think this will resolve the problem - RCurl is require to install devtools.\n. @grantbrown I suspect just re-installing RCurl and httr would have fixed the problem you were having.\n. If you have a version of RCurl installed already, I find it hard to imagine that you couldn't reinstall it. That sounds like a messed up config.\n. Yeah, I believe you, it's just not clear that it's common enough to justify modifying install_github in this way (which will introduce potentially other unforeseen consequences)\n. Can you give me a traceback for the error?\n. I'd say it's because child processes don't inherit .libPaths() from the parent - try calling dev_mode() in the child nodes.\n. I can't reproduce this problem any more.\n. Nice work! (BTW you're invisible on chat again)\n. That's not currently possible, sorry.\n. This seems more like an httr/rcurl/curl bug than a devtools bug.\n. What's the typo?\n. Thanks!\n. Because it causes problems with R CMD check - I'm reasonably certain that saving built vignettes in inst/doc is the wrong approach. We'll fix this in devtools eventually - see https://github.com/hadley/devtools/issues/1578. I'm pretty sure this is because you have:\n\\VignetteEngine{knitr::knitr}\n  \\VignetteIndexEntry{Sending Messages With Gmailr}\n  \\usepackage[utf8]{inputenc}\ninstead of \n%\\VignetteEngine{knitr::knitr}\n  %\\VignetteIndexEntry{Sending Messages With Gmailr}\n  %\\usepackage[utf8]{inputenc}\nwhich is completely my fault because I didn't realise the % was important to the regexp that R uses.  (It's now fixed in the template and in the book, but you must've used an earlier version).\n. Oh also, this qualifies you for the devtools guarantee, so if you email me your address, I'll send you a hand written apology card.\n. test() doesn't have a fresh argument? (any more?)\n. Is there a reason you can't use install_github()?  (which now supports releases)\n. This is fixed in the dev version which wil be on its way to cran very soon\n. - Latest release of RStudio; readLines(\"http://s3.amazonaws.com/rstudio-server/current.ver\", warn = FALSE)\n- Latest release of R: parse http://cran.rstudio.com/src/base/R-3/ ?\n. @gaborcsardi can you please remind me of your package that checks R is up-to-date?\n. @gaborcsardi (I mean that returns the released version of R)\n. @gaborcsardi oh it's rversions - I was looking under your person github instead of metacran.\n. Is there a reason you don't use that in rversions? I don't care much about speed for this usage - I'd rather have something that's likely to keep working for a few years.\n. @gaborcsardi ah, makes sense.\n. I'd rather not do this. It seems fragile to me.\n. When would you do this?\n. I meant when would you run that code? CRAN submission is done, but I might need to do a point release.\n. Hmmmmm, I'd be willing to review a PR, but my suspicion is that it would either have to be complicated (and hence hard to maintain) or fragile to minor variations in file formatting.\n. Maybe in the same way as release_questions? (i.e. an un-exported function with special name)\n. I'm generally not super excited about this, because I don't think it's hard to do by hand, and updating the NEWS (and all the variations) is going to be hard.  I'll still review a PR though\n. It just feels too complicated and fragile to me :/\n. But maybe I'm being needlessly negative, because use_package() is fragile in a similar way\n. Oh bummer.  Would you mind also adding a bullet to NEWS?\n. Thanks!\n. This no longer seems that important to me. It would basically print out the NAMESPACE.\n. It's not important to me, but it seems like it would be helpful for other people. The key would be to show what's not exported.\n. It would be nice, but it's a lot of work and unlikely to get to the top of my priority list.\n. Now think that this is easy enough to do by hand with new summary output.\n. Since we already have git wrappers, I was thinking of using them.  So it would all be R commands.\n. Now think that this belongs in a separate revdep package.\n. Duplicate of #595 \n. Will submit a patch release to cran soon.\n. Ooops, thanks!\n. We could resolve this by setting a CRAN options somewhere, but I'm not sure where given that we're running with --vanilla. Is there an env var?\n. I don't think it's related.\n. How does this work on travis? You can set a CRAN env var there.\n. Related to #678 \n. Seems like we should modify R() and RCMD() to do that?\nIt might be possible to just do it via env vars, by setting R_ENVIRON, R_ENVIRON_USER, R_PROFILE, R_PROFILE_USER etc. I think it requires a close reading of ?Startup to figure out what the best process is.  \nMaybe we can drop --vanilla in favour of ignoring user files, and overriding the location of R_PROFILE to something we create?\n. I'd be happy to review a pull request.\n. I think adding a built argument is overkill - the only reason that the manual isn't built already is an oversight on my part - it should always be built for release().\n. I think it should be always included although obviously it's not required or CRAN would've complained by now. Would you mind doing a PR? It's not a high priority for me.\n. Thanks!\n. ``` R\n' @export\n' @rdname use_vignette\nuse_vignette_extra <- function(path, pkg = \".\", escape = TRUE) {\n  pkg <- as.package(pkg)\ndir.create(file.path(pkg$path, \"vignettes\"), showWarnings = FALSE)\n  if (escape) {\n    files <- paste0(\"^\", gsub(\"\\.\", \"\\\\.\", files), \"$\")\n  }\npath <- file.path(pkg$path, \"vignettes\", \".install_extra\")\n  union_write(path, files)\n}\n``\n- Needs to strip vignettes prefix. \n- Extract out escape function and also use inuse_build_ignore`\n- Better escaping (dig up old stringr function)\nr\nfixed <- function(string) {\n  str_replace(string, \"([][^${}().?*+\\\\])\", \"\\\\\\\\\\\\1\")\n}\n. No longer think that this is necessary - better to put data in data/\n. Can you please send the output of running git remote -v in the package root dir?\n. Does your git remote include your actually password? That seems pretty strange.\n. Also, you don't appear to have an origin set, which is what is causing devtools to fail.\n. See discussion in #608\n. I think that's a good idea in principle, but devtools isn't the place for it.  Instead:\n- roxygen2 should provide template functions for different types of object\n- Rstudio should make it easy to insert those templates\nI know @kevinushey has been thinking about this too.\n. I'd rather avoid Makefiles if possible - the fewer the languages a package developer needs to understand, the better.\n. Something like this:\n``` R\nlibrary(rvest)\nlibrary(tidyr)\nlibrary(dplyr)\ncheck <- html(\"http://cran.r-project.org/web/checks/check_results_dplyr.html\")\ntbl <- check %>%\n  html_node(\"table\") %>%\n  html_table()\ntbl %>% \n  separate(Flavor, c(\"r\", \"version\", \"os\", \"arch\", \"compiler\"), \"-\", \n    extra = \"merge\") %>%\n  select(version:compiler, ver = Version, time = Ttotal, status = Status)\n``\n. No guarantees, but I'd be happy to review a PR. I think the implementation should be fairly simple.\n. Thanks!\n. Thanks!\n. @jjallaire any thoughts?\n. Duplicate of #574 \n. I don't think it's possible to check for title case automatically (because it's not clear what words are significant). That implies it would need to be an additional question in the release questions, but that seems like a fairly large burden for a minor change that only needs to be done once.\n. Seems to already have been done. Thanks though!\n. I think we should probably callroxygen2::update_collateinload_all()- if there are no@includetags, this should leave the description as is.\n. If there are no@includedirectives, roxygen shouldn't touch the collate. If it does, it's a bug.\n. Can you please refile a pull request with that change and the tests?\n. Could you please add a bullet point toNEWS.md.  It might be worth thinking about where else in the docs we should highlight this - maybe incompile_dll()?\n. @jjallaire any thoughts on a clean way to turn off devtool's auto-cleaning when a proper makefile is present?\n. No one else seems to experienced this problem, and the PR has been open for over two years, so I'm just going to close it.. Now I can't remember why I wanted this, andcheck()already has an argument.\n. Could you give me a bit more info about your use case please?\n. I think that's a reasonable approach, but I'd prefer to hold off on including this in devtools. I need more time to think about the problem in general\n.create()is designed to be a first step, not a second. I think you should either adopt the standard devtools workflow, or submit a PR that implements a new function (extracting out most of the code fromcreate()).\n. Thanks!\n. I'd be happy to review a PR that did this.\n. Can you give me an example of what happens when this fails? What happens currently if you have packages in a non-standard repo?\n. I think we can do this by checking all dependencies are available on CRAN or bioconductor, and the version requirements are met.\n. This hasn't caused me any problems, but I'd be happy to review a pull request\n. Yes, but this is the version prior to the first release so it needs to be less than0.1.0.0.0.1.9000could be an option, but I don't think it makes much difference.\n. @gaborcsardi what would you prefer? semver only governs released versions. I think using the four component for dev versions is reasonable (and it's used by a lot of personal and rstudio packages so we're unlikely to change)\n. I don't see being valid semi a particularly strong restraint. Versioning in R is always going to be fundamentally different from other programming languages.\n. Yeah, I think exactly three is best\n. Just pushed some doc improvements. Please let me know if that doesn't answer your question.\n. Yes,setup()would be perfect.\n. Looks good - thanks!\n. I'm actually working on this at the moment ;)   (mostly in the context ofrevdep_check())\n. Sure, PR?\n. I think that's an accident - it should matchR CMD check` as closely as possible.  \nBut I think you should always be able to use system.file() to get files in inst/\n. Can you merge/rebase please?\n. Thanks!\n. Why did I comment this code out?\nR\n  # git2r::branch_set_upstream(git2r::head(r), \"origin/master\")\n  # git2r::push(r, \"origin\", \"refs/heads/master\")\n. Done in #901\n. @jennybc do you have any code that helps check students are set up correctly to use github? Can you suggest any thing else I should be checking in this function?\n. git2r has come a long way since I last looked at it - I think I might be able to replace a lot of code.\n. @jennybc I decided not to implement the path checking - RStudio also makes some efforts to determine the correct git path, and I don't want to have to replicate exactly what it does. I think in the long run, it might be possible for RStudio to also switch to using git2r, thus avoiding the path problem altogether.\n. Already done! (And the default??!)\n. I'm not too keen on working around bugs in base R. I think this is unlikely to cause problems in practice.\n. This is an RCurl problem - see https://github.com/hadley/devtools/issues/467.  \nStart by checking that you're not using the NSS SSL library:\n``` R\ncheck_for_nss <- function() {\n  if (!grepl(\"^NSS\", RCurl::curlVersion()$ssl_version)) return()\nwarning('\n\nYour installed RCurl is linked to the NSS library (libcurl4-nss-dev)\n  which is likely to cause issues.\nTo resolve the problem:\n\n\nQuit R.\n\n\nInstall OpenSSL (apt-get install libcurl4-openssl-dev) or\n     GnuTLS (apt-get install libcurl4-gnutls-dev) variants of libCurl.\n\n\nRestart R.\n\n\nReinstall RCurl: install.packages(\"RCurl\").\n\n\n\n', call. = FALSE)\n}\n``\n. That's becauseread.dcf()strips white space. Useread_dcf()instead.\n. Already done in another PR\n. Try reinstalling RCurl? Make sure you're either using ther-cran-rcurlpackage, orinstall.packages(\"RCurl\")not both.\n. A few thoughts:\n- Can you do the XML manip with rvest? That would make the xml processing a little nicer\n- Can you usenumeric_version()for the version parsing?\n- I need to add better custom verb support to httr\n. @wch I'm not sure I want to add an rvest dependency, but I'd rather start with a clean version of the code that has a lot of dependencies, then work to a harder-to-understand version with fewer dependencies.\n. Any chance you're now providing this info in a nice json api somewhere?\n. Ok, cool.\n. It would just add an extra step for no real gain?  Vignettes are already special-cased.\n. I'm probably going to change my vignette policy - I think it makes more sense to treat them like documentation, and store a rendered copy in the package.\n. It's your choice, with your .gitignore, but I think there are good reasons to store html files\n. @jeroenooms I don't think that will work here becauseinstall_github()` uses httr\n. @jeroenooms oops, yes\n. Thanks, I didn't know what to put there either!\n. Thanks! I wish R CMD check picked this is up like it did for non-recommended packages.\n. Done\n. Part of #675\n. It already does:\nR\nrd_files <- function(pkg) {\n  path_man <- file.path(pkg$path, \"man\")\n  files <- dir(path_man, pattern = \"\\\\.[Rr]d$\", full.names = TRUE)\n  names(files) <- basename(files)\n  with_collate(\"C\", sort(files))\n}\n. Thanks! I also need write a use_cran_comments() function to do this automatically. \n. Thanks!\n. You could do something like this:\nR\nwith(as.environment(\"package:httr\"), GET(\"http://google.com\"))\nbut that requires that you attach the package first\n. Here's a better approach:\nR\nwith_package <- function(pkg, code) {\n  env <- getNamespaceInfo(pkg, \"exports\")\n  eval(substitute(code), envir = env)\n}\nwith_package(httr, GET(\"http://google.com\"))\nbut it still suffers from the problem that @wch identified. I don't think there's a general way of avoiding the problem, expect maybe attaching then detaching the package. Either way, I don't think this function is suitable for devtools.\n. I'd be happy to review a PR for this\n. Needs to work with travis caching: http://docs.travis-ci.com/user/caching/#Fetching-and-storing-caches\n. Call it update_package()\n. @wch yes, but normalizePath should convert any weird path to the 8.3 short form, avoiding the problem.\n. You'll need to get the dev version\n. It's described in the intro, and the instructions are also on the readme: https://github.com/hadley/devtools\nI haven't bothered highlighting it in the book as it's only a transient problem; there will be a new CRAN release of devtools soon.\n. The choice of --vanilla was deliberate because we want to ignore the user files. But maybe --no-init-file --no-environ would be adequate\n. Because people often load packages in their .Rprofile, and set up other stuff that's not the same as on CRAN.\n. Setting R_PROFILE might be a reasonable thing to do. But the reality is that most people developing packages have not read ?Startup, and have lots of junk in that file. So this mostly reduces problems rather than causing them. But I take your point that some users need extra control.\n. It doesn't anymore!  \nHowever, there's no command line option to say skip user files and not site files, so I don't think this will solve your problem.  But devtools is usually pretty good about parsing on your R library, so maybe you could provide a bit more context about where this problem crops up?\n. Feel free to re-open with more details.\n. I don't understand why this is a problem. Why not just do load_all() to diagnose the problem?\n. Wow, that looks really slick!\n. Do you have plans to submit covr to CRAN? Ideally, I'd like to rely only on CRAN packages in the released version\n. Ok, that sounds good. In that case, I'm happy to merge this (after some review).\n. Bump\n. Thanks!\n. You'll need to look at the latex log file and search for errors, then backtrack to the Rd file, then roxygen comment that created it.\n. I would have thought existing warnings would have picked this up too. But displaying the archive size prior to the upload question would work well\n. It'd be useful if could give me the output of git clean -n in order to help me understand when this problem occurs\n. I'd be happy to review a PR that printed the file size before uploading\n. Oh hmmm, that is a problem. Your fix won't work for me, since I use a PAT for public git to increase the standard API limits. We probably need two distinct env vars\n. I'd be happy to review a PR if you want to add an alternative env var\n. Sounds reasonable to me\n. I have no idea :(  I'd recommend trying with httr::with_verbose() and verifying that you can submit regular requests through your proxy .\n. If you're on windows, it's possible a call to setInternet2() will work.\n. What OS are you using?\n. Make sure you have the latest versions of RCurl and httr.  The OS X problem doesn't sound like it's coming from devtools.\n. Done (mostly) in 14cca3f5\n. I think we need to push back on this a little. R CMD check should be checking that the result of the expression is a person object (or coercing to it), not looking at the literal calls. I've emailed CRAN to suggest a patch.\n. They're definitely not going to change :(\n. Fixed in 1650b1ffed12b8d8348eec9ba22c8d962a01d98e\n. I have to say I'm getting more and more comfortable about putting generated files in the repo, just because R users are not like typical software developers.  There are many advantages to including generated files when most people installing/building your package are using it, not developing it.\n. Most people do not have a working C compiler because they're on windows. Even installing Rtools is challenging for many people. If you only talk to other R programmers/developers, you start to think that getting a working R tool chain is easy, but it's not for most R users.\nWriting the roxygen version into the headers is actually a very deliberate way of making sure everyone is using the same version of roxygen so that spurious differences don't accidentally get bundled into a commit.\n. There's also the data analysis side of R, where I think it really makes sense to check in generated files (i.e. your data analysis reports from knitr), because it makes it much easier to track changes in the result. \nPlus what's the harm in committing generated files, provided you have a standard, documented way of re-generating them?\n. My responses\n1. That's not an argument ;)\n2. That's in the eye of the beholder - I'd claim in many situations they actually enhance git diff because you can see exactly what's changed in the output\n3. Rebase, maybe, but lots of people consider that bad practice. Merge, not really, because you can always regenerate the files.\n4. Yes, that's a pain, but should be solved with packrat or similar (eventually)\n. Thanks!\n. Can you tweak the travis to install from github?\n. Thanks!\n. Thanks!\n. devtools 1.7.0 is still in CRAN limbo, but this looks good to do once it's out.  (If it gets rejected, I'll try and remember to include this pull request before resubmitting)\n. Looks good. Can you please add a bullet to NEWS now?\n. Thanks!\n. Unfortunately I think this is just the reality of relying on bioconductor packages. If anyone has bright ideas about how to make it a bit better, I'd be happy to review a PR.\n. It might be possible to drop in 3.2 since curl is now bundled, but devtools is always going to need httr (which needs curl) for github API stuff.\n. What's the use case for this?\n. Seems like this would be better pushed upstream.\n. I've never had a problem with Rcpp generated files. I think you'd be best to report any problems with that directly to Rcpp.\nOtherwise, roxygen automatically deletes man files when you re-document, and you can't delete the NAMESPACE because that often yields an un-loadable package.\n. Ooops, thanks!\n. https://github.com/ggobi/ggally/blob/master/.Rbuildignore#L2 ;)\n. It uses curl, via httr. Are you sure you have the latest devtools, because that url looks wrong (i.e. there shouldn't be a hadley in it)\n. Does this need a bump in the version req for lintr?\n. And would you mind adding a bit more info about the cache? i.e. where it's saved and how to get rid of it.  Does the cache file needed to be added to .gitignore and/or .Rbuildignore?\n. Thanks!\n. Closed in ed3475f117b768cd5f14b8fca1b72cdc0717a32f\n. I think these functions would be better off in another package too\n. And can you please add a bullet point to NEWS?\n. Thanks!\n. Could you add a note to NEWS.md please?\n. Thanks!\n(FWIW github only notifies on comments, not commits, so it's useful to add a comment like \"PTAL\" when done so I see the changes sooner)\n. I'd be happy to review a pull request that implemented this, but since I don't use bitbucket, I can't write it myself.\n. Can you fix please?\n. @jjallaire any thoughts?\n. @jjallaire I was wondering more if you're aware of this issue of specially escaping & in quoted paths on windows?\n. @JoshOBrien it's not obvious those links apply here - I'm not using the command shell and I'm already quoting the paths.\n. I don't think this is a devtools issue. If I run the following code from the command line, I also get an error:\n```\nmkdir \"A&\"\nR\ninstall.packages(\"pkgKitten\")\npkgKitten::kitten(\"aPackage\", \"A&\")\nq()\nR CMD INSTALL \"A&\"\n```\nI'm going to report to R-devel.\n. I'd be happy to review a pull request.\n. Duplicate of #738\n. @Kapondo please file a new issue - a comment on a closed issue is likely to get missed.\n. Any chance there's an & in the path?\n. The fact that it shows the warning mentioning nodosfilewarning is suspicious - in regular operation, devtools sets the env var to suppress that message.\n. I think this should be pushed upstream in to R-travis (and maybe it now happens automatically since we're installing latex now)\n. There are a few options you can set - I probably should set them somewhere\n. Fix all the dependent packages for me too? :wink: \n. The problem is that it's really hard to test if something has been correctly title-cased. The rules are complicated\n. I'm not prepared to make any guarantees that load_all() will work in parallel, and I'm happy that it makes minor changes in order to make the package load correctly (and I expect there might be more in future to (e.g.) deal with broken namespaces). I'd be happy to review a pull request as long as it was extremely simple.\n. I think this would be better integrated into roxygen as a new roclet. Would you mind moving the issue there?\n. Thanks!\n. Fixed - thanks!\n. Thanks!\n. Thanks!\n. They should already do that. I tried creating a parse error in devtools and got:\n``` R\n\ndevtools::load_all(\".\")\n Error in parse(text = lines, n = -1, srcfile = srcfile) (from source.r#24) : \n  /Users/hadley/Documents/devtools/devtools/R/source.r:35:0: unexpected end of input\n33:   invisible()\n34: }\n   ^ \n``\n. @wch but we need to fix this anyway - I think there's a bug in R CMD check where it doesn't pick up missing namespace imports for recommended packages.\n. Could you please add a bullet point toNEWS.md`?\n. Bump - let me know if you don't have time, and I can manually rebase & update news.\n. I can't seem to merge this myself, so I'm just going to redo.\n\n@gaborcsardi any interesting in reporting this problem to R-devel? I think it's a problem that R CMD check doesn't detect missing imports from base packages (except base).\n. I just call tools::buildVignettes() so I'm a bit mystified as to why it doesn't complain. \nWhat do you think about automatically installing the vignette builder package if needed? \n. Unfortunately I don't think install_github() can rely on having git installed locally.\n. How about lapply(c(path1, path2), install_deps) ?\n. Nope, the installs happen in series. \n. Did you have Rtools installed? You shouldn't need any cygwin config.\n. I'd strongly recommend you use RTools, or you a likely to face random crashes later because your package will be using a different compiler toolchain to what R uses.\n. See here ;)\nhttps://github.com/rstudio/rstudio/pull/359\n. I'd really rather avoid this - I think it's fundamentally dangerous, and it's something that CRAN disapproves of.  I think you're better off doing a regular install in covr.\n. My feeling is that it's easier to set the global repos function - maybe it would be useful to have with_repos() analogous to  with_libpaths() ?\n. Hmm, I'm flip-flopping on this a bit - might be best to add repos and type arguments to install(), which will get passed along to install_deps() which is going to get overhauled shortly.\n. I think I've plumbed it all together so that ... now (through a chain of like 6 functions) gets passed to install.packages(), can you please give it a go and re-open if it doesn't work?\n. Would you mind adding sudo: required while you're in there?\n. Thanks!\n. Could you please add a note to NEWS?\n. Looks good - thanks!\n. Strange. Unfortunately I have no idea how to fix this :/\n. Do we need sudo: required always, or only if we use the apt-get install mechanism? (The only bit that currently requires sudo at the user end)\n. Should be fixed now.\n. Easy enough to use `args = \"--use-valgrind\")\n. Looks good! Could you please add a bullet point to NEWS, thanking your github username?\n(FYI github only notifies me about comments, not commits, so when done please add a comment like \"PTAL\")\n. Thanks!\n. Thanks!\n. Best practice for checking the package is to first build it, and then check the built file - that's what devtools does. There are some more notes on the process at http://r-pkgs.had.co.nz/check.html\n. Hmmmm, it seems weird that you're not using SSL (even though it's internal). I guess this needs an extra option :/\n. Can you please add a notes to NEWS?\n. Thanks!\n. This doesn't seem like a devtools bug to me. I'm not sure what (if anything) we can do to work around it.\n. Motivation?\n. From my perspective, it's just a file that I always have to remember to delete. That's why create() no longer makes a package doc template.\n. I like it! I'll close this PR since I don't think there will be much overlap.\n. I think this needs to be fixed in check_cran(), otherwise it'll break the nice reporting provided by check_cran().\n. Thanks!\n. Fixed now.\n. Dup of #746 \n. Can you figure out where \"S4Vectors_defines.h\" is located? It might be that install_github() isn't setting a path quite right.  Do you have a custom .Rprofile?\n. Hmmmmmmmmm. What happens if you clone then use install_local()?\n. Can you try again with the dev version? I can no longer reproduce the problem.\n. Sorry, try again now\n. I wonder if it's because you have an old version of IRanges. Can you try updating with BiocInstaller::biocLite()? \n. i can't reproduce locally, and I have very similar versions. I can't imagine what the problem would be, since install_github() is basically just downloads the package and then installs it (with a thin wrapper around install.packages().\n. Comparing the compiler lines from you:\ngcc -std=gnu99 -I/usr/share/R/include -DNDEBUG   -I\"/home/nsheffield/R/IRanges/include\"   -fpic  -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c R_init_IRangeKernels.c -o R_init_IRangeKernels.o\nand me\nccache clang -Qunused-arguments  -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG  -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I\"/Users/hadley/R/IRanges/include\"   -fPIC  -Wall -mtune=core2 -g -O2  -c R_init_IRangeKernels.c -o R_init_IRangeKernels.o\nI don't see anything obviously wrong\n. I'm going to close for now since I can't reproduce. If anything else comes to light, please let me know.\n. No problems, and glad you figured out where the problem was!\n. Thanks - a few more minor suggestions. I want to make sure that this code is easy to understand, because I think it's quite important.\nI think the NEW needs a bit more. Something like: Previously, devtools ran all external R processes with R --vanilla. Now it only suppresses user profiles, and constructs a custom Rprofile to override the default.\n. Thanks! \nFWIW, can you please add a comment when you've complete a round of changes? (just PTAL is fine) That way github pings me\n. Thanks!\n. I've never seen this problem. Do you have an example package?\n. Ok, please re-open if you manage to create a reprex.\n. You can do it yourself with a ~/.R/Makevars I have:\nCC=ccache clang -Qunused-arguments # -Wsign-compare\nCXX=ccache clang++ -Qunused-arguments # -Wsign-compare\nCCACHE_CPP2=yes\n. I think it might be better to file this as an issue first - I'm not convinced this should be a separate function to release(), but I'm happy to discuss more.\n. Yeah, I think this is wontfix, unless you want to do a PR that drops empty package names (or warns about invalid specification)\n. I'd be happy to accept a PR for this, but since I don't have TFS, I have no way to write the code.\n@stephlocke the install functions are designed around a fairly flexible S3 class, so it shouldn't be too hard to implement.\n. I think a better approach would be to:\n- Write github_has_remotes() that returns TRUE or FALSE\n- Add positive and negative test on real repo - no mocking\n. Do you think you could do this by Monday? I'd like to submit to CRAN then\n. Looks good! I'll probably merge once werker responds about requiring full read/write permissions for all public/private repos.\n. I'm going to hang off on merging this for this version of devtools because I can't recommend people use it until they fix the overly OAuth scope request\n. I'm going to close. We can re-open once wercker has a less ridiculous policy.\n. Just pushed a fix\n. By looking at that command, you can see all the paths are quoted, so it's clearly a different problem.\nGoogling a bit suggests that it's a generic windows file system error message, so you might want to try running some disk checker tool.\n. Good catch - thanks!\n. Bump. Any chance you could finish this today?\n. Thanks!\n. Thanks!\n. Hmmmmmmmm, this doesn't seem like it's going to help a lot of people given that aspell isn't usually installed?  (And also maybe it should be used just when cran = TRUE?)\n. Ah, got it. Can you please add a note to NEWS and to the check docs?\n. Thanks!\n. Thanks!\n. Thanks!\n. Thanks!\n. It's only confusing if you're not familiar with R's function call semantics - I prefer this form because then you can get an author per line.\n. Oh maybe I'll just keep using it in my packages, but change the default to be a bit more explanatory. Want to do a quick PR?\n. Thanks!\n. Devtools should never touch DESCRIPTION unless you explicitly ask for it (e.g. with a use_* function), and roxygen2 shouldn't touch it unless you're using @include. If you can figure out what's triggering it, I'm happy to fix it\n. You have an old version of roxygen2. The current release has:\nR\nupdate_collate <- function(base_path) {\n  collate <- generate_collate(file.path(base_path, \"R\"))\n  if (is.null(collate)) return()\n  ...\n}\n. That's fixed in the dev version of devtools - it might be overly aggressive now, but it currently ensures that all dependencies are also up to date.\n. I'm happy to review a PR for this change.\n. Ooops, fixed it myself before I got to this notification\n. Thanks!\n. It should work. It's likely to be a problem with git2r config\n. It's new in 1.8.0.  I'd recommend taking a look at the code in install_git to see if you can create a minimal reprex using git2r code (it should be pretty simple). Then you can follow up with the git2r folks.\n. https://github.com/ropensci/git2r\nOn Mon, May 11, 2015 at 1:14 PM, Luca Cerone notifications@github.com\nwrote:\n\nThe issue is not present with R 3.1.3 (that I have at home), so I can't\nreproduce the issue.\nI'll try again with my laptop at work (where I have R 3.2.0) and try to\nfigure out why it happens.\nI have seen there are several git2r repos in github, which is the official\none? I guess it is the cran/git2r, but would like to be sure.\nThanks a lot again for your help with this!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/796#issuecomment-101003207.\n\n\nhttp://had.co.nz/\n. Maybe you need the dev version of git2r?  \nBut I don't usually bother with installing R-devel myself - build_win() tests on R-devel for you.\n. Oh bummer. I guess I'll need to do a point release in the near future\n. Could you please file a reprex? It should work with 3.1, but I may have missed something.\n. I think it would be fine as an argument to build_win(). But modifying the DESCRIPTION file is a pain.\n. I'd be happy to accept a PR that implemented this.\n. Works for me. Please supply traceback() and devtools::package_deps(\"devtools\")\n. You must have something else on the search path that's interfering with devtools.\n. Can you please provide the output of devtools::session_info()\n. Set the envar GITHUB_PAT to your personal access token\n. Yes! Want to do a PR?\n. Thanks!\n. Makes sense to me. Want to do a PR?\n. @jimhester any thoughts?\n. This looks like a mirror problem - I'd recommending us the 0-cloud mirror.\n. Can you please modify the source in check.R?\n. Hmmm, looking at this again, this seems more like a pdf layout problem. I'd rather have it be semantically correct in the sources.\n. Can you please give me devtools::session_info()?\n. Would you mind also updating cran-comments?\n. You can remove the first bullet point\n. Could you please merge/rebase to fix the travis error?\n. Thanks!\n. Could you please take a look at http://win-builder.r-project.org/r8sssx3TY6ue/00check.log ? This seems to be failing on win builder on r-devel\n. Thanks!\n. What's your OS?\n. See https://github.com/ropensci/git2r/issues/131\n. Looks good - could you add a bullet to NEWS (and maybe a unit test?)\n. Thanks!\n. Moved to pkgload. Looks good, but can you merge/rebase please?\n. Thanks!\n. The problem is that you're using collate.unix and collate.windows which devtools doesn't know about. I'd be happy to accept a PR to add support (you'd need to patch https://github.com/hadley/devtools/blob/master/R/load-code.r#L40-L65). They're rare enough that I don't have the time to add support myself.\n. I'd say export\n. Thanks!\n. Do you want to move this to withr?\n. Could you link to a minimal reproducible example?\n. Closing for now. If you add a MRE, I'll reopen.\n. loadRcppModules() contains:\nR\n    calls <- sys.calls()\n    w <- which(sapply(calls, function(call) {\n        identical(call[[1L]], as.name(\"runHook\"))\n    }))\n    if (!length(w)) \n        stop(\"loadRcppModules can only be used within a .onLoad function\")\n    w <- w[length(w)]\n    call <- calls[[w]]\n    if (!identical(call[[2L]], \".onLoad\")) \n        stop(\"loadRcppModules can only be used within a .onLoad function\")\nSo they really don't you to run it some other way (and devtools calls .onLoad() directly, not through the usual runHook() mechanism). runHook() isn't an exported function, so I can't use that, so I think that makes this an Rcpp issue.\nMaybe @romainfrancois has some thoughts.\n. Thanks!\n. Thanks! The timings were a bit different for me - 0.4s before, and 0.07 after.\n. Thanks!\n. Ooops, fixed this myself\n. Probably fixed in #846 \n. Please try the dev version. If it still fails, please include the output of traceback()\n. Great!\n. Thanks! I wondered why I had that @importFrom rversions\n. Could you please squash? (And close #833?)\n. See the revdep check functions. I also recommend checking with build_win()\n. It's as similar as we can make it without running CRAN checks that we don't want (e.g. checking the incoming version check which is lengthy and not usually important). release() runs check() with --as-cran as a final check. You should also be checking on other platforms like with build_win()\n. It\n. Thanks!\n. Thanks!\n. Fixed (a while back, I think)\n. cc @jjallaire \n. Thanks - could you please also add a bullet point to NEWS?\n. codecov is mostly informatively - I'm still experimenting with it.\n. Thanks!\n. I don't have the resources to support old versions of R. Unlike python, relatively few R users use linux, so windows and mac support is much more important.  (And I'm not sure even python is the best example with the whole python 2 vs 3 debacle)\n. @wch happen to remember an elegant way to do this?\n. Ideally you'd do a topological sort on the S4 dependency graph before deleting\n. Could you please add some unit tests for sort_s4classes()?\n. Could you please also add a bullet to NEWS?\n. Thanks!\n. Thanks!\n. That sounds good to me (although I'd use NA as the default not NULL, and maybe it only needs to be called create?)\n. Restart R?\n. Already fixed in dev version\n. I don't think you need quite so many options. I think just implementing update would be fine.\n. I'm going to close because this seems a bit premature to me - I really need to think through how vignettes should behave (and who should be responsible for building - roxygen2 or devtools)\n. I think setup() now needs a bit of extra checking to be safe, but I can add that.\n. Duplicate of #779 - I'm not sure what the problem is, but I don't think it's devtools related.\n. Could you please give me the output of: dr_devtools() and devtools:::git_uncommitted()\n. It's on its way to CRAN now ;)\n. Thanks!\n. Thanks!\n. Seems reasonable to me (although I'd call it use_citation() to be consistent with the other functions)\n. I'd be happy to review a pull request\n. Yeah, this is expected behaviour because I see a lot of people who have problems because (e.g.) they installed the latest ggplot2, but have an old version of dplyr.  If you don't want to update the deps, do dep = FALSE.\n. I think type = \"both\" is still a bit buggy, but I will revert to it eventually. See #907 for progress.\n. I think that would be reasonable as its own package :)\n. @wch would have a little time to look into this? It causes some hassles for CRAN.\n. Currently we set a whole lot of envvars to mimic what as cran does  instead we should probably use regular as cran and override only the envvars for things we want to turn off. \n. @elbanez yes, if you're using R-devel\n. Do you have the dev version of devtools?\n. Please try installing the development version, and if that fails, post a minimal reprex.\n. Fixed by #895? cc @jimhester \n. It's still not quite right:\n```\n\ninstall_github(\"dtenenba/anRpackage\", build_vignettes=TRUE, \n+     repos=\"http://bioconductor.org/packages/3.2/bioc\", \n+     dependencies=TRUE, type=\"source\")\nUsing github PAT from envvar GITHUB_PAT\nDownloading GitHub repo dtenenba/anRpackage@master\nInstalling anRpackage\nSkipping 8 packages not available: devtools, httr, knitr, optparse, RCurl, rmarkdown, RUnit, XML\nInstalling 1 packages: BiocCheck\nInstalling package into \u2018/Users/hadley/R\u2019\n(as \u2018lib\u2019 is unspecified)\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0 20 4025k   20  814k    0     0  1954k      0  0:00:02 --:--:--  0:00:02 1952k100 4025k  100 4025k    0     0  3623k      0  0:00:01  0:00:01 --:--:-- 3626k\nERROR: dependency \u2018optparse\u2019 is not available for package \u2018BiocCheck\u2019\n* removing \u2018/Users/hadley/R/BiocCheck\u2019\n```\n\nSo I'm not getting quiet downloading for some reason, and optparse doesn't get installed (probably because it's on CRAN and that repo is clobbered)\n. Oh, the file doesn't download quietly because type = \"source\"\n. Thanks!\n. Thanks!\n. system2() is a just wrapper for system(), so I'd prefer to use system() directly.  Plus this code is sensitive and not well tested, so I'd need a very strong argument to change it.\nWhy not just use the log generated by R CMD check?\n. The recommendation to use system2() in the docs is not good - I've been burned before.  The way it sets env var is extremely suboptimal - it just lumps then together before the command A=1 B=1 ls.\n. Thanks!\n. This will be fixed in the next release (because the dev version of R now will pick up these missing issues), but installing a package in your Rprofile is a rather unusual thing to do.\n. Sorry, I can't really follow what the point of the function is.\n. Once this robustr on CRAN, I'd be happy to review a PR\n(ps. I think wither would be a cooler name ;)\n. You'll need to do something like\nR\nlibrary(httr)\nwith_config(use_proxy(...), install_github(...))\n. This seems to be a git2r issue:\n``` R\nlibrary(git2r)\nout <- tempfile()\nr <- clone(\"https://github.com/hadley/devtools\", out, progress = FALSE)\ngit2r::checkout(r, \"v1.8.0\")\n```\nCan you please follow up at https://github.com/ropensci/git2r/issues ?\n. This is only a problem with interrupts, not errors, right?\n. But normally you don't need to cleanup if the setup function fails - it's responsible for doing any intermediate house keeping.\n. Does tryCatch + finally have the same problem?\nI understand that this is a potential problem, but it seems like a fairly unlikely scenario to me. (i.e. compare to all the other numerous sources of bugs that I could fix, this is fairly low down on my list)\n. I'd be happy to review a PR that implemented this.\n. devtools generally already protects you against any problems by adding appropriate files to .gitignore and .Rbuildignore. If you have a concrete problem, I'm happy to fix it, but I don't think there's any need to for a clean function. In particular, it's best practice to check in the NAMESPACE and Rd files.\n. Pretty sure this is fixed now\n. Works for me\n. Could you please give me the output of this code:\nR\nfile.path(R.home(\"bin\"), \"R\")\nnormalizePath(file.path(R.home(\"bin\"), \"R\"))\n. Hmm, what about just normalizePath(R.home(\"bin\"))\n. I'm pretty sure this is a bug in R, because the docs for R.home() say it's always supposed to return a short name. I've posted an question on R-devel - hopefully someone on R-core will pick it up.\nOtherwise, will probably need to file an official R bug report.\n. @sabas can you try shortPathName(R.home(\"bin\"))? If gives something sensible, I can use it in devtools.\n. As I mentioned in the pull request, devtools is already too big, so I think this belongs elsewhere.\n. Agreed. Want to do a PR or want me to do it?\n. If you can tell me what to do, I can do it. But I don't have access to LFS (even though I applied to the beta months ago)\n. There doesn't seem to be a github API for this, and the github docs on LFS are terrible, so I'm not optimistic about this.\n. Probably need to reinstall git2r\n. I'm with @gaborcsardi on this one. I think they're useful functions, but since devtools is already so big, and these functions are not tightly coupled to devtools, I think another package is the way to go.\n. Also needs bullet point for NEWS\n. I just refactored check_env_vars() out, so this should be a bit easier now\n. Do you have time for this? I need it by tomorrow if you want in this release\n. Yeah, I think it's probably easiest to start from scratch. But threading the arguments through all the function calls is tricky, and I'm likely to make a mistake :/\n. Hmmm, I think I'm swayed by your argument that this is of limited utility since it's now easy to do elsewhere.\n. Could you please add a bullet to NEWS?\n. Thanks!\n. Thanks!\n. Can you please supply a minimal reproducible example?\n. When I run check and look at 00install.out, I see\nR\nWarning: namespace \u2018rgdal\u2019 is not available and has been replaced\nby .GlobalEnv when processing object \u2018woodmiceTrees\u2019\nWarning: namespace \u2018rgdal\u2019 is not available and has been replaced\nby .GlobalEnv when processing object \u2018woodmiceTrees\u2019\nNote: the specification for S3 class \u201cAsIs\u201d in package \u2018jsonlite\u2019 seems equivalent to one from package \u2018RJSONIO\u2019: not turning on duplicate class definitions for this class.\nSo I suspect it's a problem with your package, not with devtools. I looked at woodmiceTrees and I can't see anything wrong with it, but you are importing an awful lot of packages, so its possible you've hit some bad combination.\nWith R --vanilla I get:\n```\n\nsearch()\n[1] \".GlobalEnv\"        \"package:stats\"     \"package:graphics\" \n[4] \"package:grDevices\" \"package:utils\"     \"package:datasets\" \n[7] \"package:methods\"   \"Autoloads\"         \"package:base\"   \nload(\"woodmiceTrees.RData\")\nsearch()\n[1] \".GlobalEnv\"        \"package:stats\"     \"package:graphics\" \n[4] \"package:grDevices\" \"package:utils\"     \"package:datasets\" \n[7] \"package:methods\"   \"Autoloads\"         \"package:base\"   \n``\n. Also, I agree with @jimhester WRT how the placeholders should work\n. Oops, forgot to ask for a bullet point in NEWS. Could you please add in a new PR?\n. 1. I like it.  It's especially nice since it means you no longer need to describe in multiple places (e.g..travis.ymlandREADME.mdand somewhere else that I forget, but is annoying to update). \n2.DevPackageseems ok to me, but I suspect there's a better name. Note also that CRAN will warn about non-standard fields in the DESCRIPTION, but I guess that's actually ok because they should be all removed by the time you submit to CRAN.\n3. Seems reasonable to me.\n4. Hmmm good question. Maybe we need an installation vignette that describes in general how dependencies are fixed?\n5. Rather than mocking (which I really rather dislike), I'd rather you separate the code out into parsing vs. doing. Then just test the parsing code. (The doing should just be a simplelapply()so shouldn't need testing)\n. This looks good overall and I'm happy with the nameRemotes`.\n\nI agree that it's fine to leave out additional options for other endpoints for now.\nCould you please add a few tests for badly formed remote specifications?\n. I prefer to omit the github - I think the vast vast majority of packages use github so it's ok to be terse in that case.  I don't think we need to deal with private repos now - we can see what happens as people use this tool more.\n. I don't really like Repositories because technically those urls are not repositories (they're individual packages). \nI do think I prefer :: to |\n. Thanks - this is awesome :)\n. @jimhester any updates on this? Now that I'm using caching on travis this would be nice :)\n. LGTM - feel free to merge\n. It currently checks HCU and HLM. Should it also try HKLU (and HKLM?) instead? And in what order? (and a little explanation would be helpful since I no nothing about the registry)\n. @jjallaire any thoughts on this? I don't know which registry \"hives\" I should be looking in.\n. So I should try (in order) HCU, HLM, HKLU and HKLM?\n. Reading around about registry hives, I think the current behaviour is correct. @spadehed I suspect your problem will be fixed if you just try the dev version.\n. Thanks!\n. This isn't terribly useful right now: see https://github.com/eddelbuettel/drat/issues/37 for details.  See more-repos branch when these problems are fixed in R/drat.\n. cc @gaborcsardi \n. @jimhester could you also take a look at this one?\n. Unfortunately I don't currently have the resources to support dplyr with the experimental windows toolchain. I don't know why those examples are failing, but you can see the code that devtools is running.\n. Please provide a reproducible example\n. Thanks!\n. Thanks!\n. I don't see that as a big problem, as you should pick up when running build_win()\n. np\n. Thanks!\n. Thanks!\n. Perfect. Thanks!\n. Thanks!\n. Already been fixed ;)\n. Thanks!\n. Thanks!\n. Thanks!\n. Thanks!\n. I think 1 would be ok if you did the revdep checks and informed the revdep maintainers\n. Thanks!\n. Can you please merge/rebase?\n. This is just an interim problem with travis. I don't think it's a good idea to add these binary deps.\n. Thanks!\n. Thanks!\n. Can you please merge/rebase?\n. Thanks!\n. I preview them with Cmd + Shift + K. What else do you need to do during dev?\n. Oh hmmmm, maybe we need a vignette() shim to get the dev version?\n. Moved to pkgload. I haven't had any problems with this so would you mind adding a test case?\n. I think it's probably better to push this into https://github.com/metacran/description and then eventually using description in devtools.\n. Thanks!\n. That's very weird - I've never seen that problem before and I do a lot of re-loading of C++ code. Unfortunately it's likely to be something idiosyncratic with your setup/environment.\n. Thanks!  (It also really needs to come much early in the check)\n. Thanks!\n. Thanks!\n. Thanks!\n. I now think doing this for every package will be too aggressive. Let's start my at least making it easy to include the full text of the license in a CRAN friendly way, i.e. https://github.com/r-lib/usethis/issues/10. Will hopefully be fixed once we switch to @gaborcsardi's new dcf package\n. Thanks!\n. Whenever you see \"lazy-load database corrupted\", the first thing to try is restarting R.\n. @jimhester could you take a look at this one too please?\n. Thanks!\n. Thanks!\n. You should avoid all NOTEs if possible. Just don't expose the environment to the user rather than locking it.\n. Now handled by r-hub\n. Thanks!\n. I only use NEWS.md, so I'd want that for devtools.\n. @gaborcsardi have there been any updates to NEWS.md support for CRAN? IIRC it still causes a R CMD check problem.\n. So that means NEWS.md submission should be ok now, right? (Because CRAN runs R CMD check with R-devel)\n. Yes!\n. Any interest in doing a PR for this?  I think you could just do a regexp on the first (say) ~20 lines.  It would be another function called from release_checks()\n. This seems like a downstream problem, not a devtools problem?\n. Where does evaluate get used? In run_examples() maybe?\n. The only package I'm hesitant about removing is roxygen2, because I have some vague recollection that we deliberately made it part of devtools.  I think it's basically because there's a strong tension in devtools to be batteries included because it makes teaching R package development that much easier.\n. Another option would be to have a batteriesincluded package that just had everything people needed as a dependency.\n. For symmetry if we're going to drop roxygen2, I think we should also drop testhat.\nAnd could you add a bullet point to NEWS and think about how to change the README to tell people how to get a full environment for package development?\n. @gaborcsardi I think removing the Rcpp dependency from roxygen2 is going to be hard - it's just a much better tool for parsing stuff than R is. I'd rather push towards moving all the package install stuff out in a separate package.\n. This looks good but I'm concerned that the version req is now recorded in two places, and the chances are that I'll forget to update one\n. Thanks!\n. It should be path. Where is your package relative to the working directory?\n. No. How could it know where your package is? (I admit the documentation is confusing)\n. Thanks!\n. Probably most important for check() as this lets you detect and fix partial argument matches when you're most interested in them.\n. I'm going to put this in my user profile and leave it to stew for a bit.  Can probably drop warnPartialMatchArgs since R CMD check already gets that.\n. From Kurt:\nWhat the check code already does is\nR\n    ## Allow specifying a codetools \"profile\" for checking via the\n    ## environment variable _R_CHECK_CODETOOLS_PROFILE_, used as e.g.\n    ##   _R_CHECK_CODETOOLS_PROFILE_=\"suppressLocalUnused=FALSE\"\n    ## (where the values get converted to logicals \"the usual way\").\n    args <- list(skipWith = TRUE,\n                 suppressPartialMatchArgs = FALSE,\n                 suppressLocalUnused = TRUE)\n    opts <- unlist(strsplit(Sys.getenv(\"_R_CHECK_CODETOOLS_PROFILE_\"),\n                            \"[[:space:]]*,[[:space:]]*\"))\nso we should always see the partial match args notes in the code\nanalysis.\n. Move to rcmdcheck. Any interest in implementing this?\n. Thanks!\n. This is a different problem to #941, right?\n. I like the idea of using MaintainerNote. \nWhen should this be recorded? On package creation? Every time you run load_all()? Every time as.package() is run?\n. @gaborcsardi I was thinking may be it would be a simple flag - i.e. that the package uses devtools, not that it uses a specific version.\nI really would like a way to proactively reach out to devtools uses so I can ask a wide range of uses to test pre-release versions.\n. I'm going to close this for now. I think GA and requesting emails are interesting ideas, but too challenging right now.\n. I don't think that's true in general.\n. Reading https://docs.travis-ci.com/api#with-a-github-token suggests this code should work:\nR\n  req <- httr::POST(\"https://api.travis-ci.org/auth/github\", \n    body = list(github_token = github_pat()),\n    httr::accept(\"application/vnd.travis-ci.2+json\"),\n    httr::verbose(),\n    encode = \"json\"\n  )\n  httr::content(req, \"text\")\nBut it doesn't, and the error recommends contacting support. Since travis support never replies with anything useful, this doesn't seem worth pursuing at this time.\n. Critical bit seems to be using the same user agent as their example:\nR\nreq <- httr::POST(\"https://api.travis-ci.org/auth/github\", \n                  body = list(github_token = github_pat()),\n                  httr::accept(\"application/vnd.travis-ci.2+json\"),\n                  httr::verbose(),\n                  httr::user_agent(\"MyClient/1.0.0\"),\n                  encode = \"json\"\n)\nhttr::content(req)\n. Complete process:\n``` R\nlibrary(httr)\nGet auth token using Github PAT -----------------------------------------\ntravis_token <- function() {\n  req <- POST(\"https://api.travis-ci.org/auth/github\", \n    body = list(github_token = github_pat()),\n    accept(\"application/vnd.travis-ci.2+json\"),\n    user_agent(\"MyClient/1.0.0\"),\n    encode = \"json\"\n  )\n  stop_for_status(req)\n  token <- httr::content(req)$access_token\nadd_headers(Authorization = paste0(\"token \", token))\n}\ntoken <- travis_token()\nDetermine repo id -------------------------------------------------------\nrepos <- content(GET(\"https://api.travis-ci.org/repos\", token, query = list(slug = \"hadley/monads\")))\nid <- repos[[1]]$id\nSet hook to active ------------------------------------------------------\nreq <- PUT(\"https://api.travis-ci.org/hooks\", \n  body = list(hook = list(id = id, active = TRUE)), \n  encode = \"json\", \n  token\n)\nstop_for_status(req)\ncontent(req)\nlibrary(purrr)\nhooks <- content(GET(\"https://api.travis-ci.org/hooks\", token))\nhooks %>% map_chr(\"uid\")\nhooks %>% keep(~.$name == \"monads\") %>% str()\n``\n. I'd be happy to review a PR, but this code is pretty complicated already.\n. Thanks!\n. Maybe we could make devtools respect aCRAN_MIRRORenv var?\n. I'm not sure if it's important to generalise - I thinkCRAN_REPOS+BIOC_REPOSwould solve 90% of issues.\n. Maybe we could havedevtools::set_repos()` - that would take care of modifying the correct file on disk.\nWould also be useful to have a devtools::install_pandoc() which would download and install the RStudio binary\n. Closing since @jimhester is on this. @jimhester can you break this up into smaller issues?\n. @jimhester will take the first round of review, and then I'll take a look\n. Hi @bearloga - we really appreciate the pull request but it's currently too far from how we'd implement it that I don't think it's useful to iterate here. In a few minutes, I'll create a new issue describing the problem, and quickly dumping my thoughts on the issue. We'll probably tackle it ourselves for 1.11, but thanks for the idea and the sketch implementation that shows it shouldn't be too much work!\n. Thanks!\n. Thanks!\n. Thanks!\n. Thanks!\n. I've never seen these notes. Can you provide more details?  What system requirements are necessary to be able to compact vignettes?\n. Hmmm, if it needs other software, we definitely shouldn't do this unconditionally.  Could you please add a check for the presence of the needed software?\n. Yeah, that sounds good.\n. If you can do this by Friday it'll make it in 1.10, otherwise it will have to wait for 1.11 (probably in about a months time)\n. Can you please rebase & squash?\n. Can you supply a traceback() please?\n. Nice idea!\nI made it work so you can do:\nR\nsave(tcga_ovarian_pepdata_bp, file = package_path(\"data\",\"ModifiedOvarianPepdataBP.Rdata\"))\n. BTW in this case you'd probably be better off using saveRDS().\n. @jennybc I don't see why not. File an issue over there?\n. Is there a reason that load_all() doesn't do what you want? I think it's much better to put the functions in an environment.\n. You call it like use_data(a).\n. That's not what use_data() is designed for. You're probably best off using save() directly.\n. I don't really follow why this would be useful, and I've never felt the need for it myself. But I'd be happy to review a PR that implemented it :)\n. Yeah, devtools is generally tied pretty tightly to the latest version of R\n. You need to run check(as_cran = TRUE) to run these additional (expensive) tests\n. If you're following the standard devtools release process, release() does that for you.\n. It runs exactly the same code that CRAN does, although CRAN runs it with R-devel.\n. I like it!\n. This is for devtools internal use only, and I'm pretty sure that R's read.dcf() doesn't support whitespace or comments.\n. Yeah, unfortunately you can't reliably unload packages with C code\n. I think this should all be resolved with the latest git2r release.\n. I like it. I think the only thing that's missing is a comment with the code explaining your reasoning above \n. Thanks!\n. @jimhester thanks for digging into this - it's been a hassle for ages!\n. I'd be happy to review a pull request that added a document = TRUE/FALSE option to run_examples()\n. How does this handle languages with different pluralisation rules? (http://unicode.org/repos/cldr-tmp/trunk/diff/supplemental/language_plural_rules.html)\n. But how can that work with just two options?\n. Got it - thanks!\nWouldn't it be better style to do (e.g.)\nR\nmessage(ngettext(length(ahead), \n  \"Skipping %d package not available: \", \n  \"Skipping %d packages not available: \"\n)\nWhich as I re-read it seems rather contorted. Maybe \"Skipping %d unavailable packages:\" ?\n. Thanks!\n. It's not a bug - it's just a warning that comes from load_all. \n. This seems like a R CMD check issue? \n. That's a really massive reprex. Could you try making something smaller please?\n. Fixed in pkgload. Thanks!\n. It would be nice - it's most important for binary packages on windows. Are you interested in putting together a PR for review?\n. Thanks!\n. I think that logic holds. @jimhester can you please also check?\n. Here is fine\n. @jimhester I like that approach!\n. LGTM - could you please also add a bullet to NEWS?\n. Thanks!\n. Roxygen is a run-time documentation system - it inspects the objects in the package environment, not just the source code. That means it needs to load_all() the package, which obviously it can't do without compiling any C code.  \nWould you mind briefly outlining a series of steps that gets you to this point? Normally the NAMESPACE doesn't matter when compiling code.\n. How did you create the original package? Most ways should give you a dummy/empty NAMESPACE.\n. Thanks!\n. Thanks!\n. Also note, but never talk about, %:::% :wink: \n. I'm not sure if this has ended up any simpler/better than the previous code. What do you think?\n. @wch what other functions need to be in this PR?\n. I suspect delayedAssign() at the top-level of a package gets caught in the package lazy-load mechanism that's used for data sets\n. I think this is fine, provided @wch agrees.  \nI also wonder if we should capture in one place if any of the replacement fails, and throw a single warning on attach - \"Devtools is incompatible with the current version of R. load_all() may function incorrectly.\" Otherwise we'll never find out.\nIf we do more of this it might be worthwhile to write ast_patch() which does some sort of templatised search-and-replace on ASTs.  Maybe we need a whole package that provides xml2 like operations on ASTs?\n. LGTM\n. Thanks!\n. Thanks!\n. Quick thoughts:\n- @jimhester's implementation of git_wd_clean() is adequate, and doesn't need to be exported\n- git_wd_clean() would be better called git_committed() or similar\n- You shouldn't need to modify the description file. Why can't you use the same approach install_github() uses to add extra metadata?\n. Thanks!\n. It would be super useful if you could also fill in the github info if the repo has been pushed to github. (That would make my life easier when working with shinyapps and development versions of my packages)\n. I don't think the logic is quite right. When I run install() with this version (on devtools itself), the installed DESCRIPTION is not modified, and the DESCRIPTION in the current directory is.\n. The problem is that base::find.package(pkg$package) doesn't give the installed path for a package loaded with devtools, but instead gives the path to the source package.  This will only be a problem if you've run load_all() before install(), but that seems like a fairly common scenario to me (and is certainly something I'd do)\n. Ok - this now just needs a bullet in NEWS.md and we're good to merge.\n@jjallaire @kevinushey FYI: this PR will add git/github information when installing from a local package. I vaguely remember there's some interaction with packrat, so you need to know about this.\n. Don't worry about it, I just merged by hand.\n. Cool! Could you please also add a bullet to NEWS?\n. Thanks!\n. Hmmm, I'm trying to replicate this locally, but the tests segfault. Also you have a merge conflict in your .gitgnore which you should probably fix. Also the vignettes are really really slow, which makes R CMD check painful.\n. release() just calls check(pkg, cran = TRUE, check_version = TRUE, manual = TRUE), so I'm not sure what's going on here. \n. Thanks!\n. This is already done by release().\n. Would you mind adding a unit test for this too please?  (i.e. that the path returned by build() actually exists)\n. Thanks!\n. Awesome - thanks Jenny!\n. Moved to pkgload, and looks like it's unfixable unfortunately.. Oops, I messed up the headings. Just put it directly under 1.10.0.9000\n. Can you please merge/rebase and squash?\n. Thanks!\n. Am I missing some reason that you're not doing this?\nR\n  if (!uses_github(path)) {\n    return(doctor(\"github\", \"Current path is not a github repository\"))\n  }\n. Haha, thanks!\n. I'd rather remove all of the with functions, or none of them, but removing in the next version (which is only a couple of months away seems too soon)\n. Can you import functions with an alias?\n. LGTM\n. I now think this is mostly better done via travis\n. We're both involved in other projects right now but will review it before the next release.\n. I'll get to it when I get to it.\n. I'm going to close this PR in recognition that it's been open for over year with no movement.. You can now :) check() now returns an object with errors, warnings, and notes.\n. Yeah, I think ssh is an older format.\n. Want to do a PR?\n. Maybe \nR\ncran_url <- function() {\n  if (capabilities(\"libcurl\")) {\n    \"https://cloud.r-project.org\"\n  } else {\n    \"http://cloud.r-project.org\"\n  }\n}\n?\n. I would really rather keep it simple and just condition of libcurl. Maybe something like:\nR\nprotocol <- function() {\n  if (getRversion() >= \"3.3.0\" && capabilities(\"libcurl\")) {\n    \"https\"\n  } else {\n    \"http\"\n  }\n}\n. @jjallaire pointed out that there are other situations in which an https mirror will still succeed so should test directly with download.file().\nMaybe something like:\n``` R\nmirror_ok <- function(url) {\n  tryCatch(\n    {\n      download.file(paste0(url, \"/Rlogo.svg\"), destfile = tempfile(), quiet = TRUE)\n      TRUE\n    }, \n    error = function(...) FALSE\n  )\n}\ncran_mirror <- function() {\n  if (mirror_ok(\"https://cran.rstudio.com\")) {\n    \"https://cran.rstudio.com\"\n  } else if (mirror_ok(\"http://cran.rstudio.com\")) {\n    \"http://cran.rstudio.com\"\n  } else {\n    stop(\"Failed to connect to RStudio CRAN mirror\", call. = FALSE)\n  }\n}\n``\n. Would still need to be memoised (if it didn't fail)\n. I'm going to close this and start a new PR\n. Custom libraries already should be supported. Could you please paste the exact error message you get?\n. Thanks!\n. I'm not sure - I was actually thinking that too.  \n. I don't think that's the right approach, because there's no way to infer if a package should be suggested or imported. \n. Yes - I believe that those are important decisions that can not be automated.  (Especially since you should never use@importand only rarely use@importFrom)\n. No - you either dostringr::str_replace_all()_or_@importFrom stringr str_replace_all+str_replace_all()`\n. Oops fixed.\n. BTW I think if you always add the NEWs bullet at the top, it's less likely to cause merge conflicts because it gets anchored to the unchanging heading. (That's my theory anyway)\n. I think this is now supported well enough with:\nyaml\nr:\n  - oldrel\n  - release\n  - devel\n. https://github.com/rwinlib/r-base/wiki/Testing-Packages-with-Experimental-R-Devel-Build-for-Windows\n. It feels like this might be better as multiple functions:\n- One function returns a named list with notes, warnings, and errors\n- Another function filters and prints\n- Another function throws the error and has defaults so can be called easily from the command line\nI think we should probably also print this out at the end of check() and use the same function to throw the error.\n. Actually let me take a stab at this one.\n. This isn't quite perfect yet, but should be a better place to build off of.\n. #1011 ;)  But we do need a specific one for devtools too.\n. I'm also not sure sure how to handle the fact that the advice will basically be identical across all my repos\n. Thanks!\n. I imagine the doctor functions are something you run at the beginning of class to make sure that eveyone is set up ok.  It also seems useful to run them before release to make sure you're still good to go.  \nDoes that make sense?\n. Please restart R then install.packages(c(\"curl\", \"httr\")) then try again.\n. Oh good thought - I'll try mc.allow.recursive = FALSE\n. Tried it and still had same failure - it does always seem to happen once the last package is checked.\n. Reinstalling my revdep library seems to have made this problem go way \n. And also all platform information\n. The check in release() does - I think the check_version = TRUE also turns on url checking.\n. It's disabled by default because it's super slow and gives spurious warnings about CRAN versions.\n. I made this change because I assumed (possibly) incorrectly that you'd want to suppress building the manual, and if there was no manual in the package, you wouldn't need to check it.\n. So I guess we need to check during both building and checking? Or should the check move back to check()?\n. I think an additional argument passed down to both build() and check_built() would be best\n. Thanks!\n. @jjallaire @kevinushey is this feasible?\n. @jjallaire just to confirm, this is an RStudio issue, not a devtools issue?\n. Great\n. Thanks!\n. Thanks!\n. Fixed in fc3fd791e1abb6d225ed74bd89685e68c348541e\n. I think making the statement a question makes it easier to see what's happening.\n. I think I already fixed this\n. I thought I'd fixed this but I forgot to push :/\n. What do you want to do with the vignettes? Are you interested in previewing them locally or something else?\nIf you just want an installed version of the package that contains them, run install(build_vignettes = TRUE)\n. I'd be happy to review a PR of this. I don't think you need to worry too much about testing - as long as it works for public github, and the url is pluggable, it should work for any internal github.\n. Thanks!\n. Thanks!\n. Is there a backend for windows? makeClusterFunctionsMulticore() uses multicore, so wouldn't help on windows.\n. Which brings us back to parLapply() :/\n. @klmr ah thanks. But it looks like it uses this bash script: https://github.com/tudo-r/BatchJobs/blob/master/inst/bin/linux-helper. That's not going to work on windows.\n. @mllg is there someway for children to send information back to the parents for display? That's a deal breaker for me.\n. Much improved parallelism now in revdechecp. As long as ls and gcc are on the path, devtools won't mess with it. So I'd recommend you set up your path variables appropriately.\n. @jimhester can you take a look at this please?\n. Probably related to #1086 and #1099\n. I think @gaborcsardi has a separate package for this?\n. That's nothing something I would advice since examples are run automatically by R CMD check anyway, and should generally serve a different purpose to tests.\n. Thanks!\n. Thanks! Maybe this should be added to release() as well? (i.e. \"Have you used spell_check() to check for spelling errrors?\")\n. Closing since this seems more like an RStudio issue\n. Could you provide a little justification? I don't see why this would be useful.\n. I agree with @jimhester on this.\n. @krlmlr do you have any thoughts on this?\n. Already done, not sure when.\n. Thanks!\n. @gaborcsardi I was thinking you'd initialise the pipe in the parent, and then pass it to the children. The children would communicate status updates by writing to the pipe.\n. This is probably a duplicate of #1106\n. Right, there's already a lot of processes being created, but it doesn't seem to be a problem. \n. @krlmlr the goal is to add a warning to release() if there are commits on the master remote that you don't have locally. What's the best way to figure that out?\n. Ah the problem seems to be that git2r doesn't support the git protocol for updating: \"Error in 'git2r_remote_fetch': Unsupported URL protocol\".  That makes it not very useful for me.\n. Because they're checks that your git state is good, not for problems with the package\n. This is a roxygen2 bug - can you please file an issue there? (if it doesn't already exist)\n. Is this now resolved? (I think it is)\n. Thanks!\n. Thanks!  Do you have any thoughts on #1128?\n. Nice!\n. Crafty!\n. Yes, we need to do this\n. Ooops, closed the wrong issue\n. I think this looks good overall, but the main change is that you should use the host consistently everywhere - that means it should always look like http://api.github.com, including the protocol, but not including the path. I think that will simplify the code\n. Can you please merge/rebase? Something is currently wrong with this PR as it's showing changes to >100 files.\nIt would be great if you want to incorporate @jennybc's changes into this PR\n. Did you check all the check boxes?\n. Could you please file this on the roxygen repo? (since it's a roxygen2 bug)\n. Sure\n. @berndbischl maybe condition on interactive()?\n. What are you typically tearing down?\n. Maybe what we need for the non-idempotent stuff is to simply source a setup.R before running the tests and a teardown.R after the tests?\n. No, but that would be another approach - if you wanted to keep setup and tear down in the same file together.  Could have something that allowed you to register setup and teardown code for each run.\nI'm thinking something like:\nR\nregister_test_something(\n  setup = file.create(\"x\"),\n  teardown = unlink(\"x\")\n)\n. Moved to pkgload. Thanks!\n. Thanks!\n. Thanks!\n. @wch looks like this was you - would you mind taking a look?\n. Actually seems ok now\n. Not on CRAN yet\n. Ooops, I was looking for \"rmdcheck\"\n. Looking at a bit more, I don't think we can switch now because we have so much custom logic about envvars etc. Switching engines would be a lot of work\n. LGTM. Can you add a bullet to NEWS? Let me know once you merge, and I'll release\n. Thanks!\n. If your unloading code uses C, why not register it at the C level?\n. Yeah, I think that's a reasonable thing to add\n. Looks like a problem with base R to me\n. @jimhester can you review please?\n. @imanuelcostigan Do you think you'll be able to do this in the next week? If yes, we can get it into the next version of devtools; if no, it'll have to wait\n. Can you please merge/rebase? Otherwise looks good.\n. Thanks!\n. Please provide a reproducible example\n. I'd rather not add an argument for this, but instead provide some other way to scope your helpers so they work differently between formal and informal testing.\n. @pitakakariki any interest in merging and updating? We'll be working on devtools for the next few weeks. . I really don't want to introduce variation here - I think it's better that everyone use basically the same process.\n. Hmmmm, I was initially quite positive about this, but after looking at it closely the interface doesn't seem quite right to me yet. The problem is that this basically generates a citation that's the same as the default you get if you don't have a CITATION file. I think it would be more useful to provide an interface that helped you generate the citation for a published paper.  I'd be happy to re-review if that's what you implement.\nI include some code below that I wrote to simply the process of extracting author names. I don't think it's that useful now (since you don't just want to include all the package authors), but I'm putting it here since I did spend a few minutes writing it.\n``` R\npackage_authors <- function(pkg = \".\", has_role = NULL) {\n  pkg <- as.package(pkg)\nauthors <- eval(parse(text = pkg$authors@r))\nif (!is.null(has_role)) {\n    authors <- Filter(function(x) any(has_role %in% x$role), authors)\n  }\nauthors\n}\nauthor_name <- function(x) {\n  if (is.null(x$family)) {\n    x$given\n  } else {\n    paste0(x$family, \", \", x$given)\n  }\n}\n``\n. I think it'll be sufficiently different that it's better to open a new one\n. LGTM. @kevinushey can you take a quick look too please?\n. @Ironholds do you think you'll be able to do this in the next week? If yes, we can get it into the next version of devtools; if no, it'll have to wait\n. Sorry for never merging this :(  And this code has migrated to the usethis package. Would you mind resubmitting over there?. Yes - because using fixed dependencies in R is not good practice (because each library can only have one version of a package, using fixed dependencies makes mutually incompatible versions easy)\n. Thanks!\n. I think that's a bad idea because you shouldn't be recording password like things in your DESCRIPTION.  I think using the github PAT env var should work?\n. Yes, this is because the README is designed to be read on github.\n. Thanks!\n. Fixed by #1192\n. Also needs a bullet in NEWS\n. It looks fine to me, but you're probably more familiar with this code than I am, so take it with a grain of salt. Feel free to merge.\n. Oh I like that idea!\n. But ifexport_all = FALSEyou can't test internal functions, which is extremely important. I don't think this should be an option.\n. Those are options to your package?\n. No, the point ofload_all()is to make it easy to interactively develop the package. This is a big help for people starting out with package development.\n. If it's really causing pain, I'll take a PR to add an option\n. Moved to pkgload. PR at https://github.com/r-lib/pkgload/pull/41. PTAL - I added a check for libcurl and removed the RStudio license block.\n. LGTM\n. Thanks!\n. I'd rather tackle this meta-problem by providing better tools to detect which functions aren't important, i.e. #596 \n. LGTM\n. Yes, you'll need the dev version of devtools\n. Thanks!\n. This is unlikely to be a devtools problem. You might try asking on the Rcpp mailing list for help.\n. LGTM. @jimhester are you ok with merging?\n. Thanks Ian!\n. @imanuelcostigan I'm merging pull requests with squashing so it doesn't really matter.\n. @imanuelcostigan would you be interested in porting this to remotes? That's what devtools will use for installation in the future. We are working on breaking devtools up into smaller pieces to try and make development a bit more fluid.. Thanks!. It's an internal function and I'd prefer to not export it as it's not pivotal to devtools.\n. Would you be mind porting this to [remotes](https://github.com/r-lib/remotes)? That's what devtools will use for installation in the future. We are working on breaking devtools up into smaller pieces to try and make development a bit more fluid.. Thanks!!\n. Sounds reasonable to me. Does this solve a current problem?\n. Ooooooooh, that explains a lot of the problems I've been having too\n. LGTM\n. LGTM\n. Yeah, I'm not entirely sure what the message should be here. I find it a helpful reminder because often I forget to check stuff in and then what's on github is subtly out-of-sync with what's on CRAN.\n. Re-opening just as a reminder to improve the text\n. It doesn't feel too dangerous to me as you still have to confirm submission with the email link.\n.submit_cran()should probably work the same way asbuild_win(), i.e. move the confirmation & email check out ofrelease()`.\n. Seems to have been bumped a while back. Thanks for the bug report!. This feels out of scope for devtools, now that we're splitting it into smaller pieces. \nThere isn't an obvious home for it yet, but it seems related to https://github.com/r-lib/pkgload/issues/42, by @billdenney. Checking seems too aggressive to me. I'd prefer to start with a function that just tells you what that version is.\n. This seems like a roxygen2 issue, not devtools.\n. Duplicate of #1464. Hmmm, might actually be a different problem, so I'll keep this one open.. This seems like a good idea, but unfortunately it's not high enough on my priority list that I will implement it myself. However, I'd be happy to review a PR.. Yeah, that seems a fine place to start for a PR.. Devtools will be switching to use remotes in the future, so I'm going to close this issue. Thanks for the PR!. devtools release check flags it too I think\n. We'll be adding automated tests to ensure the devtools works with R 3.1.0 very shortly. We'll see if it's possible to push back to R 3.0.3.. Is this still a problem?\n. It automatically calls Rcpp::compileAttributes() for you, which I think is important.\n. I think if you are hand-tuning the output from Rcpp::compileAttributes() you are going to be in a world of pain anyway.\n. No one seems interested, so will wait for demand.\n. isTRUE() would be a more compact fix \n. Thanks!\n. Duplicate of #1244 \n. Of #1250 I mean\n. Could you please add a bullet to NEWS?\n. This is the strategy implemented in revdepcheck, and boy is it better. Thanks!\n. I like it. As far as I know, there are no problems with everyone re-exporting the pipe.\n. Also it might be worthwhile to let this simmer for a bit, with the aim of eventually becoming use_tidyverse() or similar.\n. Would you be mind porting this to remotes? That's what devtools will use for installation in the future. We are working on breaking devtools up into smaller pieces to try and make development a bit more fluid.. This will be dealt with in remotes, particularly as we rethink how installation and updates should happen.. @jimhester is this good to merge?\n. I'd prefer to leave this for now as this code is likely to be moving to a new home soon\n. We'll tackle this when we work on package installation in general.. I don't think this is a devtools issue\n. Sorry, I forgot about your PR and ended up fixing by hand.. @dmurdoch I'm finally getting around to implementing this. Did it make it into R-patched?\n. I'm working on devtools at the moment, but we're planning for a big release (splitting devtools up into many smaller pieces), so it's unlikely to be ready this year.\n. Could you please provide a minimal reprex? You need to at least provide a link to sna, but ideally you'd do work on a copy of the sna package progressively removing code until you figure out exactly what's triggering the problem.\n. I think you misunderstand load_all() - it's meant to be called on a local development package, not an installed package.\n. Closing since should be better in revdepcheck package. If not, can you please file an issue there?. Oops I checked but must've be blind :(\n. That feels a little heavy to me. Surely you're previewing them as you write them?\n. I'd rather leave this for now, as the package install code is likely to be moving to a new home\n. This now feels out of scope for devtools. I have local code to achieve this and will package up at some point. Could you please add a news bullet and rebase/merge?\n. That should simplify the install instructions in the readme, right?\n. Can you add please? Might also be worth adding deprecation notice to build_github_devtools()\n(But can you please verify it does actually work on windows)\n. Thanks!\n. LGTM\n. Looks great - thanks!\n. Thanks!\n. Could you please add a bullet to NEWS?\n. Could you please include a minimal reprex? What code are you running to  trigger the segfaults?\n. And a sessionInfo() please?  (Although I can't imagine that this a bug in devtools)\n. That seems a little aggressive to me - don't we want to encourage people to set globally?  Maybe just a message if not set?\n. Please move to revdepcheck if you're still interested. I'd prefer to leave this for now, as this code is likely to be moving into another package in the near future.\n. remotes\n. @gaborcsardi would you consider adding remotes helpers to desc?\n. Yeah, I like it.\n. Thanks!\n. Duplicate of #1401. Ignore no longer seems necessary with revdepcheck package since we have better timeouts.. I'd like to have a plan to get this merged into the next release of devtools. Is there a good list of missing functionality?\n. Yeah, that's a lot of stuff. \nI think we also need to do quite a bit of refactoring with an eye to making it all easier to test (i.e. separating out a data structure that describes a set of need actions and performing those actions). I'm not sure how much of that you did in remotes?\n. Let's close this for now. I think we'll aim for a release of devtools that incorporates the existing diaspora about from remotes. And then we'll aim for another release fairly soon after that aims to switch over to remotes.. This would require quite a bit of NAMESPACE parsing, so I'm not sure it's worth the effort.\n. Moved to pkgload. In the future, please include Fixes #issue-number in one of the commit descriptions\n. I can't reproduce this problem unfortunately.. Yes, that is my understanding.\n. It's pretty low-priority right now - if it happens it's likely to happen in another package.\n. We'll probably split up in to pkgdeps for determining the complete set of dependencies of a given package and comparing against what you currently have installed; and pkginstall for installing individual packages from different sources.. It seems a bit aggressive to run this every time. Just a helper function would be handy though.\n. Moved to pkgload - we'd love a PR, but unfortunately it's not pressing enough to work on automatically.. I think this would feel better as a separate function writing to (e.g.) timing.md. \n. LGTM\n. LGTM - just needs a news bullet\n. LGTM - just needs news \n. What's use_src_deps()?\n. Why do you want the manual?\n. I think we'll implement the build_manual() function, but I think very few people use the pdf manuals these days.. Should be much better in revdepcheck please file issues there if not.. This will be/is resolved in the new revdepcheck package. I think it's going to be hard to do better without sending data back to the primary node.\n. Let's leave it in suggests for now, and we can move into imports once we've extracted the stuff CI tools needs into a separate package. \n. Thanks!\n. Thanks!\n. Migrated to desc and fixed there. @shapenaji unfortunately this is unlikely to be devtools fault, but we'll take a look.\n@jimhester any idea where the cert validation dialog is coming from?\n. That's probably not devtools fault either - I suspect you're using RStudio?\n. Duplicate of #1346 . WFM.\nCan you install other packages with compiled code? e.g. devtools::install_github(\"tidyverse/readr\")\n. Yeah, you generally shouldn't be including inst/docs in your submission. I'll look into this whole workflow and figure out what's going wrong.\n. I have never seen this problem so I'm not sure what's different with your workflows. Do you have files in inst/doc before submitting?. I think these will move to calling functions in @gaborcsardi micropackage. He should be able to suggest a good home for the unzip wrapper.\n. I'd rather have one overkill package that many smaller packages that each solve part of the problem.\n. I'd rather not do this here - instead it should be a feature of the remotes package, which devtools will use in the future.\n. Could you please try making a minimal reprex with a public facing repo? Otherwise it's unlikely we'll be able to track down the problem.\n. In that case, it's probably a duplicate of #1280. Can you please add a bullet to NEWS?\n. Why are you using https with self-signed certs? \n. Ok, makes sense. This isn't super high priority, but we're planning some work on the install side and we'll try to get this in.\n. Fixed in pkgload. I'd rather think about generalising it slightly (what other devtools functions work in a similar way?) and pull out to a separate package.\n. Ok, then lets close for now.\n. Could you eliminate the dependency on datacheckr?\n. I don't have time to think through this through at the moment, but you need to acknowledge that the code was extracted from devtools and I am the primary author.. Fine. This causes pain in revdep_check_install if there are any CRAN packages with a BiocViews setting because the library is in the wrong place, since biocLite is undocumented, getting it to install in the right library is a pain.\ncc @jimhester \n. This is now resolved, right?\n. Can you please put in check-devtools.r, following the template in release_checks()?\n. Are you still interested in finishing this off? If I don't hear from you in a week, I'll assume you're not, and I'll close the PR.. I now think we can fix this automatically: https://github.com/r-lib/pkgbuild/issues/10.  Sorry for not realising earlier before you put all this effort into a PR.. This feels out of scope for devtools to me. We will fix eventually when we turn out sights on a better package for performing file and directory operations. I hate sourcing a random file, but it's clearly the best solution \ud83d\ude04 \n. Thanks!\n. Looks good - thanks!\n. I like this idea, but I think the timestamp needs to only appear in one place, and I'd prefer something custom created with strftime() + Sys.time(). Maybe \"10:30pm (2016-10-11)\".  \nWhile you're in there, it might be worth updating the time limit. I'm seeing times of more like 15-30 minutes lately.\n. @jimhester can you please squash-merge by hand?. Thanks!\n. Could you please add a bullet to NEWS?\n. Could you please provide a minimal reprex?\n. Moved to pkgload \u2014 but we can't reproduce locally.. Could you please take a look at the build failures?\n. Duplicate of #1266 \n. It should also include library(xyz) in that chunk\n. Moved to usethis issues.. Likely to be duplicate of #1280. Would you be mind porting this to remotes? That's what devtools will use for installation in the future. We are working on breaking devtools up into smaller pieces to try and make development a bit more fluid.. @jimhester I can't quite imagine why this would fail. It's not like there's a separate package index apart from directory structure.\n. That seems out of scope for devtools - the github support is just the minimal needed for installing from github. I'd rather put more advanced stuff in a separate package (like gh).\n. @jennybc where do you see people using this?  It's not quite a use_ function because it doesn't modify any files.\n. Moved to usethis issues.. Yeah, that's not the point of cran = TRUE - it's more about enabling slightly more tests in R CMD check\n. Still fails due to lack of trimws()\n. Should we take another pass at this, or go for R 3.1?. Superseded by #1560 . @jimhester can you please port to pkgload?. Duplicate of #1346. I think this is out of scope for devtools just because we have so many more pressing problems. I think some standard for badging in-development packages is a good idea though.. We'll be deprecating revdep_check() and friends in the very near future in favour of the vastly superior revdepcheck. Can you please give sessionInfo()?\n. What happens if you Ctrl + C during the install? Can you get a traceback()?\n. The error you saw with the local version usually implies you need to restart R.  Can you try that?\n. I don't think there's much we can do here, although it's not clear to me why ssh-agent is involved at all.. Thanks - this should be resolved in revdepcheck (which does a much better job installation generally). If you still want this, can you please file at https://github.com/r-lib/revdepcheck/issues ?. Unfortunately that message is generated by R, not devtools, so there's no easy way to suppress it.. Can you easily get back to a place where it's possible to finish this off?. Yeah, I think that would be great.. Moving to a meta issue. Can you please provide a minimal reprex (reproducible example)? The goal of a reprex is to make it as easy as possible for me to recreate your problem so that I can fix it: please help me help you! \nIf you've never heard of a reprex before, start by reading \"What is a reprex\", and follow the advice further down the page. Please make sure your reprex is created with the reprex package as it gives nicely formatted output and avoids a number of common pitfalls.\nFWIW I don't think your explanation of the cause is correct because the shims are attached close to the global environment; they affect user code, not code in packages.. Ah so citation() only fails if you've run load_all(). That seems like a sufficiently rare case that I'm just going to say \"don't do that\". I'd be happy to review a PR if anyone figures out a fix, but otherwise it's sufficiently low-priority that it's unlikely to be fixed otherwise.. Thanks! Unfortunately revdep_check() is going away in favour of the new revdepcheck package so this is no longer relevant. Sorry for taking so long to get back to you!. Thanks - this is also fixed in the revdepcheck package. revdep_check() is going to be soon gone in favour of the much better revdepcheck package.. Thanks - merged by hand.. Is this still failing for you? What version of GitHub enterprise are you using?. Moved to a meta issue, but it would still be useful if you could answer the above questions here.. This code has moved to pkgbuild, and it seems to be fine on appveyor: https://github.com/r-lib/pkgbuild. I'm assuming this is fixed now. You appear to be using the githubinstall package. You'll need to file an issue there.. Can you please provide a link to the source code for your package?. Ok, if it does crop up again, please file an issue at remotes, which is where all package installation code is moving.. Can you please provide a link to the source code?. I've closed this issue due to lack of requested reprex. If you still care about this bug, please open a new issue with a reprex.. I bet it's requesting the passphrase to unlock your ssh keys.\n@krlmlr any ideas how we can fix this?. @stewid what happens if you have a SSH key passphrase? Does it try and prompt you to enter the passphrase, but it's failing because it's running inside RStudio, not a regular console?. Thanks @stewid !. If you're on windows, you'll also need to install Rtools. Confusingly, the way to build a binary package is to call R CMD install. That means you need to make sure your file is also listed in .Rinstignore.. file:~/xxx is not a valid URI, so I'm not sure why you expect it to work?. I've seen this too and I don't understand why \ud83d\ude22 . Can you please provide a minimal reprex (reproducible example)? The goal of a reprex is to make it as easy as possible for me to recreate your problem so that I can fix it: please help me help you! \nIf you've never heard of a reprex before, start by reading \"What is a reprex\", and follow the advice further down the page. Please make sure your reprex is created with the reprex package as it gives nicely formatted output and avoids a number of common pitfalls.. I've closed this issue due to lack of requested reprex. If you still care about this bug, please open a new issue with a reprex.. devtools::check() just calls R CMD check - it's no more rigorous than using RStudio.. Thanks!. All the devtools revdep checking functions will be deprecated shortly in favour of the vastly better revdepcheck. Could you please both provide session_info()? (Just the OS part, not the packages). It seems to be the same problem as #1464, so lets move all discussion there. It looks like it's going to be painful to track down the issue since it's seemingly random on which computers it works.. It's fixed in the dev version. I think this was just a temporary win-builder problem.. Maybe release() should only document() if a RoxygenNote is present in the description?. Can you please move to revdepcheck?. Thanks! We might as well remove both comments.. Are you sure you just didn't get unlucky with the timing? It's possible that the binary appeared on CRAN in between your runs.. https://github.com/chfleming/ctmm doesn't exist?. We can't simply make that change since it breaks all the error handling.  Regardless, this code will be moving to remotes where we will consider other approaches.. Build and reload is an RStudio function that installs the package, restarts R, and then calls library(). I'm surprised that something is going wrong here, but I see the issue too.\n@kevinushey @jjallaire could you please take a look?. I'm going to close this, and leave in the hands of the IDE team. Since this is caught by R CMD check (with the appropriate version of R) it's outside the scope of devtools. You should generally be using build_win() or rhub::check_for_cran() to make sure you've checked with the latest version of R.. Shouldn't you do this yourself by providing a Makevars?. Could you please merge/rebase and add a bullet to NEWS?. Fixes #1449. @amcdavid are you interested in finishing this off?. No problems - @jimhester can finish it off. Sorry for letting it languish for so long!. This appears to be a duplicate of https://github.com/r-lib/pkgload/issues/39. This is fixed in usethis, which devtools will use shortly.. Can you please provide a minimal reprex (reproducible example)? The goal of a reprex is to make it as easy as possible for me to recreate your problem so that I can fix it: please help me help you! \nIf you've never heard of a reprex before, start by reading \"What is a reprex\", and follow the advice further down the page. Please make sure your reprex is created with the reprex package as it gives nicely formatted output and avoids a number of common pitfalls.. Maybe you'd like to do a PR instead?. @Neil-Schneider I think you did the PR on the wrong repo.. Oh I see you did it in the right place and @jimhester merged it. I think this is already covered in the second paragraph, so if more clarification is needed, it should go there.. The expectation of one package per repo is deeply baked into devtools, and you will be sailing upstream if you try to fight it.. Can you please file a reproducible example over at pkgload? That's where this code now lives.. @gaborcsardi @jimhester have you seen this before?. @imanuelcostigan you might also try comparing getOption(\"unzip\") on your computer vs. your colleagues. It's possible that this may also be related to the path length.. @gaborcsardi good point. I'll keep the other issue open. I'm going to reopen this so we can include some basic fix for devtools (to at least help diagnose the problem). And devtools does respect the unzip option, so you might able to set the option to overcome your problems (but you might want to check that different versions of zip consistently fail or not in case the problem has a stochastic component).. I think we'll close this issue since it doesn't seem like devtools' problem - but feel free to continue to contribute insights here (so people find them when googling), and we are likely to explore alternatives to the internal zip utility in remotes.. Yeah, I think this is out of scope for devtools, since:\n\nIt's really R's fault\nThere's already an existing best practice (using PACKAGE or registration) that avoids the problem.. Just delete the contents of NAMESPACE, without deleting the complete file.. Since the error is likely coming from install.packages() not devtools we won't fix here. But we'll definitely be thinking more about this problem in the general context of robust package installation.. You should use testthat::test_path() instead - it's designed for exactly this scenario.. data.table uses some magic to determine if it's needed or not. Clearly the magic is failing due to the special way that load_all() simulates package loading.  \n\nI'd recommend filing a minimal reproducible example at pkgbuild, which is where the package loading code now lives. You'll probably need to create a minimal package that illustrates the problem and host it on github.. Sorry, I meant pkgload, not pkgbuild. It's likely because the check occurs in a newer version of R than you had installed. In general, it's a good idea to run build_win() before submitting to CRAN because then you know that you're running the same checks that CRAN will.. revdep_check() will be deprecated shortly, in favour of the vastly superior revdepcheck package. Duplicate of r-pkgs/usethis/issues/19. The error message suggests that you have devtools loaded already. I'd recommend trying again in a fresh R session.. revdep_check() will be deprecated shortly, in favour of the vastly superior revdepcheck package. Thanks - this should go to remotes too please.. Can you please try with sessioninfo::session_info() and if it still happens, file the bug there?\n(https://github.com/r-lib/sessioninfo). Should we make them look the same?. This is useful but out of scope for devtools, especially as we are moving to a bunch of smaller packages (i.e. devtools will become more like the tidyverse package - it will aggregate together tools from a bunch of other packages).. Yeah, I also don't think this is needed.. For now, just stick with the CRAN version. There's no need to get the dev version.. Works for me with dev devtools.. Fixed in usethis package, which devtools will switch to using shortly.. Would you mind moving this to remotes? (if it's not already fixed there). That's where all package downloading code is moving.. I think it can may be removed altogether. Moved to https://github.com/r-lib/usethis/issues/37. Yeah, I think build_win() is now mostly for historical interest + one final check before submission.. @gaborcsardi I have a vague memory of buggyness, but maybe that's fixed now.\nThis should move to remotes, right?. This needs an update to rtools-metadata.R in pkgbuild. \n@jimhester can you please handle?. Can you please move to usethis? That's where all this code is moving. Yes, this is a deliberate design to make errors more clear.. I think we'll probably totally rethink the release() function in the near future. I don't use it any more since it just seems to cause me more hassle than it saves.. I don't know exactly - it's just some additional friction so I've basically switch to just using submit_cran(). I think it's probably just because my workflow has drifted a bit and so the questions aren't quite right.. @jeroen can you please take a look? I think this is your code. Yeah, looks like it. Anyone want to push to R-devel / bugzilla?. I think this out of scope for devtools - I think it's good to include the badges, although we may need to think about how to make clear they're apply to the dev version.. revdepcheck is vastly superior to devtools::revdep_check(). I highly suggest you switch - we'll be deprecating revdep_check() v. soon.. We won't fix it in devtools. If it's still a problem we might consider fixing in revdepcheck.. revdepcheck already has better defaults for this. Can you please create a minimal package that illustrates this package and then create a reprex using the reprex package?. This is likely to be a bitbucket issue not a devtools issue. Devtools just request the download url with http basic authentication.. This looks ok to me with sessioninfo::session_info() and devtools will be switching to that in #1552. Closed in favour of https://github.com/r-lib/usethis/issues/36. It's hard to know what the problem is without more context. devtools certainly works fine with dlls.. Oh, you're just copying in DLLs from elsewhere. It's possible that devtools has never been tested for that use case.  \nIt looks like the error is coming from your call to library.dynam() which obviously can't find the DLL because the package isn't installed. I think you'll need to call dyn.load() instead.. @jimhester can you please have a look at this travis issue?. This code has moved to revdepcheck which generally has a much better strategy for installing packages. Thanks for the code, and my apologies for not getting in touch sooner.. I'm not sure why you've filed this issue here. I think you want https://github.com/rstudio/reticulate. Can you please start by filing an issue that describes where this occurs?. Closing, since this is a roxygen2 issue.. This code now lives in usethis. Can you please refile there if you're still interested?. I'd rather solve this by teaching the user how to set a better tempdir path. Oh I forgot that it's set before the process starts up.   But I'd prefer some other fix because there's unlikely to be devtools release for some time, and most of this code is moving into remotes.. Could you please rework your reproducible example to use the reprex package ? That makes it easier to see both the input and the output, formatted in such a way that I can easily re-run in a local session.\nAdditionally, GitHub issues use markdown and they're much easier to read if you learn a little bit about it. The most important thing is to put your R code inside a block that starts with ```R and ends with ```. \nPlease update your original issue rather than adding new comments.. Duplicate of #1430 . Can you confirm that this definitely does what you want? The documentation just says \"Weave and run texi2pdf in quiet mode\". This appears to be fixed in the remotes package, which devtools will soon switch to using.. I think it's a simple omission.\nShould this get fixed in devtools or does it belong in remotes?. @gaborcsardi yes, we should be able to use the internal unzip command, I think.. I feel like using unicode file names in an R package is likely to cause problems elsewhere.. The other approach would be to add unzip support to zip and then unconditionally use that. What's the use case for this? knitting a vignette in order to preview it already happens in a temp dir.\n(If you still think it's important, can you please refile with motivation at https://github.com/r-lib/usethis/issues/new). use_readme_rmd() now lives in usethis, which contains an up-to-date version: https://github.com/r-lib/usethis/blob/master/inst/templates/omni-README\nWe'll be updating devtools to use usethis v. shortly.. Should devtools just depend on usethis?. I think that's the only downside? Otherwise we'll have to keep devtools in sync, and the documentation is a pain.. Oh darn. That means we need to deprecate some how. But I don't think we have a good existing strategy for deprecating functions that are moving from one package to another.. Yeah, lets remove the withr wrappers, and take the same approach for the use_ functions.. The plan is also to add to Depends, right? . We could set .conflicts.OK <- TRUE in usethis. Ok, I think 3.0.3 is going to be too much work, so lets stick with 3.1.0.  \n@gaborcsardi could you do a CRAN release of desc so we get the 3.1.0 support?. @gaborcsardi I vaguely remember some discussion we had about this but I can't remember where, or what the conclusion was. But there was definitely something that was going to be hard to work around. I think we can make a push to get 3.1 everywhere and then we'll hold it there for a while and see how it goes. . Thanks for all your work on this!. Either install the binary version, or just wait a couple of days until the binary is updated on CRAN.. I've closed this issue due to lack of reprex. If you manage to capture the logs, please file a new issue.. I think resolving this issue is outside the scope of build_vignettes(). I agree that is a frustrating problem, but I don't think manually building vignettes locally is the way forward.. Per discussion in the issue, this seems unlikely to be the right fix. I don't think this is perfect, but the docs should be better now. It's hard to succinctly describe all the details.. Yeah, probably good idea. Thanks!. Probably because implementing it for install_git is more challenging. Can you please continue discussion over at remotes? That's where devtools installation code is moving in the near future.. @Neil-Schneider this is something that we're unlikely to find the time to work on, but it's possible to create a roclet in any package, so there's nothing holding you back from working on it \ud83d\ude04 . I don't think its necessary - generally saving is not a dangerous option, and it's more frustrating to forget to save and then wonder why loading the package didn't change anything. The keyboard shortcuts do already save, so it's mostly a matter of bringing the CLI up to spec.. @DataStrategist  If you want to display live vignettes, the best solution (IMO) is pkgdown. You are welcome to try something else based on not ignoring inst/doc, but you're on your own.. @DataStrategist pkgdown turns your vignettes into a website. I don't think there's anything we can do except wait for a release of testthat (which should hopefully come in the next month or two). This is likely to get completely replaced once we move to remotes\n(BTW when did the cool inline previews of links to code start happening???). This might be better to do inside of roxygen since it'll be easier with the parse data (so you can conditionally perform it based on the tag type). Roxygen's data structure isn't currently exported.. The long term solution is here: https://github.com/klutometis/roxygen/issues/372. @kevinushey any ideas?. Thanks - we prefer to avoid sQuote() because it's behaviour differs from system to system making tests more challenging and leading to spurious diffs in files. But @jimhester can make the same change by hand, no need to revise the PR.. Funnily enough @jennybc was just complaining about the same problem in roxygen2. Improving this behaviour seems like a good idea, but unfortunately it's not high enough on my priority list that I will implement it myself. However, I'd be happy to review a PR.. What does pkgbuild::has_build_tools() return? What about pkgbuild::has_compiler(debug = TRUE)?  . revdep_check() has been deprecated in favour of revdepcheck. @qingchenyuanluo we've made this change, so you just need to reinstall devtools from github.. 5 seconds seems long to me for something that needs to be run interactively. \nWill Escape/Ctrl + Break stop the execution of a slow completion? Does it block UI events? (i.e. can you keep typing while it looks up?). We've totally changed the interface for this function (now functions) in the next release. Thanks!. What is API 7?. I have no idea what you are talking about. I think you have a wrong repo. Yes!. I think we should also have check_win_devel() and check_win_release() just because for the last year I thought build_win() defaulted to \"R-devel\" (and typically you only want to run one). Oh that is super confusing!. Thanks!. @jeroen any ideas?. Could you please provide some details?. @jennybc is already working on this. You're using load_all() in a bit of a weird way - you should be giving it a directory, not a file. \nIt's also possible that you accidentally source()d a file (I do this all the time) and so you might also try restarting R with a clean session.. Can you please try with the dev version of https://github.com/r-lib/pkgbuild, and if it still doesn't work, file an issue over there? We'll be using pkgbuild in the next version of devtools (which should be coming soon). We're just calling spelling::spell_check_package(), so @jeroen will need to fix this in the spelling package. Would you mind filing an issue over there?. You might also try deleting your library and reinstalling. Crashes of this nature are often caused by conflicts between the built and installed versions of Rcpp.. That's an RStudio function so you might want to file an issue at https://github.com/rstudio/rstudio, but from the error message I suspect it's a problem with one of your vignettes.. Thanks!. Now at https://github.com/r-lib/pkgbuild/issues/17 and https://github.com/r-lib/rcmdcheck/issues/48. Requires https://github.com/r-hub/rhub/issues/98. Maybe that's a better approach - it'll change the signature, but it's only in the dev version.. Probably should say usethis::proj_set() instead of setwd().. Thanks!. Yes please.. Sometimes compiling a package from scratch does take a long time. Does it eventually finish?. No, but we're working on other faster ways of downloading by default.. We should probably re-export to reduce the time needed for release.. Thanks!. Would you like to do a PR?. It already does?. @ThisIsJeron we strongly recommend against modifying the system path. A somewhat related idea: if we adhere to the convention that every file in R/ should have a matching file in test/ we could simply have a \u201ctest current file\u201d function, and expose it in an add in. I think that might be a lot simpler and still solve most common testing challenges. . Ooops, sorry!. I think you mean \"British\" spelling @jimhester \ud83d\ude09 . It's not sorry, it's a limitation of base R. This feels like a usethis function to me - maybe browse_github_pat()?  We could eventually have use_github_pat() once we have more wrappers around modifying .Renviron\n. Yeah, although for a resubmission, I often don't run the full release() cycle. We're a little more aggressive in devtools because people should only be using these functions interactively; we don't need to care so much about breaking CRAN revdeps.. @stewid it's not clear to me that actually makes life substantially easier for developers. You'd still need a packageVersion(\"git2r\") switch if you wanted to maintain backward compatibility.. If it's only six, I wouldn't bother with multiple releases - just give authors a month's notice before you submit to CRAN.. Want to do a PR??. Rebuilding README.md (+ improved vignette workflow) should also involve installing development package to a temporary library.. I think we'll use this in enough places it's worth baking in to devtools. I type that wrong every single time \ud83d\ude2d . @kevinushey how hard would it to be add something to rstudioapi to tell us what help file is currently open?\n(@jimhester since we're already shimming ?, couldn't we track the last help file loaded?). I just realised another challenge \u2014 devtools::document() is usually run in another process. But document() can't call rstudioapi, because it's not run from RStudio (usually). I don't think this solves the whole vignette workflow, but it obviously improves things.\nFor tidyverse packages, I think there's a strong pressure to move towards articles and away from vignettes since the vignettes often need graphics and hence end up rather large. Downloading large vignettes that are more easily discoverable from the web doesn't seem like a big win.. (To be clear I think you are good to merge). * Might be worth mention the keyboard shortcuts for RStudio users?\n\n\nI think you should add test_coverage(), and remove run_examples(). Also mention check_rhub()?\n\n\n\"drafts the email\" -> something about cran comments.\n\n\nROpenSci packages book link is missing\n\n\nIs it time to retire the guarantee? No one has taken me up on it for several years.\n\n\nCode of conduct heading is too large?\n\n\nThank you for spelling focussed correctly.. I think this is a documentation problem since reload() is unrelated to load_all().. My memory is that the version requirements of suggested packages aren't enforced, but I might be wrong.. Hmm, looks like it should be an error? I'm in favour of just bumping if you're ok with it.. Appveyor failure seems unrelated; I think this is good to merge.. Would you mind filing a roxygen2 bug so I don't forget?. Yeah, that seems like a good idea.. But it has to do it for every function, so even a moderate expense is going to add up (whereas checking for an attribute could take an early execute if there were no attributes).. I ended up memoising (as possibly a premature optimisation) your basic approach so now we get:\n\n\n```\n\nconflicts_find(c(\"usethis\", \"devtools\"))\n26 conflicts\n use_appveyor       : [usethis]\n use_build_ignore   : [usethis]\n use_code_of_conduct: [usethis]\n use_coverage       : [usethis]\n* use_cran_badge     : [usethis]\n...\n```\n\nwithout any modifications to devtools \ud83d\ude04 . I suspect at the time it was written we might not have fully understood the difference between loaded and attached.. Oh I didn't notice it is a straightforward alias; conflicted should be eliminating the conflict a different way \ud83d\ude2c . Now in https://github.com/r-lib/conflicted/issues/25. Oh the problem is that use_data() isn't re-exported, as you have:\nR\nuse_data <- usethis::use_data\nThis copies usethis::use_data() at package build time.. Maybe we should have a pkg_sitrep() too?. If has_devel() doesn't return an error, you are good to go.. I think devtools is primarily about doing stuff where as usethis is about creating stuff; or maybe usethis is simplifies things that you do once (like creating a file), whereas devtools automates things that you do multiple times (like running all tests).. Yes, but instead of the dummy function, use local()\n. And you can do the whole thing like:\n``` R\ndev_mode <- local({\n   .prompt <- NULL\nfunction(on, path) {\n     ...\n     .prompt <<- getOption(\"prompt\")\n   }\n})\n``\n. I don't think this is needed for this function\n. I think source url would be a better name.  Probably works with ftp too.\n. Do you need to close this connection?\n. Maybe add a note how this is a thin wrapper combining source and getUrl especially to work with https urls.\n. What's thedQuotefor?\n. Can you wrap these lines to 80 characters?\n. I wonder if this function should be vectorised?\n. I think it should source all files by default (if that's not too tricky) - that's why I suggested vectorisingsource_url. Ok, good point.  Let's leave it as is.\n. Can you use paste instead? (for consistency of style).  And messages automatically get newlines\n. I think these changes are spurious too (because of a bug in roxygen2 where it relies on the default collation), but I can fix that.\n. Could you please put function on the same line, and a put a space after()?\n. Could you please use<-for assignment, and put spaces around infix operators? (e.g.=)\n. Can you please do# @importFrom utils readRegistryand just call the function name directly?\n. Can you please use{}?  And this should useinherits. Good point - just leave it as is.  I wish packages exported the same functions on all platforms, and just threw an error if the platform wasn't supported.\n. Could you please make the titles a little more consistent ? e.g. start with a capital letter, end with a period, and put a blank comment line afterwards.\n. Can this now change to justRtools not in path?\n. Is that a typo?  And why do we need a try statement?\n. Could you please put spaces after commas and around =?\n. Yeah,get,setandaddcould probably all be documented on the same page.\n. I guess I don't see how a problem could arise since you're already checking that the directory exists.\n. Are you sure you need to do all this path munging?  Couldn't you just usenormalizePath?\n. Could you please start each title with a capital letter and end with a full stop and empty roxygen line?\n. This function should invisibly return the old path\n. Can you please make sure you have a space after each comma, and around=?\n. It's better to useon.exithere, so that the env vars are restored even if there's an error.\n. I think you should make the arguments matchinstallexactly.\n. I still don't understand why you need to do this - could you provide an example wherenormalizePathdoesn't already convert a relative to an absolute path?\n. Maybe namespace them likedevtools.github.useranddevtools.path?\n. Can you please put the{on the same line?\n. How aboutsetdiff(names(op.devtools), names(op)). Oh true, when I first wrote it I thought you could send a zero length vector to options, but you can't.  Annoying!\n. Yeah, you're right.github.useris sufficient.\n. I wonder if the current.onAttachfunction should actually be.onLoad. On more thought, I think the current behaviour is correct.\n. You can just usestop_for_statusinstead\n. I thinkpath,auth(oruser,pwd),destdirwould be a better argument list.  And I'd probably call itspider_svn. You can usefile.pathhere\n. I wonder iflist2env(as.list(src), dest)is a better idiom for this?\n. Also be careful about objects starting with.. Could you also add a warning for this case?  We should be encouraging people to move to the new directory structure.\n. It probably won't be - but I think that's ok.\n. I really don't see the point of usingpackage.skeleton, and I'd much rather just do everything ourselves. \n. I would drop this all together\n. I'd recommend using lists and then usemodifyList. Is that useful at this point?\n. There's alreadyload_pkg_description. I think this should be calledsave_pkg_descriptionand live inpackage.r. I'd just condition on something likeif (length(dir(path_vig, \"Rnw\")) > 0). Well both, but particularly checking the package (check should already produce a message)\n. A \"dependent\" package?\n. Should these functions be exported?\n. Does this documentation explain anything?  Switch#'to#?\n. typo\n. Oh ok, that makes sense.\n. Yeah, that's right.\n. The advantage of paste is that we don't need to add a dependency onstringr. Are suggests still loaded in here? If so, they probably shouldn't be.\n. That never made it into a released version, so it doesn't need a news item\n. Accidentally included?\n.find.package(name)?\n. Bump\n. If we need this, then I think it's a sign that we still need to overridesystem.file. But couldn't we just insert it in the namespace environment?\n. Yes, exactly.\n. I meant that devtools would insert it in the namespace environment of every package loaded withload_all- then you can always rely onsystem.fileto find the files\n. That's what we want, right?\n. You forgot to export this method\n. Can you usedir(for consistency) and pattern should really be.c$\" if we're being picky\n. Build clean uses unlink(c(Sys.glob(c(\"*.o\", \"*.sl\", \"*.so\", , \"*.dylib\")), paste0(pkgname, c(\".a\", \".dll\", ,\".def\")), \"symbols.rds\"))\n. I kind of prefer if (xor(is.null(branch), is.null(pull)) stop(...)\n. We should probably rename branch to ref too, since that's what it really is\n. Fixed - thanks.\n. I think you can just use suppressWarnings here?\n. This title would be clearer if it contained a verb\n. If show = TRUE it's not run, just commented out. If show = FALSE, it's run.  (These params correspond to the Rd tags not what run_example does) \n. I agree in principle, but a better way to do this in general would be to track whether or not the package needs to be reloaded, so we can do it a minimal number of times regardless of in what order the functions are called.\n. Using regular expressions to do this seems really inelegant, but I don't know a better way\n. I think you note that this requires git installed, and there should be a specific error if it is not\n. I think you'd be better off installing to tempfile() so it's guaranteed to be unique\n. Sys.which would be better.  On windows, you'll need to look for git.exe\n. Maybe use system_check here?\n. Maybe this should be an option?  (see zzz.r)\n. You don't need to use paste with stop - it accepts ... and paste together with no sep.\n. I think get_default_git_binary should throw an error if it can't find one\n. Don't need explicit return\n. Are you using as.character to strip the names?  If so, unname would be more clear.\n. if (os_type == \"unix\") \"git\" else \"git.exe\" would be more idiomatic\n. But I think I'd rather just have this wrapped inside of get_git_command_path (which maybe could be called git_path?)\n. I think the identing level is slightly off\n. And no return either ;)\n. It would be better to integrate this with set_env\n. You could write this as\nenv_vars <- c(\n   if (cran) cran(),\n   if (check_version) \"_R_CHECK_CRAN_INCOMING_\" = \"TRUE\"\n)\netc\n. @davidcoallier I'm confused - have you ever programmed in R before? ;)  But I did just try it on a windows VM, and it worked without errors.\n. I was thinking more like shims <- new.env(); shims$system.file <- ... and then I think you might be able to reuse the namespace code to copy in\n. I think we also want to disable building the manual here too\n. @param\n. I think we might be able to just do class@contains <- list(), given that we're removing all other classes in the package anyway.  I guess maybe the case that your more complicated code handles is if you've created classes in the global environment that extend classes in the package that you're unloading.  So in other words we should keep it :)  But that suggests other test cases we might want to include - load the package, create a class that connects to a class in the package, unload the package and see what happens.\n. I think this needs updating...\n. !identical(file_sha1, sha1) is slightly safer here\n. Included by accident?\n. Maybe add stopifnot(is.character(url), length(url) == 1) while we're in here?\n. Can you add call. = FALSE?\n. Maybe we should pull this out to a top-level warning in as.package?\n. Agreed. But generally matching package and directory name is a good idea.  But you're right that we probably don't want to be too prescriptive - there are lots of reasons they might not match.\n. Is there a reason this shouldn't be the default?\n. Can you add a relevant example here?\n. Can you remove the ; please?\n. Can you please put spaces around ==\n. Missing space\n. Can you leave of the heading? I add these just prior to release.\n. How about automating this question by inspecting rownames(available.packages(type = \"source\")) ?\n. Filter doesn't have quite the right connotation to me - this function might also add new files\n. probably should be \"\\nGithubSHA1:\" to be safe\n. I agree, I like before_install best.\n. Since you're in here, would you mind making the dependencies argument work? i.e. if it's true add in suggests\n. Could you write this in a more functional style? i.e. basically by improving the old not.installed package?\n. - Can you please eliminate the redundant {}?\n- It's a bad idea to use sapply in a function because you never know what it's going to return - can you please vectorise instead (i.e. gsub() and nchar() both take vectors as inputs)\n- nchar(NA) is 2 - is it ever possible for file to be NA?\n. @wch I think it would be slightly nicer to do:\n``` R\nneeds_install <- function(pkg, compare, version) {\n  if (length(find.package(pkg, quiet = TRUE)) == 0) return(TRUE)\n  if (is.na(compare)) return(FALSE)\ncompare <- match.fun(compare)\n  compare(packageVersion(pkg), version)\n}\n``\n. FYIMap(...)is a shorter way of writingmappy(..., SIMPLIFY = FALSE). Could you pull out into a separate function and useMap?\n.install_github_singlewould be the obvious name\n. You're commenting on a patch that wasn't accepted - see https://github.com/hadley/devtools/pull/355\n. Is this not called from anywhere else?\n. Could you add spaces around = please?\n. I'm not in love with this strategy, but I'm not sure what would be better.\n. Seems like a lot of duplication withinstall_github`.  Could you pull out into a separate function?  I think it would have an interface like this (untested):\n``` R\nupdate_description <- function(prefix, ...) {\n  function(bundle, pkg_path) {\n    # Ensure the DESCRIPTION ends with a newline\n    desc <- file.path(pkg_path, \"DESCRIPTION\")\n    if (!ends_with_newline(desc))\n      cat(\"\\n\", sep=\"\", file = desc, append = TRUE)\n# Function to append a field to the DESCRIPTION if it's not null\nappend_field <- function(name, value) {\n  if (!is.null(value)) {\n    cat(prefix, name, \":\", value, \"\\n\", sep = \"\", file = desc, append = TRUE)\n  }\n}\n\nfields <- list(...)\nMap(append_field, names(fields), fields)\n\n}\n}\n``\n. I think we're happy with the strategy as it stands, since it's encapsulated and well tested. The only other thing to consider is whether the function name should change - I suspect we can use that structure for any remote repo. Can you comment @imanuelcostigan?\n. Why do you want to do this?\n. Shouldn't this come before install_deps? Otherwise two versions of testthat will be installed.\n. I wonder if this block could be pulled out into a function too - it's basically identical toinstall_github. I think this also needs a \"#\"\n. I think this can be omitted since it's the default.\n. How about: \"What the package does (paragraph)\"\n. Never put the date in the DESCRIPTION. There's no need and it gets out of date very quickly ;)\n. For this function, I think we can not worry about backward compatibility. (esp since you'd usually sayquiet = T)\n. Could you put this in{}` please?\n. Maybe generate the url outside of lapply? \nurl <- paste0(\"ftp://win-builder.r-project.org/\", version, \"/\", basename(built_path))\nlapply(url, ftpUpload, what = built_path)\n. Should really be if, not ifelse, since not vectorised.  And maybe this block should also be wrapped in if (!quiet)\n{}\n. I think if you add warn = FALSE this also eliminates the need for \"Ensure the DESCRIPTION ends with a newline\"\n. I don't think a warning is necessary here\n. I think DESCRIPTION[DESCRIPTION != \"\"] is better, because the interface of setdiff() doesn't guarantee that order will be preserved\n. Spaces around = please?\n. This is now complicated enough to move into its own function. And might be better off using Sys.which()\n. You could now simplify this function by terminating early if not rstudio, or windows.\n. Change example too?\n. You don't really need the locking now, right?\n. What happens when this is called multiple times?\n. Can you please remove these two files?\n. Why not make this a special token for ref? e.g. install_github(\"hadley/devtools\", ref = released())\n. That would actually also be a better way to implement pull - install_github(\"hadley/devtools\", ref = PR(10))\n. Shouldn't need to set user agent with modern httr - rather than setting, I'd rather bump the httr dependency.\n. Can we please keep this as auth? And then can you squash?\n. Won't this always be false?\n. Can you please not use with()? I prefer to avoid non-standard evaluation in functions (plus it makes it harder to understand where the variables are coming from)\n. Just two spaces indent please\n. You need to @export the methods\n. Remove commented code?\n. I don't understand the point of this function. Why would pull not be null?\n. I think this code should be moved into github_parse_path() - i.e. it should return a pull_request object in the ref field.\n. Oh I see - missed the separation of the functions in the diff.\n. Yes - @export exports the S3 method definitions, which you must export (otherwise the generic won't find them)\n. What if you don't attach devtools and do devtool::install_github(\"devtools\", ref = devtools::github_pull(509)) ? I think that might be the problematic case.  I'm pretty sure not exporting S3 method has bitten me in the past.\n. I would honestly prefer to export every S3 method, regardless of whether or not the generic is exported. Then I don't need to think about it.\n. I think at this point, it's better to give up on the regexp approach and take a dependency on jsonlite.\n. Please just use jsonlite, no need to add fallbacks.\n. Don't need add_appveyor() existing add functions will eventually be deprecated and removed.\n. Can you update to actually generate the shield markdown? (see my work this morning)\n. Since basically every devtools function starts with pkg, you don't need to explicitly name it.  I think it's also better to preserve the user friendly \"Adding Rstudio project file\" rather than just \"Adding xxx.Rproj\".\n. Multiple lines please\n. You can remove that line\n. I'd document this with github_pull()\n. I wonder if it's worth refactoring with_mock() so that you could do:\nR\nwith_mock(\n  { \n    ...\n  }, \n  github_resolve_ref.github_release = function(x, param) { \n    param$ref <- \"latest-release\"\n    param\n  }\n)\n. Right\n. Sure, let's do that. Might be better to do by creating a new environment, but not sure if S3 method lookup will work out right.\n. Shouldn't that be an error?\n. How about something like is_root <- function(x) identical(x, dirname(x)) ?\n. Maybe just normalizePath(path, mustWork = FALSE)?\n. Can you please use {} here? (http://r-pkgs.had.co.nz/style.html)\n. I'd put this in a new test file test-package.R\n. I think this would be cleaner with a tryCatch:\nR\ntryCatch({\n  setupPackage(...)\n}, error = function(e) {\n  unlink(path, recursive = TRUE)\n  stop(e)\n})\nor \nR\nwithCallingHandlers({\n  setupPackage(...)\n}, error = function(e) {\n  unlink(path, recursive = TRUE)\n})\n. Thinking about it more, it might be simpler to extract out check_package_name() (i.e. modify valid_name() to throw error on failure) and call it from both setup() and create(). That would also keep the code and text description of the restrictions together.\n. Extraneous indent?\n. I think this would be more convenient if it returned the lines (or character()) if no makefile\n. Why do we need this?\n. This check is unnecessary since devtools now imports roxygen2\n. Please remove this message\n. Could you please use {} here, and indent? (e.g. as described in the curly braces section of http://adv-r.had.co.nz/Style.html)\n. The else needs to be in {} too\n. And the else should be on the same line as { :)\n. Can you please extract out a has_no_auto_clean() function that takes a vector of paths, and returns TRUE or FALSE? (It's also slightly nicer to use grepl() rather than grep())\n. Can you please include the issue/PR number, and thank your github user name?\n. Can you please remove the extraneous ;\n. I prefer on.exit() to tryCatch() - can you please change?\n. Are you using request for anything?\n. 1. I think the comment is extraneous (given how simple the code is)\n2. Can you please use a space after if\n3. warning() looks like it's indented too much\n4. I always use call. = FALSE with warning\n5. I think it would be easier to understand if src_submodules was defined in front of this block\n. I'm a bit leery about automatically modifying the travis file, especially now that there are two main formats. Could you please just print out instructions? (and update them for the language: r style)\n. This needs to be pulled from whatever the current option is. I think you'll need dput() to handle multiple repos.\n. Maybe that should go in r_env_vars()?\n. file.path(tempdir(), \".Rprofile\") would avoid creating multiple files\n. I think it would be better to show the size in either kb or (maybe) mb\n. It just occurred to me that this would be nicer as vars[[\"NOT_CRAN\"]] <- \"true\"\n. I'd do on.exit(close(tmp_user_profile)) here to be a bit safer. \n. Maybe this would be better called r_profile()?  We might expand it to include other options in the future.\n. Space around =\n. I think this also needs --no-save and --no-restore?\n. Are you sure? R --help gives me :  --vanilla Combine --no-save,\n--no-restore, --no-site-file, --no-init-file and --no-environ\nOn 4/22/15, Kirill M\u00fcller notifications@github.com wrote:\n\n\n@@ -1,6 +1,6 @@\n # R(\"-e 'str(as.list(Sys.getenv()))' --slave\")\n R <- function(options, path = tempdir(), env_vars = NULL, ...) {\n-  options <- paste(\"--vanilla\", options)\n-  options <- paste(\"--no-site-file\", \"--no-environ\", options)\n\nHm... --vanilla doesn't imply --no-save, but I agree it's better to add\nit anyway.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/pull/767/files#r28900125\n\n\nhttp://had.co.nz/\n. Looks like you have a merge conflict here - re-documenting should fix it\n. I'm not a big fan of including the Date field in the DESCRIPTION, just because it's something you need to keep up-to-date, and doesn't really seem necessary (since a built date is automatically added when you build the package). Do you have a reason you like to use it?\n. FWIW, a simpler pattern is pwd <- setwd(bundle) - but I'll make this change locally.\n. Can you please revert this change\n. Should go under helpers\n. Doesn't this line also need a fix?\n. Can you put unload() on a new line please? (And similarly below)\n. I wonder if it would be useful to pull this out into with_temp_lib or something?\n. Maybe it would be to handle this consistently with the other setter functions, i.e. add a add argument?\n. That would make sense\n. I like the action idea. Another with_ function does the same thing right?\nI have no objections to moving these functions into a separate package.\n. Hmmm, I think the goal was to make it easy to bootstrap an existing directory into a package - i.e. you could just drag all your files into an R directory and start using devtools immediately.\n. I think the goal was to make load_all() just work for people, even before they'd formally made a package.\n. I wonder if the absence of testthat should just be an error.\n. Could you please use discover = TRUE?\n. Oh, oops, I was getting confused.\n. I don't think that's necessary\n. I think the worry here is that if you have both origin and something else that points to github (e.g. upstream), this will pick the wrong one.\n. This can be eliminated since it's already covered by uses_github()\n. I don't find the logic here easy to follow. I think you should be testing r_remote_urls rather than r_remote_urls[NULL] (as in the default case)\n. This doesn't seem like the right test to me. I think it httr::has_content() on req would be better. (I presume this was added to handle the delete repo case)\n. That's fine - but that strategy is not currently obvious in the code, so it needs a little refactoring.\n. Why do you need to do the decoding yourself here?\n. Isn't that the default?\n. Param description should start with a capital letter\n. Could we move this up and use is_installed()? I think that would eliminate the need for suppressWarnings()\n. I think it would be useful to have something like github_package() that returns the name of the package at the specified remote, or otherwise throws an error.\n. This seems backwards to me - normally you'd keep the last instance. Can you please flip around with fromLast?\n. I'd rather you test this by pulling rcmd_check_envars() out into a separate function.\n. Please indent arguments by only two spaces\n. Can you please just delete this whole comment block? i.e. 47-51\n. Could we just make this \"Devtools dependencies\" and include remote versions as a section?\n. I think these could just be a single bulleted list\n. I think this will requiring a bump in the R version in DESCRIPTION?\n. You forgot to make this trim_ws\n. I feel like this might be simpler if you just iterated once over pieces:\nR\nparse_one <- function(parts) {\n  if (length(x) == 1) {\n    type <- \"github\"\n    repo <- x\n  } else if (length(x) == 2) {\n    type <- x[1]\n    repo <- x[2]\n  } else {\n    stop(\"Malformed...\")\n  }\n  fun <- match.fun(paste0(\"install_\", type))\n}\n. I think it's more important to warn that Url and BugReports fields are empty. \nDo you think that people mindlessly copying-and-pasting <USERNAME>/<REPO> is a common failure mode?\n. Maybe \"found\" is a little more accurate than \"exists\"?\n. Just having this function in devtools scares me a bit. Could you at least at an interactive confirmation prompt?\n. I think it's better to default to ssh in the R ecosystem. It certainly works much more smoothly with RStudio. I'd recommend deleting the link to Github's advice \n. That seems like a reasonable change to me, so you can delete the comment\n. I think EMAIL = \"\" would be a bit nicer (it mimics http auth elsewhere)\n. Does this need a git2r version bump in DESCRIPTION?\n. Seems like this should just stop(). (Also message() and stop() take ... so you don't need the paste())\n. Would be nicer if this didn't clobber existing URL\n. The uses functions are normally designed to fail instead of overriding existing fields\n. Ah ok - I think it would be better to just barf in use_github_links()\n. Ah got it\n. In fact, I don't think you even need this anymore - Sys.setenv() will take care of it (and the chances of duplication are now basically zero with new cran = TRUE strategy)\n. Is it possible to do this with git2r? devtools traditionally hasn't assumed that you have git installed.\n. I think NULL would be more appropriate here\n. Was there a reason for this change?\n. I think that should probably be parsed <- list()\n. How does auth get set?\n. This still feels risky to me - I'd rather not test adding repos if we have to delete them afterwards.\n. Did you mean to change the version of git2r?\n. Sounds good.\n. Do you realise that you accidentally modified the version of Rcpp instead of git2r?\n. I'm not terribly consistent about enforcing this, but I'd prefer subsequent arguments to be indented just one extra level\n. This check could now go\n. That's new roxygen2 5.0.0 behaviour - it just links to the main entry, not every alias.  \nI just pushed a commit that upgrades to roxygen2 5.0.0. Could you please merge/rebase?\n. Maybe delete this old comment?\n. I think this could be reworded to be a bit more clear\n. I think force might be too generic - does it all to specified packages or their deps or both? Maybe the description of the function also needs to change to emphasize that it never reinstalls packages if already present \n. Doesn't this also need a stop()? (i.e. if they say no)\n. Can you please use tryCatch() instead? I don't like the way try() works\n. Please put spaces around = to match existing style\n. Why not put everything in one message block?\n. I think this should probably still print a message() - see the new behaviour for use_git() and use_github()\n. Could you eliminate use of try() here please?\n. How about just stop(\"Unknown remote type\")?\n. And maybe put the type into just to be helpful?\n. I think the logic here is round the wrong way - isFALSE(force) would be better\n. We can't use git2r to get this?\n. Make this an early return?\n. Ok, that's fine.\n. Hmmmm, thinking it through again, I think your original code is correct.\n. The point of the early return was so you could eliminate the big else block ;)\n. Think you missed this comment\n. Doesn't seem worth it to me - use_data() is purely for interactive use.\n. How about integrating this with check_to_save()?\n. I'd rather just inline this inside use_data()\n. Bump\n. I'd prefer to have one message containing all the information\n. Given that this function is not just the negation of git_committed() I think it's confusing.\n. Just do uses_git(x$path) && !git_uncommitted(x$path) here\n. Is this argument used anywhere?\n. I think this now needs to move\n. Need more details here. What sort of object is it? How does the addition happen?\n. I prefer to be explicit: length(metadata) > 0\n. This needs to be an if else:\n``` R\nif (file.exists(source_desc)) { \n} else if (file.exists(binary_desc)) { \n} else {\n  stop(\"No DESCRIPTION found.\", call. = FALSE)\n}\n``\n. Yes, if it would be helpful\n. Still missing the else clauses here\n. Oh, I see you added that below. But that makes it unclear that there are three options - I'd prefer the if else if else structure I suggested.\n. I'd say:Named list of metadata entries to be added to the \\code{DESCRIPTION} prior to installation.. This definition (andshaanduser_shabelow) would be better off in an else clause.\n. This logic is all a bit confusing, and I think it could do with some refactoring.\n. I think all theseadd_sha = FALSEneed to go away now?\n. Oh, @jimhester pointed out that both might exist, so this is the right thing to do.  A comment explaining that would be helpful.\n. Don't need explicit return here, but it's not a blocker.\n. Maybe include (some of) the sha in the output? \"...the SHA1 (axcvsadf9234) ...\" \n. Is there are reason to do this here, rather than relying on the individual install methods?\n. Could we drop some nesting here?\n. Please don't add headings yourself. I add these during the final release process.\n. I think you should just drop the compare argument as the only one that's useful is>=.\n. I think you can eliminate the sentence describing what happens with invalid version specs\n. Looks like you added spurious indentation here\n. Should be defined closer to where it's used\n. I read that, but I disagree. I don't there's any point in exposing an interface that people are unlikely to use. But if you can find a couple of packages in the wild that use<or==, I might change my mind.\n. What do you think about having a CRAN package type here? That might make it easy forupdate_packages()to work with everything\n. I'd prefer all lowercase to be consistent\n. I forget how this works, but are we already computing the dependencies that are missing/out-of-date?\n. I think this maybe needsdependencies = TRUE. I think you accidentally deleted this?\n. Couldn't we put thestop_for_status()` in the github response? I think that would make this cleaner.\n. If you did go this route (which I don't think we should), it would be better to write:\nR\ntryCatch(\n   ...,\n   github_response = function(e) stop(e),\n   error = function(e) ...\n)\n. Doesn't that still need httr?\n. And this line? ;)\n. We should probably also bump this to support 3.4\n. I don't think the branch is quite right here. It should be after the check for empty env var, and should give a different message.\n. Yes please!\n. Bump\n. Can you please tweak indenting here? The nesting of list() inside structure() isn't obvious.\n. @krlmlr it could, but it's a better bottleneck than the current unauthenticated approach, and then message could tell people what they need to do to use their own token\n. Maybe: \"Using bundled GitHub PAT. Please add your own PAT to the env var GITHUB_PAT\"?\n. \"NEWS.Rd does not exist\" would be a better message, I think.\nAlso this is going to be a false positive for people who use inst/NEWS.Rd only\n. g?\n. Where did these come from? Can I ignore?\n. Can you indent these lines please?\n. I like to have arguments line up with the ( in function(\n. Why does this code go away?\n. I think it would be a little safer to condition on cran binary packages\n. No need to bump the version\n. Please just stick with >= and > - I'm not interested in supporting the other cases.\n. This test feels like overkill to me - the function is not that complicated so I don't think it needs an extensive testing harness. I'd rather have a few smaller tests that each tested on specific failure point.\n. I think you can just omit the protocol, simply changing the bit after github\n. Same here\n. You'll need to update this for our recent tweaks which include the protocol in the host string\n. Why would it contain a path?\n. Why do you give the full path here? I think it should just be the protocol and host name\n. I'd do one test for proper functionality, and one test for idempotency.\nThe problem with the current test is that it is so long that I can't easily understand the goal in a glance. That's a problem because I have to maintain this code, and if use_package() needs to change in the future, I need to understand what the tests actually do so that I don't break existing behaviour.\n. That's a little different to before - previously the tryCatch() covered a much smaller scope. That's important so that load_all() can continue to (mostly) work if the NAMESPACE isn't quite right\n. This seems like a common pattern - extract into a function?\n``` R\ncomp_lang <- function(x, y) {\n  if (length(x) < length(y)) return(FALSE)\nidentical(x[1:length(y)], y)\n}\n```\nOr maybe that's just how extract_lang should work if the 2nd arg is a call?\nAnd maybe extract_lang should get an i argument?\n. I'm not sure what the [[1]] does\n. The problem is if one of the imports is badly formed - before it would still import everything after that\n. But won't this remove unexported functions from the interactive environment if they previously had used load_all()?\n. Why not just always include the path in the host name? Nothing would change for public github, and you'd just need to document that internal github needs the path added. \n. It feels like this logic should be in github_POST() not here\n. And this should be pulled out into a function like github_url_from_host() or similar.\n. Good point! I guess they used to be different?\n. I think you can drop this entire test - 30 lines of code seems overkill to test a single line in the function. You're effectively just testing that match.arg() does what it's supposed to.\n. These are much better!\n. Can you eliminate the lapply()? I think copying and pasting is fine if you only have two copies of basically the same code.\n. Maybe it would be easier to just have this as use_catch() rather than an argument? use_catch() would call use_testthat() if the testing infrastructure hadn't already been set up (in the same way that use_test() does)\n. sp\n. Can you please put spaces around =?\n. I think the message would be more helpful if you told people what to do instead\n. It's currently so you can ignore if needed \u2014 i.e. I don't always actually care that there are uncommitted files but I want to know about it.\nAlso, I don't actually care if there are local changes that haven't been pushed to the remote; but I do care if there are remote changes I don't have locally. How hard would it be to make that work?\n. It's slightly annoying that there's an interactive prompt here, because it might get triggered arbitrarily later after starting revdep_check(). But I don't know how to avoid it\n. VOMITING IN MY MOUTH \n. Is it necessary to stop here on failure? There appear to be CRAN packages for which is_bioconductor() is true\n. Would you mind adding that? It'd help with my revdep checks.\n. Are you sure this line is necessary?\n. How is type = \"both\" handled now?\n. Can you please move this to check-devtools.r, following the template in release_checks()?\n. I think this is now out of date\n. Can you please mention the issue here? And add a line break.\n. This is rather confusing logic. I think it would be better as:\nif (length(r_files) == 1) {\n   ...\n} else {\n   ...\n}\nPresumably zero files should also be an error.\n. == ?\n. Need another newline here\n. This should go above check_status(), and can you please match the identation style of the check_match() call with the other check functions?\n. Maybe \"'inst/doc' is empty\"?\n. clean_vignettes()\n. Also not clear what \"vignette testing files\" are. Can you clarify?\n. Missing new line at start. inst/doc should be in quotes. Second line should be indented.\n. That's not really what \"imports\" does though.. Bad indent?. Bullet?. Trailing comma?. Leading nl. Sounds good. Note this will also need to be moved once you merge changes from master. Can you please put spaces around = and dedent }. Can you please move this to the correct place once you merge/rebase?. Please add spaces around ==. Thinking about this a bit more, how does rcmdcheck handle build tools?. Yeah, I like the idea of using the pkgbuild functions. That pushes all the build tools related errors to one home.. Missing nl. I think you should also delete this documentation block, and say something like: Use the revdepcheck package instead.. Yeah, that's fine. We'll probably start doing releases of those packages next week.. Can you please eliminate the extra newlines here and after the docs?. This can be written more succinctly as:\nR\npath <- path %||% dirname(pkg$path). Can you please use callr::rmd() here?. It should look something like \nR\ncallr::rcmd(\"Rd2pdf\", args = c(\n  \"--force\", \n  paste0(\"--output=\", path, \"/\", name), \n  pkg$path\n)). Can you remove this since this code has now moved to usethis?. Needs update to use current practice. I think it's fine to stick with this example.  Any sufficiently motivating example here will inevitably end up in a package.. Now r-libs, and agreed.. Yeah, I think skip for the first package.. If you don't see a build tab, seek help now?. I'd prefer dir(). We should be able to relaunch automatically - https://github.com/r-lib/usethis/issues/42. I think for safety this needs a timeout, and to be wrapped in a tryCatch(). I wonder if we should also support \"backwards\" completion so that completeme could autocomplete to jimhester/completeme. An early return would make this code a bit simpler. Might be worth providing completeme helper? Should it also check the argument name?. Is there a reason to change this default?. Is there a good reason to deprecate this, rather than soft-deprecating it?. We deprecated the usethis functions because we're going to attach usethis so generally you'll get the new versions (the deprecation is just for people importing via namespace). It's probably best to keep as is here, and as much as I hate to say it, it's probably to default to US english even in the spelling package (and make it an option). Missing `. Extra ,?. Drop #pull?. Mention that we won't reinstall if sha is the same?. Either way, need to describe the temporary install in the docs.. Do we want to check this in? How will we keep this up to date? Do you imagine these changes will also flow into the roxygen vignette roclet? \nShould we also create an md version for easy previewing on github?. Doh. ",
    "jcdny": "The code keeps a list of database environment variables and a key for\nwhich to DB use.  It's in the global environment since the package is\nalso used in some legacy code which sets these explicitly prior to the\npackage being loaded.\nHere is the actual .onLoad function....\n```\n.onLoad <- function(lib, pkg, ...) {\n  ## CONNECTION MANAGEMENT\n  if (!exists(\".DB.USE\",globalenv()))\n    .DB.USE <<- Sys.getenv(\"DB_USE\", unset=\"PROD\")\nif (!exists(\".DB.ENV\",globalenv())) {\n    .DB.ENV <<- list()\n    .DB.ENV[[.DB.USE]] <<- db.env.get(.DB.USE)\n  }\n}\n```\nI changed it to use the package namespace (following the example in\nlubridate):\n```\n.DB.ENV <- NULL\n.DB.USE <- NULL\n.onLoad <- function(lib, pkg, ...) {\n  ## CONNECTION MANAGEMENT\n  if (is.null(.DB.USE))\n    .DB.USE <<- Sys.getenv(\"DB_USE\",unset=\"PGPROD\")\nif (is.null(.DB.ENV)) {\n    .DB.ENV <<- list()\n    .DB.ENV[[.DB.USE]] <<- db.env.get(.DB.USE)\n  }\n}\n```\nWhich is cleaner, works, and is no doubt the right answer but that\nmeans I needed to explicitly unlock the bindings for .DB.USE and\n.DB.ENV, and the existing legacy code would need to be modified to\nwork properly (overdue cleanup so not terrible I guess).\nIt just surprised me that a package that worked fine via library would not load.\nLooking at devtools code I am guessing the issue is that when you create\nthe environment you don't assign a parent frame and then do the attach\nbefore sourcing the code rather than sourcing then attaching.\n. I accidentally closed this.  I made the change to create the environment, source, then attach and then the sample code works.  Take a look at jcdny/devtools@025c6504c1907e37accd for what I am talking about.\n. You need to do both things.  You need to provide the enclosing environment when doing the source and when you attach it actually makes a copy of the environment and I think discards the enclosing environment. \nI've messed around with it a bit and nothing seems to break with that change though I admit it was all a bit cargo culted and it's not clear if the env should be globalenv() or \nsomething else.  Someone with much more R internals experience would have to answer that one.\n. Here is a simple example of what I am talking about \nIn /tmp/x.R:\n    ZZ <<- 1\n    cat(\"found ZZ in\",find(\"ZZ\"),\"\\n\")\n    cat(\"ZZ=\",ZZ,\"\\n\")  \nthen run:\n```\ne1 <- new.env(parent = emptyenv())\nattach(e1, name=\"E1\")\ne2 <- as.environment(\"E1\")\ne3 <- new.env(parent = globalenv())\nattach(e3, name=\"E3\")\ne4 <- as.environment(\"E3\")\nfor (e in c(\"e1\",\"e2\",\"e3\",\"e4\")) {\n  cat(\"\\n\",e,\"\\n\")\n  print(get(e))\n  try(sys.source(\"/tmp/x.R\", env=get(e)))\n  try(rm(\"ZZ\", envir=globalenv()))\n}\n```\nWhich for me produced:\n    e1 \n    \n    Error in eval(expr, envir, enclos) : could not find function \"<<-\"\n```\n e2 \n\nattr(,\"name\")\n[1] \"E1\"\nfound ZZ in .GlobalEnv \nError in cat(\"ZZ=\", ZZ, \"\\n\") : object 'ZZ' not found\nIn addition: Warning message:\nIn rm(\"ZZ\", envir = globalenv()) : object 'ZZ' not found\ne3 \n\nfound ZZ in .GlobalEnv \nZZ= 1 \ne4 \n\nattr(,\"name\")\n[1] \"E3\"\nfound ZZ in .GlobalEnv \nError in cat(\"ZZ=\", ZZ, \"\\n\") : object 'ZZ' not found\n```\n. Ah, I tested with a number of packages but nothing with S4 methods.  That's unfortunate.\nI will think about it more and if I get any bright ideas I will let you know.  I suspect to support namespaces  you will need to load packages more like the existing code does and that might be the only way to get both of these.\n. ",
    "wch": "Fixed in #126.\n. OK, I made the changes and rebased.\n- changed sprintf to paste\n- changed cat to message\n- added function bisect_load_and_test. I decided to use this longer name to make sure it's clear to the user what they're doing.\n. Here's some skeleton code for what test scripts look like. This is stuff that you always put at the top:\n``` R\n!/usr/bin/Rscript\ncat(\"\\n===== Running test script ======\\n\")\nlibrary(devtools)\n```\nAfter that, you can add the tests. Here's a fully automated test: \n``` R\nA fully automated test\ntestRun <- function() {\n  # Do test...\n  # If it reaches this point, then success. Mark GOOD\n  return(TRUE)\n}\nIf error, mark BAD\nbisect_load_and_test(testRun, pkgdir=\".\", on_run_error = FALSE)\n```\nA test that requires user inspection and response (without stuff at top of script):\n``` R\ntestRunInteractive <- function() {\n  # Do test...\n  # User must visually inspect and mark good/bad/skip\n  bisect_return_interactive()\n}\nIf error, mark SKIP\nbisect_load_and_test(testRunInteractive, pkgdir=\".\", on_run_error = NA)\n```\nSometimes the loading and testing requires more flexbility. To get a recent test from the mailing list to work, I had to install each version of ggplot2, load another package from souce, and then load ggplot2 via library.\n``` R\nload_stuff <- function() {\n  # Install the current commit version of ggplot2\n  install.packages('.', repos = NULL, type = \"source\")\nload_all(\"../granovaGG\")\n  library(ggplot2)\n}\nIf error loading, mark SKIP\nbisect_runtest(load_stuff, on_error = NA)\nThe real test\ntestfun <- function() {\n  # Do test...\n  # If it reaches this point, then it successfully printed. Mark GOOD\n  return(TRUE)\n}\nIf error, mark BAD\nbisect_runtest(testfun, on_error = FALSE)\n``\n. Oh, are you thinking that the whole thing would be run within R -- that is, creating the test scripts and then runninggit bisect run myscript.r`? That was actually my original intent, but I don't think that's possible, for a couple reasons:\n- It would have to start an R session within an R session, which would probably make it impossible to get user input.\n- Usually the start of the bisect process is very manual. For example, check out HEAD, try the test; then pick some older version, try the test; if that fails, keep searching for a good commit. The starting and resetting a git bisect inherently requires interaction from the command line (I don't even think most git GUIs can do it).\nIf the idea is to have a nicely-contained, automatable set of functions like in testthat, I don't think that's necessary for bisect testing, since this is always a one-off procedure. At least, I can't think of a reason why you'd want to add a bisect test to a test suite -- if you've found the bad commit once, you've found the bad commit. Future runs of the bisect will just find the same thing (or they won't find anything at all, since, after a bug is fixed, it will report that HEAD is good).\n. One thing I should mention... Right now, there's a convenience function that loads packages with load_all(). However, sometimes the tests require actually installing a package (instead of just running load_all(). I'm thinking of adding a function bisect_install that installs a package and loads it via library(). I don't know how to get the name of the package from a source directory. I'd like the function to do something like this, but I don't know how:\nR\ninstall.packages('.', repos = NULL, type = \"source\")\nlibrary(get_packagename('.'))\nAlso, there's a bit of simplification I want to do - I think the bisect_load_and_test convenience function isn't necessary since it just only saves typing one line of code.\n. I made some changes and rebased. The two main changes are:\n- The user now has to load packages and run test in two separate steps.\n- There are functions for installing packages.\nHere's some new skeleton code for test scripts. This should always go at the top:\n``` R\n!/usr/bin/Rscript\ncat(\"\\n===== Running test script ======\\n\")\nlibrary(devtools)\n```\nAfter that, you can add the tests. Here's a fully automated test: \n``` R\nA fully automated test\ntestRun <- function() {\n  # Do test...\n  # If it reaches this point, then success. Mark GOOD\n  return(TRUE)\n}\nLoad package. If error, this returns NA (mark SKIP)\nbisect_load_all(\".\")\nRun the test. If error, return FALSE (mark BAD)\nbisect_runtest(testRun, on_error = FALSE)\n```\nIf instead you want to install a package and load it the normal way (like require() or library()):\n``` R\nInstall package. If error, this returns NA (mark SKIP)\nbisect_install(\".\")\nLoad package. If error, this returns NA (mark SKIP)\nbisect_require(ggplot2)\nRun the test. If error, return FALSE (mark BAD)\nbisect_runtest(testRun, on_error = FALSE)\n```\nAn interactive test would look something like this:\n``` R\ntestRunInteractive <- function() {\n  # Do test...\n  # User must visually inspect and mark good/bad/skip\n  bisect_return_interactive()\n}\nLoad package. If error, this returns NA (mark SKIP)\nbisect_load_all(\".\")\nRun the test. If error, return NA (mark SKIP)\nbisect_runtest(testRunInteractive, on_error = NA)\n```\n. This stuff has been moved into a new package.\n. Fixed in #126.\n. It would also be helpful to have a wrapper function that does this when you install from local source, like:\nR\ninstall.packages('.', repos = NULL, type = \"source\")\n. Also, it's impossible to put the current commit's hash anywhere in the current commit. The commit hash has to be extracted and put somewhere (in an untracked file?) after doing a checkout. I don't know if this is a good general solution, since it requires git to be installed.\nThis will get the most recent tag, the number of commits since that tag, and the hash:\n``` R\ngit describe --tags\nggplot2-0.9.0-68-gc235a93\n```\n. Indeed there is: https://api.github.com/repos/hadley/ggplot2/git/refs/heads/master\nDocumentation here: http://developer.github.com/v3/git/refs/\nAlso, if you want to grab detailed information about a hash: https://api.github.com/repos/hadley/ggplot2/git/commits/f9915d0784cc9bd733903f1658143687e2821854\n. Fixed in #126.\n. It looks like the culprit is the --with-keep.source flag in the R CMD INSTALL.\n```\nThis results in the srcref problem\nR CMD INSTALL staticdocs --library='/Users/winston/R-dev' --with-keep.source\nThis is OK\nR CMD INSTALL staticdocs --library='/Users/winston/R-dev'\n``\n. The problem may not be with devtools per se, but with the wayinst_pathchecks whether it's in an installed package vs. package loaded withload_all`.  This function works around for the issue:\n``` R\ninst_path <- function() {\n  envname <- environmentName(environment(inst_path))\n# If installed in package, envname == \"extrafont\"\n  # If loaded with load_all, envname == \"package:extrafont\"\n  # (The names seem a little backward)\n  if (envname == \"extrafont\") {\n    system.file(package = \"extrafont\")\n  } else {\n    srcfile <- attr(attr(inst_path, \"srcref\"), \"srcfile\")\n    file.path(dirname(dirname(srcfile$filename)), \"inst\")\n  }\n}\n```\n. With pull request #126, this doesn't need to be overridden anymore. (But if you want to, it is now possible, by defining the function in the imports environment.)\nI think system.file() uses the path attribute of the <package:ggplot2> environment, which is properly set in #126.\n``` R\nOld version of devtools\nsystem.file(package='ggplot2')\n\"/Users/winston/R-dev/ggplot2\"\nNew version of devtools, with #126\nsystem.file(package='ggplot2')\n\"/Users/winston/Projects/ggplot2\"\n```\n. The commit for this one appears to be empty?\n. Implemented in #126.\n. With the #126 pull request, this is closer to working.\nIn help(), this is how it tries to find the help file:\nR\n paths <- index.search(topic, find.package(package, lib.loc, verbose = verbose))\nWith the changes in the pull request, find.package now finds the directory of the working version of the package, rather than the installed version. I think it uses the path attribute of the <package:ggplot2> environment.\n``` R\nfind.package('ggplot2')\n\"/Users/winston/Projects/ggplot2\"\nwith old version of devtools, this reported:\n\"/Users/winston/R-dev/ggplot2\"\n```\nBut utils:::index.search looks for help/aliases.rds or help/AnIndex, and these files don't exist. So the index still has to be created somehow.\n. I think you'd also have to generate the help/ and html/ directories.\nAnother possible solution is to define a function like dhelp(), which would search the man/ directories of all packages loaded via devtools, and then run show_rd for the requested page. Or maybe it's possible to redefine ? to search devtools-loaded packages, and then if it doesn't find the help page, to call the regular ? function.\n. Normally, the dynamic library has the same name as the package, so this should work:\npkgname <- 'c_test'\npkgpath <- system.file(package=pkgname)\nlibrary.dynam.unload(pkgname, pkgpath)\nBut in case there are multiple libraries in that path, it might be better to search the .dynLibs() for all libraries that contain the pkgpath:\n```\ndynlib_paths <- vapply(.dynLibs(), function(x) x[[\"path\"]], character(1))\nList all the libraries under that path\nNeed to be careful since the string matches anywhere, not just at the beginning\ndynlib_paths[grepl(pkgpath, dynlib_paths, fixed=TRUE)]\n```\nIt appears that most packages have library files with the same name as the package. But there are some exceptions. A find in my library path turns up a few:\n```\n./data.table/libs/x86_64/datatable.so\n./data.table/libs/x86_64/datatable.so.dSYM/Contents/Resources/DWARF/datatable.so\n./rgl/libs/i386/aglrgl.so\n./rgl/libs/i386/aglrgl.so.dSYM/Contents/Resources/DWARF/aglrgl.so\n./rgl/libs/i386/rgl.so\n./rgl/libs/i386/rgl.so.dSYM/Contents/Resources/DWARF/rgl.so\n./rgl/libs/x86_64/aglrgl.so\n./rgl/libs/x86_64/aglrgl.so.dSYM/Contents/Resources/DWARF/aglrgl.so\n./rgl/libs/x86_64/rgl.so\n./rgl/libs/x86_64/rgl.so.dSYM/Contents/Resources/DWARF/rgl.so\n```\n. This code should unload all the loaded libraries from a given package:\n```\nlibrary(bitops)\nShow what's loaded\n.dynLibs()\npkgname <- 'bitops'\nGet installation path for the package\npkgpath <- system.file(package=pkgname)\nGet a vector of paths for all loaded libs\ndynlib_paths <- vapply(.dynLibs(), function(x) x[[\"path\"]], character(1))\nFind which of the lib paths start with pkgpath\npkgmatch <- pkgpath == substr(dynlib_paths, 1, nchar(pkgpath))\nGet matching lib paths and strip off leading path and extension (.so or .dll)\nlibnames <- sub(\"\\.[^\\.]*$\", \"\", basename(dynlib_paths[pkgmatch]))\nlibrary.dynam.unload(libnames, pkgpath)\nShow what's loaded\n.dynLibs()\nWe can also unload the package\ndetach(paste(\"package\", pkgname, sep =\":\"), character.only = TRUE, force = TRUE, unload = TRUE)\n```\nI tried experimenting with plyr, but it appears that it can't be unloaded because devtools depends on testthat, which depends on stringr, which depends on plyr.\nAlso, it appears that some packages are nice enough to have an .onUnload function that does it automatically:\n```\n\nMASS:::.onUnload\nfunction (libpath) \nlibrary.dynam.unload(\"MASS\", libpath)\n\n```\n. Implemented in #137.\n. I added some tests, but I haven't pushed, since I also rebased this branch onto my load-env branch... I'll push this once that branch is merged into master.\n\nIs there a way to tell devtools to compile stuff in the src/ directory? Right now, to test this I have run install() on the test package, then load it with library(), then unload with unload(). It's kind of an awkward process.\n. This should also collect all the 00check.log files at the end, and put them together (preserving test order?) in a useful way.\n. Implemented in #126.\n. Writing tests for this will be a challenge. What do you think about making a another package inside of devtools, specifically for running tests on? Maybe it could go in /inst. It could also be used for testing many other parts of devtools.\n. The imports also need to be properly loaded. They should go in the parent environment of <namespace:ggplot2>.\nFor example, if you run this code when loading via library(), the\n``` R\nPrint parent frames, and return last one printed\ne: the environment to start in\nn: max number of levels envs to print\np: print all the environments? If FALSE, just return last frame\nprintenvs <- function(e = parent.frame(), n = 100, p = TRUE) {\n  if (p)  cat(str(e, give.attr=F))\n  i <- 1\n  while(i < n) {\n    if (identical(e, emptyenv()))  break\ne <- parent.env(e)\nif (p)  cat(str(e, give.attr=F))\ni <- i+1\n\n}\n  cat(\"\\n\")\n  return(e)\n}\nlibrary(ggplot2)\ndebug(qplot)\nqplot()\nNow at browser prompt\ne <- printenvs(n=3)\n\n\n\ne\n\nattr(,\"name\")\n[1] \"imports:ggplot2\"\nls(e)\nShows all the objects from ggplot2 imports, like grid, scales, plyr\n```\nThe imported packages are loaded into their appropriate namespaces, but the do not have the associated <package:plyr>, which is what makes the functions available in the global env. \nStill at the debug prompt:\n``` R\ntrue\nfunction (...)\nTRUE\n\ndebug(true)\n true()\nAt debug prompt for true()\nShow all parent envs\nprintenvs(n=5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n```\nSo the imported packages are loaded into their namespace, and then their exported objects are copied over to the \"imports:ggplot2\" environment, which is a parent of <namespace:ggplot2>.\nAlso see: \nhttp://digitheadslabnotebook.blogspot.com/2011/06/environments-in-r.html\nhttp://obeautifulcode.com/R/How-R-Searches-And-Finds-Stuff/\n. It now imports objects in to the imports environment (instead of loading the dependency packages with require(), which attaches the packages).\nNow I'm getting a strange warning in load_code() when I run load_all('ggplot2'). (This is with options(showWarnCalls=T, showNCalls=500)):\nWarning message:\nIn getPackageName(where) :\n  Created a package name, \u20182012-08-06 13:09:56\u2019, when none found\nCalls: load_all -> load_code -> sys.source -> eval -> eval -> setRefClass -> setClass -> makeClassRepresentation -> getPackageName\nThis warning happens in the lapply in load_code():\nR\n  tryCatch(\n    lapply(paths, sys.source, envir = env, chdir = TRUE, \n      keep.source = TRUE), \n    error = function(e) {\n      clear_cache()\n      stop(e)\n    }\nWhen I replace the lapply with a loop, the warning still happens:\nR\n  for (path in paths) {\n    sys.source(path, envir = env, chdir = TRUE, keep.source = TRUE)\n  }\nBut if I use a loop that uses numerical indexing, the warning doesn't happen!\nR\n  for (i in length(paths)) {\n    sys.source(paths[i], envir = env, chdir = TRUE, keep.source = TRUE)\n  }\n. This pull request fixes #3, #85, #102, #109, and #125.\nIt also fixes #60. However, I get warning messages when loading some packages, like ggplot2 and lubridate. I think it has something to do with S4 classes but I'm not sure:\nWarning message:\nIn getPackageName(where) :\n  Created a package name, \u20182012-08-09 00:49:25\u2019, when none found\n. I think a good way to do this is to add an object (either a list or an environment) in the package's namespace called .__DEVTOOLS__, which would hold the metadata. This is similar to how metadata about the namespace is stored, in an environment called .__NAMESPACE__.\nIt could also hold the status of .onLoad, and .onAttach, which are presently stored in variables in the namespace.\n. Implemented in #126.\n. Does it also need to store the libpaths added by dev_mode?\n. If the purpose is to for cross-session storage, we'll also have to make sure to get the prompt to show up correctly based on this option when loading info from another session.\n. Implemented in #126, with inst().\n. Implemented in #137.\n. I think the start argument in check_examples() shouldn't require .Rd on the filename.\n. run_example('devtools', 'load_all') doesn't work for me. I think it's because this doesn't seem to generate the output file:\ntools:::Rd2ex(rd, tmp)\n. A few issues:\nThe header when I use dev_help looks like this:\nload_allpackage:/Users/winston/Dropbox/Projects/devtoolsR Documentation\nI think it should just have the package name (not the path).\n\nSome examples don't work:\n``` R\nOK\ndev_example('parent_envs')\nerror - maybe because of \\dontrun?\ndev_example('load_all')\n```\n\nProblem with run_examples on devtools:\n``` R\nSeems to be an error in 'create' examples\nrun_examples('.')\n[....]\n\ncreate(\"../myCustomPackage\", my_description)\nCreating package myCustomPackage in ..\nError: Directory already exists\nExecution halted\nError: Command failed (1)\n```\n\n\nOtherwise it looks pretty good to me.\n. Should find_topic support ::?\nR\nfind_topic(\"devtools::parent_envs\")\nThis would allow dev_example to support it also.\n\nThis throws an error, but maybe it should return NULL or throw a different error/warning:\n``` R\n\ndev_example('asdf')\nLoading devtools\nChecking asdf...\n\n\nError:  Sections \\title, and \\name must exist and be unique in Rd files\n``\n. Theloaded_packages()` function was added in #135.\n. I've tested it with plyr:\n``` R\nlibrary(devtools)\nload_all('devtools/', T)\nload_all('plyr/')\ntest('plyr')\nload_all('plyr', T)\ntest('plyr')\n``\n. Implemented and merged in 36aa49e93547fe434f7b39695c011609cf053a07.\n. I changedbranchtoref` for the github, gitorious, and bitbucket functions. I didn't test the latter two, though.\n. Fixed and merged in 9330614511f733c49231618da68c7b1a64b2c312. A second part needed fixing, at f57967aed8a3d0d21e87f7b05e1020e73680192b.\nI changed it use importing code from loadNamespace. This also made it import packages and objects list in the NAMESPACE file, in the same way that they are loaded when using library().\nNow the DESCRIPTION file isn't used to actually import packages, although it is still used to check version numbers.\n. Oh yeah, I've seen this again recently. The date isn't a lubridate thing - I believe it has something to do with R's handing of .removeSuperclassBackRefs. Sorry I don't have more insight on it right now!\n. Garrett - which package are you using when you see this?\nWith Shiny, this warning comes up now when you reload a package. It was introduced in rstudio/shiny@8d8ea53804251a24d9f38368b8ed0a9cf0133be5,\nThe problem is import(methods) in NAMESPACE. When that line is removed, reloading works fine.\n. One more thing I just remembered: John Chambers suggests putting methods into the Depends field instead of importing it. It's the third message in this thread:\nhttp://r.789695.n4.nabble.com/advise-on-Depends-td4678930.html\n. I'm thinking now that you can leave imports(methods) - the issue is with devtools. There's something different about how S4 classes are created when using load_all(), as compared to loading a built package with library(). Hopefully I'll be able to get load_all() to behave more like library().\n. The \"Created package name\" warning seems to be gone on R 3.0.3, and R-devel (from about two weeks ago).\n@garrettgman A heads up: on R-devel, I see these messages after the tests (but not on R 3.0.3):\nWarning messages:\n1: In Ops.factor(left, right) : - not meaningful for factors\n2: In Ops.factor(left, right) : - not meaningful for factors\n3: In Ops.factor(left, right) : - not meaningful for factors\n. I added code to properly register S3 methods.\nIt shouldn't be too hard to write a function that prints out exported and non-exported methods.\n. I think this is ready to merge now.\n. I think the '.Rd' is still needed with the start flag. It would nice if this were optional.\n```\nStarts from beginning\nrun_examples('.', start='load_all')\nStarts from load_all\nrun_examples('.', start='load_all.Rd')\n``\n. Looks good to me.\n. It would be nice if it still read~/.Renviron. Maybe--no-save --no-restore --no-site-file --no-init-file, but _not_--no-environ`?\nOr at least make it optional somehow.\n. All my packages are installed in ~/R because of how my .Renviron file is set up.\n. git ls-files -m doesn't seem to show modified files that have been staged (with git add). For checking whether there have been changes since the last commit, you can run this and get the return code:\n```\ngit diff-index HEAD --quiet\nFrom shell, print the previous return code\necho $?\n0: no changes\n1: there are changes (staged or not staged)\n128: error (e.g. not in a git repo)\n```\nAlso, the redirection to /dev/null might not work correctly on Windows, so it's a good idea to test that out.\n. It looks like this may be because of a difference between how hg repositories are zipped up vs. git repositories.\nTo install this repo, I think you need to specify a branch other than the default master (which is the name of the main branch in a git repo). But this currently gives an error:\n``` R\ninstall_bitbucket(\"hgnchelper\", username=\"lwaldron\", ref=\"default\")\nError: Does not appear to be an R package\n```\nThe problem is that in decompress(), the outdir() function takes the first item in the zip file and uses that for the directory name. This works with a devtools zip file downloaded from github, but not the hg zip file here. This is the outdir function for zip files, as defined in decompress:\noutdir <- function() {\n      basename(as.character(expand(src, list = TRUE)$Name[1]))\n    }\nHere's what the file list looks like for devtools:\nd> z <- unzip(zipfile, list=TRUE)\nd> z$Name\n  [1] hadley-devtools-c6fe626/                                          \n  [2] hadley-devtools-c6fe626/DESCRIPTION                               \n  [3] hadley-devtools-c6fe626/NAMESPACE                                 \n  [4] hadley-devtools-c6fe626/NEWS                                      \n  [5] hadley-devtools-c6fe626/R/\n...\nAnd here's what it looks like for hgnchelper:\nd> z$Name\n [1] lwaldron-hgnchelper-69a750601835/.hg_archival.txt           \n [2] lwaldron-hgnchelper-69a750601835/.hgtags                    \n [3] lwaldron-hgnchelper-69a750601835/CHANGELOG                  \n [4] lwaldron-hgnchelper-69a750601835/DESCRIPTION                \n [5] lwaldron-hgnchelper-69a750601835/NAMESPACE                  \n...\nI think a possible solution is to take the first item in the name list and drop everything after the last slash (though Windows may require something slightly different).\n. Now that I look at the code for decompress a bit more, it seems more \"functionalized\" than necessary -- it would be simpler if each if-statement just unzipped the files and found the outdir.\n. Something to keep in mind: Sometimes there are changes that affect the behavior of a function. For example, in R 2.15,  system2() changed so that it could stdout and the exit code:\nhttp://stackoverflow.com/questions/7014081/capture-both-exit-status-and-output-from-a-system-call-in-r\n. The way things are going, we'll eventually have a copy of loadNamespace with some small bits altered, like the paths and environment locking. :)\n. Fixed by #154.\n. Sample output from build():\n```\n\nbuild()\n/Library/Frameworks/R.framework/Resources/bin/R --vanilla CMD build  \\\n  '/Users/winston/Dropbox/Projects/scales' --no-manual --no-vignettes  \\\n  --no-resave-data \n\n\nchecking for file '/Users/winston/Dropbox/Projects/scales/DESCRIPTION' ... OK\npreparing 'scales':\nchecking DESCRIPTION meta-information ... OK\ninstalling the package to process help pages\nLoading required package: scales\nsaving partial Rd database\nchecking for LF line-endings in source and make files\nchecking for empty or unneeded directories\nbuilding 'scales_0.2.2.99.tar.gz'\n\ndevtools is checking for any extra files in built .tar.gz file... Non-standard files found: scales.sublime-project, scales.sublime-workspace.\n  Did you intend to include these files?\n```\nSample output from check():\n```\n\ncheck()\nLoading required package: roxygen2\nLoading required package: digest\nUpdating scales documentation\nLoading scales\nLoading required namespace: RColorBrewer\nLoading required namespace: dichromat\nLoading required namespace: munsell\nLoading required namespace: labeling\nWriting rescale.Rd\nWriting rescale_mid.Rd\nWriting rescale_none.Rd\nWriting censor.Rd\nWriting discard.Rd\nWriting squish.Rd\nWriting squish_infinite.Rd\nWriting expand_range.Rd\nWriting zero_range.Rd\nWriting pretty_breaks.Rd\nWriting extended_breaks.Rd\nWriting log_breaks.Rd\nWriting trans_breaks.Rd\nWriting cbreaks.Rd\nWriting col2hcl.Rd\nWriting muted.Rd\nWriting alpha.Rd\nWriting show_col.Rd\nWriting comma_format.Rd\nWriting dollar_format.Rd\nWriting percent_format.Rd\nWriting scientific_format.Rd\nWriting parse_format.Rd\nWriting math_format.Rd\nWriting trans_format.Rd\nWriting format_format.Rd\nWriting fullseq.Rd\nWriting area_pal.Rd\nWriting brewer_pal.Rd\nWriting dichromat_pal.Rd\nWriting gradient_n_pal.Rd\nWriting div_gradient_pal.Rd\nWriting seq_gradient_pal.Rd\nWriting grey_pal.Rd\nWriting hue_pal.Rd\nWriting identity_pal.Rd\nWriting linetype_pal.Rd\nWriting manual_pal.Rd\nWriting rescale_pal.Rd\nWriting shape_pal.Rd\nWriting Range.Rd\nWriting cscale.Rd\nWriting dscale.Rd\nWriting package-scales.Rd\nWriting date_trans.Rd\nWriting time_trans.Rd\nWriting date_breaks.Rd\nWriting date_format.Rd\nWriting asn_trans.Rd\nWriting atanh_trans.Rd\nWriting boxcox_trans.Rd\nWriting exp_trans.Rd\nWriting identity_trans.Rd\nWriting log_trans.Rd\nWriting log1p_trans.Rd\nWriting probability_trans.Rd\nWriting reciprocal_trans.Rd\nWriting reverse_trans.Rd\nWriting sqrt_trans.Rd\nWriting trans_new.Rd\nWriting as.trans.Rd\nWriting trans_range.Rd\nChecking scales\n/Library/Frameworks/R.framework/Resources/bin/R --vanilla CMD build  \\\n  '/Users/winston/Dropbox/Projects/scales' --no-manual --no-vignettes  \\\n  --no-resave-data \n\n\nchecking for file '/Users/winston/Dropbox/Projects/scales/DESCRIPTION' ... OK\npreparing 'scales':\nchecking DESCRIPTION meta-information ... OK\ninstalling the package to process help pages\nLoading required package: scales\nsaving partial Rd database\nchecking for LF line-endings in source and make files\nchecking for empty or unneeded directories\nbuilding 'scales_0.2.2.99.tar.gz'\n\ndevtools is checking for any extra files in built .tar.gz file... Non-standard files found: scales.sublime-project, scales.sublime-workspace.\n  Did you intend to include these files?\n/Library/Frameworks/R.framework/Resources/bin/R --vanilla CMD check  \\\n  '/var/folders/1b/bbmrmc8x6z71h3bcrpgcl7_00000gq/T//RtmpdZBawM/scales_0.2.2.99.tar.gz'  \\\n  --timings --as-cran \n\nusing log directory '/private/var/folders/1b/bbmrmc8x6z71h3bcrpgcl7_00000gq/T/RtmpdZBawM/scales.Rcheck'\nusing R version 2.15.1 (2012-06-22)\nusing platform: x86_64-apple-darwin9.8.0 (64-bit)\nusing session charset: ASCII\nchecking for file 'scales/DESCRIPTION' ... OK\nchecking extension type ... Package\nthis is package 'scales' version '0.2.2.99'\nchecking CRAN incoming feasibility ... OK\nchecking package namespace information ... OK\nchecking package dependencies ... OK\nchecking if this is a source package ... OK\nchecking if there is a namespace ... OK\nchecking for executable files ... OK\nchecking whether package 'scales' can be installed ... OK\nchecking installed package size ... OK\nchecking package directory ... OK\nchecking for portable file names ... OK\nchecking for sufficient/correct file permissions ... OK\nchecking DESCRIPTION meta-information ... OK\nchecking top-level files ... OK\nchecking index information ... OK\nchecking package subdirectories ... OK\nchecking R files for non-ASCII characters ... OK\nchecking R files for syntax errors ... OK\nchecking whether the package can be loaded ... OK\nchecking whether the package can be loaded with stated dependencies ... OK\nchecking whether the package can be unloaded cleanly ... OK\nchecking whether the namespace can be loaded with stated dependencies ... OK\nchecking whether the namespace can be unloaded cleanly ... OK\nchecking for unstated dependencies in R code ... OK\nchecking S3 generic/method consistency ... OK\nchecking replacement functions ... OK\nchecking foreign function calls ... OK\nchecking R code for possible problems ... NOTE\nfloor_time: no visible global function definition for 'to_time'\nmath_format: no visible binding for global variable '.x'\nchecking Rd files ... OK\nchecking Rd metadata ... OK\nchecking Rd cross-references ... OK\nchecking for missing documentation entries ... WARNING\nUndocumented code objects:\n  'abs_area' 'rescale_max'\nAll user-level objects in a package should have documentation entries.\nSee the chapter 'Writing R documentation files' in the 'Writing R\nExtensions' manual.\nchecking for code/documentation mismatches ... OK\nchecking Rd \\usage sections ... OK\nchecking Rd contents ... OK\nchecking for unstated dependencies in examples ... OK\nchecking examples ... OK\nchecking for unstated dependencies in tests ... OK\nchecking tests ...\n  Running 'test-all.R'\n OK\nchecking PDF version of manual ... OK\n\nWARNING: There was 1 warning.\nNOTE: There was 1 note.\nSee\n  '/private/var/folders/1b/bbmrmc8x6z71h3bcrpgcl7_00000gq/T/RtmpdZBawM/scales.Rcheck/00check.log'\nfor details.\n``\n. Removing packages works for me. One thing you might want to watch for: according to?remove.packages, it only tries to uninstall from the first path in.libPaths()`.\nSo if you're doing something like this, you might have a problem, since it will only search in ~/R-dev for a package to uninstall:\nlibrary(devtools)\ninstal_github('ggplot2')\ndev_mode(true)\nremove.packages('ggplot2')\n. For some reason, these classes are getting tangled up with EnumerationValue from RCurl (which is loaded because devtools is loaded) when using load_all, but not when loading with library.\nWith load_all:\n```\nd> load_all(export_all = FALSE)\nd> getClass(\"Duration\")\nClass \"Duration\" [package \"lubridate\"]\nSlots:\nName:    .Data\nClass: numeric\nExtends: \nClass \"Timespan\", directly\nClass \"numeric\", from data part\nClass \"vector\", by class \"numeric\", distance 2\nClass \"EnumerationValue\", by class \"numeric\", distance 2\n```\nWith library:\n```\nd> library(lubridate)\nd> getClass(\"Duration\")\nClass \"Duration\" [package \"lubridate\"]\nSlots:\nName:    .Data\nClass: numeric\nExtends: \nClass \"Timespan\", directly\nClass \"numeric\", from data part\nClass \"vector\", by class \"numeric\", distance 2\n``\n. Oddly, if you load lubridate first withlibrary(), then you canload_all` as much as you like without trouble.\n``` R\nlibrary(devtools)\nlibrary(lubridate)\ndetach('package:lubridate', unload=TRUE)\nload_all(reset=TRUE) # OK\nload_all(reset=TRUE) # OK\n```\nIt also works if you load lubridate before devtools:\n``` R\nStart new R session\nlibrary(lubridate)\nlibrary(devtools)\ndetach('package:lubridate', unload=TRUE)\nload_all(reset=TRUE) # OK\nload_all(reset=TRUE) # OK\n```\nBut it gives the warnings if you load devtools after unloading lubridate!\n``` R\nStart new R session\nlibrary(lubridate)\ndetach('package:lubridate', unload=TRUE)\nlibrary(devtools)\nload_all(reset=TRUE) # OK\nload_all(reset=TRUE) # Warnings\n``\n. Slowly narrowing this down... The problem (wheregetClass(\"Duration\")referencesEnumerationValuewhen it shouldn't) appears immediately after runningload_code(), which happens before any the S4 registration stuff. The analogous point inloadNamespace` is line 422:\nR\nres <- try(sys.source(codeFile, env, keep.source = keep.source))\nThis runs ~/R/lubridate/R/lubridate, which is an R file with the following:\nR\nlocal({\n    info <- loadingNamespaceInfo()\n    ns <- .Internal(getRegisteredNamespace(as.name(info$pkgname)))\n    if (is.null(ns))\n        stop(\"cannot find namespace environment\");\n    barepackage <- sub(\"([^-]+)_.*\", \"\\\\1\", info$pkgname)\n    dbbase <- file.path(info$libname, info$pkgname, \"R\", barepackage)\n    lazyLoad(dbbase, ns, filter = function(n) n != \".__NAMESPACE__.\")\n})\nThe lazyLoad() does the actual loading of the code. As soon as that is run, getClass(\"Duration\") will return the correct result. If load_all() is modified to run lazyLoad() (with the installed version of lubridate's dbbase) instead of load_code(), then getClass(\"Duration\") also returns the correct result. This suggests that the problem is load_code() itself, and not the preparation of namespace environment before that point.\n. If you manually create the classes, somehow, simply loading devtools can make the Duration class reference EnumerationValue:\n``` R\nsetClass(\"Timespan\")\nsetClass(\"Duration\", contains = c(\"Timespan\", \"numeric\"))\ngetClass(\"Duration\")\ngood: no reference to EnumerationValue\nNew R session\nlibrary(devtools)\nsetClass(\"Timespan\")\nsetClass(\"Duration\", contains = c(\"Timespan\", \"numeric\"))\ngetClass(\"Duration\")\nbad: reference to EnumerationValue\nNew R session\nlibrary(RCurl)\nsetClass(\"Timespan\")\nsetClass(\"Duration\", contains = c(\"Timespan\", \"numeric\"))\ngetClass(\"Duration\")\nbad: reference to EnumerationValue\n```\nOddly, when using library(), it doesn't have the problem, but when using load_all(), it does.\n``` R\nNew R session\nlibrary(devtools)\nlibrary(lubridate)    # Load lubridate instead of manually creating classes\ngetClass(\"Duration\")\ngood: no reference to EnumerationValue\nNew R session\nlibrary(devtools)\n.la()\nload_all('lubridate', export_all=FALSE)\ngetClass(\"Duration\")\nbad: reference to EnumerationValue\n```\n. It looks like, when a package is created the normal way, all the objects in the package, including s4 classes, are created with a clean R environment. When s4 classes are created this way, they won't have extraneous references to classes in other packages -- for example, the Duration class in lubridate won't have a reference to EnumerationValue in RCurl.\nThese objects are saved into .rdb and .rdx files and then loaded directly when library() is called. In the case of s4 classes, they won't be considered super- or sub-classes of other classes that happen to be loaded now -- they only have this relation to classes that were loaded when the package was created.\nWorking around this might not be possible with the current structure of load_all, since it would require a clean R environment, which isn't possible when devtools is loaded. One possible workaround is to modify unload so that it runs removeClass() on all the classes that are contained in the package.\nFor example, in the case of lubridate, it might do something like this:\n``` R\nlibrary(devtools)\nload_all('lubridate')\nd <- getClass(\"Duration\")\nd@contains <- list()\nassignClassDef(\"Duration\", d, asNamespace(\"lubridate\"))\nremoveClass(\"Duration\", asNamespace(\"lubridate\"))\nNote: need to be careful not to try this when lubridate is loaded with library()\nbecause can't modify a locked environment\n```\nThe modification of d@contains is necessary because removeClass tries to remove all the extended classes, which would include EnumerationValue here. By cleaning out the @contains, this doesn't happen.\nThe above code can be turned into a function and lapplyed over all the classes in a package:\n``` R\nremove_class <- function(classname, env) {\n  class <- getClass(classname)\n  class@contains <- list()\n  assignClassDef(classname, class, env)\n  removeClass(classname, env)\n}\nclasses <- getClasses(asNamespace(\"lubridate\"))\nlapply(classes, remove_class, asNamespace(\"lubridate\"))\n```\n. I don't get this with devtools 0.8 (or with the current master, e4aca48) when I load roxygen3. Which version of devtools do you have installed?\n```\n\nlibrary(devtools)\n packageVersion(\"devtools\")\n[1] \u20180.8\u2019\nload_all()\nLoading roxygen3\nLoading required namespace: brew\nLoading required namespace: codetools\nLoading required namespace: igraph\nCreating a new generic function for \u2018topicName\u2019 in package \u2018roxygen3\u2019\nCreating a generic function for \u2018format\u2019 from package \u2018base\u2019 in package \u2018roxygen3\u2019\nWarning message:\nreplacing previous import \u2018forget\u2019 when loading \u2018memoise\u2019 \ngenerics <- getGenerics()@.Data\nis_generic <- vapply(generics, isGeneric, logical(1))\ngenerics[!is_generic]\ncharacter(0)\n```\n. When I install the s4-mojo package and load it, I get different results:\n\nd> library(s4mojo)\nd> m <- new(\"Model\")\nd> coef(m)\nError in coef(m) : \n  no slot of name \"coef\" for this object of class \"Model\"\nd> \nd> f <- getMethod(\"coef\", \"Model\")\nd> f(m)\nError in f(m) : no slot of name \"coef\" for this object of class \"Model\"\nShould it access object@coefs (instead of object@coef) in all-generics.r?\nI have a fix locally that exhibits the same behavior with load_all() and with library(), with both object@coef and object@coefs.\n. @lianos I've pushed the branch with s4 code. Could you try it out on your package and see if it works for you? You can install it with:\ninstall_github('devtools', 'wch', 's4')\n. @lianos I've rebased the s4 branch onto master. Could you do the following and report what results you get?\n- test it with the s4 branch, using install_github('devtools', 'wch', 's4')\n- test it with the master branch, using install_github('devtools')\nThe reason for this is that there were some other s4-related changes recently merged into the master branch that may have fixed your problem. If they did indeed fix it, then the s4 branch won't have to be merged.\n. Interesting. You're right: when I run has_devel() from R in a Terminal, it thinks I have i386:\n```\n\nhas_devel()\n/Library/Frameworks/R.framework/Resources/bin/R --vanilla CMD SHLIB foo.c \n\ngcc -arch i386 -std=gnu99 -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -DNDEBUG  -I/usr/local/include    -fPIC  -g -O2  -c foo.c -o foo.o\ngcc -arch i386 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/lib -o foo.so foo.o -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation\n[1] TRUE\n```\nBut when I run it from RStudio, it thinks I have x86_64:\n```\n\nhas_devel()\n/Library/Frameworks/R.framework/Resources/bin/R --vanilla CMD SHLIB foo.c \n\ngcc -arch x86_64 -std=gnu99 -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/x86_64 -DNDEBUG  -I/usr/local/include    -fPIC  -g -O2  -c foo.c -o foo.o\ngcc -arch x86_64 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/lib -o foo.so foo.o -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation\n[1] TRUE\n```\nI don't think it's safe to always use x86_64 on a Mac, though -- there are some machines that are still 32-bit (Core Duo machines, I believe), and I wonder if the 32/64-bit distinction matters if they're running 32-bit vs 64-bit R, even on 64-bit machines.\n. Another thought - when I run sessionInfo(), I get different results from the Terminal and form RStudio.\nTerminal:\n```\n$ R\n\nsessionInfo()\nR version 2.15.2 (2012-10-26)\nPlatform: i386-apple-darwin9.8.0/i386 (32-bit)\n...\n```\n\nRStudio:\n```\n\nsessionInfo()\nR version 2.15.2 (2012-10-26)\nPlatform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)\n```\n\nThe key is to run R64 from the terminal:\n```\n$ R64\n\nsessionInfo()\nR version 2.15.2 (2012-10-26)\nPlatform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)\n```\n\nOne weird thing is that R64 doesn't seem to respect my .Rprofile. I'm not sure why that is. It would be better if R just default to the 64-bit version.\nUpdate: According to  http://r.research.att.com/, the right thing to do is run R --arch x86_64, not R64.\n. @jjallaire, thanks, that helps to make sense of this situation.\nI got R from the terminal to default to 64-bit by putting this in my ~/.profile:\n``` bash\nMake R default to 64-bit on Mac, if available\nif [ uname -m == \"x86_64\" ]; then\n    export R_ARCH=/x86_64\nfi\n```\nI also tried putting this in my .Rprofile, but it didn't seem to have any effect:\nR_ARCH=/x86_64\nI wonder why they don't just make R default to 64 bit when it's available.\n. Fixed in c9df3d247ec664bfe19a8a3890062c7bd3c427c6.\n. Installing that package works fine for me... Are you using the latest version of R and are all of your packages up to date with update.packages()?\n. I wonder if this is related to the relatively old version of Mac OS X - I see that it's Darwin9.8.0, which (I believe) is OS X 10.5.8.\n. @emhart Oh, you're right. Mine says the same thing. I bet that's the platform that it was built on.\n. I think some of the package installation failures have to do with installing packages from source in dev_mode. Maybe the libpaths don't get set correctly?\nFor example, quantreg depends on SparseM, and both have to be compiled. On a clean(ish) Linux system, installing in \"normal\" mode works, but installing in dev mode fails.  It manages to install SparseM, but then quantreg fails. Here's part of the status output:\n```\ninstalling to /home/ubuntu/R-dev/quantreg/libs\n R\n data\n demo\n inst\n preparing package for lazy loading\n help\n installing help indices\n* building package indices\n installing vignettes\n   \u2018crq.Rnw\u2019 \n   \u2018rq.Rnw\u2019 \n   \u2018rqss.Rnw\u2019 \n* testing if installed package can be loaded\nWarning in library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc = lib.loc) :\n  there is no package called \u2018SparseM\u2019\nError : package \u2018SparseM\u2019 could not be loaded\nError: loading failed\nExecution halted\nERROR: loading failed\n removing \u2018/home/ubuntu/R-dev/quantreg\u2019\nThe downloaded source packages are in\n        \u2018/mnt/tmp/Rtmpz0oiGd/downloaded_packages\u2019\nWarning message:\nIn install.packages(\"quantreg\") :\n  installation of package \u2018quantreg\u2019 had non-zero exit status\n``\n. Adding~/R-devto the~/.Renviron` file works:\nR_LIBS=~/R:~/R-dev\nBut this isn't a very good solution. I wonder if there's a way to make install.packages() pass along the current .libPaths().\n. I think there may also be a bug in install.packages() when Ncpus is large. Some of these packages fail to install when I use 32 threads, but some install fine when I use 2. Yet more install fine when I use 1. Maybe the problem is with Makefiles that don't properly handle that many threads?\n. This is the result of an R bug. See last message here for more info:\nhttp://r.789695.n4.nabble.com/install-packages-fails-if-libPaths-set-td4647797.html\nIt happens because install.packages doesn't run R \u2014vanilla and hence it ihnerits settings from the defaults, rather than the current process.\nDeferring this until we have a replacement for install.packages().\n. Did you mean that you ran check('.'), not create('.')?\nI'm not able to reproduce this error. I tried to reproduce your package at https://github.com/wch/s4-union, but I'm not sure it's exactly the same. (Note that if you clone that repo, you'll have to manually create a man/ directory to make check() happy -- git doesn't store empty directories.)\nIf you still have the problem, could you post your sessionInfo after running check? I just want to make sure that we're using the same things. This is what I have:\n```\n\nsessionInfo()\nR version 2.15.2 (2012-10-26)\nPlatform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] s4union_0.1    roxygen2_2.2.2 digest_0.6.0   devtools_0.8  \nloaded via a namespace (and not attached):\n[1] brew_1.0-6      evaluate_0.4.3  httr_0.2        memoise_0.1  \n[5] parallel_2.15.2 RCurl_1.95-3    stringr_0.6.2   tools_2.15.2 \n[9] whisker_0.1\n``\n. Can you try with theI previously thought this was a problem with the unloading code, but now I think it might be a problem with the loading code inload_all. It's possible to load and unload the package as many times as you want usinglibrary()anddetach(unload=T)and it won't give any errors. But if you useload_all()` after doing this, it complains.\n``` R\nlibrary(devtools)\nlibrary() once: OK\nlibrary(mcmc4)\ndetach('package:mcmc4', unload=TRUE)\nunloadNamespace('mcmc4') # Just to be sure it's unloaded\nlibrary() again: OK\nlibrary(mcmc4)\ndetach('package:mcmc4', unload=TRUE)\nunloadNamespace('mcmc4') # Just to be sure it's unloaded\nload_all results in error\nload_all(reset=TRUE)\nLoading mcmc4\nError in .walkClassGraph(ClassDef, \"contains\", where, attr(ext, \"conflicts\")) :\nthe 'superClass' list for class \u201cNULL\u201d, includes an undefined class \u201cMcmcChainItersOrNull\u201d\nError in setClassUnion(\"McmcParChainsOrNull\", c(\"McmcParChains\", \"NULL\")) :\nunable to create union class:  could not set members \"NULL\"\n```\nFirst loading with load_all() is Ok, but second loading results in the error.\n``` R\nNew R session\nlibrary(devtools)\nOK\nload_all(reset=TRUE)\nError\nload_all(reset=TRUE)\n```\nIt seems that that, whether the package is loaded with library() or load_all(), unloading it leaves some traces behind. Subsequent loading with library() seems to be OK, but that's not the case with load_all().\nThe reason you're encountering this with check() is because check() runs load_all().\n. I would suggest taking things out of your package until you have the bare minimum that still produces the same error.\nI've also written up something here and sent Luke Tierney an email about the issue -- hopefully he'll be able to shed some light on what's going on.\nhttps://github.com/wch/s4test\n. I think it would be a good idea to make a shallow git clone, to minimize the download size.\n. @davidcoallier yes, --depth=1 was what I was thinking. (I haven't used it before, though.)\n. Looking good!\n. Thanks! Fixed.\n. This flag apparently doesn't work with the --as-cran argument, so the use of --as-cran in devtools will have to be replaced by the environment variables listed in http://cran.r-project.org/doc/manuals/R-ints.html#Tools.\n. @bbolker no, quick=TRUE presently doesn't affect vignette building. The vignettes are built during the build phase, not the install phase, and quick=TRUE only affects the install phase.\n. I'm trying to reproduce this issue so I can fix it. Could you provide a package that exhibits this problem?\n. I have to wonder if this is necessary -- install_bitbucket accesses a repository by name and installs the package from the repo. Why is desirable to change the name of the repo that the user asks for?\n. I've implemented this in 14e0631 .\n. Yes, this is probably the same issue. Right now devtools doesn't attach packages that are listed as Depends.\n. See the inst_path() function from staticdocs for a workaround:\nhttps://github.com/hadley/staticdocs/blob/master/R/util.r\nThe root of the problem is that the directory structure of an installed package is different from a development package.\n. OK, this could be tricky... I don't think it's possible to make a 100% compatible version of system.file.\nHere's one possible way to do it:\nSuppose that the name of the development package is \"newpackage\", and the path is /foo/newpackage.\n- If called with system.file(package=\"stats\"), where stats is any package other than newpackage, just pass through to base::system.file.\n- If called with system.file(package=\"mypackage\") have some customized behavior:\n  - If the path requested is /, return /foo/newpackage.\n  - If the path requested is /DESCRIPTION, /NEWS, or /NAMESPACE, return /foo/newpackage/xxx, where xxx is the file.\n  - If the path is data/, then return /foo/newpackage/data/\n  - If the path is anything else, return the path under /foo/newpackage/inst/\nLimitations:\n- Any calls to system.file(package=\"newpackage\") from other packages or from the R console will get base::system.file, not the modified version.\n- If users manually get a subdir based off the top level of newpackage, it'll probably be wrong. For example, file.path(system.file(package=\"newpackage\"), \"somefile.txt\") will return /foo/newpackage/somefile.txt, instead of /foo/newpackage/inst/somefile.txt, which is what they probably want.\n- If functions like find.package and path.package are used, they still won't quite work right (this is almost the same as previous). For example, if someone does something like file.path(find.package(\"newpackage\"), \"somefile.txt\"), it'll return /foo/newpackage/somefile.txt, instead of /foo/newpackage/inst/somefile.txt, which is what they probably want.\n- Tangential: other functions that use lib.loc or libpath won't work correctly, and I don't think it's possible to make them work correctly. For example, see #191.\nSo, overall, it might be possible to make a version of system.file that sort of works, but there will be a lot exceptions to the behavior, which is why I'm kind of lukewarm on it. The fundamental problem is that the directory structure of an installed package is different from the directory structure of an in-development package.\n. This might be because of a bug in install.packages(): https://stat.ethz.ch/pipermail/r-devel/2012-October/065111.html\nA workaround for now is to set R_LIBS in ~/.Renviron, then use that path as the libpath for revdep_check.\n~/.Renviron contains:\nR_LIBS=/tmp/R-lib\nAnd then run revdep_check like this:\nrevdep_check('ggplot2', libpath='/tmp/R-lib')\n. I don't think that this was because of the .libPath thing in check_cran (#199).\n I tried this again and didn't end up with any more successfully installed packages on the second run, even when I first ran with more threads, like this:\n```\nrevdep_check('ggplot2', threads=32)\n208 packages installed at this point in /tmp/xxx/R-lib\nrevdep_check('ggplot2')\n208 packages installed at this point in /tmp/xxx/R-lib\n```\nAnd I get the same result when I don't specify libpath:\n```\nrevdep_check('ggplot2', libpath='/tmp/R-lib', threads=32)\n208 packages installed at this point in /tmp/R-lib\nrevdep_check('ggplot2', libpath='/tmp/R-lib')\n208 packages installed at this point in /tmp/R-lib\n```\nSo maybe there was some change along the way that fixed it. There's still the bug with install.packages not working right with source packages and R_LIBS, but that might not matter here.\n. While we're at it, we should also disable the CRAN incoming version check.\n. This is closely related to #196.\nHow does this sound for the set of conditions where _R_CHECK_FORCE_SUGGESTS_ is set to FALSE?\n- If called from check_cran: FALSE\n- If running on Windows: FALSE\n- Otherwise: TRUE (but make it an option to check(), like force_suggests = TRUE?)\n. The CRAN incoming version presently is run by release(). It has the following line:\ncheck(pkg, cran = TRUE, check_version = TRUE)\nDo you have in mind something else?\n. I tried setting the following for check, but it still ran a bunch of stuff:\nenv_vars <- c(\n    \"_R_CHECK_CRAN_INCOMING_\" = \"TRUE\",\n    \"_R_CHECK_FORCE_SUGGESTS_\" = \"FALSE\",\n    \"_R_CHECK_RD_CONTENTS_\" = \"FALSE\",\n    \"_R_CHECK_RD_STYLE_\" = \"FALSE\",\n    \"_R_CHECK_RD_XREFS_\" = \"FALSE\",\n    \"_R_CHECK_SUBDIRS_NOCASE_\" = \"FALSE\",\n    \"_R_CHECK_USE_CODETOOLS_\" = \"FALSE\",\n    \"_R_CHECK_CODOC_S4_METHODS_\" = \"FALSE\",\n    \"_R_CHECK_DOT_INTERNAL_\" = \"FALSE\",\n    \"_R_CHECK_EXECUTABLES_\" = \"FALSE\",\n    \"_R_CHECK_PERMISSIONS_\" = \"FALSE\",\n    \"_R_CHECK_LICENSE_\" = \"FALSE\",\n    \"_R_CHECK_ASCII_CODE_\" = \"FALSE\",\n    \"_R_CHECK_ASCII_DATA_\" = \"FALSE\",\n    \"_R_CHECK_COMPACT_DATA_\" = \"FALSE\",\n    \"_R_CHECK_PKG_SIZES_\" = \"FALSE\",\n    \"_R_CHECK_DOC_SIZES_\" = \"FALSE\",\n    \"_R_CHECK_UNSAFE_CALLS_\" = \"FALSE\"\n  )\nMaybe the way to go is to check the version manually.\n. Fixed by pull request #208.\n. Instead of removing the old results, check_cran now makes a new temp dir for each run.\n. When I install other packages, it seems to work -- the problem for me happens with ggplot2:\nFor example, this works fine for me:\n```\ninstall_version(\"scales\",  \"0.2.2\")\ninstall_version(\"scales\",  \"0.2.1\")\ninstall_version(\"gtable\",  \"0.1.1\")\ninstall_version(\"gtable\",  \"0.1.0\")\n```\nAlso, these versions of ggplot2 work:\ninstall_version(\"ggplot2\",  \"0.9.2\")\ninstall_version(\"ggplot2\",  \"0.9.2.1\")\nI only seem to have problems when version 0.9.1 is involved.\n. Since it seems to have something to do with version 0.9.1, I don't think it should be filed as a ggplot2 bug either -- that version can't be changed, so there's really nothing to fix.\n. I think maybe scaffold is a special name? I just tried renaming it to scaffold-1 and it installed correctly. Maybe this is a question for the r-devel list?\n. I'd be curious to find out why this happens. Do you mind posting a question about it to the r-devel list?\n. Great - I was wondering why it was being run from both load_all and build.\n. Sounds good - looking forward to talking about this stuff.\n. This was a duplicate of #171 - it was due to a bug in R, fixed in 2.15.2.\n. I'm not familiar with how Rcpp attribute compilation works... Does this leave behind anything that should be cleaned up (for example, by clean_dll())?\n. Looks good!\n. Here's the relevant code from loadNamespace(): https://github.com/wch/r-source/blob/trunk/src/library/base/R/namespace.R#L450\nIt does appear that the .onLoad hooks (line 455) run before the namespace export setup stuff (starting line 458). But I don't see anything about calling getLoadActions() there. I searched the R source and didn't find any calls to getLoadActions() at all.\nI think the place where the load actions are being run from is line 467, with methods:::cacheMetaData(ns, TRUE, ns). Here's that function: https://github.com/wch/r-source/blob/trunk/src/library/methods/R/RMethodUtils.R#L829\nAt the end, it calls .doLoadActions(), which I would guess runs the load actions.\nI think the solution is to modify setup_ns_exports(). Presently it does the work of lines 458-461, and then line 622 in namespace.R, but it skips the whole block in the middle, where cacheMetaData() is called. That block seems to be mostly related to S4 stuff. Probably the proper fix is to implement that whole block (which may fix some of the outstanding issues related to S4) but for now it might work to just call cacheMetaData() before the call to namespaceExport().\n. I think this can be merged - the issues with S4 need to be fixed anyway, so I think we might as well merge this and fix that later. As long as we have good tests, this should be a safe way to go.\n. @jjallaire, keep in mind that Hadley trimmed all trailing whitespace in devtools, so you may see a lot of conflicts that aren't really conflicts.\nIf rebasing ends up being too much of a pain, I can merge and resolve the conflicts by hand.\n. Thanks! There was still a conflict in NEWS (I think you rebased against a slightly out of date master), but that was easy to resolve.\n. Ah, the bug appears to be fixed in R 2.15.2. Do you think this patch should be merged, or just tossed?\n. OK, I'll just close it then.\n. I'm not sure this is quite the right solution...\nIt causes a few of the tests (using test()) to fail, because the code here uses the named argument libname. The test packages expect have .onLoad defined as function(lib, pkg). According to ?.onLoad, the arguments passed to the function are not named:\n\nAfter loading, \u2018loadNamespace\u2019 looks for a hook function named \u2018.onLoad\u2019 and calls it (with two unnamed arguments) before sealing the namespace and processing exports.\n\nSo the proper call would be:\nnsenv$.onLoad(NULL, pkg$package)\nExcept there's another issue: when a package installed and loaded the normal way, the first argument isn't NULL; instead, it's the path to the library. For example, if mypackage is installed in /Users/winston/R/mypackage, the library is /Users/winston/R. But of course, when using load_all(), you're not using a library, and the package isn't guaranteed to be in a subdir with the same name as the package. So I'm not sure this second problem can be fixed.\nIt might be best to just remove the naming of the arguments and make a comment about the library problem.\n. I'm travelling so I can't try it right now, but I think it should work to change the call to have non-named arguments.\n. Implemented in 5d97fd02adcc0f4465686fe79d72213683438543 and 4cd8610ada14d960dff31166b741108b23dd0fde. Thanks!\n. When did they deprecate that? Googling around, I can't seem to find any news about it.\nUpdate -  found it: https://github.com/blog/1302-goodbye-uploads\n. For normal checking, disabling in Windows isn't an issue; only when check_cran is used. And in that case, force_suggests is now set to FALSE anyway, so this won't be an issue.\n. I think you'll also want to make sure that devtools isn't one of the packages that you'll unload.\n. Actually, I think it's because the setdiff(.libPaths(), libpath) will remove multiple instances of the libpath. But the add=TRUE thing also needs fixing.\n. Just a note: without Rtools, install_github() on Windows fails at the build() stage. Here's an example of trying to build devtools:\n```\n\nbuild('devtools')\nC:/PROGRA~1/R/R-215~1.2/bin/i386/R --vanilla CMD build  \\\n  \"Z:\\devtools\" --no-manual --no-resave-data \n\n\nchecking for file 'Z:\\devtools/DESCRIPTION' ... OK\npreparing 'devtools':\nchecking DESCRIPTION meta-information ... OK\ncleaning src\nchecking for LF line-endings in source and make files\nchecking for empty or unneeded directories\nbuilding 'devtools_0.8.0.99.tar.gz'\n ERROR\npackaging into .tar.gz failed\nError: Command failed (1)\nIn addition: Warning message:\nrunning command '\"C:/PROGRA~1/R/R-215~1.2/bin/i386/R\" --vanilla CMD build \"Z:\\devtools\" --no-manual --no-resave-data' had status 1 \n``\n. It looks like this is due to a bug inmclapply(). More information in this thread: http://r.789695.n4.nabble.com/Bug-in-mclapply-td4652743.html\n. Apparently themclapply` issue was fixed in r-devel: https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15140\n. Do you mean that it should be monitored manually?\n. I think the logic isn't quite right -- it shouldn't always be FALSE for Windows, only when the check is supposed to be like CRAN.\n\nMaybe the best thing to do is take out the Windows test entirely. check_cran already uses force_suggests=FALSE, and that's when it really matters. If users are running check() on individual packages, they can just set force_suggests=FALSE by hand.\n. Fixed in 6f54ac8.\n. Weird - these commits closed 161, even though the branch hasn't been merged yet.\n. This might also address #192.\n. These are the results of an experiment with two variables.\nVariable A: contents of ~/.Renviron\n- ~/.Renviron doesn't exist\n- ~/.Renviron contains R_LIBS=/tmp/R-lib\nVariable B: libpath passed to revdep_check:\n- revdep_check('ggplot2', threads=32)\n- revdep_check('ggplot2', libpath='/tmp/R-lib', threads=32)\n- revdep_check('ggplot2', libpath='/tmp/R-lib2', threads=32)\nIn each condition of AxB, I counted the number of successfully installed packages. I also checked to see whether a second run would result in more successfully installed packages (it didn't in any condition).\n| .Renviron | libpath | # of packages first run | # of packages second run |\n| --- | --- | --- | --- |\n| /tmp/R-lib/ | /tmp/R-lib | 342 | 342 |\n| /tmp/R-lib/ | /tmp/R-lib2 | 206 | 206 |\n| /tmp/R-lib/ | - | 206 | 206 |\n| - | /tmp/R-lib | 342 | 342 |\n| - | /tmp/R-lib2 | 342 | 342 |\n| - | - | 322 | 322 |\nIt looks like setting R_LIBS in .Renvion can lead to weird results with install.packages. I think the reason that the last one has 322 packages is because there are 20 other packages that needed to be installed first before beginning the check (like devtools, ggplot2, scales, etc), and in that condition they went to a different directory than the one I counted.\n. This has the same root cause as #166.\n. Updated and rebased.\n. Sure. But should something be done to ensure that a full check is done before a release?\n. OK, I've made the wording a bit stronger, rebased, and added a NEWS item.\n. Rebased and pushed. I wish there were a way to avoid these NEWS conflicts.\n. So, have a devtools config file for a package? That's an interesting idea. Are there other things that you have in mind to put in it?\n. I've added a devtools.cleandoc option. By default it's FALSE, so document() does not clean out existing files in man/.\n. Glad it's useful for you! \nThis is a duplicate of #171.. If you need a workaround, see pull request #189.\n. Try installing the newest version of Rcpp -- it should have the cpp_files argument.\n. Could you provide a reproducible example? That would be helpful for solving this issue.\n. @hadley, can you recommend a good way to test for no error for a given expression -- I'd like to do something like expect_no_error().\nUpdate: This is what I've come up with:\n``` R\nexception <- \"none\"\nwithCallingHandlers(load_all(\"s4union\"),\n  error   = function(e) { exception <<- \"error\"   },\n  warning = function(w) { exception <<- \"warning\" }\n)\nexpect_equal(exception, \"none\")\n``\n. I've added a functionexpect_no_warn_errorinhelper-error.r`. This can be removed when testthat gets a function that does the same thing.\nI've added the tests. There's one strange thing.\nThe loaded package has the following:\nR\ngetClass(\"A\")\ngetClassDef(\"A\")\ngetClassDef(\"AB\")\nWhen the package is unloaded, running getClassDef() on any of those should return NULL. However, the actual result is that B and AB are NULL, but A is not NULL!\nexpect_true(is.null(getClassDef(\"A\")))   # Fail\nexpect_true(is.null(getClassDef(\"B\")))   # Pass\nexpect_true(is.null(getClassDef(\"AB\")))  # Pass\nThe test with A is in the test suite, but I've commented it out. Even though that class appears to be hanging around when it shouldn't be, I don't see any practical problems that it causes (reloading the package works fine).\n\nOddly, it seems to be possible to remove class A. The unload() function calls remove_s4_class(), and in that function, this is the line that actually removes the class:\nremoveClass(classname, where = nsenv)\nI tried putting in a browser() right before that line, and then, when it came time to remove A, I ran removeClass(\"A\"), without specifying a value for where. When I did that, it removed A just fine. But getting rid of the where causes problems for removing other classes -- they don't load properly when doing load_all is run on the package again.\nMy guess is that the failure to remove A is a bug in R's implementation of S4.\n. Yes, expect_null would be handy, as would expect_na.\nMore on the issues with removing class A in the tests. This is what happens when the package is loaded then unloaded (which calls remove_s4_class()). The class still shows up with getClass(\"A\"), but if you try to remove it, it says the class definition isn't found. I think this probably a bug in R's class caching.\n```\n\nload_all(\"s4union\")\nLoading s4union\nLoading required namespace: stats4\nunload(\"s4union\")\ngetClass(\"A\")\nVirtual Class \"A\" [package \"s4union\"]\n\nNo Slots, prototype of class \"NULL\"\nExtends: \"AB\", \"mleA\", \"mle2A\"\n\nremoveClass(\"A\")\n[1] FALSE\nWarning message:\nIn removeClass(\"A\") : Class definition for \u201cA\u201d not found (no action taken)\n``\n. Actually, nevermind the idea of looking at subkeys. The2.15` entry was a leftover from my previous installation of Rtools. With a clean installation, there's no reference at all to 2.15:\n\n```\n\nkey <- utils::readRegistry(\"SOFTWARE\\R-core\\Rtools\",\n+      hive = \"HLM\", view = \"32-bit\")\nkey\n$Current Version\n[1] \"2.16\"\n\n$InstallPath\n[1] \"c:\\Rtools\"\n$2.16\n[1] \"\"\n```\nI think potential solutions include:\n- Dropping the version check entirely.\n- Make sure that the minor version of Rtools is within 1 of the minor version of R.\n- Hard-code the version table from the Rtools website into rtools(). \n. I think leading and trailing underscores should be used to match the format of the other check-related environment vars (the underscores just didn't show up in the chat window previously): _LOCAL_TEST_.\n. This should be fixed in the development version of devtools (via pull request #213).\nJust to make sure: if you're using Windows, install_github('devtools') might not have worked properly, even though it appears to. You'll need to follow the instructions linked to from this message: https://groups.google.com/forum/?fromgroups=#!topic/rdevtools/hfC-VAgUDjg\n. This issue was fixed a while back.\nIf the file is in extdata, you need to load it with something like this:\nload(system.file(\"extdata\", \"datafile.rda\", package=\"mypackage\"))\nIf you need further help the rdevtools mailing list is the place to ask: https://groups.google.com/forum/#!forum/rdevtools\n. I think this might be problematic to load your data if your current working directory isn't the same as the top-level of the project.\nProbably a more reliable way is to do something like this:\nvarname <- load(system.file(\"data\",\"dataset.rda\", package=\"mypackage\"))\nSPECIALDATA <- eval(parse(text=varname)\n. Oh, that probably means that the path isn't entered correctly. If system.file gets an invalid path, it returns \"\". From the R console, try changing the arguments of system.file() until it returns the path to your data file. Also, you'll need devtools 1.0 for this to work.\n. One problem is that devtools is untested on 2.14 -- and it does a lot of low-level stuff that may or may not work on versions prior to 2.15.\nYou could install 2.15 by following the instructions here:\n  http://cran.r-project.org/bin/linux/ubuntu/\nI wrote up a summary about it here:\n  https://github.com/wch/ggplot2/wiki/R-on-Ubuntu\n. It looks like load_data and load_all currently don't handle data objects quite right. When a package is loaded the normal way, the data is in the package environment, but not the namespace:\n```\nlibrary(plyr)\nns <- asNamespace('plyr')\nhead(ns$baseball)\nNULL\npkg <- as.environment('package:plyr')\nhead(pkg$baseball)\n[prints out data]\n```\nBut when you use load_all, it gets loaded into the namespace first, then is copied to the package environment (if export_all==TRUE):\n```\nload_all()\nns <- asNamespace('plyr')\nhead(ns$baseball)\n[prints out data]\npkg <- as.environment('package:plyr')\nhead(pkg$baseball)\n[prints out data]\n```\nMaybe it should use the lazy-loading code from R? https://github.com/wch/r-source/blob/trunk/src/library/base/R/namespace.R#L426\nEdit: Nevermind about the lazy-loading; that requires .rdb and .rdx files, which (I think) are generated when the package is built.\n. I think when lazyLoad is called, it puts a \"promise\" into nsenv$.__NAMESPACE__.$lazydata, and those somehow get copied into the package environment. For example, this will print out the data:\nlibrary(plyr)\nns <- asNamespace('plyr')\nhead(ns$.__NAMESPACE__.$lazydata$baseball)\nI tried sImply copying objects into $lazydata, and that's apparently not quite enough -- they don't show up in the package env. So I'm going to also have the export process copy objects from $lazydata to the package env.\n. This is due to a conflict in package names on the CRAN build machine, and should be fixed by ee2e2b2.\n. Also, it should allow private gists, which can have hexadecimal characters. See the Shiny implementation of runGist for code that deals with both these issues:\nhttps://github.com/rstudio/shiny/blob/master/R/run-url.R#L25\n. Also keep in mind that those who aren't command-line-savvy will need an easy way to run these commands.\n. @CharlesCara Should be fixed in 1.1, which is on CRAN now. Can you test it out?\n. I think the right thing to do is run the tests in a separate R session, to avoid this and other side-effects.\n. Installing httr from github works fine for me on my Mac with devtools 1.1. What platform are you on?\n. httr::GET seems to be working for me. Here's what happens when you fetch a URL without following the redirect. This particular URL should redirect 3 times before hitting the actual document (at http://httpbin.org/get):\n$ curl \"https://httpbin.org/redirect/3\"\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n<title>Redirecting...</title>\n<h1>Redirecting...</h1>\n<p>You should be redirected automatically to target URL: <a href=\"/redirect/2\">/redirect/2</a>.  If not click the link.\nAnd with GET:\n```\n\nhttr::GET(\"https://httpbin.org/redirect/3\")\nResponse [http://httpbin.org/get]\n  Status: 200\n  Content-type: application/json\n{\n  \"headers\": {\n    \"Accept-Encoding\": \"gzip\",\n    \"Connection\": \"close\",\n    \"Host\": \"httpbin.org\",\n    \"Accept\": \"/\"\n  },\n  \"args\": {},\n  \"url\": \"http://httpbin.org/get\",\n  \"origin\": \"10.44.106.72\"\n} \n```\n\nPerhaps you had an old version of httr that didn't follow redirects?\n. It looks like CRAN uses a UTF-8 for all platforms except Mac. See http://cran.r-project.org/web/checks/check_results_abd.html\nIf you follow the NOTE/WARN links, you'll see \"using session charset\" and \"package encoding\". My guess is that they just use the default locale on their checking systems. On my Ubuntu 12.04 installation, it defaults to a UTF-8 locale.\nIs there a reason that R() sets it to a C locale? I know that it's useful for consistent sorting when generating docs, but  it's not clear to me why it's used here. (And also, this makes me realize that using the C locale for sorting might not be good, since it might do weird things for packages with UTF-8 characters.)\n. Could you provide a small test package that demonstrates this error? You can see examples of these test packages in insts/tests/. If it's not too complicated, it might make sense to modify the s4 union test package.\n. Sounds good - you can leave this pull request open, it's not a problem.\n. Hang on, don't merge yet: the sha1 here doesn't match the value from shasum at the command line.\n. OK, I've incorporated your comment, and fixed the file saving format (with type=\"raw\").\n. OK, I've incorporated the changes and pushed. I also clarified the source_gist docs a bit.\n. The same problem with .onLoad() came up in #191. The same issue applies here: it's not possible to pass in the libname in a way that's guaranteed to work, for the same reason as in the previous issue.\nI think the best solution is to call onAttach() the same way, with nsenv$.onAttach(NULL, pkg$package). Also, it should print a warning if the dirname doesn't match the package name, when .onLoad and .onAttach are called.\n. Oops, I meant to say that onAttach should be called with:\nnsenv$.onAttach(dirname(pkg$path), pkg$package)\n. Can this be an option? I can see it causing unexpected problems if it's always done automatically.\n. Usually, export_all=TRUE, so most changes to NAMESPACE (the exports) won't result in any changes to what's actually exported with load_all(). Also, most changes to the source code won't result in a change NAMESPACE file. \nSo I'm wondering: why choose a changed NAMESPACE file as the signal to reload, given that it's not a particularly reliable one? Is it just the best option? In an ideal world, when would you want devtools to auto-reload a package?\n. install() is in the devtools package, so you need to do library(devtools) or devtools::install().\n. I believe the 403 errors happen when an older version of devtools is used, and it tries to install from a URL like this:\n  https://api.github.com/repos/hadley/devtools/zipball/master\nGithub changed the download URL (around December, I think), so newer versions of devtools use URLs like this:\n   https://github.com/hadley/devtools/archive/master.zip\n. One more thing: the 403 error from api.github.com doesn't happen when you use a browser, but it will happen when downloading via httr:\n```\n\nlibrary(httr)\nGET('https://api.github.com/repos/hadley/devtools/zipball/master')\nResponse [https://api.github.com/repos/hadley/devtools/zipball/master]\n  Status: 403\n  Content-type: application/octet-stream\n{\"message\":\"Missing or invalid User Agent string. See http://developer.github.com/v3/#user-agent-required\"} \n``\n. As a temporary workaround, runninglibrary(digest)will allow it to work.\n. For cases like this, I've used this script which I've namedRD` to start up R-devel (you'll need to tweak the path for your installation):\n\n``` bash\n!/bin/bash\nMay need to set R_LIBS_SITE\nexport R_LIBS_SITE=${R_LIBS_SITE-'/usr/lib/R-devel/lib/R/library:/usr/local/lib/R/site-library:/usr/lib/R/site-library::/usr/lib/R/library'}\nexport PATH=\"/usr/local/lib/R-devel/bin:$PATH\"\nR \"$@\"\n```\nThen if you use devtools to run check(), when it calls R to run checks, it will start up R-devel. You can check this by running the following from your R session:\nsystem(\"R -e 'version'\")\n. For test cases, there needs to be at the very least a detailed description of what should happen. For example, some thing like \"when an error happens and traceback() is run, line numbers are printed\", or \"when R prints out the definition of a function in a package, the original formatting is preserved.\"\n. This happens on because, after loading devtools, the devtools.dll file is open and, in Windows, can't be overwritten.\nThe workaround I've used is to clone the devtools repo, then install from source in a clean R session:\n```\nGo to devtools' parent directory\nsetwd('C:/somedir/')\ninstall.packages('devtools', type='source', repos=NULL)\n``\n. If the ability to pass args tosystem2is added, I'd suggest using named arguments instead of...`.\nAlso, would this need to be implemented for other install commands?\n. General style notes, for consistency:\n- Should have space after if, and before opening {.\n- Should have spaces between else and surrounding brackets.\n- Indents should be two spaces.\nInstead of oopts, I would also suggest using oop, to be consistent with the source_many function above.\n. Actually, is it necessary to call options(keep.source = TRUE) from source_one(? I ask because that option is also set from the source_many() function.\n. (For future reference, this pull request was related to #319)\nIn R 2.15.3, the keep.source doesn't do anything, when srcfile is specified. See: https://github.com/wch/r-source/blob/tags/R-2-15-3/src/library/base/R/parse.R\nWith R trunk, the way that source_one() calls parse(), it should never use the keep.source argument, since text is not NULL, and srcfile is not missing. Even if it did need to look at keep.source, it should get that value via getOption('keep.source'). See https://github.com/wch/r-source/blob/tags/R-2-15-3/src/library/base/R/parse.R. So commit 40d822986e081df6d33375d6bba9e988e31af11c had no effect. (Note that I've reverted that commit)\nI think what we need to fix this issue is a clear test case: not necessarily a formal test, but at the very least some code illustrates what exactly the problem is.\n. Thanks for the diagnosis. A reproducible example would be very helpful.\n. Sorry, we've been focusing on other projects for the last few months but we'll take a look when we can.\n. Looks good! I have some comments inline.\n. Excellent, thanks!\n. Does the same thing happen when you run this from a command shell?\n```\nFirst, cd to the parent directory of the package\nR CMD build packagename\n``\n. My guess is that the problem is somewhere in thetar` function, when it does assignment with an indexed range of values on the left side, like: https://github.com/wch/r-source/blob/trunk/src/library/utils/R/tar.R#L465\nAs to why that's happening, I can only guess. Maybe there are weird characters in the file path, or weird characters in your username? If that's not it, maybe try starting with a near-empty package and add files one by one until you get the error? And if you can isolate one file, try modifying it until the error goes away -- for example, remove all the content, add some back, etc.\n. One more thing you can try if you're familiar with debugging in R is to do the following:\n```\noptions(warn=2)\noptions(error=recover)\nI think this does the same as R CMD build\ntools:::.build_packages('mypackage')\n```\nThen you can find out where it's breaking.\nIf that doesn't quite do it, you can also try:\ndebug(tar)\nAnd then build.\n. Interesting - I wonder why it thinks the uid of eia is such a large number. Are you using some sort of network login system like NIS?\nWhen you run uid from the unix shell, does it give you that same number? (If you're not the eia user, you may have to run uid eia).\nThis does sound like a bug in R's handling of large user id values - but I am curious how you got such a large number.\n. Oops, sorry, the command is id, not uid. But it sounds like you have it figured out anyway!\n. Thanks!\n. Are you using the latest version of devtools from github? I believe this was fixed in 4845477a9705c56e13c03b357a0746af358f604e.\nAlso see https://github.com/hadley/devtools/pull/331#issuecomment-21258838\n. Yup, the head of the master branch should be OK to use (although that's not always true!).\n. Glad it works!\n. Strange, those errors involve the whisker package.\nWhat do you get when you run these commands?\npackageVersion('whisker')\npackageVersion('devtools')\nThe output of sessionInfo() would also be useful.\n. What if you do library(whisker)? If you have a problem with that, then it's possible that your installation of whisker is corrupted.\n. That sounds reasonable to me.\n. Some of the vignette tests just won't work in 2.15. Is it OK to just disable those tests for 2.15?\n. I've been looking at this more, There are a number of things that are different in 3.0 from 2.15, including new arguments to pkgVignettes(), file generating behavior, markdown support, etc.\nI'm starting to think that the best course of action is to just disable the vignette stuff and tests for < 3.0, and tell people to not use the vignette features in 2.15. Then devtools can still be used in 2.15 for installing and loading packages and other stuff like that.\n. Are you using the latest github version of devtools? \n. Also, see #360 before merging this one.\n. The return value from installing two packages is something like this:\n```\n[[1]]\nhttps://github.com/rstudio/shiny/archive/master.zip \n                                               TRUE \n[[2]]\nhttps://github.com/hadley/lineprof/archive/master.zip \n                                                 TRUE \n```\nDoes it matter enough to use vapply instead of lapply (or to unlist the return value)?\n. It's already invisible; I'll make it use vapply.\n. Fixed. Now it returns a named vector:\nrstudio/shiny hadley/lineprof \n           TRUE            TRUE\n. @hadley This was implemented for install_xx functions which use install_url, but not for install.\nEdit: And it would also be useful to record the SHA1 with load_all.\n. Yup, it's fixed in the dev version.\n. A couple comments:\n- I think it would be useful to give an error if a string is invalid\n- I like that there are tests for the parsing!\n. If I understand correctly, you want to put in a temporary replacement version of github_pull_info, because it's called by another function. Here's an idea for how to do this:\n- Create a new environment as a child of the namespace\n- Copy the function(s) to be tested into the new environment, and set their environment to the new environment.\n- Define the mock function (github_pull_info) in that environment\n- Call the functions that you want to test\nThere are some limitations of doing it this way. If you want to call the mock function indirectly (via another function that's not copied to the new environment), it won't work right. To get around this issue, you could copy over everything from the namespace into the new environment, and simply replace the mocked function, but this could be slow if you're running a lot of tests.\nAll of this is overkill for this one test, but it's a way you could do mocking in general.\n. I think the TRUE/FALSE/NA values aren't very intuitive. An alternative is to change dependencies to a string argument, and you could deprecate the TRUE/FALSE values.\n. One problem with running document() as part of the install_github() process is that the resulting .Rd files are not fully determined by the contents of the package source. They can depend on external packages, for example:\n- If you use @inheritParams from something from a different package, the version of that package matters. Sometimes documentation changes between versions. (This is an issue I've encountered in the past.)\n- The output .Rd files depend on the version of roxygen2.\nOn one hand, you might think this is good, because these changes to external packages don't result in \"extra\" commits to your package's source code. But on the other hand, there's a big problem: if you are releasing a package to CRAN, there's no commit that corresponds to the exact contents of what's built and sent to CRAN, because what's sent depends on both the source code and the R ecosystem on your computer.\n. This issue and #523 are starting to make me think that maybe we should offer this as an option...\nI've also realized that another possible end-user issue is that, when re-documenting, the entries in NAMESPACE can depend on which packages are currently loaded. This is something I've seen with S3 methods and generics.\n. With the new version of roxygen2, by default no Collate field is created, so the files will be loaded in alphabetical order - and this probably is different than the order you previously had in the Collate field. If you want files to show in the Collate field, you need to add an @include directive to specify that some file will be included before the current one. Then when you run document(), the Collate field will be added, with the files listed in an order such that the included file comes before the one that includes it.\nFor example, see: https://github.com/hadley/ggplot2/blob/master/R/annotation-custom.r#L1\n. Doug, no problem, glad you have it figured out!\n. Ug, after grinding away at this for a while, I think this is all due to bugs in R's S4 implementation. Even simply loading and unloading some packages with S4 or ref classes results in errors. For example:\n```\ninstall.packages('shiny') # Install from CRAN\nlibrary(shiny)\nunloadNamespace('shiny')\nThere were 50 or more warnings (use warnings() to see the first 50)\ninstall.packages('lubridate') # Install from CRAN\nlibrary(lubridate)\nunloadNamespace('lubridate')\nWarning messages:\n1: In FUN(X[[2L]], ...) :\nCreated a package name, \u20182013-12-18 21:43:02\u2019, when none found\n2: In FUN(X[[2L]], ...) :\nCreated a package name, \u20182013-12-18 21:43:02\u2019, when none found\n...\nlibrary(sp)\nunloadNamespace('sp')\nWarning messages:\n1: In FUN(X[[2L]], ...) :\nCreated a package name, \u20182013-12-18 22:02:16\u2019, when none found\n...\n```\nThese errors happen in cacheMetaData() -> .removeSuperclassBackRefs() -> findClass().\nSome packages with S4 don't seem to have problems, though, such as the Matrix package.\n. Apparently the issue is fixed in R 3.0.2-patched and will be out in the next release.\nhttp://r.789695.n4.nabble.com/Strange-warnings-when-unloading-packages-with-S4-classes-td4682489.html\nhttps://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15481\n. There is a call to parse.file in document.r, but it shouldn't reach that code if you have version >= 3 of roxygen2. Can you include the output of sessionInfo()?\n. What does it return when you run getOption(\"unzip\")?\n. Strange that it's \"\". On the Linux machine I have, here's what I get:\n```\n\ngetOption('unzip')\n[1] \"internal\"\n```\n\nWhat distribution of Linux are you using, and did do anything unusual, such as compile R yourself?\n. It's probably best not to put it in your package, since it may unexpectedly change the state of the option for other users. This may be helpful: http://stackoverflow.com/questions/20408250/default-options-setting-for-unzip\n. Works fine for me with 1.4.1. Are you sure the URL isn't blocked?\n. I wonder if this has something to do with the User-Agent string that's set here:\nhttps://github.com/hadley/devtools/blob/master/R/run-source.r#L125\nMaybe you have a weird intermediate version of devtools? Can you see if your version of devtools:::find_gist has that User-agent line?\n@hadley, is it possible that the problem is that you have User-agent, but the correct field is User-Agent?\nhttp://developer.github.com/v3/#user-agent-required\n. This looks like a duplicate of #406.\n. I agree that it could be useful to load import packages without attaching them. I think part of the diagnosis here isn't right though - is_loaded (and ns_env) should only check for whether a package is loaded, not whether it's attached.\n. Here's the definition for is_loaded. It checks whether the package is loaded, not attached:\n```\nReports whether a package is loaded into a namespace. It may be\nattached or not attached.\nis_loaded <- function(pkg = \".\") {\n  pkg <- as.package(pkg)\n  pkg$package %in% loadedNamespaces()\n}\n```\nhttps://github.com/hadley/devtools/blob/master/R/namespace-env.r#L308\nFor example:\n```\n\nlibrary(devtools)\nsessionInfo()\nR version 3.0.2 (2013-09-25)\nPlatform: x86_64-apple-darwin10.8.0 (64-bit)\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.4.1\nloaded via a namespace (and not attached):\n[1] digest_0.6.3   evaluate_0.5.1 httr_0.2       memoise_0.1    parallel_3.0.2\n[6] RCurl_1.95-4.1 stringr_0.6.2  tools_3.0.2    whisker_0.3-2 \n\ndevtools:::is_loaded('./stringr')\n[1] TRUE\n```\n\nI don't think there should be any problems with S3 or S4 stuff... it should work if the imported packages are just be loaded with loadNamespace().\n. Oh wait, I think I misunderstood. I thought you wanted to load the imports for the current package without attaching them. But you want to load the current package without attaching it? \nWhat happens when you do something like this?\n```\npkgA is imported by pkgB\nload_all('./pkgA', export_all=F)\ndetach('package:pkgA')\nload_all('./pkgB')\n``\n. It looks like the problem was that it couldn't find the source for the next package, BiocParallel. But the missing package message didn't print out the name of the package with missing source. I've modifiedcheck_cran` to give a more informative message when that happens. Now it says:\nCan't find package source for 3: BiocParallel. Skipping...\n. Sounds good. By the way, you can use revdep_check to figure out the reverse dependencies for you and check them, with revdep_check('BBmisc'). And you can use the ignore argument to not try to check specific packages like BiocParallel.\n. This is closely related to #363, but more general.\n. Does the same error happen when you do it the non-devtools way?\n```\nlibrary(pkgdll)\nlibrary(rjsonioUser)\nrjson(1:10)\ndetach('package:pkgdll', unload=TRUE)\nOr maybe this:\nunloadNamespace('pkgdll')\nlibrary(pkgdll)\nrjson(1:10)\n``\n. I did a bit more investigating of this issue. The reason it doesn't cause a problem withunloadNamespaceordetachis because those don't unload thepkgdll.so` shared library.\nFirst modify pkgdll to have an .onUnload function like this (which is considered good practice; see http://r.789695.n4.nabble.com/Using-onUnload-to-unload-DLLs-td4637562.html):\nR\n.onUnload <- function (libpath) {\n  library.dynam.unload(\"pkgdll\", libpath)\n}\nThen install pkgdll, and run the following. You'll get the same error:\n``` R\nlibrary(devtools)\nlibrary(methods)\ninstall('pkgdll')\nlibrary(pkgdll)\nload_all('rjsonioUser/')\nrjson(1:10)\ncat('######################## after first call\\n')\nunloadNamespace('pkgdll')\nlibrary(pkgdll)\ncat('=============================before call2\\n')\nrjson(1:10)\nError in .Call(\"R_fromJSON\", content, as.integer(sum(simplify)), nullValue,  :\n\"R_fromJSON\" not resolved from current namespace (RJSONIO)\ncat('#############################after call2\\n')\n```\nI suspect it has something to do with R trying to unload a DLL that wasn't the last one loaded. If, after loading the packages, you run .dynLibs(), you'll see that the RJSONIO DLL was loaded after pkgdll.\nIf you want to trace into the problem, you can do: debug(shiny:::library.dynam2) and run your original bug1.R code. Step through this function until it gets to the line:\nR\ndllinfo <- dyn.load(dllfile)\nBefore you run that line, you can do rjson(1:10). After you run that line, you'll get an error.\nIn short, it looks like the problem is some interaction between R and RJSONIO. The reason you don't get it when you do unloadNamespace('pkgdll') is because that won't unload the DLL (unless you add an .onUnload function as I wrote above). Devtools tries harder than unloadNamespace to really unload a DLL, which is why you see the issue when you use devtools.\n. It might have something to do with the accent in the path. Can you try this in another directory that has only ASCII characters?\n. I actually implemented this a while back but forgot to close this issue:\nhttps://github.com/hadley/devtools/blob/c4f1de69d4e8907e52f6fd97b1d887a29776e6c7/R/check-cran.r#L219-L226\n. Though now that the new install code is in, should it use RemoteSha instead of GithubSHA1?\n. OK, done: 7f2f0eb0f5823d62d5626dbf23e84207bcc5d5ea\n. I'm not sure, but it might be possible to remove the devtools non-standard file check. I noticed recently that R CMD check started giving notes or warnings for non-standard files. (I'm not sure if this was with R 3.0.3 or with R-devel.)\n. What version of devtools are you using? Recent versions support syntax like install_github(\"Teradata/teradataR/\").\n. That's strange - I haven't see that before. My guess is that this has something to do with today's release of R 3.1.0.\n. The contents of /inst get copied over to the root of package directory when the package is built and installed. This is the normal behavior for the R package build process.\nSee http://cran.r-project.org/doc/manuals/R-exts.html#Package-subdirectories\n. I'd personally like a function that updates all packages, from Github, CRAN, and whatever else. I use a couple different machines for my work and it would be nice to be able to quickly update all my packages.\nOne possible issue with updating github packages is that the user may have asked for a particular, branch, tag, or commit. If they asked for a branch, it makes sense to update to the latest version of the branch (including master); if they asked for a tag or commit, it makes sense to stay at that tag, with perhaps a status message saying so. But I don't think the metadata we keep right now is rich enough to support that.\n. Oh, you're right the GithubRef field should do the trick.\n. @hadley We could put the rstudioapi in imports, but I think it shouldn't be hard to structure the code to avoid attempts to load rstudioapi.\n@klmr Can you include a traceback for the error? I'm curious to see where it's trying to load the package.\n. @hadley OK, that makes sense.\n@klmr Thanks, my version was slightly outdated so I didn't have that code path.\n. Regarding the paths with library.dynam, devtools needed a customized version of it because of the differences in paths between source and installed packages. See: https://github.com/hadley/devtools/blob/master/R/load-dll.r#L54 and https://github.com/hadley/devtools/blob/master/R/load-dll.r#L21\n. I think I fixed the tests already - it looks like Travis may be testing a different commit? It says it's testing 9a23c55, but that's not in the commit history. I had force-pushed a commit, so maybe that's why it's confused.\n. Yeah, looks like I have a couple things to fix related to the help. Tests pass with test(), but not with check().\n. I've fixed the issues with help docs on master, and rebased this branch.\n. Thanks for the report! R treats ??foo as `?(?(foo))`, so it just needed a check for that special case, but this check needs to happen before it decides to evaluate the inner expression.\n. Hm, seems to be working. Maybe I was typing it wrong.\n(The feature/mask-reactive-context branch has been merged and deleted since I filed this issue, so that's not suitable for testing anymore.)\n. What I had in mind wasn't to download the zip file from a hard-coded URL at api.github.com, but to query the API to find the download URL of the zip file. This is because the API query URLs should be stable over time, but the zip file links aren't necessarily so. (It's not clear to me whether the zip file URLs you're using at api.github.com will be stable over time or not.)\nFor example, if you visit the releases API page at https://api.github.com/repos/hadley/devtools/releases, there's an entry zipball_url, which tells you where the zip file is. Unfortunately, I wasn't able to find a similar entry in a regular branch API page: https://api.github.com/repos/hadley/devtools/branches/master.\nIt looks like you've used similar zip URLs as the ones pointed to from the API pages - I'm just not sure if they're going to be more stable than the current zip URLs that we're using.\n. Oh, great, I didn't realize it was in the docs.\n. Have you tried reinstalling RCurl? And what happens when you just run library(RCurl)?\n. I believe this has already been fixed in the development version of devtools:\nhttps://github.com/hadley/devtools/blob/master/R/check.r#L159\nCan you try again with the latest development version?\n. You also need Rtools: http://cran.r-project.org/bin/windows/Rtools/\nWhat does it say when you run devtools::has_devel()?\n. @adrtod I see you fixed the problem in this PR, in #514. I suggest making the same change on this branch and pushing it so that the fix is in this pull request. This should fix the failing test.\n. I think you'll also have to use overwrite=TRUE in order for it to work.\nThough now that I look at it, I don't see why the DLL needs to be copied over at all. In the process of installing the package, the DLL is created in the src/ directory already, so the file.copy just overwrites the file, with the newly-installed copy of itself.\n. @kevinushey The required R version for devtools is 3.0.2, so I think the check isn't necessary.\n. Thanks!\n. OK, I changed it to a function called session_info.\n. Oh, I think made a mistake - I thought that create() was adding both the Authors@R and the Maintainer fields, but I must have added in the Maintainer myself in a package I was working on.\n. Thanks!\n. I think this is fixed in the dev version. Can you test that?\n. Should have been fixed with b612d9a.\n. IIRC, the installer code assumes that there's a subdirectory with the package contents. Perhaps it would be helpful to have better documentation, or an error message that explains the issue.\n. It seems reasonable to me check to see if a subdir contains a package (using the current method), and if not, check if the top level directory contains a package.\n@hadley, @jmcphers What do you think?\n. What version of devtools are you using?\n. I think you need the latest version of devtools from github. The 1.5 release was before the bug was fixed.\n. Installing the github version didn't work -- you re-installed the CRAN version.\nDid you use the build_github_devtools function from the README?\n. Sorry, you'll also need to do install.packages('rstudioapi') (from CRAN) - that package dependency was added since 1.5.\n. After devtools::build_github_devtools(), you have to restart R and run:\n``` R\nRestart R before continuing\ninstall.packages(\"devtools.zip\", repos = NULL)\n``\n. I'd be reluctant to exportmakeNamespace`, since that would be one more thing that devtools would have to support in the long run. What are you using these virtual namespaces for?\nIt's been in the back of my mind how to extract these internal R functions in such a way that devtools has the right version of these functions on whatever version of R it's running on. Here's what I came up with -- this function will find an assignment to a variable within a quoted expression.\n``` R\nextract_def <- function(x, pattern = NULL) {\n  if (is.call(x)) {\n    pieces <- as.list(x)\n# Is this call object an assigment for the search pattern?\nif (identical(pieces[[1]], quote(`<-`)) &&\n    identical(pieces[[2]], pattern)) {\n  return(pieces[[3]])\n}\n\n# Recursively search for the pattern\nres <- lapply(pieces, extract_def, pattern)\n\n# Drop all NULLs from res\nres <- res[!vapply(res, is.null, logical(1))]\n# If found any non-NULLs, return the first one\nif (length(res) > 0) {\n  return(res[[1]])\n}\n\n}\nNULL\n}\n```\nIn use:\n``` R\nfoo <- function(x=1, y=1) {\n  if (z > 10) {\n    bar <- function() 40\n  }\n  20\n}\nextract_def(body(foo), quote(bar))\nfunction() 40\n```\nAnd this is what you really want:\n``` R\nextract_def(body(base::loadNamespace), quote(makeNamespace))\nfunction(name, version = NULL, lib = NULL) {\nimpenv <- new.env(parent = .BaseNamespaceEnv, hash = TRUE)\nattr(impenv, \"name\") <- paste(\"imports\", name, sep = \":\")\nenv <- new.env(parent = impenv, hash = TRUE)\nname <- as.character(as.name(name))\nversion <- as.character(version)\ninfo <- new.env(hash = TRUE, parent = baseenv())\nassign(\".NAMESPACE.\", info, envir = env)\nassign(\"spec\", c(name = name, version = version), envir = info)\nsetNamespaceInfo(env, \"exports\", new.env(hash = TRUE, parent = baseenv()))\ndimpenv <- new.env(parent = baseenv(), hash = TRUE)\nattr(dimpenv, \"name\") <- paste(\"lazydata\", name, sep = \":\")\nsetNamespaceInfo(env, \"lazydata\", dimpenv)\nsetNamespaceInfo(env, \"imports\", list(base = TRUE))\nsetNamespaceInfo(env, \"path\", normalizePath(file.path(lib,\nname), \"/\", TRUE))\nsetNamespaceInfo(env, \"dynlibs\", NULL)\nsetNamespaceInfo(env, \"S3methods\", matrix(NA_character_,\n0L, 3L))\nassign(\".S3MethodsTable.\", new.env(hash = TRUE, parent = baseenv()),\nenvir = env)\n.Internal(registerNamespace(name, env))\nenv\n}\n```\nSo this is a way to get the makeNamespace function without needing any other packages, and without putting the code directly in your package. devtools itself should probably do it this way.\n. The only purpose of the register_namespace function is to avoid the .Internal() call, which R CMD check doesn't like. That's also the reason that \"namespace\" package was created.\nI'm not 100% sure that extracting makeNamespace with the technique above will give a result that passes R CMD check -- it depends on at which stage of building that R CMD check searches the code for .Internal().\nHave you considered just storing sessions in a simple environment? makeNamespace adds some extra stuff that probably isn't necessary for your use case. Of course, with a simple environment you don't get to access it with ::, but you could provide a simple accessor function.\nAnother possibility is to strip out the unnecessary stuff out of makeNamespace, but in a way that x0af73b37c::foo still works. You might be able to get away with just creating an environment and registering it as a namespace.\n. You need to do install.packages('rstudioapi').\nAfter the next version of devtools is released to CRAN, hopefully we won't see this issue come up again because that package will have already been installed.\n. Implemented in 6ef209c.\n. If :: is too slow for your use case, you can use $ instead, although you'll have to retrieve the relevant package's environment first. For example:\n``` R\nlibrary(microbenchmark)\nCall this somewhere in your package's code\nbase <- as.environment('package:base')\nmicrobenchmark(\n  identity(1),\n  base::identity(1),\n  base$identity(1),\n  as.environment('package:base')$identity(1)\n)\nUnit: nanoseconds\nexpr  min     lq median     uq   max neval\nidentity(1)  222  255.0  287.5  354.5   889   100\nbase::identity(1) 5203 5829.5 6274.0 6731.5 66757   100\nbase$identity(1)  503  583.0  676.0  780.0 16143   100\nas.environment(\"package:base\")$identity(1)  556  667.0  766.5  840.5  2845   100\n```\nReading that SO post, it seems that you're also concerned with using namespacing when calling your own package's code. You may be able to solve that by putting this in your package's code:\n``` R\nmypackage <- environment()\nTo call mypackage::foo from a function in the package:\nf <- function() {\n  mypackage$foo()\n}\n```\n. @hadley, I agree with @adrtod that it removes code that had no effect. Do you remember what the original purpose of that code was?\nThis is where you originally added the file copying:\nhttps://github.com/hadley/devtools/commit/5a9afe8a89ea04af0b051087a091d0c7725fe00d#diff-89f3f094e2cd17061c71776c560350d3R46\nAnd where you changed it to use \"inst\":\nhttps://github.com/hadley/devtools/commit/cff54de70d25e70eb2082eb252a70bf3795f1ad1#diff-89f3f094e2cd17061c71776c560350d3R37\n. Thanks!\n. In RStudio, If I load_all a different package (not devtools) and then do ?\"?\", nothing comes up in the RStudio help pane.\nBut if I do the same thing in a terminal, it seems to work:\n```\n\ndevtools::load_all()\nLoading shiny\n?\"?\"\nHelp on topic \u2018?\u2019 was found in the following packages:\n\nPackage               Library\n  devtools              /home/winston/R/3.1\n  utils                 /usr/lib/R/library\nChoose one \n1: Drop-in replacements for help and ? functions {devtools}\n2: Documentation Shortcuts {utils}\nSelection: \n```\n. Looks like it's not just in RStudio. It also happens when you use web help from the terminal.\noptions(help_type = \"html\")\n?\"?\"\nThis results in a browser going to http://127.0.0.1:10178/library/NULL/help/? , and it displays:\nError in as.name(topic) : attempt to use zero-length variable name\n. With debug(?) and debug(utils::?), I found that it eventually calls help(\"?\", package = NULL).\nIf you run that command in a clean R session without loading a package, the help page shows up just fine.\nBut if you do options(help_type = \"html\") and load_all() on a (non-devtools) package, then when you run help(\"?\", package = NULL), you get that error. Also, utils::help(\"?\") gives the same error. However, utils::help(\"?\", package = \"utils\") gives the correct help page.\n. In a clean R session with HTML help on, the URL for ?\"?\" is http://127.0.0.1:15456/library/utils/html/Question.html.\nBut after doing a load_all(), the URL is http://127.0.0.1:10178/library/NULL/help/? , and I don't think this is a valid help URL.\nThe different URL is because, after the load_all, doing ?\"?\" returns an object with multiple file paths:\n```\n\nx <- help(\"?\", package = NULL)\nstr(x)\nClass 'help_files_with_topic'  atomic [1:2] /Users/winston/R/3.1/devtools/help/help /Library/Frameworks/R.framework/Versions/3.1/Resources/library/utils/help/Question\n  ..- attr(, \"call\")= language utils::help(topic = ?, package = NULL)\n  ..- attr(, \"topic\")= chr \"?\"\n  ..- attr(, \"tried_all_packages\")= logi FALSE\n  ..- attr(, \"type\")= chr \"html\"\n```\n\nWhen there are multiple paths, utils::help goes down this code path instead of this one.\nI think the only reasonable solution is to special-case the devtools shim_help so that it recognizes when ?\"?\" is called and in that case does help(\"?\", package = \"utils\").\n. The special casing would involve adding something like this near the end of shim_help:\nR\n  else if (identical(e1_str, \"?\")) {\n    utils::help(\"?\", package = \"utils\")\n  }\n. A little more info: the real problem is that is that the URL isn't being escaped properly by utils:::print.help_files_with_topic. Instead of http://127.0.0.1:13958/library/NULL/help/%3F, it's going to http://127.0.0.1:13958/library/NULL/help/?.\nSort of fixing utils:::print.help_files_with_topic, it's possible to modify the help object so that it has the correct topic for html help, by escaping the ?:\n``` R\nload a non-devtools package\nload_all('../shiny')\noptions(help_type = \"html\")\nz <- help(\"?\", package = NULL)\nstr(z)\nClass 'help_files_with_topic'  atomic [1:2] /Users/winston/R/3.1/devtools/help/help /Library/Frameworks/R.framework/Versions/3.1/Resources/library/utils/help/Question\n..- attr(*, \"call\")= language utils::help(topic = ?, package = NULL)\n..- attr(*, \"topic\")= chr \"?\"\n..- attr(*, \"tried_all_packages\")= logi FALSE\n..- attr(*, \"type\")= chr \"html\"\nif (attr(z, \"type\") == \"html\") {\n  # escape the ?\n  attr(z, \"topic\") <- \"%3F\"\n}\nz\n```\n. Filed a bug report for R: https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16173\n. Looks like it's fixed in R-devel:  wch/r-source@3bf09244e8b422ab58a3413cf8736686d296b554\n. This is a real-life example of a classic visual illusion!\nhttp://www.moillusions.com/test-sharp-minded/\nhttp://planetperplex.com/en/item/a-bird/\n. Are you using the latest development version of devtools?\n. The sprintf() could also print out the commands directly, instead of using env vars. The one danger with that is if, say, the cd fails, you might end up copying files to the wrong place. So it's probably better to use full path names everywhere.\nAnother possibility is to do the copying in R, then leave just the git commands for the terminal.\n. I'd prefer to keep things as is -- this proposal sounds a little too magical, and it's for a uncommon use case (I think most people run it in the top directory of a package). You could easily write wrappers that do exactly what you're describing though.\n. That is a good point...\n. Thanks!\n. Have you tried updating to the most recent roxygen2?\n. Did you try restarting R before running install_github? The lazy-load database error sometimes happens when you try to reinstall a package that is loaded in your R session.\n. Also, I just took a look at your repository, and you've checked in *.o files in src/, which you shouldn't do, since those are compiled objects.\n. I suspect this is a problem with calling unzip. What do you get when you run getOption(\"unzip\")?\n. I think this will help: #406.\n. Are you using the version of devtools that lets you call test() and other functions from any subdirectory, and is your current working directory the R/ subdirectory? I believe devtools::test() just runs in the current working dir.\n. Are you sure you want to add another dependency (rvest, and its deps) to devtools?\n. Could you also include the output of devtools::session_info()? Also, even though it is very simple, having the example package on GitHub would be helpful.\n. Thanks, that's helpful. This is giving me flashbacks to previous efforts to work with S4 in devtools...\nAt any rate, I think this is the result of a bug in R's S4 code.\nHere's what happen when we load the package.\n``` R\nInstall\ndevtools::install_github('jayweiler/testError')\nRestart R before continuing\nlibrary(testError)\ngetClassDef('DateOrLogical')\nExtended class definition ( \"ClassUnionRepresentation\" )\nVirtual Class \"DateOrLogical\" [package \"testError\"]\n\nNo Slots, prototype of class \"S4\"\n\nKnown Subclasses: \"Date\", \"logical\"\ngetClassDef('logical')\nClass \"logical\" [package \"methods\"]\n\nNo Slots, prototype of class \"logical\"\n\nExtends: \"vector\", \"DataFrameOrLogical\", \"DateOrLogical\"\n```\nSo far, so good. DateOrLogical thinks it's a virtual superclass of logical, and logical thinks it's a subclass of DateOrLogical.\nUnloading the package should remove the DateOrLogical class and logical's reference to it. But the latter doesn't occur:\n``` R\nunloadNamespace('testError')\ngetClassDef('DateOrLogical')\nNULL\ngetClassDef('logical')\nClass \"logical\" [package \"methods\"]\n\nNo Slots, prototype of class \"logical\"\n\nExtends: \"vector\", \"DataFrameOrLogical\", \"DateOrLogical\"\n```\nI'd suggest reporting this to the R-devel mailing list.\nAlso, your test repository includes the .Rproj.user directory -- I'd suggest removing it and doing a git commit --amend, then git push -f.\n. I think with(as.environment(\"package:httr\"), GET(url)) won't work as expected, since it won't be able to find the url variable in the httr package environment.\n. Here's an example that illustrates the problem. It needs to be in a function to more closely simulate code running in a package; if you run it at the console, the behavior will be different because the global environment is in the search path of the httr namespace.\n``` R\nfoo <- function() {\n  x <- 10\n  with(asNamespace(\"httr\"), print(x))\n}\nfoo()\nError in print(x) : object 'x' not found\nIf you use as.environment('package:httr'), you get a different error when httr isn't\nalready attached\nfoo2 <- function() {\n  x <- 10\n  with(as.environment(\"package:httr\"), print(x))\n}\nfoo2()\nError in as.environment(\"package:httr\") :\nno item called \"package:httr\" on the search list\n```\nI can't think of a good way in general to accomplish what's being asked for -- as far as I can tell, this requires manipulating the search path.\n. Good idea - I've made the change.\n. I wonder if there's some encoding issue. Can you paste the output of sessionInfo()?\n. Does it happen when you run it in the regular Windows R GUI (not RStudio)?\nAnd what is the output of Encoding(\"text\")? If you can also run it again, replacing \"text\" with the name of your home directory, including the accented character, that would be helpful.\n. @hadley I suspect this doesn't fix the root problem. I experimented a bit with the problem, and I think even if you try this on Windows, it fails when the path contains a non-ASCII character:\nR\nsystem('R --vanilla CMD INSTALL /path/to/package')\n(Note that this is from memory; I haven't looked at it in a few weeks.) If this is right, then I don't think there's a good way to solve the issue.\n. Oh, maybe you're right. It's hard to believe that resorting to 8.3 filenames is still the solution to filename troubles in Windows!\n. I think you also need -d, as in git clean -nxd so that if there are any subdirs, they'll be listed as well. \nFor example:\n``` R\n$ git clean -n\nWould remove shiny.sublime-project\nWould remove test.R\n$ git clean -nx\nWould remove .Rhistory\nWould remove shiny.sublime-project\nWould remove test.R\n$ git clean -nxd\nWould remove .Rhistory\nWould remove .Rproj.user/\nWould remove shiny.sublime-project\nWould skip repository temp/progress\nWould remove temp/app\nWould remove test.R\nWould remove tools/node_modules/\n``\n. Maybe agit fetch` and then compare SHAs for HEAD and the tracking branch?\nOr maybe parse the output of git branch -vv, as suggested at http://stackoverflow.com/a/12538667/412655\n$ git branch -vv\n* master cd0a739 [origin/master: ahead 1] Update license information\n. There are four different stages of package building:\n1. \"True\" sources (no generated files)\n2. True sources plus generated files. This can be given to R CMD build. It can also be installed with devtools::install.\n3. An R source package. This can be installed with R CMD install or install.packages(type = \"source\").\n4. An R binary package. This can be installed with R CMD install or install.packages().\nThe devtools workflow is to check in stage 2 to the repo, but @gaborcsardi, you (and others) would like to check in stage 1.\nMaybe someone (you?) could outline a workflow for that? I suspect that in order to get from stage 1 to 2 in a repeatable manner, another file with build metadata (e.g., versions of other packages to build with) would be needed. Perhaps an automated build system would be useful - when a stage 1 commit is checked in, you could build a stage 2 package and push it on a branch or maybe a different repo. If there is code to do all this, it might belong in a separate package.\n. The downloader package is meant to make it possible to download via https on the various platforms. But this isn't enough to remove the httr dependency from devtools. In devtools, httr is used for more than just downloading files. For example:\nhttps://github.com/hadley/devtools/blob/b064918e42548cdf478a89aee69f6d05960b33d0/R/release.r#L260-L266\n. I think this may already be fixed in the latest dev version of devtools.\n. That is the right version - I thought it might have been fixed along with #676, but apparently not.\nI think in addition to the normalizePath that was added, it might also need shQuote.\n. The development version of R has this check built in. That's where the CRAN maintainers are seeing it -- they check your package on the release and development version of R.\nIf you run check() on R-devel, you'll see this warning. Also, if you run build_win() on your package before submitting it to CRAN, it will automatically run R CMD check on R-devel and send you the results.\n. I agree with the principle that load_all does one thing, and document does another.\nHowever, if #649 were reverted, then bug #623 would come back. That is, it wouldn't even be possible to run document on packages that need the Collate field to be updated. So we'd need some other solution to that issue.\n. Very nice! How about also updating the template in inst/templates?\n. Hi, the right place to ask this is the shiny-discuss list. Stack Overflow is another good resource for this kind of question.\n. Does your package have a function called setNames? Since stats isn't listed as an import for devtools, I guess it would make sense that this would happen if you have another function named setNames that's on the search path.\n. I agree that it should be fixed. I suspect there are also lots of functions from utils that are called without explicit namespacing.\n. The parent environment of a package namespace is its imports environment, which contains imported objects listed in the package's NAMESPACE file. The parent of that is the base namespace, and the parent of that is the global environment.\nFrom there, you have the usual search path, of package environments for packages that are attached. You can look at this with pryr::parenvs(). In this case, it'll show all the ancestor environments of the devtools namespace:\n```\n\npryr::parenvs(e = asNamespace(\"devtools\"), all = TRUE)\n   label                             name             \n1   \"\"               \n2          \"imports:devtools\" \n3       \"\"               \n4          \"\"               \n5          \"tools:rstudio\"  \n6        \"package:stats\"  \n7     \"package:graphics\" \n8    \"package:grDevices\"\n9        \"package:utils\"  \n10    \"package:datasets\" \n11         \"custom\"         \n12     \"package:methods\"\n13         \"Autoloads\"      \n14                \"\"               \n15          \"\"               \n```\n\n@Geoff99 is right that it would be safer to import objects from stats or use :: -- it would be safest not to rely on the search path (i.e., attached packages) to find functions.\n. install_github and install_git work in different ways: install_github downloads a zip file from github, while install_git does a git clone --depth=1.\nAs for the difference between the git:// and the git@github.com repo addresses, the latter uses ssh, so my guess is that you have some sort of ssh issue on Windows. Have you tried doing a git clone of the ssh address from the command line in Windows? Something like:\ngit clone git@github.com:hadley/memoise.git\n. That does make sense. Although if it's git that's hanging, there's not much that devtools can do about it.\n. I think this would be a useful feature to include. Why did you rename the arg from subdir to svn_subdir ? (Also I think the documentation wasn't updated for that change.)\n. Oh, OK, that makes sense. I think that even though the change might be backward incompatible, it's a rare enough case that you don't need to worry about.\n. The reason it returns inst/ is because that's where files that system.file() looks for are most likely to be.   For example, if someone does file.path(system.file(package=\"foo\"), \"myfile\"), the current method works better.\nThe directory structure of an in-development package is different from the directory structure of an installed package, and we decided this was the best heuristic to use.\nSee the source for more info: https://github.com/hadley/devtools/blob/master/R/shims.r#L27-L96\n. To clarify a bit: files from inst/ in the package sources get copied to the top level of the installed package, and that's why shim_system.file() returns the inst/ directory by default.\n. Rtools isn't an R package - it's a a set of tools for Windows.\nhttp://cran.r-project.org/bin/windows/Rtools/\n. It feels unsafe to me to be replacing objects in base packages. A less invasive way would be to attach a new environment as the parent of the global env, with these things in it. Even that feels a bit weird... but if you were to go about it, you could do it like:\nR\nshims <- new.env()\nbase::attach(shims, name = \"devtools_shims\", warn.conflicts = FALSE)\nAlso, is the C code supposed to be part of this PR?\n. I think this would be fixed by #734.\n. Win-builder simply uses the maintainer's email address, so this would require modification to the DESCRIPTION file before uploading.\nI do agree that in general that something like this would be useful - perhaps a confirmation prompt that says  \"message will be sent to person@foo.com\", before uploading the package?\n. @moorepants devtools imports xml2, which needs R 3.1.0 or higher. It's not the fault of devtools that Ubuntu 14.04 includes a somewhat old version of R (3.0.2).\nSo it's not an R bug, and it's not a devtools bug. It's just that Ubuntu's default version of R is out of date.\n. I disagree that it's a devtools bug, and I didn't say it was a Ubuntu bug. It's not a bug.\nRecent versions of R are available for Ubuntu. This link is to the CRAN apt repository which provides newer versions of R: https://cran.r-project.org/bin/linux/ubuntu/\nI don't think it's reasonable to expect all R packages to support whatever version of R is supplied by the Ubuntu LTS release (not to mention the previous one).\nAll that said, it's probable that the xml2 package would work on R 3.0 without any modifcation. But that's an issue to take up in the xml2 repo.\n. This should install the latest version of R on a Ubuntu system:\nsudo echo \"deb http://cran.rstudio.com/bin/linux/ubuntu trusty/\" >> /etc/apt/sources.list\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9\nsudo apt-get update\nsudo apt-get install r-base\n. I agree that this behavior is annoying and causes unexpected system changes when I'm debugging stuff. Maybe make it opt-in?\n. Can you clarify a bit? I'm not sure exactly what you mean.\n. I'm not necessarily opposed to this, but have you seen any problems arise from the commonly-used pattern?\n. @AnnePetersen1 it's very helpful that you have two similar systems. Can you do the following on each, in a clean R session, and the paste the results? I'm wondering if there's some encoding issue. Also, if you could run it in RStudio as well as the regular RGui and see if there are any differences, that would help too.\n``` R\nlibrary(devtools)\ndebug(system)\ninstall()\nShould be at the Browser prompt now\ncommand\nEncoding(command)\ndput(charToRaw(command))\n```\nThe output should look something like this:\n```\n\nlibrary(devtools)\ndebug(system)\ninstall()\nInstalling R6\n'/usr/lib/R/bin/R' --no-site-file --no-environ --no-save --no-restore --quiet  \\\n  CMD INSTALL '/home/winston/R6' --library='/home/winston/R/3.3'  \\\n  --install-tests \n\ndebugging in: system(full, intern = quiet, ignore.stderr = quiet, ...)\ndebug: {\n    if (!missing(show.output.on.console) || !missing(minimized) || \n        !missing(invisible)) \n        message(\"arguments 'show.output.on.console', 'minimized' and 'invisible' are for Windows only\")\n    if (!is.logical(intern) || is.na(intern)) \n        stop(\"'intern' must be TRUE or FALSE\")\n    if (!is.logical(ignore.stdout) || is.na(ignore.stdout)) \n        stop(\"'ignore.stdout' must be TRUE or FALSE\")\n    if (!is.logical(ignore.stderr) || is.na(ignore.stderr)) \n        stop(\"'ignore.stderr' must be TRUE or FALSE\")\n    if (!is.logical(wait) || is.na(wait)) \n        stop(\"'wait' must be TRUE or FALSE\")\n    if (ignore.stdout) \n        command <- paste(command, \">/dev/null\")\n    if (ignore.stderr) \n        command <- paste(command, \"2>/dev/null\")\n    if (!is.null(input)) {\n        if (!is.character(input)) \n            stop(\"'input' must be a character vector or 'NULL'\")\n        f <- tempfile()\n        on.exit(unlink(f))\n        writeLines(input, f)\n        command <- paste(\"<\", shQuote(f), command)\n    }\n    if (!wait && !intern) \n        command <- paste(command, \"&\")\n    .Internal(system(command, intern))\n}\nBrowse[2]> command\n[1] \"'/usr/lib/R/bin/R' --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL '/home/winston/R6' --library='/home/winston/R/3.3' --install-tests \"\nBrowse[2]> Encoding(command)\n[1] \"unknown\"\nBrowse[2]> dput(charToRaw(command))\nas.raw(c(0x27, 0x2f, 0x75, 0x73, 0x72, 0x2f, 0x6c, 0x69, 0x62, \n0x2f, 0x52, 0x2f, 0x62, 0x69, 0x6e, 0x2f, 0x52, 0x27, 0x20, 0x2d, \n0x2d, 0x6e, 0x6f, 0x2d, 0x73, 0x69, 0x74, 0x65, 0x2d, 0x66, 0x69, \n0x6c, 0x65, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x65, 0x6e, 0x76, \n0x69, 0x72, 0x6f, 0x6e, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x73, \n0x61, 0x76, 0x65, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x72, 0x65, \n0x73, 0x74, 0x6f, 0x72, 0x65, 0x20, 0x2d, 0x2d, 0x71, 0x75, 0x69, \n0x65, 0x74, 0x20, 0x43, 0x4d, 0x44, 0x20, 0x49, 0x4e, 0x53, 0x54, \n0x41, 0x4c, 0x4c, 0x20, 0x27, 0x2f, 0x68, 0x6f, 0x6d, 0x65, 0x2f, \n0x77, 0x69, 0x6e, 0x73, 0x74, 0x6f, 0x6e, 0x2f, 0x52, 0x36, 0x27, \n0x20, 0x2d, 0x2d, 0x6c, 0x69, 0x62, 0x72, 0x61, 0x72, 0x79, 0x3d, \n0x27, 0x2f, 0x68, 0x6f, 0x6d, 0x65, 0x2f, 0x77, 0x69, 0x6e, 0x73, \n0x74, 0x6f, 0x6e, 0x2f, 0x52, 0x2f, 0x33, 0x2e, 0x33, 0x27, 0x20, \n0x2d, 0x2d, 0x69, 0x6e, 0x73, 0x74, 0x61, 0x6c, 0x6c, 0x2d, 0x74, \n0x65, 0x73, 0x74, 0x73, 0x20))\n```\nMy session_info():\n```\n\nsession_info()\nSession info ------------------------------------------------------------------\n setting  value                     \n version  R version 3.3.1 (2016-06-21)\n system   x86_64, linux-gnu         \n ui       X11                       \n language en_US                     \n collate  en_US.UTF-8               \n tz       SystemV/CST6CDT           \n date     2016-10-13                  \n\nPackages ----------------------------------------------------------------------\n package  * version     date       source                        \n devtools * 1.12.0.9000 2016-09-21 Github (hadley/devtools@26c507b)\n digest     0.6.10      2016-08-02 CRAN (R 3.3.1)                \n knitr      1.14        2016-08-13 CRAN (R 3.3.1)                \n memoise    1.0.0       2016-01-29 CRAN (R 3.3.0)                \n withr      1.0.2       2016-06-20 CRAN (R 3.3.1)        \n```\n. It looks like it's not an encoding issue, as I thought it might be.\nOne thing that's different is this:\n- On computer1 (where it works), the command uses the short 8.3 form of the filename, as in \\\"C:/PROGRA~1/R/R-32~1.3/bin/x64/R\\\"\n- On computer 2 (where it doesn't work) the command uses the long form: \\\"C:/Program Files/R/R-3.3.1/bin/x64/R\\\"\nI'm not sure why the long form doesn't work, though. It appears properly quoted. I don't see any strange characters on it, and when I convert the raw vector to a character and pass it to system() on a Windows VM, it works. R runs but it complains that it can't find the package, which is expected since I don't have it:\n``` R\nlongcmd <- rawToChar(as.raw(c(0x22, 0x43, 0x3a, 0x2f, 0x50, 0x72, 0x6f, 0x67, 0x72, 0x61, 0x6d, 0x20, 0x46, 0x69, 0x6c, 0x65, 0x73, 0x2f, 0x52, 0x2f, 0x52, 0x2d, 0x33, 0x2e, 0x33, 0x2e, 0x31, 0x2f, 0x62, 0x69, 0x6e, 0x2f, 0x78, 0x36, 0x34, 0x2f, 0x52, 0x22, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x73, 0x69, 0x74, 0x65, 0x2d, 0x66, 0x69, 0x6c, 0x65, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x65, 0x6e, 0x76, 0x69, 0x72, 0x6f, 0x6e, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x73, 0x61, 0x76, 0x65, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x72, 0x65, 0x73, 0x74, 0x6f, 0x72, 0x65, 0x20, 0x2d, 0x2d, 0x71, 0x75, 0x69, 0x65, 0x74, 0x20, 0x43, 0x4d, 0x44, 0x20, 0x49, 0x4e, 0x53, 0x54, 0x41, 0x4c, 0x4c, 0x20, 0x22, 0x50, 0x3a, 0x2f, 0x41, 0x6c, 0x6b, 0x6f, 0x68, 0x6f, 0x6c, 0x70, 0x72, 0x6f, 0x6a, 0x65, 0x6b, 0x74, 0x2f, 0x52, 0x2f, 0x63, 0x6c, 0x65, 0x61, 0x6e, 0x52, 0x22, 0x20, 0x2d, 0x2d, 0x6c, 0x69, 0x62, 0x72, 0x61, 0x72, 0x79, 0x3d, 0x22, 0x43, 0x3a, 0x2f, 0x50, 0x72, 0x6f, 0x67, 0x72, 0x61, 0x6d, 0x20, 0x46, 0x69, 0x6c, 0x65, 0x73, 0x2f, 0x52, 0x2f, 0x52, 0x2d, 0x33, 0x2e, 0x33, 0x2e, 0x31, 0x2f, 0x6c, 0x69, 0x62, 0x72, 0x61, 0x72, 0x79, 0x22, 0x20, 0x2d, 0x2d, 0x69, 0x6e, 0x73, 0x74, 0x61, 0x6c, 0x6c, 0x2d, 0x74, 0x65, 0x73, 0x74, 0x73, 0x20)))\nlongcmd\n[1] \"\\\"C:/Program Files/R/R-3.3.1/bin/x64/R\\\" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \\\"P:/Alkoholprojekt/R/cleanR\\\" --library=\\\"C:/Program Files/R/R-3.3.1/library\\\" --install-tests \"\nsystem(longcmd)\nWarning: invalid package 'P:/Alkoholprojekt/R/cleanR'\nError: ERROR: no packages specified\nWarning message:\nrunning command '\"C:/Program Files/R/R-3.3.1/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \"P:/Alkoholprojekt/R/cleanR\" --library=\"C:/Program Files/R/R-3.3.1/library\" --install-tests ' had status 1\n```\nWhat happens if you run this on each computer? I would expect this to work on computer 1, but error on computer 2.\nR\nsystem(\"\\\"C:/Program Files/R/R-3.3.1/bin/x64/R\\\" --quiet -e \\\"R.version.string\\\"\")\n\nAt this point I'm just guessing at other possibilities.\nThere are some other odd things I can see on computer 2. For example, some packages were built under R 3.2.5 but you're running R 3.3.1. Sometimes that can cause problems which can be fixed by reinstalling the packages.\nIf any of the base R packages are built under a different version of R than you're running, that could definitely cause problems. The output of this would be helpful:\nR\nsession_info(include_base=TRUE)\nThis is what I get on my Windows VM:\n```\n\nsession_info(include_base=TRUE)\nSession info ---------------------------------------------------------------------------\n setting  value                     \n version  R version 3.3.1 (2016-06-21)\n system   x86_64, mingw32           \n ui       RStudio (0.99.1288)       \n language (EN)                      \n collate  English_United States.1252\n tz       America/Los_Angeles       \n date     2016-10-14                  \n\nPackages -------------------------------------------------------------------------------\n package    * version date       source      \n base       * 3.3.1   2016-06-21 local       \n datasets   * 3.3.1   2016-06-21 local       \n devtools   * 1.12.0  2016-06-24 CRAN (R 3.3.1)\n digest       0.6.10  2016-08-02 CRAN (R 3.3.1)\n git2r        0.15.0  2016-05-11 CRAN (R 3.3.1)\n graphics   * 3.3.1   2016-06-21 local       \n grDevices  * 3.3.1   2016-06-21 local       \n memoise      1.0.0   2016-01-29 CRAN (R 3.3.1)\n methods    * 3.3.1   2016-06-21 local       \n rstudioapi   0.6     2016-06-27 CRAN (R 3.3.1)\n stats      * 3.3.1   2016-06-21 local       \n tools        3.3.1   2016-06-21 local       \n utils      * 3.3.1   2016-06-21 local       \n withr        1.0.2   2016-06-20 CRAN (R 3.3.1)\n``\n. That's strange - why would Rcpp be trying to unload itself?\n. I can't reproduce it either.require()shouldn't ever try to unload a package. Do you have something in your~/.Rprofile` that might be modifying the behavior?\nIf you type require and hit enter, it should show a function that looks like this:\n https://github.com/wch/r-source/blob/826de7c2/src/library/base/R/library.R#L586-L616\n. Some thoughts:\n- It would be good for release() to check for the Remotes field and issue a warning or possibly even an error.\n- I personally don't like having github be the default. I know that it's by far the most common source of packages, but still, I think the location of a package should be explicit.\n- I think a :: separator would be nicer than |. For example, github::hadley/ggplot2, local::/pkgs/testthat, svn::https://github.com/hadley/stringr.\nAlso, is there a way to specify private git/github/bitbucket/svn repos? I suppose one possibility is for users to install those packages separately. But it would be nice not to have to do that. (I've almost never had to install a private package so there may well be an obvious way.)\n. Is it desirable to have it search in non-devtools environments? (That's what happens because of the default inherits=TRUE).\n. I think you mean that commit uses inherits = FALSE. :)\n. I think you mean that commit uses inherits = FALSE. :)\n. I think your VM doesn't have a copy of R that supports https downloads, or it's not configured properly for https. Have you tried installing any other packages?\n. That wouldn't work, because an installed package (which is what find.package() gives you) has a very different structure from package source (which is what devtools wants for load_all()).\n. Oh, unless you mean to call find.package() on a package that was loaded with load_all(). But then you'd still need a way to tell when a string represents the name of a package vs. the directory containing a package.\n. In many cases it's possible to reliably unload a package with compiled code, and devtools does that automatically. However, tcltk in particular is known to have problems with being unloaded.\n. In many cases it's possible to reliably unload a package with compiled code, and devtools does that automatically. However, tcltk in particular is known to have problems with being unloaded.\n. Nice! If this is indeed a reliable fix that's compatible with S4 stuff, it'll be great to have those errors go away.\n. I like this general approach -- there's a bunch of stuff that devtools borrowed from the R sources that could be retrieved dynamically like this.\nTo avoid the R CMD check warning, you could get the code either at run time or load time.\n. Here's what I found. I think the categories below are correct, but I could be wrong about some of them:\nThese functions are taken verbatim from R:\n- add_classes_to_exports\n- addNamespaceDynLibs\nThese functions are almost verbatim, but with very small changes:\n- makeNamespace - there is one change, to call register_namespace() instead of .Internal(registerNamespace(name, env)), but that might not be necessary if the code is extracted dynamically from R.\n- assignNativeRoutines\n- process_imports\nThese functions contain sections that are taken from R. For some, it might make sense to spin those parts out into separate function, but not for all:\n- setup_ns_exports\n- load_dll\n- library.dynam2\n. I think the code extraction should be done in .onLoad, so that R CMD check doesn't complain about stuff like ::: and internal function calls. I think doing it at load time will avoid those problems but I don't know for sure -- I don't know at exactly what point R CMD check scans the parse tree for those problems.\nDoing extraction at load time will also ensure that the extracted code matches the user's version of R. With the current code in this PR, the extraction happens in the bundled package -> binary package phase, so a binary package on CRAN might extract code from (say) R 3.2.4, but the user may try run it on 3.2.0.\n. Some care is needed when using delayedAssign at the top level of package code. In the past we had used it in Shiny, but it caused problems because it didn't behave the way we had expected. According to what I wrote in some emails, the promises will be evaluated on package load, not when the symbol is first accessed, for reasons that aren't entirely clear to me.\nBeing evaluated on package load is safe, but I could have been wrong before about the exact time when that happens. It would be a good idea to check that they don't get evaluated during the package source -> package bundle phase, or during the package bundle -> binary package phase. (Maybe add a cat(\"foo\", file=stderr()) to the expression and see when it gets printed.)\nSee rstudio/shiny@d7eb9b2, and if you want a bit more information, I can forward some of the old emails relating to the use of delayedAssign at the top level of a package.\n. I guess there's also the issue that bindings in a package namespace are locked so you can't modify them with .onLoad. You'd probably have to store them in an environment.\n. Oh cool, that simplifies things a bit.\n. It looks good to me. I agree that a compatibility check and warning is a good idea.\n. \ud83d\udc4d \n. Yes, @gaborcsardi, I think you're right -- my R session has been open for over a day and I think it had an old cached version of available.packages().\n. Agreed. Maybe even a shorter time would make sense, like 4-8 hours?\n. Thanks!\n. Now that I've thought about it some more, I think it's probably better to remove only the pkgname.a and pkgname.dll files instead of *.a and *.dll.\n. It's starnge that you're using R 3.2.3 but it's trying to install to an R 3.1 directory. Do other packages install properly?\n. One problem is that, right after you run release(), you can't be sure that the submitted package will actually be accepted onto CRAN without any revisions.\n. Just another thought about this: One thing that release() could do is to write a file named \"released_to_cran\" to package directory, with some content like: \"This package was sent to CRAN with devtools::release(). If it was accepted, you should remove this file and tag the commit that was released (a3728b). If it was rejected, just remove this file.\"\nSeeing the file there would serve as a reminder to tag the commit before committing more code.\n. @merliseclyde You might be interested in an article we recently about upgrading to a new version of R and possible package compatibility problems : http://shiny.rstudio.com/articles/upgrade-R.html. I'm glad you're making these improvements. One thing I ran into: when I ran revdep_check() and it failed to install the package that I'm doing the revdep checks on, it also gave the uninformative error message. In my case, it was because the R lib directory that I had chosen wasn't writable by the user. It would be helpful to have more information in case the target package fails to install.\n```\n\nrevdep_check()\nReverse dependency checks for shiny ===========================================\nSaving check results in revdep/checks/\nSaving install results in revdep/install/\nComputing reverse dependencies... AFM, AdaptGauss, BBEST, BayesBD, BayesianNetwork, CLME, CTTShiny, ChannelAttributionApp, Cite, CosmoPhotoz, DT, DVHmetrics, DynNom, ECharts2Shiny, EMMAgeo, EMSaov, EffectLiteR, EmiStatR, EpiModel, EurosarcBayes, Factoshiny, FreqProf, G2Sd, HH, IMP, IRTShiny, ImportExport, IncucyteDRC, LDAvis, MAVIS, MetaAnalyser, NNTbiomarker, OpenImageR, QCAGUI, RGA, RJafroc, RLumShiny, RQuantLib, ReporteRs, RtutoR, RxODE, SDEFSR, SHELF, SOMbrero, SSDM, SciencesPo, SensMixed, ShinyItemAnalysis, Sofi, SpaDES, StereoMorph, SubVis, VRPM, VWPre, VineCopula, addinslist, adegenet, adespatial, ahp, archivist, backpipe, backtestGraphics, bde, beanz, benchmarkme, benchmarkmeData, bigQueryR, blkbox, bookdown, capm, chipPCR, citr, colourpicker, compareGroups, condvis, cosinor, covr, crawl, d3heatmap, datacheck, ddpcr, detzrcr, diffr, distcomp, diveRsity, dpcR, dropR, eAnalytics, edgebundleR, eechidna, eemR, elementR, embryogrowth, enviPick, evobiR, explor, fanplot, flexdashboard, flora, formatR, formattable, gazepath, geneSLOPE, ggExtra, ggThemeAssist, ggiraph, ggraptR, ggvis, gmDatabase, googleAnalyticsR, googleAuthR, googleVis, gridsampler, gwdegree, idem, ifaTools, igraphinshiny, interAdapt, irtDemo, koRpus, lavaan.shiny, leaflet, learnstats, lightsout, likert, listviewer, merTools, meta4diag, metricsgraphics, miniUI, mirt, mirtCAT, mldr, mlr, mlxR, mplot, mwaved, nbc4va, npregfast, pairsD3, paramGUI, phenology, pipe.design, pitchRx, plotROC, plotSEMM, plotly, polmineR, poppr, pqantimalarials, qrage, questionr, quipu, rAmCharts, radarchart, rangeMapper, rcrossref, refund.shiny, repo, rgl, rgpui, rhandsontable, rintrojs, rivr, rmarkdown, rtable, sadists, sdm, searchConsoleR, seasonal, sglr, shinyAce, shinyBS, shinyDND, shinyFiles, shinyRGL, shinyTime, shinyTree, shinybootstrap2, shinydashboard, shinyjs, shinystan, shinythemes, shinytoastr, shotGroups, signalHsmm, simPATHy, soc.ca, sparkTable, squid, statnetWeb, subspaceMOA, swirlify, synthACS, tableHTML, tabplot, tigerstats, timeline, timeseriesdb, timevis, treemap, treescape, trelliscope, webshot, weightr, wppExplorer, xxIRT\nInstalling shiny 0.13.2.9005 and dependencies to /R-lib/\nError: Command failed (1)\n``\n. It might be a good idea to haveload_all()give a warning if filenames are invalid.\n. One more note: This issue makes it very difficult to run revdep checks on Linux, because any package installation failure leads to therevdep_check()exiting, and without any information about why. It would help to:\n- Show which package install failed, along with the error message.\n- Be able to continue therevdep_checkeven if some package installations fail, because the user might not want to install every single system dependency required for all the packages to compile correctly.\n. @gaborcsardi, I had a discussion with @jcheng5 today about writing some C/C++ code for process management, for the shiny testing stuff. The idea is to replace processx in the short term so that the testing can be done with a more reliable (but simpler) process management. In the long term, that code could be migrated into processx.\n. Hm, I wonder if this is the root cause of #885. We tried getting to the bottom of it but never figured it out.. Great. Here's the relevant commit: https://github.com/wch/r-source/commit/4fc486751c90b0a34bd4c2e10bbf6de3ec58fe14. @Ruminare Upgrading to the latest version of R (3.5.0) might help.. There are pros and cons of committing generated files to a repository. The stance taken in devtools is that the files in the repo can be given toR CMD build` to create a source or binary R package. This means that some generated files, like NAMESPACE file and the .Rd files, are part of the repository. Others, like .so and .dll files, are not, because they are created during the build phase.\n\nAnother reason for having those files be committed to the repository is so that when a version that has been released to CRAN is tagged, that tag represents the set of files that was used to create the source package that was submitted to CRAN. If the NAMESPACE and .Rd files are not part of the repository, there's no guarantee that they'll be the same when you generate them in the future, because roxygen2 may behave differently, and because the .Rd files might inherit information from other packages, and the other packages can change.\n. If you install the development version of devtools, it will work. First, use @aparpara's workaround, then upgrade devtools:\n```\nlibrary(devtools)\nassignInNamespace(\"version_info\", c(devtools:::version_info, list(\"3.5\" = list(version_min = \"3.3.0\", version_max = \"99.99.99\", path = \"bin\"))), \"devtools\")\nfind_rtools() # is TRUE now\ndevtools::install_github(\"r-lib/devtools\")\n```\n. Yup, I think @hadley is right.. I copied this function directly from the inside of base::loadNamespace() in R 2.15.1. I don't know if it's correct for other versions of R.\n. OK, got the '.' objects. The list2env isn't appropriate here, since the environment is already created by the makeNamespace function.\n. Doesn't \"x is dependent\" mean that x depends on something else, as in \"John is dependent on nicotine\".\n\"x is a dependency of y\" means that y depends on x. It's slightly awkward, but you could say, \"nicotine is a dependency of John's\".\n. I've found it useful. It lets you type this:\nR\nns_env('.')\npkg_env('.')\nInstead of this:\nR\nasNamespace('ggplot2')\nas.environment('package:ggplot2')\nBut maybe I'm using them in a different way than originally intended -- I often use them as accessor functions, but they also serve as creation functions. Maybe it would be good to separate out this functionality.\n. Thanks, fixed.\n. Should I also take out @keywords internal?\n. fixed.\n. Thanks, fixed.\n. oops.\n. Doing this can be tricky. If you just define a function system.file in the devtools package, that function will be called when you run system.file from the R console, and it will be called when you call system.file from devtools. But this version of the function won't be called when other packages use system.file.\nSuppose that you want to call system.file from inside of a ggplot2 function. This is the environment hierarchy:\n```\n\nprint_envs(ggplot2:::qplot)\n\n     # imports:ggplot2\n\n\n\n\n\n\n\n\n\n\n\n\n \n```\n\nggplot2 will find system.file in <namespace:base>, and that version will be called.\nTo override the copy of system.file that is used by everything in R, you'd have to replace it in <namespace:base>, as well the copy in the base package environment. I think this can be done base the base namespace environment is special in that it isn't locked.\n. If we put it in <namespace:devtools> then the modified version of system.file will be used by devtools functions, but not by anything else. Is that what you have in mind?\n. Since it is only to be called from devtools, how about a function with a different name, like system.file2, to avoid confusion? Or is there some benefit to overriding the existing name that I'm missing?\n. If system.file is inserted into the namespace of each package loaded with load_all (or into the imports environment for the package), then if anything in the package's namespace calls system.file, it'll get the substitute version.  But if system.file is called from any of the base packages, it'll be the original version.\n. I'm not sure exactly how system.file gets used by other packages, so it's hard for me to say.\nIf we want to go that route, I'll revert this change and do that on a separate branch.\n. Examples of this and run_examples would be helpful.\n. I don't know if it matters, but this won't remove the object from the new environment; it'll assign it NULL.\n. Thanks, fixed.\n. If show is TRUE, is it run and displayed but commented out?\nIf it's FALSE, then is it run and not shown at all?\n. typo: donrun\n. I think document() runs load_all, so this may not be needed. But the reset and export_all args should probably also be passed to document,\n. Oh, OK, I was mixing up the example-running code with the documentation-generating code, where it really does need to be removed (and not just commented).\n. Calling load_all in document will use the default export_all=TRUE. Maybe this line should be move below the call to document?\n. No need for space here.\n. No space here.\n. There are other calls to return for which this applies.\n. if (length(setVars) == 0) would be preferable here (and in next block).\n. A description of what this function does would be helpful.\n. Does this need to be careful of packages that might have \"Rcpp\" in their name?\n. I think you should also do unload(\"dll-rcpp\") here.\n. This doesn't seem to work for named vectors:\nd> c(if (F) \"a\"=1, if (T) \"b\"=2)\n[1] 2\n. Although, wrapping each one with c() seems to make it work:\nd> c(if (F) c(\"a\"=1), if (T) c(\"b\"=2))\nb \n2\n. Extra comma?\n. I think these two variables don't need to be defined up here -- even without these lines, they will be defined before being used by anything else.\n. Maybe use !file.exists(Sys.which(git_binary_name))? Otherwise, will users need to specify the full path?\n. Does this need to be world-writeable? If not, 755 would be better. (Also, does Sys.chmod work on Windows?)\n. I don't see this function used anywhere. Can it be removed?\n. I think git URLs usually have .git on the end of them, and it might be nice to strip that part off as well.\n. Here's why it's not a good idea to add this function in a namespace that gets imported: That function still needs to have some record of the loaded package -- it needs to know the name of the package (which is why it's a closure). if the closure is put into a namespace -- call it foo::system.file -- then there can be only one copy of that function in the whole R session.  So if you load_all multiple packages, then it will return modified results only for one of them. It could work if the function didn't have to be a closure, but I can't think of a good way to do that.\n. A simpler way to strip off .git is to do this:\nname <- gsub(\"\\\\.git$\", \"\", name)\nExample cases:\n```\ngsub(\"\\.git$\", \"\", \"foo.git\")  # should change this\n[1] foo\ngsub(\"\\.git$\", \"\", \"foogit\")  # shouldn't change\n[1] \"foogit\"\ngsub(\"\\.git$\", \"\", \"foo.gitbar\")  # shouldn't change\n[1] \"foo.gitbar\"\n``\n. Sure, done in 72ce098266260bd810d8f4b7d1eddac67f8caffc.\n. I actually tried that, and it causes problems when reloading packages, as was the case with #168. The problem happens when a class B in a package has a reference to another class A (that's not in the package), and A has a reference back to B. If you remove all theB@containsreferences and then removeB`, then A has a dangling reference back to B. When you try to create a class B again, you get errors because it tries to modify A to have a reference to B, but that reference already exists.\nIn the case of 168, the analog of class A was oldClass. And I think the problem happened with another class as well.\n. This happened when I did document(). I can take it out.\n. One reason for keeping it here is that it presently only gives a warning when it matters -- that is, when .onLoad or .onAttach is called. If the warning is moved into as.package, it'll give the warning even when there's no .onLoad or .onAttach function.\n. For consistency with the rest of the code base, I'd suggest using:\ngetRversion() >= '3.0.0'\n. Please wrap at about 80 columns.\n. This function looks like it was copy-pasted from the R console when you type loadNamespace (and has been reformatted by R). Could you replace with the code directly from r-source, with the original formatting? You can find it here: https://github.com/wch/r-source/blob/trunk/src/library/base/R/namespace.R#L484\n. Unload packages at end of test, please.\n. \"importing an S4 class ...\"?\n. @yihui Maybe something like this? (Note that it works for the example but I haven't tested thoroughly)\n```\nneeds_install <- function(pkg, compare, version) {\n  if (length(find.package(pkg, quiet = TRUE)) == 0) return(TRUE)\n  if (is.na(compare)) return(FALSE)\n  do.call(compare, list(packageVersion(pkg), version))\n}\nExample\ndeps <- parse_deps(\"httr (< 2.1),\\nRCurl (>= 3)\")\nneeded <- mapply(needs_install, deps$name, deps$compare, deps$version)\nneeded <- deps$name[needed]\n``\n. @hadley agreed,match.fun` is nicer. \nOne more thing: with the mapply, the returned object isn't always the same time, which can cause a problem when deps has zero rows. Probably best to do something like:\nneeded <- mapply(needs_install, deps$name, deps$compare, deps$version, SIMPLIFY = FALSE)\nneeded <- deps$name[as.logical(needed)]\nWhich works for both of these cases, at least:\ndeps <- parse_deps(\"httr (< 2.1),\\nRCurl (>= 3)\")\ndeps <- parse_deps(\"\")\n. This example won't work since the v1.4-rc branch is gone - but there's a devtools-1.4 tag now.\n. An alternative is to do something like this:\n- If there's a slash, split on the first one to find (A) username and (B) repo[/subdir][#pull|@ref]\n- Take part B and split on # or @ to find a pull or ref.\nYou might need some logic to make sure that there isn't a pull and a ref, and perhaps for other forms of bad input. I think it should be possible to construct a relatively simple validation regexp for this purpose.\n. I think this line was erroneously added by roxygen. (Bug?)\n. The first thing this function does is check if the environment has already been added, and if so, it exits.\n. Yeah, it's not really necessary.\n. If I remember correctly, this will only work correctly if the package directory is the same as the name of the package. That assumption is true for installed packages, but not necessarily for in-development packages.\nThe general problem is that the directory structure of installed packages isn't the same as that for source code, and I don't know of a good way around that.\n. Does it actually work to assign a value to shims when devtools is loaded the normal way (i.e. not with load_all)? I would expect that it would be a locked binding, and you would have to use an environment instead of a list.\n. I think it would be best to just take out the License field here. Or it should be the same license as devtools itself.\n. I think it should it be \"loaded\" instead of \"installed\"?\n. ",
    "jmlondon": "I'm using the roxygen from you via install_github(\"roxygen\"). \nIt does not appear to be intermittent, for me. I can reproduce it reliably and it started sometime in the last week. I was using the document() function frequently on the flight back from SFO last week and it was not an issue then. \nIf I get a chance, later today, I'll see if I can reproduce it on a dummy package.\njosh\nOn Jun 20, 2011, at 2:02 PM, hadley wrote:\n\nI've had that problem intermittently too, but I've never been able to track it down.  Are you using my roxygen or cran roxygen?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/9#issuecomment-1405806\n. Creating either a file or directory named 'Users' did not raise any error. roxygen just appears to overwrite without complaints.\n\nThat said, I just restarted my R session and can no longer replicate the issue. Now everything behaves as expected despite my best efforts to force the issue.\nI suggest classifying this as a 'gremlin' that, as with many things, may be resolved by simply restarting the R session.\nOn Jun 21, 2011, at 7:40 AM, hadley wrote:\n\nOne possible means of tracking the problem down would be to create a file called Users inside your package directory.  Then when roxygen tries to create that path, it will raise an error, and the traceback should help me narrow down the problem.  Thanks!\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/9#issuecomment-1410767\n. \n",
    "jcborras": "Old box running 2.12....\nI guess and upgrade on both this box and devtools's DESCRIPTION file\nis in place.\nOn Wed, Jun 29, 2011 at 12:18 AM, hadley\nreply@reply.github.com\nwrote:\n\nWhat version of R are you using? It's definitely find.package in 2.13\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/pull/12#issuecomment-1459113\n. R version 2.13.0 Patched (2011-06-27 r56229)\nAnd the problem persists\nGive it a spin by cloning git://github.com/jcborras/rseedpkg.git and\ncalling devtools::check('rseedpkg')\n\n2011/6/29 Juan Carlos Borr\u00e1s jcborras@gmail.com:\n\nOld box running 2.12....\nI guess and upgrade on both this box and devtools's DESCRIPTION file\nis in place.\nOn Wed, Jun 29, 2011 at 12:18 AM, hadley\nreply@reply.github.com\nwrote:\n\nWhat version of R are you using? It's definitely find.package in 2.13\n. No problems anymore once I figured out how to use roxygen.\nThat little beast wipes out NAMESPACE unless to declare what you\nexport in the function definition files.\nBTW, I though I'd never say this but I'm starting to like the devtools pkg....\n\n\nOn Wed, Jun 29, 2011 at 11:51 PM, hadley\nreply@reply.github.com\nwrote:\n\nWhich problem persists? Issues are bit easier to work with if you stick to one problem per issue.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/pull/12#issuecomment-1470469\n\n\nCheers,\njcb!\n\nhttp://twitter.com/jcborras\n. I have narrowed the culprit to the call of roxygenize inside devtools::document()\nThat roxygenize among other things removes my NAMESPACE file. It doesn't dare on your devtools though but I find hard to believe it's a question of name and or prestige. \nYes, it could be the expected behaviour, but now tell me how to generate a valid NAMESPACE file.\n. ",
    "lendle": "The workaround is helpful. Thanks! What about having devtools check the DESCRIPTION files for Suggests, and if it finds any, print out a message explaining the workaround?\n. ",
    "kohske": "I had not, and now I got it, cool :-)\nJust for others, here is a usege:\ninstall:\ndev_mode(TRUE)\ninstall_github(\"scales\")\ninstall_github(\"ggplot2\", branch=\"develop\")\nnow, dev versiong of ggplot2 is installed in ~/R_dev\nusage:\n```\ndev_mode(FALSE)\nlibrary(ggplot2) # load release version\ndo something with release version\ndetach(\"package:ggplot2\", unload=TRUE)  # detach the release version\ndev_mdoe(TRUE)\nlibrary(ggplot2) # load dev version\ndo something with dev version\n```\nthanks Hadley and lovely devtools!!\n. How about simply install induces an error if source and destination directories are same?\nAnd maybe it is better (1) ask if users really want to install when destination is not empty (unless option force = TRUE) and (2) stop the install when destination includes some VCS info (unless option force = TRUE).\n. Thanks. Then do you mean like this?\n``` R\n\ndev_mode(TRUE)\n\n>\n> dev_mode(FALSE)\n\n```\n\nOr please tell me your preference of the symbol instead of #>.\n\nAlso the .old_prompt variable shouldn't live in the global environment. Use local to create a place for it to live.\n\nThe .old_prompt need to be accessed by different dev_mode call. Is it possible with local variable?\n. > Also the .old_prompt variable shouldn't live in the global environment. Use local to create a place for it to live.\nNow I see. thanks. I pushed the \"closure\" version.\n. The second one enables to use the url like source_gist(\"gist.github.com/1654919\"). If this form of url is passed, it will be internally changed to this form https://raw.github.com/gist/1739337. That's all. \n. Conflict has been resolved. Do you need rebase?\n. No, that does not work. I put the log below:\n```\n\nlibrary(plyr)\nload_all(\"ggplot2\", TRUE)\n\nLoading ggplot2\nPackage SparseM (0.96) loaded.\n       To cite, see citation(\"SparseM\")\n... snip\n\nsessionInfo()\nR version 2.15.0 (2012-03-30)\nPlatform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)\n\nlocale:\n[1] C/C/C/C/C/ja_JP.UTF-8\nattached base packages:\n[1] grid      splines   stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n [1] MASS_7.3-17      proto_0.3-9.2    memoise_0.1      scales_0.2.0     reshape2_1.2.1   digest_0.5.2     nlme_3.1-103     multcomp_1.2-12  mvtnorm_0.9-9992 maptools_0.8-14  sp_0.9-98        foreign_0.8-49   gpclib_1.5-1     hexbin_1.26.0    lattice_0.20-6   mapproj_1.1-8.3 \n[17] maps_2.2-5       Hmisc_3.9-3      survival_2.36-12 quantreg_4.78    SparseM_0.96     plyr_1.7.1       devtools_0.6    \nloaded via a namespace (and not attached):\n[1] RColorBrewer_1.0-5 RCurl_1.91-1       cluster_1.14.2     codetools_0.2-8    colorspace_1.1-1   dichromat_1.2-4    munsell_0.3        stringr_0.6        tools_2.15.0      \n\nqplot(1:3, 1:3)\nError in summarize(subset(table$layout, grepl(\"^panel\", name)), t = min(t),  : \n  object 'b' not found\ndebug(qplot)\nqplot(1:3, 1:3)\n\ndebugging in: qplot(1:3, 1:3)\ndebug at /Users/takahashi/Dropbox/dev/R/ggplot2/R/quick-plot.r#77: {\nsnip\nBrowse[2]> search()\n [1] \".GlobalEnv\"        \"package:ggplot2\"   \"package:MASS\"      \"package:proto\"     \"package:memoise\"   \"package:scales\"    \"package:reshape2\"  \"package:digest\"    \"package:nlme\"      \"package:multcomp\"  \"package:mvtnorm\"   \"package:maptools\"  \"package:sp\"        \"package:foreign\"\n[15] \"package:gpclib\"    \"package:hexbin\"    \"package:lattice\"   \"package:grid\"      \"package:mapproj\"   \"package:maps\"      \"package:Hmisc\"     \"package:survival\"  \"package:splines\"   \"package:quantreg\"  \"package:SparseM\"   \"package:plyr\"      \"tools:RGUI\"        \"package:stats\"  \n[29] \"package:graphics\"  \"package:grDevices\" \"package:utils\"     \"package:datasets\"  \"package:devtools\"  \"MacJapanEnv\"       \"package:methods\"   \"Autoloads\"         \"package:base\"   \n``\n. Yes, butshow_rdis file-name based, while?is object-name based.\nOk, maybe I will hack?` in future.\n. Yes, but Rd file is well structured so it might not be so difficult.\nAt the moment, reverse lookup of Rd from function (or object name) is sufficient, \nso grep alias *.Rd might be the first step.\n. Of course, tools:::parse_Rd is better.\n. I mean like this:\n``` r\nwhen load_all(...)\nit makes index of the package inside namespace:devtools\nfiles <- list()\nfiles[[\"ggplot2\"]] <- dir(\"~/Dropbox/dev/R/ggplot2/man\", \"\\.Rd$\", full = TRUE)\nr <- lapply(files[[\"ggplot2\"]], function(x) {\n  r <- tools:::parse_Rd(x)\n  unlist(r[which(tools:::RdTags(r) == \"\\alias\")])\n})\naliases <- list()\naliases[[\"ggplot2\"]] <- r\nand accessor\ndevq <- function(p, f) {\n  i <- which(sapply(aliases[[p]], function(a) any(f == a)))\n  print(files[[p]][i])\n  if (length(i) == 1) show_rd(p, basename(files[[p]][i]))\n}\nuse it\ndevq(\"ggplot2\", \"aes\")\n```\n. > Hmmm, the problem is then keeping the index in sync after you roxygenise - although I guess document could also update it.\nindexing takes place every time when load_alled the package, so I think there is no sync problem.\nBut,\n\nAnd I think we'd just modify show_rd so it could either accept the name of a topic or a file name.\n\nAgreed. This is more simple. Perhaps looking up the topic is not so heavy, so we don't need index.\n. Got it.\nIs this technique popular?\n. OK, I will remove.\n. OK.\n. This some sentence is a citation from gist site. https://gist.github.com/\nIs there a markup for citation (quotation) in Rd?\n. Actually this function will work with any protocol that is supported in curl. So it can work as a simple wrapper for source.\nOk, I rename it to source_url.\n. Not necessary since unused connection is automatically closed, but I will change to close it explicitly. \n. Of course it can be, but sourcedoes not accept vector so I don't think vectorize is necessary.\nAs you know sapply(urls, source_url) will do that.\n. A problem is that a entry of the gist can contain different types of files, so maybe one is .R, the other is .txt.\nBut as the gist wisely identify the type of file, maybe we can wisely detect and source only .R. I will check if it is possible.\n. One way is to download tar.gz that contains all entries, extract it, inspect the extension, and run the file if it is .R.\nNot sure which way is most convenient.\nWhat do you think?\n. ",
    "BrianDiggs": "Done.  Didn't realize those were also checked in.  Assumed they weren't because they are derived files.  Shouldn't assume.\n. You're right; I should have filed this against roxygen2.  I'm going to close this and file it there.\n. To give another example where this could be useful: R-Forge subversion repositories also have this structure: the package are not at the root of the repository, but under a pkg directory off the root.\n. You can use the github API to get the SHA\nhttp://developer.github.com/v3/git/refs/\nYou know the repo owner, repo, and branch, which allows creating the URL.\ne.g.\nhttps://api.github.com/repos/hadley/ggplot2/git/refs/heads/master\nreturns a JSON object:\njson\n{\n  \"ref\": \"refs/heads/master\",\n  \"url\": \"https://api.github.com/repos/hadley/ggplot2/git/refs/heads/master\",\n  \"object\": {\n    \"type\": \"commit\",\n    \"sha\": \"f9915d0784cc9bd733903f1658143687e2821854\",\n    \"url\": \"https://api.github.com/repos/hadley/ggplot2/git/commits/f9915d0784cc9bd733903f1658143687e2821854\"\n  }\n}\nI assume there is a JSON parser, or simple string parsing might work if enough is known about the structure of the JSON.\n. Duplicate of Issue #248?\n. @hadley Build the source package (into .tar.gz) from the source directory using devtools and then do the R CMD INSTALL from the command line (thus without devtools loaded)?\n. @hadley CRAN.\n. I wonder if it would not be better to set the version.max on the last version of Rtools to something absurdly large (such as \"4.0.0\"). With this approach, devtools would not need to be updated with each (minor) release of R. I think it is a choice of failure modes:\n- When a new version of R comes out, until devtools is updated and the update installed, the right Rtools can't be determined\n- When a new version of Rtools comes out, old versions of devtools which have not been updated (to a version of devtools which recognizes the new version of Rtools) will require/look for the wrong version of Rtools.\nThe first happens more often (but with announcements, so it can be gotten ahead of) and results in a failure mode where you can't do something; the latter happens more rarely, but will always allow something to work even if it is sometimes the wrong thing.\nI'm not even sure which one I would advocate.\n. Looking at the rough patterns some more, setting the max to \"3.0.99\" might be the sweet spot of covering everything likely to be appropriate and likely not including too much that isn't. In general, if the most recent version is \"a.b\", set the max to \"a.b.99\", to be adjusted when there is a real max (which would presumably be known when a new Rtools comes out).\n. Duplicate of Issue #308.  Fixed in Issue #298. I'm not sure when the next version with this fix will be released. \n. Duplicate of Issue #292 which has been merged and should be in next release. In the meantime, if you manually load the digest package (library(\"digest\")), subsequent calls should work.\n. I am no longer sure that putting utils in the Depends: field does make it work with devtools.  Loading utils (library(\"utils\")) right before calling, say, document() does allow it to work.\n. The problem does occur in document(), and I can get around that by calling document() separately (with utils on the search path) and then calling check(document = FALSE). However, this separation does not always work. load_all() fails with a similar error:\nd> load_all(\"dummy\")\nLoading dummy\nError in eval(expr, envir, enclos) : could not find function \"read.csv\"\nd> traceback()\n7: eval(expr, envir, enclos)\n6: eval(i, envir)\n5: FUN(\"h:\\\\My Documents\\\\Projects\\\\gitrepos\\\\dummy/data/dataformat.R\"[[1L]], \n       ...)\n4: lapply(paths, sys.source, envir = lazydata_env, chdir = TRUE, \n       keep.source = TRUE)\n3: unlist(lapply(paths, sys.source, envir = lazydata_env, chdir = TRUE, \n       keep.source = TRUE))\n2: load_data(pkg)\n1: load_all(\"dummy\")\nThe problem, not surprisingly, is in load_data(). However, when run interactively, load_data() works\nd> load_data(\"dummy\")\nd>\nI guessing that is because interactively utils in on the search path but when called from within load_all(), it is operating withing devtools's namespace which does not see utils. In the case of load_all(), it is not possible to separate the calls (like with document() and check(document=FALSE)).\n. utils::sessionInfo() also does not report the version number for base, or for any of the base packages (base, compiler, datasets, grDevices, graphics, grid, methods, parallel, splines, stats, stats4, tcltk, tools, and utils). That is because these packages are version locked with the version of R; they have the same version as the running version of R and updates are only released when a new version of R is released. \nGiven that, it is reasonable that devtools::session_info() also does not report the version number.\n. I hadn't noticed that session_info() did not report the base packages at all; I thought the issue was that the packages were reported without a version number. I do think session_info() should get a include_base argument (default FALSE for backward compatibility, but I could make a completeness argument that TRUE should be the default) which is propagated to the non-exported function package_info which can already handle this.\n. Is there a reason you can't do it with appropriate arguments to install_git?\n. Currently devtools lists git2r in it Imports field, so devtools can assume that git2r is installed and available in order for it (that is, check()) to work properly.\nI think there may be an issue that when updating a package, the depends/imports are not enforced and so if a new dependency is added (which git2r was, relatively recently) it won't necessarily get installed automatically (as it would with the default values of the arguments to install.packages()).\n. In that case, what I suggested is irrelevant. Hopefully someone else can help.\n. Should remove the install_gitorious line because that function has been removed. See #913.\n. ",
    "jlaake": "I tried it to see the contents of the tar.gz file. I only did it because I had forgotten to change my .Rpackages location after I created a new workspace for the new version of Eclipse and to put projects on github.  I kept making changes and they weren't being reflected in load_all etc because it was still pointing to old location which hadn't been changed.  So I probably don't need it but you may want to change your README because that was what I was following.\n. On 7/11/2011 7:47 AM, hadley wrote:\n\nI think you want R CMD build --binary rather than R CMD install --build, and you'll now get what you want with build(\"CIPinnipedAnalysis\", binary = TRUE).  Please let me know if you have any problems.  I'll probably push a new version of devtools to cran by the end of the week.\nThanks for doing that.  I needed to make a small change in build to get \nthis to work.  I didn't try release.\n\nR(paste(\"CMD build \", shQuote(pkg$path), \" \", options, sep = \"\"),\ndirname(pkg$path))\nuse dirname(pkg$path) instead of path.\nI have always used  R CMD install --build  and never had any problems.\nIs there a reason to use the other?  I saw some traffic on r-devel about \nthis but didn't follow it.\nregards --jeff\n. On 7/11/2011 9:20 AM, hadley wrote:\n\nOoops, just pushed dirname fix.\nAs far as I know R CMD install --build is now deprecated, and you can't expect it to continue to work in future versions of R.\nGot it.  Just been doing that way for awhile and didn't know it \nchanged.  Thanks again for devtools and the fix. --jeff\n. It is also pdftex if the package has a vignette; see issue 173; \n\nI'm the person who raised this issue with Ben.  He had been using RForge and I suggested he switch to github. To avoid building binaries using install_github from source was suggested. I tried on a virgin Windows system that had not been used for r developing, tex etc.  It broke in many places the first being Rtools.  I loaded that and then devtools tried to modify the path but that didn't work. It created c:\\rtools\\bin/bin for some reason instead of c:\\Rtools/bin. Once I modified my path then I tried further and ran into the vignette issue with Ben's R2admb package.\nregards --jeff\n. Will do.  Was interrupted and didn't get a chance. It is on a different\nmachine.  --jeff\nOn Wed, Dec 5, 2012 at 5:16 AM, hadley wickham notifications@github.comwrote:\n\n@jlaake https://github.com/jlaake If there's a problem with Rtools path\ndetection, please report it - unless people report bugs I can't make it\nbetter. My experience is that it works in about 95% of cases: the last time\nI taught a class using it, all 20 or so windows users didn't have any\nproblems.\n@bbolker https://github.com/bbolker It's not that I think it's a bad\nidea, I just need to understand the motivation. If it's relatively simple\nto make work, I'd be happy to accept a patch, although I'm not sure exactly\nwhere the problem might lie since devtools just wraps the standard R way of\ninstalling packages.\n173 is definitely fixable.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/200#issuecomment-11040850.\n. With the removal of the downloads tab on github, there is more incentive to be able to build R packages from source in Windows. Is the minimum installation Rtools, devtools and pdftex (if there is a vignette)?  Are you working on this to include in RStudio? That would certainly solve the issue.\n\nregards --jeff\n. Great to hear. I know you aren't a windows user but many folks are and I'm\nsure they will be very appreciative of the work you are doing on their\nbehalf. It will also benefit developers from needing to build window\nbinaries for packages that aren't on CRAN or are in between uploads to\nCRAN. RStudio is quickly becoming (or is) the dominant IDE for R and that\nchange will be a further big improvement that will solidify that position.\nregards --jeff\nOn Wed, Dec 12, 2012 at 2:13 PM, hadley wickham notifications@github.comwrote:\n\n@jlaake https://github.com/jlaake yes, that's on the long term to do\nlist. The next version of devtools will attempt to remove the pdftex\ndependency.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/200#issuecomment-11312216.\n. I just used the defaults.  I'll remove Rtools and reinstall to see what it\nis setting.\n\n--jeff\nOn Thu, Dec 6, 2012 at 5:51 AM, hadley wickham notifications@github.comwrote:\n\nDid you set any options when installing Rtools?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/201#issuecomment-11086078.\n. > utils::readRegistry(\"SOFTWARE\\R-core\\Rtools\", hive = \"HLM\", view =\n\"32-bit\")\nError in utils::readRegistry(\"SOFTWARE\\R-core\\Rtools\", hive = \"HLM\",  :\n  Registry key 'SOFTWARE\\R-core\\Rtools' not found\nI should explain that this is a Fed govt computer where they neuter\nyour prvileges to some degree.  You can enter a password to get some level\nof admin privilege but maybe it won't allow registry changes.  Not sure.\nLike I said earlier this is not my work computer and I was just using it as\na test bed.  There will be lots of folks out there with a similar issue\nhowever both fed, state and other organizations that don't allow full admin\nprivilege.  That is why I use my personal computer and work outside the\nsystem so I don't have this type of issue.\n\n--jeff\nOn Thu, Dec 6, 2012 at 7:43 AM, hadley wickham notifications@github.comwrote:\n\nDon't worry about reinstalling, I just wanted to know if you did something\nunusual.\nCould you please give me the output of utils::readRegistry(\"SOFTWARE\\R-core\\Rtools\",\nhive = \"HLM\", view = \"32-bit\") ?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/201#issuecomment-11090331.\n. This is what I get on my personal computer where everything works.\n\nutils::readRegistry(\"SOFTWARE\\R-core\\Rtools\", hive = \"HLM\", view =\n\"32-bit\")\n$Current Version\n[1] \"2.16\"\n$InstallPath\n[1] \"c:\\Rtools\"\n$2.13\n[1] \"\"\n$2.14\n[1] \"\"\n$2.15\n[1] \"\"\n$2.16\n[1] \"\"\nOn Thu, Dec 6, 2012 at 7:43 AM, hadley wickham notifications@github.comwrote:\n\nDon't worry about reinstalling, I just wanted to know if you did something\nunusual.\nCould you please give me the output of utils::readRegistry(\"SOFTWARE\\R-core\\Rtools\",\nhive = \"HLM\", view = \"32-bit\") ?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/201#issuecomment-11090331.\n. But without --as-cran it doesn't catch the lines too long for the pdf and\nthe CRAN folks reject the submission. Is there another way to catch that\nwith devtools?\n\nOn Thu, Jun 26, 2014 at 5:35 AM, Hadley Wickham notifications@github.com\nwrote:\n\nWe don't use --as-cran because this isn't exactly what CRAN does, and we\nwant to skip some of the more expensive tests (like for version\ndependencies).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/496#issuecomment-47219843.\n. Thanks. Will do.\n\nOn Thu, Jun 26, 2014 at 7:14 AM, Winston Chang notifications@github.com\nwrote:\n\nI believe this has already been fixed in the development version of\ndevtools:\nhttps://github.com/hadley/devtools/blob/master/R/check.r#L159\nCan you try again with the latest development version?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/496#issuecomment-47230542.\n. Worked. Thanks.  --jeff\n\nOn Thu, Jun 26, 2014 at 7:15 AM, Jeff Laake jefflaake@gmail.com wrote:\n\nThanks. Will do.\nOn Thu, Jun 26, 2014 at 7:14 AM, Winston Chang notifications@github.com\nwrote:\n\nI believe this has already been fixed in the development version of\ndevtools:\nhttps://github.com/hadley/devtools/blob/master/R/check.r#L159\nCan you try again with the latest development version?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/496#issuecomment-47230542.\n. \n\n",
    "andrie": "Two reasons:\n1. There is a standardised way for R users to use install.packages(pkg, repos=\"R-forge...\", ...).  I have tried various permutations of this command to install a package from github, but no success yet.  It seems to me this lowers the barrier to get users to try my package.  (I discovered last night that devtools now has a function to install directly from github, but this still means the user has to have devtools first.)\n2. I like their automated overnight build system that builds to various platforms.  In theory this could highlight issues on other platforms.\nHowever, I prefer the distributed nature of git vs the centralised nature of svn.  So I'm not completely set on this course of action yet.\n. That's a fair point.  And now that devtools is on CRAN - there is no excuse!\nThank you, as always, for doing a great job!\n. Yes, I updated to the dev version this morning, then re-ran the tests and had the same outcome.\nI'll try again.\n. > Restarting R session...\n\nlibrary(devtools)\nScanning path...\nls : c:\\Rtools\\bin\\ls.exe \ngcc: c:\\Rtools\\GCC-46~1.3\\bin\\gcc.exe \nVERSION.txt\nRtools version 2.16.0.1923 \nVersion: 2.16 \nsystem.file(\"inst\", \"extdata\", \"DellSurveyWave2.xlsx\", package=\"tbgSurvey\")\n[1] \"\"\nsystem.file(\"extdata\", \"DellSurveyWave2.xlsx\", package=\"tbgSurvey\")\n[1] \"C:/Program Files/R/R-2.15.2/library/tbgSurvey/extdata/DellSurveyWave2.xlsx\"\n`\n\nNow run run_examples()\n\nRunning examples in xReadExcel.Rd\n\nsdat2 <- xReadExcel(system.file(\"extdata\", \"DellSurveyWave2.xlsx\", package=\"tbgSurvey\"))\nLoading required package: XLConnect\nLoading required package: XLConnectJars\nLoading required package: rJava\nXLConnect 0.2-3 by Mirai Solutions GmbH\nhttp://www.mirai-solutions.com ,\nhttp://miraisolutions.wordpress.com\nError: file.exists(filename) is not TRUE `\n\n\nIf it will help, I can construct a minimal example package that demonstrates my problem and upload to github.\n\nPS. The underlying reason, I believe, is nothing to do with devtools() per se, but the arbitrary nature of the R CMD build process. What I mean is that in the package source the files live at inst/extdata/ but in the built version the same files live at extdata/\n. Yes, I updated devtools successfully this morning after seeing your tweet.\nThank you for looking into this.\nI'll update devtools on a different machine and test again. Then I'll post further feedback.\n. ",
    "tds151": "I'm using roxygen (and i'm working to figure out how to install roxygen2 on\nmy system thanks to your help).  that said, i made this post because - under\nroxygen - document() behaves differently than roxygenize(), which does\nutilize the @rdname tags and doesn't generate documentation for a function\nwith no tags (differently from document() on my system).\nOn Tue, Jul 19, 2011 at 11:05 AM, hadley \nreply@reply.github.comwrote:\n\nAre you using roxygen2?  Document just calls roxygen, so any issues should\nbe filed at https://github.com/klutometis/roxygen\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/21#issuecomment-1609207\n\n\nThank you, Terrance Savitsky\n. ",
    "edwindj": "Thanks for the quick answer! \nI tested it, but it doesn't work: I tracked it down as an issue for RStudio on Windows: It currently has problems installing source packages (while RGui and RTerm are working fine). \nI filed a bug/problem description on the RStudio website. If know more, i will let you know\nBest\n. It is a bug of RStudio: version, R.home(\"bin\") in RStudio currently expands to the long name (in stead of the shortname). If this contains any spaces (which it by default does), the install command fails.\nShould be fixed soon \n. devtools currently doesn't install because it should be: \n.Platform$r_arch == \"x64\"\nin stead of\n.Platform$OS$r_arch == \"x64\"\n. Hi Hadley, \nMine is:\n``` R\n\nstr(.Platform)\nList of 8\n $ OS.type   : chr \"windows\"\n $ file.sep  : chr \"/\"\n $ dynlib.ext: chr \".dll\"\n $ GUI       : chr \"RStudio\"\n $ endian    : chr \"little\"\n $ pkgType   : chr \"win.binary\"\n $ path.sep  : chr \";\"\n $ r_arch    : chr \"x64\"\n```\n\nBut the thing is that currently .onAttach contains\na statement with .Platform$OS$r_arch which generates an error during R CMD INSTALL devtools\nBest\n. I ran into problems using brew and/or Rook within a package and loading it with devtools.\nMy template files are normally in the ./inst/brew and ./inst/app/html and the installed ones are loaded by the package using system.file (from /brew and app/html respectively). \nDuring development I do edit them a lot, but the most recent one are not loaded by devtools, so I came up with this fix.\nInnitially I had this fix in my .Rprofile and that works fine, but I can imagine more devtools users will hit this problem.\n. Addendum, \nMay be a better/cleaner fix is to add the override system.file to the pkg_env\n. You are right: that is a better fix!\n. ",
    "gthb": "Yep. I only lost documentation changes that I hadn't pushed, and I was able to pluck those out from a built PDF, so it wasn't that bad. But it could have been.\n. But that would not have caught this; my project directory did contain a DESCRIPTION, so it would still be nuked.\nIt could check that they all look like built packages (contain a DESCRIPTION with a Built line, or is it Packaged?) \u2014 would that work?\n. That sounds fine to me. The dev_mode check would just let you realize your error sooner, but it's not important if install prevents the actual foot-shootings.\n. ",
    "yihui": "I see. Thanks!\n. Although I do not want to mention the possible hack, I think you have a good point there, which is also what I wanted a few years ago (in my early days of using roxygen, I hated the bogus changes in GIT very much). What you can do is to hack the Authors@R field in DESCRIPTION, which will be parsed and evaluated during R CMD build:\nAuthors@R: if (file.exists('DESCRIPTION') && !file.exists('man')) roxygen2::roxygenize('.');\n    person('Joe', 'J', role=c('cre','aut'), email='joe@example.com')\nThen roxygenization is done automatically, and you do not need to put man/ in your GIT repository. No need to use Makefile, so no RTools. No CI. No devtools support. It is a pure R solution, but it is just a hack. The more reasonable support should come from R core by allowing some code to be executed before R CMD build. There has been a discussion in r-help (https://stat.ethz.ch/pipermail/r-devel/2013-October/067722.html), where Henrik really had a good point, but Duncan did not seem to get it. Sigh.\n. To confess, I used this trick once to hack r-forge.r-project.org because nobody answered me when I requested installing some dependencies. I don't dare using it on CRAN. Crandalf will not be happy seeing this, I guess.\nI mean no need to request devtools support. Wherever you can call R CMD build, you can use this trick. \n. I see. Thanks!\n. okay, anything else to do?\n. Sure. I'll do that.\n. Done.\n. I did not know devtools was forcing the locale to be C, which is a bad idea. I believe it makes a lot of sense to remove this restriction. The locale can be temporarily set to C in a few cases to ensure consistency, such as sorting, but in general, the C locale will make R unable to read/write Unicode characters correctly.\n. the old not.installed function only takes one argument (package names); now I need to take three, and I guess Filter() is no longer an elegant solution, so I just used the dumb loop approach, which seems to be the most straightforward\n. okay, done\n. @wch Thanks! I can do that and test it if you two are happy with it.\n. ",
    "jthetzel": "I was not aware of normalizePath().  Thanks.  I'll close this and resubmit with it.\n. I'll look into this some more.  However, I'm not sure if normalizePath() will work, at least on its own.  It works for Linux. However for Windows, normalizePath(\"/path/to/directory/\") returns \\\\path\\\\to\\\\directory\\\\, which file.exists() returns as FALSE. I think a function to remove ending / and \\\\ is still needed.\n. ",
    "cboettig": "Hmm, working for me too now, not sure what had happened before.  Sorry for not checking more closely first!\n. Ah, it seems that in one of my packages, @import is correctly adding the import directive to the NAMESPACE but not the DESCRIPTION after I call document() .  Do I need to do something else to make sure this happens?\n. Hmm, no go for me.  Still complains that configure file is not executable:  \nInstalling package(s) into '/home/cboettig/R/x86_64-pc-linux-gnu-library/2.14'\n(as 'lib' is unspecified)\n* installing *source* package 'wrightscape' ...\nERROR: 'configure' exists but is not executable -- see the 'R Installation and Administration Manual'\n* removing '/home/cboettig/R/x86_64-pc-linux-gnu-library/2.14/wrightscape'\n* restoring previous '/home/cboettig/R/x86_64-pc-linux-gnu-library/2.14/wrightscape'\nPerhaps this is a platform-dependent issue?  I'm running ubuntu 11.10 with R-2.14.1.\n. cool, works for me.  thanks!\nOn Thu, Jun 14, 2012 at 12:58 PM, hadley wickham <\nreply@reply.github.com\n\nwrote:\nWorks for me - which I think means that you need to set TMP to point to\na writeable directory.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/32#issuecomment-6338947\n\n\nCarl Boettiger\nUC Davis\nhttp://www.carlboettiger.info/\n. That's just what I was looking for!  How do you feel about incorporating it into the check call?\n. Sure, makes sense.  I should have just done a better job of finding the tools utility -- the check message tells me to run R CMD build --resave-data, whereas obviously I'd rather just fix my data in R than create a new build archive.\n. Yeah, that makes sense, (how will the order be determined in roxygen then?)\nbut it still seems to me that I would want to document without writing the\nNAMESPACE (or perhaps equivalently, editing the DESCRIPTION).\nI've come across this\nproblemhttp://stackoverflow.com/questions/8884607/r-using-s3-and-s4-methods-of-simulate-in-the-same-packagemost\nrecently via what appears to be conflict between NAMESPACE, S3 and S4\nclasses.  The 'solution' I have at the moment is to delete the S3 method\nline in the namespace (but not the documentation) and then check and\ninstall don't complain.  I guess I can run document(), edit the NAMESPACE,\nand then run check(document=F) and release(check=F).  Anyway, thanks for\nconsidering.\nOn Thu, Jan 19, 2012 at 12:30 PM, hadley wickham <\nreply@reply.github.com\n\nwrote:\nThe namespace reordering is a bug in roxygen2 and should be fixed in the\nnext release.  I'd rather not add features in devtools to work around bugs\nin other packages (especially when I also maintain the other package!)\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/47#issuecomment-3573690\n\n\nCarl Boettiger\nUC Davis\nhttp://www.carlboettiger.info/\n. This error was coming from a colleague trying to install one of my github-based packages, turns out he has R 2.12 and devtools 0.2, which I'm guessing was the reason for the error.  Sorry for the false bug report!\n. Good idea.  It does look like it's corrupted. \nArchive:  /home/cboettig/Desktop/RWordPress.zip\n[/home/cboettig/Desktop/RWordPress.zip]\n  End-of-central-directory signature not found.  Either this file is not\n  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n  latter case the central directory and zipfile comment will be found on\n  the last disk(s) of this archive.\nzipinfo:  cannot find zipfile directory in one of /home/cboettig/Desktop/RWordPress.zip or\n          /home/cboettig/Desktop/RWordPress.zip.zip, and cannot find /home/cboettig/Desktop/RWordPress.zip.ZIP, period.\nAny idea why this happens?  the error is replicable for me.\n. 10 bytes.  not a good sign ;-)\nNot using a proxy.  Other packages work just fine, i.e.\ninstall_github(\"Rflickr\", \"duncantl\")\nworks without an issue.\nOn Wed, Apr 11, 2012 at 2:46 PM, hadley wickham <\nreply@reply.github.com\n\nwrote:\nAnd are you using a proxy?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/82#issuecomment-5079819\n\n\nCarl Boettiger\nUC Davis\nhttp://www.carlboettiger.info/\n. whoops.  I could swear I got the same error from ROAuth, which actually\ndoes exist, in which I was able to download and install the repo.  But now\ninstall_github is working for that.  Must have somehow called\ninstall_github while the zip file was unavailable(?)\nAnyway, mystery solved, sorry for the trouble!\nOn Wed, Apr 11, 2012 at 2:52 PM, hadley wickham <\nreply@reply.github.com\n\nwrote:\nHmmm - maybe because https://github.com/duncantl/RWordPress/zipball gives\na 404? And https://github.com/duncantl/RWordPress says \"nothing to see\nhere\"\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/82#issuecomment-5079943\n\n\nCarl Boettiger\nUC Davis\nhttp://www.carlboettiger.info/\n. Thanks for fixing this.  Might you mention the fix on the original SO question so I can accept it as the correct answer?\n. Whoops, the later is me not understanding citation and people objects directly.  I guess you avoid dates because CRAN will automatically add them?\n. Thanks for the advice! I'll try and stick with hand-crafted NEWS then, and maybe link to issues for details.\n. thanks!\nOn Mon, Jun 10, 2013 at 12:37 PM, Winston Chang notifications@github.comwrote:\n\nFor cases like this, I've used this script which I've named RD to start\nup R-devel (you'll need to tweak the path for your installation):\n!/bin/bash\nMay need to set R_LIBS_SITE# export R_LIBS_SITE=${R_LIBS_SITE-'/usr/lib/R-devel/lib/R/library:/usr/local/lib/R/site-library:/usr/lib/R/site-library::/usr/lib/R/library'}\nexport PATH=\"/usr/local/lib/R-devel/bin:$PATH\"\nR \"$@\"\nThen if you use devtools to run check(), when it calls R to run checks,\nit will start up R-devel. You can check this by running the following from\nyour R session:\nsystem(\"R -e 'version'\")\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/301#issuecomment-19221126\n.\n\n\nCarl Boettiger\nUC Santa Cruz\nhttp://carlboettiger.info/\n. This is an exact duplicate of https://github.com/hadley/devtools/issues/797 and has already been fixed in the GitHub version.\nHowever, since that fix has not been released to CRAN, anyone using the latest copy of devtools and git2r from CRAN gets this error; which is super annoying since release() is basically broken in the CRAN version not that git2r version 0.10.1 is on CRAN.  So a new release to CRAN would be stellar ;-)\n. this also affects devtools::install, which similarly attempts to install the newer igraph (and all its new dependencies) rather than use the version already installed.\n. Just to make this a concise reproducible example:\n``` r\ndevtools::install_version('igraph', '0.7.1', repo = 'http://cran.rstudio.com')\nThis next command first upgrades igraph, which causes the installation to fail\ndevtools::install_github(\"nimble-dev/nimble/packages/nimble@stable\")\n```\nnote that the nimble package does not place any restrictions on version numbers of its dependencies (and its installation fails with igraph > 1.0, but works with 0.7.1).  Or maybe @gaborcsardi can see if I'm just doing something wrong with respect to igraph or this installation?\n. Apologies for not having a good minimal example, this could be user error from a naive attempt to wrap a C program.  Anyway, if you clone https://github.com/cboettig/rappl/tree/testing and run devtools::document() you should see the error about not having a NAMESPACE.  \nHere's the run log I see:\n```\ndevtools::document()\nUpdating rappl documentation\nLoading rappl\nRe-compiling rappl\n'/usr/lib/R/bin/R' --no-site-file --no-environ --no-save --no-restore CMD  \\\n  INSTALL '/home/rstudio/rappl'  \\\n  --library='/tmp/RtmpDrJUwI/devtools_install_17fbdfe81' --no-R --no-data  \\\n  --no-help --no-demo --no-inst --no-docs --no-exec --no-multiarch  \\\n  --no-test-load --preclean \n\ninstalling source package \u2018rappl\u2019 ...\nrm -f ./PolicyGraph/PolicyGraph.o ./PolicyGraph/PolicyGraphGenerator.o ./Evaluator/EvaluationEngine.o ./Evaluator/EvaluatorSampleEngine.o ./Simulator/SimulationEngine.o ./MathLib/DenseVector.o ./MathLib/MathLib.o ./MathLib/SparseMatrix.o ./MathLib/SparseVector.o ./Algorithms/SARSOP/BinManager.o ./Algorithms/SARSOP/BinManagerSet.o ./Algorithms/SARSOP/Sample.o ./Algorithms/SARSOP/SampleBP.o ./Algorithms/SARSOP/SARSOP.o ./Algorithms/SARSOP/SARSOPPrune.o ./Models/MOMDP/BeliefTransitionMOMDP.o ./Models/MOMDP/ObservationProbabilities.o ./Models/MOMDP/VariableRelation.o ./Models/MOMDP/BooleanVariable.o ./Models/MOMDP/StateTransitionXY.o ./Models/MOMDP/StateTransitionY.o ./Models/MOMDP/MOMDPLite.o ./Models/MOMDP/MOMDP.o ./Models/MOMDP/VariableValue.o ./Models/MOMDP/Variable.o ./Models/MOMDP/StateTransitionXXpY.o ./Models/MOMDP/IVariable.o ./Models/MOMDP/VariableCombined.o ./Models/MOMDP/Rewards.o ./Models/MOMDP/StateTransitionX.o ./Models/MOMDP/BeliefTransitionMOMDPLite.o ./Models/MOMDP/IVariableValue.o ./OfflineSolver/GlobalResource.o ./OfflineSolver/solverUtils.o ./Bounds/AlphaPlane.o ./Bounds/AlphaPlanePool.o ./Bounds/AlphaPlanePoolSet.o ./Bounds/AlphaVectorPolicy.o ./Bounds/BackupAlphaPlaneMOMDP.o ./Bounds/BackupAlphaPlaneMOMDPLite.o ./Bounds/BackupBeliefValuePairMOMDP.o ./Bounds/BackupBeliefValuePairMOMDPLite.o ./Bounds/BeliefValuePair.o ./Bounds/BeliefValuePairPool.o ./Bounds/BeliefValuePairPoolSet.o ./Bounds/BlindLBInitializer.o ./Bounds/FastInfUBInitializer.o ./Bounds/FullObsUBInitializer.o ./Bounds/PruneAlphaPlane.o ./Bounds/PruneBeliefValuePair.o ./Bounds/xml_parse_lib.o ./Core/Actions.o ./Core/VariableContainer.o ./Core/Belief.o ./Core/BeliefCache.o ./Core/BeliefException.o ./Core/BeliefForest.o ./Core/BeliefTreeNode.o ./Core/BeliefWithState.o ./Core/MObject.o ./Core/Observations.o ./Core/States.o ./Core/UniqueBeliefHeap.o ./Parser/Cassandra/Parser.o ./Parser/Cassandra/POMDP.o ./Parser/Cassandra/pomdpCassandraWrapper.o ./Parser/ParserSelector.o ./Parser/POMDPX/FactoredPomdp.o ./Parser/POMDPX/Function.o ./Parser/POMDPX/ObsAct.o ./Parser/POMDPX/PreCEntry.o ./Parser/POMDPX/PreCMatrix.o ./Parser/POMDPX/SparseEntry.o ./Parser/POMDPX/SparseTable.o ./Parser/POMDPX/State.o ./Parser/POMDPX/StateObsAct.o ./Parser/POMDPX/tinystr.o ./Parser/POMDPX/tinyxml.o ./Parser/POMDPX/tinyxmlerror.o ./Parser/POMDPX/tinyxmlparser.o ./Utils/InfoLog.o ./Utils/md5.o ./Utils/md5wrapper.o ./Utils/CPMemUtils.o ./Utils/StatsCollector.o ./Utils/SimulationRewardCollector.o ./Parser/Cassandra/include/pomdp_spec.tab.o ./Parser/Cassandra/include/pomdp_spec.yy.o ./miniposix/getopt.o ./miniposix/getopt1.o ./miniposix/getopt_init.o ./Parser/Cassandra/decision-tree.o ./Parser/Cassandra/imm-reward.o ./Parser/Cassandra/mdpCassandra.o ./Parser/Cassandra/parse_err.o ./Parser/Cassandra/parse_hash.o ./Parser/Cassandra/sparse-matrix.o ./Controller/Controller.o   ./OfflineSolver/solver.o  ./Simulator/Simulator.o  ./Evaluator/Evaluator.o  ./PolicyGraph/PolicyGraph.o  ./PomdpConvertor/convertor.o  ./Controller/testControllerTiger.o \nrm -f libappl.a pomdpsol pomdpsim pomdpeval polgraph pomdpconvert testControllerTiger\nERROR: a 'NAMESPACE' file is required\nremoving \u2018/tmp/RtmpDrJUwI/devtools_install_17fbdfe81/rappl\u2019\nError: Command failed (1)\n```\n\n\n\nThis seems to be related to the fact that I am using the Makefile from the original C program, which I understand isn't the right thing to do, so perhaps this isn't a problem once I figure out how to write the proper Makevars file in place of it, so perhaps this isn't a real issue. (I have a deal to learn still on that front). I was just surprised by the error.\n. I created it with devtools::setup() (actually copied a template created with setup()).  This created a dummy NAMESPACE (that does not have the #Generated by roxygen2: header), and so Roxygen was refusing to overwrite that.  So I deleted the NAMESPACE and wound up with the above error. \n. Thanks @jimhester , very nice!\n. \n@hadley pkgbuild::has_build_tools() returns FALSE and attempts to launch the same dialog in RStudio.  pkgbuild::has_compiler(debug=TRUE) is perfectly happy I think:\n```r\n pkgbuild::has_compiler(debug = TRUE)\nTrying to compile a simple C file\nRunning command /usr/local/lib/R/bin/R \nArguments:\nCMD\nSHLIB\nfoo.c\ngcc -I/usr/local/lib/R/include -DNDEBUG   -I/usr/local/include   -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c foo.c -o foo.o\ngcc -shared -L/usr/local/lib/R/lib -L/usr/local/lib -o foo.so foo.o -L/usr/local/lib/R/lib -lR\n[1] TRUE\n```\n@jimhester , sorry about that. I'll do it in rocker/tidyverse to avoid having to install stuff first:\ndocker pull rocker/tidyverse\ndocker run -p 8787:8787 rocker/tidyverse\nI go to localhost:8787, log in with use/pw rstudio/rstudio.  I run:\nr\ndevtools::install_github(\"hadley/readr\")\nAnd then I get the error.  (current release of devtools on CRAN).  sessionInfo:\n```r\n> sessionInfo() R version 3.4.1 (2017-06-30) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Debian GNU/Linux 9 (stretch)  Matrix products: default BLAS/LAPACK: /usr/lib/libopenblasp-r0.2.19.so  locale:  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C                [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8      [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=C               [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                   [9] LC_ADDRESS=C               LC_TELEPHONE=C             [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C         attached base packages: [1] stats     graphics  grDevices utils     datasets  methods   base       loaded via a namespace (and not attached):  [1] httr_1.3.0      compiler_3.4.1  R6_2.2.2        tools_3.4.1      [5] withr_2.0.0     curl_2.8.1      memoise_1.1.0   git2r_0.19.0     [9] digest_0.6.12   devtools_1.13.3\n\n| >\n\n\n```\nI then try the dev version by first running:\nr\nremotes::install_github(\"hadley/devtools\")\nand repeat the command and get the same error.  I then ran the pkgbuild commands above.  \nI should have stressed, this only happens in RStudio.  Running the exact same container with command-line R docker run --rm -ti rocker/tidyverse R, everything works just fine.  \n. @jimhester Okay, cool, thanks.  Yeah, guess it should have been obvious that it was an IDE issue since it only happened in the IDE, I'm just never sure when R packages are packaging RStudio-specific plugin code.  Guess I should file a bug report in RStudio for this?. Thanks @kevinushey !!  \nI've actually been confused for some time with what RStudio is doing with PATH, so any help would be great. Note that  /usr/local/bin is already in the Debian path, and with precedence over /usr/bin:\ndocker run --rm -ti rocker/rstudio bash \necho $PATH\ngives:\n/usr/lib/rstudio-server/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nAs expected.  (We added `rstudio-server/bin to the path in https://github.com/rocker-org/rocker-versioned/blob/master/rstudio/Dockerfile#L6).\nYet for reasons I have never understood, If I log into RStudio session rather than running the container in CLI mode, I see a different PATH:\n```r\n\nsystem(\"echo $PATH\")\n/usr/bin:/usr/sbin:/bin:/sbin\n```\n\nNo idea why or where that's coming from or how to alter it.  It does not appear to respect the system ENV PATH set in the Dockerfile though.    \nTo work around this, we ended up telling /etc/rstudio/server.conf to use R from /usr/local/bin, otherwise it will instead pick up an R from /usr/bin, if available, and not look in /usr/local/bin/ \nhttps://github.com/rocker-org/rocker-versioned/blob/master/rstudio/Dockerfile#L59-L60\nI'd be happy for any hints on how to get RStudio-server to use the same $PATH I see in the Docker shell...  (Sorry for the tangent to the above issue)\n. Thanks @kevinushey , that sounds likely, lemme know what you discover.  I've wondered if there's a way to set the PATH in rserver.conf or rstudio.conf (https://support.rstudio.com/hc/en-us/articles/200552316-Configuring-the-Server), but can't really find any documentation of what config options are recognized (https://support.rstudio.com/hc/en-us/community/posts/200656527-list-of-all-rserver-conf-rsession-conf-options). Thanks @kevinushey, that's an excellent point.  We actually already do that here: https://github.com/rocker-org/rocker-versioned/blob/master/rstudio/Dockerfile#L52 but it is putting a literal $PATH instead of evaluating it, so it's not much help.  I've just dropped all those escaped parens so that it writes the value of $PATH variable into Renviron, and that seems to do the trick.  Sys.getenv() returns the expected Debian path, and the above issue with devtools is resolved!\n. ",
    "mgagliol": "Don't know if it helps: on my machine, I have a similar issue (with another package, igraph) as /tmp is a tmpfs mounted with option \"noexec\", which means that files are not executable regardless of the permission. As R uses /tmp by default to unpack and build packages, this caused the error in my case. So I solved executing the following before install:\nsudo mount -o remount,exec /tmp\nan alternative would be to tell R to use a different temporary directory but I don't know how..\n. indeed a cleaner alternative is to set TMPDIR to a different location, e.g.\nsh\nexport TMPDIR=~/tmp\nas documented here:\nhttp://cran.r-project.org/doc/manuals/R-admin.html#Running-R\n. @hadley @mkohara a student of mine has the exact same issue, what should she do? For \"dev devtools\" do you mean she should first devtools::install_github(\"r-lib/devtools\") ? Thanks\n. ",
    "jiho": "On 2011-Dec-09, at 02:13 , hadley wickham wrote:\n\nWould you mind extracting out an install_url function?\n\nI was sure you would say that ;) I actually almost did it. There's more than just prodicing a URL though, since the compressions are not the same. But detecting the file extension and acting accordingly should work. No promises as to when I'll do this though.\n. I took a stab a implementing it actually ;)\n. No pressure... right ;)\nI imagined you meant rebasing the branch on the current master. I did this, deleted the old branch and re-pushed the new, rebased branch. Github seems to have kept the connection to the branch because they have the same name. Let me know if you can pull and keep a clean history.\nOn my end, the last commit before the four in this pull-request is 675551435337f3b72, with message \"Use with_env in system_check\" so it looks OK.\n. Here's a new implementation, cleaner I hope, and more in line with httr's API.\nSorry for all the small commits, I spotted some mistakes only when reviewing the changes here. It should be possible to squash them before pulling the code I guess.\n. OK, did not think of it.\nOverriding ? would be very nice indeed!\n. I'd say that github.user is general enough to stay that way don't you think?\n. Then it requires to:\n- test wether the result is of length > 0 instead of just using any() in the test\n- index using names instead of a boolean vector\nI don't know what is best in general (I'd guess that performance is not an issue here).\n. Done\n. I namespaced options with a devtools. prefix butI find devtools.github.user a bit verbose and think that github.user is explicit enough (and reusable enough) to be used as is. Let me know what you prefer and I'll change it back if need be.\n. Your notes disappeared. Don't know why. Changed back to github.user\n. Hadley wrote:\n\nI wonder if the current .onAttach function should actually be .onLoad \n\nI have no idea ;) I used onLoad because that's what packages distributed with R (stats and so on) use to set options. I considered them as reference.\n. That would stop the whole command if only one package is missing. Here I am using next() to skip the missing one and still proceed with the rest.\n. Then I need to force fsep to be /, don't I. Because I don't want to have \\ in a URL when executing on a windows box.\nWhat would be the advantage over str_c or paste (the help mentions speed but it's probably irrelevant here given the relative speed of constructing the url and actually downloading the file.\n. OK. What I understood from your email is that I shouldn't bother using handle because httr will take care of re-using the correct handle for me (is that right?). If it is so, then I'll probably pass url to spider_svn rather than a path and a handle.\n. ",
    "baptiste": "either R graphics (grid) or tikz could be considered for this task.\n. Paul Murrell did some work in the direction of drawing with Grid, \nhttp://r-forge.r-project.org/projects/gridgraph/ (using graphviz)\nhttp://www.stat.auckland.ac.nz/~paul/R/Diagram\n. quick thought: moving to a tempdir is probably incompatible with some of\nthe assumptions of the standard official R building process. In particular,\nIIRC one can specify relative paths to e.g data files in the package\ndirectory tree to build the vignette. Not sure where you aim to place such\nwrappers in devtools, following all or only select R core design decisions?\nCheers,\nb.\nOn 10 August 2012 11:02, hadley wickham notifications@github.com wrote:\n\nThanks! Ended up going in a slightly different direction, but the impetus\nto fix it was appreciated. Let me know what you think of my changes.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/pull/127#issuecomment-7652117.\n. it's probably ok actually, just re-read\nhttp://cran.r-project.org/doc/manuals/R-exts.html#Writing-package-vignettes\nand it states:\nThe R working directory for all vignette tests in R CMD check is a copy of the vignette source directory. Make sure all files needed to run the R code in the vignette (data sets, ...) are accessible by either placing them in the inst/doc hierarchy of the source package or by using calls to system.file(). All other files needed to re-make the vignette PDFs (such as LaTeX style files, BiBTeX input files and files for any figures not created by running the code in the vignette) must in the vignette source directory.\n\nthus no need for relative path, system.file() will look for the unusual\nfiles in the installed package (and data() for normal usage). Sorry for the\nwrong warning.\nb.\nOn 15 August 2012 11:35, hadley wickham notifications@github.com wrote:\n\nAre you sure that's true? I think vignettes are supposed to be\nself-contained - if you wanted to get data from data/, shouldn't you just\nbe using the data() function?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/pull/127#issuecomment-7764785.\n. running c++ code seems a bit of an overkill for standard roxygen use (I must be missing out cool things); could it be an option for document() to simply use roxygenise? \nEven then, my c++ code compiles fine outside load_all(), but that's another issue I guess.\n. I still get an error with https://github.com/baptiste/cda/blob/master/R/zzz.r\n\nUpdating cda documentation\nLoading cda\nError in loadRcppModules(direct = FALSE) : \n  loadRcppModules can only be used within a .onLoad function\n. oops, nevermind, seems I was using an old version.\n. Here's a minimal package failing to build with devtools (but fine with R CMD) because of this load_all issue,\nhttps://github.com/baptiste/mini\nNote that Rcpp's internal unit tests seem to have moved away from this loadRcppModules strategy, but I prefer it to expose just the module names and not the module contents in the Namespace (cf direct argument).\n. I tried that, but it becomes too convoluted: it's not having a directory /inst/doc that's deprecated, but rather having Rnw files in it. And testing for that is not amenable to the in_dir() construct you have below...\n. I've made a new commit and tested it on a dummy package (minus the texi2pdf step which fails on my machine for some reason). \nPS: I'm off to India + Europe for a month, won't be able to do follow this up\n. ",
    "tekumara": "has_devel() returns TRUE.\n. PS: I've now tried this on the same package in both my Windows and Linux development environments and I get the same error.\n. I've tried this an I get the same message with no details: Error:\nCommand failed (1)\nOn 17 January 2012 02:18, hadley wickham\nreply@reply.github.com\nwrote:\n\nCould you please try:\n``` R\nbuilt_path <- build(pkg, tempdir())\n\u00a0devtools:::R(paste(\"CMD check \", built_path, sep = \"\"), tempdir())\n```\nwhere pkg is the full path to your package. \u00a0Something must be going wrong with the generation of the R CMD check command.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/42#issuecomment-3510534\n. \"(SET LC_ALL=C) && \\\"C:/Program Files/R/R-2.14.0/bin/i386/R\\\" CMD check d:/workspace/simar\"\n. I think I've found the problem. I'm running R using StatET inside Eclipse. It seems StatET isn't capturing the output from the check. When I run it in R GUI it works.\n. This is a StatET issue. To see the standard output console window edit the Run Configuration and on the Common tab check \"Allocate additional Error Log Consoles\". Output from the system command and devtools commands like check will appear on this additional console view.\nSee the thread http://lists.r-forge.r-project.org/pipermail/statet-user/2012-February/001241.html for more details.\n. \n",
    "rpruim": "Sounds like a good solution to me.\n. The trouble with a Makefile is that it requires users to know one more thing.  It would be nicer if it were an R file.  Anyone making an R package will know how an R file works.  They may or may not know how to build a sane Makefile.  Besides, the things that one is likely to want to do are R-ish (like running roxygen).\nBut if a Makefile is the simplest way, it will likely solve my problems.\nBut I suppose this is pretty low priority, since having the Rd files in the repository is not so terrible.  (And as a side effect, it reminds you which documentation has changed when you do your commits.)\n. I think the culprit is the last line of install_local_single()\nr\ninstall(pkg_path, local = TRUE, quiet = quiet, ...)\n. It looks like you are right about local=FALSE working correctly with an updated devtools.  Sorry about that.  But I still think that vignettes should be built by default rather than requiring an option to be set.\n. I wonder if when you figure this out it will answer another question I have:  Is it possible to create a vignette (Rnw -> PDF) that has links to files that will be installed with the package (in inst/PDF, for example)?\n. PDFs created using Rnw files but also including lots of additional images and using resampling, so they are slow to generate.  I don't want to regenerate them every time I check the package :(  Furthermore, the files use some custom style files.  So it seems simpler just to get the PDF compiled and provide it as a done deal.\nMy current solution is to put the PDFs in inst/PDFS and then put a real vignette with links to these on github (even though the files are actually also inside the package).\nI suppose the other option would be to include them as additional documentation that isn't a vignette, but then they don't show up when searching for vignettes.\n. Actually, I think the problem is the other way around -- you need to have an OLD version of git2r.  Looks like the verbose argument to git2r::status() was recently removed (at @hadley's suggestion).  The change is not backward compitable and now using verbose = FALSE produces and error.\nI get this same error using R 3.2.0 using both CRAN and github versions of git2r with both CRAN and github versions of devtools:\n``` r\n\ndevtools::release()\nError in git2r::status(r, verbose = FALSE) : \n  unused argument (verbose = FALSE)\ntraceback()\n4: git2r::status(r, verbose = FALSE)\n3: vapply(git2r::status(r, verbose = FALSE), length, integer(1))\n2: git_uncommitted(pkg$path)\n1: devtools::release()\nargs(git2r::status)\nfunction (repo, staged = TRUE, unstaged = TRUE, untracked = TRUE, \n    ignored = FALSE) \nNULL\n```\n\nBut if we roll back a couple weeks to\nr\ninstall_github(\"ropensci/git2r\", ref=\"66e1523872b5edeaf1c4fd2b753fd99e305994d1\")\nthen we get an out-of-date warning, but things go through:\n``` r\n\ndevtools::release()\nWarning: DR_DEVTOOLS FOUND PROBLEMS\n* Devtools or dependencies out of date: git2r\n```\n\nUnfortunately, git2r was just submitted to CRAN, so it is a little late to get the backward compatibility and just have it ignore verbose = FALSE.\n. Perhaps the message could change.  I did not have \"uncommited changes\".  Perhaps \"uncomitted changes or untracked files\" would be better.  Even better would be to have it detect which problem exists and report accordingly.\nWhile I do use .gitignore, I often have a handful of files that are not required for building the package, but I haven't decided about regarding being on github.  These are things like notes to myself in data-raw/.  I leave them untracked to keep them on my radar.\n. I like the reminder as well, so I'm not complaining about that.  And being reminded about untracked files is good too, because I sometimes forget to add in derived files (like .Rd files).  But the message makes it sound like there are modified, tracked files in need of committing.\n. ",
    "krlmlr": "Maintaining those .Rd files in parallel is a real pain, especially when working on repositories that are roxygenized with a not-so-up-to-date version of roxygen2. May I suggest reconsidering this? To trigger this, we could use a mechanism similar to that employed by roxygen2 to indicate if wrapping is enabled:\nDevtools: list(pre_build=Rd2roxygen::rab('.'))\nor something along these lines.\nWhat's wrong with creating documentation during build/install from src/Makefile? The following seems to work for me:\nRscript -e 'devtools::install_github(\"krlmlr/R-pkg-template@auto-roxygenize\")'\nSource: https://github.com/krlmlr/R-pkg-template/tree/auto-roxygenize\n(The NAMESPACE and DESCRIPTION files might be an issue, not sure if these get updated. But the .Rd files seem to be generated and installed properly.)\n. Thanks for your feedback.\n1. In an ideal world, yes. But these services tend to be even more difficult to set up (e.g., private key to the repo to push back to). Also, currently this would work only for GitHub and only for Travis CI.\n2. A Windows user who wants to install from source needs Rtools -> Cygwin make, when installing from binary the .Rd files are already generated through R CMD build. For other OSs we can really assume the existence of make, otherwise many other packages that need compilation are not installable either. Could you describe a relevant situation where make is not available? \n. 1. Perhaps rstudio.com could provide such a service, based on (a fork of) Travis CI?\n2. Installing from source requires extra one-time effort from the user. But installing Rtools is very simple, and so I assume is installing xcode on OS X. (Isn't it even required for install_github?) Also, both platforms allow for \"binary\" packages. (There's nothing like WinBuilder on OS X, is it?)\nTo sum up the discussion:\n- devtools is not the right place to implement roxygenize-before-build\n- A CI service would be better for that, but currently there's nothing that would be easy to use\n- Roxygenizing via src/Makefile could work but requires further investigation and an installation of Rtools/xcode on Windows/OS X\nHow to proceed from here to be able to keep the redundant .Rd files out of the Git tree one day?\n. @yihui: This is really evil. And beautiful. What do you mean by \"no devtools support\" -- no devtools support needed? This won't appear in the installed DESCRIPTION file, right? Were you able to place such a package on CRAN?\n. @hadley: Technically it's possible to keep .Rd files out of a Git repository, only that install_github doesn't work anymore. Would you review a pull request that allows pre-build actions to be executed by devtools? Perhaps configurable with a Devtools: list(...) field in DESCRIPTION. Once implemented in devtools, these could be adopted later by R CMD build if they turn out to be useful.\n. I can't replicate this issue with R 3.2.0, data.table 1.9.4 and devtools 1.8.0. Need to create a NAMESPACE file to get rid of a R CMD check warning; code for myfunction also had errors. Full script:\n```\nlibrary(devtools)\nsetwd(tempdir())\nmake dummy package called foo\ncreate(\"foo\")\nsetwd(\"foo\")\nadd data.table as a package dependency\na <- readLines(\"DESCRIPTION\")\ndepends.idx <- grepl(\"Depends\", a)\na[depends.idx] <- paste0(a[depends.idx], \", data.table\")\nwriteLines(a, \"DESCRIPTION\")\nwriteLines(\"import(data.table)\", \"NAMESPACE\")\ncreate a dummy function\nwriteLines(\"myfunction <- function() {a <- data.table(b=1); return(a[,'b'])}\",\n            \"R/foo.R\")\ncheck and throw error\ncheck() # fails but documents and compiles\nlibrary(foo)\nmyfunction()\nsessionInfo()\n```\n. May I suggest storing the output of\nsed -n '/^@chapter Tools$/,/^@node/p' R-ints.texi\n(i.e., the lines between @chapter Tools and the following @node) in a .save file and comparing with the current state in Travis? These checks should be active for the master branch only, to avoid false positives for pull requests.\nThe problem with simply monitoring the file is that only a small share of changes actually affects the section that describes the checks.\n. Related: #43.\n. I had the same problems as described above. After installing https://dl.dropbox.com/u/41902/devtools_1.1.zip, I'm now seeing the following error message (with R 3.0.0):\nError: package \u2018devtools\u2019 was built before R 3.0.0: please re-install it\n. @hadley: Would you accept a pull request that, by default, installs from all directories that contain a DESCRIPTION file? Again, I would like enable this for all installation functions -- I believe this is a useful feature.\nThe search is pruned once a DESCRIPTION file is found. Assuming the following tree,\na/DESCRIPTION\nb/DESCRIPTION\nb/c/DESCRIPTION\nonly packages a and b would be installed. This means that the current use case of the install_* function without explicitly specifying the subdir argument works just the same for those cases where it works now, and auto-discovers packages hidden in subdirectories.\n. ## Reasons for supporting auto-discovery of subdirectories\nTwo main reasons, and a minor one:\n1. Continuous integration\n2. Being able to place extra files (Makefile, helper scripts, ...) in the same repository, including hidden files\n3. Keeping related packages in one repo, installing them simultaneously\nCI\nI would like to use continuous integration for my R packages, and builds on all platforms, automatically, without having to setup and maintain extra infrastructure and three operating systems. As far as I'm aware, there are only two services that offer this: R-Forge and Rforge. You have opted for GitHub in this SO question, but does it provide a CI facility for R packages? Ben Bolker's answer compares the number of packages in each of the hosters, and to date it just seems that R-Forge has many more packages. Also, they have announced moving their servers, but I'm not sure if and how this affects reliability.\nI'm not even thinking about hosting my files at R-Forge. GitHub it is. But I intend to push code to their SVN repo to have packages tested and built for different platforms. And for this, it is easiest if GitHub and R-Forge SVN layouts match.\nExtra files\nKeeping the package in a subdirectory allows for perfect separation, even if R takes some care not to install files it doesn't need.\nMultiple packages\nA feature nice to have, but then we'd also have to think about package order.\nExplaining to end users\nMy incentive for looking into this is that\ninstall_github('package', 'gh-user')\nshould just work, no matter what the layout is. Documentation draft:\n\nAll install* functions, by default, scan the entire directory tree for files named DESCRIPTION. If a directory contains such a file, it is assumed to be the root of a package, and no further subdirectories are scanned. After that, all discovered packages are installed, the first failure stops (but does not roll back) the installation process. You can override this behavior by explicitly specifying a subdirectory using the subdir parameter, in this case no recursive search is performed.\n\ninstall_r_forge\nI'm not sure about its semantics. If it just maps to install_github(..., subdir=\"pkg\") then this is by far the easiest way. And if my argumentation is not convincing, that could be an alternative. If you mean pulling from R-Forge's SVN, then this means adding a whole layer of infrastructure just to do the SVN checkout. Installing packages compiled by R-Forge is already solved using\ninstall.packages(..., repos=\"http://R-Forge.R-project.org\")\n. Thanks for the advice concerning .Rbuildignore. Hope there'll be Travis CI for R soon, or an improved R-Forge service. I do realize that I should have used a different title for this issue ;-)\n. Well, the purpose of this patch was that install_github and friends installs a package also if it sits in the pkg subdirectory. An install_r_forge function won't help much. Let me close this and propose an alternative.\n. What if there is no unzip executable, e.g., on Windows?\n. Hasn't this been fixed in #328? Could you try installing the most recent version of devtools from GitHub?\n. This would be a great feature. How about the following syntax:\ninstall_github(\"user/repo[/subdir]*\")\n? (Of course, in addition to a new parameter to install_github.)\n. @hadley: A single-character flag such as the asterisk is much shorter, and easier to type. Hash and @ are taken, they also mean something in Git/GitHub. I'm not sure there's a special character connected with releases, except that they are a kind of a tag. So, the @ would be appropriate -- how about a combination of @ with another special character, like @* for \"latest\" (intuition: any robust ref) and @! for \"released\"?\n@randy3k: CRAN discourages too frequent releases, they suggest\n\nonce every 1-2 months seems appropriate.\n. From man git-check-ref-format:\nGit imposes the following rules on how references are named:\n1. ...\n2. ...\n3. ...\n4. They cannot have ASCII control characters (i.e. bytes whose values are lower than \\040, or \\177 DEL), space, tilde ~, caret ^, or colon : anywhere.\n5. They cannot have question-mark ?, asterisk *, or open bracket [ anywhere. See the --refspec-pattern option below for an exception to this rule.\n6. ...\n7. They cannot end with a dot ..\n8. ...\n9. They cannot be the single character @.\n\nAnd below:\n\n--refspec-pattern\n          Interpret  as a reference name pattern for a refspec (as used with remote repositories). If this option is enabled,  is allowed to contain a single * in place of a one full pathname component (e.g., foo/*/bar but not foo/bar*).\n\nTo me, this means we can use at least @ + any of ~^:?*.@ without having to fear conflicts. I still prefer @*.\n. implemented in #355 .\n. #380.\n. There is no invalid input to this routine, everything can be decomposed one way or another. (Haven't tested with multiline strings, though...). The regular expressions deliberately don't check for bad input, but they could.\n. Wrong: \"test#6@123\" does not parse. Will fix.\n. There seem to be issues with the source_gist examples (https://travis-ci.org/hadley/devtools/builds/14391000). Why are they run anyway?\n. Just rebased to current master, but this isn't going to fix the tests, is it?\n. No, the tests seem to be fine now.\n. Squashed and added docs/NEWS.\n. I have no idea, but it is: see e.g. https://travis-ci.org/krlmlr/devtools/builds/14389165 (a build without the changes).\n. There's a trivial conflict with #390, but I can resolve that once your PR is merged.\n. @hadley: Do you intend to merge this? I can rebase #390 onto this PR beforehand, or wait until this PR is merged.\n. That's what I get for not testing it... A fix is just being tested by Travis.\n@hadley: I need to mock github_pull_info for a unit test. I have a hack, but I was wondering if there are any recommended techniques. A StackOverflow search for [testthat] mock returned no results, and a post to R-devel hasn't been answered.\n. @wch: Thanks for the writeup. Perhaps one day... For now, I hope my hack will do.\n. Travis shows errors because texi2dvi (i.e., LaTeX) is not installed. Do we want to install LaTeX for four tests, or do we just skip them if texi2dvi is not available?\n. Ready for merging. Added LaTeX for now so that the current codebase doesn't throw errors.\n. Rebased to current master.\n. Other options to add:\n- Integrate with r-travis\n- Add version control (probably Git)\n- Add README and/or NEWS files\n- Add RStudio project file\n- Boilerplate for package documentation\n- ...\nThe choice of options could be performed by a new parameter.\nWould this justify a dedicated package just for that purpose?\n. Then there might be no need to support the simple document = TRUE syntax.\n. The beauty of install_github is that you can install any ref or even pull request. Any mirroring technique will have to provide this to be of equivalent use.\nI agree that pre-building in devtools has to be painless for the user.\nThe article about storing compiled files is a nice solution, but the setup is slightly complicated. Not all updates of .Rd files cause a merge conflict. If a small tool would take care about those details -- great!\n. @hadley: Can we agree on making the BuildDepends dependency optional for build and install but mandatory for check and release? I think otherwise the requirement that \"pre-building has to be painless for the user\" cannot be satisfied easily. It's \"only\" documentation, if the user needs it he can take appropriate action to ensure it is installed; if not there's no need to abort installation because a dependency is missing.\n. You could still maintain a branch of \"released\" versions that does contain the roxygenized files:\nA===B===C===D===E===F===G===...\n \\                   \\\n  R1==================R2=========...\nHere, A till G represent the development branch, and R1 and R2 are releases; the .Rd files are contained in the release branch.\nThe other issues you mentioned could be mitigated by a packrat-like approach. (Really using packrat would require rstudio/packrat#31.) While this seems overkill just for the task at hand, this also allows \"controlled upgrading\" of dependencies -- see the comments in the linked issue.\n. This is similar with packages that need compilation: On Windows, you need Rtools. I think, non-expert users shouldn't have to be using install_github in the first place, but this requires some infrastructure, e.g., as outlined in rpkg/rep.\n. Would you support an argument document = TRUE for build()?\n. Will this also speed up installing and checking from within RStudio (provided that I set options(Ncpus))?\n. The first issue seems to be a temporary one, I can install using your command. The second issue has been fixed (but not yet merged) in #390.\nAlso related: #388 (where the second issue has been reported first).\n. I can now replicate the first issue in a \"clean\" environment (from packrat), not sure why it does not occur in my \"regular\" environment. Can be fixed by passing\n, config = add_headers(\"User-agent\" = \"hadley/devtools\")\nto the GET call in github_pull_info. I'm about to submit a pull request.\n. The build seems to fail because docs are out of sync with code. Roxygenizing could help. (Perhaps Travis should run roxygenize to avoid this kind of error?) See also #397.\n. Removed compatibility code and merged to master.\n. That would be great, hit me today when I forgot to ask about it. It seems that ftpUpload isn't vectorized, an extra lapply would be required.\nI'll send a pull.\n. I use git status --porcelain, there is no output iff the w.c. is clean. The code in the sha1 function should read sha <- paste0(...), I think.\n. In #390, fixed now.\n. Same on Ubuntu.\n. Just thought of another, perhaps more elegant option:\nwith_something <- function(set) {\n  function(..., code) {\n    old <- set(...)\n    on.exit(set(old))\n    force(code)\n  }\n}\nHowever, this would require special handling if missing(code) to maintain backward compatibility. Tricky. (?)\n. Failing test run: https://travis-ci.org/krlmlr/devtools/builds/20538142\n. What is the preferable/intended syntax anyway?\n1. with_options(c(scipen=999), ...)\n2. with_options(scipen=999, ...)\nFor 2. (my favorite), we can leave with_something as it is, and hard-code with_options or define\nwith_anything <- function(set) {\n  function(..., code) {\n    old <- set(...)\n    on.exit(set(old))\n    force(code)\n  }\n}\n. Merged with master, ready for pulling.\nI was thinking about moving all of the with_... functionality to a separate package. This paradigm could be useful also outside of package development. Would you support this?\n. I think I've addressed all issues.\n. @wch: That's a corner case that hasn't been tested yet.\n@randyzwitch: Does it work when you omit the trailing slash?\n. To me, this looks very similar to #397. \n. Trying to update a tag will result in the same SHA1 as the installed version, this could be handled with a message. Trying to update a version that has a SHA1 but no GithubRef can be even detected early. Other than that -- perhaps I'm missing something, but wouldn't a GitHub update be equivalent to install_github(\"GithubUsername/GithubRepo@GithubRef\")?\nUpdating everything would be even nicer, in my opinion update_github() would be a prerequisite to update(). ?\n. #350 (support for releases) could be relevant.\n. I'm fine with saying dep=NA if I don't need the suggested packages. The problem is that now the dependencies parameter is ignored -- install_github_single is called with dependencies = TRUE, and this PR fixes it.\n. The following works on my machine:\ndevtools::install_github('rstudio/shiny@feature/bootstrap-layout')\nThe branch feature/mask-reactive-context doesn't seem to exist in the GitHub repo.\n. These are part of the API documentation. It just happens that the API is convenient enough here to 302 us to the right link. See also my SO post.\nSo, I guess, yes, they're more stable.\n. @hadley: This is a prerequesite to #475, do you want to review and merge this first?\n. Should be good now.\n. @tbates: Seconded: more than 500 hits in GitHub code, the dictionaries really have to catch up here.\n. I have asked GitHub what they think about it. Hope they reply soon.\n. Ivan \u017du\u017eak from GitHub support has replied. Below are the relevant parts of the conversation:\n\n\n\n\nAfter changing an R package to use GitHub API for downloading ZIP archives instead of the https://github.com/user/repo/archive/master.zip syntax, a user complains about \"forbidden\" messages when using the new implementation that don't occur with the old one: https://github.com/hadley/devtools/pull/474 . Could you please comment?\n\nIn order to keep the API fast and reliable for all our users, the API indeed has rate limiting in place:\nhttps://developer.github.com/v3/#rate-limiting\nThe rate limit is 60 reqs/hour per IP for anonymous requests, and 5000 reqs/hour per user for authenticated requests. The message which the user received from the API (\"API rate limit exceeded\" from my IP address\") indicates that the user is making anonymous request, and hit the 60 reqs/hour rate limit. In addition to that message, the API also told the user: \"But here's the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.\".\nAnd that's the advice I can recommend here -- instead of making anonymous requests, use an OAuth token and make authenticated requests. Anonymous requests are good for drive-by testing, but shouldn't be used for development in real environments, as it's pretty easy to hit the rate limit.\n\nWould you advise using the \"old\" URL syntax in this case, to avoid hitting the API rate limit? Or would you perhaps consider raising the limit for this specific API?\n\nMy advice would be to use the API because that's what the API was designed for. The Web UI is intended to be used by humans, and the API is intended to be used by our machine friends. \nI'm not sure why that user is hitting the 60 reqs/hour -- it might be because he shares the IP address with other users who are making requests to the API, or it might be because he's making lots of requests to the API himself. Increasing the rate limit is not a possibility -- as I mentioned, these rate limits are in place to provide a fast a reliable service you depend upon.\nMost tools for installing packages by downloading from GitHub (e.g. composer) allow users to authenticate in case they're hitting the rate limit (e.g. if they're installing lots of packages, or a package which has lots of dependencies). This doesn't need to be a requirement, it can be an option to help users continue working instead of getting stuck and waiting for an hour for the rate limit quota to refresh. From our experience, users have never had any problems with this approach.\n\nI think we have the following options here:\n1. Revert to the old behavior if no authentication is provided by the user (contrary to Ivan's advice)\n2. Show the user a nicer warning if the rate limit is exceeded (seems to come with the response header in the X-RateLimit-* fields)\n3. Set up a few dummy accounts that can be used at random when no authentication is provided (prone to misuse)\n. I think it's 60 API requests in total per hour.\n(1) would only use the \"old\" URL if no authentication is provided; with authentication, there is a much lower risk to hit the rate limit, and so the \"new\" API access (=current implementation) can be used.\nPerhaps we should at the very least show the message \"API rate limit exceeded\", I'm sure it can be obtained from what httr::GET returns.\n. Would (2) work with authentication, i.e. for private repos or enterprise installations?\n. There is httr::GET which is used all over the place. The URL scheme you mentioned is precisely the one currently in use (see the list of changes for this PR).\n. I'm not sure I understand correctly. Wouldn't even querying the correct URL count as an API access, subject to the rate limit?\nThe call at line 113 is an API call that will just get the file, as is the call at line 197. (The latter won't get a file, but query the branch and user name.)\n. Line 113 is a documented API call. GitHub probably won't change this, at least for v3 of the API. On the other hand, the URL used previously might actually change without notice.\n. I'll update this pull request.\n. Done. There's still potential for expansion:\n- Only named releases are installed, need to use a different API for tags\n- Only latest release installed, possible to look at the previous release, or even at a release before/after a certain date\n- Doesn't distinguish between pre-releases and full releases\n. How about *release? (The asterisk is used because it's illegal in branch names.) See also my earlier comment.\n. Should it be hadley/devtools@*release or hadley/devtools*release?\n. Current implementation uses hadley/devtools@*release.\n. We don't have tests for github_resolve_ref.* yet. I'll try to implement those using a mock for github_GET, and add the tests to this PR.\n. Done -- enhanced tests, installation works, all tests pass locally.\n. You could still create two files test-that-1.R and test-that-2.R, where each uses a different filter argument in their test_check call, and organize your test files accordingly. This should produce one output line per file, and you can even easily decide not to run the longer tests on CRAN's machines.\n. Do you mean something like this:\n```\ngithub_ref <- function(x) UseMethod(\"github_ref\")\ngithub_ref.default <- function(x) list(ref=x)\ngithub_ref.pull <- function(x) {\n  list(repo=xxx, username=yyy, ref=zzz)\n}\ngithub_pull <- function(pull) structure(pull, class=\"pull\")\nin github_get_conn:\nref_params <- github_ref(ref)\nparams[names(ref_params)] <- ref_params\n```\n?\n. This implementation seems to work for me.\n. Should be okay now.\n. I've rewritten the patch, the refactoring is now gone -- too many special cases.\n. Added a section to the .yml file so that artifacts created by the build (including binary .zip file) are deployed to AppVeyor. Ready for merging.\n. Missed that, sorry.\n. If implemented carefully, this will allow automatic verification (in the tests) that all routines that change files in the working copy actually touch only a well-defined set of files. Anyway, git2r is not on CRAN yet, no point in discussing this further at this stage.\n. I could have it (mostly) ready by tomorrow evening. Are you thinking about delaying CRAN submission?\n. A new function bump(pos, delimiter), intended to be called manually or (optionally) after a successful check().\n. @hadley: A few tasks are now gone, the remaining ones should be more or less robust. How should we configure package-specific actions (if at all)?\n. It's not hard to do by hand, but if it's automated you can assign new version identifiers more often, and it's less error-prone.\nUpdating NEWS.md works for me by means of a NEWS.md.tmpl file with placeholders for version and date. The file (with placeholders expanded) is prepended to NEWS.md. I'd add also a function that creates this .tmpl file and adds it to .Rbuildignore. How do you like this approach?\n. I have to take a closer look. This might be related to #603.\n. The note also occurs with devtools::check(check_version = TRUE). It is related to an unset repos option.\nFrom the description of R startup, I guess we'll have to:\n- [ ] fabricate a one-line .Rprofile\n- [ ] set the R_PROFILE_USER environment variable to that file\n- [ ] use --no-site-file --no-environ instead of --vanilla\nHow about adding a new argument with_repos = FALSE to the internal R function?\n. We seem to need all of the three above -- our own .Rprofile, setting the env var and changing command-line arguments. The .Rprofile would look like this:\noptions(repos=c(CRAN=\"http://cran.rstudio.com\"))\n. Detection if a pre-built manual is necessary happens here: https://github.com/wch/r-source/blob/2b9bb44c6f9b03bd05b06823592b0c2ad0fa5b30/src/library/tools/R/QC.R#L6683. I'd rather not replicate this check.\nI was thinking about adding a new field to DESCRIPTION, like DevtoolsBuildOptions or DevtoolsBuildManual. Of course, simply having extra arguments to release() is much easier to implement.\nAs releases tend to happen rarely, I think I'll stick with simply adding arguments.\n. Is a pre-built manual always required? Are you going to implement this, or would you like me to resubmit?\n. If you look at the code, the manual actually is built only if necessary, even if --no-manual is omitted. So, this is the way to go.\n. I'm using this branch to release tikzDevice that requires compaction of its vignette in order to satisfy R CMD check. Would you consider reopening this pull request?\n. No doubt. It just hurts when you try to do it the other way round. Related: #593.\n. Before submitting a PR, I wanted to hear opinions. Personally, I think that tools should adopt to workflows, not the other way round.\nI'd like to look further into this issue. What would be a good name for the new function?\n. I have the following in my .Rprofile, among other things:\noptions(\n  devtools.desc = list(Encoding = \"UTF-8\", Version = \"0.0-0\")\n)\n. But two version components (e.g., 2.5) should be okay, too?\n. Would setup() work, too?\n. I love sed ;-)\n. Thanks for the review.\n. Could you please post your sessionInfo() or devtools::session_info()?\n. This is strange. Have you tried reinstalling? setup() should be available even in the CRAN version.\n. This is amazing, looking forward to it!\n. Would you consider exporting check_failures()?\n. @hadley: Thanks -- system.file seems to return the correct path. However, this means that I need to figure out the name of the package that is being installed -- getNamespaceName(parent.frame()) didn't produce useful results for the test() and document() cases but works for R CMD check and R CMD INSTALL. (I'll take a look at this issue as well -- according to getNamespaceInfo it seems that we need to place an object named .__NAMESPACE__. in the package's environment.) I have updated the test package.\n@wch: No, CWD is package root when running those tests.\n. Code is explicitly loaded with R/ as current directory: https://github.com/hadley/devtools/blob/master/R/load-code.r#L26.\n@gaborcsardi: Thanks, didn't know that. This function expects an object named .packageName in the environment. Actually, both packageName() and getNamespaceName(...) seem to work from devtools -- not sure why I assumed otherwise.\n. The error message can be tested by executing devtools::load_all(\"tests/testthat/loadError\"), on R 3.1.2 it looks like this:\n```\n\ndevtools::load_all(\"tests/testthat/testError/\")\nLoading testError\nError in eval(expr, envir, enclos) (from error.r#7) : This is an error!\n```\n\nI can't find a way to test the format of the file-line output, this is not part of the error message. Where does it come from?\n. Merged.\n. Okay. Perhaps it would be helpful then to clear the vignettes directory and to supply a doc/index.html explaining why the vignettes are missing. The auto-generated doc/index.html is rubbish, try e.g. browsing the documentation index of R.rsp after devtools::install_github(\"HenrikBengtsson/R.rsp\"):\nR.rsp::     R packages: Static PDF and HTML vignettes   source  \nR.rsp::     R packages: LaTeX vignettes                 source  \nR.rsp::     Dynamic document creation using RSP         source  \nR.rsp::     RSP Markup Language - Reference Card        source  \nR.rsp::     R packages: RSP vignettes                   source  \nR.rsp::     R packages: Vignettes prior to R 3.0.0      source  \nR.rsp::     Introductory slides on RSP                  source\n. Storing a .md file is helpful, but do you really want to store binary PDF or virtually binary HTML files?\n. I do get warnings if the vignette is too large and can be compressed. I didn't notice any warnings about a substantially larger size of the archive.\n. In this case, git clean -nx would have shown lots of stuff in the tests directory -- ignored via .gitignore but forgot to ignore via .Rbuildignore. (git clean -n would have been empty, -x = \"also clean ignored files\".)\n. It's nice to have this information when you need it -- to double-check if your local configuration matches that on Travis if test results differ. It's just a few lines in the log that are collapsed by default.\n. - Example file that can be extended without having to look up testthat syntax\n- R CMD check doesn't start failing\n. How about\nuse_test <- function(name, pkg = \".\")\nsimilar to use_vignette?\n. Thanks for the review, I've updated the code and also fixed a minor unrelated style issue in 12e6414.\n. I think it's pretty standard on Debian/Ubuntu, at least it's straightforward to install it (via packages aspell and aspell-en, tested on rocker). I guess it can be a pain on Windows or even OS X, that's why I made it optional (with warning).\nThe spell check is part of the \"incoming\" check (see R source reference), which is activated only with check_version = TRUE. Only when R-core chooses to split this logic, it will make sense to include it with cran = TRUE.\n. Updated docs and NEWS. Please document().\n. We could use as.person(eval(parse(text=getOption(\"devtools.desc.author\"))))$email as e-mail address, and perhaps a prompt (in interactive mode) or an argument that allows overriding the maintainer's mail address (for scripting). Not sure if this will make everybody happy, though.\n. Should work now. The implementation hacks into pkg$depends and adds testthat as last dependency. (Not sure about that -- perhaps it should be the first dependency.)\n. Sorry, not yet. Travis doesn't seem to indicate errors with R CMD check: https://travis-ci.org/hadley/devtools/builds/64069778#L1615. (1 error, 1 note, no warning...)\n. Ready for review. Includes two other pull requests, which can also be merged separately. Note that Travis build status seems unreliable (https://github.com/travis-ci/travis-ci/issues/3697).\n. What should go into cran-comments?\n. Updated cran-comments, tests still running.\n. Done, tests pass now.\n. Done. Contains two unrelated code quality improvements in install.r and test-dll.r, hope it's ok.\n. I think the warnings in R CMD check relate to this pull request:\n```\nUndocumented arguments in documentation object 'use_coveralls'\n  \u2018pkg\u2019\nUndocumented arguments in documentation object 'infrastructure'\n  \u2018type\u2019\n```\nThey disappear if I revert 0840e0b.\n. Merged master, checks pass now.\n. Closing for now, feature should be part of a new package to which the existing with_* functions will be migrated. (What should it be called? withr? scoper? set.unset?)\n. Should be good to merge now. I have no idea what's wrong with the coverage -- I've added explicit tests. @jimhester Any idea?\n. Thanks @jimhester for the quick reply. My point is:\n- I have added a test for the new code\n- The test calls with_lib and with_libpaths\n- These call (albeit internally) set_lib et al., which are not covered\n. Thanks. I probably should have been a bit more specific right from the start.\n. Removed the force() call as suggested by @jimhester and added a test to satisfy codecov.\n. Rebased and added NEWS.\n. Just to clarify: The way it is now, all deps of the covr package will be installed from source. Using\nr_binary_packages:\n  - covr\ndoesn't work, because rex is not yet available on Debian. Once covr is on Debian, we might want to use the declaration shown above.\n. Rebased.\n. Rebased, now using tryCatch() instead of try().\n. I remember that this was useful when revdep-checking memoise -- the surveillance package uses Latin1 encoding, and this messes up the summary without this PR. Does that count as test case? :-)\n. @gaborcsardi Does \"description\" have equivalent code for the case of non-ASCII encoding?\n. You're welcome -- it was me who broke it :-)\n. ...and perhaps check that the \"to\" year is current (krlmlr/tibble@cd81dc699e7).\n. Inlined functions, merged master, added NEWS. I'd rather not rebase, because I have other internal branches based on this.\n. Can be worked around by placing data into inst/extdata instead.\n. Comments in closed issues tend to be overlooked. I have no idea how to implement such a feature efficiently, given the data is stored in .rda files, and it may not be worth the effort (hasn't been for me, at least).. Hash + timestamp would be faster, yes. Anyway, this discussion belongs in pkgload now.?. I think it's the same problem, the solution in #941 is more subtle. Let's shelve this for now.\n. It's even a warning, and happens with PDF vignettes.\nhttp://win-builder.r-project.org/48l69H500MSZ/00check.log was created with 3835a87f49 and contains:\n* checking sizes of PDF files under 'inst/doc' ... WARNING\n  'gs+qpdf' made some significant size reductions:\n     compacted 'tikzDevice.pdf' from 1137Kb to 493Kb\n. Didn't think about that. Adding an args argument to release() would be simpler and potentially more useful, would you prefer that? (build_win() already has one.)\n. This seems to be by design, try\ndevtools::install_github(..., build_vignettes = TRUE)\nThe \"build_vignettes\" argument to install() (which is ultimately called) is set to FALSE by default.\n. While you're at it: Is there a way to not install/upgrade remotes, just to install a single package? I tried\ndevtools::install(\"path\", dependencies = FALSE, upgrade_dependencies = FALSE, metadata = NULL)\nto no avail. (Now I know that the \"metadata\" arg does something different, never mind.) To me, it looks like install_dev_remotes() is called unconditionally. For now, I'll be using RCMD(\"INSTALL\") as workaround.\n. There are two more instances of with_libpaths():\nR/check-cran.r:51:  libpaths_orig <- withr::with_libpaths(libpath, {\nR/build.r:72:  withr::with_libpaths(c(temp_lib, .libPaths()), R(cmd, path, quiet = quiet))\n. Merged with master, and replaced instance of with_libpaths() by with_temp_libpaths().\n. Restored lines killed when resolving merge conflicts, added \"dependencies = TRUE\".\n. Nope: I have put together a test script that simulates adding a bullet point to the top of the NEWS file, a merge conflict is raised when trying to merge the second branch. Using .gitattributes helps, but only locally, not on GitHub.\nIn my code, I record the NEWS entries in the bodies of the merge commit messages. Then, just before release, I use\ngit log --first-parent <tag>.. --format=format:\"%b\" | sed \"/^$/d\"\nwhere <tag> is the last released tag. The log command lists precisely the merge commits, the sed removes empty lines.\n. Thanks for looking into it.\n$ make -v\nGNU Make 4.0\nBuilt for x86_64-pc-linux-gnu\nCopyright (C) 1988-2013 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\nIt's strange that I didn't have any problems a few months ago, also with make 4.0. Please feel free to close -- I've worked around it, and it may be just too minor.\n. I forgot to say: If you use R CMD INSTALL $* as recipe in the Makefile, it works again (branch \"parallel-install\" in the test repo). This makes me think that it's something that devtools does that triggers this behavior.\nAlso: Parallel \"make\" doesn't support reading from stdin, could that be the problem here?\n. Just released tikzDevice with\ndevtools::release(args=\"--compact-vignettes=both\")\nusing this branch. Twice. :-)\nAppVeyor fails because of GitHub's rate limiting.\n. I think R CMD check still looks for a manual or tries to build one. This is what I see when pdflatex is not installed and I run check():\n* checking PDF version of manual ... WARNING\nLaTeX errors when creating PDF version.\nThis typically indicates Rd problems.\n* checking PDF version of manual without hyperrefs or index ... ERROR\nRe-running with no redirection of stdout/stderr.\nHmm ... looks like a package\nError in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  : \n  pdflatex is not available\nError in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  : \n  pdflatex is not available\nError in running tools::texi2pdf()\nYou may want to clean up by 'rm -rf /tmp/RtmpFYGkVI/Rd2pdfe41141f346'\n. I think we need to do the check in both places, yes. Optionally we may want to add a new arg \"manual = FALSE\" to check().\n. Missed it.\n. @hadley: makeClusterFunctionsMulticore() is a misnomer, it spawns new R processes and explicitly does not use multicore. The documentation mentions Linux, but I don't see a reason why it shouldn't work on Windows.\n. It might be possible to implement a connector to the snow package, which should work on Windows, too (https://github.com/tudo-r/BatchJobs/issues/114).\n. I have it in all of my packages, not aware of any problems.\n. @jimhester: This is what BatchJob does with the so-called \"multicore\" backend. Perhaps it's easier to implement a Windows (or even R-based) version of the linux-helper?\n. To me, this looks like git_sync_status() with the fetch() call re-enabled. Am I missing anything? What's the advantage of asking fetch_heads()?\n(In other words: I thought git_sync_status() was supposed to do this; the fetch() call is currently disabled there.)\n. I think git_sync_status() is a good template. ahead_behind() does the checking, local branch is in sync if ahead = behind = 0, if behind > 0 the remote has new commits, if ahead > 0 local has new commits. The fetch() call synchronizes with the remote.\nFor the release() check, you'd probably:\n1. try to fetch(), if this fails (offline?) a warning is issued\n2. if fetch() succeeds, check ahead_behind()\n3. if ahead or behind, warn\n. git: works for me on Linux, but not https: . If errors in fetch() raised a warning only, this would still be useful.\n. Is there a reason why the Git-specific checks are not part of the devtools checks in release_checks()? Anyway perhaps it's better to refactor to a new git_checks().\n. I'll work on git_checks() then.\n. Right: The git@github.com remote protocol (for r/w access) seems unsupported, too.\n. @hadley: I got git@github.com remotes working with git2r by installing ssh2 libraries on my system. Could you check the full output of\ninstall.packages(\"git2r\", type = \"source\")\nto see if git2r is configured with SSH support?\n. @hadley: https://github.com/ropensci/git2r/issues/131 might be of interest: SSH remotes should basically work with binary builds on OS X and Windows. Can you confirm? On OS X you'd need to install from source to see if SSH support is enabled.\n. No use case if all releases are tagged as they should be; if revdep was not active for the last release, it's still easy enough to go back to the tag and temporarily install revdep machinery.\n. Changed error message, added pending NEWS. This check is invoked only if NEWS.md exists.\n. Thanks. The code is now using branch_target(), looks like this is the most accurate solution (equivalent to commits(r, n = 1, time = FALSE, topological = FALSE)).\n. I've seen this too, it's handled in dd36872a1786 (part of #1183).\n. #1256 (now merged) relies on the helpers being loaded already by load_all(). We'll need to use helpers = TRUE there, too, or use helpers = FALSE and revert #1256.\n. On that note, I think it would be great if helpers = TRUE added testthat to the search path, so that the testthat functions are available. @hadley: What do you think?\n. Can't replicate with dev version.\n. @jimhester: Could you please merge this, so that I can fix dplyr builds on Travis?\n. I think this is fixed in the dev version of devtools.\n. This grew bigger than anticipated, let me know if you like me to split it.\n. Does this also work for install_deps(\".\", dependencies = TRUE) for dplyr?\n. I can confirm that dtplyr -> dplyr works (https://travis-ci.org/krlmlr/dplyr/builds/129929004), but not dplyr -> dtplyr -> dplyr if I do install_deps(dependencies = TRUE) (https://travis-ci.org/krlmlr/dplyr/builds/129933568). I think the \"release\" build always runs with an empty cache because it's failing.\n. Thanks. Of course I forgot, now it works. My mistake.\nThat's just awesome! Are you planning a release anytime soon?\n. One packages I'm working on installs itself into a temporary library during testing. I'd like to do this in a helper, but that would slow down loading.\nWhat if testthat had a way to reliably determine if it's currently testing or not? The helper code could check this and react accordingly.\nEDIT: I missed @jimhester's suggestion to use\nif (!interactive() || identical(Sys.getenv(\"NOT_CRAN\"), \"true\")) {\n...\n}\nThis works for me, but currently the helpers are always sourced twice.\n. I was able to work around the problem with a multicore future:\nIn the helper:\nslow_result_future <- future::multicore(compute_and_return_result())\nIn the test:\nresult <- future::value(slow_result_future)\nThe future is evaluated in a separate process which doesn't block the main R process. On Windows, you need to use to future::multiprocess() instead.\n. Tested cases: ahead, behind, and offline. Works for me, ready to merge.\n(Tests fail because there's no test coverage for the patch.)\n. Thanks. I think everything's fine now.\n. FWIW, I'm getting good results with a simple shell script: https://github.com/rstats-db/RSQLite/blob/750624bc6f4c568c3a164caa1629b60b89764ca2/revdep/diff.sh.. To me, exposing an internal object via C code falls in the same league as hiding a call to .Internal() from the CRAN checks.\nDirect access to the namespace registry seems necessary so that devtools can emulate package loading, without actually installing the package. Under normal circumstances, this is solely the responsibility of base, and there are good reasons why direct access to the namespace registry is not allowed. On the other hand, devtools tests its package loading mechanism very carefully. To me, this means that exporting the functionality from base is not desired, but it's okay to bend the rules somewhat for devtools.\n. Use explicit version argument, version number at point of release unknown when revdep-checking.\n. Change defaults to send only for problems.\n. Changed defaults to send only for problems, and using explicit version argument. Tested with RSQLite.\n. This patch has been corrupted in master, working on restoring it.\n. Luckily, it was only the master branch in my fork. Please ignore.\n. I'm using a per-repository user/email config, it would be useful to me. This would only kick in if the Git options aren't set globally and option devtools.desc.author is set, and we could give a message that describes what we do.\n. I had #1284 in there for testing, but removed it now.\n. The Bioconductor revdeps are still huge. I don't have access to a recent-enough OS X machine, but I got myself a 16-core Ubuntu server on Azure ;-)\nCan you please summarize the changes you've made in \"devtools\" that are not yet part of \"remotes\" package?\n. Thanks!\n. It's really not much more than a proof of concept now. I'll use this on my machine and update the branch as necessary. Feel free to beta-test, too.\n. I've seen at least one case where a package loaded with load_all() that didn't declare an import in DESCRIPTION couldn't use that import. That also helps, but is not very nice.\nThe following code is a first approximation (use ns_env() inside devtools):\nr\nasNamespace(\"devtools\") %>%\n  parent.env() %>%\n  as.list %>%\n  lapply(environment) %>%\n  purrr::compact() %>%\n  vapply(getPackageName, character(1)) %>%\n  unique\n. Do you want to wrap udapi::get_term()? How about calling for setup() only, and add a release question?\n. Example: https://github.com/rstats-db/RSQLite/blob/8fbcff79424c73605fab99997ca8972ce16d5c6d/revdep/timing.md\n. Merged now.\n. ``` r\n\nrevdep_cache_path_raw(\"\")\n[1] \"/revdep/.cache.rds\"\n```\n. Merged now.\n. Merged now.\n. R CMD INSTALL uses make, of course. This is about automatically inferring dependencies between source and header files.\n\nThe R build system (at least on my system) offers access to predefined rules that build .d files from source files by invoking the compiler with a special switch. These files encode the dependencies in a format readable by make. You're welcome to try it out in bleeding-edge RSQLite.\n. Never mind, devtools::compile_dll() + ccache + gold should work for most users. Does devtools::install() call needs_clean(), like compile_dll() does?\n. You could try #1300 or my m-revdep branch (where I collect revdep-related fixes):\nr\ndevtools::install_github(\"hadley/devtools#1300\")\ndevtools::install_github(\"krlmlr/devtools@m-revdep\")\n. I've been through this with RSQLite. It's a one-time cost, which you can alleviate by setting MAKEFLAGS=-j $(nproc) .\nSee https://github.com/MangoTheCat/remotes/issues/34 for a related discussion; looks like devtools might eventually forward to the \"remotes\" package (#1310).\n. Agreed: Not worth the effort here, perhaps elsewhere.\n. Merged now.\n. I'm still observing this or a similar issue on Windows with devtools 1.12.0. See the AppVeyor test for tibble, it now suggests dplyr; dplyr is installed but imports DBI which is not installed. The same tibble version works on Travis.. I'm switching to using remotes in r-appveyor, perhaps r-travis could do the same?. I'm using git2r to check sync status.\n@stewid: git2r operations seem to hang indefinitely when using the SSH protocol for some users. Does this ring a bell? Relevant code: https://github.com/hadley/devtools/blob/b05bd25c63690e1b61d978888c298c7b19aacbe4/R/git.R#L25-L59. @stewid Thanks! The release() function doesn't currently have a notion of Git credentials. Do we need to change anything?. Yeah, a new git2r::with_clean_clone() would achieve roughly the same. We might want to consider a facility that warns about vcs-ignored files that are not .Rbuildignore-d, because that is usually a mistake (but not always).. Could we use backports by simply copying its R files?. rlang is GPL-3, backports is GPL-2, what am I missing?. Now reading up, dtplyr (and others) have run time registration of S3 methods, we might be able to do something similar.. I don't even remember how to manually upload a package to CRAN ;-) Would be interested to understand the hassle it's causing to you.. Can that add-in output to the \"Build\" pane? I have skimmed through functions exported from rstudioapi but haven't found anything useful.. Also, there's brushthat: https://github.com/krlmlr/brushthat. Runs all tests by default, but can be extended to run single tests.. I think testthis pretty much fits the description of the original issue (minus the separate session), CC @s-fleck.. If we just use test(), this works out of the box with the RStudio IDE, there the test() call seems hard-wired.\n\nI'm fine with a list of test files, because the tests in a file are usually related.\ndevtools?\nHow about a reporter whose sole responsibility it is to capture files with at least one failing test?\n\nI'm going to implement related functionality in brushthat first, we might be able to reuse code from there.. This is much simpler, and a good approach for new packages, but for existing code? Also, I can imagine cases where a test uses functionality across several files.\n(3.) FWIW, devtools::test() already returns a data frame with test and timing results, regardless of the reporter used.. Just found testthis by @s-fleck that offers functionality to run tests associated with a file.. I have implemented this functionality in brushthat -- by default only failing tests are re-run. To sum up:\n\ntestthis already implements the add-in functionality to jump between source and test files, and to run individual tests\nretest() may be useful as a stand-alone functionality, maybe also in testthis\nmaybe testthis and brushthat should really be just one package?\n\nClosing, because this doesn't seem to be a devtools issue at this time.. I suspect this is a temporary problem that will resolve itself in a few hours or days.. Partially solved by use_tidy_versions().. I need to omit --no-manual, but can't because pkgbuild::build() is called with the default setting of manual = FALSE. I have a patch ready.. The winbuilder service allows submitting the same package twice if the version number is different.. Then it's :::. I can take care of it in this PR if you want.. Thanks!. The ... is a much better solution indeed. Can we please have the same for submit_cran()? I need to submit with compile_attributes = FALSE because I need to stay out of sync with Rcpp's opinion for compatibility reasons (https://github.com/krlmlr/bindrcpp/commit/dc4c6f12c8e5eab4d5d550e9bbed8d3cf0c5f346).. This looks related to https://github.com/klutometis/roxygen/issues/822.. Shouldn't deps include, e.g., parse_deps(pkg$suggests) if specified by the dependencies argument?\n. My fault. Patch was accepted (177d7b34005f6aceb81) but overridden later, I haven't fetched the latest version locally.\n. There are many ways to implement github_parse_path. I had hoped mine is sufficiently clear, and even extensible.\n. Will fix.\n. I was afraid that if it comes before install_deps, two versions of devtools will be installed. But I haven't actually checked.\n. Cargo cult. We may as well leave it out if you prefer.\n. Fixed. Sys.which(\"open\") finds /bin/open on my system, so I'm looking for xdg-open first.\n. Done -- I also prefer early termination. Is there a consensus when to use early termination and when to use nested if-s?\n. I like this idea. However, a pull contains of both user name and ref, we'd need to define a class for that. Let me think about it.\n. Fixed in 5c1e503740931449 .\n. This is now a working proof of concept, perhaps we should discuss #509 first.\n. Not if an explicit pull = xxx is passed to install_github -- it will be captured by ... and assigned to pull in the call to install_github_single.\n. They are not intended to be called directly -- the user is not expected to ever call github_ref(). Do we still need to @export?\n. This conflicts with my perception:\n- The tests succeed, both in devtools::test and R CMD check\n- install_github with ref = github_pull(xxx) works correctly when called from a fresh R session\nWhat have I overlooked?\n. I have tested the example you provided in a fresh session without devtools attached, it runs without error. It is true that getS3method(\"github_ref\") doesn't find anything, with or without devtools attached. I have also noticed that the following fails:\ndevtools:::github_ref(devtools:::github_pull(509))\nBoth with and without devtools attached. \nBut I think this only matters if we want the user to call github_ref(), which we don't. Only devtools code is supposed to ever call github_ref(). (I have also tested creating the generic inside the function github_get_conn -- works as well!)\nSince the tests succeed and the implementation works -- may I suggest abstaining from exporting for the time being? Adding an export can be done easily, but un-exporting something hardly ever happens. Also, this would save us from adding documentation for an otherwise useless item.\n. It looks like this is at least very difficult (if not impossible), since the shield URL contains a unique identifier, as in https://ci.appveyor.com/api/projects/status/xtc629xek00o5rui .\n. I've asked support: http://help.appveyor.com/discussions/questions/471-infer-badge-url-from-github-user-repo-name\n. Removed. Thanks, good catch.\n. You mean, in the same .Rd?\n. I've tried before doing it the generic way, but it didn't work out right away.\nCurrently, with_mock is a proof of concept, but I'd be happy to discuss a \"proper\" implementation -- perhaps in the testthat package?\n. Your version is certainly shorter, but I fear that it might take longer for a human to parse that code when trying to figure out what it does. I've reformatted the code to match the other conditional extension of args that happens below.\n. Indeed, I wasn't sure how to propagate the error. Thanks!\n. Makes sense. Checks will be executed more than once, but this shouldn't matter. I've added two tiny improvements to create_description(); they are in separate commits and could be removed from this branch with little effort.\n. Should r_env_vars() be responsible for creating the file, too? A faint smell...\nAnother problem: r_env_vars() is used in contexts where overwriting the user's preference is not necessarily the right thing to do. I'll extract this to a separate function.\n. Hm... --vanilla doesn't imply --no-save, but I agree it's better to add it anyway.\n. Not at all. I was relying on ?Startup which reads\n\nThe command-line option --vanilla implies --no-site-file, --no-init-file, --no-environ and (except for R CMD) --no-restore\n\nbut this refers to startup only and does not seem to list what else is implied by --vanilla. Thanks.\n. Do you really want to use a box this large? Wercker saves the box after each build, for hadleyverse this contributes to 1:30 minutes of build time. I've played with creating a smaller base box tailored to wercker: https://github.com/krlmlr/r-wercker-base; the box is based on drd and includes devtools, lintr and covr.\n. So far I've built upon Dirk and Carl's efforts, but we might be able to squeeze it just a bit further. Note that my image includes devtools and all system deps necessary for it. (It also includes R-devel.)\n. @jimhester: No, I haven't seen your post until now, but somehow you have found mine ;-) Thanks for the credit. -- Wercker steps are a clean solution, it's great you've found the time to implement them.\n. Right, and also the line below. The two functions are not interchangeable. I'm closing this pull.\n. Agreed, but let's not clutter this pull request even more.\n. Do we deprecate with_libpaths then?\n. There is an inconsistency: with_path will append the new path to PATH if add is set, but with_lib should prepend. This inconsistency will be difficult to communicate. Options:\n- Prepend to PATH if add is set\n- Use parameter action = c(\"replace\", \"prefix\", \"suffix\") instead of add for with_path and with_lib\nPlease advise.\nWhile we're at it: The with functions are tremendously useful on their own, how about extracting them to a separate package (with less dependencies ;-) )?\n. @hadley What is the point of calling create_description() in load_all() if the DESCRIPTION file is missing? What was the original intention? The load_all() fails anyway if R and/or man is missing.\n. But why in load_all()?\n. Could you please elaborate? testthat is normally listed in Suggests: and by default would not be loaded by load_all.\n. @hadley Is there anything nicer than this? For some reason, expect_true(!is.null(test(\"...\", ...))) does not seem to work in this particular case.\n. @jimhester Thanks for letting me know. New development should continue there (https://github.com/jimhester/robustr/issues/1, https://github.com/jimhester/robustr/issues/2).\n. @hadley: Do you mind if I import lazyeval and implement a corresponding use_data_ function, as in 9d38ccc126? The above seems to be the only remaining instance of dots().\n. Would the hard-coded PAT below be ever used, if $GITHUB_PAT is empty?\n. Could the lintr-bot become a bottleneck? 5000 reqs/hour is not much.\n. Not sure: 5000 per token vs. 60 per IP-address. Or is it 5000 per token per IP?\nDreaming out loud, we could implement a web service that provides ephemeral read-only GitHub tokens upon request. Each token is linked to a realm, new realms require a timeout (e.g., 1 minute, gradually decreasing) to prevent abuse. CC @gaborcsardi\n. A \"realm\" is just a string that identifies clients. New clients have to wait, existing trusted clients don't. But this doesn't really add any security, just a way to track and perhaps block users.\nWe sample from a list of tokens it if this turns out to become a bottleneck.\nI can't find a reference about publishing tokens other than \"guard them carefully\" ... \"like a password\".\nWhy exactly are we using the API instead of direct download e.g. from https://github.com/hadley/devtools/archive/master.zip?\n. These are good I think -- already merged (#1124, #1136) but didn't have NEWS.\n. package2remote(remote_package_name(...)) looks at the installed package, which may have a different kind of remote than the requested remote.\n. What about \"Enhances\"?\n. What happens if there's a dependency chain like A -> (enhances) B -> (imports) A and I try to install(A) or install_deps(A)?\n. At some point we may want to avoid this question when we \"know\" that all checks succeeded.\n. Would the following work without the globalVariables() call:\nr\ninternal <- get(\".Internal\", envir = baseenv(), mode = \"function\")\ninternal(\"getNamespaceRegistry\"())\n(just curious)\n. Not hard at all, a simple tweak to git_sync_status(). Will change this.\n. ",
    "pchalasani": "Sorry I didn't get to this until now. This is still broken -- I cloned your devtools and installed devtools from the clone, then tried to install a package, and I get the same error as before...\n```\ninstall_github('rapport', 'aL3xa')\nInstalling github repo(s) rapport from aL3xa\nInstalling rapport.zip from https://github.com/aL3xa/rapport/zipball\nInstalling rapport\n checking for file '/private/var/folders/j4/vll_yjq95076jc7bt3nq8z_m0000gn/T/Rtmp7ynxUn/aL3xa-rapport-08e68ca/DESCRIPTION' ... OK\n preparing 'rapport':\n checking DESCRIPTION meta-information ... OK\n checking for LF line-endings in source and make files\n checking for empty or unneeded directories\n looking to see if a 'data/datalist' file should be added\n re-saving .R files as .rda\n  NB: .R converted to .rda: other files may need to be removed\n* building 'rapport_0.31.tar.gz'\nWarning: invalid package '/var/folders/j4/vll_yjq95076jc7bt3nq8z_m0000gn/T//Rtmp7ynxUn/rapport_0.31.tar.gz'\nError: ERROR: no packages specified\nWarning message:\nIn install.packages(built_path, repos = NULL, type = \"source\", ...) :\n  installation of package '/var/folders/j4/vll_yjq95076jc7bt3nq8z_m0000gn/T//Rtmp7ynxUn/rapport_0.31.tar.gz' had non-zero exit status\n.\n\nhas_devel()\ngcc -arch x86_64 -std=gnu99 -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/x86_64  -I/usr/local/include    -fPIC  -g -O2 -c foo.c -o foo.o\ngcc -arch x86_64 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/lib -o foo.so foo.o -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation\n[1] TRUE\nsessionInfo()\nR version 2.14.1 (2011-12-22)\nPlatform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)\n\nlocale:\n[1] C\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_0.5.1\nloaded via a namespace (and not attached):\n[1] RCurl_1.9-4  tools_2.14.1\n```\n. Yes it's still broken... I just installed 'devtools'...\n``````\ni> install_github('knitr', 'yihui')\nInstalling github repo(s) knitr/master from yihui\nInstalling knitr.zip from https://github.com/yihui/knitr/zipball\nInstalling knitr\n checking for file '/private/var/folders/j4/vll_yjq95076jc7bt3nq8z_m0000gn/T/RtmpvnpQPg/yihui-knitr-2fd9a5e/DESCRIPTION' ... OK\n preparing 'knitr':\n checking DESCRIPTION meta-information ... OK\n checking for LF line-endings in source and make files\n checking for empty or unneeded directories\n building 'knitr_0.4.11.tar.gz'\nWarning: invalid package '/var/folders/j4/vll_yjq95076jc7bt3nq8z_m0000gn/T//RtmpvnpQPg/knitr_0.4.11.tar.gz'\nError: ERROR: no packages specified\nError: Command failed (1)\n\nsessionInfo()\nR version 2.14.1 (2011-12-22)\nPlatform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_0.6\nloaded via a namespace (and not attached):\n[1] RCurl_1.9-4  tcltk_2.14.1 tools_2.14.1\n\nhas_devel()\ngcc -arch x86_64 -std=gnu99 -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/x86_64  -I/usr/local/include    -fPIC  -g -O2 -c foo.c -o foo.o\ngcc -arch x86_64 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/lib -o foo.so foo.o -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation\n[1] TRUE\n```\n``````\n. Still same problem...\n\n```\n\nSys.setenv(TMPDIR='/tmp')\ninstall.packages('devtools')\n--- Please select a CRAN mirror for use in this session ---\nLoading Tcl/Tk interface ... done\ntrying URL 'http://cran.case.edu/bin/macosx/leopard/contrib/2.14/devtools_0.6.tgz'\nContent type 'application/x-gzip' length 91490 bytes (89 Kb)\nopened URL\n==================================================\ndownloaded 89 Kb\n\nThe downloaded packages are in\n    /var/folders/j4/vll_yjq95076jc7bt3nq8z_m0000gn/T//Rtmpv9YLgF/downloaded_packages\n\nrequire(devtools)\nLoading required package: devtools\ninstall_github('knitr', 'yihui')\nInstalling github repo(s) knitr/master from yihui\nInstalling knitr.zip from https://github.com/yihui/knitr/zipball\nInstalling knitr\n checking for file '/private/var/folders/j4/vll_yjq95076jc7bt3nq8z_m0000gn/T/Rtmpv9YLgF/yihui-knitr-2fd9a5e/DESCRIPTION' ... OK\n preparing 'knitr':\n checking DESCRIPTION meta-information ... OK\n checking for LF line-endings in source and make files\n checking for empty or unneeded directories\n building 'knitr_0.4.11.tar.gz'\n\nWarning: invalid package '/var/folders/j4/vll_yjq95076jc7bt3nq8z_m0000gn/T//Rtmpv9YLgF/knitr_0.4.11.tar.gz'\nError: ERROR: no packages specified\nError: Command failed (1)\n```\n. ",
    "mnel": "I was using devtools 0.4 (installed using install.packages('devtools')  [I am using  Windows]\nI have installed he development version and now get\nr\ninstall_github('lubridate')\nInstalling github repo(s) lubridate from hadley\nInstalling lubridate.zip from https://github.com/hadley/lubridate/zipball\nError in function (type, msg, asError = TRUE)  : \n  Unknown SSL protocol error in connection to github.com:443\nFollowing through the code, it appears to be a problem with the RCurl functiongetBinaryURL. I have updated RCurl` to the latest version -- but get the same error message.\ninstall_github appears to work perfectly on my MAC.\n. ``` r\nRCurl::curlVersion()\n$age\n[1] 3\n$version\n[1] \"7.19.7\"\n$vesion_num\n[1] 463623\n$host\n[1] \"i386-pc-win32\"\n$features\n      ssl      libz      ntlm largefile       \n        4         8        16       512      1024 \n$ssl_version\n[1] \"OpenSSL/0.9.8l\"\n$ssl_version_num\n[1] 0\n$libz_version\n[1] \"1.2.3\"\n$protocols\n [1] \"tftp\"   \"ftp\"    \"telnet\" \"dict\"   \"ldap\"   \"http\"   \"file\"   \"https\"  \"ftps\"   \"scp\"    \"sftp\"  \n$ares\n[1] \"\"\n```\n. On closer inspection of my computer, I think it is a broader issues with SSL protocols, not an R problem. \n. Sorry about the multiple pushes -- but it is done!\n. The problem is that the  proxy settings are hidden by the adminstrator. \n. Because it appears that the repo identifier within the bit bucket URL is all lowercase regardless of the r package name capitalization.\nOn 20/10/2012, at 2:26 AM, \"Winston Chang\" notifications@github.com<mailto:notifications@github.com> wrote:\nI have to wonder if this is necessary -- install_bitbucket accesses a repository by name and installs the package from the repo. Why is desirable to change the name of the repo that the user asks for?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/pull/175#issuecomment-9605155.\n. ",
    "garrettgman": "Here's more information. The problem disappears when I use check(\"lubridate\", document = F). Also these combinations of code work:\n```\ntest(\"lubridate\")\ntest(\"lubridate\")\ndocument(\"lubridate\", clean = TRUE)\ndocument(\"lubridate\", clean = TRUE)\n```\nand these do not. They give the error above\n```\ntest(\"lubridate\")\ndocument(\"lubridate\", clean = TRUE)\ndocument(\"lubridate\", clean = TRUE)\ntest(\"lubridate\")\n```\n. Yes on mac. Version 2.14.1.\n. Winston, \nWhat was up here? I'm getting some of the behavior you describe above:\n```\n\nlibrary(devtools)\ndevtools::test()\n\n(the test output - everything passes)\nWarning message:\nIn FUN(X[[2L]], ...) :\n  Created a package name, \u20182013-12-17 11:06:29\u2019, when none found\n```\nIt's spooky that a date is involved, but I'm guessing that it's not a lubridate thing. Also, the warning message does not always appear, and it sometimes appears for load_all() -- even though the package loads fine.\n. Winston, \nI was using lubridate, of course :)\nIt's good to know that we can trace the problem to import(methods). Lubridate already lists methods in the dependency field. However, I add imports(methods) to pass R CMD check (it fails on a warning otherwise).\nIs there an alternative way to use methods and pass CRAN's check?\n. This resolved itself when I switched my (apparently bad) version of roxygen2 for cran's. Sorry for the alarm :P \n. We should attempt to detect if pdftex is available, and if not, don't try and install vignettes. - Hadley\n. ",
    "doobwa": "Will do. Thanks.\n. ",
    "lianos": "I'll take a shot at forking + provide pull request if others also find this useful -- just wanted to get some feedback on a good way to name/specify the subdir param I'm proposing.\n. Sorry for being MIA, and also having a typo in my test package as pointed out by @wch.\nI can confirm that the bug has been fixed in @wch's s4 branch, which I guess hasn't been pushed back into devtools/master as this doesn't work using latest in the master branch (currently labeled as Version: 0.8.0.99).\nSorry again for not responding sooner, and thanks for the fix!\n. ",
    "jlehtoma": "@lianos we would definitely find this feature really useful! We're exactly in the situation @BrianDiggs described: maintaining the dev-version in GitHub and pushing the releases to R-Forge for Win and Mac builds. Let me know if there's anything I can do to help.\n. Thanks for looking into this. Here's one repo you can test with:\nhttps://github.com/louhos/soRvi-dev/\nFew notes:\n- Branch rforge-dir-structure is what is on R-forge, so ideally this would work\ninstall_github(repo='soRvi-dev', username='louhos', branch='rforge-dir-structure', subdir='pkg')\n- master is essentially the content of pkg dir in R-Forge; this currently works with install_github\n- Our package currently has (too!) many dependencies, which may cause some trouble\n. ",
    "dmenne": "Result is TRUE and all loc point to the right path.\nDieter\n\n-----Original Message-----\nFrom: hadley wickham [mailto:reply+i-3352490-\n6eb4c6df0b35fd651a6753e3abb7d3d2a7b8bea9-506275@reply.github.com]\nSent: Thursday, February 23, 2012 4:47 PM\nTo: dmenne\nSubject: Re: [devtools] devtools gives false alarm \"Rtools not\ninstalled\" (#65)\nCould you please run\nR\n  loc <- unname(Sys.which(c(\"ls.exe\", \"gcc.exe\")))\n  all(loc != \"\")\nand let me know what the result is?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/65#issuecomment-4138654\n. Nope, I had tried that:\n\n```\n\nnormalizePath(\"d:/rtools/bin\")\n[1] \"d:\\Rtools\\bin\"\nnormalizePath(\"D:/rtools/bin\")\n[1] \"D:\\Rtools\\bin\"\n```\n. Lost in compilation .... Some problem with export of to_lower?\nThis was run in RStudio for easer copy/paste, but same error in rterm.\n\n```\n\nbuild_github_devtools()\nDownloading devtools from https://github.com/hadley/devtools/archive/master.zip\n\"D:/R/R/bin/i386/R\" --vanilla CMD INSTALL \"C:\\Users\\Dieter\\AppData\\Local\\Temp\\RtmpCGNnZo\\devtools-master\" --build \n\n\ninstalling to library 'D:/R/R/library'\ninstalling source package 'devtools' ...\n** libs\n\n*** arch - i386\ngcc -m32 -I\"D:/R/R/include\" -DNDEBUG     -I\"d:/RCompile/CRANpkg/extralibs64/local/include\"     -O3 -Wall  -std=gnu99 -mtune=core2 -c devtools.c -o devtools.o\ngcc -m32 -shared -s -static-libgcc -o devtools.dll tmp.def devtools.o -Ld:/RCompile/CRANpkg/extralibs64/local/lib/i386 -Ld:/RCompile/CRANpkg/extralibs64/local/lib -LD:/R/R/bin/i386 -lR\ninstalling to D:/R/R/library/devtools/libs/i386\nWarning in file.copy(files, dest, overwrite = TRUE) :\n  problem copying .\\devtools.dll to D:\\R\\R\\library\\devtools\\libs\\i386\\devtools.dll: Permission denied\n arch - x64\ngcc -m64 -I\"D:/R/R/include\" -DNDEBUG     -I\"d:/RCompile/CRANpkg/extralibs64/local/include\"     -O2 -Wall  -std=gnu99 -mtune=core2 -c devtools.c -o devtools.o\ngcc -m64 -shared -s -static-libgcc -o devtools.dll tmp.def devtools.o -Ld:/RCompile/CRANpkg/extralibs64/local/lib/x64 -Ld:/RCompile/CRANpkg/extralibs64/local/lib -LD:/R/R/bin/x64 -lR\ninstalling to D:/R/R/library/devtools/libs/x64\n* R\n inst\n preparing package for lazy loading\n help\n installing help indices\n* building package indices\n testing if installed package can be loaded\n arch - i386\nError : .onAttach failed in attachNamespace() for 'devtools', details:\n  call: scan_path_for_rtools(debug)\n  error: could not find function \"to_lower\"\nError: loading failed\nExecution halted\n arch - x64\nError : .onAttach failed in attachNamespace() for 'devtools', details:\n  call: scan_path_for_rtools(debug)\n  error: could not find function \"to_lower\"\nError: loading failed\nExecution halted\nERROR: loading failed for 'i386', 'x64'\n removing 'D:/R/R/library/devtools'\n restoring previous 'D:/R/R/library/devtools'\nWarning in file.copy(lp, dirname(pkgdir), recursive = TRUE) :\n  problem copying D:\\R\\R\\library\\00LOCK-devtools-master\\devtools\\libs\\i386\\devtools.dll to D:\\R\\R\\library\\devtools\\libs\\i386\\devtools.dll: Permission denied\nR version 3.0.3 (2014-03-06)\nPlatform: i386-w64-mingw32/i386 (32-bit)\nlocale:\n[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252    LC_MONETARY=German_Germany.1252\n[4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.4.1.99\nloaded via a namespace (and not attached):\n [1] digest_0.6.4   evaluate_0.5.1 fortunes_1.5-2 httr_0.2       memoise_0.1    parallel_3.0.3 RCurl_1.95-4.1\n [8] stringr_0.6.2  tools_3.0.3    whisker_0.3-2 \n\n```\n. Same error when installed from Github and built in RStudio\n```\n==> Rcmd.exe INSTALL --no-multiarch --with-keep.source devtools\n\ninstalling to library 'D:/R/R/library'\ninstalling source package 'devtools' ...\n libs\ngcc -m32 -I\"D:/R/R/include\" -DNDEBUG     -I\"d:/RCompile/CRANpkg/extralibs64/local/include\"     -O3 -Wall  -std=gnu99 -mtune=core2 -c devtools.c -o devtools.o\ngcc -m32 -shared -s -static-libgcc -o devtools.dll tmp.def devtools.o -Ld:/RCompile/CRANpkg/extralibs64/local/lib/i386 -Ld:/RCompile/CRANpkg/extralibs64/local/lib -LD:/R/R/bin/i386 -lR\ninstalling to D:/R/R/library/devtools/libs/i386\n R\n inst\n preparing package for lazy loading\n** help\n installing help indices\n* building package indices\n testing if installed package can be loaded\nError : .onAttach failed in attachNamespace() for 'devtools', details:\n  call: scan_path_for_rtools(debug)\n  error: could not find function \"to_lower\"\nError: loading failed\nExecution halted\nERROR: loading failed\nremoving 'D:/R/R/library/devtools'\nrestoring previous 'D:/R/R/library/devtools'\n\nExited with status 1.\n```\n. Are you sure you pushed?  Have to go, will try tomorrow.\n. Compiles, builds fine now, but (warning only):\n```\n testing if installed package can be loaded\n* arch - i386\nWARNING: Rtools is required to build R packages, but is not currently installed.\nPlease download and install Rtools 3.1 from http://cran.r-project.org/bin/windows/Rtools/ and then run find_rtools().\n*** arch - x64\nWARNING: Rtools is required to build R packages, but is not currently installed.\nPlease download and install Rtools 3.1 from http://cran.r-project.org/bin/windows/Rtools/ and then run find_rtools().\n* MD5 sums\n```\n. Sorry, I was on the run and did not check carefully. All good now.\n. @jjailaire build(). Works. Sorry I had forgotten to mention it.\n. @jjallaire: \"RStudio no longer recognizes Rtools on the PATH\". Slightly confused; does it mean there should be some environment or RStudio variable which I forgot to set?  This might be a good idea, but there are plenty of other tools that rely on Rtools on the path.\n. @jjallaire: I have installed Rtools31.exe, and the warning is printed even for a trivial vanilla skeleton that compiles correctly.\n. \nI checked, there is no such entry. I reinstalled RTools, no entry was generated. Could it be that it is on of the entries in Setup-RTools, which I cannot select, because the box cannot be scrolled and my path is long?\n\n. The second problem you mentioned It is not specific to RStudio and an everyday nuisance when you work with open source or other UNIX tools, and I shift sequences in my path once a week. \nI will report the problem to Duncan (RTools). Maybe you could mention the registry in  the error message; I never expected you would search there for rtools, because by default the checkbox seems not to be set.\n. Duncan Murdoch has corrected the problem in the installation by truncating the path. And for those who still have the old version: If you blindly click the second checkbox during installation which is covered by the path-text, the \"add to registry\" text will appear, and the path is added to the registry\n. @hadley: I don't think of devtools as an \"build obfuscation^Hhelper tool\" as mentioned in the above reference; thanks for putting your effort into it. \nHowever, it might be helpful to reconsider some environment-fiddling workaround; Ben Goodrich has confirmed at current they have not yet found a solution for packages with precompiled C++.\n. Since loadRcppModules is deprecated, of secondary importance. Use \nRcpp::loadModule(\"stan_fit4linexp_gastro_1b_mod\")\ninstead.\nClosed\n. Thanks, I had already seen this and even went so far as to reinstall R from scratch. Since I can reproduce this on  Windows 32, Windows 64, and an Ubuntu 16.04-Server, I do not believe that it is specific to some locked/stale file.\n. I have to partially correct my findings: The error occurs in load_all\ndevtools::load_all(\".\")\n\nLoading breathteststan\nError in is(module, \"character\") : object 'm' not found. \n",
    "mike-lawrence": "Nope, nothing more than that.\n. ",
    "jjallaire": "Yes, this was merged into master some time ago.\nOn Fri, Jan 30, 2015 at 2:33 PM, Antonio Piccolboni \nnotifications@github.com wrote:\n\nHi,\nactually there is an old branch, feature/install-github-sha1 or some such,\nwith one commit by @jjallaire https://github.com/jjallaire that\nimplements this. It seems to work. +1 for this feature. Carefully\nincrementing version number doesn't work, who increments version number for\neach commit? I know better fairy tales.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/70#issuecomment-72256914.\n. Yes, the issue here is that base R defaults to 32-bit on the Mac whereas RStudio only supports 64-bit on the Mac. Within RStudio on the Mac the R_ARCH environment variable is therefore always set to /x86_64.\n. I made a complete hash of this pull request while trying to back out the changes to load_all...will resubmit a cleaner, simpler request.\n. Technically it should be done in load_all (since it ensures that all generated export shims are up to date) however there are other issues preventing load_all from building packages that rely on other packages: (1) Adding the package include directories to the build environment; and (2) Adding appropriate linker flags (not required by all packages) to the build environment. Until we get those issues sorted out it doesn't make sense to add it load_all. Some of my changes were an attempt to get all the build environment issues taken care of but I backed them out because I wanted to understand load_all better before committing such a big change. Let's discuss next time we get together or vchat.\n. No, there is no cleanup required. It basically compiles extern \"C\" SEXP and R shims for functions declared with standard C++ types. It generates two files (src/RcppExports.cpp and R/RcppExports.R) that are both permanent parts of the package source.\n. The last commit covers a few more cases for compile_dll:\n\n1) Packages that have header files in inst/include\n2) Packages that depend on native code in other packages via LinkingTo\n3) Packages that use Rcpp\n. I made all of the requested changes save for adding tests (next commit will have the tests)\n. I added the call to cacheMetaData() before the call to namespaceExport()\nand this did not result in the loadModule functions being available in the\nsimulated devtools environment (don't understand all of the mechanisms well\nenough to understand why). Another important note: this fix would still\nviolate the contract of setLoadAction because it would call the loadAction\nprior to calling onLoad.\nI've left the current fix checked in since we know that works (although of\ncourse still need to review for logical consistency/correctness). For what\nit's worth all the devtools tests pass but I don't know if the tests cover\nthis level of interaction/granularity.\nNo hurry whatsoever on resolving this -- enjoy your trip and we can pick it\nup again when you get back!\n. > @jjallaire https://github.com/jjallaire, keep in mind that Hadley\n\ntrimmed all trailing whitespace in devtools, so you may see a lot of\nconflicts that aren't really conflicts.\n\nYes, in attempting to rebase I get all kinds of output from Git I don't\nunderstand:\n- branch            master     -> FETCH_HEAD\n  First, rewinding head to replay your work on top of it...\n  Applying: Compile attributes for Rcpp packages\n  Using index info to reconstruct a base tree...\n  :51: trailing whitespace.\n:64: trailing whitespace.\n:67: trailing whitespace.\n:68: trailing whitespace.\n    if (!require(\"Rcpp\"))\n:70: trailing whitespace.\nwarning: 5 lines add whitespace errors.\nFalling back to patching base and 3-way merge...\nAuto-merging NEWS\nCONFLICT (content): Merge conflict in NEWS\nFailed to merge in the changes.\nPatch failed at 0001 Compile attributes for Rcpp packages\nWhen you have resolved this problem run \"git rebase --continue\".\nIf you would prefer to skip this patch, instead run \"git rebase --skip\".\nTo check out the original branch and stop rebasing run \"git rebase --abort\".\nIf rebasing ends up being too much of a pain, I can merge and resolve the\n\nconflicts by hand.\n\nI think to minimize the chance of my making a hash of your repo that your\nresolving manually might be the sanest approach. I'm happy to do whatever\nyou'd like to make this easier, but I don't want to naively assume I can\nmake it right and then do something nasty to the state of the repo.\n. I tried just rebasing my commit history into a single commit and that seems\nto have worked better than trying to rebase against the current master\n(which encountered the end of line merge problems you mentioned). I'll try\nto push the squashed commits so the pull request comes in as a single\ncommit rather than a dozen or so (perhaps that's what you had in mind in\nthe first place).\nJ.J.\n. As I feared my attempt to do this has made things worse. I'm going to need\nto send you a new pull request as the last is now in a state I don't\nunderstand.\n. And now the final note: I was looking at the wrong branch when I thought\nthings had been messed up. The squash and git push --force worked fine so\nthe pull request is in one single clean commit. You can merge it as it is.\n. Okay, glad to hear it wasn't too involved and thanks for all of the\nfeedback on the request.\n. To get this exactly right you need to do a couple of things:\n(1) If Rtools is discovered on the PATH (as opposed to the registry) you\ncan actually parse it's version out of the VERSION file in the root of\nRtools (but note this file didn't appear until I believe R tools 2.13).\n(2) Once you know the version you need custom logic (based on the docs on\nthe Rtools web page) to determine if there is a correct version match. You\nalso need custom logic for which directories to add to the PATH. Both are\nillustrated here:\nhttps://github.com/rstudio/rstudio/blob/master/src/cpp/core/r_util/RToolsInfo.cpp\nA final related note: I think it might be too aggressive to add Rtools to\nthe PATH for the entire R session (this adds quite a few binaries at the\nvery front of the path and could cause unexpected interactions w/ other\nprograms). What about just adding Rtools during build operations?\nOn Tue, Dec 11, 2012 at 8:46 AM, hadley wickham notifications@github.comwrote:\n\nChange to warning rather than error\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/203.\n. > If I do recode in R, is there some way we could both use going forward?\nShould we consider an Rtools package?\n\nI think if we both want to use the same code (e.g. from an Rtools package)\nI'd still take the R code as a snapshot into RStudio (then update as\nnecessary). That way we won't have version fragility/complications as new\nversions of the package and RStudio are released (otherwise both would be\nburdened with forward and backward compatibility concerns and be harder to\nsupport and evolve). Given that, if you think the only user of the Rtools\npackage would be devtools I'd say just put it in devtools and I'll take the\nsnapshot from there.\n. Hadley has ported the RStudio Rtools detection code to R (it's implemented\nin C++ in RStudio). It's not fully tested and integrated into devtools yet,\nbut here's the code so far:\nhttps://github.com/hadley/devtools/blob/winpaths/R/rtools.r\nOn Wed, Jan 9, 2013 at 5:00 PM, Winston Chang notifications@github.comwrote:\n\nActually, nevermind the idea of looking at subkeys. The 2.15 entry was a\nleftover from my previous installation of Rtools. With a clean\ninstallation, there's no reference at all to 2.15:\n\nkey <- utils::readRegistry(\"SOFTWARE\\\n\\R-core\\Rtools\",\n-      hive = \"HLM\", view = \"32-bit\")\n  key\n  $Current Version\n  [1] \"2.16\"\n\n$InstallPath\n[1] \"c:\\Rtools\"\n$2.16\n[1] \"\"\nI think potential solutions include:\n- Dropping the version check entirely.\n- Make sure that the minor version of Rtools is within 1 of the minor\n  version of R.\n- Hard-code the version table from the Rtools website into rtools().\n\u2014\n  Reply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/226#issuecomment-12069153.\n. We're now using the R package build system directly for building native libraries. In this context there is a known Rcpp constraint that you can't have Rcpp installed in a directory with spaces in the path. This issue has been resolved in the development version of Rcpp (which you can get from svn or R-forge).\n. Hi Carlos,\n\nAre you using RStudio Build and Reload or devtools::load_all() to build the package?\nIf you are using Build and Reload I'd be surprised if there was a variation in behavior because all it does under the hood is call R CMD INSTALL.\nIf you are using devtools::load_all I'm not sure what's going on (I'm not aware of anything that would make load_all work different under RStudio visa vi the Terminal or R GUI). \nNote that the 2nd problem related to loading modules should be idiosyncratic to load_all (since the error results from the fact that load_code simulates but don't exactly replicate the behavior of R package loading). You should be able to get past this error by using Build and Reload since that will literally reload the package in a fresh R session.\nJ.J.\n. If you create an RStudio project based on your package's source directory\nyou'll see all of our package development tools. This includes Build and\nReload which unloads the package, builds it using R CMD INSTALL, then\nrestarts R and reloads the package. This takes about 1 or 2 seconds and\npreserves all of your IDE state.\nMore on package development tools here:\nhttp://www.rstudio.com/ide/docs/packages/overview\nOnce you've enabled the package development tools then there will also be\nglobal keyboard shortcuts for both load_all and Build and Reload (both of\nwhich automatically save all unsaved source files so you can go from coding\nto rebuilt package in one keystroke).\nJ.J.\nOn Thu, Feb 14, 2013 at 12:06 PM, Carlos Scheidegger \nnotifications@github.com wrote:\n\nI am using devtools::load_all(). From a bash shell:\n$ R64\n\nlibrary(devtools)\nload_all(\"/Users/cscheid/code/guitar\")\nLoading guitar\nLoading required namespace: Rcpp\nLoading required package: Rcpp\nAdding files missing in collate: guitar.R\n\nFrom RStudio 0.97.312:\n\nlibrary(devtools)\nload_all(\"/Users/cscheid/code/guitar\")\nLoading guitar\nLoading required namespace: Rcpp\nLoading required package: Rcpp\nAdding files missing in collate: guitar.R\nError in dyn.load(dllfile) :\n  unable to load shared object '/Users/cscheid/code/guitar/src/guitar.so':\n  dlopen(/Users/cscheid/code/guitar/src/guitar.so, 6): Library not loaded: libgit2.0.dylib\n  Referenced from: /Users/cscheid/code/guitar/src/guitar.so\n  Reason: image not found\n\nI thought the issue was 32-bit vs 64-bit, but running R from a bash shell\ngives me a different error:\n\nlibrary(devtools)\nload_all(\"/Users/cscheid/code/guitar\")\nLoading guitar\nLoading required namespace: Rcpp\nLoading required package: Rcpp\nAdding files missing in collate: guitar.R\nError in dyn.load(dllfile) :\n  unable to load shared object '/Users/cscheid/code/guitar/src/guitar.so':\n  dlopen(/Users/cscheid/code/guitar/src/guitar.so, 6): no suitable image found.  Did find:\n/Users/cscheid/code/guitar/src/guitar.so: mach-o, but wrong architecture\n\n(Showing my complete ignorance here, I don't know what you mean by Build\nand Reload!)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/253#issuecomment-13566293.\n. I suspect an architecture mismatch issue. What version of RStudio are you\nrunning?\n\nJJ\nOn Feb 14, 2013, at 12:51 PM, Carlos Scheidegger notifications@github.com\nwrote:\nJ.J., thank you for walking me through this. I created the project, used\nthe Build and Reload command, and it still doesn't work. (I pushed the new\nfiles created by RStudio to the experimental-devtools\nbranchhttps://github.com/cscheid/guitar/tree/experimental-devtoolsin\nguitar as well). A similar error happens, now from the build tab in\nthe\nproject view in RStudio:\n==> R CMD INSTALL --no-multiarch guitar\n- installing to library\n  \u2018/Library/Frameworks/R.framework/Versions/2.15/Resources/library\u2019\n- installing source package \u2018guitar\u2019 ...\n  * libs\n  * arch - x86_64\n  make: Nothing to be done for `all'.\n  installing to /Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64\n  * R\n  * inst\n  * preparing package for lazy loading\n  * help\n  * installing help indices\n  * building package indices\n  ** testing if installed package can be loaded\n  Error in dyn.load(file, DLLpath = DLLpath, ...) :\n  unable to load shared object\n  '/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64/guitar.so':\n  dlopen(/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64/guitar.so,\n  6): Library not loaded: libgit2.0.dylib\n  Referenced from:\n  /Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64/guitar.so\n  Reason: image not found\n  Error: loading failed\n  Execution halted\n  ERROR: loading failed\n- removing \u2018/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar\u2019\n- restoring previous\n  \u2018/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar\u2019\nExited with status 1.\nThis same project directory setup works for plain R64 CMD INSTALL\n--no-multiarch:\n$ R64 CMD INSTALL guitar --no-multiarch\n- installing to library\n  \u2018/Library/Frameworks/R.framework/Versions/2.15/Resources/library\u2019\n- installing source package \u2018guitar\u2019 ...\n  * libs\n  * arch - x86_64\n  make: Nothing to be done for `all'.\n  installing to /Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64\n  * R\n  * inst\n  * preparing package for lazy loading\n  * help\n  * installing help indices\n  * building package indices\n  ** testing if installed package can be loaded\n- DONE (guitar)\nI suspect it's something I do in my environment. How do I inspect the\nenvironment RStudio is getting vs the one plain R is getting?\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/hadley/devtools/issues/253#issuecomment-13568673.\n. Okay, I'll try to repro and let you know what I discover (thanks for the\ndetailed diagnostics!)\nJJ\nOn Feb 14, 2013, at 1:01 PM, Carlos Scheidegger notifications@github.com\nwrote:\nRStudio 0.97.316 (fails with 0.97.312 as well), R 2.15.2, OS X 10.8.2\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/hadley/devtools/issues/253#issuecomment-13569157.\n. Carlos,\nI discovered the source of the problem -- as of about a month ago we\nstarted setting the DYLD_FALLBACK_LIBRARY_PATH to dynamically bind to\ndifferent versions of libR.dylib  (e.g. MacPorts or homebrew). Previously\nwe were setting DYLD_LIBRARY_PATH however this caused conficts over gcc\nversions since R64 has it's own version of libgcc_s.1.dylib in it's lib\ndirectory.\nWhat I didn't know about DYLD_FALLBACK_LIBRARY_PATH (and just discovered\ntoday) is that it has an implicit default value (/usr/local/lib:/usr/lib)\nwhich you need to explicitly included when overriding it. As a result of\nnot doing this, we couldn't load any libraries from /usr/local/lib at all!\n(so just doing library(guitar) on a correctly built version also failed).\nObviously a very serious issue which I'm going to put out a patch release\nfor later today.\nThanks for your help sorting this out -- will let you know when the new\nrelease is available for download!\nJ.J.\nOn Thu, Feb 14, 2013 at 1:06 PM, Carlos Scheidegger \nnotifications@github.com wrote:\n\nAlso, I don't think it's only architecture mismatch. When I do\nforcefully trigger architecture mismatch problems, (by typing R CMD\nINSTALL guitar --no-multiarch on a bash shell instead of R64 CMD INSTALL\nguitar --no-multiarch) this is what I get instead:\n** testing if installed package can be loaded\nError in dyn.load(file, DLLpath = DLLpath, ...) :\n  unable to load shared object '/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/i386/guitar.so':\n  dlopen(/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/i386/guitar.so, 6): Symbol not found: _git_index_free\n  Referenced from: /Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/i386/guitar.so\n  Expected in: flat namespace\n in /Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/i386/guitar.so\nError: loading failed\nExecution halted\nERROR: loading failed\nNotice this is not the same error as the one I get from RStudio (which I\nreproduce below:)\n** testing if installed package can be loaded\nError in dyn.load(file, DLLpath = DLLpath, ...) :\n  unable to load shared object '/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64/guitar.so':\n  dlopen(/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64/guitar.so, 6): Library not loaded: libgit2.0.dylib\n  Referenced from: /Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64/guitar.so\n  Reason: image not found\nIs there a better forum for me to move this to?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/253#issuecomment-13569406.\n. Version 0.97.318 of RStudio is now available and fixes the DYLD_FALLBACK_LIBRARY_PATH identified above. Thanks again for helping us track this down!\n. In RStudio we do a slightly less conservative version of this so that we can work with R-devel. Currently we treat Rtools 3.0 as compatible with a max R version of 3.1\n\nOn May 17, 2013, at 6:05 PM, Brian Diggs notifications@github.com wrote:\n\nLooking at the rough patterns some more, setting the max to \"3.0.99\" might be the sweet spot of covering everything likely to be appropriate and likely not including too much that isn't. In general, if the most recent version is \"a.b\", set the max to \"a.b.99\", to be adjusted when there is a real max (which would presumably be known when a new Rtools comes out).\n\u2014\nReply to this email directly or view it on GitHub.\n. I think we'll also need this in order for breakpoints to work in RStudio\n. In terms of the fragility, I think the fact that it's document as part of git provides pretty strong assurance (and there is likely already lots of code depending on it). I also think doing the whole thing locally is faster and more foolproof than requiring an http (or even https?) call.\n. made the changes we discussed. I did note however that including \\n prior to the GithubSHA1 entry broke package installation with: \"Error: contains a blank line\". So I removed the \\n. R appends a \"Built\" field during installation and I'm wondering if they already rely on a newline after the last line? In any case, do you think I should read the description and check for a newline at the end?\n. okay, I'll update to make sure the newline behavior is correct in all cases.\n. Made the change to have more intelligent newline handling (and tested on Windows).\n. Your right! I'll update to add the extra context.\n\nOn Thu, Sep 26, 2013 at 2:41 PM, hadley wickham notifications@github.comwrote:\n\nIt just occured to me that this isn't enough - we also need the username,\nrepo name (might be different from package) and subdir. We want also want\nto flag if it's a private repo (i.e. needs username and password to\ndownload)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/pull/349#issuecomment-25192435\n.\n. Updated to add all of the parameters to install_github (doesn't add anything for parameters that are NULL). Also rebased into a single commit. \n. Okay, eliminated the newlines at the end of utils.R\n. Okay, done.\n\nOn Fri, Sep 27, 2013 at 9:12 AM, hadley wickham notifications@github.comwrote:\n\nSorry I meant NULL, not return (NULL)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/pull/349#issuecomment-25243859\n.\n. Done (and rebased again)\n\nOn Fri, Sep 27, 2013 at 9:28 AM, hadley wickham notifications@github.comwrote:\n\nSorry forgot one last thing - can you please add a bullet point to NEWS\nbriefly describing the change and crediting yourself?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/pull/349#issuecomment-25244830\n.\n. No there isn't currently a way to do this. You could just take the default\nfor each platform as observed in a vanilla version of R (it's highly\ndoubtful that users are overriding \"browser\" and even if they are email\nfrom devtools is such as specialized case that using the base R default\nisn't likely to be objectionable)\n\nOn Tue, Mar 11, 2014 at 10:43 AM, Hadley Wickham\nnotifications@github.comwrote:\n\n@jjallaire https://github.com/jjallaire is there a way to find out the\ndefault value of getOption(\"browser\") before it's overridden by Rstudio?\n\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/433#issuecomment-37303019\n.\n. FYI you can disable the use of devtools by going to the package build options.\n. I think we could add a global preference to RStudio that controls whether new projects get this by default (so you could set this once per machine for all time and be done with it)\n. Okay, I just added a global preference (under Packages) that you can flip to ensure that new packages always use plain R CMD check. I am sure it will be also straightforward to modify devtools to not warn for ChangeLog.\n. RStudio no longer recognizes Rtools on the PATH (this is inherently problematic since it is still fragile to other things on the PATH that might interfere with correct operation e.g. cygwin and is also not robust to multiple versions of R). \n. No, there's nothing additional for you to do in devtools. That warning is\nprinted by RStudio if a build fails and we don't find the right Rtools\ninstalled in the registry. Not sure what the full conditions are here and\nwhether this is a false negative. Dieter, any more details?\n\nOn Thu, Jul 17, 2014 at 5:54 AM, Dieter Menne notifications@github.com\nwrote:\n\n@jjallaire https://github.com/jjallaire: \"RStudio no longer recognizes\nRtools on the PATH\". Slightly confused; does it mean there should be some\nenvironment or RStudio variable which I forgot to set?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/525#issuecomment-49286205.\n. 2 questions:\n\n(1) What is your PATH?\n(2) Could you export this registry key:\nHKEY_LOCAL_MACHINE\\Software\\R-core\\Rtools\nOn Thu, Jul 17, 2014 at 6:07 AM, Dieter Menne notifications@github.com\nwrote:\n\n@jjallaire https://github.com/jjallaire: I have installed Rtools31.exe,\nand the warning is printed even for a trivial vanilla skeleton that\ncompiles correctly.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/525#issuecomment-49287691.\n. That is indeed the problem. There is a check box below that you need to select (see attached screenshot)\n\n\nHere are the registry entries that work on my machine:\n```\nKey Name:          HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\R-core\\Rtools\nClass Name:        \nLast Write Time:   6/30/2014 - 9:55 AM\nValue 0\n  Name:            InstallPath\n  Type:            REG_SZ\n  Data:            C:\\RBuildTools\\3.1\nValue 1\n  Name:            Current Version\n  Type:            REG_SZ\n  Data:            3.1\nKey Name:          HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\R-core\\Rtools\\3.1\nClass Name:        \nLast Write Time:   7/1/2014 - 11:02 AM\nValue 0\n  Name:            InstallPath\n  Type:            REG_SZ\n  Data:            C:\\RBuildTools\\3.1\nValue 1\n  Name:            FullVersion\n  Type:            REG_SZ\n  Data:            3.1.0.1942\nValue 2\n  Name:            MinRVersion\n  Type:            REG_SZ\n  Data:            2.15.3\n```\nIf this is a common problem we may need to revert to scanning the PATH. This leaves us open to one malconfiguration (Rtools on the PATH but another toolchain that also provides gcc and/or posix tools preceeding it on the PATH) but the user has a workaround for that (and we could code around it with some extra effort).\n. I reverted the change I made to ignore the PATH (as you point out, users with conflicting UNIX toolchains on their PATH already need to actively manage this).\n. I'd say the most explicit/direct way to do this would be to:\n1. Add the auto_clean argument as suggested.\n2. Have it default to getOption(\"devtools.autoclean', TRUE) so it can be externally specified on a global or per-project basis.\n. This may it may or not be an Rcpp issue (Kevin would know for sure) but I\ndon't know when our next release is so I'd recommend a local workaround for\nnow\n. Thanks! I just made the same change: https://github.com/rstudio/rstudio/commit/be6ba0954062775f13eda69290fb56f9f0608569\nOne difference is that I scan HKLM first so that the detected version won't change from under existing users (i.e. we'll always do exactly what we did before and then only if we fail entirely will we scan HKCU).\n. I don't have any thoughts beyond what devtools and rstudio already do (I\nactually thought that HCU was an alias to user-writeable storage so could\nstill work with non-admin installs).\nOn Thu, Sep 3, 2015 at 9:24 AM, Hadley Wickham notifications@github.com\nwrote:\n\n@jjallaire https://github.com/jjallaire any thoughts on this? I don't\nknow which registry \"hives\" I should be looking in.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/904#issuecomment-137444086.\n. I just realized that one problem with this is that an attacker can arrange\nfor the test to fail thus forcing you back to http. I think you need some\nvariation of this code to test whether the current download method is\nsecure:\n\nhttps://github.com/rstudio/rstudio/blob/master/src/cpp/session/modules/SessionPackages.R#L1045-L1076\nOn Thu, Jun 2, 2016 at 3:01 PM, Hadley Wickham notifications@github.com\nwrote:\n\nWould still need to be memoised (if it didn't fail)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hadley/devtools/pull/1060#issuecomment-223389631, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AAGXx-VPrwwnN-zec4v0bk96osYmremeks5qHyijgaJpZM4HQl2R\n.\n. Yes, I think this would be quite straightforward. I'll log an issue for the\nnext release.\n\nOn Sat, Feb 13, 2016 at 8:51 AM, Hadley Wickham notifications@github.com\nwrote:\n\n@jjallaire https://github.com/jjallaire @kevinushey\nhttps://github.com/kevinushey is this feasible?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/1089#issuecomment-183693032.\n. Yup, and we fixed a couple of weeks ago!\n\nJ.J.\nOn Wed, Mar 23, 2016 at 11:14 AM, Hadley Wickham notifications@github.com\nwrote:\n\n@jjallaire https://github.com/jjallaire just to confirm, this is an\nRStudio issue, not a devtools issue?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/1089#issuecomment-200389023\n. In R 3.3 a download method of \"auto\" will actually result in \"libcurl\" on Unix alikes, form the docs:\nIf method = \"auto\" is chosen (the default), on a Unix-alike method \"libcurl\" is chosen for https:// and ftps:// URLs and the \"internal\" method is chosen for other schemes.\n\nSo you may want to update the auto_download_method function to reflect that.\nIt's fine to relicense the source. You should keep the copyright notice but just change the license for that bit to whatever is used for the package (GPL-2 it looks like).\n. Jim, I think the change I suggested might just pick that up  (i.e. if the\ndownload method is \"auto\" then \"libcurl\" is used on Unix alikes).\nOn Fri, Jun 3, 2016 at 10:42 AM, Jim Hester notifications@github.com\nwrote:\n\nI think the logic needs to be tweaked to include capabilities(\"libcurl\")\nsomewhere. Currently on my machine download_method_secure() # FALSE even\nthough capabilities(\"libcurl\") #TRUE\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hadley/devtools/pull/1203#issuecomment-223597759, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AAGXx4N5tDX3p5YQg7mbnwrIDTRDw568ks5qID07gaJpZM4ItmFw\n.\n. I do know that we have some purposeful suppression of output at startup on build and reload (I don't recall why). However, the fact that this occurs sometimes but not others makes me think it's not a case of eating the output on purpose.. Okay, great. Thanks!\n\nOn Fri, Apr 7, 2017 at 2:59 PM, Jim Hester notifications@github.com wrote:\n\nThanks for the report JJ, I believe this is a known issue, see #1370\n(comment)\nhttps://github.com/hadley/devtools/issues/1370#issuecomment-273570049\nfor some discussion of the cause. We should have a fix for this in the near\nfuture.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hadley/devtools/issues/1492#issuecomment-292623748,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAGXxwleNYUi4selNRI5l6qr1-UYhkx_ks5rtoehgaJpZM4M21Rw\n.\n. Initially I didn't like filter either but struggled to come up with something more apt. The fact that it adds new files doesn't to me disqualify filter (as in, this will filter the contents of the directory including adding, deleting, modifying, etc.). Other possibilities: pre_install, on_pre_install, pre_install_hook, before_install.  Of those I might like before_install best, what do you think?\n. Just committed that change\n. \n",
    "piccolbo": "Sorry I should have tried instead\n. ",
    "josiekre": "I don't understand the post-close comment above. I see that install_github() adds fields to the Description file (which I see using packageDescription(lib)), but is it possible to have the version number look like '0.9.0-68-gc235a93' (see @wch comment above using git describe --tags)?. @gaborcsardi That is a bummer. Thanks for the clarification. I use this kind of versioning in Python, and man is it helpful!. ",
    "gaborcsardi": "@josiekre that's not a valid R package version number, unfortunately. It can only contain numbers separated by dots or dashes.. I think this could be handled by including some R code in the github tree, that is run by devtools::install_github (or ratherdevtools::install in general).\nThere are a couple of questions about the how:\n- Where to put the R code. This is probably simple, and it could just go into a file that is ignored by build(), e.g. build_package.R.\n- How to avoid the problem @wch mentioned. This could be done by fixing the versions of the builder package, e.g. adding a BuildDependencies field to DESCRIPTION, that can specify the exact version of the package you want to use for building. Examples:\nBuildDependencies: roxygen2 (= 4.0.1), Rcpp (>= 0.11)\nor even this to depend on an exact version:\nBuildDependencies: http://github.com/hadley/roxygen/7759478a86f803c5222c19189a022134de251ccb\nThis would also solve the problem we were having sometimes when various packages use different versions of roxygen2, and then various developers also have various versions.\nI just read over this thread, and realized that @hadley was suggesting essentially the same at the very beginning......\n. Yes, I know it does that. \nHowever, 1) it is somewhat cumbersome to compare package versions with that, and 2) you don't get it if you install the package locally, as it happens most of the time during development, and also 3) sessionInfo() does not contain the SHA AFAIK. \n. Was the PR about the sessionInfo() a joke? :) \nJust because I need to record exact versions now (packrat is not an option unfortunately), so I am willing to write a session_info() (or sessionInfo() if you want to overwrite the builtin one) function.\n. Oh, I just noticed that there is a session_info() function in devtools! Oooops, sorry for not checking first.\n. Which PR? \nAnyway, I realized this is not a good fit into devtools, and started to do it for myself: https://github.com/gaborcsardi/snap\nI really want to have named snapshots, within a single project, because parts of the project use different package versions. So packrat is not a good fit for me, unfortunately. \n. I guess for sharing code, packrat would need to export some lower level functionality, so that I can create named snapshots. Or, I could add named snapshots to packrat, but it somehow does not go well with the project directory concept packrat has.\nAnyway, this is getting off-topic here.\n. I don't how fast the RStudio server picks up the stuff, but maybe it is better to parse http://cran.r-project.org/. If a couple of hours after a release matter.\n. @hadley Yes, it is also on CRAN now: http://cran.r-project.org/web/packages/rversions/index.html This queries the SVN, so it is not super fast.\nI also have a web service, which just serves static data in JSON, it is updated after each R release:\nhttp://rversions.r-pkg.org/r-release\nhttp://rversions.r-pkg.org/r-oldrel\nhttp://rversions.r-pkg.org/r-versions\nThis is fast, obviously.\n. You mean for not using my web service in the R package?\nThe R package was before and it is used to update the web service. I made the web service after, because I needed the current version without R, in https://github.com/metacran/r-builder, to check which version of R to install.\nBut I could use the web service in the R package by default, obviously. I am not sure if that's better or not.\n. It is actually pretty slow (1s vs ~0s), so I think I might change it to use the web service by default.\n. FWIW, I have a function to bump semver version numbers, here:\nhttps://github.com/metacran/semver/blob/master/R/semver.r#L159\nYes, it is complicated. But semver is also more complicated than a simple major.minor.patch scheme.\n. There is nothing magical here. E.g. all modern version control systems work like this, you can say git diff from any subdirectory of your project. git just looks for the first parent directory with a .git subdirectory.\n. This is done with the merging of #616.\n. You mean the Title field in DESCRIPTION. Btw. it does not pass BDR, either.\nIt is something new: https://github.com/wch/r-source/commit/1f0dcb55368d7509c8123ce0bff5c6ef95a48607 (search for \"title case\")\n. This is what I usually do:\nsh\nRscript -e 'devtools::create(\"newpackage\")'\ncd newpackage\ngit init .\ngit add .\ngit commit -m 'Initial commit, after devtools::create()'\n...\nThis seems to be about the same amount of typing.\n. I guess this is a matter of choice, largely. However, note that semver.org has this:\n\nHow should I deal with revisions in the 0.y.z initial development phase?\nThe simplest thing to do is start your initial development release at 0.1.0 and then increment the minor version for each subsequent release.\n. Sure, that makes sense, I didn't immediately realize that you want a version number that refers to the  state before a release. It is a pity that you cannot have 0.1.0-dev or something like that. :(\n. @krlmlr That is fine with R, but I would encourage some numbering that conforms to http://semver.org, because it is becoming a standard in the JS, Ruby, etc. world.\n. We can choose something that is valid for R, smaller than 0.1.0, and also valid semver, and smaller than 0.1.0 for semver as well. These are not valid semver:\n\n``` r\nsemver::valid(\"0.0-0\")\n> NULL\nsemver::valid(\"0.0.0.9000\")\n> NULL\n```\nThese are valid:\n``` r\nsemver::valid(\"0.0.0\")\n> [1] \"0.0.0\"\nsemver::valid(\"0.1.0-99\")\n> [1] \"0.1.0-99\"\nsemver::valid(\"0.0.1-99\")\n> [1] \"0.0.1-99\"\nsemver::valid(\"0.0.0-99\")\n> [1] \"0.0.0-99\"\nsemver::valid(\"0.0.0-9000\")\n> [1] \"0.0.0-9000\"\nsemver::valid(\"0.0.0-0\")\n> [1] \"0.0.0-0\"\nsemver::valid(\"0.0.0-1\")\n> [1] \"0.0.0-1\"\n```\nI think 0.0.1-99 is somewhat strange, because we set the patch version to 1, 0.1.0-99 is bigger than 0.1.0, so that is not good, either. \nI think 0.0.0-9000, or even 0.0.0-1 or 0.0.0-0 are good.\nI don't really understand why you would want the last, fourth number to be big, to be honest. Because it will be similar later, for larger version numbers, i.e. 0.9.0-999? So I guess 0.0.0-9000 is fine, and it is almost what you wanted in the first place.\n. Although the ordering of R and semver will never match, of course. E.g. 0.0.0-99 is smaller than 0.0.0 in semver:\n``` r\nsemver::lt(\"0.0.0-99\", \"0.0.0\")\n> [1] TRUE\n```\nbut in R the opposite is true:\n``` r\npackage_version(\"0.0.0-99\") < package_version(\"0.0.0\")\n> [1] FALSE\n``\n. I guess you are right. So, whatever is fine then. :)\n. IMHO exactly three components are the way to go, for most packages. They are easy to interpret, the semver way. \n. Btw.packageName()is supposed to give you the name of the package is it called from, but I am actually not sure if it works from devtools.\n. Simpler code, withoutXML`:\n``` r\nlibrary(magrittr)\nlibrary(RCurl)\nget_tags <- function(xml) {\n  xml2 <- xml %>%\n    gsub(pattern = \"(.*?)\", replacement = \"\")\nmatches <- xml2 %>%\n    gregexpr(pattern = \"[^<]+\")\nregmatches(xml2, matches)[[1]] %>%\n    sub(pattern = \"\", replacement = \"\") %>%\n    sub(pattern = \"\", replacement = \"\")\n}\nGet the tag info from SVN\ntags <- getURLContent(\n  \"http://svn.r-project.org/R/tags/\",\n  customrequest = \"PROPFIND\",\n  httpheader=c(\"Depth\"=\"1\")\n) %>%\n  get_tags()\nSplit a version number to major, minor, patch\nsplit_versions <- function(x) {\n  x %>%\n    sub(pattern = \"^([0-9]+-[0-9]+)$\", replacement = \"\\1-0\") %>%\n    strsplit(split = \"-\") %>%\n    sapply(as.numeric)\n}\nSort version numbers\nsort_tags <- function(x) {\n  x_order <- x %>%\n    split_versions() %>%\n    apply(1, list) %>%\n    lapply(\"[[\", 1) %>%\n    do.call(what = order)\n  x [x_order]\n}\nExtract versions numbers from tags and sort them\nversions <-  tags %>%\n  sub(pattern = \"/R/tags/R-([^/]+)/\", replacement = \"\\1\") %>%\n  grep(pattern = \"^[0-9]+-[0-9]+(-[0-9]+|)$\", value = TRUE) %>%\n  sort_tags()\nRelase is easy, most recent\nrelease <- tail(versions, 1)\nOldrel is latest from the previous minor\n(Careful with factors, they are ordered by default!)\noldrel <- versions %>%\n  sub(pattern = \"-[0-9]+$\", replacement = \"\") %>%\n  factor(levels = unique(.)) %>%\n  tapply(X = versions, FUN = tail, 1) %>%\n  tail(2) %>%\n  head(1) %>%\n  unname()\n```\n. > - Can you do the XML manip with rvest? That would make the xml processing a little nicer\nCould, but then you need to depend on rvest. I wanted to avoid an additional dependency, devtools is already kind of heavy to install.\n\n\nCan you use numeric_version() for the version parsing?\n\n\nI thought about that, but that is only for packages, AFAIK. Btw. you can't really use it for parsing, because you need to transform the R-x-y-z tags to x.y.z, anyway, and then you already did the parsing. But for sorting, I could use it.\n\n\nI need to add better custom verb support to httr\n\n\nYep. :)\n. Btw. I would also remove magrittr.\n. Well, look at the XML version on top, then. That is clean in this respect.\nI just find all <D:href> tags, that's all XML or rvest is needed for.\n. No, not in an API. :( It is in a package, though not on CRAN: https://github.com/metacran/rversions\nI would prefer something else than R for a JSON API, e.g. JavaScript is easier to host. That's why I haven't put it in JSON yet, I would rewrite it in JS.\n. Don't you get warnings/notes for these from check()? \n. That's sad, but not completely unexpected.\nBtw. I think R/devtools would very much need a build system that runs before R CMD build. This would solve (well, work around) this problem, and could also run roxygen, the Rcpp attributes generator, etc. I have to say I hate putting generated files into the repo....\n. :) Well, you can get used to bad habits as well, and then they don't seem so bad any more.\nWith a simple build system, you could have both. Almost all people already have roxygen installed anyway, and Rcpp as well. install() would just run a simple script, automatically, to build the docs, and whatever we would like add later. So it would be just us user friendly as it is now, in fact the users would not notice anything (well, a bit longer install time and more output).\nE.g. it is kind of annoying when people use different versions of roxygen for different projects, and then it keeps overwriting the headers of the manual files, unless you undo it by hand....\nIt is true that it increases complexity, and ideally this should be part of R CMD build, anyway. \n. Yes, I keep forgetting that you need to a C compiler to use roxygen. (I worked around it in my own packages.)\n\nWriting the roxygen version into the headers is actually a very deliberate way of making sure everyone is using the same version of roxygen so that spurious differences don't accidentally get bundled into a commit.\n\nYes, although this solves a problem that you created by using github both for version control and distribution. But, indeed, this is convenient for users.\n. In general, these files bloat the repository.\nMore specifically:\n- it is considered good practice not to check in generated files (yes, this is a very week point, I agree)\n- they mess up git diff, and the history in general\n- they (might) mess up merging and rebase\n- as said above you need to be on the same roxygen version as other devs, and this sometimes changes between projects. (In the past, for a while I always had to re-install roxygen for this, many times a day.)\nBut I agree with you that the benefits are bigger for R packages, I just forgot about the C compiler.\nBtw. how about working around in roxygen, so that it does not compile the C source (or only if needed). IMO, it is not needed for most packages.\n. First of all, I agree with @hadley, that unless we manage to change roxygen to work without a C compiler (well, almost always), the current way of putting the generated man files into repo is the best compromise.\nSecond, I still think that bloating the repo with generated files is not a good idea. The number of things you will want to auto-generate in the future is only increasing:\n- NAMESPACE, DESCRIPTION\n- manual\n- vignettes\n- R/C/C++ code for automatically wrapping C/C++ libs\n- embedded libraries, like libgit in git2r\n- JS/npm packages for the new V8 engine.\n- etc.\nThird, and I am repeating myself again, the root of all \"troubles\" is that we are using the same Github repo for development and distribution.\n@wch \n\nMaybe someone (you?) could outline a workflow for that?\n\nWell, not really yet, sorry. I had some ideas when I brought this up earlier today, but now realized that the good solution is to really separate development from distribution. But this is also not easy, because it complicates the workflow, and makes it much more error-prone.\nYou are probably right that this all belongs to a separate package/tool.\n. \"curl\" is not portable I guess. And the rest do not support https. But FIXME.\n. Especially that these are only loosely coupled to devtools, and should probably be in the same package together. A dockerdev package or something like that. \n. I am doing sg somewhat similar right now here: \nhttps://github.com/r-hub/localbuilder (there is an rpackage branch, which will have the scripts as an R package).\nThe idea of localbuilder is that it will create an environment for your R code, and then it will run it. More specifically, this currently means:\n1. take a source R package tarball, and \n2. take a docker image (e.g. one of the R-hub images),\n3. install all sysreqs of the package on the R-hub image,\n4. install the package dependencies of the package on the image,\n5. run an arbitrary (R?) command in the new image, currently R CMD check.\nI am not using harbor, though.. Fix me if I am wrong, but my understanding is that devtools is for package development, and if you want to use the package, in your case by multiple R processes in parallel, then you can just install it, and load it with library. \nBecause if you really want to use devtools in parallel, then there are issues with all the generated files, not just DESCRIPTION, and these issues are hard to fix, essentially all writes would require locking.\n. > The current solution might actually be fine, as long as it only writes the\n\nDESCRIPTION file when necessary. In my case it keeps writing it even if the\nresulting Collate field is identical to the current one.\n\n@renozao Maybe so for your case. \nBut I think that the general point of \"do not run devtools from multiple R processes on the same directory\" still stands. AFAIK devtools does not do any locking, so your toolchain will probably break at some point. \n. > when you say toolchain, do you mean in the case there is compiled code or even in plain R packages? \n@renozao Even in plain R packages. E.g. if you export a new function via roxygen, then devtools will need to rewrite the NAMESPACE file, so there is a potential race condition if you do this from multiple R processes. The NAMESPACE file might get messed up.\n\nIt is just simpler and I had no issue until the update_collate change.\n\nMaybe you were just lucky. Obviously, if devtools updates files less, there will be fewer race conditions. But this does not necessarily make the situation better. You'll get fewer crashes, yes, but they'll also be harder to debug.\n. @hadley: nitpicking, but stats is a base package. It seems that you need to declare imports even from base packages, otherwise another package might just override a base function for you.\nI am not sure why it is this way, but it seems rather silly. Maybe historical reasons, or I am missing something.\n. @Geoff99 \n\nonly the base package itself is included in the chain of enclosing environments above a package's own namespace environment,\n\nI don't think this is true. Surely, all base and recommended packages are included there. At least you don't need to explicitly import (say) plot, even if plot is in graphics, not base. It seems that recommended packages are also included (head is in utils, which is not a base package):\n``` R\nlibrary(disposables)\npkg <- make_packages(foo = { h <- function(...) head(...) })\nfoo::h(1:100)\n> [1] 1 2 3 4 5 6\ndispose_packages(pkg)\n```\nTo make things even worse, it seems attached packages are also searched, even before the recommended and base packages.\nConsider the following example, in which package bar calls density from the stats base package. If you have another package (foo) loaded, and foo redefines density, then bar calls foo::density. Which IMO does not make much sense.\n``` R\np1 <- make_packages(foo = { density <- function(...) print(\"cocooo!\") })\np2 <- make_packages(bar = { f <- function() density(1:10) })\nbar::f()\n> [1] \"cocooo!\"\ndispose_packages(p1)\ndispose_packages(p2)\n```\nCalling density explicitly from stats solves the problem.\n``` R\np1 <- make_packages(foo = { density <- function(...) print(\"cocooo!\") })\np2 <- make_packages(bar = { f <- function() stats::density(1:10) })\nbar::f()\n> Call:\n>  density.default(x = 1:10)\n>\n> Data: 1:10 (10 obs.);    Bandwidth 'bw' = 1.719\n>\n>        x                 y\n>  Min.   :-4.1579   Min.   :0.0003034\n>  1st Qu.: 0.6711   1st Qu.:0.0092711\n>  Median : 5.5000   Median :0.0538486\n>  Mean   : 5.5000   Mean   :0.0517052\n>  3rd Qu.:10.3289   3rd Qu.:0.0936045\n>  Max.   :15.1579   Max.   :0.0997741\ndispose_packages(p1)\ndispose_packages(p2)\n```\nIf you explicitly import stats (I guess importing just density is enough, too), that also solves the problem:\n``` R\np1 <- make_packages(foo = { density <- function(...) print(\"cocooo!\") })\np2 <- make_packages(bar = { f <- function() density(1:10) }, imports = \"stats\")\nbar::f()\n> Call:\n>  density.default(x = 1:10)\n>\n> Data: 1:10 (10 obs.);    Bandwidth 'bw' = 1.719\n>\n>        x                 y\n>  Min.   :-4.1579   Min.   :0.0003034\n>  1st Qu.: 0.6711   1st Qu.:0.0092711\n>  Median : 5.5000   Median :0.0538486\n>  Mean   : 5.5000   Mean   :0.0517052\n>  3rd Qu.:10.3289   3rd Qu.:0.0936045\n>  Max.   :15.1579   Max.   :0.0997741\ndispose_packages(p1)\ndispose_packages(p2)\n```\nSo, unless I am missing something, the best is to import everything, even stuff from base and certainly from recommended packages. But hopefully I am missing something.\n. > @Geoff99 is right that it would be safer to import objects from stats or use :: -- it would be safest not to rely on the search path (i.e., attached packages) to find functions.\nAgreed. All I am saying is that you need to do this for base packages as well (except maybe base itself), not only for recommended ones. E.g. stats is a base package.\n. @hadley Sure, I can report it. I am pretty sure that they know about it. I am also pretty sure that they won't fix it, because it would generate NOTEs for many-many packages. It really should be fixed, though, so I'll give it a try later today.\n. @bquast IMHO it is better to leave it out. It is simply not needed, so why bother?\n. Of course I haven't. But how could I? Errors only happen if you manually interrupt between the two expressions, or the first expression is interrupted (e.g. because R runs out of memory) after it created some side effects.\nEven if an error happens because of this, most probably you would have no idea what caused it, and of course it is not reproducible.\nThis is kind of similar to PROTECT bugs that only happen in edge cases. Probably less important, though.\nRace conditions like this are considered to be security vulnerabilities in general, but I guess this is not really a serious issue for R, at least currently. But note that as R becomes more mainstream and with increasing embedded use, this might become an issue. E.g. MS plans to embed R into SQL server, and then it might become an issue. Not the on.exit() calls in devtools probably, but the general practice of not caring about race conditions.\nSo, yes, the importance is negligible. But it also does not take much to write things correctly, just switch the order of the two expressions.\n. I think errors might be problematic, too. E.g. if the change_something() call errors out, and has already changed something before the error (e.g. it has side effects), then you can have a problem. \n. Ideally yes. But this is hard to achieve sometimes. E.g. look at devtools:::set_locale:\nr\nfunction (cats) {\n    stopifnot(is.named(cats), is.character(cats))\n    old <- vapply(names(cats), Sys.getlocale, character(1))\n    mapply(Sys.setlocale, names(cats), cats)\n    invisible(old)\n}\nIf there is an error in the mapply, then the locale settings that were already set will not be undone.\n. > Does tryCatch + finally have the same problem?\nNo, I think finally is always evaluated, so that is safe.\n\nI understand that this is a potential problem, but it seems like a fairly unlikely scenario to me. (i.e. compare to all the other numerous sources of bugs that I could fix, this is fairly low down on my list)\n\nI understand, I am not doing it either in my projects. (I mean fixing the existing code.) But when you next time write an on.exit() expression, consider putting it before the expression that changes the global context. :)\n. Hmmm, what files specifically? I can't recall having to remove any files. Maybe you just need a .gitignore file?\n. > I think the cleaner solution would be for the tool to know which files get generated. Having a method that removes everything that gets generated would be helpful independently of the used VCS and for other tasks too. \ngit clean -fdx removes everything that is not in the VCS.\n\nBut a .gitignore file would also be helpful if devtools generates it and pre-fills it with the list of files/patterns of what gets generated.\n\ndevtools already does that AFAIR.\n\nSo, from my noob perspective, I think ideally the clean() method would remove all the *.Rd files that got generated, the NAMESPACE file, other files generated by roxygen2, any compiled files, and probably others I do not even know about yet.\n\nYou are supposed to put the .Rd files and NAMESPACE in the VCS. Otherwise tools like install_github do not work correctly. \nCompiled files are ignored by default in devtools's .gitignore AFAIR. Again, you can remove them with git clean -fdx.\nI hope this helps.\n. I have the same platform as you and cannot replicate this with any devtools/Rcpp versions, CRAN or GitHub.\n. IMHO, this could be in another package. devtools is already huge and has a lot of functionality that could be refactored into other smaller packages.\n. @jennybc AFAIK both Travis and Appveyor can be used with GitHub alternatives, e.g. BitBucket, Kiln, etc.\n. How about calling it Repositories? I think it is a better name than Remotes, especially if some of them are local.\nOr how about using (and abusing) the already used Additional_repositories field?\n. This is a great PR, by the way! \n. @hadley Fair point, I was already thinking about extending this to repositories. :+1:)\n. @krlmlr I don't think so. \nBut I would not recode the fields when reading the file. Then you would need to recode it back when exporting, copying, etc.\nI would rather change it when printing, or when the problem actually comes up. \n. That's the one!\n. @krlmlr hash the data file(s) and only reload if they change? This assumes that hashing is much quicker than loading, which is probably true, but we would need to measure it.. > Hash + timestamp would be faster, yes.\nSome file systems do not have proper mtimes, so timestamps can be messy. Hashing is simpler imo.\n\nAnyway, this discussion belongs in pkgload now.?\n\nIndeed.. It is imo unclear what the best practice is. \n- Traditionally R packages used a NEWS.rd file, but this is heavy, and cumbersome, so a lot of people don't use them any more.\n- On GitHub people use NEWS.md files, these are in Markdown. This is used now by CRAN as well, see below.\n- You can also use a NEWS file, according to the GNU standards. This is picked up and shown on CRAN, as a text file, AFAIR.\nPersonally I like NEWS.md. In fact recently (https://github.com/wch/r-source/commit/e7cf1f06c0cdf439eca9d561b84316a44089e142) NEWS.md is picked up by CRAN. Incidentally inst/NEWS.md is also picked up, which is a pity, because I specifically put NEWs.md in inst/ so that CRAN does not bother with them....\nCRAN uses Pandoc to format Markdown, which is unfortunate, because GitHub uses a different parser, and you often end up with an MD file that is fine on GitHub, but gives warnings or errors on CRAN. And then you get emails from CRAN.\n. Btw. here is a recent discussion about NEWS.md: http://r.789695.n4.nabble.com/NEWS-md-support-on-CRAN-td4707539.html\n. @hadley It is a problem in r-release I think, but not in r-devel. Unless there was a change since wch/r-source@e7cf1f0\n...\nThere was no change it seems: https://github.com/wch/r-source/commits/e7cf1f06c0cdf439eca9d561b84316a44089e142/src/library/tools/R/check.R\nSo yes, NEWS.md and inst/NEWS.md are picked up by r-devel:\n- they convert it to HTML with pandoc\n- they'll put it on the CRAN website (maybe not until R 3.3.0)\n- you'll get an email from CRAN if pandoc fails :)\n. YEs, I think so. (Except for the pandoc failures. :)\n. Valgrind does not always support the latest OS X versions immediately. They have some preliminary support for 10.11 now, I am not sure what that means exactly. In the past some OS X versions were unsupported for long periods of time.\n. Whenever ppl try using testthat or roxygen, they could just get a message that it is missing, and it needs to be installed. Potentially devtools could also install them if interactive().\nBtw. as much as I like micropackages, I personally don't like \"removing\" testthat and roxygen2.\nMaybe we can work on making roxygen2 lighter, e.g. remove the Rcpp dependency. testthat is not too heavy imo. And/or moving the install_* functions to separate packages.\nBtw.2. slightly related, https://github.com/metacran/description is almost ready. Some more docs would be nice, and validation is mostly missing. Validation is very hard, actually, for some fields, e.g. License. I'll add them, slowly, but it will take a while. \n. @hadley I am not suggesting removing the C++ code, only the Rcpp wrapper. Rcpp is great, but the roxygen C++ code is short and seems straightforward without Rcpp, too.\nJust an idea, not sure if it is worth the effort.\n. IMO DevtoolsNote will not pass R CMD check. RoxygenNote does, because Roxygen is a valid key. So for devtools you would need another valid key, and append Note to if, which is not ideal.\n. @hadley Personally, I am not sure if this is a good idea.\nIf you do it at package creation, then it will get outdated, and useless.\nIf you do it in load_all or in as.package, then there will be spurious changes in DESCRIPTION. OK, not too frequently, but still. \nMaybe more importantly, I think the state of the package should be independent of the devtools version.\n(Roxygen is a different thing IMO, because that creates package files on purpose, and these might change depending on roxygen version.)\nI think if you want to inform people about new versions, devtools could just check occasionally whether there is a new version available, and if isTRUE(interactive()), inform the users. I have long wanted to write a micropackage for this. With metacran, it is trivial, anyway, just get http://crandb.r-pkg.org/devtools and check Version. If devtools sends an extra header with the current version, then we can even track usage.\n. @hadley I see. Without version numbers it is definitely better.\nAlthough I bet that it'll still be annoying at times. E.g. if I fork a package that does not have it, I'll have to remove it from my commits and the PRs I submit. And if as.package() keeps adding it back, I'll have to remove it over and over again....\nHow about reporting usage to google analytics, anonymously? Is that off limits? Probably, as even as much as a package name can be sensitive information. It could be opt-in, though.\n. On 20 Jan 2016 18:22, \"Jim Hester\" notifications@github.com wrote:\n\nIf the idea is to communicate back to devtools users the GA idea won't\nhelp (it is an interesting idea though).\n\nDevtools can send the package name to GA. The email address as well, but\nthat might be too much....\n\nCould we add a registration prompt to devtools that would ask devtools\nusers to send their email addresses to us? They could be entered in a\ndrawing to win devtools stickers as incentive to register?\n\u2014\nReply to this email directly or view it on GitHub.\n. :+1:\n. @jpmorris Looks like you want to change the library directory. I think you can do that easily using:\nwithr::with_libpaths(new_lib, install_github(...)).. Installing a package does not load or attach it. library() does both.\n. Periods are totally fine in package and repo names. A lot of packages and repos have them. You must have made another mistake.\n. ++ :100:\n. Btw. this makes me want to create an unloader package. :)\n. Yeah, I am adding a test case in the remotes package, exactly the same way:\nhttps://github.com/MangoTheCat/remotes/blob/800ac4486fba4e3e183559aac6c02ff818d007e8/tests/testthat/test-install-github.R#L263-L295\nI can add it here, too.\n\nNeed some more time to get it right, though. Might be easier to create an object by hand. \n. Btw. I found this while trying to get 100% test coverage for remotes. This was the single line of code not covered. :) \ncovr FTW!\n. I'll refactor the whole compare_versions code, because I just can't keep the -2, ..., 2 codes in my mind.... they also seem to be broken (another way), but I am not sure until I refactored it...... \nThe refactoring can be in another PR, or here, as you wish.\nEDIT: not sure\n. I have added test cases. \nI have also added comments to compare_versions and related functions, and renamed compare_versions arguments, for readability. (Did not find more bugs.)\nRebased.\n. Merged Jim's PR, and rebased.\n. I agree it is useful to set a PAT, my packages are regularly over the rate limit, too. I guess we are all competing with each other.....\n. @wch One possible explanation is that your R session has been running for a day or so and you had an old version of the aviailable.packages() table cached.\nI'll fix this in mangothecat/remotes, with a simple alternative approach: we just try both urls, the current first, and the one in Archive if the current fails.\n. AFAIR available.packages() itself uses a cache now, so maybe we could scrap the caching entirely.\n. Btw. I think simply trying both URLs is still a better solution, gets rid of the expired cache problem, an (admittedly improbable) race condition, and also omits downloading the large available.packages() table.\n. You'll probably need some trick with the .git file, AFAIR that is ignored/complained about by R CMD build or check. So you might need to put in a git file without a dot, and then copy it to .git in the test, and then remove it in on.exit().\nI am not completely sure, but don't be surprised if it happens.\n. @jennybc I don't think that you can do this with .Rbuildignore. But you can create a .git or the whole test folder dynamically. Maybe the best is to just zip up the folder and extract it in the test. Quite cumbersome....\n. Of course install-time stuff is always dangerous, because you might end-up with an out-of-date version in devtools. E.g. if a bug is fixed in withr (assuming it has bugs, sorry :), then you need to re-install devtools to fix it. \nIMO it is better to \"import\" them in .onLoad().\nI know that you know all this, just a reminder. :)\n. Looks like base R reads the source files like this:\nhttps://github.com/wch/r-source/blob/b156e3a711967f58131e23c1b1dc1ea90e2f0c43/src/library/tools/R/admin.R#L235\nI.e.:\nr\ntools::list_files_with_type(\"R\", \"code\", full.names=FALSE)\nThis puts the unix/ subdir at the end, somewhat surprisingly, because then the usual zzz.R file is not the last any more....\n. I have no idea about the locale setting. I am trying to test, but the docs says:\nSys.setlocale(\"LC_COLLATE\", \"C\")   # turn off locale-specific sorting,\n                                        # usually, but not on all platforms\nso maybe this is hard to test.\n``` r\n\nlibrary(tools)\ndevtools:::withr_with_collate(\"C\", list_files_with_type(\".\", type = \"code\"))\n[1] \"./gabor.R\" \"./g\u00e1bor.R\" \"./gbor.R\"\nSys.getlocale()\n[1] \"en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\"\nlist_files_with_type(\".\", type = \"code\")\n[1] \"./gabor.R\" \"./g\u00e1bor.R\" \"./gbor.R\"\n```\n\nI guess we can just leave the locale, to be on the safe side, I'll update the PR.\n. How about now? :)\n. I like BatchJobs a lot, but that brings in a lot of dependencies, and devtools already has some biggish ones.\n. @hadley Looks like not. :( I suppose SSH would work on windows, but needs an SSH server.....\n. Personally I hate the parallel API, zero feedback to the user..... anyway.....\n. drat repos are regular CRAN-like repositories imo, so they are better handled via the Additional_repositories field in DESCRIPTION. (See Writing R extensions.) The Remotes field is not supported by CRAN, whereas Additional_repositories is.\n. Yes, https://github.com/metacran/description\nIt'll go on CRAN soon, I am considering adding a non-OO API to it, and then it is good to go.\n. FYI, pipes definitely work on windows, e.g. https://github.com/MangoTheCat/rcmdcheck/blob/f51b1407b1f0b7bbebad798b2f01ace6db0ea88f/R/safe_system.R#L26-L38 \nopens a pipe and calls a callback function for every line. I checked it on windows as well.\nSince pipe starts a new process, you don't even need parLapply, because that's an extra process again. \nThe alternative is just to read the output log files line by line, while the check is writing it. This is not completely trivial to do in R in a portable way (seeking in R is not reliable on windows), but I remember that I managed to make it work. I should be able to find the code, I abandoned it in favour of the pipe approach.\n. @hadley That certainly looks like a good option, but the current devtools package check code is not really compatible with it. I.e. you cannot simply call check() in the child (parLapply child or pipe child), because that will start another R process. I mean, you can, but there will be an extra process. Which might not be such a big deal, actually.\nYou would need to have a new version of the R() function, that runs R() via a pipe. Certainly possible, maybe not even difficult.\n. Kinda. Currently\n1. desc keeps the space if it is there, keeps its absence if it is absent, and adds it to new fields it creates.\n2. devtools does not add spaces AFAIK.\n3. RStudio removes the space AFAIK.\nIt would be great to change 3. imo, but that's a separate issue.\n. load_all also loads the non-exported functions by default, so it is already different from library().\nBut I agree that loading the test helpers by default is a bit too much. Usually I don't have any helpers, so not a serious issue, but it is sometimes annoying.\n. I would second @kforner on this. It would be nice to have an option to avoid the test helpers, as one don't always needs them. At least I mostly don't. :)\n. I suppose so, but these are not quite the same and somewhat less convenient. \nIs there really anything against an option that defaults to the current behaviour? \n. I think this is fixed in remotes, actually.. Well, the check is already there, you get a NOTE when release() runs the check. So in this case there is nothing to do.\nI was thinking about removing it from the built tarball (with a warning or message). \n. Sure, makes sense, I was already thinking about it. How about\n- get_remotes()\n- set_remotes(remotes)\n- add_remotes(remotes)\n- del_remotes(pattern)\n- clear_remotes()\n  ?\nThis basically matches the other helpers in desc, e.g. for URL.\n. Actually, I am writing this now, and you would also need sg that updates a location, because it happens relatively often that you specify a (different) tag or hash for an existing remote. So I'll add \n- update_remotes(remotes)\nas well. This is more work, as I need to parse the location to see which one needs to be updated.\nOr maybe add_remotes() should just handle this automatically, and update instead of just append.\nAlso, it makes sense to warn if a remote is added but the package is not in any of the dependency fields.\n. OK, I'll leave out the updating part for now, there is no proper API for it anywhere.....\n. There is an implementation in https://github.com/metacran/desc/commit/dc6d680eaf333e083dd48db1ae6fc8fe52e35eba\n. Hi all. I don't think remotes is missing much that is needed for the reverse dependency checks. You don't really need updates, and I believe that it can handle bioc packages the usual way, you just specify the bioc repos.\nBtw. I am also working on a separate revdepcheck package, based on remotes and rcmdcheck, it is private for the moment, but will make it public soon.\n. Note that remotes does have some important open bugs, e.g. compiling on windows.\n. Here is a list:\n- [ ] Only install from if a different sha from current (https://github.com/hadley/devtools/pull/903)\n- [ ] Install sha of git repos (https://github.com/hadley/devtools/pull/1027)\n- [ ] install_bioc()\n- [ ] install_cran()\n- [ ] Always look up remote SHA https://github.com/hadley/devtools/commit/f0d6fae1ac8880846ea2103c77d296c689860c82\n- [ ] Move lazy download logic to install_remote 88f8f9b76fbac63763921bb0bfea9c6150a9f380\n- [ ] Add update_remote functionality to update_packages 00f3bef19c44c58540389aba61d617ad41a6ca59\n- [ ] Refactor remote and CRAN dependencies to use a common path for both cf2fbbfab9fd7edbfd256e20477b53e2696e9ec0\n- [ ] install_git: Support passthrough of credentials to git2r 91fddbf5d3376faf76527db51e4d212913b1ef21\n- [ ] install_git: Support detached HEAD b260b714e3ce39dc4bc1fa802c864ff24758c08a\n- [ ] Fully specify host url for install_github 463023920a73955874586ea2724231f3bef232fa\n- [ ] install_min\n- [ ] Install binary packages from zip files directly on windows 4d8e4e1b3d0ea4c40bf97b384f292f4619fb65dd\n- [ ] local installs use SHA1 if using git, otherwise use version numbers 7fcd8b90fb55cc8dd1638d84c7818b452a6a0832\n- [ ] install_svn updates: https://github.com/hadley/devtools/commits/master/R/install-svn.r?author=lev-kuznetsov\nVarious fixes. These might or migth not be relevant:\n- [ ] 5b20fe78bd2be22f7d47254d9dbb245cc1f85f2e\n- [ ] 3be587720b7a579287759465f943d06daad68a66\n- [ ] 276ae93813adbfb4db73d2f39070c063702f6fee\n- [ ] 5cd2d80e5c8af68822c2c3a506053f413fbc7f56\nPlus a bunch of stuff potentially in install.r, I didn't go over all of these:\nhttps://github.com/hadley/devtools/commits/master/R/install.r\nSo, yeah, a lot of stuff....\n. > I'm not sure how much of that you did in remotes?\nNot much. It is basically the code from (old) devtools, fixed up a bit, and some extra to get rid of dependencies or make dependencies optional.\nI would not mind refactoring it.\n. Can't these packages just use make? I don't know the details, just\nasking....\n. The Date field is not needed, you can just remove it completely. CRAN will add their own Date/Publication field to the package they put in the repository.\n. Create releases, and the built source R package to them. These will not contain the data-raw folder. Then you can install them with the @ notation: install_github(\"user/repo@release\") AFAIR.\n. I guess build() copies everything over to a temporary directory, and then the file modification dates are updated. It should be possible to copy over the files without changing the modification dates. . my_unzip is literally five lines, so that would rather be a nano-package. I would keep that in devtools. :) Unless there are some similar compress/uncompress functions, in which it would make sense to put them in some compress package. There used to sg similar on Omegahat....\nsystem_check OTOH would be useful in some system package. My processx package is similar but quite often overkill. I have similar safe_system functions in  many packages, and I am sure that many people have the same.... so a system3 package would make sense imo.\n. @hadley Agreed. It's just that basically the point of processx is to be async, and it would share zero code with a simple system3 package that just calls system, system2 or shell, synchronously.\nI think it is also a different use case, to do a quick sync call, or to start sg in the background and then manage it.\nAlso, processx is much harder to implement, I am still not even sure if it is possible to implement it reliably in R code only. I tried to put it on CRAN, but it killed win-builder..... So it might be replaced with sg. containing OS specific C code in the future.\nsystem3 is straightforward to implement, basically the devtools implementation is mostly sufficient, and I already have a bunch of other similar implementations. We would just take the union of these.\n. @wch Cool!\n. TODO list:\n- [x] add email argument\n- [x] make rhub package optional\n. Thanks for the suggestions, all should be fixed now.\n. Great, thanks for the quick fix!. AFAIK R code files must ASCII. You need to encode non-ascii characters using \\uxxxx escape sequences.. Again, R code files should be ASCII. UTF-8 R files might work on your system, but they might fail on another system. (Or on the same system with a different setting, like it happens to you.) This is regardless of what encoding devtools uses. It is very poor practice to write code that only works if the user's platform has a specific encoding.\nPlease see https://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Encoding-issues \nIn particular:\n\nThere is a portable way to have arbitrary text in character strings (only) in your R code, which is to supply them in Unicode as \\uxxxx escapes.. https://github.com/r-lib/devtools/issues/1421#issuecomment-287082810  still holds  I think.. >  As R sources are now required to be UTF-8\n\nWhy do you think so? This is from \"Writing R Extensions\":\n\nOnly ASCII characters (and the control characters tab, formfeed, LF and CR) should be used in code files. Other characters are accepted in comments14, but then the comments may not be readable in e.g. a UTF-8 locale. Non-ASCII characters in object names will normally15 fail when the package is installed. Any byte will be allowed in a quoted character string but \\uxxxx escapes should be used for non-ASCII characters. However, non-ASCII character strings may not be usable in some locales and may display incorrectly in others.. I think the problem is not the guide, but that R reads the source files in the default system locale. If  that is not UTF-8 (AFAIK it never is on Windows), then the installation of your UTF-8 package will fail.. Yes, it does work on Windows  if  your files are also in the local encoding (i.e. Chinese (Simplified)_China.936).  But if you package this up on this Windows and try to install it on a system with a different locale, that will probably fail.)\n\nI.e. the problem is using the same code files on all platforms.. @jimhester I believe that devtools assumes too much about the SVN directory structure. AFAICT this is the same issue that was fixed in remotes not too long ago: https://github.com/r-pkgs/remotes/pull/33\n@MikeWise2718 install.packages() does not use Remotes, so it does not try to install the dependency from SVN. But I guess the package author put the Remotes dependency there for a reason.. @MikeWise2718 The R-forge version of rgl has a Remotes field in its DESCRIPTION file, meaning that it requires some (dev version) of some package that is not available from CRAN, but needs to be installed from SVN. That's why the installation needs SVN. There is nothing broken in devtools in this respect.\nWhat @jimhester  says, is that even if you have SVN installed, it will fail, because there is another bug in devtools. This bug was fixed in the remotes package, which is an alternative to (and mostly a copy of) devtools::install_github(). \nSo what you can do is to\n Install SVN, and then\n Use the remotes package to install rgl from R-forge, or wait until devtools is fixed.. @MikeWise2718 Exactly. You would need to ask the rgl authors or try to look in the commit messages or NEWS file to see what exactly is wrong with the CRAN version of the dependency.. @bbolker Please try it, but do expect some hiccups. Feedback is much welcome!. I believe that remotes handles proxy configuration on windows better. Please open an issue there if you have problems.. E.g. test(). But also install(), because if you just do install_github(), then you will probably not add reload = FALSE.\nThis is sg I can work around for myself, but people that install my package from GH will not be aware of it, and they'll just see the crashes. Hence the suggestion to trigger a message from the package.\nBtw. I can add a stop() into .onUnload(), and while this will not stop the unloading, because it is converted to a warning, at least it gives a message. Looks like devtools::unload() does not call .onUnload(), at least I don't see the message.\n. Haven't. Can't reproduce. Maybe a \"wrong\" unzip program again? Although I am not sure how removing .Rbuildignore would fix that..... @imanuelcostigan Can you pls share a zip file that is problematic, and also the winzip version your colleagues have?. @hadley In the original error, the path is only about 90 characters long, that should be ok.. @wch I think digest was installed by devtools, which added the Remote* entries to DESCRIPTION, no?. I vote yes. Otherwise it is confusing. The package is from CRAN after all. . I don't think there are any situations in which this check is useful.\nIf you want to run the tests, then a warning about testthat being unavailable is hardly what you want, no?\nIf you don't want to run the tests, then just don't run them. :). >  If you want to run the tests but testthat is unavailable then what do you think would be more useful than a warning? Should it be a stop() error condition instead?\nYes, an error is more appropriate I think. Which you'll already get if testthat is not available, without your check.\n\nI agree that not running the tests is also fine, which is presumably why devtools sets testthat as Suggests rather than Depends.\n\nWhat I mean is that not running the tests is fine if you don't want to run the tests.\ndevtools sets testthat as Suggests, because testthat is not needed for using the package. It is only needed if you want to run the tests. But then it is needed and not optional.. In other words, I don't think it ever happens that you want to run the tests if testthat is available, but just want to ignore them if not. What would be this good for?. IMO, we should not do this, there is already an easy solution: .Rbuildignore.. @dkod Can you try it with the GitHub version of devtools?. Btw. here:\nhttps://github.com/hadley/devtools/blob/d8ab190cd05e4bd2a3688a1eab3324109060b111/R/install.r#L158\nargs should be opts, no? Otherwise opts is not used at all.... Actually, is there any reason not to use the internal tar implementation? Is it slow?. Yes, remotes. We'll need to look/ask around about problems with the internal implementation. It would be great if we could just use that.. This code runs at install time, which can be potentially dangerous. E.g. if they change trimws in the future. Unlikely, but still, in general it is just better to avoid install time code in packages.\nI wonder if we want to use the backports package, that creates the polyfill functions at load time, and very well maintained: https://github.com/mllg/backports. To my surprise, it seems that it is executed as install time, which sucks, and makes backports much less useful in its current state.\n:( \nOK, no backports then.. Anyway, I think we could still \n inject missing functions as load time, or\n just use our own implementation, always.\n. https://github.com/mllg/backports/issues/12\n. Personally I would be happy if Michel \"fixed\" backports, and then we don't have to maintain it. :)\nAnd for the current problem, I think we can just use our own replacement functions. . Yeah, not easy to choose between dependency-free and DRY.. @krlmlr If GPL is not a problem. Ideally I would keep things in backports, so that we don't need to maintain it and my non-GPL packages can use it. But I understand that being dependency-free is an important virtue.\n. The codecov website claims that they are integrated, but it still does not work me...... @pfgherardini was this with the GitHub version of devtools? If not, can you please try it with the GitHub version? Thanks.. Thanks!. You need to remove it before cran submission. \nIt is not supposed to be there in a CRAN package.. All R code in the package runs at install time.\nAn alternative is to download the large file at run time, and then put it in an appropriate directory.\n. Can you please provide a reproducible example?. This is the infamous R_TESTS catch. Put this at the beginning of your test file:\nSys.unsetenv(\"R_TESTS\")\n. Also, the create_... file should be a helper file, move it to tests/testthat/helper.R and then it is automatically loaded before the tests.\n. See this thread: https://stat.ethz.ch/pipermail/r-package-devel/2017q1/001313.html\nCan you please close this issue? Thanks.. I believe devtools::install_github uses libcurl, which checks the certificate of github.com. github.com is HTTPS only AFAIK.. That check warning also happened with HTTPS, without the redirection. It was a bug in one of the Haskell packages that Pandoc used.\nCRAN is using an updated Pandoc now, which should not have this problem.\nAs you said, the badge page redirects from HTTP to HTTPS, so it still makes sense to link the HTTPS version, to avoid the extra hop.\nChanging the other files, however, in the same PR, is not very good imo.. Actually, anyone knows what the reason is for not using the internal unzip implementation?. Sorry, for repeating this again, but can't we actually just use the internal unzip implementation instead of an external tool?. If it is only used to unzip downloaded repos, then it does make more sense in remotes, yes.. Either way is good. Adding unzip support to zip is easy. I would need to check if it supports unicode filenames.\nBtw. the internal untar is an order of magnitude slower than the external one, but internal unzip seems to be fine.. FYI, I'll release sessioninfo soon. Want to wait a couple of days, to see if any more issues come up with it.. With so many dependencies, I think this will be tricky. But let's try.. Sure, NP, I'll do it tomorrow.\nI don't even know why it needs 3.1.x any more. I should really make a note about these dependencies somewhere..... @hadley: I found it, it is in the roxygen repo, of course :/ https://github.com/klutometis/roxygen/issues/582#issuecomment-278310358\nSo the biggest issue is probably that testthat does not work on 3.0.x. Anyway, I'll make a desc release in a minute.. OK, desc submitted. . What's the package index?. I see. That would probably be a new roclet I think. . You can easily implement this with the packageDescription function, which is in base R.. If we just want to start running the checks, why do we need default_cran_check_platforms? Can't we just call check_for_cran ?. Oh, I see, the current function just takes the platform, of course. Yeah, that makes sense as well, I don't mind updating the package.. Actually, my CRAN submission just failed with:\nPackage has help file(s) containing install/render-stage \\Sexpr{} \nexpressions but no prebuilt PDF manual.\nIt happens to me EVERY TIME when I have code in the manual...\nAnyway, this is good now, so I can resubmit it with the changes we need. :)\n. Also, if you don't touch the dependencies, you still get this:\n\u276f install(upgrade_dependencies=FALSE)\nInstalling devtools\nError in curl::curl_fetch_disk(url, x$path, handle = handle) :\n  Could not resolve host: raw.githubusercontent.com\n(I was offline to show the error message.). For the record: you don't need the GitHub version of crayon, the latest version on CRAN is fine.. 2 months old, and definitely has col_align: https://github.com/cran/crayon/blob/c1b2524e6e7d0e666e425d31424f772647ed4fab/NAMESPACE#L23\nI guess you haven't restarted R, so the old version was still loaded.. Maybe it was something else, e.g. you have two versions installed at different places. I can only guess from here..... So, this  is actually a devtools issue, because  devtools always uses --timings, so maybe it needs an argument to make  this optional?  \nhttps://github.com/r-lib/devtools/blob/dbac1faa21b39de71229c7abbf27968b17facf9e/R/check.r#L169. Yeah, that's good, too.. And you  also need cran = FALSE,  because --as-cran also turns on the timings.. This is a pity, because now I don't know how to set compiler flags for load_all().... Tips are very welcome.... . I think this has been fixed in the remotes package as well, if you need something on CRAN now.. Yeah, if you need to install from svn during build, e.g. via the Remotes field, then I am afraid you cannot use remotes.. > Are you talking about the following?\nyes.\n\nI think the method currently used seems to install packages from source in some case even when there is a binary available\n\nI don't see how that is possible. Maybe if the user explicitly sets the type to source, but then that's the desired behavior?. pkgman fixes this eventually, but it would be nice to reproduce it, nevertheless. \"both\" works well in remotes:\n```\nsetting R_COMPILE_AND_INSTALL_PACKAGES to always\n\nremotes::install_local('tidyhydat',dependencies=TRUE,INSTALL_opts='--build')\nInstalling 64 packages: assertthat, backports, base64enc, BH, bindr, bindrcpp, bit, bit64, blob, cli, colorspace, crayon, curl, DBI, dbplyr, dichromat, digest, dplyr, evaluate, ggplot2, glue, gtable, highr, hms, htmltools, httr, jsonlite, knitr, labeling, lazyeval, lubridate, magrittr, markdown, memoise, mime, munsell, openssl, pillar, pkgconfig, plogr, plyr, praise, purrr, R6, rappdirs, RColorBrewer, Rcpp, readr, reshape2, rlang, rmarkdown, rprojroot, RSQLite, scales, stringi, stringr, testthat, tibble, tidyr, tidyselect, utf8, viridisLite, withr, yaml\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.5:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.5/PACKAGES'\nPackage which is only available in source form, and may need\n  compilation of C/C++/Fortran: 'tidyselect'\npackage 'assertthat' successfully unpacked and MD5 sums checked\npackage 'backports' successfully unpacked and MD5 sums checked\npackage 'base64enc' successfully unpacked and MD5 sums checked\npackage 'BH' successfully unpacked and MD5 sums checked\npackage 'bindr' successfully unpacked and MD5 sums checked\n...\n``. @jdblischak I am not entirely sure in which situations it makes sense to install old binary packages. Most of the time these are not available for R-release, anyway. The old binary builds available are for older R versions.. You meanpkgdown::build_site()`?. > I suggest that release should ask and delete the field temporarily before building the package. After the built for CRAN the original DESCRIPTION should be restored.\n\nI am not sure what is the use case here, but usually you add Remotes if the CRAN version is not good enough for you. And when you submit to CRAN, the CRAN version must be good enough for you, meaning that it is time to remove Remotes permanently.. > pkgman stuff if you are feeling adventurous.\nplease don't use pkgman yet. That's  (partially)  because install_github() does not call R CMD build on the package.  If you use local = FALSE (which should be the default imo), then  R  CMD build fixes the permissions of  configure:\n* checking for file \u2018/private/var/folders/59/0gkmw1yj2w7bf2dfc3jznv5w0000gn/T/RtmpPDEoK4/devtools9153552faec1/rstudio-httpuv-a868452/DESCRIPTION\u2019 ... OK\n* preparing \u2018httpuv\u2019:\n* checking DESCRIPTION meta-information ... OK\n* cleaning src\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\n* building \u2018httpuv_1.4.3.tar.gz\u2019\nWarning: file 'httpuv/src/libuv/configure' did not have execute permissions: corrected\nIt still fails, because install-sh  is  not executable, either:\nmake --directory=libuv \\\n        HAVE_DTRACE=0\nmake[1]: ./install-sh: Permission denied\nbut this can be fixed from configure, I think.. Btw., also, an explicit local = FALSE is not ideal, because it is not passed to the installed dependencies, so if httpuv is  installed  as  a dependency, it will still fail. The ideal solution would be to change the default for all install_* functions (but not for install()) to local = FALSE.. > I don't think it should be the default.\nWhy?. Even with  R CMD  build  --no-resave-data  --no-build-vignettes ?. This might be just https://github.com/r-lib/pkgload/issues/35\n. > My memory is that the version requirements of suggested packages aren't enforced, but I might be wrong.\nWRE has:\n\nVersion requirements can be specified but should be checked by the code which uses the package.\n\nKind of makes sense for a suggested package.. I think the next devtools release should fix this, as it uses rcmdcheck.. This was fixed in the dev version of devtools/remotes, but was not included in the 1.13.x patch versions.. It just means that the bugfix was not included in any released version of devtools yet. It will be included in the next one, due soon.. Maybe there is a way to quote it, but I did not manage to get it working. It is possible that we would  need to quote and pass windows_verbatim_args down to processx.\nSo yeah, changing the working directory is much simpler.. check_win() should probably call build with manual  = TRUE here:\nhttps://github.com/r-lib/devtools/blob/95ba7657d7da116d08e900a5b5078f3a47d038a5/R/check-win.R#L60. AFAIK only if the package has  \\Sexpr, in which case you do need latex. For manual = FALSE it just omits the --no-manual flag, and R CMD build decides  automatically:\n```\n\u276f R  CMD build --help\nUsage: R CMD build [options] pkgdirs\nBuild R packages from package sources in the directories specified by\n\u2018pkgdirs\u2019\nOptions:\n  -h, --help        print short help message and exit\n[...]\n  --no-manual           do not build the PDF manual even if \\Sexprs are present\n``. Thanks!. I think a workaround is to check where the imported package is coming from, that's in the namespace info, seegetNapespaceInfo(), and add alib.locarg to thelibrary()` call, to make sure the same package is attached.. I tested it, it does work.. Or make it always pretty: https://github.com/gaborcsardi/prettyunits (sorry, again, self-promotion). If you don't want another dependency, the function is very small, so you can just take it: https://github.com/gaborcsardi/prettyunits/blob/master/R/sizes.r\n. Btw. archived packages are also red. \nBtw.2. Obviously, if someone else has an package with the same name on CRAN, then that package will be on the badge. Do we want a note about this in the docs?\n. Hmmmm. I am sure if GH would be happy about this. It is just a way going around (well, loosen) their rate limits. Also, I don't think we could implement realms without requiring authentication.\nI think a token is fine for now, but maybe I would create a devtools-robot user for it.\nBtw. what is GH's approach to publishing these tokens? Is that OK?\n. > A \"realm\" is just a string that identifies clients. New clients have to wait, existing trusted clients don't. But this doesn't really add any security, just a way to track and perhaps block users.\nYes, that's why you would need authentication. If it is done properly.\n\nI can't find a reference about publishing tokens other than \"guard them carefully\" ... \"like a password\".\n\n:) Well, imo that means that we should not publish tokens. Even if they can only read public data.\n\nWhy exactly are we using the API instead of direct download\n\nIn theory the download link might change. I doubt that it will often, so probably it would make sense to try the current scheme first, and then fall back to the API query. I think this is way better than setting up a token service.\n. Thanks! My son jumped on the 'e' key and it is half-broken now. :)\n. I thought about that, and rhub::check() allows that. But build_win() does not, so I went with a similar API. But I can easily add this. \n. Good point, I will do this, too. It is pretty lightweight, except for packages that are only needed by devtools: httr and curl. But if testthat is not required, then rhub should not be, either.\n. Minimal:\nhttps://github.com/r-lib/rcmdcheck/blob/master/R/build.R\nMaybe best would be to build, and then call rcmdcheck on the built tarball. Or to add build support to it. That should be just a pkgbuild call, no?. https://github.com/r-lib/rcmdcheck/issues/31\n. Maybe wait until that is done?. So, if I do this, then pkgbuild needs to go on CRAN before the rcmdcheck (and revdepcheck) release. I assume that OK.. yeah, think about the kittens before you use missing() :). ",
    "rmflight": "I think this was part of my motivation to get the git-SHA included in the extra package tags even when installing from local, and then get it to show up when using devtools::session_info, it's not officially part of the version number, but you can get the information and document it as part of an analysis. That was this pull request. I haven't checked in a while, but I think that is still the behavior ..... So it does. OK, that works much better. What was confusing me, was that even if the Rmd file is in inst/doc, that message still comes up. I think this is because it used to be possible to put everything in inst/doc. Alrighty then, sorry for the confusion.\n. Weird, when I have no vignettes directory, but inst/doc, I get the message that stuff is being moved\n. I have it. If there is an empty vignettes directory, then I get \"NULL\" returned, even if there is stuff in inst/doc. If there is no vignettes directory at all, but there is stuff in inst/doc, then I get the message, and nothing is actually moved\nIs this an issue with how vignettes used to be done?\nI see it was in 2.14 that we went from inst/doc to vignettes, I hadn't been keeping fully abreast of changes, and missed this one, especially because inst/doc still works.\nAlso odd is that one can have an Rmd in inst/doc, and creating a \"source\" package does create the vignettes properly. Good to be aware of.\n. What about combining devtools with https://github.com/cscheid/rgithub?  @cscheid\n. Check the requirements, the latest version requires R 3.0.2 at least.\n. Or is it possible to add the list of bioconductor repos as a repos source in package_deps??\nhttp://bioconductor.org/packages/release/bioc/\nhttp://bioconductor.org/packages/release/data/annotation\nhttp://bioconductor.org/packages/release/data/experiment\nhttp://bioconductor.org/packages/release/extra\nThese will return the list of available packages using available_packages, just checked on R 3.2.0 and devtools 1.8.0\n. But it looks like there would need to be a pull request to add these to the package_deps function before they would be useful in install_github?? \n. Given the already huge amount of stuff in devtools, why wouldn't one package these functions up into their own package?\n. +1 from me. More html vignettes is a good thing\n. but that is what devtools::install() is for, installing directly from either the current directory or a defined directory\n. not sure, but on my install of devtools (1.7.0), the example provided in install_local works fine, it installs a source copy of testthat correctly. Perhaps it is an issue with a directory vs a tarball? I would test to see what the issue is. It also may be that the documentation needs to be updated that it actually expects a built package as a tarball.\n. aha, if it used to work in 1.6 with directories, then you might have a legit issue. Imma let @hadley handle this.\nI only chimed in when I saw this issue because I've only ever used install, and didn't even know about install_local.\n. Fair enough. I'll add that in, and think about the tests to check it.\n. This is something that should be done on any local install, correct? So it would apply to both install and install_local, because this property could occur in both cases. So it would go in the logic for remote_metadata for local and package, and perhaps give a warning, but continue to install?\nhttps://github.com/rmflight/devtools/blob/install_sha/R/install-local.r#L44\nI like the idea of maybe having a clean_tree function that is the default argument to add_sha. I'll try a couple of things and see what works, especially for both install and install_local\n. what about is_wd_clean for the function? where wd is working directory, this fits with the message from git on a clean repo of: working directory clean\n. Poking around the git.R file, there is the function git_uncommitted (https://github.com/rmflight/devtools/blob/install_sha/R/git.R#L11), but it is currently unexported. Should I use this function and export it, or create an alias function with a nicer name that is exported? I like is_wd_clean or git_wd_clean as functions that match up to the status messages that git supplies with git status\n. Nope, never mind, just realized I got my logic completely backwards. WD should be clean if all changes are committed, so we do the check, and then make the modification. So this shouldn't be that big an issue, but I just spent past hour thinking it was. Will have to undo and then try again. Will try later, going out atm.\n. Added the modifications we talked about. All tests pass. If you think the general approach is good, then I would need to add documentation on the devtools.git.wd.clean option, and I maybe should add a couple of more tests that things do continue working properly when called from install, but overall I think it works well.\n. Yeah, but it gets more complicated if we want it to revert to local from local (/@sha) when there is a dirty working directory. The current method modifies the DESCRIPTION file in place, and then leaves it there. I have made another branch that I think is more along the lines of what you proposed in the first place, @jimhester.\nDo we want the behavior of going from local (/@sha) to local if the working directory is dirty? If so, that may take a bit more work. If so, I'd also take feedback on how to do that.\nMy initial thought is to copy DESCRIPTION, modify the one in place, install, then put original DESCRIPTION back. This should keep git from complaining too much as well.\n. OK, I was basing my implementation on install_local, which does modify\nthe DESCRPTION file, but I will look again at the implementations.\nWill take a look at all this again tonight.\nOn Thu, Jan 14, 2016, 5:55 PM Hadley Wickham notifications@github.com\nwrote:\n\nQuick thoughts:\n-\n@jimhester https://github.com/jimhester's implementation of\n   git_wd_clean() is adequate, and doesn't need to be exported\n   -\ngit_wd_clean() would be better called git_committed() or similar\n   -\nYou shouldn't need to modify the description file. Why can't you use\n   the same approach install_github() uses to add extra metadata?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/pull/1024#issuecomment-171807926.\n. OK, have confirmation that the actual DESCRIPTION file is modified.\n\nBased on the master branch, I modified install_remote with a readLines() and a cat of the DESCRIPTION file before and after add_metadata.\nThen I did a call to install_github(\"rmflight/categoryCompare2\")\nbefore add_metadata\nPackage: categoryCompare2\nVersion: 0.99.158\nTitle: Meta-analysis of high-throughput experiments using feature\n        annotations\nAuthor: Robert M. Flight <rflight79@gmail.com>\nMaintainer: Robert M. Flight <rflight79@gmail.com>\nURL: https://github.com/rmflight/categoryCompare2\nBugReports: https://github.com/rmflight/categoryCompare2/issues\nLicense: GPL-2\nDepends: R (>= 3.1.0), Biobase, BiocGenerics\nSuggests: knitr, methods, GO.db, estrogen, org.Hs.eg.db, hgu95av2.db,\n        limma, affy, genefilter, testthat\nImports: AnnotationDbi, hwriter, GSEABase, Category, GOstats, annotate,\n        colorspace, graph, RCytoscape (>= 1.5.11)\nLazyLoad: yes\nDescription: Facilitates comparison of significant annotations\n        (categories) generated on one or more feature lists.\n        Interactive exploration is facilitated through the use of\n        RCytoscape (heavily suggested).\nSystemRequirements: Cytoscape (>= 2.8.0) (if used for visualization of\n        results, heavily suggested), CytoscapeRPC plugin (>= 1.8)\nbiocViews: Annotation, GO, MultipleComparison, Pathways, GeneExpression\nVignetteBuilder: knitr\nafter add_metadata\nPackage: categoryCompare2\nVersion: 0.99.158\nTitle: Meta-analysis of high-throughput experiments using feature\n        annotations\nAuthor: Robert M. Flight <rflight79@gmail.com>\nMaintainer: Robert M. Flight <rflight79@gmail.com>\nURL: https://github.com/rmflight/categoryCompare2\nBugReports: https://github.com/rmflight/categoryCompare2/issues\nLicense: GPL-2\nDepends: R (>= 3.1.0), Biobase, BiocGenerics\nSuggests: knitr, methods, GO.db, estrogen, org.Hs.eg.db, hgu95av2.db,\n        limma, affy, genefilter, testthat\nImports: AnnotationDbi, hwriter, GSEABase, Category, GOstats, annotate,\n        colorspace, graph, RCytoscape (>= 1.5.11)\nLazyLoad: yes\nDescription: Facilitates comparison of significant annotations\n        (categories) generated on one or more feature lists.\n        Interactive exploration is facilitated through the use of\n        RCytoscape (heavily suggested).\nSystemRequirements: Cytoscape (>= 2.8.0) (if used for visualization of\n        results, heavily suggested), CytoscapeRPC plugin (>= 1.8)\nbiocViews: Annotation, GO, MultipleComparison, Pathways, GeneExpression\nVignetteBuilder: knitr\nRemoteType: github\nRemoteHost: api.github.com\nRemoteRepo: categoryCompare2\nRemoteUsername: rmflight\nRemoteRef: master\nRemoteSha: 0478ba3af9914f0df7598b47c7ccc9d9c3c91de8\nGithubRepo: categoryCompare2\nGithubUsername: rmflight\nGithubRef: master\nGithubSHA1: 0478ba3af9914f0df7598b47c7ccc9d9c3c91de8\nThis works OK on github remotes because who cares about modifying the downloaded source that will get redownloaded. \ninstall_local also takes the directory, and copies the whole thing off to a temp directory, and then does install_remote on it, from what I can tell https://github.com/hadley/devtools/blob/master/R/install-local.r#L19\n. Yep, confirmed that install_local first copies everything off to a temp directory, and then does the same process as install_remote. I'll think about this some more and think of which function can be modified without breaking anything.\n. OK, I like this idea, but have some questions:\n1. I didn't think what I ended up doing in this pull request was that complicated. Sure it is a 2 pass call to install, but it keeps it doing what it does best.\n2. This is completely different than the approach that all of the other install_ use to add metadata, and I worry about debugging that in the future\n3. I thought it was bad practice for functions to be able to modify system files once they are copied into the system. From that perspective I would worry about this not passing a CRAN review.\nI'm willing to implement and properly test your suggestion, but just wanted to bring these up.\n. OK, I like that idea even better.\nFinal point, add to this pull request, or start over and submit a new one?\n. So currently, the remote_metadata is an S3 function, with methods for github_remote, local_remote, etc. So I would see adding a new method for package, and then have something like:\n```\ninstall <- functioin(...., metadata = git_committed){\nif (is.function(metadata)) {\n  metadata <- git_committed(pkg$path)\n} \nR CMD stuff\nif (metadata) {\n  new_metadata <- remote_metadata(pkg)\n  add_metadata(base::system.file(package = pkg$package), new_metadata)\n}\n```\nDoes that seem reasonable? I'll start actually coding something up.\n. OK, trying it out, and there is an issue. packageDescription (which session_info uses to get package informationdoes not read from DESCRIPTION directly, but rather readspackage.rds, which looks like it is generated at INSTALL. This gets read byreadRDS. I've got an implementation, but the test indicates that it doesn't work at modifying the information that shows up insession_info, which is what I think has to happen for this to be useful.\n. As I noted, https://github.com/hadley/devtools/commit/70b9b25890ca1e89d902d6bec83a8591e4d75c56#diff-17d36a2a2b0eac6b55b22dae5787dc48R167, this test fails becausepackageDescriptionusesreadRDS. So we either need to change theadd_metadatato modify both the DESCRIPTION and thepackage.rdsfile, or changesession_infoto useread.dcf` in the package location.\nDo you or @hadley know offhand if there is a function for writing RDS files outside of what INSTALL does?\n. just found it, looks like saveRDS\n. I also think I might need to create some tests just for metadata checking\n. OK, this works (rmflight@9c7447a961), and passes all of the previous devtools tests, and passes the new ones I wrote to check that the SHA1 is being written in.\n. In for a penny, in for a pound. May as well make it consistent somewhere else.\n. That sounds really useful and cool @hadley, but can we maybe make an issue and assign it to me, and I can work on that particular feature some other time?\nI want to get the reporting in session_info cleaned up, and then have this as a stand alone pull request and be done with it at this point.\n. ok, rmflight@bb9e337 has a modified session_info that will generate:\nfrom github:\ncategoryCompare2    * 0.99.158   2016-01-15 Github (rmflight/categoryCompare2@0478ba3)\nfrom local git with clean tree and metadata not NULL:\ntestMetadataInstall * 0.0.0.9000 2016-01-15 package (@373e621)  \nand then local git with a dirty working directory:\ntestMetadataInstall * 0.0.0.9000 2016-01-15 package               \ndoes that work for you @jimhester ?\n. OK, fair enough on the package vs local. \nIf changing this, I feel like remote_metadata.local_remote and remote_metadata.package should be doing the exact same thing as far as annotating the metadata.\n. OK. Originally went with two functions so it would be easier to change in the future if decided they should be different, but you are right, currently they are the same, so should just alias one from the other.\nI will give rebasing an attempt, this is the first time I've tried to use it.\n. Thanks, that helps.\n. OK, successfully rebased onto current devtools/master\n. Given that this makes the metadata a first class thing that the user can see, should the various remote_metadata methods be documented as far as what metadata will be added to the DESCRIPTION?\n. Is there an easy way to tell that it was done by load_all so as to avoid\nthis? Or maybe we can look for the package in the directory specified by\n.libPaths()?\nOn Wed, Jan 20, 2016, 5:56 PM Hadley Wickham notifications@github.com\nwrote:\n\nThe problem is that base::find.package(pkg$package) doesn't give the\ninstalled path for a package loaded with devtools, but instead gives the\npath to the source package. This will only be a problem if you've run\nload_all() before install(), but that seems like a fairly common scenario\nto me (and is certainly something I'd do)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/pull/1027#issuecomment-173391076.\n. Used inst() in 1c3fccd, and added a test of load_all(); install() to double check that the correct instance was indeed modified.\n. @jimhester: using withr::with_temp_libpaths() in the test suite 2f54a5e6\n\n@hadley: bullet added to News.md 526db44\n. OK, I'm curious, how do I resolve a conflict that I can't see?\n. Thank you! And thank you and @jimhester for all of your support and coaching through this process. Just so you know, this was my first pull request that involved any amount of real code, and you both made it a pretty cool experience.\n. so remove the clear_description_md5, as it is no longer needed because the metadata is not being added before install?\n. done in 0688b7e\n. Sorry, missed this while making merges in rebasing ontop of current master\n. so something like:\n```\n' @param metadata \\code{list} of metadata (normally generated by \\code{remote_metadata}) to\n'    add to the DESCRIPTION file after installation.\n```\n. Yes, some functions will look to one or the other, so both files (if present) need to be modified. It might be a good idea to add a warning that neither file exists and metadata couldn't be added?\n```\nif (file.exists(source_desc)) {}\nif (file.exists(binary_desc)) {}\nif (!file.exists(source_desc) && !file.exists(binary_desc)) {\n    warning(\"No DESCRIPTION found, metadata not added!\", call. = FALSE)\n}\n``\n. no problem.\n. done in 30f9d406\n. removed call toclear_description_md5` in 6467f7c, running tests suggests it doesn't break anything. I wonder if the function is needed at all in the code anymore? I think this was the only place it was being called.\n. just to be clear, we are now modifying the DESCRIPTION after installation.\n. yep, they sure do.\n. gone as of adcb043\n. I admit the logic is confusing, it took me a good while to work through it myself. \nis it the setting of variables to character(0) and then setting them is the problem? I did that to avoid a bunch of if ... else constructs that in my mind clutter up the code, but I can do it that way instead.\n. the logic is bad because we want to delineate between:\nremoteType (username/repo@commit)\nremoteType (username/repo)\nremoteType (@commit)\nremoteType\n. Hopefully a little clearer in cbb090e\n. explanation added in 7ec9b258\n. From the context, I think it was probably meant to be on hand, but I agree with @jennybc that happy or some other positive emotion. happy is probably the simplest.\n. ",
    "lock[bot]": "This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/\n. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. This old issue has been automatically locked. If you believe you have found a related problem, please file a new issue (with reprex) and link to this issue. https://reprex.tidyverse.org/. ",
    "halpo": "sure do I submit as as new pull request or is there a way to update this one?\n. I think that cleans everything up.  This should now be ready to pull in.\n. I think I caught all the style changes.  See my note about the utils::readRegistry use.  I might be wrong about the namespace stuff, but it failed on my linux box.\n. I noticed that with the new Rtools 2.15 the directory structure is different.  The folders are\nfor 2.14 \\\n- C:\\Rtools\n  - bin\n  - MinGW\n  - MinGW64\nfor 2.15 \\\n- C:\\Rtools\n  - bin\n  - gcc-4.6.3\nShould this be checked and accounted for or assume the most recent (2.15)?  Or perhaps I have my setup messed up, which is entirely possible with windows.\n. I added to .onAttach the conditional logic for Rtools 2.15.  This also adds some safer code that prevents failures if there is something particularly odd with someones setup.\n. Updated pull request with spacing changes and documentation additions.\n. I attempted to rebase then update the pull request.  I'm not sure that it came through correctly.\n. Will replace this pull request with one that is much cleaner.  The only files that are relevant are the path.r and zzz.r and the derived help files.  Those will be reflected in a new pull request coming shortly.\n. No optimization.  In some cases this could severely hurt the performance.  It really only makes a difference in the compiled code, but could tremendously help the packages building off Rcpp.  It could be an option in the regular install function, but I like the feel of the separate debugging install.  When writing it for myself I didn't really want to mess with the install, so that I could rebase/patch in the future more easily.\n. Updated with NEWS, and realized that I should flush out all the compile flags.   I'm not sure about the Fortran flags, as I never program in Fortran, perhaps there is someone that could comment on the appropriate default flags for debugging builds.\n. The changes that you requested should be in this pull now.\n. Yes looks fine to me.\n. would making the call as you list fix the test() problem?  The NULL denotes to automatically find the package not just a specific install version.  I realize that the second problem might not ever get fixed.  The only solution to that might be to install to a temporary directory and then load from there, but that kind of defeats the point of load_all()\n. readRegistry only exists on Windows adding a namespace declaration creates build fail on linux and mac systems.  In this case I think that It is better to use the explicit utils::readRegistry.\n. utils pacakge uses \nif(tools:::.OStype() == \"windows\") {\n  export(readRegistry)\n}\nBut I'm an aware how to add system dependent NAMESPACE declarations through roxygen2, might be useful.\nsee http://svn.r-project.org/R/trunk/src/library/utils/NAMESPACE\n. Do you think that all path manipulation functions should be grouped together?\n. The try statement will help  prevent someone from really screwing something up.  Such as the case for updating from 2.14 to 2.15 the MinGW folder no longer exists, adding it to the path will throw an error from add_path.   The try ensures that .onAttach runs successfully.\nYes that is a typo.  not sure how that got there.\n. ",
    "richierocks": "Also, minor thing but url and zip_url would be a little cleaner as\nurl <- paste(\"https://github.com\", username, repo, sep = \"/\")\nzip_url <- paste(\"https://nodeload.github.com\", username, repo, \"zipball\", branch, sep = \"/\")\n. Setting .libPaths() makes sense for day-to-day package installation.  Occasionally you might want to install to a different location though.  For example, if you want to install two different versions of the same package (http://stackoverflow.com/questions/2988559/how-do-you-use-multiple-versions-of-the-same-r-package) or you may have other reasons for wanting to keep the package out of your usual library.\nSetting .libPaths() and then reverting it seems clunky in this case.\n. OK, great, thanks.\n. Actually, looking into this further, you can do this more simply by using shQuote instead of dQuote.  That way there is no need to mess about with changing options.\n. Ok, it seems I haven't taken a look around devtools properly in ages.\nThis already exists. Duh.\n. Try Thomas Leeper's msgtools, though it's a work-in-progress.\n. @jimhester Thanks for the clarification!\nJust to be super clear on this, when students are taking the course in 2020 and one of the videos states \"to build your package, you need to call the build() function in the devtools package\", am I* going to have to deal with a load of complaints from students saying \"build() isn't in the devtools package anymore, it's in pkgbuild\"?\n\nBy \"I\" I mean the DataCamp support team in the future.. \n",
    "karthik": "In the case of ROAuth, I can report the same issue that Carl had. install_github works intermittently on some repos. It works sometimes without any error but fails at other times despite the lack of any updates to the repo itself. Just tried it again in dev_mode() and it works fine.\n. Thanks Winston. That makes a lot of sense. I should just update my .libPaths(). \n. @hadley done. \n. ",
    "philchalmers": "normalizePath did clean the code up a bit, thanks for the suggestion. \n. You're entirely correct, I was not using normalizePath effectively; my mistake. Function is now very simple (and now that I understand normalizePath better almost needless) but still gets the job done and saves precious keystrokes. \n. No, but collectively they add up to a lot and make Travis think the program has frozen. The devtools Travis run only takes some 27 seconds to run so that's just fine and Travis doesn't complain.\n* checking for unstated dependencies in tests ... OK\n* checking tests ...\n  Running \u2018has-devel.R\u2019\n  Running \u2018test-that.R\u2019 [22s/27s]\n OK\nBut for larger testing, if I were to run the R CMD check locally I would get something more like this: \n* checking for unstated dependencies in tests ... OK\n* checking tests ...\n  Running \u2018test-that.R\u2019 [25min]\n OK\nindicating that in total the tests took 25 minutes. Travis will fail on the long test since it times out after about 10 minutes if no output is being flushed to the console. So I've typically split up the check and test processes and make sure the testthat package prints the .'s to the console whenever an assertion is passed, like so:\n$ make test\nRscript -e \"library('testthat',quietly=TRUE);library('mirt',quietly=TRUE);options(warn=2);test_dir('tests/tests')\"\nmirtOne : ..............................................................\nmirtTwo : .........................................................\nbfactor : .........................\nmultipleGroup : ...................................\nconfmirtOne : ..................\nconfmirtTwo : ........................\nmixedmirt : ......................\ncreateItem : .......\nmirt.model : ......\nextras : ........................\nThe command \"make test\" exited with 0.\nIn hindsight though, since checks/tests are done on CRAN tests with testthat which take too long will probably not be accepted, so unfortunately this request seems futile if one is going to submit their package to CRAN. I'll close this request since there doesn't seem to be a point if in the end it just generates more headaches from/for the CRAN maintainers. \n. Interesting, thanks for the tip. I'll check that approach out.\nOn Thu, Jun 26, 2014 at 10:00 AM, Kirill M\u00fcller notifications@github.com\nwrote:\n\nYou could still create two files test-that-1.R and test-that-2.R, where\neach uses a different filter argument in their test_check call, and\norganize your test files accordingly. This should produce one output line\nper file, and you can even easily decide not to run the longer tests on\nCRAN's machines.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/481#issuecomment-47228810.\n. \n",
    "vspinu": "\nHmmm, I wonder if this should just be the default behaviour - you are using __dev__tools after all!\n\nIt is the default. getOption(\"keep.source\") is TRUE by default. Or what\ndo you mean?\n. > I was wondering why devtools shouldn't always assume you want to keep the code.\nI cannot see one such reason for devtools not to keep the source. So the\nargument keep.source can be removed as far as I am concerned.\n. This also explains why keep.source was not there in the first place. I fixed the compatibility issue. Opening a new pull as github  is not appending changes to closed pulls. \nThanks for tracking this down.\n. First patch was tested with a month old R trunk and it had effect. Second\npatch had effect in 2.15 as well. Without them r is not reporting source\nreferences. So they are needed. Unless there is a smarter way to fix that,\nplease don't delete.\nOn Friday, 19 July 2013, hadley wickham wrote:\n\nI think the original diagnosis and fix was incorrect - keep.sourcedoesn't actually have any effect in this case, because I'm already\nexplicitly suppling srcfile to parse.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/pull/319#issuecomment-21257968\n.\n. Ok, I am back and just looked into it more carefully. It turned out that it was\na messup on my side. The problem was fixed 5 weeks ago in f40a25c. My installed\ndevtools was dated earlier, and I was so much in a hurry to fix it, that I\ndidn't notice the minor change in code while pulling it up.\n\nAnyways, for reference, a complete and reproducible description of the problem\nis here: https://stat.ethz.ch/pipermail/ess-help/2013-June/009190.html\nPlease revert this patch. Sorry for the havoc.\n. > > Rainer M Krug notifications@github.com\n\n\non Sun, 21 Jul 2013 23:47:06 -0700 wrote:\n\nUnfortunately, I deleted the file from dropboxsome time ago. Vitalie - do you\npossibly still have it?\n\nhttp://vitalie.spinu.info/tmp/testTraceback_0.0-1.tar.gz \nI don't think a formal test is worth here.\n. The error is reported as expeted. So, devtools works. ESS also\nhighlights the error as expected. \n\n\nRainer M Krug notifications@github.com\non Mon, 16 Sep 2013 02:38:22 -0700 wrote:\ntestprog()\nError in x + 1 (from testprog.R#2) : 'x' is missing\nsessionInfo()\n. Ok, I think this is a recent change in R. R doesn't report a full path anymore. ESS doesn't know where your testprog.R#2 comes from but you can open it manually and then click on the reference link, or register the containing directory in ess-tracebug-search-path. \n\n\nAs to traceback() not reporting error location, that is indeed weird and I think it's an R issue. \n. > > Winston Chang notifications@github.com\n\n\non Thu, 18 Jul 2013 14:22:25 -0700 wrote:\n\nActually, is it necessary to call options(keep.source = TRUE) from source_one(?\nI ask because that option is also set from the source_many() function.\n\nYeh, I also was wondering about that. It didn't work before, so the\npatch was necessary. \nI am leaving for 4 days soon and will not be able to incorporate your\nstyle suggestions. Please feel free to ignore my patch and add your own.\nVitalie\n. > > Winston Chang notifications@github.com\n\n\non Thu, 18 Jul 2013 14:19:07 -0700 wrote:\n\n\n[...]\nWC> * Indents should be two spaces. \nBTW, I was planing to bring this to RStudio for quite some time\nalready. R official standards suggest 4 spaces [1] and it is widely\nregarded that gnu default 2 spaces is not very readable, be it R or any\nother language. Screens are now larger and 4 spaces is a good default.\nWe at ESS just switched the default from 2 to 4 a couple of months\nago. Would be really nice to see similar change in R Studio.\nVitalie\n[1] http://cran.r-project.org/doc/manuals/R-ints.html#R-coding-standards\n. download.file(\"https://github.com/hadley/devtools/archive/master.zip\", \"devtools.zip\", \"curl\")\n. @jonkeane, have you dug into this further? It's quite a headache I must say.. I am seeing it on a repo which is not public yet, but I could make it available. Whatever I do RcppExports is not automatically created, with neither install, load_all, or `document.\nI can reproduce it partially with lubridate with which RcppExports are only added if compilation is invoked: \n```sh\ntmp$ git clone https://github.com/tidyverse/lubridate.git\ntmp$ cd lubridate/\nlubridate$ R-devel\n\ndevtools::install(\".\")\nquit()\nlubridate$ rm -rf src/RcppExports.cpp R/RcppExports.R \nlubridate$ R-devel \ndevtools::document(\".\")\nUpdating lubridate documentation\nUpdating collate directive in  /home/vspinu/tmp/lubridate/DESCRIPTION \nLoading lubridate\nquit(\"no\")\nlubridate$ ll src/ | grep Exports\n-rw-rw-r-- 1 vspinu 1.5M Mar 21 21:42 RcppExports.o\nlubridate$ ll R/ | grep Exports\nlubridate$ \n```\n\nWhat kind of hints document uses? I should be able to debug this myself if I knew in which package the logic lies. There is not a single mention of RcppAttributes in the entire repo.\nThis is outside R-studio btw, with:\nR\nR Under development (unstable) (2018-02-17 r74265) -- \"Unsuffered Consequences\"\nIt might have something to do with the fact that the repo in question doesn't have Collate: derective in the DESCRIPTION. \nWith lubridate, if I delete all object files, trigger document, at the end of the re-compilation I see:\nR\nAdding files missing in collate: RcppExports.R. Ok. I have figure this out. It was the install_min which was running the preclean and deleting my RcppAttributes. I had rm src/RcppExports.cpp R/RcppExports.R in my ./cleanup. Well. Now I know :/\nI think it would make more sense to first preclean and then compileAttributes, no?\n\nIf you want to explicitly compile them yourself you can do so with \n\nSure, but in my mind RcppAttributes is more about documentation rather than compilation. Just like @export are parsed by document and NAMESPACE is updated, I do expect // [[Rcpp::export]] to be parsed and relevant files added regardless of whether compilation is triggered or not.. ",
    "markheckmann": "I uploaded two minimal R packages to two repos on my bitbucket account. \ninstall_bitbucket(c(\"testrepo\", \"testrepo2\", \"markheckmann\", \"master\")\nThis works. Unfortunately there is no feature on bitbucket to sort repos by language. I found only one R project hosted on bitbucket: readgrads.\nHere things don't work:\ninstall_bitbucket(\"readgrads\", \"paulhiemstra\", \"default\")\n...\nError: Does not appear to be an R package\nThe reason: bitbucket allows for git or Mercurial version control. readgrads uses Mercurial. I found the reason for the error in the name choosing mechanism in devtools:::decompress. \nexpand <- unzip\noutdir <- function() {\n  basename(as.character(expand(src, list = TRUE)$Name[1]))\n}\nThe dir name is chosen applying basename to the first entry as returned by unzip -l. This works for the git repos but fails as the Mercurial repo seems to contain the meta files that \u00b4.hg_archival.txt\u00b4 etc. \u00b4decompress\u00b4 will use these to indetify the file dir and fail. \nmarkheckmann$ unzip -l default.zip \nArchive:  default.zip\nLength     Date   Time    Name\n--------    ----   ----    ----\n149  01-25-12 14:38   paulhiemstra-readgrads-ca4e85315903/.hg_archival.txt\n  48  01-25-12 14:38   paulhiemstra-readgrads-ca4e85315903/.hgtags\n509  01-25-12 14:38   paulhiemstra-readgrads-ca4e85315903/DESCRIPTION\n...\nIn short:\nThings seem to work for git repos. For Mercurial (at least when archive metafiles are included) it fails. This might need touching devtools:::decompress. \n. ",
    "kenahoo": "Thanks.  Looks like it was 1e1654d7ffa184127ec7bf12989850ec43e70a07 .\n. My main point is that the effect lasts even after the tests are completed.  The functions are not just exported for the duration of testing.\n. Sorry, forgot to mention - I was using version 1.3 from CRAN, i.e. http://cran.revolutionanalytics.com/bin/windows/contrib/2.15/devtools_1.3.zip .  Is the github HEAD considered safe to use?\n. Great - it does indeed work for me.\nOn Wed, Aug 28, 2013 at 3:10 PM, Winston Chang notifications@github.comwrote:\n\nYup, the head of the master branch should be OK to use (although that's\nnot always true!).\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/341#issuecomment-23443593\n.\n. I can get it to work fine if I give it a path, but the docs say it can take a package name, and I was really hoping to use it that way.  Has that ever worked?\n. It could easily know by just calling the find.package() function, which is what I'll use as a workaround I guess.\n\nThis does seem like a common use case - install a newer version of a package (perhaps one under active development locally) and then in a long-running session, load the new package.  It would be nice to support that flow.\n. Given all that, I think there's still a bug here - load_all says it can take a package name, so that's a doc bug;  and if it really can only take a path string, then the code that's looking for a package object is also a code bug that should be removed.\n. Looking closer at install_version(), it looks like the version argument is an exact version required, not a minimum version.  So my example above would need to be:\nrepos <- c(Stable=\"http://myserver/cran-stable\",\n              Dev=\"http://myserver/cran-dev\",\n             CRAN=\"https://cran.revolutionanalytics.com\")\ninstall_version('MyPackage', '>= 0.23', repos)  # Installs from \u2018Stable\u2019\ninstall_version('MyPackage', '>= 0.24', repos)  # Installs from \u2018Dev\u2019\nand the version field would be extended to take a specification like the Depends: and Imports: fields in a DESCRIPTION file (and like those, multiple specs could be provided to be 'and'-ed together).\n. That doesn't work because dev packages can depend on prod packages.\n. Here's a scenario where that doesn't work: \n```\n  Repo-Stable:\n    Package A, version 1.2; depends on B (>= 1.0)\n    Package B, version 1.4\nRepo-Dev:\n    Package A, version 1.3-415; depends on B (>= 1.0)\n    Package B, version 1.5-31\n```\nIf I want to install the 'dev' version of A, then your suggestion would be to call install.packages('A', repos=c(repo.dev, repo.stable)).  But that would install B 1.5-31 as a prereq, even though the stable one satisfies the dependency.\nIn a nutshell, wanting the dev version of a specific package doesn't mean I want the dev version of all the other packages too.  If we could make my proposed change to install_version, then the order of repos would indicate the caller's policy (which would usually be \"prefer stable packages to dev packages\" but might be the other way around; it could also be \"prefer our local repo to a remote CRAN repo but fall back if necessary\").\nYour suggestion of tweaking options('repos') is exactly what we've been doing around here for a long time, but it's gotten extremely fiddly and annoying.  It basically makes the developer manually check & satisfy all dependencies up & down the tree, by hand.  In contrast, the Java developers in our office just tell Maven which version of which artifact they want, and which repositories can provide it, and Maven just figures everything out, which is what I'm hoping devtools can help with in a similar way.\n. Here's my forkbranch where I'm working on this: https://github.com/kenahoo/devtools/commits/install_version-multi\n. Even simpler, maybe it could only perform the check if it detects that an installation attempt failed?\n. I see this is failing the Travis & AppVeyor builds.  It seems to be a version thing on 'testthat', does it have something to with the change I made?\n. Any thoughts on this?\n. Great, glad to hear it!  Thanks for taking a look. \n. I just rebased this WRT master.. Wait - did you mean to close this?  It seems like it would be good to fix it.\n. I'd love to help if possible - we have a continuous build server for R packages that we sometimes have to go manually install/update stuff on when we hit this issue, and it would be nice to get it working more smoothly.  If I prepared a PR could you look at it, or is there already another package (materializing?) on this topic?\n. We're still struggling with this, could you comment on the \"another package\" you mentioned?. That sounds like a good plan.  Thanks for the update.\nI might create a forkbranch to see what could be done directly in devtools in the short term too.. Addendum: I upgraded to devtools 1.13.4 on general principle and I see the same behavior.. Oh, okay, thanks.  Do you happen to know whether the R-Devel people have already considered & rejected an improvement (from my perspective, anyway) to change that behavior so it doesn't copy them in the first place?. ",
    "bryanhanson": "Strangely, when I do .onAttach() R claims there is no such function.  Should I call it with some sort of prefix?  And I had to do http not https even though I was logged into my acct on github.  Thanks.\nOn Jun 15, 2012, at 2:22 PM, hadley wickham wrote:\n\nCan you please try the dev version?  I think it should be fixed. \nYou should be able to bootstrap yourself up with \nR\nlibrary(devtools)\nsource_url(\"https://raw.github.com/hadley/devtools/master/R/zzz.r\")\n.onAttach()\ninstall_github(\"devtools\")\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/103#issuecomment-6363203\n. Thank you, fixed.  I'll close the issue.  Bryan\n\nOn Jun 15, 2012, at 6:23 PM, hadley wickham wrote:\n\nIf sourcing doesn't work, try copying and pasting.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/103#issuecomment-6368021\n. \n",
    "ldecicco-USGS": "Not that I can see. I go to the temporary folder, and it's empty:\nC:\\Users\\ldecicco\\AppData\\Local\\Temp\\2\\RtmpUdVkNN\nThe message I get while running check() is:\n```\n\ncheck()\nUpdating dataRetrieval documentation\nWriting dataRetrieval-package.Rd\nWriting ChoptankRiverNitrate.Rd\nWriting ChoptankRiverFlow.Rd\nWriting FLUX_UNIT.Rd\nChecking dataRetrieval\n checking for file 'D:\\LADData\\R Code\\gitWRTDS\\MainRCodes\\dataRetrieval/DESCRIPTION' ... OK\n preparing 'dataRetrieval':\n checking DESCRIPTION meta-information ... OK\n checking for LF line-endings in source and make files\n checking for empty or unneeded directories\n looking to see if a 'data/datalist' file should be added\n re-saving tabular files\n building 'dataRetrieval_1.0.6.tar.gz'\n\nWarning: 'C:\\Users\\ldecicco\\AppData\\Local\\Temp\\2\\Rtmpq4Afu9/dataRetrieval_1.0.6.tar.gz' is neither a file nor directory, skipping\n```\nthen it stops.  Hope that helps.\n. I started having this error while using Rtools 215.  I upgraded to see if that would solve the problem, but it didn't.  I just uninstalled Rtools216, (re-)installed 215, and get have the same problem.  \nI noticed this on the R website concerning changes from 2.15.0 to 2.15.1:\n\"For R CMD check, a few people have reported problems with junctions on Windows (although they were tested on Windows 7, XP and Server 2008 machines and it is unknown under what circumstances the problems occur). Setting the environment variable R_WIN_NO_JUNCTIONS to a non-empty value (e.g. in \u2018~/.R/check.Renviron\u2019) will force copies to be used instead. \"\n...I really have no idea what that means, but that's what I was looking into recently.\n. Although I don't get an error on build(), no zipped package is created.  The messages in R are:\n```\n\nbuild(\"dataRetrieval\")\n checking for file 'D:\\LADData\\R Code\\gitWRTDS\\MainRCodes\\dataRetrieval/DESCRIPTION' ... OK\n preparing 'dataRetrieval':\n checking DESCRIPTION meta-information ... OK\n checking for LF line-endings in source and make files\n checking for empty or unneeded directories\n looking to see if a 'data/datalist' file should be added\n re-saving tabular files\n building 'dataRetrieval_1.0.6.tar.gz'\n\n[1] \"D:/LADData/R Code/gitWRTDS/MainRCodes/dataRetrieval_1.0.6.tar.gz\"\n```\nBut, there is nothing in D:/LADData/R Code/gitWRTDS/MainRCodes/ called dataRetrieval_1.0.6.tar.gz\nI finally got around to checking if it really was a problem with R 2.15.1 or the latest version of devtools, and it is NOT.  I have the exact same problem on a different computer where I only use R 2.14.1 (the same error before and after updating devtools).\nAs I said earlier, I've been building (and re-building) packages for awhile (6 months or so) with no problems, then all of a sudden this started happening, and it corresponded to when I updated my version of R - but a little more digging shows me that that must have been a coincidence.   I still am stuck, so if you have any suggestions, I'm all ears.  The packages I am trying to build are here:\nhttps://github.com/USGS-CIDA/WRTDS/tree/master/MainRCodes/dataRetrieval\nhttps://github.com/USGS-CIDA/WRTDS/tree/master/MainRCodes/EGRET\nI have a Mac that I've built a package on in the past. I am planning to try that out next.  Thanks for all your help.\n. I took the space out, and still no luck. \n```\n\nlibrary(devtools)\nload_all(\"dataRetrieval\",T)\nLoading dataRetrieval\ndocument()\nLoading required package: roxygen2\nLoading required package: digest\nUpdating dataRetrieval documentation\ncheck()\nUpdating dataRetrieval documentation\nWriting dataRetrieval-package.Rd\n...\nWriting dataOverview.Rd\nWriting fluxUnit-class.Rd\nWriting testFunc.Rd\nChecking dataRetrieval\n checking for file 'D:\\LADData\\RCode\\gitWRTDS\\MainRCodes\\dataRetrieval/DESCRIPTION' ... OK\n preparing 'dataRetrieval':\n checking DESCRIPTION meta-information ... OK\n checking for LF line-endings in source and make files\n checking for empty or unneeded directories\n looking to see if a 'data/datalist' file should be added\n re-saving tabular files\n building 'dataRetrieval_1.0.6.tar.gz'\n\nWarning: 'C:\\Users\\ldecicco\\AppData\\Local\\Temp\\1\\RtmpiWLGFr/dataRetrieval_1.0.6.tar.gz' is neither a file nor directory, skipping\n\nbuild(\"dataRetrieval\")\n checking for file 'D:\\LADData\\RCode\\gitWRTDS\\MainRCodes\\dataRetrieval/DESCRIPTION' ... OK\n preparing 'dataRetrieval':\n checking DESCRIPTION meta-information ... OK\n checking for LF line-endings in source and make files\n checking for empty or unneeded directories\n looking to see if a 'data/datalist' file should be added\n re-saving tabular files\n building 'dataRetrieval_1.0.6.tar.gz'\n\n[1] \"D:/LADData/RCode/gitWRTDS/MainRCodes/dataRetrieval_1.0.6.tar.gz\"\n\ninstall(\"dataRetrieval\")\nInstalling dataRetrieval\n checking for file 'D:\\LADData\\RCode\\gitWRTDS\\MainRCodes\\dataRetrieval/DESCRIPTION' ... OK\n preparing 'dataRetrieval':\n checking DESCRIPTION meta-information ... OK\n checking for LF line-endings in source and make files\n checking for empty or unneeded directories\n looking to see if a 'data/datalist' file should be added\n re-saving tabular files\n building 'dataRetrieval_1.0.6.tar.gz'\n\nWarning: invalid package 'C:\\Users\\ldecicco\\AppData\\Local\\Temp\\1\\RtmpiWLGFr/dataRetrieval_1.0.6.tar.gz'\nError: ERROR: no packages specified\nError: Command failed (1)\nIn addition: Warning message:\nrunning command '\"C:/PROGRA~1/R/R-215~1.1/bin/i386/R\" CMD INSTALL \"C:\\Users\\ldecicco\\AppData\\Local\\Temp\\1\\RtmpiWLGFr/dataRetrieval_1.0.6.tar.gz\" --library=\"C:/Users/ldecicco/Documents/R/win-library/2.15\" --with-keep.source ' had status 1 \n\n```\n\nLaura\n. I just built the packages on a Mac (in R 2.15.1), confirming my suspicions that it's a Windows specific problem.\n. Just in case anyone else is troubleshooting a similar problem, I added an Environmental Variable \"HOME\" and set it equal to \"%USERPROFILE%\" as recommended here:\nhttp://cran.freestatistics.org/bin/windows/Rtools/\nwhere it says:\n\"Changes since R 2.15.1\nThe bitmap libraries have been updated to jpeg-8d, libpng 1.5.12, and libtiff 4.0.2. The Cygwin tools have been updated to versions current as of July 13, 2012. NB: some of the tools now require you to have a HOME environment variable, listing your home directory. One way you can create it in a Windows command shell is by using\nset HOME=%USERPROFILE%\n\"\nBut, I still am not able to build any packages on Windows.\nI also tried adding a new environmental variable R_WIN_NO_JUNCTIONS, and I set it first to \"~/.R/check.Renviron\", then to \"C:/Windows/TEMP\" because I don't really know what it's looking for.  Neither helped.\nSo....I changed my PATH variable from R 2.15.1 back to R-2.15.0patched:\nC:\\Program Files\\R\\R-2.15.0patched\\bin\\x64\nopened up RStudio with that patched version of R, and ran through my normal devtools procedure:\nlibrary(devtools)\nload_all(\"mypackage\",T)\ndocument()\ncheck()\nbuild()\nAnd now it works just fine.  Just to be sure I didn't screw anything up, I changed the PATH variable back to:\nC:\\Program Files\\R\\R-2.15.1\\bin\\x64\nopened up RStudio using R 2.15.1, tried again - didn't work.  \nI also tried building the package using the command line with:\nRcmd INSTALL ...\nwith no luck in 2.15.1, but no problems in 2.15.0patched.\nI also had no problems building a package on a Mac.  \nSo my conclusion, I think there's a problem building packages in R 2.15.1 on Windows computers.  For now, I'm sticking with R 2.15.0patched, or switching to a Mac if I absolutely need to use 2.15.1.  Thanks for listening!\nLaura\n. Ah HA!\nSorry to keep bothering you, but I narrowed down the \"2.15.1 bug\" by reading this:\nhttps://stat.ethz.ch/pipermail/r-devel/2012-February/063365.html\nIt's not that there's a problem with 2.15.1, it's a problem because I altered my R 2.15.1's Rprofile.site to include:\nsetwd(\"D:/LAD/RCode\")\nand for whatever reason, that messes up the Rcmd build.  \nI never added a custom working directory to earlier versions of R, that is why they did not fail. If I comment out the setwd line in the Rprofile.site file, everything works in R 2.15.1.\nSorry for wasting so much of your time on this.\n. ",
    "yoni": "Oops. Accidentally send this before squashing my commits.\n. Hadley and Erik,\nThank you both for all of the constructive feedback. I've fixed all of the stuff, following your advice almost everywhere. Can we pull this stuff in?\nCheers,\nYoni\n. Thanks Hadley. :)\n. Thanks for the response, @hadley. :)\nReturning r_cmd_check_path implies that the caller needs to add error handling to their code. I like the top-down check_dir option better.\n. Thanks for adding this, @hadley! It was on my TODO list, but I never quite got the time.\n. Yeah I tend to agree. \n. Writing the message or checking the package?\n. Actually, package.skeleton really makes the code noisy. I'll be removing it.\n. Done.\n. Removing the message, but I like leaving the check in. I don't want any surprises in case something went wrong.\n. ",
    "emhart": "I'm using R 2.15.1, and all packages are up to date (I did run update), and I am running it in RStudio 0.96.316. Here's a traceback call for the error.  It's not really a big deal for me because I'm just installing packages from the terminal now anyway, but maybe the bug is more widespread than just me.  \n\ntraceback()\n11: as.list(param_pieces[, 2])\n10: setNames(as.list(param_pieces[, 2]), param_pieces[, 1]) at media-parse.r#41\n9: parse_media(type) at content-parse.r#66\n8: parseability(type) at utils.r#2\n7: as %||% parseability(type) at content.r#51\n6: content(request)\n5: writeBin(content(request), bundle)\n4: function (url, name = NULL, subdir = NULL, config = list(), ...) \n   {\n       if (is.null(name)) {\n           name <- basename(url)\n       }\n       message(\"Installing \", name, \" from \", url)\n       bundle <- file.path(tempdir(), name)\n       request <- GET(url, config)\n       stop_for_status(request)\n       writeBin(content(request), bundle)\n       on.exit(unlink(bundle), add = TRUE)\n       unbundle <- decompress(bundle)\n       on.exit(unlink(unbundle), add = TRUE)\n       pkg_path <- if (is.null(subdir)) \n           unbundle\n       else file.path(unbundle, subdir)\n       if (!file.exists(file.path(pkg_path, \"DESCRIPTION\"))) {\n           stop(\"Does not appear to be an R package\", call. = FALSE)\n       }\n       config_path <- file.path(pkg_path, \"configure\")\n       if (file.exists(config_path)) {\n           Sys.chmod(config_path, \"777\")\n       }\n       install(pkg_path, ...)\n   }(dots[[1L]][[1L]], dots[[2L]][[1L]], subdir = NULL, config = list())\n3: mapply(install_url_single, url, name, MoreArgs = list(subdir = subdir, \n       config = config, ...))\n2: install_url(url, paste(repo, \".zip\", sep = \"\"), subdir = subdir, \n       config = auth, ...)\n1: install_github(\"rGtrends\", \"emhart\")\n. I was using a version I installed from github, 0.1.1 I believe.  I just updated though and I have the same error.  See below.  Don't expend any energy on this on my behalf, I'm happy installing from the command line, but I'm not sure if it's a bug that affects more than myself.  \nlibrary(httr)\nsessionInfo()\nR version 2.15.1 (2012-06-22)\nPlatform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)\n\nlocale:\n[1] C/en_US.UTF-8/C/C/C/C\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] httr_0.2\nloaded via a namespace (and not attached):\n [1] MASS_7.3-21        RColorBrewer_1.0-5 RCurl_1.95-0.1     colorspace_1.1-1   dichromat_1.2-4    digest_0.5.2       ggplot2_0.9.0\n [8] grid_2.15.1        lavaan_0.4-12      memoise_0.1        munsell_0.3        plyr_1.7.1         proto_0.3-9.2      reshape2_1.2.1\n[15] scales_0.2.0       stats4_2.15.1      stringr_0.6        tools_2.15.1      \n\nlibrary(devtools)\ninstall_github(\"rGtrends\",\"emhart\")\nInstalling github repo(s) rGtrends/master from emhart\nInstalling rGtrends.zip from https://api.github.com/repos/emhart/rGtrends/zipball/master\nError in as.list(param_pieces[, 2]) : subscript out of bounds\nhelp(install_github)\ninstall_github(\"rfigshare\",\"ropensci\")\nInstalling github repo(s) rfigshare/master from ropensci\nInstalling rfigshare.zip from https://api.github.com/repos/ropensci/rfigshare/zipball/master\nError in as.list(param_pieces[, 2]) : subscript out of bounds\n. I'm running Lion though, so that's sort of weird on the part of R.  Here's the version info from a terminal. emh@Edmunds-MacBook-Pro:~/Downloads$ uname -a\nDarwin Edmunds-MacBook-Pro.local 11.4.2 Darwin Kernel Version 11.4.2: Thu Aug 23 16:25:48 PDT 2012; root:xnu-1699.32.7~1/RELEASE_X86_64 x86_64\n. I updated stringr from 0.6 to 0.6.1 and that solved the problem.  Thanks for the suggestion.\n. \n",
    "jrnold": "Damn, you're right. I can't replicate my own error.  I know I get this error with my package, https://github.com/jrnold/mcmcS4, but now I suspect it must be something in my code (although the package itself installs and runs fine). \n. Any idea how I might track down what is going wrong, or find out what isn't being unloaded? \n. Awesome work! Thanks!\n. I just ran into this issue. In my case it was due to the repo using a SSH key and it asking for a passphrase. This is bit me a few times since MacOS Sierra since it not longer automatically loads SSH keys into the keychain. See this thread.. ",
    "professorbeautiful": "A similar problem, it seems,\nwithin my package CTDesignExplorer, with these lines\nR\nsetClassUnion(\"NumericLogical\",c(\"numeric\",\"logical\"))\nsetClassUnion(\"OptionalNumeric\",c(\"numeric\",\"NULL\"))\nsetClassUnion(\"OptionalCharacter\",c(\"character\",\"NULL\"))\nThey run fine in a console window (RStudio).\nR CMD INSTALL (and Build&Reload in RStudio) gives these errors:\nError in .walkClassGraph(ClassDef, \"contains\", where, attr(ext, \"conflicts\")) : \n  the 'superClass' list for class \u201cnumeric\u201d, includes an undefined class \u201cOptionalNumeric\u201d\nError in setClassUnion(\"NumericLogical\", c(\"numeric\", \"logical\")) : \n  unable to create union class:  could not set members \"numeric\"\nError : unable to load R code in package \u2018CTDesignExplorer\u2019\nYour discussion above is rather over my head.\nIt seems to have ended with a resolution of the problem, yet here I am, adrift.\nYour guidance would be greatly appreciated.\n```\n\nversion\n               _                         \nplatform       x86_64-apple-darwin10.8.0 \narch           x86_64                    \nos             darwin10.8.0              \nsystem         x86_64, darwin10.8.0      \nstatus                                   \nmajor          3                         \nminor          0.1                       \nyear           2013                      \nmonth          05                        \nday            16                        \nsvn rev        62743                     \nlanguage       R                         \nversion.string R version 3.0.1 (2013-05-16)\nnickname       Good Sport\n```\n. OK, thanks, I'll keep hunting.\n\nOn Aug 7, 2013, at 10:40 AM, hadley wickham notifications@github.com wrote:\n\n@professorbeautiful I think that's a different problem - this is issue related to load_all not R CMD install\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "jayweiler": "I think I'm encountering this issue with logicals. \nIn a separate unions-and-generics.R I have: \nsetClassUnion(\"DataFrameOrLogical\", c(\"data.frame\",\"logical\"))\nsetClassUnion(\"DateOrLogical\", c(\"Date\", \"logical\"))\nBuild & reload works fine, but devtools::load_all(\".\") gives me:\n```\nError in .walkClassGraph(ClassDef, \"contains\", where, attr(ext, \"conflicts\")) : \n  the 'superClass' list for class \u201clogical\u201d, includes an undefined class \u201cDateOrLogical\u201d\n Show Traceback\nRerun with Debug\n Error in setClassUnion(\"DataFrameOrLogical\", c(\"data.frame\", \"logical\")) (from unions-and-generics.R#1) : \n  unable to create union class:  could not set members \"logical\" \n```\nIs it possible this issue still persists for logical values, or do you have any other ideas ? Thanks.\n. Thanks @hadley, I created a new issue at #657\n. Thanks @wch.\nI've created a minimal repo at https://github.com/jayweiler/testError .\nBelow is my session_info() dump. Please let me know if anything else would be helpful.\n```\n\ndevtools::session_info()\nSession info------------------------------------------------------------------------------------------------------------------------------------\n setting  value                     \n version  R version 3.1.2 (2014-10-31)\n system   x86_64, darwin13.4.0      \n ui       RStudio (0.98.1091)       \n language (EN)                      \n collate  en_US.UTF-8               \n tz       America/Los_Angeles         \n\nPackages----------------------------------------------------------------------------------------------------------------------------------------\n package    * version date       source      \n devtools     1.6.1   2014-10-07 CRAN (R 3.1.1)\n rstudioapi   0.1     2014-03-27 CRAN (R 3.1.0)\n```\n. Thanks so much @wch, I'll post there and see what happens. Really appreciate you looking into it.\n. ",
    "davidcoallier": "Great stuff thanks for all the comments :) I'll rework the patch, rebase it and let you know inline.\nIf, after reflexion, you realise that you don't want to use it, that's fine as well. I was thinking about adding the ability to specify your git binary in the install_git(...) parameters. What do you think?\n. @hadley I've rebased and added the changes from the peer-review. The OS detection is a lot better and I've added a parameter for people that'd want to use their own git binary.\nLet me know if this seems to make a bit more sense :)\n. I've left out the .onLoad options(...) setting because it really made it look awkward. \n. Did you have a chance to review and think about that @hadley? I've been using install_git on a few machines now and it works pretty well :P\n. Cool thanks :)\n. @wch Yeah I agree. --depth=1 or do you have something else in mind?\n. Ok I've rebased off your master and made the changes. This version of the PR should be a lot better now.\nAs for the comment (https://github.com/hadley/devtools/pull/169#discussion_r2409816), I've decided to leave the variable declarations at the top of the function as it makes it easier for me to track. If you feel like removing it, feel free to commit it to my branch and I'll push it here :)\n. Yeah I think git_path makes sense. I'll do the changes and rebase.\n. Saw that after, it'll be part of my next rebase alongside the other changes :-)\n. Must have been from some residual changes I had done. I'll remove and rebase.\n. This case is for users that did specify the path. We only validate what they said before proceeding further. The users don't need to always specify the full path, that's what the else right after takes care of.\n. 755 does make more sense. I'll change that.\nWith regards to Sys.chmod on Windows, I'd suspect that if it doesn't work, it'll degrade nicely. It is in the base package after all. Anyone with a Window machine could test that?\n. Sure, it was for the eventuality of unit-tests for the install-git functions.\n. Hah :) It is my first public R code-contribution and I'm sure you can tell from the first version of this pull-request ;)\nFrom having worked with many other projects, the \"Sys\"-like libraries are usually the only ones I've noticed with a knack to degrade nicely, now I assume no other R library is going to be that gentle :P\n. ",
    "spacedman": "seems to be because parse(file=\"./empty\") where ./empty is an empty file causes R to read from stdin. Because in parse, it reads the file with readLines, gets character(0), this then gets passed to .Internal for parse, which then I guess thinks the user meant to parse 'file', which is now stdin(). So that might be a bug in parse... But should create() create an empty NAMESPACE file anyway? Is that a roxygen problem? Have tried with roxygen2 2.2.2, still does it.\n. ",
    "barryrowlingson": "bug in parse fixed in R-patched.\n. Having just been prodded with this by CRAN, I've had a look at current titles and very few of them conform.\nThe only code for title casing I can find is in stringi, and that doesn't do it \"properly\" according to the rules of title case here: http://www.grammar-monster.com/lessons/capital_letters_title_case.htm since it caps all words:\n```\n\nstri_trans_totitle(\"last of the mohicans\")\n [1] \"Last Of The Mohicans\"\n```\n\nbut only the \"principal words\" should be capped. Is there a heuristic for detecting \"principal words\"?\nOr should release() add \"Is This Package Title in Title Case or is it Not?\" to its naggy questions? :)\n. I found some python code that does a pretty neat job of title-casing all the current package titles scraped from CRAN. But yes, there's always exceptions. You'd think CRAN were intentionally putting in NP-hard complexity things on purpose. \nin case you want to add it to stringr:\nhttps://muffinresearch.co.uk/titlecasepy-titlecase-in-python/\n. Yes. Until CRAN provide an algorithmic definition of \"Title Case\" there's no point writing code to chase CRAN's ever metamorphosing tail.\n. ",
    "bbolker": "one quick thought: is specifying quick=TRUE a temporary workaround for this issue?\n. sorry to be a bonehead, but I'm just getting started with devtools so may be a little obtuse.  I am having this precise problem.  I can follow the link to the inst_path function, but I'm not sure how I can use to it to work around the problem ... hints?  Seems related to https://github.com/hadley/devtools/pull/74\n. You're right that it's easy to install Rtools, but it's just one more step, and sometimes that can be a last straw ...  I'm considering the use of devtools not really by people who want to do development, but just as a convenient shortcut to be able to install packages straight from Github. I can appreciate  that this might not be a high priority -- if you (Hadley) say that you don't see any reason that it's a bad idea, I might (as I suggested above) try to figure out what would need to be changed to allow it to work.  (thanks for responding so quickly ...)\n. Too busy right now, but I will keep it on my list. Thanks.\n. thanks!\n. OK, I fixed this via git remote set-url origin git@github.com:lme4/lme4.git . Might be worth adding the older format to the list of possible cases, if it isn't just something wonky that happens to work for me?\nFeel free to close this (I'll leave it open for now)\n. OK, although does it need to be/should it be conditional on R >= 3.3.0? (I thought there were other uses of hard-coded http://, but I think I was wrong)\n. Hmm, neither of those install_github commands works for me (\"404 not found\").  Does install_github really know about those kinds of references ... ?  (Maybe this has been incorporated into the master branch? I'm going to install_github(\"hadley/devtools\") and see how it goes ...)\n. Hmm. I followed @singmann 's advice but I still get\nrevdep_check(\"bbmle\",libpath=\"bbmle_revdep_check/\",check_dir=\"revdep_checks\")\nReverse dependency checks for bbmle ============================================\nComputing reverse dependencies\nInstalling bbmle 1.0.19 and dependencies to bbmle_revdep_check/\nSetting env vars ---------------------------------------------------------------\nNOT_CRAN    : false\nRGL_USE_NULL: true\nDISPLAY     : \nChecking 14 CRAN packages ======================================================\nResults saved in revdep_checks\nInstalling dependencies --------------------------------------------------------\nDetermining available packages\nDownloading source packages for checking\nChecking packages --------------------------------------------------------------\nError: Check failed: '/media/sf_Documents/Rpkgs/revdep_checks/broom.Rcheck' doesn't exist\n(same results with revdep_check=\"../revdep_checks\")\nany hints/diagnostic ideas?. are you interested in beta testers? (I would try it out but the repo says DO NOT USE IT). ",
    "mannyishere": "Interestingly, I don't experience any errors or warnings when running check() which I believe checks the examples as one of the last steps.\n. I think this is a roxygen2 issue. When I add export(generic_function_name) to NAMESPACE, the examples run fine.\n. I don't think this is a roxygen thing after all. It shouldn't need to export(generic_function_name). It should just need the exportMethods directive. See Writing R extensions\n. I can confirm that commenting out the library settings in those three files does not solve Issue 174.\n. I think this makes devtools special functionality close to unusable for me. Is there a way around this bug?\n. ",
    "RyanHope": "I am also hitting this issue on a package that I am working on. I get no errors when I run check() but when I use run_examples() my generic functions can't be found.\n. I setwd() to the root of my project then call run_examples() with no arguments\n. The only warnings I am getting from document() are the \"incomplete final line found on\" warnings which I can't seem to get rid of. When I run load_all(export_all = FALSE) I get a bunch of these warnings \"Warning: character(0)\", not sure what that is about.\n. ",
    "ramnathv": "Thanks. I will check that.\n. That is strange. I just renamed the directory and it works. But, I am still puzzled since scaffold did not cause any problem when installing from the local repository. Do install and install_github work differently, which might be causing some of the issue?\n. Feel free to close this issue, since renaming worked for me. However, my question is still of academic interest!\n. Can it not be autodetected using sessionInfo()? Or maybe this could be a Window's only option, since the building from source issue crops up mostly for Windows users. Another option is to make the user explicitly pass the OS as an option to the function.\n. I don't have a windows machine. I checked on the Mac and the installation works perfectly. The slidifyLibraries package is mainly js and css assets and contains only one R function. However, it is bulky and is around 10 MB. Moreover some of the directories are deeply nested and I am wondering if that could lead to an error.\nAny recommendations on how to go about exploring this error if I don't have a windows machine?\n. I was just about to post this as an issue. You beat me to it :+1:.\n. ",
    "rappster": "Thanks for addressing this!\nWell, my use case in the broader sense is pretty simple: I'd just like \nto have as much/the same flexiblity that 'install.packages()' offers me \nwith respect to the package library that should be used (argument 'lib' \nor 'lib.loc' in functions like 'require()', 'library()', 'system.file()' \netc.)\nThe more specific use case:\nI came up with a own workflow for my R projects that makes use of a \ncertain project structure in style of that offered by ProjectTemplate \n(http://cran.r-project.org/web/packages/ProjectTemplate/index.html, \nhttp://projecttemplate.net/getting_started.html). I added a lot of \nfunctionality though, the most prominent one have a \"one-click process\" \nfor turning your project into a full grown R package that follows CRAN \nconventions.\nPart of that project structure is a \"local package library\" paradigm: \neach project gets its own local R package library in order to keep the \nstandard library as clean as possible and allow for experimental \ninstallation/deinstallation of packages in a \"sandbox mode\" (i.e. \nchanges are only bound to the project's library, not the standard \nlibrary). In order to do that and use 'devtools', I'd need a 'lib' \nargument, though.\nHope this clarifies the reason for my feature request.\nBest regards,\nJanko\nAm 12.12.2012 13:38, schrieb hadley wickham:\n\nCould you describe your use case? I'd rather solve it in general a \nwrapper function, rather than having to add |lib| to every install \nfunction.\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/hadley/devtools/issues/183#issuecomment-11287309.\n. When I run install_github() from R.exe, Rterm.exe, RStudio and via Eclipse/StatET, it crashes. When running it via Rgui.exe, I get the above error, but the console stays \"alive\".\n. I tried to narrow things down a bit:\n1. Tested on a different machine with identical settings, same result.\n2. On that other machine, tested with an old installation of R-3.1.0 and thus (possibly) old versions of devtools' package dependencies (I'll have to check that in more detail; the version of devtools itself already was at 1.5 anyway) and everything worked just fine.\n3. On that other machine, tested with a new installation of R-3.1.0 and thus latest dependency versions and it failed again.\n\nIn all three cases, I used the Rtools 3.1.\nSo I'm guessing, that it has to do with some package that devtools depends on?\n. Okay, I think I got it narrowed down to being a problem with RCurl version 1.95-4.1 (working) vs. 1.95-4.2 (not working).\nStarting from my old installation of R-3.1.0, the only package that devtools depends on and that changed until today is RCurl. After upgrading to version 1.95-4.2, install_github() fails (see details below).\nHTH,\nJanko\n\n```\nFunctions //\ngetCurrentLibraryState <- function() {\n  pkgs <- list.files(R.home(\"library\"))\n  vsns <- sapply(pkgs, packageDescription, field=\"Version\")\n  vsns[order(names(vsns))]\n}\ngetRepositoryState <- function() {\n  vsns <- available.packages()[,\"Version\"]\n  vsns <- vsns[which(names(vsns) %in% list.files(R.home(\"library\")))]\n  vsns[order(names(vsns))]\n}\ngetVersionDifferences <- function(vsns) {\n  sapply(1:nrow(vsns), function(ii) {\n    vsns[ii,1] != vsns[ii,2]\n  })\n}\nVersion overview //\nrepos <- getRepositoryState()\nlocal <- getCurrentLibraryState()[names(repos)]\nvsns <- data.frame(\n  local=local,\n  repos=repos,\n  stringsAsFactors=FALSE\n)\nvsns$changed <- getVersionDifferences(vsns=vsns)\n```\nThe only dependency for which a new version is available for R-3.1.0 is package RCurl:\n```\nDevtools dependencies //\ndeps <- packageDescription(\"devtools\", field=\"Imports\")\ndeps <- unlist(strsplit(gsub(\"\\s|\\(.*\\)|\\n\", \"\", deps), split=\",\"))\nvsns_2 <- vsns[which(rownames(vsns) %in% deps), ]\n\nvsns_2\n            local    repos changed\ndigest      0.6.4    0.6.4   FALSE\nevaluate    0.5.5    0.5.5   FALSE\nhttr          0.3      0.3   FALSE\nmemoise     0.2.1    0.2.1   FALSE\nRCurl    1.95-4.1 1.95-4.2    TRUE\nwhisker     0.3-2    0.3-2   FALSE\n```\n\nBefore updating RCurl, everything still works fine:\n```\n\nrequire(\"devtools\")\ninstall_github(\"rstudio/packrat\")\nInstalling github repo packrat/master from rstudio\nDownloading master.zip from https://github.com/rstudio/packrat/archive/master.zip\nInstalling package from C:\\Users\\rappster\\AppData\\Local\\Temp\\RtmpQT0Exb/master.zip\nInstalling packrat\n\"C:/home/apps/r/R-31~1.0/bin/x64/R\" --vanilla CMD INSTALL  \\\n  \"C:\\Users\\rappster\\AppData\\Local\\Temp\\RtmpQT0Exb\\devtools10c0124774a9\\packrat-master\"  \\\n  --library=\"C:/home/apps/r/R-3.1.0/library\" --install-tests \n\n\ninstalling source package 'packrat' ...\n R\n inst\n tests\n preparing package for lazy loading\n** help\n installing help indices\n* building package indices\n testing if installed package can be loaded\n arch - i386\n arch - x64\nDONE (packrat)\n```\n\nAfter the update, the whole thing fails:\n```\n\ninstall.packages(\"RCurl\")\n--- Please select a CRAN mirror for use in this session ---\n\nThere is a binary version available (and will be installed) but the source version is later:\n        binary   source\nRCurl 1.95-4.2 1.95-4.3\ntrying URL 'http://cran.rstudio.com/bin/windows/contrib/3.1/RCurl_1.95-4.2.zip'\nContent type 'application/zip' length 2835598 bytes (2.7 Mb)\nopened URL\ndownloaded 2.7 Mb\npackage \u2018RCurl\u2019 successfully unpacked and MD5 sums checked\nThe downloaded binary packages are in\n        C:\\Users\\rappster\\AppData\\Local\\Temp\\RtmpYJd16m\\downloaded_packages\n\npackageDescription(\"RCurl\", field=\"Version\")\n[1] \"1.95-4.2\"\nrequire(\"devtools\")\nLoading required package: devtools\n\nAttaching package: \u2018devtools\u2019\nThe following objects are masked from \u2018package:utils\u2019:\n?, help\n\nThe following object is masked from \u2018package:base\u2019:\nsystem.file\n\n\ninstall_github(\"rstudio/packrat\")\nInstalling github repo packrat/master from rstudio\nDownloading master.zip from https://github.com/rstudio/packrat/archive/master.zip\nInstalling package from C:\\Users\\rappster\\AppData\\Local\\Temp\\RtmpYJd16m/master.zip\nError in unzip(src, list = TRUE) : \n  zip file 'C:\\Users\\rappster\\AppData\\Local\\Temp\\RtmpYJd16m/master.zip' cannot be opened\nIn addition: Warning messages:\n1: In mapCurlOptNames(names(.els), asNames = TRUE) :\n  Unrecognized CURL options: writedata\n2: In mapCurlOptNames(names(.els), asNames = TRUE) :\n  Unrecognized CURL options: writedata\n3: In unzip(src, exdir = target, unzip = getOption(\"unzip\")) :\n  error 1 in extracting from zip file\n``\n. I would like to, but compiling RCurl from source on Windows seems to be a bit tricky with respect tolibcurland its companion DLLs. I gues I'm stuck until the Windows binary forv.1.95-4.3comes out.\n. Ok, thanks. I see your point. I'm totally in favour of being explicit about things when it adds to code robustness and reliability! But do you happen to know if anything has improved with respect to the overhead of using::? Last time I checked (which is quite a while ago), having lots of explicit calls via::` could substantially slow things down as Dominik Samperi once pointed out (see section Downsides of using the :: operator in this post).\n\nThanks\n. Cool, thanks very much for the details and suggestions! It it wasn't for its overhead, I'd use :: all the time, but most of the time this overhead probably won't really matter that much and then there's also the workaround you suggested. \nWith respect to using the namespace of my own package: devtools::load_all() takes care of that just fine! Currently, I'm not really explicitly referencing a package's own functions via mypackage::foo() yet as it feels a bit like \"overdoing it with the explicitness\", but it's great to know that courtesy of devtools now I can do it if I wanted to :-). \nThanks and keep up the great work!\n. Sorry, didn't see that. Thanks!\n. ",
    "dlebauer": "@wch I also can not reproduce this with other packages; perhaps it should be closed and / or migrated to a ggplot2 bug?\n. @hadley Is this bug related to http://stackoverflow.com/q/24501245/513006 and http://stackoverflow.com/q/23252231/513006? If so, should it be reopened?\nHere is a reproducible example from the first link\n``` r\nlibrary(devtools)\nsetwd(tempdir())\nmake dummy package called foo\ncreate(\"foo\")\nsetwd(\"foo\")\nadd data.table as a package dependency\na <- readLines(\"DESCRIPTION\")\ndepends.idx <- grepl(\"Depends\", a)\na[depends.idx] <- paste0(a[depends.idx], \", data.table\")\nwriteLines(a, \"DESCRIPTION\")\ncreate a dummy function\nwriteLines(\"myfunction <- function() {a <- data.table(b=1); return(a[,b])}\",\n            \"R/foo.R\")\ncheck and throw error\ncheck() # fails but documents and compiles\nlibrary(foo)\nmyfunction()\n``\n. The example I gave works now on my machine too (assuming by dev version you mean this github master retrieved frominstall_github(\"devtools\", \"hadley\")`)\n. ",
    "jamiefolson": "Maybe a convention for defining a Dependences file with definitions for how to install packages? Could be in R? YAML?\nWhat are you thinking at this point?  There shouldn't really be any technical challenge, right?  Just figuring out a way that's simple without being too limited.\n. I though perhaps just assigning functions in a script where the function installs the package indicated by the name.  This could be loaded into an environment and then used to install any packages from the package dependencies.\ndevtools <- install_github(\"devtools\")\nroxygen3 <- install_github(\"roxygen3\")\nThe main problem I see is that I'm not sure how you'd check versions so you're not just always installing everything.\n. ",
    "mattdowle": "Wild guess is that devtools needs to create .Depends in the namespace environment, to mimick more closely what R itself does. When I looked at devtools NEWS for 0.8, it appeared that devtools simulates a namespace, or creates one itself somehow. So it isn't a namespace exactly as would be created by R CMD INSTALL followed by library() ?\n. Great, thanks. I'll close the data.table bug report then, now it's confirmed as likely a devtools issue.\n. ",
    "gsee": "Thanks to a suggestion from Matthew Dowle, a workaround for me is to add .datatable.aware=TRUE in my package, which makes this problem disappear. \n. ",
    "utalo": "I seem to be encountering the same issue as discussed above. I posted a related question on stackoverflow: http://stackoverflow.com/questions/36547235/r-data-table-and-testthat-package\nReproducible code example can be found here: https://github.com/utalo/test_datatable_testthat\nI am using R-3.2.3, data.table 1.9.6 and devtools 1.10.0.\n. ",
    "Bohdan-Khomtchouk": "Also getting identical error:\nError in `[.data.frame`(x, i, j) : object 'my_object' not found\nCalled from: `[.data.frame`(x, i, j)\nTried all the tips included here, read all relevant Stack Overflow posts, and updated my devtools and data.table libraries to the most recent versions.  No luck.\n. ",
    "cmclean3": "Hi all\nTrying to install a package from Github on a strongly locked down work pc. \nI had Rtools installed (by using an administrator's password) but when the package tries to open Rtools to build during the install process, the pc security blocks it from being open as its an unauthorized application.\nIs there any way to install a package from github without requiring Rtools to be installed?\nAlternatively is it possible to create a package archive file (.zip or .tar.gz) from a github package on another open computer? Then i would copy to the locked computer and install manually.\nthanks. that's great, will attempt tonight at home - thanks Jim. @jimhester so i was able to clone the repo and change directory, however after i enter R CMD build i get the error:\nbash: R: command not found\nSearching the web for a solution but no luck yet. Is this something you have come across before?\n. ",
    "jimhester": "@cmclean3 If the package has a src/ directory it contains compiled code and needs Rtools in order to compile the code.\nYou can build a binary package from a separate computer with\nR\ngit clone repo.git\ncd repo\nR CMD build .\nR CMD INSTALL --build pkg*tar.gz\nThis will produce a foo.zip package with the compiled code that can be installed on the other computer with Rscript -e \"install.packages('foo.zip', repos = NULL)\".\nSee http://www.hep.by/gnu/r-patched/r-exts/R-exts_20.html for more information.. Doesn't look like R is installed, or if it is installed it is not on your path.\nNote if you want to use an R package on a windows machine the binary package needs to be built on windows as well.. @danielecook Are you using the latest version of devtools? Can you provide your devtools::session_info(). Also in order to figure out the cause you need to provide the full error message including traceback.\n. I must have!  That did fix the issue, thanks @hadley.  using devtools release() almost made this CRAN interaction pain free.\n. Sorry, had a few issues with the original pull request,  dfdae79 should be good to go though, you will also need to enable the repo at https://coveralls.io/repos/new.\n. I am but I am using some devtools functions which are unexported in the current release.  (https://github.com/jimhester/covr/issues/63).  So ideally I would like to submit covr to CRAN after the next devtools release.  Circular dependencies, so we would have to coordinate the releases somehow.\nAlternatively I am currently working on extracting the with_* functions, R, RCMD functions from devtools into a new robustr package, along with a couple of utility functions I needed to write for covr.  robustr would provide safe alternatives for modifying global state and calling R from within R.  Once that is done I can convert covr and devtools to use that package for those functions and that would solve this issue.\nIf you have other suggestions on functions that you think would be useful to include in robustr I would be happy to include them.\n. Ok I think everything should be ok with this now, I added a note to the NEWS as well.\n. This pull is generating a warning in cran check because covr is not on CRAN yet, so it is unable to verify the documentation linking.\nAlso I apparently cannot spell implementation past 10 EST.\n. Yep I tweaked the travis to install covr from github and fixed the conflict, this should be good to merge.\n. Ok this should be good to do now.\n. That is a good point, I will update this\n. Ok lintr version bumped and requirement added to devtools.\n. Ok this should be ok to merge now, let me know if the documentation is unclear.\n. This should be fixed in devtools develpment version on github\nR/rtools.r#L252-L255\nBut is not fixed in the last released devtools on CRAN, so if you are getting this error for now the solution should be to use the development version.\n. Ah right, you are correct now that they have rolled back to using gcc 4.6.3 this needs to be updated with\nr\n  \"3.3\" = list(\n    version_min = \"3.2.0\",\n    version_max = \"3.2.99\",\n    path = c(\"bin\", \"gcc-4.6.3/bin\")\n  )\nWhich I think should fix things using Rtools33.\n. The warning that is failing the build now is baffling me, https://travis-ci.org/hadley/devtools/builds/55557865#L1559-L1562\nIt mentions tools:::httpdPort, but that function does not seem to appear anywhere in devtools, and definitely wasn't part of my changes.  I will try to figure out what is going on.\n. Ok so I have finally figured out what is going on with the tools:::httpdPort warning.  This occurs in R-3.1.3 because there is a call to tools:::httpdPort in the definition to utils::? and utils::help.  We copy these existing definitions to shims$help$orig_value and shims$?$orig_value and these definitions are causing the warning.\nHowever the definitions for utils::help and utils::? in R-devel no longer call tools:::httpdPort so this warning does not happen in R-devel, and would not happen in CRANs checks either.\nSo this code should actually be ok to merge, but it will continue to cause a WARNING on travis because we are not able to test against R-devel.\nIf you want I can modify travis.yml so that  warnings_are_errors: false so this builds without failing.\n. As I mentioned now that travis is using R 3.2 this now builds without warnings.\nI can fix the merge conflicts once you are done with this round of merging.\n. I did end up doing a regular install as you suggest, I was running into issues using load_all with S4 classes as well trying to use covr on Bioconductor packages.\n. invert = TRUE is not an option for grepl() (which I forgot), so to get that functionality you would also need https://github.com/hadley/testthat/pull/239 in addition to this pull request.\n. I have added a note to NEWS, however the build seems to have stalled.  It should be ok to merge, all I did was rebase on the latest master.\n. @jonkeane install_git() uses libgit2 rather than the git client to clone the git repository. git2r the R client to the libgit2 library does not look it has an interface for submodules on cursory inspection.\nProbably the easiest thing to do assuming you do have the command line git client installed is define a simple helper function to clone the repository locally and install from there.\n``` r\ninstall_submodule_git <- function(x, ...) {\n  install_dir <- tempfile()\n  system(paste(\"git clone --recursive\", shQuote(x), shQuote(install_dir)))\n  devtools::install(install_dir, ...)\n}\ninstall_submodule_git(\"https://github.com/jonkeane/mocapGrip\")\nlist.files(system.file(package = \"mocapGrip\", \"python\", \"pyelan\"))\n> [1] \"init.py\"      \"elanGen.py\"       \"elanSkeleton.eaf\" \"pyelan.py\"        \"README.md\"        \"relPathFix.py\"\n``\n. FYI https://github.com/hadley/devtools/pull/746 already setsbioc_required=true`, it just needs to be merged.\n. You may want to open an issue about it at https://github.com/wercker/support/issues, not sure which method would get an answer faster.\nI agree it seems excessive to ask for that loose of permission up front.\n. There is a lint expectation built into lintr, I would recommend @nsh87 use that, from the lintr README\nr\nif (requireNamespace(\"lintr\", quietly = TRUE)) {\n  context(\"lints\")\n  test_that(\"Package Style\", {\n    lintr::expect_lint_free()\n  })\n}\n. This is not a bug in devtools (but maybe in lintr).  devtools::check() runs the check in a temporary directory, but lint_package() assumes it is being run in a package directory, therefore there are no source files to be linted.  @nsh87 you can confirm this with devtools::check(check_dir = \".\"), which should produce linting failures if devtools::test() does.\nMaybe lintr:::expect_lint_free should use system.file() to find the source files (but this would then break test() unless we revisit #744 to properly shim system.file() globally.\n. @c97sr Are you sure you want to use install_git() and not install_github(\"c97sr/idd\")?\n. Rebased to 2cca68dbebeeb4123c14b75942f7b2537a67f318\n. It is failing the \"patch coverage\" test.  Patch coverage refers to\n\nThe lines changed in each commit must meet this minimum coverage. Recommended value of 90%+. \n\nhttps://github.com/codecov/support/wiki/Patch-Coverage-Status\nPresumably because you did not add any new tests for the changed lines from this pull request.  Looks like @hadley set it so that 90% of the changed lines need to have coverage to pass.\n. Ah I misunderstood the issue, I will try to figure out what is going on\nthen.\nOn Jul 3, 2015 9:01 AM, \"Kirill M\u00fcller\" notifications@github.com wrote:\n\nThanks @jimhester https://github.com/jimhester for the quick reply. My\npoint is:\n- I have added a test for the new code\n  https://github.com/hadley/devtools/pull/836/files#diff-5c28a8e2e00a665df9b1f5938388e7c0R44\n- The test calls with_lib\n  https://github.com/hadley/devtools/pull/836/files#diff-7793392c33c95f57fb11771ab7b11f2aR153\n  and with_libpaths\n  https://github.com/hadley/devtools/pull/836/files#diff-7793392c33c95f57fb11771ab7b11f2aR139\n- These call (albeit internally) set_lib et al., which are not covered\n  https://codecov.io/github/hadley/devtools/R/with.r?ref=20bcb8662ccfdf949d2aa71ed62220513b0a7974#l-144\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/pull/836#issuecomment-118342500.\n. @krlmlr So the reason set_lib() was not being covered was because you were forcing the set and reset functions in with_something().  This forces a copy of the functions to be created, and only this copy was being run, not the original function.  Removing those lines shows the proper coverage.\n. This is actually a different issue that I have just tracked down, I will send a pr fixing it in the next couple of minutes.\n. @hadley your fix at https://github.com/hadley/devtools/commit/884d6e2bdd8eb515bc012bca91bb51b12e44b332 will fix this as well, it was the same issue at heart in both.\n. Try\n\nr\ninstall_github(\"dtenenba/anRpackage\", build_vignettes=TRUE, \n  repos=BiocInstaller::biocinstallRepos(),\n  dependencies=TRUE, type=\"source\")\nThat sets a CRAN repo properly, so should work.  This is also what https://github.com/hadley/devtools/pull/895 is doing.\n. See https://github.com/jimhester/robustr for a start to this\n. I changed the name to withr, but maybe I should stick the 'e' on as well...\nI want to make a withering vine logo for it, but my photoshop / artistic talents are lackluster at best. :frowning: \n. head was deprecated in the recent version of git2r, the devel version of devtools has fixed this.. I can look at it, I think most of it can be removed with your changes though.\n. 2a161ae should be good to go I think.  This whole issue is much less of a problem now with the change to setting --as-cran.  The user can just do something like\nr\nwith_env(list(\"_R_CHECK_LIMIT_CORES_\" = \"warn\"),  check())\nWhereas previously the above would have been overwritten by devtools internally.\nStill it is at least slightly useful to provide an argument to the function, so I guess it can't hurt to merge this.\n. @PeteHaitch The dependencies work with this patch the same way they do with biocLite(), they pull from the BiocInstaller::biocinstallRepos(), so it will only be packages that have successfully passed through the Bioconductor build system, not from the git mirrors.\n. Done https://github.com/hadley/devtools/commit/406f3dd09410340b391f960f466a367868da77b7\n. FWIW I would preserve the existing behavior (filling in user/repo) for the common case (GitHub), and just use the placeholders if !isTRUE(uses_github()).\nHaving to replace the dummy values really reduces the utility of these setup functions IMHO.\n. That is true about the non-standard fields, although it is only included in the general NOTE, and Writing R Extensions does state\n\nThere is no restriction on the use of other fields not mentioned here (but using other capitalizations of these field names would cause confusion). Fields Note, Contact (for contacting the authors/developers) and MailingList are in common use. Some repositories (including CRAN and R-forge) add their own fields.\n\nSo it shouldn't be be hard to justify it if needed.  But the argument is largely moot as you said because once you submit to CRAN you wouldn't need this anyway.\nIt would be possible to get the name to pass the check by prefixing it with X-CRAN or with a standard field suffixed with Note, see r-source/library/tools/R/QC.R#L6605-L6610.  But even the best of those options ImportsNote, Additional_repositoriesNote, ect seem a little hacky to me.\nOther names we could consider are RemotePackages, RemoteDepends, just Remotes...\nI will work on some tests and ping you when they are done!\n. Ok e43e46e has tests, a note to NEWS and a vignette with example usage.  Let me know if I can make it clearer on first reading.\nI changed the field name to Remotes as I think it is both shorter and more accurate.  Plus theoretically this doesn't have to just be for development packages, you could distribute packages entirely without CRAN if you wanted.\nThe main remaining limitation with this approach is there is no way to supply any additional arguments to the install_* functions.  This won't be a large deal for the git based install functions, as installing from a branch/sha1/pull/tag is all supported in the syntax (@, #, ect).  However for install_svn not being able to supply a branch or subdirectory parameter is pretty limiting.  Even for the install_github() it would be nice to support specifying the host= argument for example.\nHowever I don't know what syntax I could use that would be easily parsable.  I had initially thought of a syntax like Remotes: user/repo(opt1 = 1, opt2 = 2), user2/repo2.  Matching parenthesis with regular expressions while possible with modern engines is tricky to get right.  It would also complicate the initial dependency splitting code (to disambiguate commas within parenthesis and without).\nSo I think it is ok to leave passing additional options out for now, as I am not sure how much use they would get and the current approach is much simpler.\n. Ok https://github.com/jimhester/devtools/commit/ce160212ee18f9045315ddd96bf05b44edc3335b should be good to go, I think I addressed all of your comments.  Thank you for the review!\n. - Agreed on release() checking for Remotes, that is a good suggestion!\n- The package authors can choose to make it explicit if they would like in the current implementation.  I personally prefer making this syntax as simple as possible for the common case, but if you and hadley prefer it to be explicit always it can be so.\n- I agree :: is nicer than |, and also is familiar to R users as a bonus.  I am happy to switch to :: as long as we can be sure it won't occur in URLs.  Looking at https://en.wikipedia.org/wiki/Uniform_resource_identifier it looks safe to me.\nprivate repos can currently be accessed in a couple of ways\n1. Using the git remote (rather than github and the direct private git url) e.g.\ngit|https://github.com/hadley/devtools.git.  This should also work for the other git based services.\n2. Using the github remote and setting the GITHUB_PAT environment variable to your github personal access token.  This could be done on travis using their encrypted environment variables for instance.\n3. For svn it caches your credentials by default so it assuming you have used svn on the private repo before on that machine it should work.\nThat information should probably be included in the vignette as well.\nThat should handle a large number of the cases however 100% support would require us to define a syntax that would allow passing in additional arguments to the backends.  Something like (using the suggested ::)\nRemotes: \n  github::hadley/ggplot[host = \"github.company.com\", repos = \"cran.company.com\"], \n  github::hadley/testthat\nThe only real tricky part in this is disambiguate the commas within the options from those outside, as the remotes are split on commas first.\n. Ok!  @hadley any opinion on using :: as Winston suggested?  I can change that, add a check to release() to remove the Remotes: and fix the conflicts, then it can be merged.\n. R CMD check already does some stuff with Additional_repositories (https://github.com/wch/r-source/blob/1b8396c/src/library/tools/R/QC.R#L6746-L6808), so I don't think you could use it without causing errors.  Plus that field name always grates on my nerves with it's random underscore and lowercase, inconsistency is the only consistency in R-base!\nI am not opposed to using Repositories apart from being a longer name, as it is slightly more accurate...\n. As of https://github.com/hadley/devtools/commit/2e9589bbc06c79ee66b85f4b214dd0c840e41f76 everything uses :: now, I added a check for Remotes: to release() and I rebased on eda31f7b674\n. So my main worry with this is having to query the GitHub API twice, when unauthenticated the rate limit is only 60 requests per hour, so if someone is doing testing using install_github() with 5 github packages in Remotes: they only have to run install_github() 5 times before they hit the rate limit. (6 * 2 * 5 = 60).\nI think I can get the same information without querying the GitHub API using e.g.\n``` bash\ngit ls-remote git@github.com:jimhester/lintr.git\naaf61208cf877fe3a077c5146126a0f3867205a2        HEAD\n50ab86db4ebc7272d95990f8d15b3fabe0278936        refs/heads/chunk_parsing\nfc80f59b2051ed3043c572bd808e53368123a529        refs/heads/comment\ncc0e600b043eac2d3753ca8058c160c5d690adfd        refs/heads/linter_names\naaf61208cf877fe3a077c5146126a0f3867205a2        refs/heads/master\nf88a4804df4c7cccb1585b1cf08a5601c41e490f        refs/heads/single_line\na73b1762d795a67fda02475b9a02a4a4151850e9        refs/pull/109/head\n5e4a4f295744bfb02b0f85a7da1a5f620c0e3b6f        refs/pull/110/head\n7b3ac8f985251063ca25a3be21d803abfb6ff2ad        refs/pull/19/head\nb1a9d4bc5d501859769c498aceaef30b9a2ed23b        refs/pull/28/head\n67b8681335482359bc0b6a6bd4ca01596e920be3        refs/pull/37/head\n517a4df59f9dab8bfb736a9f73e2efe3021720a2        refs/pull/46/head\n427e177926421819b917c4dd55cd3c42cb231525        refs/pull/49/head\n7b07088df347352b0da75eebc82ecc2e7cc1ab23        refs/pull/51/head\nfc80f59b2051ed3043c572bd808e53368123a529        refs/pull/52/head\n7b422f6bc02b6d014ee1260d0f7d8d59d185dba6        refs/pull/69/head\n97f5e794e8c0b379ca9945c23200dbbca0e101af        refs/pull/70/head\n7d27c930710696c91688c610a634efa3490699aa        refs/pull/70/merge\nb828e3333c2fc2e7172116d6f6de44436651c72e        refs/pull/71/head\nab973a26e330677f91b39da9f9ca423f6a36eb90        refs/pull/74/head\ncc1ee872613fc9a527f5680f6ca491b29ce3fa41        refs/pull/78/head\n71d6d2f58612f291838b74ad3992e8886cd1b928        refs/pull/80/head\n6d10a4250cda301926e8462be7e67001d8f10f7d        refs/pull/83/head\n6f17692c940ac2b81cd6648194a0ca2753abbb1a        refs/pull/90/head\n4722335176ba6601f7a0178f821c42dbd23ba53b        refs/pull/93/head\n207f0fd1f679ce04e85a703189e6dd7ffffca12c        refs/pull/93/merge\nb09b3ed1132983eccb61c4cf32987a28243f95ba        refs/pull/94/head\n975a404bab2ea2aa3d094f0ffd4db1abef29b049        refs/pull/95/head\n3335be532798f4bff0373873b37a81495b25a01e        refs/pull/95/merge\nbb932678932a1b3196b06194509019c459ea312d        refs/pull/97/head\n3d9e70b15559c460bc60e8961dd94cdaca8dc094        refs/pull/99/head\nf7e6ba13dca58bb612f6bba0a6875a5ba53ca84f        refs/tags/0.1\nf8fcbe89c7da9cb491bc3c0cd9377ee8f68d1d0a        refs/tags/0.1^{}\nd7eaa02fb7f31c049279797eb6bcaa183d1a7898        refs/tags/0.1.0\n7aa7d9943e57c992b3a702c69950125ddefe89f6        refs/tags/0.1.0^{}\n00e8748ff27d631ebfb01b038c20695b2cba8138        refs/tags/0.2.0\n2f3b60b9432f7a79cf907df24dd0dbf95a11df2d        refs/tags/0.2.0^{}\n3ef07e7f38e7c2da73652e2a04ba82f5d654b143        refs/tags/0.2.0.9000\nb095569b69e445fccdb6e9865f10270f38bff4c0        refs/tags/0.2.0.9000^{}\n88ad2aad380341286fce189be484e075bc60f21e        refs/tags/0.2.1.9000\n96962306a005e84fe217a19b018bfd64ec433a28        refs/tags/0.2.1.9000^{}\n7c46d350e1877d857b0586b74aa1274592147c4b        refs/tags/0.3.0.9000\n2b9d30fcf7e74420b564889d08ee1af3f9518a3a        refs/tags/0.3.0.9000^{}\na98a234dafbb76a1622ad2a22a8eebdbe5fbae7d        refs/tags/0.3.0.9001\n0fb087149e45aeeb5f1f23d4a11cff980deb4feb        refs/tags/0.3.0.9001^{}\n15ca21869654706f44c6d1659822b7d3760a3eec        refs/tags/0.3.0.9002\n780be8ea5cc9ba9321f8d09f084b6efac55ad17f        refs/tags/0.3.0.9002^{}\n3e6cb3d4f9d617533f4f6a107e2f05f028299286        refs/tags/0.3.1\n1df8c3daf61a026565380d59b8ae7a3fe64434b9        refs/tags/v0.2.0\n```\nAnd the DESCRIPTION with\nhttps://raw.githubusercontent.com/jimhester/covr/master/DESCRIPTION\nThis would let this work without any API requests.\nIt also gives us a avenue to use the same approach for the other git based install_* functions.  We can use git archive --remote=git://github.com/jimhester/lintr.git HEAD:. DESCRIPTION to get just the description from a git repository without cloning the entire repository (GitHub does not support this method however).\nWill try to incorporate your comments and work on this some more.\n. https://github.com/jimhester/devtools/commit/98016e49d4ad6d83cbf706364bb335720d5d1638 uses the alternative implementation I discussed above and adds support for git and bitbucket backends.\ngitorious seems to have been shutdown / acquired by GitLab (https://gitorious.org/, https://en.wikipedia.org/wiki/Gitorious) so I don't think it is worth or possible to get it working.  We may want to deprecate that backend...\nI could add support for SVN repositories as well if we stored the revision in the DESCRIPTION metadata, however it looks like we do not ATM.\nI think I addressed all of your comments that still applied however the code changed quite a bit so it could use another review.\nIt also needs some tests, although it seems to work via interactive testing.\n. Ok 72edbbf should now be using git2r::ls_remote().  It is also the first use of Remotes: in the wild, hopefully it works!\n. https://github.com/hadley/devtools/commit/2425180596017d545a7bac7cbeb2197424d95341 adds tests , note to NEWS and re-based, however it is broken because Travis uses CRAN devtools to install the dependencies, so the Remotes field isn't picked up.\ngit2r::remotes_ls() which I added to git2r with https://github.com/ropensci/git2r/pull/172 has been merged, but I don't know when @stewid is planning the next CRAN release of git2r, so this PR likely won't make it in the upcoming devtools release anyway.\n. This should now be ready to merge as well. https://github.com/jimhester/devtools/commit/a00cd186f8fc79a4991e47b7fa2028e23abf1e0d passes without any new NOTES being generated.\n. @hadley PTAL at this when you can, particularly https://github.com/jimhester/devtools/commit/65e4fe575132a5901eda3ea892660f8b7d8c8c78. If you think that looks good this should be ok to merge.\n. https://github.com/jimhester/devtools/commit/ce7869dcee67c8dac5c5dc70a940a13ce07a5952 adds the early return. Let me know if you see anything else that needs to change. If not I think this can be merged.\n. This now works, all of the calls to with_ functions within devtools are replaced by calls to the corresponding withr functions.\nHowever we need to decide how to handle calls to the old with_ function from other packages. There are three possibilities I see\n1. Do nothing (this will break packages that use the functions, but will force them to update to withr functions immediately).\n2. Continue to supply the functions and with a .Deprecated warning, remove them at a later date.\n3. Export the existing functions as aliases to the corresponding withr functions.\n1 isn't going to happen so 2 seems to be the best option, as part of the reason for splitting the functions out was so fewer packages would need to depend on devtools directly.\n. Oh well... already did the deprecation work!\nhttps://github.com/hadley/devtools/commit/bee53b738d7f1163a6da4ffd6734b216835bbe7b should be good (assuming it passes).\n. I edited the comment, no one will ever know!\n. https://github.com/jimhester/devtools/commit/d21c892ae490385e6c8891a6df77ec3603ddc481 should be ready to merge whenever. This will allow use of the Remotes: feature on travis, so it is fairly useful.\n. This should now be ready to merge.\n. https://github.com/metacran/description I assume\n. This error is actually entirely unrelated to devtools and can be reproduced from a fresh R --vanilla session.\n``` r\noptions(repos = c(CRAN = \"http://cran.rstudio.com\"))\ninstall.packages(\"ggplot2\")\n> Updating HTML index of packages in '.Library'\n> Making 'packages.html' ... done\nlibrary(\"ggplot2\")\ninstall.packages(\"ggplot2\")\n> Updating HTML index of packages in '.Library'\n> Making 'packages.html' ... done\nunloadNamespace(\"ggplot2\")\nlibrary(\"ggplot2\")\n> Warning in get(method, envir = home): internal error -3 in R_decompress1\n> Error: package or namespace load failed for 'ggplot2'\n```\nIt seems there is a bug in properly closing/freeing the lazy-load database when unloadNamespace() is called. So then when you install the new package over top of the old one the database files are changed on disk and you get the internal error. unloadNamespace() calls lazyLoadDBflush() which should remove the reference to the database file. This alone must not be sufficient for this use case however...\nYou can unloadNamespace() a package and then re-attach it with library() or require() as many times as you like as long as as long as you don't try overwrite the existing files.\nYou can also install the library to a different location then load it without error.\n``` r\noptions(repos = c(CRAN = \"http://cran.rstudio.com\"))\ninstall.packages(\"ggplot2\")\n> Updating HTML index of packages in '.Library'\n> Making 'packages.html' ... done\nlibrary(\"ggplot2\")\ninstall.packages(\"ggplot2\", lib = tempdir())\nunloadNamespace(\"ggplot2\")\nlibrary(\"ggplot2\", lib.loc = tempdir())\n```\nIt is only when you install a package over top the already loaded one, then unload and try to reload that it causes an error.\n. @hadley might be easier for me (and you) to keep track of if you just assign these issues to me. It doesn't look like I can assign them to myself. :frowning: \n. This is unfortunately currently broken until https://github.com/hadley/devtools/pull/936 is merged.\nIf you do\nyaml\nr_github_packages:\n  - hadley/devtools#936\nIt should work without without having to specify hadley/readr in .travis.yml.\n. Yeah exactly that is the idea, it just has the bug currently that prevents\nit from working on travis because devtools is not attached to the search\npath in the travis-r script (so it can't find the proper install_*\nfunction).\nOn Fri, Oct 2, 2015 at 4:41 PM, Jennifer (Jenny) Bryan \nnotifications@github.com wrote:\n\nOK so when that's merged the depedency on a dev/github version could be\nfully captured in DESCRIPTION? You won't have to change .travis.yml and\nyou won't have to put something in a README.md that says, e.g., devtools::install_github(\"hadley/readr\");\ndevtools::install_github(\"jennybc/jane\")?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/944#issuecomment-145150146.\n. Yes, so it is still a ways away before it can be used widely, I wish I had caught this bug before the last release :frowning: \n. You need to have the Remotes in one of the other fields as well, e.g. Imports: Suggests: Depends: LinkingTo:.\n\nAlso it isn't necessary to specify github::, that is the implicit default.. I am just going to add this to https://github.com/hadley/devtools/pull/962 rather than using a separate pull request for it.\n. Evaluate is from run_examples(), I had a check for it, but failed to save that file, included in https://github.com/hadley/devtools/commit/9fc052fa47bbd4fda2258ef3edf12dad0ae5cdc8.\nAlso removed the extra Rcpp check in https://github.com/hadley/devtools/commit/8b94cf415da6de12074ad7c51e6f3625388a49cb.\nUnfortunately roxygen2 has dependencies for both stringr and Rcpp, which are the two biggest dependencies for devtools currently, so keeping it in Imports kind of defeats the purpose of this PR.\nI agree with the batteries included approach to devtools, it just doesn't jive well when it is used for installing packages on CIs. You could always suggest people install devtools with install.packages(\"devtools\", dependencies = TRUE) to install all the Suggested packages (including roxygen2).\nThe best solution would be to split out the install_ functions to their own package (installr?), which would have limited dependencies, but for now I guess this is a stop gap.\n. Actually testthat has nearly always been in Suggests (https://github.com/hadley/devtools/commit/0a02d83069e11e6d40c88831d0b5b047a4ced874) and is only used for test(), which we check for https://github.com/hadley/devtools/pull/962/files#diff-576140fd16c657af5df5c401b5f95bbbR21, so that should be OK.\nThe main issues with just using install.packages(\"devtools\", dependencies = TRUE) is\n1. BiocInstaller, because you can't install that from CRAN (and most people aren't going to need it)\n2. Rcpp (not needed if you are doing R only) and Windows users often don't have a RTools installed.\n3. lintr - many people aren't going to use this, has a hefty igraph dependency (although it wouldn't hurt it's popularity :smile:)\n4. MASS and bitops - these are just used in the tests\n5. knitr & rmarkdown (not useful if you are using old style Sweave vignettes)\nI think 1. kind of makes the dependencies = TRUE approach a non-starter for general use.\nRe: @gaborcsardi this implementation does generate an error with informative message about the missing packages, but offering to install them isn't a bad idea though, maybe that is the best way to solve this problem...\n. https://github.com/hadley/devtools/commit/e4f1ece54584097c14f962ede12742090dcd814c adds the a prompt to install the suggested packages if they are not installed, I think it will work well.\n. https://github.com/jimhester/devtools/commit/2db88ba7e380a4f7fc369a1fe0962ea2633869a3 adds a NOTE to news.\nWith https://github.com/hadley/devtools/commit/e4f1ece54584097c14f962ede12742090dcd814c if someone doesn't have roxygen2 or testthat installed when they run document() or test() respectively it will prompt them asking if they want to install it, so it should be pretty seamless for new users I think.\nAnother additional thing we could do would be to add installation prompts to setup() for roxygen2 and testthat. setup() is called for create() as well, so this would ensure users have both roxygen2 and testthat if they are writing a new package. I don't know how much that adds to the current functionality though, thoughts?\n. This is now ready https://github.com/jimhester/devtools/commit/d7c94be970e86c598512177ceaf2401a2658d88c failed only because of GitHub rate limiting on Appveyor and contains only NEWS changes from https://github.com/jimhester/devtools/commit/b4bc23e04f192154c2d3cb8ef8277442d6925290, which passed.\n. Hmm true, I can write a function to read the version number from the DESCRIPTION and use that is the default value of version for check_suggested().\n. I believe the relevant source lines are https://github.com/wch/r-source/blob/c2eacc98080d425319d44708fc06435522315737/src/library/tools/R/QC.R#L6605-L6611, which gives us the following fields to choose from\n``` r\npaste0(tools:::.get_standard_DESCRIPTION_fields(),\"Note\")\n>  [1] \"PackageNote\"                 \"VersionNote\"\n>  [3] \"PriorityNote\"                \"DependsNote\"\n>  [5] \"ImportsNote\"                 \"LinkingToNote\"\n>  [7] \"SuggestsNote\"                \"EnhancesNote\"\n>  [9] \"LicenseNote\"                 \"License_is_FOSSNote\"\n> [11] \"License_restricts_useNote\"   \"OS_typeNote\"\n> [13] \"ArchsNote\"                   \"MD5sumNote\"\n> [15] \"NeedsCompilationNote\"        \"Additional_repositoriesNote\"\n> [17] \"AuthorNote\"                  \"Authors@RNote\"\n> [19] \"BiarchNote\"                  \"BugReportsNote\"\n> [21] \"BuildKeepEmptyNote\"          \"BuildManualNote\"\n> [23] \"BuildResaveDataNote\"         \"BuildVignettesNote\"\n> [25] \"BuiltNote\"                   \"ByteCompileNote\"\n> [27] \"Classification/ACMNote\"      \"Classification/ACM-2012Note\"\n> [29] \"Classification/JELNote\"      \"Classification/MSCNote\"\n> [31] \"Classification/MSC-2010Note\" \"CollateNote\"\n> [33] \"Collate.unixNote\"            \"Collate.windowsNote\"\n> [35] \"ContactNote\"                 \"CopyrightNote\"\n> [37] \"DateNote\"                    \"DescriptionNote\"\n> [39] \"EncodingNote\"                \"KeepSourceNote\"\n> [41] \"LanguageNote\"                \"LazyDataNote\"\n> [43] \"LazyDataCompressionNote\"     \"LazyLoadNote\"\n> [45] \"MailingListNote\"             \"MaintainerNote\"\n> [47] \"NoteNote\"                    \"PackagedNote\"\n> [49] \"SysDataCompressionNote\"      \"SystemRequirementsNote\"\n> [51] \"TitleNote\"                   \"TypeNote\"\n> [53] \"URLNote\"                     \"VignetteBuilderNote\"\n> [55] \"ZipDataNote\"                 \"RepositoryNote\"\n> [57] \"PathNote\"                    \"Date/PublicationNote\"\n> [59] \"LastChangedDateNote\"         \"LastChangedRevisionNote\"\n> [61] \"RevisionNote\"                \"RcmdrModelsNote\"\n> [63] \"RcppModulesNote\"             \"RoxygenNote\"\n> [65] \"AcknowledgementsNote\"        \"AcknowledgmentsNote\"\n> [67] \"biocViewsNote\"\n```\nWe could probably co-opt PackageNote, Package_d_Note, MaintainerNote or one of the other ones if they seem more suitable.\n. If the idea is to communicate back to devtools users the GA idea won't help (it is an interesting idea though).\nCould we add a registration prompt to devtools that would ask devtools users to send their email addresses to us? They could be entered in a drawing to win devtools stickers as incentive to register?\n. A agree, it seems like all the CIs scripts have to jump through hoops to set the CRAN mirror.\nIt might be worth using a format that allows one to set any repository (so you could use alternate bioconductor, omegahat or other repositories as well).\nMaybe a format like\nbash\nR_REPOS=cran=http://cran.rstudio.com:BiocSoft=https://bioconductor.org/packages/3.3/bioc:CRANxtras=http://www.stats.ox.ac.uk/pub/RWin\nSimple implementation to parse could be something like\n``` r\nparse_repos <- function(x) {\n  # perl = TRUE is needed for the negative lookahead assertion\n  splt <- strsplit(strsplit(x, \":(?!//)\", perl = TRUE)[[1]], \"=\")\n  if (length(splt[[1]]) == 1) {\n    return(splt[[1]])\n  }\nnms <- vapply(splt, [[, character(1), 1)\n  urls <- vapply(splt, [[, character(1), 2)\nsetNames(urls, nms)\n}\nSys.setenv(R_REPOS=\"cran=http://cran.rstudio.com:BiocSoft=https://bioconductor.org/packages/3.3/bioc:CRANxtras=http://www.stats.ox.ac.uk/pub/RWin\")\nparse_repos(Sys.getenv(\"R_REPOS\"))\n>                                         cran\n>                    \"http://cran.rstudio.com\"\n>                                     BiocSoft\n> \"https://bioconductor.org/packages/3.3/bioc\"\n>                                    CRANxtras\n>         \"http://www.stats.ox.ac.uk/pub/RWin\"\nSys.setenv(R_REPOS=\"http://cran.rstudio.com\")\nparse_repos(Sys.getenv(\"R_REPOS\"))\n> [1] \"http://cran.rstudio.com\"\n```\nThe above also handles simple case of specifying only the CRAN repository, i.e. R_REPOS=http://cran.rstudio.com\nI feel like this should really be supported in base R, but that is probably too steep a hill to climb.\n. I guess if drat repos get more popular that would be another use case, but you are probably right most people aren't going to use them.\n. You could reduce the list to only the CRAN part pretty simply though. Tweaking the proposed scheme to be just a quoted R character vector.\n``` bash\nCRAN=\"http://cran.rstudio.com\"\nCRAN_INLINE=$(echo $CRAN | perl -pe 's/.cran=\"([^\"]+)\"./$1/')\necho $CRAN_INLINE\nhttp://cran.rstudio.com\nCRAN='c(cran=\"http://cran.rstudio.com\", BiocSoft=\"https://bioconductor.org/packages/3.3/bioc\", CRANxtras=\"http://www.stats.ox.ac.uk/pub/RWin\")'\nCRAN_INLINE=$(echo $CRAN | perl -pe 's/.cran\\s=\\s\"([^\"]+)\"./$1/')\necho $CRAN_INLINE\nhttp://cran.rstudio.com\n```\nI used perl to do the substitution, but you could use an equivalent sed expression if you prefer, I just don't remember the proper regex syntax off-hand.\n. @onlymee you can squash your commits with git rebase -i to combine them. See https://help.github.com/articles/about-git-rebase/.\nYou should also rebase this PR against the current master first which would remove a lot of the above commits. If you have 'hadley/devtools' as the remote called upstream then git rebase upstream master when you are on your master branch should do it.\n. I rebased, squashed and merged at https://github.com/hadley/devtools/commit/91fddbf5d3376faf76527db51e4d212913b1ef21. Thanks @onlymee!\n. You can specify a sha1 hash or tag to install with install_github() to pin it to a particular version. This is actually more stable than using CRAN, which always will install the most current version. See the examples at ?install_github, e.g.\nr\ninstall_github(c(\"hadley/httr@v0.4\", \"klutometis/roxygen#142\",\n       \"mfrasca/r-logging/pkg\"))\nIf you want to do this same thing with CRAN releases you can use the mirrors at https://github.com/cran/, which have tagged versions for each release.\n. While this is working for the test package and for devtools itself I have not tested it with any S4 packages to ensure it works there. I wanted to put it out there to get feedback on the implementation and see if there are any changes that need to be made.\nThis error has long been a frustrating one for me, as it seemed to happen randomly, so finally figuring out what was going on and fixing it was pretty satisfying!\n. https://github.com/hadley/devtools/commit/200b631d42192c966dfacff5a48b51edd837f70f uses a different approach to fixing the issue by simply forcing all of the promises explicitly before trying to unload rather than removing them. I also converted all of the previous uses of as.list() to use eapply(ns, force) to make it a little more explicit what was going on.\nThe previous commit was running into problems when trying to unload or reinstall devtools that do not occur using this method.\nI also tested this version on some S4 classes from Bioconductor and they seem to work without error.\n. I actually had a comment written (https://github.com/hadley/devtools/commit/6d760c5bf903294bee4aaf3dfc6f01f2e2cac51e) just neglected to push it. I also added a note to the NEWS about this change https://github.com/hadley/devtools/commit/d96101f163916162a81a4f12f820f4849917f4e4.\nLet me know if you want me to squash the commits or leave them as-is.\n. For reference I opened a bug report about this (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16644). BDR points out it is technically documented behavior, so there is unlikely to be a fix upstream. \nPersonally I think the current behavior of detach() and unloadNamespace() is hostile to users. You should be able to first load and unload a package and have your environment be identical to when you started. It doesn't even seem that difficult to add this support, so I wonder why it wasn't implemented (I am probably missing some subtlety).\nAnyway this pull should fix the majority of the errors people experience when using devtools at least, thank you for merging it!\n. That looks correct to me, current behavior seems broken.\n@gaborcsardi it would be great to have a test for this as well to prevent a regression in the future. Seems a little tricky to test though, you could supply a parse_deps() object to update.package_deps() with a mock install_packages function.\n. @gaborcsardi maybe we could just set some constants for the various numeric codes, which should make this more self-documenting. https://github.com/gaborcsardi/devtools/pull/1 has an implementation, although I did not use the constants in the tests.\nAlso I am not sure my choice of UNINSTALLED was the best, maybe NOTINSTALLED would be better?\n. I actually think this might be better done just by manually adding an unencrypted GITHUB_PAT in the Appveyor settings. https://ci.appveyor.com/project/hadley/devtools/settings/environment. I don't have access to the appveyor settings, they don't inherit GitHubs settings apparently. See http://www.appveyor.com/docs/team-setup\nIf you just make a PAT (https://github.com/settings/tokens) without any scopes it should work fine for this purpose though.\n. I have addressed this in a different way (limiting the number of requests devtools makes https://github.com/hadley/devtools/commit/7e6a29023f1c2fce83d20754590f0c81a1ff85b8 https://github.com/hadley/devtools/commit/3251999b8fabcde110761e96284f4c8f0ff2e4f7. Still might be useful to set a PAT within appveyor though...\n. Yeah the Appveyor folks must have only a few external IPs so you hit it pretty quickly, travis either has an exception from GitHub or uses many more external IPs.\n. I guess one bad consequence of this approach is it generates a WARNING from R CMD check because the code from loadNamespace has calls to internal methods functions. https://ci.appveyor.com/project/hadley/devtools/build/1.0.174#L263. Could get rid of them but it would require more meta-programming :frowning:.\nI am still not sure why we are getting failures on windows, still working on it.\n. In this case we are setting the enclosing environment of the function to the methods package anyway, so I could just strip the methods::: calls from the code (https://github.com/jimhester/devtools/commit/9c3eb0b7495f39c8f82aed709aca19188069de98).\n. I think the approach has merit, when we need to copy code it seems better if it is done programmatically rather than by hand.\nI think we can wait to merge this PR though. I want to use this same idea for other code in devtools so I will add to this PR as I go.\n. I am now using delayedAssign() to do the assignment, which ensures the functions will only be extracted from the currently running version of R. This also removes any issues with R CMD check.\nCurrent progress\n- [x] add_classes_to_exports\n- [x] addNamespaceDynLibs\n- [x] makeNamespace\n- [x] assignNativeRoutines\n- [x] process_imports\n- [ ] setup_ns_exports\n- [x] load_dll\n- [ ] library.dynam2\n. @wch Thanks for the background winston, I was actually just running into some strange issues with delayedAssign() and assignNativeRoutines so am going to try to do it in .onLoad() instead.\n. Actually the package namespace is not locked until after .onLoad() runs, so you can actually assign to the package namespace. We are currently doing this already for the withr:: functions (https://github.com/hadley/devtools/blob/master/R/load-dll.r)\n. Ok this is probably ready to review now, setup_ns_exports and library.dynam2 are both different enough from the base R code I don't think there is much we can extract and all the others have been done.\nAny thoughts on making this code more clear would be appreciated, doing meta-programming is always a little tricky to understand at first glance.\n. I modified the calls to use the new comp_lang() function which I think cleaned things up a bit. Also moved the tryCatch blocks to inside the for loops.\n. I added the suggested warning and some simple tests to prevent regressions in the future.\n. I added the warning as well as some simple tests.\n. One thing that makes this problematic is it assumes the version of code you are installing is actually committed. If you have not actually committed the changes the SHA will still be the same as last committed version even though the installed code will be different.\nMaybe we could check if the git status shows no modifications or uncommitted files before adding the SHA?\n. You can use something like the following\n``` r\nr <- git2r::repository(\".\", discover = TRUE)\ns <- git2r::status(s)\n> working directory clean\nstr(s)\n>  $ staged   : Named list()\n>  $ unstaged : Named list()\n>  $ untracked: Named list()\n>  - attr(*, \"class\")= chr \"git_status\"\nall(vapply(git2r::status(r), length, integer(1)) == 0)\n> [1] TRUE\nPutting this in a function the default argument for add_sha could be add_sha = is_clean(pkg)\nis_clean <- function(path) {\n  r <- git2r::repository(\".\", discover = TRUE)\n  all(vapply(git2r::status(r), length, integer(1)) == 0L))\n}\n```\nI am not sure is_clean is a great name for the function, probably too generic...\n. You can't use git_uncommitted directly as it throws an error if you are not in a git repository, so you will have to write a wrapping function that calls uses_git() first.\nr\ngit_wd_clean <- function(path = \".\") {\n  uses_git(path) && !git_uncommitted(path)\n}\nYou shouldn't actually have to export this function IIRC\n. I personally think you should keep things simple and make the git_wd_clean() implementation just\nr\ngit_wd_clean <- function(path = \".\") {\n  uses_git(path) && !git_uncommitted(path)\n}\nWe really want to err on the side of caution with this and only add a SHA reference if we are sure everything in the working directory is committed. Particularly once https://github.com/hadley/devtools/pull/903 is merged and doesn't reinstall packages if the SHA is the same as the previous install. If a user really wants to ignore a dirty working directory they could always just use add_sha = TRUE.\nInstalling without a SHA is the current behavior and works fine, so I don't see much downside on being conservative and only adding one if we are sure it is valid.\n@hadley any thoughts?\n. I think this is very transient, it now works fine for '0.12.2' as well.\n``` r\n\ninstall_version('shiny', '0.12.2', type='source')\nDownloading package from url: https://cran.rstudio.com/src/contrib/Archive/shiny/shiny_0.12.2.tar.gz\nInstalling shiny\n'/usr/local/Cellar/r/3.2.3/R.framework/Resources/bin/R' --no-site-file --no-environ --no-save --no-restore CMD INSTALL  \\\n  '/private/var/folders/dt/r5s12t392tb5sk181j3gs4zw0000gn/T/RtmpbT31m1/devtools3ac848fec49c/shiny' --library='/usr/local/lib/R/3.2/site-library' --with-keep.source  \\\n  --install-tests\n\n\ninstalling source package \u2018shiny\u2019 ...\n package \u2018shiny\u2019 successfully unpacked and MD5 sums checked\n R\n inst\n tests\n preparing package for lazy loading\n help\n installing help indices\n* building package indices\n testing if installed package can be loaded\nDONE (shiny)\n```\n. It might make sense to have the memoised cache timeout after a day. https://github.com/hadley/memoise/issues/11 has a proposal to that effect, or could use the non-arguments cache in the same way https://github.com/hadley/memoise/pull/16 if that is merged.\n. Trying both makes sense to me.\n\nFWIW available.packages() still much slower than the memoised version\n``` r\nmicrobenchmark(times = 10L,\n  available_packages(repos = \"https://cran.rstudio.com\", type = \"both\"),\n  available.packages(contrib.url(repos = \"https://cran.rstudio.com\", type = \"both\"), type = \"both\")\n)\n> Unit: microseconds\n>                                                                                                    expr\n>                                   available_packages(repos = \"https://cran.rstudio.com\", type = \"both\")\n>  available.packages(contrib.url(repos = \"https://cran.rstudio.com\",      type = \"both\"), type = \"both\")\n>         min         lq        mean     median         uq        max neval\n>      64.977     69.516    116.5874    139.475    149.765    158.225    10\n>  291890.933 300657.495 307988.7893 304793.931 313268.456 338722.133    10\n``\n. Here's an alternative plan that might make things simpler. How about instead of havingadd_metadata()add the metadata to theDESCRIPTION_before_ it gets installed (https://github.com/hadley/devtools/blob/master/R/install-remote.R#L20) we add ametadata=argument toinstall` and have the remotes pass the metadata to it and add it after installation (e.g. at https://github.com/hadley/devtools/blob/master/R/install.r#L106).\nThat removes the whole chicken and the egg issue and we can just write a function for metadata= that by default checks if the git working directory is clean and adds the SHA metadata if so.\n. See proof on concept https://github.com/jimhester/devtools/commit/aa15cd0f3e9e8c8eadfc8e9c962f4bd958ec060f which works with limited testing on my machine.\n. Also note this is using remote_metadata.local_remote directly, but we will probably want to define a new function that uses your git_committed() function instead of just uses_git() in the if statement.\n. The idea would be to change the other install_ functions to pass their remote_metadata calls to install, everything would use the same path, so nothing would need to be special cased.\n1. Maybe relevant, but as long as it doesn't generate a NOTE from R CMD check it should be ok.\n. Sorry I was not more clear in my proof on concept what I had in mind.\nI would keep this pull request. Actually I would have kept the previous one open so that the discussion was all together, you can always \n``` shell\nreset state to previous state\ngit reset upstream/master\nmake new commits\n...\ngit push --force\n```\nTo remove the old commits if needed.\n. I would really follow my proof on concept. Just write a new method for package\nr\nremote_metadata.package <- function(x, bundle = NULL, source = NULL) {\n  list(\n    RemoteType = \"package\",\n    RemoteUrl = x$path,\n    RemoteSha = if (git_committed(x$path)) git_sha1(path = x$path)\n  )\n}\nMake the default argument for install metadata = remote_metadata(as.package(pkg)) and add it after the R CMD check.\nr\nif (length(metadata)) {\n  add_metadata(base::system.file(package = pkg$package), metadata)\n}\nThen just change https://github.com/hadley/devtools/blob/master/R/install-remote.R#L20-L25 to pass the metadata to install rather than adding it beforehand.\n``` diff\ndiff --git a/R/install-remote.R b/R/install-remote.R\nindex b1192b4..a22232a 100644\n--- a/R/install-remote.R\n+++ b/R/install-remote.R\n@@ -17,12 +17,13 @@ install_remote <- function(remote, ..., quiet = FALSE) {\n   source <- source_pkg(bundle, subdir = remote$subdir)\n   on.exit(unlink(source, recursive = TRUE), add = TRUE)\n-  add_metadata(source, remote_metadata(remote, bundle, source))\n# Because we've modified DESCRIPTION, its original MD5 value is wrong\n   clear_description_md5(source)\n\ninstall(source, ..., quiet = quiet)\ninstall(source,\nmetadata = remote_metadata(remote, bundle, source),\n..., quiet = quiet)\n+\n }\n```\n\nYou actually don't have to change any of the install_ functions directly.\n. https://github.com/jimhester/devtools/commit/212d272b9726529b034ee6329da856f0c68d16ea has a working implementation passing the regular devtools tests (https://travis-ci.org/rmflight/devtools/builds/102617084#L2277-L2279). It just needs documentation and some additional tests written if possible.\n. Mmm yes that is an issue, see https://github.com/jimhester/devtools/commit/bd0cff1e906f647b19a03005267fe70f821b4b58 for code which updates it as well as the DESCRIPTION.\n. Ok this is looking good, I think we should modify https://github.com/hadley/devtools/blob/81dd313e1d143a3bdaaa2e1f09c887801db66694/R/session-info.r#L156-L159 to work with this situation better. Right now the code assumes there is always a RemoteUsername and RemoteRepo if there is a RemoteType, which in this case (and when using install_local`) that is not true.\n. This should fill in the github user/repo information if the repository has a github remote set up. It doesn't necessarily mean the given revision is actually pushed to that remote however...\n``` diff\ndiff --git a/R/install-local.r b/R/install-local.r\nindex 6877f5d..b7d843e 100644\n--- a/R/install-local.r\n+++ b/R/install-local.r\n@@ -49,10 +49,18 @@ remote_metadata.local_remote <- function(x, bundle = NULL, source = NULL) {\n#' @export\n remote_metadata.package <- function(x, bundle = NULL, source = NULL) {\n-  list(\n-    RemoteType = \"package\",\n-    RemoteUrl = x$path,\n-    RemoteSubdir = x$subdir,\n-    RemoteSha = if (git_committed(x$path)) git_sha1(path = x$path)\n+  res <- list(\n+    RemoteType = \"local\",\n+    RemoteUrl = x$path\n   )\n+\n+  if (git_committed(x$path)) {\n+    res$RemoteSha <-  git_sha1(path = x$path)\n+  }\n+  if (uses_github(x$path)) {\n+    info <- github_info(x$path)\n+    res$RemoteUsername <- info$username\n+    res$RemoteRepo <- info$repo\n+  }\n+  res\n }\n``\n. Also I am not sure having aRemoteType = 'package'` is useful, which is why I switched it back to 'local' in the diff.\n. If the two functions are literally the same I think we should just make them aliases.\nr\nremote_metadata.package <- remote_metadata.local_remote\nAlso could you rebase this on the current master and possibly squash some of the more trivial commits. https://help.github.com/articles/about-git-rebase/ has some help on using Git rebase if you need a reference.\n. Just remember you can always abort the rebase with git rebase --abort if needed. If you are worried about messing something up you can checkout the current state into a new branch, then switch back. The backup won't be altered by the rebase.\ngit checkout install_sha\ngit checkout -b backup\ngit checkout install_sha\n. @rmflight Best thing to do is just use inst() here instead of find.package(). It will always give the path to the installed copy of the package.\nSee https://github.com/jimhester/devtools/commit/fc359c214d81073375e0c0ec0cf85b827f28edb7\n. I am going to add the fix for https://github.com/hadley/devtools/issues/943 here as well as they are somewhat related and this pull request will exacerbate the situation there (as users will have more than one repo more often).\n. Ok I decided to make them separate after all, this one looks good to merge now.\n. Ok this should be ready to merge unless there is something you think needs changing.\n. If this was using utils::packageVersion() as the comment suggests wch/r-source/src/library/base/R/library.R#L812-L826 this would work fine. But as you noted because load_all() does not create a package.rds file this breaks.\nWe could insert a shim .getRequiredPackages2 in devtools to fix this I suppose although I think it is best to keep shims to a minimum...\n. I can relax the withr dependency to 3.0.2 but I am not sure when I will do another withr release...\n. Thanks for looking into the problem and the fix. This actually will happen often in practice because travis does a shallow clone of the repository for every build.\nIt would be great to have a test for this case, though I would prefer it be of a local git repository rather than a remote one.\nCould you also add a note to NEWS.md.\n. @nparley I would make a dummy package with a shallow checkout using command line git and put it in tests/testthat, then use that for testing.\n. Good point Gabor, an easy fix is to use a --bare clone, so you don't have any .git directory. We don't actually need any files for this test, just the git objects.\nshell\ngit clone --depth=50 --bare https://github.com/hadley/devtools.git /tmp/devtools\nRscript -e 'r <- git2r::repository(\"/tmp/devtools\")' -e 'git2r::branch_target(git2r::head(r))'\n[1] \"21d5d9401101dcf2baada3db424e4de0e9c7f869\"\n. @jennybc You can store .git with other names, see variety of answers at http://stackoverflow.com/questions/505467/can-i-store-the-git-folder-outside-the-files-i-want-tracked\nI even wrote a post about this a few years ago (http://www.jimhester.com/blog/2012/11/08/external-git/) although the solution there still has a .git file, so won't help here. \n. The Found the following non-portable file paths: NOTE occurs because the filename is more than 100 characters long. See (https://stat.ethz.ch/R-manual/R-devel/library/utils/html/tar.html) for details.\n``` r\nnchar(\"devtools/tests/testthat/testBareDepthRepo/objects/pack/pack-c4e0f1d1d68408f260cbbf0a533ad5f6bfd5524e.idx\")\n> [1] 104\n```\nrenaming the testBareDepthRepo directory to be shorter should fix the NOTE.\ntestthat tests are run with tests/testthat as the working directory, so that test should be correct.\nYou can remove all the sample hooks from tests/testthat/testBareDepthRepo/hooks/*, might as well not include them as they won't be used.\n. Yes because I like making things more complicated than they need to be :frowning:. https://github.com/hadley/devtools/commit/7ef2c95e1b2a9c2abbbd1ff26f62f54f1677b65a does as you suggest!\n. I don't think you can import with an alias using importFrom in the NAMESPACE, but we could do it explicitly at install-time withr_with_dir <- withr::with_dir which I think will allow us to keep the deprecated functions and fix this issue.\n. Thanks Gabor, you are correct doing it on .onLoad() is preferred. https://github.com/jimhester/devtools/commit/4e7e30e3faad543aecfb2014f23dfdaf3c4ff631 should preserve the deprecation behavior and allow load_all(\"withr\") to work as well.\n. My previous commit was inadvertently assigning into the global namespace. https://github.com/hadley/devtools/commit/014f3074d27dcdf695196da637b631ef7e77a5e8 properly assigns the aliased functions into the package namespace.\n. Specifying exact version dependencies pkg (== 1.1.1) is not really useful in practice because install.packages() always installs the latest package from the repository. This means that your package will no longer be installable if any of the dependencies with exact specifications release a new version. Because of this I think use_package() could just have a version= parameter that would add (>= version) if set or do nothing if NULL.\nPlease either do not bump the devtools version or bump the minor version number only, e.g. to 1.10.0.9001.\nYou also need to run devtools::document() to update the documentation from the updated roxygen comments.\n. IMHO the interface for this should be as follows.\n``` r\nuse_package <- function(package, type = \"Imports\", pkg = \".\", \n  version = NULL, compare =  c(\">=\", \">\", \"==\", \"<=\", \"<\")) {\nif (!is.null(version)) { # add a version dependency\n    if (isTRUE(version)) {\n      version <- packageVersion(package)\n    }\n    compare <- match.arg(compare)\n    package_txt <- paste0(package, \" (\", compare, \" \", version, \")\")\n  } else {\n    package_txt <- package\n  }\n  package_txt\n# ... rest of function\n}\nuse_package(\"devtools\")\n> [1] \"devtools\"\nuse_package(\"devtools\", version = TRUE)\n> [1] \"devtools (>= 1.10.0.9000)\"\nuse_package(\"devtools\", version = TRUE, compare = \"==\")\n> [1] \"devtools (== 1.10.0.9000)\"\nuse_package(\"devtools\", version = \"1.10\")\n> [1] \"devtools (>= 1.10)\"\nuse_package(\"devtools\", version = \"1.10\", compare = \">\")\n> [1] \"devtools (> 1.10)\"\n```\nThis allows the default behavior to remain the same as it is currently. If you want to have a version dependency you can pass version = TRUE to use the installed version, or specify the explicit version you want. If you want to use a different comparison function you can pass that to compare.\n. https://github.com/stevenpollack/devtools/commit/52bd39af5e75c2e72c564e48a22976d98215c038 looks good!\nPlease add a note about this change to the NEWS.md file.\nIt also would be nice to have some tests for this function, there are not currently any written. I would make a simple test package like used in the tests for use_data() https://github.com/hadley/devtools/blob/master/tests/testthat/test-infrastructure.r. The package you can add could be a base package like utils, which would ensure it is always available.\n. Remotes: works the same as Imports: etc, you need commas in between each entry.\ndiff\n@@ -3,5 +3,5 @@\n Imports:\n  devtools (>= 1.10.0)\n Remotes:\n-  hadley/ggplot2\n+  hadley/ggplot2,\n   hadley/memoise\n. I think we need to bump the R version in DESCRIPTION as well to at least 3.2, possibly 3.2.2. Versions prior to that did not properly support https repositories. See https://support.rstudio.com/hc/en-us/articles/206827897 for more details. \nMaybe devtools should set the proper download method for https for you? \n. capabilities(\"libcurl\") should work for R >= 3.2 on OS X and linux, but maybe not on windows?\nMaybe the easiest thing would be to try establishing a https connection and if it fails fallback to http?\nr\ncran_url <- memoise::memoise(function() {\n  tryCatch({\n    stopifnot(identical(httr::status_code(httr::HEAD(\"https://cloud.r-project.org\")), 200L))\n    \"https://cloud.r-project.org\"\n    }, error = function(e) \"http://cloud.r-project.org\")\n})\n. The BiocInstaller does a similar thing (https://github.com/Bioconductor/BiocInstaller/blob/master/R/zzz.R#L43-L69)\n. This is an RStudio issue. See https://support.rstudio.com/hc/en-us/community/posts/200652506-RStudio-Desktop-is-not-resecting-my-R-LIBS-USER. You are probably setting your R user directory in a way RStudio is not picking up (like your shell startup files).\n. https://github.com/jimhester/devtools/commit/ed000dd17f5561464915b28d2d5d3c2a3e0c3caa does as you suggest moving the SHA checking into install_remote() so it works the same across all remote types.\nI also moved the remote updating into update.package_deps, so it will automatically work with the existing update_packages().\n. @krlmlr You are correct, the remotes should respect update_dependencies as well.\n. https://github.com/hadley/devtools/pull/1067/commits/c35630ca941b043b8560c63801ab7a34ac13507d has a simple implementation to handle #1109 \n. This LGTM. I ran into this as well. I think this is a regression caused by the switch to withr. withr::with_libpaths has a default action of 'replace', while I believe the devtools version prepended.\n. I was wrong about it being a regression of set_libpaths, it did replace completely previously.\nThat first instance was deliberately changed to from prepending to replace at\nhttps://github.com/hadley/devtools/commit/516e59fbeebf438adb9c44bb239bf7186bff62ab. The second looks like we can replace with action = 'prefix'.\n. setting NEWS.md merge=union in the projects .gitattributes works locally, but GitHub ignores that setting when doing its merge. That is unfortunate :frowning:. It is probably still worth setting it for devtools as it would make local merging easier. https://github.com/isaacs/github/issues/487 is the un-official issue for GitHub support for union merges.\n. What version of make do you have. Your test works on my machine OS X 10.11.2 (with an admittedly old version of make)\n```\nGNU Make 3.81\nCopyright (C) 2006  Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.\nThere is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A\nPARTICULAR PURPOSE.\nThis program built for i386-apple-darwin11.3.0\n```\n. And sure enough if I use a newer version of make I can reproduce this\n```\n\nmake -v\nGNU Make 4.1\nBuilt for x86_64-apple-darwin15.2.0\nCopyright (C) 1988-2014 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later http://gnu.org/licenses/gpl.html\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\nmake -j4 install\ngit clean -fdx; Rscript --vanilla -e \"devtools::load_all()\"\nRemoving src/RcppExports.o\nRemoving src/fakepackage.so\nRemoving src/hello.o\nLoading fakepackage\nRe-compiling fakepackage\n'/usr/local/Cellar/r/3.2.3/R.framework/Resources/bin/R' --no-site-file  \\\n  --no-environ --no-save --no-restore CMD INSTALL  \\\n  '/Users/jhester/pkg/r-appveyor'  \\\n  --library='/var/folders/dt/r5s12t392tb5sk181j3gs4zw0000gn/T//RtmpI49ilp/devtools_install_2497d1c95e9'  \\\n  --no-R --no-data --no-help --no-demo --no-inst --no-docs --no-exec  \\\n  --no-multiarch --no-test-load\n\n\ninstalling source package \u2018fakepackage\u2019 ...\n** libs\nclang++ -I/usr/local/Cellar/r/3.2.3/R.framework/Resources/include -DNDEBUG -I/usr/local/include  -I/usr/local/opt/gettext/include -I/usr/local/opt/readline/include -I/usr/local/opt/openssl/include -I/usr/local/include -I\"/usr/local/lib/R/3.2/site-library/Rcpp/include\" -I/usr/local/include   -fPIC  -g -O2  -c RcppExports.cpp -o RcppExports.o\nmake[1]:  read jobs pipe: No such file or directory.  Stop.\nmake[1]:  Waiting for unfinished jobs....\nERROR: compilation failed for package \u2018fakepackage\u2019\nremoving \u2018/private/var/folders/dt/r5s12t392tb5sk181j3gs4zw0000gn/T/RtmpI49ilp/devtools_install_2497d1c95e9/fakepackage\u2019\nError: Command failed (1)\nExecution halted\nMakefile:4: recipe for target 'install' failed\ngmake: *** [install] Error 1\n```\n\nI don't really know the solution though, it looks to me like the downstream make calls are inheriting the parameters of the top level make and the downstream makefile does not support parallel make.\n. Have use_github() automatically add it for us :smile:.\n. I guess you have most of this already at https://github.com/hadley/ggplot2/blob/master/CONTRIBUTING.md, so we can adapt that as the template\n. I wonder if this is an issue when the package being tested also uses mclapply(). It might be worth seeing if it is caused by a specific package(s).\n. If you use install_github(\"tdhock/animint\", upgrade_dependencies = FALSE) it will not try to upgrade the outdated ggplot2.\nAlternatively you can artificially bump the version number in your fork of ggplot2 to be higher than the CRAN version.\nThe assumption is that development dependencies will always have greater versions than CRAN versions. It might be worth tweaking the logic to exclude development packages from the version checking logic entirely however...\n.  \nStrikes again, thanks!\n. Thanks!\n@hadley I am just merging this as it is clearly wrong and a minor change.\n. Dupe of #1097\n. Right now the remotes do not respect the upgrade_dependencies argument of install(). This is an oversight I am currently working on correcting.\nIn the meantime I would suggest you create a personal fork of bookdown and modify the Remotes: to pin to the versions you want to use.\nyaml\nRemotes: rstudio/rmarkdown@70b9f1ec4ce71628d, rstudio/htmltools@abc123, ramnathv/htmlwidgets@xyz242526\nIf you want to lock down the CRAN dependencies as well add them to your Remotes: from the GitHub mirrors at https://github.com/cran. e.g.\nyaml\nRemotes: cran/knitr@1.12.3\n. roxygen2 has this same deficiency, I will send a PR there as well.\n. Do we need to sort the filenames here, or change the collation order around the call to list_files_with_type()?\nlist.files() returns them sorted, but I guess if you are using a local with a different collation order than C it wouldn't be sorted properly?\n. Setting the locale/collate goes all the way back to the initial devtools checkin https://github.com/hadley/devtools/commit/fbae60ced0afee0e7c0f8dc3b5b1bb48d303f3dd#diff-170bec08bbfc9e0be8b468b0fb147ec7R21, I am not sure if it is actually required or not in practice though...\n. It would only be used conditionally so could just be in Suggests, so it\nwouldn't be too bad...\nOn Mar 23, 2016 5:58 PM, \"G\u00e1bor Cs\u00e1rdi\" notifications@github.com wrote:\n\nI like BatchJobs a lot, but that brings in a lot of dependencies, and\ndevtools already has some biggish ones.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/1106#issuecomment-200560336\n. Why can't you use install.packages() directly and adjust the repos option depending on whether you want to install from the stable or development branch? If you want to make this easy to switch just write a simple function to change the repos option.\n\n``` r\nuse_devel <- function(devel = TRUE) {\n  repos <- getOption(\"repos\")\n  if (isTRUE(devel)) {\n    repos[\"Dev\"] <- \"http://myserver/cran-dev\"\n  } else {\n    repos <- repos[names(repos) != \"Dev\"]\n  }\n  options(repos = repos)\n}\n``\n. 'prod' packages would still be available usinginstall.packages(), just setoptions(repos = c(Stable = \"Stable=\"http://myserver/cran-stable\", CRAN=\"https://cran.revolutionanalytics.com\"))in your personal or site.Rprofile.\n. FWIW drat repositories should already work on travis if you put them inAdditional_repositoriesas Gabor said. If you find this not to be the case please let us know.\n. This is already supported by bothinstall_github()andbiocLite()`.\nr\ndevtools::install_github(\"Bioconductor-mirror/Gviz\")\nAnd \nr\nBiocInstaller::biocLite(\"Bioconductor-mirror/Gviz\")\nboth do what you want to do. If you are developing a new package make sure it has BiocViews populated in your DESCRIPTION, which is what devtools uses to detect a package is a Bioconductor package (https://github.com/hadley/devtools/blob/dfec75fe9d457d6b0bb04f99252e3dcf0940f0e4/R/utils.r#L149-L151).\n. This should be submitted to https://github.com/klutometis/roxygen/issues instead.\n. libhunspell-dev is in the whitelist for ubuntu-precise, so this should be using the apt addon rather than using sudo (https://github.com/travis-ci/apt-package-whitelist/blob/master/ubuntu-precise#L5584)\nyaml\naddons:\n  apt:\n    packages:\n      - libhunspell-dev\n. Devtools uses NEWS.md, which is now rendered by CRAN as HTML.\nSee https://cran.rstudio.com/web/packages/devtools/news.html\n. Yep looks to be hardcoded to NEWS (https://github.com/rstudio/rstudio/blob/d5ab5dfa53c057a289179826a94622b715146e79/src/cpp/session/modules/SessionPackages.R#L429-L432)\n@kevinushey What do you think the best way to handle this situation is? I don't think there is any way to tell the type of NEWS file a given package is using other than to try both of them.\n. There are 22 packages on CRAN with both NEWS and NEWS.md (https://gist.github.com/jimhester/9e5251c07ffba9e2cfd5 for query code, https://github.com/cran/granovaGG/ for an example package).\nLooking at the first one https://cran.r-project.org/web/packages/granovaGG/index.html CRAN links to the rendered NEWS.html file produced from NEWS.md and does not link to the NEWS file.\nI would probably do 2) as both of the options require two requests and then you don't have to worry about the layout breaking your parse.\n. https://github.com/hadley/devtools/pull/1121/commits/422f4d3d534eea776973d6c8e0f8aac41fceb3da should use the correct logic. Let me know if you want to change the message text.\n. FWIW I think this is a mistake. Printing the full paths could expose sensitive information from the absolute paths in the report and most users are not going to have non-default libpaths.\nYou can pretty simply provide a custiom session_info function that does provide this information though.\n``` r\noptions(width = 120)\nmy_session_info <- function(...) {\n  libs <- unique(normalizePath(.libPaths(), winslash = \"/\"))\n  nums <- sapply(libs, function (x) length(list.files(x)))\ndevtools:::rule(\"Library info\")\n  print(data.frame(library = libs, packages = nums, stringsAsFactors = FALSE), right = FALSE, row.names = FALSE)\n  print(devtools::session_info())\n}\nmy_session_info()\n> Library info -----------------------------------------------------------------------------------------------------------\n>  library                                                              packages\n>  /usr/local/lib/R/3.2/site-library                                    304\n>  /usr/local/Cellar/r/3.2.3/R.framework/Versions/3.2/Resources/library  30\n> Session info -----------------------------------------------------------------------------------------------------------\n>  setting  value\n>  version  R version 3.2.3 (2015-12-10)\n>  system   x86_64, darwin15.2.0\n>  ui       unknown\n>  language (EN)\n>  collate  en_US.UTF-8\n>  tz       America/New_York\n>  date     2016-03-24\n> Packages ---------------------------------------------------------------------------------------------------------------\n>  package    * version     date       source\n>  clipr        0.2.0       2015-10-06 CRAN (R 3.2.3)\n>  colorspace   1.2-6       2015-03-11 CRAN (R 3.2.3)\n>  devtools   * 1.10.0.9000 2016-02-29 Github (gaborcsardi/devtools@b2c72f5)\n>  digest       0.6.9       2016-01-08 CRAN (R 3.2.3)\n>  evaluate     0.8.3       2016-03-05 CRAN (R 3.2.3)\n>  formatR      1.3         2016-03-05 CRAN (R 3.2.3)\n>  ggplot2    * 2.1.0       2016-03-01 CRAN (R 3.2.3)\n>  gtable       0.2.0       2016-02-26 CRAN (R 3.2.3)\n>  htmltools    0.3.5       2016-03-21 CRAN (R 3.2.3)\n>  knitr        1.12.3      2016-01-22 CRAN (R 3.2.3)\n>  magrittr     1.5         2014-11-22 CRAN (R 3.2.3)\n>  memoise      1.0.0       2016-01-29 CRAN (R 3.2.3)\n>  munsell      0.4.3       2016-02-13 CRAN (R 3.2.3)\n>  plyr         1.8.3       2015-06-12 CRAN (R 3.2.3)\n>  Rcpp         0.12.3      2016-01-10 CRAN (R 3.2.3)\n>  reprex       0.0.0.9001  2016-01-20 Github (helix123/reprex@7a8d39e)\n>  rmarkdown    0.9.5       2016-02-16 Github (rstudio/rmarkdown@1a76e23)\n>  rstudioapi   0.5         2016-01-24 CRAN (R 3.2.3)\n>  scales       0.4.0       2016-02-26 CRAN (R 3.2.3)\n>  stringi      1.0-1       2015-10-22 CRAN (R 3.2.3)\n>  stringr      1.0.0.9000  2016-03-07 Github (hadley/stringr@a67f8f0)\n>  withr        1.0.1       2016-02-12 Github (jimhester/withr@7cc6377)\n``\n. So since all the work is being done in a new R process (started fromcheck_built). Another option would be to start some new child processes withwait = FALSE, thenSys.sleep()in the parent and check if they are done manually, then start some more. This avoids using any parallel backend and is cross platform. The issues would be the inability to stop the child processes from the R console once started, progress could be tracked by looking for theCOMPLETE` file and I guess there would have to be a timeout for stuck processes.\nIt would really be nice if R would return the child process id when wait=FALSE, but alas...\n. This PR breaks the tests on linux and windows. I would suggest running the tests locally with devtools::test() and figuring out why this change breaks them, then update your code so it no longer does so.\n. Should be fixed by https://github.com/hadley/devtools/pull/1104, but we haven't had a CRAN release since that was merged.\n. The problem is the helpers are sourced in the package environment, but data() by default loads the objects in the global environment. Explicitly loading into the calling environment fixes the issue. (see https://github.com/mlr-org/mlr/pull/835)\n@hadley maybe we should add a data() shim which makes this the default?\n. Should be fixed with https://github.com/hadley/devtools/commit/3b066eefbadbe54bba69e725762c2a665270bd89, thanks Winston.\n. Looks like it is actually https://cran.r-project.org/package=rcmdcheck\n. Probably true, I guess this can stay on the backlog until we can get to it.\n. igraph0 being archived was done on pupose for the test, still probably wise to use mocking for this though...\n. https://github.com/hadley/devtools/pull/1155/commits/678dc1e225c9df2be8e8201738a1a7dfa4feb07e should be ok to merge.\nIt got a clean check from win-builder (http://win-builder.r-project.org/ZrVV35IPB27C/00check.log)\n. Ok now merged, can be released whenever you are ready.\n. http://win-builder.r-project.org/AR9c4VAKB8y6/00check.log report is clean.\n. Do you have an example package where this is occurring?\n. Also a workaround with CRAN devtools is to use something like the following https://github.com/hadley/devtools/pull/751#issuecomment-215540807. I would prefer to keep as much implementation consistent with the GitHub methods as possible. If there are methods which are unchanged from the github implementation they should simply be aliases. Bitbucket is not currently widely used compared to GitHub by the main devtools developers so if the code is simply copied they will likely not be kept up to date.\nAs noted storing the access token in the users' home directory is against CRAN policies, I think another location will have to be considered. There also needs to be a way for users to customize where this token is placed, either a R option or environment variable (or both).\nRather than merging master into your branch could you rebase your branch on master, it will remove the unnecessary merge commits (you will have to git push --force-with-lease after doing this).\n. @imanuelcostigan sounds good, I agree a PAT solution is probably easier to implement and use. Thanks for working on this!\n. Devtools does not fail if packages are not installed so there is nothing to change.\n. R 3.3.0 uses gcc-4.9.3, but it looks like you only have gcc-4.6.3 installed. You need to download an updated Rtools33 from https://cran.r-project.org/bin/windows/Rtools/Rtools33.exe\n. This is missing the parameter name at https://github.com/hadley/devtools/pull/1177/files#diff-5edd38b303cb4b300beb72d1161397edR125 which is causing travis to fail https://travis-ci.org/hadley/devtools/jobs/128773783#L3741-L3745.\n. As of 39222f8cbbc82cdc719a48746bc6b912a45a58a5 install_github(\"hadley/dtplyr@ec0aaea\") now works on my machine regardless of the state of dplyr, installed from CRAN, dev version installed from GitHub or locally and not installed dtplyr is installed properly regardless.\n. @krlmlr The main issue with this currently is it queries the remotes twice, but getting rate limited seems to be less of an issue with the embedded PAT now.\n. @hadley if the small hack used in https://github.com/hadley/devtools/pull/1184/commits/7f54aaf4c9f2b31d498d096d98004d4a906b8fb5 (use of the installed environment to store state) is OK I can merge this, I verified it correctly handles the dplyr -> dtplyr issue in both directions.\n. > Does this also work for install_deps(\".\", dependencies = TRUE) for dplyr?\nYes, that seems to work fine on my machine\n. Looks like you forgot to put dtplyr back in Remotes: on that test https://github.com/krlmlr/dplyr/blob/4b2911fa657df1b0e4cf03ad2ca4b81c95df489b/DESCRIPTION\n. I feel like this is really a bug / shortcoming in R, in that you cannot install binary package on Windows once it is extracted.\n``` r\ndest <- download.packages(\"zoo\", tempdir(), type = \"win.binary\")[,2]\nunzip(dest, exdir = tempdir())\ninstall.packages(file.path(tempdir(), \"zoo\"), repos = NULL, type = 'source')\n> Installing package into 'C:/library'\n> (as 'lib' is unspecified)\n> Warning in install.packages :\n>   running command '\"C:/PROGRA~1/R/R-33~1.0/bin/x64/R\" CMD INSTALL -l \"C:\\library\" \"C:/pkg/temp/RtmpU7RZbU/zoo\"' had status 1\n> Warning in install.packages :\n>   installation of package 'C:/pkg/temp/RtmpU7RZbU/zoo' had non-zero exit status\n```\nNonetheless #1192 fixes your example and should fix the issue.\n. This should be ready to be reviewed now, seems to work well.\n. Is there anything in particular motivating the change? looks like for devtools the zip file is 604Kb, while the tar is 456K, so it seems worthwhile just for the the space/transmission savings.\nReading ?untar it looks like there are compatible implementations for Windows, which would be my other major concern.\n. Actually devtools runs tests in an environment with the package under tests namespace as a parent. load_all() is used just to generate this environment.\nSo we can set export_all = FALSE unconditionally and the internal functions are still able to be tested without dirting the users search path.\n1210 does this.\n. I think the idea behind load_all() is to have an interactive environment that mimics the environment your tests are run in.\nAn alternative workaround is to keep the expensive things in your helper, but surround it in \nr\nif (!interactive() || identical(Sys.getenv(\"NOT_CRAN\"), \"true\")) {\n...\n}\ndevtools only sets NOT_CRAN=true when running tests interactively, so this code will only be run by devtools::test() or during R CMD check, not when calling load_all().\n. Another option is to use devtools::dev_mode() and devtools::install(quick = TRUE), which should give you relatively quick library installs that don't interfere with your normally installed packages.\n. I think the logic needs to be tweaked to include capabilities(\"libcurl\") somewhere. Currently on my machine download_method_secure() # FALSE even though capabilities(\"libcurl\") #TRUE\n. GitHub returns a regular HTTP response in the first case, whereas in the second it returns a JSON response. Devtools is always expecting a JSON response, which is why you got the confusing error.\n1211 tries to parse the response as JSON, if it fails it treats the response content as a message which cleans up this issue.\n``` r\ndownload_github(tempfile(), \"https://api.github.com/repos/rstudio/rmarkdown/zipball/feature/html-vignette-readme\")\n> Error in stop(github_error(request)) : Not Found (404)\n``\n. The issue is packages installed before https://github.com/hadley/devtools/commit/463023920a73955874586ea2724231f3bef232fa are not going to have the protocol in their RemoteUrl. I just opened #1208 to fix this.\n. https://github.com/hadley/devtools/pull/1210/commits/612c9d5d61fb63759361e728acfcce3e1f2dc564 will now preserve the prior export status when runningtest().\n. LGTM merge away\n. And thanks for your patience and work Ian!\n. This was actually a false alarm\n. Ah you have yourself to blame for this one I think [devtools::git_extract_sha1()`](https://github.com/hadley/devtools/blob/master/R/git.R#L153-L175) is not working because it assumes a .zip file format rather than .tar.gz. (due to #1196).\nWe will have to see if there is a corresponding comment on the tarball.\n. From https://www.kernel.org/pub/software/scm/git/docs/git-archive.html\n\nAdditionally the commit ID is stored in a global extended pax header if the tar format is used; it can be extracted using git get-tar-commit-id\n\nDon't know if git2r has a similar command (I am guessing not).\n. This should be merged for the next release, which should be fairly soon, thank you everyone for the patience.\n@kleinschmidt If you need to use this sooner you can always install this PR directly\nr\ndevtools::install_github(\"hadley/devtools#1220\")\n. I was running into check errors when doing revdep_check() for packages with dependencies which are already loaded by devtools. For example digest was not being installed in the revdep_check library because the DESCRIPTION of the loaded namespace was being used instead of looking in the new library, where it was not yet installed. So checks were failing due to missing dependencies.\n. Yes anything that shows up when you run git status will trigger this (including untracked files).\nEither run git clean to remove them, add them to your .gitignore to ignore them or ignore this warning (as you did).\nThis behavior is needed if you forget to commit a new file for instance, so this is definitely working as intended.\n. Nevermind I think this was because of a password on my ssh key, running in RStudio did not popup the password dialog.\n. I agree this is a major limitation with the current implementation of install_svn() and that dropping this assumption is the right idea. \nNon-standard SVN layouts was part of the motivation for writing install_bioc(), although Bioconductor repositories also have additional requirements that would require a custom function even with this change.\n. We should just have a check in release() that fails if you have Remotes:. Keeping it in is going to generate a NOTE from R CMD check which CRAN will complain about.\n. @cboettig I just opened a PR that should address your issue (as long as you specify your repos appropriately)\n@eddelbuettel That vignette was written to explain the remotes feature of devtools, not as a general review of available CRAN alternatives. However if you would like drat to be mentioned in it I am sure we would be happy to merge a pull request with the change.\n. This should be fixed after https://github.com/hadley/devtools/commit/5cd2d80e5c8af68822c2c3a506053f413fbc7f56, let me know if this is not the case.\n. The patch has been merged to master, but people still run into it if they are using the CRAN release though (such as is the default on travis).\n. There is really no reason to use install_local() other than convenience. If you are trying to install a package from a folder use install() directly. If you are trying to install a package from a compressed file just use R CMD INSTALL.\n. You can avoid perl = TRUE with\nr\n\"github[^/:]*[/:]([^/]+)/(.*?)(?:\\\\.git)?$\"\nWhich also works in all your test cases.\n. Yes this is true, however on travis there is no need to install BiocInstaller manually. You can set\nyaml\nuse_bioc: true\nTo automatically install BiocInstaller, or set\nyaml\nr:\n  - bioc-devel\n  - bioc-release\nTo testing using the current Bioconductor devel and release branch (automatically implies use_bioc).\n. The argument is bioc_required: true, I was going off of memory (which is faulty, sorry).\n. I agree this is the best strategy. To save time you only really only need to check the packages which fail in some way in the first check, which should speed things up for the second round of checks.\n. The testthat PR needs to be merged and testthat needs to add testthat to Remotes:, or that PR needs to be added to Remotes to avoid breaking devtools.\n. This should probably be \"[[:space:]]*,[[:space:]]*\", tabs are valid in dcf files as well https://www.debian.org/doc/debian-policy/ch-controlfields.html\n. I think this looks like a nice improvement, thank you for working on it. We will take a closer look at it nearer to the next devtools release with some more comments.\nI apologize for the delayed response!\n. I think it would be better to test if pkgs is TRUE and update all packages if so (without prompting).\n. Thanks! Merged in aa5d4dabd7eca. It will likely be merged eventually next time we are doing devtools maintenance.\nIn the meantime you can add r_github_packages: hadley/devtools#1263 to your .travis.yml and it would use the code from that pull request to install dependencies.\n. The plan is to do major package development work in the next month or so. Thanks! Merged in a61d87fc995. Duncan had mentioned this in https://github.com/hadley/devtools/issues/1271 as well.\n. Could also use the information in git commits directly.\n`` r\nlibrary(git2r)\nr <- repository(\"~/p/devtools\")\nc <- commits(r)\nauthors <- lapply(c,slot, \"author\")\nnames <- vapply(authors,slot, character(1), \"name\")\nemails <- vapply(authors,slot`, character(1), \"email\")\ntime <- lapply(authors, function(x) as(x@when, \"POSIXct\"))\ntibble::data_frame(author = names, email = emails, time = time)\n> # A tibble: 2,623 x 3\n>           author                            email       time\n>              \n> 1     Jim Hester         james.f.hester@gmail.com \n> 2     Jim Hester         james.f.hester@gmail.com \n> 3     Jim Hester         james.f.hester@gmail.com \n> 4  Kirill M\u00fcller  krlmlr@users.noreply.github.com \n> 5     Roy Storey kiwiroy@users.noreply.github.com \n> 6         hadley              h.wickham@gmail.com \n> 7         hadley              h.wickham@gmail.com \n> 8         hadley              h.wickham@gmail.com \n> 9         hadley              h.wickham@gmail.com \n> 10        hadley              h.wickham@gmail.com \n> # ... with 2,613 more rows\n```\nOf course this only works well if people have their full names in their git config \ud83d\ude09 .\n. ``` r\n(get(\".Internal\", envir = baseenv(), mode = \"function\"))(getNamespaceRegistry())\nwith a call to\nutils::globalVariables(\"getNamespaceRegistry\")\n```\nAlso seems to avoid a NOTE without resorting to bquote/eval.\nI think this is a good suggestion, it would be very nice to be able to install devtools without needing RTools installed.\n. Yeah that is true, want me to add that to this PR or will you modify it after merging?\n. Seems to be working fine on windows, and I updated the README as well.\n. Appveyor was failing because of a devtools bug in the current release version, but USE_RTOOLS:true will be useful once #1283 is merged and devtools no longer has a src/ directory, so thanks!\n. Thanks! Merged in 72b1926131. Reproducible example\n. from ?install it mentions\n\nTo install a package in a non-default library, use \u2018with_libpaths\u2019.\n\nSo withr::with_libpaths(\"/tmp\", install_github(\"hadley/devtools\")) should do the trick.\n. This is really a roxygen issue, but @ symbols in roxygen need to be escaped by doubling them. So you need to use\n``` r\n' dbGetQuery(con, \"select @@@@version\")\n``\n. This is a known issue (#1246, #1265) and is fixed in the development version of devtools. Please install it withdevtools::install_github(\"hadley/devtools\")`.\n. Try restarting the R session after installing devel devtools.\nOn Aug 24, 2016 6:51 AM, \"charlottesirot\" notifications@github.com wrote:\n\nDear developers,\nI try to install my package (https://github.com/charlottesirot/elementR)\nfrom github on my win7 machine without success. I have the same issue than\ndgrtwo/widyr#3 https://github.com/dgrtwo/widyr/pull/3 and #1265\nhttps://github.com/hadley/devtools/issues/1265. So I tried with the new\nversion of devtools but it seems not to work:\n\ndevtools::install_github(\"hadley/devtools\", force = T)\nDownloading GitHub repo hadley/devtools@master\nfrom URL https://api.github.com/repos/hadley/devtools/zipball/master\nInstalling devtools\n\"C:/PROGRA~1/R/R-33~1.1/bin/i386/R\" --no-site-file --no-environ --no-save  \\\n  --no-restore --quiet CMD INSTALL  \\\n  \"C:/Users/cha/AppData/Local/Temp/RtmpQ9I7QI/devtools24053e462ea/hadley-devtools-e6ad9b5\"  \\\n  --library=\"C:/Users/cha/Documents/R/win-library/3.3\" --install-tests\n- installing source package 'devtools' ...\n  * R\n  * inst\n  * tests\n  * preparing package for lazy loading\n  * help\n  * installing help indices\n  * building package indices\n  * installing vignettes\n  ** testing if installed package can be loaded\n  * arch - i386\n  ** arch - x64\n- DONE (devtools)\n  Reloading installed devtools\ninstall_github('Rstudio/DT')\nDownloading GitHub repo Rstudio/DT@master\nfrom URL https://api.github.com/repos/Rstudio/DT/zipball/master\nInstalling DT\n\"C:/PROGRA~1/R/R-33~1.1/bin/i386/R\" --no-site-file --no-environ --no-save  \\\n--no-restore --quiet CMD INSTALL  \\\n\"C:/Users/cha/AppData/Local/Temp/RtmpQ9I7QI/devtools24027754908/rstudio-DT-25d879b\"  \\\n--library=\"C:/Users/cha/Documents/R/win-library/3.3\" --install-tests\n- installing source package 'DT' ...\n  * R\n  * inst\n  ** preparing package for lazy loading\n  Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :\n  there is no package called 'Rcpp'\n  ERROR: lazy loading failed for package 'DT'\n- removing 'C:/Users/cha/Documents/R/win-library/3.3/DT'\n  Error: Command failed (1)\ninstall_github('Rstudio/DT', dependencies = T)\nDownloading GitHub repo Rstudio/DT@master\nfrom URL https://api.github.com/repos/Rstudio/DT/zipball/master\nInstalling DT\n\"C:/PROGRA~1/R/R-33~1.1/bin/i386/R\" --no-site-file --no-environ --no-save  \\\n--no-restore --quiet CMD INSTALL  \\\n\"C:/Users/cha/AppData/Local/Temp/RtmpQ9I7QI/devtools240743c1947/rstudio-DT-25d879b\"  \\\n--library=\"C:/Users/cha/Documents/R/win-library/3.3\" --install-tests\n- installing source package 'DT' ...\n  * R\n  * inst\n  ** preparing package for lazy loading\n  Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :\n  there is no package called 'Rcpp'\n  ERROR: lazy loading failed for package 'DT'\n- removing 'C:/Users/cha/Documents/R/win-library/3.3/DT'\n  Error: Command failed (1)\nlibrary(devtools)\ninstall_github('Rstudio/DT', dependencies = T)\nDownloading GitHub repo Rstudio/DT@master\nfrom URL https://api.github.com/repos/Rstudio/DT/zipball/master\nInstalling DT\n\"C:/PROGRA~1/R/R-33~1.1/bin/i386/R\" --no-site-file --no-environ --no-save  \\\n--no-restore --quiet CMD INSTALL  \\\n\"C:/Users/cha/AppData/Local/Temp/RtmpQ9I7QI/devtools2403d75358c/rstudio-DT-25d879b\"  \\\n--library=\"C:/Users/cha/Documents/R/win-library/3.3\" --install-tests\n- installing source package 'DT' ...\n  * R\n  * inst\n  ** preparing package for lazy loading\n  Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :\n  there is no package called 'Rcpp'\n  ERROR: lazy loading failed for package 'DT'\n- removing 'C:/Users/cha/Documents/R/win-library/3.3/DT'\n  Error: Command failed (1)\n\nI don't understand why... Do I miss something ?\nSorry if this is a newbie question :S\nThank you very much in advance for your answer\ncha\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hadley/devtools/issues/1298, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAMh20miTMVt2QyL1nogSacTH8HgyYgbks5qjCJIgaJpZM4Jr4XI\n.\n. Shouldn't this PR just be https://github.com/hadley/devtools/pull/1301/commits/0d1554c97fea90ecfa1b78ba89e1356e41e9bc11?\n. Looks like testthat::test_file() and testthat::source_file() need to gain an encoding option (defaulting to \"unknown\") and devtools::test() needs to call testthat::test_dir(..., encoding = pkg$encoding %||% \"unknown\").\n\n@hansharhoff You seem to have a good grip on the problem and solution, do you want to try submitting pull requests to devtools and testthat with the above fixes? See https://github.com/hadley/devtools/blob/master/CONTRIBUTING.md#pull-requests for information on contributing to devtools.\n. IIRC the certificate warning is a false positive (reference), you need to accept the certificate (once permanently) in an interactive session. Otherwise you will get the message every time you interact with the Bioconductor SVN server.  Try running svn info https://hedgehog.fhcrc.org/bioconductor/branches/RELEASE_3_3/madman/Rpacks from the command line first, permanately accepting the Bioconductor certificate, then trying to install your package again.\nIt may also be worth posting at support.bioconductor.org about the certificate warning, maybe they could change something so the certificate would be trusted without the manual intervention.\n. org.Hs.eg.db is a Bioconductor data package, not a software package.\nDevtools only supports installing software packages with install_bioc and\nremotes.\nIt should work if you have a BiocViews entry in your DESCRIPTION and put\norg.Hs.eg.db as a regular dependency (Depends, Imports, or Suggests)\nOn Aug 29, 2016 12:14 PM, \"Ewy Mathe\" notifications@github.com wrote:\n\nI have played around with this a bit more and am still perplexed, thinking\nit is something with the install_github() function.\nSpecifically, I have set the repositories and am able to successfully\ninstall \"org.Hs.eg.db\" with install.packages():\n\nmyrepos=biocinstallRepos()\ninstall.packages(\"org.Hs.eg.db\",repos=myrepos)\ninstalling the source package \u2018org.Hs.eg.db\u2019\n\ntrying URL 'https://bioconductor.org/packages/3.3/data/annotation/src/contrib/org.Hs.eg.db_3.3.0.tar.gz'\nContent type 'application/x-gzip' length 69122902 bytes (65.9 MB)\n====^C==\ndownloaded 65.9 MB\nSo I know my repos will grab the package. However, if I try to install\nwith install_github() while passing the repos, it still cannot find the\npackage:\n\nlibrary(devtools)\ninstall_github(\"ewymathe/testALTREinstall\",repos=myrepos)\nDownloading GitHub repo ewymathe/testALTREinstall@master\nfrom URL https://api.github.com/repos/ewymathe/testALTREinstall/zipball/master\nInstalling ALTRE\n'/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file --no-environ  \\\n  --no-save --no-restore --quiet CMD INSTALL  \\\n  '/private/var/folders/j4/m74j380917j4njwrrvf2fh480000gn/T/Rtmp3VEYyF/devtools762b528dbac0/ewymathe-testALTREinstall-000280d'  \\\n  --library='/Library/Frameworks/R.framework/Versions/3.3/Resources/library'  \\\n  --install-tests\n\nERROR: dependency \u2018org.Hs.eg.db\u2019 is not available for package \u2018ALTRE\u2019\n- removing \u2018/Library/Frameworks/R.framework/Versions/3.3/Resources/library/ALTRE\u2019\n  Installation failed: Command failed (1)\nAny idea what is happening?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hadley/devtools/issues/1307#issuecomment-243172311,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAMh22FW6odalBVkB-3xR271_rOTHuk5ks5qkwVggaJpZM4Jtf-T\n.\n. Gabor has https://github.com/MangoTheCat/remotes as a simpler option to devtools, unfortuately he started working on it right before I made a number of changes to devtools remote handling, which is why we have not switched the devtools code to use it.\n\nI assume you are using linux, so have to recompile all of the dependencies, which is why they are taking so long to install. RSQLite only has 105 dependencies, so it should not be so onerous. This process really works best on OS X as you can download the CRAN binaries and run them in parallel. Hadley can install (and run) the (~800 or so) ggplot2 dependencies in a few hours.\n. Biggest things were the changes in https://github.com/hadley/devtools/pull/1067, but it also doesn't have support for bioc remotes (https://github.com/hadley/devtools/pull/1194) and a number of other smaller things, basically any devtools changes from January on.\nI still think splitting it out into a new package is a good idea and remotes is a great start, but it not an entirely trivial update.\n. From\nhttps://cran.r-project.org/doc/manuals/r-release/R-exts.html#Package-subdirectories\nR source files must start with upper or lower case ASCII letters or digits.\n. @melindahiggins2000 That behavior will only happen when installing the package with install_github(), if downloaded from CRAN the package will have a Date/Publication field that is used.\n``` r\ncitation(\"tidyr\")\n>\n> To cite package 'tidyr' in publications use:\n>\n>   Hadley Wickham (2016). tidyr: Easily Tidy Data with spread()\n>   and gather() Functions. R package version 0.6.0.\n>   https://CRAN.R-project.org/package=tidyr\n>\n> A BibTeX entry for LaTeX users is\n>\n>   @Manual{,\n>     title = {tidyr: Easily Tidy Data with spread() and gather() Functions},\n>     author = {Hadley Wickham},\n>     year = {2016},\n>     note = {R package version 0.6.0},\n>     url = {https://CRAN.R-project.org/package=tidyr},\n>   }\n```\nwe could add this same field to the package description when we install it from GitHub, which would fix the behavior you describe.\n. You should be able to add ^docs/ to your .Rbuildignore file, and it won't be included in the built package.\n. I think it is just as valid to store the website indocs/` as in a gh-pages branch.\n. > Maybe the question is: when pkgType is set to \"both\", why does it try installing source packages when a binary is available?\nThis is a good question, I am not sure of the answer but it is clearly not working as intended.. @hadley may disagree, but I would prefer keeping this in Suggests:, while it is self-contained it still requires compilation and will be unused functionality for the vast majority of builds on the CIs, where we are trying to lighten the devtools dependency load.\n. Thanks! Merged in 3af9ccab. I saw the same issue and fix it in #1339 as well.\n. FWIW this is the same as https://github.com/hadley/devtools/issues/1401 which also talks about why it occurs and how to fix the issue.. All of these are fixed in the devel version of the 1.13.0 branch, you can install it with\nr\ndevtools::install_github(\"hadley/devtools@1.13.0\"). @plantarum The failure with R-devel is an unrelated issue, you can safely ignore it.\n. Thanks! Merged in 3dbef06d6c7. @lnalborczyk Also note devtools includes devtools::use_mit_license(), which will set this up for you, so you don't need to do it manually.\n. Yeah with https://github.com/hadley/devtools/commit/f0d1c7ed3d7f30d559b62eb0060135589824c687\n. The warning is saying it needs a dependency on R 2.10, not 2.1.\nAlso devtools is really not the proper place for this issue (or your previous one #1357).\nProblems generated from R CMD check should probabably go to the R-package-devel mailing list.\n. Thanks!\nMerged by hand at https://github.com/hadley/devtools/commit/95a1ad66ac58ce554413334d31a239aed7ceb22d, so closing this PR.. This is IMHO a bug in R, from ?detach it states\n\nregistered S3 methods from the  namespace will not be removed.\n\nSo the S3 methods remain even if a given namespace is removed. Therefore there is not much you can do in this case but to not attach gam and car in the same session.\n. This is a known issue with the current CRAN version see #1246, #1343 and should be fixed in the development version. You can install it on windows with\n``` R\nlibrary(devtools)\nbuild_github_devtools()\nRestart R before continuing\ninstall.packages(\"devtools.zip\", repos = NULL, type = \"source\")\nRemove the package after installation\nunlink(\"devtools.zip\")\n``\n. I merged this manually at https://github.com/hadley/devtools/commit/9a24447aad6ffe45c7143759ef510b0161c3c230, incoporating Hadley's comments.. @ReportMort You don't need to resubmit, if you push more commits to the same branch the PR was on they will be added to the existing PR.\n. Thanks! Merged in 2636e2a4. Nevermind this is #1244, I am terrible :(\n.devtools::use_rcpp()` will set things up for you and tell you exactly what to include.\nYou just need to make a new .R file in the R/ directory with only the following.\n``` r\n' @useDynLib pkgName\n' @importFrom Rcpp sourceCpp\nNULL\n``\n. I don't think this is going to happen, installing dependencies andload_all()` are really different fundamentally. However if you want this you can write a function to do this yourself!\nr\nmy_load_all <- function(pkg = \".\", ...) {\n  devtools::install_deps(pkg)\n  load_all(...)\n}\n. Steps to reproduce\n1. install a local package with devtools::install().\n2. Move (or remove the package) on the filesystem.\n3. Try to run devtools::update_packages().\n. @clesiemo3 Actually reading your post it looks like you did what I just suggested, apparently need to investigate this a little further.\n. It is working now, but the check is failing because suggested packages are not available for that version of R\n. Seems transient, fixed without changes in devtools.. Done (https://github.com/r-lib/pkgload/commit/51fa0f0ed80a2017d1e6e7da9a11e8ba66aee372)\nClosing this PR, as it is no longer needed here.. The short answer is there is not a builder for Solaris. You can try to use a VM ala https://gist.github.com/jeroenooms/4c61c821172ad640545d, but it is not trivial to reproduce CRANs build environment.. Listing branches available could be useful, but belongs in a separate function rather than output by install_github(), which arguably produces too much output as it is. \nThe remaining information has no standard location or definition and often the package authors do not know the answers themselves, so don't see how it would be possible for devtools to provide.. I think what is going on is the ssh-agent is prompting for a password, but there is no tty to receive one. Try cloning or fetching from a github repository on the command line, input your password when prompted and it should then be cached.\n. Thanks! Merged in 15b5410c. shell\nsvn info --username readonly --password readonly https://hedgehog.fhcrc.org/bioconductor/branches/RELEASE_3_4/madman/Rpacks \nshould allow you to accept the certificate.\n@mtmorgan Do you know of anything we can do to remedy this? I get the prompt (and error) just using the command line tools on a fresh install (or by moving ~/.subversion), so this is not just an R or devtools issue.. I think the SVN certificate it is still messed up on your machine actually, can you try the following in a shell.\n```shell\nmv ~/.subversion{,.bak}\nsvn info --username readonly --password readonly https://hedgehog.fhcrc.org/bioconductor/branches/RELEASE_3_4/madman/Rpacks\naccept it permanetly\n/usr/bin/svn co --username readonly --password readonly https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/MeasurementError.cor /tmp/test\n``\nThen verify that/tmp/test` contains the checked out version of that package. If that works successfully than the test should also work.. Hmm, works ok for me, does making this change fix it for you?\n```diff\ndiff --git a/tests/testthat/test-bioconductor.r b/tests/testthat/test-bioconductor.r\nindex c497e08..862c5fb 100644\n--- a/tests/testthat/test-bioconductor.r\n+++ b/tests/testthat/test-bioconductor.r\n@@ -38,6 +38,6 @@ test_that(\"install_bioc\", {\n   # This package has no dependencies or compiled code and is old\n   install_bioc(\"MeasurementError.cor\", quiet = TRUE)\n\nexpect_silent(packageDescription(\"MeasurementError.cor\"))\nexpect_equal(packageDescription(\"MeasurementError.cor\")$RemoteType, \"bioc\")\nexpect_silent(desc <- packageDescription(\"MeasurementError.cor\", lib.loc = .libPaths()))\nexpect_equal(desc$RemoteType, \"bioc\")\n })\n``. No I use a personal library as well~/Library/R/3.3/library.libPaths()is just to the temporary directory is so that the bioconductor installation is completely isolated, so using the old libpaths as well seems wrong. Do you still get the same results usingR --vanilla -e 'devtools::test()'`?. @mtmorgan After looking into this a little more you are correct, the SVN client bundled with MacOS doesn't include any CA bundles. MacOS does come with CA bundles, but they are part of the keychain. http://superuser.com/questions/903263/what-does-subversion-use-for-its-ca-list has some options for using the bundled command line SVN.\n\nAlternatively if one is using SVN from homebrew it is linked to openssl. Openssl is also doesn't have the appropriate CA bundle by default, but you can export it from the keychain (as a .pem)\n\nAdd it to /usr/local/etc/openssl/certs and run /usr/local/opt/openssl/bin/c_rehash.\nThis will then prompt you to use the certificate bundle when trying to connect to hedgehog and authenticate it appropriately.\nWhich is a long winded way of saying this is really a shortcoming of the svn clients for OS X and the CA bundle setup, not a bioconductor issue and the easiest option for users on OS X is to do as suggested, run a svn command against the bioconductor servers and permanently accept the certificate.. Yes @kiwiroy, devtools::test() uses devtools::load_all(), which breaks citation(). The tests should work fine with devtools::check() which runs R CMD check and does not use load_all().. Should be fixed by https://github.com/hadley/devtools/commit/1ce84b04568ff7846c3da754f28e7e22a23c8737.\nThank you for the good reprex, it was pretty easy to track down the issue looking at the devtools changes in respect to remotes.. See ?devtools::revdep_check, ?devtools::revdep_check_save_summary etc. . Thanks! Merged in a5ad54c4290d6. Not every Unicode code point can be represented in every Windows locale, so while this may work on your local locale, it won't work on every locale. You can potentially use UTF-8 characters in the comments, but if you want your package to be portable the code needs to be only ASCII.\nRegardless of whether it will work or not having non-ASCII characters in your code will generate a NOTE from R CMD check, and would need to be changed before the package could be on CRAN.\nThe root of all of these problems is not devtools, or roxygen, it is R and specifically how R handles Unicode on Windows. There is nothing we can do to change this in these packages.. rgl is using the devtools Remote: feature to install a remote dependency using SVN, https://github.com/rforge/rgl/blob/master/pkg/rgl/DESCRIPTION#L20, which does need SVN to be installed.\nHowever there does still seem to be a bug here, I get the following (with svn installed)\n```r\ndevtools::install_github(\"rforge/rgl/pkg/rgl\")\n> Downloading GitHub repo rforge/rgl@master\n> from URL https://api.github.com/repos/rforge/rgl/zipball/master\n> Installing rgl\n> svn: warning: W160013: File not found: revision 1528, path '/pkg/rglwidget/trunk/DESCRIPTION'\n> svn: E200009: Could not cat all targets because some targets don't exist\n> svn: E200009: Illegal target for the requested operation\n> Error: There was a problem retrieving the current SVN revision\n``. This should be fixed after https://github.com/hadley/devtools/pull/1424, based on the PR G\u00e1bor mentioned..R CMD check` has roughly 1 Billion options.\n```r\ncyclocomp::cyclocomp(tools:::.check_packages)\n> [1] 1207\n```\nSome options take a long time to run, which we turn off, but some which only work on certain platforms.\nI think rcmdcheck does a better job of mimicking CRAN settings, so this should improve soon!. The issue is devtools::release() calls devtools::check() with the default argument document = TRUE. You can run the check manually then run devtools::release() without the check.\nr\ndevtools::check(document = FALSE)\ndevtools::release(check = FALSE). Turns out these comments were actually already removed in the devel version (https://github.com/hadley/devtools/commit/28135778556493f90d9c8dde72e8a764964fc806), but still this PR is nice to remove the comments from the test files.. I don't think I would call it a bug, install.libs.R is a pretty esoteric convention, it looks like only around 20 packages use it in all of CRAN.\nWe might accept a PR adding support assuming it could be done with a minimum of extra code.... This seems correct, perhaps git@bitbucket.org:dannavarro/lsr-package.git would be a better example, as bitbucket does support git archive --remote. This looks OK, but your test needs to be tweaked, you just need to escape the special characters in the regex (https://travis-ci.org/hadley/devtools/jobs/195934346#L895-L896). You can safely ignore the Appveyor failures they are unrelated to this change.. I merged this manually at https://github.com/hadley/devtools/commit/0128ed8ef52e81fcea270bf1b8e2ba40cf95db2c. Thanks for the PR and for your patience!. Did you try running\nshell\nR CMD build .\nR CMD check datpkg*tar.gz\nI think you will observe the same behavior. Unfortunately the way R CMD build works is it copies the full package directory, then deletes excluded files, so I don't think there is any way to avoid doing what you are currently doing.\nYou could probably put those steps in a Makefile (or write an R function) to make them less painful to do, but I think that is all I can offer \ud83d\ude26 .. What devtools function in particular are you talking about? install() has a reload argument which can be set to FALSE to avoid attempting to reload the package. . I cannot reproduce this, can you supply your devtools::session_info() and the full output (including traceback) after setting options(error = function() traceback(3)). See https://github.com/RcppCore/Rcpp/issues/636, eventually Rcpp will generate this automatically for you, without any changes to devtools.. The proper way to do this is to use word boundary anchors around the package name.\n``` r\nre <- \"\\btest\\b\"\ngrepl(re, \"test\")\n> [1] TRUE\ngrepl(re, \"ttest\")\n> [1] FALSE\ngrepl(re, \"testt\")\n> [1] FALSE\ngrepl(re, \" test\")\n> [1] TRUE\ngrepl(re, \" test \")\n> [1] TRUE\ngrepl(re, \" test, \")\n> [1] TRUE\n```. Thanks! Merged in f7d4c020. I am pretty sure this issue is only tangentially related to devtools code, the error is coming from the internal unzip code. \nhttps://github.com/wch/r-source/blob/780021752eb83a71e2198019acf069ba8741103b/src/main/dounzip.c#L177\nPossible causes could be \n- lack of write permissions in tempdir() or one of the children for the user R is running under\n- tempdir() or one of the child directories being removed. This could be done automatically by certain windows options.. Just keep the # Generated by roxygen2: do not edit by hand line at the top then.. You should be use helper scripts to do this, which are sourced by devtools::test(). Simply rename your utils.R file to helper-utils.R and place it in testthat/ and this will work as you intend.. This is the way that this has always worked, it is very unlikely to change. If you want custom logic to be run both during R CMD check and interactively with devtools::test() you need to put it in a helper script.. Yes that is right. This could actually be useful functionality. Some packages may never go on CRAN but still have GitHub releases. The situation is rare enough I don't think it is worth including in install_github() unless more people are looking for it. If you do think this is worthwhile, you would need to open an issue in remotes.. load_all() never installs package dependencies regardless of source, you need to use devtools::install_deps() to install dependencies for development packages.. The error message says the issue\n\n\u2018BiocInstaller\u2019 must be installed for this functionality.\n\nyou need to run the install directions at https://bioconductor.org/install/ once to install the BiocInstaller package. Once it is installed devtools will use it for all further installations.. We have a helper in devtools to check for suggested packages. This can be just\ncheck_suggested(\"hunspell\"). Thanks! Merged in c7a71dba9. libgit2 does not natively support git lfs. Supporting this would likely require changes in the R libgit2 bindings so while possible I don't think it is likely to happen. I would suggest writing a function that calls the command line git client to clone the repository locally, then use devtools::install() to install it.. Yeah @gaborcsardi is correct, this has to do with how the packages were installed, if using install.packages() it won't have the RemoteTypes field and be capital CRAN, if installed by install_cran() or as a dependency in a devtools installation it will.. agreed.. Devtools expects a valid DESCRIPTION file, I think you will have to generate it at least once outside the build process in order to use devtools.. You have committed object files in your src/ directory, use devtools::clean_dll() to remove them and I would suggest adding a .gitignore file with something like https://www.gitignore.io/api/c in your src/ directory to avoid this in the future.\nWith the object files removed devtools::check() builds and checks the epicR package successfully.. I would find this useful as well, but I don't think we can assume users are using git when they run build, or that all changes have been committed to the repo. I think this is best done as a wrapper function build_clean()? that does a shallow clone into a temporary directory and then calls build() as normal.. You can get this behavior by calling devtools::install_cran(), which will only install packages from CRAN if they are a newer version than the currently installed version.. Thanks for the report JJ, I believe this is a known issue, see https://github.com/hadley/devtools/issues/1370#issuecomment-273570049 for some discussion of the cause. We should have a fix for this in the near future.. Yep you are right, I made the change. ssh is probably trying to prompt for your credentials, try using ssh-agent to cache them.. This is an regression in R actually and was fixed in R-patched available at (https://stat.ethz.ch/R/daily/), see also the R-patched release notes.\n\nfile.mtime() no longer returns NA on Windows when the file or directory is being used by another process.. Thanks! Merged in 68d23434e534. This is now fixed in the 1.13.0 branch (https://github.com/hadley/devtools/tree/1.13.0), you can install it with devtools::install_github(\"hadley/devtools@1.13.0\"). Yes it is, https://github.com/hadley/devtools/blob/c071299c7014d01a846052bf1a05087c0726be5c/R/install-bitbucket.r#L29, you need to restart your R session.. The short term solution is to install devel testthat, this functionality inadvertently depends on changes in testthat that are not yet released to CRAN.\n\nr\ndevtools::install_github(\"hadley/testthat\"). Not sure, I would check your %PATH%, it looks like there is more than one version of tar on it?. Duplicate of https://github.com/hadley/devtools/issues/1502. I just added a GitHub release https://github.com/hadley/devtools/releases/tag/v1.13.1 and bumped the master version to 1.13.1.9000. We already do assignments .onLoad in devtools / pkgload https://github.com/r-pkgs/pkgload/blob/master/R/aaa.r, https://github.com/r-pkgs/pkgload/blob/master/R/zzz.r anyway, pretty sure we can just do onload_assign(\"trimws\", backports::trimws) anywhere in R\\ files and it should work how you intend.\nAlthough this code has been moved to pkgload, so I guess will not work here anymore.... I actually do not want to use backports for this, the implementation is not the same as the R version. \nIt uses gsub rather than sub and [[:space:]] rather than [ \\t\\r\\\\n], we should just define our own version with the base R definition.. I am pretty sure devtools >= 1.13.1 now works with R 3.1. Yes that makes sense. \nA simple fix could be\n```diff\ndiff --git a/R/install-remote.R b/R/install-remote.R\nindex c55981a..42ede9c 100644\n--- a/R/install-remote.R\n+++ b/R/install-remote.R\n@@ -149,7 +149,7 @@ remote_sha <- function(remote, ...) UseMethod(\"remote_sha\")\npackage2remote <- function(name, repos = getOption(\"repos\"), type = getOption(\"pkgType\")) {\n\nx <- tryCatch(packageDescription(name, lib.loc = .libPaths()), error = function(e) NA, warning = function(e) NA)\nx <- tryCatch(packageDescription(name, lib.loc = .libPaths()[[1]]), error = function(e) NA, warning = function(e) NA)\n\n# will be NA if not installed\n   if (identical(x, NA)) {\n```\nMy only question is if there is any case R will not install to the first directory in .libPaths(). I believe not, install.packages() fails if the library is not writable.... I have actually changed my mind about this, I don't think only looking at the first library is appropriate in many cases. If you want this behavior I would wrap your installation command in something like this instead to temporarily set libPaths as desired.\nr\nwithr::with_libpaths(.libPaths()[[1]], {\n  install_xyz()\n}). They should be integrated, but if it doesn't work I will add the token manually. Thanks! \nI merged this manually (https://github.com/hadley/devtools/commit/668a580f8c0b068df960863f8ee3b25b42b37f050) so GitHub did not close this PR automatically.. This should probably go in https://github.com/r-pkgs/usethis, which is where the use_*() functions are migrating to.. It already implicitly calls document when it runs the package check, because the default is document = TRUE. It is true this is after the Git checks.. This is actually a feature, if your package is using Remotes it is depending on development packages which aren't going to be available on CRAN. devtools::release() warns about this as well as R CMD check, both of which should be used before submitting to CRAN. See http://r-pkgs.had.co.nz/release.html#release-check for some suggestions on the process you should use to catch this type of error before it is submitted to CRAN. This is a bug in the pandoc version that CRAN is using, in particular the pandoc dependency tls https://github.com/vincenthz/hs-tls/issues/152. It is not an error in shields.io, but a bug in validating the (actually valid) ssl certificate from shields.io.\nYou can work around the issue by using the badge from codecov.io, which uses a different encryption method that does not uncover this bug, as you mentioned.. We could add a shim for library.dynam(). We have one for library.dynam.unload() but not for library.dynam() https://github.com/r-lib/pkgload/blob/793c8245dac9c6b260470a160b53c87364a786f0/R/shims.r#L102. The build log doesn't provide any clues unfortunately, but this may be due to you running R CMD javareconf on MacOS, try removing that and see if the build passes.. Try just using a install block for those dependencies explicitly and remove devtools out of the equation entirely.\nyaml\ninstall: \n  - R -e 'install.packages(c(\"rJava\", \"xlsxjars\"))'. The message is coming from utils::person(), not from devtools. You can read the documentation for more details (?person), but the short answer is you need to include the middle name in the given field.\n``` r\nperson(\"Joshua\", \"M.\", \"Rosenberg\")\n> It is recommended to use 'given' instead of 'middle'.\n> [1] \"Joshua Rosenberg M.\"\nperson(c(\"Joshua\", \"M.\"), \"Rosenberg\")\n> [1] \"Joshua M. Rosenberg\"\n``. Yourdevtools.desc.author(authors@R) string is not correct, it should be actual calls toperson()`\ni.e.\nr\noptions(devtools.desc.author = 'person(\"Jim\", \"Hester\", email = \"james.f.hester@gmail.com\", role = c(\"aut\", \"cre\"))'. You can pass a subdirectory as part of the repo name.\nr\ndevtools::install_github(\"user/pkg/subdir\"). looks like the original issue looks like https://github.com/hadley/devtools/issues/540, but that still doesn't address just using the internal unzip unconditionally. From ?unzip\n\nThe default internal method is a minimal implementation,\n     principally designed for Windows' users to be able to unpack\n     Windows binary packages without external software.  It does not\n     (for example) support Unicode filenames as introduced in \u2018zip\n     3.0\u2019: for that use \u2018unzip = \"unzip\"\u2019 with \u2018unzip 6.00\u2019 or later.\n     It does have some support for \u2018bzip2\u2019 compression and > 2GB zip\n     files (but not >= 4GB files pre-compression contained in a zip\n     file: like many builds of \u2018unzip\u2019 it may truncate these, in R's\n     case with a warning if possible).\n\nThe no-unicode filenames could be an issue, the size limitations probably not for this use-case.. Good news!\nThe warnings you show can be ignored, and devtools should have been installed, so there is nothing else you need to do, just start using devtools.. Maybe, that would save busy work importing and exporting, although the downside is you would lose auto-completion with devtools::use_<tab> right?. Yeah I am fine moving it to Depends.. Ok switch to using Depends. I guess one more issue with this is that code which previously used devtools::use_xyz() will no longer work, which may break some things.. Looks like there are 68 usages on CRAN package with devtools::use_*(). We can do like we did with the with_ functions (https://github.com/hadley/devtools/blob/master/R/with.r#L1-L8).\nWe could probably remove them completely now as well, they have been deprecated for a while at this point.. I added deprecation messages to all the use_ functions and forwarded their arguments to the usethis equivalents.\nuse_data() broke using this approach because it uses basic NSE, so I simply aliased the function rather than using a wrapper. We don't have a deprecation message then, but I don't think there is a way to fix the problem short of using rlang / tidyeval.. Eventually yes, but if we put usethis in Depends in this PR we get masked warnings about all the use_ functions.\n```\nThe following objects are masked from \u2018package:usethis\u2019:\nuse_appveyor, use_build_ignore, use_code_of_conduct, use_coverage, use_cran_\n\nbadge, use_cran_comments, use_data, use_data_raw, use_dev_version, use_git,\n    use_git_hook, use_github, use_github_links, use_gpl3_license, use_mit_licens\ne, use_news_md, use_package, use_package_doc, use_rcpp, use_readme_md,\n    use_readme_rmd, use_revdep, use_rstudio, use_test, use_testthat, use_travis,\n use_vignette\n```\nOnce we remove the deprecated functions fully we can just put usethis in Depends.. TIL about .conflicts.OK, sure we can do that.. Failing on 3.0 due to pkgbuild and pkgload. pkgbuild is failing becuase desc is not available (https://github.com/r-lib/desc/blob/master/DESCRIPTION#L15). pkgload is failing because it depends on pkgbuild and rlang (https://travis-ci.org/hadley/devtools/jobs/260342442#L1473-L1477). \nhttps://github.com/tidyverse/rlang/issues/143. build_github_devtools() is no longer needed, if you want to update devtools to the latest CRAN release just use update.packages(\"devtools\") or install.packages(\"devtools\").\nIt looks to me like having R installed on a NFS is causing problems, are you able to install other packages successfully?. Try running the code in a R terminal outside of RStudio.\nAlso you can check the RStudio error logs to see if there is a useful error message there. They are stored by default in ~/.rstudio-desktop/log if you are using RStudio Desktop on linux.. This is a good idea!\nI don't there is a way to map Rd output back to the roxygen comment, as the relationship is not one to one.\nHowever an alternative would be modifying devtools::spell_check() to search roxygen comment lines (#') in .R files as well / in place of .Rd. This is generally more useful anyway because it tells you what needs to be edited. Probably the easiest way to do this is to use a regex that blanks out non-roxygen comment lines, then run the spell check function on those files.\nrstudioapi::sourceMarkers() is the function that can be called to add markers to the marker pane.. No, it is that way by design, we try to keep the number of \"hard\" dependencies relatively low for devtools. The spelling package is only required for the spell_check() function, so it is not installed by default.\nWe could add a call to check_suggested(\"spelling\") to spell_check() however, which would give you a more useful error message, and prompt to install the package if it is not installed.. The system() call in question is trying to run R CMD config CC. I would imagine there is an issue with your %PATH% variable and R is not on it.. ceiling has been an argument in git2r since version 0.12.1. What version of git2r do you have installed?\nr\nutils::packageVersion(\"git2r\")\nIt seems the dependency version needs to be bumped in devtools.. Sure!. Should the saving be configurable with an option? Or is there one set in the IDE we could query?. Closed by https://github.com/hadley/devtools/commit/5517fdb9f4b655eaeffdc7e371db42cddcc679e4, https://github.com/hadley/devtools/commit/ebe4cbfc65f8c2fe50a00c9cfe00571b78d29e90. @hadley was saying to build vignettes with the install_*() functions by default. So that calling devtools::install_github(\"repo/xyz\") will build them by default.\nNow that remotes has support for building packages this should be a matter of calling the remotes functions with remotes::install_github(..., build = TRUE, build_opts = c(\"--no-resave-data\", \"--no-manual\") (removing the --no-build-vignettes) option which is the default.\nI am somewhat undecided if this is worth doing now, it will make maintenance more of a burden.. Thanks!\nI merged this manually with https://github.com/hadley/devtools/commit/e215ebf00164ceafba385164c90d17603f842ddd.\nYou may want to add the email used in the commits schneidernw <Neil.Schneider@crowehorwath.com> as one of the emails associated with your GitHub username, so they are properly linked on GitHub.. An alternative approach that avoids most of the parsing is to take the misspelled words found with the Rd files and search for them in the roxygen comments of the files.\nI have a working example of this, but doing it efficiently would require a little more thought. It would be easier if hunspell would return the location of misspelled words, rather than only the line.. This should close https://github.com/hadley/devtools/issues/1577, https://github.com/hadley/devtools/issues/1576 once it is merged.. The easy solution is as you noted to just run document() twice.\nHaving to run document() twice ends up being fairly common when you make changes that affect the NAMESPACE.. Also FWIW the only reason that roxygen2::roxygenize() seems to 'work' in the example package is because calling roxygenize() implicitly loads the roxygen2 namespace. i.e. it will only work with generics defined in roxygen2 itself. Modify your example to define a method for remote_sha, a generic defined in devtools, run roxygen2::roxygenize() and you will see the same behavior as document().. I am not sure of the cause of this, but it would be useful to know if it occurs only with the CRAN version of devtools, or with the development version. Also if does this crash occur when developing any package or only specific packages?. We would need more information to determine the case, particularly what package you are trying to develop.. We actually just made a very similar change in pkgload (including adding quoting of package names) https://github.com/r-lib/pkgload/pull/54. I think we should export check_dep_version() in pkgload and possibly import and re-export it in devtools.\nThank you for the PR!. Other use of sQuote() was by me I am afraid, clearly I was not following the style guide. Sorry for the confusion, will update those as well!. Sorry I cannot replicate this behavior with either the currently released devtools or devel devtools in the rocker/rstudio docker container. Can you post a reproducible example with the exact commands you are trying to run?. Ok I can replicate it now, thank you for the exposition.\nThis is a bug in the IDE, not with devtools, it basically boils down to this in the IDE, which should probably be returning true unless there is something wrong with the build toolchain in the rocker containers.\n```r\n.Call(\"rs_canBuildCpp\")\n> [1] FALSE\n```. I notified the authorities about it, should have at least a diagnosis in the not too distant future. Make sure you are using fully upgraded versions of the packages.\nr\ndevtools::install_github(\"hadley/devtools\")\nShould upgrade all of them for you automatically.\nThe documentSaveAll() looks like it needs IDE version 1.1.287 or later to work. We will need to add code to devtools which checks that these functions are available.. If you are seeing different behavior in the IDE and in the console the only possibilities are a stale version in your session (which restarting the entire IDE should fix) or different .libPaths() picking up an old version of devtools.. Was able to reproduce this. The IDE calls devtools::check() with a check_dir argument (https://github.com/rstudio/rstudio/blob/ff4ec56122a07058aafa04d6f80b2d1225e037c9/src/cpp/session/modules/build/SessionBuild.cpp#L937), but doesn't show that in it's output.. We will need to keep check_dir for the time being, even if we just swallow the input. Or modify rcmdcheck to accept a check_dir argument.. usethis::use_pipe() may make you happy :smile:, and yeah this should have been in usethis. In the install_github() case you can specify any treeish object e.g. install_github(\"hadley/devtools@branchname\") or install_github(\"hadley/devtools@sha123abc\").\nFor install_git() you can install from branches or tags, this is unlikely to change in the near term.. Ok I added a timeout and a tryCatch(). I set the timeout for 5 seconds, not sure what you had in mind or if this should be user configurable with a global option.... I cleaned up the conditional and it now checks for the argument name (or being the first argument) before trying the completion.\nIt also completes on any part of the repo name, not just the prefix like before.\n\n. I am not really sure why the code it written as it is, having 'R-release' first in the default argument does make it seem like it would default to 'R-release', but it does default to R-devel\nhttps://github.com/hadley/devtools/blob/a0c8d7333be185f979a60823dcfad66c9f3ea35e/R/build-win.r#L23-L24\nAnyway, I agree having separate functions makes sense to me.. You should just commit the NAMESPACE file, not doing so makes it more difficult for others to install your package without any real material gain.. This behavior is fixed in usethis, which is what devtools will be using for this function in the future.\nIn the meantime I would suggest renaming your LICENSE file to LICENSE.md and adding it to .Rbuildignore, so it is not included in the built package. This will allow you to continue to have the license file in your source repository but not be against the CRAN guidelines.. You need to use the devel version of callr, which should have been installed when you ran install_github(\"hadley/devtools\"), but perhaps there was an issue during the install. You can run the following to install devel callr without devtools, and then reinstall devel devtools.\nr\nsource(\"https://install-github.me/r-lib/callr\")\nsource(\"https://install-github.me/hadley/devtools\"). This should be fixed by https://github.com/hadley/devtools/commit/c9ca63a21586e537a2fcb1ed44ba38159da55e7e. I am pretty sure it is caused by callr being moved to r-lib.. This was a bug caused by moving functions to pkgload that used to exist in devtools and should now be fixed in the devel version as well.. This was a bug caused by moving functions to pkgload that used to exist in devtools and should now be fixed.. No, CRAN does not keep binaries of old versions, only the latest one.. Thanks! I ended up doing this in https://github.com/hadley/devtools/commit/49bf36139525796d6aa846dd4449e6adf690c4b1. Please try running R CMD check from the terminal / command line and see if the error is reproduced there. devtools::check() is just a thin wrapper around R CMD check. \nIf you can provide an example package that exhibits this behavior we can try to help further. This is very likely an issue with your package or your local libraries rather than a devtools issue.. A simple package with those dependencies works fine on my machine. Please make sure you have updated all your packages to the latest versions, this seems like a library corruption issue to me.\nr\nupdate.packages(ask = FALSE, checkBuilt = TRUE). Yes this is already done in usethis, which is where the devtools use_ functions have gone and what devtools will be using in the future.. As mentioned in #1514 this stems from bug(s) in R which should be fixed in R-devel.. If possible a workaround is to install R and Rtools into directory paths without spaces.. In particular use the RemoteSha entries in the DESCRIPTION that devtools adds when installing a package.. Why are you installing devel devtools in the first place? It is probably better to just rely on CRAN devtools which is installed by default with language: r.. This should already be fixed in the development version of devtools.. More specifically https://github.com/r-lib/remotes/pull/112. It would be easier to recommend the best solution if you could link to the actual package directly.\nBut the short answer I think is to use system.file(package = \"foo\", \"include\"). Devtools modifies system.file() to look in inst/ if the package is loaded by devtools::load_all(), which is what is done in devtools::test().. I think the simplest solution for your use case might be to just symlink include to inst/include. and put include in your .Rbuildignore file.. the use_* functions in future versions of devtools will be part of https://github.com/r-lib/usethis. If you could please open this issue there instead, as usethis::use_package_doc() still seems to have no open argument.. Does this occur with any package or just a specific one? Have you run devtools::clean_dll() before running devtools::document()? Have you tried reinstalling roxygen2 and devtools?. Eeek \ud83d\ude48 , sorry, the perils of not actually running the code. Both issues now fixed.. It also could be an internet connectivity issue if the package is using Remotes.. Or have these packages update to using pkgload::inst() instead.. It might make sense to provide some infrastructure around the (undocumented) whitelisting for CRANs spell checking as well http://dirk.eddelbuettel.com/blog/2017/08/10/. The spell check in release was removed in https://github.com/hadley/devtools/commit/2fc8895ddbfe4dad277d429c1cd8c253885f6806, not sure if that was intentional or not. I am guessing not because the argument is still there.... The devtools code needs to be updated to use git based Bioconductor.. Not everything, only install_bioc() and the bioc() remote is broken. using install() locally would still work, as would install_git() with the Bioconductor repository, although that would always install the devel branch.. Yes please do!. Closed by #1705. This is not a devtools issue, likely it is due to the CRAN rmarkdown using --smart, which seems to have been fixed https://github.com/rstudio/rmarkdown/commit/fa23a72208ceeab8f3d81a9cea19273b54bf2cdf in the devel version.\nI would suggest installing devel rmarkdown if you want to use pandoc 2.0.\nr\ndevtools::install_github(\"rstudio/rmarkdown\"). This error is coming from the windows OS, I don't think there is really much we can do about this, sorry.. Rcpp::loadModule() uses setLoadAction() with an artificially constructed call that in this case seems to pose problems when trying to reload the package.\nMore generally packages using Rcpp::loadModule() don't seem to work with when loading with pkgload / devtools after the first time.\nAs a workaround I added a document parameter to run_examples() in f4893c2b5, which will turn off re-documenting (which uses load_all()) so you can then use devtools::run_examples() in a fresh session to run the examples.\nI unfortunately do not have time to investigate a more complete fix with Rcpp modules, perhaps someone who uses them more frequently than I do may submit a PR in the future.. I do not think this feature is used often enough to warrant the time investment towards fixing it, so am going to close it for now.. I think this is a good idea, but feel like having a retest() or similar function name might be a clearer API than using filter = NULL.\nThere is also a few additional questions\n\nShould it be a list of failed tests or test files? If the former how to handle test files that have additional setup code in the test file.\nWhich package should be responsible for storing the list of tests and the retest logic?\nHow should the failed tests be stored? The different reporters currently store the results in different ways.. This behavior is likely changed in devel devtools, which uses the rcmdcheck package to run R CMD check. If it is not fixed I would encourage you to open this issue in that repository.. Seems like we should hoist the \"--timings\" to the default for args, so you can turn it off if desired.. Ok if you check with devtools::check(args = NULL) this should now turn off the timings.. @hadley I don't think that was the issue, rstudioapi::hasFun(\"documentSaveAll\") returns FALSE for me from the terminal. But the explicit check is fine to keep I guess.. This is likely due to ssh agent or similar trying to query for credentials. Try cloning a repo from the command line first and see if your credentials are then cached.. focussed is I believe just using the british spelling, @hadley can verify.\n\nThe other is a real typo though AFAIK, thanks!. I am not sure, but this looks like an issue with the .libPaths(), and is likely fixed by using devel devtools, which uses the rcmdcheck. If it is not fixed I would encourage you to open this issue at https://github.com/r-lib/rcmdcheck/issues.. If you are building vignettes you need all Suggested dependencies for the package as well, which is the difference. Otherwise you only need hard dependencies (Imports, Depends, LinkinTo). So I think this is working as intended.. I think this is good, but I think it really should be in usethis rather than here.. use_github_pat()?. Closing this here, I opened an usethis issue for it https://github.com/r-lib/usethis/issues/248. Likely R is trying to query ssh-agent or similar for your credentials. Try using them from the command line first so they are cached then installing with R. See https://github.com/hadley/devtools/search?q=ssh-agent&type=Issues&utf8=%E2%9C%93 for other instances of this issue.. The --no-build-vignettes needs to go in the Check Package dialog to be added when running R CMD check() and the check needs to be run with build->Check from within RStudio to pick up the option.\n\n. You actually need --no-build-vignettes in both the build and check steps to avoid building them completely.. You can use withr::with_makevars() to temporarily change the makevars file.\ne.g. https://github.com/hadley/devtools/pull/788\nFWIW I am not sure that compiler flags set in the environment have ever been used by R. AFAIK they have always required being set in the Makevars file.. This is now fixed in pkgbuild and devel devtools.. The plan is for devtools to be a meta package similar to tidyverse, so package authors will continue to use devtools to develop packages. However package authors should not need to use devtools as a package dependency in their own packages. Rather they should depend on one of the smaller package that implements the specific functionality they need.\nThe exact mechanism of how the functions will be exposed is somewhat of an implementation detail, but will probably be a combination of just putting the relevant packages in Depends (attaching the packages) and in some cases importing with a wrapper.\nThe with_* functions were somewhat of a special case as they were primarily used in devtools internally rather than for users / package authors and were really orthogonal to devtools' purpose.\nThe infrastructure functions have all been moved to usethis. The functions will exist in devtools for a little while with deprecation messages, eventually they will be removed and usethis will be put in the Depends for devtools, so will be automatically attached when devtools is attached.\nThe bottom line is devtools will continue to exist and should be what you recommend students use now and in the future for package development.. I don't think there is any need to worry. The plan is for devtools to always be a meta-package that contains the major build verbs (build being one of them). Most people will never need to know precisely which package the functions are coming from, the only time this could be important is when deciding which package to depend on.. Thanks! Unfortunately foghorn has an implicit dependency on stringr, (through rvest->selectr->stringr) so we cannot directly depend on it in devtools. You will need make this code conditional, e.g. if (requireNamespace(\"foghorn\")) { ... } in devtools::release() and put foghorn in Suggests: instead.\nAlso please add a note to NEWS.md with the change and mentioning the issue number and your GitHub username.. Looks great, thanks!. If people are interested in this feature we would review a PR for it, but are not going to develop it ourselves.. Please include the results of traceback() after the error, to help us pinpoint the issue on your machine.. This seem to be https://github.com/r-lib/testthat/issues/700, and to be related to where and how many context() calls are in your test file.\nIn any case it is not a devtools issue, so I will close this.. Yes, I am sure. The progress reporter assumes a context, those examples don't have one.. Is there any additional error message below error in running command? I am pretty confident the GITHUB_PAT is not the true issue.. Is R on the PATH? the command it is trying to run is R.. Maybe you should base your runner on one of the rocker containers, which should work without issues.. Both git2r and withr have had new releases in the past couple of days, it looks like your package database is stale. I would try restarting your R session and trying to install devtools again.. Thanks! This is fine, you just need to use the non-vectorized || function.\nMake that change and add a note to NEWS.md mentioning this change, the PR number and your GitHub handle and I can merge this.. Thanks!. Ok this should now work as it does with CRAN devtools, sorry for the trouble!. As mentioned in https://github.com/hadley/devtools/pull/1659, this is not a typo, it is the \"British\" spelling of the word.. I think this is an issue with a mismatch between libcurl versions, see https://github.com/jeroen/curl/issues/129#issuecomment-339730996, and potentially open an issue in the curl repository if you are not able to debug it further.\nIn any case this is not an issue in the devtools package, so I will close this issue here.. This is not a devtools issue, it is an R issue, R copies the full directory then removes files in .RBuildginore.\nA workaround would be to make data/ a symlink. I don't know.. It originally was a warning and was changed in https://github.com/hadley/devtools/commit/f541a131bfd41079c1c19bd6f684aafa886eaeac\nI tweaked the wording in b85dacd. Thanks!. This actually is not a typo, instead it is the British spelling of the word.. This is an R issue with Windows, I would recommend installing R to a path without spaces or special characters in any directories in the path. Your username is the likely culprit here.. Set the TMPDIR environment variable to somewhere not under your username. Do you actually have write access to these directories, the error messages imply you do not.. Thanks, should now be fixed. As there is nothing in the CRAN policies which explicitly states packages must have examples (and in the case of data packages this is not true) I don't think it makes sense to add a check for this at this time.. This is already done in the devel version of devtools https://github.com/hadley/devtools/blob/7e364c1749c4b7ebfd4fd64f72d69368399e354e/R/check-win.r#L33. What version of devtools do you have installed?. I would suggest re-installing devtools from CRAN in a fresh R session.\nr\ninstall.packages(\"devtools\"). looks like a quoting problem with your R temporary library.\nWhat does tempdir() return on your system?. Unfortunately the MYNAME_ bit is the important part, as it looks like there is either a space in the name or non-ASCII characters which are causing the issue. You can try setting your R temporary directory to a different location (without a space in the folder names) https://stackoverflow.com/a/17108351/2055486. \nThat should hopefully fix the issue.. It is hard to say, but you might try using devtools::install(), or alternatively eschewing devtools altogether and installing the package locally with install.packages(\"C:\\\\temp\\\\IRkernel\", repos = NULL). This should not be an issue if you use pkgbuild::build(), which is what devel devtools uses.. Thanks!. Unfortunately for the very near term CRAN devtools does not have the usethis functions, and we cannot update devtools / the diaspora packages because devel processx is blocked on CRAN. So if you are using CRAN devtools you might want to attach usethis after devtools. \nDevel devtools attaches usethis when you attach devtools (before devtools in the search path), so if you\nr\nlibrary(devtools)\nuse_test(\"foo\")\nR calls usethis::use_test() directly. The only time you will get the devtools implementation (and the deprecration notice) is if you use devtools::use_test(). We did it this way because we want package authors to depend on the various diaspora package directly rather than depending on all of devtools, but we want users to just have to attach devtools.\nEventually the deprecration message (and devtools use_() functions) will be completely removed and devtools will put usethis in Depends:.\nThe main idea is the only package end users should ever need to attach anywhere is devtools.. Sounds like this is fixed then. You should be able to see what is installed by saving the result then printing it. It is just returned invisibly by default.. This feels like a roxygen2 issue rather than a devtools issue, Ideally roxygen2 would fail if the tag is defined incorrectly in this case. I encourage you to open an issue at https://github.com/klutometis/roxygen. This check is not run by default with devtools::check() because the check require network access to CRANs servers and take a long time to run.\nUsing devtools::check(check_version = TRUE) turns on this check, and this check is turned on when using devtools::release(). It will also be turned on if you submit your package to win builder with devtools::build_win() or rhub with rhub::check_for_cran().\nThese are all checks that are useful to run prior to CRAN submission.. I made a change in the devel version of devtools which will now turn on more of the incoming checks, so this specific case will now be caught by devtools::check() with the default arguments and R versions > 3.4.0. There is an issue with the new default testthat reporter when you do not have a context() block, which none of your test files seems to have. So this is actually a testthat issue, not a devtools one.\nhttps://github.com/r-lib/testthat/issues/700\nduplicate of #1675. Thanks! I think the only thing missing is adding a note to NEWS.md with the change, mentioning the issue number and your GitHub username, then I can merge this.. Looks good, thanks!. The results of traceback() after the failure would be useful to help debug this. You can do so by setting a custom error handler, options(error = function() traceback(3))\ne.g.\n```shell\n\nRscript -e ' options(error = function() traceback(3)); f <- function() stop(\"hi\"); f()'\nError in f() : hi\n2: stop(\"hi\")\n1: f()\n``. This is actually [**extremely common**](https://github.com/search?utf8=%E2%9C%93&q=user%3Acran+%22Vignette+Title%22+extension%3ARmd&type=Code) even for published packages on CRAN, yes this seems like a very good idea.. Yes definitely open a PR!. Oh yes, it is still there, so it should have caught this before you submitted @jrosen48 (assuming you did so withdevtools::release()).. Maybe we should have a check inrelease()` for this? Ideally if you are resubmitting you should remove CRAN-RELEASE prior to submission?\n\nI ran into this as well; accidently submitting a package with CRAN-RELEASE in the tarball.. Thanks!. @jennybc since you were the original impetus for this saga I feel like it is only right I have you review this ;). Gah, git failure, thanks Jenny. Thanks for the reviews!. utils::globalVariables() is the correct solution to the problem and doesn't introduce any additional issues.\nI don't like the idea of providing a helper because there are plenty of cases where this check does catch an issue (a typo in a variable name for instance, or forgetting to include a variable as a function argument), so I think this is something a human needs to look at and verify they are really false positives.\nIt is possible there could be a usethis helper which would help construct the globalVariables() call for you but it would be somewhat tricky to do correctly. I think if this was anywhere it would be there rather than in devtools.. This has been fixed in the devel devtools for a long time 328ebe0e8c9c257044b26332d812a84ca764f557. I am guessing when you tried it devel devtools was actually still loaded (perhaps you did not restart R after installing it).. Thanks for saying what I would have said for me Jenny :). You can do this yourself pretty easily, I don't feel we need an additional argument\nr\ninstalled_packages <- installed.packages()[, \"Package\"]\ndevtools::update_packages(setdiff(installed_packages, c(\"RSQLite\", \"data.table\"))). I ended up finishing this with https://github.com/r-lib/devtools/commit/21fe55a912ca4eaa49ef5b7d891ff3e2aae7a370, which GitHub did not pickup as merging this PR, so will close this.\nThank you for getting it started @jennybc, it made it pretty easy to finish off!. You can use check_win_devel(args = '--no-manual') . Fixed by https://github.com/r-lib/devtools/commit/2f7bc84fc8f0a1392d6b9644b65d67a226c5208b. I would suggest you call roxygen2::rogyxenise() manually, the approach you are using is not one we have resources to support.. Is it possible R is not on your PATH?. So this (at least in your case) seems like a conda bug then, do you think you could open an issue at https://github.com/conda/conda/issues?. This same behavior is also mentioned at https://github.com/r-lib/devtools/issues/379#issuecomment-309836261. Yes I agree, I was actually the person who recommended this for the rhub::check_()functions for the very same reason!. This is actually a bit tricky to do unless we switch devtools to using desc.. Are you talking about the following? https://github.com/r-lib/devtools/blob/3068e654770d18be4e2a626c30300a95f9e50c32/R/deps.R#L321-L324\nI would love to have a better way to make sure install.packages() install binaries if they are available and falls back to source if not (without prompting for user input), but both this and the previous method used seem to have various issues https://github.com/r-lib/devtools/blob/64a4791f78416d2623c5963715b56ef5077c5cee/R/deps.R#L52-L55\nI think the method currently used seems to install packages from source in some case even when there is a binary available, which is the cause of https://github.com/r-lib/devtools/issues/1605\nIf you can think of a better way to do this it would be great!. Oh, so devel devtools does not overwrite the type option, but as I said above this approach also has issues of its own.. The behavior I have observed in devel devtools is dependencies being compiled from source even when there are binaries available and getOption(pkgType) == \"both\". And it is fixed by explicitly passing type = \"binary\" to install_(). > because the dependency package is installed by install_github before, the local package description file has the github remote information, and devtools will take that and install from github\nThis is the intended behavior, if you have a devel version of a package installed it should update the package to the latest devel version, not install a binary.. So github disabled support for SSLv1 connections at the end of February https://githubengineering.com/crypto-removal-notice/, which broke git2r::remote_ls() to GitHub, so you now always get an NA result from GitHub repositories and the error message you observed. e.g.\n``` r\ngit2r::remote_ls(\"https://github.com/r-lib/devtools.git\")\n> Error in git2r::remote_ls(\"https://github.com/r-lib/devtools.git\"): Error in 'git2r_remote_ls': SSL error: error:1407742E:SSL routines:SSL23_GET_SERVER_HELLO:tlsv1 alert protocol version\n```\nCreated on 2018-03-13 by the reprex package (v0.2.0).\nI will have to investigate to see if we can specify a later protocol for remote_ls() or if not use an alternative way to get the current SHA, perhaps with the GitHub API.. The SSL v1 issue is fixed by https://github.com/r-lib/devtools/commit/21fe55a912ca4eaa49ef5b7d891ff3e2aae7a370. Great, thanks!. Thanks!. The only way to do this would be to have devtools send a anonymized tracking request to something like google analytics, like what is done with homebrew by default.\nWe have so far avoided doing this due to privacy concerns, but if there was community support for it we could add it to devtools (with the ability to opt out).. That only works for releases, typically when people use install_github() they are installing the current master, not a release.. Thanks @MarkEdmondson1234, that is useful information. homebrew's analytics is a useful model for this and I believe they use that same GA protocol.. Thanks! LGTM, please add a news entry and I can merge it.. Not sure what the best solution is; the current plan is to eventually switch devtools to use pkgman, which uses a different API and method for package installation, so devtools will likely never use remotes as-is.\nHowever you are still welcome to open an issue there if you want to try and fix binary installation; in general you are somewhat limited in what binary versions are available, as CRAN only builds the most recent version of a package for a given version of R.. Looks good, thanks!. I think this was related to the git2r SSL v1 issue, it should be fixed by upgrading to a newer version of git2r.. Whoops, typo on my part, thanks!. This is not a devtools issue. In your NAMESPACE file you are exporting only functions which match [[:alpha:]]+, but your function has a _ in it, which is not matched by that regular expression, so the function is not exported.\nhttps://github.com/cbail/textnets/blob/46705ae19cb44cc2fe58dc88b577e31e5b864666/NAMESPACE#L1. Closed by https://github.com/r-lib/devtools/commit/6c30827661cb4d751f377a8e95455215df811c9b. This is not a devtools issue, you will likely have better success finding a solution by asking it on https://community.rstudio.com/c/general. Thank you for the pull request! However this seems a too specific issue to include in the general devtools checks. Maybe as an alternative you could add it to the release_questions() function in your package, to remind you to avoid them in cran-comments? See ?release for details\n\nYou can add arbitrary extra questions by defining an (un-exported)\n     function called \u2018release_questions()\u2019 that returns a character\n     vector of additional questions to ask.\n. This seems to be working fine with the development version of devtools / pkgload.\n\n```r\ndevtools::load_all()\n> Loading namespacecollisions\n> Warning: replacing previous import \u2018rlang::is_null\u2019 by \u2018testthat::is_null\u2019 when loading \u2018namespacecollisions\u2019\n> Warning: replacing previous import \u2018rlang::is_true\u2019 by \u2018testthat::is_true\u2019 when loading \u2018namespacecollisions\u2019\n> Warning: replacing previous import \u2018rlang::is_false\u2019 by \u2018testthat::is_false\u2019 when loading \u2018namespacecollisions\u2019\n``. Could you provide more details, this is working as intended on my machine.. The code is in https://github.com/r-lib/pkgbuild/blob/master/R/rcpp-attributes.R, also it does not run when runningdocument()it runs when compiling the dll e.g.pkgbuild::compile_dll()which is called when runningdevtools::load_all()` or during package installation.\ndevtools::document() does call load_all(), however if none of your source files are newer than the shared library the code will not be compiled (and no attributes will be compiled).\nIf you want to explicitly compile them yourself you can do so with pkgbuild:::compile_rcpp_attributes() or Rcpp::compileAttributes().. Removing RcppExports in cleanup is not a good idea, cleanup is run by R CMD build when creating a source package, so your source will ship without RcppExports and not actually work if you try to install it with R CMD INSTALL.. You can use devtools::install(), perhaps with conjunction with devtools::dev_mode() to use a development library.. The check you cite was recently added to R-devel, which is why you did not see it when running devtools::check() locally. This is also why it is recommended to check your package in R-devel before submission, using devtools::check_win_devel() or devtools::check_rhub(), both of which will check your package against the latest R-devel.\nTo get your package to pass the check you need to change the Depends: R (>= 3.3.3) to either Depends: R (>= 3.3) or Depends: R (>= 3.3.0).. Not sure when you would not know the version you are checking, but I guess it doesn't hurt to include this.. Because the check_win_() functions are being documented with name of check_win. Looks like a roxygen bug really, but I will probably just change the name of the Rd file.\nAlso the intent is not to export check_win(), just use the exported alternatives instead.. I ended up doing this differently and just passed ... to pkgbuild::build() so you can set whatever arguments you need.\nAlso the real reason that check_win() was being exported was there was a extraneous #' @export, https://github.com/r-lib/devtools/blob/7947bf6e620b4f3252191fade38d15910835e382/R/check-win.r#L14. I think instead we need to add repos and type to the formals of install_remote, but ignore them for the call to install_packages() and always use the repos and type from the parsed remote for this call to install_packages(). But do pass them to the call to install() at the end of the function.. Also please add a note to news with this change. Thanks! I ended up handling this somewhat differently with https://github.com/r-lib/devtools/commit/5a1b9d9de68c916545e97adedd34cc2727cc6f5c, so will close this.. Thanks, can you add a note to NEWS.md explaining the change and mentioning your GitHub username and the issue number.. Thanks! I added the note to news myself. This is a duplicate of https://github.com/r-lib/devtools/issues/1266 and is fixed by cb86ae45434d. I think we can probably turn it off by default definitely.. @maelle You can do two separate ones definitely! Put them on two different git branches to keep them straight. I just realized when reviewing this is we already had a question in release for this (for the devel version of devtools)\nhttps://github.com/r-lib/devtools/blob/ab568e954252a95f2279281784480afd117e63fa/R/release.r#L115\nAlthough it seems to have a typo...(fixed in https://github.com/r-lib/devtools/commit/13ee56b9bb43dd2cb2e3b364bcba2c49ef350fac). My main hesitation with this is the vast majority of packages are not going to have this. But as you mentioned I guess this reminder would only occur if a codemeta.json file is in the package; so it is probably fine.. So just realized we have a mechanism for package authors to add custom release check questions by defining release_questions function in their package environment. I think this may be the best way to handle this. We could have codemetar::write_codemeta() issue a message to add this prompt to the package source the first time it is run on a package. e.g.\nr\nmessage(\n  \"* Include the following code somewhere in your package\\n\",\n  '  release_questions <- function() \"Have you updated codemeta.json with codemetar::write_codemeta()?\"')\nThen this question will be automatically picked up and included in the release questions for the package.. No there are no docs, but you can have the function return a character vector of questions to ask.\nr\nrelease_questions <- function() {\n  c(\"Have you xyz\",\n     \"Have you 123\")\n}. As mentioned in the documentation\n\nref: Desired git reference. Could be a commit, tag, or branch name, or a call to \u2018github_pull\u2019\n\nSo to use a pull you need to use ref = github_pull(\"14\").\nHowever I would recommend you do not use the ref argument at all and instead include the reference at the end of the name. e.g.\n```r\ndevtools::install_github(\"trias-project/trias@add_origin\")\ndevtools::install_github(\"trias-project/trias#14\")\n``. This basically just wrapstest()and generates thefilterargument to match the test / source file. Seems to work well and I didn't want to duplicate the package setup code intest().. It also re-uses some logic fromusethis:::find_test_name().. Thanks! This is pretty nice actually, not sure why we didn't do this earlier :). Sounds good, did so https://github.com/r-lib/covr/issues/308. I think this issue has been opened in the wrong repository, this is for the devtools R package..parse_ns_file` is removed in the devel version of devtools and moved to pkgload, which only supports a path to a package, or within a package.\n```\nparse_ns_file             package:pkgload              R Documentation\nParses the NAMESPACE file for a package\nDescription:\n Parses the NAMESPACE file for a package\n\nUsage:\n parse_ns_file(path = \".\")\n\nArguments:\npath: Path to a package, or within a package.\n\n``. Should be fixed by https://github.com/r-lib/pkgbuild/commit/4ee12afc1e38f2aa36947036f01297ca3e4148cd, please update pkgbuild and try again.. Thanks!. The remote checks are disabled, but in newer R versions the other checks still happen. See https://github.com/r-lib/devtools/blob/13ee56b9bb43dd2cb2e3b364bcba2c49ef350fac/R/check.r#L207-L214 and #1271 . You seem to be missing a comma in between yourRemotes: ` fields.\nhttps://github.com/ms609/hyoliths/blob/05e0e37827e974fe61f9220a4201e34707ec1a6e/DESCRIPTION#L18-L19. @Serenthia this results in a more informative error in the devel version of devtools, but it is not yet release to CRAN.. I don't think we need to expose upgrade, but sure we can add clean.. Fixed by https://github.com/r-lib/devtools/commit/61c0c41a7875385b4d4732a921be21c345c5e080. Yes, a CRAN release will be coming soon, in the next week or two.. Could you try\nr\npkgbuild::with_build_tools(remotes::install_github(\"thomasp85/tweenr\"))\nWith the CRAN versions of pkgbuild and remotes. @jamesgriggs please just use the CRAN version of devtools, the workaround is no longer necessary.. find_rtools() was removed from devtools, it is only in pkgbuild now. If you want to call the function you need to load pkgbuild.. This seemed to work fine in the devel version of devtools.. @maelle actually had an issue for this https://github.com/r-lib/devtools/issues/1754, which we decided to close in favor of package authors adding a release_questions object to their package rather than adding additional logic to devtools. But if we (tidyverse team) are going to start using this we can add it.. Ok this question is now included in devtools::release() if a codemeta.json file exists.. This is actually referring to the encoding = parameter to testthat::test_dir(), rather than the Encoding: field in the DESCRIPTION file. We should remove the encoding argument at https://github.com/r-lib/devtools/blob/ab568e954252a95f2279281784480afd117e63fa/R/test.r#L70. But as  workaround you should be able to add Encoding: UTF-8 to your DESCRIPTION and that should make this warning go away.. You should remove the Remotes field when submitting, then add it back, we are not going to do this automatically because it should be a conscious choice whether to use Remotes or not.. Thanks, this is great!. And do you get the same error from running R CMD check on the command line?. cc @kevinushey any idea why the repos would be inherited differently in the build pane than from the command line or RStudio console?. Well I would guess you are using incompatible versions of the cygwin DLL.\nIt would help if you showed us the locations of the cygwin1.dll. and what is currently on your PATH.. Yes, you have C:\\Program Files\\ConEmu\\ConEmu in your PATH, so that cygwin1.dll is being used instead of the one from R.. If you are still looking for help I would suggest posting on https://community.rstudio.com, I don't think this is a devtools specific issue.. It mentions ... is passed to install.packages() not devtools::install(), so this is working as intended.. The documentation is already fixed in the devel version of devtools.. I think you should just clone the repository yourself, then install it with devtools::install().\nThis workflow is not something we plan to support in devtools.\nAlso note devtools tracks the git SHA when it installs the package, you can retrieve it (after installing with install_github()) with packageDescription(\"xyz\")$RemoteSha.. I think this would require something like rstudioapi::getHelpContext(), which does not exist and doesn't look like there is any tooling for tracking which file is open. It would also have to disambiguate between viewing a help file and doing other things in that pane, like files and plots.. I think the workflow would be something like\ndevtools::load_all()\n?xyz \nWhere xyz is a fun of the pkg under development, this (as it does now) would open xyz in the help pane.\nuser makes changes in roxygen comment in source file\ndevtools::document()\nmagic which doesn't currently exist\nThe open help pane of xyz is updated with the changes.\nI think we would need to determine if a help page from the current pkg is currently being viewed (probably the URL is sufficient for this) and to refresh the page if so (maybe we could just issue a new call to help() the help page topic for this).. It probably would be sufficient, or have a function in rstudioapi to refresh the Help pane, and we could just call it from document().. Yeah, I agree, thanks!. I think this is an issue in R rather than in devtools, you might try using R 3.5, which has some better support for non ASCII filenames / long names on Windows.\nIn the worst case, try setting your temporary directory and library to paths that contain only ASCII characters.. I agree this is a useful thing to check, however I am not sure devtools is the right place for it. It seems more appropriate as a lintr linter or part of goodpractice.. So this is actually a testthat issue, https://github.com/r-lib/testthat/issues/700 and is fixed in the devel version of testthat (not yet on CRAN).. A workaround is to ensure all of your test files have a context() line before any tests.. The original plan was to use remotes, but because getting the other diaspora packages on CRAN as drawn out so long now the current plan is to skip remotes and go straight to pkgman and friends I think.. The main benefit to remotes vs devtools is remotes has no dependencies, so for local use I would recommend using devtools or pkgman stuff if you are feeling adventurous.\nIt is possible there are some bugs fixed in remotes that are not in devtools, but I think if there are they are very rare.. I don't think this is a devtools / pkgload issue. The clusterExperiment package does not seem to be able to be unloaded by R.\ne.g.\n``` r\nloadNamespace(\"clusterExperiment\")\n> Warning: namespace 'bigmemory' is not available and has been replaced\n> by .GlobalEnv when processing object ''\n> Warning: namespace 'bigmemory' is not available and has been replaced\n> by .GlobalEnv when processing object ''\n> \nunloadNamespace(\"clusterExperiment\")\n> Warning: namespace 'bigmemory' is not available and has been replaced\n> by .GlobalEnv when processing object ''\n> Warning: namespace 'bigmemory' is not available and has been replaced\n> by .GlobalEnv when processing object ''\n\"clusterExperiment\" %in% loadedNamespaces()\n> [1] TRUE\n```\nCreated on 2018-07-17 by the reprex package (v0.2.0).\nContrast this with a package which is able to be unloaded.\n``` r\nloadNamespace(\"fs\")\n> \nunloadNamespace(\"fs\")\n\"fs\" %in% loadedNamespaces()\n> [1] FALSE\n```\nWe won't be able to do anything with devtools unless either the package or R is fixed for this case. I unfortunately do not have the time to invest to determine why the package cannot be unloaded.. This does not support the PR format like we do with GitHub, nor releases, as AFAIK there is no 1-1 equivalent of releases in GitLab. It does support tags, SHAs and branches, e.g. all of the below work\n```r\ndevtools::install_gitlab(\"jimhester/covr\")\ntag\ndevtools::install_gitlab(\"jimhester/covr@v3.1.0\")\nbranch\ndevtools::install_gitlab(\"jimhester/covr@static_reports\")\n```\nIt also does the same thing as GitHub and only installs if the remote reference has changed. Re: tests yes agreed, I didn't mainly because there were none for other install_ functions.. Ok I added simple tests, mostly adapting tests from remotes for install_github.. Thanks for the review, I will merge this for now, we can fix any additional issues that crop up as needed later.. withr has with_path(), so you can get the same behavior as add_path(after = Inf) with withr::with_path(path, action = \"suffix\").\nIt doesn't seem like these functions are used by any packages on CRAN (including devtools) so maybe we should just remove them entirely?. If you want to do this then you will need to do it without testthat in a separate test file.. You need to install pkgB to use it from pkgA, you cannot just use load_all(), which does not actually install the package.\nLikely previously you had some version of pkgB installed.\nIn general it is best to use devtools::install(\"pkgB\") in this situation rather than load_all(). Yes, but previously you had an installed version of pkgB on your system, now you do not.\nNothing has changed in this regard on the CRAN version of devtools for probably 2 years, so this is not due to a change in devtools.. local = FALSE is just an incomplete workaround, it is not a general solution (as you showed it doesn't fix the issue for non-configure scripts) and I don't think it should be the default.. Building the package first is much slower in some cases, particularly large packages with a lot of data. You still have to copy, archive and recompress the archive, then decompress them again to actually install the package. It looks like you have having issues installing igraph and git2r. You would need to post more of the installation log to know more.\nAlso this is unlikely due to devtools code, I would recommend you post this on https://community.rstudio.com/ with the full installation log.. This does not seem related to devtools, perhaps you want to post it on https://community.rstudio.com?. I believe this is fixed in the devel version of devtools.. The current behavior is by design. The SHA is recorded only if the local package was installed from a git directory with a clean working tree, otherwise it is NA, as we cannot be sure if the package has changed since the last time it was installed.\nIf the local package does have a clean working tree then the SHA will be recorded, and it will only be re-installed if the package has changed. See https://github.com/r-lib/devtools/pull/1027 for when this was added.. I don't really think we need an option, but you could write a helper to stash the current changes and install if you prefer this behavior. Note git2r doesn't currently have an API for git stash apply (https://github.com/ropensci/git2r/issues/358), so you need to use command line git.\nr\ninstall_last_commit <- function(...) {\n  system(\"git stash --include-untracked\")\n  devtools::install(...)\n  system(\"git stash pop\")\n}. With the option upgrade_dependencies = TRUE (the default) devtools upgrades all dependencies when installing a package. You can set this to FALSE to avoid this.\nLocal dependencies are treated like any other dependency, GitHub, CRAN or otherwise, if the remote has changed since the previous install than the package will be upgraded from the previous location assuming upgrade_dependencies = TRUE.\nIf you install local dependencies with a dirty working directory there is no way for us to know what the state of the package is when it is installed, so we always will reinstall it. If you install the package with a clean working directory then the SHA will be recorded, and it will only be re-installed if the SHA changes.. Thanks, reproduced and now fixed. It looks like your library is set to a network drive, but the path is not correct (the \\uka-file1\\ should be //uka-file1. I would suggest you set your library to a location on your physical drive with .libPaths().\nIt also looks like your R distribution is installed on a network drive, generally I would not recommend this setup as there are cases where R has problems with network drives.\nI would try re-installing R on a local drive and if you are still running into problems try posting the issue on community.rstudio.com\nAs this is not a devtools specific issue I am going to close it.. We will not be exporting these functions, so I would suggest you either copy the implementations (with attribution) or find a way to do this without devtools.. It is expected, we are planning to re-think how devtools builds vignettes https://github.com/r-lib/devtools/issues/1578.. Try devtools::install(args = \"--no-test-load\")\nHowever I think you will continue to run into problems down the line, R does not handle paths with spaces very well in many cases. I would suggest making sure you set the installation directory to either a short code of the current path (which won't have spaces), or a different path without them.. devtools::check() by default does not run the 'version' or 'incoming' checks, because they take a while to run and have to check CRANs or other external servers. You can run them by passing devtools::check(check_version = TRUE)\ndevtools::check_win_devel() runs on win-builder, which is an identical setup to the CRANs autocheck makines, so it will give you the same results as what you would get when submitting to CRAN.. It is possible this could be better documented, or the argument could be renamed to make it more clear which tests are suppressed.. I think you need to open an issue at https://github.com/RDAdams/RedShifteR/issues, this has nothing to do with devtools.. Thanks!. Looks great, thanks!. This behavior is already changed in the devel version of devtools https://github.com/r-lib/devtools/commit/1ce84b04568ff7846c3da754f28e7e22a23c8737#diff-e7118181d76027ea30ccf5babc54f550. Paths ending with / and those which do not are not equivalent on windows. See https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14721\nAnyway I am pretty sure this is already fixed in pkgload; which devtools will use in the next version.\nCould you verify this works\nr\ninstall.packages(\"pkgload\")\npkgload::load_all(\"C:/git/pknca/\"). Changing the working directory would only help if you had not called a usethis function to set the project yet. Once the usethis project is set the working directory is ignored. You need to use usethis::proj_set() to change the active project rather than changing the working directory.\nPerhaps instead warn_unless_current_dir() should be changed to throw an error if pkg$path does not equal usethis::proj_get(). Ok I have added temporarily setting the active project to warn_unless_current_dir(), so we can preserve existing behavior (with a warning) for all usethis functions in devtools.. @hadley mainly looking for feedback if this seems to be the right track\n@jennybc if you could look at the usethis parts of the PR that would be great. One issue with this is making sure to remove the lazy load database from memory before updating, otherwise you get Error in fetch(key) : lazy-load database '.../devtools/help/devtools.rdb' is corrupt errors when trying to re-load a help file that was previously loaded.. I think we are going to wait on this for now.. Shouldn't you use git2::cred_token() for this?. Thanks, applied with https://github.com/r-lib/devtools/commit/7270c205d1027894ad9ef8cd71d26af3e071fedd. Thanks, should now be fixed, please try the devel version of devtools and let me know if it works for you.. It is on the master branch, the commit is linked above.\nI do not know when the next CRAN release will be, maybe in the next month or so.. I cannot reproduce this, the attached package tests without on both Windows and MacOS, with both the CRAN release of devtools as well as the devel version.\nCould you provide your sessioninfo::session_info() when you observe the crashing?. I can reproduce it on linux with both CRAN devtools and devel devtools, the relevant backtrace is\n```\n0  0x0000000003f2ab40 in ?? ()\n1  0x00007ffff18510da in Catch::seedRng (config=...) at /usr/local/lib/R/site-library/testthat/include/testthat/vendor/catch.h:8652\n2  0x00007ffff1859c15 in run (this=0x7ffff1a91920 ) at /usr/local/lib/R/site-library/testthat/include/testthat/vendor/catch.h:7115\n3  run_tests () at /usr/local/lib/R/site-library/testthat/include/testthat/testthat.h:118\n4  run_testthat_tests () at /usr/local/lib/R/site-library/testthat/include/testthat/testthat.h:151\n5  0x00007ffff7884bdd in ?? () from /usr/lib/R/lib/libR.so\n```\nI am not that familiar with this code, but it seems Catch is using a singleton and it is crashing when trying to initialize the RNG the second time. Perhaps the first singleton is not being destructed properly. @kevinushey any ideas?. Wow that is quite a strange one, I was not aware of this gcc behavior.\nIf this is a gcc specific issue I wonder why I did not observe this on Windows as well, maybe just deterministic behavior and I did not try re-running test() enough to trigger it.\nI wonder if we should have pkgload include -fno-gnu-unique when compiling packages with gcc, or if static variables in inline functions are rare enough case we don't need to worry about it.. Great thanks again Kevin for looking into this, I would not have thought of this being an issue, so I am glad you had an inkling of where to look.. Thanks!. What version of devtools and roxygen are you using? Please try with the development versions if you have not done so.. Could you try this with usethis::use_vignette()? and if the problem still occurs open an issue at https://github.com/r-lib/usethis. Thanks!. Thanks!. I reverted the graphql commits, so this should now be fixed.. Thanks!. Yes, we will likely be changing this in the near future, sorry for the breakage.. I reverted the commits adding the graphql API calls. There is nothing we can do about the build-time note, it is dependent on how fast the vignettes run on the CRAN build machines, they must take less time locally and on win-builder.\nThe commented examples check is not part of R CMD check as far as I can tell, it was just found manually by the CRAN maintainers, so I don't think there is much we can do about this either.\n. No, there is no code in the R sources R CMD check for this, you can look yourself https://github.com/wch/r-source/search?q=%22unexported+function%22&unscoped_q=%22unexported+function%22.\nCRAN does allow dontrun, but it is only appropriate if the code cannot be run by either users or automated checks out of the box. If the code could be run by users interactively you should use \\donttest{}. Please see Uwe's response at https://stat.ethz.ch/pipermail/r-package-devel/2018q2/002812.html for details.. Please read the full error message more closely, git2r should have given you an error saying something similar to\n```r\n   The zlib library that is required to build\n   git2r was not found.\nPlease install:\n     zlib1g-dev (package on e.g. Debian and Ubuntu)\n     zlib-devel (package on e.g. Fedora, CentOS and RHEL)\n   and try again.\n```\nSo you need to use the package manager for your linux distribution to install the appropriate system libraries for git2r installation to succeed.\nIn any case this is not an issue with devtools.. Couldn't we just depend on roxygen 6.1.0 now that it is on CRAN, even with it still in Suggests? We already depend on roxygen 5.0.0 there. IIRC check_suggested() (called above) will throw an error for older versions if a version dependency is in the DESCRIPTION.. Right, but we do check this explicitly with pkgload::check_suggested() earlier in this function, although you get a warning rather than an error. (I artificially bumped the version in the DESCRIPTION as a test).\n```r\n\ncheck_suggested(\"roxygen2\")\nWarning in check_dep_version(package, version) :\n  Need roxygen2 >= 7.0.0 but loaded version is 6.1.0\n``. Yeah just bumping sounds good to me.. Thanks!. Maybe we should be callingpkgload::load_all(helpers = FALSE)in roxygen2 and maybeexport_all = FALSEto more closely mimic a normal package namespace? I am not sure what roxygen2 assumes in regards to exports.. Also potentiallyrecompile = FALSE, which would be a way to fix https://github.com/klutometis/roxygen/issues/771, but maybe would cause other issues if the dll was not built.. I think we should put it inR/save-all.R` with an eye towards expanding the functionality to other editors in the future. Although doing so would likely require a package to communicate with them ala rstudioapi.. The directory Rtools is installed is not the problem and devtools does not even require that Rtools be on your PATH.\n\nI believe this is simply a duplicate of https://github.com/r-lib/devtools/issues/1772, please try that workaround or updating to the development version of devtools and see if that fixes your issue.. You may want to try with install() rather than install_local().. Could conflicted do this automatically by looking for .Deprecated() calls? If you just look at the first call after { is should not be too costly to check.. The cost does not seem to be really any worse than checking for the attribute\n``` r\ndevtools::load_all(\"~/p/devtools\")\n> Loading devtools\nhas_deprecated_attribute <- function(f) isTRUE(attr(f, \"conflicted_deprecated\"))\nhas_deprecated_call <- function(f) {\n  deprecated <- as.symbol(\".Deprecated\")\n  b <- body(f)\n  identical(b[[1]], deprecated) || length(b) > 1 && identical(b[[2]][[1]], deprecated)\n}\nbench::mark(\n  has_deprecated_attribute(devtools::use_coverage),\n  has_deprecated_call(devtools::use_coverage)\n)\n> # A tibble: 2 x 10\n>   expression    min   mean median     max itr/sec mem_alloc  n_gc n_itr\n>           \n> 1 has_depre\u2026 5.09\u00b5s 7.82\u00b5s  5.7\u00b5s 15.55ms   127819.        0B     4  9996\n> 2 has_depre\u2026 6.12\u00b5s 7.87\u00b5s  6.8\u00b5s  5.61ms   127044.        0B     5  9995\n> # ... with 1 more variable: total_time \n```\nCreated on 2018-08-22 by the reprex package (v0.2.0).. Awesome, thanks!. Could you push the latest version of the baseballr package to github (maybe in a branch?). We will not be able to debug this without being able to reproduce it ourselves.\nAlso suppling the value of traceback() after the error occurs would be useful.. I cannot reproduce this with the CRAN versions of devtools and roxygen2. Can you give your full sessioninfo::session_info() as well and double check you have committed everything in your local repository?. @layik if you would like to see what the output will look like in upcoming releases of devtools you can use rcmdcheck::rcmdcheck().. We plan to have a devtools 2.0.0 release based off the master branch of devtools in the next couple of weeks / ~ 1 month, so this should be fixed on CRAN soon.. remotes 2.0.0 has now been released to CRAN, with the updated bioc code, devtools will be submitted in the very near future (using remotes) as well.. because CRAN submissions are currently closed, see https://cran.r-project.org/submit.html. Looks great, thanks!. Still some work to be done, mainly opening this to test on CIs. I merged this locally instead.. Looks good to me, thanks! Could you add a note to NEWS.md documenting the change and mentioning the issue # and your GitHub name.\nDon't worry about the travis errors, I will fix them after merging.. Also if you want GitHub to map your commits to your GitHub user you will need to add the email you used in the commits to https://github.com/settings/emails. Thanks again!. The issue seems to be \\icnas2.cc.ic.ac.uk/yguo2/R/win-library/3.5, try setting your libPaths to somewhere on your local harddrive, not a network share.. By setting R_LIBS_USER in your .Renviron file, see https://whattheyforgot.org/r-startup.html#renviron for more information.. Is there a reason we can't use shQuote()? Or you just think changing the working directory is more robust?. Looks good, thanks!. The error is stating you need to install the libgit2 homebrew package.\nshell\nbrew install libgit2\nThen you can install the git2r R package\nr\ninstall.packages(\"git2r\")\nThen devtools should install normally\nr\ninstall.packages(\"devtools\"). I am almost 100% sure this is an issue with your package rather than an issue with devtools.\nLikely the path to child_docs is not being constructed as you expect.\nTry something like\nr\nsystem.file(\"ParametrizedReportsChild\", child_docs, package = \"SRMService\")\nI unfortunately cannot reproduce the error on my machine, I get an error when building a different vignette.\nQuitting from lines 109-124 (Run_Tidy_MSqRob_Analysis.Rmd)\nError: processing vignette 'Run_Tidy_MSqRob_Analysis.Rmd' failed with diagnostics:\nError: `x` is not a matrix object\nAlso I needed to make the following changes to correctly install all dependencies for the package\ndiff\ndiff --git a/DESCRIPTION b/DESCRIPTION\nindex 7d3bbec..08ba6a9 100644\n--- a/DESCRIPTION\n+++ b/DESCRIPTION\n@@ -68,6 +68,13 @@ Collate:\n     'zzz.R'\n Suggests:\n     testthat,\n+    ggplot2,\n     knitr,\n-    rmarkdown\n+    readxl,\n+    rmarkdown,\n+    MSqRob\n+Remotes:\n+    protViz/bibliospec,\n+    statOmics/MSqRob\n+BiocViews:\n VignetteBuilder: knitr. This is not a devtools issue. You should not need to build your vignettes before building the package. The way you are specifying the child documents is wrong, I unfortunately do not have the time to figure out how.\nI would suggest if you need further help with your vignettes to post the issue at community.rstudio.com. Thanks!. Ok thanks for taking a look!. So I agree it should be, the comments explain why it is not formally deprecated\nhttps://github.com/r-lib/devtools/blob/75e1dbe6faf0b9abfe9cbfa57d036e537a983daf/R/infrastructure.R#L87-L95\nI guess conflicted then complains about this function, which is why you have opened the issue.... Yes, it should be revdepcheck sorry, it not being on CRAN is fine, people can install from GH if they need it.. Thanks!. So we should only need changes to pkgbuild (https://github.com/r-lib/pkgbuild/pull/47). No changes to rcmdcheck needed thankfully.. Thanks, this is fixed in the devel version of devtools. . So it is not being double-installed, but the output is being doubled, likely from recent changes to pkgbuild, I will track it down.. Thanks, should now be fixed.. more useful than the session information would be what package you are trying to check.... It would be more useful to see the full check output, but this is very unlikely to be a devtools issue, particularly with the development version which always builds and checks the package in a temporary library.\nI ran devtools::check(build_args = \"--no-build-vignettes\", args = \"--no-vignettes\", document=FALSE) twice locally and had the same installed package size both times.\nN  checking installed package size\n     installed size is  7.3Mb\n     sub-directories of 1Mb or more:\n       help   6.8Mb\nI unfortunately do not have time to check your package with vignettes.. This seems to work fine on my machine, can you provide more details on what is on your PATH and what version of devtools you are using?. And what does R CMD config CXX11 run in the command line terminal give you?. And what does which clang++ give you?. Are you running R from within RStudio or from the command line?. What does getOption(\"buildtools.check\", NULL) return? and what version of RStudio?. And what happens when you try to run the function? e.g. \nr\ngetOption(\"buildtools.check\", NULL)(\"Building R package from source\"). This must be a bug in RStudio's detection then, I am not sure what is going wrong. @kevinushey any thoughts?. I don't believe this is a devtools specific issue, I would suggest if you continue to have problems you post on the community site or in the RStudio IDE issue tracker . I cannot reproduce this in a VM, can you provide more details of the exact error message with the full output?\nThis is very unlikely to be an issue in devtools, we do not do anything with SSL in the devtools codebase. You might have some success posting this to https://community.rstudio.com with the full details of the output from the install.. We have no way to know how long a vignette is going to take to build on CRAN's machines, which are under very different load and specifications than your local machine.. https://github.com/r-lib/devtools/pull/1824. devtools::use_test(\"mytest\") / usethis::use_test(\"mytest\") already does this. Not everything has been moved to a separate package, release() is just in devtools proper.. no. The function fibonnacci() you mention is not exported by your package, so is not available to be used in your examples, which simply attach the package.\nI would suggest removing the example for the internal function, or if you meant it to be an internal exported function, doing so.. Your package would work without a conditional if instead of looking up system.file() in the base environment you use the search path by using Rf_findFun(Rf_install(\"system.file\"), ENCLOS(R_GlobalEnv)).\nBut to answer the question asked you can use pkgload::is_dev_package() to determine if a package has been loaded by load_all().. No there is no solution I am aware of, but based on the error message they are trying to execute the Rmd file directly, which is clearly wrong, I think they may be confused on what the issue is.\nAlso this question would be better posed to https://community.rstudio.com. (there is a section devoted to package development https://community.rstudio.com/c/package-development)\nThe devtools issue tracker is for bugs or feature requests for devtools.. The devel version of devtools does use the spelling package, you seem to be using the CRAN version of devtools.\nhttps://github.com/r-lib/devtools/blob/95ba7657d7da116d08e900a5b5078f3a47d038a5/R/spell-check.R#L19. The devel version of devtools passes ... to pkgbuild::build(), so you just need to specify manual = TRUE in this case.\nI am not really sure we should necessarily change the default as building the manual requires a LaTeX installation, which not everyone will have.. These are coming from two separate installation steps, it is unlikely to be possible without major rewriting of the code.. Yes, this is already implemented, see the error_on argument in the devel version.. Yes, remove --no-build-vignettes from the build_opts to build the vignettes. e.g.\nr\ndevtools::install_github(\"foo/bar\", build_opts = c(\"--no-resave-data\", \"--no-manual\")). You don't mention how you are trying to install devtools (presumably by install.packages()? Anyway the results indicate the configure scripts are not getting the proper executable bit set, this is most likely due to a mis-configuration of your machine.\nPerhaps as described in http://mazamascience.com/WorkingWithData/?p=1185 the default TMPDIR is marked as \"noexec\"? In that case you will need to point R to a different directory.\nIf you have additional issues related to package installation I would encourage you to open an issue at https://community.rstudio.com.\nIn any case this does not seem to be a devtools specific issue, so I will close this.. Yes you are correct, sorry for the oversight and thank you for the fix!. Yes, probably in the next week or so.. The DESCRIPTION file in question is malformed, it has two Depends fields.\nhttps://github.com/adamMaier/reviewr/blob/ae038d82a886a8316c4e6e44211a856d07285c8e/DESCRIPTION#L10\nand\nhttps://github.com/adamMaier/reviewr/blob/ae038d82a886a8316c4e6e44211a856d07285c8e/DESCRIPTION#L14. They are not used now except for in source_gist(), but actually the way the GitHub API works if you are using basic authentication with a Oauth token the token can be in either the username or the password https://developer.github.com/v3/auth/#via-oauth-tokens, so this is actually working as intended.. devtools now builds packages by default before trying to install them, try installing with build = FALSE and see if that works.. In addition the repo seems to contain a submodule, which are now checked out by default before building. If the developers do not intend for these submodules to be included in the tarball they should be added to .Rbuildignore.. This was previously reported and is fixed by https://github.com/r-lib/remotes/issues/220. This is how it used to work when install_deps() was in devtools, but the functions in remotes don't do this so we no longer have this functionality.\nOne way to get it back is to use devtools::package_file(), e.g.\ndevtools::install_deps(devtools::package_file()). This is fixed by https://github.com/r-lib/remotes/commit/c0aa8682b55936e3f28f1dbae2b5e983341ff3d4, we plan to have a release of remotes today to fix this.. This is fixed by https://github.com/r-lib/rcmdcheck/pull/84, you can install the development version of rcmdcheck to fix this or wait until a new version is released on CRAN (which should be soon).\ncc @gaborcsardi . your repos option needs to be a named character vector, not a list.. This is the expected behavior, please see https://github.com/r-lib/devtools/pull/1824 for a discussion of why the change was made.. You should be able to set _R_CHECK_DOC_SIZES_=FALSE environment variable to disable that particular check. Also make sure you are using equivalent options when running R CMD check on the command line, particularly --as-cran.. Sorry I cannot reproduce this, please provide an example package that reproduces this error with the current release of devtools.. Please be sure to update the rcmdcheck package, there is a known bug in v1.3.1 and earlier versions that causes old tarballs to be used when run as RStudio does.. Sorry I cannot reproduce this, please provide an example package that reproduces this error with the current release of devtools.. This is a duplicate of https://github.com/r-lib/devtools/issues/1914, see the workarounds in that issue until it is fixed.. It is now fixed in the development version of devtools, please try that.. Is there a reason you need this?. The folder is only removed if you build the vignettes, during the check.\ne.g. build your package into a tarball with pkgbuild::build() then use that built package as the input to check_win*().. Thanks!. The proper way to pass arguments to make is using MAKEFLAGS, e.g.\nMAKEFLAGS=-j8. https://remotes.r-lib.org/#environment-variables. In that case maybe you are better off using pkgbuild::build() to build the package and passing the built tarball to remotes::install_local() or callr::rcmd(\"INSTALL\") directly.. Thanks!. Please do not open issues here that are not actual issues with devtools itself. \nhttps://community.rstudio.com is the best place for such questions.. You seem to have a non-standard tar on your PATH. You could try setting Sys.setenv(\"TAR\" = \"internal\") to use R's internal tar instead.. Sorry there is not enough information here to do anything. If you add additional details I can reopen this.. Please see https://github.com/r-lib/pkgbuild/issues/58 for discussion.. This is an issue with anaconda, not with devtools. I would suggest you raise an issue with their help resources (https://www.anaconda.com/community/)\nIn general you will run into fewer installation issues by avoiding use of anaconda for R packages.. Thanks, I often like to inspect the built tarball myself, so this is a good idea!. By default all install_github() functions have --no-build-vignettes in the build_opts argument, because many packages take a long time to build the vignettes. If you want to build the vignettes simply remove this option, e.g.\nr\ninstall_github(\"foo/bar\", build_opts = c(\"--no-resave-data\", \"--no-manual\")). Use system.file() to access the content and it should work in both cases.. > The package submission system will remain offline until Jan 2nd 2019. \nReasons being CRAN team vacation and maintenance work.\n\nHappy holidays and thank you for your understanding.\n\nhttps://cran.r-project.org/submit.html. I think you must have set an environment variable to something weird. What does\nSys.getenv(\"R_REMOTES_NO_ERRORS_FROM_WARNINGS\") give you? It should be true or false, not something like 1.. Oh, the _R_CHECK_FORCE_SUGGESTS_=0 is the problem, change it to _R_CHECK_FORCE_SUGGESTS_=false and it will fix this error and retain the same behavior elsewhere in R.. Invalidating the entire cache on any DESCRIPTION change seems overkill.\nAlso I don't think this change is actually necessary. The default behavior for remotes::install_deps() is to upgrade out of date dependencies.. @schloerke it already uses the GitHub SHA to determine if the package needs to be updated.. Yes, don't delete the branch and it would have been fine, this is https://github.com/r-lib/remotes/issues/274 and will be fixed at some point soonish.. If the repo is private you need to setup a GITHUB_PAT environment variable in the docker container to access it.. What package are you trying to install with devtools?. @mialj1 please try using the development version of the remotes package and see if it resolves this issue.\nr\ndevtools::install_dev(\"remotes\"). Thanks @jonthegeek! But actually to fix this you need to do more than just import the function, you also need to export the function again, which is what we call this re-export.\nAn example of what you need is\nhttps://github.com/r-lib/devtools/blob/bcdde3985c8220accc975e38236e5f802a0036b2/R/pkgbuild.R#L16-L18\n. no worries!. Thanks, this is great! Great job!. Maybe load_all() as well, I had to make this same suggestion to many people at the dev day too.. Thanks!. The environment variable is not going to be set unless you do so explicitly when calling devtools::release(), so something like the following should do what you want.\nr\nwithr::with_envvar(c(\"NOT_CRAN\" = \"true\"),\n  devtools::release()\n). What does remotes:::download_method() and capabilities() return? Also what version of R are you using?. devtools uses the foghorn package to parse the check issues, so I think this issue is better opened there https://github.com/fmichonneau/foghorn/issues. You will need to restart R, then re-install devtools with no other packages loaded.. Closing this as it is not a bug in devtools, but in roxygen.. devtools already does attach usethis when you attach devtools.\nhttps://github.com/r-lib/devtools/blob/e4e57aa6a775ef6f48eebc933ed7c4ad0a6e9c07/R/zzz.R#L68-L71\nThe functions that previously existed in devtools are re-exported in devtools only to provide deprecation messages.\n``` r\nlibrary(devtools)\nsessionInfo()\n> R version 3.5.1 (2018-07-02)\n> Platform: x86_64-apple-darwin15.6.0 (64-bit)\n> Running under: macOS  10.14.2\n>\n> Matrix products: default\n> BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib\n> LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib\n>\n> locale:\n> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n>\n> attached base packages:\n> [1] stats     graphics  grDevices utils     datasets  methods   base\n>\n> other attached packages:\n> [1] usethis_1.4.0.9000  devtools_2.0.1.9000\n>\n> loaded via a namespace (and not attached):\n>  [1] Rcpp_1.0.0         knitr_1.21         magrittr_1.5\n>  [4] pkgload_1.0.2      R6_2.3.0           rlang_0.3.1\n>  [7] stringr_1.3.1      highr_0.7          tools_3.5.1\n> [10] pkgbuild_1.0.2     xfun_0.4           sessioninfo_1.1.1\n> [13] cli_1.0.1.9000     withr_2.1.2        remotes_2.0.2.9000\n> [16] htmltools_0.3.6    yaml_2.2.0         rprojroot_1.3-2\n> [19] digest_0.6.18      assertthat_0.2.0   crayon_1.3.4\n> [22] processx_3.2.1     callr_3.1.1.9000   fs_1.2.6\n> [25] ps_1.3.0.9000      testthat_2.0.1     glue_1.3.0.9000\n> [28] memoise_1.1.0      evaluate_0.12      rmarkdown_1.10\n> [31] stringi_1.2.4      compiler_3.5.1     desc_1.2.0\n> [34] backports_1.1.3    prettyunits_1.0.2\n```\nCreated on 2019-02-09 by the reprex package (v0.2.1). And yes the plan is to eventually remove the re-exported functions completely and put usethis in depends.. I really dislike check() running document by default :(\nI think adding a quiet argument to document is the best option.. > Is there a reason why devtools can't simply just depend on usethis?\nYes, we wanted the use_*() functions to be depreciated in devtools, but still attach usethis to the search path, so only functions called with devtools:: would have a deprecation message. The problem with just using Depends is the devtools functions then come before the usethis functions in the search path, so you get deprecation messages when calling the unqualified function, e.g. use_readme_md().\nWe could now probably remove the deprecation messages for the next release and just use Depends.. Thanks! this looks good to me. devtools::run_examples(run = FALSE) should do it.. This is basically a duplicate of https://github.com/r-lib/remotes/issues/287. Thanks!. I would definitely not want document to render the readme, I at least usually have fairly heavy examples in my readme and run document many many times throughout the day. I generally only build the readme when I make a change to the text or am nearing a release.. It looks like the namespace is not locked until after .onLoad() is\ncalled, so it does work with a regular load as well.  I get no errors after\ninstalling the package in this pull request and (in a new session) calling\nlibrary(devtools).\nMy initial pull request used an environment as you describe and populated\nthe environment when load_all was called for the first time, but this\nmethod seems simpler as there is no need for these objects to change after\nthe package is loaded.\nC code missing was a silly mistake, thank you for pointing it out.\nThe situation this pull request is trying to remedy is when one package\n(\"test_package\") is loaded with load_all().  And a second package calls\none of the shim'd functions, e.g. system.file(\"unitTests\", package =\n\"test_package\").  Would what you proposed work in that case?\n. This is a fair point, I would actually prefer to just use rocker/r-base, but it seems incapable of installing devtools because of a missing curl dependency.\nYou think it would be possible to get a working R on https://registry.hub.docker.com/_/busybox/.  2.5 Mb base image is pretty appealing :smile:.\n. Also @krlmlr I wrote a blog post about this setup if you haven't seen it, http://jimhester.com/post/wercker-and-rocker-finally-performant-continuous-integration-for-r.  Your post and repositories were part of my inspiration for working on it, so thanks for blazing the trail!\n. @krlmrlr I started moving the with_ functions a few months ago, https://github.com/jimhester/robustr, made a few improvements (including more useful function definitions when printing), but I haven't had time to give it a final polish and convert devtools to use it.\n. I forgot trimws() was only available in new R versions.  We can replace it with trimws <- function(x, gsub(\"^[[:space:]]+|[[:space:]]+$\", \"\", x)) so we don't have to bump the version.\n. I think lengths is also only available in R-devel as well, I will use the appropriate vapply instead.\n. The github API returns a JSON object with a content field that is base64 encoded.  I think httr will decode automatically if the entire response is base64 encoded, but only part of it is in this case.\nIf there is a httr function I can use to do this decoding that would be great, I just missed it!\n. https://github.com/ropensci/git2r/issues/130 would seem to suggest no, I can try and hunt down the code in libgit2 and see how much work it would be to add to git2r\n. Wouldn't it be more clear to just lookup the user's configured git email and use that here?\nr\nc <- git2r::config(r)\nemail <- c$local$user.email %||% c$global$user.email\nWould do the job I think.\n. https://github.com/ropensci/git2r/pull/172 adds ls_remote() to git2r, which exposes this functionality to us.\nThis PR also uses git archive to download the file for plain git remotes.  I imagine git2r doesn't have this either.  I think it is lower priority though as plain git is used less frequently than github or bitbucket and people will likely already have a git client installed in that case.  They can always just set force = TRUE to revert to the current behavior of always installing the package.\n. Should be fixed by 4903b51\n. You are correct, this comment was partially copied from install() and I missed that. Fixed with https://github.com/jimhester/devtools/commit/1ca9e288079fef5dabcc804d747ba6c2c12a8b84 Thanks!\n. I kept that comment because for the devtools case we are forcing the promises to avoid the lazy load errors and because it lets us continue to use the functions when devtools is being reloaded.\nBut I am fine removing it if it seems confusing.\n. Yes! Fixed with https://github.com/jimhester/devtools/commit/ab8bae8508b9b656da095a2cb68d4163aaf74eb6. Having the two stop() calls right after each other looks a little ugly, but modifying the conditional to avoid them would be just as bad in other ways.\n. Works for me, done in https://github.com/jimhester/devtools/commit/7b378ee0e6a2afcbc21172e61a790f613f335b15\n. Done! https://github.com/hadley/devtools/commit/f4151b9da8e68051eadc4e9cc452648c520585e6\n. If we change this to the following it will give us consistent results with the legacy behavior if the package is not using git or has an unclean working directory.\nr\ncompact(list(\n    RemoteType = \"local\",\n    RemoteUrl = x$path,\n    RemoteSubdir = x$subdir,\n    RemoteSha = if (git_committed(x$path)) git_sha1(path = x$path)\n  ))\n. Actually I am wrong, just looked at the code for pkg_source https://github.com/hadley/devtools/blob/81dd313e1d143a3bdaaa2e1f09c887801db66694/R/session-info.r#L156-L159\n. unfortunately there is no isFALSE function in base R, but I can write one easily enough of course.\n. Theoretically you probably could, but it would require a patch to git2r, possibly . Using git archive --remote is really special case and we are using it as a hack to retrieve just a specific file from a git repository. There isn't really a standard way to do so normally with git.\nSo while it is probably possible to do I am not sure it is worth the time investment to add it to git2r. We have ways to get the file for the other remotes, just the raw git one needs to use this functionality so I think it is worth relying on the user having a git client installed. If they do not the behavior will be the same as the current behavior, which seems to be OK for most people.\n. Thanks for catching this, oversight on my part\n. Also this begs the question what the definition of isFALSE() should be. isTRUE() is defined as identical(TRUE, x), so anything but TRUE is FALSE. So we do not want identical(FALSE, x) but !identical(TRUE, x), so isFALSE() is a bit of a misnomer.\nIt is a small difference so I am happy to define isFALSE as !identical(TRUE, x), but it a slightly inaccurate name.\n. Wow, I clearly was too tired when I looked at it this morning.\n. I actually did this without an else on purpose because I wanted to add the metadata to both the binary description as well as the text description in the same way. Some functions only look at the text DESCRIPTION, others will use the binary if it is available, so I wanted the same results regardless.\n. I think it should be an error if neither can be found, but agree it is a good idea to check that case.\n. I am not sure the prior / during / after installation distinction is useful knowledge for the user and will likely just make things confusing. Just Named list of metadata entries to be added to the \\code{DESCRIPTION}. seems sufficient to me.\n. 0ec4145 defines a helper function so we don't have so much nesting.\n. ? why can't you move it to L362?\n. I think Hadley was talking about the package_txt variable definition, not the build_package_txt function definition.\n. This has been done at https://github.com/jimhester/devtools/commit/8bdb10bb92972cc26d02a0d1ef6c711c24bbec, let me know your thoughts...\n. Dependencies are all done in install() itself which calls install_deps() so we don't have to worry about it here.\n. Done at https://github.com/jimhester/devtools/commit/16dbe00e4bc70bcd3eb0d2e09e2c221c39860715\n. Ah true, I forgot you could do that based on the class of the error.\n. I guess the issue was what happens when the response is not from GitHub but somewhere else and is not JSON but another format? Then \ntext <- httr::content(req, as = \"text\")\nparsed <- jsonlite::fromJSON(text, simplifyVector = FALSE)\nIs going to throw an error, but in that case we don't care about the parsing error, we just want to return the stop_for_status of the response.\n. Maybe a simpler plan would be to write a download_github() function and call that instead of download() from install_github.\n. Yep sorry, copied this code from an old blame before we were using httr:: and I missed fixing this line. Fixed in d5c2750\n. Gahhhhh!\nOk I reviewed this whole thing again, 413300a should actually be correct.\n. You are correct, fixed with 199b0c2eab7e67af06586d1c2eda8fe34add2f36. Thank you for catching that I clearly was not thinking it through correctly.\n. Yeah I guess you are right this function should\n1. If GITHUB_PAT is set, use that (say Using github PAT from envvar GITHUB_PAT)\n2. If GITHUB_PAT is not set and in a CI, use the default PAT (with appropriate message?)\n3. Otherwise return NULL\n. 5000 is a lot better than 60 though! Plus we could always generate a bunch of tokens and randomly pick one to even out the distribution if it really becomes a problem.\n. Done, c8c5e6d\nThis was a good suggestion BTW, I actually had the parenthesis wrong and the class argument was being used in list() rather than structure().\n. Done https://github.com/hadley/devtools/pull/1121/commits/5b01dadfd5dcf8f0b7372d3b659336e37e6f010e\n. Oh you should definitely not publish tokens. In fact GitHub will automatically revoke them if they are plaintext in any commit (which is why I had to split it up).\nI think the API is used because GitHub enterprise instances won't necessarily have a archive/master.zip link but most Travis builds are going to be using public GitHub so it is probably worth using the normal link in the common case.\n. Ugg, fixed in https://github.com/hadley/devtools/pull/1085/commits/d9a7d67c525b0495689832e22e597766d6e11481\n. How much indentation? Just one additional level or to line up with function?\n. Great that is what I did :smile:!\n. Yeah removing this looks right, I just ran into this as well when debugging Kirills' dtplyr issue.\n. I think Enhances should be fine to installed in the initial installation. Note Enhances: are not installed unless explicitly set by default (see ?install.packages).\n\nlogical indicating whether to also install uninstalled\npackages which these packages depend on/link\nto/import/suggest (and so on recursively).  Not used if\n\u2018repos = NULL\u2019.  Can also be a character vector, a subset of\n\u2018c(\"Depends\", \"Imports\", \"LinkingTo\", \"Suggests\",\n  \"Enhances\")\u2019\nOnly supported if \u2018lib\u2019 is of length one (or missing), so it is\nunambiguous where to install the dependent packages.  If this is not the case\nit is ignored, with a warning.\nThe default, \u2018NA\u2019, means \u2018c(\"Depends\", \"Imports\",\n  \"LinkingTo\")\u2019.\n\u2018TRUE\u2019 means to use \u2018c(\"Depends\", \"Imports\", \"LinkingTo\",\n  \"Suggests\")\u2019 for \u2018pkgs\u2019 and \u2018c(\"Depends\", \"Imports\",\n  \"LinkingTo\")\u2019 for added dependencies: this installs all the\npackages needed to run \u2018pkgs\u2019, their examples, tests and\nvignettes (if the package author specified them correctly).\nIn all of these, \u2018\"LinkingTo\"\u2019 is omitted for binary\npackages.\n. The extract_lang() function always returns a list of functions it found, so just returning the first item. extract_lang() should probably do this automatically...\n. The only increased scope is the for loop indexing though, which is just a list, so if nsInfo$imports doesn't exist it will just return NULL, which won't throw any conditions.\n\nI agree in general it is nice to keep the scope small, in this case I don't think it can change the behavior and it will be quite a bit more work to modify each for loop appropriately.\n. Ah I see now, because the tryCatch is around each iteration in the loop rather than the whole thing.\nOk I will get that working as before then.\n. Yeah it does (just checked). I wonder we could come up with an easy test for fully exported namespace and set export_all based on that...\n. There is no point in having %||% NULL, the right hand side will only be used if the left hand side is already null, so you should just pass x$auth_token directly to download.\n. This seems an unnecessary complication, why can't you just have https://api.bitbucket.org be the default host?\n. Rather than creating a new generic maybe we should change the existing github_resolve_ref generic to resolve_ref and have methods for github and bitbucket pull and releases appropriately.\n. I think rather than duplicating this logic it would be better to have a function which takes a path, regex and names and returns the result that can be used both here and in parse_git_repo().\n``` r\nparse_repo <- function(path, rx, nms) {\n   replace <- stats::setNames(sprintf(\"\\%d\", seq_along(nms)), nms)\n  params <- lapply(replace, function(r) gsub(rx, r, path, perl = TRUE))\n  if (params$invalid != \"\")\n    stop(sprintf(\"Invalid repo: %s\", path))\n  params <- params[sapply(params, nchar) > 0]\nparams\n}\n``\n. If both of these regexes are exactly the same there is no need for these conditionals.\n.httr:GET()` can accept a url object directly, so this can be replaced by the following.\nr\nurl <- httr::parse_url(host)\nurl$path <- paste(url$path, path, sep = \"/')\nreq <- httr::GET(url, github_auth(pat), ...)\n. I think this function should be rewritten to query the API for the repo and return the html_url and issues_url from the response (https://developer.github.com/v3/repos/#response-3) rather than special casing the api.github.com url.\nThe issues_url returns https://api.github.com/repos/hadley/devtools/issues{/number} so the {/number} needs to be stripped first.\nr\nres <- github_GET(\"repos/hadley/devtools\")\ngithub_URL <- res$html_url\nissues_URL <- sub(\"\\\\{/number\\\\}\", \"\", res$issues_url)\n. Ah you are right, my apologies, I think appending '/issues' to html_url is the right thing then.\n. L138 and L141\n. Ah you are right about them being different, my mistake. \nIf we are just ignoring everything but the user/repo slug they might as well be combined I think.\n. I am not seeing this behavior\n``` r\nhost <- \"https://api.github.com\"\npath <- \"users/hadley/repos\"\nurl <- httr::parse_url(host)\nurl$path <- paste(url$path, path, sep = \"/\")\nhttr::build_url(url)\n> [1] \"https://api.github.com/users/hadley/repos\"\nhttr::GET(url)\n> Response [https://api.github.com/users/hadley/repos]\n>   Date: 2016-06-08 20:20\n>   Status: 200\n>   Content-Type: application/json; charset=utf-8\n>   Size: 155 kB\n> [\n>   {\n>     \"id\": 40423928,\n>     \"name\": \"15-state-of-the-union\",\n>     \"full_name\": \"hadley/15-state-of-the-union\",\n>     \"owner\": {\n>       \"login\": \"hadley\",\n>       \"id\": 4196,\n>       \"avatar_url\": \"https://avatars.githubusercontent.com/u/4196?v=3\",\n>       \"gravatar_id\": \"\",\n> ...\n``\n. Looks like the difference is https://github.com/hadley/httr/commit/2f6baa0b98c9eaf632acc43ede3be2b187893ba3 (I am using devel httr)\n. Yeah please do\n. I think we should be consistent with the Github convention and call the environment variable BITBUCKET_PAT and functionbitbucket_pat(). I think this test should belength(userpwd) == 2` and we should have a more useful error message\nr\nparts <- strsplit(x$auth_token, \":\")[[1]]\nif (length(parts) != 2) {\n  stop (\"`auth_token` needs a username and password separated by a colon\", call. = FALSE)\n}\n. This is no longer true right? Can we run these tests on the CIs now?\n. Thanks, fixed!\n. Could you get rid of the trailing line here\n. No it still generates the  NOTE\nns_registry: no visible global function definition for\n  \u2018getNamespaceRegistry\u2019\n. Ok, good idea! https://github.com/hadley/devtools/pull/1283/commits/eaa21c510c9c6cc3a344bfb847c7985bc03dfd8f#diff-16f1b7f2a08c02db5035892c22a81eeeR35\n. We could have a R option or environment variable for all of the check_suggested() stuff to automatically install them if they are missing (and not prompt).\n. They are likely packages that were rejected for Bioconductor for whatever reason and the authors did not remove the BiocViews field.\nWe could add a bioconductor argument to dev_package_deps() which would allow you to turn off the check like we have in check_cran().\n. Sure, done in 7d7e6af\n. Missing an e in package.\n. Maybe we should allow setting the email as an extra parameter? I know there have been a handful of times I wanted to check a package on win-builder I was not the normal maintainer for.\nIt also would be handy for checking PR before sending them.\n. Don't know how heavy-weight rhub is, but maybe this should be in Suggests() with a devtools::check_suggested().\n. method = 'wget'and method = 'curl' require that those executables be installed on the users system and on the PATH. This is not the case on windows unless the user has Rtools installed and the Rtools directory on the path. We should just be calling utils::download.file without the method set to respect the users choice of preferred download method.\nIf you personally like being able to continue downloads you can set options(download.method.file = \"wget\", download.method.file.extra = \"--continue') in your .RProfile and have this happen for all calls of download.file().\n. This was deliberately done using a regular http request rather than using the GitHub API because we were regularly hitting the unauthenticated GitHub API rate limits on Travis. That problem has since been ameliorated, so this is probably a reasonable change...\n. This function should be in R/github.R and should be named github_contents(). It also needs to pass along the ref parameter from the remote, the code as written assumes retrieval from the HEAD of the repository (see the ref parameter).\n. The code in devtools predates the introduction of this endpoint.\nHowever https://developer.github.com/changes/2016-02-24-commit-reference-sha-api/ mentions a couple of things this PR does not do.\n1. The Accept header needs to be set to application/vnd.github.VERSION.sha.\n2. ETags should be used with the local SHA, the response will return a 304 Not Modified if the SHA is the same. ie.\nbash\ncurl \"https://api.github.com/repos/Homebrew/homebrew/commits/master\" \\\n  -H \"Accept: application/vnd.github.chitauri-preview+sha\" \\\n  -H \"If-None-Match: \\\"814412cfbd631109df337e16c807207e78c0d24e\\\"\"\nUsing 2. prevents this call from decrementing the rate limit and reduces load on GitHub's servers.\n. devtools always forces a type of binary https://github.com/hadley/devtools/pull/1339/files#diff-e7118181d76027ea30ccf5babc54f550L51, which means you never have a interactive dialog asking if you want to install.\nThis PR sets option(\"install.packages.compile.from.source\" = \"never\"), which effectively means the same as forcing a type of \"binary\" if type = 'both', unless there is no binary available (such as drat repositories), in which case it will compile the package.\n. I think something like the following would be clearer. The distinction between package name and repo name while correct is fairly rare and just muddies the waters.\nRemotes: specifies the source of a development package, the package still needs to be listed in Imports:, Suggests: Depends: or  LinkingTo:. e.g. Imports: ggplot2 in the above example.. getRversion() < \"3.2.0\"?. assignInMyNamespace might be a better alternative here.. So is this good to merge then? The changes in rcmdcheck would be unrelated to this PR I think, since we are always explicitly building the package before checking.. Done!. Yeah that makes sense, the query wouldn't have to be altered for this, just the regular expression tweaked a little. I would use covr::report(). I think I am going to be removing the shine() alias in the near future, as it no longer produces a shiny app, so doesn't really make sense.. FWIW I generally think you should default to the first argument, just because that is the normal convention. In this particular case I wanted to have different default behavior when run non-interactively, so needed to do this.\nMaybe I should have used error_on = NULL so could have had the logic only in one place rather than two, I am not sure.... I think in that case I would not use missing() and would use something like.\nincrement = c(\"none\", \"major\", \"minor\", \"patch\", \"dev\"). I removed this mainly because it was useful for running revdep checks, it was added in https://github.com/r-lib/devtools/pull/1284 and we no longer use devtools to do this.\nIt also makes the user experience when installing a single repository worse, as there is no longer an explicit error on failure to download the package.. Yes, the vignette has no R code, which is why there is nothing here. Yes, that is right. I added this option mainly because it was taking a while to install the package when I was writing / testing this. We could alternatively just remove the option.... I don't know about whether to check in or not, maybe we should not, but the benefit would be users would not have to build vignettes themselves. You would have to update it with devtools::build_vignette().\nIntermediates like .md are challenging to deal with without special casing rmarkdown vignettes and rendering them separately. It is somewhat questionable how much utility they have particularly now that we have pkgdown to view devel vignettes.. We can remove this conditional, the only way you could be in this block is by being less than \"6.1.0\". I think we should probably leave styler out of Suggests. While it is nice to have it as a hint for contributors it has a non-trivial number of dependencies which would need to be installed on the CI systems for each build. So if we aren't actually going to use it there I think it would be better to omit it.. ",
    "davharris": "Oops, sorry for the duplicate.  Thanks again\n. ",
    "gsk3": "I thought I was using the latest, but clearly I'm not.  Sorry about that.\nHappy new year!\nOn Sun, Dec 23, 2012 at 7:39 PM, Winston Chang notifications@github.comwrote:\n\nTry installing the newest version of Rcpp -- it should have the cpp_filesargument.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/221#issuecomment-11652517.\n. \n",
    "lucacerone": "Sorry has this issue been solved? How can I make the dataset in inst/extdata/dataset.rda available for internal use by functions?\n. Thanks, I was having issues because I was trying with \"inst/extdata\" and of course things were not working! Thanks for the link, I wasn't aware of the group!\n. Oh sorry I didn't get this reading the manual.\n. I also tried to use install_git(\"https:/address.git\") but the effect is the same.\n. Hi @wch I think one of the possible causes of errors is becuase in Windows you have both a\nUSERPROFILE variable and a HOME variable; on my computer HOME was set to the same path\nwhere the .ssh folder with the public and private keys are, but USERPROFILE was not.\nI got confused, because if I asked RStudio to see the public key, it was shown just fine, \nbut then running `system(\"git clone gitrepo .\") didn't work, while git works just fine in both\ngit-bash and cmd.exe.\nChanging HOME and USERPROFILE to be the same and where .ssh is, fixed the issue for me.\nAnyway, in the event install_git doesn't find the proper key, I think it should return an Error rather\nthank hanging and blocking R (possibly suggesting to fix the environment variable); does that make sense?\n. Thanks @hadley and @wch. I agree absolutely that it should prefix inst to  simulate the behaviour of the base::system.file when you have to access a file that is in inst and it will be copied to the root later. My point is that it can resemble even more the base one by checking whether as.list(...) is an empty list, or it contains only an empty character, and in that case just return pkg_path before prefixing inst and doing all the next steps.\nReading the code (thanks I wasn't able to find it), it doesn't look like this would break existing functionalities, but I might be wrong of course. I could try to do it myself and push a pull request, but if you prefer to keep it this way I understand :+1: \nThanks a lot for all the clarifications!\n. unfortunately none that I can share... and I am not able to find the logic behind the bug....\n(if I have time I'll try to create a mock package reproducing the bug).\nSometimes when I load_all() there is a message saying that some functions are being added to the Collate field, but then they are not added (though the functions work just fine in the R shell) in the DESCRIPTION.\nWhen this happens if I document() and then install() I get an error saying that the same functions are not in the Collate field. If I add them manually then everything works fine.\nI have found that document() sometimes fail to create correct documentation if there is an extraspace between #' and the roclet, for example\n```\n' @describeIn fun1\n```\nproduces good documentation, \nbut\n```\n'    @describeIn fun1\n```\ndoesn't (the file fun1 is produced, but the \\title are messed up and sometimes empty (like \\title{})\nwhich makes impossible to install.\nI have found that this was the case for the functions that were not added. Removing the extra spaces produced good documentation, but still they were not added to DESCRIPTION.\nI am sorry I can't help you more with this, I hope I can make a reproducible example soon!\n. Thanks Hadley!\nIs git2r a new introduction to devtools or has always been there?\nThe problem you mention with git2r config is something that I should fix on my side? can you point me to some guide for this?\n. The issue is not present with R 3.1.3 (that I have at home), so I can't reproduce the issue.\nI'll try again with my laptop at work (where I have R 3.2.0) and try to figure out why it happens.\nI have seen there are several git2r repos in github, which is the official one? I guess it is the cran/git2r, but would like to be sure.\nThanks a lot again for your help with this!\n. Thanks! It turns out is is an issue with a missing C library, libssh2.  Installing that fixes the issue.\n. thanks (embarassed)\n. I am having issues too with Remotes in the DESCRIPTION.\nIf in R is use devtools::install_git(\"https://mycompany.com/project.git\") the package is installed correctly.\nWhen in the DESCRIPTION file I add:\nRemotes: git::https://mycompany.com/project.git\nthen when I use devtools::install(\".\") to install the package and check that dependencies are resolved I get the error:\n\nInstalling rpackage\nError in vapply(remote, remote_package_name, character(1)) : \n  values must be type 'character',\n but FUN(X[[1]]) result is type 'logical'\n. the same applies to install_git, it doesn't work anymore if you don't provide an argument to quiet. \n",
    "zhenglei-gao": "After running the script at https://gist.github.com/4506250, the package devtools cannot be correctly loaded. Here is what I got:\n> require(devtools)\nLoading required package: devtools\nScanning path...\nls : c:\\Rtools\\bin\\ls.exe \nScanning registry...\nFound c:/Rtools for 2.16 \nError : .onAttach failed in attachNamespace() for 'devtools', details:\n  call: installed_version(from_registry$path)\n  error: argument \"debug\" is missing, with no default\n> traceback()\n2: stop(gettextf(\"package/namespace load failed for %s\", sQuote(package)), \n       call. = FALSE, domain = NA)\n1: library(devtools)\n. Now it works. has_devel() returns TRUE\nThanks a lot for your work.\n. A related question:\nI don't know what I did but when I run check()again it gives a warning which did not exist before:\n* checking for missing documentation entries ... WARNING\nUndocumented code objects:\n  'autolayout'\nStrangely, the autolayout.Rd file exists under the /man directory after running roxygenize but not in the built tar ball. What could cause the problem? \n. I have tried to remove all the .R files and add back as .r files back to Github, but the same error occurs. I will check again if there is other mismatch.\n. In case anyone is interested, for the second problem, the cause is in .Rbuildignore file. I put out there,  which makes the build overlooked the function autolayout.\n. ",
    "SutherlandRuss": "I have received the same error as @zhenglei-gao when running has_devel() on windows & using R studio and R 3.0.2.:\n```\nhas_devel()\n\"C:/PROGRA~1/R/R-30~1.2/bin/x64/R\" --vanilla CMD SHLIB foo.c \nError: Command failed (1)\n```\nWhen I  restart R, run the script at https://gist.github.com/hadley/4506250 and then re-run library(devtools) I get the error:\nlibrary(devtools)\nError: package \u2018devtools\u2019 was built before R 3.0.0: please re-install it\nAs far as I can tell my problem may lie in the linked devtools package being built for R 2.x\nI am unsure how to fix this error. Do you know how I could install devtools successfully please?\n. I had a problem with my Rtools installation. I re-installed Rtools, then used the devtools from cran and the error has been fixed. \nThanks for your advice.\n. ",
    "tbs08": "hi Hadley,\nI used the script from https://gist.github.com/hadley/4506250 and i got the below error:\n\ninstall.packages(temp, repos = NULL)\nError in install.packages : type == \"both\" cannot be used with 'repos = NULL'\nfile.remove(temp)\n[1] TRUE\n\nwhat did i miss?\n. ",
    "eshilts": "Do you know of anyone working on the custom repository situation? It didn't seem like there was any movement to make CRAN-like repositories more widely available when I asked about it on StackOverflow and on the r-devel mailing list.\n. Do you know of documentation of how the CRAN repo works as far as archiving, directory structure, dealing with windows/mac/source packages, etc? The rails/sinatra option doesn't sound too bad but specs would help.\n. ",
    "eddelbuettel": "Thank you :)\n. Yes and I now have but I \n- dislike having to do that over and over for each project on each machine\n- devtools is still wrong, whether I choose to ignore it or not\n. And, of course CRAN is perfectly happy to display a ChangeLog file alongside a NEWS and README file -- eg Rcpp has all three, as do a few others of my packages.\n. Yes, I would welcome that.\nI would also welcome a fix to the 'ChangeLog does not belong here' issue.  At best, you are imposing personal preferences. The file is a GNU coding standard.  You can do better than this.\n. Thank you.  We can leave the devtools change to its strong-willed maintainer.   \nConfigure.in also belongs in a tarball if I as maintainer decide it belongs. It governs / documents the build and is source code. \nOverall, one cannot simultaneously complain about CRAN Policy being inconsistent and poorly communicated and then make up one's own checks out of this air like this.  I am really surprised by this, and not in positive way... \n. Thanks for the feedback. I'd be happy to help, time permitting.  \nRe 1), we'd need a clear pulished list to go by. Otherwise locally extending what is guestimated to be R CMD check's intent is madness.  I am all for checking leftover / backup files from editors, IDEs etc but actual working source is where I draw the line.\n. Do you have Rtools installed?\n. Step way back.  Maybe consult the RStudio documentation on building R packages and many of their other documentation entries.  The RStudio IDE checks for matching RTools etc pp.\nIn essence, you never built an R package, and need to work through this.  It is documented in many places, please do not expect us to repeat it all for you here.\nI suggest @hadley closes this.  There is no devtools issue.\n. Actually, I think you as OP could close this too.  Please do.\n. That's why some of us install packages from the command-line.  Littler is still your friend.   Never had this issue.  (Note that OP is off the island anyway as he uses Windows which famously has all sorts of other issues.)\n. Oh, and @jennybc I don't think install_github() has anything to do with it.  At the end of the day it still calls install.packages() on a tarballs just like the Founding Fathers intended.   It just uses a non-standard way of getting that tarball...\n. > That's why some of us install packages from the command-line.\n-- Me, on Sep 30\n. Also, the discussion in the remotes vignette fails to mention drat use.  Given that CRAN supports it, and other packages use it, you may want to mention this (as a non-devtools alternative).\n. @jimhester could do if you think it fits -- I was mostly coming from the 'well remotes is not the only way to do this' angle of actually mentioning the fact that CRAN now formally supports Additional_repositories.  The remotes documentation, focused as it is, seems to imply it was the only game in town.\n. ",
    "imanuelcostigan": "Using devtools master, I get, using @wch suggestion:\nLoading marketholidays\nLoading required namespace: data.table\nError in readChar(con, 5L, useBytes = TRUE) : cannot open the connection\nIn addition: Warning message:\nIn readChar(con, 5L, useBytes = TRUE) :\n  cannot open compressed file '', probable reason 'No such file or directory'\n@hadley \nI didn't realise that such a thing existing. I'll check it out.\nI haven't experienced any problems with my fork of devtools. Does the change I suggested mess things up elsewhere?\nCheers.\n. sysdata.rda works well. Thanks @hadley. R development has a lot of idiosyncracies!\n. It's a problem on both CRAN and the latest github vesion.\n. nope, seems to have been resolved:\n```\n\nsessionInfo()\nR version 3.0.3 (2014-03-06)\nPlatform: x86_64-apple-darwin13.1.0 (64-bit)\n\nlocale:\n[1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] x_0.3.1.12 lubridate_1.3.3     testthat_0.8.1   \n[4] devtools_1.4.1.99  \nloaded via a namespace (and not attached):\n [1] assertthat_0.1  codetools_0.2-8 digest_0.6.4    evaluate_0.5.1 \n [5] httr_0.2        memoise_0.1     parallel_3.0.3  xx_0.6 \n [9] plyr_1.8.1      Rcpp_0.11.1     RCurl_1.95-4.1  stringr_0.6.2\n[13] tools_3.0.3     whisker_0.3-2\n``\n. I'm done on this unless you have any further feedback.\n. Not sure why this is a more natural fit for packrat. Would you be able to elaborate? Seems to me that packrat is designed for specific projects and not really about system wide actions\n. :+1: \n. Actually its harder...you need to regenerate the token if you didn't copy the token when generated. \n. I'm having issues withinstall_github()` using master branch of devtools. I'm getting 406 errors. I get this when I'm trying to install from a public repo (e.g. klutometis/roxygen) and from a private repo (say one of mine). When reverting back to CRAN, installing from public repo works fine (no 406 errors).\n. My fork is working fine for public repos. It's giving me 406 errors for my private repos. What options are ticked in your Account Settings > Applications > Edit personal access token (for devtools)?\nI have:\n1. repo\n2. user \n3. gist \nticked. The others are blank. \nd> install_github('imanuelcostigan/blah')\nInstalling github repo blah/master from imanuelcostigan\nDownloading master.zip from https://github.com/imanuelcostigan/blah/archive/master.zip\nError: client error: (406) Not Acceptable\n. repos = private repo (see the info pop over)\nAlso from the API docs:\n\nrepo: Grants read/write access to code, commit statuses, and deployment statuses for public and private repositories and organizations.\n. Ignore the first commit. Deleted the my fork because there were big diffs...I started from scratch, see second commit...See pull request #445 \n. Tim, whilst your suggestion has some conceptual overlap with this issue, I think a new issue (and pull request) should be created.\n\nI'm happy with my devtools PAT being sucked in from an envvar (no need to save in script). I can set fairly restrictive permissions to that particular PAT and the PAT can be revoked when I believe it to be compromised (I can see account activity on github.com). \nAs such I'm closing this issue.\n. In what sense is it more customary? Setting it up as an environment variable makes it trickier for the user - especially if they don't have the required permissions or technical knowledge. The devtools .onLoad() function sets a number of different options. \n. Right, I'll patch.\n. For those on Mac OSX (Mavericks), this stack overflow answer worked for me, but contrary to the comments, I needed to restart OSX to get R to recognise this.\nI suspect setting the envvar on Windows is more straightforward (assuming you have the permissions to do so).\nOf course, you could set the github.pat environment variable in .First() using a call to Sys.setenv(). This is probably easier for most people. And unlike setting the envvar at a system level, this one isn't liable to change with every release of OSX.\n. This is ready \n. Assume the convention is to leave pull requests open?\n. Neat, good to learn from your style.\n. See policy change diff communicated on 19 Aug 2014. Seems like they don't want ftp transfers or emails unless form fails.\n```\n@@ -288,25 +309,16 @@\n@node Submission,  , Binary packages, Top\n@unnumbered Submission\n-When submitting a package to CRAN you should @strong{either}\n-@itemize\n+When submitting a package to CRAN you should use the submission form at\n+@uref{http://CRAN.R-project.org/submit.html} (and not send an email).\n+You will be sent a confirmation email which needs to be accepted.\n-@item\n-use the submission form at @uref{http://CRAN.R-project.org/submit.html}\n-(and not send an email).  You will be sent a confirmation email which\n-needs to be accepted.\n+If this fails, upload by anonymous @command{ftp} to\n+@uref{ftp://CRAN.R-project.org/@/incoming/} and send a (plain text\n+ASCII) email at the same time, with subject line as specified below.\n-@strong{or}\n-@item\n-upload by anonymous @command{ftp} to\n-@uref{ftp://CRAN.R-project.org/@/incoming/} and send a (plain text ASCII)\n-email at the same time, with subject line as specified below.\n-\n-@end itemize\n-\n``\n. See #1220 \n. I have a package that creates someoptionsettings through the.onAttachhook. My test helper files require these options. Unfortunately, devtools runs the package hooks **after** sourcing the test helpers and breaks things for me. Why can't the test helper files be loaded after the package is attached byload_all()`?\n. @hadley would you be open to me submitting a PR with the effect of sourcing the test helper files after running hooks?\nPS - check() passes without error after making this change.\n. is it bad form to :+1: ones own issue? Too late...\n. Notes:\n- Current code base can install private and public Bitbucket hosted R packages.\n- Cannot download zip/tarball of repo through API (v1 or v2). Need to guess naming convention from Downloads section of repo website.\nTasks:\n- [X] Work out Bitbucket vs Bitbucket Server (formerly known as Stash) API differences. Ans: See links, they are quite different.\n- [X] Confirm that Bitbucket doesn't have Github-like PAT functionality which replaces need for username/password pair. Ans: They do not support API keys (aka PATs). They only support basic auth (u/n and p/w) or OAuth ~~(which isn't particularly useful for CLI based application like R)~~. Can use httr package support for OAuth to retrieve (and auto-refresh) access tokens in a relatively straightforward fashion cf. process for GitHub process (see below).\n- [X] Can we read username/password values in by default from an option / env var? Using option might be better as this could be coupled to host specification in an option (see below). Ans: As Bitbucket and Bitbucket Server APIs are quite different, will create separate process for Bitbucket Server so this isn't necessary.\n- [x] Check how to specify port number for Bitbucket Server \n- ~~[ ]  Work out whether host parameter approach used for install_github makes sense. It's a bit difficult to remember the host name for an enterprise instance of Github or Bitbucket. Should this be stored in an R option / environment variable?~~\n. ## OAuth2.0\nUser setup:\n1. Create an OAuth consumer key from https://bitbucket.org/account/user/{USERNAME}/api\n2. Create two environment variables: BITBUCKET_CONSUMER_KEY and BITBUCKET_CONSUMER_SECRET that store resulting key/secret pair. See vignette(\"api-packages\", \"http\") appendix for steps to set up across all systems.\n3. Call bitbucket_pat() which does the OAuth handshake and retrieves an access token and caches to ~/ (does this fall afoul of CRAN rules?). See https://github.com/imanuelcostigan/devtools/commit/d29084e2e36228123d87a72be5864bbec9678092\n. ## Bitbucket Server\nWill create separate set of functions supporting install_bitbucket_server() as bitbucket.org and Bitbucket Server are different products with different APIs.\n. Note that Bitbucket Cloud now supports PATs. Binned OAuth approach and will implement PAT approach. \n. See #1157 \n. I am not sure what is causing the following error on check():\n```\nE  checking tests\n   Running the tests in \u2018tests/test-that.R\u2019 failed.\n   Last 13 lines of output:\n        })\n     4: FUN(X[[i]], ...)\n     5: stop(\"Function \", name, \" not found in environment \", environmentName(env), \".\", \n            call. = FALSE)\n Updating collate directive in  /private/var/folders/9f/kz67r0rn3qb9tx_rmgbps94r0000gq/T/RtmpDcLHv0/testCollateOrder/DESCRIPTION\n\n testthat results ================================================================\n OK: 364 SKIPPED: 7 FAILED: 1\n 1. Error: Bitbucket remote build works (@test-bitbucket.R#33)\n\n Error: testthat unit tests failed\n Execution halted\n\n```\nWhen I run test(filter = \"bit\"), tests all run correctly.\n. Hot off the press! Bitbucket just released app passwords (aka PAT). This is for those with and without 2FA turned on (which the blog post isn't clear about), but the docs are.\nI'll look into this in more depth on the weekend. But it's looking likely that I will close this PR and submit a new one. I'll refer back to the feedback provided above in any new PR.\n. @hadley Replaced by #1220 \n. @hadley done\n. We have been having very strange issues using install_github at work where on some Windows machines, the zip file is showing up as corrupted an can't be unpacked, while on others there are no issues. I should note that manually downloading zip file using browser and trying to unpack also results in same errors for those who had errors using install_github. Though interesting, manually extracting contents of zip file directory by directory seemed to work. \nWill be interesting to see whether this change makes this issue go away. If so, \ud83d\udc4d \n. @jimhester I should also apologies for continued use of merge vs rebase. I'm not proficient enough to use rebase safely so I've stuck with merge. It doesn't look nice in project history, but I'd rather contribute than not. \n. @jimhester updated PR with changes per your feedback. Thanks!\n. @hadley @jimhester I'm skipping remote build tests. Works locally for me, but not sure why this isn't working with_mock. Ready for merge from my end.\n. @jimhester @hadley seeing as 1.12.0 has been released, should milestone for this be updated? When are you likely to merge this back in? \n. @jimhester will this make it into the next update? . @hadley I have implemented bitbucket interfaces into the ghit package https://github.com/cloudyr/ghit\nI'll look to do the same for remotes package. This looks like the same bug that has been bedevilling my team for years (!). We all have Windows 7 x64 PC, each with the same corporate \"build\" and have same admin privileges. Yet install_github() works on my PC, but not on any other person's PC. Everyone else has this same issue. See this SO thread: https://stackoverflow.com/questions/41293748/unzip-fails-using-install-github/41293968\nIn particular, note this behaviour:\n\nwhen they download the zip directly from Github's website and try to extract into their user folder, they get the same behaviour from Winzip, but 7-zip can successfully unpack the file.\n\nI've spent quite a bit of time debugging this all to no avail. Squashing this bug would be massive for us.\n. @hadley getOption(\"unzip\") yields \"internal\" for me.\n@pgwatson @jonathanrandall can you please add what you get from the same command to this thread? \nThanks. @hadley let me know if my team or I can help provide you any more info. . @jimhester I'm pretty sure that the issue isn't caused by either of those. We continued to see the same error when setting a different temp directory that users definitely had read/write access to and the directory was not being removed as we were able to see the directory after the process failed. In fact, unzipping the package failed using WinZip with the same sort of error in a user directory. \nIn summary, what we have found was the unzipping the package:\n\nworked for everyone using 7-zip\nworked for everyone using Github compiled unzip (but per comment above, GH's unzip is compiled differently to the one bundled by R, even though they are the same version)\nworked for me using WinZip but no one else\n\nworked for me using R bundled unzip code, but not for anyone else in my team\n. install_github() has now stopped working for me on my new machine. Following @pgwatson suggestion above, here's a work around: \n\n\nDownload and install Git. \n\nSet the unzip option to version of unzip.exe supplied by Git e.g. options(unzip = \"c:/Program Files/Git/usr/bin/unzip.exe\"). You can obviously set this option at startup by adding this the .First() function definition in your .Rprofile.\n\nEverything now works.. I've actioned this in pull request #385 - particularly edcd5aa\n. @hadley Which block?\n. Done\n. Agreed \n. that makes sense. Should I include this change in my PR?\n. ",
    "mronkko": "My use case is to develop R scripts on my computer and then upload these to a shared server and run them there. I am not the admin for the server, so upgrading is not an option. (I could of course compile R and install it into my home dir, but this seems an overkill for the problem.)\nI will build the package myself and see if I can get it to work on 2.14\n. It seems that not all the dependencies install on 2.14, so decreasing the version requirement would not work.\n. I believe that this is a bug in R itself, because the same problem occurs also when installing packages from locally checked sources with R CMD INSTALL. This only occurs on my Mac and when running R in terminal, but not when running R.app. The difference is that in terminal, the temporary directory contains spaces whereas in R.app the temporary directory name does not contain spaces.\n```\nR version 3.0.1 (2013-05-16) -- \"Good Sport\"\nCopyright (C) 2013 The R Foundation for Statistical Computing\nPlatform: x86_64-apple-darwin10.8.0 (64-bit)\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\nNatural language support but running in an English locale\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\nSys.getenv(\"TMPDIR\")\n[1] \"/private/var/folders/40/c9p1lf_905jdjpymvkn_mvkw0000gn/T/Cleanup At Startup\"\nlibrary(devtools)\ndev_mode(on=T)\nDev mode: ON\nd> install_github(\"MplusAutomation\", user = \"mronkko\")\nInstalling github repo(s) MplusAutomation/master from mronkko\nDownloading MplusAutomation.zip from https://github.com/mronkko/MplusAutomation/archive/master.zip\nInstalling package from /private/var/folders/40/c9p1lf_905jdjpymvkn_mvkw0000gn/T/Cleanup At Startup/RtmpdKojxO/MplusAutomation.zip\nInstalling MplusAutomation\n'/Library/Frameworks/R.framework/Resources/bin/R' --vanilla CMD INSTALL  \\\n  '/private/var/folders/40/c9p1lf_905jdjpymvkn_mvkw0000gn/T/Cleanup At  \\\n  Startup/RtmpdKojxO/MplusAutomation-master' --library='/Users/mronkko/R-dev'  \\\n  --with-keep.source --install-tests \n\n\ninstalling source package 'MplusAutomation' ...\n R\n inst\n preparing package for lazy loading\n help\n installing help indices\n* building package indices\n installing vignettes\n   'Vignette.Rnw' \n** testing if installed package can be loaded\nsh: /private/var/folders/40/c9p1lf_905jdjpymvkn_mvkw0000gn/T/Cleanup: No such file or directory\nERROR: loading failed\nremoving '/Users/mronkko/R-dev/MplusAutomation'\nrestoring previous '/Users/mronkko/R-dev/MplusAutomation'\nError: Command failed (1)\nd> sessionInfo()\nR version 3.0.1 (2013-05-16)\nPlatform: x86_64-apple-darwin10.8.0 (64-bit)\n\nlocale:\n[1] C/UTF-8/C/C/C/C\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.3\nloaded via a namespace (and not attached):\n[1] RCurl_1.95-4.1 digest_0.6.3   evaluate_0.4.4 httr_0.2       memoise_0.1 \n[6] parallel_3.0.1 stringr_0.6.2  tools_3.0.1    whisker_0.3-2 \nd> \n```\n. Submitted a bug report to R tracker\nhttps://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15422\n. ",
    "wibeasley": "If this helps diagnose anything, the package (version 1.201) was built successfully by R-Forge for all three OSes: https://r-forge.r-project.org/R/?group_id=1330\nThe widely permission exportPattern (see (2) in my initial post) was NOT included in that namespace file (see here).\n. I agree it's not a big problem, and it's unusual that an error/warning arises in one OS and not the other (which is relevant b/c win-builder won't catch a Linux-specific problem).\nI understand if you don't think it happens frequently enough to justify the extra step.  Tell me if your threshold shifts in the future.\n\nAnd I really appreciate the release() function.  I updated all four of my CRAN packages in the past week, and was losing track of what changes I made to each package.  This function caught two things that slipped through the cracks.\n. ",
    "briatte": "Thank you, and thanks to CRAN for updating the binary so quickly.\n. > The problem is that it's really hard to test if something has been correctly title-cased. The rules are complicated\nHow about comparing the title to the results of tools::toTitleCase(title) and sending a warning if they differ?\nR\ntitle <- \"A package that asserts that 'ggplot2' rocks\"\nif (!identical(title, tools::toTitleCase(title))) {\n  warning(\"Title differs from tools::toTitleCase(title); consider revising\")\n}\nMight be better than nothing, since I guess that many package submissions (including my first one!) get the title wrong.\n. ",
    "r-cheologist": "Downloading/installing from github.com/hadley/devtols/archive/master.zip \ndoesn't do it. Where do I get this from?\nJoh\nOn Wednesday, February 06, 2013 21:47:27 hadley wickham wrote:\n\nThat was fixed in f51994d70f0a577dd2d0f604877d82c5dbb2e866 - you'll need\nthe development version.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/248#issuecomment-13198035\n. Forget it. Checkid it out of git and seems to e working now.\n\nJoh\nOn Wednesday, February 06, 2013 22:19:45 Johannes Graumann wrote:\n\nDownloading/installing from github.com/hadley/devtols/archive/master.zip\ndoesn't do it. Where do I get this from?\nJoh\nOn Wednesday, February 06, 2013 21:47:27 hadley wickham wrote:\n\nThat was fixed in f51994d70f0a577dd2d0f604877d82c5dbb2e866 - you'll need\nthe development version.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/issues/248#issuecomment-13198035\n. Not true - fixed in your fork, but the following still's broken:\n\n\nPROMPT> devtools::install_github(\"hadley/devtools@1.13.0\")\nSkipping install of 'devtools' from a github remote, the SHA1 (c071299c) has not changed since last install.\n Use `force = TRUE` to force installation\n\nPROMPT> packageVersion(\"devtools\")\n[1] \u20181.13.0\u2019\n\nPROMPT> devtools::install_bitbucket\nfunction (repo, username, ref = \"master\", subdir = NULL, quiet = FALSE, \n    auth_user = NULL, password = NULL, ...) \n{\n    remotes <- lapply(repo, bitbucket_remote, username = username, \n        ref = ref, subdir = subdir, auth_user = auth_user, password = password)\n    install_remotes(remotes, ...)\n}\n<environment: namespace:devtools>. Even restarted the lxc-container this is running in and still get the error..\n",
    "CharlesCara": "Thanks, but when I cannot load (using require or library) the version of devtools in CRAN!  I feel like John Yossarian here.  Maybe I should wait until this version of devtools is released to CRAN.\n. Thanks.  Maybe another source of confusion is that the RTools website is not listing RTools215 as compatible with R 2.15.2 .\n. double Grrr.  RTools2.15 is not compatible with R2.15.2:\nlibrary(\"devtools\", lib.loc=\"C:/R/R-2.15.2/library\")\nWARNING: Rtools is required to build R packages, but no version of Rtools compatible with R 2.15.2 was found. \n. Yes it works now.  Thank you very much.\nAs a reference for anyone else who hits this problem, I needed to upgrade RTools to 3.0 and make sure the Windows registry had no reference to earlier versions of RTools.\n. ",
    "cscheid": "Ok, sorry, I'm playing with this further, and I think it's stupidity on my part about RStudio. I get further if I just do this on a tty R64 session:\n* DONE (guitar)\nAdding files missing in collate: guitar.R\nError in loadRcppModules() : \n  loadRcppModules can only be used within a .onLoad function\nIt still doesn't work, but according to https://github.com/hadley/devtools/issues/61, I need to go to Eddelbuettel and plead help :)\nThe rest of the problem seems to be that I'm failing to let RStudio know about libgit2.0.dylib. It currently lives on /usr/local/lib, but even after symlinking it to /usr/lib, or copying the actual library file to /usr/lib/libgit2.0.dylib, RStudio still fails to find it. It might not even be entirely my fault! :)\n. I am using devtools::load_all(). From a bash shell:\n```\n$ R64 \n\nlibrary(devtools)\nload_all(\"/Users/cscheid/code/guitar\")\nLoading guitar\nLoading required namespace: Rcpp\nLoading required package: Rcpp\nAdding files missing in collate: guitar.R\n```\n\nFrom RStudio 0.97.312:\n```\n\nlibrary(devtools)\nload_all(\"/Users/cscheid/code/guitar\")\nLoading guitar\nLoading required namespace: Rcpp\nLoading required package: Rcpp\nAdding files missing in collate: guitar.R\nError in dyn.load(dllfile) : \n  unable to load shared object '/Users/cscheid/code/guitar/src/guitar.so':\n  dlopen(/Users/cscheid/code/guitar/src/guitar.so, 6): Library not loaded: libgit2.0.dylib\n  Referenced from: /Users/cscheid/code/guitar/src/guitar.so\n  Reason: image not found\n```\n\nI thought the issue was 32-bit vs 64-bit, but running R from a bash shell gives me a different error:\n```\n\nlibrary(devtools)\nload_all(\"/Users/cscheid/code/guitar\")\nLoading guitar\nLoading required namespace: Rcpp\nLoading required package: Rcpp\nAdding files missing in collate: guitar.R\nError in dyn.load(dllfile) : \n  unable to load shared object '/Users/cscheid/code/guitar/src/guitar.so':\n  dlopen(/Users/cscheid/code/guitar/src/guitar.so, 6): no suitable image found.  Did find:\n/Users/cscheid/code/guitar/src/guitar.so: mach-o, but wrong architecture\n```\n\n(Showing my complete ignorance here, I don't know what you mean by Build and Reload!)\n. J.J., thank you for walking me through this. I created the project, used the Build and Reload command, and it still doesn't work. (I pushed the new files created by RStudio to the experimental-devtools branch in guitar as well). A similar error happens, now from the build tab in the project view in RStudio:\n```\n==> R CMD INSTALL --no-multiarch guitar\n\ninstalling to library \u2018/Library/Frameworks/R.framework/Versions/2.15/Resources/library\u2019\ninstalling source package \u2018guitar\u2019 ...\n libs\n arch - x86_64\nmake: Nothing to be done for `all'.\ninstalling to /Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64\n* R\n inst\n preparing package for lazy loading\n** help\n installing help indices\n* building package indices\n testing if installed package can be loaded\nError in dyn.load(file, DLLpath = DLLpath, ...) : \n  unable to load shared object     '/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64/guitar.so':\n  dlopen(/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64/guitar.so, 6): Library not loaded: libgit2.0.dylib\n  Referenced from: /Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64/guitar.so\n  Reason: image not found\nError: loading failed\nExecution halted\nERROR: loading failed\nremoving \u2018/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar\u2019\nrestoring previous \u2018/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar\u2019\n\nExited with status 1.\n```\nThis same project directory setup works for plain R64 CMD INSTALL --no-multiarch:\n``\n$ R64 CMD INSTALL guitar --no-multiarch\n* installing to library \u2018/Library/Frameworks/R.framework/Versions/2.15/Resources/library\u2019\n* installing *source* package \u2018guitar\u2019 ...\n** libs\n*** arch - x86_64\nmake: Nothing to be done forall'.\ninstalling to /Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64\n R\n inst\n preparing package for lazy loading\n help\n installing help indices\n* building package indices\n testing if installed package can be loaded\n\nDONE (guitar)\n```\n\nI suspect it's something I do in my environment. How do I inspect the environment RStudio is getting vs the one plain R is getting? \nEDIT: Actually, we should move this discussion away from devtools(). I worked around Rcpp and load_all now works!\n. RStudio 0.97.316 (fails with 0.97.312 as well), R 2.15.2, OS X 10.8.2\n. Also, I don't think it's only architecture mismatch. When I do forcefully trigger architecture mismatch problems, (by typing R CMD INSTALL guitar --no-multiarch on a bash shell instead of R64 CMD INSTALL guitar --no-multiarch) this is what I get instead:\n** testing if installed package can be loaded\nError in dyn.load(file, DLLpath = DLLpath, ...) : \n  unable to load shared object '/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/i386/guitar.so':\n  dlopen(/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/i386/guitar.so, 6): Symbol not found: _git_index_free\n  Referenced from: /Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/i386/guitar.so\n  Expected in: flat namespace\n in /Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/i386/guitar.so\nError: loading failed\nExecution halted\nERROR: loading failed\nNotice this is not the same error as the one I get from RStudio (which I reproduce below:)\n** testing if installed package can be loaded\nError in dyn.load(file, DLLpath = DLLpath, ...) : \n  unable to load shared object '/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64/guitar.so':\n  dlopen(/Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64/guitar.so, 6): Library not loaded: libgit2.0.dylib\n  Referenced from: /Library/Frameworks/R.framework/Versions/2.15/Resources/library/guitar/libs/x86_64/guitar.so\n  Reason: image not found\nIs there a better forum for me to move this to?\n. Yup, I can confirm this works for me as well. Thanks, JJ!\n. Devtools 1.1, OS X 10.8.2, R 2.15.1:\n```\n\nversion\n               _                          \nplatform       x86_64-apple-darwin9.8.0   \narch           x86_64                     \nos             darwin9.8.0                \nsystem         x86_64, darwin9.8.0        \nstatus                                    \nmajor          2                          \nminor          15.1                       \nyear           2012                       \n...\n\nother attached packages:\n[1] devtools_1.1\n```\n. Incidentally, it works now for me, but that's because github didn't redirect. So the problem still stands: when github redirects the download, install_github fails. I suspect the culprit is install-url, specifically lines 35-36, which do not appear to check for redirection (at least that's what it seems from skimming the source of GET in httr, which goes to http--request, which does not appear to auto-redirect).\n. Huh, that's possibly it. I can't get it to reproduce now anymore, and I did update httr in the process of debugging something else. Sorry about the noise.\n. ",
    "cubranic": "The problem is that if you install your package with devtools::install, it will use the \"--install-tests\" argument to R CMD INSTALL. This puts your top-level test script (\"guitar/tests/test-all.R\") into the library folder \"guitar/tests\". This files is found by testthat::test_package, which sources it, and that will call \"test_package\" again, starting the infinite loop.\nThe danger is that not only do you have to use devtools::test for all interactive testing: you can't use test_package if your test runner's name matches \"test*.[Rr]\" and the package was installed with '--keep-source', period. I can reproduce the same error with, for instance plyr. The solution is to rename \"test-all.R\" to something that doesn't look like a unit test to testthat, for instance \"run-all-tests.R\".\n. The doc for test_package still says:\n\nUse test_package to test an installed package, or in tests/test-all.R if you're using the older inst/tests convention.\n\nAnd if the package is installed with \"--install-tests\" this will cause an infinite loop.\n. Ah, I see: those lines were added in June (commit d5b9754). The most recent CRAN version (0.7.1) was released in March, so it\u2019s missing that check.\nDavor\nOn Dec 12, 2013, at 5:44 AM, Hadley Wickham notifications@github.com wrote:\n\nActually, looking at the first few lines of test_package, I see:\n# Ensure that test package returns silently if called recursively - this\n  # will occur if test-all.R ends up in the same directory as all the other\n  # tests.\n  if (test_env$in_test) return(invisible())\n  test_env$in_test <- TRUE\n  on.exit(test_env$in_test <- FALSE)\nso certainly the intent is to not get stuck in an infinite loop. If that's not working for you, could you please open a new issue with a reproducible set of steps? Thanks!\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "jimmarq": "\nfind_rtools(TRUE)\nScanning path...\nls : C:\\dev\\Rtools\\bin\\ls.exe \nScanning registry...\nFound c:/dev/Rtools for 3.0 \nVERSION.txt\nRtools version 3.0.0.1927 \nWARNING: Rtools is required to build R packages, but the version of Rtools previously installed in c:/dev/Rtools has been deleted.\n\nPlease download and install Rtools 3.0 from http://cran.r-project.org/bin/windows/Rtools/ and then run find_rtools().\n. Yes, that fixed the issue. Thanks!\nThere were no errors when loading the devtools package. Also, the find_rtools() function seemed to work fine. I've included the output below.\n```\n\nfind_rtools(TRUE)\nScanning path...\nls : C:\\dev\\Rtools\\bin\\ls.exe \nScanning registry...\nFound c:/dev/Rtools for 3.0 \nVERSION.txt\nRtools version 3.0.0.1927 \n[1] TRUE\n```\n. \n",
    "Brent-Dickinson": "Hi, \nI am having the same problem as jimmarq had. And when I run find_rtools(TRUE), I get:\n\"> find_rtools(TRUE)\nScanning path...\nScanning registry...\nFound c:/Rtools for 3.0 \nVERSION.txt\nRtools version 3.0.0.1927 \nWARNING: Rtools is required to build R packages, but the version of Rtools previously installed in c:/Rtools has been deleted.\nPlease download and install Rtools 3.0 from http://cran.r-project.org/bin/windows/Rtools/ and then run find_rtools().\"\nI am new to devtools, but can't get past this problem.\n. Thanks very much, that seems to have taken care of the problem!\n. ",
    "vjd": "I updated the devtools package to the one from CRAN, but I still get the message that Rtools could not be found\n\nfind_rtools(TRUE)\nScanning path...\nls : C:\\PROGRA~2\\OpenSSH\\bin\\ls.exe \ngcc: C:\\PHSTMI~1\\bin\\gcc.exe \nScanning registry...\nFound c:/Rtools for 3.0 \nVERSION.txt\nRtools version 3.0.0.1930 \nWARNING: Rtools is required to build R packages, but the version of Rtools previously installed in c:/Rtools has been deleted.\n\nPlease download and install Rtools 3.0 from http://cran.r-project.org/bin/windows/Rtools/ and then run find_rtools()..\n. ",
    "imriss": "Similar to vjd, I got the same error, while I installed devtools on R 2.15.3 yesterday. sessionInfo() says devtools_1.1. Also I tried to download the devtools_1.1.zip listed above, but the link is not working. Should I open a new issue thread? Thanks.\nScanning path...\nls : C:\\Windows\\system32\\ls.exe \ngcc: c:\\Rtools\\GCC-46~1.3\\bin\\gcc.exe \nScanning registry...\nFound c:/Rtools for 3.0 \nVERSION.txt\nRtools version 3.0.0.1930 \nWARNING: Rtools is required to build R packages, but the version of Rtools previously installed in c:/Rtools has been deleted.\n. Thanks. Can you also comment on my request regarding R 2.15.2 and Rtools in Issue https://github.com/hadley/devtools/issues/262. I have devtools 1.1 installed, but it cannot see Rtools 3.0, and says it has been deleted.\n. ",
    "Dasonk": "Oh that makes sense - for a while I thought you had a function that made a nice plot of the call tree and that's what you were trying to do with draw_tree.  Thanks for the update.\n. ",
    "renozao": "Yes, that's good, I saw Martin's email about it.\nWouldn't it sill be useful to run the cleanup procedure in try()? To avoid\nany unexpected other issue (there are always with S4 stuff) to mask the\nprimary error?\n2013/3/26 hadley wickham notifications@github.com\n\nFixed in R-devel.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/268#issuecomment-15484454\n.\n. :) fair enough, sound strategy.\nSo what about outputting both errors?\n\n2013/3/26 hadley wickham notifications@github.com\n\nI'd rather they break devtools so we find out about them and fix them.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/268#issuecomment-15487911\n.\n. I am using it on a cluster with independent jobs, not real parallel R\nsession, so things work well and running in dev mode makes it easier to\nquickly fix bugs.\n\nIf the purpose is to be able to run document, then shouldn't the\ncollate be updated only when effectively running document?\nThe current solution might actually be fine, as long as it only writes the\nDESCRIPTION file when necessary. In my case it keeps writing it even if the\nresulting Collate field is identical to the current one.\nOn Monday, February 23, 2015, G\u00e1bor Cs\u00e1rdi notifications@github.com\n<javascript:_e(%7B%7D,'cvml','notifications@github.com');> wrote:\n\nFix me if I am wrong, but my understanding is that devtools is for package\ndevelopment, and if you want to use the package, in your case by multiple R\nprocesses in parallel, then you can just install it, and load it with\nlibrary.\nBecause if you really want to use devtools in parallel, then there are\nissues with all the generated files, not just DESCRIPTION, and these\nissues are hard to fix, essentially all writes would require locking.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/723#issuecomment-75596017.\n. @gaborcsardi: when you say toolchain, do you mean in the case there is compiled code or even in plain R packages? \nI know it seems safer to use installed packages when running jobs on the cluster, but I am using multiple packages, and it would require to re-install each of them after debugging from my local machine (which I sometimes forget), and by using devtools I am sure I am using the latest fixed version of all of them. It is just simpler and I had no issue until the update_collate change.\nFull production runs will use standard installed packages.\n\n@Geoff99: I understand the objective of calling update_collate in load_all, but I think it is better practice to have a conservative behavior of only updating if necessary, and notify the user about the update as well (with a message or a warning).\nWill try your branch (on Ubuntu).\n. To clarify my thoughts and use case: \n- I think having load_all fix/update some incorrect files like DESCRIPTION and NAMESPACE is fine and a good feature.\n- My jobs load a \"frozen\" package directory that was previously tested and loaded with load_all, so I am not expected any change to appear in those files. \nWhat happens is that there is a race condition due to parallel jobs trying to re-write a file with its very same content. \n@Geoff99, I forked and implemented a fix on your roxygen2 feature branch. Will send a push request shortly.\n. This issue is still present on the current CRAN version (1.12.0). Only affects Windows. This is a blocking bug, which affect all install_* functions.\nCan we hope for a hotfix pushed to CRAN soon? See hints below for quick fix.\nThanks\nThe bug is reproducible by calling install_cran on any package that has a direct dependency that is not already installed on the host. For example:\nR\ninstall_cran('argparse')\nwill not install dependency getopt if not there.\nIf I correctly followed the chain of calls, I think the issue lies in install_remote, which contains the following block:\nR\nif (is_windows && inherits(remote, \"cran_remote\")) {\n        install_packages(package_name, repos = remote$repos, \n            type = remote$pkg_type, ..., quiet = quiet)\n        return(invisible(TRUE))\n    }\nThis explains the Windows-specificity of the bug. \nThe issue then arises from function install_packages that has default argument dependencies = FALSE, instead of the standard and expected dependencies = NA.\nNote that this notably affect all install_* functions because they all eventually call install_remote.\n. Thanks for the fix.\nI saw that you fixed it in another way I had thought of, but I did not want to change the interface of install_remote, to limit side-effects I may not have been aware of. . @jimhester I am definite that the installed pkgA was loading the loaded development version of pkgB. I have been using this feature many many times: I could see that pkgA was using the modified version of the functions in pkgB I was busy with.\nThis behaviour would happen even if there was an installed version of pkgB: pkgA would not try to load pkgB from the library, if it was already loaded by load_all.\nCurrently, not only the loaded pkgB dev package is not used, but neither is found its installed \"old\" version. \nI am aware and indeed experienced things that go wrong when using load_all for dependencies, but this was in relatively specific and rare situations, e.g., with dependencies with compiled libraries in parallel computations or intricate S4 methods and classes.\n. ",
    "dkesh": "Sorry for the inactivity.  This is my use-case; please tell me if there's a better way.  If you agree this is the best way, I can make the suggested changes and update the pull request.\nI build packages on one server using install_deps(); document(); build(), install().  I run the install()ed version through the testing / continuous integration process. If everything passes, the build()ed version gets marked for transfer to the production server.  We don't commit NAMESPACE or man/* files to source control as they are fully automated.  I can't run install() before document() because the NAMESPACE files aren't updated yet, but I can't run document() before install() because newly introduced dependencies won't be downloaded on the continuous integration server.\nSo, we could change our process to check in the generated files, but it seemed like exporting install_deps was another way to go about it.\n. These packages aren't distributed externally to my organization.  They're\ninstalled on the machines of those developing the packages and the testing\n/ production environments and nowhere else.  We can check in NAMESPACE and\nrd files to get around needing to run document before build/install; the\ninstall_deps solution just seemed like less extra distraction.\nOn Sun, Apr 7, 2013 at 7:46 PM, hadley wickham notifications@github.comwrote:\n\nHmmm, I think it's generally best practice to check in NAMESPACE and rd\nfiles - R basically has no way to declare build/install dependencies, and\nit's common practice to install directly from a source code repo.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/pull/271#issuecomment-16027995\n.\n. Okay, I'm going to leave this pull request closed then.\n\nOn Sun, Apr 7, 2013 at 10:28 PM, hadley wickham notifications@github.comwrote:\n\nYeah, I understand - I just think currently it's best practice for R\npackages to include NAMESPACE and rd files in the source, even though\nthey're automatically generated. Eventually devtools might gain support for\npre-install actions.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/pull/271#issuecomment-16030886\n.\n. \n",
    "hcorrada": "I'm finding it hard to replicate this with a simple package. I encountered the error developing a relatively complex package and it only shows up after a number of updates/load_all calls. I'll try to isolate the problem but it might take a while. Perhaps I should close this pull request until I do so?\n. ",
    "christophergandrud": "Sure thing. \nSending it now . . .\n. Hi @boulby69. I believe your question is more general than the issue discussed in this Pull request. \nYou probably want to submit it as its own question in the \"Issues\" section. It will get more attention there.\nBest\n. I'm on a plane so this is short, but the package is at\nhttps://github.com/christophergandrud/simPH.\nThe README links to the Travis fail. It fails the same way on my Mac.\nOn 11 Apr 2014 18:25, \"Hadley Wickham\" notifications@github.com wrote:\n\nCould you please provide a reproducible example? (i.e. a pointer to the\npackage). The fact that it's complaining about methods called . is\ninteresting.\n\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/455#issuecomment-40222499\n.\n. Oh, sorry. I added in the . . . to stand in for the function names.\n\nThe original error in the install.out file when running devtools::check(args = c('--as-cran')) in R version 3.1.0 on the package at http://git.io/02U1cQ is:\nS\n** testing if installed package can be loaded\nWarning: S3 methods 'simGG.siminteract', 'simGG.simlinear', 'simGG.simpoly', 'simGG.simspline', 'simGG.simtvc' were declared in NAMESPACE but not found\nError in namespaceExport(ns, exports) : undefined exports: simGG\nError: loading failed\nExecution halted\nERROR: loading failed\nThe NAMESPACE created by Roxygen2 (both the development version 4.0.0 and 3.1.0)  includes:\nS3method(simGG,siminteract)\nS3method(simGG,simlinear)\nS3method(simGG,simpoly)\nS3method(simGG,simspline)\nS3method(simGG,simtvc)\nexport(simGG)\n. I've solved the problem, though I'm not exactly sure how the solution worked.\nSolution\nIn the package's parent directory I have a folder called 'img' that stores an image for the README.md. I had told  .Rbuildignore to ignore its contents with img/*. When I changed this to ^img the package builds perfectly and passes CRAN check. \nI must be missing something behind the scenes to understand why this solution works. There could be some way that R 3.1.0 builds methods, that is different from previous versions and leads to S3methods declared in the NAMESPACE being ignored by when img/* was in .Rbuildignore.\nThought\nI'm sure this is a pretty unusual problem, but it might be good if devtools or Roxygen could give an informative error about the underlying problem. \n. That seems about right to me. The issue is probably an edge case so not anything to really worry about (it did take a fair amount of time to find the bug however, since the errors did not really point in an obvious direction).\n. ",
    "boulby69": "Hello,\nI have tried to install r packgage from gihub especially rcharts an i have this error message : http client error (403)\nI follow your steps with the lines command :require(devtools)\ninstall_github('rCharts', 'ramnathv')\nI retried for other packages and i have the same error message, so i think the problem come to devtools?\nAny sugestions?\nBest regards\n. Hello,\nI want to install some R package enable on github like Rcharts for example, but when i launch the R command : require(devtools)\ninstall_github('rCharts', 'ramnathv')\n and i have this message: \nInstalling github repo(s) rCharts/master from ramnathv\nInstalling rCharts.zip from https://api.github.com/repos/ramnathv/rCharts/zipball/master\nError: http client error (403)\nI am not behind proxy, butmaybe the problem could be a configuration of my  firewall box (internet provider)\n. When i check you link i have this error:500: Internal Server Error so i go on http://ramnathv.github.io/rCharts/r2js/ and download the zip ball, but when i tried to use install(path/to/rCharts.zip) R doesn't recognize the install function, is it install.package instead?\nRegards\n. Ok it works, just to precise you need to create a directory who contains the DESCRIPTION file present in the zip ball\nRegards\n. ",
    "csgillespie": "A user got a similar error installing my package using devtools: https://github.com/csgillespie/poweRlaw/issues/5\nI couldn't reproduce it. \n. ",
    "brianbolt": "Here is the documentation:\nhttps://confluence.atlassian.com/display/BITBUCKET/Using+the+Bitbucket+REST+APIs\nThis call works:\ninstall_url(url = \"https://bitbucket.org/bbolt/mypackage/get/master.zip\", config = authenticate(user = \"username\", password = \"password\", type = \"basic\"))\nThanks!\nOn Jun 3, 2013, at 7:32 AM, hadley wickham notifications@github.com wrote:\n\nCan you provide a pointer to the API docs?\n\u2014\nReply to this email directly or view it on GitHub.\n. Yep, that works for me.\n\nThanks!\nOn Jun 10, 2013, at 12:56 PM, hadley wickham notifications@github.com wrote:\n\nCould you please check that this works? Thanks!\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "kforner": "Sure...\nI wrote some code above devtools/testthat/roxygen to extend the use of devtools to a collection of interrelated packages, and to add some features like line numbers in failing test units, parallelized testing and checking of the collection... \nThis code currently hacks your packages, calling internal functions, and sometimes duplicate some functions to tweak their behaviour.\nI'm in the process of cleaning up this code, refactoring it, packaging it and more important testing it extensively.\nI will be in Lyon by the end of the month at the R meeting so maybe we can meet to talk about it and its future.\nBack to the use case, during this process, I try to fix each misuse of your packages. I need parse_deps to figure out the intra-collection dependencies of a given package.\nAnd a big thanks for all your incredibly useful packages that we use all day long.\nBest,\nKarl\n. Thanks. \nSee you there.\n. Hello,\nIn fact it's more complicated that I thought: here's a reproducible example:\nhttps://github.com/kforner/bug_devtools_s4_export\nDo not hesitate to contact me for further info.\nBest,\nKarl\n. No news... 2 months...\n. So ?\n. Hi Winston. \nI tried to fix the issues you raised. Can you check if it's ok ? \nThanks\nKarl\n. You're welcome ! I'm glad to contribute to such an helpful package.\n. You got me wrong: currently is_loaded() check whether it is attached, as ns_env() does, but they should not.\nSo do you think this is feasible ? I was wondering if there were hidden complexities, when dealing with S3 and s4 methods cache for instance...\n. You're absolutely right I'm sorry. \nI do not understand, I'm sure while debugging that I found this behaviour, my bad.\nBut it's good news though. \nHow should we proceed then: would you accept a pull request with and addition argument attach = TRUE for load_all that would conditionally attach the namespace  ?\n. In fact it seems to work. That's what I tried previously and tried to debug. Anyway so far so good. Thanks for your help.\n. @hadley I tried to have a quick look at RJSONIO, but could not find anything special, thought I'm not very experienced with pkgs with dlls\n@wch \nnope.\nI tried with detach or unloadNamespace, both work.\n. I read that jsonlite was a fork of RJSONIO. I pushed a new test (bug1a.R) and it does not crash at all. So there seems indeed to be a very nasty business with RJSONIO.\n. but you still use it in shiny right ? 'cause we had the problem recently.\n. the roxygen2::update_collate() call in load_all(), and  write.description() in roxygen2::update_collate() \nalso from the NEWS.md about 1.7.0:\nload_all() runs roxygen2::update_collate() before loading code. This ensures that files are sourced in the way you expect, as defined by roxygen @include tags. If you don't have any @include tags, the collate will be not be touched (#623).\njust checked with grep -r: I do not use @include\nroxygen2      * 4.0.2      2014-09-02 CRAN (R 3.1.1) \nroxygen2::update_collate\nfunction (base_path) \n{\n    collate <- generate_collate(file.path(base_path, \"R\"))\n    if (!is.null(collate)) {\n        collate <- paste0(\"'\", collate, \"'\", collapse = \" \")\n    }\n    desc_path <- file.path(base_path, \"DESCRIPTION\")\n    old <- read.description(desc_path)\n    new <- old\n    new$Collate <- collate\n    write.description(new, desc_path)\n    if (!identical(old, read.description(desc_path))) {\n        cat(\"Updating collate directive in \", desc_path, \"\\n\")\n    }\n}\nfrom what I understand, the description file is unconditionally written \nroxygen2:::write.description\nfunction (desc, file = \"\") \n{\n    unlink(file)\n    mapply(cat.description, names(desc), desc, MoreArgs = list(file = file))\n    invisible()\n}\n. indeed, thanks. \nQuestion: I installed the devtools 1.7 version using devtools::install_github. It does not enforce the deps versions specified in the DESCRIPTION file ?\n. Thanks.\n. This causes me problems too, and because my tests are run in parallel I can't use the workaround as is.\nI'd like know why load_all sources the test helpers ???\nYou could imagine doing things are expensive in those helpers, both in CPU and in memory, that are only useful when executing tests, so why would you want to have them executed at load time ?\nSo an option or a parameter would be welcome.\nThanks.\n. > I think the idea behind load_all() is to have an interactive environment that mimics the environment your >\n\ntests are run in.\n\nAs a long-time user, I would say that for me the idea is to be able to load \"quickly\" a package from source, as if it was installed. Period. Loading a package via library() DO NOT source the test helpers.\nWhy force this behaviour ? Why not add an option or make a special function for people that want to run tests interactively, like load_for_testing() ? or instead make a lower level load_all function: load_package_from_source() ? \nThe UNIX philosophy is to try to make one thing right. Why can't I just  have a function that loads the package ? \n. > load_all also loads the non-exported functions by default, so it is already different from library().\nYes but you have the export_all param to make it work like library (and I do use this option). \nI could totally live with the \"by default behaviour\", what bothers me is that I have no way but hacking the function to get the behaviour I need.\n. ok. In this case, would it be possible to have the load_package_from_source()/library_from_src() function, basically load_all without the sourcing of test helpers ? \nThanks.\n. The reason I insist is that it breaks our dev workflow (and that it was already painful to identify the cause). Maybe the design is flawed, but in any case it involves quite an effort to fix it. It's so much easier for me to downgrade devtools in the meantime, and to wait for an option not to run those helpers, or to patch load_all if the option will not happen.\n. wOOt. an option (as in getOption()), or a function parameter ? \n. ",
    "mlt": "Forgot to update docs...\n. While not denying suggested change, I realized that submodules don't quite work with git-svn which is the way to push stuff to rforge. Perhaps one may be directed toward git subtree for new projects to avoid all this mess.\n. I don't know about git in particular but since you are using system2 it is safer to split extra args ahead of time. There might be issues on non-windows platforms if a single string was used. Also I updated your example.\nP.S. I rebased topic branch to see how github handles it with pull requests. It handles it well. Though in case you have cloned it, now it is orphaned.\n. Former behavior? :-) I guess it should be default. I tried not to change defaults. Though it might produce inconsistent results when compared to install_github with tarball missing submodules.\n. I could include install_git(\"git://github.com/mlt/swap2r.git\", recursive = TRUE). Though it is an incomplete package in early alpha. I'm not aware of anything else as of now.\nThough perhaps example might be negative if we change defaults, e.g., recursive = FALSE will fail installation.\n. I don't know if someone might be using an older git. Also instead of adding these & those options, wouldn't it be better to pass a list with command line options down to git, e.g list(branch=\"xyz\", recursive=TRUE) or as a single string. I'm not sure though whether it would work fine on *nix if all arguments are lumped into a single string. And for the former example, something needs to be done to convert recursive=TRUE into just --recusrive.\n. ",
    "jeroen": "Thanks\n. I'm using devtools to install packages requested by a user on the fly in my web framework. However, sometimes installation of packages fails without it being clear why. Being able to capture output and present it to the user would be very informative and helpful for debugging.\n. I am looking into devtools:::system_check where it is calling system. It would be great if we could switch to system2 indeed.\nDo you remember what was the rationale behind using system with with_envvar? It seems that system2 has an native env argument that does something very similar.\nAlso there seems to be minor a bug right now that when internal=quiet is set to TRUE, then the result is never 0 or 1, it is the output stream of the command instead. However I guess it would only be problematic when the command prints a 0 to stdout when successful.\n. I implemented the minimal change to switch from system to system2:\nhttps://github.com/jeroenooms/devtools/commits/master. Tested on win, mac\nand linux, as far as I can tell there are no side effects.\nOn Wed, Jul 10, 2013 at 1:25 AM, hadley wickham notifications@github.comwrote:\n\nYes - the way system tries to set environmental variables (pasting in\nfront of the command) does not work across platforms\nI think there's some way to get the result code by looking at an attribute\nof the output.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/315#issuecomment-20727981\n.\n. I'm sending a pull request, not to push you but just to make sure it\ndoesn't get lost:\n\nhttps://github.com/hadley/devtools/pull/327\nOn Wed, Jul 10, 2013 at 1:41 PM, Jeroen Ooms jeroenooms@gmail.com wrote:\n\nI implemented the minimal change to switch from system to system2:\nhttps://github.com/jeroenooms/devtools/commits/master. Tested on win, mac\nand linux, as far as I can tell there are no side effects.\nOn Wed, Jul 10, 2013 at 1:25 AM, hadley wickham notifications@github.comwrote:\n\nYes - the way system tries to set environmental variables (pasting in\nfront of the command) does not work across platforms\nI think there's some way to get the result code by looking at an\nattribute of the output.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/315#issuecomment-20727981\n.\n. Yup.\n. @wch yes I considered this. However the thing is that the arguments from system2 are somewhat platform specific. For example in unix you might want to pass stdout and stderr whereas in windows you might want to pass arguments for invisible and minimized. Therefore I thought it would be safer to leave this to the user.\n\n\nI think the install commands, e.g. install_github are already passing the arguments in ... to install so afaik, no additional changes are needed.\n. We can put this on hold for a bit. I found some problems with system2 both\non RGUI and Rstudio-win. See\nhttp://r.789695.n4.nabble.com/Redirect-system2-stdout-to-a-file-on-windows-td4671543.html\nOn Thu, Jul 18, 2013 at 2:36 PM, hadley wickham notifications@github.comwrote:\n\nAny thoughts on some simple tests?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/pull/327#issuecomment-21180014\n.\n. Ran into this as well. I don't think blank lines are illegal in DESCRIPTION files? According to R NEWS 2.15.3:\nR CMD check no longer fails with an error if a \u2018DESCRIPTION\u2019 file incorrectly contains a blank line. (Reported by Bill Dunlap.)\n\nSo I think devtools shouldn't be choking on this either?\n. I can work on this, but I'm not sure what the most elegant way to implement this would be. We can add an additional parameter personal_token to install_github, or somehow generalize the current parameters?\n. That seems like a bit of overkill to add a single header.\n. Upon some further study, it seems like this is already possible. Github [allows}(https://developer.github.com/v3/auth/) for using the access token in basic authentication. Just use the token as username, and set the password to \"x-oauth-basic\". I tested it and it works!\ninstall_github(\"secretpackage\", \"jeroenooms\", auth_user=\"1da889a628de9086f5d9d2f0e37xxxxxxxxxxx\", password=\"x-oauth-basic\")\n. Closing this in favor of https://github.com/hadley/devtools/pull/418.\n. I think that would be preferred, if you're not worried about breaking backward compatibility.\n. Yup, sry.\n. Thanks, that is a pretty cool hack :-) In the comments of devtools it says \n\n.Internal(registerNamespace(name, env)) is replaced by register_namespace(name, env)\n\nDoes that have any consequences in practice?\nThe makeNamespace function is used in OpenCPU to give sessions the same status as packages. So clients can refer to x0af73b37c::foo to use object foo from session x0af73b37c. \nI am also experimenting with an alternative package manager for which creating namespaces would be cool, but that is more premature at this point. \n. If you're on windows you can try setInternet2()\n. He is specifically complaining about install.packages() ? Maybe I don't understand the issue/\n. +1 for an option to disable automatic package upgrades. The problem with dep = FALSE is that it won't install required missing dependencies either, which causes the installation to fail. \nWe still need dependencies that are currently not installed, just not reinstall packages when a suitable version is available.\n. Thanks, fixed.\n. Maybe we can convince @hadley to do a bugfix release on the current version with this fix? CRAN would probably be more comfortable with the new tooclhain if popular packages like devtools are passing checks...\n. I'm 99% confident this is a false positive (lots of trojans use openssl code). The openssl.so file is part of the openssl package, so this is the wrong repo. Do you get the same error when installing openssl?\nr\ninstall.packages(\"openssl\")\nAnd what happens when you try installing openssl from source?\nr\ninstall.packages(\"openssl\", type = \"source\")\n. Right, I don't disagree with that. Though it would be nice to run a full documentation spell check by default during CI builds and release(). It works really well :-)\n. OK it's back in suggests now.\n. @jimhester I think this solution will suffice. You could pass down the lib arg to install.packages() but maybe that's not needed.\nlgtm, let's merge :D (this one has really been bugging me :). This is a bug in sprintf() handling of multibyte chars it?\nr\ncat(sprintf(\"| %-10s|\", c(\"df\", \"Kirill\", \"M\u00fcller\", \"RStudio\")), sep = \"\\n\")\n| df        |\n| Kirill    |\n| M\u00fcller   |\n| RStudio   |. I think they will just say that it's working as intended. C level sprintf simply looks at the number of bytes in the string. It doesn't take into account multibyte characters. Maybe stringi has something smarter.. OK squashed and pushed.. I'm on afk this week, will look into it on Monday. . @Isaacsh can you give me the output of these commands:\nr\nfile.exists(file.path(R.home(\"etc\"), \"curl-ca-bundle.crt\"))\nr\nSys.getenv(\"CURL_CA_BUNDLE\", NA)\nr\ncurl:::.onLoad(). What sort of R are you running? What is /MIE74D~1/ROPEN~1/?. Does the same problem appear for another url for example:\nr\ncurl::curl_fetch_memory(\"https://httpbin.org/get\")\nAnd does it happen in base R for example:\nr\nreadLines(base::url(\"https://httpbin.org/get\")). That's odd. Does your actual path (the expanded version of \"C:/PROGRA~1/MIE74D~1/ROPEN~1/R-34~1.0/etc/curl-ca-bundle.crt\") contain diatrics or so?. So your path above says the dir is called MIE74D~1 but your snapshot says Microsoft. Is that correct?. Can you perhaps upgrade to Microsoft R Open 3.4.1 and see if the problem persists?. So you are 100% sure that the path C:/PROGRA~1/MIE74D~1/ROPEN~1/R-34~1.0/etc/curl-ca-bundle.crt\" corresponds to the path you show in your screenshot (which has very different labels)?. So this works in your MS R?\nr\nreadLines(\"C:/PROGRA~1/MIE74D~1/ROPEN~1/R-34~1.0/etc/curl-ca-bundle.crt\"). Somehow curl doesn't find it. Perhaps there is a hint in:\nr\ncurl::curl_fetch_memory(\"https://httpbin.org/get\", handle = new_handle(verbose=T)). Yes please open an issue on https://github.com/ropensci/spelling. Also note that the default file to wordlist words is inst/WORDLIST in your pkg.\n. Are you sure? The function is not changing anything in R or in the package. It just sends the user to a webpage to generate a token. I thought it would be nice to accompany the github_pat() function.\nWhat would it be called in usethis?. But that implies that the github pat is actually installed? That is actually a different feature. I would expect you would have to call use_github_pat(\"2b7a27ced93ca519\") or something and then it would modify your Rprofile or so?\nThe PR above only opens a browser window.. No, I just followed the example from the use_this functions. We can also keep it there as a wrapper if you'd like.. To match the default in the spelling package.. OK i have updated the PR to not deprecate.. ",
    "phaebz": "build_args would be nice.\nWe had some issues with C code and R packages that only run on 32 bit Windows. The upshot is that we have different local repos for 32 bit and 64 bit binary packages. I am working on the 64 bit repo and the package dependencies require me to build (and thus check) on 64 bit.\n. Thanks for the prompt implementation!\n. By hand I meant running\n\"C:/opt/R/R-3.0.1/bin/x64/R\" --vanilla CMD build \"d:\\R\\frt\" --no-manual --no-resave-data\non a command prompt and not by devtools::build.\nc:/opt/ on Windows was suggested to me some time ago (I think by Dirk Edelb\u00fcttel) for tools that cannot handle blanks in paths.\nI am sorry for the noise, I was bit by the inconsolata.sty issue during building of the vignette which did not occur when I tested building by hand because of my LaTeX setup - I will investigate more before posting in the future.\nPlease close quietly.\n. ",
    "rkrug": "Thanks Hadley. \nI was the one who encountered the problem.\nIt is strange - I used exactly the workflow under Linux, and it worked there. I migrated to Mac, and not anymore, although the option keep.source is also set to TRUE.\nI will report back, if it is working now.\n. Installed from github and it is working.\nThanks,\nRainer\n. carlboe notifications@github.com writes:\n\nWorks with R 3.x but it seem to still fail in R2.15    I installed from the latest github (2 July).\nIt used to work for me.  \n\nload_all(\"./Foo\")\nLoading Foo\nError in parse(text = lines, n = -1, srcfile = srcfile, keep.source = TRUE) : \n  unused argument(s) (keep.source = TRUE)\noptions()$keep.source\n[1] TRUE\n\nI reverted back a ways and found that, e.g.,\n9b7cb84b075d5708634ea02417304c9643aed534 does not give the same error\nunder R2.15 Bisecting led to 40d822986e081df6d33375d6bba9e988e31af11c\naka this patch as breaking devtools under R2.15\n\nHm - under OS X, this patch was necessary to display the traceback source\nunder ESS and R 3.x - even though options()$keep.source was set to true,\nthe ESS did not find the source file, what it did with keep.source=TRUE.\nYes - that argument was introduced only in R 3.0.\nIs there any way that we can keep it in and make it work under older\nversions as well?\nRainer\n\n--Carl\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/pull/319#issuecomment-21159713\n\n\nRainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)\nCentre of Excellence for Invasion Biology\nStellenbosch University\nSouth Africa\nTel :       +33 - (0)9 53 10 27 44\nCell:       +33 - (0)6 85 62 59 98\nFax :       +33 - (0)9 58 10 27 44\nFax (D):    +49 - (0)3 21 21 25 22 44\nemail:      Rainer@krugs.de\nSkype:      RMkrug\n. Unfortunately, I deleted the file from dropboxsome time ago. Vitalie - do you possibly still have it?\n. I just tried the package testTraceback again, and it does not work.\nDevtools is installed from github using\ninstall_github(\"devtools\")\nThis results in the following error (whole session paster for completeness).\n```\nR version 3.0.1 (2013-05-16) -- \"Good Sport\"\nCopyright (C) 2013 The R Foundation for Statistical Computing\nPlatform: x86_64-apple-darwin10.8.0 (64-bit)\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\nNatural language support but running in an English locale\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n\noptions(STERM='iESS', str.dendrogram.last=\"'\", editor='emacsclient', show.error.locations=TRUE)\nlibrary(devtools)\nload_all(\"~/Documents/Projects/R-Packages/testTraceback/\")\nLoading testTraceback\ntestprog()\nError in x + 1 (from testprog.R#2) : 'x' is missing\nsessionInfo()\nR version 3.0.1 (2013-05-16)\nPlatform: x86_64-apple-darwin10.8.0 (64-bit)\n\n\nlocale:\n[1] C\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] testTraceback_0.0-1 devtools_1.3.99    \nloaded via a namespace (and not attached):\n [1] RCurl_1.95-4.1 compiler_3.0.1 digest_0.6.3   evaluate_0.4.7 httr_0.2    \n [6] memoise_0.1    parallel_3.0.1 stringr_0.6.2  tools_3.0.1    whisker_0.3-2 \n\nversion\n               _                         \nplatform       x86_64-apple-darwin10.8.0 \narch           x86_64                    \nos             darwin10.8.0              \nsystem         x86_64, darwin10.8.0      \nstatus                                   \nmajor          3                         \nminor          0.1                       \nyear           2013                      \nmonth          05                        \nday            16                        \nsvn rev        62743                     \nlanguage       R                         \nversion.string R version 3.0.1 (2013-05-16)\nnickname       Good Sport                \n```\n\nand clicking on the error, gives in emacs:\nReference to 'testprog.R' not found\nGNU Emacs 24.3.1 (x86_64-apple-darwin12.4.0, NS apple-appkit-1187.39) of 2013-09-05 on Rainers-MacBook-Pro.local\ness-version: 13.09 \n. Sorry about not being clear - the error I am referring to is the one further down and from emacs:\nReference to 'testprog.R' not found\nafter I click on the highlighted error, which normally opens the R source code file.\n. Just to clarify: I don't get a meaningful traceback after the error:\n```\n\nlibrary(devtools)\nload_all(\"~/Documents/Projects/R-Packages/testTraceback/\")\nLoading testTraceback\ntestprog()\nError in x + 1 (from testprog.R#2) : 'x' is missing\ntraceback()\n1: testprog()\n```\n. \n",
    "carlboe": "Works with R 3.x but it seem to still fail in R2.15    I installed from the latest github (2 July).\nIt used to work for me.  \n\nload_all(\"./Foo\")\nLoading Foo\nError in parse(text = lines, n = -1, srcfile = srcfile, keep.source = TRUE) : \n  unused argument(s) (keep.source = TRUE)\noptions()$keep.source\n[1] TRUE\n\nI reverted back a ways and found that, e.g., 9b7cb84b075d5708634ea02417304c9643aed534 does not give the same error under R2.15  Bisecting led to 40d822986e081df6d33375d6bba9e988e31af11c  aka this patch as breaking devtools under R2.15\n--Carl\n. I see that parse() under 2.15 does not take the offending keep.source \nargument, but does test for getOption(\"keep.source\") inside the \nfunction.  parse under 3.x does have has the additional argument: \nkeep.source = getOption(\"keep.source\")\nFixes? You could use a wrapper function for parse which branched \ndepending upon R version or which temporarily set \noptions(keep.source=TRUE) and restored the setting upon exit.  You could \njust quote v3.x definition of parse within the package.\nIt's unfortunate that .Internal(parse.... depends upon a global variable \nfor its behavior, rather than passing the flag in as an argument.\nOn 7/18/13 12:12 AM, Rainer M Krug wrote:\n\ncarlboe notifications@github.com writes:\n\nWorks with R 3.x but it seem to still fail in R2.15 I installed from\nthe latest github (2 July).\nIt used to work for me.\n\nload_all(\"./Foo\")\nLoading Foo\nError in parse(text = lines, n = -1, srcfile = srcfile, keep.source =\nTRUE) :\nunused argument(s) (keep.source = TRUE)\noptions()$keep.source\n[1] TRUE\n\nI reverted back a ways and found that, e.g.,\n9b7cb84b075d5708634ea02417304c9643aed534 does not give the same error\nunder R2.15 Bisecting led to 40d822986e081df6d33375d6bba9e988e31af11c\naka this patch as breaking devtools under R2.15\n\nHm - under OS X, this patch was necessary to display the traceback source\nunder ESS and R 3.x - even though options()$keep.source was set to true,\nthe ESS did not find the source file, what it did with keep.source=TRUE.\nYes - that argument was introduced only in R 3.0.\nIs there any way that we can keep it in and make it work under older\nversions as well?\nRainer\n\n--Carl\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/pull/319#issuecomment-21159713\n\n\nRainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation\nBiology, UCT), Dipl. Phys. (Germany)\nCentre of Excellence for Invasion Biology\nStellenbosch University\nSouth Africa\nTel : +33 - (0)9 53 10 27 44\nCell: +33 - (0)6 85 62 59 98\nFax : +33 - (0)9 58 10 27 44\nFax (D): +49 - (0)3 21 21 25 22 44\nemail: Rainer@krugs.de\nSkype: RMkrug\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/pull/319#issuecomment-21166477.\n\n\nCarl Boe\nDemography - Center on the Economics and Demography of Aging\nUniversity of California, Berkeley\n510-982-6378\n. ",
    "HenrikBengtsson": "Yup - works. Thxs.\n. Found another one:  methods::getClasses()\n. I'm coming here because I'm seeing the same for the caper CRAN package.  In this case it's because there's an extra space after the parentheses holding the version specification;\n``` r\n\ndevtools:::parse_deps(\"R (>= 2.10), ape (>= 3.0-6) , MASS, mvtnorm\")\nError in devtools:::parse_deps(\"R (>= 2.10), ape (>= 3.0-6) , MASS, mvtnorm\") : \n  Invalid comparison operator in dependency: >= \n```\n\nIt'll work if one removes that extra space after the \"ape\" spec;\n``` r\n\ndevtools:::parse_deps(\"R (>= 2.10), ape (>= 3.0-6), MASS, mvtnorm\")\n     name compare version\n2     ape      >=   3.0-6\n3    MASS     \n4 mvtnorm     \n```\n\nLooking at the diagram package, you'll find the same extra space in the DESCRIPTION:\nr\nDepends:    R (\u2265 2.01) , shape\nSo, this sounds like an issue with devtools:::parse_deps().   This easiest fix is probably to replace:\nr\n  pieces <- strsplit(string, \",\")[[1]]\nwith\nr\n  pieces <- strsplit(string, \"[ ]*,[ ]*\")[[1]]\nsuch that we get:\n``` r\n\nstring <- \"R (>= 2.10), ape (>= 3.0-6) , MASS, mvtnorm\"\nstrsplit(string, \"[ ],[ ]\")[[1]]\n[1] \"R (>= 2.10)\"    \"ape (>= 3.0-6)\" \"MASS\"           \"mvtnorm\"     \n```\n\ninstead of\n``` r\n\nstrsplit(string, \",\")[[1]]\n[1] \"R (>= 2.10)\"      \" ape (>= 3.0-6) \" \" MASS\"            \" mvtnorm\"      \n``\n. @hadley, forgot to say, if you don't mindsQuote()`, the error message would have been more informative with quotes, i.e.\n\nr\n  if(!all(compare_valid)) {\n    stop(\"Invalid comparison operator in dependency: \",\n      paste(sQuote(compare_nna[!compare_valid]), collapse = \", \"))\n  }\n. @pierucci, the following patched version should fix it for you until fixed upstream:\nr\ndevtools::install_github(\"HenrikBengtsson/devtools@hotfix/parse_deps\")\n. I removed my hotfix after my fix (https://github.com/hadley/devtools/pull/1257) was merged into the master branch.  \n@zezantam, @dweichel and @jannepeltola, what version are you using?  The one on CRAN or the one on the master branch?  The devtools 1.12.0 (2016-12-05) available on CRAN does not to contain the fix (see below).\nRetry with installing devtools on the master branch, i.e.\nr\ndevtools::install_github(\"hadley/devtools\")\nDetails\nWhat the devtools 1.12.0 implements:\n```r\n\npackageVersion(\"devtools\")\n[1] '1.12.0'\ndevtools::parse_deps \nfunction (string) \n{\n    if (is.null(string)) \n        return()\n    stopifnot(is.character(string), length(string) == 1)\n    if (grepl(\"^\\s$\", string)) \n        return()\n    pieces <- strsplit(string, \",\")[[1]]\n[...]\nCompare that `pieces <- ...` line to what devtools 1.12.0-9000 (master branch) has:r\npackageVersion(\"devtools\")\n[1] '1.12.0.9000'\n devtools::parse_deps \nfunction (string) \n{\n    if (is.null(string)) \n        return()\n    stopifnot(is.character(string), length(string) == 1)\n    if (grepl(\"^\\s$\", string)) \n        return()\n    pieces <- strsplit(string, \"[[:space:]],[[:space:]]\")[[1]]\n```\nIf you don't see the latter, that's why.. Agree; updated PR.\n\nI incorrectly though [[:space:]] required perl = TRUE and I didn't want to force that.  I've learned something today :)\n. Just for my clarification, that was a 'wontfix' correct?. Sorry, my example was confusing since I used base; it's a package without a NAMESPACE file. I've edited my original post to use utils instead.. Ok. thxs. ",
    "bastistician": "mmh... it's just that I usually don't need a collate field for my\npackages and it would make my DESCRIPTION files rather long.\nI personally also don't feel comfortable with an R script intermingling\nmy manually composed DESCRIPTION...\nSo what about\nroclets = getOption(\"devtools.roclets\")\nin document() with default option\ndevtools.roclets = c(\"collate\", \"namespace\", \"rd\")\nin .onLoad()?\n. I agree. Roxygenizing the package is really part of building the package and its configuration determines the result as you say. On the other hand, the roxygen options used for building the package are not really a relevant DESCRIPTION of the finally built package. So one could also vote for specifications in a separate file .Roxygen (like with .Rbuildignore) or maybe via a special @Roxygen tag (for NULL code, like for tags going into a pkg-package.Rd file).\n. I just stumbled upon the same error, checked the underlying code, and came to the conclusion that reverse dependency checks are actually \"defunct\" rather than \"deprecated\" in current devtools.\nHere is why:\n\u2500\u2500 Saving check results to `revdep/checks.rds` \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nError: 'sessioninfo' is not in Suggests: for 'devtools'\nhas the following traceback():\n7: stop(\"'\", package, \"' is not in Suggests: for '\", pkg_name(path), \n       \"'\", call. = FALSE)\n6: suggests_dep(package, path = path)\n5: pkgload::check_suggested(package = package, version = version, \n       compare = compare, path = path)\n4: check_suggested(\"sessioninfo\")\n3: revdep_check_save(pkg, cache$revdeps, cache$check_dir, cache$libpath)\n2: revdep_check_from_cache(pkg, cache)\n1: devtools::revdep_check(threads = 3)\nI thought this would be easy to fix, since we would only need to remove the obsolete call\nhttps://github.com/r-lib/devtools/blob/e4e57aa6a775ef6f48eebc933ed7c4ad0a6e9c07/R/revdep.R#L253\nin revdep_check_save().\nUnfortunately, this won't revive reverse dependency checks in devtools because:\n\n\nthe subsequent call\nhttps://github.com/r-lib/devtools/blob/e4e57aa6a775ef6f48eebc933ed7c4ad0a6e9c07/R/revdep.R#L265\nfails because of the obsolete argument libpath. (This is easy to fix.)\n\n\nmost importantly, the workhorse function check_cran(), which should actually run R CMD check on reverse dependencies, no longer does anything in current devtools except issuing a deprecation warning (suggesting the use of revdepcheck::revdep_check()).\n\n\nSo reverse dependency checks are actually \"defunct\" in current devtools.\nI think this issue could be marked as \"won't fix*. Maybe devtools::revdep_check() will be modified to call revdepcheck in the future (maybe once that package is released on CRAN).. ",
    "iagomosqueira": "On 07/09/2013 03:04 PM, hadley wickham wrote:\n\nWhat if |unzip| just used |unzip = getOption(\"unzip\")| internally?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/326#issuecomment-20672163.\n\nSounds good, at least the option can be set before calling\ninstall_github. Maybe the wider issue here is why the internal unzip\nbehaves that way.\nIago\n. On 07/09/2013 04:10 PM, Kirill M\u00fcller wrote:\n\nWhat if there is no |unzip| executable, e.g., on Windows?\n\nThat appears to default to \"internal\". And file permissions are not an\nissue, as fai as I can see, in Windows.\nIago\n. Yes, this seems to work as expected. Many thanks.\nIago\n. ",
    "eusebe": "The remix package:\n``` R\n\ninstall_github(\"remix\", \"eusebe\")\nInstalling github repo(s) remix/master from eusebe\nDownloading remix.zip from https://github.com/eusebe/remix/archive/master.zip\nInstalling package from d:\\users\\G-BCH-~1\\AppData\\Local\\Temp\\RtmpQHyvBD/remix.zip\nInstalling remix\n\"C:/PROGRA~1/R/R-30~1.1/bin/x64/R\" --vanilla CMD INSTALL  \\\n  \"d:\\users\\G-BCH-5053164\\AppData\\Local\\Temp\\RtmpQHyvBD\\remix-master\"  \\\n  --library=\"C:/Program Files/R/R-3.0.1/library\" --with-keep.source  \\\n  --install-tests \n\n\ninstalling source package 'remix' ...\n** R\nError in .install_package_code_files(\".\", instdir) : \nfiles in 'd:/users/G-BCH-5053164/AppData/Local/Temp/RtmpQHyvBD/remix-master/R' missing from 'Collate' field:\n  layout.r\n  plot.r\nERROR: unable to collate and parse R files for package 'remix'\nremoving 'C:/Program Files/R/R-3.0.1/library/remix'\nrestoring previous 'C:/Program Files/R/R-3.0.1/library/remix'\nErreur : Command failed (1)\n\n```\n. Thank you very much!\n. ",
    "kornl": "Since I'm new to GitHub: Am I supposed to merge your upstream branch now and resolve the merge conflict in NEWS and add this merge to the pull request (or rebase it in some way) or is it fine the way it is?\n. Thanks and hopefully done.\n. Squished as wished.\n. ",
    "holstius": "I am trying to use dplyr in a data-generating file, and seemingly running into the same issue. Minimal example from a mock package mycars:\n```\nContents of mycars/data/mycars.R\nutils::data(cars, package=\"datasets\")\nlibrary(dplyr)\nmycars <- cars %>% group_by(speed)\n```\nThis yields:\n```\n\ndocument()\nUpdating mycars documentation\nLoading mycars\nError in eval(expr, envir, enclos) : could not find function \"%>%\"\n```\n\nNot being able to use %>% for readability is kind of a bummer!\n. Hmm ... nope, same problem. Thanks for the suggestion though.\nI understand you don't advocate for .R files in data/. My scenario is I've got a collaborator who is supplying .csv files, and I'm cleaning and reshaping them for use in a package. \nOur goal is to have both the .csv files and the cleaning/reshaping code under version control in the same repository.\n. That looks like good practice. Thanks!\n. ",
    "sritchie73": "Confirming that I'm having the same issue on Mac OSX, however I also get the same repeated warnings if I move the source files across to a server running Ubuntu and build there.\n. Mac OSX 10.8.4\nSessionInfo():\n```\nR version 3.0.0 (2013-04-03)\nPlatform: x86_64-apple-darwin12.3.0 (64-bit)\nlocale:\n[1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base \n```\nTar environment variables:\n```\n\nSys.getenv(\"TAR\")\n[1] \"/usr/bin/gnutar\"\nSys.getenv(\"R_BUILD_TAR\")\n[1] \"\"\nSys.which(\"tar\")\n           tar \n\"/usr/bin/tar\" \n```\n\nUbuntu 12.04.2\nSessionInfo():\n```\nR version 3.0.1 (2013-05-16)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nlocale:\n [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C            \n [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8  \n [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8 \n [7] LC_PAPER=C                 LC_NAME=C               \n [9] LC_ADDRESS=C               LC_TELEPHONE=C          \n[11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C       \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base \n```\nTar env variables:\n```\n\nSys.getenv(\"TAR\")\n[1] \"/bin/tar\"\nSys.getenv(\"R_BUILD_TAR\")\n[1] \"\"\nSys.which(\"tar\")\n       tar \n\"/bin/tar\" \n``\n. Yes, on both machines. The only possible discrepancy is that the folder the package in does not have the same name as the package (package folder ispackage, package name isFastModPres`).\n\n53100-B110155:FastModPres scottr$ R CMD build package\n* checking for file \u2018package/DESCRIPTION\u2019 ... OK\n* preparing \u2018FastModPres\u2019:\n* checking DESCRIPTION meta-information ... OK\n* cleaning src\n* checking for LF line-endings in source and make files\n* checking for empty or unneeded directories\n* building \u2018FastModPres_0.1.tar.gz\u2019 \nWarning in utils::tar(filepath, pkgname, compression = \"gzip\", compression_level = 9L,  :\n  number of items to replace is not a multiple of replacement length\nThis warning repeats a whole bunch of times.\n. I have create a new package with the DESCRIPTION file as follows:\nPackage: mypackage\nType: Package\nTitle: Placeholder \nVersion: 0.1\nDate: 2013-08-26\nAuthor: Me\nMaintainer: Me <sritchie73@gmail.com>\nDescription: Placeholder\nLicense: GPL\nDepends:\nAnd a blank NAMESPACE file. My current working directory has no unusual characters:\n/Users/scottr/workspace/FastModPres\nI still get 4 repeated warnings from tar:\n$ R CMD build mypackage\n* checking for file \u2018mypackage/DESCRIPTION\u2019 ... OK\n* preparing \u2018mypackage\u2019:\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files\n* checking for empty or unneeded directories\n* building \u2018mypackage_0.1.tar.gz\u2019\nWarning in utils::tar(filepath, pkgname, compression = \"gzip\", compression_level = 9L,  :\n  number of items to replace is not a multiple of replacement length\nWarning in utils::tar(filepath, pkgname, compression = \"gzip\", compression_level = 9L,  :\n  number of items to replace is not a multiple of replacement length\nWarning in utils::tar(filepath, pkgname, compression = \"gzip\", compression_level = 9L,  :\n  number of items to replace is not a multiple of replacement length\nWarning in utils::tar(filepath, pkgname, compression = \"gzip\", compression_level = 9L,  :\n  number of items to replace is not a multiple of replacement length\n. It seems to be an issue with R > 3.0.0.  I've also got a variant of R 2.15 (pretty quick R) installed, and I can use that to build without warnings.\n. I've also updated my Command Line Tools through Xcode as this resolved bug suggests, but i still get the warnings.\n. I have filed a bug report with the R core team since this does not appear to be related to devtools:\nhttps://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15436\n. Interesting will do. I don't have uid installed on either machine (and do not have super user permissions to do so on the ubuntu machine) but I suspect this is the case. My account on both machines was created from a University account, so I suspect they might have the same uid.\nI've found the following commands to get my user ID (im not sure if this returns the same result as uid):\nMac: dscl . -list /Users UniqueID gives me the unique id: 1421593977.\nUbuntu: echo \"$(id -u)\" gives me the unique id: 1424757904.\n. Ok, so I also have an older account on the Ubuntu server with a uid of 1003.  When I run R CMD build on an empty package from package.skeleton() i get no warnings from tar!\n. I've updated the bug report on the R-core site.\n. ",
    "EricArcher": "sritchie73: Will you list the results of your 'sessioninfo()' and the tar-related environmental variables I listed above to see if there are any differences? Thanks!\n. When trying \n\ndebug(tar)\ntools:::.build_packages(\"eiaGenetics\")\n\nI end up with the warning coming from\ndebug: uid <- info$uid\nBrowse[2]> \ndebug: if (!is.null(uid) && !is.na(uid)) header[109:115] <- charToRaw(sprintf(\"%07o\", \n    uid))\nBrowse[2]> \ndebug: header[109:115] <- charToRaw(sprintf(\"%07o\", uid))\nBrowse[2]> \nWarning in header[109:115] <- charToRaw(sprintf(\"%07o\", uid)) :\n  number of items to replace is not a multiple of replacement length\nand this seems to be the source of the problem:\nBrowse[2]> uid\n[1] 260048028\nBrowse[2]> info\n                 size isdir mode               mtime               ctime               atime       uid gid\neiaGenetics/data  204  TRUE  755 2013-08-08 15:05:57 2013-08-28 08:26:09 2013-08-28 08:26:35 260048028  20\n                 uname grname\neiaGenetics/data   eia  staff\nBrowse[2]> charToRaw(sprintf(\"%070\", uid))\nError in sprintf(\"%070\", uid) : unrecognised format specification '%070'\nBrowse[2]> charToRaw(sprintf(\"%07o\", uid))\n [1] 31 37 34 30 30 30 32 32 33 34\n...so this line is assigning the 10 element vector from 'charToRaw' to the 6 elements in 'header'.  I'm not familiar enough with tar file architecture to understand what these lines should be doing though.\n. I am logged into a WAN. \n'id' from my terminal shows my uid as being the same number as produced by 'file.info' in R.\n. I can confirm that this error does not occur in R 3.2.4 revised, but does occur in 3.3.0.\nThe error I get can be replicated with the following object:\n```\n\nx$value@defined\nAn object of class \u201csignature\u201d\n       x \n\"gtypes\" \nstr(x$value@defined)\nFormal class 'signature' [package \"methods\"] with 3 slots\n  ..@ .Data  : chr \"gtypes\"\n  ..@ names  : chr \"x\"\n  ..@ package: chr \"roxygen_devtest\"\n```\n\nIn R 3.2.4, this is the result I get:\n```\n\nas.vector(x$value@defined, \"character\")\n[1] \"gtypes\"\n```\n\nIn R 3.3.0, I get the C stack error described above and in [https://github.com/klutometis/roxygen/issues/475]\nIn the NEWS file for 3.3.0 there are these two lines that might be relevant:\n```\nC-LEVEL FACILITIES:\n* New API call R_orderVector1, a faster one-argument version of\n  R_orderVector.\n\nBUG FIXES:\n* C-level asChar(x) is fixed for when x is not a vector, and it\n  returns \"TRUE\"/\"FALSE\" instead of \"T\"/\"F\" for logical vectors.\n\n```\n. Based on a suggestion by Luke Tierney, I removed packages one-by-one to see if I could make the error go away with that. When I removed Matrix (v1.2-6 on R 3.3.1), I got no error. Matrix automatically reinstalls (same version), but all is good now.\n. ",
    "FarrelBuch": "@wch I ran those commands and this is what I got\n```\n\npackageVersion('whisker')\n[1] \u20180.3.2\u2019\npackageVersion('devtools')\n[1] \u20181.3\u2019\nsessionInfo() \nR version 3.0.1 (2013-05-16)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\n\nlocale:\n[1] LC_COLLATE=English_United States.1252 \n[2] LC_CTYPE=English_United States.1252 \n[3] LC_MONETARY=English_United States.1252\n[4] LC_NUMERIC=C                        \n[5] LC_TIME=English_United States.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base   \n```\nSo then I tried to load devtools. All of this was done in a regular old R console. Rstudio is on my computer but I had not opened it.\n```\n\nrequire(devtools)\nLoading required package: devtools\nError in namespaceExport(ns, exports) : \n  undefined exports: iteratelist, rowSplit, whisker.escape, whisker.render\n```\n\n. @wch I did as you suggested\n```\n\nlibrary(whisker)\nError in namespaceExport(ns, exports) : \n  undefined exports: iteratelist, rowSplit, whisker.escape, whisker.render\nError: package or namespace load failed for \u2018whisker\u2019\n```\n\nThat led me to believe, (stimulated by the suggestion of Dwin on my stackoverflow question, that I may be able to solve the problem of devtools by deleting the whisker folders I had on my hard drive and then reinstalling. Voil\u00e0! It worked. I can now load devtools and whisker. Thank you for your help. I did not even know about whisker as a package. \n. ",
    "jeffwong": "I saw this too.  the source_gist command uses source_url underneath, which uses Rcurl to retrieve the file; if you enter https://raw.github.com/gist/1654919 into your web browser you'll find that it truly doesn't exist.  I think github must have changed the way it structures its urls, and devtools just hasn't caught up\nHere is a link on SO describing how gist urls have changed\nhttp://stackoverflow.com/questions/12522539/github-gist-editing-without-changing-url\n. Here's a quick fix that should do the trick - note that username has to be passed in now.  It would be cool if there was some kind of regex to extract the username from a url if the user specified something like\nhttps://gist.github.com/jeffwong/6517317\nsource_gist <- function(entry, username, ..., sha1 = NULL) {\n  # 1654919 or \"1654919\"\n  if (is.numeric(entry) ||  grepl(\"^[0-9a-f]+$\", entry)) {\n    entry <- sprintf(\"https://gist.github.com/%s/%s/raw\", username, entry)\n  }\n  # https://gist.github.com/kohske/1654919, https://gist.github.com/1654919,\n  # or gist.github.com/1654919\n  else if (grepl(\"((^https://)|^)gist.github.com/([^/]+/)?[0-9a-f]+$\", entry)) {\n    entry <- sprintf(\"https://gist.github.com/%s/%s/raw\",\n                     username,\n                     regmatches(entry, regexpr(\"[0-9a-f]+$\", entry)))\n  }\n  print(entry)\n  source_url(entry, ..., sha1 = sha1)\n}\n. Strange worked fine for me too yesterday, but not working right now\n. Just upgraded to R 3.0.2 with devtools 1.4.1.  Still can't source_gist\n```\n Connection #0 seems to be dead!\n Closing connection #0\n About to connect() to api.github.com port 443 (#0)\n   Trying 192.30.252.138...\n connected\n Connected to api.github.com (192.30.252.138) port 443 (#0)\n successfully set certificate verify locations:\n   CAfile: /Library/Frameworks/R.framework/Versions/3.0/Resources/library/RCurl/CurlSSL/cacert.pem\n  CApath: none\n SSL re-using session ID\n SSL connection using AES128-SHA\n Server certificate:\n    subject: C=US; ST=California; L=San Francisco; O=GitHub, Inc.; CN=.github.com\n    start date: 2012-04-30 00:00:00 GMT\n    expire date: 2014-07-09 12:00:00 GMT\n    subjectAltName: api.github.com matched\n    issuer: C=US; O=DigiCert Inc; OU=www.digicert.com; CN=DigiCert High Assurance CA-3\n    SSL certificate verify ok.\n\nGET /gists/5101679 HTTP/1.1\nHost: api.github.com\nAccept: /\nAccept-Encoding: gzip\nUser-agent: hadley/devtools\n\n< HTTP/1.1 403 Forbidden\n< Server: GitHub.com\n< Date: Tue, 07 Jan 2014 22:28:36 GMT\n< Content-Type: application/json; charset=utf-8\n< Transfer-Encoding: chunked\n< Status: 403 Forbidden\n< X-RateLimit-Limit: 60\n< X-RateLimit-Remaining: 0\n< X-RateLimit-Reset: 1389134558\n< X-GitHub-Media-Type: github.beta\n< X-Content-Type-Options: nosniff\n< Access-Control-Allow-Credentials: true\n< Access-Control-Expose-Headers: ETag, Link, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval\n< Access-Control-Allow-Origin: \n< X-GitHub-Request-Id: 4535ED48:06F3:6CD2C68:52CC7F94\n< Content-Encoding: gzip\n< \n Connection #0 to host api.github.com left intact\nError: client error: (403) Forbidden\nR version 3.0.2 (2013-09-25)\nPlatform: x86_64-apple-darwin10.8.0 (64-bit)\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n [1] httr_0.2             data.table_1.8.10    TimeProjection_0.2.0 Matrix_1.0-14        lattice_0.20-23      timeDate_3010.98     lubridate_1.3.3   \n [8] forecast_4.8         reshape2_1.2.2       ggplot2_0.9.3.1      devtools_1.4.1       teradataR_1.0.2      RJDBC_0.2-3          rJava_0.9-6       \n[15] DBI_0.2-7           \nloaded via a namespace (and not attached):\n [1] colorspace_1.2-4      dichromat_2.0-0       digest_0.6.4          evaluate_0.5.1        fracdiff_1.4-2        grid_3.0.2         \n [7] gtable_0.1.2          labeling_0.2          MASS_7.3-29           memoise_0.1           munsell_0.4.2         nnet_7.3-7         \n[13] parallel_3.0.2        plyr_1.8              proto_0.3-10          quadprog_1.5-5        RColorBrewer_1.0-5    Rcpp_0.10.6        \n[19] RcppArmadillo_0.4.000 RCurl_1.95-4.1        scales_0.2.3          stringr_0.6.2         tools_3.0.2           tseries_0.10-32    \n[25] whisker_0.3-2         zoo_1.7-10\n```\n. Yes discovered it is possible through install_git\n. A strange consequence to this is Rcpp cannot be required after devtools\n\nrequire(Rcpp)\nLoading required package: Rcpp\nError in unloadNamespace(package) :\n  namespace \u2018Rcpp\u2019 is imported by \u2018xml2\u2019 so cannot be unloaded\nFailed with error:  \u2018Package \u2018Rcpp\u2019 version 0.11.6 cannot be unloaded\u2019\n. Sorry I was the culprit on the first issue of not being able to update Rcpp because it's already loaded - this was because I had a require(Rcpp) tucked away in my script. However the second issue is pretty strange\n\nrequire(devtools)\nrequire(Rcpp)\nin a clean R session will show an error. If you require them in the opposite order it will go succeed though\n. ",
    "sfuj": "apologies @hadley, although those urls were from ?source_gist, I should've tried them before posting. \nJust created a dummy public gist.. if that helps.\n. ",
    "randy3k": "any way to install the latest release via install_github?\nnow, it is only possible to install a particular tag/commit\n. I think a better way may be install_github(\"user/repo\") will install the latest release by default, if there are no releases, then use the latest commit.\nBecause releases are supposed to be installable but the latest commit does not.\n. @hadley , the reason I brought up this is to avoid dependence on CRAN. I feel like some developers are not pushing their releases to CRAN due to its strict R CMD check.\nIn this way, developers will get back the controls. It may be even more useful to allow binary releases for different platforms (ignore possible security considerations).\n. how about user/repo@* for latest release and user/repo^ for development (^  means HEAD) and mapping user/repo to  user/repo^ with an option to  user/repo@*.\n. Also, if you are building Rmarkdown files, make sure you have put\nVignetteBuilder: knitr\nin the DESCRIPTION.. ",
    "SimonHStats": "My apologies if this is a duplicate, I did check similar problems and didn't see this raised.\n. I've asked a question related to this on StackOverflow, http://stackoverflow.com/questions/19221520/error-when-installing-rga-package but as you can see the title is a bit off, because i thought it was a problem with 'rga' but I've found the same problems with the 'ganalytics' package too.\nEDIT: And I get a similar error for the 'shiny' package. All seems to be going fine and the I get told that there is no package called 'shiny' is it possible that install_github doesn't have access to the relevant library paths? (from the output it seems to, but doesn't seem to find what it needs.....\n. Sure thing\n.libPaths()\n[1] \"\\..../personal/..../simon.hayward/Documents/R/win-library/3.0\"\n[2] \"C:/Program Files/R/R-3.0.1/library\"\nThe ellipses are just there to hide some company specific stuff.\nEDIT: Just realised github is hiding some of the backslashes at the beginning of the first path, there are four in the R output, so they should be escaped properly.\n. .libPaths()\n[1] \"\\\\thiscompany.office/personal/userdata-Inthistown/simon.hayward/Documents/R/win-library/3.0\"\n[2] \"C:/Program Files/R/R-3.0.1/library\"\nI've added extra backslashes at the beginning of the string so it now appears exactly as I see it in RStudio.\nThanks Hadley.\n. Yes, the top one is shared. If I try to write to the local drive (by deleting the network drive as a libPath) I get\n\"Warning in install.packages(deps, dependencies = dependencies) :\n  'lib = \"C:/Program Files/R/R-3.0.1/library\"' is not writable\"\nSo the shared drive library was set by default when I tried to install a package and it couldn't install on the C drive with R (if I recall correctly), so it created another library elsewhere. Maybe I need to speak to a sysadmin about getting write permission for the C: drive and that make allow the installation?\nI don't know why install_github wouldn't just write to the library on the shared drive as install.packages has been doing, but then again I don't really know enough to fix this kind of issue when it arises.\n. Yes, here's me installing ggmap for example, just now\ninstall.packages(\"ggmap\")\nInstalling package into \u2018\\this.office/personal/UserData-thistown/simon.hayward/Documents/R/win-library/3.0\u2019\n(as \u2018lib\u2019 is unspecified)\ntrying URL 'http://cran.rstudio.com/bin/windows/contrib/3.0/ggmap_2.3.zip'\nContent type 'application/zip' length 4529269 bytes (4.3 Mb)\nopened URL\ndownloaded 4.3 Mb\n. Odd that it tells me 'lib' is unspecified, yet .libPaths() gives me two paths to libraries.\n. Managed it to install it ok on my home computer, which has a very similar stack. So must be that it can't write to the local library, and the shared network folder is a problem. Github has complained when I tried to use that for my repository before.\nI will send the new version to myself at work (I'm at home now), to try tomorrow. Thanks for the continued help.\n. Still no luck on my work machine with version 1.3.99 of devtools, still the same error when I try to use install_github.\nI did get the following warning when installing devtools\n\"Warning in install.packages :\n  package \u2018//this.office/personal/UserData-thisTown/simon.hayward/Downloads/devtools_1.3.99.zip\u2019 is not available (for R version 3.0.1)\"\nBut it seems to have installed ok, and the version in my library on the network drive is 1.3.99 according to the decription file.\nI'm going to ask the sys admins if I there's a way that I can have my R library on the C: drive, it seems a ludicrous restriction that R can't save packages there.\n. I'm now pretty sure that this is an issue with 1. The C drive and my needing admin privileges to write to it. I don't know how I would invoke those privileges within R or R studio. 2. So, R is using a local library on the network shared drive for my other packages, but I think github is sulking because of the \\ at the beginning of the network drive filepath, so between the two issues, I'm unable to use install_github :(\n. No joy, the error message states\nError in C(\"/this.office/personal/UserData-thistown/simon.hayward/Documents/R/win-library/3.0\",  : \n  object not interpretable as a factor\nAgain GitHub has eaten one of the forward slashes. Yes the R output has 4 backslashes in the first part of the .libPath() output.\nIs there anyway for devtools to install from a local zip file? I've tried installing 'rga' from a local zip (using install.packages) but R tells me that it isn't a valid package, (since it is still under development). \nFurther: I need admin privileges to write to the C: drive on my computer. I've tried running RStudio as an admin but it still won't write to the C: drive. Is there anyway I could pass elevated privileges to install_github?\n. Right, I'm a fool.\nI changed to .libPaths(\"//this.office/personal/UserData-thistown/simon.hayward/Documents/R/win-library/3.0\")  succesfully, but now my error message is as follows:-\n installing source package 'rga' ...\n* R\n* preparing package for lazy loading\n* help\n* installing help indices\n* building package indices\n* testing if installed package can be loaded\n* arch - i386\nWarning in library(pkg_name, lib.loc = lib, character.only = TRUE, logical.return = TRUE) :\n  there is no package called 'rga'\nError: loading failed\nExecution halted\n** arch - x64\nWarning in library(pkg_name, lib.loc = lib, character.only = TRUE, logical.return = TRUE) :\n  there is no package called 'rga'\nError: loading failed\nExecution halted\nERROR: loading failed for 'i386', 'x64'\n removing '\\this.office/personal/UserData-thistown/simon.hayward/Documents/R/win-library/3.0/rga'\nError: Command failed (1)\nWhich is at least different to what I had before! :)\n. The output of .libPaths() still has the 4 backslashes, although it seemed to change succesfully. Should have checked more carefully.\n. Yes, that's a good idea, I'll have to speak to the senior sysadmin on Monday, rather than monkeying with registry entries!\nThanks Hadley you're a good man and thorough. Have a good weekend.\n. Yes! It worked! (Also it's easier now to map a drive to a letter than it used to be).\nThanks a bunch Professor!\n. ",
    "xianyongyin": "Hi Simon,\nHow did you solve this problem? I have an identical problem when I was trying to install a package from github using install_github into a share disc.\n . ",
    "romainfrancois": "Something like this: \ngithub_issues <- function(repo=\"devtools\", user = getOption( \"github.user\" )){\n    if( isTRUE(grepl(\"/\", repo)) ){\n        rx <- \"^(.*)/(.*)$\"\n        user <- sub( rx, \"\\\\1\", repo )\n        repo <- sub( rx, \"\\\\2\", repo )\n    }\n    url <- sprintf( \"https://api.github.com/repos/%s/%s/issues\", user, repo )\n    json <- GET(url)\n    fromJSON(json)    \n}\nBut further manipulating the json output to make it look nice and useful. But I'm getting a ouch when using rjson::fromJSON: \n```\n\ngithub_issues( \"hadley/devtools\")\nErreur dans fromJSON(json) :\n  STRING_ELT() can only be applied to a 'character vector', not a 'list'\n```\n\nSo I guess I'd need to patch rjson first. \n. I have this in my ~/bin/github_issues: \n```\n!/usr/bin/Rscript\nlibrary(methods)\nlibrary(devtools)\nlibrary(rjson) \nlibrary(httr)\ngithub_issues <- function(repo=\"devtools\", user = getOption( \"github.user\" )){\n  if( isTRUE(grepl(\"/\", repo)) ){\n      rx <- \"^(.)/(.)$\"\n      user <- sub( rx, \"\\1\", repo )\n      repo <- sub( rx, \"\\2\", repo )\n  }\n  url <- sprintf( \"https://api.github.com/repos/%s/%s/issues\", user, repo )\n  json <- content(GET(url), \"text\" )\n  data <- fromJSON(json)\n  out <- data.frame( \n    number = sapply( data, function(x) x$number ), \n    user   = sapply( data, function(x) x$user$login ),\n    title  = sapply( data, function(x) x$title ), \n    labels = sapply( data, function(x) { \n      lab <- x[[\"labels\"]] \n      paste( sapply( lab, function(.) .$name ), collapse = \", \" )\n    })\n  )\n  out\n}\nargs <- commandArgs(TRUE)\noptions( width = 200 )\ngithub_issues( tail( args, 1L) )\n```\nSo that I can do: \n$ github_issues hadley/dplyr\n   number           user                                                         title                labels\n1      98         hadley                                   Setup databases with travis           enhancement\n2      97         hadley                                               Unique operator           enhancement\n3      96         hadley                           Implement right join and outer join           enhancement\n4      95 romainfrancois                                             Hybrid evaluation enhancement, internal\n5      94         hadley                 Make sure all vignettes work from R CMD check                   bug\n6      93         hadley               Document and implement \"col aligning operators\"           enhancement\n7      91         hadley                                                MySQL problems                   bug\n8      82         hadley                  equal_data_frame should be more configurable           enhancement\n9      78         hadley Provide version of equal_data_frame that works like all.equal           enhancement\n10     62 romainfrancois                                      Registration of reducers              internal\n11     57 romainfrancois                                     Support more result types              internal\n12     44         hadley                               Strict version of translate_sql           enhancement\n13     43         hadley                  Consistent interface for windowing functions           enhancement\n14     40         hadley                                        Should tbl_dt be lazy?           enhancement\n15     37         hadley                                  Implement ganalytics backend           enhancement\n16     35         hadley                                        Simplify generated sql           enhancement\n17     29         hadley                                            Plyr compatibility           enhancement\n18     14         hadley                                       Other types of grouping           enhancement\n19      8         hadley                                               MonetDB backend           enhancement\nMaybe it does not need to go on devtools. One thing I though we could do is settle on some convention about chunk of code that goes in an issue, so that we could do something like this: \ntest_github_issue( \"hadley/dplyr/#95\" )\nThis would grab code from the issue, and just run it. Would be a nice way to go about \"did I fix this issue ?\". Now what I do is copy and paste the code into some temp file and run this temp file.\n. Closing this as siesta now offers a way to do it. \n. Nevermind. bad idea. \n. I think this goes beyond devtools. I have this vague idea for a boostjam type of thing for RC++ related code where you would declare somehow dependencies (Rcpp.*, armadillo, RcppParallel, etc ...) and their version and it just sets up a repo for you with a standalone package that contains all the necessary code. This is still pretty vague, but that's the direction I want to go to. \n. That's definitely an Rcpp issue, please log it on theire repo. \nI currently don't have time to offer a fix\n. ",
    "tbates": "when no gzip is found, suggest re-installing R from CRAN\n. It would be very helpful to have test_.r files created whenever an Rd file is created (i.e., as part of the build function). Perhaps dropping in the example code as a starter when the file doesn't exist.\nPerhaps rather than add everything with create() have create end by saying \"you might like to try add_travis(); update_version(); news(); and create_README()\n. Glad if people have the time to implement this, I can see the use and I get that people have religion about tracking built files...\nBut for most users, building Rd files locally will be a source of many intractable errors.  That will then lead to them bugging package authors and Hadley... Might be wise to prominently recommend storing the pre-built .Rd files if non-experts are using your package?\n. amen to avoiding Rtools for windows users. \"CRAN 2.0\" sounds good, although the severe checking they impose does give a boost to confidence about code integrity.\n. pre-processing those files to replace non-ASCII with {rd codes} would be nice. Then we could write using legible UTF-8, but R would still see what it currently wants.\nOn 7 Feb 2014, at 16:28, homerhanumat notifications@github.com wrote:\n\nThanks. I will add utf-8 to my growing \"be aware of\" list!\n\u2014\nReply to this email directly or view it on GitHub.\n. It would be great if users didn't have to hard-code their passwords in scripts (bad because of exposing passwords in what are often open documents and making the script person-specific\n\nIf auth_user/password could be cached on their machine like ssl access can be that would be great!\n. There are plenty of auto generated files already in your version control:\nRd files for instance. If you like, you could not add them to vc and just\ngenerate them at all the locations you compile from?\nOn Mar 31, 2014 11:53 AM, \"Konrad Rudolph\" notifications@github.com wrote:\n\nThe install_* family of functions which install from a repository (git,\ngithub, gitorious, bitbucket \u2026) require non-source files in that\nrepository in order to work.\nIn particular, it requires a NAMESPACE file in the repository, even\nthough said file is generated from source (#' @export directives), and\nshould therefore not be put under version control. The error I\u2019m getting is\n- installing source package 'packagename' ...\n  ERROR: a 'NAMESPACE' file is required\nAs a consequence, I cannot use it to install a GitHub hosted package\nwithout putting auto-generated files under version control.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/449\n.\n. I vote \"deprecrated\" becomes a valid word in English :-)\nwarning(\"'password' is deprecrated. Please use 'auth_token' instead\",\n. supercilous answer \"yes\" :-)\nIf you look at the cran page\n\nDepends:    R (\u2265 3.0.2)\nSo: Install 3.0.2 or later if you have permission\n. install_github_enterprise() would be nice with an accompanying \ndevtools_git_enterprise() function which returned this info when called with no arguments and wrote them to the environment when given a parameter value.\nthen this would work:\nsplus\ninstall_github_enterprise(repo=\"kickass\", github_url = devtools_git_enterprise() )\n. Should be closed: this doesn't replicate under roxygen 5.0.1\n```\n' f\n' @param\n' @export\n'\nf <- function() {\n}\n```\nBuild error:\n    @param [test.r#3]: requires a value \npackageVersion(\"roxygen2\")\n[1] \u20185.0.1\u2019\n. Ahh.. So this is perhaps a bug report for RStudio (which in it's package update dialog links to news and too a blank page for devtools\n. Just to note that this is currently backwards incompatible and requires some coding changes in consuming packages. (now getting an error from release check in code updated for dev version).\ndevtools::check_win()\n\nMissing or unexported object: \u2018devtools::check_win\u2019\npackageVersion(\"devtools\")\n[1] \u20181.13.3\u2019\n\n. Manually grabbing callr succeeded. I see callr installed two new dependencies - perhaps that was the hiccup. So, people should be installing callr first before devtools\nsource(\"https://install-github.me/r-lib/callr\")\nDownloading GitHub repo r-lib/callr@master\nInstalling 2 packages: debugme, processx\n* installing *source* package \u2018callr\u2019 ...\nThe devtools source line, however yielded the following Warning messages:\n1: In utils::install.packages(...) :\n  installation of package \u2018/var/folders/nk/c_89sgqd3tv4gfwty7tzkmj80000gn/T//RtmpRROAWG/remotesb4585adbf006/hadley-testthat-c7e8330\u2019 had non-zero exit status\n2: In utils::install.packages(...) :\n  installation of package \u2018/var/folders/nk/c_89sgqd3tv4gfwty7tzkmj80000gn/T//RtmpRROAWG/remotesb4583aab6e58/tidyverse-rlang-53ebc71\u2019 had non-zero exit status\nI then quit R, reopened, and tried building a package.\nThis triggered some additional package downloading, and scales failed\n```\nInstalling scales\nRunning command /Library/Frameworks/R.framework/Resources/bin/R \nArguments:\nCMD\nINSTALL\n/private/var/folders/nk/c_89sgqd3tv4gfwty7tzkmj80000gn/T/RtmpDgn8tU/devtoolsc99819a202ec/scales\n--library=/Library/Frameworks/R.framework/Versions/3.4/Resources/library\n--install-tests\nInstallation failed: run(bin, args = real_cmdargs, stdout_line_callback = real_callback(stdout),      stderr_line_callback = real_callback(stderr), stdout_callback = real_block_callback,      stderr_callback = real_block_callback, echo_cmd = echo, echo = show,      spinner = spinner, error_on_status = fail_on_status, timeout = timeout) : System command error\nError in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) : derr), stdout_callback = real_block_callback,      stderr_callback = real_block_callback, echo_cmd = echo, echo = show,      spinner = spinner, error_on_status = fail_on_status, timeout = timeout) : System command error\n  namespace \u2018scales\u2019 0.4.1 is being loaded, but >= 0.5.0 is required\n```\nThis would not resolve with repeated attempts using devtools. The update of scales to .5 failed, leaving v 1.4.1 of scales installed.\n.5.0 is  just the CRAN version, and a simple install.packages(\"scales\") fixed it, so unclear what's going wrong when devtools tries too...\nAll's working now.. @jimhester  after some more manual installs got it all working.\nFYI, though, just got this error running release\nError: \u2018rversions\u2019 is not in Suggests: for pkgload!\n\nTrying to do a win check yields this error:\nError: \u2018curl\u2019 is not in Suggests: for pkgload!. At a first glance, it appears a solution is for devtools to use [spelling](https://github.com/ropensci/spelling) instead of `hunspell`.\n\nThen switch to calling spell_check_package(\".\") to just inherit spelling's smart parsing and also any inst/WORDLIST file contained in the package.\n. not sure if it does or not.\nUsing the latest github devtools::release() with check=TRUE, I'm not now seeing any spell checking done, and introducing typos doesn't give a type list (I have a WORDLIST in the package).\nAlso, not sure the process is functioning correctly, as after I OK that I have done a win build, I get this error about finding package root:\nHave you checked on win-builder (with `check_win_devel()`)?\n# 1: Yeah\nError: Could not find package root.\n\nThis is with\npackageVersion(\"devtools\")\n\n[1] \u20181.13.3.9000\u2019. thanks @jimhester! spell_check working nicely with WORDLIST, and great to break out spell_check from release - much quicker iterating to a successful outcome. This seems to be a show stopper for the dev version of devtools\n```Splus\ndevtools::release()\nError in stop(github_error(req)) : \n  This endpoint requires you to be authenticated. (401)\n```\n. I don't think there is a package called zlib. But I installed devtools on R 3.5.1 under MacOS just fine.\nhttps://cran.r-project.org/web/packages/zlib/. OK: so going forward we can use spelling::spell_check_package (if devtools::spell_check just calls it. Makes sense.\nSorry for the false alarm,\nt\nPS: I see the Rd for spell_check still refers to hunspell\n\nOther languages require installation of a custom dictionary, see the hunspell vignette\n\nPPS: I guess y'all have made the cost/benefit analysis, but backward-incompatible changes in devtools make it hard to keep up with: When the dev version gets in a non-functional state, one can't fall back on the CRAN version as dependent packages may compile on either devtools dev OR devtools CRAN, but not both as the changes break functions that depend on devtools... \ne.g. Since the June CRAN release, the dev version dropped the spell parameter from release.\n. working fine here under packageVersion(\"devtools\")  \u20182.0.1.9000\u2019, including for this textnets package...\nR\ninstall_github(\"cbail/textnets\")\nDownloading GitHub repo cbail/textnets@master\nbroom       (NA     -> 0.5.1     ) [CRAN]\ndata.table  (1.11.4 -> 1.12.0    ) [CRAN]\nfarver      (NA     -> 1.1.0     ) [CRAN]\ngenerics    (NA     -> 0.0.2     ) [CRAN]\nggforce     (NA     -> 0.1.3     ) [CRAN]\nggraph      (NA     -> 1.0.2     ) [CRAN]\nggrepel     (NA     -> 0.8.0     ) [CRAN]\nhunspell    (2.9    -> 3.0       ) [CRAN]\nISOcodes    (NA     -> 2018.06.29) [CRAN]\njaneaustenr (NA     -> 0.1.5     ) [CRAN]\nnetworkD3   (NA     -> 0.4       ) [CRAN]\nSnowballC   (NA     -> 0.6.0     ) [CRAN]\nstopwords   (NA     -> 0.9.0     ) [CRAN]\ntidytext    (NA     -> 0.2.0     ) [CRAN]\ntokenizers  (NA     -> 0.2.1     ) [CRAN]\ntweenr      (NA     -> 1.0.1     ) [CRAN]\nudpipe      (NA     -> 0.8       ) [CRAN]\nunits       (NA     -> 0.6-2     ) [CRAN]\nInstalling 18 packages: broom, data.table, farver, generics, ggforce, ggraph, ggrepel, hunspell, ISOcodes, janeaustenr, networkD3, SnowballC, stopwords, tidytext, tokenizers, tweenr, udpipe, units\ntrying URL 'https://cloud.r-project.org/bin/macosx/el-capitan/contrib/3.5/broom_0.5.1.tgz'\nContent type 'application/x-gzip' length 1992593 bytes (1.9 MB)\n==================================================\ndownloaded 1.9 MB\n... etc.\n. ",
    "jcheng5": "How's that @hadley?\n. OK, amended and force-pushed.\n. ",
    "mattsigal": "After the update, I ran: update.packages(checkBuilt=TRUE, ask=FALSE), which ran fine (no errors), but mirt still gives the above error.  I'll try reinstalling R/my packages.\n. Fresh R install; fresh libraries folder.  I can install from github packages that don't have compiled code.  However, packages with compiled code (e.g., mirt and lme4) yield the same crash.\n. Thanks for the insight, Hadley!  After reinstalling Rcpp from source, mirt installed successfully.\n. ",
    "famuvie": "You are right. It works in that case. \nIt has nothing to do with the virtual machine, after all.\n. No... actually, the build took place a few days before, and was under R version 3.0.3 (2014-03-06)\n. I can workaround by modifying run-all.R like\nif(require(testthat)) test_package(---)\nBut it was nice to have the package tested under Windoze...\n. https://github.com/famuvie/breedR\n. Oops. I'm really sorry. Thank you.\n. Mmm... contrary to #848, with this reverse removing of classes the error arises when the derived class is named 'splines'. What is it special with this name?\n. Ok. There is nothing particular with the class name splines except for the fact that alphabetically comes after my_class. The current devtools version removes classes by alphabetical order which happen to coincide with inheritance hierarchy (i.e. my_class is extended by splines).\nI needed to write a small routine to sort the classes defined in the package, so that extended classes are before their respective extensions. With this approach I think the problem is solved.\n. Right. My solution worked for me, but not necessarily in general.\nImplemented a topological sorting. Not very fast in R, but graphs of classes should not be huge.\n. sure... in a couple of weeks.\n. Done, with some modifications thanks to the testing.\nIncidentally, this fixes one previously failing check that was commented out in test-s4-unload.R.\n. Done.\n. I would certainly appreciate it.\n. Maybe a corrputed previous installation?\nTry manually removing the whole dir\n|C:/Users/Rvermaak/Documents/R/win-library/3.2/devtools/|\nand reinstall\n\u0192acu.-\nOn 09/30/2015 10:54 AM, csrvermaak wrote:\n\nHi Hadley\nI'm reading your book \u201cR packages\u201d, but unfortunately got stuck at the\nGetting Started section with the\ndevtools::install_github(\"hadley/devtools\") line.\nI've installed the packages:\ninstall.packages(c(\"devtools\", \"roxygen2\", \"testthat\", \"knitr\"))\nI've got the RStudio API:\nrstudioapi::isAvailable(\"0.99.149\")\n[1] TRUE\nBut, when I run the following:\ndevtools::install_github(\"hadley/devtools\")\nI get this:\ndevtools::install_github(\"hadley/devtools\")\nDownloading github repo hadley/devtools@master\nInstalling devtools\n\"C:/PROGRA~1/RRO/R-32~1.2/bin/x64/R\" --no-site-file --no-environ\n--no-save --no-restore CMD INSTALL \\\n\"C:/Users/Rvermaak/AppData/Local/Temp/Rtmpwnsawu/devtools2e2455761c23/hadley-devtools-81dd313\"\n\\\n--library=\"C:/Users/Rvermaak/Documents/R/win-library/3.2\"\n--install-tests\n- installing /source/ package 'devtools' ... * libs gcc -m64\n  -I\"C:/PROGRA~1/RRO/R-32~1.2/include\" -DNDEBUG\n  -I\"c:/applications/extsoft/include\" -O2 -Wall -std=gnu99\n  -mtune=core2 -c devtools.c -o devtools.o gcc -m64 -shared -s\n  -static-libgcc -o devtools.dll tmp.def devtools.o\n  -Lc:/applications/extsoft/lib/x64 -Lc:/applications/extsoft/lib\n  -LC:/PROGRA~1/RRO/R-32~1.2/bin/x64 -lR installing to\n  C:/Users/Rvermaak/Documents/R/win-library/3.2/devtools/libs/x64\n  Warning in file.copy(files, dest, overwrite = TRUE) : problem\n  copying .\\devtools.dll to\n  C:\\Users\\Rvermaak\\Documents\\R\\win-library\\3.2\\devtools\\libs\\x64\\devtools.dll:\n  Permission denied * R * inst * tests * preparing package for\n  lazy loading * help * installing help indices * building\n  package indices * installing vignettes ** testing if installed\n  package can be loaded\n- DONE (devtools)\n(NOTE: There is a file copy warning, but it seems to have installed fine?)\nWhen I try to subsequently load the library, things go a bit pear-shaped:\nlibrary(devtools)\nError in get(method, envir = home) :\nlazy-load database\n'C:/Users/Rvermaak/Documents/R/win-library/3.2/devtools/R/devtools.rdb'\nis corrupt\nIn addition: Warning message:\nIn get(method, envir = home) : internal error -3 in R_decompress1\nError: package or namespace load failed for \u2018devtools\u2019\nI've tried re-installing a few times, but I'm out of ideas. Please\nadvise?\nThank you in advance\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/942.\n\u200b\nSignature electronique\nINRA http://www.inra.fr\n\nFacundo MU\u00d1OZ\nPostdoctoral Statistician\nfacundo.munoz@orleans.inra.fr mailto:facundo.munoz@orleans.inra.fr\nInstitut National de la Recherche Agronomique - Centre Val de Loire\nUnit\u00e9 Am\u00e9lioration, G\u00e9n\u00e9tique et Physiologie Foresti\u00e8res\nT\u00e8l. : +33 (0)2 38 41 78 14\nFax : +33 (0)2 38 41 78 79\n2163 Avenue de la Pomme de Pin\nCS 40001 ARDON, 45075 ORLEANS Cedex 02\nFrance\nwww.inra.fr http://www.inra.fr\n. I am!!\nIn fact, part of the reason for which I have not moved already to GitLab is the lack of devtools support.\n. ",
    "VitlZ": "I have the same problem. Windows8.1 R v3.0.2. Could you please tell me what should I do?\ninstall_github(\"wch/ggplot2\")\nInstalling github repo wch/ggplot2@master from wch\nDownloading ggplot2.zip from https://api.github.com/repos/wch/ggplot2/zipball/master\nInstalling package from C:\\Users\\vitaly\\AppData\\Local\\Temp\\RtmpuGGCNn/ggplot2.zip\nError in system(full, intern = quiet, ignore.stderr = quiet, ...) : \n  '\"internal\"' not found\ntempdir() \"C:\\Users\\vitaly\\AppData\\Local\\Temp\\RtmpuGGCNn\"\nSessiion info\nR version 3.0.2 (2013-09-25)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nlocale:\n[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252\n[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base\nother attached packages:\n[1] skmExergy_1.0     devtools_1.5.0.99\nloaded via a namespace (and not attached):\n[1] digest_0.6.4   evaluate_0.5.5 httr_0.4       memoise_0.2.1  parallel_3.0.2 RCurl_1.95-4.3 stringr_0.6.2  tools_3.0.2\n[9] whisker_0.3-2 \n. \"\\RtmpuGGCNn/ggplot2.zip\"  May be slash difference is the reason?\n. ",
    "sckott": "symlinking  worked for me (reference: http://apple.stackexchange.com/questions/106189/missing-usr-bin-gnutar-on-mavericks-macports/106209#106209)\nsudo ln -s /usr/bin/tar /usr/bin/gnutar\n. Okay, thx\n. @benmarwick @wch is working on harbor https://github.com/wch/harbor - spawned at least in part so we could use it in analogsea - is that what you had in mind?\n. ",
    "ncarchedi": "I was having the same issue, but with check():\nChecking for any extra files in built .tar.gz file... sh: /usr/bin/gnutar: No such file or directory\nError in system(cmd, intern = TRUE) : error in running command\nIt looks like Apple got rid of /usr/bin/gnutar in OS X 10.9 (Mavericks). \nThis solved the problem and now check() passes with no error: http://day-to-day-stuff.blogspot.com/2013/11/installing-gnutar-on-maverick.html\nI'm on OS X 10.9.1 with R 3.0.2 and devtools 1.4.1.99.\n. There's a couple things going on here. I'm working on a solution.\n. At present (not including any changes made in this pull request), devtools options are not persistent between sessions. Is this your intention?\nExample: \n```\n\nlibrary(devtools)\ngetOption(\"devtools.desc.author\")\n[1] \"# getOptions('devtools.desc.author')\"\noptions(devtools.desc.author=\"'Nick Carchedi nick.carchedi@gmail.com [aut, cre]'\")\ngetOption(\"devtools.desc.author\")\n[1] \"'Nick Carchedi nick.carchedi@gmail.com [aut, cre]'\"\n\nRestarting R session...\nWelcome at Tue Jan 21 10:29:28 2014 \n\nlibrary(devtools)\ngetOption(\"devtools.desc.author\")\n[1] \"# getOptions('devtools.desc.author')\"\n```\n\nSession info:\n```\n\nsessionInfo()\nR version 3.0.2 (2013-09-25)\nPlatform: x86_64-apple-darwin10.8.0 (64-bit)\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.4.1.99\nloaded via a namespace (and not attached):\n[1] digest_0.6.4   evaluate_0.5.1 httr_0.2       memoise_0.1    parallel_3.0.2\n[6] RCurl_1.95-4.1 stringr_0.6.2  tools_3.0.2    whisker_0.3-2 \n```\n. This is worth some thought. I'll brainstorm some solutions this week or next and get back to you.\n. Sorry I haven't had a chance to work on this sooner. After running in a few circles, I settled on some small changes that should address both of these issues:\n1) http://stackoverflow.com/questions/17662713/devtools-description-file\n2) https://gist.github.com/mbannert/8403801\nHere's the result of my changes:\n```\n\nlibrary(devtools)\ncreate(\"myPackage\")\nCreating package myPackage in .\nNo DESCRIPTION found. Creating with values:\n\nPackage: myPackage\nTitle: \nDescription: \nVersion: 0.1\nAuthors@R: \"First Last first.last@example.com [aut, cre]\"\nDepends: R (>= 3.0.2)\nLicense: \nLazyData: true\nAdding Rstudio project file to myPackage\n\ndocument(\"myPackage\")\nLoading required package: roxygen2\nUpdating myPackage documentation\nLoading myPackage\nUpdating namespace directives\nWriting myPackage.Rd\n```\n. Another option is to align the default DESCRIPTION file for devtools with the one RStudio creates for you: \n\nPackage: myPackage\nType: Package\nTitle: What the package does (short line)\nVersion: 1.0\nDate: 2014-02-12\nAuthor: Who wrote it\nMaintainer: Who to complain to <yourfault@somewhere.net>\nDescription: More about what it does (maybe more than one line)\nLicense: What license is it under?\nI'm happy to make this change if it makes sense.\n. Okay, sounds good. I'm scrapping this pull request and starting with a clean slate. Hope to have something for you within a week.\n. All good suggestions. Here's the new output:\n```\n\ncreate(\"testPackage\")\nCreating package testPackage in .\nNo DESCRIPTION found. Creating with values:\n\nPackage: testPackage\nTitle: What the package does (short line)\nVersion: 0.1\nAuthors@R: \"First Last first.last@example.com [aut, cre]\"\nDescription: What the package does (paragraph)\nDepends: R (>= 3.0.2)\nLicense: What license is it under?\nLazyData: true\nAdding Rstudio project file to testPackage\n\n```\n. Sure, thanks! \n\nYou might consider bringing the RStudio defaults in line with the new devtools defaults. When you create a new package project in RStudio, here's what it gives you:\nPackage: testPackage\nType: Package\nTitle: What the package does (short line)\nVersion: 1.0\nDate: 2014-02-21\nAuthor: Who wrote it\nMaintainer: Who to complain to <yourfault@somewhere.net>\nDescription: More about what it does (maybe more than one line)\nLicense: What license is it under?\n. Sorry, I missed that. You're right.\n. ",
    "GISDev01": "For any future google'ers that end up here like I did, I actually had a similar issue with using devtools to install xml2 via the git repo. \nThis is the command and the error I was getting on Ubuntu 14.04.5 on an AWS EC2 box running Anaconda r-essentials as the R 3.2.2 distro:\ndevtools::install_git(\"git://github.com/hadley/xml2.git\", branch = \"master\")\nInstalling xml2\ntrying URL http://cran.rstudio.com/src/contrib/BH_1.60.0-2.tar.gz\nContent type application/x-gzip length 9783419 bytes (9.3 MB)\ndownloaded 9.3 MB\nsh: 1: /bin/gtar: not found\nTo fix it, I tried something similar to work worked for @sckott above:\nsudo ln -s /bin/tar /bin/gtar\nSure enough, symlinking gtar to the real tar did the trick, and the install went perfectly after that.  \nPretty sure this has nothing to do with any bugs in devtools or xml2, but something that is wacky with my PATH and Anaconda R having something up with it, but this did the trick for us.\n. ",
    "ressy": "Just to add a little more proof to what @GISDev01 mentioned (since I'm one of those future googlers), it's Sys.getenv(\"TAR\") by way of utils::untar that's to blame, at least in my case.  That getenv call returns /bin/gtar on my system for some reason.  (This is all inside an Anaconda-provided R install; it returns the correct path when using the OS-provided R package.)\nA simple fix that did the trick for me and doesn't require root access was just doing an export TAR=/bin/tar on the shell before launching R.  Then Sys.getenv(\"TAR\") just returns the actual environment variable instead of doing whatever magic it does to try to figure it out, and devtools can untar its dependencies during installation.. ",
    "carbocation": "To make this even simpler for people with this issue, calling the following in R resolved this issue for me without having to exit R, change my path, sudo, etc:\nSys.setenv(TAR = \"/bin/tar\"). ",
    "lgatto": "I investigated a bit and the error occurs in utils:::.read_description. The function seems to work fine if there is a blank line at the very end, but fails if it occurs in the middle of the file. However, devtools appends github-specific information (GithubRepo, GithubUsername, ...) at the end of the file, which eventually causes the error. \n. @hadley yes, of course, that's the most pragmatic fix. I have posted this on r-devel, to see if blank lines are supposed to trigger such an error or not. \n. @hadley Would you consider a pull request that checks/removes black lines before appending the Github lines? Something along the lines \ndesclines <- readLines(desc)\nwriteLines(desclines[!grepl('^[ \\t]*$', desclines)], desc)\nin install-github.r\n. ",
    "leeper": "How about something like this: https://gist.github.com/leeper/9123584\n. This function has been implemented in dtupdate.\n. Well, system2() is not a wrapper for system(); they're both wrappers for the same Internal but system() does not expose all of the arguments of that internal to the user. It seems like you want to be using system2() because that's the recommendation (according to the R docs) due to it providing finer control. And the code for system_check() is doing things like setting environment variables and concatenating a system command, which could be handled directly by system2(). (I assume that's why you were using system2() previously?)\nThat said, in terms of the specific problem motivating all of this, I think pointing to the .Rcheck file makes sense.\n. Interesting...that seems like a strange recommendation, then.\n. ngettext() is the general mechanism for internationalization of these types of messages. devtools doesn't have any message translations, so before and after this change all messages will be printed in English regardless of locale. If one were to contribute translations (.po files) with the correct pluralizations, they would be appropriately accessed after the change (but not under devtool's current behavior). So, this is an i18n step, l10n could come next.\n. Take an example from print.data.frame(): \nR\n    if(length(x) == 0L) {\n    cat(sprintf(ngettext(n, \"data frame with 0 columns and %d row\",\n                 \"data frame with 0 columns and %d rows\"),\n            n), \"\\n\", sep = \"\")\n    }\nWhat happens here is that in English there are only two possible pluralizations (for n==1 and for n != 1). They're provided as arguments to the function. The translations, say in Polish, are provided in a .po file in the package source:\nmsgid \"data frame with 0 columns and %d row\"\nmsgid_plural \"data frame with 0 columns and %d rows\"\nmsgstr[0] \"ramka danych z zerow\u0105 liczb\u0105 kolumn oraz %d wierszem\"\nmsgstr[1] \"ramka danych z zerow\u0105 liczb\u0105 kolumn oraz %d wierszami\"\nmsgstr[2] \"ramka danych z zerow\u0105 liczb\u0105 kolumn oraz %d wierszami\"\nWhen R is running in English, the arguments to ngettext() are used directly. When running in a different locale, the gettext catalog (if present and installed) is queried for the appropriate translation based on the value of n. The format above shows pluralizations for a three-plural language. \n(That's not a great example because the plural forms for n==1 and n>=2 are the same, but there apparently aren't any examples of easily-accessible messages in base R where the messages are actually different in those two forms in any translated language (there's an example of one here, but that message can't be triggered to display all of its possible values).)\nIn another (non-English), two-plural language like French, the file is similar but with only two translations:\nmsgid \"data frame with 0 columns and %d row\"\nmsgid_plural \"data frame with 0 columns and %d rows\"\nmsgstr[0] \"tableau de donn\u00e9es (data frame) avec 0 colonnes et %d lignes\"\nmsgstr[1] \"tableau de donn\u00e9es (data frame) avec 0 colonnes et %d lignes\"\nSo, in short, the value of the 2nd argument to ngettext() is used to look up translations in the catalog and the appropriate, pluralized translation is selected from among those available based on the value of n.\n. Just updated the commit to more closely mimic that style.\n. ",
    "kevinushey": "Sure. Here's a commit on my package that breaks install_github:\nhttps://github.com/kevinushey/Kmisc/commit/2e5f66201771919fa70001c69c45080338526387\nlibrary(devtools)\ninstall_github(\"Kmisc\", \"kevinushey\", ref=\"2e5f66201771919fa70001c69c45080338526387\")\nUndoing that fixes everything, of course (https://github.com/kevinushey/Kmisc/commit/94413062dc275993d0de3461ebf5edda4d708f0a)\nlibrary(devtools)\ninstall_github(\"Kmisc\", \"kevinushey\", ref=\"94413062dc275993d0de3461ebf5edda4d708f0a\")\nOf course, a more local solution as far as unit testing would be preferred, but either that means the code in install_github() should be refactored out into a testable piece or there needs to be some skeleton GitHub package that can be tested.\n. I was just able to run install_github(\"omegahat/Rcompression\") without issue, so at least it seems like the devtools side of things are in good shape (using the latest CRAN version of devtools + underlying packages).\nThat said, removing the trailing spaces as you have is an appropriate workaround if you're still seeing the issue.. That seems like a fair workaround. Ultimately it seems like the bug would lie in Packrat though, not devtools (it has its own version of install_github() used during restore). Ideally, this code should be versioned on the version of R being run / called:\nR\nif (getRversion() < \"3.0.0\") {\n    ...\n} else {\n    ...\n}\n. Did you mean to post this on the packrat issues page? Or are you more curious about a devtools + packrat approach to package development?\nAt minimum, you just need to commit the lockfile (packrat/packrat.lock), but we generally recommend committing package sources as well (just in case you depend on a package / version of a package that might be inaccessible for whatever reason).\n. Okay, but unless this is trivial to use then Rcpp11 won't be adopted. The less one has to learn to use Rcpp11 the better; and IMO the best-case scenario is that we make it super easy for someone already familiar with 'traditional' R package development to use Rcpp11.\nWhatever is used, it should be reducible to a single R function call or a single command line invocation (which could be called from R in some way)\n. I'm going to close this in lieu of using cmake + an automatically generated CMakeLists.txt file -- which would then allow many different IDEs to handle and R project (XCode, QtCreator, CLion, and so on...)\n. But that's only if you know that the extra comma was intentional and not a typo. and you can't know that without knowing the function's signature. I definitely don't think it's an idiom worth encouraging.\n. What is the output of Sys.getenv(\"R_HOME\")? Normally this should be a short path.\nIf it's not, do you have a ~/.Renviron where you set that explicitly, or something to that effect?\n. @hadley FYI, you can work around this by explicitly calling utils::shortPathName() to transform 'long' to 'short' paths. Note that this function only exists on Windows R so you'll have to properly shield its use from R CMD check.\n. @sabas, can you copy in some more output? My guess is that there is some .Renviron file that's causing a bad R_HOME to be populated. Try running this and please copy output back here:\n``` r\nif (file.exists(\"~/.Rprofile\"))\n    readLines(\"~/.Rprofile\")\nif (file.exists(\"~/.Renviron\"))\n    readLines(\"~/.Renviron\")\nSys.getenv()[grep(\"^R_\", names(Sys.getenv()))]\n```\n. @AnnePetersen1, one last thing that would be worth knowing: what if you try to execute R using the short path name? I'm curious what this reports on each machine (wherein you have R installed in a path containing spaces)\nR <- R.home(\"bin/R\")\nprint(R)\nR <- utils::shortPathName(R)\nprint(R)\nsystem(paste(R, \"RHOME\"))\n. What is the output of Sys.getenv(\"PATH\"), or what mechanism are you using to ensure that the Rtools toolchain is discovered? (It's possible that an incorrect version of gcc is getting picked up, for some reason)\n. Another thought -- do you have the 'old' version of Rtools installed in the usual place (e.g. C:/Rtools)? It's possible that devtools is putting that on the PATH before your custom toolchain (which might not be installed in the 'regular' location)?\n. Sure, I can take a shot at this.\n. This is an error in the tools package itself, so you might want to raise this with R core maintainers.\nHonestly, though, the lowest friction way of resolving this will be to just remove that apostrophe from your user name...\n. I think there are a couple options:\n1) Determine the appropriate NEWS link based on the contents of the https://cran.rstudio.com/web/packages/devtools/ landing page,\n2) Try both, and use the first one that works, \nOne potential option (which isn't great, but avoids a web request) is to infer the appropriate NEWS URL based on the locally installed package -- e.g. look for an installed version of devtools, and see if there is a NEWS.md versus NEWS file present. This probably isn't that bad, though, as I doubt many packages switch NEWS formats over time.\nI wonder what happens if a CRAN package is submitted with both NEWS and NEWS.md? Are both links populated? (One could imagine just having a build step that just copies NEWS.md to NEWS)\n. Yes indeed -- thanks for being the one to get started on this work!\n. This PR is motivated by packrat -- it tries to obtain package sources (as a tarball) and stores them alongside the project; we want to use the devtoools download machinery when appropriate (as this can handle GitHub authentication) and this change should help make it easier to obtain package sources as tarballs from GitHub.\n. Ah, shoot -- thanks for digging in. I'll see if we can use similar tricks to extract the header from the tarball.\n. It seems like the git commit id is not actually embedded in the tarballs distributed through the GitHub API, so we might have to revert that commit and go back to using zip. \ud83d\ude1e \n(git get-tar-commit-id is failing to discover the commit id, in my case)\n. Oops, sorry, they are -- but you have to un-gzip the file first (to get the plain tar archive), and then attempt to read from that.\nOverall, I think we might want to just revert to downloading zipballs. (Sorry for the noise!)\n. I believe this was actually an issue with the memoise package (I had a development version installed, and that was causing the issue). I think https://github.com/hadley/memoise/commit/e392c7b8ac4acedba57d8877a06b0a63d2a1a901 is the commit that fixed things up.. I'll try and see if I can figure out what's going on.. I see the same issue all the way back to RStudio v0.98.1091 (didn't test anything older, though) so this appears to be a long-standing issue.. @paternogbc can you replicate the crash outside of RStudio (e.g. in RGui.exe or similar)?. Just took a look at this alongside @jimhester: there's a bug in RStudio here that accidentally assumes that R is on the PATH (when we should instead just be using R.home(\"bin\")/R). We'll try to get this fixed up soon, but in the meantime you might want to just ensure that /usr/local/bin is also added to the PATH for the Docker image.. I believe this is because, with the open source version of RStudio Server, R sessions are not launched through a shell, and so don't inherit the default PATH. (I'm not exactly sure on the particulars so may need to dig in further). One way you could do this is by running e.g.\n/usr/lib/rstudio-server/bin/rsession --help\n\nbut I'm not aware of anything for setting the PATH here. (I think we would normally recommend setting it directly in an R startup file, e.g. Rprofile.site or Renviron.site or similar). Any chance that a CRAN release will be coming soon with this fix?. RStudio executes the moral equivalent of R --vanilla --slave -e 'devtools::check(<args>)' in this case, so I'm not sure where those repositories could be coming from. We don't make any special effort to overlay the current R options into the launched child R session or anything like that either.\nIt'd be helpful to see the whole devtools::check() output so we can know exactly where in the R CMD check process things are going awry.\nI know those repositories are typically pulled from BiocInstaller::biocinstallRepos() so maybe that's being called somewhere during the check process?. Can you give me a full run-through of the workflow you're imaging here? Would you also need the ability to programmatically refresh the Help pane? What information do you need from the Help pane (e.g. is just the URL being viewed sufficient)?. Maybe it would be sufficient for RStudio to just always refresh the Help pane after a Build pane action completes successfully?. I think the intention would be that devtools::document()s run in the current session would use rstudioapi to refresh the Help pane, but RStudio would just refresh the Help pane by default for things that happen in the Build pane.. I'll take a look!. I suspect that part of the issue is that dyn.unload() does not actually unload the associated DLL on Linux (for libraries containing static variables within inline functions):\n```\n\nlibrary(testthat)\nsystem(paste(\"lsof -p\", Sys.getpid(), \"| grep testthat.so\"))\nR       9125 kevin  mem    REG    8,1  4112576 1709656 /home/kevin/R/x86_64-pc-linux-gnu-library/3.4/testthat/libs/testthat.so\ndyn.unload(system.file(\"libs/testthat.so\", package = \"testthat\"))\nsystem(paste(\"lsof -p\", Sys.getpid(), \"| grep testthat.so\"))\nR       9125 kevin  mem    REG    8,1  4112576 1709656 /home/kevin/R/x86_64-pc-linux-gnu-library/3.4/testthat/libs/testthat.so\n```\n\nSome discussion of this issue on the RedHat bugzilla: https://bugzilla.redhat.com/show_bug.cgi?id=1215452\nThe GCC manpage has a flag -fno-gnu-unique that helps control behavior around how static data objects are initialized on unload / reload:\n\n-fno-gnu-unique\nOn systems with recent GNU assembler and C library, the C++ compiler uses the STB_GNU_UNIQUE binding to make sure that definitions of template static data members and static local variables in inline functions are unique even in the presence of RTLD_LOCAL; this is necessary to avoid problems with a library used by two different RTLD_LOCAL plugins depending on a definition in one of them and therefore disagreeing with the other one about the binding of the symbol. But this causes dlclose to be ignored for affected DSOs; if your program relies on reinitialization of a DSO via dlclose and dlopen, you can use -fno-gnu-unique.\n\nBut asking package authors to make this change isn't quite realistic. I'll have to think of a better solution.. I think my PR in https://github.com/r-lib/testthat/pull/779 will fix this without requiring extra compiler flags.. I think static variables in inline functions should be relatively rare. There's also the worry that (in theory) if a package is tested locally with -fno-gnu-unique but published to CRAN without that flag active, that some usages of that package would fail across unload + load.\nI suspect this issue will be rare enough that the issue is worth punting on until someone actually reports similar trouble.\nFWIW I went this route (inline function with static variable) just to minimize the amount of boilerplate needed in R packages that wanted to use Catch.. Are you a macOS user? Did you recently update to Mojave? If so, to install packages from source you'll need to reinstall command line tools and also install a special package that ensure C / C++ standard library headers get reinstalled at /usr/include.\ninstaller -pkg /Library/Developer/CommandLineTools/Packages/macOS_SDK_headers_for_macOS_10.14.pkg -target /\nThis was documented in the Xcode 10 release notes: https://developer.apple.com/documentation/xcode_release_notes/xcode_10_release_notes, but it's definitely an annoying change (if this is indeed the issue you're having). You can also try running /usr/bin/clang++ --version from the command line; you should be prompted if you do need to install command line tools.. Do you think devtools / remotes should do this? Could they use rprojroot::find_package_root_file() as a default? Or should I just learn to live with the change in behavior?. Thanks!. It's a pattern we were using in the IDE:\nhttps://github.com/rstudio/rstudio/pull/3876\nIt made it easier to (only using devtools) load a package when given the path to a test file living within that package.. Thanks!. Done!\n. This won't get run if testthat infrastructure (minus Catch) has already been initialized (e.g. you can't run devtools::use_testthat(catch = TRUE) to add Catch to a package already using testthat).\nCould that be alleviated? E.g. move this to a separate function, use_catch()), and call it earlier in the use_testthat() call?\n. It looks like this fails if the src/ directory does not exist already.\n. Should this be use_template(\"test-runner.cpp\", \"src/test-runner.cpp\")?\n. I think you also need the R template file: https://github.com/hadley/testthat/blob/master/R/test-compiled-code.R#L183-L187 (this is used so that the Catch unit tests are run during devtools::test())\n. FWIW the 'overwrite?' dialog for use_template is kind of awkward here (you either need to accept that your original Makevars is overwritten, or you get an error when you cancel / reject the dialog)\n. I think that makes sense -- export use_catch() on the devtools side, use that function within the use_testthat() call when catch = TRUE, and (after this is merged) we could deprecate use_catch() within testthat. Does that make sense, @hadley?\n. I think this behavior would be a bit friendlier:\n1. Only apply the template if src/Makevars doesn't exist already, or\n2. Amend the Makevars file to add PKG_CPPFLAGS = ../inst/include if it already exists.\nI would prefer having behavior 1) in this PR so that we don't overwrite a users potentially hand-crafted / fully populated Makevars file; 2) is more of a 'nice-to-have'.\n. Ah, and now that I'm looking at it -- should we also generate src/Makevars.win?\n. I don't think we need use_rcpp() for Catch (it doesn't depend on Rcpp); I think use_catch() should be able to handle this without also adding Rcpp infrastructure. Does that make sense?\n. ",
    "luckyrandom": "I think the course for all the trouble is that one repository on github is used for both source managing and package distributing. The Rd files should never be tracked by git in the source repository; on the other hand, the Rd files must be tracked and shared through github in the package repository.\nConceptually, we have something like,\nprebuild, such as generate Rd\n  Src ====================================> Package\nI want to call the action from src to package as build, but build means something different in R, so let's call it prebuild here.\nOne solution is to get two repository, one for source files, such as RPackageFoo-dev, and one for package distributing, such as RPackageFoo. Then, with some script, such as a git hook, we can update the package distributing repository automatically. Under such setting, everyone can install package from the package repository without any problem, and the developers, who use the source repository, need to handle the prebuilding process by themselves. The cost here is that we have to handle two repository, and some users and develops may not notice the pkg has two repositories.\nAnother solution is embedding prebuilding into devtools, and let the users handle prebuilding by themselves. Hopefully, it's painless for both developers and users, with the help of devtools. To make it really works as expected, the prebuilding procedure should easy enough to be handled by any machine, including Windows. If devtools have to handle the building dependence and the users may have to install a bunch of packages or even different versions of one packate, then it is too complex to push the job to the users, and the developers should do the heavy lifting, if possible.\nOr, we can keep using one repository for both src managing and pkg distributing, and build some script and configure to deal with \"compiled\" files in git easily. I find the article Dealing With Compiled Files in Git useful. The basic setups are,\n- set .gitattributes so git diff would skip all the compiled files\n- set git merge driver so git merge always use local version of compiled files\n- set git hook so the Rd files are updated before pushing to github\nThe potential pitfall is that git merge driver and git hook can not be synced by git and must be set manually by every developers. The good news is, I guess, improper setting by other developer will not mess your repository. Another trouble is that, you may not be able to handle pull request on github, as it doesn't support merge drive. Actually, the only way to make sure Rd files are updated properly, is to precompile locally and push to github. I don't think I'm foresee all possible issues, as it is somehow too complex for me.\n. I was playing with the idea of automating build and deploy tool for travis-ci. The project repository is available at r-deploy-git. It's at early stage, and seems to work well my dummy r package. At least, it shows it's doable. Hopefully,  a reliable script will be available in the near future, with everyone's help.\nFor devtools, I think it would be a good idea to have a way to distinguish a \"souce\" package and \"prebuild\" package. For a \"source\" package, prebuild must be called to generate files,  such as Rd files, and the developers of pkg can use any tools as they want, including make, as we assume anyone installing \"src\" package as developers or power users. For a \"prebuilt\" package, it must follow the CRAN standard, and can be installed with R CMD INSTALL.\n. When review my own code, this implementation feels like a back door, as it change the behavior of compile_dll by adding comment to makevars. To make it more user friendly, we may add a function use_detect_ dependencies that generates the Makevars file.\nAn alternative implementation is adding arg auto_clean to compile_dll and load_all. Which way do you prefer?\n. I modify function headers to get this function. I thought the returned value should be consistent with headers.\n. We should clean and compile all the source files, when Makevars file is modified.\n. ",
    "hetong007": "I changed the structure of my codes since then. This earlier version is related to the problem.\nIt is reproducable on My Windows XP and Ubuntu 12.04.\n. tmcn is on R-Forge and can be installed by \ninstall.packages(\"tmcn\", repos = \"http://R-Forge.R-project.org\")\nHowever, the problem disappeared totally. Sorry. I'll be more careful when opening an issue next time.\n. ",
    "mllg": "On a second thought, threads should default to getOption(\"Ncpus\", 1) in all functions.\n. > Scalability: Works interactively, multicore, in a local network of machines via SSH, or on a HPC cluster; devtools doesn't need to care about configuration\n\nEase of use: BatchJobs::batchMap() is a drop-in replacement of parallel::mclapply()\n\nIf you guys care about these two points, I would like to point you to https://github.com/berndbischl/parallelMap. Instead of calling mclapply, you call parallelMap. The user can configure the backend (sequential, multicore, socket, mpi, SSH, HPC) from outside the package, e.g. in his Rprofile. You can also allow users to specifically which parts to parallelize by labeling the calls to parallelMap.\n. > @mllg is there someway for children to send information back to the parents for display? That's a deal breaker for me.\nI'm not sure I completely understand what you are asking for. Do you mean the output which is send to stdout() on the nodes or the the results?\n. ",
    "dougmitarotonda": "Thanks for clarifying this Winston and sorry for missing that in the roxygen2 update. I now remembering reading that in the NEWS, but didn't really think about the impact it had until I ran into a problem! \n. Yes, I am using roxygen2 v3.0.0\n\nsessionInfo()\nR version 3.0.2 (2013-09-25)\nPlatform: x86_64-apple-darwin10.8.0 (64-bit)\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  datasets  grDevices utils     methods   base     \nother attached packages:\n [1] plyr_1.8                                           ...\nextrafont_0.15\n[25] roxygen2_3.0.0                                       testthat_0.7.1\n[27] devtools_1.4.1                                      \nloaded via a namespace (and not attached):\n [1] biglm_0.9-1        boot_1.3-9         brew_1.0-6         cluster_1.14.4     codetools_0.2-8\n [6] colorspace_1.2-4   corrplot_0.73      data.table_1.8.10  dichromat_2.0-0    digest_0.6.4\n[11] evaluate_0.5.1     extrafontdb_1.0    formatR_0.10       Formula_1.1-1      ggplot2_0.9.3.1\n[16] gmp_0.5-11         grid_3.0.2         gtable_0.1.2       Hmisc_3.13-0       httr_0.2\n[21] knitr_1.5          labeling_0.2       lattice_0.20-24    lubridate_1.3.3    MASS_7.3-29\n[26] memoise_0.1        munsell_0.4.2      parallel_3.0.2     proto_0.3-10       R.cache_0.9.0\n[31] R.methodsS3_1.5.2  R.oo_1.15.8        R.utils_1.28.4     RColorBrewer_1.0-5 RCurl_1.95-4.1\n[36] reshape2_1.2.2     rjson_0.2.13       Rttf2pt1_1.2       scales_0.2.3       splines_3.0.2\n[41] stringr_0.6.2      survival_2.37-4    tools_3.0.2        whisker_0.3-2      xtable_1.7-1 \n. Nothing obvious, but seems like I must have something lingering where I don't expect it. I will keep searching; sorry to be a bother.\n. I am reopening this issue because I have been able to create a MWE that produces an error associated with @importFrom (though I am not entirely sure related to my original post). \nI constructed a skeleton package with barebones files and only edited the help.R file, which is very simple:\n```\n' @docType package\n'\n' @importFrom plyr ddply\nNULL\n```\nWhen I call document(package_directory, clean = TRUE) (where package_directory is a variable holding the path to the package), everything works fine. Now, I change help.R to:\n```\n' @docType package\n'\n' @importFrom plyr\nNULL\n```\nand call document(package_directory, clean = TRUE), which causes an error, as expected:\nError in asChar(ivars) : \n  empty name in directive 'importFrom' in 'NAMESPACE' file\nNow, lets go back and fix the help.R so it is back to the original:\n```\n' @docType package\n'\n' @importFrom plyr ddply\nNULL\n```\nWhen I call document(package_directory, clean = TRUE), I surprisingly still get the error I got when broke help.R. I would have thought it would have worked fine here because document ignores the NAMESPACE file.\nAn additional twist is that if instead of using document after breaking things, I use roxygenize, it works fine. \nAccording to the roxygen documentation, \"If you have a simple package, you can use roxygenise(), but for anything more complicated, I recommend that you use document().\" So, why does document not work here but roxygenize does? And when should each be used?\nAs for versions, I am up to date:\n```\n\nsessionInfo()\nR version 3.0.3 (2014-03-06)\nPlatform: x86_64-apple-darwin10.8.0 (64-bit)\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  datasets  grDevices utils     methods   base     \nother attached packages:\n[1] plyr_1.8.1     extrafont_0.16 roxygen2_3.1.0 testthat_0.8.1 devtools_1.4.1\n```\n. ",
    "bbuchsbaum": "thanks for the quick response, here's some more info.\ndocument()\nUpdating neuroim documentation\nLoading neuroim\nError in match.fun(FUN) : object 'parse.file' not found\ntraceback()\n4: match.fun(FUN)\n3: lapply(r_files, parse.file, env = env, env_hash = env_hash)\n2: unlist(lapply(r_files, parse.file, env = env, env_hash = env_hash),\n       recursive = FALSE)\n1: document()\nhere's my sessionInfo()\nR version 3.0.2 (2013-09-25)\nPlatform: x86_64-apple-darwin10.8.0 (64-bit)\nlocale:\n[1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8\nattached base packages:\n[1] grid      stats     graphics  grDevices utils     datasets  methods\nbase\nother attached packages:\n [1] roxygen2_3.0.0  neuroim_0.0.2   iterators_1.0.6 hash_2.2.6\n Matrix_1.0-14   lattice_0.20-23 abind_1.4-0     yaImpute_1.0-19\n [9] stringr_0.6.2   devtools_1.3\nloaded via a namespace (and not attached):\n [1] brew_1.0-6      codetools_0.2-8 digest_0.6.3    evaluate_0.4.7\n httr_0.2        memoise_0.1     parallel_3.0.2  RCurl_1.95-4.1\n [9] tools_3.0.2     whisker_0.3-2\nOn Thu, Dec 19, 2013 at 10:17 AM, Winston Chang notifications@github.comwrote:\n\nThere is a call to parse.file in document.r, but it shouldn't reach that\ncode if you have version >= 3 of roxygen2. Can you include the output of\nsessionInfo()?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/404#issuecomment-30936235\n.\n\n\nBradley R. Buchsbaum\nRotman Research Institute\n3560 Bathurst St.\nToronto, ON Canada M6A 2E1\nemail: bbuchsbaum@rotman-baycrest.on.ca\n. OK, looks like updating devtools to 1.4.1 fixed the issue. Sorry for that.\nOn Thu, Dec 19, 2013 at 10:32 AM, Bradley Buchsbaum \nbrad.buchsbaum@gmail.com wrote:\n\nthanks for the quick response, here's some more info.\ndocument()\nUpdating neuroim documentation\nLoading neuroim\nError in match.fun(FUN) : object 'parse.file' not found\ntraceback()\n4: match.fun(FUN)\n3: lapply(r_files, parse.file, env = env, env_hash = env_hash)\n2: unlist(lapply(r_files, parse.file, env = env, env_hash = env_hash),\n       recursive = FALSE)\n1: document()\nhere's my sessionInfo()\nR version 3.0.2 (2013-09-25)\nPlatform: x86_64-apple-darwin10.8.0 (64-bit)\nlocale:\n[1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8\nattached base packages:\n[1] grid      stats     graphics  grDevices utils     datasets  methods\nbase\nother attached packages:\n [1] roxygen2_3.0.0  neuroim_0.0.2   iterators_1.0.6 hash_2.2.6\n Matrix_1.0-14   lattice_0.20-23 abind_1.4-0     yaImpute_1.0-19\n [9] stringr_0.6.2   devtools_1.3\nloaded via a namespace (and not attached):\n [1] brew_1.0-6      codetools_0.2-8 digest_0.6.3    evaluate_0.4.7\n httr_0.2        memoise_0.1     parallel_3.0.2  RCurl_1.95-4.1\n [9] tools_3.0.2     whisker_0.3-2\nOn Thu, Dec 19, 2013 at 10:17 AM, Winston Chang notifications@github.comwrote:\n\nThere is a call to parse.file in document.r, but it shouldn't reach that\ncode if you have version >= 3 of roxygen2. Can you include the output of\nsessionInfo()?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/hadley/devtools/issues/404#issuecomment-30936235\n.\n\n\nBradley R. Buchsbaum\nRotman Research Institute\n3560 Bathurst St.\nToronto, ON Canada M6A 2E1\nemail: bbuchsbaum@rotman-baycrest.on.ca\n\n\nBradley R. Buchsbaum\nRotman Research Institute\n3560 Bathurst St.\nToronto, ON Canada M6A 2E1\nemail: bbuchsbaum@rotman-baycrest.on.ca\n. ",
    "tpoisot": "Silly me...\n```\n\ngetOption(\"unzip\")\n[1] \"\"\n```\n\nSo running options(unzip = \"unzip\") makes it work. Wouldn't it make sense that it returns a warning if unzip is not set?\n. I'm using Arch Linux, and I haven't compiled R myself. I guess it can be solved by\nif(getOption(\"unzip\") == \"\") options(unzip = 'internal')\nsomewhere in the package...\n. ",
    "amtf1019": "delete the namespace file and do load_all() and then do devtools::docuement(). It should do the work.. ",
    "ghost": "just updated manually last devtools from github: still not resolved\n. by the way, why it getting zip instead tar?\n\ndevtools::install_github(\"devtools\")\nInstalling github repo devtools/master from hadley\nDownloading devtools.zip from https://github.com/hadley/devtools/archive/master.zip\nInstalling package from /tmp/RtmpTvfJtu/devtools.zip\n\u041e\u0448\u0438\u0431\u043a\u0430 \u0432 unzip(src, exdir = target, unzip = getOption(\"unzip\")) : \n  'unzip' must be a single character string\n. R version 3.0.2 (2013-09-25)\nPlatform: x86_64-suse-linux-gnu (64-bit)\n\nlocale:\n [1] LC_CTYPE=ru_RU.UTF-8       LC_NUMERIC=C               LC_TIME=ru_RU.UTF-8        LC_COLLATE=ru_RU.UTF-8\n [5] LC_MONETARY=ru_RU.UTF-8    LC_MESSAGES=ru_RU.UTF-8    LC_PAPER=ru_RU.UTF-8       LC_NAME=C\n [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=ru_RU.UTF-8 LC_IDENTIFICATION=C       \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.4.1.99\nloaded via a namespace (and not attached):\n[1] digest_0.6.3   evaluate_0.5.1 httr_0.2       memoise_0.1    parallel_3.0.2 RCurl_1.95-4.1 stringr_0.6.2  tools_3.0.2\n[9] whisker_0.3-2 \n. sorry, silly mistake of mine...\n. I think you'd still want --no-save --no-restore too, or else you could really mess up the user's workspace.\nWhat's the reason for wanting to ignore the user files though?\n. People also use config files to set basic facts about their environment though, e.g. if they don't have administrative rights on the box, they may need to point R to their library locations.\nIf ~/.Rprofile isn't read, then it seems prudent to give the non-admin user some way to set options for R startup - the only other thing I can think of would be to set the R_PROFILE environment variable to some userspace file and use that to set things up.  Similarly with R_ENVIRON.  That seems like a misuse of those mechanisms though, and encouraging people to change their ~/.Rprofile to something less invasive might be a good idea.\nThe Startup help page in R has this to say about the matter:\n\nIf you want \u2018~/.Renviron\u2019 or \u2018~/.Rprofile\u2019 to be ignored by child R processes (such as those run by R CMD check and R CMD build), set the appropriate environment variable R_ENVIRON_USER or R_PROFILE_USER to (if possible, which it is not on Windows) \"\" or to the name of a non-existent file.\n\nThis seems to imply that people should expect those files to be read during building & testing unless explicitly turned off.\n. Well, it's just not an obvious step to take (at least it wasn't to me!) since test() doesn't document that it calls load_all(), so I didn't even understand until I started poking around in the debugger (and truthfully, not even then, until you mentioned it) that manually calling load_all() would be helpful.\nWhy the reluctance to pass the errors through to the user, at least when explicitly requested, though?  In general, if some piece of software spits out an error saying \"some mysterious error happened, go try to figure it out, but you're on your own\" that's a pretty good sign that it could probably find something more helpful to say.  It seems like an easy way to throw the user a helpful bone.  But perhaps a mention in the help page for test() would be just as good if you prefer that.\n. @grishagin Hello, have you solved this problem? Now I meet the same error, and have not find the solution yet. Would you like to help me if you have solved it? \nThank you.\n. ",
    "hilaryparker": "I believe the URL structure is the same. The only difference is the url is github.company.com, where company is whatever the enterprise account's name is. It's possible the account might need to somehow pass credentials, as the enterprise account is only viewable by others in the company.\n. Nice!!\nI agree that github_url is probably more intuitive than repo_path.\nI'm pretty agnostic to it being a separate function vs. an option in install_github(). For my use case it's mostly me just installing my own functions, so I'm not often calling the function to begin with.\n. YAY!! It comes full circle.. now he's helping me! :D\n. ",
    "pssguy": "Thanks for the quick response\na) Had a brief look at script but its pretty much beyond me\nGuess I need to somehow combine lines 160 & 263\nb) I'll follow up with RCurl first. If I can get that loading then maybe devtools and github packages wil follow\n. Thanks to your suggestion for searching the RCurl FAQ, I now have devtools installed. \nUsing the travis link, I tried\nRscript -e 'library(devtools); library(methods);  install_github(commandArgs(TRUE))' \"ramnathv/rCharts\"\nYAY  rCharts.zip is downloaded\nNAY 'lib=\"/usr/local/lib/R/site-library\"' is not writable  etc. Execution halted\nUnclear of problem . All other packages , inc devtools ggplot2 etc got written to that directory\n. An update on my travails.\nI found this suggestion at\nhttp://r-forge.r-project.org/forum/forum.php?set=custom&forum_id=84&style=nested&max_rows=50&submit=Change+View\nYou try to install the package to a directory which only root has write access to. Here is what you can do:\n- Create a Rlib folder in your home directory\n- Add the following line to your .bashrc file (in your home directory):\n  export R_LIBS=/home/your_user_name/Rlib\n- start a new shell and try again\nNot sure this applies as I have had no problem writing CRAN packages there but tried it anyways\nIt is a bit confusing about which is home directory is it home or home/ubuntu (where ubuntu is my user name) but I set up a folder in the home/ubuntu directory and amended the ,.bashrc file in the home/ubuntu directory and restarted shell\nNow get :command not found\n-bash :/home/ubuntu/..bashrc; error line 6: syntax error near unexpected token '$' in\\r  ???\nWhatever, the same error occurs when I try to load a github package and CRAN ones still get written to the /usr/local/lib/R/site-library\nAlso when I remove the additional line from .bashrc I still get the error message on launching shell\nSo basically, no steps forward one step back\n. I set up a new server instance on AWS to obviate the .bashrc problem\nThen this seems to do the trick\nsudo apt-get install git\ngit clone https://github.com/ramnathv/rCharts.git\nsudo R CMD INSTALL rCharts\n. Seems to apply to both Rtools34 and 33\n```\nSession info -----------------------------------------------------------------------------------------------------------   ----------------\n setting  value                     \n version  R version 3.3.0 (2016-05-03)\n system   x86_64, mingw32           \n ui       RStudio (0.99.1212)       \n language (EN)                      \n  collate  English_Canada.1252       \n tz       America/Los_Angeles       \n date     2016-06-11                  \nPackages -------------------------------------------------------------------------------------------------------------------------------\n package  * version date       source      \n devtools * 1.11.1  2016-04-21 CRAN (R 3.3.0)\n digest     0.6.9   2016-01-08 CRAN (R 3.3.0)\n memoise    1.0.0   2016-01-29 CRAN (R 3.3.0)\n  withr      1.0.1   2016-02-04 CRAN (R 3.3.0)\n```\n. ",
    "berndbischl": "Thx a lot for the quick reply.\nI can live for now with the BioC stuff not being checked, if the CRAN package is.\nYou can close if you want.\n. > Explicitly loading into the calling environment fixes the issue.\nCool that you are even fixing our package for us :) Thx a lot!\n\n@hadley maybe we should add a data() shim which makes this the default?\n\nI would seriously suggest that. What happened on our side was that I wanted to show a student assistant how the mlr unit tests work. Apparently at that point in time we got the new devtools version on her laptop. After calling load_all on the package, and seeing the error,  we had 3 technically competent people sitting around the laptop for 30 min thinking \"wtf is happening\". \nThe error is extremely \"unintuitive\" and very hard to debug. I basically had to guess what happened, and downgrade devtools to figure this out.\n. one other question from my side, that i just noticed.\nin the past, i also created a file called helper_zzz.R\nthis eg set a seed for my unit tests. and this seed should ONLY be set for the unit tests.\nnow it is always used (when i call load_all on the package)\nso i guess my question is: \nhow can i do \"state changes\" in my helper files, which are only executed when i am in \"testthat unit testing mode\" ?\n. > @berndbischl maybe condition on interactive()?\nwe also run our unit tests in non-interactive mode via shell scripts / from the console. actually we do that most often.\n. ",
    "kendonB": "If anyone cares, I also have this problem.\n. ",
    "WilliamKinaan": "This problem is making me crazy, yet no solution\n. ",
    "danielecook": "I get this error message constantly - any idea why this is happening so I can try to avoid it?\n. ",
    "homerhanumat": "No, and it's not familiar, but I'll see if I can grep it somehow.\nAnd sorry, the second error message got cut off:\nIt was:\nInstalling github repo(s) homerhanumat/tigerstats/master from hadley\nDownloading homerhanumat/tigerstats.zip from https://github.com/hadley/homerhanumat/tigerstats/archive/master.zip\nError: client error: (404) Not Found\n. Foud it:\n4.2.25 homer 05:17:05 -> grep -r \"April 2003\" .\n./man/ostrichtemp.Rd:  1171\u20131181.  April 2003.\n./R/ostrichtemp.R:#'  ostriches in their natural habitat\",  The Journal of Experimental Bi\nIt's a page-number reference in some data documentation:  seems harmless.\n. Of course that search was on my local repository, not the remote on Github.  But the two are synced at the moment.\n. Thanks.  I will add utf-8 to my growing \"be aware of\" list!\n. Pre-processding would be great.  I still haven't been able to track down and remove that embedded null character.\n. I know, but my changes from my Linux machine (e.g., delete most of the line and retype with no  dash at all)  so far have had no effect.  I'll try something more drastic, and/or switch to editing in Windows, and report back later.\n. I went to my Windows system and re-composed ostrichtemp.R entirely by hand (no pasting in of any text, no dash between 1171 and 1181).  I saved that version to Dropbox, rebooted to Linux (where my repository resides), copied from Dropbox to my repository, committed and pushed the changes to the Github repository, rebooted to Windows and tried install_github() again, getting exactly the same error message as before.\nMaybe Dropbox has something odd going on.\nHomer\n. Aaargh, all afternoon I have been forgetting to re R-oxygenate prior to pushing.  Never mind, sorry.\n. ",
    "klmr": "Just to verify \u2026 is this a bug in R\u2019s Windows implementation? Is it a bug in Rtools? Where would one report this?\n. Hmm. Good point. To be fair I\u2019m just used to assuming UTF-8 anywhere in the absence of any overriding encoding specification, but obviously I\u2019m spoilt by Unix-like systems here. Then again, R doesn\u2019t seem to have  a way of specifying source file encoding inside the file itself so this seems like an unsolvable problem. That, then, sounds like a bug (some pay prefer to call it  a sorely missing feature\u00a0\u2026).\n. > There are plenty of auto generated files already in your version control\nActually there aren\u2019t. Rd files for instance of course aren\u2019t there either. The only auto-generated files are those which are generated once and then updated by hand (DESCRIPTION). Auto-generated files don\u2019t really belong under VCS. Of course different people have different opinions about that, but devtools at the moment forces one opinion, which many VCS users believe to be the wrong one.\n. :+1:\nMaybe install_* could simply provide a from_source=TRUE option or similar, instead of putting this into the (ostensibly tool agnostic) DESCRIPTION file, but really any option which makes this fundamentally possible would be good.\n. @wch Here you go:\n```\n\ntraceback()\n11: stop(e)\n10: value[3L]\n9: tryCatchOne(expr, names, parentenv, handlers[[1L]])\n8: tryCatchList(expr, classes, parentenv, handlers)\n7: tryCatch(loadNamespace(name), error = function(e) stop(e))\n6: getNamespace(ns)\n5: asNamespace(ns)\n4: getExportedValue(pkg, name)\n3: rstudioapi::hasFun\n2: dev_help(e1_str)\n1: ?(test)\n``\n. A reinstall viainstall_github('hadley/devtools')fixed the segfault \u2013 although now I am observing that every once in a whileload_all` just hangs indefinitely without producing any output (and Ctrl+C doesn\u2019t interrupt it).\n\nSo there still seems to be something odd going on.\n. Something else, I recently added the following to my ~/.Rprofile, so that I could use the development version of my packages without having to load devtools):\nr\n.libPaths('~/R-dev')\nOther than that, I have no R specific environment settings.\n. How do I find this out?\n. Sounds reasonable. Unfortunately, I don\u2019t see a way to verify this in retrospect. Let\u2019s see whether I or somebody else can repro the problem. However, just going by the code you\u2019re almost certainly right.\n. Fair enough, that\u2019s an acceptable solution if it\u2019s clearly documented.\nI\u2019m wondering if it\u2019s actually necessary to load the package so meticulously when generating the NAMESPACE file, rather than simply loading all imports \u2014 similar to what roxygen2:::source_package does (although it would probably be better not to use require, which attaches packages).\n\u2026 But I\u2019m probably overlooking some corner cases where that would yield wrong results, am I not?. @jimhester roxygen2:::load_pkg_dependencies (which is called internally) should take care of that, shouldn\u2019t it?. ",
    "cornejom": "I've just tried on a different network, one without a proxy, and the installation worked. Problem resolved.\nNot sure why this is a problem since navigating via http was not a problem ... just running install_github.\n. ",
    "woodhaha": "Thanks @hadley @dmenne \nI have tried many times intalling the pkg \"devtools\" from GitHub on my windows10(x+64),and finally successed.\nFllowing the steps\n1. Upgrade the java devlopment enviroment on my win10 ( http://www.oracle.com/technetwork/java/javase/downloads/index.html) install \"Java SE 8u131\"(Java Platform, Standard Edition)\nand then configuring the developing enviroment on java control panel, setting the java runtime for related Apps \n2. Install \"Rtools34\" in \uff08Path C:\\Rtools\uff09,then select components(R toolset,Cygwin DLLs, R3.3.x+64 bit toolchain,Extras to build 64bit R\uff09\n\n\nInstall \u201ccygwin setup-x86_64\u201d comfiguring the linux devlopment enviroment \n\n\nInstall \"basic-miktex-2.9.6236-x64\"\n\n\nRestart your windows system, then in RStudio configuring Rtools developing enviroment by using the function: \nnormalizePath(\"C:/Rtools/bin\")\nand lastly using \ndevtools::build_github_devtools() ## to install the Github devtools pkg\"devtools_1.12.0.9000.zip\"#. I have tried many times intalling the pkg \"devtools\" from GitHub on my windows10(x+64),and finally successed.\nFllowing the steps\n1.upgrade the java devlopment enviroment on my win10 ( http://www.oracle.com/technetwork/java/javase/downloads/index.html)\ninstall \"Java SE 8u131\"(Java Platform, Standard Edition)\nand then configuring the developing enviroment on java control panel,setting the java runtime for related Apps \n\n\n2.install \"Rtools34\" in \uff08Path C:\\Rtools\uff09,then select components(R toolset,Cygwin DLLs, R3.3.x+64 bit toolchain,Extras to build 64bit R\uff09\n3.install\u201ccygwin setup-x86_64\u201dcomfiguring the linux devlopment enviroment \n4.install \"basic-miktex-2.9.6236-x64\"\n5.restart your windows system, then in RStudio configuring Rtools \ndeveloping enviroment by using the function \nnormalizePath(\"C:/Rtools/bin\"),and lastly using devtools::build_github_devtools() to install the Github devtools pkg\"devtools_1.12.0.9000.zip\". ",
    "jdanielnd": "The folder that contains an accent in its name is the user folder. I'm not sure how can I change it; it is a default temporary directory. I tried changing the working directory, but it make any difference on that path.\n. It worked. It was necessary to change the TMP var before starting R; because R creates the session temp folder during initialization, so there would be no effect if I change the TMP variable after the session starts. It was also necessary to change the R_LIBS env var, because it was on a path with accents too.\n. This is the tempdir() result:\n```\n\ntempdir()\n[1] \"C:\\Users\\CLUDIO~1\\AppData\\Local\\Temp\\Rtmp6rP2pl\"\n```\n\nIt seems that the folder name that has accents is collapsed. The original name is: \"Cl\u00e1udio\".\nThanks!\n. ",
    "jacopone": "Hi all, apologies if this is not the right way to report this. \nI've installed Rcompression to solve this problem http://r.789695.n4.nabble.com/Decompressing-raw-vectors-in-memory-td4603202.html via install_github(\"omegahat/Rcompression\"). \nIt seems that the problem reported here also happens here https://github.com/omegahat/Rcompression/blob/master/DESCRIPTION, and I expected, maybe wrongly, this fix to solve it. \nOr should I remove blank lines from https://github.com/jacopone/Rcompression/blob/master/DESCRIPTION ? \nThanks. Yes that works well. The problem really happens when in a project using packrat:\n install_github(\"omegahat/Rcompression\")\n packrat::snapshot()\nThen when I restore() it breaks. The workaround I'm using so far is forking Rcompression, removing the spaces and using that version on my project. \nThanks!. ",
    "randyzwitch": "I see that you already got to this...yes, it works without the trailing slash. Thanks guys.\n. Nevermind\nhttps://github.com/hadley/devtools/pull/521/\n. ",
    "joethorley": "Found them. Thanks. Apologies for my slowness...\n. What do you mean by similar? If you mean question based, with the exception of three calls to \nmenu(c(\"Yes\", \"No\")) == 1, yesno is the only code to use the menu function?\nFWIW I created a package for my own use https://github.com/poissonconsulting/yesno. It could form the basis for development although there is very little to it.\n. Do you mind if I push it to CRAN? I can add you as an co-author.\n. Yes\nSent from my iPhone\nOn Nov 3, 2016, at 17:43, Hadley Wickham notifications@github.com wrote:\nCould you eliminate the dependency on datacheckr?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hadley/devtools/issues/1359#issuecomment-258315996,\nor mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAldJzmozqXqGdZfnqfD5LbLgLMNxQ3Oks5q6n-cgaJpZM4KL1qj\n.\n. I've removed the dependency on datacheckr and added substantially more documentation.\nI've also replaced the string argument with ... which is then paste0(..., collapse = \"\") (as you have it in the original devtools function).\nI think its CRAN ready. I would like to add you as a co-author. I'm happy to remain as maintainer if thats what you prefer but have no attachment either way. I'm also happy to move the package to your profile on GitHub. Let me know what you are thinking.\nI've invited you to repo in case you want to make any changes directly. \n. Can I push to CRAN with you as a co-author? Or would you prefer to have your name removed?. I have set you as the primary author and myself as the compiler and maintainer. \nI have also explicitly acknowledged the source of the code as devtools.\nI am planning on submitting to CRAN in early 2017 unless you indicate otherwise.\nThe package is at https://github.com/poissonconsulting/yesno.. @hadley I would like to submit yesno (https://github.com/poissonconsulting/yesno) to CRAN with you as primary author and myself as compiler and maintainer. I'm also happy to entirely remove my name and have you take it over. I would just like to be able to use in my current and future CRAN packages. Thanks . Since other packages I want to push to CRAN require this functionality I am going to push yesno to CRAN on Feb 15th with @hadley as the primary author (as requested on Nov 28). If I get other direction I will follow it.. Thanks I appreciate it. FWIW yesno is now on CRAN\nhttps://cran.r-project.org/web/packages/yesno/index.html\nthanks for your flexibility :). ",
    "adrtod": "I fixed a few things to make it work on my package on linux and windows\n. The Travis CI build currently fails because of a warning in the documentation check.\nIt simply needs a fresh roxygenize to be fixed.\n. Done !\n. My changes intend to avoid failure of load_all() when .onLoad is\n.onLoad <- function(lib, pkg)\n{\n library.dynam(\"mypkg\", pkg, lib)\n}\nsee details in the line notes above\n. Ok thanks, I am just adapting from the rjags package :\nhttp://sourceforge.net/p/mcmc-jags/rjags/ci/default/tree/R/unix/zzz.R.in\nThis must be an old practice.\n. Thanks for the answer.\nLines 21 of install-min.r and 37 of compile-dll.r are still wrong.\nI will suggest another patch.\n. Sure. I'll have a look at it.\n. This is replaced by patch-4\n. Actually the proposition does not change anything in the behaviour, just remove useless code.\nCould you be more specific on what you need?\n. I am not familiar with testhat but I think the test-dll.r script checks it works ok. Maybe @wch can confirm?\n. fix error: name field does not exist. must be package\n. there is an error here: \"inst\" should not have quotes.\nit must rather be the inst variable content\n. this call to file.copy silently fails and its boolean output is not checked\n. but I prefer not copy the compiled library and return the temporary installation path.\n. store the output of compile_dll, i.e. the temporary installation path\n. With this code, problem occurs when .onLoad package function is e.g.:\n.onLoad <- function(lib, pkg)\n{\n library.dynam(\"mypkg\", pkg, lib)\n}\nI guess library.dynam looks for \"mypkg.dll\" in \"<lib>/<pkg>/libs\" directory where lib is dirname(pkg$path) and fails because a previous call to compile_dll has copied \"mypkg.dll\" in \"<lib>/<pkg>/src\" (assuming file.copy did not fail)\n. I thus give the temporary installation path as argument to .onLoad or .onAttach instead of the source package path.\n. if inst is not null, which means compilation was needed, I call run_pkg_hook with additional argument: lib=dirname(inst)\n. add optional argument lib to run_pkg_hook function with default value dirname(pkg$path) (unchanged from previous behavior)\n. ",
    "dakep": "Starting with an empty project (i.e., no .Rd files exist), the devtools::document function in the current version from github (1.5.0.99) still gives me an error and no .Rd files are generated (but the error message is more meaningful \u2013 thank you!)\nError: Failure in roxygen block beginning foo.R:8\nCould not find topic foo in: foo\nBut the help function is not giving me an error anymore.\nroxygen2::roxygenize works like a charm and once invoked (i.e., the foo.Rd file were generated), devtools::document also works.\n. ",
    "mcieslik-mctp": "I have exactly the same problem\n```\n!> sessionInfo()                                                                                                                                                                                                               \n R version 3.1.0 (2014-04-10)                                                                                                                                                                                                  \n Platform: x86_64-pc-linux-gnu (64-bit)                                                                                                                                                                                          \nlocale:                                                                                                                                                                                                                       \n  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C                                                                                                                                                                                  \n  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8                                                                                                                                                                        \n  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8                                                                                                                                                                       \n  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                                                                                                                                                                                     \n  [9] LC_ADDRESS=C               LC_TELEPHONE=C                                                                                                                                                                                \n [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C                                                                                                                                                                             \nattached base packages:                                                                                                                                                                                                       \n [1] stats     graphics  grDevices utils     datasets  methods   base                                                                                                                                                            \nother attached packages:                                                                                                                                                                                                      \n [1] devtools_1.5                                                                                                                                                                                                                \nloaded via a namespace (and not attached):                                                                                                                                                                                    \n  [1] compiler_3.1.0 digest_0.6.4   evaluate_0.5.5 httr_0.3       memoise_0.2.1                                                                                                                                                \n  [6] parallel_3.1.0 RCurl_1.95-4.1 stringr_0.6.2  tools_3.1.0    whisker_0.3-2\n```\n. ",
    "lbraglia": "Obviously I'm available for further tests, if needed. \n. reproduced with github's devtools version 1.5.0.99 :(\n. A quick'n dirty bash script in the meantime\n```\n!/bin/bash\nusage (eg):\nr_install_github devtools hadley\ncd /tmp && \\\nmkdir R_install_github  && \\\ncd R_install_github && \\\nwget https://github.com/$2/$1/archive/master.zip && \\\nunzip master.zip\nR CMD build $1-master && \\\nR CMD INSTALL $1*.tar.gz && \\\ncd /tmp && \\\nrm -rf R_install_github\n```\nHTH\n. @duncantl we summon you!\n. I updated libcurl to the latest version (available in debian testing) . Now with\nii  libcurl3:amd64                                              7.37.0-1                           amd64        easy-to-use client-side URL transfer library (OpenSSL flavour)\nii  libcurl3-gnutls:amd64                                       7.37.0-1                           amd64        easy-to-use client-side URL transfer library (GnuTLS flavour)\nii  libcurl4-openssl-dev:amd64                                  7.37.0-1                           amd64        development files and documentation for libcurl (OpenSSL flavour)\nand devtools 1.5 it works fine!\n. @iugrina are you still having problems?\n. ",
    "tobiasweise": "I have the same problem.\n```\n\nsessionInfo()\nR version 3.1.0 (2014-04-10)\nPlatform: x86_64-pc-linux-gnu (64-bit)\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=de_DE.UTF-8        LC_COLLATE=en_US.UTF-8     LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=en_US.UTF-8 \n [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.5\nloaded via a namespace (and not attached):\n[1] digest_0.6.4   evaluate_0.5.5 httr_0.3       memoise_0.2.1  parallel_3.1.0 RCurl_1.95-4.1 stringr_0.6.2  tools_3.1.0    whisker_0.3-2 \n```\nThanks @lbraglia for the script !\n. ",
    "kirstin-rhys": "This looks like a problem with RCurl on linux--I get the same error with MTurkR AccountBalance()\n. Thanks!\nWith verbose on, I get:\nR> AccountBalance()\n- Hostname was NOT found in DNS cache\n-   Trying 72.21.194.50...\n- Connected to mechanicalturk.amazonaws.com (72.21.194.50) port 443 (#7)\n- WARNING: failed to load NSS PEM library libnsspem.so. Using OpenSSL PEM certificates will not work.\n- Closing connection 7\n  Error in function (type, msg, asError = TRUE)  : \nIt appears (if indeed the missing libnsspem library is the culprit) that it is going to be some time before upstream NSS includes the pem module (apparently it needs a bit of clean up w/r/t memory, tests, etc). It's present on Fedora/RedHat, but not in any other distributions that I'm aware of.\nA quick fix in the meantime should theoretically be setting ssl.verifypeer = FALSE for RCurlOptions; however that doesn't seem to make any difference.\nI'll try tracing the RCurl requests.\n. Another option might be some means of selecting gnutls rather than nss?\n. Nevermind. It looks like guntls doesn't like pem cert bundles.\n. ",
    "duncantl": "Well, unfortunately, it works for me and I cannot reproduce the problem\nI'm using a version of from svn compiled at some point, but I'd be surprised if\nthat was in anyway related. See the sessionInfo() below.\nIt could well be to do with the network connection.\nSo I'd suggest either tracing/debugging the RCurl requests\nand also enabling verbose requests, e.g. setting\n options(RCurlOptions = list(verbose = TRUE))\nand hoping the layers respect and use that.\n```\nsessionInfo()\nR Under development (unstable) (2014-05-17 r65643)\nPlatform: x86_64-unknown-linux-gnu (64-bit)\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C\n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8\n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8\n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C\n [9] LC_ADDRESS=C               LC_TELEPHONE=C\n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base\nother attached packages:\n[1] devtools_1.5.0.99\nloaded via a namespace (and not attached):\n[1] digest_0.6.4   evaluate_0.5.5 httr_0.3       memoise_0.2.1  parallel_3.2.0\n[6] RCurl_1.95-4.1 stringr_0.6.2  tools_3.2.0    whisker_0.3-2\n```\n. ",
    "iugrina": "Unfortunately, I am still having problems on debian testing using\nii  libcurl3:amd64            7.37.0-1  \nii  libcurl3-gnutls:amd64     7.37.0-1\nii  libcurl3-nss:amd64        7.37.0-1\nii  libcurl4-gnutls-dev:amd64 7.37.0-1\nUsing  options(RCurlOptions = list(verbose = TRUE)) doesn't print anything new.\n```\nR version 3.1.0 (2014-04-10)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8     \n [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8 \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C            \n[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] vimcom.plus_0.9-92 setwidth_1.0-3     colorout_1.0-2    \nloaded via a namespace (and not attached):\n [1] devtools_1.5   digest_0.6.4   evaluate_0.5.5 httr_0.3       memoise_0.2.1  parallel_3.1.0\n [7] RCurl_1.95-4.1 stringr_0.6.2  tools_3.1.0    whisker_0.3-2 \n```\n. @lbraglia I've solved it by using CRAN version of RCurl (install.packages(...)) and not using r-cran-rcurl.\n. ",
    "charles-plessy": "Hello, just for the record, this was a bug in the Debian package r-cran-rcurl that we corrected in all Debian distribution unstable, testing, and more recently stable (Jessie 8.2). Sorry for the problem, and thanks for using Debian ! The correction eventually made it in Ubuntu wily as well.\n. Hello, just for the record, this was a bug in the Debian package r-cran-rcurl that we corrected in all Debian distribution unstable, testing, and more recently stable (Jessie 8.2). Sorry for the problem, and thanks for using Debian ! The correction eventually made it in Ubuntu wily as well.\n. ",
    "hack-r": "I encounter this issue daily with R  v3.1.1 and the current build of devtools so I don't think it's fixed unless the fix is still in some newer version waiting to be published\n. Sorry for the delay, I thought I had already replied. I did try re-installing RCurl with no success, but at some point the problem went away. I think perhaps I changed the version of R that I was using. It works fine now.\n. This problem has cropped back up. I run R on about 5 or 6 different machines and I believe what happened before was just that I started using a different machine and forgot which one had this issue. I have installed and uninstalled RCurl several times.\n. [Package devtools version 1.5 Index]\n. Oh, ok, sorry. I thought I just installed from GitHub. Must be some sort of confusion on my part; I have a lot of computers running R. Thanks. I'll do it now and report back.\n. > download.file(url = \"https://github.com/hadley/devtools/archive/master.zip\", destfile = \"devtools.zip\")\n\ninstall.packages(\"devtools.zip\", repos = NULL, type = \"source\")\nWarning in read.dcf(file.path(pkgname, \"DESCRIPTION\"), c(\"Package\", \"Type\")) :\n  cannot open compressed file 'devtools/DESCRIPTION', probable reason 'No such file or directory'\nError in read.dcf(file.path(pkgname, \"DESCRIPTION\"), c(\"Package\", \"Type\")) : \n  cannot open the connection\nWarning in install.packages :\n  running command '\"C:/PROGRA~1/R/R-31~1.1/bin/i386/R\" CMD INSTALL -l \"C:\\Program Files\\R\\R-3.1.1\\library\" \"devtools.zip\"' had status 1\nWarning in install.packages :\n  installation of package \u2018devtools.zip\u2019 had non-zero exit status\ninstall.packages(\"devtools\")\ntrying URL 'http://cran.rstudio.com/bin/windows/contrib/3.1/devtools_1.5.zip'\nContent type 'application/zip' length 255595 bytes (249 Kb)\nopened URL\ndownloaded 249 Kb\n\npackage \u2018devtools\u2019 successfully unpacked and MD5 sums checked\nThe downloaded binary packages are in\n    C:\\Users\\jmiller\\AppData\\Local\\Temp\\2\\Rtmpuc93wo\\downloaded_packages\n\nrequire(devtools)\nLoading required package: devtools\n\nAttaching package: \u2018devtools\u2019\nThe following objects are masked from \u2018package:utils\u2019:\n?, help\nThe following object is masked from \u2018package:base\u2019:\nsystem.file\n\n??corpus\nError in strsplit(topic, \"::\")[[1]] : subscript out of bounds\n. I didn't, thanks. Just tried it now and no luck tho:\ndevtools::build_github_devtools()\nDownloading devtools from https://github.com/hadley/devtools/archive/master.zip\n\"C:/PROGRA~1/R/R-31~1.1/bin/i386/R\" --vanilla CMD INSTALL  \\\n  \"C:\\Users\\jmiller\\AppData\\Local\\Temp\\2\\Rtmpuc93wo\\devtools-master\" --build \n- installing to library 'C:/Users/jmiller/AppData/Local/Temp/2/Rtmpuc93wo'\n  ERROR: dependency 'rstudioapi' is not available for package 'devtools'\n- removing 'C:/Users/jmiller/AppData/Local/Temp/2/Rtmpuc93wo/devtools'\n  Error: Command failed (1)\n. Thanks, I should've got that one on my own.\ninstall.packages('rstudioapi')\ntrying URL 'http://cran.rstudio.com/bin/windows/contrib/3.1/rstudioapi_0.1.zip'\nContent type 'application/zip' length 16112 bytes (15 Kb)\nopened URL\ndownloaded 15 Kb\n\npackage \u2018rstudioapi\u2019 successfully unpacked and MD5 sums checked\nThe downloaded binary packages are in\n    C:\\Users\\jmiller\\AppData\\Local\\Temp\\2\\Rtmpuc93wo\\downloaded_packages\n\ndevtools::build_github_devtools()\nDownloading devtools from https://github.com/hadley/devtools/archive/master.zip\n\"C:/PROGRA~1/R/R-31~1.1/bin/i386/R\" --vanilla CMD INSTALL  \\\n  \"C:\\Users\\jmiller\\AppData\\Local\\Temp\\2\\Rtmpuc93wo\\devtools-master\" --build \n- installing to library 'C:/Users/jmiller/AppData/Local/Temp/2/Rtmpuc93wo'\n- installing source package 'devtools' ...\n  ** libs\n\n*** arch - i386\ngcc -m32 -I\"C:/PROGRA~1/R/R-31~1.1/include\" -DNDEBUG     -I\"d:/RCompile/CRANpkg/extralibs64/local/include\"     -O3 -Wall  -std=gnu99 -mtune=core2 -c devtools.c -o devtools.o\ngcc -m32 -shared -s -static-libgcc -o devtools.dll tmp.def devtools.o -Ld:/RCompile/CRANpkg/extralibs64/local/lib/i386 -Ld:/RCompile/CRANpkg/extralibs64/local/lib -LC:/PROGRA~1/R/R-31~1.1/bin/i386 -lR\ninstalling to C:/Users/jmiller/AppData/Local/Temp/2/Rtmpuc93wo/devtools/libs/i386\n* arch - x64\ngcc -m64 -I\"C:/PROGRA~1/R/R-31~1.1/include\" -DNDEBUG     -I\"d:/RCompile/CRANpkg/extralibs64/local/include\"     -O2 -Wall  -std=gnu99 -mtune=core2 -c devtools.c -o devtools.o\ngcc -m64 -shared -s -static-libgcc -o devtools.dll tmp.def devtools.o -Ld:/RCompile/CRANpkg/extralibs64/local/lib/x64 -Ld:/RCompile/CRANpkg/extralibs64/local/lib -LC:/PROGRA~1/R/R-31~1.1/bin/x64 -lR\ninstalling to C:/Users/jmiller/AppData/Local/Temp/2/Rtmpuc93wo/devtools/libs/x64\n* R\n* inst\n* preparing package for lazy loading\n* help\n* installing help indices\n* building package indices\n* testing if installed package can be loaded\n* arch - i386\n* arch - x64\n- MD5 sums\n  packaged installation of 'devtools' as devtools_1.5.0.99.zip\n- DONE (devtools)\n  Renaming file to ./devtools.zip\n\n??corpus\nError in strsplit(topic, \"::\")[[1]] : subscript out of bounds\nrequire(devtools)\n??corpus\nError in strsplit(topic, \"::\")[[1]] : subscript out of bounds\n. It works! Thanks so much, @wch !\n. I noticed this as well. It's useful.. \n",
    "juliangehring": "Does this function or the documentation require more tweaking from my side?\n. This should address it.\n. Replacing this with #510.\n. ",
    "ghuiber": "This API download recipe fails me with \"API rate limit exceeded\" from my IP address (I'm at work). The devtools 1.5 version from CRAN works fine though. \nHere's the response from trying to install a package using devtools 1.5.0.99 built from source:\n```\n\ndevtools::install_github('ghuiber/syncR')\nUsing github PAT from envvar GITHUB_PAT\nInstalling github repo syncR/master from ghuiber\nDownloading syncR.zip from https://api.github.com/repos/ghuiber/syncR/zipball/master\n Show Traceback\n\nRerun with Debug\n Error in (function (url, name = NULL, subdir = NULL, config = list(),  : \n  client error: (403) Forbidden \n```\nAnd here's the response after re-installing devtools from CRAN:\n```\n\ndevtools::install_github('ghuiber/syncR')\nInstalling github repo syncR/master from ghuiber\nDownloading master.zip from https://github.com/ghuiber/syncR/archive/master.zip\nInstalling package from C:\\Users\\ghuiber\\AppData\\Local\\Temp\\RtmpSwztkC/master.zip\nInstalling syncR\n\"C:/PROGRA~1/R/bin/x64/R\" --vanilla CMD INSTALL  \\\n  \"C:\\Users\\ghuiber\\AppData\\Local\\Temp\\RtmpSwztkC\\devtools36acee46cd7\\syncR-master\" --library=\"C:/Program Files/R/library\"  \\\n  --install-tests \n\n\ninstalling source package 'syncR' ...\n R\n preparing package for lazy loading\n** help\n installing help indices\n* building package indices\n testing if installed package can be loaded\n arch - i386\n arch - x64\nDONE (syncR)\n```\n\nSo, it looks to me like this https://github.com/user/repo/archive/master.zip redirect is somehow more generous with rate limits than the newer https://api.github.com/repos/user/repo/zipball/master/repo.zip.\n. Regarding (2), I have no idea how I managed to exceed one request per minute. I definitely didn't make 60 requests for an archive link in total for the whole day. It must have been some kind of accounting glitch. 60 requests per hour sounds like a reasonable limit to me, so I don't mind the stern warning if  I really I hit it.\nResorting to (3) seems sneaky to me. \nAs to (1), I ran into this rate limit issue in the process of testing my install_github_enterprise() wrapper for custom URL's (see pull request 506) using a few variations of the API v3 call that you implemented for install_github(). Custom URL's, I expect, are private by default, with mandatory authentication, so (1) is not an option for them. \nSince the old behavior (archive/master.zip) still works I am tempted to just stick with it. But this is only because my employer's implementation of API v3 does not yet work properly; the 302 redirect will serve a full clone of the repo, not a repo.zip file. This confuses the PC, which expects something to unzip in the chain of events started by install_github() or install_github_enterprise(). \nSo, for now, my version of install_github.r implements a split solution. It sticks with the old behavior for install_github_enterprise(), and it adopts your implementation of the API call if install_github() points at a public repo. I want to respect GitHub's wishes and use the API as much as I can, but I'm grateful for the wiggle room.\n. There are two options, it seems to me:\n1. devtools implements what Kirill suggests. This solution would default to the old URL silently if no authentication is provided; with authentication, the new API limits are generous. Either way current devtools users will suffer no inconvenience. This solution will have one future-proof branch, with code on record that can be re-purposed for the no-authentication branch if GitHub decides to retire the old URL. On the enterprise side, this has a more immediate advantage: I expect that some enterprise hosts implement the new API well, while others, like mine, still rely on the old URL. My implementation of install_github_enterprise() uses the old URL and works for now. If somebody wants to put in code that checks whether the new API works for their host and redirect accordingly, having code on hand that shows how the API v3 URL is built on the public GitHub side will make their life easier.\n2. Stick with the old URL until GitHub makes the official announcement that the old URL is to be retired. When that happens, all the checks that (1) would have to implement, and therefore half its code, will be obsolete anyway. I like (2) because I think that less code is better.\n. Yes. See auth_token parameter in ?install_github.\n. I think we're courting trouble when we try to build by hand the final URL of interest to us (see line 113 in R/install_github.r). The API v3 seems to prefer a generic GET call with some set parameters that it will then redirect it to this final URL, which still subject to change. \nI don't know how to make devtools send a GET call to GitHub; Google turned up this overview of RCurl, which seems to be an R interface to these generic HTTP calls. \nA GET call of the form GET /repos/:owner/:repo/:archive_format/:ref would redirect correctly, on both GitHub and GitHub enterprise, no matter how the specific path may change in the future -- this, at least, is my reading of the e-mail I got from the GitHub help desk:\n\nI think the best and safest thing to do to ensure things continue to work in future across both sites is to ensure you use GET /repos/:owner/:repo/:archive_format/:ref and follow the redirect for all queries to both GitHub.com and GitHub Enterprise.  This will ensure you are always redirected to the correct file regardless of whether we update the relocation destination or not.\nThis redirection is to ensure the API remains stable whilst still allowing us to make changes behind the scenes. It also allows for slightly differing paths as GitHub.com and GitHub Enterprise don't quite work 100% the same in this regard.\n. Cool, thank you for httr::GET. I may not be using it right, or my customer's employees are prodigious GitHub consumers, because I'm still running into rate limits. Here's what I'm getting:\n\n```\n\nBuild a GitHub GET request\nsetParam <- function(username, repo, ref='master', host='https://api.github.com') {\n+     out <- list(username,repo,ref,host)\n+     names(out) <- c('username','repo','ref','host')\n+     return(out)\n+ }\nfoo <-setParam('ghuiber','devtools')\nhttr::GET(url=foo$host,user=foo$username,path='repos',\n+           client_id=foo$username,client_secret=Sys.getenv('GITHUB_PAT_PUBLIC'))\nResponse [https://api.github.com/repos]\n  Status: 403\n  Content-type: application/json; charset=utf-8\n{\n  \"message\": \"API rate limit exceeded for 216.113.168.141. (But here's the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.)\",\n  \"documentation_url\": \"https://developer.github.com/v3/#rate-limiting\"\n}\n```\n\nBut in any case, if httr::GET can have the API redirect us correctly, then why not grab the URL that we're redirected to instead of building it by hand? In other words, I'm not sure why install_github.r is doing what it's doing at line 113, rather than building param$url from something like the function defined at line 193.\n. It seems to me that the difference between the two is this: the call at\nline 197 is a GET call that will take whatever the GitHub API will serve.\nThat now happens to be the URL strung together explicitly by the call at\nline 113. So, both work, but this may change in the future.\nIf, for example, GitHub decides to serve the archive link from an URL that\nsays \"zipcube\" instead of \"zipball\", the call at line 197 will still work,\nwhile the call at 113 will fail.\nThis, I think, is why the CS reps you and I talked to were so strenuously\npushing the API redirect idea instead of an explicit reference to the old\n\"archive/master.zip\" URL.\nGabi\nOn Thu, Jul 24, 2014 at 2:09 AM, Kirill M\u00fcller notifications@github.com\nwrote:\n\nI'm not sure I understand correctly. Wouldn't even querying the correct\nURL count as an API access, subject to the rate limit?\nThe call at line 113\nhttps://github.com/hadley/devtools/blob/master/R/install-github.r#L113\nis an API call that will just get the file, as is the call at line 197\nhttps://github.com/hadley/devtools/blob/master/R/install-github.r#L197.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/pull/474#issuecomment-49984449.\n. You are right about build(). I could do it, though with some warnings, then install from the tar.gz file using RStudio's install GUI, so I made progress. \n\nBut help is not available for my version of devtools. Here's the output:\n```\n\ndevtools::build()\n\"C:/PROGRA~1/R/bin/x64/R\" --vanilla CMD build \"C:\\Users\\ghuiber\\Documents\\GitHub\\devtools\" --no-manual  \\\n  --no-resave-data \n\n\nchecking for file 'C:\\Users\\ghuiber\\Documents\\GitHub\\devtools/DESCRIPTION' ... OK\npreparing 'devtools':\nchecking DESCRIPTION meta-information ... OK\ncleaning src\nchecking for LF line-endings in source and make files\nchecking for empty or unneeded directories\nRemoved empty directory 'devtools/tests/testthat/testMarkdownVignettes/inst/doc'\nRemoved empty directory 'devtools/tests/testthat/testMarkdownVignettes/inst'\nRemoved empty directory 'devtools/tests/testthat/testVignetteExtras/inst/doc'\nRemoved empty directory 'devtools/tests/testthat/testVignetteExtras/inst'\nRemoved empty directory 'devtools/tests/testthat/testVignettes/inst/doc'\nRemoved empty directory 'devtools/tests/testthat/testVignettes/inst'\nbuilding 'devtools_1.5.0.99.tar.gz'\n\n[1] \"C:/Users/ghuiber/Documents/GitHub/devtools_1.5.0.99.tar.gz\"\n\ninstall.packages(\"~/GitHub/devtools_1.5.0.99.tar.gz\", repos = NULL, type = \"source\")\n installing source package 'devtools' ...\n* libs\n\n*** arch - i386\ncygwin warning:\n  MS-DOS style path detected: C:/PROGRA~1/R/etc/i386/Makeconf\n  Preferred POSIX equivalent is: /cygdrive/c/PROGRA~1/R/etc/i386/Makeconf\n  CYGWIN environment variable option \"nodosfilewarning\" turns off this warning.\n  Consult the user's guide for more details about POSIX paths:\n    http://cygwin.com/cygwin-ug-net/using.html#using-pathnames\ngcc -m32 -I\"C:/PROGRA~1/R/include\" -DNDEBUG     -I\"d:/RCompile/CRANpkg/extralibs64/local/include\"     -O3 -Wall  -std=gnu99 -mtune=core2 -c devtools.c -o devtools.o\ngcc -m32 -shared -s -static-libgcc -o devtools.dll tmp.def devtools.o -Ld:/RCompile/CRANpkg/extralibs64/local/lib/i386 -Ld:/RCompile/CRANpkg/extralibs64/local/lib -LC:/PROGRA~1/R/bin/i386 -lR\ninstalling to C:/Program Files/R/library/devtools/libs/i386\n arch - x64\ncygwin warning:\n  MS-DOS style path detected: C:/PROGRA~1/R/etc/x64/Makeconf\n  Preferred POSIX equivalent is: /cygdrive/c/PROGRA~1/R/etc/x64/Makeconf\n  CYGWIN environment variable option \"nodosfilewarning\" turns off this warning.\n  Consult the user's guide for more details about POSIX paths:\n    http://cygwin.com/cygwin-ug-net/using.html#using-pathnames\ngcc -m64 -I\"C:/PROGRA~1/R/include\" -DNDEBUG     -I\"d:/RCompile/CRANpkg/extralibs64/local/include\"     -O2 -Wall  -std=gnu99 -mtune=core2 -c devtools.c -o devtools.o\ngcc -m64 -shared -s -static-libgcc -o devtools.dll tmp.def devtools.o -Ld:/RCompile/CRANpkg/extralibs64/local/lib/x64 -Ld:/RCompile/CRANpkg/extralibs64/local/lib -LC:/PROGRA~1/R/bin/x64 -lR\ninstalling to C:/Program Files/R/library/devtools/libs/x64\nWarning in file.copy(files, dest, overwrite = TRUE) :\n  problem copying .\\devtools.dll to C:\\Program Files\\R\\library\\devtools\\libs\\x64\\devtools.dll: Permission denied\n* R\n inst\n preparing package for lazy loading\n help\n installing help indices\n* building package indices\n testing if installed package can be loaded\n arch - i386\n arch - x64\n* DONE (devtools)\n\nrequire(devtools)\n?install_github\nError in loadNamespace(name) : there is no package called \u2018rstudioapi\u2019\n```\n\nAny idea how to get over this snag? Thank you.\n. Almost there! \nInstalling the rstudioapi package got me unstuck. Then build() and install from the new tar.gz file got me my own devtools installed, which correctly handles the new repo_path parameter. It also talks about it in the help file that pops up in response to ?install_github.\nSo I added an archive/master.zip file to my private R package, by typing, at the Git BASH prompt,\ngit archive --format zip --output archive/master.zip master\nThen I install_github()-ed my package with repo_path set and to my enterprise GitHub repo URL and with an auth_token I had set up ahead of time. This worked: my package has one function, which shows up and is usable. \nThere are two problems though:\n- The help file that should talk about this function is broken. Instead, RStudio shows an error message that goes\nError in fetch(key) : lazy-load database '\ufffd' is corrupt\n- The function works, but with warnings that go\nWarning messages:\n1: In fetch(key) : internal error -3 in R_decompress1\n2: In fetch(key) : internal error -3 in R_decompress1\nI suspect that this \"archive/master.zip\" file that install_github() is looking for is built in some other fashion than the way I tried to build it, but I have no idea what I'm doing wrong.\n. You're right again, and thank you! It took two restarts, but now install_github() produces what is expected: it installs from my archive/master.zip and the help files are all here. No warnings upon require() either, or when the script makes function calls. I think I did it. \nI am making a pull request. You never know. This may be useful to other people with custom enterprise GitHub URL's. Thanks again.\n. I like github_url much better than repo_path, so I made the change, recompiled the docs, tested, built, installed, committed and pushed. That was an easy fix.\nAs to install_github() vs. install_github_enterprise(): what got me to nose around devtools in the first place was my client's wondering whether there was such a thing as install_github_[your company name here](). That's one piece of evidence that people would indeed find a separate function a more convenient place for a custom URL functionality than another argument to install_github(). The latter was just easier for me to implement.\nHow would I go about writing it with as little code duplication as possible? Add an install_github_enterprise() function definition to my install_github.r as a kind of convenience wrapper? This way my current version of install_github() continues to work with github_url explicitly set, or people can ignore that part altogether and just use install_github_enterprise().\nFinally, I have no idea about two unrelated bits\n1. How to do what @tbates suggests\n2. What to make of this Travis CI build fail. I'd like to make this pull request as easy on @hadley as I can, but I'm at a loss. Some shell script seems to be the snag, but what do I have to do with it?\n. Done. There is now an install_github_enterprise() wrapper for install_github(), and a helper devtools_git_enterprise() that retrieves the GITHUB_URL environment variable as Tim suggested.\n. Resolved merge conflict in my install-github.r to accommodate new GitHub API call #474. Travis CI build probably fails for whatever the original reason was 3 days ago.\n. Well, one warning still squeaked by, but I don't think it's aimed at me. It has to do with duplicate references to this SVN functionality. See https://travis-ci.org/hadley/devtools/builds/28632916#L954\n. I have no idea what's going on here. Travis turns up the same lone warning about one Rd file with duplicated names: svn_path.Rd. I have seen something to do with this in my test() output, shown below, but I also saw some other warnings which I thought would be both more serious and my own fault. \nI would appreciate any hints:\n```\n\nWarning messages:\n1: install_svn.Rd not generated by roxygen2. Skipped. \n2: install_svn_single.Rd not generated by roxygen2. Skipped. \nTesting devtools\nLoading devtools\nChecks : .\nData : ............................\nDependencies : ..............\nDESCRIPTION checks : ..\nCompiled DLLs : ................\nGitHub : ........................\nhelp : ...................\nImports : .....\nLoad: collate : ......\nLoad hooks : ....................................\nMetadata : .................\nNamespace : .............................\nRtools tests : ....\ns4-export : .\ns4-unload : ......................\nshim : ................\nVignettes : ......................\n...\nWith : ...............\nWarning messages:\n1: In if (!file.exists(pkg$path, \"src\")) return(TRUE) :\n  the condition has length > 1 and only the first element will be used\n2: In if (!file.exists(pkg$path, \"src\")) return(TRUE) :\n  the condition has length > 1 and only the first element will be used\n3: In if (!file.exists(pkg$path, \"src\")) return(TRUE) :\n  the condition has length > 1 and only the first element will be used\n4: In if (!file.exists(pkg$path, \"src\")) return(TRUE) :\n  the condition has length > 1 and only the first element will be used\n5: In if (!file.exists(pkg$path, \"src\")) return(TRUE) :\n  the condition has length > 1 and only the first element will be used\n\"C:/PROGRA~1/R/bin/x64/R\" --vanilla CMD build \"C:\\Users\\ghuiber\\Documents\\GitHub\\devtools\" --no-manual  \\\n  --no-resave-data \n\nchecking for file 'C:\\Users\\ghuiber\\Documents\\GitHub\\devtools/DESCRIPTION' ... OK\npreparing 'devtools':\nchecking DESCRIPTION meta-information ... OK\ncleaning src\nchecking for LF line-endings in source and make files\nchecking for empty or unneeded directories\nRemoved empty directory 'devtools/tests/testthat/testMarkdownVignettes/inst/doc'\nRemoved empty directory 'devtools/tests/testthat/testMarkdownVignettes/inst'\nRemoved empty directory 'devtools/tests/testthat/testVignetteExtras/inst/doc'\nRemoved empty directory 'devtools/tests/testthat/testVignetteExtras/inst'\nRemoved empty directory 'devtools/tests/testthat/testVignettes/inst/doc'\nRemoved empty directory 'devtools/tests/testthat/testVignettes/inst'\nbuilding 'devtools_1.5.0.99.tar.gz'\n\n[1] \"C:/Users/ghuiber/Documents/GitHub/devtools_1.5.0.99.tar.gz\"\nWarning message:\nIn if (!file.exists(pkg$path, \"src\")) return(TRUE) :\n  the condition has length > 1 and only the first element will be used\n```\nThis is all. Travis is not worried about any of the pkg$path condition length warnings. My local version of install_github_enterprise() works.\n. All may look well, but it's not. While load_all(); document(); test(); build() went without a hitch and Travis CI build passed too, now public GitHub doesn't work either. My API v3 call to get the archive zip file goes through, which is progress, but upon attempting actual installation I get this:\n```\n\nlibrary(devtools)\ninstall_github('ghuiber/syncR',auth_token=Sys.getenv()[['GITHUB_PAT_PUBLIC']])\nInstalling github repo ghuiber/syncR@master from ghuiber\nDownloading syncR.zip from https://api.github.com/repos/ghuiber/syncR/zipball/master\nInstalling package from C:\\Users\\ghuiber\\AppData\\Local\\Temp\\Rtmp6Rb2qt/syncR.zip\nError in system(full, intern = quiet, ignore.stderr = quiet, ...) : \n  '\"internal\"' not found\n```\n\nAny ideas? Maybe Rtools rotted again? I re-installed them not a month ago.\n. All seems well, but it's not and re-installing Rtools did not fix the problem. This version of devtools will choke on known, working GitHub packages such as Slidify with the same error message:\n```\n\ninstall_github(\"ramnathv/slidify\")\nUsing github PAT from envvar GITHUB_PAT\nInstalling github repo ramnathv/slidify@master from ramnathv\nDownloading slidify.zip from https://api.github.com/repos/ramnathv/slidify/zipball/master\nInstalling package from C:\\Users\\ghuiber\\AppData\\Local\\Temp\\RtmpQN2X5y/slidify.zip\nError in system(full, intern = quiet, ignore.stderr = quiet, ...) : \n  '\"internal\"' not found\ninstall_github(\"ramnathv/slidify\",auth_token=NULL)\nInstalling github repo ramnathv/slidify@master from ramnathv\nDownloading slidify.zip from https://api.github.com/repos/ramnathv/slidify/zipball/master\nInstalling package from C:\\Users\\ghuiber\\AppData\\Local\\Temp\\RtmpQN2X5y/slidify.zip\nError in system(full, intern = quiet, ignore.stderr = quiet, ...) : \n  '\"internal\"' not found\n```\n\nEdit: this works on the Mac though (OS X Mavericks, R 3.1.1).\n. Thank you so much! I can't wait for the next CRAN release :)\n. It does indeed! My install_github_enterprise() works again, now with API v3 redirect. Thank you!\n. Deleted src-i386/devtools.c and src-x64/devtools.c.\nOn Wed, Jun 25, 2014 at 10:04 AM, Hadley Wickham notifications@github.com\nwrote:\n\nIn src-i386/devtools.c:\n\n@@ -0,0 +1,6 @@\n+#include \n\nCan you please remove these two files?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/pull/506/files#r14198881.\n. \n",
    "saurfang": "I agree. Thanks for sharing your thoughts. I think the packrat package is very exciting and promising.\n. This is awesome! One thing I'd like to add is that with https://github.com/cscheid/rgithub I can use OAuth token instead of PAT. The upside is that I no longer need to ask every user to go to a page, click, type, click, copy, create file, paste, save and makes mistake. Downside is that token can expire and as long as they are logged in, they just need to close the page.\nA sample code might looks like this\n```r\nif (!requireNamespace(\"devtools\", quietly = TRUE)) {\n    message(\"Installing devtools package...\")\n    install.packages(\"devtools\")\n}\nif (!requireNamespace(\"github\", quietly = TRUE)) {\n    message(\"Installing rGithub package...\")\n    devtools::install_github(\"cscheid/rgithub\")\n}\n' Generate an Interactive GHE Context\n'\n' Authenticate with GHE using OAuth token.\n'\n' @seealso \\link[httr]{oauth2.0_token}\nghe_context <- function() {\n  # Save current httr OAuth caching option\n  old_httr_oauth_cache <- getOption(\"httr_oauth_cache\")\n  # Cache OAuth token at home directory instead\n  options(httr_oauth_cache = \"~/.utilr{{private}}/.httr-oauth-ghe\")\n  # Restore httr OAuth caching option\n  on.exit(options(httr_oauth_cache = old_httr_oauth_cache))\nclient_id <- \"{{not_so_secret_id}}\"\n  client_secret <- \"{{not_so_secret_token}}\"\n  base_url <- \"{{private host}}\"\n  api_url <- file.path(base_url, \"api\", \"v3\")\n  github::interactive.login(client_id, client_secret, NULL, base_url, api_url)\n}\n' Updates utilr{{private}} and all of its required packages to the latest versions\n'\n' @export\nupdate_utilr <- function(...) {\n  ctx <- ghe_context()\n  auth_token <- ctx$token$credentials$access_token\ndevtools::install_github(\"{{private}}/utilr\", host = ctx$api_url, auth_token = auth_token, ...)\n}\n```\n. ",
    "jackwasey": "http://docs.travis-ci.com/user/build-timeouts/#Build-times-out-because-no-output-was-received\n. to be clear, a workaround is to use library(pkgbuild) with an updated pkgbuild after loading devtools. ",
    "renkun-ken": "http://cran.r-project.org/doc/manuals/r-release/R-exts.html#Licensing gives very detailed instruction on the format of licensing. I scanned all licenses at http://www.r-project.org/Licenses/ and find that only BSD-2, BSD-3, and MIT require additional file LICENSE that should be correctly formatted.\nSo check DESCRIPTION for\nLicense: BSD_2_clause + file LICENSE\nor\nLicense: MIT + file LICENSE\nthen check LICENSE file:\nYEAR:\nCOPYRIGHT HOLDER:\nOr check for DESCRIPTION for\nLicense: BSD_3_clause + file LICENSE\nthen check LICENSE file:\nYEAR:\nCOPYRIGHT HOLDER: \nORGANIZATION:\n. @hadley, the problem is that for the same package, sometimes it takes only a few seconds to go through Installing <package> but it may sometimes takes several minutes as well hanging at Installing <package>. Mostly it finishes unless I cannot wait any longer and kill it. If it hangs, then I kill it. After several times, it may eventually step to compiling and so on without hanging at Installing <package>.\n@jimhester The package does not depend on or import any remotes (no declared Remotes in DESCRIPTION).\nI'm not sure what's happening at Installing <package>?. No hanging is observed so far.. No error occurs in command line or in RStudio console. This error only occurs when I click \"Check\" button in Build pane in RStudio. . If I do not set CRAN mirror in .Rprofile, a fresh R session would take forever to get the mirror list. If I set the CRAN mirror in .Rprofile, the problem is completely gone. It is most probably due to the proxy setup of my machine. It behaves normally on other machines.. ",
    "amcdavid": "I appreciate the thought that it's better to fix the underlying problem, as well as the quick response.   The config=list(...) works fine for install_url, is there an equivalent solution for install_github?  It doesn't look like I can pass \"config\" as an argument to install_github.\n. Additionally, in the pkgload refactor, dev_help was moved and is currently not re-exported by devtools.  Is this the intended API?  If so, a deprecation message to users about this change seems appropriate, since it was a public function in devtools previously.. Hrm, weird.  I added fixed=TRUE and it worked on my machine.  Will try escaping and removing fixed.. I am buffaloed as to why this fails on the CI.  R CMD check on the built package works fine on my system.. Wrangling this pull RQ exceeds the bounds of my github-fu.  I'll leave this to someone more experienced to finish off.. ",
    "fabian-s": "Sorry, never mind. I forgot to manually include Matrix and methods in DESCRIPTION's Depends field. I'm an idiot.\n. ",
    "aleksandar-spasojevic": "In both ways, i haven't realized that, thanks for mentioning.\n. ",
    "pimentel": "Hello. I'd like to follow up with this as I'm having similar issues even after adding to Depends or Imports\n$ R --vanilla\n``` R\n\nlibrary(devtools)\ncreate('testPackage')\nsetwd('testPackage/')\ntest()\nNo testing infrastructure found. Create it?\n\n1: Yes\n2: No\nSelection: 1\n```\nPut the following in tests/testthat/test-data.table.R:\n``` R\ncontext('data.table bug')\ntest_that('construction',\n    {\n    i2t <- data.table(data.frame(\n        myCol = c('i1', 'i1', 'i2', 'i3', 'i3'),\n        targ = c('t1', 't2', 't1', 't4', 't1'),\n        stringsAsFactors = T), key = 'targ')\n\n    targExp <- data.table(data.frame(\n        samp1 = c(1, 0.5, 4, 1, 0, 10, 2),\n        samp2 = c(1, 0.25, 0, 2, 8, 3, 3),\n        targ = c('i1', 'i2', 't1', 't2', 't3', 't4', 'i3'),\n        stringsAsFactors = T), key = 'targ')\n\n    print(targExp[i2t,,])\n})\n\n```\nThen, the DESCRIPTION file looks like:\nPackage: testPackage\nTitle: What the package does (short line)\nVersion: 0.1\nAuthors.R: \"First Last <first.last@example.com> [aut, cre]\"\nDescription: It tests devtools & data.table issue\nDepends: R (>= 3.1.1), data.table\nLicense: What license is it under?\nLazyData: true\nSuggests: testthat\nThen running test() results in:\n``` R\n\ntest()\nTesting testPackage\nLoading testPackage\ndata.table bug : 1\n\n\nError: construction ---------------------------------------------------------\ninvalid subscript type 'list'\n1: print(targExp[i2t, , ]) at test-data.table.R:17\n2: targExp[i2t, , ]\n3: [.data.table(targExp, i2t, , )\n4: [.data.frame(x, i, j)\n```\n\nBut behavior is as expected when you source:\n``` R\n\nsource('tests/testthat/test-data.table.R')\n   targ samp1 samp2 myCol\n1:   t1     4     0    i1\n2:   t1     4     0    i2\n3:   t1     4     0    i3\n4:   t2     1     2    i1\n5:   t4    10     3    i3\n```\n\nAny suggestions?\nThanks!\nEDIT: Here is my sessionInfo()\n``` R\n\nsessionInfo()\nR version 3.1.1 (2014-07-10)\nPlatform: x86_64-apple-darwin13.1.0 (64-bit)\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] testPackage_0.1  data.table_1.9.2 testthat_0.8.1   devtools_1.5    \nloaded via a namespace (and not attached):\n [1] digest_0.6.4   evaluate_0.5.5 httr_0.3       memoise_0.2.1  parallel_3.1.1\n [6] plyr_1.8.1     Rcpp_0.11.2    RCurl_1.95-4.3 reshape2_1.4   stringr_0.6.2 \n[11] tools_3.1.1    whisker_0.3-2 \n```\n. ",
    "svenski": "I have the same issue with data.table and devtools. A potential work around is to force the package into the data.table aware override as per: http://stackoverflow.com/questions/13106018/data-table-error-when-used-through-knitr-gwidgetswww/13131555#13131555. \n. ",
    "1beb": "Had the same problem, can confirm that adding data.table to Imports in my description file fixed this issue. I had it in Depends but the problem persisted.\n. This is run inside of a circleci build using: \nRscript -e 'devtools::install_github(...)'\nI can certainly try to run it again, although I don't know how to get a traceback when using Rscript -e at the console.\n. ",
    "cjyang90": "I did install Rtools, but I still get the following error when I ran devtools::has_devel()\n\"C:/PROGRA~1/R/R-31~1.0/bin/i386/R\" --vanilla CMD SHLIB foo.c \nWarning message:\nrunning command 'make -f \"C:/PROGRA~1/R/R-31~1.0/etc/i386/Makeconf\" -f \"C:/PROGRA~1/R/R-31~1.0/share/make/winshlib.mk\" SHLIB=\"foo.dll\" OBJECTS=\"foo.o\"' had status 127 \nError: Command failed (1)\n. ",
    "busasquatch": "Thank you tbates.  I am a bit of a novice.  I'll see if that works.\n. ",
    "wush978": "In https://github.com/wush978/devtools/commit/8470f0f790bb74a9e3f72cf55e98d1d0b370b7e4 to https://github.com/wush978/devtools/commit/93fe2304807a357aedb43978a75ad588842a8b35 :\n- souce_gist will use either source or Rcpp::sourceCpp according to the file extension. The related parsers are implemented in . parseJSON1.\n- Some tests are implemented in tests/testthat/test-gist.r\n- All files in gist will be downloaded and renamed accordingly, so they could source each other with argument: chdir = TRUE with relative path. Please check the second test in tests/testthat/test-gist.r\n. Your change is merged and the test is passed. Note that I also change the behavior of sourcing R scripts. Under this branch, R will download all files in gist and move them into a temporal directory so that they can source each other.\n. Hi Hadley,\nI thought I was waiting you to accept/reject this PR or any further feedback after merging your changes of find_gist, so there was no more action before hearing any feedback from others. \nStill thank you for your response after 3 years.. For development, maybe you could call the roxygenize through autotools.\nFor example, write a configure.ac:\n```\n-- Autoconf --\nProcess this file with autoconf to produce a configure script.\nAC_PREREQ([2.69])\nAC_INIT([FULL-PACKAGE-NAME], [VERSION], [BUG-REPORT-ADDRESS])\nRscript -e \"library(roxygen2);roxygenize()\"\nAC_OUTPUT\n```\nThen, call autoconf once to generate configure. After shipping the package with configure, the client will re-generate document with roxygenize before installing the packge.\n. I put an example here: https://github.com/wush978/DemoAutotoolWithRoxygenize\nTry:\nr\nlibrary(devtools)\ninstall_github(\"DemoAutotoolWithRoxygenize\", \"wush978\")\nlibrary(Test)\n?hello\nThere is no man and NAMESPACE in the source. The configure script will launch roxygenize to generate them before installation.\n. I'll implement it with jsonlite or rjson. The .parseJSON1 will be used if these packages are not existed.\n. Thanks for you suggestion. I'll update it soon.\n. ",
    "volkanunsal": "ok, thank you.\n. ",
    "scottkosty": "Sure, I forgot about that. I will submit a different pull request. Why do you track these files? For install_github? Would it make sense to have install_github run roxygenise (and promote roxygen2 to an import) so these files don't need to be tracked? Or am I missing something else?\n. OK. New PR at #517.\n. ",
    "ManojG20": "Thank you Hadley :) \nWorks Perfectly!\n. ",
    "jangorecki": "with_libpaths() works fine.\njust curious, is there any reason why not to allow lib argument, the same way as install.packages?\n. It would be just more aligned to the standard well used for decades install.packages. Nothing more.\n. ",
    "phonixor": "i am not familiar with autoconf and stuff, but how can this be called in combination with install_github()?\ninstall_github() downloads the source code, compiles it into a binary package, and then deletes the source code, with no chance to intervene as far as i know.\nits also relatively hard to make your own install_github(), as https is not supported by R by default.... which is kinda silly\n. Awesome!\nSo R CMD BUILD or R CMD INSTALL checks for a file named configure.ac in the projects root directory?   and then calls autoconfig to create the configure file ?\ngonna try at home if that works on windows as well (i figure that would require Rtools)\n. @wch sorry i should have seen that issue. \n@wush978 \non windows i get the following:\n```\n\ninstall_github(\"DemoAutotoolWithRoxygenize\", \"wush978\")\nInstalling github repo DemoAutotoolWithRoxygenize/master from wush978\nDownloading master.zip from https://github.com/wush978/DemoAutotoolWithRoxygenize/archive/master.zip\nInstalling package from C:\\Users\\phonixor\\AppData\\Local\\Temp\\RStudioPortableTemp\\RtmpIHbLTx/master.zip\nInstalling Test\n\"D:/PORTAB~1/R-PORT~1/App/R-PORT~1/bin/x64/R\" --vanilla CMD INSTALL  \\\n  \"C:\\Users\\phonixor\\AppData\\Local\\Temp\\RStudioPortableTemp\\RtmpIHbLTx\\devtools10ec3e51335f\\DemoAutotoolWithRoxygenize-master\"  \\\n  --library=\"C:/Users/phonixor/Documents/R/win-library/3.0\" --install-tests \n\n\ninstalling source package 'Test' ...\n\n\nWARNING: this package has a configure script\n         It probably needs manual configuration\n\nERROR: a 'NAMESPACE' file is required\n* removing 'C:/Users/phonixor/Documents/R/win-library/3.0/Test'\nError: Command failed (1)\n```\ngonna test if it works if i add a NAMESPACE file\n. ok even if i add a NAMESPACE file it still does not work on windows, and so its not a valid solution :(\n```\n\ninstall_github(\"DemoAutotoolWithRoxygenize\", \"phonixor\")\nInstalling github repo DemoAutotoolWithRoxygenize/master from phonixor\nDownloading master.zip from https://github.com/phonixor/DemoAutotoolWithRoxygenize/archive/master.zip\nInstalling package from C:\\Users\\phonixor\\AppData\\Local\\Temp\\RStudioPortableTemp\\Rtmp8OT0hB/master.zip\nInstalling Test\n\"D:/PORTAB~1/R-PORT~1/App/R-PORT~1/bin/x64/R\" --vanilla CMD INSTALL  \\\n  \"C:\\Users\\phonixor\\AppData\\Local\\Temp\\RStudioPortableTemp\\Rtmp8OT0hB\\devtools20907afc2d1c\\DemoAutotoolWithRoxygenize-master\"  \\\n  --library=\"C:/Users/phonixor/Documents/R/win-library/3.0\" --install-tests \n\n\ninstalling source package 'Test' ...\n\n\nWARNING: this package has a configure script\n         It probably needs manual configuration\n\n R\n preparing package for lazy loading\n* help\nNo man pages found in package  'Test' \n installing help indices\n* building package indices\n testing if installed package can be loaded\n arch - i386\n arch - x64\n DONE (Test)\n```\n. ",
    "d-mishra": "I got the issue resolved. It seems that pre-installed cygwin doesnt work well with the installation. I removed the preinstalled cygwin from the PATH variable and included the cygwin DLLs durin installation of rtools. That resolved the issue.\n. ",
    "dacorea1": "Hey there Rappster.  I'm actually experiencing the same issue you've been troubleshooting today.  I just had to update all my R packages today, leaving me with an RCurl installation that crashes my R session every time I need to use devtools.  Seeing as how it's nearing the end of my day, I thought I'd make my way to Stack Overflow, only to find that you already posted this issue there. :+1: \nThanks so much for going through the trouble to uncover this troublesome package.   I'll let you know if I make any progress on my end, and I'll keep an eye out to see you if make any as well.\n. Rappster and Hadley,\nThanks for both of your efforts in understanding this bug. CRAN now has a binary file for v.1.95-4.3 of RCurl hosted on its site.\nAfter downloading it, and building it from source, I have a working version of RCurl on my windows machine again.\n. ",
    "geneorama": "For what it's worth, I found a workaround that works for me;\n1. Clone the project that you want to install (I'm assuming this project is an R Package, like devtools)\n2. Start a new R Studio project in that project folder\n3. Click on the \"build\" tab\n4. Click on the \"Build & Reload\" button. \nThe package should be installed.\n. Thanks for the reply Hadley!  I posted my work around in 532, hopefully it's useful.\n. Also I apologize for posting a question that is at the top of the issues list, that was my bad and accidental.\n. ",
    "tpayer": "Hi Hadley,\nI just took the Coursera course on R programming and have some how got a\nflood of your email traffic from GitHub.\nHow can \"unsubscribe\"?\nTim\nOn Thu, Aug 21, 2014 at 2:11 PM, Hadley Wickham notifications@github.com\nwrote:\n\nClosed #534 https://github.com/hadley/devtools/issues/534 via 6c35693\nhttps://github.com/hadley/devtools/commit/6c356930fcf072599f1eee7e504f286255c3af92\n.\n\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/534#event-155795294.\n. \n",
    "smbache": "The downloaded zip does not have a single folder in it with the R package, but just has the contents of such a folder.. maybe that is where the problem is.\n. I could fix it as\ndevtools::install_url(url, subdir = \"..\")\nDon't know whether it should be considered a \"bug\" or not. \n. Yeah; that's what I also conclude :) I know, for example, that a Stash git server using an Archive plugin (https://marketplace.atlassian.com/plugins/com.atlassian.stash.plugin.stash-archive) does not use such subdirectory when archiving,  so perhaps it should have a check whether it is actually a directory it gets; otherwise try to \"level up\"... \n. While we're at it -- another nice minor (minor) thing would be to perhaps default to something (e.g. zip which is probably more common?!) when the saved temp file doesn't have a file ending, i.e. when basename(url) doesn't return anything useful. Also something I encountered. Specifying namesolved it, but just makes the call a little more verbose.\n. as in the master branch? Still does not seem to fix this issue.\nAlso I got a warning package \u2018BiocInstaller\u2019 is not available\" and also \nWarning in file.copy(files, dest, overwrite = TRUE) :\n  problem copying .\\devtools.dll to C:\\opt\\R\\current\\library\\devtools\\libs\\x64\\devtools.dll: Permission    denied\n. Problem is that I only know this one private stash server and can't really use that. But it delivers the R packages zipped, but not in a \"sub directory\", and the URL does not have base name, i.e. no extension can be extracted from it, e.g. zip.\nOh, and the warnings mentioned above was from installing devtools from github master...\n. Sure, on phone for the weekend, but monday-ish! :)\n. You can try this:\ndevtools::install_url(\"http://stefanbache.dk/spacewastr.zip\")\nshould replicate the bahviour.\n. ",
    "audy": "I did mean to post this on the packrat issues page. Too many open tabs I guess.\nThanks for your help anyway!\n. ",
    "teramonagi": "I re-wrote my utility.R for the  purpose of this check as a file included in a package.\nutility.R includes only the one function f.\n``` r\n' sample function\n' @param x arugument\n'\n' @return just value\n'\n' @export\nf <- function(x)\n{\n  x\n}\n```\nWhen I \"Document(Ctrl+Shift+D)\" on RStudio, it works well.\nBut on the other hand, when I modified function f as using \"default arugment\" like the following:\n``` r\n' sample function\n' @param x arugument\n'\n' @return just value\n'\n' @export\nf <- function(x=c(1))\n{\n  x\n}\n```\nI got the error I wrote the above.\n```\n\ndevtools::document(roclets=c(\"rd\", 'namespace'))\nUpdating tempErrorCheck documentation\nLoading tempErrorCheck\nError: Failure in roxygen block beginning utility.R:7\ninvalid multibyte string at '=c(1)'\n```\n\nAnd as I wrote the above, I can fixed the issue to set my \"LC_CTYPE\" variable to \"C\".\n``` r\n\nSys.setlocale(category = \"LC_CTYPE\", locale = \"C\")\n```\n. I sent to to you an email with the RStudio project file including utility.R.\n\nI think that it is the only problem happen in \"Windows  + Japanese(or Multi-byte language)\" environment. \nAnd the easiest way to solve a this type of problems seems that RStudio introduces the functionality to run some R-command before build, documentation and tests.\n. ",
    "robertzk": "This is great! Hope this makes it to master some day.\n. Looks like he just removed a newline.\n. Something like this?\n. Great points!\n. @gaborcsardi Still working on Windows support, but is this better? Thanks for the feedback.\n. @gaborcsardi Feel free to devtools::install_github('robertzk/devtools@load_from_anywhere') to try it out yourself (yes, I realize this is a little recursive, but I promise my PR doesn't break install_github to change back to hadley's version).\n. bump - per our convo at R day, will refactor to use standard testing\n. Better?\n. Thanks for the comments! I think I incorporated every suggestion. \n. How do I fix CI? Add \"stats\" to Imports?\nThe command \"Rscript -e 'options(repos = \"http://cran.rstudio.com\"); tryCatch({   deps <- devtools::install_deps(dependencies = TRUE) }, error = function(e) {   message(e);   q(status=1) }); if (!all(deps %in% installed.packages())) {  q(status = 1, save = \"no\") }'\" failed and exited with 1 during .\n. I think I deleted my fork of devtools, and now I can't access it either. Sorry about that.\n. ```\n\nSys.info()\n                                                                                           sysname                                                                                            release\n                                                                                          \"Darwin\"                                                                                           \"13.4.0\"\n                                                                                           version                                                                                           nodename\n\"Darwin Kernel Version 13.4.0: Sun Aug 17 19:50:11 PDT 2014; root:xnu-2422.115.4~1/RELEASE_X86_64\"                                                                      \"Roberts-MacBook-Air-3.local\"\n                                                                                           machine                                                                                              login\n                                                                                          \"x86_64\"                                                                                          \"robertk\"\n                                                                                              user                                                                                     effective_user\n                                                                                         \"robertk\"                                                                                          \"robertk\"\n.\nR version 3.0.2 (2013-09-25)\nPlatform: x86_64-apple-darwin10.8.0 (64-bit)\n``\n. https://github.com/hadley/devtools/pull/762\n. My devtools was out of date.\n.c(NULL, 'a')yieldsc('a')`, so would it also be OK to do this?\n\nR\nargs <- c(args, if (!\"--manual\" %in% args) \"--no-manual\", \"--no-resave-data\")\n(note infix operators take precedence over !)\n. This is technically fine since any failures will get captured by test_that, but whenever running a block of code that has to change something back (like options or environment variables), I would suggest local in conjunction with on.exit, or tryCatch\nR\n.R_TESTS <- Sys.getenv(\"R_TESTS\")\ntry_catch(finally = Sys.setenv(R_TESTS = .R_TESTS), {\n   Sys.setenv(R_TESTS = \"\")\n   # test_that code goes here\n})\n. Very nice\n. ",
    "Geoff99": "Know I know (slightly) more about git and branches and R, I will close this pull request, and resubmit the key elements as a smaller and more focused proposal.\nGeoff\n. PPPPS The sessionInfo for the examples was \n```\n\nsessionInfo()\nR version 3.1.1 (2014-07-10)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\n\nlocale:\n[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252 \n[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                    \n[5] LC_TIME=English_Australia.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] loadallExample_0.1  devtools_1.6.0.9000\nloaded via a namespace (and not attached):\n[1] Rcpp_0.11.2    roxygen2_4.0.1 stringr_0.6.2  tools_3.1.1   \n\n```\n. I have just now updated from roxygen2 4.0.1 to 4.0.2 (the CRAN version of roxygen2, not the very latest github version) and I still get the same problem (as long as I remember to clean out the DESCRIPTION file so it has no collate entry, so that the example test is valid - once I've run roxygen2::update_collate() once, everything is of course fixed in the DESCRIPTION file my example )\n\n```\n\nlibrary(devtools)\nload_all()\nLoading loadallExample\nError in reconcilePropertiesAndPrototype(name, slots, prototype, superClasses,  (from a.r#2) : \n  no definition was found for superclass \u201cClass1\u201d in the specification of class \u201cClass2\u201d\nlibrary(roxygen2)\nsessionInfo()\nR version 3.1.1 (2014-07-10)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\n\nlocale:\n[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252 \n[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                    \n[5] LC_TIME=English_Australia.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] roxygen2_4.0.2      devtools_1.6.0.9000\nloaded via a namespace (and not attached):\n[1] Rcpp_0.11.2   stringr_0.6.2 tools_3.1.1  \n\n```\n\nI didn't think of checking the latest version of roxygen2 at first (but I should have done) because it looks like the failure happens before roxygen2 is invoked - apologies for the oversight.\nGeoff\n. Hi Winston\nI hadn\u2019t at the time I posted the issue, but I did as soon as I saw your question, and the short answer is, using the latest CRAN version of roxygen2 doesn\u2019t fix the issue (I think the error occurs before roxygen2 is invoked).\nGeoff\nPS I\u2019ve posted the details on github \u2013 I\u2019m still getting used to what github does with notifications and watching etc, so apologies in advance for the duplication if you already saw my response there\nFrom: Winston Chang [mailto:notifications@github.com] \nSent: Tuesday, 21 October 2014 2:16 AM\nTo: hadley/devtools\nCc: Geoff99\nSubject: Re: [devtools] devtools::load_all() may fail when S4 class definitions are in different files (#623)\nHave you tried updating to the most recent roxygen2?\n\u2014\nReply to this email directly or view it on GitHub https://github.com/hadley/devtools/issues/623#issuecomment-59777343 .  https://github.com/notifications/beacon/8340230__eyJzY29wZSI6Ik5ld3NpZXM6QmVhY29uIiwiZXhwaXJlcyI6MTcyOTQzNzM1MywiZGF0YSI6eyJpZCI6NDYyNTYyODl9fQ==--9b2462337da10c8fa9dbc3715c3c78d8a42c1e36.gif \n. Thanks Hadley.  That's what I thought after I'd read through the load.r code.  It seems to be on the same plane as creating a default DESCRIPTION file if none exits.\n#' @include seems philosophically a little bit unusual as a roxygen2 comment - it isn't pure documentation since it has a side effect (expressed via the collate entry in the DESCRIPTION file) on what the packaged code actually does.  But it's very useful - much more natural to me than compiling the collate list manually and editing it into the DESCRIPTION file.\nPS I couldn't quite figure out whether or not it was necessary to call as.package (possibly again) after the call to roxygen2::update_collate in order to reflect the updated collate field in the information stored about the pkg in devtools online memory\n. Hi @hadley \nI've been working on this (very slowly, since I'm still learning the very basics of git, and happily working my way through my copy of the Advanced R book which arrived a couple of weeks ago).\nI've hit a snag, which means I've got some more thinking to do.  If you have any guidance to offer, it would be most appreciated. \nEdited in some thoughts about options (on Mon 11 Nov 2014) - see below\nIt seems that roxygen2::update_collate overwrites the existing Collate field in the DESCRIPTION file, based on the @include directives that it finds in the files in the package directory.  \nThat's good for my situation :-)  (as I slowly build up the package I am working on, and tidy the functions into nice workable and maintainable code, I want the Collate entries to be changed to reflect my latest file structure.)  \nBut if someone else has chosen to create their Collate entries by manually editing the DESCRIPTION file instead of using the @include roxygen2 directives, this will wipe out their entries, and make them unhappy :-(\nIt may need a bit more work to figure out which situation applies and hence to guess what the user actually wants to do. \nRegards\nGeoff\nPS This has been a really good example for me to appreciate the value of the testthat approach to development.  I figured this out only after I started to try and work out why some of the existing expectations in test-load-collate.r were failing after I added the call to update_collate in my forked branch of devtools.\nEdited in - thoughts about possible approaches\nI can think of three possible approaches, none feel really good.  The last one (3b) seems the least worst to me.\nOptions\n\nMandate that if the collate order matters to your package and you want to use devtools then either:\n   1a. You must use @include and cannot edit the DESCRIPTION file collate field by hand or\n   1b. You cannot @include and must edit the DESCRIPTION file collate field by hand\nAdd a new argument to devtools::load_all which indicates whether or not you want the collate field to be generated from @include directives; make sure that all internal uses of load_all are aware of this, and pass the appropriate argument through\nDo your best to guess what the package builder wants, as follows\n\n| '@includesexist in package files | Guessed action |\n| --- | --- |\n| Yes |update_collateand overwrite any existing collate entries |\n| No | leave collate entry (if it exists) unchanged, ie do notupdate_collate` |\n3a. Find out about the existence of any @includes by mirroring parts of the roxygen2 code and / or calling unexported roxygen2 functions (bad :-( )\n3b. Find out about the existence of any @includes by taking a safecopy of the DESCRIPTION file, running update_collate, then seeing if the new updated DESCRIPTION file has a non-null collate entry\nAny comments and better suggestions much appreciated, Geoff\n. I think there is a bug in the version of roxygen2::update_collate I am using then.\nIf I have a test package with the following DESCRIPTION file \nPackage: roxygenbugexample\nTitle: Checks Whether roxygen2::update_collate Removes Entries\nVersion: 0.0.0.9000\nAuthors@R: \"First Last <first.last@example.com> [aut, cre]\"\nDescription: Simple package with no @includes and a pre-existing Collate entry\nDepends: R (>= 3.1.1)\nLicense: What license is it under?\nLazyData: true\nCollate: b.r a.r\nand then run roxygen2::update_collate() on it \n```\n\nlibrary(roxygen2)\nroxygen2::update_collate('.')\nUpdating collate directive in  ./DESCRIPTION \n```\n\nthe DESCRIPTION file becomes\nPackage: roxygenbugexample\nTitle: Checks Whether roxygen2::update_collate Removes Entries\nVersion: 0.0.0.9000\nAuthors@R: \"First Last <first.last@example.com> [aut, cre]\"\nDescription: Simple package with no @includes and a pre-existing Collate entry\nDepends:\n    R (>= 3.1.1)\nLicense: What license is it under?\nLazyData: true\ni.e. the collate entry is removed rather than nothing happening (there are no @includes in a.r or b.r)\nHere is the sessionInfo from my run.\n```\n\nsessionInfo()\nR version 3.1.1 (2014-07-10)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\n\nlocale:\n[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252 \n[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                    \n[5] LC_TIME=English_Australia.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] roxygen2_4.0.2\nloaded via a namespace (and not attached):\n[1] Rcpp_0.11.2   stringr_0.6.2 tools_3.1.1 \n```\nI'll file an issue for roxygen2 (after I check that I am using an up to date version of roxygen2)\n. Hi @hadley \nNot sure if it is the correct protocol to comment on a closed issue but I'd like to reopen the issue / suggest an additional change.  \nThe test_that (from pull request #649) load_all() recognises and processes the @include generated collate order is still failing, even though load_all now includes a call to roxygen2::update_collate.\nIt appears that as well as calling update_collate to create / refresh the Collate field in the DESCRIPTION file, devtools also needs to refresh the pkg$collate entry in the pkg list / structure so that the remainder of the load_all() code is aware that the collate order has been generated / refreshed and is (possibly) non-alphabetical.\nThe following extra line (after the commented explanation) does this\nroxygen2::update_collate(pkg$path)\n#Refresh the pkg structure with any updates to the Collate entry\n#in the DESCRIPTION file\npkg <- as.package(pkg$path)\n. Sure, I\u2019ll be happy to.\nWill be later today (my time) before I get chance to make sure I\u2019ve got everything neat and tidy\nGeoff\nFrom: Hadley Wickham [mailto:notifications@github.com] \nSent: Thursday, 15 January 2015 8:22 AM\nTo: hadley/devtools\nCc: Geoff99\nSubject: Re: [devtools] devtools::load_all() may fail when S4 class definitions are in different files (#623)\nCan you please refile a pull request with that change and the tests?\n\u2014\nReply to this email directly or view it on GitHub https://github.com/hadley/devtools/issues/623#issuecomment-69994384 .  https://github.com/notifications/beacon/AH9DBq19PCwxhux-wZnVr48lAZIsiUuHks5nhtWTgaJpZM4CwdCh.gif \n. Please see pull request #649 \nHappy to make any adjustments you want\nGeoff\n. I have just realised that I probably ought to have waited for the roxygen2 changes this fix depends upon before submitting this pull request, since until the roxygen2 issue is resolved, making this change to devtools causes it to fail the Travis tests  :-(\nApologies.\nMmmm, learning something new every day.\nGeoff\n. Temporarily closing this pull request (sorry for all the toing and froing) while I learn more about using version numbers to ensure that this fix to devtools ensures that the fix to roxygen2 upon which it depends is available.\nUpdate As at 22 Nov 2014 I think I have figured out the answers to the queries below, so don't bother reading the rest of this comment.  I am only leaving them in there as a record for myself of what I was confused about (in case future me forgets again).  Geoff\nAdvice re the following topics which have me slightly puzzled would be appreciated (I'll continue to research / learn / experiment myself but advice or pointers (eg links to what I should read) would be appreciated if anyone has time to offer them).\nFirst : I know I can update the DESCRIPTION file so that the Suggests field says it needs a particular version of roxygen2, eg\nSuggests:\n    testthat (>= 0.7),\n    roxygen2 (>= 4.0.2.9001), \n    ...\nbut I'm unclear about exactly when that gets checked (and very unclear about how it interacts with Travis, which is on the far horizon of my personal knowledge space at the moment (I know it's there but ...))\nSecond : I could insert code into the fix in load_all which uses packageVersion(\"roxygen2\") >= \"4.0.2.9001\" to test that roxygen2 version number is sufficiently large when load_all is executed \n(or I could employ the is_installed function from devtools utils.r, once I work out why it checks for > rather than >=   --- it looks like I would need to code it as is_installed(\"roxygen2\", version = \"4.0.2.9000\") to get the effect I want),\nbut I'm not sure exactly what action I should take if the roxygen version is not high enough.\n- I might put out an advisory message and continue without calling update_collate (in which case users with @includes will not get what they expect, but will at least be warned); or\n- I could stop , but that seems to me to imply that roxygen2 should be promoted from Suggests to Imports (but I'm still reading up on, and slowly getting my mind around the difference between Suggests, Imports and Depends, so I could be way off track here).  And anyway, that seems a big change to propose for what is essentially a 1 line fix to the code !\nGeoff\n. Hi @hadley \nI've decided to leave this fix for issue #623 parked and wait until there has been time to review the pull request for roxygen2 which makes update_collate genuinely do  nothing if there are no @includes in the package code (see klutometis/roxygen#303 for the proposed fix, or klutometis/roxygen#304 for the fix plus a testthat)\nI did try (on a separate experimental branch in my forked copy of devtools) to use version numbers to make the requirement for the roxygen2 correction be 'automatically (or automagically) applied when devtools is loaded (and when Travis CI runs).  I got part of the way there (and learnt lots more about Travis, and also about exactly which version numbers gets checked by what commands, and when) but it's getting too complicated  (Travis CI needs devtools for some of the scripts to work) for a fix which amounts to only three lines of code (plus some testthats) so I'll just do them in series, and worry about getting the roxygen2 fix right and accepted first.\nGeoff\n. Closing (temporarily) pending understanding more about the polite way of managing inter package dependencies (when both packages are on development branches, and this fix depends upon a pull request on the other package which hasn't yet been accepted).\nSee comment in pull request #648 for details (of what I need to learn more about)\nGeoff\n. Hi @hadley \nNow that update_collate has been fixed in roxygen2 (4.1.0) this proposed change to load_all (essentially just a one-liner to call roxygen2::update_collate ) should fix #623 , so I'm reopening this pull request .  I (think I) have brought the pull request code up to date with other changes to devtools that have been committed since I first wrote it.\nThere is a bit of a hack in the requireNamespace(...) call(s) just before the actual fix, to make sure that the installed version of roxygen2 is up to date enough.  The hack is necessary because there is a discrepancy (bug), as at R3.1.2,  in the documentation of the versionCheck argument to loadNamespace, and hence to requireNamespace as well.  The bug has been accepted and I believe it will be fixed in a future release of R.\n(As an aside I believe there are some other gaps in the version checking that loadNamespace does of required packages - but that's a story for another place and day).\nThe remainder of the code is a testthat to make sure that the insertion of update_collate into the load_all code is having the desired effect for packages where there are @includes in the code.  For extra security I should probably also have added add some tests that this change does not break packages where there are no @includes - but I know those checks were part of the upgrade to roxygen2.\nHappy to react to any comments, suggestions or other feedback.\nHope this is useful\nGeoff\nPS I almost wonder whether roxygen2 should be upgraded from suggests to imports (even if only a few functions are @importFromed into the NAMESPACE file) but I don't really know enough about the rationale for choosing suggests over imports for roxygen2 in this case to make a strong argument for the change. \n. Temporarily close this pull request while I bring my forked copy of devtools up to date with the latest official development version of devtools \n. Hi @hadley \nAs promised yesterday.\nThis pull request contains a test_that load_all processes files in the correct collate order.\nIt also contains a fix for load_all itself, so that after roxygen2::update_collate has created/refreshed the collate order in the DESCRIPTION file, the pkg$collate entry in the pkg structure (list) is also refreshed - and hence load_all passes the test  :-).\nFinally, I have taken the liberty of adding a check that the version of roxygen2 is up to date, since if it is not, the older version of update_collate messes up packages which use a manually created Collate entry.  I found out the hard way that this is particularly nasty since the place where I have found most manually generated collate entries is in dummy packages in test_that s - and if the collate entry is altered unintentionally, the test no longer does what it did when it was first coded :-( .  The version check is a bit ugly, since there is a bug in the current version of R (3.1.2) which I have been told will be fixed in the next release.  If you'd like me to remove or adjust this version check, just say.\nPS The explicit version check seems to be necessary since R 3.1.2 (on my Windows machine) only does version checks on imports packages when it comes across a reference to them in the NAMESPACE file, and roxygen2 does not appear in the devtools NAMESPACE file, since devtools uses the roxygen2::etc  syntax.\nGeoff\n. Correction to\n~~The version check is a bit ugly, since there is a bug in the current version of R (3.1.2) which I have been told will be fixed in the next release.~~ \nI have tidied up the versionCheck code after reading through the bug fix in R itself, and figuring out that the code I had originally written was more elaborate than needed.\n. Hi @hadley \nMany thanks for looking over this testCollateOrder pull request so quickly.\nI've removed the message from the test_that, and deleted the explicit version check on roxygen2.  \nI am still nervous about deleting the roxygen2 version check, because although I cannot build devtools with an outdated version of roxygen2, I can install it in a library which has an outdated version of roxygen2 and run it with that outdated version.  I can supply an example if that would be useful.  It is because of a bug (OK perhaps a design feature) in how base R (as at 3.1.2) does (or doesn't do) dependency checks on Imports packages (dependency checks are only applied to DESCRIPTION file Imports packages which are also mentioned in the NAMESPACE file).  I'll accept whatever you decide is best, of course :-)\nGeoff\n. Sure, no worries.  Makes sense as a strategy to me.\nI have tried raising the issue on the R-Bugs site, but I don't think I'll get a reaction.  I need (lots!) more skill to write concise but helpfully precise bug reports.  I'll get better.\nKeep up the great work on devtools (and all the other packages).  I really appreciate it (and am learning heaps from seeing your 'style')\nGeoff\nPS The pull request already has the workaround removed\n. Ooops sorry for wasting your time @hadley.  I never thought to check what read.dcf was doing, and I should have :-(\nThanks for sorting this out.\n. I'm very much a novice, and largely a spectator/learner rather than a contributor, but for what It's worth, I agree, especially if pull request #649 (or a variant thereof) is accepted to fix an issue with load_all and S4 classes (basically insert a call to roxygen2::update_collate() into load_all to ensure the collate order is up to date so that S4 classes with inheritance split across several .r files are loaded in the intended order).  That would make roxygen2 essential for (yet) another core function of devtools.\n. PS : The following is perhaps a bit esoteric, but the behaviour had me puzzled for quite a while, so I'll mention it in case it help others avoid the pitfall I encountered, while I was experimenting with forked copies of devtools and roxygen2.\nIf you want the version of roxygen2 to be checked when devtools is loaded, you have to ...\n(Even) if you have devtools import roxygen2, the version of roxygen2 specified in the DESCRIPTION file will not necessarily be checked automatically (as at R version 3.1.2) when devtools is loaded if you use the roxygen2::some_roxygen2_function syntax.\nIf you want the version of roxygen2 to be checked you have to either:\n- Continue to explicitly check it in the devtools code using  requireNamespace(\"roxygen2\", versionCheck = list(op = \">=\", version = \"x.y.z\")) i.e the same as you would while roxygen2 is a Suggests dependency,  or\n-  Either\n  - @import roxygen2 or\n  -  @importFrom roxygen2 at_least_one_roxygen2_function\nThis is because loadNamespace  reads the version constraints on Imports package dependencies (eg roxygen2) when it processes the DESCRIPTION file for the package it is loading (eg devtools),\nbut\n it does not check the version constraints until it is processing the NAMESPACE file.  \nIf you have used the devtools::some_function syntax throughout devtools (ie you do not mention roxygen2 in an @import or an @importFrom ) there will be no mention of  roxygen2 in the NAMESPACE file, and hence no version checking will be done.\nPPS It is possible that using library(devtools) (which is what most users are likely to do) gets around this, because library does some extra version checking of its own (I think - I haven't worked through this closely)\nPPPS As at R 3.1.2 you actually have to use requireNamespace(\"roxygen2\", versionCheck = list(name = \"roxygen2\", op = \">=\", version = \"x.y.z\")), because there is a discrepancy between the documentation for loadNamespace (and requireNamespace) and the actual code - but I understand this will be fixed in a future release of R\n. Hi @renozao \nAs the original author of the pull request, I feel slightly responsible for your problem, and would like to see if I can contribute to a solution.  I don't have any experience running parallel jobs in R though.  It would help me understand better if you could describe the workflow where devtools is used in parallel jobs on the same package.  Like @gaborcsardi , I understand devtools is to be used during development, and I can't quite see how that can be done in parallel.  But as I said, I have no experience with parallel processing, so I may be missing something obvious.\nPS Your philosophy of keeping the concepts of the packages separate has some attractions to me, but there are things that devtools can't properly do unless it refreshes the DESCRIPTION and NAMESPACE files based on the roxygen2 comments in the packages R files (at least that's what I've observed with my own experiments, while trying to become totally roxygen based for developing my own package)\n. Thanks.  I'll have to think a bit.\nThe problem I was having is that underneath the hood, document uses load_all --- it needs to source the R code, or (as load_all does) load the result of running it into an environment / namespace, so that roxygen2  has the information it needs about the package when running the roclets.  And if the Collate order in the DESCRIPTION file was wrong, then load_all didn't work, so document didn't work, so load_all didn't work, so ...\nI was enormously confused when it first happened to me because I resorted to commenting out new bits of my code to try and track down the error - at some stage document would suddenly work - which would fix the collate entry (which I didn't realise) - once my code was working I removed the comments, one by one, and then got all the way back to my original code - which suddenly was fine :-(\n'nuff of my issue, I'll have a think about your problem.\n. Hi @renozao \nI agree with @gaborcsardi about the dangers of running multiple R processes on the same directory.\nBut putting aside those reservations, I have created a branch in my forked (for my own learning and development) copy of roxygen2 which does what you suggested, ie only tries to rewrite the DESCRIPTION file if the collate entry has changed.  If you want to try it out, it is available at http://github.com/Geoff99/roxygen/tree/only-update-changed-collate\nYou'd have to download and install it from github (and probably, if you are using Windows as I do, you might have to restart your R session before it would be available).\nLet me know if you try it out and it does what you want.  It seems to work for me - but I'm not doing anything in parallel.\n. Hi @hadley \nAs the person who wanted (and still does) the update_collate addition so that document and load_all would work, I'm more than happy with that.  \nBased on my recent experiences, devtools / roxygen2  might well be OK with NAMESPACES already.  I make a lot of mistakes while I'm learning, but having messed up my NAMESPACES several times over the last few days (eg while I tried to figure out which imported package I was using it was that promoted assorted S3 generics to S4 status, so I could importFrom the right place to get rid of assorted warnings), I think devtools copes OK with NAMESPACE mistakes.  It will load_all and document (albeit with various grumbles), the resultant package just doesn't run quite properly, which trips up various test_thats which I am progressively building and tidying up, which tells me where to look to fix my own package up.  In short, the closer I approximate your recommended package development cycle, the better things work :-) many thanks.  (Of course tomorrow, I may well find a new and unusual way to break something).\nI'll wait to hear back whether my branch makes life easier for the use case that initiated this issue, before I even think about submitting a pull request..  It's only a few lines, but not as crisply elegant as I would like.  I'm not able to test it myself, and indeed, the more I thought about it, the harder I found it to think of how I might develop a reproducible parallel test_that anyway. And I am steadily becoming more of a fan of test_thats each day.  Even just thinking about what I want to test and in which order clarifies my thoughts about the structure of my own package.\n. > Even in plain R packages. E.g. if you export a new function via roxygen, then devtools will need to rewrite the  NAMESPACE  file, so there is a potential race condition if you do this from multiple R processes. The  NAMESPACE  file might get messed up\nHi @gaborcsardi .  I totally agree with you about the possibility of race conditions (even though I have never yet felt confident enough to try anything remotely parallel in R).\nUsing the default arguments in devtools::load_all() makes it ignore the NAMESPACE export definitions in order to make development work simpler.  So maybe (depending on the exact details of what is running in the parallel sessions, and how dependent they are on NAMESPACE imports --- versus say using the otherpkg::fun(...) approach) some races have been lost already, but the messed up NAMESPACE didn't break anything?  And if roxygen is being used to generate all the NAMESPACE contents, devtools will fix the NAMESPACE file for you automagically when the package is built and installed the traditional way anyway.\n. Hi @gaborcsardi \nI'm still getting up to speed on all this, but I think I read in Hadley's Advanced R book that only the base package itself is included in the chain of enclosing environments above a package's own namespace environment, and before the global environment, \"as a convenience\".  All the other recommended packages are on the search path, between the global environment and the empty environment (and hence subject to the vagaries of whatever a user has installed on their search path, and in which order, in a particular session).  If I understand properly, that would explain why it would be safer to @import or use the :: approach to calling those functions, pain though it is!\n. Hi @gaborcsardi \nI think we are all in violent agreement about what we need to do to be absolutely safe :-)\nI willingly confess I am vague about the difference between :\n- the base package (singular), \n- the base packages (plural), and \n- whatever the name is for the set of packages which are automatically attached between R_GlobalEnv and R_EmptyEnv in an interactive session of RStudio (and I suspect in normal R as well, though I use RStudio pretty well exclusively).\nso I have resorted to writing myself little recursive programs using parent.env to see what is actually where (now @wch has drawn my attention to pryr::parenvs() my life will be that bit easier - thanks!)\n. Hi @DarwinAwardWinner , Issue #623 should be fixed in the versions of devtools and roxygen2 your sessionInfo report mentions, so it's probably not that.  \nJust a guess - have you got #' @include filename.r type roxygen2 comments in your various files, to ensure that the collate sequence in the DESCRIPTION file is correct.  By default devtools loads files in alphabetical order of the filenames, which can lead to code being out of order and hence R may be trying to create a subclass before it knows about the superclass (if the correct collate order is not alphabetical). PS If you have manually entered the collate sequence in the DESCRIPTION file don't use the #' @include approach - it would wipe out all the manual entries :-(\nOr alternatively, if the missing superclass (BiocParallelParam) comes from another package, you might be missing an #' @importClassesFrom whateverpkg BiocParallelParam type statement.\nEmphasise these are both just guesses.  Hope they help though.\nPPS Both guesses wrong - sorry.  Just had a look at your github link and you have manually created  collate sequences in the DESCRIPTION file, which have BioParallelParam defined before BatchJobsParam.  Maybe something to do with the fact you have both Collate.unix and  Collate.windows entries is confusing devtools or roxygen2?  \nI'll have to leave this to someone more knowledgeable than me.\n```\nCollate.unix: AllGenerics.R BiocParallelParam-class.R ErrorHandling.R \n bpbackend-methods.R bpisup-methods.R bplapply-methods.R bpmapply-methods.R \n bpiterate-methods.R bpschedule-methods.R bpstart-methods.R bpstop-methods.R \n bpvec-methods.R bpvectorize-methods.R bpworkers-methods.R \n bpaggregate-methods.R bpvalidate.R SnowParam-class.R MulticoreParam-class.R \n register.R SerialParam-class.R DoparParam-class.R SnowParam-utils.R \n BatchJobsParam-class.R progress.R utilities.R unix/pvec.R\n unix/mclapply.R unix/zzz.R \nCollate.windows: AllGenerics.R BiocParallelParam-class.R ErrorHandling.R \n bpbackend-methods.R bpisup-methods.R bplapply-methods.R bpmapply-methods.R \n bpiterate-methods.R bpschedule-methods.R bpstart-methods.R bpstop-methods.R \n bpvec-methods.R bpvectorize-methods.R bpworkers-methods.R \n bpaggregate-methods.R bpvalidate.R SnowParam-class.R MulticoreParam-class.R \n register.R SerialParam-class.R DoparParam-class.R SnowParam-utils.R \n BatchJobsParam-class.R progress.R utilities.R windows/zzz.R \n```\n. ",
    "dslramsey": "Thanks.  That worked.  I was following the instructions in devtools/README\nand wasn't aware this was a CRAN package.  Might be worth updating the\nwindows section in README at least until the new version is pushed to CRAN\ncheers\nDave\nOn Thu, Aug 14, 2014 at 11:31 AM, Winston Chang notifications@github.com\nwrote:\n\nYou need to do install.packages('rstudioapi').\nAfter the next version of devtools is released to CRAN, hopefully we won't\nsee this issue come up again because that package will have already been\ninstalled.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/551#issuecomment-52133815.\n. \n",
    "MaryamIdris": "Hi Hadley, I apologize for delay I have been away. I've just installed Xcode and still getting the same error!!??!!\n. ",
    "grantbrown": "Well, I'm not sure of the details, but I believe at least some version of RCurl is generally distributed with R (I show version 1.95, but did not manually install the package). On the other hand, an installation of RCurl via install.packages on ubuntu-alike linux machines fails without the appropriate libcurl package. \nI'm working in two environments right now. First, my own laptop running Linux Mint. Second, some departmental linux machines. In both environments I received the following error while using install_github:\n\"Error in function (type, msg, asError = TRUE)  : \"\nI was able to resolve the problem on my laptop by installing the appropriate libcurl package and the newest version of RCurl. \nInstalling system level packages on the school machines, however, is not always an option, but I found that I could use install_git to bypass the error message. This tryCatch hack was the result, and it allowed me to install the rCharts library via devtools without libcurl. \nAs I said, there are probably better ways to accomplish this end, but this worked for me. \n. Yes, that was my experience, but re-installation of RCurl is not possible without installing libcurl, which is a system level package and requires administrative privileges. As \"install_git\" works without this requirement, it seems reasonable that \"install_github\" should be able to as well. \n. I never installed RCurl - I believe an older version was prepackaged with the R installation. This may be an issue which is specific to the r-base-core and r-base-dev packages on debian based linux distributions. \nI can assure you that \n```\n\ninstall.packages(\"RCurl\")\n```\n\nfails without first running something like:\nsudo apt-get install <insert libcurl package name here>\n. Fair enough, do you have any idea what the underlying cause might be? As far as I can tell, this issue should be duplicable for most Linux distributions.\n. ```\n\ninstall_github(\"ramnathv/rcharts\")\nInstalling github repo rcharts/master from ramnathv\nDownloading master.zip from https://github.com/ramnathv/rcharts/archive/master.zip\nError in function (type, msg, asError = TRUE)  : \ntraceback()\n13: fun(structure(list(message = msg, call = sys.call()), class = c(typeName,\n        \"GenericCurlError\", \"error\", \"condition\")))\n12: function (type, msg, asError = TRUE)\n    {\n        if (!is.character(type)) {\n            i = match(type, CURLcodeValues)\n            typeName = if (is.na(i))\n                character()\n            else names(CURLcodeValues)[i]\n        }\n        typeName = gsub(\"^CURLE_\", \"\", typeName)\n        fun = (if (asError)\n            stop\n        else warning)\n        fun(structure(list(message = msg, call = sys.call()), class = c(typeName,\n            \"GenericCurlError\", \"error\", \"condition\")))\n    }(77L, \"\", TRUE)\n11: .Call(\"R_curl_easy_perform\", curl, .opts, isProtected, .encoding,\n        PACKAGE = \"RCurl\")\n10: RCurl::curlPerform(curl = handle$handle, .opts = curl_opts$values)\n9: perform(handle, opts, body)\n8: make_request(\"get\", hu$handle, hu$url, config)\n7: GET(url, config)\n6: (function (url, name = NULL, subdir = NULL, config = list(),\n       before_install = NULL, ...)\n   {\n       if (is.null(name)) {\n           name <- basename(url)\n       }\n       message(\"Downloading \", name, \" from \", url)\n       bundle <- file.path(tempdir(), name)\n       request <- GET(url, config)\n       stop_for_status(request)\n       writeBin(content(request), bundle)\n       on.exit(unlink(bundle), add = TRUE)\n       install_local_single(bundle, subdir = subdir, before_install = before_install,\n           ...)\n   })(dots[[1L]][[1L]], dots[[2L]][[1L]], subdir = NULL, config = list(),\n       before_install = function (bundle, pkg_path)\n       {\n           desc <- file.path(pkg_path, \"DESCRIPTION\")\n           DESCRIPTION <- readLines(desc, warn = FALSE)\n           if (any(DESCRIPTION == \"\")) {\n               DESCRIPTION <- DESCRIPTION[DESCRIPTION != \"\"]\n           }\n           cat(DESCRIPTION, file = desc, sep = \"\\n\")\n           append_field <- function(name, value) {\n               if (!is.null(value)) {\n                   cat(\"Github\", name, \":\", value, \"\\n\", sep = \"\",\n                     file = desc, append = TRUE)\n               }\n           }\n           append_field(\"Repo\", conn$repo)\n           append_field(\"Username\", conn$username)\n           append_field(\"Ref\", conn$ref)\n           append_field(\"SHA1\", github_extract_sha1(bundle))\n           append_field(\"Pull\", conn$pull)\n           append_field(\"Subdir\", conn$subdir)\n           append_field(\"Branch\", conn$branch)\n           append_field(\"AuthUser\", conn$auth_user)\n       }, dependencies = TRUE)\n5: mapply(install_url_single, url, name, MoreArgs = list(subdir = subdir,\n       config = config, before_install = before_install, ...))\n4: install_url(conn$url, subdir = conn$subdir, config = conn$auth,\n       before_install = github_before_install, ...)\n3: FUN(\"ramnathv/rcharts\"[[1L]], ...)\n2: vapply(repo, install_github_single, FUN.VALUE = logical(1), username,\n       ref, pull, subdir, branch, auth_user, password, auth_token,\n       ..., dependencies = TRUE)\n1: install_github(\"ramnathv/rcharts\")\n```\n. \n",
    "gonike": "Running clusterEvalQ(cl, dev_mode()) right after cluster creation really does solve the problem. I'd just like to note that this isn't really a satisfying solution, since it would require the developer to maintain two distinct versions of a package: one for usage with devtools, and one for deployment. It would be really nice if this could be handled automatically by devtools.\n. ",
    "alejandrodumas": "You can can use it can is repeated 2 times\n. ",
    "jtr13": "Why? Isn't it more efficient to have the built vignettes on Github rather than use build_vignettes = TRUE w/ install_github()? More discussion here: https://github.com/STAT545-UBC/Discussion/issues/68. I'll trust your instincts.  So, to confirm, the right approach is to instruct users on Github to add build_vignettes = TRUE? Surprising this is rarely done, AFAIK.. Got it, thanks.  . ",
    "mbojan": "Nope, I was not. Indeed seems fixed in the development ver. Sorry!\n. I think it might be useful, e.g. if you clone an (almost) empty repository to create a package there. For example, when you clone a GitHub repository containing only README.md\n. ",
    "gennaro-tedesco": "Hi all,\nI am having the exact same issue as reported above, being unable to build the vignette index despite having the correct %\\VignetteIndexEntry{<my vignette title>}. \nRunning \n```\n\nbuild_vignettes()\nNULL\n```\n\nreturns a NULL value, nevertheless the vignette itself builds fine and there is no other warning of sort. \nIs there any other particular trick that can conflict with creating the vignette index?\nP. S. The package source codes can be found here: https://github.com/gennaro-tedesco/Rdice\n. ",
    "gunhanb": "Hi gennaro,\nI have exactly same problem, build_vignettes() returns NULL. And I searched a lot, but could not find any solution. \nWhen I use .Rnw file with knitr, it works. For this reason, I will use .Rnw (instead of .Rmd). \n. ",
    "muschellij2": "Getting NULL from build_vignettes can also happen when VignetteBuilder is not specified in the DESCRIPTION correctly. \nThis is because build_vignettes uses tools::pkgVignettes which uses tools::pkgVignettes which calls\nbuildPkgs <- loadVignetteBuilder(dir, mustwork = FALSE)\n    engineList <- vignetteEngine(package = buildPkgs)\nand if you have not specified VignetteBuilder then loadVignetteBuilder doesn't recognize knitr or rmarkdown and will simply return utils and that's why a Rnw works (since utils::Sweave is found).\nYou should be able to add\nVignetteBuilder: knitr\nto the DESCRIPTION and should be fine.. Thought this was fixed with 3.3.1 - it was not.\n. Adding bioc_packages: BiocInstaller worked:\nhttps://travis-ci.org/muschellij2/testmatrixstats/builds/142568390\nas well as use_bioc: true:\nhttps://travis-ci.org/muschellij2/testmatrixstats/builds/142569006\nAs I just want to check against CRAN (as these are all CRAN-based packages), I think just using use_bioc: true maybe the most appropriate.  I just have never run into biocViews causing a problem with installation because it has an inherent dependency of sorts on BiocInstaller though no packages in the installation actually depend on that package or any bioC packages\nThis should patch the issue discussed with @HenrikBengtsson for matrixStats, but I'd like to hear your thoughts about needing to add to the non-default .travis.yml (from use_travis()) for packages that do not depend on bioC, but have bioViews in DESCRIPTION.\n. Although this should be solved in future versions of matrixStats, this method did not seem to work for the following package based on the error:\nhttps://travis-ci.org/emsweene/oasis/builds/142846730#L1043\n. Thanks - I'll look into and close again.\n. OK thanks - remotes or ghit by any chance?\n. I agree, that is not always wanted as a permanent tempdir path.  Also, it needs to be reset before the R session starts.  Is there harm putting this in however?   \nI have a specific example that I need because CMake complains about the tempdir being too long to compile on Windows and liked this simple workaround. \nI'm teaching R right now so that may bleed over in the idea of making it \"too easy\" for a new user vs. them having to do the redefinition of TEMPDIR/TMP/etc in their environment variable.\n. Looks like devtools OSX has ERRORs: \nhttps://cran.r-project.org/web/checks/check_results_devtools.html\nhttps://www.r-project.org/nosvn/R.check/r-release-osx-x86_64/devtools-00check.html\nhttps://www.r-project.org/nosvn/R.check/r-oldrel-osx-x86_64/devtools-00check.html. ",
    "dill": "Ah, sorry, I didn't see this when I looked before. I just specify the release tag as the ref= arg or as part of the repo= arg.\nThanks! Sorry for taking up your time.\n. ",
    "hmalmedal": "I pushed an update.\n. ",
    "talgalili": "Sure:\n```\nTal@TAL-PC /d/Dropbox/aaaa good R code/AA - My packages/dendextend (master)\n$ git remote -v\ndendextend_github       https://talgalili:GITHUBPASSWORD@github.com/\ntalgalili/dendextend/ (fetch)\ndendextend_github       https://talgalili:GITHUBPASSWORD@github.com/\ntalgalili/dendextend/ (push)\n```\n. Thanks @gaborcsardi (I found that out today :) )\n\nMaybe it should be made clearer in the vignette.\nI do think it might be helpful to have a place to put it so that it could be also pushed to CRAN without extra hassle.\n. Hi Jim, thanks for the explanation.\nWould it be helpful if I would try to a PR with some of the text written here into the vignette? I believe there would be value in clarifying it a bit more for people who would read it in the future.\n\n. Yes, I read that - but it wasn't clear enough for me the first (or second) time I've read it.\nFor example, if I include ggplot2, that package is already on CRAN - so by that logic it should have been fine. I think an alternative way to write this would be:\n\"\nCRAN does not support the \"Remotes\" field. When submitting your package to CRAN, the \"Remotes\" field should first be removed from the DESCRIPTION file. This is because all of the package dependencies must also be available on CRAN. For this reason, release() will warn you if you try to release a package with a Remotes field.\n\"\nWhat do you think?\n. ",
    "matt32106": "some news:\ni managed to get working installs from github with the following\ninstall.packages('RJSONIO')\nand update packages\nlooks like some dependencies are not checked somewhere\nthanks for your code!\n. ",
    "bpbond": "Yes, thanks for the clarification. Updated issue description.\n. I agree that this doesn't warrant being in the release questions, but think it's good to at least note for the user when devtools creates an empty package structure.\n. See discussion above, in particular @barryrowlingson 's comment. No, it's not automated.\n. ",
    "sanmai-NL": "It's a bit anglocentric to require this. But it is currently possible to convert titles to title case using tools::toTitleCase. Have you automated this check and/or and fix yet?\n. I would like to bring this issue up again. I do not see a very strong case to deviate the R versioning scheme from Semantic Versioning 2.0.0, given that the R-exts documentation seems compatible with this widely adopted standard. \nFirst of all, currently the initial version as prescribed in the development guide appears to be:\nVersion: 0.1\nAlthough there is indeed a deviation between SemVer and R's treatment of\n``` R\npackage_version(\"0.1.0\") < package_version(\"0.1.0-9000\")\n> [1] TRUE\n```\nThis can be easily circumvented using a default initial version of\n``` R\npackage_version(\"0.1.0-2\") < package_version(\"0.1.0-1\")\n> [1] FALSE\n```\n@hadley, you wrote at the time that SemVer is only for released versions. However, SemVer 2.0.0 states: \n\nMajor version zero (0.y.z) is for initial development. Anything may change at any time. The public API should not be considered stable.\n\nI don't believe that R versioning must necessarily be out of step with conventions for general purpose programming languages. For e.g. Python, some deviation happens for PEP 0440 compliance. But if there is a lack of such a standardized convention in R, then I would suggest that the example DESCRIPTION and devtools take the SemVer compatible default of 0.1.0 instead of 0.1.\nThe practical benefit: such an improvement allows you to refer your readership and user base to SemVer, if they want to come to understand the logic of software versioning, even if they are R package developers not familiar with software engineering practices. That would encourage good package development practices, e.g. understanding the difference between essential quality levels of software and how to communicate them.\n. ",
    "Mullefa": "Sure: it may be that we are doing something incorrectly. \nWe have created a framework of packages at work for deploying R code (processes, packages and shiny apps) to production. One of these packages facilitates package management.\nGiven a project's private library, there is a function which uses the DESCRIPTION files to get the source code for each package. For CRAN-like repositories it works as you would expect: it uses the value of the Repository field to look up the appropriate url in the named vector returned by getOption(\"repos\").\nCurrently the function we use for deploying packages to our company repository uses the build() function defined above as part of the implementation, though it would be preferable if this was supported in devtools.\nIf you need more context (or are just interested), I can push the framework so it is available publicly.\n. For whatever reason this no longer seems to be an issue. \nOn a new environment, after installing devtools, I can open up a new R session, use:\nR\nhttr::set_config(httr::use_proxy(...))\nto set the proxy, then:\nR\ndevtools::install_github(\"hadley/dplyr\")\ninstalls dplyr and all its dependencies. Nice! :)\n. Sure thing. Have you got any preference for their names? GITHUB_PAT and GITHUB_PAT_ENT? \n. Here is the issue:\nI'm on a server which is on the same network as my company github. This means that to install a package P from my company github using install_github() a proxy can't be set.\nHowever, lets say the packages (on CRAN) for which P depends are not installed. Then the call to install_github() will fail unless I set the argument dependencies = TRUE. However, with dependencies = TRUE, this results to a call to install.packages() which will hang because a proxy hasn't been set.\nThe situation is even worse because of the following: \nSay I have started an R session on the server where a proxy hasn't been set in the parent environment. Then calls to install.packages(...) and install_github(..., host = \"api.github.com\") will hang.\nIf I use httr from within R to set the proxy then calls to install_github(..., host = \"api.github.com\") will now work, however, calls to install.packages(...) will still hang - presumably because install.packages() isn't using the functions in httr. \nAs an initial step towards this problem, I think it would be good to create a new function install_package() - like install.packages(), but uses the functions in httr to download the relevant source code from CRAN.\nAs a second step, it would be great to have an option to pass httr::use_proxy() to the install functions in devtools, so that the proxy is set at the function level. \nUltimately, I would love a package which can replicate the behaviour of pip for python. To this end I have set up a spike called installr.\nCheers, and keep up the good work :)\n. ",
    "matthieugomez": "I've emailed you the output of devtools::release\n. @briencj does --as-cran use the cran version of packages that a package imports and not the local version? Or are you talking about something else.\n. ",
    "zhilongjia": "@wch Thank you. it works after deleting the *.o files in github. Concerning the  lazy-load database error, it should be the reason of no restart.\n. ",
    "hofnerb": "I am not completly sure what happens in revdep_check(pkg = \"somepackage\") .\nAre you using the currently installed version of somepackage or is the package also downloaded from CRAN? And/or can I specify a path to the package instead of the package name (as in other devtools functions such as check) and run the reverse check on this package?  I think the documentation should clarify these issues.\nEDIT: I now do understand that revdep_check() needs to access CRAN in order to determine the reverse dependencies. However, I think one could add this to the manual (and the question which version of somepackage is used in this check stays open).\n. Great, thank you very much!\n. ",
    "etheleon": "gives the following when i try to run setup\nError: 'setup' is not an exported object from 'namespace:devtools'\n``` r\nsessioninfo()\nR version 3.1.1 (2014-07-10)\nPlatform: x86_64-apple-darwin13.1.0 (64-bit)\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.9.0 colorout_1.0-3\nloaded via a namespace (and not attached):\n[1] bitops_1.0-6   httr_0.6.0     RCurl_1.95-4.5 stringr_0.6.2  tools_3.1.1 \n```\n``` r\n\ndevtools::session_info()\nSession info-------------------------------------------------------------------\n setting  value                     \n version  R version 3.1.1 (2014-07-10)\n system   x86_64, darwin13.1.0      \n ui       X11                       \n language en_US.UTF-8               \n collate  en_US.UTF-8               \n tz       Asia/Singapore              \n\nPackages-----------------------------------------------------------------------\n package    * version  date       source                          \n bitops       1.0.6    2013-08-17 CRAN (R 3.1.0)                  \n colorout   * 1.0.3    2014-10-16 Github (jalvesaq/colorout@98d5fd7)\n devtools   * 1.9.0    2015-07-09 Github (hadley/devtools@2881db5)\n httr         0.6.0    2014-12-13 CRAN (R 3.1.2)                  \n RCurl        1.95.4.5 2014-12-06 CRAN (R 3.1.2)                  \n rstudioapi   0.3.1    2015-04-07 CRAN (R 3.1.3)                  \n stringr      0.6.2    2012-12-06 CRAN (R 3.1.0)                  \n```\n. edited my previous post. \n. reinstalling from CRAN resolved the error. \n. ",
    "paolocrosetto": "Hey wch, thanks for your reply.\nI get his (weird) result when I call unzip:\n\ngetOption(\"unzip\")\n[1] \"\"\n\nlooks like something is indeed amiss...\n. ",
    "jennybc": "The recent conversation probably already reminded you ...\nYou probably commented this out because pushing and/or setting tracking branches with git2r is not completely sorted out yet: https://github.com/ropensci/git2r/issues/133, https://github.com/ropensci/git2r/issues/116, https://github.com/ropensci/git2r/issues/152. FWIW I am using v0.11.0 of git2r and have still not managed to set the upstream remote with code like you've got above. Caveat: I'm using https. Maybe the alleged fix only applies to ssh?\n. Thanks @stewid for the explicit example using cred_env()! I will try that.\nI guess my hope was that my cached credentials that allow other pushes to \"just work\", from command line git or RStudio or SourceTree, would get picked up by git2r.  I have no idea if that is even realistic.\n. @stewid Can you help me out here?\nI use git2r::branch_set_upstream() inside use_github() which was merged above.\nI usually use https and can affirm that all is well with use_github(..., protocol = \"https\").\nBut the default protocol is ssh.\nI've now set up SSH keys in order to test use_github(..., protocol = \"ssh\") and I get an error from git2r::branch_set_upstream(). Specifically, I get Failed to authenticate SSH session: Callback returned error. I can demonstrate all of this, including in a pure git2r example that has nothing to with devtools.\nBefore I go there ...\nIn your example above, are you using an SSH key without a passphrase? Or is your passphrase kept in a keychain or some such and git2r/libgit2 is able to access it? Because it's clearly not going into the credential object and that seems to be my problem. I can rescue things IFF I provide a passphrase.\nWondering if my ssh setup is somehow deficient or are we going to have handle the SSH passphrase somehow?\n. OK here is the threatened/promised reprex. I assume you both use ssh? Like all the time? And your key has a passphrase? What happens for you?\n``` r\npath <- \"foo\"\ndir.create(path)\nrepo <- init(path)\nwriteLines(\"yada yada yada\", file.path(path, \"example.txt\"))\nadd(repo, \"example.txt\")\ncommit(repo, \"First commit message\")\n> [b3de976] 2015-09-10: First commit message\nreq <-\n  httr::POST(\"https://api.github.com/user/repos\",\n             config = httr::authenticate(Sys.getenv(\"GITHUB_PAT\"),\n                                         \"x-oauth-basic\", \"basic\"),\n             encode = \"json\",\n             body = list(\n               name = jsonlite::unbox(\"foo\"),\n               description = jsonlite::unbox(\"test branch_set_upstream\"),\n               private = jsonlite::unbox(TRUE)\n             ))\nhttr::http_status(req)\n> $category\n> [1] \"success\"\n>\n> $message\n> [1] \"success: (201) Created\"\nhttr::content(req)$ssh_url\n> [1] \"git@github.com:jennybc/foo.git\"\nremote_add(repo, \"origin\", httr::content(req)$ssh_url)\ncred <- cred_ssh_key(\"~/.ssh/id_rsa.pub\", \"~/.ssh/id_rsa\")\npush(repo, \"origin\", \"refs/heads/master\", credentials = cred)\n> Error in .local(object, ...): Error in 'git2r_push': Failed to authenticate SSH session: Callback returned error\ncred <- cred_ssh_key(\"~/.ssh/id_rsa.pub\", \"~/.ssh/id_rsa\", \"\")\npush(repo, \"origin\", \"refs/heads/master\", credentials = cred)\nbranch_get_upstream(head(repo))\n> NULL\nbranch_set_upstream(git2r::head(repo), \"origin/master\")\nbranch_get_upstream(head(repo))\n> [b3de97] (origin @ git@github.com:jennybc/foo.git) master\n```\nIn use_github() I use GITHUB_PAT and https to push, so the ssh error first arises on branch_set_upstream(). But the above makes the point that I can't complete the set up w/o providing the passphrase. And yes git push works when I use git from the command line: ssh-agent is configured properly and I don't need to explicitly provide my passphrase.\n. OK yes that works. If I do the push via ssh, with a NULL credential object, I can subsequently set remote tracking branch. Sadly, the converse also true. I can ONLY set remote tracking branch with an ssh remote URL if I have previously pushed to said remote via ssh (not https). I can and will change use_github() logic to honor this requirement.\nIs it obvious that this should be the case? Is this what you mean by \"... and authentication with ssh key is ok\"? Does a successful ssh push create some persistent state in git2r that affects downstream commands with no explicit credentialling? This pre-requisite and the need to use NULL credentials if the SSH key has a passphrase would be great to document in git2r (unless that's well-known and I'm just learning hard lessons about git here).\nWhat's the intended workflow if public and private keys live in non-default location and we can't use NULL credentials?\n@hadley I will make a new PR shortly to deal with this.\n. All the checks I've ever done have been interactive. FWIW here they are anyway:\nWe run git config --global --list, which allows sanity check of user.name, user.email, and credential.helper. Note that I usually have students work with GitHub via https, at least at first, rather than fussing with the ssh keys. This requires a credential helper, so we use git --version to make sure it's 1.7.10 or newer. The advice on activating and initializing the credential helper varies by OS and I'm not sure if you even want to get into that.\nI think it's great for devtools to do a Git check-up! Other thoughts:\n- I've never used git2r but the cred_*() functions might be relevant to your support of ssh.\n- Telling user where Git lives is a useful thing, because sometimes they need to tell RStudio this explicitly: which git (*nix), where git (some Windows), whereis git.exe (some other Windows).\n- Checking that the Git executable is in PATH would also be a huge favour for novices.\n. FWIW, from reading Git docs and my own experience, it seems perfectly OK to create the .git/hooks subdirectory de novo and carry on.\n. I am happy either way. Was planning to PR this after the one other played itself out. This is much smaller thing.\n. Hey! Git Large File Storage (Git LFS) has reached a 1.0 milestone and is now available to all repositories on GitHub.com\nhttps://github.com/blog/2069-git-large-file-storage-v1-0\n. In addition to no API, I think for public repositories you have to choose between using LFS and using forks + pull requests? This was written in October 2015 -- I'm not sure if anything has changed for the better.\nGitHub\u2019s Large File Storage is no panacea for Open Source\u200a\u2014\u200aquite the opposite\n@mdlincoln I'm not sure what your large file problem is, but you might want to look at datastorr by @richfitz or the ideas there. From him I learned you can attach inconveniently large files to GitHub releases (and yet they don't live in your repo) and a lot of the normal GH limits don't apply. It seems too good to be true and I'm sure he can explain it better.\n. I'll work on your remaining comments and add examples/tests when back from camping.\n. Do you have a policy that you only test exported functions? Context: want to know if appropriate to write tests for uses_git(), uses_github(), github_info(), all of which are not exported. This is tempting because they can be tested without calling or mocking the GitHub API.\n. I will make a new PR shortly, where the above commits and more are squashed.\n. BTW GitHub recommends https over ssh: Which remote URL should I use?. I made \"ssh\" the default in use_github() because that's what you had before but would you consider making \"https\" the default?\nI would only need to invert order of default args for protocol in use_github(). Optionally, could also tweak dr_github(), which currently suggests that ssh > https.\n. use_travis() and use_appveyor() should probably call uses_github() early on to make a \"go\" / \"no go\" decision.\n. Yes, you're right @gaborcsardi. I was being sort of myopic: I just looked for instances of github_info() that weren't preceded by a test for GitHub usage. As it is, the messaging in these functions presupposes GitHub usage.\nLooking closer, use_coverage() is in the same boat.\nSo maybe the thing to do is to adjust the messaging if GitHub usage can or cannot be detected. Or just do nothing. Dummy values <USERNAME> and <REPO> aren't going to hurt anyone.\n. Thanks for the comments! Will act on them.\n. Thank you for your patience. I did as asked in all the comments. Highlights of changes and departures from initial PR message:\n- The scary github_delete_repo() function had been moved into test-github-connections.R. Has an improved check for repo existence and a commented-out interactive confirmation menu.\n- devtools preference for ssh protocol over https faithfully upheld.\n- New exported function use_github_links() does nothing if no GitHub connection detected and will not clobber existing entries in URL and BugReports fields of DESCRIPTION.\n- dr_github() diagnoses the lack of a GitHub connection, empty URL or BugReports, and lack of GitHub repo and issue links.\n- Functions use_travis(), use_appveyor(), and use_coverage() were not touched.\n- git2r version bumped to v0.11.0 and comments left where things can be made nicer when > v0.11.0 is on CRAN.\n. This last travis failure appears to just be bad luck, but I can't restart it. Successful build and test with previous commit.\n. Please see the revised tests. No more calls to the GitHub API and no git2r usage that actually hits a remote.\n. Yes re: NEWS but will be much later today. First day classes.\n. What IS the official party line on how to manage vignettes during development?\nIn your book, vignette workflow addresses the (ephemeral) preview. And development cycle gets at the other end ... when building and installing a package properly.\nWhat about the bit in the middle?\n. I'm thinking about the vignettes relative to what we do for roxygen comment / Rd file (and README.Rmd / README.md?).\nThe documentation workflow results in persistent help files you can preview in their natural habitat with ?. What's the equivalent for a vignette? The Cmd + Shift + K preview can be a drag because sometimes they take a long time to render.\nIt's not that I can't figure out how get a rendered vignette. It's about figuring out the most devtools-ish way to get and possibly hold on to them.\n. Everytime I get this message it means I have re-installed a package that is loaded in my current R session. So then I restart (like Hadley says) and it loads cleanly in the new session. I think this practically happens by definition whenever you install devtools from github?\n. OK so when that's merged the dependency on a dev/github version could be fully captured in DESCRIPTION? You won't have to change .travis.yml and you won't have to put something in a README.md that says, e.g., devtools::install_github(\"hadley/readr\"); devtools::install_github(\"jennybc/jane\")?\n. Yay it works! Thanks.\n. One last thing: the bit about the user getting the proper result with a simple devtools::install_github(\"jennybc/jane\") ... that will require that they have the post-merge dev version of devtools ... yes?\n. OK yes.\n. @daattali Maybe you should do similar for use_github()? It's also silent when it does nothing.\nRight here:\nhttps://github.com/hadley/devtools/blob/81dd313e1d143a3bdaaa2e1f09c887801db66694/R/infrastructure-git.R#L84-L85\n. > This way a source file never needs to know where it is relative to the root of a package. \nSlightly off-topic but .. if only something this sane could be used in an RStudio project that isn't an R package .... rstudioapi::project_file()?\n. This happens when the package uses Git but ~~not GitHub~~ does not have a remote tracking branch. You can reproduce it like so:\nr\nlibrary(git2r)\nlibrary(devtools)\ntpath <- tempfile(\"devtools\")\ncreate(tpath)\ninit(tpath)\nrelease(tpath)\nI am about to submit a fix.\n. What @gaborcsardi says will definitely happen (.git will be Rbuildignored). I wrestle with this elsewhere and can't necessarily use @jimhester's bare repo solution. You know how you can invert gitignores with !? Is there anything like that but for Rbuildignore? So you can Rbuild-UN-ignore things instead of fiddling with the names? I can't find any evidence of such but hope I am just missing something.\n. Do you think it's obnoxious to also open it in the browser, e.g. if (interactive()) browseURL(create$html_url)? I have something that does that with new repos and it's quite gratifying.\n. For a github remote specifically, this is now a simple API call: https://developer.github.com/changes/2016-02-24-commit-reference-sha-api/.\n. Those tests look familiar to me ... @ijlyttle I sent you a PR that clears these warnings, if you wish to just fix as part of this.\n. It feels like part of the pain around test helpers is that they are used for setup but there's no similarly official way to do corresponding tear down. I have a faux test file named test-zz-clean-up.R that does this. Is that awful?\n. OK this will be very specific. But I remove an OAuth token from an environment internal to the package. I delete some local files. I delete some things from Google Drive.\n. Is there something like on.exit() in this context?\n. Wish I'd thought of that. OK I upgraded w/ your regex and dropped perl = TRUE.\n. Bullet added (and rebased).\n. I've always found the gh-pages branch approach awkward, as it seems optimized to make it hard to see everything you need to see at once when troubleshooting. I prefer the location based approach in docs/.\n. OK good point. So any GHE solution needs to not make github.com API calls impossible or extremely awkward. Too bad .Renviron doesn't work more like .gitconfig, i.e. you get union of local and global settings.\n. Nice! So maybe I will try some variation on your solution for a while.\n. Trying naming this file LICENSE without any extension.\n. That's odd. I am able to reproduce your warning in a successfully-building package by renaming the extra MIT license file to LICENSE.txt. But it also generates a NOTE about a non-standard file/directory LICENSE.txt. You don't get this note?\n```\nStatus: 1 WARNING, 1 NOTE\nchecking DESCRIPTION meta-information ... WARNING\nInvalid license file pointers: LICENSE\nchecking top-level files ... NOTE\nNon-standard file/directory found at top level:\n  \u2018LICENSE.txt\u2019\n```\nCheck .Rbuildignore. Is there's something there that's causing your license file to be ignored?\n. This chunk might also be nice in a new vignette, but that is currently initialized via rmarkdown::draft(), so easier said than done. Maybe it could be added to the html_vignette template over there?. Pretty much! But it would follow devtools naming conventions ... maybe use_cran_canonical()? And possibly just use message() to print something to screen, the way many other infrastructure helpers advise you on what to do next. Alternatively, it would be nice to put the canonical URL on the clipboard but I don't think that Rubicon has been crossed yet in devtools.\n. Somehow I missed the above question. Typical scenario: you are working on package A and want to mention + link to package B and as a matter of policy you've decided to use canonical CRAN links everywhere.\nIt is truly a very minor thing, so drop it if you like. If it survives, it would be nice if available in a workflow package that one is willing to load in all interactive sessions via .Rprofile.. It would be interesting if the stuff people put in the usual badges was actually machine readable. It's so close already.. I have used http://www.repostatus.org badges to annotate stuff that is not yet on CRAN or might never to go CRAN. The idea also seems useful at the other of the life cycle.. Thanks @jimhester that DOES allow me to accept the certificate. Well, not really \"accept\". There was nothing interactive about it, but it seems to have accomplished what was needed.\nBut the installation of MeasurementError.cor still fails, like so:\n``` r\n\ninstall_bioc(\"MeasurementError.cor\", quiet = FALSE)\nDownloading Bioconductor repo MeasurementError.cor\n/usr/bin/svn co --username readonly --password readonly https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/MeasurementError.cor /var/folders/vt/4sdxy0rd1b3b65nqssx4sx_h0000gn/T//RtmpYiFiBW/file434665cdf239\nInstalling MeasurementError.cor\n'/Library/Frameworks/R.framework/Resources/bin/R' CMD INSTALL '/private/var/folders/vt/4sdxy0rd1b3b65nqssx4sx_h0000gn/T/RtmpYiFiBW/file434665cdf239' \nInstallation failed: argument is of length zero\n``. It is true that the package was not being downloaded. So I did the svn / certificate stuff above. All seemed to be successful and yes there was interactive acceptance this time. Yes/tmp/test` contains the checked out version of MeasurementError.cor.\n\nHowever I was getting the exact same failure with install_bioc(\"MeasurementError.cor\", quiet = FALSE), interactively and with Check in RStudio build pane.\nI note that if I change the library paths in this test, I can pass tests now:\n``` r\nbefore\n.libPaths(lib)\nafter\n.libPaths(c(lib, libpath))\n```\n. No, that does not fix it. Possibly relevant: I don't allow anything but the base and Recommended packages to live in my default library. Is it possible you have more there?. Then I get this, since devtools itself cannot be found:\n```\njenny@2015-mbp devtools $ R --vanilla -e 'devtools::test()'\nR version 3.3.1 (2016-06-21) -- \"Bug in Your Hair\"\nCopyright (C) 2016 The R Foundation for Statistical Computing\nPlatform: x86_64-apple-darwin13.4.0 (64-bit)\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\nNatural language support but running in an English locale\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\ndevtools::test()\nError in loadNamespace(name) : there is no package called \u2018devtools\u2019\nCalls: :: ... tryCatch -> tryCatchList -> tryCatchOne -> \nExecution halted\n```\n\nI think we are on to something w/r/t me because I have other problems with devtools tests depending on how I run them and they are all plausibly related to library paths.. For example, here what I get with devtools::test() in the R console (with the modified lib path in the BioC test):\n``` r\n\ntest()\nLoading devtools\nTesting devtools\nbioc: ..............\nCheck: ....\ngetrootdir: ..\ngit: ....\ngit usage and GitHub connections: ................................\nGitHub: ........................\nInfrastructure: ...................\nInstall specific version: ......\nInstall: ..\nremote-metadata: .....\nremote_deps: .......................12.3\nsort: ...\nTest: ..\nUninstall: ..4\nupdate.package_deps: ...\nVignettes: .......................\n...\n\nFailed ----------------------------------------------------------------------\n1. Failure: package2remotes looks for the DESCRIPTION in .libPaths (@test-remotes.r#79) \npackage2remote(\"testTest\")$sha not equal to NA.\n1/1 mismatches\nx[1]: \"0.1\"\ny[1]: NA\n\n\nFailure: package2remotes looks for the DESCRIPTION in .libPaths (@test-remotes.r#80) \npackage2remote(\"testTest\")$sha not equal to NA.\n1/1 mismatches\nx[1]: \"0.1\"\ny[1]: NA\n\n\nFailure: package2remotes looks for the DESCRIPTION in .libPaths (@test-remotes.r#89) \npackage2remote(\"testTest\")$sha not equal to NA.\n1/1 mismatches\nx[1]: \"0.1\"\ny[1]: NA\n\n\nError: uninstall() unloads and removes from library (@test-uninstall.r#20) \nthere is no package called \u2018testHelp\u2019\n1: uninstall(\"testHelp\", quiet = TRUE) at /Users/jenny/rrr/devtools/tests/testthat/test-uninstall.r:20\n2: remove.packages(pkg$package) at /Users/jenny/rrr/devtools/R/uninstall.r:27\n3: find.package(pkgs, lib)\n4: stop(gettextf(\"there is no package called %s\", sQuote(pkg)), domain = NA)\n\n\nDONE ========================================================================\n```\nThe same tests fail via R CMD check and Rscript -e 'devtools::test(\"devtools\")', but pass cleanly via Rscript -e 'devtools::check(\"devtools\")'.\nI can take this to a different issue or slack if you want? As I think we have resolved the Bioconductor issue (sort of).. So is a proper svn setup absolutely necessary to test the BioC functionality in devtools?. Yes. Maybe we can discuss briefly today.. > This almost feels too big to be a vignette to me. Maybe it would be better off as a smaller bookdown site?\nSure. It will be miserable as an actual vignette anyway, for all the usual reasons.\nSo I should make it a standalone repo + website within r-lib? Plus its companion repo, where an example package gets built.. It sounds like a version problem with git2r. Try updating that.. @jimhester helped me work through a lot of related misunderstandings recently here, in case it's a helpful read:\nhttps://github.com/r-lib/pkgload/issues/56. If you want the latest release, why install it from github vs from CRAN via install.packages()? In theory GitHub releases and CRAN releases don't have to coincide but they often do.. > I placed Rtools above git in my PATH and that fixed this error (didn't know that order mattered)\nI'm surprised you don't have PTSD from this re: STAT 545!. This is in the CRAN submission section at the end of the vignette.\n\nWhen you submit your package to CRAN, all of its dependencies must also be available on CRAN. For this reason, release() will warn you if you try to release a package with a Remotes field.. You might be better off to conditionally execute the code in that vignette based on, say, an env var that you set when conditions are favorable. Put something like this in a setup chunk:\n\nr\nSPARK <- identical(tolower(Sys.getenv(\"SPARK\")), \"true\")\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\",\n  purl = SPARK,\n  eval = SPARK\n). True. Is this package already on CRAN or destined for that? I find the entire workflow around vignettes painful if they have special requirements and shouldn't be rebuilt casually. There are various workarounds in order to \"pre-compile\" vignettes, so you may need to go that route. Even if build_vignettes() became more flexible, it won't solve the problem re: CRAN.\nIf you think you might make a package website with pkgdown, you could turn this spark vignette into a non-vignette article and wash your hands of the problem. That is what I plan to do from now on for vignettes that require auth tokens, for example.. For the future, usethis::use_vignette() is a handy function to initiate a new vignette and it gets all this fiddly stuff set up for you.. Also related: the RStudio > Build > Check workflow. Results in that case are extra vulnerable to deletion, because (quoting @hadley)\n\nRStudio build pane which runs R in a new session, and the default location is a session specific temporary directory which is deleted when that process ends. Thanks. I'm glad I asked!. I already did this once. Did this check go missing?\n\nhttps://github.com/r-lib/devtools/pull/1043. You can only have the Remotes field in DESCRIPTION while you are in a development state.\nExactly how are you running R CMD check? If you run with --as-cran, I would expect this error, because you can't submit a package to CRAN with this field.. Also, this has nothing to do with the remotes R package, so you should remove that addition from Suggests, in any case.. Nothing on CRAN can depend on a non-CRAN, i.e. development, version of another package.\nSo, yes, ggExtra should appear in Imports but with a minimum version that is actually available on CRAN.\nYes, you must remove the Remotes field from your DESCRIPTION.. So is there any reason to have remotes in one's .Rprofile now? Is there any function there that we like better for any reason than its counterpart in some other package, mainly devtools, I suppose?\nIt's all a bit foggy now, but I think remotes::install_github() was, at some point, the reason I put remotes in .Rprofile and I placed it after devtools, so masking it. If I want cutting edge r-lib, should I revert this?. OK I am going to revert to devtools for my non-utils::install.packages() package installation needs. And will speak up if I notice something that was good about remotes that should be brought into devtools or pkgman.. I can convince myself either way, but The Great Devtools Breakup certainly feels like a good time to clean out the proverbial closet.. To record this thought from group meeting: I'm not sure how important it is to make the index available this way. From the roxygen workflow, I am already accustomed to the idea that I must properly build and install to have my docs fully \"wired up\", e.g. all links working. I am prepared to accept the analogous limitation for vignettes.. I am finding that I need this PR in order for devtools::document() to do the right thing with roxygen2 v6.1.0. Specifically, without this PR, re-document()ing after changing a function signature does not, in fact, cause the corresponding change in the .Rd. The signatures appear to persistently derive from the installed version, as opposed to current source.\nHere's what happens if you create a new package with usethis::create_package() and add an exported, roxygen-documented function (but you never install the package):\n```\n==> devtools::document(roclets=c('rd', 'collate', 'namespace'))\nUpdating aabb documentation\nFirst time using roxygen2. Upgrading automatically...\nWriting NAMESPACE\nError in as.environment(where) : using 'as.environment(NULL)' is defunct\nCalls: suppressPackageStartupMessages ... block_find_object -> object_from_call -> parser -> exists\nExecution halted\nExited with status 1.\n```\nA different consequence of this PR that might be undesirable is that the helpers = FALSE behaviour (in the sense of load_all(pkg$path, helpers = FALSE)) has been lost. Is that worth taking a stand on?. I think this is still worth pondering but I guess it's a roxygen2 matter now (?):\n\nA different consequence of this PR that might be undesirable is that the helpers = FALSE behaviour (in the sense of load_all(pkg$path, helpers = FALSE)) has been lost. Is that worth taking a stand on?. \"Everything after zoo\" is the final column in the 4-column data frame that devtools::session_info() reports (package, version, date, source).. This PR should probably be made against usethis, instead of or in addition to devtools.. Also related to how hard it is to nuke the appveyor cache: https://github.com/krlmlr/r-appveyor/issues/98.\n\nAlthough I understand that @schloerke's goal is related to auto-invalidation, not manual.. Let's also remember that we are only talking about the default template that we fling out into the world. Any individual can enact non-default treatment, in which case this discussion could be summarized in some documentation, to raise awareness of alternatives.. This error sounds a lot like: #1900 install_github() gives Error in read.dcf(path) \nThe resolution reached there is to update the remotes package, where this may have been fixed. The fix is currently only in the dev version, so you'd need to to devtools::install_github(\"r-lib/remotes\").. OK great, so this is a duplicate of #1900.. E and E<- (the assignment form) are two different functions.\nhttps://github.com/cran/igraph/blob/88642b96a3ba8576df72405008c8f5ffea6cefba/NAMESPACE#L106\nversus\nhttps://github.com/cran/igraph/blob/88642b96a3ba8576df72405008c8f5ffea6cefba/NAMESPACE#L96\nAre you sure you are importing both?. > devtools already does attach usethis when you attach devtools\nAHA! I didn't delve deeply enough to see this and attributed some of my local phenomena to the fact that I always have usethis attached (at least in interactive sessions). OK thanks I think I know how to talk/write about this now.. > I think adding a quiet argument to document is the best option.\nI started descending down that ladder and it's not going to be easy because the lower-level functions generally don't have a switch for verbosity.. This is because the CRAN macOS machine either has no Pandoc or has a rather ancient Pandoc.. This has already been reported and fixed in the dev version of devtools.\nhttps://github.com/r-lib/devtools/issues/1909. This is what devtools::load_all() does. And yes it is indeed incredibly handy during development!. This looks like a pull request made in error.. The question of rendering README has come up before and I'd agree that, yeah, it has never been fully resolved, from a workflow point of view.\nbuild_readme() is helpful, but it's still not wired into anything automatic, like document().\nRelated issue:\n\n\n1762 Do something about README.Rmd --> README.md . The way I select the single remote URL to send to github_remote_parse() will always select the one named \"origin\" if such exists. Among remote URLs that contain \"github\", we prioritize remotes according to name like so: take \"origin\" ... or \"github\" ... or \"upstream\" ... or whatever's left.\n\n\nWould you just rather keep the hard requirement that the primary github remote be named \"origin\"?\n. ok I removed this comment and revert to plain old git2r::remote_url() since names will not be vetted\n. good point\ndone\n. done (and yes, response after successful deletion is empty)\n. I check for dummy info because use_github_links() will dutifully insert placeholder links, even if GitHub remote can't be detected. It felt like good citizenship to build in a check for this weird state. No I cannot imagine anyone doing this on purpose!\nGood point re: also checking for empty Url and BugReports. Will add.\n. Yes, I imagine so. Currently DESCRIPTION say git2r (>= 0.10.1) but I am working against 0.11.0 from CRAN and suspect this actually matters.\nIn fact, you might want git2r to have a CRAN release before you merge this. There are at least 2 changes in v0.11.0.9000 that were prompted by issues I opened and that, if exploited, would make this code cleaner. Notes mostly for me:\n- Ability to edit a remote's URL (https://github.com/ropensci/git2r/commit/26276693ab80d7cce4171786f04c467c66f7d079) vs. delete it then add it back\n- New credential method that works with PAT only (https://github.com/ropensci/git2r/commit/a91a716fc6d7bcc7177e7bdbd942ff646f960f72) vs dummy email/username and PAT as password\n. I'm moving it into the test file, where it is used and makes it reasonably available for development.\n. I just learned, with some pain, that if you send an empty email, git2r::push() hangs the R process (and RStudio somehow can't recover). I'll bring that up over in git2r. But for now I'm going with EMAIL = \"EMAIL\" here. Once git2r updates, we can use the new git2r::cred_token() and will no longer need to provide dummy email.\n. I cannot promise that v0.11.0 is necessary, though suspect it is. I will check with v0.10.0.\n. Now that I've moved github_delete_repo() out of the package, I could actually put this function back as I found it. This was only necessary because the content of the response after successful deletion is empty and jsonlite::fromJSON(\"\") errors. But apparently that has never been a problem before.\n. YES git2r must be >= 0.11.0. Otherwise cred_env() is not exported and we are unable to establish push to Github. And if you can't push, you can't set the remote tracking branch.\n. I set it to TRUE when I check locally, because I'm happy for my GITHUB_PAT to be used for tests of GitHub connectivity.\nIn theory, I change it back to FALSE every time I push, because devtools doesn't have an encrypted GITHUB_PAT env var on Travis yet.\nIn reality, I forget and have to make even more commits :(\n. Should I write a version of that file that has zero ambitions to actually do anything on GitHub?\n. :flushed: \n. This seems to come from @family infrastructure vs @rdname infrastructure, plus re-roxygenizing? Not sure which you prefer. Affects use_build_ignore(), use_data(), use_package(), use_readme_rmd().\n. OK rebased now, so it's just my proposed changes.\n. @hadley would you like same thing done for use_github()?\n. or even \"happy\"?\n. I am glad to pick up this pattern: how to reveal default args in signature and use match.arg(), while not necessarily defaulting to the first element.. The exact thing just came up in usethis re: incrementing versions. It make sense to have \"major\", \"minor\", \"patch\", \"dev\", in that order. But in the absence of explicit info ... you probably don't want to increment the major version (in fact, we don't increment at all in that case). Also, I like revealing the possible values in the signature vs. documentation.. This installs current dev version to a temporary library that is used just to render the vignette, right? I believe this happens elsewhere too now (README?), so it would be good to nail the wording and use in all places. Specifically, IIUC, the installation referred to here does not affect one's normal library and has no persistent effect. It makes the dev state of vignettes and README more parallel to docs below man/.. Is this expected?. Good point re: pkgdown. Some of my vignette whining may no longer relevant. If I have a balky vignette (takes a non-trivial amount of time to render, calls internet, needs auth, etc.), I would turn it into an article now.\nThat just transfers some whining from devtools to pkgdown \ud83d\ude05 but I still think lowers the overall amount of pain. Why? Because pkgdown is designed to make the built product (the site) constantly available, whereas the official vignette workflow is much more tied to an official build/release event.. ",
    "stewid": "I have managed to add an existing project to GitHub using SSH and https with v0.11.0 of git2r. \n``` r\nlibrary(git2r)\nAdd an existing project to GitHub using SSH and git2r. Create a new\nrepository on GitHub before running the following R code.\n1) Create a new repository\nrepo <- init(\"test-01\")\n2) Add 'README.md' to local repository\nadd(repo, \"README.md\")\n3) Commit staged 'README.md'. Add sessionInfo to commit message\ncommit(repo, message = \"Initial commit\", session = TRUE)\n4) Add URL for the remote repository\nremote_add(repo, \"origin\", \"git@github.com:stewid/test-01.git\")\n5) Create SSH credentials\ncred <- cred_ssh_key(\"~/.ssh/id_rsa.pub\", \"~/.ssh/id_rsa\")\n6) Push changes in local repository to GitHub\npush(repo, \"origin\", \"refs/heads/master\", credentials = cred)\n```\n``` r\nlibrary(git2r)\nAdd an existing project to GitHub using https and git2r. Create a\nnew repository on GitHub before running the following R code.\n1) Create a new repository\nrepo <- init(\"test-02\")\n2) Add 'README.md' to local repository\nadd(repo, \"README.md\")\n3) Commit staged 'README.md'. Add sessionInfo to commit message\ncommit(repo, message = \"Initial commit\", session = TRUE)\n4) Add URL for the remote repository\nremote_add(repo, \"origin\", \"https://github.com/stewid/test-02.git\")\n5) Create credentials from environmental variables\ncred <- cred_env(\"GITHUB_USER\", \"GITHUB_PAT\")\n6) Push changes in local repository to GitHub\npush(repo, \"origin\", \"refs/heads/master\", credentials = cred)\n```\nsessionInfo:\n``` r\nR version 3.2.2 RC (2015-08-08 r68921)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 14.04.3 LTS\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C            \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8  \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8 \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C               \n [9] LC_ADDRESS=C               LC_TELEPHONE=C          \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] git2r_0.11.0\n```\n. I have done more testing on other platforms with git2r v0.11.0 to push a local repository to GitHub.\n| R version | Platform | Protocol | Repository |\n| --- | --- | --- | --- |\n| 3.2.2 RC | x86_64-pc-linux-gnu (64-bit) | SSH | test-01 |\n| 3.2.2 RC | x86_64-pc-linux-gnu (64-bit) | https | test-02 |\n| 3.2.0 | x86_64-apple-darwin13.4.0 (64-bit) | SSH | test-03 |\n| 3.2.0 | x86_64-apple-darwin13.4.0 (64-bit) | https | test-04 |\n| 3.1.1 | i386-pc-solaris2.10 (32-bit) | SSH | test-05 |\n| 3.1.1 | i386-pc-solaris2.10 (32-bit) | https | test-06 |\n| 3.2.2 | x86_64-w64-mingw32/x64 (64-bit) | SSH | test-07 |\n| 3.2.2 | x86_64-w64-mingw32/x64 (64-bit) | https | test-08 |\n. Hi @jennybc, I'm testing, will return in a moment.\n. > In your example above, are you using an SSH key without a passphrase?\nYes\n\nOr is your passphrase kept in a keychain or some such and git2r/libgit2 is able to access it?\n\nNo\n\nI can rescue things IFF I provide a passphrase\n\nGreat\n\nI assume you both use ssh?\n\nYes, I use ssh\n\nLike all the time?\n\nYes\n\nAnd your key has a passphrase?\n\nYes, but I did not use keys with a passphrase in the example above.\n\nThe ssh-agent method is only used if the credentials is NULL and authentication with ssh keys is ok.\nhttps://github.com/ropensci/git2r/blob/master/src/git2r_cred.c#L232\n Skip the credentials argument in git2r to use the ssh-agent.\npush(repo, \"origin\", \"refs/heads/master\")\nDoes that work?\n. > Is this what you mean by \"... and authentication with ssh key is ok\"?\nFor operations that might need credentials, e.g. push, git2r supplies the callback function git2r_cred_acquire_cb to libgit2. If the remote host requires authentication in order to connect to it, the callback git2r_cred_acquire_cb is called from libgit2.  One argument to this function is the allowed credential type. If that argument says that it's OK with ssh keys but no credentials object was supplied to the  operation, than git2r instructs libgit2 to try the ssh-agent for the keys.\n\nDoes a successful ssh push create some persistent state in git2r that affects downstream commands with no explicit credentialling?\n\nNo\n\nThis pre-requisite and the need to use NULL credentials if the SSH key has a passphrase would be great to document in git2r\n\nThe reason for NULL credentials is not about the passphrase. It tells git2r to tell libgit2 to try to get the keys from the ssh-agent. I will improve the documentation.\n\nWhat's the intended workflow if public and private keys live in non-default location and we can't use NULL credentials?\n\nTo use the git2r cred_ssh_key function.\n@jennybc thanks for your feedback. Much of this functionality is very recently implemented in git2r, your testing and suggestions to improve workflow and documentation are much appreciated.\n. I have not set a date, but git2r v 0.11.0 was released only 27 days ago.\n. @jimhester and @hadley I'm working on a new release https://github.com/ropensci/git2r/issues/191\n. @krlmlr  Looks fine :+1: . I have added the is_branch method to git2r https://github.com/ropensci/git2r/commit/a5e65c3d52337f910dbdfbb22c7b54cf418473b0\nI suggest that you add n = 1 in c1 <- git2r::commits(r, n = 1)[[1]]\nhttps://github.com/krlmlr/devtools/blob/feature/git-detached/R/git.R#L32 to avoid listing all commits\n. Maybe it calls the C function callback git2r_cred_acquire_cb over and over again?  @krlmlr if you can reproduce the issue, could you please add a break point or a print statement to explore what happens in\nhttps://github.com/ropensci/git2r/blob/master/src/git2r_cred.c#L217\n. I'm able to reproduce the issue and I will try to fix it the tomorrow.\n. Ok, I was able to reproduce the hang, both inside RStudio and on a regular console, with a call to fetch over ssh (git@github.com:ropensci/git2r.git) on a ubuntu 17.04 machine with git2r v0.19. The hang occurred after I turned off the SSH key agent and used a SSH key with a passphrase. The git2r\ninternal callback to create credentials for the remote host authentication was then called over and over again. I have changed the callback in https://github.com/ropensci/git2r/commit/e289c233968d130098ca0bb68925f30244d297d3 to signal an error instead of trying again if the authentication failed the first time.\n. @hadley the SSH key passphrase is an argument to the cred_ssh_key function (https://github.com/ropensci/git2r/blob/master/R/credential.r#L139). If the passphrase is required but missing, it prompts the user with the getPass package (if it's installed).\n@krlmlr I noticed that git2r::fetch(r, git2r::branch_remote_name(upstream)) in https://github.com/hadley/devtools/blob/b05bd25c63690e1b61d978888c298c7b19aacbe4/R/git.R#L25-L59 does not pass credentials to git2r.. Maybe the transition of S4->S3 in git2r on CRAN should be a three-step process.  i) identify all slots that are used directly in packages and add an accessor function for each of them, for example, sha. ii) release a new S4 version of git2r on CRAN with those accessor functions. iii) About a month later, release the new S3 version of git2r.\n. @hadley thanks for the advice. I have found six reverse dependency packages on CRAN using @ mostly @sha. Maybe it's better to synchronize an update on CRAN. I'm not sure when I'm ready with a release candidate.  At the moment git2r does not build on CRAN because of library dependencies on github e.g. libssh2 . ",
    "wilkinson": "My bad, I should have checked first -- this is already included in a different pull request.\n. ",
    "lcolladotor": "Aye, Dan Tenenbaum made a similar remark on the other site (see here). \nI realize that Martin Morgan edited his earlier comment. He wanted to refer to the parallel package, not base. So I'll edit the subject here.\nYou covered parallel in your list, so I'll leave it up to them to reply about it. Maybe there's a use case they have in mind where what you said doesn't hold. But given that install.packages('parallel') fails on R 3.1.2 and 3.2 I have a hard time coming up with one.\n. ",
    "mtmorgan": "My confusion started because parallel was not reported at all (I've revised my original post, empowered by the ability to change the past ;) ). It seems useful to indicate the full user session, including base packages (since both R [thinking of the methods package and Rscript] and the user can do all kinds of funky things, including starting R with no packages other than 'base') and especially base packages like parallel that are not loaded by default in a factory-fresh installation. Also, the user could install an arbitrary version of parallel in their R library directory. Hopefully that utils::sessionInfo() doesn't report versions of these packages is not compelling!\n. Hi @jimhester I (continue) to think that the certificate is valid but that the CA certificate bundle @jennybc (and other Mac users?) have does not recognize the authority. I'm told that a slightly less heavy-handed solution is to delete ~/.subversion/auth/svn.ssl.server and then manually accept (permanently) as above svn list --username readonly --password readonly https://hedgehog.fhcrc.org/bioconductor/branches/RELEASE_3_4/madman/Rpacks maybe substituting --username with a valid svn username.\n. Two comments, but more from the outsider perspective as I don't know what @jennybc or devtools are trying to accomplish. Bioc packages are distributed in CRAN-style repositories, so svn is only required for source code access. The appropriate repositories for the version of R in use is given by\nsource(\"https://biocondcutor.org/biocLite.R\")\nBiocInstaller::biocinstallRepos()\nOne could then use this as an argument to install.packages() / devtools::install() or ignore the explicit need to specify repository with biocLite() (which installs Bioconductor, CRAN [via install.packages()] and github [via delegation to devtools] packages). The title for install_bioc() (\"Install a package from a Bioconductor repository\") is  ambiguous, since there are CRAN-style 'repositories' (used in install_cran()) and source control repositories (like github or svn); Bioconductor hosts both. Also, Bioconductor has (and correct functionality depends on) a particular versioning system, and it is inappropriate for instance to install the current svn 'trunk' packages on the current release version of R. BiocInstaller and our repositories enforce this system, but devtools::install_github() will lead to invalid installations.\nMaybe slightly less satisfactory is github.com/Bioconductor-mirror and branches @release-3.4, etc. which can be accessed as, e.g., devtools::install_github(\"Bioconductor-mirror/\"). Unsatisfactory because parts of the mirror are sometimes out of sync with svn, and because svn is really the cannonical source code repository for Bioconductor packages.\nSee also https://github.com/hadley/devtools/issues/1240. See other uses of sQuote in R/utils.r. I don't really know what that means; is devtools::install_bioc() no longer supported? If so, please mark it as such? . ",
    "brauner": "Adding a missing dependency resolved the issue.\n. ",
    "franc00018": "use  options(unzip = 'internal')\n. ",
    "sthesing": "Thanks! That did the trick! Sorry for overlooking #467. \n. ",
    "plantarum": "Fixed, thanks!\nI had only r-omegahat-rcurl, which got pulled in as a dependency of r-cran-devtools. I removed r-cran-devtools and all its dependencies (including r-omegahat-rcurl), which were installed from the Debian repositories, then reinstalled devtools from CRAN directly : install.packages(\"devtools\", dependencies = TRUE). Now all is well. It's very cool to be able to distribute my package via github now!\nBest,\nTyler\n. Apparently I can't. I'm not familiar with the continuous-integration checks, but it appears I've broken something to do with the code that tests the help files? I don't see anything obviously connected to this in the three files I've changed in this pull request?\n. I just tried installing the zip file directly and got the same problem, so the problem is probably not with devtools itself?\ninstall.packages(\"C:/Users/jamest/Downloads/flowPloidy-master.zip\", repos = NULL, type = \"win.binary\")\nError in install.packages : cannot open file 'C:/Users/jamest/Documents/R-3.3.2/library/file4e4c8cc0b/flowPloidy-master/R/FlowHist.R': No such file or directory. ",
    "prise6": "Hi, i don't know if this bug was fixed in later versions but it's still there for R 3.2.0.\nFYI, same issue with: \n```\n\ndevtools::session_info()\nSession info ----------------------\n setting  value                     \n version  R version 3.2.0 (2015-04-16)\n system   x86_64, linux-gnu         \n ui       RStudio (0.99.902)        \n language (EN)                      \n collate  fr_FR.UTF-8               \n tz       Europe/Paris\n```\n. \n",
    "madwsa": "Was able to build in my environments with PR merged in.  Thank you!\n. ",
    "VUarrota": "Afternoon,\ni have installed it via Rstudio. the sessioninfo and the error are attached\n```\nsessionInfo()\nR version 3.1.2 (2014-10-31)\nPlatform: i386-w64-mingw32/i386 (32-bit)\nlocale:\n[1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252 \n[3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C                    \n[5] LC_TIME=Portuguese_Brazil.1252    \nattached base packages:\n[1] grid      stats     graphics  grDevices utils     datasets  methods\n[8] base     \nother attached packages:\n [1] MALDIquant_1.11         baseline_1.1-3          hyperChemoBridge_1.1.3 \n [4] hyperSpec_0.98-20140523 mvtnorm_1.0-2           devtools_1.6.1       \n [7] R.utils_1.34.0          R.oo_1.18.0             R.methodsS3_1.6.1    \n[10] gsubfn_0.6-6            proto_0.3-10            IDPmisc_1.1.17       \n[13] lattice_0.20-29         ChemoSpec_2.0-2        \nloaded via a namespace (and not attached):\n [1] amap_0.8-14           bitops_1.0-6          chemometrics_1.3.8 \n [4] class_7.3-11          cluster_1.15.3        colorspace_1.2-4   \n [7] DEoptimR_1.0-2        digest_0.6.6          e1071_1.6-4        \n[10] gclus_1.3.1           GGally_0.5.0          ggplot2_1.0.0      \n[13] gtable_0.1.2          httr_0.6.0            MASS_7.3-35        \n[16] mclust_4.4            munsell_0.4.2         mvoutlier_2.0.5    \n[19] nnet_7.3-8            pcaPP_1.9-60          pls_2.4-3          \n[22] plyr_1.8.1            RColorBrewer_1.1-2    Rcpp_0.11.3        \n[25] RCurl_1.95-4.5        reshape_0.8.5         reshape2_1.4.1     \n[28] rgl_0.95.1158         robCompositions_1.9.0 robustbase_0.92-2  \n[31] rpart_4.1-8           rrcov_1.3-8           scales_0.2.4       \n[34] seriation_1.0-14      sgeostat_1.0-25       som_0.3-5          \n[37] SparseM_1.05          stats4_3.1.2          stringr_0.6.2      \n[40] tcltk_3.1.2           tools_3.1.2           TSP_1.0-9   \nlibrary(devtools)\n\ninstall_github(repo = \"Chathurga/HyperChemoBridge\",ref = \"devel\")\nDownloading github repo Chathurga/HyperChemoBridge@devel\nInstalling hyperChemoBridge\n\"C:/PROGRA~1/R/R-31~1.2/bin/i386/R\" --vanilla CMD INSTALL  \\\n  \"C:\\Users\\Virg\u00edlio\\AppData\\Local\\Temp\\Rtmp868HrV\\devtools12a06e423309\\Chathurga-HyperChemoBridge-5e993b4\"  \\\n  --library=\"C:/Users/Virg\u00edlio/Documents/R/win-library/3.1\" --install-tests \n\n\ninstalling source package 'hyperChemoBridge' ...\nWarning in file(file, ifelse(append, \"a\", \"w\")) :\n  cannot open file 'C:/Users/Virgmlio/Documents/R/win-library/3.1/hyperChemoBridge/DESCRIPTION': No such file or directory\nError in file(file, ifelse(append, \"a\", \"w\")) : \n  cannot open the connection\nERROR: installing package DESCRIPTION failed for package 'hyperChemoBridge'\nremoving 'C:/Users/Virg\u00edlio/Documents/R/win-library/3.1/hyperChemoBridge'\nError: Command failed (1)\n```\n. \n",
    "oscardelama": "I guess you mean the dev version of devtools. Am I right? If so, where I get that? I have perused the branches names and \"http://r-pkgs.had.co.nz/release.html\" without success.\nPerhaps you should mention this requested info in \"http://r-pkgs.had.co.nz/release.html\", where I took the suggestion about using devtools::use_readme_rmd(), but where nothing is said about this function not being neither in the CRAN version nor here.\nI wish you a happy new year!\n. ",
    "sharmak": "Here is my latest commit to solve the problem. https://github.com/sharmak/devtools/commit/c933038592eb49046cdd8c121161479b6d7c5cbd\n. ",
    "Thrianadh": "Use a proxy to connect to the internet.\nUse the Package httr\nlibrary(\"httr\")\nset_config(use_proxy(\"abcd.com\",port = 8080, username = \"*\", password=\"**\"))\nits worked for me. ",
    "timothyslau": "Windows 7 Enterprise SP1 & if I run it on Mac OSX 10.10 I get:\n\nError in structure(as.daxmlToList(xmlParse(response, asText = TRUE)),  :\ncould not find function \"as.daxmlToList\"\n. Updated packages & tried:\nsource_gist(\"https://gist.github.com/jmcastagnetto/2253d846af1c60f5c0da\")\n\nGot:\nSourcing https://gist.githubusercontent.com/jmcastagnetto/2253d846af1c60f5c0da/raw/2869a425de08ed70b743e424023ae17fe79268cd/nist-beacon-response.R\nSHA-1 hash of file is eeb9a91d9e3c46d96e0da51c22b6f81aaf9e9c1c\nError in function (type, msg, asError = TRUE)  : \n  SSL certificate problem: unable to get local issuer certificate\nClicked \"Show Traceback\" & got:\n11 fun(structure(list(message = msg, call = sys.call()), class = c(typeName, \n    \"GenericCurlError\", \"error\", \"condition\"))) \n10 function (type, msg, asError = TRUE) \n{\n    if (!is.character(type)) {\n        i = match(type, CURLcodeValues) ... \n9 curlPerform(curl = curl, .opts = opts, .encoding = .encoding) \n8 getURL(url, headerfunction = headers$update) at C:\\Users\\t0lau001\\AppData\\Local\\Temp\\RtmpeyFTvT\\file17d811f1783f#15\n7 NISTBeaconResponse(ts) at C:\\Users\\t0lau001\\AppData\\Local\\Temp\\RtmpeyFTvT\\file17d811f1783f#49\n6 eval(expr, envir, enclos) \n5 eval(ei, envir) \n4 withVisible(eval(ei, envir)) \n3 source(temp_file, ...) \n2 source_url(url, ..., sha1 = sha1) \n1 source_gist(\"https://gist.github.com/jmcastagnetto/2253d846af1c60f5c0da\") \n. This might be an issue with the Gist code rather than source_gist I'm not sure how to tell.\n. Scratch that, It is an issue with the gist, not source_gist. Sorry to bother you.\nAlthough, if you had a fix for the function it would be appreciated ;)\n. Linux vs Windows issue apparently ;(\nhttps://gist.github.com/jmcastagnetto/2253d846af1c60f5c0da\n. ",
    "PeteHaitch": "This works fine for me; can you please provide a reproducible example of when it's not working for you?\nDoes the following work for you?\nr\ndevtools::install_github('PeteHaitch/BioCpkgA')\nIt should install a toy package BioCpkgA whose only dependency is GenomicTuples, which is available via Bioconductor and not CRAN.\n``` r\nMy sesion info\ndevtools::session_info()\nSession info ---------------------------------------------------------------------\n setting  value                     \n version  R version 3.1.2 (2014-10-31)\n system   x86_64, darwin10.8.0      \n ui       RStudio (0.99.234)        \n language (EN)                      \n collate  en_AU.UTF-8               \n tz       Australia/Melbourne         \nPackages -------------------------------------------------------------------------\n package       * version  date       source                            \n Biobase       * 2.26.0   2014-10-14 Bioconductor                      \n BiocGenerics  * 0.12.1   2014-11-14 Bioconductor                      \n BioCpkgA        0.1      2015-03-02 Github (PeteHaitch/BioCpkgA@26d12ba)\n bitops        * 1.0-6    2013-08-17 CRAN (R 3.1.0)                    \n devtools      * 1.7.0    2015-01-17 CRAN (R 3.1.2)                    \n GenomeInfoDb  * 1.2.4    2014-12-19 Bioconductor                      \n GenomicRanges * 1.18.4   2015-01-07 Bioconductor                      \n GenomicTuples * 1.0.0    2014-10-14 Bioconductor                      \n httr          * 0.6.1    2015-01-01 CRAN (R 3.1.2)                    \n IRanges       * 2.0.1    2014-12-12 Bioconductor                      \n packrat       * 0.4.3    2015-01-29 CRAN (R 3.1.2)                    \n Rcpp          * 0.11.4   2015-01-24 CRAN (R 3.1.2)                    \n RCurl         * 1.95-4.5 2014-12-06 CRAN (R 3.1.2)                    \n rstudioapi    * 0.2      2014-12-31 CRAN (R 3.1.2)                    \n S4Vectors     * 0.4.0    2014-10-14 Bioconductor                      \n stringr       * 0.6.2    2012-12-06 CRAN (R 3.1.0)                    \n XVector       * 0.6.0    2014-10-14 Bioconductor\n``\n. Hmm, yes there does seem to be a problem. I just tried on a fresh installation of R 3.2 and confirmed thatdevtools::install_github('PeteHaitch/BioCpkgA')` doesn't work unless GenomicTuples is first installed via  \nr\nsource(\"http://bioconductor.org/biocLite.R\")\nbiocLite(\"GenomicTuples\")\nor BiocInstaller::biocLite('GenomicTuples') (if BiocInstaller is already installed).\nI thought this used to work (i.e., in R 3.1), but I may be mistaken.\nI won't have time to look into this until next week at the earliest, possibly the following week. \n``` r\nSession info with BioC release\n\ndevtools::session_info()\nSession info ---------------------------------------------------------------------\n setting  value                     \n version  R version 3.2.0 (2015-04-16)\n system   x86_64, darwin13.4.0      \n ui       RStudio (0.99.235)        \n language (EN)                      \n collate  en_AU.UTF-8               \n tz       Australia/Melbourne         \n\nPackages -------------------------------------------------------------------------\n package       * version  date       source      \n BiocInstaller   1.18.1   2015-04-17 Bioconductor\n bitops        * 1.0-6    2013-08-17 CRAN (R 3.2.0)\n devtools      * 1.7.0    2015-01-17 CRAN (R 3.2.0)\n httr          * 0.6.1    2015-01-01 CRAN (R 3.2.0)\n RCurl         * 1.95-4.5 2014-12-28 CRAN (R 3.2.0)\n rstudioapi    * 0.3.1    2015-04-07 CRAN (R 3.2.0)\n stringr       * 0.6.2    2012-12-06 CRAN (R 3.2.0)\nSession info with BioC devel, i.e., following BiocInstaller::useDevel(TRUE)\n\ndevtools::session_info()\nSession info ---------------------------------------------------------------------\n setting  value                     \n version  R version 3.2.0 (2015-04-16)\n system   x86_64, darwin13.4.0      \n ui       RStudio (0.99.235)        \n language (EN)                      \n collate  en_AU.UTF-8               \n tz       Australia/Melbourne         \n\nPackages -------------------------------------------------------------------------\n package       * version  date       source      \n BiocInstaller   1.19.3   2015-04-20 Bioconductor\n bitops        * 1.0-6    2013-08-17 CRAN (R 3.2.0)\n devtools      * 1.7.0    2015-01-17 CRAN (R 3.2.0)\n httr          * 0.6.1    2015-01-01 CRAN (R 3.2.0)\n RCurl         * 1.95-4.5 2014-12-28 CRAN (R 3.2.0)\n rstudioapi    * 0.3.1    2015-04-07 CRAN (R 3.2.0)\n stringr       * 0.6.2    2012-12-06 CRAN (R 3.2.0)\n```\n. Very happy to see this being worked on! (And sorry I haven't made any progress myself) \nOne question, Jim: are you proposing that dependencies that are from the Bioconductor devel branch are installed from the Bioconductor-mirror github repo rather than using BiocInstaller::useDevel(TRUE); BiocInstaller::biocLite(\"pkg\")? The issue I see there is that those packages available from the Bioconductor-mirror repo aren't guaranteed to pass R CMD build/check since they haven't been run through the BioC build system. Apologies if I've misunderstood.\n. Awesome! I thought so (given the code) but your example confused me. Cheers.\n. Appveyor failure seems unrelated to PR. ",
    "nsheff": "This example does not work for me:\n```\ndevtools::install_github('PeteHaitch/BioCpkgA')\nDownloading github repo PeteHaitch/BioCpkgA@master\nInstalling BioCpkgA\nInstalling dependencies for BioCpkgA:\nGenomicTuples\nInstalling package into \u2018/home/nsheffield/R\u2019\n(as \u2018lib\u2019 is unspecified)\n'/usr/lib/R/bin/R' --vanilla CMD INSTALL  \\\n  '/tmp/Rtmp6GpfdN/devtools194d288e6252/PeteHaitch-BioCpkgA-26d12ba'  \\\n  --library='/home/nsheffield/R' --install-tests \nERROR: dependency \u2018GenomicTuples\u2019 is not available for package \u2018BioCpkgA\u2019\n* removing \u2018/home/nsheffield/R/BioCpkgA\u2019\n```\nIf I first install GenomicTuples, then it works:\n```\ndevtools::install_github('PeteHaitch/BioCpkgA')\nDownloading github repo PeteHaitch/BioCpkgA@master\nInstalling BioCpkgA\n'/usr/lib/R/bin/R' --vanilla CMD INSTALL  \\\n  '/tmp/Rtmp6GpfdN/devtools194d690d04ab/PeteHaitch-BioCpkgA-26d12ba'  \\\n  --library='/home/nsheffield/R' --install-tests \n\ninstalling source package \u2018BioCpkgA\u2019 ...\n R\n preparing package for lazy loading\n** help\n installing help indices\n* building package indices\n testing if installed package can be loaded\nDONE (BioCpkgA)\n```\n\nHere is a package of mine with the same issue: https://github.com/sheffien/LOLA\nIt will not download and install IRanges, for example.\n```\ndevtools::session_info()\nSession info -------------------------------------------------------------------\n setting  value                     \n version  R version 3.2.0 (2015-04-16)\n system   x86_64, linux-gnu         \n ui       X11                       \n language en_US                     \n collate  en_US.UTF-8               \n tz        \nPackages -----------------------------------------------------------------------\n package       * version  date       source      \n BiocInstaller   1.19.3   2015-04-21 Bioconductor\n bitops        * 1.0-6    2013-08-17 CRAN (R 3.2.0)\n devtools      * 1.7.0    2015-01-17 CRAN (R 3.2.0)\n httr          * 0.6.1    2015-01-01 CRAN (R 3.2.0)\n RCurl         * 1.95-4.5 2014-12-28 CRAN (R 3.2.0)\n rstudioapi    * 0.3.1    2015-04-07 CRAN (R 3.2.0)\n stringr       * 0.6.2    2012-12-06 CRAN (R 3.2.0)\n``\n.\"S4Vectors_defines.h\"` is in S4Vectors/include.  S4Vectors is included in the IRanges LinkingTo field.\nThe IRanges/include/IRanges_defines.h file refers to the \"S4Vectors/include/S4Vectors_defines.h\" file.\nI do have a custom .Rprofile, but if I remove it, I get the same error, so it's not related to any setting therein. Anyway, it doesn't do much: \nlocal({r <- getOption(\"repos\");\n       r[\"CRAN\"] <- \"http://cran.at.r-project.org\";   #AUSTRIA mirror\n       options(repos=r)})\nand then sets some options and defines a few functions\n. That appears to work:\ninstall_local(\"rpack/IRangeKernels/\")                                                                 \u2502\nInstalling IRangeKernels                                                                                \u2502\n'/usr/lib/R/bin/R' --vanilla CMD INSTALL  \\                                                             \u2502\n  '/tmp/RtmppbNynh/file8cc53934bb/IRangeKernels'  \\                                                     \u2502\n  --library='/home/nsheffield/R' --install-tests                                                        \u2502\n                                                                                                        \u2502\n* installing *source* package \u2018IRangeKernels\u2019 ...                                                       \u2502\n** libs                                                                                                 \u2502\nmake: Nothing to be done for `all'.                                                                     \u2502\ninstalling to /home/nsheffield/R/IRangeKernels/libs                                                     \u2502\n** R                                                                                                    \u2502\n** preparing package for lazy loading                                                                   \u2502\n** help                                                                                                 \u2502\n*** installing help indices                                                                             \u2502\n** building package indices                                                                             \u2502\n** testing if installed package can be loaded                                                           \u2502\n* DONE (IRangeKernels)\n. The dev version (of devtools) seems to have broken install_github() for me, for any package:\n```\nDONE (devtools)\nReloading installed devtools\n\ndevtools::install_github(\"hadley/devtools\")\nDownloading github repo hadley/devtools@master\nError: is.config(config) is not TRUE\ndevtools::install_github(\"sheffien/IRangesKernels\")\nDownloading github repo sheffien/IRangesKernels@master\nError: is.config(config) is not TRUE\n```\n\n```\ndevtools::session_info()\nSession info -------------------------------------------------------------------\n setting  value                     \n version  R version 3.2.0 (2015-04-16)\n system   x86_64, linux-gnu         \n ui       X11                       \n language en_US                     \n collate  en_US.UTF-8               \n tz        \nPackages -----------------------------------------------------------------------\n package       * version    date       source                        \n BiocInstaller   1.19.4     2015-04-24 Bioconductor                  \n bitops        * 1.0-6      2013-08-17 CRAN (R 3.2.0)                \n devtools        1.7.0.9000 2015-04-29 Github (hadley/devtools@dee7b74)\n digest        * 0.6.8      2014-12-31 CRAN (R 3.2.0)                \n httr          * 0.6.1.9000 2015-04-29 Github (hadley/httr@75aca2b)  \n knitr         * 1.10       2015-04-23 CRAN (R 3.2.0)                \n memoise       * 0.2.1      2014-04-22 CRAN (R 3.2.0)                \n RCurl         * 1.95-4.6   2015-04-24 CRAN (R 3.2.0)                \n rstudioapi    * 0.3.1      2015-04-07 CRAN (R 3.2.0)                \n stringr       * 0.6.2      2012-12-06 CRAN (R 3.2.0)              \n```\n. Ok, this solved the config error, but I'm still getting the original includes error:\n```\n\ndevtools::install_local(\"rpack/IRangeKernels\")\nInstalling IRangeKernels\n'/usr/lib/R/bin/R' --no-site-file --no-environ --no-save --no-restore CMD  \\\n  INSTALL '/tmp/RtmpmAMxQb/file387a7522d7d7/IRangeKernels'  \\\n  --library='/home/nsheffield/R' --install-tests \n\n\ninstalling source package \u2018IRangeKernels\u2019 ...\n libs\nmake: Nothing to be done for `all'.\ninstalling to /home/nsheffield/R/IRangeKernels/libs\n R\n preparing package for lazy loading\n help\n installing help indices\n* building package indices\n testing if installed package can be loaded\n\nDONE (IRangeKernels)\n\ndevtools::install_github(\"sheffien/IRangeKernels\")\nDownloading github repo sheffien/IRangeKernels@master\nInstalling IRangeKernels\n'/usr/lib/R/bin/R' --no-site-file --no-environ --no-save --no-restore CMD  \\\n  INSTALL  \\\n  '/tmp/RtmpmAMxQb/devtools387a678b6811/sheffien-IRangeKernels-8e77a03'  \\\n  --library='/home/nsheffield/R' --install-tests \n\n\n\ninstalling source package \u2018IRangeKernels\u2019 ...\n libs\ngcc -std=gnu99 -I/usr/share/R/include -DNDEBUG   -I\"/home/nsheffield/R/IRanges/include\"   -fpic  -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c R_init_IRangeKernels.c -o R_init_IRangeKernels.o\nIn file included from IRangeKernels.h:1:0,\n                 from R_init_IRangeKernels.c:1:\n/home/nsheffield/R/IRanges/include/IRanges_defines.h:18:31: fatal error: S4Vectors_defines.h: No such file or directory\n #include \"S4Vectors_defines.h\"\n                               ^\ncompilation terminated.\nmake: * [R_init_IRangeKernels.o] Error 1\nERROR: compilation failed for package \u2018IRangeKernels\u2019\n\nremoving \u2018/home/nsheffield/R/IRangeKernels\u2019\nrestoring previous \u2018/home/nsheffield/R/IRangeKernels\u2019\nError: Command failed (1)\ndevtools::session_info()\nSession info -------------------------------------------------------------------\n setting  value                     \n version  R version 3.2.0 (2015-04-16)\n system   x86_64, linux-gnu         \n ui       X11                       \n language en_US                     \n collate  en_US.UTF-8               \n tz        \n\n\n\nPackages -----------------------------------------------------------------------\n package       * version    date       source                        \n BiocInstaller   1.19.4     2015-04-24 Bioconductor                  \n bitops        * 1.0-6      2013-08-17 CRAN (R 3.2.0)                \n devtools      * 1.7.0.9000 2015-04-29 Github (hadley/devtools@1a80e3c)\n httr          * 0.6.1.9000 2015-04-29 Github (hadley/httr@75aca2b)  \n RCurl         * 1.95-4.6   2015-04-24 CRAN (R 3.2.0)                \n rstudioapi    * 0.3.1      2015-04-07 CRAN (R 3.2.0)                \n stringr       * 0.6.2      2012-12-06 CRAN (R 3.2.0)         \n```\n. I'm using the devel version, and IRanges was just a couple of days old:\nPackages -----------------------------------------------------------------------\n package       * version    date       source                          \n BiocGenerics    0.15.0     2015-04-21 Bioconductor                    \n BiocInstaller   1.19.4     2015-04-24 Bioconductor                    \n bitops        * 1.0-6      2013-08-17 CRAN (R 3.2.0)                  \n devtools      * 1.7.0.9000 2015-04-29 Github (hadley/devtools@1a80e3c)\n httr          * 0.6.1.9000 2015-04-29 Github (hadley/httr@75aca2b)    \n IRanges         2.3.2      2015-04-24 Bioconductor                    \n RCurl         * 1.95-4.6   2015-04-24 CRAN (R 3.2.0)                  \n rstudioapi    * 0.3.1      2015-04-07 CRAN (R 3.2.0)                  \n S4Vectors       0.7.0      2015-04-21 Bioconductor                    \n stringr       * 0.6.2      2012-12-06 CRAN (R 3.2.0)\nAfter BiocInstaller::biocLite():\nPackages -----------------------------------------------------------------------\n package       * version    date       source                          \n BiocGenerics    0.15.0     2015-04-21 Bioconductor                    \n BiocInstaller   1.19.4     2015-04-24 Bioconductor                    \n bitops        * 1.0-6      2013-08-17 CRAN (R 3.2.0)                  \n devtools      * 1.7.0.9000 2015-04-29 Github (hadley/devtools@1a80e3c)\n httr          * 0.6.1.9000 2015-04-29 Github (hadley/httr@75aca2b)    \n IRanges         2.3.3      2015-04-29 Bioconductor                    \n RCurl         * 1.95-4.6   2015-04-24 CRAN (R 3.2.0)                  \n rstudioapi    * 0.3.1      2015-04-07 CRAN (R 3.2.0)                  \n S4Vectors       0.7.0      2015-04-21 Bioconductor                    \n stringr       * 0.6.2      2012-12-06 CRAN (R 3.2.0)\nBut still no dice:\n```\ndevtools::install_github(\"sheffien/IRangeKernels\")\nDownloading github repo sheffien/IRangeKernels@master\nInstalling IRangeKernels\n'/usr/lib/R/bin/R' --no-site-file --no-environ --no-save --no-restore CMD  \\\n  INSTALL  \\\n  '/tmp/RtmpmAMxQb/devtools387a151ac68b/sheffien-IRangeKernels-8e77a03'  \\\n  --library='/home/nsheffield/R' --install-tests \n\ninstalling source package \u2018IRangeKernels\u2019 ...\n libs\ngcc -std=gnu99 -I/usr/share/R/include -DNDEBUG   -I\"/home/nsheffield/R/IRanges/include\"   -fpic  -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c R_init_IRangeKernels.c -o R_init_IRangeKernels.o\nIn file included from IRangeKernels.h:1:0,\n                 from R_init_IRangeKernels.c:1:\n/home/nsheffield/R/IRanges/include/IRanges_defines.h:18:31: fatal error: S4Vectors_defines.h: No such file or directory\n #include \"S4Vectors_defines.h\"\n                               ^\ncompilation terminated.\nmake: * [R_init_IRangeKernels.o] Error 1\nERROR: compilation failed for package \u2018IRangeKernels\n```\n\nAnyway I have the same problem on the previous version of R with the release version of bioconductor, on a different machine:\n```\n\ndevtools::install_github(\"sheffien/IRangeKernels\")\nDownloading github repo sheffien/IRangeKernels@master\nInstalling IRangeKernels\n'/cm/shared/apps/R/3.1.2/lib64/R/bin/R' --vanilla CMD INSTALL  \\\n  '/tmp/RtmpFhPMyp/devtools2c1359077e2b/sheffien-IRangeKernels-8e77a03'  \\\n  --library='/home/nsheffield/.R' --install-tests \n\n\ninstalling source package \u2018IRangeKernels\u2019 ...\n libs\ngcc -std=gnu99 -I/cm/shared/apps/R/3.1.2/lib64/R/include -DNDEBUG  -I/usr/local/include -I\"/home/nsheffield/.R/IRanges/include\"   -fpic  -g -O2  -c R_init_IRangeKernels.c -o R_init_IRangeKernels.o\nIn file included from IRangeKernels.h:1:0,\n                 from R_init_IRangeKernels.c:1:\n/home/nsheffield/.R/IRanges/include/IRanges_defines.h:18:31: fatal error: S4Vectors_defines.h: No such file or directory\n #include \"S4Vectors_defines.h\"\n                               ^\ncompilation terminated.\nmake: * [R_init_IRangeKernels.o] Error 1\nERROR: compilation failed for package \u2018IRangeKernels\u2019\nremoving \u2018/home/nsheffield/.R/IRangeKernels\u2019\nrestoring previous \u2018/home/nsheffield/.R/IRangeKernels\u2019\nSession info -------------------------------------------------------------------\n setting  value                     \n version  R version 3.1.2 (2014-10-31)\n system   x86_64, linux-gnu         \n ui       X11                       \n language (EN)                      \n collate  en_US.UTF-8               \n tz        \n\nPackages -----------------------------------------------------------------------\n package       * version    date       source                        \n BiocGenerics    0.12.1     2015-03-04 Bioconductor                  \n BiocInstaller   1.16.4     2015-04-24 Bioconductor                  \n bitops        * 1.0-6      2013-08-17 CRAN (R 3.1.2)                \n devtools      * 1.7.0.9000 2015-04-29 Github (hadley/devtools@14cca3f)\n httr          * 0.6.1      2015-01-01 CRAN (R 3.1.2)                \n IRanges         2.0.1      2015-03-09 Bioconductor                  \n RCurl         * 1.95-4.5   2014-12-28 CRAN (R 3.1.2)                \n rstudioapi    * 0.3.1      2015-04-07 CRAN (R 3.1.2)                \n S4Vectors       0.4.0      2015-03-09 Bioconductor                  \n stringr       * 0.6.2      2012-12-06 CRAN (R 3.1.0)\n```\n. I can reproduce it across 4 different instances here now (all Linux), virtual machines, cluster, local computers. If you don't have the same problem it must have something to do with environment or OS or something. I wonder if it's a linux-only thing.\nAnyway, I'll let you know if I figure anything else out.\n. I traced this problem to something outside install_github... Basically, I hadn't accounted for the fact that when I cloned from github, I already had a .so file in there, since I was cloning into an existing repo. \nSo install_github was showing the problem because it was actually pulling a fresh clone, which thus lacked the .so file. \nI still haven't solved the problem, but it's not with install_github() as I had thought. My mistake, and sorry to lead you down a wild goose chase.\n. ",
    "lamortenera": "This is indeed a pity, now the installation instructions for a package of mine (\"lamortenera/epicseg\") have become more tedious and might scare users. \nMaybe that's a very naive and stupid idea, but what argues against providing a flag for allowing installation from Bioconductor? Something like the bioc_required option provided by R-travis?\nI guess this could be implemented by installing every dependency with\n   source(\"http://bioconductor.org/biocLite.R\")\n   biocLite(\"pkgname\")\ninstead of\n   install.packages(\"pkgname\")\nThat said, devtools is still an awesome package and thanks so much for it.\n. This is awesome! My bad that I didn't see it.\nThanks so much!\n. Ah right, I celebrated too early. I thought that the ... in install_github were used in install, which has also some ... used in install.packages, which has option repos. But this is not working :(\n. ",
    "biocyberman": "One way to make devtools install dependencies from Bioconductor is like this: \n``` r\nInstall a cool package\ndevtools::install_github(repo=\"Bioconductor-mirror/CoolPkg1\")\nHuman: Error: CoolPkg1 require SomePkgA version x.10.10 ; only SomePkgA version x.9.9 is installed.\nMachine: Look for SomePkgA on gitbub?\nHuman: Yes\nMachine: From which github users?\n[1]  Bioconductor-mirror\n[2] Bioconductor-mirror (use as default)\nHuman: Answer: 2\nMachine: Ok, now I will try to install required dependencies from this github user: Bioconductor-mirror\nMachine: Just sit back and relax.\nMahcine: But beware that you will get all the risk of using unstable versions of packages.\nHuman: What?!!! Ok, could you please roll back?\nMachine: No, it's too late. Joking :-)\nHuman: Phew!\nMachine: Rolling back ....\n```\nContinued...\n``` r\nMachine: You know what, maybe you don't need this install_github() at all.\nMachine: To install Bioconductor development versions of packages\nMachine: Just run this:\nsource(\"http://bioconductor.org/biocLite.R\")\nBiocInstaller::useDevel()\nbiocLite(\"CoolPkg1\")\nHuman: Cool. What if things mess up so bad and I want to revert to stable version.\nMachine: No problem, do this:\nQuit current R session and open a new one\nsource(\"http://bioconductor.org/biocLite.R\")\npkgs <- rownames(installed.packages())\nBiocInstaller::useDevel(FALSE)\nbiocLite(pkgs) # this could take hours to finish.\n```\n. ",
    "ck37": "There is a trick for this: add biocViews: to the package's DESCRIPTION and R will know to search the bioconductor repository automatically for package requirements. This trick is not documented anywhere.\n. If you add biocViews: to your DESCRIPTION file I think you don't need the extra suggestsNote or Additional_repositories.\n. ",
    "Ironholds": "What alternative would you propose?\n. Yep, so this is extraneous and we're good :)\n. Oh, also I fixed a couple of warnings in the test suite caused by calling deprecated testthat functions.\n. Thanks for feedback and thoughts all! The impression I'm getting is:\n1. The actual idea isn't a bad one;\n2. The implementation needs work.\nIs this accurate? If so I'll tweak things in line with Jim and Kevin's excellent feedback this weekend (I'm spending my free time today doing Foundation-related shi- uh. Stuff.)\n. Absolutely! This coming weekend is most likely (last weekend was Survey\nRelease Hell)\nOn Thursday, 9 June 2016, Hadley Wickham notifications@github.com wrote:\n\n@Ironholds https://github.com/Ironholds do you think you'll be able to\ndo this in the next week? If yes, we can get it into the next version of\ndevtools; if no, it'll have to wait\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hadley/devtools/pull/1177#issuecomment-224995784, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/ACXz3mBKibfkZuUic6tHLJE4XhLU0L3-ks5qKGS0gaJpZM4IZ3Q9\n.\n. Good, hah, catch!\n. Makes sense; do you think use_catch() should be exported as well, or?\n. Is that a patch issue or a \"we should look into that\" issue or?\n. Yeah, that's sort of what I was thinking - presumably it'd call use_rcpp() too since there's the breaking edge case where catch is called but /src/ doesn't exist? Unless I'm horribly overthinking it.\n. Good call. I'll try for 2, fall back to 1.\n. \n",
    "schloerke": "ha!.... Thank you\n. @llhh000 Add ..Rcheck to your .Rbuildignore file.. Original: \n``` r\nRun R CMD check on all downstream dependencies of ggplot2\nres <- revdep_check(\"ggplot2\")\nrevdep_check_summary(res)\nrevdep_check_save_logs(res)\n```\nNew version?:\n``` r\nRun R CMD check on all downstream dependencies of ggplot2\nrevdep_check(\"ggplot2\")\nrevdep_check_save_summary(\"ggplot2\")\nrevdep_check_print_problems(\"ggplot2\")\n```\nPersonal usage:\n``` r\nRun R CMD check on all downstream dependencies\nrevdep_check()\nrevdep_check_save_summary()\nrevdep_check_print_problems()\n``\n. [hafen/packagedocs](http://github.com/hafen/packagedocs) found that deleting the wholeinst/docfolder before callingdevtools::build()worked around the issue.\n. Changing the git location from ssh (git@github.com:USER/REPO.git) to https (https://github.com/USER/REPO.git`) worked for me.  . Yes, I'm looking to do auto-invalidation.\n@jennybc Correct. It's more fitting in usethis package.   If it's still a worth while PR, I'd be happy to make a new PR for usethis.\n@jimhester If remote::install_deps() changes to look for changes in the git SHA and not just versions, then I'm all for updating remote::install_deps() instead.    If not, to me, the cache is cheap and can be busted more often than necessary.\nI had issues with a github package that was installed from a branch.  That branch was removed and the Remotes location was updated.  Appveyor was still failing until I could get the cache to bust.. @jimhester This was the error I ran into. https://ci.appveyor.com/project/trestletech/plumber/builds/21501372#L169 . At the time of running this test, the branch \"swagger_v3\" did not exist in https://github.com/rstudio/swagger anymore as it was merged into master.. Thank you, @jimhester !\nFeel free to close this PR as r-lib/remotes#274 should cover my original use case, making my change not needed. . ",
    "llhh000": "I saw a similar issue in R. How did you solve it? The answer is not explicit for me. Thanks!. ",
    "saptarshiguha": "You are correct. Updated and it works now.\nThanks much.\n. ",
    "russellpierce": "bump.  also see https://github.com/eddelbuettel/drat/issues/1.  Issue also bites with install_github on https://github.com/lianos/buckshot\n. ... even if that passed the letter of the CRAN rules regarding calling Internal functions it would seem to very much violate the spirit of the dictum.  That being said, the aim you express certainly is laudable.  One wonders if base would/could expose that functionality directly.\n. ",
    "andrewblim": "Thank you!\n. ",
    "benmarwick": "Yes, fair point. In favour of squeezing them into devtools: \n- I'm imagining these docker functions being a logical part of package development, just like travisci has become for many people. \n- So when the user thinks 'right, I'm doing package development... where are all the handy functions to save me time and pain?' they don't have to think beyond devtools\nBut perhaps I'm wrong in assuming others see docker as part of the R package building and testing workflow...\n. On the other other hand, a package with these functions could probably be whipped up pretty quickly by @sckott, @karthik, @cboettig and others at @ropensci for their collection. \n. Yes, thanks, I didn't know about that one, looks very relevant. Perhaps that's where the functions I'm thinking of should go.\n. @nuest I'm not aware of anything beyond Gabor's work with r-hub. Your containerit package looks great, seems to be right on what I was discussing above. . Agreed, you make lots of good points in favour of this. Maybe it should be an argument to add_travis() to give the user some control over whether the vignette is built on the test? In the case of the package-as-research-compendium, building the vignette/manuscript might take too long for Travis. But these might be marginal use cases.\n. ",
    "nuest": "Is anyone here aware of developments in direction since this thread closed?\nI want to develop a package for automatically creating Dockerfiles based on R sessions, scripts, or \"workspaces\" in a folder. I'll rely on sysreqs, harbor. I just want to make sure I'm not redoing something that exists!\nI'm happy to take this discussion elsewhere. Feedback on a first draft how I imagine the package to be used is highly welcome: https://github.com/o2r-project/containerit/blob/master/vignettes/basic.Rmd. @gaborcsardi Thanks for the pointer! I would like to use sysreqs to create the respective distribution's install statements for the libraries within the Dockerfile. Afaics you're using bash scripts, and your use case is quite different.\nTherefore I'm not worrying about overlaps anymore and we will continue our developments. We will start with extending functions of dockertest.\n@hadley apologies for stealing this issue!. Just a short follow up: We've completed a first prototype, see this blog post. I will also be at useR Brussels and it would be awesome to chat with people here about containers.. ",
    "larskotthoff": "Done.\n. Done, sorry about that.\n. Ooook, this is getting embarassing :) I hope I got it right this time!\n. ",
    "Serenthia": "I'm not really wanting to commit my plaintext Bitbucket password for all my company to see, but I'm not sure of any way round this without this feature?  I'd like to second @imadcat's request, should anyone feel up to the task of making that PR.\nMany thanks \n. Any news on when this is expected to be merged, as it missed the last release?  I'm still having to use devtools#1220, as I'm not committing plaintext creds in our projects.\nMany thanks.. Should this perhaps be caught in the R CMD check (ie. a check for \\n characters in Remotes)?  I ask as I've just been caught out by the same!. ",
    "kleinschmidt": "I was hoping to do the same thing. Once I looked at the code, however, I realized that install_bitbucket uses the REST API to download a .zip of the repo. The API can only be accessed through HTTPS (as far as I can tell).\nThe way around it is to use install_git('git@bitbucket.org/<username>/<repo>/') instead of install_bitbucket('username/repo'), but that requires a bit more boilerplate. @hadley, would you be open to falling back on install_git for something like install_bitbucket('<username>/<repo>', use_ssh=TRUE)? If so I'll open a PR.\n. What's the status of this? Lots of our lab stuff is in bitbucket private repos so authenticating to bitbucket in a secure way is really important for us.\n. Ah, right, of course. Thanks, appreciate the work!\n. ",
    "paulrougieux": "See also  bitbucket app passwords\n\nin the Access Management section of your account settings\n\nAs seen on App passwords are here in Bitbucket Cloud.\nThe issue with an app password is that it gives access to all repositories on you account. The PAT gives access to one repository only. . @Serenthia alternatively, you can use install_git():\ndevtools::install_git('ssh://git@bitbucket.org/user/repository.git')\nMake sure SSH support is enabled in git2r as explained in this StackOverflow answer. Also check Bitbucket instructions on how to setup SSH for git.\n. ",
    "JoshOBrien": "OK. I just updated using build_github_devtools() etc., giving me devtools_1.7.0.9000, and I still get the error. Not sure, though, whether you're referring to another even later latest dev version. Thanks.\n. Hi Winston,\nThat would've been my first thought too, but install() already performs the requisite call to shQuote().\nTrying an idea I found in this SO answer (which recommends prepending ampersands in paths with the caret symbol, so that & becomes ^&) I found that the following addition to the body of install() actually makes it work -- at least in this single test case:\n```\nbuilt_path <- normalizePath(built_path, winslash = \"/\")\n\nif(Sys.info()[[\"sysname\"]]==\"Windows\") {\n    built_path <- gsub(\"&\", \"^&\", built_path)\n}\n\nR(paste(\"CMD INSTALL \", shQuote(built_path), \" \", opts, sep = \"\"),\n    quiet = quiet)\n```\nFeels like there must be a better way (and if there isn't, there should be one built into base R), but this does seem to do the trick.\n. @hadley It looks like it's a Windows command shell issue that comes into play whenever passing arguments that contain ampersands, pipes, or parentheses. There's a mention of it here in the official Microsoft documentation (search for \"the ampersand\"). Here also is a related and highly upvoted SO answer about the same issue.\n. ",
    "rBatt": "Working on a Windows machine recently (usually on Mac), just ran into this issue for the first time. @hadley , was there any useful response to your R-devel report? Any suggestion where I can go to look for a solution to this issue? Thanks. I just ran into this too with \nr\n*** moving datasets to lazyload DB\nWarning: file \u2018ETOPO.RData\u2019 has magic number 'versi'\n  Use of save versions prior to 2 is deprecated\nError : bad restore file magic number (file may be corrupted) -- no data loaded\n. Also, like @jennybc mentions, I'm pretty sure you don't need a special invite anymore, @hadley \nRight now I tell people to clone the repo, and to just use devtools::install().\n. It looks like GitHub changed the way LFS files are displayed --- clicking to download a .RData file, for example, no longer downloads the 3 lines of text, but instead downloads the actual binary. However, I run into the same issue with devtools::install_github().\nIf someone is able and motivated, it might be taking another look at tackling this problem to see if recent changes might have made facilitated the use of install_github() with Git LFS>. ",
    "bheavner": "https://twitter.com/jimhester_/status/1003727023385333761. I'm having the same issue with install_github, also unsure how to troubleshoot:\n```\n\ndevtools::install_github(\"UW-GAC/wgsaparsr\")\nInstallation failed: An unknown option was passed in to libcurl\nsessionInfo()\nR version 3.4.3 (2017-11-30)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: CentOS Linux 7 (Core)\n\nMatrix products: default\nBLAS/LAPACK: /usr/local/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin/libmkl_gf_lp64.so\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C            \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8  \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8 \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C               \n [9] LC_ADDRESS=C               LC_TELEPHONE=C          \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nloaded via a namespace (and not attached):\n[1] httr_1.3.1      compiler_3.4.3  R6_2.2.2        withr_2.1.1  \n[5] curl_3.1        memoise_1.1.0   git2r_0.21.0    digest_0.6.14\n[9] devtools_1.13.4\n```. ",
    "juancentro": "It seems that the variable version_info doesn't hold information for my 3.2 installation. I reverted to RTools 3.1 temporarily\n. I still get\n```\nWARNING: Rtools 3.3 found on the path at c:/Rtools is not compatible with R 3.2.0.\nPlease download and install Rtools 3.1 from http://cran.r-project.org/bin/windows/Rtools/, remove the incompatible version from your PATH, then run find_rtools().\n```\nwhen using R 3.2.0 with RTools 3.3\n. This is fixed in the latest commit on the master branch\nOn Sun, Apr 26, 2015, 20:18 ropeladder notifications@github.com wrote:\n\nI'm getting the exact same error as juancentro.\n\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/717#issuecomment-96447656.\n. \n",
    "dtenenba": "I also get this when using R-devel (R-3.2.0), which should definitely be compatible with Rtools-3.2.\n. Just to add, there is now an Rtools version 33 (which works with R-devel/3.2.0) so devtools needs to recognize that as well as a valid version. The warning that's produced is confusing a lot of people into thinking they have done something wrong.\n. If I read this right, it will still give an error under Rtools 3.3.\n. Doesn't seem like a duplicate to me.\n. I guess you don't want to do this anymore (at least not yet); sounds like Rtools33 is going to roll back to using gcc 4.6.3.\n. ",
    "jakesherman": "I am having the same issue. \n. ",
    "ropeladder": "I'm getting the exact same error as juancentro's last comment. (R 3.2.0 doesn't work with Rtools 3.3)\n. ",
    "Kapondo": "I recently installed RTools 3.4 (over an RTools 3.3 installation, after having problem with building R Package). There seems to be incompatibility issues between RTools 3.4 and R version 3.3.0 (2016-05-03). I reverted back to RTools 3.3 but when I try to build and reload a trial package I get the following error message:\n==> devtools::document(roclets=c('rd', 'collate', 'namespace'))\nUpdating topten documentation\nLoading topten\nWriting topten.Rd\nWriting predct10.Rd\nWriting NAMESPACE\nDocumentation completed\n==> Rcmd.exe INSTALL --no-multiarch --with-keep.source topten\n- installing to library 'C:/Program Files/R/R-3.3.0/library'\n- installing source package 'topten' ...\n  * R\n  * preparing package for lazy loading\n  * help\n  * installing help indices\n  * building package indices\n  ** testing if installed package can be loaded\n- DONE (topten)\n  WARNING: Rtools is required to build R packages but no version of Rtools compatible with the currently running version of R was found. Note that the following incompatible version(s) of Rtools were found:\n  - Rtools 3.3 (installed at c:\\Rtools)\nPlease download and install the appropriate version of Rtools before proceeding:\nhttps://cran.rstudio.com/bin/windows/Rtools/\nwhen I run devtools::find_rtools() with RTools 3.3 installed I get TRUE\nbut with RTools 3.4 installed and run devtools::find_rtools() I get the below error message:\nWARNING: Rtools is required to build R packages, but no version of Rtools compatible with R 3.3.0 was found. Rtools 3.3 was previously installed in c:/Rtools but now that directory contains Rtools 3.4.\nPlease download and install Rtools 3.3 from http://cran.r-project.org/bin/windows/Rtools/.\nPlease help!!\n. ",
    "tom-n-pdx": "Humm.. no - there wasn't a & in the path\nI'll check the latest version and see if problem is still there.\ntom\nOn Tue, Apr 21, 2015 at 7:29 AM, Hadley Wickham notifications@github.com\nwrote:\n\nAny chance there's an & in the path?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/718#issuecomment-94814480.\n\n\ntom shott tshott@pdx.edu, Portland State University\n_http://www.pdx.edu/extreme-technology-analytics/\nhttp://www.pdx.edu/extreme-technology-analytics/_mobile\n503-970-7341\n*google cal *  tshott@pdx.edu\n. ",
    "wleepang": "FYI:\nI'm on a windows machine with R 3.1.2 for development and I had this issue occur today with devtools 1.7.1.\nTo resolve, I:\n- removed MingGW from my PATH.\n- (re)installed Rtools3.2\n- upgraded devtools to 1.9.1\n. ",
    "craigcitro": "i tried doing combinations of options(warnPartialMatchDollar = TRUE) for detection, and options(warn = 2) to turn those into errors -- but the issue is that there are existing errors in dependencies. i didn't know a way to set \"only turn this warning into an error for this package\".\n. well, all is a big commitment. :stuck_out_tongue: \n. @wch see #727 :wink:\n. @brendan-R pshaw, this is the best pull request i've seen all day! (since i didn't have to write it myself :wink:)\n. @linearregression do you have a link to the build?\n. FWIW, the only reason I haven't already switched to supporting multiple CRAN repos is a silly one -- ${CRAN} gets used in two contexts for both travis variants:\n- as an env var which is inlined to a URL (example)\n- as an R string (example)\nA list syntax that works in both of those cases doesn't exist, right? :wink: \n. yeah, we definitely can do rewriting (though the error messages are going to be totally inscrutable if someone typos their CRAN variable).\nhonestly, though, maybe it's OK to just have two vars?\nCRAN=\"http://cran.rstudio.com\"\nif [[ -z ${CRAN_REPOS} ]]; then\n  CRAN_REPOS=\"c(cran=\\\"${CRAN}\\\")\"\nfi\nand people can override CRAN_REPOS as they'd like?\n. ",
    "jemus42": "I understand.\nIf it's not feasible/worth the effort, I'd agree to closing the issue.\n. ",
    "cbarbu": "That sounds right. Sure!\nLe 23 f\u00e9vr. 2015 20:20, \"Hadley Wickham\" notifications@github.com a \u00e9crit\n:\n\nI think this would be better integrated into roxygen as a new roclet.\nWould you mind moving the issue there?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/pull/724#issuecomment-75611756.\n. \n",
    "scheuchzer": "What was your solution? I'm having the same issue here when installing from a private Git repository.\n. ",
    "jmarca": "the link in the README.md should be caps case\ns/conduct.md/CONDUCT.md/\n. Ah yes.  The notes in check.html are exactly what I was missing.  \nI guess I expected that passage in \"Testing\", I didn't think to look in \"Best Practices\".\n. ",
    "ashander": "This would be helpful, and avoid issues for some folks (e.g., https://github.com/armstrtw/rzmq/issues/15 ). But, the implementation of install_github relies on github zipballs -- which don't include submodules.\nSo, a change in implementation would be needed. The first of the options below seems simplest: \n- git clone --recursive to a temp dir and use install_git\n- Use approach mentioned in this SO thread on the topic to parse .gitmodules, download several zipballs and build a single for install.\n. Travis CI fails with message below. Seems like a separate issue.\n``` sh\nWarning message:\npackage \u2018BiocInstaller\u2019 is not available (for R version 3.1.3)\nThe command \"Rscript -e 'options(repos = \"http://cran.rstudio.com\"); tryCatch({ deps <- devtools::install_deps(dependencies = TRUE) }, error = function(e) { message(e); q(status=1) }); if (!all(deps %in% installed.packages())) { q(status = 1, save = \"no\") }'\" failed and exited with 1 during .\n```\n. Yes looks like @jimhester has a fix in PR #746\n. Done! PTAL\n-\u00a0Jaime\nOn Tue, Apr 28, 2015 at 6:18 AM, Hadley Wickham notifications@github.com\nwrote:\n\nLooks good! Could you please add a bullet point to NEWS, thanking your github username?\n(FYI github only notifies me about comments, not commits, so when done please add a comment like \"PTAL\")\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/pull/751#issuecomment-97058328\n. I can't say for certain. But, it seems adopting git2r traded stability for the args. See https://github.com/hadley/devtools/commit/1b7e67acce1398f2a409752f7d99c9a0220196a1\n\nRather than commenting here, it's probably better to open a new issue regarding git2r and args (unless that discussion has already happened -- I haven't searched). In that issue you could reference this PR.\nIn any case, the suggestion to use install_git with --args should be removed from the docs to install-github.r\n. +1 seems less brittle, assuming no issue to have real repo hits in the tests and I can think of reliably TRUE and FALSE repos.\nI'll make this change shortly unless I hear otherwise. Thanks,\n- Jaime\nOn Wed, Apr 29, 2015 at 6:34 AM, Hadley Wickham notifications@github.com\nwrote:\n\nI think a better approach would be to:\n- Write github_has_remotes() that returns TRUE or FALSE\n* Add positive and negative test on real repo - no mocking\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/pull/776#issuecomment-97427679\n. Yes, no problem\n\n-\u00a0Jaime\nOn Thu, Apr 30, 2015 at 6:30 AM, Hadley Wickham notifications@github.com\nwrote:\n\nDo you think you could do this by Monday? I'd like to submit to CRAN then\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/pull/776#issuecomment-97785856\n. #786 implements this suggestion, so closing\n. Thanks!\u00a0Sorry for missing the indent and if-paren style with this PR.\u00a0\n\nI've made the changes, and also fixed indent style in changes the tests\n-\u00a0Jaime\nOn Tue, Apr 21, 2015 at 6:51 AM, Hadley Wickham notifications@github.com\nwrote:\n\n\n@@ -98,6 +106,10 @@ remote_download.github_remote <- function(x, quiet = FALSE) {\n   } else {\n     auth <- NULL\n   }\n-  ## if repo uses submodules warn user\n- I think the comment is extraneous (given how simple the code is)\n- Can you please use a space after if\n- warning() looks like it's indented too much\n4. I always use call. = FALSE with warning\nReply to this email directly or view it on GitHub:\nhttps://github.com/hadley/devtools/pull/751/files#r28778939\n. \n\n",
    "lev-kuznetsov": "I don't want to seem impatient, I'm just wondering if this or something like it would be accepted since what I need to do next would be contingent on it eventually making its way upstream (or not)\n. I didn't change API for install_svn, that still takes an argument named subdir, that change is only underneath for the svn_remote object.\nBefore my changes the subdir argument is dealt with after the checkout from root by the generic install_remote. So it checks out the entire repo and then installs only from the subfolder which would be prohibitive for large repos or impossible for repos where you cannot checkout from root due to permissions.\nWith this change the subdir is appended to the url prior to checkout and as far as install_remote is concerned it's always installing from root of the checkout. As far as I've used svn I've always been able to check out directly from the subfolder.\n. Come to think of it with the revision parameter before the variadic it's conceivable that was a backward incompatible API change for install_svn, I moved is after\n. That's it I think\n. ",
    "skyebend": "if package C is a Dependency of packages A and B, won't lapply(c(A, B), install_deps)  calculate the set of dependencies for A and B independently in parallel, and so install C twice?\n. sna is on CRAN.  But I'm no longer seeing the original issue, so perhaps it was local config problem.\ninstall.packages('sna')\nlibrary(devtools)\nload_all('sna',quiet=FALSE)\nError: Can't find 'sna'.\nHowever, if I peek in .libPaths() and give it the full path to the package, it works fine and does not generate the shared object error.  I'm guessing that before I only gave the path to the local source dir, not the installed system path. \nload_all('/home/skyebend/R/i686-pc-linux-gnu-library/3.2/sna',quiet=FALSE)\nLoading sna\nLoading required package: statnet.common\nLoading required package: network\nnetwork: Classes for Relational Data\nVersion 1.14 created on 2016-05-07.\ncopyright (c) 2005, Carter T. Butts, University of California-Irvine\n                    Mark S. Handcock, University of California -- Los Angeles\n                    David R. Hunter, Penn State University\n                    Martina Morris, University of Washington\n                    Skye Bender-deMoll, University of Washington\n For citation information, type citation(\"network\").\n Type help(\"network-package\") to get started.\n. ",
    "laurikoobas": "Nope. I started to use R in cygwin just today and didn't know to install Rtools first.\nBesides: package \u2018Rtools\u2019 is not available (for R version 3.1.2). I guess I could go and download 3.1.3 and install that from source or something.\n. Right. Thanks. I'll try it on a different machine later as I already got everything working without RTools.\nI guess feel free to close the comment?\n. ",
    "jread-usgs": "Yes, that would be a good fit for our needs. Any others running into a similar use case? We can find a way around it, but it would be handy to be cooked into devtools\n. Thank you. Will try this out and if you don't hear back from me, it works for our pattern. \n. Here is what I see from https://github.com/jread-usgs/geoknife/tree/devtools_release (I removed the vignette and most tests from this branch):\nr\ndevtools::document(roclets=c('rd', 'collate', 'namespace'))\nUpdating geoknife documentation\nLoading geoknife\nCreating a new generic function for \u2018title\u2019 in package \u2018geoknife\u2019\nCreating a new generic function for \u2018start\u2019 in package \u2018geoknife\u2019\nCreating a new generic function for \u2018url\u2019 in package \u2018geoknife\u2019\nr\ndevtools::release()\nWarning: Git not synched with remote.\nUpdating geoknife documentation\nLoading geoknife\nCreating a new generic function for \u2018title\u2019 in package \u2018geoknife\u2019\nCreating a new generic function for \u2018start\u2019 in package \u2018geoknife\u2019\nCreating a new generic function for \u2018url\u2019 in package \u2018geoknife\u2019\nWriting datagroup-methods.Rd\nSetting env vars ------------------------------------------------------------\netc\nNote that the datagroup-methods.Rd is modified in the release() but not document(). The release() version of the Rd causes the following doc warning: \n* checking for missing documentation entries ... WARNING\nUndocumented S4 methods:\n  generic '[' and siglist 'datagroup'\nam on the following:\n* using R version 3.2.3 (2015-12-10)\n* using platform: x86_64-apple-darwin13.4.0 (64-bit)\n* using session charset: UTF-8\n* using option \u2018--as-cran\u2019\n. ",
    "thk686": "Here's output from a test case. First without \"load_all\" and then with \"load_all\":\n==8076== Memcheck, a memory error detector\n==8076== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.\n==8076== Using Valgrind-3.10.0.SVN and LibVEX; rerun with -h for copyright info\n==8076== Command: /usr/lib/R/bin/exec/R --vanilla -f test.R\n==8076== \nR version 3.1.2 (2014-10-31) -- \"Pumpkin Helmet\"\nCopyright (C) 2014 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\nNatural language support but running in an English locale\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\nlibrary(geospatial)\nlibrary(testthat)\nx = georaster(100, 100, driver = \"GTiff\", nosave = TRUE)\nexpect_is(x, \"GeoRaster\")\nSRS(x) = \"EPSG:4326\"\nexpect_equal(as(SRS(x), \"character\"), \"+proj=longlat +datum=WGS84 +no_defs \")\nSRS(x) = SRS(\"+proj=longlat\")\nexpect_equal(as(SRS(x), \"character\"), \"+proj=longlat +ellps=WGS84 +no_defs \")\nSRS(x) = sp::CRS(\"+proj=longlat\")\nexpect_equal(as(SRS(x), \"character\"), \"+proj=longlat +ellps=WGS84 +no_defs \")\n==8076== \n==8076== HEAP SUMMARY:\n==8076==     in use at exit: 75,808,747 bytes in 39,381 blocks\n==8076==   total heap usage: 140,968 allocs, 101,587 frees, 190,212,374 bytes allocated\n==8076== \n==8076== LEAK SUMMARY:\n==8076==    definitely lost: 240 bytes in 5 blocks\n==8076==    indirectly lost: 4,755 bytes in 235 blocks\n==8076==      possibly lost: 0 bytes in 0 blocks\n==8076==    still reachable: 75,803,752 bytes in 39,141 blocks\n==8076==         suppressed: 0 bytes in 0 blocks\n==8076== Rerun with --leak-check=full to see details of leaked memory\n==8076== \n==8076== For counts of detected and suppressed errors, rerun with: -v\n==8076== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)\n\nUsing \"load_all\":\n==8127== Memcheck, a memory error detector\n==8127== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.\n==8127== Using Valgrind-3.10.0.SVN and LibVEX; rerun with -h for copyright info\n==8127== Command: /usr/lib/R/bin/exec/R --vanilla -f test2.R\n==8127== \nR version 3.1.2 (2014-10-31) -- \"Pumpkin Helmet\"\nCopyright (C) 2014 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\nNatural language support but running in an English locale\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\nlibrary(testthat)\ndevtools::load_all(\"~/Desktop/tkeitt/Dropbox/Software/R-Project/geospatial/\")\nLoading geospatial\nx = georaster(100, 100, driver = \"GTiff\", nosave = TRUE)\nexpect_is(x, \"GeoRaster\")\nSRS(x) = \"EPSG:4326\"\n==8127== Invalid read of size 1\n==8127==    at 0x12A87FC5: ??? (in /usr/lib/libgdal.so.1.18.1)\n==8127==    by 0x11EED375: Rcpp::S4_ImplRcpp::PreserveStorage Rcpp::internal::asRcpp::S4_Impl(SEXPREC*, Rcpp::traits::r_type_generic_tag) clone .isra.36\n==8127==    by 0x11EEE636: geospatial_set_georaster_srs (RcppExports.cpp:191)\n==8127==    by 0x4EC83E1: ??? (in /usr/lib/R/lib/libR.so)\n==8127==    by 0x4F07F25: Rf_eval (in /usr/lib/R/lib/libR.so)\n==8127==    by 0x4F0B501: ??? (in /usr/lib/R/lib/libR.so)\n==8127==    by 0x4F07E00: Rf_eval (in /usr/lib/R/lib/libR.so)\n==8127==    by 0x4F0A062: ??? (in /usr/lib/R/lib/libR.so)\n==8127==    by 0x4F07D3E: Rf_eval (in /usr/lib/R/lib/libR.so)\n==8127==    by 0x4F09014: Rf_applyClosure (in /usr/lib/R/lib/libR.so)\n==8127==    by 0x4F07ADD: Rf_eval (in /usr/lib/R/lib/libR.so)\n==8127==    by 0x4F0A062: ??? (in /usr/lib/R/lib/libR.so)\n==8127==  Address 0x4e is not stack'd, malloc'd or (recently) free'd\n==8127== \n\n* caught segfault *\naddress 0x4e, cause 'memory not mapped'\nTraceback:\n 1: .Call(\"geospatial_set_georaster_srs\", PACKAGE = \"geospatial\",     georas, srs)\n 2: set_georaster_srs(object, srs)\n 3: SRS<-(*tmp*, value = \"EPSG:4326\")\n 4: SRS<-(*tmp*, value = \"EPSG:4326\")\naborting ...\n==8127== \n==8127== HEAP SUMMARY:\n==8127==     in use at exit: 88,218,425 bytes in 45,971 blocks\n==8127==   total heap usage: 134,855 allocs, 88,884 frees, 213,945,830 bytes allocated\n==8127== \n==8127== LEAK SUMMARY:\n==8127==    definitely lost: 0 bytes in 0 blocks\n==8127==    indirectly lost: 0 bytes in 0 blocks\n==8127==      possibly lost: 5,427 bytes in 155 blocks\n==8127==    still reachable: 88,212,998 bytes in 45,816 blocks\n==8127==         suppressed: 0 bytes in 0 blocks\n==8127== Rerun with --leak-check=full to see details of leaked memory\n==8127== \n==8127== For counts of detected and suppressed errors, rerun with: -v\n==8127== ERROR SUMMARY: 2 errors from 1 contexts (suppressed: 0 from 0)\n. Yes, its weird. I've found that 99% of the time segfaults are user errors.\nI just cannot find it in this case.\nT.\nOn Tue, Apr 21, 2015 at 9:36 AM, Hadley Wickham notifications@github.com\nwrote:\n\nStrange. Unfortunately I have no idea how to fix this :/\n\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/748#issuecomment-94816859.\n\n\nTimothy H. Keitt\nhttp://www.keittlab.org/\n. After more experimentation, it seems the artifacts are retained in check_path. Will have to debug in the docker environment.. ",
    "jonkeane": "I'm attempting to install from a github repository that has a submodule. I've tried to use install_git('[url to repo]\", args=\"--recursive\") but I get a warning that args is deprecated. Is there a new prefered method for installing submodules? Now that args is deprecated with install_git()?\nSorry if reviving this issue is inappropriate, I'm happy to start a new one if that is preferred. \n. I haven't looked at this since I sent the PR. If you check out the code at that point it should work, but let me know if there are any problems and I'll see what I can do to fix them.. I'm running into this issue as well, although it's in the context of of trying to install an older package from cran. \nI can get the appropriate version with devtools' install_version(), but it looks like install_deps() is calling install.packages() directly. It shouldn't be too difficult to swap in install_version() at https://github.com/hadley/devtools/blob/12574cc356fbd8362899890f7203f61578b5e258/R/deps.R#L330-L332 \nOr am I'm missing a better way to ensure/force the installation of a specific version of a dependency?\n. ",
    "schnee": "Oh, it is definitely weird, and I've pointed that out to the keepers of our internal github.\n. ",
    "bquast": "I've added it as follows:\nexplain need for explicit CRAN setting\n. I noticed that and I have since stopped including it myself. My reason fort including it was simply that many others maintainers still do.\nI could replace the yesno  menu with menu which suggests removing it, with updating it as an alternative. Or would you rather leave it out altogether?\n. @gaborcsardi so my reason was more that some maintainers are perhaps not aware of it being optional, and in that case and up-to-date field is better than an outdated one. the if(exists(\"date\", envir = 1) condition should make sure that anyone who doesn't use this field isn't bothered with this question.\nHowever, if you think that this generally accepted practice, then perhaps it is indeed redundant.\n. ",
    "donlelek": "Hi @hadley I think it's an OS X problem, check this:\nhttp://stackoverflow.com/questions/29529455/missing-c-header-debug-after-updating-osx-command-line-tools-6-3\nit's affecting every package that compiles using Rcpp\n. ",
    "tklebel": "I linked the question above, but maybe not very obvious.\nThe solution which was suggested there works. You don't actually have to be registered in a dev-plan in order to download commandlinetoolsosx10.10forxcode6.2.dmg.\n. ",
    "jefferis": "bit me too!\n. ",
    "linearregression": "First seen the failure:\nhttps://travis-ci.org/linearregression/devtools/builds/59164984 \nform just forking\nThen after moving sudo required up\nyou will see  it fails on bioinstaller:\nhttps://travis-ci.org/linearregression/devtools/builds/59165654\nThen after setting \nbioc_required: true\nit will pass\nLook at pull requests:\nhttps://github.com/hadley/devtools/pull/764\n. ",
    "englianhu": "`````` r\n\ninstall_github(\"cscheid/rgithub\")\nDownloading github repo cscheid/rgithub@master\nInstalling github\n\"C:/PROGRA~1/R/R-32~1.0/bin/x64/R\" --vanilla CMD INSTALL  \\\n  \"C:/Users/Scibrokes/AppData/Local/Temp/RtmpyYylPq/devtools254c32b2430a/cscheid-rgithub-ead1c0d\"  \\\n  --library=\"C:/Users/Scibrokes/Documents/R/win-library/3.2\" --install-tests \n\nError in parse_git_repo(repo) : could not find function \"setNames\"\nCalls:  -> lapply -> FUN -> parse_git_repo\nExecution halted\nError: Command failed (1)```\n``````\n. > traceback()\n\n15: tolower(names(x))\n14: insensitive(setNames(values, names))\n13: FUN(X[[i]], ...)\n12: lapply(unname(split(lines, grps)), parse_single_header)\n11: parse_headers(headers)\n10: perform(handle, writer, method, opts, body)\n9: make_request(\"head\", hu$handle, hu$url, config)\n8: httr::HEAD(src_submodules, , auth)\n7: github_has_remotes(x, auth)\n6: remote_download.github_remote(remote, quiet = quiet)\n5: remote_download(remote, quiet = quiet)\n4: FUN(X[[i]], ...)\n3: vapply(remotes, install_remote, ..., FUN.VALUE = logical(1))\n2: install_remotes(remotes, ...)\n1: devtools::install_github(\"ropensci/plotly\")\n1\n[1] 1\ndevtools::package_deps(\"devtools\")\ndevtools::install_github(\"ropensci/plotly\")\nDownloading github repo ropensci/plotly@master\nInstalling plotly\nError in basename(fnames) : a character vector argument expected\ntraceback()\n9: basename(fnames)\n8: payload(filenames = files, description)\n7: update(pkg, Ncpus = threads, ...)\n6: install_deps(pkg, dependencies = dependencies, threads = threads,\n       ...)\n5: install(source, ..., quiet = quiet)\n4: FUN(X[[i]], ...)\n3: vapply(remotes, install_remote, ..., FUN.VALUE = logical(1))\n2: install_remotes(remotes, ...)\n1: devtools::install_github(\"ropensci/plotly\")\ndevtools::install_github(\"ropensci/plotly\")\nDownloading github repo ropensci/plotly@master\nInstalling plotly\nError in basename(fnames) : a character vector argument expected\n\nKindly assist.\n2015-05-15 21:10 GMT+09:00 Hadley Wickham notifications@github.com:\n\nWorks for me. Please supply traceback() and\ndevtools::package_deps(\"devtools\")\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/801#issuecomment-102382698.\n\n\n\u00ae\n. Dear,\nAny idea?\n[image: \u57cb\u3081\u8fbc\u307f\u753b\u50cf 1]\nThanks lot.\n\u00ae\n2015-05-16 0:31 GMT+09:00 Ryo Eng englianhu@gmail.com:\n\n\ntraceback()\n15: tolower(names(x))\n14: insensitive(setNames(values, names))\n13: FUN(X[[i]], ...)\n12: lapply(unname(split(lines, grps)), parse_single_header)\n11: parse_headers(headers)\n10: perform(handle, writer, method, opts, body)\n9: make_request(\"head\", hu$handle, hu$url, config)\n8: httr::HEAD(src_submodules, , auth)\n7: github_has_remotes(x, auth)\n6: remote_download.github_remote(remote, quiet = quiet)\n5: remote_download(remote, quiet = quiet)\n4: FUN(X[[i]], ...)\n3: vapply(remotes, install_remote, ..., FUN.VALUE = logical(1))\n2: install_remotes(remotes, ...)\n1: devtools::install_github(\"ropensci/plotly\")\n1\n[1] 1\ndevtools::package_deps(\"devtools\")\ndevtools::install_github(\"ropensci/plotly\")\nDownloading github repo ropensci/plotly@master\nInstalling plotly\nError in basename(fnames) : a character vector argument expected\ntraceback()\n9: basename(fnames)\n8: payload(filenames = files, description)\n7: update(pkg, Ncpus = threads, ...)\n6: install_deps(pkg, dependencies = dependencies, threads = threads,\n       ...)\n5: install(source, ..., quiet = quiet)\n4: FUN(X[[i]], ...)\n3: vapply(remotes, install_remote, ..., FUN.VALUE = logical(1))\n2: install_remotes(remotes, ...)\n1: devtools::install_github(\"ropensci/plotly\")\ndevtools::install_github(\"ropensci/plotly\")\nDownloading github repo ropensci/plotly@master\nInstalling plotly\nError in basename(fnames) : a character vector argument expected\n\nKindly assist.\n2015-05-15 21:10 GMT+09:00 Hadley Wickham notifications@github.com:\n\nWorks for me. Please supply traceback() and\ndevtools::package_deps(\"devtools\")\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/801#issuecomment-102382698.\n\n\n\u00ae\n\n\n\u00ae\n. May I know what path will normally crash with devtools? There is a Python\npath error if I run with R3.1.3...\nOn Fri, Jun 19, 2015, 8:43 PM Hadley Wickham notifications@github.com\nwrote:\n\nYou must have something else on the search path that's interfering with\ndevtools.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/801#issuecomment-113485829.\n. Ryo  Eng\u00ae would like to share papers and updates with you.\n\nAccept Ryo  Eng\u00ae's invitation:\nhttp://academia.edu/t/a-Kf5XyNk-sf2dC/Yes-reply%2B006e48be20c568605b7cef35179c2e69fd2e1bc4de818a5992cf00000001116da42c92a169ce048ff2d3-at-reply.github.com-is-an-academic-or-graduate-student\nRyo  Eng\u00ae has invited you to Academia.edu, a global network of over 23,662,800 researchers. After you sign up, you'll be able to share your papers, see analytics on your profile and papers, follow other people in your field, and more.\nThanks,\nThe Academia.edu Team\nFor more information visit https://www.academia.edu/t/a-Kf5XyNk-sf2dC/press or contact us: feedback@academia.edu\n\nYou can opt out of receiving these kinds of emails from Academia.edu with the link below:\nhttps://www.academia.edu/t/a-Kf5XyNk-sf2dC/optout/88844f8004a25ebb44af1bd5343ea34c\nAcademia.edu, 251 Kearny St., Suite 520, San Francisco, CA, 94108\n. Ryo  Eng\u00ae would like to share papers and updates with you.\nAccept Ryo  Eng\u00ae's invitation:\nhttp://academia.edu/t/a-Kf5XyQk-EedSw/Yes-reply%2B006e48be6a296864379d85dc77050bca8041f3dcaf1f4dbb92cf00000001119bc24792a169ce048ff2d3-at-reply.github.com-is-an-academic-or-graduate-student\nRyo  Eng\u00ae has invited you to Academia.edu, a global network of over 23,662,800 researchers. After you sign up, you'll be able to share your papers, see analytics on your profile and papers, follow other people in your field, and more.\nThanks,\nThe Academia.edu Team\nFor more information visit https://www.academia.edu/t/a-Kf5XyQk-EedSw/press or contact us: feedback@academia.edu\n\nYou can opt out of receiving these kinds of emails from Academia.edu with the link below:\nhttps://www.academia.edu/t/a-Kf5XyQk-EedSw/optout/3b8b2b6a5ee8a3a16f49ce4172d715b0\nAcademia.edu, 251 Kearny St., Suite 520, San Francisco, CA, 94108\n. I tried to setup RStudio and Shiny Server but there is an error with installation of devtools packages. Any idea? or alternative method?\nAccording to below link, devtools does indeed require libssl-dev to be installed\nhttp://deanattali.com/2015/05/09/setup-rstudio-shiny-server-digital-ocean/#comment-2021216940\n\n. Subject Line (for proofing, doesn't show in actual email)\nhttps://www.digitalocean.com                         == Deploy a Server\nFor Free! ==\nYour friend Eng Lian Hu has been using DigitalOcean \u2013 a cloud hosting\nservice designed just for developers \u2013 and thought you might want to give\nit a shot. You can deploy a server in 55 seconds from our control panel or\nuse our simple API. \nBecause you\u2019ve been invited by a friend, we\u2019d like to give you a $10\ncredit to try it out. Just use this link to create an account and you\u2019ll\nbe credited automatically.\nRedeem Your Credit\nhttps://cloud.digitalocean.com/accept?code=bec4df50a36014&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=Mandrill\nHappy Coding,\n DigitalOcean \n\u00a9 DigitalOcean <http://do.co/email_twitter>\nhttp://do.co/email_gplus http://do.co/email_facebook\n. hadley/devtools\u3055\u3093\nLinkedIn\u3067\u3064\u306a\u304c\u3063\u3066\u304f\u3060\u3055\u3044\u3002\u3088\u308d\u3057\u304f\u304a\u9858\u3044\u3057\u307e\u3059\u3002\n\u00ae\u03b3\u03c3\n\u00ae\u03b3\u03c3\u3055\u3093\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u627f\u8a8d\u3059\u308b: https://www.linkedin.com/e/v2?e=0-ik840954-rq&t=ssuw&tracking=eml-guest-invite-cta&ek=invite_guest&sharedKey=_ARYYjBp&invitationId=6100955036555235332\n\u672c\u30e1\u30fc\u30eb\u306fLinkedIn\u306e\u3064\u306a\u304c\u308a\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u3054\u6848\u5185\u3059\u308b\u3082\u306e\u3067\u3059\u3002LinkedIn\u306f\u3001\u3042\u306a\u305f\u306e\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u3092\u77e5\u308a\u5408\u3044\u306e\u7d39\u4ecb\u6a5f\u80fd\u306b\u4f7f\u7528\u3057\u307e\u3059\u3002\u30e1\u30fc\u30eb\u8cfc\u8aad\u3092\u505c\u6b62\u3059\u308b\u306b\u306f\u6b21\u306e\u30ea\u30f3\u30af\u3092\u30af\u30ea\u30c3\u30af\u3057\u3066\u304f\u3060\u3055\u3044: https://www.linkedin.com/e/v2?e=0-ik840954-rq&t=lun&midToken=AQFmrFVhGEd36Q&ek=invite_guest&loid=AQEoFj1_Gl0DEgAAAVKryZ5NaKlGV1mUi8KZfObT8WBZuwhuSO-EF8xHGHepx7BtC4yuLSSiUPLMRQgUw0eEyM90imxoCIpprhDV2A_-Va42qSit7jcIBRUgQ7K8QicJVT87ajHRWFdonaQo1dDDmaj1EFwcXU60bqnLziNlDwwBCaxH940BIw3PUt2yLJs5il7o&eid=0-ik840954-rq\n\u672c\u30e1\u30fc\u30eb\u306freply@reply.github.com\u306b\u9001\u4fe1\u3055\u308c\u3066\u3044\u307e\u3059\u3002\nIf you need assistance or have questions, please contact LinkedIn Customer Service: https://www.linkedin.com/e/v2?e=0-ik840954-rq&a=customerServiceUrl&ek=invite_guest\n\u00a9 2016 LinkedIn Corporation, 2029 Stierlin Court, Mountain View CA 94043.LinkedIn\u304a\u3088\u3073LinkedIn\u306e\u30ed\u30b4\u306f\u3001LinkedIn\u306e\u767b\u9332\u5546\u6a19\u3067\u3059\u3002\n. hadley/devtools\u3055\u3093\nLinkedIn\u3067\u3064\u306a\u304c\u3063\u3066\u304f\u3060\u3055\u3044\u3002\u3088\u308d\u3057\u304f\u304a\u9858\u3044\u3057\u307e\u3059\u3002\n\u00ae\u03b3\u03c3\n\u00ae\u03b3\u03c3\u3055\u3093\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u627f\u8a8d\u3059\u308b: https://www.linkedin.com/e/v2?e=0-ik8409fz-hy&t=ssuw&tracking=eml-guest-invite-cta&ek=invite_guest&sharedKey=56Te5LWF&invitationId=6100955036764958721\n\u672c\u30e1\u30fc\u30eb\u306fLinkedIn\u306e\u3064\u306a\u304c\u308a\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u3054\u6848\u5185\u3059\u308b\u3082\u306e\u3067\u3059\u3002LinkedIn\u306f\u3001\u3042\u306a\u305f\u306e\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u3092\u77e5\u308a\u5408\u3044\u306e\u7d39\u4ecb\u6a5f\u80fd\u306b\u4f7f\u7528\u3057\u307e\u3059\u3002\u30e1\u30fc\u30eb\u8cfc\u8aad\u3092\u505c\u6b62\u3059\u308b\u306b\u306f\u6b21\u306e\u30ea\u30f3\u30af\u3092\u30af\u30ea\u30c3\u30af\u3057\u3066\u304f\u3060\u3055\u3044: https://www.linkedin.com/e/v2?e=0-ik8409fz-hy&t=lun&midToken=AQFmrFVhGEd36Q&ek=invite_guest&loid=AQFxyKeyjMC5ZAAAAVKry5VoevMP9zUW3rI9l6Fk5M6fJH5myveU0gX_F4axfJ_yrODjyHvilPCIs5VgH9dkU0pAOYpSAyRA5fSi38JKndy9fPFG7OWrbE9rqt1296JCe9ffnO-pdCAXDGxCYSKdfckpdHykgKeWDNP42y9WmRAU6ft70SwLPzVE8Lsv-zqX-V4U&eid=0-ik8409fz-hy\n\u672c\u30e1\u30fc\u30eb\u306freply@reply.github.com\u306b\u9001\u4fe1\u3055\u308c\u3066\u3044\u307e\u3059\u3002\nIf you need assistance or have questions, please contact LinkedIn Customer Service: https://www.linkedin.com/e/v2?e=0-ik8409fz-hy&a=customerServiceUrl&ek=invite_guest\n\u00a9 2016 LinkedIn Corporation, 2029 Stierlin Court, Mountain View CA 94043.LinkedIn\u304a\u3088\u3073LinkedIn\u306e\u30ed\u30b4\u306f\u3001LinkedIn\u306e\u767b\u9332\u5546\u6a19\u3067\u3059\u3002\n. \u00ae\u03b3\u03c3 Eng would like to connect on LinkedIn. How would you like to respond?\nAccept: https://www.linkedin.com/e/v2?e=-s1wy7h-ikge626s-f9&a=preRegInvite&ek=first_guest_reminder_01&li=14&m=hero&ts=accept_text&sharedKey=56Te5LWF&invitationID=6100955036764958721\nView \u00ae\u03b3\u03c3 Eng's profile: https://www.linkedin.com/e/v2?e=-s1wy7h-ikge626s-f9&a=preRegInvite&ek=first_guest_reminder_01&li=3&m=hero&ts=profile_text&sharedKey=56Te5LWF&invitationID=6100955036764958721\n\u672c\u30e1\u30fc\u30eb\u306fLinkedIn\u306e\u3064\u306a\u304c\u308a\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u3054\u6848\u5185\u3059\u308b\u3082\u306e\u3067\u3059\u3002LinkedIn\u306f\u3001\u3042\u306a\u305f\u306e\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u3092\u77e5\u308a\u5408\u3044\u306e\u7d39\u4ecb\u6a5f\u80fd\u306b\u4f7f\u7528\u3057\u307e\u3059\u3002\u8cfc\u8aad\u505c\u6b62: https://www.linkedin.com/e/v2?e=-s1wy7h-ikge626s-f9&t=lun&midToken=AQFmrFVhGEd36Q&ek=first_guest_reminder_01&li=16&m=unsub&ts=HTML&eid=-s1wy7h-ikge626s-f9&loid=AQEgSPaA3VQeoQAAAVLKbJsPVDyHgvBxKQ_8ILCJ9sDtU1KssXfxhr6DofSHpakMW8OjeR4SuLQlRglQX3RHETqwtuv5xTGVuiZMIa6dJ1JWQTGZIwHBAnM8BBT3aCq5h1BdnDhmyoRm1M-v9L_6Dua2wmSWAI4i7eE5rkrOUAe19_tiHKWYLzoSUlavOOAumozX\n\u672c\u30e1\u30fc\u30eb\u306freply@reply.github.com\u306b\u9001\u4fe1\u3055\u308c\u3066\u3044\u307e\u3059\u3002\nIf you need assistance or have questions, please contact LinkedIn Customer Service: https://www.linkedin.com/e/v2?e=-s1wy7h-ikge626s-f9&a=customerServiceUrl&ek=first_guest_reminder_01\n\u00a9 2016 LinkedIn Corporation, 2029 Stierlin Court, Mountain View CA 94043.LinkedIn\u304a\u3088\u3073LinkedIn\u306e\u30ed\u30b4\u306f\u3001LinkedIn\u306e\u767b\u9332\u5546\u6a19\u3067\u3059\u3002\n. \u00ae\u03b3\u03c3 Eng would like to connect on LinkedIn. How would you like to respond?\nAccept: https://www.linkedin.com/e/v2?e=usu9ap-ikge3t8n-x6&a=preRegInvite&ek=first_guest_reminder_01&li=14&m=hero&ts=accept_text&sharedKey=_ARYYjBp&invitationID=6100955036555235332\nView \u00ae\u03b3\u03c3 Eng's profile: https://www.linkedin.com/e/v2?e=usu9ap-ikge3t8n-x6&a=preRegInvite&ek=first_guest_reminder_01&li=3&m=hero&ts=profile_text&sharedKey=_ARYYjBp&invitationID=6100955036555235332\n\u672c\u30e1\u30fc\u30eb\u306fLinkedIn\u306e\u3064\u306a\u304c\u308a\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u3054\u6848\u5185\u3059\u308b\u3082\u306e\u3067\u3059\u3002LinkedIn\u306f\u3001\u3042\u306a\u305f\u306e\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u3092\u77e5\u308a\u5408\u3044\u306e\u7d39\u4ecb\u6a5f\u80fd\u306b\u4f7f\u7528\u3057\u307e\u3059\u3002\u8cfc\u8aad\u505c\u6b62: https://www.linkedin.com/e/v2?e=usu9ap-ikge3t8n-x6&t=lun&midToken=AQFmrFVhGEd36Q&ek=first_guest_reminder_01&li=16&m=unsub&ts=HTML&eid=usu9ap-ikge3t8n-x6&loid=AQGt9FlDzztmkgAAAVLKb6GdOhMjJAZzV7XncSnsqiAQIvpwTjcXRhplU1UPk8yLS3f8-m655MLeEy0ERzXpvsrAQtCD1GzbuuI96tYBp8O5I2EpNBaiXUBsJF_g133T9fp62I9YC1Ad2U3oXEo6qe3jcf8NwCH4oL-maTM7GrOTuhcJmeRfp9jND0lbshuuU6hK\n\u672c\u30e1\u30fc\u30eb\u306freply@reply.github.com\u306b\u9001\u4fe1\u3055\u308c\u3066\u3044\u307e\u3059\u3002\nIf you need assistance or have questions, please contact LinkedIn Customer Service: https://www.linkedin.com/e/v2?e=usu9ap-ikge3t8n-x6&a=customerServiceUrl&ek=first_guest_reminder_01\n\u00a9 2016 LinkedIn Corporation, 2029 Stierlin Court, Mountain View CA 94043.LinkedIn\u304a\u3088\u3073LinkedIn\u306e\u30ed\u30b4\u306f\u3001LinkedIn\u306e\u767b\u9332\u5546\u6a19\u3067\u3059\u3002\n. ",
    "stephlocke": "This might be made more generic by enabling the passing of a httr::authenticate() token or similar to the install_git function as an optional parameter. That way bitbucket, github private repos, and other sources of private repositories could be utilised.\n. The current way in the R Extensions manual is NEWS so we can start with that first? We can  then converge on markdown as the R versions move towards it.\n. ",
    "coveralls": "\nCoverage decreased (-0.07%) to 33.43% when pulling e1ce0603ae5216530ced6603d6b6b0194c779e5e on karthik:master into c9470ca8f9a5ddb8b7ce14259007bf71f3ad5479 on hadley:master.\n. \nCoverage increased (+0.24%) to 33.74% when pulling ad6f35ceb7bfbd40cc0bdb8bea26df0fd80a17f9 on karthik:master into c9470ca8f9a5ddb8b7ce14259007bf71f3ad5479 on hadley:master.\n. \nCoverage remained the same at 33.5% when pulling 0667886f3546bdbd1cdc34b856bc6b5d39cc2b6c on hmalmedal:master into c9470ca8f9a5ddb8b7ce14259007bf71f3ad5479 on hadley:master.\n. \nCoverage decreased (-0.1%) to 33.4% when pulling f21079a662f54750f57761dbb1ee88aace9548fc on krlmlr:aspell into c9470ca8f9a5ddb8b7ce14259007bf71f3ad5479 on hadley:master.\n. \nCoverage decreased (-0.1%) to 33.4% when pulling f21079a662f54750f57761dbb1ee88aace9548fc on krlmlr:aspell into c9470ca8f9a5ddb8b7ce14259007bf71f3ad5479 on hadley:master.\n. \nCoverage decreased (-0.1%) to 33.4% when pulling f21079a662f54750f57761dbb1ee88aace9548fc on krlmlr:aspell into c9470ca8f9a5ddb8b7ce14259007bf71f3ad5479 on hadley:master.\n. \nCoverage increased (+0.2%) to 33.7% when pulling fe6e9af6d275297c3bdfc6b3cbd7513c4100f3eb on krlmlr:aspell into c9470ca8f9a5ddb8b7ce14259007bf71f3ad5479 on hadley:master.\n. \nCoverage increased (+0.31%) to 33.81% when pulling 5492497ba5abd5c45942d078a430d3a138ab7e52 on krlmlr:aspell into c9470ca8f9a5ddb8b7ce14259007bf71f3ad5479 on hadley:master.\n. \nCoverage remained the same at 33.5% when pulling ec55b2de1614e4b1f0d9c838238cedbdc95917a3 on krlmlr:pkg_deps into c9470ca8f9a5ddb8b7ce14259007bf71f3ad5479 on hadley:master.\n. \nCoverage increased (+0.11%) to 33.61% when pulling 0c28be0f1c4339477bd373451d5260d805ed5ffa on ashander:fix/submodule-warn-tests into c9470ca8f9a5ddb8b7ce14259007bf71f3ad5479 on hadley:master.\n. \nCoverage decreased (-0.31%) to 33.4% when pulling 9d587b338c51ea06a698472f3162cd38a50f7dc6 on jimhester:with_makevars into c5c14babc494b3ac660b68790724965e75b15c35 on hadley:master.\n. \nCoverage increased (+0.1%) to 33.52% when pulling 2bd10cda52905e821ab25bc3008be75332555123 on krlmlr:subpackage into dc61a9e79c44f47214a154b3a722bd96a22d5e2e on hadley:master.\n. \nCoverage increased (+0.1%) to 33.52% when pulling f8313313f1b491b7a81bac71e0ae3976ccfb6ad8 on krlmlr:subpackage into dc61a9e79c44f47214a154b3a722bd96a22d5e2e on hadley:master.\n. \nCoverage remained the same at 33.52% when pulling e671128bcaaa13880de36208aa6df229c2f9fe06 on bbolker:master into 4ea1d4ca0f12cb1c845379b1b52c456648320a63 on hadley:master.\n. \nCoverage remained the same at 33.52% when pulling 336df9ab99b48be648e85508a5af568b61f01360 on XD-DENG:master into 57c93d43663ff411c964712377787fbb72f29014 on hadley:master.\n. \nCoverage remained the same at 33.52% when pulling 46ae0dd80babdcab2edbb6433830d4c908abf74e on XD-DENG:master into 57c93d43663ff411c964712377787fbb72f29014 on hadley:master.\n. \nCoverage decreased (-0.1%) to 33.42% when pulling 24ed56060e402aca854a428a407802e87965c3d7 on krlmlr:subpackage-fix into 57c93d43663ff411c964712377787fbb72f29014 on hadley:master.\n. \nCoverage decreased (-0.15%) to 33.37% when pulling 3b4e28a39b77c21b92778dc257b98130c1806670 on krlmlr:subpackage-fix into 57c93d43663ff411c964712377787fbb72f29014 on hadley:master.\n. \nCoverage decreased (-0.24%) to 33.28% when pulling 3b4e28a39b77c21b92778dc257b98130c1806670 on krlmlr:subpackage-fix into 57c93d43663ff411c964712377787fbb72f29014 on hadley:master.\n. \nCoverage remained the same at 33.52% when pulling 1b4e601943e0673d7401b609539a37e4ea25483a on krlmlr:subpackage-fix into 57c93d43663ff411c964712377787fbb72f29014 on hadley:master.\n. ",
    "iembry-USGS": "Hi Hadley, check out http://blog.gitorious.org/2015/04/15/gitorious-org-is-dead-long-live-gitorious-org/ (Gitorious.org is dead, long live gitorious.org) & https://about.gitlab.com/2015/03/03/gitlab-acquires-gitorious/ (GitLab acquires Gitorious to bolster its on premises code collaboration platform). Thank you.\n. Hi Hadley, I am currently using devtools_1.9.1.9000 and git2r_0.13.1.9000 is loaded via a namespace. I used devtools to upgrade to both the development versions of devtools and git2r. Then, I terminated R and restarted R.\nI am still getting the same  error message as sachsmc.\nCan you reopen this issue?\nThank you.\nIrucka Embry\n. ",
    "daliati": "I'm getting the same error now, R version 3.5.0 (2018-04-23) -- \"Joy in Playing\", newest devtools. libssh2 is installed. But mostly I just got sentimental coming across this issue :) . ",
    "LechMadeyski": "Using R3.2.0 and the latest dev version of devtools (and git2r) if you run devtools::release() you get:\nWarning: Uncommited changes in git.\nError in git2r::lookup(r, git2r::branch_target(upstream)) : \n  error in evaluating the argument 'sha' in selecting a method for function 'lookup': Error in (function (classes, fdef, mtable)  : \n  unable to find an inherited method for function \u2018branch_target\u2019 for signature \u2018\"NULL\"\u2019\n. ",
    "bamcdougall": "Hi Hadley,\nI'm glad you are thinking about this issue.\nWith library(\"devtools\"), RStudio (Version 0.98.1102) returns:\nWARNING: Rtools 3.2 found on the path at d:/Rtools is not compatible with R 3.1.2.\nPlease download and install Rtools 3.1 from http://cran.r-project.org/bin/windows/Rtools/, remove the incompatible version from your PATH, then run find_rtools().\nwarning: Rtools 3.2 found on the path at d:/Rtools is not compatible with R 3.1.2.Please download and install Rtools 3.1 from http://cran.r-project.org/bin/windows/Rtools/, remove the incompatible version from your PATH, then run find_rtools().\nFrom sessionInfo():  R version 3.1.2 (2014-10-31)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\n.  a simple package update resolved my issue \n. ",
    "LiNk-NY": "I got the same error. I was able to work around it by running the same code with R --vanilla. \n\ntraceback()\n9: basename(fnames)\n8: payload(filenames = files, description)\n7: update(pkg, Ncpus = threads, ...)\n6: install_deps(pkg, dependencies = dependencies, threads = threads, \n       ...)\n5: install(source, ..., quiet = quiet)\n4: FUN(X[[i]], ...)\n3: vapply(remotes, install_remote, ..., FUN.VALUE = logical(1))\n2: install_remotes(remotes, ...)\n1: install_github(\"hadley/haven\")\n\nMy session info: \n\nsessionInfo()\nR version 3.2.0 (2015-04-16)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 15.04\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8\n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8    LC_PAPER=en_US.UTF-8       LC_NAME=C\n [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.8.0       FirebrowseR_0.2.10   BiocInstaller_1.18.3 gistr_0.2.0          vimcom_1.2-6         setwidth_1.0-3\n[7] colorout_1.1-1      \nloaded via a namespace (and not attached):\n [1] Rcpp_0.11.6     knitr_1.10.5    xml2_0.1.1      magrittr_1.5    R6_2.0.1        stringr_1.0.0   httr_0.6.1      dplyr_0.4.2\n [9] tcltk_3.2.0     tools_3.2.0     parallel_3.2.0  DBI_0.3.1       git2r_0.10.1    htmltools_0.2.6 rversions_1.0.1 assertthat_0.1 \n[17] digest_0.6.8    bitops_1.0-6    RCurl_1.95-4.6  curl_0.8        memoise_0.2.1   rmarkdown_0.7   stringi_0.4-1   jsonlite_0.9.16\n. Solved the error by changing the conflicting name with another function. \n. ",
    "BrainyGuy": "I am seeing the same error for any GitHub install:\n```\n\ndevtools::install_github(\"hadley/devtools\")\nUsing github PAT from envvar GITHUB_PAT\nDownloading github repo hadley/devtools@master\nError in system(full, intern = quiet, ignore.stderr = quiet, ...) : \n  error in running command\n```\n. \n",
    "Rewarp": "Sorry for the delay. I ran the devtools command from a new RStudio installation.\n``` R\n\ndevtools::session_info()\nSession info ---------------------------------------------------------------------\n setting  value                     \n version  R version 3.1.1 (2014-07-10)\n system   x86_64, linux-gnu         \n ui       RStudio (0.98.1103)       \n language en_US                     \n collate  en_US.UTF-8               \n tz       America/Chicago             \nPackages -------------------------------------------------------------------------\n package   * version  date       source      \n bitops      1.0-6    2013-08-17 CRAN (R 3.1.1)\n devtools    1.8.0    2015-05-09 CRAN (R 3.1.1)\n digest      0.6.8    2014-12-31 CRAN (R 3.1.1)\n git2r       0.10.1   2015-05-07 CRAN (R 3.1.1)\n httr        0.6.1    2015-01-01 CRAN (R 3.1.1)\n magrittr    1.5      2014-11-22 CRAN (R 3.1.1)\n memoise     0.2.1    2014-04-22 CRAN (R 3.1.1)\n RCurl       1.95-4.6 2015-04-24 CRAN (R 3.1.1)\n rversions   1.0.0    2015-04-22 CRAN (R 3.1.1)\n stringi     0.4-1    2014-12-14 CRAN (R 3.1.1)\n stringr     1.0.0    2015-04-30 CRAN (R 3.1.1)\n XML         3.98-1.1 2013-06-20 CRAN (R 3.1.1)\n```\n. What's the full syntax? I am, very new to devtools. My apologies.\n. Oh I see. options is the base package. Yes it works now. Thanks!\n. \n",
    "thepetestop": "Call options(unzip = 'internal') before calling install_github\n. Enter R on the terminal using sudo\n$ sudo R\nOn R,\noptions(unzip = 'internal')\ndevtools::install_github('rstudio/shinyapps')\nIt worked for me. I changed your shiny to shinyapps. You do have the shiny package installed already, I assume.\n. ",
    "nsh87": "Using the latest version of lintr from GitHub, devtools::check() incorrectly passes the check even though devtools::test() fails:\n``` R\n\ndevtools::test()\nLoading receptormarker\nTesting receptormarker\nLint package to verify code style : \n......\n[[1]]\nR/receptormarker.R:57:1: style: lines should not be more than 80 characters.\n                                     \"on your system. In order to achieve the slajsld\",\n^~\n\n1\nRun a basic test to verify tests are working : .\nSystem checks for getting Python and Biopython version numbers : .......\n\nFailure(@test_lint_package.R#39): code conforms to the style guide -------------------------------------------------\nlength(lint_errs) not equal to 0\nMean absolute difference: 1\n\n\ndevtools::check()\nUpdating receptormarker documentation\nLoading receptormarker\nSkipping invalid path:  .onLoad.Rd \nSkipping invalid path:  .onAttach.Rd \n'/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file --no-environ --no-save --no-restore CMD build  \\\n  '/Users/me/dev/receptormarker/receptormarker' --no-resave-data --no-manual \n\n\nchecking for file \u2018/Users/me/dev/receptormarker/receptormarker/DESCRIPTION\u2019 ... OK\npreparing \u2018receptormarker\u2019:\nchecking DESCRIPTION meta-information ... OK\nchecking for LF line-endings in source and make files\nchecking for empty or unneeded directories\nbuilding \u2018receptormarker_0.0.0.9000.tar.gz\u2019\n\n'/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file --no-environ --no-save --no-restore CMD check  \\\n  '/var/folders/ps/4zmxslc50ls5cxjpng935wpm0000gn/T//Rtmp9vQKu4/receptormarker_0.0.0.9000.tar.gz' --timings \n\nusing log directory \u2018/private/var/folders/ps/4zmxslc50ls5cxjpng935wpm0000gn/T/Rtmp9vQKu4/receptormarker.Rcheck\u2019\nusing R version 3.2.0 (2015-04-16)\nusing platform: x86_64-apple-darwin13.4.0 (64-bit)\nusing session charset: UTF-8\nchecking for file \u2018receptormarker/DESCRIPTION\u2019 ... OK\nchecking extension type ... Package\nthis is package \u2018receptormarker\u2019 version \u20180.0.0.9000\u2019\nchecking package namespace information ... OK\nchecking package dependencies ... OK\nchecking if this is a source package ... OK\nchecking if there is a namespace ... OK\nchecking for executable files ... OK\nchecking for hidden files and directories ... OK\nchecking for portable file names ... OK\nchecking for sufficient/correct file permissions ... OK\nchecking whether package \u2018receptormarker\u2019 can be installed ... OK\nchecking installed package size ... OK\nchecking package directory ... OK\nchecking DESCRIPTION meta-information ... OK\nchecking top-level files ... OK\nchecking for left-over files ... OK\nchecking index information ... OK\nchecking package subdirectories ... OK\nchecking R files for non-ASCII characters ... OK\nchecking R files for syntax errors ... OK\nchecking whether the package can be loaded ... OK\nchecking whether the package can be loaded with stated dependencies ... OK\nchecking whether the package can be unloaded cleanly ... OK\nchecking whether the namespace can be loaded with stated dependencies ... OK\nchecking whether the namespace can be unloaded cleanly ... OK\nchecking loading without being on the library search path ... OK\nchecking use of S3 registration ... OK\nchecking dependencies in R code ... NOTE\nNamespace in Imports field not imported from: \u2018fpc\u2019\n  All declared Imports should be used.\nchecking S3 generic/method consistency ... OK\nchecking replacement functions ... OK\nchecking foreign function calls ... OK\nchecking R code for possible problems ... OK\nchecking Rd files ... OK\nchecking Rd metadata ... OK\nchecking Rd line widths ... OK\nchecking Rd cross-references ... OK\nchecking for missing documentation entries ... OK\nchecking for code/documentation mismatches ... OK\nchecking Rd \\usage sections ... OK\nchecking Rd contents ... OK\nchecking for unstated dependencies in examples ... OK\nchecking examples ... OK\nchecking for unstated dependencies in \u2018tests\u2019 ... OK\nchecking tests ...\n  Running \u2018testthat.R\u2019\n OK\nchecking PDF version of manual ... OK\nDONE\n\nStatus: 1 NOTE\nSee\n  \u2018/private/var/folders/ps/4zmxslc50ls5cxjpng935wpm0000gn/T/Rtmp9vQKu4/receptormarker.Rcheck/00check.log\u2019\nfor details.\n```\nHere's a commit with the code. I'm going to update the title of the issue. The testthat code is below.\ntests/testthat/test_lint.R:\n``` R\ncontext(\"Lint package to verify code style\")\ntest_that(\"code conforms to the style guide\", {\n  lint_errs <- lintr::lint_package(linters=lintr::with_defaults(\n    trailing_whitespace_linter=NULL,\n    line_length_linter=lintr::line_length_linter(80)))\nlint_err_info <- \"\"\n  trim.leading <- function (x)  sub(\"^\\s+\", \"\", x)\n  if (length(lint_errs) > 0) {\n    # Some linters failed, build a variable to hold the linter error info:\n    k <- lapply(seq_along(lint_errs), function(y, i) {\n        x <- y[[i]]  # Set current list element to x\n        linted_file <- trim.leading(x[\"filename\"])\n        line_num <- x[\"line_number\"]\n        col_num <- x[\"column_number\"]\n        err_type <- x[\"type\"]\n        lint_msg <- x[\"message\"]\n        caret_pos <- as.numeric(x[\"column_number\"]) - 1\n        # Construct each lint failure's error message\n        err_num <- c(\"[[\", i, \"]]\")\n        err_info <- c(linted_file, \":\", line_num, \":\", col_num, \": \", err_type,\n                      \": \", lint_msg)\n        guilty_line <- as.character(x[\"line\"])\n        caret_str <- paste0(c(rep(\" \", caret_pos), \"^\", \"~\"), collapse=\"\")\n        paste0(c(err_num, \"\\n\",\n                 err_info, \"\\n\",\n                 guilty_line, \"\\n\",\n                 caret_str, \"\\n\\n\")\n               )\n      }\n      , y=lint_errs\n    )\n    lint_err_info <- lapply(k, function(x) {\n      trim.leading(paste0(as.character(unlist(x)), collapse=\"\"))\n    })\n  }\n  expect_that(length(lint_errs), equals(0), info=cat(unlist(lint_err_info)))\n})\n``\n. Ok, I'll try that. It seems like the behavior of devtools should be to fail still, since I'm just check list sizes and it failed intest, but what do I know! It is quite possible to use lintr's CRAN version still, which doesn't have the option pointed out by @jimhester. @jimhester, given the strange behaviors I saw with lintr and the commonly used devtools package it might be worth it to give a hard suggestion not to install via CRAN, or if possible update CRAN's version. The README or somewhere says to add lintr to Suggests... It becomes a bit confusing since it would seem acceptable to install lintr from CRAN at that point since Suggests would be checked against CRAN's version. Just my 2 cents. In any case, coming from the Python world the R community seems wonderful thus far; thanks for the support. It seems like the community needs a new solution to package management, though, with issues like this cropping up because there are two common ways to install and each repo has a different version. Perhaps there are restrictions by CRAN that prevent newer versions of lintr from going there... If so maybe those restrictions need to be rethought..? \n. After implementing the suggestion to use the lint expectation this issue still isn't solved.devtools::check()still passes even thoughdevtools::test()` fails.\n. ",
    "stanekam": "Mac OS X 10.9.5\n. ",
    "dcangst": "I have the same problem with Mac OS X 10.10.3 using an internal GitLab 7.6.2 repository.\nsessionInfo():\n```\nR version 3.2.0 (2015-04-16)\nPlatform: x86_64-apple-darwin13.4.0 (64-bit)\nRunning under: OS X 10.10.3 (Yosemite)\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] git2r_0.10.1        devtools_1.8.0.9000\nloaded via a namespace (and not attached):\n[1] memoise_0.2.1 digest_0.6.8 \n```\n. ",
    "c97sr": "Hi there, I'm getting a similar issue on ubuntu 14.04 with ssh installed. I had installed devtools without ther ssh2 dev library, but I fixed that and reinstalled git2r and then devtools. git2r now reports as happy with ssh, but I still can't get devtools to run install_git .\n\ninstall_git(\"c97sr/idd\")\nDownloading git repo c97sr/idd\nError in git2r::clone(x$url, bundle, credentials = x$credentials, progress = FALSE) : \n  Error in 'git2r_clone': Unsupported URL protocol\nlibgit2_features()\n$threads\n[1] FALSE\n\n$https\n[1] TRUE\n$ssh\n[1] TRUE\n. Yes - that makes sense. Thanks for the quick answer.\nOn 26 July 2016 at 13:14, Jim Hester notifications@github.com wrote:\n\n@c97sr https://github.com/c97sr Are you sure you want to use\ninstall_git() and not install_github(\"c97sr/idd)?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hadley/devtools/issues/819#issuecomment-235249788,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ADGGGQDFVZOl3aJWta3zbbeKVwO-pp4Jks5qZfoqgaJpZM4Eqrdb\n.\n\n\nProfessor of Infectious Disease Dynamics\nMRC Centre for Outbreak Analysis and Modelling\nDepartment of Infectious Disease Epidemiology\nSchool of Public Health, Imperial College London\n+44 207 594 2452 | goo.gl/m4KfhR | @SRileyIDD\n. ",
    "quantitative-technologies": "@jimhester I need install_git() because of this: \"Attempting to install from a source repository that uses submodules raises a warning. Because the zipped sources provided by GitHub do not include submodules, this may lead to unexpected behaviour or compilation failure in source packages. In this case, cloning the repository manually using install_git with args=\"--recursive\" may yield better results.\"\nHowever install_git() also gives me the error:\nError in 'git2r_clone': Unsupported URL protocol\n. ",
    "varadharajan": "Doc mentions \"install_local() from a local file on disk\". I'm sorry, probably i miss understood it, but isn't install_local meant for that?\ndevtools::install() works with local packages. If install_local is behaving as intended, please close this issue :)\n. Yeah.. It works fine with built packages. In devtools 1.6, it used to work fine with directories as well, but it now fails in 1.8 with the above failure. May be we can just update the docs with the details.\n. @hadley Sorry for the delay. I will update the thread by tomorrow.\n. @hadley  Looks like its fixed in master branch. I'm able to install packages successfully. \n. ",
    "bachmeil": "I'm using version 1.8. install_local installs without issue for one directory:\ninstall_local(\"path/to/package1\")\nbut fails for another:\ninstall_local(\"path/to/package2\")\nreturning\n\nError in validObject(.Object) :\ninvalid class \u201cgit_repository\u201d object: Invalid repository\n\nBoth are git repos, and both packages install without issue using older versions of devtools. I don't have a tarball in either directory.\n. ",
    "sboehringer": "I have the same problem.\nI have re-run install_local on a local project which used to work. Now I get the above error. So this is definitely a regression. I am on devtools_1.8.0\nA workaround for me is to zip up the package folder like so:\npkgPath = Sprintf('%{dir}Q/PredictionPenalized.tgz', dir = tempdir());\nSystem(Sprintf('tar czf %{pkgPath}Q ../PredictionPenalized'), 2);\ninstall_local(pkgPath);\n. ",
    "briencj": "I was under the misapprehension that using devtools::check with CRAN=TRUE is the same as running R CMD check with --as-cran. This is not the case and so I missed some errors when I submitted a package. I now use args = \"--as-cran\" with devtools::check and so far so good. However, it would be better if it was clearer what CRAN=TRUE does - I am still not sure.\n. My comment was more about the general problem of getting the same checking as CRAN does. To quote from the R CMD check --help: --as-cran selects customizations similar to those used for incoming cran checking. I do not know the technicalities of what is done, but I have found that I get error messages when using it that do not show when just CRAN=TRUE is used. One of my problems revolved around having the namespace for stats loaded by default when I run R and this namespace is not available when --as-cran is used. I do not know which version of the package (local or cran) is used to import the namespace of a package.\n. ",
    "StevenLOL": "Error when installing \u201cdevtools\u201d package for R in Ubuntu\n. ",
    "mbjones": "Yes, I'll change to use 'TRUE', and add a bullet to news in a revised PR.  More soon...\n. @hadley I made the changes you requested, and tests passed on my local Mac deployment, as well as in Travis.  I'm not clear on your development workflow -- do you want PRs to fix the codecov issues?  Or does this look good now?\n. ",
    "shanedp": "Just to follow up on this issue - no need for further comment. I just needed to install a newer version of r-base to get around the issues I was having. Ubuntu 14.04 will, by default, install version 3.0.2 by default, which is fairly old now. You can get around this by adding an entry to your sources.list file to point to one of the cran mirrors. \nInstructions on how to do that can be found here:\nhttp://cran.r-project.org/bin/linux/ubuntu/README\nOnce I did that, everything installed fine.\n. ",
    "moorepants": "It isn't clear to me why @shanedp's solution is the best solution here. Ubuntu 14.04 is supported until April 2019 so shouldn't installing devtools just work? Why is this an R core bug and not a devtools bug?\n. I disagree with you @wch. Ubuntu is the most widely used version of Linux which is released every six months and every two years it releases a long term support release, which 14.04 is the latest one. It is up to devtools to decide which versions of R to support. If devtools isn't willing to support the version of R that is available on one of the most widely installed versions of Linux, then it is a devtools bug, not Ubuntu one. As a software developer you should choose to support a reasonable range of versions for your dependencies. The choice to make devtools non-optionally dependent on xlm2 that depends on R >= 3.1.0 when R 3.0.2 is what is on Ubuntu 14.04 LTS (not to mention that 12.04 LTS is still supported and on many machines, e.g. Travis) doesn't seem that reasonable to me.\n. Thanks wch, I understand how to get the latest version of R on Ubuntu already. That's not really my issue. The issue is that there seems to be quite a few hoops to jump through to install devtools on the most recent LTS version of Ubuntu.\nI think we just disagree on this. I'm relatively new to the R world and am ignorant of the customs. I am probably just expecting it to be like the Python world (which I spend most of my time in). Any reputable Python package supports back to 2.4/5/6 some of which are over 10 years old and still in use on many systems. We typically decide on dropping Python version support based on what different OS's provide and surveys of users. I may not be a typical R user.\n. ",
    "vsbuffalo": "Ultimately uninstalling pkg-config from Homebrew worked.\n. Sorry to reopen this issue, but is inst/extdata the preferred method here? I think there's a case to be made that data should be in data/ (as recommended in the book R Packages) and load_all() should listen to LazyData: true in DESCRIPTION. . ",
    "leerichardson": "This didn't quite fix it. \nBut I ended up adding a vignette to the package, and then this ended up fixing the issue, no longer does dplyr in Suggests when building. \nThanks!!! The dev tools package incredibly useful.\n. ",
    "grishagin": "I've tried to look at the code in more detail, and here's what I found: foo.dll cannot be found. It is indeed not there, or anywhere else for that matter. \n``` R\n\nhas_devel\nfunction () \n{\n    foo_path <- file.path(tempdir(), \"foo.c\")\n    cat(\"void foo(int bar) { bar=1; }\\n\", file = foo_path)\n    on.exit(unlink(foo_path))\n    R(\"CMD SHLIB foo.c\", tempdir())\n    dylib <- file.path(tempdir(), paste(\"foo\", .Platform$dynlib.ext, \n        sep = \"\"))\n    on.exit(unlink(dylib), add = TRUE)\n    dll <- dyn.load(dylib)\n    on.exit(dyn.unload(dylib), add = TRUE)\n    stopifnot(.C(dll$foo, 0L)[[1]] == 1L)\n    TRUE\n}\n\nfoo_path <- file.path(tempdir(), \"foo.c\")\ncat(\"void foo(int bar) { bar=1; }\\n\", file = foo_path)\nfoo_path\n[1] \"C:\\Users\\GRISHA~1\\AppData\\Local\\Temp\\Rtmpi6gTQo/foo.c\"\non.exit(unlink(foo_path))\ndylib <- file.path(tempdir(), paste(\"foo\", .Platform$dynlib.ext, \n+                                     sep = \"\"))\ndylib\n[1] \"C:\\Users\\GRISHA~1\\AppData\\Local\\Temp\\Rtmpi6gTQo/foo.dll\"\non.exit(unlink(dylib), add = TRUE)\ndll <- dyn.load(dylib)\nError in inDL(x, as.logical(local), as.logical(now), ...) : \n  unable to load shared object 'C:/Users/GRISHA~1/AppData/Local/Temp/Rtmpi6gTQo/foo.dll':\n  LoadLibrary failure:  The specified module could not be found.\n```\n. Yes, the problem has been resolved, but I am not sure what was the culprit, or the solution for that matter! I simply quit trying for a while after I've exhausted all options. \nThe next time I tried to use devtools - it worked, but I already had updated to Windows 10 and had a different version of R. \nBottomline, it seems to be related to R talking to cmd in windows, and under certain specific circumstances unbeknownst to me, this process fails.\n. \n",
    "stanstrup": "devtools::install_github(\"stanstrup/PredRet\",subdir = \"PredRetR\", dependencies=FALSE, upgrade_dependencies=FALSE)\nStill tries to install  stanstrup/Rplot.extra even if it is already installed.\nAny solution for that?\nThe installed Rplot.extra was not specified as a remote in the currently installed version if that makes a difference.\nEDIT: install.packages(\"/usr/local/lib/R/PredRetR.tar.gz\", type=\"source\", dependencies=FALSE) works.\nr\nPackage: PredRetR\nVersion: 0.55\nDate: 2016-05-20\nTitle: PredRetR\nAuthor: Jan Stanstrup <stanstrup@gmail.com>\nMaintainer: Jan Stanstrup <stanstrup@gmail.com>\nDepends: R (>= 2.14.0), rmongodb, ggplot2, shiny\nSuggests: rCharts\nImports: stringr, mgcv, pracma, boot, parallel, plyr, reshape2, Rplot.extra, massageR, igraph, ini\nEnhances: \nDescription: Functions for PredRet prediction of retention times.\nLicense: GPL (>= 2)\nURL: None\nbiocViews: Metabolomics\nRemotes: stanstrup/Rplot.extra, stanstrup/massageR. ",
    "vladpetyuk": "A workaround is just set the type to \"source\" by default.  However, this will make all the packages to be installed as \"source\".\nr\noptions(pkgType=\"source\")\n. ",
    "eibanez": "Will this catch the new requirement that functions from all packages other than base (e.g., utils) need to be explicitly imported?\n. Excellent. Thanks, Hadley.\nOn Tuesday, July 28, 2015, Hadley Wickham notifications@github.com wrote:\n\n@elbanez yes, if you're using R-devel\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/866#issuecomment-125656554.\n. \n",
    "carljv": "As a workaround, I've just put the raw/unbuilt source in the repo, so we can use install_github (which doesn't seem to work for built packages). \n. No -- should I?\ndevtools  * 1.8.0   2015-05-09 CRAN (R 3.2.0)\n. ",
    "brry": "Awesome. (I use it in Rprofile to install the package I'm developing if there is a more recent version on my harddrive than currently installed. I tend to forget to RCMD INSTALL at the end of the day and later wonder where my fixes went.)\n. ~~I do not have the problem anymore. Change date for vignettes/bF.Rmd is 2016-10-13 21:55, while in inst/doc/bF.Rmd its 2017-01-16 12:38.~~\nI do not get CRAN warnings anymore, presumably they relaxed the test...\nSo for me, this is not a significant problem anymore. If CRAN is happy, I am happy ;-)\nIn the generated tar.gz file, the vignettes/.Rmd now is 3 seconds newer than the (derivated) inst/doc/.Rmd file. . ",
    "jpmarindiaz": "I am having the same issue, cannot install any package using devtools.\n@hadley Any ideas?\n```\n\ndevtools::install_github('rstudio/shinyapps')\nDownloading github repo rstudio/shinyapps@master\nError in curl::curl_fetch_memory(url, handle = handle) : \n  Couldn't connect to server\nsessionInfo()\nR version 3.2.1 (2015-06-18)\nPlatform: x86_64-apple-darwin13.4.0 (64-bit)\nRunning under: OS X 10.10.4 (Yosemite)\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.8.0  httr_1.0.0.9000 RCurl_1.95-4.7  bitops_1.0-6   \nloaded via a namespace (and not attached):\n [1] R6_2.1.0         magrittr_1.5     rversions_1.0.2  tools_3.2.1      rstudioapi_0.3.1\n [6] curl_0.9.1       Rcpp_0.12.0      memoise_0.2.1    xml2_0.1.1       stringi_0.5-5 \n[11] git2r_0.10.1     stringr_1.0.0    digest_0.6.8 \n``\n. On Mac, by usingoptions(download.file.method = \"libcurl\")` it works for public packages.\nBut I am getting the same error for private packages on Github.\n. ",
    "ncdingari": "You might be behind firewall, need to use proxy settings from 'httr' package. I could solve the issue using proxy settings. Please check if you can access github and then use proxy settings.\n. ",
    "luiandresgonzalez": "Hi, \nI'm having a similar issue and I'm sure I'm not using a proxy (I don't know a formal test to this, but every other service in my computer that would require a proxy config is not having any issue). Other people are reporting similar cases (see http://stackoverflow.com/questions/38263920/unable-to-install-r-package-from-github). \nI tried a clean uninstall - reinstall of everything from r-base to libcurl and the problem persists. I'm running Ubuntu Mate 16.04. \n```\n\nsession_info()\nSession info -------------------------------------------------------------------------------------\n setting  value                     \n version  R version 3.2.3 (2015-12-10)\n system   x86_64, linux-gnu         \n ui       RStudio (0.99.903)        \n language en_US                     \n collate  en_US.UTF-8               \n tz       America/Sao_Paulo         \n date     2016-07-31                  \n\nPackages -----------------------------------------------------------------------------------------\n package  * version date       source      \n curl       1.1     2016-07-26 CRAN (R 3.2.3)\n devtools * 1.12.0  2016-06-24 CRAN (R 3.2.3)\n digest     0.6.9   2016-01-08 CRAN (R 3.2.3)\n git2r      0.15.0  2016-05-11 CRAN (R 3.2.3)\n httr     * 1.2.1   2016-07-03 CRAN (R 3.2.3)\n knitr      1.13    2016-05-09 cran (@1.13)\n memoise    1.0.0   2016-01-29 CRAN (R 3.2.3)\n R6         2.1.2   2016-01-26 CRAN (R 3.2.3)\n withr      1.0.2   2016-06-20 CRAN (R 3.2.3)\n```\n. In my case it was solved by mannually changing the DNS server to an OpenDNS or Google's. \n. ",
    "sainathadapa": "There seems to be a problem with curl in Ubuntu 16.04. I am facing similar problem with devtools::install_github, and also with xml2::read_html. I am not behind a proxy or firewall.\n```\n\nlibrary(devtools)\nlibrary(rvest)\nLoading required package: xml2\nread_html('https://github.com/hadley/devtools/issues/877')\nError in open.connection(x, \"rb\") : Timeout was reached\nsession_info()\nSession info ---------------------------------------------------------------------------------------------------\n setting  value                     \n version  R version 3.3.1 (2016-06-21)\n system   x86_64, linux-gnu         \n ui       RStudio (99.9.9)          \n language en_IN:en                  \n collate  en_US.UTF-8               \n tz       Asia/Calcutta             \n date     2016-08-13                  \n\nPackages -------------------------------------------------------------------------------------------------------\n package  * version date       source      \n curl       1.1     2016-07-26 CRAN (R 3.3.1)\n devtools * 1.12.0  2016-06-24 CRAN (R 3.3.1)\n digest     0.6.10  2016-08-02 CRAN (R 3.3.1)\n httr       1.2.1   2016-07-03 CRAN (R 3.3.1)\n magrittr   1.5     2014-11-22 CRAN (R 3.3.0)\n memoise    1.0.0   2016-01-29 CRAN (R 3.3.0)\n R6         2.1.2   2016-01-26 CRAN (R 3.3.0)\n Rcpp       0.12.6  2016-07-19 CRAN (R 3.3.1)\n rvest    * 0.3.2   2016-06-17 CRAN (R 3.3.1)\n withr      1.0.2   2016-06-20 CRAN (R 3.3.0)\n xml2     * 1.0.0   2016-06-24 CRAN (R 3.3.1)\n```\nEdit: There is now a open issue posted related to this- https://github.com/jeroenooms/curl/issues/72\n. ",
    "iPALVIKAS": "Trying this option worked for me.\nlibrary(httr)\nwith_config(use_proxy(...), install_github(...))\nOR\nlibrary(httr)\nset_config(use_proxy(url = \"*_\", port = \"_\"))\ndevtools::install_github(\"username/packagename\")\nThanks to @hadley \n. ",
    "mtuchmanLumeris": "It would be helpful to know what arguments to use for use_proxy. All the replies are very vague on this point.. ",
    "samuel-rosa": "Solved installing the latest version with:\ndevtools::install_github(\"hadley/devtools\")\nThe problem occurs when using the current CRAN version.\n. ",
    "ClaytonJY": "@robinsonjj posted this to git2r as https://github.com/ropensci/git2r/issues/176, which has been fixed quite recently, but I'm still getting a failure:\n```r\n\ndevtools::install_git(\"https://github.com/r-lib/httr.git\", branch = \"v1.3.1\")\n\nDownloading git repo https://github.com/r-lib/httr.git\nInstallation failed: 'head' is not an exported object from 'namespace:git2r'\n``\n(The second line used to beInstallation failed: 'v1.3.1' did not match any branch`.)\nCan confirm that the checkout example posted on the git2r issue does work, which makes me think it may now be a devtools issue, though I'm far from certain. Can't see where devtools or git2r refer to just head.\n\nSession Info\n\n```r\n> devtools::session_info(c(\"devtools\", \"git2r\"))\nSession info ------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n setting  value                       \n version  R version 3.4.4 (2018-03-15)\n system   x86_64, linux-gnu           \n ui       RStudio (1.1.383)           \n language (EN)                        \n collate  en_US.UTF-8                 \n tz       America/New_York            \n date     2018-05-18                  \n\nPackages ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n package    * version     date       source                         \n curl         3.2         2018-03-28 CRAN (R 3.4.4)                 \n devtools     1.13.5      2018-05-18 local                          \n digest       0.6.15      2018-01-28 CRAN (R 3.4.4)                 \n git2r        0.21.0.9002 2018-05-18 Github (ropensci/git2r@dcb3d91)\n graphics   * 3.4.4       2018-03-16 local                          \n grDevices  * 3.4.4       2018-03-16 local                          \n httr         1.3.1       2017-08-20 CRAN (R 3.4.4)                 \n jsonlite     1.5         2017-06-01 CRAN (R 3.4.4)                 \n memoise      1.1.0       2017-04-21 CRAN (R 3.4.4)                 \n methods    * 3.4.4       2018-03-16 local                          \n mime         0.5         2016-07-07 CRAN (R 3.4.4)                 \n openssl      1.0.1       2018-03-03 CRAN (R 3.4.4)                 \n R6           2.2.2       2017-06-17 CRAN (R 3.4.4)                 \n rstudioapi   0.7         2017-09-07 CRAN (R 3.4.4)                 \n stats      * 3.4.4       2018-03-16 local                          \n tools        3.4.4       2018-03-16 local                          \n utils      * 3.4.4       2018-03-16 local                          \n whisker      0.3-2       2013-04-28 CRAN (R 3.4.4)                 \n withr        2.1.2       2018-03-15 CRAN (R 3.4.4) \n```\n\n. Oh wow I had installed the latest devtools but R hadn't picked it up; you're right, github version makes it work! Sorry for the bother, thanks for the quick response.. @jimhester Could this issue be reopened? I'm having a very similar issue; package loaded in testthat.R is loaded as expected with devtools::check(), but not with devtools::test(). In this case I'm loading checkmate to extend the testthat assertions, so the failure when test()-ing is that it can't find the checkmate function I use first.\nI would think the idea is for testing to be done exactly the same way in both testing and checking, but that appears to not be the case in version 1.13.5.9000 (current github).\nDoes this issue belong in one of the new diaspora packages? Not clear which one handles testing functionality.. @jimhester thanks for the quick response; does that mean when using devtools,  the testthat.R file should never contain anything but the following?\n```r\nlibrary(testthat)\ntest_check(\"mypackage\")\n```\ne.g. anything beyond that is custom logic that needs to go in a helper* file?. gotcha, thanks @jimhester. ",
    "johann-petrak": "I think the cleaner solution would be for the tool to know which files get generated. Having a method that removes everything that gets generated would be helpful independently of the used VCS and for other tasks too. But a .gitignore file would also be helpful if devtools generates it and pre-fills it with the list of files/patterns of what gets generated. But the basic point is that the authors of the tools usually know better which files these are than the end-user. \nTBH I have submitted this because I am a noob and I feel that others know better which files to not check in.\nSo, from my noob perspective, I think ideally the clean() method would remove all the *.Rd files that got generated, the NAMESPACE file, other files generated by roxygen2, any compiled files, and probably others I do not even know about yet. \nAgain, experienced users or the tool authors probably know much better the detailed list.\n. ",
    "sabas": "```\n\nfile.path(R.home(\"bin\"), \"R\")\n[1] \"C:/Program Files/R/R-32~1.0/bin/x64/R\"\nnormalizePath(file.path(R.home(\"bin\"), \"R\"))\n[1] \"C:\\Program Files\\R\\R-32~1.0\\bin\\x64\\R\"\nWarning message:\nIn normalizePath(path.expand(path), winslash, mustWork) :\n  path[1]=\"C:/Program Files/R/R-32~1.0/bin/x64/R\": Impossibile trovare il file specificato\n```\n\nImpossibile trovare il file specificato = File not found\nedit\nThe executable is C:\\Program Files\\R\\R-3.2.0\\bin\\x64\\R.exe\n. ```\n\nnormalizePath(R.home(\"bin\"))\n[1] \"C:\\Program Files\\R\\R-3.2.0\\bin\\x64\"\nSys.getenv(\"R_HOME\")\n[1] \"C:/Program Files/R/R-32~1.0\"\n```\n\n@kevinushey I believe not, I'm trying on a pc where I used just rstudio a couple of times (the commands you both suggested were tried on R and Rstudio)\n. ```\n\nshortPathName(R.home(\"bin\"))\n[1] \"C:\\Program Files\\R\\R-32~1.0\\bin\\x64\"\n.\nif (file.exists(\"~/.Rprofile\"))\n+     readLines(\"~/.Rprofile\")\nif (file.exists(\"~/.Renviron\"))\n+     readLines(\"~/.Renviron\")\nSys.getenv()[grep(\"^R_\", names(Sys.getenv()))]\nR_ARCH                  /x64\nR_HOME                  C:/Program Files/R/R-32~1.0\nR_LIBS_USER             C:\\Users\\sabas\\Documents/R/win-library/3.2\nR_USER                  C:\\Users\\sabas\\Documents\n```\n. \n",
    "annennenne": "Was this issue ever resolved? I'm experiencing the same thing, but with an interesting twist. I'm trying to use devtools::install() on two different computers, both running the same Windows version and the same version of devtools. On one, install() executes as expected, but on the other, I get the same error message as in the above: \n``` r eval=F\n\ninstall()\nInstalling cleanR\n\"C:/Program Files/R/R-3.3.1/bin/x64/R\" --no-site-file --no-environ --no-save  \\\n  --no-restore --quiet CMD INSTALL \"P:/Alkoholprojekt/R/cleanR\" --library=\"C:/Program  \\\n  Files/R/R-3.3.1/library\" --install-tests \n\n'C:\\Program' blev ikke genkendt som en intern eller ekstern kommando,\net program eller en batchfil.\nError: Command failed (1)\"\n```\n(now in Danish, but same error).\nsession_info() from computer 1 (where it works):\n``` r, eval=F\n\nsession_info()\nSession info -------------------------------------------------------------\n setting  value                     \n version  R version 3.2.3 (2015-12-10)\n system   x86_64, mingw32           \n ui       RStudio (0.99.491)        \n language (EN)                      \n collate  Danish_Denmark.1252       \n tz       Europe/Paris              \n date     2016-10-13                  \n\nPackages -----------------------------------------------------------------\n package    * version date       source                  \n cleanR     * 0.4     2016-10-13 local (ekstroem/cleanR@NA)\n colorspace   1.2-7   2016-10-11 CRAN (R 3.2.5)          \n devtools   * 1.12.0  2016-06-24 CRAN (R 3.2.5)          \n digest       0.6.10  2016-08-02 CRAN (R 3.2.5)          \n ggplot2    * 2.1.0   2016-03-01 CRAN (R 3.2.5)          \n git2r        0.15.0  2016-05-11 CRAN (R 3.2.5)          \n gtable       0.2.0   2016-02-26 CRAN (R 3.2.5)          \n memoise      1.0.0   2016-01-29 CRAN (R 3.2.5)          \n munsell      0.4.3   2016-02-13 CRAN (R 3.2.3)          \n pander     * 0.6.0   2015-11-23 CRAN (R 3.2.5)          \n plyr         1.8.4   2016-06-08 CRAN (R 3.2.5)          \n Rcpp         0.12.7  2016-09-05 CRAN (R 3.2.5)          \n scales       0.4.0   2016-02-26 CRAN (R 3.2.5)          \n withr        1.0.1   2016-02-04 CRAN (R 3.2.5)    \n```\nsession_info() from computer 2 (where it does not work):\n``` r, eval=F\n\nsession_info()\nSession info ---------------------------------------------------------------------------\n setting  value                     \n version  R version 3.3.1 (2016-06-21)\n system   x86_64, mingw32           \n ui       RStudio (0.99.903)        \n language (EN)                      \n collate  Danish_Denmark.1252       \n tz       Europe/Paris              \n date     2016-10-13                  \n\nPackages -------------------------------------------------------------------------------\n package    * version date       source      \n devtools   * 1.12.0  2016-06-24 CRAN (R 3.3.1)\n digest       0.6.10  2016-08-02 CRAN (R 3.2.5)\n memoise      1.0.0   2016-01-29 CRAN (R 3.2.5)\n rstudioapi   0.6     2016-06-27 CRAN (R 3.2.5)\n withr        1.0.2   2016-06-20 CRAN (R 3.2.5)\n```\nI just updated R on computer 2 and it didn't work with R 3.2.2. either.\n. Okay, I've tried it and the results are posted below. I noticed the following differences:\n- On both computer 1 and computer 2, my system function seems to differ from yours. Is that an OS thing?\n- The command output differs on computer 1 and computer 2.  And so does the dput(charToRaw(command)) output.\nI seems like the results are not sensitive to whether I run it in RStudio or RGui. Also, I checked if the error still occurs using RGui on computer 2 (and similarly, if install() works on computer 1), and it's just the same as in RStudio. \nComputer 1 (where it works) - Rstudio\n``` r, eval=F\n\nlibrary(devtools)\nWarning message:\npakke \u2018devtools\u2019 blev bygget under R version 3.2.5 \ndebug(system)\ninstall()\nInstalling cleanR\n\"C:/PROGRA~1/R/R-32~1.3/bin/x64/R\" --no-site-file --no-environ  \\\n  --no-save --no-restore --quiet CMD INSTALL  \\\n  \"C:/Users/zms499/Documents/cleanR\" --library=\"C:/Program  \\\n  Files/R/R-3.2.3/library\" --install-tests \n\ndebugging in: system(full, intern = quiet, ignore.stderr = quiet, ...)\ndebug: {\n    if (!is.logical(intern) || is.na(intern)) \n        stop(\"'intern' must be TRUE or FALSE\")\n    if (!is.logical(ignore.stdout) || is.na(ignore.stdout)) \n        stop(\"'ignore.stdout' must be TRUE or FALSE\")\n    if (!is.logical(ignore.stderr) || is.na(ignore.stderr)) \n        stop(\"'ignore.stderr' must be TRUE or FALSE\")\n    if (!is.logical(wait) || is.na(wait)) \n        stop(\"'wait' must be TRUE or FALSE\")\n    if (!is.logical(show.output.on.console) || is.na(show.output.on.console)) \n        stop(\"'show.output.on.console' must be TRUE or FALSE\")\n    if (!is.logical(minimized) || is.na(minimized)) \n        stop(\"'minimized' must be TRUE or FALSE\")\n    if (!is.logical(invisible) || is.na(invisible)) \n        stop(\"'invisible' must be TRUE or FALSE\")\n    stdout <- ifelse(ignore.stdout, FALSE, \"\")\n    stderr <- ifelse(ignore.stderr, FALSE, \"\")\n    f <- \"\"\n    if (!is.null(input)) {\n        f <- tempfile()\n        on.exit(unlink(f))\n        writeLines(input, f)\n    }\n    if (intern) {\n        flag <- 3L\n        if (stdout == \"\") \n            stdout <- TRUE\n        if (!ignore.stderr && .Platform$GUI == \"Rgui\") \n            stderr <- TRUE\n    }\n    else {\n        flag <- if (wait) \n            ifelse(show.output.on.console, 2L, 1L)\n        else 0L\n    }\n    if (invisible) \n        flag <- 20L + flag\n    else if (minimized) \n        flag <- 10L + flag\n    .Internal(system(command, as.integer(flag), f, stdout, stderr))\n}\nBrowse[2]> \ndebug: if (!is.logical(intern) || is.na(intern)) stop(\"'intern' must be TRUE or FALSE\")\nBrowse[2]> command\n[1] \"\\\"C:/PROGRA~1/R/R-32~1.3/bin/x64/R\\\" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \\\"C:/Users/zms499/Documents/cleanR\\\" --library=\\\"C:/Program Files/R/R-3.2.3/library\\\" --install-tests \"\nBrowse[2]> Encoding(command)\n[1] \"unknown\"\nBrowse[2]> dput(charToRaw(command))\nas.raw(c(0x22, 0x43, 0x3a, 0x2f, 0x50, 0x52, 0x4f, 0x47, 0x52, \n0x41, 0x7e, 0x31, 0x2f, 0x52, 0x2f, 0x52, 0x2d, 0x33, 0x32, 0x7e, \n0x31, 0x2e, 0x33, 0x2f, 0x62, 0x69, 0x6e, 0x2f, 0x78, 0x36, 0x34, \n0x2f, 0x52, 0x22, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x73, 0x69, \n0x74, 0x65, 0x2d, 0x66, 0x69, 0x6c, 0x65, 0x20, 0x2d, 0x2d, 0x6e, \n0x6f, 0x2d, 0x65, 0x6e, 0x76, 0x69, 0x72, 0x6f, 0x6e, 0x20, 0x2d, \n0x2d, 0x6e, 0x6f, 0x2d, 0x73, 0x61, 0x76, 0x65, 0x20, 0x2d, 0x2d, \n0x6e, 0x6f, 0x2d, 0x72, 0x65, 0x73, 0x74, 0x6f, 0x72, 0x65, 0x20, \n0x2d, 0x2d, 0x71, 0x75, 0x69, 0x65, 0x74, 0x20, 0x43, 0x4d, 0x44, \n0x20, 0x49, 0x4e, 0x53, 0x54, 0x41, 0x4c, 0x4c, 0x20, 0x22, 0x43, \n0x3a, 0x2f, 0x55, 0x73, 0x65, 0x72, 0x73, 0x2f, 0x7a, 0x6d, 0x73, \n0x34, 0x39, 0x39, 0x2f, 0x44, 0x6f, 0x63, 0x75, 0x6d, 0x65, 0x6e, \n0x74, 0x73, 0x2f, 0x63, 0x6c, 0x65, 0x61, 0x6e, 0x52, 0x22, 0x20, \n0x2d, 0x2d, 0x6c, 0x69, 0x62, 0x72, 0x61, 0x72, 0x79, 0x3d, 0x22, \n0x43, 0x3a, 0x2f, 0x50, 0x72, 0x6f, 0x67, 0x72, 0x61, 0x6d, 0x20, \n0x46, 0x69, 0x6c, 0x65, 0x73, 0x2f, 0x52, 0x2f, 0x52, 0x2d, 0x33, \n0x2e, 0x32, 0x2e, 0x33, 0x2f, 0x6c, 0x69, 0x62, 0x72, 0x61, 0x72, \n0x79, 0x22, 0x20, 0x2d, 0x2d, 0x69, 0x6e, 0x73, 0x74, 0x61, 0x6c, \n0x6c, 0x2d, 0x74, 0x65, 0x73, 0x74, 0x73, 0x20))\n```\nComputer 1, RGui\n``` r, eval=F\n\nlibrary(devtools)\nAdvarselsbesked:\npakke \u2018devtools\u2019 blev bygget under R version 3.2.5 \ndebug(system)\ninstall()\nInstalling cleanR\n\"C:/PROGRA~1/R/R-32~1.3/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \"C:/Users/zms499/Documents/cleanR\"  \\\n  --library=\"C:/Program Files/R/R-3.2.3/library\" --install-tests \n\ndebugging in: system(full, intern = quiet, ignore.stderr = quiet, ...)\ndebug: {\n    if (!is.logical(intern) || is.na(intern)) \n        stop(\"'intern' must be TRUE or FALSE\")\n    if (!is.logical(ignore.stdout) || is.na(ignore.stdout)) \n        stop(\"'ignore.stdout' must be TRUE or FALSE\")\n    if (!is.logical(ignore.stderr) || is.na(ignore.stderr)) \n        stop(\"'ignore.stderr' must be TRUE or FALSE\")\n    if (!is.logical(wait) || is.na(wait)) \n        stop(\"'wait' must be TRUE or FALSE\")\n    if (!is.logical(show.output.on.console) || is.na(show.output.on.console)) \n        stop(\"'show.output.on.console' must be TRUE or FALSE\")\n    if (!is.logical(minimized) || is.na(minimized)) \n        stop(\"'minimized' must be TRUE or FALSE\")\n    if (!is.logical(invisible) || is.na(invisible)) \n        stop(\"'invisible' must be TRUE or FALSE\")\n    stdout <- ifelse(ignore.stdout, FALSE, \"\")\n    stderr <- ifelse(ignore.stderr, FALSE, \"\")\n    f <- \"\"\n    if (!is.null(input)) {\n        f <- tempfile()\n        on.exit(unlink(f))\n        writeLines(input, f)\n    }\n    if (intern) {\n        flag <- 3L\n        if (stdout == \"\") \n            stdout <- TRUE\n        if (!ignore.stderr && .Platform$GUI == \"Rgui\") \n            stderr <- TRUE\n    }\n    else {\n        flag <- if (wait) \n            ifelse(show.output.on.console, 2L, 1L)\n        else 0L\n    }\n    if (invisible) \n        flag <- 20L + flag\n    else if (minimized) \n        flag <- 10L + flag\n    .Internal(system(command, as.integer(flag), f, stdout, stderr))\n}\nBrowse[2]> command\n[1] \"\\\"C:/PROGRA~1/R/R-32~1.3/bin/x64/R\\\" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \\\"C:/Users/zms499/Documents/cleanR\\\" --library=\\\"C:/Program Files/R/R-3.2.3/library\\\" --install-tests \"\nBrowse[2]> Encoding(command)\n[1] \"unknown\"\nBrowse[2]> dput(charToRaw(command)\n+ )\nas.raw(c(0x22, 0x43, 0x3a, 0x2f, 0x50, 0x52, 0x4f, 0x47, 0x52, \n0x41, 0x7e, 0x31, 0x2f, 0x52, 0x2f, 0x52, 0x2d, 0x33, 0x32, 0x7e, \n0x31, 0x2e, 0x33, 0x2f, 0x62, 0x69, 0x6e, 0x2f, 0x78, 0x36, 0x34, \n0x2f, 0x52, 0x22, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x73, 0x69, \n0x74, 0x65, 0x2d, 0x66, 0x69, 0x6c, 0x65, 0x20, 0x2d, 0x2d, 0x6e, \n0x6f, 0x2d, 0x65, 0x6e, 0x76, 0x69, 0x72, 0x6f, 0x6e, 0x20, 0x2d, \n0x2d, 0x6e, 0x6f, 0x2d, 0x73, 0x61, 0x76, 0x65, 0x20, 0x2d, 0x2d, \n0x6e, 0x6f, 0x2d, 0x72, 0x65, 0x73, 0x74, 0x6f, 0x72, 0x65, 0x20, \n0x2d, 0x2d, 0x71, 0x75, 0x69, 0x65, 0x74, 0x20, 0x43, 0x4d, 0x44, \n0x20, 0x49, 0x4e, 0x53, 0x54, 0x41, 0x4c, 0x4c, 0x20, 0x22, 0x43, \n0x3a, 0x2f, 0x55, 0x73, 0x65, 0x72, 0x73, 0x2f, 0x7a, 0x6d, 0x73, \n0x34, 0x39, 0x39, 0x2f, 0x44, 0x6f, 0x63, 0x75, 0x6d, 0x65, 0x6e, \n0x74, 0x73, 0x2f, 0x63, 0x6c, 0x65, 0x61, 0x6e, 0x52, 0x22, 0x20, \n0x2d, 0x2d, 0x6c, 0x69, 0x62, 0x72, 0x61, 0x72, 0x79, 0x3d, 0x22, \n0x43, 0x3a, 0x2f, 0x50, 0x72, 0x6f, 0x67, 0x72, 0x61, 0x6d, 0x20, \n0x46, 0x69, 0x6c, 0x65, 0x73, 0x2f, 0x52, 0x2f, 0x52, 0x2d, 0x33, \n0x2e, 0x32, 0x2e, 0x33, 0x2f, 0x6c, 0x69, 0x62, 0x72, 0x61, 0x72, \n0x79, 0x22, 0x20, 0x2d, 0x2d, 0x69, 0x6e, 0x73, 0x74, 0x61, 0x6c, \n0x6c, 0x2d, 0x74, 0x65, 0x73, 0x74, 0x73, 0x20))\n```\nComputer 2 (where it doesn't work) - Rstudio\n``` r, eval=F\n\nlibrary(devtools)\ndebug(system)\ninstall()\nInstalling cleanR\n\"C:/Program Files/R/R-3.3.1/bin/x64/R\" --no-site-file --no-environ --no-save  \\\n  --no-restore --quiet CMD INSTALL \"P:/Alkoholprojekt/R/cleanR\" --library=\"C:/Program  \\\n  Files/R/R-3.3.1/library\" --install-tests \n\ndebugging in: system(full, intern = quiet, ignore.stderr = quiet, ...)\ndebug: {\n    if (!is.logical(intern) || is.na(intern)) \n        stop(\"'intern' must be TRUE or FALSE\")\n    if (!is.logical(ignore.stdout) || is.na(ignore.stdout)) \n        stop(\"'ignore.stdout' must be TRUE or FALSE\")\n    if (!is.logical(ignore.stderr) || is.na(ignore.stderr)) \n        stop(\"'ignore.stderr' must be TRUE or FALSE\")\n    if (!is.logical(wait) || is.na(wait)) \n        stop(\"'wait' must be TRUE or FALSE\")\n    if (!is.logical(show.output.on.console) || is.na(show.output.on.console)) \n        stop(\"'show.output.on.console' must be TRUE or FALSE\")\n    if (!is.logical(minimized) || is.na(minimized)) \n        stop(\"'minimized' must be TRUE or FALSE\")\n    if (!is.logical(invisible) || is.na(invisible)) \n        stop(\"'invisible' must be TRUE or FALSE\")\n    stdout <- ifelse(ignore.stdout, FALSE, \"\")\n    stderr <- ifelse(ignore.stderr, FALSE, \"\")\n    f <- \"\"\n    if (!is.null(input)) {\n        f <- tempfile()\n        on.exit(unlink(f))\n        writeLines(input, f)\n    }\n    if (intern) {\n        flag <- 3L\n        if (stdout == \"\") \n            stdout <- TRUE\n        if (!ignore.stderr && .Platform$GUI == \"Rgui\") \n            stderr <- TRUE\n    }\n    else {\n        flag <- if (wait) \n            ifelse(show.output.on.console, 2L, 1L)\n        else 0L\n    }\n    if (invisible) \n        flag <- 20L + flag\n    else if (minimized) \n        flag <- 10L + flag\n    .Internal(system(command, as.integer(flag), f, stdout, stderr))\n}\nBrowse[2]> command\n[1] \"\\\"C:/Program Files/R/R-3.3.1/bin/x64/R\\\" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \\\"P:/Alkoholprojekt/R/cleanR\\\" --library=\\\"C:/Program Files/R/R-3.3.1/library\\\" --install-tests \"\nBrowse[2]> Encoding(command)\n[1] \"unknown\"\nBrowse[2]> dput(charToRaw(command))\nas.raw(c(0x22, 0x43, 0x3a, 0x2f, 0x50, 0x72, 0x6f, 0x67, 0x72, \n0x61, 0x6d, 0x20, 0x46, 0x69, 0x6c, 0x65, 0x73, 0x2f, 0x52, 0x2f, \n0x52, 0x2d, 0x33, 0x2e, 0x33, 0x2e, 0x31, 0x2f, 0x62, 0x69, 0x6e, \n0x2f, 0x78, 0x36, 0x34, 0x2f, 0x52, 0x22, 0x20, 0x2d, 0x2d, 0x6e, \n0x6f, 0x2d, 0x73, 0x69, 0x74, 0x65, 0x2d, 0x66, 0x69, 0x6c, 0x65, \n0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x65, 0x6e, 0x76, 0x69, 0x72, \n0x6f, 0x6e, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x73, 0x61, 0x76, \n0x65, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x72, 0x65, 0x73, 0x74, \n0x6f, 0x72, 0x65, 0x20, 0x2d, 0x2d, 0x71, 0x75, 0x69, 0x65, 0x74, \n0x20, 0x43, 0x4d, 0x44, 0x20, 0x49, 0x4e, 0x53, 0x54, 0x41, 0x4c, \n0x4c, 0x20, 0x22, 0x50, 0x3a, 0x2f, 0x41, 0x6c, 0x6b, 0x6f, 0x68, \n0x6f, 0x6c, 0x70, 0x72, 0x6f, 0x6a, 0x65, 0x6b, 0x74, 0x2f, 0x52, \n0x2f, 0x63, 0x6c, 0x65, 0x61, 0x6e, 0x52, 0x22, 0x20, 0x2d, 0x2d, \n0x6c, 0x69, 0x62, 0x72, 0x61, 0x72, 0x79, 0x3d, 0x22, 0x43, 0x3a, \n0x2f, 0x50, 0x72, 0x6f, 0x67, 0x72, 0x61, 0x6d, 0x20, 0x46, 0x69, \n0x6c, 0x65, 0x73, 0x2f, 0x52, 0x2f, 0x52, 0x2d, 0x33, 0x2e, 0x33, \n0x2e, 0x31, 0x2f, 0x6c, 0x69, 0x62, 0x72, 0x61, 0x72, 0x79, 0x22, \n0x20, 0x2d, 0x2d, 0x69, 0x6e, 0x73, 0x74, 0x61, 0x6c, 0x6c, 0x2d, \n0x74, 0x65, 0x73, 0x74, 0x73, 0x20))\n```\nComputer 2, RGui\n``` r, eval=F\n\nlibrary(devtools)\ndebug(system)\ninstall()\nInstalling cleanR\n\"C:/Program Files/R/R-3.3.1/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \"P:/Alkoholprojekt/R/cleanR\" --library=\"C:/Program Files/R/R-3.3.1/library\" --install-tests \n\ndebugging in: system(full, intern = quiet, ignore.stderr = quiet, ...)\ndebug: {\n    if (!is.logical(intern) || is.na(intern)) \n        stop(\"'intern' must be TRUE or FALSE\")\n    if (!is.logical(ignore.stdout) || is.na(ignore.stdout)) \n        stop(\"'ignore.stdout' must be TRUE or FALSE\")\n    if (!is.logical(ignore.stderr) || is.na(ignore.stderr)) \n        stop(\"'ignore.stderr' must be TRUE or FALSE\")\n    if (!is.logical(wait) || is.na(wait)) \n        stop(\"'wait' must be TRUE or FALSE\")\n    if (!is.logical(show.output.on.console) || is.na(show.output.on.console)) \n        stop(\"'show.output.on.console' must be TRUE or FALSE\")\n    if (!is.logical(minimized) || is.na(minimized)) \n        stop(\"'minimized' must be TRUE or FALSE\")\n    if (!is.logical(invisible) || is.na(invisible)) \n        stop(\"'invisible' must be TRUE or FALSE\")\n    stdout <- ifelse(ignore.stdout, FALSE, \"\")\n    stderr <- ifelse(ignore.stderr, FALSE, \"\")\n    f <- \"\"\n    if (!is.null(input)) {\n        f <- tempfile()\n        on.exit(unlink(f))\n        writeLines(input, f)\n    }\n    if (intern) {\n        flag <- 3L\n        if (stdout == \"\") \n            stdout <- TRUE\n        if (!ignore.stderr && .Platform$GUI == \"Rgui\") \n            stderr <- TRUE\n    }\n    else {\n        flag <- if (wait) \n            ifelse(show.output.on.console, 2L, 1L)\n        else 0L\n    }\n    if (invisible) \n        flag <- 20L + flag\n    else if (minimized) \n        flag <- 10L + flag\n    .Internal(system(command, as.integer(flag), f, stdout, stderr))\n}\nBrowse[2]> Q\n\nsetwd(\"P:/Alkoholprojekt/R/cleanR\")\nlibrary(devtools)\ndebug(system)\ninstall()\nInstalling cleanR\n\"C:/Program Files/R/R-3.3.1/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \"P:/Alkoholprojekt/R/cleanR\" --library=\"C:/Program Files/R/R-3.3.1/library\" --install-tests \n\ndebugging in: system(full, intern = quiet, ignore.stderr = quiet, ...)\ndebug: {\n    if (!is.logical(intern) || is.na(intern)) \n        stop(\"'intern' must be TRUE or FALSE\")\n    if (!is.logical(ignore.stdout) || is.na(ignore.stdout)) \n        stop(\"'ignore.stdout' must be TRUE or FALSE\")\n    if (!is.logical(ignore.stderr) || is.na(ignore.stderr)) \n        stop(\"'ignore.stderr' must be TRUE or FALSE\")\n    if (!is.logical(wait) || is.na(wait)) \n        stop(\"'wait' must be TRUE or FALSE\")\n    if (!is.logical(show.output.on.console) || is.na(show.output.on.console)) \n        stop(\"'show.output.on.console' must be TRUE or FALSE\")\n    if (!is.logical(minimized) || is.na(minimized)) \n        stop(\"'minimized' must be TRUE or FALSE\")\n    if (!is.logical(invisible) || is.na(invisible)) \n        stop(\"'invisible' must be TRUE or FALSE\")\n    stdout <- ifelse(ignore.stdout, FALSE, \"\")\n    stderr <- ifelse(ignore.stderr, FALSE, \"\")\n    f <- \"\"\n    if (!is.null(input)) {\n        f <- tempfile()\n        on.exit(unlink(f))\n        writeLines(input, f)\n    }\n    if (intern) {\n        flag <- 3L\n        if (stdout == \"\") \n            stdout <- TRUE\n        if (!ignore.stderr && .Platform$GUI == \"Rgui\") \n            stderr <- TRUE\n    }\n    else {\n        flag <- if (wait) \n            ifelse(show.output.on.console, 2L, 1L)\n        else 0L\n    }\n    if (invisible) \n        flag <- 20L + flag\n    else if (minimized) \n        flag <- 10L + flag\n    .Internal(system(command, as.integer(flag), f, stdout, stderr))\n}\nBrowse[2]> command\n[1] \"\\\"C:/Program Files/R/R-3.3.1/bin/x64/R\\\" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \\\"P:/Alkoholprojekt/R/cleanR\\\" --library=\\\"C:/Program Files/R/R-3.3.1/library\\\" --install-tests \"\nBrowse[2]> Encoding(command)\n[1] \"unknown\"\nBrowse[2]> dput(charToRaw(command))\nas.raw(c(0x22, 0x43, 0x3a, 0x2f, 0x50, 0x72, 0x6f, 0x67, 0x72, \n0x61, 0x6d, 0x20, 0x46, 0x69, 0x6c, 0x65, 0x73, 0x2f, 0x52, 0x2f, \n0x52, 0x2d, 0x33, 0x2e, 0x33, 0x2e, 0x31, 0x2f, 0x62, 0x69, 0x6e, \n0x2f, 0x78, 0x36, 0x34, 0x2f, 0x52, 0x22, 0x20, 0x2d, 0x2d, 0x6e, \n0x6f, 0x2d, 0x73, 0x69, 0x74, 0x65, 0x2d, 0x66, 0x69, 0x6c, 0x65, \n0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x65, 0x6e, 0x76, 0x69, 0x72, \n0x6f, 0x6e, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x73, 0x61, 0x76, \n0x65, 0x20, 0x2d, 0x2d, 0x6e, 0x6f, 0x2d, 0x72, 0x65, 0x73, 0x74, \n0x6f, 0x72, 0x65, 0x20, 0x2d, 0x2d, 0x71, 0x75, 0x69, 0x65, 0x74, \n0x20, 0x43, 0x4d, 0x44, 0x20, 0x49, 0x4e, 0x53, 0x54, 0x41, 0x4c, \n0x4c, 0x20, 0x22, 0x50, 0x3a, 0x2f, 0x41, 0x6c, 0x6b, 0x6f, 0x68, \n0x6f, 0x6c, 0x70, 0x72, 0x6f, 0x6a, 0x65, 0x6b, 0x74, 0x2f, 0x52, \n0x2f, 0x63, 0x6c, 0x65, 0x61, 0x6e, 0x52, 0x22, 0x20, 0x2d, 0x2d, \n0x6c, 0x69, 0x62, 0x72, 0x61, 0x72, 0x79, 0x3d, 0x22, 0x43, 0x3a, \n0x2f, 0x50, 0x72, 0x6f, 0x67, 0x72, 0x61, 0x6d, 0x20, 0x46, 0x69, \n0x6c, 0x65, 0x73, 0x2f, 0x52, 0x2f, 0x52, 0x2d, 0x33, 0x2e, 0x33, \n0x2e, 0x31, 0x2f, 0x6c, 0x69, 0x62, 0x72, 0x61, 0x72, 0x79, 0x22, \n0x20, 0x2d, 0x2d, 0x69, 0x6e, 0x73, 0x74, 0x61, 0x6c, 0x6c, 0x2d, \n0x74, 0x65, 0x73, 0x74, 0x73, 0x20))\n```\n. So, I assume you want the first command to use the right version of R, depending on the computer? On computer 1  I get\n``` r, eval=F\n\nsystem(\"\\\"C:/Program Files/R/R-3.3.1/bin/x64/R\\\" --quiet -e \\\"R.version.string\\\"\")\nWarning message:\nrunning command '\"C:/Program Files/R/R-3.3.1/bin/x64/R\" --quiet -e \"R.version.string\"' had status 127 \nsystem(\"\\\"C:/Program Files/R/R-3.2.3/bin/x64/R\\\" --quiet -e \\\"R.version.string\\\"\")\nR.version.string\n[1] \"R version 3.2.3 (2015-12-10)\"\n```\n\nand on computer 2 an error is thrown, as always:\n``` r, eval=F\n\nsystem(\"\\\"C:/Program Files/R/R-3.3.1/bin/x64/R\\\" --quiet -e \\\"R.version.string\\\"\")\n'C:\\Program' blev ikke genkendt som en intern eller ekstern kommando,\net program eller en batchfil.\nWarning message:\nrunning command '\"C:/Program Files/R/R-3.3.1/bin/x64/R\" --quiet -e \"R.version.string\"' had status 1 \n```\n\nI havn't updated computer 1, as I'm afraid it might induce the problem I experience on computer 2, and then it will be difficult to find the cause. But if you think it's informative, I don't mind updating it to R 3.3.1., so they are running the exact same versions. \nThere's a very simple explanation as to why most of my packages were built under R 3.2.5 on computer 2. I recently updated R, as I noticed computer 2 was using an older version than computer 1 - I hoped it would solve my issues with devtools. I updated R and copied all packages using installr. So my base packages are fine on computer 2:\n``` r, eval=F\n\nsession_info(include_base=TRUE)\nSession info --------------------------------------------------------------------\n setting  value                     \n version  R version 3.3.1 (2016-06-21)\n system   x86_64, mingw32           \n ui       RStudio (0.99.903)        \n language (EN)                      \n collate  Danish_Denmark.1252       \n tz       Europe/Paris              \n date     2016-10-17                  \n\nPackages ------------------------------------------------------------------------\n package   * version date       source      \n base      * 3.3.1   2016-06-21 local       \n datasets  * 3.3.1   2016-06-21 local       \n devtools  * 1.12.0  2016-06-24 CRAN (R 3.3.1)\n digest      0.6.10  2016-08-02 CRAN (R 3.2.5)\n graphics  * 3.3.1   2016-06-21 local       \n grDevices * 3.3.1   2016-06-21 local       \n memoise     1.0.0   2016-01-29 CRAN (R 3.2.5)\n methods   * 3.3.1   2016-06-21 local       \n stats     * 3.3.1   2016-06-21 local       \n tools       3.3.1   2016-06-21 local       \n utils     * 3.3.1   2016-06-21 local       \n withr       1.0.2   2016-06-20 CRAN (R 3.2.5)\n```\n. I just tried installing a new version of R in a different directory (whose path does not contain a blankspace) and  it \"solved\" the problem (or, rather, circumvented it).\n. Sorry for the late response, I haven't been in my office (containing the two computers) for a few days. \nOn computer 1 I get the following output:\n``` r, eval=F\n\nR <- R.home(\"bin/R\")\nprint(R)\n[1] \"C:/PROGRA~1/R/R-32~1.3/bin/R\"\nR <- utils::shortPathName(R)\nprint(R)\n[1] \"C:\\PROGRA~1\\R\\R-32~1.3\\bin\\R\"\nsystem(paste(R, \"RHOME\"))\nC:\\PROGRA~1\\R\\R-32~1.3\n```\n\nOn computer 2 (using the R-installation that is in a folder with spaces in its name), I get\n``` r, eval=F\n\nR <- R.home(\"bin/R\")\nprint(R)\n[1] \"C:/Program Files/R/R-3.3.1/bin/R\"\nR <- utils::shortPathName(R)\nprint(R)\n[1] \"C:\\Program Files\\R\\R-3.3.1\\bin\\R\"\nsystem(paste(R, \"RHOME\"))\nAdvarselsbesked:\nk\u00f8rende kommando 'C:\\Program Files\\R\\R-3.3.1\\bin\\R RHOME' havde status 127 \n```\n\nThe last line translates to \"Warning: Running command ... had status 127\".\n. ",
    "ThisIsJeron": "A year on and still getting this issue, funnily enough while trying to install ggplot2. \n```\n\ndevtools::install_github('hadley/ggplot2')\nDownloading GitHub repo hadley/ggplot2@master\nfrom URL https://api.github.com/repos/hadley/ggplot2/zipball/master\nInstalling ggplot2\nDownloading GitHub repo hadley/scales@master\nfrom URL https://api.github.com/repos/hadley/scales/zipball/master\nError: running command '\"C:/PROGRA~1/R/R-34~1.1/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD config CC' had status 127\n```. It is important to note that installing RTools via RStudio does not give you the \"Select Additional Tasks\" to edit system PATH, so it is necessary to install RTools from their website here. Thanks for finally finding the solution to install_github has status 127 for me!. @hadley I see, I was just following @skhiggins's suggestion. Even though his solution solved my problem, do you know of an method to solving status 127 error without editing system path?. \n",
    "colemonnahan": "(crossing this with issue https://github.com/hadley/devtools/issues/1648 so all see it)\nI had this same issue and was able to fix it. In my case, I had Rtools installed but also another compiler (mingw64 as packaged with AD Model Builder). This other one was first in my environmental PATH. I simply put the Rtools binaries directory at the top of my path and it worked fine after restarting R.\nWindows 10, R 3.3.3, Rtools 3.3.0.1959. \n. I had this same issue and was able to fix it. In my case, I had Rtools installed but also another compiler (mingw64 as packaged with AD Model Builder). This other one was first in my environmental PATH. I simply put the Rtools binaries directory at the top of my path and it worked fine after restarting R.\nWindows 10, R 3.3.3, Rtools 3.3.0.1959. . ",
    "zji90": "It would be very helpful if install_github can download the data file tracked by LFS. I have a package now on github using LFS but install_github cannot get the LFS tracked file. I have to ask users to manually download and install the package, which is tedious.\n. ",
    "mdlincoln": "agreed re: all of this\nOn Wed, Jan 20, 2016 at 3:30 PM, Jennifer (Jenny) Bryan \nnotifications@github.com wrote:\n\nIn addition to no API, I think for public repositories you have to choose\nbetween using LFS and using forks + pull requests? This was written in\nOctober 2015 -- I'm not sure if anything has changed for the better.\nGitHub\u2019s Large File Storage is no panacea for Open Source \u2014 quite the\nopposite\nhttps://medium.com/@megastep/github-s-large-file-storage-is-no-panacea-for-open-source-quite-the-opposite-12c0e16a9a91#.coe0d5f4q\n@mdlincoln https://github.com/mdlincoln I'm not sure what your large\nfile problem is, but you might want to look at datastorr\nhttps://github.com/richfitz/datastorr by @richfitz\nhttps://github.com/richfitz or the ideas there. From him I learned you\ncan attach inconveniently large files to GitHub releases (and yet they\ndon't live in your repo) and a lot of the normal GH limits don't apply. It\nseems too good to be true and I'm sure he can explain it better.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/889#issuecomment-173350404.\n\n\nMatthew D. Lincoln\nPh.D Candidate\nDepartment of Art History & Archaeology http://arthistory.umd.edu\nUniversity of Maryland\nCollege Park, MD 20742\nmlincol1@umd.edu\nmatthewlincoln.net\n. ",
    "Gofer51": "I reinstalled git2r but there is the same error message. Again: the problem\nis present only with git2r and then consequently with devtools.\nI will report issue to github/git2r.\nThanks\nGoffredo Iannetti\n2015-08-08 14:52 GMT+02:00 Hadley Wickham notifications@github.com:\n\nClosed #890 https://github.com/hadley/devtools/issues/890.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/890#event-377009090.\n. \n",
    "paulobrecht": "Solved. This works:\ninstall_github(\"myOrganization/myPackage\", host=\"github.myEnterprise.org/api/v3/\")\nIn other words, \"host\" has to point to the github API endpoint, not to what I would naively think of as the \"host\". Further, including \".git\" in the repo name, or \"https://\" in the host name causes it to break.\n. ",
    "minimenchmuncher": "UPDATE:\nI reinstalled the Xcode tools, and that seemed to clear the issue up. Not sure why though...\n. ",
    "chicoscience1": "I posted this error on stackOverflow in this link:\nStackoverflow\nAnd daattali, Shiny developer, added the name of the function that is causing the issue with Shiny.  The Shiny error message is called when there is a non-namespaced function call to a function that shinyjs has. I updated shinyjs using:\ndevtools::install_github(\"daattali/shinyjs\")\nand the error message became: \nError : shinyjs: you cannot mix named and unnamed arguments in the same function call (function: removeClass)\nSo there is a call to a function in devtools called removeClass that is not namespaced, and getting in conflict with Shinyjs - which has a function with the same name. I suppose that removeClass is only called by devtools when attempting to unload a reference class before loading it again, the second time we invoke load_all.\n. I checked devtools source. In file remove-s4-class.r, line 50, there is the call to remove class:\nremoveClass(classname, where = nsenv)\nI wonder if simply adding the methods namespace would fix this bug?\nmethods::removeClass(classname, where = nsenv)\n. ",
    "thibautjombart": "Hmm.. I would have sworn the git2r warning was vanishing before when installing it before running check(). Turns out now, even after library(git2r), the warning is still there.:\n``` r\n....\n checking for sufficient/correct file permissions ... OK\n checking whether package \u2018treescape\u2019 can be installed ... [11s/11s] WARNING\nFound the following significant warnings:\n  Warning: namespace \u2018git2r\u2019 is not available and has been replaced\nSee \u2018/tmp/RtmpeU1vEm/treescape.Rcheck/00install.out\u2019 for details.\n checking installed package size ... OK\n checking package directory ... OK\n* checking DESCRIPTION meta-information ... OK\n....\n\nsearch()\n [1] \".GlobalEnv\"        \"package:treescape\" \"package:git2r\"  \n [4] \"devtools_shims\"    \"package:ade4\"      \"package:ape\"    \n [7] \"package:stats\"     \"package:graphics\"  \"package:grDevices\"\n[10] \"package:utils\"     \"package:datasets\"  \"package:knitr\"  \n[13] \"package:devtools\"  \"package:methods\"   \"Autoloads\"      \n[16] \"package:base\"   \n```\n. Not sure if relevant now that the issue is closed, but from a (linux) terminal:\n\ngit clone https://github.com/thibautjombart/treescape.git\nR\nthen:\nr\nlibrary(devtools)\ncheck(\"treescape\")\nHere's the complete log:\n``` r\nUpdating treescape documentation\nLoading treescape\nRe-compiling treescape\n'/usr/local/lib/R/bin/R' --no-site-file --no-environ --no-save --no-restore  \\\n  CMD INSTALL '/home/thibaut/temp/treescape'  \\\n  --library='/tmp/Rtmpcljm6d/devtools_install_136f7d0eddb6' --no-R --no-data  \\\n  --no-help --no-demo --no-inst --no-docs --no-exec --no-multiarch  \\\n  --no-test-load \n\ninstalling source package \u2018treescape\u2019 ...\n** libs\ng++ -I/usr/local/lib/R/include -DNDEBUG  -I/usr/local/include -I\"/usr/local/lib/R/site-library/Rcpp/include\"   -fpic  -g -O2  -c CPP_update_combinations.cpp -o CPP_update_combinations.o\ng++ -I/usr/local/lib/R/include -DNDEBUG  -I/usr/local/include -I\"/usr/local/lib/R/site-library/Rcpp/include\"   -fpic  -g -O2  -c RcppExports.cpp -o RcppExports.o\ng++ -I/usr/local/lib/R/include -DNDEBUG  -I/usr/local/include -I\"/usr/local/lib/R/site-library/Rcpp/include\"   -fpic  -g -O2  -c rcpp_hello_world.cpp -o rcpp_hello_world.o\ng++ -shared -L/usr/local/lib -o treescape.so CPP_update_combinations.o RcppExports.o rcpp_hello_world.o\ninstalling to /tmp/Rtmpcljm6d/devtools_install_136f7d0eddb6/treescape/libs\n\nDONE (treescape)\nLoading required package: ape\nLoading required package: ade4\nSkipping invalid path:  .render.server.info.Rd \n'/usr/local/lib/R/bin/R' --no-site-file --no-environ --no-save --no-restore  \\\n  CMD build '/home/thibaut/temp/treescape' --no-resave-data --no-manual \n\n\nchecking for file \u2018/home/thibaut/temp/treescape/DESCRIPTION\u2019 ... OK\n\npreparing \u2018treescape\u2019:\nchecking DESCRIPTION meta-information ... OK\ncleaning src\nchecking for LF line-endings in source and make files\nchecking for empty or unneeded directories\nlooking to see if a \u2018data/datalist\u2019 file should be added\nbuilding \u2018treescape_1.0.0.tar.gz\u2019\n\n'/usr/local/lib/R/bin/R' --no-site-file --no-environ --no-save --no-restore  \\\n  CMD check '/tmp/Rtmpcljm6d/treescape_1.0.0.tar.gz' --timings \n\nusing log directory \u2018/tmp/Rtmpcljm6d/treescape.Rcheck\u2019\nusing R Under development (unstable) (2015-08-18 r69117)\nusing platform: x86_64-pc-linux-gnu (64-bit)\nusing session charset: UTF-8\nchecking for file \u2018treescape/DESCRIPTION\u2019 ... OK\nthis is package \u2018treescape\u2019 version \u20181.0.0\u2019\nchecking package namespace information ... OK\nchecking package dependencies ... OK\nchecking if this is a source package ... OK\nchecking if there is a namespace ... OK\nchecking for executable files ... OK\nchecking for hidden files and directories ... OK\nchecking for portable file names ... OK\nchecking for sufficient/correct file permissions ... OK\nchecking whether package \u2018treescape\u2019 can be installed ... [13s/13s] WARNING\nFound the following significant warnings:\n  Warning: namespace \u2018git2r\u2019 is not available and has been replaced\n  Warning: namespace \u2018rgdal\u2019 is not available and has been replaced\nSee \u2018/tmp/Rtmpcljm6d/treescape.Rcheck/00install.out\u2019 for details.\nchecking installed package size ... OK\nchecking package directory ... OK\nchecking DESCRIPTION meta-information ... OK\nchecking top-level files ... OK\nchecking for left-over files ... OK\nchecking index information ... OK\nchecking package subdirectories ... OK\nchecking R files for non-ASCII characters ... OK\nchecking R files for syntax errors ... OK\nchecking whether the package can be loaded ... OK\nchecking whether the package can be loaded with stated dependencies ... OK\nchecking whether the package can be unloaded cleanly ... OK\nchecking whether the namespace can be loaded with stated dependencies ... OK\nchecking whether the namespace can be unloaded cleanly ... OK\nchecking loading without being on the library search path ... OK\nchecking use of S3 registration ... OK\nchecking dependencies in R code ... OK\nchecking S3 generic/method consistency ... OK\nchecking replacement functions ... OK\nchecking foreign function calls ... OK\nchecking R code for possible problems ... OK\nchecking Rd files ... OK\nchecking Rd metadata ... OK\nchecking Rd line widths ... OK\nchecking Rd cross-references ... OK\nchecking for missing documentation entries ... OK\nchecking for code/documentation mismatches ... OK\nchecking Rd \\usage sections ... OK\nchecking Rd contents ... OK\nchecking for unstated dependencies in examples ... OK\nchecking contents of \u2018data\u2019 directory ... OK\nchecking data for non-ASCII characters ... OK\nchecking data for ASCII and uncompressed saves ... OK\nchecking line endings in C/C++/Fortran sources/headers ... OK\nchecking compiled code ... OK\nchecking files in \u2018vignettes\u2019 ... NOTE\nThe following directory looks like a leftover from 'knitr':\n  \u2018cache\u2019\nPlease remove from your package.\nchecking examples ... OK\nchecking for unstated dependencies in \u2018tests\u2019 ... OK\nchecking tests ...\n  Running \u2018testthat.R\u2019\n OK\nchecking PDF version of manual ... OK\nDONE\n\nStatus: 1 WARNING, 1 NOTE\nSee\n  \u2018/tmp/Rtmpcljm6d/treescape.Rcheck/00check.log\u2019\nfor details.\n```\n. OK thanks for looking into it.\n. Thanks for the update.\nFor what it's worth, turns out the rgdal warning was apparently coming from\na dependency on RLumShiny.\nOn Mon, Sep 7, 2015 at 9:08 PM, Christopher Brown notifications@github.com\nwrote:\n\nI had this same problems that seemed to be fixed by updating git2r. YMMV.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/900#issuecomment-138360536.\n. \n",
    "ctbrown": "I had this same problems that seemed to be fixed by updating git2r. YMMV.\n. ",
    "spadehed": "HKLU would be a good option in addition to the others, as it is the Users own registry tree that is searched.  It's main use would be for those stuck on windows machines without admin rights who have installed Rtools, but are unable to set the registry values in the main HKLM hive, they could then set their own user values themselves.\nAdmittedly it is likely a small pool of users who would be affected by this.\n. ",
    "npjc": "@BrianDiggs removed thanks!\n. ",
    "csrvermaak": "Hi famuvie\nThanks for the great suggestion, I tried it, but it unfortunately didn't work. \n. I just installed it, unfortunately no luck. Thanks for the suggestion, will keep plugging at it\n. 100% - will do that\n. ",
    "MehrabGBari": "This command worked for me on RGUi (not on Rstudio):\ninstall_github(\"hadley/devtools\",force = TRUE)\n. ",
    "karl-forner-quartz-bio": "same kind of problem here. install_version() fails when length(repos) > 1.\nMy current work-around is to set the repos params, e.g. repos = getOption(\"repos\")[1]\n. ",
    "maxheld83": "Is it possible this problem still exists and/or that there has been a recursion @jimhester @jennybc?\nI am running devtools 1.12.0, and so, presumably, is Travis CI.\nI've added a reproducible example on this repo branch. Also see this failing and this successful build.\nIt appears that again, setting r_github_packages in the .travis.yml works, but the equivalent settings just in DESCRIPTION do not.\n\nSuccessful Build\n.travis.yml\n```\nlanguage: r\nsudo: false\nr_github_packages:\n  - maxheld83/qmethod\nwarnings_are_errors: false\ncache:\n  packages: true\nscript:\n  - Rscript test-script.R\nnotifications:\n  email: false\n```\nDESCRIPTION:\nPackage: travis-cache-test\nTitle: placeholder\nVersion: 0.0.0.9000\nAuthors@R: c(\n    person(\"Maximilian\", \"Held\", email = \"info@maxheld.de\", role = \"cre\")\nDepends:\n    R (>= 3.2.3)\nLicense: None\nEncoding: UTF-8\nLazyData: true\nImports: \n  ggplot2,\n  devtools\n\nFailing Build\n.travis.yml:\n```\nlanguage: r\nsudo: false\nwarnings_are_errors: false\ncache:\n  packages: true\nscript:\n  - Rscript test-script.R\nnotifications:\n  email: false\n```\nDESCRIPTION\nPackage: travis-cache-test\nTitle: placeholder\nVersion: 0.0.0.9000\nAuthors@R: c(\n    person(\"Maximilian\", \"Held\", email = \"info@maxheld.de\", role = \"cre\")\nDepends:\n    R (>= 3.2.3)\nLicense: None\nEncoding: UTF-8\nLazyData: true\nImports: \n  ggplot2,\n  devtools\nRemotes: github::maxheld83/qmethod. thanks @jimhester. \nI added some PRs to make sure other people as dense as myself don't stumble upon this. \n\n[x] Travis-CI Docs\n[x] Remotes vignette\n[\u00a0] ~~rpkgs book (maybe?)~~ (does not appear to be covered therein). possibly related: \nhttps://github.com/r-lib/testthat/issues/811. \n",
    "tayepe": "Issue fixed! The location of my command line tools moved from /usr/bin to /bin which wasn't in my $PATH variable.\n. ",
    "sebastian-c": "This needs a better fix than what I did. It's mostly likely that there will be multiple files.\n. ",
    "helix123": "I would very much welcome such checks in devtools. While partial argument matching is checked for already by the above, having an complementary test especiallyfor  partial dollar matching (extraction by $) would be great!. Sorry to chip in again. I cannot find an option to get the full checking logs of each checked package... moreover, the files in check_dir get removed after revdep_check()\nFrom ?revdep_check:\n\ncheck_dir \nA temporary directory to hold the results of the package checks. This should not exist as after the revdep checks complete successfully this directory is blown away.. Yes, still present. Raised an issue for rcmdcheck.. \n",
    "bhive01": "The errors for this are: \nshell\n* checking Rd cross-references ... WARNING\nMissing link or links in documentation object 'package_deps.Rd':\n  \u2018install_packages\u2019\nSee section 'Cross-references' in the 'Writing R Extensions' manual.\n* checking for missing documentation entries ... OK\n* checking for code/documentation mismatches ... OK\n* checking Rd \\usage sections ... WARNING\nDocumented arguments not in \\usage in documentation object 'update_packages':\n  \u2018ask\u2019\nFunctions with \\usage entries need to have the appropriate \\alias\nentries, and all their arguments documented.\nThe \\usage entries must correspond to syntactically valid R code.\nSee chapter \u2018Writing R documentation files\u2019 in the \u2018Writing R\nExtensions\u2019 manual.\nLooks like the build issue is related to documentation. \nI'm kind of awful at the roxygen stuff, but it looks like the issue is on line 14/15 of update.R. The ask parameter is not used in update_packages(), but in update_remotes(). Maybe delete that and see if it builds?\n. Bitchin'.  Your move @hadley. \ud83d\ude1c \n. ",
    "daattali": "@jennybc done https://github.com/hadley/devtools/pull/977\n. You're right, I have a tar under C:\\Program Files\\Git\\usr\\bin as well as\nunder Rtools/bin\nI placed Rtools above git in my PATH and that fixed this error (didn't know\nthat order mattered)\nAlthough now when I try to install 2.2.1 I get\ntrying URL 'https://cran.rstudio.com/src/contrib/ggplot2_2.2.1.zip'\nError in download.file(url, destfile, method, mode = \"wb\", ...) :\n  cannot open URL 'https://cran.rstudio.com/src/contrib/ggplot2_2.2.1.zip'\nSo it looks like it's not going to the correct URL when using the current\nversion. Don't want to open another issue in case it's again a problem on\nmy end\n\nDean Attali\nPresident & CEO\nAttaliTech Ltd\nhttp://AttaliTech.com http://attalitech.com\nOn 11 May 2017 at 09:25, Jim Hester notifications@github.com wrote:\n\nNot sure, I would check your %PATH%, it looks like there is more than one\nversion of tar on it?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hadley/devtools/issues/1504#issuecomment-300788346,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AA6IFHsuicdELzXvUSzNY_GrCZQAM3cMks5r4wxfgaJpZM4NXUKD\n.\n. I guess my way of dealing is by \"blocking\" :)  I don't think this specific issue of the order within your PATH was ever encountered at UBC? If it was, it really is a repressed memory.... \n",
    "onlymee": "AppVeyor test is failing because it's hitting the Github API Rate limit while running the tests.\n. Also added the credentials passthrough to use_github as suggested.  I checked for other git2r clone/push/fetch but missed that one.\nThis could probably have been 1 or 2 commits - will chalk that down to experience.\n. ",
    "jrounds": "Thanks!\n. ",
    "vzemlys": "I looked at the install_github man page for that option. Stupid me.\n. ",
    "jgdt": "Thanks for your reply. I will try to be clearer:\nIf I call use_data(a), 'b' will be written in 'a.rda'. I want '3' to be written in 'b.rda'.\nActually I would like to call use_data in a loop:\nR\nlibrary(devtools)\ndataToMake <- c(\"a.csv\", \"b.csv\", \"c.csv\", \"d.csv\")\nfor (File in dataToMake)\n{\n        Data <- read.csv(File)\n        DataName <- sub(\".csv\", \"\", File)\n        assign(DataName, Data)\n        use_data(as.name(DataName))\n}\nAnd anyway it seems strange that an output of 'as.name' function won't be accepted by the 'is.symbol' check. Maybe due to the 'dots' function (which I don't know):\nuse_data() ll. 5-6\nR\n    to_save <- dots(...)\n    is_name <- vapply(to_save, is.symbol, logical(1))\nThanks for replying.\n. ",
    "jpmorris": "use case: organization uses changing codebase of libraries that are constantly evolving.  Some analysts might use particular versions of the library that is pulled by a particular hash from github using install_github (using ref=).  If the analyst needs to use legacy code installed locally to support an older version AND a different project using the more up-to-date library then install.packages would allow two separate locations and library (with lib.loc=) would allow loading two versions of the same library in two different projects without having to reinstall the diferent versions each time.  install_github does not allow for this possibility.  Though I may be missing a workaround that I'm not aware of.. ",
    "soodoku": "Dear Hadley,\nI went via release(). It may be that it doesn't check links in vignettes?\n. Dear Hadley,\nI was able to fix the issue so let me describe the issue in detail.\nI build vignettes using knitr. In the header, I had:\n%\\VignetteEngine{knitr::rmarkdown} \nThis leads knitr to process Rmd so that when it sees a word starting with http://, it automatically creates a link. So in: \nhttps://github.com/soodoku/clarifai/blob/master/vignettes/poligrams.Rmd\nhttp://localhost:1410/ became a link in the html. And of course that is not going to be accessible.\nUsing %\\VignetteEngine{knitr::knitr} doesn't do that.\n. ",
    "peterhurford": ":+1: \n. ",
    "TomNash": "library() wasn't working at all after trying the install both ways.\nRenamed to remove the period from the package name and changed the repo name, now it seems to work.\n. ",
    "brodieG": "@jimhester bloody awesome.  Best X-mas present this year.  So sick and tired of the install-test-install-corrupt-db-quit-restart-crap-didn't-save-workspace cycle.\n. ",
    "sanjmeh": "I am still facing the same frustrating install-test-install-corrupt-db-quit-restart-crap-didn't-save-workspace cycle. Can one of the experts here document the solution or attach a link to Stack overflow where this is addressed to your satisfaction? Apologies if this is already resolved and documented somewhere else.. ",
    "jeanimal": "I am using version devtools_1.9.1\n. ",
    "stevenpollack": "I can try, but the gist (pun unintended) of the example is:\n1. make, add, and dev_help a roxygenated function.\n2. make and add another roxygenated function.\n3. try and dev_help the function in step 2 with the style being html\n...\n. I agree that == is not useful in practice, but it doesn't hurt to provide the option, so I figured \"why not?\"...\nI was wondering what the versioning semantics were...\nI couldn't find any unit tests for this function; are there none?\n. Also, I'm not in love with the parameter name version... Can we come up with something better?\n. @jimhester can I get an update on the status of this PR?\n. I really like this! Will implement shortly.\n. @jimhester (first draft) of unit tests have been created -- I'm not sure if the choice of doing everything in an apply over an expand.grid of all test cases is \"best practice\", but I figure I'd throw it out there, and hear if you had any better ideas.\n. @jimhester or @hadley -- thoughts?\n. Right on, thanks.\n. So... it's been nearly 2 weeks... Any status update?\n. ???\n. To be honest, I had done my part and answered all follow up's from package\nmaintainers... So, if I may write candidly, this should've been merged in\nmonths ago... Why it has yet to be, is beyond me.\nOn Wed 2. Aug 2017 at 00:17, Hadley Wickham notifications@github.com\nwrote:\n\nI'm going to close this PR in recognition that it's been open for over\nyear with no movement.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hadley/devtools/pull/1054#issuecomment-319513098, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACfIgxDYOqjehStyERGYlx_s7UkfBAg3ks5sT6P7gaJpZM4HOhew\n.\n. So, you'd rather users manually handle @import, @importFrom, and then use_package, as opposed to having at least some computer assistance?\n. I'm not sure I'm following. In the chance when I am importing, say, stringr::str_replace_all(), shouldn't I include @importFrom stringr str_replace_all inside my roxygen block?\n. Right on. Well, then I was _sorely_ mistaken:\n\nI always figured we should be using :: (or :::) and also annotating our roxygen. \ud83d\ude05\nSo, given a person is following your form above: there's absolutely no reason for my proposed function to exist. Awesome. YOU ARE THE MAN!\n. Like I mentioned in the PR to @jimhester : it costs very little to keep the extra options in. Moreover, I can envision a case where someone is developing a package and wants to use >= and <= . Or, if they're writing production code that'll turn into a microservice in a docker container, == might also make sense. \nThis was our resolution.\n. Okie dokie. Is there a \"contributing to devtools\" page somewhere that could tell people about these little details? E.g., how to add to NEW.md, or change the version number?\n. I think that was from RStudio's Reformat Code function -- is there a linter I should/could be using for working with this project?\n. this is defined as close as I can make it (one line above use_package()'s roxumentation), while still making it accessible to the unit tests \n. because adding it to L362 would make it inaccessible to L120 in the unit test.\n. I can tell you that where I used to work, there was serious consideration for == in our private package development since we didn't want to have to update our code when dependencies changed. In the end, we said \"what the hell\" and went with >=. That being said, changes to stringr (from 0.6.3 to 1.0.0) ended up \"forcing\" some time to package maintenance.  \nI don't agree with that we should drop compare because it's \"unlikely\" that someone will use the other options. I thought the spirit of devtools is to help people build packages (with minimal opinions, beyond best practice). Restricting the user to either package or package (>= packageVersion) in the DESCRIPTION file seems mighty opinionated. \n. Woops, totally misunderstood \ud83d\ude05. Sorry about that.\n. Not to barrage you with updates, however, I ran a script that checked CRAN's available packages for all dependencies that called on comparators (\u2264, <, >, or ==). There were 10 packages, all of which published after 26.1.2015...\nThe most surprising fact is that popular use of ==, with 3 counts. Whereas, \u2264 and < have a total of 8...\n. With the exception of a change to L75, I don't really see how this is \"overkill\" so much as it's just thorough. Every potential use of the function is tested\n1. for proper functionality\n2. for idempotency \nand finally a check to make sure the docs aren't lying and an error is thrown on an invalid version number is performed.\nIf this is, indeed, overkill, which tests would you keep?\n. @hadley not sure if you're going to like this, but I broke up the tests and made their descriptions a bit more verbose... Let me know...\n. Dropped.\n. \ud83d\ude47 \n. ",
    "MichaelChirico": "@hadley I've got no expertise so it would take quite some time/elbow grease to get it going -- better suited to someone that knows the workings of the package and all.\nI'll put it somewhere in the middle of my priority list.\n. ",
    "jaimyoung": "Combine into a single message block per suggestion.\nThe message now looks like:\n\ndevtools::install_github(repo = \"user/repo\", host=\"github.host.com/api/v3/\")\n...\nDownloading GitHub repo user/repo@master\nfrom URL https://github.host.com/api/v3//repos/user/repo/zipball/master\n...\n. That's absolutely fine. \nThen this message (a few lines above) then needs to happen after \"src\" string is assembled.\n\nif (!quiet) {\n    message(\"Downloading GitHub repo \", x$username, \"/\", x$repo, \"@\", x$ref)\n  }\nThat should work.\n. Actually, looking at the codes again, it might be better to keep this as a separate message block.\nBetween the first message and the new message, enough number of things happen, 1) dest tempfile created, 2) src URL built, 3) authenticated, 4) checking submodules. \nSo it would be good to have the two messages separate.\nLet me know what you think.\n. ",
    "richfitz": "I didn't see test files for the build in general so wasn't sure if I should add some.  Added now, including a similar one for the source files (which is fine of course).\n. Thanks Jim! More than happy to test things out here on our windows users.\n. ",
    "bearloga": "Even though we discussed this on twitter, I should note here that this functionality is implemented exactly by makeRepo() in Revolution Analytics' miniCRAN package.\n. @jimhester has the fix for this made it into the version that's on CRAN?. ",
    "nparley": "Created https://github.com/hadley/devtools/pull/1048 to fix this problem\n. @jimhester writing a test for this is not actually straight forward as git2r does not support creating shallow clones (e.g. https://github.com/ropensci/git2r/issues/129). So the git repo to test against would have to be made another way, for example with the command line, or package a repo inside test? \n. @jimhester also would the note go under 1.10.0.9000 in the bug fixes, thanks.\n. I have added a test for the shallow clone repo and added a shallow bare copy into the testthat directory to test against. CMD check is now giving the note:\nFound the following non-portable file paths:\n  devtools/tests/testthat/testBareDepthRepo/objects/pack/pack-c4e0f1d1d68408f260cbbf0a533ad5f6bfd5524e.idx\n  devtools/tests/testthat/testBareDepthRepo/objects/pack/pack-c4e0f1d1d68408f260cbbf0a533ad5f6bfd5524e.pack\nalso the test \nR\npkg_sha <- git_sha1(path='testBareDepthRepo')\nexpect_equal(pkg_sha, '21d5d94011')\nassumes something of the path and so might not work in all situations?\n. OK that's solved the non-portable file paths problem and the sample hooks have been removed.\n. Done\n. ",
    "gturri": "I believe I experience the same issue: installing devtools now fails with error ERROR: dependency \u2018withr\u2019 is not available for package \u2018devtools\u2019.\n. ",
    "jsta": "For people arriving here trying to track down this error message - I fixed by switching the repo's git remote origin from http to https:\n$ git remote set-url origin https://github.com/jsta/foo.git\n. ",
    "carlmcqueen": "Hadley:  I removed devtools from my workaround of putting it in the library in the R install folder and I removed devtools from my main directory.  I then reinstalled it to the custom library location I use.  Having it installed in two places is never a good idea.  Now I'm getting issues again.\nwhen I hit control+shift+d I get:\ndevtools::document(roclets=c('rd', 'collate', 'namespace'))\nError in loadNamespace(name) : there is no package called 'devtools'\nCalls: suppressPackageStartupMessages ... tryCatch -> tryCatchList -> tryCatchOne -> \nExecution halted\nExited with status 1.\nwhen I hit build source from the build tab:\n==> devtools::document(roclets=c('rd', 'collate', 'namespace'))\nError in loadNamespace(name) : there is no package called 'devtools'\nCalls: suppressPackageStartupMessages ... tryCatch -> tryCatchList -> tryCatchOne -> \nExecution halted\nExited with status 1.\nDo you think it's devtools or do you think it's Rstudio?\n. @jimhester I do use a custom Rprofile.site that defines the library.  The site you linked doesn't seem to mention a solution as I understand the .Renviron is the same as a windows .site for windows.  \nI have the libpath defined there and when I type .libpaths() it lists the path that I use.\nIs there a better way to have RStudio recognize a custom library instead of the default location?\n. ",
    "morrowcj": "I am also having this problem. I switched to a custom library to avoid reinstalling all the packages with each new R update. Since doing so, I haven't been able to get the package build functionality of Rstudio to work. I set the custom library in my Rprofile.site file with the line: \n.libPaths(\"~/custom_dir\")\nIs there a way to get Rstudio to recognize this directory when using the build tools? Typing .libPaths() returns the correct directory but Rstudio still gives this error with ctrl+shift+D:\n```\n==> devtools::document(roclets=c('rd', 'collate', 'namespace', 'vignette'))\nError in check_dep_version(pkg, version, compare) : \n  Dependency package roxygen2 not available.\nCalls: suppressPackageStartupMessages ...  -> check_suggested -> check_dep_version\nExecution halted\nExited with status 1.\nHere's my setup info:\nversion info\n\nversion\n               _                         \nplatform       x86_64-w64-mingw32        \narch           x86_64                    \nos             mingw32                   \nsystem         x86_64, mingw32           \nstatus                                   \nmajor          3                         \nminor          5.1                       \nyear           2018                      \nmonth          07                        \nday            02                        \nsvn rev        74947                     \nlanguage       R                         \nversion.string R version 3.5.1 (2018-07-02)\nnickname       Feather Spray   \n```. \n",
    "codecov-io": "Current coverage is 42.33%\n\nMerging #1067 into master will decrease coverage by -0.65%\n\ndiff\n@@           master   #1067   diff @@\n=====================================\n  Files          85      86     +1   \n  Lines        4310    4429   +119   \n  Methods         0       0          \n  Branches        0       0          \n=====================================\n+ Hits         1853    1875    +22   \n- Misses       2457    2554    +97   \n  Partials        0       0\n1. 5 files (not in diff) in R were modified. more \n   - Misses -48 \n   - Hits +14\n2. File R/install-remote.R was modified. more \n   - Misses -1 \n   - Partials 0 \n   - Hits +1\n\n\nPowered by Codecov. Last updated by 40eafb1\n. ## Current coverage is 41.91%\nMerging #1169 into master will increase coverage by +0.17%\n\ndiff\n@@             master      #1169   diff @@\n==========================================\n  Files            86         86          \n  Lines          4464       4464          \n  Methods           0          0          \n  Messages          0          0          \n  Branches          0          0          \n==========================================\n+ Hits           1863       1871     +8   \n+ Misses         2601       2593     -8   \n  Partials          0          0\n1. File R/github.R (not in diff) was modified. more \n   - Misses -8 \n   - Partials 0 \n   - Hits +8\n\nPowered by Codecov. Last updated by c19c6f6...bded5f5\n. ## Current coverage is 41.81%\nMerging #1172 into master will increase coverage by +<.01%\n\ndiff\n@@             master      #1172   diff @@\n==========================================\n  Files            86         86          \n  Lines          4464       4475    +11   \n  Methods           0          0          \n  Messages          0          0          \n  Branches          0          0          \n==========================================\n+ Hits           1863       1871     +8   \n- Misses         2601       2604     +3   \n  Partials          0          0\n1. File R/github.R (not in diff) was modified. more \n   - Misses -8 \n   - Partials 0 \n   - Hits +8\n\nPowered by Codecov. Last updated by c19c6f6...942af04\n. ## Current coverage is 41.93%\nMerging #1183 into master will increase coverage by +0.16%\n\ndiff\n@@             master      #1183   diff @@\n==========================================\n  Files            86         86          \n  Lines          4464       4465     +1   \n  Methods           0          0          \n  Messages          0          0          \n  Branches          0          0          \n==========================================\n+ Hits           1863       1872     +9   \n+ Misses         2601       2593     -8   \n  Partials          0          0\n1. File R/github.R (not in diff) was modified. more \n   - Misses -8 \n   - Partials 0 \n   - Hits +8\n\nPowered by Codecov. Last updated by 9ded9d3...a527cf2\n. ## Current coverage is 42.84%\nMerging #1194 into master will increase coverage by 0.95%\n\ndiff\n@@             master      #1194   diff @@\n==========================================\n  Files            86         87     +1   \n  Lines          4481       4580    +99   \n  Methods           0          0          \n  Messages          0          0          \n  Branches          0          0          \n==========================================\n+ Hits           1877       1962    +85   \n- Misses         2604       2618    +14   \n  Partials          0          0\n\nPowered by Codecov. Last updated by 75b7d12...b105512\n. ## Current coverage is 42.07%\nMerging #1196 into master will increase coverage by 0.17%\n\ndiff\n@@             master      #1196   diff @@\n==========================================\n  Files            86         86          \n  Lines          4481       4481          \n  Methods           0          0          \n  Messages          0          0          \n  Branches          0          0          \n==========================================\n+ Hits           1877       1885     +8   \n+ Misses         2604       2596     -8   \n  Partials          0          0\n\nPowered by Codecov. Last updated by 75b7d12...e9d14c2\n. ## Current coverage is 42.08%\nMerging #1197 into master will increase coverage by 0.16%\n\ndiff\n@@             master      #1197   diff @@\n==========================================\n  Files            86         86          \n  Lines          4481       4482     +1   \n  Methods           0          0          \n  Messages          0          0          \n  Branches          0          0          \n==========================================\n+ Hits           1877       1886     +9   \n+ Misses         2604       2596     -8   \n  Partials          0          0\n\nPowered by Codecov. Last updated by 75b7d12...11d685c\n. \n",
    "darny": "It worked ! Very much appreciated, @hadley ! \n\n. ",
    "bent3well": "I was having the same problem using install_from_swirl(...) in the swirl package that's used in the Coursera Data Science Specialization. Thanks for your help and inspiration, Dr. Wickham!\n. ",
    "smallmonster23": "I have the same question\uff0cbut the according the way above .the problem is exist.. ",
    "prakash-aditya44": "Hi,\nR version 3.3.3 (2017-03-06)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 7 x64 (build 7601) Service Pack 1\nwhen running these commands:\ninstall.packages(c(\"curl\", \"httr\"))\nsc <- spark_connect(master = \"my_cloud_url\", method = \"livy\")\nFollowing error comes:\nError in curl::curl_fetch_memory(url, handle = handle) : \n  Couldn't connect to server\n. ",
    "nick-youngblut": "I'm still getting the \"SSL CA cert (path? access rights?)\" after updating \"curl\" and \"httr\". \n~~~\n\ndevtools::install_github(\"hadley/r4ds\")\nInstallation failed: Problem with the SSL CA cert (path? access rights?)\n~~~\n\n~~~\n\nsessionInfo()\nR version 3.3.1 (2016-06-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 16.04.2 LTS\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C\n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8\n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8\n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C\n [9] LC_ADDRESS=C               LC_TELEPHONE=C\n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base\nother attached packages:\n[1] httr_1.2.1      devtools_1.13.2\nloaded via a namespace (and not attached):\n[1] R6_2.2.0      tools_3.3.1   withr_1.0.2   curl_2.7      memoise_1.0.0\n[6] git2r_0.18.0  digest_0.6.12\n~~~\nAny ideas on what's going wrong?. ",
    "haseebmahmud": "UPDATE: \nFixed by following this https://github.com/swirldev/swirl/issues/475\n\nSame problem. @hadley 's solution is not working. \n\nsessionInfo()\nR version 3.4.3 (2017-11-30)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 17.10\n\nMatrix products: default\nBLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=de_DE.UTF-8     \n [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=en_US.UTF-8 \n [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                  LC_ADDRESS=C            \n[10] LC_TELEPHONE=C             LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] Rfacebook_0.6.15 httpuv_1.3.5     rjson_0.2.15     httr_1.3.1       curl_3.1      \n[6] devtools_1.13.4 \nloaded via a namespace (and not attached):\n [1] compiler_3.4.3 R6_2.2.2       tools_3.4.3    withr_2.1.1    rstudioapi_0.7\n [6] yaml_2.1.16    Rcpp_0.12.14   memoise_1.1.0  git2r_0.20.0   digest_0.6.13 . Changing the host argument is not solving the issue. \nHere is what I am trying to do, \n```\n\ndevtools::install_github(\"basilesimon/noaastorms\", host = \"https://api.github.com\")\nError in curl::curl_fetch_memory(url, handle = h) : \n  Failed to connect to api.github.com port 443: Timed out\nsessionInfo()\nR version 3.5.2 (2018-12-20)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows >= 8 x64 (build 9200)\n\nMatrix products: default\nlocale:\n[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252 \n[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                 \n[5] LC_TIME=German_Germany.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] usethis_1.4.0  devtools_2.0.1\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.0        rstudioapi_0.8    magrittr_1.5   \n [4] pkgload_1.0.2     R6_2.3.0          rlang_0.3.0.1  \n [7] tools_3.5.2       pkgbuild_1.0.2    sessioninfo_1.1.1\n[10] cli_1.0.1         withr_2.1.2       remotes_2.0.2  \n[13] yaml_2.2.0        assertthat_0.2.0  digest_0.6.18  \n[16] rprojroot_1.3-2   crayon_1.3.4      processx_3.2.1 \n[19] callr_3.1.1       fs_1.2.6          ps_1.3.0       \n[22] curl_3.3          testthat_2.0.1    memoise_1.1.0  \n[25] glue_1.3.0        compiler_3.5.2    desc_1.2.0     \n[28] backports_1.1.3   prettyunits_1.0.2\n```. ",
    "tdhock": "upgrade_dependencies=FALSE worked for me\nOn Fri, Feb 12, 2016 at 8:15 AM, Jim Hester notifications@github.com\nwrote:\n\nIf you use install_github(\"tdhock/animint\", upgrade_dependencies = FALSE)\nit will not try to upgrade the outdated devtools.\nAlternatively you can artificially bump the version number in your fork of\nggplot2 to be higher than the CRAN version.\nThe assumption is that development dependencies will always have greater\nversions than CRAN versions. It might be worth tweaking the logic to\nexclude development packages from the version checking logic entirely\nhowever...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/1086#issuecomment-183324209.\n. \n",
    "aronatkins": "Thanks for the suggestions, @jimhester. I'm going to let rmarkdown float for now, but will use this Remotes trick if we decide we want to start pinning. Our need to pin may change when bookdown goes to CRAN.\n. ",
    "ijlyttle": "Will do - thanks!\n. done in #1215\n. Will investigate build failures and try again...\n. I reworked things a bit, to put all the url logic into use_github(), along with some comments that hopefully lay out the motivation. \nIn short, the host argument to use_github() must contain a protocol and a hostname, and may include a path to describe the endpoint-root - per your last suggestion (which I can't seem to find on this page anymore).\nMy claims:\n- by manual test, use_github() remains working for host = \"https://api.github.com\"\n- by manual test, use_github() works for host = \"https://github.hostname.com/api/v3\"\n- all the tests: test(filter = \"github\") remain successful, except for a series of warnings that appear when messages are expected (output below). This seems unrelated to this PR; I can file a separate issue if you like.\nHappy to amend as needed.\n```\n\ntest(filter = \"github\")\nLoading devtools\nTesting devtools\ngit usage and GitHub connections: .W.....W..........W.W........\nGitHub: ........................\n\nWarnings -------------------------------------------------------------------------------------\n1. git (non-)usage is detected, diagnosed, and can be added (@test-github-connections.R#30) - DR_GITHUB FOUND PROBLEMS\n\n\nGitHub non-usage is handled (@test-github-connections.R#47) - DR_GITHUB FOUND PROBLEMS\n\n\ngithub info and links can be queried and manipulated (@test-github-connections.R#94) - DR_GITHUB FOUND PROBLEMS\n\n\ngithub info and links can be queried and manipulated (@test-github-connections.R#95) - DR_GITHUB FOUND PROBLEMS\n\n\nDONE =========================================================================================\n```\n. Hi @jennybc - Thanks! I'm glad it was a straightforward fix.\nI'll wait for the signal from @hadley to see how he would like to weave the threads together.\n. Will do - I must have got something backwards, sorry for the mess!\n. I have been twiddling around with the GitHub site - things should appear much cleaner if I just make a new pull request - accordingly:\n- I close this PR, with the expectation that a new one will appear very soon.\n- The new PR will have incorporated the PR from @jennybc \n. Have added a couple of internal functions, and tests for them:\n- github_reg_host_path(host, path) returns a regularized host and path\n- github_url_from_host(host) returns the url for github links\ngithub_reg_host_path() is implemented in github_POST() and in github_GET() (for completeness).\ngithub_url_from_host() is implemented in use_github() to send the correct host to use_github_links().\nAll claims (manual tests of use_github() and test(filter = \"github\")) re-checked.\nHopefully, this is closer. \n. First - thanks @jimhester for your feedback and patience today.\nI think all the boxes are checked - I was able to delete a lot of code. \nThere are a couple of lines in github_GET() and github_POST() that should be able to be deleted at the next release of httr.\nAll previous claims (manual test of use_github() on github.com and enterprise, test(filter = \"github\")) verified.\n. Happy to let this simmer - if/when I can be of help, please let me know.\n. Thanks! (feeling shame)\nReading some more, I realized that there is this function called devtools::use_build_ignore(). \nClosing the issue (should not have been opened, apologies). Interested to hear opinions on the advisability (or lack of) of using /docs in this manner.\n. Thanks!\n. I prefer the idea of using docs as well for exactly those reasons, and am starting to dip my toes in. I'm probably paranoid, but I'm interested to find out if this approach isn't \"too good to be true\".\nSo far, so good - if I am reading correctly.\n. I'm intrigued by the idea. It might avoid the necessity for a company-specific function like I have written and packaged (privately), use_github_se(), which uses our host as a default, and looks for an env var named GITHUB_SE_PAT. \nMaybe the company-specific helper function would do something different, writing the project-level .Renviron.\nThe one thing I cannot reason about is what might happen if we rely on a project-level definition of \nGITHUB_PAT, then install_github(\"hadley/newpackage\") - would things fail in a way that would be difficult to figure out? \nI will have to make an experiment :)\n. I am mindful that I am likely diverting the thread, but here's (the start of) a writeup of how I have approached the GHE solution: http://ijlyttle.github.io/nondim_devtools_gh.html - it's very rough at this point, but if I wait until I get the prose right, well, we'll be waiting...\nAs I note, I don't pretend that this a best practice, simply that it is a practice. If nothing else, maybe it can shake loose some ideas.\n. Thanks!\n. FWIW, pull request #1263 takes care of this problem - I think the USE.NAMES = FALSE did the trick. Closing this issue in anticipation of #1263 being merged.\n. @jimhester Thanks! The best sort of bugs are the ones that are already fixed!\n. done in f0b9cc9\n. done in f0b9cc9\n. I do this because the endpoint prefix for enterprise Github is different from github.com.\nenterprise: http(s)://hostname/api/v3/ ref\ngithub.com: https://api.github.com ref\nOf course, this does not mean that stuffing everything into host is the right way to do it :)\nJust to spitball on a possible paths forward, I could use two args (with defaults): host = \"https://api.github.com\" and path_prefix = NULL. To use enterprise github, one could specify \nhost = \"https://github.hostname.com\" and path_prefix = \"api/v3\".\nPlease let me know what you think and I'll change things accordingly.\n(edit: to be clear, I am proposing the path_prefix for use_github(), not github_GET() or github_POST())\n. Please see previous response\n. I will try that out - thanks!\n. I'm happy to make the change for github_URL, but I don't think issues_URL is returning what we want. The hostname in issues_URL is api.github.com, where we want github.com\nAs a first approach, could I just append \"/issues\" to github_URL? \n. There's likely something I am not seeing here - which are the regexes that are the same?\n. Here's what I have for L138 and L141:\nR\n    re <- \"github[^/]*/(.*?)/(.*)\\\\.git\" # L138\n    re <- \"github[^:]*:(.*?)/(.*)\\\\.git\" # L141\nI think the difference is in the delimiter, / for L138 and : for L141, to distinguish\nhttps://github.com/hadley/devtools.git # L138 case\ngit@github.com:hadley/devtools.git     # L141 case\nI think the two might be combined, as I don't think that either delimiter is legal part of a hostname in either case.\nWhat do you think?\n. Placeholder to say that I am noodling this out - I am just a bit slow :)\n. Cool, I'll get on combining those.\n. I agree that this is cleaner - the problem I run into is the case where url$path the empty string. For example:\n``` R\nhost <- \"https://api.github.com\"\npath <- \"user/repos\"\nurl <- httr::parse_url(host)\nurl$path <- paste(url$path, path, sep = \"/\")\nhttr::build_url(url)\n```\nThis results in \"https://api.github.com//user/repos\" - the extra slash between the host and the path gets put there by paste, by virtue of the extra string. With the extra slash, I find that httr::GET returns 404.\nThere is enough extra logic that I will propose a function, github_compose_url(host, path) that will replace github_reg_host_path().\n``` R\ngithub_compose_url <- function(host, path = \"\"){\nurl <- httr::parse_url(host)\nif (identical(url$path, \"\")){\n    url$path <- path\n  } else {\n    url$path <- paste(url$path, path, sep = \"/\")\n  }\nurl\n}\n```\n. Yikes! I'll try again...\nHere's me:\n``` R\n\nhost <- \"https://api.github.com\"\npath <- \"users/hadley/repos\"\nurl <- httr::parse_url(host)\nurl$path <- paste(url$path, path, sep = \"/\")\nhttr::build_url(url)\n[1] \"https://api.github.com//users/hadley/repos\"\nhttr::GET(url)\nResponse [https://api.github.com//users/hadley/repos]\n  Date: 2016-06-08 20:43\n  Status: 404\n  Content-Type: application/json; charset=utf-8\n  Size: 87 B\n{\n  \"message\": \"Not Found\",\n  \"documentation_url\": \"https://developer.github.com/v3\"\n}\nsession_info()\nSession info ---------------------------------------------------------------------------------\n setting  value                     \n version  R version 3.3.0 (2016-05-03)\n system   x86_64, darwin13.4.0      \n ui       RStudio (0.99.902)        \n language (EN)                      \n collate  en_US.UTF-8               \n tz       America/Chicago           \n date     2016-06-08                  \n\nPackages -------------------------------------------------------------------------------------\n package    * version     date       source      \n curl         0.9.7       2016-04-10 CRAN (R 3.3.0)\n devtools   * 1.11.1.9000 2016-06-08 local       \n digest       0.6.9       2016-01-08 CRAN (R 3.3.0)\n httr         1.1.0       2016-01-28 CRAN (R 3.3.0)\n memoise      1.0.0       2016-01-29 CRAN (R 3.3.0)\n R6           2.1.2       2016-01-26 CRAN (R 3.3.0)\n rstudioapi   0.5         2016-01-24 CRAN (R 3.3.0)\n withr        1.0.1       2016-02-04 CRAN (R 3.3.0)\n```\n. I'll poke around - I would sure like to get your behavior...\n. Good news for the future!\nIn that case, I'll look into  hadley/httr@2f6baa0  and see where the difference is, I'll propose a very small bit of code to cover the difference until the next CRAN release of httr (I'll leave a comment/issue to remove it from devtools).\nAlmost there!\n. done in af11ad7\n. done in 3263cee\n. done in a8d5d29 - there is some code that can be taken out when the next httr is released\n. ",
    "AndreMikulec": "Yes, error on my part.  Dummy me. I noticed that mistake today.  In my .bat file I forgot  to append \";%PATH%\".\n. Thanks.. ",
    "markvanderloo": "Good point, I missed that. This PR can be safely dismissed then.\n. ",
    "kippandrew": "I suspect something strange is going on with your environment which is breaking devtools.\nThe good news is rsconnect is now on CRAN, so you can install it with:\ninstall.packages('rsconnect')\n. ",
    "lionel-": "thanks that looks nice!\n. > I am not sure what to do with this, and I don't think it is very important (read.dcf reads the file without the space), but it would be nice to handle it the same way.\nI think it's very important. Think of all the back and forth commit noise if the development tools don't format DESCRIPTION the same way :/\n. I have the same issue of cryptic error message on macOS.\nEdit: Got things much faster and streamlined by setting options(pkgType = \"mac.binary\"). should type defaults to binary packages for platforms that support it?\nEdit: Maybe the question is: when pkgType is set to \"both\", why does it try installing source packages when a binary is available?. Ah nice, I didn't know about that package. I see it has a trimws() backport.. @gaborcsardi is the code in the NAMESPACE file executed at install time or at loading time?. rlang could provide an exported function to conditionally assign our backports in a given environment as a function of the current R version. Then we'd call that it in the .onLoad() hook to populate our package namespaces.. @krlmlr might have other ideas. I'd have to keep hardcoding backports in rlang because it shouldn't depend on any other package. Maybe backports could be an exception though.. > Now reading up, dtplyr (and others) have run time registration of S3 methods, we might be able to do something similar.\nThat would be my preference as well.\nr\n.onLoad <- function(libname, pkgname) {\n  backports::import(pkgname)\n}\nWith an optional argument to supply a character vector of backport names.. @jimhester that would be a bit cumbersome because you'd need an else branch returning the base function. Please have a look at the last commit, I think that's the most straightforward solution.. Yeah I was thinking the same actually. And stringi is a heavy dep. I switched to our own implementation.. This is breaking ESS but I understand if you don't care about it ;). Oh, so the dependency gets reinstalled from the local source?\nThis is quite confusing. Should we print some hints to explain why and whence the package is reinstalled?. I'm not sure I like this behaviour. If I work on say Rcpp, install it from source, then work on it a bit more, it will get automatically reinstalled with the WIP changes which is often not (maybe never?) what I'd want.\nOr am I missing something? I guess the issue is that I rarely have a clean working directory (I might have changed the maintainer email in DESCRIPTION to redirect winbuilder and rhub to my mailbox for instance). I wonder if we need an option in devtools::install() to install from last commit rather than the working tree, then it'd have the proper SHA.. Could you tell me more about the intended workflow for the current behaviour of local installs please? I don't understand it. Is it not dangerous to reinstall from working tree each time? Can a user reasonably expect this behaviour? Wouldn't they expect the intalled version to remain the same as the last explicit install?. > You can set this to FALSE to avoid this.\nI have, so there might be a bug.\n\nLocal dependencies are treated like any other dependency.\nthere is no way for us to know what the state of the package is when it is installed, so we always will reinstall it.\n\nDespite the apparent consistency this does not seem to be the right thing to do. A working tree is not necessarily in working order. You can assume that the user knows that the state was good at time of installation, but not at random ulterior times such as when upgrading dependencies.\nThis behaviour seems unintuitive and dangerous to me. It should at least be told to the user in the output, something like \"Reinstalling somepkg because it was installed with a WIP git working tree. Install from a clean working tree to avoid this.\". > Perhaps instead warn_unless_current_dir() should be changed to throw an error if pkg$path does not equal usethis::proj_get()\nThat would break ESS and force devtools users to change their workflow (custom scripts, etc) right away. Is a transition period possible?\n\nChanging the working directory would only help if you had not called a usethis function to set the project yet.\n\nShould I change setwd() with proj_set()?. Thanks. Not sure why but devtools::install_github(\"r-lib/devtools) didn't upgrade rcmdcheck even though the Imports depends on >= 1.3.0. devtools::check() didn't work properly until I manually installed the new version. It is possible my devtools installation is entirely borked.. Thanks, confirmed. The new output looks great.. ",
    "vivekbhr": "Thanks a lot @jimhester .. I finally got my package to work after populating the biocViews. \n. ",
    "setempler": "In a production environment, we use different setups of library paths for different pipelines/scripts. \nThe implementation would allow to check the session info while working on a such a project (and creating a report), saving a call to .libPaths and list.files, or a self-made function.\nAny concerns with the type of implementation (using list.files)?\n\nOn 23 Mar 2016, at 16:18, Hadley Wickham notifications@github.com wrote:\nCould you provide a little justification? I don't see why this would be useful.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. Many thanks for the suggestion\n. \n",
    "ampu3ro": "PTAL. Sorry about the unnecessary commenting :/ first time \n. Can't say it was easy (rtools is super finicky!), but I think I got all the tests to pass. Not sure what's failing in the AppVeyor tests though...\n. much better solution. thanks\n. ",
    "rellan": "When I tried at work I didn\u00b4t have any problem. It might be some weird internet configuration at home that I am not aware of.\nSolved.\n. ",
    "tanwira08": "I am getting this problem with \"rmarkdown\" . . .\ndevtools::install_github(\"rstudio/rmarkdown\")\nDownloading GitHub repo rstudio/rmarkdown@master\nfrom URL https://api.github.com/repos/rstudio/rmarkdown/zipball/master\nError in curl::curl_fetch_memory(url, handle = handle) : \n  SSL connect error\n. ",
    "darrkj": "After further efforts I think the root of the problem is that install_github is grab a zip file, which you can see form the link above. So the solution may be something related to this knowing that I am on a Mac. This makes sense that I have all of the Mac build tools but maybe it cant find the Windows build tools.\nWhen I try to install the zip file at that location via the Packages window in RStudio I get:\nError in install.packages : cannot install Windows binary packages on this platform\n. I upgraded/re-installed R to version 3.2.4 and now everything works. I doubt it was the upgrade because I was not about to type R at the command prompt anymore.  It was most likely just another issue that the reinstall fixed, so this was just the first place I noticed it. Should mark this as closed.\n. ",
    "rz1988": "Hi Hadley, \nYes I did check all the boxes. Actually, I have successfully uploaded the package to CRAN thru the website. \nThanks,\nRyan\n. ",
    "antaldaniel": "I had the same issue, and after visiting the CRAN website, I realized the reason:\n\nCRAN vacation from Sep 1 to Sep 9, 2018.\nDuring this time, the submission of packages is not possible.\nSorry for any inconvenience\n\n. ",
    "vijaybarve": "@hadley Need to trap this error and change message?. ",
    "Amateur2": "Thank you for responding so promptly.\nI use Intego VirusBarrier8 (with up-to-date virus definitions) which I\nunderstand to be reliable for use on macs (which is what I'm using), but\nI'm by no means an expert.\nWhen I ran a full scan subsequently, it picked up the same file\n(openssl.so), and 'repaired' it when I selected that option.\nI sent it to you because the error message popped up immediately after I\ntyped:\ninstall.packages (\"devtools\")\ninto the RStudio screen.\nIt was the first instruction I'd typed, so I thought you were the obvious\npeople to send a message to, but  if I understand you correctly, it might\nbe another package used in the process rather than devtools itself - in\nwhich case, my apologies.\nAs will be evident, I'm a novice so reluctant to tempt fate by opening\n'openssl' again. However if you are unable to reproduce the problem, it\nsounds as if it's ok for others to use, which was my motive in contacting\nyou.\nMany thanks for your time, and for getting back to me so quickly.\nOn 10 April 2016 at 23:58, Jeroen Ooms notifications@github.com wrote:\n\nI'm 99% confident this is a false positive (lots of trojans use openssl\ncode). The openssl.so file is part of the openssl package, so this is\ndefinitely the wrong repo. Do you get the same error when installing\nopenssl?\ninstall.packages(\"openssl\")\nAnd what happens when you try installing openssl from source?\ninstall.packages(\"openssl\", type = \"source\")\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hadley/devtools/issues/1144#issuecomment-208087720\n. \n",
    "pitakakariki": "\n@berndbischl maybe condition on interactive()?\n\nI think interactive() returns TRUE whether you've called load_all() or test().\n. @hadley will do. Should I wait till devtools is passing on Appveyor or is it okay to do it now?. I've sent a pull request to pkgload here https://github.com/r-lib/pkgload/pull/41. Options are closer to \"basically the same process\" than forks though.\n. Yes, options within my package.\n. Current workaround, if anyone else is having this problem: set the options in test_aaa.R instead.\n. https://github.com/hadley/devtools/pull/1169\n. I closed this because it was superseded by https://github.com/hadley/devtools/commit/43e325cbfa448fe85e5f2503bf8fcf0affafca63. Spaces are there now.\n. ",
    "hhoeflin": "None that I can publish at the moment, sorry.\n. ",
    "rtobar": "I'm also eager to see these changes included in devtools. Thus, I rebased @jonkeane's patch on top of the current master, and added a small improvement on top of it. I commented on the original pull request about this to know whether I should create a new one or if we can reuse it to include my changes as well.. I have an updated version of this patch on top of the current master, plus a small improvement. Should I open a new pull request for it? Otherwise, how can I contribute to this one?. ",
    "ronammar": "Has this feature been incorporated into devtools master?\nWould the syntax appear as follows?:\nr\ndevtools::install_git(myRepoURL, args=\"--recursive\"). ",
    "DSLituiev": "It is a convention on this machine;) Other packages do install well.\n. ",
    "ateucher": "Awesome, thanks!\n. ",
    "coatless": "@hadley \nCan-do. \nIs it possible to re-open this PR or should I submit a new one?\n. Thanks @jimhester, opened a ticket at: fmichonneau/foghorn#33. ",
    "yutannihilation": "@krlmlr Thanks so much! I've confirmed the issue is fixed :+1: \n. Thanks!\nI feel the same as you. This is more like a bug in R...\n. I've confirmed. Thanks! :+1: \n. Thanks. I found this issue is already fixed in remotes by this commit: https://github.com/r-lib/remotes/commit/9bb69f18023fc189603609166ee9cbfb68b61a35\nLooking forward the time when remotes is ready!. > a Oauth token the token can be in either the username or the password\nOh, wow! I don't think it's documented, but I confirmed \"x-oauth-basic\" is a special password that let us use the token as the username... Thanks.. ",
    "saritha080": "Im trying to install SparkR on 64 bit windows with R3.3.2. Facing the same error  while trying to install SparkR through devtools from command line as:\n%SPARK_HOME%\\R\\lib\\SparkR>R -e \"devtools::install ('.')\"\nWarning: running command 'cp -R . \"C:/Users/HP/Documents/R/win-library/3.3/Spark\nR\" || ( internal cd - .| (cd \"C:/Users/HP/Documents/R/win-library/3.3/SparkR\" &&\n internal -xf -))' had status 1\nERROR: installing binary package failed\n* removing 'C:/Users/HP/Documents/R/win-library/3.3/SparkR'\nError: Command failed (1)\nExecution halted\nI read the previous posts where this seems to be fixed. Which release is this available? How can I continue with my installation?. ",
    "hariramn": "Hi @saritha080 any luck resolving this?. ",
    "kbenoit": "Or that Brian Ripley won't give you two weeks to upload a revision, after it's been published, to fix a single non-ASCII character in an .Rd file!\nIn practice the revisions that @wch refers to happen all the time immediately after first submission.\n. ",
    "zdk123": "I found this issue when searching for a work around that wouldn't require changing the devtools. I think this is a generic way to get around the export_all=TRUE, with apologies to Hadley for breaking the intended test setup.\nin a test.R file:\n```r\ncontext('...')\nany setup stuff here\ntest_that('...', {\n  ## set the parent of current environment to the global environment ##\n  e <- environment()\n  pe <- parent.env(e)\n  parent.env(e) <- globalenv()\n  pkgpath <- find.package('pkgname')\n  devtools::load_all(pkgpath, export_all=FALSE, quiet=TRUE)\n## Run all tests with nonexported functions ##\n## Reset environment for subsequent tests ##\n  parent.env(e) <- pe\n  devtools::load_all(pkgpath, export_all=TRUE, quiet=TRUE)\n})\n```\nSince devtools::test sets the package namespace as the parent of the testing environment, it wasn't enough for my purposes to simply reload the package with export_all=FALSE, though you need to do that as well. Calls like match.fun('internal.function') could still find internal.function in the parent environment. \nHowever, it is possible to manipulate the environment stack from a calling environment.  Above, I've set the parent to the global environment, but one could as easily set it to a new/empty one.\nJust make sure to reset / reload or you might break other tests.. ",
    "r2evans": "@jimhester's suggestion doesn't work for me, when I want to differentiate between calling load_all() (load no helpers) and test() (load helpers), since the NO_CRAN env var is not a player. My (hackish) adaptation (that appears to work for me):\nr\nif (! interactive() || ! any(grepl(\"\\\\bload_all\\\\b\", as.character(sys.calls()[1])))) {\n  # ...\n}\n(The ! interactive() doesn't really come into play, as far as I can tell.). @jimhester ... I can't tell you how long I've been using something like options(repos=list(CRAN = \"https://cran.rstudio.com/\")) (on windows, mostly) ... and generally things work just fine. Trying to bring my linux work area up to speed and ran into a similar bug, found this. Not sure when I switched from c to list, but it seems odd how so many other things work just fine either way (until now).\nThanks.. ",
    "khakieconomics": "Thanks. \n. ",
    "sfirke": "That fix from STAT545 issue 429 worked for me on Windows 10.  That is, running find_rtools() led has_devel()  to work:\n```\nR version 3.3.2 (2016-10-31) -- \"Sincere Pumpkin Patch\"\n\ninstall.packages(\"devtools\")\nInstalling package into \u2018C:/Users/SFirke/Documents/R/win-library/3.3\u2019\n(as \u2018lib\u2019 is unspecified)\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.3/devtools_1.12.0.zip'\nContent type 'application/zip' length 433071 bytes (422 KB)\ndownloaded 422 KB\n\npackage \u2018devtools\u2019 successfully unpacked and MD5 sums checked\nThe downloaded binary packages are in\n    C:\\Users\\SFirke\\AppData\\Local\\Temp\\Rtmp8uWd7f\\downloaded_packages\n\nlibrary(devtools)\ninstall_github(\"hadley/devtools\")\nDownloading GitHub repo hadley/devtools@master\nfrom URL https://api.github.com/repos/hadley/devtools/zipball/master\nInstalling devtools\n\"C:/PROGRA~1/R/R-33~1.2/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \\\n  \"C:/Users/SFirke/AppData/Local/Temp/Rtmp8uWd7f/devtools1a4c463575d4/hadley-devtools-d8ab190\" --library=\"C:/Users/SFirke/Documents/R/win-library/3.3\" --install-tests \n\n\ninstalling source package 'devtools' ...\n R\n inst\n tests\n preparing package for lazy loading\n help\n installing help indices\n* building package indices\n installing vignettes\n testing if installed package can be loaded\n arch - i386\nError : package 'devtools' is not installed for 'arch = i386'\nError: loading failed\nExecution halted\n arch - x64\nERROR: loading failed for 'i386'\nremoving 'C:/Users/SFirke/Documents/R/win-library/3.3/devtools'\nrestoring previous 'C:/Users/SFirke/Documents/R/win-library/3.3/devtools'\nWarning in file.copy(lp, dirname(pkgdir), recursive = TRUE, copy.date = TRUE) :\n  problem copying C:\\Users\\SFirke\\Documents\\R\\win-library\\3.3\\00LOCK-hadley-devtools-d8ab190\\devtools\\libs\\x64\\devtools.dll to C:\\Users\\SFirke\\Documents\\R\\win-library\\3.3\\devtools\\libs\\x64\\devtools.dll: Permission denied\nError: Command failed (1)\ndevtools::build_github_devtools()\n\"C:/PROGRA~1/R/R-33~1.2/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD SHLIB foo.c \n\n\n\nWarning message:\nrunning command 'make -f \"C:/PROGRA~1/R/R-33~1.2/etc/x64/Makeconf\" -f \"C:/PROGRA~1/R/R-33~1.2/share/make/winshlib.mk\" SHLIB=\"foo.dll\" WIN=64 TCLBIN=64 OBJECTS=\"foo.o\"' had status 127 \nError: Command failed (1)\n\nfind_rtools()\n[1] TRUE\nhas_devel()\n\"C:/PROGRA~1/R/R-33~1.2/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD SHLIB foo.c \n\nC:/RBuildTools/3.4/mingw_64/bin/gcc  -I\"C:/PROGRA~1/R/R-33~1.2/include\" -DNDEBUG     -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O2 -Wall  -std=gnu99 -mtune=core2 -c foo.c -o foo.o\nC:/RBuildTools/3.4/mingw_64/bin/gcc -shared -s -static-libgcc -o foo.dll tmp.def foo.o -Ld:/Compiler/gcc-4.9.3/local330/lib/x64 -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/PROGRA~1/R/R-33~1.2/bin/x64 -lR\n[1] TRUE\n\nbuild_github_devtools()\n\"C:/PROGRA~1/R/R-33~1.2/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD SHLIB foo.c \n\nC:/RBuildTools/3.4/mingw_64/bin/gcc  -I\"C:/PROGRA~1/R/R-33~1.2/include\" -DNDEBUG     -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O2 -Wall  -std=gnu99 -mtune=core2 -c foo.c -o foo.o\nC:/RBuildTools/3.4/mingw_64/bin/gcc -shared -s -static-libgcc -o foo.dll tmp.def foo.o -Ld:/Compiler/gcc-4.9.3/local330/lib/x64 -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/PROGRA~1/R/R-33~1.2/bin/x64 -lR\nDownloading devtools from https://github.com/hadley/devtools/archive/master.zip\n\"C:/PROGRA~1/R/R-33~1.2/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \"C:\\Users\\SFirke\\AppData\\Local\\Temp\\Rtmp8uWd7f\\devtools-master\" --build \n\ninstalling to library 'C:/Users/SFirke/AppData/Local/Temp/Rtmp8uWd7f/temp_libpath1a4c1a06874'\ninstalling source package 'devtools' ...\n R\n inst\n preparing package for lazy loading\n help\n installing help indices\n* building package indices\n installing vignettes\n** testing if installed package can be loaded\n arch - i386\n arch - x64\nMD5 sums\npackaged installation of 'devtools' as devtools_1.12.0.9000.zip\nDONE (devtools)\nRenaming file to ./devtools.zip\n``. I experience this on Windows 10 both with CRAN version 1.12.0 as noted by @renozao, also with today's current development version 1.21.0.9000 (belowhtmlwidgetsis a dependency offormattable`, which my package depends on):\n\n```\n\nlibrary(devtools)\nsession_info()\nSession info ---------------------------------------------------------------------------------------------------------------------------------------------------------------------\n setting  value                     \n version  R version 3.3.2 (2016-10-31)\n system   x86_64, mingw32           \n ui       RStudio (1.0.136)         \n language (EN)                      \n collate  English_United States.1252\n tz       America/New_York          \n date     2017-02-09                  \n\nPackages -------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n package  * version     date       source                        \n devtools * 1.12.0.9000 2017-02-10 local                         \n digest     0.6.12      2017-01-27 CRAN (R 3.3.2)                \n memoise    1.0.0       2016-01-29 CRAN (R 3.3.0)                \n pkgbuild   0.0.0.9000  2017-02-09 Github (r-pkgs/pkgbuild@65eace0)\n pkgload    0.0.0.9000  2017-02-09 Github (r-pkgs/pkgload@def2b10) \n withr      1.0.2       2016-06-20 CRAN (R 3.3.1)                  \n\ndevtools::install_git(\"https://tools.tntp.org/bitbucket/scm/ct/tntpr.git\")\nDownloading git repo https://tools.tntp.org/bitbucket/scm/ct/tntpr.git\nInstalling tntpr\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\n\"C:/PROGRA~1/R/R-33~1.2/bin/x64/Rcmd.exe\" INSTALL \"C:/Users/SFirke/AppData/Local/Temp/RtmpigYaP7/file3474161d1fa5\" \nInstallation failed: NULL : Command failed:\n \"C:/PROGRA~1/R/R-33~1.2/bin/x64/Rcmd.exe\" INSTALL \"C:/Users/SFirke/AppData/Local/Temp/RtmpigYaP7/file3474161d1fa5\"\n * installing to library 'C:/Users/SFirke/Documents/R/win-library/3.3'\n installing source package 'tntpr' ...\n R\n data\n moving datasets to lazyload DB\n* inst\n preparing package for lazy loading\nError in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) : \n  there is no package called 'htmlwidgets'\nERROR: lazy loading failed for package 'tntpr'\n removing 'C:/Users/SFirke/Documents/R/win-library/3.3/tntpr'\n```\n\nAs an interim workaround, I installed devtools 1.11.1 from April 2016 and it runs the install_git() command successfully.. ",
    "markdly": "The suggested fix of running find_rtools() then has_devel() worked for me. I downloaded and installed Rtools then did the following\n``` R \nR version 3.3.3 (2017-03-06)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows >= 8 x64 (build 9200)\ninstall.packages(\"devtools\")\nlibrary(devtools)\nhas_devel()  # has error\nfind_rtools()\nhas_devel()  # now it works\n```\nOutput was\n``` R\n\ninstall.packages(\"devtools\")\nInstalling package into \u2018C:/Users/Mark/Documents/R/win-library/3.3\u2019\n(as \u2018lib\u2019 is unspecified)\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.3/devtools_1.13.1.zip'\nContent type 'application/zip' length 440212 bytes (429 KB)\ndownloaded 429 KB\n\npackage \u2018devtools\u2019 successfully unpacked and MD5 sums checked\nThe downloaded binary packages are in\n    C:\\Users\\Mark\\AppData\\Local\\Temp\\RtmpW2jpI5\\downloaded_packages\n\nlibrary(devtools)\nhas_devel()  # has error\n\"C:/PROGRA~1/R/R-33~1.3/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD SHLIB foo.c \n\nWarning message:\nrunning command 'make -f \"C:/PROGRA~1/R/R-33~1.3/etc/x64/Makeconf\" -f \"C:/PROGRA~1/R/R-33~1.3/share/make/winshlib.mk\" SHLIB=\"foo.dll\" WIN=64 TCLBIN=64 OBJECTS=\"foo.o\"' had status 127 \nError: Command failed (1)\n\nfind_rtools()\n[1] TRUE\nhas_devel()  # now it works\n\"C:/PROGRA~1/R/R-33~1.3/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD SHLIB foo.c \n\nC:/RBuildTools/3.4/mingw_64/bin/gcc  -I\"C:/PROGRA~1/R/R-33~1.3/include\" -DNDEBUG     -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O2 -Wall  -std=gnu99 -mtune=core2 -c foo.c -o foo.o\nC:/RBuildTools/3.4/mingw_64/bin/gcc -shared -s -static-libgcc -o foo.dll tmp.def foo.o -Ld:/Compiler/gcc-4.9.3/local330/lib/x64 -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/PROGRA~1/R/R-33~1.3/bin/x64 -lR\n[1] TRUE\n```. ",
    "faridcher": "I am on win10 with R 3.4.1 x64. everthing works fine except rtools which isn't recognized with rstudio (devtools). I can't build & load from source and naturally can't install devtools from github. In my rsession I get:\n\nfind_rtools(T)\nError: running command '\"C:/PROGRA~1/R/R-34~1.1/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD config CC' had status 2\nSys.which(\"ls.exe\")\n                   ls.exe \n\"C:\\rtools\\bin\\ls.exe\" \nSys.which(\"gcc.exe\")\n                             gcc.exe \n\"c:\\rtools\\mingw_64\\bin\\gcc.exe\" \n\nrunning the command in cmd returns:\n\nC:\\Users\\farid>r --no-site-file --no-environ --no-save --no-restore --quiet CMD config cc\nmake: /etc/x64/Makeconf: No such file or directory\nmake: /share/make/config.mk: No such file or directory\nmake:  No rule to make target /share/make/config.mk'.  Stop.\nmake: /etc/x64/Makeconf: No such file or directory\nmake: /share/make/config.mk: No such file or directory\nmake: *** No rule to make target/share/make/config.mk'.  Stop.\nmake: /etc/x64/Makeconf: No such file or directory\nmake: /share/make/config.mk: No such file or directory\nmake:  No rule to make target /share/make/config.mk'.  Stop.\nmake: /etc/x64/Makeconf: No such file or directory\nmake: /share/make/config.mk: No such file or directory\nmake: *** No rule to make target/share/make/config.mk'.  Stop.\nmake: /etc/x64/Makeconf: No such file or directory\nmake: /share/make/config.mk: No such file or directory\nmake: *** No rule to make target `/share/make/config.mk'.  Stop.\nERROR: no information for variable 'cc'\n\n. ",
    "sz-cgt": "Any news on  this?. ",
    "haozhu233": "Just realized that someone reported it before and it has been fixed in the dev version of devtools. sorry for missing that\n. ",
    "henrygabs": "Any suggestions for a solution to or this problem?\n. ",
    "jianlingfan": "I got the same problem recently, do you have a solution?. I have the same problem for several weeks too, still looking for a solution.. ",
    "AndreasChristianHill": "After installing the latest devtools release, I also just ran into the issue that running \"check\" or \"build\" does no longer produce a pdf-manual. It says --no-manual and I don't know how to change this. Is this a new issue of devtools or did i might have changed some settings?\n. @twolodzko Spending a bit more time reading the devtools-manual, I figured out that all options (including producing a pdf-manual) can actually be set if you call the respective functions \"check\" and \"build\" in the command line. E.g. checking with producing a manual goes like check(pkg = \".\", document = TRUE, build_args = NULL, ...,\n  manual = TRUE, cran = TRUE, check_version = FALSE,\n  force_suggests = FALSE, run_dont_test = FALSE, args = NULL,\n  env_vars = NULL, quiet = FALSE, check_dir = tempdir(), cleanup = TRUE).\nHowever, it seems to me that these options cannot be changed using the \"configure build tools\" in RStudio anymore. That would be worth a request @Hadley in my opinion.\n. ",
    "twolodzko": "@AndreasChristianHill sorry, this is what I meant - Rstudio. Running check(manual=TRUE) works fine, but needs you to wait until compilation, while R CMD Rd2pdf works instantly. As about Rstudio, I did not found any way to revert the default behavior to produce pdf's.\n. @hadley what about the code I proposed in my initial message? I may pull it (it works for me on Windows and Linux), but I can't see point of PR if for some reason you find it insufficient. Also my knowledge of what can go wrong in producing the pdf manuals is limited to practical issues, so I don't know what could potentially go wrong with the code (if it can).. There is also a related feature request to add function to build the pdf manually: https://github.com/hadley/devtools/issues/1238\n. @hadley manual is a part of documentation, it also needs to be checked. If you include TeX formulas (\\eqn{}{} and \\deqn{}{}) than from time to time there are issues with producing pdf's, so this needs running check(manual=TRUE) each time to check if the issue is solved. \n. @jimhester are you sure? The bug you link mentions usage of context(). I haven't set any context() in the tests that fail. The example given by @ELToulemonde also does not mention using it. Moreover, difference is between calling tests from devtools::test() and testthat::test_dir() etc., so testthat alone seems to be OK.. I made the two other edits you suggested, but I don't understand the syntax for callr::rcmd and I can't make it work.. @hadley thanks, done.. ",
    "dmurdoch": "It would only be accessible if it is exported in your NAMESPACE file.  If you're using roxygen2 to produce that file, are you telling it to export the symbol?  If you're writing it yourself, are you explicitly doing the export?  In any case, this doesn't look like a devtools issue.\n. No, it's still only in R-devel.  It probably should go into R-patched, I just haven't had time.  If you're planning a devtools update soon I'll try to push it forward, but otherwise I'd like to wait until things calm down here in December.\n. On 09/08/2017 11:00 AM, Hadley Wickham wrote:\n\nI don't think this is perfect, but the docs should be better now. It's hard to succinctly describe all the details.\n\nThanks, it looks good to me.\n. ",
    "flummoxed": "After trial and error -- located this prior thread with a solution which\nworked:\nhttps://github.com/klutometis/roxygen/issues/374\nThank you\nOn Mon, Jun 27, 2016 at 4:41 AM, dmurdoch notifications@github.com wrote:\n\nIt would only be accessible if it is exported in your NAMESPACE file. If\nyou're using roxygen2 to produce that file, are you telling it to export\nthe symbol? If you're writing it yourself, are you explicitly doing the\nexport? In any case, this doesn't look like a devtools issue.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hadley/devtools/issues/1241#issuecomment-228722676,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AGFtwB5O7YN_c6fVPcS9Jb2j7WOGmNpsks5qP7bmgaJpZM4I-vs1\n.\n. \n",
    "crarlus": "I can confirm this issue for R 3.1. \nError in if (capabilities(\"libcurl\")) { : argument is of length zero\nApparently this arises in older versions of R.\nIn R 3.3 \nhelp(\"capabilities\")\nstates\nlibcurl \nis libcurl available in this build? Used by function curlGetHeaders and optionally by download.file and url. As from R 3.3.0 always true for Unix-alikes, and true for CRAN Windows builds.\nThe entry for libcurl is missing in older versions of R.\nFurthermore, in https://cran.r-project.org/doc/manuals/r-release/NEWS.html it was announced\n```\nCHANGES IN R 3.2.0\n    ...\n    capabilities(\"libcurl\") reports if this is available.\n```\nHence, in file download-method.R one needs to check if the entry for \"libcurl\" exists at all, e.g.\nR\nany(names(capabilities()) == \"libcurl\")\n. ",
    "damesek": "These lines solved this problem at my case:\nsudo apt-get install libcurl4-openssl-dev libxml2-dev libxslt-dev libssl-dev -y\nsudo apt-get install r-base r-base-dev -y\n(ubuntu 14.04)\n. ",
    "vext01": "The workaround I used is:\n> options(download.file.method = \"wget\"). ",
    "rpodcast": "Just wanted to mention that I'm experiencing the same issue with private GitHub repositories that depend on packages in other GitHub private repositories.  I installed the dependency package from the other private repo first and the install went through without a hitch.  But during the installation of the main package from the private GitHub repo it still tries to install the dependency package even though it is already available.  FWIW I am using packrat with this project.\n. ",
    "filipsch": "I'm also seeing this issue. Exact same situation that @moosilauke18 mentions, but for private packages on GitHub.\n. ",
    "pierucci": "@HenrikBengtsson Thanks! The issue was fixed by applying your patch in the Travis-CI config file.\n. ",
    "jannepeltola": "It's still a problem for me with devtools::install_github(\"google/CausalImpact\") (or, more specifically, BoomSpikeSlab 0.7.0):\n```\nDownloading GitHub repo google/CausalImpact@master\nfrom URL https://api.github.com/repos/google/CausalImpact/zipball/master\nInstalling CausalImpact\ntrying URL 'https://cran.rstudio.com/src/contrib/bsts_0.6.5.tar.gz'\nContent type 'application/x-gzip' length 149015 bytes (145 KB)\n==================================================\ndownloaded 145 KB\ntar: Failed to set default locale\ntar: Failed to set default locale\nInstalling bsts\ntrying URL 'https://cran.rstudio.com/src/contrib/BoomSpikeSlab_0.7.0.tar.gz'\nContent type 'application/x-gzip' length 70988 bytes (69 KB)\n==================================================\ndownloaded 69 KB\ntar: Failed to set default locale\ntar: Failed to set default locale\nInstalling BoomSpikeSlab\nError in FUN(X[[i]], ...) : \n  Invalid comparison operator in dependency: >=\n```\nI was running the most recent version of devtools on a fresh install of R 3.3. \nInstalling the @HenrikBengtsson patch fixed the problem for me, but it would be good to have the fix upstream as well.\n. ",
    "dweichel": "@jimhester I'm running into the same issue as @jannepeltola. How should I proceed if I'm using a CRAN release 3.3.3?. ",
    "sconti555": "@jimhester Same thing here: I'm running into the exact same problem as @dweichel and @jannepeltola and seem to be able to successfully install neither the @HenrikBengtsson devtools patch (file no longer there) nor the fork (due to \"invalid package\" warnings followed by \"no packages\" specified errors).. I followed the same approach @zezantam adopted -- with the CRAN-sourced 'devtools' (version 1.12.0) package pre-installed -- and it worked for me as well.  Sincere thanks to you all for chipping in!. ",
    "zezantam": "@jimhester same here - same issue as @dweichel and @jannepeltola and @HenrikBengtsson is not available. thanks for such a quick reply @HenrikBengtsson - I solved it by running install.packages(\"BoomSpikeSlab\") \nbefore running \ndevtools::install_github(\"google/CausalImpact\")\nwhich probably effectively did the same thing as you suggested. ",
    "rdiaz02": "You are the boss, of course, but that behavior can break perfectly functional packages. In particular, the examples I give above show that comments, which should be innocuous, can lead to breakage. Moreover, this precludes a package author from tuning the output of Rcpp::compileAttributes() outside of devtools.\nI think that calling Rcpp::compileAttributes() should be optional and, ideally, its output should not overwrite the existing files (but be provided as a suggestion).\n. Not if I decide to add another argument to a function, for instance, or comment one out sometime after I got the output from compileAttributes. Modifying the files is simple. \nRegardless, one might want to use devtools on packages that have long had the compileAttributes dance taken care of but, as I showed above, that might fail.\n. ",
    "kiwiroy": "@hadley good call, done\n. Is this the cause in this reprex? Is there a solution?. Thanks for the confirmation @jimhester.\ndevtools::load_all() is responsible for ending at this point.\nSo this is a workaround using pkgload ::: internals and both \u2318 \u21e7 T and \u2318 \u21e7 E succeed, which saves a full check.\nIs this the responsibility of usethis and its .onLoad()?\n. ",
    "aschmu": "I'm also having the same problem on windows 7 Pro and Windows 10, I'll try and see if the same occurs on Ubuntu but I suspect it will. \nHere's a reproducible example, taken directly from the devtools documentation of install_source : \ndir <- tempfile()\ndir.create(dir)\npkg <- download.packages(\"mistral\", dir, type = \"source\")\ninstall_local(pkg[, 2])\nI have tried the above using R 3.3.1 (win 7 Pro and win 10) and 3.2.5 (win 10). Given @stulacy 's comments, I don't think it's a matter of platform or R version.\n. ",
    "thoughtfulbloke": "I am volunteering on helping in Mooc, and we have had a couple of reports of this in the past week as well, but it seems to be a tiny percentage of people (not me so I have nothing specific to add about the cause)\n. Hydebutterfly, In every case of this I have heard about, the manual extraction workaround found by stulacy (above) works- download the file from its archive on github, decompress the zip compressed file yourself so you have a folder with the package parts in it, and then do\ninstall_local(\"path/to/the/decompressed/folder\")\nusing the path to your decompressed folder.\n. ",
    "vsalmendra": "Same issue:\nWindows 8.1\ndevtools 1.12.0\nplatform       x86_64-w64-mingw32\narch           x86_64\nos             mingw32\nsystem         x86_64, mingw32\nstatus\nmajor          3\nminor          3.1\nyear           2016\nmonth          06\nday            21\nsvn rev        70800\nlanguage       R\nversion.string R version 3.3.1 (2016-06-21)\nnickname       Bug in Your Hair\n. ",
    "Hydebutterfy": "I am a learner in Mooc from China. Because China web control I have to chose install_local(). However it does not work. Any advice?\ninstall_local(file.choose())\nError in git2r::discover_repository(path, ceiling = 0) : \nError in 'git2r_repository_discover': The .git file at '/Users/XXXXXX/Desktop/statsr-master.zip' is malformed\n. ",
    "javier6723": "thanks a lot @thoughtfulbloke, I tried this and it works perfectly\n. ",
    "happyshows": "@thoughtfulbloke  I tried but it starts to look for all the dependency packages... Does that mean I'll have to remove the dependency package in description file every time I want to install a package?\n. This is really a nasty issue and I'll have to spend 10x more time on updating my packages :S\n. ",
    "caiomsouza": "I changed from install_local to install() and it worked for me as suggested by @jimhester Thanks for the advice. \nMy code as example:\nlibrary(devtools)\ndevtools::install(\"/Users/caiomsouza/git/github.com/SparkR-pkg/pkg/\")\n. ",
    "dfrankow": "Didn't work for me:\ndevtools::install(\"/Users/dan/work/foo\")\nInstalling foo\n'/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file --no-environ --no-save --no-restore --quiet  \\\n  CMD INSTALL '/Users/dan/work/foo'  \\\n  --library='/Library/Frameworks/R.framework/Versions/3.2/Resources/library' --install-tests \n\ninstalling source package \u2018foo\u2019 ...\n R\n tests\n preparing package for lazy loading\n help\n installing help indices\n* building package indices\n testing if installed package can be loaded\nDONE (foo)\nError in git2r::discover_repository(path, ceiling = 0) : \n  unused argument (ceiling = 0)\n\n\nR.version.string\n[1] \"R version 3.2.4 (2016-03-10)\"\n\nOS X 10.12.1\n. This appeared for me with install_local. ",
    "yonicd": "this works for me\n```\ninstall_remote=function (path, ..., force = FALSE, quiet = FALSE){\n  remotes <- lapply(path, devtools:::local_remote, subdir = NULL)\n  invisible(vapply(remotes,FUN = function(remote){\n    stopifnot(devtools:::is.remote(remote))\n    bundle <- devtools:::remote_download(remote, quiet = quiet)\n    on.exit(unlink(bundle), add = TRUE)\n    source <- devtools:::source_pkg(bundle, subdir = remote$subdir)\n    on.exit(unlink(source, recursive = TRUE), add = TRUE)\n    devtools::install(source, ..., quiet = quiet)  \n  }, FUN.VALUE = logical(1)))\n}\n```. ",
    "benjjneb": "I just ran into this same issue after making an innocuous change to my Bioconductor package (https://github.com/benjjneb/dada2).\nAdding both use_bioc: true and bioc_required: true to  .travis.yml finally fixed the problem, but why did this suddenly crop up?\n. ",
    "pkq": "Is this what you had in mind?\n. I've cleaned this pull request up a bit, PTAL. Any guidance regarding testing is appreciated. Thanks!. Thank you!. ",
    "eriknil": "We get the same error when specifying a remote package in the DESCRIPTION that doesn't exist.\nI've uploaded a package on eriknil/depError that will fail to install because of this. Reproducible example below:\n``` r\n\ndevtools::install_github(\"eriknil/depError\")\nDownloading GitHub repo eriknil/depError@master\nfrom URL https://api.github.com/repos/eriknil/depError/zipball/master\nInstalling depError\nError in data.frame(package = package, installed = installed, available = available,  : \n  row names contain missing values\n```\n\nI updated the PR to fix this.\n. I ended up using the old r-travis instead. Had to change a few things but this allowed me to install my own fork of devtools. Just a temporary solution though.\nWould be glad to update the PR if there's anything else needed.\n. of course\n. ",
    "DavidSichau": "We have currently the same problem, is there any chance that this pull request can be accepted?\n. ",
    "dy-kim": "@jimhester ~~Is it r_github_packages: hadley/devtools#1263, not r_github_packages: hadley/devtools#1262?~~\nOh, I've checked it.\n. @jimhester Recently, I've updated what you suggested. Please review the changes.. @hadley Yes, I've heard those story from @jimhester at the latest useR conference. I would review the up-to-date remotes and make issues and PRs if needed.. @hadley I agree minimizing scope for devtools in supporting GitHub. But still, I think getting SHA from GitHub could be included in the minimal requirements for installing from GitHub. \nSo I'd like to suggest building github_response at least to be able to handle a response for a SHA request(or making use of the functionality from gh).\n. Can we get an advice from @jimhester ?\n. @cderv I've resolved this issue by PR #1382. May be you can find another solution on this.. I've referred the following GitHub API.\nPlease give attention that this codes are using unexported function github_GET() from devtools.\nend_point <- \"repos/OHDSI/OhdsiRTools/releases/latest\"\nresponse <- devtools:::github_GET(end_point)\nlatest_tag_name <- response$tag_name\ndevtools::install_github(\"OHDSI/OhdsiRTools\", ref = latest_tag_name)\n. I'll close the precedent but now duplicated issue #1491 . Okay \ud83d\udc4d \n. I see, I'll fix the  problems.\n. I didn't consider the case of windows. Thanks. I'll change utils::download.file to be called without the method set. Also, the tip using .RProfile would be helpful \ud83d\udc4d \n. I've checked the references again. I missed some important points as you mentioned. I think the first method would be appropriate. The latter one requires local SHA which is not considered in the present remote_sha.github_remote. Moreover, the role of remote_sha.github_remote should be simply returning remote SHA and  doing something more(compare and return logical info).\n. So I've tried the first method, by passing the extra argument httr::add_headers(Accept = \"application/vnd.github.VERSION.sha\") to github_GET. In this case the line github_response(req) inside of the definition of github_GET raise an issue and I've documented it (hadly/devtools#1384). \n. To sum these up, I'd like to approach with the first suggested method, and it carries an issue rooted from the restriction in the github_GET, but I don't want to avoid this problem by not using github_GET. Instead, I think it is better to extend github_GET together in this time.\n. ",
    "jucor": "Hi @jimhester , @hadley : any chance you'd share no-commitment guesstimate when is the \"next time [you] are doing devtools maintenance\"? Promise, we won't hold you to it, but it's been 3 months since your message, Jim :). Great, thanks a lot for the quick answer and the heads up @jimhester!  (and it is pre-emptively understood that \"plan\" and \"reality\" do not always match). ",
    "kirillseva": "@jimhester ;). ",
    "deanchen": "Would be great if we can get this supported within devtools. We've been maintaining a forked version of devtools for this reason.. @jimhester we're maintaining our own branch of devtools with the PR since reference private repos doesn't work without this. would appreciate it if you can take some time to review and merge this in.. ",
    "cmdcolin": "This is just a random note but I ran into this same error message when I had a \"Remotes:\" line in my description file that separated the two things by spaces instead of comma, and then installed the app via install_github. If devtools was able to catch that error it would be great ;) but otherwise just thought I'd add that note for posterity. I was seeing something that reminded me of this\nWhen I installed my package which lists shiny as a Depends with install_github it would produce errors about httpuv and Rcpp etc not being installed.  I could try to make a minimal test case too if there is interest\nI didn't try using the latest devtools because it said it needed Rtools which seemed a little bit heavy duty. ",
    "jalazawa": "I have the same issue . ",
    "malwinare": "@jimhester Since devtools is under going some changes and will be spilt into smaller packages, would it be maybe a good time to pick up this issue? \nWe use devtool::intall_git() on a regular basis and it would be great if you could make installing from a tag possible, despite of still open issue about git2r::checkout. We would really appreciate it.  \nThank you in advance. . ",
    "blosloos": "The whole may be related to problems referenced here: \nhttps://github.com/krlmlr/r-appveyor/issues/69\nand finally\nhttps://github.com/dgrtwo/widyr/pull/3\n. Ok! Wow, thanks for your speedy reply on labour's day!. ",
    "Chris-Larkin": "The issue page hadley/devtools/issues/1266 seems to indicate this has been fixed, but I'm getting the same error as @Cauchy2. I've updated devtools and attempted to call gist_source() but to no avail.\n```\n\nlibrary(devtools)\nsource_gist(9112634)\nError in r_files[[which]] : invalid subscript type 'closure'\n```\n\nI'm a bit of a novice with this stuff so apologies in advance if i'm missing something simple!\n. ",
    "adamdsmith": "Of course.  Thanks for your patience...\n. Fair enough.  I'll adjust accordingly. You already exit with an error when length(r_files) == 0 so no additional modification is necessary.  Thanks!\n. ",
    "stla": "Similar problem with devtools:release().\n. Because available.packages() works with file:~/xxx, if I well remember (not sure, I have abandoned to use packrat since, but I remember that something works).. Hmm.. however there's this solution:\nrepo <- c(SL=\"file:////Rixdsntp001/cmcstat/7~1.STA/71-IA~1/LOCALA~1/CRANLI~1\")\nTo get such an \u201cencoding\u201d, use the function shortPathName.\n. Try to run devtools::find_rtools() before, then run document().. My package is here: https://github.com/stla/hwriteXLSX but I don't upload the DLL\"s on Github because they are big. Do you see any problem with the architecture? The package works fine. \nI can create a package with a small DLL if needed.. Mmmh sorry, since I don't upload the DLL you cannot see the architecture.  I put the DLLs in inst/libs like this:\n``\ninst\n|\n+- libs\n|  |\n|  +- x64\n|  |  |\n|  |- json2xlsx.dll\n|  |\n|  +- json2xlsx.so\n|  |\n|  - i386\n|     |\n|- json2xlsx.dll\n```\n. ",
    "privefl": "```\nSuggestsNote: BioC (>= 3.0)\nAdditional_repositories: http://bioconductor.org/packages/release/bioc/\nbiocViews:\n```\nwon't work anymore (tested on Travis).\n. See fix at https://github.com/privefl/bigsnpr/pull/1.\nThanks jimhester.\n. I have the same issue. \nDeleting the contents of NAMESPACE didn't change the warning: Warning: The existing 'NAMESPACE' file was not generated by roxygen2, and will not be overwritten..\nCommand used: devtools::document(roclets=c('rd', 'collate', 'namespace')).. ",
    "cosli": "@Luxios \nJust try to reinstall R in a dirctory where the path doesn't include space , like D:/R . \n. @burgerga Yes, that would be the best way by making devtools package to handle this error properly.\n. ",
    "burgerga": "@cosli that is not always possible, and seen the numerous threads/issues opened everywhere, it would definitely by easier if devtools would properly escape paths.\n. @Luxios I was having another look at it, but can't reproduce the issue with the newest R, 3.3.1, can you?\n. ",
    "sherkwast": "@burgerga  No,I can't. I tried to use another tool.Has the problem be solved?\n. ",
    "mdsumner": "Well fwiw, they turn out very different in tarball and on CRAN than in RStudio (map figures were always too small) but I've trained myself and pkgdown provides a great mech, and release_checks can do this job if anyone wants a prompt.\n. ",
    "reuning": "I think it has to do with a path issue caused by my lack of ability to edit the path. Fixed it now by reinstalling R into a happier place. \n. ",
    "rubenarslan": "Can this somehow be fixed in devtools by somehow escaping the path/using short DOSpaths with ~? It's really hard to debug for non-technical users and not a very googleable error message when it happens. It can even happen for packages that don't need compilation.\n. ",
    "jdeligt": "Seems to be in the binary. Full stack trace below;\n```\n  caught segfault \naddress 0x18, cause 'memory not mapped'\nTraceback:\n 1: dyn.load(file, DLLpath = DLLpath, ...)\n 2: library.dynam(lib, package, package.lib)\n 3: loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]])\n 4: asNamespace(ns)\n 5: namespaceImportFrom(ns, loadNamespace(j <- i[[1L]], c(lib.loc,     .libPaths()), versionCheck = vI[[j]]), i[[2L]], from = package)\n 6: loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]])\n 7: asNamespace(ns)\n 8: namespaceImportFrom(ns, loadNamespace(j <- i[[1L]], c(lib.loc,     .libPaths()), versionCheck = vI[[j]]), i[[2L]], from = package)\n 9: loadNamespace(package, lib.loc)\n10: doTryCatch(return(expr), name, parentenv, handler)\n11: tryCatchOne(expr, names, parentenv, handlers[[1L]])\n12: tryCatchList(expr, classes, parentenv, handlers)\n13: tryCatch(expr, error = function(e) {    call <- conditionCall(e)    if (!is.null(call)) {        if (identical(call[[1L]], quote(doTryCatch)))             call <- sys.call(-4L)        dcall <- deparse(call)[1L]        prefix <- paste(\"Error in\", dcall, \": \")        LONG <- 75L        msg <- conditionMessage(e)        sm <- strsplit(msg, \"\\n\")[[1L]]        w <- 14L + nchar(dcall, type = \"w\") + nchar(sm[1L], type = \"w\")        if (is.na(w))             w <- 14L + nchar(dcall, type = \"b\") + nchar(sm[1L],                 type = \"b\")        if (w > LONG)             prefix <- paste0(prefix, \"\\n  \")    }    else prefix <- \"Error : \"    msg <- paste0(prefix, conditionMessage(e), \"\\n\")    .Internal(seterrmessage(msg[1L]))    if (!silent && identical(getOption(\"show.error.messages\"),         TRUE)) {        cat(msg, file = stderr())        .Internal(printDeferredWarnings())    }    invisible(structure(msg, class = \"try-error\", condition = e))})\n14: try({    attr(package, \"LibPath\") <- which.lib.loc    ns <- loadNamespace(package, lib.loc)    env <- attachNamespace(ns, pos = pos, deps)})\n15: library(\"devtools\")\n``\n.\nR\ninstall.packages(\"devtools\")\n`\n. ",
    "alexDeCastroAtGit": "I'm having the same issue: \n* caught segfault *\naddress 0x18, cause 'memory not mapped'\nTraceback:\n 1: dyn.load(file, DLLpath = DLLpath, ...)\n 2: library.dynam(lib, package, package.lib)\n 3: loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]])\n 4: asNamespace(ns)\n 5: namespaceImportFrom(ns, loadNamespace(j <- i[[1L]], c(lib.loc,     .libPaths()), versionCheck = vI[[j]]), i[[2L]], from = package)\n 6: loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]])\n 7: asNamespace(ns)\n 8: namespaceImportFrom(ns, loadNamespace(j <- i[[1L]], c(lib.loc,     .libPaths()), versionCheck = vI[[j]]), i[[2L]], from = package)\n 9: loadNamespace(package, lib.loc, keep.source, partial = TRUE)\n10: withCallingHandlers(expr, packageStartupMessage = function(c) invokeRestart(\"muffleMessage\"))\n11: suppressPackageStartupMessages(loadNamespace(package, lib.loc,     keep.source, partial = TRUE))\n12: code2LazyLoadDB(package, lib.loc = lib.loc, keep.source = keep.source,     compress = compress)\n13: makeLazyLoading(pkg_name, lib, keep.source = keep.source)\n14: doTryCatch(return(expr), name, parentenv, handler)\n15: tryCatchOne(expr, names, parentenv, handlers[[1L]])\n16: tryCatchList(expr, classes, parentenv, handlers)\n17: tryCatch(expr, error = function(e) {    call <- conditionCall(e)    if (!is.null(call)) {        if (identical(call[[1L]], quote(doTryCatch)))             call <- sys.call(-4L)        dcall <- deparse(call)[1L]        prefix <- paste(\"Error in\", dcall, \": \")        LONG <- 75L        msg <- conditionMessage(e)        sm <- strsplit(msg, \"\\n\")[[1L]]        w <- 14L + nchar(dcall, type = \"w\") + nchar(sm[1L], type = \"w\")        if (is.na(w))             w <- 14L + nchar(dcall, type = \"b\") + nchar(sm[1L],                 type = \"b\")        if (w > LONG)             prefix <- paste0(prefix, \"\\n  \")    }    else prefix <- \"Error : \"    msg <- paste0(prefix, conditionMessage(e), \"\\n\")    .Internal(seterrmessage(msg[1L]))    if (!silent && identical(getOption(\"show.error.messages\"),         TRUE)) {        cat(msg, file = stderr())        .Internal(printDeferredWarnings())    }    invisible(structure(msg, class = \"try-error\", condition = e))})\n18: try({    suppressPackageStartupMessages(.getRequiredPackages(quietly = TRUE))    makeLazyLoading(pkg_name, lib, keep.source = keep.source)})\n19: do_install_source(pkg_name, instdir, pkg, desc)\n20: do_install(pkg)\n21: tools:::.install_packages()\nAn irrecoverable exception occurred. R is aborting now ...\n/usr/local/Cellar/r/3.3.1_3/R.framework/Resources/bin/INSTALL: line 34: 94825 Done                    echo 'tools:::.install_packages()'\n     94826 Segmentation fault: 11  | R_DEFAULT_PACKAGES= LC_COLLATE=C \"${R_HOME}/bin/R\" $myArgs --slave --args ${args}\nWarning in install.packages :\n  installation of package \u2018devtools\u2019 had non-zero exit status\n. Hi Hadley, apologies, I was on leave from work. I think that was an issue with my ROR. In the latest CRAN release I can install devtools fine. \nThanks,\nAlex\n. What's \"reprex\" here? \n. ",
    "merliseclyde": "I  had the same issue after upgrading to Mac OS X 10.12.4 and with  R 3.4.0. (same errors)\nI removed all /Library/Frameworks/R.frameworks files, reinstalled R and the issues went away (temporarily).\nFor tracking down another issue I installed R from source via macports, rebuilt packages from source.  However running the binary R from CRAN via the GUI or RStudio the seg faults with loading libraries reappeared.  Reinstalled Xcode, deleted libraries, reinstalled R from CRAN, etc...  but still had seg faults.\nFinally looked at .libPath() and realized that both instances of R were looking at the user library before the system library.   So if the packages were linked to different  system libraries from the compiled versions (OS X  Sierra and El Capitan in my case) this could create the seg fault.\nRemoving libraries in the  user library  ~/user/Library/R/version#  fixed the issue (with installing to different locations)\nI believe the issue occured from a  mix of installing packages from install.packages() under both versions without specifying lib  as  the default uses the first entry in  .libPath()  pointed to the same directory rather than the system library.    . @wch  Very useful!    Wish that had been posted last week :-)  . ",
    "lshep": "Thank you. My mistake.\n. ",
    "boxuancui": "I see. I will close it. Thanks for your help!\n. ",
    "charlottesirot": "So just to be sure, I did:\n1. Open R\n2. run:\n```\n\nlibrary(devtools)\ndevtools::install_github(\"hadley/devtools\", force = T)\n```\n\nEverything is OK\n1. I closed R\n2. I reopened R\n3.  and then:\n```\n\nlibrary(devtools)\ninstall_github('Rstudio/DT', dependencies = T)\nDownloading GitHub repo Rstudio/DT@master\nfrom URL https://api.github.com/repos/Rstudio/DT/zipball/master\nInstalling DT\n\"C:/PROGRA~1/R/R-33~1.1/bin/i386/R\" --no-site-file --no-environ --no-save  \\\n  --no-restore --quiet CMD INSTALL  \\\n  \"C:/Users/cha/AppData/Local/Temp/Rtmp4UqfDo/devtools7c45b22c6f/rstudio-DT-25d879b\"  \\\n  --library=\"C:/Users/cha/Documents/R/win-library/3.3\" --install-tests \n\n\ninstalling source package 'DT' ...\n R\n inst\n** preparing package for lazy loading\nError in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) : \n  there is no package called 'Rcpp'\nERROR: lazy loading failed for package 'DT'\nremoving 'C:/Users/cha/Documents/R/win-library/3.3/DT'\nError: Command failed (1)\n```\n\nDo I understand well ??\nAgain thank you so much for your help \nCha\n. ",
    "fbreitwieser": "I have the same issue on Windows (R 3.3.2 32bit), and the problem persists after restarting R.\n. ",
    "jrgant": "I'm still having this issue as well. I have tried devtools 1.12.0 and 1.12.0.9000 (went the Rtools route) in R 3.3.2 and 3.3.3. Nothing I've tried has succeeded in getting the sub-dependencies to be installed, unfortunately.. ",
    "vedatAltun": "try to download libxml2-dev libs for Ubuntu 16.04\nsudo apt-get install libxml2-dev or sudo apt-get install libxml2\nand reinstall your package in R Studio. ",
    "hansharhoff": "I traced the calling functions from\n\ndevtools::test()\n\nto\n\ntestthat::test_dir\n\nto\n\ntestthat::test_files\n\nto\n\ntestthat::test_file\n\nand finally to\n>testthat::source_file\nThis uses readLines to get the lines from the test-R-file. I can confirm that using:\n\nreadLines(pathToFile, encoding = \"UTF-8\") \n\nreads the file correctly.\nBut \n\nreadLines(pathToFile) \n\ndoes not.\nSo propagating the encoding to this function would solve the problem.\n. I have made two pull requests in regards to this issue. They should fix the issue without disturbing any functionality. I also to add a test to test the filter parameter of test(), but I did not manage to make a consistent test since the indirection of pointing at another set of tests confused me.\nI also did not add a test of the encoding issue, in part because it only occurs on some platforms.\n. I believe this is closely related to issue #1312\n. Agreed. Removed.\n. I added a line break. The issue is #1306. Do I need more information here?\n. ",
    "ewymathe": "Thanks for the prompt response!  Unfortunately, I'm still getting an error though.\n```\nEwys-MBP:~ ewymathe$ svn info https://hedgehog.fhcrc.org/bioconductor/branches/RELEASE_3_3/madman/Rpacks\nError validating server certificate for 'https://hedgehog.fhcrc.org:443':\n - The certificate is not issued by a trusted authority. Use the\n   fingerprint to validate the certificate manually!\nCertificate information:\n - Hostname: *.fhcrc.org\n - Valid: from Sat, 18 Oct 2014 16:52:00 GMT until Fri, 23 Nov 2018 15:15:23 GMT\n - Issuer: http://certs.godaddy.com/repository/, GoDaddy.com, Inc., Scottsdale, Arizona, US\n - Fingerprint: 55:64:9d:ce:78:a9:b0:b4:2f:df:4c:c6:59:b1:51:56:bb:5c:44:6a\n(R)eject, accept (t)emporarily or accept (p)ermanently? p\nPath: Rpacks\nURL: https://hedgehog.fhcrc.org/bioconductor/branches/RELEASE_3_3/madman/Rpacks\nRepository Root: https://hedgehog.fhcrc.org/bioconductor\nRepository UUID: bc3139a8-67e5-0310-9ffc-ced21a209358\nRevision: 120436\nNode Kind: directory\nLast Changed Author: jspidlen@bccrc.ca\nLast Changed Rev: 120432\nLast Changed Date: 2016-08-25 16:34:54 -0400 (Thu, 25 Aug 2016)\n```\nThen in R:\n```\n\nhttps://hedgehog.fhcrc.org/bioconductor/branches/RELEASE_3_3/madman/Rpacks/org.Hs.eg.db\nError: unexpected '/' in \"https:/\"\ninstall_github(\"ewymathe/testALTREinstall\")\nDownloading GitHub repo ewymathe/testALTREinstall@master\nfrom URL https://api.github.com/repos/ewymathe/testALTREinstall/zipball/master\nInstalling ALTRE\nsvn: warning: W170000: URL 'https://hedgehog.fhcrc.org/bioconductor/branches/RELEASE_3_3/madman/Rpacks/org.Hs.eg.db' non-existent in revision 120437\n\nsvn: E200009: Could not display info for all targets because some targets don't exist\nInstallation failed: There was a problem retrieving the current SVN revision\nWarning message:\nrunning command ''/usr/bin/svn' info --xml --username readonly --password readonly https://hedgehog.fhcrc.org/bioconductor/branches/RELEASE_3_3/madman/Rpacks/org.Hs.eg.db' had status 1\n```\nAlso, when I try to access the link in my browser, I'm being asked for authentication...\nAny other thought(s)?\n. I have played around with this a bit more and am still perplexed, thinking it is something with the install_github() function.\nSpecifically, I have set the repositories and am able to successfully install \"org.Hs.eg.db\" with install.packages():\n```\n\nmyrepos=biocinstallRepos()\ninstall.packages(\"org.Hs.eg.db\",repos=myrepos)\ninstalling the source package \u2018org.Hs.eg.db\u2019\n\ntrying URL 'https://bioconductor.org/packages/3.3/data/annotation/src/contrib/org.Hs.eg.db_3.3.0.tar.gz'\nContent type 'application/x-gzip' length 69122902 bytes (65.9 MB)\n====^C==\n============================================\ndownloaded 65.9 MB\n\n```\n\nSo I know my repos will grab the package.  However, if I try to install with install_github() while passing the repos, it still cannot find the package:\n```\n\nlibrary(devtools)\ninstall_github(\"ewymathe/testALTREinstall\",repos=myrepos)\nDownloading GitHub repo ewymathe/testALTREinstall@master\nfrom URL https://api.github.com/repos/ewymathe/testALTREinstall/zipball/master\nInstalling ALTRE\n'/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file --no-environ  \\\n  --no-save --no-restore --quiet CMD INSTALL  \\\n  '/private/var/folders/j4/m74j380917j4njwrrvf2fh480000gn/T/Rtmp3VEYyF/devtools762b528dbac0/ewymathe-testALTREinstall-000280d'  \\\n  --library='/Library/Frameworks/R.framework/Versions/3.3/Resources/library'  \\\n  --install-tests\n\nERROR: dependency \u2018org.Hs.eg.db\u2019 is not available for package \u2018ALTRE\u2019\n* removing \u2018/Library/Frameworks/R.framework/Versions/3.3/Resources/library/ALTRE\u2019\nInstallation failed: Command failed (1)\n```\nAny idea what is happening?\n. ",
    "shrektan": "Ha a little suggest that you may want to have a better commit history by use git reset --soft HEAD~8 , rewrite the commit log, and git push -f hansharhoff add-encoding-support\n. @hadley Oh, just notice that the load_all() has been moved to https://github.com/r-pkgs/pkgload \nHowever, I just added support for reading encoding from DESCRIPTION as well as a unit test. . Close because related code has been moved to https://github.com/r-pkgs/pkgload. you should declare the linking in the DESCRIPTION file. I'm pretty sure this is necessary, because I just reproduced this to confirm.\n1. Let's say we are working on a windows platform, whose native encoding is not utf-8,\n2. If we have a function (e.g., futf8()) that contains nonASCII chars in some package ,\n3. Without lines <- enc2native(lines), devtools::load_all() performs good and the function futf8() works well,\n4. But, if you print(futf8), you will find mess in the console,\n5. It will be solved by adding this line.\nwithout the line\n\nwith this line\n\n. ",
    "victorvicpal": "I have the same issue installing my MGSR package on a Jupyter notebook.. ",
    "alexWhitworth": "@jimhester -- Thanks!! I clearly missed that. And I like Winston's idea. I'm guessing I'm not the only person who's only skimmed the R-Ext Manual / uses it as a reference on an as-needed basis. \n. ",
    "mpettis": "Following these instructions helped me (found after having similar issue, finding this issue): https://github.com/hadley/devtools/issues/426\n. Did you try the instructions at: https://github.com/hadley/devtools/issues/426 ?\n. Following these instructions helped me (found after having similar issue, finding this issue): https://github.com/hadley/devtools/issues/426\n. ",
    "lbusett": "Hi. having the same problem on Windows 10 64 bit\n. thanks. solved.\nI actually DID try those instructions before posting, and it wasn't working... I probably just had to restart RStudio.\n. HI. I have the same issue: run_example fails with \nError in FUN(X[[i]], ...) : unused argument (show = TRUE)\n\n\nsessionInfo()\nR version 3.4.1 (2017-06-30)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows >= 8 x64 (build 9200)\nMatrix products: default\nlocale:\n[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252 \n[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C                         \n[5] LC_TIME=English_United Kingdom.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.13.2.9000\nloaded via a namespace (and not attached):\n[1] compiler_3.4.1      tools_3.4.1         withr_1.0.2         memoise_1.1.0       pkgload_0.0.0.9000 \n[6] digest_0.6.12       pkgbuild_0.0.0.9000 rlang_0.1.1         . \n",
    "bgreenwell": "I was not aware of that, thanks for the tip!\n. ",
    "melindahiggins2000": "I agree. It would be nice for the Date to be automatically loaded into the DESCRIPTION file by default. That way (for example) citation(\"tidyr\") won't throw the warning message that\nWarning messages:\n1: In citation(\"tidyr\") :\n  no date field in DESCRIPTION file of package \u2018tidyr\u2019\n2: In citation(\"tidyr\") :\n  could not determine year for \u2018tidyr\u2019 from package DESCRIPTION file\nThe current citation for the tidyr package lists the date as NA\nHadley Wickham (NA). tidyr: Easily Tidy Data with\n  `spread()` and `gather()` Functions. R package\n  version 0.6.0.9000. https://github.com/hadley/tidyr\nThis will most likely generate nagging comments from journal reviewers when citing R packages in manuscripts/publications.\n. Ahh good point - I see now the difference in the CRAN vs development Github versions. I just think in general it is good practice to track the date of the current version in use and when cited. Thank you for the clarification. \n. ",
    "dracodoc": "@jimhester If I'm understanding correctly, this is not implemented yet\n\nwe could add this same field to the package description when we install it from GitHub\n\nI think that can actually be very helpful, not just for citation usage.\n\nThis will not conflict with CRAN version since CRAN just ignore it.\nThis is still very useful because a lot of packages now deliver through install_github now, and lots of users just use the github version instead of CRAN version.\nThis kind of timestamp should be managed automatically, and the best place for this date is the package building process.\nFor github hosted packages, version is often not enough. A build date is more accurate and useful.\n\n. That package was moved to organization repo here\nhttps://github.com/ctmm-initiative/ctmm\n(This comment is made by my personal github account when I replied in email directly) . The fact that manual restart R session works make me wonder if the build and reload function called .rs.restartR(), but that function didn't do these two things according to this \n- Data from current session is removed\n- Packages from current session are unloaded\nIt's probably not this simple, since I don't think packages are not unloaded, which is part of the whole purpose.\nI didn't find the code of the build and reload function so I can only guess this much.\n. Great, thanks!. I had similar issue but it's with current CRAN version 1.13.5, and I'm not using ref. \nThe example below is simple and didn't create much problems, however when I try to install httpuv it always fail to compile because of fopenmp support in Mac. In every try it will compile promise and later first then start to compile httpuv. I think promise and later should at least be skipped because they can be compiled properly.\n```r\n\ndevtools::install_github(\"r-lib/crayon\")\nDownloading GitHub repo r-lib/crayon@master\nfrom URL https://api.github.com/repos/r-lib/crayon/zipball/master\nInstalling crayon\n'/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file --no-environ --no-save --no-restore  \\\n  --quiet CMD INSTALL  \\\n  '/private/var/folders/f3/6cdx4zf94qz95r6d89s_4xcsrcsjqm/T/RtmpWhp3NA/devtools183212980998b/r-lib-crayon-95b3eae'  \\\n  --library='/Library/Frameworks/R.framework/Versions/3.4/Resources/library' --install-tests \n\n\ninstalling source package \u2018crayon\u2019 ...\n R\n inst\n tests\n preparing package for lazy loading\n** help\n installing help indices\n* building package indices\n testing if installed package can be loaded\n\nDONE (crayon)\n\ndevtools::install_github(\"r-lib/crayon\")\nDownloading GitHub repo r-lib/crayon@master\nfrom URL https://api.github.com/repos/r-lib/crayon/zipball/master\nInstalling crayon\n'/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file --no-environ --no-save --no-restore  \\\n  --quiet CMD INSTALL  \\\n  '/private/var/folders/f3/6cdx4zf94qz95r6d89s_4xcsrcsjqm/T/RtmpWhp3NA/devtools1832116e48be2/r-lib-crayon-95b3eae'  \\\n  --library='/Library/Frameworks/R.framework/Versions/3.4/Resources/library' --install-tests \n\n\n\ninstalling source package \u2018crayon\u2019 ...\n R\n inst\n tests\n preparing package for lazy loading\n** help\n installing help indices\n* building package indices\n testing if installed package can be loaded\n\nDONE (crayon)\n```\n\n```r\n\nsessionInfo()\nR version 3.4.3 (2017-11-30)\nPlatform: x86_64-apple-darwin15.6.0 (64-bit)\nRunning under: macOS Sierra 10.12.2\n\nMatrix products: default\nBLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nloaded via a namespace (and not attached):\n [1] httr_1.3.1      compiler_3.4.3  R6_2.2.2        tools_3.4.3     withr_2.1.1     curl_3.1     \n [7] yaml_2.1.16     memoise_1.1.0   git2r_0.21.0    digest_0.6.15   devtools_1.13.5\n```. @jimhester I think I found the problem.\nI clone the package, added browser() in various place to track down the problem. \nThis line remote_sha <- remote_sha(remote) didn't return a valid sha value from remote.\n```r\nBrowse[1]> remote\n$host\n[1] \"https://api.github.com\"\n$repo\n[1] \"crayon\"\n$subdir\nNULL\n$username\n[1] \"r-lib\"\n$ref\n[1] \"master\"\n$sha\nNULL\n$auth_token\nNULL\nattr(,\"class\")\n[1] \"github_remote\" \"remote\"      \nBrowse[1]> remote_sha(remote)\n[1] NA\nBrowse[1]> remote_sha.github_remote(remote)\n[1] NA\n```\nIt's because this line has error\nr\nBrowse[1]> git2r::remote_ls(\n+       paste0(url, \"/\", remote$username, \"/\", remote$repo, \".git\"))\nError in git2r::remote_ls(paste0(url, \"/\", remote$username, \"/\", remote$repo,  : \n  Error in 'git2r_remote_ls': SSL error: error:1407742E:SSL routines:SSL23_GET_SERVER_HELLO:tlsv1 alert protocol version\nThis could be platform dependent, so it only generate error for some users, like @mrustl , myself, and another issue #1731 created today by @carlganz .\nThis remote_sha.github_remote function only appeared in devtools, not in remotes. I used the code in remotes to replace this line (remotes don't have this problem for me)\nr\n  # remote_sha <- remote_sha(remote)\n  remote_sha <- github_commit(remote$username, remote$repo, remote$ref)$sha\nand the problem is fixed for me.\n```r\n\ndevtools::install_github(\"r-lib/crayon\")\nSkipping install of 'crayon' from a github remote, the SHA1 (95b3eae3) has not changed since last install.\n  Use force = TRUE to force installation\n```\n\nOf course the github_commit is only used to prove the problem cause is here, I'm not sure if it's the best solution. However to check sha from remote, this seemed to be the only alternative other than git2r, and git2r may have more dependency issues especially with SSL error.\nBy the way, I noticed there were quite some difference between devtools and remotes in this section now\n- remote_metadata.github_remote in remote is using different sha fetching methods\n-  remotes don't has the remote_sha.github_remote function\n- and the commit history in two packages in this aspect are in quite different directions.\nI think devtools is trying to diaspora this part to remotes, so this could be a difficult task given the differences now.\n. It's also possible the cause I found is not the same cause for @mrustl and @carlganz , because they only have problem in a special case, but I'm having the problem in general case. However I think the places I found should be the most possible location.\nBecause of this, and the complexity of remotes and devtools difference, I didn't create a PR.\nI did create a branch in my local fork, so @mrustl and @carlganz can test with that to see if it will solve your problem. Just install with\n```r\n\ndevtools::install_github(\"dracodoc/devtools\", ref = \"sha-checking\")\nDownloading GitHub repo dracodoc/devtools@sha-checking\nfrom URL https://api.github.com/repos/dracodoc/devtools/zipball/sha-checking\nInstalling devtools\nSkipping install of 'crayon' from a github remote, the SHA1 (95b3eae3) has not changed since last install.\n  Use force = TRUE to force installation\nSkipping install of 'enc' from a github remote, the SHA1 (6b0171d9) has not changed since last install.\n  Use force = TRUE to force installation\nSkipping install of 'memoise' from a github remote, the SHA1 (611cfadb) has not changed since last install.\n  Use force = TRUE to force installation\n....\n```\n\nThe installation process already proved the problem is fixed for me.. @jimhester I further tracked to your original PR for this feature #903 when I was reading a similar issue in remotes .\nMy hack above is not optimal because of the github api limit concern mentioned by you. So I checked again. Maybe we should use SSH url instead of HTTPS?\nr\nremote_sha.github_remote <- function(remote, url = \"git@github.com:\", ...)\nAnd this worked for me\n```r\n\ndevtools::install_github(\"r-lib/crayon\")\nCalled from: remote_sha.github_remote(remote)\nBrowse[1]> url = \"https://github.com\"\nBrowse[1]> git2r::remote_ls(\n+       paste0(url, \"/\", remote$username, \"/\", remote$repo, \".git\"))\nError in git2r::remote_ls(paste0(url, \"/\", remote$username, \"/\", remote$repo,  : \n  Error in 'git2r_remote_ls': SSL error: error:1407742E:SSL routines:SSL23_GET_SERVER_HELLO:tlsv1 alert protocol version\nBrowse[1]> url = \"git@github.com:\"\nBrowse[1]> git2r::remote_ls(\n+       paste0(url, \"/\", remote$username, \"/\", remote$repo, \".git\"))\n                                      HEAD             refs/heads/fix/data-env-travis \n\"95b3eae38cdb199fa9fe0db8810e03f45bca0746\" \"5bce6bad742a569606260652baa41ab45e1ece3e\" \n                         refs/heads/master                          refs/heads/travis \n```\n\nI'm not sure if this is a git2r problem (it could be because many people seemed to start have this problem recently in various cases), and if the SSH hack is a good solution. \nMaybe we can try both methods if one failed, and give some error message when there is error, so it'll be easy to locate the problem.\n. I attempted with this, it's kind of ugly because I nested trycatch for 3 times. I don't know if there is a better method to do this.\nBasically I try HTTPS url first, then SSH (the order may be switched if SSH is more reliable, I used this order because I knew HTTPS will fail for me so I can test the fallback), then github api. Any one failed will fall to next method. If everything failed there will be a warning.\nThis is not complete because url parameter is not used, and install_bitbucket need a similar function. I can modify the url parameter to make it work on both github and bitbucket if this solution is approved.. When I run the tests with check in rstudio (test package doesn't seem to run all tests, I didn't find out how to run them separately yet, because the functions are mostly not exported), these tests failed\nr\n     \u2550\u2550 testthat results  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n     OK: 116 SKIPPED: 5 FAILED: 7\n     1. Error: SHA for regular repository (@test-git.R#15) \n     2. Error: SHA for detached head (@test-git.R#24) \n     3. Error: git (non-)usage is detected, diagnosed, and can be added (@test-github-connections.R#6) \n     4. Error: GitHub non-usage is handled (@test-github-connections.R#24) \n     5. Error: github info and links can be queried and manipulated (@test-github-connections.R#48) \n     6. Error: github_info() prefers, but doesn't require, remote named 'origin' (@test-github-connections.R#91) \n     7. Error: install on packages adds metadata (@test-remote-metadata.R#15)\nI think that's because some git related functions don't work in my machine, which could be a git2r problem.   \n. @jimhester The behavior you mentioned is exactly what I observed (with CRAN version, not just devel devtools)\n\nWhen installing a package with devtools::install_github, dependency packages were installed from source in github, even when there is binary available in CRAN.\nAnd the problem was made worse because of the bug of sha not checked, every dependency package was compiled again and again in every install (not skipped when I have that same version installed)\n\nMy finding is that because the dependency package is installed by install_github before, the local package description file has the github remote information, and devtools will take that and install from github. Reinstall that dependency package from CRAN will solve the problem.\nSpecifying binary in package install doesn't solve this problem because we often want to install some packages from source. I think the both option in install.packages strike a good balance in this\n- binary was tried if both are available, in same version\n- ask user whether to install source if source is newer\n- there is option to skip the prompt. I also found remotes is working well in this case. \nMaybe devtools can pick a remotes commit, delegate related tasks to remotes (it could be hard because other parts may need some newer functions, but this should be done sooner than later), then gradually apply the new changes in devtools side to remotes. At least that will be work in single direction.. Yes, think again I agree that behavior is actually reasonable. \nPreviously I was frustrated because httpuv take a long time to compile and fail every time, and every of my installation need to go through that again (and several other packages can compile but take time, but were installed again because of the sha checking bug).. Thanks for finding out the root cause! \nI created a hack in #1624, use SSH, HTTPS method first then fall back to github api.\nSSH url worked for me.. @cklunch @jimhester \n~I think you can use the tar.gz download count from github API for this, since install_github always use github api to download the tar.gz first. Something like this.~\nSee related discussion here.\n~This can be done totally in your side (nothing relate to devtools). You probably can use the gh package.~\nUPDATE: the answer of using Package Download API no longer works, see expanded comments under that answer. You need to use release API, which may only works if you made releases explicitly.. Yes I realized that and edited my post. I probably should edit again to make it more obvious to avoid confusions.. ",
    "jvcasillas": "Adding to what has been mentioned above, I believe it would be useful for the date field to be updated automatically (specifically, for use with citation) because it is often the case that one needs to cite a package that is only on github, i.e., not on cran. . ",
    "katrinleinweber": "Why build date, rather than timestamp of the commit from which it was built? I'd compared that with the publication date of an article vs. the timestamp of the publisher-generated PDF that I download.\nAlso: can the version be mapped back to a git commit in each case? When using the GitHub-Zenodo integration and being stringent about release tagging, it always can be, can't it?. ",
    "singmann": "At the beginning I had the same problem as @wch that revdep_check() (for afex) just failed with Error: Command failed (1) while installing the required packages on Linux. \nThe solution was to set a libpath outside the package directory (e.g., revdep_check(libpath = \"../revdep\")) and install all failed packages per hand there (e.g., install.packages(\"apa\", lib = \"../revdep\")). Then I had to continue with revdep_check_resume() until the next package failed which I would then install with install.packages again, and so forth (i.e., I could install the failing packages via install.packages, but not via revdep_check() and could not figure out why).\nUnfortunately, after all packages had been installed, revdep_check(libpath = \"../revdep\") failed again:\n```\n\nrevdep_check(libpath = \"../revdep\")\nReverse dependency checks for afex =============================================================\nSaving check results in revdep/checks/\nComputing reverse dependencies\nInstalling afex 0.17-3 and dependencies to ../revdep\nSetting env vars -------------------------------------------------------------------------------\nNOT_CRAN    : false\nRGL_USE_NULL: true\nDISPLAY     : \nChecking 4 CRAN packages =======================================================================\nResults saved in /home/henrik/packages/afex/git/afex/revdep/checks\nInstalling dependencies ------------------------------------------------------------------------\nDetermining available packages\nDownloading source packages for checking\nChecking packages ------------------------------------------------------------------------------\nError: Check failed: '/home/henrik/packages/afex/git/afex/revdep/checks/apa.Rcheck' doesn't exist\n```\n\nThe solution was to also use a check_dir outside the package directory:  revdep_check(libpath = \"../revdep\", check_dir = \"../revdep_checks\"). This worked; it created and then deleted ../revdep_checks. However it nevertheless created revdep in the package directory (which contained the results check.rds):\n```\n\nrevdep_check(libpath = \"../revdep\", check_dir = \"../revdep_checks\")\nReverse dependency checks for afex =============================================================\nComputing reverse dependencies\nInstalling afex 0.17-3 and dependencies to ../revdep\nSetting env vars -------------------------------------------------------------------------------\nNOT_CRAN    : false\nRGL_USE_NULL: true\nDISPLAY     : \nChecking 4 CRAN packages =======================================================================\nResults saved in ../revdep_checks\nInstalling dependencies ------------------------------------------------------------------------\nDetermining available packages\nDownloading source packages for checking\nChecking packages ------------------------------------------------------------------------------\nChecked apa     : 0 errors | 0 warnings | 0 notes\nChecked fullfact: 0 errors | 0 warnings | 0 notes\nChecked jmv     : 0 errors | 0 warnings | 0 notes\nChecked r2glmm  : 0 errors | 0 warnings | 0 notes\nSaving check results to revdep/check.rds -----------------------------------------------------\nCleaning up ------------------------------------------------------------------------------------\n``  \n. @bbolker I managed to get it to run forbbmle, at least partly, under the following condition (same as for my package):\n- The working directory is source directory of package (and not one level below it).\n-revdep_check(libpath = \"../revdep\", check_dir = \"../revdep_checks\")- Install several of the in total 302 (!) required packages by hand, e.g.,install.packages(\"xergm\", lib = \"../revdep\")-revdep_check_resume()`\n\nThis gives (with the latest github master version):\nInstalling bbmle 1.0.19 and dependencies to ../revdep\nSetting env vars ---------------------------------------------------------------------------------------\nNOT_CRAN    : false\nRGL_USE_NULL: true\nDISPLAY     : \nChecking 14 CRAN packages ==============================================================================\nResults saved in ../revdep_checks\nInstalling dependencies --------------------------------------------------------------------------------\nDetermining available packages\nDownloading source packages for checking\nDownloading 14 packages\nChecking packages --------------------------------------------------------------------------------------\nChecked broom       : 0 errors | 1 warning  | 0 notes\nChecked copula      : 0 errors | 0 warnings | 2 notes\nChecked emdbook     : 0 errors | 0 warnings | 0 notes\nChecked frair       : 0 errors | 0 warnings | 0 notes\nChecked glmmTMB     : 0 errors | 0 warnings | 1 note \nChecked Luminescence: 0 errors | 0 warnings | 0 notes\nChecked metamisc    : 0 errors | 0 warnings | 0 notes\nChecked metaplus    : 0 errors | 0 warnings | 0 notes\nChecked primer      : 0 errors | 0 warnings | 3 notes\nChecked R2admb      : 0 errors | 0 warnings | 1 note \nChecked 10/14. Elapsed 00:15. Remaining ~00:06\nChecked rstpm2      : 0 errors | 0 warnings | 1 note \nChecked sads        : 0 errors | 0 warnings | 0 notes\nChecked SEERaBomb   : 0 errors | 0 warnings | 0 notes\nChecked ss3sim      : 0 errors | 1 warning  | 0 notes\nSaving check results to `revdep/check.rds` -------------------------------------------------------------\nError in desc$Priority : $ operator is invalid for atomic vectors\nIn addition: Warning message:\nIn packageDescription(pkg) : no package 'emdbook' was found\nUnfortunately, it seems that the error and warning in the end related to emdbook break the writing of the check.rds file so no compact output is saved. It seems one can only get th eoutput from the individual check folders.. ",
    "kellijohnson": "I was having the same issue, but for an Import of an Import. Specifically bbmle is an import of ss3sim and when I execute\ninstall_github(\"ss3sim/ss3sim\")\nbbmle is installed, but numDeriv, which is an import of bbmle is not. If I instead execute\ninstall.packages(\"ss3sim\")\nboth bbmle and numDeriv are correctly installed. I was using the CRAN version of devtools (1.12.0). After I executed the following code with the development version of devtools the issue went away:\ninstall.packages(\"devtools\", repos = \"http://cran.us.r-project.org\")\nlibrary(devtools)\ninstall_github(\"hadley/devtools\", force = TRUE)\ndetach(\"package:devtools\", unload = TRUE)\nlibrary(devtools)\ninstall_github(\"ss3sim/ss3sim\")\nlibrary(ss3sim)\nI think the issue can be closed.\n. ",
    "dfalbel": "@gaborcsardi  Thanks! I'll test this as soon as possible\n. ",
    "jirkalewandowski": "(duplicate of #1243, thanks @jimhester )\n. ",
    "hashar": "That one is still affecting me with devtools 1.13.2 when doing:\n```\n\ngetOption(\"repos\")\n    CRAN \n\"@CRAN@\" \ninstall.packages(\"devtools\", repos=\"http://cran.us.r-project.org\")\n...\ndevtools::install_deps(\"src\", repos=\"http://cran.us.r-project.org\", dependencies = TRUE )\nInstalling testthat\n'/usr/lib/R/bin/R' --no-site-file --no-environ --no-save --no-restore --quiet  \\\n  CMD INSTALL '/tmp/RtmpXB6s5u/devtools10dd7bf8ed3e/testthat'  \\\n  --library='/home/hashar/Rpackages' --install-tests \n\nERROR: dependencies \u2018crayon\u2019, \u2018praise\u2019, \u2018magrittr\u2019 are not available for package \u2018testthat\u2019\n* removing \u2018/home/hashar/Rpackages/testthat\u2019\nInstallation failed: Command failed (1)\n```\nhttps://github.com/ManifestoProject/manifestoR/commit/7f76cf1466dc989e0e6a91b2377baf78d9efbb47 is a working workaround. Or namely set the repos with options:\n```\n\noptions(repos=\"http://cran.us.r-project.org\")\ninstall.packages(\"devtools\", dependencies = TRUE )\ndevtools::install_deps(\"src\", dependencies = TRUE )\n// works\n```\n\n. ",
    "shapenaji": "Yeah, I suspected the certificate error was an SEP. But the hanging on failure seemed like a potential issue for devtools in future.\n. Yes, I haven't tried it again in some time and I believe I updated RStudio in the meantime, since now I get this, with no hang\ndevtools::install_bioc('GenomicRanges')\nsvn: E170013: Unable to connect to a repository at URL 'https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/GenomicRanges'\nsvn: E230001: Server SSL certificate verification failed: issuer is not trusted\nError: There was a problem retrieving the current SVN revision\nIn addition: Warning message:\nrunning command ''/usr/bin/svn' info --xml --username readonly --password readonly https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/GenomicRanges' had status 1\n. ",
    "bborgesr": "I also just ran into this (for dplyr in my case)\n. ",
    "msenn": "This error also appears for install_git().\n. ",
    "mhines-usgs": "Appeared for me with install_url. @jimhester I did have this version installed when I encountered the error:\n```\nThe downloaded source packages are in\n    \u2018/tmp/RtmphGEWsQ/downloaded_packages\u2019\n[1] \"\"\n[1] \"Checking png ...\"\n[1] \"Found version: 0.1.7\"\n[1] \"Up to date with repository version\"\n[1] \"\"\n[1] \"Checking scales ...\"\n[1] \"Found version: 0.4.1\"\n[1] \"Up to date with repository version\"\n[1] \"\"\n[1] \"Checking jsonlite ...\"\n[1] \"Found version: 1.4\"\n[1] \"Up to date with repository version\"\n[1] \"\"\n[1] \"Checking maps ...\"\n[1] \"Found version: 3.1.1\"\n[1] \"Up to date with repository version\"\n[1] \"\"\n[1] \"Checking httr ...\"\n[1] \"Found version: 1.2.1\"\n[1] \"Up to date with repository version\"\n[1] \"\"\n[1] \"Checking base64enc ...\"\n[1] \"Found version: 0.1.3\"\n[1] \"Up to date with repository version\"\n[1] \"\"\n[1] \"Checking yaml ...\"\n[1] \"Found version: 2.1.14\"\n[1] \"Up to date with repository version\"\n[1] \"\"\n[1] \"Checking mapdata ...\"\n[1] \"Found version: 2.2.6\"\n[1] \"Up to date with repository version\"\n[1] \"\"\n[1] \"Checking devtools ...\"\n[1] \"Found version: 1.12.0\"\n[1] \"Does not match version on repository: 1.13.0\"\n[1] \"Installing devtools 1.13.0 ...\"\ntrying URL 'http://cran.rstudio.com/src/contrib/devtools_1.13.0.tar.gz'\nContent type 'application/x-gzip' length 486058 bytes (474 KB)\n==================================================\ndownloaded 474 KB\n\ninstalling source package \u2018devtools\u2019 ...\n package \u2018devtools\u2019 successfully unpacked and MD5 sums checked\n R\n inst\n preparing package for lazy loading\n help\n installing help indices\n  converting help for package \u2018devtools\u2019\n    finding HTML links ... done\n    RCMD                                    html\n    as.package                              html\n    bash                                    html\n    build                                   html\n    build_github_devtools                   html\n    build_vignettes                         html\n    build_win                               html\n    check                                   html\n    check_cran                              html\n    check_dep_version                       html\n    check_failures                          html\n    check_man                               html\n    clean_dll                               html\n    clean_source                            html\n    clean_vignettes                         html\n    compile_dll                             html\n    compiler_flags                          html\n    create                                  html\n    create_description                      html\n    dev_example                             html\n    dev_help                                html\n    dev_meta                                html\n    dev_mode                                html\n    dev_packages                            html\n    devtest                                 html\n    devtools-deprecated                     html\n    devtools                                html\nRd warning: /tmp/RtmpIxQYFP/R.INSTALL31ab31a8aa39/devtools/man/devtools.Rd:28: missing file link \u2018as.person\u2019\n    document                                html\n    dr_devtools                             html\n    dr_github                               html\n    eval_clean                              html\n    find_topic                              html\n    git_checks                              html\n    github_pat                              html\n    github_refs                             html\n    has_devel                               html\n    has_tests                               html\n    help                                    html\nRd warning: /tmp/RtmpIxQYFP/R.INSTALL31ab31a8aa39/devtools/man/help.Rd:33: missing file link \u2018?\u2019\n    imports_env                             html\n    infrastructure                          html\n    inst                                    html\n    install                                 html\n    install_bioc                            html\n    install_bitbucket                       html\n    install_cran                            html\n    install_deps                            html\n    install_git                             html\nRd warning: /tmp/RtmpIxQYFP/R.INSTALL31ab31a8aa39/devtools/man/install_git.Rd:20: missing file link \u2018clone\u2019\n    install_github                          html\n    install_local                           html\n    install_svn                             html\n    install_url                             html\n    install_version                         html\n    is.package                              html\n    lint                                    html\n    load_all                                html\n    load_code                               html\n    load_data                               html\n    load_dll                                html\n    load_imports                            html\n    loaded_packages                         html\n    missing_s3                              html\n    ns_env                                  html\n    on_path                                 html\n    package_deps                            html\n    package_file                            html\n    parse_deps                              html\n    parse_ns_file                           html\n    path                                    html\n    pkg_env                                 html\n    r_env_vars                              html\n    release                                 html\n    release_checks                          html\n    reload                                  html\n    revdep                                  html\n    revdep_check                            html\n    revdep_email                            html\n    run_examples                            html\n    run_pkg_hook                            html\n    session_info                            html\n    setup_rtools                            html\n    show_news                               html\n    source_gist                             html\n    source_url                              html\n    spell_check                             html\n    submit_cran                             html\n    system.file                             html\n    system_check                            html\n    system_output                           html\n    test                                    html\n    uninstall                               html\n    unload                                  html\n    update_packages                         html\n    use_build_ignore                        html\n    use_data                                html\n    use_data_raw                            html\n    use_git                                 html\n    use_git_hook                            html\n    use_github                              html\n    use_github_links                        html\n    use_news_md                             html\n    use_package                             html\n    use_readme_rmd                          html\n    wd                                      html\n    with_debug                              html\n* building package indices\n installing vignettes\n testing if installed package can be loaded\nDONE (devtools)\n\nThe downloaded source packages are in\n    \u2018/tmp/RtmphGEWsQ/downloaded_packages\u2019\n[1] \"\"\n+ Rscript -e 'library(devtools);install_url(\"https://github.com/USGS-R/hazardItems/archive/v2.5.0.zip\")'\nError in value[3L] : argument \"quiet\" is missing, with no default\nCalls: install_url ... tryCatch -> tryCatchList -> tryCatchOne -> \nExecution halted\nBuild step 'Execute shell' marked build as failure\nFinished: FAILURE\n```\n. ",
    "cjolivier01": "I also have this problem\n. ",
    "jwinter6": "And another one.\nIt is only showing up if I ask for a specific version.\n5 days ago it worked without any issues.. Thanks!. ",
    "jenast": "Same result when using devtools 1.12, but works with version 1.10.\nBut it worked on an old R 3.2.3 installation, and works for me also after updating to R 3.3.2. So the issue is resolved, whatever the problem was. \nThanks again and sorry for the trouble.\n. ",
    "pfizer1234": "I have this problem with R 3.3.2\n\ninstall_github(\"hadley/testthat\")\nDownloading GitHub repo hadley/testthat@master\nfrom URL https://api.github.com/repos/hadley/testthat/zipball/master\nError: running command '\"C:/R/R-3.3.2/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD config CC' had status 2\nsessionInfo()\nR version 3.3.2 (2016-10-31)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 10586)\n\nlocale:\n[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252\n[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.12.0\nloaded via a namespace (and not attached):\n[1] httr_1.2.1    R6_2.2.0      withr_1.0.2   curl_2.3      memoise_1.0.0 git2r_0.18.0  digest_0.6.11\n. ",
    "gergness": "Sorry if this is unrelated, but I had a similar issue, but running R CMD from the command line didn't help. To fix, I had to delete the files in inst/doc and then recreate them with build_vignette().\n. ",
    "stefvanbuuren": "This is my approach to circumvent the time stamp problem:\ndevtools::build_vignettes()\ndevtools::build(vignettes = FALSE). Yes, build_vignettes() is fine, but build() appears to touch files. CRAN is (again?) unhappy with that.. ",
    "clesiemo3": "Give Rprof() a shot. This should give an indication of what's causing the most trouble. https://www.r-bloggers.com/profiling-r-code/ for a quick intro.\nHere's my example for devtools itself. \n```\n\nRprof()\ndevtools::load_all()\nLoading devtools\nRprof(NULL)\nsummaryRprof()\n$by.self\n                  self.time self.pct total.time total.pct\n\"gc\"                   0.18    27.27       0.18     27.27\n\"identical\"            0.06     9.09       0.10     15.15\n\"vapply\"               0.04     6.06       0.22     33.33\n\"parseDirective\"       0.04     6.06       0.06      9.09\n\"parse\"                0.04     6.06       0.04      6.06\n\"sys.call\"             0.04     6.06       0.04      6.06\n\"FUN\"                  0.02     3.03       0.24     36.36\n\"unlist\"               0.02     3.03       0.22     33.33\n\"f\"                    0.02     3.03       0.12     18.18\n\"readLines\"            0.02     3.03       0.08     12.12\n\"file\"                 0.02     3.03       0.06      9.09\n\"as.list\"              0.02     3.03       0.04      6.06\n\"match\"                0.02     3.03       0.04      6.06\n\"[.POSIXct\"            0.02     3.03       0.02      3.03\n\"as.list.default\"      0.02     3.03       0.02      3.03\n\"c\"                    0.02     3.03       0.02      3.03\n\"grepl\"                0.02     3.03       0.02      3.03\n\"options\"              0.02     3.03       0.02      3.03\n\"Sys.getenv\"           0.02     3.03       0.02      3.03\n\n$by.total\n                     total.time total.pct self.time self.pct\n\"devtools::load_all\"       0.66    100.00      0.00     0.00\n\"FUN\"                      0.24     36.36      0.02     3.03\n\"assign\"                   0.24     36.36      0.00     0.00\n\"eval\"                     0.24     36.36      0.00     0.00\n\"extract_lang\"             0.24     36.36      0.00     0.00\n\"lapply\"                   0.24     36.36      0.00     0.00\n\"nsenv[[f_name]]\"          0.24     36.36      0.00     0.00\n\"recurse\"                  0.24     36.36      0.00     0.00\n\"run_pkg_hook\"             0.24     36.36      0.00     0.00\n\"vapply\"                   0.22     33.33      0.04     6.06\n\"unlist\"                   0.22     33.33      0.02     3.03\n\"compact\"                  0.22     33.33      0.00     0.00\n\"gc\"                       0.18     27.27      0.18    27.27\n\"unload_dll\"               0.18     27.27      0.00     0.00\n\"make_function\"            0.16     24.24      0.00     0.00\n\"stopifnot\"                0.16     24.24      0.00     0.00\n\"force\"                    0.14     21.21      0.00     0.00\n\"load_code\"                0.14     21.21      0.00     0.00\n\"source_many\"              0.14     21.21      0.00     0.00\n\"source_one\"               0.14     21.21      0.00     0.00\n\"withr_with_dir\"           0.14     21.21      0.00     0.00\n\"f\"                        0.12     18.18      0.02     3.03\n\"bquote\"                   0.12     18.18      0.00     0.00\n\"unquote\"                  0.12     18.18      0.00     0.00\n\"identical\"                0.10     15.15      0.06     9.09\n\"readLines\"                0.08     12.12      0.02     3.03\n\"isTRUE\"                   0.08     12.12      0.00     0.00\n\"modify_lang\"              0.08     12.12      0.00     0.00\n\"unload\"                   0.08     12.12      0.00     0.00\n\"wrap_inner_loop\"          0.08     12.12      0.00     0.00\n\"parseDirective\"           0.06      9.09      0.04     6.06\n\"file\"                     0.06      9.09      0.02     3.03\n\"comp_lang\"                0.06      9.09      0.00     0.00\n\"parse_ns_file\"            0.06      9.09      0.00     0.00\n\"parseNamespaceFile\"       0.06      9.09      0.00     0.00\n\"parse\"                    0.04      6.06      0.04     6.06\n\"sys.call\"                 0.04      6.06      0.04     6.06\n\"as.list\"                  0.04      6.06      0.02     3.03\n\"match\"                    0.04      6.06      0.02     3.03\n\"%in%\"                     0.04      6.06      0.00     0.00\n\"getOption\"                0.04      6.06      0.00     0.00\n\"[.POSIXct\"                0.02      3.03      0.02     3.03\n\"as.list.default\"          0.02      3.03      0.02     3.03\n\"c\"                        0.02      3.03      0.02     3.03\n\"grepl\"                    0.02      3.03      0.02     3.03\n\"options\"                  0.02      3.03      0.02     3.03\n\"Sys.getenv\"               0.02      3.03      0.02     3.03\n\"[.data.frame\"             0.02      3.03      0.00     0.00\n\"[\"                        0.02      3.03      0.00     0.00\n\"\"              0.02      3.03      0.00     0.00\n\"compile_dll\"              0.02      3.03      0.00     0.00\n\"export_ns\"                0.02      3.03      0.00     0.00\n\"load_dll\"                 0.02      3.03      0.00     0.00\n\"load_imports\"             0.02      3.03      0.00     0.00\n\"process_imports\"          0.02      3.03      0.00     0.00\n\"set_envvar\"               0.02      3.03      0.00     0.00\n\"srcfilecopy\"              0.02      3.03      0.00     0.00\n\"withr_with_envvar\"        0.02      3.03      0.00     0.00\n$sample.interval\n[1] 0.02\n$sampling.time\n[1] 0.66\n\n```\n. I was looking to hop in and try to contribute but I'm not able to reproduce this. Am I doing something wrong? It seems to be fine for me. When you say 'moved' or 'renamed' are you referring to server/cran side?\n\nBelow is my attempt at reproducing with jsonlite from the cran github.\n```\n\nour.lib <- .libPaths()[1]\nlist.files(our.lib, pattern = \"jsonlite\")\ncharacter(0)\ndir <- tempfile()\ndir.create(dir)\nsystem(paste(\"git clone https://github.com/cran/jsonlite\",dir))\nCloning into '/var/folders/5h/5q77bcfx04n2pfkt35w4yv040000gn/T//RtmpToIJ0D/file5d91a9e7936'...\ndevtools::install(dir, quiet = TRUE)\nfile.rename(paste(our.lib, \"jsonlite\", sep = \"/\"), paste(our.lib, \"jsonlite_moved\", sep = \"/\"))\n[1] TRUE\nlist.files(our.lib, pattern = \"jsonlite\")\n[1] \"jsonlite_moved\"\nupdate_packages(package_deps(\"devtools\")[,1])\ntrying URL 'https://cran.rstudio.com/bin/macosx/mavericks/contrib/3.3/jsonlite_1.1.tgz'\nContent type 'application/x-gzip' length 1104452 bytes (1.1 MB)\n==================================================\ndownloaded 1.1 MB\n\nInstalling jsonlite\n'/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \\\n  '/private/var/folders/5h/5q77bcfx04n2pfkt35w4yv040000gn/T/RtmpToIJ0D/devtools5d92d4ab431/jsonlite'  \\\n  --library='/Users/clesiemo3/Library/R/3.3/library' --install-tests \n\ninstalling binary package \u2018jsonlite\u2019 ...\nDONE (jsonlite)\nlist.files(our.lib, pattern = \"jsonlite\")\n[1] \"jsonlite\"       \"jsonlite_moved\"\n```\n\n\n\nsessionInfo()\n```\n\nsessionInfo()\nR version 3.3.1 (2016-06-21)\nPlatform: x86_64-apple-darwin13.4.0 (64-bit)\nRunning under: OS X 10.12.1 (Sierra)\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.12.0\nloaded via a namespace (and not attached):\n[1] tools_3.3.1   withr_1.0.2   memoise_1.0.0 git2r_0.15.0  digest_0.6.10\n```\n. Would this be something as simple as this with the ability to cat() the output for easy copy/paste?\nCRAN.link <- function(pkg, root=\"https://CRAN.R-project.org/package=\", return.value = TRUE){\n  urls <- paste0(root,pkg)\n  if(!return.value){\n    for(u in urls){\n      cat(paste0(u,\"\\n\"))\n    }\n    return(invisible())\n  } else {\n    return(urls)\n  }\n}\n```\n\nCRAN.link(devtools::package_deps(\"devtools\")[,1])\n [1] \"https://CRAN.R-project.org/package=curl\"       \"https://CRAN.R-project.org/package=devtools\"\n [3] \"https://CRAN.R-project.org/package=digest\"     \"https://CRAN.R-project.org/package=git2r\"   \n [5] \"https://CRAN.R-project.org/package=httr\"       \"https://CRAN.R-project.org/package=jsonlite\"\n [7] \"https://CRAN.R-project.org/package=memoise\"    \"https://CRAN.R-project.org/package=mime\"    \n [9] \"https://CRAN.R-project.org/package=openssl\"    \"https://CRAN.R-project.org/package=R6\"      \n[11] \"https://CRAN.R-project.org/package=rstudioapi\" \"https://CRAN.R-project.org/package=whisker\" \n[13] \"https://CRAN.R-project.org/package=withr\"   \nCRAN.link(devtools::package_deps(\"devtools\")[,1], return.value = FALSE)\nhttps://CRAN.R-project.org/package=curl\nhttps://CRAN.R-project.org/package=devtools\nhttps://CRAN.R-project.org/package=digest\nhttps://CRAN.R-project.org/package=git2r\nhttps://CRAN.R-project.org/package=httr\nhttps://CRAN.R-project.org/package=jsonlite\nhttps://CRAN.R-project.org/package=memoise\nhttps://CRAN.R-project.org/package=mime\nhttps://CRAN.R-project.org/package=openssl\nhttps://CRAN.R-project.org/package=R6\nhttps://CRAN.R-project.org/package=rstudioapi\nhttps://CRAN.R-project.org/package=whisker\nhttps://CRAN.R-project.org/package=withr\nCRAN.link(\"devtools\")\n[1] \"https://CRAN.R-project.org/package=devtools\"\nCRAN.link(\"devtools\", return.value = FALSE)\nhttps://CRAN.R-project.org/package=devtools\n```\n. I'd be willing to tidy up the code above, use message() and put in a pull request if the appropriate parties are on board.\n\nClipboard is a tricky one in R if you want to support multiple operating systems. Might be better to just pipe the output of this function into another that handles the clipboard world\n. scales needs some C compiled (https://github.com/hadley/scales/blob/master/src/colors.cpp) and it looks like you're having trouble with setting the config for the C Compiler (https://svn.r-project.org/R/trunk/src/scripts/config R CMD config CC)\nNot the best answer I know but I'd wager to say that it's not a devtools issue but rather an issue around whatever C/C++ compiler you have on your machine and it interacting with R. You might be able to mess around with the config on your machine (such as http://stackoverflow.com/questions/10921153/c-compilation-flags-from-r) but that's a bit beyond my knowledge. Perhaps someone else can take this further.\nEdit: For what it's worth, here is an example of what it looks like when successfully running on my machine:\nSection of interest:\n* installing *source* package \u2018scales\u2019 ...\n** libs\nclang++ -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG  -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I\"/Users/clesiemo3/Library/R/3.3/library/Rcpp/include\"   -fPIC  -Wall -mtune=core2 -g -O2  -c RcppExports.cpp -o RcppExports.o\nclang++ -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG  -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I\"/Users/clesiemo3/Library/R/3.3/library/Rcpp/include\"   -fPIC  -Wall -mtune=core2 -g -O2  -c colors.cpp -o colors.o\nclang++ -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/Library/Frameworks/R.framework/Resources/lib -L/usr/local/lib -o scales.so RcppExports.o colors.o -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation\ninstalling to /Users/clesiemo3/Library/R/3.3/library/scales/libs\nEverything:\n```\n\ndevtools::install_github(\"hadley/ggplot2\")\nDownloading GitHub repo hadley/ggplot2@master\nfrom URL https://api.github.com/repos/hadley/ggplot2/zipball/master\nInstalling ggplot2\ntrying URL 'https://cran.rstudio.com/bin/macosx/mavericks/contrib/3.3/reshape2_1.4.2.tgz'\nContent type 'application/x-gzip' length 202343 bytes (197 KB)\n==================================================\ndownloaded 197 KB\n\nInstalling reshape2\n'/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \\\n  '/private/var/folders/5h/5q77bcfx04n2pfkt35w4yv040000gn/T/RtmpToIJ0D/devtools5d92e55d8b9/reshape2'  \\\n  --library='/Users/clesiemo3/Library/R/3.3/library' --install-tests \n\ninstalling binary package \u2018reshape2\u2019 ...\n\nDONE (reshape2)\nDownloading GitHub repo hadley/scales@master\nfrom URL https://api.github.com/repos/hadley/scales/zipball/master\nInstalling scales\n'/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \\\n  '/private/var/folders/5h/5q77bcfx04n2pfkt35w4yv040000gn/T/RtmpToIJ0D/devtools5d91d9ce75f/hadley-scales-d58d83a'  \\\n  --library='/Users/clesiemo3/Library/R/3.3/library' --install-tests \n\n\ninstalling source package \u2018scales\u2019 ...\n libs\nclang++ -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG  -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I\"/Users/clesiemo3/Library/R/3.3/library/Rcpp/include\"   -fPIC  -Wall -mtune=core2 -g -O2  -c RcppExports.cpp -o RcppExports.o\nclang++ -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG  -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I\"/Users/clesiemo3/Library/R/3.3/library/Rcpp/include\"   -fPIC  -Wall -mtune=core2 -g -O2  -c colors.cpp -o colors.o\nclang++ -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/Library/Frameworks/R.framework/Resources/lib -L/usr/local/lib -o scales.so RcppExports.o colors.o -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation\ninstalling to /Users/clesiemo3/Library/R/3.3/library/scales/libs\n R\n tests\n preparing package for lazy loading\n** help\nLoading required package: scales\n installing help indices\n* building package indices\n testing if installed package can be loaded\n\n\nDONE (scales)\n'/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \\\n  '/private/var/folders/5h/5q77bcfx04n2pfkt35w4yv040000gn/T/RtmpToIJ0D/devtools5d9d4bcae6/tidyverse-ggplot2-9f7b08c'  \\\n  --library='/Users/clesiemo3/Library/R/3.3/library' --install-tests \n\n\ninstalling source package \u2018ggplot2\u2019 ...\n R\n data\n moving datasets to lazyload DB\n* inst\n tests\n preparing package for lazy loading\n help\n installing help indices\n* building package indices\n installing vignettes\n** testing if installed package can be loaded\n\nDONE (ggplot2)\n```\n. When you build locally it's probably not pulling scales and building it as a dependency. It is just building the ggplot2 code which doesn't appear to have C code to compile.\n\nTry this: devtools::install_github(\"hadley/ggplot2\", dependencies = FALSE) and see if it is successful and just relies on an already installed scales package.\nedit: or on the flipside try to clone and build hadley/scales locally and see if that's successful\n. Nice! Glad to hear it. Definitely an odd problem :)\nThe bandaid solution is to install binary packages to avoid compiling but someday you'll probably need to compile SOMETHING. Still no idea on that unfortunately =\\\nI guess you can survive if you find a friend with a windows machine to build all your packages for you ;)\n. ",
    "jcmsb": "I am also seeing this on private repos that depend on other private repos - the error message is the same as you get if you try to access a private repo without the auth token. I have not reproduced this on public repos. I speculate that the process is seeing the import, assuming it is public and trying to download it without passing through the auth token.. ",
    "dmarkwat": "The software I am working with (Sonatype's Nexus 3) uses https and the company I am working with typically doesn't like handing out signed certs for internal usage, especially non-production.  So this is mostly for testing unless I simply can't get a signed cert at all.  All the same, it worked for install_url (with the config) and not install_version which seemed a little inconsistent so I tried to track down the root cause.\n. That would be great; hope to see it soon!\n. ",
    "lnalborczyk": "Same error for me, though I have a \"LICENSE.md\" file in a \"LICENSE\" sub-directory...\n* checking DESCRIPTION meta-information ... WARNING\nInvalid license file pointers: LICENSE\n. Thanks for the help but it did not solve my problem. I also tried to put the LICENSE file either in a license or an inst subdirectory but nothing worked. I changed the License field of my DESCRIPTION file from MIT to GPL-3 as a temporary solution but the \"MIT bug\" seems to be tough...\n. You're right, completely (i.e., not only visually in Finder but by modifying file parameters( with cmd+i, in mac osx)) removing the file extension solved my problem, thanks.\n. ",
    "wmurphyrd": "Moved the check into check-devtools.r and rebased on current master \n. Thanks for the bump. What did you think about the the wording change from \"Vignette testing files should be removed with clean_vignettes\" to \"Built vignettes should be removed withclean_vignettes()\" ?. An automatic fix is even better than a check! Awesome.. Thanks for the help. How does \"Built vignettes should be removed withclean_vignettes()\" sound?\n. ",
    "aarti7": "So silly of me. Pretty embarrassed right now! Gonna head for stronger coffee! \nThank you so much for solving it. \nAnd I will stop posting queries here. I didn't know of the  forum you posted the link for. It definitely is extremely helpful. Thanks a ton!\n. ",
    "achubaty": "@hadley good suggestions. I've updated as requested.\nNote: there's an unrelated error in the travis checks on R-devel that's causing a failure (#1389), as well as some unrelated errors locally:\n``` r\nchecking tests ... ERROR\nRunning the tests in \u2018tests/test-that.R\u2019 failed.\nLast 13 lines of output:\ntestthat results ================================================================\n  OK: 409 SKIPPED: 0 FAILED: 6\n  1. Failure: install_bioc (@test-bioconductor.r#39) \n  2. Error: install_bioc (@test-bioconductor.r#40) \n  3. Error: github info and links can be queried and manipulated (@test-github-connections.R#49) \n  4. Error: github_info() prefers, but doesn't require, remote named 'origin' (@test-github-connections.R#93) \n  5. Error: install on packages adds metadata (@test-remote-metadata.R#15) \n  6. Failure: remote_sha.github_remote returns expected value if remote does exist (@test-remotes.r#75) \nError: testthat unit tests failed\n  Execution halted\nR CMD check results\n1 error  | 0 warnings | 0 notes\nR CMD check succeeded\n```\nI have all the package dependencies (including Suggests) installed and up to date.\n. ",
    "fyears": "It's weird. Actually I tried devtools::install_github('hadley/devtools') before...\nMaybe that's because in the actual DESCRIPTION the item devtools reset it into the cran repo version.\n. ",
    "shntnu": "This may be relevant to keep in mind:\nhttp://dirk.eddelbuettel.com/blog/2017/03/22/#suggests_is_not_depends. ",
    "IndrajeetPatil": "Has this bug resurfaced in the development version? I downloaded the latest development version of devtools today (8944e1159f0640e5e4375c128a63cccb66341f85) and every instance of devtools::install_github is giving me the following  error-\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir, skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments. @jennybc Thanks! Yes, I ran it with --as-cran. \nIf I can't use Remotes field when I submit to CRAN, then how can I add development version of a package in dependencies? \nShould I just add ggExtra (>= 0.7.1.9000) to Imports and then remove Remotes field? \nCool, I'll remove remotes package from Suggests. . Gotcha! Perfect, thanks. Will implement this. . Cool, thanks! Didn't know about devtools::check_win_devel() or devtools::check_rhub(). Will make it a habit to run these checks as well. . sigh, I see.\nFrom Twitter (I think it was @leeper's tweet), I had learned that CRAN no longer allows don't run examples-\n```\n'@examples\n'\\dontrun{\n'}\n``\nSo I feel like they might have made changes toR CMD CHECKto catch all instances where either examples have been commented out or examples are included for functions not exported from the package.. Ah, I see. Okay, I will just manually check for these errors. Doesn't seem to be a way around it.. Oh, I see. The formatting completely threw me off! Thanks.. Oops, sorry about that. This is the package in question:\nhttps://github.com/IndrajeetPatil/ggstatsplot. Ah, I see. Don't know what's going on then. I ran the check again and here is the full check output. Now the size is6.9 MB`.\n```\n==> devtools::check(args = c('--as-cran'))\nUpdating ggstatsplot documentation\nWarning: @inherit [C:\\Users\\inp099\\Documents\\ggstatsplot\\R\\helpers_messages.R#20]: Unknown inherit type: value\nWarning: @inherit [C:\\Users\\inp099\\Documents\\ggstatsplot\\R\\helpers_messages.R#95]: Unknown inherit type: value\nWriting NAMESPACE\nLoading ggstatsplot\nWriting NAMESPACE\n-- Building ------------------ ggstatsplot --\nSetting env vars:\n CFLAGS    : -Wall -pedantic -fdiagnostics-color=always\n CXXFLAGS  : -Wall -pedantic -fdiagnostics-color=always\n* CXX11FLAGS: -Wall -pedantic -fdiagnostics-color=always\n\nv  checking for file 'C:\\Users\\inp099\\Documents\\ggstatsplot/DESCRIPTION' (568ms)\n-  preparing 'ggstatsplot': (11s)\nv  checking DESCRIPTION meta-information ... \n-  installing the package to build vignettes (425ms)\nv  creating vignettes (6m 46.1s)\n-  checking for LF line-endings in source and make files and shell scripts (5.5s)\n-  checking for empty or unneeded directories\n   Removed empty directory 'ggstatsplot/tests/figs/ggbetweenstats'\n-  looking to see if a 'data/datalist' file should be added\n-  building 'ggstatsplot_0.0.6.tar.gz'\n-- Checking ------------------ ggstatsplot --\nSetting env vars:\n R_CHECK_CRAN_INCOMING_USE_ASPELL: TRUE\n R_CHECK_CRAN_INCOMING_REMOTE    : FALSE\n R_CHECK_CRAN_INCOMING           : FALSE\n R_CHECK_FORCE_SUGGESTS          : FALSE\n-- R CMD check -----------------------------------------------------------------\n-  using log directory 'C:/Users/inp099/Documents/ggstatsplot.Rcheck' (353ms)\n-  using R version 3.5.1 (2018-07-02)\n-  using platform: x86_64-w64-mingw32 (64-bit)\n-  using session charset: ISO8859-1\n-  using options '--no-manual --as-cran' (733ms)\nv  checking for file 'ggstatsplot/DESCRIPTION'\n-  checking extension type ... Package\n-  this is package 'ggstatsplot' version '0.0.6'\n-  package encoding: UTF-8\nv  checking package namespace information ...\nv  checking package dependencies (2.4s)\nv  checking if this is a source package ... \nv  checking if there is a namespace\nv  checking for executable files (664ms)\nv  checking for hidden files and directories ... \nv  checking for portable file names ... \nv  checking serialization versions ... \nv  checking whether package 'ggstatsplot' can be installed (13.8s)\nN  checking installed package size ... \n     installed size is  6.9Mb\n     sub-directories of 1Mb or more:\n       doc    3.4Mb\n       help   3.1Mb\nv  checking package directory (1.4s)\nv  checking 'build' directory ...\nv  checking DESCRIPTION meta-information (571ms)\nv  checking top-level files ...\nv  checking for left-over files ... \nv  checking index information (415ms)\nv  checking package subdirectories (557ms)\nv  checking R files for non-ASCII characters ... \nv  checking R files for syntax errors ... \nv  checking whether the package can be loaded (3s)\nv  checking whether the package can be loaded with stated dependencies (2.8s)\nv  checking whether the package can be unloaded cleanly (2.8s)\nv  checking whether the namespace can be loaded with stated dependencies (2.7s)\nv  checking whether the namespace can be unloaded cleanly (3s)\nv  checking loading without being on the library search path (3.7s)\nv  checking dependencies in R code (2.9s)\nv  checking S3 generic/method consistency (4.6s)\nv  checking replacement functions (3.5s)\nv  checking foreign function calls (3s)\nv  checking R code for possible problems (17.2s)\nv  checking Rd files (715ms)\nv  checking Rd metadata ... \nv  checking Rd line widths ... \nv  checking Rd cross-references (412ms)\nv  checking for missing documentation entries (2.8s)\nv  checking for code/documentation mismatches (9.3s)\nv  checking Rd \\usage sections (5.3s)\nv  checking Rd contents (415ms)\nv  checking for unstated dependencies in examples (614ms)\nv  checking contents of 'data' directory ...\nv  checking data for non-ASCII characters (409ms)\nv  checking data for ASCII and uncompressed saves ... \nv  checking installed files from 'inst/doc' ... \nv  checking files in 'vignettes' ... \nv  checking examples (34s)\n   Examples with CPU or elapsed time > 5s\n                                user system elapsed\n   subtitle_ggbetween_rob_anova 5.25      0    5.27\nv  checking for unstated dependencies in 'tests' ... \n-  checking tests ...\nv< smal       ggscatterstats.Rmd:97 (10.3s)out.save' ...\nv  Running 'testthat.R'\nv  checking for unstated dependencies in vignettes (555ms)\nv  checking package vignettes in 'inst/doc' ... \nv  checking re-building of vignette outputs (6m 6.1s)\nSee\n     'C:/Users/inp099/Documents/ggstatsplot.Rcheck/00check.log'\n   for details.\n-- R CMD check results ---------------------------------- ggstatsplot 0.0.6 ----\nDuration: 8m 32.2s\n\nchecking installed package size ... NOTE\n    installed size is  6.9Mb\n    sub-directories of 1Mb or more:\n      doc    3.4Mb\n      help   3.1Mb\n\n0 errors v | 0 warnings v | 1 note x\nR CMD check succeeded\n``. I am no longer getting inconsistent results. Might have been something transitory in my R session that was messing with the size calculation.. Also, my Travis and AppVeyor builds don\u2019t fail or produce this warning. So not sure why I am getting this warning only with devtools.. Did some digging. This seems to be due to changes made tosaveRDS()function inR 3.5.1` (ftp://cran.r-project.org/pub/R/doc/manuals/r-patched/NEWS.pdf):\n\nR has new serialization format (version 3) which supports custom serialization of\nALTREP framework objects. These objects can still be serialized in format 2, but\nless efficiently. Serialization format 3 also records the current native encoding of\nunflagged strings and converts them when de-serialized in R running under different\nnative encoding. Format 3 comes with new serialization magic numbers (RDA3,\nRDB3, RDX3). Format 3 can be selected by version = 3 in save(), serialize()\nand saveRDS(), but format 2 remains the default for all serialization and saving of\nthe workspace. Serialized data in format 3 cannot be read by versions of R prior to\nversion 3.5.0.\n\nSince this is the version of R on my computer, the data was saved in format 3 and this warning was produced. \nThis is resolved if I run:\nsaveRDS(version = 2)\nSo that solves this issue. But I will keep this open and let you close it in case you feel that devtools or usethis should run a check on data formats and automatically update R version in the DESCRIPTION file based on such a check. . ",
    "flying-sheep": "no, sorry. my elbow is bust and typing left-handed is hard.\nit occurs with this package\n. yes, it does. texi2dvi (the R function) suppresses all output if quiet = TRUE is supplied\n\n\n```console\n$ R --slave -e 'tools::texi2dvi' | grep -EC3 'quiet|sys2'\n```\n\n\n\n```console\nfunction (file, pdf = FALSE, clean = FALSE, quiet = TRUE, texi2dvi = getOption(\"texi2dvi\"), \n    texinputs = NULL, index = TRUE) \n{\n    if (clean) \n--\n        opt_pdf <- if (pdf) \n            \"--pdf\"\n        else \"\"\n        opt_quiet <- if (quiet) \n            \"--quiet\"\n        else \"\"\n        opt_extra <- \"\"\n        out <- .system_with_capture(texi2dvi, \"--help\")\n--\n        env0 <- \"LC_COLLATE=C\"\n        if (grepl(\" \", Sys.getenv(\"TMPDIR\"))) \n            env0 <- paste(env0, \"TMPDIR=/tmp\")\n        out <- .system_with_capture(texi2dvi, c(opt_pdf, opt_quiet, \n            opt_extra, shQuote(file)), env = env0)\n        log <- paste0(file_path_sans_ext(file), \".log\")\n        if (out$status && file_test(\"-f\", log) && any(grepl(\"(Rerun to get|biblatex.*\\\\\\\\(re\\\\\\\\)run)\", \n            readLines(log, warn = FALSE)))) {\n            out <- .system_with_capture(texi2dvi, c(opt_pdf, \n                opt_quiet, opt_extra, shQuote(file)), env = env0)\n        }\n        errors <- character()\n        log <- paste0(file_path_sans_ext(file), \".log\")\n--\n            else if (length(out$stderr)) \n                msg <- paste(msg, \"Messages:\", paste(out$stderr, \n                  collapse = \"\\\\n\"), sep = \"\\\\n\")\n            if (!quiet) \n                msg <- paste(msg, \"Output:\", paste(out$stdout, \n                  collapse = \"\\\\n\"), sep = \"\\\\n\")\n        }\n        do_cleanup(clean)\n        if (nzchar(msg)) \n            stop(msg, domain = NA)\n        else if (!quiet) \n            message(paste(paste(out$stderr, collapse = \"\\\\n\"), \n                paste(out$stdout, collapse = \"\\\\n\"), sep = \"\\\\n\"))\n    }\n--\n            extra <- paste(extra, paste(paths, collapse = \" \"))\n        }\n        base <- basename(file_path_sans_ext(file))\n        system(paste(shQuote(texi2dvi), if (quiet) \n            \"--quiet\"\n        else \"\", if (pdf) \n            \"--pdf\"\n        else \"\", shQuote(file), extra), intern = TRUE, ignore.stderr = TRUE)\n--\n            stop(if (pdf) \n                \"pdflatex\"\n            else \"latex\", \" is not available\", domain = NA)\n        sys2 <- if (quiet) \n            function(...) system2(..., stdout = FALSE, stderr = FALSE)\n        else system2\n        bibtex <- Sys.getenv(\"BIBTEX\", \"bibtex\")\n        makeindex <- Sys.getenv(\"MAKEINDEX\", \"makeindex\")\n        ltxargs <- c(\"-interaction=nonstopmode\", texfile)\n        if (sys2(latex, ltxargs)) \n            stop(gettextf(\"unable to run '%s' on '%s'\", latex, \n                file), domain = NA)\n        nmiss <- length(grep(\"Warning:.*Citation.*undefined\", \n            readLines(paste0(base, \".log\"))))\n        for (iter in 1L:10L) {\n            if (nmiss) \n                sys2(bibtex, shQuote(base))\n            nmiss_prev <- nmiss\n            if (index && file.exists(idxfile)) {\n                if (sys2(makeindex, shQuote(idxfile))) \n                  stop(gettextf(\"unable to run '%s' on '%s'\", \n                    makeindex, idxfile), domain = NA)\n            }\n            if (sys2(latex, ltxargs)) {\n                lines <- .get_LaTeX_errors_from_log_file(paste0(base, \n                  \".log\"))\n                errors <- if (length(lines)) \n```\n\n. ",
    "StevenMMortimer": "I've taken a look at build failures and resubmitted PR as #1390. There's still a failure on Travis, but seems unrelated. Thanks for taking a look.\n. Thanks @jimhester. I'm aware. This was sort of a dumb thing on my part. I reset hard on some commits and GitHub automatically closed this PR and opened a new one. I closed #1390 and re-opened this guy.\n. ",
    "KhagayN": "Thanks! \nI ran that code and it has updated the NAMESPACE file but, after running load_all() and calling \npackage_name::function_name() \nI get an error: \nError in .Call(\"rSeqLibPackage_timesTwo\", PACKAGE = \"rSeqLibPackage\",  : \n  \"rSeqLibPackage_timesTwo\" not available for .Call() for package \"rSeqLibPackage\"\nIf I try the Build & Reload utility from RStudio, I get a different error:\nError in library.dynam(lib, package, package.lib) : \n  shared object \u2018rRseqLibPackage.so\u2019 not found\nError: loading failed\nWhat is happening?\n. ",
    "HughParsonage": "Thanks for the response. I'm somewhat sceptical of your diagnosis, however, because I can build the package locally. (That is if I fork the ggplot2 repo, clone it on my computer, then build the package locally, I do not get any error.) Does your diagnosis explain this behaviour?\nHowever, something I've discovered since opening this issue is that find_rtools() returns the same error.\n. You're right: running that will build correctly! My mistake.\n. I think the failure  is spurious. Change is trivial and only occurs on R 3.2. \n\n0.76schecking tests ... ERROR\nRunning the tests in \u2018tests/test-that.R\u2019 failed.\nLast 13 lines of output:\n  7: force(code)\n  8: usethis::use_github_links()\n  9: gh::gh(\"GET /repos/:owner/:repo\", owner = info$username, repo = info$repo, .api_url = host, \n         .token = auth_token)\n  10: gh_process_response(raw)\n\u2550\u2550 testthat results  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  OK: 161 SKIPPED: 2 FAILED: 1\n  1. Error: install on packages adds metadata (@test-remote-metadata.R#15) \nError: testthat unit tests failed\n  Execution halted. I can reproduce this, though perhaps an RStudio issue?\n\n\nCreate a package in RStudio with a broken License field.\nClick Check in the Build tab.\nFix the License field.\nRun Check again. The error persists.. \n",
    "tersmitten": "I just encountered the same problem:\n```\n\ndevtools::install_local(\"/home/foo/Downloads/bar_0.1.1.tar.gz\")\nError in read.dcf(path) : cannot open the connection\nIn addition: Warning message:\nIn read.dcf(path) :\n  cannot open compressed file '/home/foo/Downloads/bar_0.1.1.tar.gz/DESCRIPTION', probable reason 'Not a directory'\n```\n\n```\n\nsessionInfo()\nR version 3.3.2 (2016-10-31)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 14.04.5 LTS\n```. \n",
    "fikovnik": "I encountered the same thing. The install_url works though:\ninstall_url(\"file:///path/to/testthat_1.0.2.tar.gz\")\n. ",
    "rstub": "Old issue but maybe still useful: rhub.io meanwhile has a Solaris based builder. Very useful, indeed!. ",
    "mruessler": "```\n\nsessionInfo()\nR version 3.3.2 (2016-10-31)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Arch Linux\n\nlocale:\n [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C               LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8     LC_MONETARY=en_GB.UTF-8 \n [6] LC_MESSAGES=en_GB.UTF-8    LC_PAPER=en_GB.UTF-8       LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C          \n[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] devtools_1.12.0\nloaded via a namespace (and not attached):\n[1] withr_1.0.2   memoise_1.0.0 digest_0.6.9 \n``\n. I cannot interrupt with Ctrl + C. Only process termination works. The ssh-agent process returns back to normal CPU values after R is killed. So notraceback().\nAre there other ways to obtain additional information?\n. @jimhester Good call! When I cloned thedevtoolsrepository and added a key viassh-addI was suddenly able to install withdevtools::install_github(\"hadley/devtools\")`. As far as I can remember this was not standard behaviour a few months ago. I wonder what has changed\u2026\nThere is probably nothing that can be done from within R in this case, right?\n. ",
    "cderv": "Looking for a solution, I found several things : \n\nMy problem is related to #1280 but it does not seems to work even with GITHUB_PAT\nMy issue is in fact a duplicate of #1262 and PR #1263 should resolves it (sorry I did not see it before)\nI found that remotes package seems to be the new packages for installing functions (#1310) . So I tried it.  \n\nConclusion :  It works fine, provided that on Windows, proxy configuration is correctly done (see MangoTheCat/remotes#45) . ",
    "jdblischak": "I have another example where this causes problems with unit tests. I created an rmarkdown template in inst/rmarkdown/templates. My unit tests break because rmarkdown::draft calls system.file, which then searches my source code instead of the installed package. Because of the differences in directory structure, this breaks the tests.\nI understand that this behavior was purposeful (e.g. this comment), but it would be useful if there was some way to temporarily disable the shims. I tried experimenting with including detach(\"devtools_shims\") in my unit test, but that did not work. For now, I am skipping these tests with skip and running them manually via source.. @jimhester Great. I added a news entry. Thanks!. @jimhester Also, regarding my observation that remotes::install_version cannot install the binary version of the packages, is this desired behavior or should I open an Issue on remotes? Copy-pasting the relevant section from above:\n\nEdit: I investigated more. The implementation of remotes::install_version has substantially changed from the one in devtools, i.e. it doesn't use install.packages to determine the download URL. Instead it constructs the URL itself, always specifying the extension .tar.gz. Thus this works when installing from source, but breaks if passed type = \"binary\".\n\nI wasn't able to find an easy fix like I did for here, and there has been recent development about how to handle binary packages (e.g. the most recent commit). Thus I wasn't sure how best to proceed. I think it could be solved by checking contriburl for the string \"bin\", and then switching the file extension to .tgz. However, I don't know how robust that solution is, and I could only get it to work when manually specifying type = \"binary\". I think a better default, especially for Windows users that may not have compilers installed, would be to try and install the binary if it is available.. > Not sure what the best solution is; the current plan is to eventually switch devtools to use pkgman, which uses a different API and method for package installation, so devtools will likely never use remotes as-is.\n@jimhester Good to know! I didn't realize that was the plan.\n\nI am not entirely sure in which situations it makes sense to install old binary packages. Most of the time these are not available for R-release, anyway. The old binary builds available are for older R versions.\n\n@gaborcsardi Thanks for the advice! I agree this is an edge case. This PR to devtools solves the main problem I was having, so I am fine with remotes keeping its current behavior of always installing from source.\nInstead of changing the behavior of remotes::install_version, what about changing the documentation to indicate that binary downloads are not supported? The documentation for type is currently:\n\ncharacter, indicating the type of package to download and install. Will be \"source\" except on Windows and some macOS builds: see the section on \u2018Binary packages\u2019 for those.\n\nIf a user specifies type = \"binary\" with the current CRAN release, it breaks:\n```\n\ninstall_version(\"git2r\", \"0.21.0\", type = \"binary\")\nDownloading package from url: https://cran.rstudio.com/bin/windows/contrib/3.4/git2r_0.21.0.tar.gz\n Show Traceback\n\nRerun with Debug\n Error in utils::download.file(url, path, method = download_method(), quiet = quiet,  : \n  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/git2r_0.21.0.tar.gz' \n```\nIf a user specifies type = \"binary\" with a previous CRAN release, it installs from source:\n```\n\ninstall_version(\"git2r\", \"0.19.0\", type = \"binary\")\nTrying https://cran.rstudio.com/\nDownloading package from url: https://cran.rstudio.com//src/contrib/Archive/git2r/git2r_0.19.0.tar.gz\nInstalling package into \u2018C:/Users/john/Documents/R/win-library/3.4\u2019\n(as \u2018lib\u2019 is unspecified)\n installing source* package 'git2r' ...\n```\n\nIf you're interested, I could send a PR that 1) notes in the documentation that type = \"binary\" is not accepted by install_version, and 2) has install_version throw an error early if type == \"binary\". If you're not interested in these changes, I'm fine leaving it as is.. @jimhester Is my NEWS entry ok? If yes, then this PR is ready to merge.. ",
    "cosi1": "Mine doesn't seem to be associated directly with devtools' system.file(), but rather with the corrupt handling of package directories in packageDescription().\nSteps to reproduce:\n\nCreate package myPackage in a \"simulated SVN repository\", e.g., ~/myPackage/trunk. (Note: this works for any directory name different than the actual name of the package.)\nEnter that directory: setwd(\"~/myPackage/trunk\")\nLoad devtools: library(devtools)\nLoad myPackage with devtools: load_all()\nTry to get citation for your package: citation(\"myPackage\")\n\nThe reason citation() fails is because packageDescription() assumes that the root directory of a package would be the same as its name, which is not always true. Anyway, the above example works when system.file() isn't masked by devtools.. ",
    "pat-s": "Package.\nI meanwhile removed the need to use mc.reset.stream within the package so it is not reproducible with the current version. \nI assume this is is rather a general package building problem rather than an install_github() error.\nIf you need the most recent commit before the removal, I'll search for it. \nHowever, it is not urgent for me anymore. . ",
    "mkearney": "Just experienced same.\nEdit: Still not sure the cause, but think it's on my end. Switching to CRAN version avoided the indefinite hanging though.\nLast update: A rather large data file got mistakenly added to a subfolder. Once I removed that it ran fine.. ",
    "bomeara": "I tried re-cloning the package I was testing as https://github.com/bomeara/yearn.git (github clone with https option) rather than git@github.com:bomeara/yearn.git (github clone with ssh option) and it seemed to eliminate this problem.. ",
    "danielsjf": "The same problem happens when devtools::test() is used on a file that is UTF-8 encoded while the machine encoding is different.. @gaborcsardi Rstudio by default saves files as UTF-8. Also, everything works when I source the code from Rstudio or if I compile the package using the build as source from Rstudio. It seems that devtools has a different behavior.. @gaborcsardi it was not possible to supply my characters in ASCII since they were not part of ASCII. However, your suggestion to put them in unicode worked.\nI did declare the UTF-8 encoding in my description though (in fact Rstudio does this automatically when you create a new package). I perfectly understand that not every system works in UTF-8, but that doesn't mean that you can't parse UTF-8 on a given system. As long as there is a way to be aware of the UTF-8 encoding, UTF-8 usually avoids a lot of issues.. ",
    "nicholaelaw": "I apologize for the grave-digging, but devtools::document() is giving me similar troubles.\nI understand that in the past source code should be ASCII only. But I'm using the data.table package in my package, and the data I'm dealing with had column names in Chinese. data.table allows using unquoted column names in its syntax. For example, I can just type dt[15L, \u7f16\u53f7] and retrieve the item from row 15, column \u7f16\u53f7.\nHowever code written this way could not be processed by devtools::document() on Windows. If environment encoding is left untouched, it throws an 'invalid multibyte character at line XX' error. If I set options(encoding = 'UTF-8'), the error becomes \"unexpected '<' at line XX:YY\".\nI am aware of the escaping method mentioned above. In fact dt[15L, eval(parse(text = '\u7f16\u53f7'))] works too. Chinese in quotes does not bother devtools::document() at all. But for operations involving dozens of columns code like that becomes very hard to read and tiresome. \nTherefore I request that Unicode variable name support be added to devtools::document(). Currently it fails on Windows, but works fine on macOS. I'd have test to confirm the situation on Linux, but I believe it works there too.. The situation, I think, is that code works. It works across platforms. I've run code like this across Windows, macOS and Linux (CentOS). As R sources are now required to be UTF-8, I think it will work on any system that supports UTF-8 and has a recent version of R.\nWhat's not working though, is devtools::document. I can skip it by manually editing NAMESPACE and the package builds fine, albeit without documentation. So I think it could be said that it was devtools not working for a specific platform...\nI hope I'm not sounding offensive. But the \"ASCII-only\" rule really feels outdated these days. Just imagine how a Chinese/Japanese/Arabic Shiny app would look like if every non-ASCII character has to be escaped.. My mistake then. It's been a long time since I last used R outside of RStudio. Admittedly there are many platforms that does not support UTF-8, but I think that does not constitute a reason for not supporting UTF-8. Wouldn't you agree?\nAlso as I have stated, Unicode variable names work. Only for modern platforms perhaps, but that is all I am targeting.\nThat guide should be updated to reflect the reality.. Yet it works. It works on Windows. My comments on how the package works across platforms are mysteriously ignored. What must I do to convince you that it works?\nI'm using my package right now on Windows 10, in RStudio, with locale\n```r\n\nSys.getlocale()\n[1] \"LC_COLLATE=Chinese (Simplified)_China.936;LC_CTYPE=Chinese (Simplified)_China.936;LC_MONETARY=Chinese (Simplified)_China.936;LC_NUMERIC=C;LC_TIME=Chinese (Simplified)_China.936\"\n```\n\nThe guide is excellent, the guide is not law, the guide needs to be updated.. AFAIK, RStudio defaults to UTF-8 encoding for all sources on all platforms. I'm staring at my sources encoded in UTF-8, lines ending with LF (Posix), written on Windows. The package builds fine, installs fine and runs fine.\n\n. This exact source, was pulled from my GitHub repository, originally pushed from my MacBook, after it's been built and tested to work. In other words, this exact package works on both macOS (UTF-8 locale) and Windows (rubbish locale), without any modification.. ",
    "MikeWise2718": "But I downloaded the repo and installed with install.packages(\"rgl\",type=\"source\") from the pkg/rgl directory and it installed ok (I think, the version number was off which prevented me from doing a lot of testing). And I do not have SVN installed. I think it is not meant to need SVN.. You mean there is a remotes dependency in install_github or one in rgl? Sorry, I am not familiar with what remotes does (Remotes?) and how it works.\nAnd is it possible that this worked once and some change to install_github, or rgl broke it?. Ok, so the rgl that install.packages built might not have everything that was intended, i.e. it might be want to have some packages with functionality that it expects, regardless of the fact that it did compile.\nAlso I just found out that the rforge mirror has not been updated since July 2016 so I shouldn't be using that anyway.... ",
    "while": "The problem seems to be that the function file_ext as it is only extracting the filename from the raw url rather than getting it from the server.  \nIf you get the url from the httr::GET request it will resolve to the redirected url instead. Or a httr::HEAD call if it is better to resolve the path before calling GET. \nR\nhead_request <- httr::HEAD(x$url)\nfinal_url <- head_request$url\n. ",
    "Kenkleinman": "I have this problem also.  Major PIA.. I have not been able to install_github() on my work computer since I got it, but today, it works.  Is that a smiley face or a frowney face?. ",
    "asardaes": "This is still broken in version 1.13.3. ",
    "friendly": "Confirmed.  It now seems to work.  I only filed an issue because it didn't work for two days. ",
    "dankelley": "I'm finding this problem, today 2017-03-30 and yesterday, with R-devel, although R-release works okay (\"oce\" package).. Also, I tried with the web interface and got as follows, so I don't think this is a devtools::build_win() problem.\nR-devel\nFor uploading R source packages to be built and checked with R-devel, please use this second form:\nERROR: Access to the path 'C:\\Inetpub\\ftproot\\R-devel\\oce_0.9-21.tar.gz' is denied.. Thanks. I get\n```R\n\nSys.getenv(\"R_REMOTES_NO_ERRORS_FROM_WARNINGS\")\n[1] \"\"\nAlso -- and this is for reasons that I no longer recall and likely never understood -- I have the following in my `~/.bash_profile`, and I wonder whether I ought to remove or alter them?\nexport R_BUILD_COMPACT_VIGNETTES=1\nexport R_CHECK_FORCE_SUGGESTS=0\n```. \n",
    "camrinbraun": "Same for me today but only with R-devel, both using devtools::build_win() and the web interface. R-release works fine via both methods. Any idea why this is happening?. ",
    "s-fleck": "I think you misread. From your link:\n\nThe \u2018LazyData\u2019 logical field controls whether the R datasets use lazy-loading. A \u2018LazyLoad\u2019 field was used in versions prior to 2.14.0, but now is ignored.. @krlmlr I think the ability to run in the build pane does not yet exists. I was looking for that when I started working on testthis, but also couldn't find anything :(. @krlmlr Running just the tests in a the single associated test file works pretty well in my workflow when I have to deal with packages with long running tests. If you still find retest() would be useful - and to awkward for devtools - you can file a feature request for testthis and i'll try to figure something out.. \n",
    "jakubkuzilek": "Ahh, you are right, I should stop reading at night :). ",
    "levimcclenny": "I actually had the same issue, when calling devtools::release() my NAMESPACE was overwritten with a blank one, resulting in some random warnings and notes right before submission. Funny part is that I used roxygen2 to create the initial NAMESPACE anyway, so I'm not sure about the comment 'first time use of roxygen2'\nI believe this is a bug, but I got my package submitted using devtools::release(check = FALSE) regardless. I just ran an extra check before submitting. \nEdit After a little more digging, it turns out that devtools::release() runs roxygen2::oxygenize() (somehow), therefore the NAMESPACE file is overwritten by one from your roxygen2 comments every time release() is run. I elected not to use any roxygen2 formatting in my package and do it the old fashioned way (e.g. writing .rd files by hand), which burned me here. That being said, simply going through and adding the @importFrom and @export to the applicable functions allowed for a proper namespace to be developed and viola, no, issues with NAMESPACE when running release()\nThat being said, perhaps there is a way to change release() (or an upstream function) to overlook this for those electing to hand-write their .rd and NAMESPACE files.. ",
    "xhdong-umd": "I just tried again. Unfortunately I cannot install the development version of devtools now\n```r\nERROR: dependencies \u2018callr\u2019, \u2018pkgbuild\u2019, \u2018pkgload\u2019 are not available for package \u2018devtools\u2019\n* removing \u2018/Library/Frameworks/R.framework/Versions/3.4/Resources/library/devtools\u2019\nInstallation failed: Command failed (1)\n\nsessionInfo()\nR version 3.4.1 (2017-06-30)\nPlatform: x86_64-apple-darwin15.6.0 (64-bit)\nRunning under: macOS Sierra 10.12.2\n\nMatrix products: default\nBLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nloaded via a namespace (and not attached):\n[1] compiler_3.4.1 tools_3.4.1 \n```. My initial guess on problem probably was not right. From the error messages, I think the development version tried to install binary package but failed first, then tried to install source. The similar command used in CRAN version was different and succeeded.\nI tested again with devtools 1.12.0 and 1.13.0 (which covered the original Jan report date), both can install ctmm current version correctly. I'm not sure why the current development version cannot be installed, but the original issue is no longer a problem now.. ",
    "hruffieux": "Ok, I updated git2r, it works now. Thanks!. ",
    "jtbates": "Ah, okay. I had assumed it was more common since I found it in the manual. I've figured out how to install the binary without install.libs.R. If the target for the executable in Makevars is set to ../inst/bin/execname then it can be found by system.file('bin', 'execname', package=pkg_name) because the shim checks in inst/.\nI don't think it would be much code to add support for install.lib.R in the way that I was using it. It looks like there was code for it at one point in packman. However, I am not sure if some packages' install.libs.R scripts depend on the installation directory R_PACKAGE_DIR being different from the source directory R_PACKAGE_SOURCE. That would complicate things.\nWould the relevant code to look at for adding support for install.libs.R be found in pkgload::load_all?. ",
    "PerFuchs": "Yep, I agree. Works on my machine as well.. ",
    "briancohn": "I am also getting this error. ",
    "Neil-Schneider": "I attempted resolving this in #1580, but ran into some odd behavior from the warning if show was not missing.. Yes he did. Thanks!. The help index can be seen here: help(package=\"devtools\"). It is populated by /library/devtools/html/00index.html.  \nThe inst/NEWS.Rd gets included in the help index during the install as seen here: help(package = \"lme4\"). You can see at the top of the index is a link to Package NEWS. (/library/lme4/NEWS.Rd). It appears the test-examples still fails due to differences in quoting characters. (' vs \"). ",
    "robertamezquita": "Yes, you're right, same result occurs when doing R CMD build . ..so this isn't a devtools problem then, sorry about that...but if you happen to have any suggest workarounds for this, I would very much appreciate the help! Thanks ~. The Makefile workaround is a great idea, thank you so much!. ",
    "bdwyer2": "I think it would be difficult to create a reproducible example because I would have to create a whole package skeleton but it's easy to see the bug if you run View(devtools::run_examples) and look at lines 20-29.. ",
    "naught101": "(Just realised this isn't a devtools problem, but I still haven't found any useful way to debug an R CMD build call...)\n. OK, looks like it is due to a man/FluxnetProcessing-package.Rd file, which was a template that I hadn't filled out yet. I deleted that file and it's now working.\nI guess I should close this, but any general advice on how to debug a broken build would be great. (I had to manually bisect this by deleting files and re-trying the build). Ok, that wasn't it. That stopped R CMD build . from failing, but R CMD INSTALL . still fails, with the same message.. Ok, bad data file in data/ - there was a readme.txt in there, which was being treated as a CSV, changing that to a .md fixed things.\nSorry for the hassle, perhaps this can be useful to someone else.... ",
    "cinkie": "Don't install R under 'program files' folder. ",
    "mschilli87": "I wanted to test more packages without risking to break more usable packages, so I tried\nr\nrequire(devtools)\nrequire(withr)\nwithr::with_libpaths(\"/tmp/\",install_github(\"bimsbbioinfo/circus\"))\nand it worked (pulling in a lot of dependencies incl. Bioconductor).\nSo I tried\nr\nwithr::with_libpaths(\"/tmp/\",install_github(\"rajewsky-lab/dropbead\"))\nwithr::with_libpaths(\"/tmp/\",install_github(\"satijalab/seurat\"))\nand again it worked: a lot of dependencies & the target packages were installed sucessfully in my /tmp directory.\n\nAs this suggested  a problem with my existing library, I tried to rebuild it from scratch:\n```r\nbackup existing library\nmylib<-.libPaths()[1]\nbackuplib<-paste0(mylib,\".old\")\nfile.rename(mylib,backuplib)\ndir.create(mylib)\ninstall CRAN version of devtools\ninstall.packages(\"devtools\")\ninstall github version of devtools\nrequire(devtools)\ninstall_github(\"hadley/devtools\")\nre-load (new) devtools\ndetach(\"package:devtools\", unload = TRUE)\nrequire(devtools)\ninstall Bioconductor\nsource(\"https://www.bioconductor.org/biocLite.R\")\nbiocLite()\nbiocValid()\ndowngrade packages as requested by biocValid\nbiocLite(c(\"callr\", \"devtools\"))\nbiocValid()\nre-install all packages installed previously\nbiocLite(dir(backuplib))\n```\nThis installed all but a few packages that I had installed from github before.\nTrying to install the first of them, I got a new error:\nr\ninstall_github(\"jalvesaq/colorout\")\nDownloading GitHub repo jalvesaq/colorout@master\nfrom URL https://api.github.com/repos/jalvesaq/colorout/zipball/master\nInstalling colorout\nInstallation failed: NULL : 'rcmd_safe_env' is not an exported object from 'namespace:callr'\nAs callr & devtools were the two packages downgraded for Bioconductor, I figured I had to re-load them again.\nr\ndetach(\"package:devtools\", unload = TRUE)\nrequire(devtools)\nLoading required package: devtools\nError in get(method, envir = home) : \n  lazy-load database '/home/mschilli/R/x86_64-pc-linux-gnu-library/3.3/devtools/R/devtools.rdb' is corrupt\nIn addition: Warning message:\nIn get(method, envir = home) : internal error -3 in R_decompress1\nSo just in case, I tried to re-install devtools through biocLite:\nr\nremove.packages(\"devtools\")\nbiocLite(\"devtools\")\nbiocValid()\nrequire(devtools)\n```\nLoading required package: devtools\nError in get(method, envir = home) : \n  lazy-load database '/home/mschilli/R/x86_64-pc-linux-gnu-library/3.3/devtools/R/devtools.rdb' is corrupt\nIn addition: Warning messages:\n1: In .registerS3method(fin[i, 1], fin[i, 2], fin[i, 3], fin[i, 4],  :\n  restarting interrupted promise evaluation\n2: In get(method, envir = home) :\n  restarting interrupted promise evaluation\n3: In get(method, envir = home) : internal error -3 in R_decompress1\n\ndetach(\"package:devtools\", unload = TRUE)\nError in detach(\"package:devtools\", unload = TRUE) : \n  invalid 'name' argument\n```\n\nAs this did not work out, I tried again with the CRAN devtools\nr\nremove.packages(\"devtools\")\ninstall.packages(\"devtools\")\nrequire(devtools)\n```\nLoading required package: devtools\nError in get(method, envir = home) : \n  lazy-load database '/home/mschilli/R/x86_64-pc-linux-gnu-library/3.3/devtools/R/devtools.rdb' is corrupt\nIn addition: Warning messages:\n1: In .registerS3method(fin[i, 1], fin[i, 2], fin[i, 3], fin[i, 4],  :\n  restarting interrupted promise evaluation\n2: In get(method, envir = home) :\n  restarting interrupted promise evaluation\n3: In get(method, envir = home) : internal error -3 in R_decompress1\n\ndetach(\"package:devtools\", unload = TRUE)\nError in detach(\"package:devtools\", unload = TRUE) : \n  invalid 'name' argument\n```\n\nNext I tried launching a new session:\nr\nq(save=\"no\")\nsh\nR\nNow I managed to install devtools (Bioconductor-compatible) and all github packages I need:\n```r\nre-install devtools (& callr) using biocLite\nrequire(BiocInstaller)\nremove.packages(c(\"callr\",\"devtools\"))\nbiocLite(\"devtools\")\nbiocValid()\nrequire(devtools)\ninstall packages reported as 'not available' from github\ninstall_github(\"jalvesaq/colorout\")\ninstall_github(\"bimsbbioinfo/circus\")\nremove old library\nmylib<-.libPaths()[1]\nbackuplib<-paste0(mylib,\".old\")\nunlink(backuplib, recursive=TRUE)\ninstall 'problematic' packages\ninstall_github(\"rajewsky-lab/dropbead\")\ninstall_github(\"satijalab/seurat\")\n```\n\nWhile this does not explain what was broken, I hope it can help others running into similar issues to 'fix' them.\nThank you for you response and let me know if there is still anything I can do to track down this issue.. ",
    "thomasp85": "Oh, didn't know that one... Much cleaner. ",
    "alex23lemm": "Today, I ran into the problem by letting several people install the tutor package using devtools. All Mac and Linux users had no issues and also the installation for the majority of the Windows users went well. \nHowever, some of the Windows users ran into the problem described above which looked as follows in our case:\n ```r\n\ndevtools::install_github(\"rstudio/tutor\")\nDownloading GitHub repo rstudio/tutor@master\nfrom URL https://api.github.com/repos/rstudio/tutor/zipball/master\nError in utils::unzip(src, exdir = target) : \n  cannot open file 'C:/Users/mshumper/AppData/Local/Temp/RtmpeE4D2Q/devtools23e061002ad9/rstudio-tutor-1476bf6/R/ace.R': No such file or directory\n``\nAll users installed the current R version 3.3.3 and the current RStudio version 1.0.136  today prior to trying to installtutorviadevtools`.\n\nEven though I am on Windows as well I was not able to reproduce the bug on my machine.\n. ",
    "dfifield": "This sounds very similar to the problem described in Issue #1433. The work-around was to get rid of .Rbuildignore.. ",
    "jonathanrandall": "\"internal\". ",
    "pgwatson": "getOption(\u201cunzip\u201d) also yields \u201cinternal\u201d and fails for me\nHowever if I set the unzip option to point to the unzip.exe program bundled with the github application then everything appears to work correctly.\nThe version info for unzip.exe bundled with github is\nGithub/unzip.exe -v\nUnZip 6.00 of 20 April 2009, by Info-ZIP.  Maintained by C. Spieler.  Send\nbug reports using http://www.info-zip.org/zip-bug.html; see README for details.\nLatest sources and executables are at ftp://ftp.info-zip.org/pub/infozip/ ;\nsee ftp://ftp.info-zip.org/pub/infozip/UnZip.html for other sites.\nCompiled with gcc 4.9.2 for Unix (Cygwin) on Nov  4 2014.\nUnZip special compilation options:\n        ACORN_FTYPE_NFS\n        ASM_CRC\n        COPYRIGHT_CLEAN (PKZIP 0.9x unreducing method not supported)\n        SET_DIR_ATTRIB\n        SYMLINKS (symbolic links supported, if RTL and file system permit)\n        TIMESTAMP\n        UNIXBACKUP\n        USE_EF_UT_TIME\n        USE_UNSHRINK (PKZIP/Zip 1.x unshrinking method supported)\n        USE_DEFLATE64 (PKZIP 4.x Deflate64(tm) supported)\n        UNICODE_SUPPORT [wide-chars, char coding: UTF-8] (handle UTF-8 paths)\n        MBCS-support (multibyte character support, MB_CUR_MAX = 6)\n        LARGE_FILE_SUPPORT (large files over 2 GiB supported)\n        ZIP64_SUPPORT (archives using Zip64 for large files supported)\n        USE_BZIP2 (PKZIP 4.6+, using bzip2 lib version 1.0.6, 6-Sept-2010)\n        VMS_TEXT_CONV\n        WILD_STOP_AT_DIR\n        [decryption, version 2.11 of 05 Jan 2007]\nUnZip and ZipInfo environment options:\n           UNZIP:  [none]\n        UNZIPOPT:  [none]\n         ZIPINFO:  [none]\n      ZIPINFOOPT:  [none]\n. Interestingly if I point instead to the version 6.00 unzip bundled with Rtools then the devtools::install_github process still fails\nThe Rtools version of unzip (which doesn\u2019t work) has several different compilation flags set compared to the version from github (which does work)\nCompilation flags follow:\nRtools/unzip.exe -v\nUnZip 6.00 of 20 April 2009, by Info-ZIP.  Maintained by C. Spieler.  Send\nbug reports using http://www.info-zip.org/zip-bug.html; see README for details.\nLatest sources and executables are at ftp://ftp.info-zip.org/pub/infozip/ ;\nsee ftp://ftp.info-zip.org/pub/infozip/UnZip.html for other sites.\nCompiled with Microsoft C 13.10 (Visual C++ 7.1) for\nWindows 9x / Windows NT/2K/XP/2K3 (32-bit) on Apr 20 2009.\nUnZip special compilation options:\n        ASM_CRC\n        COPYRIGHT_CLEAN (PKZIP 0.9x unreducing method not supported)\n        NTSD_EAS\n        SET_DIR_ATTRIB\n        TIMESTAMP\n        UNIXBACKUP\n        USE_EF_UT_TIME\n        USE_UNSHRINK (PKZIP/Zip 1.x unshrinking method supported)\n        USE_DEFLATE64 (PKZIP 4.x Deflate64(tm) supported)\n        UNICODE_SUPPORT [wide-chars] (handle UTF-8 paths)\n        MBCS-support (multibyte character support, MB_CUR_MAX = 1)\n        LARGE_FILE_SUPPORT (large files over 2 GiB supported)\n        ZIP64_SUPPORT (archives using Zip64 for large files supported)\n        USE_BZIP2 (PKZIP 4.6+, using bzip2 lib version 1.0.5, 10-Dec-2007)\n        VMS_TEXT_CONV\n        [decryption, version 2.11 of 05 Jan 2007]\nUnZip and ZipInfo environment options:\n           UNZIP:  [none]\n        UNZIPOPT:  [none]\n         ZIPINFO:  [none]\n      ZIPINFOOPT:  [none]\nGithub/unzip.exe -v\nUnZip 6.00 of 20 April 2009, by Info-ZIP.  Maintained by C. Spieler.  Send\nbug reports using http://www.info-zip.org/zip-bug.html; see README for details.\nLatest sources and executables are at ftp://ftp.info-zip.org/pub/infozip/ ;\nsee ftp://ftp.info-zip.org/pub/infozip/UnZip.html for other sites.\nCompiled with gcc 4.9.2 for Unix (Cygwin) on Nov  4 2014.\nUnZip special compilation options:\n        ACORN_FTYPE_NFS\n        ASM_CRC\n        COPYRIGHT_CLEAN (PKZIP 0.9x unreducing method not supported)\n        SET_DIR_ATTRIB\n        SYMLINKS (symbolic links supported, if RTL and file system permit)\n        TIMESTAMP\n        UNIXBACKUP\n        USE_EF_UT_TIME\n        USE_UNSHRINK (PKZIP/Zip 1.x unshrinking method supported)\n        USE_DEFLATE64 (PKZIP 4.x Deflate64(tm) supported)\n        UNICODE_SUPPORT [wide-chars, char coding: UTF-8] (handle UTF-8 paths)\n        MBCS-support (multibyte character support, MB_CUR_MAX = 6)\n        LARGE_FILE_SUPPORT (large files over 2 GiB supported)\n        ZIP64_SUPPORT (archives using Zip64 for large files supported)\n        USE_BZIP2 (PKZIP 4.6+, using bzip2 lib version 1.0.6, 6-Sept-2010)\n        VMS_TEXT_CONV\n        WILD_STOP_AT_DIR\n        [decryption, version 2.11 of 05 Jan 2007]\nUnZip and ZipInfo environment options:\n           UNZIP:  [none]\n        UNZIPOPT:  [none]\n         ZIPINFO:  [none]\n      ZIPINFOOPT:  [none]\n. ",
    "BarkleyBG": "I've had a similar issue with devtools 1.12 and roxygen2 6.0.1. However, I was able to get this to work with devtools 1.12 and roxygen2 4.0.1. If you rolled back to your roxygen2 4.1.1, are you able to get this to work?\nEDIT: \nI am also having issue nearly identical to klutometis/roxygen#600, which may or may not be helpful to diagnosing the issue in the present issue ticket.. I think this may relate to https://github.com/r-lib/devtools/issues/1979 ? \n```{r}\ninstall\ninstall_github(MY_ORG,  username = MY_ID, host = MY_HOST,\nauth_token = my_github_pat, dependencies = T)\n```\nwhich returns\n```{r}\nError in class(xx) <- cl : attempt to set an attribute on NULL\n```\nHere's a traceback:\n{r}\ntraceback()\n10: .POSIXct(res_headers$x-ratelimit-reset, tz = \"UTC\")\n9: github_error(res)\n8: stop(github_error(res))\n7: github_DESCRIPTION(username = remote$username, repo = remote$repo,\nsubdir = remote$subdir, host = remote$host, ref = remote$ref,\npat = remote$auth_token %||% github_pat(), use_curl = use_curl)\n6: remote_package_name.github_remote(remote)\n5: remote_package_name(remote)\n4: FUN(X[[i]], ...)\n3: vapply(remotes, install_remote, ..., FUN.VALUE = character(1))\n2: install_remotes(remotes, auth_token = auth_token, host = host,\ndependencies = dependencies, upgrade = upgrade, force = force,\nquiet = quiet, build = build, build_opts = build_opts, repos = repos,\ntype = type, ...)\n1: install_github( MY_ORG,  username = MY_ID, host = MY_HOST,\nauth_token = my_github_pat, dependencies = T). ",
    "RalphJO": "Thank you for all the suggestions. Adding # Generated by roxygen2: do not edit by hand to the namespace file is the workaround that worked for me. It does feel like a workaround not a fix though: I'm not sure a function designed to create the documentation should fail with an error if a piece of documentation doesn't exist.\n----Original message----\nFrom : notifications@github.com\nDate : 09/03/2017 - 13:06 (GMT)\nTo : devtools@noreply.github.com\nCc : ralpholsson@btinternet.com, author@noreply.github.com\nSubject : Re: [hadley/devtools] document() failing after upgrade from 1.7.0 to 1.12.0 due to NAMESPACE file (#1466)\nJust keep the # Generated by roxygen2: do not edit by hand line at the top then.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/hadley/devtools\",\"title\":\"hadley/devtools\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/hadley/devtools\"}},\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@jimhester in #1466: Just keep the # Generated by roxygen2: do not edit by hand line at the top then.\"}],\"action\":{\"name\":\"View Issue\",\"url\":\"https://github.com/hadley/devtools/issues/1466#issuecomment-285346175\"}}}\n. ",
    "fangly": "Great suggestion regarding the helper utils, Jim, thanks! Back when I investigated this issue, the corresponding StackOverflow question did not have this answer.\nBut there is still the issue of other code that may be present in the \"tests/testthat.R\" file. In my case, I have a library(pkg1) statement, that loads a module containing testthat expectations. Or I may append extra lines of code to the file in the future to postprocess the test_check() results. Do you have a better alternative for these use cases, other than having devtools::test() use the \"tests/testthat.R\" just like devtools::check()?\n. ",
    "matdoering": "Ok, thank you for clarifying. In this case, would it be possible to update the function documentation to reflect this?\nApart from this, what about the problem of installing BiocInstaller using install() as described above? It seems that devtools doesn't load biocLite correctly?. Well, of course the issue is clearly communicated. But when you are distributing a package in development to a person that is not a developer you have to tell them how it's done rather than having it done automatically by devtools. Just a suggestion :-). ",
    "cvitolo": "I had a similar issue with an Rmd vignette. I fixed it by changing the YAML header of the vignette to something like this:\n```\nauthor: \"Name Surname\"\ndate: \"r Sys.Date()\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteEngine{knitr::knitr}\n  %\\VignetteIndexEntry{Title of your vignette}\n  %\\usepackage[UTF-8]{inputenc}\n\n```\n. ",
    "MansMeg": "```\nR version 3.3.2 (2016-10-31)\nPlatform: x86_64-apple-darwin13.4.0 (64-bit)\nRunning under: macOS Sierra 10.12.2\nlocale:\n[1] sv_SE.UTF-8/sv_SE.UTF-8/sv_SE.UTF-8/C/sv_SE.UTF-8/sv_SE.UTF-8\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] dplyr_0.5.0\nloaded via a namespace (and not attached):\n [1] magrittr_1.5     R6_2.2.0         assertthat_0.1   DBI_0.5-1     \n [5] tools_3.3.2      withr_1.0.2      tibble_1.2       Rcpp_0.12.9   \n [9] memoise_1.0.0    stringi_1.1.2    stringr_1.2.0    digest_0.6.11 \n[13] rcrpsriksdag_0.1 devtools_1.12.0 \n``. Ah! Thanks for the information. Then I'll try that or maybe move out the R data file outside the package. It does not make much sense to have it in a package then.. Cool. I didn't know that. Maybe runuse_test()as a part ofuse_testthat()? Or print a message when runninguse_testthat()that says thatuse_test()` creates new example test? I spent 20 minutes finding an old test example, and I guess others would do the same mistake. =). ",
    "wiaidp": "A similar issue was discussed at https://github.com/hadley/devtools/issues/1332 but the link provided there (https://github.com/hadley/devtools/issues/426) did not address that problem, at least as far as I can see.. ",
    "jpritikin": "Can't we ask devtools to look at DESCRIPTION.in? The only differences are:\nDate: @DATE@\nVersion: @VERSION@\nIt doesn't need the date and version, does it?. ",
    "jimvine": "Thanks for looking at this, @gaborcsardi. If you want to run the tests but testthat is unavailable then what do you think would be more useful than a warning? Should it be a stop() error condition instead?\nI agree that not running the tests is also fine, which is presumably why devtools sets testthat as Suggests rather than Depends.. ",
    "earino": "@jimhester perfect! Thank you!. ",
    "lwjohnst86": "@dkod ~Have you tried wrapping your name with \" quotes rather than '? For instance \"O'Day\".~ I see, the issue is with the initial installation to the file path indicated. Double quotes might not work then.. ",
    "mkohara": "@hadley What do you mean by it works with \"dev devtools\". I'm also having the same issue that @dkod had due to an apostrophe in my name.. ",
    "luiarthur": "I actually found the solution here.\nApparently, the java directory needs to be in the inst directory. After making the change, everything works fine.\nHere's the toy example of a package that depends on rscala. \n. ",
    "pooranis": "I had the same problem.  In the source code, the install_remote function doesn't pass the credentials to remote_sha.git_remote (or actually, remote_sha.git_remote doesn't pass it to git2r::remote_ls),  so the function just hangs.  They do get passed through remote_download.git_remote to git2r::clone.  Could this be changed to be consistent or is this a problem with git2r?\nIf the ssh key is not the default, then you would have to pass the credentials.  I'm not sure how to cache them with ssh-agent from within Rstudio.  So, if that's a better solution than changing the function, does anyone have any pointers?. ",
    "james-atkins": "Yes looks like @pooranis is right and the credentials are not passed to git2r::remote_ls. I've submitted a pull request which should fix this: https://github.com/hadley/devtools/pull/1501.. ",
    "vermouthmjl": "From what I can see, it seems there isn't really need to have load_helpers here\n (https://github.com/hadley/devtools/commit/c323994466562b4117f071a0bcf8e7392dc2045d https://github.com/hadley/devtools/commit/588dd9716b72ca89a185146cb0cd947f1c308144), since it's already in https://github.com/hadley/testthat/commit/326a52c83d7ee49a57f6c6b4a7db0c70e9a115cc, at least for using test(). However, I don't know if these changes affect other things.. OK, great. Thank you.\n(I was trying to use install_version to install an older version of devtools, and that does not seem to work, but I guess that's normal.). ",
    "mdavy86": "thanks for that.. ",
    "schifferl": "@jimhester thank you for the excellent work that you have done with Travis CI, AppVeyor, and Codecov\nI can confirm that both of the points brought up by @gaborcsardi are still issues.\nSee my YAML files here https://github.com/schifferl/devtoo\nSee the single quotes issue at line 324 https://ci.appveyor.com/project/schifferl/devtoo/build/1.0.3#L324\nThen see the missing integration at line 259 https://ci.appveyor.com/project/schifferl/devtoo/build/1.0.4#L259\nI will just fix with the token but wanted to confirm the behavior.. I suppose it is somewhat of a moot point because Codecov will just merge matrix builds into a single report. https://codecov.io/pricing\n\nHow does Codecov combine matrix builds and multiple CI providers?\nEffortlessly. Codecov merges builds into a single report while maintaining the original source of the coverage data. Send as many uploads from different CI providers and languages to Codecov. Plug-and-Play! See a fine example here pyca/cryptography .. \n",
    "pfgherardini": "Looks like it to me. ",
    "zbjornson": "(I'm the one with the original problem who @pfgherardini was helping out.)\n@gaborcsardi the version of devtools in the master branch of this repo has the same problem.\nI think this is worth filing as a bug in R-core, as newer versions of Windows have SFN disabled by default on NTFS drives other than C: AFAIK. That is, the issue will only get worse as more users get newer versions of Windows.. I reported this issue on r-devel last week: https://stat.ethz.ch/pipermail/r-devel/2017-September/074921.html\nThe R developers keep bugzilla locked down, so I can't file a bug directly, and no one has picked up the bug from the mailing list yet.. https://stat.ethz.ch/pipermail/r-devel/2017-October/075023.html\n\nThis has now been mostly fixed in R-devel. What remains to be resolved \nis that some packages with custom make files cannot be installed from \nsource (when R is installed into a directory with space in its name and \nshort file names are not available)\nTomas. \n",
    "raonirao": "Hello guys!\n[Editing my previous reply]\nI had posted a long reply arguing that enabling 8dot3name wouldn't work, but I was wrong. I took the time to investigate further and simply enabling it using fsutil.exe doesn't create shortnames for existing diretories (such as C:\\Program Files). So the problem hasn't been solved for my R installation's folder.\nWhat are our options then? I thought about creating shortnames for C:\\Program Files, would it solve it? Or would it be needed for other folders as well? Anyway, it doesn't seem straightforward, specially for the average user (look here). I'm asking all of this instead of testing bc I have this issue with my employer's computer, what leaves little room to experiment (security concerns from the IT guys, a lot of convincing to do, spending precious work hours because I can't do it from home ...). My home PC has 8dotname enabled and it works fine (maps C:\\PROGRA~1 to C:\\Program Files as it should).\nThat said, is this being addressed elsewhere (e.g. R-core)? I couldn't find a reply for the issue on the R-devel threads (@hadley's question here). \nThanks again everyone!\nAbra\u00e7o,\nRaoni\nMy original post is below:\nI've had the same issue, specifically when trying to create a binary for a package I use at my work (devtools::build). I've talked with the IT department and they've enabled the 8dot3name to all volumes in my machine (currently 2, the R is on C:)\nLong story short: enabling the 8dot3name didn't seem to help, but I may be having some issues with Rtools as well. More below.\nTrying to build the binary (.zip, for windows), I get:\n```r\n\"C:/Program Files/R/R-3.4.0patched/bin/x64/R\" --no-site-file --no-environ  \\\n  --no-save --no-restore --quiet CMD INSTALL \"D:_PACOTES R\\utilidades\"  \\\n  --build --preclean \n'C:\\Program' n\ufffdo \ufffd reconhecido como um comando interno\nou externo, um programa oper\ufffdvel ou um arquivo em lotes.\nError: Command failed (1)\nExecution halted\nExited with status 1.\n```\n(which is this thread's title in Portuguese with a few encoding issues)\nIf I try to Build & Reload, I get:\n```r\n==> Rcmd.exe INSTALL --no-multiarch --with-keep.source utilidades\n'C:\\Program' n\ufffdo \ufffd reconhecido como um comando interno\nou externo, um programa oper\ufffdvel ou um arquivo em lotes.\nExited with status 1.\n```\nIt also brings a popup: Building R packages requires installation of additional build tools. Do you want to install the additional build tools now?. By clicking 'yes' it tries to download Rtools, which I already have, but fails because the mirror it uses is blocked by the IT department. I don't think this is at the core of the issue, since it fails the build as usual (\"C:\\Program is not recognized as internal or external program...\").\nOn issue #855 Hadley said the R.home() is supposed to return the 8.3 name. From ?R.home(): \n\nOn Windows the values of R.home() and R_HOME are switched to the 8.3 short form of path elements if required and if the Windows service to do that is enabled. The value of R_HOME is set to use forward slashes (since many package maintainers pass it unquoted to shells, for example in \u2018Makefile\u2019s).\n\nIn my case, it is still returning the full path:\n```r\n\nR.home()\n[1] \"C:/Program Files/R/R-3.4.0patched\"\n```\n\nAdditionally, for utils::shortPathName's documentation:\n\nFor most file systems, the short form is the \u2018DOS\u2019 form with 8+3 path components and no spaces, and this used to be guaranteed. But some file systems on recent versions of Windows do not have short path names when the long-name path will be returned instead.\n\nIn my case, enabling 8dot3name didn't change it either:\n```r\n\nshortPathName(R.home())\n[1] \"C:\\Program Files\\R\\R-3.4.0patched\"\n```\n\nI couldn't find a reply for the issue on the R-devel threads (Hadley's question here). Question: is this being addressed elsewhere (e.g. base R)?\n```r\n\nsessionInfo()\nR version 3.4.0 Patched (2017-06-17 r72808)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows >= 8 x64 (build 9200)\n\nMatrix products: default\nlocale:\n[1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252    LC_MONETARY=Portuguese_Brazil.1252\n[4] LC_NUMERIC=C                       LC_TIME=Portuguese_Brazil.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nloaded via a namespace (and not attached):\n[1] compiler_3.4.0 tools_3.4.0 \n```\nAbra\u00e7os,\nRaoni. ",
    "julcoh": "I am also having this issue right now.\n@zbjornson I believe you may be onto something-- is it possible this is an issue if the \"Program Files\" directory is located on a second hard drive separate from the Windows OS? I have the majority of my files on a D drive.\nNote the below output is trying installation with a local download of the github repo after failing with the devtools::install_github command.\n```\n\ndevtools::install_local(\"D:/Downloads/streamgraph-master\")\nInstalling streamgraph\n\"D:/Program Files/R/R-3.4.1/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \\\n  \"C:/Users/Julien/AppData/Local/Temp/Rtmpuw4ku3/file25583e4523d5/streamgraph-master\" --library=\"D:/Program  \\\n  Files/R/R-3.4.1/library\" --install-tests \n\n'D:\\Program' is not recognized as an internal or external command,\noperable program or batch file.\nInstallation failed: Command failed (1)\n```. @Hong-Revo Of course, that worked.\nDoesn't solve the core issue, but thank you for the help.. @zbjornson thanks for the update.. ",
    "Hong-Revo": "Running fsutil.exe enables short filename support for a drive, but doesn't create them for directories that already exist.\nTry uninstalling and reinstalling R, this time into a brand-new directory tree (not under \\Program Files). Or you could delete \\Program Files and recreate it, but I really wouldn't do that.\n. Unfortunately that doesn't work. The vignette still gets compiled, it just means that there's no output from any R code inside it. It then gets copied to inst/doc, overwriting the version with the output.. Will pkgdown actually solve this problem? From what I saw on browsing the documentation, the situation is the same: build_site will build all vignettes, without any options to choose which ones.. This looks like the same issue as #1514.. ",
    "JoWi2": "I just ran into the same issue, following Hadley's instructions on how to \"make\" the ggplot2 book.\n\n'make' is not recognized as an internal or external command, operable program or batch file.\nExited with status 1.\n\nSo doing some research I found this thread and it seems (?!?) the issue is resolved. But since I have no experience with git at all, I still have no clue how to resolve it in my case and would be very happy if someone could guide me through it (step by step for newbies)\nThanks!\n\nEdit:\nNow I tried it using the Git Bash and learned that the make command Hadley suggests is not part of normal Git but needs to be installed as an \"add on\". So I did that and everything works fine, except for the final command \"make\" (make clear worked fine!).\nInstead of the coveted PDF I get\n$ make\nmkdir -p book/tex\nmkdir -p book/tex/_figures\nmkdir -p book/tex/diagrams\ncp book/ggplot2-book.tex book/tex/ggplot2-book.tex\nRscript book/render-tex.R data-manip.rmd\nprocess_begin: CreateProcess(NULL, Rscript book/render-tex.R data-manip.rmd, ...) failed.\nmake (e=2): The system cannot find the file specified.\nmake: *** [Makefile:23: book/tex/data-manip.tex] Error 2\n. I still have the same problem\nOn Thursday, June 28, 2018 2:46:42 AM EDT Michael Batech wrote:\n\nIs this still broken?\n`> install.packages(\"finalfit\")\ninstalling the source package \u2018finalfit\u2019\ntrying URL\n'https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.rstudio.com_src_\ncontrib_finalfit-5F0.7.8.tar.gz&d=DwIFaQ&c=c6MrceVCY5m5A_KAUkrdoA&r=ONEg04Ap\n1V9ObWqAi-6ivIsrgcd91QLmkEy8RAKCfoM&m=wlWFJXFfmObHL7u13uti01GpV3Qon2A910Lpmv\nACCak&s=dWYPni3Fyzp8sJ3QeiLIVAz52YWLHO5si8eS6TwUJfs&e=' Content type\n'application/x-gzip' length 922694 bytes (901 KB)\ndownloaded 901 KB\n'C:\\Program' is not recognized as an internal or external command,\noperable program or batch file.\nWarning in install.packages :\n  running command '\"C:/Program Files (x86)/R/R-3.4.2/bin/x64/R\" CMD INSTALL\n-l \"C:\\Program Files (x86)\\R\\R-3.4.2\\library\"\nC:\\Users\\M285595\\AppData\\Local\\Temp\\Rtmpa8EnDU/downloaded_packages/finalfit\n_0.7.8.tar.gz' had status 1 Warning in install.packages :\n  installation of package \u2018finalfit\u2019 had non-zero exit status\nThe downloaded source packages are in\n  \u2018C:\\Users\\M257495\\AppData\\Local\\Temp\\Rtmpa8EnDU\\downloaded_packages\u2019\n\nR.home()\n\n[1] \"C:/Program Files (x86)/R/R-3.4.2\"\n\nshortPathName(R.home())\n\n[1] \"C:\\Program Files (x86)\\R\\R-3.4.2\"`\n. \n",
    "Ruminare": "Is this still broken?\n\n> install.packages(\"finalfit\")\ninstalling the source package \u2018finalfit\u2019\ntrying URL 'https://cran.rstudio.com/src/contrib/finalfit_0.7.8.tar.gz'\nContent type 'application/x-gzip' length 922694 bytes (901 KB)\ndownloaded 901 KB\n'C:\\Program' is not recognized as an internal or external command,\noperable program or batch file.\nWarning in install.packages :\n  running command '\"C:/Program Files (x86)/R/R-3.4.2/bin/x64/R\" CMD INSTALL -l \"C:\\Program Files (x86)\\R\\R-3.4.2\\library\" C:\\Users\\M285595\\AppData\\Local\\Temp\\Rtmpa8EnDU/downloaded_packages/finalfit_0.7.8.tar.gz' had status 1\nWarning in install.packages :\n  installation of package \u2018finalfit\u2019 had non-zero exit status\nThe downloaded source packages are in\n  \u2018C:\\Users\\M285595\\AppData\\Local\\Temp\\Rtmpa8EnDU\\downloaded_packages\u2019\n> R.home()\n[1] \"C:/Program Files (x86)/R/R-3.4.2\"\n> shortPathName(R.home())\n[1] \"C:\\Program Files (x86)\\R\\R-3.4.2\". \n",
    "seankross": "Thanks @jimhester, I'll do that.. ",
    "MarkEdmondson1234": "Relevant, I just had a package fail CRAN submission as the codecov badge was incorrect. https://github.com/hadley/devtools/issues/1528. There would be no concern for GDPR if no ID is stored that can be linked back to a user (I've done GDPR audits for web analytics past few months)  \nI've wondered about doing this myself for tracking package installs, which I suggest if using Google Analytics would be best done by a measurement protocol hit that I've wrapped in https://github.com/MarkEdmondson1234/googleMeasureR - if its a random cid (cookieID) and anonymise ip you would just get aggregated metrics.  Lots of similar services out there that work via a API hit.  I would favour an opt-in though upon installation. (\"I agree to give anonymous statistics to help the developers etc. etc\"). ",
    "drisso": "FWIW I can reproduce your two examples with the full clusterExperiment package. I.e., \n{r}\nlibrary(devtools)\nload_all()\nlibrary(clusterExperiment)\nload_all()\nworks with a warning. While (new session)\n{r}\nlibrary(clusterExperiment)\nlibrary(devtools)\nload_all()\ngives\n{r}\n Error in setClassUnion(\"dendrogramOrNULL\", members = c(\"dendrogram\", \"NULL\")) : \n  unable to create union class:  could not set members \"NULL\"\nSo I believe that your minimal example does fully capture the behavior that we see in clusterExperiment.\n```{r}\n\nsessionInfo()\nR version 3.4.0 (2017-04-21)\nPlatform: x86_64-apple-darwin15.6.0 (64-bit)\nRunning under: macOS Sierra 10.12.5\n\nMatrix products: default\nBLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\nattached base packages:\n[1] parallel  stats4    stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n [1] devtools_1.13.2            bigmemory_4.5.19           bigmemory.sri_0.1.3        SummarizedExperiment_1.7.4\n [5] DelayedArray_0.3.12        matrixStats_0.52.2         Biobase_2.37.2             GenomicRanges_1.29.4    \n [9] GenomeInfoDb_1.13.4        IRanges_2.11.5             S4Vectors_0.15.4           BiocGenerics_0.23.0       \nloaded via a namespace (and not attached):\n [1] nlme_3.1-131            bitops_1.0-6            bold_0.4.0              doParallel_1.0.10    \n [5] RColorBrewer_1.1-2      progress_1.1.2          httr_1.2.1              prabclus_2.2-6       \n [9] tools_3.4.0             R6_2.2.1                DBI_0.6-1               lazyeval_0.2.0       \n[13] colorspace_1.3-2        ade4_1.7-6              trimcluster_0.1-2       nnet_7.3-12          \n[17] withr_1.0.2             gridExtra_2.2.1         prettyunits_1.0.2       compiler_3.4.0       \n[21] xml2_1.1.1              pkgmaker_0.22           diptest_0.75-7          scales_0.4.1         \n[25] DEoptimR_1.0-8          mvtnorm_1.0-6           robustbase_0.92-7       NMF_0.20.6           \n[29] commonmark_1.2          stringr_1.2.0           digest_0.6.12           XVector_0.17.0       \n[33] limma_3.33.3            rlang_0.1.1             howmany_0.3-1           jsonlite_1.5         \n[37] mclust_5.3              dendextend_1.5.2        dplyr_0.5.0             RCurl_1.95-4.8       \n[41] magrittr_1.5            modeltools_0.2-21       GenomeInfoDbData_0.99.1 Matrix_1.2-10        \n[45] Rcpp_0.12.11            munsell_0.4.3           ape_4.1                 abind_1.4-5          \n[49] viridis_0.4.0           stringi_1.1.5           whisker_0.3-2           MASS_7.3-47          \n[53] zlibbioc_1.23.0         flexmix_2.3-14          MAST_1.3.1              plyr_1.8.4           \n[57] grid_3.4.0              rncl_0.8.2              lattice_0.20-35         splines_3.4.0        \n[61] uuid_0.1-2              taxize_0.8.4            fpc_2.1-10              rngtools_1.2.4       \n[65] reshape2_1.4.2          codetools_0.2-15        XML_3.98-1.7            RNeXML_2.0.7         \n[69] data.table_1.10.4       foreach_1.4.3           locfdr_1.1-8            gtable_0.2.0         \n[73] tidyr_0.6.3             reshape_0.8.6           kernlab_0.9-25          assertthat_0.2.0     \n[77] ggplot2_2.2.1           gridBase_0.4-7          phylobase_0.8.4         xtable_1.8-2         \n[81] RSpectra_0.12-0         roxygen2_6.0.1          class_7.3-14            viridisLite_0.2.0    \n[85] tibble_1.3.3            iterators_1.0.8         registry_0.3            memoise_1.1.0        \n[89] cluster_2.0.6        \n```. ",
    "mjpnijmeijer": "I build the package (in which I kept the offending unit test as the only one). I am not sure if that allows you to reproduce the issue. If not, please let me know.\nlmvar_1.2.1.900.tar.gz\n. Thank you. Removing the R_TESTS variable indeed solves the issue. If there is some info available about this variable / issue, I'll go through it. I searched the internet but nothing much turned up.\nI also did not know about the helper file. Nice!. ",
    "colearendt": "Same issue after removing R CMD javareconf.  \n```\n$ Rscript -e 'deps <- devtools::dev_package_deps(dependencies = NA);devtools::install_deps(dependencies = TRUE);if (!all(deps$package %in% installed.packages())) { message(\"missing: \", paste(setdiff(deps$package, installed.packages()), collapse=\", \")); q(status = 1, save = \"no\")}'\nmissing: rJava, xlsxjars\nThe command \"Rscript -e 'deps <- devtools::dev_package_deps(dependencies = NA);devtools::install_deps(dependencies = TRUE);if (!all(deps$package %in% installed.packages())) { message(\"missing: \", paste(setdiff(deps$package, installed.packages()), collapse=\", \")); q(status = 1, save = \"no\")}'\" failed and exited with 1 during .\n```\nIs there any way to add additional verbosity to the log that would be helpful?  Or a way to test this out locally?  I am happy to contribute, but am ignorant of how to test these sorts of builds locally.  If this is an issue with devtools, I would love to figure it out before the next R release.\nConfig on most recent build:\n```\n{\n  \"language\": \"r\",\n  \"os\": \"osx\",\n  \"sudo\": true,\n  \"cache\": \"packages\",\n  \"r\": \"devel\",\n  \"before_script\": [\n    \"java -version\",\n    \"echo PATH=$PATH\",\n    \"echo JAVA_HOME=$JAVA_HOME\"\n  ],\n  \"after_success\": [\n    \"Rscript -e 'covr::codecov()'\"\n  ]\n}\n``. The install block (required _all_ dependencies) was a successful workaround for the devtools issue.  I am out of ideas for what might be the root issue, as it does not look like devtools even tries to install the packages before failing.  I also tried moving the packages fromDependstoImports`, unfortunately to no avail.  Not sure if there is something about these dependencies in particular that is a problem.  Perhaps it would be worth building a test package that allows more easily declaring various dependencies to see where the root cause is.  Is this concerning in any regard from a devtools perspective; enough to warrant re-opening?  Might it be something related to building from source or the version of R that packages are built with on CRAN?  (i.e. if it does not look like the packages are on CRAN because it is running on R 3.5?)\nIt is definitely less than ideal to have to maintain a list of all dependencies in DESCRIPTION, as well as in .travis.yml, when devtools works great on all other OS / version combinations.. @jimhester I am fairly concerned this might be a devtools bug that is worth re-opening.  I created a basic package with RStudio, and the build on osx with R 3.5 is failing with the same problems.  I tested rJava by itself, as well as dplyr by itself.  Both failed with the same error message, suggesting that the packages are not the problem.\nIt seems that for some reason, devtools is not installing dependencies appropriately on osx / R 3.5.  The hope is that this would only be due to it being a \"devel\" release at present and perhaps something about how CRAN is built, but it might be worth doing some deeper digging to be sure.  I am unsure of the best way to do so or what next steps might be beneficial.. Related to #1370, perhaps, although this problem is only on OSX and the devel version of R, so not sure whether there is any relationship.. @hadley @jimhester I think this ought to be reopened and addressed, as it suggests a universal problem with devtools properly installing dependencies on devel / OSX.  I would think it is preferable to resolve the issue before R 3.5 is released.  (Again - build failure with a dependency only on dplyr). More OSX R-devel build failures on otherwise good builds... not sure if this is related or not.  Maybe R-devel is having problems on OSX and devtools just did not handle it nicely... (or handled it too nicely to give a nice warning / error)\ncurl -fLo /tmp/R.pkg https://r.research.att.com/mavericks/R-devel/R-devel-mavericks-signed.pkg\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (60) SSL certificate problem: Invalid certificate chain\nMore details here: http://curl.haxx.se/docs/sslcerts.html\ncurl performs SSL certificate verification by default, using a \"bundle\"\n of Certificate Authority (CA) public keys (CA certs). If the default\n bundle file isn't adequate, you can specify an alternate file\n using the --cacert option.\nIf this HTTPS server uses a certificate signed by a CA represented in\n the bundle, the certificate verification probably failed due to a\n problem with the certificate (it might be expired, or the name might\n not match the domain name in the URL).\nIf you'd like to turn off curl's verification of the certificate, use\n the -k (or --insecure) option.\nThe command \"eval curl -fLo /tmp/R.pkg https://r.research.att.com/mavericks/R-devel/R-devel-mavericks-signed.pkg \" failed. Retrying, 2 of 3.\nConfirmed that the same failure occurred on my previous test (fail is on R install now, before devtools goes to work).  Here is to hoping that R-3.5 is the problem and not devtools!. Merp.  Yes, dev version working fine.  I needed to restart R to get the dev changes to take effect.  And here I trusted session_info! haha.  Sorry about that! . ",
    "akumaraug": "The same issue i have find.. ",
    "tonytonov": "Same here for \nR version 3.4.1 (2017-06-30)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows >= 8 x64 (build 9200)\nCan be bypassed by using Authors@R, (source).. ",
    "alistaire47": "\nCRAN is using an updated Pandoc now, which should not have this problem.\n\nGood to know, thanks! \n\nChanging the other files, however, in the same PR, is not very good imo.\n\nYeah, I was startled when I looked at the diff; I literally only typed one letter. There's a lot of automation going on with the rest, which I think is mostly the result of running document(). It appeared it hadn't been run in a while which is why I left the changes, but updated with a commit without them.\nI found StripTrailingWhitespace: Yes was set in the project options (devtools.Rproj), which is where the other change in infrastructure.R came from. I turned it off, saved, and turned it on again, so the commit is now literally one letter.\n\nEdit: Oops, clicked the wrong button and closed by accident, sorry. Fixed.. ",
    "TinkaMiau": "Unfortunately not. \nI also tried the german version to install it and it says after installing I should use \"devtools::install_github(\"dcangst/batplotr\",dependencies=TRUE)\" but there the information \"Error in loadNamespace(name) : es gibt kein Paket namens \u2018devtools\u2019\" is given which means \"there is no \"devtools\" package\". I tried again to install it as following:\ninstall.packages(c(\"devtools\"),dependencies=TRUE)\nWarning in install.packages :\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES.rds': HTTP status was '404 Not Found'\nInstalling package into \u2018C:/Users/t_kni/Documents/R/win-library/3.4\u2019\n(as \u2018lib\u2019 is unspecified)\nWarning in install.packages :\n  dependency \u2018BiocInstaller\u2019 is not available\nalso installing the dependencies \u2018backports\u2019, \u2018lazyeval\u2019, \u2018irlba\u2019, \u2018pkgconfig\u2019, \u2018assertthat\u2019, \u2018BH\u2019, \u2018praise\u2019, \u2018magrittr\u2019, \u2018yaml\u2019, \u2018htmltools\u2019, \u2018caTools\u2019, \u2018base64enc\u2019, \u2018rprojroot\u2019, \u2018stringr\u2019, \u2018highr\u2019, \u2018markdown\u2019, \u2018rex\u2019, \u2018stringdist\u2019, \u2018igraph\u2019, \u2018stringi\u2019, \u2018brew\u2019, \u2018desc\u2019, \u2018commonmark\u2019, \u2018xml2\u2019, \u2018jsonlite\u2019, \u2018git2r\u2019, \u2018withr\u2019, \u2018crayon\u2019, \u2018testthat\u2019, \u2018Rcpp\u2019, \u2018rmarkdown\u2019, \u2018knitr\u2019, \u2018hunspell\u2019, \u2018lintr\u2019, \u2018bitops\u2019, \u2018roxygen2\u2019, \u2018evaluate\u2019, \u2018rversions\u2019, \u2018covr\u2019, \u2018gmailr\u2019\nWarning in install.packages :\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.4/PACKAGES.rds': HTTP status was '404 Not Found'\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/backports_1.1.0.zip'\nContent type 'application/zip' length 32812 bytes (32 KB)\ndownloaded 32 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/lazyeval_0.2.0.zip'\nContent type 'application/zip' length 140103 bytes (136 KB)\ndownloaded 136 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/irlba_2.2.1.zip'\nContent type 'application/zip' length 263497 bytes (257 KB)\ndownloaded 257 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/pkgconfig_2.0.1.zip'\nContent type 'application/zip' length 20030 bytes (19 KB)\ndownloaded 19 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/assertthat_0.2.0.zip'\nContent type 'application/zip' length 43793 bytes (42 KB)\ndownloaded 42 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/BH_1.62.0-1.zip'\nContent type 'application/zip' length 16150325 bytes (15.4 MB)\ndownloaded 15.4 MB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/praise_1.0.0.zip'\nContent type 'application/zip' length 17957 bytes (17 KB)\ndownloaded 17 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/magrittr_1.5.zip'\nContent type 'application/zip' length 155022 bytes (151 KB)\ndownloaded 151 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/yaml_2.1.14.zip'\nContent type 'application/zip' length 179637 bytes (175 KB)\ndownloaded 175 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/htmltools_0.3.6.zip'\nContent type 'application/zip' length 618631 bytes (604 KB)\ndownloaded 604 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/caTools_1.17.1.zip'\nContent type 'application/zip' length 285771 bytes (279 KB)\ndownloaded 279 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/base64enc_0.1-3.zip'\nContent type 'application/zip' length 39385 bytes (38 KB)\ndownloaded 38 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/rprojroot_1.2.zip'\nContent type 'application/zip' length 60673 bytes (59 KB)\ndownloaded 59 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/stringr_1.2.0.zip'\nContent type 'application/zip' length 148102 bytes (144 KB)\ndownloaded 144 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/highr_0.6.zip'\nContent type 'application/zip' length 36059 bytes (35 KB)\ndownloaded 35 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/markdown_0.8.zip'\nContent type 'application/zip' length 168929 bytes (164 KB)\ndownloaded 164 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/rex_1.1.1.zip'\nContent type 'application/zip' length 88365 bytes (86 KB)\ndownloaded 86 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/stringdist_0.9.4.4.zip'\nContent type 'application/zip' length 201966 bytes (197 KB)\ndownloaded 197 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/igraph_1.1.2.zip'\nContent type 'application/zip' length 8250281 bytes (7.9 MB)\ndownloaded 7.9 MB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/stringi_1.1.5.zip'\nContent type 'application/zip' length 14289534 bytes (13.6 MB)\ndownloaded 13.6 MB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/brew_1.0-6.zip'\nContent type 'application/zip' length 104967 bytes (102 KB)\ndownloaded 102 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/desc_1.1.0.zip'\nContent type 'application/zip' length 173196 bytes (169 KB)\ndownloaded 169 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/commonmark_1.2.zip'\nContent type 'application/zip' length 251436 bytes (245 KB)\ndownloaded 245 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/xml2_1.1.1.zip'\nContent type 'application/zip' length 3528889 bytes (3.4 MB)\ndownloaded 3.4 MB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/jsonlite_1.5.zip'\nContent type 'application/zip' length 1159897 bytes (1.1 MB)\ndownloaded 1.1 MB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/git2r_0.19.0.zip'\nContent type 'application/zip' length 3027960 bytes (2.9 MB)\ndownloaded 2.9 MB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/withr_1.0.2.zip'\nContent type 'application/zip' length 44312 bytes (43 KB)\ndownloaded 43 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/crayon_1.3.2.zip'\nContent type 'application/zip' length 705930 bytes (689 KB)\ndownloaded 689 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/testthat_1.0.2.zip'\nContent type 'application/zip' length 1057262 bytes (1.0 MB)\ndownloaded 1.0 MB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/Rcpp_0.12.12.zip'\nContent type 'application/zip' length 3319033 bytes (3.2 MB)\ndownloaded 3.2 MB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/rmarkdown_1.6.zip'\nContent type 'application/zip' length 2275638 bytes (2.2 MB)\ndownloaded 2.2 MB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/knitr_1.16.zip'\nContent type 'application/zip' length 1026285 bytes (1002 KB)\ndownloaded 1002 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/hunspell_2.6.zip'\nContent type 'application/zip' length 1808003 bytes (1.7 MB)\ndownloaded 1.7 MB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/lintr_1.0.0.zip'\nContent type 'application/zip' length 152090 bytes (148 KB)\ndownloaded 148 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/bitops_1.0-6.zip'\nContent type 'application/zip' length 37218 bytes (36 KB)\ndownloaded 36 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/roxygen2_6.0.1.zip'\nContent type 'application/zip' length 756939 bytes (739 KB)\ndownloaded 739 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/evaluate_0.10.1.zip'\nContent type 'application/zip' length 48479 bytes (47 KB)\ndownloaded 47 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/rversions_1.0.3.zip'\nContent type 'application/zip' length 17110 bytes (16 KB)\ndownloaded 16 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/covr_3.0.0.zip'\nContent type 'application/zip' length 118076 bytes (115 KB)\ndownloaded 115 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/gmailr_0.7.1.zip'\nContent type 'application/zip' length 109971 bytes (107 KB)\ndownloaded 107 KB\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/devtools_1.13.2.zip'\nContent type 'application/zip' length 443150 bytes (432 KB)\ndownloaded 432 KB\npackage \u2018backports\u2019 successfully unpacked and MD5 sums checked\npackage \u2018lazyeval\u2019 successfully unpacked and MD5 sums checked\nError in install.packages : cannot open file 'C:/Users/t_kni/Documents/R/win-library/3.4/file38b0745a65/irlba/doc/irlba.pdf': Permission denied\nI do not know what to do.... thanks for your reply. I do have the admin privileges because I am the only user at that computer. :/. ",
    "samkart": "Hey, everything looks good with the download part. \nYou can try that again by starting R with admin privileges. The same thing happened to me. I found that the dll files were inaccessible due to improper permissions. \nI'm thinking it is relevant because Error in install.packages : cannot open file 'C:/Users/t_kni/Documents/R/win-library/3.4/file38b0745a65/irlba/doc/irlba.pdf': Permission denied has Permission denied in it.. ",
    "lfmcmillan": "I'm really glad there is a build_manual() function as a separate function, because when I run check(manual=TRUE) and build(manual=TRUE) from the command line in Windows 10, they don't actually create the manual, and running build_manual() seems to be the only way to successfully create the PDF manual. ",
    "alexilliamson": "Yes installing other packages works fine.  Here is what happens when I try to install from CRAN:\n`\ninstall.packages(\"devtools\")\nInstalling package into \u2018C:/Users/abwilliamson/Rpackages\u2019\n(as \u2018lib\u2019 is unspecified)\nThere is a binary version available but the source version is later:\n         binary source needs_compilation\ndevtools 1.13.2 1.13.3             FALSE\ninstalling the source package \u2018devtools\u2019\ntrying URL 'http://cran.rstudio.com/src/contrib/devtools_1.13.3.tar.gz'\nContent type 'application/x-gzip' length 486402 bytes (475 KB)\ndownloaded 475 KB\nWarning in install.packages :\n  running command '\"//cityofno/cno-fs/UserData/Home2/abwilliamson/R/R-3.3.3/bin/x64/R\" CMD INSTALL -l \"C:\\Users\\abwilliamson\\Rpackages\" C:\\Users\\ABWILL~1\\AppData\\Local\\Temp\\RtmpsPnNQq/downloaded_packages/devtools_1.13.3.tar.gz' had status 127\nWarning in install.packages :\n  installation of package \u2018devtools\u2019 had non-zero exit status\n`. I reinstalled R, Rtools, and then RStudio. Not ideal, but hey it works now!  Thanks for your help. ",
    "paternogbc": "Thanks @jimhester !\nI will do that and give you a feedback! \n. Hi @kevinushey ,\nI am running LINUX but there is no crash outside Rstudio. When using R outside Rstudio, devtools functions works just fine. I am not sure if that was what you asked. I can also try to install and do some testing in a virtual machine with Windows or other Linux distributions.\nAlso, when running the commands document() or check() with the Rstudio GUI panel, it also works fine. Is just when using these commands at the console that Rstudio crashes. \nLet me know how I can help.. ",
    "AmundsenJunior": "In trying to test this, I found that spelling, called from spell-check.R, is only a \"Suggests\" not \"Required\" package. Calling devtools::spell_check() failed because this pkg was missing. Should it be moved to \"Required\"?. Looking into this, is there an idea as to how to change default behavior of build_vignettes() with its call to install()? \nbuild_vignettes() has install = TRUE for a param and its default. If the default of install() is changed to build_vignettes = TRUE per this feature request, then calling build_vignettes() would actually build the vignettes twice.\nDo I have that logic correct? Would we want build_vignettes() to call install as devtools::install(..., build_vignettes = FALSE) to keep the process the same for that function?. I'm considering two ways of implementing this. First option is to place a save_all() function into R/utils.R. I'm not sure that this is the best location, if we are anticipating expanding with impls for other editors. In that case, it makes more sense to me to create R/save-all.R, and export the function from that file.. @jimhester created PR for save-all.R. I ran devtools::document() to generate a new check.Rd for the latest change to that file, as it was the only error in TravisCI. Doing so only revealed other errors in the build. Should I remove the check.Rd change and/or wait to address this PR once the test failures are resolved?. @jimhester Updated NEWS.md and the email address. Thanks.. styler removed all function indentation as extra whitespaces, so I added it back. It will get removed each time styler is run against this file, though.. This whole file is not noticeably changed much by styler. The side-by-side compare is mixed-up for reasons I can't discern.. ~~Will do.~~ Done.. cran_submission_url isn't a function - doe this upload_to call still work?. As the dest is no longer just the known hard-coded CRAN URL, perhaps should include a cleaner on the parameter. In remotes pkg, they pass a trimmed whitespace URL to their remote functions. Could similarly here call the trim_ws() function.. This function release_to() doesn't appear to exist.. Was a function structure similar to your change of upload_cran() calling upload_to() considered for this function as well, since much of the structure is the same?. Consider renaming build_cran() to build_pkg(), as the package can be generically built, regardless of destination.. ",
    "kanasethu": "Issue resolved.  Looked through the install_github code.  Not sure where, why or how a GITHUB_PAT was set in my R environment!  Unsetting it worked fine.\n```\n\ninstall_github(\"StatsWithR/statsr\")\nUsing GitHub PAT from envvar GITHUB_PAT\nDownloading GitHub repo StatsWithR/statsr@master\nfrom URL https://api.github.com/repos/StatsWithR/statsr/zipball/master\nInstallation failed: Bad credentials (401)\ninstall_github\nfunction (repo, username = NULL, ref = \"master\", subdir = NULL,\nauth_token = github_pat(quiet), host = \"https://api.github.com\",\nquiet = FALSE, ...)\n      \n}\n\ngithub_pat(1)\n[1] \"bf88\"\ngithub_pat\n\nfunction (quiet = FALSE)\n{\npat <- Sys.getenv(\"GITHUB_PAT\")\n   \nreturn(NULL)\n}\n\n\nSys.getenv(\"GITHUB_PAT\")\n[1] \"bf88\"\nSys.unsetenv(\"GITHUB_PAT\")\nSys.getenv(\"GITHUB_PAT\")\n\n[1] \"\"\n\ninstall_github(\"StatsWithR/statsr\")\nDownloading GitHub repo StatsWithR/statsr@master\nfrom URL https://api.github.com/repos/StatsWithR/statsr/zipball/master\nInstalling statsr                     <<< Bob's your uncle. \n",
    "potterzot": "Thanks, I was at 0.11.0. Manually updating git2r (now 0.19.0) does the trick. Would you like me to do a PR with the DESCRIPTION change you highlighted?. ",
    "DataStrategist": "So it's clear to me that if I have a package on github (not yet on CRAN), and used use_vignettes() and want to let users to see the vignette when they install from github, we should instruct to \n use devtools::install_github(..., build_vignettes = TRUE). \nHowever, this prevents me from displaying my vignette on github per se. The vignette is (kind of by definition) the best way to explain how to use my package and would like to be able to display it to prospective downloaders on github itself. So I have 2 questions:\n\nWhat is the motivation for  .gitignoreing the inst/doc? \nHow frowny would it be for me to manually remove inst/doc from gitignore so that I can show my vignette from github? Would that screw up install_github()?. @hadley So I guess the question (and this is def. a soft question) then becomes \"what's the difference between walthroughing your package in pkgdown or in a vignette? Is it appropriate to one walkthrough that takes both forms?. @hadley so it does. I'm going to go into the corner and curl into a ball and cry myself to sleep now... thanks.. I've been having this issue again on the latest version of devtools and Rstudio... do you know why? Running Sys.setenv(\"TAR\" = \"internal\") makes it work, but I have to reset that everytime I start Rstudio.\n\n\nsessionInfo()\nR version 3.5.2 (2018-12-20)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows >= 8 x64 (build 9200)\n\nMatrix products: default\nlocale:\n[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252 \n[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                        \n[5] LC_TIME=English_United States.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.0         rstudioapi_0.7     magrittr_1.5       usethis_1.4.0   \n [5] devtools_2.0.1     pkgload_1.0.2      debugme_1.1.0      R6_2.3.0        \n [9] rlang_0.3.1        tools_3.5.2        pkgbuild_1.0.2     sessioninfo_1.1.1 \n[13] cli_1.0.1          withr_2.1.2        remotes_2.0.2.9000 yaml_2.1.19     \n[17] assertthat_0.2.0   digest_0.6.18      rprojroot_1.3-2    crayon_1.3.4    \n[21] callr_2.0.3        fs_1.2.6           curl_3.2           testthat_2.0.1  \n[25] memoise_1.1.0      glue_1.3.0         compiler_3.5.2     desc_1.2.0      \n[29] backports_1.1.2    prettyunits_1.0.2 \n. ",
    "micdonato": "I am having the same problem. \nWhenever I run devtools::document() or devtools::check() RStudio crashes.\nNothing seems to be saved in the logs.\nThe only thing I get is the \"bomb\" message (\"R session aborted, fatal error, yadda yadda\").\nIf I run check from the RStudio panel I get the following error, but I can't identify what I am missing.\n```\n==> devtools::document(roclets=c('rd', 'collate', 'namespace'))\n caught segfault \naddress 0x18, cause 'memory not mapped'\nTraceback:\n 1: dyn.load(file, DLLpath = DLLpath, ...)\n 2: library.dynam(lib, package, package.lib)\n 3: loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])\n 4: namespaceImport(ns, loadNamespace(i, c(lib.loc, .libPaths()),     versionCheck = vI[[i]]), from = package)\n 5: loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])\n 6: namespaceImport(ns, loadNamespace(i, c(lib.loc, .libPaths()),     versionCheck = vI[[i]]), from = package)\n 7: loadNamespace(package, ...)\n 8: doTryCatch(return(expr), name, parentenv, handler)\n 9: tryCatchOne(expr, names, parentenv, handlers[[1L]])\n10: tryCatchList(expr, classes, parentenv, handlers)\n11: tryCatch(loadNamespace(package, ...), error = function(e) e)\n12: requireNamespace(dep_name, quietly = TRUE)\n13: check_dep_version(package, version)\n14: pkgload::check_suggested(package = package, version = version,     compare = compare, path = path)\n15: check_suggested(\"roxygen2\")\n16: devtools::document(roclets = c(\"rd\", \"collate\", \"namespace\"))\n17: withCallingHandlers(expr, packageStartupMessage = function(c) invokeRestart(\"muffleMessage\"))\n18: suppressPackageStartupMessages({    oldLC <- Sys.getlocale(category = \"LC_COLLATE\")    Sys.setlocale(category = \"LC_COLLATE\", locale = \"C\")    on.exit(Sys.setlocale(category = \"LC_COLLATE\", locale = oldLC))    devtools::document(roclets = c(\"rd\", \"collate\", \"namespace\"))})\nAn irrecoverable exception occurred. R is aborting now ...\nExited with status 11.\n```\nroxygen2 is installed\ndevtools is installed from github. ",
    "benjaminhlina": "@jimhester Thank you for the suggestions and updating devtools. However, I'm running into a very similar issue as @ShanSabri. He was having issues both in the build tab and console. At this moment, I'm able to enter devtools::check() in the console, devtools operates as normal and checks the package, but if I am to run the check in the build tab it produces the same error as described above. Thanks for any help.. ",
    "qinghenyuanluo": "@benjaminhlina I encountered the exact same problem as yours. \"I'm able to enter devtools::check() in the console, devtools operates as normal and checks the package, but if I am to run the check in the build tab it produces the same error as described above. \" How do you fix it? Thank you!. ",
    "qingchenyuanluo": "@jimhester Thanks for your answers. But I'm really new to R, and I'm not sure what does \"keep check_dir\" mean and how to \"modify the rcmdcheck to accept a check_dir argument\". Sorry about this. If you could further explain it, I would be appreciated!. ",
    "Keaton1188": "My bad, meant API versions* Its currently on 3.0.0-ALPHA6  \nNeed it on ALPHA7 please. . ",
    "JustinMShea": "Rolled back from dev version on Github to CRAN and its working fine!. Ok cool! My initial thought was to just download it again, but I checked my version and that of the DESCRIPTION file, and they matched, ending in .9000. So I decided to 'reverse' to the CRAN repo, but thanks for messaging here so I can get back on the Github.. ",
    "pawamoy": "I'm interested in this as well.\nIt seems that a lot of the packages I install with install_version are being compiled on my local machine every time, and it takes a long time. But maybe this is normal behavior? If it is, then is there a way to install a specific version using binary, not sources?. OK, thanks :crying_cat_face: . ",
    "sshenoy-mdsol": "Running R CMD check from the terminal does work. I have included the output below.\nR_CMD_check_output.txt\nR_check_install_output.txt\n00install.out.txt\nUnfortunately I am not allowed to share this package but I will try to create a minimal example package that exhibits the same behavior.. ",
    "sushilashenoy": "Okay, I was able to reproduce this issue with only two lines from the DESCRIPTION file. If I make a new package in Rstudio without changing any defaults, devtools::check() completes with 1 warning. If I add these lines to the end of the DESCRIPTION file:\nImports: caret\nDepends: survival\nThen this happens:\n```\n....\n checking for sufficient/correct file permissions ... OK\n checking whether package \u2018blah\u2019 can be installed ... ERROR\nInstallation failed.\nSee \u2018/tmp/RtmpxbD6lO/blah.Rcheck/00install.out\u2019 for details.\n* DONE\nStatus: 1 ERROR\nSee\n  \u2018/tmp/RtmpxbD6lO/blah.Rcheck/00check.log\u2019\nfor details.\nR CMD check results\n1 error  | 0 warnings | 0 notes\nchecking whether package \u2018blah\u2019 can be installed ... ERROR\nInstallation failed.\nSee \u2018/tmp/RtmpxbD6lO/blah.Rcheck/00install.out\u2019 for details.\n```\nand the 00install.out file contains:\n* installing *source* package \u2018blah\u2019 ...\n** R\n** preparing package for lazy loading\nError: package or namespace load failed for \u2018survival\u2019 in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\n there is no package called \u2018Matrix\u2019\nError : package \u2018survival\u2019 could not be loaded\nERROR: lazy loading failed for package \u2018blah\u2019\n* removing \u2018/tmp/RtmpxbD6lO/blah.Rcheck/blah\u2019\nIf I remove either the \"Imports: caret\" or \"Depends: survival\" lines from the DESCRIPTION file, devtools::check() no longer fails at installation.. ",
    "Isaacsh": "Sure\nfile.exists(file.path(R.home(\"etc\"), \"curl-ca-bundle.crt\"))\nTRUE\nSys.getenv(\"CURL_CA_BUNDLE\", NA)\nNA\ncurl:::.onLoad()\n\"C:/PROGRA~1/MIE74D~1/ROPEN~1/R-34~1.0/etc/curl-ca-bundle.crt\"\n. Microsoft R Open. https://mran.microsoft.com/\n. Yes\ncurl::curl_fetch_memory(\"https://httpbin.org/get\")\nError in curl::curl_fetch_memory(\"https://httpbin.org/get\") : \n  error setting certificate verify locations:\n  CAfile: /mingw64/ssl/certs/ca-bundle.crt\n  CApath: none \nNo\nreadLines(base::url(\"https://httpbin.org/get\"))\n[1] \"{\"                                                                \n [2] \"  \\\"args\\\": {}, \"                                                 \n [3] \"  \\\"headers\\\": {\"                                                 \n [4] \"    \\\"Cache-Control\\\": \\\"no-cache\\\", \"                            \n [5] \"    \\\"Connection\\\": \\\"close\\\", \"                                  \n [6] \"    \\\"Host\\\": \\\"httpbin.org\\\", \"                                  \n [7] \"    \\\"User-Agent\\\": \\\"R (3.4.0 x86_64-w64-mingw32 x86_64 mingw32)\\\"\"\n [8] \"  }, \"                                                            \n [9] \"  \\\"origin\\\": \\\"198.208.159.19\\\", \"                               \n[10] \"  \\\"url\\\": \\\"https://httpbin.org/get\\\"\"                           \n[11] \"}\" \n. Here is the snapshot\n\n. That's right which sounds odd. I am currently upgrading. More to come. Upgrading to 3.4.1 didn't help.. Exactly same errors pop up. I cannot reach the path  (C:/PROGRA~1/MIE74D~1) from Windows Explorer due to changes in the labels applied (have no idea how), but think it matches to the screenshot.. True\n\nreadLines(\"C:/PROGRA~1/MIE74D~1/ROPEN~1/R-34~1.1/etc/curl-ca-bundle.crt\")[1:20]\n [1] \"##\"                                                                                                          \n [2] \"## Bundle of CA Root Certificates\"                                                                           \n [3] \"##\"                                                                                                          \n [4] \"## Certificate data from Mozilla downloaded on: Thu Sep  4 06:31:22 2014\"                                    \n [5] \"##\"                                                                                                          \n [6] \"## This is a bundle of X.509 certificates of public Certificate Authorities\"                                 \n [7] \"## (CA). These were automatically extracted from Mozilla's root certificates\"                                \n [8] \"## file (certdata.txt).  This file can be found in the mozilla source tree:\"                                 \n [9] \"## http://hg.mozilla.org/releases/mozilla-release/raw-file/default/security/nss/lib/ckfw/builtins/certdata.txt\"\n[10] \"##\"                                                                                                          \n[11] \"## It contains the certificates in PEM format and therefore\"                                                 \n[12] \"## can be directly used with curl / libcurl / php_curl, or with\"                                             \n[13] \"## an Apache+mod_ssl webserver for SSL client authentication.\"                                               \n[14] \"## Just configure this file as the SSLCACertificateFile.\"                                                    \n[15] \"##\"                                                                                                          \n[16] \"## Conversion done with mk-ca-bundle.pl verison 1.22.\"                                                       \n[17] \"## SHA1: c4540021427a6fa29e5f50db9f12d48c97d33889\"                                                           \n[18] \"##\"                                                                                                          \n[19] \"\"                                                                                                            \n[20] \"\"  . Results of running the code is:\n\n\ntimeout on name lookup is not supported\nHostname in DNS cache was stale, zapped\nTrying 144.72.225.21...\nTCP_NODELAY set\nConnected to naproxy.[SOMETHING].com (144.72.225.21) port 80 (#1)\nALPN, offering http/1.1\nCipher selection: ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH\nerror setting certificate verify locations:\n  CAfile: /mingw64/ssl/certs/ca-bundle.crt\n  CApath: none\nClosing connection 1\nError in curl::curl_fetch_memory(\"https://httpbin.org/get\", handle = new_handle(verbose = T)) : \n  error setting certificate verify locations:\n  CAfile: /mingw64/ssl/certs/ca-bundle.crt\n  CApath: none\n\n. Issue was resolved with #jeroen/curl#116 by explicitly passing h handle with curl::curl_fetch_memory(\"https://httpbin.org/get\", handle = h) using corporate proxies. It didn't work by tweaking .Renviron file though. \nThanks!. Is there a way to pass handle explicitly in httr::oauth1.0_token. Am getting the same error while trying to test demo code oauth1-twitter.r:\nlibrary(httr)\noauth_endpoints(\"twitter\")\nmyapp <- oauth_app(\"twitter\",key = key1, secret = s1)\ntwitter_token <- oauth1.0_token(oauth_endpoints(\"twitter\"), myapp)\nAnd it yells again: \nError in curl::curl_fetch_memory(url, handle = handle) : \n  error setting certificate verify locations:\n  CAfile: /mingw64/ssl/certs/ca-bundle.crt\n  CApath: none\n. Here is the traceback output:\n\ntraceback()\n11: .Call(R_curl_fetch_memory, enc2utf8(url), handle, nonblocking)\n10: curl::curl_fetch_memory(url, handle = handle)\n9: request_fetch.write_memory(req$output, req$url, handle)\n8: request_fetch(req$output, req$url, handle)\n7: request_perform(req, hu$handle$handle)\n6: POST(endpoint$request, oauth_sig(endpoint$request, \"POST\", private_key = private_key))\n5: init_oauth1.0(self$endpoint, self$app, permission = self$params$permission, \n       private_key = self$private_key)\n4: self$init_credentials()\n3: .subset2(public_bind_env, \"initialize\")(...)\n2: Token1.0$new(app = app, endpoint = endpoint, params = params, \n       private_key = private_key, cache_path = cache)\n1: oauth1.0_token(oauth_endpoints(\"twitter\"), myapp). It worked now. So strange as I had to put them in with http and https prefixes for other applications including Anaconda Python .condarc config file to work. Thanks a bunches. . \n",
    "chinsoon12": "see #https://github.com/jeroen/curl/issues/116. Hi @Isaacsh, does setting \n\u2018Sys.getenv(http_proxy=\u201cmycompanyproxy:8080\u201d)\u2019\n\u2018Sys.getenv(https_proxy=\u201cmycompanyproxy:8080\u201d)\u2019\nBefore running those codes help?\nNote there should not be any http not https in front of the company proxy address. ",
    "wlandau-lilly": "Thank you both!. ",
    "navdeep-G": "Potential solution: https://github.com/h2oai/rsparkling/commit/d7163a8272efc304e38549b36ed2adedca54bcc3. I believe I had a reason and now I do not remember. I will remove those two lines and rely on the CRAN version of devtools. I have a test here: https://github.com/h2oai/rsparkling/pull/54\nThanks!. ",
    "crew102": "Hi @kendonB, the reason why the trailing slash isn't working for you is b/c on Windows file names ending in / are actually invalid. I think I agree that it would be nice if trailing slashes were supported by devtools, given that RStudio adds the trailing slash when auto-completing (though perhaps this should be considered more of an issue with RStudio than with devtools). Here are two discussions of the issue:\nhttps://bugs.r-project.org/bugzilla/show_bug.cgi?id=14721\nhttp://r.789695.n4.nabble.com/file-exists-does-not-like-path-names-ending-in-td4683717.html\n@hadley , what are your thoughts on devtools stripping trailing /'s in file paths? If you think it should be done, I can issue PRs to devtools, pkgload, and desc to support this. \n. ",
    "cdeterman": "@jimhester here is the package I am developing.. @jimhester how would you suggest applying the system.file approach you are suggesting?  I'm not sure how anything I pass to test can alter where the process looks for the files.. ",
    "Bandytwin": "Yes I had accidently sourced a file, thanks for the help!. ",
    "FilipeamTeixeira": "Tried everything you mentioned with no results.\nThis started after installing the new RStudio version. I started having random crashes, which didn't get solved by removing .rstudio-desktop and the usual files to reset everything. Even tried to reinstall R with no success.\nAs that was happening, I decided to tackle the issue package by package, until I got to devtools and data.table. Loading one of those results in R either crashing or giving a similar error to the one mentioned above.. ",
    "jogrue": "Sorry, I just saw that this functionality has now been moved to https://github.com/r-lib/remotes. I have got the same problem when using remotes 1.1.0. Should I close this and move the issue there?. Thank you and sorry for opening the issue here. It is now at https://github.com/r-lib/remotes/issues/114.. ",
    "bioinformatist": "Glad to hear that. Thanks.. ",
    "bioticinteractions": "uninstalled package and reinstalled, problem went away.. ",
    "nibrivia": "Similar issue here. Could not install.packages(\"tidyverse\") with the error above. Installing github version of crayon solved it.. So, I could not get that to work minutes before writing the message. Is this recent enough of an update to not have propagated through the mirrors?. Huh, I thought I did... I'll let you know if this comes back up then.... ",
    "omarbenites": "I had the same issue a couple of weeks ago, because I was working with an older version of crayon (col_align was not included in it). I re-installed install_packages(\"crayon), and it's sorted out.. ",
    "mbaradas": "@omarbenites comment on Dec 23, 2017 worked for me. \"re-installed install_packages(\"crayon), and it's sorted out.\". ",
    "DesmondCampbell": "One of my collaborators had the same problem. It also appears to have come up for find_rtools().\nSee below an extract from an email \nregards\nDesmond\nOn the first computer, everything was fine until devtools::install_github(\"DesmondCampbell/diseaseRiskPredictor\")\n\u2022   The person originally has a very old version of R installed, so I installed the newest version (3.4.2) and all the following is done under R 3.4.2.\n\u2022   The PC has no C++ installed. So indeed Rtools is required for evalCpp() to work.\n\u2022   The newest Rtools is installed.\n\u2022   devtools and Rcpp could be successfully installed and loaded.\n\u2022   evalCpp() works properly.\n\u2022   find_rtools() does not work.\n\u2022   devtools::install_github() does not work.\n\ndevtools::install_github(\"DesmondCampbell/diseaseRiskPredictor\")\nDownloading GitHub repo DesmondCampbell/diseaseRiskPredictor@master\nfrom URL https://api.github.com/repos/DesmondCampbell/diseaseRiskPredictor/zipball/master\nError: running command '\"C:/PROGRA~1/R/R-34~1.2/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD config CC' had status 127\n\nfind_rtools has a similar error. \n. ",
    "skhiggins": "A modified version of @colemonnahan's solution worked for me: I reinstalled Rtools and during installation, on the \"Select Additional Tasks\" dialog box I checked \"Edit the system PATH. ...\". Then on the next screen of the dialog box it confirmed \"Edit the PATH (leaving Rtools\\bin first)\" which means the Rtools directory was now at the top of my path. Then I re-ran\nr\ninstall.packages(\"devtools\")\ndevtools::install_github(\"tidyverse/ggplot2\")\nand got the Github version with no error.. ",
    "andrewrech": "Am I correct that all devtools Bioconductor installs are currently broken because of this?. Ah, I did not realize this about install_git, thank you!. ",
    "rcannood": "I've attempted to fix this over at dynverse/devtools by looking at the code for install_git. I've implemented the fix on the master branch, and backported it to 1.13.0.\nThis fix allows travis to install bioconductor packages from the git repostories.\nShould I create a pull request to be reviewed?. @jimhester Could you review my latest PR (#1705)?\nI've updated my repository as there were some merge conflicts in the meantime. \nSince the subversion repositories have, in the meantime, been fully discontinued, I think this issue should get looked at rather sooner than later.. I moved the repository, will create another PR. Some travis tests are failed at this step (e.g. test-github-connections.R#49):\nR\n  test_pkg <- create_in_temp(\"testGitHub\")\n  mock_use_github(test_pkg)\nCorrect me if I'm wrong, but I believe this is unrelated to the changes that I made.. Done! I synced the fork, just to make sure there were no conflicts.. ",
    "Melkiades": "devtools::install_github(\"rstudio/rmarkdown\"). ",
    "magic-lantern": "Thanks for the guidance @Melkiades and @jimhester . In case someone thinks that the missing dependencies are the source of the problem, I fixed that, but am still getting the same error at the end. Also, I get the same error regardless of user account running (specific user or \"Run as administrator\")\n```\n\ndevtools::install_github(\"hadley/devtools\", build_vignettes = TRUE, force = TRUE)\nDownloading GitHub repo hadley/devtools@master\nfrom URL https://api.github.com/repos/hadley/devtools/zipball/master\nInstalling devtools\nRunning command C:/PROGRA~1/R/R-34~1.3/bin/x64/Rcmd.exe \nArguments:\nbuild\nC:\\Users\\username\\AppData\\Local\\Temp\\RtmpQpK5Yi\\devtools25f4138c52c3\\hadley-devtools-7f5a683\n--no-resave-data\n--no-manual\n checking for file 'C:\\Users\\username\\AppData\\Local\\Temp\\RtmpQpK5Yi\\devtools25f4138c52c3\\hadley-devtools-7f5a683/DESCRIPTION' ... OK\n preparing 'devtools':\n checking DESCRIPTION meta-information ... OK\n installing the package to build vignettes\n* creating vignettes ...Warning: running command '\"C:/PROGRA~1/R/R-34~1.3/bin/x64/Rscript\" --vanilla --default-packages= -e \"tools::buildVignettes(dir = '.', tangle = TRUE)\"' had status 1\n ERROR\nError: file 'C:/Users/username/AppData/Local/Temp/RtmpKe9Atv/Rbuild24501e281f1c/devtools/DESCRIPTION' is not in valid DCF format\nIn addition: Warning message:\nIn read.dcf(dfile, keep.white = .keep_white_description_fields) :\n  cannot open compressed file 'C:/Users/username/AppData/Local/Temp/RtmpKe9Atv/Rbuild24501e281f1c/devtools/DESCRIPTION', probable reason 'Permission denied'\nExecution halted\nInstallation failed: run(bin, args = real_cmdargs, stdout_line_callback = real_callback(stdout),      stderr_line_callback = real_callback(stderr), stdout_callback = real_block_callback,      stderr_callback = real_block_callback, echo_cmd = echo, echo = show,      spinner = spinner, error_on_status = fail_on_status, timeout = timeout) : System command error\n```. Just wanted to post that this is still an issue. There have been many package updates since I first opened this issue, but it still is unchanged eve after updating. I did also try to uninstall everything and re-install, but still doesn't work.. I re-installed R to a non-default path so that there were no spaces in the full path (default is to C:\\Program Files...) new full R path is now:\n\n.libPaths()\n[1] \"C:/Users/username/Documents/R/win-library/3.4\" \"C:/R/R-3.4.3/library\"\nMy username is only ascii letter characters.\nSince I've got R installed to a path without spaces or special characters and my username does not have special characters nor spaces, it seems that this issue may be caused by something different.\nAny ideas for next steps?. Just wanted to provide another update - I also tried installing R to a path that didn't have periods or dashes to see if that made a difference. Still get the same error:\n```\ndevtools::install_github(\"hadley/devtools\", build_vignettes = TRUE, force = TRUE)\nDownloading GitHub repo hadley/devtools@master\nfrom URL https://api.github.com/repos/hadley/devtools/zipball/master\nInstalling devtools\n\"C:/R/R343/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD build  \\\n  \"C:\\Users\\username\\AppData\\Local\\Temp\\RtmpERZR9F\\devtools2a2c28430fa\\r-lib-devtools-95b987c\"  \\\n  --no-resave-data --no-manual \n\nchecking for file 'C:\\Users\\username\\AppData\\Local\\Temp\\RtmpERZR9F\\devtools2a2c28430fa\\r-lib-devtools-95b987c/DESCRIPTION' ... OK\npreparing 'devtools':\nchecking DESCRIPTION meta-information ... OK\ninstalling the package to build vignettes\ncreating vignettes ...Warning: running command '\"C:/R/R343/bin/x64/Rscript\" --vanilla --default-packages= -e \"tools::buildVignettes(dir = '.', tangle = TRUE)\"' had status 1\n ERROR\nError: file 'C:/Users/username/AppData/Local/Temp/RtmpGM8wSd/Rbuild3534409b365e/devtools/DESCRIPTION' is not in valid DCF format\nIn addition: Warning message:\nIn read.dcf(dfile, keep.white = .keep_white_description_fields) :\n  cannot open compressed file 'C:/Users/username/AppData/Local/Temp/RtmpGM8wSd/Rbuild3534409b365e/devtools/DESCRIPTION', probable reason 'Permission denied'\nExecution halted\nInstallation failed: Command failed (1)\n```. My TMPDIR only has ascii characters - no spaces. I did change it to a shorter path though outside my user directory and I also still get the same error as before.\n\nAs an FYI, I did combine this change with changing the R install path - and still getting the same error.. My account is an administrative account (in the Administrators group). I can manually create files/folders and write to existing files and folders in the TMPDIR.. ",
    "jburos": "This may or may not help, but I have seen this error when using devtools to install rstanarm from github. In my case, using option args = \"--preclean\" helps. In your scenario, this would look like the following:\nr\ndevtools::install_github(\"dmenne/breathteststan\", args = \"--preclean\")\nThese related bug reports may also be helpful:\n\nhttp://discourse.mc-stan.org/t/rstanarm-failed-installation-from-github-object-m-not-found/735/5\nhttps://github.com/stan-dev/rstanarm/issues/190\n. \n",
    "hrbrmstr": "It's not doing this on other ones tho. likely something in the pkg. apologies for the annoyance.. i had forgotten that there was a call to rstudioapi::askForPassword(). It's definitely a \"Monday\" so far.. ",
    "batpigandme": "Wow, you just kinda blew my mind with that focussed tidbit\u2026 \ud83d\ude33. ",
    "unDocUMeantIt": "i think i didn't explain myself too well. the one missing package was already installed, system wide, but install_github() decided to install it again, but in my user's R library and from scratch. what's more, the installation happened after the package i actually wanted to install has also already successfully been installed, so installing all dependencies after that doesn't seem to make too much sense to me.. ",
    "kmcconeghy": "I discovered issue, I had a line in .Rbuildignore \"md\". . ",
    "RS-eco": "Okay, I am not really sure how to do this, but will try to figure it out. But, does this mean only someone with a registered ssh key can access the repository. Ideally, I want to keep the repository private, but I want to share it with colleagues, who don't have a GitHub account or registered SSH key. Is there a way, how I can do this?. ",
    "vkapartzianis-reddeer": "I'm having the same issue, and I'm not even using ssh. Trying something like the following just crashes the session.\nR\ndevtools::install_github(\n  repo = \"username/repo\",\n  ref = \"devel\",\n  subdir = \"Library/PackageName\",\n  auth_token = \"abc\"\n) . ",
    "FMKerckhof": "I am having a very similar issue, but I do have addedd --no-build--vignettes to the configure build tools:\n\nNevertheless, running build>Check keeps building vignettes ...\nI am using Version 1.1.383 of Rstudio on a Ubuntu 17.10 desktop.\ndevtools::session_info() gives:\n```\nSession info ------------------------------------------------------------------------------------------\n setting  value                     \n version  R version 3.4.4 (2018-03-15)\n system   x86_64, linux-gnu         \n ui       RStudio (1.1.383)         \n language (EN)                      \n collate  en_US.UTF-8               \n tz       Europe/Brussels           \n date     2018-04-03                  \nPackages ----------------------------------------------------------------------------------------------\n package      * version date       source      \n base         * 3.4.4   2018-03-16 local       \n Biobase        2.38.0  2018-04-03 Bioconductor\n BiocGenerics   0.24.0  2018-04-03 Bioconductor\n cluster        2.0.7   2018-04-01 CRAN (R 3.4.4)\n compiler       3.4.4   2018-03-16 local       \n corpcor        1.6.9   2017-04-01 cran (@1.6.9) \n datasets     * 3.4.4   2018-03-16 local       \n DEoptimR       1.0-8   2016-11-19 cran (@1.0-8) \n devtools       1.13.5  2018-02-18 CRAN (R 3.4.4)\n digest         0.6.15  2018-01-28 CRAN (R 3.4.4)\n flowCore     * 1.44.2  2018-04-03 Bioconductor\n graph          1.56.0  2018-04-03 Bioconductor\n graphics     * 3.4.4   2018-03-16 local       \n grDevices    * 3.4.4   2018-03-16 local       \n grid           3.4.4   2018-03-16 local       \n lattice        0.20-35 2017-03-25 CRAN (R 3.4.4)\n matrixStats    0.53.1  2018-02-11 CRAN (R 3.4.4)\n memoise        1.1.0   2017-04-21 CRAN (R 3.4.1)\n methods      * 3.4.4   2018-03-16 local       \n mvtnorm        1.0-7   2018-01-26 CRAN (R 3.4.4)\n parallel       3.4.4   2018-03-16 local       \n pcaPP          1.9-73  2018-01-14 CRAN (R 3.4.3)\n Rcpp           0.12.16 2018-03-13 CRAN (R 3.4.4)\n robustbase     0.92-8  2017-11-01 CRAN (R 3.4.3)\n rrcov          1.4-3   2016-09-06 cran (@1.4-3) \n stats        * 3.4.4   2018-03-16 local       \n stats4         3.4.4   2018-03-16 local       \n tools          3.4.4   2018-03-16 local       \n utils        * 3.4.4   2018-03-16 local       \n withr          2.1.2   2018-03-15 CRAN (R 3.4.4)\n yaml           2.1.16  2017-12-12 CRAN (R 3.4.3)\n```\n. Thanks Jim, that indeed was the case. . ",
    "nbenn": "The fix is actually very easy: load_all has a helpers argument which can be set to FALSE.. ",
    "fmichonneau": "Thanks @jimhester! I updated the pull request to make the use of foghorn conditional. The travis tests fail but it looks unrelated to my changes. Let me know if the logic I use to only display the \"have you fixed all existing problems at...\" message when:\n- foghorn is absent OR\n- if foghorn detects that there are things to fix\nseems reasonable. PTAL.. @jimhester, a new version of foghorn that includes the fix for this is on CRAN now. Would you like me to submit a PR here to update the minimum required version?. ",
    "ha0ye": "If I find myself with some free time (hah!) over the next few months, I might take a crack at a PR, but it might be slow going given that I don't have any experience in the constructing JSON files.. ",
    "Bustami": "\n9: stop(e)\n8: value[3L]\n7: tryCatchOne(expr, names, parentenv, handlers[[1L]])\n6: tryCatchList(expr, classes, parentenv, handlers)\n5: tryCatch(loadNamespace(name), error = function(e) stop(e))\n4: getNamespace(ns)\n3: asNamespace(ns)\n2: getExportedValue(pkg, name)\n1: devtools::install_github\n\nIt seems be related to my user name in path \"Ismael G\u00f3mez\" not match:\n\n\ninstalling source package 'icon' ...\nWarning in file(file, if (append) \"a\" else \"w\") :\n  cannot open file 'C:/Users/Ismael Gsmez/Documents/R/win-library/3.4/icon/DESCRIPTION': No such file or directory\n. I solved it this way:\n1) Changed my dir for install packages, adding  the new path to my Rpprofile.site:\nR_LIBS_USER=\"new_path\".\n(It's important the new path have only ASCII characters!! )\n2) I copied the already installed packages to the new path\n3) Then i restarted R and execute .libPaths() in order to probe the solution and it has been OK: now i can install hadley/devtools and other packages with devtools::install_github(). \n\n",
    "ELToulemonde": "Hi,\nI encounter the same problem. (By the way thanks for the idea of testthat::test_dir)\nI have managed to build a reproducible example:\nfoo.R: a R file in /R/\nfoo <- function(obj){\n  return(as.numeric(obj))\n}\ntest_foo.R: a uniit test file in /tests/testthat\n```\ntest_that(\"Test my foo function: \",\n          {\n            expect_true(is.na(foo(\"1,5\")))\n            })\n```\ntesthat.R: to run my units tests in /tests/\nlibrary(testthat)\nlibrary(foo)\ntest_check(\"foo\")\n Two scenarios \nRunning: devtools::test()\n```\n\ndevtools::test()\nLoading foo\nLoading required package: testthat\nTesting foo\n\u221a | OK F W S | Context\nError in x[method] : attempt to apply non-function\n\n== Results =====================================================================\nDuration: 0.1 s\nOK:       0\nFailed:   4\nWarnings: 1\nSkipped:  0\n```\nRunning testtjat::test_dir(\"tests/\")\n```\n\ntestthat::test_dir(\"tests/\")\n\u221a | OK F W S | Context\n== testthat results  ===========================================================\nOK: 2 SKIPPED: 0 FAILED: 0\n\n== Results =====================================================================\nDuration: 0.1 s\nOK:       0\nFailed:   0\nWarnings: 0\nSkipped:  0\n```\nEnvironement\n```\n\nsessionInfo()\nR version 3.4.3 (2017-11-30)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows >= 8 x64 (build 9200)\n\nMatrix products: default\nlocale:\n[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252    LC_MONETARY=French_France.1252 LC_NUMERIC=C                \n[5] LC_TIME=French_France.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] foo_0.0.0.9000 testthat_2.0.0\nloaded via a namespace (and not attached):\n [1] Rcpp_0.12.15     roxygen2_6.0.1   rprojroot_1.3-2  crayon_1.3.4     assertthat_0.2.0 digest_0.6.14    withr_2.1.1      commonmark_1.4\n [9] R6_2.2.2         backports_1.1.2  magrittr_1.5     cli_1.0.0        rlang_0.1.6      stringi_1.1.6    rstudioapi_0.7   xml2_1.1.1    \n[17] desc_1.1.1       devtools_1.13.4  tools_3.4.3      stringr_1.2.0    yaml_2.1.16      compiler_3.4.3   memoise_1.1.0 \n```\n. I got back to testthat v1.0.2 and it is working well.\nI guess this issue appeared when testthat was updated to v2.0.0. ",
    "theGreatWhiteShark": "Unfortunately not. \nI also can reproduce the error in the docker image locally. So it's not an issue of the GitLab runner.\nIn the image I took a vanilla Ubuntu 16.04 system (without X) and installed all packages required to compile R-3.4.0 from source. Are there any additional dependencies for the devtools package I might have missed?. Okay, I took a deeper look at it. In the end it was neither an issue of GitLab nor Docker.\nThe download of the package worked just fine. But the extraction didn't worked, since unzip wasn't installed in the Docker image before compiling R. Since it couldn't be linked against is, getOptions( \"unzip\" ) in devtools:::my_unzip returned an empty string, causing devtools::system_check to fail. . Alright, done.. ",
    "MarcHiggins": "Thanks Jim, that worked. . ",
    "gilbertocamara": "Dear Hadley and RStudio team:\nI found what the problem was. Instead of \n%\\VignetteEngine{knitr::knitr}\nit should have been written \n%\\VignetteEngine{knitr::rmarkdown}\nSorry for disturbing you. In any case, the RStudio documentation could be a bit improved on this matter.. Dear Jenny\nMany thanks!!\nGilberto.\nOn Fri, 22 Dec 2017 at 17:24 Jennifer (Jenny) Bryan \nnotifications@github.com wrote:\n\nFor the future, usethis::use_vignette() is a handy function to initiate a\nnew vignette and it gets all this fiddly stuff set up for you.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hadley/devtools/issues/1679#issuecomment-353660607,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AFxyDcG3_Kk-fjWpXZPfhJWUU-xc0gR2ks5tDAHzgaJpZM4RLFr4\n.\n-- \nProf. Dr. Dr. h.c. Gilberto Camara\nNational Institute for Space Research, INPE, Brazil\nhttp://www.dpi.inpe.br/gilberto\n. \n",
    "htso": "Any update on this issue. Have exactly the same error. \n\nsessionInfo()\nR version 3.4.4 (2018-03-15)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 14.04.5 LTS\n\nMatrix products: default\nBLAS: /usr/lib/atlas-base/atlas/libblas.so.3.0\nLAPACK: /usr/lib/lapack/liblapack.so.3.0\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C            \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8  \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8 \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C               \n [9] LC_ADDRESS=C               LC_TELEPHONE=C          \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods\n[7] base     \nother attached packages:\n[1] PBO_0.1.0       gtools_3.8.1    devtools_1.13.6\nloaded via a namespace (and not attached):\n [1] httr_1.3.1     compiler_3.4.4 R6_2.2.2       tools_3.4.4 \n [5] withr_2.1.2    curl_3.2       yaml_2.2.0     memoise_1.1.0 \n [9] git2r_0.23.0   digest_0.6.16 . ",
    "SymbolixAU": "Thanks. I think that's clearer now. . ",
    "dtelad11": "My bad, the solution was to pull from trunk branch, not master. Sorry for false alarm!. ",
    "SamGG": "For those who may come here, the solution is\nlibrary(devtools)\ninstall_github(\"RGLab/flowCore\",ref='trunk'). ",
    "vtmacox": "I am also having the same issues on my Windows machine.  I have tried running R through the R CMD as an administrator and still get the same error.  I've even changed the temp directory which doesn't fix the issue.  Additionally, this issue seems to extend to any package I try to install and build the vignette.. I've changed TMPDIR and I still get the same error.. ",
    "DocOfi": "Hi,\nI'm still getting the same error.  Is there anything you can advise me to do?. Thank you for your kind reply.  from the package help page: Documentation for package \u2018devtools\u2019 version 1.13.3.9000. Thanks!\n I also tried installing ggplot2 from github and got this error.  Just in case you can make something of it.\n\ndevtools::install_github('hadley/ggplot2')\nDownloading GitHub repo hadley/ggplot2@master\nfrom URL https://api.github.com/repos/hadley/ggplot2/zipball/master\nInstalling ggplot2\nDownloading GitHub repo r-lib/cli@master\nfrom URL https://api.github.com/repos/r-lib/cli/zipball/master\nInstalling cli\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nDownloading GitHub repo r-lib/ansistrings@master\nfrom URL https://api.github.com/repos/r-lib/ansistrings/zipball/master\nInstalling ansistrings\nDownloading GitHub repo r-lib/cli@master\nfrom URL https://api.github.com/repos/r-lib/cli/zipball/master\nSkipping cli, it is already being installed.\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nDownloading GitHub repo MangoTheCat/rematch2@master\nfrom URL https://api.github.com/repos/MangoTheCat/rematch2/zipball/master\nInstalling rematch2\nDownloading GitHub repo r-lib/cli@master\nfrom URL https://api.github.com/repos/r-lib/cli/zipball/master\nSkipping cli, it is already being installed.\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nRunning command C:/PROGRA~1/R/R-34~1.1/bin/x64/Rcmd.exe \nArguments:\nINSTALL\nC:/Users/user/AppData/Local/Temp/RtmpMPTQpC/devtools9e832831acd/MangoTheCat-rematch2-180fb61\n--library=C:/Users/user/Documents/R/win-library/3.4\n--install-tests\n\n\ninstalling source package 'rematch2' ...\n R\n inst\n tests\n preparing package for lazy loading\n** help\n installing help indices\n* building package indices\n testing if installed package can be loaded\n arch - i386\n arch - x64\n\nDONE (rematch2)\nRunning command C:/PROGRA~1/R/R-34~1.1/bin/x64/Rcmd.exe \nArguments:\nINSTALL\nC:/Users/user/AppData/Local/Temp/RtmpMPTQpC/devtools9e839db49a1/r-lib-ansistrings-f27619b\n--library=C:/Users/user/Documents/R/win-library/3.4\n--install-tests\n\n\ninstalling source package 'ansistrings' ...\n** libs\n\n\n*** arch - i386\nc:/Rtools/mingw_32/bin/gcc  -I\"C:/PROGRA~1/R/R-34~1.1/include\" -DNDEBUG     -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O3 -Wall  -std=gnu99 -mtune=core2 -c map.c -o map.o\nc:/Rtools/mingw_32/bin/gcc -shared -s -static-libgcc -o ansistrings.dll tmp.def map.o -Ld:/Compiler/gcc-4.9.3/local330/lib/i386 -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/PROGRA~1/R/R-34~1.1/bin/i386 -lR\ninstalling to C:/Users/user/Documents/R/win-library/3.4/ansistrings/libs/i386\n arch - x64\nc:/Rtools/mingw_64/bin/gcc  -I\"C:/PROGRA~1/R/R-34~1.1/include\" -DNDEBUG     -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O2 -Wall  -std=gnu99 -mtune=core2 -c map.c -o map.o\nc:/Rtools/mingw_64/bin/gcc -shared -s -static-libgcc -o ansistrings.dll tmp.def map.o -Ld:/Compiler/gcc-4.9.3/local330/lib/x64 -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/PROGRA~1/R/R-34~1.1/bin/x64 -lR\ninstalling to C:/Users/user/Documents/R/win-library/3.4/ansistrings/libs/x64\n* R\n inst\n tests\n preparing package for lazy loading\n* help\n installing help indices\n* building package indices\n testing if installed package can be loaded\n arch - i386\n arch - x64\n DONE (ansistrings)\nDownloading GitHub repo r-lib/progress@master\nfrom URL https://api.github.com/repos/r-lib/progress/zipball/master\nInstalling progress\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nRunning command C:/PROGRA~1/R/R-34~1.1/bin/x64/Rcmd.exe \nArguments:\nINSTALL\nC:/Users/user/AppData/Local/Temp/RtmpMPTQpC/devtools9e8452658d4/r-lib-progress-97f2c4e\n--library=C:/Users/user/Documents/R/win-library/3.4\n--install-tests\n\ninstalling source package 'progress' ...\n R\n inst\n tests\n preparing package for lazy loading\n** help\n installing help indices\n* building package indices\n testing if installed package can be loaded\n arch - i386\n arch - x64\n\nDONE (progress)\nRunning command C:/PROGRA~1/R/R-34~1.1/bin/x64/Rcmd.exe \nArguments:\nINSTALL\nC:/Users/user/AppData/Local/Temp/RtmpMPTQpC/devtools9e848105baa/r-lib-cli-1b58269\n--library=C:/Users/user/Documents/R/win-library/3.4\n--install-tests\n\n\ninstalling source package 'cli' ...\n R\n tests\n preparing package for lazy loading\n help\n installing help indices\n copying figures\n building package indices\n testing if installed package can be loaded\n arch - i386\n arch - x64\n\n\nDONE (cli)\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nInstallation failed: install_packages(package_name, repos = remote$repos, type = remote$pkg_type,      dependencies = NA, ..., quiet = quiet, out_dir = out_dir,      skip_if_log_exists = skip_if_log_exists) : formal argument \"repos\" matched by multiple actual arguments\nDownloading GitHub repo tidyverse/rlang@master\nfrom URL https://api.github.com/repos/tidyverse/rlang/zipball/master\nInstalling rlang\nRunning command C:/PROGRA~1/R/R-34~1.1/bin/x64/Rcmd.exe \nArguments:\nINSTALL\nC:/Users/user/AppData/Local/Temp/RtmpMPTQpC/devtools9e86fe93697/r-lib-rlang-c6747f9\n--library=C:/Users/user/Documents/R/win-library/3.4\n--install-tests\n\n\ninstalling source package 'rlang' ...\n** libs\n\n\n arch - i386\nc:/Rtools/mingw_32/bin/gcc  -I\"C:/PROGRA~1/R/R-34~1.1/include\" -DNDEBUG -I./lib/    -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O3 -Wall  -std=gnu99 -mtune=core2 -c capture.c -o capture.o\nc:/Rtools/mingw_32/bin/gcc  -I\"C:/PROGRA~1/R/R-34~1.1/include\" -DNDEBUG -I./lib/    -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O3 -Wall  -std=gnu99 -mtune=core2 -c export.c -o export.o\nIn file included from export/init.c:242:0,\n                 from export.c:3:\nexport/../internal/expr-interp.h:11:20: warning: 'uq_names' defined but not used [-Wunused-variable]\n static const char uq_names[UQ_N] = { \"UQ\", \"!!\" };\n                    ^\nexport/../internal/expr-interp.h:12:20: warning: 'uqe_names' defined but not used [-Wunused-variable]\n static const char uqe_names[UQE_N] = { \"UQE\" };\n                    ^\nexport/../internal/expr-interp.h:19:20: warning: 'fixup_ops_names' defined but not used [-Wunused-variable]\n static const char fixup_ops_names[FIXUP_OPS_N] = {\n                    ^\nexport/../internal/expr-interp.h:22:20: warning: 'fixup_unary_ops_names' defined but not used [-Wunused-variable]\n static const char fixup_unary_ops_names[FIXUP_UNARY_OPS_N] = {\n                    ^\nc:/Rtools/mingw_32/bin/gcc  -I\"C:/PROGRA~1/R/R-34~1.1/include\" -DNDEBUG -I./lib/    -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O3 -Wall  -std=gnu99 -mtune=core2 -c internal.c -o internal.o\nIn file included from internal/arg.c:2:0,\n                 from internal.c:1:\ninternal/expr-interp.h:11:20: warning: 'uq_names' defined but not used [-Wunused-variable]\n static const char uq_names[UQ_N] = { \"UQ\", \"!!\" };\n                    ^\ninternal/expr-interp.h:19:20: warning: 'fixup_ops_names' defined but not used [-Wunused-variable]\n static const char fixup_ops_names[FIXUP_OPS_N] = {\n                    ^\ninternal/expr-interp.h:22:20: warning: 'fixup_unary_ops_names' defined but not used [-Wunused-variable]\n static const char fixup_unary_ops_names[FIXUP_UNARY_OPS_N] = {\n                    ^\nIn file included from internal.c:4:0:\ninternal/expr-interp.c: In function 'call_interp_impl':\ninternal/expr-interp.c:318:1: warning: control reaches end of non-void function [-Wreturn-type]\n }\n ^\nc:/Rtools/mingw_32/bin/gcc  -I\"C:/PROGRA~1/R/R-34~1.1/include\" -DNDEBUG -I./lib/    -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O3 -Wall  -std=gnu99 -mtune=core2 -c lib.c -o lib.o\nIn file included from lib.c:16:0:\nlib/parse.c: In function 'r_op_as_c_string':\nlib/parse.c:386:1: warning: control reaches end of non-void function [-Wreturn-type]\n }\n ^\nC:\\Rtools\\mingw_32\\bin\\nm.exe: lib.c: File format not recognized\nC:\\Rtools\\mingw_32\\bin\\nm.exe: internal.c: File format not recognized\nC:\\Rtools\\mingw_32\\bin\\nm.exe: export.c: File format not recognized\nc:/Rtools/mingw_32/bin/gcc -shared -s -static-libgcc -o rlang.dll tmp.def capture.o export.o internal.o lib.o -Ld:/Compiler/gcc-4.9.3/local330/lib/i386 -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/PROGRA~1/R/R-34~1.1/bin/i386 -lR\ninstalling to C:/Users/user/Documents/R/win-library/3.4/rlang/libs/i386\n arch - x64\nc:/Rtools/mingw_64/bin/gcc  -I\"C:/PROGRA~1/R/R-34~1.1/include\" -DNDEBUG -I./lib/    -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O2 -Wall  -std=gnu99 -mtune=core2 -c capture.c -o capture.o\nc:/Rtools/mingw_64/bin/gcc  -I\"C:/PROGRA~1/R/R-34~1.1/include\" -DNDEBUG -I./lib/    -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O2 -Wall  -std=gnu99 -mtune=core2 -c export.c -o export.o\nIn file included from export/init.c:242:0,\n                 from export.c:3:\nexport/../internal/expr-interp.h:11:20: warning: 'uq_names' defined but not used [-Wunused-variable]\n static const char uq_names[UQ_N] = { \"UQ\", \"!!\" };\n                    ^\nexport/../internal/expr-interp.h:12:20: warning: 'uqe_names' defined but not used [-Wunused-variable]\n static const char uqe_names[UQE_N] = { \"UQE\" };\n                    ^\nexport/../internal/expr-interp.h:19:20: warning: 'fixup_ops_names' defined but not used [-Wunused-variable]\n static const char fixup_ops_names[FIXUP_OPS_N] = {\n                    ^\nexport/../internal/expr-interp.h:22:20: warning: 'fixup_unary_ops_names' defined but not used [-Wunused-variable]\n static const char fixup_unary_ops_names[FIXUP_UNARY_OPS_N] = {\n                    ^\nc:/Rtools/mingw_64/bin/gcc  -I\"C:/PROGRA~1/R/R-34~1.1/include\" -DNDEBUG -I./lib/    -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O2 -Wall  -std=gnu99 -mtune=core2 -c internal.c -o internal.o\nIn file included from internal/arg.c:2:0,\n                 from internal.c:1:\ninternal/expr-interp.h:11:20: warning: 'uq_names' defined but not used [-Wunused-variable]\n static const char uq_names[UQ_N] = { \"UQ\", \"!!\" };\n                    ^\ninternal/expr-interp.h:19:20: warning: 'fixup_ops_names' defined but not used [-Wunused-variable]\n static const char fixup_ops_names[FIXUP_OPS_N] = {\n                    ^\ninternal/expr-interp.h:22:20: warning: 'fixup_unary_ops_names' defined but not used [-Wunused-variable]\n static const char fixup_unary_ops_names[FIXUP_UNARY_OPS_N] = {\n                    ^\nIn file included from internal.c:4:0:\ninternal/expr-interp.c: In function 'call_interp_impl':\ninternal/expr-interp.c:318:1: warning: control reaches end of non-void function [-Wreturn-type]\n }\n ^\nc:/Rtools/mingw_64/bin/gcc  -I\"C:/PROGRA~1/R/R-34~1.1/include\" -DNDEBUG -I./lib/    -I\"d:/Compiler/gcc-4.9.3/local330/include\"     -O2 -Wall  -std=gnu99 -mtune=core2 -c lib.c -o lib.o\nIn file included from lib.c:16:0:\nlib/parse.c: In function 'r_op_as_c_string':\nlib/parse.c:386:1: warning: control reaches end of non-void function [-Wreturn-type]\n }\n ^\nC:\\Rtools\\mingw_64\\bin\\nm.exe: lib.c: File format not recognized\nC:\\Rtools\\mingw_64\\bin\\nm.exe: internal.c: File format not recognized\nC:\\Rtools\\mingw_64\\bin\\nm.exe: export.c: File format not recognized\nc:/Rtools/mingw_64/bin/gcc -shared -s -static-libgcc -o rlang.dll tmp.def capture.o export.o internal.o lib.o -Ld:/Compiler/gcc-4.9.3/local330/lib/x64 -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/PROGRA~1/R/R-34~1.1/bin/x64 -lR\ninstalling to C:/Users/user/Documents/R/win-library/3.4/rlang/libs/x64\nWarning in file.copy(files, dest, overwrite = TRUE) :\n  problem copying .\\rlang.dll to C:\\Users\\user\\Documents\\R\\win-library\\3.4\\rlang\\libs\\x64\\rlang.dll: Permission denied\n R\n tests\n byte-compile and prepare package for lazy loading\n help\n installing help indices\n copying figures\n building package indices\n testing if installed package can be loaded\n arch - i386\n arch - x64\nError: package or namespace load failed for 'rlang':\n .onLoad failed in loadNamespace() for 'rlang', details:\n  call: dots_list(...)\n  error: object 'rlang_dots_list' not found\nError: loading failed\nExecution halted\nERROR: loading failed for 'x64'\n removing 'C:/Users/user/Documents/R/win-library/3.4/rlang'\n restoring previous 'C:/Users/user/Documents/R/win-library/3.4/rlang'\nWarning in file.copy(lp, dirname(pkgdir), recursive = TRUE, copy.date = TRUE) :\n  problem copying C:\\Users\\user\\Documents\\R\\win-library\\3.4\\00LOCK-r-lib-rlang-c6747f9\\rlang\\libs\\x64\\rlang.dll to C:\\Users\\user\\Documents\\R\\win-library\\3.4\\rlang\\libs\\x64\\rlang.dll: Permission denied\nInstallation failed: run(bin, args = real_cmdargs, stdout_line_callback = real_callback(stdout),      stderr_line_callback = real_callback(stderr), stdout_callback = real_block_callback,      stderr_callback = real_block_callback, echo_cmd = echo, echo = show,      spinner = spinner, error_on_status = fail_on_status, timeout = timeout) : System command error\nRunning command C:/PROGRA~1/R/R-34~1.1/bin/x64/Rcmd.exe \nArguments:\nINSTALL\nC:/Users/user/AppData/Local/Temp/RtmpMPTQpC/devtools9e84d9b5f82/tidyverse-ggplot2-a2dc248\n--library=C:/Users/user/Documents/R/win-library/3.4\n--install-tests\n\ninstalling source package 'ggplot2' ...\n R\n data\n moving datasets to lazyload DB\n* inst\n tests\n** preparing package for lazy loading\nError : 'enexprs' is not an exported object from 'namespace:rlang'\nError : unable to load R code in package 'ggplot2'\nERROR: lazy loading failed for package 'ggplot2'\nremoving 'C:/Users/user/Documents/R/win-library/3.4/ggplot2'\nrestoring previous 'C:/Users/user/Documents/R/win-library/3.4/ggplot2'\nInstallation failed: run(bin, args = real_cmdargs, stdout_line_callback = real_callback(stdout),      stderr_line_callback = real_callback(stderr), stdout_callback = real_block_callback,      stderr_callback = real_block_callback, echo_cmd = echo, echo = show,      spinner = spinner, error_on_status = fail_on_status, timeout = timeout) : System command error. Hi,\nI did as you suggested and was able to successfully install devtools and was able to use install_github.\n\nThanks for your help. . ",
    "sammo3182": "It returns this, @jimhester :\n\"C:\\\\Users\\\\MYNAME_local\\\\AppData\\\\Local\\\\Temp\\\\RtmpWWViOY\"\nAnd you know the Rtmp.... will change everytime I restart Rstudio. . My bad, @jimhester! And yes, there's a space in there: \n\"C:\\\\Users\\\\Yue Hu_local\\\\AppData\\\\Local\\\\Temp\\\\RtmpeOtT92\"\nThat's the problem? Is there a way I can fix it? Thank you!. OMG, it did fix the issue! Thank you so so much, @jimhester!! I was about to reinstall the Windows system---which is always painful and won't solve the problem at all. . ",
    "DiogoFerrari": "Yes, of course. That works. However, I get now the error \" undefined symbol: dpotrf_\". For the record,I am using ubuntu. I have been searching around, it seems a problem with the makevars file name, but I am not using any explicitly.. Ok, I had to generate the folders using RcppArmadillo.package.skeleton(). If I copy the Makevars file generated by that function to the src folder generated by devtools::use_rcpp(), it works. Then, devtools::document() works in the folder generated by devtools. The Makevars contains:\nCXX_STD = CXX11\n\nPKG_CXXFLAGS = $(SHLIB_OPENMP_CXXFLAGS) \nPKG_LIBS = $(SHLIB_OPENMP_CFLAGS) $(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)\n\nI think it give a clue for the solution.. ",
    "msberends": "Ah thanks \ud83d\udc4d . ",
    "paul-buerkner": "Thanks!. That seems to work perfectly! Thank you!. ",
    "jrosen48": "I'll confess that that package on CRAN (above) is mine! Would you be willing to consider a PR for this? I may take some coaching up on it but would be very interested in trying to dive in.\n. (if you think this is an idea worth moving forward). Grr, I just missed this (didn't pay enough attention).. ",
    "mrustl": "You are right that the problem is solved in the latest development version of devtools (r-lib/devtools@3068e65). \nHowever, in the latest CRAN version (1.13.5) the outdated wrong function devtools:::full_svn_url is used (restarted R multiple times):\nfull_svn_url <- function (x) \n{\n    if (!is.null(x$branch)) {\n        url <- file.path(x$url, \"branches\", x$branch)\n    }\n    else {\n        url <- file.path(x$url, \"trunk\")\n    }\n    if (!is.null(x$svn_subdir)) {\n        url <- file.path(url, x$svn_subdir)\n    }\n    url\n}\nBut the problem only occurs in case of devtools::install_svn(\"http://repos_path\") but not in case of  devtools::install_svn(\"https://github.com/r-lib/devtools.git\"). Anyway, in the next release the fix should be hopefully also on CRAN.. Yes the remotes package on CRAN works properly. However, the RStudio \"Build\" button works using the devtools package in the background right?. ",
    "kimyen": "This may be helpful. I printed the value of file.path(libname, pkgname). While running Build & Load, it prints:\n\"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/PythonEmbedInR\"\nand while running devtools::document, it prints:\n\"/Users/kimyentruong/Documents/PythonEmbedInR\". @jimhester Thank you for your response. I tried what you suggested and the problem persists. I will open another issue on roxygen2 repo.\nI think creating document requires reading the .R file, and should not requires loading the entire package. While in my package, loading the package requires loading the dynamic library, this will fail for call to load hook from the source code directory. And calling these functions from the installed directory (where I can find the .so file) would not include the source code (.R files). . ",
    "nsgrantham": "I have been experiencing the same error, as have others:\n - https://github.com/RevolutionAnalytics/RRO/issues/37\n- https://github.com/sammo3182/interplot/issues/25\n- https://github.com/r-lib/devtools/issues/406\nThe proposed solutions from these issues is to set options(unzip = \"internal\") before installing from github:\nr\nlibrary(devtools)\noptions(unzip = \"internal\")\ndevtools::install_github(\"tidyverse/dplyr\")\nor to run sudo apt-get install unzip. However, this alone did not solve my problem. \nAfter a little more digging, the problem arises from the fact that, in my case, the conda-provided R install (conda install -c r r-base) sets TAR=/bin/gtar within R (Sys.getenv[\"TAR\"]) which does not exist on a vanilla Ubuntu 16.04 install (it should be TAR=/bin/tar according to https://github.com/r-lib/devtools/issues/379). \nThe following worked for me:\n```\nsudo apt-get install unzip\nexport TAR=/bin/tar\nrun R code here\n```\nInstead of export TAR=/bin/tar you could also create a symlink with sudo ln -s /bin/tar /bin/gtar, but exporting the environmental variable is preferred.\n. ",
    "rvernica": "I ran into the same issue and it was indeed https://github.com/conda-forge/r-devtools-feedstock/issues/4 It would be nice for devtools to give a better error message than just error in running command.. ",
    "ashiklom": "My apologies -- I see this was fixed in the GitHub version of devtools. Here are the relevant linke of pkgload: https://github.com/r-lib/pkgload/blob/master/R/dev-help.r#L25-L45\nClosing this issue.. ",
    "cklunch": "Thanks for the reply! It's good to know it's at least possible. I think this would be a really useful addition to the package, if the community is comfortable with it.\n. ",
    "llrs": "How would it handle reinstalling a package from the same IP? Who would store the data? How would it handle the GDPR law?\nPS:\nWhat would be your opinion on #rstats devtools tracking package installations for github (and other) remotes?They would be anonymized download counts per package and could be disabled by setting an environment variable. (Suggested by https://t.co/02U9crxbsm)\u2014 Jim Hester (@jimhester_) 17 de julio de 2018\n. ",
    "cbail": "Thank you very much- and sorry that I couldn't figure this out on my own!. ",
    "jefshe": "Sorry this is a bug in the R source code.\nin the .write_description function, ind is undefined:\nhttps://github.com/wch/r-source/blame/tags/R-3-4-4/src/library/tools/R/utils.R#L1769\ndue to this commit:\nhttps://github.com/wch/r-source/commit/7c13143e79c9b9c52a923623089349a14c8e6a20. My solution was just to downgrade my version of R. I raised the issue with the R developers and it has now been fixed. ",
    "lcgodoy": "Did you solve this problem ? I'm having the same issue. ",
    "kytolav": "In case someone faces the same issue and cannot upgrade or downgrade R (happened to me on an administered server when trying to install package https://github.com/raivokolde/seqlm), there is a workaround.\nThere is probably a non-latin1 character in the library's DESCRIPTION file that seems to cause the crash. In case of timelyportfolio/d3vennR my guess is that it's the \"\u00e9\" on line \"S\u00e9bastien\", \"Loisel\".\nYou can git clone a local copy of the repository and edit the DESCRIPTION file inside it by removing the offending character, and then install the package on R command line using devtools::install(<path_to_locally_cloned_edited_repo>).. ",
    "djm158": "Tried installing devtools from github via:\nR\ndevtools::install_github(\"hadley/devtools\")\nThis seems to have resolved this issue but now I'm getting this error message:\nInstallation failed: curl::curl_fetch_memory(url, handle = handle) : Protocol \"ssh\" not supported or disabled in libcurl\nsh\ncurl --version\noutputs:\ncurl 7.55.1 (x86_64-conda_cos6-linux-gnu) libcurl/7.55.1 OpenSSL/1.0.2l zlib/1.2.11 libssh2/1.8.0\nRelease-Date: 2017-08-14\nProtocols: dict file ftp ftps gopher http https imap imaps pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp\nFeatures: AsynchDNS IPv6 Largefile NTLM NTLM_WB SSL libz TLS-SRP UnixSockets HTTPS-proxy\n~~It does appear to in fact install the package regardless of this error though:~~\nIf I manually uninstall the Remotes dependencies, the install will fail.. edit: I rebuilt curl from source with libssh2 support.\nOutput of curl::curl_version() from an R session:\ncurl::curl_version()\n$version\n[1] \"7.59.0\"\n$ssl_version\n[1] \"OpenSSL/1.0.2g\"\n$libz_version\n[1] \"1.2.8\"\n$libssh_version\n[1] \"libssh2/1.8.0\"\n$libidn_version\n[1] NA\n$host\n[1] \"x86_64-pc-linux-gnu\"\n$protocols\n [1] \"dict\"   \"file\"   \"ftp\"    \"ftps\"   \"gopher\" \"http\"   \"https\"  \"imap\"\n [9] \"imaps\"  \"pop3\"   \"pop3s\"  \"rtsp\"   \"scp\"    \"sftp\"   \"smb\"    \"smbs\"\n[17] \"smtp\"   \"smtps\"  \"telnet\" \"tftp\"\n$ipv6\n[1] TRUE\n$http2\n[1] FALSE\n$idn\n[1] FALSE. Apologies for the string of somewhat unrelated issues/comments. I've realized that https://github.com/r-lib/devtools/issues/1740#issuecomment-377617504 was an issue with a malformed url in a Remotes dependency. \nhttps://github.com/r-lib/devtools/issues/1740#issue-307682013 seems to be in issue for for devtools <= 1.13.5 which is resolved by installing devtools from master of this repository.. ",
    "gzagatti": "Thanks, using devtools::install_local() solves the issue. I can install the package every time I\u2019m testing a particular function that expects it to be installed and I can thus develop efficiently. Also I didn\u2019t know about devtools::dev_mode(). I have yet to try it out.. ",
    "maelle": "Could I do a PR for this and #1754 at the same time? \ud83d\udc7c . Cool if both are welcome, will prepare them next week and separately. \u263a. I'll work on the other PR once I know how this one should look like (adding a reminder for codemeta.json should be quite similar \ud83d\ude00 ). Oh cool! Then I'll close this and my PR \ud83d\ude00 . Just a few code lines that I promise to maintain when needed \ud83d\ude09. Oh nice! Are there some docs so that I might stop bothering you? I'm wondering how to add several questions \ud83d\udc7c . Fantastic, thanks!. I'm not sure why some Travis builds fail, I don't think the three failing tests are related to this PR? \ud83e\udd14 . Useless cf https://github.com/r-lib/devtools/issues/1753#issuecomment-379812939. What happens now in write_codemeta when called inside a package project\n\n\nRbuildignore codemeta.json\n\n\nAdds pre-commit git hook\n\n\nMessage suggesting adding the release question (which is a bit superfluous given there's a git hook). \n\n\nWe're actually working on a codemetar CRAN release for yesterday :joy: (release failed, we'll try again today). \nDoes it make sense to suggest this release question if you're going to add it to devtools? If you add it and someone has the question inside their code they'll get asked the same question twice upon devtools::release unless the phrasing is the same and devtools only asks unique questions?. cc @cboettig. ",
    "damianooldoni": "Thanks, @jimhester. \nIndeed, it works!. ",
    "ms609": "Thank you for spotting this.  A lot of frustration for the sake of a comma!. ",
    "courtiol": "That would be great, thank you!. ",
    "EricMarcon": "It seems that devtools:::version_info$3.5 is missing.\nAlso, devtools:::version_info$3.4$version_max is \"3.4.99\" so Rtools 3.5 cannot be used with R 3.4.4..\nIt seems to be the same issue as pkgbuild issue #38 but devtools has not been updated yet.\n. Unfortunately, it does not work on Windows:  devtools::install_github(\"r-lib/pkgbuild\") fails because the CRAN version of devtools does not accept either R 3.5 nor Rtools 3.5 to compile it.\nWe need a binary of pkgbuild on CRAN first to allow using Rtools.\nI went back to R 3.4.4 and Rtools 3.4 until pkgbuild is on CRAN.. ",
    "krshedd": "Thanks for the workaround Jack, much appreciated. This allowed be to be able to use devtools::install_github to download other R packages from GitHub that require Rtools to build them.\nHere is the code just in case anyone else has this issue. \ninstall.packages(\"pkgbuild\")  # pkgbuild is not available (for R version 3.5.0)\ninstall.packages(\"devtools\")  # make sure you have the latest version from CRAN\nlibrary(devtools)  # load package\ndevtools::install_github(\"r-lib/pkgbuild\")  # install updated version of pkgbuild from GitHub\nlibrary(pkgbuild)  # load package\nfind_rtools()  # should be TRUE, assuming you have Rtools 3.5\nI'll leave this issue open for now since this workaround doesn't really close the underlying issue.. ",
    "aparpara": "This workaround works for me:\nlibrary(devtools)\nassignInNamespace(\"version_info\", c(devtools:::version_info, list(\"3.5\" = list(version_min = \"3.3.0\", version_max = \"99.99.99\", path = \"bin\"))), \"devtools\")\nfind_rtools() # is TRUE now\n. ",
    "urwa": "Windows 10 x64\nI was getting the same error while installing rPython package.\nI followed the workaround code by krshedd and got find_rtools() is TRUE now.  \nThe problem is when I try to install rPython using install(\"C:/Users/urwa/Downloads/rPython\")\nand I am back with the same error\n\nWARNING: Rtools is required to build R packages, but no version of Rtools compatible with R 3.5.0 was found. (Only the following incompatible version(s) of Rtools were found:3.5)\nPlease download and install the appropriate version of Rtools from http://cran.r-project.org/bin/windows/Rtools/.\nError: Could not find build tools necessary to build rPython. \n",
    "rjrich": "@wch: Thanks for the tip about installing the development version of devtools! This enabled me to install the development version of the \"philentropy\" package in Windows 10 ver 1709. Thanks also to @aparpara for the initial workaround.. ",
    "bshor": "When I tried this I'm getting errors for loading any other package...\nError: package or namespace load failed for \u2018haven\u2019 in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\n there is no package called \u2018Rcpp\u2019\nHow do I reverse this? My R installation is screwed (for now).... ",
    "guilhermefrias23": "Thank you! It worked really well!. ",
    "majusus": "@krshedd ..thank you this work around works even for the updated versions of R and Rtools.. (Y). ",
    "luckygoh": "Hi, i followed the workaround as mentioned previously but still failed to install the xcms package via github.\n\nlibrary(devtools)\nlibrary(pkgbuild)\n\nAttaching package: \u2018pkgbuild\u2019\nThe following objects are masked from \u2018package:devtools\u2019:\nbuild, clean_dll, compile_dll, compiler_flags, find_rtools, has_devel, setup_rtools,\nwith_debug\n\n\nfind_rtools()\n[1] TRUE\ndevtools::install_github(\"sneumann/xcms\")\nDownloading GitHub repo sneumann/xcms@master\nfrom URL https://api.github.com/repos/sneumann/xcms/zipball/master\nWARNING: Rtools is required to build R packages, but no version of Rtools compatible with R 3.5.1 was found. (Only the following incompatible version(s) of Rtools were found:3.5)\n\nPlease download and install the appropriate version of Rtools from http://cran.r-project.org/bin/windows/Rtools/.\nInstalling xcms\n\"C:/PROGRA~1/R/R-35 ~1.1/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD  \\\n  INSTALL  \\\n  \"C:/Users/UM/AppData/Local/Temp/RtmpIPsMnn/devtools2a98569359a7/sneumann-xcms-f1eecf6\"  \\\n  --library=\"C:/Users/UM/Documents/R/win-library/3.5\" --install-tests \ninstalling source package 'xcms' ...\nlibs\nWarning in system(cmd) : 'make' not found\nERROR: compilation failed for package 'xcms'\n removing 'C:/Users/UM/Documents/R/win-library/3.5/xcms'\n* restoring previous 'C:/Users/UMSBIOTECH/Documents/R/win-library/3.5/xcms'\nWarning in file.copy(lp, dirname(pkgdir), recursive = TRUE, copy.date = TRUE) :\n  problem copying C:\\Users\\UM\\Documents\\R\\win-library\\3.5\\00LOCK-sneumann-xcms-f1eecf6\\xcms\\libs\\x64\\xcms.dll to C:\\Users\\UM\\Documents\\R\\win-library\\3.5\\xcms\\libs\\x64\\xcms.dll: Permission denied\nIn R CMD INSTALL\nInstallation failed: Command failed (1). Hi,\nthe workaround seems like not working for me. or there is something i did wrong.\nI used the code below as mentioned by previously and get a TRUE.\nbut the error still occurs.\n`\n\nfind_rtools()\n[1] TRUE\ndevtools::install_github(\"sneumann/xcms\")\nDownloading GitHub repo sneumann/xcms@master\nfrom URL https://api.github.com/repos/sneumann/xcms/zipball/master\nWARNING: Rtools is required to build R packages, but no version of Rtools compatible with R 3.5.1 was found. (Only the following incompatible version(s) of Rtools were found:3.5)\n\nPlease download and install the appropriate version of Rtools from http://cran.r-project.org/bin/windows/Rtools/.\nInstalling xcms\n\"C:/PROGRA~ 1/R/R-35~ 1.1/bin/x64/R\" --no-site-file --no-environ --no-save --no-restore --quiet CMD  \\\n  INSTALL  \\\n  \"C:/Users/UM/AppData/Local/Temp/Rtmp2LXJjL/devtools26081b46695c/sneumann-xcms-f1eecf6\"  \\\n  --library=\"C:/Users/UM/Documents/R/win-library/3.5\" --install-tests\ninstalling source package 'xcms' ...\n libs\nWarning in system(cmd) : 'make' not found\nERROR: compilation failed for package 'xcms'\nremoving 'C:/Users/UMSBIOTECH/Documents/R/win-library/3.5/xcms'\n*restoring previous 'C:/Users/UMSBIOTECH/Documents/R/win-library/3.5/xcms'\nIn R CMD INSTALL\nInstallation failed: Command failed (1)\n`\n. ",
    "samfranks": "Having trouble installing tweenr because of the RTools problem. I've tried the workarounds from @aparpara and @krshedd. Still getting this error:\n```\n\nfind_rtools()\n[1] TRUE\ndevtools::install_github(\"thomasp85/tweenr\")\nDownloading GitHub repo thomasp85/tweenr@master\nfrom URL https://api.github.com/repos/thomasp85/tweenr/zipball/master\nWARNING: Rtools is required to build R packages, but no version of Rtools compatible with R 3.5.0 was found. (Only the following incompatible version(s) of Rtools were found:3.5)\n\nPlease download and install the appropriate version of Rtools from http://cran.r-project.org/bin/windows/Rtools/.\nInstallation failed: Could not find build tools necessary to build tweenr\n\n\nsessionInfo()\nR version 3.5.0 (2018-04-23)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows >= 8 x64 (build 9200)\n\nMatrix products: default\nlocale:\n[1] LC_COLLATE=English_United Kingdom.1252 \n[2] LC_CTYPE=English_United Kingdom.1252 \n[3] LC_MONETARY=English_United Kingdom.1252\n[4] LC_NUMERIC=C                         \n[5] LC_TIME=English_United Kingdom.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nother attached packages:\n[1] pkgbuild_1.0.0  devtools_1.13.6\nloaded via a namespace (and not attached):\n [1] ps_1.1.0              digest_0.6.16         crayon_1.3.4       \n [4] withr_2.1.2           assertthat_0.2.0      R6_2.2.2           \n [7] git2r_0.23.0          httr_1.3.1            curl_3.2           \n[10] rstudioapi_0.7.0-9002 callr_3.0.0           tools_3.5.0        \n[13] yaml_2.2.0            compiler_3.5.0        processx_3.2.0     \n[16] base64enc_0.1-3       memoise_1.1.0\n```\nAny other ways to install gganimate @thomasp85?. ",
    "ankitgupta124": "Hi, facing trouble with rtools 3.5 on R3.5.1 windows. \nIt shows following message when I use find_rtools()\nError in find_rtools() : could not find function \"find_rtools\"\nPlease help.. ",
    "plnnr": "@jimhester This worked!\n\nCould you try\nr\npkgbuild::with_build_tools(remotes::install_github(\"thomasp85/tweenr\"))\nWith the CRAN versions of pkgbuild and remotes\n\n. ",
    "jamesgriggs": "Hi,\nTrying the workaround with R 3.5.1 to get devtools/Rtools to work as described in this issue, but it doesn't appear to work. Any advice?\n\nlibrary(devtools)\nassignInNamespace(\"version_info\", c(devtools:::version_info, list(\"3.5\" = list(version_min = \"3.3.0\", version_max = \"99.99.99\", path = \"bin\"))), \"devtools\")\n\nError in bindingIsLocked(x, ns) : no binding for \"version_info\"\n\nfind_rtools() \n\nError in find_rtools() : could not find function \"find_rtools\". ",
    "anqelnquyenx": "@jimhester I am having trouble with Rtools. I downloaded the latest version and followed steps 1-3 on your site https://www.r-project.org/nosvn/pandoc/devtools.html but I am still getting the message: Error in write.xlsx(simple.list, file = \"simple_list.xlsx\") : \n  could not find function \"write.xlsx\"\nYour help is greatly appreciated. Thank you.. ",
    "ritwikguhathakurta": "Error in find_rtools() : could not find function \"find_rtools\"\nHow to reslove the issue?? Please help... That works fine with pkgbuild but not with devtools.\nOn Fri, Dec 7, 2018 at 5:09 PM isabelle-fischer notifications@github.com\nwrote:\n\nI have the same problem. I am using R version 3.5.1 and RTools 35. I\ninstalled the devtools Package and loaded it, but I always get this error\nmessage:\nError in find_rtools() : could not find function \"find_rtools\"\nI also tried every suggested workaround (even though they should not be\nnecessary), but nothing works. I'm running out of ideas.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/r-lib/devtools/issues/1772#issuecomment-445203899,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ArkOoyDWSE85HEX17-1WHsmRhJCiJjJJks5u2k_bgaJpZM4Tgr9a\n.\n. Thank you very much for your response..\n\nOn Fri, 7 Dec 2018, 21:27 Jim Hester <notifications@github.com wrote:\n\nfind_rtools() was removed from devtools, it is only in pkgbuild now. If\nyou want to call the function you need to load pkgbuild.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/r-lib/devtools/issues/1772#issuecomment-445276688,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ArkOo7F8CmWIbgxvLRN1N67Lfzr4pj9_ks5u2pAHgaJpZM4Tgr9a\n.\n. I have installed Latest R package 3.5.1 but when I give the command\nfind_rtool () it throws the error. How can I remove this error.\n\nOn Fri, Dec 7, 2018 at 7:11 PM Jim Hester notifications@github.com wrote:\n\nClosed #1941 https://github.com/r-lib/devtools/issues/1941.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/r-lib/devtools/issues/1941#event-2012431874, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ArkOo5jkN2NMRjzDAtPpDBQhq13b418hks5u2myIgaJpZM4ZIUNo\n.\n. \n",
    "isabelle-fischer": "I have the same problem. I am using R version 3.5.1 and RTools 35. I installed the devtools Package and loaded it, but I always get this error message:\nError in find_rtools() : could not find function \"find_rtools\"\nI also tried every suggested workaround (even though they should not be necessary), but nothing works. I'm running out of ideas.\n. Ah, found aother workaround!\nLoaded pkgbuild and then ran find_rTools . Worked perfectly fine!. ",
    "ankursworld": "I have R3.5.1 and Rtools 3.5.0.4. I tried library(pkgbuild), and find_rtools() is coming TRUE. However when I run \"devtools::install_github(\"rstudio/reticulate\", force=TRUE)\", I get the error below. Any suggestions are appreciated!\nWARNING: Rtools is required to build R packages, but no version of Rtools compatible with R 3.5.1 was found. (Only the following incompatible version(s) of Rtools were found:3.5)\nPlease download and install the appropriate version of Rtools from http://cran.r-project.org/bin/windows/Rtools/.\n.....\nWarning in system(cmd) : 'make' not found\nERROR: compilation failed for package 'reticulate'\n* removing 'C:/.../Documents/R/win-library/3.5/reticulate'\nIn R CMD INSTALL\nInstallation failed: Command failed (1)\n. ",
    "proxteus": "\nThanks for the workaround Jack, much appreciated. This allowed be to be able to use devtools::install_github to download other R packages from GitHub that require Rtools to build them.\nHere is the code just in case anyone else has this issue.\ninstall.packages(\"pkgbuild\") # pkgbuild is not available (for R version 3.5.0)\ninstall.packages(\"devtools\") # make sure you have the latest version from CRAN\nlibrary(devtools) # load package\ndevtools::install_github(\"r-lib/pkgbuild\") # install updated version of pkgbuild from GitHub\nlibrary(pkgbuild) # load package\nfind_rtools() # should be TRUE, assuming you have Rtools 3.5\nI'll leave this issue open for now since this workaround doesn't really close the underlying issue.\n\nThank u @krshedd . ",
    "Akansha-Kapoor": "\nto be clear, a workaround is to use library(pkgbuild) with an updated pkgbuild after loading devtools\n\nThank you!! I have been trying to get this done for an hour now, I am new to R and did not understand most of the discussions happening. But this answer was very clear! Thanks a lot. . ",
    "a3guyen": "\nfind_rtools() was removed from devtools, it is only in pkgbuild now. If you want to call the function you need to load pkgbuild.\n\nYeah. Thanks for that. I am new to R but this really help. I use windows 10, R 3.5.2 version so here is what I did:\ninstall.packages(\"devtools\")\nlibrary(devtools)\nfind_rtools() # Error in find_rtools() : could not find function \"find_rtools\"\ninstall.packages(\"pkgbuild\")\nlibrary(pkgbuild)\nfind_rtools()\n[1] TRUE\nSo basically we need to install pkgbuild instead of devtools to get TRUE result from find_rtools() function. ",
    "move[bot]": "This issue was moved by jimhester to r-lib/remotes#144.. This issue was moved by jimhester to r-lib/usethis#402.. This issue was moved by jimhester to r-lib/pkgload#72.. This issue was moved by jimhester to r-lib/pkgload#73.. This issue was moved by jimhester to r-lib/pkgload#75.. This issue was moved by jimhester to r-lib/remotes#211.. This issue was moved by jimhester to r-lib/remotes#213.. This issue was moved by jimhester to r-lib/remotes#220.. ",
    "bgctw": "My use case: I migrated some parts of larger package REddyProc to its own package REddyProcNCDF. The latter lists the former in the DEPENDS field and also used the Remotes field. In the latter package I want always use the most recent version of the former.  I could  make sure myself, that I update the dependencies during development, but I thought, this was the purpose of the Remotes field.\nI would like to use,\n\nOn cran, the most recent cran version of the dependency \nwhile on non-cran (development), the most recent github version of the dependency.\n\nWhat would be the recommended procedure?. ",
    "surmann": "I tested this issue with the same environment (Win 10 instead of Win 7) on a different machine. It worked.\nHere are the three locations of the machine with the issue:\n- c:\\Program Files\\ConEmu\\ConEmu\\wsl\\cygwin1.dll\n- c:\\texlive\\2016\\tlpkg\\asymptote\\cygwin1.dll\n- c:\\Users\\surmann\\Documents\\Programme\\testdisk-7.0\\cygwin1.dll\nThis is the content of PATH.\nSystem:\nC:\\Program Files\\ImageMagick-7.0.7-Q16;C:\\Python36\\Scripts\\;C:\\Python36\\;C:\\Program Files\\ConEmu\\ConEmu\\Scripts;C:\\Program Files\\ConEmu;C:\\Program Files\\ConEmu\\ConEmu;C:\\Program Files\\R\\R-3.5.0\\bin;C:\\Rtools\\bin;C:\\ProgramData\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\Intel\\iCLS Client\\;C:\\Program Files\\Intel\\iCLS Client\\;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\IPT;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\IPT;C:\\texlive\\2016\\bin\\win32;C:\\Program Files (x86)\\MiKTeX 2.9\\miktex\\bin\\;C:\\Users\\surmann\\Documents\\RPackages\\rt\\win;C:\\Program Files (x86)\\GNU\\GnuPG\\pub;C:\\ProgramData\\chocolatey\\bin;C:\\Users\\surmann\\AppData\\Local\\Programs\\Python\\Python35-32\\Scripts\\;C:\\Users\\surmann\\AppData\\Local\\Programs\\Python\\Python35-32\\;C:\\Users\\surmann\\AppData\\Local\\Pandoc\\;C:\\Program Files (x86)\\vim\\vim80;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files\\TortoiseSVN\\bin;%systemroot%\\System32\\WindowsPowerShell\\v1.0\\;%systemroot%\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files\\Git\\cmd;C:\\Strawberry\\c\\bin;C:\\Strawberry\\perl\\site\\bin;C:\\Strawberry\\perl\\bin;C:\\Program Files\\OpenSSH-Win64;C:\\Program Files\\TortoiseGit\\bin\n\nDo you have an idea?. I know. There are two reasons to argue the converse:\n- The PATH variable does not look in subdirectories. wsl as a subdirectory of ConEmu is not browsed.\n- On my other system with a similar (Win 10 instead of Win 7) installation, everything works fine.\nIf you have any ideas, how to tackle this problem, let me know.. Is there a plan to add it one of the other packages?. ",
    "jayMcoder": "Get similar error with quick = TRUE\nError in download.file(url, destfile, method, mode = \"wb\", ...) : \n  unused argument (quick = FALSE)\n@jimhester @amstilp \ndevtools document stays additional parameters in install_version are passed to devtools::install not install.packages()\n``` install_version\nArguments\npackage\npackage name\nversion\nIf the specified version is NULL or the same as the most recent version of the package, this function simply calls install. Otherwise, it looks at the list of archived source tarballs and tries to install an older version instead.\nrepos\ncharacter vector, the base URL(s) of the repositories to use, e.g., the URL of a CRAN mirror such as \"https://cloud.r-project.org\". For more details on supported URL schemes see url.\nCan be NULL to install from local files, directories or URLs: this will be inferred by extension from pkgs if of length one.\ntype\ncharacter, indicating the type of package to download and install. Will be \"source\" except on Windows and some macOS builds: see the section on \u2018Binary packages\u2019 for those.\n...\nOther arguments passed on to install.\nquiet\nlogical: if true, reduce the amount of output.\nLooks to me like an issue. So basically devtools call the download.file function of R util package with additional parameters passed to install_version -> This restricts use of install parameters defined by devtools::install\nR utils package download.file\ndownload.file(url, destfile, method, quiet = FALSE, mode = \"w\",\n              cacheOK = TRUE,\n              extra = getOption(\"download.file.extra\"), ...)\n```. ",
    "statquant": "Many thanks @jimhester for the prompt reply. ",
    "andriuking": "Thanks Jim.\nYou are right. Its a R issue. I managed to solve it with your last alternative: creating a exclusive Windows User for R without any strange character.\nRegards.. ",
    "jonathanbratt": "@hughjonesd \nI found myself wanting to write the same sort of test you refer to. It seems to work if I detach the current package in the base environment and run the call to be tested there. Something like:\ntest_that(\"package routine can be called using ::, without the package being attached\", {\n  expect_silent(\n    local({\n        library(my_package)\n        detach(\"package:my_package\")\n        my_package::my_function()\n        library(my_package)\n    },\n    envir=baseenv()) \n  )\n}). ",
    "LaurentFranckx": "I have installed the devel version of devtools, and I keep on having the same problem with install_local, not just with the actual package I am trying to install, but also with the example from the helpfile. . ",
    "Dripdrop12": "Thanks @jimhester!. Thanks @jimhester! I may try another way because there is a tight web of internals that is a challenge to unpack here.. ",
    "neekro": "It worked. Thanks!. ",
    "stewartli": "I run into the same problem and found many methods suggested. I spent the whole day and finally solved it with the combination of many things and a little bit luck. Here is what I did for future googlers. \n1. install RRTools properly. \nlibrary(devtools)\nfind_rtools()\n2. change the environment\nSys.setenv(PATH = paste(Sys.getenv(\"PATH\"), \"C:/Rtools/bin/\",\n                        \"C:/Rtools/mingw_64/bin\", sep = \";\"))\nSys.setenv(BINPREF = \"C:/Rtools/mingw_64/bin/\")\n3. configure with c++\n.fixdevtools <- function() { httr::set_config( httr::config( ssl_verifypeer = 0L ) ) }\n.fixdevtools()\n4. change temp file\nwrite(\"TMP = C:/tmp\", file=file.path(Sys.getenv('R_USER'), '.Renviron'))\n5. apply Jim Hester's advice\ndevtools::install_github('thomasp85/gganimate', args = \"--no-test-load\")\n6. final result you will get\nDONE (gganimate)\nIn R CMD INSTALL\nReferences;\nhttps://github.com/r-lib/devtools/issues/1772\nhttps://stackoverflow.com/questions/31293325/r-install-github-fails\nhttps://github.com/r-lib/devtools/issues/1810. ",
    "jtfeld": "After hundreds of seamless package installations via \"install and restart\" in R Studio, I installed a windows update the other day and now suddenly I'm getting this error.  I tried all of the fixes from stewartli and the only one that worked was Jim's suggestion to add args = \"--no-test-load\".  Two questions: 1) could someone kindly elaborate on the \"related to whitespace on windows\" explanation?  2) I know I can use Project Options > Build Tools to add \"--no-test-load\" to the Build and Reload options, but what does the test load accomplish when installing a package?  I'm running windows 10 64 bit, R 3.5.2, RStudio v1.1.463.. ",
    "dpastoor": "thanks jim!. ",
    "kemin711": "This issue is resolved after pulling in the latest version of htslib. ",
    "ntdef": "Hey @AmundsenJunior thanks for the review. I'm going to look over this PR over the weekend. . ",
    "Xiaojieqiu": "I had the same issue today. Will this issue resolved soon? . ",
    "billdenney": "Wow, that's a horrible bug in base R.  Thanks for letting me know about it.\nIt's not on the CRAN version of pkgload:\n``` r\n\ninstall.packages(\"pkgload\")\nInstalling package into \u2018C:/Users/Bill Denney/Documents/R/win-library/3.4\u2019\n(as \u2018lib\u2019 is unspecified)\ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/pkgload_1.0.0.zip'\nContent type 'application/zip' length 101899 bytes (99 KB)\ndownloaded 99 KB\n\npackage \u2018pkgload\u2019 successfully unpacked and MD5 sums checked\nThe downloaded binary packages are in\n    C:\\Users\\Bill Denney\\AppData\\Local\\Temp\\RtmpKIwds9\\downloaded_packages\n\ndevtools::load_all(\"c:/git/pknca/\")\nError: Can't find 'c:\\git\\pknca\\'.\ndevtools::load_all(\"c:/git/pknca\")\nLoading PKNCA\n```\n\nI also installed the GitHub version of pkgload, and got the same result.. ",
    "JohnMount": "That was fast.  Thanks!!!\nJust a note: I have a vague memory that devtools::test() may or may not have a similar non-isolation issue. It didn't cause me trouble, so I didn't look into it further.. ",
    "ifellows": "Just a note on this. I now have to have an extra step in my workflow where I have to manually copy the doc directory to inst/doc. In many packages they take some time to run and prebuilt vignettes are a good thing. Plus I point people to the vignettes on github as part of the documentation (see for example https://github.com/statnet/lolog), so having them prebuilt and up-to-date is important. Not a huge deal, but definitely not an expected change.\nI can't say that I understand the rational either. I've never run vignette(vignName) while developing a package, so that didn't seem like a pressing issue (at least for me). I would have thought it would be more important to put the files where CRAN expects them.\n. ",
    "crossxwill": "Thank you. Unfortunately, my company won't allow me to install non-CRAN packages. I'll assume it's fixed and wait for the next CRAN release. Do you know approximately when is the next CRAN release?. ",
    "KallyopeBio": "I've posted the same issue on the github repo for testthat. OK. I will do so now. Please note that I observe this crash on Linux (specifically, Ubuntu 16.04). Here is the session info:\nsession_info.txt\nI invoked the session_info() function after the first call to test(.) but before the second call to test(.), which then caused the R session to crash\n. I can also e-mail you a tar.gz file with the core dump and my R binary if it helps. I cannot attach it here because the file size exceeds 10 MB. I confirm that's precisely the backtrace from the crash as it occurs on my machine, as well. . I'm open to incorporating a workaround into my package. If I set that compile flag in the makefile for my package, will that resolve the problem?. I just tested the above workaround: I included the -fno-gnu-unique flag during the compilation of my package. It does indeed fix the crash. I can run test(.) an arbitrary number of times in a row, with no problem. . ",
    "anhqle": "I could no longer reproduce this error because I nuked my R package folders and switched packrat for development.\nThanks a lot for your prompt reply! I'll close this issue for now and will re-open if I run into it again. Sorry for opening an unhelpful issue :(. ",
    "dashaub": "FYI, this is broken for install_gitlab() too, e.g.\n```\n\ndevtools::install_gitlab(\"dashaub/forecast\")\nDownloading GitLab repo dashaub/forecast@master\nfrom URL https://www.gitlab.com/dashaub/forecast/repository/archive.zip?ref=master\nInstalling forecast\nError in stop(github_error(req)) : \n  This endpoint requires you to be authenticated. (401)\n```\n\n```\n\ntraceback()\n17: stop(github_error(req))\n16: github_response(req)\n15: github_POST(\"graphql\", body = jsonlite::toJSON(auto_unbox = TRUE, \n        list(query = query, variables = list(org = username, repo = repo, \n            ref = ref))))\n14: github_sha(username = remote$username, repo = remote$repo, host = remote$host, \n        ref = remote$ref, pat = remote$auth_token)\n13: remote_sha.github_remote(X[[i]], ...)\n12: FUN(X[[i]], ...)\n11: vapply(remote, remote_sha, character(1))\n10: package_deps(deps, repos = repos, type = type)\n9: rbind(cran_deps, remote_deps)\n8: filter_duplicate_deps(package_deps(deps, repos = repos, type = type), \n       installing$remote_deps %||% remote_deps(pkg))\n7: dev_package_deps(pkg, repos = repos, dependencies = dependencies, \n       type = type)\n6: install_deps(pkg, dependencies = initial_deps, upgrade = upgrade_dependencies, \n       threads = threads, force_deps = force_deps, quiet = quiet, \n       ..., out_dir = out_dir, skip_if_log_exists = skip_if_log_exists)\n5: install(source, ..., quiet = quiet, metadata = metadata, out_dir = out_dir, \n       skip_if_log_exists = skip_if_log_exists, repos = repos, type = type, \n       dependencies = dependencies)\n4: FUN(X[[i]], ...)\n3: vapply(remotes, install_remote, ..., FUN.VALUE = logical(1))\n2: install_remotes(remotes, quiet = quiet, ...)\n1: devtools::install_gitlab(\"dashaub/forecast\")\n```. \n",
    "Xinzhu-Fang": "thanks. ",
    "nholford": "How can anybody think that forcing users to install in the root directory is an acceptable practice? I don't think you should describe the C:\\Rtools directory as the standard directory. It should be described as non-standard and forced on users by bad programming practices.\nDo you think this is a devtools programming error?  Do you know if anybody ever got devtools to work  with Rtools not in C:\\?. ",
    "mattfidler": "Thank you @jimhester .  Hopefully it makes it on CRAN soon. . If you need any more information to make this reproducible, let me know.. https://github.com/nlmixrdevelopment/RxODE/issues/59. Simply deleting the vignette.rds should do the trick.. ",
    "KoichiHashikawa": "yes, I also got the same error as @luckygoh.\nIn my case, find_rtools gave TRUE, but whenever I tried to install packages through GitHub using devtools, it installed other packages (such as Rcpp) and crashed R.. ",
    "BillPetti": "Oops, yes that would help.\nThe latest version is here: BillPetti/baseballr\ntraceback()\n11: .f(.x[[i]], ...)\n10: .Call(map_impl, environment(), \".x\", \".f\", \"list\")\n9: purrr::map(purrr::set_names(fields), ~dcf$get_field(.x))\n8: read.description(desc_path)\n7: read_pkg_description(path)\n6: package_files(path)\n5: parse_package(base_path, env = NULL, registry = registry, global_options = options)\n4: roxygen2::roxygenise(pkg$path, roclets = roclets, load_code = ns_env)\n3: force(code)\n2: withr::with_envvar(r_env_vars(), roxygen2::roxygenise(pkg$path, \n       roclets = roclets, load_code = ns_env))\n1: devtools::document()\nMany thanks.. Sure. I've double checked my local repo matches the GitHub version.\nHere's my session info:\n```\ndevtools::session_info()\nSession info ------------------------------------------------------------\n setting  value                     \n version  R version 3.4.1 (2017-06-30)\n system   x86_64, darwin15.6.0      \n ui       RStudio (1.0.153)         \n language (EN)                      \n collate  en_US.UTF-8               \n tz        \n date     2018-08-30                  \nPackages ----------------------------------------------------------------\n package      * version    date       source                          \n acepack        1.4.1      2016-10-29 CRAN (R 3.4.0)                  \n assertthat     0.2.0      2017-04-11 CRAN (R 3.4.0)                  \n backports      1.1.0      2017-05-22 CRAN (R 3.4.0)                  \n base         * 3.4.1      2017-07-07 local                           \n base64enc      0.1-3      2015-07-28 CRAN (R 3.4.0)                  \n baseballr    * 0.3.4.9002        local                           \n bindr          0.1.1      2018-03-13 cran (@0.1.1)                   \n bindrcpp       0.2.2      2018-03-29 cran (@0.2.2)                   \n bitops         1.0-6      2013-08-17 CRAN (R 3.4.0)                  \n broom          0.4.5      2018-07-03 cran (@0.4.5)                   \n checkmate      1.8.3      2017-07-03 CRAN (R 3.4.1)                  \n cluster        2.0.7-1    2018-04-09 CRAN (R 3.4.4)                  \n colorspace     1.3-2      2016-12-14 CRAN (R 3.4.0)                  \n commonmark     1.4        2017-09-01 CRAN (R 3.4.1)                  \n compiler       3.4.1      2017-07-07 local                           \n crayon         1.3.4      2018-08-30 Github (r-lib/crayon@3e751fb)   \n curl           3.2        2018-03-28 cran (@3.2)                     \n data.table     1.11.4     2018-05-27 cran (@1.11.4)                  \n datasets     * 3.4.1      2017-07-07 local                           \n desc           1.1.1      2017-08-03 CRAN (R 3.4.1)                  \n devtools     * 1.13.6     2018-06-27 CRAN (R 3.4.4)                  \n digest         0.6.16     2018-08-22 cran (@0.6.16)                  \n dplyr          0.7.6      2018-06-29 cran (@0.7.6)                   \n foreign        0.8-69     2017-06-22 CRAN (R 3.4.1)                  \n Formula        1.2-3      2018-05-03 cran (@1.2-3)                   \n ggplot2        3.0.0      2018-07-03 CRAN (R 3.4.4)                  \n glue           1.3.0      2018-07-17 cran (@1.3.0)                   \n graphics     * 3.4.1      2017-07-07 local                           \n grDevices    * 3.4.1      2017-07-07 local                           \n grid           3.4.1      2017-07-07 local                           \n gridExtra      2.3        2017-09-09 cran (@2.3)                     \n gtable         0.2.0      2016-02-26 CRAN (R 3.4.0)                  \n hexbin         1.27.2     2018-01-15 cran (@1.27.2)                  \n highcharter    0.5.0      2017-01-17 CRAN (R 3.4.0)                  \n Hmisc          4.1-1      2018-01-03 cran (@4.1-1)                   \n hms            0.4.2      2018-03-10 cran (@0.4.2)                   \n htmlTable      1.12       2018-05-26 CRAN (R 3.4.4)                  \n htmltools      0.3.6      2017-04-28 CRAN (R 3.4.0)                  \n htmlwidgets    0.9        2017-07-10 CRAN (R 3.4.1)                  \n httr           1.3.1      2017-08-20 CRAN (R 3.4.1)                  \n igraph         1.1.2      2017-07-21 CRAN (R 3.4.1)                  \n jsonlite       1.5        2017-06-01 CRAN (R 3.4.0)                  \n knitr          1.20       2018-02-20 CRAN (R 3.4.3)                  \n lattice        0.20-35    2017-03-25 CRAN (R 3.4.1)                  \n latticeExtra   0.6-28     2016-02-09 CRAN (R 3.4.0)                  \n lazyeval       0.2.1      2017-10-29 cran (@0.2.1)                   \n lubridate      1.7.4      2018-04-11 cran (@1.7.4)                   \n magrittr       1.5        2014-11-22 CRAN (R 3.4.0)                  \n MASS           7.3-47     2017-02-26 CRAN (R 3.4.1)                  \n Matrix         1.2-11     2017-08-16 CRAN (R 3.4.1)                  \n memoise        1.1.0      2017-04-21 CRAN (R 3.4.0)                  \n methods      * 3.4.1      2017-07-07 local                           \n mgcv           1.8-19     2017-08-29 CRAN (R 3.4.1)                  \n mnormt         1.5-5      2016-10-15 CRAN (R 3.4.0)                  \n munsell        0.5.0      2018-06-12 cran (@0.5.0)                   \n nlme           3.1-131    2017-02-06 CRAN (R 3.4.1)                  \n nnet           7.3-12     2016-02-02 CRAN (R 3.4.1)                  \n parallel       3.4.1      2017-07-07 local                           \n pbapply        1.3-4      2018-01-10 cran (@1.3-4)                   \n pillar         1.1.0.9000 2018-02-24 Github (hadley/pillar@25931cf)  \n pitchRx        1.8.4      2018-05-28 Github (cpsievert/pitchRx@fe6c45f)\n pkgconfig      2.0.1      2017-03-21 CRAN (R 3.4.0)                  \n plyr           1.8.4      2016-06-08 CRAN (R 3.4.0)                  \n psych          1.8.4      2018-05-06 cran (@1.8.4)                   \n purrr          0.2.5      2018-05-29 cran (@0.2.5)                   \n quantmod       0.4-10     2017-06-20 CRAN (R 3.4.1)                  \n R6             2.2.2      2017-06-17 CRAN (R 3.4.0)                  \n RColorBrewer   1.1-2      2014-12-07 CRAN (R 3.4.0)                  \n Rcpp           0.12.18    2018-07-23 cran (@0.12.18)                 \n RCurl          1.95-4.8   2016-03-01 CRAN (R 3.4.0)                  \n readr          1.1.1      2017-05-16 CRAN (R 3.4.0)                  \n reldist        1.6-6      2016-10-09 CRAN (R 3.4.0)                  \n reshape2       1.4.3      2017-12-11 cran (@1.4.3)                   \n rlang          0.2.2      2018-08-16 cran (@0.2.2)                   \n rlist          0.4.6.1    2016-04-04 CRAN (R 3.4.0)                  \n roxygen2       6.1.0      2018-07-27 CRAN (R 3.4.4)                  \n rpart          4.1-11     2017-03-13 CRAN (R 3.4.1)                  \n rprojroot      1.2        2017-01-16 CRAN (R 3.4.0)                  \n rstudioapi     0.7        2017-09-07 cran (@0.7)                     \n rvest          0.3.2      2016-06-17 CRAN (R 3.4.0)                  \n scales         1.0.0      2018-08-09 cran (@1.0.0)                   \n splines        3.4.1      2017-07-07 local                           \n stats        * 3.4.1      2017-07-07 local                           \n stringi        1.2.4      2018-07-20 cran (@1.2.4)                   \n stringr        1.3.1      2018-05-10 cran (@1.3.1)                   \n survival       2.41-3     2017-04-04 CRAN (R 3.4.1)                  \n testthat       2.0.0.9000 2018-08-30 Github (r-lib/testthat@8216ebe) \n tibble         1.4.2      2018-01-22 cran (@1.4.2)                   \n tidyr          0.8.1      2018-05-18 cran (@0.8.1)                   \n tidyselect     0.2.4      2018-02-26 cran (@0.2.4)                   \n tools          3.4.1      2017-07-07 local                           \n TTR            0.23-2     2017-07-11 CRAN (R 3.4.1)                  \n utils        * 3.4.1      2017-07-07 local                           \n withr          2.1.2      2018-03-15 cran (@2.1.2)                   \n XML            3.98-1.15  2018-08-10 CRAN (R 3.4.4)                  \n xml2           1.2.0      2018-01-24 cran (@1.2.0)                   \n XML2R          0.0.6      2014-03-10 CRAN (R 3.4.0)                  \n xts            0.10-0     2017-07-07 CRAN (R 3.4.1)                  \n zoo            1.8-0      2017-04-12 CRAN (R 3.4.0)  . Well, this makes two of us. Updated to R 3.5.1 this morning and no longer receive the error. Documentation builds with no problem.. ",
    "Yue-Jiang": "I just had the same issue with my package too, but it appears to be fixed by updating from R 3.4.1 to the current R 3.5.1.. ",
    "Deleetdk": "Also worked for me (Mint 18, previous R 3.4.x).. ",
    "layik": "Thanks @jimhester & @gaborcsardi noted.. ",
    "YanpingGuo312": "Hi, Jim, thanks for your reply. How can I change the libPaths to local drive?. ",
    "wolski": "Dear Jim,\nThank you a lot. That indeed solves the problem. Have a great Day.\nregards\nWitek. Dear Jim,\nI did some further testing.\nI implemented that change and \nchild_docs <- system.file(\"ParametrizedReportsChild\",child_docs,package = \"SRMService\")\nupdated the DESCRIPTION\nbut executing\ndevtools::clean_vignettes()\ndevtools::build()\nIs still crashing with:\nError in eval(x, envir = envir) : object 'child_docs' not found\nWarning in readLines(if (is.character(input2)) { :\n  cannot open file './child_docs': No such file or directory\nQuitting from lines 387-388 (./child_docs) \nError in readLines(if (is.character(input2)) { : \n  cannot open the connection\nERROR: installing vignettes failed\nwhile \ndevtools::clean_vignettes()\ndevtools::build_vignettes()\ndevtools::build()\nbuilds with no problem.\nI did test it on two systems.\nMicrosoft R Open 3.5.1\nThe enhanced R distribution from Microsoft\nMicrosoft packages Copyright (C) 2018 Microsoft Corporation\nAnd:\nR version 3.4.4 (2018-03-15) -- \"Someone to Lean On\"\nCopyright (C) 2018 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\nBoth systems have exactly the same behavior.\nKind regards\nWitek. ",
    "jiaqitony": "This is my path: \n/Library/Frameworks/Python.framework/Versions/2.7/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin\nand the veirsion of devtool is 1.13.6\n. clang++. /usr/bin/clang++. I am running this within RStudio.. function (action) \n{\n    if (identical(.Platform$pkgType, \"mac.binary.mavericks\")) {\n        .Call(\"rs_canBuildCpp\")\n    }\n    else {\n        if (!.Call(\"rs_canBuildCpp\")) {\n            .rs.installBuildTools(action)\n            FALSE\n        }\n        else {\n            TRUE\n        }\n    }\n}\n<environment: 0x105997220>\nversion: 1.1.456. A window that asks me to install command line tools on this website: https://www.cnet.com/how-to/install-command-line-developer-tools-in-os-x/.\nI have followed the instruction and installed xcode before.. I am still on High Sierra.\nThis is what is returned.\nApple LLVM version 10.0.0 (clang-1000.10.43.1)\nTarget: x86_64-apple-darwin17.7.0\nThread model: posix\nInstalledDir: /Applications/Xcode-beta.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin. ",
    "EDYAC": "options(buildtools.check = function(action) TRUE)\nthis seem to fix it?. ",
    "Fazendaaa": "Thanks, @jimhester . Thanks, @jimhester :). It works just fine, thanks :). ",
    "mikldk": "@jimhester : Thanks! It seems like your suggestion simply corresponds to Rcpp::Function system_file(\"system.file\"); (Rcpp Function).\nThanks heaps for both \"answers\"!. ",
    "akubisch": "Great, thank you! Now I need to find out why github does not inform me about updates.... ",
    "SanVerhavert": "This issue appears to be solved in the development version on github. I forgot about that option. My apologies.\nLove the new output by the way!. ",
    "Paxanator": "Thanks @jimhester ! Is there a planned maintenance release in the future?. ",
    "adamMaier": "I fixed the two depends fields issues. But I was actually getting the same read.dcf error after that. I cut the number of spaces of indenting in the DESCRIPTION to 1 instead of 4, and that seemed to solve the issue.. ",
    "schuemie": "Voting to reopen this issue. I still get this error, but have a perfectly valid DESCRIPTION file (this example package happens to also live on CRAN, where there are no problems). I guess I might solve it by removing some extra spaces, but would hate to have to do that for all my prior Git tags. Code to reproduce the error:\n```r\ndevtools::install_github(\"ohdsi/SqlRender\", ref = \"v1.5.3\")\nError in read.dcf(path) :\nFound continuation line starting '    person(\"Martijn\" ...' at begin of record.\n```\nHere's the DESCRIPTION file at that tag. Session info:\n```r\n\nsessionInfo()\nR version 3.5.1 (2018-07-02)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 7 x64 (build 7601) Service Pack 1\n\nMatrix products: default\nlocale:\n[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252\n[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \nloaded via a namespace (and not attached):\n [1] Rcpp_0.12.17      rstudioapi_0.7    magrittr_1.5      usethis_1.4.0     devtools_2.0.1    pkgload_1.0.2  \n [7] R6_2.2.2          rlang_0.2.1       tools_3.5.1       pkgbuild_1.0.2    sessioninfo_1.1.1 cli_1.0.0      \n[13] withr_2.1.2       remotes_2.0.2     yaml_2.1.19       assertthat_0.2.0  digest_0.6.15     rprojroot_1.3-2\n[19] crayon_1.3.4      processx_3.1.0    callr_2.0.4       fs_1.2.6          curl_3.2          testthat_2.0.0 \n[25] memoise_1.1.0     glue_1.2.0        compiler_3.5.1    desc_1.2.0        backports_1.1.2   prettyunits_1.0.2\n. @jimhester : no comment? This effects quite a lot of users, and seems to be a genuine bug in devtools.. Digging into this, I found this problem has been fixed [here in the `remotes` package](https://github.com/r-lib/remotes/commit/e56a41e1d0cad55cbe7d60b274b99ab7b7a76b5c). Until that makes it into CRAN, you can update remotes to the right point usingr\ndevtools::install_github(\"r-lib/remotes\", ref = \"e56a41e1d0cad55cbe7d60b274b99ab7b7a76b5c\")\n```. ",
    "eaurele": "Same issue here, with a well-formed DESCRIPTION file (\"ThinkR-open/shinytemplate\"). Cloning and doing remotes::install_local() works though.\n```r\n\nremotes::install_github(\"Thinkr-open/shinytemplate\")\nError in read.dcf(path) : \n  Found continuation line starting '    R (>= 3.0) ...' at begin of record.\n```\n\nbash\n$ git clone git@github.com:ThinkR-open/shinytemplate.git\n```r\n\nremotes::install_local()\nThese packages have more recent versions available.\nWhich would you like to update?\n\n1:   jsonlite (1.5   -> 1.6  ) [CRAN]\n2:   processx (3.2.0 -> 3.2.1) [CRAN]\n3:   CRAN packages only\n4:   All\n5:   None\nEnter one or more numbers separated by spaces, or an empty line to cancel\n1: 5\n\u221a  checking for file 'C:\\Users\\AureleMorovan\\AppData\\Local\\Temp\\RtmpQLVRJV\\file38d4531863f1\\shinytemplate/DESCRIPTION'\n-  preparing 'shinytemplate':\n\u221a  checking DESCRIPTION meta-information ... \n-  checking for LF line-endings in source and make files and shell scripts\n-  checking for empty or unneeded directories\n-  building 'shinytemplate_0.0.21.tar.gz'\nInstalling package into \u2018C:/Users/AureleMorovan/Documents/R/win-library/3.5\u2019\n(as \u2018lib\u2019 is unspecified)\n installing source package 'shinytemplate' ...\n R\n inst\n byte-compile and prepare package for lazy loading\n help\n installing help indices\n  converting help for package 'shinytemplate'\n    finding HTML links ... done\n    create_shiny_template                   html\n    get_dependencies                        html\n* building package indices\n testing if installed package can be loaded\n arch - i386\n arch - x64\n DONE (shinytemplate)\nIn R CMD INSTALL\n```\n____\n```r\n\nsessionInfo()\nR version 3.5.1 (2018-07-02)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows >= 8 x64 (build 9200)\n\nMatrix products: default\nlocale:\n[1] LC_COLLATE=English_Netherlands.1252 \n[2] LC_CTYPE=English_Netherlands.1252 \n[3] LC_MONETARY=English_Netherlands.1252\n[4] LC_NUMERIC=C                      \n[5] LC_TIME=English_Netherlands.1252    \nattached base packages:\n[1] stats     graphics  grDevices utils     datasets \n[6] methods   base     \nloaded via a namespace (and not attached):\n [1] ps_1.2.1          prettyunits_1.0.2 withr_2.1.2    \n [4] rprojroot_1.3-2   crayon_1.3.4      assertthat_0.2.0 \n [7] R6_2.3.0          backports_1.1.2   magrittr_1.5   \n[10] debugme_1.1.0     cli_1.0.1         remotes_2.0.2  \n[13] rstudioapi_0.8    callr_3.0.0       tools_3.5.1    \n[16] yaml_2.2.0        compiler_3.5.1    processx_3.2.0 \n[19] base64enc_0.1-3   pkgbuild_1.0.2 \n```\nNote: I used remotes::install_* but same behavior with devtools::. ",
    "pbr6cornell": "I am running into the same issue identified by @schuemie  and @eaurele .  My only recourse was to revert to older version of devtools.  But I dislike that 'solution', as I'd really like to keep up with all of the impressive work that this team is doing.  Can we relax the DESCRIPTION file reader to more gracefully handle spaces?. ",
    "Nelson-Gon": "This seems to be due to indentation. At least that fixed it for me.. ",
    "MrFlick": "OK. Using build=FALSE with devtools 2.0 does install the package without error. Thank you.\nSo it seems if I check the repo out via git outside of R, and run devtools::build() then on the repo, neither 2.0 nor 1.13 produce a working tarball (neither does R CMD build). So that's likely because of the sub-modules? That's very helpful info I can pass on to the maintainer. There must be something different on their machine that allows them to build successfully.. ",
    "BenoitLondon": "thanks!. Ok I had MAKE='make -j' in my .Renviron file which works fine with R base commands and previous devtools versions but apparently new devtools commands conflict with the -j\nsetting MAKE='make' in the .Renviron file make devtools::install work. \nSo the question is how to tell R to compile in parallel without bugging devtools? Thanks for any help. ah thank you Jim :). sorry for the newbie question again but should it be in .Renviron or Makevars?\nAlso I think I went for the MAKE solution because MAKEFLAGS was not getting picked \nsee this post. ok in the .Renviron it works thanks! :). Thanks. ",
    "jonthegeek": "Working on this.. Sigh, I knew that. Too excited to get things done! Fixing it, sorry about that!. @jimhester Actually exported now (tested by running devtools::find_rtools() in console, it isn't clear to me how to set up an automated test for this in particular, though).. ",
    "cimentadaj": "Hmm this is weird, I ran the same thing after a restart and now it works. Thanks anways.. ",
    "briholt100": "did you find a cause and fix for this? . ",
    "PatBall1": "Yes, thanks. The problems was that I didn't have curl properly set up in my path. It worked fine once I had corrected this.. > How did you properly set up the path ? I am having the same problem but don't know how to fix it.\nPlease see the link below. Good luck!\nhttps://develop.zendesk.com/hc/en-us/articles/360001068567-Installing-and-using-cURL#install. ",
    "anitasgiraldo": "How did you properly set  up the path ? I am having the same problem but don't know how to fix it.. ",
    "Maiae": "There seems to be an issue with curl and api.github.com specifically.\nMy workaround was to change the host argument in devtools::install_github like the example below:\nr\ndevtools::install_github(\"snowflakedb/dplyr-snowflakedb\", host = \"https://api.github.com\"). There seems to be an issue with curl and api.github.com specifically.\nMy workaround was to change the host argument in devtools::install_github like the example below:\nr\ndevtools::install_github(\"snowflakedb/dplyr-snowflakedb\", host = \"https://api.github.com\"). ",
    "jjzmajic": "@Maiae 's solution did not work for me, but what I realized is even though I was behind a corporate proxy, and I had export HTTP(S)_PROXY=xyz set, R did not understand it when it was capitalized. So what you want do is add export http(s)_proxy=xyz to your .basrc or wherever, source it, and then start R. Things should work with no issues after that.. ",
    "ArPharazon": "I had the same issue on windows behind corp proxy.\nResolved by setting the http_proxy and https_proxy environment variables.. ",
    "juliasilge": "I'll take this one! Is 1.01 the correct version requirement?. ",
    "russHyde": "Just had a similar thing on ubuntu where R CMD build ...; R CMD check passed on a package that had failed with the check workflow in rstudio.  \nThe rstudio check was indicating that the parameters for a function had not been defined in my roxygen2 annotations; this was happening even after I added @param annotations for that function, after I renamed it (when the name of the initial function still threw an error in check) and after I @noRded the function.  \nI believe that there was some stuff stored in my .Rproj.user that was causing the problem, because after renaming the function - and with the previously named function still throwing the error, but being absent from my R/ directory - the only reference to the previous name of the function was in subdirectories of .Rproj.user.\nAfter running R CMD build/check, the errors in rstudio's check disappeared. (devtools 2.0.1 / roxygen2 6.1.1 / rstudio 1.1.456). ",
    "strengejacke": "But the thing is that this worked well with the previous version of devtools, and now no longer works.. Ok, I will try this. I was a confused because there's now a two-step-action required when using devtools::check_win*() (not on a source tarball) for packages, first to decide if you really want to check and second if the folder should be removed.. ",
    "rsetienne": "Dear Jim,\nAttached is the package that I am trying to check, and below is the \nresult of check:\nCheers, Rampal\n==> devtools::check(args = c('--timings','--as-cran')) Updating secsse \ndocumentation Writing NAMESPACE Loading secsse Registered S3 method \noverwritten by 'dplyr': method from as.data.frame.tbl_df tibble \nRegistered S3 method overwritten by 'geiger': method from \nunique.multiPhylo ape Writing NAMESPACE \n--Building-----------------------------------------secsse--Setting env \nvars: CFLAGS : -Wall -pedantic -fdiagnostics-color=always CXXFLAGS : \n-Wall -pedantic -fdiagnostics-color=always CXX11FLAGS: -Wall -pedantic \n-fdiagnostics-color=always---------------------------------------------------------------vchecking \nfor file 'D:\\data\\Ms\\SecSSE\\secsse/DESCRIPTION'(615ms)-preparing \n'secsse':(1.1s)vchecking DESCRIPTION meta-information... - cleaning \nsrc-installing the package to build vignettes(451ms)vcreating \nvignettes(17s)-cleaning src-checking for LF line-endings in source and \nmake files and shell scripts(414ms)-checking for empty or unneeded \ndirectories-looking to see if a 'data/datalist' file should be \nadded-building \n'secsse_0.1.11.tar.gz'--Checking-----------------------------------------secsse--Setting \nenv vars: R_CHECK_CRAN_INCOMING_USE_ASPELL: TRUE\nR_CHECK_CRAN_INCOMING_REMOTE : FALSE R_CHECK_CRAN_INCOMING : FALSE* \nR_CHECK_FORCE_SUGGESTS : FALSE-- R CMD check \n-----------------------------------------------------------------Warning \nin config_val_to_logical(Sys.getenv(\"R_CHECK_FORCE_SUGGESTS\", : cannot \ncoerce 'FALSE FALSE' to logical -using log directory \n'D:/data/Ms/SecSSE/secsse.Rcheck'- using R Under development (unstable) \n(2018-11-05 r75543)-using platform: x86_64-w64-mingw32 (64-bit)- using \nsession charset: ISO8859-1-using options '--no-manual \n--as-cran'(678ms)vchecking for file 'secsse/DESCRIPTION'- this is \npackage 'secsse' version '0.1.11'- package encoding: UTF-8vchecking \npackage namespace information... -checking package dependencies ...Error \nin if (force_suggests) lsuggests : (3.7s)missing value where TRUE/FALSE \nneeded Execution halted -- R CMD check results \n-------------------------------------- secsse 0.1.11 ----Duration: 5.5s \n0 errors v| 0 warnings v| 0 notes vR CMD check succeeded. Thanks. I would never have guessed that this is the same problem, though :-)\nOn Thu, Nov 8, 2018, 17:20 Jim Hester notifications@github.com wrote:\n\nThis is a duplicate of #1914\nhttps://github.com/r-lib/devtools/issues/1914, see the workarounds in\nthat issue until it is fixed.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/r-lib/devtools/issues/1921#issuecomment-437056502,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ANkzmQOjhMZNGZ3c50LGfKccZG_yHNYjks5utFm4gaJpZM4YUm9P\n.\n. And I guess it isn't the same problem, because it persists even with the workaround check(incoming = NULL).. Dear Jim,\n\nI installed it from GitHub yesterday and still the same error.\nCheers, Rampal\nOn Fri, Nov 9, 2018, 13:46 Jim Hester notifications@github.com wrote:\n\nIt is fixed in the development version of devtools, please try that.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/r-lib/devtools/issues/1921#issuecomment-437349584,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ANkzmdHyKfOxfFRf3nbCvBOpCRlNsxYqks5utXlBgaJpZM4YUm9P\n.\n. \n",
    "kiendang": "Already closed this because I saw 8a3d2c2. But then reopened because I saw the @param upgrade entries haven't been re-generated in doc. I guess because the latest remotes wasn't installed locally when re-documenting?. ",
    "ADometrius": "Also experiencing the same issue:\nversion  R version 3.4.4 (2018-03-15)\n os       Windows 7 x64 SP 1          \n system   i386, mingw32               \n ui       RStudio                     \n language (EN)                        \n collate  English_United States.1252  \n ctype    English_United States.1252  \n tz       America/Chicago             \n date     2019-01-28. ",
    "rluech": "Hm, whatever it was, its fine now, only using roxygen2 now . ",
    "asimumba": "I tried to implement your suggestion, but to no avail. When I run Sys.getenv(\"TAR\")\nthis is the result, [1] \"\". . After setting the Sys.setenv(\"TAR\" = \"internal\") to a directory and then back to internal did the trick. Now I get internal as a result when I run Sys.getenv(\"TAR\"). And the packages can now install.. > I've been having this issue again on the latest version of devtools and Rstudio... do you know why? Running Sys.setenv(\"TAR\" = \"internal\") makes it work, but I have to reset that everytime I start Rstudio.\n\n\nsessionInfo()\nR version 3.5.2 (2018-12-20)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows >= 8 x64 (build 9200)\n\nMatrix products: default\nlocale:\n[1] LC_COLLATE=English_United States.1252 LC_CTYPE=English_United States.1252\n[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C\n[5] LC_TIME=English_United States.1252\nattached base packages:\n[1] stats graphics grDevices utils datasets methods base\nloaded via a namespace (and not attached):\n[1] Rcpp_1.0.0 rstudioapi_0.7 magrittr_1.5 usethis_1.4.0\n[5] devtools_2.0.1 pkgload_1.0.2 debugme_1.1.0 R6_2.3.0\n[9] rlang_0.3.1 tools_3.5.2 pkgbuild_1.0.2 sessioninfo_1.1.1\n[13] cli_1.0.1 withr_2.1.2 remotes_2.0.2.9000 yaml_2.1.19\n[17] assertthat_0.2.0 digest_0.6.18 rprojroot_1.3-2 crayon_1.3.4\n[21] callr_2.0.3 fs_1.2.6 curl_3.2 testthat_2.0.1\n[25] memoise_1.1.0 glue_1.3.0 compiler_3.5.2 desc_1.2.0\n[29] backports_1.1.2 prettyunits_1.0.2\n\n@DataStrategist All you need to do is place this Sys.setenv(\"TAR\" = \"internal\")  in your .Rprofile file so that every time R starts, the code is run.. ",
    "cotp27": "This allowed be to be able to use \n\ndevtools::install_github \n\nto download other R packages from GitHub that require Rtools to build them.\nHere is the code just in case anyone else has this issue.\n\ninstall.packages(\"pkgbuild\") # pkgbuild is not available (for R version 3.5.0)\ninstall.packages(\"devtools\") # make sure you have the latest version from CRAN\nlibrary(devtools) # load package\ndevtools::install_github(\"r-lib/pkgbuild\") # install updated version of pkgbuild from GitHub\nlibrary(pkgbuild) # load package\n<find_rtools() # should be TRUE, assuming you have Rtools 3.5\n\nI'll leave this issue open for now since this workaround doesn't really close the underlying issue.. ",
    "rvlenth": "Update: I found out what happens... It uses pkgbuild::build(), which has code that deletes inst/doc; if in interactive mode, it asks for confirmation. But RStudio's plug-in isn't interactive.\nSo I guess this is really an issue for pkgbuild, not devtools. I still think this is pretty nasty. Is it really necessary to delete the whole inst/doc directory? I'm really feeling like I can't trust devtools anymore.. ",
    "MichaelTuchman": "It's still there.   AT this point, I have fulfilled my obligation to check the existence of the issue in the latest build. Upon further digging, it is my opinion that the issue is likely in the package remotes and not here.  But insofar as it surfaces here, I'll leave it for now. . ",
    "pchabros": "You have to update processx package. That will fix the problem.. ",
    "gohaku": "\nYou have to update processx package. That will fix the problem.\nthank you,the problem was fixed.\n. \n",
    "cells2numbers": "I installed my own package https://github.com/cells2numbers/migrationminer. Installation works but the travis build fails with \nThe downloaded source packages are in\n    \u2018/tmp/RtmpyK0Mm2/downloaded_packages\u2019\n0.96s$ Rscript -e 'deps <- devtools::dev_package_deps(dependencies = NA);devtools::install_deps(dependencies = TRUE);if (!all(deps$package %in% installed.packages())) { message(\"missing: \", paste(setdiff(deps$package, installed.packages()), collapse=\", \")); q(status = 1, save = \"no\")}'\nError in FUN(X[[i]], ...) : \n  Invalid comparison operator in dependency: >= \nCalls: <Anonymous> -> local_package_deps -> lapply -> FUN\nExecution halted\nThe command \"Rscript -e 'deps <- devtools::dev_package_deps(dependencies = NA);devtools::install_deps(dependencies = TRUE);if (!all(deps$package %in% installed.packages())) { message(\"missing: \", paste(setdiff(deps$package, installed.packages()), collapse=\", \")); q(status = 1, save = \"no\")}'\" failed and exited with 1 during .\nYour build has been stopped.\nsee https://travis-ci.org/cells2numbers/migrationminer\nUpdate: local installation works, but installing using devtools::install_github results in the same error\n```\n\ndevtools::install_github(\"cells2numbers/migrationminer\")\nDownloading GitHub repo cells2numbers/migrationminer@master\nError in FUN(X[[i]], ...) : \n  Invalid comparison operator in dependency: >= \n. The issue seems related to devtools 2.0.0 and 2.0.1 (both do not work). After installing devtools 1.9.1 using\ndevtools::install_version(\"devtools\", version = \"1.9.1\")\nI can install my package using\ndevtools::install_github(\"cells2numbers/migrationminer\", force = TRUE)\n```. \n",
    "PauloEduardoCardoso": "it seems to be working properly simply by adding \n' @import here\n' @importFrom dplyr summarise\ninstead of \n' @import(here)\n' @importFrom(dplyr,summarise)\n. ",
    "alexandrosgryparis": "Hi all,\nI have the same problem mentioned above by @mialj1. I try to install the \"tobiasmuetze/ThreeArmedTrials\" package in R, and I get the following error message:\n>devtools::install_github(\"tobiasmuetze/ThreeArmedTrials\")\nDownloading GitHub repo tobiasmuetze/ThreeArmedTrials@master\nError in if (!is_dir(path)) { : missing value where TRUE/FALSE needed \nI tried githubinstall, and it didn't work either:\n> githubinstall(\"ThreeArmedTrials\")\nSuggestion:\n tobiasmuetze/ThreeArmedTrials \nDo you want to install the package (Y/n)?  Y\nInstalling \"ThreeArmedTrials\" package from GitHub, but already installed from CRAN.\nThis package is already installed. Are you sure you want to overwrite it (Y/n)?  Y\nDownloading GitHub repo tobiasmuetze/ThreeArmedTrials@master\nError in if (!is_dir(path)) { : missing value where TRUE/FALSE needed\nIn addition: Warning message:\nIn fread(download_url, sep = \"\\t\", header = FALSE, stringsAsFactors = FALSE,  :\n  Found and resolved improper quoting out-of-sample. First healed line 4848: <<Puriney  honfleuR\nI tried the development version of the remotes package, and got the same issue as well:\n> devtools::install_dev(\"remotes\")\nDownloading GitHub repo r-lib/remotes@master\nError in if (!is_dir(path)) { : missing value where TRUE/FALSE needed\nAny suggestion will be greatly appreciated.\nMy session info:\nR version 3.5.2 (2018-12-20) -- \"Eggshell Igloo\"\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nlocale:\n\"LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252\"\nattached base packages:\n\".GlobalEnv\" \"package:stats\" \"package:graphics\" \"package:grDevices\" \"package:utils\" \"package:datasets\" \"package:methods\" \"Autoloads\" \"package:base\"\nThank you    . ",
    "MathurinD": "I got the same problem when running unit tests for my package.\nThe error is generated by the function 'devtools::load_all(\".\", quiet=TRUE)'.\nTo fix it one has to run 'library(devtools); load_all(\".\")' in an R session and look at what error messages appear (they are suppressed by quiet=TRUE in 'test').\nFor my package the problem came from the fact that I use Rcpp and 'load_all' inspects the C++ code. Recompiling before testing solved the problem.. ",
    "wangt-biotime": "It return:\n``` r\n\nremotes:::download_method()\n[1] \"auto\"\ncapabilities()\n       jpeg         png        tiff       tcltk         X11        aqua    http/ftp     sockets      libxml        fifo      cledit       iconv \n       TRUE        TRUE        TRUE        TRUE       FALSE       FALSE        TRUE        TRUE        TRUE        TRUE        TRUE        TRUE \n        NLS     profmem       cairo         ICU long.double     libcurl \n       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE \n```. \n",
    "kamapu": "still having this problem within my colleagues.... ",
    "simongrund1": "Can confirm this. Fresh install after an update to 3.5.2 on Windows with no other external packages installed besides devtools. The full set of commands run right after the install were:\nr\ninstall.packages(\"devtools\")\ndevtools::install_github(\"stefvanbuuren/mice\")\nThis gave the error:\nError in read.dcf(path) :\n  Found continuation line starting '    email = \"stef. va ...' at begin of record.\nNote that this is a different package. It's also interesting that I was able to run the same command without problem on an older install of R version 3.5.1 (also on Windows).. This solves the problem for me. Specifically, I needed to:\n\nRun devtools::install_github(\"r-lib/remotes\")\nRestart R.\nRun devtools::install_github(\"...\") for the intended package.\n\nDoing this, all packages install as intended. Thanks for the quick feedback!. ",
    "Kota-R": "Thanks jimhester. I have run following commands. \n`> .rs.restartR()\n\nlibrary(devtools)\nhas_devel()`\n\nI thought the last command should return TRUE or FALSE, but it does not return anything. Is there anyway to check if devtools are ready?. ",
    "mkarikom": "\nE and E<- (the assignment form) are two different functions.\nhttps://github.com/cran/igraph/blob/88642b96a3ba8576df72405008c8f5ffea6cefba/NAMESPACE#L106\nversus\nhttps://github.com/cran/igraph/blob/88642b96a3ba8576df72405008c8f5ffea6cefba/NAMESPACE#L96\nAre you sure you are importing both?\n\nHello @jennybc, thanks for the heads up.  I didn't notice that E<- was actually a separate function.   it's It's working after adding E<- to @importFrom igraph.. ",
    "ramiromagno": "See this issue too: https://github.com/klutometis/roxygen/issues/843. ",
    "mjsteinbaugh": "Nice. Thanks @jimhester . ",
    "PrasanthV454": "Facing the same problem here. I reinstalled rtools \nlibrary(pkgbuild)\nlibrary(devtools)\nfind_rtools()\nSuccessfully yielded TRUE. ",
    "GaryMilburn": "are checks complete. ",
    "jmcphers": "Thanks for the tips, I've simplified this. I don't think it's possible for the file lists produced by untar and friends to contain NA entries, although if you think this is possible I can write it such that these are ignored. \n. "
}