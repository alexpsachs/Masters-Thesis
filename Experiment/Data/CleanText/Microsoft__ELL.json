{
    "kmader": "I get further, but still crash at 24%\n```\n[ 24%] Building CXX object libraries/model/CMakeFiles/model.dir/src/CompilableNode.cpp.o\nIn file included from /Users/mader/Dropbox/Informatics/ELL/libraries/model/src/CompilableNode.cpp:9:\nIn file included from /Users/mader/Dropbox/Informatics/ELL/libraries/model/include/CompilableNode.h:11:\n/Users/mader/Dropbox/Informatics/ELL/libraries/model/include/IRModelProfiler.h:15:10: fatal error: \n      'EmitterTypes.h' file not found\ninclude \"EmitterTypes.h\"\n```. ",
    "jacobrosenthal": "I can confirm this as well. I needed these changes:\nhttps://github.com/Jacobrosenthal/ELL/tree/update-mac\nAnd even then I had to remove the javascript bindings generation for a bunch of node/atom shell errors.. Sierra 10.12.5\nIm stuck exactly here as well\nThough Ill note, I had one more snag even getting here\ncompile_darknetReference.sh: line 9: llc: command not found\nApparently on mac with brew, llvm bins are not linked https://github.com/Homebrew/legacy-homebrew/issues/29733\nI had to change line 9 from\nllc -filetype=obj darknetReference.ll\nto \n/usr/local/opt/llvm\\@3.9/bin/llc -filetype=obj darknetReference.ll. The instructions no longer mention sh compile_darknetReference.sh anymore, and whats in the readme works for me now.. Just another user here\ndid you cmake and make _ELL_python from\nhttps://github.com/Microsoft/ELL/tree/master/interfaces\nOn Wed, Jul 5, 2017 at 5:34 PM, ack72tdp notifications@github.com wrote:\n\nI was able to compile and run unit tests successfully now ... and follow\ninstructions\nhttps://github.com/Microsoft/ELL/blob/master/tutorials/\nvision/gettingStarted/README.md\ninstalled\nminiconda,\nOpenCV,\nnumpy\nand downloaded Microsoft Cognitive Toolkit\nBut it seems to fail in this step now ..\nroot@8fa27a83d7dd:~/ELL/build/tutorials/vision/gettingStarted# python\ncntkDemo.py\nCould not find './../../../build/interfaces/python/ELL.py', did you\nfollow the ELL Python Binding build instructions?\nAlso, can't find compile_vggImageNet.sh ... what is ELL Python Binding\nbuild? and how can I get ELL.py file?\nThnaks in advance...\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Microsoft/ELL/issues/38, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAb0dL9I3MWzq1q8bWDxiuzpQzQUnkajks5sLAFvgaJpZM4OO5ha\n.\n. Just another user here. Have you tried the swig directions at\nhttps://github.com/Microsoft/ELL/blob/244273ee64ec9432243a8d0e354d3769b642e502/interfaces/README.md\n\nOn Wed, Jul 5, 2017 at 6:14 PM, ack72tdp notifications@github.com wrote:\n\n-- Using BLAS include path: /usr/include\n-- Using BLAS library: /usr/lib/libblas.so\n-- Using BLAS DLLs:\n-- Found PythonInterp: /root/miniconda3/bin/python (found version \"3.6.1\")\n-- Found PythonLibs: /root/miniconda3/lib/libpython3.6m.so (found version\n\"3.6.1\")\n-- Could NOT find SWIG (missing: SWIG_EXECUTABLE SWIG_DIR) (Required is at\nleast version \"3.0.12\")\nCMake Warning at CMakeLists.txt:85 (message):\nSWIG not found, interfaces and projects that depend on them will not build\nproperly. They are not part of the default make targets, so can be\nskipped. If you want to build interfaces (such as the Python bindings),\nfollow the instructions in INSTALL-XXXXX.md file to install SWIG. Then\ndelete the CMakeCache.txt file from your build directory run the cmake\ncommand again.\n-- Could NOT find SWIG (missing: SWIG_EXECUTABLE SWIG_DIR) (Required is at\nleast version \"3.0.12\")\n-- Could NOT find SWIG (missing: SWIG_EXECUTABLE SWIG_DIR) (Required is at\nleast version \"3.0.12\")\n-- Could NOT find SWIG (missing: SWIG_EXECUTABLE SWIG_DIR) (Required is at\nleast version \"3.0.12\")\n-- Creating wrappers for python\n-- Could NOT find SWIG (missing: SWIG_EXECUTABLE SWIG_DIR) (Required is at\nleast version \"3.0.12\")\n-- Creating wrappers for javascript\n-- Could NOT find SWIG (missing: SWIG_EXECUTABLE SWIG_DIR) (Required is at\nleast version \"3.0.12\")\n-- Creating wrappers for xml\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /root/ELL/build\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Microsoft/ELL/issues/39, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAb0dJe2xJH4z1YNgyQuVnfv9epLqHRFks5sLAq4gaJpZM4OO70T\n.\n. ModuleNotFoundError: No module named 'cv2'\nLooks like you need opencv\n\nThats covered here:\nhttps://github.com/Microsoft/ELL/blob/4d3c0cc6ed13cc7885150ff74b5d3788f3ee36e8/tutorials/vision/gettingStarted/opencv.md\nconda install -c conda-forge opencv\nI actually got stuck here as well (on osx) with this issue:\nImportError: dlopen(/Users/jacobrosenthal/miniconda3/envs/py36/lib/python3.6/site-packages/cv2.cpython-36m-darwin.so, 2): Library not loaded: @rpath/libopenblasp-r0.2.19.dylib\n  Referenced from: /Users/jacobrosenthal/miniconda3/envs/py36/lib/libopencv_hdf.3.2.0.dylib\n  Reason: image not found\neven though i installed openblas per instructions with both brew brew install homebrew/science/openblas and conda conda install openblas=0.2.19\nThis issue said  https://github.com/conda-forge/opencv-feedstock/issues/69\nconda update --all -c conda-forge\nWhich got me up and running with python darknetDemo.py\n. Probably unrelated, but note I didnt do conda install -c conda-forge opencv\nYouve got a different error there you should google \nImportError: libGL.so.1: cannot open shared object file: No such file or directory\n. Care to post your fix for others? Also if this is resolved please close your issue.. ",
    "lovettchris": "Should be fixed now.. This change is incorrect.  The tar zxvf does actually strip the .tar folder extension, and the current http download address is: \"wget http://prdownloads.sourceforge.net/swig/swig-3.0.12.tar.gz\".. Ah, got it, this info has moved to a different readme, I will update it.. This issue is now fixed.. This issue is now fixed.. Weird that 3.7 doesn't work yet on Ubuntu 16 3.5 works fine?  What was the error?. So I think you are running into a gcc version issue, not a cmake version issue.  Can you try the latest bits and see if it works on gcc 5.4 ?  If not you may need to move to gcc 6.4.  I think we should leave the ubuntu setup saying minimum cmake version required is 3.5. Thanks for the pull request, but we'd prefer to leave our setup instructions just pointing the user to https://cmake.org/ so they can follow the instructions there (which keep changing).  For example, latest cmake is now 3.13.  This way is less doc maintenance for us.. already fixed in latest updates.. This issue is now fixed.. This issue is resolved now that python install has been added to the INSTALL-xxx.md files.. This is now fixed.. I chose to do this slightly differently, it now auto-detects which version of VS is installed.  . This has been fixed already in latest updates.. This is now fixed.. This can happen if you have missing prerequisite libraries (openblas, LLVM, etc).  Perhaps openblas is not optional as per the install instructions.. And you got LLVM ?\nsudo apt-get install -y wget\nwget -O - http://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -\nsudo apt-add-repository \"deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-3.9 main\"\nsudo apt-get -y update\nsudo apt-get install -y llvm-3.9-dev. Do you still have this problem on the latest bits?. can you run ctest again with a -VV command line argument and post the verbose output?. closing due to inactivity, please reactivate if you get an update on this, thanks.. This has been fixed already in latest updates.. This is now fixed.. 23ms on CPU is fast for darknet, which model were you using?  When I run this on my Xeon HP Z840:\ndarknet -nogpu classifier predict cfg\\imagenet1k.data darknet.cfg darknet.weights\nI get darknet reporting .21 seconds.  The ELL python tutorial in \"reference\" mode 'darknetDemo.py' gets 12 FPS (0.083 seconds) and the compiled ELL model using gets 17 fps or 0.058 seconds, and this is including the time to read from live video camera.. Try this readme page on opencv.. This has been fixed already in latest updates, and this info has moved to the INSTALL-xxx.md pages.. This is now fixed and the content has moved to INSTALL-Mac.md. cmake --build . --config release --target _ELL_python\n. Well, check that the build/interfaces/python/ELL.py actually exists, along with the \"_ELL.pyd\" native module.  I see you are using Linux so you might need \"make _ELL_python\" command line.  If these files exist and they are refusing to load this can be caused by missing openblas shared library.  But on Linux so long as you did the \"sudo apt-get install -y libopenblas-dev\" it should be there, you will see it in /usr/lib/libopenblas.so.  You could try running \"ldd _ELL.pyd\" to see if there's anything else missing.  Other than that, double checkout our install instructions.\nYou might also be missing \"source activate py36\" to activate your Python 3.6 environment.\nThis is what \"ldd _ELL.so\" shows on my machine:\nhris@clovett14:/mnt/d/temp/ELL/linux/interfaces/python$ ldd _ELL.so\n        linux-vdso.so.1 =>  (0x00007ffff6f56000)\n        libpython3.6m.so.1.0 => /home/chris/miniconda3/lib/libpython3.6m.so.1.0 (0x00007f70492d9000)\n        libLLVM-3.9.so.1 => /usr/lib/x86_64-linux-gnu/libLLVM-3.9.so.1 (0x00007f7046710000)\n        libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f70464e0000)\n        libblas.so.3 => /usr/lib/libblas.so.3 (0x00007f7046270000)\n        libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f7045ee0000)\n        libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f7045bc0000)\n        libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f70459a0000)\n        libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f70455d0000)\n        libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f70453b0000)\n        libutil.so.1 => /lib/x86_64-linux-gnu/libutil.so.1 (0x00007f70451a0000)\n        librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f7044f90000)\n        libffi.so.6 => /usr/lib/x86_64-linux-gnu/libffi.so.6 (0x00007f7044d70000)\n        libedit.so.2 => /usr/lib/x86_64-linux-gnu/libedit.so.2 (0x00007f7044b30000)\n        libtinfo.so.5 => /lib/x86_64-linux-gnu/libtinfo.so.5 (0x00007f7044900000)\n        libz.so.1 => /lib/x86_64-linux-gnu/libz.so.1 (0x00007f70446d0000)\n        /lib64/ld-linux-x86-64.so.2 (0x00007f704ac00000)\n        libopenblas.so.0 => /usr/lib/libopenblas.so.0 (0x00007f7042630000)\n        libbsd.so.0 => /lib/x86_64-linux-gnu/libbsd.so.0 (0x00007f7042400000)\n        libgfortran.so.3 => /usr/lib/x86_64-linux-gnu/libgfortran.so.3 (0x00007f70420c0000)\n        libquadmath.so.0 => /usr/lib/x86_64-linux-gnu/libquadmath.so.0 (0x00007f7041e80000)\n. This is now fixed.. This is now fixed.. I'm glad you got the compiled code working on pi3.  Congrats!\nYes it is not clear from which labels tiny-darknet uses , I had good luck with darknetImageNetLabels.txt.  This is my modelHelper constructor:\nhelper = mh.ModelHelper(sys.argv, \"darknetReference\", [\"yolo.cfg\", \"yolo.weights\"], \"darknetImageNetLabels.txt\", inputHeightAndWidth=(224, 224))\nNote that tiny-yolo is 224x224, not 416x416.  But I think there's a bug in our compiler because the compiled version of this model doesn't work, so I filed a bug on that already.  \n\n. Ah, yes, I think we are using different darknet models then, I'm using tiny.cfg with tiny.weights, as listed on this web page  and that one is 216x216.  You are using tiny-yolo.cfg.  Where did you get that from?  I could only find tiny-yolo-voc.weights on this other web page and that one is 416x416.  I found a bug in our importer with this cfg file (missing if (\"=\" in param): on line 39 of darknet_to_ell.py).  \nThe \"predictions\" output of that model is 13x13x125, which is 21,125 numbers, which is why the labels indices are out of range.  These are not just labels, they are 13x13 sized grids containing a label bitmask and an offset inside each grid so that bounding boxes can be computed along with those labels.  We do not have the python code in the demo yet to parse all this information.\nNote also that we do not yet support the [region] layer, so the above layer output is probably not fully formed anyway.  The region detection also makes these models much larger, which is why we are only using the classification models for now.  Even the tiny-yolo-voc.weights  is twice the size of the darknet.weights that we were using.  . Yeah, ok, that one matches the tiny-yolo-voc.weights that I was using, and it does contain the region layer.  So (1) yes, scrubbing ### solves the problem.  And (2) and (3) support for [region] layers is on our backlog, I'll bring up your request in our meeting tomorrow and see what we can do for prioritizing this request :-) In the meantime if you want to take a crack at it, then all pull requests are welcome :-) . The issue is on our backlog, but it is not at the top of the list, so it will be a couple sprints out.   We have some more pressing work ahead of this.  In the meantime if you want to take a crack at it, then all pull requests are welcome :-)\n. The missing darknetReference.map will cause compile_darknetReference.sh to fail, so that is expected.  That will be fixed when you get your darknetDemo.py to work.  Are you using the same darknet.weights and darknet.cfg listed in the darknet.md readme?\n. is everything good now?. This would imply your camera is not producing images for some reason, see if you can run this little test just to view your camera output:\nimport numpy as np\nimport cv2\ncam = cv2.VideoCapture(0)\nwhile True:\n    ret, frame = cam.read()\n    cv2.imshow('test', frame)\n    if cv2.waitKey(1) & 0xFF == 27:\n        break. no problem.  We should add better error checking in the sample and report a more useful error message if no camera is found. I filed a bug on that.. > ImportError: libmpi_cxx.so.1: cannot open shared object file: No such file or directory\nI wonder if \"sudo apt-get install libopenmpi-dev\" will solve this problem?\nThere's a lot more CNTK Linux instructions if that doesn't work, one would assume the conda cntk python package should have taken care of all these prerequisites, but perhaps it has a bug...\n. This is now fixed.. Sure thing, you don't have to use the python wrappers, you will notice in the generated header file darknetReference_i.h which contains this function:\nvoid darknetReference_predict(float*, float*);\nJust call it with the correct size input and output buffers and you will get your results in C++.  The correct size for these buffers is provided in the same header file via darknetReference_GetInputSize and darknetReference_GetOutputSize.. are you actually using GCC 7.1 on a Pi ? I've never done that.  I've been using GCC 5.4 and 6 and ELL compiles fine using those versions. You'll need LLVM on there too, if it fits.  How did you do that?  I normally build the raspberry pi binaries on my host PC then download just the compiled binaries to the pi for running there.  Then I don't need the full ELL setup on the Pi itself.  This process is described in the tutorials.. Ah, I wasn't clear, the host PC can use LLVM to cross-compile the \"darknetReference.so\" library, this is why we need LLVM, it already has cross-compilation support.  So if you do have LLVM on your host PC then you have everything you need.  Then the \"darknetReference.so\" library is used in a little cmake project to build the final binaries on the Pi itself.  So this way the Pi doesn't need to build all of ELL, just the tutorial.  When you run cmake --build . --config Release --target compiled_darknetReference_pi3 you will notice that it creates the  \"darknetReference.so\" library already targeted for the pi.  You then copy compiled_darknetReference_pi3 to the pi and finish the compile/link there.  If you are using a 64bit arch Linux install on the Pi then you might need to use  compiled_darknetReference_aarch64 instead.. Fixed now.. I opened separate issue about esp32.. We do not, but we do publish times on the models we have published in our gallery. Also, when testing a model it doesn't make sense to ask it to recognize images that it wasn't trained on.  So your test set should be limited to these categories ImageNet 1k categories  and notice these do not include any flowers or kids toys or apples.  So if you remove those from your test set you have 7 and ELL got 5 out of 7.  It is unfortunate it didn't get the bicycle, but it was trained on mountain bikes only.. ELL uses CNTK to do CNN training.  See CNTK Examples: Image/Classification/AlexNet.. ELL uses OpenBlas, so if you can get OpenBlas library for your embedded device then you should be good to go.  Which chipset is it?. Closing due to inactivity, please reopen if you'd like to revisit.. Weird, I know for sure folks have built ELL no problems on OSX, but I see there is some discussion about this on stackoverflow.  I suppose you could try defining CLOCK_REALTIME to 0 like we do on windows.. ELL is a \"cross-compiler\" so you should be able to use ELL to compile a model targeting your Android device, this will produce object code that you can then link into your Android app using C++ to call the \"predict\" method that ELL has compiled into that object code.  The only trick is making sure your wrap.py target parameters match the target android device you are running on.  Usually armv7 I would think.  You will be using these ~/ELL/build/bin/compile options:\nTarget device options\n        --target (-t) [host]              target name  {host | pi0 | pi3 | orangepi0 | pi3_64 | mac | linux | windows | ios | aarch64 | custom}\n        --numBits (-b) [0]                Number of bits for target [0 == auto]\n        --cpu (-cpu) []                   The CPU target for generating code\n        --triple []                       The triple describing the target architecture\n        --datalayout []                   The string describing the target data layout\n        --features []                     A string describing target-specific features to enable or disable (these are LLVM attributes, in the format the llc -mattr option uses). We require Python 3.6, see INSTALL-Windows.md section under Python where we recommend you use Miniconda or Anaconda python environments. \nSo for example, what I do is I use Anaconda, then I create a new environment called py3.6 using conda create -n py36 anaconda python=3.6, then I activate that using \"activate py36\" which gives me a console window that is now setup so that Visual Studio can find Python.h among other things.\nWhen I run the rebuild.cmd script from there and everything should be good.. closing due to inactivity, please reopen if you still have issues, thanks.. great!. It lives here: https://github.com/Microsoft/ELL/tree/master/tools/wrap . Yeah, it is easier to run Wrap.py from where it is and not try and move it.  It uses some \"..\" paths to find other stuff in the repo that it needs.. The trainers in the libraries folder are only there because they are unique to ELL and do not exist elsewhere.  There is no plan for ELL to duplicate CNTK or tensorflow training.  ELL is focused on optimizing the inference side for running trained models on embedded hardware.. Yes, you can still use your laptop. This Tutorial  explains how, especially step 3 and the tutorial on Importing Models  will help you with the CNTK problem above (which looks like you are missing the CNTK Python module).. You may have missed a \"cd ..\" in there somewhere.  The tutorial.py should be in host, not in build, and same for model.py.  You should see a _model.pyd file in build\\Release folder, and model.py loads this, but it will not find it if model.py is in the wrong place.  So I would go back and repeat the tutorial instructions, and look for the \"cd ..\" instructions.. Yes it does, see the tutorial on importing models  for examples.. If by \"frame\" you mean the input image format, the ELL model is expecting the same format RGB that darknet is expecting (not BGR like CNTK and opencv).  This is why our demoHelper.py makes the BGR to RGB conversion optional, so in the darknet case you request pass bgr=false.  This is mentioned in the tutorial at the bottom:\n\nNote: Using a converted Darknet model from pjreddie will require OpenCV input reordered from BGR to RGB. tutorial_helpers.py and tutorialHelpers.h provide helper functions for Python and C++, respectively, that take an argument to reorder the input image from BGR to RGB.\n\nLooking at the tutorial_helpers prepare_image_for_model the argument is named reorder_to_rgb, so in the darknet case you set this to true.\nBut in demoHelper.py it is called \"bgr\" and is an option to DemoHelper, and so in the darknet case you set that to false.  . thanks, fix is on the way.. Thanks, fix is on the way.. Assuming you followed the INSTALL-windows   instructions you should have the openblas library in the external\\OpenBLASLibs.0.2.19.3\\build\\native\\x64\\haswell\\lib.  If that is not there you may have missed this step:\nnuget.exe restore external/packages.config -PackagesDirectory external\nand you then may get additional help from the Path Environment steps at the end of the setup page.\n. ELL itself is fine on Stretch, the only problem is finding a good opencv solution.  You may have noticed we built a custom opencv for Raspberry Pi and published it in our microsoft-ell conda channel.\nStretch updated a lot of things, (GCC 6, and new avcodecs) unfortunately this breaks our existing microsoft-ell opencv package because that build of opencv assumes the Jessie version of libavcodec.so.56, but Stretch is now using libavcodec.so.57.  This would normally not be a problem except this is a built in package included in the Raspbian image and those cannot easily be down leveled, at least I couldn\u2019t find an easy way to do it\u2026nor could I find another apt-get installable package that includes the older version.  \nSo the work around for now if you need opencv on Stretch is to build it yourself.  You can build it on the pi, It takes a long time, but it can be done.  You'll want to build it with this command line to ensure you don't run out of space or memory:\ncmake -DBUILD_SHARED_LIBS=OFF -DBUILD_TESTS=OFF -DBUILD_PERF_TESTS=OFF \\\n    -DPYTHON3_EXECUTABLE=\"/usr/bin/python3.4\" \\\n    -DPYTHON3_LIBRARY=\"/usr/lib/python3.4\" \\\n    -DPYTHON3_INCLUDE_DIR=\"/usr/include/python3.4\" \\\n        -DCMAKE_BUILD_TYPE=\"Release\" -Wno-dev ..\n. You are right, that is an excellent article by Adrian Rosebrock, thanks for the link.  And congratulations for being a motivated developer, so you got opencv working on Stretch with py34 bindings ?. That's great, hey if you are interested, it would be awesome if you published your results on your own conda channel so that we can point ELL customers to your version of OpenCV for Stretch.. awesome!. Wow you have been busy! Fantastic blog.. If using only the CPU to do the job yes.  Darknet's inference takes 1.49 seconds using this imagenet model, whereas the same model compiled by ELL takes 94 milliseconds.\nBut if you compile darknet with GPU then it will be faster than ELL.  ELL does not support targeting GPU as it is designed for small embedded hardware that does not have a big GPU.\nFor example, ELL can run the same darknet model on a raspberry pi 3 in 3.6 seconds.  If you don't care so much about the accuracy of the model you can get simpler models to run much faster on the pi, as shown in the model gallery.. If you follow the Importing Models  tutorial it will show you how to use wrap.py to generate a darknet model from the darknet .cfg and .weights files.  The resulting *.ell file can then be loaded into python using ELL.ELL_Map.  But it is better if you compile the .ell file to code as discussed in Step 3 of the Getting started tutorial. . Awesome applications.  I like Eric-tang's description of the difference between Azure IoT Edge and ELL.  I think of the Azure service as a horizontal solution that pulls everything together and I think of ELL as a building block that could be deployed on IoT devices used in such an end-to-end system.\nWe've definitely run ELL on Dragonboad 410c, so the 820c should be fine.  The 410 is twice as fast as the Raspberry Pi.  Love to see how the 820 performs, so I look forward to your next blog!. Hey, ELL and PX4, my favorite combination :-)   Both the Qualcomm Flight kit and the intel Aero are using the PX4 stack, so either kit is a good choice.  See also my MavLinkCom library which is part of AirSim.  The idea with Airsim is you can test our vision algorithms in a simulator before trying them on a drone :-) . Agreed!  I feel like there is more opportunity to do really amazing stuff with computing right now than there ever has been.. Are you running debug bits perhaps?  The Release build is much quicker.  Also when I switched your code to use the TutorialHelpers  for doing center cropping of the image I was able to get your code to produce correct results.  Release bits detected this elephant in about 0.9 seconds on my HP Z840 desktop machine.\n. Alternatively, if you compile your darknet ELL model instead, using the technique described in this tutorial , then you will not only find it is much easier to compile a C++ application around that it also runs a lot faster.\nSimply include the compiled \"darknet.i.h\" and the \"darknet.obj\" into your project and call the predict darknet_Predict function.  This version runs predict in about 23 milliseconds.\n```cpp\ninclude \"darknet.i.h\"\nvoid test_compiled_ell_model() \n{\n    cv::Mat frame;\nstd::vector<float> predictions;\npredictions.resize(1000);\n\ncvNamedWindow(\"Display\");\nwhile (1)\n{\n    // frame = cvQueryFrame(capture);\n\n    frame = cv::imread(\"d:\\\\temp\\\\elephant.png\");\n    cv::imshow(\"ELL model\", frame);\n\n    std::vector<float> data = TutorialHelpers::PrepareImageForModel(frame, 224, 224, true);\n\n    clock_t start = clock();\n    darknet_Predict(data, predictions);\n    clock_t end = clock();\n    double need_time = (double)((end - start) * 1000 / CLOCKS_PER_SEC);\n    cout << need_time << \"ms :\";\n    auto max = std::max_element(predictions.begin(), predictions.end());\n    auto index = max - predictions.begin();\n    cout << \"  index=\" << index << \"  val=\" << *max << endl;\n    char c = cvWaitKey(33);\n    if (c == 27)  break;\n}\n\n}. You're welcome, glad to hear it works better now.  ELL does not support region detection models, yet..... moved to #120 . We have not done it yet, and the nrf51822 chip on the microbit is very resource constrained (256kb flash and 32 kb RAM), so it would only be able to run a very small model, perhaps a ProtoNN based model might work.  The following compile.exe command line might work:\nELL\\build\\bin\\release\\compile \u2026 --target custom --cpu cortex-m0 \n--triple armv6m-unknown-none-eabi --features +armv6-m,+v6m --numBits 32 \n```\nBut ELL models typically use a lot of floating point, so I would recommend instead you choose a board that has a Cortex-M4f processor at least, like the newer nRF52840 from Nordic.  The following command line builds Cortex-M4F code, making use of the vectorized floating point instructions:\nELL\\build\\bin\\release\\compile \u2026 --target custom --numBits 32 \n--cpu cortex-m4 --triple armv6m-gnueabi --features +vfp4-sp-d16,+soft-float. See also Building an ELL model for ARM Cortex-M4. Yes, underneath wrap.py is a tool called compile (which you will find in your build/bin folder after building ELL).  If you run wrap.py on a model with the \"--verbose\" argument you will see what command line arguments it is passing to compile.  You can then modify those arguments to specify the Cortex-A9 cpu as follows and the special target of \"custom\" meaning, you are providing cpu, triple, and dataLayout.\nD:/git/ELL/ELL/build/bin/release/compile -imap mnist.ell -cfn Predict -cmn mnist --target custom -od . --fuseLinearOps True --blas false --optimize true --triple armv7ve-linux-gnueabihf --cpu cortex-a9 --numBits 32 --dataLayout e-m:e-p:32:32-i64:64-v128:64:128-a:0:32-n32-S64  --objectCode --features \"+neon,-soft-float,+virtualization\" --header\nNote: this is a custom cortex-a7 chip running a 32bit Linux OS.  If your OS is 64 bit you will need --numBits 64 and the dataLayout of \"e-m:e-i64:64-i128:128-n32:64-S128\"\nSee LLVM data-layout.\n. no there isn't. and if you didn't compile ELL in the conda environment, you will need to run \"rebuild.cmd\" to ensure you delete the \"build\" folder, otherwise cmake will not update the make files needed to build the ELL python modules.. Here's a version of the tutorial that works with the new callback interface:\n```cpp\n////////////////////////////////////////////////////////////////////////////////////////////////////\n//\n//  Project:  Embedded Learning Library (ELL)\n//  File:     tutorial.cpp\n//  Authors:  Byron Changuion\n//\n////////////////////////////////////////////////////////////////////////////////////////////////////\ninclude \ninclude \ninclude \ninclude \ninclude \n// Include the model interface file for the compiled ELL model\ninclude \"model.h\"\n// Include helper functions\ninclude \"tutorialHelpers.h\"\nclass Tutorial \n{\npublic:\nTutorial() \n{\n    // Read the category names\n    this->categories = ReadLinesFromFile(\"categories.txt\");\n\n    // Get the model's input shape. We will use this information later to resize images .\n    TensorShape inputShape;\n    model_GetInputShape(0, &inputShape);\n    this->inputShape = inputShape;\n    this->inputSize = model_GetInputSize();\n    printf(\"Input shape=[%d,%d,%d]\\n\", inputShape.rows, inputShape.columns,\n        inputShape.channels);\n\n    TensorShape outputShape;\n    model_GetOutputShape(0, &outputShape);\n    this->outputShape = outputShape;\n    printf(\"Output shape=[%d,%d,%d]\\n\", outputShape.rows, outputShape.columns,\n        outputShape.channels);\n\n    // Create a vector to hold the model's output predictions\n\n    this->outputSize = model_GetOutputSize();\n    this->input.resize(this->inputSize);\n\n\n    this->start = std::chrono::steady_clock::now();\n}\n\nvoid PrepareNextImage(cv::VideoCapture& camera)\n{\n    // Get an image from the camera. (Alternatively, call GetImageFromFile to read from file)\n    cv::Mat image = GetImageFromCamera(camera);\n    this->image = image;\n\n    // Prepare an image for processing\n    // - Resize and center-crop to the required width and height while preserving aspect ratio.\n    // - OpenCV gives the image in BGR order. If needed, re-order the channels to RGB.\n    // - Convert the OpenCV result to a std::vector<float>\n    this->input = tutorialHelpers::PrepareImageForModel(image, this->inputShape.columns,\n        this->inputShape.rows);\n}\n\nint8_t InputCallback(float* buffer)\n{\n    size_t size = this->input.size();\n    assert(size == this->inputSize);\n    ::memcpy(buffer, &this->input[0], this->inputSize * sizeof(float));\n\n    return true;\n}\n\nvoid OutputCallback(float* buffer)\n{\n    this->predictions = std::vector<float>(&buffer[0], &buffer[this->outputSize]);\n}\n\nbool ValidateCategories()\n{\n    return (categories.size() == this->outputSize);\n}\n\nint GetOutputSize() {\n    return this->outputSize;\n}\n\nvoid Step() \n{\n    auto now = std::chrono::steady_clock::now();\n    double ticksFromStart = std::chrono::duration<double>(now - start).count();\n    double ticks = model_GetTicksUntilNextInterval(ticksFromStart);\n    model_Predict(ticks, this->input.data());\n}\n\nbool HasPrediction() \n{\n    return this->predictions.size() > 0;\n}\n\nstd::vector<std::pair<size_t, float>> GetTopN(size_t topN = 5, double threshold = 0.20)\n{\n    return tutorialHelpers::GetTopN(this->predictions, 5);\n}\n\nstd::string GetCategory(int index) \n{\n    return categories[index];\n}\n\ncv::Mat GetImage() \n{\n    return this->image;\n}\n\nprivate:\n    // Read an image from the camera\n    static cv::Mat GetImageFromCamera(cv::VideoCapture& camera)\n    {\n        cv::Mat frame;\n        camera >> frame;\n        return frame;\n    }\n// Read an image from a file\nstatic cv::Mat GetImageFromFile(const std::string& filename)\n{\n    return cv::imread(filename);\n}\n\n// Read a file of strings\nstatic std::vector<std::string> ReadLinesFromFile(const std::string& filename)\n{\n    std::vector<std::string> lines;\n    std::string line;\n\n    std::ifstream file(filename);\n\n    while (std::getline(file, line))\n    {\n        if (line.length() > 0) lines.emplace_back(line);\n    }\n\n    return lines;\n}\n\n\nstd::vector<std::string> categories;\nTensorShape inputShape;\nTensorShape outputShape;\nsize_t inputSize;\nstd::vector<float> input;\ncv::Mat image;\nsize_t outputSize;\nstd::vector<float> predictions;\nstd::chrono::time_point<std::chrono::steady_clock> start;\n\n};\nTutorial tutorial;\nint8_t model_InputCallback(float* buffer)\n{\n    return tutorial.InputCallback(buffer);\n}\nvoid model_OutputCallback(float* buffer)\n{\n    tutorial.OutputCallback(buffer);\n}\nint main(int argc, char** argv)\n{\n    // use video camera 0, change index if necessary.\n    cv::VideoCapture camera(1);\nif (!tutorial.ValidateCategories())\n{\n    printf(\"categories.txt does not contain %d categories\\n\", (int)tutorial.GetOutputSize());\n    return 1;\n}\n\n// Declare a variable to hold the prediction times\nstd::vector<double>  predictionTimes;\ndouble meanTimeToPredict = 0.0;\n\nwhile ((cv::waitKey(1) & 0xFF) == 0xFF)\n{\n    tutorial.PrepareNextImage(camera);\n\n    // Send the image to the compiled model and fill the predictions vector with \n    // scores, measure how long it takes\n    auto begin = std::chrono::steady_clock::now();\n    tutorial.Step();\n    auto end = std::chrono::steady_clock::now();\n\n    if (tutorial.HasPrediction())\n    {\n        // Get the value of the top 5 predictions\n        auto top5 = tutorial.GetTopN(5);\n\n        // Generate header text that represents the top5 predictions\n        std::stringstream headerText;\n        for (auto element : top5)\n        {\n            headerText << \"(\" << std::floor(element.second * 100.0) << \"%) \";\n            headerText << tutorial.GetCategory(element.first) << \"  \";\n        }\n        cv::Mat image = tutorial.GetImage();\n        tutorialHelpers::DrawHeader(image, headerText.str());\n\n        // Generate footer text that represents the mean evaluation time\n        std::stringstream footerText;\n        meanTimeToPredict = std::floor(tutorialHelpers::GetMeanDuration(predictionTimes,\n            std::chrono::duration<double>(end - begin).count()) * 1000);\n        footerText << meanTimeToPredict << \"ms/frame\";\n        tutorialHelpers::DrawFooter(image, footerText.str());\n\n        // Display the image\n        cv::imshow(\"ELL model\", image);\n    }\n}\n\nstd::cout << \"Mean prediction time: \" << meanTimeToPredict << \"ms/frame\" << std::endl;\n\nreturn 0;\n\n}\n. closing due to inactivity. Fix is on the way, it is related to our callback system, if you build a model without source/sink nodes it will not leak.. Thanks for the bug report, I have filed this internally to make sure we take a look and fix it.. Surely this is a misdirected post.  Please find the correct Slicer4 github, thanks.. I've confirmed this crash, we are investigating.... Found the problem, the DataLoader.tcc uses old prototype for callback functions.  The callbacks now take a void* context parameter, the fix will be included in next update.. Can you run this and include the output you see?\npython -c 'import sys; print(sys.version)'\n```\nIf this says python 2.7, then you may need to be using \"python3\" instead of \"python\" in all your ELL commands.. Correct, currently compile generates code using statically allocated buffers, so there are no calls to malloc/free when you call the predict function.  You can actually run our \"compile\" tool with \"--output ir\" or \"assembler\" and look at the code we generate.  We don't throw exceptions either since this is also callable from \"C\" programs.  I don't know if we promise never to change that, but you can see that our CompilableNode  API defines a Compile method that takes an IRFunctionEmitter and that this function emitter is trying to steer Node implementors to implement simple functions, for loops, if statements, vector math, etc.  But there is a \"call\" function and a node could call out to client code and that client code could do whatever (which is true in the \"callback\" model case).  . This is how I built it for miniconda's python 3.4.\nIf you modify the paths to python below to your python 3.5 install then you should get a version that works.  CMake takes a while because it is looking for all sorts of stuff, when it is done you should see a Python3 section in the output that is populated with all the right information.  If the Python3 section is blank, then something went wrong, and you need to fix your python paths until cmake finds it.  Each time cmake fails wipe your build folder so that it starts from scratch.  \nhttps://docs.opencv.org/master/d7/d9f/tutorial_linux_install.html \nhttps://www.pyimagesearch.com/2017/09/04/raspbian-stretch-install-opencv-3-python-on-your-raspberry-pi/\nsudo apt-get install -y build-essential cmake pkg-config\nsudo apt-get install -y libjpeg-dev libtiff5-dev libjasper-dev libpng12-dev libdc1394-22-dev\nsudo apt-get install -y libavcodec-dev libavformat-dev libswscale-dev libv4l-dev\nsudo apt-get install -y libxvidcore-dev libx264-dev\nsudo apt-get install -y libgtk2.0-dev libgtk-3-dev\nsudo apt-get install -y libatlas-base-dev gfortran\nsudo apt-get install -y python3-dev\nconda install jinja2\ncd ~\nwget -O opencv.zip https://github.com/Itseez/opencv/archive/3.3.0.zip\nunzip opencv.zip\ncd opencv-3.3.0\nwget -O opencv_contrib.zip https://github.com/Itseez/opencv_contrib/archive/3.3.0.zip\nunzip opencv_contrib.zip\nmkdir build\ncd build\ncmake -DCMAKE_BUILD_TYPE=RELEASE \\\n-DCMAKE_INSTALL_PREFIX=~/opencv-3.3.0/install \\\n-DOPENCV_EXTRA_MODULES_PATH=../opencv_contrib-3.3.0/modules \\\n-DBUILD_EXAMPLES=OFF \\\n-DBUILD_TESTS=OFF -D BUILD_PERF_TESTS=OFF \\\n-DBUILD_opencv_python2=0 \\\n-DPYTHON2_EXECUTABLE= \\\n-DPYTHON2_INCLUDE_DIR= \\\n-DPYTHON2_LIBRARY= \\\n-DPYTHON2_NUMPY_INCLUDE_DIRS= \\\n-DPYTHON2_PACKAGES_PATH= \\\n-DBUILD_opencv_python3=1 \\\n-DPYTHON3_EXECUTABLE=/home/pi/miniconda3/envs/py34/bin/python3.4 \\\n-DPYTHON3_INCLUDE_DIR=/home/pi/miniconda3/envs/py34/include/python3.4m \\\n-DPYTHON3_LIBRARY=/home/pi/miniconda3/envs/py34/lib/libpython3.4m.so \\\n-DPYTHON3_NUMPY_INCLUDE_DIRS=/home/pi/miniconda3/envs/py34/lib/python3.4/site-packages/numpy/core/include \\\n-DPYTHON3_PACKAGES_PATH=/home/pi/miniconda3/envs/py34/lib/python3.4/site-packages \\\n..\nmake\nsudo make install\npython3 -c \"import cv2; print(cv2.version)\". Thanks for the write up, I'll promote this to our docs and give you credit.  I'm curious about the pip3 upgrade, what problems did you run into without this upgrade?. This is probably caused by our CMake\\OpenBLASSetup.cmake script is not recognizing your CPU id (see lines 100-160).  We only packaged two of the most common Intel CPU types in our OpenBLAS Nuget package (..\\external\\OpenBLASLibs.0.2.19.3\\build\\native\\x64), Haswell and Sandybridge.  Now turns out these also work for a bunch of newer chips, which is what OpenBLASSetup.cmake is doing (for example it maps Broadwell to Haswell).  But when newer and newer chips come out we need to keep updating that mapping... So you can see that whole cmake script is operating on the output of the following registry values:\nreg query HKEY_LOCAL_MACHINE\\Hardware\\Description\\System\\CentralProcessor\\0\nSo if you attach the output of that to this issue we can work from there.... I assume you are following all the instructions in this tutorial ?\nYou should have this directory structure when you are done:\n(ell) d:\\temp\\tutorial>dir /s /b\nd:\\temp\\tutorial\\call_model.py\nd:\\temp\\tutorial\\categories.txt\nd:\\temp\\tutorial\\coffeemug.jpg\nd:\\temp\\tutorial\\host\nd:\\temp\\tutorial\\model.py\nd:\\temp\\tutorial\\tutorial_helpers.py\nd:\\temp\\tutorial\\host\\build\\Release\\_model.exp\nd:\\temp\\tutorial\\host\\build\\Release\\_model.lib\nd:\\temp\\tutorial\\host\\build\\Release\\_model.pyd\nd:\\temp\\tutorial\\host\\CMakeLists.txt\nd:\\temp\\tutorial\\host\\include\nd:\\temp\\tutorial\\host\\model.bc\nd:\\temp\\tutorial\\host\\model.ell\nd:\\temp\\tutorial\\host\\model.i\nd:\\temp\\tutorial\\host\\model.i.h\nd:\\temp\\tutorial\\host\\model.obj\nd:\\temp\\tutorial\\host\\model.opt.bc\nd:\\temp\\tutorial\\host\\modelPYTHON_wrap.cxx\nd:\\temp\\tutorial\\host\\modelPYTHON_wrap.h\nd:\\temp\\tutorial\\host\\OpenBLASSetup.cmake\nd:\\temp\\tutorial\\host\\tcc\nd:\\temp\\tutorial\\host\\include\\CallbackInterface.h\nd:\\temp\\tutorial\\host\\tcc\\CallbackInterface.tcc\n. This also happens if you did add the openblas dll location to your PATH.  See Path Environment in Windows Setup.. We just pushed new bits, can you try again with the latest? Thanks.. Duplicate of https://github.com/Microsoft/ELL/issues/157 which has more discussion.. Thanks Lisa!\n. I added this to the setup instructions, thanks.. All these models should work https://github.com/Microsoft/ELL-models. I see, yes, we still have some work to do to support every layer type that is supported by CNTK.  Thanks for the bug report, I'll make sure we take a look at the pretrained models on the CNTK website.. Yep, sorry about that, we ran up against our bandwidth quota, we are working on a fix, apologies for the inconvenience.\n. This is fixed now.. I believe the retargetTrainer requires at least 2 classes.  If you created only one class for retraining I think the retargetTrainer gets stuck.  It shouldn't matter if you have only a small number of images in each class.. This might indicate a problem with the \"OpenBlas\" version you are using on your laptop, perhaps it doesn't properly match the CPU you have there.  Can you attach the output of \"dxdiag\" so we can check your laptop CPU model ?. Undefined reference to ell::math::Blas::Gemm indicates a link error because the linker cannot find your OpenBlas library.  Looks like you are using Linux, so please double check you followed all the Ubuntu Installation instructions, specifically this line:\nsudo apt-get install -y libopenblas-dev. Or if that doesn't work try and do \"git clean -dfx\" and \"git pull\" to make sure your have a clean enlistment before you build.. You build the ELL git repo on your PC.  This produces a \"compile\" tool which you will find in your build/bin output folder.  This is actually a cross-compiler meaning it can compile code that runs on other platforms, as well as on your PC.  To compile your model to run on Cortex-M4 see this Wiki page for instructions.. Hi, this indicates that the .ell file on the gallery is out of date, and we need to \"reimport\" the .cntk model using the latest ELL bits.  Sometimes we break our ELL file format, sorry about that.  I have filed an internal request to get this done, but in the meantime you can run the cntk importer yourself, like this:\ncurl --location -o pretrained.cntk.zip https://github.com/Microsoft/ELL-models/raw/master/models/ILSVRC2012/dsf_I64x64x3CCMCCMCCMCMCMC1AS/dsf_I64x64x3CCMCCMCCMCMCMC1AS.cntk.zip\nunzip pretrained.cntk.zip\npython %ELL_ROOT%\\tools\\importers\\CNTK\\cntk_import.py dsf_I64x64x3CCMCCMCCMCMCMC1AS.cntk\ncopy dsf_I64x64x3CCMCCMCCMCMCMC1AS.ell pretrained.ell\n. can you zip up and attach the sample training data you are using so I can reproduce the problem?. Yes, thanks for the data, I can reproduce the bug.  Here\u2019s the scoop, the team has been working on improving how Port MemoryLayout is managed throughout the ELL stack, and this is where the bug was introduced.\nIf you sync your git repo back to this commit:\n\uf0d8   git checkout c9e2a268c51e2aef0715eb270f7a38b3741b3a54\nthen rebuild ELL, you will get a version that works properly with the retargeting tutorial.\nWe are working on a fix, but it will take a couple days to get it fully tested and pushed to github.. I think this is now obsolete :-) . Yes indeed, there is a bug in CntkDenseConverter, in cntk_converters.py.   This line:\npython\nif self.activation:\nshould be:\npython\nif self.activation is not None:\nI'll push a fix.. \"Release_model.pyd\" ? I assum you are missing a backslash there and it is \"\\build\\Release_model.pyd\" ?  Can you try this change to call_model.py:\nfrom host import model. Can you make sure you ran \"build.cmd\" ? This will populate your externals folder which contains nuget packages, including one for SWIG, so you should see this:\n(ell) d:\\git\\ELL\\ELL\\external>dir /s /b swig.swg\nd:\\git\\ELL\\ELL\\external\\swigwintools.3.0.12\\tools\\swigwin-3.0.12\\Lib\\swig.swg. I have the same version of OpenBlas and it is working fine:\n```\npackages in environment at /home/pi/miniconda3/envs/py34:\n\nimutils                   0.4.6                     \njpeg                      8d                            0\nlibgfortran               1.0                           0\nlibpng                    1.6.17                        0\nlibtiff                   4.0.2                         1\nnumpy                     1.9.2                    py34_1\nonnx                      1.2.2                     \nopenblas                  0.2.14                        1\nopencv                    3.3.0                np19py34_0\nopenssl                   1.0.1k                        1\npip                       7.1.2                    py34_0\nprotobuf                  3.6.0                     \npyaudio                   0.2.11                    \npython                    3.4.3                         1\nsetuptools                18.1                     py34_0\nsix                       1.11.0                    \nsqlite                    3.8.4.1                       1\nwheel                     0.24.0                   py34_0\nxz                        5.0.5                         0\nzlib                      1.2.8                         0\n```. Ah, but I wonder if the problem is that the default version now for libopenblas-dev is 0.2.19... but then again, I see the right version here: ~/miniconda3/pkgs/openblas-0.2.14-1, so I'm not sure why it is not using that version.... Until we figure out a fix I have posted a Raspbian image here that has a working opencv installed:\nhttps://elldeviceimages.blob.core.windows.net/pi3/readme.htm\nThanks bhakthil, sounds like it is a miniconda conflict, good to know virtualenv works.. There is also a pip installable open cv available here:\nhttps://www.pyimagesearch.com/2018/09/19/pip-install-opencv/\nalso using virtualenv.  We are considering switching to virtualenv anyway.... This should be fixed now, still using miniconda as per our setup instructions, just do this:\nconda install -y -c microsoft-ell/label/stretch opencv\nAnd you will now get 3 packages, including a newer version of openblas:\nopenblas-0.3.6             |                1         7.0 MB\n    numpy-1.9.2                |           py34_1         5.1 MB\n    opencv-3.3.0               |       np19py34_0        33.2 MB. Ah, doc is out of date, sorry.  The new \"void* context\" argument is added to handle the case that you have any \"callbacks\" from the predict function.  The \"context\" argument is now plumbed through to those callbacks.  But for simple predict calls you can simply pass nullptr\" for this argument.  Now you may also notice the tutorial has been updated to use a new ModelWrapper class that is now generated that makes all this stuff (especially callbacks) even easier.. Sound like your approach should work.  This is what our C++ tutorial  is doing, so if this is not working as expected, then we need to check your model, how it was trained, and whether there were any import errors or warnings.  Can you share the model, how it was trained, the model architecture, and output from any \"import\" process you followed? From there we can narrow down what might be the problem here.  Typically what we like to do in debugging a new model from here is compare the ELL \"Compute\" code path on a layer by layer basis with whatever runtime you used to train the model and make sure each layout output matches the expected result.  This technique can find a bug in the import process where some node parameter was not copied over correctly to the ELL model.  Or if the very first layer doesn't match, perhaps the image preprocessing is wrong (e.g. BGR versus RGB, or scaling the numbers to 0,1 versus some models require that you leave then in byte range 0-255, especially if the model already contains a \"scaling\" node that does the conversion to 0-1, etc) all depends on how the model was trained and what the set of nodes are that get properly imported to ELL, etc.. Does the tutorial.cpp code work for you that is included in the  C++ tutorial folder?  I just tried the full tutorial steps using this code and the OpenCV 3.4.3 binaries from sourceforge and when I modify the tutorial.cpp to use this static image like this:\ncpp\ncv::Mat photo = GetImageFromFile(argv[1]);\nI see this output:\n\n. I just tried it an it works fine, can you try again with the latest bits?\n(ell) d:\\Temp\\tutorials\\retarget>%ELL_root%\\build\\bin\\release\\print.exe -imap pretrained.ell --includeNodeId --refineIterations 1\n<id:1528> InputNode<float>(12288)\n<id:1529> ConstantNode<float>()\n<id:1530> ConstantNode<float>()\n<id:1531> BroadcastLinearFunctionNode<float>(1528.output[0:12288], 1529.output[0:3], 1530.output[0:3])\n<id:1532> ConstantNode<float>()\n<id:1533> ConstantNode<float>()\n<id:1534> BroadcastLinearFunctionNode<float>(1531.output[0:12288], 1532.output[0:3], 1533.output[0:0])\n<id:1535> ConstantNode<float>()\n<id:1536> ConstantNode<float>()\n<id:1537> BroadcastLinearFunctionNode<float>(1534.output[0:12288], 1535.output[0:0], 1536.output[0:3])\n<id:1538> ReorderDataNode<float>(1537.output[0:13068])\n<id:1539> UnrolledConvolutionNode<float>(1538.output[0:13068])\n<id:1540> ReorderDataNode<float>(1539.output[0:131072])\n<id:1541> ConstantNode<float>()\n<id:1542> ConstantNode<float>()\n<id:1543> BroadcastLinearFunctionNode<float>(1540.output[0:131072], 1541.output[0:0], 1542.output[0:32])\n<id:1544> BroadcastUnaryFunctionNode<float,ReLUActivationFunction<float>>(1543.output[0:131072])\n<id:1545> ConstantNode<float>()\n<id:1546> ConstantNode<float>()\n<id:1547> BroadcastLinearFunctionNode<float>(1544.output[0:131072], 1545.output[0:32], 1546.output[0:32])\n<id:1548> ConstantNode<float>()\n<id:1549> ConstantNode<float>()\n<id:1550> BroadcastLinearFunctionNode<float>(1547.output[0:131072], 1548.output[0:32], 1549.output[0:0])\n<id:1551> ConstantNode<float>()\n<id:1552> ConstantNode<float>()\n<id:1553> BroadcastLinearFunctionNode<float>(1550.output[0:131072], 1551.output[0:0], 1552.output[0:32])\n<id:1554> ReorderDataNode<float>(1553.output[0:139392])\n<id:1555> UnrolledConvolutionNode<float>(1554.output[0:139392])\n<id:1556> ReorderDataNode<float>(1555.output[0:131072])\n<id:1557> ConstantNode<float>()\n<id:1558> ConstantNode<float>()\n<id:1559> BroadcastLinearFunctionNode<float>(1556.output[0:131072], 1557.output[0:0], 1558.output[0:32])\n<id:1560> BroadcastUnaryFunctionNode<float,ReLUActivationFunction<float>>(1559.output[0:131072])\n<id:1561> PoolingLayerNode<float,MaxPoolingFunction>(1560.output[0:131072])\n    PoolingLayer<float,MaxPoolingFunction>(shape=[64,64,32]->[32,32,32], function=maxpooling, stride=2, size=2)\n<id:1562> ConstantNode<float>()\n<id:1563> ConstantNode<float>()\n<id:1564> BroadcastLinearFunctionNode<float>(1561.output[0:32768], 1562.output[0:32], 1563.output[0:32])\n<id:1565> ConstantNode<float>()\n<id:1566> ConstantNode<float>()\n<id:1567> BroadcastLinearFunctionNode<float>(1564.output[0:32768], 1565.output[0:32], 1566.output[0:0])\n<id:1568> ConstantNode<float>()\n<id:1569> ConstantNode<float>()\n<id:1570> BroadcastLinearFunctionNode<float>(1567.output[0:32768], 1568.output[0:0], 1569.output[0:32])\n<id:1571> ReorderDataNode<float>(1570.output[0:36992])\n<id:1572> UnrolledConvolutionNode<float>(1571.output[0:36992])\n<id:1573> ReorderDataNode<float>(1572.output[0:65536])\n<id:1574> ConstantNode<float>()\n<id:1575> ConstantNode<float>()\n<id:1576> BroadcastLinearFunctionNode<float>(1573.output[0:65536], 1574.output[0:0], 1575.output[0:64])\n<id:1577> BroadcastUnaryFunctionNode<float,ReLUActivationFunction<float>>(1576.output[0:65536])\n<id:1578> ConstantNode<float>()\n<id:1579> ConstantNode<float>()\n<id:1580> BroadcastLinearFunctionNode<float>(1577.output[0:65536], 1578.output[0:64], 1579.output[0:64])\n<id:1581> ConstantNode<float>()\n<id:1582> ConstantNode<float>()\n<id:1583> BroadcastLinearFunctionNode<float>(1580.output[0:65536], 1581.output[0:64], 1582.output[0:0])\n<id:1584> ConstantNode<float>()\n<id:1585> ConstantNode<float>()\n<id:1586> BroadcastLinearFunctionNode<float>(1583.output[0:65536], 1584.output[0:0], 1585.output[0:64])\n<id:1587> ReorderDataNode<float>(1586.output[0:73984])\n<id:1588> UnrolledConvolutionNode<float>(1587.output[0:73984])\n<id:1589> ReorderDataNode<float>(1588.output[0:65536])\n<id:1590> ConstantNode<float>()\n<id:1591> ConstantNode<float>()\n<id:1592> BroadcastLinearFunctionNode<float>(1589.output[0:65536], 1590.output[0:0], 1591.output[0:64])\n<id:1593> BroadcastUnaryFunctionNode<float,ReLUActivationFunction<float>>(1592.output[0:65536])\n<id:1594> PoolingLayerNode<float,MaxPoolingFunction>(1593.output[0:65536])\n    PoolingLayer<float,MaxPoolingFunction>(shape=[32,32,64]->[16,16,64], function=maxpooling, stride=2, size=2)\n<id:1595> ConstantNode<float>()\n<id:1596> ConstantNode<float>()\n<id:1597> BroadcastLinearFunctionNode<float>(1594.output[0:16384], 1595.output[0:64], 1596.output[0:64])\n<id:1598> ConstantNode<float>()\n<id:1599> ConstantNode<float>()\n<id:1600> BroadcastLinearFunctionNode<float>(1597.output[0:16384], 1598.output[0:64], 1599.output[0:0])\n<id:1601> ConstantNode<float>()\n<id:1602> ConstantNode<float>()\n<id:1603> BroadcastLinearFunctionNode<float>(1600.output[0:16384], 1601.output[0:0], 1602.output[0:64])\n<id:1604> ReorderDataNode<float>(1603.output[0:20736])\n<id:1605> UnrolledConvolutionNode<float>(1604.output[0:20736])\n<id:1606> ReorderDataNode<float>(1605.output[0:32768])\n<id:1607> ConstantNode<float>()\n<id:1608> ConstantNode<float>()\n<id:1609> BroadcastLinearFunctionNode<float>(1606.output[0:32768], 1607.output[0:0], 1608.output[0:128])\n<id:1610> BroadcastUnaryFunctionNode<float,ReLUActivationFunction<float>>(1609.output[0:32768])\n<id:1611> ConstantNode<float>()\n<id:1612> ConstantNode<float>()\n<id:1613> BroadcastLinearFunctionNode<float>(1610.output[0:32768], 1611.output[0:128], 1612.output[0:128])\n<id:1614> ConstantNode<float>()\n<id:1615> ConstantNode<float>()\n<id:1616> BroadcastLinearFunctionNode<float>(1613.output[0:32768], 1614.output[0:128], 1615.output[0:0])\n<id:1617> ConstantNode<float>()\n<id:1618> ConstantNode<float>()\n<id:1619> BroadcastLinearFunctionNode<float>(1616.output[0:32768], 1617.output[0:0], 1618.output[0:128])\n<id:1620> ReorderDataNode<float>(1619.output[0:41472])\n<id:1621> UnrolledConvolutionNode<float>(1620.output[0:41472])\n<id:1622> ReorderDataNode<float>(1621.output[0:32768])\n<id:1623> ConstantNode<float>()\n<id:1624> ConstantNode<float>()\n<id:1625> BroadcastLinearFunctionNode<float>(1622.output[0:32768], 1623.output[0:0], 1624.output[0:128])\n<id:1626> BroadcastUnaryFunctionNode<float,ReLUActivationFunction<float>>(1625.output[0:32768])\n<id:1627> PoolingLayerNode<float,MaxPoolingFunction>(1626.output[0:32768])\n    PoolingLayer<float,MaxPoolingFunction>(shape=[16,16,128]->[8,8,128], function=maxpooling, stride=2, size=2)\n<id:1628> ConstantNode<float>()\n<id:1629> ConstantNode<float>()\n<id:1630> BroadcastLinearFunctionNode<float>(1627.output[0:8192], 1628.output[0:128], 1629.output[0:128])\n<id:1631> ConstantNode<float>()\n<id:1632> ConstantNode<float>()\n<id:1633> BroadcastLinearFunctionNode<float>(1630.output[0:8192], 1631.output[0:128], 1632.output[0:0])\n<id:1634> ConstantNode<float>()\n<id:1635> ConstantNode<float>()\n<id:1636> BroadcastLinearFunctionNode<float>(1633.output[0:8192], 1634.output[0:0], 1635.output[0:128])\n<id:1637> ReorderDataNode<float>(1636.output[0:12800])\n<id:1638> UnrolledConvolutionNode<float>(1637.output[0:12800])\n<id:1639> ReorderDataNode<float>(1638.output[0:16384])\n<id:1640> ConstantNode<float>()\n<id:1641> ConstantNode<float>()\n<id:1642> BroadcastLinearFunctionNode<float>(1639.output[0:16384], 1640.output[0:0], 1641.output[0:256])\n<id:1643> BroadcastUnaryFunctionNode<float,ReLUActivationFunction<float>>(1642.output[0:16384])\n<id:1644> PoolingLayerNode<float,MaxPoolingFunction>(1643.output[0:16384])\n    PoolingLayer<float,MaxPoolingFunction>(shape=[8,8,256]->[4,4,256], function=maxpooling, stride=2, size=2)\n<id:1645> ConstantNode<float>()\n<id:1646> ConstantNode<float>()\n<id:1647> BroadcastLinearFunctionNode<float>(1644.output[0:4096], 1645.output[0:256], 1646.output[0:256])\n<id:1648> ConstantNode<float>()\n<id:1649> ConstantNode<float>()\n<id:1650> BroadcastLinearFunctionNode<float>(1647.output[0:4096], 1648.output[0:256], 1649.output[0:0])\n<id:1651> ConstantNode<float>()\n<id:1652> ConstantNode<float>()\n<id:1653> BroadcastLinearFunctionNode<float>(1650.output[0:4096], 1651.output[0:0], 1652.output[0:256])\n<id:1654> ReorderDataNode<float>(1653.output[0:9216])\n<id:1655> UnrolledConvolutionNode<float>(1654.output[0:9216])\n<id:1656> ReorderDataNode<float>(1655.output[0:8192])\n<id:1657> ConstantNode<float>()\n<id:1658> ConstantNode<float>()\n<id:1659> BroadcastLinearFunctionNode<float>(1656.output[0:8192], 1657.output[0:0], 1658.output[0:512])\n<id:1660> BroadcastUnaryFunctionNode<float,ReLUActivationFunction<float>>(1659.output[0:8192])\n<id:1661> PoolingLayerNode<float,MaxPoolingFunction>(1660.output[0:8192])\n    PoolingLayer<float,MaxPoolingFunction>(shape=[4,4,512]->[2,2,512], function=maxpooling, stride=2, size=2)\n<id:1662> ReorderDataNode<float>(1661.output[0:2048])\n<id:1663> UnrolledConvolutionNode<float>(1662.output[0:2048])\n<id:1664> ReorderDataNode<float>(1663.output[0:4000])\n<id:1665> ConstantNode<float>()\n<id:1666> ConstantNode<float>()\n<id:1667> BroadcastLinearFunctionNode<float>(1664.output[0:4000], 1665.output[0:0], 1666.output[0:1000])\n<id:1668> BroadcastUnaryFunctionNode<float,ReLUActivationFunction<float>>(1667.output[0:4000])\n<id:1669> PoolingLayerNode<float,MeanPoolingFunction>(1668.output[0:4000])\n    PoolingLayer<float,MeanPoolingFunction>(shape=[2,2,1000]->[1,1,1000], function=meanpooling, stride=1, size=2)\n<id:1670> SoftmaxLayerNode<float>(1669.output[0:1000])\n    SoftmaxLayer<float>(shape=[1,1,1000]->[1,1,1000])\n<id:1671> OutputNode<float>(1670.output[0:1000])\n```. See Keyword Spotting on MXCHIP. Agreed :-) This may already be possible if you can find an LLVM bitcode to JavaScript generator, like say emscripten.  The ELL compiler has a \"-bitcode\" output option already.  But I haven't tried whether this actually works... probably also need to compile the ELL model with \"--blas false\" so that your bitcode has no openblas dependency.. No.  But I see no reason why these things couldn't already work with the compiled neural network output from ELL:\n\nand\n\nthis second case might be a bit trickier since the C# code would need to know how to call the ELL generated native API to \"predict\", perhaps a native interop could achieve that.. Sure thing, love to get some help.  In the meantime if you use IL2CPP or CoreRT to native code there it should already by possible to link the ELL generated object code into an existing native application.  I'd be happy to help get that working if you want to try something along those lines.. Assuming you have Visual Studio 2017 installed you should be able to open a \"Developer Command Prompt\" for Visual studio which looks like this:\n\nand then cmake will be available (it lives here: C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin\\cmake.exe)\n. Right.  VS Code is great for python development, but you need full Visual Studio to get the C++ compiler that is needed to build ELL.. I wonder if your Visual Studio installation is missing the C++ feature?  This is what I have installed:\n\n. did you forget to activate your miniconda environment and run ctest from there?  You also need to run the initial cmake and build from your activated your miniconda environment  otherwise it will not build the ell_py.pyd python module.  If you did not run cmake from your miniconda environment you will need to delete your build folder and start over.  cmake won't be able to change your build from non-python to python.. Oh, one more thing, you need to make sure openblas is in your PATH environment, assuming you have a haswell CPU try this:\nset PATH=%PATH%;E:\\git\\ELL\\external\\OpenBLASLibs.0.2.19.3\\build\\native\\x64\\haswell\\bin;\nFor more info see \"Path Environment\" section of INSTALL-Windows.md. can you show me the results of \"dir E:\\Git\\ELL\\build\\interfaces\\python\\package\\ell\\release\" ? You should see an _ell_py.pyd module there, and if you run the http://www.dependencywalker.com/ on this module you might find what is missing (ignore the errors reported about anything named API-MS-WIN-*, but if you see anything else missing then that will be it.  I find the \"View/Collapse All\" option is handy.  This is what I see on my machine:\n\n. Interesting.  I wonder then if you have a CPU that our OpenBlas doesn't support...   Do you see output like this from cmake?\n-- Processor family: 6, model: 58\n-- Using OpenBLAS compiled for sandybridge\n-- Using BLAS include path: D:/git/ELL/ELL/external/OpenBLASLibs.0.2.19.3/build/native/x64/sandybridge/include\n-- Using BLAS library: D:/git/ELL/ELL/external/OpenBLASLibs.0.2.19.3/build/native/x64/sandybridge/lib/libopenblas.dll.a\n-- Using BLAS DLLs: libopenblas.dll;libgcc_s_seh-1.dll;libgfortran-3.dll;libquadmath-0.dll. Ok great, so OpenBlas should work, and depends.exe is finding your OpenBlas so all should be good.  I also noticed you reported error \"ModuleNotFoundError: No module named 'numpy'\" -- so did you install OpenCV in your python environment?  Installing OpenCV should also bring in numpy...\n. Sorry I missed your earlier comment about being able to import numpy, this is now really weird.  You can import numpy, so why can't ell.  Can you try this:\ncd E:\\Git\\ELL\\build\\interfaces\\python\\package\npython\nimport ell\nIf this fails with the same error then I may need to ask  you to debug into this using VS code.. Ah this is a clue:\nImportError: Module use of python37.dll conflicts with this version of Python.\nit is odd this is mentioning python37 when your environment is \"C:\\Users\\harsh\\Miniconda3\\envs\\py36\".  Did you do a system wide install of python37?  Perhaps it is finding that instead of your python36... \nWhat do you get from \"where python\" ?. so \"C:\\Users\\harsh\\Miniconda3\\python.exe\" is a python 3.7 then eh?   Can you remove C:\\Users\\harsh\\Miniconda3\\ from your PATH environment, and activate py36, and run the ELL rebuild.cmd ?  I suspect something in there got confused about the presence of python 3.7 in your PATH.... Assuming \"depends.exe\" is still happy with _ell_py.pyd, this error is the one that normally means a DLL cannot be found, in debugging \"import ell\" in vs code if you break on all exceptions you might get more information.. Cool, thanks for the update.. Can you include the output of your \"cmake ..\" command line ?. Sorry can you delete your build folder and do it again, I'm curious what C and C++ compiler versions it is finding (which is not reported the second time you run cmake).  I'm looking for output like this:\n-- The C compiler identification is GNU 8.2.0\n-- The CXX compiler identification is GNU 7.3.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\nwhich shows my C and C++ compiler versions are mismatched.  One is 7 and the other is 8.  And I will get compiler errors as a result.  But if I run this:\n```\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 50 --slave /usr/bin/g++ g++ /usr/bin/g++-8\nthen everything compiles without errors.. I just ran our full setup instructions on fresh Ubuntu 18 machine I got a newer compiler:\n-- The C compiler identification is GNU 8.2.0\n-- The CXX compiler identification is GNU 8.2.0\nis this not available on Ubuntu 16 when you use this:\nsudo add-apt-repository ppa:ubuntu-toolchain-r/test\nsudo apt-get -y update\nsudo apt-get install -y gcc-8 g++-8 \n```. Not according to this thread  on raspberry pi forums, it says:\n\"should have been \"/LXDE-pi/\" rather than \"/LXDE/\". Before Raspbian started including the users autostart (and switched from LXDE to LXDE-pi) you had to create your own \"/lxsession/LXDE/autostart\" to override the one at \"/etc/xdg/\". If you had used \"nano ~/.config/lxsession/LXDE-pi/autostart\" you would have been editing the correct autostart, but using \"/LXDE/\" it created a new file instead, but of course it won't use it.\". More confirmation here that LXDE-pi is the new name.  You can check this log file to see what config file is being used:\n/home/pi/.cache/lxsession/LXDE-pi/run.log\nmine says:\n** Message: utils.vala:68: User config used : /home/pi/.config/lxsession/LXDE-pi/autostart\nInterestingly this log also says:\n** (lxsession:480): WARNING **: app.vala:86: Failed to execute child process \"xscreensaver\" (No such file or directory). I take it you have two different raspberry pi devices then? one with LXDE and one with both?  What is the \"lsb_release -a\" output from each of these?. closed due to inactivity. I've seen this on a PC running an older Intel \"sandybridge\" CPU.  Seems LLVM is getting stuck.  The bug is being investigated.. Try running this to produce the required model.o object file:\nd:/git/ELL/ELL/build/bin/release/compile -imap model.ell -cfn Predict -cmn model --target host -od model --fuseLinearOps True --optimizeReorderDataNodes True --header --blas true --optimize true --objectCode. Oh, and be sure to add \"--target pi3\" to the compile command line if you plan to run that model on your raspberry pi.. Not enough information, just says \"Killed\" that is weird.  Did you type CTRL+C ?  That would kill it...  perhaps you could monitor the memory usage of the app, is it running out of memory compared to the amount of memory that your system has?. Yeah, I see 3.7 gb in your window there, that's pretty low, especially since we are building an audio library of size 2,563,557,026 (and that's the disk size, the numpy memory size is probably larger) and the OS probably takes a bunch of memory.  So if you cannot increase the amount of RAM available to this machine then I would recommend lowering the max_files_per_directory you provide to make_training_list to something like 1000 or 500.. ah ha, this time we do see \"MemoryError\" which confirms our suspicions that this is a memory problem.  So you will have to keep decreasing max_files_per_directory until you find one that fits in the available RAM.  Training neural networks is known to use lots of RAM, the tutorial probably should state you need at least 16 gb of RAM or more.. I don't know just keep subtracting 100 until it works.  But I'm curious what kind of machine this is that has only 3.7gb RAM.  Is there any way to get more RAM for this machine?. Can you run just the \"compile\" part of this command again with \"--verbose\" and report the output you see?\n/Users/jonathanli/Applications/squirrel-tracker/ELL/build/bin/compile -imap model.ell -cfn Predict -cmn model --bitcode --target host -od host --fuseLinearOps True --optimizeReorderDataNodes True --swig --blas true --optimize true --verbose. clone https://github.com/xianyi/OpenBLAS, then:\nmkdir build\ncd build\ncmake -G \"Visual Studio 15 2017 Win64\" ..\ncmake --build . --config Release\nThis will give you an OpenBlas build that works for your computer.  The output of this build is in OpenBLAS\\build\\lib\\release where you will see libopenblas.dll.  Then run this from an Admin command prompt:\ncmake --build . --config Release --target INSTALL\nThis will put the installed bits in \"C:/Program Files/OpenBLAS\" and the next step is helping the ELL build find this build of OpenBlas.  The easiest way might be something like this before the FindPackage call:\nset(BLAS_DLL_DIR \"C:/Program Files/OpenBLAS/bin\")\nset(BLAS_INCLUDE_SEARCH_PATHS ${BLAS_PACKAGE_DIR}/include/)\nset(BLAS_LIB_SEARCH_PATHS ${BLAS_PACKAGE_DIR}/lib/). It is a  bit more work to get OpenBlasSetup.cmake to find this version, see attached updates.\nOpenBLASSetup.zip\n. You can safely ignore all those warnings, go ahead with the build step:\ncmake --build . --config Release. Great, now for the install step from an admin command prompt:\ncmake --build . --config Release --target INSTALL. yes, replace OpenBLASSetup.cmake in your ELL/Cmake with the one I attached earlier, then delete any ELL/build folder you may have created earlier, then follow the ELL build instrucrtions.. CMake Error at CMake/OpenBLASSetup.cmake:171 (get_processor_mapping):\n  get_processor_mapping Macro invoked with incorrect arguments for macro\n  named: get_processor_mapping\nHuh, what version of cmake are you using?  This is the one I'm using:\n```\nC:\\Program Files\\CMake\\bin\\cmake.exe\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin\\cmake.exe\n(ell) c:\\git\\ELL\\ELL>cmake --version\ncmake version 3.10.0\n. Hmm, I just tried my modified OpenBLASSetup.cmake on another machine with the exact same version of cmake (cmake version 3.12.18081601-MSVC_2) and it works fine... can you run the following on your machine and report the output?\n(ell) d:\\temp\\ELL\\ELL\\CMake>set proc\nPROCESSOR_ARCHITECTURE=AMD64\nPROCESSOR_IDENTIFIER=Intel64 Family 6 Model 79 Stepping 1, GenuineIntel\nPROCESSOR_LEVEL=6\nPROCESSOR_REVISION=4f01\nI suspect we have a bug in our get_processor_mapping macro... oh, and I need the output of this one too:\n(ell) d:\\temp\\ELL\\ELL\\CMake>reg query HKEY_LOCAL_MACHINE\\Hardware\\Description\\System\\CentralProcessor\\0\nHKEY_LOCAL_MACHINE\\Hardware\\Description\\System\\CentralProcessor\\0\n    Component Information    REG_BINARY    00000000000000000000000000000000\n    Identifier    REG_SZ    Intel64 Family 6 Model 79 Stepping 1\n    Configuration Data    REG_FULL_RESOURCE_DESCRIPTOR    FFFFFFFFFFFFFFFF0000000000000000\n    ProcessorNameString    REG_SZ    Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz\n    VendorIdentifier    REG_SZ    GenuineIntel\n    FeatureSet    REG_DWORD    0x3d1b3fff\n    ~MHz    REG_DWORD    0x82f\n    Update Revision    REG_BINARY    000000002E00000B\n    Update Status    REG_DWORD    0x7\n    Previous Update Revision    REG_BINARY    000000002E00000B\n    Platform Specific Field 1    REG_DWORD    0x1\n. Oh, hang on, the OpenBLASSetup.cmake shouldn't be getting to line 171.  It should be finding your OpenBlas installation in c:\\program files\\openblas\u2026 but this output means it did not find that:\n-- BLAS library not found\nSo we need to debug why the new lines I added 108-121 didn't succeed in finding your openblas install...  running this line and attaching a zipped version of the trace.log file will help with that:\ncmake -G \"Visual Studio 15 2017 Win64\" .. --trace > trace.log 2>&1\n. Yes, thanks that was helpful.  Looks like OpenBLASSetup.cmake is not finding your OpenBlas install.  You should see this output in the trace.log file:\nD:/temp/ELL/ELL/CMake/OpenBLASSetup.cmake(93):  if(BLAS_FOUND )\nD:/temp/ELL/ELL/CMake/OpenBLASSetup.cmake(105):  else()\nD:/temp/ELL/ELL/CMake/OpenBLASSetup.cmake(106):  if(WIN32 )\nD:/temp/ELL/ELL/CMake/OpenBLASSetup.cmake(109):  if(${CMAKE_SYSTEM_PROCESSOR} STREQUAL AMD64 )\nD:/temp/ELL/ELL/CMake/OpenBLASSetup.cmake(110):  set(BLAS_PACKAGE_DIR $ENV{ProgramW6432}/OpenBlas )\nD:/temp/ELL/ELL/CMake/OpenBLASSetup.cmake(115):  if(EXISTS ${BLAS_PACKAGE_DIR}/lib/libopenblas.lib )\nD:/temp/ELL/ELL/CMake/OpenBLASSetup.cmake(116):  message(STATUS Found OpenBlas in ${BLAS_PACKAGE_DIR} )\n-- Found OpenBlas in C:\\Program Files/OpenBlas\nBut that last line is missing from your trace.  Can you check your OpenBlas INSTALL step worked properly and put open blas in this location \"C:\\Program Files\\OpenBlas\" ?. hmmm, ok, perhaps on an AMD machine the CMAKE_SYSTEM_PROCESSOR is set to something different, can you print out the result of message(STATUS CMAKE_SYSTEM_PROCESSOR=${CMAKE_SYSTEM_PROCESSOR}) ?  Just add this to a tiny cmake file and run the cmake generator step (cmake -G \"Visual Studio 15 2017 Win64\").  You should see something like this in the cmake output:\n-- CMAKE_SYSTEM_PROCESSOR=AMD64\n. Sorry I wasn't clear.  I didn't mean for you to edit the ELL cmake files.  Instead create a new empty folder named \"foo\" someplace, add one text file named \"CMakeLists.txt\", containing this:\nmessage(STATUS CMAKE_SYSTEM_PROCESSOR=${CMAKE_SYSTEM_PROCESSOR})\nthen in this folder run this command:\ncmake -G \"Visual Studio 15 2017 Win64\"\nand send the output that you see.  If this works, then we can build up from there to this and figure out why it isn't working:\nThis is the default location for a manually installed OpenBlas build.\nif(${CMAKE_SYSTEM_PROCESSOR} STREQUAL \"AMD64\")\n    set(BLAS_PACKAGE_DIR $ENV{ProgramW6432}/OpenBlas)\nelse()\n    set(BLAS_PACKAGE_DIR $ENV{ProgramFiles}/OpenBlas)\nendif()\nif(EXISTS ${BLAS_PACKAGE_DIR}/lib/libopenblas.lib)\n    message(STATUS \"Found OpenBlas in ${BLAS_PACKAGE_DIR}\")\n    set(BLAS_DLLS libopenblas.dll)\n    set(BLAS_DLL_DIR ${BLAS_PACKAGE_DIR}/bin)\n    set(BLAS_INCLUDE_SEARCH_PATHS ${BLAS_PACKAGE_DIR}/include/)\n    set(BLAS_LIB_SEARCH_PATHS ${BLAS_PACKAGE_DIR}/lib/)\n    set(BLAS_FOUND TRUE)\nendif()\n. Ok, great the important thing here is we see this output:\n-- CMAKE_SYSTEM_PROCESSOR=AMD64\nThis is good, now please modify your little test CMakeLists.txt so it contains this:\nThis is the default location for a manually installed OpenBlas build.\nmessage(STATUS \"ProgramW6432=[$ENV{ProgramW6432}]\")\nif(${CMAKE_SYSTEM_PROCESSOR} STREQUAL \"AMD64\")\n    set(BLAS_PACKAGE_DIR $ENV{ProgramW6432}/OpenBlas)\nelse()\n    set(BLAS_PACKAGE_DIR $ENV{ProgramFiles}/OpenBlas)\nendif()\nif(EXISTS ${BLAS_PACKAGE_DIR}/lib/libopenblas.lib)\n    message(STATUS \"Found OpenBlas in ${BLAS_PACKAGE_DIR}\")\n    set(BLAS_DLLS libopenblas.dll)\n    set(BLAS_DLL_DIR ${BLAS_PACKAGE_DIR}/bin)\n    set(BLAS_INCLUDE_SEARCH_PATHS ${BLAS_PACKAGE_DIR}/include/)\n    set(BLAS_LIB_SEARCH_PATHS ${BLAS_PACKAGE_DIR}/lib/)\n    set(BLAS_FOUND TRUE)\nendif()\nand re-run this command line in that folder:\ncmake -G \"Visual Studio 15 2017 Win64\"\nHopefully you should see this output:\n-- ProgramW6432=[C:\\Program Files]\n-- Found OpenBlas in C:\\Program Files/OpenBlas\n. Ok, great, keep adding \"message\" statements until we figure out what is not working here, is it the first if block that is failing?  If so this would indicate that \"C:\\Program Files\\OpenBlas\" does not exist.  (Ignore the forward slashes versus backslashes - cmake uses forward slashes but can also handle the backslashes that Windows uses).\nif(${CMAKE_SYSTEM_PROCESSOR} STREQUAL \"AMD64\")\n    set(BLAS_PACKAGE_DIR $ENV{ProgramW6432}/OpenBlas)\nelse()\n    set(BLAS_PACKAGE_DIR $ENV{ProgramFiles}/OpenBlas)\nendif()\nor is it the second if block?\nif(EXISTS ${BLAS_PACKAGE_DIR}/lib/libopenblas.lib)\n    message(STATUS \"Found OpenBlas in ${BLAS_PACKAGE_DIR}\")\n    set(BLAS_DLLS libopenblas.dll)\n    set(BLAS_DLL_DIR ${BLAS_PACKAGE_DIR}/bin)\n    set(BLAS_INCLUDE_SEARCH_PATHS ${BLAS_PACKAGE_DIR}/include/)\n    set(BLAS_LIB_SEARCH_PATHS ${BLAS_PACKAGE_DIR}/lib/)\n    set(BLAS_FOUND TRUE)\nendif()\n```\nFor example, let's add this status message just before the above if-test:\nmessage(STATUS \"BLAS_PACKAGE_DIR=[${BLAS_PACKAGE_DIR}]\")\n. Ok, great, then we have narrowed it down to this line is failing:\nif(EXISTS ${BLAS_PACKAGE_DIR}/lib/libopenblas.lib)\nSo can you check the contents of your folder: C:\\Program Files\\OpenBlas\\lib and see if it contains a file named \"libopenblas.lib\" ?. Interesting.  So OpenBlas build does something different on your machine then.  Can you run this from a command prompt window and send post the output?\ndir /s /b \"c:\\Program Files\"\\openblas. Hey do you have Visual Studio installed and did you built OpenBlas from a Visual Studio Developer Command Prompt ?  I see this in the OpenBlas CMakeLists.txt and it seems that this naming difference happens if cmake is not finding Microsoft Visual C++:\nif(MSVC)\nset(OpenBLAS_LIBNAME libopenblas)\nelse()\nset(OpenBLAS_LIBNAME openblas)\nendif(). this is what I see:\n(base) C:\\Users\\clovett>dir /s /b \"c:\\Program Files\"\\openblas\nc:\\Program Files\\openblas\\bin\nc:\\Program Files\\openblas\\include\nc:\\Program Files\\openblas\\lib\nc:\\Program Files\\openblas\\bin\\libopenblas.dll\nc:\\Program Files\\openblas\\include\\cblas.h\nc:\\Program Files\\openblas\\include\\f77blas.h\nc:\\Program Files\\openblas\\include\\openblas_config.h\nc:\\Program Files\\openblas\\lib\\libopenblas.lib\nI normally setup my command prompt environment using this trick:\ncall \"c:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\Tools\\VsDevCmd.bat\". yep, let's remove this openblas install from \"c:\\Program Files\\openblas\", and your openblas/build folder, open a Visual Studio Developer Command Prompt, should look like this:\n\nand rebuild open blas from there.  This should build openblas with MSVC and you should see the names libopenblas.  Then the ELL build should work with that.. you can simply delete it :-) . Hmmm, very odd, now I need to compare cmake output from your OpenBLAS folder with what I'm getting.  Can you run this?\ncmake -G \"Visual Studio 15 2017 Win64\" .. > cmake.log 2>&1\nYou should get something like this:\ncmake.log\nAnd the build should finish with output like this:\nlibopenblas.vcxproj -> D:\\git\\OpenBLAS\\build\\lib\\RELEASE\\libopenblas.dll. Thanks, very different output from mine.  I think you may need to ask for some help on the OpenBlas git repo to figure out how to get OpenBlas to build properly using the MSVC compiler.  See how my cmake output in yellow right off the bat identifies CXX is MSVC version 19.16... yours doesn't.\n\n. You could try doing this before running the OpenBLAS cmake:\ncall \"c:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\Tools\\VsDevCmd.bat\" \nset WindowsSdkDir=\nAnd delete the OpenBLAS build folder each time you rerun cmake to make sure it is a clean cmake generation from scratch.. Looks much better.  This is what I mean by building OpenBLAS from a \"Visual Studio Developer Command Prompt\".  You should be good to go now.. weird, static_cast is not a lambda, so there's nothing to capture.  But the previous line tries to do this \"const auto&\" to a return type of type \"model::PortMemoryLayout\" which also doesn't really make sense, so perhaps try replacing line 514 with this:\ncpp\nmodel::PortMemoryLayout outputLayout = GetOutputMemoryLayout();. Can you run just the compile command line by itself and report the output you see?\nC:/Users/dtlabvr/ELL/build/bin/release/compile -imap model.ell -cfn Predict -cmn model --bitcode --target host -od host --fuseLinearOps True --optimizeReorderDataNodes True --swig --blas false --optimize true. Just follow the setup and build instructions that match your operating system:\n\nWindows\nUbuntu Linux\nMac OS X\n\nwhen you are done the above test app will appear in the build/libraries/trainers folder.\n. Thanks for the bug report.  I can reproduce this bug.  We'll get it fixed.. ",
    "HaRo87": "Hey folks,\nI really like the idea of ELL. While trying to set it up I am struggling with getting it up and running on my Mac. I get the same error as already mentioned above:\n`ELL/libraries/model/include/IRModelProfiler.h:15:10: fatal error: \n      'EmitterTypes.h' file not found\ninclude \"EmitterTypes.h\"`\nThe installation procedure on the Pi worked like a charm.\n@lovettchris can you provide any details about how you've fixed that?. Hey @michhar and @YanMinge,\nthanks for your support. I was able to build ELL now. But as already raised by @YanMinge on issue #130 I am now stuck at the point of compiling my first model following this tutorial. :-(. Hey folks,\nI am facing the same issue on my Mac. The solutions found via Google did not really help. Any progress on this topic?\nI tried to use both versions which came with my miniconda installation:\n\n3.6.3\n3.6.4\n\nI was using the following command:\n~/miniconda3/bin/python3.6 ~/ELL/tools/wrap/wrap.py model.ell -lang python -target host\nand still get the following error:\n\nFatal Python error: PyThreadState_Get: no current thread \nAbort trap: 6\n\nIs there any information about which version of python was used by the ELL project?\nThanks and Cheers,\nRobert. Hey @YanMinge,\nI've switched to Ubuntu 16.04 and did a fresh install following all the steps in the tutorial and I was able to call wrap.py without the error mentioned above. But still no luck, now I am getting a WrapException.  . ",
    "michhar": "@HaRo87 I'm on macOS High Sierra 10.13.2\nI had the same error and the fix was pretty simple for me.  It has to do with where the llvm package gets installed.  To fix, I just symbolically linked from the llvm@3.9 (it names the Cellar this) into the llvm Cellar folder:\ncd /usr/local/Cellar/llvm\nln -s ../llvm@3.9/3.9.1_1\nAnd make sure you're using that version, brew switch as follows:\nbrew switch llvm 3.9.1_1\nI was able then to run cmake .. and then make to build the latest ELL (v2.1.7) (checkout today).\nHope that helps.\n@lovettchris May want to note in the macOS installation instructions.. ",
    "kernhanda": "thanks @michhar. We'll add this to our notes and try to make this automatic for future builds. . Please note that this PR is no longer valid. Also, one of the objectives of the tutorials is to keep the code simple and easy to understand.. Please note that this PR is no longer valid and all the tutorials should be functional.. Thanks. Similar functionality is available in our repo now through SETUP-Ubuntu.sh.. @y-vyrovoy, looks like he forgot to select \"Desktop Development with C++\" when he was running the VS installer.. This PR is no longer valid.. Fixed with 2d36e7d21c184f87947cda2fd18db2fc743de683.. Running protoNNTrainer with a valid dataset passed in with the --inputDataFilename command line argument properly sets this value in the code. Please ensure that you're using a proper input.\nIf you're using the aforementioned command line argument and the variable value is still incorrect, please reactivate this issue and provide the command line invocation, along with a sample of the training data being used.\n. Yes, if you look at https://microsoft.github.io/ELL/tutorials/Getting-started-with-image-classification-in-cpp/, you can see that ELL creates a function called model_Predict, where model can be replaced by a name of your choice.. Per our importing models tutorial, please install CNTK on your machine.. If you're on WSL, you don't need the VS 2017 compatibility.. Per our importing models tutorial, please install CNTK on your machine.. Unfortunately, ELL does not support converting CNTK's Combine layers.. Thanks @IvanFarkas. We'll work on cleaning up the CMake configuration output. Please let us know if you were unable to build.. This is just a warning and it can be safely ignored. We're working to get rid of it.. Did you run sudo apt-get install -y libopenblas-dev per the Ubuntu install instructions?. Can you try passing -DBLA_VENDOR=OpenBLAS to cmake and then try building? Please make sure to delete your build folder and create it again.. This looks to be a fault with the compiler. It should never be killed when compiling a file. Please file a bug report for your compiler and/or upgrade your compiler.\nFor the sake of curiousity, what's the version of your compiler?. Does it result in the same error? Can you please run the following (feel free to adjust the cmake commands if you were doing something different, but please call it out) in the ELL repository\nshell\ngit clean -fdx\nmkdir build\ncd build\ncmake ..\ncmake --build .\nand share the output?\n. Thanks. What was the problem?. Thanks!. @kvijaykiran - Perhaps the instructions at https://github.com/Microsoft/ELL/issues/1#issuecomment-359204598 will prove to be helpful for you. LGTM.. Thanks for letting us know! Closing this issue.. Did the docs provide the instructions you were looking for? . Thanks for the feedback!. Thanks for letting us know what the problem was, @braca51e. Closing this issue now.. Thanks for bring this to our attention! We'll investigate further and update this thread with our findings. Thanks! . This is fixed in release 2.3.2.. Can you explain a little bit about what you're trying to do? From the logs provided, ELL doesn't seem to be mentioned at all.. How does slicer relate to ELL? . Thanks for letting us know. This file was accidentally deleted. It will be restored in the next release.. Resolved with release v2.3.5.. Your problem seems to be similar to https://github.com/caffe2/caffe2/issues/854, which seems to be a system configuration issue around python specifically.. Please see #140 .. Resolved with release v2.3.5. Resolved with release v2.3.5. LGTM. Resolved with release v2.3.5. Fixed with release v2.3.7.. Building v2.3.5 works for me. Can you share your cmake configuration step (cmake -G ...)?. The warning about LLVM can be safely ignored. Please note that you're using Visual Studio 2015, per the -G \"Visual Studio 14 2015 Win64\" part of the cmake command. We no longer support VS2015. Please try it with Visual Studio 2017, which is available for free.. Are you sure this is for ELL? The cmake output suggests you're building \"kcov\".\n\nlinked by target \"kcov\" in directory /root/kcov-master/src\n-- Configuring incomplete, errors occurred!\nSee also \"/root/kcov-master/build/CMakeFiles/CMakeOutput.log\".\nSee also \"/root/kcov-master/build/CMakeFiles/CMakeError.log\".\n. Can you provide the entirety of the output from the initial cmake .. (the configuration) step?. Sorry, please delete CMakeCache.txt and run cmake .. again. In particular, I'm looking for your compiler with its full version.. Thanks. While you have GCC 8 installed, the cmake configuration step is using GCC 5.5.0.\n-- The C compiler identification is GNU 5.5.0                                                                                                                                                                                               \n-- The CXX compiler identification is GNU 5.5.0\n\nTry deleting CMakeCache.txt and running the following CC=gcc-8 CXX=g++-8 cmake .. and then try building.. Fixed with release v2.3.7.. I would prefer if it was stated that the extra argument is needed when building with VS.. The instructions have been fixed to provide different instructions for Windows. Thanks for pointing this out!. Stale references to VS 2015 have been removed. Thanks for pointing this out!. You might be able to figure out what's happening by doing tail -f\n/var/log/kern.log in a separate shell while running make_dataset.py.\nAlternatively, just run less /var/log/kern.log after seeing a Killed\noutput from the system.\nOn Tue, Feb 12, 2019 at 11:29 AM Chris Lovett notifications@github.com\nwrote:\n\nNot enough information, just says \"Killed\" that is weird. Did you type\nCTRL+C ? That would kill it... perhaps you could monitor the memory usage\nof the app, is it running out of memory compared to the amount of memory\nthat your system has?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Microsoft/ELL/issues/197#issuecomment-462900363, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABPkp7C8eEHRosZK-VUHhyhQf7wMO46Gks5vMxYXgaJpZM4a2eQ0\n.\n. Yes, my suggestion should still work, at least as a confirmation that the python script is running out of memory.\n\nPlease let us know what the results are so that we can address the issue correctly.. Closing this issue.. s/customly/manually/. might just be better to do s/custom/manual/ on the whole file. DBLA_VENDOR is no longer needed with the latest master. \" at the end of the line is unnecessary. is this whole section really necessary? isn't it covered by the raspberry pi tutorial, which is already linked?. s/memory issue/out of memory errors/\n  . I think your new instructions supersede this blurb, no? Maybe they could be merged. \"If setting LLVM_DIR fixes your issues, you may want to consider creating a symlink.\".. No, we don't have one yet. I think we can get to it around August? Let us know if that's too long.. ",
    "YanMinge": "@michhar , I refer to your settings, but the same error still occurred. cmake log as shown below. and \nconfigure environment variables can solve this problem\nEnter the command in the command line:\nshell\nsudo vi ~ / .bash_profile\nand add your llvm file directory\nshell\nexport PATH=\"/usr/local/Cellar/llvm/3.9.1_1/bin:$PATH\"\nThis should be able to completely solve the problem that cmake cann\u2018t find llvm configuration\n```\n-- The C compiler identification is AppleClang 9.0.0.9000039\n-- The CXX compiler identification is AppleClang 9.0.0.9000039\n-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc\n-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++\n-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- PYTHONINTERP_FOUND=TRUE\n-- PYTHON_EXECUTABLE=/Users/yanminge/miniconda3/bin/python3.6\n-- PYTHON_VERSION_STRING=3.6.3\n-- PYTHON_VERSION_MAJOR=3\n-- PYTHONLIBS_FOUND=TRUE\n-- PYTHON_LIBRARIES=/Users/yanminge/miniconda3/lib/libpython3.6m.dylib\n-- PYTHON_INCLUDE_PATH=/Users/yanminge/miniconda3/include/python3.6m\n-- PYTHON_INCLUDE_DIRS=/Users/yanminge/miniconda3/include/python3.6m\n-- PYTHON_DEBUG_LIBRARIES=\n-- PYTHONLIBS_VERSION_STRING=3.6.3\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - found\n-- Found Threads: TRUE\n-- Using BLAS include path: /System/Library/Frameworks/Accelerate.framework/Versions/Current/Frameworks/vecLib.framework/Versions/Current/Headers\n-- Using BLAS library: /usr/lib/libcblas.dylib\n-- Using BLAS DLLs: \nCMake Warning at CMake/LLVMSetup.cmake:48 (find_package):\n  By not providing \"FindLLVM.cmake\" in CMAKE_MODULE_PATH this project has\n  asked CMake to find a package configuration file provided by \"LLVM\", but\n  CMake did not find one.\nCould not find a package configuration file provided by \"LLVM\" (requested\n  version 3.9) with any of the following names:\nLLVMConfig.cmake\nllvm-config.cmake\n\nAdd the installation prefix of \"LLVM\" to CMAKE_PREFIX_PATH or set\n  \"LLVM_DIR\" to a directory containing one of the above files.  If \"LLVM\"\n  provides a separate development package or SDK, be sure it has been\n  installed.\nCall Stack (most recent call first):\n  CMakeLists.txt:115 (include)\n-- Found SWIG: /usr/local/bin/swig (found suitable version \"3.0.12\", minimum required is \"3.0.12\") \nLLVM unavailable. Compilers disabled.\nLLVM unavailable. Compiler disabled.\n-- LLVM not found, please check that LLVM is installed.\nERRORLLVM not found, please check that LLVM is installed.\n-- Creating wrappers for python\nCMake Deprecation Warning at /usr/local/Cellar/cmake/3.10.2/share/cmake/Modules/UseSWIG.cmake:231 (message):\n  SWIG_ADD_MODULE is deprecated.  Use SWIG_ADD_LIBRARY instead.\nCall Stack (most recent call first):\n  CMake/CommonInterfaces.cmake:127 (swig_add_module)\n  CMake/CommonInterfaces.cmake:159 (generate_interface_module)\n  interfaces/python/CMakeLists.txt:22 (generate_interface)\n-- Creating wrappers for javascript\n-- Creating wrappers for xml\n-- Configuring done\nCMake Warning (dev) at CMake/CommonInterfaces.cmake:68 (add_dependencies):\n  Policy CMP0046 is not set: Error on non-existent dependency in\n  add_dependencies.  Run \"cmake --help-policy CMP0046\" for policy details.\n  Use the cmake_policy command to set the policy and suppress this warning.\nThe dependency target \"emitters\" of target \"ELL_common\" does not exist.\nCall Stack (most recent call first):\n  CMake/CommonInterfaces.cmake:159 (generate_interface_module)\n  interfaces/common/CMakeLists.txt:11 (generate_interface)\nThis warning is for project developers.  Use -Wno-dev to suppress it.\n-- Generating done\n-- Build files have been written to: /Users/yanminge/project/ELL/build\n```. I also searched for the same content on google\uff0cBecause I used to refer to this document to create my environment https://github.com/Microsoft/ELL/blob/master/INSTALL-Mac.md\uff0cSo I am using a virtual environment\uff0cand you can see my python environment returned the expected result. \nwith otool I got the info\n(root) yanmingedeMacBook-Pro:wrap yanminge$ source activate py36\n(py36) yanmingedeMacBook-Pro:wrap yanminge$ sudo otool -L ~/project/ELL/build/interfaces/python/_ell_py.so \n/Users/yanminge/project/ELL/build/interfaces/python/_ell_py.so:\n    @rpath/libpython3.6m.dylib (compatibility version 3.6.0, current version 3.6.0)\n    /usr/lib/libedit.3.dylib (compatibility version 2.0.0, current version 3.0.0)\n    /usr/local/opt/libffi/lib/libffi.6.dylib (compatibility version 7.0.0, current version 7.4.0)\n    /usr/lib/libncurses.5.4.dylib (compatibility version 5.4.0, current version 5.4.0)\n    /usr/lib/libz.1.dylib (compatibility version 1.0.0, current version 1.2.11)\n    /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1252.0.0)\n    /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib (compatibility version 1.0.0, current version 1.0.0)\n    /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 400.9.0)\nand libpython3.6m.dylib is just the version I installed on the virtual machine.\nWhy you haven\u2018t encountered such a problem\uff1f. I still didn\u2018t solve this problem,  so I switched it to my ubuntu computer.. ",
    "luto65": "I confirm the issue of building on MacOS (10.13.3) and as well the resolution obtained by \ncd /usr/local/Cellar/\nmkdir llvm\ncd llvm\nln -s ../llvm@3.9/3.9.1_1\nexport PATH=\"/usr/local/Cellar/llvm/3.9.1_1/bin:$PATH\"\ncd <ELL distribution>/build\ncmake ..\nmake. ",
    "DarrenRainey": "What version of gcc/g++ and cmake are you using sometimes old compilers won't work with new coding standardss. maybe try upgrading gcc to version 6 and cmake to 3.8 and check this guide that might help : https://github.com/Microsoft/ELL/blob/master/INSTALL-Ubuntu.md. can you share a pastebin with your error log. I havent used docker that much but this might help : https://stackoverflow.com/questions/34302096/sharing-devices-webcam-usb-drives-etc-with-docker\nalso guess you could try streaming your camera over the network to the docker machine if you can't get the hardware pass though working.. Looking through your error log I've found a few things first \n\nOpenBLAS : Your OS does not support AVX instructions. OpenBLAS is using Nehalem kernels as a fallback, which may give poorer performance.\n\nThis means your cpu does not support the AVX instruction set so it will take longer.\n\n/home/codelast/programme/pi/ELL/build/tutorials/vision/gettingStarted/compiled_vgg16ImageNet_pi3/vgg16ImageNet.o for pi3\nKilled\n\nAnd Here it looks like the kernel is killing the build process for using too many resources.. What version of python are you using ? . You might need to update to 3.6 as it looks like your running 3.4.3\n. Looks like its not finding OpenBLAS from this line\n\nELL module is not loading It is possible that you need to add LibOpenBLAS to your system path (See Install-*.md) from root of this repo \n\nMaybe try  apt install libopenblas-dev or if you already have it installed add it to your $PATH. ",
    "mnbvcxz010308": "\n\ncmake version 3.5.1 \ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609. You need to install SWIG.  \n\n\nPlease note: Follow this order to build.\n- ### STEP 1 : Cloning the ELL repository\nThe instructions below assume that ELL was obtained from GitHub using git. The git client is typically installed by default on Ubuntu systems, but if it isn't, open a terminal and type\nsudo apt-get install git\nIn a terminal, clone the ELL repository by typing\ngit clone https://github.com/Microsoft/ELL.git\nPrerequisites\nWe recommend using the apt-get package manager to download and install prerequisites. First, make sure that apt-get is up to date, by typing\nsudo apt-get -y update\nGCC and CMake\nNext, you will need gcc and CMake. They are often installed by default on Ubuntu systems, but to confirm type\nsudo apt-get install -y gcc cmake\n\nLLVM\nYou will also need the dev version of LLVM-3.9. At the time of writing this document, apt-get doesn't yet have the required version of LLVM. To check this, type\napt-cache show llvm-dev\n\nand look for the version number. If the version number is 3.9 or greater, you can simply type sudo apt-get install -y llvm-dev. Otherwise, do the following:\nsudo apt-get install -y wget\nwget -O - http://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -\nsudo apt-add-repository \"deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-3.9 main\"\nsudo apt-get -y update\nsudo apt-get install -y llvm-3.9-dev\n\nlibedit\nInstall the BSD editline and history libraries\nsudo apt-get install -y libedit-dev\n\nzlib\nsudo apt-get install zlibc zlib1g zlib1g-dev\n\nOptional Prerequisites (OpenBLAS and Doxygen)\nELL can optionally take advantage of the optimized linear algebra libraries in OpenBlas, and generate code documentation using Doxygen. To install these optional dependencies, type\nsudo apt-get install -y libopenblas-dev doxygen\n\n\n\nSTEP 2 : ELL Language Bindings\n\n\nOverview\nThis section covers how to generate and test the ELL language bindings, which provide language-specific wrappers for ELL's library functions.\nGeneral setup\nThe language bindings are generated using SWIG. To build them, you need to install SWIG version 3.0.12 or later. \n\nLinux / Mac:\n- Download SWIG from here\n-  tar zxvf swig-3.0.12.tar.gz && cd swig-3.0.12.tar\n-  ./configure --without-pcre && make && sudo make install\n-  May be required on some Linux systems (replace VERSION with the actual version on your system)\nsudo ln /lib/x86_64-linux-gnu/libpcre.so.VERSION /usr/lib/libpcre.so.1\n\n\nVERSION is 3 for x64 Ubuntu 16.04\n\nPython\n\nInstall Python 3.6, preferably through Miniconda, which works well with Jupyter notebooks and provides a way to manage different python versions. ELL SWIG bindings require Python 3.6.\nLinux: Miniconda3-Linux-x86_64\nMac: Miniconda3-latest-MacOSX-x86_64\nWindows: Miniconda3-latest-Windows-x86_64\n\nNote: you can also use the full Anaconda if you already have that installed.\n\nConfigure the Python 3.6 environment using Miniconda\n```\n\nCreate the environment\nconda create -n py36 anaconda python=3\nActivate the environment\nactivate py36\nELL requires gcc 5 and above for C++14. Upgrade anaconda's environment to support it.\nconda install libgcc \n3. Generate the python bindings. In the repository root directory from within the py36 anaconda environment:\nmkdir build\ncd build\ncmake ..\nLinux / Mac\nmake _ELL_python \n```\nNote: if you already built ELL before you installed Python, you will need to delete that build and repeat the above steps\nin order to ensure the build is correctly setup to do the additional Python related build steps.\n\nTest the python bindings, which are located in build/interfaces/python/test:\ncd interfaces/python/test\npython test.py\n. AFAIK ELL supports  JS, Python. This project is WIP and they would add more bindings. This is my assumption, by looking into the interface directory of ELL and I would recommend you to reach out ELL guys to get more accurate answer on this. Thanks. \ud83d\ude04 . \n",
    "lisaong": "Closing out this issue as it looks like an out of date cmake and g++.  @vipings, if you followed @DarrenRainey's recommendation, this should build for you.  If not, let us know.. Hi,\nThanks for bringing this up.\nsudo make is not a supported build configuration for ELL at this time.  Is there a reason for needing to do sudo make instead of make?\nOur make command does not install anything or require sudo privileges.. Thanks for the details. Can you try a Ubuntu 16.04 container instead to see if it make a difference? . Great! Thanks for reporting back. . Indeed, we are recommending Ubuntu 16.04 at minimum, unless there is a strong reason for using Ubuntu 14.. My guess is that the blas headers being picked up are incorrect. They aren't declaring functions that ELL relies on. \nBlasWrapper.cpp:(.text+0x31)\uff1a\u5bf9\u2018cblas_scopy\u2019\u672a\u5b9a\u4e49\u7684\u5f15\u7528\nIf you followed the INSTALL.*md and installed blas, maybe you had another version that is taking precedence (cmake found that instead of the one ELL needs). Try:\n1) grep for that function in the header files to find the header needed, and\n2a) if found, modify the Blas cmake in ELL/CMake to point to the corrected include and and library paths, or\n2b) if not found, try installing blas again. If you search the issues thread for other recent Ubuntu build issues, you should find an example cmake output that someone posted which has the right blas paths. \n. Thanks for pasting the config details, this looks like a cmake error.  My guess is you have a newer version that is unhappy with line 51 of LLVMSetup.cmake. We've been using cmake 3.9 mostly, what version do you have and can you try 3.9?. Thanks for trying this out, and for putting in your time to get this to compile for Pi.  Instructions on running models for Raspberry Pi will be coming very shortly.\nThere are two parts to ELL.  1) The infrastructure for importing and compiling models (this runs on desktop environments, not the Pi) and 2) the models that get compiled to run on small devices (this runs on the Pi). \nInstructions for the 2nd part are starting to be collected at tutorials/vision/gettingStarted, but have not covered Pi yet. This part we are working on actively because it's about how to run the ML models. We're hoping to get something ready in a week or so. \nWe'll try to clarify the docs as well. Basically you don't need a build ELL itself on Pi to get the models to run. The error you are seeing is likely due to needing an updated gcc. . Ah, looks like you may have helped uncover a gcc 7 issue in the meantime. It'll be helpful when we support gcc 7 for desktop. \nThanks for spending the time on this! . Thanks for letting us know! Closing out this issue as resolved.  The compile_darknetReference.sh file was temporary and we've replaced it with the (hopefully more robust) cmake mechanism.. Hi, I'm closing out the issue since it looks like things are working.  Let us know if it isn't.\nThanks for trying ELL!. Hi,\nIt's hard to tell from the error, maybe you're using the wrong version of LLVM. Can you paste the output of cmake ..?  We've been developing with LLVM 3.9 and 3.9.1 because that's what is more widely available.. Hmm...Maybe your LLVM libs are not setup correctly.\nCheck what llvm libs are being linked against in link.txt under build/libraries/emitters/CMakeFiles/emitters_test.dir.\nOnce you find the libs, you can use nm to dump the libs and grep for getDefaultTargetTriple. If that doesn't exist, try reinstalling llvm...\n\nFrom: devilloser notifications@github.com\nSent: Wednesday, July 12, 2017 6:28:40 PM\nTo: Microsoft/ELL\nCc: Lisa Ong; Mention\nSubject: Re: [Microsoft/ELL] question:can't make in Ubuntu 14.04 (#50)\n@lisaonghttps://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Flisaong&data=02%7C01%7Clisaong%40microsoft.com%7C54e3582c31fd4e2c4a9008d4c98e7efa%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636355061234849639&sdata=1qa44uxMN3eJHLXe6h%2BmydsgPq1T2fLF%2BSSKk4niWTA%3D&reserved=0\n-- The C compiler identification is GNU 6.3.0\n-- The CXX compiler identification is GNU 6.3.0\n-- Check for working C compiler: /usr/local/bin/gcc\n-- Check for working C compiler: /usr/local/bin/gcc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/local/bin/c++\n-- Check for working CXX compiler: /usr/local/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Looking for pthread_create in pthreads\n-- Looking for pthread_create in pthreads - not found\n-- Looking for pthread_create in pthread\n-- Looking for pthread_create in pthread - found\n-- Found Threads: TRUE\n-- Blas libraries: /usr/lib/libopenblas.so\n-- Blas linker flags:\n-- Blas include directories:\n-- Using BLAS include path: /usr/include\n-- Using BLAS library: /usr/lib/libopenblas.so\n-- Using BLAS DLLs:\n-- Found PythonInterp: /usr/bin/python (found version \"3.6\")\n-- Found PythonLibs: /usr/local/lib/libpython3.6m.a (found version \"3.6.0\")\n-- Found SWIG: /usr/local/bin/swig (found suitable version \"3.0.12\", minimum required is \"3.0.12\")\n-- Creating wrappers for python\nCMake Deprecation Warning at /home/zf/develop/cmake-3.8.2-Linux-x86_64/share/cmake-3.8/Modules/UseSWIG.cmake:226 (message):\nSWIG_ADD_MODULE is deprecated. Use SWIG_ADD_LIBRARY instead.\nCall Stack (most recent call first):\nCMake/CommonInterfaces.cmake:159 (swig_add_module)\nCMake/CommonInterfaces.cmake:190 (generate_interface_module)\ninterfaces/python/CMakeLists.txt:21 (generate_interface)\n-- Creating wrappers for javascript\n-- Found npm at /usr/bin/npm\n-- Creating wrappers for xml\n-- Using python found at: /usr/bin/python\n-- Using python libraries found at: /usr/local/lib/libpython3.6m.a\n-- Creating wrappers for python\nCMake Deprecation Warning at /home/zf/develop/cmake-3.8.2-Linux-x86_64/share/cmake-3.8/Modules/UseSWIG.cmake:226 (message):\nSWIG_ADD_MODULE is deprecated. Use SWIG_ADD_LIBRARY instead.\nCall Stack (most recent call first):\nCMake/CommonInterfaces.cmake:159 (swig_add_module)\nCMake/CommonInterfaces.cmake:237 (generate_interface_module)\nexamples/emitted_interfaces/step/CMakeLists.txt:25 (generate_emitted_interface_module)\n-- Generated target compiled_vgg16ImageNet_host\n-- Generated target compiled_vgg16ImageNet_pi3\n-- Generated target compiled_vgg16ImageNet_pi0\n-- Generated target compiled_darknetReference_host\n-- Generated target compiled_darknetReference_pi3\n-- Generated target compiled_darknetReference_pi0\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/zf/ELL/build\nthis is the output of cmake ..\uff0cand my LLVM version is 3.9.1\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FMicrosoft%2FELL%2Fissues%2F50%23issuecomment-314943501&data=02%7C01%7Clisaong%40microsoft.com%7C54e3582c31fd4e2c4a9008d4c98e7efa%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636355061234849639&sdata=iYPVj69gNX3CsF9t9QywCgXRRFgrvyj%2F%2FT2Yha%2BSK4g%3D&reserved=0, or mute the threadhttps://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAKyz4eijb3nB-ejhwqdrWknowu0nuiroks5sNXLIgaJpZM4OTrCv&data=02%7C01%7Clisaong%40microsoft.com%7C54e3582c31fd4e2c4a9008d4c98e7efa%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636355061234849639&sdata=DVj0BYXIGfbOUvO9kP%2BwlKmfUwU0SKnsfe2CoGg%2FW%2Bc%3D&reserved=0.\n. Here's a Raspberry Pi 3 docker with ELL and Miniconda:\nhttps://hub.docker.com/r/lisaong/pi3-miniconda3-ell\nTo run it and mount a folder containing your Jupyter notebooks:\ndocker run -it \\\n  -v your_notebook_location:/notebooks/myNotebooks \\\n  -v /opt/vc:/opt/vc \\\n  -p:28888:8888 \\\n  lisaong/pi3-miniconda3-ell:2.3.3\nNote that this container is designed to run on a Raspberry Pi 3.  To install Docker on Raspberry Pi 3:\ncurl -sSL get.docker.com | sh\nsudo usermod -aG docker pi\nlog out, then log back in again for the change to take effect\nsudo systemctl start docker\nReference: https://github.com/romilly/rpi-docker-tensorflow\nHope this helps,\nlisa. See: https://github.com/Microsoft/ELL/issues/14 for details.\nTo compile models for Raspberry Pi 3, check out the tutorial instructions, starting with compile.md.. Hi @alan-gu, let us know if this doesn't works for you.  We'll close out the issue in the meantime.. No longer needed. Thanks for submitting the PR that highlights this issue!. Hi,\nCompared to the darknetReference model, the vgg16 model is much larger.  As a result, compiling it on the PC (regardless of target) will take quite a while.\n```\n[100%] Compiling vgg16ImageNet.ll to /home/codelast/programme/pi/ELL/build/tutorials/vision/gettingStarted/compiled_vgg16ImageNet_pi3/vgg16ImageNet.o for pi3\nKilled\n````\nWhat the error message shows above is probably your compiler taking a very long time (which is expected for vgg).  \nWe are aware of this limitation of off-the-shelf models, and working on coming up with smaller models that work better for embedded devices.  For now, I recommend sticking to darknetReference, which is a smaller and more manageable size. \n. No longer needed. Thanks for submitting the PR that highlights this issue!. I see your post on Raspberry Pi / Stack Exchange: https://raspberrypi.stackexchange.com/questions/70261/cant-install-miniconda-3\nUnfortunately I don't have more helpful information to give, because this is part of the installation script created by Continuum / Anaconda.  It's a blob to us....\nIf you haven't done so already, try the -f option (see https://conda.io/docs/troubleshooting.html#fix-broken-conda), and also try a brand new Raspberry Pi SD card image to rule out other environment issues.\n(Closing this issue because it's not specific to ELL, but we'll monitor the stackexchange thread to see if there are responses). Hi, please start with the steps in darknet.md, which will run the model on your desktop and generate the .map file.. Hi,\nThanks for bringing this up and glad the tutorial examples worked for you!  We've been focused more on the tutorials because they help demonstrate a real use case.  \nAs a result, the examples/compiled_code stuff are out of date, and probably need a revamp.\n. Ah, I get your question now.  \nIf you look at cntkDemo.py and darknetDemo.py, you'll see the models being imported from the python scripts.  Basically, the idea is you pass model files (from CNTK or darknet) you want to try to those scripts.  It should be pretty clear from the script where you can pass in your own model files, just look for these lines:\n```\n    # Pick the model you want to work with\n    helper = mh.ModelHelper(sys.argv, \"darknetReference\", [\"darknet.cfg\", \"darknet.weights\"], \"darknetImageNetLabels.txt\")\n# Import the model\nmodel = get_ell_predictor(helper)\n\n```\nAt this time we've only verified darknetReference and vgg16, but you can always pass in a different model from either framework.  \nKeep in mind though that some of the other models (e.g. tiny-yolo) are huge, which makes it harder to compile and link against.  We're aware of this issue with off the shelf models, and are working to resolve it.  For now, I recommend choosing models that are similar in size with darknet.weights for best results.. (Updated the title, thanks for the feedback)\nThe compile and llc commands are documented in compilingAdvanced. The commands are written for a Windows host machine, but you should be able to adapt for a Linux or Mac host machine.. Correct, for non-Windows (i.e. Linux and Mac), the compile executable is in the build/bin folder.  \nFor Windows, you add the \"Release\" or \"Debug\" subfolders because of the way Visual Studio generates the configurations. . Hi,\npython 3.4.3 should be ok on the Raspberry Pi3, because that's what the Miniconda environment currently supports.\nThe \"cblas_dgemm\" undefined symbol is potentially an incorrect set blas libs on your pi system.  For example, another version of blas or libatlas taking precedence over openblas and getting picked up by cmake.\nTake a look at these issues to see if they help: https://github.com/Microsoft/ELL/issues?utf8=%E2%9C%93&q=is%3Aissue%20cblas_dgemm\nIn particular, check whether libblas.so has that symbol defined.  If not, and if you did run \"sudo apt-get install libopenblas-dev\", then check whether there are other blas .so that have the correct symbol.\n. Thanks for verifying that you have the right lib. The only other thing I can think of is that your conda environment is somehow not finding the .so at runtime.  \nDoes your LD_LIBRARY_PATH contain /usr/lib?\n\nFile \"/root/.miniconda3/envs/py34/lib/python3.4/importlib/init.py\", line 109, in import_module\nreturn _bootstrap._gcd_import(name[level:], package, level)\nImportError: build/_darknetReference.so: undefined symbol: cblas_sgemm. Great to see you found a fix!. This error means that _ELL.so was compiled with a different (likely newer) version of libstdc++.so.6 from what miniconda knows about. Miniconda has its own links to libstdc++ that it uses to build packages, etc.\n\nImportError: /home/zxd/miniconda3/envs/py36/lib/python3.6/site-packages/../../libstdc++.so.6: version CXXABI_1.3.9' not found (required by ./../../../../build/interfaces/python/_ELL.so)\nThere are a couple of ways to fix this, but the least intrusive method in my experience is to:\n1. Make sure you have the library somewhere (you should have it on the system since you built _ELL.so)\n2. export LD_LIBRARY_PATH=path_to_that_libstdc++.so:$LD_LIBRARY_PATH\nThen re-run the demo.\n. This is a known issue that we are still investigating. No ETA yet at this time but we are open to suggestions from anyone.. New instructions for Raspberry Pi Zero are now published with release v2.1.5.  . Hi, great to see progress made.  These layers are not yet recognized by the CNTK importer, which focuses more on convolutional networks as a starting point.  \nFor logistic regression, you can try updating tools/importers/CNTK/cntk_to_ell.py to handle the Times and Plus op_names for your model's needs.\nWe are in the process of documenting how to update the importer, and refactoring it to make it easier to update, but here are a few notes to get you started meanwhile:\n\nYou'd want to update get_filtered_layers_list() to recognize Times and Plus op_names, and convert_cntk_layers_to_ell_layers() to do the conversion\nBasically, the Times operation should be handled similarly to ElementTimes, and the Plus operation should be equivalent to adding a ELL Bias layer.  \nSince the importer is written for convolutional networks in mind, you may need to write simple logic to map your rows and columns differently.  \nThe CNTK and ELL layer ordering differ for convolutional networks (CNTK does channels, rows, columns ordering, while ELL does rows, columns channels ordering). \nPadding: get_input_padding_parameters_for_layer: Hopefully your model is simple enough to just assume no padding (the default).\n\n. Glad you found the error and was able to implement the layers you need!. As for your questions:\n\nHow does the neural network implementation work if there is no plus and times operation?\n\nA: we do support ElementTimes and Bias.  Some CNTK layers do similar operations (depending on whether you are calling a function or block), and the convolutional networks that we started on for vision happen not to be using Times and Plus.  We're actually working on adding \"Plus\" in the next release because we've encountered other networks that need it.  The choice of the CNTK layer is done at model design time, and we happened to be using ElementTimes instead of Times.\n\nI have one more question regarding the expected workflow with ELL: Right now I interpret it more as a compiler for cntk models. But basically I could just design the whole model with ELL, right?\nIs there a recommended workflow how to use ELL?\n\nA: You can design a model with ELL from the ground up, especially if the model is fairly simple like what you tried.  However, since ELL doesn't support training (yet), it is often useful to author and train more complex models using CNTK, and then import that model into ELL.  The \"import into ELL\" workflow also applies if you have trained existing models (e.g. darknet).\n. Thanks for reporting these.  We have been mostly running on Ubuntu 64 bit, and will need to investigate these errors that look related to 32-bit.  \nMeanwhile, if it is feasible for you, is it possible for you to use 64 bit?. Hi,\nThis sounds like an incompatibility with the open blas library and your processor.  Are you running an Intel CPU, and if yes, what chipset is it?\nYou can find the logic that's used to infer the processor from here: https://github.com/Microsoft/ELL/blob/master/CMake/OpenBLASSetup.cmake, around line 63. \n. Thanks for the details.  Since your CPU is not one of those supported by our Nuget package (which targets the more common configurations), you can try building OpenBlas for your CPU target and replacing the dlls in your ELL\\external\\OpenBLASLibs.0.2.19.3\\build\\native\\x64 folder.\nInstructions on building OpenBlas are here:\nhttps://github.com/xianyi/openblas/releases. No longer needed.  Thanks for submitting the PR that highlights this issue!. Thanks @codelast for taking the time to do the comparison and posting the results!\nFor accuracy benchmarking, here are a few suggestions on what to try next:\n- Since you are using photos, which is great as a test because it eliminates webcam variances, you can perform the comparison on your desktop machine.  This should save you some time.  Speed comparisons should still be done on the Raspberry Pi though.\n\nFor accuracy, in general you'd want to compare models that are equivalent.  Since ELL basically takes a pre-trained model and compiles it to run faster, the model's accuracy is dependent on how that model is trained.\n\nFor example, for darknetReference, you can compare the accuracy of the original darknetReference model at https://pjreddie.com/darknet/imagenet/ (search for \"Darknet Reference\" on the page for instructions on how to get it up and running) with ELL's compiled version.  TensorFlow doesn't readily have a darknetReference model available because it requires TensorFlow to support importing darknet models.\nIn other words, your comparison can be done this way:\n1. Accuracy (on PC):  original darknetReference (from the pjreddie site) vs. ELL darknetReference\n2. Speed (on PC):  original darknetReference (from the pjreddie site) vs. ELL darknetReference.  If you can use GPU for original darknetReference, I expect the original to be faster.\n3. Speed (on Pi3):  original darknetReference (from the pjreddie site) vs. ELL darknetReference.  I'm not sure if the original supports compiling on the Pi3 though. \nIdeally, it will be nice to be able to compare ELL(Inception v3 model) with TensorFlow(Inception v3 model).  This is good feedback but not yet supported.  \n. Hi, \nThis error is not obvious, but it typically means that the image input is invalid.  If this is the script from the tutorial (running on the host, not on the Raspberry Pi), this error means that coffeemug.jpg is not found.  \nTry downloading coffemug.jpg from the tutorial (there should be a link to it) and saving it to the same folder location of your script.  \nlisa\nPS: OpenCV's cv2.imread doesn't actually fail if the file isn't found, but one enhancement that can be made to the script is to check (via Python) whether the file exists before feeding it to OpenCV.\n. Hi Ivan,\nWhat model did you use for the import? \nFrom the error text file, this is a different model architecture from the VGG16_ImageNet_Caffe.model referenced in the tutorial.  Maybe one of the RELU layers in the model you've used is not being imported correctly.\n. I should have been clearer, the cntk.model that you used has this architecture:\nConvolution : 226x226x3 -> 224x224x64 | input padding 1 output padding 0\nReLU : 224x224x64 -> 226x226x64 | input padding 0 output padding 1\nConvolution : 226x226x64 -> 224x224x64 | input padding 1 output padding 0\nReLU : 224x224x64 -> 224x224x64 | input padding 0 output padding 0\nMaxPooling : 224x224x64 -> 114x114x64 | input padding 0 output padding 1\nConvolution : 114x114x64 -> 112x112x128 | input padding 1 output padding 0\nReLU : 112x112x128 -> 114x114x128 | input padding 0 output padding 1\nConvolution : 114x114x128 -> 112x112x128 | input padding 1 output padding 0\nReLU : 112x112x128 -> 112x112x128 | input padding 0 output padding 0\nMaxPooling : 112x112x128 -> 58x58x128 | input padding 0 output padding 1\nConvolution : 58x58x128 -> 56x56x256 | input padding 1 output padding 0\nReLU : 56x56x256 -> 58x58x256 | input padding 0 output padding 1\nConvolution : 58x58x256 -> 56x56x256 | input padding 1 output padding 0\nReLU : 56x56x256 -> 58x58x256 | input padding 0 output padding 1\nConvolution : 58x58x256 -> 56x56x256 | input padding 1 output padding 0\nReLU : 56x56x256 -> 56x56x256 | input padding 0 output padding 0\nMaxPooling : 56x56x256 -> 30x30x256 | input padding 0 output padding 1\nConvolution : 30x30x256 -> 28x28x512 | input padding 1 output padding 0\nReLU : 28x28x512 -> 30x30x512 | input padding 0 output padding 1\nConvolution : 30x30x512 -> 28x28x512 | input padding 1 output padding 0\nReLU : 28x28x512 -> 30x30x512 | input padding 0 output padding 1\nConvolution : 30x30x512 -> 28x28x512 | input padding 1 output padding 0\nReLU : 28x28x512 -> 28x28x512 | input padding 0 output padding 0\nMaxPooling : 28x28x512 -> 16x16x512 | input padding 0 output padding 1\nConvolution : 16x16x512 -> 14x14x512 | input padding 1 output padding 0\nReLU : 14x14x512 -> 16x16x512 | input padding 0 output padding 1\nConvolution : 16x16x512 -> 14x14x512 | input padding 1 output padding 0\nReLU : 14x14x512 -> 16x16x512 | input padding 0 output padding 1\nConvolution : 16x16x512 -> 14x14x512 | input padding 1 output padding 0\nReLU : 14x14x512 -> 14x14x512 | input padding 0 output padding 0\nMaxPooling : 14x14x512 -> 7x7x512 | input padding 0 output padding 0\nReLU : 1x1x4096 -> 1x1x4096 | input padding 0 output padding 0\nReLU : 1x1x4096 -> 1x1x4096 | input padding 0 output padding 0\nSoftmax : 1x1x1000 -> 1x1x1000 | input padding 0 output padding 0\nIs your cntk.model the downloaded VGG16_ImageNet_Caffe.model, or another model?\nlisa\n. Where did you download your model.cntk file?. Okay, will take a look.\n\nFrom: Ivan Farkas notifications@github.com\nSent: Friday, November 10, 2017 4:12:12 AM\nTo: Microsoft/ELL\nCc: Lisa Ong; Comment\nSubject: Re: [Microsoft/ELL] Importing models tutorial - CNTK model conversion fails (#110)\nI am just following your playbookhttps://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fmicrosoft.github.io%2FELL%2Ftutorials%2FImporting-models%2F&data=02%7C01%7Clisaong%40microsoft.com%7Cbbb9bfebde024ca16cb408d52834469a%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636459127373837820&sdata=cp5Oq7P%2FtKrcN4bwtsgsII3g721%2FpN4EN%2Bq0lrvjlgQ%3D&reserved=0.\nStep1 - Get CNTK model VGG16_ImageNet_Caffe.model\n(py36) C:\\ML\\EEL\\Tutorial\\Importing_Models>curl --location -o model.cntk https://www.cntk.ai/Models/Caffe_Converted/VGG16_ImageNet_Caffe.model\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  527M  100  527M    0     0  5657k      0  0:01:35  0:01:35 --:--:-- 4610k\nStep 2 - Get categories.txt\n(py36) C:\\ML\\EEL\\Tutorial\\Importing_Models>curl --location -o categories.txt https://raw.githubusercontent.com/Microsoft/ELL-models/master/models/ILSVRC2012/ILSVRC2012_labels.txt\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0    120      0 --:--:-- --:--:-- --:--:--   120\nStep 3 - Run cntk_import.py\n(py36) C:\\ML\\EEL\\Tutorial\\Importing_Models>python C:/ML/EEL/ELL/tools/importers/cntk/cntk_import.py model.cntk\nLoading...\nSelected CPU as the process wide default device.\nFinished loading.\nPre-processing...\nWill not process linear - skipping this layer as irrelevant.\nWill not process Dropout - skipping this layer as irrelevant.\nWill not process linear - skipping this layer as irrelevant.\nWill not process Dropout - skipping this layer as irrelevant.\nWill not process linear - skipping this layer as irrelevant.\nWill not process Combine - skipping this layer as irrelevant.\nConvolution : 226x226x3 -> 224x224x64 | input padding 1 output padding 0\nReLU : 224x224x64 -> 226x226x64 | input padding 0 output padding 1\nConvolution : 226x226x64 -> 224x224x64 | input padding 1 output padding 0\nReLU : 224x224x64 -> 224x224x64 | input padding 0 output padding 0\nMaxPooling : 224x224x64 -> 114x114x64 | input padding 0 output padding 1\nConvolution : 114x114x64 -> 112x112x128 | input padding 1 output padding 0\nReLU : 112x112x128 -> 114x114x128 | input padding 0 output padding 1\nConvolution : 114x114x128 -> 112x112x128 | input padding 1 output padding 0\nReLU : 112x112x128 -> 112x112x128 | input padding 0 output padding 0\nMaxPooling : 112x112x128 -> 58x58x128 | input padding 0 output padding 1\nConvolution : 58x58x128 -> 56x56x256 | input padding 1 output padding 0\nReLU : 56x56x256 -> 58x58x256 | input padding 0 output padding 1\nConvolution : 58x58x256 -> 56x56x256 | input padding 1 output padding 0\nReLU : 56x56x256 -> 58x58x256 | input padding 0 output padding 1\nConvolution : 58x58x256 -> 56x56x256 | input padding 1 output padding 0\nReLU : 56x56x256 -> 56x56x256 | input padding 0 output padding 0\nMaxPooling : 56x56x256 -> 30x30x256 | input padding 0 output padding 1\nConvolution : 30x30x256 -> 28x28x512 | input padding 1 output padding 0\nReLU : 28x28x512 -> 30x30x512 | input padding 0 output padding 1\nConvolution : 30x30x512 -> 28x28x512 | input padding 1 output padding 0\nReLU : 28x28x512 -> 30x30x512 | input padding 0 output padding 1\nConvolution : 30x30x512 -> 28x28x512 | input padding 1 output padding 0\nReLU : 28x28x512 -> 28x28x512 | input padding 0 output padding 0\nMaxPooling : 28x28x512 -> 16x16x512 | input padding 0 output padding 1\nConvolution : 16x16x512 -> 14x14x512 | input padding 1 output padding 0\nReLU : 14x14x512 -> 16x16x512 | input padding 0 output padding 1\nConvolution : 16x16x512 -> 14x14x512 | input padding 1 output padding 0\nReLU : 14x14x512 -> 16x16x512 | input padding 0 output padding 1\nConvolution : 16x16x512 -> 14x14x512 | input padding 1 output padding 0\nReLU : 14x14x512 -> 14x14x512 | input padding 0 output padding 0\nMaxPooling : 14x14x512 -> 7x7x512 | input padding 0 output padding 0\nReLU : 1x1x4096 -> 1x1x4096 | input padding 0 output padding 0\nReLU : 1x1x4096 -> 1x1x4096 | input padding 0 output padding 0\nSoftmax : 1x1x1000 -> 1x1x1000 | input padding 0 output padding 0\nFinished pre-processing.\nError occurred attempting to convert cntk layers to ELL layers\nTraceback (most recent call last):\n  File \"C:/ML/EEL/ELL/tools/importers/cntk/cntk_import.py\", line 59, in \n    main(sys.argv[1:]) # drop the first argument (program name)\n  File \"C:/ML/EEL/ELL/tools/importers/cntk/cntk_import.py\", line 44, in main\n    predictor = cntk_to_ell.predictor_from_cntk_model(filename)\n  File \"C:\\ML\\EEL\\ELL\\tools\\importers\\cntk\\cntk_to_ell.py\", line 53, in predictor_from_cntk_model\n    raise exception\n  File \"C:\\ML\\EEL\\ELL\\tools\\importers\\cntk\\cntk_to_ell.py\", line 50, in predictor_from_cntk_model\n    predictor = ELL.FloatNeuralNetworkPredictor(ellLayers)\n  File \"C:\\ML\\EEL\\ELL\\build\\interfaces\\python\\ELL.py\", line 4448, in init\n    this = _ELL.new_FloatNeuralNetworkPredictor(layers, scaleFactor)\nValueError: Input tensor must not exceed output tensor (minus padding) dimensions for activation layer.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHubhttps://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FMicrosoft%2FELL%2Fissues%2F110%23issuecomment-343457985&data=02%7C01%7Clisaong%40microsoft.com%7Cbbb9bfebde024ca16cb408d52834469a%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636459127373837820&sdata=eaj1zhHbwfBMgoiEDnuX8HjLnwyYd7YRnB6hIoasiqc%3D&reserved=0, or mute the threadhttps://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAKyz4aYk-VsLSXVSMTpl_Crzi3pMAn-Mks5s1D2cgaJpZM4QR8wy&data=02%7C01%7Clisaong%40microsoft.com%7Cbbb9bfebde024ca16cb408d52834469a%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636459127373837820&sdata=COxz1hYGPJ3x03d6zJv25ZZQHCDcDMSL%2FL%2BqhNP0%2BCE%3D&reserved=0.\n. Thanks for reporting this! Fix is on the way, but if you don't feel like waiting, here's a diff that shows the change:\nELL/tools/importers/CNTK/lib/cntk_layers.py, around line 922:\n```\n<< elif (cntkLayer.op_name == 'Linear'):\n\n\nelif (cntkLayer.op_name == 'linear'):  # this op_name must be lower-case\n```\n. Fixed in v2.0.5. @IvanFarkas, we use this repo to build opencv conda packages for armv71 (Jessie).  You can fork it as a starting point for your Stretch package.  \n\n\nThe opencv3 folder contains a build script that you can either customize or fork.\nhttps://github.com/lisaong/raspberrypi-conda-recipes\n. As you noted, there's some incompatibility between how the Dense layers are being converted from Keras to CNTK, because the model imports to ELL fine if constructed using CNTK directly.\nThis will require some debugging to compare the two models.  Maybe the attributes on the Dense layer are set up differently for the Keras-imported model.\n. I couldn't add more reviewers besides @lovettchris , so I assigned the PR to @kernhanda as well. The darknet_InputCallback and darknet_OutputCallback errors are now fixed with release v2.1.5\nFor the cblas_sgemm error, looks like you're missing OpenBLAS libraries.  If you search the issues, there should be a few examples of how to fix this. \ndarknet.obj : error LNK2019: in function 'darknet_Predict', undefined reference to 'cblas_sgemm';\nIn particular, to troubleshoot this, check what the output of cmake .. spews.  It should find the path to OpenBlas libs.. Are you running from within a conda environment?  From the spew, looks like you are running the system-installed python.\nactivate py36\npython .../darknet_import.py darknet.cfg darknet.weights\n. I see, can you compare what's under these folders? \ndir /s E:\\ELL_20171228\\build\\interfaces\\python\\package\\ell\ndir /s E:\\ELL_20180109\\build\\interfaces\\python\\package\\ell. Thanks for reporting this.  There has been an update to the C++ interface but the tutorial has not yet caught up. We'll be fixing this hopefully within the next couple days.. Hi, can you describe what \"old style\" model means?. Thanks for the clarification, will take a look and get back shortly. Hi! This is now fixed with v2.2.0. . Hi, as you may have found online, this error happens on Macs when various versions of python conflict. \nAs this is a setup problem with the Mac environment, here are some references that may help:\nhttps://github.com/snap-stanford/snap/issues/88\n...which points to this more detailed troubleshooting guide for something else, but may help you here:\nhttps://docs.google.com/document/d/1ODvtQsJgiTOJH4-qBqwa6eAvoNJoiALqnk2pxFf1IzY/edit\n. On macOS Sierra, I managed to get around the PyThreadState_Get: no current thread error by using Homebrew's version of python3 (and libs) instead of Anaconda's.  Somehow, the Anaconda libs and Homebrew's libs are incompatible (as hinted by this thread: https://code.activestate.com/lists/python-list/1807/)\n\nbrew install python3\nIf you had anaconda installed, edit .bash_profile to \"demote\" Anaconda's python:\nsudo nano ~/.bash_profile\n```\n\nadded by Anaconda3 5.0.1 installer\nexport PATH=\"/anaconda3/bin:$PATH\"\nexport PATH=\"$PATH:/anaconda3/bin\"\n3. Re-run cmake and check that PythonInterp and PythonLibs point to Homebrew's python3:\n-- PYTHONINTERP_FOUND=TRUE\n-- PYTHON_EXECUTABLE=/usr/local/bin/python3.6\n-- PYTHON_VERSION_STRING=3.6.4\n-- PYTHON_VERSION_MAJOR=3\n-- PYTHONLIBS_FOUND=TRUE\n-- PYTHON_LIBRARIES=/usr/local/Frameworks/Python.framework/Versions/3.6/lib/libpython3.6m.dylib\n-- PYTHON_INCLUDE_PATH=/usr/local/Frameworks/Python.framework/Versions/3.6/include/python3.6m\n-- PYTHON_INCLUDE_DIRS=/usr/local/Frameworks/Python.framework/Versions/3.6/include/python3.6m\n-- PYTHON_DEBUG_LIBRARIES=\n-- PYTHONLIBS_VERSION_STRING=3.6.4\n``\n4.makeandmake _ELL_python5. When running tools like wrap.py, callpython3instead ofpython` (the latter defaults to python2.7). \nThis workaround doesn't use virtualenvs, which means stuff like NumPy will need to be installed via pip3 install numpy, instead of conda install numpy.   It's not as contained as a virtualenv,  but at least things should run.\n. I've seen this exception when I've accidentally run python 2.7 instead of python 3.6.  Type \"which python\" in your command line, or try:\npython3 <ELL-root>/tools/wrap/wrap.py model.ell -lang python -target host\n. @lovettchris, do you mind taking a look? . Interim PR on my fork master (to trigger Travis CI): https://github.com/lisaong/ELL/pull/1\nExample Travis CI job: https://travis-ci.com/lisaong/ELL/builds/73653563\n. Aborting this PR in favor of splitting into two separate PRs: one for the build break fix, and one for adding Travis. @cjacobs , do you mind taking a look? . Great! Feel free to merge the PR when ready.. @kernhanda , do you mind taking a look?. @kernhanda, to your question below, the Ubuntu docker image is based on continuumio/miniconda3:latest (see ELL/Dockerfile)\nFollowing the trail, this is debian:latest (https://hub.docker.com/r/continuumio/miniconda3/~/dockerfile/). Hopefully you can squash merge to keep the history clean.\nIn case you weren't planning to do this, this repo will need to have travis setup in order for the CI workflow to actually kick in. Right now the checks are not setup.. Note: s/python/Python/g when writing text, i.e.\nline 33: \"here we install Python 3.4 directly ...\"\nand\nline 35: \"To install Python 3.4 on Raspbian Jessie...\". Move \"To install OpenBLAS, type the following.\" to line 47, or the end of line 46. . typo. Will be helpful to add a link to /tutorials/Setting-up-Raspberry-Pi-Zero-W here.. Need this first:\nsudo pip3 install cython -v\nsudo apt-get install -y gfortran\nWorth noting that the compilation of Cython seems to take a while on the Pi Zero.. Conda => Anaconda\na conda tool => an Anaconda tool. sudo python3 setup.py install. these apt-get install commands should specify -y\n. Add this to the beginning (to avoid cloning numpy in OpenBlas):\ncd ~. On my vanilla Pi Zero W with a clean Jessie image, the compiler/linker keep running out of memory or getting internal compiler error. \nTo avoid that, add this blurb before calling \"make\":\nBefore compiling OpenCV, increase the size of the swap file on the Pi Zero.\nsudo nano /etc/dphys-swapfile\nAdd this line:\nCONF_SWAPSIZE=1024\nsudo /etc/init.d/dphys-swapfile stop\nsudo /etc/init.d/dphys-swapfile start. I would put pi0 after pi3 and before orangepi0, for consistency. I'm not sure, because I didn't see this issue... . In any case, that troubleshooting instruction didn't work for me in a clean setup, so I removed it.  We can always add it back later.. will need to update to ELL's official account. @kernhanda is there an ELL dockerhub account that the image can be pushed to? Otherwise, I don't mind using my account for now.. no worries. we can park it there a long as you need.. ",
    "clovett": "Looks like your GCC setup is broken, notice the cmake output:\n\nThe C++ compiler \"/usr/bin/gcc\" is not able to compile a simple test program\n\nThis is what your cmake output should look like on Ubuntu 16.04:\n-- The C compiler identification is GNU 5.4.0\n-- The CXX compiler identification is GNU 5.4.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Looking for pthread_create in pthreads\n-- Looking for pthread_create in pthreads - not found\n-- Looking for pthread_create in pthread\n-- Looking for pthread_create in pthread - found\n-- Found Threads: TRUE\n-- Blas libraries: /usr/lib/libblas.so\n-- Blas linker flags:\n-- Blas include directories:\n-- Using BLAS include path: /usr/include\n-- Using BLAS library: /usr/lib/libblas.so\n-- Using BLAS DLLs:\n-- Found PythonInterp: /usr/bin/python (found version \"2.7.12\")\n-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython2.7.so (found version \"2.7.12\")\n-- Found SWIG: /usr/local/bin/swig (found suitable version \"3.0.12\", minimum required is \"3.0.12\")\nCMake Warning at interfaces/python/CMakeLists.txt:9 (message):\n  Couldn't find Python libraries 3.5 or later, _ELL_python target will not be\n  build properly.  This is not a required component, so it can be skipped.\n-- Creating wrappers for python\n-- Creating wrappers for javascript\n-- Creating wrappers for xml\n-- Using python found at: /usr/bin/python\n-- Using python libraries found at: /usr/lib/x86_64-linux-gnu/libpython2.7.so\n-- Creating wrappers for python\nCMake Warning at CMakeLists.txt:134 (message):\n  Doxygen processor not found\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /mnt/d/git/ELL/ELL/linux\n. Are you compiling ELL with Visual Studio 2015?  Since you are on windows you can run 'depend.exe' to see what dll is missing, run it on the _ELL.pyd module.  In case you don't have that handy tool, I attached it here:\nDepends.zip\n. Ah, those are windows redirect dlls you can ignore those, but did any show up with yellow icons?  Let's also check that you actually built ELL.py and _ELL.pyd by running the following the additional steps listed in the interfaces readme.\n. For example, if you see this:\n\nThen you should get this output when you try and run the demo:\n(py35) D:\\git\\ELL\\ELL\\build\\tutorials\\vision\\gettingStarted>python darknetDemo.py\n====================================================================\nELL module is not loading\nIt is possible that you need to add LibOpenBLAS to your system path (See Install-*.md) from root of this repo\nWe have Intel versions here: D:\\git\\ELL\\ELL\\external\\OpenBLASLibs.0.2.19.2\\build\\native\\x64\nYou need to use the one that matches your computer chip model\n   'haswell' works for haswell and broadwell chips\n   'sandybridge' works for sandy bridge and ivy bridge chips\n====================================================================\nIf this is the case then you need to do this:\nset PATH=%PATH%;D:\\git\\ELL\\external\\OpenBLASLibs.0.2.19.2\\build\\native\\x64\\haswell\\bin\n(change the path to point to your ELL git repo location, and switch to \"sandybridge\\bin\" if the above doesn't work).. Ah yes, there is one more step for building Python wrappers, it is described in the interfaces readme.. You are right we are missing these steps in the readme:\nmkdir build\ncd build\nThen run cmake.  We do have the VS 2017 command line in the readme. But I'll get the above added.. Weird, I'm not getting this error.  But my build built things in a different order, it did \"emitters\" after \"data\", so I wonder if that's why it found the header.  The file lives here:\n./libraries/emitters/include/EmitterTypes.h\nThe ./libraries/model/CMakeLists.txt contains:\ntarget_include_directories(${library_name} PUBLIC include)\nSo I wonder if adding this include path will help make it less dependent on build order:\ntarget_include_directories(${library_name} PUBLIC include ../emitters/include)\n. compile_darknetReference.cmd  is gone, there is a new way to do that now if you sync to the latest bits.. Already fixed in latest updates, and this info has moved to top level INSTALL-xxx.md pages.. Already fixed in latest updates, and this info has moved to top level INSTALL-xxx.md pages.. Two separate questions here:\n1) performance\n2) using tiny-yolo.cfg & tiny-yolo.weights\nOn performance, you should look into the compiling steps which will create a faster executable.  The \"darknetDemo.py\" script is a model test loader that is not optimized the same way.  \nUsing tiny-yolo will require updating the provided darknetImageNetLabels.txt.  These labels match what is expected by darknet.cfg & darknet.weights which is probably why the self.labels[...] array index was out of range.\n. This is why we recommend miniconda or anaconda on our INSTALL-Ubuntu readme instructions.  This app is cool because it can setup an \"conda environment\" for a selected python version, then cmake will find the right version.. ELL needs to be installed as per our README, but once installed ELL can produce a compiled package in a directory that executes a given CNN model for a specified target platform.  This is what compiling is all about.  Think of ELL as a CNN compiler.. Already fixed in latest updates.. Can you run this opencv test to see if your camera works?\n```\nimport numpy as np\nimport cv2\ncap = cv2.VideoCapture(0)\nwhile True:\n    ret, frame = cap.read()\n    if (ret == False):\n        print(\"Error reading from camera\")\n        break\n    cv2.imshow('frame',frame)\n    key = cv2.waitKey(1) & 0xFF;\n    if (key == 27 or key == ord('q') or key == ord('x')):\n        break;\ncap.release()\ncv2.destroyAllWindows()\n```. Thanks for the pointer, I agree we should use \"vswhere.exe\" to handle VS 2017 setup.. No, ELL is not a CNN training system, it is a compiler for CNN's (and other ML algorithms) that optimizes the execution of a pre-trained model on a given target platform with a focus on embedded platforms, like Raspberry Pi.  ELL currently supports importing trained models from CNTK and darknet.. what happens if you run the \"rebuild.cmd\" script instead?. Those are the tests that depend on Python.  Try launching the ell.sln from your Anaconda Command Prompt so that the ctest process can find the right Python environment.  This is what I see when I do that:\n```\n1>------ Build started: Project: RUN_TESTS, Configuration: Release x64 ------\n1>Test project D:/git/ELL/ELL/build\n1>      Start  1: common_test\n1> 1/39 Test  #1: common_test ......................   Passed    0.20 sec\n1>      Start  2: data_test\n1> 2/39 Test  #2: data_test ........................   Passed    0.02 sec\n1>      Start  3: dsp_test\n1> 3/39 Test  #3: dsp_test .........................   Passed    5.09 sec\n1>      Start  4: emitters_test\n1> 4/39 Test  #4: emitters_test ....................   Passed    0.17 sec\n1>      Start  5: evaluators_test\n1> 5/39 Test  #5: evaluators_test ..................   Passed    0.01 sec\n1>      Start  6: functions_test\n1> 6/39 Test  #6: functions_test ...................   Passed    0.02 sec\n1>      Start  7: math_test\n1> 7/39 Test  #7: math_test ........................   Passed    0.05 sec\n1>      Start  8: model_test\n1> 8/39 Test  #8: model_test .......................   Passed    0.03 sec\n1>      Start  9: model_compiler_test\n1> 9/39 Test  #9: model_compiler_test ..............   Passed    4.70 sec\n1>      Start 10: nodes_test\n1>10/39 Test #10: nodes_test .......................   Passed    0.05 sec\n1>      Start 11: dsp_nodes_test\n1>11/39 Test #11: dsp_nodes_test ...................   Passed   20.34 sec\n1>      Start 12: nn_nodes_test\n1>12/39 Test #12: nn_nodes_test ....................   Passed    0.03 sec\n1>      Start 13: passes_test\n1>13/39 Test #13: passes_test ......................   Passed    0.03 sec\n1>      Start 14: predictors_test\n1>14/39 Test #14: predictors_test ..................   Passed    0.02 sec\n1>      Start 15: trainers_test\n1>15/39 Test #15: trainers_test ....................   Passed    0.01 sec\n1>      Start 16: utilities_test\n1>16/39 Test #16: utilities_test ...................   Passed    0.90 sec\n1>      Start 17: cntk_importer_test\n1>17/39 Test #17: cntk_importer_test ...............   Passed   97.27 sec\n1>      Start 18: darknet_importer_test\n1>18/39 Test #18: darknet_importer_test ............   Passed    1.43 sec\n1>      Start 19: forestTrainer_test\n1>19/39 Test #19: forestTrainer_test ...............   Passed    0.02 sec\n1>      Start 20: linearTrainer_test_0\n1>20/39 Test #20: linearTrainer_test_0 .............   Passed    0.02 sec\n1>      Start 21: linearTrainer_test_1\n1>21/39 Test #21: linearTrainer_test_1 .............   Passed    0.03 sec\n1>      Start 22: linearTrainer_test_2\n1>22/39 Test #22: linearTrainer_test_2 .............   Passed    0.02 sec\n1>      Start 23: linearTrainer_test_3\n1>23/39 Test #23: linearTrainer_test_3 .............   Passed    0.02 sec\n1>      Start 24: linearTrainer_test_4\n1>24/39 Test #24: linearTrainer_test_4 .............   Passed    0.02 sec\n1>      Start 25: linearTrainer_test_5\n1>25/39 Test #25: linearTrainer_test_5 .............   Passed    0.02 sec\n1>      Start 26: linearTrainer_test_6\n1>26/39 Test #26: linearTrainer_test_6 .............   Passed    0.02 sec\n1>      Start 27: linearTrainer_test_7\n1>27/39 Test #27: linearTrainer_test_7 .............   Passed    0.02 sec\n1>      Start 28: linearTrainer_test_8\n1>28/39 Test #28: linearTrainer_test_8 .............   Passed    0.02 sec\n1>      Start 29: linearTrainer_test_9\n1>29/39 Test #29: linearTrainer_test_9 .............   Passed    0.02 sec\n1>      Start 30: linearTrainer_test_10\n1>30/39 Test #30: linearTrainer_test_10 ............   Passed    0.02 sec\n1>      Start 31: protoNNTrainer_test_0\n1>31/39 Test #31: protoNNTrainer_test_0 ............   Passed    0.14 sec\n1>      Start 32: sweepingSGDTrainer_test\n1>32/39 Test #32: sweepingSGDTrainer_test ..........   Passed    0.02 sec\n1>      Start 33: apply_test\n1>33/39 Test #33: apply_test .......................   Passed    0.02 sec\n1>      Start 34: compile_test1\n1>34/39 Test #34: compile_test1 ....................   Passed    0.03 sec\n1>      Start 35: compile_test2\n1>35/39 Test #35: compile_test2 ....................   Passed    0.03 sec\n1>      Start 36: make_profiler_test\n1>36/39 Test #36: make_profiler_test ...............   Passed   33.71 sec\n1>      Start 37: wrap-test\n1>37/39 Test #37: wrap-test ........................   Passed   37.28 sec\n1>      Start 38: ell-python-interface-test\n1>38/39 Test #38: ell-python-interface-test ........   Passed    1.67 sec\n1>      Start 39: ell_module_test\n1>39/39 Test #39: ell_module_test ..................   Passed    0.16 sec\n1>\n1>100% tests passed, 0 tests failed out of 39\n1>\n1>Total Test time (real) = 203.94 sec\n========== Build: 1 succeeded, 0 failed, 1 up-to-date, 0 skipped ==========\n``. Cool, yeah, sorry about the missing libjasper, couldn't figure out how to build OpenCV with that properly included.  We removed the \"default\" install of OpenCV which you would get with your original command lineconda install -c microsoft-ell opencv -y` because if we provide a default then you can't install the jessie version any more, some weird conda limitation...  But you found the right path.  We have updated docs coming that will make all this more clear.. We don't normally build ELL itself on raspberry Pi zero, because ELL is actually a cross-compiler, you can build \"ELL Models to run on raspberry pi\" by using \"ELL on your PC\".   but if you really do want to compile ELL on the pi0, you may need to upgrade your GCC compiler to 6.4.  It could also be the compiler needs some swap space.  . This error message usually means our importer ran into a \"layer\" type that is not supported yet.  In this case it seems to be complaining about the \"Pooling\" layer, which is odd, because I'm pretty sure we do support importing CNTK Pooling layers. But if you look at the cntk_converter_map in cntk_to_ell.py you will see it lists AveragePooling and MaxPooling, but not just \"Pooling\" so perhaps that is the problem.  But then when I look at the CNTK docs  I don't see \"Pooling\" listed, I only see AveragePooling and MaxPooling.  So this will take some debugging.  If you put a breakpoint on this import process can you print out more details about the CNTK layer being imported?. I found a bug in the retarget trainer, a fix is on the way.... Interesting data, thanks.  This is a skylake processor which we haven't tested well.  Can you print your PROCESSOR_IDENTIFIER number, I suspect it is model 42 which we've mapped to the \"sandybridge\" version of OpenBLAS.  So to setup your PATH correctly you would do this:\nset PATH=%PATH%;D:\\git\\ELL\\ELL\\external\\OpenBLASLibs.0.2.19.3\\build\\native\\x64\\sandybridge\\bin. Very interesting that a model copied from your desktop runs fine.  This indicates it is not an OpenBLAS problem, but instead a code generation problem which is really odd, we haven't seen that with Intel CPU's, normally our LLVM backend is very reliable about generating good code...  So can you also print PROCESSOR_IDENTIFIER environment variable from your desktop PC ? And does the desktop also have OpenBLAS setup ?  I wonder if PC was build a non-openBLAS version for some reason.... First Azure IoT Edge is a product, whereas ELL is research.  We are researching how to maximize the speed of a model that runs on tiny hardware, all the way down to Cortex-M4 class chips and therefore also how to minimize the size of these models and how to fit them into memory constrained devices.  As we make progress on this front we've love to see our ideas get incorporated into products, including Azure IoT Edge.  The Azure Iot Dev Kit with the MXCHIP board is a great example.  We have ELL compiled Audio Keyword Spotting models running on this device.  I don't believe Azure IoT Edge can remotely provision these devices yet, but hey, that would be great too.  Combined this with Azure Sphere and provide a full ALM story around managing your models and sending as much intelligence to your edge devices as possible.  We envision some day the cloud being able to intelligently decide which models to run in the cloud and which to run on the device, and even better if the device models could be automatically derived from the big models and performance tuned to run on the devices.  Imagine something like the Ring Doorbell, where the cloud can send some intelligence to the device, the device might then tell the cloud \"I think a person is standing at the front door\" and the cloud then gets involved and verifies this with a bigger more reliable model.  This kind of hybrid approach takes the best of both worlds with cloud and intelligent device working together to provide the most cost effective and intelligent solution for customers.  So ELL is researching all this and providing open source to help facilitate community involvement as we push towards this vision.  . oops, yeah, steppable api support has changed, so we need to fix the tutorial, but there's a work around. I pushed a new version of the model that is not \"steppable\" so the tutorial works again.  If you re-run this step it should work now:\ncurl --location -o model.ell.zip https://github.com/Microsoft/ELL-models/raw/master/models/ILSVRC2012/d_I224x224x3CMCMCMCMCMCMC1AS/d_I224x224x3CMCMCMCMCMCMC1AS.ell.zip\n. This is also now a new Azure IoT devkit sample.. Have you tried loading the CMakeLists.txt directly (VS now supports cmake directly).  If that doesn't work you can probably find the cmake generator manually using the version of cmake that comes with VS.  If you type \"cmake -G\" you will see the list of supported VS versions under Generators, I'm guessing it will be named \"Visual Studio 16 2019 Win64\" and then you might be able to do this in the ELL folder :\nmkdir build\ncd build\ncmake -G \"Visual Studio 16 2019 Win64\" ..\ncmake --build . --config Release\nDoes this work for you?. When you rebuild y our VM let's go with VS 2017 this time, then it should be good.. The Azure IOT devkit used in this demo  is actually running Arduino.  The thing is \"Arduino devices\" is ambiguous, Arduino firmware runs on lots of different types of devices these days.  If your device contains an ARM chip then ELL can compile models for that chip.  If it is an ATMEL chip then the current answer is we haven't tried it, so probably not.  It is on our list of things to support, but is not actively being worked on.  ELL uses LLVM and there is an AVR LLVM backend so theoretically it should not be too hard to hook it up.  ELL can generate bitcode, so you should be able to find an LLVM compiler that can compile that bitcode to AVR.  We would love for someone in the community to try it and create a Pull Request.  Having said that don't expect great performance from a typical model unless your chip has good floating point vectorization.  You may need to quantize your models to integer values to get any kind of performance from atmel chips, but ELL does not yet fully support integerized models, so that would be another chunk of work.  The internal ELL nodes are templatized on element type which we use to support float and double, so it should not be too hard to support int as well, but there will be work required in the math library to do integer computation in a way that doesn't loose too much precision.. Cool, thanks for the encouragement.  I'll pass along your request for longer term roadmap.. Well you might be looking for an ELL to C++ option, this would then give you more platform options (any platform that can compile that C++ code), but this is not currently supported.  But it is on our list of things to look into.. Ah, for VS 2017 the cmake command line is different:\ncmake -G \"Visual Studio 15 2017 Win64\"\n. Ah, whenever you see a message like that simply delete the \"build\" folder and start over.. ",
    "barronbarnett": "@ack72tdp \nMake sure G++ is installed.\nIt looks like you're using a docker container. I've created a Dockerfile and repo that has all the proper tools already installed.\nYou can either reference it to fix you're current container or use it as a new starting point. I've also pushed it to docker hub so you can do docker run -ti -v (yourlocalsourcedir):/root barronbarnett/ell_env:latest --name ell_env and docker will pull down the image directly.. ",
    "ack72tdp": "This is great Barron. Docker version worked perfect .. Thanks so much. Appreciate your help... fixed using barron docker container.. that has all tools installed.. Thanks Jacob. It helped move forward bit... However I run into few other issues..\n(py36) root@8fa27a83d7dd:~/ELL/build/tutorials/vision/gettingStarted# python darknetDemo.py\nTraceback (most recent call last):\n  File \"darknetDemo.py\", line 4, in \n    import cv2\nModuleNotFoundError: No module named 'cv2'\n(py36) root@8fa27a83d7dd:~/ELL/build/tutorials/vision/gettingStarted# sh compile_darknetReference.sh\nCompiling darknetReference from ELL, emitting LLVM IR\nCommand line parse error:\nCannot read from specified input map file: darknetReference.map\nParsing darknetReference from ELL, generating SWIG interface\nCommand line parse error:\nCannot read from specified input map file: darknetReference.map\nCompiling darknetReference LLVM IR, generating model object file\ncompile_darknetReference.sh: 9: compile_darknetReference.sh: llc: not found\nRunning disutils setup to compile and link model + SWIG wrappers into Python module, and install package locally\nrunning build\nrunning build_ext\nbuilding '_darknetReference' extension\nswigging darknetReference.i to darknetReference_wrap.cpp\nswig -python -modern -c++ -py3 -Fmicrosoft -I/root/ELL/interfaces/common -I/root/ELL/interfaces/common/include -I/root/ELL/libraries/emitters/include -o darknetReference_wrap.cpp darknetReference.i\nUnable to find file 'darknetReference.i'.\nerror: command 'swig' failed with exit status 1. OR with microsoft cognitive kit\n(py36) root@8fa27a83d7dd:~/ELL/build/tutorials/vision/gettingStarted# python cntkDemo.py\nTraceback (most recent call last):\n  File \"cntkDemo.py\", line 4, in \n    import cv2\nModuleNotFoundError: No module named 'cv2'. Thanks a lot Jacob. Unfortunately it didn't work in my case after running all 3 below..\nconda install -c conda-forge opencv\nconda install openblas=0.2.19\nconda update --all -c conda-forge\n(py36) root@8fa27a83d7dd:~/ELL/build/tutorials/vision/gettingStarted# python cntkDemo.py\nTraceback (most recent call last):\n  File \"cntkDemo.py\", line 4, in \n    import cv2\nImportError: libGL.so.1: cannot open shared object file: No such file or directory\n(py36) root@8fa27a83d7dd:~/ELL/build/tutorials/vision/gettingStarted# python darknetDemo.py\nTraceback (most recent call last):\n  File \"darknetDemo.py\", line 4, in \n    import cv2\nImportError: libGL.so.1: cannot open shared object file: No such file or directory\n. Thanks a lot Jacob. I am able to move forward much more.. Appreciate all your help.. Certainly, all I did is follow step 5 ELL Python Language Bindings and Step 6.Microsoft Cognitive Toolkit install steps again and then used Step 7:Darknet model to .. run .. microsoft cognitive toolkit didn't quite work.. but darnet model seems to atleast run, but also bailed out at the end ...\nAny case we can close this here and I opened new..\n . Yes, I believe so.. these are the weights and cfg downloaded and i see darnetDemo.py uses them..\ncurl -O https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/darknet.cfg\ncurl -O https://pjreddie.com/media/files/darknet.weights. However, I got error when trying to get  weights file.. and so I passed it with -k option ..\noot@8fa27a83d7dd:~/ELL/build/tutorials/vision/gettingStarted# curl -O https://pjreddie.com/media/files/darknet.weights\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\ncurl: (60) SSL certificate problem: unable to get local issuer certificate\nMore details here: https://curl.haxx.se/docs/sslcerts.html\ncurl performs SSL certificate verification by default, using a \"bundle\"\n of Certificate Authority (CA) public keys (CA certs). If the default\n bundle file isn't adequate, you can specify an alternate file\n using the --cacert option.\nIf this HTTPS server uses a certificate signed by a CA represented in\n the bundle, the certificate verification probably failed due to a\n problem with the certificate (it might be expired, or the name might\n not match the domain name in the URL).\nIf you'd like to turn off curl's verification of the certificate, use\n the -k (or --insecure) option.\nroot@8fa27a83d7dd:~/ELL/build/tutorials/vision/gettingStarted# curl -O https://pjreddie.com/media/files/darknet.weights -k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  4749  100  4749    0     0   3054      0  0:00:01  0:00:01 --:--:--  3097. Or if any one has docker image with ELL compiled and ready to go ... it would be great if you publish that image. \nAlso, instructions on how to hook up camera in PC or Rasberry PI to dockerized ELL ... output of C:/MSELL/ELL/build/CMakeFiles/CMakeOutput.log\". just says ..\nThe system is: Windows - 10.0.10586 - AMD64. MSBuild appear to be in path\n(py36) c:\\MSELL\\ELL\\build>MSbuild\nMicrosoft (R) Build Engine version 15.1.1012.6693\nCopyright (C) Microsoft Corporation. All rights reserved.\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\n. never mind .. missed ... Desktop Development with C++. Thanks. It works great... Thank you .. That worked fine... Thank you. It was indeed missing the image file and after copying it worked fine.. Also call_model.py file came like this ..and it chokes .. because width was missing .. I changed that too...\n resized = cv2.resize(cropped, (height, )) --> resized = cv2.resize(cropped, (height, width))\n(py36) C:\\ELL\\tutorials\\tutorial1\\host>python call_model.py\nModel input shape: [224, 224, 3]\nModel output shape: [1, 1, 1000]\nCategory index: 291\nConfidence: 0.9998146891593933\nNow the next problem is I want to use webcam to capture the image and send it the prediction model..\nI copied tutorial.py file from the site in to the same host folder. and run it can't find helpers modules .. Any ideas on what I am missing with helpers module...\n(py36) C:\\ELL\\tutorials\\tutorial1\\host>python tutorial.py\nTraceback (most recent call last):\n  File \"tutorial.py\", line 28, in \n    import tutorial_helpers as helpers\nModuleNotFoundError: No module named 'tutorial_helpers'\nAll the steps compiled and run fine to this point ..  \n. It's resolved .. This copies the file as pi3 ... so it is not recognizing the tutorial helper module ... It should be either pi3/tutorial_helpers.py or hosts/turorial_helpers.py \n[Windows] copy ......\\docs\\tutorials\\shared\\tutorial_helpers.py pi3\n. ",
    "devilloser": "so do i . @lisaong \n-- The C compiler identification is GNU 6.3.0\n-- The CXX compiler identification is GNU 6.3.0\n-- Check for working C compiler: /usr/local/bin/gcc\n-- Check for working C compiler: /usr/local/bin/gcc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/local/bin/c++\n-- Check for working CXX compiler: /usr/local/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Looking for pthread_create in pthreads\n-- Looking for pthread_create in pthreads - not found\n-- Looking for pthread_create in pthread\n-- Looking for pthread_create in pthread - found\n-- Found Threads: TRUE\n-- Blas libraries: /usr/lib/libopenblas.so\n-- Blas linker flags: \n-- Blas include directories: \n-- Using BLAS include path: /usr/include\n-- Using BLAS library: /usr/lib/libopenblas.so\n-- Using BLAS DLLs: \n-- Found PythonInterp: /usr/bin/python (found version \"3.6\") \n-- Found PythonLibs: /usr/local/lib/libpython3.6m.a (found version \"3.6.0\") \n-- Found SWIG: /usr/local/bin/swig (found suitable version \"3.0.12\", minimum required is \"3.0.12\") \n-- Creating wrappers for python\nCMake Deprecation Warning at /home/zf/develop/cmake-3.8.2-Linux-x86_64/share/cmake-3.8/Modules/UseSWIG.cmake:226 (message):\n  SWIG_ADD_MODULE is deprecated.  Use SWIG_ADD_LIBRARY instead.\nCall Stack (most recent call first):\n  CMake/CommonInterfaces.cmake:159 (swig_add_module)\n  CMake/CommonInterfaces.cmake:190 (generate_interface_module)\n  interfaces/python/CMakeLists.txt:21 (generate_interface)\n-- Creating wrappers for javascript\n-- Found npm at /usr/bin/npm\n-- Creating wrappers for xml\n-- Using python found at: /usr/bin/python\n-- Using python libraries found at: /usr/local/lib/libpython3.6m.a\n-- Creating wrappers for python\nCMake Deprecation Warning at /home/zf/develop/cmake-3.8.2-Linux-x86_64/share/cmake-3.8/Modules/UseSWIG.cmake:226 (message):\n  SWIG_ADD_MODULE is deprecated.  Use SWIG_ADD_LIBRARY instead.\nCall Stack (most recent call first):\n  CMake/CommonInterfaces.cmake:159 (swig_add_module)\n  CMake/CommonInterfaces.cmake:237 (generate_interface_module)\n  examples/emitted_interfaces/step/CMakeLists.txt:25 (generate_emitted_interface_module)\n-- Generated target compiled_vgg16ImageNet_host\n-- Generated target compiled_vgg16ImageNet_pi3\n-- Generated target compiled_vgg16ImageNet_pi0\n-- Generated target compiled_darknetReference_host\n-- Generated target compiled_darknetReference_pi3\n-- Generated target compiled_darknetReference_pi0\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/zf/ELL/build\nthis is the output of cmake ..\uff0cand my LLVM version is 3.9.1. ",
    "h4gen": "Hey! I have exactly the same issue but even without sudo I encounter the same problem. I tried to compile ELL in the CNTK docker container, provided by Microsoft, to build a consistent Toolchain in a transportable environment. I installed all dependencies in the guide. \nThe container also uses Ubuntu 14.04.. Hey @lisaong. With a fresh Ubuntu 16.04 everything works now. Thanks!. Thanks for the update! But how can I compile a model that is not one of the examples? Can you tell me where the entry point is to figure out how the translation from model to LLVM IR works? I don't know if I am missing something, but it seems to me that, apart from the examples, this is essentially what ELL is all about?. Thanks for your kind Answer. \nSorry maybe the explanation of my Problem was to short. Just using the script does not help me. I am in particular interested in the build process, as I want to deploy a model on an ARM Cortex M4. For this I have to understand the build process and the cross compilation process. Right now, as it seems to me, the really interesting part, namely the build process, is hidden within huge makefiles. That is why I asked for the compile command, which does not work, but it seemed as it should work. I want to understand how I can compile a small model as in ELL/examples/compiled_code for a different target than the host or an raspberry3. I assume that this is possible, as you have an example for ARM Cortex M0 and state that models can be deployed to other architectures. I just don't see where this happens, or where I can entry to do it on myself.\nThanks for your effort.\nEdit: So, the changed topic is also wrong. Its not about the tutorial. Its more about cross compiling and controlling the build process to build for other targets.. Thank you for your answer. This article has the same Problem as the other.\nIt uses the compile command. But this command does not work. And I have no\nchance of fixing this error because it is explained nowhere. Is it a\ndependency? Is it defined during the make of ELL? WHAT is the compile\ncommand? Also there is no Release folder. So I think that something is\ngoing wrong when building ELL?\nAm 26.07.2017 22:06 schrieb \"Lisa Ong\" notifications@github.com:\n\n(Updated the title, thanks for the feedback)\nThe compile commands are documented in compilingAdvanced\nhttps://github.com/Microsoft/ELL/blob/master/tutorials/vision/gettingStarted/compilingAdvanced.md.\nThe commands are written for a Windows host machine, but you should be able\nto adapt for a Linux or Mac host machine.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Microsoft/ELL/issues/63#issuecomment-318166982, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AL-Z26z73iflJGyt4vIwCJlx-Qg1v1Saks5sR5wwgaJpZM4Ojmcg\n.\n. Okay, I found it. It seems, as that the compile executable is not located in the ELL/build/bin/Release, but in the ELL/build/bin folder. Now it makes sense, that you have to add this directory to the PATH before you can use it.\n\nThat answered my question. . @vrbala Hi! Surely I can explain you what I know so far. Regarding the Cortex Ecosystem: This is quite a complex topic. Currently I am using the Bosch XDK and the XDK Workbench as IDE. Right now I am looking for a way to inject my generated object files from ELL into my Project. What I can tell you so far:\nThe Compiling Readme works for me on Mac (or Linux) if I make the ELL compiler known to my system by:\nexport PATH=$PATH:pathtoELL/ELL/build/bin\nAfter this I can use the compile command to create the LLVM IR and then the llc to create an object file.\nBasically I am using:\nllc -mtriple=armv6m-unknown-none-eabi -march=thumb -mcpu=cortex-m4 -float-abi=soft -mattr=+armv6-m,+v6m -filetype=obj ../../../examples/compiled_code/identity.ll \nThis is just the same as in the example, but I changed the filetype from asm to obj and I also changed the target to cortex-m4.\nWith a working toolchain for ARM Cortex you should be able to make the generated object file known to the linker and so you should be able to inject your model in your embedded code. At least this is how I understand it :)\nThis is the step where I am currently stuck (XDK Workbench problem) but in general it should work like this.\n. @pnvphuong What happens, when you just comment out the whole opencv part in the python script? Looks pretty much like an opencv issue to me. I would be surprised, if the ELL compiled code calls any gtk functions itself. . Okay thanks, I will try to fix it. But I am still a little bit puzzled. How does the neural network implementation work if there is no plus and times operation? \nI mean, basically a logistic regression does the same thing as a perceptron.\nI would assume that it does nearly the same as your linear layer in the Library. Is there maybe a possible workaround to create a model in cntk that does not need times and plus? Unfortunately I could not not find something like a linear layer in cntk.\nI have one more question regarding the expected workflow with ELL: Right now I interpret it more as a compiler for cntk models. But basically I could just design the whole model with ELL, right?\nIs there a recommended workflow how to use ELL?. Hi there!\nI tried implementing the processing for the layers.\nI added this code:\n```\ndef process_plus_layer(layer,ellLayers):\n    biasParameter = findParameterByName(layer.parameters, 'b', 0)\n    biasVector = get_float_vector_from_cntk_trainable_parameter(biasParameter)\n    layerParameters = ELL.LayerParameters(layer.ell_outputShapeMinusPadding, ELL.NoPadding(\n    ), layer.ell_outputShape, layer.ell_outputPaddingParameters)\n    ellLayers.append(ELL.FloatBiasLayer(layerParameters, biasVector))\n    return\ndef process_times_layer(layer,ellLayers):\n    weightsParameter = findParameterByName(layer.parameters, 'W', 0)\n    weightsTensor = get_float_tensor_from_cntk_dense_weight_parameter(weightsParameter)\n    layerParameters = ELL.LayerParameters(layer.ell_inputShape, layer.ell_inputPaddingParameters, layer.ell_outputShapeMinusPadding, ELL.NoPadding())\n    ellLayers.append(ELL.FloatFullyConnectedLayer(layerParameters, weightsTensor))\n    return\n```\nand added to convert_cntk_layers_to_ell_layers \nelif (cntkLayer.op_name == 'Times'):\n            process_times_layer(cntkLayer, ellLayers)\n        elif (cntkLayer.op_name == 'Plus'):\n            process_plus_layer(cntkLayer, ellLayers)\nand so to get_filtered_layers_list\nelif ((currentLayer.op_name == 'Dense') or\n                ...     \n           (currentLayer.op_name == 'Times') or\n           (currentLayer.op_name == 'Plus')\nAfter this the ell pre processing and the compiling works fine! This is the output:\n```\nFinished loading.\nPre-processing...\nTimes :  1x1x2  ->  1x1x2 | padding  0\nPlus :  1x1x2  ->  1x1x2 | padding  0\nSoftmax :  1x1x2  ->  1x1x2 | padding  0\nFinished pre-processing.\nConstructing equivalent ELL layers from CNTK...\nConverting layer  Times(Tensor[2]) -> Tensor[2]\nConverting layer  Plus(Tensor[2]) -> Tensor[2]\nConverting layer  Softmax(Tensor[2]) -> Tensor[2]\n...Finished constructing ELL layers.\n```\ncompiling and cross compiling is done via:\ncompile -imap mymodel.map --header --ir \nllc-3.9 -mtriple=armv7m-unknown-none-eabi -march=thumb -mcpu=cortex-m3 \n-mattr=+armv7-m,+v7 -float-abi=soft -filetype=obj mymodel.ll\nThen I get this error, when injecting the code in my project and compile it:\nIn function `_Node__MatrixVectorMultiplyNode_float__in_4_2_out_2':\nmymodel.ll:(.text+0xe4): undefined reference to `cblas_sgemv\nThis is the model I export from cntk (I added a plus layer in comparison to the original from the tutorial)\nweight_param = C.parameter(shape=(input_dim, output_dim),name='W')\nbias_param = C.parameter(shape=(output_dim),name='b')\nC.softmax(C.plus(C.times(input_var, weight_param), bias_param))\nAny ideas whats going wrong?. Okay, immediately found my error. The compile command has to be called with --blas false, so that there are no function calls to BLAS.. ",
    "pnvphuong": "There are some incompatibilities with Ubuntu14.\nELL requires gcc 5 or above, but CUDA 8 only supports gcc 4x for Ubuntu 14. Therefore, it's hard to install and build ELL on Ubuntu 14.\nOn the other hand, CUDA 8 supports gcc 5x for Ubuntu 16. Everything will be fine then. Thanks a lot for your reply, lisaong. I hope we can find a solution soon for Pi Zero. \nI just wonder if the errors come from ELL compiled code itself or from the tutorials, e.g. using opencv.. ",
    "eulesv": "Hi clovett, \nI'm using Visual Studio 2017, however I think the problem is related to missing packages on python, dependencies shows a bunch of missing modules:\n\nAPI-MS-WIN-CORE-APIQUERY-L1-1-0.DLL\nAPI-MS-WIN-CORE-APPCOMPAT-L1-1-1.DLL\nAPI-MS-WIN-CORE-APPINIT-L1-1-0.DLL\nAPI-MS-WIN-CORE-ATOMS-L1-1-0.DLL\nAPI-MS-WIN-CORE-COM-L1-1-0\nAPI-MS-WIN-CORE-COM-L1-1-1.DLL\nAPI-MS-WIN-CORE-COM-L1-1-2.DLL\nAPI-MS-WIN-CORE-COM-MIDLPROXYSTUB-L1-1-0.DLL\nAPI-MS-WIN-CORE-COM-PRIVATE-L1-1-0.DLL\nAPI-MS-WIN-CORE-COM-PRIVATE-L1-1-1.DLL\nAPI-MS-WIN-CORE-COMM-L1-1-0.DLL\nAPI-MS-WIN-CORE-CONSOLE-L2-1-0.DLL\nAPI-MS-WIN-CORE-CONSOLE-L3-1-0.DLL\nAPI-MS-WIN-CORE-CRT-L1-1-0.DLL\nAPI-MS-WIN-CORE-CRT-L2-1-0.DLL\nAPI-MS-WIN-CORE-DATETIME-L1-1-1.DLL\nAPI-MS-WIN-CORE-DATETIME-L1-1-2.DLL\nAPI-MS-WIN-CORE-DEBUG-L1-1-1.DLL\nAPI-MS-WIN-CORE-DELAYLOAD-L1-1-1.DLL\nAPI-MS-WIN-CORE-ENCLAVE-L1-1-0.DLL\nAPI-MS-WIN-CORE-ERRORHANDLING-L1-1-1.DLL\nAPI-MS-WIN-CORE-ERRORHANDLING-L1-1-3.DLL\nAPI-MS-WIN-CORE-FIBERS-L1-1-1.DLL\nAPI-MS-WIN-CORE-FIBERS-L2-1-1.DLL\nAPI-MS-WIN-CORE-FILE-L1-2-1.DLL\nAPI-MS-WIN-CORE-FILE-L1-2-2.DLL\nAPI-MS-WIN-CORE-FILE-L2-1-1.DLL\nAPI-MS-WIN-CORE-FILE-L2-1-2.DLL\nAPI-MS-WIN-CORE-HEAP-L1-2-0.DLL\nAPI-MS-WIN-CORE-HEAP-L2-1-0.DLL\nAPI-MS-WIN-CORE-HEAP-OBSOLETE-L1-1-0.DLL\nAPI-MS-WIN-CORE-INTERLOCKED-L1-2-0.DLL\nAPI-MS-WIN-CORE-IO-L1-1-1.DLL\nAPI-MS-WIN-CORE-JOB-L1-1-0.DLL\nAPI-MS-WIN-CORE-JOB-L2-1-0.DLL\nAPI-MS-WIN-CORE-KERNEL32-LEGACY-L1-1-1.DLL\nAPI-MS-WIN-CORE-KERNEL32-LEGACY-L1-1-5.DLL\nAPI-MS-WIN-CORE-KERNEL32-PRIVATE-L1-1-1.DLL\nAPI-MS-WIN-CORE-KERNEL32-PRIVATE-L1-1-2.DLL\nAPI-MS-WIN-CORE-LARGEINTEGER-L1-1-0.DLL\nAPI-MS-WIN-CORE-LIBRARYLOADER-L1-2-0.DLL\nAPI-MS-WIN-CORE-LIBRARYLOADER-L1-2-2.DLL\nAPI-MS-WIN-CORE-LIBRARYLOADER-L2-1-0.DLL\nAPI-MS-WIN-CORE-LOCALIZATION-L1-2-1.DLL\nAPI-MS-WIN-CORE-LOCALIZATION-L1-2-2.DLL\nAPI-MS-WIN-CORE-LOCALIZATION-L2-1-0.DLL\nAPI-MS-WIN-CORE-LOCALIZATION-OBSOLETE-L1-3-0.DLL\nAPI-MS-WIN-CORE-LOCALIZATION-PRIVATE-L1-1-0.DLL\nAPI-MS-WIN-CORE-MEMORY-L1-1-2.DLL\nAPI-MS-WIN-CORE-MISC-L1-1-0.DLL\nAPI-MS-WIN-CORE-NAMEDPIPE-L1-2-0.DLL\nAPI-MS-WIN-CORE-NAMEDPIPE-L1-2-2.DLL\nAPI-MS-WIN-CORE-NAMESPACE-L1-1-0.DLL\nAPI-MS-WIN-CORE-NORMALIZATION-L1-1-0.DLL\nAPI-MS-WIN-CORE-PATH-L1-1-0.DLL\nAPI-MS-WIN-CORE-PERFCOUNTERS-L1-1-0.DLL\nAPI-MS-WIN-CORE-PRIVATEPROFILE-L1-1-1.DLL\nAPI-MS-WIN-CORE-PROCESSENVIRONMENT-L1-2-0.DLL\nAPI-MS-WIN-CORE-PROCESSSNAPSHOT-L1-1-0.DLL\nAPI-MS-WIN-CORE-PROCESSTHREADS-L1-1-2.DLL\nAPI-MS-WIN-CORE-PROCESSTHREADS-L1-1-3.DLL\nAPI-MS-WIN-CORE-PROCESSTOPOLOGY-L1-2-0.DLL\nAPI-MS-WIN-CORE-PSAPI-ANSI-L1-1-0.DLL\nAPI-MS-WIN-CORE-PSAPI-L1-1-0.DLL\nAPI-MS-WIN-CORE-PSM-KEY-L1-1-0.DLL\nAPI-MS-WIN-CORE-QUIRKS-L1-1-0.DLL\nAPI-MS-WIN-CORE-REALTIME-L1-1-0.DLL\nAPI-MS-WIN-CORE-REGISTRY-L1-1-0.DLL\nAPI-MS-WIN-CORE-REGISTRY-L1-1-1.DLL\nAPI-MS-WIN-CORE-REGISTRYUSERSPECIFIC-L1-1-0.DLL\nAPI-MS-WIN-CORE-RTLSUPPORT-L1-2-0.DLL\nAPI-MS-WIN-CORE-SHLWAPI-LEGACY-L1-1-0.DLL\nAPI-MS-WIN-CORE-SHLWAPI-OBSOLETE-L1-2-0.DLL\nAPI-MS-WIN-CORE-SIDEBYSIDE-L1-1-0.DLL\nAPI-MS-WIN-CORE-STRING-L2-1-0.DLL\nAPI-MS-WIN-CORE-STRING-L2-1-1.DLL\nAPI-MS-WIN-CORE-STRING-OBSOLETE-L1-1-0.DLL\nAPI-MS-WIN-CORE-STRINGANSI-L1-1-0.DLL\nAPI-MS-WIN-CORE-SYNCH-L1-2-1.DLL\nAPI-MS-WIN-CORE-SYSINFO-L1-2-1.DLL\nAPI-MS-WIN-CORE-SYSINFO-L1-2-3.DLL\nAPI-MS-WIN-CORE-SYSTEMTOPOLOGY-L1-1-0.DLL\nAPI-MS-WIN-CORE-SYSTEMTOPOLOGY-L1-1-1.DLL\nAPI-MS-WIN-CORE-THREADPOOL-L1-2-0.DLL\nAPI-MS-WIN-CORE-THREADPOOL-LEGACY-L1-1-0.DLL\nAPI-MS-WIN-CORE-THREADPOOL-PRIVATE-L1-1-0.DLL\nAPI-MS-WIN-CORE-URL-L1-1-0.DLL\nAPI-MS-WIN-CORE-VERSION-L1-1-0.DLL\nAPI-MS-WIN-CORE-VERSION-L1-1-1.DLL\nAPI-MS-WIN-CORE-VERSION-PRIVATE-L1-1-0.DLL\nAPI-MS-WIN-CORE-VERSIONANSI-L1-1-0.DLL\nAPI-MS-WIN-CORE-VERSIONANSI-L1-1-1.DLL\nAPI-MS-WIN-CORE-WINDOWSERRORREPORTING-L1-1-0.DLL\nAPI-MS-WIN-CORE-WINDOWSERRORREPORTING-L1-1-1.DLL\nAPI-MS-WIN-CORE-WINRT-ERROR-L1-1-1.DLL\nAPI-MS-WIN-CORE-WINRT-STRING-L1-1-0.DLL\nAPI-MS-WIN-CORE-WOW64-L1-1-0.DLL\nAPI-MS-WIN-CORE-WOW64-L1-1-1.DLL\nAPI-MS-WIN-CORE-XSTATE-L2-1-0.DLL\nAPI-MS-WIN-DEVICES-CONFIG-L1-1-1.DLL\nAPI-MS-WIN-EVENTING-CLASSICPROVIDER-L1-1-0.DLL\nAPI-MS-WIN-EVENTING-CONSUMER-L1-1-0.DLL\nAPI-MS-WIN-EVENTING-CONTROLLER-L1-1-0.DLL\nAPI-MS-WIN-EVENTING-OBSOLETE-L1-1-0.DLL\nAPI-MS-WIN-EVENTING-PROVIDER-L1-1-0.DLL\nAPI-MS-WIN-GDI-INTERNAL-UAP-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-APPCONTAINER-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-AUDIT-L1-1-1.DLL\nAPI-MS-WIN-SECURITY-BASE-L1-2-0.DLL\nAPI-MS-WIN-SECURITY-BASE-PRIVATE-L1-1-1.DLL\nAPI-MS-WIN-SECURITY-CAPABILITY-L1-1-0.DLL\nAPI-MS-WIN-SERVICE-CORE-L1-1-1.DLL\nAPI-MS-WIN-SERVICE-CORE-L1-1-2.DLL\nAPI-MS-WIN-SERVICE-MANAGEMENT-L1-1-0.DLL\nAPI-MS-WIN-SERVICE-MANAGEMENT-L2-1-0.DLL\nAPI-MS-WIN-SERVICE-PRIVATE-L1-1-0\nAPI-MS-WIN-SERVICE-PRIVATE-L1-1-1.DLL\nAPI-MS-WIN-SERVICE-PRIVATE-L1-1-3.DLL\nAPI-MS-WIN-SERVICE-WINSVC-L1-2-0.DLL\nAPI-MS-WIN-SHCORE-PATH-L1-1-0.DLL\nAPI-MS-WIN-SHELL-SHELLCOM-L1-1-0.DLL\nAPI-MS-WIN-SHELL-SHELLFOLDERS-L1-1-0.DLL\nAPI-MS-WIN-STORAGE-EXPORTS-EXTERNAL-L1-1-0.DLL\nAPI-MS-WIN-STORAGE-EXPORTS-INTERNAL-L1-1-0.DLL\nAPI-MS-ONECOREUAP-SETTINGSYNC-STATUS-L1-1-0.DLL\nAPI-MS-WIN-APPMODEL-IDENTITY-L1-2-0.DLL\nAPI-MS-WIN-APPMODEL-RUNTIME-INTERNAL-L1-1-0.DLL\nAPI-MS-WIN-APPMODEL-RUNTIME-INTERNAL-L1-1-4.DLL\nAPI-MS-WIN-APPMODEL-RUNTIME-L1-1-0.DLL\nAPI-MS-WIN-APPMODEL-RUNTIME-L1-1-1.DLL\nAPI-MS-WIN-APPMODEL-RUNTIME-L1-1-2.DLL\nAPI-MS-WIN-APPMODEL-STATE-L1-2-0.DLL\nAPI-MS-WIN-APPMODEL-UNLOCK-L1-1-0.DLL\nAPI-MS-WIN-BASE-UTIL-L1-1-0.DLL\nAPI-MS-WIN-CORE-CALENDAR-L1-1-0.DLL\nAPI-MS-WIN-CORE-COM-L1-1-0.DLL\nAPI-MS-WIN-CORE-COM-L2-1-1.DLL\nAPI-MS-WIN-CORE-DELAYLOAD-L1-1-0.DLL\nAPI-MS-WIN-CORE-FIRMWARE-L1-1-0.DLL\nAPI-MS-WIN-CORE-IO-L1-1-0.DLL\nAPI-MS-WIN-CORE-KERNEL32-LEGACY-L1-1-0.DLL\nAPI-MS-WIN-CORE-LOCALIZATION-L1-1-0.DLL\nAPI-MS-WIN-CORE-LOCALIZATION-OBSOLETE-L1-2-0.DLL\nAPI-MS-WIN-CORE-LOCALREGISTRY-L1-1-0.DLL\nAPI-MS-WIN-CORE-MARSHAL-L1-1-0.DLL\nAPI-MS-WIN-CORE-MEMORY-L1-1-1.DLL\nAPI-MS-WIN-CORE-MEMORY-L1-1-5.DLL\nAPI-MS-WIN-CORE-PRIVATEPROFILE-L1-1-0.DLL\nAPI-MS-WIN-CORE-PROCESSTOPOLOGY-OBSOLETE-L1-1-0.DLL\nAPI-MS-WIN-CORE-PSM-APP-L1-1-0.DLL\nAPI-MS-WIN-CORE-PSM-APPNOTIFY-L1-1-0.DLL\nAPI-MS-WIN-CORE-REALTIME-L1-1-2.DLL\nAPI-MS-WIN-CORE-REGISTRY-L2-2-0.DLL\nAPI-MS-WIN-CORE-REGISTRY-PRIVATE-L1-1-0.DLL\nAPI-MS-WIN-CORE-SHLWAPI-OBSOLETE-L1-1-0.DLL\nAPI-MS-WIN-CORE-SHUTDOWN-L1-1-1.DLL\nAPI-MS-WIN-CORE-SYSINFO-L1-2-0.DLL\nAPI-MS-WIN-CORE-TOOLHELP-L1-1-0.DLL\nAPI-MS-WIN-CORE-WINRT-ERRORPRIVATE-L1-1-1.DLL\nAPI-MS-WIN-CORE-WINRT-L1-1-0.DLL\nAPI-MS-WIN-CORE-WINRT-PROPERTYSETPRIVATE-L1-1-0.DLL\nAPI-MS-WIN-CORE-WINRT-PROPERTYSETPRIVATE-L1-1-1.DLL\nAPI-MS-WIN-CORE-WINRT-REGISTRATION-L1-1-0.DLL\nAPI-MS-WIN-CORE-WINRT-ROBUFFER-L1-1-0.DLL\nAPI-MS-WIN-CORE-WINRT-STRING-L1-1-1.DLL\nAPI-MS-WIN-COREUI-SECRUNTIME-L1-1-0.DLL\nAPI-MS-WIN-DEVICES-QUERY-L1-1-1.DLL\nAPI-MS-WIN-DOWNLEVEL-ADVAPI32-L1-1-0.DLL\nAPI-MS-WIN-DOWNLEVEL-ADVAPI32-L2-1-0.DLL\nAPI-MS-WIN-DOWNLEVEL-KERNEL32-L2-1-0.DLL\nAPI-MS-WIN-DOWNLEVEL-NORMALIZ-L1-1-0.DLL\nAPI-MS-WIN-DOWNLEVEL-OLE32-L1-1-0.DLL\nAPI-MS-WIN-DOWNLEVEL-SHELL32-L1-1-0.DLL\nAPI-MS-WIN-DOWNLEVEL-SHLWAPI-L1-1-0.DLL\nAPI-MS-WIN-DOWNLEVEL-SHLWAPI-L2-1-0.DLL\nAPI-MS-WIN-DOWNLEVEL-USER32-L1-1-0.DLL\nAPI-MS-WIN-DOWNLEVEL-VERSION-L1-1-0.DLL\nAPI-MS-WIN-DWMAPI-L1-1-0.DLL\nAPI-MS-WIN-DX-D3DKMT-L1-1-0.DLL\nAPI-MS-WIN-DX-D3DKMT-L1-1-3.DLL\nAPI-MS-WIN-EVENTING-LEGACY-L1-1-0.DLL\nAPI-MS-WIN-EVENTING-TDH-L1-1-0.DLL\nAPI-MS-WIN-EVENTLOG-LEGACY-L1-1-0.DLL\nAPI-MS-WIN-GDI-DPIINFO-L1-1-0.DLL\nAPI-MS-WIN-HTTP-TIME-L1-1-0.DLL\nAPI-MS-WIN-MM-JOYSTICK-L1-1-0.DLL\nAPI-MS-WIN-MM-MISC-L1-1-1.DLL\nAPI-MS-WIN-MM-MISC-L2-1-0.DLL\nAPI-MS-WIN-MM-MME-L1-1-0.DLL\nAPI-MS-WIN-MM-TIME-L1-1-0.DLL\nAPI-MS-WIN-NETWORKING-INTERFACECONTEXTS-L1-1-0.DLL\nAPI-MS-WIN-NTUSER-RECTANGLE-L1-1-0.DLL\nAPI-MS-WIN-NTUSER-SYSPARAMS-L1-1-0.DLL\nAPI-MS-WIN-OLE32-IE-L1-1-0.DLL\nAPI-MS-WIN-OOBE-NOTIFICATION-L1-1-0.DLL\nAPI-MS-WIN-POWER-BASE-L1-1-0.DLL\nAPI-MS-WIN-POWER-SETTING-L1-1-0.DLL\nAPI-MS-WIN-RO-TYPERESOLUTION-L1-1-0.DLL\nAPI-MS-WIN-RTCORE-NTUSER-CLIPBOARD-L1-1-0.DLL\nAPI-MS-WIN-RTCORE-NTUSER-PRIVATE-L1-1-0.DLL\nAPI-MS-WIN-RTCORE-NTUSER-PRIVATE-L1-1-5.DLL\nAPI-MS-WIN-RTCORE-NTUSER-SHELL-L1-1-0.DLL\nAPI-MS-WIN-RTCORE-NTUSER-SYNCH-L1-1-0.DLL\nAPI-MS-WIN-RTCORE-NTUSER-WINDOW-L1-1-0.DLL\nAPI-MS-WIN-RTCORE-NTUSER-WINEVENT-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-ACCESSHLPR-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-ACTIVEDIRECTORYCLIENT-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-ACTIVEDIRECTORYCLIENT-L1-1-1.DLL\nAPI-MS-WIN-SECURITY-BASE-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-CREDENTIALS-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-CREDENTIALS-L2-1-0.DLL\nAPI-MS-WIN-SECURITY-CRYPTOAPI-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-GROUPPOLICY-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-LSALOOKUP-ANSI-L2-1-0.DLL\nAPI-MS-WIN-SECURITY-LSALOOKUP-L1-1-1.DLL\nAPI-MS-WIN-SECURITY-LSALOOKUP-L1-1-2.DLL\nAPI-MS-WIN-SECURITY-LSALOOKUP-L2-1-1.DLL\nAPI-MS-WIN-SECURITY-LSAPOLICY-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-PROVIDER-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-SDDL-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-SDDLPARSECOND-L1-1-0.DLL\nAPI-MS-WIN-SECURITY-SYSTEMFUNCTIONS-L1-1-0.DLL\nAPI-MS-WIN-SERVICE-WINSVC-L1-1-0.DLL\nAPI-MS-WIN-SHCORE-COMHELPERS-L1-1-0.DLL\nAPI-MS-WIN-SHCORE-OBSOLETE-L1-1-0.DLL\nAPI-MS-WIN-SHCORE-REGISTRY-L1-1-1.DLL\nAPI-MS-WIN-SHCORE-SCALING-L1-1-1.DLL\nAPI-MS-WIN-SHCORE-STREAM-L1-1-0.DLL\nAPI-MS-WIN-SHCORE-STREAM-WINRT-L1-1-0.DLL\nAPI-MS-WIN-SHCORE-SYSINFO-L1-1-0.DLL\nAPI-MS-WIN-SHCORE-THREAD-L1-1-0.DLL\nAPI-MS-WIN-SHCORE-UNICODEANSI-L1-1-0.DLL\nAPI-MS-WIN-SHELL-CHANGENOTIFY-L1-1-0.DLL\nAPI-MS-WIN-SHELL-NAMESPACE-L1-1-0.DLL\nAPI-MS-WIN-SHELL-SHDIRECTORY-L1-1-0.DLL\nAPI-MS-WIN-SHLWAPI-IE-L1-1-0.DLL\nAPI-MS-WIN-SHLWAPI-WINRT-STORAGE-L1-1-1.DLL\nDEVICELOCKHELPERS.DLL\nEMCLIENT.DLL\nEXT-MS-MF-PAL-L2-1-0.DLL\nEXT-MS-ONECORE-APPCHROMEAPI-L1-1-0.DLL\nEXT-MS-ONECORE-APPDEFAULTS-L1-1-0.DLL\nEXT-MS-ONECORE-APPMODEL-EMCLIENT-L1-1-0.DLL\nEXT-MS-ONECORE-APPMODEL-STATEREPOSITORY-INTERNAL-L1-1-1.DLL\nEXT-MS-ONECORE-DCOMP-L1-1-0.DLL\nEXT-MS-ONECORE-HLINK-L1-1-0.DLL\nEXT-MS-ONECORE-ORIENTATION-L1-1-0.DLL\nEXT-MS-ONECORE-PHONEINFO-L1-1-0.DLL\nEXT-MS-ONECORE-SHELLCHROMEAPI-L1-1-2.DLL\nEXT-MS-WIN-ADVAPI32-MSI-L1-1-0.DLL\nEXT-MS-WIN-ADVAPI32-NPUSERNAME-L1-1-0.DLL\nEXT-MS-WIN-ADVAPI32-NTMARTA-L1-1-0.DLL\nEXT-MS-WIN-ADVAPI32-PSM-APP-L1-1-0.DLL\nEXT-MS-WIN-ADVAPI32-REGISTRY-L1-1-0.DLL\nEXT-MS-WIN-ADVAPI32-SAFER-L1-1-0.DLL\nEXT-MS-WIN-APPCOMPAT-AEPIC-L1-1-0.DLL\nEXT-MS-WIN-APPCOMPAT-APPHELP-L1-1-0.DLL\nEXT-MS-WIN-APPMODEL-DAXCORE-L1-1-1.DLL\nEXT-MS-WIN-APPMODEL-DEPLOYMENT-L1-1-1.DLL\nEXT-MS-WIN-APPMODEL-RESTRICTEDAPPCONTAINER-INTERNAL-L1-1-0.DLL\nEXT-MS-WIN-APPMODEL-STATE-EXT-L1-2-0.DLL\nEXT-MS-WIN-APPMODEL-USERCONTEXT-L1-1-0.DLL\nEXT-MS-WIN-APPMODEL-VIEWSCALEFACTOR-L1-1-0.DLL\nEXT-MS-WIN-APPXDEPLOYMENTCLIENT-APPXDEPLOY-L1-1-0.DLL\nEXT-MS-WIN-APPXDEPLOYMENTCLIENT-APPXDEPLOYONECORE-L1-1-0.DLL\nEXT-MS-WIN-AUDIOCORE-PAL-L1-2-0.DLL\nEXT-MS-WIN-AUTHZ-CONTEXT-L1-1-0.DLL\nEXT-MS-WIN-AUTHZ-REMOTE-L1-1-0.DLL\nEXT-MS-WIN-COM-CLBCATQ-L1-1-0.DLL\nEXT-MS-WIN-COM-COML2-L1-1-1.DLL\nEXT-MS-WIN-COM-OLE32-L1-1-1.DLL\nEXT-MS-WIN-COM-OLE32-L1-1-5.DLL\nEXT-MS-WIN-COM-PSMREGISTER-L1-2-2.DLL\nEXT-MS-WIN-COM-SUSPENDRESILIENCY-L1-1-0.DLL\nEXT-MS-WIN-CORE-IURI-L1-1-0.DLL\nEXT-MS-WIN-CORE-WINRT-REMOTE-L1-1-0.DLL\nEXT-MS-WIN-DEVMGMT-DM-L1-1-1.DLL\nEXT-MS-WIN-DEVMGMT-POLICY-L1-1-1.DLL\nEXT-MS-WIN-DIRECT2D-DESKTOP-L1-1-0.DLL\nEXT-MS-WIN-DOMAINJOIN-NETJOIN-L1-1-0.DLL\nEXT-MS-WIN-DWMAPI-EXT-L1-1-0.DLL\nEXT-MS-WIN-DWMAPIDXGI-EXT-L1-1-0.DLL\nEXT-MS-WIN-EDPUTIL-POLICY-L1-1-1.DLL\nEXT-MS-WIN-ELS-ELSCORE-L1-1-0.DLL\nEXT-MS-WIN-EVENTING-RUNDOWN-L1-1-0.DLL\nEXT-MS-WIN-FAMILYSAFETY-CHILDACCOUNT-L1-1-0.DLL\nEXT-MS-WIN-FECLIENT-ENCRYPTEDFILE-L1-1-0.DLL\nEXT-MS-WIN-FECLIENT-ENCRYPTEDFILE-L1-1-1.DLL\nEXT-MS-WIN-FIREWALLAPI-WEBPROXY-L1-1-0.DLL\nEXT-MS-WIN-GDI-CLIPPING-L1-1-0.DLL\nEXT-MS-WIN-GDI-DC-CREATE-L1-1-1.DLL\nEXT-MS-WIN-GDI-DC-L1-2-0.DLL\nEXT-MS-WIN-GDI-DC-L1-2-1.DLL\nEXT-MS-WIN-GDI-DEVCAPS-L1-1-0.DLL\nEXT-MS-WIN-GDI-DRAW-L1-1-1.DLL\nEXT-MS-WIN-GDI-DRAW-L1-1-3.DLL\nEXT-MS-WIN-GDI-FONT-L1-1-1.DLL\nEXT-MS-WIN-GDI-FONT-L1-1-3.DLL\nEXT-MS-WIN-GDI-GDIPLUS-L1-1-0.DLL\nEXT-MS-WIN-GDI-INTERNAL-DESKTOP-L1-1-1.DLL\nEXT-MS-WIN-GDI-METAFILE-L1-1-1.DLL\nEXT-MS-WIN-GDI-METAFILE-L1-1-2.DLL\nEXT-MS-WIN-GDI-PATH-L1-1-0.DLL\nEXT-MS-WIN-GDI-PRINT-L1-1-0.DLL\nEXT-MS-WIN-GDI-PRIVATE-L1-1-0.DLL\nEXT-MS-WIN-GDI-RENDER-L1-1-0.DLL\nEXT-MS-WIN-GDI-WCS-L1-1-0.DLL\nEXT-MS-WIN-GPAPI-GROUPPOLICY-L1-1-0.DLL\nEXT-MS-WIN-GUI-DUI70-L1-1-0.DLL\nEXT-MS-WIN-IMM-L1-1-1.DLL\nEXT-MS-WIN-KERNEL32-APPCOMPAT-L1-1-0.DLL\nEXT-MS-WIN-KERNEL32-DATETIME-L1-1-0.DLL\nEXT-MS-WIN-KERNEL32-ERRORHANDLING-L1-1-0.DLL\nEXT-MS-WIN-KERNEL32-FILE-L1-1-0.DLL\nEXT-MS-WIN-KERNEL32-LOCALIZATION-L1-1-0.DLL\nEXT-MS-WIN-KERNEL32-PACKAGE-CURRENT-L1-1-0.DLL\nEXT-MS-WIN-KERNEL32-PACKAGE-L1-1-1.DLL\nEXT-MS-WIN-KERNEL32-QUIRKS-L1-1-0.DLL\nEXT-MS-WIN-KERNEL32-QUIRKS-L1-1-1.DLL\nEXT-MS-WIN-KERNEL32-REGISTRY-L1-1-0.DLL\nEXT-MS-WIN-KERNEL32-SIDEBYSIDE-L1-1-0.DLL\nEXT-MS-WIN-KERNELBASE-PROCESSTHREAD-L1-1-0.DLL\nEXT-MS-WIN-MININPUT-INPUTHOST-L1-1-0.DLL\nEXT-MS-WIN-MPR-MULTIPLEPROVIDERROUTER-L1-1-0.DLL\nEXT-MS-WIN-MRMCORER-ENVIRONMENT-L1-1-0.DLL\nEXT-MS-WIN-MRMCORER-RESMANAGER-L1-1-0.DLL\nEXT-MS-WIN-NETWORKING-WLANSTORAGE-L1-1-0.DLL\nEXT-MS-WIN-NTDSAPI-ACTIVEDIRECTORYCLIENT-L1-1-0.DLL\nEXT-MS-WIN-NTDSAPI-ACTIVEDIRECTORYCLIENT-L1-1-1.DLL\nEXT-MS-WIN-NTUSER-DC-ACCESS-EXT-L1-1-0.DLL\nEXT-MS-WIN-NTUSER-DIALOGBOX-L1-1-1.DLL\nEXT-MS-WIN-NTUSER-DRAW-L1-1-1.DLL\nEXT-MS-WIN-NTUSER-DRAW-L1-1-2.DLL\nEXT-MS-WIN-NTUSER-GUI-L1-3-1.DLL\nEXT-MS-WIN-NTUSER-KEYBOARD-L1-3-0.DLL\nEXT-MS-WIN-NTUSER-MENU-L1-1-3.DLL\nEXT-MS-WIN-NTUSER-MESSAGE-L1-1-1.DLL\nEXT-MS-WIN-NTUSER-MESSAGE-L1-1-3.DLL\nEXT-MS-WIN-NTUSER-MISC-L1-5-1.DLL\nEXT-MS-WIN-NTUSER-MIT-L1-1-0.DLL\nEXT-MS-WIN-NTUSER-MOUSE-L1-1-0.DLL\nEXT-MS-WIN-NTUSER-PRIVATE-L1-3-2.DLL\nEXT-MS-WIN-NTUSER-RECTANGLE-EXT-L1-1-0.DLL\nEXT-MS-WIN-NTUSER-ROTATIONMANAGER-L1-1-0.DLL\nEXT-MS-WIN-NTUSER-SERVER-L1-1-0.DLL\nEXT-MS-WIN-NTUSER-STRING-L1-1-0.DLL\nEXT-MS-WIN-NTUSER-SYNCH-L1-1-0.DLL\nEXT-MS-WIN-NTUSER-UICONTEXT-EXT-L1-1-0.DLL\nEXT-MS-WIN-NTUSER-WINDOW-L1-1-1.DLL\nEXT-MS-WIN-NTUSER-WINDOW-L1-1-4.DLL\nEXT-MS-WIN-NTUSER-WINDOWCLASS-L1-1-1.DLL\nEXT-MS-WIN-NTUSER-WINDOWSTATION-L1-1-1.DLL\nEXT-MS-WIN-ODBC-ODBC32-L1-1-0.DLL\nEXT-MS-WIN-OLE32-BINDCTX-L1-1-0.DLL\nEXT-MS-WIN-OLE32-IE-EXT-L1-1-0.DLL\nEXT-MS-WIN-OLE32-OLEAUTOMATION-L1-1-0.DLL\nEXT-MS-WIN-OLEACC-L1-1-2.DLL\nEXT-MS-WIN-PRINTER-PRNTVPT-L1-1-1.DLL\nEXT-MS-WIN-PROFILE-EXTENDER-L1-1-0.DLL\nEXT-MS-WIN-PROFILE-LOAD-L1-1-0.DLL\nEXT-MS-WIN-PROFILE-USERENV-L1-1-0.DLL\nEXT-MS-WIN-PROFILE-USERENV-L1-1-1.DLL\nEXT-MS-WIN-RAS-RASAPI32-L1-1-0.DLL\nEXT-MS-WIN-RAS-TAPI32-L1-1-1.DLL\nEXT-MS-WIN-RDR-DAVHLPR-L1-1-0.DLL\nEXT-MS-WIN-RESOURCES-DEPLOYMENT-L1-1-0.DLL\nEXT-MS-WIN-RO-TYPERESOLUTION-L1-1-0.DLL\nEXT-MS-WIN-RPC-SSL-L1-1-0.DLL\nEXT-MS-WIN-RTCORE-GDI-DEVCAPS-L1-1-0.DLL\nEXT-MS-WIN-RTCORE-GDI-OBJECT-L1-1-0.DLL\nEXT-MS-WIN-RTCORE-GDI-RGN-L1-1-0.DLL\nEXT-MS-WIN-RTCORE-GDI-RGN-L1-1-1.DLL\nEXT-MS-WIN-RTCORE-MINUSER-INPUT-L1-1-2.DLL\nEXT-MS-WIN-RTCORE-MINUSER-PRIVATE-EXT-L1-1-0.DLL\nEXT-MS-WIN-RTCORE-NTUSER-CURSOR-L1-1-1.DLL\nEXT-MS-WIN-RTCORE-NTUSER-DC-ACCESS-L1-1-0.DLL\nEXT-MS-WIN-RTCORE-NTUSER-DPI-L1-2-0.DLL\nEXT-MS-WIN-RTCORE-NTUSER-IAM-L1-1-1.DLL\nEXT-MS-WIN-RTCORE-NTUSER-INTEGRATION-L1-1-0.DLL\nEXT-MS-WIN-RTCORE-NTUSER-SYNCH-EXT-L1-1-0.DLL\nEXT-MS-WIN-RTCORE-NTUSER-SYSCOLORS-L1-1-0.DLL\nEXT-MS-WIN-RTCORE-NTUSER-SYSPARAMS-L1-1-0.DLL\nEXT-MS-WIN-RTCORE-NTUSER-WINDOW-EXT-L1-1-0.DLL\nEXT-MS-WIN-SECUR32-TRANSLATENAME-L1-1-0.DLL\nEXT-MS-WIN-SECURITY-CAPAUTHZ-L1-1-1.DLL\nEXT-MS-WIN-SECURITY-CHAMBERS-L1-1-0.DLL\nEXT-MS-WIN-SECURITY-CHAMBERS-L1-1-1.DLL\nEXT-MS-WIN-SECURITY-CREDUI-INTERNAL-L1-1-0.DLL\nEXT-MS-WIN-SECURITY-CREDUI-L1-1-0.DLL\nEXT-MS-WIN-SECURITY-CRYPTUI-L1-1-0.DLL\nEXT-MS-WIN-SECURITY-CRYPTUI-L1-1-1.DLL\nEXT-MS-WIN-SECURITY-EFS-L1-1-1.DLL\nEXT-MS-WIN-SECURITY-EFSWRT-L1-1-1.DLL\nEXT-MS-WIN-SECURITY-WINSCARD-L1-1-0.DLL\nEXT-MS-WIN-SESSION-USERMGR-L1-1-0.DLL\nEXT-MS-WIN-SESSION-USERMGR-L1-2-0.DLL\nEXT-MS-WIN-SESSION-USERTOKEN-L1-1-0.DLL\nEXT-MS-WIN-SESSION-WINSTA-L1-1-0.DLL\nEXT-MS-WIN-SESSION-WTSAPI32-L1-1-0.DLL\nEXT-MS-WIN-SETUPAPI-INF-L1-1-0.DLL\nEXT-MS-WIN-SETUPAPI-INF-L1-1-1.DLL\nEXT-MS-WIN-SHELL-DIRECTORY-L1-1-0.DLL\nEXT-MS-WIN-SHELL-EMBEDDEDMODE-L1-1-0.DLL\nEXT-MS-WIN-SHELL-SHELL32-L1-2-0.DLL\nEXT-MS-WIN-SHELL-SHLWAPI-L1-2-0.DLL\nEXT-MS-WIN-SHELL32-SHELLCOM-L1-1-0.DLL\nEXT-MS-WIN-SHELL32-SHELLFOLDERS-L1-2-0.DLL\nEXT-MS-WIN-SMBSHARE-BROWSERCLIENT-L1-1-0.DLL\nEXT-MS-WIN-STORAGE-SENSE-L1-2-0.DLL\nEXT-MS-WIN-SXS-OLEAUTOMATION-L1-1-0.DLL\nEXT-MS-WIN-TSF-MSCTF-L1-1-2.DLL\nEXT-MS-WIN-UI-VIEWMANAGEMENT-L1-1-0.DLL\nEXT-MS-WIN-USP10-L1-1-0.DLL\nEXT-MS-WIN-WER-UI-L1-1-0.DLL\nEXT-MS-WIN-WER-XBOX-L1-1-0.DLL\nEXT-MS-WIN-WINRT-STORAGE-L1-1-0.DLL\nEXT-MS-WIN-WLAN-ONEXUI-L1-1-0.DLL\nEXT-MS-WIN-WLAN-SCARD-L1-1-0.DLL\nIESHIMS.DLL\n\nSo probably/hopefully one or more packages should be the answer to my problems :) any ideas?\nThanks for your help!\n--Rp\n. Well, \nLIBOPENBLAS was missing but I tried setting it on the script using a \nsys.path.append('./../../../bin/Debug')\nI know very little python so I don't know if it has the same effect, I'm going to try adding it to path and I'll let you know, thanks for your time clovett!\n--Rp. There you go!! so sys.path.append only works for python modules? Anyhow, thank you very much clovett!! Now I can continue with the tutorial!. Hi pquodling,\nSWIG will allow to use ELL from other languages such as python, you can download SWIG from http://www.swig.org/. If you need to build the interfaces (for example to run the tutorial), you'll need SWIG; you can follow the instructions on https://github.com/Microsoft/ELL/tree/master/interfaces\nHope it helps!\n--Rp. Hi VedAustin,\nYou still need to build the python interface, follow the instructions here https://github.com/Microsoft/ELL/tree/master/interfaces. I'm still having some issues on that part, so please let me know if it works.\n--Rp. I'll piggy back on this one... right at the end of the tutorial, it makes a reference to a build script (compile_darknetReference.cmd)... where is this script located? . The one at the root is the original folder, the one under build is a copy created during build; I'm following the contentes of a compiling.md file but the tutorial says there is a build script, i think this file is missing on the repo. Nevermind... I just realized those files where added after I originally clone the repo, I just did fetch/pull :). Did you use the rebuild.cmd? It uses a different configuration RelWithDebInfo, none of the scripts point to that one :(. ",
    "cjacobs": "Hi,\nCould you cd to your build directory, run cmake .. and paste the result here?\nThanks!. Looks good to me! Thanks!. Hi,\nThis error is due to the implementations of the model_InputCallback and model_OutputCallback being in the model header file. If the header gets included more than once, those callback functions can get multiply defined.\nThere's a fix in the works for this error, and it should appear here soon. In the meantime, here's a workaround:\nAt the top of the generated model.h file, add a #pragma once to ensure the file doesn't get included multiple times. Then at the bottom of the same file, put an #ifdef block around the callback definitions:\n```\npragma once\n...\nifdef MAIN\nextern \"C\" \n{\n  // (callbacks here)\n} // extern \"C\"\nendif\n```\nThen in your main.cpp file, define the MAIN symbol before including the model header file:\n```\ndefine MAIN\ninclude \"model.h\"\n...\n```\nNow the callback definitions will only be seen when compiling main.cpp, and the linker error should go away.\nKeep in mind that the model.h file gets regenerated when you compile the model, so you'll have to re-modify it if you recompile.\nHope this helps!\n--chuck\n. Thanks for the report! I'll take a look.. Hi,\nIs the compile executable perhaps in /homne/marohera/git/ell/ELL/build/bin? (without the 'release')?. ",
    "jackcc": "Thank you for your reply, this is the log\n-- Blas libraries: /usr/lib/libf77blas.so;/usr/lib/libatlas.so\n-- Blas linker flags: \n-- Blas include directories: /usr/include\n-- Using BLAS include path: /usr/include\n-- Using BLAS library: /usr/lib/libf77blas.so;/usr/lib/libatlas.so\n-- Using BLAS DLLs: \n-- Could NOT find SWIG (missing:  SWIG_EXECUTABLE SWIG_DIR) (Required is at least version \"3.0.12\")\nCMake Warning at CMakeLists.txt:83 (message):\n  SWIG not found, interfaces and projects that depend on them will not build\n  properly.  They are not part of the default make targets, so can be\n  skipped.  If you want to build interfaces (such as the Python bindings),\n  follow the instructions in INSTALL-XXXXX.md file to install SWIG.  Then\n  delete the CMakeCache.txt file from your build directory run the cmake\n  command again.\n-- Could NOT find SWIG (missing:  SWIG_EXECUTABLE SWIG_DIR) (Required is at least version \"3.0.12\")\nCMake Warning at interfaces/python/CMakeLists.txt:9 (message):\n  Couldn't find Python libraries 3.5 or later, _ELL_python target will not be\n  build properly.  This is not a required component, so it can be skipped.\n-- Could NOT find SWIG (missing:  SWIG_EXECUTABLE SWIG_DIR) (Required is at least version \"3.0.12\")\n-- Creating wrappers for python\n-- Could NOT find SWIG (missing:  SWIG_EXECUTABLE SWIG_DIR) (Required is at least version \"3.0.12\")\n-- Creating wrappers for javascript\n-- Found npm at /usr/bin/npm\n-- Could NOT find SWIG (missing:  SWIG_EXECUTABLE SWIG_DIR) (Required is at least version \"3.0.12\")\n-- Creating wrappers for xml\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/jack/ELL/build\n. from the log: \nSWIG:This is not a required component, so it can be skipped.\nSWIG must be installed?i will try it.. Thanks,@vipings,it works.but the interface is python , which i want is C++. any more suggestions?. @lisaong you are right\uff0cthank you very much.Before I installed openblas, I have installed atlas.so i remove atlas,it works very well.. ",
    "LiyuCode": "Sorry, guys, when doing reproduction on a different computer, https://github.com/Microsoft/ELL/tree/master/interfaces seems enough. \nThe above sol can be misleading. \n[Issue Close]. ",
    "msftclas": "This seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \n@sambolu,\nThanks for your contribution.\nTo ensure that the project team has proper rights to use your work, please complete the Contribution License Agreement at https://cla.microsoft.com.\nIt will cover your contributions to all Microsoft-managed open source projects.\nThanks,\nMicrosoft Pull Request Bot. @sambolu, thanks for signing the contribution license agreement. We will now validate the agreement and then the pull request.\nThanks, Microsoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\nMicrosoft Pull Request Bot.  All CLA requirements met..  All CLA requirements met.. ",
    "hwchong": "CNTK has support for Keras (beta at this stage). You should be able to import a Keras model and convert it to a CNTK model?\nhttps://docs.microsoft.com/en-us/cognitive-toolkit/Using-CNTK-with-Keras\n. ",
    "jacobmanning": "Anyone find a reliable way to convert a Keras model to CNTK format? I haven't had any luck. What is the output of your cmake .. command? Has CMake correctly found your Python libraries?. @Fred-Erik I had the same issue, were you able to run the tests (python test.py) in ELL/build/interfaces/python/test? That script is adding \"ELL/build/interfaces/python\" to the system path before importing ELL. It looks like the directory \"ELL/build/interfaces/python\" has the \"_ELL.so\" and \"ELL.py\" for importing ELL. Hmm. I'm not an expert, but OpenBLAS and BLAS are two different things. It looks like that import is trying to find BLAS, not OpenBLAS. In fact, it looks like when I installed ELL cmake used BLAS instead of OpenBLAS.\nMy advice would be to install BLAS and LAPACK (sudo apt-get install libblas-dev liblapack-dev), remove the build directory (rm -rf build) and try to rebuild ELL (mkdir build && cd build and cmake ..). When you run cmake .. you should get a list of outputs. Make sure that \"-- Blas Libraries\" now points to the /usr/lib/libblas.so from your BLAS installation.\nAlso, on the topic of the original question, in this README the instructions say to move the ELL/build/interfaces/python/ELL.py and ELL/build/interfaces/python/_ELL.so files to your Python site packages. That should solve the original ImportError once BLAS is installed.. I have that same version of OpenBLAS. I haven't actually run the tutorials though so I don't know how performance is. ",
    "malynda": "I've been running with cmake v3.7.2. Downloading cmake 3.9.0.rc5 now.... Woohoo, it worked!. If you take a look at the changes I made, I did strip the .tar... the documentation included the .tar. And there was a space missing between two links in the wget line.. @clovett what version of Ubuntu are you using? I'm now trying this on my 16.04 box and everything is going swimmingly so far.. I discovered I didn't have llvm installed... went back, installed, re-did cmake and was able to run make just fine.. Now trying this on my 16.04 box which default has cmake 3.5 ... perhaps only 17.04 needs 3.9? 17.04 default was 3.7.2. Nope, just followed what the Python Language Bindings instructions on https://github.com/Microsoft/ELL/blob/master/interfaces/README.md said.. Thanks @jimaobian !  Have you already submitted a PR for that?. This matches PR #22 . Hi! I had this issue also, on Ubuntu 17.04. I had the problem on the initial make from https://github.com/Microsoft/ELL/blob/master/INSTALL-Ubuntu.md. \nWhat OS & version are you running? . ",
    "codelast": "Actually my gcc version is quite new:\n\ngcc (GCC) 7.1.1 20170516\n\nSince you said that I don't need to compile ELL on Pi, then OK, I know I did a meaningless thing, so just wait to see your updated doc.\nThank you.. And below are the output of my \"cmake ..\" command under the \"build\" dir:\n\n-- The C compiler identification is GNU 6.3.0\n-- The CXX compiler identification is GNU 6.3.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Looking for pthread_create in pthreads\n-- Looking for pthread_create in pthreads - not found\n-- Looking for pthread_create in pthread\n-- Looking for pthread_create in pthread - found\n-- Found Threads: TRUE\n-- Blas libraries: /usr/lib/libf77blas.so;/usr/lib/libatlas.so\n-- Blas linker flags: \n-- Blas include directories: \n-- Using BLAS include path: /usr/include\n-- Using BLAS library: /usr/lib/libf77blas.so;/usr/lib/libatlas.so\n-- Using BLAS DLLs: \n-- Found PythonInterp: /home/codelast/.miniconda3/bin/python (found version \"3.6.1\") \n-- Found PythonLibs: /home/codelast/.miniconda3/lib/libpython3.6m.so (found version \"3.6.1\") \n-- Found SWIG: /usr/local/bin/swig (found suitable version \"3.0.12\", minimum required is \"3.0.12\") \n-- Creating wrappers for python\n-- Creating wrappers for javascript\n-- Creating wrappers for xml\n-- Using python found at: /home/codelast/.miniconda3/bin/python\n-- Using python libraries found at: /home/codelast/.miniconda3/lib/libpython3.6m.so\n-- Creating wrappers for python\n-- Generated target compiled_vgg16ImageNet_host\n-- Generated target compiled_vgg16ImageNet_pi3\n-- Generated target compiled_vgg16ImageNet_pi0\n-- Generated target compiled_darknetReference_host\n-- Generated target compiled_darknetReference_pi3\n-- Generated target compiled_darknetReference_pi0\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/codelast/programme/pi/ELL/build. @dirksy Could you please give a more detailed info about which files to rename?\nCan I just uninstall libatlas-dev?\nThank you.. @dirksy OK, I'll try it later, thank you.. @dirksy After I uninstalled the following 3 packages from my Ubuntu 14.04, the \"make\" process finally succeeded, thank you!\nsudo apt-get remove libatlas-base-dev libatlas-dev ibatlas3-base. @dirksy Not able to run the demo yet, still have some other problems to be solved.. @lovettchris Thank you for providing the info, I'll try it later.. @lovettchris \nsudo apt-get install libopenmpi-dev can't solve the problem because on Ubuntu 14.04 the package installed by this way is too old:\n[codelast@ ~]$ apt-cache show libopenmpi-dev\nVersion: 1.6.5-8\n[codelast@ ~]$ ll /usr/lib/libmpi.so*\nlrwxrwxrwx 1 root root 27  7 12 00:03 /usr/lib/libmpi.so -> /etc/alternatives/libmpi.so\nlrwxrwxrwx 1 root root 15 12 29  2013 /usr/lib/libmpi.so.1 -> libmpi.so.1.0.8\nlrwxrwxrwx 1 root root 27 12 29  2013 /usr/lib/libmpi.so.1.0.8 -> openmpi/lib/libmpi.so.1.0.8\n\nWhile ELL requires libmpi.so.12, so I have to do the following things:\n(1) uninstall all the openmpi-related packages on my Ubuntu 14.04:\n\nsudo apt-get remove libmpich-dev mpi-default-dev libopenmpi-dev libopenmpi1.6 openmpi-common\n\n(2) download the openmpi-1.10.2.tar.gz package on this web page, and then :\n\ntar zxf openmpi-1.10.2.tar.gz\ncd openmpi-1.10.2/\n./configure\nmake\nsudo make install\n\n(3) check the installation:\n\n[codelast@ ~]$ sudo find ./ -name libmpi.so.12\n./usr/local/lib/libmpi.so.12\n\nThat's it! Problem solved!. @clovett I tried, and it didn't work.\nAfter hours of search I finally figured it out why.\nOn my Ubuntu 14.04, the way by ELL doc to install opencv caused the error result:\n\nconda install -c conda-forge opencv\n\nHere is the solution:\n\nconda install --channel loopbio --channel conda-forge --channel pkgw-forge gtk2 ffmpeg ffmpeg-feature gtk2-feature opencv\n\nRefer to the following two links for details:\n(1) https://stackoverflow.com/questions/40207011/opencv-not-working-properly-with-python-on-linux-with-anaconda-getting-error-th\n(2) https://github.com/conda-forge/opencv-feedstock/issues/43. @lovettchris \nMaybe it's not very common to install Arch Linux ARM on RPi comparing to Raspbian, and Arch Linux ARM for RPi has a very new gcc version(under default installation), as you seen, 7.1.1.\nIt's not easy to install gcc 6 on Arch Linux ARM - I tried to build gcc 6 from source, and it took a very very long time & failed finally :(\nI've read the tutorial in your post, and if I did't misunderstand it, the problem I mentioned in this issue is in the step \"Compiling the model code on target device into a Python module\", and what you said \"I normally build the raspberry pi binaries on my host PC\" must be under the condition that your cross-compilation toolchain properly setup on your PC, right?\nSo I'm in a embarrassing situation: firstly I have no cross-compilation toolchain on my Ubuntu PC, secondly my RPi OS has gcc 7.1.1 which may too new.\nI consider maybe reinstalling Raspbian on my RPi a more time-saving way to solve my problem?\nAny other suggestions?\nThank you.. I did try to build the target .so several times on my Ubuntu PC, but all of them failed and didn't provide a clear error reason:\n\n(py36) [codelast@ build]$ make compiled_vgg16ImageNet_pi3\n[ 16%] Built target utilities\n[ 18%] Built target math\n[ 23%] Built target data\n[ 38%] Built target emitters\n[ 40%] Built target evaluators\n[ 45%] Built target functions\n[ 60%] Built target model\n[ 63%] Built target predictors\n[ 78%] Built target nodes\n[ 85%] Built target trainers\n[ 96%] Built target common\n[ 98%] Built target compile\n[ 98%] Generating /home/codelast/programme/pi/ELL/build/tutorials/vision/gettingStarted/compiled_vgg16ImageNet_pi3/vgg16ImageNet.ll;/home/codelast/programme/pi/ELL/build/tutorials/vision/gettingStarted/compiled_vgg16ImageNet_pi3/vgg16ImageNet.i;/home/codelast/programme/pi/ELL/build/tutorials/vision/gettingStarted/compiled_vgg16ImageNet_pi3/vgg16ImageNet.i.h\nOpenBLAS : Your OS does not support AVX instructions. OpenBLAS is using Nehalem kernels as a fallback, which may give poorer performance.\n[100%] Compiling vgg16ImageNet.ll to /home/codelast/programme/pi/ELL/build/tutorials/vision/gettingStarted/compiled_vgg16ImageNet_pi3/vgg16ImageNet.o for pi3\nKilled\nmake[3]:  [tutorials/vision/gettingStarted/compiled_vgg16ImageNet_pi3/vgg16ImageNet.o] Error 137\nmake[3]:  Deleting file `tutorials/vision/gettingStarted/compiled_vgg16ImageNet_pi3/vgg16ImageNet.o'\nmake[2]:  [tutorials/vision/gettingStarted/CMakeFiles/compiled_vgg16ImageNet_pi3.dir/all] Error 2\nmake[1]:  [tutorials/vision/gettingStarted/CMakeFiles/compiled_vgg16ImageNet_pi3.dir/rule] Error 2\nmake: *** [compiled_vgg16ImageNet_pi3] Error 2\n\nI don't know whether it has more detailed log about the error ?. @lisaong Thank you so much & I'll try darknet later.. @DarrenRainey Seems that you were right. I switched to darknet and the compilation successfully finished.\nSo it must be that compiling the CNTK model using too much resource on my old PC :(. @lisaong As you suggested, I just tried darknet and successfully compiled it on my Ubuntu PC.\nThank you so much.. Thank you for your reply.\nThese days I tried several methods but none of them works for me :(\nI don't have atlas installed on my RPi, and I check the blas library .so file printed by the cmake command, it does contains the cblas_sgemm function, e.g. \n\nnm -D xxx.so | grep cblas_sgemm\n(The output is NOT empty, e.g. \"0005f230 T cblas_sgemm\")\n\nI havn't figured out this problem yet, if anyone knows anything that might help solving this problem, please post a comment here, thank you in advance.. @lisaong I figure it out finally :)\nHere is my solution(all following steps are executed on RPi 3):\n Uninstall the blas & cblas library installed by \"pacman -S blas cblas\"(I'm using Arch Linux ARM on RPi 3, command pacman -S xxx is just like the apt-get install xxx on Raspbian)\n Download the OpenBlas source code & compile it from souce, then install it to /usr/lib/openblas\n* Before \"cmake ..\", set the LD_LIBRARY_PATH to let the openblas lib directory be found by cmake:\n\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/openblas/lib\n* make a little change to the OpenBLASSetup.cmake file, add path /usr/lib/openblas/include/ to the set(BLAS_INCLUDE_SEARCH_PATHS section, that is, the section will looks like:\nset(BLAS_INCLUDE_SEARCH_PATHS\n    /System/Library/Frameworks/Accelerate.framework/Versions/Current/Frameworks/vecLib.framework/Versions/Current/Headers/\n    /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/Headers/\n    /usr/include\n    /usr/local/include\n    /usr/lib/openblas/include\n)\n\n\n\nAfter that, the blas-related messages in cmake output looks like:\n\n\n-- Blas libraries: /usr/lib/openblas/lib/libopenblas.so\n-- Blas linker flags: \n-- Blas include directories: \n-- Using BLAS include path: /usr/lib/openblas/include\n-- Using BLAS library: /usr/lib/openblas/lib/libopenblas.so\n\n\nThen make the Python module _darknetReference.so, and test it, it works!\n\nFinally I would like to say thank you to all of your ELL developers, you gave me a lot of help in the process of testing it, and it's a quite good project.. I made a very, very simple comparison between ELL(Darknet model) & TensorFlow(Inception v3 model)  on doing image classification jobs, the result shows that:\n the inference speed of ELL+Darknet is much faster than TensorFlow+Inception v3\n the inference accuracy of ELL+Darknet is much worse than TensorFlow+Inception v3\nThe result can be found here(only has Chinese version, sorry). ",
    "VedAustin": "Yes .. Finally it is working!\nBefore I ran this: cmake --build .\nI ran this: cmake --build . --target _ELL_python --config Release\nThe above command might have installed ELL.py\nWhen I ran this: ctest --build-config Debug\nNone of the test even ran. So I figured i will run this: cmake --build . and reran this: ctest --build-config Debug\nAll tests passed.\nWhen I ran this step again : python cntkDemo.py I got a new error message about a openblas not being in the path, so I included it in the path. Now it is working as expected.\n. I found this under build\\tutorials\\vision\\gettingStarted\nBut I also found a tutorial folder under the root ELL. So I am a bit confused about two tutorials folder being present.. ",
    "YG-FLUSH": "In this page\n, it contains a wrong link(ELL Python Language Bindings) which is 404.. @jimaobian thanks! it works!. ",
    "sherwinjoseph": "This could be useful. ",
    "wuchangjin": "I had two problems:\n      (1)libraries/utilities/include/../tcc/Archiver.tcc:185:9: error: no matching function for call to \u2018ell::utilities::Unarchiver::UnarchiveArray(const char&, std::vector >&)\u2019\n         UnarchiveArray(name, arr);\n   \uff082\uff09libraries/utilities/include/../tcc/Archiver.tcc:67:9: error: no matching function for call to \u2018ell::utilities::Archiver::ArchiveArray(const char&, const std::vector >&)\u2019\n         ArchiveArray(name, array);\nwhy there had error ? \uff08on ubuntu16.04\uff0ccmake3.10.0-rc4,llvm3.9.1,g++/gcc version 5.4.0\uff09,and what shall i do for building it?thanks. ",
    "jimaobian": "@malynda There is a typo in findEll.py :\nsys.path.append(buildDir + '/tools/importers/Darknet')\nChange Darknet to darknet\n. Try:\nconda update --all -c conda-forge. ",
    "sria91": "@malynda I'm running Ubuntu 16.04. @lovettchris  I've installed openBLAS as well as doxygen. Still I am getting the error.. @lovettchris Yes, I do.. @jacobmanning Following is the output of the cmake command:\nsh\nsria91@gpumachine:~/Development/ELL/build$ cmake -D PYTHON_EXECUTABLE=/usr/bin/python3 ..\n-- The C compiler identification is GNU 5.4.0\n-- The CXX compiler identification is GNU 5.4.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Looking for pthread_create in pthreads\n-- Looking for pthread_create in pthreads - not found\n-- Looking for pthread_create in pthread\n-- Looking for pthread_create in pthread - found\n-- Found Threads: TRUE  \n-- Blas libraries: /usr/lib/libf77blas.so;/usr/lib/libatlas.so\n-- Blas linker flags: \n-- Blas include directories: \n-- Using BLAS include path: /usr/include\n-- Using BLAS library: /usr/lib/libf77blas.so;/usr/lib/libatlas.so\n-- Using BLAS DLLs: \n-- Found PythonInterp: /usr/bin/python3 (found version \"3.5.2\") \n-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.5m.so (found version \"3.5.2\") \n-- Found SWIG: /usr/local/bin/swig (found suitable version \"3.0.12\", minimum required is \"3.0.12\") \n-- Creating wrappers for python\n-- Creating wrappers for javascript\n-- Creating wrappers for xml\n-- Using python found at: /usr/bin/python3\n-- Using python libraries found at: /usr/lib/x86_64-linux-gnu/libpython3.5m.so\n-- Creating wrappers for python\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/sria91/Development/ELL/build\nOf course it finds the Python libraries.. @lovettchris yes. Following is the output of the make command on latest bits.\nsh\nsria91@gpumachine:~/Development/ELL/build$ make -j4\nScanning dependencies of target documentation\nScanning dependencies of target utilities\nScanning dependencies of target modelFiles\nScanning dependencies of target testing\n[  0%] Built target documentation\n[  0%] Building CXX object libraries/testing/CMakeFiles/testing.dir/src/testing.cpp.o\n[  0%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/CommandLineParser.cpp.o\n[  1%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/CompressedIntegerList.cpp.o\n[  1%] Built target modelFiles\n[  1%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/ConformingVector.cpp.o\n[  2%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/CStringParser.cpp.o\n[  2%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/Files.cpp.o\n[  2%] Linking CXX static library libtesting.a\n[  2%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/Format.cpp.o\n[  2%] Built target testing\n[  3%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/IArchivable.cpp.o\n[  3%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/IndentedTextWriter.cpp.o\n[  4%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/IntegerList.cpp.o\n[  4%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/IntegerStack.cpp.o\n[  4%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/JsonArchiver.cpp.o\n[  6%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/ObjectArchive.cpp.o\n[  6%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/ObjectArchiver.cpp.o\n[  7%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/OutputStreamImpostor.cpp.o\n[  7%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/PPMImageParser.cpp.o\n[  7%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/RandomEngines.cpp.o\n[  8%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/Tokenizer.cpp.o\n[  8%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/TypeName.cpp.o\n[  8%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/UniqueId.cpp.o\n[  9%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/Variant.cpp.o\n[  9%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/XmlArchiver.cpp.o\n[ 10%] Linking CXX static library libutilities.a\n[ 10%] Built target utilities\nScanning dependencies of target math\nScanning dependencies of target emitters\n[ 10%] Building CXX object libraries/math/CMakeFiles/math.dir/src/BlasWrapper.cpp.o\n[ 12%] Linking CXX static library libmath.a\n[ 12%] Built target math\nScanning dependencies of target math_test\nScanning dependencies of target data\nScanning dependencies of target functions\n[ 12%] Building CXX object libraries/math/CMakeFiles/math_test.dir/test/src/main.cpp.o\n[ 13%] Building CXX object libraries/data/CMakeFiles/data.dir/src/Dataset.cpp.o\n[ 13%] Building CXX object libraries/functions/CMakeFiles/functions.dir/src/ElasticNetRegularizer.cpp.o\n[ 13%] Building CXX object libraries/functions/CMakeFiles/functions.dir/src/HingeLoss.cpp.o\n[ 13%] Building CXX object libraries/data/CMakeFiles/data.dir/src/DataVector.cpp.o\n[ 14%] Building CXX object libraries/functions/CMakeFiles/functions.dir/src/L2Regularizer.cpp.o\n[ 15%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/EmitterTypes.cpp.o\n[ 15%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRAssemblyWriter.cpp.o\n[ 16%] Building CXX object libraries/data/CMakeFiles/data.dir/src/DataVectorOperations.cpp.o\n[ 16%] Building CXX object libraries/functions/CMakeFiles/functions.dir/src/LogLoss.cpp.o\n[ 18%] Building CXX object libraries/functions/CMakeFiles/functions.dir/src/SmoothHingeLoss.cpp.o\n[ 18%] Building CXX object libraries/functions/CMakeFiles/functions.dir/src/SquaredLoss.cpp.o\n[ 18%] Linking CXX static library libfunctions.a\n[ 18%] Built target functions\nScanning dependencies of target functions_test\n[ 19%] Building CXX object libraries/functions/CMakeFiles/functions_test.dir/test/src/main.cpp.o\n[ 19%] Building CXX object libraries/data/CMakeFiles/data.dir/src/GeneralizedSparseParsingIterator.cpp.o\n[ 19%] Building CXX object libraries/data/CMakeFiles/data.dir/src/SequentialLineIterator.cpp.o\n[ 19%] Linking CXX executable math_test\n[ 20%] Building CXX object libraries/data/CMakeFiles/data.dir/src/TextLine.cpp.o\n[ 20%] Linking CXX executable functions_test\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Copy(int, float const*, int, float*, int)':\nBlasWrapper.cpp:(.text+0x31): undefined reference to `cblas_scopy'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Copy(int, double const*, int, double*, int)':\nBlasWrapper.cpp:(.text+0x69): undefined reference to `cblas_dcopy'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Asum(int, float const*, int)':\nBlasWrapper.cpp:(.text+0x92): undefined reference to `cblas_sasum'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Asum(int, double const*, int)':\nBlasWrapper.cpp:(.text+0xba): undefined reference to `cblas_dasum'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Nrm2(int, float const*, int)':\nBlasWrapper.cpp:(.text+0xf0): undefined reference to `cblas_snrm2'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Nrm2(int, double const*, int)':\nBlasWrapper.cpp:(.text+0x118): undefined reference to `cblas_dnrm2'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Scal(int, float, float*, int)':\nBlasWrapper.cpp:(.text+0x15b): undefined reference to `cblas_sscal'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Scal(int, double, double*, int)':\nBlasWrapper.cpp:(.text+0x193): undefined reference to `cblas_dscal'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Axpy(int, float, float const*, int, float*, int)':\nBlasWrapper.cpp:(.text+0x1d9): undefined reference to `cblas_saxpy'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Axpy(int, double, double const*, int, double*, int)':\nBlasWrapper.cpp:(.text+0x221): undefined reference to `cblas_daxpy'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Dot(int, float const*, int, float const*, int)':\nBlasWrapper.cpp:(.text+0x259): undefined reference to `cblas_sdot'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Dot(int, double const*, int, double const*, int)':\nBlasWrapper.cpp:(.text+0x290): undefined reference to `cblas_ddot'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Gemv(CBLAS_LAYOUT, CBLAS_TRANSPOSE, int, int, float, float const*, int, float const*, int, float, float*, int)':\nBlasWrapper.cpp:(.text+0x309): undefined reference to `cblas_sgemv'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Gemv(CBLAS_LAYOUT, CBLAS_TRANSPOSE, int, int, double, double const*, int, double const*, int, double, double*, int)':\nBlasWrapper.cpp:(.text+0x37c): undefined reference to `cblas_dgemv'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Gemm(CBLAS_LAYOUT, CBLAS_TRANSPOSE, CBLAS_TRANSPOSE, int, int, int, float, float const*, int, float const*, int, float, float*, int)':\nBlasWrapper.cpp:(.text+0x3f5): undefined reference to `cblas_sgemm'\n../math/libmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Gemm(CBLAS_LAYOUT, CBLAS_TRANSPOSE, CBLAS_TRANSPOSE, int, int, int, double, double const*, int, double const*, int, double, double*, int)':\nBlasWrapper.cpp:(.text+0x471): undefined reference to `cblas_dgemm'\ncollect2: error: ld returned 1 exit status\nlibraries/functions/CMakeFiles/functions_test.dir/build.make:101: recipe for target 'libraries/functions/functions_test' failed\nmake[2]: *** [libraries/functions/functions_test] Error 1\nCMakeFiles/Makefile2:668: recipe for target 'libraries/functions/CMakeFiles/functions_test.dir/all' failed\nmake[1]: *** [libraries/functions/CMakeFiles/functions_test.dir/all] Error 2\nmake[1]: *** Waiting for unfinished jobs....\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Copy(int, float const*, int, float*, int)':\nBlasWrapper.cpp:(.text+0x31): undefined reference to `cblas_scopy'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Copy(int, double const*, int, double*, int)':\nBlasWrapper.cpp:(.text+0x69): undefined reference to `cblas_dcopy'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Asum(int, float const*, int)':\nBlasWrapper.cpp:(.text+0x92): undefined reference to `cblas_sasum'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Asum(int, double const*, int)':\nBlasWrapper.cpp:(.text+0xba): undefined reference to `cblas_dasum'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Nrm2(int, float const*, int)':\nBlasWrapper.cpp:(.text+0xf0): undefined reference to `cblas_snrm2'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Nrm2(int, double const*, int)':\nBlasWrapper.cpp:(.text+0x118): undefined reference to `cblas_dnrm2'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Scal(int, float, float*, int)':\nBlasWrapper.cpp:(.text+0x15b): undefined reference to `cblas_sscal'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Scal(int, double, double*, int)':\nBlasWrapper.cpp:(.text+0x193): undefined reference to `cblas_dscal'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Axpy(int, float, float const*, int, float*, int)':\nBlasWrapper.cpp:(.text+0x1d9): undefined reference to `cblas_saxpy'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Axpy(int, double, double const*, int, double*, int)':\nBlasWrapper.cpp:(.text+0x221): undefined reference to `cblas_daxpy'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Dot(int, float const*, int, float const*, int)':\nBlasWrapper.cpp:(.text+0x259): undefined reference to `cblas_sdot'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Dot(int, double const*, int, double const*, int)':\nBlasWrapper.cpp:(.text+0x290): undefined reference to `cblas_ddot'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Gemv(CBLAS_LAYOUT, CBLAS_TRANSPOSE, int, int, float, float const*, int, float const*, int, float, float*, int)':\nBlasWrapper.cpp:(.text+0x309): undefined reference to `cblas_sgemv'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Gemv(CBLAS_LAYOUT, CBLAS_TRANSPOSE, int, int, double, double const*, int, double const*, int, double, double*, int)':\nBlasWrapper.cpp:(.text+0x37c): undefined reference to `cblas_dgemv'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Gemm(CBLAS_LAYOUT, CBLAS_TRANSPOSE, CBLAS_TRANSPOSE, int, int, int, float, float const*, int, float const*, int, float, float*, int)':\nBlasWrapper.cpp:(.text+0x3f5): undefined reference to `cblas_sgemm'\nlibmath.a(BlasWrapper.cpp.o): In function `ell::math::Blas::Gemm(CBLAS_LAYOUT, CBLAS_TRANSPOSE, CBLAS_TRANSPOSE, int, int, int, double, double const*, int, double const*, int, double, double*, int)':\nBlasWrapper.cpp:(.text+0x471): undefined reference to `cblas_dgemm'\ncollect2: error: ld returned 1 exit status\nlibraries/math/CMakeFiles/math_test.dir/build.make:99: recipe for target 'libraries/math/math_test' failed\nmake[2]: *** [libraries/math/math_test] Error 1\nCMakeFiles/Makefile2:764: recipe for target 'libraries/math/CMakeFiles/math_test.dir/all' failed\nmake[1]: *** [libraries/math/CMakeFiles/math_test.dir/all] Error 2\n[ 20%] Building CXX object libraries/data/CMakeFiles/data.dir/src/WeightLabel.cpp.o\n[ 20%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRBlockRegion.cpp.o\n[ 21%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRDiagnosticHandler.cpp.o\n[ 22%] Linking CXX static library libdata.a\n[ 22%] Built target data\n[ 22%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IREmitter.cpp.o\n[ 24%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRExecutionEngine.cpp.o\n[ 24%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRFunctionEmitter.cpp.o\n[ 24%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRHeaderWriter.cpp.o\n[ 25%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRIfEmitter.cpp.o\n[ 25%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRLoader.cpp.o\n[ 25%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRLoopEmitter.cpp.o\n[ 26%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRMetadata.cpp.o\n[ 26%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRModuleEmitter.cpp.o\n[ 27%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IROptimizer.cpp.o\n[ 27%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRRuntime.cpp.o\n[ 27%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/IRSwigInterfaceWriter.cpp.o\n[ 28%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/ModuleEmitter.cpp.o\n[ 28%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/TargetDevice.cpp.o\n[ 30%] Building CXX object libraries/emitters/CMakeFiles/emitters.dir/src/Variable.cpp.o\n[ 30%] Linking CXX static library libemitters.a\n[ 30%] Built target emitters\nMakefile:94: recipe for target 'all' failed\nmake: *** [all] Error 2. @hustzxd Thanks that worked.. ",
    "hustzxd": "I got the same error. Have you solved it?\nerror report. I solved the problem by changing cmake version (3.5.1 to 3.9.0).\nwget https://cmake.org/files/v3.9/cmake-3.9.0-rc5.tar.gz\ntar zxvf cmake-3.9.0-rc5.tar.gz && cd cmake-3.9.0-rc5\n./bootstrap\nmake\nsudo make install. Thank you!   :)\nexport LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libstdc++.so.6. ",
    "Fred-Erik": "Thank you! The line you mentioned wasn't in my test.py, but when I added it it did manage to find something at least. Is everything working for you now? Because I now get the following error:\n\nTraceback (most recent call last):\n  File \"/home/frederik/Documents/dev/experimental/ELL/build/interfaces/python/ELL.py\", line 14, in swig_import_helper\n    return importlib.import_module(mname)\n  File \"/home/frederik/anaconda3/envs/ell/lib/python3.6/importlib/init.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"\", line 978, in _gcd_import\n  File \"\", line 961, in _find_and_load\n  File \"\", line 950, in _find_and_load_unlocked\n  File \"\", line 648, in _load_unlocked\n  File \"\", line 560, in module_from_spec\n  File \"\", line 922, in create_module\n  File \"\", line 205, in _call_with_frames_removed\nImportError: /usr/lib/libblas.so.3: undefined symbol: gotoblas\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"test.py\", line 14, in \n    import ELL\n  File \"/home/frederik/Documents/dev/experimental/ELL/build/interfaces/python/ELL.py\", line 17, in \n    _ELL = swig_import_helper()\n  File \"/home/frederik/Documents/dev/experimental/ELL/build/interfaces/python/ELL.py\", line 16, in swig_import_helper\n    return importlib.import_module('_ELL')\n  File \"/home/frederik/anaconda3/envs/ell/lib/python3.6/importlib/init.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\nImportError: /usr/lib/libblas.so.3: undefined symbol: gotoblas\n\nI have OpenBLAS installed; the newest version, according to apt-get: \"0.2.18-1ubuntu1\". The files are all there in /usr/lib/. I also tried forcing Anaconda to use OpenBLAS instead of MKL using these instructions but that didn't make a difference.. Thanks again! The suggestion from the README you linked solved the import issue. I already had BLAS installed but when I did sudo apt-get remove libopenblas* the errors stopped and test.py runs fine! So there seems to be something wrong with my OpenBLAS configuration. According to this README you can install OpenBLAS for optimization, which I would like.\nDo you have libopenblas-dev installed, and could you check which version? The version apt-get will installed with me is 0.2.18 (on Ubuntu 16.04) and seems not to work with ELL.\nThe performance without OpenBLAS is very much sub-par; to illustrate, the darknetDemo.py runs at < 1 FPS, whereas if I run the same model in the DarkNet framework, I get a prediction in 23ms (on CPU).. Yeah, I should have mentioned that I use DarkNet with NNPack and the DarkNet reference model (same one you are using). Thank you for giving your performance; this means that at least for now, DarkNet is faster and gives me more options (eg. object detection, which ELL does not yet support) for running CNNs on ARM. But I'm curious how the development will progress!. ",
    "sambolu": "I faced this issue too when I missed installing OpenBLAS.\nPlease install this library and try again. It resolved this compilation issue\n\"sudo apt-get install -y libopenblas-dev doxygen\". ",
    "liudf0716": "@sambolu thanks, I will try it.  . it work, thanks @sambolu . ",
    "vyraun": "@ack72tdp @jacobrosenthal Hi, I Am getting the same error after running the vision demo:\nCould not find './../../../build/interfaces/python/ELL.py', did you follow the ELL Python Binding build instructions?\nRunning test.py gives Import Error. Python bindings didn't get installed I guess. ctest --build-config Debug works perfectly, all tests are passed.\nHow did you resolve the issue? I am not sure what installation has to do with the instructions at https://github.com/Microsoft/ELL/tree/master/interfaces.\nPlease take a look. Thanks.  \n. @lovettchris Thanks for the reply. However, I had executed that command and running it again says: [100%] Build target _ELL_python, while the error message \"Could not find ....\" continues upon running the python tutorial. I am on an Ubuntu 16.04 system. Thanks.. ",
    "dirksy": "could anyone tell me why my questions had nothing reply?. @clovett thanks for ur reply.\ni have modified some codes to use new labels just as i mentioned above like this \nhelper = mh.ModelHelper(\"darknetReference\", [\"data/tinyyolo.cfg\", \"data/tinyyolo.weights\"], \"data/coco.txt\",(416,416))\nwatch param 'data/coco.txt'.\ndoes the label name must be darknetImageNetLabels.txt? and the path must same as darknetDemo.py? i will try it soon.\nbtw.i have run it correctly on pi3 with darknet.cfg&weight.result is amazing and fantastic.ell just took 1300ms-1600ms for each cycle.very good\n\nI have tested the probelm still exist.\nI put tiny-yolo.cfg & tiny-yolo.weights in path where darknetDemo.py is.and update darknetImageNetLabels.txt with \"coco.data\" content which just contain just 80 classes.\nthe fatal error information is same.. @lovettchris thanks for your confirmation.\nI am not sure '  Note that tiny-yolo is 224x224, not 416x416.  ' means. as dimension of image described in tiny-yolo.cfg&weights I used for training or testing  is 416x416.what u means I can just modify the cfg file' image width&height params to 224x224? and then i am able to get correct result like your demo ? i am confused.\n\nI checked your tiny-darknet link. that is not the files I used. so I update links above tiny-yolo.cfg&weights files. pls check it again thank you.. thanks for your soon reply.\nlink of tiny-yolo.cfg :https://github.com/pjreddie/darknet/blob/master/cfg/tiny-yolo.cfg\nand tiny-yolo.weights :https://pjreddie.com/media/files/tiny-yolo.weights\nif you need ,I can send you label file.\nall right. \n1\\your first bug is in my fist comment(your parser encounter a '#\"),just clean '#' in cfg file ,that will be ok.\n2\\will the second problem be solved ? and when ?\n3\\will ELL suport the third problem ? and when ?\nmany thanks!\n. just waiting for ur good news.. just waiting for ur good news.. your python3.6 environment path must be wrong.pls check it.ell still use python2.7. see?\n. u have both atlas and blas . u can rename atlas files and re-cmake. then the problem solved.. @codelast yes.u r right.but u should make sure there r no atlas libs in path /usr/lib or usr/local/lib.. @codelast my pleasure.btw do u record demo run duration? how many ms every cycle  it took ?. ",
    "zschoyanm": "You need a newer Version of cmake and gcc.\nHave the same issue with the old gcc and cmake in Ubuntu 16.04.\nUse cmake 3.8.2 and gcc 6.3 and it works.. ",
    "sajunkmails": "Thanks, it worked.  Managed to install the cmake and gcc versions mentioned, and passed the parameter to \"make\" to use gcc-6, and it worked.  Thanks again!. ",
    "PeterLayton": "if you install python2.7 first, it will use python2.7 environment normally, so you can open the environment setting and add the 3.6 environment and set it front of the 2.7.. ",
    "tdpdan": "A dark cloud of ignorance just wooshed away. Thank you lovettchris!\nI did not run your test. I built this on a windows laptop that has no camera and as soon as I read your post I face-palmed.\nThank you!. ",
    "grahamehorner": "You could try https://hub.docker.com/r/ryankurte/ this is an emulator of the Raspberry PI environment running inside docker. @lovettchris IMHO the esp32 is a chip that I feel is ideal for edge processing where low power WiFi or Bluetooth is used for communication, I have personally used these a number of times in personal projects with great success. IMHO ELL would be a great on these devices and/or aurduio device maybe an ELL arduino runtime library is a possible option if ELL is not able/going to support native compilation for the ESP32 FreeRTOS ICs ? \nI would love to see this re-opened to allow more discussion on ELL and ICs that aren\u2019t covered with the LLVM compiler generally.. FYI \nhttps://github.com/Sonicadvance1/llvm-xtensa. So something like mono-llvm ? . Is it at all possible to swap out the llvm implementation used by ELL with something like https://github.com/Sonicadvance1/llvm-xtensa to attempt generation of code for Xtensa = ESP8266/ESP32 as well as wasm etc.. sorry; that doesn't work for me :'( looking at rebuilding a dev machine specifically to research ELL and guidance what to include on the dev box (VM). @clovett thanks it\u2019s really interesting work you guys are doing and it would be good to understand the longer term roadmap and/or vision of the chips/languages you are thinking of supporting. Keep up the great work loving the ideas \ud83d\udca1 . I was thinking something more like \nneural network -> ELL -> C# -> CoreRT -> C++ ?\nneural network -> ELL -> object + .h -> ?\nas then ELL could build upon the CoreRT efforts and perhaps be deployed onto a platform that is not currently supported; but becomes a supported CoreRT platform ?\nall just thinking aloud with ideas for the future; loving the fact ML/AI is running on the edge and the work you guys are doing :D  +1000\n. @clover cool would love to contribute as when if you guys start this or believe the effort is worth the time. @lovettchris cool, looking to build a dev me today for exactly that, looking forward to creating some awesome proof of concepts using ELL \ud83d\udd96. @rverm44820 No, Visual Studio & Visual Studio Code are NOT the same, Visual Studio is a commercial IDE; yet is offered for free as a Community Edition for Windows & iOS it has a lot more functionality the VS Code.  VS Code is a free cross platform IDE that allows development on Windows, iOS and a number of Linux operating systems.   \nI would recommend using the Visual Studio 2017 Community Edition for this repo in the first instance.. ",
    "cocteau666": "My cmake result is below.\n-- The C compiler identification is GNU 6.3.0\n-- The CXX compiler identification is GNU 6.3.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Looking for pthread_create in pthreads\n-- Looking for pthread_create in pthreads - not found\n-- Looking for pthread_create in pthread\n-- Looking for pthread_create in pthread - found\n-- Found Threads: TRUE\n-- Blas libraries: /usr/lib/libopenblas.so\n-- Blas linker flags: \n-- Blas include directories: \n-- Using BLAS include path: /usr/include\n-- Using BLAS library: /usr/lib/libopenblas.so\n-- Using BLAS DLLs: \n-- Found PythonInterp: /usr/bin/python3 (found version \"3.4.2\") \n-- Found PythonLibs: /usr/lib/arm-linux-gnueabihf/libpython3.4m.so\n-- Found SWIG: /usr/local/bin/swig (found suitable version \"3.0.12\", minimum required is \"3.0.12\") \n-- Creating wrappers for python\n-- Creating wrappers for javascript\n-- Creating wrappers for xml\n-- Using python found at: /usr/bin/python3\n-- Using python libraries found at: /usr/lib/arm-linux-gnueabihf/libpython3.4m.so\n-- Creating wrappers for python\n-- Generated target compiled_vgg16ImageNet_host\n-- Generated target compiled_vgg16ImageNet_host_profile\n-- Generated target compiled_vgg16ImageNet_pi3\n-- Generated target compiled_vgg16ImageNet_pi3_profile\n-- Generated target compiled_vgg16ImageNet_pi0\n-- Generated target compiled_vgg16ImageNet_aarch64\n-- Generated target compiled_darknetReference_host\n-- Generated target compiled_darknetReference_host_profile\n-- Generated target compiled_darknetReference_pi3\n-- Generated target compiled_darknetReference_pi3_profile\n-- Generated target compiled_darknetReference_pi0\n-- Generated target compiled_darknetReference_aarch64\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /root/ELL/build\ncmake options:\n\n-DPYTHON_INCLUDE_DIR=/usr/include/python3.4m\n-DPYTHON_LIBRARY=/usr/lib/arm-linux-gnueabihf/libpython3.4m.so\n-DPYTHON_EXECUTABLE=/usr/bin/python3\n\nSWIG has been compiled from source code.\ngcc-6 has been installed from stretch repository.\n. ",
    "alan-gu": "Sorry for the delay.\nThank you for your answer. I managed to run the program, but the result was undesirable. The worst thing is that I just know too little about machine learning to have any thought on this.\nOur group is completely new to this machine learning thing. After trying for about a week, we decided to get more general ideas about machine learning before applying it to our system, which seems to be a very advanced  task. We hope we could be able to challenge this task in 3 months.\nThank you again.. ",
    "xhMatt": "Thanks, I compiled the source code without error, but I cant find the generated header file darknetReference_i.h in ELL directory or any of subdirectory (Ubuntu 16.04),  what I am trying to do is translate your .py to .cpp, but I don't think this could help, thanks!. ",
    "hiramf": "Found the problem. Line 33 in cntkDemo.py defines the wrong variable.\nlast_prediction = \"\"\nshould be \nlastPrediction = \"\". ",
    "vrbala": "@h4gen Hi, I am also interested in using ELL library in Cortex series micro controllers. I am barely a starter and would like to know more about this and looking forward for options to  collaborate. \nCould you provide any pointers on how to start on this please? Currently I am spending most of my time on learning the Cortex ecosystem.\nMany thanks!. Thanks @h4gen! This is a very good starter for me. . ",
    "saurabhvyas": "will it work on esp32 ? . ",
    "Dezorian": "Same FPS 0.7-0.8 on my RPi3. You could try overclocking it if you need it faster.\nBut for a CNN i've heard that this performance is already pretty awesome! CNTK network didnt even load because of the size of net file >512MB wich is too large for the rpi. Sticking to darknet and training my own data!. > will it work on esp32 ?\nI seriously doubt it.. ",
    "Sneha369": "okay. I will try it out on the 64 bit. Thanks for the reply :). Hi,\nI have tried it on 64 bit , and everything worked!! Thank you.. ",
    "CheekyMonkey": "Hi, I observe the same issue:\n82% tests passed, 6 tests failed out of 33\nTotal Test time (real) = 113.06 sec\nThe following tests FAILED:\n          6 - math_test (Failed)\n          8 - model_compiler_test (Failed)\n          9 - nodes_test (ILLEGAL)\n         10 - predictors_test (ILLEGAL)\n         14 - darknet_importer_test (ILLEGAL)\n         32 - ell_module_test (Failed)\nErrors while running CTest\nMy CPU is \"Mobile Intel Core i5 520M (Arrandale)\"\nMy registry value for the following key\n\\HKEY_LOCAL_MACHINE\\HARDWARE\\DESCRIPTION\\System\\CentralProcessor\\0\nis \"Intel64 Family 6 Model 37 Stepping 5\"\nThe CPU types shown in OpenBLASSetup.cmake are:\n    # Haswell: Family 6, model 60, 63, 69\n    # Broadwell: Family 6, Model 70, 79 (compatible with Haswell)\n    # Kobylake: Family 6, Model 78 (compatible with Haswell)\n    # Sandybridge: Family 6, model 42, 45\n    # Ivybridge: Family 6, model 58 (compatible with Sandybridge)\n    # Skylake: Family 6, model 42\n\nIs there a processor-specific version of OpenBLAS for my particular CPU?\n\n\n. Thanks for the guidance\nThat appears to have made a difference in my case\nAfter running through the compile steps again, test outcomes are now as follows:\n(py36) G:\\DeepLearning\\Microsoft\\ELL\\build>ctest --build-config Release\nTest project G:/DeepLearning/Microsoft/ELL/build\n      Start  1: common_test\n 1/33 Test  #1: common_test ......................   Passed    0.97 sec\n      Start  2: data_test\n 2/33 Test  #2: data_test ........................   Passed    0.02 sec\n      Start  3: emitters_test\n 3/33 Test  #3: emitters_test ....................   Passed    0.45 sec\n      Start  4: evaluators_test\n 4/33 Test  #4: evaluators_test ..................   Passed    0.01 sec\n      Start  5: functions_test\n 5/33 Test  #5: functions_test ...................   Passed    0.02 sec\n      Start  6: math_test\n 6/33 Test  #6: math_test ........................   Passed    0.08 sec\n      Start  7: model_test\n 7/33 Test  #7: model_test .......................   Passed    0.29 sec\n      Start  8: model_compiler_test\n 8/33 Test  #8: model_compiler_test ..............   Passed    2.75 sec\n      Start  9: nodes_test\n 9/33 Test  #9: nodes_test .......................   Passed    0.07 sec\n      Start 10: predictors_test\n10/33 Test #10: predictors_test ..................   Passed    0.03 sec\n      Start 11: trainers_test\n11/33 Test #11: trainers_test ....................   Passed    0.02 sec\n      Start 12: utilities_test\n12/33 Test #12: utilities_test ...................   Passed    0.88 sec\n      Start 13: cntk_importer_test\n13/33 Test #13: cntk_importer_test ...............   Passed    8.72 sec\n      Start 14: darknet_importer_test\n14/33 Test #14: darknet_importer_test ............   Passed    0.78 sec\n      Start 15: linearTrainer_test_0\n15/33 Test #15: linearTrainer_test_0 .............   Passed    0.10 sec\n      Start 16: linearTrainer_test_1\n16/33 Test #16: linearTrainer_test_1 .............   Passed    0.11 sec\n      Start 17: linearTrainer_test_2\n17/33 Test #17: linearTrainer_test_2 .............   Passed    0.03 sec\n      Start 18: linearTrainer_test_3\n18/33 Test #18: linearTrainer_test_3 .............   Passed    0.03 sec\n      Start 19: linearTrainer_test_4\n19/33 Test #19: linearTrainer_test_4 .............   Passed    0.03 sec\n      Start 20: linearTrainer_test_5\n20/33 Test #20: linearTrainer_test_5 .............   Passed    0.03 sec\n      Start 21: linearTrainer_test_6\n21/33 Test #21: linearTrainer_test_6 .............   Passed    0.05 sec\n      Start 22: linearTrainer_test_7\n22/33 Test #22: linearTrainer_test_7 .............   Passed    0.03 sec\n      Start 23: linearTrainer_test_8\n23/33 Test #23: linearTrainer_test_8 .............   Passed    0.04 sec\n      Start 24: linearTrainer_test_9\n24/33 Test #24: linearTrainer_test_9 .............   Passed    0.03 sec\n      Start 25: linearTrainer_test_10\n25/33 Test #25: linearTrainer_test_10 ............   Passed    0.03 sec\n      Start 26: forestTrainer_test\n26/33 Test #26: forestTrainer_test ...............   Passed    0.11 sec\n      Start 27: sweepingSGDTrainer_test\n27/33 Test #27: sweepingSGDTrainer_test ..........   Passed    0.11 sec\n      Start 28: apply_test\n28/33 Test #28: apply_test .......................   Passed    0.04 sec\n      Start 29: compile_test1\n29/33 Test #29: compile_test1 ....................   Passed    0.09 sec\n      Start 30: compile_test2\n30/33 Test #30: compile_test2 ....................   Passed    0.07 sec\n      Start 31: ell-python-interface-test\n31/33 Test #31: ell-python-interface-test ........   Passed    0.71 sec\n      Start 32: ell_module_test\n32/33 Test #32: ell_module_test ..................***Failed    0.29 sec\n      Start 33: ELL_step10_python_test\n33/33 Test #33: ELL_step10_python_test ...........   Passed    0.09 sec\n97% tests passed, 1 tests failed out of 33\nTotal Test time (real) =  18.92 sec\nThe following tests FAILED:\n         32 - ell_module_test (Failed)\nErrors while running CTest\nThe test that fails, shows the following in the test logs:\n32/33 Testing: ell_module_test\n32/33 Test: ell_module_test\nCommand: \"C:/Program Files (x86)/nodejs/node.exe\" \"TestCompiler.js\"\nDirectory: G:/DeepLearning/Microsoft/ELL/interfaces/javascript/ell_module/test/js\n\"ell_module_test\" start time: Aug 07 04:50 GMT Summer Time\nOutput:\n\nG:\\DeepLearning\\Microsoft\\ELL\\interfaces\\javascript\\ell_module\\test\\js\\TestCompiler.js:3\nlet path = require('path');\n^^^\nSyntaxError: Unexpected strict mode reserved word\n    at exports.runInThisContext (vm.js:73:16)\n    at Module._compile (module.js:443:25)\n    at Object.Module._extensions..js (module.js:478:10)\n    at Module.load (module.js:355:32)\n    at Function.Module._load (module.js:310:12)\n    at Function.Module.runMain (module.js:501:10)\n    at startup (node.js:129:16)\n    at node.js:814:3\n\nTest time =   0.29 sec\n\nTest Failed.\n\"ell_module_test\" end time: Aug 07 04:50 GMT Summer Time\n\"ell_module_test\" time elapsed: 00:00:00\n\nAre you able to share any guidance on how to overcome that test failure?\nI should point out that despite the failed test, both the darknet and cntk image recognition demo scripts work as expected\n. ",
    "lmiroslaw": "I have an Ivybridge and had to recompile OpenBLAS.\nI also replaced the libs in the mentioned directory with the new ones:\n1049089    99328 Aug  3 10:44 libgcc_s_seh-1.dll\n1049089  1220096 Aug  3 10:44 libgfortran-3.dll\n1049089 17663597 Aug  3 10:44 libopenblas.dll\n1049089   346112 Aug  3 10:44 libquadmath-0.dll\nNow, the passing rate is a bit greater: \n88% tests passed, 4 tests failed out of 32\nTotal Test time (real) =  37.98 sec\nThe following tests FAILED:\n          6 - math_test (Failed)\n          8 - model_compiler_test (Failed)\n          9 - nodes_test (Failed)\n         10 - predictors_test (Failed)\nErrors while running CTest. ",
    "y-vyrovoy": "so what was the solution?. ",
    "Weiney": "I have the same problem today,to solve this\nadd ms path to the Environmental path\nlike  D:\\Microsoft Visual Studio\\MSBuild\\15.0\\Bin. ",
    "butterl": "I  also interested in this, and others may too. \nFor if we can get a clear look on the performance and use case optimization , ELL would get more people in .\n@lisaong  I find you are answering many issue\uff0c would you like to help  to share it :)\n. ",
    "stephansgit": "Thanks! Works like a charm.... @kernhanda I've update my initial post with the full output of cmake .. - please see above.\nThanks for looking into it!. I edited my original post for missing information.\nIf it helps:\ncmake --version gives cmake version 3.11.3;\ngcc-8 --version gives gcc-8 (Ubuntu 8.1.0-5ubuntu1~16.04) 8.1.0\n. @kernhanda, this solved the issue.\nThanks, really glad you took the time to look into it!. Thanks; it works now!. ",
    "irjudson": "+1 - Implementing so it can be done via Xamarin (cross platform) would be ideal for me. Targets -> iOS, Android. ",
    "amitmc19": "Apologies for the delay in my response. I have anaconda installed. To rule out installation problems, I uninstalled and reinstalled Anaconda.(conda version is 4.3.27)\nI opened a terminal(win cmd prompt) using the Anaconda navigator and created a python 3.6 environment. I activated the python 3.6 environment. Post this I ran the script \"cmake --build . --target _ELL_python --config Release\" (as mentioned in the link)\nI still get the Python.h not found error. (Attached the build logs)\npyELLBuildError.txt\n. I deleted the build folder, and followed the \"Building ELL\" section again. After this, I don't see the problem anymore. \nThanks for the help. (Looks like the reinstall of anaconda helped). ok. If I copy this folder into my local setup, then I get a different error. \n\"../utilities/pythonlibs\\find_ell.py../utilities/pythonlibs\\find_ell.py is not found\"\nLooks like lot of contents in the ELL changed after I cloned it.  \nShould I use the latest clone and re start the windows setup again?\n. ",
    "SaimaSafdar": "Hello\nI am getting lots of error while building slicer. I am new here. Please see the following:\nI am using Visual studio 2017, git2.16.2-64-bit, cmake 3.11.0, qt 4.7.4, slicer 4.9.0, sil.1.9.7 and window 7\nPlease see the below:\nSeverity    Code    Description Project File    Line    Suppression State\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   MSB6006 \"cmd.exe\" exited with code 1.   curl    C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   LNK1112 module machine type 'x86' conflicts with target machine type 'x64' [C:\\SLicer4Build\\CTKAppLauncherLib-build\\CTKAppLauncher.vcxproj] CTKAppLauncherLib   C:\\SLicer4Build\\QtCored4.lib(QtCored4.dll)  1 \nError   LNK1112 module machine type 'x86' conflicts with target machine type 'x64' [C:\\SLicer4Build\\CTKAppLauncherLib-build\\CTKAppLauncherW.vcxproj]    CTKAppLauncherLib   C:\\SLicer4Build\\QtCored4.lib(QtCored4.dll)  1 \nError   LNK1112 module machine type 'x86' conflicts with target machine type 'x64' [C:\\SLicer4Build\\CTKAppLauncherLib-build\\CTKAppLauncher.vcxproj] CTKAppLauncherLib   C:\\SLicer4Build\\QtCored4.lib(QtCored4.dll)  1 \nError   LNK1112 module machine type 'x86' conflicts with target machine type 'x64' [C:\\SLicer4Build\\CTKAppLauncherLib-build\\CTKAppLauncherW.vcxproj]    CTKAppLauncherLib   C:\\SLicer4Build\\QtCored4.lib(QtCored4.dll)  1 \nError   MSB6006 \"cmd.exe\" exited with code 1.   python  C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 3.   python-appdirs  C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 3.   python-pyparsing    C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 3.   python-six  C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 3.   python-packaging    C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 1.   python-setuptools   C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 3.   python-smmap    C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 1.   python-gitdb    C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 3.   python-wheel    C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 3.   python-GitPython    C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 1.   python-nose C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 3.   python-couchdb  C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 3.   python-chardet  C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 3.   python-pip  C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 1.   NUMPY   C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 1.   VTKv9   C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 3. [C:\\SLicer4Build\\ITKv4-build\\Wrapping\\Modules\\ITKCommon\\ITKCommonSwig.vcxproj]    ITKv4   C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   C1083   Cannot open include file: 'patchlevel.h': No such file or directory [C:\\SLicer4Build\\ITKv4-build\\Wrapping\\Generators\\Python\\PyBase\\ITKPyBasePython.vcxproj] ITKv4   c:\\slicer4build\\itkv4\\wrapping\\generators\\python\\patchedpython27pyconfig.h  2 \nError   C1083   Cannot open include file: 'patchlevel.h': No such file or directory [C:\\SLicer4Build\\ITKv4-build\\Wrapping\\Generators\\Python\\PyBase\\ITKPyBasePython.vcxproj] ITKv4   c:\\slicer4build\\itkv4\\wrapping\\generators\\python\\patchedpython27pyconfig.h  2 \nError   MSB6006 \"cmd.exe\" exited with code 1. [C:\\SLicer4Build\\ITKv4-build\\Wrapping\\Generators\\Python\\PyUtils\\ITKPyUtilsCastXML.vcxproj]    ITKv4   C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 3. [C:\\SLicer4Build\\ITKv4-build\\Wrapping\\Modules\\ITKCommon\\ITKCommonSwig.vcxproj]    ITKv4   C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   C1083   Cannot open include file: 'patchlevel.h': No such file or directory [C:\\SLicer4Build\\ITKv4-build\\Wrapping\\Generators\\Python\\PyBase\\ITKPyBasePython.vcxproj] ITKv4   c:\\slicer4build\\itkv4\\wrapping\\generators\\python\\patchedpython27pyconfig.h  2 \nError   C1083   Cannot open include file: 'patchlevel.h': No such file or directory [C:\\SLicer4Build\\ITKv4-build\\Wrapping\\Generators\\Python\\PyBase\\ITKPyBasePython.vcxproj] ITKv4   c:\\slicer4build\\itkv4\\wrapping\\generators\\python\\patchedpython27pyconfig.h  2 \nError   MSB6006 \"cmd.exe\" exited with code 1. [C:\\SLicer4Build\\ITKv4-build\\Wrapping\\Generators\\Python\\PyUtils\\ITKPyUtilsCastXML.vcxproj]    ITKv4   C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   LNK1112 module machine type 'x86' conflicts with target machine type 'x64' [C:\\SLicer4Build\\CTK-build\\QtTesting-build\\QtTesting.vcxproj] [C:\\SLicer4Build\\CTK-build\\QtTesting.vcxproj]  CTK C:\\SLicer4Build\\QtCored4.lib(QtCored4.dll)  1 \nError   LNK1112 module machine type 'x86' conflicts with target machine type 'x64' [C:\\SLicer4Build\\CTK-build\\QtTesting-build\\QtTesting.vcxproj] [C:\\SLicer4Build\\CTK-build\\QtTesting.vcxproj]  CTK C:\\SLicer4Build\\QtCored4.lib(QtCored4.dll)  1 \nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   C1083   Cannot open include file: 'Python.h': No such file or directory [C:\\SLicer4Build\\CTK-build\\PythonQt-build\\PythonQt.vcxproj] [C:\\SLicer4Build\\CTK-build\\PythonQt.vcxproj]    CTK c:\\slicer4build\\ctk-build\\pythonqt\\src\\pythonqtpythoninclude.h  90\nError   LNK1112 module machine type 'x86' conflicts with target machine type 'x64' [C:\\SLicer4Build\\CTK-build\\QtTesting-build\\QtTesting.vcxproj] [C:\\SLicer4Build\\CTK-build\\QtTesting.vcxproj]  CTK C:\\SLicer4Build\\QtCored4.lib(QtCored4.dll)  1 \nError   LNK1112 module machine type 'x86' conflicts with target machine type 'x64' [C:\\SLicer4Build\\CTK-build\\QtTesting-build\\QtTesting.vcxproj] [C:\\SLicer4Build\\CTK-build\\QtTesting.vcxproj]  CTK C:\\SLicer4Build\\QtCored4.lib(QtCored4.dll)  1 \nError   MSB6006 \"cmd.exe\" exited with code 1. [C:\\SLicer4Build\\SimpleITK-build\\SimpleITK.vcxproj]   SimpleITK   C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   MSB6006 \"cmd.exe\" exited with code 1. [C:\\SLicer4Build\\SimpleITK-build\\SimpleITK.vcxproj]   SimpleITK   C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets 171 \nError   LNK1104 cannot open file 'vtkRenderingOpenGL.lib' [C:\\SLicer4Build\\SlicerExecutionModel-build\\ModuleDescriptionParser\\ModuleDescriptionParser.vcxproj]  SlicerExecutionModel    C:\\SLicer4Build\\LINK    1 \nError   LNK1104 cannot open file 'vtkRenderingOpenGL.lib' [C:\\SLicer4Build\\SlicerExecutionModel-build\\ModuleDescriptionParser\\ModuleDescriptionParser.vcxproj]  SlicerExecutionModel    C:\\SLicer4Build\\LINK    1 \nError       VTK was not configured to use QT, you probably need to recompile it Slicer  C:\\SLicer4Build\\CUSTOMBUILD 1   \n. Want to build slicer then utilizing its template for building modules c++. ",
    "Ppinjari": "Thanks for quick reply. \nIf it doesn't support training of neural network, then what is the use case of trainers (SGD, SDCA, etc) that ELL is supporting. (Trainers are defined in libraries/trainers/). Will ELL support training of CNN in near future?. ",
    "Tryljs": "Thank you!\nIn the ELL, is the darknet model running  with a ELL frame or a darknet frame ?  And  what's the use of the codes in the neural file?. If i want to use c++ to call the darknet model, does the ELL can  provide some function interfaces to implement it?. Thank you!. Thank you very much.. Thanks too much! I've done to recognition the target  with your demo. \n And another question, does the 'darknet_Predict' function can return the location information of the target, such as top point, size and so on ? . Now, I want to run ELL on Cortex-A9. But it just support target platforms are pi3, aarch64 and host, none of them are ARMv7 framework. And I find the cross compiling of 'arm-poky-linux-gnueabi-gcc' coundn't to compile ELL, because the std of 'arm-poky-linux-gnueabi-gcc' is not supported. How can I do for ELL to make it run on Cortex-A9?. \u6211\u770b\u4e86\u4e0b\u751f\u6210\u7684\u6587\u4ef6  \u5e94\u8be5\u662f\u652f\u6301ARM\u7aef\u7684. \u8fd9\u4e2a\u6211\u662f\u731c\u7684  \u6211\u4e5f\u6ca1\u6709\u5b9e\u73b0. My compiler's version is 5.4.0.20160609. I upgrade my compiler version with 6.3.0. But it doesn't work.. This problem had been solved.. Lack of caching. In the predict function, I found its parameters are \"double\", \"float*\", how to input my picture to predict the result?. I don't think. Before I update the code, my script runs in the Windows and it can successfully execute the 'darknet_import.py'. I executed the ELL code was 2017-12-28. The running message as following:\nE:\\darknet_to_ell>python ../ELL_20171228/tools/importers/darknet/darknet_import.\npy darknet.cfg darknet.weights'\nConvolution : 224x224x3 -> 224x224x16 | input padding 1 output padding 0\n......\nSaving model file: 'darknet.ell'\nE:\\darknet_to_ell>pause\n. Not. ",
    "IvanFarkas": "Without CUDA and OpenBLAS is OK.\nI'll repeat the test when proper processor model detection (OpenBLAS) and VS 2017 build with CUDA 9 fix is in.. Re-tested. Success.. I am waiting for CNTK CUDA 9 and VS 2017 compatibility.\nIt's promised that it will be done in this iteration, hopefully in a couple of days. Thx.. Correct. Confused with the other similar issue. I'll just wait for CUDA 9 support. Thx.. It works now. All tests succeded.\nInstalled CNTK 2.3\nran this\nshell\nsource activate py36\ncd ELL/build\nctest --force-new-ctest-process --verbose -C Release\nResult is OK\n```shell\ntest 14\n      Start 14: cntk_importer_test\n14: Test command: /home/ifarkas/miniconda3/envs/py36/bin/python \"-m\" \"unittest\" \"cntk_to_ell_importer_test.py\"\n14: Test timeout computed to be: 9.99988e+06\n14: ssssssssss\n14: ----------------------------------------------------------------------\n14: Ran 10 tests in 0.000s\n14:\n14: OK (skipped=10)\n14/33 Test #14: cntk_importer_test ...............   Passed    0.33 sec\n```. I am waiting for CNTK CUDA 9 and VS 2017 compatibility.\nIt's promised that it will be done in this iteration, hopefully in a couple of days. Thx.. Installed CNTK 2.3. All tests passed.\nTest Results.txt\n. C:/ML/EEL/ELL is the ELL GitHup repo root.. The full output is below\n```\n(py36) C:\\ML\\EEL\\Tutorial\\Importing_Models>python C:/ML/EEL/ELL/tools/importers/cntk/cntk_import.py model.cntk\nLoading...\nSelected CPU as the process wide default device.\nFinished loading.\nPre-processing...\nWill not process linear - skipping this layer as irrelevant.\nWill not process Dropout - skipping this layer as irrelevant.\nWill not process linear - skipping this layer as irrelevant.\nWill not process Dropout - skipping this layer as irrelevant.\nWill not process linear - skipping this layer as irrelevant.\nWill not process Combine - skipping this layer as irrelevant.\nConvolution : 226x226x3 -> 224x224x64 | input padding 1 output padding 0\nReLU : 224x224x64 -> 226x226x64 | input padding 0 output padding 1\nConvolution : 226x226x64 -> 224x224x64 | input padding 1 output padding 0\nReLU : 224x224x64 -> 224x224x64 | input padding 0 output padding 0\nMaxPooling : 224x224x64 -> 114x114x64 | input padding 0 output padding 1\nConvolution : 114x114x64 -> 112x112x128 | input padding 1 output padding 0\nReLU : 112x112x128 -> 114x114x128 | input padding 0 output padding 1\nConvolution : 114x114x128 -> 112x112x128 | input padding 1 output padding 0\nReLU : 112x112x128 -> 112x112x128 | input padding 0 output padding 0\nMaxPooling : 112x112x128 -> 58x58x128 | input padding 0 output padding 1\nConvolution : 58x58x128 -> 56x56x256 | input padding 1 output padding 0\nReLU : 56x56x256 -> 58x58x256 | input padding 0 output padding 1\nConvolution : 58x58x256 -> 56x56x256 | input padding 1 output padding 0\nReLU : 56x56x256 -> 58x58x256 | input padding 0 output padding 1\nConvolution : 58x58x256 -> 56x56x256 | input padding 1 output padding 0\nReLU : 56x56x256 -> 56x56x256 | input padding 0 output padding 0\nMaxPooling : 56x56x256 -> 30x30x256 | input padding 0 output padding 1\nConvolution : 30x30x256 -> 28x28x512 | input padding 1 output padding 0\nReLU : 28x28x512 -> 30x30x512 | input padding 0 output padding 1\nConvolution : 30x30x512 -> 28x28x512 | input padding 1 output padding 0\nReLU : 28x28x512 -> 30x30x512 | input padding 0 output padding 1\nConvolution : 30x30x512 -> 28x28x512 | input padding 1 output padding 0\nReLU : 28x28x512 -> 28x28x512 | input padding 0 output padding 0\nMaxPooling : 28x28x512 -> 16x16x512 | input padding 0 output padding 1\nConvolution : 16x16x512 -> 14x14x512 | input padding 1 output padding 0\nReLU : 14x14x512 -> 16x16x512 | input padding 0 output padding 1\nConvolution : 16x16x512 -> 14x14x512 | input padding 1 output padding 0\nReLU : 14x14x512 -> 16x16x512 | input padding 0 output padding 1\nConvolution : 16x16x512 -> 14x14x512 | input padding 1 output padding 0\nReLU : 14x14x512 -> 14x14x512 | input padding 0 output padding 0\nMaxPooling : 14x14x512 -> 7x7x512 | input padding 0 output padding 0\nReLU : 1x1x4096 -> 1x1x4096 | input padding 0 output padding 0\nReLU : 1x1x4096 -> 1x1x4096 | input padding 0 output padding 0\nSoftmax : 1x1x1000 -> 1x1x1000 | input padding 0 output padding 0\nFinished pre-processing.\nError occurred attempting to convert cntk layers to ELL layers\nTraceback (most recent call last):\n  File \"C:/ML/EEL/ELL/tools/importers/cntk/cntk_import.py\", line 59, in \n    main(sys.argv[1:]) # drop the first argument (program name)\n  File \"C:/ML/EEL/ELL/tools/importers/cntk/cntk_import.py\", line 44, in main\n    predictor = cntk_to_ell.predictor_from_cntk_model(filename)\n  File \"C:\\ML\\EEL\\ELL\\tools\\importers\\cntk\\cntk_to_ell.py\", line 53, in predictor_from_cntk_model\n    raise exception\n  File \"C:\\ML\\EEL\\ELL\\tools\\importers\\cntk\\cntk_to_ell.py\", line 50, in predictor_from_cntk_model\n    predictor = ELL.FloatNeuralNetworkPredictor(ellLayers)\n  File \"C:\\ML\\EEL\\ELL\\build\\interfaces\\python\\ELL.py\", line 4448, in init\n    this = _ELL.new_FloatNeuralNetworkPredictor(layers, scaleFactor)\nValueError: Input tensor must not exceed output tensor (minus padding) dimensions for activation layer.\n```. I do not have CNTK installed.\nI am still waiting to be able to compile with VS 2017.. I am just following your playbook.\nStep1 - Get CNTK model VGG16_ImageNet_Caffe.model\n(py36) C:\\ML\\EEL\\Tutorial\\Importing_Models>curl --location -o model.cntk https://www.cntk.ai/Models/Caffe_Converted/VGG16_ImageNet_Caffe.model\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  527M  100  527M    0     0  5657k      0  0:01:35  0:01:35 --:--:-- 4610k\nStep 2 - Get categories.txt\n(py36) C:\\ML\\EEL\\Tutorial\\Importing_Models>curl --location -o categories.txt https://raw.githubusercontent.com/Microsoft/ELL-models/master/models/ILSVRC2012/ILSVRC2012_labels.txt\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0    120      0 --:--:-- --:--:-- --:--:--   120\nStep 3 - Run cntk_import.py\n```\n(py36) C:\\ML\\EEL\\Tutorial\\Importing_Models>python C:/ML/EEL/ELL/tools/importers/cntk/cntk_import.py model.cntk\nLoading...\nSelected CPU as the process wide default device.\nFinished loading.\nPre-processing...\nWill not process linear - skipping this layer as irrelevant.\nWill not process Dropout - skipping this layer as irrelevant.\nWill not process linear - skipping this layer as irrelevant.\nWill not process Dropout - skipping this layer as irrelevant.\nWill not process linear - skipping this layer as irrelevant.\nWill not process Combine - skipping this layer as irrelevant.\nConvolution : 226x226x3 -> 224x224x64 | input padding 1 output padding 0\nReLU : 224x224x64 -> 226x226x64 | input padding 0 output padding 1\nConvolution : 226x226x64 -> 224x224x64 | input padding 1 output padding 0\nReLU : 224x224x64 -> 224x224x64 | input padding 0 output padding 0\nMaxPooling : 224x224x64 -> 114x114x64 | input padding 0 output padding 1\nConvolution : 114x114x64 -> 112x112x128 | input padding 1 output padding 0\nReLU : 112x112x128 -> 114x114x128 | input padding 0 output padding 1\nConvolution : 114x114x128 -> 112x112x128 | input padding 1 output padding 0\nReLU : 112x112x128 -> 112x112x128 | input padding 0 output padding 0\nMaxPooling : 112x112x128 -> 58x58x128 | input padding 0 output padding 1\nConvolution : 58x58x128 -> 56x56x256 | input padding 1 output padding 0\nReLU : 56x56x256 -> 58x58x256 | input padding 0 output padding 1\nConvolution : 58x58x256 -> 56x56x256 | input padding 1 output padding 0\nReLU : 56x56x256 -> 58x58x256 | input padding 0 output padding 1\nConvolution : 58x58x256 -> 56x56x256 | input padding 1 output padding 0\nReLU : 56x56x256 -> 56x56x256 | input padding 0 output padding 0\nMaxPooling : 56x56x256 -> 30x30x256 | input padding 0 output padding 1\nConvolution : 30x30x256 -> 28x28x512 | input padding 1 output padding 0\nReLU : 28x28x512 -> 30x30x512 | input padding 0 output padding 1\nConvolution : 30x30x512 -> 28x28x512 | input padding 1 output padding 0\nReLU : 28x28x512 -> 30x30x512 | input padding 0 output padding 1\nConvolution : 30x30x512 -> 28x28x512 | input padding 1 output padding 0\nReLU : 28x28x512 -> 28x28x512 | input padding 0 output padding 0\nMaxPooling : 28x28x512 -> 16x16x512 | input padding 0 output padding 1\nConvolution : 16x16x512 -> 14x14x512 | input padding 1 output padding 0\nReLU : 14x14x512 -> 16x16x512 | input padding 0 output padding 1\nConvolution : 16x16x512 -> 14x14x512 | input padding 1 output padding 0\nReLU : 14x14x512 -> 16x16x512 | input padding 0 output padding 1\nConvolution : 16x16x512 -> 14x14x512 | input padding 1 output padding 0\nReLU : 14x14x512 -> 14x14x512 | input padding 0 output padding 0\nMaxPooling : 14x14x512 -> 7x7x512 | input padding 0 output padding 0\nReLU : 1x1x4096 -> 1x1x4096 | input padding 0 output padding 0\nReLU : 1x1x4096 -> 1x1x4096 | input padding 0 output padding 0\nSoftmax : 1x1x1000 -> 1x1x1000 | input padding 0 output padding 0\nFinished pre-processing.\nError occurred attempting to convert cntk layers to ELL layers\nTraceback (most recent call last):\n  File \"C:/ML/EEL/ELL/tools/importers/cntk/cntk_import.py\", line 59, in \n    main(sys.argv[1:]) # drop the first argument (program name)\n  File \"C:/ML/EEL/ELL/tools/importers/cntk/cntk_import.py\", line 44, in main\n    predictor = cntk_to_ell.predictor_from_cntk_model(filename)\n  File \"C:\\ML\\EEL\\ELL\\tools\\importers\\cntk\\cntk_to_ell.py\", line 53, in predictor_from_cntk_model\n    raise exception\n  File \"C:\\ML\\EEL\\ELL\\tools\\importers\\cntk\\cntk_to_ell.py\", line 50, in predictor_from_cntk_model\n    predictor = ELL.FloatNeuralNetworkPredictor(ellLayers)\n  File \"C:\\ML\\EEL\\ELL\\build\\interfaces\\python\\ELL.py\", line 4448, in init\n    this = _ELL.new_FloatNeuralNetworkPredictor(layers, scaleFactor)\nValueError: Input tensor must not exceed output tensor (minus padding) dimensions for activation layer.\n```\n. I'll retest by tomorrow. Thx Lisa.. That is so wonderful.\nI did that already as a separate exercise based on this great article:\nOptimizing OpenCV on the Raspberry Pi by Adrian Rosebrock \nIt would be great to include Optimizing OpenCV on the Raspberry Pi in your resources as an advanced material.\nAlso, it would be fantastic if you share your roadblocks or blocking dependencies with the community so motivated developers like myself can help all of us to succeed faster.\nI followed the article with slight modifications:\n\nI skipped Step #4, since I had MiniConda installed that ELL is using,\nAdded the following to CMake:\n-D PYTHON3_PACKAGES_PATH=/home/ifarkas/miniconda3/envs/py34/lib/python3.4/site-packages \\\n  -D PYTHON3_LIBRARY=/home/ifarkas/miniconda3/envs/py34/lib/libpython3.4m.so \\\n  -D PYTHON_INCLUDE_DIR=/home/ifarkas/miniconda3/envs/py34/include/python3.4m \\\n  -D PYTHON3_EXECUTABLE=/home/ifarkas/miniconda3/envs/py34/bin/python3.4 \\\n  -D PYTHON_NUMPY_INCLUDE_DIRS=/home/ifarkas/miniconda3/envs/py34/lib/python3.4/site-packages/numpy/core/include. Not yet. I did the optimization on Jessie with success.\nI'll do Stretch with py34 bindings over the weekend.. I got super fast SDs and will try 2 different \"Best\" cooling and overclock strategies.\nI can't wait to share the fast and OpenCV optimized test results.\nAfter success, I'll do the same on DragonBoard 410c.. Working on it. Embedded Learning Library (ELL) and OpenCV Optimization on Raspbian Stretch is published.\nIt describes how to build an optimized OpenCV on Raspbian Stretch, overclocking CPU and SD card, stress testing Pi and many other useful tidbits.. Thx Chris.\nConda channel is coming with a highly optimized OpenCV for Raspberry Pi Raspbian Stretch.\nI'll update the blog when it's ready.. I am new to creating a Conda armv7l (Raspbian) package recipe for OpenCV.\nBased on the Building conda packages for general code projects Conda tutorial does not seem too complicated, but as we all know the devil is always in the details.\n\nI used opencv-python packages on conda-forge channel as a base.\nUnzipped linux-64 opencv-3.3.0-py36_blas_openblas_201.tar.bz2 and used \\info\\recipe\\meta.yaml.template as my meta.yaml recipe (attached).\nDue to the fact that armv7l does not get the same attention as Windows, Linux and MacOS make it nearly impossible to accomplish this task.\nI found some armv7l OpenCV packages that are half-baked like opencv-python-armv7l 3.2.0 (no FFmpeg and cv2.imshow() does not work) (see METADATA.txt), and that is just unexaptable.\nIt's entirely possible that I am missing something. Community! SOS!\n(lose the .txt extension)\nmeta.yaml.txt\nMETADATA.txt\n. @lisaong I tried and I ran into dependency hell. I'll revisit another time. Thx for your help Lisa.. That's awesome, but it still does not answer my question.\nHow does ELL and AI Toolkit for Azure IoT Edge differ, please?. @eric-tang Thank you very much for the quick and detailed explanation.\nI do understand the differences now.\nFor Edge computing, I am looking for more powerful SBCs like DragonBoard 820c and the mighty Snapdragon 835 with sufficient active/liquid cooling to overclock CPU, GPU, memory.\nI am going to CES 2018 to see and test the latest from Qualcomm and others.\nMy application is the TeleCuris TeleHealth IoMT Kit is a TeleHealth Internet of Medical Things (IoMT) Remote Patient Diagnoses Kit consist of various remote vital sign diagnostic devices.\nAs soon as MS fixes the broken installation of Azure Machine Learning Workbench on Windows I'll blog about it at Ivan-Farkas.com\nSee the the detailed error in my comment (TeleCuris) at this link.\nInstallation of Azure Machine Learning Workbench on Windows fails!\nIt can't install ca-certificates 2017.7.27.\nI am looking forward to seeing your project results and compare notes. Good luck.. @lovettchris I'll do a blog next week about the Dragonboad 410c and compare it to a SnapDragon 820 Dev Kit as soon as I get one.\nChris. Which Linux distro do you prefer for ELL/Azure IoT Edge and camera, audio and sensor I/O?. @lovettchris Chris. What drone platform would you use in the next 6-12 month for the open source PX4 flight stack that I can integrate with ELL?\n\nPixhawk\nQualcomm\u00ae Snapdragon\u2122 Flight\u2122 Development Kit\nIntel Aero ready to fly drone\n\n. I'll sure do Chris. 2018 is gonna be a great year for IoT, Machine Learning, and intelligent drones!. @lovettchris Chris. How do I get in touch with you offline, please?. ELL built successfully.. ELL built successfully.. Twice. That worked. Compiled successfully. Please update the documents. Thx for your help.. What about after\nshell\nsudo apt update && sudo apt upgrade. ",
    "oferdekel": "Microsoft strives to make great products for our customers \u2013 Azure and Azure IoT are good examples. One way to create best-in-class products is to invest in basic computer science research, which is what we do at Microsoft Research. ELL is not a Microsoft product, it is an early preview of the ongoing research work done at Microsoft Research around resource-constrained AI. Microsoft Research often shares its latest research innovations with the external research community (and with tech enthusiasts in general) by publishing research papers and releasing open source code. . ",
    "eric-tang": "@IvanFarkas I'm prototyping a little project which gets both involved. Here is my understanding of the difference between AI Toolkit for Azure IoT edge and ELL:\nThe most notable thing to understand is the difference between the \"Edge\" concept in the term \"Azure IoT Edge\" and the \"thing\" concept in IoT area. If you go through the tutorial of Azure IoT edge, the \"Edge\" is actually a reasonable powerful local computing resource, which could be a Linux VM, a powerful local workstation or even a group of private local cloud deployed by your own. The Azure ToolKit (IMHO, it's actually not limited to just IoT kit, it could be any Azure toolset) is to deploy a bunch of Azure tools (e.g. some Machine Learning Framework/Libraries) onto your Edge devices which makes your Edge device a gateway between your IoT devices and Azure Cloud. The purposes for the concept of \"Edge\" is multi-fold, some straightforward benefits are: (1) Minimize the latency of the decision making between your IoT devices. You \"Edge\" device can quickly make the decision based on the information collected from IoT things and act on that fast by deliver the instruction on a local network. This is critical in some scenarios such as Drone/Robot control; (2) Minimize your cost for directly connect your IoT devices to Azure cloud. Imagine you have millions of IoT nodes in the wild and all of them keep sending messages to Azure Cloud. It would intrigue significant amount of cost on your bill. With a edge device, it can collect all those messages, analyze it, compress it and send it in a more efficient way to Azure cloud to minimize your cost. You can compare Azure IoT Edge to AWS GreenGrass service to understand the reasoning behind.\nOn the other hand, ELL is an AI focused library intended to run learning algorithms on resources constrained systems, such as a Raspberry Pi in the tutorial (Actually I think the confusion might come from the Raspberry Pi, since this little device is powerful enough to run as a \"Edge\"). The purpose of this library is to help you use the advanced AI techniques on you local IoT without Network with a reasonable amount of power consumption. My current prototype project requires to recognize some wild animals in the wild with no internet or very limited cellular connection. I cannot take pictures and consistently send large pictures back for recognition. Then ELL is super critical to me since I need to run it on my local IoT device and just send the recognition result back to my main service (either Edge or Azure public cloud).\nHopefully my understanding is a correct interpretation here and inspires the discussion here. @oferdekel . @lisaong Please take a look at this PR and include proper reviewers into it.\nThanks!. Hey @lisaong @kernhanda I made a few more changes based on your suggestions. Please take a loot at them to see if they fixed the issues. Thanks!. Close the PR per discussion with Chris offline @lovettchris . Edited. Thanks!. Moved over the line 47.. Fixed. Thanks!. Added the link to the tutorial. Thanks!. Yeah, you are right. I just remembered that I spent some time here. Thank you for the reminding!. Fixed.. Fixed. Thanks!. Fixed. Thanks!. Good to have it. Added. Thanks!. I removed the first section for the power cable stuff. I kept the \"Operating System\" section and the \"Network setup\" section to make user follow up correct steps on Raspberry Pi Zero.\nThanks!. For some reason, I didn't see any memory issue (or maybe I missed it). Yeah it's nice to have this set up before hand. I added a new section to instruct user setting up swap space before all package installation.\nThanks!. Wow, I just found a more serious issue here than just order, I missed a quote on pi3! Thank you for pointing out the order issue here :-). ",
    "huoyunjie": "\u591a\u8c22\uff01\u6211\u8fd8\u6ca1\u8dd1\u8fc7\uff0c\u4e00\u76f4\u6ca1\u6709\u770b\u5230\u5728micro:bit\u4e0a\u8fd0\u884c\u7684\u4f8b\u5b50\uff01. ",
    "JayjieL": "so how to solve this problem..... ",
    "julian0001": "Hallo @Tryljs have you solved your issue with the ModuleNotFoundError of ell._ell_py? Because I have the same issue now with CNTK.. Does anyone have the same issue with the python ell binding??. This is my output of ctest:\n(py36) C:\\Users\\Julian\\Documents\\ELL\\ELL.git\\trunk\\build>ctest --build-config Release\nTest project C:/Users/Julian/Documents/ELL/ELL.git/trunk/build\n      Start  1: common_test\n 1/36 Test  #1: common_test ......................   Passed    0.29 sec\n      Start  2: data_test\n 2/36 Test  #2: data_test ........................   Passed    0.03 sec\n      Start  3: dsp_test\n 3/36 Test  #3: dsp_test .........................   Passed    3.62 sec\n      Start  4: emitters_test\n 4/36 Test  #4: emitters_test ....................   Passed    0.25 sec\n      Start  5: evaluators_test\n 5/36 Test  #5: evaluators_test ..................   Passed    0.03 sec\n      Start  6: functions_test\n 6/36 Test  #6: functions_test ...................   Passed    0.04 sec\n      Start  7: math_test\n 7/36 Test  #7: math_test ........................   Passed    0.09 sec\n      Start  8: model_test\n 8/36 Test  #8: model_test .......................   Passed    0.08 sec\n      Start  9: model_compiler_test\n 9/36 Test  #9: model_compiler_test ..............   Passed    6.03 sec\n      Start 10: nodes_test\n10/36 Test #10: nodes_test .......................   Passed   14.00 sec\n      Start 11: passes_test\n11/36 Test #11: passes_test ......................   Passed    0.10 sec\n      Start 12: predictors_test\n12/36 Test #12: predictors_test ..................   Passed    0.06 sec\n      Start 13: trainers_test\n13/36 Test #13: trainers_test ....................   Passed    0.04 sec\n      Start 14: utilities_test\n14/36 Test #14: utilities_test ...................   Passed    1.15 sec\n      Start 15: cntk_importer_test\n15/36 Test #15: cntk_importer_test ...............Failed    0.81 sec\n      Start 16: darknet_importer_test\n16/36 Test #16: darknet_importer_test ............Exception: Exit code 0xc0000409\n  2.16 sec\n      Start 17: forestTrainer_test\n17/36 Test #17: forestTrainer_test ...............   Passed    0.07 sec\n      Start 18: linearTrainer_test_0\n18/36 Test #18: linearTrainer_test_0 .............   Passed    0.07 sec\n      Start 19: linearTrainer_test_1\n19/36 Test #19: linearTrainer_test_1 .............   Passed    0.06 sec\n      Start 20: linearTrainer_test_2\n20/36 Test #20: linearTrainer_test_2 .............   Passed    0.03 sec\n      Start 21: linearTrainer_test_3\n21/36 Test #21: linearTrainer_test_3 .............   Passed    0.04 sec\n      Start 22: linearTrainer_test_4\n22/36 Test #22: linearTrainer_test_4 .............   Passed    0.04 sec\n      Start 23: linearTrainer_test_5\n23/36 Test #23: linearTrainer_test_5 .............   Passed    0.04 sec\n      Start 24: linearTrainer_test_6\n24/36 Test #24: linearTrainer_test_6 .............   Passed    0.04 sec\n      Start 25: linearTrainer_test_7\n25/36 Test #25: linearTrainer_test_7 .............   Passed    0.03 sec\n      Start 26: linearTrainer_test_8\n26/36 Test #26: linearTrainer_test_8 .............   Passed    0.04 sec\n      Start 27: linearTrainer_test_9\n27/36 Test #27: linearTrainer_test_9 .............   Passed    0.04 sec\n      Start 28: linearTrainer_test_10\n28/36 Test #28: linearTrainer_test_10 ............   Passed    0.03 sec\n      Start 29: protoNNTrainer_test_0\n29/36 Test #29: protoNNTrainer_test_0 ............   Passed    0.25 sec\n      Start 30: sweepingSGDTrainer_test\n30/36 Test #30: sweepingSGDTrainer_test ..........   Passed    0.08 sec\n      Start 31: apply_test\n31/36 Test #31: apply_test .......................   Passed    0.07 sec\n      Start 32: compile_test1\n32/36 Test #32: compile_test1 ....................   Passed    0.11 sec\n      Start 33: compile_test2\n33/36 Test #33: compile_test2 ....................   Passed    0.05 sec\n      Start 34: make_profiler_test\n34/36 Test #34: make_profiler_test ...............Failed   49.90 sec\n      Start 35: wrap-test\n35/36 Test #35: wrap-test ........................   Passed   43.15 sec\n      Start 36: ell-python-interface-test\n36/36 Test #36: ell-python-interface-test ........Exception: Illegal  0.63 sec\n89% tests passed, 4 tests failed out of 36\nTotal Test time (real) = 124.21 sec\nThe following tests FAILED:\n         15 - cntk_importer_test (Failed)\n         16 - darknet_importer_test (Exit code 0xc0000409\n)\n         34 - make_profiler_test (Failed)\n         36 - ell-python-interface-test (ILLEGAL)\nErrors while running CTest. Hallo @clovett , \nI will check this now, but generally it should be possible to import a CNTK model as mentioned in the tutorial. Anyway are there any simple examples of a cntk model which I can reuse and which were already tested with the ELL? Because by now, as you mentioned, you are pretty sure that it would be supported. So I think it would be great if there are any examples with the cntk and also darknet model.\nAnd also a model which was generated with a supported base model, should run I think.\nThank you,\nJulian Sprenger. Hallo @clovett ,\nthey do, but if I want to import my own models with CNTK, like I mentioned (https://docs.microsoft.com/en-us/cognitive-toolkit/Build-your-own-image-classifier-using-Transfer-Learning) it does not work. Because my aim is, and I think it should also be so, to train with the own dataset a model and import it in ELL. So my question would be how can I use the CNTK correctly to import my model in the ELL?. Hallo @lovettchris ,\nthank you for your advice, but also with the latest ELL bits the wrap.py does not work for the new generated model.ell. I have tried it with one, two or three classes... I get always the same WrapException.\nMaybe there is a bug in the module \"ActivationLayerNode\"?\n(py36) C:\\Users\\Julian\\Documents\\ELLext\\transfer_learning>python %ELL_ROOT%/tools/wrap/wrap.py model.ell --language python --target host --verbose\ncopy \"C:\\Users\\Julian\\Documents\\ELLext\\ELL\\CMake/OpenBLASSetup.cmake\" \"host\\OpenBLASSetup.cmake\"\ncopy \"C:\\Users\\Julian\\Documents\\ELLext\\ELL\\interfaces/common/include/CallbackInterface.h\" \"host\\include\\CallbackInterface.h\"\ncopy \"C:\\Users\\Julian\\Documents\\ELLext\\ELL\\interfaces/common/tcc/CallbackInterface.tcc\" \"host\\tcc\\CallbackInterface.tcc\"\ncompiling model...\nC:/Users/Julian/Documents/ELLext/ELL/build/bin/release/compile -imap model.ell -cfn Predict -cmn model --bitcode --target host -od host --fuseLinearOps True --swig --blas true --optimize true\nexception: Input and output active area sizes don't match\ncommand C:/Users/Julian/Documents/ELLext/ELL/build/bin/release/compile failed with error code 1\nWrapException: : C:/Users/Julian/Documents/ELLext/ELL/build/bin/release/compile -imap model.ell -cfn Predict -cmn model --bitcode --target host -od host --fuseLinearOps True --swig --blas true --optimize true\n. Yes of course. Attached the sample dataset and the generated model.ell with its .gsdf - files.\ntransfer_learning.zip\ndata.zip\n. Hallo @lovettchris ,\nhave you tried out my sample dataset already?. Great thank you, it works finally \ud83d\udc4d. ",
    "psiphi75": "I had a similar issue under Linux and it appears that I did not compile ELL in the conda environment.\nHence running the following before compiling ELL:\nsh\nsource activate py36\nAnd making sure that before running any ELL commands you do the same.\n. ",
    "jesuspicazo": "Hi Lisa. Thanks to you for your replay. Is there any quick workaround to solve this until you have fixed the tutorial? I would be very thankful for that.\nThank you very much.\nBest regards.. Same thing happens to me. After importing my Darknet trained network to ELL it gives very bad results compared to the tests I have performed using just Darknet. What could be the reason?. I have trained a cnn using Darknet to  dintinguish between 3 classes of robots. I need ELL to implant this network in a raspberry pi who actuallly is on board of another robot. So the thing is that when I test the network as it gets out of darknet, it reaches like 90-95% accuracy.  I import the network as indicated in the tutorial and everything seems to be fine, but when I try it the percentages I obtain are almost always the same and are wrong and they are not similar to the results obtained when testing using darknet whatsoever.\nI'm attaching the cfg and weights files as required.\nrobotsGardenCressDoubleFC.cfg.zip\nrobotsGardenCressDoubleFC.weights.zip\nThank you so much \nfor this amazing tool and your dedication. . Thank you very much for your response. I've tried replacing darknet_to_ell.py but it isn't working. In fact, in this case, the predictions are always the same. No matter how different the test images are.\nI'll be waiting for your fix update. \nThank you again. . Hi,\nI'm just relaunching this issue because I'm still not able to import a Darknet-trained CNN properly using the import tool from ELL.\nTo make this problem easily reproducible, I have trained a very simple CNN which is the one that is in the Darknet tutorial for training a classifier on CIFAR-10 dataset. \nhttps://pjreddie.com/darknet/train-cifar/\nAfter training the network, I import the model exactly the way it is explained in the ELL c++ tutorial but when I try to recognize the images of the cifar-10 test set I obtain the following:\n-nan -nan -nan\n I also have observed that this happens when I set the activation of the convolutional layers as 'leaky'. When I turn them into 'relu' it doesn't give '-nan' but the results are very bad and they are always the same even with very different test images. Here I attach the .cfg and .weights files so the problem can b tested:\ncifar_small.cfg.zip\ncifar_small.weights.zip\nFor more details, I've tested this network using Darknet and it works as expected so I don't know whether I'm making any kind of mistake when using the darknet_import.py tool. Because I don't know what else it could be. \nPlease, I've been  dealing with this issue for like 2 months now and any help would be highly appreciated.\nThanks a lot in advance.\nCheers.\n. I'm facing the same issue too. Please, any help?\n. Please, are there any updates? . ",
    "m-zara": "Your new ELL model generator from CNTK puts these layers at the beginning:\n\"nodes\": [\n    {\n      \"_type\": \"InputNode\",\n      \"_version\": \"2\",\n      \"id\":       \"1012\",\n      \"size\": 1,\n      \"shape\": [1, 1, 1]\n    }, \n    {\n      \"_type\": \"ClockNode\",\n      \"_version\": \"0\",\n      \"id\":       \"1013\",\n      \"input\": {\n        \"_type\": \"InputPort\",\n        \"_version\": \"0\",\n        \"nodeId\":         \"1013\",\n        \"name\": \"input\",\n        \"type\": 2,\n        \"input\":         \"1012.output[0]\"\n      },\n      \"output\": {\n        \"_type\": \"OutputPort\",\n        \"_version\": \"0\",\n        \"nodeId\":         \"1013\",\n        \"name\": \"output\",\n        \"type\": 2,\n        \"size\": 2\n      },\n      \"interval\": 0,\n      \"lagThreshold\": 0,\n      \"lagNotificationFunctionName\": \"LagNotification\"\n    }, \n    {\n      \"_type\": \"SourceNode\",\n      \"_version\": \"4\",\n      \"id\":       \"1014\",\n      \"input\": {\n        \"_type\": \"InputPort\",\n        \"_version\": \"0\",\n        \"nodeId\":         \"1014\",\n        \"name\": \"input\",\n        \"type\": 2,\n        \"input\":         \"1013.output[0:2]\"\n      },\n      \"output\": {\n        \"_type\": \"OutputPort\",\n        \"_version\": \"0\",\n        \"nodeId\":         \"1014\",\n        \"name\": \"output\",\n        \"type\": 1,\n        \"size\": 12288\n      },\n      \"sourceFunctionName\": \"InputCallback\",\n      \"shape\": [64, 64, 3]\n    }, \n    {\n      \"_type\": \"NeuralNetworkPredictorNode\",\n      \"_version\": \"0\",\n      \"id\":       \"1015\",\n      \"input\": {\n        \"_type\": \"InputPort\",\n        \"_version\": \"0\",\n        \"nodeId\":         \"1015\",\n        \"name\": \"input\",\n        \"type\": 1,\n        \"input\":         \"1014.output[0:12288]\"\n      },\nBut retargetTrainer has not been updated yet, this function does not put above layers at the beginning, just these ones:\n\"nodes\": [\n    {\n      \"_type\": \"InputNode\",\n      \"_version\": \"2\",\n      \"id\":       \"1006\",\n      \"size\": 12288,\n      \"shape\": [64, 64, 3]\n    }, \n    {\n      \"_type\": \"NeuralNetworkPredictorNode\",\n      \"_version\": \"0\",\n      \"id\":       \"1007\",\n      \"input\": {\n        \"_type\": \"InputPort\",\n        \"_version\": \"0\",\n        \"nodeId\":         \"1007\",\n        \"name\": \"input\",\n        \"type\": 1,\n        \"input\":         \"1006.output[0:12288]\"\n      },\n. Thank you.. ",
    "braca51e": "Found the problem!\nWrong swig version.. Already found docs!!!. Yes they did, Thanks!\nBus I was confused because the name says Getting started with image classification on Raspberry Pi and the first steps tell you how to run on a Computer and that was not indicated in the beginning. I had to read all step until I realized that what I actually needed started until step 5!. Thanks @byronChanguion. I'm using blas, at least thats it's found by cmake. But inference times are not consistent, sometimes I get 400 ms then I restart the demo and get up to 1.5 secs not yet found a reason for this large difference. I'm using same config as listed in you Rpi set-up.. @byronChanguion Finally found the problem. I was using WiFi as soon as I shut it down inference speed was exactly the same that you report!!. I have a similar problem when I run the example script for a long period of time (more than 1 hour). ",
    "byronChanguion": "You are right to be suspicious: The screenshot at the top of the \"Comparing image classification models side by side on the Raspberry Pi\" seems to be from a PC and not on a Raspberry Pi. I will update the screenshot to one from the Raspberry Pi, sorry for the confusion.\nFor the time per frame on a Pi, please use the time listed for the model in the Gallery.\nFor old models that are no longer listed in the Gallery's table of recommended models, you can get the results by looking at the validation_p3.out from the model's directory in the ELL-Models repo. For example, the models in the Comparing image classification models tutorial can be found at:\nhttps://github.com/Microsoft/ELL-models/blob/master/models/ILSVRC2012/d_I160x160x3CMCMCMCMCMCMC1AS/validation_pi3.out\nand\nhttps://github.com/Microsoft/ELL-models/blob/master/models/ILSVRC2012/d_I160x160x3CMCMBMBMBMBMC1AS/validation_pi3.out\nHowever, 800 to 900ms per frame does seem to be excessively slow. Do you have OpenBLAS enabled in your CMake environment?\n. I noticed that in your ELL file, the first FullyConnectedLayer is correctly followed by a Bias, but is missing the ReLUActivationLayer. I imported both your configs, and the resulting ELL files all have an activation layer between the last two FullyConenctedLayers i.e. the end of the network should look like:\n    {\n      \"_type\": \"FullyConnectedLayer<float>\",\n      \"_version\": \"0\",\n      \"inputPaddingScheme\": 0,\n      \"inputPaddingSize\": 0,\n      \"outputShape\": [1, 1, 1024],\n      \"outputPaddingScheme\": 0,\n      \"outputPaddingSize\": 0,\n      \"weights_rows\": 1024,\n      \"weights_columns\": 3136,\n      \"weights_values\": [#deleted#]\n    }, \n    {\n      \"_type\": \"BiasLayer<float>\",\n      \"_version\": \"0\",\n      \"inputPaddingScheme\": 0,\n      \"inputPaddingSize\": 0,\n      \"outputShape\": [1, 1, 1024],\n      \"outputPaddingScheme\": 0,\n      \"outputPaddingSize\": 0,\n      \"bias\": [#deleted#]\n    }, \n    {\n      \"_type\": \"ActivationLayer<float,ReLUActivation>\",\n      \"_version\": \"0\",\n      \"inputPaddingScheme\": 0,\n      \"inputPaddingSize\": 0,\n      \"outputShape\": [1, 1, 1024],\n      \"outputPaddingScheme\": 0,\n      \"outputPaddingSize\": 0\n    }, \n    {\n      \"_type\": \"FullyConnectedLayer<float>\",\n      \"_version\": \"0\",\n      \"inputPaddingScheme\": 0,\n      \"inputPaddingSize\": 0,\n      \"outputShape\": [1, 1, 10],\n      \"outputPaddingScheme\": 0,\n      \"outputPaddingSize\": 0,\n      \"weights_rows\": 10,\n      \"weights_columns\": 1024,\n      \"weights_values\": [#deleted#]\n    }, \n    {\n      \"_type\": \"BiasLayer<float>\",\n      \"_version\": \"0\",\n      \"inputPaddingScheme\": 0,\n      \"inputPaddingSize\": 0,\n      \"outputShape\": [1, 1, 10],\n      \"outputPaddingScheme\": 0,\n      \"outputPaddingSize\": 0,\n      \"bias\": [#deleted#]\n    }, \n    {\n      \"_type\": \"SoftmaxLayer<float>\",\n      \"_version\": \"0\",\n      \"inputPaddingScheme\": 0,\n      \"inputPaddingSize\": 0,\n      \"outputShape\": [1, 1, 10],\n      \"outputPaddingScheme\": 0,\n      \"outputPaddingSize\": 0\n    }],\n    \"output\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n  }\n\nCan you confirm whether importing using the bits in master now produces a model which includes the correct activation layer?. Can you share your Darknet config and weights files so we can try to import and reproduce the problem?. Thanks for the model .cfg and .weights files! I was able to reproduce the problem and found what was causing the errors:\n1. ReLU activation was being skipped by the importer in [connected] layers.\n2. The weights of the [connected] layer need to be transposed by the importer.\nAfter fixing those, I get the same results as Darknet. I'll run a few more tests and push a fix within in the next couple days. As a temporary work-around, try replacing the ELL/tools/importers/Darknet/darknet_to_ell.py file with darknet_to_ell.zip\n. ",
    "CalderaSrv": "Awesome.  Thanks!. I also had problems in the past week.  Specifically with the \"ELL featurizer model file\" and \"ELL classifier model file\" from the \"Getting started with audio keyword classification\" tutorial.  http links and curl commands download a 1kb zip file with no usable content.. ",
    "sdudeck": "Hello,\nfind attached the two files with the mnist-darknet model.\nmnist_lenet.cfg.txt\nmnist_lenet.weights.txt\nI tried two things yesterday:\n1. I just inserted the missing activation layer in the ELL-file as in the snippet above and recompiled it. This new compiled model gave slightly different results but the quality didn't really improved.\n2. I updated my local files from the git-hub repository and recompiled the ELL stuff. Now the darknet-to-ELL import does not work anymore (ImportError: cannot import name 'MapCompilerOptions', tried it on two different darknet models).\nFull message:\n(py36-ell-env) D:\\Crest\\DarknetModels>python ./../libs/ell/tools/importers/darknet/darknet_import.py mnist_lenet.cfg mnist_lenet.weights\nTraceback (most recent call last):\n  File \"./../libs/ell/tools/importers/darknet/darknet_import.py\", line 22, in <module>\n    import darknet_to_ell\n  File \"D:\\Crest\\libs\\ell\\tools\\importers\\darknet\\darknet_to_ell.py\", line 22, in <module>\n    import ell\n  File \"D:\\Crest\\libs\\ell\\build\\interfaces\\python\\package\\ell\\__init__.py\", line 22, in <module>\n    from . import model\n  File \"D:\\Crest\\libs\\ell\\build\\interfaces\\python\\package\\ell\\model\\__init__.py\" , line 9, in <module>\n    from ..ell_py import \\\nImportError: cannot import name 'MapCompilerOptions'\nThanks for helping,\nSven\n. Thanks a lot.\nWith the workaround py-file I get the ReLu-layer inserted in the ELL-file and the inference output values are different but still do not match the darknet values. So I will wait as well for the complete fix.\nP.S.: I got rid of the 'MapCompilerOptions'-error mentioned above by pulling a clean version of the current ELL-repository and compiling it again.. Thanks al lot - that helps our discussions.. thanks a lot - changing this line did the trick :-). ",
    "langongjin": "Not really, it is more similar to this one https://github.com/Microsoft/ELL/issues/130, but still not same. Is anybody have some ideas? Thanks!. Could anybody give me a hand? Thanks!. Thanks in advance, I will try and feedback to you.. I have the same issue too, so how is it going right now. ",
    "BretStateham": "I'll give it a shot.. Thanks Chris, I used what you posted above, tweaked it for the Python 3.5 install that shipped with the 2018-04-18 Raspbian Stretch image, and was able to make it work.  I think we can close this issue.\nHere's exactly what I did:\nBuilding OpenCV 3.3.0 on Raspbian Stretch with Python 3.5.3\n\n\nStarting from a clean Raspbian Stretch image - 2018-04-18\n\n\nImaged the SD card using the image above using Etcher.io\n\n\nLogged in as the user pi with the password raspberry\n\n\nUpdate the os:\nbash\nsudo apt-get update\nsudo apt-get upgrade -y\n1.  Configured wifi by editing /etc/wpa_supplicant/wpa_supplicant.conf.  See Headless Pi - Configure the WiFi Network for more info.\n\n\nVerified the Python 3 version by running:\nbash\n  python3 --version\nAnd verifying it is Python 3.5.3\nbash\n  Python 3.5.3\n\n\nInstall pre-reqs:\nbash\nsudo apt-get install -y build-essential cmake pkg-config\nsudo apt-get install -y libjpeg-dev libtiff5-dev libjasper-dev libpng12-dev libdc1394-22-dev\nsudo apt-get install -y libavcodec-dev libavformat-dev libswscale-dev libv4l-dev\nsudo apt-get install -y libxvidcore-dev libx264-dev\nsudo apt-get install -y libgtk2.0-dev libgtk-3-dev\nsudo apt-get install -y libatlas-base-dev gfortran\nsudo apt-get install -y python3-dev\n1.  Upgrade pip3\nbash\npython3 -m pip install -U pip\n\n\nThe update works, but somehow breaks the pathing for pip3.  To verify the new version you need to call the pip module from within python3.  Run the following command:\nbash\npython3 -m pip --version\nAnd verify that it is version 10.0.1 or greater\nbash\npip 10.0.1 from /home/pi/.local/lib/python3.5/site-packages/pip (python 3.5)\n\n\nInstall Jinja2 (remember all pip3 installs have to be run as python3 -m pip install ...)\nbash\npython3 -m pip install jinja2\n\n\nInstall numpy\nbash\npython3 -m pip install numpy\n\n\nDownload and extract OpenCV source:\nbash\ncd ~\nwget -O opencv.zip https://github.com/Itseez/opencv/archive/3.3.0.zip\nunzip opencv.zip\ncd opencv-3.3.0\nwget -O opencv_contrib.zip https://github.com/Itseez/opencv_contrib/archive/3.3.0.zip\nunzip opencv_contrib.zip\n\n\nCreate and change into the ~/opencv-3.3.0/build directory\nbash\nmkdir build\ncd build\n\n\nRun cmake with the proper options:\n\nNote: The very last line of the command points to the parent folder .. of the ~/opencv-3.3.0/build folder.  Make sure to include the .. at the end of the command.\n\nbash\ncmake -D CMAKE_BUILD_TYPE=RELEASE \\\n  -D CMAKE_INSTALL_PREFIX=/usr/local \\\n  -D OPENCV_EXTRA_MODULES_PATH=../opencv_contrib-3.3.0/modules \\\n  -D BUILD_EXAMPLES=OFF \\\n  -D BUILD_TESTS=OFF \\\n  -D BUILD_PERF_TESTS=OFF \\\n  -D BUILD_opencv_python2=0 \\\n  -D PYTHON2_EXECUTABLE= \\\n  -D PYTHON2_INCLUDE_DIR= \\\n  -D PYTHON2_LIBRARY= \\\n  -D PYTHON2_NUMPY_INCLUDE_DIRS= \\\n  -D PYTHON2_PACKAGES_PATH= \\\n  -D BUILD_opencv_python3=1 \\\n  -D PYTHON3_EXECUTABLE=/usr/bin/python3 \\\n  -D PYTHON3_INCLUDE_DIR=/usr/include/python3.5 \\\n  -D PYTHON3_LIBRARY=/usr/lib/arm-linux-gnueabihf/libpython3.5m.so \\\n  -D PYTHON3_NUMPY_INCLUDE_DIRS=/usr/lib/python3/dist-packages/numpy/core/include \\\n  -D PYTHON3_PACKAGES_PATH=/home/pi/.local/lib/python3.5/site-packages \\\n  ..\n\n\nThe output of the above command should look like the following at the end:\n```bash\n-- General configuration for OpenCV 3.3.0 =====================================\n--   Version control:               unknown\n--\n--   Extra modules:\n--     Location (extra):            /home/pi/opencv-3.3.0/opencv_contrib-3.3.0/modules\n--     Version control (extra):     unknown\n--\n--   Platform:\n--     Timestamp:                   2018-05-08T17:43:30Z\n--     Host:                        Linux 4.14.34-v7+ armv7l\n--     CMake:                       3.7.2\n--     CMake generator:             Unix Makefiles\n--     CMake build tool:            /usr/bin/make\n--     Configuration:               RELEASE\n--\n--   CPU/HW features:\n--     Baseline:\n--       requested:                 DETECT\n--       disabled:                  VFPV3 NEON\n--\n--   C/C++:\n--     Built as dynamic libs?:      YES\n--     C++11:                       YES\n--     C++ Compiler:                /usr/bin/c++  (ver 6.3.0)\n--     C++ flags (Release):         -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winit-self -Wno-narrowing -Wno-delete-non-virtual-dtor -Wno-comment -fdiagnostics-show-option -pthread -fomit-frame-pointer -ffunction-sections  -mfp16-format=ieee -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG\n--     C++ flags (Debug):           -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winit-self -Wno-narrowing -Wno-delete-non-virtual-dtor -Wno-comment -fdiagnostics-show-option -pthread -fomit-frame-pointer -ffunction-sections  -mfp16-format=ieee -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG\n--     C Compiler:                  /usr/bin/cc\n--     C flags (Release):           -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Winit-self -Wno-narrowing -Wno-comment -fdiagnostics-show-option -pthread -fomit-frame-pointer -ffunction-sections  -mfp16-format=ieee -fvisibility=hidden -O3 -DNDEBUG  -DNDEBUG\n--     C flags (Debug):             -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Winit-self -Wno-narrowing -Wno-comment -fdiagnostics-show-option -pthread -fomit-frame-pointer -ffunction-sections  -mfp16-format=ieee -fvisibility=hidden -g  -O0 -DDEBUG -D_DEBUG\n--     Linker flags (Release):\n--     Linker flags (Debug):\n--     ccache:                      NO\n--     Precompiled headers:         YES\n--     Extra dependencies:          gtk-3 gdk-3 pangocairo-1.0 pango-1.0 atk-1.0 cairo-gobject cairo gdk_pixbuf-2.0 gio-2.0 gobject-2.0 glib-2.0 gthread-2.0 /usr/lib/arm-linux-gnueabihf/libpng.so /usr/lib/arm-linux-gnueabihf/libz.so /usr/lib/arm-linux-gnueabihf/libtiff.so /usr/lib/arm-linux-gnueabihf/libjasper.so /usr/lib/arm-linux-gnueabihf/libjpeg.so dc1394 avcodec avformat avutil swscale freetype harfbuzz dl m pthread rt\n--     3rdparty dependencies:\n--\n--   OpenCV modules:\n--     To be built:                 core flann imgproc ml objdetect phase_unwrapping photo plot reg surface_matching video xphoto bgsegm dnn face freetype fuzzy img_hash imgcodecs shape videoio xobjdetect highgui superres bioinspired dpm features2d line_descriptor saliency text calib3d ccalib datasets rgbd stereo structured_light tracking videostab xfeatures2d ximgproc aruco optflow stitching python3\n--     Disabled:                    world contrib_world\n--     Disabled by dependency:      -\n--     Unavailable:                 cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev java python2 ts viz cnn_3dobj cvv dnn_modern hdf matlab sfm\n--\n--   GUI:\n--     QT:                          NO\n--     GTK+ 3.x:                    YES (ver 3.22.11)\n--     GThread :                    YES (ver 2.50.3)\n--     GtkGlExt:                    NO\n--     OpenGL support:              NO\n--     VTK support:                 NO\n--\n--   Media I/O:\n--     ZLib:                        /usr/lib/arm-linux-gnueabihf/libz.so (ver 1.2.8)\n--     JPEG:                        /usr/lib/arm-linux-gnueabihf/libjpeg.so (ver )\n--     WEBP:                        build (ver encoder: 0x020e)\n--     PNG:                         /usr/lib/arm-linux-gnueabihf/libpng.so (ver 1.6.28)\n--     TIFF:                        /usr/lib/arm-linux-gnueabihf/libtiff.so (ver 42 - 4.0.8)\n--     JPEG 2000:                   /usr/lib/arm-linux-gnueabihf/libjasper.so (ver 1.900.1)\n--     OpenEXR:                     build (ver 1.7.1)\n--     GDAL:                        NO\n--     GDCM:                        NO\n--\n--   Video I/O:\n--     DC1394 1.x:                  NO\n--     DC1394 2.x:                  YES (ver 2.2.5)\n--     FFMPEG:                      YES\n--       avcodec:                   YES (ver 57.64.101)\n--       avformat:                  YES (ver 57.56.101)\n--       avutil:                    YES (ver 55.34.101)\n--       swscale:                   YES (ver 4.2.100)\n--       avresample:                NO\n--     GStreamer:                   NO\n--     OpenNI:                      NO\n--     OpenNI PrimeSensor Modules:  NO\n--     OpenNI2:                     NO\n--     PvAPI:                       NO\n--     GigEVisionSDK:               NO\n--     Aravis SDK:                  NO\n--     UniCap:                      NO\n--     UniCap ucil:                 NO\n--     V4L/V4L2:                    NO/YES\n--     XIMEA:                       NO\n--     Xine:                        NO\n--     Intel Media SDK:             NO\n--     gPhoto2:                     NO\n--\n--   Parallel framework:            pthreads\n--\n--   Trace:                         YES ()\n--\n--   Other third-party libraries:\n--     Use Intel IPP:               NO\n--     Use Intel IPP IW:            NO\n--     Use VA:                      NO\n--     Use Intel VA-API/OpenCL:     NO\n--     Use Lapack:                  NO\n--     Use Eigen:                   NO\n--     Use Cuda:                    NO\n--     Use OpenCL:                  YES\n--     Use OpenVX:                  NO\n--     Use custom HAL:              YES (carotene (ver 0.0.1))\n--\n--   OpenCL:                        \n--     Include path:                /home/pi/opencv-3.3.0/3rdparty/include/opencl/1.2\n--     Use AMDFFT:                  NO\n--     Use AMDBLAS:                 NO\n--\n--   Python 2:\n--     Interpreter:                 (ver 2.7.13)\n--\n--   Python 3:\n--     Interpreter:                 /usr/bin/python3 (ver 3.5.3)\n--     Libraries:                   /usr/lib/arm-linux-gnueabihf/libpython3.5m.so (ver 3.5.3)\n--     numpy:                       /usr/lib/python3/dist-packages/numpy/core/include (ver 1.12.1)\n--     packages path:               /home/pi/.local/lib/python3.5/site-packages\n--\n--   Python (for build):\n--\n--   Java:\n--     ant:                         NO\n--     JNI:                         NO\n--     Java wrappers:               NO\n--     Java tests:                  NO\n--\n--   Matlab:                        Matlab not found or implicitly disabled\n--\n--   Documentation:\n--     Doxygen:                     NO\n--\n--   Tests and samples:\n--     Tests:                       NO\n--     Performance tests:           NO\n--     C/C++ Examples:              NO\n--\n--   Install path:                  /usr/local\n--\n--   cvconfig.h is in:              /home/pi/opencv-3.3.0/build\n\n--\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/pi/opencv-3.3.0/build\n```\n\n\nRun make\n\nNote: This took about one hour and fourty five minutes (1:45) on my Raspberry Pi with a 32GB San Disk Ultra microSDHC UHS-I Card\n\nbash\nmake\n\n\nRun make install\nbash\nsudo make install\n\n\nTest it:\nbash\npython3 -c \"import cv2; print(cv2.__version__)\"\n1.  OPTIONAL - Remove the ~/opencv-3.3.0 folder\nbash\nsudo rm -rf ~/opencv-3.3.0\n\n\nAnd remove the downloaded ~/opencv.zip file:\n``bash\nrm ~/opencv.zip\n````. Regarding the pip3 upgrade, once you do it, if you try to runpip3` by itself, you get the following error:\n\n\nbash\nTraceback (most recent call last):\n  File \"/usr/bin/pip3\", line 9, in <module>\n    from pip import main\nImportError: cannot import name 'main'\nHowever, if you run pip3 (pip) by loading it as a module into python3, it works. \nFor example, this command will error after you upgraded pip3:\nbash\npip3 --version\nHowever, this will work:\nbash\npython3 -m pip --version. ",
    "zhengszh": "Thank you. My output result of this command is:\nHKEY_LOCAL_MACHINE\\Hardware\\Description\\System\\CentralProcessor\\0\nComponent Information    REG_BINARY    00000000000000000000000000000000\nIdentifier    REG_SZ    Intel64 Family 6 Model 61 Stepping 4\nConfiguration Data    REG_FULL_RESOURCE_DESCRIPTOR    FFFFFFFFFFFFFFFF0000000000000000\nProcessorNameString    REG_SZ    Intel(R) Core(TM) i7-5600U CPU @ 2.60GHz\nVendorIdentifier    REG_SZ    GenuineIntel\nFeatureSet    REG_DWORD    0x3d1b3fff\n~MHz    REG_DWORD    0xa22\nUpdate Revision    REG_BINARY    000000001F000000\nUpdate Status    REG_DWORD    0x0\nPrevious Update Revision    REG_BINARY    000000001D000000\nPlatform Specific Field 1    REG_DWORD    0x40. I solved the problem by adding this statements to OpenBLASSetup.cmake:\n\nelseif(processor_model EQUAL 61)\n    set(processor_generation \"haswell\")\n\nAnd the build process is completed.. But unfortunately, not all the tests have passed when I try to build RUN_TESTS:\n The following tests FAILED:\n     15 - cntk_importer_test (Failed)\n     35 - wrap-test (Failed)\n  Errors while running CTest. When I run the \"python <ELL-root>/tools/wrap/wrap.py featurizer_16k.ell --target host --outdir featurizer_16k --module_name mfcc\" command in the \"Audio Classification Tutorials in Python\", it gets warp errors:\n\ncompiling model...\n    command C:/Users/t-suzhen/Desktop/ELL/build/bin/release/compile failed with error code 1\n    ### WrapException: <class 'buildtools.EllBuildToolsRunException'>:C:/Users/tsuzhen/Desktop/ELL/build/bin/release/compile -imap featurizer_16k.ell -cfn Predict -cmn featurizer_16k --bitcode --target host -od host --fuseLinearOps True --swig --blas true --optimize true\n\nI think this has something to do with the warp error in RUN_TESTS.. It worked. Thank you!. ",
    "salah-selim": "the file \"featureizer_16k.ell\" is missing the following:\n\"inputLayout1\"\n\"inputLayout2\"\n\"outputLayout\"\nFor the node:\n      \"_type\": \"BinaryOperationNode\",\nnear the end of the file.\nThe modified file (which works without errors) is attached.\nfeaturizer_16k .txt\n. ",
    "gegogabriel": "up. I have the same problem. One notable change that i made reading through the other issues was to change in OPENBLASsetup cmake to accept my processor\nReading the comments in the cmake i saw that sky lake would be compatible with sandy so I tried with it(I also tried with the other) but the same error so I don't think this is related.\nComponent Information    REG_BINARY    00000000000000000000000000000000\n    Identifier    REG_SZ    Intel64 Family 6 Model 94 Stepping 3\n    Configuration Data    REG_FULL_RESOURCE_DESCRIPTOR    FFFFFFFFFFFFFFFF0000000000000000\n    ProcessorNameString    REG_SZ    Intel(R) Core(TM) i7-6700HQ CPU @ 2.60GHz\n    VendorIdentifier    REG_SZ    GenuineIntel\n    FeatureSet    REG_DWORD    0x3d1b3fff\n    ~MHz    REG_DWORD    0xa20\n    Update Revision    REG_BINARY    00000000BA000000\n    Update Status    REG_DWORD    0x0\n    Previous Update Revision    REG_BINARY    0000000074000000\n    Platform Specific Field 1    REG_DWORD    0x20. I figured it would be hard to understand from the intial description, so:\nI made a gist with the relavant files.\nIn the past day I tried everything I know and could find on the internet, however whatever I'm doing it just doesen't work.\nI want to mention that what is very unusual is that if I have only .h files including model.h it's ok. I made , a new class in a /h wrapping functions from model.h and I could use it in main.cpp. \nHowver in the moment when I'm including the wrapper.h in another .h which has also .cpp with implementations it gives me these error.\nAny help will me much appreciated.\nhttps://gist.github.com/gegogabriel/7d595aacacccd27182b187646784798a. ",
    "codehArt": "facing same issue..\ndependencies & system config :\ngcc version :  5.4.0 20160609\ncmake version : 3.11.2\nsystem : ubuntu 14.04 x86_64\nprocessor : Intel(R) Core(TM) i5-2430M CPU @ 2.40GHz\n . ",
    "andreas-mucha": "FYI, this seems to be related to the GCC version. For me it occurred with gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609. Also manually setting CMAKE_CXX_FLAGS=-std=c++14 in the cmake invocation did not help.\nI got around the issue by manually installing gcc-7 (see https://askubuntu.com/questions/466651/how-do-i-use-the-latest-gcc-on-ubuntu/581497#581497 for instructions for Ubuntu)\nand passing the arguments -D CMAKE_C_COMPILER=gcc-7 -D CMAKE_CXX_COMPILER=g++-7 to cmake.. ",
    "cornellnikko": "Hi toni-pad,\nI looked around the Anaconda website and saw that on https://anaconda.org/microsoft-ell/opencv the following commands are suggested:\nconda install -c microsoft-ell/label/stretch opencv\nI then ran tutorial.py and got: \nFile \"tutorial.py\", line 13, in <module>\nimport cv2\nImportError: libjasper.so.1: cannot open shared object file: No such file or directory\nSo I installed libjasper as follows:\nsudo apt install libjasper-dev\nNow when I run tutorial.py, I get an exception saying \"Your capture device is not returning images\" - which is strange, because raspistill works just fine.  Will report back with any progress.\nEDIT: Silly me, I forgot to run sudo modprobe bcm2835-v4l2 as mentioned in the camera setup. It works now.. ",
    "toni-pad": "Thanks cornellnikko for your hint.\nI use\nsudo apt install libjasper1\nand \nconda install -c microsoft-ell/label/stretch opencv\nThanks.\n. ",
    "Raulpb49": "Great ! Thanks for the information.\nRgds\nRp\nOn Tue, 10 Jul 2018 at 6:31 AM, Chris Lovett notifications@github.com\nwrote:\n\nWe don't normally build ELL itself on raspberry Pi zero, because ELL is\nactually a cross-compiler, you can build \"ELL Models to run on raspberry\npi\" by using \"ELL on your PC\". but if you really do want to compile ELL on\nthe pi0, you may need to upgrade your GCC compiler to 6.4. It could also be\nthe compiler needs some swap space\nhttp://raspberrypimaker.com/adding-swap-to-the-raspberrypi/.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Microsoft/ELL/issues/161#issuecomment-403665752, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/Ab53dHYjVK-PR9K5Cf-uBsFOL-Gd3qekks5uE_zagaJpZM4U96KP\n.\n. \n",
    "riple": "I found out that the .zip files are stored as Git LFS files, for their large size. So I installed git lfs, and then tried to fetch the original files but failed with some reason.\nThis is what it said:\n\ndesktop:~/work/ell/ELL-models/models/ILSVRC2012/d_I224x224x3CMCMCMCMCMCMC1AS$ git lfs fetch\nfetch: Fetching reference refs/heads/master\nbatch response: This repository is over its data quota. Purchase more data packs to restore access.                                         \nbatch response: This repository is over its data quota. Purchase more data packs to restore access.\nerror: failed to fetch some objects from 'https://github.com/Microsoft/ELL-models.git/info/lfs'. Look into your cmake log, it should say it cannot find the openblas library.\n\nI am using Ubuntu 18.04 64bit, and I ran into the same issue. I fixed it by adding the installation path of OpenBlas to the CMake/OpenBLASSetup.cmake settings file.\nThe \"x86_64-linux-gnu\" lines are manually added.\nset(BLAS_INCLUDE_SEARCH_PATHS\n    /opt/OpenBLAS/include\n    /usr/include\n    /usr/local/include\n    /usr/include/openblas\n    /usr/include/x86_64-linux-gnu\n)\n\nset(BLAS_LIB_SEARCH_PATHS\n    /opt/OpenBLAS/lib\n    /usr/local/Cellar/openblas/0.2.20_1/lib\n    /usr/lib64/atlas-sse3\n    /usr/lib64/atlas\n    /usr/lib64\n    /usr/local/lib64/atlas\n    /usr/local/lib64\n    /usr/lib/atlas-sse3\n    /usr/lib/atlas-sse2\n    /usr/lib/atlas-sse\n    /usr/lib/atlas-3dnow\n    /usr/lib/atlas\n    /usr/lib\n    /usr/local/lib/atlas\n    /usr/local/lib\n    /usr/lib/x86_64-linux-gnu/openblas\n).\n",
    "mingyangSunshine": "I have tried the same process on My desktop PC, and it ran successfully. But it kept crashing on my laptop.. Thanks, @lovettchris !\ndxdiag output is:\n\nI found that if I copy the model compiled on my desktop PC to the laptop, it ran correctly. But the model complied on my laptop doesn't work on any computer.\nlaptop software version:\n\n\nMircosoft Visual Studio 2017 community version15.7.5\n\n\nOpenBLASLibs.0.2.19.3\n\n\nanaconda environment: python 3.6.6\n\n\ncmake 3.12.0\n. \n\n",
    "pengbo19921206": "Thank you very much.I want to use the ELL in ARM Cortex-M4.But  ARM Cortex-M4 can not use linux\uff0cbecause ARM Cortex-M4  has not MMU .What should I do?. ",
    "Zhengyu-Li": "@kernhanda Seems everything is ok but LLVM.\n(py36) D:\\ELL-2.3.5\\build>cmake -G \"Visual Studio 14 2015 Win64\" ..\n-- Selecting Windows SDK version  to target Windows 10.0.17134.\n-- PYTHONINTERP_FOUND=TRUE\n-- PYTHON_EXECUTABLE=C:/Users/li/AppData/Local/Continuum/anaconda3/envs/py36/python.exe\n-- PYTHON_VERSION_STRING=3.6.6\n-- PYTHON_VERSION_MAJOR=3\n-- PYTHONLIBS_FOUND=TRUE\n-- PYTHON_LIBRARIES=C:/Users/li/AppData/Local/Continuum/anaconda3/envs/py36/libs/python36.lib\n-- PYTHON_INCLUDE_PATH=C:/Users/li/AppData/Local/Continuum/anaconda3/envs/py36/include\n-- PYTHON_INCLUDE_DIRS=C:/Users/li/AppData/Local/Continuum/anaconda3/envs/py36/include\n-- PYTHON_DEBUG_LIBRARIES=PYTHON_DEBUG_LIBRARY-NOTFOUND\n-- PYTHONLIBS_VERSION_STRING=3.6.6\n-- Processor family: 6, model: 94\n-- Using OpenBLAS compiled for haswell\n-- Using BLAS include path: D:/ELL-2.3.5/external/OpenBLASLibs.0.2.19.3/build/native/x64/haswell/include\n-- Using BLAS library: D:/ELL-2.3.5/external/OpenBLASLibs.0.2.19.3/build/native/x64/haswell/lib/libopenblas.dll.a\n-- Using BLAS DLLs: libopenblas.dll;libgcc_s_seh-1.dll;libgfortran-3.dll;libquadmath-0.dll\nCMake Warning at CMake/LLVMSetup.cmake:48 (find_package):\n  By not providing \"FindLLVM.cmake\" in CMAKE_MODULE_PATH this project has\n  asked CMake to find a package configuration file provided by \"LLVM\", but\n  CMake did not find one.\nCould not find a package configuration file provided by \"LLVM\" (requested\n  version 3.9) with any of the following names:\nLLVMConfig.cmake\nllvm-config.cmake\n\nAdd the installation prefix of \"LLVM\" to CMAKE_PREFIX_PATH or set\n  \"LLVM_DIR\" to a directory containing one of the above files.  If \"LLVM\"\n  provides a separate development package or SDK, be sure it has been\n  installed.\nCall Stack (most recent call first):\n  CMakeLists.txt:118 (include)\n-- LLVM not found, please check that LLVM is installed.\nERRORLLVM not found, please check that LLVM is installed.\n-- Creating wrappers for python\nCMake Deprecation Warning at D:/CMake/share/cmake-3.11/Modules/UseSWIG.cmake:272 (message):\n  SWIG_ADD_MODULE is deprecated.  Use SWIG_ADD_LIBRARY instead.\nCall Stack (most recent call first):\n  CMake/CommonInterfaces.cmake:127 (swig_add_module)\n  CMake/CommonInterfaces.cmake:159 (generate_interface_module)\n  interfaces/python/CMakeLists.txt:21 (generate_interface)\n-- Creating wrappers for javascript\n-- Creating wrappers for xml\n-- Configuring done\n-- Generating done\n-- Build files have been written to: D:/ELL-2.3.5/build. @kernhanda Ok...Thanks a lot. . ",
    "bhakthil": "This was due to previuos build issue. build issue was fixed by adding correct path to SWIG_LIB path.. The issue was that SWIG_LIB in all build files are pointing to swig root directory instead of \\Lib directory. I change the path to \\Lib and solved the problem.. I was able to build and run the samples outside of miniconda env. happy to provide the instructions if that would be helpful in the future.\nBL. Hi,\nI followed the below blog for installing OpenCV on virtualenv and completely ignored miniconda package manager. rest of the ELL tutorial still holds true for everything else.\nhttps://www.pyimagesearch.com/2017/09/04/raspbian-stretch-install-opencv-3-python-on-your-raspberry-pi/\n. ",
    "brunisgirl": "I get the same error, can you please provide the instructions for building it outside miniconda?\nS.. ",
    "phromo": "I'm getting this error on a new raspberry 3 model b+ running raspbian stretch. I'm following the instructions on https://microsoft.github.io/ELL/tutorials/Raspberry-Pi-setup/\nIf you managed to resolve this, can you please share?. the pip package was really easy. Installed it directly to my root python. @lovettchris if you are revising your instructions, you might also want to consider pipenv (pipenv shell) which I've used in my recent projects. Collaborators find it intuitive that the state of the virtualenv is tied to a definition file (the Pipfile) instead of a procedural call of install commands.. ",
    "harshmittal2210": "Hi,\nI am also facing the same issue, I am getting one more message:\nYou may need to install the anaconda-client command line client with\n              conda install anaconda-client\nI even installed the anaconda-client still error is shown.. I have updated the changes, please check if this is what you were suggesting.. I had already install C++ features as shown in the your screenshot @lovettchris , still I am getting this error . I am using VS 2017 but again error is showing if I run\n\ncmake -G \"Visual Studio 15 2017 Win64\"\n\nError:\n\nCMake Error: Error: generator : Visual Studio 15 2017 Win64\nDoes not match the generator used previously: Visual Studio 14 2015 Win64\nEither remove the CMakeCache.txt file and CMakeFiles directory or choose a different binary directory.\n\n. Yup..it worked, thank you. I had activated the miniconda environment and also the initial cmake and build were run.. Yes I had done this also. And also included this path in PATH variable in properties of computer->advance settings->Environment Variables and then adding this address in PATH variable. \n\nAlso I am using Intel(R) Core(TM) i5-8300H CPU @2.3GHz . . When I run \"cmake .\" Following is a part of message that is shown\n-- Processor family: 6, model: 158\n-- Using OpenBLAS compiled for haswell\n-- Using BLAS include path: E:/Git/ELL/external/OpenBLASLibs.0.2.19.3/build/native/x64/haswell/include\n-- Using BLAS library: E:/Git/ELL/external/OpenBLASLibs.0.2.19.3/build/native/x64/haswell/lib/libopenblas.dll.a\n-- Using BLAS DLLs: libopenblas.dll;libgcc_s_seh-1.dll;libgfortran-3.dll;libquadmath-0.dll\n-- Found LLVM 6.0.1\n-- Using LLVMConfig.cmake in: E:/Git/ELL/external/LLVMNativeWindowsLibs.x64.6.0.1/llvm-6.0/lib/cmake/llvm. Yes opencv was installed it.\nI tried installing numpy using pip it showed that numpy was already installed, so it tried \n\nconda install -c conda-forge numpy\n\nstill no use, same error is showing. . Just like I said earlier if type following in cmd line no error is shown:\n\npython\nimport numpy as np\n\nI am able import numpy that means numpy is installed but while running the test it is showing this error. > import ell\nTraceback (most recent call last):\n  File \"E:\\Git\\ELL\\build\\interfaces\\python\\package\\ell\\ell_py.py\", line 14, in swig_import_helper\n    return importlib.import_module(mname)\n  File \"C:\\Users\\harsh\\Miniconda3\\envs\\py36\\lib\\importlib__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"\", line 994, in _gcd_import\n  File \"\", line 971, in _find_and_load\n  File \"\", line 953, in _find_and_load_unlocked\nModuleNotFoundError: No module named 'ell._ell_py'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \"E:\\Git\\ELL\\build\\interfaces\\python\\package\\ell__init__.py\", line 42, in \n    from . import data\n  File \"E:\\Git\\ELL\\build\\interfaces\\python\\package\\ell\\data__init__.py\", line 9, in \n    from ..ell_py import AutoDataVector, \\\n  File \"E:\\Git\\ELL\\build\\interfaces\\python\\package\\ell\\ell_py.py\", line 17, in \n    _ell_py = swig_import_helper()\n  File \"E:\\Git\\ELL\\build\\interfaces\\python\\package\\ell\\ell_py.py\", line 16, in swig_import_helper\n    return importlib.import_module('_ell_py')\n  File \"C:\\Users\\harsh\\Miniconda3\\envs\\py36\\lib\\importlib__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\nImportError: Module use of python37.dll conflicts with this version of Python.. It is returning:\n\nC:\\Users\\harsh\\Miniconda3\\python.exe\nC:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python36\\python.exe\n\nOh yes Python 3.7.1 is installed in my system\n<DIR>python\nPython 3.7.1 (default, Dec 10 2018, 22:54:23) [MSC v.1915 64 bit (AMD64)] :: Anaconda, Inc. on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\nAfter activating py36:\n(py36) E:\\Git\\ELL\\build\\interfaces\\python\\package>python\nPython 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 18:50:55) [MSC v.1915 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.. After removing it from the path, following error message is shown after \"import ell\"\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \"E:\\Git\\ELL\\build\\interfaces\\python\\package\\ell__init__.py\", line 42, in \n    from . import data\n  File \"E:\\Git\\ELL\\build\\interfaces\\python\\package\\ell\\data__init__.py\", line 9, in \n    from ..ell_py import AutoDataVector, \\\n  File \"E:\\Git\\ELL\\build\\interfaces\\python\\package\\ell\\ell_py.py\", line 17, in \n    _ell_py = swig_import_helper()\n  File \"E:\\Git\\ELL\\build\\interfaces\\python\\package\\ell\\ell_py.py\", line 16, in swig_import_helper\n    return importlib.import_module('_ell_py')\n  File \"C:\\Users\\harsh\\Miniconda3\\envs\\py36\\lib\\importlib__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\nImportError: DLL load failed: The specified module could not be found.. So I deleted the build folder and started again and with response to my PR #189 changes have been made for the ctest command for windows as well and now 100% tests are passed. Still really not sure what caused the problem in the first place but now the problem is solved\nThanks for the help @lovettchris  . If in some pi board LXDE-pi is there and in some only LXDE then it can be advised to check using 'ls' command.. I am a bit confused. I have the following directories.\n\npi@raspberrypi:~/.config/lxsession $ ls\n\nLXDE\n\npi@raspberrypi:~/.cache/lxsession $ ls\n\nLXDE        LXDE-pi\n\n\nSo this means should I create LXDE-pi in /.config/lxsession ?\nAlso in my run.log for both LXDE and LXDE-pi i have no message for User config used, but yes xscreensaver warning message is there.. ",
    "evenex": "Thanks for the explanation. I think I understand how the callback API is used, but I have a different use case. I'm using one of the pretrained models that I wrapped with wrap.py. I have the image loaded in memory, with the option of RGB or BGR and float* or double* normalized from 0 to 1. What is the minimal way to get a prediction from there?\nI have tried something like model_Predict(nullptr, (double*)image.data(), (float*)output.data()) but this is giving me nonsense results.. I'm using the same model as in the tutorial, d_I224x224x3CMCMCMCMCMCMC1AS.ell. I've confirmed that my inputs are normalized and that the image I'm capturing in the pipeline is what I expect. (In this case, I'm testing it with a picture of a coffee mug I found online.)\nThe result is that it is classified as \"nematode\" always. And sometimes the model reports a very high (1e30+) confidence that it is something called a \"Tinca\". I see this result no matter what image or video I show.\nThis layer-by-layer debugging sounds promising - how can I get expected layer outputs so that I can compare to what my local model is computing?. The tutorial works for me. I'll compare my program to the tutorial more carefully and work out where I'm going wrong. Thanks!. ",
    "rverm44820": "Is visual code studio the same program?\nOn Sun, Jan 6, 2019, 7:08 PM Chris Lovett <notifications@github.com wrote:\n\nAssuming you have Visual Studio 2017\nhttps://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=Community&rel=15\ninstalled you should be able to open a \"Developer Command Prompt\" for\nVisual studio which looks like this:\n[image: image]\nhttps://user-images.githubusercontent.com/18707114/50743469-2ba96380-11cd-11e9-8948-05fc4583574d.png\nand then cmake will be available (it lives here: C:\\Program Files\n(x86)\\Microsoft Visual\nStudio\\2017\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin\\cmake.exe)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Microsoft/ELL/issues/188#issuecomment-451788441, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ALyPJqqgdutdMwU_xPQ7q-fVbiKirs3Cks5vAo_qgaJpZM4ZyQV8\n.\n. \n",
    "Harsha5524": "~/ELL/build$ cmake ..\n-- Configuring tests to use TEST_MODELS_REPO at: https://github.com/Microsoft/ell-test-models\n-- PYTHONINTERP_FOUND=TRUE\n-- PYTHON_EXECUTABLE=/home/kharsha/miniconda3/bin/python3.7\n-- PYTHON_VERSION_STRING=3.7.1\n-- PYTHON_VERSION_MAJOR=3\n-- PYTHONLIBS_FOUND=TRUE\n-- PYTHON_LIBRARIES=/home/kharsha/miniconda3/lib/libpython3.7m.so\n-- PYTHON_INCLUDE_PATH=/home/kharsha/miniconda3/include/python3.7m\n-- PYTHON_INCLUDE_DIRS=/home/kharsha/miniconda3/include/python3.7m\n-- PYTHON_DEBUG_LIBRARIES=\n-- PYTHONLIBS_VERSION_STRING=3.7.1\n-- Blas libraries: /usr/lib/libopenblas.so\n-- Blas linker flags: \n-- Blas include directories: /usr/include\n-- Blas Vendor: OpenBLAS\n-- Using BLAS include path: /usr/include\n-- Using BLAS library: /usr/lib/libopenblas.so\n-- Using BLAS DLLs: \n-- Found LLVM 6.0.0\n-- Using LLVMConfig.cmake in: /usr/lib/llvm-6.0/cmake\n-- Found SWIG_EXECUTABLE=/usr/local/bin/swig\n-- Creating wrappers for python\nCMake Deprecation Warning at /usr/local/share/cmake-3.13/Modules/UseSWIG.cmake:524 (message):\n  SWIG_ADD_MODULE is deprecated.  Use SWIG_ADD_LIBRARY instead.\nCall Stack (most recent call first):\n  CMake/CommonInterfaces.cmake:129 (swig_add_module)\n  CMake/CommonInterfaces.cmake:160 (generate_interface_module)\n  interfaces/python/CMakeLists.txt:21 (generate_interface)\nCMake Warning (dev) at /usr/local/share/cmake-3.13/Modules/UseSWIG.cmake:564 (message):\n  Policy CMP0078 is not set.  Run \"cmake --help-policy CMP0078\" for policy\n  details.  Use the cmake_policy command to set the policy and suppress this\n  warning.\nCall Stack (most recent call first):\n  /usr/local/share/cmake-3.13/Modules/UseSWIG.cmake:525 (swig_add_library)\n  CMake/CommonInterfaces.cmake:129 (swig_add_module)\n  CMake/CommonInterfaces.cmake:160 (generate_interface_module)\n  interfaces/python/CMakeLists.txt:21 (generate_interface)\nThis warning is for project developers.  Use -Wno-dev to suppress it.\n-- Creating wrappers for javascript\n-- Creating wrappers for xml\n-- Writing: /home/kharsha/ELL/build/config.json\n-- Configuring done\nCMake Warning at tools/utilities/debugCompiler/CMakeLists.txt:29 (add_executable):\n  Cannot generate a safe runtime search path for target debugCompiler because\n  files in some directories may conflict with libraries in implicit\n  directories:\nruntime library [libffi.so.6] in /usr/lib/x86_64-linux-gnu may be hidden by files in:\n  /home/kharsha/miniconda3/lib\n\nSome of these libraries may not be found correctly.\nCMake Warning at tools/utilities/profile/CMakeLists.txt:27 (add_executable):\n  Cannot generate a safe runtime search path for target profile because files\n  in some directories may conflict with libraries in implicit directories:\nruntime library [libffi.so.6] in /usr/lib/x86_64-linux-gnu may be hidden by files in:\n  /home/kharsha/miniconda3/lib\n\nSome of these libraries may not be found correctly.\nCMake Warning at /usr/local/share/cmake-3.13/Modules/UseSWIG.cmake:665 (add_library):\n  Cannot generate a safe runtime search path for target _ELL_python because\n  files in some directories may conflict with libraries in implicit\n  directories:\nruntime library [libffi.so.6] in /usr/lib/x86_64-linux-gnu may be hidden by files in:\n  /home/kharsha/miniconda3/lib\n\nSome of these libraries may not be found correctly.\nCall Stack (most recent call first):\n  /usr/local/share/cmake-3.13/Modules/UseSWIG.cmake:525 (swig_add_library)\n  CMake/CommonInterfaces.cmake:129 (swig_add_module)\n  CMake/CommonInterfaces.cmake:160 (generate_interface_module)\n  interfaces/python/CMakeLists.txt:21 (generate_interface)\n-- Generating done\n-- Build files have been written to: /home/kharsha/ELL/build\n. > Sorry can you delete your build folder and do it again, I'm curious what C and C++ compiler versions it is finding (which is not reported the second time you run cmake). I'm looking for output like this:\n\n-- The C compiler identification is GNU 8.2.0\n-- The CXX compiler identification is GNU 7.3.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\nwhich shows my C and C++ compiler versions are mismatched. One is 7 and the other is 8. And I will get compiler errors as a result. But if I run this:\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 50 --slave /usr/bin/g++ g++ /usr/bin/g++-8\nthen everything compiles without errors.\n\nAfter re build my folder cmake output like this\n~/ELL/build$ cmake ..\n-- The C compiler identification is GNU 8.1.0\n-- The CXX compiler identification is GNU 8.1.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Configuring tests to use TEST_MODELS_REPO at: https://github.com/Microsoft/ell-test-models\n-- PYTHONINTERP_FOUND=TRUE\n-- PYTHON_EXECUTABLE=/home/kharsha/miniconda3/bin/python3.7\n-- PYTHON_VERSION_STRING=3.7.1\n-- PYTHON_VERSION_MAJOR=3\n-- PYTHONLIBS_FOUND=TRUE\n-- PYTHON_LIBRARIES=/home/kharsha/miniconda3/lib/libpython3.7m.so\n-- PYTHON_INCLUDE_PATH=/home/kharsha/miniconda3/include/python3.7m\n-- PYTHON_INCLUDE_DIRS=/home/kharsha/miniconda3/include/python3.7m\n-- PYTHON_DEBUG_LIBRARIES=\n-- PYTHONLIBS_VERSION_STRING=3.7.1\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Check if compiler accepts -pthread\n-- Check if compiler accepts -pthread - yes\n-- Found Threads: TRUE\n-- Blas libraries: /usr/lib/libopenblas.so\n-- Blas linker flags: \n-- Blas include directories: \n-- Blas Vendor: OpenBLAS\n-- Using BLAS include path: /usr/include\n-- Using BLAS library: /usr/lib/libopenblas.so\n-- Using BLAS DLLs: \n-- Found LLVM 6.0.0\n-- Using LLVMConfig.cmake in: /usr/lib/llvm-6.0/cmake\n-- Found SWIG: /usr/local/bin/swig (found suitable version \"3.0.12\", minimum required is \"3.0.12\") \n-- Found SWIG_EXECUTABLE=/usr/local/bin/swig\n-- Creating wrappers for python\nCMake Deprecation Warning at /usr/local/share/cmake-3.13/Modules/UseSWIG.cmake:524 (message):\n  SWIG_ADD_MODULE is deprecated.  Use SWIG_ADD_LIBRARY instead.\nCall Stack (most recent call first):\n  CMake/CommonInterfaces.cmake:129 (swig_add_module)\n  CMake/CommonInterfaces.cmake:160 (generate_interface_module)\n  interfaces/python/CMakeLists.txt:21 (generate_interface)\nCMake Warning (dev) at /usr/local/share/cmake-3.13/Modules/UseSWIG.cmake:564 (message):\n  Policy CMP0078 is not set.  Run \"cmake --help-policy CMP0078\" for policy\n  details.  Use the cmake_policy command to set the policy and suppress this\n  warning.\nCall Stack (most recent call first):\n  /usr/local/share/cmake-3.13/Modules/UseSWIG.cmake:525 (swig_add_library)\n  CMake/CommonInterfaces.cmake:129 (swig_add_module)\n  CMake/CommonInterfaces.cmake:160 (generate_interface_module)\n  interfaces/python/CMakeLists.txt:21 (generate_interface)\nThis warning is for project developers.  Use -Wno-dev to suppress it.\n-- Creating wrappers for javascript\n-- Creating wrappers for xml\n-- Writing: /home/kharsha/ELL/build/config.json\n-- Configuring done\nCMake Warning at tools/utilities/debugCompiler/CMakeLists.txt:29 (add_executable):\n  Cannot generate a safe runtime search path for target debugCompiler because\n  files in some directories may conflict with libraries in implicit\n  directories:\nruntime library [libffi.so.6] in /usr/lib/x86_64-linux-gnu may be hidden by files in:\n  /home/kharsha/miniconda3/lib\n\nSome of these libraries may not be found correctly.\nCMake Warning at tools/utilities/profile/CMakeLists.txt:27 (add_executable):\n  Cannot generate a safe runtime search path for target profile because files\n  in some directories may conflict with libraries in implicit directories:\nruntime library [libffi.so.6] in /usr/lib/x86_64-linux-gnu may be hidden by files in:\n  /home/kharsha/miniconda3/lib\n\nSome of these libraries may not be found correctly.\nCMake Warning at /usr/local/share/cmake-3.13/Modules/UseSWIG.cmake:665 (add_library):\n  Cannot generate a safe runtime search path for target _ELL_python because\n  files in some directories may conflict with libraries in implicit\n  directories:\nruntime library [libffi.so.6] in /usr/lib/x86_64-linux-gnu may be hidden by files in:\n  /home/kharsha/miniconda3/lib\n\nSome of these libraries may not be found correctly.\nCall Stack (most recent call first):\n  /usr/local/share/cmake-3.13/Modules/UseSWIG.cmake:525 (swig_add_library)\n  CMake/CommonInterfaces.cmake:129 (swig_add_module)\n  CMake/CommonInterfaces.cmake:160 (generate_interface_module)\n  interfaces/python/CMakeLists.txt:21 (generate_interface)\n-- Generating done\n-- Build files have been written to: /home/kharsha/ELL/build. And still I am facing this errors..............\n(py36) kharsha@kharsha:~/ELL/build$ make\n[  0%] Built target documentation\n[  0%] Building CXX object libraries/utilities/CMakeFiles/utilities.dir/src/Archiver.cpp.o\nIn file included from /home/kharsha/ELL/libraries/utilities/include/TypeName.h:11,\n                 from /home/kharsha/ELL/libraries/utilities/include/Archiver.h:13,\n                 from /home/kharsha/ELL/libraries/utilities/src/Archiver.cpp:9:\n/home/kharsha/ELL/libraries/utilities/include/TypeTraits.h:106:17: error: \u2018is_pointer_v\u2019 in namespace \u2018std\u2019 does not name a type\n            std::is_pointer_v>T<<\n                 ^~~~~~~~~~~~\nIn file included from /usr/include/c++/8/bits/move.h:55,\n                 from /usr/include/c++/8/bits/nested_exception.h:40,\n                 from /usr/include/c++/8/exception:144,\n                 from /home/kharsha/ELL/libraries/utilities/include/Exception.h:11,\n                 from /home/kharsha/ELL/libraries/utilities/include/Debug.h:10,\n                 from /home/kharsha/ELL/libraries/utilities/include/TypeFactory.h:11,\n                 from /home/kharsha/ELL/libraries/utilities/include/Archiver.h:12,\n                 from /home/kharsha/ELL/libraries/utilities/src/Archiver.cpp:9:\n/usr/include/c++/8/type_traits:2742:25: note: \u2018template constexpr const bool std::is_pointer_v<_Tp>\u2019 declared here\n   inline constexpr bool is_pointer_v = is_pointer<_Tp>::value;\n                         ^~~~~~~~~~~~\nIn file included from /home/kharsha/ELL/libraries/utilities/include/TypeName.h:11,\n                 from /home/kharsha/ELL/libraries/utilities/include/Archiver.h:13,\n                 from /home/kharsha/ELL/libraries/utilities/src/Archiver.cpp:9:\n/home/kharsha/ELL/libraries/utilities/include/TypeTraits.h:115:16: error: \u2018RemoveAllPointers\u2019 is not a class template\n         struct RemoveAllPointers < T;\n                ^~~~~~~~~~~~~~~~~\n/home/kharsha/ELL/libraries/utilities/include/TypeTraits.h:116:9: error: expected unqualified-id before \u2018false\u2019\n         false >\n         ^~~~~\nlibraries/utilities/CMakeFiles/utilities.dir/build.make:62: recipe for target 'libraries/utilities/CMakeFiles/utilities.dir/src/Archiver.cpp.o' failed\nmake[2]:  [libraries/utilities/CMakeFiles/utilities.dir/src/Archiver.cpp.o] Error 1\nCMakeFiles/Makefile2:2201: recipe for target 'libraries/utilities/CMakeFiles/utilities.dir/all' failed\nmake[1]:  [libraries/utilities/CMakeFiles/utilities.dir/all] Error 2\nMakefile:94: recipe for target 'all' failed\nmake: *** [all] Error 2\n. Thanks for support.......\nUpgraded to 18.04 it is successfully build.......... this is my system specifications\n\n\n. My system is it Necessary for doing this?\n. > Yeah, I see 3.7 gb in your window there, that's pretty low, especially since we are building an audio library of size 2,563,557,026 (and that's the disk size, the numpy memory size is probably larger) and the OS probably takes a bunch of memory. So if you cannot increase the amount of RAM available to this machine then I would recommend lowering the max_files_per_directory you provide to make_training_list to something like 1000 or 500.\nwhen I am using max_files_per_directory 1000\nMy output like is \n~/tutorial/audio$ python make_dataset.py --list_file ~/tutorial/audio/training_list.txt --featurizer compiled_featurizer/mfcc --sample_rate 8000 \nTransforming 12 files from  ... ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\nALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\nALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\nALSA lib pcm_route.c:867:(find_matching_chmap) Found no matching channel map\nALSA lib pcm_route.c:867:(find_matching_chmap) Found no matching channel map\nALSA lib pcm_route.c:867:(find_matching_chmap) Found no matching channel map\nALSA lib pcm_route.c:867:(find_matching_chmap) Found no matching channel map\nCannot connect to server socket err = No such file or directory\nCannot connect to server request channel\njack server is not running or cannot be started\nJackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\nJackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n found 2420 rows\nTransforming 1000 files from bed ...  found 1000 rows\nTransforming 1000 files from bird ...  found 1000 rows\nTransforming 1000 files from cat ...  found 1000 rows\nTransforming 1000 files from dog ...  found 1000 rows\nTransforming 1000 files from down ...  found 1000 rows\nTransforming 1000 files from eight ...  found 1000 rows\nTransforming 1000 files from five ...  found 1000 rows\nTransforming 1000 files from four ...  found 1000 rows\nTransforming 1000 files from go ...  found 1000 rows\nTransforming 1000 files from happy ...  found 1000 rows\nTransforming 1000 files from house ...  found 1000 rows\nTransforming 1000 files from left ...  found 1000 rows\nTransforming 1000 files from marvin ...  found 1000 rows\nTransforming 1000 files from nine ...  found 1000 rows\nTransforming 1000 files from no ...  found 1000 rows\nTransforming 1000 files from off ...  found 1000 rows\nTransforming 1000 files from on ...  found 1000 rows\nTransforming 1000 files from one ...  found 1000 rows\nTransforming 1000 files from right ...  found 1000 rows\nTransforming 1000 files from seven ...  found 1000 rows\nTransforming 1000 files from sheila ...  found 1000 rows\nTransforming 1000 files from six ...  found 1000 rows\nTransforming 1000 files from stop ...  found 1000 rows\nTransforming 1000 files from three ...  found 1000 rows\nTransforming 1000 files from tree ...  found 1000 rows\nTransforming 1000 files from two ...  found 1000 rows\nTransforming 1000 files from up ...  found 1000 rows\nTransforming 1000 files from wow ...  found 1000 rows\nTransforming 1000 files from yes ...  found 1000 rows\nTransforming 1000 files from zero ...  found 1000 rows\nTraceback (most recent call last):\n  File \"make_dataset.py\", line 182, in \n    make_dataset(args.list_file, args.featurizer, args.sample_rate, args.window_size, args.shift)\n  File \"make_dataset.py\", line 160, in make_dataset\n    dataset = _get_dataset(entry_map, transform, sample_rate, window_size, shift)\n  File \"make_dataset.py\", line 142, in _get_dataset\n    features = np.concatenate(data_rows, axis=0)\nMemoryError\n. > ah ha, this time we do see \"MemoryError\" which confirms our suspicions that this is a memory problem. So you will have to keep decreasing max_files_per_directory until you find one that fits in the available RAM. Training neural networks is known to use lots of RAM, the tutorial probably should state you need at least 16 gb of RAM or more.\nI got like this now for max_files_per_directory 500\n~/tutorial/audio$ python make_dataset.py --list_file ~/tutorial/audio/training_list.txt --featurizer compiled_featurizer/mfcc --sample_rate 8000 \nTransforming 12 files from  ... ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\nALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\nALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\nALSA lib pcm_route.c:867:(find_matching_chmap) Found no matching channel map\nALSA lib pcm_route.c:867:(find_matching_chmap) Found no matching channel map\nALSA lib pcm_route.c:867:(find_matching_chmap) Found no matching channel map\nALSA lib pcm_route.c:867:(find_matching_chmap) Found no matching channel map\n found 2420 rows\nTransforming 500 files from bed ...  found 500 rows\nTransforming 500 files from bird ...  found 500 rows\nTransforming 500 files from cat ...  found 500 rows\nTransforming 500 files from dog ...  found 500 rows\nTransforming 500 files from down ...  found 500 rows\nTransforming 500 files from eight ...  found 500 rows\nTransforming 500 files from five ...  found 500 rows\nTransforming 500 files from four ...  found 500 rows\nTransforming 500 files from go ...  found 500 rows\nTransforming 500 files from happy ...  found 500 rows\nTransforming 500 files from house ...  found 500 rows\nTransforming 500 files from left ...  found 500 rows\nTransforming 500 files from marvin ...  found 500 rows\nTransforming 500 files from nine ...  found 500 rows\nTransforming 500 files from no ...  found 500 rows\nTransforming 500 files from off ...  found 500 rows\nTransforming 500 files from on ...  found 500 rows\nTransforming 500 files from one ...  found 500 rows\nTransforming 500 files from right ...  found 500 rows\nTransforming 500 files from seven ...  found 500 rows\nTransforming 500 files from sheila ...  found 500 rows\nTransforming 500 files from six ...  found 500 rows\nTransforming 500 files from stop ...  found 500 rows\nTransforming 500 files from three ...  found 500 rows\nTransforming 500 files from tree ...  found 500 rows\nTransforming 500 files from two ...  found 500 rows\nTransforming 500 files from up ...  found 500 rows\nTransforming 500 files from wow ...  found 500 rows\nTransforming 500 files from yes ...  found 500 rows\nTransforming 500 files from zero ...  found 500 rows\nTraceback (most recent call last):\n  File \"make_dataset.py\", line 182, in \n    make_dataset(args.list_file, args.featurizer, args.sample_rate, args.window_size, args.shift)\n  File \"make_dataset.py\", line 160, in make_dataset\n    dataset = _get_dataset(entry_map, transform, sample_rate, window_size, shift)\n  File \"make_dataset.py\", line 146, in _get_dataset\n    return Dataset(features, label_names, parameters)\n  File \"/home/kharsha/tutorial/audio/dataset.py\", line 46, in init\n    self._init()\n  File \"/home/kharsha/tutorial/audio/dataset.py\", line 53, in _init\n    std = np.std(self.features, axis=0)\n  File \"/home/kharsha/.conda/envs/torch/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 3038, in std\n    **kwargs)\n  File \"/home/kharsha/.conda/envs/torch/lib/python3.6/site-packages/numpy/core/_methods.py\", line 140, in _std\n    keepdims=keepdims)\n  File \"/home/kharsha/.conda/envs/torch/lib/python3.6/site-packages/numpy/core/_methods.py\", line 117, in _var\n    x = asanyarray(arr - arrmean)\nMemoryError\nOk! How Much can I decrease?. > I don't know just keep subtracting 100 until it works. But I'm curious what kind of machine this is that has only 3.7gb RAM. Is there any way to get more RAM for this machine?\nNow it works on 300....... Thanks for your support.................\n. ",
    "mrohera": "With multiple GCC version installed on my machine, I used update-alternatives to pin to GCC 8.2. Perhaps these instructions are useful to others running into similar issues:\nsudo update-alternatives --config gcc // check if any GCC versions already registered\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 8 --slave /usr/bin/g++ g++ /usr/bin/g++-8\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-7 7 --slave /usr/bin/g++ g++ /usr/bin/g++-7\nsudo update-alternatives --config gcc  // I ensured that 8.2 was auto\nProps to an excellent write up on the topic: http://charette.no-ip.com:81/programming/2011-12-24_GCCv47/\n. Thanks for getting back! After following the tutorial I created the build dir and ran cmake. I do not have the compile executable as per your comment above. If you have a writeup to generate a model.o that is perfect and exactly what I am after.. Found it under /ELL/build/bin sorry it was my bad, I issued the command and looks like it worked. Thanks Chris.\nls -lr model \ntotal 100140\n-rw-r--r-- 1 marohera marohera       66 Feb  4 14:31 opt.log\n-rw-r--r-- 1 marohera marohera     7813 Feb  4 14:30 OpenBLASSetup.cmake\n-rw-r--r-- 1 marohera marohera 36665152 Feb  4 14:31 model.opt.bc\n-rw-r--r-- 1 marohera marohera 29588496 Feb  5 11:06 model.o\n-rw-r--r-- 1 marohera marohera     3816 Feb  5 11:06 model.h\n-rw-r--r-- 1 marohera marohera 36254288 Feb  4 14:31 model.bc\n-rw-r--r-- 1 marohera marohera      101 Feb  4 14:31 llc.log\ndrwxr-xr-x 2 marohera marohera     4096 Feb  3 17:53 include\n-rw-r--r-- 1 marohera marohera      208 Feb  4 14:30 compile.log. Just FYI here is the output of /proc/cpuinfo/\ncat /proc/cpuinfo\nprocessor   : 0\nvendor_id   : GenuineIntel\ncpu family  : 6\nmodel       : 58\nmodel name  : Intel(R) Core(TM) i7-3667U CPU @ 2.00GHz\nThis is the Intel's product page for this CPU: https://ark.intel.com/products/64898/Intel-Core-i7-3667U-Processor-4M-Cache-up-to-3-20-GHz-. ",
    "Ry7en": "Thank you very much for your prompt reply; after running \"cmake -G \"Visual Studio 15 2017 Win64\" ..\" the output contained a number of warnings, namely:\na \"CMake Deprecation Warning\";\nmultiple  \"Policy CMP0054 is not set\" warnings;\na \"Could NOT find PkgConfig (missing: PKG_CONFIG_EXECUTABLE)\" warning.\n```\n(py36) C:\\Users\\HP\\OpenBLAS\\build>cmake -G \"Visual Studio 15 2017 Win64\" ..\n-- Selecting Windows SDK version 10.0.17763.0 to target Windows 10.0.17134.\n-- The C compiler identification is MSVC 19.16.27027.1\n-- The ASM compiler identification is MSVC\n-- Found assembler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\nCMake Warning at CMakeLists.txt:59 (message):\n  CMake support is experimental.  It does not yet support all build options\n  and may not produce the same Makefiles that OpenBLAS ships with.\n-- GEMM multithread threshold set to 4.\n-- Multi-threading enabled with 8 threads.\nCMake Deprecation Warning at C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/Common7/IDE/CommonExtensions/Microsoft/CMake/CMake/share/cmake-3.12/Modules/CMakeForceCompiler.cmake:97 (message):\n  The CMAKE_FORCE_Fortran_COMPILER macro is deprecated.  Instead just set\n  CMAKE_Fortran_COMPILER and allow CMake to identify the compiler.\nCall Stack (most recent call first):\n  cmake/f_check.cmake:27 (CMAKE_FORCE_Fortran_COMPILER)\n  cmake/prebuild.cmake:84 (include)\n  cmake/system.cmake:141 (include)\n  CMakeLists.txt:62 (include)\nCMake Warning (dev) at cmake/prebuild.cmake:298 (if):\n  Policy CMP0054 is not set: Only interpret if() arguments as variables or\n  keywords when unquoted.  Run \"cmake --help-policy CMP0054\" for policy\n  details.  Use the cmake_policy command to set the policy and suppress this\n  warning.\nQuoted variables like \"MSVC\" will no longer be dereferenced when the policy\n  is set to NEW.  Since the policy is not set the OLD behavior will be used.\nCall Stack (most recent call first):\n  cmake/system.cmake:141 (include)\n  CMakeLists.txt:62 (include)\nThis warning is for project developers.  Use -Wno-dev to suppress it.\nMSVC\n-- Running getarch\n-- GETARCH results:\nCORE=generic\nLIBCORE=generic\nNUM_CORES=8\nGENERIC=1\nL1_DATA_SIZE=32768\nL1_DATA_LINESIZE=128\nL2_SIZE=512488\nL2_LINESIZE=128\nDTB_DEFAULT_ENTRIES=128\nDTB_SIZE=4096\nL2_ASSOCIATIVE=8\nMAKE += -j 8\n-- Building Single Precision\n-- Building Double Precision\n-- Building Complex Precision\n-- Building Double Complex Precision\n-- Reading vars from C:/Users/HP/OpenBLAS/kernel/x86_64/KERNEL...\n-- Reading vars from C:/Users/HP/OpenBLAS/kernel/x86_64/KERNEL.generic...\nCMake Warning (dev) at kernel/CMakeLists.txt:124 (if):\n  Policy CMP0054 is not set: Only interpret if() arguments as variables or\n  keywords when unquoted.  Run \"cmake --help-policy CMP0054\" for policy\n  details.  Use the cmake_policy command to set the policy and suppress this\n  warning.\nQuoted variables like \"GENERIC\" will no longer be dereferenced when the\n  policy is set to NEW.  Since the policy is not set the OLD behavior will be\n  used.\nCall Stack (most recent call first):\n  kernel/CMakeLists.txt:546 (build_core)\nThis warning is for project developers.  Use -Wno-dev to suppress it.\n-- Looking for pthread.h\n-- Looking for pthread.h - not found\n-- Found Threads: TRUE\nCMake Warning (dev) at utest/CMakeLists.txt:4 (if):\n  Policy CMP0054 is not set: Only interpret if() arguments as variables or\n  keywords when unquoted.  Run \"cmake --help-policy CMP0054\" for policy\n  details.  Use the cmake_policy command to set the policy and suppress this\n  warning.\nQuoted variables like \"MSVC\" will no longer be dereferenced when the policy\n  is set to NEW.  Since the policy is not set the OLD behavior will be used.\nThis warning is for project developers.  Use -Wno-dev to suppress it.\n-- Generating openblas_config.h in include/openblas\n-- Generating f77blas.h in include/openblas\n-- Generating cblas.h in include/openblas\n-- Could NOT find PkgConfig (missing: PKG_CONFIG_EXECUTABLE)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: C:/Users/HP/OpenBLAS/build\n```\nIn my previous attempt to resolve the problem of getting OpenBLAS to work I tried following the instructions for a \"Native (MSVC) ABI\" build (https://github.com/xianyi/OpenBLAS/wiki/How-to-use-OpenBLAS-in-Microsoft-Visual-Studio), and I recall that some packages installed previously during the ELL installation were up and down-graded. Perhaps this is causing the PkgConfig warning?. The build step has completed with no errors, but 515 warnings, which mostly seem to be code C4244:\nconversion from 'BLASLONG' to 'int', possible loss of data\n. The install proceeded with no errors, but for the next step should I skip the last instruction in your first post, and replace the OpenBLASSetup.cmake in my ELL/CMake folder with the one you attached in your second post?. After following the \"Building ELL\" section of the installation guide and running \"cmake -G \"Visual Studio 15 2017 Win64\" ..\", the following was output, including the \"-- Unknown processor, disabling OpenBLAS\" warning :\n```\n(py36) C:\\Users\\HP\\ELL\\build>cmake -G \"Visual Studio 15 2017 Win64\" ..\n-- Selecting Windows SDK version 10.0.17763.0 to target Windows 10.0.17134.\n-- The C compiler identification is MSVC 19.16.27027.1\n-- The CXX compiler identification is MSVC 19.16.27027.1\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- ELL version 2.4.0\n-- Configuring tests to use TEST_MODELS_REPO at: https://github.com/Microsoft/ell-test-models\n-- PYTHONINTERP_FOUND=FALSE\n-- PYTHON_EXECUTABLE=C:/Users/HP/Miniconda3/envs/py36/python.exe\n-- PYTHON_VERSION_STRING=3.6.8\n-- PYTHON_VERSION_MAJOR=3\n-- PYTHONLIBS_FOUND=FALSE\n-- PYTHON_LIBRARIES=C:/Users/HP/Miniconda3/envs/py36/libs/python36.lib\n-- PYTHON_INCLUDE_PATH=C:/Users/HP/Miniconda3/envs/py36/include\n-- PYTHON_INCLUDE_DIRS=C:/Users/HP/Miniconda3/envs/py36/include\n-- PYTHON_DEBUG_LIBRARIES=PYTHON_DEBUG_LIBRARY-NOTFOUND\n-- PYTHONLIBS_VERSION_STRING=3.6.8\n-- PYTHONINTERP_FOUND=TRUE\n-- PYTHON_EXECUTABLE=C:/Users/HP/Miniconda3/envs/py36/python.exe\n-- PYTHON_VERSION_STRING=3.6.8\n-- PYTHON_VERSION_MAJOR=3\n-- PYTHONLIBS_FOUND=TRUE\n-- PYTHON_LIBRARIES=C:/Users/HP/Miniconda3/envs/py36/libs/python36.lib\n-- PYTHON_INCLUDE_PATH=C:/Users/HP/Miniconda3/envs/py36/include\n-- PYTHON_INCLUDE_DIRS=C:/Users/HP/Miniconda3/envs/py36/include\n-- PYTHON_DEBUG_LIBRARIES=PYTHON_DEBUG_LIBRARY-NOTFOUND\n-- PYTHONLIBS_VERSION_STRING=3.6.8\nCMake Warning at CMake/Flake8.cmake:7 (message):\n  ### could not find 'flake8', please run 'pip install flake8'\nCall Stack (most recent call first):\n  CMakeLists.txt:86 (include)\n-- Looking for pthread.h\n-- Looking for pthread.h - not found\n-- Found Threads: TRUE\n-- Processor family: 23, model: 17\nCMake Error at CMake/OpenBLASSetup.cmake:171 (get_processor_mapping):\n  get_processor_mapping Macro invoked with incorrect arguments for macro\n  named: get_processor_mapping\nCall Stack (most recent call first):\n  CMakeLists.txt:145 (include)\n-- Unknown processor, disabling OpenBLAS\n-- BLAS library not found\n-- Found LLVM 6.0.1\n-- Using LLVMConfig.cmake in: C:/Users/HP/ELL/external/LLVMNativeWindowsLibs.x64.6.0.1/llvm-6.0/lib/cmake/llvm\n-- Found SWIG: C:/Users/HP/ELL/external/swigwintools.3.0.12/tools/swigwin-3.0.12/swig.exe (found suitable version \"3.0.12\", minimum required is \"3.0.12\")\n-- Found SWIG_EXECUTABLE=C:/Users/HP/ELL/external/swigwintools.3.0.12/tools/swigwin-3.0.12/swig.exe\n-- Skipping pitest because one of RPI_CLUSTER, RPI_PASSWORD, RPI_KEY, TEST_MODELS_REPO is missing\n-- Creating wrappers for python\nCMake Deprecation Warning at C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/Common7/IDE/CommonExtensions/Microsoft/CMake/CMake/share/cmake-3.12/Modules/UseSWIG.cmake:492 (message):\n  SWIG_ADD_MODULE is deprecated.  Use SWIG_ADD_LIBRARY instead.\nCall Stack (most recent call first):\n  CMake/CommonInterfaces.cmake:129 (swig_add_module)\n  CMake/CommonInterfaces.cmake:160 (generate_interface_module)\n  interfaces/python/CMakeLists.txt:21 (generate_interface)\n-- Creating wrappers for javascript\n-- Creating wrappers for xml\n-- Writing: C:/Users/HP/ELL/build/config.json\n-- Configuring incomplete, errors occurred!\nSee also \"C:/Users/HP/ELL/build/CMakeFiles/CMakeOutput.log\".\nSee also \"C:/Users/HP/ELL/build/CMakeFiles/CMakeError.log\".\n```\n. I get:\n```\nC:\\Users\\HP\\ELL>cmake --version\ncmake version 3.12.18081601-MSVC_2\nCMake suite maintained and supported by Kitware (kitware.com/cmake).\n```\nI believe that CMake may have been updated during my aforementioned attempt to follow the \"Native (MSVC) ABI\" OpenBLAS build tutorial.\n. In the first example I get:\nC:\\Users\\HP\\ELL\\CMake>set proc\nPROCESSOR_ARCHITECTURE=AMD64\nPROCESSOR_IDENTIFIER=AMD64 Family 23 Model 17 Stepping 0, AuthenticAMD\nPROCESSOR_LEVEL=23\nPROCESSOR_REVISION=1100\nWhilst the second has:\n```\nC:\\Users\\HP\\ELL\\CMake>reg query HKEY_LOCAL_MACHINE\\Hardware\\Description\\System\\CentralProcessor\\0\nHKEY_LOCAL_MACHINE\\Hardware\\Description\\System\\CentralProcessor\\0\n    Component Information    REG_BINARY    00000000000000000000000000000000\n    Identifier    REG_SZ    AMD64 Family 23 Model 17 Stepping 0\n    Configuration Data    REG_FULL_RESOURCE_DESCRIPTOR    FFFFFFFFFFFFFFFF0000000000000000\n    ProcessorNameString    REG_SZ    AMD Ryzen 5 PRO 2500U w/ Radeon Vega Mobile Gfx\n    VendorIdentifier    REG_SZ    AuthenticAMD\n    FeatureSet    REG_DWORD    0x3c3b3dff\n    ~MHz    REG_DWORD    0x7cc\n    Update Revision    REG_BINARY    0B10100800000000\n    Update Status    REG_DWORD    0x1\n    Previous Update Revision    REG_BINARY    0B10100800000000\n    Platform Specific Field1    REG_DWORD    0x810100b\n```. I hope this is what was required:\ntrace.zip\n. As far as I can tell, the install step was successful - \"C:\\Program Files\\OpenBLAS\" is present and contains three folders; \"include\", \"lib\" and \"share\". . I don't think I've interpreted your instructions correctly, but nevertheless I added \"message(STATUS CMAKE_SYSTEM_PROCESSOR=${CMAKE_SYSTEM_PROCESSOR})\" to OpenBLASSetup.cmake, ran \"cmake -G \"Visual Studio 15 2017 Win64\" ..\" (I had to add the two periods at the end otherwise I would get a CMakeLists.txt missing error) which included in its output:\n-- CMAKE_SYSTEM_PROCESSOR=AMD64\ninstead of the lines previously output\n ```\n-- Looking for pthread.h\n-- Looking for pthread.h - not found\n-- Found Threads: TRUE\n```\n. Thank you for persevering with me, I've undone the changes to OpenBLASSetup.cmake; the output from \ncmake -G \"Visual Studio 15 2017 Win64\"\nis:\n```\nC:\\Users\\HP\\Documents\\foo>cmake -G \"Visual Studio 15 2017 Win64\"\n-- Selecting Windows SDK version 10.0.17763.0 to target Windows 10.0.17134.\n-- The C compiler identification is MSVC 19.16.27027.1\n-- The CXX compiler identification is MSVC 19.16.27027.1\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- CMAKE_SYSTEM_PROCESSOR=AMD64\n-- Configuring done\n-- Generating done\n-- Build files have been written to: C:/Users/HP/Documents/foo\n```. The first line is present:\n-- ProgramW6432=[C:\\Program Files]\nbut not the second:\nC:\\Users\\HP\\Documents\\foo>cmake -G \"Visual Studio 15 2017 Win64\"\n-- Selecting Windows SDK version 10.0.17763.0 to target Windows 10.0.17134.\n-- ProgramW6432=[C:\\Program Files]\n-- Configuring done\n-- Generating done\n-- Build files have been written to: C:/Users/HP/Documents/foo. When CMakeLists.txt is modified to contain:\n```\nThis is the default location for a manually installed OpenBlas build.\nmessage(STATUS \"ProgramW6432=[$ENV{ProgramW6432}]\")\nif(${CMAKE_SYSTEM_PROCESSOR} STREQUAL \"AMD64\")\n    set(BLAS_PACKAGE_DIR $ENV{ProgramW6432}/OpenBlas)\nelse()\n    set(BLAS_PACKAGE_DIR $ENV{ProgramFiles}/OpenBlas)\nendif()\nmessage(STATUS \"BLAS_PACKAGE_DIR=[${BLAS_PACKAGE_DIR}]\")\nif(EXISTS ${BLAS_PACKAGE_DIR}/lib/libopenblas.lib)\n    message(STATUS \"Found OpenBlas in ${BLAS_PACKAGE_DIR}\")\n    set(BLAS_DLLS libopenblas.dll)\n    set(BLAS_DLL_DIR ${BLAS_PACKAGE_DIR}/bin)\n    set(BLAS_INCLUDE_SEARCH_PATHS ${BLAS_PACKAGE_DIR}/include/)\n    set(BLAS_LIB_SEARCH_PATHS ${BLAS_PACKAGE_DIR}/lib/)\n    set(BLAS_FOUND TRUE)\nendif()\n```\nthe output is:\nC:\\Users\\HP\\Documents\\foo>cmake -G \"Visual Studio 15 2017 Win64\"\n-- Selecting Windows SDK version 10.0.17763.0 to target Windows 10.0.17134.\n-- ProgramW6432=[C:\\Program Files]\n-- BLAS_PACKAGE_DIR=[C:\\Program Files/OpenBlas]\n-- Configuring done\n-- Generating done\n-- Build files have been written to: C:/Users/HP/Documents/foo. The only file in that location that I can see is \"openblas.lib\", not \"libopenblas.lib\".. I have Visual Studio installed as per the tutorial (I recall that I unselected something like \"Tests for Google\" to save HDD space as I didn't think it looked like a crucial component), though I wasn't certain what was meant under \"CMake 3.8\"; I ended up adding the location mentioned: \nc:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin\\cmake.exe\nto my Path, in environment variables, which seemed to allow cmake to be run from the anaconda prompt. . I see:\n```\nC:\\Users\\HP>dir /s /b \"c:\\Program Files\"\\openblas\nc:\\Program Files\\openblas\\include\nc:\\Program Files\\openblas\\lib\nc:\\Program Files\\openblas\\share\nc:\\Program Files\\openblas\\include\\openblas\nc:\\Program Files\\openblas\\include\\openblas\\cblas.h\nc:\\Program Files\\openblas\\include\\openblas\\f77blas.h\nc:\\Program Files\\openblas\\include\\openblas\\openblas_config.h\nc:\\Program Files\\openblas\\lib\\openblas.lib\nc:\\Program Files\\openblas\\share\\cmake\nc:\\Program Files\\openblas\\share\\cmake\\OpenBLAS\nc:\\Program Files\\openblas\\share\\cmake\\OpenBLAS\\OpenBLASConfig.cmake\nc:\\Program Files\\openblas\\share\\cmake\\OpenBLAS\\OpenBLASConfigVersion.cmake\nc:\\Program Files\\openblas\\share\\cmake\\OpenBLAS\\OpenBLASTargets-release.cmake\nc:\\Program Files\\openblas\\share\\cmake\\OpenBLAS\\OpenBLASTargets.cmake\n```\nThank you for the tip; should I remove the location I added to my Path and run the call? . May I simply delete the \"c:\\Program Files\\openblas\" install, or is there an uninstall procedure to be followed?. Excellent - now there's no shame in confessing to have been a little faster in deleting than in asking questions; alas my fortune didn't endure, as after deleting the folders and following these steps:\nclone https://github.com/xianyi/OpenBLAS, then:\nmkdir build\ncd build\ncmake -G \"Visual Studio 15 2017 Win64\" ..\ncmake --build . --config Release\nI can only see a \"openblas.lib\" in \"C:\\Users\\HP\\OpenBLAS\\build\\lib\\RELEASE\". I did notice after searching my computer that there are \"libopenblas.dll.a\" files in \"C:\\Users\\HP\\ELL\\external\\OpenBLASLibs.0.2.19.3\\build\\native\\x64\\haswell\\lib\" and the \"x64\\sandybridge\\lib\" folders, if that is of any importance.. When I ran cmake -G \"Visual Studio 15 2017 Win64\" .. > cmake.log 2>&1 from my  \"C:\\Users\\HP\\OpenBLAS\\build\" folder, \"cmake.log\" was generated, but the command prompt didn't output details of a build. \ncmake.zip\n. I ran call c:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\Tools\\VsDevCmd.bat\" before generating the cmake.log attached in my previous post, but not set WindowsSdkDir=. Running both and rebuilding I noticed this line at the beginning of the new log \"The C compiler identification is MSVC 19.16.27027.1\" followed by others similar to the ones in your cmake.log.\ncmake 2.zip\n. Unfortunately the next step\ncmake --build . --config Release\nfails to produce a \"libopenblas.dll\", only openblas.lib as before. I've opened an issue on the OpenBLAS repository as suggested, so with any luck will soon get to the bottom of this. \n. I attach a reply from the above thread - might this have any bearing on what could be amiss? \n\"Yes, you can simply rename it if the other program expects it to be named libopenblas.dll. (Would need to search the commit history to find when it was renamed, but I expect somebody stated that the \"lib\" prefix was not standard on Windows. Similarly it used to be the case that the cmake build created both .lib and .dll by default in the past until it was pointed out that this was not what cmake builds usually do.) Probably the build instructions for the other project were written a year or more ago and not updated to reflect these changes in the OpenBLAS build process.)\"\nAfter renaming \"openblas.lib\" and \"openblas.dll\" in \"C:\\Program Files\\OpenBLAS\" to \"libopenblas.lib\" and \"libopenblas.dll\", the output after running\ncmake -G \"Visual Studio 15 2017 Win64\" ..\nfrom a VS developer prompt is:\n```\nC:\\Users\\HP\\ELL\\build>cmake -G \"Visual Studio 15 2017 Win64\" ..\n-- Selecting Windows SDK version 10.0.17763.0 to target Windows 10.0.17134.\n-- The C compiler identification is MSVC 19.16.27027.1\n-- The CXX compiler identification is MSVC 19.16.27027.1\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x64/cl.exe -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- ELL version 2.4.0\n-- Configuring tests to use TEST_MODELS_REPO at: https://github.com/Microsoft/ell-test-models\n-- PYTHONINTERP_FOUND=TRUE\n-- PYTHON_EXECUTABLE=C:/Users/HP/Miniconda3/python.exe\n-- PYTHON_VERSION_STRING=3.7.1\n-- PYTHON_VERSION_MAJOR=3\n-- PYTHONLIBS_FOUND=TRUE\n-- PYTHON_LIBRARIES=C:/Users/HP/Miniconda3/libs/python37.lib\n-- PYTHON_INCLUDE_PATH=C:/Users/HP/Miniconda3/include\n-- PYTHON_INCLUDE_DIRS=C:/Users/HP/Miniconda3/include\n-- PYTHON_DEBUG_LIBRARIES=PYTHON_DEBUG_LIBRARY-NOTFOUND\n-- PYTHONLIBS_VERSION_STRING=3.7.1\nCMake Warning at CMake/Flake8.cmake:7 (message):\n  ### could not find 'flake8', please run 'pip install flake8'\nCall Stack (most recent call first):\n  CMakeLists.txt:86 (include)\n-- Looking for pthread.h\n-- Looking for pthread.h - not found\n-- Found Threads: TRUE\n-- Found OpenBlas in C:\\Program Files/OpenBlas\n-- BLAS library not found\n-- Found LLVM 6.0.1\n-- Using LLVMConfig.cmake in: C:/Users/HP/ELL/external/LLVMNativeWindowsLibs.x64.6.0.1/llvm-6.0/lib/cmake/llvm\n-- Found SWIG: C:/Users/HP/ELL/external/swigwintools.3.0.12/tools/swigwin-3.0.12/swig.exe (found suitable version \"3.0.12\", minimum required is \"3.0.12\")\n-- Found SWIG_EXECUTABLE=C:/Users/HP/ELL/external/swigwintools.3.0.12/tools/swigwin-3.0.12/swig.exe\n-- Skipping pitest because one of RPI_CLUSTER, RPI_PASSWORD, RPI_KEY, TEST_MODELS_REPO is missing\n-- Creating wrappers for python\nCMake Deprecation Warning at C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/Common7/IDE/CommonExtensions/Microsoft/CMake/CMake/share/cmake-3.12/Modules/UseSWIG.cmake:492 (message):\n  SWIG_ADD_MODULE is deprecated.  Use SWIG_ADD_LIBRARY instead.\nCall Stack (most recent call first):\n  CMake/CommonInterfaces.cmake:129 (swig_add_module)\n  CMake/CommonInterfaces.cmake:160 (generate_interface_module)\n  interfaces/python/CMakeLists.txt:21 (generate_interface)\n-- Creating wrappers for javascript\n-- Creating wrappers for xml\n-- Writing: C:/Users/HP/ELL/build/config.json\n-- Configuring done\n-- Generating done\n-- Build files have been written to: C:/Users/HP/ELL/build\n```\n. ",
    "FoxMarts": "After a few tries, I was able to make a cmake that just runs the example outside of the ELL directory.\nNow I want to change the code to save the SDGTrainer Model in the same folder as the executable, but i do not know what new headers to put in the code and what to change or change in cmake.\nCan someone help?\nBest regards.\nThe CMakefile \ncmake_minimum_required(VERSION 3.8 FATAL_ERROR)\n\ncmake file for forestTrainer project\n\nproject(ELLtest)\nELL location\nset(ELL ELL/)\nELL libraries location\nset(ELL_LIBRARIES_DIR ${ELL}/libraries)\nELL link library\nset(ELL_LINK_DIR ${ELL}/build/libraries/)\nInclude modules in the CMake directory.\nlist(APPEND CMAKE_MODULE_PATH \"${ELL}/CMake\")\ninclude(CompilerCache)\nSet C++ version\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\nSet GCC-specific options\nadd_compile_options(-Wall)\nadd_compile_options(-Wsign-compare)\nadd_compile_options(-Wno-missing-braces)\nadd_compile_options(-Wmissing-field-initializers)\nadd_compile_options(-fvisibility-inlines-hidden)\nadd_compile_options(-Wno-unknown-pragmas)\nset(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} -ggdb3 -O0\")\nset(CMAKE_C_FLAGS_DEBUG \"${CMAKE_C_FLAGS_DEBUG} -ggdb3 -O0\")\nset(CMAKE_CXX_FLAGS_RELWITHDEBINFO \"${CMAKE_CXX_FLAGS_RELWITHDEBINFO} -ggdb3\")\nset(CMAKE_C_FLAGS_RELWITHDEBINFO \"${CMAKE_C_FLAGS_RELWITHDEBINFO} -ggdb3\")\nSet up global variables to help find NuGet projects\nset(PACKAGE_ROOT ${EXTERNAL_DIR})\ninclude(OpenBLASSetup)\ninclude(LLVMSetup)\ninclude(SWIGSetup)\ninclude(CopySharedLibraries)\ninclude(AddPrecompiledHeader)\nfind_library(trainers trainers ${ELL_LINK_DIR}/trainers)\nfind_library(functions functions ${ELL_LINK_DIR}/functions)\nfind_library(testing testing ${ELL_LINK_DIR}/testing)\nfind_library(utilities utilities ${ELL_LINK_DIR}/utilities)\nfind_library(data data ${ELL_LINK_DIR}/data)\ndefine project\nset (test_name test)\nset (test_src main.cpp)\nsource_group(\"src\" FILES ${test_src})\nadd_executable(${test_name} ${test_src})\ntarget_include_directories(${test_name} PRIVATE include ${ELL_LIBRARIES_DIR})\ntarget_link_libraries(\n    ${test_name}\n    ${trainers} \n    ${functions} \n    ${testing} \n    ${utilities}\n    ${data}\n)\n. "
}