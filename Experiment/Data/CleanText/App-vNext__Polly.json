{
    "michael-wolfenden": "I think this is a really good idea and I will look into implementing it.\nIn the meantime, you can probably get information about the call that raised the exception from either the exception itself or the call stack. See How to get the name of the method that caused the exception for more information.\n. Not a problem\n. While I cannot guarantee thread safety under all possible scenarios, I have made sure to synchronize any access to shared state with locks (see CircuitBreakerState.cs)\n. Geoff.\nI was meaning to add a portable class library but haven't had the time so your contribution is much appreciated.\nThe checked over the changes and they look good, however there are two minor issues\n1) Are you able to change the default namespace and assembly name of the PCL project from  'Polly.Pcl' to 'Polly' to stay keep consistent with the other projects.\n2) Can you strongly name the portable class library. You will need to copy the Polly.snk from the solution root into the PCL project root and then click 'SIgn the assembly' from the project properties and select this file.\nIf you have any questions then let me know. Once you have made these changes, I will merge them and get a new nuget package deployed.\nThanks once again for you help.\nMichael Wolfenden\n. Geoff,\nI just thought of something else.\n3) Currently you are using Task.Delay as a replacement for Thread.Sleep, but for that to work you need to await it.\nhttp://stackoverflow.com/questions/12641223/thread-sleep-replacement-in-net-for-windows-store \nChanging\nSleep = span => Task.Delay(span);\nto\nSleep = async (span) => await Task.Delay(span);\nShould work, but I haven't had time to investigate fully.\n. Geoff,\nI am happy to go ahead with this change.\nMy preference is for unsigned assemblies but at the time there were no\nclear nuget standards on naming the signed / unsigned packages, so I went\nfor the lesser evil and strongly named the library.\nMichael\nOn 12/03/2014 7:17 AM, \"Geoffrey Huntley\" notifications@github.com wrote:\n\nHi Michael,\nI'd like to propose to introduce a breaking change where by Polly is not\nstrong named by default. i.e. increment the semver major.\nThe migration path for existing users who are using strong-names would to\nbe to\nmigrate to a separate nuget package. i.e.\nSigned versions of the client libraries are also available at:\nPM> Install-Package Polly-Signed\nThis is the path that other OSS packages are taking:\n- https://www.nuget.org/packages/Machine.Specifications-Signed/\n- https://www.nuget.org/packages/FluentValidation-Signed/\n- https://www.nuget.org/packages/ServiceStack.Text.Signed/\netc.\nImportant note binding Redirect is not available w/Portable Class\nLibraries:\n-\n   https://stackoverflow.com/questions/12337378/is-bindingredirect-supported-in-silverlight-windows-phone-and-metro\n   -\n   https://wpdev.uservoice.com/forums/110705-app-platform/suggestions/2511980-assembly-binding-redirection-support\nSuplemental material:\n- https://nuget.codeplex.com/discussions/247827\n  -\n  https://stackoverflow.com/questions/11656520/signing-binaries-of-open-source-projects\n  -\n  http://haacked.com/archive/2012/02/16/changing-a-strong-name-is-a-major-breaking-change.aspx/\n- restsharp/RestSharp#187https://github.com/restsharp/RestSharp/issues/187\n- https://json.codeplex.com/workitem/21995\nThoughts,\nGeoff\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/michael-wolfenden/Polly/issues/5\n.\n. Cheers\n. If after n retries the function call was unsuccessful, the exception that was causing the call to fail will be thrown. So if the function call succeeded, no exception will be raised.\n\nHope that makes sense.\n. Unfortunately, this is not currently possible. A Policy can handle multiple exception types however they all will use the same retry strategy.\n. Thanks for the contribution\n. The reason you are seeing this behaviour is that you are using an async void method, so the exception is being thrown on another thread.\nSee \"Gotcha 3: Async void methods\" at http://tomasp.net/blog/csharp-async-gotchas.aspx/\nThe following article is was written by someone facing the same issue. You can try their workaround, but unfortunately, Polly does not support retrying async methods yet.\nhttp://blog.dotnetnerd.dk/post/2014/07/13/Robust-integration-with-Redis-on-Azure-and-Polly.aspx\n. Maurice, sorry about the delay.\nFirstly, many thanks for the contribution. Async support has been the number one requested feature.\nIn terms of implementation though, I was thinking that perhaps a nicer way to implement it might be:\n1) Make the classes in the Polly.Net35 project that we need to add the new async methods to partial\n2) Add the implementations in the Polly.Net45 project\nFor example:\nin Polly.Net35 make the Policy class partial\nin Polly.Net45 add a new file called PolicyAsync with the implementation e.g.:\n``` csharp\npublic partial class Policy {\npublic Task ExecuteAsync(Func<Task> action) {\n{\n}\n\n}\n```\n3) Try not to change any code in the Polly.Net35 project. Add all new code in the Polly.Net45project, even is this means duplicating a method but giving it a new name e.g. append Async perhaps\nI am happy to accept you pull request and then merge all your changes into the structure above.\nI would be interested in your thoughts?\n. Maurice, once again thanks.\nI've taken a quick look and noticed a couple of things:\n- [ ] PolyAsync.cs, the constructor takes both an exceptionPolicy and asyncExceptionPolicy. Only the asyncExceptionPolicy is needed\n- [ ] CircuitBreakerSyntaxAsync.cs should has method CircuitBreakerAsync not CircuitBreaker\n- [ ] All the async unit tests should return Task and their Policy should be awaited\ncsharp\n[Fact]\npublic async Task MyAsyncUnitTest()\n{\n    // ... setup code here ...\nvar result = await CallMyAsyncApi(...);\n\n// ... assertions here ...\n\n}\n``\n- [ ] I think we should addConfigureAwait(false)to all our awaited tasks as we are writing a library adn we know the consumer doesn't need a synchronization context. Soawait action()becomesawait action().ConfigureAwait(false)` http://stackoverflow.com/a/13489639/386287\nI am happy to accept the pull request and make these changes.\nLet me know you thoughts / questions\n. Sorry, closed by mistak\n. Maurice,\nI'm confused.\nIf I change the constructor in PolyAsync.cs to the following :\n``` csharp\ninternal Policy( Func, Task> asyncExceptionPolicy)\n{\n    if (asyncExceptionPolicy == null) throw new ArgumentNullException(\"asyncExceptionPolicy\");\n_asyncExceptionPolicy = asyncExceptionPolicy;\n\n}\n```\nand fix the build errors due to constructor taking only one parameter now, all the tests still pass.\nHave I misunderstood?\n. Maurice,\nI get you now. \nI think the best option is what you suggested, to throw a InvalidOperationException with a detailed message. I would rather this, than for it to succeed even though the usage was wrong. \n. Ali.. Not yet.. But we will be adding support in the next couple of weeks.\nOn Wed, 26 Nov 2014 11:31 PM Ali Kheyrollahi notifications@github.com\nwrote:\n\nDoes Polly support async?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/michael-wolfenden/Polly/issues/15.\n. Rob,\n\nFirstly, thank you for your contribution, I've been meaning to add async support to the PCL but haven't had time to investigate whether its supported by all the profiles.\nUnfortunately, It takes quite a bit of time to review, merge, test then release any updates and I've been extremely busy lately.\nI have some free time coming up in the next couple of weeks and will review then.\n. Tom is correct. You can do this:\ncsharp\nPolicy.Handle<Exception>(ex => /* Generic logic here */)\n. pdamp, onovotny\nI've just release a new version (2.2.0) that has corrected the nuget target.\nLet me know if this has fixed this issue.\n. Thanks guys\n. SlyNet,\nYou could do this\nPolicy.Handle<Exception>(ex => !(exception is OperationCancelledException))\n. SlyNet,\nThanks for you input, I will consider adding this. In the meantime, If you wanted to, your could add this as an extension method in your code.\n. James,\nIf I provided an IPolicy interface, you would still have references to Polly all over your code base. \nThe point of decoupling is to shield your code from third party code. To do this, you would create the interface that your code relies on (IPolicy) and then implement it using Polly  (as you have done), or some other exception handling library. \nThe point is that your code only knows about your own interface which you inject everywhere. You could use some other library, and your code would not care. If I defined an IPolicy that you used everywhere and you wanted to change libraries, you are stuck.\nDoes this make sense?\n. James,\nMuch appreciated, I'm glad you are enjoying the library.\nRegards\nMichael\n. Justin,\nThanks for the bug report. The issue is that async span => await Task.Delay(span) is not blocking, hence causing the issue you are seeing. I think I'll replace your suggestion of the ManualResetEvent\n. Mark,\nThat functionality does not yet exist, however in the meantime you can achieve something similar by maintaining your own count like below:\n``` csharp\nvar retryCount = 0;\nvar policy = Policy\n    .Handle()\n    .WaitAndRetry(\n        5, \n        retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)), \n        (exception, timeSpan) => {\n            retryCount += 1;\n            // if retryCount ...\n        }\n    );\n```\n. Hi,\nThe reason that the DivideByZeroException is not being caught, is that the first time through, DoSomething executes 1/0 which cause a DivideByZeroException to be thrown. Polly will then retry, however in your retry handler, you are incrementing zero, so the next time we call DoSomething, it executes 1/1 which is valid and won't throw an exception, so no more retries are performed.\nI have create a code sample at https://dotnetfiddle.net/Widget/NDjoJF which demonstrates how it should work.\nLet me know if that answers your question\n. I have just released the latest version (2.2.3) with includes post execution support. This should allow you do what you are suggesting.\n. @yftachman, thanks for your contribution, but I have tackled this in another way. Version 2.2.3 now includes post execute support that will allow you to do what you are suggesting.\n. Thanks for your contribution\n. Hey Hacko,\nThanks for the issue, your suggestion is a good one and I'll add it when I get a chance.\nI'm curious though about why your calling .Result. This means your blocking on the asynchronous call which can cause deadlocks (http://blog.stephencleary.com/2012/07/dont-block-on-async-code.html).\nThe solution is to not mix synchronous and asynchronous code although I know in some situations this is avoidable.\nAre you able to post some sample code so I can get a better context on what your trying to achieve?\n. Frank,\nThanks for your feedback. I agree these are better names, but to change them at this point would be a huge breaking change that would everyone using the library.\nI will mark as wont fix and close\n. Much appreciated. Will merge, update the release notes and push out a new nuget package.\nThis closes #34.\n. Thanks for the contribution, but I want to hold out on adding ASP.NET 5 support until it goes RTM as the platform seems to be in a lot of flux at the moment.\n. Thomas,\nThanks for your contribution. My ai mis always to keep the surface area of the api as small as possible.\nAre you able to implement this via extensions methods rather than modifying the existing solution?\nFor example \ncsharp\npublic static HandledPolicy ExecuteAnd(this Policy policy, Action action) {\n    try\n    {\n        policy.Execute(action);\n        return new HandledPolicy(null);\n    }\n    catch (Exception ex)\n    {\n        return new HandledPolicy(ex);\n    }\n}\n. @ThomasMentzel I'm going to merge your request, however I am going to make a few changes. To keep the surface area of the api small, I am going to remove the extension methods as you can add them in your own project. I will also make some naming changes. Hopefully I can get a new nuget package out today, if not in the next couple of days. Thanks again for your contribution.\n. Agreed, I was thinking that you could specify another timespan that would reset the count if an exception hadn't occurred in that period of time.\nThoughts?\n. Thanks @kmcginnes for you contribution, I will look at merging in the next couple of days\n. Thanks @benjamin-hodgson \n. @MisinformedDNA Thanks for the contribution :+1: \n. @manastalukdar Thanks for the pull request however given that no 4.6 features are used there is no no benefit in providing a NET 4.6 library and hence maintaining another project.\n. Sure thing @yevhen, send through the pull request and I'll check it out \n. Hey @mauricedb,\nThanks once again for you help. \nI restructured the project recently in an attempt to add .NET Core support following https://oren.codes/2015/07/29/targeting-net-core/. I haven't released the updated nupkg's yet as I haven't done extensive enoguh testing yet.\nI looked at moving to the new project.json system, but at the time my understanding was that I could not target 3.5 or the other PCL plateforms. I'm not sure if this is still the case and in either case I figured if I could get away with providing .NET Core support using the existing system I would stick to that. \nIn terms of testing, your right. SystemClock.Sleep being static was a bad idea. I bit me hard when I moved to xunit2 which runs all the tests in parallel. I was getting random test failures and ended up having to disable running the tests in parallel\nSee:\nhttps://github.com/michael-wolfenden/Polly/blob/master/src/Polly.Pcl.Specs/Properties/AssemblyInfo.cs#L5\nhttps://github.com/michael-wolfenden/Polly/blob/master/src/Polly.Net45.Specs/Properties/AssemblyInfo.cs#L5\nI have to admit, I'm finding all the changes to the .NET platform confusing and your advice would be appreciated. Are the changes I've already made enough to run Polly on .NET Core? If not can I move to the new project format and still support the same target?\n. Basically taking complete ownership of the repository, handling issues / pull requests /updates etc. I'm looking for people committed to the ongoing maintenance of this project.\n. Thanks @joelhulen, I've put a call out on twitter. I'll leave if for a couple days and get back to you.\n. @ploeh Absolutely, and if you know anyone that is interested then it would be much appreciated\n. @joelhulen You still happy to take the reins?\n. @joelhulen Last night I created https://github.com/PollyOrganisation and was going to move the Polly repo there, but its your call? \n. @joelhulen Whats the github url?\n. Hmmm.. I need admin rights to App-vNext to transfer the repo\n. @joelhulen Its been successfully transferred, feel free to remove me from your organidation. Thanks again for taking over the reins, its much appreciated. I have an appveyor build setup under my name that is currently building it on pushes / pull requests. The badge in the readme is also pointing to that. You will need to set up your own appveyor project to do the same (or not). Let me know if you need any help setting it up. The readme, nuspec all point to the old repo as well, the links will need to be changed to your new repo.\n. @joelhulen In regards to appveyor, as far as I remember the appveyor.yml configuration file (https://github.com/App-vNext/Polly/blob/master/appveyor.yml) should be all that is needed. It just specifies to use vs2015 to build and rund the build.ps1 script. The build script itself will do the rest of the work including setting the appveyor version (using gitversion). Note, I manually upload the packages (artifacts) produced by appveyor to nuget. Are you having issues?\nThe other information comes from the nuspec file (https://github.com/App-vNext/Polly/blob/master/src/Polly.nuspec), but you will need to publish a new version of Polly to nuget for the changes you've made to show. The last change I made to Polly was to add .NET Core support (following https://oren.codes/2015/07/29/targeting-net-core/) however I never published this version (2.2.4) . You could publish this if you wanted so that your not just publishing a new version to change the project details. Note, there is also a signed version of Polly that the build produces (https://www.nuget.org/packages/polly-signed)\nLet me know if you have any more questions. \n. @joelhulen What is your nuget username?. Looking at https://docs.nuget.org/create/managing-package-owners, I can make you an owner, and then you can remove me as an owner to basically transfer ownership.\n. Just made you an owner of both Polly and Polly-Signed\n. @joelhulen yep thats right\n. @onovotny I'm a bit confused. I thought I was updating the nuspec file as part of the build script using the ReferenceGenerator cli. For clarification was this incorrect?. \nIn this pull request it looks like you've manually specified the dependendies in the nuspec file, but my understanding was that this is the whole point of ReferenceGenerator ie to automatically generate these so if you add a new dependency to your project, it will correctly be added to the nuspec.\nAny clarification would be much appreciated.\n. No problem @onovotny, happens to the best of us. Thanks for clarifying though and thanks in general. Your posts have be invaluable in helping me understand the new nuget monikers and net core.\n. ",
    "waynebrantley": "Great, thanks...\n. ",
    "ghuntley": "2) Can you strongly name the portable class library. You will need to copy the\n   Polly.snk from the solution root into the PCL project root and then click\n   'SIgn the assembly' from the project properties and select this file.\nSee and discuss this on issue #5 \nAs for other points you have raised I'll go through and clean up the pull.\n. ",
    "bcuff": ":+1: I hope this gets merged. I would like this exposed as well.\n. Maybe exceptionsAllowedBeforeBreaking should be a parameter to the circuitBreakerState implementation. You may want an implementation that requires a success ratio for example. In that case the exception count would be meaningless.\n. ",
    "bunceg": "Ditto +1\n. Hi,\nHappy to wait for a wider discussion/direction as this makes sense if some hystrix logic may be ported. Circuit breaker is probably the most useful, (and most complex :) of the polly features) so it makes sense to think this through carefully.\nFor my immediate need, I am working around the issue anyway now by putting my own coordinator in front of the Polly handler (i.e. coordinator think it's tripped just throw a BrokenCircuit without even checking Polly). Isolate and Reset work ok as a \"master switch\" but not really in my scenario.\n. sounds good to me, thanks\n. Thanks for this\n. Good idea, however could you have some internal checks on the handle exception to get round it....? You can argue that to keep it simple, you should implement it yourself in this layer instead, instead of adding the override to the circuit breaker?\nTbh, I would like to see the self-implementation of circuit breaker fork merged instead if that is in-line with your design, as that sort of covers this, ie do it yourself in a custom implementation, and also allows us to handle circuit breaks in a central place across several out-of-process services........ Though maybe my solution to tims request is the same for me... Haven't thought it through fully yet...\ud83d\ude0f\n. Regardless of the mathematics, I think your approach to the problem is fine as it makes more sense to what you would want a circuit breaker to be in practice.\nHowever, to refer back to the other part of my note, all of these circuit breakers are great for the simple one-process approach. IMO, the type of things you are circuit breaking (external services) are highly likely to be used across processes. Unless I've completely missed it, I don't think Polly handles this scenario.\nSo, should Polly implement this ? (I think not, as the backing store to hold this data, and the appropriate trigger logic for the breaker, is probably very system specific) but I'm not sure of the best way to go about implemented this outside of Polly and injecting the functionality into it's fluent based framework...\n. HI,\nYes you do understand, and we are following the same principle in that A, B or C will find out of their own accord eventually. I take on board your comment about the co-ordinator could fail, which is a real concern to our situation too, but IMO that is a decision for the implementing team based on the services involved and the consumers of those services.\nHowever, your approach of injecting state may well solve the problem anyway - something else can check the shared state first and manually break the circuit and I like the way of doing this. Our implementation uses a master switch to avoid calling the service anyway but your option sounds a bit cleaner.\nps: thanks for the book recommendation, I'll add it to my collection with \"release it!\" :)\n. Ok... worked this out. The Policy was being overwritten each time so wasn't keeping state between calls. I needed to store this in a static variable so it could remember previous actions\n. On the open issue #6, I appreciate it wasn't the path the team wanted to go at the time, but I really can't see any other clean way to solve the issue below...\n\nTwo instances in their own processes, each has an instance of circuit breaker. Instance A trips at 00:00 and lasts for 5 minutes.. Due to random load balancing, most requests just happen to go to instance A. However, by chance, at 04:50 instance B gets some requests and also trips. it's 5 minute trip timer now starts. However, the tripped service is back at 05:00. The instance A breaker is cleared at 05:01 but the instance B breaker is not able to be cleared until 09:50 - 4+ minutes after when it should be able to serve requests.\n\nI take on board all the comments re: negotiation between services and what if connection to the shared state handler goes down etc. but I'm taking the pessimistic view that if a service the breaker is protecting is dead then it's more likely that the service is really dead rather than the alternative that the service is alive but one instance can't seem to talk to it.\nBesides, IMO, that can be some kind of \"quorum\" logic - two instances, two need to vote dead etc. More complex, but this can be part of the state handler to be developed by the poor soul (i.e. me!) who desires this kind of functionality...\n. Never mind. Worked out that I need to store a CircuitBreakerPolicy not a Policy object as my static pointer to the circuit breaker policy...\n. Fantastic write up guys of all points so far. As somehow who has implemented something like this, I went down the route suggested by @mcquiggd. I implemented a decorator above Polly that used Redis caching to hold state - it isn't perfect but it's good enough for our needs.\nTherefore, although I would love an out of the box solution to take the problem away, I agree that this is hard and there are so many possibilities for how to implement this so I'd rather have an extension point / interface that I can hook into instead. \nPolly Contrib would be nice and, eventually perhaps, this goes down the NHibernate route of incorporating battle-tested stable contribs into polly itself but that's for something down the road.\nI'd vote for (d), but a simple OOB contrib to demonstrate an example would also be helpful. ",
    "reisenberger": "@lund @bunceg @bcuff / for anyone reading this PR at a later date:\nWhile Polly has not at this point gone the route of allowing people to inject circuit-breaker state (see also the discussion in #41 on merits/de-merits of this), \n- more manual control over the Circuit-Breaker has been provided in Polly v4.0; \n- and the Roadmap proposes future Circuit-Breaker types which break on different statistics.\n. Hi @bunceg, coming to the discussion from the other thread:\n\nI take on board all the comments re: negotiation between services and what if connection to the \nshared state handler goes down etc. but I'm taking the pessimistic view that if a service the \nbreaker is protecting is dead then it's more likely that the service is really dead rather than the \nalternative that the service is alive but one instance can't seem to talk to it.\nBesides, IMO, that can be some kind of \"quorum\" logic - two instances, two need to vote dead etc. \nMore complex, but this can be part of the state handler to be developed by the poor soul (i.e. me!) \nwho desires this kind of functionality...\n\nRe the scenario:\n\n\nTwo instances in their own processes, each has an instance of circuit breaker. Instance A trips \nat 00:00 and lasts for 5 minutes.. Due to random load balancing, most requests just happen to \ngo to instance A. However, by chance, at 04:50 instance B gets some requests and also trips. \nit's 5 minute trip timer now starts. However, the tripped service is back at 05:00. The instance \nA breaker is cleared at 05:01 but the instance B breaker is not able to be cleared until 09:50,\n4+ minutes after when it should be able to serve requests.\n\n\nThe manual controls .Isolate() and .Reset() added in Polly v4 (designed to allow greater control over isolation of downstream systems) could be used.  Whenever your co-ordination system (by whatever logic deemed quorate) decides that the breaker on instance B can be cleared, it could invoke .Reset() on the instance B breaker straight away - no need to wait.  EDIT: To determine when A breaks/clears, you have the new onBreak/onReset delegates.\nSimilarly, on the breaking side of the process, if A (plus however many other services deemed quorate) determine that some subsystem should be marked unavailable for all, you could (at present) call .Isolate() on breakers used elsewhere over that subsystem, and later .Reset() them when your co-ordination system deems it is safe to do so.\nPer previous discussion (#41), there are arguments for and against maintaining such a cross-process-breaker-state co-ordination system, but your line of reasoning (effectively to trust the co-ordination between local services more than the link to a certain downstream service) makes a reasonable argument for this.  And, clearly the approach outlined above is not as straightforward as simply injecting state would be (tho this would also have other implications).  Interested to hear other community views, and keeping this open for review.\n. @bunceg On a practical level also, we would like to resolve the future direction for the circuit-breaker further (frequency-based? proportion-based? hystrix-like?) (ref #41 and #90) before making the internal state public eg to be injected.  The internal representation of circuit-breaker state has already evolved over the last few months, and may evolve yet further as new circuit-breaker variants are introduced.  We need to avoid making the internal state public and 'locking ourselves in' at this point, and/or providing an API which we only break for you later.  \nThis is not to say that Polly might not at some future date expose the internal breaker state for injection - can see how this would help the use case you describe and possibly others.  Just that it's not next up on the roadmap.  Sharing this wider roadmap view in case that is useful.\n. Closing this old PR as this will not be the approach to adding this to Polly.  On-going discussion of allowing circuit-breakers to use external state is in #215 .  Referencing this from #215, for anyone who wants to read the discussion here.. @NielsKlosterAndreassen @mattgwagner  The AppvNext team have now taken on the stewardship of Polly.  Although this PR is old, just updating you that this (being able to specify no-retry as a Policy) seems a reasonable idea, that several people have asked for.  The retry-count-of-zero approach is preferred for this and we should be able to merge this in due course.  See #37 if you want to follow / help implement this!\n. Closing this PR in favour of #37\n. @joelhulen Extending Polly such that policies could handle/react to return values as well as exceptions could be useful, for example, in the case of calls to endpoints returning HTTP status codes.  eg Calls to RESTful endpoints might be indicating significant failure via http status codes rather than exceptions. We could look in to this in the longer-term.\n. @DSanchen Thanks for the feedback!  We are always seeking to understand how people are using or  would like to use Polly: what would your Use Case for reacting-to-return-values be?  (Others reading this thread in future: feel free to contribute your Use Cases too so we can take into account!).\nAnd: in the Polly roadmap, there is a more detailed example of the proposed syntax for this feature.  Would this syntax work for you?\n. @DSanchen Thanks -good to see.\n. @ilmax @DannyRyman @renzska @DSanchen @tidusjar  PR #130 proposes an implementation of this feature: allow Polly policies to react to return values.  Please feel free to pull down the code of the PR and experiment if you wish.  Pending any feedback, I'd expect the feature to be released in the next week or so.  The main outstanding work before release is to add suitable documentation.  \nBriefly, the additional syntax for policies-handling-return-results is designed to flow entirely fluently with existing syntax, eg: \ncsharp\nint[] httpStatusCodesWorthRetrying = {408, 500, 502, 503, 504}; \nHttpResponse result = Policy\n  .Handle<HttpException>()\n  .OrResult<HttpResponse>(r => httpStatusCodesWorthRetrying.Contains(r.StatusCode))\n  .Retry(...)\n  .Execute<HttpResponse>( /* some Func<...,HttpResponse> */ )\nEssentially, you have new methods .HandleResult<TResult>(Func<TResult, bool>), .OrResult<TResult>(Func<TResult, bool>) (and a few similar overloads) alongside .Handle<TException>(...) and .Or<TException>(...).   \nPolicies can be configured to handle both exceptions and return results (in the same policy), and exception- and result-handling can be expressed fluently in any preferred order.\nThe implementation handles return results natively rather than throwing handle-able results as exceptions.\n. Feature delivered: on Nuget as v4.3.0\n. Hi @kbabiy  (Michael Wolfenden has stepped back from Polly by the way; the AppvNext team have now taken stewardship.)\nI'll reflect further on an .Except(...) feature: I can see a syntax like this would suit some situations.  \nAspects to think through would be how it played alongside the existing syntax.  For instance, what would be meant by the following?\ncsharp\nPolicy\n  .Handle<X>()\n  .Or<Y>()\n  .Except<A>()\n  .Or<B>()\nShould B be taken to be excluded or included by that? (And would the decision be clear to all users, whichever we chose?). It would probably be clearer to say that 'whitelisting' and 'blacklisting' exceptions could not be mixed, and 'all except' was an entirely alternative fluent stream.  eg\ncsharp\nPolicy\n  .HandleAllExcept<X>()\n  .Or<Y>(); // Clearer here that Y is not handled?\nWe'd also then need a way to combine that with the fact that Polly can also now handle return results.  We probably wouldn't want to mix blacklisting and whitelisting in the same syntax, so result-handling would have to follow the 'all except' pattern too. \ncsharp\nPolicy\n  .HandleAllExcept<X>()\n  .Or<Y>()\n  .AndAllResultsExcept<TResult>(...) \n  .OrResult<TResult>(...) // etc\nBeginning to become quite complex to follow ... \nWe always have to consider whether extra API surface/complication adds sufficient benefit ... jury slightly still out for me on this one, given that there is already a workround (and taking into account the complex play with handling results).  Very happy however for further community feedback on this.\n. @kbabiy Regarding other ways to handle the scenario:\n\nTimeout quite probably means that requested resource is in trouble (working on top of its capacity) \nand adding retries makes things even worse\n\n... you have described the classic case for using a CircuitBreaker wrapping (or wrapped by) the Retry policy.  See the very similar description about when retries become counter-productive, in the introductions to Retry and CircuitBreaker in the wiki.\nPerhjaps consider wrapping a CircuitBreaker (perhaps breaking specifically on TimeoutException) in with your Retry.\n. Closed via #79 \n. Closed in #110 \n. Hi @eldiosyeldiablo @Plasma Many people have requested this (retry count of 0), and there is an open PR #37 which addresses this.  We hope to get this merged soon - please see the comments in #37, and feel free to volunteer to fix it up when the right time comes over the following days ...\n. Closed via #37.\nClosing given that the retry-zero-times functionality (asked for by several people) has been delivered.\nHowever, @eldiosyeldiablo , if you feel a wider discussion on exception filtering using Polly is merited, please feel free to comment further!  I agree that exception filters in C# 6.0 will also contribute in this area.\n. @nelsonghezzi Thanks for this PR earlier in the year!  AppvNext are now stewarding Polly, and agree this feature would be good to add.  \nAt the moment there is some work underway on async retry which may affect the retry overloads, so it may be best to hold off rebasing until that is complete.  However, if you (@nelsonghezzi) or anyone else who's asked for this (@NielsKlosterAndreassen @mattgwagner  @eldiosyeldiablo @Plasma ?) can volunteer to rebase this PR at the time, please post on this thread! \nWe will ping again on this thread when it's a good time to rebase and get this merged! \nThanks\n. @nelsonghezzi Super, please go ahead!  \n(@joelhulen On closer inspection, I think this PR and the other in progress (PR 53) are orthogonal, so it doesn't matter in which order we take them. )\n@nelsonghezzi : Would you be able to update changelog.MD to describe the change?\n. ( @nelsonghezzi Have edited previous comment to add a bit more explanation as I see that magic strings were already used in some nearby tests (context tests), bool style elsewhere )\n. Thanks @nelsonghezzi , looks good to go to me! :smile: \nI am heavily involved in the codebase (and closely in touch w joel behind the scenes), but joel on the AppVNext team is the ultimate product owner, and managing pushes to nuget, so: over to @joelhulen on this, and how he wants to handle changelog.md / GitVersionConfig.yaml .\n. @YoniH @hawkunsh An AppvNext team has taken over stewardship of Polly, and are now looking at historic issues such as this.  I'll comment in case still useful to you or others.\nThe ContextualPolicy was added way back #1, and had as intention to pass static (read-only) data from a particular .Execute() call to the onRetry delegate of a policy.  It looks as if context was made a read-only collection as the focus was on capturing static data for logging; perhaps also to avoid getting in to issues of thread-safety.  As you have discovered, although you cannot manipulate the contents of the collection, you can exchange mutable data by manipulating a property on some fixed instance held in the collection.\nThe general case of your request would be a mechanism within Polly for passing mutable data between control delegates (such as onRetry) and Execute delegates.  At present, there is no mechanism within Polly to do this.  We could look at this for the future (for example relaxing the read-only constraint on the context collection), but would need time to evaluate the thread-safety aspects.  Effectively, it would pass responsibility for managing the thread-safety of context to the library user (it may be as simple as that).  Alternatively, if we were not targeting .NET3.5, we could possibly move context to an inherently thread-safe collection such as ConcurrentDictionary.\n@YoniH asked if there was any better way to do this than the example presented.  My only observation is that, as the example already implicitly closes over someNumber for the Execute delegate, one could implicitly close over someNumber for the onRetry delegate as well (bypassing using the Polly context at all) (although this is probably only practical if policy declaration, and usage, are adjacent, as in the example).  \n```\nclass Program\n{\n    static void Main(string[] args)\n    {\n        int someNumber = 0;\n    var policy = Policy.Handle<DivideByZeroException>().Retry(3, (exception, retryCount) =>\n    {\n        someNumber = 17; //Instead of 17, the value would be calculated based on the exception\n    });\n\n    policy.Execute(() => DoSomething(someNumber));\n}\n\nprivate static void DoSomething(Integer numberArgument)\n{\n    Console.WriteLine(\"The number is {0}\", numberArgument.Value);\n    Console.WriteLine();\n\n    int x = 0;\n    var y = 2/x;\n}\n\n}\n```\nHope that this helps.\nWe'll leave this issue open, as a general prompt of the possibility to pass mutable data between onRetry and Execute.\nOthers interested, please +1 if this is an important feature for you\n. The ability to do this is now delivered in Polly v5.1.  Polly's Context flowing with the execution becomes mutable, to allow what @YoniH and @hawkunsh requested.  \nSee http://www.thepollyproject.org/2017/05/04/putting-the-context-into-polly/ for details.  Shout if any questions/suggestions.. I'm not sure from @TimGebhardt's original question, if he was assuming there were successes in-between the failures across the three-hour period or not.  My reading of the codebase was that the breaker state is Reset() after any successful call to the supplied action.  (Have I got this right?). So, if [A] a service failed intermittently (with successes in-between) across three hours, the existing CircuitBreakerPolicy implementation wouldn't trip.  If on the other hand [B] the service only received three calls across a three-hour-period and all failed, the existing CircuitBreakerPolicy would trip. (Seems to make sense - all calls have failed - but not sure how long one would choose to trip a circuit for on a service only averaging a call per hour?)\nThe question made me think tho about a frequency-based circuit-breaker (which Michael Nygard also hints at in his book).  Something like: \"If the policy experiences N exceptions in any period T, break the circuit for a given timespan\" (eg \"Break the circuit if we receive 3 exceptions in 30 seconds\").  I have just firmed up a sketch I put together a few days ago (when first saw Tim's q) and committed to https://github.com/reisenberger/Polly/tree/FrequencyBasedCircuitBreaker - is this an avenue worth pursuing at all?\nIt essentially maintains a FIFO queue of the timestamps of the last N exceptions, and uses this quite simply to determine if N have occurred within the given timespan.\n. Or for an alternative mathematical averaging approach? (doesn't maintain a FIFO queue)\nhttps://github.com/reisenberger/Polly/tree/FrequencyBasedCircuitBreaker2 \n(I can see merits and demerits to all of the alternatives ...)\n. Hi @bunceg .  If I understand you rightly, the scenario is that if services A, B and C (say) all use another service M, then if service A breaks its circuit to M, it could be useful for services B and C to know about this and break their calls to service M too?  We went through a similar line of thinking, but concluded - is there a need?  If service A cannot reach service M for a reason that would also prevent service B, won't service B just discover that of its own accord (and also circuit-break) in due course?  Is the overhead of inter-process co-ordination (which might also fail) worth it?  (And A could also fail to reach M for a reason which doesn't affect B ...)\nWe did, however, go through a similar line of thinking - that it could be useful to be able to inject state (as you say) into a CircuitBreaker - for manually breaking a circuit.  Sam Newman's (highly recommended) book on microservices suggests one might manually break all circuits to a downstream service in order to upgrade that downstream service.  I fretted for a while over the fact that we couldn't inject state into a Polly CircuitBreaker to achieve this.  For now, we have however gone with the same pragmatic above logic - do we need to?  If we build our processes robust enough to be able to survive downstream unavailability (whether unexpected or 'expected' eg due to upgrade), then that should be enough.  But @michael-wolfenden - could being able to manually break a circuit (inject state) perhaps be a useful addition sometime?\n. @kristianhald Thank you for your interest in Polly - and offer of help!\nMore sophisticated approaches to circuit-breaking are very much on the Polly roadmap (see towards end of doc) (for reasons TimGebhardt and you mention, and others)\nRight now AppvNext are reflecting further on the best forward path for circuit-breaker: whether to go for the frequency-based and proportion-based circuit-breakers already mooted in the roadmap, and/or whether something more sophisticated along the lines of Hystrix\u2019s time-slicing approach (somewhat similar to the suggestion from @DarrellMozingo above).  Community views?\n(may set out further views/options for feedback, later in this thread)\n. ( and @kristianhald - we may yet take you up on your offer of help! )\n. @kristianhald Many thanks for your input!\nThe Polly circuit-breaker internals have evolved since last August, and I pushed some new prototypes last couple days to https://github.com/reisenberger/Polly/tree/CircuitBreakerSpikeMarch16 . This includes a new sketch closer to the Hystrix approach.  @kristianhald / wider community: very happy for any feedback on these.  (New variants are also optimised for performance over the previous, and factor out metrics controlling the circuit more clearly.)  \nConsecutiveCountCircuitController: the existing Polly circuit-breaker logic.\nFrequencyCircuitController: as discussed earlier in this thread and in the Polly roadmap.  Triggers on >N exceptions in a period T.\nProportionCircuitController: as in the Polly roadmap.  Triggers on >N exceptions in T calls.\nCommentary: An advantage of the FrequencyCircuitController and ProportionCircuitController is that both are simple to understand.  Some disadvantages:\n- a pure proportion/ratio-based circuit breaker may not adapt well to the kind of \u2018slow period\u2019 referred to earlier in this thread.  7-in-10 failures occurring widely spaced in a slow period \u2013> you might not want to break circuit.  A minimum throughput could help here.\n- a pure frequency-based circuit breaker potentially has problems at the opposite end of the scale \u2013 it doesn\u2019t adapt well to sudden increases in load.  For instance, say you initially set your circuit-breaker to trip on >5 failures per T.  That might have been a significant threshold at the time of configuration.  If the system in question goes through a serious load increase (say, peak sale period), suddenly you may be getting (and managing to handle) 75 requests per T, of which only 5 are failing (a small proportion) \u2013 you might not want to circuit-break on only 5 failures at that throughput (and kill off the other 70 requests which could have got through successfully).  One could argue this was misconfiguring the tripping threshold in the first place, but the concept remains: pure error frequencies (N per time T) as a measure, are vulnerable to not scaling with load increases or decreases.\n... which brings us to...\nTimesliceCircuitController: This is an early cut at a ratio-within-timeslice approach.  @kristianhald, it brings in the minimum throughput threshold idea too.  \nCommentary: Initially harder to understand.  But the approach deals well with both quiet period and high densities (combining as it does elements of both ratio and frequency measures).  The approach may be better suited to higher throughput systems because of the time-slicing, tho user has control over duration of slice.  \nCommunity views on all these options welcome\n. @kristianhald If you are interested in helping/contributing, I can set out what would be needed to bring one or more of the above variants to production in Polly (wiring up the configuration; unit tests), and you can state what you might be interested in taking on?  ... The unit tests for any of the above time-based policies will be quite fun :smiley_cat:, using Polly\u2019s SystemClock concept to manipulate time to simulate scenarios. \n(AppvNext efforts at the moment are focused on #14 (a major step to unlocking some of the other elements on the roadmap), and I will have extra time challenges from April.) \nAs a first step also, the wider AppvNext team must decide how many of the above variants to bring to market.  As ever, balance to be struck between power/options and simplicity. \nCommunity feedback welcome again: would some of the circuit-breaker variants in previous post be more useful than others?\n. Further development effort has been made on TimesliceCircuitBreaker .  The https://github.com/reisenberger/Polly/tree/CircuitBreakerSpikeMarch16  spike now wires up the TimesliceCircuitBreaker syntax and adds unit tests.  The implementation does not at this time (in the hystrix manner) subdivide the timeslice into further statistical buckets, for 'smoothing' of the statistics at timeslice rollover (though this could be added).  Comment welcome.\n. @kristianhald  Thanks for your interest and involvement with this feature!  If you have time available, any contribution to add the rolling slices/buckets within timesliceDuration (making it more a sliding statistical window) would be valuable.  Shout if you can work on that - and if any thoughts/questions around it.  (We could operate/operate initially without it, but it would improve the responsiveness of the breaker.)  \nNice observation about OnAccessSuccess! Will comment further shortly.\nRe:\n\nwhat the timesliceDuration  is going to be set to (seconds, minutes or hours)\n\n... I have thoughts exactly about this - about the most appropriate way to configure this kind of circuit-breaker.  I will add thoughts either here or in draft documentation (review will be welcome...), in a few days' time.  \nThanks!\n. @kristianhald Here are some specific thoughts around adding the rolling slices/buckets within timesliceDuration ... if you are able to work on it!\n[1] The number of buckets that timesliceDuration is divided into internally, need not (I am thinking) be user-configurable at this stage.  For example, we could just pick a number (4? 5? 8? 10?) which significantly improves the responsiveness/fidelity of the circuit-breaker to its configuration.  eg 5 = rolling-throw-away 20% of the statistics at a time (a great improvement on 100%-throw-away; likely to cover most fidelity situations; strikes a balance between fidelity and extra computation).  What do you think?\nRegarding not user-configurable:  Simplicity of configuration is a Polly goal.  My feeling is the extra configurability of number of internal buckets would not significantly add feature benefit versus the extra comprehension load.  Our aim is just improve breaker fidelity-to-configuration to acceptable tolerance, any sensible value that achieves this is good ...  (tho open to community feedback if anyone can make a case for configurable buckets ...)\n(Hystrix probably cares about configuring this more, because they emit stats at bucket frequencies)\n[2] Should we consider some minimum timesliceDuration below which we do not subdivide into further buckets?  Or (alternative/similar) some minimum size for a bucket? (ie use fewer buckets - or none at all - if they would be smaller than that).  What do you think? \nRationale: At some point there will be diminishing returns in the trade off between more fidelity/a more responsive circuit-breaker, versus higher computation.  We could performance-measure to determine exactly that point ... it might even be quite small ... But keeping pragmatic, is there likely to be a need to fine-tune breaker responsiveness (what buckets affects) at sub-half-second or sub-quarter-second levels?  (And if that fine-tuning is needed, reducing the overall timesliceDuration to those levels, without buckets, is probably equally effective.).  I would be comfortable with a minimum half-second or quarter-second bucket-within-timeslice size.  \n(In summary ... Usually I do not like to impose decisions from within a library on the user.  But for this already-quite-complex feature, I propose starting with some sensible/pragmatic decisions to reduce configuration complexity, and await community feedback (always welcome!) if refinement is needed... ... )\n(EDIT: Configuration assumptions/limits/tolerances would also be documented.)\n. Hi @kristianhald.  Thanks for all this thorough and detailed thinking; all very useful!\n\nI made a quick [buckets] POC \n\nThanks - will look at this shortly!\nI made a draft documentation (wiki page) earlier today at https://gist.github.com/reisenberger/d0ed99101634b0388dd7e3b92fbfadac .  \n@kristianhald Re the proposed logarithmic calculation of bucket size from stat window duration, see my comments within the draft doco about the possible downside of this kind of circuit-breaker with long statistical windows: the responsiveness of the circuit-breaker seems in the worst case (do you agree?) essentially proportional to the stat window duration, however finely you divide it into buckets, because of the 'long tail of successes' problem described.  Is the logarthimic calculation of bucket size still worthwhile in light of this?  I cannot imagine anyone really wants a circuit-breaker that doesn't react for 5 minutes, 10 minutes, 30 mins, whatever, to an 100% failure problem.  Given the relatively narrow range of times this leaves for which the timesliceDuration probably makes sense (a few seconds to a minute or two), I wonder if it is adequate just to adopt a fixed number of buckets (unless makes buckets too small as prev discussed).  (While I like the elegance of the logarithmic approach, we have to consider also that we have perhaps to explain it in doco; that somebody has to maintain this in future, or ask/seek to understand why it was done this way, etc).  @kristianhald, perhaps really this is the same as you are also already saying: choosing a calculation that provides a good number for any input might be hard... :smiley: \n@kristianhald You'll see in the doco that I have varied the terms slightly (AdvancedCircuitBreaker; samplingDuration).  However, for now, in the forks we are working on, stick to current class/variable names if poss - this will keep forks easier to merge while work-in-progress.  When we are feature complete, then we rename to some final naming before making the PR to master.  Thanks!  That said: feedback on choice of terminology all welcome!\n. @kristianhald To state more precisely part of my previous thinking: varying the size/number of buckets can increase the fidelity (fidelity-at-all-times) of the circuit-breaker to its configured thresholds, but cannot increase its responsiveness (overall speed of response) to the theoretical 'long-tail of successes' problem stated. (which also, after all, might not only be a theoretical problem in a lot of cases: some systems will behave exactly like this 100->0%! :smile_cat: )\nI will continue thinking about this, but would be interested in your reaction to this problem.  \nFinally, regarding my comments about configuration values that are suitable / not-suitable: this is at this stage to share thinking and explore the contours of the problem, not suggesting yet to disallow values in code.  However, we should indeed consider (later) the configuration limits for each parameter.\nAgain: very many thanks for the productive contributions!\n. Draft documentation (https://gist.github.com/reisenberger/d0ed99101634b0388dd7e3b92fbfadac)  updated to be less prescriptive about which timesliceDurations make sense, because, as @kristianhald you rightly point out, we cannot anticipate all usages of the feature.  \nHowever, relationship between timesliceDuration and breaker responsiveness kept clear, because it is important that users seeking a responsive breaker do not fail to understand the possible implication of configuring a breaker in minute or hour periods.\n. @kristianhald Lots more useful thoughts - thank-you!  I think we are shaping up what are the important practical limits on each parameter. I will summarise these shortly for review.\nRe the POC sketch, I see no problems with this (nice refactor).  I can see possible points-to-check later around possible/minor micro-optimisations [to consider if necess] and naming, but that best done after all the major conceptual issues and boundary issues (in discussion now) are resolved, implemented and tested/proved through testing.\nThanks for all the great contribution!\n. Hi @kristianhald \n\nnew implementation [...] \nhttps://github.com/kristianhald/Polly/tree/CircuitBreakerSpikeMarch16_AddedWindows\n\nSuper; I will review further in the next few days.\n. Hi @kristianhald. Re:\n\nI was thinking, in regards to the issue with a low sampling duration and windows, maybe for \nsimplicity only use rolling windows if the sampling duration is set high enough. It could be \ndocumented by stating that if sampling duration is set to x or higher, then rolling windows are used \nelse a single window is used for the entire sampling duration.\n\nYes, let's do this.  I suggest herewith some decisions to keep us moving (tho comments certainly welcome if anyone sees other angles).  Let us declare in the TimesliceCircuitBreaker some internal consts such as:\ncsharp\ninternal const int DefaultNumberOfInternalBuckets = 10; // or 'windows' ... align to preferred terminology\ninternal const long ResolutionOfCircuitTimer = TimeSpan.FromMilliseconds(20).Ticks;\nand run some decision code as you suggest, something like \ncsharp\nif (timesliceDuration < ResolutionOfCircuitTimer * DefaultNumberOfBuckets) { /* don't divide into windows */ } else { /* do divide into windows */ }\nCan the operational code be done so that it doesn't look too messy / branching depending on whether it's using further buckets/windows or not? \nRationale: Per DateTime documentation, DateTime resolution is around 15-16ms, as you commented earlier.  Let's round this up to TimeSpan.FromMilliseconds(20).  There isn't any point in creating slices (or windows within slices) smaller than this, as it will just lead to empty slices/windows.  As we are defining as a well-named const ResolutionOfCircuitTimer, it'll be easy to change later if needed, and easily visible if any user later has higher resolution requirements and investigates the code.\nSimilarly, in TimesliceCircuitBreaker/Async, let's change:\nif (timesliceDuration <= TimeSpan.Zero) throw new ArgumentOutOfRangeException(\"timesliceDuration\", \"Value must be greater than zero.\");\nfor something like:\nif (timesliceDuration.Ticks <= TimesliceCircuitBreaker.ResolutionOfCircuitTimer ) throw new ArgumentOutOfRangeException(\"timesliceDuration\", String.Format(\"Value must be greater than {0} milliseconds.  This is the minimum resolution of the CircuitBreaker timer.\", TimesliceCircuitBreaker.ResolutionOfCircuitTimer /* converted to millisecnds! */));\nThese approaches could be refined later (for example, between 200ms and 20ms we could adopt an  algorithm which provided the maximum number of buckets which kept bucket size over 20ms).  But let's start instead from a premise 'keep things as simple as possible until we know they need to be more complicated'.\nRegarding descending as far as TimeSpan.FromMilliseconds(20) rather than some arbitrary limit 1 second or 1/4 second, well: given we have the resolution, we may as well permit it: as you say, we can't foresee all uses of the library.\nDoes this sound like a good way to proceed?\nTomorrow hopefully I will add my promised comments/responses on the practical limits on each parameter and how they may interact. Have one more observation to add, but otherwise believe that is fairly thoroughly thought through now.\nThanks for the great collaboration!\nEDIT: Draft documentation updated for these suggestions.\n. @kristianhald I made a timing test harness also for the circuit breakers here: https://gist.github.com/reisenberger/92dc8d73b4df127b296ed8daee3ed93d\nThe results on my current development machine are here: https://gist.github.com/reisenberger/a6fab34402731333a61600dc0f06d7b0\nLater, we can use this for performance tuning, if/as necessary.  At this stage, the intent was to determine that the impact of using-versus-not-using CircuitBreaker or TimesliceCircuitBreaker (both are tested) was negligible compared to the other tolerances we have been discussing.  It is not a surprise to know this, but good to have it confirmed.  The impact of using either circuit-breaker is (on my machine) about 3 to 6 millionths of a second per call (if anyone wants to double check the code/calculation I will be happy!).  While other machines/servers etc may vary, this is clearly orders of magnitude different than typical network latency etc.  And orders of magnitude faster than the dimensions we are setting on slices/buckets/windows (important to know no interference there).\n[Results based on my original spike of the TimesliceCircuitBreaker; we should run this against the variants with buckets/windows also - but reassuring to know we are orders-of-magnitude insulated from interferance at mo]\nIf anyone can spot any thinking mistakes in the timing test harness, do shout!\nThanks\n. Addendum: my performance stats test only the synchronous versions of the circuit-breaker.  We should also test the async versions, as there'll be the extra async/await overhead.  It may be significant, but hopefully/probably not enough extra to touch the other configuration limits we have proposed.\n. @kristianhald Briefly re my previous comment:\n\nCan the operational code be done so that it doesn't look too messy / branching \ndepending on whether it's using further buckets/windows or not?\n\n(BTW, this was just a general thought - not based on any reading of the code). Thanks!\n. @kristianhald I now feel relatively clear on the effects of setting different parameters near boundaries, as follows.  \nfailureThreshold: Very low (eg 10%) will clearly cause the breaker to behave like a 'hair trigger', to break on almost the slightest error.  Very high (eg 90%+) will cause the breaker to break almost only on underlying system completely unresponsive - similar to the original Polly breaker, but with the added benefit of samplingDuration cut-off.  I am assuming users can deduce these self-evident effects of failureThreshold; in the interests of keeping documentation concise, don't plan to document.\nsamplingDuration: Low will hit circuit resolution (already documented). Proportional responsiveness of breaker means that high will cause slow responsiveness (already documented).\nminimumThroughput: Low will cause coarse initial throughput resolution (already documented). Propose code forbids the value 1; minimum permitted is 2.   @kristianhald A good observation where you alluded to the issue of possible miscalibration with minimumThroughput set high such that it might struggle to be reached within the samplingDuration.  Have documented this more generally as keeping minimum throughput away from typical throughput.\nEffect of buckets/windows versus not: I believe the effects are much as we have discussed, but - given the very low 200ms boundary, which few users are likely to work near - my instinct is keep things simple (thinking of the majority of users): state the boundary but not document elaborately.  Most circuits governing downstream network calls will likely be working in timescales (eg seconds), clear away from the boundary.  If higher frequency requirements emerge, we can refine as-and-when.\nAs a general comment: @kristianhald as you say, we cannot predict all ways that people will use the circuit-breaker.  And performance characteristics of the underlying actions in question (for example whether more sssssssssssssssfffffffffffffffffffffffff [or] sssfsffsffsffsfsfssf) will also be a significant factor in the interaction between configuration and results.  I think it is to be expected that users using a circuit of this sophistication (and with sufficient throughput to merit such a circuit) should expect to have to engage in some performance tuning in light of the real-life characteristics of their given system, and those characteristics are not something we can predict.  However, we can warn users away from configurations which we know are likely to give unhelpful results.\nThis is my summary of configuration characteristics I see as worth documenting.  Is this missing something major, some more complex interaction?\nEDIT: To take the documentation away from too abstract discussion, I may add a 'suggested typical starting configuration' for downstream network calls.\n. @kristianhald Re:\n\nupdated my fork with some additional features\n\nThank you for this extremely productive contribution!  Hoping to review and then we can pull this together for release very shortly (keen altogether to get this feature out this week or next, due to other commitments) (just need find time to review :smile: ).\n. @kristianhald \n\nthe part about configuration recommendations for the sampling duration requires some thought [...] \nbeginning [...] with suggested configuration [...] then more detailed information later \n\nCompletely agree!  Will adjust ...\n. @kristianhald Merged your work on RollingHealthMetrics to my local fork.  Thanks for the great contribution!  \n@kristianhald @joelhulen Remaining to do (on my side) before this ready to PR against master:\n- minor tidies\n- rename TimesliceCircuitController etc to preferred terminology\n- remove breaker implementations (proportion, frequency) not currently intended for release\n- add readme.md doco [brief]\n- yaml etc\nHopefully in the next day or so ...\n. @kristianhald  To offer some commentary on final decisions taken on previous points you raised:\n\nAt the moment the decision on using [RollingHealthMetrics and SingleHealthMetrics] \nis happening in the controller\n\nLeft this where you had it.  Encapsulates the concern.\n\non my machine there goes about '10000' ticks per millisecond\n\nSee const TimeSpan.TicksPerMillisecond\n\nafter a bit of thought, I came to the conclusion that it did not make sense to open the circuit \non a success even if the failureThreshold has been reached\n\nI reviewed and agree with this.  Breaking on a success seems counterintuitive.  The circuit may have 100% recovered for now (sssssssssss...), in which case breaking would be counterproductive.  If the circuit hasn't 100% recovered and is still intermitting (ssfsfsfsfsf), circuit will receive a failure soon enough within the same period, to break on.\n@kristianhald Please feel free to review the final changes to  https://github.com/reisenberger/Polly/tree/CircuitBreakerSpikeMarch16 if you have an interest.  I intend to PR this to master later today.\n. > what is the procedure for nuget packaging the master branch?\nMerging to App-vNext/master (and earlier, creating the PR against it) automatically runs an AppVeyor verification build.  We could push packages to nuget automatically on merging any PR, but opt to push them to Nuget manually.  (Manual gives us the ability to occasionally merge PRs (eg readme doco fixes) without pushing a package and bumping rev number.)\n@joelhulen owns this process, and can correct me if any of that is wrong / out of date.\n. @kristianhald PR to master in process.  Thanks for your awesome contributions to this feature in code and thought.\n. A further post to this closed issue just to document an issue that was discussed between @kristianhald and @reisenberger during merging down on to @reisenberger's fork.  This post copies parts of the discussion from there (https://github.com/reisenberger/Polly/pull/1) in case that is ever lost:\n[The issue has no bearing on the operation of the v4.2 AdvancedCircuitBreaker (proved by unit tests), but would come into play if the Polly AdvancedCircuitBreaker were to want to evolve to emit health statistics at regular intervals.]\n@reisenberger wrote:\n\nHey @kristianhald. Here is a conceptual issue. I observe that, from our implementation, the \nwindows we create within the timeslice are not necessarily adjacent. For instance, imagining \nwindows of size 1, if the first action records at t = 0, and the second action at t = 1.5, we will be \nrunning two windows from 0->1, and 1.5->2.5, with a 0.5 gap in between them. Reasoning \nsuggests this has no effect on the statistics, as the gaps only represent 'empty' times with no \nresults.\nI considered an outside case: imagining windows of size 1 in slice size 10, we could have a window \nat t = 0 and another at t = 9.9, this latter in theory extending +1 to t = 10.9 ... Again, reasoning \nsuggests that if any statistic comes in at t >= 10, the t = 0 window will be dropped, so at no point \nwill we be considering statistics for a period >10. However, it might be nice (for regression value, in \ncase anyone refactors...) to have a test proving this.\nIt looks like this could be done by duplicating the test \nShould_not_open_circuit_if_failure_threshold_exceeded_but_throughput_threshold_not_met_before_timeslice_expires__even_if_timeslice_expires_only_exactly()\nand adding SystemClock.UtcNow = () => time.Add(timesliceDuration.Subtract(TimeSpan.FromTicks(1))); just before the third exception? \nWould this cover it? It should cause it to create a new bucket which overlaps into the following \ntimeslice ... but the t = 0 window should be dropped when the fourth exception comes in?\nIn general: Do you agree that the non-adjacent windows issue has no effect on statistics, or am I \nmissing something?\nPerhaps controversially, my first instinct is not to code to make windows adjacent before merging. It \nadds complication and doesn't add anything to solving the problem at hand. Following the mantra \n'Keep the code as simple as possible to deliver the job needed', we don't need to correct for this, \nand the current creation/disposal of window code reads intuitively. However, there would be future \nscenarios (eg emitting regular statistics, as Hystrix does) where it would become important. And \ninterested in your thoughts...\n\n@kristianhald : \n\n@reisenberger Don't have such a test and I believe that you are correct that we should have one to \nensure that it works as expected. I think that the test would ensure the outer case is valid.\nI will add it immediately.\n\n[this test was added and proves correct operation of the current statistics]\n@kristianhald : \n\nI am under the impression, like you state, that as long as we remove buckets/windows that are \nolder than Now() - timesliceDuration then it will not have an impact. Also I felt that the \nimplementation would be smaller and easier to read.\nDid a little thinking and it might actually be quite easy to add the logic for adjacent \nbuckets/windows.\nIf we need the buckets to align adjacent to each other, then I think that the easiest solution would \nbe to decide on a 'start time' (maybe construction time of the class or just zero) and when we \ncreate a new bucket, we move the 'StartedAt' timestamp backwards in time to where the bucket \nshould have been created.\nLets take the following scenario:\nStart time: Could be decided at constructor time or just be zero (Beginning of the universe \n:smile_cat:). Lets say it is 23 seconds (from when the universe began).\nBucket/Window duration: 0.7 seconds\nAt the current moment in time, DateTime.Now() reads 26.457 seconds and an error occurs.\nFrom 23 seconds and forward until 26.457 the buckets StartedAt reads:\n23, 23.7, 24.4, 25.1, 25.8, 26.5\nAs the 26.5 bucket is in the future, then this cannot be created. Therefore the bucket we are in is \n25.8. The question is then, how do we get from 26.457 to 25.8 without having to create all buckets \nfrom 23 seconds. The answer (I think :smile:. Just throwing a quick idea here) is the following \ncalculation: StartedAt = Now() - ((Now() - StartTime) MOD BucketDuration)\nIf we take the above numbers we should get:\nStartedAt = 26.457 - ((26.457 - 23) MOD 0.7)\n= 26.457 - (3.457 MOD 0.7)\n= 26.457 - 0.657\n= 25.8\nIt will still have empty buckets as holes, but it should align the buckets to each other.\nQuestion: Would aligning the buckets actually solve the statistics issue?\n\neg emitting regular statistics, as Hystrix does\n\nWhen you say 'regular' do you mean bucket/window duration regular, every 1 second regular or a \ndelegate call, when an event occurs (Success or Error)?\n\n@reisenberger: \n\nAt regular intervals (every call = too frequent). But the frequency of emitting these statistics would \nabsolutely be aligned to either timesliceDuration or windowDuration. Definitely don't want some \ndifferent system of timing to interact with ;~) Vague memory, Hystrix emits stats at one of these \nintervals I think.\nOptions for adding this (later) to Polly:\n+emit a HealthMetric when dequeueing it from front of the queue;\nOR (more timely, fractionally more code)\n+emit a metric when it ceases being the _current\n\n.\nThis essentially documents the issue, tho there is further implementation discussion at \nhttps://github.com/reisenberger/Polly/pull/1.  \nImplementation would be as @kristianhald suggested with:\n StartedAt = Now() - ((Now() - StartTime) MOD BucketDuration)\nAn alternative could be:\n StartedAt = Now() - ((Now() - StartTimeOfLastBucket) MOD BucketDuration)\nbut this opens up complications across a circuit reset, when there isn't a last bucket.\n. Noting against this closed issue for future reference, possible optimisations that could be made in the AdvancedCircuitBreaker implementation in future:\nAny optimisation decisions should be driven by need, and by running before-and-after performance stats, for example with the test harness here: https://gist.github.com/reisenberger/92dc8d73b4df127b296ed8daee3ed93d\nCurrent performance: \nPerformance analysis of the AdvancedCircuitBreaker across one-hundred-thousand (100000) iterations, including frequent circuit-breaking, suggests introducing the AdvancedCircuitBreaker costs around 30 ticks (3 millionths of a second) per call.  Performance for the original Polly CircuitBreaker broadly matches.  \nPossible optimisations:\n[a] Replacing the use of Queue with an internal fixed-size array we manage ourselves.  While this has little benefit in itself (the implementation of Queue is backed by a similar array...), it may open up [b].\n[b] Avoid the generation (and subsequent garbage-collection once out of scope) of HealthCount instances.  This could be done by retaining a fixed set of instances ourselves, in an array [a] we own, and blanking-and-reusing existing instances rather than letting them go out of scope and creating new.\n[c] Maintain a running total of successes/failures across the timeslice, rather than re-summing it each failure  (to be checked by performance analysis whether this optimises or not; it\u2019s swings and roundabouts; the change would add a ++ to each success/fail; avoids larger summing each fail)\nEDIT: As stated, it would have to be measured whether these optimisations add value.  However, they are all items which Hystrix optimise away for their high throughput implementation.\n. Closing due to lack of activity.\n. @pawepaw . This is easy to do already with existing Polly.  A circuit breaker policy rethrows the exception - or a BrokenCircuitException (with the triggering exception wrapped as InnerException), if the exception triggers breaking the circuit.  So:\ncsharp\ntry\n{\n    circuitBreaker.Execute(() => Action());\n}\ncatch (BrokenCircuitException)\n{\n    // Add actions on circuit-breaking here\n}\ncatch (Exception e)\n{\n    // Add actions on exception here\n}\n. @nedstoyanov In #56 I have another issue that might move things towards cancellation support\nWe also think cancellation support would be a valuable addition. Exponential back-off retry (eg after 1, 2, 4 seconds; or even 5, 10, 30) is wonderful, especially in a machine-to-machine/service-to-service environment, where eventual consistency is acceptable, and eventual success (even after quite generous delays) is far preferable to faults to be manually troubleshot later.  However, the lack of cancellation support makes it hard to conduct a graceful shutdown of such retries.\n. @joelhulen Some starting thoughts / a possible spec around cancellation support. Keen to hear others' views.\n[1] All types of asynchronous retry policy should support cancellation.  In respect of retries, cancellation should prevent further retries commencing, if the delegate being ExecuteAsync()d throws.  For WaitAndRetryAsync(), cancellation should also interrupt the Task.Delay.  All retry policies should also honour cancelled-before-first-try (I believe this is .NET framework approach - don't even start a Task if it's cancellation token is found cancelled, on entry)\n[2] Should synchronous retry policies support a CancellationToken?  CancellationToken exists for .NET4, so cancellation could conceivably be added for .NET4 versions of synchronous retry policies.  However, would lead to divergence in the synchronous API between .NET3.5 and .NET4+. Perhaps conceptually simpler (including for understanding of the product) to limit/align cancellation support to async?\n[3] Specifying that a retry policy should observe a cancellation token, probably forms part of the retry overload signature?, eg\nvar cancellableRetryPolicy = Policy.Handle<WhateverException>.Retry(3, myCancellationToken)\n[4] actions being ExecuteAsync()d obviously often support a CancellationToken too.  But there's possibly no need for Polly to get involved with that (eg with extra ExecuteAsync() overloads), can leave cancellation tokens to be captured by implicit closure, to reduce Polly interface surface, eg:\nCancellationToken cancellationToken = ... \nvar retryPolicy = Policy.Handle<Whatever>.WaitAndRetryAsync(new[] {\n                   1.Seconds(),\n                   2.Seconds(),\n                   4.Seconds()\n                }, cancellationToken);\nvar result = retryPolicy.ExecuteAsync(() => httpClient.GetAsync(url, cancellationToken));\nViews on all the above welcome!\nI sketched an implementation roughly along these lines yesterday while commuting, but the meat of the work implementing (and tests) depends on what of #53 or #56 is merged first.  Also v happy if anyone with more time than me, or App-vNext, want to do this ...\n. Thanks @nedstoyanov.  Apologies for delay in replying: AppvNext have asked me to come onboard the project team and help respond to issues, pull requests, and forward-plan, and we've been reviewing the various requests (I\u2019m co-ordinated v closely with @joelhulen and the rest of the AppvNext team on all this).\nAt the moment the plan is to get #53 merged (thanks @yevhen), then come to this, cancellation support.  @nedstoyanov , I would suggest hold off at the moment on any work on this, as I have second thoughts/doubts now about parts [3] and [4] of the above proposal, and may post on this in the coming days.\nCommunity shout: If anyone has specific Use Cases to describe for cancellation support or ways they'd like to see it work, please comment in this issue.\n. @nedstoyanov Just to let you know that I have taken on the coding of this (async cancellation support) (I became aware of a number of potentials 'gotcha's while thinking it through, explored thru coding, and now half done).  However, it would be great to have your review / input / comment when I post the Pull Request!  (eg if meets your needs, is as you envisaged) (or indeed contribution on other issues)\nIntend to get to this early in the new year.\nThanks.\n. I have now committed an implementation of this to a branch reisenberger:AsyncCancellationSupport3, diff viewable as: \nhttps://github.com/App-vNext/Polly/compare/master...reisenberger:AsyncCancellationSupport3\nIf anyone gets the chance to review this ( @nedstoyanov from your original interest? ) ( @yevhen from your heavy previous involvement in the async code? ) , any review input gratefully received.\n@joelhulen I'll pull request this in a few days pending any comments.\n.\nCompared to my 4 Dec proposal above, the final implementation adopts the following decisions:\n[1] as before\n[2] cancellation support for PCL and .NET 4.5 async only\n[3] specifying an execution which honours cancellation now forms part of the call to ExecuteAsync(...), not policy configuration.  This aligns with the recent continueOnCapturedContext implementation, and more cleanly separates policy configuration concerns from action execution concerns.  You can configure an async policy of whatever type.  Separately, you can run individual actions through that policy either with cancellation support, continueOnCapturedContext, or not, according to the needs of the delegate to execute.\n[4] Because supplying the 'cancellationToken' is now part of ExecuteAsync(...), the safer explicit capture (rather than implicit closure) was preferred to support delegates which in turn can honour a cancellationToken.\nExample syntax:\ncsharp\n// Try several times to retrieve from a uri, but support cancellation at any time.\nCancellationToken cancellationToken = // ...\nvar policy = Policy.Handle<Exception>().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10) });\nvar response = await policy.ExecuteAsync(ct => httpClient.GetAsync(uri, ct), cancellationToken);\n. @gramanero This seems like a strong idea for the reasons you mention (ability to tweak policies in production without recompiling and redeploying code).  AppvNext are planning to look at a longer-term roadmap, and I will place this on the table for discussion.  If you do develop / are continuing to develop any complete sample in this direction, do let us know - open source projects depend on contributions from the community to implement all the available ideas!\nMy instinct would be for (as you suggest) a separate NuGet package.  \nIf you are already developing this in any way: I saw that Ian Cooper's Brighter / paramore project https://github.com/iancooper/Paramore already uses a string-name-identified registry of Polly policies.  Don't know if there might be any mileage in contacting that project to see if they are interested in this feature too? (possible collaboration / or could be developed in a way that would fit them). (NB no idea if they may or may not be interested - no prior contact with them - just a thought).\nThanks.\n. @gramanero Thanks!  Is the nuget package you use for this something you would be happy to share details about?  (I couldn't find anything obvious...)\n. Hey @gramanero, great to hear you are interested in contributing.\n@joelhulen My take on the packaging is also to keep the package separate.  Alternate configuration methods (this, or by attribute #87) feel like 'add-ons' with a distinct boundary; some users will love them [we could use this in my org :smile: ], but others will have no interest (not want to config their policies that way), and not need this in the main package.  By keeping them separate, we reduce the complexity of the main package (including of overload options presented to users).  However, open.  Do you have views?\nSeems like a first decision worth resolving, as affects whether we / @gramanero establish a new repo, or fork from the existing Polly.  (Although we cld still switch this decision later in the dev process.)\n. Hey @gramanero . I think a next step (if you happy) would be for you to upload a copy of the code you have to some repository on https://github.com/gramanero . The Polly team can then get sight of the code and we can explore together the best way to structure an adjunct to Polly.\nOne aspect on my radar is that there may be some beneficial overlap with #87 (apply policies from attributes).  I'm wondering if the configure-policies-from-config approach perhaps has elements of [i] extract, [ii] store and [iii] apply.  #87 probably also needs some kind of [ii] store ('Policy Registry'?), and is a method of [iii] applying.  \nWe might (speculating here...) eventually end up with something like separate packages Polly.Config, Polly.Registry, Polly.Attribute (of which people pull in the bits they need) ... But speculating - hence, a useful first step would be to see any existing code, then we can begin to reason about the best way to structure this.\nThanks!\n. Hi @gramanero All sounds great (agree w your naming suggestions).  No pressure at all about timing - we all have other things on - and no shortage of other things in dev w Polly at the mo anyway. :smile_cat: \n. @pvmraghunandan Great to have your comments! - parallels a lot of the thinking at App-vNext.\nYes: a general PolicyRegistry class or similar could take input from any number of pluggable sources: config files; json; whatever...\nAs your comment suggests, though, configuring anything involving a lambda from flat config files, at runtime, would be hard.  That includes predicates specifying what exceptions / results to handle (beyond more-or-less-simple matching); and any of the lambda state-change delegates that policies can also take: onRetry, onBreak, onReset etc.  \nThere are also some arguments around whether it is a good idea to allow the reconfiguration of what a policy handles at runtime  ... think fragility risks from unexpected emergent behaviour (Somebody changes the config so the app stops handling a certain exception during runtime: what's the effect on the downstream code? etc). ... And how does this play with testable code? ... not impossible, but a number of questions around.\nWhere configuration-from-config (and reconfiguration-without-redeploy) could really shine, though, is in re-configuring the numeric parameters of policies.  I see a major benefit to be able to tweak, on the fly, in production, the trigger thresholds and break durations of circuit-breakers, the delay between retries etc, according to real-world behaviour.  This could be achieved by pulling the numeric-parameterisation parts of each policy out into a configuration class, which could be injected (to update the policy) at any time.  Perhaps where we should focus our efforts first on this feature?\nIn sum, I'm starting to see this (and the related #87) proposal perhaps emerge into two separate (potential) features:\n[1] the ability to reconfigure the numeric parameters of (all) policies at any time (with perhaps some plugins/separate projects/packages demo-ing how to do this from configs, json etc)\n[2] a PolicyRegistry for those who want to maintain a bank of (named) policies in a Registry, perhaps applying them by attribute as @eaba suggested (but without the suggestion at this stage that we can configure every aspect of the policies in the Registry from config)\nThoughts, anyone?\n. > we are thinking to provide some sort of configuration like \n\n{Type, PropertyName, PropertyType, Accepted Values}. \n\n@pvmraghunandan Was this with the types and properties of exceptions (or results) handled by the policy in mind? \nIt's likely that the core Polly team wouldn't have time to look at this for the next couple of months, by the way, while the focus is on the new resilience features.\n. Noting that @brunolauze also had good proposals for this here. Closing as duplicate of / in favour of the similar ideas in #143. @SamuelEnglard Do you want to push that local clone up to your remote, so that we can view? (can't find on your remote).  \nDilemma is getting sucked into chasing a moving target with .NET Core/Standard while the tooling is still in such a state of flux, and that spannering work for weeks on the other features on the Polly Roadmap. Maybe (hopefully :pray: ) in only just couple weeks Microsoft will come out w/ a clear direction and more settled version of tooling.  OTOH, we appreciate ppl want to get on w Polly in .NET core/standard.\n@SamuelEnglard Certainly happy to look at what you've done and see if we can find quick win?  I can :eyeglasses: over the tests.\n. > @reisenberger should I make a proper pull request?\n@SamuelEnglard Hang fire on a new PR just now (tho thanks).  I am hoping to release Polly 4.3.0 (delivering #14) in the coming week; and we may get some new/changed tooling from Microsoft over next few days too.\n. @SamuelEnglard I expect your test failures are around tests which manipulate properties on SystemClock?  Because this is (currently) a static in the Polly design, tests cannot be run in parallel.  Add [assembly: CollectionBehavior(DisableTestParallelization = true)] to the relevant AssemblyInfo.cs and you should clear the test failures. \n@SamuelEnglard @mattwoberts I am currently preparing a Polly pre-release nuget package supporting .NET Core (following your start @SamuelEnglard; thanks @SamuelEnglard !).  Good progress.  Seems good in VS.  Just working @joelhulen on getting the cake build to run the new .NET core tests, so that we can have a fully mature CI process around this.  @SamuelEnglard @mattwoberts it would be great if you could test the nuget package in (hopefully) next few days.\n.NET Core RTM 1.0 from Microsoft Mon27 didn't add any new tooling, so this is all still project.json-based - which of course is deprecated and will (later) go away.\n. Closed in favour of #132.  However, thanks to @mauricedb for his early work on this, shining the light on many of the issues which are still relevant as .NET Core goes RTM.\n. @jabaran Thank you very much for this suggestion - events on circuit state change could be a valuable addition to circuit-breaker for other reasons too - for example for performance and health monitoring.  The AppvNext team (new stewards of Polly) hopes to turn its attention to circuit-breaker shortly, so watch this space!\n. @jabaran A very valuable idea, not least for those (including my own team) who may wish to log - or raise more intrusive alerts to DevOps - on changes of circuit state.  Thanks for the idea.  PR coming, including this, shortly.\n. @jabaran See the full documentation now for the new circuit-breaker features at: https://github.com/App-vNext/Polly/wiki/Circuit-Breaker\nNote that the onBreak, onReset and onHalfOpen delegates execute (necessarily) within locks held by the circuit-breaker - see the detailed documentation for greater detail.  For this reason you (naturally) do not want to execute too long blocking actions during these delegates.  However, it is intended that usages such as you originally requested should work.\n. @yevhen Looking at your PR, I see (only now...) that you have also tackled async sleep as await Task.Delay as part of this PR on captured ctx, same as I have raised in #56.  I have done it slightly differently, but same underlying principle.  Will be happy with whatever Polly community want to integrate. Think this is an important fix.\n. @yevhen @joelhulen On the subject of all those overloads (agree), it might be worth some forethought - if we are going to introduce both bool continueOnCapturedContext, and CancellationToken cancellationToken (ref #46) - on what priority order we want the parameters to run in.\nIn the retry overloads in this #53, @yevhen @joelhulen (see snip below) ... \n\n... I like the order in RetryAsync(...) and RetryForeverAsync(...) (it seems logical that bool continueOnCapturedContext comes after how many retries but before Action onRetry ... ).  But, for WaitAndRetryAsync(...) I would suggest bool continueOnCapturedContext should come after Func<int, TimeSpan> sleepDurationProvider or IEnumerable<TimeSpan> sleepDurations.  The how-long-to-delay-for is core to expressing WaitAndRetryAsync(...) and should come right near the (.  This would also place overload parameters in a consistent order for all retry variants:\nhow many times / with what delay to retry,\nwhether to continue on captured context,\naction on retry\nIf/when introducing CancellationToken could then be expanded to:\nhow many times / with what delay to retry,\ncancellation token,\nwhether to continue on captured context,\naction on retry\n(or cancellation token / captured context in the other order)\n. @yevhen Thanks for this great contribution; we're looking to get this merged soon.  \nRe overloads I can see three options, not sure if any quite come together (tho if anyone can see a bright way through this conundrum, please shout)\nOptional parameters: Would be ideal (my preferred) if it weren't for the caller/call-ee problem in how this is implemented in C#.  IE if we later have to change signature, can cause run-time failure if people just drop in new DLL rather than recompile against.  Believe why most of .NET framework doesn't use optional params.\nT4: Slight concern about introducing something lesser-known which may raise the barrier of entry for other contributors.  Also, does this just help with documentation (eg xml comments)?\nParameter object: Problem I can see is there's already the optional onRetry parameter.  If we move that into a parameter object, it'd be a breaking change :cry:.  If we don't move it in to a parameter object, some of the optional parameters will be in a parameter object and some not  :disappointed: .\nAlso, .RetryAsync(int, new RetryAsyncOptions(CancellationToken, bool), Action) not necessarily more concise when calling than .RetryAsync(int, CancellationToken, bool, Action)\n.\nOpen to views, but it may be the overloads are just something we're going to have to live with, rather like Task.Factory.StartNew() in the framework\n. @yevhen Thanks again for this important PR!  Unless anyone has brighter idea on overloads, team AppvNext are ready to accept/merge.  \nAre you able to update the PR with the following minor adjustments? - then it will be good to go!\n- resolve conflicts by rebasing against latest master\n- fix overload not using bool continueOnCapturedContext mentioned few days ago\n- adjust bool continueOnCapturedContext parameter position per discussion few days ago and a few more line notes I will add\n- update changelog.MD to describe change (but not GitVersionConfig.yaml; @joelhulen will update yaml when pushing to Nuget)\nThank you!\n. ( @yevhen / all, apologies, and thanks, for bearing with flurry of line notes ) ( as you rightly say, yevhen, large number of overloads ...;)  \nBut purpose: If we fix parameter order appropriately now, the cancellation support #46 can be built right around this without any breaking changes to the API between releases\n. Hey both @yevhen @joelhulen .  While on this, I spotted a couple of awaits that possibly weren't yet configured with the new (great) bool you're adding yevhen (ie what context the continuation runs on).  I think it was the awaits on the calls to CanRetryAsync() and SleepAsync().  Do you think/agree that we want to control the continuation context there also? (ie propogate configureawait() control via the new bool to those calls also?) In order to configure the awaits everywhere, ie to make the context after the awaits completely deterministic throughout the Polly library.  \nCould there be a risk, for example, that a retry runs on a different context from the original try? (which might not help you MS Orleans scenario, yevhen?), if we weren't controlling  CanRetryAsync() and SleepAsync()?\nI found a great plugin for ReSharper that helped me find these: https://github.com/aelij/ConfigureAwaitChecker - but you can find/install it via the PlugIns library on ReSharper of VStudio.\n(I was using the same plug-in when exploring issues in the possible cancellation code)\nShout if I'm not making sense or you think this is wrong - in haste with this comment as I need to be elsewhere!\n. @yevhen @joelhulen Super: it was my absolute assumption that we would want to be completely deterministic about this across the library, but wanted to involve you guys.  \n@yevhen : those two:\nif (!(await policyState.CanRetryAsync(ex)))\n/\nawait SystemClock.SleepAsync(currentTimeSpan);\n... appear to the only two not currently controlling the synchonization context (.ConfigureAwait()) via the new bool continueOnCapturedContext.\n. I've seen cr/lf oddness too but don't know the setting - over to @joelhulen ? - would be good to iron this out.\n. Apologies - more thoughts coming on this:\nBecause of the way the codebase has evolved (see end of post), we now have / are working towards a number of constructs in the codebase like / effectively equivalent to:  [+]\nif (continueOnCapturedContext)\n   await action();\nelse\n   await action().NotOnCapturedContext();\nor\nif (onCapturedContext)\n   return await task;\nelse\n   return await task.NotOnCapturedContext();\nCan these not just be shortened to await task.ConfigureAwait(continueOnCapturedContext) ? \n(It could also have the advantage of explicitly configuring the await either way - it probably makes no practical difference in the current .NET implementation, but may be clearer to subsequent code readers what is going on.)\nThe history of this in the Polly library was:  (from memory- could be wrong on some detail) \n- Async implementation was initially added, without (I think; cld be wrong) code controlling continuation context, ie plain await Task \n- Contributors then logically requested the addition of .ConfigureAwait(false), as is standard for library code, particularly if library code shouldn't care about sycnhronisation context.  This was abbreviated to nice extension methods .NotOnCapturedContext(this Task task) etc.\n- But since the point of Polly is to run delegates (wrapped in some way), we might sometimes need to control the synchonisation context the delegates run on - hence yevhen's contribution.  We can see why, built on the existing .NotOnCapturedContext(), this leads to patterns like [+] above, but I'm wondering if we can now shorten to the much more direct await task.ConfigureAwait(continueOnCapturedContext); ?\n(with apologies again for late additional realisation ... what do you guys think?)\n. @yevhen Thanks for your exemplary clear presentation! (a standard for us to follow :smile: ).  Have been a good second pair of :eyes: and @joelhulen  looks good to go to me!  Many thanks yevhen for tracking all that detail...\n. Thanks @yevhen .  Cancellation support (#46) coming shortly (I've been working on it in background), which should round out the async support in Polly nicely. :wink:\n. Hi @DennisNerush Many thanks for the idea here and your interest in the Polly library!\nPolly does not currently maintain an internal list of the policies which have been created.  I would be reluctant to recommend adding this, because it could constitute a memory leak.  At the moment, if somebody codes Policy.Handle<Whatever>().Retry().Execute(...) (or similar), the single-use policy created is, in due course, garbage-collected.  If otoh Polly were maintaining some static/thread-safe list of all policies created, single-use policies would not be garbage-collected and (think high-volume scenarios) could eventually constitute a memory-leak.  Therefore recommending this one as 'wont fix'\nThere is nothing of course to stop library users holding references to created policies themselves (var myPolicy = Policy.Handle<Whatever>().Retry();)\nRegarding the ability to reset a circuit-breaker policy, this seems like a valuable addition for other reasons too (eg for operational control); keeping #62 open to track that.\n. UPDATE: I now have an implementation for WaitAndRetryAsync(...) using the non-blocking await Task.Delay.\nWill aim to post the solution to a Polly fork on my github in the next few days, in case anyone else facing same problem (and for feedback).  Before posting, want to produce a small console app to prove/demonstrate that the expect benefits in thread consumption are being realised.  \nCan Pull Request this as soon as new stewardship for Polly in place.  \nIt should make WaitAndRetryAsync(...) more async-friendly and potentially much more efficient on the thread pool.\n. @joelhulen, all. See github gist https://gist.github.com/reisenberger/48b4e8e0102d0d0f6290 for small console app which demonstrates the thread starvation caused by blocking WaitAndRetryAsync(...).  (Obviously to be assumed on seeing Thread.Sleep in async implementation, but console app provides clear demo  - and allows us to check fixes bring expected benefits.)  Run console app against current implementation to see thread starvation. Run against a fix with await Task.Delay (eg @yevhen's #53) and thread-usage/elapsed time is as expected.\nI have a local fix too, can make into pull request, but wanted to align it with @yevhen's #53 first, for easier onward merges.  Or we simply merge #53  ...?\n( @joelhulen will comment further on .NET versioning of library another time )\n. ( @joelhulen thanks for your stewardship, great to see this all moving)\n. @joelhulen At https://github.com/reisenberger/Polly/tree/AsyncSleepExperiment have committed a branch had been using to experiment with substituting await Task.Delay for Thread.Sleep in RetryAndWaitAsync()\nAt https://github.com/reisenberger/Polly/tree/AsPR53AsyncSleepTaskDelayOnly I have committed a branch taking the async-sleep elements only out of @yevhen's PR #53, just so that the async sleep elements can be seen clearly separately.  \nBoth branches, if run against my gist console app (see earlier in thread), show the thread starvation problem fixed.\nI would recommend merging @yevhen's version as, while his and my version are effectively identical technically, @yevhen's presentation with the partial classes (and other factors) is clearer for onward maintenance.  It's the conditional compile thing as @mauricedb  says, but yevhen's presentation is neat.\nYou could (if happy) either merge #53, or merge from https://github.com/reisenberger/Polly/tree/AsPR53AsyncSleepTaskDelayOnly to get the async-task-delay bit only.  If merging from reisenberger/Polly/tree/AsPR53AsyncSleepTaskDelayOnly, credit for this should go to @yevhen (don't know how to do that fancy github magic like \"Person X committed with Y\" to credit it ;~)\n. Closed via #53 \n. @monotore @joelhulen My reading of the Polly codebase is that Policy instances are thread-safe.\n@joelhulen, your team might want to verify this for yourselves independently (see if you agree...), but my reasoning:\nRetry policies: Use an underlying instance of IRetryPolicyState to maintain retry state (eg number of retries made).  However, each call to someRetryPolicyInstance.Execute(...) uses the Func<IRetryPolicyState> policyStateFactory to make a new, private instance of the relevant IRetryPolicyState implementation, so retry state data for different calls through someRetryPolicyInstance.Execute(...) is entirely independent (and hence thread-safe).\nCircuit-breaker policies: Multiple calls to someCircuitBreakerPolicyInstance.Execute(...) share (and must share) the same underlying ICircuitBreakerState, so that any exceptions thrown during each call to Execute(...) accumulate towards the (consecutive) total at which the circuit will break.  However, all manipulation and reading of the ICircuitBreakerState's state data is protected by locks making it thread-safe.\nHope this is useful.\n. New documentation of some example policy patterns has been added at https://github.com/App-vNext/Polly/wiki/Some-policy-patterns.  This covers:\n- re-using policy instances\n- thread-safety of policy instances\n- nesting policies\n. @DennisNerush [aside: I'm just another user very interested in Polly, not core team]\nWhat happens if the Policy is a retry policy type, and .Reset() is called? IE\ncsharp\nPolicy retryPolicy = Policy.Handle<Exception>().Retry();\nretryPolicy.Reset();\n@joelhulen Perhaps Policy abstract base class with derived types CircuitBreakerPolicy and RetryPolicy, if desired, to accommodate this?\n. @joelhulen There could be other benefits to explicitly separating out policies in to separate CircuitBreakerPolicy and RetryPolicy types.  Example: In our microservices implementation, for certain calls we allow callers to pass in the retry policy or circuit-breaker policy (but specifically one or the other) they want to use.  Because the Polly library at present does not distinguish the types, we cannot use Policy as a parameter type (people could pass in a circuit-breaker where a retry is expected...).\nIt's ended up in us having to wrap Policy in marker classes equivalent to what I've suggested (CircuitBreakerPolicy and RetryPolicy), these classes enforce the kind and re-duplicate the Polly interface for it but only pass all calls through to a relevant inner Polly.Policy - long-winded.  [should have PRd on this earlier!]\nHaving separate CircuitBreakerPolicy and RetryPolicy types  could allow library users to specify to expect / pass around instance of eg RetryPolicy type only, as well as build functionality specific only to either the CircuitBreakerPolicy and RetryPolicy type.\nIf you want, I can open this as a separate issue # for tracking. EDIT: Opened #63\n. @DennisNerush I've noted a few more potential complications with the separating out in #63 (although I think it's a good idea).  Stepping back now to let @joelhulen and team consider way forward, and/or @michael-wolfenden clarify. \n. Thanks @DennisNerush.  (Apologies for delay in replying - AppvNext have asked me to join the project team on this and we've been reviewing the various issues and requests.)  \nSuggest hold on any new PR for now, as we intend first (per #63) to have a broader think about where/how abstract base classes or interfaces might be introduced.  That is planned to follow fixes/enhancements to async retry (53, 46).  \nHowever, your idea to be able to reset circuit breaker state fits right in with other requests for manual control over the circuit breaker (eg ability to break it manually, for manual override; then likewise reset it). We plan to look at circuit breaker when the stuff mentioned above is in (may take until the new year), but it seems like a sensible feature, so: watch this space!\n. @DennisNerush We are making a PR that will implement your request here - thanks for the initial idea.\n. @joelhulen I've noticed there's a third kind, ContextualPolicy, that might need to be considered in this.  Need some time to read whether ContextualPolicy is a conceptually distinct kind.  Maybe it can only be applied to retry policies (these are the only kinds of usage in the codebase at present...), or maybe it's intended to be more general ... (unless @michael-wolfenden can save time with comment/ explanation on this).\n. It looks to me as if ContextualPolicy is only used for retry policies at present, but could conceivably be used for circuit-breaker policies too.  This could lead to an overall class structure (if desired) like:\nRetryPolicy : (abstract) Policy, IRetryPolicy\nCircuitBreakerPolicy : (abstract) Policy, ICircuitBreakerPolicy\nRetryContextualPolicy : (abstract) ContextualPolicy, IRetryPolicy\nCircuitBreakerContextualPolicy : (abstract) ContextualPolicy, ICircuitBreakerPolicy // although CircuitBreakerContextualPolicy isn't used yet, so might be better not to add yet. At the moment there are no callbacks possible from circuit-breaker policies, but if something like #52 were implemented (callbacks on circuit-breaker), then call-backs with added context might make sense.\n(and where IRetryPolicy and ICircuitBreakerPolicy are mostly marker interfaces)\nI notice also that there are also internal classes already named CircuitBreakerPolicy and RetryPolicy, which might want renaming, to avoid confusion in the codebase with the new intended public versions CircuitBreakerPolicy and RetryPolicy.\nI could code this all up and PR to demonstrate, if more useful.\nNB ContextualPolicy is new to me and not one I've used, so welcome comment if anyone knows better, tho the above seems to make sense from reading the codebase and documentation\n. @joelhulen Re:\n\nwould you be interested in joining the core team? \n\nThanks for the invite!  Could you private-mail me at software[at]reisenberger.net, for me briefly to get an idea what you have in mind / what would be involved? - and I can clarify for you what level input / commitment I might be able to bring.  Thanks! \u2013 Dylan\n. @penderi  Re ContextualPolicy and Policy not being possible to combine, if I have understood, the problem is that because they have no common ancestor or interface, you cannot choose a return type for SetRetryPolicy(...) which would encompass both: is that it?  If so, agree, and have noted similar in comments to #63. The proposal in #63 was fairly rapidly thought through (might want refinement), but hopefully, with the introduction of common abstract base classes or interfaces, this situation could be resolved for you.  eg the results of your original calls (currently returning non-combinable  ContextualPolicy and Policy) might return classes which both fulfil some new interface IRetryPolicy, giving a minimum baseline of some common Execute(...) overloads you could call from either return result.\n. @penderi  Regarding combining policies, yes, this is the way we have done it too.  For example, in a microservices environment publishing messages to a message broker like RabbitMQ, we are nesting retry and circuit-breaker with something like:\ncsharp\npublic Task TransientFaultProtectedPublishAsync(Func<IMessage, Task> publishAction, IMessage message)\n{\n    var retryPolicy = ... \n    var circuitBreakerPolicy = ...\n    Task messagePublishTask = retryPolicy.ExecuteAsync(() =>\n        {\n            circuitBreakerPolicy.ExecuteAsync(() =>\n            {\n                publishAction.Invoke(message);\n            });\n        });\n    return messagePublishTask;\n}\n(In reality it's decorated with a bunch of .ContinueWith(...) for error-tracking, and our policy instances are initialised/defined elsewhere, but this gives a clearer idea of structure)\n. Hi @videege.  Three thoughts: \n[1] The overload .Handle<TException>(Func<TException, bool> exceptionPredicate) allows you to specify a predicate to select in more detail the exceptions you want handled.  For instance, with:\nvar policy = Policy.Handle<ThirdPartyHttpException>(e => e.StatusCode == 503).WaitAndRetryAsync(...)\n... ThirdPartyHttpExceptions with 503 codes only would be handled by the policy and retried; other exceptions would be re-thrown without retries.\n[2] In your example, I would expect throw new ApiException() within the onRetry delegate to cause further retries to be aborted.  Is this not happening? EDIT for explanation: A policy handles exceptions thrown by the .Execute() / .ExecuteAsync() delegate, but exceptions thrown by the onRetry delegate propagate as normal.\n[3] We are intending shortly to add cancellation support for the async uses of Polly \u2013 see #46 (tho the spec may change slightly).  Various async overloads will be able to take a CancellationToken.  Cancelling the related CancellationTokenSource would also cause any further retries to be aborted - another (future) avenue to achieving this.\nDoes this help?\n. @videege . Cancellation support has recently been added for async Policy execution - for details, see readme on the Polly home page.  \nYou can also cancel a related CancellationTokenSource within an onRetry delegate, and further retries will be cancelled.\nIn your original question: what about throw new ApiException(\"Not Found\"); was not working as expected?  Is the scenario, that you are using the given Policy with .ExecuteAndCaptureAsync(), and were expecting / would like .ExecuteAndCaptureAsync() to capture the ApiException thrown, into the PolicyResult?\n. @yevhen Apologies that I did not notice this when we were working on #53.  I could not have seen this if it had not been for your original clear exposition of #53 - we are all standing on each other's shoulders - this is the beauty of open source collaboration!\n(Your #53 opened the path for me to add cancellation support; in doing so I saw this continueOnCapturedContext API optimisation, as the cancellation code does similar.)\n. Hi @jmattw42350 .  Many apologies, but I have not completely understood the question.  Could you perhaps explain in more detail, or show a code example of what you would like to see working?\n. @jmattw42350 : In Polly (as now), policy execution captures exceptions thrown by the delegate supplied to .ExecuteAndCapture(), ~~but does not capture exceptions thrown by the onRetry delegate. Exceptions thrown by the onRetry delegate propagate as normal, and so are not captured into a PolicyResult instance.~~  \nIs this related to your question?\n. @jmattw42350 : I believe I erred in my previous assessment that .ExecuteAndCapture() would not capture exceptions thrown by an onRetry delegate.  Those exceptions should be captured, but would be identified as ExceptionType.Unhandled in the returned PolicyResult.\nLet us know if we can help further with your original question (supplying a code example of what you would like to achieve may help my understanding)\n. Thanks @nedstoyanov !  I've opened that (just for clarity) as a separate issue #78 (although I agree it could relate).  I spotted this also while investigating #63 .\n. Hi @TrevorPilley.  \nBecause of the way the Polly execute methods are generalised, capturing the number of attempts into the PolicyResult is not that straightforward.  .ExecuteAndCaptureAsync(...) is agnostic to (and has no knowledge of) whether what is being run underneath is a retry policy, circuit-breaker policy without retries (or indeed some new kind of action-transforming policy in the future).\nAn approach in the meantime could be something like :\nint attempts = 0;\nvar policy = step.BuildExceptionPolicy();\nvar result = policy.ExecuteAndCaptureAsync(async () => { \n   attempts++;\n   //  ... \n} );\n@joelhulen : I suggest we leave this issue open for a while so that others can comment if they would also like additional execution metadata inPolicyResult.\n. @TrevorPilley.  I looked at this in more depth in the intervening week, and agree that this would not be as difficult to integrate into Polly as initially feared: the attempts++ approach could be pushed down to the core Polly codebase.  \nWe have also to consider how this would play in the context of both Retry and CircuitBreaker policies, but I think this could be ok. For CircuitBreaker, the PolicyResult.Attempts (or similar) property would just indicate 1 if the call was attempted, and 0 if it was not (due to the circuit being broken).\nDiscussing this one further with the core App vNext team, and hope to come back on this in the coming days.\n. Just updating thinking on this issue:\nCurrent conclusion: having set out the longer-term vision for Polly in the Roadmap, it became clearer that Retry was just one policy among a larger/growing set of eventual envisaged policies.  In that context, reluctant to add AttemptCount (which makes most sense for retry) to PolicyResult (which has to make sense for all policy types) at this stage.  \nIn particular, for the Polly Pipeline (functional composition of policies in a nested wrap), the possible meaning of AttemptCount is unclear at this stage in thinking: some policies in the overall Policy wrap might have attempted execution of their next-inner delegate, others not ... what would overall AttemptCount represent and how should it be interpreted?\nNot to say that this might not be added later - something like DelegateInvocationCount could still perhaps be useful as a 0 or 1 value for policies like Cache, ParallelThrottle - however, this will be easier to reason about once the wider range of policies is in place.\nEDIT: The attempts++ approach outlined in earlier post remains available.  And, many flavours of retry expose the retry count to an onRetry delegate, from which attempt count can also easily be derived.\n. Looking at this problem more broadly: We are looking more widely at ways Polly can expose information about how the Policy executed.  For example, all policies could emit events that could be observed as a Reactive Extensions event stream via Observable<PolicyEvent> or similar.  This would provide the ability for the various kinds of policy to emit events specific to their type \u2013 FallbackValueProvided, CacheValueProvided, TimeoutExceeded etc \u2013 as well as opening up wider possibilities for health monitoring and telemetry.  In this vision, PolicyResult retains its current focus on properties common to all types of Policy execution (success/fail outcome, last exception, result [for funcs]), while behaviour specific to individual policies can be emitted as observable events.\nThis could also open up a more generalised form of the add-AttemptCount-to-PolicyResult idea.  For example, maybe PolicyResult could include an IEnumerable<PolicyEvent> of all events which occurred during execution.  This generalised approach would work for all policy types, and could be mined for all sorts of data - how many attempts were made, was the cache used, etc etc.\nCommunity views on any of this welcome ... \n. @TrevorPilley Polly v5.1.0 just released now provides a way to do what you originally asked: define a policy in one part of the codebase, have the onRetry delegate of that policy do something (akin to attempts++), and access that in the PolicyResult returned by ExecuteAndCapture/Async(), in a completely different part of the codebase.\nThis is achieved in v5.1 by having all delegates used by Polly able to take as a parameter the Context flowing with each execution.  You can then manipulate any properties on the context:, eg do context[\"retries\"]++ in the onRetry.  Or define your own custom MyContext class subclassing Context and context.Retries++ directly.  The PolicyResult returned by ExecuteAndCaptureAsync() then exposes PolicyResult.Context.  Blogged more here.\nWhile we could have exposed public int Attempts {get;set;} directly on PolicyResult, this would have implied the limitation that only one retry policy could be used in a PolicyWrap.  In general, we wanted to reject the limitations imposed by a Hystrix-type approach where the structure of what can be used in an overall resilience strategy is pre-defined or has limitations in this way.  We chose with Polly instead to go for a fully flexible PolicyWrap, in which more than one retry policy might be used (for example to handle different exceptions differently) - which wouldn't have played with a direct Attempts property on PolicyResult\nThanks for the original suggestion!. Noticed this too - haven't found any new address to which the article has been moved - will remove link in due course.  Many thanks.\n. Thanks @maverix @joelhulen  !  \n@maverix @SurajGupta  / anyone else interested: The readme now also includes further CircuitBreaker articles from Martin Fowler at Thoughtworks, and the Microsoft Patterns and Practices team.\n. @alvpaz  Did you resolve this problem?  Do you require any further help?  (If not, we will close this issue soon, as the issue seems more related with how to use the WCF component than Polly.)\nThis link http://stackoverflow.com/questions/2763592/the-communication-object-system-servicemodel-channels-servicechannel-cannot-be seems to offer good advice.\n. May relate to #72; also noticed while investigating #63\nSuggest we fix this after #63 .\n. @nedstoyanov Very many thanks for your continuing involvement in Polly, and for your PR!  I am assuming this is an implementation for #24 \nI would like to recommend to @joelhulen that we incorporate this, if we can fix up a few issues first:\n[1] Can you consider adding async support, so that .WaitAndRetryForever() could launch for both sync and async?  There is a partial class pattern that should be easy to follow between RetrySyntax / RetrySyntaxAsync, RetryPolicyStateWithSleep / Async (see that for how to handle async sleep), WaitAndRetryAsyncSpecs (see for async test examples). The async tests tend to closely mimic sync tests, but with .RaiseExceptionAsync(), and policy.Awaiting( in place of policy.Invoking( . Let me know if you want any further guidance on this!\n[2] Can you consider int.MaxValue defence?  Maybe something as simple as if (_errorCount < int.MaxValue) _errorCount += 1;.  While it is unlikely a failing retryforever might reach int.MaxValue, as a library, we should probably defend.\n[3] Polly v4.0.0 published last night with new circuit breaker support; so (with apologies) you would need to rebase on latest.\nThanks again @nedstoyanov !  This is looking like a good implementation for #24 \n. @nedstoyanov re: \n\nshould we just stop incrementing once it reaches  int.MaxValue ? \nAlternatively we can return  false  from  CanRetry  but that won't really be retrying forever. \n\nLet's just stop incrementing once it reaches int.MaxValue.  It's better that retry forever, really means retry forever.\n. @nedstoyanov Many thanks! I will aim to review in the next few days.\n. Many thanks @nedstoyanov for your contribution!  I have been able so far to review the operating code (not the tests), and had only three small comments: \n- _errorCount += 1 needs defending against int.maxValue, within CanRetryAsync(...) of RetryPolicyStateWithSleepDurationProvider, in the same way as in CanRetry(...) \n- Please can the final overload in each of RetrySyntax and RetrySyntaxAsync, return a RetryPolicy rather than a ContextualPolicy\n- [minor] Please could all the new overloads in RetrySyntax and RetrySyntaxAsync indicate, in their <exception cref=\"System.ArgumentNullException\"> section, that an ArgumentNullException may also be thrown for sleepDurationProvider (sample style for multiple ArgumentNullExceptions in the similar WaitAndRetry overloads)\n@joelhulen @nedstoyanov After I have read the xUnit tests will comment further.\nMany thanks!\n. Very many thanks again @nedstoyanov for your contribution and PR!  Here a few things to do on test coverage, to make this good to go!\nBelow comments apply equally for WaitAndRetryForeverSpecs and WaitAndRetryForeverAsyncSpecs (action in both)\n- Should_create_new_state_for_each_call_to_policy() is not relevant for retry-forever policies - can be deleted. \n- Should_throw_when_onretry_action_is_null_without_context_when_using_provider_overload and Should_throw_when_onretry_action_is_null_with_context_when_using_provider_overload can be deleted; they duplicate the third and fourth tests. (In the WaitAndRetrySpecs model you may have followed, they were not duplicates because of the different possible ways of specifying waits.)\n- Can we add the test Should_call_onretry_on_each_retry_with_the_current_exception()?  Model to follow in WaitAndRetry/AsyncSpecs.\n- The test Should_not_call_onretry_when_no_retries_are_performed() does not amend in any way the retryCounts = new List<int>() collection, so the assertion retryCounts.Should().BeEmpty(); does not test anything.  Need to use the onRetry delegate to add something to the retryCounts collection on each retry, so that the final Should().BeEmpty(); has meaning.  See good example in RetrySpecs.  (This issue also exists in the versions in WaitAndRetry/AsyncSpecs, which you may have followed; feel free to fix it there also if you want.)  \nOn the async tests:\n- Place WaitAndRetryForeverAsyncSpecs in same namespace as other tests, Polly.Specs\n- We ought to add the tests on CancellationToken support.  These can follow exactly the form in RetryForeverAsyncSpecs: we need all tests from Should_execute_action_when_non_faulting_and_cancellationtoken_not_cancelled() to the end of the file.  Just substitute .WaitAndRetryForeverAsync(provider) for .RetryForeverAsync(), and these should be good to go!  \n@nedstoyanov, Very many thanks again for your contribution!  One of the strengths of the Polly codebase is the thoroughness of the test coverage; but we appreciate this does mean adding a lot of tests when adding a new policy (as you have done). So - thank you for your persistence with this!   Let me know if you want any assistance with the above \u2013 or if you have questions.\nMany thanks!\n. @mgj Good to hear ;-)\n@nedstoyanov No problem.\n. @nedstoyanov, Many thanks for your contribution! - and also for fixing up the WaitAndRetry/AsyncSpecs.  All looks good to go!  AppvNext hoping to push this out to Nuget as v4.1.0 in the next 24-48 hours.  :+1:\n. @mfjerome, Thank you for the valuable suggestion.  You will see that this has now been incorporated in the Roadmap in a more general form - we think this could be used not only for CircuitBreaker.\n. # Proposal: Fallback policy\nPurpose\nTo provide a fallback result or fallback delegate to be executed, if a handled exception is thrown or handled result returned. \nEncourages developers to think what the fallback strategy should be, for a potentially failing operation, at the point of initial coding.\nScope\n\nSupport all sync and async variants\nSupport non-result-returning invocations (Action) and result-returning (Func<TResult>)\nSupport Execute(...) and ExecuteAndCapture(...) variants.  \n\nConfiguration syntax\nFor Policy<TResult> forms\ncssharp\nFallbackPolicy<TResult> fallbackPolicy = Policy\n  .Handle<Whatever>(...)\n  .OrTResult<TResult>(...)\n  .Fallback<TResult>(Func<TResult> fallbackFunc);\nFor non-generic Policy\nWhile the most obvious use of a fallback policy is in the TResult case (as above), a non-generic form could also be useful, for providing an alternative Action to execute if a governed .Execute(Action) failed.\ncssharp\nFallbackPolicy fallbackPolicy = Policy\n  .Handle<Whatever>(...)\n  .Fallback(Action fallbackAction);\nOperation\n``` cssharp\n// TResult form\nTResult result = fallbackPolicy\n  .Execute(Func executionFunc);\n// void form\nfallbackPolicy\n  .Execute(Action executionFunc);\n``\n- Calls/returns value fromexecutionFunc.  \n- IfexecutionFuncraises a handled fault: invoke/return value fromfallbackFuncinstead.\n- IffallbackFunc` raises any kind of fault: no special handling; rethrow / pass fault result to caller.\nComments?\nComments?  Alternative suggestions?  Extra considerations to bear in mind?  \nGot scenarios to share where you'd use this? (could inform development)\n. @SeanFarrow Good catch - hadn't yet worked-through ExecuteAndCapture() in detail for this.\nThe intuitive implementation seems like:\n- The whole purpose of FallbackPolicy is to substitute the value/action from fallbackFunc if the governed executionFunc fails.  So if the governed executionFunc fails, ExecuteAndCapture() shouldn't step in and return a PolicyResult capturing executionFunc's failure: the policy should invoke fallbackFunc and aim to substitute its outcome.\n- But the point of ExecuteAndCapture() is capture-rather-than-throw if the policy (after whatever other handling it specifies) eventually 'fails' (eg to avoid having to have another try-catch round the policy execution).  So if fallbackFunc fails ~~with a handled fault~~ with any fault, then ExecuteAndCapture() should capture that fault, with PolicyResult specifying in the usual way whether it was a 'handled' or 'unhandled' fault/result.  [EDITED for correct alignment with what ExecuteAndCapture() does.]\nDoes this sound like it makes sense?\n\nI haven't quite followed your question about the Or(...), but post a code example if it helps clarify.  If it helps:\n- Handle<TResult>() and Or<TResult> are treated in the codebase exactly as Handle<TException>() and Or<TException>, ie the values matched by TResult-predicates are treated as if faults.  So yes, if any TResult-predicate matched, the fallbackFunc would be executed.\n- Handle<TResult>() and Or<TResult> do already have Func<TResult, bool> overloads (was that the question?)\n. @mfjerome @SeanFarrow Great question from both of you, that I've kind-of answered here . We could expose the Exception1 in your example in several places:\n[1] in the captured PolicyResult somehow (but complicated)\n[2] as part of an event stream (later) \n[3] in a simple onFallback delegate (perfect for logging)\n[4] to the fallbackFunc as well \nIn detail:\n[1] PolicyResult<TResult> could contain an IEnumerable<Exception> property as @SeanFarrow says, that details other exceptions before the fallback (or anything else if part of a bigger wrap) was invoked.  A few issues I see with this as stated here: there may be duplicates, it's hard (in a broader wrap context) to connect which exception occurred with which policy-in-the-wrap, and it's actually quite hard to implement in the wrap unless I'm missing something (you kind-of want both-at-the-same-time to capture the exception into some PolicyResult you pass back to capture in the enumerable, but also throw the exception to outer layers at the same time so they can handle it ... you can't capture and throw at the same time??)\n[2] Eventually we can capture all manner of policy behaviour as an event stream as suggested here (but not soon).\n[3] We offer an additional overload taking a simple onFallback delegate, so:\ncsharp\nFallbackPolicy<TResult> fallbackPolicy = Policy\n  .Handle<Whatever>(...)\n  .Fallback<TResult>(Func<TResult> fallbackFunc, Action<DelegateResult<TResult>> onFallback); // for async variants, Func<DelegateResult<TResult>, Task> onFallbackAsync\nThis is my preferred option: simple, available now, and parallels the onRetry and onBreak delegates already well known to users on the retry and circuit-breaker policies.  The classic solution in Polly for logging faults as the policy operated.  Shall we go with this?\n[4] A final option is to combine [3] with what @mfjerome suggested, ie offer the DelegateResult to the fallbackFunc too, ie offer additional overloads:\ncsharp\nFallbackPolicy<TResult> fallbackPolicy = Policy\n  .Handle<Whatever>(...)\n  .Fallback<TResult>(Func<DelegateResult<TResult>, TResult> fallbackFunc);\n// and\nFallbackPolicy<TResult> fallbackPolicy = Policy\n  .Handle<Whatever>(...)\n  .Fallback<TResult>(Func<DelegateResult<TResult>, TResult> fallbackFunc, Action<DelegateResult<TResult>> onFallback); // for async variants, Func<DelegateResult<TResult>, Task> onFallbackAsync\nI'm not sure at the moment if this adds value (maybe somebody really wants to include details of the exception in the fallback value...), or just confusion (too many overloads).  Either way, I propose we keep [3].  Do you think [4] adds anything?\n. COMMUNITY ALERT  Upcoming edge-case breaking change only if currently combining ContextualPolicy and Policy in certain very specific ways.  \nRead on if you think this could affect you - though steps have been taken to minimise impact / ensure only extreme edge cases may be affected.\nBACKGROUND\nThe existing class structure of Polly had ContextualPolicy and Policy with no relation.  Arising from this:\n1. People wanting to combine both ContextualPolicy and Policy faced barriers doing so (#64)\n2. ContextualPolicy was generally not tied in to a number of features provided for Policy; eg no async support (#81), no .ExecuteAndCapture() support (#78)\n3. The lack of relation between ContextualPolicy and Policy meant it would be hard to split Circuit-Breaker from Retry (in order to add deeper functionality specific to circuit-breaker - requested in several PRs/issues) ... while still maintaining support for both ContextualPolicy and Policy in both circuit-breaker and retry (which we did not want to sacrifice).\nConclusion\nWe propose ContextualPolicy : Policy.\nThis resolves all aforementioned issues and provides a platform to grow ContextualPolicy with full support in both retry and circuit-breaker.  However, it was identified this could be a breaking change in certain very limited scenarios.\nThe limited scenario affected by a breaking change\nThe only usages that could experience a breaking change would be code which reasons based on the current split Policy / ContextualPolicy structure in one particular way.\n- only if you have noticed the problem @penderi raised in #64 \n- only if you who have chosen to solve it by trying to capture either policy type into an item of type object (because there was no other choice)\n- and only further if you have code reasoning which this object represents, with code such as:\nif (myCouldBeEitherType is Policy) { // then it can\u2019t be a ContextualPolicy }\nCode which reasons in the above manner only may give unexpected results after this PR is released.\nCode facing the same dilemma which reasons in the opposite direction, taking the more specific case, would be fine:\nif (myCouldBeEitherType is ContextualPolicy) { // do something specific to ContextualPolicys }\n_FOR CLARITY - ALL MAINSTREAM USAGES OF POLLY UNAFFECTED_\nFor clarity, all mainstream uses of both Policy and ContextualPolicy will be unaffected and experience no breaking change:\nvar myPolicy = Policy.Handle<Whatever>.WhateverPolicy(my, arguments) // unaffected \u2026\nPolicy myPolicy = Policy.Handle<Whatever>.WhateverPolicy(my, arguments) // unaffected  \u2026\nvar myPolicy = Policy.Handle<Whatever>.WhateverPolicy(my, arguments, context) // unaffected \u2026\nContextualPolicy p = Policy.Handle<Whatever>.Whatever(my, arguments, context) // unaffected \u2026\n. The new features added to the circuit-breaker in Polly v4.0.0 are now documented in greater depth, at: https://github.com/App-vNext/Polly/wiki/Circuit-Breaker\nAs usual, the readme https://github.com/App-vNext/Polly remains the overview for syntax.\n. @eaba How would you like to see such an attribute used, or working?  \nYou may also be interested to know that Brighter is already adopting an attribute-based approach with Polly, to apply policies.  See: ~http://iancooper.github.io/Paramore/PolicyRetryAndCircuitBreaker.html~ EDITED to update link: http://paramore.readthedocs.io/en/latest/PolicyRetryAndCircuitBreaker.html\n(I haven't evaluated this implementation in detail)\n. Closing due to no further community comment/request for 2 years.\nAnyone please reopen if further interest in or ideas for an attribute-based approach to applying policies.. Agree @TrevorPilley @joelhulen great idea!\n. In the meantime, @TrevorPilley , here's a github compare view which shows the differences between v3.0 and v4.0: https://github.com/app-vnext/polly/compare/86f887ed1bd53743086fbc3dd70ab9fd578630fc...cd3434467ca4639141b6f2088dae7c5ba25977e9\n(not as good a reading experience as it could be, given the [necessary] file renames, and the highly repetitive content of the syntax classes)\nLet us know if you think there are further ways we can support explaining new features.  The intent so far has been to stick to the original, concise documentation in the readme (see the changes there - they should cover everything).  However, given the new layers of functionality in the circuit-breaker, we'd like (given time) to blog about them more fully on the wiki next week.\n. @joelhulen I'm all for tagging minor vers too, if we can just make it part of our workflow.\n. @TrevorPilley Thanks for this great suggestion.  Closing this issue now, as we are adopting your suggestion going forward (tho feel free to remind us if we forget! :smiley: )\n. @fubar-coder Very many thanks for this and for your involvement with Polly!\nDo you have any code example, where an action executed through Polly is generating nested AggregateExceptions? \nThe Polly async implementation is async/await throughout, therefore, nested AggregateExceptions should not be generated specifically by using Polly.  (Ref, second half of: Stephen Toub on Task Exception Handling).  \nI would only expect Polly to return nested AggregateExceptions if:\n(i) the action delegate itself is generating the nested AggregateExceptions.\nor\n(ii) the action delegate only generates one (not-nested) AggregateException, but code is synchronously-waiting on the result of async policy execution, like policy.ExecuteAsync(action).Wait() (or similar).  \nIn (ii), the Polly codebase cannot help flatten the AggregateException: it has no control over the AggregateException returned by the outer .Wait().\nIn (i), the question becomes whether Polly should (on behalf of the user) flatten nested AggregateExceptions created purely within the user's action delegate. \nMy first instinct is that Polly should not intervene by modifying exception effects purely of the user's action delegate.  This keeps Polly's intervention minimal and transparent, without adding any 'side effects' (save the retries or whatever intended) to how the user's delegate is executed.  This is a slightly purist approach, but allows the user maximum control to make their own choice about exceptions, rather than imposing a choice from the library.\nUsers calling .ExecuteAsync(...) in a mode like policy.ExecuteAsync(action).Wait() or (EDIT) .ContinueWith(...) can of course call .Flatten() themselves, which has the advantage of including the outer AggregateException.\n. @fubar-coder Based on the above reasoning, I am intending to recommend this as 'wont-fix'.  \nHowever, if you have a particular code sample where this is causing problems, we would be very interested to see it, as this could (of course) shed further light on the problem.\nMany thanks\n. Hi @bunceg, many thanks for the input!  Noted that you are still looking for the best solution to shared circuit-breaker state across processes with Polly, and/or a feature to inject state into a circuit.  Further views on this welcome from across the community...\n@bunceg I'll respond to the specific scenario back within #6, since that feels like it might turn into a longer discussion.\n. Following the live demo today at devinteractions, there was a request to add caching into the policy pipeline.  So we've added to the roadmap a proposal drawing on ICacheProvider, to allow any existing .NET cache implementation.\n``` csharp\n// Possible configuration syntax\nvar cachingPolicy = Policy\n  .CacheProvider(ICacheProvider provider);\n// Execution syntax might different slightly from the normal policy .Execute() syntax, eg:\n// Possible syntax:\ncachingPolicy.ExecuteOrGetExisting(Func func, string cacheKey);\n```\nOther .ExecuteOrGetExisting(...) overloads could also be provided, mimicking ICacheProvider .AddOrGetExisting(...) overloads, for easy comprehension.\nComments welcome on this (or any other feature in the roadmap) under this issue.\n. Hey @pj-moviestarplanet Great idea, added stats to the roadmap.  Happy for any community feedback on an architecture for this.\nOne question is phasing: whether to start emitting stats/events from Polly as of now or when the fuller Polly Pipeline is in place.  Phased would be great if we can see far enough ahead not to introduce breaking changes later.\nRelated: The Polly Pipeline proposal differs from the Hystrix approach in one significant way.  While Hystrix has a fixed structure in which the various elements are composed (fallback, cache, circuit-breaker etc; hmm, no retry), the Polly Pipeline proposal is currently more flexible, allowing users to compose whichever elements of the (envisaged) Polly resilience armoury they want, in any order.  \nThe intended advantage of this flexibility is simplicity: users select and compose only the elements they want.  However, a disadvantage may be if (if) that flexibility makes emitting overall stats for calls more difficult ... it may depend whether Polly's role is to emit stats or raw(er) events (perhaps as a ReactiveExtensions Observable<T>) which something else compiles to/pushes to stats.\nKeen for any community feedback on the current Pipeline proposal - strengths, weaknesses?  Definitely an area of the roadmap that's still up for grabs how we architect it ...\n. @KBRETON1 Thanks for the vote for this! (async methods in .NET 4.0 using Microsoft.Bcl.Async).  This is already in progress as #103 .\n. @mattwoberts The Polly team view .NET core compatibility as essential and high prio on the roadmap.  The current PCL259 codebase is entirely netstandard1.0 compatible, so no major code issues.  The recent flux in tooling from Microsoft has been a barrier (we have wanted to avoid tracking a moving target and that impacting other active feature development over last few weeks).  We are hoping for some stability from Microsoft in the tooling coming Monday 27 but remains to be seen ...\n@SamuelEnglard has made a start at this (thanks @SamuelEnglard  !), @mattwoberts see conversation and links at end of #51 . I am hoping to look at this in the coming days/weeks, @mattwoberts if you also have time to evaluate and take further with @SamuelEnglard please do!\n(I am just now completing #14, which will unlock the path to many of the hystrix-like features that @seanfarrow, I and many others are interested in on the long-term Roadmap ...)\n. Hi @adamhathcock , thanks for your interest!  We are hoping to start work on the Pipeline in about a week's time (this week's focus is nuget packages supporting .NET Core).  Would be great to hear any input you have on how you see this working, or the context you'd be using it in.  I'm also hoping to put out an implementation proposal for comment in the next few days - @seanfarrow and others also interested in this feature.\nFor now, see nesting policies in the wiki, for a syntax for nesting calls through multiple policies at present.  Similar syntax also works for async.\n. @adamhathcock @seanfarrow  For a brief comment on implementation thoughts so far around the policy pipeline: I see a Pipeline represented as a linked list.  However, we probably also want to retain the ability to re-use a policy across more than one call, and therefore in more than one pipeline (for benefits of this see wiki).  This probably means a pipeline is a linked list of pointers to policy instances, not a linked list of actual policy instances.  Thoughts?\n. All thinking out loud welcome! (lots of interesting ideas guys)\nRather than respond piece-by-piece, I'm working up (and will post shortly) a full proposal statement for each of the envisaged wider resilience features.  \nI think it will help to consider them as a group: a lot of these proposed policies and considerations interlock (eg the need for an id/key on a policy, and/or on an individual execution, also comes into play for using a cache, for emitting events/stats, for configuring policies from a PolicyRegistry, etc...)\n. @adamhathcock , re:\n\nI don't really like the look of the Nested Policies thing. It looks like there could be a better way to \nhook things together but each policy remain atomic? [...] Maybe there would have to be ...\n\nYes, the nested policies thing in the wiki is (for clarity) not a proposal.  It's just some standard C# syntax that I put out as doco to guide people with chaining the existing policies, when App-vNext took on Polly six months ago.  What you're suggesting is exactly the essence of the Pipeline proposal to provide something nicer :smile:  (great to hear; all thinking out loud welcome! :wink: )\n. @Amerdrix See comment from a couple of days ago if you haven't already.  Pipeline is shortly up on the development agenda, and there's a pointer to existing C# syntax for chaining policies in that comment.\nStay tuned: we'll be posting a fuller proposal for the pipeline feature for comment, in the next few days.\n. Hi @adamhathcock @SeanFarrow There are already a lot of players in the task/job scheduling space in .NET.  All essentially have a job triggered as a lambda delegate, or a method to be fulfilled from an interface.  Polly can inflect the action of any lambda / wrap how any method is invoked, so in principle it shouldn't be difficult to integrate with any job scheduler.\nIf one wanted to do tighter integration (allow people to declaratively specify, eg in the manner Brighter does, the Polly policies they want to modify the operation of their scheduled task), I would see that as a separate project (eg Quartz.Polly) (although some of those schedulers, like Hangfire and Quartz, already have retry built in).\n. Hi @adamhathcock \nThe essence of Polly is that a policy inflects how an action is actioned.  This can even be seen right in the codebase in the base Policy class as Action<Action>. (I like to show this as it's a great way of understanding what Polly does!)  The inner Action is the delegate you pass Polly to execute; the outer Action is what the configured policy will do with it.  \nIn that sense, Polly doesn't own any jobs at all.  A policy inflects the operation of delegates/lambdas that are passed to/through it.  So yes, as you say: Polly encapsulates common (resilience) logic that may be applied to delegates anywhere.\n(Brief further comments on the code line I pulled out: The Context you see in there too is an execution context that travels with each invocation. And the async version is similar with, you guessed it, some Funcs. :wink: )\n. @adamhathcock No problem.  Debating the roadmap and boundaries - above all hearing people's use cases and integration points - sharpens things up for everybody.  \nDoco and applicability for open source projects is really important too: we've tried hard to make the readme cover all the syntax, and the wiki the concepts, but I'd like to get some other usage patterns (like the oauth stuff, and an MVC pipeline example) out into an expanded policy patterns section.  Are people really aware of what's there in the wiki? (maybe we don't highlight it enough)\nIf anyone thinks there are things that would be useful to see more of in the doco, feel free to shout.\n. Interfaces in Polly and custom policies could potentially be a powerful development: People could develop their own custom policies; even publish them as packages; the best could be taken into the main Polly project.  \nThe question: is now the right time to add interfaces? ... At mo, the planned functionality means we'd probably (necessarily) be adding to the base class/interface relatively frequently (breaking the interface if there was one).  I'm wary of publishing an interface now and breaking it repeatedly over the coming months ... (thoughts anyone?)\n. Looking at things from another angle too @adamhathcock, it could be just as advantageous for you (thinking of your pipeline) to put your own interface around Polly.  The Polly Execute() overloads themselves, given the fluent syntax, have to try to do all things for all people.  For instance, there are numerous overloads for ExecuteAsync() controlling continueOnCapturedContext, CancellationToken, involving Polly\u2019s Context or not, then TResult versus void-returning etc ... You might decide for your own purposes you always/never want to capture async context, always insist on a CancellationToken etc, and might define a much tighter interface. It's only a few minutes\u2019 work then to write a lightweight wrapper for a Polly policy which delegates downwards to the chosen overload/s and your own custom operations of course plug into that interface.  ... \nApologies for this detail, but thought it worth calling out the numerous overloads, as it is a potential issue for a Polly interface.  The fluent configuration is one of Polly's original greatest strengths, but it's stretching a bit more as we add more functionality - on the radar and feedback welcome.\n. @SeanFarrow,\n\nCould we not make the changes and then work out how we extract an interface at a later date?\n\nYes (potentially).  I'm also thinking about whether some interface segregation could stage things ... this will also become clearer as the new functionality is planned and executed.\nWorth pointing out though that it was a huge benefit that the founder of Polly hadn't started with an interface at 1.0; we would have been breaking them repeatedly as the library grew.   To judge ongoing.\nAlso imperative to decide whether to tighten the number of overloads (see foot of roadmap) before publishing an interface.  \n@SeanFarrow See for example also Hystrix holding off interfaces in places to give themselves room to grow.  Big potential interface benefits for reasons previously stated (and usual design reasons), but care also in still-evolving library?\n. @PaybackMan You asked for .Net Standard Support for Polly.  Just alerting you that we're in beta on this!  There are beta packages posted (targeting .NETStandard versions 1.0 for PCL; and 1.6 for .NET Core) in the threads #132 and #133 respectively .  Please feel free to try them out! (and we would love feedback). (We are letting interested parties pre-trial them before posting them to nuget, though they should go out there fairly soon...)\n. @mfjerome That\u2019s great to hear! And perfect timing \u2013 after a big refactor (#130), we\u2019re just about to embark on those Hystrix-like wider resilience policies.  Please stay tuned as we\u2019ll be putting up deeper docs on those features in the coming days/24hrs(?) and it would be great to have your feedback!\nExtra dev power could well be useful @mfjerome, definitely opportunities.  Are you able to contact me briefly off-github at software[at]reisenberger.net, we can talk a little more freely about how you/your devs could contribute? (and timings - I have some away time coming up).  All contributors will be credited!\n\nTimeout, Bulkheads and Fallbacks [... for use in ...] project templates/frameworks to build microservices \n\nA good fit.  I have experience of these in a microservices environment, part of my desire to apply to Polly.\nThank you for your support and involvement!\n. I thought it might be useful to set down some thoughts I had about differences in approach/implementation (on resilience policies) between Hystrix and Polly.\nNB In each case, neither of the approaches is necessarily better/worse (I can often see advantages from one perspective, disadvantages from another), but identifying them helps stimulate discussion and think about product direction for Polly.   Hystrix-derivatives in .NET also tend to have Hystrix characteristics.\n(The comparison is intended to call out differences in approach/emphasis, not be a worklist, so the observations  assume the intended features on the Polly roadmap will be in place.)\n| Hystrix | Polly |\n| --- | --- |\n| has a central command-type class which brings together all the resilience features.  has a fixed set of elements all of which the dev has potentially to understand and configure before using a command (slightly heavier-weight) | has separate components - users can choose to use only the Policys they need |\n| the command class is derived from to manage an execution to be put through Hystrix. Code to be executed through the command is placed in an overridden run() method or similar. | a Policy is not coupled to the code it can run.  A Policy can be applied to any delegate.  Policies can thread-safely be reused across multiple delegates (for benefits see wiki).  Policies can be passed to entirely different parts of the codebase (allows decoupling/dependency injection/easier stubbing by DI, for testing). |\n| uses the fixed set of strategies-in-a-command always in the same order | allows users to compose policies to apply to a call in any order |\n| uses each strategy (circuit-breaker; fallback etc) once in each command | allows configuring PolicyWraps which use individual strategies (eg retry; fallback) multiple times.  Combined with filtering, allows for responding to different exceptions differently, eg different retry strategies by exception (retry only once a XException, but on YException 5 times); or eg different fallback strategies/stub values for different outcomes. |\n| has configuration by setting properties on the command instance | has fluent configuration during instantiation of a policy |\n| has the ability to recalibrate command parameters after initialisation | does not (yet) have the ability to recalibrate policy parameters after initialisation (policies are immutable and pretty much 'black boxes') UPDATE: January 2018, now offered via PolicyRegistry |\n| has central system-wide defaults for configuration parameters | has no/few hidden defaults (policies only do what you explicitly configure them to do) |\n| has no retry policies | has retry policies |\n| is geared more explicitly around result-returning calls, the execution of remote requests | caters natively for both result-returning and void-returning actions |\n| has exception filtering only by exception type; 'greedy' exception-catching with opt out | can filter by deeper exception properties; specify explicitly the exceptions to handle (opt in), but can greedily catch-all if desired |\n| is not (check?) able to interpret return values as faults to handle | is able to interpret return values as faults to handle |\n(And maybe other dimensions - if you think there are others to consider, or if a comparison seems inaccurate / could be better stated, please comment!)\n(And: There is clearly a raft of things Hystrix-in-Java does beyond fault-handling, in terms of stats/metrics, dashboard for visibility etc, beyond these resilience aspects.)\n\nTo date I have tried to grow Polly (since AppvNext took stewardship) in the spirit of the original, that is: fluent configuration; lightweight; minimal impact on your code (to use) after you have configured a policy.\nAny thoughts arising from the above? Things we should/shouldn't do in Polly? Should/shouldn't do like Hystrix?\n. @adamhathcock / @Amerdrix / @SeanFarrow / @mfjerome / @joelhulen  / anyone interested: I have now posted some more detailed proposals for the possible operation/implementation of the planned, hystrix-like resilience features:\n#80 Fallback\n136 Cache\n137 Timeout\n138 Throttle\n139 (Keys, to use with cache, potential later PolicyRegistry and events/stats emission)\n140 Policy Wrap (was: Pipeline)\nI appreciate this is a lot of material to read: thanks in advance for anyone's time/interest/involvement.  Most are essentially more detailed statements of an implementation already outlined in the Roadmap.  The biggest change is in #140 Policy wrap (may add more comments/qs around this shortly).  \nPlease do add comments / qs / thoughts under the relevant issue!  (Or equally if you think a proposal sounds good-to-go as it is.)\n. To answer the v good question @SeanFarrow raised under specific new proposed policies:  All new policies would cater for all existing Execute syntaxes and sync/async variants unless otherwise stated.  The syntax examples given were just examples (too many overloads to state all). \nIn general:\n- ExecuteAndCapture() should be supported throughout\n- sync and async should be supported throughout\n... and if there are exceptions the Scope section (or detailed notes) in each policy proposal should call them out.  For example:\n- Cache makes no sense for void returning :wink: \n- Timeout requires new co-operative-cancellation overloads with Cancellation for sync .Execute()\n- ExecuteAndCapture() probably wants special treatment in a policy wrap: ... one would want more-inner policies in the wrap still to throw, and only the outermost call to ...Capture?)\nThanks for the great q.  I'll go over them again and look for any missed cases.  Anyone shout if you think any thinking steps missed on this!\n. COMMUNITY FEEDBACK SOUGHT\nFollowing release of Polly v5.0, the potential Polly roadmap has been updated with a few new items and clarifications.\nThere is clear community interest in metrics; work on this is beginning, including discussion in our slack channel.  Full proposals will be posted on GitHub as they cohere.\nBeyond metrics, what is your view of priorities among the other items? \nWhat would you like to see, that is not on the roadmap?. @railarmenien  re:\n\nCircuitBreaker and AdvancedCircuitBreaker have a locking nature due to the use of a Monitor in the \nTimedLock implementation. A implementation using the Interlocked class may avoid to lock the circuit \nstate. What do you think about it ? Would it be relevant ?\n\nThanks @railarmenien for this great point!  The circuit-breaker design App-vNext inherited when taking over the project, as you say, uses locking.  I started investigating moving the design to Interlocked in January when we resolved #216 with lock-free techniques.  My broad-brush assessment was:\n(a) Metrics calculation and general operation in Closed state: is the key case to optimise.  It makes sense to absolutely minimise any latency through contention for concurrent, multi-threaded requests on a healthy system.  As most metrics updates consist of increments and assignments/queue-manipulation (rolling the metrics buckets over), these can likely be moved to Interlocked and/or thread-safe collections.  Same for HalfOpen state if #239 is pursued.  \n(b) Transitions of circuit-state (where we have locks guarding modifications to several variables): seems not/less worth optimising away the locks.  If your circuit is breaking, the problems you are likely suffering (eg network latency; faulting downstream system; breaking the circuit for presumably several seconds) are all orders of magnitude greater time-wise than the differences between locking techniques.  No value to increase code complexity/risks here?\n(c) Read locks: Some locks effectively act only as read locks.  Some I think could be reasoned away as unnecessary.  Others (eg if read-then-modify) cannot.\nThere's also extensive discussion here on pros/cons including from the eminent Reed Copsey.  The broad conclusion is 'measure don't assume' (so we should do that).  My instinct, reviewing the code, is that we should pursue (a), and would make gains, but we ought to take an evidence-based approach and get some benchmarking around this (as @ankitbko has suggested elsewhere) .  \nWhat do you / does anyone think?\nI can take this forward but it requires a dedicated chunk of time.  I'd be very happy to hear further comment/contributions from anyone in the community.. Added the idea of a RateLimitPolicy (serial throttle) to the Roadmap.. @MihaMarkic @devapalanisamy Polly v6.0.0, now published, includes a .NET Standard 2.0 target.. Hi @bunceg .  Re:\n\nWorked out that I need to store a CircuitBreakerPolicy not a Policy object as \nmy static pointer to the circuit breaker policy\n\nYes, that would be needed.  We had to retain the ability for people to code Policy myPolicy = ....CircuitBreaker(...) for backwards compatibility.  But, to gain access to the V4 circuit-breaker's full features (including passing context), you have to switch to var myPolicy = ....CircuitBreaker(...) or CircuitBreakerPolicy myPolicy = ....CircuitBreaker(...)\nHope this helps!\n. Hi @bunceg .  Thank you for picking this up.  You are right: the onReset delegate is currently firing too often.  A pull request will fix this very shortly.\n. Hi @bunceg . Thanks again for picking this up.  Revised nuget packages fixing this should be available from nuget in the next hour or so - soon as it says 4.1.2 there.\n. Hi @mxa0079 \nI have not run the code, but in the gist sample, you have two repeated lines:\nBreakOnNumberOfExceptions = breakOnNumberOfExceptions; \nBreakOnNumberOfExceptions = breakOnNumberOfExceptions;\nWas this meant to be:\nBreakOnNumberOfExceptions = breakOnNumberOfExceptions; \nBreakCircuitForSeconds = breakCircuitForSeconds;\n?\nAs the gist stands, it looks like your PollyCircuitBreaker wrapping class will be creating a CircuitBreaker to break for TimeSpan.FromSeconds(0), which will be why it is transitioning from Closed to HalfOpen immediately.  ~~(Why certain cases return Closed and others HalfOpen may be a race condition between TimeSpan.FromSeconds(0) and the test code; preferring to reply quickly, I haven't investigated that.)  Anyway:~~ Adding BreakCircuitForSeconds = breakCircuitForSeconds; should fix it?\nYour issue does point up that the original circuit-breaker code doesn't have a guard condition on breaking for a zero TimeSpan.  If that was in place, your issue would have been spotted sooner.  We'll consider adding that!\n. @Lumirris Please feel free to take yourself a fork and try this out.  The availability / inclusion of the async overloads is controlled by a compilation constant SUPPORTS_ASYNC.  In the .NET4.0 proj, include Microsoft.Bcl.Async, add SUPPORTS_ASYNC as a conditional compilation constant, and you should be good to go.\n. Hi @Lumirris Having consulted internally at App-vNext, current view is not to take extra dependencies in the core Polly project, as we're targeting .NET Core compatibility and reducing the overall number of separate projects / dependencies.  Will however leave the issue open to see if there is greater demand.\nThat said, it should be fairly easy to maintain your own fork for this and rebase it when you want to pick up new features.  \nHappy for any feedback on how Polly async plays with Microsoft.Bcl.Async (shouldn't be any problems), from anything you try ...\n. Hi @Lumirris   To make code suitable for a .NET4.0Async nuget package, I would follow the principles: \n- only include a .NET4.0 proj (not 4.5, 3.5, PCL), so there isn't any confusion that this package provides anything other than specifically the .NET4.0Async version\n- only include one .NET4.0 proj in the package (wasn't sure if you were suggesting src/Polly.Net45/Polly.Net40Async.csproj (45 a typo?) as additional to the existing .NET40 package or replacement; suggest replacement).\nTry the following steps:\n- take your own fork of Polly\n- remove all projects except for the .NET40 project, Polly.Shared and Polly.SharedSpecs\n- rename the .NET40 project in the solution as Polly.Net40Async.csproj as you suggest (makes it v clear)\n- reference Microsoft.Bcl.Async from that csproj\n- add SUPPORTS_ASYNC as a conditional compilation constant to that proj\nLet us know how you get on.\n. Hey @Lumirris We talked further at AppvNext, I believe from @joelhulen we'd be happy to host and maintain (ie keep udpated) a Nuget package like Polly.Net40Async, as you suggest - assuming we can get all components to play.\n@Lumirris Did you have any luck trying out a prototype, per previous notes?  (if you have an immediate need for this, you'd be well placed to test :smile: ).  Do you need any further assistance?  \n@joelhulen I see this clearest as a separate package, not part of the main Polly package, to reduce the dependencies of the main Polly package.\nThanks!\n. Hey @Lumirris.  Thanks for all your work on this!  \nWith you about Task vs TaskEx in Microsoft.Bcl.Async.  SUPPORTS_ASYNC_40 switch sounds good.  \nAm assuming (shout if I misunderstood) that SUPPORTS_ASYNC_40 should supplement (rather than replace) SUPPORTS_ASYNC as a compilation constant in the new package, so the Polly.Net40Async.csproj would set both  SUPPORTS_ASYNC and SUPPORTS_ASYNC_40.  This will certainly reduce modifications elsewhere.\nLike the idea of centralising the Task vs TaskEx switches - just a slight tweak to suggest.  Rather than wrapping methods, can we follow the pattern that's already in SystemClock.cs?  IE Define a public static Action<...> and vary the definition of that.  So we might have a new class TaskHelpers in Utilities folder, the whole class definition wrapped in #if SUPPORTS_ASYNC / #endif, and then definitions like:\n``` csharp\n        /// \n        /// Allows the setting of a custom async Sleep implementation for testing.\n        /// By default this will be a call to \n        /// \nif !SUPPORT_ASYNC_40\n    public static Func<TimeSpan, CancellationToken, Task> SleepAsync = Task.Delay;\n\nelse\n    public static Func<TimeSpan, CancellationToken, Task> SleepAsync = TaskEx.Delay;\n\nendif\n```\n@Lumirris What do you think?  Does this all sound good?\n. @Lumirris @joelhulen I put some investigation into the unit-testing for an async 4.0 package.\nIt turns out .NET4.0 unit tests were removed back in October 2015 because the latest XUnit 2.0+, which Polly uses, supports only 4.5+.  In other words, for the validity of the .NET4.0 and 3.5 packages we currently offer, we assume backwards .NET compatibility: that the supported .NET3.5 / .NET4.0 behaviours behave the same as the .NET4.5 and PCL tests verify.\nFollowing the same logic, for the new .NET40async package, we would be relying additionally on the Microsoft.Bcl.Async TaskEx functionality behaving as the later Task functionality does.  Given the Microsoft.Bcl.Async package was the community technology preview for the relevant .Net4.5 elements anyway - and @Lumirris has identified the only switches will be around Task.FromResult and Task.Delay - I think this is acceptable.  Just @joelhulen sharing.\nAlternatives could be ( ... but I propose we don't adopt either; they are not particularly palatable from the p-o-view of long-term maintenance ...) : \n- Downgrade both the master Polly package and the .NET40 async package to the earlier XUnit 1.9.2, and remove the XUnit 2.0+ features we use.  Not proposing taking / holding the overall package back like this.\n  [or]\n- Maintain divergent sets of tests (on different versions of xunit) between the two different packages.  Maintenance headache.\nIf anyone has a brighter idea, please shout. :smile: \nEDIT: Xunit and .NET4.0 reference: https://github.com/xunit/xunit/issues/241\n. @Lumirris Great.  Agree with your sentiments about using static.  The method names probably hold (because Microsoft.Bcl.Async was the community tech prev for the relevant .Net4.5 elements), but it isn't guaranteed or necessarily as clear.  Always good to and happy to explore options, tho.  :wink: \n. @Lumirris  Huge thanks for offering to take on this Microsoft.Bcl.Async work!  How are you progressing with this?  Any blocks?  Do you need any assistance?  \n@KBRETON1 Are you (having expressed an interest under #90) available to assist with this? (if we need any assistance).  EDIT: @KBRETON1: Have a read of the thread above to see what's involved!\n@Lumirris Re my reference to this issue from #107: I have constructed the #108 fix for #107 so that users of Polly with .Net40 and Microsoft.Bcl.Async in VS2010 would be able to specify the new async onRetry delegates cleanly (by either of the two methods proposed in my comment https://github.com/App-vNext/Polly/issues/107#issuecomment-218895978), despite the VS2010 limitation.  So, my comments in #107 are not an issue for progressing this. \nMany thanks!\n. @Lumirris Thanks for all your work on this, and @KBRETON1, thanks for your support/involvement!  @KBRETON1 Please (as another user wanting the .NET40 support) do feel free to review alongside me, at review stage.\n@Lumirris For now, as you suggest, carry on pushing your changes to your master, to complete the work.  Will be at least clear to review there, before we engage in rebasing.    \n@joelhulen The final requirement will be to publish a separate Polly.Net40Async nuget package.  That Polly.Net40Async nuget package will take the Microsoft.BCL.Async dependency, but, as we know, the main nuget Polly package mustn't.  Can you from your nuget script/process publish both packages like that out of the one GitHub repo?  Only asking as, if we have instead to split into two separate github repo sources (one without .NET40, one with), that may change the whole merge/rebase requirement anyway.\n. @joelhulen D'oh.  Don't know why I didn't check the build.cake for that.  Cool!  Imagine yes we can (and should) keep it all in the same repo then.\n. @Lumirris If you have managed to move it off your master and into the feature branch (as looks), even better.  Great: will review!  Many thanks for this!\n. @Lumirris Re the tests, a version of XUnit was adopted a while back that no longer supports .NET40, so makes sense if no tests could be run in the version of the solution you've just pushed.  Ref my earlier comment: we'll rely on the .NET4.5 tests to assure the behaviour of the .NET4.0+Bcl.Async solution.  Given the tiny differences, this seems fine.\nGreat work on the rebase.\n\nonly the SystemClock that needed any change\n\nYeah, I squashed some Task.FromResult(...) stuff out when fixing the async onRetry delegs.\n. @Lumirris REVIEW: Given the way we have now decided to master the nuget packages from one repo (rather than a separate repo for this), the advice in my 25 April comment to remove all other csprojs (.NET35, .NET45, PCL, .NET45specs, PCLspecs) was as it turns out unhelpful (wrong in retrospect!).  Can you reinstate all the deletions of those from Polly.sln?  (Copy-paste from a good master or from the diff?)  Then I will pull down and build/test locally.\nShouldn't be further probs - the eventual changes are so small!\n. @Lumirris In principle this is looking good!  Aiming for some brief real-world testing of the NET40-async package tomorrow / day after(?), then we'll sort out a PR and work on the build.cake nuget packaging our end.\n@Lumirris Are there any unused references among the Polly.Net40Async project?  Could anything unused be removed?  Guessing we can't be using anything from System.Net, System.IO ... any others that can go? (possibly just adding Bcl async via nuget pulled these refs in...)\n\nMany thanks for all your work on this!  \nEDIT: @Lumirris: I resolved these issues in the work done May 27\n. @Lumirris. We need to adjust the documentation and start setting up the cake build to generate the new nuget packages for this.  We may need to experiment with the cake/nuget packaging a bit, so I'm going to pull (PR) your fork across to a fork on my repo reisenberger/Polly first, then start fixing things up there (cuts down toing-froing noise of requests to you).  I'll re-alert you when we have something ready to PR to app-vNext/master!\nThanks for all the initial work on this!  Hopefully get this out soon.\n. @Lumirris @joelhulen Please find a version with some doco added, nearly ready for PR, here\n@Lumirris @KBRETON1 @joelhulen Anything need correcting?\n@joelhulen build.cake and the nuget packaging next.\nEDIT: NET40Async solution tests out perfectly with most complex async sample in Polly-samples\n. @joelhulen Over to you to fix up the nuget packaging side in build.cake.\n- I am fully signed off on the content.\n- .NET4.0 async tests fine with both manual tests and the most complicated example in Polly-samples.  \nJoel: Please feel free to make a PR directly on to app-vNext/master from here when ready.\nI assumed (already listed in the doco) Polly.Net40Async and Polly.Net40Async-signed.as the names for the new nuget packages.\n@Lumirris Thanks for your contribution!  Pushed this through quickly today as am travelling and largely away from keyboard next 10 days.  Thanks!\n. @KBRETON1 Thanks for highlighting that potential issue with the Nuget.config.  What version of Visual Studio are you using?  I didn't have that issue (VS2015).  Nevertheless, I will look at the missing nuget.config in due course.  Thanks!\n. Thanks @KBRETON1.  On reflection, has to be VS2015, given the Shared projects in the Polly solution.\nRe:\n\ndo you have any inside into why System.Net is there?\n\nSure I'm stating the obvious here, but the classic use cases for async are to not block a thread while the system waits for a response from an IO device (methods like System.Io.StreamReader.ReadToEndAsync()), or while waiting for a network response (methods like System.Net.Http.HttpClient.GetStringAsync()).  It thus makes sense that Microsoft.BCL.Async would include versions of System.IO and System.Net, to bring in all the new *Async() methods.\nIf the question is different - why R# might suggest System.Net is needed...  @Lumirris I am not finding we can take R# as a reliable guide for what is needed.  For instance, on my machine it says System.Runtime is not needed for this csproj, but removing it causes compilation failure.  [R# has a number of problems with the Shared project setup on my machine.]\nI know 100% that Polly doesn't use System.IO and System.Net so I have removed from the proposed package.  I have tested and can run the most complicated Polly-Samples against the version with them removed.\n. > why System.Core is there, but not in the other Polly projects\nMicrosoft.BCL.Async helps a wide range of platforms adopt await/async (as described at https://www.nuget.org/packages/Microsoft.Bcl.Async/), including Silverlight.  In the reference sources for the LINQ extension methods, one sees code like:\n```\n // Include Silverlight's managed resources\n #if SILVERLIGHT \nusing System.Core; \nendif\n```\nPerhaps more elements needed to be added to the package to support async in Silverlight, or Silverlight had some extension methods in slightly different namespaces? (Hunching; I haven't worked with Silverlight.  Happy for update by anyone with detailed knowledge?)\nI can remove System.Core and the NET40Async package compiles on my machine.  However, I have erred on the side of caution and left that one in the package, in case, for example, it is needed for Silverlight usage.\nEDIT: We'd be interested to hear from any user who tries to use the Net40Async package with Silverlight.  It may be that we should recompile it with the SILVERLIGHT compilation constant set.\n. Hi @KBRETON1 Re hintpath and nuget.config:  https://docs.nuget.org/consume/nuget-config-settings confirms that $(Solutiondir)\\Packages (which the hint paths reference) is the default in absence of a Nuget.Config specifying a different value.\nDo you possibly have the repositoryPath key overridden in your master/default nuget.config (located per this)?  Could you confirm?  If so, could you confirm whether dropping a Nuget.Config as follows, next to Polly.sln, solves the problem for you? (with the original hintpaths in the csprojs in place).  Assuming this fixes for you, we should be able to add this to the repo.  Many thanks.\nxml\n<configuration>\n    <config>\n        <add key=\"repositoryPath\" value=\"./packages\" />\n    </config>\n</configuration>\nEDIT: I was able to mock up my machine to have the master Nuget.Config specify a different download location, delete my previous downloaded BCL.Async packages, but still receive no compilation errors on compiling Polly: Nuget of course just downloads packages to the specified location, and compiles them in / references them from there.  @KBRETON1 Not sure what the issue will have been on your machine - unless you can describe in more detail?\n. @KBRETON1 Thanks, great to know!\n. Hey @KBRETON1  I am on the road till Mon 6th, so only getting the odd hour at keyboard in hotel rooms this week.  Apologies for any delay and thanks for bearing with us on this! \nRemaining step is to adjust the build scripts to generate separate nuget packages for existing Polly and Polly.Net40Async.  I pushed an early version of build scripts yesterday to: https://github.com/reisenberger/Polly/tree/Net40Asyncv3 . @joelhulen on the App-vNext teams owns the nuget publishing gateway/process, so ...\n@joelhulen I'll make a formal PR of this in a mo, and you can review / decide whether to go with the current build scripts to get the Polly.Net40Async packages out - or await refinement.  Thanks!\n. @joelhulen @KBRETON1 @Lumirris Also agree.  I believe in fact that three further layers of change were needed, now PRd in #108 : \n[1] exclude non Polly dlls from the build output: I've excluded them @joelhulen from the parts of the build output copied into the nuget package.  Is this what you meant, or have I misunderstood?\n[2] remove irrelevant dependencies: See  PR, for details.\n[3] ensure stated dependencies targeted correct NET40 TFM/moniker: again, see PR.\nI tested this (compile-and-run) both against @KBRETON1 's ConsoleApplication2 , and an entirely fresh sample - ie without Microsoft.BCL.Async already included.  Calling in the Polly.Net40Async nuget package brought in the necessary dependencies, and allowed policies to be keyed, compiled and run.\n@KBRETON1 Do you want to verify the package now both looks and behaves, as you would expect?\n. @joelhulen @Lumirris @KBRETON1  I have done a line-by-line comparison of the Polly.Net40.csproj against Polly.Net40Async.csproj.  The moral of the story (for future similar cases...) could be that we will have a cleaner result/process, if we start (in similar circumstance) by initially copy-pasting Polly.Net40.csproj to Polly.Net40Async.csproj, rather than (say) adding a fresh project.\nA shortly forthcoming PR:\n- re-instates XML file\n- ensures Polly.Async40.dll will be semver version-stamped (this had also been lost)\n- harmonizes other aspects\n@KBRETON1 Thanks for the :eyes: .  Line-by-line comparison does not now reveal any other substantive differences - but let us know if you spot anything!\n(comment on extra .config file coming separately)\n. @joelhulen / all.  The Polly.NET40Async.dll.config file is being added automatically by the build process [it doesn't stem from any app.config added manually to the solution], and it specifies binding redirects for two DLLs from Microsoft.BCL.Async.  \nThis discussion suggests it must be left in place, for a package based on BCL.Async to operate correctly.\n. Hi @BertLamb \nUsing .Or<TException> lets you handle more than one type of exception in the same policy.  And, the exception just thrown is passed the to onRetry delegate before the next try commences, so you can vary onRetry actions depending on the exception causing the retry.  So:\n``` csharp\n// don't need to reconnect on a CommandException\n// but need to reconnect before a retry when an IOException occurs\nmyPolicy = Policy\n    .Handle()\n    .Or()             \n    .Retry(10, (exception, retryCount, context) => \n    {  \n        if (exception is IOException) { Reconnect(); }\n    });\nmyPolicy.Execute(Command);\n```\nDoes this cover it?  Let us know if you have any other questions!\n. Hi @BertLamb Did this solve your problem?  Can we close the issue?  Or: Would you like any further assistance?\nThanks\n. Hi @BertLamb .  To do that with Polly, you can define separate policies and nest them, as described in the wiki here or as shown below:\n``` csharp\nvar retryPolicy = Policy\n    .Handle()\n    .Retry(10, (exception, retryCount, context) => Reconnect());\nvar circuitBreaker = Policy\n    .Handle\n    .CircuitBreaker(2, TimeSpan.FromMinutes(1));\nretryPolicy.Execute(() => circuitBreaker.Execute(command));\n```\nThere isn't currently a way to define a Policy that handles a variety of different exceptions in a variety of different ways, all in one single fluent statement.  However, the Polly Roadmap envisages the Polly Pipeline, which would allow any number of functionally-composed policies to be reduced to one Policy, thus:\ncsharp\nvar combinedPolicy = Policy.Pipeline(retryPolicy, circuitBreaker);\ncombinedPolicy.Execute(command);\nor (an alternative syntax under consideration):\nvar combinedPolicy = retryPolicy.Wrap(circuitBreaker);\ncombinedPolicy.Execute(command);\nI guess once the functionality for collapsing functionally-composed (wrapped) policies into one (as in the Polly Pipeline) was in place, it might be possible to create an on-going fluent syntax as follows - is this the kind of thing you had in mind?\n``` csharp\nvar myPolicy = Policy\n    .Handle()\n    .Retry(10, (exception, retryCount, context) => Reconnect());\n    .Handle\n    .CircuitBreaker(2, TimeSpan.FromMinutes(1));\nmyPolicy.Execute(command);\n``\n. @johnknoop Yes, this was delivered at Polly v5.0.0 and its eventual name was [PolicyWrap](https://github.com/App-vNext/Polly/wiki/PolicyWrap).  (We moved away from thePipeline` name as that suggested a one-way flow, but as you'll see from the diags in the PolicyWrap wiki, the execution flow through the PolicyWrap is very much two-way.). Hi @StefDotmailer . This:\n\nif the error is exactly \"error\", it will do exponential backoff; if the error is \"error, something unexpected happened\" it will do a regular retry\n\nsuggests the intention is two mutually exclusive cases. To get that effect, define the policy predicates to be mutually exclusive. Then, only one or the other policy (not both) will handle any return result:\nvar retryBackOff = Policy.HandleResult<string>(job => job == \"error\") /* etc */\nvar retryAllErrorsExceptQuoteErrorQuote = Policy.HandleResult<string>(job => job.StartsWith(\"error\") && job != \"error\") /* etc */\n\n\nTo explain why your posted code generated 9 retries: both the predicates job => job.StartsWith(\"error\") and job => job == \"error\" match \"error\". So both policies (correctly) handled the error. PolicyWrap does not apply mutual-exclusivity; PolicyWrap acts in a nested fashion by functional composition, so Execute places calls through the outer policy, through the next inner policy ... until eventually the next-inner thing to execute is your delegate.  Since both policies handled the execution result, you were (correctly) getting 3 x 3 = 9 retries.\n. @michael-wolfenden Thanks, but: none of this would exist if it weren't for the elegant simplicity of your original idea! :smile:  \nOur aim is to continue to grow Polly in that same spirit: each policy does one thing well, simple to configure, easy to comprehend.\n. Hey @Mittchel.  Thanks for your interest in Polly!  Great to hear about the usage within Xamarin - love to hear more details about the context within xamarin, if you can share :smile: \nA Polly retry policy will absorb handled exceptions and make a retry, for the number of retries you have configured.  After the number of configured retries are exhausted, the policy stops absorbing exceptions and rethrows the final (one-too-many) exception.  Rethrowing allows calling code to observe that last exception.\nReading your sample code, assuming _eventService.GetEventsWithError() is throwing more than 5 exceptions in a row, the 6th exception will get rethrown from within .ExecuteAsync().  Since you don't have any try/catch, this will get passed back up the call chain to whatever called GetEventsErrorRemoteAsync().  Likely, that exception being thrown back up the call stack beyond GetEventsErrorRemoteAsync() is causing your UI never to update.\nTwo ways you could avoid this.  Either:\n- Put a try { } catch { } around the call to .ExecuteAsync(), to catch the final exception; [or]\n- Use .ExecuteAndCaptureAsync() instead of  .ExecuteAsync().  .ExecuteAndCaptureAsync() traps any final exception for you, and captures the overall outcome of policy execution into a PolicyResult instance.  You can extract either (on success) the TResult from this, or (on failure, if interested) the FinalException.\nLet us know if that solves the issue for you! - or if any other questions.\nThanks!\n. Hey @Mittchel . Not sure the exact place you mean, in 'breakpoint on the events variable', but: It is the policy's operating code (invoked behind .ExecuteAsync()) which will rethrow the final exception.  \nAssuming private async Task<List<EventDto>> GetEventsErrorRemoteAsync() is being called with an await, the exception should bubble further up the call stack until something catches it (or not!).  If GetEventsErrorRemoteAsync() isn't being called with an await, the exception would get placed in the returning Task and the task placed in an IsFaulted state (which could cause it to seem to disappear, if not checked for).  \nYou could also possibly fall foul of an invalid cast, at (ApiException)exception (though a cast exception would be thrown if you did).  If you're confident the only exceptions you expect to receive / want to handle in the policy are ApiException, you could .Handle<ApiException>() at line 15, to preclude the invalid cast possibility.\n. Right.  I've not used Akavache or ReactiveUI, so may not be able to help there.  In general, there are standard ways to turn Task<T> into an RX Observable<T>, which will also cause any exception thrown within the Task to be emitted by the Observable: see http://www.introtorx.com/Content/v1.0.10621.0/04_CreatingObservableSequences.html#FromTask ! \nBut that link may be irrelevant to your needs, as the libraries you're using should be covering it.  Looking at the http://reactiveui.net/ front page, they seem to show ways of capturing exceptions thrown by the delegates you execute with ReactiveCommand.\n. Added extra diagrams to the wiki covering the full lifecycle of a retry request, including what happens when all trys expire.\n. Hi @PhilipAnthonyMurray  Thanks for your interest in Polly!\nWhat I think happening here is that the Polly retry policies declare the onRetry delegate as synchronous:  onRetry is of type Action<...> rather than Func<..., Task>.  It looks like you (we :smile:) are then falling foul of some 'helpful' (in this case unhelpful?) compiler magic which allows you to assign the async lambda to Action<...>.  \nAs the actual signature of the Polly onRetry delegate is Action<...>, Polly cannot await it, and calls it as onRetry(); rather than await onRetry();.  The delegate is probably therefore ~completing as soon as it has kicked off the background Task you .Run()~ (CORRECTION: returning as soon as it hits the first await) - without waiting for it to complete, as you observe - leaving Polly continuing to the next try of .ExecuteAsync(...) straight after. ... And all due to that compiler magic assignment of an async lambda to Action<...>! (which effectively seems to silently drop all the async/await behaviour without warning you) \n--- Background ---\nThis kind of gotcha with async void lambdas is described by the noted async expert Stephen Cleary in this article \n\nAsync void methods are tricky because you can assign a lambda like \nasync () => { await Task.Yield(); } to a variable of type Action, even \nthough the natural type of that lambda is Func.\n\nand this one\n\nOne subtle trap is passing an async lambda to a method taking an Action parameter; in this case, \nthe async lambda returns void and inherits all the problems of async void methods. As a general \nrule, async lambdas should only be used if they\u2019re converted to a delegate type that returns Task \n(for example, Func).\n\nand from other angles, by Stephen Toub of the relevant Microsoft team here\n(one of the subtlest areas of async imo!)\nEDIT: Another good discussion of this (number 4) and similar async gotchas: http://tomasp.net/blog/csharp-async-gotchas.aspx/ \nEDIT: And Stephen Toub nails it again as number 4 here: http://blogs.msdn.com/b/pfxteam/archive/2013/01/28/psychic-debugging-of-async-methods.aspx\n--- Background ends ---\nWhat to do?\nIt looks like an opportunity was missed to allow Polly policies to take fully async onRetry delegates when async was first introduced to Polly (prior App-vNext stewardship; and we have evidently not picked up and dealt with since).  \n@PhilipAnthonyMurray If I work on a fix for this over the coming days, would you be happy to trial it (see if it resolves your issue?), alongside obviously the full unit tests I put in place.\nI do (did?) also have a concern over whether we will be able to introduce this (two different forms of the onRetry delegate) without the compiler complaining about ambiguous method resolution, or without taking a breaking change for existing async users - which would clearly lead to a difficult decision.  However, the end of the Stephen Cleary article suggests we should be fine here:\n\nAs a closing note, the C# compiler has been updated in VS2012 to correctly \nperform overload resolution in the presence of async lambdas. \n\nClearly also, it would be possible for you to write a blocking onRetry delegate instead, but this is not ideal: let's see if we can do better in Polly!\nThanks\n. @PhilipAnthonyMurray Great, thanks for your interest and support.  \n@joelhulen @PhilipAnthonyMurray A couple of potential issues with this which we should work through:\n1: Visual Studio 2010 apparently will not handle the ambiguous method resolution of an async lambda between Action<...> and Func<..., Task>.  Since @joelhulen @lumirris we are currently exploring adding async support for .NET4.0 via Microsoft.Bcl.Async under #103 - and .NET4.0 is I believe available on Visual Studio 2010 - there is a potential issue for the small group of users who may be on both VS2010 and .NET4.0 who'd use the new package from #103.  \nFor this group of users, ambiguous async lambdas would I believe fail to compile.  There are viable workrounds however, as discussed here.  One can explicitly construct new Action(async () => { ...}) or new Func<Task>(async () => { ...}).  And we could name the parameters onRetry in one overload, and onRetryAsync in another, allowing users to select an overload using named parameter syntax.  \n@joelhulen Since these workrounds are necessary only for 2010 technology (assuming a small/diminshing group of users), I don't believe we should let this block moving onRetry to async for the wider user constituency - but views welcome.\n2: circuit-breaker state-change delegates: The case for/against allowing async/await for the onBreak / onReset / onHalfOpen delegates of the circuit-breaker is more complex.\nThe circuit-breaker state-change delegates intentionally run within the breaker's state management locks for the reason set out foot of here: that without this, in a high-throughput, multi-threaded scenario, the state implied by raising the state change delegate could fail to hold (could be superseded by events elsewhere) during the lifetime of the delegate execution.\nNow, it's well documented that mixing await and lock was originally debarred, as explained by luminaries Eric Lippert and Jon Skeet here . On the other hand, there are now workrounds for this: use SemaphoreSlim.WaitAsync() with a SemaphoreSlim of capacity 1, as described here; or the techniques here from Scott Hanselman or Stephen Toub again.\nAt this point, the jury is still out for me on the wisdom of permitting async/await for the breaker's state-change delegates - further reflection needed.  In general, a blocking / long-running circuit-breaker state-change delegate, since it necessarily runs within the breaker's locks, is a bad idea [will hit performance], since it would block all other operations through the circuit-breaker while the await was awaiting.  But it may be technically possible, caveat emptor.\n\nApologies for the long post, but some complex issues here which need a clear airing.\n. Complete final aside: I wondered why the compiler should do such a thing: silently allow an async lambda to be assigned to an Action when Func<Task> is the correct type - and couldn't immediately find any online explanation.  Hunching that it may have been to do with wanting to introduce interoperability between new async methods in the newer parts of the BCL, and some older parts of .NET (perhaps delegates on events fixed as of type Actions).  If anyone knows an explanation, shout! \nEDIT: It is to support async void event handlers eg for UI elements.\nKind-a shame the compiler drops the await functionality silently.  Maybe there is a compiler warning that could be elevated to a build fail.  @PhilipAnthonyMurray Did you get any compiler warning on this?\n. @PhilipAnthonyMurray I was able to reproduce the issue in a small unit test.  And the expected fix indeed makes the test pass.  \nI just pushed this fix for testing to https://github.com/reisenberger/Polly/tree/AsyncOnRetryDelegate .  It would be great (if you have availability) if you were able to pull that branch down to your local machine, compile, and test the fix also against your RefreshApiAuthentication() / GetBookingsApiCall() scenario.  Thanks!\nThe fix has been applied at this stage only to the RetryAsync(...) flavour of retry.  Before we are ready to nuget package this, some repetitive work needed to apply the fix to other retry flavours (on the assumption it tests good in the wild :smile: ).\n. @PhilipAnthonyMurray Thanks for the feedback re compiler warning!  On this, I've concluded (sadly) that the compiler gives no warning for assigning Func<Task> silently to Action.  My unit test exemplifying the issue gives no compiler warnings.  And your reduced sample gives no compiler warning, but still contains the async (ex, retry) => delegate, which must (with Polly 4.2) be undergoing such assignment. \nIf ...\ncsharp\n.RetryAsync(2, async (ex, retry) =>\n                        {\n                            await Task.Run(async () => await RefreshApiAuthentication(retry));\n                            System.Diagnostics.Debugger.Break();\n                        })\n... gave a compiler warning, I'd be interested in what it was (but not critical). \n. @PhilipAnthonyMurray No problem! (no urgency). And: thanks for your collaboration!\n. Similar fix for all other async retry variants now pushed to https://github.com/reisenberger/Polly/tree/AsyncOnRetryDelegate\n. Hi @PhilipAnthonyMurray . Many thanks once again for raising this issue!  We've a fix ready to release: let us know if you envisage having time to / are interested to test this against your original scenario in the next few days.  No worries if not: the unit tests clearly demonstrated, and demonstrate fixed, the issue.  Thanks!\n. A final note to record more accurately what the compiler is doing and why.  The nub is that an async method that has no return value can take either of the signatures:\ncsharp\npublic async void AsyncFooNoReturnValue1(...) { ... } // [1] : maps to Action<...>\npublic async Task AsyncFooNoReturnValue2(...) { ... } // [2] : maps to Func<..., Task>\nThe compiler can map an async lambda anonymous method async (...) => { /* no return value */ } to either of these (the async lambda itself does not and cannot indicate which is preferred).\nTherefore if, as library creators, we only supply Action<...> parameter types, the compiler, with no other option, will map an async delegate to form [1].  (We may, as library creators, have meant that we only wish to accept sync delegates.  However, as Action is essentially ambiguous - it could accept either a sync or async delegate - we do not unfortunately have the option to specify explicitly which we accept.)\nIf, as library creators, we supply overloads taking both forms (Action and Func<Task>), compilers from VS2012 onwards will prefer to resolve async lambdas to form [2].  (VS2010 will raise an ambiguous method invocation compile error.)\n(Libraries generally could also navigate this dilemma by only offering form [2]; for Polly however this would represent a breaking change, as [1] had already been in the wild for some time.)  EDIT: And many cases may only need a synchronous onRetry delegate anyway.\nThe problematic form [1] owes its existence (as I rightly surmised earlier) to a language requirement to support fire-and-forget void-returning event handlers wanting to use async functionality.\n. @PhilipAnthonyMurray Great, thanks.  Very many thanks for your collaboration!\n. Hey @PhilipAnthonyMurray  Thanks for your interest in Polly and for alerting this issue originally!\nWe pushed this fix out to keep Polly moving, and because the unit tests gave us clear visibility of the issue and fix.  However, very happy still to hear your real world feedback, and here still for any further assistance you may need!\nThanks\n. @PhilipAnthonyMurray Just reporting that new onRetryAsync delegates test good for us in the wild (no surprise but :smile:).  Just tested by adapting the most complex example in Polly-Samples.\nNevertheless happy for any feedback when you get this in place in your solution.\n. @PhilipAnthonyMurray Great. We were confident now this was watertight from our own tests, but great to have confirmation it's fixed your issue too!\n. Also fixes #109 \n. @fergusontom Thanks for calling that out (and apologies for any confusion caused!).  We'll clarify that shortly.  \nI'm assuming you're referring to the WaitAndRetry(...) examples in the main https://github.com/App-vNext/Polly/blob/master/README.md ? A quick search only brought up those examples for me - but let us know if you spied any others!\n(The Polly specs are in fact pulling this syntax out of https://www.nuget.org/packages/FluentAssertions rather than Humanizer, but some syntax from the specs obviously got copied into the Readme without explanation.  Agree it's a great syntax!)\n. Fixed via #108 \n. @SteveCote Very many thanks for this PR and for picking up this 'up-for-grabs' issue!\n- Could you rebase for the changes in 108 and (after it is merged; best wait till then) 112?  Rebasing notes here\n- You'll find 108 changed RetryPolicyStateWithSleepAsync.cs.  It's form is now very similar to RetryPolicyStateWithSleep.cs, so similar changes can be applied.\n- The current PR only adds the new onRetry delegates to the sync variants of .WaitAndRetry(...).  Similar changes should be applied to RetrySyntaxAsync.cs, to add the new onRetry delegates to the .WaitAndRetryAsync(...) policies too.  Note that async onRetry delegates come in two forms: Action<...> and Func<..., Task>.\n- It would be good to add some specs (tests) that the correct int retryCount is being passed to the new onRetry delegate.  An existing test (for same thing for non-waiting retry) provides a model: \n  Should_call_onretry_on_each_retry_with_the_current_retry_count().  Such tests for the new onRetry should be added for both sync (RetrySpecs) and async (RetryAsyncSpecs) versions.\nVery many thanks again for this contribution.  Please do come back to me if any clarification needed: we realise there are a lot of configuration overloads within Polly to navigate!\n. Hey @SteveCote Many thanks for picking off this 'up for grabs' issue!  \nAfter picking off the three minor things I marked with line notes, think this will be good to go! :rocket: \nDo you want also to:\n- changelog.md, polly.nuspec and polly.net40async.nuspec: Add text to each describing the addition, as release 4.2.4.\n- readme.md: Add to the retry and wait section of the documentation, to show example with the new onRetry overloads (after similar existing examples).\n- readme.md again: credit yourself in the acknowledgements.\n  (you may need to rebase again for joel's recent readme update)\nThanks!\n(@joelhulen normally updates gitversionconfig.yaml himself when he's ready to publish.)\n. @SteveCote You are right that some tests started failing after changing \n(exception, span, i, c) => onRetry(exception, span, context)\nto\n(exception, span, i, c) => onRetry(exception, span, c)\nWe should still do this.  (We should avoid the extra closure over context; the onRetry delegate to run should be defined only by the incoming variables passed to it.)\nThe additional problem (causing test failure) is that this constructor overload, when it chains up to the fullest constructor overload, is failing to pass the value of context it receives up to the fuller overload: instead it's passing Context.Empty.  Thus:\npublic RetryPolicyStateWithSleep(IEnumerable<TimeSpan> sleepDurations, Action<Exception, TimeSpan, Context> onRetry, Context context) :\n            this(sleepDurations, (exception, span, i, c) => onRetry(exception, span, context), Context.Empty)\nshould (with two necessary changes) become:\npublic RetryPolicyStateWithSleep(IEnumerable<TimeSpan> sleepDurations, Action<Exception, TimeSpan, Context> onRetry, Context context) :\n            this(sleepDurations, (exception, span, i, c) => onRetry(exception, span, c), context)\nThis applies here, and in the similar place in RetryPolicyStateWithSleepAsync.\nThanks for all your work on this!\n. @SteveCote @joelhulen This looks good to merge to me!  :+1: \n. Hey @jeroenwo !  I am travelling at the moment and haven't been able to test your code, but I think your code needs to take account of the different ways that await Task and Task.Wait() propagate exceptions.  \nWhen you wait synchronously on a Task (such as with .Wait() or .Result), exceptions thrown are always wrapped in an AggregateException.  However, when you await a Task, the original exception (if an exception is unhandled) is rethrown at the await (not wrapped in an AggregateException).  For a detailed discussion, see Stephen Toub on \u201cTask.Result\u201d vs \u201cawait task\u201d Exception handling.\nIn the async version of your code, you only .Handle<AggregateException>().  But your inner call documentClient.UpsertDocumentAsync(...) is presumably throwing some other exception (for discussion let's call it a CannotUpsertException).  Since the policy is only declared to handle AggregateExceptions, it doesn't handle the CannotUpsertException, and immediately rethrows it without retries, as you are observing.  \nThen (in the code you posted), within Main(...) you eventually have a .Wait(), which causes the CannotUpsertException rethrown up the await call stack, to be wrapped in an AggregateException at the point of that .Wait() only (perhaps making it look superficially as if an AggregateException was originally thrown all along - which I'm assuming is not the case).\nSo to fix: in the async version, just change .Handle<AggregateException>() to .Handle<CannotUpsertException>() (or whatever the inner work is throwing). \nIf you have a number of possible exceptions you want the policy to handle, use Polly's .Or<AnotherException>() syntax.\nPlease let us know if this solves the issue for you!  (Or equally if not! - as I'm travelling, I've only had the chance to run your code through the virtual machine in my head... :smiley: )\n. @joelhulen The Polly.Net40Async.bat | .ps1 | .cake build script was quick copy-paste of the main build script (w suitable adjustments) to keep things going while I on the road.\nIssues:\n- main Polly build and Polly.Net40Async build are separate scripts\n- each script clears down previous packages (incl. those of other build script)\nOptions:\n- publish new Polly and Polly.Net40Async packages from current scripts now\n- await time for me to integrate to one build script next week\n- somebody else integrate to one build script \n. Hi @SeanFarrow \nThis link suggests Task.ContinueWith(...) is available in .NET4.0.  You should be able to do something like:\nTask task = httpClient.GetAsync(url).ContinueWith(t => { /* some continuation code */ });\nHow are you looking to slot this together with Polly?  What's the overall goal?  Or, do you have some code draft that's not working/compiling, to help us see what you are looking to achieve?\n. EDIT: Yes, the package Joel mentioned is the one you want.  \n@SeanFarrow \nBoth .ExecuteAndCaptureAsync(...) and .ContinueWith(...) perform a similar function: both capture any exception thrown by an earlier-executed task into a result object which can be queried.  So, there is possibly little benefit in using .ExecuteAndCaptureAsync(...) and .ContinueWith(...) combined.  I constructed code to do it (happy to post), but it's unnecessarily double-layered for what it achieves.\nTo answer this another way, re your q:\n\ntrying to use the HttpClient.GetAsync(url) using polly, \nthen call a continuation with the result with is a HttpRequestMessage\n\n... this will not work directly [edit with ExecuteAndCaptureAsync], because the return type of ExecuteAndCaptureAsync is a PolicyResult<HttpResponseMessage> not an HttpResponseMessage.\nTo achieve a task-continuation where its TResult generic type is an HttpResponseMessage, I would suggest using the straightforward .ExecuteAsync(...) method with .ContinueWith(...), not .ExecuteAndCaptureAsync(...).  Something (in outline) like: \ncsharp\nPolicy retryPolicy = Policy.Handle<Exception>().RetryAsync(3);\nstring url = \"some url\";\nusing (HttpClient httpClient = new HttpClient())\n{\n        HttpResponseMessage response = await retryPolicy.ExecuteAsync(() => httpClient.GetAsync(url))\n                .ContinueWith(t => !t.IsFaulted ? t.Result : null)\n        // Do other stuff with response\n}\nThis is not intended to be a finished example, just to address your question of combining .ExecuteAndCapureAsync(...) with a task-continuation.  A more refined example might do something with response.IsSuccessStatusCode or response.EnsureSuccessStatusCode(), depending what you're trying to achieve.  \nDoes this help?\n. Thanks @SeanFarrow, glad it helped!.\nFor anyone reading in future or interested in how to use HttpClient.GetAsync() with HttpResponseMessage.EnsureSuccessStatusCode() with Polly, I put together this example (will add to wiki).  \nUsing a .ContinueWith() invoking EnsureSuccessStatusCode(), within the Polly ExecuteAsync(...) call, is a nice way to catch the mix of exceptions and http status codes indicating failure, that HttpClient.GetAsync() might generate.\ncsharp\nPolicyResult<HttpResponseMessage> responseResult = await retryPolicy.ExecuteAndCaptureAsync(\n                () => httpClient.GetAsync(url)\n                    .ContinueWith(t =>\n                    {\n                        t.Result.EnsureSuccessStatusCode();\n                        return t.Result;\n                    }, TaskContinuationOptions.OnlyOnRanToCompletion)\n                );\nComments:\n- In this case I have combined .ExecuteAndCaptureAsync() with .ContinueWith(), as the .ContinueWith() is being used to throw exceptions, not absorb them.\n- The use of TaskContinuationOptions.OnlyOnRanToCompletion avoids extra code to rethrow t.Exception from within the .ContinueWith() while preserving the stack-trace.\n. Hey @robertbaker.  This came up on StackOverflow recently, but I think the q has been deleted.  It's  very possible.  Configure a policy with an onRetry delegate.  Polly calls the onRetry delegate before the next try.  In the onRetry delegate, call your authentication method.\nThe code at the top of #107 gives an example.  [#107 uncovered an obscure compiler gotcha that led to an async sequencing issue, now fixed, but the code example matches your need I think!]\nLet us know if you need any further assistance!\nEDIT: The example in #107 is async, but you can also do this with sync policies.\n. @robertbaker  If an additional issue is that HttpClient returns 403 as a status code rather than throws an exception, HttpResponseMessage.EnsureSuccessStatusCode() can be used to make that an exception, as described here.  This provides a way of getting Polly to handle outcomes from HttpClient calls that might be either exceptions (eg timeouts) or status codes.  There's a sketch of an async example using continuations here.  EDIT: Or of course you can throw a specific exception only on 403 yourself.\nWe are looking at allowing Policies to handle return values as well as exceptions natively - see #14, and wider discussion in the Roadmap.  Any feedback you have towards this feature would be welcome!  Thanks.  \nUPDATE: The feature #14 is now delivered.  The main Polly readme describes much more elegant ways of handling exceptions and HttpStatusCodes combied.\n. @robertbaker No problem.  @PhilipAnthonyMurray was essentially working on sthg similar I think.  We are doing the same thing in-house and achieved this pattern (refreshing authentication on retry) against both straight https authentication and SAML authentication: but the pattern isn't any more complicated than outlined above.\n. @adamhathcock You raised OAuth and Polly on #90, see this thread #122. One pattern is to use the onRetry delegate (which gets executed between tries), so, in its simplest schematic form, something like:\n``` csharp\nvar authorisationEnsuringPolicy = Policy\n  .Handle()\n  .Retry(1, onRetry: (e, i) => RefreshAuthorization());\nauthorisationEnsuringPolicy.Execute(() => DoSomethingThatRequiresAuthorization());\n```\n. Closing historic issue.  Fully documented on wiki. @SeanFarrow .  At the moment there isn't a way within Polly to execute specific code after all retries have been exhausted. However, this is on the Roadmap as a feature we plan to add.  It's described within #80 and the Roadmap as a Fallback policy.\n- The Fallback policy would specify a lambda to execute (eg to provide an alternative value; or take other remedial action) if the main policy (retry/ circuit-breaker/ whatever) still eventually threw.\n- The Fallback policy could be wrapped around any other policy, as described in the Pipeline in the Roadmap, so that Fallback could eventually be combined with a wider range of transient-fault-handling techniques: cache, retry/circuit-breaker combined, throttle, timeout etc.\nPlease feel free to have a read of the proposed feature and let us know if you have any feedback!\nFor now, to execute code after all retries have been exhausted, you can either try-catch around your .ExecuteAsync(...) call to catch the final exception.  Or, use .ExecuteandCapture(...) and identify if there was a final exception from the returned PolicyResult.\nHope this helps! (and let us know if there is anything else you need assistance with)\n. @SeanFarrow  Great.  There is a lot of material on the Roadmap: contributions will always be welcome.  \nThe App-vNext team has some relatively developed ideas about how some of this functionality can be implemented (for example from similar in-house experience without Polly), but, like any OSS project, ideas of course also up for debate as the work evolves.\n@SeanFarrow  Would be very happy to hear more about the project you are looking to slot this into (to whatever extent you able to share). Helps us better understand perspective you bring (all new perspectives valuable...) and angle on any issues.\nAre there particular timescales you are looking to meet for the project you are working on?\nAt the moment next step is to unblock #14; relatedly, we probably need to split the Polly codebase between non-generic Policy and a generic Policy<TResult>, for most of the new-policy features on the wider resilience roadmap.  Many of these (Fallback; Cache; Handle Return Values) depend on operating to return a common TResult, and will compose as a Pipeline more coherently from a strongly-typed generic Policy<TResult>.  I am now well embarked on this (after a regular range of async refinements and circuit-breaker extensions since App-vNext took over the project Dec15), but it's also a relatively large piece of work.\n@SeanFarrow  I have a couple of major annual meetings to prepare for this week Wednesday/Thursday/Fri; hope to set out more about vision for these features after that.\n. Closing as duplicate of #80\n. @christopherbahr Thanks!  On a quick read this looks good - I'd like to have a little more time to think over the edge case/s, so give me couple days on that ... (agree there is the edge case you mentioned; and it probably pans out as you say)... Optimisations always welcome, though, so thanks!\nI also have some CircuitBreaker timing tets (testing 100000 calls through the breaker) which we put together when performance-testing implementation options for the new AdvancedCircuitBreaker: it produces stats for well-behaving underlying systems, frequently faulting systems, etc ... so I'll run the change through the performance-tester too and see what we get!\nYour optimisation also depends on the switch expression only being evaluated once ... I'd eat my hat if that wasn't the way it was implemented :smile: (and think remember reading that somewhere), but shout if you know different! \nThanks!\n. @christopherbahr Many thanks for this PR!  Squeezed in some time for performance-testing after the recent major feature work, and agree that this is a valuable optimisation to the hot path.  This commit contains an equivalent change to the new CircuitStateController, and we expect this to be released as part of #130 in the next few days.  I am not proposing we do any special workaround for the switch statement; I agree with your assessment of the edge case in your original post.\nThe next phase of Polly (have you seen the Roadmap?) is very much intended to support high volume / low latency scenarios, with new policies such as cache, fallback, and parallelism-throttle for bulkhead isolation or (if user requires) load-shedding.  If you are working in a high-throughput/low latency environment, now is a great time to provide any feedback you have or feature requests under the related feedback issue.  \nAlso continuing to develop the performance test bed for Polly: if you are able to share the kind of throughputs you are dealing with, whether sync or async, EDIT how much parallel contention, etc (post here or email me at software[at]reisenberger.net if you prefer), it might be interesting to put your kind of numbers through the test bed?\nThanks\n. Delivered in #130.  On Nuget as v.4.30\n. @pvmraghunandan This is now both code-complete and documentation-complete.  It is just undergoing our governance process of within-team code-review (by another AppvNext team member) before being merged and released.  I would expect it to be released within the next few days.\n. @pvmraghunandan I will try to get back to you on this within the coming day.\n. hi @pvmraghunandan. Could I make sure I\u2019ve understood the problem properly? (please correct me if I\u2019m wrong). \nIs the problem that you might have some WCF service offering a number of functions returning different types, and you want to apply some common fault-handling policies (eg retries) across the calls returning different types?  eg Something like the below schematically (I\u2019m omitting WCF attributes for brevity)\ncsharp\npublic class MyFooService : IMyFooService // a service exposed across WCF to some client somewhere\n{\n    public int Foo1(Guid id) { ... }\n    public string Foo2(Guid id) { ... }\n}\nFor example, perhaps at the caller you want to define some common RetryPolicy for MyFooService across these two calls with return different types? (int, string).  And then maybe some extra value-based fault-handling specific to each call? (like, null or 0 should also be considered failures and retried). \nIf this is not the class of problem, could you post a simple code example?\nAlso: are you seeking to apply the Polly policies on the service side (when handling the requests, perhaps because that has other vulnerable downstream dependencies), or on the client side? (when calling the service), or both?\nThanks\nEDIT: If the above example describes the kind of problem, I can see ways of dealing with this without a major restructuring of Polly, and without using object and casting.\n.  @pvmraghunandan Thank you for highlighting the question of applying a single policy to methods of different return types (such as possibly in a WCF service), with the strongly-typed Policy<TResult> form.\nThe move #129 to adopt strongly-typed policies Policy<TResult> was influenced by factors on the wider resilience roadmap: CachePolicy and FallbackPolicy in particular (and combining them in a PolicyWrap) only really make sense in strongly-typed forms.\nIf we stuck with only a non-generic Policy with generic Execute<TResult>() methods, and we did this:\n\nShouldnt we update logic to accept predicate during Execute()?\n\nwe would also have to move cache and fallback functionality into the Execute<TResult>() methods.  The cache and fallback functionality would have to be reduced (eg no onFallback delegate), and we would quickly have quite complex .Execute() overloads like:\n.Execute<TResult>(Func<TResult> executionFunc, Func<TResult, bool> shouldHandleResult, IResultCacheProvider<TResult> cache, Func<TResult> fallbackFunc)\nIf we then wanted to offer overloads in variants including/not including cache, fallbackFunc and shouldHandleResult (not everybody wants all all the time), quickly the number of overloads multiplies - on top of the existing already large number of overloads (see async forms).  This development direction for Polly felt unsustainable.\nStrategies for dealing with the large number of overloads almost all involve moving instead to a Hystrix-like Command class and setting properties to configure it, but that would inevitably be strongly-typed Command<TResult> too.\n. @pvmraghunandan To use policies of a common characteristic across calls returning different types without resorting to object and casting, one option is to add your own extension methods to Polly's PolicyBuilder<TResult> class.  (Polly's fluent policy-construction syntax depends on a public PolicyBuilder class, but this isn't usually seen because of the way the syntax encourages constructing a whole policy in one statement.)\nExtension method examples:\n``` csharp\npublic static PolicyBuilder WithStandardExceptionHandling(this PolicyBuilder builder)\n{\n    return builder\n        .Or()\n        .Or(); // etc - more detailed predicates as needed\n}\npublic static RetryPolicy WithStandardRetryPolicy(this PolicyBuilder builder)\n{\n     return builder\n        .Retry(1); // or whatever\n}\n```\nThen you can concisely construct policies with similar characteristics for different TResult-types, and with different specific handling for the TResult.\n``` csharp\nvar intVariantOfPolicy = Policy\n    .HandleResult(i => i == 0)\n    .WithStandardExceptionHandling()\n    .WithStandardRetryPolicy();\nvar stringVariantOfPolicy = Policy\n    .HandleResult(s => s == null)\n    .WithStandardExceptionHandling()\n    .WithStandardRetryPolicy();\n```\nDoes this help with your WCF case where you want common handling across different return types? \nEDIT: This extension-method principle could be extended in lots of ways.  For instance, to avoid having a separate extension method for each WCF service (and the fact that extension methods defines the policy in a different class from the service), you could define a more general extension method:\ncsharp\npublic static RetryPolicy<TResult> WithRetryPolicy<TResult>(this PolicyBuilder<TResult> builder, Func<PolicyBuilder<TResult>, RetryPolicy<TResult>> definesRetry)\n{\n    return definesRetry(builder);\n}\nThen a service-wide retry policy could be defined within each WCF service / service-caller as a property  Func<PolicyBuilder<TResult>, RetryPolicy<TResult>>.  Or func could be injected on service/caller construction - there are many possibilities - it depends what you are looking to achieve.\n. Hi @pvmraghunandan \n\nToday we can't achieve the common policy because if we want to apply result handling \nand when we say .OrResult(), the return type is PolicyBuilder\n\nPolicyBuilder<TResult> presumably? (A non-generic PolicyBuilder occurs for the non-result-handling policies.)  See if my earlier suggestions about extension methods chaining on PolicyBuilder<TResult>  help.\n\nWe have onRetry and other delegates also as independant because we want to tie up with our \nlogging engine where activityId and other related information is different for each call. \nWith passing onRetry during object creation, we cant achieve this\n\nThis can be achieved in existing Polly.  Configure the policy with an onRetry taking a Context.  Call .Execute() on the policy with an .Execute() (or similar) overload taking a Context.  The context passed in to the execute call gets passed to the onRetry.  \nHope this helps!\n. @pvmraghunandan No problem.  Re:\n\nResult Type is unknown at compile time so today we are casting back \nand using is/as operators to achieve this.\n\nIf TResult is unknown at compile time but is known at run-time, you could consider using MakeGenericMethod and MakeGenericType? - to make a strongly-typed Policy for a type you discover only at runtime. (Since in Polly the TResult-policies are constructed using static method calls rather than new-ing, that would be MakeGenericMethod more than MakeGenericType).  \nThese can effectively help invoke closed/bound generic methods or instantiate closed/bound generic types from their unbound equivalents at runtime.  It can be quite powerful, including working with nested generics.  And if, once ResultType is known at runtime, you expect to see the same ResultType/set of ResultTypes over and over, you can cache the results of the reflection rather than repeat it each time.\n(All this may or may not make things simpler, depending on what you are looking to achieve!)\n. Hi @pvmraghunandan . Thank you for the explanation.  Re:\n\nBut why cant we expect delegate as an Execute() parameter \nso that its up to caller to send whatever delegate he need. \n\nThe driver here @pvmraghunandan is coherence of the library and its API.  Since which exceptions to handle was already specified in Polly during the Policy configuration stage - not at execution - when we came to add handling results, it was considered more coherent for the library and API if the handling of results was specified in the same place.  I am not keen at this stage (unless there is significant community feedback) to split the specification of what to handle - exceptions and results - into two different places - configuration and execution. This seems overall like a less coherent product and API.   In essence we are guided/constrained by the product's history.  (EDIT: For clarity also not just an API choice: a re-code is also involved to move the predicates from policy-scope to execution-scope.)\nThere could of course be more significant rewrites - moving specifying both exception-handling and result-handling to execution-time - but this would be a significant change in API/approach and a significant rewrite - anything is possible, but it would have to be strongly motivated.  \nThe existing Polly team are of course limited in their time (ie have to decide where to prioritise), but always open to views: Do other people have views on the Policy construction API?  What works for you?  What doesn't?\n. @pvmraghunandan Given this:\n\nIn our case especially we deal with multiple external systems and each has multiple methods. \nSome will send specific error codes that indicates their transient failure and some will not. \nSo its upto implementation (In our case adapter) to send result handling delegate as i am \nalready invoking policyBuilder with type as specific type.\n\nI would then recommend the solution from my previous comment: Use extension methods so that you can state common policy characteristics in a central place for the service - or pass them in as a configuration func - but configure the variant parts (result-handling) as individually as you want for each endpoint.  This is (for sure) not the same as having a single policy for the service on which you can vary result-predicates at execution time, but gets you closer.\n. @Finity Thanks for this.  This will be fixed (in a slightly more optimised fix) in #130 (release v4.3.0), due out in the next few days.\n(This issue can be traced to v4.2.0)\n. @SamuelEnglard @mattwoberts / anyone else wanting .NET Core 1.0 rtm support: This branch on my local fork is the first beta of .NET Core 1.0 RTM Tools Preview 2 support based on all the issues mentioned above and @SamuelEnglard's earlier prototype (thanks!).  It should support  .NET Core 1.0 RTM based on Polly v4.3.0.\nThis Polly.4.4.0-beta-core10tpv2-0001--60e495a.zip contains the generated nuget packages.\n@SamuelEnglard @mattwoberts / anyone: Would you be able to test these Nuget packages in your .NET Core apps and advise if they work, or any probs?  Based on feedback @joelhulen or I may then promote them to betas on nuget.\n@SamuelEnglard As you said elsewhere, various package refs needed updating for RTM.  Feel free to comment if you see any other significant differences from what you have trialled.\nThanks\n. @ThreeSevenths Also alerting you on this based on #39: feel free to trial the new .NET Core 1.0 RTM support.\n. hi @SamuelEnglard ! Very many thanks for all your input (and contribs so far).  Let me know how the package testing goes!  \nAlso happy to hear if you spot any other differences in construction between the package I made (based on Polly v4.3.0) and your earlier prototype.  (I wanted to create a fresh package to get a feel for the latest tooling and see what June 27 releases might have added, broadly the end result seemed fairly similar to yours, but happy for all feedback! ...)\nRe:\n\nI only updated to support 1.3 as I don't think we to require 1.6.\n\nI was following Mapping the .NET Platform Standard to platforms, which seemed to label .NET Core app as should map to .NET Standard 1.6?\nOn the other hand, Polly itself (if you take out the SerializationInfo constructors for Exceptions) (as Polly.Pcl does), is fully PCL259 compatible, thus fully .NET Standard 1.0 compatible.  So we should also be able to go with a .NET Standard 1.0 package (which also supports the portable Xamarin etc targets).  I've posted a .NET Standard 1.0 package under #133.  I'd be extremely grateful if you could also feedback whether that package plays with your ASP.NET Core webapps (it should).\nThanks!\n(And @mattwoberts If you're able to join in on this too, all feedback gratefully received!)\n. Hey @SamuelEnglard @mattwoberts Did you have any time to try out the Polly .Net Core beta nuget packages posted in this thread? (Or the ones in #133 ?)  Thank you so much @SamuelEnglard for your kicking off with the first prototype! (the draft readme credits you as contributing).\n. @SamuelEnglard Completely understood.  Do give us a shout (or anyone else) if you do get a chance / have any feedback on the early packages, otherwise @joelhulen will probably push them out to nuget when he has some availability.\n. @mattwoberts Sure thing, we know how it goes :wink: All feedback gratefully received if you get the chance!\n. Closing in favour of the v5.0.1-release, which also supports .NET Standard 1.0\n. Early beta package for .NET Standard 1.0 support...\nThis branch on my local fork is a first beta of .NET Standard 1.0 support, taking account of issues mentioned earlier in this thread.  It should support  .NET Standard 1.0 based on Polly v4.3.0.  \nUnit-testing is (for now only) omitted in generating the Net Standard 1.0 package while awaiting ~~~support from unit-testing dependencies (see earlier comment)~~~ revised approach to unit-testing. , But the Polly codebase otherwise remains unchanged from the fully tested v4.3.0. \nThis Polly.4.5.0-beta-netstandar-0001--a9acf76.zip contains the generated nuget packages.\nThese packages are provided as early betas for anyone wanting to take their portable / Xamarin / Windows Phone etc apps straight to .NET Standard 1.0 with Polly: feedback gratefully received.  Packages may be promoted to nuget after suitable testing.\n@SamuelEnglard @mattwoberts : I would be exceptionally grateful if you were able also to test these Nuget packages also in your .NET Core apps and feed back?  Given  .NET Standard 1.0 offers wider support than .NET Standard 1.6 (==.NET Core 1.0), these packages should also work in .NET Core apps, per Microsoft doco.  \nMany thanks\n. @ry8806 great to see your :+1: on the Polly .Net Standard 1.0 nuget package.  We're keen to hear any feedback before putting the packages out more widely on nuget - the package is playing well for you then? any problems?  And would love to hear details of what kind of project you have it plugged into.  Thanks!\n. > Any chance for a beta package to get pushed to nuget?\n@joelhulen owns the nuget side for AppvNext, I'll see if @joelhulen is available for this?  Apologies for the delay.\n. Hi @adamhathcock .  The .NET Standard packages posted in this thread and #132 should support .Net Standard / Core RTM versions as released by Microsoft end June/beginning July.  We've labelled our nuget packages 'beta' because the tooling support for running the xunit tests against the package was fairly problematic when I tried it 02 July (haven't had a chance to look again since) (if anyone wants to work on this, please say), so I don't want to merge this to Polly master yet. The content of the packages is however no different from the previous fully-tested versions: the only change necessary for .NETStandard support was to remove the serialization across AppDomains for Polly's custom exceptions.\nIf it's about getting the existing packages in this thread and #132 on to nuget labelled as beta packages, I'll ping @joelhulen again about that.  Apologies for the delay on this.\n. Closing in favour of the v5.0.1-release, which also supports .NET Standard 1.0\n. @adamhathcock Short answer (for now) to a big question: yes, a great idea (to do Polly.Rx.Net); yes, it has been thought about; probably not the right time to introduce Rx into the Polly project at the moment.  (i'll aim to expand on this later)\n. To come back to this in detail: a great question, and one that we have explored at AppvNext at various times.  \nThere\u2019s just a great opportunity out there to take the spirit of Polly and apply it to Rx to make Polly.Rx.Net (Polly functionality fully implemented in the Rx API). Just a great idea.   If anyone wants to do this, or take a shot at starting it, shout.  It\u2019s not something I have time to take on at the moment (could divert, but at the expense of all the other forward functionality.)  Rx has some related implementations already built in, and people in the blogosphere have explored how to implement other parts.  \nShould existing Polly be rewritten with Rx behind, or new Polly features in the existing API be implemented in Rx because something similar in Rx already exists? A slightly different question. One observation is that the existing API we're building on (the fixed point in the current proj at least) is imperative and very much focused on inflecting the operation of a single Action or Func at a time.  Given that, not so sure it's a good fit (/makes for a readable implementation) say to fulfil functionality by generating an Rx Observable that\u2019s only ever destined to return one result?\nBut a proper, Rx-focused Polly.Rx.Net? That's a great idea. \n\nReally interested to hear more from the community also on this: is there a demand for an Rx-focused Polly? \n. Closing due to lack of activity/comment.. @apobekiaris Polly does not have any internal TaskSchedulers it manages, so there isn't (in that sense) any option to change the scheduler that Polly uses.\nIs the question how to unit-test (for example) a wait-and-retry policy which waits N seconds, without having the test actually take N seconds elapsed real-world time?  If so: All Polly policies which interact with time use an abstracted system clock.  This, and its properties, are public, so you can manipulate virtual time in tests to avoid real-world delays.  See any of the tests in the codebase which manipulate SystemClock, for examples.. Hi @orlandow \n\nIs there a way to achieve this?\n\nThe current approach to policy configuration produces immutable policies with private properties, so hooking into/appending to a previously-configured onRetry is not available.  \nThere could be future possibilities via Polly exposing the onRetry as a delegate that one could += extras onto. Although the signature of onRetry differs across retry policies, so it would probably have to be moved to an eventing model with some OnRetryEventArgs common to all types.  [NB The forward roadmap is quite full at the moment so I don't have a date/guarantee for this.]\nDo you have control over the code configuring the RetryPolicys?  Obviously a number of options if you do.  I like the injection (passing-policy-from-elsewhere) model - we do the same in some of our in-house uses of Polly where I work - but we wire the logging in where we configure.\n. @orlandow Here is another possibility which would achieve what you are after with the current Polly.  In the case where you have no control over the passed RetryPolicy, you can still inject some code around the delegate:\n``` csharp\npublic void YourInvokerMethod(RetryPolicy retryPolicy, Action action) // don't know your exact signature - making this up\n{\n  int tries = 0;\n  retryPolicy.Execute(() => \n  {\n    tries++;\n    if (tries > 1) { / log some retry info / };\n    action();\n  }\n}\n```\n. > Are the ExecuteAndCapture variants going to be supported?\nYes - good catch.  And since the implementation obviously checks for a cached value before executing the user delegate, makes no difference to the operation of the CachePolicy whether any fault from the func is rethrown/passed to more outer layers, or captured.\n. @SeanFarrow Sounds good!  Many thanks for your involvement and offering to work up a PR on this!  Please do come back to me questions / comments etc as they arise.\n. > I\u2019m able to start working on this at the end of the month\nSure @SeanFarrow .  Thanks for all your support and involvement!\n\nWhat caches do we want, I\u2019m thinking, Redis/Memcached, and the .net memory cache \nas well as maybe a disc based cache, with the memory cache being the default. \nAny other caches/thoughts?\n\nAll sound like good options!  \nAnd with the proposed IResultCacheProvider<TResult> interface, people can of course easily implement others.\nGiven we'd likely want to avoid taking dependencies on all these in the main Polly package, the individual cache implementations (default memory cache excepted) would probably go out as separate nuget packages Polly.Cache.Redis, Polly.Cache.Memcached etc, do you think?  Unless they were each individually so small (in terms of code lines) that providing a wiki page for each was just as much an option - to decide later?\n. @community : other caches you'd like to see supported?\n. @SeanFarrow All sounds good.\nOnly thought: maybe the default MemoryCache option (and IResultCacheProvider<TResult> interface) can just be part of the main Polly package, so that the CachePolicy (based on the MemoryCache default) works out-of-the-box with just the main Polly package.  Yes, MemoryCache is part of the runtime at System.Runtime.Caching.MemoryCache\n. Good question.  Per #142 we will discontinue .NET3.5 support from Polly v5.0.0, as a number of the other new policies require facilities not in .NET3.5 either.\n. Hey @SeanFarrow . Hmm.  Seems from the github instructions I can't add you with the assignees button (same for Jerome and Bruno) because its scope is limited to AppvNext org members (since AppvNext also broader than Polly, not my position just to add you to AppvNext).  No reflection on the importance of your contribution to Polly (great to have you involved!).  Consider this assigned.  Added the in progress label to indicate that it is spoken for!\n. Hey @SeanFarrow Great questions.  What were your thoughts?\nSome thoughts:\n\nGiven we're supporting async variants of execute, should we have an async cache provider as well?\n\n[1] Yes good call. Polly having an async cache provider so that async executions through Polly can take advantage of where 3rd-party caches have (mature/stable) async APIs \u2013> we should do that.  Feels like two separate interfaces in Polly for sync and async providers, ie IResultCacheProvider<TResult> and IResultCacheProviderAsync<TResult>? That what you thinking?  Async interface sthg like:\ncsharp\n// namespace Polly.Cache\ninterface IResultCacheProviderAsync<TResult>\n{\n   TResult GetAsync(Context); // should return: Task<TResult>\n   void    PutAsync(Context, TResult); // should return: Task\n}\nNB If you think the design of the IResultCacheProvider/Async<TResult> interfaces can be refined, feel free to say.  \n[2] The config overloads .CacheAsync<TResult>(...) configuring Polly\u2019s async cache policies should probably provide options to take either a sync or an async cache provider tho.  Because there might be some cache providers which only have sync APIs but we still want to offer them to async cache policies? (MemoryCache.Default is in this category?) \nSo:\ncsharp\n// Async policy taking async cache provider\nCachePolicy<TResult> asyncCachePolicy = Policy\n  .CacheAsync<TResult>(IResultCacheProviderAsync<TResult> cacheProviderAsync);\n// Async policy taking sync cache provider\nCachePolicy<TResult> asyncCachePolicy = Policy\n  .CacheAsync<TResult>(IResultCacheProvider<TResult> cacheProvider);\n\nRe:\n\nif the cache doesn't support synchronous functionality, what should our default position be?\n\nAgain, really interested to hear your views.  Thinking aloud from my side:\n[3] The config overloads configuring Polly's sync cache policy should probably only take sync cache providers. IE just:\ncsharp\n// Sync policy taking sync cache provider\nCachePolicy<TResult> cachePolicy = Policy\n  .Cache<TResult>(IResultCacheProvider<TResult> cacheProvider);\n(The opposite \u2013 providing  an overload for a sync cache policy taking an async provider \u2013 feels like creating a potentially confusing API.  Particularly, there\u2019s a risk people would mistake that syntax for giving them the benefits of async behaviour, when it\u2019d not be: it\u2019d have to be blocking on the calls to the async cache provider to bring it into a sync policy/sync call, no?)\n[4] But we could allow the use of third-party caches with async-only interfaces, in Polly\u2019s sync CachePolicys, if desired, by providing an implementation fulfilling Polly\u2019s IResultCacheProvider<TResult> sync interface, just .Wait()-ing (or equiv) on the async calls.  (And NB documenting that this is what it does!).  Arguments for / against doing that?  Doing it that way round, at least there\u2019s no mistaking from the API we provide that you\u2019re getting blocking/sync behaviour.\nHmm.  The choice of C# clients for some of these caches has moved on since I was last involved, in some cases.  Which of the 3rd-party cache's are currently offering an async-only (no sync) API?\nThoughts on all this?\n. > In my mind the AsyncCachePolicy should \n\nreturn a Task and Task for get/put methods respectively.\n\nOops on my part: yes definitely!  \n(more on other q later)\n. Hey @SeanFarrow .  Great to have all this on the cache policy!\nRe:\n\nhow do we want to handle the conversion from the cache to the TResult type?\n[...] should we offer the capability to define a delegate/lambda, or a conversion interface?\n\nWhere were you thinking this would sit in the architecture?  As part of the CachePolicy configuration overloads, or in the IResultCacheProvider implementations?\nMy instinct is to keep the main CachePolicy configuration overloads simple-as-possible, ie we have the TimeSpan varieties plus:\n.Cache<TResult>(IResultCacheProvider<TResult> cacheProvider) [and] \n.CacheAsync<TResult>(IResultCacheProviderAsync<TResult> cacheProviderAsync)\nrather than extend those with additional:\n.Cache<TResult, TCachedFormat>(IResultCacheProvider<TResult> cacheProvider, ICacheValueFormatter<TResult, TCachedFormat> cacheValueFormatter) [etc] \n(The formatter probably makes sense for some kinds of cache but not others.  And: IResultCacheProvider<TResult> cacheProvider feels like the correct scope of interface to configure a CachePolicy ... for the policy to use the cache, all you need to know is that you can get and put in and out of it ... if some cache implementations prefer to compress or map to a more cloud-friendly format, that feels like a cache implementation concern. )\nSo thinking of it structurally as a cache implementation concern, my instinct is for the transform-for-caching functionality being part of IResultCacheProvider/Async implementations where needed, config'd on them where needed.\nSound sensible? / can you see disadvantages? / or just stating the obvious??\n:+1: re conversion interface.  If we went as above ... and if there were a group of cache implementations (cloud caches?) where this approach might be particularly useful, one could still eg structure that with an abstract base class taking a conversion interface like you say, and some cache implementations deriving from that ...  \nFurther thoughts? (You deep in and may see other angles! )\n. hey @SeanFarrow Great qs.  Completely with you about needing conversion funcs rather than new-ing items out of cache.  (Defined on an ICacheOutputConverter<TResult> interface or similar like you suggest sounds good!) \nHow do you see this:\n\nwe could put an ICacheOutputConverter interface as part of the get/put calls, \ndefaulting to null. If the converter is null we just use the default which does a new T. \n\nlooking in actual code?  We'd need to avoid the various gotchas flowing from having optional parameters in interfaces (like the default values in the interface taking precedence over values in any implementations of the interface, if the call is being made against the interface not an implementation), but maybe that is not what you were thinking anyway?\n. > how about having a SetCacheOutputConverter on the cache interface?\nMutable policies by property-injection/setter-method injection a possible trap for the unwary in highly concurrent / multi-threaded scenario?  (Setting output converter then executing not atomic; risk some thread sets the cache output converter while another thread is mid executing?).  (Might not be the way we envisage it being used, but opens up the possibility)  \nConstructor-injection somewhere (resulting in immutable policy) safer?  ICacheOutputConverter<TResult> could perhaps be constructor-injected into the class fulfilling IResultCacheProvider/Async?  What do you think?\n. > what if I want a different converter per type?\nGood point!  \n\nWe will need to support passing in an Ienumerable of converters.\n\nHmm. Were you thinking this maybe isn't ideal?  Could we do better somehow?\n.\nI am wondering if one of us throwing together a quick class/interface diagram (as a 'straw man' ...) would help at this point? (getting hard to envision sentence-wise).  A class diag to pull about could help sort out the different components, role they play and their multiplicity/scope.  \nGreat to have all your deep input on these caching qs!\n. @seanfarrow  Stepping back and thinking about converters-for-caches, I wonder if we are missing something simple: just a minimal adapter pattern?\nAssuming the previous IResultCacheProvider<TResult> and (for discussion; say if you think different) ... a format-conversion interface like below:\ncsharp\ninterface ICacheFormatConverter<TResult, TCacheFormat> {\n    TCacheFormat Encode(TResult result);\n    TResult      Decode(TCacheFormat cachedValue);   \n}\nFormat converters could be provided via a lightweight adapter:\n``` csharp\npublic class CacheWithConversion(ICacheFormatConverter converter, IResultCacheProvider wrappedCache) : IResultCacheProvider\n{\n    public TResult Get(Context context)\n    {\n        return converter.Decode(wrappedCache.Get(context));\n    };\npublic void Put(Context context, TResult result)\n{\n    wrappedCache.Put(Context, converter.Encode(result)); \n}\n\n}\n```\n?\nIf this still doesn't seem to join with your thoughts on cache providers so far, then possibly we have a different vision of how the contributing classes interact and their multiplicity: let's dig deeper if so.\n(Not saying this is the only solution - there could be others - but one way to deal with the multiplicity problem (\"different converter per type\") without any enumerable?)\n. Hi @SeanFarrow .  Re: \n\nI had visions of people being able to supply the cache to wrap the converter with at runtime.\n\n(I haven\u2019t quite followed here.  Do you think the lightweight wrapper proposal is good in this respect, or is there an at-runtime capability we are missing?)\nRe:\n\nWith your proposal, wouldn\u2019t we need converters for each cache type? \n\nI am wondering if some of the questions around multiplicity are stemming from the original proposal for the IResultCacheProvider<TResult> to be strongly-typed.  \nAre you thinking that rather than IResultCacheProvider, the cache provider interface could be non-generic?\ncsharp\ninterface IResultCacheProvider\n{\n   object Get(Context);\n   void    Put(Context, object);\n}\nand thus the converter interface only ICacheFormatConverter<TResult>?\n(just wanting to understand clearly at this point- can then think through in context of rest of design)\nThanks!\n. Re:\n\nI think if we use a non-generic cache interface, this would make the converters easier\n\nThanks @SeanFarrow, this is well worth thinking about .  I now need to spend some time on the PolicyWrap, to explore mixing strongly-typed/generic and non-generic policies, which is related.\n. @SeanFarrow , re:\n\nWhat I\u2019m thinking is that a converter would know what type it converts to, \nand has a CanHandle message\n\nHow does the CanHandle method(?) come into play?  Does the CanHandle method imply a list of converters registered somewhere (for example on the CacheProvider), that some cache logic tries in turn until it finds one that 'can handle' in the context of the execution-in-process?\n(If the converter was wrapping the cache provider supplied to CachePolicy, per my example a day or so ago, a  CanHandle method wouldn't be necessary? - it just applies because it is part of the cache policy for that call.)\n. @SeanFarrow I'm feeling the need for some code samples / a 'straw man', to get a clearer shared understanding of any proposal being discussed.\nI am putting something together in a repo entirely separate from Polly.\nFeel free also to set any architectural sketch down in code! (it would give comparative perspectives to discuss)\n(All Polly activity has to fall outside work time for me, but pushing this along - it would be good to progress this feature!).\n. @SeanFarrow This branch contains a proposed cache architecture for Polly emerging from our discussion.  \nTo summarise its take on various points discussed in the past:\n- It allows for a non-generic CachePolicy which can generic .Execute<TResult>() for any TResult, rather than (as was once mooted) forcing every CachePolicy to be a strongly-typed CachePolicy<TResult>.  This will allow for more re-use of the same CachePolicy instance across multiple PolicyWraps / calls returning different TResult. [*]\n- It does no-op/pass-through (rather than throwing exception), as @drewburlingame suggested, where the CachePolicy is  applied (perhaps as part of a wrap) to a void-returning Action\n- It maintains separate ICacheProvider and ICacheProviderAsync interfaces rather than combining them.  Segregating the sync/async interfaces means we enable but don't force implementers to provide an async-over-sync or sync-over-async implementation if desired (for the cases where underlying cache supplies only one of sync or async).\n- The mapping from execution Context to cache key is segregated into a new, separate interface ICacheKeyStrategy.  A DefaultCacheKeyStrategy is provided, taking Context.ExecutionKey as the cache key, but users can implement their own ICacheKeyStrategy if they want to form a key in a more sophisticated manner from context data.  A good example might be Polly protecting 'get-by-id' style calls to an underlying db, where cache keys including the record id might be desired.\n- It takes the decorator-pattern approach to applying transformations (base64; zip; strip-sensitive-user-data; etc) which might be desired for items going in/out of cache.  The decorator-pattern allows users to functionally-compose (wrap) several such transformations together where needed; and simply use the result as another ICacheProvider.\n. @SeanFarrow It should have all the tests in the v5.0-alpha branch, as it was a recent sub-branch off it.  Can you name a missing test, and I'll look more deeply?\n. @SeanFarrow Re branching, I think we can merge it into v5.0-alpha as soon as you confirm you also like / happy with architecture. I will raise a few additional qs for reflection tomorrow\nRe architecture for implementing individual caches, I think we had then discussed packaging  (... /cc @joelhulen I want you to be aware of this too ...) :\n- separate packages for individual cache providers, such as Polly.Cache.Redis.  This would eg contain a Polly.Caching.RedisCacheProvider (fulfilling Polly.Caching.ICacheProvider) and anything associated.\n- possibly a central Polly.Cache or Polly.Cache.Core package which might provide some common facilities such as cache-mappers we deem useful across a range of cache providers.  Or perhaps those could simply be kept in the core Polly package?\nViews on the package structuring welcome.\n. @SeanFarrow I'll aim for a merge into the v5-alpha branch after work hours today.\nTwo questions:   (feedback from anyone as we proceed welcome)\n[1] The architecture leaves items-to-be-cached as object (ie ICacheProvider is non-generic), in order to avoid forcing users to create a separate ICacheProvider<TResult> instance (and thus a separate CachePolicy<TResult> instance) for each TResult type they want to handle.  This corresponds to many cache interfaces (eg MemoryCache) similarly just taking object, and promotes easier reuse of a CachePolicy instance: it might feature in a PolicyWrap used across multiple TResult types.  \nA downside is that this loose-typing leaves the signature of mappers in MappingCacheProvider as mapping between object and object.  \nWe should keep considering whether ICacheProvider<TResult> should be added: feedback welcome from anyone engaging with this.\n[2] Naming for mapper methods: The MappingCacheProvider class currently has PutMapper() and GetMapper() as the names (respectively) for the methods mapping values before placing in the cache, and after getting back from cache.  Suggestions for better names welcome.  I had Encode/Decode at one point...\n. @SeanFarrow  Re:\n\ncould we not have a wrapper type, or do something like outcome.net does?\n\n... I haven't quite followed: can you elaborate? Or, small code sketch?\nI have overnight worked up a version adding in a generic ICacheProvider<TResult>, strongly-typed mappers, and an .As<T> syntax similar to Redis's, to provide a light wrapper and frictionless transition from non-generic to generic where needed.  I'll push this later today for consideration.\n. @seanfarrow  I hadn\u2019t seen the existence of the generic variants as creating code duplication.  They just offer strongly-typed variants for those who want to code that way.  For instance, they allow users to code a MappingCacheProvider<TNative,TMapped> if they want, rather than the mappings object<->object (or having to code if (TResult is TypeOfInterest) { /* do mapping stuff */ }) implied by a non-typed ICacheProvider.\n- You\u2019d still only code one ICacheProvider implementation for each cache implementation.  eg RedisCacheProvider : ICacheProvider\n- The .As<TResult> extension method would provide a lightweight wrapper to return a ICacheProvider<TResult>, if wanting to work with a strongly-typed variant, eg to work with strongly-typed mappers.\n- Similarly, the Policy.Cache<TResult>(ICacheProvider provider) config overload will create a strongly-typed CachePolicy<TResult> if desired.\nSome users will prefer to work with a CachePolicy<TResult> (gives Visual Studio type-binding/intellisense between the various type-bound usages of Polly they might be combining).  \nOther users will prefer to work with a non-generic CachePolicy that they can use across all types, but they don\u2019t get the IDE-time type-sensitivity, or strongly-typed mappers.\nIn branch Cache-architectureTypingExperiment, I pushed this code which allows for both non-generic and generic variants.\n[ EDIT: branch shows changes only for sync forms while discussion; easy to add similar async. ]\nWhat do you think?  Where shall we go from here?\nVery open to other suggestions, but I may need to see some more worked code sketches to understand what you may be thinking of?\n. Re:\n\nWould it be better to have different types for input/output mapping from a cache[...]?\n\nAn advantage of both mappings (the mappings both ways) in the same class (as currently) is that - especially when strongly-typed - the combined interface forces users to write both mappings as a reciprocal pair.  If mappings each way are in separate classes, users could write and unwittingly combine completely unrelated mappings? So for me, it feels less coherent to have them in separate classes? (unless I've misunderstood something)\n. @SeanFarrow Also meant to add: happy to do a skype call if that easier/quicker to work through some of this.\n. @SeanFarrow Thx for the very productive skype call around caching.  The CachePolicy architecture has now been rebased against the latest v5.0-alpha, as discussed, in this branch: https://github.com/App-vNext/Polly/tree/v5.x-cache-alpha\nCommunity: We are initially planning targeting the following (pluggable) Cache providers for the CachePolicy:\n- in-memory (ie MemoryCache or similar)\n- on disk \n- Redis\n- MemCached\nOther cache providers you would like to see supported?  Please comment on this issue, or join the conversation on slack:  www.thepollyproject.org \n. @perfectsquircle Yes, among all the other features that got delivered at v5.0, this got left behind.  I've wanted to take forward, but it's been behind other things: contribution would be very welcome!\nWe have quite a developed architecture (thanks also to @SeanFarrow !), so the main thing we need now is  some first cache provider implementations to plug into that. I've just re-based the architecture against latest Polly / stuff I'm about to release.  Mini tour:\nYou construct a CachePolicy specifying:\n\nITtlStrategy: defines TTL for the items being cached by the CachePolicy.  Various implementations already written.\nICacheKeyStrategy: defines what key to use to Get/Put in the cache. The default strategy is based on a value in the Context passed  when .Execute(...)-ing on the policy.  Users can write more elaborate strategies if they want (I will blog examples).\nICacheProvider: a simple Get/Put interface for any cache provider Polly could use.  ICacheProviderAsync, similar interface for async.\n\nSo a typical cache might be configured something like:\nPolicy.Cache(\n    myCacheProvider, \n    TimeSpan.FromHours(1) // or more specific ITtlStrategy\n     /*, custom cache key strategy if desired */)\n\nThis test shows the basic usage.\n\nSo we need to implement some ICacheProviders.  @perfectsquircle Are you interested in in-process/local caching? (eg MemoryCache, disk cache), or more cloud-caching (eg Redis) or ...?  Any contribution in any of these would be welcome!  Even just an initial ICacheProvider implementation based on System.Runtime.Caching.MemoryCache, would be enough to launch the feature.  \n\nICacheProvider implementations will often depend on third-party libraries, and we didn't want the main Polly package to take those dependencies, so each ICacheProvider would be delivered as a separate Nuget, built out of a separate github repo.  \nThere are skeleton repos which you (/anyone interested in contributing!) can fork for MemoryCache, disk, Redis, etc.  We can make new repos for any other cache provider people want to support.\nWe'd need a build script for each of those repos to run tests and make the nuget package (I can help  if needed/useful). \n\nThe architecture also envisages support for serializers like Protobuf etc: let me know if you have any interest in that, and we can discuss further.  Otherwise let's leave for now.\nI am very available for further help / guidance, if you want to work on this!  Any of the above you'd be interested in tackling?  (And: thank-you!)\n. @perfectsquircle Great!  \nI made a start on a skeleton Visual Studio solution, build file, Nuget Packager etc for MemoryCache repo early this morning.  I can probably push that to github in about an hour's time ...\n\nI suppose it would be sufficient to target .NET Standard 1.0 for these plugins?\n\nAs low a .Net Standard version as we can get away with.  It looks from package search as if lowest .NET Standard for MemoryCache might be .NET Standard 1.3.  Fine if that's the case.  Although the core Polly targets .NetStandard 1.0 (soon to change to .NetStandard 1.1 when we release #231), it shouldn't be a problem to make MemoryCache repo target .NET Standard 1.3 instead.  The range of cache providers we're targeting will inevitably mean some have differing target support - delivering them through separate nuget pkgs will let us deal with that.. @perfectsquircle At https://github.com/App-vNext/Polly.Caching.MemoryCache, there is now a repo ready to fork and develop on.  \nTL;DR All we need to do now is start developing the Polly.Caching.MemoryCache.MemoryCacheProvider : Polly.Caching.ICacheProvider within the Polly.Caching.MemoryCache.Shared area of this repo, and specs in SharedSpecs.\nI put in a dummy class and test only to test the build script (build.bat) was working: can be deleted.  \nThe repo intentionally keeps the three-target layout (.NET4.0, .NET4.5 and .Net Standard) that Polly has, for now.  Theoretically we could drop .NET4.5 as a separate target and have .NET4.5 consumers reference .Net Standard, but targeting NetStandard from NetFramework is very noisy until Microsoft (hopefully) fix this in .Net Standard 2.0.  \nFor MemoryCache, you may have to change the .Net Standard 1.0 package to target .Net Standard 1.3, if package search was accurate.  (I left it at .Net Standard 1.0, so that this commit could be a useful master for other cache providers).  \nFinally, to reference the interface Polly.Caching.ICacheProvider, you'd need to be able to reference a Polly nuget which includes it.  Which obviously isn't public yet.  So the procedure would be clone \nhttps://github.com/reisenberger/Polly/tree/v5.1.x-cache-rebase locally, run its build script, and reference the Polly nugets the build script places in the artifacts\\nuget-package directory.\nPhew - but that gets us a baseline to develop on!\nLet me know if makes sense / whatever questions - whether around tooling or MemoryCacheProvider intent.\nHuge thank you for your contribution!  \n. @joelhulen I have pulled the latest Cache rebase down onto this branch on App-vNext/Polly.  Build from this branch will publish an appropriately tagged pre-release Polly build which you can push to nuget.\n@JoeBrockhaus : @joelhulen plans to push the above to Nuget as a pre-release.\n@JoeBrockhaus We would welcome contributions if you are able to contribute to Polly cache implementation - let us know what you would be interested in doing!\n[ I can get back to CachePolicy myself likely in the second half of June. ]. Hi @SeanFarrow .  Re:\n\nI've just been looking at the memory cache, we can't provide an async api, as one does not exist. Does anyone see a problem with this?\n\nI don't think this a significant problem.  We can simply write an implementation for CacheAsync(...) that addresses a sync cache provider instead of an async one, at this line (and similar).  It may mean a few extra configuration overloads, with the compiler selecting the right overload.  We can add this when we next visit the cache architecture.. @dweggemans The caching feature is expected to be released in September.  \nThis branch https://github.com/App-vNext/Polly/tree/v5.3.x-cachebeta contains the latest caching architecture, ie the core classes within Polly to support CachePolicy.  The build script will generate locally a nuget package for same.\nThis repo https://github.com/App-vNext/Polly.Caching.MemoryCache contains a beta-release of an ISyncCacheProvider and IAsyncCacheProvider implementation for MemoryCache.  The build script will generate locally a beta nuget package for same.  /cc @SeanFarrow \n@dweggemans : Are there particular cache providers you are looking to support? Community contributions to support new cache providers will be welcome: The required interfaces to implement (ISyncCacheProvider and/or IAsyncCacheProvider) are relatively straightforward.\nPolly contributors, eg @SeanFarrow , also already have a range of distributed cache providers in mind.  . Closing via #332 \nCachePolicy has been merged into the master branch, for release shortly as part of Polly v5.4.0.\nThe first cache provider implementation to go with CachePolicy - based around .NET's in-built MemoryCache - is available at: https://github.com/App-vNext/Polly.Caching.MemoryCache.  \nThe two will be released together to nuget, as soon as we hook up the build and nuget feed onto https://github.com/App-vNext/Polly.Caching.MemoryCache.  /cc @joelhulen \nDoco at: https://github.com/App-vNext/Polly/wiki/Cache. @brunolauze @mfjerome Thank you for offering (in off-github discussion) to work on this feature: I've just added you (virtually) as assignees :wink: . Please (and anyone else interested) come back with any further thoughts/questions...\n@brunolauze It may be easier to work on the async variant first, as the cancellation support is already in place for async.\n. @brunolauze Re:\n\na more dynamic way to provide timeout than just TimeSpan, just a Func would be good enough\n\nThis sounds like a very interesting idea, I'll have a deeper think about it!\n. Hey @brunolauze \nI am happy (I think this is the route you are suggesting) if our conclusion for now is:\n[1] We do not at this stage enforce the use of CancellationToken overloads on sync calls.  (IE We do not throw InvalidOperationException or similar on timeoutPolicy.Execute( /* a sync action not taking a Cancellationtoken */ )\n[2] But we do support (and recommend!) the use of CancellationToken overloads on sync calls.  (NB This will require adding overloads taking CancellationToken to the sync .Execute/AndCapture/Async(...) overload collection, and amending the sync engine of every existing (retry; circuitbreaker; others upcoming) to support cancellation.  Either you or I can do the work of weaving CancellationToken into the rest of sync Polly - discuss later, unless you already close to it? - it's fairly routine and there is a pattern to follow from use of CancellationToken in async overloads and policy engines, but it does touch a lot of code.)\n[3] We document very clearly the risks of wrapping a sync action not supporting co-operative cancellation in a timeout.\n\n(Discussion: I wanted to 'put out there' in the proposal the idea of actually throwing on invoking a sync action without cancellationtoken through a timeout policy, to gauge reaction, but per all our comments so far, it does feel quite aggressive, and there will always be legacy code which can't support it, so people would only end up with an (ugly) fake cancellation parameter anyway.  So current conclusion: permit, but document risks clearly!)\n. @brunolauze Many thanks for all this!  I will hope to review and provide comments in the next few days!\n. @brunolauze, Thank you for getting stuck into these policies.  Some comments for taking  Timeout forward:\nThe same comments as for Throttle apply about being able to simplify:\n- Timeout is non-exception-handling, so exception and result predicates can be removed, and syntax be static methods on Policy\n- State is per-policy, so the policyStateFactory and related TimeoutState classes can be removed\nCreateLinkedTokenSource(): The idea was to link the user's passed-in cancellationToken with a CancellationToken set to auto-cancel after the timeout period. That combined token can then be passed downstream meaning all downstream code (wrapped policies or the user's delegate) gets the benefit of co-operative cancellation from either the user's cancellation token or timeout.  Adapting from a concise receipe from Stephen Cleary\u2019s Concurrency Cookbook (great book btw!): \ncsharp\nvar timeoutToken = new CancellationTokenSource(timeout).Token;\nusing (var combinedCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken, timeoutToken))\n{\n    return await action(combinedCts.Token).ConfigureAwait // etc\n    // needs some try-catch (OperationCanceledException) around the above line and throw the TimeoutException if the OperationCanceledException is due to timeoutToken\n}\nOnce the predicates go, the return default(TResult) should disappear from the ends of the implementations?  The only exit paths should be return the result of the downstream delegate, throw the timeout exception, or let other exceptions propagate back to the caller.\nAsync implementation: we need to use async/await throughout (rather than eg BeginInvoke), so that we can honour continueOnCapturedcontext on the awaits.\nSync implementation:  Did you have thoughts on Task.Run()/StartNew() versus BeginInvoke()?  I suggest we should be with Task.Run() for conciseness, modernity, and some benchmarking suggests it is faster (it would be nice to do our own benchmarking too - perhaps something for later). \n@brunolauze What do you think?  Are you happy to take forward per above?\n. Hi @brunolauze. Many thanks for all your contributions and the article!\nI think we are thinking along the same lines here: the StackOverflow article is very much in line with my original proposal.  I don't think a TaskScheduler or QueuedTaskScheduler is better: Semaphore and QueuedTaskScheduler rather have different (possible) roles to play in different scenarios.  \nThrottling async code: SemaphoreSlim is definitely the way to go (your code, the Stack Overflow article, my original proposal all agree)\n~~Throttling~~ Parallelising sync code: It depends what the purpose is, and if threads are being managed upstream.\n- SemaphoreSlim a way to go (great lightweight way to go!) if threads are being managed upstream (indeed it requires that something upstream from the ThrottlePolicy is placing the calls onto separate threads).  Also nice that implementation parallels async implementation.\n- A task scheduler (for example QueuedTaskScheduler in its thread-pool flavour) is one possible way to manage and schedule synchronous work on to a defined-size thread pool.  It's (per comments in the StackOverflow article) more suited to CPU-bound work.  Possible scenarios might be:\n  - a 'listener' thread is receiving tasks, and wants to hand them off onto a parallel-limited pool of 'worker' threads to execute, with some of Polly's fault-handling built in.  [EDIT: This is exactly the scenario with some messaging clients, which listen on a dedicated listener thread.]\n  - CPU-bound work like processing audio / video / images uploaded by users.\nThe idea to offer both an IsolationMode.ThreadPool and IsolationMode.Semaphore for sync code was to give both options (do you want Polly to manage threads for you or not?), and based on Hystrix offering both.  \nThat said, IsolationMode.ThreadPool feels the harder case / has some unresolved questions.  QueuedTaskScheduler is one way of providing exactly schedule-tasks-onto-a-fixed-threadpool (I have used in the past), but I haven't had time yet to evaluate the underlying implementation against the range of .NET standard platforms we want to support.  (Was in the proposal as a ? question-mark as it probably merited further thought before implementation!)\n. As well as the first Hystrix link on ThreadPool versus Semaphore, Hystrix have an extensive discussion here.  \n(Some of the considerations can probably be seen differently in the 2016 .NET context, and recent Hystrix discussion suggests views evolving beyond what stated in those articles, but there's lots of food for thought in there!)\n. Another option would be to omit the IsolationMode.ThreadPool variant entirely - or initially. \nVery interested in community feedback: Do you see Use Cases for IsolationMode.ThreadPool throttling with Polly?\n. Many thanks @brunolauze again for your code both here and on Timeout.  I expect to be able to review in detail Sunday thru Wednesday.  \n(I think we can take the SemaphoreSlim versions of Throttle forward independent of the ThreadPool version, which I/we all can think about in parallel.)\n. @BrunoLauze  Many thanks for getting stuck in to the Timeout and Throttle Policies!  \nFirst feedback here to help us proceed Throttle (without any ThreadPool variant; will come back to that later).\nYour SemaphoreSlim approach for the throttle is spot on.  Your code follows the retry pattern perfectly! But we can simplify some of that away, some aspects needed by retry we don\u2019t need for Throttle:\n- The throttle policy is non-exception handling (won\u2019t change its operation depending on specific exceptions: we\u2019ll just let all exceptions propagate back for the caller (some other policy / the user) to deal).  Therefore:\n  -  The Policy and Engine don\u2019t need to take any exception predicates or result predicates.\n  - The syntax can all be static methods on Policy. ie \u2018ThrottleSyntax/Async\u2019 can contain public partial class Policy offering the configuration syntax you already have, as static methods on Policy (rather than extensions on this PolicyBuilder policyBuilder).\n  - The whole catch block is probably redundant (tho finally block looks spot on!)\n- The policyStateFactory is not relevant and can be removed.  Retry was a case where the scope of the state needed to be per execution (if configured for 3 retries, each call to execute needs a fresh chance at 3 retries, so needs a fresh state instance to track this).  Throttle is more like CircuitBreaker.  The state (the number of calls already occupying the semaphore) wants to be shared across calls through the policy, so the scope of the Semaphore is per-policy, not per-execution.  I would remove all the ThrottleState classes and move everything up to ThrottlePolicy/Async and ThrottleEngine.\n- New info: In the async implementation, we must always honour continueOnCapturedContext, ie await whatever.ConfigureAwait(continueOnCapturedcontext); .  The default for libraries is .ConfigureAwait(false), but in the context of needing to stay on a custom TaskScheduler as for Orleans users, they want .ConfigureAwait(true).  So we decorate every await with .ConfigureAwait(continueOnCapturedcontext); . To avoid missing any, you can use this great tool as a plugin for ReSharper, or apparently as a Roslyn code analyzer too (CA2007?), or just :eyeglasses: \n- I possibly hadn\u2019t explained the intended interaction of maxParallelization and maxQueuedActions clearly in the original proposal.  The intention is:\nmaxParallelization : the maximum number of actions that may be executing simultaneously: governed by a SemaphoreSlim that callers block on until they can acquire it or are cancelled (ie exactly as you have it @brunolauze)\nmaxQueuedActions : the maximum number of executions that may be queueing waiting for a slot on the execution semaphore.  So a user might configure maxParallelization = 8 actions are allowed to be running in parallel, but maxQueuedActions = another 20 actions are allowed to be queueing, waiting to acquire the main (execution) semaphore, if it is full.  The default for maxQueuedActions if not supplied by policy config overload should be 0.  \nThe intended implementation was a second SemaphoreSlim of capacity  maxParallelization + maxQueuedActions.  If that cannot be acquired immediately, the SemaphoreQueueFullException (custom exception we define) would be thrown.  One can try to acquire a semaphore immediately without waiting, using .Wait/Async(TimeSpan.Zero, CancellationToken) (reference; reference).\n@brunolauze Are you happy to proceed like this?  Is this helpful? You are doing a great job of getting stuck into the codebase!\n. @brunolauze I reflected further on the TaskScheduler approach and agree it should not form part of  Throttle now.\nMy inspiration was that we use QueuedTaskScheduler very successfully in house to handle incoming messages in a microservice environment.  The 'listener' is on a dedicated single thread, offloading messages to Tasks for processing in parallel.  QueuedTaskScheduler's parallelization-limiting features, queueing features (tasks can be queued but not executed until capacity is available), coupled with its prioritisation features, make a great combination here - we can balance message priorities such that messages involved in supporting immediate user interactions can be prioritised, for example, and not swamped by batch tasks or lower-priority operations.  We can use parallelization optimisations to create back pressure ... I was keen to offer some of this value in Polly.\nThe issue for Polly is that this 'offloading' (from a single thread onto multiple background threads/Tasks) isn't an exact fit with either the existing Execute() or ExecuteAsync() syntax.  Execute() clearly is sync and expects to stay on the same thread.  The ExecuteAsync() syntax (with its emphasis on continueOnCapturedContext) is geared to the async/await use of Task rather than the TPL (Task Parallel Library) use.  \nTaskSchedulers can bind nicely with the throttling concept, then, per above example, but if we are to introduce TaskSchedulers to Polly, we might want to consider a new, differentiating syntax, perhaps something like ScheduleAsync(...).  And further thought / debate would be needed on value versus complexity.\nIf other users are interested in getting TaskSchedulers into Polly, please comment here or (when this is closed) start a new issue!\n. PROPOSAL: Change the name of the ThrottlePolicy, for release, to IsolationPolicy.  Configuration syntax becomes: \nIsolationPolicy isolationPolicy = Policy\n  .IsolateAsync(int maxParallelization[, int maxQueuedActions]);\nWhy?: \n- Reactive Extensions for .NET already has a .Throttle operator.  If in future we build Polly.Rx, we would have a name collision on Throttle.  Note: Rx's Throttle does something quite different from Polly's: Rx's throttle limits results after CPU has already been spent generating them; Polly's throttle-isolation limits executions before CPU/other resources are spent on them. \n- While the implementation is a parallelism throttle, the resilience term for this approach is bulkhead isolation.  \nViews?\n. @brunolauze Good catch! (that we have another meaning for Isolate elsewhere).  @brunolauze @mfjerome I'll build on your suggestion of Bulkhead for now.\n(Time for reflection still before release - further community feedback welcome! - but .Bulkhead() seems leader of the pack for now ... :tiger:  )\n. So: Bulkhead isolation policy has been delivered into the v5.0-alpha branch, ready for a forthcoming v5.0-alpha nuget release\n. Commentary on .NET4.0 async support for Bulkhead Policy: SemaphoreSlim does not offer the .WaitAsync(...) async variant of .Wait().  Therefore, the .NET4.0 implementation (only) of bulkhead is currently blocking (when waiting to acquire the semaphore), for BulkheadPolicyAsync.\nThis is in principle easily solvable with (internal #if/#endif# forking and) use of eg Stephen Toub's async semaphore or Stephen Cleary's async semaphore.  At this point this work has not been undertaken, in case there are also .NET4.0 compatibility challenges in other v5.0 policies. A wider review of  .NET4.0 compatibility will be undertaken once all v5.0 policies are in place.\n. Hi @SeanFarrow . I'll probably take this one on myself, as passing the context/keys on correctly down the wrap will be closely aligned with the work on PolicyWrap.  Are you waiting on me to add ExecutionKey to drive lookups from/storing in the cache for #136?  \nI can possibly start this (or we can put in a stub) in the coming week.  Shout at any point if you're ready to start and this is holding you up!\n. Hi @brunolauze.  Good question.  Say a single RetryPolicy is used to wrap outbound calls at three call sites in the code:\n[a] Calls from all three call sites would share the same PolicyKey (the same Policy instance is in use)\n[b] Calls from each different call site would get an individual ExecutionKey if the coder specified it when coding the call to Execute/Async(...).  Each time that call site places a call, that ExecutionKey will apply.\nAside: The ExecutionKey would be specified by using an Execute overload taking a Context, passing the executionKey to Context thus: .Execute/Async(whatever, new Context(executionKey))\n[c] Each time any call site places a call, a random ExecutionGuid would be assigned (unique per runtime call).\n[d] PolicyWrapKeys operate like PolicyKeys - one per instance - so the same where the same PolicyWrap inytance is used, different where different instances are used.\nSo:\n| Key | Scope |\n| --- | --- |\n| PolicyWrapKey | per PolicyWrap instance |\n| PolicyKey | per Policy instance |\n| ExecutionKey | per call site in the codebase, if specified by the coder when coding |\n| ExecutionGuid | per call at runtime |\nThanks for calling out that this could be clearer: I'll update the original!\n. Hey @brunolauze / everyone.  I've updated the original table of Policy Keys with an extra row 'How would it be specified?', to show just that.  \nUsages of the keys would be:\n- All values would travel on the Context travelling with each execution\n- Coders can select onRetry, onBreak, onTimeout etc etc delegates taking the Context, so if eg these are used for logging, loggers can log as much context as you like.\n- When Polly is extended to emit stats/events, it's intended that all these keys would also feature in the PolicyEvents emitted.  So event aggregators/dashboards could identify trends per policy, policy wrap, policy usage (call site), determine latency of individual executions and aggregate this to give averages, etc.\nAny other questions / ideas, fire away!\n. Just to state that PolicyKeys and their relation to the execution Context has been delivered and merged into the v5.0-alpha branch at this commit.\n@dgodd @SeanFarrow This provides the full TDD-driven approach to keys underpinning execution Context for both metrics, and cache keys.\nOnly difference from the original proposal: it felt redundant (when implemented) for a PolicyWrap to have both a PolicyKey and a PolicyWrapKey property.  \nThe  PolicyWrapKey property on the execution Context is essential, and remains the same: it carries as a constant through the execution of any (however-nested) PolicyWrap, but a Context just takes the PolicyKey of the outermost PolicyWrap to be the Context.PolicyWrapKey property.\n. @juancarrey That's great to hear: thanks for sharing!\n\nThe chain implemented IPolicy, and any IPolicy could be chained afterwards (wrapped). \nThe innermost PolicyChain had no next policy, so it just delegates to the IPolicy inside. \n(A policy-chain contained 1 or 2 policies, the current and the next one if any.)\n\n@juancarrey That's exactly the implementation I am planning.  Each policy in the Wrap only needs to know about the next, and this actually simplifies the wrap implementation greatly.  Except that we have consciously held off IPolicy while in this phase of deep product growth (discussed in #90).\n. @juancarrey , re:\n\nExecuteAndCapture actually was done by the innermost policy, and returned backwards.\n[should it be] option at builder ?\n\nMy thought so far was that the capture of ExecuteAndCapture() doesn't want to be done by any inner policy: if an inner execution faults, you want that fault thrown back on to the next-outer policy (not neutralised-by-Capture), as the next outer policy might deal with it.  For example, in the sample wrap in the proposal (fallback, cache, retry, circuitBreaker, timeout, throttle), if the throttle or timeout rejects execution, you may well want the circuitbreaker to register that (configurable by which exceptions the breaker handles), you may want to retry after a delay (ditto), and you very likely want the fallback to detect that failure and provide the fallback substitute.  That was the (not accidental) logic in supplying fallback, cache, retry, circuitBreaker, timeout, throttle as the example. \nMy assumption so far about the ExecuteAndCapture() feature has been that its purpose is (after the policy or wrap exhausts all other options...) to capture any final unhandled fault  into an 'outcome' class, rather than have the caller have to place an extra try / catch round the execution (hence, again, only applying to the outermost call).  Is this sounding sensible to other people??  (Keen to hear if I missing something about how ExecuteAndCapture() might operate at inner levels!...)\n\nIf the question is about how to capture 'what went on [what exception was maybe thrown] at the inner levels', then my thinking so far is that the complexity dictates we need to look to another mechanism: either onSomething delegates like onBreak and onRetry in the current policies (great for logging); and/or capturing through observing events emitted from all policies in the wrap, as first mooted here.  Something like an IEnumerable<Exception> or IEnumerable<DelegateResult<TResult>> on PolicyResult wouldn't (could it?) capture enough detail about on which inner policy the exception occurred on (and might contain lots of repeats if the same exception was thrown outwards through several levels?).  \nThoughts, anyone?\n. An initial implementation of PolicyWrap can now be seen in the v5.0-alpha branch.\n. @brunolauze  It's great to see this deep engagement with the Polly codebase - thank you for your time and involvement.\nAs mentioned off-github, my availability is restricted for a few weeks, 48 hours hence.  I can't give a considered response on all the changes within that timespan, so some general/abstract qs and observations only now.  \nWe can't promise also at this stage (obviously) that core Polly will go the same direction on all points.  However, it's _great to see so many ideas.  Particularly, how to structure the Polly syntax as the number of policies grows has been a key concern, so good to consider alternative syntaxes.  @ All: community input on syntax welcome!\n...\nSetting aside implementations, the main thrust seems an alternative syntax for PolicyWrap - fair observation?  Is it fair to characterise as a configure-all-in-one-go (extended-fluent-chain) approach? (a move from static configuration to chaining-on-instances, as briefly floated in #104 ?)\nThis is a really interesting approach, and one we should definitely consider.  Conciseness appears a  key benefit, at least for more simple cases.  \nFrom another angle, I see this syntax particularly enabling \"configure all policychain elements at point of use / in one go\" (as distinct from, say, combining preconfigured policychain elements, perhaps passed in from outside). (By elements, I mean the different aspects that might make up a wrap - retry, breaker, etc; by outside I mean, say, passed in from outside the current class).  \nThat seems the key difference to me.  (NB At this stage, seeking just to call out the qualities of things - understanding the qualities deeply helps us see where proposals fit and see what range of features to provide!)\nThanks again @brunolauze for the huge contribution in terms of code and ideas - it would be good to see what we can make of this in terms of PRs, at the appropriate moment.\n. @brunolauze Re:\n\nOur main goal here is to add two other component : Polly.Config and Polly.Web\n\nWe would be happy to consider PRs on these at an appropriate point.  On config, briefly, you may have seen seen some of the discussion to date in issues #143 and #50 ?  On Polly.Web, I threw together some samples for the App-vNext team of Polly policies in Asp.Net middleware/pipeline a while back, but didn't have time to turn this into something concrete - so it would be great to see ideas.\n. @brunolauze On the policy wrap/chain briefly:  One other aspect to consider is whether policies (eg retry, circuit-breaker) can be re-used in more than one policy chain/wrap.  In some cases there are some specific functional advantages to being able to eg re-use the same circuit-breaker across more than one call site : all calls to a common subsystem can share knowledge about the state the subsystem is in.  \nSomething similar could also apply for throttle: one might to share a resource pool across a set of calls in a larger system, rather than (say) define lots of similar smaller resource pools.\n. A key tension/crossroads I see now for Polly is how to continue to grow the power (with syntax allowing powerful options), while still maintaining a simpler syntax for those who want a more off-the-shelf, more-things-preconfigured-perhaps happy path.  All community input on syntax welcome, as this a key decision now.\n@brunolauze\u2019s above speaks to this problem by offering a way to configure an entire PolicyWrap in a single extended chaining syntax (as opposed to combining previously configured policies).\n@RehanSaeed\u2019s #143 speaks to this problem by offering a way to configure a Policy (or multiple policies?/policy alternatives?) out of a single POCO class (while perhaps omitting some of the deeper power like onRetry, onBreak etc delegates \u2013 unless this were all piled into the same POCO class - it could be).\n@RehanSaeed I see particular possible application for your idea as the new resilience policies and PolicyWrap are added.  I haven\u2019t wanted to take Polly in the direction of having a single Command class with settable properties as its underlying operating architecture, as Hystrix has, for the reasons set out in the comparison here.  However, your idea of a single POCO configuring class does provide a possible bridge in this direction for the API, by offering a single class where all elements of a PolicyWrap could be configured.\nThe full PolicyWrap syntax would still offer deeper power, but there will be many users also who just want a pre-defined template for a PolicyWrap that\u2019s suitable for most cases, with a few extra options.\nCommunity feedback welcome\n. Closing due to lack of recent activity/comment, and issues now covered elsewhere.  To briefly summarise:\nMerge sync/async policies: The current position is that this is hard to do; a new, detailed blog post explores the reasons.\nAlternative syntax for PolicyWraps: The existing syntax, building a PolicyWrap from granular chunks each being an existing Policy, was preferred as less complex and more flexible over the longer term.\nConfiguration from POCOs: Remains on the Roadmap as of date of posting.\nConfig approaches: Linked to here from the main config issue #50. @RehanSaeed Thanks for sharing this.  There are some similar ideas in issue #50, with discussion around the different aspects of a policy that could be configured (numeric parameters; exceptions handled?); different configuration sources and methods of application; and configuration-only-at-startup versus reconfiguration-during-execution.   Please feel free to have a read of #50, and add any further ideas/comments!\n. @RehanSaeed Agreed: if a strategy for configuring policies depends on approaches not part of .NET Core, that would certainly be part of a separate package.\n. Triage of old issues:\nConfiguring policies from lightweight POCOs - or interfaces which group the relevant configuration parameters - remains a possible later addition.\nSome initial work can be found in this branch.  \nThe approach is configuration-provider interfaces: eg IAdvancedCircuitBreakerConfiguration; IConsecutiveCountCircuitBreakerConfiguration:\n\nthe interfaces can trivially be fulfilled by POCOs\nfor .Net Core, in-built .Net Core configuration providers can populate those POCOs \nconfiguration by interface allows community to implement any other provider they need, eg older System.Configuration.ConfigurationManager requirements\n~configuration by interface would open a variety of paths to dynamic configuration during running, eg custom providers backed by a database; Dot Net Core's various options for dynamic reconfiguration, etc.~. EDIT Feb 2018: This approach is now deprecated, because it makes policies mutable. We now recommend PolicyRegistry as the route to dynamic reconfiguration during running.\n\nThe core Polly package would likely contain only the interfaces and matching flat POCOs. Specific implementations would live in separate Polly.Contrib packages.\nPriority: Low.  Possibly in tandem with any work on refreshed Polly syntax.\nCommunity contributions welcome: lower prio for the core Polly maintainers.  I can provide guidance if anyone wants to pick up this work.\n. Pinging on this thread, to alert that there is a lot of related discussion going on in the ASP.NET Core 2.1 HttpClientFactory repo around the Polly integration.\n. Hi @pvmraghunandan .  Thank you for your question and suggestion.\nThe original Polly Circuit Breaker breaks only if the given number of handled exceptions is raised consecutively (in consecutive calls through the circuit).   Therefore, there is not (except in 100% failure scenarios) the risk of the number of exceptions building up and up over time, ever increasing, such that the circuit will eventually break.  Any successful call resets the breaker's internal count of exceptions to zero.  EDIT: I think this obviates the main motivation for having an expiry duration on the original, consecutive-count circuit breaker.\nI see that this (the original breaker's trigger being consecutive exceptions) is in the wiki, but not in the readme and intellisense: I'll add it to the readme and intellisense, to make that clearer.\nThe Advanced Circuit Breaker provides the feature you are asking for, a timeout on exceptions: the samplingDuration effectively acts as duration after which to 'forget'.  \nThere is a much deeper discussion of this and related issues in this past thread.  The Advanced Circuit Breaker grew out of wanting to offer a 'trigger' measure that would be easier to configure for consistent results for high-throughput and variable throughput circuits.  And out of exactly the point you are raising: the ability to 'forget' exceptions beyond a certain duration.  The discussion here particularly identifies why we chose the form Advanced Circuit Breaker has, effectively a hybrid of proportion-based and frequency-based, rather than a pure proportion-based or frequency-based metric.\n. @pvmraghunandan #145 will (when merged) clarify the doco on this issue.\n. Thanks again @pvmraghunandan for raising this.  Well worth clarifying this: we've made the doco on the original CircuitBreaker clearer through #145.\n. @pvmraghunandan  Re:\n\nTrying to understand SingleHealthMetrics and RollingHealthMetrics. \nCan you help us understand this and how does sampling and no.of windows work together?\n\nSee: https://github.com/App-vNext/Polly/wiki/Advanced-Circuit-Breaker#detailed-operation-of-failure-statistics\nThe failure rate and throughput of the breaker is always considered over samplingDuration.  Use of SingleHealthMetrics versus RollingHealthMetrics is purely an internal concern to smooth statistics.  \nIf samplingDuration > 200 milliseconds, the samplingDuration is divided internally into up to 10 windows of duration samplingDuration / 10 each, to smooth the statistics.  This prevents disposing 100% of stats every samplingDuration; instead, 10% are disposed potentially every samplingDuration / 10.  This creates a rolling statistical window of length samplingDuration which moves samplingDuration / 10 forward every samplingDuration / 10, provided executions fall in those periods.  I say \"up to\", \"potentially\" and \"provided\", because the circuit does not waste cpu/memory creating empty windows for periods in which no execution occurred.  RollingHealthMetrics manages all this.\nWhy?  Smoothing using windows improves the breaker's responsiveness and its fidelity to its definition statement: that it will break if the failure and throughput thresholds are both met within any  timespan of duration samplingDuration.  \nWith no smoothing/windows - if 100% of stats were disposed every samplingDuration - it is easy to imagine situations where in real world the conditions to break were met, but because some of the faults fell in one samplingDuration, some in the next, the breaker did not detect this.  Equally, with no smoothing/windows, the breaker would potentially only tend to break towards the end of each samplingDuration, once failures had built up - giving irregular responsiveness.\nIf samplingDuration < 200 milliseconds, the timescales are considered too small for dividing samplingDuration into windows to add any value.  SingleHealthMetrics is used internally.\n. Hi @kbilsted  The existing policies (retry and circuit-breaker) are fully thread-safe, and the intention is that the forthcoming wider resilience policies will be thread-safe too.\nThread-safety is documented here in the wiki, but a good idea to pull that out more clearly into the readme - thanks for pointing this out.\n. There's a little more depth on thread-safety also in these links for each of retry and circuit-breaker.\n. @dgodd Thank you for this very interesting suggestion.  I intend to put some thoughts together on this (basis for further discussion) in the coming days.\n. @dgodd Thanks for your interest in Polly!  We would love to collaborate on adding metrics to Polly, and see what we can push to Hystrix dashboard.  Videochat with myself (/and a.n.other AppvNext member/s?) next week mby?\nRight now the Polly team are engaged in pushing out v5.0, which will contain additional policies Bulkhead; Cache; Timeout; Fallback and PolicyWrap to tie everything together.  Is SteelToe interested in using / in metrics only for AdvancedCircuitBreaker, or potentially wider Polly policies?\nDipping into your PR, it looks closer to a Hystrix 1.4.x approach?  The metrics implementation we envisage for Polly v5.0+ is slightly closer to the Hystrix 1.5.x approach : we expect Polly policies to emit events (much like the Hystrix Event Types) as an Rx stream.  Aggregators would then be able to aggregate those events (and derive metrics from them) for any dashboard.  Thoughts?\nTiming-wise, we may be a few weeks getting v5.0 out first.  But carve out some time on metrics proof-of-concept during that?\nCouple of conceptual differences between Hystrix and Polly possibly to work through.  Polly has retries; Hystrix doesn't.  Do you envisage being able to adapt the Hystrix dashboard at all?\nThe Polly PolicyWrap is also more flexible (not imposing a structure) than Hystrix's fixed arrangement of strategies.  But I'm envisaging adding a 'default' PolicyWrap option to Polly (watch for post in coming days), that will be pretty close to Hystrix approach - probably allowing us to bridge this difference.\nHappy to explore further in videochat ...\n. @ wider community: And other dashboards too!  (aware that others have expressed interest in metrics). Requests welcome!  Offers of contributions (or thoughts to develop this) even better! :wink: \n. @dgodd Would any of the steeltoe team like to do a videochat this week about this?  If so, please contact me off-github on software[at]reisenberger.net, to arrange.  I am in the UK; other relevant App-vNext members are also East Coast US.\n. Hi @vknapp.  There is a relatively easy way to handle this in existing Polly.  A CircuitBreakerPolicy publicly exposes its state, so you could use a construct like below to avoid exceptions while the circuit is open:\ncsharp\nif (breaker.State != breakerState.Open && breaker.State != breakerState.Isolated)\n{\n  breaker.Execute(...)\n}\nI have documented this (in slightly more detail) on the CircuitBreaker wiki page.\n(I prefer this to offering a bespoke Execute(...) overload only applying to the circuit-breaker.  To date, we have managed to keep Execute overloads common to all policies, and this is an important foundation for the forthcoming features on the Roadmap, the PolicyWrap in particular.  Very happy for any feedback on those roadmap features, btw!)\nThanks for your interest in Polly!\n. No problem at all @vknapp !  A really good question (how to reduce the exception load on open circuits), so it's made for a useful clarification of the doco (and we've kept the gotchas of that idiom clear in the doco too, so users can use the idiom with open eyes, as it were).  Thanks again for bringing this up!\n. Hi @jiimaho  A good strategy for this could be Dependency Injection: \n- Refactor to inject the Policy into the method/class using it (whether by constructor/property/method-parameter injection - doesn't matter).\n- In your production code, inject the real policy you want to use.\n- In your test code, inject an equivalent policy that doesn't do any waiting, eg Retry(3) // etc\n. Hi @jiimaho Yes, that's absolutely right.  That's exactly the way we handle it within Polly's own specs, to allow tests to run instantly where time-delays are involved: specs either substitute SystemClock.UtcNow or SystemClock.Sleep , depending on whether the policy-under-test is waiting passively for time to pass elsewhere (as in CircuitBreaker moving to half-open) or actively controlling the delay (as in WaitAndRetry).  \nYou can see an example test here.\n(It's slightly questionable whether SystemClock should really be public ... that inherited from before AppvNext stewardship of Polly ... SystemClock is really an internal concern ... but it does have this benefit for user testing.)\nThanks for your interest in Polly!\n. Thanks for that @rog1039 . The ability to manipulate Polly\u2019s abstracted, ambient-context SystemClock is intended to provide exactly this: you can manipulate time so that tests which would otherwise incur a time delay, don\u2019t. See the many tests within the existing codebase which do this. \nLet us know how you get on with that - or if you can envisage ways it could be improved (I can envisage some - as ever, with trade-offs)\nEDIT: Improved the  Unit-testing wiki to highlight this.. Good catch @WilkaH !  And exemplifies something I'm often saying to people: \"check the reference source!\" (should've practised what I preached on this one :wink: ).  (We'll probably reverse out that PredicateHelper<> later, as doesn't aid performance or readability.)\n. @TrevorPilley Thanks for raising this.  \nThere's no reason the core Polly library is not marked as CLS-Compliant.  I just added the necessary attribute, and no issues were identified for Polly.dll in all the currently supported targets.\nAn issue was identified for xunit (warning CS3016: Arrays as attribute arguments is not CLS-compliant) on the MemberData attribute used for Theorys.  This is outside our control, but has no impact on the nuget packages: the tests don't form part of the nuget package.\nWe'll aim to get this attribute added for the v5.0 release.\n. Fixed in Polly v5.0.2 on nuget\nThe Polly.Net40Async remains non-CLS-compliant.  To support Bulkhead async for .NET40, we had to take a dependency on Nito.Async (for .NET40 folks only).  This dependency is non-CLS-compliant.. Hi @francischeung Yes, that's a completely valid way to proceed, to combine Polly's circuit-breaking with Azure's built-in retry logic, and your code sample looks perfect for this.\n\nWhen Polly v5.0 is launched in the next four weeks or so, there may be other factors to consider regarding using Azure's retries versus Polly's.  Polly v5.0 is adding a whole host of wider resilience features, and the ability to combine all those resilience strategies into a PolicyWrap.   For certain combinations of Polly resilience strategies, the most logical place for retry is going to be somewhere in the middle of the policy wrap ... something like:\ncsharp\nPolicyWrap wrap = Policy.Wrap(fallback, cache, retry, circuitBreaker, timeout, bulkhead);\nawait wrap.ExecuteAsync(async () => ... );\nPlacing a retry in the midst of Polly's (forthcoming) wider resilience strategies like this, could be done with Polly's Retry policies, but not with Azure's retry policies (you couldn't mix Polly's on both sides of Azure's).  so at that point you might want to switch to Polly retry as well.\nWe are aiming to have v5.0 as an alpha nuget release in week beginning 24 October.\nHope this helps. \n. Closing historic issue.. First documentation for the new v5.0 policies is now out on the wiki: \n- Timeout\n- Bulkhead Isolation\n- Fallback\n- PolicyWrap\nv5.0 release to nuget expected 24 or 25 October\nEDIT: The quickstart documentation for each policy is already in the readme of the v5.0-alpha branch\n. We're pleased to announce that Polly v5.0.1 is now out in alpha on nuget, with the new policies:\n- Timeout\n- Bulkhead Isolation\n- Fallback \n- PolicyWrap.\nSee the latest blog post on www.thepollyproject.org for an overview of what's in the release, details of (very minor) breaking changes, and what (again, not much) could change before the final v5.0 RTM.\nFor usual syntax overview, see the v5.0-alpha branch readme\nFor detail on each policy, see the wiki (or detailed links to each policy at top this post).\nTo feedback on v5.0-alpha, comment here, or join the discussion on slack! All feedback helps shape Polly as we take features to the next level!  \nThanks\n. Hi @OmegaAphex  Are you wanting to:\n(a) simply to prevent the next try beginning?; \n(b) cancel immediately during any wait between retries?; and/or \n(c) cancel immediately during the executed delegate?\n. @OmegaAphex As you say, this is not easy in .NET3.5, because of the lack of CancellationToken.  \nPolly v4.3.0 has the waits in synchronous WaitAndRetry implemented as a non-cancellable Thread.Sleep.  From (the forthcoming) Polly v5.0, we are moving these to cancellable - but again, using CancellationToken and Task.\nIf you are interested in attempting a back-port of this functionality to .NET3.5, you could:\n- Take a fork of the current Polly v5.0-alpha branch, which contains the cancellation support (via CancellationToken) for synchronous executions, including WaitAndRetry\n- Re-instate a .NET3.5 target\n- Try bringing in a .NET3.5 back port of the TaskParallelLibrary made available on NuGet, as described here.  Caveat: I have not had time to explore this.\n- You may well also need to remove the async/await material which is unlikely to be supportable in .NET3.5; or you could try this .NET back port from the same team.\nBecause of the age of .NET3.5, supporting this has not been a primary focus.  However, I would be willing to provide further support/guidance if you are interested in exploring making the above back-ports.  \nSuggestions from other members of the community (as always) also welcome\n, \n. Closing due to lack of response. Please re-open if wanting to take this further.. Hey @ronnieoverby \nSomething like this would certainly be possible.\nA question though: Would simply using the existing .Execute/Async() overloads meet your need?  Using .Execute/Async(), any 'FinalException' is propagated by the policy with its original stack trace, rather than captured into a PolicyResult.  (Marginally more efficient also - one less capture-rethrow.)\n(You might have other reasons for wanting to stick with ExecuteAndCapture() - please feel free to come back to me on this, if the suggestion to switch to .Execute/Async() doesn't solve it for you.)\n. @ronnieoverby This makes sense.  The Polly team is deeply geared to the launch of v5.0-alpha for Dev Intersections next week, so I'll come back to you on this once that's out the way.  Thanks.\n. @ronnieoverby Thanks for your patience with this.  The Polly v5.0 targets are decided now, so we would be happy to take a PR on this, if you are interested in providing one.  Any PR should (before v5.0 is RTM) be based on a fork of the v5.0-alpha branch, and (if timings work) should make it into v5.0.3 RTM.  \nRe:\n\nNew property on PolicyResult called FinalExceptionDispatchInfo\n\nSounds good.\n\nNew method PolicyResult.ThrowUnhandledException\n\nSounds good.  How about we name it PolicyResult.RethrowUnhandledException ?\n\nExisting property getter PolicyResult.FinalException is reimplemented as \nreturn FinalExceptionDispatchInfo?.SourceException;\n\nIs there a benefit to doing this, you are aware of, over the existing implementation?  MSDN documentation states \"It is not intended to be used by application code.\"\nMany thanks!\n. Marking this 'up-for-grabs'.\nPolly v5.0.3 RTM is now released, so PR directly against master (no longer v5.0-alpha)\n. Having revisited this: I believe it not necessary to add this feature within Polly; it is provided by the BCL as ExceptionDispatchInfo.Capture(Exception).  Users can apply that themselves to the existing PolicyResult.FinalException property.\n. You are absolutely correct @twsouthwick, thanks for picking this up.  Will be fixed in #175\n. @joelhulen Please do not merge this yet: further build tidying commits may follow.\n(xunit reference changes reverted due to differing cake-script behaviour between local runs and appveyor; no change to actual test functionality)\n. Fixed in Polly v5.0.2 on nuget. @jmansar Thanks for bringing this really interesting idea across from our slack channel!\nMain question in my mind: whether exposing result directly to sleepDurationProvider is the way we\u2019d want to support this.  Without knowing the underlying use case, some users might wonder: why is the execution result exposed to that policy-delegate? (and only that one?).  And the pattern might not immediately make sense to extend to other policy-operation-influencing delegates.\nSo: how else can we do this, that keeps the Polly architecture evolving in a coherent way?\nIn this case I'm thinking we\u2019d probably want to support this by expanding the role of the Context class in executions (something we intend anyway, when we move to support metrics).  To fulfil what you need ... we would add the execution result instead to Context; and make sleepDurationProvider take Context as input param instead. \nMaking Context the central way we channel extra info to all parts of policy execution:\n- Follows a common pattern, with all the onStateChange delegates already taking Context\n- Reduces the overall number of overloads for different variants (already too proliferated)\n- Allows all the onStateChange delegates to also benefit from getting the execution result :smile: \n\nNote there are other similar (in a very broad sense) issues like #38 .  Also about exchanging data between execution and  Policy-operation-influencing delegates.\nMy suggestion-in-the-meantime for your use case is similar to at bottom of #38.  Close over some common variable in the sleepDurationProvider and Execute delegates, to share that part of the response back to the sleepDurationProvider delegate\n. @johnmcase @jmansar This is added to the roadmap, in the generalized/extensible way I propose we should take this forward.. @jmansar @johnmcase @tcsatheesh Planning to deliver this feature in the next release :smile: .  (already coded)\nPer my previous comment, Polly is being expanded so that every delegate referenced by a policy (executed delegates; and policy control delegates such as onRetry) can share the execution Context that travels with each execution.  This generalised approach adds lots of flexibility to exchange data throughout a Polly execution, unlocking your feature and many other architecturally-similar requests, eg #73, #38, improves  pattern for #122 .\nFor RetryAfter, you can share a RetryAfter value returned by an underlying system through the Context, and feed it into your sleepDurationProvider.\nCode example:\n\nYou will be able to execute a delegate taking the current execution Context as a parameter\nDuring that delegate, if your call returns a RetryAfter value, you can store that in the Context, to pass to sleepDurationProvider\nAnd sleepDurationProvider can take account of it\n\nEDIT: I plan to blog a detailed code example when released.\nEDIT: The release may accompany the PolicyRegistry feature and interfaces, also in development.. @jmansar @johnmcase @tcsatheesh Blogged the pattern for using this for RetryAfter: http://www.thepollyproject.org/2017/05/04/putting-the-context-into-polly/ . Shout if any questions/suggestions.  \nIntend to break out the blogged Use Cases also into separate How to sections of the wiki.\nThis also makes a great case study for building your own custom policy: intending to blog/wiki how to build a custom policy that wraps all this functionality round WaitAndRetry (rather than you having to write the Context stuff manually).  \n. @jmansar @johnmcase @tcsatheesh Polly v5.6.0 (uploading to nuget in next day or so) will include the ability for WaitAndRetry policies to define a sleepDurationProvider which can take the handled fault (exception; or returned result) as an input parameter to the sleepDurationProvider delegate.  \nThis should make it even easier to use WaitAndRetry policies to wait for a 'retry after' duration specified by the called system; eg as CosmosDB does with HTTP response code 429 and response headers. Fixed in Polly v5.0.2 on nuget. Hi @mieliespoor\nNot aware of any extra steps needed in a load-balanced environment related to Polly, and not encountered this before.  (But very happy to work with you further on this if we can identify particular causes.)\n\nHave you been able to isolate that this happens only when Polly is in use?  (ie eliminate that it is not related to anything else which may have changed in the production environment or codebase or due to load-balancing indep of Polly?).  \n\nOne approach to focus on this could be introduce a config feature-toggle to either pass the executions through Polly or not (with codebase otherwise identical).  Then we could see if the problem specifically manifests itself (or not) when the executions are passed through Polly.  (Just to isolate definitively - know we are focusing on the right thing.)\n\n\nDo you have any indications from IIS logs or APM monitoring of what may be happening?\n\n\nThe Polly policies provide the ability to track how they intervene in executions, via the onRetry, onBreak etc delegates: if you want to track exactly how the Polly policies are intervening in production, hook logging into those onPolicyDidSomething delegates (if not already).  \n\n\nWhat kind of volumes/throughput is the WCF service dealing with? (out of interest)\n\n\nFinally, what is the topology?: where are the Polly policies placed in relation to the caller, callee, load-balancer, etc?  (In microservices environment where I work, we some Polly both on the caller and callee sides, for different purposes.)\nHope some of this helps, and hope we can help further with this!. @mieliespoor Also, if you want to share code sample of how the Polly policies are being used, of course we can look over that and comment if anything looks unusual.  Thanks!\n. @mieliespoor Which version of Polly are you using?  And which kind of Policy?  I have identified a possible issue with the synchronous form of WaitAndRetry(...) for Polly v5.0.1 and v5.0.2 (only), and have a fix ready for Polly v5.0.3.  However, if you are using Polly v4.3.0 or earlier, this would not be relevant.\nThanks. @mieliespoor Nothing in the code samples looks particularly unusual / likely to cause trouble.\n(With Polly, as with any exception-handling, we sometimes advise handle only the exceptions you specifically want to/can handle, rather than blanket every exception, to prevent policies handling exceptions not originally envisaged.  For instance, for I/O, we might advise handling only the expected I/O exceptions, rather than blanket .Handle<Exception>.  Probably unrelated to the load-balancer/load issue you've raised (and with relevant logging, you can obv see what the exceptions are).  A blanket .Handle<Exception>() also is less of an issue with circuitbreaker, where handling unenvisaged exceptions is at worst going to trigger breaking the circuit more eagerly.  More of an issue with retry, where retrying on exceptions where no success could be expected, can be pointless and only consume resource.)\nInterested to hear results of further investigations.\n. Also worth making sure - if the system is under high/near-capacity load - that the state-change delegates OnCircuitOpen, OnCircuitClosed aren't overly blocking, given their interaction with the locks held by the circuit-breaker described here.  \n(Somewhat 'clutching at straws' here though - you are likely to have stronger leads as to any possible issue, from your real diagnostics in your environment.). No problem @mieliespoor .  Thanks for letting us know! (and glad it\u2019s all sorted). Thanks @cgourlay! I'll aim to come back with further pointers in coming days.. Can't see a shorter way of getting to Retry(0) :wink:\nMy thought on this had been that we go the step further and create the NoOpPolicy type.  Semantically richer than retry-masking-noop, for probably <100 sloc.\nAlso, a NoOpPolicy doesn't need a .Handle<>() clause (/doesn't make sense), so we'd probably (like TimeoutPolicy) want to configure by  static method directly on Policy.\nThis one 'up-for-grabs' again, for anyone who wants to get into the Polly codebase!\n(I heard on other channels that the original contrib is unavailable at mo). Closed through #214 . hi @aliostad .  You should be able to do this with Polly v5.0's new Timeout policy, then using the new PolicyWrap to combine in a retry policy:\ncsharp\nTimeoutPolicy timeout = Policy.Timeout(myOverallTimeBudget); \nRetryPolicy retry = Policy.Handle<WhateverException>.Retry(/* my retry choices */);\nPolicyWrap retryWithTimeout = timeout.Wrap(retry); // Wrap them in the other order if you want the timeout per call, not per overall strategy\nretryWithTimeout.Execute(cancellationToken => DoSomething(cancellationToken));\n(Just an example: you can do all that both sync/async, for generic <TResult> executions/policies too, and for all flavours of retry.)\nMore:\n+ Timeout syntax summary in the v5.0-alpha readme\n+ Timeout policy deep doco on wiki\n+ PolicyWrap deep doco including recommendations for combining policies for timeout to be overall, or per try\n+ blog post re new Polly v5.0 features\nPolly v5.0 is in alpha on nuget.  Expecting RTM sometime in the next 2-3 weeks.  No change to above features expected for RTM.\nLet us know if that gets you going, or if we can help more.  All feature feedback welcome!. @aliostad  TimeoutPolicy has a configuration overload taking a Func<TimeSpan>, so certainly possible to configure a policy where you can vary the timeouts in real-time (thanks to @brunolauze and @mfjerome for this original idea).  \nRe percentiles of existing response times, Polly does not yet provide these stats, but emitting such events/metrics is a major part of the forward roadmap for 2017 (taking Polly in the metrics/dashboarding direction which Hystrix offers for Java).\n@aliostad  Are you (/any teams you work with) interested in being involved in the metrics development effort?  It's a major piece of work, which will benefit from more community resource. \nThere\u2019s already been prior discussion on our slack channel, and some folks from Canada and Pivotal in the US are interested, too.. @jpierson Are you experiencing the debugger only breaking on the final failed try (when all retries have failed), or on each-and-every try?\nIn my environment, with VisualStudio 2015 Update 3, and \u201cJustMyCode\u201d enabled:\n\nIf Polly is retrying a user delegate several times, the debugger doesn\u2019t break for each failing invocation, only for the final failed attempt (the one Polly rethrows if all configured retries have failed).\nThe debugger throws the exception back onto (ie the debugger breaks at) the policy.Execute(()=> {...} ) (or equivalent) statement; it doesn\u2019t break within Polly source code files like RetryEngine.cs, RetrySyntax.cs etc.\n\nIf your VStudio experience is less good than that, let\u2019s investigate why.\n\n@jpierson Assuming it\u2019s only the rethrow of the final failed attempt that\u2019s causing the debugger to break, you might consider using Polly\u2019s .ExecuteAndCapture/Async(...) (if not already) in place of .Execute/Async().   .ExecuteAndCapture(...) doesn\u2019t rethrow the final exception; instead it captures it into a property on a PolicyResult.  More info here. Should be much less noisy for debugging.. Very interested to hear also any community suggestions around VStudio settings.  \n( @jpierson Have reviewed the SO questions you pointed to; not aware of any tricks better than suggested there )\n. @jpierson Did you find any better solutions on this?\n. @jpierson / anyone: Any idea whether Microsoft changed this behaviour for Visual Studio 2017?  (The fact discussed here under How to Suppress Ignorable Exceptions with DebuggerNonUserCode that a performance improvement in VS2015 led to exceptions in sections marked [DebuggerNonUserCode] still breaking, ignoring the [DebuggerNonUserCode] attribute.)\n@jpierson Since Microsoft are actively engineering on VS2017 RC and seeking product feedback, could be a time to report it? - if the issue still applies.. Closing due to lack of further comment/activity.\nDetailed wiki article now written giving guidance on how to best configure Visual Studio for debugging with Polly, including reference back to this issue.. Thanks @SurajGupta for this interesting suggestion.  Unfortunately, for Polly, it seems non-trivial to set this up compared with the example you quoted and other similars (eg TinyIoc).  \n\nPolly uses Visual Studio 2015 Shared Projects combined with #if compiler directives and compilation constants, in limited ways, to support its non-.Net-Standard targets.  \nThis means simply incorporating the Polly.Shared folder into a user's project 'as is' will not work.\nSome kind of install scripting (Powershell; nuget transforms?) might be needed either to inject appropriate compilation constants into the user's project files (if acceptable) or to process the #if statements or to #define constants in ways appropriate for the user's target.   \nExcludeFromCodeCoverageAttribute appears not supported in .NET Standard until .Net Standard 2.0; but .NET Standard 1.0 is currently an important constituency, for our portable users and .NET Core.\nPolly consists of 100 .cs files, not just one; so the custom-attributing would inject noise throughout (and need maintaining accurately going forward); not just be a one-off addition.\n\nAt the moment, we're not seeing the complexity involved as adding enough value.  \nVery happy though for further community input, if anyone is aware of a simpler approach?\nAnd: Will leave this issue open for a period, so other community can +1 if seen as an important feature.. Closing due to lack of responses, and because not really practicable (/worth the complexity/maintenance effort) for a project Polly's size.  (It would be hard for the raw-code-inclusion approach to come close to a dll-package-manager\u2019s ease of use for incorporating, and updating.)\nPlease re-open if anyone thinks that line of thinking is missing something, though.. For clarity, the following are unaffected by the change proposed in this issue:\nUnchanged: Delegates which support cancellation\nNo change for executed delegates which support cancellation: cancellation will be honoured as soon as the executed delegate responds to it.\nUnchanged: Policy behaviour remains cancellable\nThe changed scenario covers where the policy's next action (after executing the user delegate) would normally be to return the delegate result.\nPolicy behaviour remains cancellable (even with delegates not observing cancellation), if cancellation occurs when flow control is with the policy, or when flow control returns to the policy.\n\n\nRetryPolicy (family): If the cancellation token is signalled during execution of a delegate not observing it, and the configured retries are not complete, any further retries due will be cancelled when control returns to the policy. (OperationCanceledException will continue to be raised, including during the \u2018wait\u2019 phase of WaitAndRetry).\n\n\nBulkheadPolicy: If execution is waiting to acquire an execution slot in the bulkhead, signalling the cancellation token will cancel that wait, and abandon execution of the user delegate.\n\n\nTimeoutPolicy (UPDATED): Exceeding the timeout will cause a pre-emptive return to the caller in all cases, whether the executed delegate observes cancellation or not (see Timeout policy doco for more details).  Signalling the user cancellation token passed in to .Execute/Async(...) however has no effect if the executed delegate does not observe cancellation.\n\n\nFallbackPolicy (UPDATED): The user can control how cancellation is handled by the way the FallbackPolicy is configured.  Cancellation will cause transition to the fallback delegate if the policy is configured with .Handle<OperationCanceledException>() (not if it is not).  The Fallback action can take the cancellation token as an input parameter: the fallback action can thus (a) determine if cancellation occurred; (b) decide what to do on cancellation: throw for cancellation, or execute the Fallback.\n\n\nDocumentation\nIt is intended to add a Cancellation heading to the deep doco (wiki page) on each policy type, indicating the points in each policy's behaviour at which the policy may throw for cancellation.\n. Hi. WaitAndRetryForever was added in v4.1. See https://www.nuget.org/packages/polly for full release notes by version. Hope that helps! . Hi.  Polly offers predicate-filtering on exceptions, as described here.  You can apply this to the InnerExceptions property of AggregateException to filter for a wrapped exception.  For example:\nPolicy\n   .Handle<MyException>()\n   .Or<AggregateException>(e => e.InnerExceptions.Any(i => i is MyException)) // handle the same exception if wrapped\nYou can additionally use AggregateExceptions Flatten() method if there may be any nested AggregateExceptions.\nAggregateExceptions can also often be reduced by making sure you are calling async methods with await (which throws exceptions directly), rather than .Wait() (or other calls similarly synchronously blocking on a Task) (which wrap exceptions in AggregateException). (This may or may not be relevant depending on the construction of your code.)\n. Hi @cemremengu . \nPolly's ExecuteAsync() supports asynchronous executions: more information in the main Polly readme here.  Depending on what you are aiming at, you might want something like:\nawait policy.ExecuteAsync(() => Task.Run(() => MyTask()));\nIf you can convert MyTask() so that it's a genuinely async method async Task MyTaskAsync() or similar, then you might want something like:\nawait policy.ExecuteAsync(() => MyTaskAsync());\n. To comment on: policy.Execute(() => Task.Run(() => MyTask())); : it doesn't make sense.\n\n\nTask.Run(() => MyTask() on its own (disregarding Polly for a moment) creates and immediately returns a Task representing MyTask() running.  \n\n\nThe example doesn't capture that Task into any variable to observe later, nor synchronously wait on its outcome (eg .Wait(), .Result), nor asynchronously await it.  It thus creates an orphaned task which risks an UnobservedTaskException if MyTask() throws.\n\n\npolicy.Execute(...) is synchronous, but it only governs Task.Run(...) near-immediately returning the Task representing MyTask() running.  It won't capture any exceptions thrown by MyTask(), nor (if that was desired) wait synchronously or asynchronously for MyTask() to complete.\n\n\nHope this helps!. No problem @cemremengu , glad it helped.  Re your observation:\n\nusing await policy.ExecuteAsync(() => MyTaskAsync());   [...failed...] [...] \nand using Execute(() => Task.Run() => ...) instead worked for some reason.\n\nIf nothing else in the codebase or environment had changed, worth bearing in mind the possibility that Execute(() => Task.Run() => ...) in fact didn't work.  That is, it's possible the same exception was being thrown in the background by MyTask(), but you just didn't see it because the Execute(() => Task.Run() => ...) created an unobserved task (see earlier comment).  \nWhether/when an UnobservedTaskException manifests (whether/when you see it) depends on a number of factors such as whether you have (or the environment you're running in has; eg if a unit test harness) anything hooked up to the UnobservedTaskException event; which version of .NET you're running (.NET40 and .NET45+ behave differently); whether the Task has been garbage-collected yet, etc.  \n(Obv you can tell more precisely from your environment whether it actually worked eg at the db level - I can't tell from here - it's just worth bearing in mind that possibility of unobserved failure, if the evidence for it appearing to work was (for example) only that no exception was thrown by the initial call). Glad @cemremengu if it's useful, and thanks for the doco idea!  Since the async gotchas we've discussed are async general rather than specific to Polly, and already decently covered in the blogosphere/Stack Overflow, think I'll keep the Polly doco purely Polly-focused.  But: thanks for the idea!  \nIf you're looking for some good references on Task and async/await, some great starting points are:\n\nmsdn on Task-based async\nStephen Cleary's Tour of Task blog posts (all parts)\nStephen Cleary's excellent book\nAlex Davies' book\n\nCheers. :+1: Thanks @DixonDs . @DixonDs When I reviewed this PR, I had a doubt over removing the empty dependency group <group targetFramework=\"net\" /> :  Would removing this from the nuspec mean that when the Polly nuget package was installed into a project targeting the .NET Framework, nuget would then attempt to install the .NETStandard1.6 libraries as a dependency?  (This should not be necessary for a .NET-Framework-targeting project, as the Framework includes all the relevant Base Class Libraries.)\nTesting suggests removing <group targetFramework=\"net\" /> is causing an issue: installing the resulting nuget package in a .NET4.5.x-framework-targeting DLL, seems to be making nuget install additional (unnecessary for .NET4.5) direct references to the various \"System.*\" packages and dlls.  Same for .NET4.6.x.  So we plan to re-instate the <group targetFramework=\"net\" />.  \nDoes this make sense, or do you think we're missing anything?\n(For background: the Polly.nupkg package does include separate compiles for .NET4.x, for those still targeting the .NET framework directly, separate from the .NETStandard1.0 target.)\n(/cc @twsouthwick Any comment on this or on the changes in the original PR welcome.). Thanks @twsouthwick for deep explanation.  Makes sense about type-forwarders, in terms of a library supporting .NET45 via a .NETStandard1.0 binary.  (Think some of the differing suggestions in this thread have stemmed from confusion over whether we are pursuing one single binary Polly.dll for both .NET45 and .NETStandard1.0, or separate binaries - currently separate.)\nRe whether (/cc @joelhulen) to provide .NET4.5 support through a single (same) binary as .NETStandard1.0: Advantage: single binary.  Disadvantage: Install into a .NET4.5-targeting solution is much noisier than sticking with supporting .NET4.5 through a dedicated Polly.dll (as we currently do).  \nIn trials just now against a couple of in-house .Net4.5 / .Net4.6.1 projects which use Polly, installing a Polly.dll supporting .NET4.5 via a .NETStandard1.0 binary added approx 45 extra package references (per project) in each packages.config and 5-20 extra System.*.dll references in each .csproj.  I guess @twsouthwick this is the expected behaviour with the type-forwarders(?), but it makes for a much noisier/more interventionist install, for those users still targeting the .NET Framework?  \nAny other thinking we're missing on this?\n(Thanks both @DixonDs and @twsouthwick for your contributions!). @twsouthwick Our supported targets for Polly v5.0 RTM are:\n(summary /cc @joelhulen for whether you have view on rationalising any of the nuget packaging) \n.NET40 with Async: \n\nCan't be supported via a .NET Standard binary\nWill be via dependencies <group targetFramework=\"net40\"><dependency id=\"Microsoft.Bcl.Async\" version=\"1.0.168\" /><dependency id=\"Nito.Async\" version=\"4.0.1-pre\" /></group>\nDelivered (for historical reasons) as a separate nuget package https://www.nuget.org/packages/Polly.Net40Async/ . We could merge it into the main Polly package.  The separate package however quite usefully tells us (via its separate nuget stats) the extent of the .NET4.0 userbase (about 3%), which might guide future support decisions.\n\nNet Standard 1.0:\n\nFor all portable support, .NET Core, future platforms\nDependencies (per #174) as <group targetFramework=\"netstandard1.0\"><dependency id=\"NETStandard.Library\" version=\"1.6.0\" /></group>\n\n.NET4.5+ : \n\nDependencies currently declared as <group targetFramework=\"net\"/> but definitely better as <group targetFramework=\"net45\"/> (thanks @DixonDs for this)   \nCurrently delivered as a separate binary Polly.dll in main Polly nuget package, with Net Standard (eg https://www.nuget.org/packages/Polly/5.0.2-v5-0-alpha0001)\n\nSo whether to merge .NET4.5 into .NetStandard seems the main question .... Thanks @twsouthwick @DixonDs for all your useful input.  . Hi @aliostad, we implemented exactly this pattern in the microservices architecture where I currently work. \nA simple approach is use the onBreak delegate of CircuitBreaker to cycle through a list of available sources, eg\nint sourceToUse = 0; \nCircuitBreakerPolicy breaker = Policy\n    .Handle<Whatever>( ... )\n    .CircuitBreaker( // or AdvancedCircuitBreaker\n        exceptionsAllowedBeforeBreaking: /* whatever */,\n            durationOfBreak: /* whatever. See note below about TimeSpan.Zero */, \n            onBreak: (e, i) => { sourceToUse = (sourceToUse + 1) % numberOfSourcesAvailable; /* or whatever, to make next call address the next available source */ }\n        ); \n(very simple example - can all be sync or async; more sophisticated approaches for selecting the initial or next source, whatever)\nAt the call-site wrap breaker.Execute(/* execute using sourceToUse */) in your own while loop or Polly retry policy.\nYou said failover rather than circuit-break?  If you don't want the circuit actually to break, just set  durationOfBreak to Timespan.Zero: onBreak will still fire, but the next caller will find the circuit closed still.\nAlternatives:\n\nWrap the circuit-breaker in a Policy.Handle<BrokenCircuitException>().Retry(/* whatever retry policy you want */), configure the onRetry delegate of the retry policy to cycle the sources, similar to onBreak above.\nUse Fallback policy or a chain of fallback policies.  Fallback's usual purpose is to provide a substitute response for a failed operation, but can also be used to provide an alternative failover execution.  \n\nFallbackPolicy (in this context) probably more appropriate for folks with a simple 1->2 primary->secondary failover, or known-length chain of failovers.   \nThe onBreak/onRetry approach cycling through a list of sources otoh can also scale if you're adding/removing sources from the mix dynamically, eg horizontal-scaling for load, which is nice.\nLet us know if that gets you going, or if we can help more!  Thanks . For those wanting to follow this, further discussion on metrics in Polly is evolving on our slack channel .\n(We will also cross-post back to Github, when there are substantive proposals to discuss)\nAlso, the Polly roadmap sets out the initial envisaged architecture for metrics in Polly, along with some related discussion against a previous PR\n. Pulled out a fresh issue, #326, to bring this to the top of the visibility pile. . Closing as now covered by #326 . Hi @tomkerkhove \nThe stack trace of the NullReferenceException points at: https://github.com/App-vNext/Polly/blob/master/src/Polly.Shared/PolicyBuilder.OrSyntax.cs#L79\nThe stack trace suggests resultPredicate is null when the retry policy comes to evaluate retry conditions, which suggests resultPredicate was null when configuring the policy with:\nretryPolicy= Policy.HandleResult(resultPredicate)\nDoes this help?. Thank you v much for this @christopherbahr , completely see the problem it solves.\nA question in my mind is how this interacts with the wider question of adding an IPolicy interface which exposes the Execute() methods.  My instinct is that when users see an ICircuitBreakerPolicy interface (says: \"this can be used as a circuit breaker policy\"), they would expect it to allow them to call the various Execute() overloads (likely with ICircuitBreakerPolicy : IPolicy).  The Polly Roadmap discusses whether we are ready to add that IPolicy interface (we have not yet for good reasons, tho getting closer).  \nThis coupling could perhaps be unpicked by renaming the interface you propose something like ICircuitState, but do Isolate() and Reset() fit in that?; and is pulling it out of  ICircuitBreakerPolicy desirable? (Comment welcome!)\nI am going to recommend not merging this one immediately, because we need I think to resolve some of above questions first.  But it's very likely we could do something like this, once/assuming IPolicy goes in.  Furthermore, I think we'd want to extend the concept the PR proposes more widely, across all policies and variants: eg BulkheadAvailableCount on IBulkheadPolicy; LastHandledResult on an ICircuitBreakerPolicy<TResult> : ICircuitBreakerPolicy; etc.\nThanks again for the PR, which sheds light on an important need we can feed into the interface thinking.\n(ie unifying between Policy and Policy<TResult>, and between different TResult forms generally) . @christopherbahr no worries!  Thanks for the original suggestion, which definitely helped focus how we should do #257 . . @christopherbahr Polly v5.2.0 released, including your original idea from here. Marking this 'up-for-grabs'.  \nInitial thoughts are that a solution would probably include: \n\nchanging the 'fake exception' line to _lastOutcome =  null\ndefending against _lastOutcome == null as necessary elsewhere. @lakario Many thanks for this!  (Your last build simply fell foul of some niggling timing sensitivity in unrelated tests (slower running on AppVeyor); I have hopefully squashed that out in #212 .) \n\nCode of PR looks good!  Considering when to merge, pending the v5.0.4-pre Net4.0Async fixes which will go out just ahead.  \nShall we add the following documentation additions, to clarify?  (Feel free to cross-check / reword if appropriate!)\nEDITED WORDINGS after original post\nhttps://github.com/lakario/Polly/blob/master/src/Polly.Shared/CircuitBreaker/CircuitBreakerPolicy.cs#L34 : Add <remarks>This will be null if no exceptions have been handled by the circuit-breaker since the circuit last closed.</remarks>\nhttps://github.com/lakario/Polly/blob/master/src/Polly.Shared/CircuitBreaker/CircuitBreakerPolicy.cs#L85 : <remarks>This will be null if no exceptions have been handled by the circuit-breaker since the circuit last closed.</remarks>\nhttps://github.com/lakario/Polly/blob/master/src/Polly.Shared/CircuitBreaker/CircuitBreakerPolicy.cs#L92 : <remarks>This will be default(TResult) if no results have been handled by the circuit-breaker since the circuit last closed.</remarks>\nThanks for your input into the original issue!. Thanks @lakario !  Merging!  . Thanks @pomma89, you are correct.  \nWe will aim to publish the replacement Polly.Net40Async nuget package in the next 24-48 hours.. @joelhulen Could you publish just the Polly.Net40Async and Polly.Net40Async.Signed nuget packages (they will publish as v5.0.4-pre), once the last merge-build completes?  The merge-to-master build is for some reason currently stuck at pending.\n@pomma89 Once published, could you confirm the package now installs good for you?  (to complement my tests in #210).\n@joelhulen On confirmation, I may recommend we merge another item or so (eg #207) to make a non-pre-release release.\nThanks. @pomma89 https://www.nuget.org/packages/Polly.Net40Async/5.0.4-pre is out.  Happy for feedback if this resolves your original issue.  The new package pulls into .NET40 apps good for me.  . Thanks @pardahlman for the extensive conversation in our slack environment.  Leaving this issue open for a short time, to see if others you've alerted to it, have more to add.  Thanks. Closing due to lack of input on this channel (discussion moved to the Polly and RawRabbit slack channels). Thanks @lakario .  Merging!. Thanks @lakario !  Excellent job following the Polly internals!  :+1: \nHad thought: we can remove even the 'cancellationToken.ThrowIfCancellationRequested();'.  Make the 'no op' concept completely pure - does nothing except exec user delegate.\nHappy to slip this into the v5.0.5 release if you are good for the amends\nThanks again!. Thanks @lakario ! AppVeyor reports: error CS0266: Cannot implicitly convert type 'int?' to 'int'. An explicit conversion exists (are you missing a cast?).  Do you want to have a look? \n:+1: clearing .Shared out of namespaces.  Spotted yest, forgot to mention.  VS2015 adds that into any classes freshly created, due to the Shared projects approach.. Thanks @lakario for this valuable contribution!  Very useful for those who want a quick way to stub-out Polly for unit-testing.  Also forms a great outline of what is needed to create a new policy.\nMerging ... :smiley: . @rahulrai-in Polly does not provide an in-built way to share circuit state between different processes / instances of an application.\nPrevious discussion on Polly highlighted possible risks with this pattern intrinsic to a distributed system.  Essentially, if node A1 is experiencing problems in calls to M, is it safe to assume that other nodes (A2, A3, A4 say) also would?  What if the problem is specific only to the network path between A1 and M, but not A2/3/4 to M?  Circuit-state co-ordination could then be dangerous and unhelpful: it risks telling A2/3/4 they can't talk to M, when in fact they still can.  Likewise if the problem is something internal only to A1 (eg burst of requests or other malfunction causing local CPU/thread/memory starvation).  What if the issue is a general network problem between A1 and anywhere?  Most methods to co-ordinate circuit state (shared db; Redis cache; messaging) would depend on the same network ...\nPer these risks, some commentators suggest it may be simpler, and safer, just to treat A1, A2, A3, A4 as independent actors, and let them pop their own circuits on the only thing they can know to be true ... that they aren't getting answers from calls to M.. @rahulrai-in  If otoh making a judgment the benefits outweigh the risks for a particular installation (effectively, you take the risk of assuming the problem is with M, not anywhere else), you could support this scenario with no changes to current Polly thus:\n\nMake the onBreak() and onReset() delegates of the CircuitBreaker, broadcast the break and reset to other instances of the application, for example via a messaging system.  \nAll instances listen for breaks and resets.  \nOn hearing of a break made by another instance, they would manually break their instance using Isolate().  [or recode Polly to allow manually break only for a set period]\nOn hearing of the reset made by the original instance, they would manually reset using Reset().  \n\n(a possibility, not necessarily a recommendation)\n.\nTo implement within Polly, alternatively, a genuine shared external storage of the circuit state updated on each and every call, would require coding a new ICircuitController implementation.  OnActionPreExecute() would read the circuit state from shared storage. Other methods such as OnActionSuccess(), OnActionFailure() etc would update it.   \nWe would not want the core Polly package to take a dependency on a particular external storage system, so an implementation would have to go in an external package such as Polly.SharedStateCircuitBreaker, rather than in the core Polly package.\nBoth approaches imply extra network overhead, and are vulnerable to failure if the network isn't available.. @moonytheloony The notion of a quorum of services which must independently report their circuit broken, before forcing others to break, seems a reasonable way of alleviating some of the risks around a single faulting service incorrectly influencing others which might otherwise succeed.\nThinking quickly, we would possibly need look at what needs adding to ICircuitController<TResult>, and what of abstract class CircuitStateController<TResult> and its existing implementations might need to be marked virtual, in order that an implementation for this feature could intercept circuit operations, to share and manipulate state.  I will aim to look at this, or: please feel free to look yourself!\nWhat would you envisage needing sharing?  The underlying statistical state of the circuit (numbers of successes/failures etc metrics), or just the major events/states? (breaks/resets; CircuitState).  Or?  EDIT: @reisenberger come to own conclusion that only the major events/states need sharing (as tarup also says later)\nNote that we are already simultaneously engaged on other large-scale features, including caching and metrics, so there are a few competing priorities in the short-term.\nFeel free to join the Polly slack channel for on-going discussion on features.\nIdeally, any solution which would eventually be integrated into the Polly stable would be generalised: ie work for both existing kinds of CircuitBreaker; and connect to external storage with an interface, in order that alternative external storage implementations could easily be coded by interested parties.\nWhat do you think?. @bunceg, you were interested in this pattern too? (circuitBreakers breaking in common across distributed systems.)  Please join the conversation as feature evolves, if you have angles to share.. Another request for this feature at #259 . Proposal for DistributedCircuitBreaker now posted as #287 . Closing as duplicate, main discussion now on #287. @vgouw @Kharos We need to get this issue squashed.  I'm just back from three days travel, and now looking at this.. No prob @Kharos , TDD-driven proof-of-concept already done yesterday, soon something pushable for review / comment / field testing :+1:. \n( @Kharos @vgouw Have reviewed the various edge case qs / suggestions around transition out of HalfOpen state.  Will respond and let's discuss further after engineering and validating a simple-as-possible  (but not simpler) implementation! ) \n. @vgouw @Kharos Thank you for highlighting this issue.\nBug fix(es), unit tests, and full integration tests (deterministically controlling parallel concurrent requests to simulate the scenarios) all now pushed to https://github.com/reisenberger/Polly/tree/b505pre-BreakerFixes . Specs aim to have simulated the scenarios thoroughly, but review and field report from your environment always welcome.  \nFeel free to review/test from https://github.com/reisenberger/Polly/tree/b505pre-BreakerFixes ; will push this also as a v5.0.5-pre nuget package soon, may work another minor circuit-breaker change #207 into same.\n@Kharos Thanks for this insightful angle:\n\nif we only allow a single half-open request and that request hangs it may keep the circuit open, so \nthere needs to be some mechanism to e.g. allow a half-open request every [break duration] time \n\n:+1: good solution, have adopted this.  This is also how Hystrix approaches the problem.\n@Kharos Re:\n\nAdditional edge case bug: The onBreak() callback is potentially called multiple times \nin that scenario, once for each failed hald-open request.\n\nLocks around the transition from HalfOpen to Open again, and that locked section always transitioning the circuit out of HalfOpen before releasing the lock, mean that transitions from HalfOpen to Open couldn't be causing this (duplicate invocations of onBreak()).  However, a thorough code review followed by integration tests suggested then proved that long-running requests, started when a circuit was closed, but hitting it with further failures later when it had already opened, could cause duplicate invocations of onBreak().  This issue also squashed, with accompanying integration tests.  Thanks @Kharos for the commentary about long-running request edge-cases, which pointed to this.  . @Kharos Obviously HttpClient (if using) has its own built-in soft timeout on SendAsync(), throws a TaskCanceledException on timeout (perhaps not uniquely distinguishable between a cancellation and a timeout).  Re:\n\nWhat I really need is a possibility to treat web requests that take longer \nthan some amount X of time as a failure \n\nhave you seen the Polly TimeoutPolicy?  Its TimeoutStrategy.Optimistic is the same mechanism HttpClient uses underneath (timing-out cancellation token), but it throws a custom TimeoutRejectedException, giving you something you can treat more clearly as a failure.   Wrap a TimeoutPolicy inside the CircuitBreaker either manually or with the new PolicyWrap, have the circuit-breaker handle those TimeoutRejectedException, and you have precisely the mechanism to treat web requests exceeding duration as health indicators that can eg be configured to trigger a circuit-break.  (TimeoutPolicy with TimeoutStrategy.Optimistic also transmits its timing-out cancellation token into the governed call, so you achieve the same soft cancellation on HttpClient.). @Kharos :+1: re test confirmation.  Those tests match the (unit and integration) tests I added to the Polly codebase too, so we have regression coverage.\n@joelhulen and I will aim to push out new Nuget pkg in next few days.  (May squeeze other outstanding PRs into it, to avoid frequent mini releases.). @Kharos With your nuanced configuration where you want to detect that tasks have exceeded a certain time limit but not abort them if they do, I agree that you need a custom implementation such as the one you describe, rather than the off-the-shelf TimeoutPolicy.. Closing - implemented as recommendation which was set out, in #223 . Closing - implemented as recommendation which was set out, in #223 . Closed via #223 . Closing.  Was a frequent problem in December/January, but has not recurred since then.. @lamest Polly contains a .NET Standard 1.0 target, which covers those Xamarin targets, so: Yes.  . Hi @lamest \nI'm not sure if this exactly answers your question, but:\n\n\nPolly targeting .NET Standard 1.0 (rather than 1.2) doesn't mean we're targeting an older build of .NET.  A .Net Standard version number defines a subset of APIs that platforms implementing that .NET Standard have to implement.  \n\n\nLibraries like Polly intentionally target the lowest-numbered .Net Standard definition they can: they state the smallest subset of .NET APIs they require, in order that they can be used by the widest range of implementation platforms.  So Polly being able to reference the lowest numbered .NET Standard (1.0) is a positive: it makes Polly as widely usable as possible.\n\n\nRegarding the System.* apparent dependencies installed when referencing the Polly .Net Standard 1.0 target, twsouthwick at Microsoft clarifies these are type forwarders.  IE They aren't extra DLLs because Polly has somehow targeted a lower-numbered version of .NET Standard.  It\u2019s acknowledged that this noisiness (the multiple extra System.* references installed) is part of using the .NET Standard 1.0 approach at the moment.\n\n\nLet us know if that helps! . Closing due to lack of activity.. An example of why IPolicyRegistry useful: it would allow for simple stubbing-out of Polly in unit tests.  \nConsider an application architecture which defines policies in the registry on start-up; then passes the PolicyRegistry instance  by dependency injection to components needing a policy.  \nWith the new NoOpPolicy (thanks to @lakario !), this architecture would facilitate a very simple NoOpPolicyRegistry : IPolicyRegistry stub, to stub all policies out for unit tests on the application components:\n```csharp\npublic class NoOpPolicyRegistry : IPolicyRegistry\n{\n    private static NoOpPolicy noop = Policy.NoOp();\npublic Policy this[string key]\n{\n    get { return noop; } // Intentionally override policies normally provided, with NoOp.\n    set { /* do nothing */ }\n}\n\n// Other members ...\n\n}\n``. For future reference: Discussion [in our slack channel](https://pollytalk.slack.com/archives/general/p1487050660001004) moved this towards using a simpler (more reduced)IPolicyRegistryinterface than the fullIDictionary<,>`.  (Further comment welcome)\nImplementation in progress; PR expected.. Closed via #231 and #263 . @nathan-alden  Thank you for your kind words.  \nThe release has been created at: https://github.com/App-vNext/Polly/releases/tag/v5.0.5\n@joelhulen Any reason not to create such a tag every release?  Suggest we continue to deliver binaries only via nuget, but a tag of the release here does no harm?\n@nathan-alden To help users follow what's in a new release, we also aim to tag Issues fixed and PRs merged in each release, with milestones matching the release number.  See, eg https://github.com/App-vNext/Polly/milestone/14?closed=1\n. No problem @nathan-alden , makes sense :+1:  , and understand that's needed in some environments.. Salut @Julien-Mialon !  J'ai mis les changes dans cette branche:  https://github.com/reisenberger/Polly/tree/NetStandardReference161\nVous pouvez verifier si ca marche, avant que je fusionne avec master?\nIf you run build.bat from that branch, the build will dump the nuget packages in subfolder artifacts\\nuget-package.    Let us know if those nuget packages fix the issue for installing against Profile 111, before we merge this to master.  \n. Merci @Julien-Mialon .  Fusionne!\n@joelhulen We're good to release v5.0.6 to nuget from master.  Already tagged as a release in GitHub.. Hi @rlenders and welcome!  I can suggest approaches to this using either Polly CircuitBreakerAsync (it has exactly the one-request-after-cooldown-period semantics you want) or Stephen Cleary\u2019s AsyncManualResetEvent, but first I have a question.  \nWhat is the scale/throughput here?  You mention \u201chundreds of threads execute through that policy concurrently\u201d, and (in the error case) delaying those executions for 5 minutes.  How many requests do you envisage would gather queuing, during the five-minute period when the request \u2018at the head of the queue\u2019 is waiting to make its retry? How large that number is might influence comments on architectures/patterns for this.\n. Hey @rlenders.  Glad you got something going with AsyncManualResetEvent!  Yes, it apparently doesn't have a wait-with-timeout overload, though you could use the approaches in comments to that issue, or the cancellation-token overload+ in the sourcecode with a timing out cancellation token like Polly does in TimeoutPolicy (although the AsyncManualResetEvent doco says that overload+ doesn't exist).   \nPossibilities with Polly\nTo get a combination of retry and circuit-breaker semantics with Polly, you can combine retry and circuit-breaker policies using PolicyWrap, or manually.  \n```csharp\nTimeSpan coolOffPeriod = TimeSpan.FromMinutes(5);\nTimeSpan acceptableLatencyOfSuccessfulCall = / define this / ; \nDateTimeOffset retryAfter = DateTimeOffset.MinValue;\nvar breaker = Policy\n    .Handle() \n    .CircuitBreakerAsync(\n        1, // Block other callers as soon as a single occurrence of the governed exception occurs.\n        coolOffPeriod, // Nobody can place a call in the cool-off period - and only one thread can retry, when the cool-off period is complete.\n        (ex, breakDuration) => { retryAfter = DateTimeOffset.UtcNow.Add(breakDuration); }\n    );\nvar headOfQueueRetry = Policy\n    .Handle() // First call which causes circuit to break will still throw this.\n    .WaitAndRetryAsync(1, i => coolOffPeriod) // Retry only once, as soon as cool-off period has elapsed.\n    );\nvar behindHeadOfQueueRetry = Policy\n    .Handle()  // Subsequent calls hitting broken circuit will throw this.\n    .WaitAndRetryAsync( \n        1, // Only retry once.\n        i => { \n                 TimeSpan remainingWait = (retryAfter - DateTimeOffset.UtcNow) // Programatically determine how long a call arriving during the cool-off period, should wait, so it's retried at the end of the cool-off period. \n                     + acceptableLatencyOfSuccessfulCall;  // But the 'waiting' threads want to give the thread at the head of the queue, enough time for its trial execution to complete successfully, before the waiting threads retry.\n                 return remainingWait <= TimeSpan.Zero ? TimeSpan.Zero : remainingWait;\n             }\n    );\nvar combinedStrategy = behindHeadOfQueueRetry.WrapAsync(headOfQueueRetry.WrapAsync(breaker));\nawait combinedStrategy.ExecuteAsync(ct => { / etc / }, cancellationToken);\n```\nNot necessarily a finished solution, but illustrates possibilities.    \nDriver behind asking about queue volumes was in case a memory bulge from the multi-1000s requests queuing could be a concern.  There could be lighter-weight ways of pending the queuing requests, if an issue.    Or an upper-bound: maybe a bounded async producer-consumer collection like AsyncProducerConsumerQueue, or wrap a BulkheadPolicy with a large queue into the PolicyWrap?  Or push the requests out to a messaging system (eg if losing them on a crash were an issue) - lots of options\nAre there any disadvantages to releasing all the queued requests pretty-much simultaneously, when the cool-off period is up?  In the calculate-when-to-retry approach of the above Polly example, you could introduce some randomisation or regular separation.   \n\nIf the underlying need is rate-limiting, could something like Jack Leitch's RateGate be useful?  Would you see it as a useful Polly feature, to have something like this as a Polly policy (say, RateLimitPolicy), combinable with other Polly policies in a PolicyWrap?\nHope some of this is useful!. Hi @rlenders \n\n\nAre there any disadvantages to releasing all the queued requests pretty-much simultaneously, when the \ncool-off period is up? In the calculate-when-to-retry approach of the above Polly example, you could \nintroduce some randomisation or regular separation.\n\nI'm not sure what you mean. Could you elaborate on this?\n\nWell, I am in to the realms of speculation here about the third-party API (and speculation may not help: as you rightly point out, your real challenge is to know what the API's rate-limit is!).  I just wondered - if it is a third-party API that limits users according to how often they access it - whether hitting it simultaneously/ very densely with multi-thousand requests might risk triggering a red flag again at their end.\n\nIt seems rate limiting is only useful when you know exactly how much requests per timespan are allowed\n\nCompletely.  If you could determine (perhaps by experiment) what the API's rate-limit is, then a rate-limit calling strategy could be useful, because you could put calls through at a (matching) steady throughput, without having to break and potentially queue 1000s.  But if you don't know - and I suppose in case the API changes its rate limit rules anyway - the wait-and-retry stategy (assuming memory bulge is managed) seems like a possible strategy. :+1: \nThanks @rlenders for the interesting discussion around a Use Case I hadn't thought of for Polly.  Let us know if you need anything else!. Closing due to lack of recent activity.  Please re-open if further questions / further support is required.. @ankitbko Apologies for my delay replying (due to volume of paid work!).  Many thanks for the revisions!   This is perfect for PolicyRegistry for policies of non-generic type Policy!  \nWhen travelling two weeks ago, I realised we hadn't provided a PolicyRegistry<TResult> for policies of type Policy<TResult>.  \n(Background: In Polly, Policy<TResult>. does not extend Policy, because the original non-generic Policy class also has a generic method .Execute<TResult>(...). During discussion around v4.3.0/v5.0, people preferred to keep that overload (for its flexibility; and removing would be a big breaking change). But its existence necessarily means Policy<TResult> cannot extend Policy. Policy<TResult> otoh is essential for strongly-typed .HandleResult<TResult>(...), and strongly-typed composition of PolicyWraps.)\nWhat we need to do\nTo complete the PolicyRegistry offering, I think we need to add a PolicyRegistry<TResult> : IPolicyRegistry<TKey, TResult>, for policies of type Policy<TResult>.  Could I suggest you:\n\nMake a PR of your branch onto new v5.0.7 branch I created rather than master\nThen either you or I can add the PolicyRegistry<TResult> concept there, add doco etc.\n\nI think the need for IPolicyRegistry<TKey, TResult> means we should probably simplify public interface IPolicyRegistry<TKey, TPolicy> where TPolicy: Polly.Policy, replace it simply with public interface IPolicyRegistry<TKey, Policy>.  Otherwise, the new public interface IPolicyRegistry<TKey, TResult> has a signature-clash with  IPolicyRegistry<TKey, TPolicy>.  \nViews?. @ankitbko  Perfect to just re-target the PR to the new branch!\nThe evolution of Polly has led to Policy<TResult> does not extend Policy.  Past #129 describes further.  Also, non-generic policies can execute Actions returning void, while generic Policy<TResult>, can only execute Funcs returning TResult.  So, unlike IEnumerable<T> : IEnumerable, we do not have Policy<TResult> : Policy.  \nI was also uncomfortable about multiple registries: one registry would probably be better, as you say.  Creating an empty marker interface, as you suggest, could be a way to do this.  I can think of one other approach.  I will aim to spike out - or describe in more detail - shortly.. Huge thanks @ankitbko for all the great thinking towards PolicyRegistry!  \nEmpty marker interface definitely a possible way to bridge between Policy<TResult> and Policy which are (necessarily) not in an inheritance hierarchy.  Two thoughts followed from the empty interface:\n(a) if the registry returns instances fulfilling empty IsPolicy (say), users would have to cast the received policy every time to the relevant Policy or Policy<TResult>.  To avoid that, the Registry c/should provide helper getter overloads to reduce the burden, maybe something like:\npublic Policy          IPolicyRegistry.Policy(TKey) // or Get(TKey)\npublic Policy<TResult> IPolicyRegistry.PolicyFor<TResult>(TKey) // or Get<TResult>(TKey)\n(b) given an empty interface, users might soon ask why it is empty, and ask for populated interfaces that in fact provide the relevant .Execute(...) overloads they can use.  \nWhich led me to consider whether:\n(i) we can/could/should now introduce interfaces, say, IPolicy, IPolicy<TResult>,  IPolicyAsync, IPolicyAsync<TResult>, defining the relevant available .Execute/AndCapture/Async(...) overloads.  Alongside the possible empty marker interface IsPolicy.\n(ii) whether either the Policy<TResult>/Policy split, or the sync/async split, can be reduced/mitigated.  \nRe (ii), I think not - intend to post later on this - but now is definitely the time to consider, before we introduce interfaces.  If we go for interfaces now, the helper methods at (a) above also would return those rather than the concrete Policy<TResult>/Policy .\nThoughts on any aspect of this? . Hi @ankitbko !  Here reisenberger/Polly/policy-registry-TResult-nointerfaces is a prototype  branch (light amend from yours) providing a single policy registry class offering overloads for both Policy and Policy<TResult>, without using interfaces.  \nthis[...] operators have been replaced by Get/Set methods.   Add, Set, Get, and TryGetValue exist in overloads for both generic and non-generic policies.\nComments welcome!\nWe could go this way with PolicyRegistry if we don't introduce interfaces.  (Not necessarily preferring this: just the first prototype which is ready.)  Working separately towards a branch of Polly including a full set of interfaces  (empty) IsPolicy and (populated) IPolicy, IPolicyAsync, IPolicy<TResult>, IPolicyAsync<TResult>.  Then we can compare the two.\n. Hi @ankitbko !  Here is a Registry based on yours, but allowing us to pull policies out of the Registry correctly typed, based on generic methods.  The generic methods become particularly useful because of adding interfaces.  \nThis version again omits the this[...] operators, because the getter on that, registry[key], could never return policies of an immediately usable type: users would always have to cast first.  \nEDIT: Do you think it is better to exclude the this[...] operators? (because the getter can only return something that would always have to be cast).  Or retain the this[...] operator (because people are used to it), and just use the doco to explain the existence of the more helpful .Get<TPolicy>(...) ?\nPlease let me know what you think!  (particularly between the two options of this comment, and the previous one). @ankitbko Huge thanks for your thoughtful feedback on the interface-based approach I overlaid on your PR!\nPushed changes in response to your comments, again to this branch: https://github.com/reisenberger/Polly/tree/feature/interfacesplusregistry\nResponses to your comments:\n\nSince now we have interface, does it make sense to have dictionary value of type object in IDictionary or should we make it IsPolicy like IDictionary?\n\nAgree.  Done!\n\nWithPolicyKey(String policyKey) method in ISyncPolicy has returns type of Policy (Line 22). Any particular reason of having reference of derived class in interface? (Similar for other sibling interfaces)\n\nGreat catch!  Done!\n\nThere are two ways to add to registry Add(string key, TPolicy policy) where TPolicy : IsPolicy and Set(string key, TPolicy policy) where TPolicy : IsPolicy. Any differences between two or can we remove Set and just keep Add (or vice versa)?\n\nThe intention was that Set() was like this[], so Add() and Set() differed in that Add() would throw ArgumentException on duplicate key, while Set() would not.  The very fact that you asked the q though, shows that sticking with API precedent probably would engender less confusion.  I've therefore switched Set() back to this[].\nThe original reason for not using this[] was the thought that users might find it frustrating that registry[key] necessarily returns only an IsPolicy, which would require the further cast (as you observed), in order to be useful.  I have addressed that now by giving explicit guidance right in the intellisense, highlighting the Get<TPolicy> alternative. And can ditto in online doco.\n\nIf using Interfaces, is there any need of making Add method generic? Alternative would be to just have Add(string key, IsPolicy policy).\n\nAgree could reduce it to IsPolicy.  Kept it generic just for symmetry with Get<>().  Encourages users into thinking about which policy type they are dealing with, for when they later Get<>() it back out of registry.\n\nI am leaning more towards interfaces side. It leaves registry class clean (rather than having different get set for Policy and Policy). What do you think?\n\n:+1:\n\nBut if we change IDictionary to store type IsPolicy, it may be useful if we add methods to IsPolicy rather than having it empty. Do you think it is possible to move common methods from ISyncPolicy and IAsyncSyncPolicy (and their generic counterpart) to IsPolicy?\n\nCompletely get the suggestion.  I'm (starting out) genuinely ambivalent, per following discussion:\n(a) The history is that the sync/async split in Polly was, long pre-AppvNext, implemented (unfortunately imo) as a runtime exception on the Policy class (instances of Policy are usable only for either sync or async, but enforced only at runtime rather than compile time), instead of defining separate Policy and PolicyAsync classes at that point.  That historical decision means that users get both sync .Execute(...) and async .ExecuteAsync(...) overloads available (eg in intellisense) on every concrete Policy instance, even though only half the overloads are valid (on any one instance), and the other half will throw.  \nMy introducing SyncPolicy and AsyncPolicy as interfaces then is an attempt to move users away from this - to separate out the sync and async functionality currently joint on Policy, by that well-known interface segregation principle.  If users get into the habit of using ISyncPolicy/AsyncPolicy , they will get only the set of execution overloads that apply :grin: \nAs SyncPolicy and AsyncPolicy are interface segregation, there are no common overloads to move on to IsPolicy.  We essentially have two options:\n(b-i) Keep IsPolicy empty, a marker-interface only (and encourage users towards SyncPolicy and AsyncPolicy)\n(b-ii) Make IsPolicy a union of SyncPolicy and AsyncPolicy\n(and similar for generic versions)\nHaving started out ambivalent, I'm leaning to (b-i).  Doing (b-ii) just places us back to the \"false promise\" that a single Policy instance can be used for both sync or async, when in fact it can only be used for one or other.  (b-i) at least begins to push the solution architecture in the right direction.  \nFor further background, this recent blog post sets out why I think we're stuck (without a major change of syntax) with separate Policy instances for sync and async executions, in Polly.\nSorry for that long explanation.  The sync/async split in Polly is an unhappy legacy part of the Polly architecture I've been tussling with, hence the long explanation - and interested in people's views.\n:sweat_smile: . Hi @ankitbko  Per discussion on slack, I have:\n\ndrafted some wiki documentation ( PolicyRegistry; Polly and interfaces ).\nalso readme doco in my working branch on this feature.\n\nAnything you think we should add/change?\nI'll aim to sort out the PRs between code branches in next few days\n. @ankitbko Merged this to the App-vNext:v5.0.7registry branch.  Decided it would be easier to merge there, then add my interfaces on top.\nThank you for your great contribution to this feature!  :100: . Hi @dannydwarren ! Net40 support is provided via a separate nuget package (also available as a signed package) as described in the main Polly readme.   \n.NET4.0 support was moved wholly out of the main package into this separate package at v5.0.0.  . Hi @dannydwarren !  I've removed the .NET4.0 reference from the main Polly.nuspec, to make this less confusing.  Thanks for pointing it out!  It will update on Nuget next time we have cause to publish a package.. Polly TimeoutPolicy will apply an overall time limit to whatever delegates you execute through it - there isn't at present a way to feed information back into a TimeoutPolicy instance to reset/adjust the timer on the basis of some external event.  (EDIT: And there would be complexities to add this, mostly around scoping - a single policy instance may be used in multiple places, including concurrently.)\nA possible approach that comes to mind for a large/slow-download could be to break the data-receive operation into smaller, chunked receives.  You could then apply a timeout to each request for a further chunk - effectively you would be gauging 'whether data is being actively received from the server' by specifying some throughput below which you consider it to be failing. eg: \"If I don't receive another 100KB in 10 seconds, treat as a failure\".\nThe usual approach to chunking a receive if using HttpClient is to make the first call to HttpClient using  HttpCompletionOption.ResponseHeadersRead.  The initial call returns as soon as the response headers are received - you could apply one level of timeout here to getting a response back from the server at all.\nYou could then read the response stream in chunks of a size you specify, similar to this example.  A TimeoutPolicy wrapped round each stream.ReadAsync(...) call should apply a time limit to obtaining each next chunk.\nThis isn't a pattern I've had cause to implement in my line of work - please let us know how you get on (if you take this approach - or indeed another), because it would make a great example to add to the wiki!. Hi @cliffcawley  Did the above help at all?. @TheFlow0360 Perfect!  Once you have something in place for this (or equally @CliffCawley ), we would love to have your example for the wiki!  . @TheFlow0360 Many thanks for spending the time on this for the benefit of the community!  \nRe the additional retry around obtaining chunks: Do we know/have you been able to test, that when we as the caller cancel a chunk we are reading, the httpStream instance we are reading from remains valid to retry? (IE the stream is not somehow cancelled as a whole; the pointer within the stream has not been advanced internally, so we can be confident the next read will read the same chunk again, and we won't have any missed chunks?)  \nBackground: TimeoutPolicy works by signalling a cancellation token after the timeout.  So, it'd be important to have confidence that signalling cancellation of reading an individual chunk, still leaves the stream as a whole in a valid state to continue reading from the original location tried (but cancelled by the caller) previously.. @TheFlow0360 No worries.  I'm going to prioritise other Polly areas over exploring effects of HttpStream.ReadAsync(...) cancellation right now, but very happy if  community members can add experience on chunked downloads / take this further! (See above: Does cancelling HttpStream.ReadAsync(...) leave stream in a valid state for retrying from the position before the read that was cancelled?)\n( @TheFlow0360  I may extract a version without the retry to the wiki; it illustrates at least timeout-per-chunk downloading.  Thanks again for the contribution! )\n@CliffCawley / future readers:  A fuller implementation of chunked reading with timeouts should also probably make use of 206 Partial Content / Range Headers for servers which support it: see eg Rick Strahl's article.  Microsoft's .NET  API browser  suggests this is supported in .NET Standard, from 1.1.  Again, if anyone has cause to use this and can work it up into a full example, we'd love to see it!. Closing due to lack of further activity.  Anyone feel free to re-open to continue the discussion, tho.. @ericbrunner @ZoranBebic  Yes, Polly v5+ does not contain a PCL target any more, and as such may not install in a Xamarin Forms PCL project.  At Polly v5.0.2, following the Microsoft recommendation, Polly moved to targeting multiple platforms via .Net Standard rather than PCL.  \nTo reference Polly v5+ from Xamarin, you may need to update your Xamarin forms projects to target .NET Standard (also notes for Visual Studio 2017).  This is not a process I have been through, so further feedback here welcome.\n@julien-mialon helped resolve some Xamarin PCL issues in #228 and may also be able to help?\nPolly v4.3.0 can be referenced from PCL-based projects.  Differences between Polly v4.3.0 and latest are documented extensively in the changelog and milestone-tagging of issues and PRs.  \n. @Julien-Mialon Perfect! Thanks for the update.  @ericbrunner @ZoranBebic Does this help?. Closing due to no further activity (re-open if further assistance needed)\n@Julien-Mialon Je vous remercie encore!\n@ZoranBebic For updates on the cache policy, follow #136 . @mikegottlieb Hmm, I'm not a Xamarin dev.  Does @Julien-Mialon 's sample from here help?  (maybe you have been through these suggestions already, but in case ...).  \nOther possible issue with clues here, here, here and here.  \nAlso, does Oren Novotny's sample app here help? Or his related updated discussion?\nCommunity / @Julien-Mialon ? - any ideas?. No problem.  If there is something we can do to improve the configuration of Polly's .NETStandard csproj, also v open to do that.  We will (soon-ish) move Polly on to VS2017, take advantage of the new tooling and poss. opportunity to straighten out as many of the old-tooling kinks as possible ... feels like .NETStandard tooling is (eventually) settling.. Closing as very similar to #237, under which there is more extensive discussion.  If there are questions specific to this not covered by #237, please feel free to re-open.. Hi @railarmenien , thanks for this.  It would be good to understand your thinking / need more clearly.  What factors are you thinking could be useful to govern the transition back from HalfOpen to Closed state?  And: what is the real-world scenario driving this?  (all helps us think around how tackle).  Thanks!. @railarmenien  I understand the logic that if fewer nodes are available behind a load-balancer, the response times of calls could increase (assuming the system is in some sense close to capacity?), but (with apologies) I am not sure I have understood how you are seeking the circuit to behave differently in light of the greater potential for timeouts.  \nAre you thinking that the circuit should be more 'lenient' (to make allowances for timeouts being higher, and not break again so easily), or more 'strict' (eg to return to closed less readily, and/or break more easily)?. Perfect @railarmenien ! : glad we are talking about the same thing!  Had just wanted to clarify following the timeout comments, because a consecutive success metric at HalfOpen can only make the circuit stricter (more likely to break again) than current implementation.  With you on the concept (mais merci aussi pour l'article: pas de probleme a lire en francais!)\n@railarmenien We would be very happy for a PR on this if you want to work on one!\nHere are some points I thought about when first considering this in January, and again now:\nConsecutive count circuit-breaker seems relatively straightforward:\n\nConsecutive success count (as you say) is the appropriate (and widely-seen) metric to refine HalfOpen to Closed, for a count-based breaker.  \nHalfOpen state must limit the calls placed as well as measuring incoming results.  Otherwise the HalfOpen state is vulnerable to request stampedes: see #216 (an inherited bug which we squashed very quickly!).  If the consecutive success count metric required to close again is N, we should also limit calls placed to N.\nThat limit on calls placed in the HalfOpen state should be N calls per breakDuration.  As @kharos rightly pointed out, a HalfOpen state may want to try to place more calls periodically, in case the earlier calls have hung.  \n\nSo the specification (as we might document it in the wiki) would become:\n\nWhen the circuit is half-open and the consecutiveSuccessRecoveryThreshold is specified (call it N):\n+ the circuit will permit N further calls to be placed per breakDuration, as trial calls to determine the circuit's health\n+ if the circuit receives N consecutive successes, the circuit will transition back to Closed.\n+ if any failures occur before N successes is reached, the circuit will transition immediately back to Open again for the configured timespan.\n\nAdvancedCircuitBreaker case seems more nuanced:\n\nFor the new metric controlling HalfOpen to Closed, my thought is that users would specify only one additional parameter double recoveryThreshold (not additional values for all three parameters which govern Closed state) (keep things as simple as we can!)\ndouble recoveryThreshold would again be a percentage of calls which fail.  eg If a user specified failureThreshold: 0.4, recoveryThreshold: 0.2, they would be specifying that they want the failure rate through the circuit to fall from 40% (when circuit breaks) to 20%, before the circuit would transition from HalfOpen to Closed again.\nThe HalfOpen state still exists to place only limited calls: to remain protective of the called system while placing enough calls to determine if the underlying operation has recovered.  It should limit calls to the minimum necessary to determine whether the failure rate falls below recoveryThreshold: in this case, N calls, where N is the minimumThroughput which the user defined to make circuit metrics statistically significant.  That  minimumThroughput becomes the maximum calls which the breaker will place while in HalfOpen state, in any period of breakDuration.\nFor same reasons as for consecutive-count breaker, that upper limit on calls placed in the HalfOpen state should be per some period, say N calls per breakDuration. \n(EDIT) The influence of the samplingDuration parameter could be retained or could become irrelevant to the HalfOpen state.  \n\nWhat do you think? Does this work for your Use Case? Could we do anything differently?  Community views?\n. (triage of open issues)\nThis (refining the metrics governing exiting half-open) remains a good possible addition to the circuit-breaker!\nBecause of the core Polly team's desire to deliver events/metrics as the next major feature, the core team hasn't time to work on this (#239) at the moment.  Community contributions remain welcome. @reisenberger provided a possible specification/starting point for discussion above.  Post on this issue if you're interested in taking this on. . Removing the 'up-for-grabs' label from this. I would prefer to next develop the circuit-breaker by more cleanly factoring out an ICircuitStateController and ICircuitStateStore, to facilitate high-priority features like #287 (Distribitued breaker for serverless/actors scenario).  The feature in this issue (refining exit from half-open state) would then become an option (also easier to implement) of a custom ICircuitStateController (rather than adding more features to the existing pre-defined circuit-breakers).. ( @joelhulen Although there are a large number of commits, suggest merge-without-squashing.  Commits contain code rearrangement [moving/renaming files]; GitHub doco suggests Git can (hopefully!) track history when these are separate commits - not if squashed ). hey @CESARDELATORRE .  Great idea!  (seen this in a Java resilience library)\nIt could already be achieved with Polly, by using one of the .WaitAndRetry(...) configuration overloads which allow you to specify a Func<..., TimeSpan> for the amount of wait.  (Similar overloads exist for async.)\nSomething like:\nRandom jitterer = new Random(); \nPolicy\n  .Handle<HttpResponseException>() // etc\n  .WaitAndRetry(5,  \n      retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt))  // exponential back-off\n                    + TimeSpan.FromMilliseconds(jitterer.Next(0, 100)) // plus some jitter\n  );\nDoes this cover it?\nSuch a great idea, I'll aim to add a wiki 'how to' page and/or blog it.\nEDIT: Thx for the references!  Reading the articles in detail, they explore a more sophisticated range of jitter algorithms than the small amount of jitter in my example above.  However, the principle of how to do this with Polly is the same: using the Func<..., Timespan> overloads, you have complete control to adopt whatever randomness/jitter algorithm you like.\n. Alternative: I note that the 'Decorrelated Jitter' suggested in this article appears to use an Accumulator approach (next value depends on the preceding one).\nTo implement this with Polly, another alternative could be a WaitAndRetry() overload taking an IEnumerable sleepDurations, and use the standard LINQ Aggregate for the Accumulator?\nCORRECTION: It needs a yield return type approach (see below).. @KennethWKZ I have revised the previous sketch to use a yield return type approach, per below.  Please let us know if you need anything else on this.\n```csharp\npublic static IEnumerable DecorrelatedJitter(int maxRetries, TimeSpan seedDelay, TimeSpan maxDelay)\n{\n    Random jitterer = new Random();\n    int attempt = 0;\ndouble seed = seedDelay.TotalMilliseconds;\ndouble max = maxDelay.TotalMilliseconds;\ndouble current = seed;\n\nwhile (attempt++ <= maxRetries) // EDIT: As pointed out in a later comment, this boundary check allows one more retry than prescribed.\n{\n    current = Math.Min(max, Math.Max(seed, current * 3 * jitterer.NextDouble())); // adopting the 'Decorrelated Jitter' formula from https://www.awsarchitectureblog.com/2015/03/backoff.html.  Can be between seed and previous * 3.  Mustn't exceed max.\n    yield return TimeSpan.FromMilliseconds(current);\n}\n\n}\n```\nUsed as (for example) :\ncsharp\n    Policy retryWithDecorrelatedJitter = Policy\n        .Handle<WhateverException>()\n        .WaitAndRetry(DecorrelatedJitter(maxRetries, seedDelay, maxDelay));. @KennethWKZ  Yes.  As with a pure exponential-backoff strategy, the idea is that seed is a low-ish, starting value.  \n\nThe algorithm will produce sleep values all of which fall between seed and max: seed should represent the minimum wait-before-retry that you want, max the max.  \nmax >= 4 * seed works well (and bigger ratios are fine).  If seed and max are any closer, values will tend to bunch at the min and max.  \n\nTo see the kind of retry delays it generates, you can run up a small console app like this.. Closing.  Detailed wiki page now created describing how to use Polly with jitter.. @23W  I agree.  I have annotated the above and corrected it in both the wiki page and github gist example.  Thank you for catching this.. Thanks @SimonCropp !  . @mcquiggd.  Yes, that was pseudo-code-ish (have re-labelled).  Thanks for identifying the issues!  Let's see if we can sort it out.  I'd also been meaning to ask @jmansar (who originally requested the feature, #177) or @tcsatheesh (who was also interested in using it with DocumentDb) if they wanted to expand on my blogged (pseudo-) code: both, feel free to chip in!  \nMore coming shortly.. @mcquiggd Having spent a couple of hours on this, I am not convinced we have adequate support within Polly yet for the DocumentDB RetryAfter Use Case.\nI can see various ways forward to support this better in Polly, but need more time to consider.\nA possible workround for now with Polly might be (using microsoft.azure.documentdb.core) as below:\nvar honoursRetryAfterFromDocumentDb = Policy\n    .Handle<DocumentClientException>(de => de.RetryAfter > TimeSpan.Zero)\n    .Or<AggregateException>(ae => ((ae.InnerException as DocumentClientException)?.RetryAfter ?? TimeSpan.Zero) > TimeSpan.Zero)\n    .WaitAndRetryAsync(retryCount: 3,\n        sleepDurationProvider: (retryAttempt, context) => TimeSpan.Zero,\n        onRetryAsync: (exception, timespan, retryAttempt, context) => \n            Task.Delay((exception as DocumentClientException)?.RetryAfter ?? (exception.InnerException as DocumentClientException)?.RetryAfter ?? TimeSpan.FromSeconds(0.5))\n       );\nClearly this is sub-optimal: we are bypassing Polly's in-built sleep, and sleeping in the onRetryAsync.  We lose the benefit of Polly's in-built cancellation support.  \nI haven't had time to test the above tonight and would be interested in feedback on whether it works/gets you closer - that would help guide how we wrap this up into a more off-the-shelf/ready-to-go solution! \nThanks!\n. Note: the Microsoft Patterns/Practices team recommend the in-built retry for DocumentDb: Is this relevant? . Also more in this documentation\nWould be great to hear if this covers it, or if there's a reason it's still worth us pursuing this use case in Polly - will help guide where to place effort.  Many thanks!  \nEDIT: I guess this paragraph:\n\nIf you have more than one client cumulatively operating consistently above the request rate, the default \nretry count currently set to 9 internally by the client may not suffice; in this case, the client throws a \nDocumentClientException with status code 429 to the application. The default retry count can be changed \nby setting the RetryOptions on the ConnectionPolicy instance. By default, the DocumentClientException \nwith status code 429 is returned after a cumulative wait time of 30 seconds if the request continues to \noperate above the request rate. This occurs even when the current retry count is less than the max retry \ncount, be it the default of 9 or a user-defined value.\n\nin the linked documentation suggests a reason why still handling this in Polly could be useful ....  . @mcquiggd Thank you also for pointing out the slips in the readme doco.  Now fixed in #248 .. Thanks for the thoughtful commentary @mcquiggd ^^ (two up). Agree on all counts!\nRe your point 3 - wrapping a bunch of policies around a call as a small abstraction - check out Polly's PolicyWrap (if not already seen it), designed for exactly this purpose.  We also provide guidelines on ordering the policies within a wrap, although PolicyWrap is intentionally fully flexible, so any ordering can be used.\n+1 to your idea of:\n\narchitect a common set of Policies and patterns for handling errors - \nbe they Blob Storage, Azure Search, DocumentDB, DynamoDB, ElasticSearch.\n\nWe would love to hear more about this later, if grows and you would like to share.  We would love to eg blog/guest-blog about it, or share samples perhaps (duly credited) via a Polly.Contrib.  (Contact me on Polly slack later if u want to discuss.)\nOne issue with the in-built retries for the various Azure services is that they are all different APIs - good in the sense each is probably a good fit/strategy for the particular service - but a slightly fragmented API experience.  Another issue with combining Polly policies with Azure's in-built retries, is that with Polly-wraps-Azure-retry you can effectively only have the retry innermost (out of the set of policies).  However, you might want to have certain policy types inside a retry, in some PolicyWraps.\nRe Topaz and the Enterprise Application Blocks, yes, feels like it is well on the way out. The Microsoft patterns and practices team are now moving away from recommending Topaz, in favour of Polly (I've provided input on the Polly samples).  . @mcquiggd Great to see this all coming together!  \n:+1:  using the Context to pass things (operation name; Id) into the call - exactly what intended for.\nA1. All Polly policies are fully thread-safe, so you're absolutely fine re-using an instance across multiple calls (if relevant to any decisions around this).\nA2. Whether you want to continueOnCapturedContext or not, be driven simply by whether better for your Use Case / usage with DocumentDB (usual considerations around how it influences async context marshalling).  Polly doesn't care either way.  continueOnCapturedContext == true usually only necessary if you specially need execution after the ExecuteAsync(...) to continue on the same context as before (some actor frameworks; or need preserve UI execution context).\nA3/A4.  Your analysis is exactly correct.  Sleep duration is calculated before onRetry/Async is invoked - even though only used after - because it's an input parameter to onRetry/Async.  I've updated the Retry wiki to make this more accurate.\nForesaw your A3 problem as soon as you posted this, btw, but ... busy day this end ... you beat me to the follow-up :grinning: and figured it out, so great :+1: .  This exact issue is why my example the day before was more circuitous!\n( A5. comments in mo ). @mcquiggd \nA5. So, we could do this (add sleepDurationProvider overloads taking exception, handled result), but I'm favouring adding the Exception / handled result to Context instead to avoid proliferating further overloads (and opens up potential for other Use Cases profiting from the same info).\nSo, you'd have access to eg, context.LastHandledException and context.LastHandledResult - would this do the trick?\n( Great to have this conversation and see the DocumentDb use case in detail: thanks for sharing! ). @mcquiggd \nB1/B2 Handled results: When a policy is a strongly-typed generic Policy<TResult>, executions through the policy can only return results of type TResult.  Given that, we should be able to pass context.LastHandledResult as TResult.  \nIt would mean creating a new generic-typed Context<TResult> : Context.  We would need to check for breaking changes, but given Context<TResult> : Context, my initial (shallow) assessment is that breaking changes would be avoided.\n(thoughts on other categories coming separately). @mcquiggd \nB1/B2 Handling multiple exception types: Yes, a single policy can handle multiple unrelated exception types (say, TException and VException).  And this power has some relatively common and useful Use Cases; eg using HttpClient w/ async, it's common to want to handle both HttpRequestException and TaskCanceledException (for timeouts).\nThat power does make providing a strongly-typed TException to eg onRetry not a straight fit.\nThinking around ... The only option (which would be a major API change) would be moving the onRetry-style delegates of Polly into the .Handle<>(...) clause.  But it carries other disadvantages.  It weakens the meaning of the delegates (would dissociate them from their current, nicely-stated onBreak, onRetry, onFallback role).  And it would introduce code duplication for the relatively common Use Case, that you simply want to log something around the exception - that it eg caused the retry or circuit breakage.  Not altogether satisfactory in different ways...\nAt this stage, I'm left thinking that the need (sometimes) to disambiguate which exception you have received is a necessary corollary of the power to handle multiple exception types, encapsulated nicely in a single Policy.  Open to thoughts, though, from anyone, if we're missing some clever alternative?\n(This discussion excludes AggregateException - comment following)\nEDIT: Another option that does exist, with existing Polly, is to specify separate policies for each exception type. You can use the same policy type more than once in a wrap.  Where the onRetry handling was known to want to differ for different exception types, this provides a mechanism. For example, this pattern is commonly used to set up one retry policy for re-authentication, and another for transient faults.. Re the case ex is TException || ex is AggregateException && ex.Flatten().InnerExceptions.Single/Any(e => e is TException): \nIt would probably be possible to introduce handle clauses like:\n.HandleIfSingleInAggregate<TException>(Func <Exception, bool> predicate) [*]\nand/or \n.HandleIfAnyInAggregate<TException>(Func <Exception, bool> predicate) [*]\nThese could extract a matching (single; or any) exception from within AggregateExceptions, and pass that directly (ie unwrapped) to any policy delegate that expects an Exception input parameter.  Reducing user code navigating this, if it's possible that an underlying delegate might throw either.\nDo Polly users think this would be useful?\nThe alternative - changing existing .Handle<>() clauses to do this - would obviously be a breaking change.  We've also always adopted the premise that Polly doesn't transform the way exceptions from your existing code are expressed (eg if rethrown) - to make introducing Polly to a project easier - there's no extra/hidden 'magic' you have to know/learn/keep in mind, to adjust for Polly being in the mix.  So, if we're going to do this, my leaning would be towards an approach that explicitly states the behaviour, like .HandleIfSingleInAggregate<TEx>().\n[*] Long, intention-revealing names intentionally used - other suggestions welcome!. As an aside @mcquiggd , do we know that ~Document~CosmosDb might throw DocumentClientException either directly, or wrapped in an AggregateException? [EDIT: as potentially either, from the same call?; see later note] (ie have we observed this in practice, or found it documented on DocumentDB?).  \nI saw this dual approach in a code example when researching, but it could have started a spurious hare .... Hi @mcquiggd . Long familiar with async, TPL and their exception behaviour - I should have been (apologies) more precise in my previous question.  Q in my mind was whether any one execution through DocumentDb might fail with either a  DocumentClientException or AggregateException (as opposed to DocumentDb expressing that variety if called in different ways).  If not, some of the preceding code handling either AggregateException or DocumentClientException in the same policy could be moot (so complexity could perhaps be reduced).\nAgree tho somewhat theoretical until see how your code patterns pan out - cranking out some real code :+1: \nAnd independently: the .HandleIfSingle/AnyInAggregate<TException>() technique of earlier comment could remain useful in Polly, regardless of whether any one execution/policy needs to trap the exception at both levels  (.Handle<TException>().OrIfSingleInAggregate<TExecption>()).  It could provide useful syntactic sugar/lifting power for AggregateExceptions in general.\nRe:\n\nIf we cannot find an elegant way to enhance the existing Polly approach to\nAggregateExceptions without breaking backwards compatibility\n\n.HandleIfSingle/AnyInAggregate<TException>(Func <Exception, bool> predicate) would be the way to extend Polly in this direction without breaking backwards compatibility.  I'll likely pull that out to a separate issue/roadmap point (for community comment) in due course.\n. @mcquiggd More detailed proposal for handling InnerExceptions of AggregateException, now under #256 : comment welcome!. @mcquiggd  Polly v5.6.0 (uploading to nuget in next day or so) will include the ability for WaitAndRetry policies to define a sleepDurationProvider which can take the handled fault (exception; or returned result) as an input parameter to the sleepDurationProvider delegate.  \nThis should make it even easier to use WaitAndRetry policies to wait for a 'retry after' duration specified by the called system; eg as CosmosDB does with HTTP response code 429 and response headers. @ranouf We added overloads where the sleepDurationProvider takes the preceding exception as an input parameter, so this can now be done more simply.  You can use that overload and take the code you have in onRetryAsync into sleepDurationProvider, and avoid having to pass anything by Context. @georgiosd All the variants of retry policies have overloads allowing you to specify an onRetry / onRetryAsync delegate.  The delegate is invoked when the policy handles an exception or TResult.  The handled exception or TResult is passed to it as an input parameter.  So, you should be able to hook something into that delegate to receive a TResult that has been deemed 'needs a retry', and dispose it.\nLet us know if this solves what you need!. @ploeh Am currently on the road travelling, but will come back to this and the interesting qs raised in your blog post in a few days' time.    . Thank you @ploeh for your enthusiasm for Polly with F#!  I have taken four main points from your blog post: You added around Polly:\n(a) extra exception-matching predicates to match InnerExceptions of AggregateException, in order for the Polly circuit-breaker to handle these \n(b) the curried helper-function to execute an async workflow through the Polly policy, translating between Tasks and F# async workflows\n(c) a function as (a) but extracting BrokenCircuitException from AggregateException\n(d) a function to translate the thrown BrokenCircuitException into a value response\n\nTaking these in a different order:\n(d) Polly has an in-built method .ExecuteandCapture(...) which performs the same conceptual function: returns the result of execution always as a PolicyResult value rather than ever throwing an exception.  Could this substitute for some of the work you did in (d)?  \n(a) and (c) We now have several requests for better-handling of InnerExceptions of AggregateException.  See this new proposal for how Polly could support this.  Comments welcome!  \nWhen that proposal is implemented, the in-built .ExecuteandCapture(...) method (d) would unwrap inner exceptions of AggregateException (PolicyResult.FinalException would return the handled inner exception directly), so this could be an advantage of using the in-built .ExecuteAndCapture().\n\n(b) / general F# support for Polly:\nVery happy for contributions!  I love the functional style (PolicyWrap is inspired by it), but haven't had time to get into F# yet, so I wouldn't be able to undertake or support this at this time.  \n(Assuming (d) (a) and (c) as dealt with per above) ...\nWould you see better F# support for circuit-breaker as involving:   \n(b-i) providing just your curried helper-function (b) out-of-box as part of the Polly package (or an extension package, eg Polly.FSharpAsync);  ?\n OR\n(b-ii) writing fresh F# implementations of the CircuitBreakerEngine, CircuitController etc.  ?\n(or something else?)\nIf (b-i) is sufficient (or even just a good first step / adds enough value on its own), doing that sounds relatively straightforward and certainly useful. Particularly given it seems to provide an F# bridge for all Polly async executions, across all Policy types? (big win).\nIf (b-ii), happy to discuss further!\nDepending on your thoughts to (b-i)/(b-ii) above, we can then think about how best to manage/package/support this.  \nAll input welcome from wider interested parties  - I see that several people have :+1: this issue \nThanks!. Thanks @ploeh. That was the answer I thought we would probably come to, based on your earlier comments, and my own reading around F# async workflows.  However, likewise, I wanted to have your deeper F# experience speak to that rather than make an assumption :smile:  \nFor anyone interested in a port of Polly to F# in future - the implementations of each Polly policy type are defined quite clearly as higher-order functions - as \"Funcs on a Func\" - very much a functional mindset to Polly in that sense.  \nTheory: The original definition of a sync Policy was (beautiful to my mind) an Action<Action>, and async a Func<Func<Task>, Task> (now only slightly more complex, as we support context, cancellation, and control over marshalling async context: sync; async).\nPractice: Those implementations can be clearly found in the classes named XXXEngine, eg RetryEngine and RetryEngineAsync.  \nThe rest of Polly is simpler concerns such as syntax/builder classes, supporting classes (eg the Context which flows with each execution) - and over 1200 tests.\nThe exception to above statement that the entire definition of a Policy can be found in an XXXEngine class is circuit-breaker, which is driven by a group of collaborating classes: CircuitBreakerEngine, implementations of ICircuitController, and classes tracking metrics.  That would be a slightly bigger port.  \nHappy to provide further input/support to anybody wanting to port Polly, or just certain concepts, to F#.. Triage of old issues: The core Polly team are not able to contribute this at present.  Happy to provide guidance to anyone who may be looking to take this on as a project.  As @ploeh says, to take full advantage of F# async workflows would essentially be a full rewrite of async Polly (\"In order to make any difference, it'd need to use F# async workflows all the way.\").  . Huge thanks again @ploeh for this useful exploration of Polly with F# (we've linked your blog post into the Polly readme) and for providing F# users with a means to bridge Polly nicely into F#, handling the AggregateException unwrapping and currying the Task/async-workflow transition. \nI am going to close this out as outside of the scope the existing Polly team can deliver (on unfunded time).  However, we continue to be happy to support and provide input/guidance to anyone wanting to take this on.\nStepping right back and looking at the bigger picture: there is some impact in using the current Polly asynchronously in F#, due to the swapping back-and-forth between Tasks and F#'s native async workflows.  However, in the context of the network access time (HTTP request and response) that most Polly policies are probably used for, hopefully the async to/fro may not have too much impact on overall execution times. I also see that there are ongoing discussions with the F# design team about native F# support for Task.\n\n(On the smaller point of AggregateException, from Polly v5.6.0 we have added native handling of InnerExceptions to Polly; so you may be able to pick up on Polly's native handling there now.). @pvmraghunandan I am currently on travel and will respond to this in two or three days' time.. Thanks @pvmraghunandan for this!\nThe possibility of a request stampede during half-open state was identified recently and we believe fixed in v5.0.5.  If you think this is still an issue (after upgrading to >=v5.0.5 if necessary), please let us know.  This is the code that enforces only one new trial call per break duration.  Multiple requests that are already in flight when the circuit transitions to open state can of course not be prevented from still returning during the half-open state (discussion of Polly's perspective on this: #217, #218).\nWe've had discussion lately of a more-refined metric for transitioning out of half-open state under #239 : latest thinking here.  For a consecutive-count-based breaker (the case discussed in the patterns/practices article), it seems fairly straightforward.  The AdvancedCircuitBreaker case (the Hystrix circuit-breaker model) is less transparent, though solvable.  Further comments welcome under #239!\n\nEDIT: Community PRs on this welcome! (I can provide guidance).  Other Polly development streams mean I would be unlikely to look at this one further for some months.  . Closing as duplicate of / covered by #239 . This feature is delivered in Polly v5.6.0 (will be released via nuget in next day or so).. @Kesmy Yes, we want to upgrade them all.  Detailed comments coming on #277. . Closed by #277. Hi @nareshkhatri81 .  Thank you for your interest in Polly!  CircuitState is stored in memory.  \nSee #215 for discussion of external storage for Circuit Breaker State - let us know what you think!\nOne issue that has concerned me, with just saving the circuit state in eg Redis, is that it could lead to the \"single bad node poisons other good nodes\" problem discussed here, if the problem is in fact with the upstream node rather than the downstream system.  \nIf that does occur - if the problem is in fact only with that single upstream node, but the shared storage 'applies' the problem also to the sibling upstream nodes - this effectively writes off the value of having the other horizontally-scaled nodes.  Thus, discussion for implementing a distributed circuit breaker in Polly has tended towards (/I haven't wanted to implement it without) a quorum-driven approach: break locally if any >=N upstream nodes in the distributed circuit have broken.  \nDo you think the quorum aspect is important, or am I over-egging this?\n. Proposal for DistributedCircuitBreaker now posted as #287 . Closing as duplicate, main discussion now on #287. Hi @georgiosd , thanks for joining the Polly conversation!  \nI've looked at Jack Leitch's article in the past, as we've had discussion around a rate-limiting Policy in our slack channel.  You mentioned \"it leaks here and there\": if you have any specifics on that (what you thought was causing the leak; or just the circumstances), it would be good to hear more, so that we can consider that in any Polly implementation.\nOne evident issue: any rate-limiter whose approach is to hold back 'hot' tasks - tasks which are already executing, in memory - is intrinsically vulnerable to memory bulges if fresh requests consistently outstrip the permitted rate, simply because those pending requests are all in memory.   At least, in the absence of any co-operative demand control (back-pressure) or load-shedding.  I've noted this in more detail in the Polly Roadmap.  Is this the kind of thing you were thinking of with the 'leaks', or did you detect leaks even in relatively steady state? (ie without large numbers of pending requests backing up).\nThanks!. Hi @georgiosd .  Re:\n\nI also don't think your second point applies to my particular use case\nBasically there are 1-5 tasks/event loops that are running concurrently\n\nWith you there :+1: (suspected that might be the setup from your initial description, but good to have it confirmed in more detail).\nRe:\n\ntried to figure out what could be causing it\n\nThe only observation I can make is that, if those up-to-five separate event loops are hitting the same API and need (combined) to not exceed the rate limit, then they'd need (from my code reading) to share the same RateGate instance.  (The same would also apply for the way I envisage we could implement this as a Polly RateLimit policy.)  \nTesting the multi-threaded case robustly is certainly something we should do if we implement a Polly RateLimit policy.. :+1: @georgiosd  Thanks for the clarification and feedback!. Hi @georgiosd .  This is on the roadmap but there isn't any allocated resource or timescale.  For the core maintainers, some other large-ish items are ahead at mo (CachePolicy; unify sync/async policies; perf enhancements).\nWe'd love to see it implemented, however, if you (or anyone else) is interested in working on a PR.  Shout if so, and we can provide guidance on how to structure an implementation as a Polly policy!. Understood @georgiosd .  When I/somebody can squeeze an implementation out, it would awesome to have you put it through its paces! (or any other contributions!). As prev. noted, other development priorities are (unfortunately) ahead of this feature at mo.. Hi @georgiosd . The best way to see the architecture of how a new Policy is implemented is look at the shape of the files making up the NoOpPolicy (and its tests).  NoOpPolicy is just an (intentionally) empty policy which does nothing, so that shows you the bare bones structure you would start with ... for adding a new policy.\nhttps://github.com/App-vNext/Polly/tree/master/src/Polly.Shared/NoOp\nhttps://github.com/App-vNext/Polly/pull/214/files\n. Cross-ref #330 . x-ref #528 . Hi @darxis !\n\nTimeoutPolicy provides the ability to time out any execution.\nPolicyWrap provides the ability to compose multiple policies into a single policy for later use. \n\nFor your Use Case, wrap a timeout policy around any retry policy you like.  For example, the following should retry with 10 second delays between tries, up to a 5-minute limit:\n```\nPolicy timeoutAfterFiveMinutes = Policy.Timeout(TimeSpan.FromMinutes(5));\nPolicy retryEveryTenSeconds = Policy.WaitAndRetryForever(iteration => TimeSpan.FromSeconds(10));\nPolicy tryEvery10SecondsUpTo5Minutes = timeoutAfterFiveMinutes.Wrap(retryEveryTenSeconds);\n// You could create the above all in one statement.  I used long-named interim variables just to make the components clearer.\n// Usage\ntryEvery10SecondsUpTo5Minutes.Execute(...);\n```\n(EDIT: For a concise syntax, you can of course create that compound policy with an extension method.)\nComments to this stackoverflow question include various working dotnetfiddle examples and discussion of further nuances.  They are async examples, and for much shorter timescales (because dotnetfiddle limits overall execution time), but the principles are the same.\nLet us know if this gives you what you need!.  Hi @sledoux , thanks for joining the Polly conversation!\nTaking first this question:\n\nis it possible to pass a context between the policy? \n\nYes.  Polly's Context  object is intended for this: \n\nEvery .Execute(...) (and similar) overload exists in a variant where the executed delegate can take Context as an input parameter.  \nLikewise, every policy-control delegate (like onRetry, onBreak etc), should also exist in a variant where that control delegate can take Context as an input parameter.   \n\nTherefore, you should be able to pass contextual information among any parts of a Polly policy, and downstream to further Polly policies part of the same execution (whether you're combining policies in some custom fashion, or automatically with PolicyWrap).\nThis blog post Putting the Context into Polly gives some examples.\nLet us know if that's making sense, or if we can help any further on this.. Hi again @sledoux !  Re: \n\nOur use case would be to have 1 circuitbreaker per fallback option, having many fallback option. The number of fallback would be dynamic. The goal being to stop retrying one of the fallback for a small period of time in case of failure. Therefore going to the next fallback automatically if the circuit of the first option is open and so on with the next fallback options\n\n@aliostad Raised essentially the same q in #199, and I provided some suggestions.  ( /cc @aliostad Any comments, on the final approach you took with this? )\n@sledoux Two further comments, looking back at my notes to @aliostad:\n\nProbably recommend the approach of wrapping with a while loop or retry policy, rather than a chain of FallbackPolicys.  FallbackPolicy is essentially linear, and feels like it'd be hard (or harder, while possible) to get the concept of a dynamically-extending failover, and a continuous-looping failover, using FallbackPolicy .  \nThe code example in that previous comment obviously has to create a closure over the variable sourceToUse.  This closure can now be avoided using precisely the Context techniques discussed in comment above / related blog post.\n\nAgain, let us know how you get on with this!. @aliostad @sledoux  After aliostad's original request, I wrote a proposal for a proper FailoverPolicy, aiming to generalise and encapsulate as much as possible, by targeting an IEnumerable<TProvider> . \nWould love feedback on that proposal - good? bad? questions? ideas?. >I don't see a method signature to pass a context to the FallBackAction of a FallBack policy. Since the FallbackAction cannot take a parametized Func or a context, it's useless to combine it with a CircuitBreakerPolicy [with context] through a PolicyWrap \nHi @sledoux You're absolutely right, it looks like this delegate was missed among the work for v5.1.  Thanks for highlighting.\nThis would be pretty quick to fix up (see #265), if you are interested in submitting a PR before I get to it.. @sledoux Perfect.  Just post on the issue if you pick it up.  I'll ditto if ditto (to avoid overlap). @sledoux FallbackPolicy with fallbackAction taking a Context input parameter, released as part of v5.3.0. Closing due to lack of further activity. Anyone feel free to re-open to continue the discussion, tho.. Fix pushed to v5.2.1 dev branch. Hi @grokky1 , thanks for joining the Polly conversation!  \nRe logging a final failure from a policy operation: We could / could have added an extra onLastFailure delegate to the retry policies, but opted to provide similar functionality through FallbackPolicy.  FallbackPolicy targets code you want to run if an overall operation still fails, and is typically used as the outermost layer of a PolicyWrap.  It serves the same purpose as   onLastFailure, but can be used after any policy type (or wider resilience strategy expressed as a PolicyWrap).\nThe main intent of FallbackPolicy is to provide a substitute value/code-to-run in the case of overall failure. It also provides an onFallback delegate, which can be used like the onRetry delegate for general concerns such as logging.  To make a combined policy you can pass around, use PolicyWrap to wrap your FallbackPolicy outside the retry:  \n```\nvar retryPolicy = ...\nvar fallbackPolicy = ...\nvar retryWithFallback = fallbackPolicy.WrapAsync(retryPolicy);\n// elsewhere:\nvar result = await retryWithFallback.ExecuteAsync(...)\n```\nIf you want to provide different fallback values/executions for different call sites, but re-use the same onFallback delegate for common logging, see the Theme and variations approach noted in this blog post.\nA minor wrinkle is that ExecuteAndCapture/Async() does not play well with PolicyWrap at present, for the (conceptual) reason described here.  For now, switch back to Execute/Async() rather than ExecuteAndCapture/Async() \nLet us know if that provides what you need, or if you have further ideas for how this could be improved.. Hi @grokky1 !   We'll aim to fix up the use of ExecuteAndCapture/Async() with PolicyWrap; I've raised #267, with a proposal.\nRe:\n\nI don't know whether the policy passed/failed [with ExecuteAndCapture/Async()], because there is nothing similar to PolicyResult.Outcome. \n\nExecuteAndCapture/Async() is just a try-catch, -> set result object.  With ExecuteAsync() rather than ExecuteAndCaptureAsync(), you just have any final exception thrown.\nSo: If policy in await policy.ExecuteAsync(() => DoSomething()); were just a retry policy, and all retries fail, the retry policy will propagate the final exception - so you'd know the retry policy failed by that exception being thrown (and need to try/catch for it).\nIf following the PolicyWrap pattern earlier in the thread, you'd typically use the FallbackPolicy to absorb that final exception from the inner retry policy (and take whatever compensating action you deem), so you'd know the retries failed from the FallbackPolicy kicking in.  Here's a fuller example commenting that, and demonstrating a common LogPolicyExceptionAsync(exc) delegate:\n```\nvar retryPolicy = Policy\n  .Handle()\n  .WaitAndRetryAsync(10, sleep, onRetryAsync: async (exc, span) => LogPolicyExceptionAsync(exc));\nvar fallbackPolicy = Policy\n  .Handle()\n  .FallbackAsync(fallbackAction: async cancellationToken => \n     {\n         // You will know all retries failed because your code hits here.\n         // Do whatever desired to substitute for/compensate-for-failure-of executions through the policy.\n     },\n     onFallbackAsync: async exc => LogPolicyExceptionAsync(exc));\nvar retryWithFallback = fallbackPolicy.WrapAsync(retryPolicy);\n// elsewhere:\nawait retryWithFallback.ExecuteAsync(() => DoSomethingAsync())\n```. Hi @grokky1 ! Newness to Polly is no measure of quality of input: thanks for all your comments!\nAgree about the long-windedness of FallbackPolicy for this Use Case.  May be one of those cases where one API design would have suited some contexts, another others.  The FallbackPolicy gives us a powerful concept for providing alternative values/actions for 'if all else fails' across all policy types / wraps, but agree, it feels heavyweight for this logging.\nAnother (unfortunate) consideration is that we're becoming constrained by the existing Polly syntax.  Distinct positives of the existing Polly syntax are that everything about a retry policy is configured explicitly in one shot at configuration (highly visible; no 'hidden magic' defaults); and a policy is immutable once configured.  But the very same design (that everything is configured in one builder overload; no setting-after-the-event) leads to a distinct negative: Polly retry is already groaning under the weight of over 100 overloads. ... Which discourages adding further overloads, at least if there are alternatives (each new feature multiplies up).  ... Which is not a comment on the merit of onLastFailure; rather, on the syntax.  TL:DR; your suggestion could be a good, easy add if we were doing after-configured fluent adjustment, as in .WithOnLastFailure(...).  \nI can see a path to overhauling the syntax (thanks to ideas from (shout-out) @brunolauze, @lakario , and @ankitbko ), but with the number of substantive features on the roadmap, syntax overhaul is sitting lower priority just at the moment.\nWill keep onLastFailure in mind; we should try to find a way to work it in.\nThanks for the great observations!. >Include a dictionary which has failure info for each policy, where the key is the policy type or the exception type (or something like that).\nExcellent idea @grokky1  :+1:  : in fact we're planning pretty much that in slightly different form.\nWhen metrics are added to Polly, each policy type will emit events broadly corresponding to where delegate hooks already exist (onRetry; onBreak etc).  Polly now carries a Context with each execution.  It is intended that Context could (for performance, optionally) capture this stream of events, in addition to any dashboarding that's consuming them.  For those who want to interrogate it programatically, this would surface chapter-and-verse on 'what the PolicyWrap did internally'.\n. Fix for this issue coded and pushed to v5.2.1 dev branch.  \nHoping to push a few other things into v5.2.1 before releasing this.. Hi @PilchardFriendly I think open/closed may be reversed in your question, which may be confusing things.  Open/closed semantics for circuit-breakers (open = blocking, closed = permitting) are opposite to those of a gateway (open = permitting, closed = blocking) .  I've just extended the circuit-breaker documentation to re-emphasize this, and illustrate why.\nIf you are looking to detect when the circuit 'recovers' from half-open state to normal, 'healthy' state, that is the half-open->closed transition, and the onReset delegate is invoked when that happens - so can be used to detect that case - as described here.\nLet us know if that helps; or if you need anything else.. @PilchardFriendly  Ok, thanks for the clarification. I see that this implementation intentionally inverts the circuit-breaker to re-purpose it as a quasi-RateLimitPolicy.\nRe:\n\nHow do I tell the difference between a transition from closed->open and from half-open->open?\n\nTwo options come to mind:\n[1] Polly circuit-breakers could be extended to offer overloads where the onBreak delegate takes the transitioning-from state as an input parameter.  This could potentially be useful for standard circuit-breakers too.  I don't plan to work on this immediately unless there is wider demand (we want to focus dev resource to pick off major items on the roadmap), but happy to provide guidance, if you (or anyone else) is interested in taking a whack at a PR?\n[2] Without changes to Polly, you could currently distinguish closed->open from half-open->open, by tracking the preceding transition:\n\na sequence onBreak -> onBreak implies the second represents half-open->open\n(or onBreak -> onHalfOpen -> onBreak ditto, if you are also tracking onHalfOpen)\na sequence onReset -> onBreak implies the second represents closed->open\n\nEDIT: The state transition delegates onBreak and onReset etc are called just after the state transitions.  So, inspecting the CircuitState property within the delegate tells you the transitioned-to state, not transitioned-from state.   Ruling that out as a potential option [3].\nHope that helps, but very happy also to answer further questions.\n. Closing.  Have extracted the 'up-for-grabs' item:\n\n[1] Polly circuit-breakers could be extended to offer overloads where the onBreak delegate takes the transitioning-from state as an input parameter.\n\nmore clearly as #325.. In progress by @hambudi as #273 . @markrendle  Thanks for the really detailed engagement!  No criticism taken - the biggest challenge with Polly is simply getting through all the ideas we have. Fair to say that the main focus since App-vNext took over has been new features ... there are gains that can be made in perf for sure (aware of things that it would be good to squash out/change from the inherited codebase), so thanks for the reminder - and offer of help!  \nQuick response today - more very soon.  Briefly, I think we should consider this both internally (where Polly may unwantedly use closures internally that we can eliminate); and externally (where executing a user delegate that wants input parameters currently requires those params to be passed in by closure ... eliminating that).  Had you been focusing more on one or the other, or both? On the public API in particular, I want to reflect on and surface a few options for how that could look.\n. (triage of open issues)  This is not forgotten. TL;DR related work is happening as part of/tied in with wider changes to Polly.\n\nWhere Polly internally uses closures, these are being removed (/the intent is to) as part of the work on metrics #326 \nWhere Polly currently requires closures to capture input parameters to user delegates, the package-parameters-and-delegate-in-a-struct approach looks a strong direction to take this. It would probably require syntax changes (as part of a 'Polly vNext') to make new overloads more feasible to integrate.\n\nFor ref for anyone interested in performance: we benchmarked Polly throughput at Polly v5.1 at around a million operations/second for all policy types. (IE, using a Policy adds ~1 microsecond to your call.)  We can continue to use those benchmarks and post stuff in the #performance channel on slack as things evolve.\n. @expand, The question is perhaps a little too broad, to be able to comment usefully.\nWhat is your goal, in introducing Polly to that method?  Are you seeking to introduce retries?  Or circuit-breakers?  Or just to replicate the existing behaviour using Polly?  Are there specific refactoring challenges you have hit?. @expand What refactor is appropriate would depend on your goal: introduce retries? circuit breaker? or just reproduce what is there already using Polly?\nIf your goal is to reproduce the existing functionality using Polly:\n(Aside: until enhancement #278 is delivered, it is not actually possible to deliver this refactor.\nWe need enhancement #278 to allow the fallback value to be based on the handled exception.)\nIt looks as if the intent of the existing method is to return the body of the response as a string. Or if HttpStatusCode.InternalServerError is returned, to return still the body of the response, if there is a body.  \nWe could start by factoring out some common code:\nc#\nprivate string GetStreamAsStringFromResponse(HttpWebResponse response)\n{\n    using (StreamReader sr = new StreamReader(response.GetResponseStream())) return sr.ReadToEnd();\n}\n(I've intentionally elided many of the guard conditions against null for brevity and to focus on the structure; you probably want to keep them.)\nThe exception conditions actually handled by the catch in the original code can be condensed into one line, as a handle condition for a Polly policy:\nPolicy.Handle<WebException>(wex => wex.Response?.StatusCode == HttpStatusCode.InternalServerError)\nThe original code substitutes one thing for another, on error, in two possible ways: one HttpWebResponse for another; and ultimately one string return value for another.  The Polly policy for providing a substitute response when something fails is FallbackPolicy.  \nFallbackPolicy is strongly-typed to the type of result you want to substitute, for compile-time type-binding with the type of delegates you execute through it.  So we need a separate FallbackPolicy for each of the HttpWebResponse and string responses.  But we can write the code to express the handled conditions only once:\n```c#\nvar handleConditions = Policy.Handle(wex => wex.Response?.StatusCode == HttpStatusCode.InternalServerError);\n// NOTE: This overload of FallbackPolicy will not be available until enhancement #278 is delivered.\nFallbackPolicy responseFallback = handleConditions \n    .Fallback((failure, context, cancellationToken) => failure.Exception.Response); // equivalent to mapping to wex.Response in your original catch (WebException wex)\n// NOTE: This overload of FallbackPolicy will not be available until enhancement #278 is delivered.\nFallbackPolicy bodyFallback = handleConditions\n    .Fallback((failure, context, cancellationToken) => { \n         using (HttpWebResponse response = (HttpWebResponse) failure.Exception.Response)\n         { \n             return GetStreamAsStringFromResponse(response));\n         } \n     });\n```\nThe overall execution then condenses to just a few lines:\n```c#\nprivate string Query(string address) {\n    HttpWebRequest webRequest = (HttpWebRequest) WebRequest.Create(new Uri(address));\n    using (HttpWebResponse response = responseFallback.Execute(() => webRequest.GetResponse()))\n    {\n        return bodyFallback.Execute(() => GetStreamAsStringFromResponse(response));\n    }\n```\nDoes this help?  Is this the kind of refactoring you were looking for?. @apobekiaris Cool.  Let us know if you have more ideas for Polly or anything we can help with.. @apobekiaris  Thanks to @ExtRemo75 's awesome contribution ( :+1: @ExtRemo75 !), the new syntax mentioned in my original reply will be available in Polly v5.4.0 (hopefully release in the next few days). @hambudi Thank you for all your work on this PR!  Would you be able to follow these instructions to switch the base branch of the PR, to this new branch? : https://github.com/App-vNext/Polly/tree/fixAggregateExceptionsInPessimisticsTimeout\nThen I can tackle the timeout issues on the tests (it's an issue with running timing-sensitive tests in AppVeyor), and add similar tests for the generic TResult variant of TimeoutPolicy, etc.\nThanks for your awesome contribution!. Hi @subatta !\nPolly can handle a condition on an exception: Policy.Handle<SqlException>(ex => ex.Number == 1205)\nPolly can handle a condition on a result returned by an execution: Policy  .HandleResult<HttpResponseMessage>(r => r.StatusCode == HttpStatusCode.NotFound)\nAre either of these what you were looking for?\nIf not, please do explain more about the scenario you are thinking of, and we will try to help further.. Thanks @subatta for that clarification and example.\nThe second option I highlighted (handle a condition on a result returned by an execution) should allow you to do what you have expressed.\nYou have expressed your condition as a positive you want to achieve, a success condition (you want to retry until status is ok).  In Polly, we express result conditions for policies to handle as the negatives - the faults you want to handle.  Just flip the polarity of your condition and it'll fit right into the handle syntax.\nc#\nPolicy\n   .HandleResult<HttpResponseMessage>(r => r.StatusCode != HttpStatusCode.Ok)\n   .WaitAndRetry(...)\nPut in words: you don't want the policy to 'handle' anything when the status is ok; you want it to handle (to retry) when they are not ok.  \nNote that you can mix handling exceptions and result codes, to cover both kinds of fault, as in the example shown at that link.\nOne note of caution sounds in my mind about .HandleResult<HttpResponseMessage>(r => r.StatusCode != HttpStatusCode.Ok); it feels like possibly a blunt instrument, if the context is a general web context.  There can be status codes returned in a general web context where a retry, with an identical call at least, won't yield any greater success (301; 307; 308; 400; 401; 403; 404 etc etc).  Of course, I don't know the nature of the system you are calling - if the return codes you expect from the called system are more circumscribed, this may not be relevant.  Or this may not be relevant if HttpStatusCode.Ok was only an example.\n. Note that we don't have a policy that handles a condition that isn't based on the return value from the delegate executed.  \nBut if you want the handle expression to be on a bool - if you're looking to express a kind of do until(true) { ... } loop with WaitAndRetry(...) built in - then you can do this, by expressing the work you want to do as a delegate which returns a bool success status. eg:\nc#\npublic bool DoMyWork(...) { \n   // ... my work\n   // return true (success) or false (failed)\n}\nThe policy to WaitAndRetry(...) until the condition is met:\nc#\nvar doUntilTrueWithWaitAndRetry = Policy\n    .HandleResult<bool>(false) // retry if DoMyWork() method returns false\n    .WaitAndRetry(/* configuration */);\nUsed as:\nc#\ndoUntilTrueWithWaitAndRetry.Execute(() => DoMyWork());\nWhether to make a further try will be determined both by the bool condition and by the number of retries you have configured in the .WaitAndRetry(...).  If you want purely the bool condition to determine retries, you'd use .WaitAndRetryForever(...) in the above.. Thanks @subatta for the kind words.  And: you're welcome!. @subatta First, Polly has async policies and overloads for asynchronous executions. You should be using these (if not already).\nSecond, we would not normally expect to see a complex evaluation (eg an awaited function evaluation) within .HandleResult(...).  The intended pattern is to put constants or simple synchronous expressions there, eg .HandleResult(false).  Complex functions are then executed through the relevant execute overload.  For example, with async:\n```\nvar doUntilTrueWithWaitAndRetry = Policy\n    .HandleResult(false) // retry if delegate executed asynchronously returns false\n    .WaitAndRetryAsync(/ configuration /) // Note ... Async() on end of method name.\nawait doUntilTrueWithWaitAndRetry.ExecuteAsync(() => DoMyWorkAsync()); // Polly's ExecuteAsync(...) overload will await DoMyWorkAsync() internally.\n// where elsewhere:\npublic async bool DoMyWorkAsync(...) { \n   // ... my work using await statements\n   // return true (success) or false (failed)\n}\n```\n\nIn general, yes, blocking on async code risks deadlocks.  So if you are coding the equivalent of:\nawait Policy\n    .HandleResult<bool>(myPredictAsync().Result)) // mixing blocking on async code ...\n    .WaitAndRetryAsync(/* configuration */) \n    .ExecuteAsync(() => DoMyWorkAsync()); // ... with true async code\nthen yes, that will likely block.  \nThis could also be expressed by saying Polly doesn't support async handle predicates.  If you have a particular use case, for which it only makes sense / makes particular sense for the .HandleResult<TResult>(...) predicate to be a more complex function executed asynchronously, could you please describe the scenario in more detail?\n. Hi @subatta , thanks for elaborating; that makes sense.\nSince Polly doesn't support asynchronous executions in the handle predicates, to do this with Polly, you would need to refactor to move the work HttpResponseMessage.Content.ReadAsAsync<MyType>() into the delegate executed through the .ExecuteAsync(...) call.  \nIf we can help any further with this, please do let us know!. @subatta Sure. Can you provide a bit more context? \n\nthe current policy you have; \nthe method (at least full signature) you are currently executing through that policy (is this effectively some Func<HttpResponseMessage>?)\nthe signature of ReadAsAsync<MyType>()\n\nThanks!. @subatta What is the full signature of .ExecuteAndReturnResponse(string)?, ie is it:\nHttpResponseMessage ExecuteAndReturnResponse(string url) // looks like this, from code you quoted?\n\nor:\nasync Task<HttpResponseMessage> ExecuteAndReturnResponse(string url)\n\n?\nIf ExecuteAndReturnResponse(string url) is blocking internally on any async calls, eg with something like HttpClient.GetAsync(...).Result, then changes around .ReadAsAsync<IEnumerable<MyType>>().Result may not be enough.  Mixing sync and async code, or blocking on async code, is frequently a recipe for deadlocks.  async code generally needs to be async all the way. \n(I have a solution to move .ReadAsAsync<IEnumerable<MyType>>() out of your .HandleResult(...) clause, but answer to the above q might affect the solution.). hi @subatta . \nIf you have control over the HttpResponseMessage ExecuteAndReturnResponse(string url) code, it would be really helpful to know at this point whether internally it is doing something like HttpClient.GetAsync(...).Result.  Otherwise, there is a risk that I spend time proposing solutions that will not help your scenario.  Any next recommendation depends very much on the answer to this question.\n. Hi @subatta  I'm now clear the codebase under discussion (a) has no async/await (so a Polly ExecuteAsync() solution from me would be inappropriate unless you wholesale refactor to async/await); (b) is synchronously blocking on async calls in two places; (c) is using the synchronous Polly policy .WaitAndRetry(...) with synchronous .Execute(...)\nKnowing (a) and (c) means the deadlock issue is unrelated to the use of Polly (there is nothing we could change in Polly that would unblock these deadlocks).  The aspects of Polly you are invoking in (c) are effectively no different to coding:\nbool success = false;\nfor (int i = 1: i <= 5 && !success; i++)\n{\n    var response = apiConnector.ExecuteAndReturnResponse(\"/api/endpoint\");\n    success = r != null && r.IsSuccessStatusCode && r.Content.ReadAsAsync<IEnumerable<MyType>>().Result.Any())\n    if (!success) Thread.Sleep(TimeSpan.FromSeconds(Math.Pow(2, i)));\n}\nBlocking on async calls is a common and widely documented source of deadlocks.  If you want/need to remain with using HttpClient synchronously, you probably want to consult existing information on doing so without deadlocking, eg: 1, 2, 3\nIf you choose to refactor the code to use async/await throughout (which brings benefits like not blocking threads while waiting for a response; and avoiding deadlocks), then the question that Polly does not have a handle predicate of the form .HandleResultAsync<TResult>(Func<Task<TResult, bool>>) may arise again.  If that becomes an issue, please do let me know, as I can happily advise several options to structure code to avoid it. \nHope that some of the links above provide useful information on the deadlocking issue!. Hi again @subatta !  \nTo follow up on our previous conversation, if you wanted to refactor the code presented to async/await, here is an example of how it could be tested with Polly:\n```\nprivate async Task ResultContainsAny(this HttpResponseMessage r)\n{\n    if (r == null || !r.IsSuccessStatusCode) return false;\n    var readResult = await r.Content.ReadAsAsync>();\n    return readResult.Any();\n}\nasync void MyTest() // assumption: your test framework and version supports async test methods\n{\n    // Arrange\n    var retryPolicy = Policy\n        .HandleResult(false)\n        .WaitAndRetryAsync(5, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));\n// Act\n// - whatever you do initially in the test for \"messages are put on a bus\"\n\n// Assert.\n\nAssert.IsTrue( // or whatever your assertion syntax\n        await retryPolicy.ExecuteAsync(() => httpClient.GetAsync(\"/api/endpoint\")\n            .ContinueWith(t => t.Result.ResultContainsAny()));\n   );\n}\n```\n(As discussed, this moves the await on ReadAsAsync() out of the handle clause; but it tries to keep the intent clear, with a ResultContainsAny<>() extension method.)\nObviously, a refactor to async/await may not suit all situations (it may not be 'minimally invasive'), but I hope that the example is useful!. ( async void a slip there on my part [due to habit of writing void-returning test methods] that should of course be avoided; but it should work just the same as an async Task test method ). @tucaz Thanks for picking up on that.  \nCannot implicitly convert type 'System.Threading.Tasks.Task<System.Threading.Tasks.Task<bool>>' to 'System.Threading.Tasks.Task<bool>'\n\ntells us we're dealing with a nested task (Task<Task<bool>>); the recommended approach is .Unwrap(). The scenario is exactly parallel to the second example on that linked Microsoft page. So:\nbool outcome = await retryPolicy.ExecuteAsync(() =>\n            client.GetAsync(\"https://google.com\").ContinueWith(t => t.Result.ResultContainsAny<MyType>()).Unwrap());\n\n\n\nThe only change I would need is to actually get the HttpResponseMessage from the successful Polly call\n\nTo return something else as well as the bool from the execution, you could refactor to make the return type (bool outcome, MyType myType) or (bool outcome, HttpResponseMessage message).\n. @nestor-reyes Many thanks for your contribution!\nIn a rare event, it happens that both @kesmy (#277) and yourself have picked up the same 'up-for-grabs' within hours of each other.  #277 is slightly further advanced, so I'm going to suggest we build on that - but please feel free to help out / comment / review in #277 as useful.  . @nestor-reyes We are also adding new 'up-for-grabs' all the time, so please keep checking back!  (eg I just posted another, #278).  We are honoured to have your interest in contributing to Polly!. @Kesmy HUGE, huge thanks for the work on this, awesome to see this so far progressed!  :+1:  :+1:  \nI ran up the cake build script (and visual studio build obv) and picked up just a few (hopefully small to fix) issues from the cake build:\nNuget packages made by cake build aren't installable\nInspected the packages with NuGetPackageExplorer and it looks like the dlls all got pushed down an extra folder, eg into lib\\net45\\net45\\Polly.dll rather than just lib\\net45\\Polly.dll.  Used NuGetPackageExplorer to edit a package (remove the extra folder) and then it installed fine. So guess we just need to fix this in the new build.\nCake build seems to compile Polly.Net40Async twice:\n```\n__BuildSolutions\n[...stuff elided...]\nPolly.Net45 -> C:\\ThirdPartyGitHub\\Kesmy\\Polly\\src\\Polly.Net45\\bin\\Release\\net45\\Polly.dll\n  Polly.Net45.Specs -> C:\\ThirdPartyGitHub\\Kesmy\\Polly\\src\\Polly.Net45.Specs\\bin\\Release\\net45\\Polly.Net45.Specs.dll\n  Polly.NetStandard11 -> C:\\ThirdPartyGitHub\\Kesmy\\Polly\\src\\Polly.NetStandard11\\bin\\Release\\netstandard1.1\\Polly.dll\n  Polly.Pcl.Specs -> C:\\ThirdPartyGitHub\\Kesmy\\Polly\\src\\Polly.Pcl.Specs\\bin\\Release\\Polly.Pcl.Specs.dll\n  Polly.Net40Async -> C:\\ThirdPartyGitHub\\Kesmy\\Polly\\src\\Polly.Net40Async\\bin\\Release\\net40\\Polly.Net40Async.dll\n  Polly.Net40Async -> C:\\ThirdPartyGitHub\\Kesmy\\Polly\\src\\Polly.Net40Async\\bin\\Release\\net40\\Polly.Net40Async.dll\n  Polly.Net40Async.Specs -> C:\\ThirdPartyGitHub\\Kesmy\\Polly\\src\\Polly.Net40Async.Specs\\bin\\Release\\net45\\Polly.Net40Async.Specs.dll\n```\nCake script seems to only detect the PCL.Specs tests to run:\n```\n__RunTests\nExecuting task: __RunTests\nxUnit.net Console Runner (64-bit .NET 4.0.30319.42000)\n  Discovering: Polly.Pcl.Specs\n  Discovered:  Polly.Pcl.Specs\n  Starting:    Polly.Pcl.Specs\n  Finished:    Polly.Pcl.Specs\n=== TEST EXECUTION SUMMARY ===\n   Polly.Pcl.Specs  Total: 1386, Errors: 0, Failed: 0, Skipped: 0, Time: 109.365s\nFinished executing task: __RunTests\n```\nWhat to do with the PCL.Specs project\nGreat question.  (We left that  targeting PCL when adopting .NET Standard 1.0, to be sure we were serving our then PCL users correctly, but it's well past time to move on :grin: )\nWhat are your thoughts on a replacement runtime for the specs proj which exercises the Polly.NetStandard11  offering?  I would happy that we still judiciously choose a single runtime target against which to test Polly.NetStandard11:   netcoreapp1.1, as FluentValidation use, seems as good a choice as any.  Open to views though ...\n(I have seen projects - such as FluentAssertions in the past - add test projects for all relevant runtimes, but they've scaled that back again now given how broad .NetStandard is :smile: .  ). \n\nIt would be totally awesome if you had time to looks at those.  All contribs get credit in the ReadMe, btw!\nThanks again for your contribution to Polly!. @Kesmy Big thanks again for this contribution, which is incredibly useful!  I am happy to dive in and have a closer look what we can do with the existing PCL.Specs.  . @Kesmy Awesome!  This is performing well, both in VS2017 and the cake build.  I'll close-read the file changes, as last check, later in the week.  Thx for all yr contribution!\n(May not get merged for few days, just while we first push out a handful of minor in-prog fixes 267, 265, 270.  I plan that this conversion to VS2017 format/builds then forms a separate release - only out of an abundance of caution, so that we can isolate any issues eg from the build change, to that one difference;  though not expecting any.  Those other PRs entirely orthogonal to yours, so I don't expect any merge conflicts.)\n. @Kesmy Thanks for your awesome contribution to Polly!  Credit added for your contribution to the project readme!. Closed via #303 . Thanks @Im5tu for joining the Polly conversation!  \nRe procedure, yes, that's exactly what we would expect to follow (per the Semver recommended practice).\nGood call.. Noting herewith some responses via twitter: https://twitter.com/softwarereisen/status/889939361298567172. Hi @brianfeucht .  Great questions.  Re:\n\nIs it possible to split these apart so that you can enforce that async policies are used \nwith the ExecuteAsync method at compile time vs execution time?\n\nYeah, the original runtime-only (not compile-time) enforcement of async-policies for async-executions is a negative.  Came in before my time on the project, but we've recently added (in a non-breaking way) what should give you the compile-time enforcement you're after.  v5.2.0 added interfaces which separate sync and async.  So right now, for example, you can declare a policy as, eg:\nISyncPolicy policy = Policy.Handle<Exception>().Retry(3);\nor:\nIAsyncPolicy policy = Policy.Handle<Exception>().RetryAsync(3);\n(and similarly for TResult-typed policies ISyncPolicy<TResult> and IAsyncPolicy<TResult>).  You can only .ExecuteAsync(...) (or .ExecuteAndCaptureAsync(...) ) on an IAsyncPolicy etc.\n. Triage of old issues (@ohadschn, apologies for the delayed reply). Re:\n\nA true compiler guarantee would have Retry and RetryAsync returning different and distinct interfaces\n\nYes, that's entirely correct.  If we retain the sync/async split in Polly, this is what we should do.\nThe reason I did not do this is that it would drive the wedge of the sync/async split deeper into Polly (and force a breaking change on users while doing so), when the intention of this work item is to remove it (unify sync/async).  I didn't want to push users in the direction of one breaking change (returning the interface instead of concrete Policy type would be a breaking change for many), only to push them in the opposite direction with another breaking change (unifying sync/async) thereafter.  \nIt's definitely true to say though that this leaves us - somewhat unsatisfactorily, as you say - only part-way through clearing up the runtime sync/async split inherited when I took over the project.  In the meantime, the availability of the interfaces does at least allow users an option to enforce compile-time failure (without breaking changes) if they want to.. Triage: further consideration of the sync/async split will sit behind getting enough of #326 in place, that policies are emitting events which can be aggregated to metrics. Picking up this issue as part of work towards Polly v7.0. \nFrom Polly v7.0 I am proposing we confirm and cleanly formalise separate sync and async policies.  This recommendation is made after practical time investigating the feasibility and cleanliness of the unified sync-async approach (spiked for v6, revisited for v7).\nOn the surface unified sync-async policies seem appealing, but (as already discussed in thread), the simplicity unravels into complexity around the policy hooks. The story becomes [^]:\n\nYou define a single policy for both sync and async usage, and you can define either or both sync or async policy hooks\nIf you define both sync and async policy hooks (and: couldn't being able to define both lead to possible contradictions in behaviour also?), an async usage of the policy will prefer to use the async policy hook and ignore the sync policy hook; but can use the sync policy hook if that's the only one you define.\nIf you define both sync and async policy hooks, a sync usage of the policy will use the sync one.  But if you define only an async policy hook, a sync usage of that policy will (do what?) -> (it has to) throw, because you can't (cleanly) use an async delegate hook amid a sync execution ...\n\nThat story seems a lot more complicated than:\n\nFor async executions define and use an async policy.\nFor sync executions define and use a sync policy.\n\nFurther drivers were:\n\nOpening up custom policies:  I was happy to sustain the complexity of implementation for [^] as lead developer for Polly's internal policies, but the complex story [^] is not one I want to sell to those implementing custom policies.\nThe strong tie-in with .Net Core HttpClientFactory.  This uses only policies in IAsyncPolicy<HttpResponseMessage>.  If users wish to develop custom policies for that use case, there's no need for us to force them to implement also a sync implementation (just to satisfy a joint sync-async policy approach).\n. 9c0a03e delivers the clean sync/async separation; intended for release in Polly v7.. Merged to v7.0.0 branch by #552.  Change will be released when v7.0.0 is merged to master and released.\n\nImpact of change clearly documented in the wiki. @johnknoop At present you have to know/remember to use .RetryAsync(...) not .Retry(...) because the original developers who added async to Polly made using a synchronous policy with an asynchronous call a runtime error, not a compile-time error.   From Polly v7 (releasing shortly) we are changing this to be a compile-time error.  You will simply not be able to code:\nservices.AddHttpClient(HttpClients.GeoCode)\n.AddTransientHttpErrorPolicy(x => x.Retry(3));\n\nbecause it will not compile.  Only the form:\nservices.AddHttpClient(HttpClients.GeoCode)\n.AddTransientHttpErrorPolicy(x => x.RetryAsync(3));\n\nwill compile.  . Closing in favour of #283 at request of original contributor. @shreyasn995  Thanks for identifying this.  Fixed in #286.   . @shreyasn995 Thanks for identifying. Fix now released to nuget.. /cc @rahulrai-in @mcquiggd  @nareshkhatri81 @tarunp @bunceg \nChannel created also in slack for more fluid discussion of this proposal https://pollytalk.slack.com/messages/C6GCFAFKK  (will port any key conclusions from slack back here). Thank you @mcquiggd for your comments.  It looks as if elements of the proposal may have come across not as I intended; I'll aim to clarify.  The comments on resilience in Azure also are great perspectives to have; thank you.   There is no intention that Polly should overlap with any of that; we see the role of Polly in architectures also that Polly only provides resilience primitives.  \nPolly users were asking about a quite specific scenario; I'll aim to focus discussion back on that, if only to move it forward (but light shone from other angles of course always welcome!).\nSummary \n\nThe DistributedCircuitBreaker users asked about is about multiple upstream callers sharing knowledge of circuit-state when calling a single downstream system.\nIf a DistributedCircuitBreaker models only a single shared state, it effectively treats any one upstream node breaking as cause enough to break all other nodes.  This risks becoming a resilience anti-pattern.  It risks inappropriately promoting an issue local only to one node/caller to a global/more widespread problem.  \nCircuits can break because of issues local only to the calling system or network path from that calling system; it's rare, but it happens.  \nWhen it does happen, a DistributedCircuitBreaker which uses only a single shared state across all upstream callers would cause a catastrophic cascading failure.  It's catastrophic because a single quirk of one caller could (by inappropriately breaking the circuit) cut off all others.\nThe essence of the proposal is that, to avoid this, users can configure the number or proportion of callers breaking, among the set, that are deemed sufficient to cause a distributed break.   \nThis can use very simple quorum logic: \ndistributed-break if >=N nodes broken independently; or \ndistributed-break if given proportion of nodes have broken independently.\nThe \"one bad node poisons other good nodes\" problem is a problem in principle for any DistributedCircuitBreaker which only models a single shared circuit state across upstream nodes.  In practice for any given system, one might decide that experience across upstream nodes would be sufficiently consistent, to choose not to engineer for this.  But as a library, we don't have the luxury of knowing the user's system.\n\n\nWhat problem are we trying to solve?\nPolly users asked here \n\nI would like to share circuit breaker state among all instances of the application. \n\nand here\n\ni have multiple containers running and if one container has tried calling service and it has tripped the circuit then i don't want other containers to call the service again which is tripped already by one container \n\nand here\n\nthe type of things you are circuit breaking (external services) are highly likely to be used across processes. Unless I've completely missed it, I don't think Polly handles this scenario\n\nand I am understanding these requests to mean we are considering a scenario where multiple upstream services/apps/nodes all call a single downstream dependency.\nDiagramatically:\n\n(The downstream system may have redundancy/horiz-scaling too, but let's consider that is hidden behind load-balancing/Azure Traffic Manager/whatever, so we are addressing via a single endpoint.)\n(We could also be talking about multiple dissimilar upstream systems A, B, C, D etc all calling M.)\nWith current Polly, each upstream node/system would have an independent circuit-breaker:\n\nI am understanding that Polly users are asking for some way for those circuit-breakers to share state or share knowledge of each other's state, such that they would (or could choose whether to) break in common.\nWhy a single shared circuit state can be dangerous: the \"one bad node poisons other good nodes\" problem\nOne solution could use a single shared breaker state:\n(the breakers exist as independent software elements in each upstream node/system; the solid box round them here is intended to illustrate they all consult/operate to the same shared state)\n\nand the benefit is that if one upstream caller \"knows\" the downstream system M is down, the other callers immediately share that knowledge (probably failing faster than if they were fully independent): \n[*1]\n\nAs however noted in the original proposal and linked threads (here, here, here) and others also noted, an approach with a single shared circuit state also risks (and by definition embeds) a catastrophic failure mode.  \nIf the reason for the circuit-of-A1-governing-M breaking is not that downstream system M is down, but instead a problem local only to A1 (eg resource starvation in A1 affecting those calls) or to the path between A1 and M, then the single shared circuit state inappropriately cuts off all the other nodes/upstream systems from communicating with M:\n[*2]\n\n(M was healthy (green). Upstream A2, A3 etc were healthy (green) and had good paths (green) to M giving green local circuit statistics.  Without the shared circuit state, the system would have had the redundancy benefit of A2, A3 etc still supporting healthy calls to M.  However, because A1 has told the single shared circuit state to break, A2, A3 etc cannot communicate to M, and the redundancy value of A2, A3 etc is thrown away.)  \nThis is a resilience anti-pattern: the single shared circuit state approach inappropriately promotes a localised problem to a global/more widespread one, causing a (horizontally) cascading failure.\nI call this the \"one bad node poisons other good nodes\" problem.\nAny approach taking the word of a single source as enough evidence that the downstream system is down, risks this: a failure at a single source will block all consumers.\nIt's rare, but it can happen.  Nodes go bad.  We all know the fallacies of distributed computing.  The problem is not that it happens very often, but that if/when it does, the single-shared-state design (yoking upstream callers together so tightly) has such a catastrophic effect.  \nIt's a bit like journalism: don't trust a story from only one source; corroborate it with others before acting. \n(So the simplification proposed in your point 3 @mcquiggd in principle embeds this risk.  That would have been the original proposal, were it not for this risk.  Of course the simplification may well be the more appropriate solution, if in a given system you judge the risk to be acceptable.)\nWithout the single shared circuit state, we would have continued to have the redundancy benefit of the horizontal scaling:\n[*3]\n\nSo: Can we fashion a solution which gives the benefits of [1] and [3], but avoids the failure of [*2]?\n\n'Crowd sourcing' whether to break - some simple quorum logic\nThe essence of the proposal is that we let users configure the number or proportion of nodes breaking, among the set, that are deemed sufficient to cause a distributed break.  This creates a non-blunt instrument.  Consistency of experience across callers gives enough confidence that the real-world happening is a downstream system failure, not something local to a particular caller.\nRather than seeking to impose a single shared truth model, the approach models the real-world complexity of multiple truths (that different callers might have different experiences of their call success to M).  And provides a user-configurable way to negotiate that.\nNodes tell the mediator when their local circuit transitions state.  And nodes can ask the mediator the state of all nodes in the set.  \nBased on this, the arbiter then embeds some extremely simple quorum logic (only requires addition and division):\n\ndistributed-break if minimum N callers broken independently; OR\ndistributed-break if given proportion of callers have broken independently\n\nThis 'crowd sources' the wisdom of whether to distributed-break or not, in a non-blunt way.\nThe solution correctly negotiates the scenario which for the simpler implementation induced the anti-pattern [*2]:\n\nBut also provides the [*1] benefit - if M is down, the quorum logic soon detects this, and breaks: \n\nMechanisms for sharing state\nThe mechanisms for sharing state information between nodes are intended exactly to be existing distributed cache technologies such as Redis, NCache etc.  (As you say @mcquiggd, all of these with their dual in-memory/remote-syncd caching are great fits.)  It also doesn't have to involve a store: if users already have some asynchronous messaging tech in the mix - Azure Service Bus Queues, Amazon SQS, RabbitMQ, whatever - these are alternatives too. \nPolly just provides a primitive\nThis doesn't make Polly embed any knowledge about the system being governed.  As ever, Polly just provides a resilience primitive.  Users model it to their own system by choosing which upstream systems to group into which distributed circuits, what quorum thresholds to configure, etc.\n. The preceding post aimed to clarify, to further discussion; not to assume what we should implement.\nFrom an understanding of the behavioural characteristics of different solutions, we can then discuss the trade-offs that there are, between complexity and fidelity/behaviour.\nWhat do others think about the \"one bad node poisons other good nodes\" problem?  \n@mcquiggd You are deeper into Azure than I: In the Azure IaaS environment, do you see upstream system behaviour as likely to be so consistent, that the risk can safely be ignored, or?\n@rahulrai-in @nareshkhatri81 / anyone interested : For your intended usages, do you think the \"one bad node poisons other good nodes\" problem relevant or irrelevant?\nMy take is that in principle the problem exists for any single-shared-circuit-state design.  In practice, as an engineer designing for a particular system, it would of course be perfectly reasonable (and very often the right decision) to be making judgments like \"For my installation, that is 'not going to happen'; at least, I will sacrifice that level of engineering, and take the risk\".\nThe trouble is, as a library, we can't foresee and don't have control over the environments in which users use the feature.\n\nFour options to move forward: (other suggestions also welcome)\n(a) do nothing\nCertainly valid to ask: is the feature worth it, for the amount of engineering necessary to get it right?  Wouldn't fully independent upstream callers just discover a downstream failure of their own accord, in due course?  Early on I was in that camp.  \nHowever, users have asked for this feature, and it can prevent each upstream caller in turn eg waiting on a timeout, to discover the same failure.  So I have aimed to propose a mature/robust design that at least avoids a catastrophic failure mode.\n(b) implement the simple version\nImplement in Polly only the simple version that embeds the anti-pattern, but warn users clearly of that failure mode.  Caveat emptor!  IE that users should only use it in systems, or with a scope, where they consider that not a risk.  \nAPI: Users have to specify:\n\nthe name of the distributed circuit the caller belongs to\n\n(c) the quorom-decision version\nThe store implementations would be not that much more complicated than (b) - it's only sticking objects in a distributed cache. \nAPI: Users have to specify:\n\nthe name of the distributed circuit the caller belongs to\nthe necessary quorum to trigger a distributed break.  \n\n(d) Only adapt Polly to allow injection of new circuit-breaker implementations\nDon't attempt to force a decision now between (b) and (c) for core Polly.  Instead simply refactor the circuit-breaker to allow injection of a custom CircuitController to provide an extension point, and let users implement whatever they like, possibly offering it to an official Polly.Contrib.\n\nThoughts?. I am keen on the (d) extension-point idea as a way forward for this too.  @rahulrai-in : would that suit your needs too?. @heneryville :+1: That's an excellent/compelling use case for this feature.\n. Part of the work towards Polly v6.0 envisages refactoring the circuit-breaker to allow injection of custom CircuitController implementations, to support this scenario.. @utkarsh5k That's great to hear!  It would be great to have more developer power on this.  \nIn (scarce) spare hours in the last few weeks I coincidentally started on point (d) of this comment, which is simpler than the original proposal:\n\n(d) Only adapt Polly to allow injection of new circuit-breaker implementations\n\nThat is: refactoring the circuit-breaker engine so that it provides a better ICircuitController seam (or similar) for the injection of custom ICircuitController (or similar) implementations.\nAnd simultaneously: refactoring the existing controller of the original circuit-breaker so that it could take (by injection) an IConsecutiveCountCircuitBreakerStateStore (and refactoring the existing in-memory implementation to fulfil this).  Building a distributed consecutive-count circuit-breaker would then be a matter of coding, say, a StackExchange.Redis (or similar) implementation for IConsecutiveCountCircuitBreakerStateStore.  \nComments welcome!\nPerhaps I should take a few more days to see if I can progress that, but also look for a good place to share work out?. Hi @harouny , thanks for the question.  If anyone has tried this, or can see a workable possibility, please say.  \nUnfortunately, I cannot see that Azure Durable Orchestration Functions with existing Polly circuit-breaker could offer a path to Distributed Circuit Breaker:\n\nNon-deterministic calls (which Polly typically guards) should not be used in orchestrator functions (longer discussion here).\nThe replay nature of orchestration functions would time-shift the outcomes of previous outbound calls (activity function invocations), skewing the purpose of circuit-breaker to reflect the current health of the called system.  For example, when an orchestration function replays, it might replay a failure result from 45 seconds ago, which is irrelevant/misleading to current system health.\nThe durable aspect of a durable orchestration function is just to persist state within a single execution (by event-sourcing results of orchestrated invocations; not, say, serializing current state). A distributed circuit-breaker on the other hand needs to accumulate and store state (success/fail stats) across calls and distributed instances.\n. To look at other possibilities: It may be possible to preserve circuit-breaker state across Azure function calls using the approach in this article or this SO discussion.  If anyone tries this, please report back.  \n\nThe static property approach could be tried simply by storing the circuit-breaker policy instance itself as a static. That would share it across function invocations which happened to run on the same VM (not a true distributed breaker if your function scales to multiple VMs, but a way of running circuit-breaker in otherwise-transient Azure function invocations, at least).\nPersisting the circuit stats/state to the Azure function's local file system should work to create a distributed breaker, but it requires similar engineering within Polly to what we need to do to make eg Redis a backing store option for circuit state.  And the network share/file-lock contention issues might well not be favourable \ud83d\ude42 , compared to using (say) Redis.. @sudheer524  There is not.\nWe could consider adding this; if so, it would be done after the major syntax refactor implied by #281.  #281 would move policy hook delegates into a fluent postfix syntax.  This will make adding further policy hook delegates easier, without proliferating additional overloads.. Similarly to the comment in #336, the Polly events-for-metrics intended for Polly v6.0, should include a SucceededWithRetries event (or similar), indicating the number of retries involved in succeeding.\nIf that event is provided, reconsider whether the extra OnSuccess delegate hook for the retry policy discussed above is necessary.. This is similar to #383 (logging eventual failure) and #336 (logging initial attempt).  \nThe best way for Polly to provide a solution for this would probably be to hook into a future emitted Policy event such as CompletedWithSuccess or SucceededWithRetries (which would be emitted automatically rather than extending the API surface in its current form).  (cf: https://github.com/App-vNext/Polly/issues/336#issuecomment-419631652).  \nLike #383, logging eventual success could also be achieved by using .ExecuteAndCapture/Async(...) overloads, perhaps using also the execution Context to capture the number of tries which have been attempted.  This could be wrapped in an extension method to easily apply it to every execution, if desired.\nThanks @sudheer524 for raising this!  It provides useful food for thought about cases which policy events should support.\nThis does feel like a strong case to support: knowing (say, on average) how many attempts were needed to achieve success.. @cppcraze Are you using .Handle<TResult>(...) clauses in your policies?  \nIf not, the non-generic versions of the policies already provide what I think your suggestion asks for.  The non-generic Policy already has void-returning overloads and TResult-returning, generic method overloads.\nSo the same non-generic CircuitBreakerPolicy instance can be used for void-returning and for .Execute/Async<TResult>(...) for multiple TResult types.\n\nSome reasons for the existence of the generic-typed Policy<TResult> when .Handle<TResult>(...) is in use are described in this wiki page.  \nIf you (/anyone) has policies using .Handle<TResult>(...) but wants to share other aspects of the policy definition (eg the circuit-breaker/circuit-breaker definition) across call sites, I can provide further comments/suggestions!. @udlose . Do you have (iiuc) that HTTP header information in hand in the code before you execute through the policy?  If so, you can achieve what I think you are after by using a Context which travels with each call, to pass information between Execute and the fallbackAction .\nAll the Execute/Async/AndCapture() execute variants have overloads where you can pass in a Context or dictionary-like data that will get placed on the Context.  \nFallbackPolicy  has configuration overloads where the Context can be an input parameter to a func that returns the fallback value.\nIf that doesn't cover it (I've had to make some assumptions), please do elaborate and we can help further!\nThanks. :+1:  @udlose  .  There are some code examples also in this blog post (they are based around retry, not fallback, but the concepts are the same).. Hi.  Which version of Polly are you using?  The ability to use context in the fallback delegates was added in v5.3.0.. Hi @udlose !  What you're after is covered by Fallback configuration overloads which take a Func to return the fallback value, rather than a pre-computed value.  \nThe principle is shown in the second example here or here.\nI've just seen the edit here.  Great q.  The Func isn't executed unless needed (see this test for confirmation), so this meets:\n\nthe construction of the Fallback [doesn't] actually occur until/unless the FallbackPolicy is actually executed\n\nA specific async-TResult overload taking Context as an input parameter for computing the fallback is here.\nUsing this, you can re-express the policy configuration you quoted as, eg:\nvar fallbackPolicy = Policy<HttpResponseMessage>\n    .Handle<Exception>()\n    .FallbackAsync(fallbackAction: async (context, token) => await BuildFallbackAsync(context), onFallbackAsync: async (result, context) =>\n    {\n        await Task.Run(() => _log.Error($\"{context.PolicyKey} at {context.ExecutionKey}: fallback value substituted, due to: {result.Exception}.\"));\n    });\nEDIT: This earlier comment shows the ExecuteAsync(...) overloads to use to pass in context; also examples in the blog post.\nLet us know if that gives you what you need, or if you need anything else!. @tynor88  Could I ask for some clarifications?\nAre you looking to separate policy definition and usage? (ie you define the policy outside this method and pass it in as an IRetryPolicy or IPolicyAsync).  \nIn that scenario, you wouldn't be able to close over the _sqlConnection variable in the way the posted code does.  The solution to this is to use the Context that Polly can flow with each execution.  I can provide further info, but the scenario and solution are essentially the same as in #292.  This blog post also gives some code examples.\nIf that was not the question, could you clarify?. >sorry for not expressing myself clearly enough.\nNot a problem, just want to make sure our advice is focused on what you need.\nRe:\n\n\nAre you looking to separate policy definition and usage? (ie you define the policy outside this method and pass it in as an IRetryPolicy or IPolicyAsync).\n\nNot necessarily - but if this is the only way to get rid of the dependency on the Policy class, then yes.\n\nInjecting policies to make the code more testable does imply separating policy definition and usage.  Rather than declaring the policy within the class/method where it is used (which means you can't change it for testing), you declare it outside, so that it (the dependency) can be injected.  By having it injected, you can then substitute something else in a test.\nAnd because you've separated policy definition from usage, you can't close over the _sqlConnection variable any more, so you have to pass it through Polly's execution Context\nYou don't have to switch to interfaces to use DI - you can inject anything, either declared as a concrete Policy myPolicy class or an IPolicyAsync myPolicy interface, but interfaces is typical (advantages a longer discussion not for here).  \nA sketch using the code you provided, and Polly interfaces:\n```\n// Somewhere outside the method or class you define the policy.  Often at app startup.\n// This policy definition shows extracting the _sqlConnection instance from the Context.  At the call site, you'll pass it in.\n// You don't need the retryCount variable in your original; Polly provides that as the passed in int retryAttempt\nIAsyncPolicy myPolicy = Policy\n        .Handle()\n        .WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromMilliseconds(0.1 * retryAttempt),\n            (ex, timeSpan, context) => {\n                 ((ConnectionClass)context[\"sqlConnection\"])?.Close();\n            })\n// Where you're actually using the policy - typically, you might inject it through a class constructor and store it in a private field:\n// (but there can be other approaches)\nclass MyClassUsingThePolicy\n{\n    private IAsyncPolicy _myInjectedPolicy;\n    MyClassUsingThePolicy(IAsyncPolicy myInjectedPolicy)\n    {\n        _myInjectedPolicy = myInjectedPolicy;\n    }\n\n    public async void MyMethodUsingThePolicy()\n    {\n        // Assumption: ConnectionClass _sqlConnection is declared and assigned somewhere ... use also the c\n\n        try\n        {\n            await _myInjectedPolicy\n                .ExecuteAsync(async context =>\n                {\n                    var sqlConnection = ((ConnectionClass)context[\"sqlConnection\"]);\n                    await sqlConnection.OpenAsync();\n                    await sqlConnection.Query<Test>(\"SELECT * FROM Test\"); \n                },\n                new Dictionary<string, object>() { { \"sqlConnection\", _sqlConnection } } // This uses the `.ExecuteAsync(...)` overload that takes dictionary data that will be placed on the `Context`\n                );\n        }\n        finally\n        {\n            _sqlConnection.Close();\n        }\n\n    }\n\n```\n(A few details weren't provided in your original code sample, like the type of _sqlConnection .... maybe it's using a micro ORM like NPoco or somethig, due to the .Query<Test> syntax? ,.. adjust the type as necessary)\nFor unit tests, you can then pass in a IAsyncPolicy myStubPolicy = Policy.NoOpAsync() to the constructor of MyClassUsingThePolicy, instead of the real policy, to stub out the effects of Polly from the test.\n. Closing due to lack of further discussion.  Please do re-open if we can help further, however.. Hi.  Declaring the policy explicitly as FallbackPolicy policy has declared a non-generic policy.  The compiler thus picks up this configuration overload: .Fallback(Action fallbackAction)\nThat this is not jumping out as a problem is in part caused by the fact that the compiler will silently accept assigning a Func<int> to an Action.  It's not an error - it's just as you could execute DivideWithoutZero(3, 0); as a statement, without doing anything with its return value - but there isn't any warning to you from the compiler that this is happening.\nInstead, you need to declare that the policy is explicitly for delegates returning int:\nFallbackPolicy<int> policy = Policy<int>.Handle<DivideByZeroException>().Fallback(() => DivideWithoutZero(3, 0));. @jonnovaretti Thanks for raising this.  Did the suggestion fix for you?\nI think we should fix this in Polly so that it's not possible to fall into the situation you encountered.  The combination is:\n(1) A plain (non-generic) FallbackPolicy configures an Action fallbackAction to run in case of fallback\n(2) All Polly non-Generic policies let you use a generic execute method .Execute<TResult>(...). But a generic-TResult execution for a plain FallbackPolicy doesn't make sense, because the Action fallbackAction configured can only ever return void, so can never provide a substitute TResult value.\nAs a result, I think we should treat FallbackPolicy (non-generic) .Execute<TResult>(...) as an InvalidOperationException.. Marking 'up-for-grabs'.  Needed:\n\noverride the generic method overloads .Execute<TResult>(...), on non-generic FallbackPolicy, so that they throw InvalidOperationException (for the reasons described in prev. comment).\n\nunit tests. Fixed in Polly v5.6.0 (will be released via nuget in next day or so).  Now throws an exception as warning, when non-generic FallbackPolicy is used with generic methods .Execute<TResult>(...), with explanatory message:  \nYou have executed the generic .Execute method on a non-generic FallbackPolicy.\nA non-generic FallbackPolicy only defines a fallback action which returns void; it can never return a substitute TResult value.\nTo use FallbackPolicy to provide fallback TResult values you must define a generic fallback policy FallbackPolicy.\nFor example, define the policy as Policy.Handle.Fallback(/ some TResult value or Func<..., TResult> /);\n. Thanks @udlose for being extra pair of :eyes: .  xunit 2.0+ (which we're using) correctly handles the async void tests (by using a custom SynchronisationContext as I understand) (Stephen Cleary did an msdn mag article mentioning it?), but yeah, let's switch them to async Task just to avoid any ambiguity or potential future false-positives (eg if we switched test-runners in future).\n\n\nThanks again for the good spot!\nFixing in #300. >For reference, here's a link to the MSDN article - https://msdn.microsoft.com/en-us/magazine/dn818493.aspx\nThanks @udlose !  \nFor future ref also, for anyone returning to this thread, here the xunit 2.0 release notes and related issue which verify the xunit 2.0 behaviour.. This is delivered in Polly v5.6.0 (will be released via nuget in next day or so).. Thanks all for all the great comments.  Hoping to come back to this and #299 before the end of the week.. @udlose @ExtRemo75  Great discussion re aggregation rather than inheritance for isolating 3rd party APIs.  I guess it depends what you are trying to achieve.  If you want to isolate Polly, then yes, wrapping in your own abstractions is the way to go.  \nThe benefit of allowing people to extend the Policy base class, is that they can implement just a little new behaviour, but also get thrown in for free all the scaffolding which Polly has - all the .Handle<>() syntax, all the .Execute() / .ExecuteAndCapture() overloads, all the events/metrics stuff as we get to add it, etc.  But yes, extending that way implies a certain investment in sticking with Polly.\nThe fact that all this functionality is loaded on the Policy base class is something of a consequence of how the architecture has evolved (including before my time).  In a hypothetical complete rewrite of Polly, it'd be possible to component-ise all that more - IFaultFilters, IPolicyBehaviour, all brought together with an IExecutionDispatcher or similar (I have versions of this in my head).  This could avoid some of the compromises like extension by extending the base class.  Such a complete rewrite would however represent a significant time commitment.\nWe would be very happy to see anyone's ideas though - we can also make incremental change.  The current approach is targeting incremental change - some of it quite significant (eg #281) - where the existing architecture is actively holding us back.\nKeep the thoughts coming, as we have opportunities to change the architecture with v6.. Closed by #391\nThe options for compenentisation discussed in the previous comment (thanks for the valuable discussion) remain options for a future version of Polly or any similar product.  As discussed above, a rewrite to such a structure would be intellectually well motivated (and does appeal).  It would require a significant chunk of time tho (and would lead to a significantly different syntax experience for users).\n( EDIT: Very happy to discuss any ideas around this, and/or support anyone who wants to explore them. ). @extremo75 , Apologies for the delay responding. Huge thank-you for your work on this PR towards allowing custom policies!\nThe PR goes further than the original proposal (thanks for  your note to this effect!).  My slight concern is it (at mo) creates a very broad extension surface to Polly, which could cause problems down the line for both Polly and users extending.  It may be better for both if we can achieve the same extensibility but keep extension points more tightly focused?\nThe concern over a  broad extension surface is the large number of potential points of contact between Polly and custom-policies which it creates - a join with a large number of connection points is potentially more rigid/ inflexible/ brittle, as Polly evolves, than if we can create one with only a small number.  With many extension points, if we change only a single one, it risks a breakage for users with custom policies.  Equally, if we set a precedent that almost every method on Policy is public/protected virtual so that people could override it, users who've created custom policies this way risk having frequently to 'play catch up' (override more methods), as we evolve and extend.  (Items like ((EDIT)) 281 will cause significant changes.)\nA single extension point (or tightly focused group) - like just making the private base class constructors protected, and making public anything necesssary to return results - should otoh flex more easily with Polly as it grows?\nI hope this makes sense.  What do you think?\n\nSo, practically, the main concern was making the .Execute(...) overloads override-able.  To make sure I've understood what this would help users achieve: what were the particular use cases you envisaged for overriding .Execute(...) and related overloads?  To permit custom policies, I had envisaged it might be enough just to allow a custom implementation (passed into the base Policy constructor at the moment), and let the  .Execute(...) overloads do their normal job.\nThanks again for all your contribution to this!. Closed in favour of the simpler equivalent, #391 . Broadly related to #177 .  \nAt the moment, we are looking not to add further policy configuration overloads to Polly, due to the already too-numerous overloads.  The forthcoming syntax changes proposed in #281 are intended to reduce the number of overloads by splitting onPolicyEvent-type delegates out of Policy configuration.  \nIt could be good then to add this after the #281 syntax changes.. This feature is delivered in Polly v5.6.0 (will be released via nuget in next day or so).. Huge thank you, @ExtRemo75 , for your contribution, and thank you @udlose, @ExtRemo75 , both, for your close attention to this code!  Yes, that corner of the PolicyWrap config code was on my list to tidy: please feel free!\n(Apologies that vacation followed by tight commitments have kept me from these PRs just lately ...). Cross-ref build issue. @ExtRemo75 Huge thanks for this contribution (just reviewed again)\nI am going to pend this PR for the moment, as I am also exploring #281 as part of v6, which may make the sync/async split redundant.\n(Thanks also for the attention to the PolicyWrap config code!). Closing in favour of #370 , which already merged to the v560dev branch, because this (#302) also included parts of #299 (which not ready to merge/still under discussion).\nCredit added to @rjongeneelen in the readme, for doing much of the refinement on PolicyWrap config syntax, which also found its way into #370.  \n370 also addressed some of the useful comments on further cleanups for PolicyWrap syntax arising in discussion from @udlose and @rjongeneelen , thanks y'all!\n. @ExtRemo75  Thank you for your investment in Polly, and this awesome contribution!  And a beautifully symmetric and complete set of tests.  Merging for v5.4.0 :+1:. @seanfarrow This PR created (as requested) the branch https://github.com/App-vNext/Polly/tree/v5.3.x-cachebeta , which you can now use: \n\nRefactors caching architecture for beta release\nbetter naming; \nchanges to TTL to support sliding expiration more explicitly\n\nrebases caching architecture on latest v5.3.x master . @ryanfollmer Briefly, as I am on the road at mo:\n\n\nThere isn't a way to reset the internal retry count of WaitAndRetryForeverAsync() (but the policy does exit each time an execution succeeds, and the count will be reset to zero for the next invocation through the policy).\n\nYou could (as you say) maintain and reset your own retry count.\nYou can also handle this kind of scenario purely with Polly, using the fact that PolicyWrap can nest more than one policy of the same type.  For instance, you can have an inner retry policy that does exponential backoff, for exceptions for which that's appropriate.  Then wrap that with an outer retry policy which catches the timeouts and retries.  When a timeout hits the outer policy and that triggers its retry, it effectively places a new call through the inner policy, so with a fresh (reset to zero) count for the exponential backoff.\n\nSomething like this (pseudo-code):\nvar outerRetry = Policy\n    .Handle<Exception>(ex => ShouldResetExponentialBackoffAndRetry(ex)) \n    .RetryForeverAsync(/* probably no delay or backoff; there's already been a long wait since exceptions caught here are due to a timeout, and it's desired to trigger an immediate reconnection attempt? */);\nvar innerRetry = Policy\n    .Handle<Exception>(ex => ShouldRetryWithBackoff(ex))\n    .WaitAndRetryForeverAsync(/* code to retry with backoff */);\nvar combinedRetry = outerRetry.Wrap(innerRetry);\nHope that helps in the interim - further questions welcome!. @iojanblog I am currently on travel, but could provide a detailed example in a few days' time.\n. @iojanblog For a first insight, your pattern:\ntry\n{\n    return await _somePolicy.ExecuteAsync(() => FooAsync<T>()); // for Func<Task<T>> FooAsync()\n}\ncatch (BrokenCircuitException ex) when (/*some condition */)\n{\n    /* some logging */\n    return await SomeFallbackAsync<T>();  // for  Func<Task<T>> SomeFallbackAsync()\n}\ncan be expressed in a FallbackPolicy thus:\nFallbackPolicy<T> _fallbackPolicy = Policy<T>\n    .Handle<BrokenCircuitException>(ex => /* some condition */)\n    .FallbackAsync(fallbackAction: cancellationToken => SomeFallbackAsync(),\n        onFallbackAsync: async delegateResult => { /* some logging using delegateResult.Exception */ });\nreturn await _fallbackPolicy.WrapAsync(_somePolicy).ExecuteAsync(() => FooAsync());. So your first method could be expressed something like:\n```\nprivate async Task ResilientAsync(Func> action, Func> fallbackAction, Func> defaultAction = null)\n{\n    FallbackPolicy outerFallback = Policy\n        .Handle(ex => defaultAction != null)\n        .FallbackAsync(\n            fallbackAction: cancellationToken => defaultAction(),\n            onFallbackAsync: async delegateResult => {  _logger.LogWarning($\"*** default fallback = {delegateResult.Exception.InnerException.Message}\"); }\n        );\nreturn await outerFallback.WrapAsync(_retryPolicy).ExecuteAsync(() => FallbackAsync(action, fallbackAction));\n\n}\n```\nSimilarly, the second method could refactor to something like:\n```\nprivate async Task FallbackAsync(Func> action, Func> fallbackAction) \n{\n     FallbackPolicy innerFallback = Policy\n        .Handle(ex => _fallClient != null)\n        .FallbackAsync(\n            fallbackAction: cancellationToken => _circuitPolicy2.ExecuteAsync(fallbackAction),\n            onFallbackAsync: async delegateResult => {  _logger.LogWarning($\"*** resilient fallback = {delegateResult.Exception.InnerException.Message}\"); }\n        );\nreturn await innerFallback.WrapAsync(_circuitPolicy).ExecuteAsync(action);\n\n}\n```\nSo, if you then inlined the second method, you could reduce the whole to:\n```\nprivate async Task ResilientAsync(Func> action, Func> fallbackAction, Func> defaultAction = null)\n{\n    FallbackPolicy outerFallback = Policy\n        .Handle(ex => defaultAction != null)\n        .FallbackAsync(\n            fallbackAction: cancellationToken => defaultAction(),\n            onFallbackAsync: async delegateResult => {  _logger.LogWarning($\"*** default fallback = {delegateResult.Exception.InnerException.Message}\"); }\n        );\n FallbackPolicy<T> innerFallback = Policy<T>\n    .Handle<BrokenCircuitException>(ex => _fallClient != null)\n    .FallbackAsync(\n        fallbackAction: cancellationToken => _circuitPolicy2.ExecuteAsync(fallbackAction),\n        onFallbackAsync: async delegateResult => {  _logger.LogWarning($\"*** resilient fallback = {delegateResult.Exception.InnerException.Message}\"); }\n    );\n\nreturn await Policy.WrapAsync(outerFallback, _retryPolicy, innerFallback, _circuitPolicy).ExecuteAsync(action));\n\n}\n```\nThere might be a wrinkle if your compile settings complain (rightly) that this particular onFallbackAsync delegate doesn't contain any awaits (I'm assuming your _logger is synchronous).  Apply the usual fixes , returning something like Task.CompletedTask from a non-async delegate, if necessary.  \nLet me know if any of that doesn't work or further qs (am pushing this example out during travel).\nThanks. Hi @udlose ! The Isolate() method should do what you need.\n. @brunoabreu .  That's a great question.  It should not be the case.  The circuit-breaker engine explicitly rethrows unhandled execptions (TaskCanceledException in your case), without them affecting circuit state or metrics (unhandled exceptions do not cause a call in to OnActionFailure(...)).\nI was able to construct a quick test, showing that the unhandled exception leaves the circuit in half-open state:\n```csharp\n[Fact]\npublic void Should_leave_circuit_halfopen_if_the_next_call_raises_an_unhandled_exception()\n{\n    var time = 1.January(2000);\n    SystemClock.UtcNow = () => time;\nvar durationOfBreak = TimeSpan.FromMinutes(1);\n\nCircuitBreakerPolicy breaker = Policy\n    .Handle<DivideByZeroException>()\n    .CircuitBreaker(2, durationOfBreak);\n\nbreaker.Invoking(x => x.RaiseException<DivideByZeroException>())\n    .ShouldThrow<DivideByZeroException>();\nbreaker.CircuitState.Should().Be(CircuitState.Closed);\n\nbreaker.Invoking(x => x.RaiseException<DivideByZeroException>())\n    .ShouldThrow<DivideByZeroException>();\nbreaker.CircuitState.Should().Be(CircuitState.Open);\n\n// 2 exception raised, circuit is now open\nbreaker.Invoking(x => x.RaiseException<DivideByZeroException>())\n    .ShouldThrow<BrokenCircuitException>();\nbreaker.CircuitState.Should().Be(CircuitState.Open);\n\n\n// duration has passed, circuit now half open\nSystemClock.UtcNow = () => time.Add(durationOfBreak);\nbreaker.CircuitState.Should().Be(CircuitState.HalfOpen);\n\n// first call after duration raises an unhandled exception\nbreaker.Invoking(x => x.RaiseException<TaskCanceledException>())\n    .ShouldThrow<TaskCanceledException>();\n// unhandled exception should not affect state - breaker should still be halfopen\nbreaker.CircuitState.Should().Be(CircuitState.HalfOpen);\n\n}\n```\nCould what you are seeing be that the circuit-breaker only permits one execution attempt per breakDuration, in half-open state?  \nSo: If, after the first TaskCanceledException in half-open state, your breakDuration has still not expired, then a second call (before breakDuration expires) will throw BrokenCircuitException, even though the circuit is still in half-open state - because only one trial call per breakDuration in half-open state is permitted.\nDoes that sound like it describes your scenario?\nThere are tests showing this here. Adding the following lines to the end of the test above, also demonstrate this: \nbreaker.Invoking(x => x.Execute(() => {})).ShouldThrow<BrokenCircuitException>();\n    breaker.CircuitState.Should().Be(CircuitState.HalfOpen);\nThe behaviour is by design, to prevent request stampedes during half-open state, and matches Hystrix's approach.  \n\nIf that doesn't describe your scenario (or if qs about it), let me know, and we'll dig deeper.. @pvmraghunandan Quick answers:\n\nWhen the circuit is in open state and transistioned to half open and at the same time if we get two calls, are we saying that we allow only one call to pass through and other call will get Broken Circuit Exception? \n\nYes, as documented in the circuit-breaker wiki.  I've made the doco clearer to confirm that blocked executions in half-open also throw BrokenCircuitException.\n\nIf that's case, can we skip whole half-open? :)\n\nNo built-in Polly syntax to do that. But you could achieve it by configuring the onHalfOpen: delegate just to call breakerPolicy.Reset(); - that will make the circuit-breaker transition directly back to closed when it hits half-open.  Of course, you don't have access to the breakerPolicy instance at the point of configuring the policy, so you'd have to do the same trick we discussed few days ago where you pass data in via Context - this time passing in the policy you are executing through via Context, so that onHalfOpen can get it from context, then call Reset() on it.\nWe may later introduce an injectible circuit-breaker controller you could custom-code to control circuit-breaker behaviour more finely.. Thank you @udlose and @ExtRemo75 for the great discussion on this!\nDecoupling of policy configuration from usage due to DI, or using PolicyRegistry, does mean that code could be passed a PolicyWrap whose constituent parts it doesn't know, but wants to.  It seems valid  for PolicyWrap to expose this.\n@udlose Re GetPolicy(string policyKey), I see your line of thinking there, but it does presuppose that the code receiving the PolicyWrap knows the key of the policy it wants to extract (so that still has to be transmitted/tracked separately).\nHow about an API which focuses simply on the essence of what PolicyWrap is:\n(1) read-only property IsPolicy Outer returning the outer policy of the wrap (without recursive unpacking if that is a PolicyWrap)\n(2) read-only property IsPolicy Inner returning the inner policy of the wrap (without recursive unpacking if that is a PolicyWrap)\n(3) method IEnumerable<IsPolicy> GetPolicies() returning all policies of the wrap (correctly sequenced outer-to-inner, recursively unpacking and flattening if any is in turn a PolicyWrap)\nFrom (3) anything like \"extract the circuit-breaker\" or \"extract the Policy with this key\" follows trivially with LINQ.\nThe current PolicyWrap stores only the implementation needed to execute on the PolicyWrap, so some private fields/read-only properties for outer and inner would need adding, probably only settable via the ctor. \nWhat do you think?\nPR to implement this would be welcome! \nCross-ref: https://stackoverflow.com/questions/45913775/ .  (If we implement this, let's post also on that StackOverflow that it is done!). @udlose Agreed, IsPolicy is not a very useful return type to work with.\nIsPolicy is a thin interface because it is just a 'marker' interface for a policy which might be either a non-generic or a generic policy (each suits different scenarios; eliminating one or the other would cause pain points elsewhere).  Since PolicyWrap allows combining non-generic and generic policies, IsPolicy is necessarily the lowest common denominator for what any element of a PolicyWrap might be.\nHowever, completely agree that IsPolicy is not a very useful return type to actually work with. With PolicyRegistry we added helper methods to extract and cast policies to a more specific type, so how about we have similar for extracting from PolicyWrap?\nSo a revised overall API for this feature could be:\n(1)-(2)-(3) as per my previous comment.  These are important as they form the logical converse to constructing the PolicyWrap.\nPlus:\n(4) IEnumerable<TPolicy> GetPolicies<TPolicy>() // gets (and casts) all policies in the wrap, which are of type TPolicy\n(5) IEnumerable<TPolicy> GetPolicies<TPolicy>(Func<TPolicy, bool>) // ditto with predicate\n(6) TPolicy GetPolicy<TPolicy>() // gets the single policy in the wrap, of type TPolicy (for when you are confident you have only one)\n(7) TPolicy GetPolicy<TPolicy>(Func<TPolicy, bool>) // ditto with predicate\nAnd: [EDIT: For the reason you say, it would be useful to have this]\n(8) TPolicy GetPolicy<TPolicy>(string policyKey)\nThoughts?\n(Thanks for input so far, which is turning this into a better feature!). This feature is delivered in Polly v5.6.0 (will be released via nuget in next day or so).. @v-rosa I'm assuming that base in your code sample refers to HttpClient.  \nThe InvalidOperation exception: The request message was already sent is part of the HttpClient design; Polly can't change that.  There are numerous suggestions for refreshing/cloning the request on StackOverflow though:\n\nhttps://stackoverflow.com/questions/25047311/\nhttps://stackoverflow.com/questions/18000583/\nhttps://stackoverflow.com/questions/34222873/\n\n. @jiimaho  Makes complete sense.  Great q.\nA few possibilities:\n(a) available now: Inject a TimeoutPolicy configured to TimeSpan.Zero : \n\nWith TimeoutStrategy.Optimistic, bear in mind that the executed delegate will execute any code up until the point it first honours a cancellation token.  Well-designed code should check the cancellation token on entry.  \nIf using TimeoutStrategy.Pessimistic because the executed delegates do not observe cancellation, the policy would throw the TimeoutRejectedException, but the delegate (if not observing cancellation) would continue to execute - which may not be what you want in the test.\n\n(b) available following a small PR: Mock an injected policy to throw TimeoutRejectedException or to set up a PolicyResult denoting TimeoutRejectedException : If you're using / can use a mocking framework, and you inject your policy in one of the interface forms, then in the test, you could set up the mock to throw TimeoutRejectedException; or the execution to return a PolicyResult with FinalException set to TimeoutRejectedException.  For the latter, the various static constructors in PolicyResult would need to be made public - we'd be happy to accept a PR for that.\n(c) not available yet: Custom policy: When we have PR #299 finalised (but it needs review/small changes), you would be able to write your own custom policy - say, AlwaysTimesOutPolicy - and inject this instead of your real TimeoutPolicy or NoOp.  \nDo any of these help?. Addendum: when custom policies are possible, the suggestion (c) could of course be generalised to various test-helper policies such as:\nPolicy.TestHelperReturns<T>(T instance): always returns instance instead of executing supplied delegate\nPolicy.TestHelperThrows(Exception exception): always throws exception\n(and similar).\nBut this overlaps with facilities already available in standard mocking frameworks, and may be better left to them.  Having a number of these would also be a distraction, if in core Polly.  Perhaps better as part of a Polly.Contrib (if anyone wants to contribute it).\nThinking aloud here - community views?. >This doesn't work. It throws an ArgumentOutOfRange exception. \nTrue: I misread the boundary condition.  We could change the boundary condition to permit TimeSpan.Zero, to support this Use Case.  You could also (right now) likely use TimeSpan.FromTicks(1) with the same practical effect.. @jiimaho Re:\n\nSeemed the effects [of a test based on a short timeout] were different depending on which machine \nexecuted it. (locally or through AppVeyor).\n\nAha.  Well, we can corroborate that experience if AppVeyor is in the mix.  We in the past observed a similar problem with CancellationToken.CancelAfter() firing significantly later than billed, in an AppVeyor build.  (A wrinkle; AppVeyor awesome in so many other ways.)\nIn any case, moving (as we are doing) to simply being able to mock the policy to return a desired PolicyResult is a much more robust solution.. Close via #317. @jiimaho  Added to the Polly [unit-testing documentation)(https://github.com/App-vNext/Polly/wiki/Unit-testing-with-Polly), to reflect this approach.. @udlose  Great question.  \nThis kind of configuration option (N failures within timespan T) was one we considered for triggering circuit-breaking, but shied away from because pure error frequencies (N per time T) as a measure are vulnerable to not scaling with load increases or decreases.\nSay you set the trigger level at 4 failures in 30 seconds.  If your circuit is handling 'typically' (say) 10 calls/30-seconds, that's a nice sensible trigger threshold (about 40% failure rate).  But what if throughput increases to, say, 100 calls/30-seconds?  Suddenly 4 failures is only 4% - would one still want to break (impose 100% failure) on a 4% failure rate?  It's a more extreme example, but the principle holds: effectively, the influence of a trigger configured as N failures per time T varies with throughput.  \n(That's not to say you might not have a scenario where you might be comfortable with it as a measure; but it's why we didn't implement it.  It starts then to beg the question of how to 'adjust' it, as the throughput of the underlying system changes.)  \n. So to come back to your question, practically:\n\nWhat would be your suggestion on implementing a requirement of:\nif there are 10 failures with a span of 5 mins, open the circuit for 5 mins\n\nMy suggestion would be: if you're thinking 10 failures in 5 mins is your trigger, you probably have in the back of your mind some idea of the overall throughput that's against: say, 20 calls in 5 mins or 30 calls in 5 mins.  I'd convert that to a proportion for the AdvancedCircuitBreaker (break on 50% failure rate; or 33% failure rate).  Set up your AdvancedCircuitBreaker as something like:\nfailureThreshold: 30% or 50%\nsamplingDuration: 5 minutes (as you wanted) (forgets about things that happened >5 mins ago)\nminimumThroughput: ~10 calls~ (10/failureThreshold: ie 20 if a 50% failureThreshold; 30 if a 30% failureThreshold).  (This effectively gives you part of what you wanted - it won't trigger unless you have at least 10 failures in those 5 minutes.)\nThen you have something close to your original intention, but you also now have a version which scales appropriately with varying throughput.\nEDIT: Hope this discussion/reasoning/suggestion is useful.  Not seeking to persuade you to a approach you don't like :smiley_cat:  ... just answering the question (what would be my suggestion, if that was the requirement put to me)\nEDIT 2: If/when we progress to option (d) here or allow custom policies, you could of course also code your own implementation of the pure frequency-based trigger.\nHope that helps.. Hi @udlose \n\nSo in the case of the AdvancedCircuitBreaker, what happens to the requests that come thru and fail but do not cause the circuit to open?\n\nThey are rethrown and will bubble to the calling code - either the next outer policy in the wrap, or (if none), your calling code.\n\nI assume that the failures will cause a Fallback policy to be invoked.\n\nYes (assuming - stating these just for precision - the fallback is somewhere outside the breaker in the wrap, and the fallback is configured to handle the given exception)\n. @jiimaho Thanks!  LGTM re internal -> static changes.  I can review comments and dress up as a new version number for nuget release.\nLooks like we need to do some work on the build tho - might be few days before I can get to that.  Looks like cake v0.22 intentionally breaks cake plug-ins, and we either need to pin our version of cake core (except instructions there don't match the Polly build- need to dig deeper) or wait for the Cake.FileHelpers plugin to update - due shortly.. @jiimaho  It looks like the cake build plug-in has been updated (fixes our build), so I'll make some suggestions about the intellisense for the PR shortly, then we should be able to merge it!. @jiimaho Since this PR only involves changing the 5 instances of internal to public to support testing, and adding intellisense per our discussions, I am not holding up the merge for your signing of the CLA agreement (it's the kind of tiny changes the CLA bot might have deemed not worthy of the signing).  However, it would be great for any future contributions if you could:  https://cla2.dotnetfoundation.org.\nThanks for this small but important contribution!. @joaoasrosa Thank you for the detailed repro.\nThis test within Polly, is intended to demonstrate that the scenario you are using with TimeoutPolicy works.\nI note that the IAmazonS3.GetObjectAsync(...) overload you .Setup(...) on the mock has a different signature from the .GetObjectAsync(...) you execute within DocumentRepository.  Have you verified the .SetUp() and its Thread.Sleep(2000); is really getting hit when the test executes?  How long does the test take to complete?  \nMaybe you could adapt the test as follows, to check that the .Callback(...) and .ReturnsAsync(...) of your .Setup(...) is really getting invoked:\n```\nvar stubResponse = new GetObjectResponse();\n_clientMock.Setup(x =>\n    x.GetObjectAsync(It.IsAny(), It.IsAny(), It.IsAny()))\n    .Callback((string b, string o, CancellationToken c) => { Thread.Sleep(2000); })\n    .ReturnsAsync(stubResponse);\nobject actualResponse = null;\nawait Record.ExceptionAsync(async () => { actualResponse = await _sut.GetDocumentAsync(\"dummy\", \"document.json\"); } );\nactualResponse.Should().BeSameAs(stubResponse);\n_policy.TimeoutTriggered.Should().BeTrue();\n```\nEDIT: If this comment is off the mark, come back, and we'll dig deeper.. @joaoasrosa A bit of lunchtime debugging: If you rewrite the test as follows, it passes:\n```csharp\npublic async Task GetDocumentAsync_WhenCallAboveThreshold_TriggersTimeout()\n{\n    _clientMock.Setup(x =>\n        x.GetObjectAsync(It.IsAny(), It.IsAny(), It.IsAny()))\n        .Returns(async () =>\n            {\n                await Task.Delay(2000);\n                return new GetObjectResponse();\n            });\nawait Record.ExceptionAsync(async () => { await _sut.GetDocumentAsync(\"dummy\", \"document.json\"); });\n\n_policy.TimeoutTriggered.Should().BeTrue();\n\n}\n```\nThe reason for your original test failing looks to be to do with the fact that Moq's .CallBack(...) isn't really async-friendly, given how async/await works\n(1) Any async method runs synchronously up to the first await.  Only at the first await, does it return a Task, returning execution to the caller.\n(2) Moq's .Callback(...) doesn't act as an async method in that manner.  It looks to be conceived to be used synchronously only (there's no corresponding .CallbackAsync(...), for example - although I'd be interested to learn more if anybody knows different about Moq).  So, in your original test, Moq's .Callback(...) runs synchronously, blocking solidly for those 2 seconds and never returning a Task that would allow the calling code (in this case the Polly policy) to continue execution and decide what to do with that Task.  In other words, the original .Callback(... => { Thread.Sleep(2000); }) simulates a badly-behaved async API that isn't really async but sync instead.  Effectively, the original test with .Callback(...) ends up using an async TimeoutPolicy on a synchronous execution, and it isn't designed for that.  \n(3) I experimented with writing .Callback(async () => { await Task.Delay(2000); }) but this also left the test failing.  In this case, since .Callback() isn't designed to be async, that form was (by my reading) creating an async void delegate. Moq has no intent to await (it has no async intent around .Callback()) and an async void delegate can't be awaited in any case.  Double whammy.  So execution proceeded immediately to the .ReturnsAsync(stubResponse) in your original, speedier than the timeout would have occurred.  So test again failed.\n(4) Hence the final version of the test I came up with.  Essentially, to simulate a well-written-for-async but slow-responding async call, the test needs to simulate asynchronously waiting for 2 seconds, not synchronously, before returning the delayed response.\nHope that detailed explanation of why the original didn't work, helps.\nThis does indicate that Polly's TimeoutAsync policy will fail, even in pessimistic mode, if used against a badly behaved async API, that blocks synchronously rather than being truly async.  EDIT: For reasons I can go into in more detail, my initial view is that this is the correct behaviour.. @joaoasrosa  I deduced those points (2) and (3) above about Moq by quick observation of what was happening, but a brief google now seems to bear out my hunches:\nhttps://stackoverflow.com/questions/36583780/async-callback-on-mocked-object-not-awaiting\nhttps://github.com/moq/moq4/issues/256#issuecomment-215121544\n. PS Thanks for the explanation: \n\nThe IAmazonS3.GetObjectAsync has 3 overloads, the last one has a default value. That is \nthe reason in the mock everything is specified, however, in the repository code, it is omitted\n\n(I'd missed the last param being optional, meaning the setup did cover the matching signature!). Hi @udlose .  Great question.  The intention is to make this kind of information available to dashboards by raising events from policies, channelling those events into an Rx stream, and aggregating metrics from the event streams - to provide a generalised approach for all policies, and the ability to aggregate data (eg overall call latency) spanning the multiple policies of a PolicyWrap.\nToday I wrote up a first proposal/early thoughts paper to take this forward, expect to publish in next few days: please (anyone else, also) join the slack channel where we can discuss.\nA number of other Polly users (@lakario; @ankitbko ; @seanfarrow; @mfjerome; others?) are all also interested, and @lakario @ankitbko and I each have Rx prototypes floating around.\nRelated: #201; #149; #326 . Closing as now covered by #326 . @udlose I haven't full sight of your test setup, but the effect you describe is likely due to concurrency of calls through the breaker.  I'm assuming the NeoLoad script is placing sufficient load that calls are being handled in parallel on different threads. \nThe path of an individual call through the breaker has three broad phases:\n(I) Should the call be allowed to proceed? (ie reject if circuit broken)\n(II) Execute the user delegate\n(III) Update circuit metrics for the result, and return/rethrow the result\nThe nub of the 'gotcha' to get in mind is that in parallel throughput, further calls can arrive at (I) before preceding calls have exited at (III). Calls can be running in parallel through the breaker.\nSay all calls fail, we're just executing throw someException;.  Consider calls arriving in high concurrency.  For example:\n\nSay 10 calls pass stage (I).\nWhile those 10 calls are in stages (II) and (III), another 4 calls (they're arriving at a high rate) get through the gateway of stage (I), before the first 10 calls have all completed (III).\nNow the 10th call failure registers at (III) and the circuit opens.  Calls 15, 16 etc arriving at stage (I) are rejected with BrokenCircuitException.\nCalls 11, 12, 13, 14 meanwhile passed (I) earlier, so they (II) executed, and arrive at (III) as failures.  The circuit-breaker bubbles their outcome outwards (rethrows someException in this case).  \nNote: Polly can detect the circuit is now open and could throw BrokenCircuitException instead at this point.  But this was considered misleading.  The user delegate has executed, and to throw BrokenCircuitException instead would mask an outcome (success or failure) of an execution which has actually occurred - that (inappropriately masking an outcome which occurred) could be critically misleading in some scenarios.\n\nThe above scenario might easily look as if it took 14 failures to open the circuit.  In fact, the circuit opened correctly once 10 failures could be detected, but 14 executions proceeded before those 10 failures arrived (and so those 14 failures, to be faithful to the calls, have to be reported).\nDoes this sound like it describes what you are observing?  If not, please share more, and we can dig deeper.\nNote: This is not a bug.  The circuit-breaker cannot do better than this: it is a reactive policy (reacts to outcomes), and cannot act any sooner than it has received the failures and counted them.  It would be possible to eliminate this apparent discrepancy (if felt to be troubling) by limiting the parallelism of calls through AdvancedCircuitBreaker to match the minimumThroughput set for statistical significance.  We intentionally didn't do this as part of the design: that was felt to be not the role of the circuit-breaker; one might well want to vary max-parallelism and minimumThroughput-for-stats independently; controlling parallelism separately in BulkheadPolicy offers more flexibility.\nMore comments below about how BulkheadPolicy complements circuit-breakers, and addresses parallelism.\n. A few related observations:\n\n\nThis behaviour is not as uncommon as the description in the previous comment (involving racing threads) might suggest.  This can be common when calls at stage (II) are timing out.  Consider you are calling a third-party endpoint which starts failing. You have a 5-second timeout imposed on it.  Consider calls are arriving/being placed at a rate of 10/second.  You quickly have 50 calls in flight in parallel (assuming no other limitations), before you even receive your first timeout.  Parallelism can rise quite quickly, regardless of how eagerly a circuit-breaker is configured.\n\n\nThis is why BulkheadPolicy exists.  BulkheadPolicy exists to prevent resource/parallelism bulges like this, when calls back up. BulkheadPolicy is a parallelism throttle.\n\n\nThe behaviours described are (for info) common to both AdvancedCircuitBreaker and original CircuitBreaker.  \n\n\n. Hi @erickhouse, Welcome to open source!  Yes, this is a perfect first issue!\nBecause this is an issue we didn't get to in a recent Polly Hackathon, in this case there happens also to be:\n\na more detailed write-up\na branch to start from\n\nMost open source projects have a guide to contributing.  Ours is here, mostly about gitflow.  Because we made a v571onBreakDelegate feature branch for this, in this case you would probably work in a branch in your fork like erickhouse/Polly/v571onBreakDelegate, and PR when ready onto App-vNext/Polly/v571onBreakDelegate\nPlease, do reach out if you have any questions!. @erickhouse Great!  \nI can't (in the formal github sense) assign the issue to you as you are outside the App-vNext organisation (ref: https://github.com/isaacs/github/issues/100).  However, consider this issue yours, by dint of this conversation!. Thanks @erickhouse !  \nTo link an issue to another, you just quote #nn, thus: thank you for PR #398 for this issue!  You can also use 'fixes', 'closes' and similar wording, on the PR side; the issue will then be automatically closed when the PR is merged to a repo's default branch (usually master).  \nYup, any PR feedback will happen on #398 . . @dhabierre. Thank you for your interest. At the moment there is no eta for this feature (it is a major piece of work), and no alpha version.  I have a full schedule until mid August, but will aim to assess next major items for Polly then unless I get any time earlier.. @lalitkale Yes, I think this is exactly what Polly should do.  I've not had time to write up a revised proposal, but with the official deprecation of Hystrix Dashboard (and no ongoing support of Hystrix), coupled with the appearance of https://www.app-metrics.io/, Polly should abandon the Rx/Hystrix route and very likely target App-Metrics. App-Metrics looks very good: I read most of the codebase earlier in the year and see no reason why Polly metrics couldn't target it.\nThe missing piece is emitting events from Polly policies in a way that can both be funnelled to App-Metrics and can support the integrated .NET Core logging requirements of IHttpClientFactory.   My thinking is that policies should emit events (event streams) which are entirely generic, not tied to any particular event sink. Different sinks (App-Metrics; ILogger; others ...) would then be pluggable subscribers.  Deep policy event logging directly to ILogger is the missing part of the collaboration we did on Polly with the Microsoft ASP.NET teams earlier this year.. Hi @sanjaysingh .  You can use PolicyWrap to wrap a TimeoutPolicy around the WaitAndRetry(...) policy.  This similar question describes in more detail how to do this, and links to sample code in DotNetFiddle.\nNote that the synchronous WaitAndRetry(...) blocks the thread while waiting. Polly isn't a 'background job scheduler' that schedules work for a later time. Polly's WaitAndRetry() is primarily designed for retrying transient faults after a short interval.  If you are intending long waits on synchronous code paths, at least especially if you might have multiple threads doing this, you might also consider Timer-driven callbacks or (if a web app) a background-work scheduler like hangfire, so as not to block threads.  You could still use the Polly Policy within the scheduled (hangfire or similar) task  to make the shorter-interval retries (eg after 2, 4, 8 etc up to 60 (or whatever you like) seconds), then switch to scheduling a new task with a work-scheduler, for the longer pauses.  (That may or may not be relevant depending on your requirements - but in case useful.)\nIn an async/await context, Polly's WaitAndRetryAsync(...) policy waits using Task.Delay(...).  . Perfect. Glad it helped.. Hi @pavan7parekh .  I believe the video from MVP  Houssem Dellai describes how to work round this issue in Xamarin (towards the end of the video).  There is also sample code, demonstrating the approach, with the video.. Hi @pavan7parekh .  Re:\n\nIf I downgrade the version of a package to 5.0.6 then it is working fine\n\nNew features in v5.2.0, meant that from then, Polly only supports .NET Standard 1.1 and above, not .NET Standard 1.0.  .Net Standard 1.1 is not compatible with PCL259, but instead with PCL111.  The only difference, as I understand, is that Windows Phone Silverlight is excluded.  Does switching to targeting PCL111 work for your scenario?\n. @pavan7parekh Did this solve the problem for you?. Closing due to lack of further response; please do re-open though, if you need further assistance.. Hi @larsbe . This is a great question! Makes total sense in terms of Task<HttpResponseMessage> HttpClient.GetAsync(...) and Task<string> HttpResponseMessage.Content.ReadAsStringAsync() being a two-stage async process.  \nSo: it would be possible to add HandleResultAsync(...) (adding Task<bool> versions of the ResultPredicates to Polly).  The main question (last time we considered) was that it encourages moving substantive \"work\" (eg I/O work) into the handle clauses.  The question then arises: what should the policy do if the .HandleResultAsync(...) clause (now doing substantive I/O) itself throws an error?  For example, with: \n.HandleResultAsync(async response => (await response.Content.ReadAsStringAsync()).Contains(\"match\"))\n\nwhat should the policy do if a failure (disconnection/timeout) occurs during the ReadAsStringAsync()?  Does it just throw it? (/place that error on the returned Task of the ExecuteAsync()?).  Can the caller tell then whether a given error placed on the returned Task of ExecuteAsync() occurred during the main .Execute'd delegate, or during one of the .HandleResultAsync(...) clauses?  And, how would one express error handling for the .HandleResultAsync()?  It could lead to nesting policies within the .HandleResultAsync(), like:\nvar asyncGetPolicy = Policy<HttpResponseMessage>\n    .HandleResultAsync(async response => (await asyncReadPolicy.ExecuteAsync(() => response.Content.ReadAsStringAsync())).Contains(\"pattern\"))\n    .RetryAsync(retries, (exception, retryCount, context) => doSomething());\n\n(But it's hard to reason still about where/how the eventual error gets expressed, if asyncReadPolicy doesn't deliver a success result.)\nTL;DR: We liked the idea of .HandleResultAsync(...) as an appealing analogue to .HandleResult() too, but we didn't find a clear/simple enough path to express its error-handling (suggestions from anyone?).\n\nAs such, when faced with this kind of case, I've tended to take the two-stage calls of the original:\nHttpResponseMessage responseMessage = await httpClient.GetAsync(url);\nstring content = await responseMessage.Content.ReadAsStringAsync();\n\nand just express a separate policy for each stage:\n// (DI, cancellation tokens etc, omitted, to focus on structure)\n\nRetryPolicy<HttpResponseMessage> asyncGetPolicy = Policy<HttpResponseMessage>\n    .Handle<WhateverExeceptions>()\n    .HandleResult(r => r.StatusCode == /* etc */)\n    .RetryAsync(/* etc */);\nRetryPolicy<string> readStreamPolicy = Policy<String>\n    .Handle<WhateverExeceptions>()\n    .HandleResult(s => s.Contains(\"pattern\"))\n    .RetryAsync(/* etc */);\n\nstring response = await readStreamPolicy.ExecuteAsync(async () => \n{\n    HttpResponseMessage responseMessage = await asyncGetPolicy.ExecuteAsync(async () => await httpClient.GetAsync(url));\n    return await responseMessage.Content.ReadAsStringAsync(); \n});\n\nIt's longer, but it's clear what each policy will handle/retry.  To make it concise to client code, of course you can wrap it into a helper method.\nBut: Does anyone have a better/alternative pattern to share?  As you say, @larsbe, this is a common problem.\n. \nA more minor issue is we don't at mo guarantee to call the .HandleResult(...) predicates only once.  Policy engines use them to check if a result should be handled (example), and  ExecuteAndCapture/Async(...) overloads also use them in the 'capture' phase to determine after-the-execution if the result was a handled-result (example).   That multiple execution likely wouldn't play with any async I/O (including stream-reading) which people might well put in a .HandleResultAsync(...) clause.  \nWe could easily refactor to remove that multiple execution, but at the minor expense of making every execution an execute-and-capture, and then discarding the 'capture' part again for the execute-only codepaths.\n. Noting an additional angle for future ref: A .HandleResultAsync<TResult>(Func<TResult, Task<bool>>)  clause would only make sense with async policies limited to async executions.  However, we are also looking at unifying sync and async policies.  \nIf #281 goes through, .HandleResultAsync<>() clauses won't make sense on a policy which (given it could be used for both) can also be used for sync executions.  So we would need to keep all async in the .ExecuteAsync() clause, and avoid .HandleResultAsync<>(), if #281 is to go  through.\nFor this reason, I'd recommend instead the approach in my original comment: keep all the async work in ExecuteAsync() clauses.. Closing as 'wont implement' for the reasons discussed earlier in this thread.  \nAt the moment in Polly, there is a clear distinction between lightweight .Handle<>() clauses (which don't need guarding for error), and the .Execute() clauses (which do the heavy work, and which the policies guard for error).  \nAdding a .HandleResultAsync<>() would start to move heavy work, needing guarding for error, into handle clauses.  This blurs the clarity of how Polly operates, and leads to complex reasoning about what happens when an exception is thrown within the handle clause.. For anyone exploring this problem, this Stackoverflow answer explores a possible solution to a similar case.. To avoid noise on the 'up-for-grabs' labels (three similar issues), I'm closing this issue in favour of the similar #260 (and noting the idea of Leaky Bucket there). . Hi @jelical\nMy initial reaction was as @joelhulen : the Polly .NET Standard 1.1 binaries/nupkgs should be forward compatible to a .NET Core 2.0 app (I have them referenced like that locally).  However, yes, there's been a lot of pain/flux around the .NET Standard/Core tooling/dependencies, so v happy to hear if further community input on this.  Could poss add a .NET Standard 2.0 target if it made a significant difference (feedback, anyone?).  (It wouldn't be part of the immediate v5.4.0 release, as we usually keep feature/retargeting releases separate.)\n@jelical Re tests:\n\n\nCould you post details of the SystemClock change you mention?  Was initially surprised that a Net Standard 1.1 to 2.0 implementation change could break something (but would obviously like to dig in and look!). \n\n\nCan you post details of the tests which were failing for you?  Is there a public branch of your port to .NET Standard 2.0 I can look at / pull down, to compare with mine? \n\n\nSome tests - particularly testing timeouts on TimeoutPolicy and a few on WaitAndRetry - have to rely on measuring elapsed time within certain tolerances.  These can be vulnerable to timing differences in different environments (we had a run of failures in AppVeyor).  If timing-related tests are failing in your local environment, try increasing the tolerances similar to in #197, #168, #167, #212 etc.\n\n\n(Obviously, we try to keep those test tolerances as low as possible, to keep the test suite running fast, but have to raise them to make tests reliable.  And everywhere Polly tests can, they instead abstract out the system clock.) \n\n\nWould love to see details of any other test issues.  (Possible some multi-threaded tests could be vulnerable, eg, to subtle changes in underlying thread-pool behaviour.)\n\n\nThanks!\n. @jelical Thanks for the SystemClock clarifications; the comments now make more sense. The existing SystemClock implementation is fully compatible with .NET Standard 2.0, just not with parallel tests, as we are obviously already long aware.  It would have been relatively easy to fix the parallel test-running at any time; it just never obtained priority against all the forward functionality.  \nWhen we fix the test parallelism, I'm thinking we should probably do so in a way consistent for all the compilation targets if possible.  We could also probably avoid the AsyncLocal (or similar) by making the abstracted clock something like a property-injectible dependency for Policy with a sensible local default for the production side.  Separating the test threads by property-injecting a manipulable clock scoped to the policy-under-test would likely have less perf impact than introducing the AsyncLocal, which also affects production code - though we could micro-benchmark to be sure.\nThanks for digging into this area of the codebase, and thereby creating the reminder about this.\nEDIT: At #362, major improvements were made to test running so that only the smaller number of tests which manipulate the SystemClock are de-parallelized.  \n. Hi @andrecarlucci \n\nThere isn't a delegate such as onFirstTry on the retry policy (if that was perhaps along your lines of thinking?).  We could consider adding this; if so, it would be done after the major syntax refactor implied by #281.  Because of the proliferation of overloads under the existing/historic syntax, we are avoiding adding further overloads at present (already around 120 configuration overloads for retry), but #281 (planned for v6) will make new overloads more viable. Cross-ref #288 . \nWhen metrics are added (currently in progress #326), there will be an PolicyExecutionStart and DelegateExecutionStart-type events, which are intended to (optionally) include a projection of Context data.  ie In future, it may be possible to harness the metrics stream for this type of logging. \nFor now: if you have a Context object in hand before executing, could one approach be perhaps to simply to call a logging method with that Context, before calling .Execute(...) (or similar)?  EDIT: Of course, you could wrap this into an extension method, to avoid code repetition.\n\nHope this helps. Closing, as a number of suggestions have been made. On further reflection now time has passed: we are possibly unlikely to add an onFirstTry delegate to complement onRetry (even with a configuration syntax refactor that made extra delegates easier to add), as it feels like a burgeoning API surface and still wouldn't centralize the problem (still leaves two API points) for how to log something before every attempt.  The best graceful solution to this from within Polly would probably be to hook into a future DelegateExecutionStart event.\nA further option\nAnother alternative, to centralize such code right now, would be simply to write your own extension method to wrap your desired logging into every execution. Something like the below (obviously richer versions would be possible for richer overloads):\nTResult LogThenExecute<TResult>(this IPolicy<TResult> policy, Func<TResult> func)\n{\n    int attempt = 0;\n    policy.Execute(() =>\n    {\n        logger.Log(/* whatever message involving attempt number */);\n        attempt++;\n        return func();\n    }\n}\n\n. And: Thanks @andrecarlucci for the great question!  It provides useful food for thought for a case that events should support.. Very similar implementation pattern to #325 . @hopdizzle Cool!  Thank you for coming forward to pick this up!\n\ncreate new overloads to TimeoutAsync that accept the new Func definition as to not break backwards compatibility, correct?\n\nYes.  We might retire older overloads at a later date as part of a major release, but we won't break backwards compat as part of a minor release, which this'll likely go into.\n\nthe timeoutAsync func needs to be changed from Func<Context, TimeSpan, Task, Task> to something like Func<Context, TimeSpan, Task, Exception, Task> and plumbed through the various references. Is that correct?\n\nYep.  The rider to that is that we should do the sync variants (sync timeout policy) too.  So the sync implementation has mechanisms similar to the async one , likewise the sync syntax (here and elsewhere in that file).   Same patterns as async so it should make sense.\nFinally, #419 ( /cc @urig ) will be affecting the same syntax files, but there'll be a handful of overloads affected by both sets of  changes.  So whichever PR we take first, the second PR may then just have to take into account anything extra from the first PR.  We can sort that out at the time.\nMany thanks again!. Huge thanks to @dustyhoppe for implementing this!  Fixed in v610 branch by merging #429.  Leaving the issue open as reminder that @reisenberger to add relevant doco (and credit to @dustyhoppe ) to v6.1.0 release.. Thanks again @dustyhoppe for implementing this.  You have a credit in the Readme! :grin: Fixed in v6.1.0 which will release to nuget shortly. Hey @udlose.  TL;DR You happen to have hit upon an async test delegate which isn't truly async. The pessimistic async timeout policy, by design, chose not to handle sync-not-async delegates in the async timeout policy, because to do so would have meant a performance penalty for the majority async case.\n\nExplanation: why does the posted test code not work?\nThe Polly async TimeoutPolicy with TimeoutStrategy.Pessimistic intentionally isn't catering for the edge case of async delegates which are not 'truly async', but are in fact actually synchronous.  \nBy 'truly async' I mean: conform to the async method pattern of returning to the caller a Task instance which represents the on-going asynchronous execution of the method.  The pessimistic async timeout implementation relies on that normative pattern: it needs to obtain this Task, in order to run a timing task in parallel, and see which completes first.  \nReturning that Task - the one which represents the on-going asynchronous execution of the method - happens automatically when an async method hits its first internal await statement.  Until it hits its first internal await, however, every await-ed method or delegate in fact runs synchronously on the calling thread.  It happens that this test delegate: \n// [1]\nct => {\n    Task.Delay(4000).Wait();  //shouldn't this cause a TimeoutRejectedException???\n    return Task.FromResult(\"hello\");\n}\n\ncontains no await statement, and so runs purely synchronously, right through to return.  It doesn't return any Task until it has already completed (including the four-second delay).  So the calling timeout policy never regains control until the test delegate has completed (including the four-second delay).  So the calling timeout policy can never time it out.\nChange the delegate to the following, and it will work:\n// [2]\nasync ct => {\n    await Task.Delay(4000);\n    return \"hello\";\n}\n\nIn this version, as soon as await Task.Delay(4000) is hit, a Task is returned to the calling policy representing the on-going asynchronous execution of the delegate.  The timeout policy implementation then resumes control, and can determine if the executed delegate or timing task completes first; and can time out on (walk away from waiting for) the test delegate, when the timeout elapses. \n. #### Follow-up discussion: Should Polly handle the case [1]?\nCould Polly async TimeoutPolicy with TimeoutStrategy.Pessimistic be coded to handle the purely-synchronous delegate case [1]  above?  And if so, should it?\nIt could: it could adopt exactly the same strategy as sync pessimistic timeout policy, of spinning off the executed delegate as a separate Task with Task.Run(). \nShould Polly do this?  At design time, I elected not.  For the vast majority of async cases, well-conforming to the async method pattern, that Task.Run() would represent a performance hit, an extra allocation and context/scheduling switch which are completely unnecessary to the vast majority, well-formed async case.  Handling the non-conforming edge case at the expense of majority performance was declined.\nCould this burn Polly users in production scenarios?  It could, but only if they are faced with executing these 'faux'-asynchronous (in fact purely-synchronous) delegates through async, pessimistic TimeoutPolicy.  \nThe main scenario I have envisaged where this might occur could be if some third-party component implements faux async-over-sync wrappers for long-running delegates, eg FooAsync() => Task.FromResult(Foo()) for some long-running Foo(). A Polly user might expect asynchronous pessimistic timeout policy to work on these, when it won't.  However, it is well documented that such wrappers are bad practice.  And, Polly users in any case have the workround of recourse to the synchronous pessimistic TimeoutPolicy for these cases.  \n\nI've followed this up at blog-post length because I appreciate this behaviour (async pessimistic timeout not handling these) could cause confusion, given the stated 'walk away from anything' power of pessimistic timeout.\nI'd be interested if community members can think of any real-world async delegate cases, for which this design decision might cause difficulty.\nEDIT: Updated the TimeoutPolicy wiki to document this.. When TimeoutPolicy in either optimistic or pessimistic mode times out on an executed delegate, a TimeoutRejectedException is thrown.  That exception can be caught either by the user code that executed through TimeoutPolicy, or by another Polly policy - for example, a RetryPolicy, or a FallbackPolicy handling TimeoutRejectedException, placed further out in the PolicyWrap.\nDoes this cover the sense of 'catch' the timeout in your question?. @udlose Let us know (after Thanksgiving!) if we can help any further on this.  Re your question:\n\nhow does the calling code \"catch\" the timeout? [in TimeoutStrategy.Optimistic]\n\n... there could be two senses.  \n(1) Per previous comment, a TimeoutRejectedException is thrown back onto the code placing the call through TimeoutPolicy.\n(2) If the question is what happened to the task being executed (which was timed out...) : in TimeoutStrategy.Optimistic, that task should honour the CancellationToken and thus cancel itself (it won't continue running).  If it wants to pass information back to the calling code about its state at the time of cancellation, that could be done by throwing a custom OperationCanceledException containing extra information.  That exception is already passed back to calling code as the inner exception of the TimeoutRejectedException.  If we extend Polly per #338, that exception would also be passed to onTimeout/Async, which might be a better place eg to capture info for logging.. Good morning @TDabasinskas .  Could you post also the code where you place the call through the PolicyWrap?  If you are able to combine all into a Minimal, Complete, and Verifiable example (even if just with a stub response method), that will also speed investigation.\nFor an immediate suggestion: test also with declaring the cache and retry policies as strongly-typed to HttpResponseMessage.  IE var cachePolicy = Policy.CacheAsync<HttpResponseMessage>(...); var retryPolicy = Policy<HttpResponseMessage>.Handle<HttpRequestException>(...)\nAssuming that works, this may be an issue specific to non-generic CachePolicy mid non-generic PolicyWrap.\nThanks\n. @TDabasinskas I can reproduce the issue.  I confirm it is limited to non-generic CachePolicy within a non-generic PolicyWrap.\nI can confirm that if you define your policies as generic policies, as mentioned in the preceding comment, all functions fine.\nI have identified a fix for non-generic CachePolicy within non-generic PolicyWrap used with the generic method overloads .Execute/Async<TResult>(...). This should follow in the next few days.. @TDabasinskas This is fixed in v5.5.0, due to be released to nuget shortly.. @naymore .  For async use in Polly as now, you should configure policies with the async overloads (eg .FallbackAsync(...), .WrapAsync(...), .WaitAndRetryAsync(...).  There's more on this and our async support in the doco in the readme and wiki.  \nWe're considering also unifying sync and async, so that one policy would serve for both, from v6 onwards.  Comments very welcome on that proposal!. Delivered via #362 . Awesome!  Thank you for all your contribution!  Will merge this after my working day is finished.. Thanks again for everything on this @matst80 !  Merging to dev branch!. :+1: LGTM!  Takes another minute off the build time, in our local tests.  Yay!. Awesome @jbergens .  Thanks for this!  Closes #359. @jbergens  Would you be able to retarget this PR against the v560dev branch if you have a moment?  (Should be possible to change on the existing PR.) Thanks!  . @MartinSStewart Thanks for the doco for this feature from the Hackathon.  Merging to the dev branch!. Merging into v560dev branch.. @romanb52 \nTo combine policies, see PolicyWrap.\nTo run code after each failure, use the overloads of WaitAndRetry(...) where you can configure an onRetry: delegate - see readme\nHere's an example I wrote a while back in dotnetfiddle.. Closing. If you need further assistance, though, do open another issue - or post a query on our slack channel. Hi @galmok .  My initial impression is that BulkheadPolicy (in its current form) is probably not a fit for this.  From the problem description it sounds as if what you need is parallelization limiting with blocking/backpressure on excess load.  BulkheadPolicy (in its current form) offers parallelization limiting with load-shedding on excess load.\nI'll try to set down some further thoughts in the next 24-48 hours.. @AndrewInScotland Which version of Polly are you using?  . Thanks @AndrewInScotland .  \nThis is expected.  To find the outcome of an .ExecuteAndCapture<TResult>(Func<TResult>) which fails all retries, you need to inspect the wider properties on the returned PolicyResult<TResult>.  \n\nThe FinalHandledResult property should contain the TestService.ServiceResult.Failure you expect.  \nThe documentation just linked covers how the properties on PolicyResult<TResult> behave.\nThis unit test documents by example.\n\nTo explain why this behaviour is expected:  \nIf your .ExecuteAndCapture<TResult>(Func<TResult>) had failed with an exception: \n\nwe would certainly expect there to be no valid Result\nwe document the final exception that was thrown in a separate property FinalException, with other supporting properties also defining the outcome\n\nBy analogy, when .ExecuteAndCapture<TResult>(Func<TResult>) fails with a handled result, we:\n\nlikewise leave the Result property equal default(TResult), to indicate no valid result was obtained\ndocument the final fault in a separate property FinalHandledResult with other supporting properties also defining the outcome\n\nThis consistency of approach in PolicyResult<TResult> was necessary particularly to support users defining policies handling both exceptions and results in the same policy - executions through these policies could fail with either an exception or a handled fault, and it made most sense for the PolicyResult.Result property to behave consistently across these cases.\n(EDIT: I think this captures the problem you were outlining, but if I've misunderstood, please do provide further clarification.). :+1: Closing. Please do open another issue though if we can help with anything else.. Thank you for this @awarrenlove .  Will aim to review in the course of this week (hopefully the nearer end).  . @awarrenlove  Thanks again for this PR.  This looks like a useful addition to the cache ttl functionality; I'm hopeful we can include this in the next release, Polly v5.7.0\nA challenge will be deciding how many/which overloads to provide.  There'll be some (merge) conflict too with some upcoming CachePolicy configuration syntax extensions. Likely I'll merge yours first, and I can sort all that out.\nPR looks pretty clean on a first read (thanks), more detail as soon as I can deep read.\nThanks again.. Thanks again @awarrenlove , finished a deep-read.\nSo the substantive change needed is that rippling out same to async cache: let me know if you are good to take that on.  \nPlease could you retarget the PR onto this v570dev branch after that?  Then I can merge and pick up the overloads.\nAll else - the changes to existing strategies - looks good.  Thanks!. Thanks @awarrenlove !  Looking good and consistent on a quick read.\nAiming to push this out to nuget (with other cache changes) either last few days Dec or first week Jan.. Thanks @awarrenlove !  Merging to the dev branch.  \nI will need to do some work on the CachePolicy configuration overloads before we merge to master; will keep you informed.. @awarrenlove Thank you again for your contribution!\nNow merged to master, due to release to Nuget soon as part of Polly v5.7.0\nCredit added in readme :+1:. Hi @TDabasinskas .  It looks like I made a mistake in the ContextualTtl documentation: apologies for this.  The released Polly package is good, the documentation just doesn't match it.  Thank you for raising the issue.\nWhere the documentation on the wiki used to read: \ncontext[ContextualTtl.TimeSpanKey] = new Ttl(TimeSpan.FromMinutes(5), slidingExpiration: true);\n\nit should have read:\ncontext[ContextualTtl.TimeSpanKey] = TimeSpan.FromMinutes(5);\ncontext[ContextualTtl.SlidingExpirationKey] = true; // if desired; if not set, false is assumed\n\nSo, your posted code should work if changed as follows:\n.ExecuteAsync(async context => await _peopleApi.GetPerson(username), new Context($\"UserProfile-{username}\",\n    new Dictionary<string, object>{{ContextualTtl.TimeSpanKey, TimeSpan.FromSeconds(3600)}}));\n\nCould you let me know if this resolves the issue for you?\n(The wiki documentation has now been updated.)\n. Thanks @TDabasinskas for the fast confirmation!. Hi @zirain . There is no built-in way to do this.  \nYou can achieve this by maintaining your own try count, closing over a variable you increment yourself:\nint attempts = 0;\nvar result = policy.Execute(() => { \n   attempts++;\n   //  ... \n} );\nPolly does not have this built in due to the fully flexible functional-composition nature of PolicyWrap.  Each layer of a PolicyWrap is agnostic to whether it is executing the final user delegate or another layer of PolicyWrap.  Equally, some users intentionally have more than one Retry policy in a PolicyWrap - to treat different kinds of exception with different retry strategies.  A price of this flexibility is that it is non-trivial to define what 'number of tries' means in the context of a PolicyWrap.\nEDIT: Cross-ref: #73 . Polly has now been migrated to the new DotNetFoundation CLA bot, and the old bot retired.. Hi @joshidp   . See Keys and context data in the wiki, and the How specified? entry for each key.  So:\n.WaitAndRetryAsync( ... ).WithPolicyKey(\"MyPolicyName\");\n. And there are more code examples in the readme here. Hi @thurfir  You are correct; the (necessary) fix #372 for #294 is related.  \nI can see options for supporting the logging scenario from the next release: proposals/suggestions will follow. @thurfir My suggestion is going to be that a LoggingPolicy is implemented as a custom policy.  #391, when released as part of Polly v5.7.0, will make custom policies possible.  I will intend that the documentation for custom policies uses LoggingPolicy as an example.. triage of recent issues: Another interim suggestion for logging the final exception/failure would be to use .ExecuteAndCapture/Async(...) overloads, and log when the PolicyResult.Outcome indicates the final result was a failure.  Obviously this is not as concise as a native LoggingPolicy would be - though it could be made concise by wrapping in a method.  Just adding other options to this thread.\nI have not yet provided the promised LoggingPolicy example of a custom policy, as we are now working on Polly v6.0, where implementation for custom policies should be yet simpler than in v5.7+. Closing, as we have proposed a number of possible solutions here.  \nTo recap: the original issue was that we closed down the possibility of using a non-generic FallbackPolicy with generic .Execute<TResult>() methods, because the compiler gotcha (which Polly can't change) of silently assigning a Func<TResult> to an Action meant that the combination of non-generic FallbackPolicy with generic .Execute<TResult>() could lead to apparently silently dropped TResult values (see #294).  However, closing down those overloads (#372) presented a problem for users like @thurfir using the non-generic FallbackPolicy as a generic exception-logging policy.\nA further option\nFallbackPolicy now requires a generic FallbackPolicy<TResult> for all TResult-returning executions.  One could however continue to use FallbackPolicy as a logging-only policy by making a simple factory class to manufacture FallbackPolicy<TResult> dumb-logging policies as needed:  [clarity: by dumb I mean dumb in the technical sense of not doing much, not a judgment!]\nstatic class LoggingPolicyFactory\n{\n    static Policy<TResult> GetLoggingPolicyFor<TResult>() // Of course extra parameters could be used to refine the faults/exceptions handled\n    {\n        return Policy<TResult>.Handle<Exception>() // Of course extra parameters could be used to refine the faults/exceptions handled\n            .Fallback(\n                fallbackAction: (outcome, context, token) => default(TResult), // We never cared about this when we were using non-generic `FallbackPolicy` just for logging, so this should do.\n                onFallback: (outcome, context) => { Log(outcome?.Exception?.ToString());} // Of course a logger could be injected.\n                );\n    }\n\n    static void Log(string message) // Of course a logger could be injected rather than a hard method here; just for simplicity of this example.\n    {\n\n    }\n}\n\n. >Is it safe to rethrow the exception from onFallback, after logging of course?\nThrowing an exception from within either onFallback or fallbackAction will cause that exception to propagate further outwards; the FallbackPolicy will not swallow or govern it in any way. (Policies govern the delegate passed to Execute(...), or all actions of a policy deeper inside a PolicyWrap. Policies do not guard their own actions (fallbackAction; onFallback; onRetry etc); that could lead to all manner of recursion.)\n\nwouldn't .Fallback with an Action prevent the Exception from actually bubbling?\n\nFallbackPolicy catches the exceptions it is configured to handle and passes control to the configured fallbackAction after calling onFallback. FallbackPolicy does not rethrow the exception it handled. If fallbackAction or onFallback rethrow it will bubble; if they do not, it will not.. Yes, async executions currently require using async variants of the policies.\nClosing.  Do however open another issue or re-open, if you need further support.. @joshidp Polly provides a PolicyRegistry (see readme; wiki).  \nA common pattern using Polly with IoC is to configure policies and place them in the PolicyRegistry on startup, and then register the PolicyRegistry on the IoC container.  At point of use, retrieve the PolicyRegistry isntance by DI/IoC and extract the policy you need from it.\nYou can use Polly's out-of-box PolicyRegistry, or fulfil the IPolicyRegistry<TKey> interface to design more complex registries if needed.\n. @joshidp \nPolicyRegistry has Dictionary<string, Policy>-like semantics, so is only intended for storing an individual configured Policy instance under each key, not Policy[].\nIf you need a DI mechanism for an array Policy[] policies, you will have to roll your own or see if Policy[] plays nicely as a type that can be registered on Unity's IoC container, out-of-box.\nIf however the overall goal is just to obtain a PolicyWrap at the call site by DI, you could perhaps refactor to configure the PolicyWrap from the Policy[] policies at startup.  Then:\n\nIf you're only using one such PolicyWrap across the app/scope of the DI container, register the single PolicyWrap on the DI container and pass that single PolicyWrap to the call site by DI\nIf using multiple such PolicyWraps across the app:\nPut each in the PolicyRegistry under a different key, and pass the PolicyRegistry  to the call site by DI.  ( A PolicyWrap is just another kind of Policy, so you can put PolicyWraps in the PolicyRegistry.)  \nOr use the Unity DI container's ability to distinguish multiple registrations of the same type, by name.\n\nRe:\n\nHow do I use IReadOnlyPolicyRegistry registry inside my class, it's not shown in your example\n\nThis is covered just below under the heading Use policies from the registry.. Closing ('how do I?' issue without recent response).  However, please do re-open - or start another issue - if you require further assistance.. Hi @joshidp . PolicyWrap is designed always to contain two (or by nesting, more) policies.\nIf you want sometimes to apply only a single policy, sometimes multiple policies, based on a supplied Policy[] policies, you could use a helper method:\npublic Policy WrapOrSingleAsync(Policy[] policies)\n{\n    switch(policies.Length)\n    {\n         case 0: \n            throw new ArgumentException(/* some error message that no policies were supplied */);\n         case 1: \n            return policies[0];\n         default: \n            return Policy.WrapAsync(policies);\n    }\n}\nThe subsequent code to execute delegates using the returned Policy will be identical regardless of whether the returned value is a single policy or wrap, since PolicyWrap is just another kind of Policy.\n\nThe constraint that a PolicyWrap always contains >=2 policies reduces run-time checks on PolicyWrap, but does require a workround such as above in the case you want a 'wrap containing only one Policy'.\nThere would be trade-offs to changing this, but I'll revisit the possibilities as part of a future release.. Closing (a 'how to' question that has not received recent comment).  Please re-open if further support is required.. @duydle Are you able to create a Minimal, Complete, and Verifiable example?  Even if only as a runnable ConsoleApp, rather than something hosted in IIS?  This would greatly help anyone wanting to assist.  This article is a good guide how, and why it helps all sides get to a solution faster.  Sometimes even just the process of constructing the Minimal, Complete, Verifiable example helps zero in on where the problem is.  \nFrom the raw post, nothing is immediately obvious, but that's obviously from a raw read without being able to run the code.\n(Community comment welcome, if anyone can see something)\nEDIT: Or as @udlose says, even more info about the exception - eg a full stack trace - would be useful.. If an MVCE is hard to produce, the next best suggestion would obviously be the standard debugging technique: eliminate aspects one-by-one, and see if the problem still reproduces.\n\nKeep all the wrappers the same but execute a hand-built function deliberately throwing an exception rather than calling Dapper at all? -> If no longer recurs, something in Dapper is the problem.\nKeep all the wrapper signatures the same but hand-build a retry function (with for or while loop)? -> If still occurs, problem is not with Polly, but with something around the DynamicInvoke and signatures, etc\n\n[etc]. No part of Polly manages its own sockets or connections.  If a SocketException is being thrown or a connection is failing, that must be by the code you are executing through the policy.  \nIf you had configured the circuit-breaker to handle that exception but were not expecting it therefore to be thrown: A circuit-breaker does not absorb exceptions.  It is a measuring-and-breaking device only.  It measures the rate of exceptions thrown by calls placed through it - to determine whether to break the circuit to protect future calls - but rethrows all exceptions.  If you wish faults to be retried, you need to combine a circuit-breaker with a retry policy using PolicyWrap.  Examples: Polly-Samples demo 6 onwards; live dotnetfiddle sample; diagrammatic explanation in the PolicyWrap wiki\nLet us know if there is anything else we can help with.. Closed via #406 . Thanks @erickhouse ! I should get to review this on Friday or Sunday afternoon.\nThis will (when merged) close #325.  . Awesome, @erickhouse ! That's a perfect PR! :ok_hand:  :100:  \nCould you retarget the base branch of the PR onto App-vNext::v571onBreakDelegate?  Then I'll merge.  We're moving toward a process where we don't merge to master until everything for that release is ready. (I'll merge App-vNext::v571onBreakDelegate to master later.)\n(If you fancy digging further into Polly :grin:, #338 is a very similar pattern (add new input parameter to a policy event delegate), but no starting branch or pointers to similar tests on that one ...)\n. Perfect.  Merging to v571 dev branch!  \nfyi, I'll merge with \"squash and merge\": this means you'll see your three commits merged into one, in the base branch.  Sometimes, project owners will squash-while-merging (or ask you as a contributor to squash commits before merging).  If later commits are just minor tidies (as in this case), representing it all as one commit in the base branch is neater.  If individual commits represent substantive and different work, owners might tend to not squash while merging - keeps the original commits separate.  . Hi @ciarancolgan \nFunc<..., Task> is the standard return type for an async delegate that returns nothing.  The delegate signature must return Task in order that that Task can be awaited by the await statement.  \nYou don't however have to explicitly return a Task instance if your delegate is delcared async: when you code async (...) => { /* some async work returning no value */ }, the compiler transforms this to a Func<..., Task> for you.   \nSee Stephen Cleary's article on sync and async delegate types - particularly the table in that article - for a full set of examples.\nIf the async delegate was returning something, say an instance of TResult, the delegate's type would be Func<..., Task<TResult>> . No problem!  For backwards compatibility reasons, btw, for retry policies, there are also overloads with the onSomePolicyEvent delegates available in sync form on the async policies.  For instance, the overload with the synchronous analogue of the delegate you quoted (with onRetry rather than onRetryAsync) is here.  So if you prefer/only need the sync delegate, that's an option.. @subatta I understand the concern as being that if WaitAndRetry policies are used at all points in a chain of synchronous calls, the waits could compound over the chain in a failing scenario, leading to an inappropriately long wait before reporting overall failure, at the outermost, original caller.  \nI can make two suggestions:\n(1) Only use wait-and-retry policies at the outermost caller in any chain.  Disadvantages may be that you may not have control over all callers; or you may not want to embed the knowledge of retry strategies into those callers.\n(2) Tag the failure response returned by any layer with an annotation of which layer is failing (perhaps using a custom HTTP header).  Then, use the ability of Polly policies to filter on any property of the response so that the wait-and-retry policy at each layer only handles faults originating from the layer immediately below.\nThis annotation approach also allows the use of circuit-breakers at each level, reflecting only (and thus allowing monitoring of) the health of the layer immediately below.  All of course at the cost of some extra complexity.\nMinimizing chains of synchronous calls, where possible, is obviously also good practice.\n. Hi @SeanFarrow  . The following code compiles and runs, so I think that the async interfaces on NoOpPolicy are already available:\n        IAsyncPolicy noOp = Policy.NoOpAsync();\n        await noOp.ExecuteAsync(async () => { });\n\n        IAsyncPolicy<String> noOpGeneric = Policy.NoOpAsync<string>();\n        await noOpGeneric.ExecuteAsync(async () => { return String.Empty; });\n\nWhen you are wanting to use the async variant of NoOpPolicy, are you declaring it as Policy.NoOpAsync()?. @benagain  Awesome, thanks for the fast PR! LGTM!\nCould you retarget the base branch of the PR onto App-vNext::v571onBreakDelegate?  Then I'll merge.  We're moving toward a process where we don't merge to master until everything for that release is ready.  Since this is a bug fix, I'll then merge that branch to master and push out asap.\nThanks!\nNote to self: semver-wise, we should push this out as v5.8.0 due to the other feature in that branch being new functionality . @benagain  Yes, if you could rebase as well, that would be great. (Thanks for the retargeting.)\nThanks!. @hajirazin  Thank you for this small but important contribution.  Looks good to me!  Merging.. @apobekiaris Since that blog post, we have hopefully made this easier.  From #367, new overloads exist for WaitAndRetry and WaitAndRetryForever policies which can take the handled-error or handled-returned-result as an input parameter to the sleepDurationProvider delegate.  \nHave a look at the unit tests on the TResult handling policies, in the files changed in that PR; these demonstrate examples.  \nIf an endpoint returns a HTTP 429 x-ms-retry-after-ms header, your policy can detect that in the outcome.Result property passed to the sleepDurationProvider delegate (or exception passed as outcome.Exception, if an exception is thrown to represent this), and make sleepDurationProvider return a wait duration based on the passed x-ms-retry-after-ms header.  Of course, you have to configure the policy in the .Handle<>() clauses, to handle such results.\nWith this approach, there is no need to use the execution Context, as was described in the earlier blog post.. Hi @apobekiaris . Thanks for spotting and pointing out that that blog post was out of date.  I've updated the blog post to point to the new approach for handling RetryAfter within Polly.\nHaving spotted that we have a section on this on the retry wiki page, I'm going to close this issue.  However, do come back to us if you need any further assistance!  \nEDITED: to update links. Hi @janzakrzewskipl .  There isn't currently a way for a single Polly policy natively to handle multiple disjoint TResult types.  Policy<TResult> instances are strongly-typed to a single TResult in order to provide that compile-time binding between .Handle<TResult>, .Execute<TResult> and multiple TResult policies in a PolicyWrap<TResult>.\nOptions now:\n\nDefine a Policy<object> and cast, as you say. \nUse a non-generic Policy, and wrap the calls so that they throw exceptions for the unhealthy states.  (Just a different kind of compromise.)\nIf you have control over StateA, StateB etc (ie if it's your code), you might be able to:\nhave StateA, StateB etc extend or fulfil some common base class or interface, and have that base class or interface signal unhealthy state, allowing you to use a common Policy<TInterface> or Policy<TBaseClass>.\n(or) wrap the outcomes in a wrapper class Outcome<TResult> : Outcome, with Outcome signalling healthy/unhealthy, and have the circuit-breaker policy handle Outcome.\n\n\nFrom Polly v6 something more native might be possible.  For Polly v6 I have sketched the ability for users to define custom circuit-breakers, passing in their own circuit controllers.  The existing circuit-controllers would also be available with public constructors.  This could allow you to set up two strongly-typed policies which share the same controller and state:\ncsharp\nConsecutiveCountCircuitController sharedController = new ConsecutiveCountCircuitController(/* your configuration */);\nPolicy<StateA> policyA = Policy.HandleResult<StateA>(StateA.Bad).CustomCircuitBreaker(sharedController);\nPolicy<StateB> policyB = Policy.HandleResult<StateB>(StateB.Unhealthy).CustomCircuitBreaker(sharedController);\nHope this helps.\n. Hi @nmurf!  You can already do this with current Polly. You can use a wait-and-retry overload taking the returned response as input to the sleepDurationProvider delegate.  Something like:\ncsharp\nIAsyncPolicy<HttpResponseMessage> retryHonouringRetryAfter =\n    Policy.Handle<HttpRequestException>\n        .OrResult<HttpResponseMessage>(r => /* clauses for other status codes you want to handle */\n            || r.StatusCode == (HttpStatusCode)429) // RetryAfter\n        .WaitAndRetryAsync(\n            retryCount: 3, \n            sleepDurationProvider: (retryCount, response, context) => {\n                // taking the pseudocode from the question\n                var serverWaitDuration = getServerWaitDuration(response.Result?.Headers.Get(\"Retry-After\")); // explaining response.Result? : The response is a Polly type DelegateResult<HttpResponseMessage>. Use null defence, as response.Result will be null if the cause for retry was an exception (in which case there was on result).\n                var waitDuration = Math.Max(clientWaitDuration.TotalMilliseconds, serverWaitDuration.TotalMilliseconds);\n                return TimeSpan.FromMilliseconds(waitDuration); \n            },\n            onRetryAsync: async (response, timespan, retryCount, context) => { \n                /* perhaps some logging, eg the retry count, the timespan delaying for */ \n            }\n        );\nThis is pseudo-code (for speed of response) : you may have to vary some details. For example, Azure Cosmos DB client SDK will wrap this response up in an Exception with a RetryAfter property after making its own retries first.  We'd love to see your final version!\nThis is documented in the Polly wiki here but I'll aim to reference that also from the main Polly readme, to make it more discoverable.   More info also in this similar question.\nLet us know how you get on!. Thanks @nmurf for sharing this!  \nOne thought: enumerating DecorrelatedJitter(...) with .ToArray() will cause the randomisation of delay times (the jitter) to be executed only once and stored in the array. All executions through the policy would then get that same jitter sequence (so jitter across executions would be 'correlated' across concurrent calls rather than 'decorrelated', if you like).  \nI see the challenge though created by the fact that responding to RetryAfter naturally requires the sleepDurationProvider: Func<..., TimeSpan> overload, while jitter naturally requires a sleepDurations: IEnumerable<TimeSpan>.  \nOne approach to solve this could be to split the original policy into two retry policies, and then combine both retry policies in a PolicyWrap.  For example:\n```csharp\n_retryAfterPolicy = Policy\n    .HandleResult(r => r?.Headers?.RetryAfter != null) // EDIT: .Net Framework only: https://msdn.microsoft.com/en-us/library/system.net.http.headers.httpresponseheaders.aspx;  not yet in this form in .NET Core?\n    .WaitAndRetryAsync(\n        retryCount: numRetries,\n        sleepDurationProvider: (retryCount, response, context) => getServerWaitDuration(response)\n        );\n_generalRetryPolicy = Policy.Handle()\n    .OrResult(filter) // omit the RetryAfter case now from 'filter'!\n    .WaitAndRetryAsync(sleepDurations: DecorrelatedJitter(numRetries, firstWaitDuration.Value, maxWaitDuration.Value));\n_policy = _generalRetryPolicy.WrapAsync(_retryAfterPolicy);\n```\n_policy will then handle retry-after cases (when they occur) with the exact retry-after duration returned by the server, and other retry cases with the jitter - with that jitter being decorrelated between every execution through the policy.\nA minor edge-case with the two retry policies nested in a PolicyWrap is that specific sequences of responses from the server (mixing retry-after and other) could cause more than numRetries tries to be made overall. From a real-world perspective and for small values of numRetries this is probably unlikely and insignificant enough to not wring hands over, but it's worth pointing out for completeness.\nIf anyone can suggest further refinements, please do add them to this thread!. @nmurf  Yes, I figured yesterday that the two policies could be joined back together by sharing state through Context. Thanks for sharing your approach!. @ikabar Use PolicyWrap (see that wiki about it), and wrap a TimeoutPolicy (for X minutes) outside of the retry-after retry policy.  This is what PolicyWrap is designed for: combining policies.. Merging this as it's only a readme change. The build failure is unrelated, due to cake.core breaking changes against cake plugins - tracking separately as #416. Fixes #416 . Hi @danation.  The Policy.Timeout(...) configuration overloads will currently throw ArgumentOutOfRangeException on constant values <= TimeSpan.Zero, but you can use the Func<TimeSpan> timeoutProvider to return these values.  My reading of CancellationTokenSource.CancelAfter() and Timer source code is that it will behave as you desire.  \n\nWe'd accept a PR to change the guard clauses in TimeoutSyntax and similarly TimeoutSyntaxAsync, to formalise allowing Timeout.InfiniteTimeSpan.  Thanks for raising this!\n. @urig Cool!  Thank you for offering to pick this up! \nThe const that Microsoft define as Timeout.InfiniteTimeSpan isn't (you'll see from the link) the same as TimeSpan.Zero.  Though the first post here suggested TimeSpan.Zero to represent infinite, I think we should stick to what Microsoft use.\nIdeally we would change Polly's guard clauses to permit two new cases: \n\nTimeout.InfiniteTimeSpan \nTimeSpan.Zero (which we would expect to time out any operation more-or-less immediately).  \n\nRe testing:\nTimeout.InfiniteTimeSpan: I agree with your comment \"fixing the guard clauses and related unit tests would suffice\" (we only go as far as testing that configuring Timeout.InfiniteTimeSpan is possible).  It's hard and too time-consuming :grin: to have a unit test that tests an infinitely-long operation never times out, right?\nTimeSpan.Zero: We should test it is possible to configure.   It would be good also to add a unit test that, when configured with TimeSpan.Zero, it does time out a fairly short operation.  There are very similar unit tests already in the test classes, in the sections #region Timeout operation - pessimistic and #region Timeout operation - optimistic .\nDo you think this is a good plan?  Do you want to take on both cases or only one?  \nThanks again for coming forward for this!. @urig Sounds good to me!  \nI reflected again on TimeSpan.Zero overnight, and was like: what would be the point in configuring a TimeoutPolicy with TimeSpan.Zero?  My reasoning yesterday had been that conceptually, somebody might have a dynamically calculating timespan which happened to calculate at zero (eg perhaps other actions elsewhere dictate we can no longer afford to wait for the action we're about to execute), so we should allow zero.  But if they have a calculated timespan, they should/would likely be using the creation overloads of TimeoutPolicy which take a Func<TimeSpan>, not the creation overloads which take a const/fixed timespan.  What would be the point of configuring and using a TimeoutPolicy with a fixed TimeSpan.Zero?  On reflection think we can forget the TimeSpan.Zero case - at least until someone can demonstrate a good reason for it :grin:  \n. @urig Sure! :+1:. Closed via #424 . @urig @Danation  This feature has now been released as part of Polly v5.9.0!\nBig thanks to @urig for the contribution! :100:   Credit has been added to you, @urig, in the acknowledgements in the readme :+1: . Thanks for clarifying @LeafDuan . Splitting Polly into smaller packages would be a reasonably significant change to consuming the project for our existing large user base, so we probably would want to see wider community demand for this - or more evidence of any problems the current packaging is causing - before changing anything.  Is the 300kb size of the current Polly.dll causing memory pressure in any environment?\nOn the downside, it adds some burden to managing the project; and for those consuming Polly who use more than one Policy type.  \nAlso, if we followed strict semver for the split-out packages, we could quickly get into a position where the group of packages (Polly.Retry, Polly.CircuitBreaker, Polly.Bulkhead, Polly.Core, Polly.Timeout etc) designed to work together all had very different rev numbers, which could be confusing. (Or we have to not follow semver and publish updates of package where there is no actual change....). None of these problems is insurmountable, but the advantages of any change would have to outweigh the disadvantages.\nOne of the beauties of OSS of course is that you can, as you say, make your own fork and split out Retry for yourself!\nWelcome further community feedback if others have input to this.. Hi @infofromca  Is your need to re-use a single Context instance/some parameter info across the multiple retries which a retry policy orchestrates for you?  Or across multiple calls into a policy?  \nIf you can provide a brief code sketch of what you are looking to achieve, we can probably help in more detail.. Context is fully re-usable to keep the modified state across retries of a single call through .Execute() or .ExecuteAsync() on a retry policy.\n(It is not intended for re-use across multiple calls through .Execute() or .ExecuteAsync().)\nRe:\n\nI need to get info(data) from exception\n\nThe onRetry/onRetryAsync policy hooks allow you to do this.\n. @infofromca  Thanks for raising this.  I've clarified the intellisense, in #423 .\nIf you want more examples of the technique, we have a blog post on this.  There's another nice example also in this recent discussion.. Thank you @urig , this is looking great!\nHmm. From the build error, it looks like .NET4.0 does not publicly expose the constant System.Threading.Timeout.InfiniteTimeSpan (altho my understanding is it behaves the same).  So we may need to define our own constant:\ninternal static readonly TimeSpan InfiniteTimeSpan = System.Threading.Timeout.InfiniteTimeSpan;\n\nand then use #if directive forking to just define it manually for .NET4.0.  Probably pull that into a TimeoutSyntaxBase base class (thoughts?) along with the ValidateTimeoutIsInRange(...) method, as they'll be used across several syntax classes? (see below).  \nLet's also catch the:\n/// <exception cref=\"System.ArgumentOutOfRangeException\">\n\nintellisense for the methods you're updating, update them to the nice new message from  ValidateTimeoutIsInRange(...)!\nI reckon that would be good to go then across the other syntax classes.  There's a very similar TimeoutTResultSyntax.cs class for the generic (Policy<TResult>), synchronous versions of TimeoutPolicy.  And then a similar pair (TimeoutSyntaxAsync.cs, TimeoutTResultSyntaxAsync.cs) for the async variants.\nThank you again for your contribution!. Thanks @urig . Merging! Will add credit and v5.9.0 doco for this later.. Polly v5.9.0 has now been published.  It deprecates the overloads scheduled for removal (example).\nPolly v6.0 will removed the deprecated overloads entirely.. Documentation published to wiki. Polly v5.9.0 has now been published.  It:\n\nuses the new names for the execution keys mentioned in this issue \ndeprecates the old names with [Obsolete(\"with explanation here\")] attributes\n\nPolly v6.0 will removed the deprecated names.. Documentation published to wiki. Also covered on the main wiki keys page.. Closed via #447.  Documentation of the last version to support .NET 4.0 is in the main Polly Readme.. Hey @dustyhoppe , many thanks for this PR!  I'm pushing this out to Polly v5.10.0 as we need to close v5.9.0 early this week as part of code freeze towards next preview release of Polly with HttpClientFactory for ASP.NET Core 2.1.\n(Know we've had a similar conversation in slack - just noting here for anyone seeing the PR!)\nThanks for your patience! :+1: (we are normally quicker! )  (also noted your qs in slack, which we can resolve). Hi @dustyhoppe . Yes, your PR has crossed with the deprecation of overloads: thanks for bearing with this!  That's causing the build failure. \nWe want to keep those tests (not deprecate them), so we need to move the calls they contain to overloads that are not deprecated. Two possible approaches to find the right overloads:\n\nThe pattern of the retained overloads is that where the .Execute/ExecuteAsync(...) overloads takes one or both method parameters Context context and CancellationToken cancellationToken, then the input parameters to the executed delegate must match (eg (ctx, ct) =>, or (ct) => or whatever).  (The deprecations are to eliminate overloads inconsistent with that.)  So, usually the simple correction is to change the input parameters of the executed delegate from () => to ctx => or from (ct) => to (ctx, ct) =>, to align.\n\nOR:\n\nI will have already made the corresponding changes in the similar tests which you originally adapted from - you can copy the relevant change from there.\n\nLet me know if that makes sense, or if I can provide any further input.\nAnd, again: Thanks for making this contribution!\n(I remember you had a q in slack - let's fix up this build, then pick up that q). @dustyhoppe Thanks for updating this! I will aim to review in the coming days.. @dustyhoppe  We hit some more packaging changes we had to push through, for the ASP NET Core 2.1 Release Candidates, and still have some work to finish around that before we get back to regular functionality PRs.  Many thanks for your contribution (and apologies it has sat behind the targeting changes).. @dustyhoppe Many thanks for your patience while our focus was on ASP NET Core 2.1 integration!  PR looks excellent :+1:.  Before merge, would you be able to:\n\nretarget the PR against our new v610dev branch.  There shouldn't be any conflicts; it should be an easy switch per these instructions. (I'm simply changing our workflow process to merge into vXYZdev branches, before master.)\nremove the file TimeoutSpecs.cs.orig from the PR\n\nThat's it!\nYou mentioned in slack that there was a particular issue with NET4.0 tests: this goes away because from Polly v6.x, we happen to have discontinued .NET4.0 support.\nI will add suitable doco after merging.\n. @dustyhoppe ! Yes, perfect!  Apologies I have been sooo slow while pre-occupied with ASPNET 2.1 changes and other things.  Merging to the v610dev branch!. Hi @Discofunk .  Overloads exist for all synchronous executions taking a CancellationToken.  The retry implementation honours cancellation before each try as well as (with wait-and-retry policies) during any wait-before-retry.\nYou can pass arbitrary data in to the execution via the Context; see the readme here for examples.  You would need to pass in a related CancellationTokenSource in order to be able to initiate cancellation within the execution.  \nIf you do not have access to the CancellationTokenSource for some existing CancellationToken being passed, then you would need to create your own CancellationTokenSource (to which you therefore do have access) and use CancellationTokenSource.CreateLinkedTokenSource() to combine with the other token.\n. @Discofunk  You could also of course just throw any-other-exception not handled by the Policy, if you want to avoid passing a CancellationTokenSource via Context.  Honouring cancellation with cancellationToken.ThrowIfCancellationRequested(); (which the retry policy does internally) is after all only the act of throwing another execption.. @Discofunk  The example you posted should work.  But per my near-simultaneous comment, if the scenario is simply the code you originally posted, the context-passing solution seems over-engineered.\nFrom your initial comment about 'not having access to the token source' I assumed that was the way you wanted to initiate cancellation.  But would the following not also suffice?\nvar policy = Policy\n    .Handle<OfflineException>()\n    .Retry(3, (ex, retryAttempt, ctx) =>\n    {\n        var result = MessageBox.Show(\"Please retry once the application is back online or cancel this request\", \"Application Offline\", MessageBoxButtons.RetryCancel, MessageBoxIcon.Error);\n        if (result != DialogResult.Retry)\n        {\n            throw new OperationCanceledException();\n        }\n    });\n. Closing as I believe we have a resolution for the question raised.  However, do please reopen - or open another issue - if you have further questions.. Thanks @discofunk for this suggestion.  There are a few reasons why it is not easy to carry through consistently:\n\nPolly policies handle both return values and exceptions; the InnerException approach could only apply (directly) to communicate exceptions which cause the previous retry, not return values. \nIf we did this, we\u2019d need to make sure it applied consistently \u2013 which means applying it also to cancellations which occur during the wait phase of wait-and-retry or are thrown by executed user delegates. To apply the same principle to those cases, Retry would have to catch the OperationCanceledException they throw, and then rethrow with the cause-of-previous-retry-exception as the InnerException ... but that means discarding the info/stack trace of the original cancellation ... (which should rightfully be the InnerException if we rethrow as a different exception instance). ... or using an AggregateException to preserve both InnerExceptions ... the complications just compound.\n\nI also feel uncomfortable about the Polly API breaking the standard idiom of what InnerException means in the documentation, that InnerException should be \u2018the cause of the current exception\u2019 and only be set for \u2018an exception that is thrown as a direct result of a previous exception\u2019. \n\nHow else could you obtain, on cancellation, the cause of a previous retry (if any)?\nThe exception-causing-the-retry is passed to the onRetry delegate (if configured) of the retry policy.  So you can either: \n\nif policy definition and usage are in the same scope, have onRetry store the exception-causing-retry in a local variable (local to the defining scope), and refer to it afterwards\nif policy definition and usage are not in the same scope, pass a Context into the execution, have onRetry store the exception-causing-retry in the Context, and extract it from the Context after execution.\n\nDoes this help?\n\nOn the other hand, if the context is the scenario from your other question, you could certainly choose yourself to use the InnerException of the OperationCanceledException as you suggest:\nvar policy = Policy\n    .Handle<OfflineException>()\n    .Retry(3, (ex, retryAttempt, ctx) =>\n    {\n        var result = MessageBox.Show(\"Please retry once the application is back online or cancel this request\", \"Application Offline\", MessageBoxButtons.RetryCancel, MessageBoxIcon.Error);\n        if (result != DialogResult.Retry)\n        {\n           throw new OperationCanceledException(\"????\", ex);\n        }\n    });. Closing as I believe we have a resolution for the question raised.  However, do please reopen - or open another issue - if you have further questions.. @taomylife521 .  The three reactive Policy types propagate handled exceptions out of the Policy as follows:\n\nRetry policies: rethrow the final exception on to your code, if all tries have failed. \nCircuitBreaker policies rethrow all exceptions, even handled ones.  A circuit-breaker measures the exceptions and decides whether to introduce fail-fast breaking (break the circuit), but rethrows all exceptions.\nFallback policies do not by default rethrow handled exceptions.\n\nThe wiki pages linked above for each Policy  give more information.\nFor the cases when a policy rethrows an exception, you can either:\n+ handle it with your own try / catch; or\n+ use .ExecuteAndCapture(...) to capture the result of execution into a PolicyResult, and so avoid an extra try / catch.\nI'm not sure if this answers your question.  Let us know if you need anything else?. Closing.  Extra documentation PRd onto readme, in #458 . Hi @luistest . It's certainly possible to nest calls through policies, so that (for example) an outer WaitAndRetry(...) policy executes code that itself includes an inner WaitAndRetry(...) execution. It sounds like that's what you want.\nFrom the problem description, I don't have a clear picture of the method signatures and how they interact. Re \"method Y uses value returned by method X\": Is that, method Y calls X(...) internally?  Or is the result of X() passed as an input parameter to Y?  For us to help further, please could you post pseudo-code showing the elements in the question and how they interact?  Without seeing that, there's a risk any code I propose might make different assumptions and not meet your needs.  Many thanks.. Hi @luistest . Does this help?\n```\nvar policyA = // ...\nvar policyB = // ...\npublic ReturnTypeOfX X() ( / code / }\npublic ReturnTypeOfY Y(ReturnTypeOfX x) ( / code / }\nvar y = policyB.Execute(() => Y(policyA.Execute(() => X()));\n```\nI am not sure if this meets your needs, because it may not match how your method Y uses the return value of X().  And in my example above, the policy usage is not in the method.  We would need to see an example of your existing code, to understand better your code structures.. Closing due to lack of response.  However, do please reopen or ask a new question if we can help further.. @paulomorgado Agreed. We will make clear the replacements for the deprecations.  \nThe original description of the changes is #425 . TL;DR We are removing overloads which take a parameter (such as Context) but where the executed delegate does not take that Context as an input parameter.  To find the new overload to use, make the signature of the input parameters to the executed delegate match the remaining parameters to the execute method.  (This guidelines applies except for async overloads involving bool continueOnCapturedContext; let me know if you need immediate further information on those.)\n. Documentation published to wiki. Briefly to add some stats around the dependent packages issue highlighted ^^ by @JamesNK (thanks!), I don't know if the following stats are accurate/complete, but libraries.io helpfully gives us some idea of the packages currently dependent on Polly unsigned:\n\ndependent packages - 163\nrepos - 267\n\nEDIT: To estimate the ripple out effect more: The number of dependent packages is as above, but the number of dependent packages that in turn have widespread consumption is small (ie projects with more than a handful of stars per libraries.io; some ad-hoc checks suggest this has correlation with high downloads).. x-ref input from the Dot Net team. Thanks @iancooper and @rvanmaanen for highlighting this important issue.\nx-ref https://github.com/aspnet/HttpClientFactory/issues/108 where I am querying the ASPNET Core team on the timing for this.  . @pardahlman (for RawRabbit); @TomPallister (for Ocelot); @fanliang11 (for surging): @RamjotSingh (for Microsoft.Bot.Connector.Teams)\nlibraries.io suggests you maintain libraries which have high downloads on nuget or high github stars, and consume Polly as a dependency. As a courtesy, please read this thread: Polly intends, from Polly v6.0.0, to switch to publish only as a strong-named version.  \nPolly v6.0.0 will be a release functionally identical to Polly v5.9.0, but a major-version bump (v6.0.0) as we switch to purely strong-naming.\nCurrent (up to Polly v5.9.0)\n| nuget package | kind |\n| --- | --- |\n| Polly | non strong-named |\n| Polly-Signed |  strong-named |\nPolly v6.0.0 onwards\n| nuget package | kind |\n| --- | --- |\n| Polly | strong-named |\nImpact\nBoth non-strong-named DLLs and strong-named DLLs can reference strong-named DLLs. \nWhether the DLLs in your package are themselves strong-named or not, you will be able to reference the new Polly v6.0.0 strong-named package.\nWhy is Polly doing this?\nASPNET Core 2.1 is moving to consume Polly for HttpClient instances created through HttpClientFactory. This will allow the easy application of Polly resilience strategies to outbound calls through HttpClient.  \nThis is expected to significantly increase consumption of Polly's strong-named package (currently labelled Polly-Signed).  That however will create conflicts which apparently have no solution for packages or projects that currently consume non-strong-named Polly (example) (good summary) and wish to use the new ASPNET Core 2.1 features.  \nIf we leave both non-strong-named and strong-named Polly in the market, we prolong the possibility of these conflicts into future months and years.  We prolong the possibility that we (and you) will have users who complain that products are unusable, because some product (perhaps consuming yours) requires strong-named Polly as a transitive dependency via one axis, and non-strong-named Polly as a transitive dependency via another axis.\nIf we switch to a single, strong-named Polly release, there is initial impact while products switch to strong-named Polly, but the duration of pain is limited by there being only a single version in the market going forward.\nDeeper discussion: 1; 2.\nThis strategy is the strategy used by many high-download nuget packages such as NewtonSoft.Json, FluentValidation, and Serilog, and is the strategy recommended by the Microsoft ASP.NET team.\nReducing onward impact\nWe are also adopting the so-called Newtonsoft.Json strategy described here to minimise onward impact.  In this strategy:\n\nnuget package numbers follow full semver (Major.Minor.Patch increments) to differentiate bug-fixes, new-functionality-without-breaking-changes, and breaking-changes.\nDlls partially follow Major.0.0 version numbering only (even if the true version is Major.Minor.Patch).  This reduces the burden on projects which consume Polly of introducing excessive assembly binding redirects.\n\nEdited: to fix links\n\nFollowing community discussion, we believe this to be the best way forward (but comments and questions are welcome!).. Polly v6.0.1 is published, delivering the changes discussed in this thread.\nLeaving the issue open as I intend to transition the discussion from this thread and https://github.com/aspnet/HttpClientFactory/issues/108, https://github.com/aspnet/HttpClientFactory/issues/105 into the Polly wiki, as documentation.. Documentation published to wiki. Thanks @NinoFloris for this great question! (apologies for delayed response).  Totally with you about not wanting to capture exceptions by string-matching!\nWe could split the Polly packaging like this, but I'd like first to understand more about the problems (and possible workrounds), otherwise we could be making a change for a large number of Polly users (split into two pkgs) for just this one use case. (And it takes time to change/administer our build routines but doesn't add new functionality).\nThe obvious q (and to help me understand more deeply) : Is it an option simply to include the existing Polly package/dll at the layer (service layer?) that needs it? Is the size of the Polly package (at 300KB) a problem for this, or are there other reasons why that may not be suitable?\nCommunity views?  Any other reasons why it would be good / not good to split like this?\n\n(Not that we can't change this; but want to understand the real-world impacts more deeply before we embark on changes to packaging.). See that this request has several \ud83d\udc4d . We may come back to this at a Polly major release, depending on time/availability.  It would be suitable for an 'up-for-grabs' if enough of the current unknowns/variables were tied down.\nWe would ideally want to resolve #281 (eliminate or refine the sync/async split) before pulling out Polly.Abstractions, so that the abstractions contained the definitive set of interfaces we expected to use going forward.. Polly v6.0.1 is published, delivering this change. Change is documented in the readme.  . Also implements: #446 Add Net Standard 2.0 target. @joelhulen I have finished local package tests.  . Closed via #447. @Dhakate I haven't used Windows Forms (and WebBrowserControl) for a while, so my guidance may be off the mark. Community input welcome from anyone closer!  That said:\n\n\nCan you post some of the actual code? That may help us/anyone help. A minimal, complete verifable example is best, but any actual code could be useful.\n\n\nAre you using TimeoutPolicy in pessimistic mode, TimeoutStrategy.Pessimistic? TimeoutStrategy.Pessimistic does execute the passed delegate on a ThreadPool thread (the only way to 'walk away' from an execution that doesn't honour co-operative cancellation, is to execute it on another thread).  So TimeoutStrategy.Pessimistic is likely incompatible with the Windows Forms requirement that UI elements are accessed on the UI thread.  \n\n\nIf you were not using TimeoutStrategy.Pessimistic, then TimeoutPolicy would execute the code on the calling thread, so I wouldn't expect TimeoutPolicy to cause any cross-thread-access concerns. But TimeoutStrategy.Optimistic cannot successfully time out a call to HtmlDocument.GetElementById(...) (EDIT: if that's long-running; or any code that doesn't honour a CancellationToken), so I would expect the timeout to have no effect.\n\n\nAre we sure the InvalidCastException is being caused by accessing UI elements from other than the UI thread?  Memory (and this documentation?) suggests we might expect InvalidOperationException for that (but NB I am not close to Windows Forms, could be wrong).\n\n\nWhat is the overall scenario, the overall goal of your code? What is taking a long time that you wish to apply a timeout to?  Perhaps the timeout can be applied at a different level - to the underlying 'slow' operation? (if there is one)\n\n\nHope some of this is useful - comment welcome from anyone with other ideas!. @Dhakate Thanks for posting the code.  I suspected there might be a loop waiting on the results of HtmlDocument.GetElementById(...), since I hadn't expected HtmlDocument.GetElementById(...) itself would take any significant time to return. \nTimeoutStrategy.Optimistic operates via CancellationToken and assumes delegates you execute support co-operative cancellation.  With optimistic timeout, you must use Execute(...) overloads taking a CancellationToken, and the executed delegate must honor that CancellationToken.  You can read more about this in both the Polly readme and wiki for TimeoutPolicy.\nTimeoutStrategy.Optimistic would not time out the code you have posted since that code takes no CancellationToken.  For completeness, a version of the Until(...) method you posted using a CancellationToken could look something like this:\npublic static void Until(Expression<Func>predicate,Timespan timeout)\n{\n    var compiledPredicate = predicate.Compile();\n    Action action = cancellationToken => {\n        while (compiledPredicate () == false) cancellationToken.ThrowIfCancellationRequested();\n    };\n\n    var policy = Policy.Timeout(timeout, ontimeout:(CTX,to,tsk)=>{\n        var message = \" timeout before completing predicate\";\n        throw new TimeoutException (message);\n    });\n\n    policy.Execute(action, CancellationToken.None); // CancellationToken.None here indicates you do not want to add any additional cancellation to the timing out provided by TimeoutPolicy.\n}\n\nThere could be concern about that tight loop burning CPU cycles, however.  And there could be many ways to simplify this.\nFor your specific Use Case, however: rather than polling for completeness in a loop, can you attach to an event like DocumentCompleted ?  Or, if a specific element is being populated after the main document has loaded, is there any event / callback that can be attached to the code populating that element?. A Polly policy can handle a particular response code, per your clause .HandleResult(response => response.StatusCode == HttpStatusCode.Accepted).  \nTo execute particular code when that handled condition occurs, you can use a FallbackPolicy.  When the fallbackAction wants to consume the result-so-far (the HttpResponseMessage with HttpStatusCode.Accepted in your case), use this overload. See the readme for how the passed DelegateResult<HttpResponseMessage> represents the outcome of the execution.  For example:\nvar _partialSuccessResponseHandlerPolicy = \n    Policy.HandleResult<HttpResponseMessage>(response => response.StatusCode == HttpStatusCode.Accepted)\n        .FallbackAsync(\n            fallbackAction: async (outcome, context, cancellationToken) => await FooWhenHttpStatusCodeAccepted(outcome.Result, cancellationToken), // Processes the outcome.Result and provides an alternative HttpResponseMessage result to the caller.  This example discarded the context parameter, on assumption the execution not using the Polly.Context.\n            onFallbackAsync: async (outcome, context) => { /* possible extra actions for when the policy handles an execution, such as logging */ }\n        );\n\nThat describes what FallbackPolicy can do, but it isn't necessarily a fit for:\n\nI want to execute a method which deseiralizes response\n\nFallbackPolicy is designed to provide an alternative response when an execution errors, and that alternative must be the same type as the original execution. So in the above example, fallbackAction can only return HttpResponseMessage.  So it is not a fit for deserializing the response within fallbackAction and returning that different (deserialized) type.  There could be alternatives (to do this with FallbackPolicy) like capturing the result of the deserialization by closing over a variable in a lambda, or out parameters. But plain old if statements to handle this case might be easier to read.\n\ndoes some other work if I want like updating metrics based up on response and other kind of stuff\n\nonFallbackAsync can be a good fit for such cross-cutting concerns.\nEDIT: Have aimed to describe here ^ both what FallbackPolicy can do and why it might / might not fit this case - hope useful.. @SashaPshenychniy  Thank you for this and apologies for the delayed reply.  We would accept a PR to add the missing overloads.  The changes would need to be implemented in all four variants of the WaitAndRetryForever policy, ie in:\n\nRetrySyntax.cs\nRetrySyntaxAsync.cs\nRetryTResultSyntax.cs\nRetryTResultSyntaxAsync.cs\n\n\nRe:\n\nadd retryAttemptNumber to Context class\n\nBecause users may have more than one retry-policy nested in a PolicyWrap, this option is not viable.  When the execution was through a PolicyWrap nesting more than one retry policy, it would not be clear what Context.RetryAttemptNumber meant.\n\nMarking this 'up-for-grabs'.  Anyone who wants to take it on, post on the issue and - please ask if you have any questions!. Hi @NRKirby Thank you for your interest in this!  @Freakazoid182 has made a PR ( #471 ) on this just hours earlier, so it may no longer be 'up-for-grabs'.  @Freakazoid182 / both: I haven't had the chance to read #471 today, but will do shortly.  @NRKirby  Do feel free to read #471; comments welcome!. Thank you @SashaPshenychniy for raising this!  Even more thanks @Freakazoid182 for implementing it (you have a credit in the Readme!).  Fixed in v6.1.0 which will release to nuget shortly.. @rkandi590 Yes, Context is the intended mechanism for passing custom data into an execution - and between different parts of an execution.  This blog post 'Using execution context in Polly' gives some examples.\nIf you need to exchange data between the executed Func and the onRetry delegate of the policy, use an overload like this (or any richer overload) of WaitAndRetryForever(...), where the onRetry delegate takes Context as an input parameter.  Similarly, use an ExecuteAsync(...) overload which takes a Context input parameter, so that you can pass Context into the execution.\nAssuming this is an async execution, you'll want to use the async variants of the overloads, as linked to above.. @skalinkin Many apologies for the delayed reply.  Polly v5.9.0 includes the identical functionality to v6.0.1, and includes a direct v4.5.1 target.\nIn v6.0 onwards we are not (at present) considering direct .NET Framework targets as we expect to add integrated eventing/logging functionality explicitly based on some .NET Standard/Core -only interfaces going forward.  . @CesarD  For asynchronous executions using ExecuteAsync(...), the policy must be defined as an asynchronous policy, thus:\nvar cachePolicy = Policy.CacheAsync(new MemoryCacheProvider(MemoryCache.Default), TimeSpan.FromMinutes(5));\n\nAll policies should give a helpful exception message explaining that, if sync/async are mixed incorrectly, but this case has escaped that. I'll fix to make sure it gives a helpful exception.\nThanks for spotting the deprecated overload quoted in the cache documentation: it'll be corrected in both the readme and wiki.. Fixes in https://github.com/reisenberger/Polly/commit/56a0e488ae534754d7618ef26d5569b44b5aaff4 . Will be PRd after some other material has been added to v6.1.0. Hi @CesarD \n\nNow I don't get the exception and the code works, but it doesn't cache the results. The call to webservice is executed on every request\n\nIf the cache get or put encounters an exception, the exception is captured and passed to a configurable delegate rather than bringing down your whole app or operation; and the underlying operation (webservice in your case) is invoked.  If you are seeing the webservice continually invoked, perhaps something is failing with cache get or put. Try attaching a delegate to one of the policy error hooks to capture what may be happening.\n\nwhat should be used instead of the deprecated overload? \n\ncachePolicy.ExecuteAsync(async context => await _webService.someMethodAsync(), new Context(\"CacheKeyToUse\"));\n\n. @CesarD Thanks for the feedback. Extra clarification added:\n\nreadme \nwiki\n\n. Hey @CESARDELATORRE !  We have Polly and IHttpClientFactory documentation in the Polly wiki. There is some discussion about setting execution context in the section on Cache policy - you can use:\nrequest.SetPolicyExecutionContext(...);\n\nWhen HttpClientFactory configures a logical HttpClient to apply Polly policies, the policy.ExecuteAsync(...) call is obviously eventually made from within the delegating handler, so the user doesn't have control to pass the Context into that call.  Given Context is execution-scoped, there was not much option except to find somewhere to attach context to the HttpRequestMessage.\nIs it Cache policy you are using with the .NET Core 2.1 HttpClient factory integration?  We are interested in people's experience around that. . Closing due to lack of further discussion.  Please re-open or start a new issue if needed!. @CESARDELATORRE  It was great to see the ASP NET Core 2.1 updates to the eShopContainers project and related ebook.  We now highlight both of these in the Polly readme.. @yaireclipse Thanks for this clear and thorough analysis.  We'll have a think about whether there is a clever way to avoid this in a future release.  \nAs it happens we explicitly don't (currently) support the use of the static varargs overload with only one policy anyway (it intends to throw as that link shows). So even if the compiler inference ambiguity were resolved, it would not be a supported feature. This is because the internal design of the PolicyWrap is essentially a b-tree. By avoiding allowing a wrap of only one policy, we avoid a lot of runtime checks for a b-tree-that-isn't-really-a-b-tree. It was not intended however that that should express itself, unhelpfully, as a compiler overload inference failure! (not sure whether something has changed there in recent compiler inference or not)\nRenaming overloads is a fix that would clear the issue as you say, but has the cost/benefit trade-off around being a breaking change for users.\nFor now I've added to the documentation (wiki) the clarification:\n\nAll PolicyWrap instances must contain two or more policies.\n\nThanks again.. @AndreaCuneo  Polly provides two cache provider implementations at present, as described here in the cache wiki.\nYou are correct that Polly.Caching.Serialization.Json is not published.  We will aim to publish that in the coming days. To explore usage, you can meantime clone the repo and build locally. This generates a nupkg which you can call into a project from a local nuget folder.\n\nIf you are working with .NET Core 2.1-RC and Polly v6.0.1, you will want to wait till https://github.com/App-vNext/Polly.Caching.Serialization.Json/issues/3 is resolved.  \nIf you are not working with .NET Core 2.1-RC, and Polly v5.9.0, Polly.Caching.Serialization.Json is good-to-go in its current form.. The JSON serializer might typically be needed when working with the IDistributedCache provider and Redis (underlying), in order to convert an HttpResponseMessage (say, from an http call) into a byte[] for caching with Redis.\n\nIt is not essential to have a serializer in use to work with a ResultTtl strategy.  ResultTtl strategy is for use when the result specifies how long the item can/should be cached for.  A returned HTTP result, for instance, might use an HTTP header to specify how long the returned value should be cached for.  That HTTP header would be extracted before serialization.. @AndreaCuneo You should be able to do: \nvar cachePolicy = Policy.CacheAsync<(string AccessToken, DateTimeOffset ExpiresOn)>(_memoryCacheProvider.AsyncFor<(string AccessToken, DateTimeOffset ExpiresOn)>(), new ResultTtl<(string AccessToken, DateTimeOffset ExpiresOn)>(r => new Ttl(r.ExpiresOn - DateTimeOffset.Now, false)));\n\nRegarding a version of Polly.Caching.MemoryCache compatible with Polly v6.0, this is ready and we are hoping to release in the next few days.. Re-opened: need to complete release of Polly.Caching.Serialization.Json and documentation mentioned in this issue. Polly.Caching.Serialization.Json is now released to nuget.. >I confirm that AsyncFor<> solves.\n\nI couldn't find that, or I missed it completly, from every doc page I looked at\n\nDocumentation now added: https://github.com/App-vNext/Polly.Caching.MemoryCache#note . Thanks for highlighting this issue!. Hi @yangzhongke . Thank you for your question!  At the moment the project is not able to take donations.  However, if something is set up to accept donations in the future, we will let you know.  Many thanks for the question.. @andregrohmann This looks like a bug: the PolicyKey should revert to the outer policy, as you say.  I have a plan for a fix for which the implementation would tie in nicely with work on Polly metrics.  Thanks for raising this.. Will be fixed with the release of v6.1.0. Fixed in #485. Thank you @andregrohmann for raising this! Fixed in v6.1.0 which will release to nuget shortly. ~That seems like a good suggestion.  We should probably publish symbol packages instead.~ EDIT: symbol packages deprecated\nSourceLink ~probably isn't an option for us as a library as of this date, as we don't (as a library) want to target a netcoreapp2.1 tfm.  However, that's based on a quick read of the docs; happy for comment from anyone who has insight on this.~ EDIT: Scratch that; should be fine.. Also the new <DebugType>embedded</DebugType> to consider, as an option for this.  Discussion and further links from here: https://twitter.com/KirillOsenkov/status/1007052524946255872 . It seems like NewtonSoft.Json is successfully enabling SourceLink and intends to start including .pdbs in nuget packages, as part of this.  Noting for reference.  We would have either that option, or publishing symbol packages as previously mentioned.  . Improving debug experience around Polly looks like a great area to improve the Polly experience with minimal other impact.  \nThree main options:\n\n~Create and publish Symbol packages to SymbolSource~ [deprecated]\nUse SourceLink  (more info also in earlier comments)\nUse the new portable pdbs, probably as <DebugType>embedded</DebugType> in the main Polly dll  (more info also in earlier comments) (would want to review size change of DLL; public reports seem v good but low-memory scenarios like Xamarin/embedded to keep in mind)\n\n@alexakryvenko Do you know whether, with each of options 2 and 3 above, you would still have the problem of having to manually exclude Polly from your code coverage reports? (Also: what code coverage tool were you using?)\nI'm going to 'up-for-grabs' this so that the core Polly team can focus on new functionality.  Happy to see contributions on any/all of 1, 2, 3 above.  EDIT: Post on the issue if you intend to take any part of this on (to avoid overlap).\nEDIT: Also really interested to hear people's views around 1, 2 and 3 above?. While a variety of options were discussed in this thread, the new OSS library guidance from Microsoft is to use SourceLink, so that is what we currently intend for Polly (#502). \nMS are also planning further evolution for debug source linking for nuget packages.  At time of writing this also focuses on SourceLink (with improved tooling) as the preferred way forward.. @paulomorgado / anyone : We have now consolidated the Polly solution similar to Paulo's original #504, which we wanted in before updating the Polly build for SourceLink.\nUp-for-grabs again to add SourceLink to Polly.  From discussion between Paulo and I (thanks Paulo!) and further investigation here, it looks like we should/could:\n\nRemove BrutalDev/StrongNameSigner from the Polly build, and replace with eg <AssemblyOriginatorKeyFile>...</AssemblyOriginatorKeyFile> and <SignAssembly>true</SignAssembly> in the csproj (or similar)\nBrutalDev/StrongNameSigner was useful when Polly published both non-strong-named and strong-named packages from the same build, now we publish strong-named only.\nReplace direct call to nuget pack with dotnet pack, as inserting the new <repository commit=\"{specific-sha}\"> attribute in the nupkg for SourceLink, relies on this - seems to be key step to get SourceLink working for Polly\nMove everything in Polly.nuspec into Polly.csproj (anything not already there, much is...)\nRemoves duplication and risk of inconsistency in stating dependencies between nuspec and csproj\nEverything in the nuspec seems covered by new csproj tags\nThe lengthy <releaseNotes>...</releaseNotes> in the nuspec, we could replace just with a simple <PackageReleaseNotes>See https://github.com/App-vNext/Polly/blob/master/CHANGELOG.md</PackageReleaseNotes> in the .csproj\n\nNB any changes should be against latest dev branch (EDIT: 9 March awaiting creation of v705orv710 branch after v7.0.4 is released) as this major commit consolidated the solution.. That's a great point, @phatcher . Having given this some thought, I'm coming down on the side that we stick with the current construction of the build script (ie still use dotnet pack), because we currently only build the nuget package if the test runs completely pass - and I like that cleanliness.  What do others think?\n@Kesmy Answers coming to your other queries shortly. Huge thanks for picking this up!. Hi @Kesmy Re the great queries ... (and: thanks again for picking this up!) : \n\n\nowner is not available in the csproj nuget properties, it inherits from Authors. Should the new Authors be App vNext to match the csproj, or Michael Wolfenden, App vNext to match the nuspec?\n\n\nStay with Michael Wolfenden, App vNext for now. Per this nuget doco (which seems to correspond with our experience even if dating from 2013):\n\nWhile each NuGet package\u2019s nuspec metadata defines the package\u2019s owner(s), the NuGet gallery at nuget.org ignores that piece of nuspec metadata. Instead, ownership of a package is defined by who publishes the package to the gallery.\n\n\nRe:\n\n\nSince SourceLink is still prerelease, is 1.0.0-beta2-18618-05 or 1.0.0-* preferable?\n\n\nI would be good with 1.0.0-* if we knew that robustly picked up the latest pre-release version.  There's some relatively recent commentary tho that 1.0.0-* is not entirely robust, and various hacky workrounds on linked threads.  Unless you think the situation is clearer than that, I'm happy we just go with 1.0.0-beta2-18618-05 and keep the build scripts clean.  Quick survey also: NewtonSoft.Json still points at a specific, and sourcelink doco specifies a specific, so seems expected practice.  We can always update it if problems emerge.  And we'll switch to 1.0 soon as they move off pre-release.\n\n\nthe package restore step can be removed, and the build can automatically restore\n\nHappy either way, depending on your available time.\nThanks again!. @Kesmy Thank you.  Just tested out the debug experience against the newly-built package locally - thanks for your awesome. :+1:\n. Closed via #616.  Huge thanks to @Kesmy for picking this up \ud83c\udf86 .  Thanks to @paulomorgado for earlier contributions too :+1:\nRelease as part of Polly v7.1.0 shortly.. Thanks for the question @B1nke ! I wonder if something else may be affecting your cases, or if you are expecting WaitAndRetryAsync to behave differently from actual in some way I haven't grasped, as I'm not sure I can reproduce the problems. Are you able to provide any minimum runnable code reproducing a problem? And/or clarify what you are expecting to happen, and what is not happening?  \nRe: \n\nthe onRetry action is hit directly when I get a result back from my API [...] The call to the action is made first, and then it will use the first timespan for sleeping\n\nThis is intended - see retry wiki.  The policy calls the onRetry delegate first (before waiting) so that there is some immediate feedback what happened with the execution, as soon as we have the execution result.  This ensures it is possible to log, for example, that the execution failed and the wait-before-next-retry commenced - and capture that logging even if the next thing that occurs is cancellation of that wait.  \n\nWaitAndRetryAsync does not use first sleep time\n\nCan you clarify or provide example code demonstrating? I re-checked this test and think it confirms that the first sleep time is used.\n\nwhen just providing a single timespan. The action will be executed directly, and then it will sleep for the timespan provided, but then it will never hit the action again because there are no more timespans.\n\nWhich action is it not hitting again that you are expecting - the onRetry action or the action executed through .ExecuteAsync(...)?  If meaning the delegate executed through .ExecuteAsync(...): I re-checked and think that this test confirms that the delegate executed through ExecuteAsync(...) is executed one more time than the number of timespans provided.  \nIf you are looking for a policy which retries repeatedly (forever) on failure, with a wait of TimeSpan.FromSeconds(20) between each try, there is this option:\nvar retryPolicy = Policy\n    .HandleResult<HttpResponseMessage>(r => r.StatusCode != HttpStatusCode.OK)\n    .Or<Exception>()\n       .WaitAndRetryForeverAsync(i => TimeSpan.FromSeconds(20), (exception, timeSpan, context) => { /* logging */ });\n\nHope this helps. Let me know if I still haven't understood a problem you are seeing!. Paul, Your considerations and reasoning make sense to me.  TL;DR For this use case, one layer with resilience policies in the HttpClient working at the HttpResponseMessage level; and a layer further out where more content-aware policies (cache; fallback) work at the level of the actual response.  \nA few thoughts in detail:\n\n\nRetry, circuit-breaker, timeout, bulkhead can certainly be common to all endpoints on an API with the same BaseUrl, and as such the policies can be reused and embedded within the HttpClient.  Note that a best practice pattern is to place the policies in DelegatingHandlers as outgoing middleware, to sidestep a number of issues detailed in that StackOverflow discussion.  In ASP NET Core 2.1 you can use IHttpClientFactory to configure this and to manage the HttpClient (and internal handler) lifecycles; we describe this in detail also in the Polly wiki.  Those policies can be common to all API endpoints on the same base address, but of course you can choose to scope them differently if you want to group calls to different endpoints in different bulkheads or something like that.\n\n\nCache: you can use the same single Cache policy instance across different API endpoints (because the cache policy just defines the underlying cache and ttl to use, while a varying OperationKey can be passed into the execution to specify the key to cache under).  However, there are (as you allude) a number of uncomfortable points around caching at the HttpResponseMessage level, as we discuss here and here and Scott Hanselman discusses here (Scott's other posts on caching in that series give good food for thought too).  \n\n\nFallback likewise is content-aware, so perhaps sits better at an layer where the content has already been extracted from the http call.\n\n\nRe:\n\na lot of boilerplate code which is just wrapping calls to the real API\n\nsounds like a classic decorator, effectively what this is - seems reasonable. \nThanks for sharing your q and thoughts; hope some of the links herein are useful.. @phatcher . Closing this as I think we are done here.  Do however re-open, or start a new issue, if there's more to discuss.. @Freakazoid182 The build appeared to time out unexpectedly (at 2 hours) on this, rather than being any test failure.  I just re-based the PR against the App-vNext:v610dev branch (and resolved a readme conflict), which has kicked off another build.. @Freakazoid182 I spotted the StackoverFlowException in the test run and had guessed a cause like that. Thanks for updating the PR.  I'll be aiming to review this for incorporation into v6.1.0. Thanks @Freakazoid182 for this contribution!  I just added a few quick unit tests, and am now merging to the v610dev branch.. @cmeeren. Thank-you for raising this. What is the return type of the delegate being executed through the policy? (ie the type of TResult or TCacheFormat).  Could you post also the code placing the execution through the policy?  If my assumptions are correct, fix should be quick and easy.. Thank you @cmeeren for raising this. Fix is already coded and tested here. We should be able to release this early next week.  \n. Thank you @cmeeren for raising this! Fixed in v6.1.0 which will release to nuget shortly. @taomylife521 For a wait-before-retry time set according to the execution result, see the discussion on handling 429 RetryAfter and code samples linked to from there.\nFor controlling how many times to retry based on execution result, I would suggest using WaitAndRetryForever(...); when you wish to not make further retries, throw an exception the policy does not handle.\n. @taomylife521 . Polly policies are intentionally immutable.  We intentionally do not allow the main parameters (eg number of retries) of an existing Polly Policy instance to be modified after initial configuration, because the consequences could be indeterminate for instances used in multi-threaded scenarios.  \nIn your specific example, since you create and use the policy within the method and all variables are method-invocation-scoped, you could thread-safely do something like that.  Because we intentionally do not allow the number of retries to be modified after configuration, you would have to use WaitAndRetryForever(...) and rethrow (indicate the exception is not handled any more) when you do not wish to retry any further, per my original comment:\n    public void Excute()\n    {\n        int retryCount = 3;\n        int sleepTime = 1;\n        RetryPolicy policy = Policy.Handle<Exception>((ex) =>\n        {\n            return (retryCount-- > 0);\n        }).WaitAndRetryForever(attempt => TimeSpan.FromSeconds(sleepTime), (exception, timespan) => { \n            Console.WriteLine(\"\u4f11\u7720\" + sleepTime.ToString() + \"\u79d2\u540e\u91cd\u8bd5\");\n        });\n        try\n        {\n            policy.Execute(() =>\n            {\n                using (var client = new WebClient())\n                {\n                    string response = null; //client.DownloadString(Configuration.WEB_API_ROOT + \"/api/values/\");\n                    if (response == null)    \n                    {\n                        **//Here TODO: i want to dynamically set retryCount and sleepTime By response\n                        retryCount = 4;\n                        sleepTime = 2;**\n                    }\n                    Console.WriteLine(response);\n\n\n                }\n            });\n\n        }\n        catch { }\n    }\n\n. Hi @taomylife521 . Hope this helped.  Closing due to lack of further comment. Do however re-open, or start a new issue, if you require further assistance.. @shaglit  Yes.  PolicyWrap (readme; wiki) is the way to combine more than one policy, so that multiple policies can be applied easily to one call.\nThere are no barriers on the way you can combine policies with PolicyWrap: you can certainly combine two policies of the same type (eg two circuit-breakers), as described in the wiki here.  . Closing due to lack of further comment. Do however re-open, or start a new issue, if you require further assistance.. Fixed in v6.1.0 which will release to nuget shortly. Hi @rmandvikar . Good question; thanks for the great repro code.\nDefining the behaviour of .ExecuteAndCapture() with PolicyWrap was hard: a PolicyWrap can flexibly consist of any number of policies with different handle clauses, making it hard to define the meaning of a single binary OutcomeType.Successful [or] .Failure representing \"Did this policywrap handle the fault? (somewhere)\".  \nAs such, it was decided that .ExecuteAndCapture(...) on a PolicyWrap indicates that a given exception or result was handled by the PolicyWrap if the outermost policy in the wrap handled it.\nWith that in mind, in your sample code, a TimeoutPolicy is outermost in the PolicyWrap.  When the executed delegate returns null, no timeout is occurring or other exception being thrown, so .ExecuteAndCapture(...) considers the execution successful.  \nYou could get the PolicyWrap to give the expected results for .ExecuteAndCapture(...) by placing a policy which handles the same results outermost in the PolicyWrap.  A FallbackPolicy can be used for this: in the below example the FallbackPolicy merely returns the same result (it doesn't substitute any different value as Fallback often does), but it does mean PolicyWrap.ExecuteAndCaptureAsync(...) will treat the outcome as having been a handled fault.\n```csharp\nIAsyncPolicy retry = Policy\n    .Handle()\n    .OrResult(ShouldHandleResult())\n    .WaitAndRetryAsync(\n        2,\n        retryAttempt => TimeSpan.FromMilliseconds(1000));\nIAsyncPolicy timeout = Policy\n    .TimeoutAsync(10);\nIAsyncPolicy fallback = Policy\n    .HandleResult(ShouldHandleResult())\n    .FallbackAsync(\n        fallbackAction: (outcome, ctx, ct) => Task.FromResult(outcome.Result), \n        onFallbackAsync: (outcome, ctx) => Task.CompletedTask\n        );\nIAsyncPolicy policyWrap = fallback.WrapAsync(timeout).WrapAsync(retry);\nPolicyResult result = await policyWrap.ExecuteAndCaptureAsync(async (ct) =>\n    {\n        ct.ThrowIfCancellationRequested();\n        //throw new Exception();\n        return await Task.FromResult((Holder)null);\n    }, CancellationToken.None)\n    .ConfigureAwait(false);\n```\nwhere:\ncsharp\nprivate static Func<Holder, bool> ShouldHandleResult()\n{\n    return h => !(h?.holder?.done) ?? true;\n}\nAdding a FallbackPolicy here is a bit of a workround (unless you want it for other reasons).  You could alternatively omit the FallbackPolicy and do something like if (result.Outcome != OutcomeType.Successful || ShouldHandleResult(result.Result)), to get the same effect.. @rmandvikar Thanks for the great example.\nWhat is happening is that the fallback policy you have configured is replacing the TimeoutRejectedException with a replacement result of null (default(object)). This is bubbled (as the overall result) back out to .ExecuteAndCaptureAsync(....), which says \"null isn't something the FallbackPolicy regards as a fault, so now we have a successful outcome!\"   .ExecuteAndCaptureAsync(....) is capturing and evaluating the final outcome, after the substitution by fallback.\nI would agree if you thought this behaviour of .ExecuteAndCapture/Async(...) with FallbackPolicy is subtle! But it makes sense: in your original fallback policy, you replace the failure outcome with a success outcome ... so the overall outcome should be reported as success!\nIf you replace the FallbackPolicy with one which doesn't substitute a different result, but bubbles the received result back outwards, then indeed the overall execution outcome is a fault, and the test will pass:\n```csharp\n    [Fact]\n    public async Task Outcome_Should_Be_Failure()\n    {\n        var retryCount = 1000;\n        var retry = Policy\n            .Handle<Exception>()\n            .OrResult<object>((result) => false)\n            .WaitAndRetryAsync(\n                retryCount,\n                ra => TimeSpan.FromMilliseconds(1000));\n        var timeout = Policy\n            .TimeoutAsync(1);\n        var fallback = Policy\n            .Handle<TimeoutRejectedException>()\n            .OrResult<object>((result) => false)\n            .FallbackAsync(\n                fallbackAction: (outcome, ctx, ct) => {\n                    if (outcome.Exception != null) throw outcome.Exception; // bubbles a received exception back outwards // or use ExceptionDispatchInfo to preserve stack trace\n                    return Task.FromResult(outcome.Result); // bubbles a handled result back outwards\n                },\n                onFallbackAsync: (outcome, ctx) => Task.CompletedTask\n            );\n        var policy = fallback.WrapAsync(timeout).WrapAsync(retry);\n\n        var time = DateTime.UtcNow;\n        var retryAttempt = -1;\n\n        var policyResult = await policy.ExecuteAndCaptureAsync(async (ct) =>\n            {\n                ct.ThrowIfCancellationRequested();\n                retryAttempt++;\n                throw new Exception();\n                return await Task.FromResult(new object());\n            }, System.Threading.CancellationToken.None)\n            .ConfigureAwait(false);\n\n        var actualTimeout = DateTime.UtcNow.Subtract(time).TotalSeconds;\n        Assert.IsTrue(retryAttempt < retryCount);\n        Assert.AreEqual(OutcomeType.Failure, policyResult.Outcome);\n        Assert.IsNull(policyResult.Result);\n    }\n\n```\nWhat I think this demonstrates is that my previous statement (and the statement in the documentation) ... :\n\n.ExecuteAndCapture(...) on a PolicyWrap indicates that a given exception or result was handled by the PolicyWrap if the outermost policy in the wrap handled it.\n\nis not precise, is misleading.  It should be something like:\n\n.ExecuteAndCapture(...) on a PolicyWrap captures whether the final outcome of the execution is one considered a fault by the outermost policy in the wrap.\n\n. @rmandvikar Thanks again for your great example which highlights these important points! We've updated the documentation for both PolicyWrap and Fallback to make this clearer.\nLet us know if there is anything else we can help with.. Closing this as I think we're done here, and we've updated the wiki to cover this more precisely.  However, if you do need anything else, please re-open the issue or start a fresh one.  Also updated the title of the issue for future discoverability.  Thanks for your great question!. @atifmir .  We would need more details to be able to help here; there isn't enough info to tell how you have implemented Polly or what might be causing the 500 to change to 503.  To help further we would need to see  some sample code; best, a minimum verifiable example.. @atifmir To come briefly back to your question:\n\nHow can I get polly to stop retrying on 500\n\nAs shown in the readme, you can specify predicates to filter which exceptions or results you do / do not want to handle.  To exclude a 500 you might want something as simple as:\nPolicy.HandleResult<HttpResponseMessage>(r => r.StatusCode != HttpStatusCode.InternalServerError)\n\nThere are many more examples in the readme.  If your scenario merits a more free-form chat, maybe try the Polly slack channel (you can self-register) where we have a wider group of people available to help.  If you think something specifically is going wrong in Polly or not behaving as you expect, post more code here or ask on our slack channel.. Closing, but if you do require further assistance, please do re-open the issue (or a new one), and we'd be very happy to look at example code if it helps.. @shagilt It is hard to tell what may be happening without seeing some code: please post sample code of the UT, if my below comments do not help.\nThe circuit-breaker does not transition [*] from Open to HalfOpen state until some action is made on the circuit-breaker (whether that action is placing another call through the circuit-breaker, or reading the CircuitState property).  If you have a unit-test just waiting for time to pass, and then expecting the onHalfOpen delegate to be fired after the time has passed, the onHalfOpen delegate will not yet fire.  Try reading the CircuitState property in the test, to trigger the circuit state transition to HalfOpen.\nThis [*] behaviour (not transitioning to HalfOpen until some other action on the circuit-breaker) is intentional: it avoids the perf cost of the circuit-breaker allocating an internal Timer and callback just to transition the circuit-state.\nYou can see (if of interest) the extensive tests Polly already has on circuit-breaker state transitions and further tests around the halfopen state and onHalfOpen delegate.  This line demonstrates the [*] behaviour:: that the onHalfOpen delegate is not triggered until some other action is made on the policy.. Glad that sorted :+1: . Thanks for the wiki feedback: have made the part of the circuit-breaker wiki you quoted more precise.  The timing that this is triggered is also documented later in the same wiki:\n\nonHalfOpen: The delegate is executed immediately after the circuit transitions to half-open. Note: the delegate does not execute automatically after the automated break timespan has expired. It executes when state is next queried - for example, at the next attempt to execute an action, or when the state is next queried manually.\n\nRe the question:\n\nDo you recommend the same in production code so that state transition is guaranteed from Open to HalfOpen after durationOfBreak?\n\nIt depends whether the timing of emitting/logging that action is critical to you.  Consider also how high your circuit throughput is (/is likely to be) in relation to the durationOfBreak.  In any high throughput system you will 'pretty soon' get another call through the circuit anyway that will trigger the same transition 'pretty soon' after the durationOfBreak. For example, if durationOfBreak is 10 seconds but you typically get 20, 50, 100s calls per second through the circuit, you will typically very soon after the 10 seconds get another call which will trigger the  open->halfOpen transition.  So (for these kinds of circuit) it hardly seems worth implementing your own timing trigger in order to make the onHalfOpen timing marginally more precise.\nThis is the design choice we made for Polly: Polly is geared to perf for those high-throughput systems, so we choose not to allocate a Timer and trigger a callback within Polly to transition open->halfOpen at 'precisely' the designated time (same design choice as Hystrix IIRC).  The trade-off of that design choice though is that the timing of the open->halfOpen transition is not precise in slower throughput systems.. Cool. I've renamed the issue title to aid discoverability around the way half-open behaves.  Closing as I think we're done here, but let us know (here, or fresh issue) if you need anything else!  Thanks for your feedback and contribution to the Polly community!. Thank you @willdean : correction welcome!  If you do not have an Edit button immediately on the Bulkhead wiki page, you can also just check out the wiki with git by checking out the repo https://github.com/App-vNext/Polly.wiki, edit the Bulkhead.md file, then just push back to master.  . Awesome! Thank you!. @vany0114 You are seeing no difference in the specific example you posted because the delegates executed through the policy do not fault.  Try this code and you'll see a difference. The key difference is that the executed delegate faults (but few enough times that the policy should handle it).  Incidental (not significant) differences are:\n\nI changed from Assert.Fail(...) only to quickly run this up as a console app.  \nI changed the signature of TestSync() to async Task so that we could await it properly.  (Won't go into a side discussion here about the perils of async void which you may know anyway.)\n\nI'll post a follow-up post in a moment explaining why TestSync() fails (but post back if it's immediately self-evident to you, on seeing this!)\n```csharp\n    class Program\n    {\n        static async Task Main(string[] args)\n        {\n            var toTestSync = new PollySyncAsyncTest();\n            var toTestAsync = new PollySyncAsyncTest();\n        await toTestSync.TestSync();\n        await toTestAsync.TestAsync();\n    }\n}\n\nclass PollySyncAsyncTest\n{\n    private int counter = 0;\n\n    public async Task TestAsync()\n    {\n        var policy = Policy\n            .Handle<Exception>()\n            .RetryAsync(3);\n\n        await policy.ExecuteAsync(async () =>\n        {\n            var something = await DoSomethingAsync();\n            if (something != true) throw new Exception(\"Assert fail\");\n        });\n    }\n\n    public async Task TestSync()\n    {\n        var policy = Policy\n            .Handle<Exception>()\n            .Retry(3);\n\n        await policy.Execute( // Executing a Func<Task> delegate through a sync policy.\n            async () => // Providing the compiler an async delegate where it expects a sync delegate.\n        {\n            var something = await DoSomethingAsync();\n            if (something != true) throw new Exception(\"Assert fail\");\n        });\n    }\n\n    private async Task<bool> DoSomethingAsync()\n    {\n        await Task.Delay(TimeSpan.FromSeconds(1));\n\n        if (++counter <= 2) throw new Exception(\"Fault which we might expect the policy to handle\");\n\n        return true;\n    }\n}\n\n```. To answer your original question:\n\nWhy and When use ExecuteAsync or Execute? \n\nUse async policies and ExecuteAsync(...) any time you are executing an async delegate.  \nWhy? In other words, why does TestSync() in the above example fail?\nAt the line marked // Providing the compiler an async delegate ... the code provides the compiler an async delegate where it expects a sync one.  The compiler doesn't complain.  An async modifier isn't actually intrinsically part of the delegate signature, it doesn't cause a compile error due to method signature mismatch. All an async modifier does is say \"the delegate can contain await statements\". And modifies the return signature of the delegate: in this case from void to Task. (An async modifier doesn't even make a delegate run asynchronously, it just (broadly) does those two previously mentioned things.) For more background on these nuances (if unfamiliar) check out articles/blogs by Stephen Cleary and Stephen Toub.  So your whole executed async () => delegate here is - as far as the compiler is concerned - just a Func<Task>.\nSo at the line marked policy.Execute( // Executing a Func<Task> delegate through a sync policy, the code is actually doing policy.Execute<Task>(Func<Task> foo).  It's saying: execute that delegate through the policy and give me back the Task the delegate returns.\nThe final piece of understanding relies on knowing what await actually does.  When execution hits an await statement, it immediately returns from the method synchronously, returning a Task representing the ongoing work.  So what happens when you await policy.Execute<Task>(Func<Task> foo) is this:\n\npolicy executes the Func<Task> that is your delegate\nas soon as execution hits the first await, in var something = await DoSomethingAsync();, the delegate synchronously (see above) returns the Task representing the rest of the execution.\nno exception has been thrown up to this point, the delegate has successfully returned a Task, so as far as policy is concerned, the execution has completed with success.  policy has finished its work (it executed a synchronous delegate and that delegate returned synchronously without an exception yet), so policy returns that Task to the calling code and plays no further part in the execution.\nback in your calling code, you then await that returned Task.  \none second later that Task throws. The calling code is awaiting a Task that throws, so it ~bombs out~ rethrows.\n\nDoes that help?\n\nEDIT: To look at this another way, we can look at why it works with the async policy and not with the sync policy.  \n\nIf we look at the internals of the async policy, we see it is (as you would expect) executing the user delegate with await.  So it awaits the Task that represents doing the user-delegate work (after the first await is hit).  So it captures the exception thrown at if (++counter <= 2) throw new Exception(...);.  So the rest of the policy can handle that exception.\nIf we look at the internals of the sync policy, it is (as you would expect) executing the user delegate without await.  So (when an async delegate is executed through a sync policy) it immediately returns the Task which represents doing the user-delegate work (after the first await is hit).  So it doesn't govern the exception thrown at if (++counter <= 2) ...\n\nIn general the moral of the story is: don't mix sync and async code - particularly where exception-handling is involved.\n. @vany0114 np. Thanks for the great question!. Added to wiki: https://github.com/App-vNext/Polly/wiki/Avoid-compiler-gotchas-mixing-sync-and-async-execution. The documentation on DelegateResult<TResult> in the readme describes the property for this.  It is the property DelegateResult<TResult>.Exception.. @vany0114 That looks good:\n\nIf you place the timeout outside the retry in the PolicyWrap (that is, declared first), then the timeout applies as an overall timeout.\nIf you place the timeout inside the retry in the PolicyWrap (that is, declared after the retry within the wrap), then the timeout applies per try.\n\nYou can also do both in the same PolicyWrap: apply an overall timeout and a timeout per try. There is no barrier to using a TimeoutPolicy twice in the same PolicyWrap.\nWe discuss this in more depth, and show the flow through a PolicyWrap of this type, in the diagram in this part of the PolicyWrap wiki\n. Yes. If waits-and-retries inside a TimeoutPolicy mean the overall execution would take longer than the timeout allows, the timeout will time out the execution.\nSpecifically for the wait phase: both TimeoutStrategy.Optimistic and TimeoutStrategy.Pessimistic have the power to cancel a WaitAndRetry policy during the wait-before-retrying phase.. Thanks for the question @vany0114 . Added doco to the Timeout wiki specifically on this.  Closing as think we are done, but reopen, or start a new issue, if further qs!. The circuit-breaker will break after N consecutive actions executed through the policy have thrown 'a' handled exception - any of the exceptions handled by the policy.  This is intentional behaviour.  \nThe documentation here used to say 'a' handled exception: I've just updated it to say 'any' handled exception, to make that clearer. Thanks for the question. \n\nIf you wanted to construct a system that counts different faults (or groups of faults) separately for the purposes of circuit-breaking, you could achieve that by defining separate circuit-breaker policy instances for each fault (or group of faults) you wanted counted separately, and then nesting those circuit-breakers in a PolicyWrap.. @cmeeren Polly itself contains no code that logs the message \"Policy execution successful\".  Can you identify the piece of your own code around Polly (or code of any integration you may be using?) which is generating this message? It should then be possible to amend that code to silence these messages.  If we can help with that, post the relevant code.  \nIf you can identify something you believe that has changed in Polly v6.1.0 that may be causing changed behaviour, please post further details.  Changes between versions of Polly are detailed:\n+ in the changelog\n+ by the issues and PRs being tagged, eg in this case v6.1.0. Hi @Arash-Sabet .  Policies used with IHttpClientFactory must be policies handling HttpResponseMessage, of type IAsyncPolicy<HttpResponseMessage>.  \nYou can amend your configuration code either as:\nc#\n    var exceptionRetryPolicy = Policy<HttpResponseMessage>\n        .Handle<OperationCanceledException>()                               \n        .WaitAndRetryAsync(3, _ => TimeSpan.FromMilliseconds(50));\nor, per the note in the above-linked wiki page, use the .AsAsyncPolicy<HttpResponseMessage>() extension method:\nc#\n    policyRegistry.Add(policyKey, exceptionRetryPolicy.AsAsyncPolicy<HttpResponseMessage>());\nLet us know if this resolves the issue.\n. >if I store the [circuit-breaker] instance, let's say, into a PolicyRegistry, cache, or another storage which hold the object between requests, it keeps the state of the circuit?\nYes.  CircuitBreakerPolicy instances store the circuit-state internally.  The circuit-state is scoped to the policy, and shared across calls.\n\nit applies for Retry as well?\n\nA RetryPolicy instance is reusable across multiple call sites but executions are isolated from each other. Each execution maintains its own retry count independently. The retry state (number of retries) is scoped to the execution, not shared across different calls or call sites.\n\n\nI would like to know which policies share the state across requests\n\nCircuitBreaker and Bulkhead.\nCircuitBreaker's purpose to count and act according to success/fail metrics across calls placed through the policy.  It stores those counts in internal state. The intended functional consequence is that if you share a CircuitBreakerPolicy instance in multiple call sites or executions, those call sites or executions will share circuit state.  \n\nShare the same breaker policy instance across call sites when you want those call sites to break in common - for instance they have a common downstream dependency.  \nDon't share a breaker instance across call sites when you want those call sites to have independent circuit state and break independently.\n\nBulkhead's purpose is to limit concurrency of calls placed through it.  Each single BulkheadPolicy instance tracks that concurrency in internal state. The intended functional consequence is that when you share a BulkheadPolicy instance across call-sites, those call-sites share the bulkhead capacity between them.  \n\nShare the same BulkheadPolicy instance across multiple call sites when you want call sites to share the bulkhead capacity amongst them.  \nDon't share the same BulkheadPolicy instance across multiple call sites when you want the call sites to have independent bulkhead capacity.  \n\n\nAll policies can be stored centrally (eg in a PolicyRegistry) and used at multiple call sites.  Only CircuitBreaker and Bulkhead maintain internal state which is shared across calls, bringing the functional effects described above of reusing a single policy instance.. Published a wiki article to cover the topic.. Initial aside: If this is for http calls through HttpClient, you'll want an async policy variant, ie, use FallbackAsync(...).\n\nTiming-wise, the onFallbackAsync runs the statement before the fallbackAction, so it is likely safe to dispose the original HttpResponseMessage in the onFallbackAsync, given your posted code doesn't use it in the subsequent fallbackAction.  \nYou do also have the option of this overload where both the fallbackAction and onFallbackAsync are provided the DelegateResult<HttpResponseMessage> as an input parameter.  So (with that overload) you can also dispose the original HttpResponseMessage later, in the fallbackAction, if needed or preferred.\n. Thanks @bartelink . Great q and can see how this would add value for test-in-prod or blue-green deployments.\nImmediate options\nCircuitBreaker: You can make an inert breaker right now by configuring durationOfBreak: TimeSpan.Zero.  When the break threshold is met the onBreak delegate will be triggered and monitoring can be attached to that for whatiffery. No request will ever see the breaker as open, so it will be inert.\nBulkhead: You can make an inert bulkhead right now by configuring maxParallelization: Int.MaxValue.  You can then monitor BulkheadAvailableCount to determine when an imaginary bulkhead capacity of N would have been exceeded.\nPlaying what-if with progressively tightening contraints: Dynamic reconfiguration during running (ie you can reconfigure without having to recycle the process) could support this.\nMaster switch: PolicyRegistry is backed by interfaces.  You could easily implement a custom IReadOnlyPolicyRegistry for a master switch or \"kill switch\" to take Polly as a whole in/out of the mix, if desired (if that adds comfort, if experimenting in a live/prod environment).  Implementation would be a custom IReadOnlyPolicyRegistry which wraps the normal implementation: ordinarily it would just delegate to a wrapped PolicyRegistry to return the normal policies, but if the \"off\" switch was set it could return NoOpPolicy for every Policy (taking Polly out of the mix).\n\nPossible extensions to Polly\nonBreakerRejected for CircuitBreaker\nWe would be happy to take a PR to add a delegate hook onBreakerRejected , which would operate in a similar way to onBulkheadRejected.  If you/anyone want to contribute this, then I can kick-start by staking out the likely new overload signatures.\n\n\nhappy to expand on this to explain in more depth what sort of things would be of interest\n\nVery happy to hear more .... @bartelink A lot of great points in here again (thank you!).  I'll hope to respond/x-ref in extra detail later, especially when things we might do in Polly converge with this.  Briefly (to get you some initial / overview responses):\n\n\nonTimeoutRejected: I think what you're describing already exists as the onTimeout/onTimeoutAsync delegate of the timeout policies.  Does that help? \n\n\nA number of the proposals (onScheduled; capturing timing information) are a close fit with things we want to do when adding metrics deeper into Polly. If/when/as-soon-as I can get time to progress that, it would be great to bring you (and anyone interested) back in on the discussion of, eg, the touchpoints for emitting events from each policy. (And indeed dev help may be useful too!).\n\n\nKeeping this briefer to keep things moving, but lots to come back to here.. :+1: .  The concept I have for metrics has an OverallExecutionOutcome event (or similar) which sounds like a close overlap for this.  It intends to encompass both overall execution duration and possible inner causes of failure (eg bulkhead rejection occurred; timeout occurred; user code executed caused this error; etc).  Very helpful to hear your needs/perspectives above: let's cross-check again when I can get closer to this.. @paulomorgado This looks very useful: thank you for taking on the build metadata improvements!\nThe PR looks to include a number of different concerns in the same PR (build metadata; project reorganisation; code style changes). Would you be happy to present just the build metadata changes in a first PR?  It would be awesome to get those benefits (cf #464) merged for the Polly community!  \n(Otherwise it will have to wait until / depend on we agree all the other changes.)\nThank you again for contributing to Polly!. Closing in favour of #504 and #502 . . @citrus7 Great question. ( /cc @stevejgordon, I think you also suggested/asked something similar once)\nYou can make Polly not cache a returned result by configuring CachePolicy with a ResultTtl (a strategy which determines the ttl to apply based on the result returned), such that it returns TimeSpan.Zero ttl for items you don't want to cache:\nFunc<Context, HttpResponseMessage, Ttl> cacheOnly200OKfilter =\n    (context, result) => new Ttl(\n        timeSpan: result.StatusCode == HttpStatusCode.OK ? TimeSpan.FromMinutes(5) : TimeSpan.Zero, \n        slidingExpiration: /* whether you want sliding expiration for the cached cases */\n    );\n\nIAsyncPolicy<HttpResponseMessage> cacheOnly200OKpolicy = \n    Policy.CacheAsync<HttpResponseMessage>(\n        cacheProvider: /* whatever cache provider you are using */,\n        ttlStrategy: new ResultTtl(cacheOnly200OKfilter),\n        onCacheError: /* whatever cache error logging */\n    ); // or whatever richer CacheAsync overload taking an ITtlStrategy ttlStrategy\n\nWhen the ITtlStrategy returns TimeSpan.Zero as the ttl, the policy intentionally doesn't even attempt to put the item to the cache. In other words, this is certain (not just lucky due to timing) to prevent such items being cached.\n\nEDITED: for syntax. For future ref: It would be easily also to handle selective caching natively within Polly: this example commit shows a pattern (only applied to the async implementation and a single new overload).  However, we would need carefully to consider how many policy configuration overloads should be added: current policy configuration syntax promotes a proliferation of overloads. \nFor now, documented the above ResultTtl : ITtlStrategy approach, which works well.. Interesting question and ideas @mebjas  - I had similar ideas in the past (as discussed with @joelhulen / @jhalterman / others) that the Polly architecture could be used for fault-injection. \nObviously there are established solutions in the market for mocking third-party endpoints, like Mountebank or Wiremock; and likewise many tools for disrupting traffic/terminating instances etc at the broader container or cloud infrastructure layer.  But fault-injection within Polly could perhaps complement and serve different use cases:\n\nInjecting faults via Polly by definition would happen in-process.  This means no external infrastructure/tool/http-interception needed. \nFor the dev/test phase, easy to mock failure of a dependency to test the envisaged Polly strategy or other response.\nNot all services are amenable to http mocking through tools such as Mountebank or Wiremock, eg if you are calling some Azure/AWS service through the AWS or Azure SDK.\nSimulating failure of a dependency in process does allow you to simulate that failure for a specific consumer/group-of-consumers without actually killing the real dependency or necessarily killing it for all consumers.  \n\nIt would be relatively easy to implement in Polly - ideas coming in a follow-up post.\n. \nFault injection proposal for Polly\nFor non-generic Polly policies:\nc#\nvar chaosPolicy = Policy.InjectFault(\n    Exception | Func<Context, Exception> fault,  // The fault to inject\n    decimal | Func<Context, decimal> injectionRate, // A decimal between 0 and 1 inclusive.  The policy will inject the fault, randomly, that proportion of the time, eg 0.01 means inject the fault randomly 1% of the time.\n    Func<Context, bool> enabled // Faults are only injected when returns true.\n);\nBy decimal | Func<decimal>, I mean an overload offering this parameter simply as decimal, and another overload offering it as Func<decimal>.\nFor generic Policy<TResult> policies governing executions returning TResult:\nSame as above, but in addition to the Exception options, there would also be overloads offering the following three options for the fault parameter:\n\nTResult fault\nFunc<Context, TResult> fault\nFunc<Context, DelegateResult<TResult>> fault\nThis last one gives the ability to build an InjectFault policy which sometimes injects an exception, sometimes a return result (eg http calls may fail with exception or an http status code).\n\nOperation\n\nIf enabled(...) returns true, and if a random number between 0 and 1 is less than injectionRate, return or throw the fault instead of executing the delegate passed to the policy for execution.\nOtherwise execute the passed delegate as normal.\n\nUsage\nTypical usage would probably be to configure a InjectFault policy as the innermost part of a PolicyWrap (so it is closest to where the passed delegate would normally execute):\nPolicy.WrapAsync(retry, breaker, timeout, faultInject)\n\nWhen InjectFault didn't inject a fault but merely acted as a pass-through, its performance should be comparable to NoOpPolicy: this has been benchmarked as adding approx 1microsecond (1 millionth of a second) to a call.\nIt would also be possible to use dynamic configuration during running to include or exclude the InjectFaultPolicy altogether, if desired.\nThe Func<Context, ...> signatures of all parameters would allow fine-grained control of instances or calls participating in the simulated faults, and indeed of the simulated faults themselves.  Polly.Context can be set up with any custom input data; this could be eg drawn from configuration or environment variables, to control when, whether and how instances participate in the simulation.\n\nThoughts?\nWhat do people think? How can we improve on this proposal?\nI am going to mark this 'up-for-grabs' as it is very simple to implement following existing Polly patterns (great way for others to get involved in the proj), and I want to focus my Polly time on features such as Distributed Breaker which depend more on existing deep Polly knowledge.  This would be an awesome feature for a new contributor to get public acknowledgment!\nThe parts to implement a policy are described here.  A simple way to implement this would be to copy-and-rename all the parts for NoOpPolicy and then start adding the functionality described above.\n. ## Latency injection proposal\nAnother obvious failure injection would be latency:\nc#\nvar latencyPolicy = Policy.InjectLatency(\n    TimeSpan | Func<Context, Timespan> latency, // The latency to inject.\n    decimal | Func<Context, decimal> injectionRate, // A decimal between 0 and 1 (inclusive).  The policy will inject the latency, randomly, that proportion of the time, eg 0.01 means inject latency 1% of the time.\n    Func<Context, bool> enabled // Latency is only injected when returns true.\n);\nOperation\n\nIf enabled returns true, and if a random number between 0 and 1 is less than injectionRate, pause for the specified latency.\nThen execute the passed delegate as normal.\n\nQuestions\n\nShould the policy pause, then execute the passed delegate?  Or should it execute the passed delegate, obtain the result, then pause before returning the result or failure?  Are there any use cases where it makes any difference?\n. @vany0114 @mebjas  I think you have both volunteered to work on this.  Is there the option to maybe take one policy (of InjectFault; InjectLatency) each, and review each other's contribution? (I will review too). Or find some other way to collaborate? (Open to suggestions...).  Thank you both for your enthusiasm!. @mebjas Very interesting comment above - I was typing my generalisation/abstraction idea simultaneously. I will still post it (below) and we can all consider further.\n\n\n@mebjas This is a great question! :\n\nIsn't this [latency] just another type of fault. If the fault could be passed as an argument we need not write individual classes for each then. \n\nWe could consider two separate questions:\n(a) is the concept of Policy.InjectLatency(...) a primary-enough concept in chaos-engineering, that it is worth providing this direct syntax for?\n(b) is there enough commonality of functionality, that we can use a common class (or abstract base class) for the features discussed in this thread?\nRe (a), my thought was that latency-injection is a primary-enough concept that it is worth providing some simple/obvious public syntax, even if we (b) generalise the implementation internally.\nRe (b), I had the thought yesterday that we could generalise both cases by abstracting out the general injection concept, something like:\nC#\n    Policy.InjectBehaviour( // Or: InjectCustom // Or just: Inject\n        Func<Context, CancellationToken, (DelegateResult<TResult>, bool)> preExecute, \n            // The DelegateResult<TResult> output parameter of preExecute is an _optional_ substitute result (which would replace executing the passed delegate). \n            // The bool output parameter of preExecute is whether to use this replacement result, or call as normal the delegate which was passed to .Execute/Async(...).\n        Func<Context, CancellationToken, DelegateResult<TResult>, DelegateResult<TResult>> postExecute, \n            // The input DelegateResult<TResult> parameter is the result from executing the delegate passed for execution by .Execute/Async(...). \n            // The output DelegateResult<TResult> parameter ... allows postExecute to augment, extend, or even replace the original obtained result.\n        Func<Context, bool> isOperative\n           // ... encapsulates any logic (however complex) \n    );\nMaybe it's easier to communicate that the synchronous implementation (BehaviourInjectionPolicyEngine) would be something like:\ninternal static TResult Implementation<TResult>(Func<Context, CancellationToken, TResult> action, Context context, CancellationToken cancellationToken, Func<Context, CancellationToken, (DelegateResult<TResult>, bool)> preExecute, Func<Context, CancellationToken, DelegateResult<TResult>, DelegateResult<TResult>> postExecute,  Func<Context, bool> isOperative)\n{\n    if (!isOperative(context)) return action(context, cancellationToken);\n\n    (DelegateResult<TResult> result, bool substitute) preExecuteResult = preExecute(context, cancellationToken);\n\n    if (preExecuteResult.substitute) return preExecuteResult.result;\n\n    DelegateResult<TResult> normalExecutionResult = action(context, cancellationToken);\n\n    return postExecute(context, cancellationToken, normalExecutionResult);\n}\n\nThis builds a generalised pre-execution-injection and post-execution-injection architecture, which users could repurpose for any means they want (if we exposed it publicly, not just as a hidden abstract base-class). Maybe they want to use postExecute to augment results returned from a particular call.  Maybe they want some custom logging in postExecute without having to use FallbackPolicy as a logging workaround.  \n\nI don't have an immediate preference - first, just sharing ideas, and we can all reflect.. ( Apologies: poss some mistakes in syntax around whether some of the return values are DelegateResult<TResult> or just TResult in the example above, but it's to illustrate the concept. I can correct tomorrow. ). Thanks @mebjas @vany0114 both. I will review the code pushed so far and then advise further!. Liking a lot of the thinking in / behind this, @bartelink !  (Some things we mby have slightly different style to do in Polly, but I can cover that off, it's awesome just to hear all the ideas/intent so that we can aim to meet them and/or doco how to achieve.)  Longer response to follow ... \nThanks for all the awesome input/contribs on this thread folks - keep it coming!. @mebjas @vany0114 @bartelink Thanks again for all the great input/contributions! I am on the road rest of week but will aim to look at this one of the evenings if events allow.. Thanks @mebjas ! Now looking at this.. Thanks again @mebjas for #508 ! (comments posted there).\n@mebjas @bartelink @vany0114 / anyone: suggest we let @mebjas (and @vany0114 ?) get this to fully functionally tested, then return to any more philosophical questions about scope, naming, abstract base classes etc from this thread ... (tho all detailed comment/review/sugg re WIP on #508 welcome in the meantime!).  Thanks.  \n. @vany0114 Cool. Probably worth letting @mebjas finish his part before beginning yours.. Thank you @mebjas ! I will review as soon as possible.. Cross-posting to catch anybody who has contributed to / is following / later reads this thread: we propose to promote the chaos-engineering dimension to its own package.. Anyone interested in the chaos-engineering functionality (/cc @martincostello / @bartelink / anyone!), please see the new Simmy repo where the functionality is being finalised.\nComment welcome on any of the Issues there!  A few issues represent remaining minor API enhancements I would like to get in place before a v0.1 release. \nSome issues shape the API and there is some particular request for community feedback.. Hi @grik001  \n\nIs it possible to throw the exception if the final Retry Fails?\n\nThat is exactly what the library does by default - see how retry works in the wiki.\nLet me know if I've not understood the question, and you're after something slightly different!. Hi @grik001 . Happy to look at any code if you can post a repro.  Here within Polly is a unit test demonstrating that WaitAndRetryAsync does rethrow the final exception.\nCouple of things that could cause a final exception not to be rethrown:\n\n.ExecuteAsync(...), like any async API, returns Task. If the result of .ExecuteAsync(...) isn't awaited, then the exception will remain captured on the Task rather than rethrown.\nIf using .ExecuteAndCaptureAsync(...), then the design intent of that is to capture any final exception into the FinalException property.  .ExecuteAndCaptureAsync(...) captures any final exception, whereas .ExecuteAsync(...) rethrows it.\n. No problem @grik001 ! Let us know if there is anything else we can help with.. @paulomorgado Thank you for this and for pulling it into a separate PR.  \n\nIs this still failing for you locally? (Is strong name signer still removing the source linking info?). My local Polly\\Tools folder contained an older version 2.1.3 of Brutal.Dev.StrongNameSigner which pre-dated the necessary Mono.Cecil fix.  Just deleting the Tools\\Brutal.Dev.StrongNameSigner folder and re-running cake build caused the latest StrongNameSigner v2.3.0 to be pulled, which should fix this.  \nIs the same good your end? Or is the StrongNameSigner thing still an issue?. > @reisenberger, compare \n@paulomorgado. Yes, my yesterday's reply was based on a quick read of the correspondence across the tool projects.  I see, on running it up, what you are saying.\nSo the cecil proj is saying this is fixed, Brutal.Dev.StrongNameSigner is referencing the latest version of Cecil but we are still experiencing the problem.\nWe are not tied to using brutaldev/StrongNameSigner for strong-naming; that was useful for packaging when we were shipping both non-strong-named and strong-named, but we now ship strong-named only.\nThank you for everything you are doing on this!. > #504 Do you have any clue to why the tests are failing for .NET Framework runtimes?\nOut of time to look at that today, but we can dig deeper soon.. @paulomorgado We can remove Brutal.Dev.StrongNameSigner from the mix with a commit like this.. I worked through a bunch of further issues with adding SourceLink.  It suggests:\n\nwe need to remove Brutal.Dev.StrongNameSigner per my previous comment\nwe need to replace direct call to nuget pack with dotnet pack, as inserting the new <repository commit=\"{specific-sha}\"> attribute in the nupkg relies on this, afaics\nfor dotnet pack to play well with the multi-targeting, we likely want to merge #504 first; and will have to change a bunch of other parts of the build script\n\nIn general, given Polly no longer targets any .NET Framework targets since v6.0, it would be an opportunity to overhaul the cake build script and move it to dotnet cli throughout.\nTL;DR This PR sits behind #504.\n. Noting here also that MS intend to further evolve the whole story around debug-linking for nuget packages: https://github.com/NuGet/Home/wiki/NuGet-Package-Debugging-&-Symbols-Improvements \nEDIT: Seems the first sample tooling for the new .snupkg format is in VS2017 v15.9.0 Preview 5\nEDIT: snupkg tooling now live, but early days, and the MS OSS library guidance hasn't moved yet away from Sourcelink. This PR was unexpectedly automatically closed by github, when deleting a (now-outdated) base branch which the PR targeted .  \nWe still intend to add source linking, though it will now have to be based off the new Polly v7.0.0, and address the issues previously identified here\nThanks @paulomorgado for all you originally did on this! We will revert when we are ready to add source linking. I will be reviewing next work items after Polly v7.0.0 and Simmy are both released.. @aaron-hammond Good question.  At the moment, yes, the syntax dictates that the entire Policy is defined in one hit when first config'd - including the behaviour-extending delegates such as onCacheError. \nYou can use Context though to pass information to vary the behaviour of the onCacheError delegate for particular call sites or executions.  The onCacheError delegate takes Context as an input parameter, you're supplying a Context to every execution, and you can attach (and retrieve) any arbitrary data to that Context using its dictionary semantics.  Does that help your particular goal?\n\nWider background: We've considered at times pulling the entire policy-config syntax apart, eg to move attaching some of that delegate behaviour to execution-despatch time, but it would be major changes (both to code up and for library consumers), and it can cut both ways (often you just want the same onX delegate in all cases, eg to attach some standard logging).  \nInterested in further feedback if the above doesn't help.. @paulomorgado Thanks again for your time on this!\nRe the test failures : it appears that the compiler or JITter is inlining a method when the tests are run with dotnet test; but not when run via the Visual Studio test runner.  If we attribute\n[MethodImpl(MethodImplOptions.NoInlining)]\n\non this method, then the tests should pass consistently (they do for me from dotnet test locally).\nI had trouble with the VS Test experience within Visual Studio for this kind of multi-targeting (will try to post more details - might have an issue/suggestions to raise against VSTest). Control and visibility of which target is running the tests was clearer via ReSharper.\nFew more things to check - but solution consolidation seems very positive.. That's a useful point to come back to on the production side (thanks for the reminder). On the test side, there can be trade-offs between performance and readability. These tests cover #270. The essence of the test is to assert where the exception expresses as thrown from, and that may be more immediately grokkable as a named method than inlined.\nIf we inline, the assert might end up something like:\npolicy.Invoking(p => p.Execute(() => { throw exception; }))\n    .ShouldThrow<AggregateException>()\n    .WithMessage(exception.Message)\n    .WithInnerException<NotImplementedException>()\n    .Where(ex => IsAnonymousClosureWithinThisType(new StackTrace(ex, false).GetFrames()[0].GetMethod()));\n\nwhere:\nprivate bool IsAnonymousClosureWithinThisType(MethodBase method)\n{\n    return method.DeclaringType.DeclaringType == GetType()\n           && method.DeclaringType.GetCustomAttribute<CompilerGeneratedAttribute>() != null;\n}\n\n(but NetStandard1_1 doesn't support all this; and I would prefer not to assert on the string-forms of the way the compiler currently renders lambdas)\nIf we choose not to inline, the assert might express its purpose like this (renaming the method to Foo_ThrowsException() and attributing [MethodImpl(MethodImplOptions.NoInlining)]) :\npolicy.Invoking(p => p.Execute(() => Foo_ThrowsException(exception)))\n    .ShouldThrow<AggregateException>()\n    .WithMessage(exception.Message)\n    .WithInnerException<NotImplementedException>()\n    .Where(ex => new StackTrace(ex, false).GetFrames()[0].GetMethod().Name == nameof(Foo_ThrowsException));\n\n(new StackTrace(ex, false).GetFrames()[0] stems from the narrower overloads offered by System.Diagnostics.StackTrace v4.3.0 for NetStandard1_1)\nLooking at the above, my feeling is that the clarity of test intent in the latter is more valuable to future devs coming to the codebase than any test performance gain from inlining (the method under consideration for inlining is used by 3 of 1700 tests).\nCurious if anyone knows any more elegant way. Let me know any further thoughts; otherwise, we can push something like that onto the PR.\nThanks for pitching in on Polly.. TL;DR For those not interested in the detail: The method under discussion for inlining is on the test side and used by only 3 of 1700 tests, so performance considerations are negligible. The essence of the test is to assert on where the exception is thrown from, and my feeling is that is clearer with a named method than inlined.\n. @paulomorgado Thanks again for this PR. I bumped the build version to achieve a green build, and re-targeted against the App-vNext:onV610dev base branch.  \nOther feature-adding PRs (508, 513, 517) progressed while the method inlining was under discussion, so we cannot merge this PR immediately as is.  I will review and select merge order.\n. Update; I am still holding (not merging) this PR while we have other significant PRs in the queue (508) with functionality built against the old project structure.\nHowever, we will make this change to simplify the project/folder structure and to fall into line with recent MS Open Source Project Guidance, as soon as the functionality PRs are merged.. This PR was unexpectedly automatically closed by github, when deleting a (now-outdated) base branch which the PR targeted .  \nI intend that we consolidate the solution (per this PR) as a next step shortly, before any further work on Polly.  This will also open up the path for sourcelink.  Thanks @paulomorgado for all you originally did on this! . @chrisckc Great question.  As you rightly observe:\n\na Polly.Context travels with each Polly execution, allowing information exchange between pre-execution, during-execution and post-execution.  \nthat Polly.Context is attached to the HttpRequestMessage, so that while the call through Polly is within the DelegatingHandler configured by HttpClientFactory, there is a bridge allowing you to obtain/set that Polly.Context via the HttpRequestMessage.\n\nI believe you are finding RequestMessage.Properties[PolicyExecutionContext] to be null after execution because, when we built the Polly-HttpClientFactory integration, we chose, for cleanliness, to clean it up if it was generated internally, not user-supplied.  \nIf you call request.SetPolicyExecutionContext(...) yourself on an HttpRequestMessage before passing it into a call through HttpClient, then the Polly.Context you supply will not be cleaned up, and you will still have access to it after execution. This may allow you to dispense with/simplify some of your info-capturing code.\nWhere your call into HttpClient is an overload such as await _client.GetAsync(resource), which doesn't directly take an HttpRequestMessage, then to use the above technique, you would of course have to replace that call with the underlying SendAsync call taking an HttpRequestMessage which it drills down to.  On that point we had no other option: overloads such as HttpClient.GetAsync(resource) understandably weren't up-for-grabs for modification to add Polly.Context.\nHope this helps. I haven't followed through all the reasons for the PollyInfo class in your example, but intuition suggests you may be able to replace that with an instance of Polly.Context which you create and pass into the execution.. Added this to the Polly and HttpClientFactory documentation.. @chrisckc  I haven't sight of the full code, so am guessing what requires the transfer of the gathered PollyInfo via the exception.Data[] dictionary.  Is the issue that, if the execution throws, then you can no longer obtain the Polly.Context via result.Result.RequestMessage.GetPolicyExecutionContext() ? \nIf so: With a pattern where you pass a Polly.Context into the execution yourself (as below) you have access to it everywhere post-execution because it's still in scope :\nvar context = new Polly.Context();\nHttpRequestMessage request = /* whatever */;\nrequest.SetPolicyExecutionContext(context);\n\ntry\n{\n    var result = await client.DoWhateverAsync(/* some overload taking HttpRequestMessage request */);\n}\ncatch\n{\n    // Handling for eventual error despite resilience strategies (unless you have already used a FallbackPolicy)\n\n    // Of course the variable `context` (the same `Polly.Context` instance that was passed to onRetryAsync that you added data to) is still in scope here\n}\n\n// And ditto `context` local variable obvs still available here\n\n(EDIT: Apologies if stating the obvious or missing the point, but without sight of full code I'm unsure why you need the exception.Data[].)\nBut the above approach does require you to use overloads on HttpClient which take an HttpRequestMessage as an input parameter. \n\nRe:\n\nIt would be useful if the Polly.Context could be automatically transferred into the Exception data\n\nWe could consider this but it would be a change in the Microsoft codebase here (at some future release), rather than in the Polly codebase. And it would necessitate an extra catch-and-rethrow, which would be a (minor) performance penalty, but a penalty paid by everybody using the codepath where a throw occurred, whether they were interested in the Polly.Context or not.  And there are patterns avoiding the need for it such as the one posted here (or the custom DelegatingHandler you created).\nWill keep this in mind but see if more users hit the same problem before we have the next dev round with the MS team.. Thanks @chrisckc ! Closing this out, as I think we have answered everything; and updated the doco to capture the learnt.. Umbrella or aggregating bulkhead: Not a broken idea. PolicyWrap is intentionally free-form enough to allow you to use the same type of Policy more than once in a wrap. \nPolicy selector: I can see mileage for this as a concept generalised outside the multi-bulkhead scenario.  We built something like this already in the Polly-HttpClientFactory integration, a dynamic, execution-time Policy selector and configuration overloads also to make that play easily with PolicyRegistry.  For HttpClientFactory the key discriminating input parameter was the HttpRequestMessage, but if we took this concept back into Polly that would naturally be Context. So we could probably have signatures like:\nPolicy.Selector(Func<Context, ISomePolicyInterfaceVariant> selector) // might need an overload for each return type ISyncPolicy, ISyncPolicy<TResult>, IAsyncPolicy and IAsyncPolicy<TResult>\nPolicy.Selector(Func<Context, IReadOnlyPolicyRegistry<TKey>, ISomePolicyInterfaceVariant> selector)\n\nInterested in community feedback - interest in this? other possible uses for it?. @mebjas Apart from minor review above we can move to adding tests \ud83d\udc4d (as you say).\nFor writing deterministic unit tests for the code involving randomisation, an approach could be similar to the way existing Polly tests involving time abstract SystemClock:\n\nAbstract out the randomiser in the same way Polly already abstracts out SystemClock.\nTests can then manipulate the abstracted dependency. In this case, tests could replace the randomiser with a deterministic implementation returning fixed values, for specific tests.\nWe attribute such test classes to ensure tests which manipulate these ambient contexts do not run in parallel and pollute each other. (Although loss of parallelism of test-running may seem a cost, the time-saving of eliminating real-time delays in wait and timeout tests far compensates.)\n\n(Time fits the ambient-context pattern for the dependency rather than constructor injection or property injection because there is a sensible local default and there are not known good use cases for varying the implementation in production. Similar arguments can apply to randomisation.)\n. @mebjas Thank you again for your contributions! Re:\n\nAbout the random function\n\nIf we adopt the same strategy as SystemClock, then in RandomGenerator we could have:\npublic static Func<Double> GetRandomNumber = () => rand.NextDouble();\n\nTests can then replace the Func<Double> to provide deterministic values eg:\nRandomGenerator.GetRandomNumber = () => 0.1;  // If this appears in a test, all calls to RandomGenerator.GetRandomNumber() in that test will return 0.1\n\nIt's important then to add this attribute to classes containing tests which manipulate RandomGenerator.GetRandomNumber in this way, to prevent these tests cross-polluting each other. \nAnd: the test class should be IDisposable with the Dispose() method using a RandomGenerator.Reset() method to reset the GetRandomNumber method.\npublic static void Reset()\n{\n    GetRandomNumber = () => rand.NextDouble();\n}\n\n(xUnit uses the Dispose() method to clean up after each individual test.)\nOverall, this is the same pattern you can see in use with tests manipulating SystemClock.\n\nI will aim to check your other qs and the overloads in the coming days.. Hi @mebjas . To force certain tests to not run in parallel, so that they don't cross-pollute:\n\nadd this attribute to classes containing tests which manipulate RandomGenerator.GetRandomNumber .\n\n(We should probably rename the attribute to something like: AmbientContextDependentTestCollection.). >Added the attribute. The attribute is being used in a lot of places. Should it be renamed in this PR?\nGreat, thanks!  I am happy if you want to leave the renaming to me as a clean-up pass after we have finished all the changes for v6.2.0.. @mebjas Many thanks! I expect to look at this at the weekend if I do not get any chance before.. Thanks @vany0114 for the extra eyes on this! . >Should we expose the MonkeyPolicy directly? if so, what's the reason to have the InjectFault ?\nI noticed also this duplication - we should likely eliminate it. I intend to review which/what to eliminate when doing a pass for naming of the new elements.. @mebjas Thank you for all the work you have done on this; a great contribution to Polly.\nI just pushed some quick minor changes (to get things moving from my side again):\n\nadded .ConfigureAwait(...) to every async call in the async engine\nseparated the test group which manipulates SystemClock, from those which manipulate RandomGenerator\n\nI think this is in a suitable state now for @vany0114 to add the InjectLatency(...) syntax, and tests around that (@vany0114 are you still good to do this?).  I see that there are some tests around the concept of injecting delay in the Monkey tests already - probably these should be pulled across to the new test classes for InjectLatency().\n@mebjas Re:\n\nWhat we could do is to remove the explicit Exception based overloads in the Monkey policies;\nThus Monkey Policies support only injection Action or Func and it's aync / context based overloads\n\nYes, this seems a good idea; please do.  \n@mebjas @vany0114 : I plan a final pass reviewing the exact naming of overloads / namespaces / base class, so I may change these later; but I will review this once all the code is in place.\n@mebjas I saw some tiny things in the tests that either you/I could tidy - may post small comment later - but looks good now for @vany0114 to proceed!\nThanks again to both of you for your contribution!. > > @mebjas I saw some tiny things in the tests that either you/I could tidy - may post small comment later\n\nSure feel free I'll pick them up.\n\nThanks @mebjas! So :\n\nContext : IDictionary<string, object>, so context[\"Enabled\"] = \"true\"; can simplify to context[\"Enabled\"] = true; (and similars), also simplifying code slightly when accessing values.\nWhere tests are named like Monkey_With_Context_Exception_Should_not_execute_user_delegate_1(), Monkey_With_Context_Exception_Should_not_execute_user_delegate_2(), etc, it would be nice to differentiate them instead with some scenario description like Monkey_With_Context_Exception_Should_not_execute_user_delegate_when_randomizer_invokes_fault_injection()\nIf the same Init() call (for test setup) is used by every test in the class, with xUnit we can just make that code the constructor of the class. (xUnit instantiates a separate instance of the class for each test).\nA small number of tests (eg Monkey_With_Context_Introduce_Delay_3()) look like two tests in one; it would be good to split into two tests.  \nIf the code of the two resulting tests is substantially similar, we could further consider (not essential) factoring down into 1 test with different input parameters, with the [Theory] attribute.  \nWhere tests have Thread.Sleep(200), we can eliminate actual sleep time by using SystemClock.Sleep(200); and overriding the abstracted SystemClock implementation just to record how it was asked to sleep for, like this test does.  If we do that, though, we will need to revert this commit of mine, (and maybe rename the single test collection something like AmbientContextDependentTestCollection).  If any one of the tests manipulates both RandomGenerator and SystemClock, that needs to never be parallelised with any test manipulating either, so they would all need to form part of one test collection.. >so can I work on this branch, right?\n\nI am happy for you work in this branch if @mebjas is. Your changes @vany0114 will be mostly additive, right? (syntax and tests for InjectLatency()), rather than changing what is there. And maybe you can move/borrow some of @mebjas 's tests around injecting delay (I proposed some small changes to those).. Hi @mebjas \n\n@reisenberger This is done; And removed corresponding tests\n\nThank you!\n\n@reisenberger I can do this, but yes the tests that uses it, most of them has dependence on RandomGenerator as well. \nWe'd need to create a new test collection here then right.\n\nI think the test project (with these tests in place) must declare only one named TestCollection named (say) AmbientContextDependentTestCollection.  And this test collection must contain all tests which manipulate either SystemClock or RandomGenerator or both.  xUnit gives us a named TestCollection to define a set of tests of which no test must be run in parallel with any other in the same set.  As soon as we have one test which manipulates both SystemClock and RandomGenerator, then those tests must not run in parallel against any test which manipulates either SystemClock or RandomGenerator, I think this means all tests which manipulate either or both need to end up in one single test collection. . First @mebjas , thank you again, because the test coverage is great \ud83d\udc4d . \n\nthe behavior of same policy and action when the parameter is true or false. Should they be part of different tests?\n\nMaybe only a style preference: I like to avoid a test with two Arrange-Act-Assert sequences (if they are not cumulative in some way like a circuit-breaker breaking then changing to the next state). But you identified the scenario precisely when you say it is the same test with different true/false parameter.  One way to do this with xUnit can be to use the Theory attribute to run different parameterised versions of the same test:\n```C#\n        [Theory]\n        [InlineData(false, false)]\n        [InlineData(true, true)]\n        public void Monkey_With_Context_Introduce_Delay_With_Fault_Lambda(bool whenContextSaysInjectFault, bool shouldDelay)\n        {\n            Context context = new Context {[\"ShouldFail\"] = whenContextSaysInjectFault};\n        Action<Context> fault = (ctx) =>\n        {\n            if ((bool)ctx[\"ShouldFail\"])\n            {\n                Thread.Sleep(200);\n            }\n        };\n\n        MonkeyPolicy policy = Policy.Monkey(fault, 0.6, () => true);\n        Boolean executed = false;\n\n        Stopwatch sw = new Stopwatch();\n        sw.Start();\n        policy.Execute((ctx) => { executed = true; }, context);\n        sw.Stop();\n\n        executed.Should().BeTrue();\n        (sw.ElapsedMilliseconds >= 200).Should().Be(shouldDelay);\n    }\n\n```\n(This is pretty much end-polishing - happy if you want to take it on or not - you have done the most important work by ensuring good test coverage!). Hi @vany0114 It looks like the test tolerance sw.Elapsed.Should().BeCloseTo(delay, Tolerance);, with private readonly int Tolerance = 15 is just too tight for some slower run environments.  I had some test failures on my local machine.  Things can run more slowly on AppVeyor particularly.  \nHowever, if we do this:\n\nWhere tests have Thread.Sleep(200), we can eliminate actual sleep time by using SystemClock.Sleep(200); and overriding the abstracted SystemClock implementation just to record how long it was asked to sleep for, like this test does. \n\nthen you can override SystemClock.Sleep/SleepAsync just to record precisely the amount requested to sleep for (instead of actually delay), so the tests can run quasi-instantly, and there will be no variability from fast- or slow-running on different environments.\nEDIT: Thanks for everything you are contributing on this!. Thank you @mebjas and @vany0114 for all your work on this. This is a great contribution. \nI want to have a think about the final naming/namespacing for the policies, do a final parse on the intellisense etc, so I will probably merge this to a branch and then possibly undertake (/propose, but I can do the work) some renaming. \n@vany0114 Have you signed the Contributor License Agreement?  When we decided you could commit also into this PR, I think it means that the CLA-enforcement bot maybe doesn't track that you have signed the CLA. Could you post a message here when you have signed the CLA? (if not already). Thanks!. >for this PR the bot didn't ask me.\nI don't know if that's because you are not the first originator of this PR or not, but anyway, because of this ...\n\nI already signed the CLA before in other contributions that I made for other projects, \nnot sure if you as a contributor only have to sign once, \n\nthat is fine; I understand from that that you have already signed the Dot Net Foundation CLA.  Thanks!.  @mebjas and @vany0114 I have merged-for-release Polly v6.1.1 (minor bug fix) ahead of this, to give us a clean slate to look at merging and naming of the fault-injection work.  I will resolve the minor merge conflict arising from that. Thanks.. @mebjas @vany0114 We will likely need to make sure the randomisation for fault injection takes account of the conversation here.  Waiting for the full benefit of that conversation running to a conclusion, then we should likely tune the RandomGenerator in this PR.. Thoughts on making Random thread-safe are converging to a possible recommendation for the chaos use case . \n@mebjas @vany0114  Comment welcome.  If you are happy with the recommendation in my link above, I am happy to push the changes onto this PR, as I already have ideas about naming to eg separate this from the slightly different Random implementation for jitter.. @vany0114 @mebjas  I have pushed onto the PR, a class ThreadSafeRandom_LockOncePerThread with a solution to thread-safe use of Random for the chaos use case.  Please let me know if happy or if any comments.  \n. @mebjas @vany0114 Thanks for your patience! (multiple strands going on with Polly at mo, and everything I give to Polly happens outside my paid work hours). \nPropose: We promote the chaos-engineering work to its own package\nI am recommending that we will promote the chaos-engineering work to its own package, to give it its own identity, name and profile.\nMain reason is to give each package a clear conceptual focus (this kind of clarity helps users grok things):\n\nPolly is about resilience\nXYZnewPackage (a \"sister\" package) is about chaos-engineering, fault-injection, fake-result-stubbing for unit-testing\n\nOther benefits are:\n\nwe can rev the new package independently (add/tweak without being held up by a PR backlog on Polly)\nkeeps the download size of Polly smaller for users who don't get into chaos-engineering\nwe can track usage separately\n\nDecisions\nPlease review this document which I wrote for other Polly/App-vNext stakeholders. Please let me know any views on naming for the new package! The current leading name is Simmy (by analogy with Simian = monkey-like, and simulates faults), but other suggestions welcome.  ( /cc @bartelink , you were interested in naming, too )\nPromotion/links between the two projects\nHaving a separate project is only to give clear identity.  We will want to promote Simmy (/whatever name) just as much in the Polly Readme, Wiki, blogs etc. It's a major feature! In fact we already added it to our latest slide deck which Carl Franklin just presented in Prague last week - check out slides 28-31.  ( EDIT: The syntax there was only TBC and to fit on the slides - not a change of syntax proposed. )\nLaunch process\n\nThe new package will need to be able to create Polly policies from outside the main Polly package. I have been building the bridge for this, in the form of a CustomPolicy type within Polly. Hoping to push a separate PR on this soon. Already proved the concept works. This CustomPolicy type is something I have wanted to do anyway for a while to open up a broader Polly.Contrib. It would be MonkeyPolicy : CustomPolicy : Policy, or maybe just MonkeyPolicy : Policy, so the MonkeyPolicy identity also is retained.\nI am considering that we still merge this PR (508) onto Polly, to give you @mebjas @vany0114 the benefit of the contributors commit credit; We could merge the PR in, then reverse-merge it out again.  \nI can do the grunt work of setting up the separate repo, build etc for the new project, and loading the code in (unless you want to) (but whatever, you would be listed eg in the readme as the main authors :grin: )\n\n\nPlease let me know any thoughts on the above, and thank you for everything you have contributed.\n. Thank you @mebjas @vany0114 @bartelink . Courtesy update: I am likely to next get a chunk of time to progress, in late December.\n. @mebjas @vany0114 I completed an extensive refactor of Polly (#552) to allow us to host policies outside Polly in a new manner.  I need to set up the new Simmy/Molly repo, then we can pull the code over there, and we can all pitch in on any final code clean-up and documentation!\n. >Is there any documentation on how this hosting policies outside polly looks like?\nI have rebased the PR onto v7.0.0 branch, and am aiming to push a commit to show how the policies would join to the new v7.0.0 approach.\nFull documentation (for the wider user community) will also follow.. @mebjas @vany0114  I was unable to push further changes to this PR, being today's modifications to bring everything into line with v7.0.0. (Maybe we have rebased the PR too many times ... not digging further now.)\nI have opened a separate PR #553 as a mechanism only to show you latest modifications:\n\nTie MonkeyPolicies into new way of integrating custom policies, Polly v7.0.0\nClasses InjectBehaviourPolicy, InjectOutcomePolicy and InjectLatencyPolicy, to fit this new pattern\nMove syntax to MonkeyPolicy.InjectFault(...)\nMove syntax to MonkeyPolicy.InjectLatency(...)\nMove syntax to MonkeyPolicy.InjectBehaviour(...)\nAdjust specs for above\nTests for functionality change: make it valid for InjectFault policies to dynamically inject null (no fault) \nTests for new guard conditions: fault-injection thresholds being out of range\n\n\nThanks for the huge amount of work you did @mebjas @vany0114 to get PR 508 to functionality-ready.  My last piece here bridges us to a way forward with Simmy as a separate package to Polly v7; and implements the syntax preferences described in the consulation document.\nAny comment welcome.\nNext steps (probably not before next weekend) : Set up the new Simmy repo and build; and move the code over to it.\nGiven the syntax preferences are done, I think the code as #553 is ready to go (in the new repo), bar trivial re-namespacing (namespace Simmy).  Will be good to get all your hard work released to the Polly public! \ud83d\udc4d . @mebjas @vany0114 Note: The state that #508 has got into due to repeated re-basing/upward merges, means we may not be able/be wise to do the merge/de-merge from to master on Polly (I'm not that happy about risking the state of the Polly master branch from this PR ...), but we will ensure that you get credit for this work all over the doco.  Thanks! . @vany0114 @mebjas , Courtesy update: I am working on the Polly v7.0 user documentation (custom policy documentation) which we need for launching v7 (which we need launched, in turn, for Simmy to reference Polly from the external repo).  . @mebjas @vany0114 / anyone interested: I created the new repo for Simmy!  Please head over!  If you are interested to take up any of the items marked help-wanted, that will speed us all along!  (Post on the issue to say anything you are picking up ...). Thanks!\nI am half-way thru the custom policy documentation, and will check in with something for all to read (and comment) soon as I can. Thanks!. Hi @mebjas Re:\n\nWhere are the documentations maintained? \n\nThe Readme and Wiki of this repo. We also sometimes blog.\n\nIs there a data for v7?\n\nThe readme directs people to sources of info on changes. Locking this thread so that conversation can relate to the latest issues and version of the codebase on the Simmy repo; interested users should head over there!\nIf anyone has concerns/questions about anything mentioned higher up this thread, please do mention it on Simmy or the design thread here on Polly.. Closing as this codebase now exists definitively in the Simmy repo, the readme now links out to Simmy and #499 still tracks on the issues page.. Thanks @hamish-rose for the exemplary report and repro code. I can reproduce this. Interestingly, if one executes instead the below (ignoring compiler warnings):\nawait policy.ExecuteAsync(async context => { throw new Exception(); }, new Context(\"ExecutingMethod\"));\n\nthe issue does not occur.\nIf my assumptions about the cause are correct, we should be able to push out a fix next week.  . The issue was (as I immediately suspected) async-await elision. Fixed in #513 . \n@hamish-rose : Is this a current production issue for you? If so, we can gladly push out a v6.1.1 with fix in coming days.  If not, I may hold to release as v6.2.0 with some of the other in-progress PRs.. @hamish-rose Thanks for the confirmation!. Fix merged to master. Will be live as soon as v6.1.1 is released to nuget. @Saphirox . Thank you for the full code of the policy declarations.  Please could you give a more specific description of the expected behaviour and the actual behaviour you are seeing and when the issue occurs?  When you say \"CircuitBreaker does not throw an exception when I use it with WaitAndRetry\", I am not clear what exception you are expecting and in what circumstances.  Thank you.\n. Thanks @Saphirox for the clarification.  Re: \n\nwhen retries would be expired, the circuit breaker should work, thereby it should throw CircuitBreakdownException\n\nNote:\n\nFor the action causing the circuit to trip, the original exception is rethrown, and the circuit state transitions to: Open\n\nas per the documentation.  The next call placed through the circuit after the circuit breaks (any call placed through the circuit while the circuit is broken)  will experience a BrokenCircuitException (provided the break duration of the circuit has not elapsed).  \nHere is a dotnetfiddle example demonstrating exactly the sequence of events, using Console.WriteLine(...) calls.. Thanks @Saphirox . Please reopen the issue or start another issue if you need any further assistance.. Hi @abjrcode . Please see our documentation on HttpClientFactory and timeouts which covers this. Summary: \n\nhttpClient.Timeout acts as an overall timeout across the whole execution (time for all tries and waits in between them).  When that timeout happens, it throws OperationCanceledException.  After this overall timeout httpClient.Timeout has occurred, no further retries of that execution can take place (the timeout has already cancelled the whole operation).  \nPolly TimeoutPolicy can be used as a timeout-per-try. To do this, it must be configured inside the RetryPolicy in the PolicyWrap or sequence of HttpDelegatingHandlers.  When TimeoutPolicy triggers a timeout, it throws TimeoutRejectedException.\n\n\nSo to obtain the expected behaviour stated in your question, keep your definitions of timeout and retry the same, but then either (this example uses PolicyWrap):\nvar teamcityHttpClientBuilder = services\n            .AddHttpClient<TeamCityClient>()\n            .AddPolicyHandler(retry.WrapAsync(timeout)); // Note: retry.WrapAsync(timeout), ie the opposite order from in your question.\n\nOr equivalently (this example uses nested DelegatingHandlers):\nvar teamcityHttpClientBuilder = services\n            .AddHttpClient<TeamCityClient>()\n            .AddPolicyHandler(retry)\n            .AddPolicyHandler(timeout);\n\nIn addition, you can:\nteamcityHttpClient.Timeout = /* whatever timeout you want for the whole operation, the combined time allowed for all tries and waits between tries */ ;\n\n\nThe behaviour will be as follows, compared to your last stated expectation 1 / 2 / 3 / 4:\n\n\nRequest is sent and a timeout happens if it takes more than 3 seconds\n\n\nYes.\n\n\nPolly captures that ~task canceled exception~ TimeoutRejectedException caused by the timeout and retries after 2^i where i = 3 now\n\n\nYes but it starts with i = 1. And it will be a TimeoutRejectedException (this is what Polly's TimeoutPolicy throws), rather than TaskCanceledException. Polly intentionally throws a different exception, TimeoutRejectedException, so that timeout cancellation can be distinguished from other cancellation.\n\n\nRepeat the previous step if another 3 second time out occurs with i = i-1\n\n\nretryAttempt increases, so this will be with i = i + 1\n\n4.Either succeed after all attempts or fail and return last HttpResponseMessage\n\nYes. Or it may fail and rethrow any exception which the last try failed with.. No problem, you're welcome. (holding merge until we decide in what order to take the PRs, but in principle ready). Thank you @zhouguoqing for sharing this and for joining the Polly conversation.\nTL;DR:\n\nThe thread pool behaviour which the StackOverflow question demonstrates is known behaviour of the .NET threadpool and not connected to Polly TimeoutPolicy.\nThe change proposed to TimeoutEngine makes no difference to the way actionTask executes: it does not control actionTask execute time.\n\n\nThreadpool behaviour\n\nThe thread pool behaviour which the StackOverflow question demonstrates is known behaviour of the .NET threadpool and not specifically connected to Polly TimeoutPolicy. If you take TimeoutPolicy out of the code in the StackOverflow question, you should still see thread starvation.\nBy default, the initial value of ThreadPool MinThreads is set to the number of cores on the system. This probably explains the rapid execution seen for the first 8 parallel operations in the StackOverflow question.  After that, the default .NET ThreadPool implementation injects one new thread per half second (500ms), or more frequently if other threads become free more quickly. (That is a brief explanation. Matt Warren has blogged this good explanation of the Thread Pool's algorithms and some Microsoft documentation is here.)\nYes, ThreadPool.SetMinThreads() is one way to force the ThreadPool to creating a greater number of threads initially (notwithstanding the Microsoft caveats), if you consciously want a greater number of operations to start in parallel without waiting for ThreadPool injection to inject more threads.\nPolly's TimeoutPolicy does not interact with the ThreadPool, except that TimeoutStrategy.Pessimistic on synchronous executions consumes an extra ThreadPool thread, as we explicitly document.\n\n\nThe proposed change\nThe change proposed to TimeoutEngine proposes:\n//Add timeout parameter to control actionTask execute time!\nactionTask.Wait(Convert.ToInt32(timeout.TotalMilliseconds), timeoutCancellationTokenSource.Token);\n\ninstead of:\nactionTask.Wait(timeoutCancellationTokenSource.Token);\n\nThis change has no effect on the way actionTask executes: it does not control actionTask execute time.  This can be verified with the following code:\npublic static void Main()\n{\n    const int sleepMs = 200;\n    const int timeoutMs = 10;\n\n    Action work = () => Thread.Sleep(sleepMs);\n    long before = Stopwatch.GetTimestamp();\n    Task showWhatHappensToWork = Task.Run(work).ContinueWith(t =>\n    {\n        long elapsedUntilWorkCompleted = (Stopwatch.GetTimestamp() - before) /  TimeSpan.TicksPerMillisecond;\n        Console.WriteLine(\"After \" + elapsedUntilWorkCompleted.ToString(\"D3\") + \" ms: Work \" + (t.IsFaulted ? \"faulted\" : (t.IsCanceled ? \"canceled\" : \"completed (was not canceled)\")));\n    }\n    );\n\n    showWhatHappensToWork.Wait(timeoutMs);\n\n    long elapsedUntilStoppedWaiting = (Stopwatch.GetTimestamp() - before) /  TimeSpan.TicksPerMillisecond;\n    Console.WriteLine(\"After \" + elapsedUntilStoppedWaiting.ToString(\"D3\") + \" ms: Stopped waiting (walked away from waiting).\" );\n\n    showWhatHappensToWork.Wait(); // To allow work enough time to complete, and Console.Writeline() its output.\n}\n\nThis code can be tried in dotnetfiddle here.  Note that .Wait(timeoutMs) does not make work terminate any sooner. It still runs to completed (was not canceled) at around 200ms.  This is the behaviour we discuss in TimeoutPolicy documentation under What happens to the timed-out delegate?.\nAll of the available Task.Wait() overloads merely control how long the calling thread will wait for the Task instance to complete, after which time the calling thread walks away from waiting (i.e. stops waiting), as we document for TimeoutPolicy. None of the Task.Wait() overloads terminate the work represented by the Task instance being .Wait()-ed.\nactionTask.Wait(Convert.ToInt32(timeout.TotalMilliseconds), timeoutCancellationTokenSource.Token) will just provide two different timing mechanisms, and these two timing mechanisms will race each other to trigger the walking-away-from-waiting,\n\nHope that helps, but please let me know if I have misunderstood the intention of the suggestion, or if you think you are seeing any behaviour that doesn't fit with this explanation.\n. @AJPoulter Yes, the use of a Polly policy in DelegatingHandler middleware of HttpClient - which is what the .NET Core 2.1 HttpClientFactory extensions configure -  is fundamentally incompatible with .ExecuteAndCaptureAsync(). And this is not something the Polly team can change, unfortunately.  \nThe reason is that extending DelegatingHandler requires overriding a method of signature \nasync Task<HttpResponseMessage> SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n\nIf the call through the Polly policy was changed to .ExecuteAndCaptureAsync(), that would change the return type to Task<PolicyResult<HttpResponseMessage>> - breaking the signature of SendAsync(...) and thus not correctly overriding DelegatingHandler.\n(It would only be possible if Microsoft chose to implement another outgoing codepath through HttpClient based on Polly's PolicyResult<T>, ie tightly coupled to Polly at the HttpClient level, which I don't expect to happen.)\n\nWhat options does that leave for your case?  If you already have a good solution with PolicyWrap and .ExecuteAndCaptureAsync(...), it may be as well to stick with that.  If you want to take advantage of the out-of-box definition of .AddTransientHttpErrorPolicy(...) (ie the definition of which faults that handles), then we provide that separately from HttpClientFactory, here as we document here.  The caveat with using Polly policies on calls through HttpClient without taking the DelegatingHandler approach is that retries can fall foul of the exception that an HttpRequestMessage cannot be re-used once sent.\nIf you want to adapt your existing DAL code to a .NET Core DI -style approach, configuring policies in StartUp.cs, then that is fairly trivial to do.  Configure a PolicyRegistry and add policies to it during StartUp.cs, as exemplified here.  Also register an IReadOnlyPolicyRegistry or IReadOnlyPolicyRegistry<T> during startup, have your DAL layer receive that IReadOnlyPolicyRegistry<T> by DI, and the DAL layer then extracts the policy it needs from the IReadOnlyPolicyRegistry<T>.\nHope that helps.\n. Polly.Context.CorrelationId is not user-settable. This allows Polly to be sure that it is unique (and immutable) per execution through a PolicyWrap, intended to allow future aggregation of policy events by execution.\nContext however has full Dictionary-like semantics: you can attach whatever custom data you like to it.  \nIf you are working the HttpClientFactory in .Net Core 2.1, follow our documentation: Polly and HttpClientFactory: Exchanging information between policy execution and calling code.\nIf you are not working with HttpClientFactory, follow our standard ReadMe documentation on executing through a Policy, passing in custom context information.\nLet us know if that helps.. @toddmeinershagen Re:\n\nHappily, I found that Policy.TimeoutAsync() works, just not in the context of the HttpClientFactory\n\nDoes our documentation on using TimeoutPolicy with HttpClientFactory help with the behaviour you are seeing?. Thanks @toddmeinershagen for the great spot \ud83d\udc40 and bringing this test into line with others with .Should/ShouldNotThrow<>()! Happy also with the idea to express a Task.Delay within the test (expresses the test intent more clearly).\nIf you want to work this into a full PR, we should:\n\nFix other instances of Should_not_throw_when_timeout_is_greater_than_execution_duration__optimistic() in the solution (async-TResult case; and two sync cases) similarly.\nFix 4x Should_not_throw_when_timeout_is_greater_than_execution_duration__pessimistic() similarly.\nBut instead of Task.Delay, use SystemClock.Sleep(...) or SystemClock.SleepAsync(...) (as appropriate) in each case.  Explanation: The timeout implementations abstract the notion of time-based cancellation and the timeout tests use and manipulate the abstraction of our abstracted system clock, with a simulated cancel-when-time-passes mechanism, in order that we can make the timeout tests run quasi-instantaneously rather than incur real time delays.  (For a single test the saving of 500ms may not seem much, but these principles across the whole test codebase of ~1700 tests drove test execution time down from order-of-10-minutes to ~30 seconds.)\n\n(If you're not available/interested to take that on, I'll tidy it in due course.)\n. @toddmeinershagen I have retargeted this PR against the onV610dev branch.\n\nI think I got all of the changes that you suggested.\n\nThere are similar tests Should_not_throw_when_timeout_is_greater_than_execution_duration__optimistic() and Should_not_throw_when_timeout_is_greater_than_execution_duration__pessimistic() [EDIT] in TimeoutSpecs.cs and TimeoutTResultSpecs.cs which it would be good to make consistent with the async changes (ie add some SystemClock.Sleep(...) shorter than the configured timeout).  Are you happy to add those?\nThank you for contributing to Polly!. @toddmeinershagen You will also need to sign the CLA agreement in order for us to be able to use your changes (this is policy for .NET Foundation projects).  Many thanks.. @toddmeinershagen Thank you. No problem; we understand corporate legal departments need to see this.. @toddmeinershagen Thank you for your contribution to Polly!  Merged to the dev branch!. @toddmeinershagen Thanks for raising this.  I cannot reproduce the issue stated in #517:\n\nadding a Policy.TimeoutAsync() to HttpClientFactory (from the AddPolicy() extension method in Microsoft.Extensions.Http.Polly library) \ndoes not allow the HttpClient to do its work and always ends up timing out.\n\nIf I use the code posted below (run simply as a .NET Core 2.1 Console Application), the execution does not hang.  \nConversely, if I switch client.BaseAddress (in the below code) to some invalid URL and set, eg, timeoutPolicy = Policy.TimeoutAsync<HttpResponseMessage>(TimeSpan.FromMilliSeconds(1));, I get a timeout as expected.\nCan you identify anything different between the code you are using, and the below sample? Or: does the sample below hang for you? Or: Are you able to provide repro code for the issue you are seeing? \n```\nusing System;\nusing System.Net.Http;\nusing System.Threading;\nusing System.Threading.Tasks;\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Hosting;\nusing Polly;\nnamespace PollyWithHttpClientFactoryInAConsole\n{\n    class Program\n    {\n        static async Task Main(string[] args)\n        {\n            var builder = new HostBuilder()\n                .ConfigureServices((hostContext, services) =>\n                {\n                    IAsyncPolicy timeoutPolicy = Policy.TimeoutAsync(TimeSpan.FromSeconds(30));\n                services.AddHttpClient(\"GoogleClient\", client =>\n                {\n                    client.BaseAddress = new Uri(\"https://www.google.com\");\n                }).AddPolicyHandler(timeoutPolicy);\n\n                services.AddSingleton<IHostedService, ConsoleService>();\n            });\n\n        await builder.RunConsoleAsync();\n    }\n\n}\n\npublic class ConsoleService : IHostedService\n{\n    private IHttpClientFactory _httpClientFactory;\n    public ConsoleService(IHttpClientFactory httpClientFactory)\n    {\n        _httpClientFactory = httpClientFactory;\n    }\n\n    public async Task StartAsync(CancellationToken cancellationToken)\n    {\n        await MakeRequestsToRemoteService();\n    }\n\n    public async Task MakeRequestsToRemoteService()\n    {\n        HttpClient httpClient = _httpClientFactory.CreateClient(\"GoogleClient\");\n\n        HttpResponseMessage response;\n        try\n        {\n            response = await httpClient.GetAsync(\"/\");\n        }\n        catch (Exception e)\n        {\n            Console.WriteLine(\"Failed with exception: \" + e);\n            return;\n        }\n\n        if (!response.IsSuccessStatusCode)\n        {\n            Console.WriteLine(\"Failed with status code: \" + response.StatusCode);\n        }\n        else\n        {\n            Console.WriteLine(\"Succeeded with status code: \" + response.StatusCode);\n        }\n    }\n\n    public Task StopAsync(CancellationToken cancellationToken)\n    {\n        return Task.CompletedTask;\n    }\n}\n\n}\n```. @toddmeinershagen Sure: You can zip the code up and email it over, upload the ZIP into this conversation, or create a GitHub gist consisting of the multiple files. \nMinimal code necessary to reproduce the issue - and eliminating other factors - is best. For instance, it would be good to eliminate the Azure function and be able to reproduce the issue for requests pointing at https://www.google.com. If we cannot reproduce it pointing at https://www.google.com, that could point at a problem simply with / with reaching the Azure function.\nWhen you see a timeout, what exception is thrown? Are you seeing TimeoutRejectedException, or OperationCanceledException?   HttpClient.Timeout property will also still be acting as an overall timeout (at the default of 100 seconds, if not modified from default).. @toddmeinershagen The configured TimeoutPolicy allows TimeSpan.FromSeconds(1) for the timeout.  What happens if you lengthen that timeout, to - just for the sake of testing - 30 seconds?  When you have the TimeoutPolicy commented out, how long does the call take to succeed?. @toddmeinershagen What happens if you set the timeout policy as follows? This policy will timeout at 1 second the first time, then allow a 30-second timeout for subsequent tries.\n    private static IAsyncPolicy<HttpResponseMessage> GetSharedTimeoutPolicy()\n    {\n        return Policy\n            .TimeoutAsync<HttpResponseMessage>(\n                ctx => \n                    !ctx.ContainsKey(\"subsequent\") \n                    ? TimeSpan.FromSeconds(1) \n                    : (TimeSpan)(ctx[\"subsequent\"] = TimeSpan.FromSeconds(30)), \n            onTimeoutAsync: async (context, timeoutPeriod, task) =>\n            {\n                await Console.Out.WriteLineAsync($\"timeout ({timeoutPeriod})\");\n            });\n    }\n\n. Thanks @toddmeinershagen for seeing the intent and making the obvious fix. (I was timing-slicing to get you quick suggestions)\nI am going to close out this item as we have demonstrated that neither TimeoutPolicy nor HttpClientFactory is implicated. (Never in doubt in my mind given all TimeoutPolicy does is execute an action with a fresh timing-out CancellationToken while HttpClientFactory simply executes the inner base.SendAsync(...) of the DelegatingHandler through the policy; but it helps to demonstrate.)  \nTo answer an earlier question:\n\nSince I don't control the performance of the Google site, [a timeout there] would be hard to control. (You may have some ideas about how to create that condition.)\n\nA simple option could be to append a DelegatingHandler into the HttpClient pipeline which blocks for a configurable amount of time. (We're actually looking at formalising this as a fault-injection policy in Polly.) Or set up a simple WebAPI endpoint which blocks, as we do in Polly-Samples,. @toddmeinershagen Haven't time to join you digging deeper at mo into the local Azure Function cold-start issues, unfortunately (time must go to other Polly issues), but interested what you find if you want to report back later.  Thoughts were that you might see if the same issue reproduces when the Azure function is run out of (say) a different Visual Studio instance; or indeed simply run up on Azure rather than locally.. Hi @SeanFarrow This suggestion seems useful for both reasons: happy to take a PR.\nI'm thinking IEnumerable<KeyValuePair<TKey, IsPolicy>> would be what it should implement (following the pattern of the dictionary-like semantics it already exposes).\nRe:\n\nwhat tests would be warranted?\n\nPolly's own concrete implementation PolicyRegistry implements IReadOnlyPolicyRegistry<string> indirectly, so it would certainly be necessary for the concrete PolicyRegistry to be extended to fulfil IEnumerable<KeyValuePair<TKey, IsPolicy>>, and for tests on that.  It could be nice also to have a test demonstrating the collection initializer syntax.. Happy with using Moq for this.. >What is the next planned version of Polly?\nWe could probably put out a next release (with this, 513 and 517) late this week or early next.  (I will scope 499/508 out of that release as dev time is longer). @SeanFarrow I am working towards a major release (v7) of Polly for first weeks of January.  If you wish to pick up this issue again and make a PR, we'd be happy to include that in V7.\nTo answer some previous points, re:\n\nWith the current design of IReadOnlyPolicyRegistry, we can't implement IEnumerable> as the T of IEnumerable is an out parameter and we are using TKey as an in.\n\nHappy to drop that out restriction for v7.\nRe:\n\nWould it make sense to restrict the IReadOnlyPolicyRegistry to use a string. Is there any reason why someone would use another type as the key?\n\nI don't think we need to restrict to string keys, to deliver the IEnumerable<KeyValuePair<TKey, ISPolicy>> and thus collection-initializer functionality. Let me know if there's something I'm missing, though.. Hi Sean. Re:\n\nHow early is \u201cearly January\u201d?\n\nA PR #552 is up to form the baseline for v7.0.0 (large PR, but doesn't affect PolicyRegistry); I expect to merge that likely tomorrow; you could target policy registry changes onto the v7.0.0 branch any time after that merge.  A goal is to publish v7 on Jan 5th or 6th, but it depends how my times falls - it could become a later weekend in Jan.\n. Hi Sean.  #552 has now been merged to the v7.0.0 branch and you can target any policy registry work onto that branch.\nRe:\n\nIs there a list as to what has changed for V7?\n\nYep. Our usual changelog covers this.  In short:\n\nA new route to creating custom policies outside Polly - doco to follow\nClarification of the sync/async split: full doco already on wiki. Thanks Sean!\n\nVery happy for any duplicate tests to be cleaned out.\nRe:\n\nI'm adding a constructor to the PolicyRegistry class that takes an IDictionary<TKey, IsPolicy>\n\nIf this is only to assist with testing, consider making that constructor internal so that we aren't adding API surface for public users.  But if we think there is a valid public use case for it, it can be public.\nThe test projects do all have access to the internals of Polly via the InternalsVisibleToAttribute, so tests would be able to access anything marked internal.  So that could apply for that constructor, and for the private property you mentioned needing reflection for too; consider marking it internal and tests will be able to see it.\nWill be easier to answer the q whether those tests are necessary once we have a PR up, I think\nThanks again!. Hi @SeanFarrow .  Re:\n\nShould we be using C# 6/7 features all over the codebase where it makes sense, given we are using vs2017 as a minimum IDE\nI'll raise an issue to cover both as it's work that could be done at the same time, it may not make it in to V7 though, as I may be starting a new job in the new year.\n\nVery happy to take a PR for any C# 6/7 features; thanks! (I take them in where I see opps, not had time to do a complete sweep.)\nSuggest we hold till after v7 is out, unless you plan a PR on that during this week.\nThanks again!. Thanks @SeanFarrow !  No problem about timing for anything; thank you for your contributions!\n+1 re performance profiling.\nThanks again.. I have an outline for how this could work. In the next few days I will aim to post (here or in the similar question in our slack channel), a minimal example, which you or the community may be able to build further on.. @umeshkarthik I have an outline for how this could work, but there are some significant potential caveats.\nThe main concern is that an action-filter solution would have to cache items of type IActionResult - but only some implementations of IActionResult represent static data which it makes sense to cache.\n\nFileContentResult and ContentResult do (for example) hold static data.  \nOther implementations of IActionResult do not hold static data: for example FileStreamResult.  \n\nBackground: The return type of a Controller method is an IActionResult and this is also the type that action filters must set when they short-circuit the execution. So the cache would have to cache (and return, on cache hit) items of type IActionResult.  But IActionResult implementations are in principle dynamic and would be reexecuted to generate the result, each time they are served from cache.\nTo illustrate some of the potential risks with FileStreamResult ... I have not tried this yet in practice but a number of concerns come to mind with the idea of caching (and re-serving a previously cached) FileStreamResult:\n\nIf it worked (functionally), it would in any case be inefficient, as re-serving the file from the file stream would re-read the file stream\nSome streams are forward-only, and may not be amenable to being read a second time.\nCaching something such as a FileStreamResult could constitute a resource leak - Stream is an IDisposable that is probably not intended to be long-lived in a cache.\n\nOther IActionResult implementations which might at first glance seem innocuous to cache also have minor issues.  For example, a JSonResult might be thought to be static data which is sensible to cache.  But caching a JSonResult would actually cache the raw underlying object (which might be unexpected or less efficient than caching the JSON string in some cases); and the json serialization would be re-executed on each serving from cache.\nTL;DR This does not mean an action-filter solution cannot be delivered; but it might only make sense for (might be best limited to) a small subset of static content types such as FileContentResult and ContentResult. Or if not, it would have to be used with deep understanding and care.\n@umeshkarthik It would be useful if you could post or state examples (eg method signatures) of the kinds of Controller methods you were thinking of decorating with an action filter.  And, given the above, is this still useful to you?. @umeshkarthik If you have an implementation with Polly CachePolicy around action filters we would love to see it and potentially share that with the community. I spent some time working on this following your request, and there were some interesting problems.\nRe:\n\nI need to serialize the result into a json format\n\nPlease see the documentation in the Polly wiki on serialization and the Polly.Caching.Serialization.Json library.. Closing this out as I think we covered this and a number of related issues in other posts.  However, please do open another issue if you require further assistance.. @umeshkarthik  All of the Ttl strategies you mention - RelativeTtl, SlidingTtl, ContextualTtl - provide a smaller subset of functionality than the ResultTtl which it looks like you are already using.  \n\nTo mimic SlidingTtl, just set IsSliding = true in the code you have already posted.\nTo mimic RelativeTtl, just pass the ts variable in the code you have already posted, as the timespan parameter.\n\nTo mimic ContextualTtl, you could change the Func<Context, IActionResult, Ttl> function you are defining to make use of data on the context parameter you are passing in.\n. Hi @umeshkarthik . Here is the sample code:\nFunc cacheOnly200OKfilter =\n    (context, result) => new Ttl(\n        timeSpan: result.StatusCode == HttpStatusCode.OK ? TimeSpan.FromMinutes(5) : TimeSpan.Zero,    //  this timespan is a relative ttl \n        slidingExpiration: false\n    );\nIAsyncPolicy cacheOnly200OKpolicy = \n    Policy.CacheAsync(\n        cacheProvider: / the cache provider you are using /,\n        ttlStrategy: new ResultTtl(cacheOnly200OKfilter),\n        onCacheError: / whatever cache error logging /\n    ); // (or other richer CacheAsync overload taking an ITtlStrategy ttlStrategy)\n\n\n(this is the example from here adjusted to slidingExpiration: false; same concept as the code you posted above)\nThis policy will cache items with a relative time-to-live of 5 minutes (they will be kept for 5-minutes from the time of putting into the cache), provided the return value's StatusCode == HttpStatusCode.OK.  This code sample is exactly what you ask for:\n\na cache policy with relative Ttl which only caches ok result\n\nThe code sample behaves the same as if you had configured new RelativeTtl(TimeSpan.FromMinutes(5)), except it does the other thing you ask for - only cache ok result.\n\nIf you change to slidingExpiration: true in the above code sample, then you have exactly equivalent to configuring new SlidingTtl(TimeSpan.FromMinutes(5)), except that it only caches ok results.. Hi @umeshkarthik \n\nDo you have any sample code for the Contextual ttl for Ok Results?\n\nI don't. If you need this behaviour, You could read the 35-line source code of ContextualTtl and merge it with the previous sample to create this quite easily for yourself, though.. @cmeeren We are now working towards a major release (v7.0) of Polly, so we have the opportunity to take the breaking change to fix this.  Are you interested in pitching in a PR to fix this?\nIt relates to the issue you raised in more detail here.\n\nNeeded would be:\n(1) Adapt the ISyncCacheProvider and IAsyncCacheProvider interfaces, so that the get methods were of the form (say):\n(bool, object) TryGetValue(String key);\nand\nTask<(bool, object)> TryGetValueAsync(String key, CancellationToken cancellationToken, bool continueOnCapturedContext);\n\nwhere the bool return value represents cache hit or miss.  (The .Net Standard 1.1 target would need to take a dependency on the nuget package System.ValueTuple.)\nOther suggestions welcome: the goal is to remove default(TResult) representing cache miss. \nAn alternative to pulling in System.ValueTuple could be to define a mini struct representing the value and whether or not we got one, similar to Service Fabric's ConditionalValue<TResult>\n\n(2) Adapt the sync cache policy engine and async cache policy engine for the fact that we would have some bool indicating cache hit/miss, rather than default(TResult)\n(3) Add suitable/adapt existing tests\n\nThen we would want to bring Polly's two cache provider implementations into line with these simple changes:\n(a) Polly.Caching.MemoryCache\n(b) Polly.Caching.IDistributedCache\n\nWe could also split more than one person over the work, if people were interested.. Marking this 'up-for-grabs', for anyone interested. Thanks @cmeeren for the fast response. I also have to choose goals, so leaving this up-for-grabs .... @cmeeren Awesome. And: thank you!\nI'm hoping to get v7 out early next week (the code is otherwise done; only finishing doco), so that would be perfect timing. Thanks for contributing!. Fixes merged to the v7.0.0 branch. Thank you @altenstedt for this useful clarification on the intellisense.  I've pushed similar changes to other related syntax files and added clarification on the other input parameters to the sleepDurationProvider delegate.. Thank you @altenstedt for your useful contribution! Merged to dev branch.  (We don't merge directly to master branch without going via dev branch, unless it is something that does not affect the released package such as a readme change.). @4ybaka If I have understood the question correctly, you simply need to use the existing .HandleResult<TResult>(...) syntax to configure the circuit-breaker to handle results as well as exceptions.  The .HandleResult<TResult>(...) syntax shown there works with .AdvancedCircuitBreakerAsync(...) as well.\nHere is another example, a test which demonstrating configuring a circuit-breaker to handle result types.  . Hi @4ybaka . The documentation previously linked shows how to handle both exceptions and results in the same policy, in the example titled // Handle both exceptions and return values in one policy.  I'll try to make that more visible by highlighting the different examples with headings.\nYou can either start by declaring exceptions to handle and then use the .OrResult<>() syntax to additionally specify results:\nvar policy = Policy\n  .Handle<HttpRequestException>()\n  .OrResult<HttpResponseMessage>(r => (int)r.StatusCode >= 500)\n  .AdvancedCircuitBreakerAsync(...);\nOr you can start by declaring results to handle, and then use the .Or<TException>() syntax to add exceptions to be handled:\nvar policy = Policy\n  .HandleResult<HttpResponseMessage>(r => (int)r.StatusCode >= 500)\n  .Or<HttpRequestException>()\n  .AdvancedCircuitBreakerAsync(...);\n. Thanks @grant-d for taking the time to package this a step further than our quick sample.\nPending this while we have discussion on #530.\nNote for later: If we do this, it would be make sense to (trivially) do some of the other IEnumerable patterns (like straight ExponentialBackoff) as convenience helpers too.  \n. Hi @sq735 . This is not something I have any current time available to develop myself.  (The time I have for Polly will likely focus on Distributed Circuit Breaker and metrics.)\nWe are fine with taking Pull Requests though, if you (or anyone else) wants to take this on.  (Right now we have great contributors developing InjectFault and InjectLatency, demonstrating how easy it is to add new policies.)\nSee also the existing discussion in the Polly roadmap around rate-limiting policies with some other algorithm options, and related #330 . . To avoid noise on the 'up-for-grabs' labels (three similar issues), I'm closing this issue in favour of the similar #260 (and noting the ideas of Token Bucket and Leaky Bucket there). . @Shadowman4205 The overload you are looking for exists here.  \nThe compiler is not finding it because, as the overloads change from exception-handling only, to also handling results (as you are using), we rename the parameters accordingly.  So the parameter exceptionsAllowedBeforeBreaking: becomes handledEventsAllowedBeforeBreaking:.  (For info, the other change is: the type of the first input parameter to onBreak changes from Exception to DelegateResult<TO>.)\nDelete exceptionsAllowedBeforeBreaking: from your code and the compiler should find the overload; then hover/whatever to reveal the intellisense for the found overload and you should see the matched parameter is called handledEventsAllowedBeforeBreaking:.\nLet me know if that sorts it for you.. @Shadowman4205 Closing on the assumption this solved the problem, but please reopen (or raise another issue) if you need any further assistance.. Thank you @george-polevoy for diving deeper on this than I had time to and for sharing that with the community, this is super interesting.  The decorrelated Jitter strategy quoted came from that AWS team research, definitely open to investigating different options.\nFirst, could you say what the axes on the graphs represent? (A guess ... the number of instances (vertical) of a specific delay of some-or-other timespan (horizontal) when averaged over 100000 iterations of the algorithm ... but you can state precisely? )\nSecond, would you be happy to share the test code which generated the results? (maybe in a ZIP or github gist). It would be great for you/ I/ others to be able to validate, and to build further on your results and explore how tweaking the algorithms affects outcomes.   \n\nFollowing code achieves much better distribution\n\nI am definitely seeing in your graphs that the green line is much more smoothly distributed than the yellow line as generated in the tests. (EDIT: But it would be good to, eg, dig into the code as @grant-d suggests, to verify why)\n\nFollowing code achieves much lower latency\n\nI want to be sure I have understood what we mean by this.  Do we mean that the average delay that the algorithm chooses to introduce before retrying (average perhaps in some sense of area under graph/percentiles), is lower?  Or do we mean (for example) that the average overall time to achieve success is less, for each algorithm pitted against a failed system which recovers after some random amount of time?  \nIt would be really interesting to build on your experiments (if they do not cover this already) to be able to analyse the dimensions of overall latency to achieve success, combined with number of calls made to achieve success.  \nThank you again for sharing this with the community!. Thanks to both of you @george-polevoy and @grant-d for progressing this!  I haven't had much time on this thread but note that:\n\nthe current .NET core implementation seems to use a static global instance of Random to provide random seeds for [ThreadStatic] instances of Random, which in turn are used to fulfil new Random() called on any thread.  This approach was supposed (according to various posts by Jon Skeet and Stephen Toub; will try to find links again) ... supposed to improve randomisation behaviour for new Random() called on any thread.  \nHowever, Jon Skeet seems to have rowed back from that and the latest .NET Framework recommendation is to use a single instance application-wide (for maximum randomness), but with fine-grained locking or similar (because a single instance is not thread-safe for simultaneous access from multiple threads).  \nThere are discussions on changing the algorithm for .NET Core/Standard, but no changes seem to have landed yet, afaics.\n\nSo: Should we just be following the recommendations here and here?\n(V happy for further clarifications/corrections, as the above was just based on some brief reading!). Circling back to our use case: given we are calculating randomised delays of far greater order of magnitude than any delay contention due to fine-grained locking, I guess we can safely follow the advice and not care about the impact of locking.\n. Thanks both @george-polevoy @grant-d ! Would be great to see graphs  of the distributions of generated by the revised algorithms.. Again, thank you both  @george-polevoy @grant-d .\n@george-polevoy I think your analysis here is exactly correct.  Thank you for spotting the (now obvious, yes) flaw in the algorithm here at time of writing.\n@grant-d The version in your PR (for which many thanks) also matches this analysis and the AWS algorithm, I believe.  Thanks for all the work on this and the PR!  (EDIT: PR suggestions will follow.)\n. ### The upper-end clamp\nAnalogous to the lower-end clamp problem which you have eliminated, @george-polevoy , your contribution led me to reason again about the upper-end clamp.  There is of course a potential upper-end clamp after enough iterations, because of the ceiling imposed at MaxDelay.TotalMilliseconds.  To have a MaxDelay seems reasonable, however, focusing pragmatically on our use case, rather than necessarily a 'flaw' in the algorithm - the concept of a \"maximum delay\" should make intuitive sense for users as a feature; and leaving the series unbounded would not necessarily give users a better experience! (think very long delays due to exponentiation). However, if MaxDelay is set too low in relation to seed for the number of retries configured/necessary, then retry intervals will certainly bunch (once MaxDelay is hit, there is a >=66% of the next interval also being MaxDelay, right?).  Which brings the question: How can we best communicate the upper-end characteristics of the configuration parameters to users?\nI drew users' attention to this in my existing guidance by emphasizing (from my own experience) that max should not be too low. However, do you think we can formalise this guidance any more precisely?  I did some work in Excel, and it looks as if the algorithm we are exploring (matching the AWS algorithm) tends asymptotically to (seed * (1.5^n) * 4/3) if Random.NextDouble() were constantly to deliver its mean value of 0.5.  (I'll try to upload the Excel somewhere.)  Does anyone want to dig into the math to capture that more precisely?\nOtherwise, perhaps some pragmatic warnings will suffice.  For example, for an initial seed of 1 second, an \"average\" sequence (think Random.NextDouble() returns 0.5) reaches a 30-second-ish delay within 7 iterations and 50 seconds within 8 iterations.  Perhaps some tables of numbers of this kind, for a few possible variations of seed and limiting number of retries to 5, 7, 8 is enough.  Doubtless there will be some systems for which it may make sense, but from a real-world perspective, I don't see more than 7-8 retries or retries delayed by order-of-60 seconds as majority use cases.  (EDIT: Background/batch processes may tolerate these levels of delay-before-retry, but again, after that degree of failure, it may be as well to stick the failing items back in some other queue for retrying later.)\nThoughts?. Finally, @george-polevoy : are you happy now with the behaviour of the AWS algorithm following the corrections you have introduced? (for which many thanks!). Or are there aspects of the 'advanced' algorithm from your original post you think still worth considering?  I did dive deeper into the advanced algorithm - came up with a bunch of further questions - but won't lengthen this unless you are also interested in pursuing.\nIt would be awesome to see how the \"fixed\" AWS algorithm looks also in your graphs.. Alternatively, @grant-d , @george-polevoy , we could eliminate the upper-end-bunching by modifying the latest implementation like this:\n        double ms = MinDelay.TotalMilliseconds;\n        for (; i < retryCount; i++)\n        {\n            double ceiling = Math.Min(MaxDelay.TotalMilliseconds, ms * 3);\n            ms = _random.Uniform(MinDelay.TotalMilliseconds, ceiling);\n\n            yield return TimeSpan.FromMilliseconds(ms);\n        }\n\nIs this worth modelling (to confirm smoothness) in George's graphing system? Can anyone see disadvantages?  One implication is that when ms * 3 > MaxDelay.TotalMilliseconds, there is no longer any in-built increase to the backoff.  It speaks to the same problem previously discussed, that users do need to choose MaxDelay significantly proportionally larger than seed.  However, that lack of increasing backoff may be preferable to the upper-end bunching.. This revisits my previous comment on implementations of System.Random, to provide promised references and clarify for the sake of accuracy and future readers: \n\nthe current .NET core implementation seems to use a static global instance of Random to provide random seeds for [ThreadStatic] instances of Random, which in turn are used to fulfil new Random() called on any thread. This approach was supposed (according to various posts by Jon Skeet and Stephen Toub; will try to find links again) ... supposed to improve randomisation behaviour for new Random() called on any thread.\n\nReferences: post by Stephen Toub; Jon Skeet 1; Jon Skeet 2.  \n\nThere are discussions on changing the algorithm for .NET Core/Standard, but no changes seem to have landed yet, afaics.\n\nThe latest .NET framework and .NET core implementations do in fact differ, because the .NET Framework 4.7.2 implementation still (!- for backward compatibility presumably) has Environment.TickCount as a seed new Random(), whereas .NET Core has moved on to a chained-RNGs approach.  (The discussions on changing the algorithm were around the Knuth algorithm vs others, rather than the seed.)\n\nHowever, Jon Skeet seems to have rowed back from [the chained-RNG approach] and the latest .NET Framework recommendation is to use a single instance application-wide (for maximum randomness), but with fine-grained locking or similar (because a single instance is not thread-safe for simultaneous access from multiple threads).\n\nThe recommendation I linked pertains to .NET Framework not .NET Core.  However, in targeting .NET Standard, Polly of course can still  (as is well known) be consumed by builds against .NET Framework 4.5 and up. So we should still take account of the .NET Framework recommendation (EDIT as PR #536 does) if for jitter we are targeting maximum randomness.\n\nBroadly, it is essential to make Random thread-safe, and these discussions embrace two different approaches to that which exhibit different trade-offs:\n\na fine-grained-lock on a single static instance of Random\nemphasizes improved randomisation but introduces fine-grained locking (per acquisition of each random number), which could affect perf in high-concurrency scenarios.  \nrecommend for Polly's Jitter use case: improved randomisation is important, to avoid spikes; delay due to lock contention is insignificant in the context of introducing jitter delays and executions which have already failed anyway.\na chained-RNGs approach with thread-safety achieved by [ThreadStatic] or ThreadLocal<T>\ndoubts over its randomisation credentials being as strong as the preceding approach, but improved perf in high-concurrency scenarios due to no locking.\nrecommend for Polly's chaos-injection use case; we would want randomised chaos-injection to have absolutely minimal drag on executions which weren't randomly selected for chaos injection, so avoidance of locking is preferred; that consideration is more important than how randomly the chaos-impacted executions are selected.. Again, big thanks both @george-polevoy , @grant-d for everything you are contributing on this. Looking forward @george-polevoy to seeing more.. Huge thanks @george-polevoy . Now digging in to this. (Bear with me if it takes a few days to respond; everything I do for Polly happens separately from paid-work ...). @george-polevoy I've run out time to dive into these in depth this week, due to the number of different strands going through on Polly, but wanting to get to this soon. Thanks!. @george-polevoy Again, thank you. I now digested the algorithm math and simulation basis, very nice.  Nice use of the natural shape of tanh to smooth just the initial part of 'soft exp soft delay' ;-}\n\nSee the comment on @grant-d 's PR: we could pull some of the new algorithms here into a separate Polly.Contrib package? (if you are willing), together with what @grant-d has put together for other sleep duration strategies.\nA remaining thought: it could be useful to understand for the new algorithms where the 50th percentile (say) falls - or see the shape of the graph as a whole - for try 1, try 2, try 3, try 4, separately ... to see how those 50th percentiles (/or the distribution) progresses, with increasing tries. \nFor example, looking at the graph (and formula) for 'exp jittered (Shifted)', it seems clear the 50th percentiles likely fall with the apex of each peak. But for 'soft exp, soft delay', we probably need to mine some data (/see a graph-per-try) to get a clear idea of how the 50th percentiles fall and progress. \nI've worked out how to amend your simulation code to generate this, so I can do, but if it's quick for you/you feel like pulling that out, say for the 'soft exp, soft delay 3' case, that would be useful to see.\nWhy? Mostly we have focused on how to make the distribution smooth, to fair-schedule retries to reduce contention, perhaps with the background assumption that the underlying system is basically healthy.  But I want to keep also in focus the dimension that the retries should happen with increasing delay, for the case of a system which is unhealthy/failing/struggling under load.  For unhealthy systems, it can be important that later retries significantly back off - to reduce the potential for retries creating a self-DDOS attack.  (Sure, the problem is stochastic, but broadly speaking, by the time fourth retries (say) start kicking in, we will be quadrupling the load.)  (And of course, there are other techniques to avoid this, like circuit-breaking on too many failures, but as a gen principle it's helpful for retries to have increasing back off.)  So, I would just like to dig into and be sure we understand this aspect - the degree of increasing backoff emerging from the new algorithms - before we go to the Polly public with a recommendation.\nThanks again, @grant-d , @george-polevoy , for everything we are doing on this.. @george-polevoy @grant-d  I adapted George's simulation code (for which huge thanks) to graph up the retry interval distribution for individual tries separately.  I am happy that the \"soft exp, soft delay\" function does create clearly increasing backoff as try number progresses. For example, for \"soft exp, soft delay 3\".  \nSoft exp, soft delay 3: Distribution of retry intervals for try 0\n\nSoft exp, soft delay 3: Distribution of retry intervals for try 1\n\nSoft exp, soft delay 3: Distribution of retry intervals for try 2\n\nSoft exp, soft delay 3: Distribution of retry intervals for try 3\n\n\nEDIT: Code used as the basis for these graphs, posted here\nEDIT 2: The same graphs for \"decorrelated jitter (AWS)\" clearly show the spikes we expected (particularly for tries 0, 1, 2), and also show (as expected) that the \"decorrelated jitter (AWS)\" reaches back to make some second and third retries after near-zero delay (taking a chance on the system having recovered, if you like).\n. Thanks again @grant-d and @george-polevoy for the great investigation into jitter strategy.\nPolly v7 has now launched, and we have a Polly-Contrib.  I propose - if you are in agreement - we take @grant-d 's PR #536 and your awesome jitter work here @george-polevoy, and make a Polly.Contrib repo Polly.Contrib.WaitAndRetryStrategies to publish it.  The repo would give you:\n\nfull 'write' rights to manage the repo, make/merge PRs etc\nisolated box (not mixed with anyone else's contrib; only you or people we invite have rights)\na template with solution/projects correctly set up to reference latest Polly and build targets\nand a full build ready to publish your nuget package which will correctly reference Polly.\n\n(ie you can basically just rename from the template, place your code in, and good to go!)\nIf this sounds good, I can clone to make you a Polly.Contrib.WaitAndRetryStrategies.\n(Polly.Contrib also allows me to \"get out of the way\" and allow contributors such as yourselves to publish these contributions without being blocked on feedback or discussion about exact shape of the API - although I'm still v much there to support if needed. And evolve, eg @george-polevoy , if you want to add something later with half-life/half-decay parameter.)\nAlso, if we go the contrib route, I would still want to feature this as strongly out from the main Polly, ie to replace/update the wiki jitter information and reach out to your contrib from there and from the readme.\nLet me know what you think.\n\n@george-polevoy Also, I did some work with Cesar de la Torre around resilience in the Microsoft Microservices sample app couple of years ago, some of it ended up in this ebook, parts of which are also online here.  Assuming we publish your jitter strategy to Polly.Contrib.WaitAndRetryStrategies, we can also suggest a PR to update that Microsoft jitter documentation to reference your better strategy.. No worries @grant-d. We've wanted to get the Polly.Contrib in place for a while, so that users can build additions without the Polly team having to sign off every decision, it gives everyone (me too) a bit more flexibility.  The retry strategies are quite a small case (could go either way), but partic the option to keep refining the jitter math point to Contrib.. I am good with Polly.Contrib.WaitAndRetry or open other suggestions.\nTo know: The choice becomes the namespace ie namespace Polly.Contrib.WaitAndRetry and thus using Polly.Contrib.WaitAndRetry . I've created the Polly.Contrib.WaitAndRetry repo and am sending you both (@grant-d @george-polevoy) invites to the Polly-Contrib organization.\n@george-polevoy I'd suggest we use your 'soft exp, soft delay X' algorithm as the best jitter candidate so far (unless you think different).  I've invited you to the repo (ie you get write-access) so that you can continue to make changes/suggestions to refine the jitter algorithm further if you want; it's been awesome to have all your great input so far.\n@grant-d Are you good to pull the conclusions we came to on this/and other thread into the new repo?  You can pull down a zip from Polly.Contrib.BlankTemplate, and just rename/add to form the new Polly.Contrib.WaitAndRetry, then upload back up to Polly.Contrib.WaitAndRetry.  After you accept the Polly-Contrib invite you have write rights on the repo.   \nLet me know when there's a nuget publish candidate and we can figure out the publish step (publish under a Contrib org or individually)\nThanks hugely to you both for the awesome contribution!\nLet me know if any questions/anything I can help with.  . Thanks @george-polevoy for the question around Polly and durable functions (sorry for delayed reply).  \nTL;DR You can use Polly in durable Activity functions as-is, but not in Orchestration functions.\nMy understanding is that the need for determinism in durable functions and the consequent time-provider recommendations apply only to durable Orchestrator functions as these are the type of durable function that is replayed.  But the kinds of operation that Polly normally guards - any external I/O, any async HTTP calls etc - are specifically barred from use within orchestration functions.  \nOn the other hand, durable Activity functions have no such constraints, and this is where I/O, HTTP calls etc should be placed.  As activity functions are not replayed and don't have the same constraints, Polly should be perfectly safe to use (without modification) within Activity functions.\n\nThe Activity functions themselves which the orchestrators coordinate, could of course succeed or fail, so one could ask: is it possible to apply Polly-like controls to the way orchestrators execute activity functions?  In most cases, durable functions provides equivalent functionality. \nRetry: Durable functions provides its own in-built retry functionality including backoffs.\nTimeout: Durable functions provides its own timeout pattern recommendation (example 1; example 2), analogous to Polly's pessimistic timeout.\nCache: Orchestrator functions already cache the results of activity functions.\nBulkhead isolation: is essentially a parallelism throttle. Durable functions provides its own concurrency throttles and scaling controls.\nCircuit Breaker: is essentially about accumulated errors over time or across parallel processes.  But orchestrator functions are isolated, single-thread processes - the only way they could accumulate success/failure statistics cross-process would be in some external store, but orchestrators are not allowed to communicate externally anyway (except via Activity functions)  ... so the problem becomes circular.  Dealing with replays through a circuit-breaker in an orchestration function would also present a challenge - when the orchestration was in replay state, the circuit-breaker would need to record neither a success or failure - because both influence statistics and the information would be in any case outdated.  It's not impossible, but TL;DR it would be much simpler to simply push the circuit-breaker down into the Activity function.  This is probably also only useful when distributed circuit-breaker becomes available.\nFallback and PolicyWrap would work in orchestrators - but on their own (without the other policies) they are not that relevant.\n\nHope this helps.  Interested if anyone can see angles on Polly-type behaviour in durable functions that this brief assessment misses.\nTL;DR Use Polly in the Activity functions rather than the Orchestration functions.. Closing this issue: no changes to Polly seem necessary to use Polly with Azure durable activity functions.\nNoting for completeness/brief aside that changing Polly's SystemClock from an ambient context to an injected dependency could bring improvement to testing.  However: a low priority, as no current production-side benefits to change (and we wouldn't want such a change to unnecessarily clutter Policy configuration syntax further, also).\n. @grant-d Thank you. A courtesy alert that private commitments and paid work mean that I likely first able to look at this at weekend or Friday evening.. @grant-d Only further thing I am reflecting on around this: which params should sit in the ctors, and which in the .Generate(...)/.GetSleepDurations(...) method?  IE if we have the interface correct; if the nudge which the pattern gives towards singleton backoff factories is helpful/unhelpful.  Final thoughts on that may perhaps follow.  Views welcome.. Re the following note added to the head of the issue:\n\nRisks\nInadequate guidance could lead to consumers using the exact same instance of a strategy across multiple calls. It is essential that .Generate is called just-in-time, not pre-generated.\n\nThis is not as risky as that note may suggest, because of the way IEnumerable<TimeSpan> (when implemented with yield return) represents a recipe for getting a sequence of timespans, not the timespans themselves. And because Polly reifies that enumerable at execution time, not at configuration time.  It is essential (for random jitter to be different each execution) that the sequence is not pre-generated, but it is not essential for users to create/configure a policy with DecorrelatedJitterBackoff.Generate(...) only just before use.  It will be perfectly fine for users to configure a policy like this once at startup:\nvar jitterPolicy = Policy\n    .Handle<HttpRequestException>()\n    .OrResult<HttpResponseMessage>(resultPredicate)\n    .WaitAndRetryAsync(s_backoff.Generate(retryCount: 5));\n\neven to hold that policy in a PolicyRegistry as a singleton, and then perfectly safe for that single policy instance to be re-used multiple times/places all round the app - it will still generate different jitter sequences each execution.\nIEnumerable<TimeSpan> represents a recipe for getting a sequence of timespans, not the timespans themselves. The .Generate(...) method is only actually executed (any enumerable is only actually reified) when code calls GetEnumerator(...) on the IEnumerable. This happens in Polly for example here on a per-execution basis when the retry state for an execution is instantiated.\nWhat users must avoid (if they want the policy to be re-usable and generate random jitter each use) is reifying the sequence at policy configuration time, ie avoid .WaitAndRetryAsync(s_backoff.Generate(5).ToList());\n. I pushed an extra test to the PR, demonstrating that the IEnumerable<TimeSpan> returned from DecorrelatedJitterBackoff.Generate(...) can be enumerated multiple times, giving different randomised results.  The test can stand as a regression test that the behaviour still stands (ie that we don't in future doesn't refactor DecorrelatedJitterBackoff to invalidate it), and as an example that users can be pointed to if they question this point.\nI also (when re-visiting the behaviour for myself) made this more visual .NET fiddle example \npublic class Program\n{\n    public static void Main()\n    {\n        new IEnumerableTests().ShowExamples();\n    }\n\n    public class IEnumerableTests\n    {\n        public static IEnumerable<int> ThreeDiceThrowsStatic()\n        {\n            Random die = new Random();\n\n            for (int i = 0; i < 3; i++)\n            {\n                yield return die.Next(1, 7);\n            }\n        }\n\n        public IEnumerable<int> ThreeDiceThrowsInstance()\n        {\n            Random die = new Random();\n\n            for (int i = 0; i < 3; i++)\n            {\n                yield return die.Next(1, 7);\n            }\n        }\n\n        public static void PrintDieThrows(IEnumerable<int> throws)\n        {\n            foreach (int result in throws)\n            {\n                Console.WriteLine(\"Threw: \" + result);\n            }\n\n            Console.WriteLine();\n        }\n\n        public static void PrintDieThrowsTwice(IEnumerable<int> throws)\n        {\n            PrintDieThrows(throws);\n            ShimDelay();\n            PrintDieThrows(throws);\n        }\n\n        public static void ShimDelay()\n        {\n            // Shim delay to eliminate the fact that instances of Random() generated in quick succession, in .NET Framework, use the same random seed.\n            Thread.Sleep(TimeSpan.FromMilliseconds(50));\n        }\n\n        public void ShowExamples()\n        {\n            Console.WriteLine(\"Delayed enumeration of same IEnumerable instance returned from static method, used twice:\");\n            PrintDieThrowsTwice(ThreeDiceThrowsStatic());\n\n            Console.WriteLine();\n            ShimDelay();\n\n            Console.WriteLine(\"Eager enumeration of IEnumerable returned from static method, used twice:\");\n            PrintDieThrowsTwice(ThreeDiceThrowsStatic().ToList());\n\n            Console.WriteLine();\n            ShimDelay();\n\n            Console.WriteLine(\"Delayed enumeration of IEnumerable returned from instance method, used twice:\");\n            PrintDieThrowsTwice(ThreeDiceThrowsInstance());\n\n            Console.WriteLine();\n            ShimDelay();\n\n            Console.WriteLine(\"Eager enumeration of IEnumerable returned from instance method, used twice:\");\n            PrintDieThrowsTwice(ThreeDiceThrowsInstance().ToList());\n        }\n    }\n}. Thanks @grant-d ! ( Yes, just the params issue to come back to. ). >>can be enumerated multiple times, giving different randomised results \u2026\n\n\nI think the above would only work in serializable contexts\n\nIIRC the details of yield return implementation, this will be fine whether different enumerations of the enumerable are executing serially or in parallel/concurrently. When the compiler sees a method returning IEnumerable which is implemented with yield return, it (IIRC) compiler-generates a hidden inner class to represent that method returning IEnumerable. Each enumeration instantiates a separate instance of that compiler-generated inner-class. (This actually gives the thing you rightly identify is needed: \"a distinct enumerator per [execution]\".)  That's a quick explanation from memory; blogs should confirm.\nSo it all works thread-safely - provided, of course, that within our IEnumerable<T>-returning, yield return-implemented method, we don't use anything non-thread-safely.  Everything mutable within DecorrelatedJitter.GetSleepDurations(...) has method-execution-scope, and we take care that we use the only shared/external item, _random, thread-safely, so it looks good to me.. @grant-d @george-polevoy . Similar to for the current fault-injection work, I am going to propose that we promote this contribution to its own package, in this case (something like) Polly.Contrib.WaitAndRetryStrategies.  Advantages:\n\nMore freedom to rev Polly.Contrib.WaitAndRetryStrategies independently from (not blocked by) the Polly rev cycle - grow/refine more freely as enhancements to the algorithms occur to us/anyone\nWe can include more of @george-polevoy 's algorithm variants (if George is happy to)\nWe can give you greater control over the Polly.Contrib package (if you wish); and headlining as contributors (either way)\nMore space to document the math in depth \n\nPlease let me know any thoughts.\nMechanics:\n\nI would need time to set up the separate package.\nWe would likely first merge, then-demerge, this PR on Polly in any case, to ensure you get the due contributor credit\nWe would advertise the package directly from the Polly retry wiki page (and everywhere else relevant) \n. @grant-d The separate package proposal (if agreed) helps guide some of our decisions around interfaces-or-not; and instances-of-a-class configuration versus static factory methods.  Propose we may go for:\n\n(a) static factory methods on a separate-class-per-strategy, ie a syntax DecorrelatedJitter.GetSleepDurations(param1, param2, retryCount) , LinearBackoff.GetSleepDurations(....), etc.  \n\nstatic class-per-strategy grows more easily than one class holding all variants\n\n(b) static methods, no instances, no interface\n\n\nIEnumerable<TimeSpan> seems a clear and well enough defined interface between Polly.Contrib.WaitAndRetryStrategies and Polly\n\n\nLess cruft, as you say.  Similarly, I have tended to avoid introducing configuration instance classes to Polly, despite requests, to avoid it becoming extra surface to maintain, constraining the API (adding options breaks the classes), and it is easy enough for Polly users to do themselves in the particular way they want anyway.\n\n\nAgain, let me know if this path forward seems ok.. @grant-d No problem! . Thanks @grant-d .  I disposed of a question around the new jitter strategy also over the festive season, probably going to be a bit more kanban over next couple of weeks (courtesy update) to focus purely on getting Polly v7.0 and Simmy out, then let's bring this to fruition also. Thanks again!\n. This PR was unexpectedly automatically closed by github, when deleting a (now-outdated) base branch which the PR targeted .  \n@grant-d Thank you for everything you have done on this!  Now that Polly v7.0.0 is released, I hope to revert shortly to how we may take this forward.  . @grant-d , I hope to come back to this at the weekend. . Hi @vishalsavsani . Thanks for the question.  No, there's no such feature in Polly, and the Polly architecture wouldn't be a good fit for an extension in that direction.  The Polly architecture is geared to how an in-process execution may be inflected, and any resume-after-waiting-to-retry would be in-process, \nAs you say, options may be any background storage/queue where you can queue a message/event to be redelivered/reprocessed at some point in the future, or anything akin to a background task or cron job checking for such tasks.\nIf you are in Azure, another option might be Azure Durable Functions, where you can now checkpoint an orchestration function to resume at a specific time in the future.. @cmeeren Thanks for alerting this. To fix this, we'll make some minor changes to (and re-release) https://github.com/App-vNext/Polly.Caching.MemoryCache/ . @cmeeren This should be fixed by: https://github.com/App-vNext/Polly.Caching.MemoryCache/pull/29 . (You are welcome to pull that PR down locally and test for yourself.)\nGiven we are in ThanksGiving week, Polly.Caching.Memory v2.0.1 may not publish to nuget for a few days, but the fix is done.\nThanks again for alerting this.. @flin-zap Please feel free to make a PR to correct them! (against the branch onV611dev)  EDIT: And: thank you for spotting this.. @flin-zap @doxakis . Thanks. That is merged to master!  Release v6.1.2 should appear on nuget in the next day or so. . Polly only provides the extensions methods which (it sounds like) you have already discovered.  However:\n\n(1) You can still construct policies of any kind and tie them in to HttpClientFactory (without any new extension methods); and\n(2) You can still wrap up your choices of what-to-handle in your own extensions methods, if you wish.\n\n(1) To register an entirely bespoke Policy with HttpClientFactory, see our Polly and HttpClientFactory documentation here - the first example there demonstrates exactly how to construct a policy handling your own bespoke choice of exceptions and status codes.\n(2) To wrap up your choices of what-to-handle in your own extension methods:\n\nFollow the pattern here to create your own version of a method like .HandleTransientHttpError().  You don't have to provide every Or...() variant in that file unless you want that flexibility.\nFollow the pattern here to tie the extension method from previous bullet into an extension method on IHttpClientBuilder\n\nYou can code and host these extension methods in your own app.. @Tyrrrz , We have this under consideration as part of #504 (simplifying the project structure to make multi-targeting easier). We will re-visit this when #504 progresses (after 508 and 536).  \nI noticed there are some mixed opinions about that Microsoft recommendation in the feedback to the doc: https://github.com/dotnet/docs/issues/8997 ; https://github.com/dotnet/docs/issues/8896 , so we'd gladly welcome further feedback from our .NET Framework users (or Microsoft) about the .NET Framework library-consumption experience.  . Fix merged to v7.0.0 branch by #552.  Will be released when v7.0.0 is merged to master and released.. @JustinMasters That pattern isn't built in to Polly.\nTwo ways you could build round Polly to achieve it:\n\n\nPlace the initial try in a try-catch.  If you detect failure, then use the existing code you have for the retries.\n\n\nUse your own CancellationTokenSource / CancellationToken pair, and call CancellationTokenSource.CancelAfter(...) within the onRetry method from the retry policy, when retryCount == 1.  If you declare/create your policies in a separate place/time (eg StartUp) from where you use them (as is often the case), you will need to use the Dictionary-like properties on Polly.Context to pass the CancellationTokenSource into the execution, and to extract it from the Context within the onRetry.  EDIT: There are examples of this technique in this blog post\n\n\nOf course you can wrap either up in your own method, to package the implementation neatly.. @yuzd What you are seeing are classic symptoms of thread-pool starvation (and potentially exhaustion).  When the .NET ThreadPool decides that more than the configured min threads are needed to service incoming work, it will inject new threads at a rate of only 2 per second (causing new incoming work to start slowly).  The adjustment you have made ( ThreadPool.SetMinThreads(...) with a higher int workerThreads value ) is the often-seen fix for this.  This adjustment is effective if many of the ThreadPool threads are blocked (but Microsoft caution that it can be counter-productive when most of the threads are active, due to competition and switching: https://docs.microsoft.com/en-us/dotnet/api/system.threading.threadpool?view=netframework-4.7.2#remarks .)\nThe Polly documentation for synchronous pessimistic TimeoutPolicy made clear that synchronous pessimistic TimeoutPolicy consumes an extra threadpool thread:\n\nAdditional notes: Pessimistic timeout for sync executions\nFor synchronous executions, the ability of the calling thread to 'walk away' comes at a cost: the policy will execute the user delegate as a Task on a ThreadPool thread.\n\nbut the documentation was not clear about the threadpool-starvation risks of using this in high-parallelism scenarios.  I have updated the Polly documentation to make this clearer.\n\nCould we change Polly to improve this?\nWe could change Polly to give users the choice to execute delegates, when using synchronous pessimistic TimeoutPolicy only, with TaskCreationOptions.LongRunning. This is a hint for .NET to execute the delegate passed to TimeoutPolicy.Execute(...) on a non-ThreadPool thread. We would welcome community feedback on this potential feature.  The feature could be a choice between something like:\n\nSyncPessimisticThreadStrategy.ThreadPool\nSyncPessimisticThreadStrategy.PreferNonThreadPool // prefer, because TaskCreationOptions.LongRunning does not guarantee it\n\nIt should be emphasized that using non-ThreadPool threads is not a magic best solution for all cases.  There are trade-offs:\n\nWhen the delegate executed through TimeoutPolicy is faulting/responding slowly (and if the number of such faults allowed to occur in parallel is not controlled (*)), then using non-ThreadPool threads should avoid some of the thread-starvation problems described in this issue. \nBut when the delegate executed through TimeoutPolicy is performing well, using non-ThreadPool threads may hurt performance (reduce throughput), because it is typically more expensive (memory overhead; processor context-switching) to create a new non-ThreadPool thread for every execution than it is to re-use a ThreadPool thread.  Some estimates report it adds an extra millisecond (or so) (but \"your mileage may vary\" depending on execution environment).  Whether it would be a good trade-off would depend on the individual application and environment.\n\n\nTwo general points also arising from this discussion:  (we have made the documentation clearer on these points)\n\n\nWe always recommend (*) explicitly managing parallelism/load in your application. as described here and in this longer article. Explicitly managing load allows you to control what happens when your application nears maximum load; you can degrade gracefully, shed load, or scale out to support load in a managed way.  Not explicitly managing load means your application will still hit implicit limits, and leaves your app more likely to fail in unexpected ways.\n\n\nUsers of Polly synchronous pessimistic TimeoutPolicy need to understand that the power of being able to 'walk away' from an execution is expensive, in terms of thread usage. (And the timed-out operation is, as we also clearly document, not terminated; it is still consuming resource.).  So users should combine synchronous pessimistic TimeoutPolicy with something like a circuit-breaker outside the timeout policy, to prevent excessive consumption of resources when too many calls to the underlying delegate are timing out.\n. @yuzd Some specific, practical points.  Re:\n\n\n\ncan not use timeout with circuitbreaker together\n\nIt is not specifically using circuit-breaker with synchronous pessimistic timeout which is the problem.  Synchronous pessimistic TimeoutPolicy can hit this problem with or without circuit-breaker, due to threadpool starvation, if parallelism is not explicitly managed (see extended discussion above).\nIn fact, we recommend using a circuit-breaker with synchronous pessimistic timeout policy, to ensure that the circuit breaks (and not too many calls are placed, consuming too many threads), if calls are timing out.  But for the circuit-breaker to prevent extra calls being placed through the timeout policy, it is important that you place the circuit-breaker outside (upstream of) the timeout policy.  Specifically: where in your code you have:\n        if (TimeOutMilliseconds > 0)\n        {\n            policy = policy.Wrap(Policy.Timeout(() => TimeSpan.FromMilliseconds(TimeOutMilliseconds),\n                Polly.Timeout.TimeoutStrategy.Pessimistic));\n        }\n\n        if (EnableCircuitBreaker && this.CircuitBreakerPolicy != null)\n        {\n            policy = policy.Wrap(CircuitBreakerPolicy);//make sure CircuitBreakerPolicy are shared!!\n        }\n\nthe timeout policy will already request an extra thread just to try the circuit-breaker.  This would be better in the other order, to place the circuit-breaker upstream of the timeout policy:\n        if (EnableCircuitBreaker && this.CircuitBreakerPolicy != null)\n        {\n            policy = policy.Wrap(CircuitBreakerPolicy);//make sure CircuitBreakerPolicy are shared!!\n        }\n\n        if (TimeOutMilliseconds > 0)\n        {\n            policy = policy.Wrap(Policy.Timeout(() => TimeSpan.FromMilliseconds(TimeOutMilliseconds),\n                Polly.Timeout.TimeoutStrategy.Pessimistic));\n        }\n\nand make sure also that CircuitBreakerPolicy is configured to handle TimeoutRejectedException.  That way, if the circuit is broken, the timeout policy will not even execute (so another thread is not required).. @ankitgh Welcome to Polly.  It is not possible to change or add an onRetry method after the policy has been configured.  This is intentional: Polly adopts the principle that policies should be immutable once constructed.\nWhat is the reason for wanting to add onRetry to the policy later?  Is it that the onRetry wants to exchange information with other variables / context at the calling site?  If so, Polly provides the Polly.Context class as a way of doing this.  You can pass a Context instance into the execution, you can access that Context instance in the onRetry delegate, and (if it was in scope, in the case when you declare Context yourself and pass it in) you also have access to the Context instance after the execution.\nFor more information on that, see:\n\nthe basic examples in the readme\na blog on this topic\n\n\nIf that doesn't help, please provide more code to allow us to see more what you are seeking to achieve, and why. EDIT: There could be many ways to achieve your goal with Polly as-is, depending exactly what that goal is. . Closing due to lack of further response.  However, if you do require further assistance, please do open another question, or ask on our slack channel, or stack overflow.  It would also be useful to have a longer description of what you are seeking to achieve, to be able to help in more depth.. Fix merged to v7.0.0 branch by #552.  Will be released when v7.0.0 is merged to master and released.. (extra comment to discuss one angle that was considered, in the proposal)\nOne obvious comment: \"Why do I have to extend a base class to create a custom policy?  Would it be less coupled if I could implement an interface?\"  \nShort answer: I would prefer composition over inheritance. Practically, though, it would now [^] be a major breaking change for the wide user base of the existing syntax, and for existing integrations eg with .NET Core. And decisions have taken into account availability, and opportunity cost against other new functionality [^] .  \nThe syntax when App-vNext took over Polly was essentially Policy.Execute(...).  Turning that around so that the policy is the \"object of the verb\" (in linguistic parlance) - something like .ExecuteUsing(policy) - would now be a reasonable rewrite and major breaking change.\nConceptually, it would be possible to turn the Polly syntax on its head and do something like:\nResiliently // anything chained on to here would create a despatcher object managing the despatch\n    .With(IPolicyImplementation policyA) // ... so policy implementations can now become the \"object\" rather than the \"subject\" \n    .With(IPolicyImplementation policyB) // ... of the execution-despatch sentence\n    .Using(CancellationToken token)\n    .Execute(/* etc */)\n\nThe gain would be composition over inheritance; the expense, the impacts to the project, both internal and external, listed [^] above.. Functionality merged to v7.0.0 branch by #552.  Will be released when v7.0.0 is merged to master and released.. Hi @vany0114 Re:\n\nI was taking a look at that, I think the validation you put on ShouldInject method, cover all scenarios since the syntax classes are ensuring that at the end of the day the injectionRate will be always a lambda\n\nThat is correct.  It would be a small improvement for parameter validation to throw at configuration time rather than execution time for the constant cases, but not essential.  Noted on the Simmy repo: https://github.com/App-vNext/Simmy/issues/15. Locking this thread (in preference to closing it right now, which reduces visibility), because this no longer represents the latest version of the codebase for this feature.  Interested parties should head on over to the Simmy repo where this functionality is being finalised!. Closing as this codebase now exists definitively in the Simmy repo, the readme now links out to Simmy and #499 still tracks on the issues page.. Hi @SeanFarrow . Looks great to me!  Going to make a tiny test change, then just push some some documentation (and credit to you) onto the PR, then I think it should be good to merge.  Probably leave it a day to merge in case you want to second-read the changes I pushed.  Thanks, as ever, for your contributions.\n. Hi @PingPongSet \n\nWebApplicationFactory.CreateClient() has no overloads that returns the named HttpClient:\n\nThat makes sense: the Httpclient returned by WebApplicationFactory.CreateClient() is specifically geared to pass requests to your app from outside; the HttpClient instances configured within your app are (on the other hand) an internal concern to it.\nI will answer the question at three different levels, and you can choose what suits best.\nIf you just want to adapt your existing test code to get the client configured with name \"test\"\n(in response to \"I cannot retrieve the HttpClient that has been configured with the Polly polly\")\nsc.BuildServiceProvider()\n    .GetRequiredService<IHttpClientFactory>()\n    .CreateClient(\"test\");\n\nIf you want a full end-to-end integration test that your app uses the configured Policy\n(to respond to the question title: \"Test Polly retry polly configured via Startup.ConfigureServices() with ASP.NET Core API\")\nIf you want to test the Polly policy configured on IHttpClientService within your app, via an end-to-end integration test of your app orchestrated by WebApplicationFactory, then you will have to fire the whole request at http://localhost:1234/api/v1/car/ (as your test code is already doing), and somehow stub out whatever downstream call http://localhost:1234/api/v1/car/ is making through HttpClientService.  To provide stub responses to that downstream call (not shown in the code posted in the question, I don't know what it is), you could use either:\n\nMountebank via MBDotNet - fairly heavyweight as it involves installing node.js and binding a port for Http traffic\nHttpClientInterception, much more lightweight - it stubs responses to HttpClient calls by adding an intercepting DelegatingHandler to the delegating handler middleware of HttpClients used by your app\n\nHttpClientInterception provides a good sample app which demonstrates how to set up HttpClientInterception to provide stub responses to outbound calls which your app makes.  The app-under-test in their sample app is also using typed-clients from IHttpClientFactory; and is also using WebApplicationFactory to orchestrate the tests; so is a close fit for the test approach you have already started on.\nYou would use Mountebank or HttpClientInterception to stub the outbound call from HttpClientService to return something the policy handles eg HttpStatusCode.InternalServerError, in order to trigger the Polly retry policy.\nAlternatively, you could write your own very short StubDelegatingHandler\n    public class StubDelegatingHandler : DelegatingHandler\n    {\n        private HttpStatusCode stubHttpStatusCode;\n        public StubDelegatingHandler(HttpStatusCode stubHttpStatusCode) => this.stubHttpStatusCode = stubHttpStatusCode;\n        protected override Task<HttpResponseMessage> SendAsync(HttpRequestMessage request, CancellationToken cancellationToken) => Task.FromResult(new HttpResponseMessage(stubHttpStatusCode));\n    }\n\nand configure it after the Polly policy on the HttpClient ('inside' the Polly policy , it terms of the nested DelegatingHandlers).\nsc.AddHttpClient(\"test\")\n    .SetWaitAndRetryPolicy1() // modify this to return IHttpClientBuilder, to allow chaining\n    .AddHttpMessageHandler(() => new StubDelegatingHandler(HttpStatusCode.InternalServerError));\n\nThis means every outbound call that the named-client \"test\" makes would return HttpStatusCode.InternalServerError; it's a minimal example of what HttpClientInterception does, but HttpClientInterception  does more, does it with much more configurability, and with a nice fluent syntax.\nOf course, you could make StubDelegatingHandler more sophisticated, to return the error only 2 times ... or whatever. \nTo test that the retry policy is invoked, you could make the test setup configure a fake/mock ILog implementation, and (for example) assert that the expected call .Error(\"Delaying for {delay}ms, ...\") in your onRetry delegate is made on the fake logger. Then you would know the retry had been invoked.\n\nIf you want the shortest possible unit test that HttpClientFactory does configure a policy correctly on the client\n... and that the policy you declare and configure with HttpClientFactory does handle errors as you want\nI offer this variant in case you just want the shortest possible test of the functionality declared in a method like .SetWaitAndRetryPolicy1().\nThis is (almost) the shortest xUnit test I could write that HttpClientFactory does correctly configure and use a policy.  There is no need for any WebApplicationFactory, IHost, IHostedService or anything from ASP.NET.  The test simply proves that HttpClientFactory does configure the HttpClient to use the policy.  It is possible simply to new up a ServiceCollection; configure a named client using HttpClientFactory; get the named client back from the IServiceProvider; and test if that client uses the policy.\npublic class HttpClientFactory_Polly_Policy_Test\n{\n    const string TestClient = \"TestClient\";\n\n    [Fact]\n    public async Task Given_a_retry_policy_configured_on_a_named_client_When_call_via_the_named_client_Then_the_policy_is_used()\n    {\n        // Given / Arrange \n        IServiceCollection services = new ServiceCollection();\n\n        bool retryCalled = false;\n\n        HttpStatusCode codeHandledByPolicy = HttpStatusCode.InternalServerError;\n\n        services.AddHttpClient(TestClient)\n            .AddPolicyHandler(HttpPolicyExtensions.HandleTransientHttpError()\n                .RetryAsync(3, onRetry: (_, __) => retryCalled = true))\n            .AddHttpMessageHandler(() => new StubDelegatingHandler(codeHandledByPolicy));\n\n        HttpClient configuredClient =\n            services\n                .BuildServiceProvider()\n                .GetRequiredService<IHttpClientFactory>()\n                .CreateClient(TestClient);\n\n        // When / Act\n        var result = await configuredClient.GetAsync(\"https://www.doesnotmatterwhatthisis.com/\");\n\n        // Then / Assert\n        Assert.Equal(codeHandledByPolicy, result.StatusCode);\n        Assert.True(retryCalled);\n    }\n\n}\n\npublic class StubDelegatingHandler : DelegatingHandler\n{\n    private readonly HttpStatusCode stubHttpStatusCode;\n    public StubDelegatingHandler(HttpStatusCode stubHttpStatusCode) => this.stubHttpStatusCode = stubHttpStatusCode;\n    protected override Task<HttpResponseMessage> SendAsync(HttpRequestMessage request, CancellationToken cancellationToken) => Task.FromResult(new HttpResponseMessage(stubHttpStatusCode));\n}\n\nIt should be easy to expand this sample to test more sophisticated policies, for example to test .SetWaitAndRetryPolicy1().\n. Hi @PingPongSet . No problem, glad it could help.\nRe:\n\nUpdated Integration Test method\nI updated my existing integration test method to below, but the retry policy is not activated. That is, it only sends request one time, not three times.\nQueston 1: Am I missing something?\n\nOne possible thing.  This:\n var client = _factory.WithWebHostBuilder(whb =>\n       {\n           whb.ConfigureServices((bc, sc) =>\n           {\n              /* snip */\n\n               sc.BuildServiceProvider()\n                   .GetRequiredService<IHttpClientFactory>()\n                   .CreateClient(\"test\"); // This isn't doing anything because the return value of this call isn't assigned to anything you use.\n           });\n       }).CreateClient();\n\nmeans the variable HttpClient client which the test posts on (await client.PostAsync(url, content);) is assigned the HttpClient returned from WebApplicationFactory, the HttpClient instance designed to invoke your webapp, not the \"test\" configuration from HttpClientFactory.  So for the test to succeed, your app must be configured such that invoking the http://localhost:1234/api/v1/car/ endpoint eventually chains on internally to something (via HttpClientService?) invoking the \"test\" configuration from HttpClientFactory  (as I believe it should, from what you have described as the code intention).  In other words, it's a full end-to-end integration test.  If that code expectation is not all wired up properly inside the app, it could be a cause of test failure.\nHowever, if you intended the test to exercise more directly the \"test\" configuration from HttpClientFactory, you may want:\n HttpClient client;\n factory.WithWebHostBuilder(whb =>\n       {\n           whb.ConfigureServices((bc, sc) =>\n           {\n              /* snip */\n\n               client = sc.BuildServiceProvider()\n                   .GetRequiredService<IHttpClientFactory>()\n                   .CreateClient(\"test\");\n           });\n       }).CreateClient();\n\nso that the variable client is assigned the \"test\" configuration from HttpClientFactory.\nThis makes it like a half-integration, half-unit test.  The test uses WebApplicationFactory to exercise your normal app startup in configuring the HttpClient/policy to be tested; but then pull the \"test\" HttpClient configuration out for a tighter unit test.\nPer my original post, if you just want a tight unit-test on the HttpClient \"test\" configured via HttpClientFactory, you can also do this with the \"shortest-possible approach\", without needing to involve WebApplicationFactory.\n\nRe:\n\nQuestion 2:\nHow can Config be setup for Integration test within WithWebHostBuilder() in TestRetry() method if it is the correct method, and for unit test in HttpClientFactory_Polly_Policy_Test class.\n\nThis is more general ASP.NET Core support rather than Polly, but some pointers: Options.Create<>() if you want the options to be entirely self-generated by a purely self-contained unit test; or use ConfigurationBuilder to read in external config (eg json settings file) if you want a more integration-style approach which reads in some version of your app's configuration.  See these example links: 1; 2; 3; 4.. Polly SystemClock class has five different functions, different of them used by different Polly policies.\nThe WaitAndRetryAsync(...) policy is using SystemClock.SleepAsync(...) to delay between retries.  To prevent an async wait-and-retry test delaying, set that function to do nothing before a retry test starts, eg:\nSystemClock.SleepAsync = (_, __) => Task.CompletedTask;\n\nand reset it at the end of each test.\nSystemClock.Reset();\n\n. I'd like to suggest please that we pause any changes between Action, local function and local method, until we have some concrete benchmarks supporting the change.  Some early benchmarks I ran did not immediately support the change. \nFurther, in the doNothing case, other optimisations are also possible and should be explored: eg Action doNothing = null; with onRetry?.Invoke(...) (or similar) syntax elsewhere.. Thanks @SeanFarrow and @moerwald ! \nPlease be sure to branch from the head of the latest v7.0.0 dev branch for any code tidy-ups! There are some significant refactors to the architecture of all Polly policies in the v7.0.0 branch; any tidy-ups started from the current master code may well not merge.\nThanks again.. Thanks again @SeanFarrow and @moerwald for everything you are doing on clean-ups!  \nAny C#6/7 tidy-ups are great (except for changing between lambdas/local functions etc as discussed - will try to post some benchmarks on that), and so long as things are (currently) based on the v7.0.0 branch.\nCachePolicy is the other one probably not to touch at the moment, as we have an open PR on that; the PR itself is good to merge, but I want to be sure we have the corresponding changes to Polly cache providers and serializers described in this comment ready before we merge cache changes in core Polly.\nThanks again!. >Have you got any objections to updating the required C# language version to v7.3? \nhi Sean. Can't see any reason not to do this, and think our build.cake and AppVeyor configuration will already handle it.  If you want to prove it out before investing time actually introducing C# 7.3 features, maybe make a separate PR just switching to C# 7.3 first, and we can see if the appveyor config just handles it or needs any work?\nThanks again!. Thanks @cmeeren .  PR looks great!  I am going to push four more tests which prove the default(TResult) cases work for an arbitrary cache provider (in other words, that Polly itself does not impose any limitations), for both get and put, for both value types and reference types. \nIndividual cache providers may of course impose their own limitations on caching null, but none (is my first initial guess...) will impose any limitation on caching default(TResult) for a value type.\nNote: I am holding (not merging) this PR until we have ready the associated fixes to Polly cache providers and serialization providers: \n\nhttps://github.com/App-vNext/Polly.Caching.MemoryCache/issues/30 ; \nhttps://github.com/App-vNext/Polly.Caching.IDistributedCache/issues/10 ; \nhttps://github.com/App-vNext/Polly.Caching.Serialization.Json/issues/10 . \n\nBut otherwise I think this PR (with extra tests I'll push) is good to go.. @cmeeren I'm merging this into the v7.0.0 dev branch now, as I've brought the cache providers and serializers into alignment with the v7.0 changes, in the following PRs:\n(the PRs on those repos will not actually be merged until Polly v7.0.0 releases publicly)\n\nhttps://github.com/App-vNext/Polly.Caching.Serialization.Json/pull/13\nhttps://github.com/App-vNext/Polly.Caching.MemoryCache/pull/33\nhttps://github.com/App-vNext/Polly.Caching.IDistributedCache/pull/13/\n\nPlease feel free to review those PRs.  Each cache provider repo now has integration tests proving we can round-trip cache or serialize a range of values across a range of types, including the default(TResult) case for value types which you originally raised.\nThanks for your contribution! You have credit in the readme!. @cmeeren The change will release publicly to nuget when v7.0.0 releases.  (Remaining work: documentation on the new custom policies and Simmy.). Closed in #561 (will release in v7.0). Thanks @moerwald !\n@joelhulen For info, this (when v7 releases) will change our License Info link on nuget\n\nso that it identifies programatically to a BSD 3-clause license rather than just linking directly to our license.txt file.  Shout if any questions/concerns.  This is the new Microsoft recommended approach.. Cross-posting from here for the benefit of new readers finding this PR : I'd like to suggest that we pause any changes between Action, local function and local method, until we have some concrete benchmarks supporting the change. . Closing as discussed. Thanks Andr\u00e9! That's great. Merging!. Thanks @moerwald !  Please could you rebase the PR on the latest v7.0.0 dev branch ?  \nYou will find also that @seanfarrow and I made some changes to PolicyRegistry as part of this merge earlier in the v700 branch, not sure if you will find anything else worth tidying among that.\nThanks again for contributing!. >rebased against v700 as described here: https://github.com/edx/edx-platform/wiki/How-to-Rebase-a-Pull-Request. Hope I've done it the right way.\nHi @moerwald . That looks (looking at the commit history of the PR) as if it now has a commit history that includes all the steps master -> v7.0.0 branch -> your PR  (so, your branch is indeed re-based on top of the v7.0.0 branch commits).  \nWhat I should have also said (/said more clearly), is that your PR should also be requesting to merge into v7.0.0, not master, ie we should change the PR's base branch (where it wants to merge into) to v7.0.0.  At the moment your PR still has master as the base branch:\n\n... which makes it looks as if your PR has 15 commits and 219 changed files (which indeed it would, if merged now straight into master).\nDo you want to switch the base-branch to v7.0.0 as well, as per here?  This, if you like, takes your PR and \"re-plants\" it as a new branch off the commit that is the current HEAD of the v7.0.0 branch.  Then we'll check it all looks clean enough (with that combination of re-base and change-base-branch).  I may have complicated things by pushing a few commits to v7.0.0 in the meantime \ud83d\ude42 , but let's see how GitHub copes if you just change the base branch now.  . @moerwald Thanks for changing the base branch! That looks great.  (I may squash-merge the PR in any case when we merge it, just in case the history is in any way confused.)\n@moerwald If you want to see the relations between the branches and their history, a git GUI like sourcetreeapp can be great for demystifying git, by the way.  (SourceTreeApp currently makes you sign up for a bitbucket or similar account on install, but you don' have to use it - you can point SourceTreeApp at github repos after install.). @moerwald Apologies, I am going back on my previous comment: Can I suggest that we abandon this PR?  It looks good in GitHub web gui (and might squash ok), but the history seen from git command line and desktop git apps is of diverged branches. Can I ask you to branch afresh from the head of the v7.0.0 branch, and then re-impose your changes from commit 443c5b9?  Thanks for your patience!\nSecond reason: @SeanFarrow @moerwald , I think some confusion may have crept in around the ReadOnlyRegistry property in the IReadOnlyPolicyRegistrySpecs.  This dates from a couple of years ago when the tests were originally authored; @moerwald had only added a readonly modifier (which seems reasonable) to the private _registry field. I'd like to suggest we retain the ReadOnlyRegistry property and don't re-impose the second commit on the new PR.  \nTo explain; It's a bit of a nit, but the intent of IReadOnlyPolicyRegistrySpecs is to test PolicyRegistry as seen through the IReadOnlyPolicyRegistry<T> interface, so I think that is what the tests should test.  There's a subtle difference between testing via IReadOnlyPolicyRegistry<T>, via IPolicyRegistry<T> or via the concrete class PolicyRegistry<T>, because the behaviour could be different if PolicyRegistry used explicit interface implementation, as this gist shows.  A bit of a nit, as we don't actually use explicit implementation in PolicyRegistry, but retaining the ReadOnlyRegistry property means the tests do test what they say they test. ... ... Anyway, this distracts from the great work we are all doing tidying the codebase :+1: :+1: (thank you!), just wanted to explain why the tests had that approach.\nThanks for everything you are doing!. Hi @SeanFarrow . Re;\n\nWhilst that all makes sense (and I agree with you), it might be worth adding some comments to the tests themselves to ensure this kind of thing doesn\u2019t happen again?\nI\u2019m happy to do this once @moerwaldhttps://github.com/moerwald has rebased and changed the commits.\n\n... that's a great idea!  Please feel free to make a PR to add a note like that to ReadOnlyPolicyRegistry on IReadOnlyPolicyRegistrySpecs . I've merged @moerwald 's new PR already so that (after the many changes) we can get a merge on that \ud83d\ude42 , but just add a comment in separate PR any time.. @moerwald Awesome. Merging! Thank you!. Hi @digitalmedia34 . Thanks for the question.  You might be better to ask this question on the Dapper repo or StackOverflow.  There will probably be some restrictions on how the SQL transaction or the dapper elements governing them should or should not be instantiated, closed again, or re-used, but that will be Dapper-specific knowledge that I can't offer with a Polly hat on.  (I have used Dapper but it was a while ago ...)\nAlso, your suspicions here sound reasonable based on the info given:\n\nmy suspicion is that I am encountering an error with sql server, polly is retrying (like it should) but the transaction still active\n\nGood idea also to post example code with a question like this.  It is hard to give any insight (spot any possible smoking guns) without an example of how the code looks.\nApologies that time will not permit me to dig into this one more deeply.  \nAnyone with Dapper insight very welcome to comment!\n. Thanks @moerwald ! Looks good!  I'm pushing a credit to you in the readme for all these clean-ups! (hope that's ok \ud83d\ude42 ). Resolved conflicts with other cache work in v7.0.0. Merging. Thanks again!. Thanks!. Thanks!. Thanks!. Thanks!. Thanks Bryan! Merging.. Thanks @maartenoosterhoff . That unwanted change that slipped in wasn't picked up by unit tests because of InternalsVisibleTo the test assembly.  \nFixed in #585 . v7.0.2 should release to nuget, fixing this, in the next few hours.\n. Thanks @diegodancourt .  This will be fixed in #589 . Closed by release of v7.0.3. TL;DR\n\nWill Polly use same request in each retry?\n\nYes\n\nA Polly retry policy in a delegating handler created by HttpClientFactory does not create a new HttpRequestMessage; it just retries using the HttpRequestMessage which has been passed to it.  The lifetime/scope of HttpRequestMessage is controlled by whatever created it - HttpClient, or your code if you create the HttpRequestMessage and pass it into an overload on HttpClient which takes HttpRequestMessage as an input parameter.\nTo understand how HttpClientFactory uses the policy in a delegating handler, here you can see the latest source code of the DelegatingHandler which HttpClientFactory creates, to wrap the Polly policy.\n\nThe extension overload you quote \npublic static IHttpClientBuilder AddPolicyHandler(this IHttpClientBuilder builder, Func<IServiceProvider, HttpRequestMessage, IAsyncPolicy> policySelector);\n\ntakes the existing HttpRequestMessage as an input parameter, and returns (selects or creates) a policy using it.\n. @Shilp I am not sure that this is an issue with Polly.  It could be to do with how your particular .NET framework 4.5.2 project was set up.  I just created a .NET framework 4.5.2 Console App, installed Polly 5.3.1 into that, and everything worked.  Can you try that sequence?  If that works, you should look for what is different about your other .NET 4.5.2 project where you have a problem.\nAlso: Do you have the .NET Standard 2.0 SDK installed?  See https://blogs.msdn.microsoft.com/benjaminperkins/2017/09/20/how-to-install-net-standard-2-0/ ; https://dotnet.microsoft.com/download. @maklipsa . Here is a sketch of a concept to get you a quick answer (rather than leave you waiting longer for an answer).  The behaviour can be expressed with existing Polly features using a pattern such as below.  Note: this is a sketch to give you all the elements of a solution; you will likely want to factor parts of this out into helper classes or methods, add defences for edge-cases, proper cancellation etc.\nTL;DR: for separate circuit-breaking per downstream server, create, maintain and reuse an instance of a circuit-breaker per downstream server.\n\nGiven:\nstring[] servers = new []\n{\n    \"http://server1.whatever.com\",\n    \"http://server2.whatever.com\",\n    \"http://server3.whatever.com\",\n};\n\nconst string ServerIndexKey = \"ServerIndexKey\";\n\nPolicyRegistry registry = new PolicyRegistry();\n\nDeclare policies such as:\nFunc<IAsyncPolicy<string>> circuitBreakerFactory = () => Policy<string>.Handle<Exception>().CircuitBreakerAsync(3, TimeSpan.FromSeconds(10)); // Or more refined fault-handling, such as only certain exceptions; also http result-codes\n\nvar multipleServerRetryPolicy = Policy\n    .Handle<Exception>() // Or more refined fault-filtering ...\n    .WaitAndRetryForeverAsync(\n        sleepDurationProvider: (attempt, context) => TimeSpan.FromMilliseconds(30)\n        , onRetry: (exception, timespan, context) => // Of course, can factor this out to a nicely-named method SelectAnotherServer() or similar.\n        {\n            int currentServer = context.GetValueOrDefault<int>(ServerIndexKey);\n            currentServer = (currentServer + 1) % servers.Length;\n            context[ServerIndexKey] = currentServer;\n        }\n    );\n\nAnd execute with:\nvar text = await multipleServerRetryPolicy.ExecuteAsync(async (context, token) =>\n        {\n            int server = context.GetValueOrDefault<int>(ServerIndexKey);\n            string url = $\"{servers[server]}/localpath/etc\"; // Or of course, the localpath part passed in from outside ...\n            var breaker = registry.GetOrAdd($\"breaker{server}\", circuitBreakerFactory);\n            return await breaker.ExecuteAsync(() => client.GetStringAsync(url));\n        }, new Context(), default(CancellationToken));\n\n( EDIT: If you wrap this into a helper class which maintains state of the last-used server, then you can also prevent the next call starting with server 0 (zero) again, by passing new Context(){[ServerIndexKey] = lastServer} in to Executeasync(....) rather than just new Context(). )\nWhere you have extension methods:\npublic static IAsyncPolicy<TResult> GetOrAdd<TResult>(this PolicyRegistry registry, string key, Func<IAsyncPolicy<TResult>> policyFactory)\n{\n    if (registry.TryGet(key, out IAsyncPolicy<TResult> policy))\n    {\n        return policy;\n    }\n\n    var newPolicy = policyFactory();\n    registry[key] = newPolicy;\n    return newPolicy;\n}\n\npublic static T GetValueOrDefault<T>(this Context context, string key)\n{\n    if (context.TryGetValue(key, out object objValue))\n    {\n        return objValue is T value ? value : default;\n    }\n    return default;\n}\n\n\nExplanations (in relation to the solution above, and some points raised in your question):\n\nCircuit-breaker state is not scoped to OperationKey.\nCircuit-breaker state is intentionally scoped to circuit-breaker policy instance.  So, for separate circuit-breaking per downstream server, create, maintain and reuse an instance of a circuit-breaker per downstream server.  The above code uses PolicyRegistry to do this. Of course, you could use other techniques like just manage an array IAsyncPolicy<string>[] \nThe retry policies do have onRetry: overloads taking Context as an input parameter - shown above.\n\n\nLet us know if that is enough info; or if any questions.. @maklipsa . It should still be usable with CachePolicy. The code sample I presented used new Context() at the multipleServerRetryPolicy.ExecuteAsync(...) call, only because I understood that was the outermost policy call.  If the execution already has a context instance created further out in the call chain, simply pass that existing context instance in to the call through multipleServerRetryPolicy instead of new Context():\n// instance 'context' created further out in the call chain\ncontext[ServerIndexKey] = /* add information about the previously-used server to the context before making the execution, if you have it. */ ;\nawait multipleServerRetryPolicy.ExecuteAsync(async (context, token) =>\n    {\n        /* as before */\n    }, context, default(CancellationToken));\n\n. @maklipsa What will not be possible is to condense your goal into a single PolicyWrap instance, in the style illustrated in your preceding post.  A single PolicyWrap instance defines a fixed sequence of policies.  However, you need to vary the circuit-breaker policy instance - to select a single long-lived policy instance per downstream server - to maintain separate circuit-state per downstream server, as described in my previous post.  This cannot be achieved with PolicyWrap: you will need to break out of a single PolicyWrap to do so (or write a custom policy to keep it in a single PolicyWrap).  \nOptions to make that tidier:\n\nstill use PolicyWrap for everything outside multipleServerRetryPolicy; or\ndefine an end-to-end PolicyWrap (all policies) per downstream server, with each PolicyWrap including the correct circuit-breaker; or\nthe notion of 'selecting the correct circuit-breaker policy' in my previous comment could be encapsulated into a custom policy.  From Polly v7, it is possible for you to author policy implementations outside Polly which slot straight into Polly's PolicyWrap.  So encapsulating the circuit-breaker-selection into a new policy would allow you still to build one overall PolicyWrap instance to handle the whole operation.\n\nYou could take this part of the implementation from my previous post:\nint server = context.GetValueOrDefault<int>(ServerIndexKey);\nvar breaker = registry.GetOrAdd($\"breaker{server}\", circuitBreakerFactory);\nreturn await breaker.ExecuteAsync(/* whatever was executed through the policy */);\n\nand make it the implementation for a custom IAsyncPolicy<TResult> following the process in this blog post.  \nEDIT: If you decide to go the custom policy route on this, please let us know!  It would be awesome to take that into Polly-Contrib!  The blog post points to templates to make this easy.. @maklipsa It seemed fun to try the custom policy-selector policy.  Here is a 15-line custom policy you could use with Polly v7.0 to select a policy according to information in Context.  You could keep your whole operation (with circuit-breaker-switcher) within one PolicyWrap, by making use of a custom policy-switcher like this:\npublic class AsyncPolicySelector<TResult> : AsyncPolicy<TResult>\n{\n    private readonly Func<Context, IAsyncPolicy<TResult>> policySelector;\n\n    public static AsyncPolicySelector<TResult> Create(Func<Context, IAsyncPolicy<TResult>> policySelector)\n    {\n        return new AsyncPolicySelector<TResult>(policySelector);\n    }\n\n    private AsyncPolicySelector(Func<Context, IAsyncPolicy<TResult>> policySelector)\n    {\n        this.policySelector = policySelector;\n    }\n\n    protected override Task<TResult> ImplementationAsync(Func<Context, CancellationToken, Task<TResult>> action, Context context, CancellationToken cancellationToken, bool continueOnCapturedContext)\n    {\n        return policySelector(context).ExecuteAsync(action, context, cancellationToken, continueOnCapturedContext);\n    }\n}\n\nThe AsyncPolicySelector<TResult> takes a Func<Context, IAsyncPolicy<TResult>> to select the policy.  In your case, you would define a Func<Context, IAsyncPolicy<TResult>> which encapsulates retrieving (or manufacturing the first instance of) the circuit-breaker for the downstream server specified via Context.. Hi @maklipsa . Can we help any further with this, or do you have what you need?. @mrmartan It sounds like a classic diamond-dependencies problem.  It sounds like your main project references Polly v7.0.2, but via Microsoft.Extensions.Http.Polly you still have a reference somehow to Polly v6.1.2.\nEdit: Or possibly you have one project in a solution referencing Polly v7, another project referencing v6.\nThis isn't something we need to (or can) fix by changing Polly, afaiu.   You just need I think to get all the references from your projects to Polly to match, so that none reference different major versions via different ('diamond') routes.  The nuget tooling should get the references to Polly right for you, so that these problems do not occur.\nSuggest:\n\nManually check all the references to the Polly nuget package in your app, eg in the raw .csproj files or in packages.config (if using that).  Check all references to Polly say v7.x, none say v6.x still.\nand/or completely Clean the build (Build->Clean within visual studio, or delete existing build output folders), so that you have no copies of an older Polly.dll cached in the build\nand/or Uninstall and re-install the relevant nuget components.\n\n\nTo show what I mean, I created a .NET Core 2.2 Console App and first installed Microsoft.Extensions.Http.  Nuget references for the project then shows this:\n\nThen I manually install Polly v7.0.2 into the same project.  The nuget tooling in Visual Studio automatically sorted out the indirect reference to Polly via Microsoft.Extensions.Http.Polly so that there was no mismatch in the diamond dependencies - see below:\n\nThis ^ is the state you want to get to.\nI was then able to take exactly your extension method above AddStandardTransientHttpErrorPolicy() and configure an http client with it, compile and run.\nHope this helps.\n\nIf you think there is still something wrong, please provide an exact sequence of steps to reproduce - or a minimum verifiable example eg as a ZIP download.  . @mrmartan Also, reading again the precise exception message:\n\nCould not load type 'Polly.CircuitBreakerTResultSyntaxAsync' from assembly 'Polly, Version=7.0.0.0, Culture=neutral, PublicKeyToken=c8a3ffc3f8f825cc'.\nat Microsoft.Extensions.DependencyInjection.PollyHttpClientBuilderExtensions.AddTransientHttpErrorPolicy(IHttpClientBuilder builder, Func`2 configurePolicy)\n\nPolly.CircuitBreakerTResultSyntaxAsync is a Polly v6.x only class.  And the exception message says it is trying to find it in Polly v7.0.0.  This suggests that your app build has placed the Polly v7 dll in the output folder, but that some other dll/other binary has not rebuilt - that other binary is still built as if it thinks it is referencing Polly v6.  \nAgain, I would suggest entirely cleaning all build output folders and re-building the app. If that fails, uninstall and reinstall relevant nuget components (... but this should not be necessary if the app build can be completely cleaned).\nI have tried again to re-create the issue by uninstalling and re-installing / upgrading and downgrading each of the nuget components in various sequences, but could not reproduce the issue.\n. @mrmartan Did you get this resolved?. >You don't really want to handle a failure you want to implement a throttle\n\nI think of Polly in terms of deciding what to do, or how to cope, when something goes wrong.\n\nHi all. Yes, Polly encompasses resilience strategies beyond pure fault-handling for a while now.  Polly's wiki page on fault-handling vs proactive resilience engineering discusses and slots each policy into this broader context.\n@emilssonn Yes, a bulkhead policy is an extremely simple within-process parallelism throttle.  Note: bulkhead policy, being based on SemaphoreSlim, will clearly operate as a per-VM-instance throttle only; there is no distributed/shared state across VM instances. If your App Service plan is such that your outgoing connections limit will ever be shared across VMs, bulkhead policy as-now will not be sufficient to govern this across VMs.\n\nNotwithstanding the above caveat, I'll answer the questions about bulkhead policy scoping and sequencing with HttpClientFactory, for completeness:\n@emilssonn Your scoping of the bulkheadPolicy instance in the original post is correct for the goal stated about typed clients: to govern the separate call-streams via TestService1 and TestService2 within the same overall parallelism limit, share the same bulkhead policy instance across both, as you have done, and as we also discuss briefly in the HttpClientFactory doco here and here.\nHowever, you want to sequence the bulkhead and the retry in the other order.  You should configure:\n.AddTransientHttpErrorPolicy(p => p.WaitAndRetryAsync(3, _ => TimeSpan.FromMilliseconds(300))\n.AddPolicyHandler(bulkheadPolicy)\n\nSee the policy sequencing recommendations within PolicyWrap for explanation.  You don't (I would assume) want any of the bulkhead's capacity occupied by waiting for the next try; you want all the bulkhead's capacity dedicated to placing outbound calls. So the bulkhead should be 'inside' the wait-and-retry, only governing the downstream call, not the waits.  For more on how policy configuration order on HttpClientFactory translates into execution order/wrapping, see our diagrams in the doco.\n. Hi @JustinKaffenberger Yes, the .Handle<>() predicates are designed to be lightweight predicates which it is idempotent to evaluate more than once without causing side-effects. \nThe intentional place to hook in additional behaviour is the onRetry delegate of the retry policies (and similar delegates for other policies). If the goal is to count the number of exceptions handled, this can readily be done in the onRetry delegate.. Thanks @Gladskih.  Please follow the instructions at: https://github.com/App-vNext/Polly.Caching.MemoryCache#how-to-use-the-pollycachingmemory-plugin\nWe will update the main Polly readme to reflect those changes (or, please feel free to make a PR to do so!). Thanks @aprooks . Merging!. Closing in favour of #607, which imposes the same on the consolidated codebase.. Thanks @utkarsh5k for the exemplary repro code and accompanying notes. I believe the behaviour you are seeing is because the OnTimeoutAsync(...) method is waiting on the completion of the timed-out task (the original delegate executed through the policy), by doing await task.ContinueWith(abandonedTask =>.  TL;DR Delete await before task.ContinueWith(...) and it should behave as expected.\n\nDemonstration\n(1) Try adding a statement Console.WriteLine(\"Timed out {0} {1}\", context.OperationKey, DateTime.Now); as the first line within OnTimeoutAsync(...), before await task.ContinueWith(...). Keep await task.ContinueWith(...) for now. The output should then show that the timeout is occurring at the expected time.  (Overall, the operation will still complete with the delays posted in the question because the OnTimeoutAsync(...) still contains await task.ContinueWith(...).)\n(2) Delete the whole await task.ContinueWith(...) statement but keep the statement added above. The output should show the timeouts occurring correctly, and the overall execution should finish in a timely manner, as the walked-away-from executions are no longer awaited (but we've lost the abandoned/cancelled/completed logging and our guard against UnobservedTaskExceptions).\n(3) Reinstate the task.ContinueWith(...) statement but don't await it (omit await).  The OnTimeoutAsync(...) will attach task continuations (in TPL-style) to the walked-away-from Tasks, but not await them.  The overall execution should finish in a timely manner.  The task.ContinueWith(...) continuations will execute whenever the walked-away-from tasks (later) complete, so the console output from them should appear interspersed in the output sequence at the times those walked-away-from Tasks eventually complete.  This should demonstrate what we mean by pessimistic timeout walking away from (but not being able to cancel) the uncancellable delegates; and how the task continuation later 'mops up' their completion.  All the continuations from timed-out/walked-away-from tasks should eventually show in the console output, provided you don't let Program.Main(...) terminate first.\n\nLet me know if that ^ works as described. To see why the original behaviour was happening, see the source code here.  On timeout, the policy awaits your OnTimeoutAsync(...) delegate before throwing to exit indicating the timeout.  Since the original OnTimeoutAsync(...) code was doing await task.ContinueWith(...) where task is the blocking DoSomething(...), the execution was naturally blocked the full 6-seconds, 4-seconds, whatever ... before continuing to the next iteration of the loop.\nUPDATE: As it's pretty unusual, that we want intentinoally to not await a task in the async case, I've added an extra note about that in the wiki. Hi @confusedIamHowBoutU , thanks for the question. PolicyWrap already provides equivalent functionality, and there are no plans to have one policy handle multiple exceptions differently in any way other than PolicyWrap.  \nThere is also no intention to develop a long-running chaining syntax to result in equivalent PolicyWrap outputs (though somebody could develop it as a Polly.Contrib if they wanted to). When PolicyWrap was designed, we moved away from the long-running chaining syntax, as it was found to be limiting (/to lead to significantly more complexity) for defining policy instances which could be recombined in different ways in different PolicyWraps.  \nTo elaborate on that: Stateless policy instances can be re-used without consequence. For stateful policies circuit-breaker and bulkhead, on the other hand, it is functionally significant whether you re-use the same instance or use different instances, across call sites. So a common requirement might be to have retry -> circuit-breaker -> timeout, using a common retry policy across all endpoints, variant circuit-breaker instances with a breaker per downstream system called, and a common timeout policy.  A long-running chaining syntax doesn't lend itself to achieving that degree of control.  Concretely:\nPolicy\n    .Handle<FooException>()\n    .Retry(3)\n    .Handle<BarException()\n    .CircuitBreaker(/* etc */) // with this kind of beyond-one-policy chaining syntax, we concluded it was not elegant to extract the circuit-breaker policy instance from here as an instance that can be re-used elsewhere. \n    .Timeout(30);\n\n. One more thought:\nPolicy\n    .Handle<FooException>(() -> log.Error(\"Foo\"))\n    .Handle<BarException>(() -> log.Error(\"Bar\"))\n    .Execute(() -> DoSomething())\n\npossibly suggests combining policies via an exclusive-or switch-case-ry: \"if a then DoA else if b then DoB\" (etc) (as opposed to the functional-composition, nested-function nature of PolicyWrap).\nFor the logging example given this looks logical and simple, and it could also work for Fallback.  But my view is that it could only make sense (remain simple) to combine multiple predicates-and-consequences within a single policy instance, for these simpler kinds of action. For anything beyond (retry or circuit-breaker), reasoning about the meaning and usage (especially in combination with the pre-existing PolicyWrap) becomes complicated. Because of this limited applicability, I doubt we will invest time taking Polly in that direction.\nFor specific cases, building one's own extension methods to achieve a particular syntax is always an option.\nIf @confusedIamHowBoutU there is anything else we can help with, let us know. If logging is a particular interest, see also Polly.Contrib.LoggingPolicy.\nHope this helps!. Thanks @confusedIamHowBoutU .  From:\nPolicy\n    .Handle<FooException>()\n    .Handle<BarException>()\n    .onRertry(3, (exp, i) -> {\n         if (exp is FooException){\n               log.error(\"foo\")\n         }\n         else if (exp is BarException){\n               log.error(\"Bar\")\n         }\n    })\n    .Execute(() -> DoSomething())\nit is clearer that the question is about variant logging on retry (not about different flavours of policy behaviour in a single policy, in the direction of #140 or PolicyWrap).\n\nStep 1 of the Polly Readme demonstrates .Or<BarException>(), see the example labelled // Multiple exception types\nThe retry section of the readme shows syntax for correctly configuring onRetry:; see the third example.\nStep 3 of the readme shows syntax examples putting it all together; the second example there executes through a policy which has just been configured to log in the onRetry.. And here's a quick working example: https://dotnetfiddle.net/Sipste\nPolly-Samples also contains many more developed examples.. Thanks @aprooks , it is intended, we just haven't got to it yet \ud83d\ude42 . Added issues on the couple repos where it wasn't explicitly flagged, so that people can see it's intended.\nhttps://github.com/Polly-Contrib/Polly.Contrib.CustomPolicyTemplates/issues/9\nhttps://github.com/Polly-Contrib/Polly.Contrib.BlankTemplate/issues/5\nhttps://github.com/Polly-Contrib/Polly.Contrib.LoggingPolicy/issues/2\nhttps://github.com/Polly-Contrib/Polly.Contrib.TimingPolicy/issues/4. Hi @stephenpatten . Re:\n\ncode that won't compile\n\nFor the execute statement, use:\nusing (IDisposable handle = lockPolicy.Execute(() => this.awdLock.GetLock(caseId)))\n\nSee the examples illustrating this syntax in Readme: Step 3 Execute the policy\n(I am not sure what act was in act => the posted code - if I misunderstood an intention, let me know,)\n\n\nhandle is guaranteed to not be null, so do something\n\nhandle could be null.  If all 7 tries (first try plus 6 retries) fail, the policy will return the unhandled result null.  More info on this in the retry wiki . \nIf you want to ensure handle will never be null, you can use WaitAndRetryForever(...). With the caveat obviously that your application can stall at that WaitAndRetryForever(...) if the success condition is never met.\n\n\nI would also like to log from the policy when the fail condition is met\n\nYou can do this using the onRetry: delegate hook of the retry policy. See the examples in Readme: Step 3 Execute the policy. Here a working .NET Fiddle example: https://dotnetfiddle.net/Sipste . If you need to log when all 7 tries fail, make that part of your manual check for handle == null.\nHope that helps.. No worries @stephenpatten , you're very welcome!  If there is anything else we can help with, fire away (or open a new issue). We try to be very responsive and answer support queries within 24 hrs (but can't guarantee!)\nThanks for the offer of help. We tag 'up-for-grabs' items thus: https://github.com/App-vNext/Polly/issues?q=is%3Aissue+is%3Aopen+label%3Aup-for-grabs . Feel free to pick up anything if you want to (but there's no obligation).. Hi @pvmraghunandan . I'm understanding that you want to be able to specify a different instance of logger per execution, using the above policy.  \nThere are two ways you could achieve this with current Polly:\n(1) Define the policy immediately before use\nYou could simply define the policy immediately before use, when the correct instance of logger is in scope.  There are disadvantages: It would incur the (small) execution cost of defining the policy each execution. And obviously not in keeping with DI (eg policies defined at startup; perhaps placed in a PolicyRegistry; policies or registry then injected into usage sites by DI).\n(2) (recommended) Use execution-scoped Context to pass in the logger\nYou can pass any transient custom data into an execution using Polly's execution-scoped Context; and the onRetry delegate can have been configured to retrieve that information from Context.  \nI have just updated the wiki to give an example with ILogger: https://github.com/App-vNext/Polly/wiki/Keys-and-Context-Data#example-varying-the-ilogger-used-within-an-onretry-delegate\nDoes this meet your need?\nThe example code there passes an ILogger into an execution, but any other object can also be passed: Context has full dictionary-like semantics.\n\nTo answer a few related background questions:\nThe fact that policy instances are immutable after creation is intentional. Policy instances being mutable would create many other problems around multi-threaded use and policy use in multiple locations in an app.\nThe fact that onRetry delegate hooks are scoped to the policy at policy-configuration time, not attachable closer to execution time, goes back to the early origins of Polly (pre-dating even my involvement). I can see advantages and disadvantages both ways - and future versions of Polly could change this or provide other options - but it is not a small change.\n\nLet us know if the code example solves your issue!. fixed in #612 . Hi @Kesmy . I have a Ready for review button: will try. Not sure also if fact that the base branch (v704orv710) has been previously merged may be causing a problem.  I'll retarget this onto master shortly.\n@Kesmy If you're thinking we're done here, I'll - if ok with you - push a commit onto your PR to add credit to you (\ud83d\ude04), update the changelog, bump the gitversionconfig.yaml (I have all this ready already) ... sound ok?  Then probably retarget to master and merge :+1: . \n. @Kesmy  I tried changing the base branch of the PR to master, but the branching history is making that want to re-impose the massive project reorganisation of this commit, lists as \"can't merge\" (too many conflicts to resolve).\nAre you happy to take the changes in the 9 files in this PR, and re-impose them afresh on a branch which starts from current master? - I just made a v710 branch for this.  (ie make a new PR targeting v710; abandon this PR when happy with new one).  (Alternative could be to merge master up into your current branch, but not clear to me based on branch history whether that will come out clean or not)\nI can also take this on if you prefer, but you would lose the credit of the commits being \"yours\" (tho credit of course still in the readme \ud83d\ude00 ).   Just let me know what you prefer.\nThanks again!\nEDIT: changed the base branch of this PR back to v704orv710 again, so that we have clean sight again of the 9 files whose changes we want.. Hi @altso , thanks for the exemplary repo.  \nYou can solve this by forcing the project indirectly referencing Polly 6.x (the project PollySeven.MyHttpClient in this case) to reference Polly 7.x instead. Add a top-level nuget dependency, within that project, to Polly v7.x. This forces the indirect dependencies also to build against Polly v7.x. The result should look like this:\n\nThe yellow-highlighted nuget reference to Polly v7.0.3 is the one you have to add.  The indirect reference to Polly via Microsoft.Extensions.Http.Polly (marked red) then falls into line and also references Polly v7.0.3.  The app then builds and starts successfully.\nThere is nothing in the Microsoft extensions to Polly which rely specifically on Polly v6 features, so this is a safe procedure.\nHere is a zip showing the fix: Issue615fix.zip\n\nFor completeness for all coming to this issue in future\nPolly v7.0 clarified the sync/async split internally in Polly policies, but no actual change in functionality on that.\nThe only other breaking change in Polly v7 is changes to cache provider interfaces. For cache providers which the Polly team maintains (Polly.Caching.Memory, Polly.Caching.Distributed and Polly.Caching.Serialization.Json), we have already released upgraded cache providers.  Thus, the only cases in which following the above procedure - forcing a Polly v7.x on an external dependency which currently references v6 - could cause a problem, , would be if the third-party component was an implementation of a custom Polly cache provider for CachePolicy, where that third-party custom cache provider had not yet updated for the v7 changes.\n. >Do you have any suggestions for the scenario when PollySeven.MyHttpClient is a third party library?\nHi @altso . I want to be sure I haven't misunderstood the question, but I think the case discussed does illustrate a third-party library. In the above example, Microsoft.Extensions.Http.Polly, which is what was referencing Polly >= v6.0.1, is a third-party library. In all cases, there must ultimately be some project-of-your-own which is referencing that third-party library, and in that project-of-your-own, you add a top-level reference to Polly v7.\nDoes that make sense, or is there a case you are thinking of which I am not seeing?\n\nSidenote: Where this would not work would be if a third-party library had restricted their library from inter-operating with versions of Polly higher than v6, eg with a dependency directive such as:\n<PackageReference Include=\"Polly\" Version=\"[6.0,7.0)\" />\n\nBut it would be against common/recommended practice for a library to have done that, as per eg the Microsoft diamond dependencies page (\"Avoid NuGet package references with a version upper limit\"). And there would be no reason for a library referencing Polly to have done that - unless they are a cache provider release only compatible with v6.. Hi @altso. Ok, let's try it. No need to publish the nuget package to public nuget: you can also drag the .nupkg file into this conversation; I can work with a local copy.\n. Thanks @altso, that's a great example. I see how this arises. Agreed that the breaking changes in v7 mean that an app fails with a runtime failure in this diamond-dependencies-conflict case. Note that this is a common concern for OSS libraries, not unique to Polly.\nTo your question:\n\nDo you have any suggestions for the scenario when PollySeven.MyHttpClient is a third party library?\n\nIf this arises (... I am assuming this is a hypothetical now; do say if not), we could:\n(a) Publish a new version of Polly, v8, which undoes the internal rearrangements to Polly code in v7 which are a partial cause; or (EDIT: I should have been clearer that I listed (a) (going backwards) to suggest that it was not really a serious option... )\n(b) Ask the third-party library to provide a version of their library built against Polly v7.\nYou can see the dilemma. I think the sensible position for me as a library maintainer is to recommend (b). ;~) This is a general question for any OSS library. OSS libraries evolve - we cannot (in a general sense) be held back from evolving by third-parties who may choose not to evolve with us. On the other hand, of course we have a responsibility to promote stability in the ecosystem and strive to avoid frequent breaking changes. In general on Polly we have promoted stability for a long time (no breaking changes for 10 months ... then for 18 months before that ... ... tho not sure that is always a good metric: there are significant breaking changes to Polly syntax (edit: also not affecting httpclientfactory) that it would be good to introduce to open up new development paths!).\nI hope that makes sense for now?  Open to feedback if people think we are getting this wrong.  \nIf a case arises, let's tackle it, but my instinct is that the first approach for your question should be (b).. Thanks @altso for the deep engagement on this issue. Re the fact that (a) would introduce another breaking change: yes, very much so, hence (per semver) my flagging that the replacement would be v8. \nI agree that an approach along the lines of (c) might be possible in principle (not tried it, but I see the logic...), but in this case I think we cannot achieve it. We cannot:\n\nbring back all the missing types and methods with the same exact signatures as they had in v6\n\nbecause, as you observe, the return type for the async policies has (intentionally) changed so that they are now separate AsyncRetryPolicy<TResult> not RetryPolicy<TResult>; so in fact it is not possible to supply a bridge class with methods of the exact same signature. This change is one of the intentional breaking changes of Polly v7 to clarify policy use. (Again, if you/anyone can see something clever I'm missing, fire away.)\n\nThere is also a fourth approach I forgot yesterday:\n(d) ILMerge or ILRepack to hide the dependency on one axis. \nI haven't tried this, and don't know if ILMerge and ILRepack are still a \"thing\", but worth keeping on the radar. It would only be needed in the case that a third-party who had been asked to update their library to v7, per suggestion (b) above, was unresponsive or unwilling. It might be possible in that case to ILRepack/ILMerge-ing their dll-built-against-Polly-v6 to merge Polly v6 in with it, thus hiding the Polly v6 dll.  \nBut (b) is the obvious preferred route. \nThe HttpClientFactory case is already solved per my earlier comment. I've added guidance on this on both the Polly v7 page and Polly with HttpClientFactory page.. Thanks @altso .\nI'm going to close this out as I think we're concluded, but please do re-open if you have further comments/questions; the discussion has surfaced lots of useful detail. \nTL;DR It's the result of an (intended) breaking change between Polly v6 and v7; and yes, diamond-dependency conflicts are a fact of life in the ecosystem if third-party libraries do not update.\n. Awesome, @Kesmy ! Merging to v710, then down to master.  . Hi @CNBoland .  It works if you reconfigure the RetryPolicy as shown in my example here: https://dotnetfiddle.net/n4ENwo - variant Test 3\nWhat is happening in Test 2, is that .HandleInner(...) aggressively extracts the inner exception matched as described here.  Now, the BrokenCircuitException which is being thrown by the circuit-breaker contains the exception which caused the circuit last to break as the InnerException.  In Test 2, the BrokenCircuitException is being thrown, it's just that the retry policy is aggressively extracting the inner InvalidOperationException of it.\nIf you resequence the handle clauses of the retryPolicy as shown - per my example, Test 3 - \n.Handle<BrokenCircuitException>()           // <= Use this line for Test 3\n.OrInner<InvalidOperationException>()       // <= Use this line for Test 3\n\nthen the retry policy matches the BrokenCircuitException first (before the .OrInner<>() is evaluated), and you get the result you expect.\nLet me know if this makes sense.. @AlexanderSysoev Thank you for the clear problem description and full working example. If you step-debug through running your test Should_retry_when_db_exception_is_thrown_async() and set appropriate breakpoints, you should see that the code is causing re-entrancy of the InternalInterceptAsync(...) method.  \nIf we change the relevant code to this:\n    private object InternalInterceptSync(IInvocation invocation)\n    {\n        Console.WriteLine(\"Starting fresh execution through the sync policy.\");\n\n        return Policy\n            .Handle<DatabaseException>()\n            .WaitAndRetry(RetryIntervals, (exception, timeSpan) =>\n            {\n                Console.WriteLine($\"Exception {timeSpan}\");\n            })\n            .Execute(() =>\n            {\n                invocation.Proceed();\n                return invocation.ReturnValue;\n            });\n    }\n\n    private async Task<TResult> InternalInterceptAsync<TResult>(IInvocation invocation)\n    { \n        // Add a breakpoint here when step-debugging.\n\n        Console.WriteLine(\"Starting fresh execution through the async policy.\");\n\n        return await Policy\n            .Handle<DatabaseException>()\n            .WaitAndRetryAsync(RetryIntervals, (exception, timeSpan) =>\n            {\n                Console.WriteLine($\"Exception {timeSpan}\");\n            })\n            .ExecuteAsync(async () =>\n            {\n                invocation.Proceed();\n                var task = (Task<TResult>)invocation.ReturnValue;\n                return await task;\n            });\n    }\n\nthen the test output confirms the re-entrancy is occurring for the async case:\nShould_retry_when_db_exception_is_thrown_sync\n===============================\nStarting fresh execution through the sync policy.\nException 00:00:01\nException 00:00:05\nException 00:00:10\n\nShould_retry_when_db_exception_is_thrown_async\n===============================\nStarting fresh execution through the async policy.\nException 00:00:01\nStarting fresh execution through the async policy.\nException 00:00:01\nStarting fresh execution through the async policy.\nException 00:00:01\n\nI am afraid that I don't know the DynamicProxy AsyncInterceptor library, to know why that re-entrancy might be occurring - or if it is intended that async operations can be invoked multiple times with that library in that way.  You can ask that question of the DynamicProxy AsyncInterceptor library.\nWe have unit tests confirming that Polly does cycle through the RetryIntervals correctly in the async case. \nI see also from your similar question/answer on StackOverflow that you experienced similar issues with hand-crafted retry.. @yevhen This overload RetryAsync(this PolicyBuilder policyBuilder, bool continueOnCapturedContext) doesn't make use of the supplied continueOnCapturedContext value.  Does it want a small correction to:\nreturn policyBuilder.RetryAsync(1, continueOnCapturedContext); ?\n(Apologies @yevhen @joelhulen for intervening but hope useful - I spotted this while doing some exploratory investigation of how to add cancellation support!)\n. Request move bool continueOnCapturedContext to be last parameter, in ImplementationAsync\n. Request add overload, not optional parameter, because of optional-params-compiled-at-callee-not-caller problem in c# implementation of optional parameters\n. Request move bool continueOnCapturedContext to be last parameter, in ExecuteAsync()\n. Request move bool continueOnCapturedContext to be last parameter, in ExecuteAndCaptureAsync()\n. Request move bool continueOnCapturedContext to be last parameter, in ExecuteAsync()\n. Request move bool continueOnCapturedContext to be last parameter\n. Per previous discussion, move bool continueOnCapturedContext to after sleepDurations\n. Per previous discussion, move bool continueOnCapturedContext to after sleepDurations\n. Per previous discussion, move bool continueOnCapturedContext to after sleepDurations but before Action\n. (you guessed it - move bool to after sleepDurations before onRetry)\n. Remove Done if unused?\n. Remove Done if unused?\n. @nelsonghezzi In these tests, do you think it may be more direct to use bool onRetryInvoked = false; ,  and have the onRetry delegate => { onRetryInvoked = true; }; etc?  A small change, but that way we could avoid the magic strings \"original_value\" and \"new_value\"... \nEDIT: This would also bring the tests closer in style to others in the codebase - the simple form like PolicySpecs.Executing_the_policy_action_should_execute_the_specified_action(). \nAnd: many thanks once again for your contribution! (A number of people asked for this feature...)\n. @SteveCote Minor thing.  At this point in RetryPolicyStateWithSleep, I think we should do:\n(exception, span, i, c) => onRetry(exception, span, c)\ninstead of\n(exception, span, i, c) => onRetry(exception, span, context)\nThe latter will cause the compiler to have to create a closure over the delegate, to supply the value of context, which will make the code do extra work.\n. @SteveCote Same here, I think we should do:\n(exception, span, i, c) => onRetry(exception, span, c)\nto avoid the extra closure over the context variable\n. @SteveCote Great stuff navigating all the extra overloads for the async retry syntax.  In each of the four new overloads added to RetrySyntaxAsync, we need a minor change to the intellisense documentation here (like you already have in the sync versions):\n\non each retry with the raised exception, current sleep duration, retry count, and context data.\n. Thanks for this @kbilsted . Suggest just remove 'but' from this sentence for grammatical correctness.\n\n@joelhulen looks like a good clarification from @kbilsted to merge!\n. Thanks @twsouthwick .  Deprecated tfm removed.\n. Thanks @twsouthwick .  Changed nuspec to state only the  \"NETStandard.Library\": \"1.6.0\" metapackage as dependency.  ( EDIT: I had the metapackage targeted originally, but had been partly misled by Rich Lander's other article of the same day which seemed to suggest that targeting individual packages was valid again, in order to make distributions smaller.)\n. Thanks @twsouthwick .  Yes, we're removing the PCL259 target in favour of the .NET Standard 1.0 target, as part of shortly-forthcoming Polly v5.0 RTM.  We figured last summer this was the way to go, but were deep in the many new features for Polly v5.0, and unsure at that time which would be the lowest .NET Standard we'd be able to target.  \n(Looking forward to tidying up the solution further when Visual Studio \"15\" / 2017 is out at RTM / with stable project migration. I see from the Visual 2017 RC release notes couple days ago that the migration tooling is still at preview.)\nThanks @twsouthwick for all your input and support with this!\n. :+1: Thanks @twsouthwick .  Will definitely revert to you if we have any qs when the VS2017 tooling comes out.  Great to have support direct from the MS teams.. We could remove cancellationToken.ThrowIfCancellationRequested(); to make the \"noop\" concept completely pure.\n(and similar elsewhere where same pattern). Could remove the DelegateResult<TResult> allocation.  The delegateOutcome.Result below only returns the action(cancellationToken) that has just been passed in to the ctor.  \n(similar where same pattern on async side). On the unit-test side, could be nice to have four-line(?) test expressing that NoOpPolicy does actually execute the delegate.  bool executed = false; flipped to true by executing deleg through policy\n(similar elsewhere across async / TResult pattern). @lakario  Additional tiny spot: we want to add a .ConfigureAwait(continueOnCapturedContext) here.  We place these on every await, to guarantee we honour the user's choice of continueOnCapturedContext all through an async call.\n(I've been using Resharper plugin to monitor these ; we are also considering adding the relevant Roslyn analyzer in the CI build)\nHuge thanks for all your work on this!. @lakario Just adding NoOpPolicy doco to the readme and changelog, will look over spec name in the same commit (no probl). Namespace should be Polly.Specs.Registry, to match others.  (Visual Studio will have inserted that .SharedSpecs. on file creation, due to the name of the shared specs library...). Because the test assigns the same instance policy to r[key] twice, it doesn't prove that the first value at r[key] has been overwritten by the second assignment.  But it looks like this test has been superseded anyway by Should_Overwrite_Existing_Policy_If_Key_Exists_When_Inserting_Using_Idexer(), which does check the overwrite :+1: .  So, perhaps this test can simply be deleted?. Should the indexer section of this test be removed, now that we have the test Should_Allow_Adding_Policy_Using_Indexer() below?\n(Or: If intent is to show/test that we can mix adding policies using .Add(...) and indexer, maybe state that explicitly in the // comment, or pull out into separate test with title stating that, eg: Should_be_able_to_mix_adding_policies_with_Add_and_indexer.). We've tended to use lower case for words in the spec name, except if that word is a class / property / method etc normally capitalised in C#.  We've also tended to use Should_be_able_to instead of Should_allow (apart from where we mean allow only one instead of allow two)\nSo: Should_be_able_to_add_Policy_using_Add()\n(No biggie, but it would be nice to make consistent.) (Similarly, in other specs.). Where spec is inserting two different policies against two different keys, it may be slightly clearer (quicker to understand intent at a glance), if we use different variables for the second policy and key (eg key2, policy2), rather than re-using existing variables policy and key.  What do you think?\n(Similarly, in other specs.). Remove indexer section from test, given there is an equivalent separate test below?. To assert they are the exact same instance, the usual FluentAssertion is Should().BeSameAs().  \nShouldBeEquivalentTo() is not quite the same semantics, as (afaik) it will compare that we have got an instance with the same property values, but it may be a different instance.  That difference could be crucial, in the context where users want to reuse the identical circuit-breaker instance so as to share the breaker state.  So we could tighten spec with Should().BeSameAs()?  (Similarly in other specs.)\n(It happens that the specs using ShouldBeEquivalentTo() (as currently) would distinguish different instances because of the default behaviour of PolicyKey to include a guid-part, but that makes the test rely on that unrelated behaviour.). typo: Idexer -> Indexer. Throughout the DefaultPolicyRegistry and IPolicyRegistry intellisense/help documentation, I think it would be great to move away from general-to-all-dictionaries terminology 'value' and 'collection' etc, instead use language specific to policy registry. So:\nvalue -> policy\nelement -> policy\ncollection -> registry. (((maybe?))) Removes the  stored under the specified key from the registry. (((maybe))) otherwise, null.. ? The property is retrieved ?. To follow the standard Microsoft style for generic type parameters, I suggest we call the type parameters TKey and TPolicy.  . otherwise, null.. Maybe .ShouldNotThrow() is redundant (can be removed) throughout this test.  .ShouldNotThrow() is perfect where it adds semantic value to the test, to state \"this call shouldn't throw\" - to make a contrast with elsewhere in the test (or other circumstances perhaps in different tests) where the same call might throw.  In this case, we never expect ContainsKey(...) to throw with a non-null key, so maybe _registry.ContainsKey(key).Should().BeTrue(); is just more readable?\nWhat do you think?  Simplicity better?  See if you think the same applies elsewhere?. Would be nice also to have the complementary test: Should_throw_while_retrieving_using_indexer_when_key_does_not_exist. Exactly: ExceptionDispatchInfo.Capture(...).Throw().\nThe wrinkle is that .NET4.0 (one of our compile targets) does not support it.  We can consider solutions such as offered here; or whether we exclude .NET4.0 from this, ie do not fix #270 for .NET 4.0.. Thanks @udlose for the observations!  Re:\n\nAnd what do you think should happen when there happen to be multiple inner exceptions? \n\nA general Task could, as you say @udlose , throw an AggregateException with either single or multiple InnerExceptions.  In this case however we know the specific way this Task is invoked.  In all tests empirically, this is throwing an AggregateException with a single InnerException.  Even if the myDelegate executed as TimeoutPolicy.Execute(() => myDelegate) throws multiple inner exceptions, the result is an: \nAggregateException -> AggregateException -> (multiple inner exceptions), and we can (as the PR does) strip off the outer AggregateException, so that the exception the policy rethrows matches the exception that would be thrown if the delegate was not executed through pessimistic TimeoutPolicy  - this is the goal.\nGiven our confidence that all AggregateExceptions thrown here will be an AggregateException with single InnerException, we could plausibly drop the ex.InnerExceptions.Count == 1 check.  However, I suggest we retain it, as it prevents Polly ever invisibly throwing away information, should the delegate throw an aggregate-with-mutliple-inners exception.\nRe:\n\nSomething like ex.Flatten() should probably be used here.\n\nCouple of reasons why we have chosen not to ex.Flatten() within Polly.  First, a principle for Polly policies is that they should not cause any side effects to the way the user's delegate is executed, or expresses exceptions, beyond the stated aim of the policy.  If we choose to ex.Flatten() within the library, that causes a side effect as it changes the way exceptions from the user's delegate are expressed - makes it different between executing the delegate without Polly or with Polly.  Second, if we choose to ex.Flatten() from within the library, we take away from the user the choice of whether to ex.Flatten().  . @hambudi Your spec here provides perfect coverage to demonstrate that an aggregate exception thrown within the Policy is correctly unwrapped.  \nI built on yours to add couple more specs which demonstrate the cases when the AggregateException thrown within the user delegate contains multiple InnerExceptions.  Would you be happy to add these (if you agree they are useful) to your PR?\n```c#\n    [Fact]\n    public void Should_rethrow_aggregate_exception_with_multiple_exceptions_from_inside_delegate__pessimistic()\n    {\n        var policy = Policy.Timeout(TimeSpan.FromMilliseconds(50), TimeoutStrategy.Pessimistic);\n        var msg = \"Aggregate Exception thrown from the delegate\";\n\n        Exception innerException1 = new NotImplementedException();\n        Exception innerException2 = new DivideByZeroException();\n        AggregateException aggregateException = new AggregateException(msg, innerException1, innerException2);\n        Action action = () => { throw aggregateException; };\n\n        // Whether executing the delegate directly, or through the policy, exception behaviour should be the same.\n        action.ShouldThrow<AggregateException>()\n            .WithMessage(msg)\n            .And.InnerExceptions.Should().BeEquivalentTo<Exception>(new[] {innerException1, innerException2});\n\n        policy.Invoking(p => p.Execute(action)).ShouldThrow<AggregateException>()\n            .WithMessage(msg)\n            .And.InnerExceptions.Should().BeEquivalentTo<Exception>(new[] {innerException1, innerException2});\n    }\n\n    [Fact]\n    public void Should_rethrow_aggregate_exception_with_example_cause_of_multiple_exceptions_from_inside_delegate__pessimistic()\n    {\n        var policy = Policy.Timeout(TimeSpan.FromMilliseconds(50), TimeoutStrategy.Pessimistic);\n\n        Exception innerException1 = new NotImplementedException();\n        Exception innerException2 = new DivideByZeroException();\n        Action action = () =>\n        {\n            Task task1 = Task.Run(() => { throw innerException1; });\n            Task task2 = Task.Run(() => { throw innerException2; });\n            Task.WhenAll(task1, task2).Wait();\n        };\n\n        // Whether executing the delegate directly, or through the policy, exception behaviour should be the same.\n        action.ShouldThrow<AggregateException>()\n            .And.InnerExceptions.Should().BeEquivalentTo<Exception>(new[] {innerException1, innerException2});\n\n        policy.Invoking(p => p.Execute(action)).ShouldThrow<AggregateException>()\n            .And.InnerExceptions.Should().BeEquivalentTo<Exception>(new[] {innerException1, innerException2});\n    }\n\n    [Fact]\n    public void Should_rethrow_aggregate_exception_with_another_example_cause_of_multiple_exceptions_from_inside_delegate__pessimistic()\n    {\n        var policy = Policy.Timeout(TimeSpan.FromMilliseconds(50), TimeoutStrategy.Pessimistic);\n\n        Exception innerException1 = new NotImplementedException();\n        Exception innerException2 = new DivideByZeroException();\n        Action action = () =>\n        {\n            Action action1 = () => { throw innerException1; };\n            Action action2 = () => { throw innerException2; };\n            Parallel.Invoke(action1, action2);\n        };\n\n        // Whether executing the delegate directly, or through the policy, exception behaviour should be the same.\n        action.ShouldThrow<AggregateException>()\n            .And.InnerExceptions.Should().BeEquivalentTo<Exception>(new[] { innerException1, innerException2 });\n\n        policy.Invoking(p => p.Execute(action)).ShouldThrow<AggregateException>()\n            .And.InnerExceptions.Should().BeEquivalentTo<Exception>(new[] { innerException1, innerException2 });\n    }\n\n```\n@udlose These specs demo what I mentioned in previous comment: if the delegate executed through TimeoutPolicy in TimeoutStrategy.Pessimistic throws an AggregateException -> (multiple inner exceptions), that gets expressed within Polly (due to the way this strategy has to execute the delegate) as AggregateException -> AggregateException -> (multiple inner exceptions), and @hambudi 's PR correctly strips off the outer AggregateException.\n. ((suggest change to))\nBuilds a <see cref=\"PolicyResult\" /> representing a successful execution through the policy.. ((suggest change to))\nThe policy execution context. ((Suggest add, for 'returns'))\nA <see cref=\"PolicyResult\" /> representing a successful execution through the policy.. ((suggest change to))\nBuilds a <see cref=\"PolicyResult\" /> representing a failed execution through the policy.. ((suggest change to))\nThe policy execution context. ((Suggest add, for 'returns'))\nA <see cref=\"PolicyResult\" /> representing a successful execution through the policy.. ((suggest change to))\nThe policy execution context. ((suggest change to))\nThe result returned by execution through the policy. ((suggest change to))\nBuilds a <see cref=\"PolicyResult\" /> representing a successful execution through the policy.. ((suggest add, for 'returns'))\nA <see cref=\"PolicyResult\" /> representing a failed execution through the policy.. ((suggest change to))\nBuilds a <see cref=\"PolicyResult\" /> representing a failed execution through the policy.. ((suggest change to))\nThe policy execution context. ((suggest add, for 'returns'))\nA <see cref=\"PolicyResult\" /> representing a failed execution through the policy.. ((suggest add, for 'returns'))\nA <see cref=\"PolicyResult\" /> representing a failed execution through the policy.. ((suggest change to))\nBuilds a <see cref=\"PolicyResult\" /> representing a failed execution through the policy.. ((suggest change to))\nThe policy execution context. ((suggest change to))\nThe result returned by execution through the policy, which was treated as a handled failure. We need to make the async version of CachePolicy follow the same pattern, so I think we need to:\n\nmake the same change on line 11 of of CacheEngineAsync, ie change the incoming ttl parameter to ITtlStrategy<TResult> ttlStrategy\nmake consequent changes to CachePolicyAsync.cs, exactly same pattern as CachePolicy.cs already changed\nconsequent changes to CacheTResultSyntaxAsync.cs, exactly same pattern as for CacheTResultSyntax.cs already \n\n@awarrenlove Are you good to bring those changes in?  Basically just making the async version of the cache policy in line with the sync changes you have already done. Because we have discontinued .NET4.0 support from v6.x, it is ok now to re-include:\nexceptionPassedToOnTimeout.Should().BeOfType(typeof(OperationCanceledException));\n\n(and remove the comment about .NET4.0 obviously...).\nLooks like this applies in all 4 test files. Many thanks!. The existing Polly syntax pattern easily leads to over-proliferation of overloads as more options are added.  Suggest omit this overload (last overload in this group is very similar), to reduce overloads from the outset, for this feature.. Suggest omit Context input parameter, so just  Func<bool> enabled in this overload, so all parameters of this simplest overload are entirely Context-free.  This serves a simple case where fault-injection is either on/off for the whole deployment rather than Contextually on or off.. Same comment as earlier: just Func<bool> enabled for this one?. Omit this overload to reduce total number of overloads?. Omit this overload to reduce total number of overloads?. Omit this overload to reduce total number of overloads?. We also need another version of this overload where the first parameter is TResult fault.  A fault to inject could be a certain TResult value.  \nFor example with TResult is HttpResponseMessage, a typical fault to inject might be HttpResponseMessage with .StatusCode == HttpStatusCode.InternalServerError.\nThis obviously requires corresponding changes in the Implementation(...) methods in the ...Engine classes.. As earlier: We should add an additional version of this overload where the first parameter is TResult fault.  . Similar to in the sync syntax: I wonder if the enabled parameter should just be as simple as possible in this overload, eg Func<bool> enabled.  It covers the case that fault-injection is either turned on or off globally by some master switch, not context-specific.. Omit overload, to reduce overall number of overloads?. Omit overload, to reduce overall number of overloads?. Just Func<bool> enabled maybe? (as pattern elsewhere)? It covers the case that fault-injection is either turned on or off globally by some master switch, not context-specific.. Omit overload, to reduce overall number of overloads?. Omit overload, to reduce overall number of overloads?. Similar to sync case: We also need another version of this overload where the first parameter is TResult fault.. Similar to sync case: We also need another version of this overload where the first parameter is Func<Context, Task<TResult>> fault.. These overloads look like they could inject any action.  To include that is fine by me, but in that case the overloads should be named InjectCustom(...) (or similar) to indicate that?\nFor an InjectLatency(...) overload, my preference would be would be that it takes a TimeSpan | Func<Context, Timespan> parameter, and uses Polly's SystemClock.Sleep(...) delegates to achieve the latency.\nShould we leave InjectLatency(...) for @vany0114 as agreed? (if @vany0114 is still interested in contributing that).. Func<bool> enabled for the simpler overload? (as elsewhere). Func<bool> enabled for the simpler overload? (as elsewhere). Suggest:\nAction<Context, CancellationToken> fault\n\nso that user has the option to inject behaviour/latency that is responsive or not responsive to cancellation.. Action<Context, CancellationToken> fault (and similar, remainder in this file). Broadly, same comments as for sync version of this file. Func<Context, CancellationToken, Task> fault. Action<Context, CancellationToken>. Probably want something like Func<Context, CancellationToken, DelegateResult<TResult>>, to enable this to return TResult values as faults (see notes in syntax classes), \n(DelegateResult<TResult> is a \"poor-man's\" discriminated union between a TResult and an Exception.). Shall we change all the parameters from Decimal to double throughout, and avoid this cast?  No good reason (that I can think) why I put Decimal in the original proposal!. Func<Context, CancellationToken, Task>. Func<Context, CancellationToken, Task<DelegateResult<TResult>>. @vany0114 You can start whenever you want, but if you take a branch now and @mebjas has further changes to make afterwards (which is the case), then you will have to merge his further changes up into your branch (ie rebase) and deal with any conflicts (if necessary). Or: wait till @mebjas is finished, take your branch after that, and not have any potential conflicts to deal with. . @mebjas Re:\n\nOther way is to expect it to fail with an exception where the expected outcome of the original action is still TResult. And these seem as two disjoint scenarios. \nSo rather than using overload I introduced here wouldn't it be better to have ...\n\nYes, that is fine.. We considered a similar should-we-expose-it question for SystemClock, the abstracted time implementation. We chose (with misgivings) to leave it public as it was helping those using Polly write tests which manipulate the abstracted dependency in the same way that Polly's unit tests do.  For example, somebody configuring a monkey policy with a random intervention rate might also want to unit test the policy, and have the benefit of being able to override the random generator in their tests.  . Variable here ^ is controlling which exception, not \"ShouldFail\" this time, maybe we should rename this one?. Suggest move all into Polly.Retry. The existing pattern reserves sub-namespaces for Policy families (apart from Polly.Utilities which cross-cut and are mostly internal).  Placing these in Polly.Retry will also mean users can consume them without adding an extra using statement.. Polly has two main strategies for generating sleep durations:\n(a) Enumerable<TimeSpan>\n(b) variants on Func<int, ..., .... , TimeSpan>; an extracted interface would model the richest\nThe naming for (a) we are adding now should take account of the existence of (b) such that we can eventually add an interface for (b) whose name pairs nicely, eg:\n\n(a) ISleepDurationSeriesStrategy and (b) ISleepDurationFuncStrategy\n(a) ISleepDurationSeriesProvider and (b) ISleepDurationFuncProvider\n(a) ISleepDurationEnumerableProvider (etc)\n\nAny alternative suggestion fulfilling the same goal welcome! ... IEnumerableSleepDurationProvider, whatever .... Aware of this approach in various of the Azure in-built retry strategies, and love it. Nice addition. \ud83d\udc4d . Is it worth adding eg ... ? \n<remarks>When true, a first retry is made after zero delay, after which the configured backoff strategy is followed. The overall number of retries is not increased.</remarks>\n(or any shorter version of this you care to come up with!)\n(Added this comment here, but actually such a <remark> would probably be better added to the intellisense on the failFirst parameter of each individual implementation, than here on the property). What do you think of the minor variant on this algorithm proposed here?  (The variant would avoid bunching at MaxDelay.TotalMilliseconds when ms * 3 >= MaxDelay.TotalMilliseconds.). I propose we do not add new overloads to the Retry*Syntax classes, only because the overloads are already too proliferated. The new features can integrate to the existing IEnumerable<TimeSpan> overloads, as you say.\n(If the policy configuration syntax was refreshed in future to break away from methods-with-many-parameters, we could add something more direct to ISleepDurationStrategy.). >here's the lock-controlled instance of Random\n:+1:. \nAdvance info: I may (later) excerpt this to be public or internal in the Polly.Utilities namespace, in order that it may be used elsewhere in Polly, and rename it (say) LockBasedThreadSafeRandom, in contradistinction to NonLockingThreadSafeRandom which may suit the chaos use case more closely.\nNo action necessary now, just advance info. . How would you feel about renaming this GetSleepDurations()?  In the Polly API we have tended to use concrete intention-revealing names over abstract names.  \nIt does make the naming somewhat repetitious on the interface (IEnumerableSleepDurationProvider.GetSleepDurations()), but at usage sites it reads nicely:\n.WaitAndRetryAsync(backoffStrategy.GetSleepDurations(retryCount: 5)). The constant wait duration before each retry.. The constant wait duration before each retry.. In case this leads people to think the generated delays can only be whole seconds, might be better to switch the example to `ms`, eg `1547ms, 2315ms, 1389ms...`. >for each retry\n\nfor the wait before each retry.\n?. >for each retry\nfor the wait before each retry.\n?. >for each retry\nfor the wait before each retry.\n?. could add , per Microsoft recommendation for maximum randomness (or similar).\n(When encountered in intellisense, will use a shared instance probably won't transmit much meaning on its own?). As above: give example in ms to avoid suggesting whole seconds?. ?\nCan be instantiated with a custom int seed .... Suggest adding links to the Microsoft recommendation for this approach, and/or Jon Skeet's note to the same effect:\nhttps://docs.microsoft.com/en-us/dotnet/api/system.random?view=netframework-4.7.2#the-systemrandom-class-and-thread-safety\nhttps://stackoverflow.com/a/25448166/\n(as a code comment, probably outside of the intellisense?)\n(Others later will see this code out of the recent discussion context.). I propose we omit this at this stage, and don't address Enumerable<TimeSpan> for the retry-forever case.  That doesn't stop users achieving it by coding an infinite enumerable of their own and using that with the existing Retry overloads.\nExperience managing an OSS project has taught me to be cautious about adding API surface that we haven't yet had demand for, especially if it may be a minority/advanced case, and/or if there isn't a single, unambiguously correct solution.  \nI can't think of a much better solution to the 'forever' part of this API than the one proposed (just repeat the highest value), but somebody will then ask for refinement/change (\"Can it also jitter as it repeats the highest value?\"), and it risks this minority part of the API becoming a source of complexity.\nI think it's ok sometimes to leave minority cases outside of the API, to avoid increasing the API surface (all more to maintain - and more for new users arriving at the project to grok what it does) ... ... at least until / of course that viewpoint can be reversed if / we receive definite demand and/or a clearer consensus what users want.  \nThank you though for digging in intellectually to what it could be (I would have done the same).\nPutting this viewpoint out there for now - open to hearing more from users about use cases that could change this.. Could call this InitialDelay (and the corresponding ctor param, initialDelay).  I realise this changes the pattern (such that not all similar are called Delay), but it is more directly what it is?. for the wait before first retry.\n?. for the wait before first retry. for the wait before first retry. for the wait before first retry. _with_default_seed  ?. nit: guess we don't need to fix the Seed for this test, it should pass for any. nit: guess we don't need to fix the Seed for this test, it should pass for any. Unnecessary test for ConstantBackoff? (no range to speak of!).  I see it follows the pattern of tests on other backoff styles, but wonder if it just confuses readers?. Unnecessary test for ConstantBackoff? (no range to speak of!).  I see it follows the pattern of tests on other backoff styles, but wonder if it just confuses readers?. Just Should_have_expected_variance(...) ?. Duplicate of above test?. Could have similar test: Should_have_no_variance_when_factor_zero(...) ?\n(where minDelay > TimeSpan.Zero). Could call this InitialDelay (and the corresponding ctor param, initialDelay). I realise this changes the pattern (such that not all similar are called Delay), but it is more directly what it is?. Thanks, good question. I agree the downside is it separates the value initialised from the property declaration; the reason for doing it was to change the default for NextDouble from being expressed in two places, to only one place. (Intend to do same for the similar properties in SystemClock.). @grant-d Great to see \ud83d\udc4d .  I was thinking that all the configuration parameters to generate the IEnumerable<TimeSpan> should be configured together (not some in the ctor, some in a method), which essentially gives a choice between forms like:\n(1) new DecorellatedJitter(param1, param2, retryCount).GetSleepDurations() // pre-configured instance with a no-params get method\n(2) DecorellatedJitter.GetSleepDurations(param1, param2, retryCount) // static factory method on static class-per-strategy  .  Same as your SleepDurationSeriesStrategy factory class, except not overloading all variants on a single factory class\nCommunity views on advs / disadvs either way welcome.  \nPolly configuration has tended to take a static-factory-method declarative approach like (2), so my initial instinct lies here.  If a given set of parameters isn't re-used, (2) also reads more concisely than (1) with its extra new.  But an instance approach (1) could bind better with the .NET Core IOptions<> approach to config binding.  \nA disadvantage of the instance approach (1) could be if it tempts / inadvertently guides users to a singleton DecorrelatedJitter instance (or single ISleepDurationSeriesStrategy fulfilment instance) to use all around their app. Singleton configuration can be a good starting point but isn't always a good fit for real world infrastructure - it's common to have a mix of more reliable/nearby (in network terms) resources like eg other Azure resources, versus more fragile eg external legacy systems, which might need different strategies.  And the absence of named-registrations in classic Net Core DI makes multiple variant registrations of the same class/interface hard.  Then again, this could be covered by documentation.  And a recommended / more typical Polly pattern is to configure all policies at startup, so it would be less usual (tho possible) to be DI-injecting DecorellatedJitter instances into point-of-use classes, to configure a policy there.  \nCommunity views?. >should we have a check for < 0 value? across the code base\nYes, this would be good.  I saw the opportunity to add some quick boundary checks in the execution-phase in my contribution, these target the cases where the dynamic Func<..., double> variants generate some out-of-range double as well.  But for cases where the injection rate is configured as a non-dynamic Double injectionRate, configuration-time checking would be an improvement. \nTagging this mentally to be done after we've moved the codebase over to the new repo.. >why explicit recasting here?\nGood q. Without it the compiler was giving an ambiguous overload resolution error.. ",
    "joelhulen": "Bouncing off of what @reisenberger, if you guys can review the latest changes and look at the roadmap for proposed circuit breaker modifications and comment on this sticky issue, that would help open up the dialog for others in context to the current state of Polly.\n. @ilmax, @DannyRyman:\nIs this still an active issue for you? Have you considered using Reactive Extensions like @vincpa suggested?\nThis does bring up an interesting question as to what is constituted as an Exception for which the Polly framework is used. In your case, it's more a matter of something not returning an expected value, rather than an actual Exception. Is this something Polly should handle as well?\n. This does seem like a useful scenario. @eldiosyeldiablo, did you end up working around this limitation by cloning the repo and making modifications yourself, or some other way?\n. @nelsonghezzi: Since you don't have permission to update the upstream (App-vNext/master) branch, or repository as a whole, you don't need to worry about overwriting it. If you follow the instructions on the contributor's guidelines under the Handling Updates from Upstream/Master, then you should be fine.\nHowever, since you're working off of your own master instead of a local branch, you may need to follow these steps after step one (stashing your changes):\n- git fetch upstream\n- git rebase upstream/master  (then fix any merge conflicts)\n- git push -f\n(Upstream/master references the App-vNext/master branch)\nThen, once you unstash your changes and resolve any conflicts, any changes you make will update your existing PR. In the future, make sure you create local branches before doing any work :)\n. Looks great! Thanks for the contribution, @nelsonghezzi. Thank you for reviewing, @reisenberger. Merged.\n. This is awesome stuff, you two! Sorry I've been unable to engage in the conversation, due to very tight commitments at the moment. I have been watching from the sidelines, but don't want to interject my opinions without thoroughly looking through the code and thinking through the scenarios.\nHowever, I will take @reisenberger's tests for a spin and offer up the results, as well as any suggestions that could possibly be helpful.\nYou guys rock!\n. @kristianhald Yes, @reisenberger has it right. The AppVeyor build process generates release-level nuget packages when we merge a PR. We control the version number via a file named GitVersionConfig.yaml, which is used for applying the release version for the signed and unsigned versions of the packages. We also update the Polly.nuspec file to include the change notes that are added as part of the package, as well as on the nuget.org site. Once the files are generated by the build server as artifacts, I manually upload them to nuget.org. As Dylan rightly states, this is to control the deployment of the packages.\n. @kmcginnes I've noticed that this PR has conflicts that need to be resolved. Could you please resolve the conflicts?\n. Everything looks good to me. I say ship it if no one objects.\n. @nedstoyanov: Just to make sure the loop is closed, I wanted to let you know that @reisenberger's implementation here has been merged into what is now version 3.0. Thanks for your review and great work you've contributed!\n. @dkrikun I wondered the same thing when I first came across Polly. So, I'll leave you with a use case where I implemented Polly in a way that would've cost me many more key strokes:\nI developed a Xamarin-based mobile app used by field engineers to take pictures after work is done on a job site, and to fill out a quality control check sheet. The app is built to run offline or within occasionally connected scenarios. When they are ready to submit their data to the intake service, they might not have the best of connections.\nPolly provides an interesting retry policy when an exception is encountered. Now, consider this: you've got 30 reasonably large photos to upload to the cloud. You may not have the most reliable data connection, but it's mostly there. You need to upload these photos while you can. So, the way I handled it is to set an exponential retry policy that waits for longer durations each time an exception is encountered before trying again. You can clearly see the exception handling here, and also easily understand the retry logic.\nHere's a code sample from my project. If I were to write this from scratch, it would take a lot more time to do, so why reinvent the wheel?\ncsharp\n                    // Retry a specified number of times, using a function to \n                    // calculate the duration to wait between retries based on \n                    // the current retry attempt (allows for exponential backoff),\n                    // calling an action on each retry with the current exception,\n                    // duration and context provided to Execute()\n                    // In this case will wait for\n                    //  1 ^ 2 = 2 seconds then\n                    //  2 ^ 2 = 4 seconds then\n                    //  3 ^ 2 = 8 seconds then\n                    //  4 ^ 2 = 16 seconds then\n                    //  5 ^ 2 = 32 seconds\n                    await Policy\n                        .Handle<Exception> ()\n                        .WaitAndRetryAsync (5, retryAttempt => \n                            TimeSpan.FromSeconds (Math.Pow (2, retryAttempt)), \n                            (exception, timeSpan, context) => {\n                                // Send exception logging to Xamarin.Insights:\n                                MessagingCenter.Send<MobileServiceClient, ExceptionContainerException> (QCApp.Client, \n                                    Common.Constants.MessageCenterMessages.MessagingCenterError, new ExceptionContainerException { Title = \"Error uploading image\",\n                                        Exception = exception\n                                    });\n                                Insights.Report (exception, new Dictionary<string,string> {\n                                    { \"Filename\", \"SectionViewModel.cs\" },\n                                    { \"Where\", \"UploadImage\" },\n                                    { \"Issue\", \"Error uploading image\" }\n                                });\n                            }\n                        )\n                        .ExecuteAsync (async () =>\n                            // JDH - 04/12/2015 - Moved away from using the Microsoft.WindowsAzure.Storage SDK in\n                            // favor of direct REST calls due to the SDK's slowness. REST calls appear to run about\n                            // 15x faster for uploads!\n                            BlobTransfer.UploadFileAsync (picture, picture.Filename)\n                        );\nPretty clear and concise, isn't it?\nBTW, implementing this exponential retry cut down failed upload attempts to almost zero.\nHopefully this helped illustrate a good use case for this excellent library.\n. @gramanero We're absolutely thrilled that you are contributing back to the community by making Polly better! We've written up guidance on our wiki about steps you can take to contribute, including a link within to learn more about forking code. Let us know if you get stuck with any of the steps.\n@reisenberger I believe that we could use a new NuGet package that provides async features for the 4.0 framework. If you agree, we could discuss whether this should be part of the current project, or a spin-off.\n. @mauricedb I am starting to work toward having Polly support .NET Core. Are you interested in helping out? Things have matured with the Core framework lately, which will help ensure there are no more breaking changes.\nMicrosoft recommends that all libraries, such as Polly, convert to .NET Core sooner rather than later. That way, once people start building solutions in Core, or converting existing projects to it, libraries will already be taken care of.\n. @yevhen Once I merge your PR (after your changes), then I'll test locally and publish the new NuGet package once verified.\n. @yevhen: We're ready to include your PR into version 3.0! This along with cancellation features @nedstoyanov and @reisenberger are working on will really help make Polly even more mature. Thank you so much for helping us push the library forward.\nIf you are ready, please fix the parameter order, as outlined in detail by @reisenberger. Once that's done, we can merge it in.\n. Thanks, @yevhen! I hope you know I wasn't trying to pressure you. It's a crazy a time of year for all of us.\n. @yevhen: Hope you had a great holiday weekend :)  Just wondering if you've had a chance to fix up those last few things? We're hoping to release a new version with your changes by year's end, if possible.\nAlso, just so you're aware, you'll need to rebase your local repo with the latest changes we incorporated yesterday. Thanks!\n. Looking forward to it! Thanks :)\n. Makes sense to me, too. I think that we want to add ConfigureAwaits(false) everywhere within the library, as you suggested. Keeping track of the original context is also important.\n. @yevhen there were some build failures yesterday due to connectivity issues between appveyor and NuGet. I'll kick off another build. \n. Build succeeded :)\n. I can modify the CHANGELOG if you haven't already.\n. @reisenberger @yevhen: I just posted instructions on fixing the line endings to our wiki site. See if these steps help. If not, feel free to update the page :)\n. Off the top of my head, I don't see any drawback to exposing the policies list. Marking this issue for review.\n. Michael,\nWhat is involved? I may be interested.\n. I will gladly step up if someone else who's already been involved doesn't. If anyone who's contributed to this project to date wants to take over, then they might be more suitable for the task. However, I am happy to keep it going.\n. Good point, @ploeh! @michael-wolfenden I've got an organization of developers, of which I am part, interested in taking over the project.\n. Yes. I'll move it under our App vNext orb so it's not tired up in my\nindividual account. There are 21 of us in the group, and at least a couple\nbesides me are interested in maintaining the library.\nOn Nov 25, 2015 3:16 PM, \"Michael Wolfenden\" notifications@github.com\nwrote:\n\n@joelhulen https://github.com/joelhulen You still happy to take the\nreins?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/michael-wolfenden/Polly/issues/55#issuecomment-159752997\n.\n. I'd like to move it under the App vNext organization, if you don't mind.\nOn Nov 25, 2015 3:30 PM, \"Michael Wolfenden\" notifications@github.com\nwrote:\n@joelhulen https://github.com/joelhulen Last night I created\nhttps://github.com/PollyOrganisation and was going to move the Polly repo\nthere, but its your call?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/michael-wolfenden/Polly/issues/55#issuecomment-159754764\n.\n. https://github.com/App-vNext\nOn Nov 25, 2015 4:34 PM, \"Michael Wolfenden\" notifications@github.com\nwrote:\n@joelhulen https://github.com/joelhulen Whats the github url?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/michael-wolfenden/Polly/issues/55#issuecomment-159765840\n.\n. I just invited you to my team as a member. You should be able to create the\nrepo, etc. Please let me know if I need to elevate your permissions.\n\nOn Wed, Nov 25, 2015 at 7:08 PM, Michael Wolfenden <notifications@github.com\n\nwrote:\nHmmm.. I need admin rights to App-vNext to transfer the repo\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/michael-wolfenden/Polly/issues/55#issuecomment-159790807\n.\n. Thanks so much, Michael. I'm glad to do my part :)\n\nI'll look into the appveyor stuff and let you know if I have any questions.\nOn Wed, Nov 25, 2015 at 8:01 PM, Michael Wolfenden <notifications@github.com\n\nwrote:\n@joelhulen https://github.com/joelhulen Its been successfully\ntransferred, feel free to remove me from your organidation. Thanks again\nfor taking over the reins, its much appreciated. I have an appveyor build\nsetup under my name that is currently building it on pushes / pull\nrequests. The badge in the readme is also pointing to that. You will need\nto set up your own appveyor project to do the same (or not). Let me know if\nyou need any help setting it up. The readme, nuspec all point to the old\nrepo as well, the links will need to be changed to your new repo.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/55#issuecomment-159798214.\n. @michael-wolfenden I have set up an appveyor project for this, and I was wondering if there are any special settings for the project within appveyor that you set, or if you are relying on the configuration files contained within the project root instead?\n. Also, how do I update the project information and links here: https://www.nuget.org/packages/polly?\n. Thanks for the great info. That's what I figured for Appveyor, but wanted to be certain.\n\nWhen I try to upload the nuget files to https://www.nuget.org/packages/upload, I receive an error message stating \"The package ID 'Polly' is not available.\". I believe it's because it's associated with your account right now. Do you know a way around this?\n. @michael-wolfenden It's \"joelhulen\".\n. Just got the emails. Perfect!\n. I noticed that this NuGet package has a bunch of dependencies now, I assume as part of the .NET Core support: https://www.nuget.org/packages/Polly/2.2.4\n. @reisenberger I agree on removing blocking and modernizing the overall architecture to support current async/await capabilities. Your point about breaking up the library does make sense, so we can take advantage of newer .NET versions. I'd also be interested in having a .NET core version of the library that can support cross-platform development. As one of the new stewards of this project, I'd like to hear some of your ideas about structuring this project, or breaking it up to support different versions.\n@mauricedb might also have some input on this, having just looked at his #51 PR.\n. It is my pleasure to help move this project along!\nThis is great stuff. I've also been playing around with the beta bits. Hopefully now that they're in RC, the namespacing will be more stable, as will the APIs in general. There's still a ways to go, so it's wise to hold off.\n@reisenberger, the @App-vNext/core and I will be going over the project this weekend, and will review your changes as well. I'll update this thread if we have any questions.\n. Could you please provide a sample of what you're trying to accomplish?\n. The samples project has been created: https://github.com/App-vNext/Polly-Samples\nThis includes a hosted web API site (http://pollytestapp.azurewebsites.net/) that throttles requests to help simulate failures within the sample console application.\nIt would be great if the community contributed samples of their own. Thinking about linking to the samples project from the Polly readme file.\n. @onovotny I won't be able to update this until this evening. If you feel so inclined, please update the NuSpec file, and submit a PR. That should help get this resolved sooner.\n. @onovotny Appreciate the PR :)\nOne thing I just noticed is, even though the build was successful in AppVeyor, there was an error thrown by cake:\n\n__AddDotNetReferencesToNuspecFile\nExecuting task: __AddDotNetReferencesToNuspecFile\nC:\\projects\\polly\\tools\\Cake\\Cake.exe : error RG001: project.lock.json is missing\nAt line:1 char:1\n- C:\\projects\\polly\\tools\\Cake\\Cake.exe \"build.cake\" -target=\"Default\" -configurat ...\n- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n  - CategoryInfo          : NotSpecified: (error RG001: pr...json is missing:String) [], RemoteException\n  - FullyQualifiedErrorId : NativeCommandError\nFinished executing task: __AddDotNetReferencesToNuspecFile\n\nThere was a new task added by your reference generator, I believe, that the above error refers to: https://github.com/App-vNext/Polly/blob/master/build.cake#L185\nAre you familiar with the error above about \"project.lock.json\" missing?\n. This is perfect. Thanks!\n. Agreed, this has been very helpful to me as well, in better understanding the NuGet dependency intricacies. The question now is whether to roll back these changes and keep the new NuGet url?\n. You, sir, are a gentleman and a scholar!\n. This has now been rolled into version 4.0.\n. @reisenberger This is going to take a little bit of time to review, but I am following your logic and like what I see so far. As an aside, the team and I met this afternoon to go over Polly in order to bring everyone up to speed. I was wondering, since you are very involved with this project and have quite a bit of experience, would you be interested in joining the core team? We could use someone like you who already is ahead on the ins and outs of the project. That way we can be a step ahead with moving forward.\n. @penderi This is excellent! I had come to the same conclusion about Polly being powerful, but difficult for newcomers to fully grock without great examples. Because of this, I, along with some of the App vNext team members, created a starter project named Polly-Samples.\nIt would be great if you could fork that project and add in your example. You'll see the start of how the project is laid out, with an web API service (PollyTestApp) to test against via http://pollytestapp.azurewebsites.net, and the PollyTestClient, which is a console app containing the Polly examples.\nThe current flow, in its infant state, is to add your example to the appropriate class underneath the Samples folder, or to create a new one named after a policy or function, if not tied to a specific policy type. Then, each Polly sample the user wants to run is launched from PollyTestClient\\Program.cs.\nWe're definitely open to suggestions as how to better organize and execute the examples.\nBy the way, I did add a link to Polly-Samples on the bottom of Polly's readme file. I'm afraid that it probably gets lost in the weeds for experienced users, but hopefully is easily found by someone reading it for the first time.\n. Agreed that what's really needed is an interface with underlying concrete classes that contain the desired elements, a la IRetryPolicy (like that name, by the way). Perhaps this would be a good addition to the 3.0 milestone.\n. @bunceg: Glad you worked it out :)\nThis is a great example of why I created the Polly-Samples project. If you'd like to contribute to it in order to add an example for using the Circuitbreaker, that would be great. If not, I'll do it once I have a spare moment.\nThanks!\n. Thanks for the heads up about the broken link! Perhaps we could replace it with this? http://blog.jaywayco.co.uk/circuit-breaking-with-polly/\n. Thanks, @maverix! I've updated the readme file to include this link.\n. @StefanBols it looks like that link is permanently gone. I've removed it and added a link to a great circuit breaker-focused article by Andrew Lock (added to the Blob post section of the readme file). Also added two  links to new videos discussing Polly, under the Videos section.. @alvpaz Based on your errors, it appears as though you are connecting to a WCF endpoint, which is timing out. On the other hand, it could be that it is throwing some other exception, then timing out when the policy retries the request. Perhaps if this is the case, then the ServiceChannel object isn't reusable and you need to reset it somehow between retries.\nDo you still encounter this issue when you take Polly out of the picture?\nIf it only happens when using the retry policy, could you try modifying your policy to capture a more specific exception to perhaps determine the source problem?\nDo your logs reflect the timeout error, or does it show something else?\nFinally, could you create a very small sample project that reproduces this error?\n. @nedstoyanov Since you've already rebased your branch, as long as you commit any merges or additional changes, they'll automatically be added to this PR. Just add a comment here once you're finished with your changes so we can review, and, ultimately, accept your PR.\n. Thanks for the great work, @nedstoyanov, and for the thorough review and helpful comments as always, @reisenberger!\nMerged :+1: \n. @TrevorPilley I'll look into doing this. It is a very good suggestion.\n. @TrevorPilley @reisenberger For now, I've tagged the closed PRs that contributed to both version 3.0 and 4.0. You can view them by looking at the closed PR list and see the v3.0.0 or v4.0.0 milestone next to each PR name (or the details within if you open it).\nDoes this suffice? Is there a need to tag minor versions as well, or just major versions, like 3.0 and 4.0?\n. This is an interesting suggestion. We've spoken about ways to visualize the process flow, but not necessarily telemetry information. I wonder if capturing that data would be best served as a plug-in, and not a part of the core package? My line of thinking about this is that there is usually a trade-off between capturing this data and performance. I believe the ideal way to capture the data would be via an asynchronous tool similar to Application Insights. Minimal impact and something you can add in.\nDo you have an example of the metrics Hystrix captures that you would like to see? For instance, what would be a priority at first?\n. @PaybackMan That is a great suggestion. Out of curiosity, what is the current holdup you are facing in using the PCL version of the Polly library, or is this request more out of providing greater flexibility for 3rd party libraries to be less dependent upon a specific .NET version within a given project?\n. The updated NuGet packages have been published, as is indicated by the 4.1.2 version displayed on the Polly home page as well as on nuget.org\n. This does help clean up the readme a bit. Thanks!\n. I really do like the pattern @reisenberger proposes here, which matches the existing SystemClock solution. This will cause the least impact on other areas of the solution. Either way, I really appreciate your contribution!\n. @Lumirris Thanks for your contribution! As far as handling merge conflicts and rebasing, that responsibility usually falls on the contributor submitting a pull request. The steps are simple and outlined on our wiki page. If you get stuck, simply reply to this thread and we'll do our best to help you sort it out.\n. @reisenberger Yes, we can. You'll see within the build.cake file where the __CreateNugetPackage and __CreateSignedNugetPackage tasks are defined. We would need to define a new NuGet package task for .Net40Async, ensuring the appropriate project/assemblies are referenced.\nI agree that it would be best to try and keep everything within this repo. Worst case, we create a new branch, but hopefully we won't have to go that route.\n. Thanks, @reisenberger. I Have been slammed busy, but I'll integrate your changes into the master build script.\n. @KBRETON1 @Lumirris @reisenberger \nI have combined @reisenberger's NuGet creation elements added to a separate cake file into the standard cake file that is executed by our AppVeyor build server. From that, we now have four NuGet packages: Polly.4.2.2.nupkg, Polly-Signed.4.2.2.nupkg, Polly.Net40Async.4.2.2.nupkg, and Polly.Net40Async-Signed.4.2.2.nupkg, respectively.\nYou can now download the new Net40Async NuGet package, as well as its signed counterpart.\nPlease let me know if you have any issues with these NuGet packages.\n. I believed this was the case as well. I'm sorry, I thought the package was already good to go. I'll see if I can track down why it's pulling in both DLLs, and why the Microsoft.Bcl.Async dependency isn't included.\n. @Lumirris @KBRETON1 \nI have a new set of NuGet packages I'd like for you guys to test before I publish them to nuget.org. What's the best way for me to send them to you? Don't want to go through setting up myget or publishing them until I'm 100% certain they're ready.\nAlso, looking at the .nuspec file for the Polly.Net40Async NuGet (nupkg) file, it does list Microsoft.Bcl.Async as a dependent package. Not sure why the NuGet package manager didn't automatically pick this up for you.\n. Polly 4.2.3 NuGet.zip\n. Try that. If you want, you can extract those packages to your local drive, then configure the NuGet Package Manager in VS to reference that folder as a NuGet package source. Let me know if you need help setting that up.\n. @Lumirris Were you able to try it out? I want to update the NuGet packages ASAP. Thanks!\n. @KBRETON1 \nI really need to set up a dev environment to mimic yours...\nAs far as the BCL NuGets, you'll see the dependency listed in the .nuspec file for the Net40Async package as <dependency id=\"Microsoft.Bcl.Async\" version=\"1.0.168\" />. Is this not the correct version?\nIf you drag & drop the zip file to the comment box on this page, does it not upload the file?\n. I see. You need to do this from the site in order for the drag/drop feature to work. No files came through...\n. Hmmmm.... you're referencing this from within a PCL? I wonder if you need a PCL version of this library, which currently targets .NET 4.5, I believe.\n. @KBRETON1 @Lumirris \n@reisenberger was gracious enough to apply a small fix to the production build that defines the SUPPORTSASYNC constant. Please try these new NuGet packages. Once verified, I'll publish them to nuget.org.\nPolly 4.2.3 NuGet packages.zip\n. @KBRETON1 @reisenberger @Lumirris \nTotally agree. @reisenberger Do you want to update\n your project to exclude those from the build output and have it rely solely on the Microsoft.Bcl NuGet package to pull down those assemblies?\n. @KBRETON1 @Lumirris \n@reisenberger just cleaned up the dependencies. The BCL DLLs are no longer included and should now be automatically added via the NuGet dependency.\nPR #108 has been merged and built. Attached are the resulting NuGet packages.\nPolly 4.2.3 NuGet packages take 5.zip\n. @reisenberger Yes, perfect. The way you cleaned it up was exactly how I would have suggested. Thanks!\n. Thanks for clarifying! Makes complete sense, as the dependency entries in the config contain the bindingRedirect properties with old and new assembly versions.\n. @KBRETON1 @Lumirris \nAttached is the latest (and hopefully last) round of NuGet packages with the latest cleanup and project tweaking results.\nPlease verify, and I'll post to nuget.org\nPolly 4.2.3 NuGet packages take 6.zip\n. @KBRETON1 I've discussed this offline with @reisenberger, but I want to know whether you agree, since you're closer to this particular issue.\nWe've tested adding the NuGet package to a simple app, both with and without the config file. It worked in both cases. The discussion @reisenberger linked to earlier, which suggest that the config file must be kept in place for BCL.Async to function correctly, makes me more confident about leaving it in, which doesn't appear to hurt anything, rather than taking it out with unknown consequences (such as dynamically loading assemblies, or other scenarios we haven't tested).\nWhat I've seen in the past in similar situations, is where the included config file is used if the containing project does not have one. Otherwise, the containing project's config is used.\nI'm not sure if it works exactly the same way in this scenario, but it seems as though the config file from our NuGet package would inform the containing project as to what the dependency values should be.\nIn the meantime, I've gone ahead and published these new (4.2.3) packages to nuget.org.\n. Thanks, @michael-wolfenden! We're just trying to build on top of this excellent library that you graciously shared with us and the community as a whole. I do what I can to help coordinate and drive efforts, but most of the credit must go to @reisenberger for really taking it to the next level. We've also had a few other great contributors along the way, such as @kristianhald, @nedstoyanov, @yevhen, and @nelsonghezzi.\nAs far as the future, I'd love it if you could offer your opinion on the roadmap via the associated issue!\n. @reisenberger Thanks so much for this pull request! I plan on merging it tomorrow.\n. @SeanFarrow I think somehow your issue description didn't save :)\n. Which version of .NET are you using, specifically? There's a huge difference between version 4.0 and 4.5/6\n. @SeanFarrow You're in luck, because we just released a new version that adds async methods to Polly for those still using 4.0, via a dependency on the Microsoft BCL Async library.\nFor sample usage of the Async methods, please check out the Polly-Samples project. For a great set of videos on using Async and cancellation tokens, I highly recommend this series by Jeremy Clark.\n. @robertbaker I haven't checked the change logs, but was this profile previously supported by Polly? \"Lost support\" suggests this.\n. Ah, yes. That makes sense. I was frantically looking through all of the changes in order to see where we may have accidentally removed support for that profile ;)\nI assume you installed the Polly.Net40Async package instead of the standard Polly one?\nI wonder if there's a better way for us to communicate which one to use?\n. These changes were incorporated into PR #130 \nThanks for your great contribution!\n. @pvmraghunandan The latest NuGet packages have been published!\n. Sorry, everyone. I've been on travel and away from any computers for six\nweeks. I should be able to create and publish the beta packages in the next\ncouple of days.\nOn Aug 9, 2016 7:53 AM, \"Adam Hathcock\" notifications@github.com wrote:\n\nPinging @joelhulen https://github.com/joelhulen too :)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/133#issuecomment-238530518,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AFrLYHDFDwNQWFsoCVsAVi4XFqGc5KXwks5qeGougaJpZM4JDwR3\n.\n. The 4.5 beta release packages for both signed and unsigned have been posted to nuget.org. Be sure to check the box in your NuGet package manager that allows you to view pre-release versions.\n. @reisenberger @JoeBrockhaus Sorry, the notification for this thread got lost amongst my piles of emails. Sometimes it's faster getting ahold of me on the Polly slack channel ;-)\n\nI'll work toward releasing the pre-release NuGet and notify everyone here once it's up.. @reisenberger @JoeBrockhaus I've published those pre-release NuGet packages. Please let me know if you have any issues finding or using them.. Thanks, @kbilsted!\n. Brilliant work, Dylan! Thank you for your contribution :)\n. @jmansar This feature has been released in the v5.1 version of the package today. Thanks for the great suggestion, and thank you @dreisenberger again for all of your hard work to add this feature and context flowing in general!. Thanks for your contribution, @NRKirby!. I would like to merge everything into a single NuGet package, but perhaps we could hold off to reduce confusion for the ~3% of the .NET40Async users and to continue to track its usage. It would be great to see what, if anything, the NuGet team comes up with regarding tracking capabilities of multiple targets within a package.. Merged. This is a big one! Thanks for everything you do, @reisenberger \ud83d\udcaf . I've personally used it in Xamarin PCL projects, so absolutely!. @reisenberger @nathan-alden Absolutely no problem with tagging each release. In fact, I've seen many projects do this very thing, and it does help keep code history aligned with their particular version. Thanks for taking care of this!. Will upload later today. Currently traveling. Thanks!\nOn Feb 10, 2017 1:03 PM, \"reisenberger\" notifications@github.com wrote:\n\nMerci @Julien-Mialon https://github.com/Julien-Mialon . Fusionne!\n@joelhulen https://github.com/joelhulen We're good to release v5.0.6 to\nnuget from master. Already tagged as a release in GitHub.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/228#issuecomment-279019182,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AFrLYIVmYjceKyWFgr-8-l2NcKRgJ0gFks5rbKaHgaJpZM4L8KYp\n.\n. Thanks for the contribution, @SaroTasciyan!. @georgiosd We're glad you're enjoying Polly :)\n\nHave you looked into using Polly to handle TResult?\nThere are typical HTTP results that are returned once you hit a rate limit or a server is busy (such as 429). Some API providers even return header results that tell you how long to wait before retrying. In fact, @dreisenberger wrote a blog post last month on the subject. There's also much discussion around the topic here.. Ok, I understand now. I thought you were dealing with HTTP requests where you just have to back off for a bit. In your case, you can't afford to hit the limit. So do you know the rate limits up front? You can, with absolute certainty, say that \"I can send x requests within a given n minute window\"? Also, is your application multi-threaded with multiple instances potentially calling this API at once, requiring you to share your API hit count across instances?. Thanks for using Polly, and thanks for the request! However, after much consideration with the team, I don't think it is possible to provide a \"sync-only\" 4.0 target at this time. There are a couple reasons for this:\n\nThe .NET40 Async library currently accounts for less than 0.5% of our user base, as it is. The no-async version would account for an even smaller constituency. This alone is not the issue, however.\nIntroducing a no-async version would introduce significant #if / #endif forking/complexity into our codebase, hitting around 50% of the files.\n\nThat level of impact and maintenance overhead for such a small number of users/use cases doesn't make sense for us to devote our time to at this point.\nHowever, because Polly is open source :) - you are free and able to fork the latest head revision and strip out the async stuff that you don't want.\nWe must consider every request very carefully to ensure our limited time makes the most positive impact, and does not negatively impact any customers in a significant way. I'm sorry, but unless someone thinks of a better way to address this, or if there's significant buy-in from the community at large, we'll have to decline your request at this time.. I would like to prioritize this for 2018. I'm also interested in taking the lead on this, as I've recently run across a good use case when using a Circuit Breaker in an Azure Function that could automatically scale out to multiple instances. This is where a distributed Circuit Breaker would come in as a useful way to make sure multiple instances aren't overloading a downstream service. Right now, when your Azure Function scales to 20 instances, per se, they each have their own Circuit Breaker instance. So one tripping a breaker won't cause another to stop processing.\n@reisenberger had suggested calling a Distributed Circuit Breaker a Circuit Breaker as a Service, or \"seabass\". I like it :). @codemerlin Totally okay with that! Just please be kind enough to link back to the Polly project somewhere :)\nLooking forward to checking out your library!. @jiimaho Thanks for your contribution!. @danroot I can offer guidance on alternative retries/circuit breaker for dealing specifically with Cognitive Services.\nDo you want to create a new issue asking for this? I think it'd be a better place to have that conversation for better discoverability.. Thanks, @labaneilers, for your eagle eye!. There is currently no plan to update to .NET Standard 2.0. Polly currently using .NET Standard 1.1, which is fully compatible with projects based on .NET Standard / .NET Core 2.0. Because Polly does not use Standard 2.0 features, there's no benefit to migrating to that version at this time. We like to take the approach, as with other libraries, to use the lowest Standard version possible, while supporting all required features, in order to more widely support projects to which Polly is added. Moving to 2.0 would make Polly less compatible with many other projects currently using it... I'm still not certain there is a need to add an additional target for Standard 2.0. The Standard library differs from .NET Base Class Libraries (e.g. 4.5), in that Standard is an abstraction of BCL API implementations. Think of it as a set of interfaces. If you created various public interfaces for your application that expose different method signatures for your concrete classes, based on which features you want to expose, then the concept is similar.\nRefer to this chart on the .NET Standard documentation page. The way the chart reads is, select the .NET implementation you are using for your application (such as .NET Core 2.0). The chart will show you what your implementation version advertises as the highest .NET Standard version it supports, a statement that means it also supports previous versions.\nAs stewards of a widely used .NET library, it is our responsibility to match up the lowest .NET Standard version that provides all of the APIs our library exposes, allowing us to target the widest range of platforms.\nIn this documentation, you will find the following guidance:\n\nThe higher the version, the more APIs are available to you. The lower the version, the more platforms implement it. In general, we recommend you to target the lowest version of .NET Standard possible.\n\nYou had said that \"Using netstandard1.x libraries mixed with netstandard2.0 creates a lot of mess and incompatibilities.\" Can you please elaborate? This does not seem consistent with official documentation. Are you creating a library of your own, or an application that is targeting .NET Standard 2.0?. @jelical We have read the .NET Standard documentation, asked around to members of the Microsoft team, and have looked at a number of high profile NuGet packages, such as Newtonsoft.Json, XUnit, FluentValidation, FluentAssertions, StackExchange.Redis, Rx.Net, Refit, ModernHttpClient, Moq, Nancy, Brighter, BenchmarkDotNet, NUnit, AutoMapper, and Serilog. None of them have added .NET Standard 2.0 as a target when 1.x suffices. As stated before, .NET Standard is an abstraction of underlying .NET frameworks, that says the features targeted in a particular version of .NET Standard is supported by, at minimum, these .NET target versions and higher. You are correct in that your projects are likely targeting .NET Core 1.x/2.x or .NET Framework 4.x.\nI don't doubt you are having some issue with various versions, and I want to help. But most importantly, I need to validate that what your experiencing is or is not an issue with the Polly library targeting .NET Standard 1.1. Could you please create a Minimal, Complete, and Verifiable example? Something we can use to reliably reproduce your issue? Then we can move toward a solution from there. As you've stated, you have a lot of moving parts, so it's difficult to reproduce unless we have an example to work from.. @praveenk2 I replied to your question in Slack, but am also responding here for more people to see.\nYou can absolutely use Polly. .NET Standard 1.1 libraries are compatible with .NET Standard 2.0-based projects. The only real difference is that .NET Standard 2.0 exposes more APIs than 1.1. On this note, there are preliminary plans for Polly version 6.x being built on .NET Standard 2.0.. @jelical @praveenk2 The latest release of Polly now targets both .NET Standard 1.1 and 2.0.. @craigbrett17 That is a great idea adding a note about where to find the last version that supports .NET 3.5. I'll update the readme now. Thanks!. Absolutely! Polly targets .NET Standard 1.1, which is the lowest .NET Standard version we are able to target while covering all of the .NET APIs that Polly uses. What this means, is that Polly is compatible with as many .NET versions as possible, across multiple platforms, from 4.5 onward. As noted in the official .NET Standard docs, one of the primary versioning rules is that they are additive, meaning higher versions incorporate all APIs from previous versions, and there are no breaking changes between versions.\nI have personally used the latest version of Polly in a .NET 4.6.1 project with no issues.. #sign-off. @danroot You've inspired me to write a detailed blog post to help with this specific scenario: http://www.thepollyproject.org/2018/03/06/policy-recommendations-for-azure-cognitive-services/\nHopefully it can me more broadly applied to creating resiliency patterns for any rate-limiting service.\nI'd really appreciate your feedback!. What are you trying to accomplish? Are these DLLs generated by your own application, or are you asking how to split up the Polly class library into separate DLLs? If you're referring to your own application, this is done by having separate projects with their own namespace, which build the DLLs when you compile them. If you're talking about doing this with the Polly project, I don't see any benefit of doing this. But I would like to hear more about what you are trying to do.. Another fine release :). I am leaning toward publishing only strong-named, starting with version 6.0. This would result in us ceasing the Polly-Signed lineage, and we'd need to make it very clear in several places that the assembly in the Polly package is strong-named.\nI had initially thought of having a new namespace called something like PollyCore that is strongly signed, and maintain that separately like we do with Polly and Polly-Signed, in order to reduce conflicts. Then thought better of it as adding more confusion and then dealing with ambiguous method names, etc. when you bring in HttpClientFactory to an existing project that uses Polly already. The other downside is that you'd have two identical DLLs, but with different names. This is not ideal for various reasons.. We've just released Polly version 6.0.0-alpha to nuget.org. It has the following characteristics:\n- Publish as strong-named package only (discontinue non-strong-named versions)\n- Add .NetStandard 2.0 tfm\n- Provide .NET4.5 support via .NetStandard 1.1 tfm\n- Discontinue .NET4.0 support\n- Remove methods marked as deprecated in v5.9.0\n\nThe first item is the one that addresses the primary issue. Because this is related to Polly and its relationship to ASP.NET Core 2.1,we're working on releasing Polly.Extensions.Http 2.0 alpha tomorrow or the next day, which follows the same single-strong-name package method and will reference this new Polly v6.0 package.\nUPDATE: Polly.Extensions.Http 2.0 alpha has been published. This follows the single-strong-named package approach and references Polly v6.0-alpha.. Looks good so far. Just waiting on the .NET Standard 2.0 target to be added before merging.. @cmeeren That NuGet package (Polly.Caching.MemoryCache) is deprecated. Unfortunately, there's no easy way to mark packages as such with nuget.org. I did add a description on the page there, but that's only useful if you're actually on the site. Please try this package out instead: https://www.nuget.org/packages/Polly.Caching.Memory\n. Fantastic!. @willdean This made me laugh \ud83e\udd23 \nYes, I like your definition better, even if pedantic.\nPlease make the change. If you don't have permissions, then I'll update it.. Thanks!. @reisenberger No apology needed! It takes volunteers like you to help spot these things and keep progress marching forward. All help is gladly accepted :)\n. ",
    "NielsKlosterAndreassen": "An alternative solution is to allow a retry count of 0. Let me know if you prefer that.\n. ",
    "mattgwagner": "I like this addition -- it's useful for me for a base class where we're not doing mandating any specific retry logic and implementing classes can add their specific handling.\n. ",
    "bchavez": "This seems to work just as well:\npublic static class Safely\n    {\n        public static PolicyBuilder HandleAny()\n        {\n            return Policy.Handle<Exception>();\n        }\n    }\n:+1: \n. ",
    "mauricedb": "Hi MIchael,\nExcellent suggestions.\nLet me update the pull request as suggested.\nMaurice\nOn Sat Nov 08 2014 at 10:57:47 Michael Wolfenden notifications@github.com\nwrote:\n\nMaurice, sorry about the delay.\nFirstly, many thanks for the contribution. Async support has been the\nnumber one requested feature.\nIn terms of implementation though, I was thinking that perhaps a nicer way\nto implement it might be:\n1) Make the classes in the Polly.Net35 project that we need to add the\nnew async methods to partial\n2) Add the implementations in the Polly.Net45 project\nFor example:\nin Polly.Net35 make the Policy class partial\nin Polly.Net45 add a new file called PolicyAsync with the implementation\ne.g.:\npublic partial class Policy {\npublic Task ExecuteAsync(Func<Task> action) {\n{\n}\n}\n3) Try not to change any code in the Polly.Net35 project. Add all new\ncode in the Polly.Net45project, even is this means duplicating a method\nbut giving it a new name e.g. append Async perhaps\nI am happy to accept you pull request and then merge all your changes into\nthe structure above.\nI would be interested in your thoughts?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/michael-wolfenden/Polly/pull/13#issuecomment-62252303\n.\n. Hi Michael,\n\nAny questions/remarks about the updates?\nMaurice\n. Hi Michael,\nI updated the code for the point 2, 3 and 4. \nGood catch on the .ConfigureAwait(false). I completely missed that.\nFor the async unit tests I only updated a few. As far as I know the async tests that use the FluentAssertions .Awaiting() should not need to be changed.\nRegarding point 1.\nThe PolicyAsync.cs contains a partial class Policy and the synchronous execution policy is passed on to the constructor in Policy.cs. I can change it to they are not two partial classes joined by the compiler but actually use a PolicyAsync class beside the Policy However when I had a look it appears that there will be quite a bit of code duplication. As a result I decided not to do so unless you really want to. If we decide to leave it like this an additional null check in ExecuteAsync() would be needed as you can call it from a non async policy and that now throws a NullReferenceException with the typically hard to read stacktrace.\nSystem.NullReferenceException: Object reference not set to an instance of an object.\n   at Polly.Policy.<ExecuteAsync>d__d`1.MoveNext() in c:\\Projects\\Polly\\src\\Polly.Net45\\PolicyAsync.cs:line 39\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()\n   at WpfApplication1.MainWindow.<Button_Click>d__2.MoveNext() in c:\\Temp\\ConsoleApplication5\\WpfApplication1\\MainWindow.xaml.cs:line 44\nLet me know what you want to do regarding this point.\nRegards,\nMaurice\n. Hi Michael,\nNo that would work just fine. However consider the following two snippets of code:\n```\nvar syncResult =  Policy\n    .Handle()\n    .RetryAsync(1)\n    .Execute(() => 1);\nvar asyncResult = await Policy\n    .Handle()\n    .Retry(1)\n    .ExecuteAsync(() => Task.FromResult(1));\n```\nBoth will compile just fine even though neither makes a lot of sense as the first does a synchronous execute through an asynchronous retry policy and the second does an asynchronous execute through a synchronous retry policy.\nThe difference between the two is that the first, even though it might not make a lot of sense, actually works just fine and the second throws a NullReferenceException. With your change both will throw a NullReferenceException. And while the first usage might not make a lot of sense there is no real harm in it either. I would just add a check for the second usage and throw an InvalidOperationException with a message pointing to the wrong usage. That said we can do that in both cases but it would require changing the Policy.cs in the Net35 project with a guard clause that would not appear to make any sense when you look at the code from that project only.\nMaurice\n. Hi Michael,\nI agree that would be best here. Added the required changes in the last commit.\nMaurice\n. Hi @michael-wolfenden,\nI agree all the changes are confusing and I certainly don't completely\nunderstand then yet. However last week I had the opportunity to work on\nthis during the MVP Summit with guidance MS engineers who actually work on\nthe core bits as well as yet to be published documentation and that helped\na lot.\nThe first step they advise is to switch from the old project files to the\nnew class library web project. With the old system each project can only\ntarget a single environment like .NET45, .NET 4 or PCL. With the new\nproject.json you can target multiple environments from a single project. So\nI turned the Polly.Shared project into a class library targeting the 4\nprevious frameworks and added dnxcore50. This lets us delete the other\nruntime projects and build with DNU build.  The result is\n\nSingle project with multiple outputs :-)\nI tried to do the same with the specs but was less successful there. The\n.NET framework and CoreCLR is fine but with the PCL version of the specs I\nhave been unable to get this to work so far. Basically FLuentAssertions and\nPolly target a different PCL profile and have not been able to get that to\nwork yet. If that works we should have a single Spec project. With dnx\ntest I can run the coreclr specs. Haven't looked into running the net45\nones yet but that should not be hard. Don't know about running then with R#\nor nCrunch yet though. This is all still very much beta so I think tooling,\neven VS2015 in some parts, still needs to catch up.\nOne thing I don't really get yet is the targeting of dotnet versus\ndnxcore50. I understand we should target dotnet but the whole\nstandard-platform and the versions mentioned is not available yet AFAIK so\nwe can't use that yet. The whole point of this is to target API versions\ninstead of different platforms as the number of platforms just keeps on\ngrowing. By specifying the API version you indicate what platforms you\nactually support\nhttps://github.com/dotnet/corefx/blob/master/Documentation/project-docs/standard-platform.md#mapping-the-net-platform-standard-to-platforms.\nSo the Profile259 should become netstandard1.0 eventually.\nThere where some more people working on CsvHelper last week, that PR\nhttps://github.com/JoshClose/CsvHelper/pull/445 might also help shed some\nlight.\nHTH\nMaurice\n. @joelhulen I would love to help out. Unfortunately I am completely saturated with work right now though so I won't be able to do much for at least the next month or so. As far as maturity goes I am not sure how much churn the whole renaming to 'dotned' will cause but I suspect a fair bit.\n. @joelhulen \nThanks for continuing with Polly!\nMy PR is more about using the new capabilities of ,NET standard and having one project build to multiple targets including .NET Core.\nI would not even try to finish this until the bits required are final which I am guessing is end of Q1 2016. After that we should be good with just two projects, one for the actual assembly and one for the specs. That also depends on testing tools though and I am not sue when they will be good enough for the one specs project. Guessing that will be around the same time.\nAs far making things more async/await friendly I guess that really depends on the compilation targets and how far you want to go. With conditional compile you can go quite far and still be backward compatible but that makes the code quite a bit harder to maintain. Personally I would be inclined to let users of older version of the .NET framework use existing versions of Polly, maybe do the occasional bug fix where needed, and build a new version for the future including CoreCLR.\n. ",
    "sgarg7": "You can throw an exception in your own code when COM returns null and base the retries off that..\n. ",
    "DannyRyman": "I would also like the ability to prevent throttling due to something other than an exception. In my case we are doing a batch retrieval of items as part of a polling mechanism. In the instance where the number of new items are low, we would like to introduce a delay. Whilst I could raise an exception, it's not really appropriate in this instance. It would be great if polly could be extended to allow for delays for conditions other than exceptions. Then I think it will provide a complete solution to prevent throttling.\n. ",
    "vincpa": "I suggest trying a library like Reactive Extensions. Going by your description it would solve your problem perfectly.\nHere's some sample code\nhttp://www.introtorx.com/content/v1.0.10621.0/01_WhyRx.html\n. I'd like a little more consistency with the .NET framework.\nInstead of having a AfterFinalRetryFailure, perhaps something more generic where you tell it when you want a delegate to run.\nWe have this in TPL.\nTask.Factory.StartNew(() => {})\n            .ContinueWith(task => { /* Do stuff*/ }, TaskContinuationOptions.OnlyOnFaulted)\nI guess this means it would come back to a solution which uses a Policy\n. @michael-wolfenden is this something you would consider merging in to the main branch?\n. ",
    "renzska": "I like this idea and hope that it gets added.\n. ",
    "DSanchen": "I would strongly appreciate this feature ! I'm not currently using Polly, but would, if it allowed to react on return values.\nAs I understand it, wrapping an expected function outcome into an exception would mean to also wrap the policy.Execute() call into a try/catch block, just to catch the wrapped function outcome (if it \"failed\") and \"convert\" it back to the original outcome... sounds weird :unamused: \n. @reisenberger  I'm thinking about just reacting on return values, without handling any exception as in Handle<something>...\nMy use case aims at multithreaded applications that would try to reserve resources for some time and give up when not all of the resources are available after, say, 10 tries with a timeout of some 100ms in between the tries.\nIn my current project I have to access resources a, b, d, x, y from thread A, while another thread (B) might have access to b, c and e. When B releases access to b (and c and e), then A could continue working, otherwise it would tell the user to try again later (when B finished...). It is expected that A and B work concurrently, and it's no fault for either thread to say: hey I'm still busy, you can have your toy later - right now I'm using it.\nSo something like\ncsharp\nbool hasAccess = Policy\n.HandleResult<bool>(r => r == false)\n.Or<bool>(someCancelFlag == false)\n.Retry(10)\n.WithDelay(...)\n.Execute(TryGetAccessToResources(ISet<...>));\nif(!hasAccess) InformTheUserAndReturn(...);\n/* work with the resources */\nReleaseResources(ISet<...>);\n. :+1: Cool, coming back from holidays and finding this feature implemented ! Great work, Thanks !\n. ",
    "tidusjar": "+1 \ud83d\udc4d \n. Looks good. I'll give it a go and let you know. \n. ",
    "ilmax": ":tada: \n. ",
    "aliostad": "Thanks. I personally would have not closed the issue before implementing it.\n. That sounds great. \nIs there a way to adapt the timeout based on a the percentile of the existing response times?. Hi,\nThis is exactly what I am looking for. I considered porting Hysterix but I knew you guys done work in the area so preferred to see if this were available. \nWe heavily do metrics, ingesting 1TB of logs a day in ASOS - the overall architecture is Microservices not too different from that of Netflix and Uber. I will join you on the conversations.\nThanks once again for the hard work. Keep it up.\n. Thank you for detailed response \ud83d\udc4d \nThis can cover my scenario so would be using it :). ",
    "RobGibbens": "Is there a reason why async is only supported in .net 4.5, and not in the PCL (specifically trying to use it on Xamarin platforms, in a PLC with target of Profile 78)\n. Are you accepting pull requests? Any status update on this one?\n. ",
    "feanz": "@michael-wolfenden was there an issue with this PR?\n. ",
    "onovotny": "One other change -- the NuGet dir for the PCL should include wpa81 as the csproj already supports that profile\n. This is already supported by the csproj, but the NuGet portable- dir needs to include wpa81 in the string.\n. :+1: \n. yeah... you need to call nuget restore in any command line script first as that lock file should never be checked in.\nHere's an example I use in Humanizer: \nhttps://github.com/Humanizr/Humanizer/blob/dev/appveyor.yml#L7-L12\nAlso, I think that cake task can be removed as the build will handle it the way it's setup as part of building the pcl csproj.\n. Ugh, this whole thing could have been a giant brain-fart/missing stuff in nuget.org. It appears to have been fine originally :(\nVery sorry for the false alarm and no hard feelings if you want to revert my commits. If you do revert, the one thing you'll want to keep is the build.ps1 update to the NuGet download location as that'll pull in v3. the existing url is frozen at v2.\n. Not sure about the cake build stuff, but this works...\n. So there's two issues, both bugs I think. The main issue is that the tool wasn't picking up the dependencies correctly. If you noticed, the dotnet section was blank, when in fact it shouldn't have been.\nIn theory, you should be able to run the tool without having it as a reference (though I'm always baffled by why people would want that as you're less shielded from cmd line arguments changes that are handled by having a matching targets file).\n1. The tool looks for the presence of a packages.config or a project.json and got confused. As the scenarios I'd previously tested relied on one of those files being there, I'm guessing there was an issue with the tool running externally and not finding one because that library had no other package references.\n2. There was a bug where project.json usage for a PCL (instead of net46/dnx/uwp, etc), didn't properly pick up the built-in system references. I've fixed that in v1.4 to work properly.\nI'm still not 100% sure of behavior without a project.json or packages.config file.\nAs to why the nuspec was checked in with it, it simply seems easier than always fighting git as the tool updates the nuspec on every build. If there are no changes, then git doesn't care either. It's entirely possible to remove that dotnet section and have it created on the CI server.\nDoes that answer your questions?\n. Hmm...re-checking the source, I stand corrected. It should handle having no packages.config present. I'd have to recheck in the debugger what was going on as it should have worked as-is (but didn't) if you'd like. Otherwise, it does work correctly as-is.\n. cross posting my comment from the other thread:\nUgh, this whole thing could have been a giant brain-fart looking at nuget.org. It appears to have been fine originally :(\nVery sorry for the false alarm and no hard feelings if you want to revert my commits. If you do revert, the one thing you'll want to keep is the build.ps1 update to the NuGet download location as that'll pull in v3. the existing url is frozen at v2.\n. In the end, I'd have to ask what benefit do you see from manually calling the cli from the cake script as opposed to having the targets do it on build?\nThere's no right or wrong answer, I just figure that in the unlikely event the params change, the targets will always be right. I pretty much assumed the cli would be more for building on mono or some other usage that people come up with.\nYour call either way.\nBTW, there seems to be an extra packages.config in the .pcl folder that has a GitVersion ref in it. That file should prob be removed and if you need the ref there, moved into the project.json (should you keep it).\n. ",
    "tdietrich513": "You can have a policy handle System.Exception, all exceptions inherit from that. \n. ",
    "LetMeCodeThis": "When your code throws an expcetion while using CircutBreaker policy then CB will throw your exception or BrokenCircuitException when the circuit state is broken (this policy does not swallow exceptions). So to access exception you need to use try/catch block.\n. ",
    "kristofferlindvall": "Makes sense. Thanks!\n. ",
    "ghost": "Seems to be working just fine, thanks for the quick response.\n. ",
    "SlyNet": "Yes, thanks. But fluent interface like Handle<Exception>().Except<OperationCancelledException> would be readable? \n. ",
    "kbabiy": "Hi, Michael\nSomething like .Except  looks like a good feature to me as well.\nCommon case I have came across is not wanting to retry on Timeout. \nReasonings are:\n- Timeout quite probably means that requested resource is in trouble (working on top of its capacity) and adding retries makes things even worse (puts more stress on the resource already in stress, opens more long-hanging connections etc.)\n- You probably already don't need the result after (retryCount + 1)x timeouts has passed\nCould you probably suggest better solution to handling this type of situation?\nThank you.\n. Hi, @reisenberger \nThank you for suggestion about CircuitBreaker. I know of this concept and reviewed it again after your suggestion, but i think it doesn't exactly fit (seems to be too radical) in my case, though generally makes a lot of sense in the similar scenarios.\nAs far as i understand problem with the Except originally proposed probably comes from the existing Or API being the only option to extend the Handle clause - therefore adding any And-like condition (like Except, AndNot, And etc.) leads to the unnecessary complex binary expressions being possible\nTherefore adding the blacklisting approach (like HandleAllExcept) looks like a cleaner solution, even though needing symmetrical changes in the results handling (which probably also makes sense to extend with blacklisting). \nHopefully the benefit of such changes will overweight the needed API complications\n. ",
    "jwconway": "It absolutely makes sense yes. In fact this is exactly how we have implemented it.\nCheers, keep up the good work :+1: \n. ",
    "sarus": "Would love to see something like this as well.  Basically an ability to retry with a delay, hit a max delay and then keep retrying at the max delay.\nSo something like:\nWait 1 Second\nWait 2 Seconds\nWait 5 Seconds\nWait 10 Seconds\nWait 30 Seconds\nWait 60 Seconds\nWait 60 Seconds\nWait 60 Seconds\n(Repeat Forever)\nThank you for providing this great library! \n. ",
    "pkl728": "Never mind.  I see now that after it retries x number of times it ends up throwing the Exception because it's sole intent is to keep trying and then let the exception through.  Closing.\n. ",
    "jeserra": "Hi, \n   Thx for your quick anwer. I found that debugging in vstudio 2013 looks like the exception wasn't rety. Buy running from console was ok. \n. ",
    "Plasma": "+1\nWould like this just because I have a code path that wants to explicitly disable retries for a certain web request (if it fails, never try a second time etc) and not being able to just pass zero to the retry count is a bit annoying.\n. ",
    "eldiosyeldiablo": "Yes I did work around it by doing this. With .net 4.6 exception filters I maybe able to rewrite this.\n''' csharp\nbool skip = false;\n                    //Wanted to avoid if else on exception catching logic\n                    //Polly gets close but its api forces a retry so abusing it a little.\n                    Policy\n                        .Handle(ex => { errorCode = OAuthErrorCodes.token_expired; return true; })\n                        .Or(ex => { errorCode = OAuthErrorCodes.invalid_scope; return true; })\n                        .Or(ex => { errorCode = OAuthErrorCodes.server_error; return true; })\n                        //Ideally retry Zero but Polly does not let you do zero\n                        .Retry((ex, i) =>\n                        {\n                            //Save it for later\n                            exception = ex;\n                        })\n                        .Execute(() =>\n                        {\n                            if (skip)\n                                return;\n                            skip = true;\n'''\n. ",
    "yftachman": "I think we should come at this from a different direction,\nwe should add to the policy builder a new method called AfterFinalRetry(Action action)\nand you an do what ever you'd like with the exception (wrap it, rethrow it, ignore it, w\\e).\nOf course the default behavior should remain the same (throw the exception after final retry), but if this method has been invoked on the policy it should override the default behavior.\nI will try to do it this weekend...\n. Hey,\nmade this fork\nhttps://github.com/yftachman/Polly\nshould contain the changes you need.\nif there are any problems with it let me know.\ni'm not that familiar with this project so problems may arise \nExample syntax:\n            Policy.Handle()\n                .AfterFinalRetryFailure(ex => AfterFinalRetryLogic(ex))\n                .Retry(2)\n                ..Execute(() => Logic());\ngl hf :)\n. ",
    "tapmantwo": "This would be super useful...\n. :+1: \n. Great, thanks :smiley_cat: \n. ",
    "Caldas": ":+1: \n. ",
    "hacko-bede": "Hey again,\nWell short answer we don't have a choice. For now part of our system is still now async ready and we should use .Result.\nThanks for your fast response and collaboration.\nCheers \n. ",
    "frankmeola": "Mike, \nThanks for taking the time to reply. I apologize for the miscommunication. I had intended that the Enact or  Enforce would be in addition to the Execute and would most likely use Execute to handle the implementation. It would be more of a semantic method overload instead of an parameter method overload :-) That way there is no breaking change and people could use whichever method fit their mental model of a policy.\nAs expected I was able to accomplish this with an extension method so the different syntax is something the client could opt-in to by adding a using statements:\npublic static class PollyExtensions\n{\n    public static void Enact(this Policy policy, Action action)\n    {\n        policy.Execute(action);\n    }\n}\nI could also understand where having two names for the same method would be confusing to the client not to mention a bigger API surface for you to manage.\nThank you for taking the time to listen to suggestions!\n. ",
    "nelsonghezzi": "Hi, I will take a look at the rebase this weekend, and let you know of any progress!\n. I'm not 100% sure on how to proceed with the rebase. If I do a git rebase App-vNext/master on my feature branch, then I'll have to force-push to my local branch on GitHub (the one in that the PR is based on), right?\nI think that would be safe, as the PR has not been accepted and no one else is working on this branch, but I'm aware that rebasing a public branch should be avoided.\n(I recently took a look to the contributors' guidelines and realized that was a mistake working directly on master for the feature, so if needed, maybe I could replay the changes on other branch first and create a new PR).\nAs for the magic string in the test, yes, I used it cause other tests in that file were in that fashion. But sure, I'll replace them with a boolean as it adds more meaning to the test.\n. Thanks @joelhulen, I did as you told.\nThe rebase went without any merge conflicts. Git did a good job (as expected) tracking the renames in the files that were made in the last commits on upstream.\n@reisenberger, I've added a new commit with the changes in the variable names as you pointed. I think it's good to go, but otherwise, let me know.\n. That's great! :tada:\nGlad I made a useful contribution :smile:\nKeep up the good work!\n. ",
    "YoniH": "After some more experimenting with the library, I want to try to be more accurate. What I want to do is this:\n1. On every retry, I want to calculate some numeric value based on the exception and maybe the retry count.\n2. This number should be passed as argument to the execution function.\nCurrently the way I'm doing it is something like this:\n```\nclass Program\n{\n    static void Main(string[] args)\n    {\n        var someNumber = new Integer();\n    var policy = Policy.Handle<DivideByZeroException>().Retry(3, (exception, retryCount, context) =>\n    {\n        (context[\"someNumber\"] as Integer).Value = 17; //Instead of 17, the value would be calculated based on the exception\n    });\n\n    policy.Execute(() => DoSomething(someNumber), new Dictionary<string, object>{{\"someNumber\", someNumber}});\n}\n\nprivate static void DoSomething(Integer numberArgument)\n{\n    Console.WriteLine(\"The number is {0}\", numberArgument.Value);\n    Console.WriteLine();\n\n    int x = 0;\n    var y = 2/x;\n}\n\nclass Integer\n{\n    public int Value { get; set; }\n}\n\n}\n```\nThis seems a bit cumbersome. Is there a better way to do that?\n. ",
    "savehansson": "Any news on this?\n. ",
    "ericis": "bump  @ThreeSevenths AppVeyor should support .net 5 projects. Any idea why it failed? Should this sit in a branch until they're out of beta?\n. ",
    "ThreeSevenths": "@ericis - It failed on my machine as well. Problem seems to be msbuild not liking the new targets for aspnet5 by default. Hopefully they will fix with RTM.\n@michael-wolfenden - Good call.\n. ",
    "ThomasMentzel": "I tried several ways to get this implemented via extension methods but I did not found any solution. My problem was the definition of the exceptions to handle. For the \"post processing\" I need the exception predicates to keep the \"throw if not handled\" mechanism. Because if I do a retry on a \"ConnectionException\" and after 10 retries, the connect did not work, Execute() throws the exception. I need to throw the exception if it was not handled and post-handle the exception if fulfills the retry predicates.\nI tried to keep the footprint as minimal as possible but unfortunately I needed to forward the exception predicates. https://github.com/michael-wolfenden/Polly/pull/40/files#diff-9c3ec5de43339ca9d19197ca30b8ef17R78 . So I made the policy contain the predicated to access these after execute.\n. ",
    "DarrellMozingo": "How about using a MemoryCache for success/failure rates by default, and getting a failure ratio from that? We prefer to use ratios rather than hard numbers (and likewise, ratios when the circuit is in the half-open state). Then just a simple x% of requests in n minutes have failed, trip it. TTL on the cache can easily give you the n minutes automatically.\nAlso agree re not having a centralised way to notifying other services about failures. What if the connection from just Serivce A -> M goes down/degrades, but the rest are OK? Now you're telling services B & C that they can't talk to M even though they can. Dangerous and lots of code/systems overhead. They'll figure it out.\n. ",
    "kristianhald": "Hi @reisenberger. Thanks to the team for developing Polly. It is a nice library.\nIn regards to this issue, I concur it would be nice with a feature that would allow the circuit to break if N exceptions occur over a period of T. \nOne example, where I would like a circuit to break is in the case, where a client is communicating with a server that is overloaded. The server would once in a while successfully handle a request, but most of the time return timeouts (As it will not be able to handle a request within the alloted time). Breaking the circuit for a little while, might help the server get it self up again.\nAnother example is the same as @TimGebhardt talked about where, during slow periods (Maybe nighttime), a single request is being retried and failing every once in a while, which breaks the circuit and can keep the circuit open, when good requests begin to filter in.\nI looked at both implementations you made and think that both would solve the two examples above. The first implementation is easier to read. The second implementation requires are bit more thought to convience that there isn't an outlying case that could result in improper behavior.\nIs this a feature that the team wants into Polly?\nAnything I can help with?\n. Looked through the source for Hysterix regarding their Circuit Breaker implementation. As I read it, they use a bucket, where each item is a slice of the '_durationOfExceptionRelevance'. The precision is then defined by the size of the slice.\nI think that the 'Frequency-based' solution is the same that Hysterix has implemented (Except that they look at percentages instead of the total number within the frequency given). The hubris in me, would state that the first implementation that @reisenberger has made with the queue of exception times, is time slicing where the window is very small and each window only contains a single information that an error occurred. :smiley:\nI also like that the Hysterix implementation, before triggering the circuit breaker, checks if the number of requests received during the period is above a certain threshold (This is probably necessary, as else a single error will have a large impact on the error percentage, if the throughput is low). \njava\n// check if we are past the statisticalWindowVolumeThreshold\nif (health.getTotalRequests() < properties.circuitBreakerRequestVolumeThreshold().get()) {\n    // we are not past the minimum volume threshold for the statisticalWindow so we'll return false immediately and not calculate anything\n    return false;\n}\nPersonally, the few times I have used circuit breaker, it has mostly been leaning towards the frequency based. It is probably a personal preference, because I always like comparing stuff that happens with when they happened.\n. Woaw, nice progress!! A bit faster than I expected. Here I come and say that I want to help and then I am nowhere to be seen. I apologise for that. Enough selfpity.\nI think the TimesliceCircuitController looks good. The OnActionSuccess not checking, if the failureThreshold has been reached got me thinking. There might be a situation, where 3 failures will occur followed by a success, which would result in 75% errors and the throughputThreshold of 4 having been reached, which would mean that it should fail.\nHowever, after a bit of thought, I came to the conclusion that it did not make sense to open the circuit on a success even if the failureThreshold has been reached. \nWhat do you think?\nAlso I am a bit uncertain if the rollover is necessary and how hard it will be to understand. Without it will mean that in worst case, it will take up to 2*timesliceDuration, before the circuit opens.\nA scenario could be where the timesliceDuration is set to 5 minutes and 1 minute into the slice, failures begin to occur, but just enough to be below the failureThreshold. The slice resets and the failures continue to occur. \nI think that it will depend on what the timesliceDuration is going to be set to (seconds, minutes or hours) and how fast the circuit breaker should react.\nFor what I work on, rolling slices is not critical, as it will just mean that Polly will react on the failure state a bit later. Being able to specify ratio and timesliceDuration is already a long way.\nI know I said it before, but I have more time on my hand now. If there anything you need fixed before this can be merged, then please throw it to me.\n. @reisenberger I can work on placing the health metrics in slices(buckets) to provide a rolling window for the circuit breaker.\nThe other day I made a quick POC based on the code you did, which includes a single test:\nhttps://github.com/kristianhald/Polly/commit/0b0bb45d28a0e7fe983a003c68ce6628740d792b\nThe POC hardcodes the bucket size to 10, but this was only done because of the POC.\nWould that be a way to go or were you thinking on going in a different direction?\nDo you have existing tests that measure performance, which I could use for inspiration?\n. > eg 5 = rolling-throw-away 20% of the statistics at a time (a great improvement on 100%-throw-away; likely to cover most fidelity situations; strikes a balance between fidelity and extra computation). What do you think?\nAny number higher than than 1 would indeed improve responsiveness. My initial thought was to have a quick calculation (Is only done once at the creation of the circuit breaker), which would give a larger bucket slice duration for larger windows with a minimum of 0.x seconds per slice (And maybe also a maximum). Something like 4Log(windowDuration * 500) which would give the following results:\n| Window duration | No of buckets(rounded) | Bucket timeslice |\n| --- | --- | --- |\n| 10 seconds | 8 | 1.25 seconds |\n| 1 minute | 13 | 4.62 seconds |\n| 10 minutes | 23 | 26.087 seconds |\n| 1 hour | 37 | 97.297 seconds |\nThe reason for choosing a calculation like the above, is to state that if the window duration is long, then the responsiveness of the breaker is allowed to be lower. However, choosing a calculation that provides a good number for any input might be hard?\n. > Regarding not user-configurable\nI agree with the difficulty of using the feature, if the developer has to choose the bucket size or the bucket duration. I always like having the library providing me with reasonable defaults as I believe the developers of the library to have better knowledge of the area, than I do. Also if the default is based on the window duration provided, then a developer wanting more responsiveness can lower the window duration.\nI do not believe it is necessary for a 1.0 version of this feature(because the feature goes a long way and the bucket duration can be controlled by the window duration), but it can be hard for a library developer to anticipate all usages of their library(Having worked on a few software projects, where a core library had to be built upon and extension was only possible at the hooks they provided) and therefore there might be cases, where a developer will need to override the default.\n\n[2] Should we consider some minimum timesliceDuration below which we do not subdivide into further buckets? Or (alternative/similar) some minimum size for a bucket?\n\nI cannot imagine (Not that someone probably would need it) needing a bucket duration less than quarter- or half-a-second. We are talking about an application that needs to cut off as soon as enough errors are encountered and cannot wait quarter- to half-a-second before opening the breaker. In most applications I do not think that this is an issue.\nWe also have to remember that we are using DateTime, which only has a resolution of 1-16ms depending on hardware and OS settings. I believe talking about bucket durations that are so low is an advanced topic.\nI still believe that in the first version, the library should provide reasonable defaults as this will be the setting mostly used. Also adding this feature will require some thought into what would be allowed and what should not be allowed.\n. @reisenberger Read the document and I entirely agree. I think that the naming is much better than what we have used before. I especially like samplingDuration.\n\nThis is because of the way a 'long tail' of successes affects statistics. Consider a circuit configured with a sampling duration of 5 minutes (not recommended), set to break at 50% failure threshold. Imagine everything has been working perfectly (100% success rate) for a while. 100% failures then start occurring (at roughly the same throughput). Such a circuit will take at least 2.5 minutes to reach 50% failure rate (to 'work off' the statistics from the 100% success era).\n\nI did not take that into account, when looking at the value given to the samplingDuration variable. Its a bit interesting what happens, when both the failure threshold and the sampling duration can be changed.\nSetting the sampling duration low, but the failure threshold high means that the breaker will break if there is a small hiccup in the network. However, setting the sampling duration high, but the failure threshold low means small hiccups in the network does not affect the breaker, but issues like packet loss can trigger the breaker. If both are set high, then it just means that it should only break in case the other side is really down and setting both low means you are using a service, where you really do not want to hammer in case something is wrong and you want it to not do it quickly (Reminds me somewhat of scraping protocols :smile:).\n\nthe responsiveness of the circuit-breaker seems in the worst case (do you agree?) essentially proportional to the stat window duration, however finely you divide it into buckets, because of the 'long tail of successes' problem described.\n\nYes.\n\nI wonder if it is adequate just to adopt a fixed number of buckets (unless makes buckets too small as prev discussed).\n\nI think that a fixed number of buckets would be sufficient for most cases and if someone needs a more finegrained or coarsegrained bucket number, then the easiest and probably best solution, would be to overload the AdvancedCircuitBreaker syntax with an additional field for specifying bucket number.\nIf a developer has this need, then it probably means the developer has enough knowledge about the circuit breaker to know the implications of this, I would assume.\n\nTo state more precisely part of my previous thinking: varying the size/number of buckets can increase the fidelity (fidelity-at-all-times) of the circuit-breaker to its configured thresholds, but cannot increase its responsiveness (overall speed of response) to the theoretical 'long-tail of successes' problem stated.\n\nI was about to write, that I didn't agree, but having thought through different examples, the only example I can think of is the case where no communication has gone through the breaker, when suddenly communication begins and it fails. This is a very poor example.\nI think that the number of buckets influence the circuit-breaker more or less depending on what the failure threshold and minimum threshold are set to (As you write). However, if the failure threshold is set low (< 50%) and the minimum threshold is set higher, then having only 1 bucket will reset the throughput counter every samplingDuration requiring the throughput counter to be met again, before the circuit-breaker acts.\nI believe that the minimum threshold is the threshold that is the most affected by the bucket numbers, than the two other thresholds. Is that correct?\n. > However, relationship between timesliceDuration and breaker responsiveness kept clear, because it is important that users seeking a responsive breaker do not fail to understand the possible implication of configuring a breaker in minute or hour periods.\nAgreed. Just thinking about the scenarios using the current three variables, shows how difficult it is to select correct values for ones need. Selecting a bad combination of numbers can either result in the circuit-breaker opening too soon or too late.\nWould it be an idea to describe in the documentation what happens, when varying the failure threshold and sampling duration. Thinking here about the four combinations that are the outer cases (high, low), (low, high), (high, high) and (low, low) and what would happen in the circuit-breaker?\n. @reisenberger Made a new implementation, which is a bit more cleaned up version of the POC.\nIts located here: https://github.com/kristianhald/Polly/tree/CircuitBreakerSpikeMarch16_AddedWindows\nI did not try to optimize the implementation, like as you said, we can do that when the fundamentals on done.\nI went from using 'Bucket' to using 'Window' instead, as I felt it was a better name for it.\nThe implementation looks alot like the POC. Also I added a few tests to ensure that the windows are being used by the implementation correctly.\nDo you see some test cases that are missing, which I should add?\nI was thinking, in regards to the issue with a low sampling duration and windows, maybe for simplicity only use rolling windows if the sampling duration is set high enough. It could be documented by stating that if sampling duration is set to x or higher, then rolling windows are used else a single window is used for the entire sampling duration.\nWhat do you think?\n. I have updated my fork with some additional features. Below I will go through the changes as they all relate to comments you have provided @reisenberger.\nThe code can be found here: https://github.com/kristianhald/Polly/tree/CircuitBreakerSpikeMarch16_AddedWindows\n\nRationale: Per DateTime documentation, DateTime resolution is around 15-16ms, as you commented earlier. Let's round this up to TimeSpan.FromMilliseconds(20). There isn't any point in creating slices (or windows within slices) smaller than this, as it will just lead to empty slices/windows. As we are defining as a well-named const ResolutionOfCircuitTimer, it'll be easy to change later if needed, and easily visible if any user later has higher resolution requirements and investigates the code.\n\nI have created the internal constants and updated the syntax to use the resolution of the circuit as the minimum allowed timesliceDuration (sampleDuration).\n\nCan the operational code be done so that it doesn't look too messy / branching depending on whether it's using further buckets/windows or not?\n\nI have done circa the same, that you have done with the ICircuitController using a strategy based approach. I believe it is the cleanest and I thought that any performance issues with using an interface instead of the class directly could be measured before not selecting it.\nThere are currently two implementations (RollingHealthMetrics and SingleHealthMetrics). The selection is based on timesliceDuration < ResolutionOfCircuitTimer * DefaultNumberOfBuckets, selecting one or the other. There is a performance overhead for using interfaces. See test results in the bottom of this comment.\nAt the moment the decision on using one or the other strategy is happening in the controller, but depending on your view, the choice can easily be done where the circuit controller is being created and then injected. I have a preference, but in this case I think that its better you make that decision :smiley: \n\nThese approaches could be refined later (for example, between 200ms and 20ms we could adopt an algorithm which provided the maximum number of buckets which kept bucket size over 20ms). But let's start instead from a premise 'keep things as simple as possible until we know they need to be more complicated'.\n\nI agree. Should not be hard to add. If we keep the current implementation, then its just another implementation of the interface and then doing a selection of when to use it (Probably when timeslice duration is between X * Resolution and Resolution * MaxNumberOfWindows.\n@reisenberger @joelhulen Did a run with the code from the fork I am working on using my development host.\nFirst result is where RollingHealthMetrics are used without inheriting from an interface:\nhttps://gist.github.com/kristianhald/534ed0540e8030060f1c49da04100e4a\nSecond result is still with RollingHealthMetrics, but it inherits an interface and the interface is used in the circuit controller(The strategy based implementation):\nhttps://gist.github.com/kristianhald/81d00afc036001afaac3c7d8927b6864\nUsing an interface decreases the performance, but only with around 10 ticks per iteration.\nI checked that on my machine there goes about '10000' ticks per millisecond, which means that a difference of 10 ticks is very low.\n. > I now feel relatively clear on the effects of setting different parameters near boundaries, as follows.\nI agree with every variable comment.\n\nTo take the documentation away from too abstract discussion, I may add a 'suggested typical starting configuration' for downstream network calls.\n\nI looked at the draft documentation again and the part about configuration recommendations for the sampling duration requires some thought to it. I think that beginning the documentation with suggested configuration, which can allow the user to quickly be up an running and then having more detailed information later is a very good way of going :smile_cat: \n. > See const TimeSpan.TicksPerMillisecond\nAhh, did not know that the ticks per millisecond for DateTime and TimeSpan is constant. Nice to know. \nNormally ticks per millisecond is defined by the CPU and OS based on the frequency they work on, which is why I provided the number of ticks :smile: \n. > Please feel free to review the final changes to https://github.com/reisenberger/Polly/tree/CircuitBreakerSpikeMarch16 if you have an interest\nDid a quick lookthrough the changes and I think they are good.\n\nI intend to PR this to master later today\n\nCool. Out of curiosity, what is the procedure for nuget packaging the master branch?\n. ",
    "kmcginnes": "Awesome. There's probably room for a little more consistency between the sync and non-async APIs.\n. ",
    "nedstoyanov": "@reisenberger I like this approach. I am happy to have a crack at this, haven't contributes to OSS before but have been playing around with async a fair bit. \n. no worries @reisenberger, I am happy to have a look once you are done. I think it will be a useful feature.\n. Had a brief look and it looks good. Will try and play with it a bit more later on. Good work.\n. @reisenberger I believe what this relates to is that ContextualPolicy does not have an ExecuteAndCapture method. I came across this as well today when doing:\npublic static readonly Func<ContextualPolicy> NotificationSendPolicy = () =>\n         Policy\n         .Handle<Exception>()\n         .WaitAndRetry(\n             NotificationSendMaxRetries,\n             GetExponentialBackoffTimeToWait,\n             (ex, t, c) =>\n             {\n                  // Log error and retry count\n             });\nYou appear to be only able to call Execute on the ContextualPolicy, not ExecuteAndCapture.\n. Thanks for your comments @reisenberger, I rebased my branch and I am fixing up the issues.\nThis is my first PR so not sure what is the process here. Do I close this PR and open a new one, or is there a way to fix this one?\n. @reisenberger regarding the error count, should we just stop incrementing once it reaches int.MaxValue? Alternatively we can return false from CanRetry but that won't really be retrying forever. \n. @reisenberger @joelhulen I think this PR should be ready. Are you able to review?\n. Thanks, @reisenberger I'll try and fix these issues in the meantime.\n. Thanks for the feedback @reisenberger, I'll make the changes in the next few days. Apologies for the holes in the code I am still relatively new to Polly.\n. @reisenberger I have implemented your suggestions and also fixed up the Should_not_call_onretry_when_no_retries_are_performed() test in the WaitAndRetry/AsyncSpecs\n. ",
    "johnkattenhorn": "Great catch - I'd never had figure this out in our project :-)  I wonder if missing project type might be Xamarin Shared ?\n. ",
    "yevhen": "I've figured out that I don't have Windows Phone SDK installed. Done that.\n@michael-wolfenden will you accept PR that fixes aforementioned problems? We can discuss api changes before I even try or I can proceed with PR, so there will be something eligible for further discussion?\nSketching that, I think it could be implemented without any breaking changes.\n. @michael-wolfenden any updates on this?\n. @reisenberger ye, think the same!\n. Very good suggestion. I will update PR.\nre order of CancellationToken/ContinueOnCapturedContext I think any order is fine.\nThe more important is to figure out what to do with all those overloads? If we introduce another set of overloads (permutation with CancellationToken) we may end up with unmaintainable mess. I think that number of parameters is already far behind the number of parameters acceptable for Clean Code :stuck_out_tongue_winking_eye: \nWhat if we introduce something like Parameter Object? Alternatively we can try to employ automation, say T4 template which will auto-generate overloads with all that currently copy-n-pasted xml documentation.\n. If you're ready to publish new Nuget package then I'm ready to update this\nin few days )))\n2015-12-10 1:26 GMT+02:00 reisenberger notifications@github.com:\n\n@yevhen https://github.com/yevhen Thanks again for this important PR!\nUnless anyone has brighter idea on overloads, team AppvNext are ready\nto accept/merge.\nAre you able to update the PR with the following minor adjustments? - then\nit will probably be good to go!\n- resolve conflicts by rebasing against latest master\n- fix overload not using bool continueOnCapturedContext mentioned few\n  days ago\n- adjust bool continueOnCapturedContext parameter position per\n  discussion few days ago and a few more line notes I will add\n- update changelog.MD to describe change (but not\n  GitVersionConfig.yaml; @joelhulen https://github.com/joelhulen will\n  when pushing to Nuget)\nThank you!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/App-vNext/Polly/pull/53#issuecomment-163435142.\n. Sorry, guys. I'll definitely do this till EOW. At the moment I'm incredibly busy, preparing for 2 public presentations this week.\n. No worries ))\n\n2015-12-16 21:18 GMT+02:00 Joel Hulen notifications@github.com:\n\nThanks, @yevhen https://github.com/yevhen! I hope you know I wasn't\ntrying to pressure you. It's a crazy a time of year for all of us.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/App-vNext/Polly/pull/53#issuecomment-165214882.\n. Hey, just recovered from all those holidays ))\n\nGoing to work on this tonight. Hope to finish it tomorrow. \nStay tuned :)\n. makes perfect sense for me. Any other places or those are the only one that need to be patched?\n. guys, what do you have set for Git's core.autocrlf and what version of git do you have installed? I'm observing absolutely weird behavior with files being modified just after the clone, despite having core.autocrlf=false. I'm using Git v1.9.5.\n. @reisenberger ye, NotOnCapturedContext() doesn't make much sense anymore. I'll incorporate this realization ;)\n. I do believe problems with line endings are due to use of .gitattributes file. I observed similar problems on my projects when this file was included. It needs to be deleted from source. It only creates more problems.\n. I've added all change requests as separate commits so it should be easy to review. If you want I can squash everything into single commit.\n. Hey, build failed for some weird reasons. Please kick a rebuild.\n. Awesome! =)\n. Ah, I forgot to modify CHANGELOG. Tomorrow then. \nCan you do it? ))\n. That would be great, cause I'm out of city till 10th of January \ud83d\ude04\n\n30 \u0434\u0435\u043a. 2015 \u0433., \u0432 19:12, Joel Hulen notifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b(\u0430):\nI can modify the CHANGELOG if you haven't already.\n\u2014\nReply to this email directly or view it on GitHub.\n. Thanks guys! It was a pleasure working with you on this PR. Keep it up!\n30 \u0434\u0435\u043a. 2015 \u0433., \u0432 21:15, reisenberger notifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b(\u0430):\n@yevhen Thanks for your exemplary clear presentation! (a standard for us to follow  ). Have been a good second pair of  and @joelhulen looks good to go to me! Many thanks yevhen for tracking all that detail...\n\u2014\nReply to this email directly or view it on GitHub.\n. Awesome! That would be great addition!\n30 \u0434\u0435\u043a. 2015 \u0433., \u0432 21:35, reisenberger notifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b(\u0430):\nThanks @yevhen . Cancellation support (#46) coming shortly (I've been working on it in background), which should round out the async support in Polly nicely. \n\u2014\nReply to this email directly or view it on GitHub.\n. @joelhulen +1 @reisenberger nice catch! I was trying really hard to not introduce breaking changes and got lost with all those pesky overloads. Many thanks and you don't need to apologize for that. It's great to have another pair of eyes! :eyes:\n. \n",
    "gramanero": "@reisenberger  Wow, so I never saw the email notification telling me that anyone responded to my suggestion. I really appreciate you taking the time to respond (like ... way back in January). We do have a NuGet package in use currently that wraps up the functionality I was asking about. I will take a look at the Paramore project to see what that is all about. \nThanks for pointing me off in that direction and for capturing this idea on the roadmap!\n. @reisenberger Yes, absolutely. In fact, the details of the actually package that we are using were included in the first post that I made on this topic. I changed some names around in the post, but the configuration structure and C# logic were pulled directly from the package that was built. To contribute it back to the community I would just need to change around the name spacing of the code and package and make any other changes necessary based on feedback. If this is something that you feel would be of value, then we can work together to get this done. I have never contributed back to the community but think this would be a good, simple start for me and the organization that I work for to start giving back.\nI will likely need a little guidance on how to go about creating a fork of the based code, etc. Having not gone thru this process before I certainly don't want to mess anything up.\nThanks!\n. @joelhulen Thanks Joel. Like I said...it'll be a bit of a learning process for me so I am sure I'll have a fair number of questions. Thanks for FWing the links. I am traveling this week so I will likely have a chance to read thru some of the information before attempting to create a fork and begin to integrate the work. Which brings up the questions you are asking @reisenberger .\nRight now the package, named OEC.Core.PollyConfig (which I will re-namespace), relies on .NET 4.5.1 and has a single dependency, that being Polly @ version 2.2.3. So this PollyConfig package wraps the base Polly package to add the support for configuration. I am not sure if that is a better approach as opposed to integrating the work directly into the base Polly package. I tend to like the idea of keeping the packages separate (although I can see where that might be a pain to manage keeping the packages inline with one another) in order to reduce the overall size ov the base Polly package in the long run. Just my .02$ and I am new to this, so feel free to provide suggestions, advice, and direction. ;-)\nAs a side note, I work for OEConnection (that is what the 'OEC' in the namespace stands for) out of Richfield, OH. I am trying to find some small opportunities to get the development staff here to give back to the open source community and I feel like this is a nice, small, starting point. I am going to run with this first one an then I hope to grow the idea from here.\n. Hi @reisenberger. This has been on my mind so thanks for the push. Sorry\nfor the lack of attention to tis recently. My summers get filled with\nmountain bike races and training, so I expect to have a bit of time now\nuntil the beginning of June.\nI am guessing I should re-namespace the project first and then stick it\ninto github? Probably makes the most sense. Figure I will just go with how\nwe have been discussing it here as Polly.Config. I really like the idea of\nmaking it a separate package and treating this more as an add-on capability\nfor others to consume when/if they feel it will add value and not have it\nunnecessarily clutter up the main line Polly package, but I am certainly\nopen to whatever the group feels would be a more maintainable approach.\nI will get to work on this today and this coming week if this all sounds\ngood.\nThanks!\nOn Sat, May 14, 2016 at 4:16 PM, reisenberger notifications@github.com\nwrote:\n\nHey @gramanero https://github.com/gramanero . I think a next step (if\nyou happy) would be for you to upload a copy of the code you have to some\nrepository on https://github.com/gramanero . The Polly team can then get\nsight of the code and we can explore together the best way to structure an\nadjunct to Polly.\nOne aspect on my radar is that there may be some beneficial overlap with\n87 https://github.com/App-vNext/Polly/issues/87 (apply policies from\nattributes). I'm wondering if the configure-policies-from-config approach\nperhaps has elements of [i] extract, [ii] store and [iii] apply. #87\nhttps://github.com/App-vNext/Polly/issues/87 probably also needs some\nkind of [ii] store ('Policy Registry'?), and is a method of [iii] applying.\nWe might (speculating here...) eventually end up with something like\nseparate packages Polly.Config, Polly.Registry, Polly.Attribute (of which\npeople pull in the bits they need) ... But speculating - hence, a useful\nfirst step would be to see any existing code, then we can begin to reason\nabout the best way to structure this.\nThanks!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/50#issuecomment-219249326\n. \n",
    "pvmraghunandan": "Is it just for configuration driven? I think we should also support end systems which can maintain configuration in different way like JSON as example. But I am more interested on handling predicates. How are we planning to achieve it?\n. \"major benefit to be able to tweak, on the fly, in production, the trigger thresholds and break durations of circuit-breakers\". This is exactly what we are looking for. And as you said, it is difficult to handle events like onBreak.. But we are thinking to provide some sort of configuration like {Type, PropertyName, PropertyType,  Accepted Values}. Eventhough its pretty much easy to code for example handling status in WebException, can we think on some optimized way so that we don't do much reflection and doesn't have performance benefits.\n. @reisenberger  The type and properties are used during HandleException and HandleRetry delegate being called. For now we have taken simple approach of only having exception types as configurable instead of introducing bit complexity and reflection.\n. Very useful in scenarios of REST (or) having WCF service that returns custom exception if its external components throttles. Any idea on when this will be available as public?\n. Thanks for updating. Could see new nuget version.\n. As per current implementation, we are expecting list of result predicates and the return type is tightly coupled with policy object. If we want to have one policy object for an WCF service, the implementation is forcing us to use object type and do typecast and all sort of stuff and also couldnt write generic code.. The code is:\nif (shouldHandleResultPredicates.Any(predicate => predicate(delegateOutcome.Result)))\nDo we ever have multiple predicates practically? Shouldnt we update logic to accept predicate during Execute() .Any feedback so that can start updating code.\n. @reisenberger  Sorry for late reply. Little bit occupied with other stuff.  We are looking for below.\n\"WCF service offering a number of functions returning different types, and we want to use same policy for all (Policy for Service) but the result handling is different\".\nToday we can't achieve the common policy because if we want to apply result handling and when we say .OrResult(), the return type is PolicyBuilder.\nAlso We have onRetry and other delegates also as independant because we want to tie up with our logging engine where activityId and other related information is different for each call. With passing onRetry during object creation, we cant achieve this.\nHystrix was one consideration but creating command classes for each type that we are going to handle might not be better way is what we feel.\n. Hi @reisenberger \nThanks for prompt reply. For onRetry() will give a try once. \nBut didn't get on one policy that returns different results and handling predicates differently. Basically Result Type is unknown at compile time so today we are casting back and using is/as operators to achieve this.\n. @reisenberger Completely agree on caching reflection and all. Infact we are doing in little different way so that we avoid much reflection. But why cant we expect delegate as an Execute() parameter so that its up to caller to send whatever delegate he need. In our case especially we deal with multiple external systems and each has multiple methods. Some will send specific error codes that indicates their transient failure and some will not. So its upto implementation (In our case adapter) to send result handling delegate as i am already invoking policyBuilder with type as specific type.\n. @reisenberger  Thanks for clarifying. Will take a look on advanced circuit breaker once.\n. @reisenberger Trying to understand SingleHealthMetrics and RollingHealthMetrics. Can you help us understand this and how does sampling and no.of windows work together?\n. We are also planning to use in high throughput telemetry ingestion in IoT scenarios which involves business processing and communication with different external systems which are out of our control. We want to use circuit breaker there but at the same time we would like to limit no.of calls (i.e. only allow X calls even if requests are more) during Half-Open and then have different configuration on Half-Open i.e. No.of calls, threshold, duration, minimum throughout incase of Advanced for fine grade control.. @reisenberger I have been quite a busy and didn't get chance to check status on this issue. I will check it out today and update accordingly. Thanks for quick response.. @reisenberger Quick question. I am facing similar issue. When the circuit is in open state and transistioned to half open and at the same time if we get two calls, are we saying that we allow only one call to pass through and other call will get Broken Circuit Exception? I am seeing similar behavior. If that's case, can we skip whole half-open? :) . @reisenberger Thanks for input. I liked option 2. Will give it a try and update.. @reisenberger  This worked!! Thanks for putting up documentation very quick. It's very helpful. Closing the issue.. ",
    "SamuelEnglard": "I have a working branch on my local clone. Passes all but 45 tests!\nI would note that this is a \"must\" for me as I'm working on a Core project for production that badly needs polly\n. @reisenberger honestly not sure why I didn't push it up but did now! https://github.com/SamuelEnglard/Polly/tree/netcore/\n. @reisenberger Yup, that attribute fixed it!\n@reisenberger One thing to note: I had to make some changes to the packages I reference to work in RTM but otherwise all good :)\n. Really want to use this in a ASP.NET Core application, any idea how I can currently?\n. @reisenberger should I make a proper pull request?\n. Personally failover and dynamic configurations would be my next top items. I'd have dynamic configuration first since that can be used to create failovers. Back at work so giving this a look. First thing to note is I only updated to support 1.3, as I don't think we to require 1.6. Otherwise looks good\n. @reisenberger I've been pulled into side issues so I haven't been able to test this week. Thanks for the credit!\n. Just wanted to give an update from my side: I've been switched from the project that is using Polly so I can't really comment on how it's going anymore but from what I know they're having no issues\n. ",
    "jabaran": "Excited to give this a shot, thank you!\n. ",
    "DennisNerush": "Currently I do this:\nprivate void ResetPolicy(IPolicy policy)\n        {\n            var privatePolicy = policy.GetType().GetField(\"_policy\", System.Reflection.BindingFlags.Instance | System.Reflection.BindingFlags.NonPublic).GetValue(policy);\n            var exPol = privatePolicy.GetType().GetField(\"_exceptionPolicy\", System.Reflection.BindingFlags.Instance | System.Reflection.BindingFlags.NonPublic).GetValue(privatePolicy);\n            var target = exPol.GetType().GetField(\"_target\", System.Reflection.BindingFlags.Instance | System.Reflection.BindingFlags.NonPublic).GetValue(exPol);\n            var state = target.GetType().GetField(\"policyState\").GetValue(target);\n            state.GetType().GetMethod(\"Reset\").Invoke(state, null);\n        }\n. IPolicy is my interface\n. Thank you\n. I can separate them and ask for another pull request. Would you want it?\n. Tell me how I can help :)\nOn Sat, Dec 5, 2015, 22:22 reisenberger notifications@github.com wrote:\n\n@DennisNerush https://github.com/DennisNerush I've noted a few more\npotential complications with the separating out in #63\nhttps://github.com/App-vNext/Polly/issues/63 (although I think it's a\ngood idea). Stepping back now to let @joelhulen\nhttps://github.com/joelhulen and team consider way forward, and/or\n@michael-wolfenden https://github.com/michael-wolfenden clarify.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/App-vNext/Polly/pull/62#issuecomment-162243202.\n. Great!\n. \n",
    "ploeh": "I think I'm probably stating the obvious here, but whatever happens from here on, make sure to migrate the project to a GitHub organisation, so that in the future, ownership can be transferred without moving the repository.\n(I'm not saying that @michael-wolfenden has done anything wrong by starting with a personal repository - I do that all the time myself, and most of the time, the projects never become popular enough for that to be an issue.)\n. I was mostly thinking about your item (b), since all the other features can easily be added in client code, if need be. The problem with a function like the following execute function is that it's likely to be inefficient (although, to my chagrin, I must admit that I haven't measured, because I have nothing against which to measure).\nfsharp\nlet private execute (policy : Policy) f  req =\n    policy.ExecuteAsync(fun () -> f req |> Async.StartAsTask) |> Async.AwaitTask\nF# async workflows aren't Task objects; there are some differences, the most important of which is that F# async workflows are pure until started, whereas Task instances just starts running in an uncontrollable fashion.\nThis means that while it's possible to go back and forth between async workflows and the TPL, such transitions aren't free. There's synchronisation and (possibly) marshalling overhead every time one does that.\nThe above execute function performs two such translations every time it runs.\nIt'd be nice to have a native Polly API that mirrors CircuitBreakerAsync, ExecuteAsync, and so on, but for F# async workflows instead of tasks. In order to make any difference, however, it'd need to use F# async workflows all the way. If it needs to translate back and forth to tasks deeper within Polly, it hardly makes any difference.\nI haven't looked at the Polly code base, so I don't know how realistic this is. Furthermore, AFAIK, all the types involved in F# async workflows are defined in FSharp.Core, and I don't see how to add support for this without taking a dependency on that assembly.\nSo it may not be desirable, but instead of reaching that conclusion all by myself, at least I thought I'd discuss it in public \ud83d\ude04 . ",
    "monotore": "I have a class where the Policy is a field. The field is used by multiple methods of the class. An instance of the class is used by multiple threads at the same time. Is this OK?\n``` C#\n   public class Class\n    {\n        private readonly Policy _policy = Policy\n            .Handle()\n            .RetryForever();\n    public void MethodA()\n    {\n        _policy.Execute(DoSomething);\n    }\n\n    public void MethodB()\n    {\n        _policy.Execute(DoSomething);\n    }\n}\n\n```\n. ",
    "videege": "Hi, sorry for the delay in replying.  I will try out the new cancellation support.  I got my code working using the approach you suggested by filtering the exception type using the lambda expression available to Handle.  I just needed to add in some additional error handling in my wrapper policy for those particular exception types - the normal propagation of exceptions in the handler was what was throwing me off.\nThanks for your help!\n. ",
    "gapotchenko": "Turned out that policy.Execute method already passes the result through.\n. ",
    "TrevorPilley": "Could you not just add public int Attempts {get;set;} to PolicyResult  and do result.Attempts++; to the code which executes the delegate passed to ExecuteAndCaptureAsync?\n. @joelhulen I tend to tag every release, even if it's a 1 liner defect fix and then turn that tag into a github release with a link to diff against the previous version. It's a small amount of effort each time but I think it gives a good experience to anyone who wants to know what's changed and what the potential impact may be of updating a package which can still be a concern even if people follow semver\n. ",
    "SurajGupta": "GREAT project, btw!  so easy to drop Polly into my code.\n. Thanks for the thoughtful reply!  All good points.  Lets see if anyone else has some ideas.. ",
    "maverix": "https://web.archive.org/web/20160106203951/http://thatextramile.be/blog/2008/05/the-circuit-breaker\n. ",
    "StefanBols": "@joelhulen the link is broken again. ",
    "alvpaz": "I will create the project. But the problem is that I am connecting a WCF service and gave expired time error, and when he tries to run again he did not allow because the context already with error status, I will try to simulate an example and post here.\n. ",
    "mgj": "Im sorry i dont have much to add, i just wanted to voice my appreciation for the work being done here - This PR will be very very useful to me. If there is anything I can help you with regarding this PR, please let me know. Thanks\n. ",
    "mfjerome": "The code above is just an example to illustrate the issue and I don't know if it possible to do it fluently this way. In Hystrix, by Netflix, the framework provides an interface that the user must implement with, among other things, a function \"GetFallBack\". That method will be called if the command execution fails because the circuit is open (short-circuited). Beforehands, this client implementation must be registered to Hystrix through data annotations.\nhttps://github.com/Netflix/Hystrix/wiki/How-it-Works#8-get-the-fallback\n. Agreed! The fallback method, if provided, could be executed whenever the main task is not accomplished, even without the usage of CircuitBreaker. Thanks for the feedback.\n. var result = Policy\n  .Handle<Whatever>(...)\n  .Fallback(() => throw new Exception2());\n  .ExecuteAndCapture(() => throw new Exception1())\nSo if I understand correctly, in this case, the captured PolicyResult should contain information about Exception2 as it is the final outcome of the policy execution. And I agree with this behaviour.\nBut what @SeanFarrow is saying is that we would lose  the original Exception1. One way or another, I also agree we need to be able to see and log the information of this fault.\nCould it be the fallback responsability to actually perform some action about this original fault it is trying to cover/replace? Just thinking out loud.\n. Agreed the idea will be uniform across policies such as  onRetry, onBreak, etc\n. About your last point: \n\nSeveral of our teams working on .NET projects have recommended Polly as being useful in building microservice-based systems. It encourages the fluent expression of transient exception-handling policies and the Circuit Breaker pattern, including policies such as Retry, Retry Forever and Wait and Retry. Similar libraries already exist in other languages (Hystrix for Java for example), and Polly is a welcome addition from the .NET community. \n\nTaken from ThoughWorks Technology Radar. There is clearly a lack of good offers in the .NET ecosystem for general resiliency framework and the spotlight is already on Polly as a Hystrix(Java) alternative so why not jump on the occasion =) \n. Hi @reisenberger. I am very happy with the recently updated roadmap. The reason I initially proposed the \"Fallback\" improvement and pushed for Hystrix-like features in March was because we are currently assembling our project templates/frameworks to build microservices inside large distributed, scalable apps for our finance business and we are using Polly in it.\nPriority for us would be to add Timeout, Bulkheads and Fallbacks to policies, and chaining them in a pipeline. We are currently experimenting some implementation ideas proposed in this tool: https://github.com/hudl/Mjolnir .\nWe might have a programmer or 2 available during the summer if you come up with specific up-for-grabs. Cheers.\n. > a Policy is not coupled to the code it can run.\nThis second element in your table is definitely a key difference that should stay going forward!\n. > Other cache providers you would like to see supported? \n@reisenberger , Gemfire (based on an apache project I think) could be nice. Maybe some gals from Steeltoe/Cloudfoundry could chime in? I am considering using that technology for distributed caching.. @SeanFarrow Hi Sean, excuse me for the delay.\n\n\nMain website: https://pivotal.io/en/big-data/pivotal-gemfire\n\n\nDocumentation: http://gemfire.docs.pivotal.io/\n\n\nC# Client API documentation: http://gemfire.docs.pivotal.io/docs-gemfire/gemfire_nativeclient/dotnet-caching-api/gemfire-csharp-dotnet-api.html\n\n\nC# Client API code example: http://gemfire.docs.pivotal.io/docs-gemfire/gemfire_nativeclient/programming-examples/csharp-example.html. I agree with the explanation to rename the policy. But just thinking out loud here, Isolation is quite a large term isn't it? What about simply Bulkhead? It fits well with Circuit Breaker and such.\n. \n\n",
    "SeanFarrow": "How would this work in the ExecuteAndCapture cases?\nAlso, I assume the Or allows the user to specify that the fallback action should only execute if the TResult is not the expected one passed in? If yes, I'm hoping this could be a Func.\n. It does make sense, however, it would be nice to know if the governed func failed with ExecuteAndCapture and with what exception.\n. Maybe, where the func being executed provides a result, we could do something similar to what ExecuteAndCapture already does and have a FallbackResult, this could then contain an exception, or an Exceptions property detailing the faults, in order that led to the fallback being executed.\n. 3 sounds good and makes the most sense!\n. That makes sense, do we want to give people the ability to add steps at any point in the pipeline? If yes, does a policy have an id?\n. What custom policies do you envisage adding?\n. Maybe we should integrate with other systems, Quartz.net for example.\n. That makes sense.\n. Could we not make the changes and then work out how we extract an interface at a later date?\n. 4.0.\nCheers\nSean.\nFrom: Joel Hulen [mailto:notifications@github.com]\nSent: 09 June 2016 19:19\nTo: App-vNext/Polly Polly@noreply.github.com\nCc: Sean Farrow sean.farrow@seanfarrow.co.uk; Author author@noreply.github.com\nSubject: Re: [App-vNext/Polly] Using ExecuteAndCaptureAsync with continueWith (#121)\nWhich version of .NET are you using, specifically? There's a huge difference between version 4.0 and 4.5/6\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/App-vNext/Polly/issues/121#issuecomment-224981855, or mute the threadhttps://github.com/notifications/unsubscribe/ABY1fv9H18AguWtKRQ85qoXQOxvBhscsks5qKFkAgaJpZM4IyQG1.\n. I[\u2018m trying ot use the HttpClient.GetAsync(url) using poly, then call a continuation with the result with is a HttpRequestMessage.\nFrom: reisenberger [mailto:notifications@github.com]\nSent: 09 June 2016 19:30\nTo: App-vNext/Polly Polly@noreply.github.com\nCc: Sean Farrow sean.farrow@seanfarrow.co.uk; Mention mention@noreply.github.com\nSubject: Re: [App-vNext/Polly] Using ExecuteAndCaptureAsync with continueWith (#121)\nHi @SeanFarrowhttps://github.com/SeanFarrow\nThis linkhttps://msdn.microsoft.com/en-us/library/dd321405(v=vs.100).aspx suggests Task.ContinueWith(...) is available in .NET4.0. You should be able to do something like:\nTask task = httpClient.GetAsync(url).ContinueWith(t => { /* some continuation code */ });\nHow are you looking to slot this together with Polly? What's the overall goal? Or, do you have some code draft that's not working/compiling, to help us see what you are looking to achieve?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://github.com/App-vNext/Polly/issues/121#issuecomment-224984914, or mute the threadhttps://github.com/notifications/unsubscribe/ABY1ftaRzY-PoiCkm2plomohrPSjp6zBks5qKFuQgaJpZM4IyQG1.\n. Hi,\nOk, I\u2019ve now got this working, so this can be closed.\nIt turns out that ExecuteAsync works really well for my purposes.\nCheers\nSean.\nFrom: reisenberger [mailto:notifications@github.com]\nSent: 09 June 2016 21:04\nTo: App-vNext/Polly Polly@noreply.github.com\nCc: Sean Farrow sean.farrow@seanfarrow.co.uk; Mention mention@noreply.github.com\nSubject: Re: [App-vNext/Polly] Using ExecuteAndCaptureAsync with continueWith (#121)\n@SeanFarrowhttps://github.com/SeanFarrow\nBoth .ExecuteAndCaptureAsync(...) and .ContinueWith(...) perform a similar function: both capture any exception thrown by an earlier-executed task into a result object which can be queried. So, there is possibly little benefit in using .ExecuteAndCaptureAsync(...) and .ContinueWith(...) combined. I constructed code to do it (happy to post), but it's unnecessarily double-layered for what it achieves.\nTo answer this another way, re your q:\ntrying to use the HttpClient.GetAsync(url) using polly,\nthen call a continuation with the result with is a HttpRequestMessage\n... this will not work directly, because the return type of ExecuteAndCaptureAsync is a PolicyResult not an HttpResponseMessage.\nTo achieve a task-continuation where its TResult generic type is an HttpResponseMessage, I would suggest using the straightforward .ExecuteAsync(...) method with .ContinueWith(...), not .ExecuteAndCaptureAsync(...). Something (in outline) like:\nPolicy retryPolicy = Policy.Handle().RetryAsync(3);\nstring url = \"some url\";\nusing (HttpClient httpClient = new HttpClient())\n{\n```\n    HttpResponseMessage response = await retryPolicy.ExecuteAsync(() => httpClient.GetAsync(url))\n        .ContinueWith(t => !t.IsFaulted ? t.Result : null)\n\n// Do other stuff with response\n\n```\n}\nThis is not intended to be a finished example, just to address your question of combining .ExecuteAndCapureAsync(...) with a task-continuation. A more refined example might do something with response.IsSuccessStatusCode or response.EnsureSuccessStatusCode(), depending what you're trying to achieve.\nHope this helps!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://github.com/App-vNext/Polly/issues/121#issuecomment-225010028, or mute the threadhttps://github.com/notifications/unsubscribe/ABY1fns5aNdDvyEcwLBccF_k5AByW8I9ks5qKHHDgaJpZM4IyQG1.\n. Hi,\nJust read the roadmap, the piping feature, cache feature and fall back policy are definitely of interest.\nI\u2019m happy and have some time to help develop these. I\u2019m currently writing a system that must be completely resilient so poly will form the core of this.\nCheers\nSean.\n. Hi,\nI can share what I\u2019m doing provate with an NDA if that helps.\nPlease contact me privately to discuss.\nCheers\nSean.\n. Are the ExecuteAndCapture variants going to be supported?\n. I'm happy to work on this, as we will need this for a project I'm working on.\n. Ok, I will. I\u2019m able to start working on this at the end of the month, I\u2019ve got a major project to finish first!\nWhat caches do we want, I\u2019m thinking, Redis/Memcached, and the .net memory cache as well as maybe a disc based cache, with the memory cache being the default. Any other caches/thoughts?\n. Definitely separate NuGet packages. That makes more sense in terms of dependencies, as each cache is likely to depend on other NuGet packages. Also, they can then be updated out of band of the main poly package assuming of course that the interface doesn\u2019t change!\nI\u2019m also thinking about a Poly.Cache.Core package containing the interface and the memory cache, as per my understanding, the memory cache is baked in to the .net framework\u2014correct me if I\u2019m wrong!\nIn terms of other caches we may want to support, maybe azure cache/amazon elastic cache, I need to check whether the latter has an api specifically, or whether it\u2019s just memcached compatible.\n. Ok, fair point, we\u2019ll go with that then!\n. What version of .net are we supporting? I notice that poly supports .net 3.5, but the memory cache is 4.0+.\nDo people see this as an issue? if so, what should we do for caching in .net 3.5?\n. Ok, cool, can you assign me to the cache policy then?\n. Ok, thanks!\n. Given we're supporting async variants of execute, should we have an async cache provider as well?\nAlso, if the cache doesn't support synchronous functionality, what should our default position be?\n. Ok, thinking out loud:\nIn my mind the AsyncCachePolicy should return a Task and Task for get/put methods respectively.\nAgree with 2, 3 and 4.\nI haven\u2019t checked specifics as yet, but generally anything cloud based will offer async and may offer sync, but they are moving towards the former only fairly rapidly.\nAlso, whilst I think about it, how do we want to handle the conversion from the cache to the TResult type?\nSometimes it may not be as straightforward as doing new T, should we offer the capability to define a delegate/lambda, or a conversion interface?\nI\u2019ve got a situation for example where I\u2019m storing a base64-encoded compressed file (zip in this case), so I can\u2019t just do new ZipArchive, or the equivalent, it needs an extra processing step!\nAlso, this may be valid, if you are storing the content of a web response a an array of bytes.\nThoughts\u2026?\n. I agree with you re scoping.\nIt may be that certain keys are compressed/others are serialized in different ways, so we may not be able to use a base class here, we could put an ICacheOutputConverter interface as part of the get/put calls, defaulting to null. If the converter is null we just use the default which does a new T. That way it\u2019s up to the user to decide/implement converters. We could provide some converters out of the box, such as serializing to/from JSon. If no converter is passed to put, we just use the caches native put call.\nFinally, Bear in mind that converting a value might not be straightforward, take the case where you have cached some compressed data, to decompress this data might require more than just calling a class constructor, you may need to read from a memory stream for example.\nThoughts\u2026?\n. Hadn\u2019t thought of that!\nOK, how about having a SetCacheOutputConverter on the cache interface?\n. Possibly, yes, but what if, I want a different converter per type?\nWe will need to support passing in an Ienumerable of converters.\n. Hi,\nThat makes sense, I had visions of people being able to supply the cache to wrap the converter with at runtime.\nWith your proposal, wouldn\u2019t we need converters for each cache type?\n. I think if we use a non-generic cache interface, this would make the converters easier. That way, people could have a converter if they want, What I\u2019m thinking is that a converter would know what type it converts to, and has a CanHandle message.\n. Yep, that\u2019s what I was thinking.\nPer your example a day or so ago if the cache policy was wrapped by a converter, we could have only one converter per cache policy? Correct me if I\u2019m wrong?\nThat\u2019s the limitation I\u2019m trying to avoid as I see myself and others storing items needing more than one conversion strategy in the same cache.\n. Let me see what you have first, snowed under work wise as you are, plus I\u2019m disappearing for a month for another job!\n. @Reisenberger,\nThis looks good.\nShould we move this in to the v5-alpha branch, or a branch off it? I notice not all the tests are there, that are in the v5 branch.\nWhat caches do people want to start with?\nCheers\nSean.\n. Hi,\nAll tests were there.\nHow do we go about testing cache providers? I suppose we could use something like Packer to build boxes, but we\u2019d need a specific category of tests as these might be slower and take a while.\nArchitecture seems fine, I\u2019m not in favour of keeping things in the core polly package, as some people just might not want any caching. A package such as Polly.Caching.Util probably seems more appropriate?\nProbably more later\u2026\n. @reisenberger,\nwith regards to 1, I still think a generic interface would be good, the only concern is as you say what this does to policy wrap, could we not have a wrapper type, or do something like outcome.net does?\nWould it be better to have different types for input/output mapping from a cache, or at least abstract classes that implement the same interface?\n. how do you see the generic types being used? Does this mean will be duplicating code?\n. Possibly, when are you available, happy to be led by your time frames.\nCheers\n. @Reisenberger,\nThanks, I\u2019ll start working on this, once the current backlog has cleared.\nCheers\nSean.\n. Hi,\nCan you give us a pointer to the source code and I\u2019ll take a look.\nCheers\nSean.\nFrom: mfjerome [mailto:notifications@github.com]\nSent: Wednesday, December 07, 2016 19:42\nTo: App-vNext/Polly Polly@noreply.github.com\nCc: Sean Farrow sean.farrow@seanfarrow.co.uk; Mention mention@noreply.github.com\nSubject: Re: [App-vNext/Polly] PROPOSAL: Cache policy (#136)\nOther cache providers you would like to see supported?\n@reisenbergerhttps://github.com/reisenberger , Gemfire (based on an apache project I think) could be nice. Maybe some gals from Steeltoe/Cloudfoundry could chime in? I am considering using that technology for distributed caching.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://github.com/App-vNext/Polly/issues/136#issuecomment-265551251, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ABY1flvH4aO11NqDuhpxl1yFcX2r8A6lks5rFwwMgaJpZM4JJmSo.\n. Hi,\nAll this is useful, but could you point me to the source and client source on GitHub?\nCheers\nSean.\nFrom: mfjerome [mailto:notifications@github.com]\nSent: Wednesday, December 14, 2016 15:46\nTo: App-vNext/Polly Polly@noreply.github.com\nCc: Sean Farrow sean.farrow@seanfarrow.co.uk; Mention mention@noreply.github.com\nSubject: Re: [App-vNext/Polly] PROPOSAL: Cache policy (#136)\n@SeanFarrowhttps://github.com/SeanFarrow Hi Sean, excuse me for the delay.\n\u00b7         Main website: https://pivotal.io/en/big-data/pivotal-gemfire\n\u00b7         Documentation: http://gemfire.docs.pivotal.io/\n\u00b7         C# Client API documentation: http://gemfire.docs.pivotal.io/docs-gemfire/gemfire_nativeclient/dotnet-caching-api/gemfire-csharp-dotnet-api.html\n\u00b7         C# Client API code example: http://gemfire.docs.pivotal.io/docs-gemfire/gemfire_nativeclient/programming-examples/csharp-example.html\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://github.com/App-vNext/Polly/issues/136#issuecomment-267068410, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ABY1fg999w29AIzThA7Q-QPSOMa5E8jtks5rIA8ugaJpZM4JJmSo.\n. @perfectsquirclehttps://github.com/perfectsquircle\nI\u2019m also like @reisenberger happy to help, although my time is limited currently.\nIf you are more interested in local caches I\u2019m happy to write the cloud-based ones. Let us know how you wish to help and we\u2019ll give you any support that is needed.\n. Hi Joe,\nWhat parts of caching are you specifically interested in?\nKind regards\nSean.. Don\u2019t worry about the delay, what cache were you looking to use? Do you want sync or async?\n. Hi,\nWhat specific cache(s) are you looking to use?. All,\nI've just been looking at the memory cache, we can't provide an async api, as one does not exist. Does anyone see a problem with this?\n. Any idea who is working on this/when they will be starting?\n. Hi,\nI am waiting for the ExecutionKey, it\u2019s not critical as yet as I\u2019m starting work on the cache implementations, but may be within a week or so, depending on other things!\nCheers\n. @reisenberger ,\nThat all makes sense. Having looked at the specs, I notice you are testing the IReadOnlyPolicyRegistry using integration-style tests. Should we test the IEnumerable> using mocks?\nEssentially, I\u2019d like to test that the  internal dictionaries GetEnumerator method is called.\nWe can then have a test that check that the collection initializer functionality is working as you suggest.\n. Ok, I\u2019ll sort this in the next day or so.\nWhat is the next planned version of Polly?. Ok, I\u2019ll work on this tomorrow.. @Reisenberger,\nWith the current design of IReadOnlyPolicyRegistry, we can't implement IEnumerable> as the T of IEnumerable is an out parameter and we are using TKey as an in.\nWould it make sense to restrict the IReadOnlyPolicyRegistry to use a string. Is there any reason why someone would use another type as the key?\n. I realise this is a breaking change, so would have to wait until V7.\n. @ Reisenberger\nHow early is \u201cearly January\u201d?\nIf we drop the out requirement, then this should work, we don\u2019t need to restrict to string.\nCheers\nSean.. Hi Dylan,\nCan you let me know when this has been murged.\nI\u2019ll update my fork and work on this early next week.\nIs there a list as to what has changed for V7?\nCheers\nSean.. Hi Dylan,\nOK, I'm doing this tomorrow (Monday).\nGiven that I want to check using Moq that the enumerator has been called, I'm adding a constructor to the PolicyRegistry class that takes an IDictionary, if this is null, we assign the concurrent dictionary as per now. Do you want this tested (it would have to use reflection to gain access to a private field), which is why I'm asking.\nAlso, whilst looking at this, I think you have duplicated tests in the policy registry, but I'll raise a separate issue/pr for that later.\nCheers\nSean.\n. @reisenberger, \nAs you will have noticed, I've submitted a PR, feel free to review/change where needed.\nI'll have a look at the tests later this week to see what can be cleaned up.\nAlso, should we be using C# 6/7 features all over the codebase where it makes sense, given we are using vs2017 as a minimum IDE, this would make sense\nI'll raise an issue to cover both as it's work that could be done at the same time, it may not make it in to V7 though, as I may be starting a new job in the new year.\n. @ Reisenberger,\nThe changes you made to the PR seem reasonable, so I\u2019m happy to merge.\nRegarding C# 6/7, this won\u2019t happen this week, but will happen sporadically over the next little while.\nI\u2019m not planning on using local functions, due to the work on issue #271. I agree, there could be allocation wins there, but I\u2019d probably want to do some performance profiling to see whether it makes a real difference.\n. @ moerwald\nNot at this stage, no.\nWe are not using local functions until the issue (#271) mentioned in #557 is addressed, feel free to use expression-bodied functions/other C#6/7 features though.. I don\u2019t know whether this means you are still up for helping, but if so, when you submit a change to this PR, could you please indicate the affected areas/policies/what has changed as this makes it easier to manage.\nCheers\nSean.. Should we use the existing Pr?. @ Reisenberger,\nThat\u2019s nice and a PR regarding caching I didn\u2019t even know about, but is really useful.\nHave you got any objections to updating the required C# language version to v7.3? If not, I\u2019ll do that tomorrow/this weekend and submit a Pr.\nSome changes might not make the initial v7 branch as I\u2019m doing work with other projects as well, so it\u2019s a question of low-hanging fruit.\nDefinitely happy to sort the cache providers/serializers out once all the other PR\u2019s are merged.\n. I\u2019ll sort a separate PR out tonight/tomorrow which will prove things out.. I\u2019ll review this later/tomorrow.\nDid you add a readonly registry property to the IReadonlyRegistry tests, or was it already there?. @, moerwald\nOn first look this looks good, however could you remove the readOnly registry property and just reference the private variable, it is readonly and only created in the constructor, so the property is redundant and not needed.\nFrom: moerwald notifications@github.com\nSent: 23 January 2019 06:43\nTo: App-vNext/Polly Polly@noreply.github.com\nCc: Sean Farrow sean.farrow@seanfarrow.co.uk; Mention mention@noreply.github.com\nSubject: Re: [App-vNext/Polly] Removed useless using statements. Now using expression-bodied members\u2026 (#564)\n@reisenbergerhttps://github.com/reisenberger thanks for the guidance. I've changed the PR base branch to v700.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://github.com/App-vNext/Polly/pull/564#issuecomment-456688875, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ABY1fukbb22p0x5cw5ugBHfJbu48fy9jks5vGARcgaJpZM4aMCh9.\n. @ Reisenberger,\nWhilst that all makes sense (and I agree with you), it might be worth adding some comments to the tests themselves to ensure this kind of thing doesn\u2019t happen again?\nI\u2019m happy to do this once @moerwaldhttps://github.com/moerwald has rebased and changed the commits.. ",
    "pj-moviestarplanet": "Have you thought about implementing some kind of metrics functionality similar to what Hystrix has. It would be very useful to be able to see Circuit Breaker metrics in for example Grafana.\nSo the idea would be to configure for example a statsd client and use it to send metrics such as call latency, number of succeful calls, number of failed calls etc.\n. ",
    "PaybackMan": "Please support .Net Standard Profile\n. ",
    "KBRETON1": "Please support async methods in .NET 4.0 by using the portable Microsoft.Bcl.Async nuget.\n. @Lumirris is there a hosted branch that I could clone to get up to speed on this thread?  I am new to this project and willing to help.   I am in general agreement with the topics above. \n. @Lumirris @reisenberger It looks good to me.  I have used Microsoft.Bcl.Async in other projects.  The System.IO was added by default.  I was able to remove it and didn't have an issue at compile time.   I'll be running this new code on an XP box with .NET 4.0 in the next several days.\n. @Lumirris @reisenberger, I forgot to add that the missing nuget.config file caused the packages to get downloaded to %appdata%\\nuget folder instead of the solution\\packages folder.  This caused my build to fail as the hint path referenced ..\\packages folder.    Is there something else I should have configured to prevent this or should the nuget.config file be added?\n. @reisenberger, I am using VS2015.\n. @reisenberger, I searched my entire hard drive and only have   entries in all of the nuget.config files.\nAdding the nuget.config file to the src folder solved my issue.  I'm not sure why it went to the Appdata folder, but my issue is resolved with the work around.   No worries. \nThanks for looking into it.\n. @reisenberger, @Lumirris : This worked great on XP sp3 running .Net 40\n. @reisenberger, what are the next steps and ultimately when this can be available in the nuget package?\nThanks,\nKevin\n. @joelhulen @Lumirris @reisenberger \nI believe there are some issues in the nuget.   Perhaps this comment should be part of #112\nFirst, There are references added for Polly.dll and Polly.Net40Async.dll which causes this error: The type 'Policy' exists in both 'Polly.Net40Async, Version=0.0.0.0, Culture=neutral, PublicKeyToken=null' and 'Polly, Version=4.2.2.0, Culture=neutral, PublicKeyToken=null'\nSecondly, when I manually remove Polly.dll in the csproj to avoid the duplication definition issue then the WaitAndRetryForeverAsync method is not found.  Using Object browser I can see the async methods are missing from Polly.Policy object.\nThird, and this might not be an issue.  Shouldn't this new nuget package also install these nugets as dependencies?  Microsoft.BCL, Microsoft.Bcl.Build, Microsoft.Bcl.Async.      \n. @joelhulen @Lumirris\nThank you for your help!   :-)   We are making some progress. \nThe first issue has been resolved.  The additional polly reference has been removed.   The other two issues still remain.  \n2nd issue:  The async functions are missing from the Polly.Net40Async.dll.   I have opened the dll in Object Explorer and the new async methods are missing.   This might be a build/compile time issue as the async dll is missing the new methods.\n3rd Issue: The bcl nugets are not installed as a dependency when install this nuget. In an unrelated BCL nuget package that my team created, we were able to set the BCL dependencies.   Installing our nuget forced the install of the other BCL nugets too.    Our nuget did not include any of the Microsoft.threading., System.Runtime., or System.Threading.* in the lib\\net40 folder of the nuget package.   \nI have a few screen shots but was not able to upload the png or zip files. :-(\n. If I drag and drop a png or zip file it says it is not supported.\u00a0 I'm trying this via email.\u00a0\u00a0\u00a0\u00a0 There is a screen shot of an unrelated nugget with the BCL dependencies that get installed.\u00a0\u00a0 I've also included a screen shot that shows the Async functions are missing from the dll.\nHope this works. :-) \nOn Saturday, June 4, 2016 5:21 PM, Joel Hulen <notifications@github.com> wrote:\n@KBRETON1 I really need to set up a dev environment to mimic yours...As far as the BCL NuGets, you'll see the dependency listed in the .nuspec file for the Net40Async package as . Is this not the correct version?If you drag & drop the zip file to the comment box on this page, does it not upload the file?\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. bclscreenshots.zip\nTrying IE now.\nScreen shots show missing Async functions in object explorer.\nAnd an unrelated nuget package that has the BCL dependencies but doesn't include the actual dlls.\n. @joelhulen  No, this is just a standard console application targeting .NET 4 platform.  Here's a zip of the project that has Polly reference 4.2.3 version from local nuget.    \nYou should notice: The packages.config file does not have any references to Microsoft.BCl.* nuget packages. \nConsoleApplication2.zip\nThe source code won't compile because the polly dll is missing the async functions.\n. @joelhulen @reisenberger @Lumirris \nI was able to compile and run with this nugget package.    :-)\nIt is still including the Microsoft.bcl assemblies directly in the lib folder.  I think it should have a dependency on those nuget packages instead of including the assemblies directly.   What are your thoughts?\n. @reisenberger @joelhulen @Lumirris \nThis worked great!! Thank you.\nThere is a Polly.NET40Async.dll.config file in the package.  The other polly nuget's have polly.xml.  Not sure if this is needed or not.\n. @joelhulen @reisenberger @Lumirris \nThis version worked great.  It built fine and ran successfully on my XP with .Net 4.0 image.   \nI need to do some research about Binding Redirects as I my experience has been in the app.config only and not at the assembly level.  Is the Polly.Net40Async.config supposed to be redistributed or is this how the bindredirects get created in the app.config?   The ConsoleApplication2 running on XP just has the app.config with the binding redirects.\nThank you.\n. I left out that I believe the app.config is modified with the redirects from the dependency on the microsoft.bcl.* nugets.  This might mean that the Polly.Net40Async.config shouldn't be included in the nuget. \n. ",
    "mattwoberts": "@SamuelEnglard \ud83d\udc4d \nI'm also interested in this. A lot of people are coming to dotnet core having used the snappily named \"The Transient Fault Handling Application Block for Windows Azure\" (topaz), and since that project seems pretty dead, it would be AWESOME if polly could take it's place, and provide a dotnet core version.\n. Hi, sorry I've been all over the place this week, had to abandon porting my app to core for now. I hope to get some time to play next week and if so I'll take a look at this!\n. ",
    "adamhathcock": "I'm interested in the pipeline idea.  Is there more details on a proposal that should be implemented or copied?\n. @reisenberger @SeanFarrow What I have is an implementation that does exactly what you say:  a pipeline that is basically a linked list and can be mutated for different calls.  I want to use Polly with it and if you're doing a pipeline thing anyway maybe I could just wholesale remove my implementation.\nI don't really like the look of the Nested Policies thing.  It looks like there could be a better way to hook things together but each policy remain atomic?  Just thinking out loud.  Maybe there would have to be a special collection PolicyList that is basically a linked list that allows insertion anywhere and can be executed which invokes the policies in order at anytime.\n. I haven't looked closely but I would also like the ability to add custom Policies into the pipeline and I don't think that functionality currently exists (appending a custom Policy). I guess that would basically mean just allowing a custom class that uses the same interface.  Maybe that's too big a refactor?\nIf that was on the table, I would envision policies looking a lot like ASP.NET Core middleware.  However the next step would be a method parameter instead of a constructor parameter.   Just thinking outloud again :)\n. Well, just anything.  Right now, one of things that my pipeline does is handle the custom OAuth token and refreshes it if necessary.  I guess I would think I could add something like that in.\nI do note that a lot of the exception handling and execute methods do take custom lambdas so you could do it there.  I just thought formalizing it into an official custom policy might be better.\n. I'm interested to see what you've got @reisenberger and where I can contribute :)\nI thinking have a base pipeline and having the current and proposed wider resilience features as links in that chain as well as allowing custom ones fitted in will make Polly much more like Hystrix.  \nI like the look of a PolicyRegistry from the linked Brighter project.  Also, having a task scheduler is part of the bulkhead pattern as well.  All things I'm interested in.\nMy only worry is expanding the scope for this project too wide :)\n. Polly should try to integrate rather than compete though I'm hoping that the use-cases envisioned don't require something \"enterprisey\" like Quartz.NET or even Paramore/Brighter (http://iancooper.github.io/Paramore/QuickStart.html).  The Brighter command processing I guess is what I kind of envision for Polly but still have a easy syntax for quick task handling.\nScaling up with things like task persistence (which seems to be the realm of Quartz and Paramore) is out of scope, imo.\n. I'm thinking Polly is \"lighter\" than a real job.  It facilitates and encapsulates common logic needed by lots of code paths.  Let me know if I'm way off base.\n. Thanks for the explanation.  Just trying to solidify what you (and me) see as the use case for Polly.\n. Thanks @reisenberger I was sure there was some way to do it without having to bring in some kind of new concept.\n. Any chance for a beta package to get pushed to nuget?\n. Any update on RTM support?\n. I'm fine with the beta status.  It sounds good to me.  I was just hoping to get the packages on nuget :)\nIt's a pain because if I use the import statement on Polly then not only does the current package using Polly have to have it, then all downstream packages do too.\n. Pinging @joelhulen too :)\n. Thanks.  I'm just trying to sort out the use cases for Polly vs other things and I remembered Rx but haven't heavily used it.\n. ",
    "Amerdrix": "Jumping in, pipelining is highest on the list for me. In fact, looking for the how to achieve this is what lead me to find the road map.\n. ",
    "gsogol": "How about reusing and integrating with hystrix dashboard via turbine (https://github.com/Netflix/Turbine/wiki)? This is useful because the hystrix community is huge. No point in recreating dashboards if integration exists via server sent events. \n. ",
    "drewburlingame": "\n... and if there are exceptions the Scope section (or detailed notes) in each policy proposal should call them out. For example:\nCache makes no sense for void returning \ud83d\ude09\n\nIdeally, we'd prefer a pass through vs throwing an exception.\nThe null pattern would be helpful in cases where all the methods for a service could use the same PolicyWrap.  If some of the methods were void and the Cache policy threw an exception for void methods, then we'd need to create two PolicyWraps.  The null pattern would allow us to use just one PolicyWrap.\nIf there are cases where we'd want to throw an exception, then hopefully it's a config option we can setup for the policy.  i.e. ignoreVoidMethods=true;\n. i like the idea of emitting events.  your examples of using the events for telemetry and logging were great examples of some of the benefits.\n. ",
    "lakario": "\nHave you thought about implementing some kind of metrics functionality similar to what Hystrix has. It would be very useful to be able to see Circuit Breaker metrics in for example Grafana.\n\nMy current project would benefit greatly from being able to export more detailed state from circuit breaker and other policies. Specific information like total number of calls, time stamps for each call (start and end), as well as aggregates by CircuitState.. Is there an argument for not simply adding extensions to RetrySyntax and RetryTResultSyntax?\ncsharp\npublic static RetryPolicy NoOp(this PolicyBuilder policyBuilder)\n{\n    return policyBuilder.Retry(0);\n}. PR #214 submitted.. Pull request submitted: #207 . NOTE: @reisenberger Need to re-work this according to #206. Update forthcoming.. Alright, fixed.. Weird, it looks like the tests didn't complete?\n[00:05:37] ----------------------------------------\n[00:05:37] Teardown\n[00:05:37] ----------------------------------------\n[00:05:37] Executing custom teardown action...\n[00:05:37] Finished running tasks.\n[00:05:37] Error: \n[00:05:37] xUnit.net (v2): Process returned an error (exit code 1).\n[00:05:37] \n[00:05:37] \n[00:05:37] Command executed with exception: \n[00:05:37] \nEOF. @reisenberger Updated per your input. I'm using a bool executed for non-TResult usages, and simply asserting the TResult for those with one.. @reisenberger All concerns have been addressed.. I believe that the .HandleInner<Exception>() syntax to a better option than implicit processing. As you mentioned, with it implicitly scanning inner exceptions it is a potentially breaking change for existing systems and I would be legitimately concerned about the performance impacts.\nIf implicit scanning were implemented, and the AggregateException wraps an AggregateException, what would be the expected behavior? By making the definition explicit, developers can extend their application's functionality as it suits them. \nIdeally, the .HandleInner<Exception>() signature could have an overload which allows it to scan an exception's inner exception to a finite depth.. Sure, can do. I'll make an update today.. Just noticed I forgot to update the name on this spec. It should not cancel! @reisenberger . ",
    "tomkerkhove": "+1 for the metrics. I'm currently at the \"I'm a moron\"-stage.\nI went through the same steps like you've mentioned but overlooked the actual issue.\nThanks for pointing it out to me, I really appreciate it!. ",
    "railarmenien": "CircuitBreaker and AdvancedCircuitBreaker have a locking nature due to the use of a Monitor in the TimedLock implementation. A implementation using the Interlocked class may avoid to lock the circuit state. What do you think about it ? Would it be relevant ?. Hi @reisenberger. \nI would need either to apply a consecutive success count check or a sampling check before transitionning back to Closed state.\nThe real world scenario is a service hosted in a farm behind a load balancer. Once one node is down the load will be processed by the remaining ones, increasing the response time and leading sometimes to timeout. In this scenario i would have to have fine grained control over the behavior of the CircuitBreaker not necessarily applying the governance strategy of the Closed to Open transition which is the behavior i will get if the first call of the HalfOpen results to a timeout.\nRegards\n. @reisenberger let's assume the circuit broke before a node fall indeed due to a load close to maximum capacity. Then, before opening gates to consumers (i.e passing from HalfOpen to Closed state), i would like to ensure the fallen node had enough time to recover not to break again immediately. So to measure the parameter \"the fallen had enough time to recover\" i would like to be able to apply a policy/strategy here (more or less strict, that's to be defined). \nMy thinking is that we should be able to setup a primary threshold leading to the transition from Closed to Open state and also a secondary threshold leading to the transition from HalfOpen to Closed. This pattern is described here http://blog.octo.com/circuit-breaker-un-pattern-pour-fiabiliser-vos-systemes-distribues-ou-microservices-partie-2/ (in french I apologize) and brings to light the idea\nof allowing a few requests to try to reach backend instead of only one when in HalfOpenstate.. ",
    "ankitbko": "@reisenberger \nThere may be another approach but I am not sure about this. Hystrix seems to do it little differently (need to check in detail). It extensively uses Reactive for both circuit breaking and metrics implementation. What I saw was that events are written into a thread-local Rx stream. From there it is then aggregated into command-specific stream. The entire circuit breaker logic(bucketing and aggregating) is done through Rx streams (by using window). Since Rx streams are thread safe, this may allow us to circumvent manual locking.\nBenchmarking first should allow us to compare the results and also check if introducing addional complexity makes sense or not. \nPS: I am not sure about this. I was just glancing over Hystrix code quite some time ago. I am not also very familiar with Rx.. @reisenberger No need to apologies. Its been great working with you. Thanks for such detailed discussion on all topic. And excellent spot that we missed Policy<TResult>.\nI did not fully understand what you mentioned here of PolicyRegistry<TResult> (maybe due to lack of background on Policy vs Policy<TResult>). From what I understand, IPolicyRegistry<Key, Policy> provides a mechanism of storing (any) policies (anywhere). The default implementation stores it in-memory (which is fine).\nAre you suggesting to create another class PolicyRegistry<TResult> which can store Policy<TResult>? But then I will have two registry, one for Policy and another for Policy<TResult> (feels weird). \nBut then what happens if I have Policy<int> and Policy<string>? Do I now have PolicyRegistry<int> and PolicyRegistry<string> to store individual type of policy? (may be I am missing something here)\nJust thinking out loud, what if we have another kind of Policy tomorrow, say Policy<TIn, TOut> (highly unlikely) so we will create another registry?\nOk so the requirement is that to register Policy<TResult> also, which is currently not possible due where Policy: Polly.Policy  generic type constraint . Let's suppose we remove the constraint. Removing it effectively makes it a generic dictionary IPolicyRegistry<Key, Value>, allowing user to store anything.\nThen the next challenge is that concrete implementation also depends upon Policy.\ncsharp\npublic class DefaultPolicyRegistry : IPolicyRegistry<string, Policy>\nHow about we create an empty interface IPolicy, derive both Policy and Policy<TResult> from it, and then implement DefaultPolicyRegistry : IPolicyRegistry<string, IPolicy> and re-introduce the where type constraint with IPolicy.\nThis should in general allow me to use same registry to store both Policy and Policy<TResult>. After retrieving, the user can then typecast it to whatever they want. (We can go a step further and change TryGetValue(string key, out Policy value) to TryGetValue<TPolicy>(string key, out TPolicy value) and typecast for them).\nFor the user, registry just stores policy(can be anywhere) and gives ability to retrieve them based on Key. Doesn't it make more sense that we have one registry which can store all kind of policies, and if I have the Key I can get whatever I stored.\nApologies if I misunderstood you and you meant something different (I had a long, tiring day).\nPS: I did not create a new PR instead I just switched the target branch in this pull request to v5.0.7 (so the discussions are not split in multiple places). I hope it works for you.. @reisenberger Very inline with my thoughts. Next steps could very well be populating the relevant interfaces.\nWe have a method TryGetValue in the registry. How about having a TryGetValue<TResult> extension method as the helper method? It would typecast and return the Policy.. @reisenberger Sorry for delay. This is excellent. Interfaces looks amazing. Couple of thoughts on the Interface implementation of registry - \n\n\nThere are two ways to add to registry Add<TPolicy>(string key, TPolicy policy) where TPolicy : IsPolicy and Set<TPolicy>(string key, TPolicy policy) where TPolicy : IsPolicy. Any differences between two or can we remove Set and just keep Add (or vice versa)?\n\n\nIf using Interfaces, is there any need of making Add method generic? Alternative would be to just have Add(string key, IsPolicy policy).\n\n\nSince now we have interface, does it make sense to have dictionary value of type object in IDictionary<string, object> or should we make it IsPolicy like IDictionary<string, IsPolicy>?\n\n\nWithPolicyKey(String policyKey) method in ISyncPolicy has returns type of Policy (Line 22). Any particular reason of having reference of derived class in interface? (Similar for other sibling interfaces)\n\n\nI am leaning more towards interfaces side. It leaves registry class clean (rather than having different get set for Policy and Policy). What do you think?\nAs for this[key], I don't see any benefit of having it (or not having it) as long as it is well documented.\nBut if we change IDictionary to store type IsPolicy, it may be useful if we add methods to IsPolicy rather than having it empty. Do you think it is possible to move common methods from ISyncPolicy and IAsyncSyncPolicy (and their generic counterpart) to IsPolicy?\nIf we are able to move common methods to IsPolicy (say Execute), people can use this[key] without having to explicitly typecast it. Does it make sense?. Completely missed this one out. Fixed.. Done. Didn't knew about this. I also tend to keep things consistent and follow the practice of the project. Will keep this in mind in my future contributions. \ud83d\ude01 . Wouldn't make any difference in behavior as I was re-initializing the variables but I see your point. I actually had done the same before but removed it later. \ud83d\ude1e Will make the changes.. Added. I also added more test cases to check ArgumentNullException is thrown when key is null while adding, removing and retrieving policy. Plus since the number of tests has now increased, I grouped them intro different region.. Fixed!. Ah.. Missed to delete it. Done now.. I have removed .ShouldNotThrow() which were redundant unless, as you mentioned, to make a contrast with elsewhere in the test (Should_not_be_able_to_add_Policy_with_duplicate_key_using_Add) and where the test explicitly says Should_not_throw (Should_not_throw_while_retrieving_when_key_does_not_exist_using_TryGetValue)\nPS: I hadn't worked with FluentAssertion much before. Thanks for helping me out with best practices. Really appreciate it.. Haha!!! Nice catch. To start with I had copied the comments from IDictionary since we had earlier inherited from it. Seems even IDictionary has a lot of mistakes. \ud83d\ude01 Fixed.\n\n. Done. Default value for reference types would have returned null. Making it explicit makes it more clear.. Done.. Removed.. Removed.. Corrected.. Done. Done.. ",
    "MihaMarkic": "Would be nice to have a .NET Standard 2.0 target in NuGet package as well. The reason is that NuGet would import a ton of referenced packages otherwise.. ",
    "mxa0079": "Duh! It always helps to get a second set of eyes. Good spot.\nAbstraction is now working as expected. Thanks for the quick reply!\nAnd yes, it would be nice to have that check in place.\n. ",
    "Lumirris": "Hi @reisenberger I wonder if a simple solution would be to create another Nuget package like Polly.Net40Async that would leverage existing *Async code and use another project file like src/Polly.Net45/Polly.Net40Async.csproj which included \n<DefineConstants>TRACE;DEBUG;SUPPORTS_ASYNC;SUPPORTS_READONLY_COLLECTION</DefineConstants>\nI haven't done something like this before, but if you think the concept is sound, I'll work on it. Does the idea of a separate Nuget package sounds good?\n. @reisenberger @joelhulen I'll get working on this tonight and share a link to my fork before doing a pull request to fix up anything you spot that needs work.\n. @reisenberger @joelhulen I forgot about the fact that Microsoft.Bcl.Async gives you some of the async features through TaskEx vs. Task. The consequences of this are that the following lines of code in Polly.Shared would need to be changed just for this Nuget package, which would put it at odds with the other projects using these files:\n-SystemClock.cs (here and here)\n -RetryPolicyStateAsync.cs\n -RetryPolicyStateWithCountAsync.cs\nMy thought is to replace calls to these async methods with calls to wrapping methods placed in a centralized location where the compiler constant switches are done, and utilize a new compiler constant, SUPPORTS_ASYNC_40 to distinguish between .NET 4.5 async support and .NET 4.0 async support through the Microsoft.Bcl.Async package and TaskEx.\nI'll post a link to my fork before making a PR for your review - please yank on the emergency brake if this seems like a bad path to take.\n. @reisenberger I'm in agreement with all of your recent suggestions pertaining to dealing with Task vs. TaskEx. I had started to go down that road already, and even experimented with using the compiler constant switch around the new using static syntax with Task and TaskEx, since the methods are named the same. Somehow that seems like an abuse, though, and brittle because it only works when the methods are named the same:\n``` c#\nif SUPPORTS_ASYNC\nusing System.Threading.Tasks;\nif SUPPORTS_ASYNC_NET40\nusing static System.Threading.Tasks.TaskEx;\nelse\nusing static System.Threading.Tasks.Task;\nendif\nendif\nnamespace Polly.Utilities\n{\n    /// \n    ///     Time-related delegates used to abstract away the async implementations\n    /// \n    public static class SystemClock\n    {\nif SUPPORTS_ASYNC\n    /// <summary>\n    ///     Allows the setting of a custom async Sleep implementation for testing.\n    ///     By default this will be a call to <see cref=\"M:Task.Delay\" /> \n    ///     or <see cref=\"M:TaskEx.Delay\" /> depending on the targeted framework.\n    /// </summary>\n    public static Func<TimeSpan, CancellationToken, Task> SleepAsync = Delay;\n\nendif\n}\n}\n```\n. @KBRETON1 I'm finishing up my work on this today; I'll push it up to my own fork, and have you and others review it before I do a pull request. Also, I see that my forked 'master' branch is now several commits behind the main 'master' branch. I'm new to open source contribution, and I'm not sure how I should proceed from here - I can't 'rebase' my forked master, since it too is public. Do I simply submit my pull request and @reisenberger would handle merge conflicts?\n. @reisenberger @joelhulen @KBRETON1 I've pushed the changes to my feature branch on my own fork. I'm not sure if you'll ultimately want the PR to come from my master branch or this feature branch, but I wanted to have the changes reviewed before the PR is made.\nComparing App-vNext Polly (master) to Lumirris Polly (async-dot-net-40)\n. @reisenberger It turned into an even smaller change than before rebasing my master to incorporate recent PRs. There was only the SystemClock that needed any change. I noticed that the Visual Studio version changed slightly in the solution file (I think I've applied the most recent VS2015 update), which could be deleted if needed. Also, I'm having a hard time getting unit tests to be discovered, so I couldn't run any of the xUnit tests, but I'm guessing the build server will.\n. OK - the solution file has been updated in this latest commit. Looking forward to hearing the results of local testing and what you'd like from me after that with regards to a PR.\n. @reisenberger Regarding the unused references, I got a chance to review this - I had used Resharper's 'Optimize References' on the project to detect what wasn't being used, but as you surmised, pulling in the Microsoft.Bcl.Async package brings a dependency on Microsoft.Bcl, which in turn brings in System.IO. \nHowever, it doesn't explain System.Net - When I use R# 'Remove Unused References', it didn't suggest removing that one, but yet it doesn't show any code dependent on it either. I decided not to remove it, believing that was the more conservative approach. Every time I try to get cute with stuff like that, I get burned.\nI also don't know where the 'System.Core' reference came from, and why only this project needs it, but there was lots of code the referenced it, all where LINQ statements were used.\nAnyway, thank you for taking over the PR from here. I'm looking forward to downloading the new package!\n. @kbreton1 re: references, do you have any inside into why System.Net is there, yet is unused and why Sydtem.Core is there (and used extensively) but is not in the other Polly projects?\n. To your third point, Polly.Net40Async does take a dependency on\nMicrosoft.Bcl.Async, but I thought that Microsoft.Bcl.Async's dependencies\n(Microsoft.Bcl.Build, and its dependency, Microsoft.BCL) would be\nautomatically pulled in, instead of having to list them explicitly.\nJeff\nOn Fri, Jun 3, 2016 at 9:39 AM, KBRETON1 notifications@github.com wrote:\n\n@joelhulen https://github.com/joelhulen @Lumirris\nhttps://github.com/Lumirris @reisenberger\nhttps://github.com/reisenberger\nI believe there are some issues in the nuget. Perhaps this comment should\nbe part of #112 https://github.com/App-vNext/Polly/pull/112\nFirst, There are references added for Polly.dll and Polly.Net40Async.dll\nwhich causes this error: The type 'Policy' exists in both\n'Polly.Net40Async, Version=0.0.0.0, Culture=neutral, PublicKeyToken=null'\nand 'Polly, Version=4.2.2.0, Culture=neutral, PublicKeyToken=null'\nSecondly, when I manually remove Polly.dll in the csproj to avoid the\nduplication definition issue then the WaitAndRetryForeverAsync method is\nnot found. Using Object browser I can see the async methods are missing\nfrom Polly.Policy object.\nThird, and this might not be an issue. Shouldn't this new nuget package\nalso install these nugets as dependencies? Microsoft.BCL,\nMicrosoft.Bcl.Build, Microsoft.Bcl.Async.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/103#issuecomment-223581215,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AAZnHgouHxpknSC7vyLQV0msJ4vbeDdeks5qIC6kgaJpZM4IIjUd\n.\n. Ok, I'll take a look tonight! Thank you!\n\nJeff\nOn Fri, Jun 3, 2016 at 4:33 PM, Joel Hulen notifications@github.com wrote:\n\nTry that. If you want, you can extract those packages to your local drive,\nthen configure the NuGet Package Manager in VS to reference that folder as\na NuGet package source. Let me know if you need help setting that up.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/103#issuecomment-223687472,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AAZnHufrqwfFRFAagYSOOWhrGTnzmK-Cks5qII-xgaJpZM4IIjUd\n.\n. Not yet. Probably not till Monday - busy this weekend. I'll let you know, though. \n\nJeff\n\nOn Jun 4, 2016, at 16:49, Joel Hulen notifications@github.com wrote:\n@Lumirris Were you able to try it out? I want to update the NuGet packages ASAP. Thanks!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. \n",
    "BertLamb": "Thanks! Yes and no, what if I wanted to have a CircuitBreaker for IOExceptions but just a Retry on CommandExceptions?\n. Ah, nice, I like that Policy.Pipeline concept. Seems a bit clearer (to me) than the fluent style I was originally thinking for chaining policies and that you captured at the end there.  Thanks for your time and help!\n. ",
    "johnknoop": "@reisenberger Any progress on this? Such a pipeline functionality would be sweet.. @reisenberger Oh, great! I'll have a look at that. Thanks!. I think it would be nice to reduce coupling. An example:\nThis is how I set up a named HttpClient in .NET Core:\ncsharp\nservices.AddHttpClient(HttpClients.GeoCode)\n    .AddTransientHttpErrorPolicy(x => x.RetryAsync(3));\nI have to choose RetryAsync and not Retry because I happen to know that the part of my application that uses this HttpClient will call GetAsync. This to me is an unfortunate coupling that I would love to get rid of.. @reisenberger Great!. ",
    "StefDotmailer": "Hi, is this solved by PolicyWrap?\nI would like to get the same behaviour as:\n```\nvar retryBackOffOrNormal =\n    Policy.HandleResult(job => job == \"error\")\n          .OrResult(job => job.StartsWith(\"error\"))\n          .WaitAndRetry(2,\n                        (attempt, ctx, x) =>\n                        {\n                            if (ctx.Result == \"error\")\n                            {\n                                Console.WriteLine(\"backoff retry\");\n                                return TimeSpan.FromSeconds(Math.Pow(2, attempt)) +\n                                  TimeSpan.FromMilliseconds(jitterer.Next(0, 100));\n                            }\n                        Console.WriteLine(\"regular retry\");\n\n                        return TimeSpan.FromSeconds(2) +\n                               TimeSpan.FromMilliseconds(jitterer.Next(0, 100));\n                    });\n\n```\nso if the error is exactly \"error\", it will do exponential backoff; if the error is \"error, something unexpected happened\" it will do a regular retry.\nif I try and use Wrap, I get 9 retries with a combination of both the wait strategies:\n```\nvar retryBackOff =\n    Policy.HandleResult(job => job == \"error\")\n          .WaitAndRetry(3,\n                             attempt =>\n                             {\n                                 Console.WriteLine(\"backoff retry\");\n                                 return TimeSpan.FromSeconds(Math.Pow(2, attempt)) +\n                                   TimeSpan.FromMilliseconds(jitterer.Next(0, 100));\n                             });\nvar retryAllErrors =\n    Policy.HandleResult(job => job.StartsWith(\"error\"))\n          .WaitAndRetry(3,\n                             attempt =>\n                             {\n                                 Console.WriteLine(\"regular retry\");\n                                 return TimeSpan.FromSeconds(2) +\n                                   TimeSpan.FromMilliseconds(jitterer.Next(0, 100));\n                             });\nvar i = 0;\nretryBackOffRateLimit.Wrap(retryAllErrors)\n                     .Execute(() =>\n                     {\n                         Console.WriteLine($\"Attempt {++i}\");\n                         return \"error\";\n                     });\n```\nam I not using it right or Wrap is not suitable for this scenario?. Hi @reisenberger, thank you for the explanation.\nwould be nice if there was also a pipeline style handling, I may have a look at implementing it and send a PR at some point in the future if it is not planned already.. ",
    "Mittchel": "Hey @reisenberger thanks for the amazing in-depth comment. I really appreciate it and you gave me something to work on. \nYou are right about the exception getting lost when its thrown up to the caller. I just wanted to update my post, but you beat me to it.\nI'm currently doing a demo application with full stack resiliency including some amazing libraries like Polly.\nThe odd thing though is when I put a breakpoint on the events variable it actualy never hits. You sure this is also about the exception thats thrown on different thread?\n. @reisenberger Gotcha!\nProblem I'm facing is that I'm using Akavache with this. Akavache uses ReactiveUI, but I'm not really sure how to bubble up the Exception in a nice way. \n. ",
    "PhilipAnthonyMurray": "@reisenberger Thank you for the thorough explanation which makes sense based on the behaviour I see. I took some time this afternoon checking the source code and came to a similar conclusion.\nI am very happy to test any changes in this, the code is not due for production for some time yet so presents little actual risk. I am out of the country on business for most of next week but will happily test from the hotel. If there is anything else I can help with please let me know.\n. @reisenberger If I do something as below no compiler warnings are given.\nbookings = await Policy\n                .Handle<Refit.ApiException>()\n                .RetryAsync(2, async (ex, retry) =>\n                    {\n                        await RefreshApiAuthentication(retry);\n                    })\n                .ExecuteAsync(async () => await GetBookingsApiCall());\n. @reisenberger Nope the anonymous async lambda wrapped in a task does not give a warning in either VS2015 or Xamarin Studio.\n. @reisenberger  I will try to test your update tomorrow. Thanks for the quick turn around./\n. @reisenberger Sorry for the delay in getting back to you but my trip over to the states has wiped out my time. I will get back to you as soon as possible.\n. @reisenberger I'm definitely still interested in this and hope to progress this issue this week.\n. @reisenberger Sorry for not being able to respond on this, things have been very busy. I plan on getting this tested early next week and will respond when complete.\n. @reisenberger I have tested the fix and confirmed that it works. Really sorry for the delay in getting this tested and confirmed as working.\n. ",
    "SteveCote": "@dreisenberger: I committed the async changes to my branch.  I'll plan to do the specs during the week.\n. @reisenberger I think pushing this change is what's causing the tests to fail.  What do you think?\n. ",
    "jeroenwo": "Wow, that VM of yours works like a charm! I changed the asynchronous code to catch every Exception and built a try {} catch {} to trap the actual exception. It is indeed not an AggregateException, but a DocumentClientException (logical in hindsight)!\nThanks a lot @reisenberger for answering and your detailed explanation!\no/\\o (virtual high five) :smile: \nEnjoy your travelling!\n. ",
    "robertbaker": "Thanks, I'll try to implement this soon.\n. 4.2.2 is what I have now and it works.\n. Look at the commits, you will see a lot of nuspec changes to the async package.\n. Actually, I removed the nuget Async package and just added regular polly and still have async. Guess I was using the wrong one.\n. In the readme you can add that package is only needed for .net 4.0. if you\nare on 4.5+ there is no need for it. I was confused and thinking that\npackage is needed for asynx functionality\nOn Wed, Jun 15, 2016, 10:57 AM Joel Hulen notifications@github.com wrote:\n\nAh, yes. That makes sense. I was frantically looking through all of the\nchanges in order to see where we may have accidentally removed support for\nthat profile ;)\nI assume you installed the Polly.Net40Async\nhttps://www.nuget.org/packages/Polly.Net40Async/ package instead of the\nstandard Polly https://www.nuget.org/packages/Polly/ one?\nI wonder if there's a better way for us to communicate which one to use?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/124#issuecomment-226268070,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AA3YJUqVLhIdLXcsTC7dQIF3mMobu8U0ks5qMD0FgaJpZM4I2mvI\n.\n. \n",
    "christopherbahr": "The spec says the first step in evaluating a switch statement is \n\"The switch expression is evaluated and converted to the governing type.\"\nhttp://www.ecma-international.org/publications/files/ECMA-ST/Ecma-334.pdf page 232\nThat reads to me like it will store the outcome of the switch expression rather than recalculating it. (I've seen someone verify this by looking at the IL but the compiler is allowed to do whatever it wants as long as it follows the spec so I'm not sure we want to rely on that). \nThat said if you're worried about it I can just copy the value into a local variable and then switch based on that. \nLet me know how the performance testing goes. It was actually during performance/load testing something that depends on Polly that I came across this. It probably won't make much difference unless your tester is multi-threaded though, it's really the contention that slows you down.\n. Sorry to just drive-by PR you like that. I had all the best intentions of coming back with a more comprehensive solution but I never quite had the time to actually do it properly. I'll go ahead and close this. That new proposal looks great :+1:. ",
    "Finity": "No problem, thanks for the very quick fixes!\n. ",
    "ry8806": "hi, yeh, the packages work great for me (am using the \"unsigned\" one).\nI'm currently using Polly in a large .Net Core Web App (due to go-live at the end of the year) - as the back-end will be making json http calls to other endpoints - I'm using Polly to handle any failures and retry appropriately.\nI'm also using Polly in a \"private Universal App\"  - more specifically on a Raspberry Pi2 running Windows 10 IoT at home. This app makes polling http calls (about 8 per minute) and Polly (again) helps with retrying after exceptions (again due to go-live end of the year - hopefully).............\nGot a busy few months ahead of me :)\n. ",
    "BrianVallelunga": "I'd also appreciate a beta version on Nuget to ease testing, building. I'm porting an app to .NET Core 1.0 right now.\n. ",
    "devlead": "@reisenberger tested your fork and beta-netstandard10 with our Cake build scripts and haven't found any issues yet, perhaps you should have an MyGet feed for alpha releases? Allot easier to test when you can pull using nuget.\n. ",
    "moswald": "So until this makes it to nuget/myget, how does one reference a local version of this beta package? ~~I can't seem to figure it out.~~\nHere's how you can reference the PCL version for now. In your project.json, your \"frameworks\" property can look like this:\n\"frameworks\": {\n    \"netstandard1.5\": {\n      \"imports\": [ \"portable-net45+netcore45+wpa81+wp8\" ],\n      \"dependencies\": {\n        \"NETStandard.Library\": \"1.6.0\"\n      }\n    },\n    \"net46\": {}\n  }\nThe important part is the \"imports\" property.\n. ",
    "apobekiaris": "I started integrating Polly and rx and the problem I face is that I cannot control the time between retries. For example RX has a TestScheduler which makes it very easy to move the virtual time. But when Polly has to handle an exception I have to switch back my tests to awaits and the Default.Scheduler. Any suggestions on this?. a possible solution could be an overload that I could do something lie\nScheduler.Default.Sleep(TimeSpan.FromTicks(1000)\nand in the RX case I could use the TestScheduler instead of the default one. I posted with wrong account before but yes WOW for Polly what an amazing framework! I guess I have to wait a bit before testing your answer but many thanks in advance!. ",
    "orlandow": "Thanks for the quick reply.\n\nDo you have control over the code configuring the RetryPolicys?\n\nNo, we have a small \"commands\" library inspired by Hystrix's and wanted to add some \"retrying\", \"circuit breaking\" capabilities.\nWe learned about Polly, and your roadmap aligns with what we want from our library, but we have a lot of legacy code depending on our commands at the moment and also have some features like persistence, logging, monitoring.\nWe decided to use Polly as a dependency and instead of wrapping it just inject a Policy as a parameter.\nThe thing is: we have centralized logging and monitoring and a lot of services using commands to talk between them, we rely on the standards and can't let it to the users to remember hooking that code. We even considered having some sort of .MyRetry extension, but it's easy to miss and use the real one :wink:.\nI think we'll go with wrapping Polly for now.\nGreat library. Thanks.\n. (Sorry, I missed your other reply, went offline and my live.github.com connection died)\nHmm... interesting... that could work for retries... but it'd be much more work for the circuit breaker part... OnClose, OnOpen, OnHalfOpen...\nThanks!\n. ",
    "perfectsquircle": "Hello,\nI'm curious if you have a prediction of when this feature might land? It seems like there's been some promising work, but it's gone quiet recently. I have a strong interest in using the caching policy in combination with retry and circuit breaker for HTTP calls.\nI'd also be happy to contribute if you need any help.. @reisenberger \nThank you for the comprehensive update. Maybe I'll get my feet wet and try to implement the memory or disk ICacheProvider. I suppose it would be sufficient to target .NET Standard 1.0 for these plugins?. Hi @reisenberger,\nI haven't gotten around to working on this. Things got crazy at work. I might try take another crack at it again soon.. ",
    "JoeBrockhaus": "Hi @reisenberger \nIs there any chance you could setup a beta/alpha myget/vso feed based off the v5.1x-cache-rebase (if that's still the latest) branch?. @SeanFarrow Sorry for the super-delay on this feedback. \nI was looking to incorporate a combination of Retry with a CircuitBreaker to proactively serve from Cache before failing on new requests whose dependencies would likely fail, but for which cached data would suffice. . Would likely be async, though i'm not sure if would be a blocker either way. \nI have had to move onto other priorities in the meantime, unfortunately. \nI'll try to find some time to poke it in the next couple days. \ud83d\ude00  . ",
    "dweggemans": "Is there an ETA on the caching feature?. @reisenberger thanks for your response. I might be able to wait a little, or else I'll build a package locally. No problem. \nThe MemoryCache suits my needs perfectly. I'm just looking for a simple way to reduce some traffic by caching results locally. . ",
    "brunolauze": "I think we should provide a more dynamic way to provide timeout than just TimeSpan, just a Func would be good enough. The idea here is to enable Hystrix like pattern where Timeout is managed across micro-services calls in a budget manner. Of course, we don't want Polly to implement any of this logic, but to only provide a way to extend the timeout value. Also, adding configuration based policy would also required to think how to provide dynamic timeout value out of it.\n\nConfiguration syntax\nTimeoutPolicy timeoutPolicy = Policy.Timeout(TimeSpan timeout)\nTimeoutPolicy<TResult> timeoutPolicy = Policy<TResult>.Timeout(TimeSpan timeout);\nTimeoutPolicy timeoutPolicy = Policy.Timeout(Func<TimeSpan> timeout);\nTimeoutPolicy<TResult> timeoutPolicy = Policy<TResult>.Timeout(Func<TimeSpan> timeout);\n(and similar async forms)\n. @reisenberger  I would recommand not enforcing CancellationToken having overloads to keep everything as it is. We would wrap any non cooperative execution with cancel checks.\n(cancellationToken) => { cancellationToken.ThrowIfCancelled(); action(); cancellationToken.ThrowIfCancelled(); }\nWhile recommanding using full cooperation cancellation pattern while using Timeout or Wrap Policies.\nThe thinking behind this conclusion is that full cooperative cancellation might not be always possible, as upstream calls might not support it even if the middleware action handles it. Knowing that some calls might be spinning cpu cycles for nothing while not implementing it fully. That would be a tradeoff against legacy code.\nA suggestion also ready to deprecate it and phase it out later on if revisited. \nThanks for the comments\n. I added 3 commits as a tentative for Timeout Policy timeout-policy to ensure having impl, specs and cooperative cancellation separated. Thanks for the comments.\n. My readings about Semaphore and TaskScheduler brings me to this exact conclusion : http://stackoverflow.com/questions/23550470/limit-parallelism-of-an-async-method-and-not-block-a-thread-pool-thread\nWhile I did try with a QueuedTaskScheduler approch, I feel this is not the Api to accomplish proper throttling. But that's only my understanding. Please comments your thoughts on why TaskScheduler would be better.\nI have push an idea on how the ThrottlePolicy could be shaped at throttle-policy\nReview is appreciated. Thanks.\n. In fact,\nPolicy.Isolate() is in direct clash with\nvar policy = Policy.CircuitBreaker()\npolicy.Isolate()\ntherefore I bring a lot more confusion even if we work around the naming clash.\nOther suggestions might be better :\n.Bulkhead()\n.LimitConcurrency()\nLet's have a look at this branch with the name changed:\nhttps://github.com/brunolauze/Polly/tree/v5.0-alpha-isolate\nWhat do you think?\n. @reisenberger @mfjerome  I think it's a good candidate because it follows directly Policy as RetryPolicy and CircuitBreakerPolicy\n. Can we describe what are the difference between wording usage and call\n...for each usage of a policy.\n...for each call through a policy...\n. @reisenberger After having played with Polly and looking at the different proposals and our own requirements/desires, I wanted to push the way we envision to use Polly. I reworked all the code so it fits more the goal we are trying to achieve. The branch is located at https://github.com/brunolauze/Polly/tree/polly-reboot. \nAlmost all the applicable specs passes, and specs like ones in FallbackSpecs are best to show vision.\nHere's one typical envisioned policy the refactoring now makes possible:\nPolicy.Throttle(10)\n         .ThenTimeout(3000)\n         .Or<ArgumentException>()\n         .OrResult<int>((x) => x < 1)\n         .CircuitBreaker()\n         .Fallback<int>(() => 1000)\nWhich reads as follow:\nFallback to value 1000 in a Circuit Breaker fashion when the execution times out of 3 seconds, raises an ArgumentException or the result is less than 1 while ensuring a maximum concurrency level of 10.\nOf course it's far from perfect but I think it stir the course in the direction we would like to take internally.\nOur main goal here is to add two other component : Polly.Config and Polly.Web\nand to have a asp.net (4.5/core) Controller with this kind of action:\n[HttpGet]\n[Policy(\"StandardCircuitBreaker\")]\npublic IEnumerable Get()\n{\n}\nand have the ActionInvoker wrapped to Execute within the named policy present in the configuration.\nAs always, everyone love comments!\n. @reisenberger  we're happy to help because we find it useful for our corporate developement to invest some time in libs like this one. I totally understand your availability please don't worry. \n\n(a move from static configuration to chaining-on-instances, as briefly floated in #104 ?)\n\nThe current approch in polly-reboot branch was to have Non Exception Policy into static methods and have those Non Exception Policy have their .ThenXXX like .ThenTimeout() extension methods\nAnother aspect we liked is the introduction of .ThenHandle<> which is a kind of reset of the stack of Exception handling. We can then have Chain Cascade Type of Exception.\nThe opposite of .Or<> if you will\n```\n.Handle()\n.Fallback(x => 10)\n.ThenHandle()\n.Fallback(x => 0)\n```\nif my http backend (or sql/whatever) is down i want 0, if my product is just not found (ProductNotFoundException) then 10.\nFor the config part: \nI see something more generic but documented as a start I pushed this https://github.com/brunolauze/Polly.Config\nUsing System.Configuration with syntax like\n```\n\n\n\n\n\n\n\n```\nwhere Policy.Resolve(\"poilcy1\") would equals:\n```\nPolicy.Handle()\n.Retry(3)\n.Fallback(() => 50)\n```\nAnd then re-implementing the same but with Microsoft.Extensions.Configuration with a configuration looking like this:\n\"polly\": {\n    \"retry\": {\n      \"handle\": {\n        \"exceptionType\": \"System.Exception\"\n      },\n      \"retry\": {\n        \"retryCount\": 3\n      }\n    }\n  }\nI think you should continue looking and tell me if I can do anything. I pushed the changes of timeout policy in my according branch for the current implementation.\n. Wow! Metrics are on my watch too! I started to look at what would be required to have an Hystrix-like metrics reporting relying on Polly. You can check https://github.com/brunolauze/Polly.Metrics https://github.com/brunolauze/Polly.Config and https://github.com/brunolauze/Polly.Web.EventStream \nSince hystrix dashboard is a html/javascript only thing, we can plug it directly in an middleware along with an Rx Stream endpoint. It's just brainstorming code so don't be harsh on quality...\nMy findings are that the current implementation for calculating minimum throughtput use an internal Rolling Count for total and failures, the goal would be to offer something more global, optionally, to count everything. (e.g.: OnFallbackCompleted;OnFallbackFailed;OnFallbackRejected;OnShortCircuited;etc..)\n. ",
    "juancarrey": "I had a PolicyChain which actually implemented this Wrap very similarly, except that ExecuteAndCapture actually was done by the innermost policy, and returned backwards. (I am not sure which solution would be ideal - option at builder ?)\nThe chain implemented IPolicy, and any IPolicy could be chained afterwards (wrapped). The innermost PolicyChain had no next policy, so it just delegates to the IPolicy inside. (A policy-chain contained 1 or 2 policies, the current and the next one if any.)\nThe IPolicy was also implemented by a CombinedPolicy which \"merges\" an async policy with a sync policy, removing the runtime exceptions of using an async policy synchronouslly and a sync policy asynchronouslly. \nI would say this \"combine\" would be a great addition to Polly if you do this transparently:\n when calling .WaitAndRetry you actually create 2 policies and combine them: .WaitAndRetry + .WaitAndRetryAsync with the same parameters (so it forces the policies to be equally deffined). Same for the rest of policy creations.\nIPolicy extended from IAsyncPolicy and from ISyncPolicy, which made policies more clearly separated and avoid any miss-usage of them.\n. @reisenberger That makes sense to be the outermost\n. ",
    "RehanSaeed": "@reisenberger I see a POCO as a very low level concept that most people would not use. All config providers could be based on it, as well as the other cool features that you have just made me aware of (Fallback's seem like a very good idea and something I'm really interested in e.g. falling back from a cache to the database).\n. While the two issues talk about config, I feel they are talking about two different kinds of config. That issue is talking about using System.Configuration which should probably exist as a separate NuGet package. What I'm talking about is being able to create a policy based on a POCO with some very simple properties. This POCO can then be used to bind to a JSON config file. This POCO should probably live in the Polly core NuGet package.\n. ",
    "kbilsted": "Those links are really nice. Perhaps a short section on threadsafety should go into the readme along with those links.\n. done\n. ",
    "vknapp": "Thank you for your answer. I was aware of that, just asked for your opinion because you advised against it \n\nin a highly concurrent environment.\n\nHowever in my case I can handle this. Thanks for a very usefull tool!\n. ",
    "jiimaho": "Hi @reisenberger and thanks for your quick reply. I actually just found what I was looking for in Polly itself!\nSystemClock.Sleep allows me to mock the internal timer for Polly, which causes the sleeps to really not sleep.\nI closed the my issue as it's not relevant anymore.\n. @reisenberger I think it's good to let consumers of the Polly API be able to provide a time-provider. If this should be done through SystemClockor not i'm not sure, however in our scenario it's perfect for testability.\n. > (a) available now: Inject a TimeoutPolicy configured to TimeSpan.Zero\nThis doesn't work. It throws an ArgumentOutOfRange exception. Have we missunderstood @reisenberger ?\n\n(b) available following a small PR: Mock an injected policy to throw TimeoutRejectedException or to set up a PolicyResult denoting TimeoutRejectedException\n\nThis would be the best it seems, not sure if we can afford the time for PR now though.\nThanks a lot for all your help and fast response! Will see how we will solve this.. > True: I misread the boundary condition. We could change the boundary condition to permit TimeSpan.Zero, to support this Use Case. You could also (right now) likely use TimeSpan.FromTicks(1) with the same practical effect.\nYes we tried this, or something very similar. Seemed the effects were different depending on which machine executed it. (locally or through AppVeyor).\nAnyway - I created a pull request. It's very minor, and i'm not sure about the comments. Please have a look: https://github.com/App-vNext/Polly/pull/317. Great, thanks a bunch for all your help and rapid feedback @reisenberger . . Made changes to the comments and just pushed. ",
    "rog1039": "@reisenberger I agree with @jiimaho in that there should be a supported way to manipulate the passage of time. We'll try using SystemClock in our unit tests. \nA good example of a library which allows the user to modify the flow of time is the ReactiveExtensions project. They provide schedulers that can be used control the flow of time which makes testing various scenarios relating to time passage very easy, repeatable, and makes unit tests very quick (Can simulate minute/hours/days/etc of time passage instantly). \nSee here \nhttp://www.introtorx.com/Content/v1.0.10621.0/16_TestingRx.html#TestScheduler for more information.\nThanks!. ",
    "OmegaAphex": "B. Basically i want to immediately stop the retry policy as soon as a the windows service that it is currently running in stops. \n. Thanks for the information. Will let you know. \n. ",
    "ronnieoverby": "I looked at doing that first. It just makes my code messier than I like (mainly because I have to declare result variable outside of try{ }.\nMore on what I propose:\nNew property on PolicyResult called FinalExceptionDispatchInfo.\nExisting property getter PolicyResult.FinalException is reimplemented as return FinalExceptionDispatchInfo?.SourceException;\nNew method PolicyResult.ThrowUnhandledException is implemented as:\nc#\nif (configAttempt.ExceptionType == ExceptionType.Unhandled)\n    configAttempt.FinalExceptionDispatchInfo.Throw();\nI haven't looked at any Polly code yet, but I imagine this is a pretty simple change (except maybe for platforms that don't support ExceptionDispatchInfo, if any don't. I'd even be willing to take a stab at it, if you agree with what I'm proposing.\n. ",
    "dnfclas": "@reisenberger, Thanks for signing the contribution license agreement so quickly! Actual humans will now validate the agreement and then evaluate the PR.\nThanks, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @NRKirby, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    \n        This seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. Real humans will now evaluate your PR.\n    \nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @DixonDs, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @christopherbahr, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    \n        In order for us to evaluate and accept your PR, we ask that you sign a contribution license agreement. It's all electronic and will take just minutes. I promise there's no faxing. https://cla2.dotnetfoundation.org.\n    \nTTYL, DNFBOT;\n. Hi @lakario, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    \n        This seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. Real humans will now evaluate your PR.\n    \nTTYL, DNFBOT;\n. @lakario, Thanks for signing the contribution license agreement so quickly! Actual humans will now validate the agreement and then evaluate the PR.\nThanks, DNFBOT;. Hi @pomma89, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    \n        This seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. Real humans will now evaluate your PR.\n    \nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @lakario, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    \n        In order for us to evaluate and accept your PR, we ask that you sign a contribution license agreement. It's all electronic and will take just minutes. I promise there's no faxing. https://cla2.dotnetfoundation.org.\n    \nTTYL, DNFBOT;\n. @lakario, Thanks for signing the contribution license agreement so quickly! Actual humans will now validate the agreement and then evaluate the PR.\nThanks, DNFBOT;. Hi @lakario, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    \n        In order for us to evaluate and accept your PR, we ask that you sign a contribution license agreement. It's all electronic and will take just minutes. I promise there's no faxing. https://cla2.dotnetfoundation.org.\n    \nTTYL, DNFBOT;\n. @lakario, Thanks for signing the contribution license agreement so quickly! Actual humans will now validate the agreement and then evaluate the PR.\nThanks, DNFBOT;. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @ankitbko, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. Hi @reisenberger, I'm your friendly neighborhood .NET Foundation Pull Request Bot (You can call me DNFBOT). Thanks for your contribution!\n    You've already signed the contribution license agreement. Thanks!\nThe agreement was validated by .NET Foundation and real humans are currently evaluating your PR.\nTTYL, DNFBOT;\n. \n@SaroTasciyan,\nThanks for having already signed the Contribution License Agreement. Your agreement was validated by .NET Foundation. We will now review your pull request.\nThanks,\n.NET Foundation Pull Request Bot. \n@reisenberger,\nThanks for having already signed the Contribution License Agreement. Your agreement was validated by .NET Foundation. We will now review your pull request.\nThanks,\n.NET Foundation Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\n.NET Foundation Pull Request Bot. \n@reisenberger,\nThanks for having already signed the Contribution License Agreement. Your agreement was validated by .NET Foundation. We will now review your pull request.\nThanks,\n.NET Foundation Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\n.NET Foundation Pull Request Bot. \n@hambudi,\nThanks for your contribution.\nTo ensure that the project team has proper rights to use your work, please complete the Contribution License Agreement at https://cla2.dotnetfoundation.org.\nIt will cover your contributions to all .NET Foundation-managed open source projects.\nThanks,\n.NET Foundation Pull Request Bot. @hambudi, thanks for signing the contribution license agreement. We will now validate the agreement and then the pull request.\nThanks, .NET Foundation Pull Request Bot. \n@nestor-reyes,\nThanks for your contribution.\nTo ensure that the project team has proper rights to use your work, please complete the Contribution License Agreement at https://cla2.dotnetfoundation.org.\nIt will cover your contributions to all .NET Foundation-managed open source projects.\nThanks,\n.NET Foundation Pull Request Bot. \n@Kesmy,\nThanks for your contribution.\nTo ensure that the project team has proper rights to use your work, please complete the Contribution License Agreement at https://cla2.dotnetfoundation.org.\nIt will cover your contributions to all .NET Foundation-managed open source projects.\nThanks,\n.NET Foundation Pull Request Bot. @Kesmy, thanks for signing the contribution license agreement. We will now validate the agreement and then the pull request.\nThanks, .NET Foundation Pull Request Bot. \n@SeanFarrow,\nThanks for having already signed the Contribution License Agreement. Your agreement was validated by .NET Foundation. We will now review your pull request.\nThanks,\n.NET Foundation Pull Request Bot. \n@ExtRemo75,\nThanks for having already signed the Contribution License Agreement. Your agreement was validated by .NET Foundation. We will now review your pull request.\nThanks,\n.NET Foundation Pull Request Bot. \n@ExtRemo75,\nThanks for having already signed the Contribution License Agreement. Your agreement was validated by .NET Foundation. We will now review your pull request.\nThanks,\n.NET Foundation Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\n.NET Foundation Pull Request Bot. \n@jiimaho,\nThanks for your contribution.\nTo ensure that the project team has proper rights to use your work, please complete the Contribution License Agreement at https://cla2.dotnetfoundation.org.\nIt will cover your contributions to all .NET Foundation-managed open source projects.\nThanks,\n.NET Foundation Pull Request Bot. \nThis seems like a small (but important) contribution, so no Contribution License Agreement is required at this point. We will now review your pull request.\nThanks,\n.NET Foundation Pull Request Bot. \n@matst80,\nThanks for your contribution.\nTo ensure that the project team has proper rights to use your work, please complete the Contribution License Agreement at https://cla2.dotnetfoundation.org.\nIt will cover your contributions to all .NET Foundation-managed open source projects.\nThanks,\n.NET Foundation Pull Request Bot. @matst80, thanks for signing the contribution license agreement. We will now validate the agreement and then the pull request.\nThanks, .NET Foundation Pull Request Bot. \n@jbergens,\nThanks for your contribution.\nTo ensure that the project team has proper rights to use your work, please complete the Contribution License Agreement at https://cla2.dotnetfoundation.org.\nIt will cover your contributions to all .NET Foundation-managed open source projects.\nThanks,\n.NET Foundation Pull Request Bot. @jbergens, thanks for signing the contribution license agreement. We will now validate the agreement and then the pull request.\nThanks, .NET Foundation Pull Request Bot. \n@MartinSStewart,\nThanks for your contribution.\nTo ensure that the project team has proper rights to use your work, please complete the Contribution License Agreement at https://cla2.dotnetfoundation.org.\nIt will cover your contributions to all .NET Foundation-managed open source projects.\nThanks,\n.NET Foundation Pull Request Bot. @MartinSStewart, thanks for signing the contribution license agreement. We will now validate the agreement and then the pull request.\nThanks, .NET Foundation Pull Request Bot.  All CLA requirements met..  All CLA requirements met..  All CLA requirements met..  All CLA requirements met..  All CLA requirements met..  All CLA requirements met..  All CLA requirements met..  All CLA requirements met..  All CLA requirements met.. ",
    "johnmcase": "+1\nExact same use case for me.  Passing in the exception as a parameter to the sleepDurationProvider would also work if that makes it simpler.. ",
    "tcsatheesh": "+1\nMy scenario: When querying DocumentDb if the request rate is too high the error response from the server includes a RetryAfter which is the Timespan to wait before retrying. It would be helpful if I can use this as part of my Retry policy.. ",
    "Ulriksen": "Are you sure that load balanced is the difference, could it be traffic/load related instead? \nWhen something hangs my first suspect is sync code calling async functions with with .wait or .result. . ",
    "mieliespoor": "Hello,\nIt might be a load issue, because the load in production is significantly more than the test environments, I will however test this over the next few days.\nI have implemented the Circuit breaker policy using v4.3.0 it seems.\nBefore I start with the testing, I will use the config flags to enable and disable the circuit breaker and see what effect it has got. Any comments on the code below would be appreciated.\nTo make it work in the WCF service, I had to implement dependency injection. IN our staging environment, it seems to work without any issue. The registration happens as follow (only way I could get it to work...):\n    `container\n           .RegisterType<IConnxService, ConnxService>()\n           .RegisterInstance<ICircuitBreakerSettings>(new CircuitBreakerSettings())\n           .RegisterInstance<ICircuitBreaker>(new PollyCircuitBreaker(container.Resolve<ICircuitBreakerSettings>()))\n           .RegisterInstance<IConnxDataHelper>(new ConnxDataHelper(container.Resolve<ICircuitBreaker>()));`\n\n    `public PollyCircuitBreaker(ICircuitBreakerSettings settings)\n    {\n        try\n        {\n            _policy = Policy\n                     .Handle<Exception>()\n                     .CircuitBreaker(settings.BreakOnNumberOfExceptions,\n                         TimeSpan.FromSeconds(settings.BreakCircuitForSeconds),\n                         OnCircuitOpen,\n                         OnCircuitClosed);\n        }\n        catch (Exception ex)\n        {\n            _telemetryClient.TrackException(ex);\n        }\n    }\n\n    public T Execute<T>(Func<T> action)\n    {\n        if (_policy == null)\n        {\n            return action.Invoke();\n        }\n        else\n        {\n            return _policy.Execute(action);\n        }\n    }`\n\nAs for samples:\n`public DataTable CnxQuery(string sql)\n    {\n        return _circuitBreaker.Execute(() =>\n        {\n            var success = true;\n            var startTime = DateTime.UtcNow;\n            var timer = System.Diagnostics.Stopwatch.StartNew();\n            try\n            {\n                ValidateConnxConnection();\n                using (CNXDataAdapter sqlda = new CNXDataAdapter(sql, connection))\n                using (DataSet ds = new DataSet())\n                {\n                    ds.Locale = CultureInfo.InvariantCulture;\n                    sqlda.Fill(ds);\n                    if (ds != null && ds.Tables != null)\n                    {\n                        return ds.Tables[0];\n                    }\n                }\n            }\n            catch (Exception)\n            {\n                success = false;\n                throw;\n            }\n            finally\n            {\n                timer.Stop();\n                TrackDependency(\"Connx\", connection.Database, \"CNXQuery\", startTime, timer.Elapsed, success);\n            }\n\n            return null;\n        });\n    }`. Hello,\n\nSorry I forgot to come back to this. I eventually did a big number of tests and found that the issues was actually not related to the circuit breaker code, but something else. It was actually a really old bug that surfaced when this code went to production. Took a bit to get it to reproduce, but once I were able to reproduce it, I could get it resolved.\nThis did however provide the opportunity to properly show how Polly works.\nWith regards to not catching a general 'Exception' - yeah, I'm against doing that. This was just to get it going and working. We do actually have a specific exception this needs to check.\nIn the OnCircuitOpen and OnCircuitClosed methods, all that happens for the moment, is event logging to Application Insights - that won't hold anything up.... ",
    "cgourlay": "@reisenberger I'm interested. Can you provide further info?. ",
    "jpierson": "@reisenberger, unfortunately no.. ",
    "mmoroni": "Thank you! . ",
    "cemremengu": "Thanks for this fantastic answer very informative! I was using await policy.ExecuteAsync(() => MyTaskAsync()); at first (which I will try again now) but I started to get a lot of connection timeouts from my Oracle db and using Execute(() => Task.Run() => ...) instead worked for some reason. I know this is probably due to a problem of the database but hopefully it will work this time with the changes you suggested.. EDIT: Nevermind :)\nBy the way, the syntax await policy.ExecuteAsync(() => MyTaskAsync()); does not compile for me. It complains that lambda function must have async modifier. That makes sense given that my service restarts occasionally without any error and I was wondering why \ud83d\ude03 I shouldnt have trusted my eyes. Thanks again, this information is gold.\nI see that you attached a tag to the conversation. If you want I can add this to docs or readme as a pitfalls section ?. Note to self: \nTry reading docs in more detail next time cause they are great. You are looking for ExecuteAndCapture. ",
    "DixonDs": "I think that is intention of .NetStandard - by using metapackage \"NETStandard.Library\", you can be sure that the same APIs are used across all frameworks.\nIf you still plan to reinstate \"net\" moniker, I would suggest to use specific monikers like \"net45\" etc, so that you target specific framework versions. Currently it shows \".NETFramework 0.0\" on nuget page: https://www.nuget.org/packages/Polly/5.0.2-v5-0-alpha0001. ",
    "twsouthwick": "@reisenberger  Those System.* packages you're seeing are what are called type-forwarders. This means they allow you to have binary compatibility; ie you expect System.Collections.Generic.List<T> to be in System.Collections, but on .NET 4.5 it's actually in mscorlib, so the System.Collections.dll just forwards the type to the correct assembly. However, on .NET Core, it is in System.Collections so it actually has the implementation there. Other implementations may have it in a different assembly, but the System.* libraries help ensure binary compatibility across implementations.\nAs @DixonDs pointed out, if you want a build for a specific .NET version, such as .NET 4.5, adding net won't work correctly, but using net45 will. This way NuGet will know which target you are specifying it for. I did the same thing for a recent project, where I kept .NET 4.5 support and added .NET Standard 1.3 using the net45 and netstandard1.3 monikers (see https://github.com/OfficeDev/Open-XML-SDK).\nWhich targets are you planning to support with the library? If there's a list of those, we can help determine what the minimum set of targets should be to include in the nuget package.. This plan sounds fine - the noisiness is unfortunately part of .NET Standard 1.0 right now. .NET Standard 2.0 reduces all the small, fine-grained packages into a single assembly (not sure if it's settled, but something like netstandard.dll) that then forwards where it needs to. For now, however, having three targets (net40, net45, and netstandard1.0) sounds like a good plan, especially since you already have the builds. \nI would suggest, for the ecosystem, to just have one package. The main reason is, if someone relies on your package for a library that supports multiple targets (including net40), they don't need to determine which package to use. Your use case is interesting, so I've opened an issue with the NuGet team to see if there is a way to get at that when it's in the same package (see https://github.com/NuGet/NuGetGallery/issues/3450). It doesn't look like this information is currently available as it is gathered from the client side. However, to get the best of both worlds, you can keep the two separate, but add a net40 entry in the main package that just depends on the net40 specific package.. This is a deprecated target framework. Is there a reason you want to include it?\n. Instead of listing the specific assemblies, the recommendation is to reference .NET Standard instead of the individual dependencies (see https://docs.microsoft.com/en-us/dotnet/articles/standard/library)\n. Yeah, that was the original recommendation, but it's since proven to be more problematic to reference specific libraries. Hence, the recommendation is to now reference the whole standard.\n. This profile is supported by .NET Standard 1.0, so it's not necessary any more if you don't want to maintain it separately (see https://docs.microsoft.com/en-us/dotnet/articles/standard/library)\n. Sounds good. Let me know if you have any questions about .NET Standard/VS 2017. btw I'm part of a team in the .NET/VS group whose goals include helping community projects adopt (and adapt) to the changes in the .NET ecosystem and help where needed. I recently learned of this project and have started incorporating it into one of our internal projects :). ",
    "pomma89": "@reisenberger OK, I will gladly test the new package as soon as it is published on NuGet.\nThank you!. @reisenberger I tried the new pre-release package, it installs and works correctly on my .NET 4 lib.\nThank you very much.. ",
    "rahulrai-in": "Thank you for the insights @reisenberger. In my opinion, there are still benefits to making Polly share state among the various services. I am working on building a stateless Microservices application in which the client requests may arrive at any instance of Microservice. I want the requests to behave in a consistent manner and not fail individually on every instance. This feature would also be beneficial in actor model as without this feature several instances of the same actor will try to communicate with external dependency before failing. This scenario is also supported by Akka.\nI agree to the fact that this should be an opt-in rather than a compulsory feature and I would love to submit a PR to include this feature in Polly. We can design this feature to trip the circuit if failure is reported from at least N instances so that communication failure between a single node and dependency does not trip the circuit.\nThis is a really good pattern for use in cloud applications esp. Microservices.. I think to support the quorum policy, we need to add another Policy class or update CircuitBreakerPolicy class to add support for Quorum policy. By doing this we can add custom policies to the Circuit Breaker. Next, CircuitBreakerState property should have the support to be loaded from a data store. Currently, this property returns what is stored in a local variable.. Adding @tarunp who is a .net architect specializing in distributed systems to add his thoughts and contribute to this feature.. @reisenberger @mcquiggd \nI completely support the view of having this feature as an opt-in rather than a forced one. By exposing simple interfaces, we can have an array of plugins that can be plugged into Circuit Breaker to persist circuit breaker state data.\nBut I would definitely like to have an opt-in transient fault handling into circuit breaker so that a transient error does not cause the circuit breaker to trip. \nAlthough I did participate and support the quorum idea earlier, I think maintaining quorum state is a hard problem to solve and requires internal knowledge of the application and the network, therefore I would rather not implement it in Polly. Moreover, many of the Microservices platforms such as Service Fabric know how to maintain a quorum and I believe no one using Polly would want to override that feature with our implementation.. Hi,\nI would go through this today and add my inputs.\nSent from my Windows 10 phone\nFrom: reisenbergernotifications@github.com\nSent: Wednesday, 23 August 2017 7:01 AM\nTo: App-vNext/PollyPolly@noreply.github.com\nCc: Rahul Rairahulrai@live.com; Mentionmention@noreply.github.com\nSubject: Re: [App-vNext/Polly] OPTION/PROPOSAL: Distributed Circuit Breaker (#287)\nI am keen on the (d) extension-point idea as a way forward for this too. @rahulrai-inhttps://github.com/rahulrai-in : would that suit your needs too?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://github.com/App-vNext/Polly/issues/287#issuecomment-324150487, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ALVfvHLTyb4-9KyCQAjROK2JkIziTYYDks5sa0GogaJpZM4Oqtop.\n. I am all for an extensible model for circuit breaker. There should be a single I terrace which the providers can implement.\nOutlook for Android\n\nFrom: Dylan Reisenberger notifications@github.com\nSent: Tuesday, November 13, 2018 9:13:08 AM\nTo: App-vNext/Polly\nCc: Rahul Rai; Mention\nSubject: Re: [App-vNext/Polly] OPTION/PROPOSAL: Distributed Circuit Breaker (#287)\n@utkarsh5khttps://github.com/utkarsh5k That's great to hear! It would be great to have more developer power on this.\nIn (scarce) spare hours in the last few weeks I coincidentally started on point (d) of this commenthttps://github.com/App-vNext/Polly/issues/287#issuecomment-322900996, which is simpler than the original proposalhttps://github.com/App-vNext/Polly/issues/287#issue-2472996900:\n(d) Only adapt Polly to allow injection of new circuit-breaker implementations\nThat is: refactoring the circuit-breaker engine so that it provides a better ICircuitController seam (or similar) for the injection of custom ICircuitController (or similar) implementations.\nAnd simultaneously: refactoring the existing controller of the original circuit-breakerhttps://github.com/App-vNext/Polly/wiki/Circuit-Breaker so that it could take (by injection) an IConsecutiveCountCircuitBreakerStateStore (and refactoring the existing in-memory implementation to fulfil this). Building a distributed consecutive-count circuit-breaker would then be a matter of coding, say, a StackExchange.Redishttps://stackexchange.github.io/StackExchange.Redis/ (or similar) implementation for IConsecutiveCountCircuitBreakerStateStore.\nComments welcome!\nPerhaps I should take a few more days to see if I can progress that, but also look for a good place to share work out?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://github.com/App-vNext/Polly/issues/287#issuecomment-438046652, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ALVfvCuU6X2gBrBSydBRlHgwKL1FqFibks5uufJ0gaJpZM4Oqtop.\n. ",
    "tarunp": "Sure @moonytheloony . I also faced the same issue in one of my application consisting of background services. If we can have quorum concept within the Polly itself then it will be really useful for multi instance scenarios. I think major events or state of the circuit should be good enough to determine the state of each node.\n. ",
    "Kharos": "I just hit the same problem. Our use case is using a circuit breaker in front of outgoing requests to a downstream server to prevent:\n\nflooding of the downstream server with requests when it is unhealthy and returns HTTP 500\nhigh resource consumption when downstream server cannot be reached (all requests will time out)\n\nThis behavior is pretty bad in case 2 as it may take a moment until the half-open requests will time out. In effect we will lose circuit breaker protection for at least several seconds after each [break duration] time.\nI understand that the issue is not trivial, e.g. if we only allow a single half-open request and that request hangs it may keep the circuit open, so there needs to be some mechanism to e.g. allow a half-open request every [break duration] time even if the previous one has not yet returned. But this issue needs to be solved for async polly circuit breakers making sense with web requests.\n[Edit] Additional edge case bug: The onBreak() callback is potentially called multiple times in that scenario, once for each failed hald-open request.\n[Edit 2] Reading the code are a lot of other edge cases if requests are started when the policy is closed, the policy breaks, goes back to half-open, and only then the requests return a result. At the moment the circuit breaker would think that these requests were half-open testing requests. Not sure if that is an important case though.... Great @reisenberger :+1:. Please tell me if I can support you - reading through the Polly codebase things looked a bit complex because the logic is distributed over multiple classes and no tracking of action seems to happen (i.e. there seems to be no way to know on a finished async call if that call was started closed or half-open), so I did not feel comfortable enough to propose a fix. But I  would be happy to for example test your changes against my codebase.. Awesome, you guys are fast :+1:!\nI will be unable to test in the next two days as I am on a conference, but I will make sure to take a close look Wednesday morning European time.. Works for my use case.\nWhat I really need is a possibility to treat web requests that take longer than some amount X of time as a failure (as large numbers of these indicate that the server is not healthy). I am able to implement this using Polly as it is now and a 'soft' timeout in our async callback - the task returns after this timeout but the actual requests continues. The timeout value will be shorter than the 'circuit broken' time, so tracking of requests would add no benefit for me.\n[Edit] That was probably hard to understand, so let me rephrase :-D. My 'soft' timeout will ensure that all async calls Polly will see are shorter than the circuit broken time, even if the 'hard' http timeout is longer.. Looks good, using your forked branch my test with two parallel half-open requests now passes: One request is allowed through, the other throws, and the onBreak callback is only invoked once. I also wrote an additional test to check the behavior when the first half-open request takes a very long time, and after waiting for the break duration one (and only one) other request is let through \ud83d\udc4d.. About the timeouts, I am not sure that what you propose will cover my use case.\nI am sending requests to a downstream server. 99% of all requests return within 4 seconds, but some requests can take significantly longer (10-20 seconds) because they access very expensive resources. So if a few requests take longer than 4 seconds I want to let them run to completion (and I have to set the HttpClient timeout pretty large to make this work), but if a significant number of requests takes longer than 4 seconds this is a sign that the downstream is unhealthy and I want the circuit to break.\nMy currrent solution is to use a Task<Task> in the polly circuit breaker: The wrapped inner task is the async HttpClient task, the outer task returns if either the inner task succeeds or if 4 seconds pass (using Task.WhenAny with the inner task and a delay task). I use Polly.HandleResult and return true to the circuit breaker if the inner task did not complete successfully (meaning it either failed or it is still running); after receiving the result from the circuit breaker I await the inner task to get the final result of the request. The benefit of this complicated implementation is that the circuit will break after 4 seconds when the downstream stops responding, even though the requests are all still in flight.\nMy code looks a bit complicated but it works. If there is a better was to do this using Polly's timeouts then please tell me :) but my understanding is that they will abort the inner task, which is not what I want.\n[Edit] I realize that the proper solution would probably be two circuit breakers with different timeouts, but the URLs are very similar and I can't easily find out if a request is in the slow or in the fast category before I send the request.... > Bug: If further call failure results arrive on a breaker in open state, the onBreak() delegate is triggered a further time for each such call failure.\nAh, that explains the behavior I could see when Polly allowed two half-open requests (2x onBreak triggered when they both returned).\nMy expectation is that the event only happens once as I want to use onBreak and the other delegates for logging, allowing us to analyze incidents after-the-fact. I prefer if Polly passes results that it receives in open to the caller normally, as these failures usually have more information for us than the 'broken circuit' exception. So for both of these my expectation seems to match your recommendation.\nI don't yet know enough about how Polly's metrics work to comment on that aspect.. ",
    "lamest": "I see now. My issue was that when i try to install Polly nuget package there are number of dependencies from system.* included. It's because of i target .Net 4.5.1 which is .NET Platform 1.2 (thanks @reisenberger). Isn't this so?\nIs there any plans for newer .NET Platform support?\n. Answer part with \"type forwarders\" is exactly what i was needed. Thanks for complete answer.. ",
    "nathan-alden": "Very cool, and thank you so much for responding so quickly. I was about to have to start work on my own internal library, which would've been a huge waste of time. Dem corporate policies... \ud83d\udc4e . To be clear: We still get our binaries from NuGet, but the team that scans OSS dependencies requires a snapshot of the code; i.e., they won't simply scan the NuGet binaries themselves.. ",
    "Julien-Mialon": "Salut @reisenberger \nParfait ! It works perfectly and can be merged.\nThanks. @ericbrunner  @ZoranBebic @reisenberger Just tried to install Polly in a PCL project targeting net451, win81, Xamarin *. It worked perfectly, but you need to have one of the last version of nuget to make it works correctly. You don't need to target netstandard to use netstandard project, it has retrocompatibility with pcl profile.. Just updated to last 3.X nuget version works perfectly, I tried with VS2015 and Xamarin Studio.. @ericbrunner That's right, you can not reference netstandard to PCL with project reference but with nuget, it works. I will setup a sample project this evening.\nYou can check that link for PCL profile & netstandard equivalent https://docs.microsoft.com/en-us/dotnet/articles/standard/library, in Profile 259 you should be able to add any nuget targeting netstandard1.0.. @ericbrunner I did the sample, it's available there : https://github.com/Julien-Mialon/PollyNetstandardSample\nYou can check in the csproj file that Polly is referenced by using netstandard1.0 version \nxml\n<Reference Include=\"Polly, Version=5.0.6.0, Culture=neutral, processorArchitecture=MSIL\">\n  <HintPath>..\\packages\\Polly.5.0.6\\lib\\netstandard1.0\\Polly.dll</HintPath>\n  <Private>True</Private>\n</Reference>\nMy nuget version is 3.5.0.1938\nOnly thing that I can think of, it's I have the .Net Core SDK installed (which add some support for netstandard project).\nHope this could help.. Hello @mikegottlieb \nGot this error for some packages recently on Xamarin Studio & Vs For Mac (alpha, currently downloading the stable version released yesterday). A workaround that I used was building from CLI by manually launching xbuild, after that XS & VSfM managed to use Polly. But it's definitely a bug in XS & VSfM since CLI works just fine.\nI will check if the issue is still present for me with last version of VSfM.\nIf it still there, the only reason I can think of is last version of Polly still use project.json system, maybe updating to VS2017 format with csproj could work, I don't know if it's something planned @reisenberger ?. Didn't have this problem anymore with last stable version of Visual Studio for Mac.\nI'm running it with Mono 5.0. Wow, didn't expecting that, thanks ;). ",
    "RudeySH": "I don't know the exact numbers right now, but I can imagine the calls queuing up to multiple thousands. I was successfully able to use AsyncManualResetEvent after I failed to use Polly to solve my problem. CircuitBreakerAsync seemed not to be the right tool for the job, because when the circuit is broken, it returns immediately (or throws an exception?) instead of waiting and retrying.\nI'm still looking for a better solution though, my current implementation using AsyncManualResetEvent is not really maintainable. I still have a lot of stuff to figure out regarding timeouts, cancellation, etc.\nThis specific wait-and-retry strategy I'm implementing is required because I'm accessing a limited API. My real underlying problem of this all is that I don't remotely know what the limits of this API are. Currently I'm trying to gather more information on this API so I can work out a better wait-and-retry strategy.. Thanks for all those links. It seems it's really easy to introduce cancellation/timeouts to any async method.\nI tried using PolicyWrap to combine wait-and-retry with circuit breaker, but I hadn't thought of using another policy to handle the BrokenCircuitException. I will try again using your example.\n\nAre there any disadvantages to releasing all the queued requests pretty-much simultaneously, when the cool-off period is up? In the calculate-when-to-retry approach of the above Polly example, you could introduce some randomisation or regular separation.\n\nI'm not sure what you mean. Could you elaborate on this?\n\nIf the underlying need is rate-limiting, could something like Jack Leitch's RateGate be useful?\n\nIt seems rate limiting is only useful when you know exactly how much requests per timespan are allowed. In my case, I don't know what the limits are, so that's why I'm looking for a solution that kicks in when a specific exception is thrown.. ",
    "dannydwarren": "Perfect. Thank you!. I always wished I had one policy for both sync and async. And agree with @Im5tu's points. Also, based on experience this would help with the learning curve.. ",
    "TheFlow0360": "@reisenberger even if it didn't help Cliff, it was valuable advice for me - thanks for that! I'll try to implement this and will come back to provide feedback afterward. It could take a while, though, since I need to prepare the API for providing discrete chunk data transfer, too.. Ok, I ended up implementing this nearly the same as described in the SO question you provided, @reisenberger , because I wasn't able to use my common api connection (RestSharp doesn't support async file download - I took a look at their code, and it would be too much pain to fix this).\npublic async Task DownloadWhatever(String requestUri, String targetPath)\n{\n    using (var httpClient = new HttpClient())\n    {\n        using (var request = new HttpRequestMessage(HttpMethod.Get, requestUri))\n        {\n            // Add additional headers\n            // ...\n\n            // IMPORTANT: using for CancellationTokenSource to prevent Memory Leaks\n            using (var cancellationTokenSource = new CancellationTokenSource())\n            {\n                using (var responseMessage = await httpClient.SendAsync(request, HttpCompletionOption.ResponseHeadersRead, cancellationTokenSource.Token).ConfigureAwait(false))\n                {\n                    var bufferSize = 1024 * 1024;  // 1 MB buffer\n                    using (var httpStream = await responseMessage.Content.ReadAsStreamAsync().ConfigureAwait(false))\n                    {\n                        using (var filestream = new FileStream(targetPath, FileMode.Create, FileAccess.Write, FileShare.None, 4096, true))\n                        {\n                            var buffer = new byte[bufferSize];\n                            while (true)\n                            {\n                                var num = await httpStream.ResilientReadAsync(buffer, cancellationTokenSource.Token);\n\n                                // TODO: report progress to UI, use TickCount for download speed calculation\n\n                                int bytesRead;\n                                if ((bytesRead = num) != 0)\n                                    await filestream.WriteAsync(buffer, 0, bytesRead, cancellationTokenSource.Token).ConfigureAwait(false);\n                                else\n                                    break;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nThis didn't change all that much, I just removed the filename acquisition because I didn't need it. Also, the cancellation token doesn't make sense in this constellation, you need to either pass it or handle the token source somewhere else. The main part is the new extension method for Stream: ResilientReadAsync\npublic static async Task<Int32> ReadAsyncWithPolicy(this Stream stream, byte[] buffer, CancellationToken cancellationToken, Policy<Int32> policy)\n{\n    return await policy.ExecuteAsync(ct => stream.ReadAsync(buffer, 0, buffer.Length, ct), cancellationToken);\n}\n\npublic static async Task<Int32> ResilientReadAsync(this Stream stream, byte[] buffer, CancellationToken cancellationToken)\n{  \n    var readAsyncResiliencePolicy = Policy.TimeoutAsync<Int32>(API_DEFAULT_OVERALL_REQUEST_TIMEOUT)\n        .WrapAsync(Policy.Handle<Exception>(ReadAsyncExceptionRetryPredicate).WaitAndRetryForeverAsync(API_DEFAULT_RETRY_INTERVAL_FUNC))\n        .WrapAsync(Policy.TimeoutAsync(API_DEFAULT_SINGLE_REQUEST_TIMEOUT));     \n    return await ReadAsyncWithPolicy(stream, buffer, cancellationToken, readAsyncResiliencePolicy);\n}\n\nprivate static bool ReadAsyncExceptionRetryPredicate(Exception exception)\n{\n    var ioEx = exception as IOException;\n    if (ioEx != null)\n    {\n        // probably the connection was closed by the host, in this case retrying won't help\n        // TODO: isn't there a better way to check if this is really the case?\n        return false;\n    }\n    return true;\n}\n\nOf course, the details of the policy are something everyone has to decide for themselves. I chose a timeout for the call itself (I took 10 seconds), wrapped by a policy that will retry with an exponential increase of delay (2^attempt), wrapped by another timeout that limits the whole operation (in my case 60 seconds).\nOne problem I noticed when testing this is that the server-side may cancel the stream if the client is waiting too long between the retries - resulting in an IOException. I don't know if there is any other way an IOException may occur. I decided to skip all IOExceptions to avoid retries when the server already cancelled, but this could be bad. In any case, I don't know how to distinguish other IOExceptions.\n@reisenberger do you have any idea regarding the IOException or any other remarks/suggestions? If not I would add this to the wiki.. @reisenberger I didn't test this thoroughly. What I did as smoke test was to modify the execution of the policy in ReadAsyncWithPolicy to randomly wait a few seconds or throw an exception (in this case it worked, except the server closed the connection because of inactivity when it happened several times in a row). I'm not sure if it would be different if the stream.ReadAsync itself failed... I honestly have no good idea how to test this properly.. ",
    "CliffCawley": "Thanks for all the info! Sorry I didn't reply, I've been busy with a deadline and recovering from a cold so I've been rather out of it :(\nI've tagged this to come back to in the future. I use Polly with Refit so I'm going to have evaluate how I will solve this one then.. ",
    "ericbrunner": "@ZoranBebic Hi Zoran, I guess my issue is related: https://github.com/App-vNext/Polly/issues/238\nI am not so experienced with Polly . Does v 4.3.0 the job as well ? So would it be sufficient to use that version? In case of yes, I could go that way otherwise I get rid of Polly. . @ZoranBebic Thank you Zoran for your support. I use Polly in Windows Services so I really like it and wanted to use it in Xamarin.Forms , too. Ok. I try the v.4.3.0 you mentioned above.. @Julien-Mialon Thank you very much. I don't think that is the full truth. As Adam Pedley blogged, you can't reference a .NET Standard library from a PCL project:https://xamarinhelp.com/dot-net-standard-pcl-xamarin-forms/\nBut you make me curious. I will try, because if you are right I could reference any .NET Standard library in my PCL with profile 259, not only my beloved Polly.\nFurther I have to check if my hosted agent in VSTS , which I use to build Xamarin.Forms Apps, already supports the 3.x nuget.exe.\nIt would definitly help when you can put a sample project either on gist.github.com or a public repo.. @Julien-Mialon Awesome! Thanks for your support.. ",
    "ZoranBebic": "@ericbrunner Hey Eric!\nOlder version still packs a punch and is extremely worth using. It lacks new features version 5.x brought in but maybe you don't need them so definitely give it a try (I only use Retry for now and love it). One thing for me particularly in version 5 is Timeout and an upcoming Cache implementation that I'd love to try.\nDue to a bug in Xamarin.Forms sadly I am unable to target NetStandard just yet. . That's great news however I'm not sure I understand this statement \"It worked perfectly, but you need to have one of the last version of nuget to make it works correctly.\"\nAre you referring to Nuget version 4+ that comes already as part of latest VisualStudio? I haven't tried updating to Polly 5.x since I switched to VS2017 and having deadline looming just around the corner I won't be able to try this for another week. Will definitely post with the results soon. Thanks!. ",
    "mikegottlieb": "I just installed VS for Mac now that it is out of preview. I had to set my Mono version to 4.8 because I'm still on a slightly older version of Xamarin.Forms. When I try to build I get the following error.\n\nThe primary reference \"Polly\" could not be resolved because it was built against the \".NETPortable,Version=v5.0\" framework. This is a higher version than the currently targeted framework \".NETPortable,Version=v4.5,Profile=Profile259\".\n\nI'm was originally using v5.0.5 of Polly, but I also tried v5.0.6. I also updated my nuget just in case that was the problem, but unfortunately non of that helped.\nWhat is really strange is that I can build fine in Xamarin Studio. Any ideas?. I manually edited the project file to reference the net45 version of Polly rather than the netstandard1.0 version and now my project builds although I get some strange warnings.\nIt looks like I'm not the only one seeing weirdness here. One of your links linked to a newer open issue in Humanizer here\nI guess maybe this is just a VS for Mac regression and I need to wait for an update. I'm not quite ready to retarget my whole application, but thanks for the link from Oren. I'm sure that will help when I'm ready.. I'm running Mono 4.8 because I cannot yet update to 5.0 due to other constraints.. ",
    "KennethWKZ": "@reisenberger tried to use decorrelated jitter that part of code but got error with not able to convert class TimeSpan to IEnumerable\nAnyway to solve this? not very familiar on this.. @reisenberger Thanks!!! Now I'm more understanding how it's works~!. @reisenberger \ncurrent = Math.Min(max, Math.Max(seed, current * 3 * jitterer.NextDouble())); \n// adopting the 'Decorrelated Jitter' formula from the quoted article.  \n//Can be between seed and previous * 3.  Mustn't exceed max.\nMay I asking this part? Is it me should set the seed lower than max? Example: max is 1000ms, so seed will be 100ms?. ",
    "23W": "Excuse me, why do you use loop with \"<=\" comparison criteria in DecorrelatedJitter, while (attempt++ <= maxRetries)? I think it should be strict \"<\", shouldn't it? So right code is:\n```\npublic static IEnumerable DecorrelatedJitter(int maxRetries, TimeSpan seedDelay, TimeSpan maxDelay)\n{\n    Random jitterer = new Random();\n    int attempt = 0;\ndouble seed = seedDelay.TotalMilliseconds;\ndouble max = maxDelay.TotalMilliseconds;\ndouble current = seed;\n\nwhile (attempt++ < maxRetries)\n{\n    current = Math.Min(max, Math.Max(seed, current * 3 * jitterer.NextDouble()));\n    yield return TimeSpan.FromMilliseconds(current);\n}\n\n}\n```. ",
    "mcquiggd": "@reisenberger \nMany thanks for taking the time to look into this - it's appreciated.\nWe had sort of come to the same point. \nMy thoughts so far:\n1) My understanding is that the Microsoft recommendations are really a general approach to retries with services (as in - 'you should have retries'), rather than any specific technical reason for using their implementation. Having chatted to a member of the DocumentDB team, they did state that the Client is only intended for basic fault handling scenarios. At present you cannot even specify a sliding scale for wait times in the Client; to do so you need to use the Transient Fault Handling package, which will be deprecated when the Client has feature parity. But there are no plans to add other features AFAIK.\n2) Polly has a major part to play in Cloud architectures, and we are unlikely to see any similar efforts from Microsoft (the Enterprise Library blocks seem to be left to one side). I want to be able to architect a common set of Policies and patterns for handling errors - be they Blob Storage, Azure Search, DocumentDB, DynamoDB, ElasticSearch.\n3) It might therefore be appropriate to take the approach of say, wrapping one of the more advanced patterns (Circuit Breaker) around the individual service-specific, simple retry logic. Perhaps catch specific exceptions such as the DocumentException in a try catch, and when retries are exhausted rethrow and handle a custom 'ServiceException' with a Polly Policy / bundle of Policies, as a small abstraction.\nStill thinking about all this... as you mention in your edit, I feel there is a role for Polly to play in this. \nI need to ponder it for a while and try some ideas over a cup of tea ... ;-). 24 hours is a long time in technology - now we have Azure Cosmos DB... \ud83e\udd47 \nFrom the documentation:\n\nIf you have more than one client cumulatively operating above the request rate, the default retry behavior may not suffice, and the client will throw a DocumentClientException with status code 429 to the application. In cases such as this, you may consider handling retry behavior and logic in your application's error handling routines or increasing the reserved throughput for the container.\n\nHaving looked at the DocumentClient source code, I am currently testing an approach that disables the built-in retries, and uses Polly instead. Will report back if I make progress.. @reisenberger \nWell, I have made a little progress.\nFirstly, I have taken the DocumentDB Benchmark project (available from the DocumentDB GitHub repo, under samples), copied it and converted it to .Net Core, so we have both .Net 4.x and .Net Core 1.x versions in the same solution.\nI am using this as a testbed for my 'experiments', with the latest DocumentDB emulator set to use a single, non-partitioned collection of 400 Request Unit capacity, the 'slowest'.\nI deliberately set the values for threads, and amount of documents to insert, to cause throttling.\nWith the DocumentDB Client retry, throttling was handled automatically.\nNext, I disabled the DocumentDB Client retries; of course exceptions occurred. Bear in mind that these settings are 'global' if you follow the sound advice of using a single Client instance, which does a lot of performance enhancement, but is also a little inflexible...\nprivate static readonly ConnectionPolicy ConnectionPolicy = new ConnectionPolicy \n{ \n    ConnectionMode = ConnectionMode.Direct, \n    ConnectionProtocol = Protocol.Tcp, \n    RequestTimeout = new TimeSpan(1, 0, 0), \n    MaxConnectionLimit = 1000, \n    RetryOptions = new RetryOptions \n    { \n        MaxRetryAttemptsOnThrottledRequests = 0, // was 10\n        MaxRetryWaitTimeInSeconds = 60\n    } \n};\nThen, I created a Polly Retry Policy, as follows:\nprivate static readonly RetryPolicy PollyRetryPolicy = Policy.Handle<DocumentClientException>(de => de.RetryAfter > TimeSpan.Zero).\n        Or<AggregateException>(ae => ((ae.InnerException as DocumentClientException)?.RetryAfter ?? TimeSpan.Zero) > TimeSpan.Zero).\n        WaitAndRetryAsync(retryCount: 3, \n                sleepDurationProvider: (retryAttempt, context) =>\n                {\n                    var retryAfter = TimeSpan.FromMilliseconds(10); // Should be 0? \n                    if (context == null || !context.ContainsKey(\"RetryAfter\")) return retryAfter;                       \n                    return (TimeSpan)context[\"RetryAfter\"];\n                }, \n                onRetryAsync: (exception, timespan, retryAttempt, context) =>\n                {\n                    context[\"RetryAfter\"] = (exception as DocumentClientException)?.RetryAfter\n                                            ?? (exception.InnerException as DocumentClientException)?.RetryAfter \n                                                 ?? TimeSpan.FromMilliseconds(1); //Just an arbitrary chosen value, never seems to be used\n                    return Task.CompletedTask;\n                }                \n        );\nSo, basically using Context to pass the retry value from the onRetryAsync to the sleepDurationProvider, and using purely Polly to handle waits etc. And now we can create different policies / settings for different 'operations', using the same Client instance, potentially passing the 'operation name' in Context from the call to Execute the Policy... if my understanding of the Retry life-cycle is correct. I have noticed that retry attempt 1 does not seem to include a server retry-after value, but had limited time today to verify.\nThis Policy is then called in the multi-threaded benchmarking app as below:\nvar response  = await PollyRetryPolicy.ExecuteAsync(async () => await client.CreateDocumentAsync(\n                                                                    UriFactory.CreateDocumentCollectionUri(_appSettings.DatabaseName, _appSettings.CollectionName),\n                                                                    newDictionary,\n                                                                    new RequestOptions()));\nThe result - Polly handles all the retries, observing the returned retry interval from the server:\n\nI'll continue to work on this (it can definitely be tidied up, I have a lot of distractions around at the moment), and upload the Solution to Github in case others wish to contribute. \nPerhaps you can spot any obvious mistakes - e.g. is it valid to create the Policy as static readonly in a multithreaded environment?\nI want to create some more advanced examples for the different scenarios available with Polly, along the lines of your last post... will pop onto Slack at some point...\n. @reisenberger \nMade some changes this morning, including storing the id of the Document to be inserted via Context when ExecuteAsync is called, and that functions as expected, with data subsequently being available within the Policy.\nA1. I changed the Policy declaration to be simply private - i.e. not static, not read only - I observed no change in behaviour.\nA2. I have also set the parameter continueOnCapturedContext on ExecuteAsync to true - this does not appear to have any impact on results.\nA3. I have verified that on retry attempt 1, there is no RetryAfter being returned in the Context, although it is returned from the server.\nA4. On investigation, this is due to the sleepDurationProvider being called before the onRetryAsync delegate, which is not what I expected from the Retry lifecycle :\n\nIf another try is permitted, the policy:\n        Raises the onRetry delegate (if configured)\n        In the case of a wait-and-retry policy, calculates the duration to wait from the IEnumerable or Func configured, and waits.\n\n\nA5. I don't see an override of the sleepDurationProvider  that provides access to the Exception / handled object - which would allow simplified logic in this instance.\nAny thoughts...?\n. > So, you'd have access to eg, context.LastHandledException and context.LastHandledResult - would this do the trick?\nVery nicely, and I was going to suggest that - the existing number of overloads was a little intimidating at first, and of course changing the execution  behaviour and breaking backwards compatibility is a non-starter.. @reisenberger \nAdded some random thoughts:\nB1. A Policy can Handle, and also Ordifferent Exception or Result types. As we found in our example for DocumentDB, that could be DocumentClientException or AggregateException. That could result in a bit of spaghetti code to determine what type the context.LastHandledException or context.LastHandledResult should be cast to for accessing the desired properties. Ugly.\nB2. As we are using an initial generic Handle<T> or HandleResult<T>, will we be passing context.LastHandledException of type T, context.LastHandledResultof type T (and exploring AggregateExceptions to locate T) ?  This would save a lot of repetitive code ... Any use cases that would rule this out?\nB3. If we are able to pass the Handledtype, makes sense to have context.HandledException and context.HandledResult.. @reisenberger \nIndeed, ~Document~ Cosmos DB will throw either a DocumentClientExceptionor an AggregateException; the latter is, I believe, due to the behaviour of asynchronous code, specifically Tasks.\nStephen Cleary states here:\n\nAllowing async to grow through the codebase is the best solution, but this means there\u2019s a lot of initial work for an application to see real benefit from async code. There are a few techniques for incrementally converting a large codebase to async code, but they\u2019re outside the scope of this article. In some cases, using Task.Wait or Task.Result can help with a partial conversion, but you need to be aware of the deadlock problem as well as the error-handling problem. I\u2019ll explain the error-handling problem now and show how to avoid the deadlock problem later in this article.\nEvery Task will store a list of exceptions. When you await a Task, the first exception is re-thrown, so you can catch the specific exception type (such as InvalidOperationException). However, when you synchronously block on a Task using Task.Wait or Task.Result, all of the exceptions are wrapped in an AggregateException and thrown. Refer again to Figure 4. The try/catch in MainAsync will catch a specific exception type, but if you put the try/catch in Main, then it will always catch an AggregateException. Error handling is much easier to deal with when you don\u2019t have an AggregateException, so I put the \u201cglobal\u201d try/catch in MainAsync.\n\nSo, there is a need to handle both possibilities. This is, I believe, how the Transient Fault Handler works. I will look at the code for it tomorrow, and will drop a message to a person I know on the DocumentDB team to see if they have any insight...\nI have some time this week to devote to this - I will try to create an example of what I envisaged for my own application; basically the same sort of approach as the Transient Fault Handler that decorates the Document DB client, but with Polly policies. These would be specified at client instantiation as '\"global\" Policies, and optionally overridden by operation specific Policies passed when calling a method.\nSo basically there would be a library of extension methods, which wrap each type of client, and return a 'Resilient' instance; such as IResilientDocumentDBClient, IResilientAzureStorageClient, IResilientHTTPClient, etc, etc. \nIf we cannot find an elegant way to enhance the existing Polly approach to AggregateExceptions without breaking backwards compatibility, I would probably look at adding a try catch block around the actual DocumentDB Client call, extracting the DocumentClientException and rethrowing that to the ExecuteAsync method of the Policy, within the Resilient decorator. For my project I also intend to add such features as concurrency handling (e.g. handing etag mismatch in DocumentDB) where appropriate.\nThat's just a summary of my initial thoughts... at this point I prefer to try to write some code to see how it 'feels', and adjust accordingly... Ill share it so we can discuss it...\nDavid\n. @reisenberger \n\nI should have been more precise in my previous question. Q in my mind was whether any one execution through DocumentDb might fail with either a DocumentClientException or AggregateException (as opposed to DocumentDb expressing that variety if called in different ways)\n\nYep, got it - thats why I wanted to look at the Transient Fault Handler code and Document Client code to see under what circumstances (and why) there are Aggregate exceptions. I put the background for others reading the thread :) \nIt would be a perfectly reasonable theory that the Async methods on DocumentClient throw AggregateExceptions, and the non-async methods throw DocumentClientExceptions. But as I say, now its time to code / examine code and see how things work ;). Another vote for .HandleInner<Exception>()\nThe following, IMHO, outweigh other considerations:\n\nNo breaking change to existing behaviour.\n\nExplicit - no 'hidden magic' which developers new to Polly have to be aware of.. Ok, as mentioned on the Slack channel, I had deleted my post just as @rahulrai-in was replying to both @reisenberger and myself. I wasn't happy with the clarity of my my post, and now I have more time, I will now attempt to explain my position in a more structured manner:\n\n\nThe discussion so far seems to have focused on Polly Circuit Breaker solutions to several different scenarios, without taking into consideration the other tools available to ensure resilience in application deployments, which are complementary to Polly. I believe if we factor those into the discussion, we can simplify the scenario that the Polly Circuit breaker needs to address.\n\n\nQuorum logic is hard to implement correctly. By exploring the features available to us in point 1) above, I believe it is unnecessary.\n\n\nI have a couple of suggestions for providing shared Circuit Breaker state, and a greatly simplified interface, and my own personal preference for implementation that would meet the 80/20 rule, which would also allow others to create more complex logic as their own specific scenarios demand.\n\n\n1. Infrastructure Solutions\nSo, let's start by looking at resilience in general, and where Polly Circuit Breaker can fit in. In terms of my preferred cloud provider, Azure, there are multiple levels where resiliency and redundancy can be implemented. AWS and Google Cloud offer similar solutions. Third parties offer on-premise solutions. \nWhen I plan my app deployments, I use the built-in Azure features of scale sets, fault zones, and update zones, to prevent temporary outages causing service interruptions. Take for example, a backend set\nof VMs / worker roles / microservices that perform processing of images, video encoding, or bulk emailing. They need to connect to a data store, and potentially an external service, e.g. MailGun. My first step would be to place an Azure Load Balancer (internal mode), to pass traffic to my 'set', which I would describe as a 'named service'.  My approach here, would be to use a Polly Circuit Breaker, to handle calls to the data store, and external service, with Policies for each. The Load Balancer probes specified endpoints to determine the health of each node; the Circuit Breaker instance of each can be used to return its state, which allows the Load Balancer to redirect traffic to other nodes, or if no nodes are available, fail the requests.\nThis propagates up to the other 'named service' that originally called the failed service. It's own Circuit Breaker Policies determine that its dependency 'named service' is unavailable, and determines if a feature should be disabled (e.g. video processing, or new user registrations as email confirmations are not available), and this is reflected in the backend.\nIn addition to the Load Balancer option, Azure offers Application Gateway (routing or requests to different 'named services' based on url rules, health etc), and Traffic Manager (DNS based redirection of traffic based on policy rules, that allow failover to a different data center or region, and can also handle services which are not hosted on Azure).\nI recommend reading Using load-balancing services in Azure\n\nAgain, each of these can be configured to probe Circuit Breaker State. \nI have worked with Akka.Net, and it has its own official Akka.Net Circuit Breaker that takes advantage of Akka specific features for state persistence and rehydration; it is far better to not attempt to reinvent the wheel in these circumstances.\n2. Quorum Logic Is Hard\nThese services mentioned above in point 1 are aware of nodes, have advanced policy configuration, and IMHO obviate the need for Polly Circuit Breaker to implement it's own quorum logic. We would never be able to implement a solution of sufficient quality. Here is an interesting read if you wish to explore that avenue: \nhttp://vldb.org/pvldb/vol5/p776_peterbailis_vldb2012.pdf\n3. My Personal Recommendations For State\nThere is a need for shared / distributed Circuit Breaker State. I would break this down into two options:\nRedis\nA simple Redis cluster (2 nodes), optionally acting as a pass through cache will be sufficient for medium availability, and meet 80%+ of use cases, as a guestimate.  That gives you extremely fast response times (especially if deployed to the same virtual network as your core app services, if you are using a Cloud provider), and auto failover. \nImportantly, it is possible to combine Redis with local, in memory caches of data, which are then synchronised with Redis, and provide resiliency to storage of state data. Here is one library that can achieve this, there are others: \nCacheManager- Open Source, can use a variety of backends, but Redis is the more feature rich.\nhttp://cachemanager.michaco.net/\nI'ts worth noting a feature CacheManager offers which is highly relevant:\nhttp://michaco.net/blog/CacheManagerReleaseOneDotOneNewFeaturesAndFuture\n\nCache Backplane with In-Memory Caches\nThe CacheManager Backplane feature was intended to be used with at least two layers of Cache where the source of truth (source layer) is a distributed cache like Redis.\nNow, the backplane can also be used to synchronize multiple instances of your app even if only one in-memory cache layer is used.\nThe use case is pretty specific, but still, useful ;) If you have multiple instances of your app running and delete a key in one instance, the backplane will distribute this delete to all the other connected instances and delete the key in those instances, too, if it exists.\nThe difference to the original implementation and intention is that there is no distributed cache as source of truth.\nIt is important to note that the backplane never transports the cached data to store it in each instance for example, to mimic a distributed cache. If you want this functionality, just use Redis.\nAlso, important to note, the only implementation of the CacheManager backplane is still using Redis pub/sub, meaning, to use the feature, you have to have a Redis server running somewhere.\n\nNote that you can still also use this approach with Redis distributed cache as the source of truth, which is preferable for allowing new nodes to be brought online and query Redis for their initial state.\nThe Redis based synchronisation of local in-memory caches would be used to prevent the nodes of a 'named service' repeatedly calling a service that was failing under high load and causing it to fail.\nIf Redis goes down / is not contactable, the nodes continue to use their local cached data, which would effectively mean the centralised control is automatically delegated to the distributed services, allowing them to act independently. When Redis is available again, they can be synchronised. This avoids creating a single point of failure.\nIndividually, they are also still managed by the Load Balancer determining their health and Circuit Breaker status. And the Traffic Manager above them, co-ordinates failover and optimised performance. Essentially you have a self-healing infrastructure.\nServerless\nA 'managed microservice' - think Azure Functions or AWS Lambda, which can then call whatever data store you want. As any session state I have is maintained in my client for many reasons including scale, I certainly don't want to corrupt that architecture by then managing a farm of Microservices that are simply there to maintain my Circuit Breaker State. \nSummary\nMy personal preference: just build a very simple interface for any Provider to implement: \n```\nCircuitBreakerState GetCircuitBreakerStateForService(string serviceName)\nvoid SetCircuitBreakerStateForService(string ServiceName, CircuitBreakerState state)\n```\nAnd then create an 'official' Redis Provider, and let the community create their own, for their specific scenarios. \nFor roll-your own approaches, the configuration of nodes, logic for any scenario specific rules that determine state (including reported failure ratios, whether a reported error on A categorically affects B, etc), can be passed into the Provider instance, but, should not be known to Polly, as they are, well, scenario specific and entirely optional.  It simply should not be part of core Polly Circuit Breaker.\nThe only thing that Polly Circuit Breaker would know is the serviceName, its State, and its corresponding Policy.\nPolly Circuit Breaker would still be highly relevant; I would look at using it to determine if a named service instance is able to connect to its database / storage / email backend, and report to Load Balancer / Traffic Manager etc that is alive and well, or failed. I would use a Circuit Breaker in my main application API to inform my UI if certain features are not available.  But, it would not be the only tool used to address resilience issues; IMHO it needs to have a clearly defined role, interface, and functionality, and I feel the proposals so far are perhaps over-engineered.\nJust my 2 centavos.. @reisenberger \nSeriously impressed with your explanation - I take my hat off to you... you've brought clarity to a subject that is tough to describe.\nPersonally, I had seen some very specific use-cases being discussed, that I simply would not encounter.\nBut to answer the specific question:\n\n@mcquiggd You are deeper into Azure than I: In the Azure IaaS environment, do you see upstream system behaviour as likely to be so consistent, that the risk can safely be ignored, or?\n\nWell, in the systems I typically use for my mission critical backends, you can 'planet scale' Cosmos DB as long as your budget lasts. You can autoscale your Redis cluster until your credit card melts. \nIf systems such as these, with millisecond failover times to geographically separate mirrors are not sufficient, a Polly circuit breaker with distributed state isn't going to add too much other than another point of failure. In the scenarios I described with Redis and a local cache, you have built-in resiliency for every node of every type of service.  I handle offline capability in my client, and attempt to resolve data issues when the system is available again.\nSo, I might pull back from this topic, however, as I don't want to muddy the water. Each of us will have our own requirements, I would just advise that whatever solution that is settled on, is as pluggable as possible, so users can make their own choice for simple, advanced, and industrial-strength SkyNet level resiliency of their circuit breaker state. Basically, let the users decided from all the options:\nSo, my vote is for (d) Only adapt Polly to allow injection of new circuit-breaker implementations.\n:)\nVery interested to see what others opinions are... the more eyes on this, the better... \n. To follow up the point, well made by @heneryville - Azure Durable Functions now offer state persistence and long-running lifetimes, with triggers to rehydrate, for example to respond to external processes calling back to continue a defined workflow. Microsoft are adding multiple persistence backends for Azure Durable Functions.\nThey could be considered to be a lightweight alternative to Logic Apps.\nPersonally I use them for executing other Functions in a defined order - their state is persisted automatically.\nPerhaps there are lessons we can learn from this approach.. ",
    "ranouf": "Hi @reisenberger ,\nDoes this code is valid? If not, do you have a valid solution available somewhere?\nThanks for your help\n\nprivate static readonly ConnectionPolicy ConnectionPolicy = new ConnectionPolicy \n{ \n    ConnectionMode = ConnectionMode.Direct, \n    ConnectionProtocol = Protocol.Tcp, \n    RequestTimeout = new TimeSpan(1, 0, 0), \n    MaxConnectionLimit = 1000, \n    RetryOptions = new RetryOptions \n    { \n        MaxRetryAttemptsOnThrottledRequests = 0, // was 10\n        MaxRetryWaitTimeInSeconds = 60\n    } \n};\nThen, I created a Polly Retry Policy, as follows:\nprivate static readonly RetryPolicy PollyRetryPolicy = Policy.Handle<DocumentClientException>(de => de.RetryAfter > TimeSpan.Zero).\n        Or<AggregateException>(ae => ((ae.InnerException as DocumentClientException)?.RetryAfter ?? TimeSpan.Zero) > TimeSpan.Zero).\n        WaitAndRetryAsync(retryCount: 3, \n                sleepDurationProvider: (retryAttempt, context) =>\n                {\n                    var retryAfter = TimeSpan.FromMilliseconds(10); // Should be 0? \n                    if (context == null || !context.ContainsKey(\"RetryAfter\")) return retryAfter;                       \n                    return (TimeSpan)context[\"RetryAfter\"];\n                }, \n                onRetryAsync: (exception, timespan, retryAttempt, context) =>\n                {\n                    context[\"RetryAfter\"] = (exception as DocumentClientException)?.RetryAfter\n                                            ?? (exception.InnerException as DocumentClientException)?.RetryAfter \n                                                 ?? TimeSpan.FromMilliseconds(1); //Just an arbitrary chosen value, never seems to be used\n                    return Task.CompletedTask;\n                }                \n        );\n. Hi, \n\nThanks @reisenberger.\nFor next one who are looking for a sample code:\nprivate readonly RetryPolicy _pollyRetryPolicy = Policy\n                .Handle<DocumentClientException>(e => e.RetryAfter > TimeSpan.Zero)\n                .WaitAndRetryAsync(\n                    retryCount: 3,\n                    sleepDurationProvider: (i, e, ctx) =>\n                    {\n                        var dce = (DocumentClientException)e;\n                        return dce.RetryAfter;\n                    },\n                    onRetryAsync: (e, ts, i, ctx) => Task.CompletedTask\n                );\nLet me know if you see something to improve :). ",
    "georgiosd": "And now I also see you can combine with Wrap(). doh. Sorry :). It does, thank you! I hadn't noticed the callback includes TResult.. Actually for the use cases I'm thinking about (cryptocurrency exchanges API), hitting the limit would be bad - the goal is to poll data as quickly as possible and if you get rate limitted there is a penalty that could make me miss an important event.\nMakes sense? :). Correct. The limits are published (though often inaccurately).\nIt is multi-threaded because there are several kinds of updates that need to happen at once (trade updates, account updates). I usually have an event loop running in a Task fetching each one. So the rate gate would effectively throttle the event loops.. Hey @reisenberger, thanks for checking in. \nI must say that this was a few months ago so my recollection is somewhat hazy - I remember that I was hitting the rate limits all the time and decided to print out the rate-limited timestamps of the requests and some of them were out of whack.\ni.e. let's say the fastest I can call the API is 2s, it would be like:\n2s\n1.99s\n2.01s\n0.5s\n2s\nYou get the idea. \nI tried to figure out what could be causing it but I couldn't understand what the code does, well enough.\nI also don't think your second point applies to my particular use case, it's much simpler than that. Basically there are 1-5 tasks/event loops that are running concurrently, making HTTP calls to the same API. I must be sure that a) none of them is allowed to execute faster than the permitted rate and b) there is some fairness in entering the critical section. Obvious, I guess, as you wouldn't want any of the event loops to \"starve\" (wait for ever or for a long time vs other event loops).\nMakes sense? Happy to provide any more details.. No problem! I forgot the mention the \"leak\" is that 0.5s delay amongst the pool of 2s ones.\nAnd yes, the RateGate was shared between event loops.. Hey @reisenberger - I resurrected the project that needs this so I was just wondering whether this is on the roadmap somewhere? :). It's not my core strength (which is why I wasn't able to find what was wrong with the RateGate and fix it, in the first place) but if you can help out with the actual logic, I'd love to contribute.. If you have give me some steps/implementation guidance, I can give it a try!. Im not so much worried about how you make a policy but rather about how you\nmake a reliable rate limitter of this kind :)\nOn Wed, 2 Aug 2017 at 01:04, reisenberger notifications@github.com wrote:\n\nHi @georgiosd https://github.com/georgiosd . The best way to see the\narchitecture of how a new Policy is implemented is look at the shape of the\nfiles making up the NoOpPolicy (and its tests). NoOpPolicy is just an\n(intentionally) empty policy which does nothing, so that shows you the bare\nbones structure you would start with ... for adding a new policy.\nhttps://github.com/App-vNext/Polly/tree/master/src/Polly.Shared/NoOp\nhttps://github.com/App-vNext/Polly/pull/214/files\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/260#issuecomment-319510421,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABmDdkU5BqMugQHJYr-GdZ1G6TTKwH_9ks5sT6DQgaJpZM4N8f9P\n.\n. \n",
    "futugyou": "my mistake...use   WaitAndRetryAsync   and ExecuteAsync . ",
    "Kesmy": "All of the projects can be upgraded to the new format, except PCL.Specs. Do you really want to only upgrade one of them?. Build and test issues should now be fixed, though it appears the build server can't locate msbuild.. @reisenberger I can't get tests passing on my machine with the netcoreap1.1 re-target.\nIt looks like that will also require more substantial changes to the build, including adding dotnet build/dotnet test steps specifically for the re-targeted Specs project. I'm not terribly familiar with Cake or Appveyor, so I'm not sure exactly what will need to happen to get dotnet tooling running.\nI'm not averse to giving it a shot, but I don't know if it belongs in this PR given that updating the project formats have so far required no code changes.\nNote that the netcoreapp1.1 retarget was just a test. I'm not familiar enough with the differences between the various \"new\" .NET targets to make any educated suggestions about which one is most appropriate.. @reisenberger It turns out that I completely overlooked the CollectionBehavior attribute that is decorating PCL.Specs. I've added it and tests now pass.\nI suddenly have a lot of free time on my hands, and will see about updating the Cake script to handle the netcoreapp tests tomorrow, then will push again.. @reisenberger If you have no reservations with targeting netcoreapp1.1 in specs, this should now be ready to go.. @paulomorgado @reisenberger I noticed this was up-for-grabs and branched off of v704or710.\nRan into a couple minor issues\n\nowner is not available in the csproj nuget properties, it inherits from Authors. Should the new Authors be App vNext to match the csproj, or Michael Wolfenden, App vNext to match the nuspec?\nSince SourceLink is still prerelease, is 1.0.0-beta2-18618-05 or 1.0.0-* preferable?. I see both sides of the argument (and didn't even realise that GeneratePackageOnBuild was a thing, so thanks @phatcher !)\n\nI like the idea of eliminating a big chunk of a build script, but I think at the end of the day, I prefer the hard-block on test failures.\n\nOn a related note, the package restore step can be removed, and the build can automatically restore, but that change may not belong here (and is going to be similarly opinionated).\n. Thanks for the quick responses.\nUpdated the Authors, will leave the restore step alone. That will be consistent with independent build/test/package, and may make it easier to differentiate between types of error in a build.. @reisenberger Hmm... apparently I can't mark this PR Ready for Review, there's no button for it... can you see if there's one on your view?. @reisenberger Sounds great to me, thanks.. @reisenberger I'll shift these changes over to v710 this evening (leaving this to  confirm that I saw your message).. Abandoned for #616 to retarget. ",
    "Matthewsre": "Just came over to request this feature and see it is already on the roadmap. Would love to see this implemented.. ",
    "phatcher": "Just chipping in with a couple of thoughts...\nBasically this looks to me like a classic producer/consumer pattern i.e. we have requests arriving at some rate and they can either be executed immediately or they need to be queued up since we are in danger of breaching the rate limit.\nOne open question is do we regularise the flow i.e. constant time between each request or do we let them flow as fast as possible until we get close to the limit.\nThis seems to be the token bucket/leaky bucket concepts.\nThere's a C# implementation of this at TokenBucket which I think could be adapted to this purpose - might be more than one policy depending on what behaviour you want e.g. discard silent, discard but throw etc, etc. @reisenberger Have a look at https://github.com/Humanizr/Humanizer, they have successfully implemented GitLink and it works nicely. You can avoid dotnet pack entirely if you put a <GeneratePackageOnBuild>true</GeneratePackageOnBuild>in the project files. Dylan\nThanks for the response. I'd followed Scott's blog posts and as I'm currently writing some new microservices in ASP.NET Core 2.1 I thought I'd use Polly rather than my current hand-rolled implementation of retry/caching\nSo my current implementation normally has something like this...\n\nIFooService : The service interface\nFooServiceClient : Client implementation that talks over http\nCachingFooServiceClient : Caching implementation that takes a IFooService and a cache implementation\n\nWhat I think the new architecture looks like is\n\nIFooService : Same as before\nFooServiceClient : Same as before but configured via Polly to have appropriate retry/timeout/circuit-breaker policies\nFallbackFooServiceClient : Delivers data/response in case of service failure, basically a null object pattern in case of get and a wrapped exception in the case of put/post\nPolicyFooServiceClient: Takes two IFooServices and wraps with with cache/fallback policies\n\nThis then isolates most of the front-end from service failures and it can decide what to do when presented with the null object.\nThe data we are presenting changes relatively infrequently but it's important to present new data when it does arrive, so I can also see some interesting use cases for a two level cache; one that has the normal expiry and another with a long timeout which is used when the service call fails instead of a null object response.. ",
    "darxis": "@reisenberger Thanks, this is what I was searching for!. ",
    "sledoux": "Hi @reisenberger,\nBeforehand, thank you for your answers. \nReading your first comment, I don't see a method signature to pass a context to the FallBackAction of a FallBack policy. Since the FallbackAction cannot take a parametized Func or a context, it's useless to combine it with a CircuitBreakerPolicy through a PolicyWrap, which would have been very nice. The idea would be to handle the CircuitBreakerOpen exception at the fallback policy, only switching to fallbacks when the circuit is open. This would avoid a spam on endpoints which are down for a long period of time, but scaled horizontally with multiple fallbacks for a good resilience.\nThe retry does have a context on the action called though so I could use that to act like a fallback with a retry count of 1. The hard part is to make this dynamically extending like you mentionned, although possible. \nFor now, the option that would fit our need would be to create one CircuitBreakerPolicy per item we have in a list. Wrapping that in a retry policy and using the onbreak call to cycle through the list of item like you mentioned in #199.\nLooking at your proposal for the FailoverPolicy (https://github.com/App-vNext/Polly/wiki/Polly-Roadmap#failover-policy), this looks exactly like what we need, combining that with circuit breakers! We would prefer that approach over the previously mentioned one by far. Also, the possibility to manually fail could be very useful.\nHope to see this soon in a release of Polly.. @reisenberger I might give it a try soon, when I get time.. ",
    "grokky1": "Thanks for the detailed info!\nA wrapped policy's lack of support for ExecuteAndCapture/Async() is confusing... Supposing my DoSomething() returns void:\ncsharp\nawait policy.ExecuteAsync(() => DoSomething());\nSo I don't know whether the policy passed/failed, because there is nothing similar to PolicyResult.Outcome. Is there a way around this?. Okay that try-catch approach makes good sense!\nI had to change it a bit, specifically to rethrow the exception from onFallback/Async:\nonFallback: (exception, context) => { /* do something here */; throw exception; }\n\nand later when executing the policy:\ntry {\n  policy.Execute(() => DoSomething());\n  // if we get here, then it succeeded\n}\ncatch {\n  // if we get here, then it failed\n}\n\nSo for the above to work the exception must be rethrown.\n\nEDIT: Ok I see now what you did. Instead of throwing the exception again as I did, you detected the success/failure in the fallbackAction delegate instead. Much neater, but on the other hand, you need to capture the success/failure inside the policy, whereas my way you can run the execution elsewhere. After going through all this, it's worth revisiting the original point. Take into account I'm new to Polly, so maybe my opinion doesn't count, but on the other hand, I'm new to Polly so I'm looking at things differently.\nI simply want to log failures (including the last one), e.g.\nWarning: service foo failed (1 of 5).\nWarning: service foo failed (2 of 5).\nWarning: service foo failed (3 of 5).\nWarning: service foo failed (4 of 5).\nError: service foo failed (5 of 5).\n\nI get what you said about it being more powerful to combine policies. So to detect all the failures, I need to add a fallback policy. And to know whether the overall thing succeeded, I need a try/catch as you explained (because ExecuteAndCapture doesn't work). All this works, but looking at this thread, it's messy.\nSo for this very simple and common use case, to detect the state I'm interested in, I need to combine policies - but that's overkill. It's much cleaner to have an onLastFailure delegate (or something similar, I don't know what would be the best approach, perhaps a single delegate which is guaranteed to be invoked after every failure, or after every attempt). Design-wise / semantically, what I want is to run a retry policy, not a retry and then fallback policy, to give me the semantics of a retry policy.\nNot trying to be argumentative, just my 0.02 which you can ignore. This library is great!. Yeah I peeked into the source and saw the staggering number of overloads! \ud83d\ude04 I agree that adding more would just make it harder to maintain.\nGlad you agree with some of my points though. Hopefully in the future we can work around such issues. Until then I've used your workaround to great effect. Thanks again.. Your proposal makes sense without modification.\nHowever, to address the issue of \"which policy does the result relate to\", what about this option:\n- Provide direct access to the failure info of the outermost policy, as you've explained, AND\n- Include a dictionary which has failure info for each policy, where the key is the policy type or the exception type (or something like that).. That sounds really useful. Looking forward to the next version!. ",
    "PilchardFriendly": "Thanks for the reply.  I agree that I'm describing things in the reversed fashion. \nIn this case reverse is exactly what i want. An open circuit is healthy, as it means I had a successful health check in the last duration, and don't need to check health again.  A closed circuit to me means the health check failed, i need to reconnect, and retry check for health again.  \nI've implemented this and it works fine. I occasionally get false positives, when the circuit is open, but the service is failing.  But I can handle those with retries/timeouts.\nSo, in this case - onReset means my health check failed.\nBut my question hasn't changed.\nHow do I tell the difference between a transition from closed->open and from half-open->open?. That's an awesome reply.  Thankyou.\nI've written up something like this:...\n```\nprivate static readonly object CircuitOpen = new object();\nprivate static readonly object CircuitClosed = new object();\nprivate static void DeDuplicate(ref T monitor, T t, Action act) where T:class\n{\n     var last = Interlocked.Exchange(ref monitor, t);\n     if (!ReferenceEquals(last, t)) act();\n }\n// For each circuit breaker\nprivate object _livenessUpCircuitState;\nvar breakServiceWhenLivePolicy = Policy\n    .HandleResult(true)\n    .CircuitBreaker(\n        handledEventsAllowedBeforeBreaking: 1,\n        durationOfBreak: TimeSpan.FromSeconds(1), \n        onBreak:(result, span, ctx) => DeDuplicate(ref _livenessUpCircuitState, CircuitOpen, () => Logger.TraceInformation($\"{ctx.PolicyKey} open\")),\n        onReset:(ctx) => DeDuplicate(ref _livenessUpCircuitState, CircuitClosed, () =>  Logger.TraceWarning($\"{ctx.PolicyKey} closed\")))\n    .WithPolicyKey($\"{policyKey}:live-up:circuitBreaker\");\n```\n. ",
    "johanna-bodnyk": "Thanks for considering and for the explanation, that makes lots of sense!. ",
    "markrendle": "@reisenberger Cool cool cool.\nI was considering both aspects, the internal and external code. For the user-facing API, it should be as simple as offering overloads of the various methods that take delegates with additional parameters, and arguments for those parameters. My only slight concern there is the interaction with the existing overloads that take a Context and CancellationToken, but my brief sandboxing suggests it should be reasonably straightfoward and the C# compiler will hit the right overloads. The biggest issue there is you get to the point where you might want to code-gen the generic parameter overloads, from Func<T1,TResult> to Func<T1,...,T8,TResult>.\nOn the internal code I think it's more of a hunt-and-pick process, once the basic library code is in place.\nLike I say, I'm very happy to pitch in PRs if issues are opened with up-for-grabs labels.. ",
    "grant-d": "Here's a similar example I came across. I believe this would be better served as a DoNothing method, which would have less runtime overhead:\n```csharp\npublic static RetryPolicy WaitAndRetry(this PolicyBuilder policyBuilder, ...)\n{\n    Action, TimeSpan, int, Context> doNothing = (, __, , ) => { };\nreturn policyBuilder.WaitAndRetry(retryCount, sleepDurationProvider, doNothing);\n\n}\nShould be:csharp\npublic static RetryPolicy WaitAndRetry(this PolicyBuilder policyBuilder, ...)\n{\n    return policyBuilder.WaitAndRetry(retryCount, sleepDurationProvider, DoNothing);\n}\nprivate static void DoNothing(\u2026) { }\n```. That's a good idea, I will wrap some of the other strategies too . I had a thought. If we add more 'sleep duration providers', then we could formalize the pattern as follows. The benefit is that we can then provide a host of duration providers, and the pattern protects the user from calling '.Create' at the wrong time.\nIt is also amenable to unit-testing and DI (thus, policy libraries)\n```csharp\n    public interface ISleepDurationStrategy // naming TBD\n    {\n        int RetryCount { get; }\n    // For when IEnumerable<TimeSpan> is needed\n    IEnumerable<TimeSpan> Create(Context context = null);\n\n    // For when Func<int, Context, TimeSpan> is needed\n    TimeSpan Next(int i, Context context = null);\n\n    // etc\n}\n\npublic sealed class DecorrelatedJitter : ISleepDurationStrategy\n{\n    // Implementations per initial post above\n}\n\npublic sealed class ExponentialBackoffProvider : ISleepDurationStrategy { }\npublic sealed class ConstantBackoffProvider : ISleepDurationStrategy { }\npublic sealed class MyCustomProvider : ISleepDurationStrategy { }\npublic sealed class NoOpProvider : ISleepDurationStrategy { }\n\n// Additional overloads/extensions on Policy/Builder (only showing two)\n\npublic static RetryPolicy<TResult> WaitAndRetryAsync<TResult>(\n    this PolicyBuilder<TResult> policyBuilder,\n    ISleepDurationStrategy sleepDurationStrategy) // Note param\n{\n    var sleepDurations = sleepDurationStrategy.Generate(); // Note call to .Generate\n\n    return policyBuilder.WaitAndRetryAsync(sleepDurations); // Existing IEnumerable<TimeSpan> overload\n}\n\npublic static RetryPolicy<TResult> WaitAndRetry<TResult>(this PolicyBuilder<TResult> policyBuilder, int retryCount, ISleepDurationStrategy sleepDurationProvider)\n{\n    Action<DelegateResult<TResult>, TimeSpan, int, Context> doNothing = (_, __, ___, ____) => { };\n\n   return policyBuilder.WaitAndRetry(retryCount, sleepDurationProvider.Next, doNothing); // Existing Func<int, Context, TimeSpan> overload\n}\n\n```. >  If we do this, it would be make sense to (trivially) do some of the other IEnumerable patterns (like straight ExponentialBackoff) as convenience helpers too\nI have created a PR #536, please see latest code there. George, would you mind trying your experiment with the Random taken out of the method and rather declared as a private static readonly Random on the class? That way we share it across concurrent retries so won't get the same seed (Datetime.Now.Ticks) . It would be interesting to see how the graph compares. \nAlso, see my abstraction in #526. If you are perhaps willing to use it in your test harness? Note that it too should be instantiated as a shared singleton, with each retry calling the factory Create method on it. See the sample code. . TLDR; I agree with George - the guidance in the wiki is not optimal. It can lead to bad performance characteristics. Which is further evidence for my suggestion to include a formal jitter in the box (#526).\n@george-polevoy, my concerns are not just a preference; my suggestion is that it may be the case that instantiating Random inside the method is also somewhat of a bug, perhaps leading to the correlations you're seeing in the decorrelated.jitter results. Random should be an external singleton.\nThere's probably further correlation due to the use of Guids as a source of (seed) randomness. Guids are built to be unique not random (there is a difference: the monotonic sequence 1,2,3,... is guaranteed unique but certainly not random). \nBoth your advanced and decorrelated.jitter test results will probably improve further if you move Random outside the method (we'll need testing to prove the degree of improvement)\n```csharp\n[ThreadStatic] // Added, per George's observation re: thread safety\nprivate static readonly Random r = new Random(); // Shared Random between all concurrent executions\nIEnumerable DecorrelatedExponent()\n{\n    // code that uses 'r'\n}\n```. > I'm using a random seed from Guid.GetHashCode\nOnce again, your source of randomness is not random - see my notes above, and see the first code snippet here, where your pattern corresponds to the warning he has in that code. \nGuid.NewGuid().GetHashCode() is not random. Uniqueness and randomness are different things:\n  1,2,3,4,5,6,7...  Unique, not Random\n  1,2,1,1,1,2,1,2,2,2... Random, not very Unique\nGuid.NewGuid() is, in principle, more similar to the former than the latter.\nTaking a hashcode of it makes it even less random, since you've compressed the domain to 32 bits.\n(You are correct that I forgot the [ThreadStatic] attribute. Code sample updated). Thanks @reisenberger, I have used the various thread-static approaches but the locking one is interesting; I would not have expected to see advice to lock a primitive like Random in high-concurrency scenarios but in some ways it makes sense. \nThe [ThreadStatic] approach will work fine for the tests but if we ship these changes then we should noodle on which approach to use for the long-term.. Agree - my code has a slightly different implementation to the wiki too, though I am still refining it. I am curious to compare it with yours, please do post it as soon as you are ready.. [Edit: This is stale - see related PR for correct algorithm]\nFor reference, here's my code:\n```csharp\n            double range = MaxDelay.TotalMilliseconds - MinDelay.TotalMilliseconds; // Range\n            for (int i = 0; i < delays.Length; i++) \n            { \n                double ms = range * _random.NextDouble(); // Ceiling\n                ms += MinDelay.TotalMilliseconds; // Floor \n            delays[i] = TimeSpan.FromMilliseconds(ms); \n        }\n\n``. Very nice, I like how clear the AWS clamping problem is (glad we fixed that).\nIs your aim with the other algorithms to include them in the library? If so I have no problem with that, I thinksoftexp` is particularly interesting.\n. > Stochastic algorithms approach\nSorry George, I don't understand what you are getting at in the last paragraph, would you mind explaining again?\n[Edit]: OK, I think I understand. You're saying no need for 'MinimumDelay' in this scheme, rather just retry somewhat immediately?. That sounds like a great idea, thanks for thinking through it in such detail. The only request I'd make is to that the name is a mouthful, I wonder if there is something more concise.  Polly.Contrib.WaitAndRetry or .Backoff or the like . Appreciate your humbleness but your involvement is critical to he success of contrib. My submission is much improved after your input. So you 'getting out the way' is not on my priority list.. > which params should sit in the ctors, and which in the [methods]\nAgree. I went back & forth on that many times. I tried to balance which would be 'constant' in a policy library, and which you would want to change on each instantiation. I ended up with the latter having count being the minimum requirement, but we can move nearly all the other params there too. It doesn't have a clear answer; both are suitable in different circumstances. Let's chew on it some more.. > This is not as risky as that note may suggest\nThanks @reisenberger, that's a fair point. In a previous incarnation of the code, I was eagerly generating the durations into a TimeSpan[] array, so it was reified once and only once. I wasn't thinking straight when I made that note, since I had subsequently backed down from that and used yield instead.\n\nI pushed an extra test to the PR\n\nAwesome, thanks for doing that. \nAny more thoughts on params vs DI. If not, can we consider merging? We can then push some of @george-polevoy's new algos (https://github.com/App-vNext/Polly/issues/530#issuecomment-441740575) afterwards.. @reisenberger, sorry I somehow missed some of the changes you requested last week. I have attended to all of them this morning. I think there may be a couple outstanding but I am having trouble navigating to find them, let me know.. > Yes, just the params issue to come back to\nHere's an idea. What if I push a version of the code that has an 'all params' approach. We won't keep both versions, but then it's easier for us to compare & contrast.\n[Edit] Pushed. See CR comments. > can be enumerated multiple times, giving different randomised results \u2026\nI thought about this some more. I think the above would only work in serializable contexts. What would be our guidance when users try to use a shared (eg reified singleton) strategy in concurrent scenarios. In that case you'd need a distinct enumerator per context.. > this will be fine whether different enumerations of the enumerable are executing serially or in parallel/concurrently ...\nYou are right, I couldn't recall whether the generated state machine was per-execution or not. I convinced myself using the following code (and associated unit):\n```csharp\n            const int count = 10;\n            DecorrelatedJitterBackoff durationStrategy = new DecorrelatedJitterBackoff(TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(3));\n        IEnumerable<TimeSpan> generate = durationStrategy.GetSleepDurations(count);\n\n        var tasks = new Task<TimeSpan[]>[100];\n        var start = new ManualResetEvent(false);\n\n        for (var i = 0; i < tasks.Length; i++)\n        {\n            var tcs = new TaskCompletionSource<TimeSpan[]>();\n            tasks[i] = tcs.Task;\n\n            var thread = new Thread(() =>\n            {\n                start.WaitOne();\n                tcs.SetResult(generate.ToArray()); // Every thread enumerates the singleton\n            });\n            thread.Start();\n        }\n\n        start.Set(); // Unleash the fury\n        Task.WaitAll(tasks);\n\n        tasks.Should().NotContain(n => n.IsFaulted); // All passed\n\n``. Sorry, been snowed under at work, will try get to this this week. Sorry for the long delay, I should have more time now.\nI have implemented the factory methods as discussed, including sample units so you can get a feel for the call-site shape.\nYour a) vs b) choice is interesting. Considering the semantics ofIEnumerable, it may be sufficient to go with b) for what we need. Would you still propose a separate (static) class per strategy?. Regardingcorevscontrib. I don't mind either way except for the risk that othercontribsI have used in the past have become ill-maintained and/or runaway trains, filled with everyone's favorite idea. As long as we curate both repos strictly, I think we should be fine.. @reisenberger any news on the plans here . Cool. My personal feeling is that class calledAlternativeis the best approach. I have used such a pattern with Polly in my own code recently, and it's clean. . I have **only overloaded one method** using the new interface, in order to show the potential pattern.\nIt usesISleepDurationStrategyinstead ofIEnumerable. \nIn other words, I copied the method above (which usesIEnumerable) and refactored it to use the new interface instead.\nThe same applies to the other new overloads. And then calls the existing overload that handles theIEnumerable.\n(My integration is bad here - converting to.ToArrayis high overhead. We should just pass it into a suitableIEnumerableoverload). Newnamespace. Happy to change if necessary. Happy to discuss a better name if necessary. Note that we don't have to implement _any_ of these functions yet. We can provide the strategies and let consumers use them directly to generateTimeSpanseries with which they can call the existingIEnumerableoverloads. See example in PR notes.. Per separate discussion, here's thelock-controlled instance ofRandom. Notelockaround the (only) method we expose. No actual changes here, this is just my over-eager formatting config. Here's where it _pre-generates_ theTimeSpanseries. Lots of units. Note howretryCountis not aproperty(ie passed in thector) but aparam. \nI used to have it as a property but I thought that making it a param would let you reuse the strategy and call it with different counts. See the example in the PR notes.. The last paramrandomis there for determinism and/or unit testing. You may want a specific seed or you may want a repeatable sequence (as you often do in units). This method is meant to be used in theForever()methods.\nIt produces an expected series ofTimeSpanvalues for the firstretryCountiterations, and thereafter 'forever' returns themaxvalue it found in that sequence. . Per decision in previous comment, we won't be integrating new overloads for now. Per decision in previous comment, we won't be integrating new overloads for now. Done. Good idea, will leave as-is for now. Agree - I like cutting scope too; it can be painful but then you don't end up with a spaghetti api after. OK, I like the first permutation;ISleepDurationSeriesStrategy.\n. Added in all locations (not sure ifworks yet?). Nice catch, that is indeed redundant, removed. Fixed. Removed. Done. Agree. Should we make the same change onExponentialBackoff?\nIt's a little more ambiguous there, since it is indeed the initial-delay, but it's also the key factor in the exponential calculation. Let's see what @george-polevoy comes back with on his modeling experiments. If we follow the AWS paper then the current algo is correct, but I also noticed the high occurrence ofmaxin the output. Let's discuss some more. Actually, I take that back. I like your variant better than mine, and it does not stray from the paper. Done.. I am now debating that, in the absence of the integration overloads, whether we need to make this interfacepublicanymore. If we made itinternalit would be less api noise. But in that case consumers would not be able to write their own extensions over _every_ concrete class. For example, a consumer would _not_ be able to write aContinuousextension like I had previously.\nSo maybe it's good to keep the interface public?. I may create a separate PR for that, since while working on this PR I built a much more feature rich decorator for random, that exposes both Uniform and Gauss distributions (via Box-Muller).\nI wonder if it's worth waiting for that so that we can use it here without breaking interfaces later. . Thought about it some more. It needs to bepublicfor the reasons outlined above. Scratch that. I don't exposeRandomanywhere right now, so we won't break abstractions later. . Decided to make the same change onExponentialBackoff- it's more consistent. Fixed. Fixed. Ah, good point. Fixed. Agree. Fixed. Agree. Fixed. Done. I like that. I had previously gone through several name changes,Generate,Create,Build, etc. Your suggestion is clean.. Done. Agree. Added an explicit factor, so that you are not limited tox2. Moved this into its own file, we may need to call it from other places.. This is the **alternative experimental api shape**. \n* We'd need this static class that holds the methods, called saySleepDurationSeriesStrategy. \n* We would deleteISleepDurationSeriesStrategyand all its concrete classes, since theinterfacewould have no purpose (it would be a marker interface only)\n* We would add the different sleep duration methods shown below. Almost like a set of extensions, but no obviousthis` to hang off of.\n* See the single unit that I updated with these changes to show what the call sites would look like.\nPros: Less cruft. Call site params can vary easily. Might have better concurrency semantics.\nCons: Less encapsulation. Not sure if/how policy library would now work.\n(Please focus on api shape for now, not on comments, etc). Here's the single unit updated to align with experimental api shape. OK, per comment at the bottom of the conversation thread, I have implemented 2) on each strategy.. Here's the option where we have static methods returning IEnumerable only. Sample callsite for static instantiation. Sample callsite for factory instantiation. Here is the new factory method. ",
    "rjongeneelen": "See Pull request #303, ready for review. See Pull request #303, ready for review. Please see pull request #299. Note that I have made more changes than this Issue suggested:\n- The constructor access modifiers for Policy have been changed to protected (public is not needed)\n- Some properties of Policy have been made public as they are commonly used to instantiate policies\n- Almost all properties/methods of Policy have been made virtual, so they can be overridden in a derived Policy\n- Some external properties (PolicyBuilder) and delegates have been made public as they are commonly used to instantiate policies\nI've added comments for the newly-public constructors/methods/properties.. @udlose Agreed, but this is how it is currently setup. \nImho, I believe if you are architecting your own solution with the ability to swap the 3rd party API (Polly) out at any point in time, which is a great idea obviously, then you'd probably have to create an abstraction for the concept of 'policies' for your own application, e.g. a policy provider with a specific implementation that uses, and optionally implements additional, Polly policies.\nMy 2 cents.. - Used interfaces throughout PolicyWrap logic, this required splitting some methods as well whenusing IsPolicy\n- Extended ISync/IAsync interfaces with access to Predicates + made those delegates public\n- Rewrote PolicyWrap static Wrap/WrapAsync methods to stop making use of Policy.Wrap() methods, since this would require making PolicyWrap public as well, which seems unnecessary and unwanted. It also removes PolicyWrap-specific logic from the Policy class\n- Changed static Success/Failure methods of PolicyResult to public, to enable instantiation from a derived policy. @reisenberger Not sure why the build fails, looks like a generic build error, rather than related to my changes?. Ready for review. I don't believe PolicyWrap is exposing its inner policies, and I don't believe it should. In the end, it's just a new policy itself, which (recursively) wraps existing policy instances.\nIf I understand your use case correctly, the FallbackPolicy instance is the actual object you want to access. Personally, I guess it shouldn't matter if it's wrapped or not, or even if it's re-used at many different locations. So rather than trying to find the policy through a PolicyWrap, I would suggest keeping track of the FallbackPolicy itself, regardless of where it's used.\nPerhaps you could use the PolicyRegistry and register the FallbackPolicy instance by name? Especially when using the PolicyRegistry in combination with DI, you could easily use the registry to find and access specific policy instances from anywhere within your application.\nJust my 2 cents.. Yes sorry, I meant to say CircuitBreaker policy, not Fallback policy.. Just like in PolicyWrapAsync.cs, there should be 3 variants:\n1: ..., ISyncPolicy outer, ISyncPolicy\\<TResult> inner)\n2: ..., ISyncPolicy\\<TResult> outer, ISyncPolicy inner)\n3: ..., ISyncPolicy\\<TResult> outer, ISyncPolicy\\<TResult> inner)\nAs you mentioned in your next review-comment below, I accidentally forgot to split up 2 and 3, I have pushed the changes to commit b3cc1a7.. Good observation, thanks!\nJust like in PolicyWrapAsync.cs, there should be 3 variants:\n1: ..., ISyncPolicy outer, ISyncPolicy\\<TResult> inner)\n2: ..., ISyncPolicy\\<TResult> outer, ISyncPolicy inner)\n3: ..., ISyncPolicy\\<TResult> outer, ISyncPolicy\\<TResult> inner)\nI will split up the IsPolicy into 2 and 3, which also aligns it with the changes made to PolicyWrapAsync.cs.\nI have pushed the changes to commit b3cc1a7.. In the old code, the enumerable already was converted into an array when passing it as argument to the policies.First().Wrap(...) method. All I did was move the ToArray to an earlier moment, to prevent both the Count() and the ToArray() to navigate through the enumerable. It should result to less overhead rather than more.\nIf we want to remove the ToArray, I reckon these type of performance improvements should be part of a separate pull request?. See above. See above. ",
    "hambudi": "I changed the base branch.. When an exception is thrown inside the task, that exception is wraped in an AggregateException when we use Task.Wait().\nIn this scenario the AggregateException will always have one inner exception. The inner exception itself can always be an AggregateException with multiple inner exceptions.\nThis will happen if delegate itself throws an AggregateException with many inner exceptions and I dont want to mess with that in this change. The intention is only to preserve the exception behaviour of the delegate and remove the inconsistency with running it inside a task.\nThis is also the reason that I am not use .Flatten(), as that would change the exception thrown by the delegate.\n. I have not, based on my reading I understand that the stacktrace will be reset every time we use \"throw ex\" command and inorder to not reset the trace we have to use throw. \nI dont think using throw is possible here.\nI will test it out and see if the stacktrace is being reset and reply back here.\nEdit: Looked like i didnt read enough. There is a solution for this here https://stackoverflow.com/questions/57383/in-c-how-can-i-rethrow-innerexception-without-losing-stack-trace\nI will fix this and add tests in an update.. I have added these.. I am currently working on adding tests for verifying the stacktrace. I was wondring if you want me to include #280  in this PR or would you like to check that in and then have me rebase?. ",
    "subatta": "Thanks @reisenberger : I'm looking for a retry until a condition is satisfied on a request not using an exception generic. For example, the following Policy usage retries with a wait until the status is Ok.\n.HandleResult(r => r.StatusCode == HttpStatusCode.Ok)\n.WaitAndRetry(...). Thanks a lot @reisenberger . The use of this pattern is for Integration tests right now. I didn't look, I assumed (erroneously so) that the Handle: T is an exception since that's what all samples show. \n.HandleResult<bool>(false) is exactly what I was looking for.\nI'm glad we picked Polly and kudos to you and all developers! \n. @reisenberger : quick question. How do I evaluate async predicate like HandleResult(myAsyncFunc)? Doing a HandleResult(myAsyncFund.Result) is blocking the policy.Execute indefinitely (likely a deadlock underneath).\n. Sure @reisenberger: In an integration test, for example, messages are put on a bus and test executes remote(HTTP) calls few times until a max timeout is reached to check on a result. One of the conditions of evaluating success is looking into the HttpResponseMessage content which is accessible with async methods. \nThat evaluation within something like \nHandleResult<HttpResponseMessage>(r => r.Content.ReadAsAsync<MyType>().Result.Any())\nis where things get into trouble.. Definitely, an example would be fantastic @reisenberger.. Sure. Here it is:\nvar retryPolicy = Policy\n         .HandleResult<HttpResponseMessage>(\n    r => r == null || !r.IsSuccessStatusCode|| !r.Content.ReadAsAsync<IEnumerable<MyType>>().Result.Any())\n         .WaitAndRetry(5, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));\nvar response = retryPolicy.Execute(() => apiConnector.ExecuteAndReturnResponse(\"/api/endpoint\"));\napiConnector.ExecuteAndReturnResponse is a wrapper around HttpClient.\nThe expectation is that the retry will happen based on WaitAndRetry configuration until max attempts are reached or until the condition specified in HandleResult() is met.\nPerhaps the condition evaluation can be done via Execute() (or the async ver), that'll be what I'm looking for.. You're right there's no async overload for the HttpResponseMessage ExecuteAndReturnResponse(string url). I'd like to know the solution that is feasible while being minimally invasive. By that I mean, changes on your side, my side, in that order. :-). Yes, it's a GetAsync(url).Result. . Thanks, @reisenberger. My initial thought when I had deadlock issue is to have async tests which solve the issue like you outlined above. Unfortunately, we use MSTest which doesn't support async void type of tests. I guess limitations exist at several fronts on our side that need addressing.\nThanks a million for your help!. ",
    "tucaz": "Hi @reisenberger! I'm sorry to revive this thread, but I'm facing a situation close to what you guys talked about and I can't get your sample to work in any way.\nHere's what I'm trying to build on top of your example:\n```csharp\nusing System;\nusing System.Collections.Generic;\nusing System.Net.Http;\nusing System.Threading.Tasks;\nusing Backend.PayPal;\nusing Polly;\nusing Xunit;\nusing Xunit.Sdk;\nnamespace Scripts\n{\n    public class PollyTest\n    {\n        [Fact]\n        async void MyTest() // assumption: your test framework and version supports async test methods\n        {\n            var retryPolicy = Policy\n                .HandleResult(false)\n                .WaitAndRetryAsync(5, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));\n        var client = new HttpClient();\n\n        await retryPolicy.ExecuteAsync(() =>\n            client.GetAsync(\"https://google.com\").ContinueWith(t => t.Result.ResultContainsAny<MyType>()));\n    }\n}\n\npublic static class Foo\n{\n    public static async Task<bool> ResultContainsAny<MyType>(this HttpResponseMessage r)\n    {\n        if (r == null || !r.IsSuccessStatusCode) return false;\n        var readResult = await r.Content.ReadAsAsync<MyType>();\n        return readResult != null;\n    }\n}\n\n}\n```\nThe only change I would need is to actually get the HttpResponseMessage from the successfull Polly call.\nRight now I'm getting:\nPollyTest.cs(24, 17): [CS0029] Cannot implicitly convert type 'System.Threading.Tasks.Task<System.Threading.Tasks.Task<bool>>' to 'System.Threading.Tasks.Task<bool>'\nand\nPollyTest.cs(24, 17): [CS1662] Cannot convert lambda expression to intended delegate type because some of the return types in the block are not implicitly convertible to the delegate return type. ",
    "Im5tu": "I would definitely agree that uniformity is a good thing between the api's, I suggest the approach:\n1 - Add in the new apis (in vnext)\n2 - Mark the existing apis as obsolete, linking to this discussion and/or a fix (in vnext)\n3 - Remove the obsolete apis post vnext\nThis gives users some time to transition and makes the experience better overall. I wouldn't keep the old API around for very long as it will hamper productivity of new features etc.\n+1 for immutability being enforced. ",
    "brianfeucht": "Is it possible to split these apart so that you can enforce that async policies are used with the ExecuteAsync method at compile time vs execution time?  \nSeems like this approach would create only breaking changes in places where execution would fail at run time anyways.  Trying to unify the two together seems like it will be a pretty big code change for anyone upgrading.\nI'm 100% for breaking changes if it means I can get feedback about API miss use at compile time vs run time.  . ",
    "ohadschn": "@reisenberger remembering to do ISyncPolicy policy = Policy.Handle<Exception>().Retry(3); is just like remembering not to do ISyncPolicy policy = Policy.Handle<Exception>().Retry(3).ExecuteAsync(...).\nWorse, there is nothing stopping me from doing IAsyncPolicy policy = Policy.Handle<Exception>().Retry(3). IMHO having Policy implement both ISyncPolicy and IAsyncPolicy does more harm than good.\nA true compiler guarantee would have Retry and RetryAsync returning different and distinct interfaces, so you couldn't make such a mistake even if you wanted to.. @reisenberger understood, thank you for explaining. Perhaps something to consider for the next major version (in which breaking changes are fair play).. ",
    "dustyhoppe": "Re: They syntax proposal around merging async/sync support\ncsharp\n.WaitAndRetry(int retryCount, Func<int, Context, TimeSpan> sleepDurationProvider)\n    .OnRetry(Action<Exception, TimeSpan, int, Context> onRetry) // optional postfix configuration step\n    .OnRetryAsync(Func<Exception, TimeSpan, int, Context, Task> onRetryAsync)\nI'm a fan of this ^^ proposal.\nRe: How would state-change delegates on such a policy operate?\n\n(b) invoke Task.FromResult(onRetry(...)) (or (C#7), with ValueTask) (current preferred solution)\n\nI'd like to add another vote to option (b).. I think I'd like to take a crack at this. Just to clarify the ask here, the timeoutAsync func needs to be changed from Func<Context, TimeSpan, Task, Task> to something like Func<Context, TimeSpan, Task, Exception, Task> and plumbed through the various references. Is that correct?. Also, this feature should be done to create new overloads to TimeoutAsync that accept the new Func definition as to not break backwards compatibility, correct?. @reisenberger I'll try and rebase this against master as soon as I can so that this can be reviewed.. It appears there were some policy methods that were marked as Obsolete in the 5.9 release. What is the process for deprecating tests that reference these deprecated methods? It seems the references may be causing the build to fail for this PR. I believe this because when the following line is commented out of the build script, the local cake build task succeeds.\n.WithProperty(\"TreatWarningsAsErrors\", \"true\"). @reisenberger this should be ready to review now.. Thanks @reisenberger. I've applied the requested changes and re-targeted the PR against the v610dev branch. Let me know if there is anything else.\n. @reisenberger  just touching base to ensure my last set of changes are align with expectations.. ",
    "heneryville": "The serverless compute model makes sharing state like this for circuit breakers absolutely necessary.\nRight now local-circuit breaking requires each node to learn on it's own that a given dependency is down. If your instances are long-lived with persistent in-memory state, that's OK. E.g. on the first 5 requests an instance sees failure, and then circuit breaks the dependency. Those 5 requests are essentially an learning period.\nHowever, with serverless compute models (e.g. AWS Lambda or Azure Cloud Functions) each instance's internal memory/state is highly transitory. In the extreme, each instance only survives long enough to make a single request to the dependency, and thus no node would survive long enough to learn the dependency's condition. The system would become equivalent to one with no circuit breaking at all.\nSharing state would become necessary so that all of the nodes contribute their learnings together.. ",
    "utkarsh5k": "Is this still up for grabs? I'd love to take this up. \nLittle background: I work at Microsoft and we use Polly in everything we do. Personally, I have a decent foundation in distributed systems theory, and at work, I have experience with microservice based architectures. I'd need a lot of help along the way, but I'm committed to putting in the time and effort to see this through. I went through the thread, and it looks like a good place to start. . @reisenberger I agree that the Polly interface should be pluggable for the providers. Having said that, would love to see the current work that you have done on: \n\nOnly adapt Polly to allow injection of new circuit-breaker implementations\n\n. Works as expected! Thanks for the explanation, @reisenberger!   . ",
    "harouny": "Question: Has anyone tried using Polly exception handling in Azure Durable functions orchestrator functions? I was thinking this can give us that distributed circuit breaking just outside of Polly.. ",
    "cppcraze": "@reisenberger, ah, thanks for pointing it out. Sorry, I overlooked the part in PolicyAsync.cs. Yes, it just works the way I want.. ",
    "udlose": "Thank you for your reply!  You understood correctly.  I do have the information available and will take a look at using the Context.  The problem I was trying to solve was avoiding the overhead of creating the policies every time they are used and instead create them upfront and cache them.  The problem came when I needed to create a Fallback response that was specific to each request.  I wasn't sure if using the context was the right way to go - or using a lambda for the creation of the Fallback response.  The latter seemed to hang me up though.  I took a look at the Polly samples and didn't see anything using the overload with the lambda using anything other than static data.. @reisenberger - so I looked at using the Context to build the Fallback. The problem is that I don't have access to the Contextfor the fallbackValue parameter - Context (from what I've seen) is only available in the event lambdas.  Maybe I'm doing something wrong?  \nOn a different note, it would be great if the  construction of the Fallback didn't actually occur until/unless the FallbackPolicy is actually executed.  Why allocate memory and CPU to construct something that in most cases isn't used.\nvar fallbackPolicy = Policy<HttpResponseMessage>\n    .Handle<Exception>()\n    .FallbackAsync(BuildFallback(/*need Context here*/), onFallbackAsync: async (result, context) =>\n    {\n        await Task.Run(() => _log.Error($\"{context.PolicyKey} at {context.ExecutionKey}: fallback value substituted, due to: {result.Exception}.\"));\n    });\n\n//wrap the circuit breaker with a wait/retry\nvar policyWrap = Policy.WrapAsync(waitAndRetryPolicy, circuitBreakerPolicy, fallbackPolicy)\n                        .WithPolicyKey(Key);. 5.3.1. Thank you. That seems to work!. Np @reisenberger.  Thanks for making the fix!\n\nFor reference, here's a link to the MSDN article - https://msdn.microsoft.com/en-us/magazine/dn818493.aspx. This at least provides the option to consumers of Polly to do so. However,\nI think it is an anti-pattern to extend an external API and expose its\nimplementation throughout your code - even when doing so thru interfaces.\nRather, it should be abstracted away and wrapped so the 3rd party API could\nbe swapped at some future point.\nOn Aug 18, 2017 5:58 PM, \"reisenberger\" notifications@github.com wrote:\n\nThe constructors of the Policy and Policy abstract base classes\nare internal but should be made public.\nThis would allow users to implement new custom policies, outside of the\nPolly package, deriving from these base classes.\nNeeded in files Policy.cs, Policy.TResult.cs, PolicyAsync.cs,\nPolicyAsync.TResult.cs.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/298, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAoC9hRppZ0av9iaA8rHm0s0kiirxqnaks5sZhcigaJpZM4O8H9p\n.\n. @ExtRemo75 - yes, you will have to somehow abstract usages of policies.  I was thinking of doing so via aggregation instead of inheritence. Though, I guess it's a matter of preference. Based on my experience, i've had more success using aggregation than inheritance to isolate 3rd party APIs. . Just for others - I found the answer. I was adding items to the PollyContext only in the action call - doh!\n\nThe following code:\nvar resiliencyPolicy = _policyRegistry.GetPolicy<TRequest>(); //custom PolicyRegistry\n                response = await resiliencyPolicy.ExecuteAsync((context, token) =>\n                {\n                    context[ContextRequestLookupKey] = requestMessage;\n                    var result = postAsyncFunc();\n                    return result;\n                }, new Polly.Context(CallsiteContextExecutionKey), cancellationToken, false).ConfigureAwait(false);\nshould have been\n```\n                var pollyContext = new Polly.Context(CallsiteContextExecutionKey);\n                pollyContext.Add(ContextRequestLookupKey, requestMessage);\n                var resiliencyPolicy = _policyRegistry.GetPolicy();\n                response = await resiliencyPolicy.ExecuteAsync((context, token) =>\n                {\n                    var result = postAsyncFunc();\n                return result;\n            }, pollyContext, cancellationToken, false).ConfigureAwait(false);\n\n```\n. smh - I saw that method but misread the comment as \"holds the circuit in its current state until \"Reset() is called\". My apologies for not correctly RTFM :). I need access to the CircuitBreaker within the PolicyWrap, not the Fallback.  It's unfortunate that the inner policies aren't exposed as now I am forced to keep track of both the CircuitBreaker that's in the PolicyWrap and the PolicyWrap itself.  I understand I can write my own implementation but I'd prefer to leverage something that's already an established pattern.  BTW, I don't see anything wrong with adding some sort of GetPolicy(policyKey) method on PolicyWrap\nHow do others keep track of the CircuitState when using a CircuitBreakerPolicy within a PolicyWrap?. @reisenberger Couple of thoughts:\n\nI really dislike the IsPolicy interface.  It only exposes a key.  To get anything of of a list of IsPolicy instances, you have to soft-cast them and check for null to find what you're looking for.\nWhat if you have more than one CB?  Maybe this would not normally happen, but the API should  account for it.\nIt is certainly possible that I have more than one of the same type of policy in a PolicyWrap.  In that case, how do I differentiate them other than PolicyKey?. @reisenberger I think most of those are good. of course any method taking a param would have to have null param validation on it which would go for (5), (7), and (8) (where this includes null check and string.IsNullOrWhitespace()). I think the methods returning IEnumerable<T> should return a non-null empty list if no such policies are found (.net Framework Design Guidelines).  I'm not sure about the need for (6), (7) though. The caller could accomplish the same by doing a .Single().  If you do think it's more convenient to provide them then I'd suggest throwing an exception if more than one policy satisfying the criteria is found.\n\nthoughts?. I had a similar requirement - to verify the result of a Fallback.  I looked at mocking out NoOpPolicy but found it insufficient.  What I ended up doing was to exercise my policy in my unit test and pass it a Func that caused failures.  Maybe this will help:\n```\n        [Test]\n        public async Task FallbackValueIsReturnedAfterRetryAttemptsExceededOnHttpException()\n        {\n            //arrange\n            var myPolicy = ObjectUnderTest.Build();\n            var testRequest = BuildRequestMessage();\n            var expectedFallback = new HttpResponseMessage(HttpStatusCode.PartialContent)\n            {\n                Content = new ObjectContent(BuildTestFoo(), Formatter),\n                RequestMessage = testRequest\n            };\n        Func<Task<HttpResponseMessage>> funcToCauseRetry = () =>\n        {\n            throw new HttpException(ApiExceptionMessage);\n        };\n        var callContext = new PolicyCallContext(MyPolicyBuilder.CallsiteContextExecutionKey);\n        callContext.Add(MyPolicyBuilder.CallContextRequestLookupKey, testRequest);\n        callContext.Add(MyPolicyBuilder.CallContextUserContextKey, _userContext);\n\n        //act\n        var actual = await myPolicy.ExecuteAsync((context, token) => funcToCauseRetry(), callContext, new CancellationToken(), false);\n\n        //assert\n        actual.ShouldBeEquivalentTo(expectedFallback, options => options.RespectingRuntimeTypes());\n\n        //retry\n        this.ForLogger().Verify(l => l.Error(It.Is<int>(i => i == TxErrorCodes.ResiliencyCodes.RetryFailed), \n            It.Is<string>(m => m.Contains($\"{CallFailedPartialMessage} 1\"))), Times.Once);\n        this.ForLogger().Verify(l => l.Error(It.Is<int>(i => i == TxErrorCodes.ResiliencyCodes.RetryFailed), \n            It.Is<string>(m => m.Contains($\"{CallFailedPartialMessage} 2\"))), Times.Once);\n        this.ForLogger().Verify(l => l.Error(It.Is<int>(i => i == TxErrorCodes.ResiliencyCodes.RetryFailed), \n            It.Is<string>(m => m.Contains($\"{CallFailedPartialMessage} 3\"))), Times.Once);\n\n        //circuit breaker\n        this.ForLogger().Verify(l => l.Error(It.Is<int>(i => i == TxErrorCodes.ResiliencyCodes.CircuitOpenError),\n            It.Is<string>(m => m.Contains($\"{MyPolicyBuilder.NameKey} reached max retry attempts of {DefaultRetryCount}\"))), Times.Once);\n\n        //fallback (circuit-breaker caused the Fallback)\n        var fallbackMessage = $\"{MyPolicyBuilder.NameKey}_CircuitBreaker at {MyPolicyBuilder.CallsiteContextExecutionKey}: fallback value substituted, due to: Polly.CircuitBreaker.BrokenCircuitException\";\n        this.ForLogger().Verify(l => l.Error(It.Is<int>(i => i == TxErrorCodes.ResiliencyCodes.FallbackUsed), \n            It.Is<string>(m => m.Contains(fallbackMessage))), Times.Once);\n    }\n\n```. @reisenberger - no problem. I appreciate the discussion and your recommendation. I'll give that a try and we'll see how it does under stress testing.\nSo in the case of the AdvancedCircuitBreaker, what happens to the requests that come thru and fail but do not cause the circuit to open?  In my case, I am using a PolicyWrap with Wait/Retry, AdvancedCB, and Fallback.  I assume that the failures will cause a Fallback policy to be invoked.. My question is what is the reason to upgrade? Are there features that you want to take advantage of? Hopefully, it is not for the sake of doing so just because it is the latest version. IMO, unless you are taking advantage of some new feature, you are only decreasing your compatibility and enforcing a new requirement upon your consumers - undesirable to a 3rd party nuget.. Thank you for the thorough explanation! I assume in the TimeoutStrategy.Optimistic, it is completely up to the calling code to catch the timeout since, as documented, it assumes cooperative cancellation?  If so, how does the calling code \"catch\" the timeout?. There is no need to use a PolicyWrap if you only have 1 Policy.  PolicyWrap is designed to associate multiple policies together.\nRefer to the documentation on the Wiki: Policy Wrap\n\nPurpose\nTo provide a simple way to combine resilience strategies.. @duydle - \n\n\n\nwhat is the exact type of the exception?  I'm not clear on what a \"memory heap\" exception is. \n What is the exception message?\n\n\nI assume dbConnection.QueryAsync<T> returns a Task? Do you need to await that call?. ok:\n\n\nI'm not sure how DynamicInvoke plays with an async call.  I haven't used it myself and I don't see an async version.  So, maybe it's ok but just something that sticks out to me. [UPDATE] I see Stephen Toub has commented on a similar question for VB - https://social.msdn.microsoft.com/Forums/en-US/cbb3cf48-afb9-4c63-a37a-ae2ffb61ab3d/awaitable-reflections?forum=async\n\n\n(not directly related to your issue) - be aware of the perf overhead of DynamicInvoke and avoid it if you can. If there is any way to have a well-defined method signature for your Func, use it instead of delegate - see https://stackoverflow.com/questions/12858340/difference-between-invoke-and-dynamicinvoke\n\n\nWhat version of .NET are you using?\n\n\nDoes the instruction pointer (IP) always have the same address? If  it is changing, then the heap is getting corrupted somehow. And that is the tricky part to figure out.\n\n\nis this 100% reproducible?. I had added a couple addtl questions above while you were answering (sorry). Can you respond to those?\n\n\nI suggest trying to create a MCVE (as @reisenberger mentions).  Also, try simpllifying things by removing the usage of your wrapper first (RetryPolicy.RetryForTimeoutAsync<T>) and just use the Polly code around your Dapper usage.. And what do you think should happen when there happen to be multiple inner exceptions?  Something like ex.Flatten() should probably be used here. \nI don't think behavior should differ based on how many inner exceptions there are.. Have you tested this to verify the stack trace is not reset?. Shouldn't both of these be ISyncPolicy?. Why was the 3rd param left as type IsPolicy? Not consistent with your other changes. Why add the overhead of creating an array using ToArray()? Use IEnumerable<ISyncPolicy>. Same comment as above about ToArray(). Same comment as above about ToArray(). ",
    "tynor88": "@reisenberger Thanks for getting back, and sorry for not expressing myself clearly enough. \nWhat I want to achieve, is to make my code more testable by using DI as described in the wiki. For that I need to inject policies rather than relying on the Policy class directly.\nI just cannot seem to figure out how I should structure the above mentioned code, by using the interfaces rather than the Policy class. I primarily use Polly for retrying DB inserts / reads and various API calls.\n\nAre you looking to separate policy definition and usage? (ie you define the policy outside this method and pass it in as an IRetryPolicy or IPolicyAsync).\n\nNot necessarily - but if this is the only way to get rid of the dependency on the Policy class, then yes. \n\nThe solution to this is to use the Context that Polly can flow with each execution. I can provide further info, but the scenario and solution are essentially the same as in #292. This blog post also gives some code examples.\n\nCan you provide an example of how to achieve this with SqlConnection?. @reisenberger thanks for the thorough explanation. I've implemented this in my project which is based on Dapper, Autofac,Serilog, and Polly.\nFor clarification here are some code examples, someone might find them useful:\nPolicyDefinitions.cs:\n```csharp\n    public static class PolicyDefinitions\n    {\n        private const int SqlRetryAttempts = 3;\n    public static IAsyncPolicy SqlQueryRetryPolicy { get; } =\n        Policy\n            .Handle<SqlException>()\n            .WaitAndRetryAsync(SqlRetryAttempts, retryCount => TimeSpan.FromMilliseconds(0.1 * retryCount),\n                (ex, timeSpan, retryCount, context) =>\n                {\n                    ((SqlConnection) context[\"sqlConnection\"])?.Close();\n                    ((ILogger) context[\"logger\"])?.Warning(ex, \"Error executing sql. Trying again... {RetryAttemptsLeft}/{RetryAttemptsTotal}\",\n                        SqlRetryAttempts - retryCount + 1, SqlRetryAttempts);\n                });\n}\n\nIoC Registration (Autofac):csharp\nbuilder.Register(f => PolicyDefinitions.SqlQueryRetryPolicy).As().InstancePerDependency();\n```\nRepository.cs:\n```csharp\n    public class Repository: IRepository\n    {\n        private const int DefaulCommandTimeout = 10;\n        private readonly ILogger _logger;\n        private readonly SqlConnection _sqlConnection;\n        private readonly IAsyncPolicy _sqlRetryPolicy;\n    public RewriteRulesReadRepository(ILogger logger, SqlConnection sqlConnection, IAsyncPolicy sqlRetryPolicy)\n    {\n        _logger = logger ?? throw new ArgumentNullException(nameof(logger));\n        _sqlConnection = sqlConnection ?? throw new ArgumentNullException(nameof(sqlConnection));\n        _sqlRetryPolicy = sqlRetryPolicy ?? throw new ArgumentNullException(nameof(sqlRetryPolicy));\n    }\n\n    public async Task<RewriteRuleDb> ReadByIdAsync(Guid rewriteRuleId)\n    {\n        RewriteRuleDb rewriteRuleDb = null;\n\n        try\n        {\n            await _sqlRetryPolicy\n                .ExecuteAsync(async context =>\n                    {\n                        string sql = $\"SELECT * FROM {RewriteRulesViewName} WHERE Id = @rewriteRuleId\";\n                        await _sqlConnection.OpenAsync();\n                        rewriteRuleDb = await _sqlConnection.QuerySingleOrDefaultAsync<RewriteRuleDb>(sql, new { rewriteRuleId }, commandTimeout: DefaulCommandTimeout);\n                    },\n                    new Dictionary<string, object>\n                    {\n                        {\"sqlConnection\", _sqlConnection},\n                        {\"logger\", _logger}\n                    }\n                );\n        }\n        finally\n        {\n            _sqlConnection.Close();\n        }\n\n        return rewriteRuleDb;\n    }\n\n}\n```\n. ",
    "ryanfollmer": "Thank you so much for the feedback! . ",
    "iojancode": "Thank you, now everything makes sense when Wrapping, just for reference code now looks like this\nprivate async Task<T> ResilientAsync<T>(Func<Task<T>> action, Func<Task<T>> fallbackAction, Func<Task<T>> defaultAction = null)\n{\n    var outerFallback = Policy\n        .Handle<BrokenCircuitException>(ex => defaultAction != null)\n        .FallbackAsync(\n            fallbackAction: cancelToken => defaultAction(),\n            onFallbackAsync: ex => { _logger.LogWarning($\"*** default fallback = {ex.InnerException.Message}\"); return Task.CompletedTask; }\n        );\n\n    var innerFallback = Policy\n        .Handle<BrokenCircuitException>(ex => _fallClient != null)\n        .FallbackAsync(\n            fallbackAction: cancelToken => _circuitPolicy2.ExecuteAsync(fallbackAction),\n            onFallbackAsync: ex => {  _logger.LogWarning($\"*** resilient fallback = {ex.InnerException.Message}\"); return Task.CompletedTask; }\n        );\n\n    return await Policy.WrapAsync(outerFallback, _retryPolicy, innerFallback, _circuitPolicy).ExecuteAsync(action);\n}\n\nnow that is solved should I close this issue, or let it open ?. ",
    "vvucetic": "Looks that problem is not there after all. It took me a lot of time and after writing this up, I've figured it out. Sorry. . ",
    "brunoabreu": "@reisenberger thank you for your explanation. I wasn't aware of this single trial call per breakDuration in half-open state. I think that is exactly what is happening here.\nAlthough I understand this strategy, it seems a little odd because if I'm not handling some kind of exception and it happens, I don't expect it to be treated as a failure that prevents my circuit breaker from transitioning half-open -> closed.\nIf it is closed, that inertia makes sense. Unhandled exception should not interfere in circuit state. But when we apply that rule in half-open case, things become a little confusing.. ",
    "joaoasrosa": "@reisenberger thanks for your quick reply.\nFrom the mentioned test, the code is similar, e.g., use the ExecutyAysnc provided by the Policy object.\nRegarding your concerns:\n1. The IAmazonS3.GetObjectAsync has 3 overloads, the last one has a default value. That is the reason in the mock everything is specified, however, in the repository code, it is omitted.\n2. The tests take 2 seconds to execute\nI added a StopWatch around the tests, and also an extra test using your suggestion.\nThe results are the same, the timeout policy is not triggered. \nAnd your comment is not off the mark. :) Thanks for the help!. @reisenberger Thanks for your lunchtime.\nYour explanation makes perfect sense, I was caught by it!\nThe POC was updated to reflect the way the tests should be written.\nCheers. ",
    "erickhouse": "Hello, I'm a first time contributor to open source. It doesn't look like anyone is working on this. I've got several years of .NET experience but have never contributed. For anyone that is familiar with this project does this seem like a reasonable first issue? I see that it's labeled up-for-grabs. . @reisenberger, Thanks for the reply. The write up is very helpful. I'm sure I'll have more questions. Are you able to assign this issue to me? I went ahead and forked the project and am ready to get started. . @reisenberger \nI just created a pull request. Do we need to link this issue to the particular request? It looks like you did almost all the heavy lifting on this one. It was a great introduction to the project! I assume the feedback all happens on the pull request now? . Great, Thanks! I just re-targeted to v571 instead of master. I'll take a look at 338.  . ",
    "dhabierre": "Hi.\nI am interesting in Polly metrics.\nAny feedback about the implementtaion status, perthaps an alpha version?\nDo you have an approximate release date?\nThank you.. ",
    "lalitkale": "@reisenberger can you check possibility of using https://www.app-metrics.io/ for metrics work. App-metrics also support various data sourcesincluding Prometheus. Also, it has pre-existing grafana dashboard. That way, we don't need to do big legwork for adopting Metrics. It also fits with .NET core and Polly's Integration with HTTPClientFactory and overall microservices space. What are your thoughts.. ",
    "sanjaysingh": "Thank you @reisenberger PolicyWrap is awesome and I am now able to achieve this. I understand that the WaitAndRetry is synchronous and that is ok for my case because i have those as backgroound Tasks which each run in isolation with their own retries. Thank you for your help.. ",
    "pavan7parekh": "@reisenberger, Thanks for your quick reply. I see this video but not able to find a solution.\nIf I downgrade the version of a package to 5.0.6 then it is working fine.. ",
    "larsbe": "Thank you, @reisenberger, for the detailed answer!\nYou argue for having a two-stage policy, however, this feels a bit like a workaround for me (at least in my case). Here is why:\nYour main argument is about the error handling and especially the unclear origin of exceptions, if you have a HandleResultAsync<>() method. But if you consider your proposed solution of a two-staged policy, a potential exception in the second stage would then also originate from the ExecuteAsync<>() method. So, I agree that error handling is problematic, but I don't see advantages in your proposed solution.\nI do agree that a two-stage policy is the right way to go, if you have a complex operation inside a potential HandleResultAsync<>() method. But this is not the case for me. I actually don't want a separate policy for ReadAsStringAsync(). If this operation fails, just let it fail and return me an exception right away.\nRegardless, thanks for the example you gave me. It definitely helps my case and I am going to implement it this way for now, but it just feels unnecessary complex for my needs. So, you might still want to consider my feedback!. ",
    "danroot": "Another scenario where this is needed is calling Azure Cognitive Services.  Basic plan has a 1/s limit and Standard has a 10/s limit.   Trello has a 300/s limit.  It would be nice to proactively limit the client to play nice with these APIs.  Guidance on alternative (retries) would be nice.. @joelhulen That would be great.  I'd appreciate any guidance you have on this.  I created #412 for this.. Very nice, thanks.  There's karma to be had over on https://stackoverflow.com/questions/49031849/how-should-i-throttle-calls-from-my-c-sharp-client-in-azure-to-a-3rd-party-api-t if they reopen my question ;). ",
    "jelical": "Thanks for fast reply, joelhulen! Using netstandard1.x libraries mixed with netstandard2.0 creates a lot of mess and incompatibilities. And I am not speaking about dropping 1.1 support. There is very little effort to build, test and publish Polly with both netstandard1.1 and netstandard2.0 (already found and fixed problem mentioned in original post, it was incompatible SystemClock implementation). . Hi, @reisenberger and  @joelhulen \nHere are details:\nThe tests affected are CirquitBreaker and Timeout. It is obvious result of the static nature of SystemClock class used: when you are running tests in parallel, any change of SystemClock static properties like here \n\nimmediatelly breaking everything already running .\nI changed SystemClock to use AsyncLocal in the context of netstandard2.0 testing.\nPull request here https://github.com/App-vNext/Polly/pull/337\n. Hi, @udlose. We are not talking about upgrade here. We talking about support for additional standard/platform and not dropping netstandard1.1. The reason is compatibility with new technologies and code - exactly the same why you have both polly.net40 and polly.net45.  Netstandard1.1 is defacto incompatible with netstandard2.0 development. Correct me if I am wrong, but application can't target netstandard, only netcoreappxxx or netxxx.  I have a big project with more that 50 libraries and web projects, build with netstandard2.0 and net4.6.1, I am in the middle of porting effort. I will try to provide you with more concrete examples soon. But (tl;dr;) when I using 2 different nugets dependent on different versions of netstandard, that leads to conflicts. More than that, when i have multiple library projects in my solution, one is net4.6.1, one is netstandard and both are using polly, they are picking different versions of polly that afterward also have conflicts. Sometimes this  can be solved manually, with remapping, sometimes - no, especially in web projects context. It is too many moving parts actually.\n. Hi. Sorry for long delay. Original issue are already not actual - current MS tooling is working great with mixed net standards. I am closing this and cancelling my merge request. Thanks a lot for attention!. Fixed build failure on warnings. ",
    "praveenk2": "Hi, I'm currently developing a library API which is targeting on the .NET standard 2.0. I would like to leverage the Polly library for transient fault handling and also to handle Retry, Circuit Breaker, Timeout, Bulkhead Isolation, and Fallback in a fluent and thread-safe manner.\n\n\nSo based on this thread, can I use the Polly[which stated and mentioned as compatible only to .NET standard 1.1] ?\n\n\nWill there be any issues or risks involved ?\n\n\nWill it requires any modifications, specific handling etc ?\n\n\nPlease kindly let me know.. Sure, ThankQ @joelhulen.. ",
    "andrecarlucci": "Hi @reisenberger ,\nI'm creating a policy to use in many places, so it was about saving some lines of code centralizing this.\nNo problem, I can proceed the other way and refactor it when the proper method is available in the future.\nThanks a lot for this great library :)\n. ",
    "tdabasinskas": "Hi @reisenberger,\nSorry for not replying sooner. I've finally tested the new version today and it seems it indeed fixed the issue. Thank you!. Hi @reisenberger,\nI can confirm, that making the changes you mentioned solve the issue and the items are now being added to cache as expected.\nI have another issue, where items are not added to the cache again once they expire, but I guess I'll open  a separate issue for that.\nThank you!. ",
    "naymore": "Ah I see, you mean I have to apply async calls everywhere in order for it to work? Will try that.\nUpdate: Of course it worked :). ",
    "matst80": "Signed and sent. ",
    "jbergens": "Will try.\nJohan\nDen 17 nov. 2017 17:38 skrev \"reisenberger\" notifications@github.com:\n\n@jbergens https://github.com/jbergens Would you be able to retarget\nthis PR against the v560dev branch if you have a moment? (Should be\npossible to change on the existing PR.) Thanks!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/pull/362#issuecomment-345295032, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AALpkuAuKvlXXToWvaDzwbZZvTZ3juMHks5s3baQgaJpZM4QiM0C\n.\n. Changed the target branch to v560dev as requested.. \n",
    "galmok": "I have my own algorithm now. A ForEachAsync that has a limit on how many tasks in parallel it keeps going. Together with the retry from Polly, I have a decently working system. :). ",
    "AndrewInScotland": "Version 5.6.1.\nOn Fri, Dec 8, 2017 at 4:58 PM, reisenberger notifications@github.com\nwrote:\n\n@AndrewInScotland https://github.com/andrewinscotland Which version of\nPolly are you using?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/377#issuecomment-350382677,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ACMCVrovAkEvSbhu9VNQ9iHs_jfKSFJHks5s-bEhgaJpZM4Q7qEn\n.\n\n\n-- \n[image: Line.png]\nandrew wallace\nsoftware engineer, trov\ntrov.com http://www.trov.com/\n. Thanks @reisenberger for the explanation - I understand the behavior and have coded appropriately.. ",
    "awarrenlove": "Yes, I'll take a look at that over the next couple days.. I believe I got everything updated. Please let me know if I missed anything or if there's anything else I can do to clean it up.. Great! Thanks. Let me know if there's anything else I can do to help.. ",
    "zirain": "Hi @reisenberger ,thx for you reply,I will maintain it myself. ",
    "joshidp": "Thanks. Thanks for the reply.\nHow do I use IReadOnlyPolicyRegistry registry inside my class, it's not shown in your example.\npublic class MyServiceGateway \n{\n    public void MyServiceGateway(..., IReadOnlyPolicyRegistry<string> registry, ...)\n    {\n       ...\n    } \n}\nCurrently  I am using Policy[] policies and Policy.Wrap(policies). So not getting how Policy[] will be set.\nThanks. ",
    "thurfir": "Thanks @reisenberger , I took a look at custom policies but I'm not confident enough about Polly's internals to create a Policy without guidance.\nAbout our specific case we are more than happy to stick with v5.5 for now, we will wait for Polly v6.0 before upgrading if this is what you recommend.. Hello @reisenberger , wouldn't .Fallback with an Action prevent the Exception from actually bubbling?\nIs it safe to rethrow the exception from onFallback, after logging of course?\nThank you.. ",
    "duydle": "After posting this issue, member of my team found this article which answers my question.  http://www.thepollyproject.org/2017/06/09/polly-and-synchronous-versus-asynchronous-policies/. @udlose Thanks for the reply.\n1. \n    Application: w3wp.exe\n    Framework Version: v4.0.30319\n    Description: The process was terminated due to an internal error in the .NET Runtime at IP 00007FFE6475425F (00007FFE645F0000) with exit code 80131506.\n that in particular is a .net clr hard crash\n\nYes it returns a Task.  I don't think it needs to await on that call.  I can try to remove it and see if it fixes the problem.. \nWhat version of .NET are you using?\n\n\n\n.NET v4.6.1\n\nDoes the instruction pointer (IP) always have the same address?\n\nYes, I think so.. Thanks all for the response.  At the moment, let's close this ticket since I won't be able spend too much time on this issue.  For now we will not implement a retry on async calls.  If I have availability, I will circle back and try to create a reproducible code sample and send your way.  Thanks all for the quick responses.. ",
    "shagilt": "Thank you @reisenberger . Thank you @reisenberger I will check PollyWrap API.. Thank you @reisenberger. Reading CircuitState property solved my UT issue. Do you recommend the same in production code so that state transition is guaranteed from Open to HalfOpen after durationOfBreak? \nAs a side note, this behavior is not documented in the wiki https://github.com/App-vNext/Polly/wiki/Circuit-Breaker#circuit-state-for-health-reporting-polly-v40 [ from wiki \"The circuit remains open for the configured durationOfBreak. After that timespan, but before the next action, the circuit transitions to: Half-Open\"].. Ok, got it. In our scenario, we dont perform any action until circuit become HalfOpen or Closed. I will add CircuitState 'read' so that state transition is guaranteed. \nAnd thanks for updating the wiki!. Thanks @reisenberger, I will try these.. Thank you @reisenberger . ",
    "craigbrett17": "v4.3.0 seems to be the last package from my experimentation. A quick note or similar in the readme would just be helpful and may save other people some time. . ",
    "ciarancolgan": "Superb answer - i missed the 'async' modifier on the delegate declaration which meant the compiler wanted a return type. \nThanks and keep up the great work :). ",
    "benagain": "@reisenberger, I changed the target branch to App-vNext::v571onBreakDelegate.  \nThat's brought in two other commits from master as that's where my branch came from originally.  Are you happy with that or do you want me to rebase my branch as well to lose them?\n(This PR is set as editable by maintainers so feel free to get it in the right state if that's easier). OK, no problem.  That's rebased now and back to just the one commit.. ",
    "rulrok": "Ow, I think I have figured that out.\nI was focusing too much on this piece of code:\ncs\nvar cacheResult = await Policy\n                    .CacheAsync(_cosmosDbPollyProvider, TimeSpan.FromDays(50))\n                    .ExecuteAndCaptureAsync(TryGetAccessTokenAsync, CosmosDbPollyProvider.GetCacheContextWithPartition(\"twitch\", \"access.token\"));\nSo I was trying to somehow tell the cache to invalidate my entry through the policy object.\nThen I turned my attention to the fact that my provider instance was just available there.\nNow I can manually call it like:\ncs\n_cosmosDbPollyProvider.PutAsync(\"twitch.access.token\", \"New token\", new Ttl(TimeSpan.FromDays(50)), CancellationToken.None, false);\nNever mind \ud83e\udd13 . ",
    "janzakrzewskipl": "Yes it helps.\nThanks.. ",
    "nmurf": "Thanks for the quick response, @reisenberger!  Great library -- I did not notice the provider overload until you pointed it out.\nFor posterity, here is an implementation of the method to obtain the header value as a TimeSpan (assumes server is in UTC):\n```\nprivate TimeSpan getServerWaitDuration(DelegateResult response)\n{\n    var retryAfter = response?.Result?.Headers?.RetryAfter;\n    if (retryAfter == null)\n        return TimeSpan.Zero;\nreturn retryAfter.Date.HasValue\n    ? retryAfter.Date.Value - DateTime.UtcNow\n    : retryAfter.Delta.GetValueOrDefault(TimeSpan.Zero);\n\n}\n```\nHere's the rest:\n```\nvar clientWaitDurations = DecorrelatedJitter(numRetries, firstWaitDuration.Value, maxWaitDuration.Value)\n    .ToArray();\n_policy = Policy\n    .Handle()\n    .OrResult(filter)\n    .WaitAndRetryAsync(\n        retryCount: numRetries,\n        sleepDurationProvider: (retryCount, response, context) => \n            TimeSpan.FromMilliseconds(\n                Math.Max(\n                    clientWaitDurations[retryCount - 1].TotalMilliseconds, \n                    getServerWaitDuration(response).TotalMilliseconds));\n``. @reisenberger, good catch with the.ToArray()` causing correlation.\nI think the correct solution here is to generate the sleep durations as needed.  I don't have time to test this at the moment, but this is what I am thinking:\n```\nvar jitterer = new Random();\nvar policy = Policy\n    .Handle()\n    .OrResult(filter)\n    .WaitAndRetryAsync(\n        retryCount: numRetries,\n        sleepDurationProvider: (retryCount, response, context) =>\n        {\n            object lastWaitDuration;\n            if (!context.TryGetValue(\"lastWaitDuration\", out lastWaitDuration))\n            {\n                lastWaitDuration = firstWaitDuration.Value;\n            }\n        var clientWaitDuration = GetNextDecorrelatedWaitDuration(\n            jitterer, firstWaitDuration.Value, (TimeSpan) lastWaitDuration, maxWaitDuration.Value);\n\n        context[\"lastWaitDuration\"] = clientWaitDuration;\n\n        return TimeSpan.FromMilliseconds(\n            Math.Max(\n                clientWaitDuration.TotalMilliseconds,\n                getServerWaitDuration(response).TotalMilliseconds));\n    });\n\n```\nHere's the new jitter method.  It could be tweaked if you need to support 64 bit millisecond durations.\n```\nprivate static TimeSpan GetNextDecorrelatedWaitDuration(Random jitterer,\n    TimeSpan seedDelay, TimeSpan lastDelay, TimeSpan maxDelay)\n{\n    var seed = (int)seedDelay.TotalMilliseconds;\n    var last = (int)lastDelay.TotalSeconds;\n    var cap = (int)maxDelay.TotalMilliseconds;\nvar current = Math.Min(cap, jitterer.Next(seed, last * 3));\nreturn TimeSpan.FromMilliseconds(current);\n\n}\n```. ",
    "ikabar": "How can we use retryafter with retry forever + timeout?\nSay I want to poll a result and the server returns the retryafter.\nI want to wait until the result is available and no longer then X minutes. I want the retry interval to be set according to the server response.. ",
    "Danation": "Hunting through the code, it looks like it uses CancellationTokenSource.CancelAfter(), which can take a -1.  I wasn't able to dig deep enough into the source to find how it handles -1, but after some testing, it looks like it does what I'd hope (no cancellation). So it looks like returning TimeSpan.FromMilliseconds(-1) in a timeoutProvider works.  Could anybody confirm that I'm correct on that?. ",
    "urig": "I'd like to \"grab\" this. Would you say fixing the guard clauses and related unit tests would suffice? In other words, how would I go about verifying the correct behavior for the Timeout when set to TimeSpan.Zero?\n. @reisenberger many many thanks for the detailed help. I'd like to take it slow and start with one of the features, let's say TimeSpan.InfiniteTimeSpan. Perhaps we can open another issue for TimeSpan.Zero and I can pick that up right after?. @reisenberger Ok if I submit a PR just for the sync part (w/o Async for now)? I'd like to show you my work and get feedback.. Thank you. PR https://github.com/App-vNext/Polly/pull/424 is ready. Your feedback most welcome :). Wonderful news. Huge thanks to you @reisenberger for your help in working on this! May all OSS maintainers be as kind and patient as you are :). I have some questions about this. Will try to catch you on Slack!\n. ",
    "LeafDuan": "Thanks for your comment.\nBecause I just want the Retry policy in Polly class library, if separating Polly class library into sepatate DLLs by function, that the DLL the project references will be smaller.\nMaybe I should separate it from the Polly project in my own project.. Thanks for reply @reisenberger . The current size of Polly.dll is very OK. Yeah, it's not convenient to sure which version  packages can work together, if splitting out.. ",
    "infofromca": "my use case is that I have a instance (S) to manipulate by retry system. after first (or second, or third..) retry , it has exception, now I need to get info(data)  from exception, reassign this data to that instance(S). then try again.\nas I understand , after each retry, instance (S) will be disposed. so I think to use Context, but Context is also disposed.\nWhat should I do?\nare there any place to keep the (modified) state across retries?\nthanks\nandy\n. Thanks \nI misunderstood between each .Execute() and each retry.\nI will try it today. ",
    "Discofunk": "Thanks for your reply.  Given your advice I believe my example would look more like this then using Cancellation Tokens:\n```\nvar policy = Policy\n    .Handle()\n    .Retry(3, (ex, retryAttempt, ctx) =>\n    {\n        var result = MessageBox.Show(\"Please retry once the application is back online or cancel this request\", \"Application Offline\", MessageBoxButtons.RetryCancel, MessageBoxIcon.Error);\n        if (result != DialogResult.Retry)\n        {\n            var cts = ctx[\"CancellationTokenSource\"] as CancellationTokenSource;\n            cts.Cancel();\n        }\n    });\nvar cts = new CancellationTokenSource();\nvar ctx = new Context(\"DoSomething\");\nctx.Add(\"CancellationTokenSource\", cts);\npolicy.Execute(ct => doSomething(), ctx, cts.Token);\n```. Thanks for the suggested alternatives - I will take a look.. ",
    "paulomorgado": "I had to go through the sources to find out what was the right overload.\nYou should consider moving those overloads to extension methods. That will keep the implementation short and precise while providing source compatibility.\nUnfortunately, going from extension methods to instance methods is easy but the other way around it's impossible.. The strong name signer is removing the source linking information from the PDBs.. https://github.com/brutaldev/StrongNameSigner/issues/50. @reisenberger, compare the size of the PDBs under the build folder with the size of the PDBs under the bin folder. Is it the same?\nAlso, the PDB must contain the string https://github.com/App-vNext/Polly/ somewhere in it.\nI've been looking at how System.Reactive is built to see if I can set the same thing up here.. Maybe we should fix #504 first. Do you have any clue to why the tests are failing for .NET Framework runtimes?. Thanks for the update, @reisenberger. Let me know if you need anything from me.. Inlining is always a good thing. For such methods I always add [MethodImpl(MethodImplOptions.AggressiveInlining)] to \"help\" the jitter.\nThe solution is choose better what to assert.. You might choose to run tests on non-optimized builds. Or there might be a way to instrument the JIT to not optimize.. @reisenberger, I misread your message. I thought you were talking about applying [MethodImpl(MethodImplOptions.AggressiveInlining)] to Polly code instead of test code.\nI applied it to the test and all tests pass now.. The build is failing because that version already exists. Should I bump the version?. @reisenberger, just let me know if there's something I can do to help.. Thanks for the update, @reisenberger. Let me know if you need anything from me.. ",
    "JamesNK": "\nI am leaning toward publishing only strong-named, starting with version 6.0. This would result in us ceasing the Polly-Signed lineage, and we'd need to make it very clear in several places that the assembly in the Polly package is strong-named.\n\n.NET Framework treats changing the signing key on the assembly, including adding and removing one, as a different assembly. That means all libraries that depends on the package will break when someone upgrades to your new package until the library is recompiled.\nThat is fine for apps - people will recompile after upgrading packages - but other NuGet packages they use that depend your package will break until they are upgraded.\nRead up on what happened when log4net changed its key.\nThis situation might have improved on .NET Core.. ",
    "iancooper": "I commented over here that consistency in the ecosystem is probably the best outcome we can hope for. The push to signed policy created by asp.net HttpClientFactory is essentially a fait accompli here, we are all going to have to take the signed version. So it would be easier to create a pit of success.\nStrong naming is problematic, but I won't solve that problem.... @sharwell Yes, see this Brighter issue where we are tracking: https://github.com/BrighterCommand/Brighter/issues/286\n. But, we are happy to go this route. It seems to be the best path forward. We'll have to release as a 'breaking change' but we can live with that issue.. ",
    "holytshirt": "Brighter project will depend on this change\nhttps://github.com/BrighterCommand/Brighter/issues/287. ",
    "sharwell": "\ud83d\udcad Is adding a strong name a binary breaking change for applications that are not strong-named? It's been so long since I did anything with an assembly that wasn't strong named that I'm not sure the answer.. > Yes, see this Brighter issue where we are tracking: BrighterCommand/Brighter#286\nThis a different issue.\u00b9 The situation I refer to would be the following:\n\nCreate a library MyLibrary which does not have a strong name\nCreate a command line application MyApp which does not have a strong name\nRecompile MyLibrary with a strong name\nCopy the binary from step (3) to the output directory from step (2), overwriting the binary in that directory originally from step (1)\nAttempt to run MyApp without recompiling it\n\n~~If the above steps are successful, it would indicate that replacing a non-strong-name assembly with a strong-name assembly would not be a binary breaking change. The key insight leading to this conclusion is step (2) - specifically it's not possible to create MyApp with a strong name at this point.~~\nEdit: I ran this test locally and found the following output in step (5):\n\nUnhandled Exception: System.IO.FileLoadException: Could not load file or assembly 'StrongNameBreakingTest, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null' or one of its dependencies. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040)\n\n\u00b9 The linked issue differs from the case I am describing because the application in question references both the non-strong-name and the strong-name forms of the assembly at the same time.. ",
    "TomPallister": "Thanks for the heads up, Ocelot uses Polly so I will do whatever I need to fit in with you :)\nThanks for the amazing work and the Polly project! . ",
    "Dhakate": "Public static void until(Expression>predicate,Timespan timeout)\n{\nVar compiledPredicate = predicate.Compile();\nAction action = () =>{\nWhile (compiledPredicate () == false)\n{}\n};\nVar policy = Policy.Timeout(timeout, TimeoutStrategy.Pessimistic,ontimeout:(CTX,to,tsk)=>{\nVar message = \" timeout before completing predicate\";\nThrow new TimeoutException (message);\n});\nPolicy.execute(action);\n}\nPolicy.execute is throwing me exception ..specified cast is not valid at system.windows forms.unsafeNativeMethods.IHtMLDocument.GetLocation()\nAt System.window.Forms.webBrowser.get_Document()\nAt lambda_method(Closure )\nM calling this method from my code where I am simulating using web browser control \nFor eg\n:\nExpression> predicate = () => (WebBrowser.Document.GetElementById(\"xyz\" != Null);\nWait.Until(predicate,Timespan.FromSeconds(3));\n. timeoutStrategy.Optimistic is not successfully timing out .. Ya right... Timeout.Optimistic requires cancellation token for timeout to work ..I would look into if I can reduce CPU cycles .\nFor now the issue is resolved. Thanks a lot for your help . ",
    "rkandi590": "Thank you for the detailed explanation Reisenberger. That helps a lot.. Thank you @reisenberger !  I have to however use Sync execution, but assuming that everything remains the same either way, closing this issue. Also, please let me know if that is not the case.. ",
    "NRKirby": "I'm interested in picking this up. \nI've had a look in RetrySyntaxAsync but I'm having trouble figuring out what the overload signatures should be - can you give any guidance on this?\nI added this overload, does it look ok? (I can submit a PR if it's easier, just let me know)\n```\n        /// \n        ///     Builds a  that will wait and retry indefinitely\n        ///     calling  on each retry with the raised exception, the current sleep duration, retry count, and context data.\n        ///     On each retry, the duration to wait is calculated by calling  with\n        ///     the current retry attempt allowing an exponentially increasing wait time (exponential backoff).\n        /// \n        /// The policy builder.\n        /// The function that provides the duration to wait for for a particular retry attempt.\n        /// The action to call on each retry.\n        /// The policy instance.\n        /// retryCount;Value must be greater than or equal to zero.\n        /// \n        ///     sleepDurationProvider\n        ///     or\n        ///     onRetry\n        /// \n        public static RetryPolicy WaitAndRetryForeverAsync(this PolicyBuilder policyBuilder, Func sleepDurationProvider, Action onRetry)\n        {\n            if (sleepDurationProvider == null) throw new ArgumentNullException(nameof(sleepDurationProvider));\n            if (onRetry == null) throw new ArgumentNullException(nameof(onRetry));\n        return policyBuilder.WaitAndRetryForeverAsync(\n            sleepDurationProvider,\n\npragma warning disable 1998 // async method has no awaits, will run synchronously\n            async (exception, timespan, i, ctx) => onRetry(exception, timespan, i, ctx)\n\npragma warning restore 1998\n        );\n    }\n\n```\nIf you could give me any advice on how I know what the overload signatures should be, I will make a start on this!. ",
    "SashaPshenychniy": "Thank you, @Freakazoid182 and everyone who participated!. ",
    "Freakazoid182": "My pleasure @SashaPshenychniy and @reisenberger. @reisenberger, sorry about that, I have seemed to create an endless loop here .\nThis results in the xUnit outputting a stack overflow exception.\nThank you for rebasing.\nI will resolve that endless loop issue. I changed that line of code there to thinking to resolve an ambiguity I created by adding the new overload. I'll make sure I've run the unit tests successfully before committing.. ",
    "CesarD": "Thanks for answering @reisenberger.\nNow I don't get the exception and the code works, but it doesn't cache the results. The call to webservice is executed on every request.\nI have configured the policies on a class that I inject later on my controllers, and I registered the DI for that class as a Singleton. Anything else I might be missing? Thanks!. Oh, btw: what should be used instead of the deprecated overload? How should I set a cache key now?\nThanks!. I modified the policy configuration like this:\ncachePolicy = Policy.CacheAsync(new MemoryCacheProvider(MemoryCache.Default), TimeSpan.FromMinutes(5),\n                (context, s) =>\n                {\n                    Console.WriteLine(\"get\");\n                }, (context, s) =>\n                {\n                    Console.WriteLine(\"miss\");\n                }, (context, s) =>\n                {\n                    Console.WriteLine(\"put\");\n                }, (context, s, ex) =>\n                {\n                    Console.WriteLine(\"getError\");\n                }, (context, s, ex) =>\n                {\n                    Console.WriteLine(\"putError\");\n                });\nWebService is called every time and responds with the results, and I put breakpoints on the console calls but none of them are captured.\nSorry, I'm on a loss here.... Never mind, I just figured it out: I needed to pass the Context parameter with the cache key on the ExecuteAsync method for all the stuff to work. Didn't seem to be required, but it is... Perhaps a note on docs to emphasize it more?\nThanks and keep up the good work ;). ",
    "CESARDELATORRE": "Awesome! Thank you! \ud83d\udc4d . ",
    "yaireclipse": "@reisenberger Thanks for responding!\n\nBy avoiding allowing a wrap of only one policy, we avoid a lot of runtime checks for a b-tree-that-isn't-really-a-b-tree.\n\nThat's actually a nice trick :)\n\nFor now I've added to the documentation (wiki) the clarification.\n\nThat's great! Thanks!. ",
    "AndreaCuneo": "Thanks for the info @reisenberger!\nSo I was on the right path for using the ResultTtl strategy :-)\nI'm going to wait for the serialization package to be released, for now I'm going to stick with a short relative Ttl.. I tried the following code with polly 5.9.0 but I get the following error compiling. \n```\nif NETSTANDARD2_0\n    Polly.Caching.MemoryCache.MemoryCacheProvider _memoryCacheProvider\n       = new Polly.Caching.MemoryCache.MemoryCacheProvider(new Microsoft.Extensions.Caching.Memory.MemoryCache(new Microsoft.Extensions.Caching.Memory.MemoryCacheOptions()));\n\nelse\n    Polly.Caching.MemoryCache.MemoryCacheProvider _memoryCacheProvider\n       = new Polly.Caching.MemoryCache.MemoryCacheProvider(System.Runtime.Caching.MemoryCache.Default);\n\nendif\nvar cachePolicy = Policy.CacheAsync<(string AccessToken, DateTimeOffset ExpiresOn)>(_memoryCacheProvider, new ResultTtl<(string AccessToken, DateTimeOffset ExpiresOn)>(r => new Ttl(r.ExpiresOn - DateTimeOffset.Now, false)));\n```\nArgument 2: cannot convert from 'Polly.Caching.ResultTtl<(string AccessToken, System.DateTimeOffset ExpiresOn)>' to 'System.TimeSpan'\nAnd makes sense as there is no overload that accept ITtlStrategy<TResult> and a plain IAsyncCacheProvider. It requires IAsyncCacheProvider<TResult> but I do not find how to make one. \nIf I update to Polly v6, there is a version clashing where Polly.Caching.MemoryCache.MemoryCacheProvider doesn't implement Polly.Caching.IAsyncCacheProvider from v6 and requires v5.9\nAm I doing something wrong?. I confirm that AsyncFor<> solves.\nI couldn't find that, or I missed it completly, from every doc page I looked at ... sorry for bothering you and thanks for your time.. ",
    "andregrohmann": "@reisenberger  Thank you for the clarification.. ",
    "B1nke": "I'm sorry, I was just looking at the onRetry action and logging from there and I was expecting it to hit one last time after the last call to ExecuteAsync(CallApiAsync) had failed.\nAfter adding logging to CallApiAsync I can see that it's executed after the expected amount of time without executing onRetry afterwards.. ",
    "cmeeren": "Note that cleaning and deleting all my projects' bin and obj folders did not help.. Thanks, my bad.\nYou could add a deprecation warning to the summary (or whatever it's called), which is shown in the nuget listing in VS (and most other places I'd think). I've seen many packages place \"DEPRECATED, please use ...\" in this field.\n\n. The type is Skippable<string option> where Skippable is an F# union type I've made that's similar to option.\nf#\nlet getCompanyName (signedInUser: User) (userToGetFor: User) : Skippable<string option> =\n  cachePolicy.Execute(\n    (fun _ -> getUncached signedInUser userToGetFor),\n    Context(string userToGetFor.CompanyID)\n  ). I had the same question and this is a great explanation @reisenberger. Should definitely be added to the wiki!. Sorry for jumping the gun. I'll investigate and get back with more details.. Found it - Application Insights tells me it's actually from Microsoft.AspNetCore.Cors.Infrastructure.CorsService:\n\nTook way too long to track down, since I tried to reproduce it using Postman, which doesn't trigger CORS unless you include the relevant headers manually. Evidently I had done so for the requests that led me to posting this issue, but not for the ones I now tried to reproduce with, so I had no idea where the message had disappeared to and could not for the life of me trigger them, neither locally nor in production. Also, CORS is rather invisible in ASP.NET Core code - you can't step through anything, since everything is pure configuration. Thankfully, Application Insights and (possibly Serilog's structured logging) saved the day!\nIn any case, thank you for the clarification and sorry for the wild goose chase.. I'm currently swamped with other work, so for the sake of me and mine I have to pass on this. Hoping someone else will be able to do this! \ud83e\udd1e . I'll try to take a stab at this today.. ~~I think the common pattern is to use out params: bool TryGet(String key, out object result);~~\n~~This also avoids an extra struct as well as the dependency on System.ValueTuple. Will try this.~~\nEdit: Oh wait, you can't do that with async. I'll go for tuples instead, I think.. Please review carefully, these are non-trivial changes to both code and tests.\nAlso, feel free to merge and make changes yourself if that's quicker/easier than having me update the PR.. Thanks, happy to help! :). ",
    "taomylife521": "For Example: \n    public void Excute()\n    {\n        int retryCount = 3;\n        int sleepTime = 1;\n        RetryPolicy policy = Policy.Handle<Exception>((ex) =>\n        {\n            return true;\n        }).WaitAndRetry(retryCount, attempt => TimeSpan.FromSeconds(sleepTime), (exception, timespan) => { \n            Console.WriteLine(\"\u4f11\u7720\" + sleepTime.ToString() + \"\u79d2\u540e\u91cd\u8bd5\");\n        });\n        try\n        {\n            policy.Execute(() =>\n            {\n                using (var client = new WebClient())\n                {\n                    string response = null; //client.DownloadString(Configuration.WEB_API_ROOT + \"/api/values/\");\n                    if (response == null)    \n                    {\n                        **//Here TODO: i want to dynamically set retryCount and sleepTime By response\n                        retryCount = 4;\n                        sleepTime = 2;**\n                    }\n                    Console.WriteLine(response);\n\n\n                }\n            });\n\n        }\n        catch (Exception) { }\n    }\n\nEDITED: by @reisenberger to format code. . ",
    "rmandvikar": "I do wrap with fallback policy to handle TimeoutRejectedException. I see, since timeout policy cannot handle result and policy wrap bubbles up only 1 level deep so need to repeat the OrResult for fallback too (fallback - timeout - retry) to mimic the behavior as retry.. Shouldn't the outcome in this case be OutcomeType.Failure too since it should time out and the timeout policy should catch it and bubble it up to PolicyWrap policy?\n```\n[Test]\npublic async Task Outcome_Should_Be_Failure()\n{\n    var retryCount = 1000;\n    var retry = Policy\n               .Handle()\n               .OrResult((result) => false)\n               .WaitAndRetryAsync(\n                   retryCount,\n                   ra => TimeSpan.FromMilliseconds(1000));\n    var timeout = Policy\n                  .TimeoutAsync(1);\n    var fallback = Policy\n                   .Handle()\n                   .OrResult((result) => false)\n                   .FallbackAsync(default(object));\n    var policy = fallback.WrapAsync(timeout).WrapAsync(retry);\nvar time = DateTime.UtcNow;\nvar retryAttempt = -1;\n\nvar policyResult = await policy.ExecuteAndCaptureAsync(async (ct) =>\n{\n    ct.ThrowIfCancellationRequested();\n    retryAttempt++;\n    throw new Exception();\n    return await Task.FromResult(new object());\n}, System.Threading.CancellationToken.None)\n.ConfigureAwait(false);\n\nvar actualTimeout = DateTime.UtcNow.Subtract(time).TotalSeconds;\nAssert.IsTrue(retryAttempt < retryCount);\nAssert.AreEqual(OutcomeType.Failure, policyResult.Outcome);\nAssert.IsNull(policyResult.Result);\n\n}\n```. ",
    "atifmir": "@reisenberger thanks for your reply I will read the wiki first and try out your suggestion failing that I will put some example code as you suggested. Thanks for pointing me to slack channel v useful\nCheers. Thanks will do\nGet Outlook for Androidhttps://aka.ms/ghei36\n\nFrom: Dylan Reisenberger notifications@github.com\nSent: Friday, July 13, 2018 9:48:07 PM\nTo: App-vNext/Polly\nCc: atifmir; Mention\nSubject: Re: [App-vNext/Polly] Get Polly to returns reponse after internal server 500 error (#478)\nClosed #478https://github.com/App-vNext/Polly/issues/478.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://github.com/App-vNext/Polly/issues/478#event-1733430600, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AciEcjaPfIT-8sxtp485bNXuaL03Wvjiks5uGQeHgaJpZM4VF2pZ.\n. ",
    "willdean": "Thanks guys - done.. ",
    "vany0114": "@reisenberger thanks for the great explanation! I just wanted to be aware in order to use them properly.. Another doubt is, what happens if my WaitAndRetry policy is configured for 3 attempts and the base of exponential backoff is 2, and my Timeout policy for every retry is, let's say 3 seconds, it means it will never reach even the second try because for the second attempt it will wait for 4 seconds.\nIf so, that means the Timeout policy would cancel the WaitAndRetry policy, so I should be consistent in the way I configure the policies, right?. Thanks  @reisenberger!. Thank you so much for your accurate answer @reisenberger!. @reisenberger  Thanks for always improve the documentation!. Hey guys, I would like to know if someone is working on this, if don't I would like to help on this, then you can assign to me this task. \ud83d\ude03 . Of course, I like that idea, so let @mebjas decide which policy wants to work on since he's the owner of the issue, then I could work on the other issue!. @reisenberger I like the first option: \n\nlatency-injection is a primary-enough concept that it is worth providing some simple/obvious public syntax, even if we (b) generalize the implementation internally.\n\nI think the generalization is a great idea, but I also think an API should be descriptive enough, having said that, the latency should be considered as an exception itself? I don't think so. I think we should separate both concerns even if we gonna call/use the same base class or something internally, for both InjectFault and InjectLatency\n. thanks a lot, @mebjas!, so, @reisenberger, should I wait for mebjas code will be merged in order to start working on InjectLatency  and make my PR?. sure, let me take a look at @mebjas PR. I will happy to help with this \ud83d\ude03 . @mebjas thanks for your work on this! these last days have been a kind of hard for me, but later this week I'm gonna take a look at your PR, thanks again man!\n. > @vany0114\n\n\nI think would be worth adding some tests where the injection rate is covered, but the consumer disable the injection of the fault through the Func\n\nIs this what you mentioned https://github.com/mebjas/Polly/blob/b4da7a7067b6140f1a0ed1f7c7c856432a2e69b1/src/Polly.SharedSpecs/Monkey/InjectFaultAsyncSpecs.cs#L96 ?\n\n@mebjas yes I didn't see it, thanks!. Yeah, I think I can start to work on this tonight, so can I work on this branch, right?. > ...Your changes @vany0114 will be mostly additive, right?\nYeah, I think so. Guys, I have a doubt with one of the overloads of InjectLatency. I'm creating a \"latency provider\" with the help of SystemClock abstraction, like this:\nSync ones \n```\n/\n the rest of the overloads...\n/\npublic static MonkeyPolicy InjectLatency(\n            TimeSpan latency,\n            Func injectionRate,\n            Func enabled)\n        {\n            ...\n            Action latencyProvider = _ => { SystemClock.Sleep(latency, CancellationToken.None); };\n            return Policy.Monkey(latencyProvider, injectionRate, enabled);\n        }\npublic static MonkeyPolicy InjectLatency(\n            Func latency,\n            Func injectionRate,\n            Func enabled)\n        {\n            ...\n            Action latencyProvider = ctx => { SystemClock.Sleep(latency(ctx), CancellationToken.None); };\n            return Policy.Monkey(latencyProvider, injectionRate, enabled);\n        }\n``\nSo, notice that for theFuncoverload I'm passing to theSleep` method the result of the user delegate. \nAsync ones\n```\n/\n the rest of the overloads...\n/\npublic static MonkeyPolicy InjectLatency(\n            TimeSpan latency,\n            Func> injectionRate,\n            Func> enabled)\n        {\n            ...\n            Func latencyProvider = (_, __) => SystemClock.SleepAsync(latency, CancellationToken.None);\n            return Policy.MonkeyAsync(latencyProvider, injectionRate, enabled);\n        }\npublic static MonkeyPolicy InjectLatency(\n            Func> latency,\n            Func> injectionRate,\n            Func> enabled)\n        {\n            ...\n            Func latencyProvider = (ctx, ct) =>\n            {\n                return SystemClock.SleepAsync(latency(ctx, ct).ConfigureAwait(false).GetAwaiter().GetResult(), ct);\n            };\n            return Policy.MonkeyAsync(latencyProvider, injectionRate, enabled);\n        }\n```\nThe point is that for the Func<Context, CancellationToken, Task<TimeSpan>>  overload, right now I'm getting the latency value in a sync fashion, any ideas?. I can do this if you guys want it since I'm working on unit tests right now.\n\nI think the test project (with these tests in place) must declare only one named TestCollection named (say) AmbientContextDependentTestCollection. And this test collection must contain all tests which manipulate either SystemClock or RandomGenerator or both. xUnit gives us a named TestCollection to define a set of tests of which no test must be run in parallel with any other in the same set. As soon as we have one test which manipulates both SystemClock and RandomGenerator, then those tests must not run in parallel against any test which manipulates either SystemClock or RandomGenerator, I think this means all tests which manipulate either or both need to end up in one single test collection.. @mebjas can you give me perms in your repo please, I wasn't able to push the changes.\nremote: Permission to mebjas/Polly.git denied to vany0114.\nfatal: unable to access 'https://github.com/mebjas/Polly.git/': The requested URL returned error: 403. Guys, I added InjectLatency syntax and their tests for review. I just realized that some of the tests didn't pass, I have to take a look at that because on my local were working fine.. @reisenberger this is done, I hadn't seen your advice about override SystemClock behavior, pretty neat \ud83d\ude03 Also thanks to you guys for letting me help you on this and put my two cents, I'm very happy to contribute with Polly, special thanks to @mebjas for letting me be part of his awesome proposal!. Hi @reisenberger, this is what I see:\n\n\nI already signed the CLA before in other contributions that I made for other projects, not sure if you as a contributor only have to sign once, because for this PR the bot didn't ask me.\nThanks again to both of you for the guidance and help, I learned pretty cool things with this contribution and I would like to make more contributions in the future \ud83d\ude03  . @reisenberger sure, thanks for letting us know.. Agreed @reisenberger, so, what's the final approach that you're gonna go with? the locking one or the no locking one?\nAnd thanks for sharing this with us, pretty interesting discussion about randomization in multi-thread scenarios, actually that passed through my mind at some point in the time while we were working on this but I forgot to mention it \ud83d\ude22 . @reisenberger I agree on that, I just put a little comment and thanks for make randomization thread safe.. @reisenberger sounds great!\n\nI totally agree with the creation of a new package.\nI like Simmy but definitively I love Molly.\nSee my name in Polly's contributors would make me happy and proud \ud83d\ude03 \nI could help with the creation of the new repo, etc since next week, I'll be on vacations leave \ud83c\udf89 \n\nThanks @reisenberger for all your extra work on this!\n. Thanks for all your work on this PR, looking forward to see Polly v7 and Simmy!. > @vany0114 @mebjas , Courtesy update: I am working on the Polly v7.0 user documentation (custom policy documentation) which we need for launching v7 (which we need launched, in turn, for Simmy to reference Polly from the external repo).\nThanks @reisenberger! If you need some help, just let me know.. Guys, I picked this one up for now. yeah I can take care of that, thanks guys! ...so should I wait until @mebjas finished with his PR or can I fork from his branch and start to work on it?. Ok, I'll wait until @mebjas finished \ud83d\ude03 . just a heads up, you're not using injectionRateLambda variable. Should we expose it?. fault variable is not being used, same at line 99. Yeah makes sense, thanks!. Just a thought, it took me a while realize that NextDouble member is initialized in the static constructor through the method Reset, that's why I avoid mutating objects because it introduces a kinda \"smoke\" maybe could be clearer something like this, instead of mutating NextDouble from the static constructor:\npublic static Func<double> NextDouble = () => t_threadRandom.Value.NextDouble();\n//or\npublic static Func<double> NextDouble = () => Reset();. > Action latencyProvider = _ => { SystemClock.Sleep(latency, CancellationToken.None); };\nThis guy is not being used, I can remove it after we've moved the codebase over to the new repo.. Don't know if I misunderstood, but I was taking a look at that, and I think the validation you put on ShouldInject method, cover all scenarios since the syntax classes are ensuring that at the end of the day the injectionRate will be always a lambda.. ",
    "vsklyarov-softheme": "@reisenberger thanks a lot! I don't know how I missed this. ",
    "Arash-Sabet": "Thanks @reisenberger . It resolved the issue and hence I am closing this issue.. ",
    "elviswatkins": "Yes, I want to use async, but this is an older repository and cannot make those changes yet.  It is in the backlog for the near future.\nI have gone with the second option and use the overload that takes the  DelegateResult<HttpResponseMessage>.  I also found a link that says it is not necessary to dispose the HttpResponseMessage, but my old school brain cannot get around not calling Dispose.. ",
    "bartelink": "Apologies for not replying sooner - your response helped more than you'll know. After a delayed start, I've since gotten to implement the bulk of my intended functionality as alluded to in the question.\nFirstly, I'll respond to your points based on my learnings:-\n\nCircuitBreaker: You can make an inert breaker right now by configuring durationOfBreak: TimeSpan.Zero. When the break threshold is met the onBreak delegate will be triggered and monitoring can be attached to that for whatiffery. No request will ever see the breaker as open, so it will be inert.\n\nThis works very well. One side issue is that onReset and onHalfOpen need to be special cased not to log as I make them do in the normal case.\n\nBulkhead: You can make an inert bulkhead right now by configuring maxParallelization: Int.MaxValue. You can then monitor BulkheadAvailableCount to determine when an imaginary bulkhead capacity of N would have been exceeded.\n\nThis also works well. One side issue is that in tests I need to jump through a lot of hoops to verify that a dryRun mode work cleanly across multiple threads\n\nPlaying what-if with progressively tightening contraints: Dynamic reconfiguration during running (ie you can reconfigure without having to recycle the process) could support this.\nMaster switch: PolicyRegistry is backed by interfaces. You could easily implement a custom IReadOnlyPolicyRegistry for a master switch or \"kill switch\" to take Polly as a whole in/out of the mix, if desired (if that adds comfort, if experimenting in a live/prod environment). Implementation would be a custom IReadOnlyPolicyRegistry which wraps the normal implementation: ordinarily it would just delegate to a wrapped PolicyRegistry to return the normal policies, but if the \"off\" switch was set it could return NoOpPolicy for every Policy (taking Polly out of the mix).\n\nWhile this is not directly useful to me (I'm effectively building my own PolicyRegistry), it does seem that your proposed scheme could achieve that. (I'm [loosely] unifying call configuration such as base urls etc. with the policies in a single config source)\n\nonBreakerRejected for CircuitBreaker\nWe would be happy to take a PR to add a delegate hook onBreakerRejected, which would operate in a similar way to onBulkheadRejected. If you/anyone want to contribute this, then I can kick-start by staking out the likely new overload signatures.\n\nThis would be useful (including when isolated) - having access to the Context's OperationKey is important but I'm sure you know that.\nI think only adding it to advanced would probably make sense\nRelated is a need to have onTimeoutRejected (I would not be able to remove the exception filter I'm using as a trap logging without that also having such a callback (aside: the elapsed time (as opposed to the timeout, which may or may not have been honored based on the cancellation mode) is useful in there too if Polly is in a position to provide that)) \nmaybe name of callback Should be onRejected ?\nSo, in summary, ordered by my perception of how useful I can imagine them being useful to others (I am not unhappy with my implementation as it is), the following extensions would be useful to me:-\n\nWhile I'm by no means blocked on this, having onRejected delegates added to AdvancedCircuitBreakerAsync, CircuitBreakerAsync and TimeoutAsync would be useful (happy to do a minimal impl of the ones I use as a base PR and then let you point out other overloads you'd like to see also have one.)\nstretch: having ExecuteAsync's callback and timeoutRejected make a TimeSpan sinceStart (but ideally as a StopwatchInterval) available (maybe via Context ?) would be useful\nsuper-stretch: I'd be able to use an onScheduled: Action<int> delegate arg on BulkheadAsync that would signal the (ephemeral) slot one got assigned in the semaphore or queue (so one can log to indicate stuff is being queued, either for real, or (where I apply an artificially unlimited maxParallelization value), to determine more authoritatively whether this is getting scheduled immediately or (implied by allocatedPosition being greater than the real maxParallelization or in my dryRun mode, the maxParallelization I'm simulating) (I doubt this makes any sense, but an int allocatedPosition parameter in the ExecuteAsync Func<CancellatonToken,Task callback would also serve my purposes in this instance)\n\nIn terms of how useful these are to me for my impl specifically:\n- an onRejected avoids the need for a messy exception filter, but given he system is already incurring an exception cost, that's probably not the end of the world perf-wise\n- a sinceStart or a waitInterval on Context would remove some slightly messy code when generating metrics\n- an onScheduled would allow me to emit more consistent metrics in a manner that the current API does not offer me due to the [correctly] lockfree implementation of bulkhead.\nI'm going to close this issue to signal that I'm not blocked and consider my question to be way more than answered already. Next step from my perspective is for you to signal (iff you wish) which, if any of the above, you'd like to see:\na) implemented (in which case we'd make an Issue ticket and I'll hopefully get around to a PR in the coming weeks)\nb) spiked to show how messy they are likely to be in terms of impl (just ask and I'll make a PR to show what I mean). Thanks for the response!\n\nonTimeoutRejected: I think what you're describing already exists as the onTimeout/onTimeoutAsync delegate of the timeout policies. Does that help?\n\nI noticed that initially but then stopped using it - while I could use it, ultimately I need to trace the time interval since the start of the overall request (which to a degree can be inferred from a TimeSpan, but ultimately does not solve all my problems TMI: I also log breaches of SLAs, and have a dryRun mode). So while I likely can take advantage of it, it means stashing and passing stuff in the Context, which I'm seeking to minimize. (Which brings us back to having a StopwatchInterval on the context itself, which I'm not seeking to push as something do do separate to the overall metrics effort).\nThe other point around here is that the general concerns of wanting to trap a rejection and have affected time window be to hand apply equally to all primitives. The most exact fit for my use case would mean having an onCompleted which is called uniformly and provides an indication of whether we are throwing or not (together with the start instant). From looking at the code, that's not something that will fit in cleanly. Additionally, I'm thinking ExecuteAsync providing onCompleted is more likely to be useful for general use (not saying very likely, just more likely). I'm thinking its easier said than done to have a mechanism that's useful both in isolation and across a composed set.\n\neg, the touchpoints for emitting events from each policy. (And indeed dev help may be useful too!).\n\nI'm definitely watching closely, and interested to see where your metrics plans lead - essentially my library is aiming to provide just that; we have some homegrown stuff we are seeking to ultimately generalize and attach to Open Tracing based outputs, but also feed to various metrics sinks. Having a good story for a clean integration of tracing, resilience primitives and metrics is definitely something that's on my radar - I'll be watching the notifications with interest.. Sounds good. Best of all, I'll hopefully be able to validate it by deleting ugly code out of CallPolly while the tests continue to pass (there's still lots of to work to do in terms of making it more approachable, i.e. readmes etc) ;). As I read this, I the name Policy.Monkey is jumping out as the name for the high level InjectXxx driver API - alongside that, obviously nodding to and/or sharing names and doc with Simian Army equivalents should be a primary part of the design and naming in order to make it all just make sense without having to read or write docs.. > Policy.InjectBehaviour( // Or: InjectCustom // Or just: Inject\nSorry should have been clearer; I feel the top level function and namespace can be such that you write Policy.Handle<X>.Monkey(...) or maybe .Chaos - you're monkeying with the call. Also namespace Polly.Monkey can house specific implementation artifacts.\n\nFunc<Context, bool> isOperative\n\nAlso, for any chaos method, I'd say the rate parameter and/or decision-to-apply-this-time function should go near the front of the list of args (assuming this fits with other APIs - I don't know the feel of the DSL well). I have given little thought, but assume you'd have a rate and an optional shouldApply which defaults to ()=>true at the desired rate etc.\n(this is thinking aloud - I've not looked at a chaos suite or DSL for good ways to do it)\nPerhaps Monkey Can control rate and shouldApply and then invoke a Func<context....>, which then gives you access to a mini-DSL which lets you do specific behaviors  ?\nPolicy.Monkey(  .1, new [] { Polly.Monkey.Latency(() => <timespan>), Polly.Monkey.Mangle(result => update(result)) } )\nor\nvar latency = Polly.Monkey.Latency(<specify range in various ways>);\nvar mangle = Polly.Monkey.Mangle<TResult>(<specify handler in various ways>);\nvar chaos =\n    Policy.Monkey( ctx => !ctx.ContainsKey[\"DisableChaos\"], factor =>\n    {\n       if (factor < .95) return null; /// to signal no chaos this time\n       else if (factor < .99) latency\n       else mangle\n   })....   \n// alternately\nvar chaos2 =\n    Policy.Monkey( (ctx, factor) =>\n    {\n       if (factor < .95 || !ctx.ContainsKey[\"DisableChaos\"]) return null; /// to signal no chaos this time\n       else if (factor < .99) return latency;\n       else return mangle;\n   })....   \n} )\nAlso maybe a .Monkeys overload can return an enumerable of IMonkeys to apply for people who want to admit the potential of >1\nThe other thing that's important (to me at least!), is to have a way in which to examine the monkey(s) selected for application (and perhaps even post-application) in order that I can log the ones applied in some meaningful way\nThis should also mesh well with being able to neatly plug in and/or test monkeys you add (or provide custom ones)\ndeclaration: the above is coIoured by me being in the middle of thinking about (and implementing) a call policy wrapping lib (which I intend to open source after bedding into our systems) which uses Polly at its heart. The body of my .Monkey selector method would be driven off a table in a config DSL external to the app. In a yamly type syntax, the policy might define sets of monkeys (tribes?!) which can be applied to actions:-\n```\ntribe general:\n   rate: .10, type: addLatency(min:5ms, max: 2s, p95: .2s)\n   rate: .01, type: badJson,\n   rate: .01, type: noBody\n   rate: .01, type: timeout\n   rate: .01, type: isolate\n   rate: .01, type: brokenCircuit\ntribe latencyOnly:\n   rate: .10, type: addLatency(min:5ms, max: 2s, p95: .2s)\n   rate: .01, type: timeout\nactions:\n  viewCart\n    monkeys: general\n    logging: whenDebug\n  addToCart\n    monkeys: general \n  placeOrder\n    monkeys: latencyOnly\n    logging: max\n``\nI'd parse those into a Discriminated Union which holds the values and would then be looking to map each one to constructing anIMonkey, and use thelogging` to control how much to do.\nAlso for the Latency one - the latency should probably be configurable to include or exclude the time the actual underlying call took (or whether the circuit is isolated or broken etc).\nNow, before I go off the deep end, can someone please provide links to some sensible prior art for this triangular wheel I'm reinventing ;). @mebjas If you do post a dev branch WIP PR, I'd be interested in seeing the API you're working on taking shape - I can't promise I'll have any deep insight, but am happy to provide any feedback I can (FYI #496 contains links to a sneak peak of the library I hinted at. I've yet to commence work on fleshing an example format whereby one'd declare chaos rules alongside normal processing rules per Action (that aspect of the code is very far from polished atm, I'm hoping to address that some time next week)).. I've implemented this in https://github.com/jet/CallPolly/pull/17 - I'm intending to have it prove its worth over there and/or wait for others to have similar needs that we can generalize from before implementing a real solution in this context so am closing this for now. Thanks again @reisenberger for helping me think this through!. Sounds great\n- separate libs FTW (and making sure the path for wrapper libs is smooth and continues to be is great for the ecosystem in general (plug: https://github.com/jet/CallPolly)).  Muchos kudos for taking on the stacks of extra work in the name of doing the right thing @reisenberger\n- Simmy works best for me naming-wise (I guess Simmy is a monkey-pirate with a parrot on it's shoulders in the logo?)\n- I agree with doing a merge with immediate demerge even if the guys are too humble\n- New levels of hierarchy such as MonkeyPolicy and CustomPolicy really need to earn their keep as they start with -100 points for consumers and people walking the code; I'd favor having a common interface (if necessary) but not a common type until it really hurts (I could be missing something and don't have time to dig deep as to whether this even makes sense in practice.). ",
    "mebjas": "@reisenberger Thanks for response! I think I can take this up if that's how it works.. > ## Latency injection proposal\n\nAnother obvious failure injection would be latency:\ncs\nvar latencyPolicy = Policy.InjectLatency(\n    TimeSpan | Func<Context, Timespan> latency, // The latency to inject.\n    decimal | Func<Context, decimal> injectionRate, // A decimal between 0 and 1 (inclusive).  The policy will inject the latency, randomly, that proportion of the time, eg 0.01 means inject latency 1% of the time.\n    Func<Context, bool> enabled // Latency is only injected when returns true.\n);\nOperation\n\nIf enabled returns true, and if a random number between 0 and 1 is less than injectionRate, pause for the specified latency.\nThen execute the passed delegate as normal.\n\n\nIsn't this just another type of fault. If the fault could be passed as an argument we need not write individual classes for each then. Latency injection can be shared as an example.\n\nQuestions\n\nShould the policy pause, then execute the passed delegate?  Or should it execute the passed delegate, obtain the result, then pause before returning the result or failure?  Are there any use cases where it makes any difference?\n\n\nBoth the cases might be needed. While, before the operation makes more sense to me and use case in my mind. If I were to wrap it around the DB call for example - I might be looking at a timeout or so with operation failure. While if the latency is injected post execution that would mean - actual operation succeeded while the upper layer timed out thus forcing me to handle more scenarios. Which ain't bad either \ud83e\udd15 \n. @reisenberger @vany0114 If they were supposed to be different policies I could go with InjectFault. As of now I just started pushing to this branch - https://github.com/mebjas/Polly/tree/dev-mebjas/src/Polly.Shared/InjectFault\nI have a doubt though, how is InjectFault different from InjectLatency?\nIf the definition looked like following:\nc#\nvar chaosPolicy = Policy.InjectFault(\n    Exception | Func<Context, Exception> fault | Action<Context> fault,  // The fault to inject\n    decimal | Func<Context, decimal> injectionRate, // A decimal between 0 and 1 inclusive.  The policy will inject the fault, randomly, that proportion of the time, eg 0.01 means inject the fault randomly 1% of the time.\n    Func<Context, bool> enabled // Faults are only injected when returns true.\n);\nI could use it as following for example to inject latency.\nc#\nPolicy.InjectFault(\n    (ctx) => { Thread.Sleep(5000); },\n    0.2,\n    (ctx) => { return true; }\n);\nIn this way we could define different kinds of faults within the delegate fault itself.\n. @reisenberger \n\n(a) is the concept of Policy.InjectLatency(...) a primary-enough concept in chaos-engineering, that it is worth providing this direct syntax for?\n(b) is there enough commonality of functionality, that we can use a common class (or abstract base class) for the features discussed in this thread?\nRe (a), my thought was that latency-injection is a primary-enough concept that it is worth providing some simple/obvious public syntax, even if we (b) generalise the implementation internally.\nThinking of it like this, yes it makes sense. Policy.InjectLatency(...) could be an example implementation of Policy.InjectFault(...). Thus making both options available as first class citizens within Polly. Or they could both share common execution.\nRe (b), I had the thought yesterday that we could generalise both cases by abstracting out the general injection concept, something like:\n\nWhile this seem to be best generalization which cover both of the above and give users ability to inject any behavior before or after the real delegate execution, is this the real use case of chaos engineering here to inject any piece of code? Would it not lead to wrong usage? Exposing Policy.InjectLatency(...), Policy.InjectFault(...) would ensure focused usage. \nHas this kind of generalization been used for any other concepts implemented in Polly?. @reisenberger @vany0114 Added code for InjectFault policy here. Added support for\nAction<Context> fault\nin InjectFaultEngine.cs which can be used to build InjectLatency policy.\n@reisenberger \nWhat all need to be done before sending a PR here. I see unit tests need to be written. Is Readme and wiki changes also needed?\nAlso, please have a look and tell if I have set of on wrong course code wise.. > As I read this, I the name Policy.Monkey is jumping out as the name for the high level InjectXxx driver API - alongside that, obviously nodding to and/or sharing names and doc with Simian Army equivalents should be a primary part of the design and naming in order to make it all just make sense without having to read or write docs.\nMake sense to me. Just correct me if I am wrong - Your suggestion is to have Policy.Monkey to be the base and we write Policy.InjectXXX on top of it right?. @bartelink Thanks for describing it in such details. As @reisenberger said there are certain ways to how things are implemented in Polly, adhering to that we can implement this in layers. Leaving the method names aside it seem every one agree the fault injection policy shall be governed by the following parameters itself\nfault - Exception | Func <Context, Exception> | Action<Context> ...\nrate - Decimal | Func <Context, Decimal>\nisOperative (or enabled) - Func <Context, Decimal>\n@reisenberger Is it ok if I send a PR to the dev branch after completing everything required by the code of conduct here and have further discussions over there?. @reisenberger @bartelink  - check this out, I haven't written the tests yet but structured the code like this.\nPR - https://github.com/App-vNext/Polly/pull/508. @reisenberger @vany0114 \nI have covered 3/4 checks. Including the code and unit tests. Please have a look and let me know if anything else is needed.. Created this PR to get reviews on the top level functions. Will start working on the tests.. @reisenberger I have dealt with most of the comments. Had some comments in the Engine implementation for supporting TResult. \nAbout the random function, are you proposing to write the method to return deterministic values during the test with some preprocessor directives?. @reisenberger pretty neat, thanks for that.\nThe other question is around usage of DelegateResult<TResult>. Meanwhile, I'll start adding tests.\n. @reisenberger I have added decent amount of test cases to cover all syntaxes. Please have a look.. @martincostello \n\nI was just having a look at this PR out of curiosity, and I wondered is there any argument for the delegates for checking if faults being enabled in the async cases to also have an overload to accept a CancellationToken?\nThe use case I'm thinking of is for where someone might plumb in something where something external is called out to to determine if things are enabled or not? Of course that might be an edge-case and/or a bad idea, but thought I'd just throw the idea out there.\n\nLike this - https://github.com/mebjas/Polly/blob/dev-minhazv/src/Polly.Shared/Monkey/MonkeyEngineAsync.cs#L14 ?. > Yeah, like that.\nYeah problems similar to this was addressed in one or other comments. And was implemented post that.\nLet me know if you are doing further review - I'll take care of all your comments / suggestions in a single push.\n@martincostello - Thanks!. @reisenberger AFAIK the fluent assertion tests would be running in parallel. \nEven if I set \nc++\nRandomGenerator.GetRandomNumber = () => 0.1;\nand reset in Dispose() method. It seems different state of tests are interfering with this common static object. How to deal with this here?. > Hi @mebjas . To force certain tests to not run in parallel, so that they don't cross-pollute:\n\n\nadd this attribute to classes containing tests which manipulate RandomGenerator.GetRandomNumber .\n\n(We should probably rename the attribute to something like: AmbientContextDependentTestCollection.)\n\nAdded the attribute. The attribute is being used in a lot of places. Should it be renamed in this PR?. Let me know if anything else is needed.. > > Should we expose the MonkeyPolicy directly? if so, what's the reason to have the InjectFault ?\n\nI noticed also this duplication - we should likely eliminate it. I intend to review which/what to eliminate when doing a pass for naming of the new elements.\n\nYeah I implemented it based on discussion we had that by default we can give InjectFault and InjectLatency policies - to be used directly with minimal configuration. Users will only have to define Fault, Latency respectively based on overload. \nHowever if they wish to inject any other delegate with own custom logic of fault injection they can use the base Monkey policies.\nWhat we could do is to remove the explicit Exception based overloads in the Monkey policies;\nThus Monkey Policies support only injection Action or Func<TResult> and it's aync / context based overloads.. > Thanks @vany0114 for the extra eyes on this!\n+1 on this, Thanks!. @vany0114 \n\nI think would be worth adding some tests where the injection rate is covered, but the consumer disable the injection of the fault through the Func\n\nIs this what you mentioned https://github.com/mebjas/Polly/blob/b4da7a7067b6140f1a0ed1f7c7c856432a2e69b1/src/Polly.SharedSpecs/Monkey/InjectFaultAsyncSpecs.cs#L96 ?. >> What we could do is to remove the explicit Exception based overloads in the Monkey policies;\n\n\nThus Monkey Policies support only injection Action or Func and it's aync / context based overloads\n\nYes, this seems a good idea; please do.\n\n@reisenberger Will pick this up today;\n\n@mebjas I saw some tiny things in the tests that either you/I could tidy - may post small comment later\n\nSure feel free I'll pick them up.\nThanks!. >> What we could do is to remove the explicit Exception based overloads in the Monkey policies;\n\n\nThus Monkey Policies support only injection Action or Func and it's aync / context based overloads\n\nYes, this seems a good idea; please do.\n\n@reisenberger  This is done; And removed corresponding tests.\n\nI am happy for you work in this branch if @mebjas is. Your changes @vany0114 will be mostly additive, right? (syntax and tests for InjectLatency()), rather than changing what is there. And maybe you can move/borrow some of @mebjas 's tests around injecting delay (I proposed some small changes to those).\n\nYeah no problem\n\nA small number of tests (eg Monkey_With_Context_Introduce_Delay_3()) look like two tests in one; it would be good to split into two tests.\nIf the code of the two resulting tests is substantially similar, we could further consider (not essential) factoring down into 1 test with different input parameters, with the [Theory] attribute.\n\nThere are places where more than one assertions are done, but they are generally around usage of Context object. More like, the behavior of same policy and action when the parameter is true or false. Should they be part of different tests.\n\nWhere tests have Thread.Sleep(200), we can eliminate actual sleep time by using SystemClock.Sleep(200); and overriding the abstracted SystemClock implementation just to record how it was asked to sleep for, like this test does. If we do that, though, we will need to revert this commit of mine, (and maybe rename the single test collection something like AmbientContextDependentTestCollection). If any one of the tests manipulates both RandomGenerator and SystemClock, that needs to never be parallelised with any test manipulating either, so they would all need to form part of one test collection.\n\n@reisenberger I can do this, but yes the tests that uses it, most of them has dependence on RandomGenerator as well. We'd need to create a new test collection here then right.. @vany0114 For the async one\n1. You might want to use the cancellation token\n2. Use async lambda with awaiter\nI guess something like this would follow\n```c++\n/\n the rest of the overloads...\n/\npublic static MonkeyPolicy InjectLatency(\n            TimeSpan latency,\n            Func> injectionRate,\n            Func> enabled)\n        {\n            ...\n            Func latencyProvider = async (_, ct) => {\n                await SystemClock.SleepAsync(latency, ct).ConfigureAwait(false);\n            }\n        return Policy.MonkeyAsync(latencyProvider, injectionRate, enabled);\n    }\n\npublic static MonkeyPolicy InjectLatency(\n            Func> latency,\n            Func> injectionRate,\n            Func> enabled)\n        {\n            ...\n            Func latencyProvider = async (ctx, ct) =>\n            {\n                await SystemClock.SleepAsync(\n                    await latency(ctx, ct).ConfigureAwait(false)).ConfigureAwait(false);\n            };\n        return Policy.MonkeyAsync(latencyProvider, injectionRate, enabled);\n    }\n\n```. > I can do this if you guys want it since I'm working on unit tests right now.\n@vany0114 Hey that would be really helpful \ud83d\udc4d \nThanks. Added you as collaborator. You might have received some invite.. @reisenberger Thanks for all the guidance and help so far. I learned quiet a few things working on this. Looking forward to contribute further.\n@vany0114 Thanks for the work on InjectLatency part :). @reisenberger \n - Makes sense to me too. +1 on this;\n - Simmy name sounds cool :) @bartelink Nice logo idea; another derivation from this could be a parrot with eye patch. Ah, nvm maybe too early for this.\n- Totally agree with following the similar interface suggestion. Would this library have a dependence on Polly? I guess yes!\n- Thanks for merge, de-merge.\n- I'd like to contribute both idea wise and code wise to this new project, kindly let me know where all the discussions happen. \n- Also, I am in if you need any help with the new project.\nThanks @reisenberger @vany0114  @bartelink . Thanks for this! \nIs there any documentation on how this hosting policies outside polly looks like?. @reisenberger I can see a lot of efforts were put into the redesign and it looks much more polished. Thanks for the contribution :)\nLook forward to the new repo and adaptation.. > @vany0114 @mebjas , Courtesy update: I am working on the Polly v7.0 user documentation (custom policy documentation) which we need for launching v7 (which we need launched, in turn, for Simmy to reference Polly from the external repo).\nThanks @reisenberger \nWhere are the documentations maintained? Is there a data for v7?. @reisenberger wow this seem like a lot of work. Kudus to you for this :). Oh yes For injecting any custom action they can use Monkey().\nI'll delete this one. @vany0014 can take care of this . Agree. Sure. I'll send ASAP.. Implemented below. Implemented below. Implemented below. Implemented below. Implemented below. I have a question: \nOne way of injecting the fault is to inject any generic type for example TResult i.e. the same return type as expected from original action being executed as you mentioned here.\nOther way is to expect it to fail with an exception where the expected outcome of the original action is still TResult. And these seem as two disjoint scenarios. So rather than using overload I introduced here wouldn't it be better to have one like this:\nc#\ninternal static TResult Implementation<TResult>(\n            Func<Context, CancellationToken, TResult> action,\n            Context context,\n            CancellationToken cancellationToken,\n            Func<Context, TResult> fault,\n            Func<Context, Double> injectionRate,\n            Func<Context, bool> enabled)\n        {\n            if (enabled(context) && GetRandomNumber() < injectionRate(context))\n            {\n                return fault(context);\n            }\n             return action(context, cancellationToken);\n        }. Ah this is a todo, I'll add.. @reisenberger let me know if this is as you expected.. Including support for TResult fault keeping 4 or so overload for now only. Implemented. Done. Nope will remove. Done;. implemented above. thanks done. Removed the overload in MonkeyPolicy and hence the test. should we have a check for < 0 value? across the code base. why explicit recasting here?. ",
    "grik001": "I will test this again, but I am sure that WaitAndRetryAsync was blocking the exception even if the last try does not succeed. . @reisenberger \nHi, I confirmed that you are right, sorry for wasting your time and thanks for the explanation . ",
    "aaron-hammond": "Hi @reisenberger, thanks for your response. That makes sense. I was just intrigued to as to whether you could add delegates on the fly but it sounds like that's not the case for various reasons. The context should provide enough flexibility for my use case so i'll give that a go in conjunction with supplying my delegates at registration. \nThanks again for the insight!. ",
    "chrisckc": "@reisenberger Thanks for the response, very helpful,  i have just read the update you have made to the docs, nicely written.\nI have now been able to refactor my code to achieve better separation of concerns.\nI still need to use a DelegatingHandler for the case where an exception occurs due to a network error or timeout etc. In this case my PollyInfo object needs to be transferred into the Exception Data.\nThe difference now is that i have been able to split this code out into a separate handler from some other tasks that needed to be done.\nIt would be useful if the Polly.Context could be automatically transferred into the Exception data, or  was made to be a configurable option?\n. @reisenberger Good point, I only quickly jumped back into the code the other day to do a quick refactor to check that your suggestion worked. Now that i have revisited the code properly, as you have pointed out above, in the case of an exception i can obtain the Polly.Context from inside the method which is making the request.\nI have now done away with the additional delegating handler (which had to do a catch and re-throw to inject the \"PollyInfo\" object) as everything Polly related can be handled in my \"ApiClient\" base class. I am still extracting and injecting my \"PollyInfo\" object into either the request properties or the exception data, but now doing it all inside the method which makes the request in the \"ApiClient\" base class.\nThe \"PollyInfo\" object is really \"RetryInfo\" and contains properties such as \"RetryCount\" and a list of objects that describe each failure with the status code, reason and wait time etc.\nThe response or exception is passed along to another class for processing and i decided that it was cleaner to augment the response.request properties or exception data with the \"RetryInfo\" object than pass it over separately.\nThe object which processes the response or exception does not care about where the retry info came from,  if it's available then make use of it. This way i can more easily substitute Polly for another library that handles retries, or re-use code in other projects that don't need Polly. Not that i can see my self using something other than Polly at the moment as it seems to be very good!\nRe my previous statement:\n\nIt would be useful if the Polly.Context could be automatically transferred into the Exception data\n\nI no longer feel that this would provide any benefit.\nThanks!\n. ",
    "aprooks": "I'm not sure if the flow you have described should be implemented like this. When a circuit breaker pops, you might expect the other system to be down for minutes and even hours. \nI would expect a worker to have an environment specific repeat policy. For example, if your worker processes messages from some persistent queue most probably there will be a processing timeout (lease time) which you won't control. So you will have to reschedule your message to be processed (much) later, limit number of workers or stop processing at all for some time.\nIf you still would like to keep processing a single operation as long as possible, you might compose WaitAndRetry policy on top of the circuit breaker. . > I see what you're saying - I didn't anticipate that a circuit breaker would operate on that kind of timescale. Is that always / almost always the case?\nyes, the circuit breaker is designed for mid-services communication, to protect both callee and caller. In a distributed world, a service can go down for hours (remember recent Azure outage for example).\nAlso, you would not like to jump start all your calls once service goes online since you might DDoS another service while it starts up and crash it again. \n\nperhaps it could filter up to the caller or some notification system to say, \"this will be blocked for another X minutes\". \n\nyes, this might be helpful for monitoring, but still, you only know when CB is configured to try close. If errors persist it will be kept open. \nSo maybe, it could be an \"I am still open event\" repeated every X minutes?. ",
    "kierenj": "I see what you're saying - I didn't anticipate that a circuit breaker would operate on that kind of timescale.  Is that always / almost always the case?\nI see your point with the retry suggestion, since it would seem I'm just waiting for a period of time until retrying again. In this case though I'm intending to wait before continuing operation, as opposed to retrying the exact same thing.  However, I could indeed do that.\nI guess it might still be handy to have the duration of the break in the exception, mind - perhaps it could filter up to the caller or some notification system to say, \"this will be blocked for another X minutes\".  But if that's not too important either, no problem to close this off.. ",
    "martincostello": "I was just having a look at this PR out of curiosity, and I wondered is there any argument for the delegates for checking if faults being enabled in the async cases to also have an overload to accept a CancellationToken?\nThe use case I'm thinking of is for where someone might plumb in something where something external is called out to to determine if things are enabled or not? Of course that might be an edge-case and/or a bad idea, but thought I'd just throw the idea out there.. Yeah, like that.. Is this being used anymore since RandomGenerator.GetRandomNumber() was added?. ",
    "hamish-rose": "Hey reisenberger\nNice job, I thought it might have been that also. I had a go at fixing in the same way but my unit test was still failing (only updated one overload, must have been the wrong one)\nNot a production issue for me - OK to wait for v6.2.0. . ",
    "Saphirox": "I expect that WaitAndRetryAsync will be work several times, then when retries would be expired, the circuit breaker should work, thereby it should throw CircuitBreakdownException, but the exception would not throw. Why?. I have found an issue in my settings. Circuit Breaker open timespan was too small to Polly reaction on circuit breaker policy. ",
    "abjrcode": "Sorry missed that part of the documentation \ud83d\ude1e \nThank you for you help clarifying this \ud83d\udc4d . ",
    "zhouguoqing": "We used TimeoutPolicy, and we found the following problem,\nhttps://stackoverflow.com/questions/50371071/c-sharp-polly-with-pessimistic-timeout-strategy-slow-on-multiple-threads\nAfter we set ThreadPool MinSize to 20, or 100, it works. \n. ",
    "AJPoulter": "Dear Dylan,\nThanks for your prompt and very detailed reply. I understand the issue now and I will adopt your proposal of injecting the PolicyRegistry with the configured Policy into the DAL base class, That covers all the bases for me.\nTHANKS!\nKind regards\nAndrew Poulter\najpoulter1961@gmail.com\n+43 (0)660 457 8017\n\nOn 13.10.2018, at 20:28, Dylan Reisenberger notifications@github.com wrote:\n@AJPoulter https://github.com/AJPoulter Yes, the use of a Polly policy in DelegatingHandler middleware of HttpClient https://www.stevejgordon.co.uk/httpclientfactory-aspnetcore-outgoing-request-middleware-pipeline-delegatinghandlers - which is what the .NET Core 2.1 HttpClientFactory extensions configure - is fundamentally incompatible with .ExecuteAndCaptureAsync(). And this is not something the Polly team can change, unfortunately.\nThe reason is that extending DelegatingHandler requires overriding a method of signature https://github.com/aspnet/HttpClientFactory/blob/4dfcf7485e62819d0d73c00d7e7eb53d75abdbd3/src/Microsoft.Extensions.Http.Polly/PolicyHttpMessageHandler.cs#L108\nasync Task SendAsync(HttpRequestMessage request, CancellationToken cancellationToken) \nIf the call through the Polly policy https://github.com/aspnet/HttpClientFactory/blob/4dfcf7485e62819d0d73c00d7e7eb53d75abdbd3/src/Microsoft.Extensions.Http.Polly/PolicyHttpMessageHandler.cs#L130 was changed to .ExecuteAndCaptureAsync(), that would change the return type to Task> - breaking the signature of SendAsync(...) and thus not correctly overriding DelegatingHandler.\n(It would only be possible if Microsoft chose to implement another outgoing codepath through HttpClient based on Polly's PolicyResult, ie tightly coupled to Polly at the HttpClient level, which I don't expect to happen.)\nWhat options does that leave for your case? If you already have a good solution with PolicyWrap and .ExecuteAndCaptureAsync(...), it may be as well to stick with that. If you want to take advantage of the out-of-box definition of .AddTransientHttpErrorPolicy(...) (ie the definition of which faults that handles), then we provide that separately from HttpClientFactory, here https://www.nuget.org/packages/Polly.Extensions.Http/ as we document here https://github.com/App-vNext/Polly/wiki/Polly-and-HttpClientFactory#extending-the-convenience-addtransienthttperrorpolicy-definition. The caveat with using Polly policies on calls through HttpClient without taking the DelegatingHandler approach is that retries can fall foul of the exception that an HttpRequestMessage cannot be re-used once sent.\nIf you want to adapt your existing DAL code to a .NET Core DI -style approach, configuring policies in StartUp.cs, then that is fairly trivial to do. Configure a PolicyRegistry https://github.com/App-vNext/Polly/wiki/PolicyRegistry and add policies to it during StartUp.cs, as exemplified here https://github.com/App-vNext/Polly/wiki/Polly-and-HttpClientFactory#selecting-policies-from-a-policyregistry. Also register an IReadOnlyPolicyRegistry https://github.com/App-vNext/Polly/blob/7eaf7414256ce6e7a86dc60742e3b0e36d893722/src/Polly.Shared/Registry/IReadOnlyPolicyRegistry.cs or IReadOnlyPolicyRegistry during startup, have your DAL layer receive that IReadOnlyPolicyRegistry by DI, and the DAL layer then extracts the policy it needs from the IReadOnlyPolicyRegistry.\nHope that helps.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub https://github.com/App-vNext/Polly/issues/515#issuecomment-429564556, or mute the thread https://github.com/notifications/unsubscribe-auth/AHe7zKVmwDLYef3P81ZVVRlhFGr2jqOzks5ukjDIgaJpZM4XapTb.\n\n\n. ",
    "fatagun": "Thank you for prompt response. I will look into the options.. ",
    "toddmeinershagen": "Actually, no.  I have read and applied the documentation and am still\nseeing the behavior.  I only have one policy added to the HttpClientFactory\nfor my type.  If I use it, the method always times out -- as though it is\nholding up execution.  If not, it executes.  When I looked over at the code\nfor Microsoft.Extensions.Http.Polly, I noticed that they are missing\nasync/await operators.  So, I think that code base is the likely culprit --\nnot Polly proper.\nHope that helps.\nOn Mon, Oct 15, 2018 at 3:34 PM Dylan Reisenberger notifications@github.com\nwrote:\n\n@toddmeinershagen https://github.com/toddmeinershagen Re:\nHappily, I found that Policy.TimeoutAsync() works, just not in the context\nof the HttpClientFactory\nDoes our documentation on using TimeoutPolicy with HttpClientFactory\nhttps://github.com/App-vNext/Polly/wiki/Polly-and-HttpClientFactory#use-case-applying-timeouts\nhelp with the behaviour you are seeing?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/pull/517#issuecomment-430003068, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAK1ZKH7aZNSdUvZy6GVR3ifUMJHXOT_ks5ulPFQgaJpZM4XdE5R\n.\n. @reisenberger I think I got all of the changes that you suggested.  Should I issue a pull request from my feature branch to the master branch or the onV610dev?. @reisenberger I signed the CLA.  Sorry it took a few days.  I was waiting to hear back from the Legal department at my company.  Let me know if you need anything else.  Hope it helps!  (Thank you for your help as well.). @reisenberger Thanks for responding so quickly.  I also appreciate your code.  There are a couple of differences I see with your code.  I was not running my code in a IHostedService.  I was merely new-ing up a ServiceCollection and loading the logging and polly policies.\n\nI also am using multiple policies.  Before the Timeout policy, I have added a retry policy and a circuitbreaker policy.  The other difference is that I am using a timeout policy with a smaller period (10 seconds) and I am calling to a service (Http-based Azure Function hosted locally) that is starting up at the same time and times out on the first try.  It seems like once it fails the first try, the rest are continually failing.  (I am thinking that is what may be tripping the rest of the calls, but I will need more time to experiment.)\ncsharp\nservices.AddHttpClient<CallSyncServiceWithNoBreaker>(client =>\n                    {\n                        //client.BaseAddress = new Uri(\"https://www.google.com\");\n                    })\n                        .SetHandlerLifetime(TimeSpan.FromMinutes(5))\n                        .AddPolicyHandler(retryPolicy)\n                        .AddPolicyHandler(HttpPolicyExtensions\n                            .HandleTransientHttpError()\n                            .Or<TimeoutRejectedException>()\n                            .CircuitBreakerAsync(\n                                handledEventsAllowedBeforeBreaking: 3,\n                                durationOfBreak: TimeSpan.FromSeconds(30))\n                        )\n                        .AddPolicyHandler(timeoutPolicy);\nRight now - the code is not in a single file format, but I could zip it up if you wanted me to send it to you.. @reisenberger Sorry it took my a little bit to get back to you.  The exception that bubbles up is the TimeoutRejectedException that is thrown from the Timeout policy.  The Retry policy is set up to handle those, but after the last retry, it will bubble out.\nI was able to simplify the solution, however, I don't think I can get this same condition to occur with calls to Google.  I would have to have the only the first try to timeout.  Since I don't control the performance of the Google site, that variable would be hard to control.  (You may have some ideas about how to create that condition.)\nAfter having worked with this for a bit, I think the main difference is that I am calling to a local v2 Azure Function.  It still doesn't make sense why that would cause it to consistently fail when using the Timeout policy, but for some reason, it appears that it never is able to make calls to the function even after the function is ready to receive Http triggered traffic.  \nI even tried starting the Azure Function first and then detaching.  When I ran the client application, it still is not able to call out to the Azure function.  I don't believe the same occurs if I am calling an ASP.NET core API.  So, this may have something to do with the calls to the local Azure Function.  Not sure why the Timeout policy would be impacted by this.  \nI have attached the simplified solution to see if you are able to reproduce the issue on your machine.\ntimeouts-broken.zip\n. @reisenberger You are correct that it works at 30 seconds.  I originally had it at 10 seconds and shortened it during the simplification so you could see the issue quicker.  Do you have any idea why if the timeout happens on the first time below a certain limit that the rest of the retries never make connection?. @reisenberger Thanks for the suggestion.  I had to modify the policy slightly to make sure that when the key didn't exist, it would set the subsequent context item.  Otherwise, it failed every time because it only used the 1 second timeout.\nAfter running it against Google, it appears that the first failure does not limit it from successfully running going forward on retries.  So, it doesn't look like there is something wrong with the Timeout policy.\nThere must be something specific to Azure functions running locally.  Perhaps the HTTP trigger mechanism gets backed up with the initial requests while it is loading and blocks other requests from being passed to the function on retries.\nBelow is the updated code you gave me.\n```csharp\nclass Program\n    {\n        static async Task Main(string[] args)\n        {\n            var builder = new HostBuilder()\n                .ConfigureServices((hostContext, services) =>\n                {\n                    var timeoutPolicy = GetSharedTimeoutPolicy();\n                    var retryPolicy = GetSharedRetryPolicyWithJitter();\n                services.AddHttpClient(\"GoogleClient\", client =>\n                {\n                    client.BaseAddress = new Uri(\"https://www.google.com\");\n                })\n                    .AddPolicyHandler(retryPolicy)\n                    .AddPolicyHandler(timeoutPolicy);\n\n                services.AddSingleton<IHostedService, ConsoleService>();\n            });\n\n        await builder.RunConsoleAsync();\n    }\n\n    private static IAsyncPolicy<HttpResponseMessage> GetSharedTimeoutPolicy()\n    {\n        return Policy\n            .TimeoutAsync<HttpResponseMessage>(ctx =>\n                {\n                    var key = \"subsequent\";\n\n                    if (ctx.ContainsKey(key))\n                    {\n                        return (TimeSpan) ctx[key];\n                    }\n\n                    ctx[key] = TimeSpan.FromSeconds(5);\n                    return TimeSpan.FromMilliseconds(1);\n                },\n                onTimeoutAsync: async (context, timeoutPeriod, task) =>\n                {\n                    await Console.Out.WriteLineAsync($\"timeout ({timeoutPeriod})\");\n                });\n    }\n\n    private static IAsyncPolicy<HttpResponseMessage> GetSharedRetryPolicyWithJitter()\n    {\n        return HttpPolicyExtensions\n            .HandleTransientHttpError()\n            .Or<TimeoutRejectedException>()\n            .RetryAsync(\n                retryCount: 3,\n                onRetryAsync: async (e, i) => await Console.Out.WriteLineAsync($\"retry attempt:  {i}\"));\n    }\n}\n\npublic class ConsoleService : IHostedService\n{\n    private readonly IHttpClientFactory _httpClientFactory;\n    public ConsoleService(IHttpClientFactory httpClientFactory)\n    {\n        _httpClientFactory = httpClientFactory;\n    }\n\n    public async Task StartAsync(CancellationToken cancellationToken)\n    {\n        await MakeRequestsToRemoteService();\n    }\n\n    public async Task MakeRequestsToRemoteService()\n    {\n        HttpClient httpClient = _httpClientFactory.CreateClient(\"GoogleClient\");\n\n        HttpResponseMessage response;\n        try\n        {\n            response = await httpClient.GetAsync(\"/\");\n        }\n        catch (Exception e)\n        {\n            Console.WriteLine(\"Failed with exception: \" + e);\n            return;\n        }\n\n        if (!response.IsSuccessStatusCode)\n        {\n            Console.WriteLine(\"Failed with status code: \" + response.StatusCode);\n        }\n        else\n        {\n            Console.WriteLine(\"Succeeded with status code: \" + response.StatusCode);\n        }\n    }\n\n    public Task StopAsync(CancellationToken cancellationToken)\n    {\n        return Task.CompletedTask;\n    }\n}\n\n```. @reisenberger - I appreciate the dialog and ideas.  I did try your suggestion of running the Azure function in a separate instance of Visual Studio and got the same results.  However, when I published the function to the cloud and ran the client locally, it ran fine.\nMy guess is that there is some kind of optimization going on when running locally.  The interesting thing is that the call never makes it to the function.  So, whatever mechanics go on to handle the webhooks triggering do not work well in that scenario.. ",
    "umeshkarthik": "Hi Dylan\nThank you for the response. Fortunately I was able to achieve the desired\nfunctionality. Now I was into a situation where I need to serialize the\nresult into a json format before we write it to the cache. Can we override\nthe OnCacheput method to do that?\nThanks\nUmesh K\nOn Thu, Oct 25, 2018 at 3:08 AM Dylan Reisenberger notifications@github.com\nwrote:\n\n@umeshkarthik https://github.com/umeshkarthik I have an outline for how\nthis could work, but there are some significant potential caveats.\nThe main concern is that an action-filter solution would have to cache\nitems of type IActionResult - but only some implementations of\nIActionResult represent static data which it makes sense to cache.\n\nFileContentResult and ContentResult do (for example) hold static data\n   https://github.com/aspnet/Mvc/blob/release/2.1/src/Microsoft.AspNetCore.Mvc.Core/ContentResult.cs#L14-L27\n   .\nOther implementations of IActionResult do not hold static data: for\n   example FileStreamResult\n   https://github.com/aspnet/AspNetWebStack/blob/749384689e027a2fcd29eb79a9137b94cea611a8/src/System.Web.Mvc/FileStreamResult.cs\n   .\n\nBackground: The return type of a Controller method is an IActionResult\nhttps://github.com/aspnet/Mvc/blob/release/2.1/src/Microsoft.AspNetCore.Mvc.Abstractions/IActionResult.cs\nand this is also the type that action filters must set when they\nshort-circuit the execution\nhttps://docs.microsoft.com/en-us/aspnet/core/mvc/controllers/filters?view=aspnetcore-2.1#cancellation-and-short-circuiting.\nSo the cache would have to cache (and return, on cache hit) items of type\nIActionResult. But IActionResult implementations are in principle dynamic\nand would be reexecuted to generate the result\nhttps://github.com/aspnet/Mvc/blob/release/2.1/src/Microsoft.AspNetCore.Mvc.Abstractions/IActionResult.cs#L20,\neach time they are served from cache.\nTo illustrate some of the potential risks with FileStreamResult ... I have\nnot tried this yet in practice but a number of concerns come to mind\nwith the idea of caching (and re-serving a previously cached)\nFileStreamResult:\n\nIf it worked (functionally), it would in any case be inefficient, as\n   re-serving the file from the file stream would re-read the file stream\n   https://github.com/aspnet/Mvc/blob/a67d9363e22be8ef63a1a62539991e1da3a6e30e/src/Microsoft.AspNetCore.Mvc.Core/Infrastructure/FileResultExecutorBase.cs#L368-L376\nSome streams are forward-only, and may not be amenable to being read\n   a second time.\nCaching something such as a FileStreamResult could constitute a\n   resource leak - Stream is an IDisposable that is probably not intended\n   to be long-lived in a cache.\n\nOther IActionResult implementations which might at first glance seem\ninnocuous to cache also have minor issues. For example, a JSonResult\nmight be thought to be static data which is sensible to cache. But caching\na JSonResult\nhttps://github.com/aspnet/Mvc/blob/eda647e27012cb02bab3474df2c093c39261c90e/src/Microsoft.AspNetCore.Mvc.Formatters.Json/JsonResult.cs\nwould actually cache the raw underlying object\nhttps://github.com/aspnet/Mvc/blob/eda647e27012cb02bab3474df2c093c39261c90e/src/Microsoft.AspNetCore.Mvc.Formatters.Json/JsonResult.cs#L58-L61\n(which might be unexpected or less efficient than caching the JSON string\nin some cases); and the json serialization would be re-executed on each\nserving from cache\nhttps://github.com/aspnet/Mvc/blob/eda647e27012cb02bab3474df2c093c39261c90e/src/Microsoft.AspNetCore.Mvc.Formatters.Json/Internal/JsonResultExecutor.cs#L123-L130\n.\nTL;DR This does not mean an action-filter solution cannot be delivered;\nbut it might only make sense for (might be best limited to) a small subset\nof static content types such as FileContentResult and ContentResult. Or\nif not, it would have to be used with deep understanding and care.\n@umeshkarthik https://github.com/umeshkarthik It would be useful if you\ncould post or state examples (eg method signatures) of the kinds of\nController methods you were thinking of decorating with an action filter.\nAnd, given the above, is this still useful to you?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/521#issuecomment-432938862,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AabhEGLR8v8KWO49zfzh36VN2z0GRj25ks5uoWNngaJpZM4X2bC0\n.\n. Hi Dylan, I am trying to create a cache policy with relative Ttl which only\ncaches ok result. With the code I have posted I coudn\u2019tfind a way of doing\nit. Can you provide a sample code piece for this.\n\nOn Saturday, October 27, 2018, Dylan Reisenberger notifications@github.com\nwrote:\n\n@umeshkarthik https://github.com/umeshkarthik All of the Ttl strategies\nyou mention - RelativeTtl, SlidingTtl, ContextualTtl - provide a smaller\nsubset of functionality than the ResultTtl which it looks like you are\nalready using\nhttps://github.com/App-vNext/Polly/wiki/Cache#caching-responses-only-selectively\n.\n\nTo mimic SlidingTtl, just set IsSliding = true in the code you have\n   already posted.\nTo mimic RelativeTtl, just pass the ts variable in the code you have\n   already posted, as the timespan parameter.\nTo mimic ContextualTtl, you could change the Func function you are defining to make use of data on\n   the context parameter you are passing in.\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/522#issuecomment-433612656,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AabhEIgv2eLHa1yeuJt9Fz14fVO1yTWeks5upEPBgaJpZM4X8YjL\n.\n. Thanks a lot Dylan,\n\nDo you have any sample code for the Contextual ttl for Ok Results.\nThanks\nUmesh K\nOn Sat, Oct 27, 2018 at 1:07 PM Dylan Reisenberger notifications@github.com\nwrote:\n\nHi @umeshkarthik https://github.com/umeshkarthik . Here is the sample\ncode:\nFunc cacheOnly200OKfilter =\n    (context, result) => new Ttl(\n        timeSpan: result.StatusCode == HttpStatusCode.OK ? TimeSpan.FromMinutes(5) : TimeSpan.Zero,    //  this timespan is a relative ttl \n        slidingExpiration: false\n    );\nIAsyncPolicy cacheOnly200OKpolicy =\n    Policy.CacheAsync(\n        cacheProvider: / the cache provider you are using /,\n        ttlStrategy: new ResultTtl(cacheOnly200OKfilter),\n        onCacheError: / whatever cache error logging /\n    ); // (or other richer CacheAsync overload taking an ITtlStrategy ttlStrategy)\n(this is the example from here\nhttps://github.com/App-vNext/Polly/wiki/Cache#caching-responses-only-selectively\nadjusted to slidingExpiration: false; same concept as the code you posted\nabove https://github.com/App-vNext/Polly/issues/522#issue-374417006)\nThis policy will cache items with a relative time-to-live of 5 minutes\n(they will be kept for 5-minutes from the time of putting into the cache),\nprovided the return value's StatusCode == HttpStatusCode.OK. This code\nsample is exactly what you ask for:\na cache policy with relative Ttl which only caches ok result\nThe code sample behaves the same as if you had configured new\nRelativeTtl(TimeSpan.FromMinutes(5)), except it does the other thing you\nask for - only cache ok result.\n\nIf you change to slidingExpiration: true in the above code sample, then\nyou have exactly equivalent to configuring new\nSlidingTtl(TimeSpan.FromMinutes(5)), except that it only caches ok\nresults.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/522#issuecomment-433637898,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AabhEMFwnnRJ-F5lvzgKJobMLEBt-twHks5upJK_gaJpZM4X8YjL\n.\n. Thanks Dylan\n\nOn Sat, Oct 27, 2018 at 1:38 PM Dylan Reisenberger notifications@github.com\nwrote:\n\nHi @umeshkarthik https://github.com/umeshkarthik\nDo you have any sample code for the Contextual ttl for Ok Results?\nI don't. If you need this behaviour, You could read the 35-line source\ncode of ContextualTtl\nhttps://github.com/App-vNext/Polly/blob/master/src/Polly.Shared/Caching/ContextualTtl.cs\nand merge it with the previous sample\nhttps://github.com/App-vNext/Polly/issues/522#issuecomment-433637898 to\ncreate this quite easily for yourself, though.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/App-vNext/Polly/issues/522#issuecomment-433640403,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AabhEDA1P02kxkAp7v0JxteVLJhYvyFYks5upJoEgaJpZM4X8YjL\n.\n. \n",
    "4ybaka": "@reisenberger I need to handle both cases in one circuit breaker: based on exception and based on result. HandleResult method creates PolicyBuilder that handles only result while Handle method handles only exceptions. How can I create policy with both of them?. Thanks, that's what I searched for.. ",
    "timdeschryver": "Woops, sorry... was a bit too fast here.. ",
    "george-polevoy": "@reisenberger Dylan, sure there was a mistake. It was concurrency that is improved, not latency, I've updated the initial issue.\nThe vertical axis represents number of experiments. Virtual massive retry event of simultaneous 100000 requests could result in concurrency splash, which is illustrated. If I try to graph fewer experiments, the graph is just too noisy. I understand that the number of experiments is irrelevant, so it would be usefult to factor it out, and display just some normalized probability distribution.\nI will try to come up with complete benchmark code, so others could explore and experiment.. @grant_d Random is not thread safe, I'm afraid, and I'm using a random seed from Guid.GetHashCode, which is an alternative to using a thread local variable.. @grant-d Randomness is not an issue here. I will share code for you to verify. My computations are now single threaded and deterministic, using a fixed random seed and a shared Random instance, not using Polly. Also, system clock issues can be ruled out, because this is just purely math integration based on deterministic pseudorandom sequence. The entire computation does not depend on runtime issues of NET, it's computed offline. It's just a math routine. I'm computing the delay sequence function itself using virtual regular time intervals.. I see the problem with your code.\nIn addition to min(cap, ...) that AWS team suggested in their blog, you've also added max(seed, ...).\nSay we have 100 requests failed at time t0.\nSeed = 1s, and max=3s.\nWhat is the probability of scheduling a request at time t0 + 1s? It's 1/3, because all of the values lower than t0+1s clamp. So you've got aprox. 33 requests at exact timing: t0 + 1s.\nAll of the other requests will be distributed uniformly. The next clamp will appear at t0 + 2s, and concurrency will be lower (1/3^2 = 1/9 = aprox. 11) at exact timing t0 + 2s.\nThat completely explains the fist two spikes on the graph, which are clearly seen.\nI've examined the code on the AWS blog, and they have slightly different thing. They use random_between, which is not max(something, random.NextDouble).\nRandom between should be a linear mapping, not limiting with Max.\nReplace it with RandomBetween(x, y) = x + r.NextDouble() * (y-x) and the problem is gone.\nI will follow up with the modelling code i'm using.. @reisenberger Algorithm by AWS also has a flaw. On my graphs it looks smoother, but still has spikes, because it's not truly decorrelated.\n@grant-d The problem with clamping using Min Max is that it ruins randomness, flooding the distribution with some constants. As for the API guarantees, you can use math to proof the MAX and MIN. For ex. max recovery interval for retry is a sum of geometric progression, not matter if you randomize inside, if only limited range random variable does not participate in any asymptotic math function such as 1/x.\nMy graphing framework turned to be very useful to analyze the problem. I will share it as I promised as I clean up the code.\nCurrently busy preparing for my DotNext talk this week.\nI will follow up next week. I've put substantial effort into exploring this, and I will make sure we use strong math and also we will have good visual proof of what's happening in our formulas.\n. I have few more results for you to consider.\n\nhttps://gist.github.com/george-polevoy/c0c36c3c22c9c1fe67821b1d8255413a\n. I think \"soft exp, soft delay X\" family looks best to me. It keeps exponential property, has reasonably low peak, low at start, and a hard limit of $2^(n+1) + 1$\nBut most importantly, it reduces the probability of sharp peaks.\nI have another framework which can be used to analyse concurrency issues. I will try to run a simulation with different kinds of retry strategies to see how they actually affect concurrency in fair-scheduling scenarios.\nStochastic algorithms approach is different from deterministic reasoning, no need to clear the interval from 0 to the first retry completely, because you don't know the exact time of start of the transient failure condition anyway, why not to try during that interval, if it helps distribute retries evenly?. @grant-d Yes, I mean immediately.\nInstead of minimum delay, there could be half decay period parameter, which is more meaningful for the exponential function. This would be a point in time when probability drops to 1/2.\nExponential property guarantees that the amount of requests going before the half decay would equal to the amount of request coming after (green and purple on the graph have the same area).\nhttps://www.desmos.com/calculator/qmqaapanvc\n\n. ",
    "flin-zap": "Policy.Async.TResult.ExecuteOverloads.ExecuteAsync() is also missing one. Done, be great if you could make a release with these fixes ASAP. ",
    "Tyrrrz": "Thanks for bringing this to my attention, I didn't realize there were even deeper underlying issues, such as the one described in https://github.com/dotnet/docs/issues/8896.. ",
    "JustinMasters": "Thanks for that @reisenberger, I thought I was just using the wrong puzzle pieces.. ",
    "yuzd": "thanks for your detailed answer. ",
    "PingPongSet": "Hi @reisenberger \nWhat a great comment and advice! \nHowever, I still have problem getting the named HttpClient, and other questions.\nPlease refer to my updated comments at the bottom of OP.\nThanks again in advance.. Hi @reisenberger,\nThanks again for the prompt reply and the great answer.\nI have another question on setting system clock.\nVery much appreicate your help.\nP.S. I posted the same question on StackOverflow a few weeks ago without any answer. I am getting answers right away here. :)\n. Hi @reisenberger,\nThanks again for your prompt reply and advice.\nIt's helpful.\n. ",
    "moerwald": "I fired a small pull request https://github.com/App-vNext/Polly/pull/562. Is that what this topic should handle? Am I on the rigth way?\nThx. Thx for clarification. @SeanFarrow yes I'm still up for helping. Please decline my pull request https://github.com/App-vNext/Polly/pull/562. I'll create a new one.. @SeanFarrow new pull request for Registry Policy -> https://github.com/App-vNext/Polly/pull/564.. @reisenberger rebased against v700 as described here: https://github.com/edx/edx-platform/wiki/How-to-Rebase-a-Pull-Request. Hope I've done it the right way.. @SeanFarrow \n\n\n\nDid you add a readonly registry property to the IReadonlyRegistry tests, or was it already there?\n\n\n\nI added it.. @reisenberger thanks for the guidance. I've changed the PR base branch to v700.. @SeanFarrow done.. @reisenberger , no problem I'll close this PR (based on v700), and create a new one only containing the changes in Registry folder. I'll keep the unit tests untouched. . Changes off CurcuitBreaker weher included, change set was to big. Going to create new PR.. ",
    "digitalmedia34": "Thank you I post the same question, hopefully someone has done something like this before. ",
    "maartenoosterhoff": "Fabulous response time, thank you very much \ud83d\udc4d. ",
    "Shilp": "@reisenberger  Thanks for the response, Sorry it was a mishap form our end where we referenced .net standard Polly instead of .net 4.5. Thanks! . ",
    "maklipsa": "I've also tried switching the server url in the multipleServerRetryPolicy:\nvar multipleServerRetryPolicy = Policy\n    .Handle<Exception>()\n    .WaitAndRetryForeverAsync(\n        sleepDurationProvider: attempt => TimeSpan.FromMilliseconds(30)\n        , onRetry: (exception, attempt) =>\n        {\n            _serverIndex++;\n            WriteLineInColor($\"[MultipleServerRetry]Switching server to:{_servers[_serverIndex]}\", ConsoleColor.Yellow);\n            _retries++;\n        }\n    );\nand executing the policy like this:\nvar serverAddress = _servers[_serverIndex % _servers.Length];\nvar url = serverAddress.AbsoluteUri + \"api/values/\" + _r.Next(0, 5);\nvar text = await policy.ExecuteAsync(async context =>\n{\n    url = serverAddress.AbsoluteUri + \"api/values/\" + _r.Next(0, 5);\n    string msg = await client.GetStringAsync(url);\n    _eventualSuccesses++;\n    return msg;\n}, new Context(new Uri(url).AbsolutePath));\nbut even though the url switches, the circuit breaker seas the initial OperationKey and it still remains open.. Thanks for the answer.\nThe sketch is more than enough.\nBut there is a problem with what solution.\nIn the real case, I'm wrapping the multiple retry policy in a cache policy (when preparing the issue I've stripped it out for clarity).\nIf then I pass a new context into the policy execution I won't have any caching.\nThe real policy tree looks like this:\nvar policy = fallbackForAnyException.WrapAsync(\n                cachePolicy.WrapAsync(\n                    wholeRequestTimeoutPolicy.WrapAsync(\n                        multipleServerRetryPolicy.WrapAsync(\n                            retryPolicy.WrapAsync(\n                                circuitBreakerPolicy.WrapAsync(\n                                    timeoutPolicy\n                                )\n                            )\n                        )\n                    )\n                )\n            );. I didn't have time to code it fully, but it should work. \nThanks for all the help!\nHave a great day :). ",
    "AceHack": "I'm having the same issue and it's not resolved by the steps above. As far as I can tell there is some breaking change between 6.x and 7.x and Microsoft.Extensions.Http.Polly v2.1.1 still references 6.x so it's impossible to upgrade to 7.x and have it work if using Circuit Breaker setup in DI.. ",
    "RichardHowells": "Seems to me that this is the wrong tool for the job.  You don't really want to handle a failure you want to implement a throttle.\nI suggest checking out the DataFlow blocks - they have a concurrency limit.\nOr even just a Semaphore.  This might give you some clues. https://stackoverflow.com/questions/10806951/how-to-limit-the-amount-of-concurrent-async-i-o-operations. Fair enough.\nIt still feels an odd use of Polly to me.\nI think of Polly in terms of deciding what to do, or how to cope, when something goes wrong.  In your use case I cannot see it as something having gone wrong.\nThe SO answer you pointed to seems a nice trick, in that Polly has all the code features he suggests.. ",
    "emilssonn": "Thanks for the answer!\nApart from your linked SO question I also looked at https://stackoverflow.com/a/52053084.\nAccording to that answer the bulkhead policy is good to use when trying to throttle, which is the core of the bulkhead policy functionality from my understanding?. @reisenberger and @RichardHowells thank you for the help!\nIt looks like the bulkhead policy will work for me. . ",
    "JustinKaffenberger": "After looking at the code-base, it seems the way it is currently designed, would make fixing this issue quite complicated. The issue is that, at its core, ExecuteAndCaptureAsync will end up calling ExecuteAsync. ExecuteAsync already evaluates the ExceptionPredicates across any exception that occur, and then rethrows the exception when it isn't successfully handled. \nThen, ExecuteAndCaptureAsync captures the 'rethrown' exception, and evaluates the ExceptionPredicates again in order to accurately populate the result.\nSo all in all, some nasty workarounds would be required for this issue, so I'm going to close it.\nThanks!. That makes sense to me. I managed to find an alternative by using ExecuteAsync but I think I'll switch to using the onRetry delegate since that seems more appropriate. Thanks!. ",
    "justConfused": "@reisenberger thanks for insight that super help full.\nWhat is guidance around following pattern?\nPolicy\n    .Handle<FooException>()\n    .Handle<BarException>()\n    .onRertry(3, (exp, i) -> {\n         if (exp is FooException){\n               log.error(\"foo\")\n         }\n         else if (exp is BarException){\n               log.error(\"Bar\")\n         }\n    })\n    .Execute(() -> DoSomething()). ",
    "stephenpatten": "Hi @reisenberger,\nThank you for taking the time to answer my noob questions!\nI was working through the issues I posted last night, probably about the same time as you answered the original post, and figured out most of it after reading more of the closed issues. \nRe: The act variable was my abbreviation for your action param (Func), which should have been represented by () Lambda syntax. -fixed\nRe: You are correct, once I was able to start testing correctly, the handle could actually be an instance or null. -fixed\n. @reisenberger  Man, you are VERY proactive! How may I help you with Polly going forward? . ",
    "altso": "@reisenberger, thanks for the prompt reply. Adding an explicit package reference to Polly v7.0.3 in PollySeven.MyHttpClient project solves the issue. Hopefully, in my case I have an access to the source code and can make this change. However, do you have any suggestions for the scenario when PollySeven.MyHttpClient is a third party library?. @reisenberger apologies for the confusion. I'll try to explain better.\nLet's assume  PollySeven.MyHttpClient is a third party library. It has only Microsoft.Extensions.Http.Polly package reference and also uses RetryAsync(). Since there is no package references to Polly v7, it compiles against Polly v6 and now has a runtime dependency on Polly.RetrySyntaxAsync.\nPollySeven references PollySeven.MyHttpClient and Polly v7, so Polly v7 is deployed along with PollySeven binaries. As a result, application would fail at runtime as Polly.RetrySyntaxAsync is missing in v7.\nEven though it's similar to how Microsoft.Extensions.Http.Polly is built, I believe there is a major difference between two that you have outlined in your first comment:\n\nThere is nothing in the Microsoft extensions to Polly which rely specifically on Polly v6 features, so this is a safe procedure. \n\nIn case of PollySeven.MyHttpClient it relies on Polly.RetrySyntaxAsync which is no longer available in v7.\nHope this clarifies my questions. I can create a complete example by publishing PollySeven.MyHttpClient to nuget if needed.\n. @reisenberger I updated the example. Please see this commit https://github.com/altso/PollySeven/commit/7a949856ef076e52b32eea466eca494cba3f66c1.\nI used this command to make a package:\ndotnet pack -c Release -o ../LocalPackageSource\nYou can download the binary here: https://github.com/altso/PollySeven/blob/master/LocalPackageSource/PollySeven.MyHttpClient.1.0.0.nupkg?raw=true\n. @reisenberger thanks for looking into that. The issue arose in a couple of internal nuget packages and we fixed that by adding an explicit reference to Polly v7 in each of them.\nI do not think option (a) is a way to go as you will introduce a breaking change between v7 and v8. I also think option (b) is better but not ideal as it requires additional work from other devs who might not be aware of the issue at all.\nA colleague of mine suggested another approach. Let's call it option (c):\n(c) Bring back all the missing types and methods with the same exact signatures as they had in v6, but provide a bridge to v7 implementations. Something like this:\n```c#\nusing System;\nusing System.ComponentModel;\nnamespace Polly\n{\n    [Obsolete]\n    [EditorBrowsable(EditorBrowsableState.Never)]\n    public static class RetryTResultSyntaxAsync\n    {\n        [Obsolete]\n        [EditorBrowsable(EditorBrowsableState.Never)]\n        public static RetryPolicy RetryAsync(PolicyBuilder policyBuilder)\n        {\n            // The line below actually does not compile as there is no conversion\n            // between AsyncRetryPolicy and RetryPolicy.\n            // Call the new api via extension method\n            return policyBuilder.RetryAsync(); \n        }\n    }\n}\n``\nPlease note:\n- types and methods are marked asObsoleteandEditorBrowsable(EditorBrowsableState.Never)to avoid new consumers of this api;\n- there is nothiskeyword in front ofPolicyBuilder` to avoid compiler confusion around extension methods with the same name.\nIf not mistaken, that should bring back the binary compatibility between v6 and v7.\nUnfortunately, I do not know how to make the code above compile and work properly at the moment - just an idea, but I can take a deeper look if you think it's worth it. Let me know.\nAlso, that would be less of an issue if Microsoft.Extensions.Http.Polly is updated to Polly v7. I see the plans to upgrade in v3, but not sure if it's planned for v2.x as well.. Thanks for the clarification @reisenberger. It sounds like there is no way to mitigate this issue in Polly itself. Option (b) worked for me and hopefully will work for others as well.. ",
    "CNBoland": "@reisenberger , yes, that does make sense, thank you for informative response. It seems a pattern to me that when RetryPolicy and CircuitBreaker are interacting this way that BrokenCircuitException should be handled first to account for the case described here. Thanks again for your response.. ",
    "WilkaH": "Enumerable.Empty already uses a single, shared, instance. i.e.\npublic static IEnumerable<TResult> Empty<TResult>() \n{\n    return EmptyEnumerable<TResult>.Instance;\n}\nwhich uses \ninternal class EmptyEnumerable<TElement>\n    {\n        public static readonly TElement[] Instance = new TElement[0];\n    }\n. "
}